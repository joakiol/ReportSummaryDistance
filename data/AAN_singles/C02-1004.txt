Combining unsupervised and supervised methods for PPattachment disambiguationMartin VolkUniversity of ZurichScho?nberggasse 9CH-8001 Zurichvlk@zhwin.chAbstractStatistical methods for PP attachment fall intotwo classes according to the training materialused: first, unsupervised methods trained onraw text corpora and second, supervised meth-ods trained on manually disambiguated exam-ples.
Usually supervised methods win over un-supervised methods with regard to attachmentaccuracy.
But what if only small sets of manu-ally disambiguated material are available?
Weshow that in this case it is advantageous to in-tertwine unsupervised and supervised methodsinto one disambiguation algorithm that outper-forms both methods used alone.11 IntroductionRecently, numerous statistical methods forprepositional phrase (PP) attachment disam-biguation have been proposed.
They canbroadly be divided into unsupervised and su-pervised methods.
In the unsupervised methodsthe attachment decision is based on informationderived from large corpora of raw text.
The textmay be automatically processed (e.g.
by shallowparsing) but not manually disambiguated.
Themost prominent unsupervised methods are theLexical Association score by Hindle and Rooth(1993) and the cooccurrence values by Ratna-parkhi (1998).
They resulted in up to 82% cor-rect attachments for a set of around 3000 testcases from the Penn treebank.
Pantel and Lin(2000) increased the training corpus, added acollocation database and a thesaurus which im-proved the accuracy to 84%.In contrast, the supervised methods are basedon information that the program learns frommanually disambiguated cases.
These cases1This research was supported by the Swiss NationalScience Foundation under grant 12-54106.98.are usually extracted from a treebank.
Su-pervised methods are as varied as the Back-off approach by Collins and Brooks (1995)and the Transformation-based approach byBrill and Resnik (1994).
Back-off scored84% correct attachments and outperformed theTransformation-based approach (80%).
Evenbetter results were reported by Stetina and Na-gao (1997) who used the WordNet thesauruswith a supervised learner and achieved 88% ac-curacy.All these accuracy figures were reported forEnglish.
We have evaluated both unsupervisedand supervised methods for PP attachment dis-ambiguation in German.
This work was con-strained by the availability of only a small Ger-man treebank (10,000 sentences).
Under thisconstraint we found that an intertwined combi-nation of using information from unsupervisedand supervised learning leads to the best re-sults.
We believe that our results are relevant tomany languages for which only small treebanksare available.2 Our training resourcesWe used the NEGRA treebank (Skut et al,1998) with 10,000 sentences from German news-papers and extracted 4-tuples (V,N1, P,N2)whenever a PP with the preposition P and thecore noun N2 immediately followed a noun N1in a clause headed by the verb V .
For example,the sentenceIn Deutschland ist das Gera?t u?ber die BadHomburger Ergos zu beziehen.
[In Germany the appliance may be ordered from Er-gos based in Bad Homburg.
]leads to the 4-tuple (beziehen, Gera?t, u?ber,Ergos).
In this way we obtained 5803 4-tupleswith the human judgements about the attach-ment of the PP (42% verb attachments and 58%noun attachments).
We call this the NEGRAtest set.As raw corpus for unsupervised training weused four annual volumes (around 5.5 mil-lion words) of the ?Computer-Zeitung?
(CZ), aweekly computer science magazine.
This corpuswas subjected to a number of processing steps:sentence recognition, proper name recognitionfor persons, companies and geographical loca-tions (cities and countries), part-of-speech tag-ging, lemmatization, NP/PP chunking, recog-nition of local and temporal PPs, and finallyclause boundary recognition.3000 sentences of the CZ corpus each contain-ing at least one PP in an ambiguous positionwere set aside for manual disambiguation.
An-notation was done according to the same guide-lines as for the NEGRA treebank.
From thesemanually annotated sentences we obtained asecond test set (which we call the CZ test set)of 4469 4-tuples from the same domain as ourraw training corpus.3 Results for the unsupervisedmethodsWe explored various possibilities to extract PPdisambiguation information from the automat-ically annotated CZ corpus.
We first used it togather frequency data on the cooccurrence ofpairs: nouns + prepositions and verbs + prepo-sitions.The cooccurrence value is the ratio of the bi-gram frequency count freq(word, preposition)divided by the unigram frequency freq(word).For our purposes word can be the verb V orthe reference noun N1.
The ratio describesthe percentage of the cooccurrence of word +preposition against all occurrences of word.
Itis thus a straightforward association measure fora word pair.
The cooccurrence value can be seenas the attachment probability of the prepositionbased on maximum likelihood estimates.
Wewrite:cooc(W,P ) = freq(W,P )/freq(W )with W ?
{V,N1}.
The cooccurrence valuesfor verb V and noun N1 correspond to the prob-ability estimates in (Ratnaparkhi, 1998) exceptthat Ratnaparkhi includes a back-off to the uni-form distribution for the zero denominator case.We will add special precautions for this casein our disambiguation algorithm.
The cooccur-rence values are also very similar to the proba-bility estimates in (Hindle and Rooth, 1993).We started by computing the cooccurrencevalues over word forms for nouns, preposi-tions, and verbs based on their part-of-speechtags.
In order to compute the pair frequen-cies freq(N1, P ), we search the training corpusfor all token pairs in which a noun is immedi-ately followed by a preposition.
The treatmentof verb + preposition cooccurrences is differentfrom the treatment of N+P pairs since verb andpreposition are seldom adjacent to each other ina German sentence.
On the contrary, they canbe far apart from each other, the only restric-tion being that they cooccur within the sameclause.
We use the clause boundary informationin our training corpus to enforce this restriction.For computing the cooccurrence values we ac-cept only verbs and nouns with a occurrencefrequency of more than 10.With the N+P and V+P cooccurrence valuesfor word forms we did a first evaluation overthe CZ test set with the following simple dis-ambiguation algorithm.if ( cooc(N1,P) && cooc(V,P) ) thenif ( cooc(N1,P) >= cooc(V,P) ) thennoun attachmentelseverb attachmentWe found that we can only decide 57% of thetest cases with an accuracy of 71.4% (93.9% cor-rect noun attachments and 55.0% correct verbattachments).
This shows a striking imbalancebetween the noun attachment accuracy and theverb attachment accuracy.
Obviously, the cooc-currence values favor verb attachment.
Thecomparison of the verb cooccurrence value andthe noun cooccurrence value too often leads toverb attachment, and only the clear cases ofnoun attachment remain.
This points to an in-herent imbalance between the cooccurrence val-ues for verbs and nouns.
We will flatten out thisimbalance with a noun factor.The noun factor is supposed to strengthenthe N+P cooccurrence values and thus to at-tract more noun attachment decisions.
Whatis the rationale behind the imbalance betweennoun cooccurrence value and verb cooccurrencevalue?
One influence is certainly the well-knownfact that verbs bind their complements strongerthan nouns.The imbalance between noun cooccurrencevalues and verb cooccurrence values can bequantified by comparing the overall tendency ofnouns to cooccur with a preposition to the over-all tendency of verbs to cooccur with a prepo-sition.
We compute the overall tendency as thecooccurrence value of all nouns with all prepo-sitions.cooc(all N, all P ) =?
(N1,P ) freq(N1, P )?N1 freq(N1)The computation for the overall verb cooc-currence tendency is analogous.
For example,in our training corpus we have found 314,028N+P pairs (tokens) and 1.72 million noun to-kens.
This leads to an overall noun cooccur-rence value of 0.182.
The noun factor (nf) isthen the ratio of the overall verb cooccurrencetendency divided by the overall noun cooccur-rence tendency:nf = cooc(all V, all P )cooc(all N, all P )In our training corpus this leads to a noun fac-tor of 0.774/0.182 = 4.25.
In the disambigua-tion algorithm we multiply the noun cooccur-rence value with this noun factor before compar-ing the product to the verb cooccurrence value.This move leads to an improvement of the over-all attachment accuracy to 81.3% (83.1% cor-rect noun attachments and 76.9% correct verbattachments).We then went on to increase the attachmentcoverage, the number of decidable cases, byusing lemmas, decompounding (i.e.
using onlythe last component of a noun compound), andproper name classes.
These measures increasedthe coverage from 57% to 86% of the test cases.For the remaining test cases we used a thresh-old comparison if either of the needed cooc-currence values (cooc(N1, P ) or cooc(V, P )) hasbeen computed from our training corpus.
Thisraises the coverage to 90%.
While coverage in-creased, accuracy suffered slightly and at thisstage was at 78.3%.This is a surprising result given the fact thatwe counted all PPs during the training phases.No disambiguation was attempted so far, wecounted ambiguous and non-ambiguous PPs inthe same manner.
We then added this distinc-tion in the training, counting one point for aPP in a non-ambiguous position and only half apoint for an ambiguous PP, in this way splittingthe PP?s contribution to verb and noun attach-ment.
This move increased the accuracy rate by2% (to 80.5%).So far we have used bigram frequencies overword pairs, (V, P ) and (N1, P ), to computethe cooccurrence values.
Some of the previousresearch (e.g.
(Collins and Brooks, 1995) and(Pantel and Lin, 2000)) has shown that it is ad-vantageous to include the noun from within thePP (called N2) in the calculation.
But mov-ing from pair frequencies to triple frequencieswill increase the sparse data problem.
Thereforewe computed the pair frequencies and triple fre-quencies in parallel and used a cascaded disam-biguation algorithm to exploit the triple cooc-currence values and the pair cooccurrence val-ues in sequence.In analogy to the pair cooccurrence value, thetriple cooccurrence value is computed as:cooc(W,P,N2) = freq(W )/freq(W,P,N2)with W ?
{V,N1}.
With the triple informa-tion (V, P,N2) we were able to identify supportverb units (such as in Angriff nehmen, unterBeweis stellen) which are clear cases of verbattachment.
We integrated this and the triplecooccurrence values into the disambiguation al-gorithm in the following manner.if ( support_verb_unit(V,P,N2) )then verb attachmentelsif (cooc(N1,P,N2) && cooc(V,P,N2))then if ((cooc(N1,P,N2) * nf)>= cooc(V,P,N2))then noun attachmentelse verb attachmentelsif (cooc(N1,P) && cooc(V,P)) thenif ((cooc(N1,P) * nf) >= cooc(V,P))then noun attachmentelse verb attachmentelsif (cooc(N1,P) > threshold(N))then noun attachmentelsif (cooc(V,P) > threshold(V))then verb attachmentThe noun factors for triple comparison andfactor correct incorrect accuracy thresholdnoun attachment 5.47; 5.97 2213 424 83.92% 0.020verb attachment 1077 314 77.43% 0.109total 3290 738 81.67%decidable test cases 4028 (of 4469) coverage: 90.13%Table 1: Attachment accuracy for the CZ test set using cooccurrence valuesfrom unsupervised learning.decision level number coverage accuracysupport verb units 97 2.2% 100.00%triple comparison 953 21.3% 84.36%pair comparison 2813 62.9% 79.95%cooc(N1, P ) > threshold 74 1.7% 85.13%cooc(V, P ) > threshold 91 2.0% 84.61%total 4028 90.1% 81.67%Table 2: Attachment accuracy for the cooc.
method split on decision levels.pair comparison are computed separately.
Thenoun factor for pairs is 5.47 and for triples 5.97.The attachment accuracy is improved to81.67% by the integration of the triple cooc-currence values (see table 1).
A split on thedecision levels reveals that triple comparison is4.41% better than pair comparison (see table 2).The 84.36% for triple comparison demon-strates what we can expect if we enlarge our cor-pus and consequently increase the percentage oftest cases that can be disambiguated based ontriple cooccurrence values.The accuracy of 81.67% reported in table 1 iscomputed over the decidable cases.
If we forcea default decision (noun attachment) on the re-maining cases, the overall accuracy is at 79.14%.4 Results for the supervisedmethodsOne of the most successful supervised methodsis the Back-off model as introduced by Collinsand Brooks (1995).
This model is based onthe idea of using the best information availableand backing off to the next best level when-ever an information level is missing.
For thePP attachment task this means using the at-tachment tendency for the complete quadruple(V,N1, P,N2) if the quadruple has been seen inthe training data.
If not, the algorithm backsoff to the attachment tendency of triples.
Alltriples that contain the preposition are consid-ered: (V,N1, P ); (V, P,N2); (N1, P,N2).
Thetriple information is used if any of the tripleshas been seen in the training data.
Else, thealgorithm backs off to pairs, then to the prepo-sition alone, and finally to default attachment.The attachment tendency on each level iscomputed as the ratio of the relative frequencyto the absolute frequency.
Lacking a large tree-bank we had to use our test sets in turn astraining data for the supervised learning.
In afirst experiment we used the NEGRA test set astraining material and evaluated against the CZtest set.
Both test sets were subjected to thefollowing restrictions to reduce the sparse dataproblem.1.
Verbs, nouns and contracted prepositionswere substituted by their base forms.
Com-pound nouns were substituted by the baseform of their last component.2.
Proper names were substituted by theirname class tag (person, location, com-pany).3.
Pronouns and numbers (in PP complementposition) were substituted by a pronountag or number tag respectively.This means we used 5803 NEGRA quadrupleswith their given attachment decisions as train-ing material for the Back-off model.
We thencorrect incorrect accuracynoun attachment 2291 677 77.19%verb attachment 1015 486 67.62%total 3306 1163 73.98%decidable test cases 4469 (of 4469) coverage: 100%Table 3: Attachment accuracy for the CZ test set using supervised learningover the NEGRA test set based on the Back-off method.decision level number coverage accuracyquadruples 8 0.2% 100.00%triples 329 7.3% 88.75%pairs 3040 68.0% 75.66%preposition 1078 24.1% 64.66%default 14 0.3% 64.29%total 4469 100.0% 73.98%Table 4: Attachment accuracy for the Back-off method split on decision levels.applied the Back-off decision algorithm to de-termine the attachments for the 4469 test casesin the CZ test set.
Table 3 shows the results.Due to the default attachment step in the algo-rithm, the coverage is 100%.
The accuracy isclose to 74%, with noun attachment accuracybeing 10% better than verb attachment.A closer look reveals that the attachmentaccuracy for quadruples (100%) and triples(88.7%) is highly reliable (cf.
table 4) but only7.5% of the test cases can be resolved in thisway.
The overall accuracy is most influenced bythe accuracy of the pairs (that account for 68%of all attachments with an accuracy of 75.66%)and by the attachment tendency of the preposi-tion alone which resolves 24.1% of the test casesbut results in a low accuracy of 64.66%.We suspected that the size of the training cor-pus has a strong impact on the disambiguationquality.
Since we did not have access to anylarger treebank for German, we used cross vali-dation on the CZ test set in a third experiment.We evenly divided this test corpus in 5 partsof 894 test cases each.
We added 4 of theseparts to the NEGRA test set as training ma-terial.
The training material thus consists of5803 quadruples from the NEGRA test set plus3576 quadruples from the CZ test set.
We thenevaluated against the remaining part of 894 testcases.
We repeated this 5 times with the differ-ent parts of the CZ test set and summed up thecorrect and incorrect attachment decisions.The result from cross validation is 5% betterthan using the NEGRA corpus alone as train-ing material.
This could be due to the enlargedtraining set or to the domain overlap of the testset with part of the training set.
We thereforedid another cross validation experiment takingonly the 4 parts of the CZ test set as trainingmaterial.
If the improved accuracy were a resultof the increased corpus size, we would expect aworse accuracy for this small training set.
Butin fact, training with this small set resulted inaround 77% attachment accuracy.
This is bet-ter than training on the NEGRA test set alne.This indicates that the domain overlap is themost influential factor.5 Intertwining unsupervised andsupervised methodsNow, that we have seen the advantages of thesupervised approaches, but lack a sufficientlylarge treebank for training, we suggest combin-ing the unsupervised and supervised informa-tion.
With the experiments on cooccurrencevalues and the Back-off method we have workedout the quality of the various decision levelswithin these approaches, and we will now orderthe decision levels according to the reliability ofthe information sources.We reuse the triple and pair cooccurrence val-ues that we have computed for the experimentswith our unsupervised method.
That meansthat we will also reuse the respective noun fac-tors and thresholds.
In addition, we use theNEGRA test set as supervised training corpusfor the Back-off method.The disambiguation algorithm will now workin the following manner.
It starts off with thesupport verb units as level 1, since they areknown to be very reliable.
As long as no at-tachment decision is taken, the algorithm pro-ceeds to the next level.
Next is the applicationof supervised quadruples (level 2), followed bysupervised triples (level 3).
In section 4 we hadseen that there is a wide gap between the accu-racy of supervised triples and pairs.
We fill thisgap by accessing unsupervised information, i.e.triple cooccurrence values followed by pair cooc-currence values (level 4 and 5).
Even thresholdcomparisons based on one cooccurrence valueare usually more reliable than supervised pairsand therefore constitute levels 6 and 7.
If still nodecision has been reached, the algorithm contin-ues with supervised pair probabilities followedby pure preposition probabilities.
The left-overcases are handled by default attachment.
Be-low is the complete disambiguation algorithmin pseudo-code:if ( support_verb_unit(V,P,N2) )then verb attachment### level 2 ###elsif ( supervised(V,N1,P,N2) ) thenif ( prob(noun_att | V,N1,P,N2) >= 0.5)then noun attachmentelse verb attachment### level 3 ###elsif ( supervised(triple) ) thenif ( prob(noun_att | triple) >= 0.5 )then noun attachmentelse verb attachment### level 4 ###elsif ( cooc(N1,P,N2) && cooc(V,P,N2) )thenif ((cooc(N1,P,N2)*nf) >= cooc(V,P,N2))then noun attachmentelse verb attachment### level 5 ###elsif ( cooc(N1,P) && cooc(V,P) ) thenif ((cooc(N1,P) * nf) >= cooc(V,P))then noun attachmentelse verb attachment### levels 6 / 7 ###elsif ( cooc(N1,P) > threshold(N) )then noun attachmentelsif ( cooc(V,P) > threshold(V) )then verb attachment### level 8 ###elsif ( supervised(pair) ) thenif ( prob(noun_attach | pair) >= 0.5)then noun attachmentelse verb attachment### level 9 ###elsif ( supervised(P) ) thenif ( prob(noun_attach | P) >= 0.5 )then noun attachmentelse verb attachment### level 10 ###else default verb attachmentAnd indeed, this combination of unsuper-vised and supervised information leads to animproved attachment accuracy.
For completecoverage we get an accuracy of 80.98% (cf.
ta-ble 5).
This compares favorably to the accuracyof the cooccurrence experiments plus default at-tachment (79.14%) reported in section 3 and tothe Back-off results (73.98%) reported in table3.
We obviously succeeded in combining thebest of both worlds into an improved behaviorof the disambiguation algorithm.The decision levels in table 6 reveal that thebulk of the attachment decisions still rests withthe cooccurrence values, mostly pair value com-parisons (59.9%) and triple value comparisons(18.9%).
But the high accuracy of the super-vised triples and, equally important, the grace-ful degradation in stepping from threshold com-parison to supervised pairs (resolving 202 testcases with 75.74% accuracy) help to improve theoverall attachment accuracy.We also checked whether the combination ofunsupervised and supervised approaches leadsto an improvement for the NEGRA test set.
Weexchanged the corpus for the supervised train-ing (now the CZ test set) and evaluated over theNEGRA test set.
This results in an accuracy of71.95% compared to 68.29% for pure applica-tion of the supervised Back-off method.
Thatmeans, the combination leads to an improve-ment of 3.66% in accuracy.6 ConclusionsWe have shown that unsupervised approachesto PP attachment disambiguation are about asfactor correct incorrect accuracy thresholdnoun attachment 5.47; 5.97 2400 469 83.65% 0.020verb attachment 1219 381 76.19% 0.109total 3619 850 80.98%decidable test cases 4469 (of 4469) coverage: 100%Table 5: Attachment accuracy for the combination of Back-off and cooccur-rence values for the CZ test set (based on training over the NEGRA test set).decision level number coverage accuracy1 support verb units 97 2.2% 100.00%2 supervised quadruples 6 0.1% 100.00%3 supervised triples 269 6.0% 86.62%4 cooccurrence triples 845 18.9% 84.97%5 cooccurrence pairs 2677 59.9% 80.39%6 cooc(N1, P ) > threshold 71 1.6% 85.51%7 cooc(V, P ) > threshold 81 1.8% 82.72%8 supervised pairs 202 4.5% 75.74%9 supervised prepositions 210 4.7% 60.48%10 default 11 0.3% 54.55%total 4469 100.0% 80.98%Table 6: Attachment accuracy split on decision levels for the combination ofBack-off and cooccurrence values.good as supervised approaches over small man-ually disambiguated training sets.
If only smallmanually disambiguated training sets are avail-able, the intertwined combination of unsuper-vised and supervised information sources leadsto the best results.In another vein of this research we havedemonstrated that cooccurrence frequencies ob-tained through WWW search engines are usefulfor PP attachment disambiguation (Volk, 2001).In the future we want to determine at which de-cision level such frequencies could be integrated.ReferencesE.
Brill and P. Resnik.
1994.
A rule-basedapproach to prepositional phrase attachmentdisambiguation.
In Proceedings of COLING,pages 1198?1204, Kyoto.
ACL.M.
Collins and J. Brooks.
1995.
Preposi-tional phrase attachment through a backed-off model.
In Proc.
of the Third Workshopon Very Large Corpora.D.
Hindle and M. Rooth.
1993.
Structural am-biguity and lexical relations.
ComputationalLinguistics, 19(1):103?120.P.
Pantel and D. Lin.
2000.
An unsupervisedapproach to prepositional phrase attachmentusing contextually similar words.
In Proc.
ofACL-2000, Hongkong.Adwait Ratnaparkhi.
1998.
Statistical modelsfor unsupervised prepositional phrase attach-ment.
In Proceedings of COLING-ACL-98,Montreal.W.
Skut, T. Brants, B. Krenn, and H. Uszko-reit.
1998.
A linguistically interpreted cor-pus of German newspaper text.
In Proc.
ofESSLLI-98 Workshop on Recent Advances inCorpus Annotation, Saarbru?cken.J.
Stetina and M. Nagao.
1997.
Corpusbased PP attachment ambiguity resolutionwith a semantic dictionary.
In J. Zhou andK.
Church, editors, Proc.
of the 5th Work-shop on Very Large Corpora, Beijing andHongkong.Martin Volk.
2001.
Exploiting the WWW asa corpus to resolve PP attachment ambigu-ities.
In Proc.
of Corpus Linguistics 2001,Lancaster, March.
