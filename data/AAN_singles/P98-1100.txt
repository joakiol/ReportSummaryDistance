Text Segmentation Using Reiteration and CollocationAmanda C. JobbinsDepartment of ComputingNottingham Trent UniversityNottingham NG1 4BU, UKajobbins @resumix.comLindsay J. EvettDepartment of ComputingNottingham Trent UniversityNottingham NG1 4BU, UKlje@doc.ntu.ac.ukAbstractA method is presented for segmenting text intosubtopic areas.
The proportion of relatedpairwise words is calculated between adjacentwindows of text to determine their lexicalsimilarity.
The lexical cohesion relations ofreiteration and collocation are used to identifyrelated words.
These relations are automaticallylocated using a combination of three linguisticfeatures: word repetition, collocation andrelation weights.
This method is shown tosuccessfully detect known subject changes intext and corresponds well to the segmentationsplaced by test subjects.IntroductionMany examples of heterogeneous data can befound in daily life.
The Wall Street Journalarchives, for example, consist of a series of articlesabout different subject areas.
Segmenting such datainto distinct topics is useful for informationretrieval, where only those segments relevant to auser's query can be retrieved.
Text segmentationcould also be used as a pre-processing step inautomatic summarisation.
Each segment could besummarised individually and then combined toprovide an abstract for a document.Previous work on text segmentation has used termmatching to identify clusters of related text.
Saltonand Buckley (1992) and later, Hearst (1994)extracted related text portions by matching highfrequency terms.
Yaari (1997) segmented text intoa hierarchical structure, identifying sub-segmentsof larger segments.
Ponte and Croft (1997) usedword co-occurrences to expand the number ofterms for matching.
Reynar (1994) compared allwords across a text rather than the more usualnearest neighbours.
A problem with using wordrepetition is that inappropriate matches can bemade because of the lack of contextual information(Salton et al, 1994).
Another approach to textsegmentation is the detection of semanticallyrelated words.Hearst (1993) incorporated semantic informationderived from WordNet but in later work reportedthat this information actually degraded wordrepetition results (Hearst, 1994).
Related wordshave been located using spreading activation on asemantic network (Kozima, 1993), although onlyone text was segmented.
Another approachextracted semantic information from Roget'sThesaurus (RT).
Lexical cohesion relations(Halliday and Hasan, 1976) between words wereidentified in RT and used to construct lexical chainsof related words in five texts (Morris and Hirst,1991).
It was reported that the lexical chainsclosely correlated to the intentional structure(Grosz and Sidner, 1986) of the texts, where thestart and end of chains coincided with the intentionranges.
However, RT does not capture all types oflexical cohesion relations.
In previous work, it wasfound that collocation (a lexical cohesion relation)was under-represented in the thesaurus.Furthermore, this process was not automated andrelied on subjective decision making.Following Morris and Hirst's work, a segmentationalgorithm was developed based on identifyinglexical cohesion relations across a text.
Theproposed algorithm is fully automated, and aquantitative measure of the association betweenwords is calculated.
This algorithm utiliseslinguistic features additional to those captured inthe thesaurus to identify the other types of lexicalcohesion relations that can exist in text.6141 Background Theory: Lexical CohesionCohesion concerns how words in a text are related.The major work on cohesion in English wasconducted by Halliday and Hasan (1976).
Aninstance of cohesion between a pair of elements ireferred to as a tie.
Ties can be anaphoric orcataphoric, and located at both the sentential andsupra-sentential level.
Halliday and Hasanclassified cohesion under two types: grammaticaland lexical.
Grammatical cohesion is expressedthrough the grammatical relations in text such asellipsis and conjunction.
Lexical cohesion isexpressed through the vocabulary used in text andthe semantic relations between those words.Identifying semantic relations in a text can be auseful indicator of its conceptual structure.Lexical cohesion is divided into three classes:general noun, reiteration and collocation.
Generalnoun's cohesive function is both grammatical ndlexical, although Halliday and Hasan's analysisshowed that this class plays a minor cohesive role.Consequently, it was not further considered.Reiteration is subdivided into four cohesiveeffects: word repetition (e.g.
ascent and ascent),synonym (e.g.
ascent and climb) which includesnear-synonym and hyponym, superordinate ( .g.ascent and task) and general word (e.g.
ascent andthing).
The effect of general word is difficult toautomatically identify because no commonreferent exists between the general word and theword to which it refers.
A collocation is apredisposed combination of words, typicallypairwise words, that tend to regularly co-occur(e.g.
orange and peel).
All semantic relations notclassified under the class of reiteration areattributed to the class of collocation.2 Identifying Lexical CohesionTo automatically detect lexical cohesion tiesbetween pairwise words, three linguistic featureswere considered: word repetition, collocation andrelation weights.
The first two methods representlexical cohesion relations.
Word repetition is acomponent of the lexical cohesion class ofreiteration, and collocation is a lexical cohesionclass in its entirety.
The remaining types of lexicalcohesion considered, include synonym andsuperordinate (the cohesive ffect of general wordwas not included).
These types can be identifiedusing relation weights (Jobbins and Evett, 1998).Word repetition: Word repetition ties in lexicalcohesion are identified by same word matches andmatches on inflections derived from the same stem.An inflected word was reduced to its stem by look-up in a lexicon (Keenan and Evett, 1989)comprising inflection and stem word pair records(e.g.
"orange oranges").Collocation: Collocations were extracted from aseven million word sample of the LongmanEnglish Language Corpus using the associationratio (Church and Hanks, 1990) and outputted to alexicon.
Collocations were automatically located ina text by looking up pairwise words in this lexicon.Figure 1 shows the record for the headword orangefollowed by its collocates.
For example, thepairwise words orange and peel form a collocation.Iorange free green lemon peel red \]state yellow IFigure 1.
Excerpt from the collocation lexicon.Relation Weights: Relation weights quantify theamount of semantic relation between words basedon the lexical organisation of RT (Jobbins andEvett, 1995).
A thesaurus is a collection ofsynonym groups, indicating that synonym relationsare captured, and the hierarchical structure of RTimplies that superordinate relations are alsocaptured.
An alphabetically-ordered in ex of RTwas generated, referred to as the ThesaurusLexicon (TLex).
Relation weights for pairwisewords are calculated based on the satisfaction ofone or more of four possible connections in TLex.3 Proposed Segmentation AlgorithmThe proposed segmentation algorithm comparesadjacent windows of sentences and determinestheir lexical similarity.
A window size of threesentences was found to produce the best results.Multiple sentences were compared because615calculating lexical similarity between words is toofine (Rotondo, 1984) and between individualsentences i  unreliable (Salton and Buckley, 1991).Lexical similarity is calculated for each windowcomparison based on the proportion of relatedwords, and is given as a normalised score.
Wordrepetitions are identified between identical wordsand words derived from the same stem.Collocations are located by looking up word pairsin the collocation lexicon.
Relation weights arecalculated between pairwise words according totheir location in RT.
The lexical similarity scoreindicates the amount of lexical cohesiondemonstrated by two windows.
Scores plotted on agraph show a series of peaks (high scores) andtroughs (low scores).
Low scores indicate a weaklevel of cohesion.
Hence, a trough signals apotential subject change and texts can besegmented atthese points.4 Experiment 1: Locating Subject ChangeAn investigation was conducted to determinewhether the segmentation algorithm could reliablylocate subject change in text.Method: Seven topical articles of between 250 to450 words in length were extracted from the WorldWide Web.
A total of 42 texts for test data weregenerated by concatenating pairs of these articles.Hence, each generated text consisted of twoarticles.
The transition from the first article to thesecond represented a known subject change point.Previous work has identified the breaks betweenconcatenated texts to evaluate the performance oftext segmentation algorithms (Reynar, 1994;Stairmand, 1997).
For each text, the troughs placedby the segmentation algorithm were compared tothe location of the known subject change point inthat text.
An error margin of one sentence itherside of this point, determined by empiricalanalysis, was allowed.Results: Table 1 gives the results for thecomparison of the troughs placed by thesegmentation algorithm to the known subjectchange points.linguistic featuretroughs placed subject changepoints locatedaverage I std.
dev.
(out of 42 poss.
)word repetition 7.1 3.16 41collocation (97.6%)word repetition 7.3 5.22 41relation weights (97.6%)41 word repetition 8.5 3.62 (97.6%)collocation 40 5.8 3.70 relation weights (95.2%)word repetition 40collocation 6.4 4.72relation weights (95.2%)39 relation weights 7 4.23 (92.9%)35 collocation 6.3 3.83 (83.3%)Table 1.
Comparison of segmentation algorithmusing different linguistic features.Discussion: The segmentation algorithm using thelinguistic features word repetition and collocationin combination achieved the best result.
A total of41 out of a possible 42 known subject changepoints were identified from the least number oftroughs placed per text (7.1).
For the text where theknown subject change point went undetected, atotal of three troughs were placed at sentences 6, 11and 18.
The subject change point occurred atsentence 13, just two sentences after a predictedsubject change at sentence 11.In this investigation, word repetition aloneachieved better esults than using either collocationor relation weights individually.
The combinationof word repetition with another linguistic featureimproved on its individual result, where lesstroughs were placed per text.5 Experiment 2: Test Subject EvaluationThe objective of the current investigation was todetermine whether all troughs coincide with asubject change.
The troughs placed by the616algorithm were compared to the segmentationsidentified by test subjects for the same texts.Method: Twenty texts were randomly selected fortest data each consisting of approximately 500words.
These texts were presented to seven testsubjects who were instructed to identify thesentences atwhich a new subject area commenced.No restriction was placed on the number of subjectchanges that could be identified.
Segmentationpoints, indicating a change of subject, weredetermined by the agreement of three or more testsubjects (Litman and Passonneau, 1996).
Adjacentsegmentation points were treated as one pointbecause it is likely that they refer to the samesubject change.The troughs placed by the segmentation algorithmwere compared to the segmentation pointsidentified by the test subjects.
In Experiment 1, thetop five approaches investigated i entified at least40 out of 42 known subject change points.
Due tothat success, these five approaches were applied inthis experiment.
To evaluate the results, theinformation retrieval metrics precision and recallwere used.
These metrics have tended to beadopted for the assessment of text segmentationalgorithms, but they do not provide a scale ofcorrectness (Beeferman et al, 1997).
The degree towhich a segmentation point was 'missed' by atrough, for instance, isnot considered.
Allowing anerror margin provides some degree of flexibility.An error margin of two sentences either side of asegmentation point was used by Hearst (1993) andReynar (1994) allowed three sentences.
In thisinvestigation, an error margin of two sentences wasconsidered.Results: Table 2 gives the mean values for thecomparison of troughs placed by the segmentationalgorithm to the segmentation points identified bythe test subjects for all the texts.Discussion: The segmentation algorithm usingword repetition and relation weights incombination achieved mean precision and recallrates of 0.80 and 0.69, respectively.
For 9 out of the20 texts segmented, all troughs were relevant.Therefore, many of the troughs placed by thesegmentation algorithm represented valid subjectlinguisticfeatureword repetition\]relation weightsword repetitioncollocationword repetitioncollocationrelation weights lcollocationrelation weightsword repetition Imean values for all textsrelevant!relevant nonrel, prec.found found rec.4.50 3.10 1.00 0.80 0.694.50 2.80 0.85 0.80 0.624.50 2.80 0.85 0.80 0.624.50 2.75 0.90 0.80 0.604.50 2.50 0.95 0.78 0.56Table 2.
Comparison of troughs to segmentationpoints placed by the test subjects.changes.
Both word repetition in combination withcollocation and all three features in combinationalso achieved a precision rate of 0.80 but attained alower recall rate of 0.62.
These results demonstratethat supplementing word repetition with otherlinguistic features can improve text segmentation.As an example, a text segmentation algorithmdeveloped by Hearst (1994) based on wordrepetition alone attained inferior precision andrecall rates of 0.66 and 0.61.In this investigation, recall rates tended to be lowerthan precision rates because the algorithmidentified fewer segments (4.1 per text) than thetest subjects (4.5).
Each text was only 500 words inlength and was related to a specific subject area.These factors limited the degree of subject changethat occurred.
Consequently, the test subjectstended to identify subject changes that were moresubtle than the algorithm could detect.ConclusionThe text segmentation algorithm developed usedthree linguistic features to automatically detectlexical cohesion relations across windows.
Thecombination of features word repetition andrelation weights produced the best precision andrecall rates of 0.80 and 0.69.
When used in617isolation, the performance of each feature wasinferior to a combined approach.
This fact providesevidence that different lexical relations aredetected by each linguistic feature considered.Areas for improving the segmentation algorithminclude incorporation of a threshold for troughs.Currently, all troughs indicate a subject change,however, minor fluctuations in scores may bediscounted.
Future work with this algorithm shouldinclude application to longer documents.
Withtrough thresholding the segments identified inlonger documents could detect significant subjectchanges.
Having located the related segments intext, a method of determining the subject of eachsegment could be developed, for example, forinformation retrieval purposes.ReferencesBeeferman D., Berger A. and Lafferty J.
(1997) Textsegmentation using exponential models, Proceedingsof the 2nd Conference on Empirical Methods inNatural Language ProcessingChurch K. W. and Hanks E (1990) Word associationnorms, mutual infotTnation and lexicograph),Proceedings of the 28th Annual Meeting of theAssociation for Computational Linguistics, pp.
76-83Grosz, B. J. and Sidner, C. L. (1986) Attention,intentions and the structure of discourse,Computational Linguistics, 12(3), pp.
175-204Halliday M. A. K. and Hasan R. (1976) Cohesion inEnglish, Longman GroupHearst M. A.
(1993) Text Tiling: A quantitative approachto discourse segmentation, Technical Report 93/24,Sequoia 2000, University of California, BerkeleyHearst M. A.
(1994) Multi-paragraph segmentation ofexpositor), texts, Report No.
UCB/CSD 94/790,University of California, BerkeleyJobbins A.
C and Evett L. J.
(1995) Automaticidentification of cohesion in texts: Exploiting thelexical organisation of Roget's Thesaurus,Proceedings of ROCLING VIII, Taipei, TaiwanJobbins A. C. and Evett L. J.
(1998) Semantich~formation from Roget's Thesaurus: Applied to theCorrection of Cursive Script Recognition Output,Proceedings of the International Conference onComputational Linguistics, Speech and DocumentProcessing, India, pp.
65-70Keenan E G and Evett L. J.
(1989) Lexical structure fornatural language processing, Proceedings of the 1stInternational Lexical Acquisition Workshop at IJCAIKozima H. (1993) Text segmentation based on similariO,between words, Proceedings of the 31st AnnualMeeting on the Association for ComputationalLinguistics, pp.
286-288Litman D. J. and Passonneau R. J.
(1996) Combiningknowledge sources for discourse segmentation,Proceedings of the 33rd Annual Meeting of theAssociation for Computational LinguisticsMorris J. and Hirst G. (1991) Lexical cohesioncomputed by thesaural relations as an indicator of thestructure of text, Computational Linguistics, 17(1),pp.
21-48Ponte J. M. and Croft W. B.
(1997) Text Segmentation byTopic, 1st European Conference on Research andAdvanced Technology for Digital Libraries(ECDL'97), pp.
113-125Reynar J. C. (1994) An automatic method of findingtopic boundaries, Proceedings of the 32nd AnnualMeeting of the Association for ComputationalLinguistics (Student Session), pp.
331-333Rotondo J.
A.
(1984) Clustering analysis of subjectivepartitions of text, Discourse Processes, 7 pp.
69-88Salton G. and Buckley C. (1991) Global te.rt matchingfor information retrieval, Science, 253, pp.
1012-1015Salton G. and Buckley C. (1992) Automatic te.rtstructuring experiments in "Text-Based IntelligentSystems: Current Research and Practice inInformation Extraction and Retrieval," P. S. Jacobs,ed, Lawrence Earlbaum Associates, New Jersey, pp.199-210Salton G., Allen J. and Buckley C. (1994) Automaticstructuring and retrieval of large text fles,Communications of the Association for ComputingMachinery, 37(2), pp.
97-108Stairmand M. A.
(1997) Textual context analysis forinformation retrieval, Proceedings ofthe ACM SIGIRConference on Research and Development inInformation Retrieval, Philadelphia, pp.
140-147Yaari Y.
(1997) Segmentation of expositor3., texts byhierarchical agglomerative clustering, RANLP'97,Bulgaria618
