LAW VIII - The 8th Linguistic Annotation Workshop, pages 139?148,Dublin, Ireland, August 23-24 2014.Interactive Annotation for Event Modality in Modern Standardand Egyptian Arabic TweetsRania Al-Sabbagh?, Roxana Girju?, Jana Diesner?
?Department of Linguistics and Beckman Institute?School of Library and Information ScienceUniversity of Illinois at Urbana-Champaign, USA{alsabba1, girju, jdiesner} @illinois.eduAbstractWe present an interactive procedure to annotate a large-scale corpus of Modern Standard andEgyptian Arabic tweets for event modality that comprises obligation, permission, commitment,ability, and volition.
The procedure splits up the annotation process into a series of simplifiedquestions, dispenses with the requirement of expert linguistic knowledge, and captures nestedmodality triggers and their attributes semi-automatically.1  IntroductionEvent modality, according to Palmer (2001), describes events that are not actualized but aremerely potential.
It comprises obligation, permission, commitment, ability, and volition.
Bothobligation and permission emanate from an external authority such as the law; whereascommitments are the obligations placed by speakers on themselves as in promises.
Ability is the(in)capacity to do something.
Volition is broadly defined as intensions, desires, wishes, andpreferences.
Event modality is used for several NLP tasks, including sales and marketinganalysis (Ramanand et al.
2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon etal.
2013), the automatic detection of request emails (Lampert et al.
2010), and the classificationof animacy and writers' emotions (Liao and Liao 2009, Bowman and Chopra 2012).To-date, there are no large-scale Arabic corpora annotated for event modality compared toEnglish (Baker et al.
2010, 2012; Rubinstein et al.
2013), Japanese (Matsuyoshi et al.
2010),Portuguese (Hendrickx et al.
2012), and Chinese (Cui and Chi 2013).
One obstacle for thecreation of modality-annotated corpora is the lack of consensus definitions of modality and itsattributes to be rendered into annotation tasks and guidelines.
Furthermore, most modalityannotation schemes use sophisticated theoretical guidelines that need annotators with linguisticbackground; hence, annotation typically takes place in in-lab settings at small scales.In this paper, we present an interactive annotation procedure to annotate event modality andits attributes of sense, polarity, intensification, tense, holders, and scopes in Modern Standardand Egyptian Arabic tweets.
The procedure depicts the following ideas: first, it defines eachannotation task as a series of questions displayed1/hidden based on prior answers; second, itavoids lengthy theoretically-sophisticated definitions and uses the questions instead assimplified self-explanatory annotation prompts; and third, based on the elicited answers itautomatically determines nested triggers and their attributes.
The fact that our procedure doesnot require special linguistic background and consists of easy-to-administer questions makes iteligible for large-scale crowdsourcing annotation.Our corpus comprises 9949 unique tweets, annotated for 12134 tokens that map to 315 uniquetypes of event modality triggers and their attributes of sense, polarity, intensification, tense,holders, and scopes.
The reason to work on the genre of tweets is that our corpus is part of alarger project to incorporate linguistic features, such as modality, with network-based featuresto automatically identify the key players of political discourse on Twitter for countries withfast-changing politics such as Egypt.
The fact that our corpus is harvested from the ArabicEgyptian Twitter entails that the corpus is diglossic for Modern Standard Arabic (MSA), theThis work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers andproceedings footer are added by the organizers.
License details: http:// creativecommons.org/licenses/by/4.0/139formal Arabic variety, and Egyptian Arabic (EA), the native Arabic dialect of Egypt.
Weevaluate the annotation results with Krippendorff's alpha (Krippendorff 2011).
Results showhigh inter-annotator reliability rates, indicating that our annotation scheme and procedure areeffective.
The contribution of this paper, therefore, is twofold: first, we create a novel annotatedresource for Arabic NLP that is larger than existing corpora even for languages other thanArabic; and second, we present an efficient and easy-to-administer annotation procedure withinteractive crowdsourcing potentials.The rest of this paper is organized as follows: Section 2 outlines the annotation scheme,guidelines and the interactive procedure; Section 3 gives examples for the final outputrepresentations; Section 4 describes corpus harvesting and sampling; Section 5 provides theannotation results and disagreement analysis; and Section 6 compares and contrasts our workwith related work.2  Annotation Scheme: Tasks and GuidelinesOur annotation scheme comprises six tasks to label sense, polarity, intensification, tense,holders, and scopes for each event modality.
Prior to the beginning of the interactive procedure,we highlight all event modalities in each tweet using a string-match algorithm and the lexiconsfrom Al-Sabbagh et al.
(2013, 2014a).
The algorithm finds all potential event modality triggers(i.e.
words/phrases that convey event modality) within each tweet in our corpus and marks themas annotation units.
A total of 12134 candidate triggers are highlighted in 9949 tweets.2.1 Task 1: SenseSense annotation is to decide for each candidate trigger in context whether it actually conveysevent modality given the tweet's context.
The same present participle ????
HAbb in example 1 isa volition trigger meaning I want/desire; whereas in example 2 it is a non-modal presentparticiple meaning like/prefer/respect.1.
????
????
????
[ ????
??
???
????
[ 1TbEA >nA m$ HAbb [Emrw mwsY yksb]Definitely, I do not want [Amr Moussa to win].2.
???
????
?????????
????????
??
: ????
????
#egypt #qalyoumEmrw >dyb: rsmyA AlktAtny m$ HAbb >bw HAmd #egypt #qalyoumAmr Adeeb: Alkatatny does not officially like Abu Hamed #egypt #qalyoumWe define sense annotation as a synonymy judgment task, following Al-Sabbagh et al.
(2013,2014b).
Each event modality sense is represented by an exemplar set manually selected so that:(1) each exemplar is an unambiguous event modality trigger; (2) exemplars are in both MSAand EA; (3) exemplars comprise both simple words and multiword expressions; (4) exemplarsare both affirmative and negative; and (5) exemplars are of different intensities.
Presented witha pre-highlighted candidate trigger in context and the exemplar sets, annotations are to decidewhether the candidate trigger is synonymous with any of the exemplar sets.
If not, the trigger isthen assumed as non-modal.If an annotator decides that a given candidate trigger is a non-modal, no further questionsabout polarity, intensification, tense, holders, or scopes are displayed.
In order to guarantee thatannotators do not select the non-modal option as an easy escape, they are not allowed to moveforward without giving at least one synonym of their own to the candidate trigger.2.2 Task 2: PolarityTask 2 uses as input the candidates labeled as valid event modality triggers in Task 1 and labeleach as either affirmative (AFF) or negative (NEG).
To decide, annotators are instructed toconsider the absence/presence of:?
Negation particles such as ??
m$ (not), ??
lA (not), and ???
gyr (not), among others.?
Negation affixes, especially in EA, like the circumfix m...$ in ?????
mqdr$ (I cannot).1 Throughout the examples, modality triggers are marked in boldface, and scopes are in-between brackets.140?
Negative polarity items like ????
Emry (never) and ??
???
lm yEd (no longer).?
Negative auxiliaries where negation is placed on the past tense auxiliary as in ?????
???
?mknt$ EAyz (I did not want).?
Inherently-negative triggers that encode negation in their lexical meanings such as ???
?EAjz (incapable) and ????
ymnE (prohibit).?
Embedding under negated epistemic modality triggers as in ??
?????
???
???
lA >Etqd >nhyjb (I do not think it is necessary) which entails that the speaker is not actually settingan obligation.Annotators are instructed that using multiple negation markers results in an affirmative sense.Thus, ??
????
lm yEjz (he was not unable to) means that he was actually able to.
Annotators arerequired to give the reason for negation if they decide that a given trigger is negative.2.3 Task 3: IntensificationEvent modality triggers have different lexical intensities (i.e.
intensities encoded in the lexicalmeaning of the word/phrase regardless of the context).
In obligation triggers, for instance, evenwithout a context, Arabic speakers know that ?????
Drwry (necessary) expresses a highernecessity than ???????
AlmfrwD (should).
When used in context, the trigger's lexical intensitycan be maintained as is, or amplified/mitigated by such linguistic means as:?
Modification: adverbs like ?????
tmAmA (absolutely) amplify lexical intensity; whereasmitigation is invoked by such adverbs as ?????
gAlbA (most probably).?
Categorical negation typically amplifies lexical intensity as in ??
???????
????
m$AlmfrwD >bdA (it should never be).?
Emphatic expressions such as ??
qd (indeed), ?????
wAllh (I swear), and ??
??
????
mn klqlby (wholeheartedly), among others, lead to lexical intensity amplification.?
Coordination of two or more triggers typically results in intensity amplification as in????
??????
lAzm wDrwry (must and necessary).?
Embedding under epistemic modality triggers can affect the lexical intensities of eventmodality triggers.
In ?????
??
???????
??
>Etqd mn AlDrwry >n (I think it is necessaryto) the strong obligation associated with ???????
AlDrwry (necessary) is mitigated bythe moderate-intensity epistemic ?????
>Etqd (I think), being embedded under it.The annotators' task for intensification annotation is to decide for each candidate labeled as avalid event modality trigger in Task 1 whether its lexical intensity is amplified (AMP), mitigated(MTG) or maintained (AS IS).
During interactive annotation, annotators are asked to provide thereason for their selection; that is, whether the lexical intensity is affected by modification,coordination, negation, embedding or any other reason whether listed above or not.2.4 Task 4: TenseIn this version of our event modality corpus, we work on the present and past tenses only.
Thus,Task 4 is to decide for each valid event modality trigger from Task 1 whether it is present (PRS)or past (PST).
Annotators are required to give their reasons for selecting either PRS or PST.2.5 Task 5: HoldersHolder annotation identifies the source of the obligation, permission, commitment, ability, orvolition.
In example 3, the source that sets the obligation that Egyptians have to learn themeaning of democracy is the Twitter user.3.
????????
???????
????
???
??????????
?????
[ ????
[lAzm [AlmSryyn ytElmwA yEny <yh dymwqrATyp Al>wl][Egyptians have to learn what democracy is first]The holder is not always the Twitter user, however.
In example 4, the Twitter user quotesKamal Alganzoury - a former Egyptian Prime Minster - stating that he does not want to141continue as the Prime Minister.
Therefore, the holder of the negated volition trigger ???
???
???
?lys ldy rgbp (not have a will) is Alganzoury not the Twitter user.
This is an example of thenested holder notion first proposed by Wiebe et al.
(2005) and Saur?
and Pustejovsky (2009).4.
?????????
[ ??
???
????
???
: ???????
????
????????
[  #SCAF #Tahrir #EgyptAldktwr kmAl Aljnzwry: lys ldy rgbp fy [AlAstmrAr] #SCAF #Tahrir #EgyptDr.
Kamal Alganzoury: I do not wish to [continue] #SCAF #Tahrir #EgyptAnother example of nested holders is example 5.
We know that the regime is incapable ofmaintaining security and protecting the people only because the Twitter user says so.
Putdifferently, the best way to understand this tweet is that according to what the Twitter user holdsas a true proposition, the regime is unable to maintain security and protect the people.5.
?????
?????
??
?????
?????????
[ ???
??????????
???
[AlnZAm gyr qAdr ElY [twfyr Al>mn >w HmAyp AlmwATnyn]The regime is not able to [maintain security and protect the people]We can have two or more nested holders.
In example 4, the two holders are Alganzoury whoexpresses his unwillingness to continue as a Prime Minster and the Twitter user who is quotingAlganzoury.
In example 5, the two holders are the regime that is incapable of marinatingsecurity and protecting its people and the Twitter user who holds this proposition as true.
Inexample 6, we have three nested holders: the Iranians who are unwilling to confront the outsideworld, Obama who holds that as a true proposition about Iranians, and the Twitter user who isquoting Obama stating his proposition.6.
???
???????????????
??
???
[ ????
??
??
???
?????
????????
: ??????
[AwbAmA: Al$Eb AlAyrAny lm yEd yrgb fy [AlmwAjhp mE AlEAlm AlxArjy]Obama: the Iranians no longer want to [confront the other countries].During the interactive procedure, annotators are first asked whether the holder is the same asthe Twitter user.
If not, more questions are displayed to determine (1) who the real holder is; (2)whether the tweet is a(n) (in)direct quote; or it conveys the Twitter user's assumptions.When the holder is not the Twitter user, annotators are asked to mark the boundaries of thelinguistic unit that corresponds to the holder in the tweet's text.
Annotators are instructed to usethe maximal length principle from Szarvas et al.
(2008) so that they mark the largest possiblemeaningful linguistic unit.
Thus, in example 4 the holder is ???????
????
????????
Aldktwr kmAlAljnzwry (Dr. Kamal Alganzoury) not only Kamal Alganzoury.2.6 Task 6: ScopesScopes are the events modified by the trigger, syntactically realized as clauses, verb phrases,deverbal nouns or to-infinitives, according to Al-Sabbagh et al.
(2013).
We use the samemaximal length principle from Task 5 so that the marked scope segment corresponds to thelargest meaningful linguistic unit that describes the event.
Typically, scope segments aredelimited by: (1) punctuation markers and (2) subordinate conjunctions.Annotators are instructed that: (1) a single trigger may have one or more scopes; (2) two ormore triggers - especially conjoined by coordinating particles - can share the same scope; and(3) scopes are not necessarily adjacent to their triggers.
Examples 7, 8 and 9 illustrate each ofthese guidelines, repecetively.7.
??????
?????
???????[?]
?????
[ ????????
??????
????
[lw AstbEd $fyq ystTyE [AlTEn] w[AlEwdp lsbAq Alr}Asp]If Shafiq is excluded, he can [appeal] and [run again for presidency].8.
[??????
????????
????
???
???
????
?????
??????
????
[????
???
??
??????
?mlAyyn AlmSryyn Ally brh mSr lAzm wHtmA wDrwry wyjb [ybqY lhm Hq AltSwyt]It is necessary, it is a must, it is a need that [Egyptians abroad are given the right to vote].9.
[????
?????
???
???
??
????
[????
#???
????
?????
???
??????
?nfsy wAllh bjd qbl mA Amwt [A$wf #mSr AHsn wAHlY bld fAldnyA]I really wish before I die to [see #Egypt becoming one of the best counties in the world].3 Final Output RepresentationAll elicited answers during annotation are organized into the representations illustrated in thefollowing examples.
The representation of example 10 reads as: the Twitter USER strongly did142not want Shafiq to win the presidential elections.
The trigger ??????
Atmnyt (wished) is tagged assynonymous with the volition exemplar set; therefore, it denotes a DESIRE.
It is then labeled as apast tense (PST), negative (NEG) trigger.
Furthermore, its lexical intensity is labeled as amplified(AMP) because of the categorical negation ????
??
Emry mA (never ever).
Originally, ?????
?Atmnyt (wished) is of moderate lexical intensity, being less intense than ??????
A$thyt (longedfor) but more intense than ????
>rdt (wanted).
Given the categorical negation, the lexicalintensity of ??????
Atmnyt (wished) goes up the scale from moderate to strong (STRG).10.
????#?????
????
????
???????
??
????
.
]????
????[??
?????????
?
?Emry mAtmnyt An [$fyq yksb].
AlHmd Allh rbnA mHrmny$ mn HAjp #mrsyI have never ever wished [Shafiq to win].
Thank God!
#Morsi.rep.
USER, STRG PST NEG DESIRE ($fyq yksb)Example 11 reads as: the Twitter USER reports Hegazy stating that he has the ability tobecome the Muslim's caliphate.
The trigger ????
>SlH (can) is labeled as synonymous with theability exemplar set.
It is also labeled as a present (PRS), affirmative (AFF) trigger whose lexicalintensity is maintained (AS IS) in the context.
Therefore, its lexical intensity is maintained to itsoriginal level which is moderate (MOD).11.
??????
????
??????
]???
??????
?????????[??
???????
: ?????
#IkhwanHjAzy: >nA >SlH >n [>kwn xlyfp llmslmyn] wsnkwn sAdp AlEAlm #IkhwanHegazy: I can [be the Muslims' caliphate] and we will become the world's masters.
#Ikhwanrep.
USER, report, (HjAzy, MOD PRS AFF ABLE, (>kwn xlyfp llmslmyn))Example 12 shows a Twitter user who holds as true that the only thing Egypt needed was awise politician to avoid the bloodshed.
The trigger ?????
tHtAj (needs) is labeled as an obligationtrigger synonymous with ?????
ttTlb (requires).
It is also labeled as past tense (PST) given thepreceding past tense auxiliary ???
tkn (was).
The assigned strong (STRG) lexical intensity label isattributed to the fact that the original moderate intensity of ?????
tHtAj (needs) is amplified bythe categorical negation structure  ???...
??
lm ... <lA (nothing but).12.
# ?????????
????
????
??
???????
????
?????
[???
????????
??
???
[#mSr lm tkn tHtAj AlA [rjl EAql yxrj mn AlAzmAt bdwn ArAqp AldmA']#Egypt needed nothing but [a rational politician who solves crises without bloodshed]rep.
USER, true, (mSr , STRG PST AFF REQUIRE (rjl EAql yxrj mn AlAzmAt bdwn ArAqp AldmA'))Example 13 illustrates the representation of three-level nested holders.
It reads as: the USERreports Obama's assumption as the latter holds as true that the Iranians do not want to confrontother countries.13.
????????
??
??????
???????
[ ????
????
???
????????
?????
: ??????
[AwbAmA: Al$Eb AlAyrAny lm yEd yrgb fy [AlmwAjhp mE AlEAlm AlxArjy]Obama: the Iranians no longer want to [confront other countries].rep.
USER, report, (AwbAmA, true, (Al$Eb AlAyrAny, MOD PRS NEG DESIRE, (AlmwAjhp mEAlEAlm AlxArjy)))Example 14 shows how two conjoined triggers (i.e.
????
lAzm (must) and ?????
Drwry(necessary)) that share the same holder and scope are merged into one representation, and theconjunction leads to amplifying the intensity of the obligation set by them both.14.
????
????
????
???
????????
??????
????
??????
[ ??????????
[lAzm wDrwry [klnA nkwn qdAm mqr AlmHAkmp wmEAnA Swrp Alr}ys]We must and it is necessary that [we go to the court with President's pictures].rep.
USER, STRG PRS AFF REQUIRE, (klnA nkwn qdAm mqr AlmHAkmp wmEAnA Swrp Alr}ys)4  Corpus HarvestingTweets are harvested from the Arabic Egyptian Twitter provided that (1) each tweet has at leastone trendy political English or Arabic hashtag; and (2) each tweet has at least one candidateevent modality trigger from the Arabic modality lexicons (Al-Sabbagh et al.
2013, 2014a).
Weharvest tweets from a variety of users such as newspapers, TV stations, political andhumanitarian campaigns, politicians, celebrities, and ordinary people.
Thus, our corpuscomprises both MSA, the formal Arabic variety, and EA, the native Arabic dialect of Egypt.The harvested corpus comprises 9949 unique tweets, with 12134 tokens of event modalitytriggers that map to 315 unique types.1435 Annotation Results5.1 Evaluation Methodology and MetricsOur annotation tasks are of two types: (1) Tasks 1-4 are label-based where there is a pre-definedset of labels from which annotators choose; and (2) Tasks 5-6 are segmentation-based where theoutput of the annotation is a text segment.
For the segmentation-based tasks, we use an all-or-nothing method to measure inter-annotator reliability: for segments to be considered asagreement, they must share both the beginning and end boundaries.
We use Krippendorff'salpha ?
(Krippendorff 2011) as our inter-annotator reliability measure, following the mostrecent work on modality annotation for other languages including English (Rubinstein et al.2013) and Chinese (Cui and Chi 2013).
For more details on Krippendorff's alpha and a, we referthe reader to Artstein and Poesio (2008).5.2 ResultsWe use the surveygizmo survey services2 to implement our interactive annotation proceduregiven that their survey structure is one that uses conditional branching and skip logic.
Wedistribute the survey on Twitter and we have three annotators participating.
According to theshort qualifying quiz given at the beginning of the survey, all three participants are nativeEgyptian Arabic (EA) speakers who have at least two-year experience with Twitter.
They arealso university graduates who, therefore, master MSA.
None of the participants has a linguisticsbackground.
Table 1 shows alpha rates for each annotation task.Sense Polarity Intensification Tense Holder ScopeObligation 0.890 0.893 0.892 0.978 0.829 0.744Permission 0.864 0.905 0.821 0.983 0.800 0.739Commitment 0.760 0.794 0.783 0.947 0.702 0.654Ability 0.895 0.914 0.905 0.950 0.828 0.763Volition 0.921 0.921 0.867 0.982 0.858 0.779Averages 0.866 0.885 0.854 0.968 0.803 0.736Table 1: Krippendorff's alpha rates for inter-annotator reliability5.3 Discussion and Disagreement AnalysisAmong the factors that lead to high inter-annotator reliability are that: (1) the vast majority ofnegation is explicitly marked by negation particles that are easy to detect by human annotators;(2) the vast majority of triggers are used without any amplification or mitigation markers; and(3) punctuation markers are surprisingly informative for marking scope boundaries and directquotations; and hence, holders.Sense-related disagreement is attributed to: (1) nominal triggers, (2) highly-polysemoustriggers, and (3) different interpretations invoked by the ?RATIONAL (i.e.
non-human) holders.Typically, event modality triggers are adjunct constituents that add an extra-layer of meaningand can be removed without disturbing the syntactic structure.
Yet, in example 15, ????
wAjb (amust) and ????
>wjb (a more important must) have main grammatical functions as thepredicates of the phrases they modify.
Most of the exemplars from Section 2.1 are adjuncts;and, thus, none can substitute ????
wAjb (a must) or ????
>wjb (a more important must) in sucha context.15.
]????
]??????
???
?????[???
????
]??????
??
??????
??????
[AltHfZ mn AxtTAf Alvwrp] wAjb lkn [AltwHd xlf m$rwE] >wjb[Being cautious about manipulating the revolution] is a must but [getting united for one project]is a more important must.Highly-polysemous triggers invoke disagreement because in many cases even the context isambiguous.
In example 16, ????
>qsm (I swear) has two eligible interpretations: an epistemictrigger interpretation I assure (you) that and a commitment trigger interpretation I promise (you)2 http://www.surveygizmo.com/144that.
Even the context is not enough to disambiguate the two interpretations and annotators goby the most common sense for the trigger according to their own opinions.16.
????
: ????
????
T???
?????
?????
???
?????
90?
????
???
]???#??
????
[?
?Emrw >dyb: >qsm bAllh [ln tsqT #mSr], AHnA $Eb 90 mlywn wm$ <$Arp htsqT bldAmr Adeeb: I promise/assure (you) by God that [#Egypt will not collapse].
We are 90 millionEgyptians and we will not be defeated by a sign.Non-human or ?RATIONAL holders invoke disagreement, especially for obligation versusvolition triggers.
The most common sense of such triggers as ?????
EAyzp (want) is volition.Yet, when the holder is ?RATIONAL like ??????????
AlAntxAbAt (the elections) in example 17,annotators disagree as to whether ?????
EAyzp means want (i.e.
a volition trigger) or need (i.e.
anobligation trigger).17.
?????
???????
????
????????
]??????
[ ??????????????
?AlAntxAbAt EAyzp [mr$Hyn] wHmlAt Al>HzAb tyjy brAHthAElections want/need [candidates] and later we can establish the political parties.Intensity-related disagreement is attributed mostly to progressive verb aspect.
Someannotators consider progressive verb aspect as indicated by the EA prefix b as a marker forlexical intensity amplification.
Thus they tag the volition trigger ?????
btmnY (I wish) in example18 as amplified, especially it is modified by ??
???
kl ywm (everyday).18.
????#????
???
[ ???????
???
[kl ywm btmnY [sqwT Hkm #mrsy]Every day, I wish for [#Morsi's regime to fall].Polarity-related disagreement is mainly caused by (1) negated holders and (2) contextualnegation.
In ????
??
????
mfy$ Hd yqdr (no one can), annotators disagree as to whether ????
yqdr(can) should be labeled as affirmative or negative.
By contextual negation we mean exampleslike ??
?????
??
?????
??
mn AlSEb >n ntmnY >n (it is hard to wish to), which entails negationdue to the adjective ?????
AlSEb (hard).Holder-related disagreement is attributed mainly to generic nouns and impersonal pronounslike ?????
Al$Eb (the people) and ??????
AlwAHd (one), respectively.
They are interpreted bysome annotators as referring implicitly to the Twitter USER.
Therefore, the annotators select theUSER as the only holder with zero nesting.
Other annotators interpret them as referring to peoplein general not necessarily the Twitter USER and thus they consider these as instances of nestedholders.Scope-related disagreement is attributed to (1) ambiguous subordinate conjunctions, (2)triggers' modifiers, and (3) absent punctuation markers.Tense yields almost perfect inter-annotator reliability rates.
Annotation disagreement does notshow any particular pattern.
Therefore, we attribute minor disagreement to random errors,resulting from fatigue.5.4 Majority StatisticsBased on majority annotations, Table 2 gives the statistics for our corpus in terms of sense,polarity, intensification, and tense.
As for holder annotations, approximately 60.5% of thetriggers have zero-nested holders (i.e.
the tweet's writer is the same as the holder).Sense Polarity Intensification TenseMD NMD AFF NEG AMP MTG ASIS PRS PSTAbility 1729 920 1047 682 348 308 1073 1175 554Commitment 1048 495 599 449 221 220 607 639 409Obligation 1786 848 1059 727 369 399 1018 1018 768Permission 1699 980 1054 645 286 428 985 1053 646Volition 1622 1007 974 648 341 292 989 1038 584Totals 7884 4250 4733 3151 1565 1647 4672 4923 2961Table 2: Token statistics for each annotation task per event modality sense where MD is modal, NMD isnon-modal, AFF is affirmative, NEG is negative, AMP is amplified, MTG is mitigated, ASIS is as is, PRS ispresent, and PST is past1456 Related WorkEvent modality is the focus of many annotation projects.
Matsuyoshi et al.
(2010) annotate acorpus of English and Japanese blog posts for a number of modality senses including volition,wishes, and permission.
They annotate sense, tense, polarity, holders as well as other attributesthat we have not covered in our scheme such as grammatical mood.
They report macro kappainter-annotator agreement rates of 0.69, 0.70, 0.66 and 0.72 for holders, tense, sense, andpolarity, respectively.Baker et al.
(2010, 2012) simultaneously annotate modality and modality-based negation forUrdu-English machine translation systems.
Among the modality senses they work on arerequirement, permission, success, intention, ability, and desires.
They report macro kappa inter-annotator agreement rates of 0.82 for sense annotation and 0.76 for scopes.
They, however, donot annotate holders and do not consider nested modalities.Hendrickx et al.
(2012) annotate eleven modality senses in Portuguese, including necessity,capacity, permission, obligation, and volition, among others.
They report a macro kappa inter-annotator rate of 0.85 for sense annotation.Rubinstein et al.
(2013) propose a linguistically-motivated annotation scheme for modalitiesin the MPQA English corpus.
They annotate sense, polarity, holders, and scopes, among otherannotation units.
They work on obligation, ability, and volition among other modality senses.They attain macro alpha inter-annotator reliability rates of 0.89 and 0.65 for sense and scope,respectively.Cui and Chi (2013) apply the same scheme of Rubinstein et al.
(2013) to the Chinese PennTreebank and get alpha inter-annotator reliability rates of 0.81 and 0.39 for sense and scopeannotation, respectively.Finally, Al-Sabbagh et al.
(2013) annotate event modality in MSA and EA tweets.
We attainkappa inter-annotator agreement rates of 0.90 and 0.93 for sense and scope annotation,respectively, for only 772 tokens of event modality triggers.Our annotation results, therefore, are comparable to the results in the literature.
Furthermore,our annotation scheme and its tasks are orthogonal to most of the aforementioned schemes.However, the key differences between our work and related work are:?
We use a standardized taxonomy of event modality - Palmer's (2001) - that has beenproved valid for a variety of languages, including Arabic, according to Mitchell andAl-Hassan (1994), Brustad (2000), and Moshref (2012).?
We annotate nested holders unlike some of the aforementioned studies  (e.g.
Baker etal.
2010, 2012) and use a wider range of negation and intensification markers.?
We use crowdsourcing with simplified guidelines implemented interactively toannotate a larger-scale corpus of 12134 tokens for event modality and its attributes.7 Conclusion and OutlookWe presented a large-scale corpus annotated for event modality in MSA and EA tweets.
We usea simplified annotation procedure that defines each annotation task as a series of questions,implemented interactively.
Our scheme covers a wide range of the most common annotationunits mentioned in the literature, including modality sense, polarity, intensification, tense,holders, and scopes.
We deal with nested holders - which are crucial in a highly interactivegenre such as tweets where users frequently quote others and make assumptions about them.We also automatically merge triggers with shared holders and scopes based on elicitedannotators' answers.
The annotation procedure yields reliable results and creates a novelresources for Arabic NLP.
The current version of our corpus does not, however, cover a numberof issues including: the future tense, grammatical moods other than the declarative, andmodality entailment.
By modality entailment, we mean, for example, when a tweet's usercriticizes the obligation of another quoted person, this entails that the user does not considersuch an event as required.
For a future version of the corpus, we plan to cover such points.Furthermore, we will use the corpus to train and test a machine learning system for theautomatic processing of Arabic event modality.146ReferencesRania Al-Sabbagh, Jana Diesner and Roxana Girju.
2013.
Using the Semantic-Syntactic Interface forReliable Arabic Modality Annotation.
In Proceedings of IJCNLP'13, pages 410-418, October 14-18,2013, Nagoya, Japan.Rania Al-Sabbagh, Roxana Girju and Jana Diesner.
2014a.
Unsupervised Construction of a Lexicon and aPattern Repository of Arabic Modal Multiword Expressions.
In Proceedings of the 10th Workshop ofMultiword Expressions at EACL'14, April 26-27, 2014, Gothenburg, Sweden.Rania Al-Sabbagh, Roxana Girju and Jana Diesner.
2014b.
3arif: A Corpus of Modern Standard andEgyptian Arabic Tweets Annotated for Epistemic Modality Using Interactive Crowdsourcing.
InProceedings of the 25th International Conference on Computational Linguistics, August 23-29, 2014,Dublin, Ireland.Ron Artstein and Massimo Poesio.
2008.
Inter-Coder Agreement for Computational Linguistics.Computational Linguistics, volume 34, issue 4, pages 555-596.Kathrin Baker, Michael Bloodgood, Mona Diab, Bonnie Dorr, Nathaniel W. Filardo, Lori Levin andChristine Piatko.
2010.
A Modality Lexicon and its Use in Automatic Tagging.
In Proceedings of the7th International Conference on Language Resources and Evaluation (LREC'10), pages 1402-1405,May 19-21, 2010, Valetta, Malta.Kathryn Baker, Michael Bloodgood, Bonnie J. Dorr, Chris Callison-Burch, Nathaniel W. Filardo,Christine Piatko, Lori Levin and Scott Miller.
2012.
Modality and Negation in SIMT.
ComputationalLinguistics.
volume 38, issue 2, pages 411-438.Samuel R. Bowman and Harshit Chopra.
2012.
Automatic Animacy Classification.
In Proceedings of theNAACL HTL 2012 Student Research Workshop, pages 7-10, June 3-8, 2012, Montreal, Canada.Kristen E. Brustad.
2000.
The Syntax of Spoken Arabic: A Comparative Study of Moroccan, Egyptian,Syrian and Kuwaiti Dialects.
Georgetown University Press, Washington DC, USA.Cohan Sujay Carlos and Madulika Yalamanchi.
2012.
Intention Analysis for Sales, Marketing andCustomer Service.
In Processing of COLING 2012: Demonstration Papers, pages 33-40, December2012, Mumbai, India.Baptiste Chardon, Farah Benamara, Yannick Mathieu, Vladimir Popescu and Nicholas Asher.
2013.Sentiment Composition Using a Parabolic Model.
In Proceedings of the 10th International Conferenceon Computational Semantics (IWCS 2013), pages 47-58, March 20-22, 2013, Potsdam, Germany.Yanyan Cui and Ting Chi.
2013.
Annotating Modal Expressions in the Chinese Treebank.
In Proceedingsof the IWC 2013Workshop on Annotation of Modal Meaning in Natural Language (WAMM), pages 24-32, March 2013, Potsdam, Germany.Iris Hendrickx, Am?lia Mendes and Silvia Mencarelti.
2012.
Modality in Text: A Proposal for CorpusAnnotation.
In Proceedings of the 8th International Conference on Language Resources and Evaluation(LREC'12), pages 1805-1812, May 21-27, 2012, Istanbul, Turkey.Klaus Krippendorff.
2011.
Computing Krippendorff's Alpha-Reliability.
Annenberg School ofCommunication, Departmental Papers: University of Pennsylvania.Andrew Lampert, Robert Dale and Cecile Paris.
2010.
Detecting Emails Containing Requests for Action.In Proceedings of Human Language Technologies: the 2010 Annual Conference of the North AmericanChapter of the ACL, pages 984-992, June 2010, Los Angles, California.Ying-Shu Liao and Ting-Gen Liao.
2009.
Modal Verbs for the Advice Move in Advice Columns.
InProceedings of the 23rd Pacific Asia Conference on language, Information and Computation, pages307-316, December 3-5, 2009, Hong Kong, China.Suguru Matsuyoshi, Megumi Eguchi, Chitose Sao, Koji Murakami, Kentaro Inui and Yuji Matsumoto.2010.
Annotating Event Mentions in Text with Modality, Focus and Source Information.
InProceedings of LREC'10, pages 1456-1463, May 19-21, 2010, Valletta, Malta.T.
F. Mitchell and S. A. Al-Hassan.
1994.
Modality, Mood and Aspect in Spoken Arabic with SpecialReference to Egypt and the Levant.
London and NY: Kegan Paul International.147Ola Moshref.
2012.
Corpus Study of Tense, Aspect, and Modality in Diglossic Speech in Cairene Arabic.PhD Thesis.
University of Illinois at Urbana-Champaign.Frank R. Palmer.
2001.
Mood and Modality.
2nd Edition.
Cambridge University Press, Cambridge, UK.J.
Ramanand, Krishna Bhavsar and Niranjan Pedanekar.
2010.
Wishful Thinking: Finding Suggestionsand "Buy" Wishes for Product Reviews.
In Proceedings of the NAACL HLT 2010 Workshop onComputational Approaches to the Analysis and Generation of Emotion in Text, pages 54-61, June2010, Los Angeles, California.Aynat Rubinstein, Hillary Harner, Elizabeth Krawczyk, Daniel Simoson, Graham Katz and Paul Portner.2013.
Toward Fine-Grained Annotation of Modality in Text.
In Proceedings of the IWC 2013Workshopon Annotation of Modal Meaning in Natural Language (WAMM), pages 38-46, March 2013, Potsdam,Germany.Roser Saur?
and James Pustejovsky.
2009.
FactBank: A Corpus Annotated with Event Factuality.Language Resources and Evaluation, 43:227-268Gy?rgy Szarvas, Veronika Vincze, Rich?rd Farkas and J?nos Csirik.
2008.
The BioScope Corpus:Annotation for Negation, Uncertainty and their Scope in Biomedical Texts.
In Proceedings of BioNLP2008: Current Trends in Biomedical Natural Language Processing, pages 38-45, June 2008,Columbus, Ohio, USA.Janyce Wiebe, Theresa Wilson and Claire Cardie.
2005.
Annotating Expressions of Opinions andEmotions in Language.
Language Resources and Evaluation, volume 39, issue 203, pages 1663-210.148
