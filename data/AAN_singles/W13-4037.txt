Proceedings of the SIGDIAL 2013 Conference, pages 233?241,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsEvaluation of Speech Dialog Strategiesfor Internet Applications in the CarHansjo?rg HofmannUte EhrlichAndre?
BertonDaimler AG / Ulm, Germany,hansjoerg.hofmann@daimler.comAngela MahrRafael MathChristian Mu?llerDFKI / Saarbru?cken, Germanyangela.mahr@dfki.deAbstractDue to the mobile Internet revolution, peo-ple tend to browse the Web while driv-ing their car which puts the driver?s safetyat risk.
Therefore, an intuitive and non-distractive in-car speech interface to theWeb needs to be developed.
Before de-veloping a new speech dialog system in anew domain developers have to examinewhat the user?s preferred interaction styleis in order to use such a system.
This pa-per reports from a very recent driving sim-ulation study and its preliminary resultswhich are conducted in order to comparedifferent speech dialog strategies.
Theuse of command-based and conversationalSDS prototypes while driving is evaluatedon usability and driving performance.
Dif-ferent GUIs are designed in order to sup-port the respective dialog strategy the mostand to evaluate the effect of the GUI on us-ability and driver distraction.
The prelim-inary results show that the conversationalspeech dialog performs more efficient thanthe command-based dialog.
However, theconversational dialog distracts more fromdriving than the command-based.
Further-more, the results indicate that an SDS sup-ported by a GUI is more efficient and bet-ter accepted by the user than without GUI.1 IntroductionThe pervasive use of smartphones in daily situ-ations impacts the automotive environment.
Inorder to stay ?always connected?
people tend touse their smartphone?s Internet functions manuallywhile driving.
However, using a smartphone man-ually while driving, distracts the driver and endan-gers the driver?s safety.
According to GovernorsHighway Safety Association (2011) 25% of U.S.car crashes are related to drivers using their cell-phones while driving.
Therefore, the developmentof an intuitive and non-distractive in-car speech in-terface to the Web is essential in order to increasedriver safety (Peissner et al 2011).Before developing a new speech dialog system(SDS) in a new domain developers have to ex-amine how users would interact with such a sys-tem.
An Internet user study by Hofmann et al(2012a) in which the subjects had to solve Internettasks orally, revealed that concerning communica-tional (e.g.
sending an Email) and transactionaltasks (e.g.
booking a hotel) conversational andcommand-based speaking styles were used withequal frequency.
Because of the equal frequencyof occurrence you have to examine which speechdialog strategy - the command-based or the con-versational - is the most suitable for these tasks.First studies on the evaluation of dialog strate-gies have been conducted by Devillers andBonneau-Maynard (1998) who compare two SDSallowing the user to retrieve touristic information.One dialog strategy guides the user via systemsuggestions, the other does not.
The evaluated di-alog strategies comprise the fundamental ideas thecommand-based and conversational dialog strat-egy consist of.
By applying qualitative and quan-titative criteria they conclude that user guidance issuitable for novices and appreciated by all kindsof users.
However, there was no GUI involvedand the speech interaction was performed as pri-mary task.
Considering the driving use case otherresults may be achieved since the primary task isdriving.
Furthermore, the use of these SDS amongadvanced users needs to be investigated.In the TALK project, Mutschler et al(2007)compared a command-based speech dialog to aconversational dialog where the driver had to con-trol the in-car mp3-player by speech while driving.The same graphical user interface (GUI) was usedfor both dialog strategies.
Although the conver-233sational dialog was more efficient the command-based dialog was more appreciated by the sub-jects.
According to Mutschler et althe high errorrate of the conversational strategy was the reasonfor the higher acceptance of the command-baseddialog.
There were no significant differences inthe driving performance revealed when using thedifferent SDS.The speech recognizer quality has improvedenormously within the last five years.
There-fore, the weak speech recognition performance ofMutschler et als conversational dialog may benowadays less significant.
Furthermore, the use ofthe same GUI for different dialog strategies couldhave additionally influenced the result.
The GUIshould be adapted to the particular dialog strategyin order to benefit from the advantages of the re-spective strategy the most and to allow for a com-parison of optimal systems.This paper reports from a very recent drivingsimulation study and its preliminary results whichare conducted in order to compare different speechdialog strategies.
The use of command-based andconversational SDS prototypes while driving isevaluated on usability and driving performance.The systems have been developed for German andallows users to perform a hotel booking by speech.Different GUIs are designed in order to support therespective dialog strategy the most and to evaluatethe effect of the GUI on usability and driver dis-traction.
The experiments have been conductedat DFKI, Saarbru?cken using the OpenDS1 driv-ing simulation.
The research work is performedwithin the scope of the EU FP7 funding projectGetHomeSafe2.The remainder of the paper is structured as fol-lows: In Section 2, the developed SDS prototypesare briefly described.
Section 3 presents the ex-perimental setup and its results and finally, con-clusions are drawn.2 SDS Prototype ConceptsThe chosen use case for the design of the SDSconcepts is booking a hotel by speech while driv-ing since it covers many different subdialog types(parameter input, list presentation and browsing,etc.).
For this purpose, the online hotel bookingservice HRS3 has been used as data provider for1http://www.opends.eu/2http://www.gethomesafe-fp7.eu3http://www.hrs.comthe SDS.Each SDS prototype concept offers the samefunctionality: First, the user has to input his searchparameter to retrieve a list of hotels.
The usercan browse the list and ask for detailed informa-tion about a certain hotel.
If the hotel matches hisneeds he is able to book the hotel.
In addition, theuser can change the search parameters.In the following, the different speech dialogstrategies and the corresponding GUI designs arebriefly decribed.
A detailed description of thehuman-machine interface (HMI) concepts can befound in Hofmann et al(2012b).2.1 Speech Dialog Strategy DesignSDS Prototypes for German language have beendeveloped including the following SDS features:In order to speak to the system the driver has topress a Push-To-Activate (PTA) button.
Further-more, the driver is able to interrupt the systemwhile prompting the user (?barge-in?).
When de-signing the different dialog strategies we particu-larly focused our attention on the dialog initiative,the possibility to enter multiple input parametersand the acoustic feedback.2.1.1 Command-based Speech DialogStrategyThe dialog behavior of the command-based dialogstrategy corresponds to the voice-control whichcan be found in current state-of-the-art in-car SDS.By calling explicit speech commands the speechdialog is initiated and the requested information isdelivered or the demanded task is executed.
Thereare several synonyms available for each command.By using implicit feedback in the voice promptsthe driver is informed about what the system hasunderstood.
After the first command the user isguided by the system and executes the steps whichare suggested and displayed by the system.
TheGUI supports the speech dialog by showing the?speakable?
commands as widgets on the screen(see Section 2.2).
A sample dialog is illustrated inthe following:Driver: Book a hotel.System: Where would you like to book a hotel?Driver: In Berlin.System: When do you want to arrive in Berlin?Driver: Tomorrow.System: How long would you like to stay in Berlin?Driver: Until the day after tomorrow.2342.1.2 Conversational Speech Dialog StrategyIn the conversational dialog strategy the dialog ini-tiative switches during the speech interaction.
Thedriver is able to speak whole sentences where mul-tiple parameters can be set within one single ut-terance.
Thereby, the dialog can be more natural,flexible and efficient.
The driver is informed aboutwhat the system has understood by using implicitfeedback.
The GUI does not present the ?speak-able?
commands on the screen.
In order to indi-cate the possible functions icons are displayed (seeSection 2.2).
A sample dialog is presented in thethe following:Driver: I would like to book a hotel in Berlin.System: When do you arrive in Berlin?Driver: I?ll arrive tomorrow and leavethe day after tomorrow.As illustrated in the example the driver can al-ready indicate some input parameters when ad-dressing the system for the first time.
The systemverifies which input parameters are missing in or-der to send a hotel request.
The system promptsthe user and collects the missing information.
Al-though the system asks for only one parameter, theuser is able to give more or other information thanrequested.2.2 GUI DesignThe different GUIs have been designed in order tosupport the speech dialog strategies and to eval-uate the effect of the GUI on usability and driv-ing performance.
The different GUIs have beencustomized corresponding to the dialog strate-gies only as much as necessary since an objec-tive comparison is targeted.
When designing thescreens we followed the international standard-ized AAM-Guidelines (Driver Focus-TelematicsWorking Group, 2002).2.2.1 Command-based GUI DesignIn the command-based dialog strategy the driveruses commands to speak to the system.
In orderto give the driver an understanding of the ?speak-able?
commands, the speech dialog is supportedby the GUI.
For that reason the currently possiblespeech commands are displayed on the screen atall times which may lead to a high visual distrac-tion.
Hence, in automotive terms the command-based speech dialog strategy is also called ?speak-what-you-see?
strategy.Figure 1(a) illustrates the main screen of the ho-tel booking application at the beginning of the ho-tel booking dialog.
Here, the first input parameter?destination?
(?Ziel?
in German) is requested bythe system.
Afterwards the user is guided step-by-step by the system.
When the driver has given therequested information, a new widget appears onthe screen and the system asks the driver for thecorresponding input.2.2.2 Conversational GUI DesignIn the conversational dialog strategy the driver canspeak freely and does not have to use certain com-mands.
There is no need to give the driver a vi-sual feedback of the currently ?speakable?
com-mands whereby the visual distraction may be low-ered.
For that reason, the content on the head unitscreen does not have to indicate the possible op-tions to proceed with the speech dialog.
The sub-function line which was used to indicate the avail-able commands is replaced by only few symbolswhich resemble the current GUI state.
Figure 1(b)shows the form filling main screen at the begin-ning of the speech interaction where the user isalready able to input several parameters at once.2.2.3 Without GUIWe also investigated the need for a visual feed-back, why the two speech dialog strategies arealso evaluated ?without GUI?.
In this case, with-out GUI means that no content information is dis-played on the screen.
However, a visual feedbackwhich indicates if the user is allowed to talk ispresented in the top bar of the screen (see Figure1(c)).3 Evaluation3.1 Method3.1.1 ParticipantsThe experiment was conducted at DFKI,Saarbru?cken.
In total, 24 German participants(mainly students) participated in the experiment.All participants received a monetary expenseallowance and possessed a valid driver?s license.Due to missing data recordings during the exper-iment data of 1 participant had to be excludedfrom the analyses.
The remaining participantscomprised 9 male and 14 female subjects and theaverage age was 26 years (standard deviation (SD)= 4,1).
56,5% of the participants were drivingtheir car at least once a day.
56,5% had little to noexperience with speech-controlled devices.235(a) Command-based GUI (b) Conversational GUI (c) ?without?
GUIFigure 1: Main Screens at the Beginning of the Interaction.3.1.2 Experimental DesignFour different HMI concept variants were evalu-ated in a 2x2 (speech dialog strategy: command-based vs. conversational, GUI: with vs. without)design.
The Command-based and ConversationalGUI were only used with the corresponding dialogstrategy.
The 4 HMI concepts were the following:?
Command-based speech dialog (?Comm?)?
with GUI (?CommGUI?)
and?
without GUI (?CommNoGUI?)?
Conversational speech dialog (?Conv?)?
with GUI (?ConvGUI?)
and?
without GUI (?ConvNoGUI?
)Each participant encountered all four conditions(?within-design?).
For each condition, two taskshad to be accomplished.
We investigated theparticipants speech dialog performance and in-fluences on driving performance while using theSDS.3.1.3 MaterialsSpeech Dialog Prototypes: In the experiment,the speech dialog prototypes described in Section2 have been used.
In order to explain the func-tionality and the control of the SDS prototypes tothe user, instruction videos for each speech dia-log strategy were presented.
By presenting tutorialvideos, we ensured that each participant was givenidentical instructions.During the experiment, participants had to solveseveral tasks: They had to book a certain hotelaccording to given search parameters.
The taskswere verbalized as little stories which containedthe necessary parameters in a memorable manner.A sample task in English is presented below:Imagine, you and your colleague are on the wayto Cologne for a two-day meeting right now.
Youneed two single rooms for these two nights whichyou have not booked, yet.
Your appointmenttakes place in the city center of Cologne, whereyou would like to spend your night.
Please lookfor a matching hotel for those nights.In total, participants had to perform 16 tasks.
Fourtasks were used as sample tasks to familiarize par-ticipants with the respective speech dialog strategyafter showing the instruction video.
The remain-ing eight tasks were used for the data collection.Questionnaires: During the experiment differ-ent questionnaires were used:?
Preliminary Interview: In a preliminary ques-tionnaire we collected demographical infor-mation (age, gender, etc.)
about the partic-ipants.
Furthermore, we surveyed drivinghabits, experience with speech-controlled de-vices, and hotel booking habits.?
SASSI questionnaire (Hone and Graham,2001): The SASSI questionnaire covering 6dimensions consists of 34 questions and iswidely used to measure subjective usabilityevaluation of SDS.?
DALI questionnaire (Pauzie, 2008): TheDALI questionnaire covers 6 dimensions inorder to evaluate the user?s cognitive load.The applied questionnaire consisted of 7questions covering each dimension and anadditional question addressing the manualdemand.?
Final Interview: This questionnaire was de-signed to allow for a direct comparison of therespective SDS prototypes at the end of theexperiment.
Each participant had to rate thedifferent SDS on a scale from 1 - 10 regard-ing several subjective measures.
For each ofthe six SASSI dimensions, one question wasasked.
Additionally, we asked questions todirectly compare cognitive load and to getinformation about the participants?
personalpreference of interaction style with the sys-tem at different sub dialogs.Driving Simulation Setup: The experimentwas conducted in the driving simulator at DFKI?s?future lab?
(see Figure 2).
The participants were236sitting on the driver?s seat in a car which wasplaced in front of a canvas onto which the drivingsimulation was projected.
The participants con-trolled the driving simulation by the car steeringwheel and pedals.
During the experiment the ex-aminer was sitting on the passenger seat.Figure 2: DFKI Driving Simulator Setup.Previous driving simulation studies employ thestandard Lane Change Test (LCT) by Mattes(2003).
However, this driving task does not con-tinuously mentally demand the user and thus, doesnot reflect the real cognitive load while driving.Furthermore, LCT is based on single tracks whichlimits the recordings to a certain time.
We em-ployed the ConTRe (Continuous Tracking and Re-action) task as part of the OpenDS1 driving sim-ulation software which complements the de-factostandard LCT including higher sensitivity and amore flexible driving task without restart interrup-tions.
The steering task for lateral control resem-bles a continuous follow drive which will help toreceive more detailed results about the two diversedialog strategies.
Furthermore, mental demand isaddressed explicitly by employing an additionalreaction task implemented as longitudinal control.A detailed description of the ConTRe task can befound in Mahr et al(2012).In the experiment, after giving the participantthe hotel booking task instructions, the experi-menter started the driving simulation.
When theparticipant has crossed the start sign in the simula-tion he had to begin the speech dialog.
When thehotel booking was completed, the experimenterstopped the driving simulation.
Thereby, drivingperformance was only recorded during the speechdialog.3.1.4 ProcedureIn the experiment, 4 conditions were evaluated:The conversational speech dialog (with and with-out GUI) and the command-based speech dialog(with and without GUI).
We did not randomizeall four conditions, because the participants mighthave been confused if the speech dialog styles varytoo often.
Therefore, we decided to employ dialogstyles blockwise (see Figure 3).
In one block, onlyone speech dialog variant with the two GUI condi-tions was tested.
The order of the two blocks wascounterbalanced between participants to controlfor learning and order effects.
Thereby, half of theparticipants were first introduced to the command-based dialog, whereas the other half of the partic-ipants started with the conversational dialog.
Fur-thermore, the order of GUI conditions within oneblock was balanced between participants.
In eachof the four conditions, the participants had to per-form two tasks.
The order of the tasks was thesame for all participants regardless of the systemcondition.
Hence, all tasks were encountered inall dialog and GUI combinations.
When the sec-ond task was finished, participants had to fill outthe SASSI and the DALI questionnaire for eachcondition.Task1Task2SASSI + DALITask1Task2SASSI + DALITask1Task2SASSI + DALITask1Task2SASSI + DALIwithGUIwithoutGUIwithoutGUIwithGUIDataCollectionSDSType1DataCollectionSDSType2Figure 3: Experiment Structure.The overall procedure of the experiment is il-lustrated in Figure 4.
At the beginning of theexperiment, participants had to fill out the pre-liminary questionnaire.
Afterwards they had thepossibility to get to know the driving simulationin a test drive lasting at least 4 minutes.
Afterthe test drive, the participants completed a 4 min-utes baseline drive and had to fill out the DALIquestionnaire afterwards to assess driving perfor-237mance without secondary task.
Next, the partic-ipants were shown the video of their first speechdialog variant and became familiar with the SDSby performing the 4 explorative tasks.
Subse-quently, participants performed the first SDS con-dition (SDS Type 1) both with and without GUI.After testing SDS Type 1, SDS Type 2 was intro-duced by presenting its instruction video and againthe explorative tasks were performed.
Participantsperformed the second SDS condition (SDS Type2) also with and without GUI.
Finally, participantscompleted a second baseline drive and filled outthe final questionnaire.PreliminaryInterviewTestDriveBaselineDrive 1 +DALIVideo SDS Type 1TrialBooking(4 explorativeTasks)DataCollectionSDSType1Video SDS Type 2TrialBooking(4 explorativeTasks)DataCollectionSDSType2BaselineDrive 2Final InterviewFigure 4: Overall Procedure of the Experiment.3.1.5 Dependent VariablesIn the experiment, we collected several types ofdata to evaluate the speech dialog and the driv-ing performance data.
During speech interactionthe SDS produces log files, which contain the linkto the recorded audio file of the spoken user ut-terance, the speech recognizer result, the inter-pretation of the natural language understanding(NLU) module, and the text-to-speech (TTS) out-put.
Based on the log file, the whole speech di-alog can be reconstructed.
The driving simula-tion OpenDS also produces log files at runtime,which contain the steering wheel deviation for lat-eral control and the reaction times for longitudinalcontrol for each recorded time frame.
During theexperiment, the examiner was observing the testprocedure in order to take notes on task success.Based on the collected data, the measures illus-trated in Table 1 were computed in order to evalu-ate the speech dialog and the driving performance.A detailed description and definition of the mea-sures can be found in (Mo?ller, 2005).In this preliminary analysis, due to time con-straints, only the first block of each participantcould be transcribed and analyzed.
In this report,Measure Data SourceTS ObservationsSpeech Dialog NoT SDS logsPerformance DD SDS logsMeasures CER SDS logsSubjective Usability SASSI,Assessment Final InterviewDriving MDev OpenDS logsPerformance Subjective Assessment DALI,Measures of Cognitive Load Final InterviewTable 1: Evaluation Measures of the Experiment.we focus on the SDS performance.
Based on theobservations the task success (TS) of each speechdialog is assessed.
The speech dialog logs are usedto compute the Number of Turns (NoT) and thedialog duration (DD) of each dialog.
We assessthe concept error rate (CER) of each user utter-ance within a dialog instead of the word error rate(WER) since this value is crucial to a successfulspeech dialog.
A subjective usability assessment isachieved by employing the SASSI questionnaire.Based on the OpenDS logs we compute the meandeviation (MDev) of the steering wheel.
In thenext step, the reaction time, the DALI question-naire and the final interview are analyzed.Overall, we expect better usability evaluationfor the conversational dialog conditions comparedwith the command-based condition.
The partic-ipants will accept the conversational dialog bet-ter than the command-based dialog because if re-flects the human-human communication.
Further-more, we expect the conversational dialog to dis-tract less than the command-based dialog becauseit is easier to control.
Generally, a visual feed-back makes it more comfortable to interact withan SDS.
Therefore, we expect the participants toaccept the SDS with GUI better than without GUI.However, concerning the influence of the GUI onthe driving performance, we expect the GUI tocause more driver distraction due to the glancesonto the GUI screen.3.2 ResultsIn the following, the preliminary results concern-ing SDS quality and driving performance are pre-sented.
In total, 48 command-based dialogs and44 conversational dialogs were transcribed and an-alyzed.
First, the results of the speech dialog eval-uation are described, followed by the results ofthe driving performance evaluation.
When com-paring the two speech dialog strategies (?Comm?vs.
?Conv?)
dependent t-tests for paired exam-ples have been applied.
Concerning the compar-ison of the 4 GUI conditions (?CommGUI?
vs.?CommNoGUI?, ?ConvGUI?
vs.
?ConvNoGUI?
)238the repeated measures anova test was applied.
Foreach comparison, a significance level ?
=0,05 wasassumed.3.2.1 Speech DialogIn this Section, first, the results of the speech dia-log performance measures are presented, followedby the results of the questionnaires.Task Success: In the first block of each experi-ment, each participant had to solve 4 tasks whiledata was recorded.
Each of the 92 dialogs werefinished with a hotel booking.
If the participantbooked a hotel, which did not match the task re-quirements the task was annotated as failed.
Fig-ure 5 shows the percentage of solved tasks forboth speech dialog strategies (left) and addition-ally split according to the two GUI conditions(right).
Using the command-based SDS prototype,participants were able to solve 95,8% of the tasks.93,8% of the tasks could be solved when usingthe conversational prototype.
Participants solvedtasks more effective when using the command-based prototype with GUI than without GUI.
Incontrast, the participants solved more tasks suc-cessfully when using the conversational prototypewithout GUI than with GUI.
However, none of thedifferences was found to be significant.95,8 93,110091,7 90,9 95,55060708090100Comm Conv CommGUI CommNoGUI ConvGUI ConvNoGUITaskSuccess[%]Figure 5: Overall TS rates.Number of Turns: Figure 6 presents the aver-age NoT.
The high number of turns is due to thelist browsing the user has to perform in order tofind the matching hotel.
Using the conversationalSDS prototype, significantly fewer dialog turnswere needed than using the command-based SDSprototype (p=0,047).
The conditions without GUIneeded less turns than the conditions with GUI.However, no significant differences were foundwhen comparing the conditions with GUI with theconditions without GUI.Dialog Duration: In Figure 7 the average DDis illustrated.
The dialogs of the conversational32,229,731,532,827,930,325262728293031323334Comm Conv CommGUI CommNoGUI ConvGUI ConvNoGUINumber Of TurnsFigure 6: Average NoT per speech dialog.speech dialogs were significantly shorter than thecommand-based speech dialogs (p=0,003).
Com-paring the GUI conditions within one speech di-alog strategy, it seems that participants using theconversational speech dialog needed less time toaccomplish a task when they could use the GUI.However, there was no significant difference re-vealed.
Concerning the GUI conditions of thecommand-based dialog, no significant differencescould be found, too.104,991,6104,4  105,381,2102020406080100120Comm Conv CommGUI CommNoGUI ConvGUI ConvNoGUIDialog Duration (sec)Figure 7: Average DD per speech dialog.Concept Error Rate: The average CER perdialog is significantly smaller in the command-based speech dialog compared to the conversa-tional speech dialog strategy (p=0,02) (see Figure8).
When comparing the GUI conditions withinone speech dialog strategy, it seems that less con-cept errors occurred when the participants used theSDS prototypes supported by a GUI.
However, nosignificant differences were found.5,28,24,9  5,56,410024681012Comm Conv CommGUI CommNoGUI ConvGUI ConvNoGUIConceptError Rate[%]Figure 8: Average CER per speech dialog.239SASSI: The overall result of the SASSI ques-tionnaire is illustrated in Figure 9.
All SDSachieve a positive usability assessment.
The con-versational dialog is slightly better accepted by theuser.
It seems that the users accept the SDS sup-ported by a GUI better than without a GUI.
How-ever, for none of the comparisons significant dif-ferences were found.Figure 9: Overall SASSI result per speech dialog.3.2.2 Driving PerformanceIn this Section a preliminary driving performanceresult is presented.Mean Deviation: Figure 10 shows the MDev ofthe baseline drive (left), both speech dialog strate-gies (middle) and additionally split according tothe two GUI conditions (right).
The MDev of thebaseline drive is 0,1.
The MDev was significantlysmaller when the participants used the command-based speech dialog (p=0,01) while driving com-pared to the conversational dialog.
No significantdifferences were found when comparing the con-ditions with GUI with the conditions without GUI.0,1 0,10,120,1 0,10,12  0,1200,020,040,060,080,10,120,14Mean DeviationFigure 10: Average MDev per speech dialog.3.3 DiscussionThe preliminary results show that the participantswere able to successfully finish the tasks withboth SDS prototype variants.
All SDS proto-types achieved a positive subjective usability as-sessment.
Although the CER is higher when usingthe conversational dialog, it performs more effi-cient than the command-based dialog which is dueto the possibility to input multiple parameters atonce.
The MDev of the baseline drive is as highas when using the command-based speech dialogwhile driving.
Usually, one would expect a bet-ter driving performance when performing no sec-ondary task.
However, the ConTRe task is a quitedifficult task since it continuously mentally de-mands the user.
Therefore, the MDev is relativelyhigh when only the driving task is performed.
Theconversational speech dialog distracts more fromdriving than the command-based dialog.
Using thecommand-based dialog, the user is guided by thesystem step-by-step, which makes it easier to use.The mental demand when using the command-based SDS might be lower and therefore, this dia-log strategy might be less distractive.Concerning the comparison of the GUI condi-tions the results indicate that the conditions withGUI are more user-friendly than the conditionswithout GUI.
However, we did not find any sig-nificant differences, yet, since the data set is toosmall when comparing the GUI conditions.
Whenthe whole data set of the experiment is analyzedfurther significances might be revealed.4 ConclusionsThis paper reports from a very recent driving sim-ulation study and its preliminary results which areconducted in order to compare different speech di-alog strategies.
The use of command-based andconversational SDS prototypes while driving isevaluated on usability and driving performance.Different GUIs are designed in order to supportthe respective dialog strategy the most and to eval-uate the effect of the GUI on usability and driverdistraction.
The preliminary results show that theconversational speech dialog performs more effi-cient than the command-based dialog.
However,the conversational dialog distracts more from driv-ing than the command-based.
Furthermore, the re-sults indicate that an SDS supported by a GUI ismore efficient and better accepted by the user thanwithout GUI.In the next step, the data set will be analyzed onall mentioned usability and driving performancemeasures.
The different subdialog types of eachdialog will be investigated in detail on dialog per-formance and speaking styles.
Furthermore, cross-links between subdialogs and the driving perfor-mance measures are analyzed.240ReferencesL.
Devillers and H. Bonneau-Maynard.
1998.
Eval-uation of dialog strategies for a tourist informationretrieval system.
In Proc.
ICSLP, pages 1187?1190.Driver Focus-Telematics Working Group.
2002.
State-ment of principles, criteria and verification pro-cedures on driver interactions with advanced in-vehicle information and communication systems.Alliance of Automotive Manufacturers.Governors Highway Safety Association.
2011.
Dis-tracted driving: What research shows and whatstates can do.
Technical report, U.S. Department ofTransportation.H.
Hofmann, U. Ehrlich, A. Berton, and W. Minker.2012a.
Speech interaction with the internet - a userstudy.
In Proceedings of Intelligent Environments,Guanajuato, Mexico, June.H.
Hofmann, Anna Silberstein, U. Ehrlich, A. Berton,and A. Mahr.
2012b.
Development of speech-basedin-car hmi concepts for information exchange inter-net apps.
In Proceedings of International Workshopon Spoken Dialogue Systems, Paris, France, Decem-ber.K.
S. Hone and R. Graham.
2001.
Subjective assess-ment of speech-system interface usability.
In Pro-ceedings of Eurospeech.Angela Mahr, Michael Feld, Mohammad MehdiMoniri, and Rafael Math.
2012.
The ConTRe (con-tinuous tracking and reaction) task: A flexible ap-proach for assessing driver cognitive workload withhigh sensitivity.
In Adjunct Proceedings of the 4thInternational Conference on Automotive User Inter-faces and Interactive Vehicular Applications, pages88?91, Portsmouth, United States.Stefan Mattes.
2003.
The lane-change-task as a toolfor driver distraction evaluation.
Proceedings ofIGfA, pages 1?30.Sebastian Mo?ller.
2005.
Parameters describing the in-teraction with spoken dialogue systems.
ITU-T Rec-ommendation Supplement 24 to P-Series, Interna-tional Telecommunication Union, Geneva, Switzer-land, October.
Based on ITU-T Contr.
COM 12-17(2009).Hartmut Mutschler, Frank Steffens, and Andreas Ko-rthauer.
2007.
Final report on multimodal exper-iments - part 1: Evaluation of the sammie system.d6.4.
talk public deliverables.
Technical report.Annie Pauzie.
2008.
Evaluating driver mental work-load using the driving activity load index (DALI).In Proceedings of European Conference on HumanInterface Design for Intelligent Transport Systems,pages 67?77.Matthias Peissner, Vanessa Doebler, and FlorianMetze.
2011.
Can voice interaction help reducingthe level of distraction and prevent accidents?
meta-study on driver distraction and voice interaction.Technical report, Fraunhofer-Institute for IndustrialEngineering (IAO) and Carnegie Mellon University.241
