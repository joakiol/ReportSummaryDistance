2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 417?426,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsEncouraging Consistent Translation ChoicesFerhan Ture,1Douglas W. Oard,2,4Philip Resnik3,41Department of Computer Science2College of Information Studies3Department of Linguistics4Institute for Advanced Computer StudiesUniversity of Maryland, College Park, MD 20740 USAfture@cs.umd.edu, oard@umd.edu, resnik@umd.eduAbstractIt has long been observed that monolingual textexhibits a tendency toward ?one sense per dis-course,?
and it has been argued that a related?one translation per discourse?
constraint is op-erative in bilingual contexts as well.
In this pa-per, we introduce a novel method using forceddecoding to confirm the validity of this con-straint, and we demonstrate that it can be ex-ploited in order to improve machine translationquality.
Three ways of incorporating such apreference into a hierarchical phrase-based MTmodel are proposed, and the approach where allthree are combined yields the greatest improve-ments  for  both  Arabic-English  and  Chinese-English translation experiments.1 IntroductionIn statistical Machine Translation (MT), the state-of-the-art approach is to translate phrases in the contextof a sentence and to re-order those phrases appro-priately.
Intuitively, it seems as if it should also bepossible to draw on information outside of a singlesentence to further improve translation quality.
Inthis paper, we challenge the conventional approachof translating each sentence independently, and ar-gue that it can indeed also be beneficial to considerdocument-scale context when translating text.
Mo-tivated by the success of a ?one sense per discourse?heuristic in Word Sense Disambiguation (WSD), weexplore the potential  benefit of leveraging a ?onetranslation per discourse?
heuristic in MT.The paper is organized as follows.
We begin withrelated work in Section 2.
Next, we provide newconfirmation that the hypothesized one-translation-per-discourse  condition  does  indeed  often  hold,based  on  a  novel  analysis  using  forced  decoding(Section 3).
We incorporate this idea into a hierarchi-cal MT framework by adding three new document-scale features to the translation model (Section 4).We then present  experimental  results  demonstrat-ing  solid  improvements  in  translation  quality  ob-tained by leveraging these features, both for Arabic-English (Ar-En) and Chinese-English (Zh-En) trans-lation (Section 5).
Conclusions and future work arepresented in Section 6.2 Related workExploiting  discourse-level  context  has  to  datereceived  only  limited  attention  in  MT re-search (e.g., (Gime?nez  and  Ma`rquez, 2007; Liuet al, 2010; Carpuat, 2009; Brown, 2008; Xiao etal., 2011)).
Exploratory analysis of reference trans-lations by Carpuat  (2009)  motivates  a  hypothesisthat MT systems might benefit from the ?one senseper discourse?
heuristic, first introduced by Gale etal.
(1992), which has proven to be effective in thecontext of WSD (Yarowsky, 1995).
Carpuat?s ap-proach was to do post-processing on the translationoutput to impose a ?one translation per discourse?constraint where the system would otherwise havemade a different choice.
A manual evaluation ona sample of sentences suggested promise from thetechnique, which  Carpuat  suggested  in  favor  ofexploring more integrated approaches.Xiao et al (2011) took this one step further andimplement an approach where they identified am-biguous translations within each document, and at-417tempt to fix them by replacing each ambiguity withthe most frequent translation choice.
Based on theirerror analysis, the authors indicate two shortcomingswhen trying to find the correct translation of a givenphrase.
First, frequency may not provide sufficientinformation to distinguish between translation can-didates, which is why we take rareness into accountwhen scoring translation candidates.
Another prob-lem is, like any other heuristic, that there may becases where the heuristic fails and there are multi-ple senses per discourse.
Guaranteeing consistencyhurts performance in such situations, which is whywe implement the heuristic as a model feature, andlet the model score decide for each case.We are aware of a few other analyses that haveshown promising results based on a similar motiva-tion.
For instance, Wasser and Dorr (2008)?s ap-proach biases the MT system based on term statisticsfrom relevant documents in comparable corpora.
Maet al (2011) show that a translation memory can beused to find similar source sentences, and consecu-tively adapt translation choices towards consistency.Domain adaptation for MT has has also been shownto be useful in some cases (Bertoldi and Federico,2009; Hildebrand et al, 2005; Sanchis-Trilles andCasacuberta, 2010; Tiedemann, 2010; Zhao et al,2004), so to the extent we consider documents to bemicro-domains we might expect similar approachesto be useful at document scale.
Indeed, hints thatsuch ideas may work have been available for sometime.
For example, there is clear evidence that thebehavior of human translators can provide evidencethat is often useful for automating WSD (Diab andResnik, 2002; Ng et al, 2003).
When coupled withthe one-sense-per-discourse heuristic, this suggeststhat the reverse may also be true.3 Exploratory analysisIt is well known that writing styles vary by genre,and in particular that the amount of vocabulary vari-ation within a document depends to some extent onthe genre (e.g., higher in poetry than in engineeringwriting).
The degree to which authors tend to makeconsistent word choices in any particular genre is,therefore, an empirical question.
In order to gain in-sight into the extent to which human translators makeconsistent vocabulary choices in the types of materi-als that we wish to translate (in this work, news sto-ries), we first explore the degree of support for ourone-translation-per-discourse hypothesis in the ref-erence translations of a standard MT test collection.We used the Ar-En MT08 data set, which con-tains 74 newswire documents with a total  of 813sentences, each of which has four reference trans-lations.
Throughout this paper we consistently usethe  document  (i.e., one  news  story)  as  a  conve-nient discourse unit, although of course finer-scale orbroader-scale discourse units might also be exploredin future work.
Moreover, throughout this paper weuse the hierarchical phrase-based translation system(Hiero), which is based on a synchronous context-free grammar (SCFG) model (Chiang, 2005).
In aSCFG, the rule [X] ||| ?
||| ?
indicates that con-text free expansion X ?
?
in the source languagecan occur synchronously with X ?
?
in the targetlanguage.
In this case, we call ?
the left hand side(LHS) of the rule, and ?
the right hand side (RHS)of the rule.To determine the extent and nature of translationconsistency choices made by human translators, werandomly selected one of the four sets of referencetranslations (first set, with id 0) and we used forceddecoding to find all possible sequences of rules thatcould transform the source sentence into the targetsentence.
In forced decoding, given a pair of sourceand target sentences, and a grammar consisting oflearned translation rules with associated probabili-ties, the decoder searches all possible derivations forthe one sequence of rules that is most likely (underthe learned translation model) to synchronously pro-duce the source sentence on the LHS and the targetsentence on the RHS.
For instance, consider the fol-lowing Arabic sentence as input:????
???
??????????
???????
.and its uncased reference translation:there is a link between the three attacks .The following four rules, which are part of the SCFGlearned from the the same translation pairs, allowsthe decoder to find a sequence of derivations that?translates?
the source-side Arabic sentence into the418X16X7  ???
X12X3  ??????????
????
???????
.R1R2 R3R4X16X7 between X12X3  the  there  attacks .
three  is  a  linkR1R2 R3R4Figure 1: Illustration of forced decoding.target-side reference translation.1R1.
[X12] ||| ????
||| there is a linkR2.
[X16] ||| [2] ???
[1] ||| [X12, 1] between [X7, 2]R3.
[X7] ||| [1] ??????????
.
||| [X3, 1] attacks .R4.
[X3] ||| ???????
||| the threeFigure 1 illustrates how the decoder uses theserules  to  produce the source and target  sides  syn-chronously.As we repeated this  procedure  for  all  sentencepairs, we kept track of all rules that were actuallyused by the decoder to generate a reference Englishtranslation from the corresponding Arabic sentences.Our next step was to identify cases in which theSCFG could reasonably have produced a substan-tially  different  translation.
Whenever  an  Arabicphrase f occurs multiple times in a document, and fappears on the LHS of two or more different gram-mar rules in the SCFG, we count this as a single?case?.2These cases correspond to unique (sourcephrase f , document d) pairs in which a translationprocess using that SCFG could have chosen to pro-duce two or more different translations of f in d.Since the multiple appearances of f are distributedamong sentences of d, each counted case may cor-respond to a number of sentences ranging from 1 tothe number of sentences in that document.Table 1 shows a small sample of the cases (i.e.,(source phrase f , document d) pairs) identified as aresult of forced decoding.
There were 321 such casesin our dataset and there were 672 sentences in whichat least one case occurred.
This is not an uncommonphenomenon; these 672 sentences comprise 83% of1Since our goal was an exploratory analysis, the MT08 testset was combined with the training set in order to ensure reach-ability of the reference translations using the learned grammar.Proper train/dev/test splits were, of course, used for the evalua-tion results reported in Section 5.2We define a phrase as any text that constitutes the entireLHS of a grammar rule.the test set.
However, many of these cases repre-sent either unlikely choices or inconsequential dif-ferences, so some post-processing is called for.Since  grammar  rules  are  typically  more  fine-grained than is necessary for our purposes (e.g., tocapture various punctuation and determiner differ-ences that do not affect the ?sense?
of the transla-tion), we applied a few simple heuristics to edit thesource and target  sides and group all  such minorvariations into a single ?mega-rule?
(e.g., ?how??
?,how?, ?third??
?a third?, ?want??
?we want?).
Forthis, we removed nonterminal symbols and punc-tuation, and  considered  two target  phrases e ande?
to  be different only  if edit distance(e, e?)
>max(length(e), length(e?
))/2, where the edit dis-tance is based on character removal and insertion.For instance, the third example in Table 1 wouldhave been considered to be translated consistentlyas a result of this heuristic, as opposed to the firstexample.
We also eliminated cases in which no rea-sonable alternatives were available in the translationgrammar (i.e., cases where the second most probablerule with the same LHS was assigned a probabilitybelow 0.1 in the grammar).
Cases 4 and 5 wouldhave been removed by this heuristic.After this filtering and aggregation we were leftwith 176 (f , d) pairs in which the translation modelcould reasonably have selected between rules thatwould have produced substantially different Englishtranslations of f in d (such as cases 1?3 and 6?9).It was these 176 cases, affecting a total of 512 sen-tences (63% of test set) for which we then examinedwhat forced decoding could tell us about translationconsistency.So now that we know what the human who pro-duced the reference translations actually did (accord-ing to forced decoding), and in which cases theymight reasonably have chosen to do something sub-stantially different (according to the SCFG), we canask in which cases the human (effectively) made aconsistent choice of translation rules when encoun-tering the same Arabic phrase in the same document.In 128 of the 176 cases, that is what they did (i.e.,when the same phrase occurred multiple times in asingle document and more than one translation wasreasonably possible, forced decoding indicated thatthe human translator translated that phrase in essen-tially the same way).
These cases affected the trans-419CaseTranslation countsSource phrase Doc #????
566 that killed = 1killing of = 1???????
782 hostages = 2???????
138 hostage = 1hostages = 2?????
466 korea = 2?????
763 korea = 2??
30 from = 2??
7 of = 1from = 1??
??????
717 of the current = 2????
30 the = 1which =1Table 1: A sample of cases (i.e., (source phrase f , docu-ment d) pairs) identified as a result of forced decoding.lation of 455 sentences (56% of the test set), suggest-ing that if we can replicate this human behavior in asystem, it might affect a nontrivial number of trans-lation choices.These statistics also suggest, however, that theremay be some risk incurred in such a process, sincein 48 of the 176 cases, the human translator optedfor a substantially different translation.
When weclosely examined these 48 instances, we found that19 (40%) involved changing a content-bearing word(sometimes to a word with similar meaning).
The re-maining 29 (60%) involved function words or simi-lar constructions.
See Figures 2 and 3 for examples.1a.
[X] ||| ????
||| had allowed1b.
[X] ||| ????
||| has permitted2a.
[X] ||| [X,1] ????
||| examining [X,1]2b.
[X] ||| [X,1] ????
||| is considering [X,1]3a.
[X] ||| [X,1] ??????
||| neighbors3b.
[X] ||| [X,1] ??????
||| neighboring countriesFigure 2: Examples of differences in lexical choice forcontent-bearing words within the same document.We can make several observations based on thisanalysis.
First, there does indeed seem to be ev-idence to support the one-translation-per-discourseheuristic, and to suggest that respecting that heuris-4a.
[X] ||| ??
||| on4b.
[X] ||| ??
||| in4c.
[X] ||| ??
||| ?s5a.
[X] ||| ??
||| had5b.
[X] ||| ??
||| wasFigure 3: Examples of differences in lexical choice forother types of lexical units within the same document.tic could improve translation outcomes for a substan-tial number of sentences.
Second, even when a ref-erence translation contains different translations ofthe same phrase, this may sometimes be the result ofstylistic choices rather than an intent by the transla-tor to affect the expressed meaning.
If a system weretry to ?fix?
such cases by enforcing consistent trans-lation, the resulting translation might be somewhatmore stilted, but perhaps not less accurate or less in-telligible.
Finally, sentence structure conventions orother language-specific phenomena may sometimesrequire the same phrase to be translated differently,so some way of encouraging consistency while stillallowing the model to consider other contextual fac-tors might be better than always imposing a hard con-sistency constraint.4 ApproachTo incorporate document-level features into an MTsystem  that  would  otherwise  operate  with  onlysentence-level  evidence, we  added  three  super-sentential ?consistency features?
to the translationmodel.
The decoder computes scores for these fea-tures in two passes over each document; in each pass,each sentence in the document is decoded.
In thefirst pass, the decoder keeps track of the number ofoccurrences of some aspects of each grammar ruleand stores that information.
The consistency fea-tures are disabled during this pass, and do not affectdecoder scoring.
In the second pass, each grammarrule is assigned as many as three consistency featurescores, each of which is based on some frozen countsfrom the first pass.
These features are designed tointroduce a bias towards translation consistency, butto leave the final decision to the decoder, which ofcourse also has access to other  features from thetranslation and language model.
At this point we aremore interested in effectiveness than efficiency, so420we simply note that this approach doubles the run-ning time of the decoder and that future work on amore elegant implementation might be productive.We explore three ways to compute features in thissection.
The essential idea behind all of them is todefine some feature function that increases monoton-ically with an increase in some count that we believeto be informative, and in which the rate of increase isdamped more strongly as that count increases.
Sev-eral feature functions could satisfy those broad re-quirements; in this section, we describe three vari-ants, C1, C2 and C3, and discuss the potential bene-fits and drawbacks of each.C1: Counting rules In this variant, we count in-stances of the same entire grammar rule, where a ruler contains both the source phrase f and the targetphrase e. During the first pass, whenever a grammarrule is chosen by the decoder for the one-best output,the count for that rule is incremented.
Given a gram-mar rule r and the number of times r was counted inthe first pass (given by N{r}), the consistency fea-ture score is computed as follows:C1(r) =2.2N{r}1.2 + N{r}(1)Equation 1 is the term frequency component of thewell known Okapi BM25 term weighting function,when parameters are set to the conventional valuesk = 1.2, b = 0.
This is an increasing and con-cave function in which the count has a diminishingmarginal effect on the feature score.
It has provento be useful in information retrieval applications, inwhich the goal is to model ?aboutness?
based on termcounts (Robertson et al, 1994).
Because our goal isto demonstrate the potential of consistency features,it seemed reasonable to work with some simple func-tion that has a shape like the one we desired.
Weleave exploration of optimal damping functions forfuture work.A drawback of this C1 approach is that as we sawin Section 3, grammar rules in phrase-based MT sys-tems tend to be somewhat more fine-grained thanseems optimal for constructing a consistency fea-ture.
For instance, consider the following rules thatall translate the same Arabic term:R1.
[X] ||| [X,1] ?????
||| [X,1] the bodiesR2.
[X] ||| [X,1] ?????
||| [X,1] the organsR3.
[X] ||| [X,1] ?????
||| [X,1] organsR4.
[X] ||| ?????
[X,1] ||| the organs of [X,1]R5.
[X] ||| ?????
[X,1] ||| [X,1] bodiesBased on these grammar rules, we as human read-ers infer that this Arabic phrase can be translated intwo different ways: as organs or as bodies.
An opti-mal application of the one-translation-per-discourseheuristic would thus group the rules based on thepresence of one of those words.
However, in the C1variant, each of these rules would be counted sepa-rately because of differences that in some cases donot directly affect the choice of content words.
Forinstance, on the source side, the Arabic token ap-pears to the right of the nonterminal symbol in R1,R2 andR3, while it is to the left of the nonterminal inR4 andR5.
On the target side, differences are due toboth nonterminal symbol position and the existenceof determiners.
Motivated by many examples likethis, we came up with an alternative way of count-ing rules.C2: Counting target tokens To partially addressthis sparseness issue, variant C2 focuses only on thetarget side.
We extract all target tokens whenever agrammar rule is used by the decoder in a one-bestderivation and increment a counter for each.
Sincewe are mainly interested in content words (e.g.
bod-ies, organs), we use simple pattern matching to dis-card nonterminal symbols and punctuation, and weignore terms that appear in more than 50% of all doc-uments (a convenient way of discarding common to-kens such as the, or, and).
This approach separatesthe rules in the example above into two groups: ruleswith bodies on the target side and rules with organson the target side.
Upon completion of the first pass,the consistency feature score for rule r is then de-termined by first computing a score for each uniquetarget-side token w using:bm25(w) = 2.2N{w}1.2 + N{w}logD + 1DF (w) + 0.5(2)where in this caseN{w}maps tokens to their respec-tive counts in the document, D is the total numberof documents in the collection, and DF (documentfrequency) is the number of documents in which thetoken occurs.
This is a fuller version of the BM25function in which (in the information retrieval ap-plication) both high term frequencies and rare terms421are rewarded.
We then set the feature score for eachrule r to the maximum score of any of its target-sideterminal tokens:C2(r) = maxe?RHS(r)bm25(e) (3)Our motivation for choosing the maximum is thatwhen there is more than one content word that sur-vives the pruning of common terms, we want thescore to be influenced most strongly by the most im-portant of those terms.
Since BM25 term weightscan be thought of as a measure of term importance,taking the maximum is a simple expedient.Although counting only target-side tokens yieldscoarser granularity than counting rules, ignoring thesource side of the rule risks combining target sidestatistics from translations of unrelated source lan-guage terms.
Consider the following grammar rule:R6.
[X] ||| <s> [X,1] ?????
||| <s> [X,1] life supportSince the counter for life and support will both beincremented whenever rule R6 fires in the one-bestdecoding during the first pass, problems could ariseif a rule with a different LHS that also contains sup-port on the RHS were to fire in the same document,for example:R7.
[X] ||| ??????
||| supportIf we don?t take the source side into account, both oc-currences of support will be grouped together whencounting and R7 will receive extra score from theconsistency feature whenever R6 is used by the de-coder.
Of course, this problem will only arise whenthe LHS of R6 and R7 are present in the same doc-ument, and how often that happens (and thus howlarge the risk from this factor is) is an empirical ques-tion.
We therefore developed a third alternative as amiddle ground between the fine-grained C1 and thecoarse-grained C2.C3: Counting  token  translation  pairs In  thisvariant, we count each terminal (source token, tar-get token) pair that survives pruning.
Specifically,if grammar rule [X]|||f1f2...fm|||e1e2...en fires, weincrement the count of every pair ?fi, ej?, where fiis aligned to ej .
After the first pass, we compute thefeature value of each observed pair, based on thiscount and the DF of the target-side of the pair.
Wechose to use only the target token in the DF com-putation (i.e., aggregating over all source tokens) toreduce sparsity effects.
Similar to C2, the feature ofa rule r is defined by the maximum of scores of allpairs extracted from r.C3(r) = maxf?LHS(r)e?RHS(r)?f,e?
alignedbm25(?f, e?)
(4)Since each variant has its benefits and drawbacks, wecan include all three in the system and let the tuningprocess decide on how each should be weighted.5 Evaluation and DiscussionWe have evaluated the one-translation-per-discoursefeature using the cdecMT system (Dyer et al, 2010).We started by building a baseline system using stan-dard features in cdec: lexical and phrase transla-tion probabilities in both directions, word and aritypenalty features, and a 5-gram language model.
Wethen added each of the three consistency feature vari-ants, along with all two-way and the one three-waycombinations of them, thus yielding a total of eightsystems for comparison, including the baseline.For training the Ar-En system, we used the datasetfrom the DARPA GALE evaluation (Olive et  al.,2011), which consists of NIST and LDC releases.The corpus was filtered to remove sentence pairswith  anomalous  length  ratios  and  subsampled  toyield a training set containing 3.4 million parallelsentence pairs.
The Arabic text was preprocessed toproduce two different segmentations (simple punctu-ation tokenization with orthographic normalization,and LDC?s ATBv3 representation (Maamouri et al,2008)), represented together using cdec?s lattice in-put format (Dyer et al, 2008).The Zh-En system was trained on parallel train-ing text consisting of the non-UN portions and non-HK Hansards portions of the NIST training corpora.Chinese was automatically segmented by the Stan-ford segmenter (Tseng et al, 2005), and traditionalcharacters were simplified.
After subsampling andfiltering, we obtain a training corpus of 1.6 millionparallel sentences.Both  training  sets  were  word-aligned  withGIZA++ (Och and Ney, 2003), using 5 Model  1and  5  HMM iterations.
A SCFG was  then  ex-tracted from these alignments using a suffix arrayextractor (Chiang, 2007).
Evaluation was done withmulti-reference BLEU (Papineni et al, 2002) on test422sets with four references for each language pair, andMIRA was used for tuning (Crammer et al, 2006).In our experiments, we run the first decoding phaseusing feature weights that are guessed heuristicallybased on weights from previously tuned systems.All feature weights, including the discourse feature,were then tuned together, based on the output  ofthe  second  decoding  phase.
For  Ar-En  parame-ter  tuning, we  used  the  MT06 newswire  dataset,which contains 104 documents and a total of 1,797sentences.
For testing, we used the MT08 datasetdescribed  above  (74  documents, 813  sentences).For Zh-En experiments, the MT02 newswire dataset(100 documents, 878 sentences) was used for tuning,and evaluation was done on the MT06 test set (79documents, 1,664 sentences).
For  both languagepairs, DF values were computed from the tuningset for both tuning and evaluation experiments.When we used NIST?s official metric (BLEU-4)to compare our results to the official NIST evalu-ation (NIST, 2006; NIST, 2008), our baseline sys-tem achieved 54.70 for  Ar-En and 31.69 for  Zh-En.
Based on reported NIST results, our baselinewould have ranked 4thin the Zh-En MT06 evalua-tion, and would have outperformed all Ar-En MT08systems.
We used a slightly different IBM-BLEUmetric for the rest of our evaluation.
In this case,the baseline system achieved 53.07 BLEU pointsfor  Ar-En  and  30.43  points  for  Zh-En.
Amongmore recent papers, the best reported results were56.87  for  Ar-En  MT08 (Zhao  et  al., 2011a)  and35.87 for Zh-En MT06 (Zhao et al, 2011b), althoughmany papers report BLEU scores below 53 pointsfor Arabic (Carpuat et al, 2011) and 32 points forChinese (Monz, 2011).
The systems that outper-formed our baseline applied novel techniques, andused larger language models, as well as many non-standard features.
We argue that these novelties arecomplementary to our approach, and therefore do notdamage the credibility of our baseline.Among the single-feature runs, C3 had the bestperformance  in  Ar-En  experiments, with  53.84BLEU points, whereas C2 yielded the best resultsfor Zh-En with a BLEU score of 30.96.
In any case,all three variants outperformed the baseline (see Ta-ble 2).
When multiple features were combined, wegenerally observed an increase in BLEU, suggestingthat our features have usefully different error char-Method BLEUAr-En Zh-EnBaseline 53.07 30.43C1 53.82 30.59C2 53.70 30.96C3 53.84 30.54C12 53.82 30.79C13 53.82 30.76C23 53.88 30.63C123 53.98 31.42Table 2: Evaluation results: BLEU scores with four ref-erences for Ar-En and Zh-En experiments.Method # documentsAr-En Zh-EnDocs 74 79C1 37 30C2 37 35C3 42 36C123 43 41Table 3: Doc-level analysis: Number of documents whereeach variant outperforms baseline.acteristics.
The combination of all three variants,C123, yielded the best results, nearly 1.0 BLEU pointhigher  than  the  baseline  for  both  language  pairs.Evaluation results are summarized in Table 2.Given our focus on documents, it  is  natural  toask  what  fraction  of  the  documents  were  helpedor  harmed  by  consistency  features.
Document-level  BLEU scores  for  Arabic-to-English  transla-tions show that C3 outperformed the baseline on alarger number of documents than any other singlefeature (42/74=57%), compared with 37/74 (50%)for both C1 and C2.
C123 did better by this measureas well, with BLEU increasing for 43 of the docu-ments.
There were no documents where the BLEUscore  was  exactly  the  same, therefore  the  BLEUscore declined for the remaining documents.
As Ta-ble 3 indicates, document-level BLEU for the Zh-Enexperiments shows similar results.We can also look at our results in a more fine-grained way, focusing on differences in how eachsystem translated the same source-language phrase.For  this  analysis, we  defined  English  phrases eand e?
to  be different if edit distance(e, e?)
>423Method Ar-En Zh-EnCases Test set Cases Test setC1 77 24% 401 48%C2 127 35% 686 60%C3 101 33% 491 53%Any 197 68% 968 94%C123 141 41% 651 59%Table 4: Effect of applying variants of the consistencyfeature (Any=C1 or C2 or C3).max(length(e), length(e?))/2.
By  this  way  ofcounting, there are 197 unique (Arabic phrase, docu-ment) pairs for which at least one single-feature sys-tem produced translations differently from the base-line system.
Together, these cases affect 553 sen-tences (68%) in 67 of the 74 documents, with asmany as 12 differences observed in a single doc-ument.
The  number  of  such  differences  is  evenhigher for Chinese-to-English translation, probablydue to lower confidence from the translation modeland longer documents.
Table 4 shows the number ofchanges by each system, and the percentage of thetest set affected by these changes.In order to gain greater insight into the effect ofthe consistency features, we randomly sampled 60of the 197 cases and analyzed the influence of thechange to the document BLEU score.
In 25 of thesampled cases, at least one of the three systems madea change that improved the BLEU score, whereas thescore was adversely affected for at least one systemin 13 cases.
BLEU remained unchanged in the re-maining 22 cases, mostly due to the use of multi-ple reference translations.
When we analyze the ef-fect of each system separately, we see that C2 wasthe most aggressive, making 25 changes that influ-enced BLEU (16 positive, 9 negative).
C1 was themost conservative, with only 13 such changes (8 pos-itive, 5 negative).
Consistent with the overall BLEUscores, C3 evidenced the best ratio between benefitand harm, making 20 changes that affected the score(16 positive, 4 negative).Looking at specific cases can yield some insightinto how the consistency features achieve improve-ments.
For example, results improved when trans-lating the phrase ??????
?, (Eng.
organizational,regulatory), which appears in the context of organi-zational groups that support terrorist ideology.
Thebaseline system translated this as organizational inone case, and regulatory in another.
Variants C1and C2 changed this behavior, so that the translationwas organizational in both cases.
One of the refer-ence translations used organizational in one case anddropped the phrase in the other, and the other threetranslators  provided  consistent  translations  (usingorganized and organizational).
As a result, applyingthe one-translation-per-discourse heuristic improvedthe multi-reference BLEU score.On the other hand, here is one of the cases whereour  feature  hurt  performance.
The  phrase ????
(Eng.
border/frontier troops/guards) appearsin two sentences of a Chinese news story about vio-lence along the India - Nepal border.
All referencetranslations consistently used the word border in thetranslation, as it is a better choice in this context.The baseline system translated the phrase as fron-tier guards and border troops in the two sentences.All system variants replaced border with frontier tomaintain consistency, and therefore produced worsetranslations, causing a decrease in BLEU score.Examples can, however, also point up limitationsin our ability to measure improvements.
In one ofthe test documents, the Arabic phrase ??????
???(Eng.
sneak, infiltrate, enter without approval) ap-pears in the context of Turkey trying to enter the Eu-ropean Union.
This was translated by the baselinesystem as sneak into in one occurrence and infiltrateinto in another.
C1 didn?t change the output, butC2 and C3 translated the phrase as infiltrate into inboth cases.
Although all of the four reference trans-lators were consistent within their choices, each ofthem chose different translations, namely worm itsway, enter, sneak and sneak into.
This resulted ina decrease in BLEU score for the two systems thatchose infiltrate into.
This case illustrates a limita-tion to fine-grained use of BLEU alone as a basisfor analysis, since we might argue that infiltrate intois no less appropriate than sneak into in this con-text.
In other words, some of the reductions we seein BLEU may not be actual errors but rather sim-ply changes that take us outside of the coverage ofthe test set.
We did not find any cases in our samplein which improvements in BLEU seemed to rewardchanges that adversely affected meaning.
From this,424we conclude that BLEU is a somewhat conservativemeasure when used in this way, and that the actualoverall improvement in translation quality over ourbaseline may be somewhat more than our roughly1.0 measured BLEU improvement would suggest.6 Conclusions and Future WorkIn this paper, we started with a new way of look-ing at, and largely supporting, the ?one translationper discourse?
hypothesis using forced decoding ofhuman reference translations.
We then leveragedinsights  from that  analysis  to  design  the  transla-tion model consistency features, obtaining solid im-provements for both Ar-En and Zh-En translation.In future work, we plan to explore additional vari-ants.
For example, we can further address sparsity byincorporating monolingual paraphrase detection onthe source side, the target side or both.
We can andshould explore other monotonically increasing con-cave feature functions in addition to the Okapi BM25function that we have found to be useful in this work,we should explore alternatives to our use of the max-imum function in C2 and C3, and we should con-sider optimizing to measures other than BLEU (e.g.,METEOR) that extend the range of rewarded lexicalchoices by leveraging monolingual paraphrase evi-dence.In designing our features we were guided by ourintuition about which kinds of consistency should berewarded.
Data can be superior to intuition, how-ever, and our forced decoding technique might alsobe helpful in generating new insights that could helpto guide the design of even more useful features.
Forexample, our forced decoding clearly points to casesin which translators have chosen different structuralvariants when translating the same phrase, and closerexamination of these cases might help us to automat-ically detect which kinds of structural variation canmost profitably be moderated using a consistencyfeature.
We should also note that we have only doneforced decoding to date in one language pair (Ar-En), and there might be more to be learned aboutlanguage-specific issues from doing the same anal-ysis for additional language pairs.Finally, the time seems propitious to reconsiderour choice of document-scale as our discourse con-text.
Documents have much to recommend them, butmuch of the content that we might wish to translate(conversational speech, text chat, email threads, .
.
.
)doesn?t present the kinds of obvious and unambigu-ous document boundaries that we find in MT testcollections that are built from news stories.
More-over, some documents (e.g., textbooks) may be toodiverse for an entire document to be the right scalefor consistency.
We might also be able to produc-tively group similar documents into clusters in whichthe vocabulary choices are (or should be) mutuallyreinforcing.We therefore  end where  we began, with  manyquestions to be answered.
Now, however, we havesomewhat different questions ?
not whether to en-courage consistency at a super-sentential scale, butrather when and how best to do that.AcknowledgementsThis research was supported in part by the BOLTprogram of the Defense Advanced Research ProjectsAgency, Contract No.
HR0011-12-C-0015.
Anyopinions, findings, conclusions or recommendationsexpressed in this paper are those of the authors anddo not necessarily reflect the view of DARPA.ReferencesNicola  Bertoldi  and  Marcello  Federico.
2009.
Do-main adaptation for statistical machine translation withmonolingual resources.
In Proceedings of the FourthWorkshop on Statistical Machine Translation (StatMT?09), pages 182?189.Ralf D. Brown.
2008.
Exploiting document-level contextfor data-driven machine translation.
In Proceedings ofthe the Eighth Conference of the Association for Ma-chine Translation in the Americas (AMTA ?08).Marine Carpuat, Yuval Marton, and Nizar Habash.
2011.Improved Arabic-to-English statistical machine trans-lation  by  reordering  post-verbal  subjects  for  wordalignment.
Machine Translation, pages 1?16.Marine Carpuat.
2009.
One translation per discourse.
InProceedings of the Workshop on Semantic Evaluations:Recent Achievements and Future Directions, DEW ?09,pages 19?27.David Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In Proceedings ofACL ?05.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33:201?228.425Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
Journal of Machine LearningResearch, 7:551?585.Mona Diab and Philip Resnik.
2002.
An unsupervisedmethod for word sense tagging using parallel corpora.In Proceedings of ACL ?02.Christopher Dyer, Smaranda Muresan, and Philip Resnik.2008.
Generalizing Word Lattice Translation.
In Pro-ceedings of ACL-HLT?08, pages 1012?1020, June.Chris Dyer, Jonathan Weese, Hendra Setiawan, AdamLopez, Ferhan Ture, Vladimir Eidelman, Juri Ganitke-vitch, Phil Blunsom, and Philip Resnik.
2010. cdec: adecoder, alignment, and learning framework for finite-state and context-free translation models.
In ACLDe-mos ?10, pages 7?12.William A.  Gale, Kenneth W.  Church, and  DavidYarowsky.
1992.
One sense per discourse.
In Pro-ceedings of the workshop on Speech and Natural Lan-guage, HLT ?91, pages 233?237.Jesu?s Gime?nez and Llu?
?s Ma`rquez.
2007.
Context-awarediscriminative phrase selection for statistical machinetranslation.
In Proceedings  of  StatMT ?07, pages159?166.AS Hildebrand, M Eck, S Vogel, and Alex Waibel.
2005.Adaptation of the translation model for statistical ma-chine translation based on information retrieval.
InProceedings of The European Association for MachineTranslation (EAMT ?05).Zhanyi Liu, Haifeng Wang, Hua Wu, and Sheng Li.
2010.Improving statistical machine translation with mono-lingual collocation.
In ACL ?10.Yanjun Ma, Yifan He, Andy Way, and Josef van Gen-abith.
2011.
Consistent translation using discrimina-tive learning: a translation memory-inspired approach.In Proceedings of ACL-HLT?11, pages 1239?1248.Mohamed Maamouri, Ann Bies, and Seth Kulick.
2008.Enhancing the Arabic Treebank: A Collaborative Ef-fort toward New Annotation Guidelines.
In LREC ?08.Christof Monz.
2011.
Statistical Machine Translationwith Local Language Models.
In EMNLP ?11.Hwee Tou Ng, Bin Wang, and Yee Seng Chan.
2003.
Ex-ploiting parallel texts for word sense disambiguation:an empirical study.
In ACL ?03.NIST.
2006. http://www.itl.nist.gov/iad/mig/tests/mt/2006/.NIST.
2008. http://www.itl.nist.gov/iad/mig/tests/mt/2008/.Franz Och and Hermann Ney.
2003.
A systematic com-parison of various statistical alignment models.
Com-putational Linguistics, 29(1):19?51.Joseph Olive, Caitlin  Christianson, and John McCary.2011.
Handbook  of  Natural  Language  Processingand Machine Translation: DARPAGlobal AutonomousLanguage  Exploitation.
Springer  Publishing  Com-pany, Inc., 1st edition.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In ACL ?02.Stephen E. Robertson, Steve Walker, Susan Jones, Miche-line  Hancock-Beaulieu, and  Mike  Gatford.
1994.Okapi at TREC-3.
In TREC.Germa?n  Sanchis-Trilles  and  Francisco  Casacuberta.2010.
Bayesian  adaptation  for  statistical  machinetranslation.
In Proceedings of the workshop on Struc-tural and Syntactic Pattern Recognition (SSPR ?10),pages 620?629.Jo?rg Tiedemann.
2010.
Context adaptation in statisticalmachine translation using models with exponentiallydecaying cache.
In Proceedings of the workshop onDomain Adaptation for Natural Language Processing(DANLP ?10), pages 8?15.Huihsin Tseng, Pi-Chuan Chang, Galen Andrew, DanielJurafsky, and Christopher Manning.
2005.
A con-ditional  random  field  word  segmenter.
In FourthSIGHAN Workshop on Chinese Language Processing.Michael M.  Wasser  and  Bonnie  Dorr.
2008.
Ma-chine  translation  with  cross-lingual  information  re-trieval based document relevance scores.
Unpublished.Tong Xiao, Jingbo Zhu, Shujie  Yao, and Hao Zhang.2011.
Document-level consistency verification in ma-chine translation.
InMachine Translation Summit XIII(MTS?11).David Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
In ACL ?95.Bing Zhao, Matthias Eck, and Stephan Vogel.
2004.
Lan-guage model adaptation for statistical machine transla-tion with structured query models.
In COLING ?04.Bing Zhao, Young-Suk Lee, Xiaoqiang Luo, and Liu Li.2011a.
Learning to transform and select elementarytrees for improved syntax-based machine translations.In ACL-HLT ?11, pages 846?855.Yinggong Zhao, Yangsheng Ji, Ning Xi, Shujian Huang,and Jiajun Chen.
2011b.
Language model weightadaptation based on cross-entropy for statistical ma-chine translation.
In Pacific Asia Conference on Lan-guage, Information and Computation (PACLIC ?11).426
