The Computer  Generat ion  of  Speech withDlscoursal ly and  Semant ica l ly  Mot ivated In tonat ionRob in  P. FawcettComputational Linguistics UnitUniversity of Wales College of CardiffCardiff CF1 3EUUKAbstractThe paper shows how it is possible, in the framemork of agygtemle funetlonal g:r~mmat, (SFG) approach to thesemantics of aatttral language, to generate an output withintonation that is motivated semantically and discoursally.Most of ~ wurk reported has already been *accuse, fullyimp lem~4 in GF.N~SY$ (the very large generator of theCOMMUNAL Pro~eet; see Appendix 1).
A major featureis that it does am flint generate a syntax tree and words, andthen impose intonational coatogm on them (as is a commonaggroaeh in modelling intonation); rather, it generates thevarious intonational feamrta diteetJy, as it is generating richlylabe.llad m:rucratea (as are typical in SFG), and the associateditems.
~ claim is not that the model p ~  he,?
solvesall the problems of generating intonation, but that it pointsa way forward that makea natural inks with semantics andditu:ourse.
A secondaJty perpoe~ of this paler is todemonstraW,, for one of many possible areas of NLO thatcould have been choc~n, that there is still much importantwork to be done in '~nt.e, mev geaeratkm'.
I do this tn orderto tefut?
the augge~On, ~easiOnally head at recente e l  that the major wod?
io 'sentence generation' hasalready been done, and that the main (only'?)
area ofs/gnifleanee in NLG is ia ltighet level planning.
In myexpea'ieace the two are inteaxlependen% and we should expectsignificant developments at eveey level in the years to come.1.
Purpose  and  ScopeThe aspect of NoZural Language Generation(NLG) to be described here is the generation ofspoken text that has intonation, where thatintonation is motivated both semantically (i.e, interms of the semantics - in a broad sense of theterm to be clarified soon - of sentences) anddJscoursally (Le.
in terms of vhat the discoursep!~..;.ng compotmnt specifies)."
Any specificationof intonation requires, of course, to be integratedwith an adapted version of a speech synthesizer(e.g.
one that draws on one of the currentlyavailable systems that attempts - inevitably withAppendix 1 for a brief overview of the project).L As will be ?l?ar from what fo l low the model presentedhcte owes a great deal to two people in particular:.
MichaelHalliday and Pad Teach.
Through them, I am well awate,there is a debt to many others, too numerous to mention,who have worked in the diffvgult field of intonation inF~glish.
\[ am grateful too for early encouragement i  thisarea from Gillian Brown (whose work is drawn on also byPaul Teach), nod for the regular?
ongoing stimulus of manygood explorations of ideas in this and other arco, s with mycolteagmt Gordon Tucker.
But none of there should bcblamed for the inevitable crudities, infelicities and no aoubtca'mrs in the model described here; these are mine.The approach is very different from that inMITalk (Allen 1986), which is essentially a text-to-speech system.
So far as I am aware, the onlygenerative model prior to ours that attempts togenerate intonation that is motivated semanticaIlyand discoursaIly is the impressive work of hard,Houghton, Pearson and their colleagues at Sussex(Houghton and hard 1987) and Houghton andPearson 1988).
Its limitation is the very small sizeof its syntax, lexis, semantics and working domain.We see our work in the COMMUNAL Project asbeing to build on their important achievement.
(But see Appendix 2 for what we do not attempt.)2.
The Relevant Components of theCommunal ModelThe major components of the overall model thatwill b?
referred to below are as follows.
Weassume an Interactive system, rather than one thatis merely monologue.
We shall ignore here thecomponents related to parsing, interpretation a dinputting to the belief system and planner.
Thecomponents relevant to generation are:1.
The  bel ief  system, which inc ludes general andspecific beliefs about ('knowledge of) situationsand things in some domain; specific beliefs aboutthe content of the preceding discourse, aboutvozious aspects of the current social situation,about the addressee and his beliefs of all types,his attitudes, his goals and plans.2.
A planner, which makes general plans, drawingon knowledge of ...3. genres (scripts, schemas, etc), introducingwhere appropriate sub-units uch as transactions(see below) and more detailed plans, using ...4, the local discourse grammar, which ismodelled as a 'systemic flowchart' (i.e.
a flowchartcontaining many small system networks at thechoice points, and which generates xchanges andtheir structure),5. the lexlcogrammar, i.e.
the sentence generator,consisting of:164a.
the system networks of semantic features fora wide variety of types of mea-;-g related tosituations and realized in the clause, includingtheme and information structure as well astransitivity, mood, negativity, modallty, affeetivemeaning and logical relationships, and equivalentsystem networks for thiage and qualities, andb.
the realization rules which turn the selectionexpressions of features that are the output frompasses through the system networks into syntacticstructures with Items (grammatical nd lexical)and markers of punctuaUou or intonation as theirterm;hal nodes.3.
Mode l l ing  In tonat ion3.1.
,am Overview of the Generation of IntonationLet as imagine that Ivy (the 'person' of whoseufind GENESYS models a part) is about togenerate a sentence, Let us suppose that she isbeing consulted by the Personnel Officer of alarge institution, who draws regularly on herspecialist knowledge and advice, and that he hasjust asked her Wghere does Peter Piper live?".
(We shall come later to how intonation isrepresented.)
Like most human users oflanguage, Ivy makes reasonable assumptions about(loosely, she 'knows') where she is in any currenttransaction (e.g.
at the start, in the middle or atthe end), and where she is in the currentexchange.
This affects the pitch level of what shesays.
She needs to choose a tone (the change inpitch marked by a stepping or a slide on the tonicsyllable) which will express the MOOD of thefinal matrix clause of her sentence.
('Matrix' heremeans 'at the top layer of structure'.)
She nee&to locate that tone on an item which will bethereby marked as new Information.
She needs todecide if it is to be presented simply as 'neW, oras 'contrastively new' (in the terms used here).And she needs to deride on the Informationstatus of any chunks of information that are to bepresented as separate from the main Informationear  of the clause.
(The information that guidesthese choices comes from various aspects of thehigher belief system, which there is unfortunatelyno space to discuss here.
)As we shaft see, these various components of thesemantic level of intonation account, in a differentway from the usual approach in British intonationstudies, for Halliday% well-known triad of TONE,TONALITY and TONICITY.
While it isperfectly possible m talk about the contrasts inintonational form to which these three rder as'systems', I suggest hat it is more insightful totake, as the level of contrasts to be modelIed insystem networks, the meanings that lie behind (or,ia the SFG metaphor, above them).
Thesesemantic features are then realized in the purelyintonational contrasts of TONE, TONICITY andTONA.LITY.The accounts of the various aspects of intonationin what follows will inevitably be introductory, andmay to the specialist appear simplistic.
Asomewhat fuller treatment is given in Teach andFawcett 1988, and a very fur treatment isgiven inTenth 1987, which includes ummaries ofrelevantwork by other intonation spe?islists.
(I omit here, for reasons of space, a specificationof how one might model the way in which theposition in a transaction and an exchange affectsintonation.
)Let us assume, then, that Ivy is preparing aresponse to the Personnel Officer's question,using the information that, while Mr Peter Piper'saddress is currently 11 Romilly Crescent, Canton,Cardiff, he is moving from there after one month.In discourse planni.g terms, she chooses that hermove will be a 'support' for a 'solicit information',gad that the act at the head of the move is a 'givenew content ) (see Fawcett, van der Mije and vanWissen 1988).
As wc shall see, these choices pro.select in the MOOD network of thelexieegrammar the features \[information\] and\[giver\].
But first there is a more basic system toconsider.32.
The MODE SystemThe inidal rule of the semantics of the lexico-grammar to be considered here is:situation ->"MODE'& 'TENOR'&'CONGRUENCZ~SIT'.Thus means that, for any 'situation' ( roughly ='proposition') that you are generating, you mustmake choices in all three of the systems named.
(Notice, then, that 'parallelism' lies at the heart ofthe grammar.)
Here we shall be concerned onlywith the MODE system.
(It is from CONGR-UENCE SIT that the main part of the networkis entered, to generate configurations ofparticipant roles, such as Agent and Affected, andchoices in MOOD, such as 'information seeker',and very many others.)
The MODE system isvery simple:'MODE' -> 70% spoken / 30% written.This means: 'In the MODE system, you mustchoose between generating a spoken output (forwhich under random generation there is a 70%probability) and generating a written output(which carries a 30% probability).
Clearly, sinc~165Ivy is in a spoken interaction, she will be stronglydisposed to select \[spoken\].
but in principle sheneed not We shall not discuss here theinteresting reasons for and ~ in~t  introducing thissystem to the lexi?o-grammar itself, except topoint to two 91~,niEcant advantages that it brings.Nor, unfortunately, is there space to discuss theroles of the probabilities and the ways in whichthey are assigned (sometimes simply a guess atthe overall pattern for central types of text;somet;mes based on textual studies).
(The ne,~ few lines presuppose some familiaritywith systemic grammars; for those without thisknowledge it may be advisable to re-read thissection after seeing the working of the examples.
)What is the role of this system?
Fh'st, it enablesthe grammat-builder to refer, at any point on thisinitial pass through the system network, towhichOver feature in this system has been chosenas an entry condition to a later system.
In otherwords, where there is greater richness of choice inme aning in the spoken mode (as is typically thecase with m~nings real|Ted in intonation, asgain.st those reAI;~,~d in punctuation), we canensure that those systems are only entered whenthe feature \[spoken\] has been chosen.
We shallshortly see the great value of this.
Second, the'MODE' system enables us to refer, at any pointin a realization rule, on this or any subsequentpass through the network, to this feature as aconditional feature for the realization of someothex feature, In other words, we can ensure thatif \[spoken\] has been chosen the realization willtake the form of intonation, and if \[wrkten\] hasbeen chosen it is expressed in punctuation.
Bothof these faclh'fies contribute greatly to the elegantoperation of the lexieogramm~tr as a whole, bothin me~nin~ r?91h'?d ill intonation and in manyother ways.3.3.
The Sentence Generator= MOODThe unmarked choice in the 'CONGRUENCESIT' system is, unsurpri~ngly, \[congruent_sill.This is the choice that opens up the whole arrayof me~-;,~gs a.~sociated with realization in aclause, and many parallel systems follow.
Amongthese is the MOOD network.
This is a fairlylarge and complex network of meanings, andthese are re~l;-ed partly in syntax, partly in items(such as "please'), and partly in tone (= variationin pitch).
The network is too large and complexto present here, but we shall trace a route throughit that shows why it is central to an understan,4;-gof intonation.
The first options in the currentGENESYS network are shown below:congruent sit->'TRANgITIVITY' & 'MOOD (& OTHERS).
'MOOD(A)' -> 90% information / 10% directive.information -> 'MOOD(B)' &'TIME REFERENCE POINT' (& OTHERS).m'MOOD(B)' ->70% giver (1.2) / 30% seeker (16).The second line reads:' In the MOOD(A) systemyou must choose between the feature\[information\], which overall has a 90% probabilityof being selected, and \[directive\], which has onlya 10% probability.
As so often, the choice of asingle feature leads to further parallel systems,one of which continues the MOOD network itself.The last line in the above rules exemplifies theuse of numbers in brackets after the features; it isthe number of the realization rule for the featureconcerned.
What will this look like?Here is a slightly simplified version of therealization rule for \[giver\]:1.2 : giver :if falls 'Z' and (simplex sit orfinal co ordinated situation)ten  on r st3,ass  itten then 'E' < "!
')"'.if on,~first_pass poken then 'E' <The.
effect of this rule is on the 'Ender' (i.e.
'E',the last element in the structure of the clause).
If\[written\] is chosen in the 'MODE' system it isexpounded by a full stop (Br.
E. for 'period'), butif the choice is \[spoken\] it is expounded by a finalintonation unit boundary, i.e.
\[.
However, says therule, neither realization will occur unle~ theclause (1) directly fdls the element 'Sentence'(represented by'Z' a~ an approximation to sigma)and (2) is 'simplex ~,i.e.
is not co~ordinated withone or more other clauses or, if it is, is the finalclause.This may seem a surpr/~gly complex rule tothose in NIP used to working with mini-grammars.
But this is typical of the working levelof complexity in a natural anguage, and thosewho ate used to working with the problems ofbuilding broad coverage grammars will appreciatethat this is not a particularly complex rule.
In thecase of our example the effect is to give to Ivy'soutput a final intonation unit boundary.We come next to an example of the value of beingable to use of the feature \[spoken\] as an entrycondition to a system.
This is necessary becausethe MOOD network also builds in variables in'key' (in the sense of HaRiday 1970); i.e.
finerchoices w/t h;.
the MOOD options.
Thesecorrespond to what Tench treats separately asvariations in attitude.
While accepting the 'viewthat these more delicate choices can be seen as166serving a separate ftmction from the function ofthe basic tone, the fact is that in any systemiccomputational implementation the way in whichthey enter the choice systom is simply us moredelicate choices that are directly dependent on thebroad choice of meaning realized in the broadtone.
The range of such delicate variationsappears to be potentially different for the variousmeani,o~ (see further below).
In the systemsgiven below, note ~ high probability of choosing\[assertive\] followed by \[neutral\].giver & spoken ->70% assertive / 15% deferring (1.21) /15% withjeservation (1.22).assertive.
> 2% very strong (L23) / 8% strong(1.24) / 60% neutral (1.25) / 30% mild (1.26).In an intermediate level model (such as PrototypeGenerator 2 (PG2), which is the most advancedversion of GENESYS currently implemented) weneed only relatively simple rules such as thefollowing:1.21 : deferring:if fills 'Z' and on first p~ spoken and(simplex sit or\]inal~co~,rdinated situation)then '2-' by 'NT.
('lq'I" = 'Nuclear Tonic'; see 3.4.3.
)1.22 : with reservation :if fills '~' and on_first_pa~ss poken and(simplexsit or fmaI_co-ordinated skuation)then 'L2' by 'hiT '.And so on, for \[very strong\] (realized by '21'),\[strong\] (realized by ~?
'), \[neutral\] (realized byT)  and \[mild\] (realized by '1-').Here we are using a numerical notation for tonesthat goes back to an earlier tradition even thanHall\[day's description (1967, 1970), though it hasmuch in common with Hallida/s.
(Readers fromthe American traditiOn used to an iconicrepresentation may hate some adjustments tomake in interpreting the notation.
But thereshould be act fundamental diffu:ulty; Hallida/sdescription has been widely used (and indeedtested) on American and Canadian English.
)I give next a brief summary of the differencesbetween the scheme for tones used here andHall\[day's well-lmown scheme (1967, 1970).Tench's (and so my) numbers '1' and '2'correspond to HoJliday's usage, as do the use of'+' and '-'.
But Halt\[day% 'Tone 3' is seen as avariant of our Tone 2; Hallida/s Tone 4 (a fall.rise) is represented by '12'; and his 'Tone 5 (aris~fall) is shown as '21'.
Tench's generaldescriptions of the tones in words (1987) imply167four pitch level.% and I therefore use the followinglabels for the model implemented: base, low, midand high.
The four levels in turn provide aframework for describing three types of pitchchange.
It will be helpful for what follows to setthem out as three 'scales'; these descriptions ofthe tones are in effect source material for writingrealization rules.
(1 have given these scalesinformal semantic labels; these are not intendedto correspond irectly to the features in theMOOD network encountered sofar, but to evokefeatures from various parts of the network,including the many options dependent on\[directive\]).
F;uaily, let me remind yon that weare not at this point trying to account for alltones, but only for those that carry the MOOD ofa matrix simplex or final clause.
This dearseparation of the ways in which tones aregenerated is a key feature of the presentproposals.
We shall come shortly to some of theways of generating appropriate tones for some ofthe other positions in which tones occur.The 'assertive' scale (Tones 21 and 1):Tone 21: rise-fall (rise to high plus fall to base)Tone 1 +: high-fall (fall from high to base)Tone 1: mid-fall (fall from mid to base)Tone 1-: low-fall (fall from low to base)Also (see below):Tone 21.: low rise.fall (lower version of Tone21)*The 'deferring' scale (Tone 2):Tone 2+: high.rise (rise from base to high)Tone 2: mid-rise (rise from base to mid)Tone 2-.: low-rise (rise from base to low)The 'implication' scale (Tone 12):Tone 12: fall-riseAlso (see below):Tone 12-: low fall-rise (lower version of 12)** Tench suggests that these are variants of Tone21 and 12 that additionally signal 'emotionalinvolvement'.As will be clear, Tench and I propose amodification to HaUiday% basic set of contrastsin TONE, such that Hallida/s Tone 5 is seen asan extreme form of Tone 1.
This fits naturallywith the semantics of these tones.
In a somewhatsimilar way, Tench treats Hallida/s Tone 3 (a lowrise) as a variant of Hall\[day's Tone 2, under therubric of 'deference tothe listener', and we adoptthis too in COMMUNAL But note that, whilethat kind of semantic description holds good forTone 2s (Hall\[day% Tone 3s) in the sentence-finalposition, I shall suggest other means of generatingthem in non-final positions.
In the present systemthere are no 'double tone groups', such asHall\[day's Tone 13 (i.e.
a Tone I to realize themain MOOD meaning, followed by a Tone 3(here 2) for 'supplementary information'.)
Suchfinal Tone 2s will be generated in a similar way tothat to be illustrated in section 3.5 below forinitial Tone 3s (and, as we shaU see, 12s).
Finally,note that I include h~e one option that Tenchincludes under 'stat~ of information'.
This is his'implication', re~l;~?d in Tone 12, i.e.
a fall-rise.This is Halliday~s Tone 4, which he characterizesas (among other descriptions) 'with reservation'.This tone occurs both as a carrier of MOOD andotherwise; it is with the former tiutt we areconcerned here.
It seems plausible to treat it asa variant hat can be chosen as an alternative tothe basic falling and rising tones recognized byboth Halliday and Tench, and 1 have thereforeincorporated it in the overall MOOD network.3.4.
Focus of Information3.4.1.
The Line of Approach to the ProblemI shall present here a somewhat novel approach tothe relationship between the two sets ofphenomena described by both Halliday and Tenchas TONALITY and TONiCITY, TONALITY istypically thought of as 'cutting up a string ofwords into intonation ,mirA' ~ench's term;Halllday's is 'tone groups'), with each intonationunit realizing one information unit.
Theproblem, when one is approaching the questionfrom the angle of generation, is that there is nostring of words to eat up - not, that is, until thesenten~ has been generated.
We therefore needto look for a semanfl?
approach to the problem,My proposal is that it is helpful to start not withTONAL ITY  but TONICITY.TONICITY is the placing of the tonic on asyllable.
The item so markfd is shown to bebeing presented as new Information - and !h{s iSa semantic concept.
('New' information isinformation presented as 'not recoverable.')
Buta further problem arises, in that linguistsreccgni*e both 'marked' and '~1~marked' tonicity.3.4.2.
Generating Marked TonidtyMarked tonidty occurs when the item cont~;-i-gthe tonic syllable is presented by the speaker as'contrastivcly new'.
Unmarked toniclty occurswhen there is no marked tonicity (which is by farthe most mual case); we shatl return to thisshortly.
Marked tonidty is handled in GENESYSha the following way.
In principle, any pathwaythrough the system network that results in thegeneration of a formal item will lead to a systemof the following form (where  is the currentterminal feature):x- > notcontrastively_new / contrastively_new.The realiTafion of \[contrastively..new\] is that acontrastive tonic is conflated with the element ofstructure that the item expotmds.
TI~ fimpleversion implemented in PG2 is as follows:' INFORMATION FOCUS'->99% no element marked as contrastively.new \]1% elementmar'fked_as..~ont'rastively..new.element marked as contrastively new->50% ~ontrast~e newness on_.~larity (18.1) /50% contrastiv~newnes~on process (18.2) /0% other.Realization rule 18.1 states the complex set ofconditions for conflating a eontrastive tonic ('CT')with the appropriate element; for the POLARITYsystem ('positive' vs. 'negative') this is typically theOperator (which may have to be supplied by a'do-support' rule) but it may be any one of severalothers, depending on whether or not the clause ismoodless and, if not, whether a directive, and ifnot, what auxiliaries are realized, etc.
The rulefor presenting the 'process' (realized in the Mainverb) as 'contrastively_nmv' is however extremelysimple:18.2 : contrastlve newness_ on_.process :'CT' by 'M'.In the case of our c~mple, the choke is not topresent any clement as conttrasfively new.3.4.3.
Generat;.~g Unmarked TonicityHow, then, should we generate unmarkedtonicity?
The answer is simple: as the default -i.e.
when there is no contrastive tonic, in otherwords, I want to suggest that ~mmarked tonicity isa formal phenomenon f intonation that does notexpress an active choice in meaning..
The relevantfacts are well known, i,e., roughly, that what wehero term a nuclear tonic ('biT') fails on the lastlexical item in the information unit.
The questionis: 'How can we define the intonation unit, insemantic terms?'
The only contender as asemantic unit, in the GENF.SYS framework, isthesituation, i.e.
the semantic unit typically rvalizcdin the c law.
The actual decision as to whichitem the unmarked tonic shall be assigned to getsmade relatively late in the generation process.
InGENESYS we simply have a list of the few dozenitems generated by the lexicogrammar that cannotcarry the unmarked tonic: roughly, the'grammatical items' of English.
Essentially, then,this default rule will insert one, and only one,nuclear tonic in each sentence.
This will holdeven when there are two or more co-ordinatedclauses in that sentence, and/or one or more168embedded dames.3-q.
Slams of Information3_5.1.
The Importance of this CategoryThis is a concept not disting~j;shed as a separatephenomenon in Halliday's ~eatment ofintonation,but which Tench does treat separately.
This dearseparation oftwo semantically distinct phenomenawas a significant help in developing the generativemodel proposed here.
However the concept of'status of information' is quite highly generalised,in the seine that it is not manifested in just onepart of the overall network (as for exampleMOOD is).
Specifically, we fred this option atmany of the points where a unit is generated thatis not the final matrix clause in the sentence.Many of these ( thou# by no means all) havealready been implemented in GENESYS, and thefollowing are a representative sample.3.5.2.
The Co-ordination of Situations and ThingsOne major source of multiple intonation units isco-ordination.
Thus, when GENESYS generatesco-ordinated clauses (realizing co-ordinatedsltuatione) such as "Either Ivy loves Ike, or sheloves Fred, or she doesn't love anybody.
', she firstrecognizes at an abstract level that separateinformation Units are being assi~ed and theninserts, depending on whether the output is to bespoken or written, either (1) commas or (2)intonation trait boundaries and an appropriatetone such as Tone 2.
We shall trot re .educehere the surprisingly large system network andrealization rules for this area of the grammar,which merit a paper to themselves.
All that needsto be said is that to develop amodel of clause co-ordination that incorporates most of thephenomena ofnaturally occurring texts is a majortask and that it took several mouths of work tobuikl our current system.
In terms of the aboveexample, it generates, if \[spoken\] has beenselected:J either Ivy loves Ike/NT/2 \[or she loves Fred/NT/2 \[or she doesn't love anybody/NT/1 \]While the patterns of the networks and theirrealizations are different for the co-ordination ofnominal grOUpS, they are handled in a s;milar way.The system accommodates the perhaps urprisingfact that, in the case of nominal groups, there istypically one more intonation unit than therewould be commas.
As in the MOOD network,there is a greater number of delicate choicesre~_li~ed in intonation than there is in punctuation,So the feature \[spoken\] is again used as an entrycond i t ion  to the sys tem in the'CO ORDINATION SIT'network, toensure thatthe ~stera is not unread unless \[spoken\] has beenchosen.
Here the speaker chooses in the system of\ [unmarked  co ord inat ion  spoken\ ]  vs.Ice ordination with reservationS..
The first isrealised by a Irene 2 base-to-mid rme; Halliday'sTone 3), and the second by a Tone 12 (fall-rise;HaUiday's Toue 4),3.5.3.
Thematized Circumstances: Situations,Things, QualitiesAnother major source of additional intonationunits is the thematizatlon of time anddrcumstanee.
These meanings are realized inAdjuncts of various types.
They may occur invarious places ha the clause, and here we shallconsider just those that appear at the beginning ofa clause.
So far GENESYS includes eleven types,each of which may be realized by either a clauseor a group (three different classes of groups beingreco~ized: nominal, prepositional nd quantity-quall~ groups).
Note, theah that we have nowidenti~d a second major source of what has beentermed 'clause ?omb;ningL A similar approach isneeded for 'dame final' dames, i.e.
clauses thatfill any of the ecleven types of Adjunct built intoGENESYS so far, and that come late in theclause.
(This is a different approach to clause-combining from that in Halliday 198.5 and so fromthat in the Nigel grammar at ISI; here suchclauses are simply treated as embedded - so farwith gains in generalizations rather than losses.
)Let us take as an e~mple the concept of timeposition, which is one of five types of'circumstance of time' reco~niTed in GENF.SYS -the others being repetition, duration, periodicfrequency, and usuality.
While GENESYS willhappily generate dames such as "until he leavesthe company" to specify a time position, iu thecase of our example Ivy has chosen the simplerstructure of the prepositional group, i.e.
"until nextmonth".
The first system to consider is:'TIME POSITION TI-IEMATIZATION"->99%-~thematize-d timeposition (20.2) /i% thematizedJim'~ Ixffifion (20.3).Because the answer modifies the presuppositionsthat the Personnel Officer brought to his question(i.e.
that Peter Piper had a fixed address), Ivydecides to thematize the part of her reply thatexpresses this, i,e.
her specification of the 'timeposition'.
This is realized by placing the 'timeposition Adjunct' at an early place in the clause.
(Note that this is not a 'movement rule'; there areno such rules in this generator, and no element islocated until it can be located in its correct place.
)The next two systems are:169thematized time_position->80% tim~..pos~io a as separateinformation un iT / -20% time_.lXm"/ion as_part of maininformation unit.
- -  - - -spoken & time_position as separateinformation unit-> - -20% high!i~ted thcmatized time_position /S0% ~utnil3heTaatizccLti~ ix,/ition.The first of the two systems appfies whether ornot the MODE is spoken or written (the writtenrealization being a comma).
But the writingsystem cannot make the distinction offered in thesecond, so that here again the feature \[spoken\]from the erR|hal MODE system is used as anentry condition.
In our example Ivy chooses to resent the specification of the time position "nntil last week") as a separate information umt,and furthermore to klshlight it (by using a Tone12 (a fall-rise).But you may have noticed that these features haveno realization rules.
How, then, do these choicesget realized?
The answer is that these featuresact as condit ional features on the realization rulesfor the units that are generated, after re-entry tothe overall network, on a subsequent pass thoughit.
The reason for including the system at thersnk of situation is that in this way we can capturethe genexalisa6on that these options are relevantwhatever the unit - a clause or some kind ofgroup - that fills the Adjunct.In our case the sub-network that we fred ourselvesin on re-entry is the network for'MINIMAL RELATIONSHIP PLUS THING',i.e.
the netv~k from which prepositional groupsare generated.
Here we enter the followingsystem (where the suffix 'mrpt' echoes the nameof the overall system):location mrpt->place-mrpt (90.001) / time_mrpt (90.002).Here \[time..mrpt\] will be In'e-selected by thechoice at the higher rank.
The part of itsrealization rule concerned with intonation mayappear, once again, somewhat complex, but onceagain it seems to correspond to the relative (butalways limited) complexity of the facts of howEnglish works:90.002 : time_mrpt :if  (on_prev ious_passtime_position as separat?
information unitand on first_l~ass'spoken )-theni l l  current unit pgp then e < "\['9,if on prc'~ous passhighlighted_thematized time positionthen '12' by 'T ~,' if on_previous_passneutral thematized time_positionthen '2' by 'T.As you will see, these rules insert appropriateintonation boundaries and tones.
The tonic ('T')is already waiting in the starting structure of thetnepositional group, so that the rule ~;mplyconflates the actual tone with it.
Let us assumethat Ivy, in order to highlight still further thethematization f the words " month', selects thehighfighting rather than the neutral option.
(Thenominal group "next month" is generated by afurther e-entry.)
Finally, the system supplies theinitial intonation unit boundary for any unitwithout one.
If we assume that the rest of itemsgenerated (in components not considered in thispaper) are "he will be living at eleven RomillyCrescent, Canton" the full output for our exampleis:\] until next month/T/12 \[ he will be living ateleven Romilly Crescent/T/2 I Canton/NT/1 i3.5.4.
Other Sources of IntonationOther sources of intonation occur in specialistmini-grammars such as those for dates andaddresses.
These can be quite complex, and mayinsert several tonics, each with an appropriatetone.
Our worked example illustrates one suchcase: note the Tone 2 on "Crescent".
Yet othertypes will be included in the next version ofGENESY$, including (1) Adjuncts (which may befilled by clauses or groups) that are placed afterthe nuclear tonic of a clause and which carry'supplementary information', and (2) 'non-restrictive relative clauses' (i.e.
ones that carry,once again, 'supplementary information'),3.6.
Summary of the lexicogrammaticalgeneration of intonationWe have now completed a fairly fuU specificationof the major aspects of intonation included at thepresent stage of the development of theGENESYS model.To summarize: GENESYS offers the choice, onentering the first system that results in thegeneration of a scntenco, between \[written\] and\[spoken\].
The importance of this apparentlytrivial system is that the choice made in itdetermines whether or not one can go on to enterquite a number of more 'delicate' systems whosechoices are realized in intonation.
Its featuresalso act as conditions on the realization offeatures chosen in the same network, or in oneentered on a subsequent pass.
The result is thatthe realization at the level of form will be in170terms of either intonation or punctuation.
Wehave seen how choices in MOOD, inINFORMATION FOCUS and in various types of'status of informaBon' contribute together to thespecification ofintonation, and we have seen someof the details of how this can be implemented.The result is an integrated model that avoids thepsychologically implausible approach whereby onefirst generates a syntax tree and a string of wordsat its leave% and then 'adds on' the intonation.Instead, it treats intonation as one of three modesof re8i|Tation (the other two being syntax anditems),, generating the various aspects ofiatonatmn at appropriate points in the generationof syntax and items.R may be helpful to conclude by specifyingexplicitly the final stages of this process.
First thegenerator looks for a eontrastive tonic ('CT') withwhich to confiate the tone., and then, if there isn'tone, it provides as a default anuclear tonic ('NT')for the flail matrix clause, i.e.. the intonationalelement of structure with which the tone reollzln~the me a,; ,g of MOOD is conflated.
The otherintonation units specified by various types ofInformation status are fitted around this centralframework, receiving tones appropriate to theirstatus.
Where they are clauses these tones will beeonflated with a nuclear tonic (unless, of course,there is a contrastive tonic), and where they aregroups the tones will be conflated with a simpletonic A nuclear tonic is thus one that ispotentially capable of r0ceiviag the type of tonethat re~!i~,?s a MOOD option.
It should be madeclear that, in every case of the location of anuclear tonic or a simple tonic, the element withwhich it is conflated must be one that is notexponndcd by an item from the list of inherentlyweak items.
(Any such item may of course stillreceive a tonic by being contrastively stressed, asin l he has/C'r/t+ eaten it I.)4.
Conc lus ions4.1, Overall SummaryThe COMMUNAL project began with a hopethat it would be possible to take the insights froma Hatlidayan-Tenchian view of intonation, and todevelop a computational adaptation andimplementation f them.
A promising overallapproach to the problem has indeed beendeveloped; much of the resulting model has beenworked out in considerable detail; and many largeand significant portions have been implementedcomputationa!iy.
The framework has proved itselfto be adaptable when modifications are indicated,and there is good reason to hope that aspects notas yet worked out expficitly will prove to besolvable in the framework of the present model.There is, therefore, the exciting prospect hat,when our sister project gets under way andprovides the necessary complementarycomponents (no doubt with some requirements onus to adapt our outputs to their needs) we shatlbe in a position to offer a relatively full model ofspeech with diseoursally and semanticallymotivated Intonation.
It will.
moreover, be aprincipled model, and we hope that it will becapable of further extension and of fme.t, ni, g.We feel that the use of SFG.
and specifically ofthe type that separates clearly system networksand realization rules (as in GENESYS), gives usa facility that is sensitive to the need for bothextension and fine-t~m;-g. Above all, thecentrality in the model of choice betweensemantic features makes it a natural formalismfor relating the 'sentence grammar' to highercomponents in the overall model.4.2.
The General Prospect in NiX;Finally, let me turn to a more general point, happears that, incr~;ngly over the last few years,the focus of interest for many researchers in NLGhas switched from what we might term sentencegeneration to hi~her level planning (which I termdiscourse 8eneraflon).
It is here, one sometimeshears it said, that 'all the really interesting work'is being done.
Going implicitly with r hk eJ~im isthe assumption, which I have occasionally heardexpressed quite explicitly, that the major problemsof sentence generation have been solved.But is this really so?
While a lot of veryimpressive work has been done, and while somequite large generators have been built (e.g.
asreported in McDonald 1985, Mann andMathiessen 1985, Fawcett 1990), very many majorproblems remain unresolved.
Specifically, manyimportant aspects of 'sentence gr~rnrnar ~ emainoutside the scope of current generators.
Where,for e~mple, will we fmd a full description of asemanticaRy and/or pragmatically motivatedmodel of even such a wen-known syntacticphenomenon as the relative clause?
And whatabout comparative constructions (where even thelinguistics fiterature is weak)?
And there aremany, many more areas of the semantics andsyntax of sentences where our models are still farfrom adequate.
There are also many issues ofmodel construction regarding, for example, theoptimal division of labour between components,the outh'ni,g of which deserves a separate paper(or book).
And, even if we had models thatcovered all these and the many other areascompetently, we have hardly begun the process ofdeveloping adequate methods for the comparisonand evaluation of models.
Thus there is still anenormous amount of challenging and fascinating171work to do before we can say with any confidencethat we have an~hing like adequate sentencegenerators.
(A senior figure in German NLPch'des uggested atCOLING '88 that one can buygood sentence generators off the shelf.
It dependshow good 'good' is*.
)In this paper I have Ulustrated two crucial points:(1) that there are indeed significant areas oflanguage not yet adequately covered in currentgenerators, and (less dearly because I have had toomit the relevant section for reasons of space) (2)that the development of an adequate model ofthese depends on the eeaeerrent development ofdiscourse and sentence generators.Clearly, while there are in e~dstence a number offairly large sentence generators, we have in noway reached a situation where no further workneeds to be done.
I am aware, as the director ofa project hat seeks to provide rich coverage foras much of English as possible, that we have agreat deal of work still to do, and that this holdsfor the sentence generator component as weft asfor the discourse planning systems.
GE~qESYSalready has 50% more systems than the NIGEL(in the long established Pe~am~n Project; seeAppendix 1), but our rough estimate is that weneed to make it at least as large again before wehave an~hlng approaching full grammaticalcoverage.
And, of course, as everyone who haswrestled seriously with genuine natural languageknows, many tricky problems will remain eventhen.
Fmding anything like the 'right' solution tomany of these ~ require, I claim, models thathave developed, m dose interaction with eachother, their discourse planning and their sentencegeneration components and their beliefrelYresentation, including befiefs about theaddressee.AcknowledgementsThe research reported here was supported bygrants from RSRE Malvem under contract no.ER1/9/4/2181/23, by the University ResearchCouncil of International Computers Ltd, and byLongman.Appendix 1COMMUNAL is a major research project hatapplies and develops Systemic FunctionalGrammar (SFG) in a very large, fully workingcomputer program.
The acronym COMMUNALstands for COnvivial Man-MachineUnderstanding through NAtural Language.
Theprindples underlying the project are set out in172Fawcett 1988, and an illustration of a generationis presented inTucker 1989.
A fuller (but fairlyinformal) overall description., incl.uding somecomparison with other proiects, ts gtven iaFawcett 1990.
See also Fawcett (to appear).
Theproject is planned to last 5 years, with around 6researchers working on it.
We finished theSUccessful Phase I in 1989, and now (May 1990)are getting under way on Phase 2 The centralcomponent ofthe overall system is the generator,built at Cardiff.
This is called GENESYS(because it GE.NErates SYStemically).ConUdbutions from the University of Leeds inPhase 1 were to build (1) a derived probabilisti?parser, called the RAP (for Reafistie AnnealingParser, which develops earlier work at Leeds),and (2) the inte~reter (called REVELATION,because it reveals the 'meaning' from the'wozding').
Each of these is a major developmentia its field.
But because both buiM di~ealy on therelevant aspects of GFENESYS, we cancharacterise the coverage of the COMMUNALsystem as a whole in terms of the fxze ofGENESYS.Here is a quotation and a few facts to give you aperspective on COMMUNAL at the end of PhaseL McDonald, Vaughan and Pustejovsky(1987:179), in referring to the Penman project atthe University of S. California, say:.
'Nigel,Penman's grammar .... is the largest systemicgrammar and possibly the largest machinegrammar of any kind.'
Although theCOMMUNAL team developed GENESYScompletely independently, starting from scratchwith new system networks and handIingrealization i  a rather different way, GENESYSalready has many more systems than NigeL (Thisis not a criticism of Nigel; the research team havebeen working on other components of Penman).A major theoretical difference between the two isthat the networks in GENESYS are moreexplicitly oriented to semantics than in Nigel.
Wemake the assumption that the system networks inthe lexicogrammar are the semantic options.GENF_.SYS has around 600 semantic systemsrealized in grammar (syntax and morphology, andalso intonation and punctuation (see below), whileNigel has about 400 grammatical systems.
ButGENESYS additionally does something that thebuilders of Nigel would have liked to do, but fromwhich they have so far been prevented (by therequirement of a sponsor): it integrates systemnetworks for vocabulary with the networksrealized grammaticatly.
GENESYS is stillgrowing, so that in Phase 2 we estimate that it wiUmore than double the number of systems r?~liTedin syntax and grammatical items.
This shouldenable it to handle something approachingunrestricted syntax.
COMMUNAL's first majorachievement is therefore the size and scope ofG~YS.
The second must he seen in thewider framework of the model as a whole.
It hasbeen a long-standlng goal of ~ to build a largescale system that uses the same grammar toeither generate or interlmet a sentence.
(Manycurrent systems use a different grammar for eachprocess.)
The second major achievement is tohave performed this task with a very largegrammar - a Systemic l~mction~d Grammar.
inthis case.
(This will be the subject of a separatepaper in the future.)
A third achievement(though one less relevant in the present context)has been the development of a probabilisti?parsex by the Leeds part of the COMMUNAl.team.Append ix  2'Intonation' is a term susceptible to a wide rangeof interpretations.
It may therefore be useful tolist some major aspects of the complex task ofgenerating natural intonation that will not bediscussed here.
The first four are not coveredbecause they lie outside the current goals of theCOMMUNAL project, while the last two areomitted because they will be implemented (weexpect) by a sister project, support for which iscurrently being negotiated.1.
We shall not be concerned with the high levelpla, , i ,?
that will tailor the text to the needs ofthe addressee as affected by the e.ha,,~!
(e.g~ tobuild in greater redundancy, in the form ofrepetition of subject matter in planning what toexpress overtly, act by act).
(For the generalnotion of tailoring, see Paris 1988.)2.
We shall not discuss variation in intonatlonalcharacteristics of the sort that distingahh betweenspeakers of different dialects (geographical, socialclass, age, etc).3.
The same goes for individual variation, i.e.intonational idleleet.4.
We shall ignore the code of tone of voice('angry', 'conciliatory', 'delighted', etc).
At thesame tlme we recognize that it is an importantsemiotic system in its own right, and that in thelonger run the way ia which it is, as it were,superimposed onthe intonation systean itsdf mustbe modelled.
We recogniTe too the problems ofdrawing a firm line between tone of voice andsome of the quite delicate distinctions that weshall recognise in the MOOD system (c.f.Halliday% 1970 term 'key').5.
We shaft ignore any aspect of intonationalvariation that does not realize meaning.
Foreaample, it may be that speakers introducesemantically ,,-motivated variation into the pre-tonic segment of an intonation unit, in order toavoid monotony (of.
Hoase and Johnr.on 1987).
(An alternative hypothesis, of course, might bethat such variation is in fact semanticaUymotivated, but that we have not yet discoveredwhat aspects of meaning it correlates with andhow best to refer to it; this is a charaeterisrie ofmuch interpersonal me~-;-g,)6.
We shall not be concerned here with thephysical implementation f the output, but simply(if only it were ~;mpleI) with providing a writtenteat output marked appropriately for input to thesystem which will integrate it with the speechsynthesis representation of the segmentalphonology.ReferencesAllen, J.
(ed.)
From Text o Speech: the MITalkSystem.
Cambridge: Cambridge University Press.Benson, J,D., and Greaves, W.S., (eds.)
1985.Systemic perxpectives ondiscourse Vol 1: Selectedtheoretical papers from the Ninth InternationalSystemic Workshop.
Norwood, NJ., Ablex.Brady, M., and Berwick, R.C.
(eds), 1983.Computational models of discourse.
Cambridge,Mass: MIT Press,Fawcett, R.P., 1980.
Cognitive linguistics andsocial interaction: towards an int~'ated model of asystemic functional grammar and the othercomponents of an interacting mind.
Heidelberg:Julius Groos and Exeter University.Fawcett, R.P., 1988.
'Language generation aschoice in social interaction'.
In Zoc.k and Sabah(eds) 1988b, 27-49.Fawcett, R.P., 1990.
'The COMMUNAL Project:two years oH and going well'.
In Network No.
13.Fawcett, R.P., (to appear).
'A systemic functionalapproach to selectional restri~ons, roles andsemantic preferences'.
Accepted for MachineTtwtslalion.Fawcett, R.P., van der Mije, A,, and van Wissen,C., 1988.
'Towards asystemic flowchart model forlocal discourse structure', in Fawcett and Young1988, pp.
116-43.Fawcett, R.P., and Young, DJ., (eds.)
1988.
Newdevelopments in systemic lingui~'cs, Vol 2: Theoryand application.
London: Pinter.173Halliday, M.A.K., 1967.
Intonation and grammarin B?itish Englial~.
The Hague: Mouton.Halliday, M.A.K., 1970.
A ccgu,se in spokenEnglish: intonation.
London: Oxford UniversityPress.Laboratorio degli studi linguistici 1989/1.Camerino: Italy: Universita degli Studi diCamerino (pp.7-27).Zock, M., and Sabah, G. (eds) 1988a.
Advancesin natural anguage generation Vol 1.
London:Pinter.Halliday, M.A.K., 1985.
An introduction tofunctional grammar.
London: Arnold.Houghton, G. and Isard, S.D.,1987.
'Why to speak,what o say and how to say it: modelling languageproduction in discourse'.
In Morris 1987, pp.
112-30.Zoek, M., and Sabah, G., (ods) 1988b.
Advancesnatural language generation Vet 2.
London:Pinter.Houghton, G., and Pearson, M., 1988.
'Theproduction of spoken 4;~1ogueL In Zock andSabah 1988a, pp.
112-30.House, J.
& Johnson, M. (1987) 'Enfivening theintonation in Text-to-Speech Synthesis: an'Accent-Unlt' Model', Procs lit.it ICPhS, Tallian.Kempen, Gerard, (ed) 1987.
Natural languagegeneration.
Dordrecht: Ma~inu~ Nijhoff.Kobsa, A., and Wahlster, W.
(cds.)
User Models inDialogue Systems.
Berlin: Springer.Mann, W.C., and Matthiessen, C.MJ.M., 1983/85.
'A demonstration f the Nigel text generationcomputer program'.
In Ma_nn and Matthiessen1983 and in Benson and Grcav?~ 1985, pp.50-83.McDonald, D., 1983.
'Natural languagegeneration asa computational problem'.
In Bradyand Berwick 1983, pp.209-65.McDonald, D.D., Vaughan, M.M., andPustejovsky, J.D., 1987.
'Factors contributing toeffideacy in natural language generation'.
InKempen 1987, pp.
159-181.Morris, P., (ed.)
1987/.
Modelling cognition.Chichester: Wiley.Paris, C.L 'Tailoring object descriptions to auser's expertise'.
In Kobsa and Wahlqer 1988.Teach, P., 1987.
The ro/e.s ofintonation in Englishdiscourse.
PhD thesis, University of Wales.Teach, P., and Fawcett, R.P., 1988.
Specificationof intonation for Prototype Generator 2.
(COMMUNAL Report No 6) Cardiff:Computational Linguistics Unit, University ofWales CoUego f Cardiff.Tucker, G.H., 1989.
'Natural language generationwith a systemic functional gTa,-m~r'.
In173a
