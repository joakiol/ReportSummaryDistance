Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 252?261,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsAiding Pronoun Translation with Co-Reference ResolutionRonan Le Nagard and Philipp KoehnUniversity of EdinburghEdinburgh, United Kingdoms0678231@sms.ed.ac.uk, pkoehn@inf.ed.ac.ukAbstractWe propose a method to improve the trans-lation of pronouns by resolving their co-reference to prior mentions.
We report re-sults using two different co-reference res-olution methods and point to remainingchallenges.1 IntroductionWhile machine translation research has madegreat progress over the last years, including the in-creasing exploitation of linguistic annotation, theproblems are mainly framed as the translation ofisolated sentences.
This restriction of the task ig-nores several discourse-level problems, such as thetranslation of pronouns.Pronouns typically refer to earlier mention ofentities, and the nature of these entities may matterfor translation.
A glaring case is the translation ofthe English it and they into languages with gram-matical gender (as for instance, most Europeanlanguages).
If it refers to an object that has a malegrammatical gender in the target language, then itstranslation is a male pronoun (e.g., il in French),while referring to a female object requires a fe-male pronoun (e.g., elle in French).Figure 1 illustrates the problem.
Given a pair ofsentence such asThe window is open.
It is blue.the translation of it cannot be determined givenonly the sentence it occurs in.
It is essential thatwe connect it to the entity the window in the pre-vious sentence.Making such a connection between referencesto the same entity is called co-reference resolu-tion, or anaphora resolution.1 While this problem1In the context of pronouns, anaphora resolution and co-reference resolution are identical, but they differ in other con-texts.has motivated significant research in the field ofnatural language processing, the integration of co-reference resolution methods into machine transla-tion has been lacking.
The recent wave of work onstatistical machine translation has essentially notmoved beyond sentence-level and has not touchedco-reference resolution.Our approach to aiding pronoun translation withco-reference resolution can be outlined as follows.On both training and test data, we identify theanaphoric noun of each occurrence of it and theyon the source side (English).
We then identifythe noun?s translation into the target language (inour experiments, French), and identify the targetnoun?s grammatical gender.
Based on that gender,we replace it with it-masculine, it-feminine or it-neutral (ditto for they).
We train a statistical ma-chine translation system with a thusly annotatedcorpus and apply it to the annotated test sentences.Our experiments show some degree of suc-cess of the method, but also highlight that currentco-reference resolution methods (we implementedHobbs and Lappin/Laess) have not yet achievedsufficient performance to significantly reduce thenumber of errors in pronoun translation.2 Related Work2.1 Co-Reference and Machine TranslationThe problem of anaphora resolution applied to ma-chine translation has not been treated much in theliterature.
Although some papers refer to the prob-lem, their content is mostly concerned with theproblem of anaphora resolution and speak very lit-tle about the integration of such an algorithm in thebigger theme of machine translation.Mitkov et al [1995] deplore the lack of studyof the question and try to address it with the im-plementation of an anaphora resolution model andits integration into the CAT2 translation system[Sharp, 1988], a transfer system that uses an ab-252The window is open.
It is blue.
La fene?tre est ouverte.
Elle est bleue.
CORRECTThe window is open.
It is black.
La fene?tre est ouverte.
Il est noir.
WRONGThe oven is open.
It is new.
Le four est ouverte.
Elle est neuve.
WRONGThe door is open.
It is new.
La porte est ouverte.
Elle est neuve.
CORRECTFigure 1: Translation errors due to lack of co-reference resolution (created with Google Translate).stract intermediate representation.
The anaphoraresolution step adds additional features to the in-termediate representation.Leass and Schwall [1991] present a list of rulesto be implemented directly into the machine trans-lation system.
These rules seem to work mostlylike a dictionary and are checked in a priority or-der.
They state what should be the translation ofa pronoun in each special case.
Being specific tothe problem of translating anaphors into Korean,these are of little interest to our current work.2.2 Co-Reference : Syntactic MethodThe first work on the resolution of pronouns wasdone in the 1970s, largely based on a syntactic ap-proach.
This work was based on empirical dataand observations about natural languages.
For ex-ample, Winograd [1972] uses the notion of co-reference chains when stating that if a single pro-noun is used several times in a sentence or a groupof adjunct sentences, all instances of this pronounshould refer to the same entity.Others have also stated that antecedents of apronoun should be found in one of the n sen-tences preceding the pronouns, where n shouldbe small [Klapholz and Lockman, 1975].
Hobbs[1978] showed that this number was close to one,although no actual limit could be really imposed.In work by both Hobbs [1978] and Winograd[1972], the resolution of pronouns also involves asyntactic study of the parse tree of sentences.
Theorder with which candidate antecedents are prior-itized is similar in both studies.
They first look forthe antecedent to be a subject, then the direct ob-ject of a noun and finally an indirect object.
Onlythereafter previous sentences are checked for anantecedent, in no particular order, although the leftto right order seems to be preferred in the literatureas it implicitly preserves the order just mentioned.Winograd uses focus values of noun phrases insentences to choose the appropriate antecedent.Hobbs also refers to the work by Charniak[1972] and Wilks [1975] for the problem ofanaphora resolution.
However, they do not offer acomplete solution to the problem.
For this reasonHobbs [1978] is often considered to be the mostcomprehensive early syntactic study of the prob-lem, and as such, often used as a baseline to evalu-ate anaphora resolution methods.
We use his workand comment on it in a later section.Another approach to anaphora resolution isbased on the centering theory first proposed byGrosz et al [1995].
Brennan et al [1987] proposean algorithm for pronoun resolution based on cen-tering theory.
Once again, the entities are rankedaccording to their grammatical role, where subjectis more salient than existential constructs, whichare more salient than direct and indirect objects.Walker [1998] further improves the theory of cen-tering theory for anaphora resolution, proposingthe idea of cache model to replace the stack modeldescribed originally.Another syntactic approach to the problem ofco-reference resolution is the use of weightedfeatures by Lappin and Leass [1994] which wepresent in more details in a further section.
This al-gorithm is based on two modules, a syntactic filterfollowed by a system of salience weighting.
Thealgorithm gathers all potential noun phrase an-tecedents of a pronoun from the current and closeprevious sentences.
The syntactic filter then filtersout the ones that are unlikely to be antecedents, ac-cording to different rules, including general agree-ment rules.
The remaining candidate noun phrasesare weighted according to salience factors.
Theauthors demonstrate a higher success rate withtheir algorithm (86%) than with their implemen-tation of the Hobbs algorithm (82%).2.3 Co-Reference : Statistical ApproachMachine Learning has also been applied to theproblem of anaphora resolution.
Ng [2005] givesa survey of the research carried out in this area.The work by Aone and Bennett [1995] is amongthe first in this field.
It applies machine learning toanaphora resolution on Japanese text.
The authorsuse a set of 66 features, related to both the referentitself and to the relation between the referent and253its antecedent.
They include ?lexical (e.g.
cate-gory), syntactic (e.g.
grammatical role), semantic(e.g.
semantic class), and positional (e.g.
distancebetween anaphor and antecedent)?
information.Ge et al [1998] also present a statistical algo-rithm based on the study of statistical data in alarge corpus and the application of a naive Bayesmodel.
The authors report an accuracy rate of82.9%, or 84.2% with the addition of statisticaldata on gender categorization of words.In more recent work, Kehler et al [2004] showa move towards the use of common-sense knowl-edge to help the resolution of anaphors.
They usereferring probabilities taken from a large anno-tated corpus as a knowledge base.2.4 Shared Tasks and EvaluationAlthough a fairly large amount of research hasbeen done in the field, it is often reported [Mitkovet al, 1995] that there does not yet exist a methodto resolve pronouns which is entirely satisfactoryand effective.
Different kinds of texts (novel,newspaper,...) pose problems [Hobbs, 1978] andthe field is also victim of lack of standardization.Algorithms are evaluated on different texts andlarge annotated corpora with co-reference infor-mation is lacking to check results.
A response tothese problems came with the creation of sharedtasks, such as the MUC [Grishman and Sund-heim, 1996] which included a co-reference sub-task [Chinchor and Hirschmann, 1997] and led tothe creation of the MUC-6 and MUC-7 corpora.There are other annotation efforts worth men-tioning, such as the ARRAU corpus [Poesio andArtstein, 2008] which include texts from varioussources and deals with previous problems in an-notation such as anaphora ambiguity and anno-tation of information on agreement, grammaticalfunction and reference.
The Anaphoric Bank andthe Phrase Detectives are both part of the Anawikiproject [Poesio et al, 2008] and also promise thecreation of a standardized corpus.
The first one al-lows for the sharing of annotated corpora.
The sec-ond is a collaborative effort to annotate large cor-pora through the Web.
In its first year of use, thesystem saw the resolution of 700,000 pronouns.3 MethodThe method has two main aspects: the applicationof co-reference to annotate pronouns and the sub-sequent integration into statistical machine trans-lation.
We begin our description with the latteraspect.3.1 Integration into Machine TranslationEnglish pronouns such as it (and they) do nothave a unique French translation, but rather sev-eral words are potential translations.
Note that forsimplicity we comment here on the pronoun it, butthe same conclusions can be drawn from the studyof the plural pronoun they.In most cases, the translation ambiguity can-not be resolved in the context of a single sentencebecause the pronoun refers to an antecedent in aprevious sentence.
Statistical machine translationfocuses on single sentences and therefore cannotdeal with antecedents in previous sentences.
Ourapproach does not fundamentally change the sta-tistical machine translation approach, but treats thenecessary pronoun classification as a external task.Hence, the pronoun it is annotated, resultingin the three different surface forms presented tothe translation system: it-neutral, it-feminine, it-masculine.
These therefore encode the gender in-formation of the pronoun and each of them willbe match to its corresponding French translationin the translation table.An interesting point to note is the fact that thesepronouns only encode gender information aboutthe pronouns and omit number and person infor-mation.
This has two reasons.Firstly, study of the lexical translation table forthe baseline system shows that the probability ofhaving the singular pronoun it translated into theplural pronouns ils and elles is 10 times smallerthan the one for the singular/singular translationpair.
This means that the number of times a sin-gular pronoun in English translates into a pluralpronoun in French is negligible.The other reason to omit the cases when a sin-gular pronoun is translated into a plural pronoun isdue to the performance of our algorithm.
Indeed,the detection of number information in the algo-rithm is not good enough and returns many falseresults which would reduce the performance of thefinal system.
Also, adding the number agreementto the pronoun would mean a high segmentationbetween all the different possibilities, which weassumed would result in worse performance of thetranslation system.Once we have created a way to tag the pronounswith gender information, the system needs to learn254The  window  is open.It  is blue.La fen?tre est ouverte.It-feminine  is blue.FEMININE?
lexical resources?
annotation?
training: word alignment, test: translation mapping?
co-reference resolutionFigure 2: Overview of the process to annotate pronouns: The word it is connected to the antecedentwindow which was translated as fene?tre, a feminine noun.
Thus, the pronoun is annotated as it-feminine.the new probabilities that link the source languagepronoun to the target language pronouns.
That isall instances of it in the training data, which canbe found at any position in the corpus sentences,should be replaced by one of its three declension.However, it is important to stress that the genderinformation that should be encoded in the Englishcorpus is the one which corresponds to the genderof the French translation of the antecedent.In order to find the correct gender informationfor the pronoun, we execute the co-reference reso-lution algorithm on the English text which returnsthe antecedent of the pronoun (more on this in thenext section).
Note that we are not interested in theEnglish gender of the antecedent, but in gender ofits translation.Thus, we need to detect the French translationof the English antecedent.
For the training data,we rely on the word alignment that is produced asa by-product of the training of a statistical machinetranslation system.
For the test data, we rely onthe implicit word mapping performed during thetranslation process.Note that this requires in practice the translationof all preceding sentences before we can annotatethe current sentence.
To avoid this practical bur-den in our experiments, we simply use the map-ping in the baseline translation.
The performanceof the sentence alignment (88Once the French word is obtained, it is used asthe input of a module which returns the gender ofthe entity in French.
This is then used to replacethe original pronoun with the new gendered pro-noun.The entire process is illustrated in Figure 2.3.2 The Hobbs AlgorithmThe Hobbs algorithm is considered to be the base-line algorithm for co-reference resolution.
The al-gorithm uses the syntactic parse tree of the sen-tences as input.The algorithm traverses the parse tree and se-lects appropriate candidate referents to the pro-noun.
It goes up sentence nodes and checks allNP nodes encountered for agreement with the pro-noun.
The order in which the algorithm traversesthe tree ensures that some priorities are respected,to make sure the most probable antecedent is re-turned first.
By doing this, the algorithm tendsto enforces some of the constraints that apply toco-reference [Jurafsky et al, 2000].
The recencyconstraint is enforced thanks to the order in whichthe algorithm traverses the sentences and both thebinding and grammatical role constraints are en-forced by the use of the syntactic tree and Part-Of-Speech tags on the words.Because the algorithm only uses the parse treeof the sentences, the semantic meaning of wordsis completely omitted in the process of select-ing candidate antecedents and no knowledge isrequired except for the implicit knowledge con-tained within agreement features.As mentioned earlier, the Hobbs algorithm goesup the tree from the given pronoun to the top of thetree and stops at each sentence or noun node on itsway.
In each of these nodes, it performs breadthfirst search of the sub tree and returns any nounphrase node encountered as a potential antecedent.If the antecedent is genuine (according to gender,number, and person agreement), it is returned.255In case no antecedent was found in the currentsentence, the algorithm goes back up in the text,looking at each sentence separately, in a left-to-right breadth first fashion.
This ensures that thesubject/object/indirect object priorities and hierar-chy are respected.
Again, if a candidate NP hasmatching agreement features, it is returned as theantecedent of the pronoun.
Otherwise the algo-rithm goes one sentence higher.The original algorithm uses limited knowledgebecause it assumes that:?
Dates do not move.?
Places do not move.?
Large fixed objects don?t move.This add limited semantic restrictions for the an-tecedent chosen.
Indeed, if the pronoun is fol-lowed by a motion verb, the antecedent could notbe a date, a place or a large fixed object.
However,as Hobbs states himself, those constraints help lit-tle since they do not apply in most cases.3.3 The Lappin and Leass AlgorithmLappin and Leass [1994] proposed an anaphoraresolution algorithm for third person pronouns andlexical anaphors.
It is based on slot grammar anduses syntax combined with a system of weightsto select the appropriate antecedent of a pronoun.The implementation of the algorithm we deal withhere is fairly different from the one presented inthe original paper, and is largely inspired from theJavaRAP implementation [Qiu et al, 2004].The first important variation was mentioned ear-lier and concerns the application of co-referenceresolution to machine translation.
We concen-trate in this work on the resolution of third per-son pronouns, and we omit reflexive pronouns (it-self, themselves) (referred to as lexical anaphora insome works).Another variation comes from the use of theCollins parser [Collins, 2003].
Although work onthe original algorithm uses McCord?s Slot Gram-mar parser [McCord, 1990], work on JavaRAPshows that rules can be created to simulate the cat-egories and predicates used in slot grammar.
Also,Preiss [2002] evaluates the use of different parsersfor the Lappin and Leass algorithm, showing thatperformance of the algorithm is not related to theperformance of the parser itself.
The JavaRAP im-plementation uses a Charniak parser, which per-forms worse than the Collins parser in Preiss?
re-search.For these reasons and in order to allow for reuseof the code used previously in the implementationof the Hobbs algorithm, the input to the Lappinand Leass algorithm is text parsed with the Collinsparser.It should be noted that the Lappin and Le-ass algorithm (also called RAP for Resolution ofAnaphora Procedure) has been used in the originalresearch for the application of machine translation.The algorithm processes sentence by sentence,keeping in memory the information regarding thelast four sentences.
In the first step of the algo-rithm, all noun phrases (NPs) are extracted andclassified.
Definite and indefinite NPs are sep-arated, and pleonastic pronouns are segregatedfrom other pronouns.The notion of salience is very important inRAP, as it allows the algorithm to choose betweencompeting NPs.
All candidate NPs are given a?salience weighting?, which represents the impor-tance and visibility of the phrase in the sentence,and in relation to the pronoun that is being re-solved.Salience weighting is based on the syntacticform of the sentence and the value for an NP iscalculated through the contribution, or not, of dif-ferent salience factors, to which weights are asso-ciated.
This calculation ensures that different im-portance will be given to a subject noun phrase ina sentence, and a noun phrase that is embedded inanother or that represents the indirect object of averb.There are a number of salience factors suchas sentence recency, subject emphasis, existentialemphasis, accusative emphasis, etc.
Each factor isassociated with a predefined weight.Once the weight of each candidate has been cal-culated, the algorithm uses syntactic informationto filter out the noun phrases that the pronoun isunlikely to refer to.
This includes agreement andother checks.The list of candidate NPs obtained after thisprocessing is then cleared of all NPs that fall un-der a given threshold.
The original algorithm thendeals with singular and plural pronouns in differ-ent ways.
The JavaRAP implementation howeverdoes not use these differences and we refer thereader to Lappin and Leass?
paper for further in-formation.Finally, the candidate NPs mentioned in the pre-vious list are ranked according to their salience256weights and the highest scoring one is returned asthe antecedent of the pronoun.
In case several NPshave the same salience weight, the one closest tothe pronoun is returned.3.4 Pleonastic ItEnglish makes an extensive use of the pronoun itin a pleonastic fashion.
That is, many times, it isconsidered to be structural and does not refer toany entity previously mentioned.
The followingare examples of pleonastic uses of it:?
It is raining.?
It seems important that I see him.?
The session is opened, it was announced.Being able to discriminate the use of a struc-tural it from the use of a referential use of it isvery important for the success of the co-referencealgorithm.
Indeed, resolving a pleonastic it willbe a waste of time for the algorithm, and more im-portantly, it will increase the chance of errors andwill result in poorer performances.
Moreover, thepleonastic it is most times translated masculine inFrench, meaning any other resolution by the algo-rithm will yield errors.In the past, the importance given to the detec-tion of the pleonastic use of it has varied from au-thor to author.
As an example, Rush et al [1971],in their work on automatic summarization, onlymentioned the problem.
Others formed a set ofrules to detect them, such as Liddy et al [1987]with 142 rules, or Lappin and Leass [1994] whopropose a very restricted set of rules for the detec-tion of the structural it.Paice and Husk [1987] carried out extensive re-search on the topic and their paper defines variouscategories for the pronoun it as well as proposinga set of rules that allow to differentiate when thepronoun it is used as a relational pronoun or as apleonastic pronoun.Their method categorise words according to thepresence of given words around the pronoun it.They distinguish constructs such as it VERB STA-TUS to TASK ; construct expressing doubt contain-ing words such as whether, if, how ; parentheticalit such as it seems, it was said.
The original arti-cle identifies seven categories for pleonastic pro-nouns.Since their own results showed a success rateof 92.2% on a test section of the LOBC corpusand the implementation of their technique yieldsresults similar to the implementation of a machinelearning technique, this method seemed appropri-ate for our purpose.4 ExperimentsIn this section, we comment on the tools used forthe implementation of the algorithms, as well assupport tools and corpora.The implementation of both of the algorithmswas done using the Python programming lan-guage, which was chosen for its simplicity in pro-cessing text files and because it is the language inwhich the Natural Language Toolkit is developed.The Natural Language Toolkit (NLTK) is a suiteof Python modules used for research into naturallanguage processing.
We mostly used its Tree andParentedTree modules which enable the represen-tation of parse trees into tree structures.
NLTKalso includes a naive Bayes classifier, which weused in association with the names corpus in orderto classify proper names into gender categories ac-cording to a set of features.
We also use NLTK forits named entity capacities, in order to find ani-macity information of entities.English sentences were annotated with the MX-POST Part of Speech tagger and the Collins syn-tactic parser.The Lefff lexicon, introduced by Sagot et al[2006] was used to get agreement features ofFrench words.
It contains over 80,000 Frenchwords,2 along with gender and number informa-tion.We used the open source Moses toolkit [Koehnet al, 2007] and trained standard phrase-basedtranslation models.As training data, we used the Europarl corpus[Koehn, 2005], a commonly used parallel corpusin statistical machine translation research.
Whilethere are also commonly used Europarl test sets,these do not contain sentences in sequence forcomplete documents.
Instead, we used as test setthe proceedings from October 5, 2000 - a set of1742 sentences from the held-out portion of thecorpus.
We translated the test set both with a base-line system and a system trained on the annotatedtraining data and tested on an annotated test set.2The original version version of the lexicon is availablefrom http://www.labri.fr/perso/clement/lefff/.257Word CountEnglish singular he 17,181she 4,575it 214,047French singular il 187,921elle 45,682English plural they 54,776French plural ils 32,350elles 16,238Table 1: Number of sentences in the training cor-pus containing third person personal pronouns.Truth MethodPleonastic ReferentialPleonastic 42 20Referential 19 98Table 2: Detection of pleonastic pronouns5 Results5.1 Corpus Statistics for PronounsPersonal pronouns are among the most frequentwords in text.
In the training corpus of 1,393,452sentences, about a 6th contain third person per-sonal pronouns.
See Table 1 for detailed statistics.The English pronoun it is much more frequentthan he or she.
For both languages, the masculineforms are more frequent than the feminine forms.There are then a total of 233,603 sentences con-taining a third person pronoun in French, and235,803 sentences containing a third person pro-noun in English.
This means that over 2,000of those pronouns in English do not have equiv-alent in French.
Similarly for plural: A totalof 48,588 sentences contain a plural pronoun inFrench, against 54,776 in English.
That shows thatover 6,000 of the English ones are not translatedinto French.5.2 Detection of the Pleonastic itWe checked, how well our method for pleonas-tic it detection works on a section of the test set.We achieved both recall and precision of 83% forthe categorization of the referential it.
For details,please see Table 2.5.3 Translation ProbabilitiesLet us now examine the translation probabilitiesfor the annotated and un-annotated pronouns.
De-tails are given in Table 3.correct annotation 33/59 56%correct translation:annotated 40/59 68%correctly annotated 27/33 82%baseline 41/59 69%Table 4: Translation Results: On a manually ex-amined portion of the test set, only 33 of 59 pro-nouns are labeled correctly.
The translation resultsof our method does not differ significantly fromthe baseline.
Most of the correctly annotated pro-nouns are translated correctly.In the baseline system, both it and they havea strong translation preference for the masculineover the feminine form of the French pronoun.It translates with probability 0.307 to il and withprobability 0.090 to elle.
The rest of the probabil-ity mass is taken up by the NULL token, punctua-tion, and a long tail of unlikely choices.For both the Hobbs and the Lappin/Laess algo-rithm, the probability distribution is shifted to thedesired French pronoun.
The shift is strongest forthe masculine marked they, which prefers the mas-culine ils with 0.431 over the feminine elles with0.053 (numbers for Hobbs, Lappin/Laess numbersare 0.435 and 0.054, respectively).Feminine marked pronouns now slightly preferfeminine French forms, overcoming the originalbias.
The neutrally marked pronouns shift slightlyin favor of masculine translations.The pronoun they-neutral appears in 12,424sentences in the corpus, which all represent failedresolution of the co-reference.
Indeed, Frenchdoes not have neutral gender and the plural thirdperson pronoun is never pleonastic.
These resultstherefore show that a lot of noise is added to thesystem.5.4 Translation ResultsThe BLEU scores for our method is almost iden-tical to the baseline performance.
This is not sur-prising, since we only expect to change the transla-tion of a small number of words (however, impor-tant words for understanding the meaning of thetext).A better evaluation metric is the number of cor-rectly translated pronouns.
This requires manualinspection of the translation results.
Results aregiven in Table 4.While the shift of the translation probabilities258Unannotated Hobbs Lappin and LaessEnglish French p English French p English French pit il 0.307 it-neutral il 0.369 it-neutral il 0.372it elle 0.090 it-neutral elle 0.065 it-neutral elle 0.064it-masculine il 0.230 it-masculine il 0.211it-masculine elle 0.060 it-masculine elle 0.051it-feminine il 0.144 it-feminine il 0.142it-feminine elle 0.168 it-feminine elle 0.156they ils 0.341 they-neutral ils 0.344 they-neutral ils 0.354they elles 0.130 they-neutral elles 0.102 they-neutral elles 0.090they-masc.
ils 0.435 they-masc.
ils 0.431they-masc.
elles 0.053 they-masc.
elles 0.054they-feminine ils 0.208 they-feminine ils 0.207they-feminine elles 0.259 they-feminine elles 0.255Table 3: Translation probabilities.
The probabilities of gender-marked pronouns are shifted to thecorresponding gender in the two cases the text was annotated with the co-reference resolution methodsmentionned earlier.suggests that we are moving the translation of pro-nouns in the right direction, this is not reflected bythe sample of pronoun translations we inspected.In fact, the performance for our method is almostidentical to the baseline (68% and 69%, respec-tively).One cause for this is the poor performanceof the co-reference resolution method, which la-bels only 56% of pronouns correctly.
On thissub-sample of correctly annotated pronouns, weachieve 82% correct translations.
However, thebaseline method also performs well on this subset.6 ConclusionWe presented a method to aid pronoun transla-tion for statistical machine translation by using co-reference resolution.
This is to our knowledge thefirst such work.While our method works in principle, the re-sults are not yet convincing.
The main problemis the low performance of the co-reference resolu-tion algorithm we used.
The method works wellwhen the co-reference resolution algorithm pro-vides correct results.Future work should concentrate on better co-reference algorithms.
The context of machinetranslation also provides an interesting testbed forsuch algorithms, since it offers standard test setsfor many language pairs.7 AcknowledgementsThis work was supported by the EuroMatrixPlusproject funded by the European Commission (7thFramework Programme).ReferencesC.
Aone and S.W.
Bennett.
Evaluating automatedand manual acquisition of anaphora resolutionstrategies.
In Proceedings of the 33rd annualmeeting on Association for Computational Lin-guistics, pages 122?129.
Association for Com-putational Linguistics Morristown, NJ, USA,1995.S.
E. Brennan, M. W. Friedman, and C. J. Pollard.A centering approach to pronouns.
In Proceed-ings of the 25th annual meeting on Associationfor Computational Linguistics, pages 155?162,1987.E.
Charniak.
Toward a model of children?s storycomprehension.
MIT, 1972.N.
Chinchor and L. Hirschmann.
MUC-7 corefer-ence task definition, version 3.0.
In Proceedingsof MUC, volume 7, 1997.M.
Collins.
Head-driven statistical models for nat-ural language parsing.
Computational Linguis-tics, 29(4):589?637, 2003.N.
Ge, J. Hale, and E. Charniak.
A statistical ap-proach to anaphora resolution.
In Proceedingsof the Sixth Workshop on Very Large Corpora,pages 161?170, 1998.259R.
Grishman and B. Sundheim.
Message un-derstanding conference-6: A brief history.
InProceedings of the 16th conference on Com-putational Linguistics-Volume 1, pages 466?471.
Association for Computational LinguisticsMorristown, NJ, USA, 1996.B.
J. Grosz, S. Weinstein, and A. K. Joshi.
Center-ing: A framework for modeling the local coher-ence of discourse.
Computational Linguistics,21(2):203?225, 1995.J.
R. Hobbs.
Resolving Pronoun References.
Lin-gua, 44:339?352, 1978.D.
Jurafsky, J. H. Martin, A. Kehler, K. Van-der Linden, and N. Ward.
Speech and languageprocessing.
Prentice Hall New York, 2000.A.
Kehler, D. Appelt, L. Taylor, and A. Simma.The (non) utility of predicate-argument fre-quencies for pronoun interpretation.
In Proc.
ofHLT-NAACL, volume 4, pages 289?296, 2004.D.
Klapholz and A. Lockman.
Contextual refer-ence resolution.
American Journal of Compu-tational Linguistics, microfiche 36, 1975.Philipp Koehn.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedingsof the Tenth Machine Translation Summit (MTSummit X), Phuket, Thailand, September 2005.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico,Nicola Bertoldi, Brooke Cowan, Wade Shen,Christine Moran, Richard Zens, Christopher J.Dyer, Ondr?ej Bojar, Alexandra Constantin,and Evan Herbst.
Moses: Open source toolkitfor statistical machine translation.
In Pro-ceedings of the 45th Annual Meeting of theAssociation for Computational LinguisticsCompanion Volume Proceedings of the Demoand Poster Sessions, pages 177?180, Prague,Czech Republic, June 2007.
Association forComputational Linguistics.S.
Lappin and H.J.
Leass.
An algorithm forpronominal anaphora resolution.
Computa-tional Linguistics, 20(4):561, 1994.Herbert Leass and Ulrike Schwall.
An AnaphoraResolution Procedure for Machine Translation.Technical Report Report 172, IBM GermanyScience Center, Institute for Knowledge BasedSystems, 1991.E.
Liddy, S. Bonzi, J. Katzer, and E. Oddy.
Astudy of discourse anaphora in scientific ab-stracts.
Journal of the American Society for In-formation Science, 38(4):255?261, 1987.Michael C. McCord.
Slot grammar: A systemfor simpler construction of practical natural lan-guage grammars.
In Proceedings of the In-ternational Symposium on Natural Languageand Logic, pages 118?145, London, UK, 1990.Springer-Verlag.
ISBN 3-540-53082-7.R.
Mitkov, S. K. Choi, and R. Sharp.
Anaphoraresolution in Machine Translation.
In Proceed-ings of the Sixth International Conference onTheoretical and Methodological Issues in Ma-chine Translation, TMI?95, 1995.V.
Ng.
Machine learning for coreference resolu-tion: From local classification to global rank-ing.
In Proceedings of the 43rd Annual Meetingon Association for Computational Linguistics,page 164.
Association for Computational Lin-guistics, 2005.C.
D. Paice and G. D. Husk.
Towards the auto-matic recognition of anaphoric features in En-glish text: the impersonal pronoun.
ComputerSpeech & Language, 2(2):109?132, 1987.M.
Poesio and R. Artstein.
Anaphoric annotationin the ARRAU corpus.
In Proceedings of the In-ternational Conference on Language Resourcesand Evaluation (LREC), 2008.M.
Poesio, U. Kruschwitz, and J. Chamberlain.ANAWIKI: Creating anaphorically annotatedresources through Web cooperation.
In Pro-ceedings of the International Conference onLanguage Resources and Evaluation (LREC),volume 8.
Citeseer, 2008.Judita Preiss.
Choosing a parser for anaphora reso-lution.
In 4th Discourse Anaphora and AnaphorResolution Colloquium (DAARC), pages 175?180.
Edi co?es Colibri, 2002.Long Qiu, Min yen Kan, and Tat seng Chua.A public reference implementation of the rapanaphora resolution algorithm.
In Proceedingsof the International Conference on LanguageResources and Evaluation (LREC), pages 291?294, 2004.J.
E. Rush, R. Salvador, and A. Zamora.
Auto-matic abstracting and indexing.
II.
Productionof indicative abstracts by application of contex-tual inference and syntactic coherence criteria.Journal of the American Society for InformationScience and Technology, 22(4):260?274, 1971.260B.
Sagot, L. Cle?ment, E. V. de La Clergerie, andP.
Boullier.
The Lefff 2 syntactic lexicon forFrench: architecture, acquisition, use.
In Pro-ceedings of the International Conference onLanguage Resources and Evaluation (LREC),2006.Randall Sharp.
CAT2 ?
implementing a formal-ism for multi-lingual MT.
In 2nd InternationalConference on Theoretical and MethodologicalIssues in Machine Translation of Natural Lan-guage, pages 3?6, 1988.M.
A. Walker.
Centering, anaphora resolution, anddiscourse structure.
Centering theory in dis-course, pages 401?435, 1998.Y.
Wilks.
A preferential, pattern-seeking, seman-tics for natural language inference.
Words andIntelligence I, pages 83?102, 1975.T.
Winograd.
Understanding natural language.Cognitive Psychology, 3(1):1?191, 1972.261
