A LOGICAL  SEMANTICSFOR NONMONOTONIC  SORTSAbst ractSuppose we have a feature system, and we wishto add default values in a well-defined way.
Wemight start with Kasper-Rounds logic, and useReiter's example to form it into a default logic.Giving a node a default value would be equiv-alent to saying "if it is consistent for this nodeto have that value, then it does."
Then wecould use default theories to describe featurestructures.
The particular feature structuredescribed would be the structure that supportsthe extension of the default theory.
This is, ineffect, what the theory of nonmonotonic sortsgives you.
This paper describes how that the-ory derives from what is described above.Mark  A .
Young &~ B i l l  RoundsArt i f ic ia l  In te l l igence  LaboratoryThe  Un ivers i ty  of  M ich igan1101 Bea l  Ave.Ann  Arbor ,  M I  48109marky, rounds?engin, umich, eduThe original presentation of nonmonotonic sortsprovided only a description of their operation andan informal description of their meaning.
In thispaper, we present a logical basis for NSs and non-monotonically sorted feature structures (NSFSs).NSFSs are shown to be equivalent to default theo-ries of default logic (Reiter 1980).
In particular, weshow how nonmonotonic sort unification is equiv-alent to finding the smallest default theory thatdescribes both NSFSs; and also how taking a solu-tion for a NSFS is the same as finding an extensionfor that theory.INTRODUCTIONThere have been many suggestions for incorporat-ing defaults into unification-based grammar for-malisms (Bouma 1990; Bouma 1992; Carpenter1991; Kaplan 1987; Russell et al 1992; Shieber1986; Shieber 1987).
Each of these proposes anon-commutative, non-associative default unifica-tion operation that combines one structure repre-senting strict information with another epresent-ing default information.
When presented with aset of structures, the result depends on the order inwhich the structures are combined.
This runs verymuch against he unification tradition, in which anyset has a unique most general satisfier (if a satisfierexists at all).A method that is free of these ordering effectswas presented in (Young 1992).
The method ofnonmonotonic sorts (NSs) allows default labels tobe assigned at any time, and used only in the ab-sence of conflicting information.
NSs replace themore traditional labels on feature structures to givenonmonotonically sorted feature structures (NS-FSs).
These structures can be combined by an asso-ciative and commutative unification operation.
FSsare rederived from NSFSs by taking a solution--anoperation defined in terms of information presentin the NSFS.FEATURE SYSTEMSUnification-based grammar formalisms use formalobjects called feature structures to encode linguis-tic information.
We use a variant of the standarddefinition.
Each structure has a sort (drawn froma finite set 8), and a (possibly empty) set of at-tributes (drawn from a finite set ~).Def in i t ion1  A feature structure is a tuple(Q, r, 6, O) where?
Q is a finite set of nodes,?
r E Q is the root node,?
6 : QxY  r ---+ Q is a partial feature value functionthat gives the edges and their labels, and?
(9 : Q ~ S is a sorting function that gives thelabels of the nodes.This structure must be connected.It is not unusual to require that these structuresalso be acyclic.
For some systems O is defined onlyfor sink nodes (PATR-II, for example).
Fig.
1 showsa standard textual representation for a FS.We sometimes want to refer to substructures of aFS.
If .A is a feature structure as described above,we write .A / f  for the feature structure rooted at6(q, f) .
This feature structure is defined by Q~ c_ Q,the set of nodes that can be reached from 6(r, f) .We will use the letter p (possibly subscripted) torepresent paths (that is, finite sequences from .T'*).We will also extend ~ to have paths in its second209<subj agr person> isa 3rd<subj agr number> isa singular<subj agr> = <pred agr><pred actor> = <subj><pred rep> isa sleep<pred tense> isa presentFigure 1: Textual Feature Structure: "Uthersleeps.
"TRUEFALSEa where a E Spl -" P2 where each Pi E J~*f : ?
where f E ~- and ?
E FML?^?
?v?Figure 2: SFML: the domain of sorted logical for-mulas.1.
A2.
A3 .
.44 .
,45.
A6.
A7 .
.4position, with the notion of iterated application of5.We will assume that there is a partial order, -~,defined on S. This ordering is such that the great-est lower bound of any two sorts is unique, if itexists.
In other words, (S U {_1_}, -q) is a meet-semilattice (where _l_ represents inconsistency orfailure).
This allows us to define the most generalunifier of two sorts as their greatest lower bound,which write as aAsb.
We also assume that there isa most general sort, T, called top.
The structure(S, -g) is called the sort hierarchy.KASPER-ROUNDS LOGIC(Kasper 1988) provides a logic for describing fea-ture structures.
Fig.
2 shows the domain of theselogical formulas.
We use the standard notion ofsatisfaction.
Let A = (Q, r, 5, O).= TRUE always;- FALSE never;=a~O(r )__ .a ;=pl  --'p~ -:-, > 5(r, pl) = 5(r,p~);= f : ?
?=~ A/ f  is defined and A/ f  ~ ?
;= ?A?
?===~ A ~ ?
and .A ~ ?
;= ?
V?
?---~ A ~?orA~?Note that item 3 is different han Kasper's originalformulation.
Kasper was working with a flat sorthierarchy and a version of FSs that allowed sortsonly on sink nodes.
The revised version allows fororder-sorted hierarchies and internal sorted nodes.NONMONOTONIC  SORTSFigure 3 shows a lexical inheritance hierarchy fora subset of German verbs.
The hierarchy specifiesVERB template<past tense suffix> default +te<past participle prefix> isa ge+<past participle suffix> default +tspiel lex VERBMIDDLE-VERB template VERB<past participle suffix> isa +enmahl lex MIDDLE-VERBSTRONG-VERB template MIDDLE-VERB<past ense suffix> isa 0zwing lex STRONG-VERB<past tense stem> isa zwang<past participle stem> isa zwungFigure 3: Example Lexicon with Defaultsstrict (isa) and default (default) values for varioussuffixes.
If we ignore the difference between strictand default values, we find that the informationspecified for the past participle of mahl is inconsis-tent.
The MIDDLE-VERB template gives +en asthe suffix, while VERB gives +t.
The declarationof the latter as a default tells the system that itshould be dropped in favour of the former.
Themethod of nonmonotonic sorts formalizes this no-tion of separating strict from default information.Def in i t ion  2 A nonmonotonic sort is a pair (s, A /where s E S, and A C S such that for each d E A,d-4 s.The first element, s, represents the strict informa-tion.
The default sorts are gathered together in A.We write Af for the set of nonmonotonic sorts.Given a pair of nonmonotonic sorts, we can unifythem to get a third NS that represents their com-bined information.Def in i t ion  3 The nonmonotonic sort unifier ofnonmonotonic sorts (s l ,Az)  and (s2,As) is thenonmonotonic sort (s, A) where?
S ~ 81Ass2 ,  and?
A = {dAss I d E Az U A2 A (dAss) -~ s}.The nonmonotonic sort unifier is undefined ifsaAss2 is undefined.
We write nzA~n2 for the NSunifier of nl and n2.The method strengthens consistent defaults whileeliminating redundant and inconsistent ones.
Itshould be clear from this definition that NS unifica-tion is both commutative and associative.
Thus wemay speak of the NS unifier of a set of NSs, with-out regard to the order those NSs appear.
Lookingback to our German verbs example, the past par-ticiple suffix in VERB is (T, {+t}), while that ofMIDDLE-VERB is (+en, {}).
The lexical entry formahl gets their nonmonotonic sort unifier, which is(+en, {}).
If +tAs+en had been defined, and equal210to, say, +ten, then the NS unifier of (T, {+t}) and(+en, {}) would have been (+an, {+ten}}.Once we have nonmonotonic sorts, we can createnonmonotonically sorted feature structures (NS-FSs) by replacing the function 0 : Q ~ S by afunction ~ : Q ~ Af.
The nodes of the graphare thus labeled by NSs instead of the usual sorts.NSFSs may be unified by the same procedures asbefore, only replacing sort unification at the nodeswith nonmonotonic sort unification.
NSFS unifi-cation, written with the symbol rlN, is associativeand commutative.NSFSs allow us to carry around default sorts, buthas so far given us no way to apply them.
Whenwe are done collecting information, we will wantto return to the original system of FSs, using alland only the applicable defaults.
To do that, weintroduce the notions of explanation and solution.Def in i t ion  4 A sort t is said to be explained by anonmonotonic sort (s,A} if there is a D C A suchthat t = S^s(AsD) .
I f  t is a maximally specificexplained sort, lhen ~ is called a solution of n.The solutions for {+en, {)) and {T, {+t}) are +enand +t respectively.
The latter NS also explains T.Note that, while D is maximal, it's not necessar-ily the case that D = A.
If we have mutually incon-sistent defaults in A, then we will have more thanone maximal consistent set of defaults, and thusmore than one solution.
On the other hand, strictinformation can eliminate defaults during unifica-tion.
That  means that a particular template caninherit conflicting defaults and still have a uniquesolution--provided that enough strict informationis given to disambiguate.NSFS solutions are defined in much the same wayas NS solutions.Def in i t ion 5 A FS (Q,r,~,O) is said to be ex-plained by a NSFS (Q,r, 8, Q) if for each nodeq E Q we have ~2(q) explains O(q).
If.A is a max-imally specific explained FS, then A is called a so-lution.If  we look again at our German verbs example, wecan see that the solution we get for mahl is the FSthat we want.
The inconsistent default suffix +thas been eliminated by the strict +en, and the soleremaining default must be applied.For the generic way we have defined featurestructures, a NSFS solution can be obtained sim-ply by taking NS solutions at each node.
Morerestricted versions of FSs may require more care.For instance, if sorts are not allowed on internalnodes, then defining an attribute for a node willeliminate any default sorts assigned to that node.Another example where care must be taken is withtyped feature structures (Carpenter 1992).
Herethe application of a default at one node can addstrict information at another (possibly making adefault at the other node inconsistent).
The defini-tion of NSFS solution handles both of these cases(and others) by requiring that the solution be aFS as the original system defines them.
In bothof these cases, however, the work can be (at leastpartially) delegated to the unification routine (inthe former by Mlowing labels with only defaultsto be removed when attributes are defined, and inthe latter by propagating type restrictions on strictsorts).What is done in other systems in one step hasbeen here broken into two steps--gathering infor-mation and taking a solution.
It is important hatthe second step be carried out appropriately, sinceit re-introduces the nonmonotonicity that we'vetaken out of the first step.
For a lexicon, templatesexist in order to organize information about words.Thus it is appropriate to take the solution of a lex-ical entry (which corresponds to a word) but not ofa higher template (which does not).
If the lexiconwere queried for the lexical entry for mahl, then, itwould collect the information from all appropriatetemplates using NSFS unification, and return thesolution of that NSFS as the result.DEFAULT LOGICThe semantics for nonmonotonic sorts is motivatedby default logic (Reiter 1980).
What  we want adefault sort to mean is: "if it is consistent for thisnode to have that sort, then it does."
But whereReiter based his DL on a first order language, wewant to base ours on Kasper-P~ounds logic.
Thiswill require some minor alterations to lZeiter's for-malism.A default theory is a pair (D, W) where D is aset of default inferences and W is a set of sentencesfrom the underlying logic.
The default inferencesare triples, written in the form~:MpEach of the greek letters here represents a wff fromthe logic.
The meaning of the default inference isthat if ~ is believed and it is consistent o assumet5, then 7 can be believed.Given a default theory (D, W), we are interestedin knowing what can we believe.
Such a set of be-liefs, cMled an extension, is a closure of W underthe usual rules of inference combined with the de-fault rules of inference given in D. An extensionE is a minimal closed set containing W and suchthat if c~ :M f l /7 is a default, and if ~ E E andconsistent with E then 7 E E (that is, if we believe~x and fl is consistent with what we believe, thenwe also believe 7).l~eiter can test a formula for consistency by test-ing for the absence of its negation.
Since Kasper-Rounds logic does not have negation, we will not beable to do that.
Fortunately, we have do have our211own natural notion of consistency--a set of formu-las is consistent if it is satisfiable.
Testing a set ofKasper-Rounds formulas for consistency thus sim-ply reduces to finding a satisfier for that set.Formally, we encode our logic as an informationsystem (Scott 1982).
An information system (IS)is a triple (A, C, b) where A is a countable set of"atoms," Cis a class of finite subsets of A, and t- isa binary relation between subsets of A and elementsof A.
A set X is said to be consistent if every finitesubset of X is an element of C. A set G is closed iffor every X _C G such that X l- a, we have a E G.Following thesty le  used for information systems,we will write G for the closure of G.In our case, A is the wffs of SFML (exceptFALSE),  and C is the class of satisfiable sets.
Theentailment relation encodes the semantics of theparticular unification system we are using.
Thatis, we haveF I - I~ if VF.F~AF~F~fl.For instance,P l  ":- P2, P2 - -  P3 I- P l  - -  P3represents the transitivity of path equations.DEFAULT KASPER-ROUNDSLOGICIn the previous section we described the genericform of default logic.
We will not need the fullgenerality to describe default sorts.
We will re-strict our attention to closed precondition-free nor-mal defaults.
That  is, all of our defaults will be ofthe form::M~We will write D E as an abbreviation for this defaultinference.
Here fl stands for a generic wff from thebase language.
Even this is more general than wetruly need, since we are really only interested indefault sorts.
Nevertheless, we will prove things inthe more general form.Note that our default inferences are closed andnormal.
This means that we will always have anextension and that the extension(s) will be consis-tent if and only if W is consistent.
These followfrom our equivalents of Reiter's theorem 3.1 andcorollaries 2.2 and 2.3.Let's consider now how we would represent heinformation in Fig.
3 in terms of Kasper-Roundsdefault logic.
The strict statements become normalKR formulas in W. For instance, the informationfor MIDDLE-VERBs (not counting the inheritanceinformation) is represented as follows:({}, {past : participle: suff ix: +en) )The information for VERB will clearly involvesome defaults.
In particular, we have two pathsleading to default sorts.
We interpret hese state-ments as saying that the path exists, and that it hasthe value indicated by default.
Thus we representthe VERB template as:D = {Dpast : tenae:suyf ix :+te ,Dpast:part ieiple:su \] \] ix : + t ) ,W = {past : tense : suffix : T ,past : participle : suffix : -I-,past : participle : prefix : ge+ }Inheritance is done simply by pair-wise set union ofancestors in the hierarchy.
Since the entry for mahlcontains no local information, the full descriptionfor it is simply the union of the two sets above.D = {Dpast:tense:suy$i~::+te,Opast:part ie iple: ,u Lf ix :  +t },W = {past : tense : suffix :-l-,past : participle : suffix : T,past : participle : prefix : ge+,past : participle : suffix : +en}We can then find an extension for that default the-ory and take the most general satisfier for that for-mula.
It is easy to see that the only extension forraahl is the closure of:past : tense : suffix : +te,past : participle : suffix : +en,past : participle : prefix : ge+The default suffix +t  is not applicable for the pastparticiple due to the presence of +en.
The suffix+re is applicable and so appears in the extension.DKRL  AND NONMONOTONICSORTSIn the previous section we defined how to get theright answers from a system using default sorts.
Inthis section we will show that the method of non-monotonic sorts gives us the same answers.
Firstwe formalize the relation between NSFSs and de-fault logic.Def in i t ion  6 Let 79 = (Q, r, 5, ~) be a nonmono-tonically sorted feature structure.
The default the-ory of D isDT(79) = ({Dp:t I ~2(5(r,p)) = (s, A)  A t  6 A},{{Pl,P2} I 5(r, PQ ---- 5(r, p2)}u{p:s  I ~(5(r,p)) = (s, A)))The default part of DT(79) encodes the defaultsorts, while the strict part encodes the path equa-tions and strict sorts.Theorem 1 The FS .4 is a solution for the NSFS7) if  and only if {?1.4~?}
is an extension ofDT(79).212Because we are dealing with closed normal defaulttheories, we can form extensions imply by takingmaximal consistent sets of defaults.
This, of course,is also how we form solutions, so the the solutionof a NSFS is an extension of its default theory.We now need to show that NSFS unification be-haves properly.
That  is, we must show that non-monotonic sort unification doesn't create or destroyextensions.
We will write (D1, W1)=zx(D2, I4/2) toindicate that (O1, W1) and (D2, W2) have the sameset of extensions.
We will do this by combining anumber of intermediate r sults.Theorem 2 Let (D, W) be a closed normal defaulttheory.1.
/fc~ A/3 ?
* 7,then (D, W to {4 ^ /3})=a(D, W to {7})-2.
/ f  W U {/3} is inconsistent,then (D t^ {DE} , W)=A(D,  W).3.
I fW ~-/3, then (D U {DE} , W)=A(D,  W).4.
I fW~-~ anda^/3?
:~7,then (D tO {DE} , W)=A(D tO {D.y}, W).The formulas ~ and /3 represent he (path pre-fixed) sorts to be unified, and 7 their (path pre-fixed) greatest lower bound.
The first part dealswith strict sort unification, and is a simple conse-quence of the fact that (D, W) has the same exten-sions as (D, W).
The next two deal with inconsis-tent and redundant default sorts.
They are simi-lar to theorems proved in (Delgrande and Jackson1991): inconsistent defaults are never applicable;while necessary ones are always applicable.
Thelast part allows for strengthening of default sorts.It follows from the previous three.
Together theyshow that nonmonotonic unification preserves theinformation present in the NSFSs being unified.Theorem 3 Let 791 and 792 be NSFSs.
ThenDT(79Z RN792)=zx DT(791) to DT(792) (using pair-wise set union).DISCUSSIONMost treatments of default unification to date havebeen presented very informally.
(Bouma 1992)and (Russell et al 1992), however, provide verythorough treatments of their respective methods.Bouma's is more traditional in that it relies on"subtracting" inconsistent information from the de-fault side of the unification.
The method given inth ispaper  is similar to Russell's method in thatit relies on consistency to decide whether defaultinformation should be added.Briefly, Bouma defines a default unification op-eration AU!B = (A - B) II B, where A - B is de-rived from A by eliminating any path that eithergets a label or shares a value in B.
In the lexi-con, each template has both "strict" and "default"information.
The default information is combinedA template<f> isa a<g> default bB template<f> default c<g> isa dC lex A BFigure 4: Multiple Default Inheritancewith the inherited information by the usual unifica-tion.
This information is then combined (using El!
)with the strict information to derive the FS associ-ated with the template.
This FS is then inheritedby any children of the template.Note that the division into "strict" and "default"for Bouma is only local to the template.
At thenext level in the hierarchy, what was strict becomesdefault.
Thus "defaultness" is not a property of theinformation itself, as it is with NSs, but rather arelation one piece of information has to another.The method described in (Russell et al 1992)also divides templates into strict and defaultparts 1.
Here, though, the definitions of strict anddefault are closer to our own.
Each lexical entryinherits from a list of templates, which are scannedin order.
Starting from the lexical entry, at eachtemplate the strict information is added, and thenall consistent defaults are applied.The list of templates that the lexical entry in-herits from is generated by a topological sort of theinheritance hierarchy.
Thus the same set may givetwo different results based on two different order-ings.
This approach to multiple inheritance allowsfor conflicts between defaults to be resolved.
Note,however, that if template A gets scanned beforetemplate B, then A must not contain any defaultsthat conflict with the strict information in templateB.
Otherwise we will get a unification failure, asthe default in A will already have been appliedwhen we reach B.
With NSs, the strict informa-tion will always override the default, regardless ofthe order information is received.The treatment of default information with NSsallows strict and default information to be inheritedfrom multiple parents.
Consider Fig.
4.
Assumingthat the sorts do not combine at all, the resultingFS for lexical entry C should be\[,a\]g dThe two methods mentioned above would fail to getany answer for 6': one default or the other wouldl'I'here may actually be multiple strict parts, whichare treated as disjuncts, but that is not pertinent to thecomparison.213be applied before the other template was even con-sidered.
In order to handle this example correctly,they would have to state C's properties directly.One advantage of both Bouma and Russell isthat exceptions to exceptions are allowed.
Withnonmonotonic sorts as we have presented themhere, we would get conflicting defaults and thusmultiple answers.
However, it is straight-forwardto add priorities to defaults.
Each solution has aunique set of defaults it uses, and so we can com-pare the priorities of various olutions to choose themost preferred one.
The priority scheme can be anypartial order, though one that mirrored the lexicalinheritance hierarchy would be most natural.Another advantage that both might claim is thatthey deal with more than just default sorts.
How-ever, the theorems we proved above were provedfor generic wits of Kasper-Rounds logic.
Thus anyformula could be used as a default, and the onlyquestion is how best to represent the information.Nonmonotonic sorts are a concise and correct im-plementation of the kind of default inheritance wehave defined here.CONCLUSIONThis paper has shown how the method ofnonmono-tonic sorts is grounded in the well-established the-ories of Kasper-Rounds logic and Reiter's defaultlogic.
This is, to our knowledge, the first attemptto combine Reiter's theory with feature systems.Most previous attempts to fuse defaults with fea-ture structures have relied on procedural code--a state of affairs that is highly inconsistent withthe declarative nature of feature systems.
Meth-ods that do not rely on procedures still suffer fromthe necessity to specify what order information isreceived in.It seems to us that the major problem that hasplagued attempts to add defaults to feature systemsis the failure to recognize the difference in kind be-tween strict and default information.
The state-ment that the present participle suffix for Englishis '+ing' is a very different sort of statement thanthat the past participle suffix is '+ed'  by default.The former is unassailable information.
The lattermerely describes a convention--that you should use'+ed' unless you're told otherwise.
The method ofnonmonotonic sorts makes this important distinc-tion between strict and default information.
Theprice of this method is in the need to find solu-tions to NSFSs.
But much of the cost of findingsolutions is dissipated through the unification pro-cess (through the elimination of inconsistent andredundant defaults).
In a properly designed lexi-con there will be only one solution, and that canbe found simply by unifying all the defaults present(getting a unification failure here means that thereis more than one solution--a situation that shouldindicates an error).The semantics given for NSs can be extended ina number of ways.
In particular, it suggests a se-mantics for one kind of default unification.
It ispossible to say that two values are by default equalby giving the formula Dp -p2.
This would be usefulin our German verbs example to specify that thepast tense root is by default equal to the presenttense root.
This would fill in roots for spiel andmahl without confounding zwing.
Another exten-sion is to use a prioritized efault logic to allow forresolution of conflicts between defaults.
The nat-ural prioritization would be parallel to the lexiconstructure, but others could be imposed if they mademore sense in the context.Re ferencesBouma, Gosse 1990.
Defaults in unification gram-mar.
In Proceedings of the 1990 Conference of theAssociation for Computational Linguistics.
165-172.Bouma, Gosse 1992.
Feature structures andnonmonotonicity.
Computational Linguistics18(2):183-203.Carpenter, Bob 1991.
Skeptical and credulous de-fault unification with applications to templatesand inheritance.
In Default Inheritance WithinUnification-Based Approaches to the Lexicon.Carpenter, Bob 1992.
The Logic of Typed FeatureStructures.
Cambridge University Press.Delgrande, James P and Jackson, W Ken 1991.Default logic revisited.
In Proceedings of the Sec-ond International Conference on the Principles ofKnowledge Representation and Reasoning.
118-127.Kaplan, Ronald 1987.
Three seductions of com-putational linguistics.
In Linguistic Theory andComputer Applications.
Academic Press, London.149-188.Kasper, Bob 1988.
Feature Structures: A LogicalTheory with Applications to Language Analysis.Ph.D.
Dissertation, University of Michigan, AnnArbor.Reiter, Ray 1980.
A logic for default reasoning.Artificial Intelligence 13:81-132.Russell, Graham; Ballim, Afzal; Carroll, John;and Warwick-Armstrong, Susan 1992.
A practi-cal approach to multiple default inheritance forunification-based lexicons.
Computational Lin-guistics 18(3):311-337.Scott, Dana 1982.
Domains for Denotational Se-mantics, volume 140 of Lecture Notes in ComputerScience.Shieber, Stuart 1986.
An Introduction toUnification-Based Approaches to Grammar, vol-ume 4 of CSLI Lecture Notes.
University ofChicago Press, Chicago.214Shieber, Stuart 1987.
Separating linguistic anal-yses from linguistic theories.
In Linguistic The-ory and Computer Applications.
Academic Press,London.
1-36.Young, Mark 1992.
Nonmonotonic sorts for fea-ture structures.
In National Conference on Arti-ficial Intelligence, San Jose, California.
596-601.215
