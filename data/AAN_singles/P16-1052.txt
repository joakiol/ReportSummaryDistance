Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 547?557,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsFinding the Middle Ground - A Model for Planning Satisficing AnswersSabine JanzenSaarland UniversitySaarbr?ucken, Germanyjanzen@iss.uni-saarland.deWolfgang Maa?Saarland UniversitySaarbr?ucken, Germanymaass@iss.uni-saarland.deTobias KowatschUniversity of St. GallenSt.
Gallen, Switzerlandtobias.kowatsch@unisg.chAbstractTo establish sophisticated dialogue sys-tems, text planning needs to cope withcongruent as well as incongruent inter-locutor interests as given in everyday di-alogues.
Little attention has been given tothis topic in text planning in contrast to di-alogues that are fully aligned with antic-ipated user interests.
When consideringdialogues with congruent and incongru-ent interlocutor interests, dialogue part-ners are facing the constant challenge offinding a balance between cooperation andcompetition.
We introduce the conceptof fairness that operationalize an equaland adequate, i.e.
equitable satisfactionof all interlocutors?
interests.
Focusingon Question-Answering (QA) settings, wedescribe an answer planning approach thatsupport fair dialogues under congruent andincongruent interlocutor interests.
Dueto the fact that fairness is subjective perse, we present promising results from anempirical study (N=107) in which humansubjects interacted with a QA system im-plementing the proposed approach.1 IntroductionFor building dialogue systems that cope with con-tradictions and individual interests of dialog part-ners, text planning is required to process incon-gruent and congruent interests of interlocutors.
Sofar, research on dialogue systems focusses on sup-porting dialogues that are fully aligned with antic-ipated user interests, e.g., (Hovy, 1991; Grosz andKraus, 1996; Moore and Paris, 1993; Lochbaum,1998; Rich and Sidner, 1997), and, thus, max-imizing cooperativeness (Bunt and Black, 2000,191 p. 5).
Few approaches exist that investi-gate text planning with pure conflict, e.g., (Jame-son et al, 1994; Hadjinikolis et al, 2013; Blackand Atkinson, 2011; Prakken, 2006).
When con-sidering dialogues with congruent as well as in-congruent interlocutors interests, dialogue part-ners are facing the constant challenge of findinga balance between cooperation and competition(Parikh, 2010).
We introduce the concept of fair-ness that operationalize an equal and adequate,i.e.
equitable satisfaction of all interlocutors?
in-terests (Oxford Dictionaries, 2016).
Focusing onQuestion-Answering (QA) settings, we describean answer planning approach that support fair dia-logues under congruent and incongruent interestsof interlocutors.
Due to the fact that fairness issubjective per se, we present results from an em-pirical study in which human subjects interactedwith a QA system in various dialogue settings.When determining appropriate answers in textplanning, approaches range from (1) wrong an-swer avoidance concepts technically checking thecorrectness of answers, e.g., Dong et al (2011),and (2) opponent models in persuasion dialoguesfor choosing most suitable arguments, e.g., Had-jinikolis et al (2013), to (3) the prediction of emo-tions of interlocutors to generate answers, e.g.,Hasegawa et al (2013).
Here, related work is rel-evant that focuses on the determination of appro-priate answers by processing concepts like users?intentions (e.g., Levelt (1993)), desires (e.g., Rao& Georgeff (1995)), preferences (e.g., Li et al(2013)), objectives (e.g., Schelling (1960)) andgoals (e.g., Traum et al (2008)) which we willhereafter subsume under the term motives.
Mo-tives refer to objectives or situations that inter-locutors would like to accomplish, e.g., to findthe best price when shopping.
According to thebelief-desire-intention model, motives can be de-scribed as desires in the sense of a motivationalstate (Georgeff et al, 1998).
Motives do not in-547volve the mandatory purpose of being recogniz-able by other participants; so they are equivalentwith the concept of intentions in (Levelt, 1993).Regarding the processing of congruent and incon-gruent motives, existing approaches rather focuson motives of single interlocutors or on joint mo-tives, e.g., Paquette (2012), Li et al (2013).
Inthe following, the aggregation of congruent andincongruent interlocutor motives in dialogues willbe described as mixed motives.In this work, we propose a model that formalizesanswer planning as psychological game (Bjorn-dahl et al, 2013) embedded in text planning ap-proaches (Mann and Thompson, 1986; Moore andParis, 1993) for creating dialogues perceived asfair by all interlocutors.
Since traditional formal-ization of motives by means of utility functionsis not sufficient to handle complex interactions asgiven in the considered dialogue setting (Bjorn-dahl et al, 2013), psychological games enrichclassical game settings with user models, i.e.
inour case explicit representations of mixed motives.One appeal of the model is the consideration of an-swer planning as psychological game that lifts theprocess of finding appropriate answers from theshort-term linguistic level to the long-term motivelevel in contrast to other approaches (van Deemter,2009; Stevens et al, 2015).
Interlocutors do nothave preferences for answers, but try to satisfy mo-tives.
So, we assume that this approach enables amore sophisticated simulation of human behaviorin mixed motive interactions as well as the estab-lishment of ?cooperativeness in response formu-lation?
(Bunt and Black, 2000, p. 5) for creat-ing dialogues perceived as fair.
By exemplifyingthe model within a QA system as natural languagesales assistant for conducting sales dialogues, wewere able to evaluate the proposed approach inan empirical user study (N=107) in terms of per-ceived fairness of created dialogues with promis-ing results.2 Planning Answers given MixedMotivesAdopting a computational pragmatics perspective,we intend to compute relevant linguistic aspectsof answers based on contextual aspects given bymixed motives (Bunt and Black, 2000, p. 3).When searching for answers that support an eq-uitable satisfaction of mixed motives during dia-logue, ?
represents the solution space with poten-tial answers.
An objective function f : ??
R as-signs values to all answers x ?
?
for representingtheir potential in satisfying motives of interlocutori ?
I .
Of course, all interlocutors I prefer an-swers x that satisfy best their motives; xaxb?f(xa) > f(xb).
So, the goal would be to find ananswer x ?
?
with highest satisfaction of motivesf(x) of interlocutor i ?
I in the sense of an opti-mal solution x*; i.e.
f(x*) = max{f(x)|x ?
?
}.But, in order to achieve fair outcomes regardingan equitable, i.e.
equal and adequate satisfactionof mixed motives, this definition is not sufficient.First, decision making takes places in the contextof social dialogue interaction, i.e.
answers have tobe selected based on multiple objective functionssince motives of all interlocutors i ?
I shall besatisfied; fi: ?
?
R. For capturing the aspect ofequal motive satisfaction, the potential of answershas to be represented absolutely and relatively.
Inother words, the performance of an answer in sat-isfying motives of an interlocutor i ?
I is com-bined with its performance in satisfying motivesof counterparts ?i ?
I; max{fi,-i(x)|x ?
?
}.Second, the aforementioned conflict between co-operation and competition needs to be solved ade-quately.
Since it is impossible to find an answersatisfying all motives of all interlocutors at anytime in the dialogue, we search for a compromisein form of a solution i.e.
an answer x+with aminimum quality s so that f(x+) ?
s. Adopt-ing the concept of satisficing by Simon (1956), anapproach that attempts to find the best alternativeavailable in contrast to optimal decision making,the goal is to find an answer x ?
?
with highestsufficient satisfaction of motives f(x) ?
s of allinterlocutors I in the sense of a satisficing solutionx+; i.e.
f(x+) = max{fi,-i(x) ?
s|x ?
?
}.3 Model for Planning SatisficingAnswersTo capture these issues, we defined a model forplanning satisficing answers in dialogues withmixed motives.
In the considered setting, a userwith motives poses questions to a QA system thattakes the role of a proxy for indirect interlocu-tors, e.g., retailers in online shopping scenarios.The QA system adopts their motives and devel-ops strategies to satisfy them.
Adopted motivesas well as user motives that are anticipated by thesystem represent mixed motives in the dialogue.Task of the system is to process these mixed mo-548tives with the objective to create a dialogue thatis perceived as fair by all interlocutors after a fi-nite number of question answer pairs.
As full sat-isfaction of all motives of all interlocutors at anytime in a mixed motive dialogue is not possible,the QA system has to find a compromise, i.e.
ithas to plan answers that satisfice mixed motivesduring dialogue.
Let us start by describing an ex-ample dialogue between a customer and a retailerin a shopping scenario:Q: Is the range of this wifi router appropriate fora house with 3 floors?A: In case of 3 floors, I would recommend an ad-ditional wifi repeater that got very good feedbackby other customers.
You can buy both router andrepeater as a bundle with 15% discount.In this dialogue snippet, the customer intends toget comprehensive product information regardingthe wifi router; the retailer also wants to satisfy in-formational needs of the customer to establish ex-cellent services.
Beyond these congruent motives,the retailer wants to increase revenue and to raisesales figures.
A balance between mixed motivesis found by giving information regarding the wifirouter as well as preferences of other customersfollowed by a discounted bundle offer.In order to implement this kind of behavior intodialogue systems, the model for planning satisfic-ing answers separates linguistics from conceptualnon-linguistic aspects (Traum and Larsson, 2003;Allen et al, 2001) and consists of three main mod-ules: linguistic module, mapper and mixed motivemodule (cf.
Fig.
1).
The linguistic module takescare for handling user questions as input as wellfor generating answers as output.
Essential com-ponents of the linguistic module are the linguisticintention model and flexible text planning tech-nologies.
For the latter, we apply text plans ac-cording to the Rhetorical Structure Theory (Mannand Thompson, 1986) in form of plan operators(Moore and Paris, 1993) for generating answers.Each plan operator consists of a single compul-sive part, called nucleus, that is related with di-verse optional text segments, mentioned as satel-lites.
We assume that beside supporting the effectof the nucleus, satellites represent an opportunityto satisfice mixed motives during dialogue.
Satel-lites are linked with entities of the linguistic inten-tion model, means linguistic intentions that cap-ture the intended effects, i.e.
functions of satel-lites within answers (Grosz and Sidner, 1986).
Bymeans of second module - the mapper - linguis-tic intentions are mapped onto motives and viceversa (cf.
Fig.
1).
Therefore domain-specificknowledge about correlations between linguisticintentions and mixed motives is required that isinduced by a domain configurator and has to bederived empirically.
Last, the mixed motive mod-ule combines an explicit representation and sit-uated processing of mixed motives (Cohen andLevesque, 1990) with a game-theoretical equilib-rium approach (Nash, 1951) to establish a psy-chological game setting (Bjorndahl et al, 2013)(cf.
Fig.
1).
Our approach operates by assum-ing that interlocutors are rational.
That meansthey act strategically and purposively in pursuit oftheir own motives that they try to maximally sat-isfy.
Therefore, we assume that game theory isan adequate prospect to deliver the analytical toolsfor planning answers in the context of mixed mo-tives.
In game theory literature, equilibrium con-cepts are widely applied, e.g., Nash equilibrium(Nash, 1951).
A Nash equilibrium is an outcomethat holds because no involved actor has a ratio-nal incentive to deviate from it, i.e., the final resultis ?good enough?
for all actors in the sense of ahappy medium.
Adapted to this work, this refersto a satisficing combination of motives at a partic-ular time in the dialogue, that is good enough forplanning an answer that supports equitable satis-faction of mixed motives.3.1 ConceptsFrom a conceptual perspective, the model usesseveral core entities.
First, we have players p ?P that represent interlocutors I .
Players havedomain-specific motives m for participating in thedialogue.
For each player p ?
P , we assumea MotiveSet that consists of individual motives,IndM , as well as of motives the player, i.e.
theinterlocutor anticipates from counterparts, AntM .MotiveSetp= IndMp+ AntM-p(1)Mixed motives MM are represented by the non-redundant aggregation of 1. .
.
n MotiveSet ofplayers p ?
P in the dialogue.MM = {MotiveSetp1.
.
.MotiveSetpn} (2)All motives m ?
MM are operationalized bymeans of real-valued weights for each player cov-ered by a weight vector??????Weightm.
Motives areformed earlier and persist during dialogue, but549Figure 1: Model for planning satisficing answers in dialogues with mixed motivesplayers deliberate about weights of motives con-tinuously (Bratman, 1987).
The achievement andthereby satisfaction of motives is supported by lin-guistic intentions li ?
LI that are satisfied bysatellites sat that are offered by plan operators andintegrated into an answer.
That means motives areachieved, if answers were given, that contributedto satisfaction of these motives.3.2 Algorithm and exampleFor introducing the proposed approach, we willgive an example course of satisficing answer plan-ning starting with user question and ending withsystem answer.
The description of the process willbe supported by a model view marked with stepnumbers in Fig.
1 as well as by an algorithmicview in Alg.
1.
In the example, we apply domain-specific knowledge that was derived empirically inthe retailing domain.
Although, in literature re-view, customer and retailer motives in sales dia-logues were specified.
Combinations of these mo-tives were analyzed in simulated sales conversa-tions between real retailers (N=3) and subjects act-ing as customers (N=12).
Recorded as video files,conversations and identified motives were vali-dated in a web-based user study (N=120) regard-ing their naturalness and relevance.
Sales conver-sations were transcribed, aggregated to a text cor-pus and analyzed regarding question and answerstructures.
So, the domain-specific knowledgerepresentation used in the example bases on re-sults of this empirical analysis and covers all coremodel concepts introduced before: a mixed motivemodel with empirically derived default weightsconsisting of 19 customer and 4 retailer motives(cf.
Tab.
1); 39 question and 33 answer schemata(McKeown, 1985), 31 plan operators (Moore andMotive m ?MM Weight paWeight pbHigh level of reliability of prod-uct (mR)1.90 1.00Fair price of product (mFP) 0.70 0.00Exclusive design of product(mED)0.53 1.00Comprehensive product infor-mation (mCPI)1.67 1.00Improving customer relationship(mICR)0.00 4.00Increase revenue (mIR) 4.00 4.00Table 1: Extract of domain-specific mixed mo-tive model with default weights for player (pa) andplayer (pb) representing customer and retailerParis, 1993), 21 satellites with 18 linguistic in-tentions (cf.
Tab.
2) and 14 rhetorical relations(Hobbs, 1978; Hovy, 1993; Mann and Thompson,1986), and exemplary product information.Imagine a sales conversation regarding consumerelectronics between customer and retailer repre-sented by player (pa) and player (pb).
Sets of mo-tives by players are equal regarding the motivesincluded but differ in weights of individual and an-ticipated motives by players (cf.
Tab.
1).MM = MotiveSetpa+ MotiveSetpb(3)MotiveSetpa= IndMpa+ AntMpbMotiveSetpb= IndMpb+ AntMpaThe customer poses a question concerningproducts with a specific feature: ?How manytablets offer the wifi features 802.11A, 802.11B,802.11G, 802.11n??
Based on the identified ques-tion schema as well as the determined communica-tive function of the question, a dialogue systemthat instantiates the proposed model selects an ap-propriate plan operator (cf.
Fig.
1, step 1 & 2).550Ling.
Intention li ?
LI supports m ?MMDescriptionAdvantages (liA) {mICR,mFP,mED,mIPD,mR,mHLS,mACB,mSCD,mI,mHLP,mPB,mQ}Integration of informationabout advantages of prod-uct(s) into answerExternalReview (liER){mSI} Presentation of customerreviewsMy Product (liMP) {mICR,mSP,mR,mHLC}Mentioning products thatcould be interesting forcustomerFunctionality (liF) {mEU} Extension of answer re-garding product functionsOpinion (liO) {mHEM,mSP,mR,mSI}Integration of subjective(retailer) opinion into an-swerTable 2: Extract of domain-specific linguistic in-tentions li ?
LI with supported motives and de-scription3.2.1 Definition of set S and determination ofSatisfactionSetIn our case, a plan operator named NUMBER OFPRODUCTS is selected that offers an obligatorynucleus and a set S of four optional satellites (cf.Fig.
2):S = {satAAS, satVER, satDF, satEUP} (4)Overall objective is to determine set S+out of setS, that consists of satellites that - besides support-ing the effect of the nucleus - contribute to satis-ficing mixes motives of customer and retailer dur-ing dialogue (cf.
Alg.
1).
According to (Groszand Sidner, 1986; Moore and Paris, 1993), satel-lites are linked with linguistic intentions; i.e.
theyfulfill certain functions regarding the overall dia-logue.
Set S is sent to the linguistic intention han-dler that specifies the SatisfactionSet (cf.
Fig.1, step 3 and Alg.
1, line 1-4).
This set covers lin-guistic intentions that can be satisfied by satellitesof set S (cf.
Tab.
2):SatisfactionSet = {liA, liER, liF, liMP} (5)Figure 2: Plan operator NUMBER OF PRODUCTS3.2.2 Mapping linguistic intentions ontomixed motivesNext, linguistic intentions have to be mapped ontomotives.
The m:n correlation between linguisticintentions and motives (Moore and Paris, 1993)is domain-specific, has to be specified empiricallyand is induced by the domain configurator (cf.Fig.
1, step 5).
Each motive is supported by aset of linguistic intentions that contribute to theachievement of this motive (cf.
Fig.
3).
On theother hand, each linguistic intention can supportthe achievement of several motives.
By processingFigure 3: Correlations between motives (M) andlinguistic intentions (LI)the supports-relation between both concepts, themapper specifies the RelevanceSet based on theSatisfactionSet.
The resulting RelevanceSetrepresents all mixed motives relevant for planningthe actual answer (cf.
Alg.
1, line 5-8):RelevanceSet = {mQ,mR,mIPD,mHCS,mACB,mICR,mI,mSCD,mPB,mEU,mFP,mED,mHLP,mSI,mSP,mHLC}(6)3.2.3 Satisficing mixed motivesHaving identified the RelevanceSet, we now in-tend to identify a satisficing combination of the in-volved motives.
Therefore, the mapper sends theRelevanceSet to the mixed motive model handlerfor specifying the SatisficingSet that consistsof motives that (1) are sufficiently interesting forall interlocutors (i.e.
weighted positively), and (2)have preferably low conflict potential (i.e.
smalldifferences in player weights) (cf.
Fig.
1, step 6).Satisficing mixed motives is considered as multi-player non-zero-sum game that is played for in-finitely many rounds, more precisely pairs of userquestions and system answers.
In each roundof the game, it has to be decided which motives551Algorithm 1 Determining set S+of satisficing satellitesRequire: set of default satellites S = {sat1.
.
.
satn}; set of players P = {p1.
.
.
pn}; set of mixed motives MM ={m1.
.
.mn}; set of linguistic intentions LI = {li1.
.
.
lin}Ensure: set of satisficing satellites S+= {sat1.
.
.
satn}1: Initialize SatisfactionSet = {li1.
.
.
lin?
LI|li.isSatisfiedBy(sat ?
S)}2: for ?sat ?
S do3: SatisfactionSet?
SatisfactionSetsat?
SatisfactionSet4: end for5: Initialize RelevanceSet = {m1.
.
.mn?MM |m.isSupportedBy(li ?
SatisfactionSet)}6: for ?li ?
SatisfactionSet do7: RelevanceSet?
RelevanceSetli?RelevanceSet8: end for9: Determine StrategySet?
P(RelevanceSet)10: Initialize StrategyProfiles = {??s1.
.
.?
?sn}11: for ?s ?
StrategySet; ?p ?
P do12: Calculate LocalPayout(s)13: Define?
?s = {s1.
.
.
sn?
StrategySet|LocalPayout(sp*|s-p) ?
LocalPayout(sp|s-p)}14: StrategyProfiles.add(?
?s )15: end for16: for ??
?s ?
StrategyProfiles do17: if LocalPayout(sp*|s*-p) ?
LocalPayout(sp|s*-p) then18:??s*??
?s19: end if20: end for21: Determine SatisficingSet = {m1.
.
.mn?
s ??
?s*}22: if SatisficingSet 6= ?
then23: Initialize SupportSet = {li1.
.
.
lin?
LI|li.supports(m ?
SatisficingSet)}24: for ?m ?
SatisficingSet do25: SupportSet?
SupportSetm?
SupportSet26: end for27: Return S+= {sat1.
.
.
satn?
S|sat.satisfies(li ?
SupportSet ?
SatisfactionSet)}28: else29: Return S+= {?
}30: end ifof the RelevanceSet are selected as trigger forplanning an answer that supports the creation ofdialogues perceived as fair by all interlocutors.The equilibrium identifier specifies strategy setsSp= {s1.
.
.
sn} for all players P by generatingthe power set of the RelevanceSet (cf.
Fig.
1,step 7 and Alg.
1, line 9).
Each of the 137 result-ing strategies s = {m1.
.
.mn} represents a pos-sible combination of motives or the empty set andis measured by a normalized local payout for eachplayer based on weights of involved motives.Spa= Spb= {s1.
.
.
s137}; s18= {mQ,mR} (7)LocalPayoutpa,s18= 0.1280;LocalPayoutpb,s18= 0.0090Strategy sets of players are identical regardingtypes of covered strategies, but differ in local pay-outs that can be expected by players when play-ing this strategy as shown in eq.
(7).
As playersprefer those strategies that provide high local pay-outs, the equilibrium identifier identifies strategiess*?
Spfor each player that represent best answersregarding the behavior of counterparts??s-p:LocalPayout(s*,?
?s-p) ?
LocalPayout(s,?
?s-p), ?s ?
Sp(8)Best answers of players in the sense of highestlocal payouts are aggregated to 17 strategy pro-files, each a vector consisting of two strategiesone for each player (cf.
Alg.
1, line 10-15):?
?s = {sx, sy}; sx?
Spa, sy?
Spb.Next, strategy profiles are selected that meet theNash equilibrium condition, i.e.
those strategyprofiles exclusively cover strategies that representmutual best answers of players (cf.
Alg.
1, line16-20):LocalPayout(s*,?
?s-p*) ?
LocalPayout(s,?
?s-p*) (9)?s ???s1.
.
.?
?snIn our example, we find two Nash equilibria.Those two strategy profiles represent best answersfor the player p as well as the whole group of play-ers P in the sense of a solution with minimumquality.
No player has an incentive to deviate fromthose strategy profile because then its local pay-out would decrease.
With?
?s = {s36, s36}, weselect the non-pareto-dominant option for findingthe strategy profile with the lowest difference inlocal payouts following the idea of the model to552create a balance between mixed motives.
Witheach answer planning, players generate local pay-outs that are added during the course of dialogueto global payouts.
Instead of gaining high globalpayouts, the objective of the model is to balancepayouts of players during dialogue or to approx-imate them in case of drifting apart.
We assumethat similar global payouts of players can be re-garded as evidence for satisficed mixed motives.Based on the selected strategy profile, involvedmotives are aggregated to the SatisficingSet ={mR,mICR} that represents a combination ofmixed motives that is satisficing for all players inthis time in the dialogue (cf.
Alg.
1, line 21).3.2.4 Mapping mixed motives onto linguisticintentionsThe resulting SatisficingSet is forwarded to themapper for mapping back motives onto linguisticintentions (cf.
Fig.
1, step 8 & 9).
In case, theSatisficingSet covers zero motives, no mappingtakes place, the process ends and none of the satel-lites in set S, cf.
eq (4), will be considered in theactual answer planning.
Otherwise, the mapperdetermines the set of supporting linguistic inten-tions by processing the inverse is-supported-by-relation between motives and linguistic intentions(cf.
Alg.
1, line 22-30) (cf.
Fig.
3).
Comparingthis set with the SatisfactionSet (cf.
eq.
(5)),an intersection called SupportSet is created thatrepresents the set of linguistic intentions that willbe satisfied in current answer planning:SupportSet = {liA, liMP} (10)3.2.5 Determination of set S+and generationof answerThe linguistic intention handler determines the fi-nal set of satellites S+by analyzing 1:1 relationsbetween linguistic intentions of the SupportSetand satellites of the set S (cf.
Fig.
1, step 10and Alg.
1, line 27).
The resulting set S+={satAAS, satEUP} consists of two satellites: Al-ternatives Advantages Survey (satAAS) and Emo-tion User Preferences (satEUP).
The text plan libhandler adjusts the final text plan regarding the se-lected satellites before sending it to the answergenerator (cf.
Fig.
1, step 11 & 12).
Last,the text plan provided by the plan operator NUM-BER OF PRODUCTS is transformed into an answer.Thereby, answer schemata referenced by nucleusas well as satellites of set S+are instantiated (cf.Fig.
1, step 13):Q: ?How many tablets offer the wifi features802.11A, 802.11B, 802.11G, 802.11n?
?A: ?
[nucThe following tablets offer this feature:Sony SGPT122 Xperia.]
[satAASDue to its features,e.g., storage capacity: 32GB, Sony SGPT122 Xpe-ria has some advantages compared to other prod-ucts in this category.]
[satEUPHow about having alook at Sony SGPT122 Xperia by Sony?
]3.2.6 SummaryIn summary, satisficing answer planning is con-sidered as a game consisting of four components?P, S, F,A?
: the set of players P = {pa, pb},strategies of players S = {Spa, Spb}, objectivefunctions of players F = {fpa, fpb}, and a statespace A = {a1.
.
.
at} that represents the roundsof the game, i.e.
answers planned in the dialogue.The game starts in an initial state a1.
At a partic-ular time t in the dialogue, the equilibrium iden-tifier observes the state atcharacterized by P, S,and F and identifies best answers for all players;st?
Sp;?p ?
P .
Consequential, a strategy pro-file meeting the Nash equilibrium condition,?
?st={stpa, stpb}, is specified and resulting payouts areobserved: f(at,?
?st) ?
LocalPayout ?
R. Thecalculation of local payouts by means of objec-tive functions f ?
F in state atdoes not de-pend solely on the selected strategy profile, buton results of former states in A, i.e.
all answersplanned in the dialogue until at.
That means, infi-nite playing of the described non-zero-sum gamea1,?
?s1, .
.
.
, at,?
?st, .
.
.
generates a stream of pay-outs f1, f2, .
.
.
, ft= f(at,??st).
Besides relevantmotives of the RelevanceSet, answer planning instate at+1is directly influenced by local payoutsft(at,?
?st) in atleading to a continuous delibera-tion of the mixed motive model during dialogue.4 Implementation and EvaluationBased on the proposed model (cf.
Fig.
1), weimplemented a German text-based QA system inform of a online shopping assistant (cf.
Fig.4)1.
Users are able to construct questions term-by-term.
Having tapped the last term of a ques-tion, the answer is given.
The QA system uses thedomain-specific knowledge representation men-tioned in section 3.2 formalized in RDF2.1QA system was implemented as web application:http://redqueen.iss.uni-saarland.de/satin2Resource Description Framework553Figure 4: Web-based QA system with posed ques-tion and given answer in German4.1 SettingTo evaluate our approach, we conducted a userstudy with the implemented prototype in Germanthat was set up as lab experiment.
Goal of thisstudy was to assess the perceived fairness andnaturalness of the dialogue with the QA systemas well as the extent of motive satisfaction ofparticipants.
For that purpose, four randomizedgroups were formed.
Each group was character-ized by a combination of motives by users (fairprice of product (mFP) or exclusive design of prod-uct (mED)) and the QA system representing the re-tailer (increasing revenue (mIR) or improving cus-tomer relationship (mICR)) (cf.
Tab.
3).
TheseTable 3: Groups and mixed motive combinationsof user studymixed motives were combined systematically bymeans of scenarios given to users and a manipu-lated mixed motive model of the QA system.
Be-fore interacting with the QA system that was em-bedded into a web-based questionnaire, partici-pants had to opportunity to get to know the QAsystem and interacting with it for the first time(cf.
Fig.
8).
Participants were then asked to posequestions to the QA system and to evaluate gener-ated answers against the background of their mo-tive (e.g., mFP) and the related scenario, e.g.
:?You are searching for a new tablet that shall befunctional regarding standby and storage capac-ity.
A fair price is important; no need for the lat-est innovation.
You do not want to spend a lotof money for the new tablet.
You are price con-scious.
?Participants were told to interact with the QA sys-tem as long as it needed to gain the informationthat was required by the scenario.
Finally, seven-point Likert scales ranging from strongly disagree(1), neither (4) to strongly agree (7) were used toassess the perceived fairness of the dialogue, thenaturalness of the dialogue and the motive satis-faction.
Tab.
4 lists the questionnaire items foreach of these constructs.4.2 ResultsIn summary, 120 subjects participated in the ex-periment.
A complete dataset from 107 partici-pants (58,3% female) with an average age of 24.3(SD=6.9) was considered for analysis.
On av-erage, interactions between participants (N=107)and the QA system covered 5.19 question answerpairs (cf.
example dialogue in appendix A).
556questions were posed by subjects; 35.07% of themwere propositional questions (e.g., ?Is product Aup-to-date??
), 62.41% set questions (e.g., ?Whereis the difference between product A and productB??)
and 2.52% choice questions (e.g., ?Whichproduct is better than product A??
), cf.
Bunt etal.
(2010).Due to the fact that Cronbachs alpha values for allthree multi-item constructs lie clearly above therecommended threshold of .70 (Nunnally, 1967),Figure 5: Subject during interaction with QA sys-tem in user studywhich indicates a good to excellent reliability ofthe scales, we calculated aggregated mean scoresfor each construct.
The descriptive statistics ofthe three core constructs are presented in Tab.
4.554Table 4: Descriptive statistics and results of one-sample t-tests for the empirical core constructs (N=107)Additionally, results of one-sample t-tests are pro-vided to evaluate whether the aggregated scoreslie significantly above or below the neutral scalevalue of 4.
Results indicate that the participantswere undecided with respect to the ?PerceivedNaturalness of Dialogue?
with the QA system.We assume that this is owed to the restricted QAsetting since there were no significant differencesamong the four groups (F(3,104) = 2.06, p = .11)(cf.
Tab.
3).
However, the data support the conclu-sion that participants perceived the dialogue as fairand that they were able to sufficiently satisfy theirmotives.
Assuming rather conflicting motives ofsubject and QA system as given for instance ingroup #4 in Tab.
3, it could be assumed that per-ceived fairness and motive satisfaction should besmaller than in rather congruent motive combi-nations as shown in group #1.
Nonetheless, themean value of the construct ?Perceived Fairnessof Dialogue?
was 5.17 across all groups (signifi-cant above mean value 4) and there were no signif-icant differences between the randomized groups(F(3,104) = 1.59, p = .20).
Furthermore, ?MotiveSatisfaction?
was rated with a mean value of 5.16across all groups (significant above mean value 4)and again, there was not a significant effect of thegroup on motive satisfaction at the .05 level of sig-nificance (F(3,104) = 2.33, p = .08).Overall, this indicates a positive evaluation of theQA system regarding its ability to generate satis-ficing answers despite of mixed motives of inter-locutors.5 ConclusionWe considered dialogues with congruent as well asincongruent interlocutor motives, where dialoguepartners are facing the constant challenge of find-ing a balance between cooperation and competi-tion.
Despite of the overall presence of dialogueswith such mixed motives in everyday life, little at-tention has been given to this topic in text planningin contrast to scrutinized dialogue systems thatsupport dialogues fully aligned with anticipateduser interests.
Focusing on Question-Answering(QA) settings, we introduced a model that formal-izes answer planning as psychological game em-bedded in text planning approaches for supportingfair dialogues under mixed motives.
The modelwas exemplified within a QA sales assistant withdomain-specific world knowledge for conductingsales dialogues.
Due to the fact that fairness is sub-jective per se, we presented results from an empir-ical study (N=107) in which human subjects inter-acted with the QA system in various mixed motivesettings.
Results indicate a positive evaluation ofthe systems performance in planning answers thatsupport fair dialogues despite of mixed motives ofinterlocutors.AcknowledgmentsThis work was partially funded by the Ger-man Federal Ministry for Education and Research(BMBF) under the contract 01IS12030.555ReferencesJames F. Allen, Donna K Byron, Myroslava Dzikovska,George Ferguson, Lucian Galescu, and AmandaStent.
2001.
Toward conversational human-computer interaction.
AI magazine, 22(4):27.Adam Bjorndahl, Joseph Y Halpern, and Rafael Pass.2013.
Language-based games.
In Proc.
of the23rd Int.
Joint Conf.
on Artificial Intelligence, pages2967?2971.Elizabeth Black and Katie Atkinson.
2011.
Choos-ing persuasive arguments for action.
In 10th Int.Conf.
on Autonomous Agents and Multiagent Sys-tems, pages 905?912.Michael Bratman.
1987.
Intention, Plans, and Practi-cal Reason.
Center for the Study of Language andInformation.Harry Bunt and William Black.
2000.
The abc of com-putational pragmatics.
Abduction, Belief and Con-text in Dialogue: Studies in Computational Prag-matics, pages 1?46.Harry Bunt, Jan Alexandersson, Jean Carletta, Jae-Woong Choe, Alex Chengyu Fang, Koiti Hasida,Kiyong Lee, Volha Petukhova, Andrei Popescu-Belis, Laurent Romary, et al 2010.
Towards aniso standard for dialogue act annotation.
In Seventhconference on International Language Resourcesand Evaluation (LREC?10).Philip R. Cohen and Hector J. Levesque.
1990.
Inten-tion is choice with commitment.
Artif.
Intell., 42(2-3):213?261.Tiansi Dong, Ulrich Furbach, Ingo Gl?ockner, and Bj?ornPelzer.
2011.
A natural language question answer-ing system as a participant in human q&a portals.
InProc.
of the 22nd Int.
Joint Conf.
on Artificial Intel-ligence, pages 2430?2435.Michael P. Georgeff, Barney Pell, Martha E. Pollack,Milind Tambe, and Michael Wooldridge.
1998.
Thebelief-desire-intention model of agency.
In Proc.
ofthe 5th Int.
Workshop on Intelligent Agents V, AgentTheories, Architectures, and Languages, pages 1?10.Barbara J. Grosz and Sarit Kraus.
1996.
Collaborativeplans for complex group action.
Artificial Intelli-gence, 86(2):269 ?
357.Barbara J. Grosz and Candace L. Sidner.
1986.
Atten-tion, intentions, and the structure of discourse.
Com-put.
Linguist., 12(3):175?204.Christos Hadjinikolis, Yiannis Siantos, Sanjay Modgil,Elizabeth Black, and Peter McBurney.
2013.
Op-ponent modelling in persuasion dialogues.
In Proc.of the 23rd Int.
Joint Conf.
on Artificial Intelligence,pages 164?170.Takayuki Hasegawa, Nobuhiro Kaji, Naoki Yoshinaga,and Masashi Toyoda.
2013.
Predicting and elicitingaddressee?s emotion in online dialogue.
In Proc.
ofthe 51st Annual Meeting of the Association for Com-putational Linguistics, pages 964?972.Jerry R. Hobbs.
1978.
Why is Discourse Coherent?
:Technical Note 176.
Stanford Research Inst., MenloPark.Eduard H. Hovy, 1991.
Approaches to the planning ofcoherent text, volume 119 of The Kluwer Interna-tional Series in Engineering and Computer Science,pages 83?102.
Springer.Eduard H. Hovy, 1993.
Automated discourse genera-tion using discourse structure relations, pages 341?385.
MIT Press.Anthony Jameson, Bernhard Kipper, Alassane Ndi-aye, Ralph Sch?afer, Joep Simons, Thomas Weis, andDetlev Zimmermann.
1994.
Cooperating to be non-cooperative: The dialog system pracma.
In Proc.
ofKI 1994.
Springer.Willem JM Levelt.
1993.
Speaking: From intention toarticulation, volume 1.
MIT press.Fangtao Li, Yang Gao, Shuchang Zhou, Xiance Si, andDecheng Dai.
2013.
Deceptive answer predictionwith user preference graph.
In ACL (1), pages 1723?1732.
Citeseer.Karen E Lochbaum.
1998.
A collaborative planningmodel of intentional structure.
Comput.
Linguist.,24(4):525?572.William C. Mann and Sandra A. Thompson.
1986.
As-sertions from discourse structure.
In Proc.
of Work-shop on Strategic comp.
natural language, pages257?270.Kathleen R. McKeown.
1985.
Discourse strategies forgenerating natural-language text.
Artificial Intelli-gence, 27(1):1?41.Johanna D. Moore and C?ecile L. Paris.
1993.
Plan-ning text for advisory dialogues: capturing inten-tional and rhetorical information.
Comput.
Lin-guist., 19(4):651?694.John Nash.
1951.
Non-cooperative games.
Annals ofMathematics, 54(2):286?295.Jum C. Nunnally.
1967.
Psychometric Theory.McGraw-Hill, New York.Oxford Dictionaries.
2016.
?fair?.
Oxford UniversityPress (http://oxforddictionaries.com).Michel A. Paquette.
2012.
Speech acts, dialogues andthe common ground.
In FLAIRS Conference.Prashant Parikh.
2010.
Language and Equilibrium.MIT Press.556Henry Prakken.
2006.
Formal systems for persua-sion dialogue.
The Knowledge Engineering Review,21(02):163?188.Anand S. Rao and Michael P. Georgeff.
1995.
Bdiagents: From theory to practice.
In Proc.
of the 1stIntl.
Conf.
on Multiagent Systems (ICMAS), pages312?319.
The MIT Press.Charles Rich and Candace L. Sidner.
1997.
Col-lagen: when agents collaborate with people.
InProceedings of the first international conference onAutonomous agents, AGENTS ?97, pages 284?291,New York, NY, USA.
ACM.Thomas C Schelling.
1960.
The strategy of conflict.Harvard university press.Herbert A. Simon.
1956.
Rational choice and thestructure of the environment.
Psychological review,63(2):129.Jon Scott Stevens, Anton Benz, Sebastian Reue, andRalf Klabunde.
2015.
A strategic reasoning modelfor generating alternative answers.
In ACL (1),pages 534?542.
The Association for Computer Lin-guistics.David Traum and Staffan Larsson, 2003.
The informa-tion state approach to dialogue management, pages325?353.
Springer.David Traum, Stacy C Marsella, Jonathan Gratch, JinaLee, and Arno Hartholt.
2008.
Multi-party, multi-issue, multi-strategy negotiation for multi-modalvirtual agents.
In Intelligent Virtual Agents, pages117?130.
Springer.Kees van Deemter.
2009.
What game theory can do fornlg: the case of vague language.
In Proceedings ofthe 12th European Workshop on Natural LanguageGeneration, pages 154?161.A Example dialogue between user andQA systemIn the following, an example dialogue between auser and the QA system consisting of four ques-tion answer pairs is given.
Questions (Q) aresegmentally constructed by the user.
Answers(A) consisting of text, images, links to webpagesand/or external product offers are generated by theQA system.
(1) Q: Which tablets are available in lowerprice range?
(2) A: In this price range, the following prod-ucts are available: Lenovo Yoga.
Com-pared to other products in this category,Lenovo Yoga offers advantages regardingits price of 198.99e.
Currently, a lot ofcustomers ask for Lenovo Yoga.
Regard-ing the price-performance ratio, the prod-uct is absolutely recommended.
(3) Q: Is there a discount for Lenovo Yoga?
(4) A: For Lenovo Yoga, there is a discount of1%.
The total comes to 197.00e.
LenovoYoga goes with Apple iPod Nano, SonyNWZ-E585B Walkman, Apple iPhone 5Sand Apple iPhone 4S.
(5) Q: How many tablets offer a standby timeof at least 18h?
(6) A: The following tablets offer this feature:Lenovo Yoga.
How about having a look atLenovo Yoga by Lenovo?
(7) Q: Are there any offers for Lenovo Yoga?
(8) A: You can order this product online, asyou can see here:557
