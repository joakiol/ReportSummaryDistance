Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 25?30,Sydney, July 2006. c?2006 Association for Computational LinguisticsModeling Human Sentence Processing Data with a StatisticalParts-of-Speech TaggerJihyun ParkDepartment of LinguisitcsThe Ohio State UniversityColumbus, OH, USApark@ling.ohio-state.eduAbstractIt has previously been assumed in thepsycholinguistic literature that finite-statemodels of language are crucially limitedin their explanatory power by the local-ity of the probability distribution and thenarrow scope of information used by themodel.
We show that a simple computa-tional model (a bigram part-of-speech tag-ger based on the design used by Corleyand Crocker (2000)) makes correct predic-tions on processing difficulty observed in awide range of empirical sentence process-ing data.
We use two modes of evaluation:one that relies on comparison with a con-trol sentence, paralleling practice in hu-man studies; another that measures prob-ability drop in the disambiguating regionof the sentence.
Both are surprisinglygood indicators of the processing difficultyof garden-path sentences.
The sentencestested are drawn from published sourcesand systematically explore five differenttypes of ambiguity: previous studies havebeen narrower in scope and smaller inscale.
We do not deny the limitations offinite-state models, but argue that our re-sults show that their usefulness has beenunderestimated.1 IntroductionThe main purpose of the current study is to inves-tigate the extent to which a probabilistic part-of-speech (POS) tagger can correctly model humansentence processing data.
Syntactically ambigu-ous sentences have been studied in great depth inpsycholinguistics because the pattern of ambigu-ity resolution provides a window onto the humansentence processing mechanism (HSPM).
Primafacie it seems unlikely that such a tagger will beadequate, because almost all previous researchershave assumed, following standard linguistic the-ory, that a formally adequate account of recur-sive syntactic structure is an essential componentof any model of the behaviour.
In this study, wetested a bigram POS tagger on different types ofstructural ambiguities and (as a sanity check) tothe well-known asymmetry of subject and objectrelative clause processing.Theoretically, the garden-path effect is definedas processing difficulty caused by reanalysis.
Em-pirically, it is attested as comparatively slowerreading time or longer eye fixation at a disam-biguating region in an ambiguous sentence com-pared to its control sentences (Frazier and Rayner,1982; Trueswell, 1996).
That is, the garden-patheffect detected in many human studies, in fact, ismeasured through a ?comparative?
method.This characteristic of the sentence processingresearch design is reconstructed in the currentstudy using a probabilistic POS tagging system.Under the assumption that larger probability de-crease indicates slower reading time, the test re-sults suggest that the probabilistic POS taggingsystem can predict reading time penalties at thedisambiguating region of garden-path sentencescompared to that of non-garden-path sentences(i.e.
control sentences).2 ExperimentsA Hidden Markov Model POS tagger based on bi-grams was used.
We made our own implementa-tion to be sure of getting as close as possible tothe design of Corley and Crocker (2000).
Givena word string, w0, w1, ?
?
?
, wn, the tagger calcu-lates the probability of every possible tag path,25t0, ?
?
?
, tn.
Under the Markov assumption, thejoint probability of the given word sequence andeach possible POS sequence can be approximatedas a product of conditional probability and transi-tion probability as shown in (1).
(1) P (w0, w1, ?
?
?
, wn, t0, t1, ?
?
?
, tn)?
?ni=1P (wi|ti) ?
P (ti|ti?1), where n ?
1.Using the Viterbi algorithm (Viterbi, 1967), thetagger finds the most likely POS sequence for agiven word string as shown in (2).
(2) argmaxP (t0, t1, ?
?
?
, tn|w0, w1, ?
?
?
, wn, ?
).This is known technology, see Manning andSchu?tze (1999), but the particular use we makeof it is unusual.
The tagger takes a word stringas an input, outputs the most likely POS sequenceand the final probability.
Additionally, it presentsaccumulated probability at each word break andprobability re-ranking, if any.
Probability re-ranking occurs when a previously less preferredPOS sequence is more favored later.
Note that therunning probability at the beginning of a sentencewill be 1, and will keep decreasing at each wordbreak since it is a product of conditional probabil-ities.We tested the predictability of the model onempirical reading data with the probability de-crease and the presence or absence of probabil-ity re-ranking.
Probability re-ranking occurs whena less preferred POS sequence is selected laterover a temporarily favored sequence.
Adoptingthe standard experimental design used in humansentence processing studies, where word-by-wordreading time or eye-fixation time is compared be-tween an experimental sentence and its controlsentence, this study compares probability at eachword break between a pair of sentences.
Compar-atively faster drop of probability is expected to bea good indicator of comparative processing diffi-culty.
Probability re-ranking, which is a simpli-fied model of the reanalysis process assumed inmany human studies, is also tested as another indi-cator of garden-path effect.
Probability re-rankingwill occur when an initially dispreferred POS sub-sequence becomes the preferred candidate later inthe parse, because it fits in better with later words.The model parameters, P (wi|ti) andP (ti|ti?1), are estimated from a small sec-tion (970,995 tokens,47,831 distinct words) ofthe British National Corpus (BNC), which is a100 million-word collection of British English,both written and spoken, developed by OxfordUniversity Press (Burnard, 1995).
The BNC waschosen for training the model because it is aPOS-annotated corpus, which allows supervisedtraining.
In the implementation we use logprobabilities to avoid underflow, and we reportlog probabilities in the sequel.2.1 HypothesesIf the HSPM is affected by frequency information,we can assume that it will be easier to processevents with higher frequency or probability com-pared to those with lower frequency or probability.Under this general assumption, the overall diffi-culty of a sentence is expected to be measured orpredicted by the mean size of probability decrease.That is, probability will drop faster in garden-pathsentences than in control sentences (e.g.
unam-biguous sentences or ambiguous but non-garden-path sentences).More importantly, the probability decrease pat-tern at disambiguating regions will predict thetrends in the reading time data.
All other things be-ing equal, we might expect a reading time penaltyfor a garden-path region when the size of the prob-ability decrease at the disambiguating region of agarden-path sentence will be greater than that ofcontrol sentences.
This is a simple and intuitiveassumption that can be easily tested.
We couldhave formed the sum over all possible POS se-quences in association with the word strings, butfor the present study we simply used the Viterbipath: justifying this because this is the best single-path approximation to the joint probability.Lastly, re-ranking of POS sequences is expectedto predict reanalysis of lexical categories.
This isbecause re-ranking in the tagger is parallel to re-analysis in human subjects, which is known to becognitively costly.2.2 MaterialsIn this study, five different types of ambigu-ity were tested including Lexical Category am-biguity, Reduced-relative ambiguity (RR am-biguity), Preposition-phrase attachment ambi-guity (PP ambiguity), Direct-object/Sentential-complement ambiguity (DO/SC ambiguity), andClausal Boundary ambiguity.
The following areexample sentences for each ambiguity type, shownwith the ambiguous region italicized and the dis-26ambiguating region bolded.
All of the examplesentences are garden-path sentneces.
(3) Lexical Category ambiguityThe foreman knows that the warehouseprices the beer very modestly.
(4) RR ambiguityThe horse raced past the barn fell.
(5) PP ambiguityKatie laid the dress on the floor onto the bed.
(6) DO/SC ambiguityHe forgot Pam needed a ride with him.
(7) Clausal Boundary ambiguityThough George kept on reading the story re-ally bothered him.The test materials are constructed such thata garden-path sentence and its control sentenceshare exactly the same word sequence except forthe disambiguating word so that extraneous vari-ables such as word frequency effect can be con-trolled.
We inherit this careful design.In this study, a total of 76 sentences weretested: 10 for lexical category ambiguity, 12 forRR ambiguity, 20 for PP attachment ambigu-ity, 16 for DO/SC ambiguity, and 18 for clausalboundary ambiguity.
This set of materials is, toour knowledge, the most comprehensive yet sub-jected to this type of study.
The sentences are di-rectly adopted from various psycholinguistic stud-ies (Frazier, 1978; Trueswell, 1996; Ferreira andHenderson, 1986).As a baseline test case of the tagger, thewell-established asymmetry between subject- andobject-relative clauses was tested as shown in (8).
(8) a.
The editor who kicked the writer fired theentire staff.
(Subject-relative)b.
The editor who the writer kicked fired theentire staff.
(Object-relative)The reading time advantage of subject-relativeclauses over object-relative clauses is robust in En-glish (Traxler et al, 2002) as well as other lan-guages (Mak et al, 2002; Homes et al, 1981).
Forthis test, materials from Traxler et al (2002) (96sentences) are used.3 Results3.1 The Probability Decrease per WordUnambiguous sentences are usually longer thangarden-path sentences.
To compare sentences ofdifferent lengths, the joint probability of the wholesentence and tags was divided by the number ofwords in the sentence.
The result showed thatthe average probability decrease was greater ingarden-path sentences compared to their unam-biguous control sentences.
This indicates thatgarden-path sentences are more difficult than un-ambiguous sentences, which is consistent withempirical findings.Probability decreased faster in object-relativesentences than in subject relatives as predicted.In the psycholinguistics literature, the comparativedifficulty of object-relative clauses has been ex-plained in terms of verbal working memory (Kingand Just, 1991), distance between the gap and thefiller (Bever and McElree, 1988), or perspectiveshifting (MacWhinney, 1982).
However, the testresults in this study provide a simpler account forthe effect.
That is, the comparative difficulty ofan object-relative clause might be attributed to itsless frequent POS sequence.
This account is par-ticularly convincing since each pair of sentences inthe experiment share the exactly same set of wordsexcept their order.3.2 Probability Decrease at theDisambiguating RegionA total of 30 pairs of a garden-path sentenceand its ambiguous, non-garden-path control weretested for a comparison of the probability decreaseat the disambiguating region.
In 80% of the cases,the probability drops more sharply in garden-pathsentences than in control sentences at the criticalword.
The test results are presented in (9) withthe number of test sets for each ambiguous typeand the number of cases where the model correctlypredicted reading-time penalty of garden-path sen-tences.
(9) Ambiguity Type (Correct Predictions/TestSets)a. Lexical Category Ambiguity (4/4)b. PP Attachment Ambiguity (10/10)c. RR Ambiguity (3/4)d. DO/SC Ambiguity (4/6)e. Clausal Boundary Ambiguity (3/6)27?60?55?50?45?40?35LogProbability(a)     PP  Attachment  AmbiguityKatie put the dress on the floor  and / onto  the ...?35?30?25?20?15LogProbability(b)  DO / SC  Ambiguity  (DO Bias)He forgot Susan  but / remembered ...theandthefloortheontoSusanbutrememberedforgotFigure 1: Probability Transition (Garden-Path vs.Non Garden-Path)(a) ?
??
: Non-Garden-Path (Adjunct PP), ?
??
: Garden-Path (Complement PP)(b) ?
?
?
: Non-Garden-Path (DO-Biased, DO-Resolved),?
?
?
: Garden-Path (DO-Biased, SC-Resolved)The two graphs in Figure 1 illustrate the com-parison of probability decrease between a pair ofsentence.
The y-axis of both graphs in Figure 1 islog probability.
The first graph compares the prob-ability drop for PP ambiguity (Katie put the dresson the floor and/onto the bed....) The empirical re-sult for this type of ambiguity shows that readingtime penalty is observed when the second PP, ontothe bed, is introduced, and there is no such effectfor the other sentence.
Indeed, the sharper proba-bility drop indicates that the additional PP is lesslikely, which makes a prediction of a comparativeprocessing difficulty.
The second graph exhibitsthe probability comparison for the DO/SC ambi-guity.
The verb forget is a DO-biased verb andthus processing difficulty is observed when it hasa sentential complement.
Again, this effect wasreplicated here.The results showed that the disambiguatingword given the previous context is more difficultin garden-path sentences compared to control sen-tences.
There are two possible explanations forthe processing difficulty.
One is that the POS se-quence of a garden-path sentence is less probablethan that of its control sentence.
The other accountis that the disambiguating word in a garden-pathsentence is a lower frequency word compared tothat of its control sentence.For example, slower reading time was observedin (10a) and (11a) compared to (10b) and (11b) atthe disambiguating region that is bolded.
(10) Different POS at the Disambiguating Regiona.
Katie laid the dress on the floor onto(?57.80) the bed.b.
Katie laid the dress on the floor after(?55.77) her mother yelled at her.
(11) Same POS at the Disambiguating Regiona.
The umpire helped the child on (?42.77)third base.b.
The umpire helped the child to (?42.23)third base.The log probability for each disambiguating wordis given at the end of each sentence.
As ex-pected, the probability at the disambiguating re-gion in (10a) and (11a) is lower than in (10b) and(11b) respectively.
The disambiguating words in(10) have different POS?s; Preposition in (10a) andConjunction (10b).
This suggests that the prob-abilities of different POS sequences can accountfor different reading time at the region.
In (11),however, both disambiguating words are the samePOS (i.e.
Preposition) and the POS sequencesfor both sentences are identical.
Instead, ?on?and ?to?, have different frequencies and this in-formation is reflected in the conditional probabil-ity P (wordi|state).
Therefore, the slower read-ing time in (11b) might be attributable to the lowerfrequency of the disambiguating word, ?to?
com-pared to ?on?.3.3 Probability Re-rankingThe probability re-ranking reported in Corley andCrocker (2000) was replicated.
The tagger suc-cessfully resolved the ambiguity by reanalysiswhen the ambiguous word was immediately fol-lowed by the disambiguating word (e.g.
With-out her he was lost.).
If the disambiguating worddid not immediately follow the ambiguous region,(e.g.
Without her contributions would be very in-adequate.)
the ambiguity is sometimes incorrectlyresolved.When revision occurred, probability droppedmore sharply at the revision point and at the dis-ambiguation region compared to the control sen-28tences.
When the ambiguity was not correctly re-solved, the probability comparison correctly mod-eled the comparative difficulty of the garden-pathsentencesOf particular interest in this study is RR ambi-guity resolution.
The tagger predicted the process-ing difficulty of the RR ambiguity with probabil-ity re-ranking.
That is, the tagger initially favorsthe main-verb interpretation for the ambiguous -edform, and later it makes a repair when the ambigu-ity is resolved as a past-participle.The RR ambiguity is often categorized as a syn-tactic ambiguity, but the results suggest that theambiguity can be resolved locally and its pro-cessing difficulty can be detected by a finite statemodel.
This suggests that we should be cautiousin assuming that a structural explanation is neededfor the RR ambiguity resolution, and it could bethat similar cautions are in order for other ambi-guities usually seen as syntactic.4 DiscussionThe current study explores Corley and Crocker?smodel(2000) further on the model?s account of hu-man sentence processing data seen in empiricalstudies.
Although there have been studies on aPOS tagger evaluating it as a potential cognitivemodule of lexical category disambiguation, therehas been little work that tests it as a modeling toolof syntactically ambiguous sentence processing.The findings here suggest that a statistical POStagging system is more informative than Crockerand Corley demonstrated.
It has a predictivepower of processing delay not only for lexi-cally ambiguous sentences but also for structurallygarden-pathed sentences.
This model is attractivesince it is computationally simpler and requiresfew statistical parameters.
More importantly, it isclearly defined what predictions can be and can-not be made by this model.
This allows system-atic testability and refutability of the model un-like some other probabilistic frameworks.
Also,the model training and testing is transparent andobservable, and true probability rather than trans-formed weights are used, all of which makes iteasy to understand the mechanism of the proposedmodel.Although the model we used in the currentstudy is not a novelty, the current work largely dif-fers from the previous study in its scope of dataused and the interpretation of the model for humansentence processing.
Corley and Crocker clearlystate that their model is strictly limited to lexicalambiguity resolution, and their test of the modelwas bounded to the noun-verb ambiguity.
How-ever, the findings in the current study play out dif-ferently.
The experiments conducted in this studyare parallel to empirical studies with regard to thedesign of experimental method and the test mate-rial.
The garden-path sentences used in this studyare authentic, most of them are selected from thecited literature, not conveniently coined by theauthors.
The word-by-word probability compar-ison between garden-path sentences and their con-trols is parallel to the experimental design widelyadopted in empirical studies in the form of region-by-region reading or eye-gaze time comparison.In the word-by-word probability comparison, themodel is tested whether or not it correctly pre-dicts the comparative processing difficulty at thegarden-path region.
Contrary to the major claimmade in previous empirical studies, which is thatthe garden-path phenomena are either modeled bysyntactic principles or by structural frequency, thefindings here show that the same phenomena canbe predicted without such structural information.Therefore, the work is neither a mere extendedapplication of Corley and Crocker?s work to abroader range of data, nor does it simply con-firm earlier observations that finite state machinesmight accurately account for psycholinguistic re-sults to some degree.
The current study providesmore concrete answers to what finite state machineis relevant to what kinds of processing difficultyand to what extent.5 ConclusionOur studies show that, at least for the sample oftest materials that we culled from the standard lit-erature, a statistical POS tagging system can pre-dict processing difficulty in structurally ambigu-ous garden-path sentences.
The statistical POStagger was surprisingly effective in modeling sen-tence processing data, given the locality of theprobability distribution.
The findings in this studyprovide an alternative account for the garden-patheffect observed in empirical studies, specifically,that the slower processing times associated withgarden-path sentences are due in part to their rela-tively unlikely POS sequences in comparison withthose of non-garden-path sentences and in part todifferences in the emission probabilities that the29tagger learns.
One attractive future direction isto carry out simulations that compare the evolu-tion of probabilities in the tagger with that in atheoretically more powerful model trained on thesame data, such as an incremental statistical parser(Wang et al, 2004; Roark, 2001).
In so doing wecan find the places where the prediction problemfaced both by the HSPM and the machines thataspire to emulate it actually warrants the greaterpower of structurally sensitive models, using thisknowledge to mine large corpora for future exper-iments with human subjects.We have not necessarily cast doubt on the hy-pothesis that the HSPM makes crucial use of struc-tural information, but we have demonstrated thatmuch of the relevant behavior can be captured ina simple model.
The ?structural?
regularities thatwe observe are reasonably well encoded into thismodel.
For purposes of initial real-time process-ing it could be that the HSPM is using a similarencoding of structural regularities into convenientprobabilistic or neural form.
It is as yet unclearwhat the final form of a cognitively accurate modelalong these lines would be, but it is clear from ourstudy that it is worthwhile, for the sake of clarityand explicit testability, to consider models that aresimpler and more precisely specified than thoseassumed by dominant theories of human sentenceprocessing.AcknowledgmentsThis project was supported by the Cognitive Sci-ence Summer 2004 Research Award at the OhioState University.
We acknowledge support fromNSF grant IIS 0347799.ReferencesT.
G. Bever and B. McElree.
Empty categoriesaccess their antecedents during comprehension.Linguistic Inquiry, 19:35?43, 1988.L Burnard.
Users Guide for the British NationalCorpus.
British National Corpus Consortium,Oxford University Computing Service, 1995.S.
Corley and M. W Crocker.
The Modular Sta-tistical Hypothesis: Exploring Lexical CategoryAmbiguity.
Architectures and Mechanisms forLanguage Processing, M. Crocker, M. Picker-ing.
and C. Charles (Eds.)
Cambridge Univer-sity Press, 2000.F.
Ferreira and J. Henderson.
Use of verb infor-mation in syntactic parsing: Evidence from eyemovements and word-by-word self-paced read-ing.
Journal of Experimental Psychology, 16:555?568, 1986.L.
Frazier.
On comprehending sentences: Syntac-tic parsing strategies.
Ph.D. dissertation, Uni-versity of Massachusetts, Amherst, MA, 1978.L.
Frazier and K. Rayner.
Making and correct-ing errors during sentence comprehension: Eyemovements in the analysis of structurally am-biguous sentences.
Cognitive Psychology, 14:178?210, 1982.V.
M. Homes, J. O?Regan, and K.G.
Evensen.
Eyefixation patterns during the reading of relativeclause sentences.
Journal of Verbal Learningand Verbal Behavior, 20:417?430, 1981.J.
King and M. A.
Just.
Individual differences insyntactic processing: The role of working mem-ory.
Journal of Memory and Language, 30:580?602, 1991.B.
MacWhinney.
Basic syntactic processes.
Lan-guage acquisition; Syntax and semantics, S.Kuczaj (Ed.
), 1:73?136, 1982.W.
M. Mak, Vonk W., and H. Schriefers.
The influ-ence of animacy on relative clause processing.Journal of Memory and Language,, 47:50?68,2002.C.D.
Manning and H. Schu?tze.
Foundations ofStatistical Natural Language Processing.
TheMIT Press, Cambridge, Massachusetts, 1999.B.
Roark.
Probabilistic top-down parsing and lan-guage modeling.
Computational Linguistics, 27(2):249?276, 2001.M.
J. Traxler, R. K. Morris, and R. E. Seely.
Pro-cessing subject and object relative clauses: evi-dence from eye movements.
Journal of Memoryand Language, 47:69?90, 2002.J.
C. Trueswell.
The role of lexical frequencyin syntactic ambiguity resolution.
Journal ofMemory and Language, 35:556?585, 1996.A.
Viterbi.
Error bounds for convolution codes andan asymptotically optimal decoding algorithm.IEEE Transactions of Information Theory, 13:260?269, 1967.W.
Wang, A. Stolcke, and M. P. Harper.
The useof a linguistically motivated language model inconversational speech recognition.
In Proceed-ings of the IEEE International Conference onAcoustic, Speech and Signal Processing, Mon-treal, Canada, 2004.30
