Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 415?423,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsActive Learning for Statistical Phrase-based Machine Translation?Gholamreza Haffari and Maxim Roy and Anoop SarkarSchool of Computing ScienceSimon Fraser UniversityBurnaby, BC, Canada{ghaffar1,maximr,anoop}@cs.sfu.caAbstractStatistical machine translation (SMT) mod-els need large bilingual corpora for train-ing, which are unavailable for some languagepairs.
This paper provides the first serious ex-perimental study of active learning for SMT.We use active learning to improve the qual-ity of a phrase-based SMT system, and showsignificant improvements in translation com-pared to a random sentence selection baseline,when test and training data are taken from thesame or different domains.
Experimental re-sults are shown in a simulated setting usingthree language pairs, and in a realistic situa-tion for Bangla-English, a language pair withlimited translation resources.1 IntroductionStatistical machine translation (SMT) systems havemade great strides in translation quality.
However,high quality translation output is dependent on theavailability of massive amounts of parallel text inthe source and target language.
However, there are alarge number of languages that are considered ?low-density?, either because the population speaking thelanguage is not very large, or even if millions of peo-ple speak the language, insufficient amounts of par-allel text are available in that language.A statistical translation system can be improvedor adapted by incorporating new training data in theform of parallel text.
In this paper, we propose sev-eral novel active learning (AL) strategies for statis-tical machine translation in order to attack this prob-lem.
Conventional techniques for AL of classifiersare problematic in the SMT setting.
Selective sam-pling of sentences for AL may lead to a parallel cor-pus where each sentence does not share any phrase?We would like to thank Chris Callison-Burch for fruitfuldiscussions.
This research was partially supported by NSERC,Canada (RGPIN: 264905) and by an IBM Faculty Award to thethird author.pairs with the others.
Thus, new sentences cannotbe translated since we lack evidence for how phrasepairs combine to form novel translations.
In this pa-per, we take the approach of exploration vs. exploita-tion: where in some cases we pick sentences thatare not entirely novel to improve translation statis-tics, while also injecting novel translation pairs toimprove coverage.There may be evidence to show that AL is use-ful even when we have massive amounts of paralleltraining data.
(Turchi et al, 2008) presents a com-prehensive learning curve analysis of a phrase-basedSMT system, and one of the conclusions they drawis, ?The first obvious approach is an effort to iden-tify or produce data sets on demand (active learning,where the learning system can request translations ofspecific sentences, to satisfy its information needs).
?Despite the promise of active learning for SMTthere has been very little experimental work pub-lished on this issue (see Sec.
5).
In this paper, wemake several novel contributions to the area of ac-tive learning for SMT:?
We use a novel framework for AL, which to ourknowledge has not been used in AL experiments be-fore.
We assume a small amount of parallel text anda large amount of monolingual source language text.Using these resources, we create a large noisy par-allel text which we then iteratively improve usingsmall injections of human translations.?
We provide many useful and novel features use-ful for AL in SMT.
In translation, we can leverage awhole new set of features that were out of reach forclassification systems: we devise features that lookat the source language, but also devise features thatmake an estimate of the potential utility of transla-tions from the source, e.g.
phrase pairs that could beextracted.?
We show that AL can be useful in domain adapta-tion.
We provide the first experimental evidence inSMT that active learning can be used to inject care-415fully selected translations in order to improve SMToutput in a new domain.?
We compare our proposed features to a random se-lection baseline in a simulated setting for three lan-guage pairs.
We also use a realistic setting: using hu-man expert annotations in our AL system we createan improved SMT system to translate from Banglato English, a language pair with very few resources.2 An Active Learning Framework for SMTStarting from an SMT model trained initially onbilingual data, the problem is to minimize the hu-man effort in translating new sentences which willbe added to the training data to make the retrainedSMT model achieves a certain level of performance.Thus, given a bitext L := {(fi, ei)} and a mono-lingual source text U := {fj}, the goal is to selecta subset of highly informative sentences from U topresent to a human expert for translation.
Highly in-formative sentences are those which, together withtheir translations, help the retrained SMT systemquickly reach a certain level of translation quality.This learning scenario is known as active learningwith Selective Sampling (Cohn et al, 1994).Algorithm 1 describes the experimental setup wepropose for active learning.
We train our initial MTsystem on the bilingual corpus L, and use it to trans-late all monolingual sentences in U .
We denote sen-tences in U together with their translations as U+(line 4 of Algorithm 1).
Then we retrain the SMTsystem on L?U+ and use the resulting model to de-code the test set.
Afterwards, we select and removea subset of highly informative sentences from U ,and add those sentences together with their human-provided translations to L. This process is continuediteratively until a certain level of translation quality,which in our case is measured by the BLEU score, ismet.
In the baseline, against which we compare oursentence selection methods, the sentences are cho-sen randomly.When (re-)training the model, two phrase tablesare learned: one from L and the other one fromU+.
The phrase table obtained from U+ is addedas a new feature function in the log-linear trans-lation model.
The alternative is to ignore U+ asin a conventional AL setting, however, in our ex-periments we have found that using more bilingualdata, even noisy data, results in better translations.Algorithm 1 AL-SMT1: Given bilingual corpus L, and monolingual cor-pus U .2: MF?E = train(L, ?
)3: for t = 1, 2, ... do4: U+ = translate(U,MF?E)5: Select k sentence pairs from U+, and ask ahuman for their true translations.6: Remove the k sentences from U , and add thek sentence pairs (translated by human) to L7: MF?E = train(L,U+)8: Monitor the performance on the test set T9: end forPhrase tables from U+ will get a 0 score in mini-mum error rate training if they are not useful, so ourmethod is more general.
Also, this method has beenshown empirically to be more effective (Ueffing etal., 2007b) than (1) using the weighted combinationof the two phrase tables from L and U+, or (2) com-bining the two sets of data and training from the bi-text L ?
U+.The setup in Algorithm 1 helps us to investigatehow to maximally take advantage of human effort(for sentence translation) when learning an SMTmodel from the available data, that includes bilin-gual and monolingual text.3 Sentence Selection StrategiesOur sentence selection strategies can be divided intotwo categories: (1) those which are independent ofthe target language and just look into the source lan-guage, and (2) those which also take into account thetarget language.
From the description of the meth-ods, it will be clear to which category they belong to.We will see in Sec.
4 that the most promising sen-tence selection strategies belong to the second cate-gory.3.1 The Utility of Translation UnitsPhrases are basic units of translation in phrase-basedSMT models.
The phrases potentially extractedfrom a sentence indicate its informativeness.
Themore new phrases a sentence can offer, the moreinformative it is.
Additionally phrase translationprobabilities need to be estimated accurately, whichmeans sentences that contain rare phrases are alsoinformative.
When selecting new sentences for hu-416man translation, we need to pay attention to thistradeoff between exploration and exploitation, i.e.selecting sentences to discover new phrases vs es-timating accurately the phrase translation probabil-ities.
A similar argument can be made that empha-sizes the importance of words rather than phrases forany SMT model.
Also we should take into accountthat smoothing is a means for accurate estimation oftranslation probabilities when events are rare.
In ourwork, we focus on methods that effectively expandthe lexicon or set of phrases of the model.3.1.1 Phrases (Geom-Phrase, Arith-Phrase)1The more frequent a phrase is in the unlabeleddata, the more important it is to know its translation;since it is more likely to occur in the test data (es-pecially when the test data is in-domain with respectto unlabeled data).
The more frequent a phrase is inthe labeled data, the more unimportant it is; sinceprobably we have observed most of its translations.Based on the above observations, we measure theimportance score of a sentence as:?pg(s) :=[ ?x?XpsP (x|U)P (x|L)] 1|Xps | (1)where Xps is the set of possible phrases that sentences can offer, and P (x|D) is the probability of observ-ing x in the data D: P (x|D) = Count(x)+?Px?XpDCount(x)+?
.The score (1) is the averaged probability ratio ofthe set of candidate phrases, i.e.
the probability ofthe candidate phrases under a probabilistic phrasemodel based on U divided by that based on L. In ad-dition to the geometric average in (1), we may alsoconsider the arithmetic average score:?pa(s) := 1|Xps |?x?XpsP (x|U)P (x|L) (2)Note that (1) can be re-written as1|Xps |?x?Xps log P (x|U)P (x|L) in the logarithm space,which is similar to (2) with the difference ofadditional log.In parallel data L, phrases are the ones which areextracted by the usual phrase extraction algorithm;but what are the candidate phrases in the unlabeled1The names in the parentheses are short names used to iden-tify the method in the experimental results.data?
Considering the k-best list of translations cantell us the possible phrases the input sentence mayoffer.
For each translation, we have access to thephrases used by the decoder to produce that output.However, there may be islands of out-of-vocabulary(OOV) words that were not in the phrase table andnot translated by the decoder as a phrase.
We grouptogether such groups of OOV words to form an OOVphrase.
The set of possible phrases we extract fromthe decoder output contain those coming from thephrase table (from labeled data L) and those comingfrom OOVs.
OOV phrases are also used in our com-putation, where P (x | L) for an OOV phrase x isthe uniform probability over all OOV phrases.3.1.2 n-grams (Geom n-gram, Arith n-gram)As an alternative to phrases, we consider n-gramsas basic units of generalization.
The resulting scoreis the weighted combination of the n-gram basedscores:?Ng (s) :=N?n=1wn|Xns |?x?Xnslog P (x|U, n)P (x|L, n) (3)where Xns denotes n-grams in the sentence s, andP (x|D, n) is the probability of x in the set of n-grams in D. The weights wn adjust the importanceof the scores of n-grams with different lengths.
Inaddition to taking geometric average, we also con-sider the arithmetic average:?Na (s) :=N?n=1wn|Xns |?x?XnsP (x|U, n)P (x|L, n) (4)As a special case when N = 1, the score motivatesselecting sentences which increase the number ofunique words with new words appearing with higherfrequency in U than L.3.2 Similarity to the Bilingual Training Data(Similarity)The simplest way to expand the lexicon set is tochoose sentences from U which are as dissimilaras possible to L. We measure the similarity usingweighted n-gram coverage (Ueffing et al, 2007b).3.3 Confidence of Translations (Confidence)The decoder produces an output translation e usingthe probability p(e | f).
This probability can be417treated as a confidence score for the translation.
Tomake the confidence score for sentences with dif-ferent lengths comparable, we normalize using thesentence length (Ueffing et al, 2007b).3.4 Feature Combination (Combined)The idea is to take into account the information fromseveral simpler methods, e.g.
those mentioned inSec.
3.1?3.3, when producing the final ranking ofsentences.
We can either merge the output rankingsof those simpler models2, or use the scores gener-ated by them as input features for a higher levelranking model.
We use a linear model:F (s) = ?k?k?k(s) (5)where ?k are the model parameters, and ?k(.)
arethe feature functions from Sections 3.1?3.3, e.g.confidence score, similarity to L, and score for theutility of translation units.
Using 20K of Spanishunlabeled text we compared the r2 correlation co-efficient between each of these scores which, apartfrom the arithmetic and geometric versions of thesame score, showed low correlation.
And so the in-formation they provide should be complementary toeach other.We train the parameters in (5) using two bilingualdevelopment sets dev1 and dev2, the sentences indev1 can be ranked with respect to the amount bywhich each particular sentence improves the BLEUscore of the retrained3 SMT model on dev2.
Havingthis ranking, we look for the weight vector whichproduces the same ordering of sentences.
As an al-ternative to this method (or its computationally de-manding generalization in which instead of a singlesentence, several sets of sentences of size k are se-lected and ranked) we use a hill climbing search onthe surface of dev2?s BLEU score.
For a fixed valueof the weight vector, dev1 sentences are ranked andthen the top-k output is selected and the amountof improvement the retrained SMT system gives ondev2?s BLEU score is measured.
Starting from arandom initial value for ?k?s, we improve one di-mension at a time and traverse the discrete grid2To see how different rankings can be combined, see (Re-ichart et al, 2008) which proposes this for multi-task AL.3Here the retrained SMT model is the one learned by addinga particular sentence from dev1 into L.placed on the values of the weight vector.
Startingwith a coarse grid, we make it finer when we getstuck in local optima during hill climbing.3.5 Hierarchical Adaptive Sampling (HAS)(Dasgupta and Hsu, 2008) propose a technique forsample selection that, under certain settings, is guar-anteed to be no worse than random sampling.
Theirmethod exploits the cluster structure (if there is any)in the unlabeled data.
Ideally, querying the labelof only one of the data points in a cluster wouldbe enough to determine the label of the other datapoints in that cluster.
Their method requires that thedata set is provided in the form of a tree represent-ing a hierarchical clustering of the data.
In AL forSMT, such a unique clustering of the unlabeled datawould be inappropriate or ad-hoc.
For this reason,we present a new algorithm inspired by the ratio-nale provided in (Dasgupta and Hsu, 2008) that canbe used in our setting, where we construct a tree-based partition of the data dynamically4 .
This dy-namic tree construction allows us to extend the HASalgorithm from classifiers to the SMT task.The algorithm adaptively samples sentences fromU while building a hierarchical clustering of the sen-tences in U (see Fig.
1 and Algorithm 2).
At any it-eration, first we retrain the SMT model and translateall monolingual sentences.
At this point one mono-lingual set of sentences represented by one of thetree leaves is chosen for further partitioning: a leafH is chosen which has the lowest average decoderconfidence score for its sentence translations.
Wethen rank all sentences in H based on their similar-ity to L and put the top ?|H| sentences in H1 andthe rest in H2.
To select K sentences, we randomlysample ?K sentences from H1 and (1 ?
?
)K sen-tences from H2 and ask a human for their transla-tions.3.6 Reverse Model (Reverse)While a translation system MF?E is built from lan-guage F to language E, we also build a translationsystem in the reverse direction ME?F .
To mea-sure how informative a monolingual sentence f is,we translate it to English by MF?E and then project4The dynamic nature of the hierarchy comes from two fac-tors: (1) selecting a leaf node for splitting, and (2) splitting aleaf node based on its similarity to the growing L.418Algorithm 2 Hierarchical-Adaptive-Sampling1: MF?E = train(L, ?
)2: Initialize the tree T by setting its root to U3: v := root(T )4: for t = 1, 2, ... do5: // rank and split sentence in vX1, X2 := Partition(L, v, ?
)6: // randomly sample and remove sents from XiY1, Y2 := Sampling(X1, X2, ?
)7: // make Xi children of node v in the tree TT := UpdateTree(X1, X2, v, T )8: // Y +i has sents in Yi together with human transL := L ?
Y +1 ?
Y +29: MF?E = train(L,U)10: for all leaves l ?
T do11: Z[l] := Average normalized confidence scoresof sentence translations in l12: end for13: v := BestLeaf(T, Z)14: Monitor the performance on the test set15: end forH1H2H22 H21H := UFigure 1: Adaptively sampling the sentences while con-structing a hierarchical clustering of U .the translation back to French using ME?F .
Denotethis reconstructed version of the original Frenchsentence by f?
.
Comparing f with f?
using BLEU (orother measures) can tell us how much informationhas been lost due to our direct and/or reverse transla-tion systems.
The sentences with higher informationloss are selected for translation by a human.4 ExperimentsThe SMT system we applied in our experiments isPORTAGE (Ueffing et al, 2007a).
The models (orfeatures) which are employed by the decoder are:(a) one or several phrase table(s), which model thetranslation direction p(f | e), (b) one or severaln-gram language model(s) trained with the SRILMtoolkit (Stolcke, 2002); in the experiments reportedhere, we used 4-gram models on the NIST data,and a trigram model on EuroParl, (c) a distortioncorpus language use sentencesEuroParl Fr,Ge,Spin-dom L 5Kin-dom U 20Kin-dom dev 2Kin-dom test 2KSee Sec.
4.2 Banglain-dom L 11Kin-dom U 20Kin-dom dev 450in-dom test 1KHansards Fr out-dom L 5KTable 1: Specification of different data sets we will use inexperiments.
The target language is English in the bilin-gual sets, and the source languages are either French (Fr),German (Ge), Spanish (Sp), or Bangla.model which assigns a penalty based on the numberof source words which are skipped when generatinga new target phrase, and (d) a word penalty.
Thesedifferent models are combined log-linearly.
Theirweights are optimized w.r.t.
BLEU score using thealgorithm described in (Och, 2003).
This is done ona development corpus which we will call dev1 in thispaper.The weight vectors in n-gram and similaritymethods are set to (.15, .2, .3, .35) to emphasizelonger n-grams.
We set ?
= ?
= .35 for HAS,and use the 100-best list of translations when identi-fying candidate phrases while setting the maximumphrase length to 10.
We set ?
= .5 to smooth proba-bilities when computing scores based on translationunits.4.1 Simulated Low Density Language PairsWe use three language pairs (French-English,German-English, Spanish-English) to compare all ofthe proposed sentence selection strategies in a simu-lated AL setting.
The training data comes from Eu-roParl corpus as distributed for the shared task inthe NAACL 2006 workshop on statistical machinetranslation (WSMT06).
For each language pair, thefirst 5K sentences from its bilingual corpus consti-tute L, and the next 20K sentences serve as U wherethe target side translation is ignored.
The size of Lwas taken to be 5K in order to be close to a real-istic setting in SMT.
We use the first 2K sentencesfrom the test sets provided for WSMT06, which arein-domain, as our test sets.
The corpus statistics aresummarized in Table 1.
The results are shown inFig.
2.
After building the initial MT systems, we se-4190 5 10 15 20 250.190.1950.20.2050.210.2150.220.225Added Sentences (multiple of 200)French to EnglishHASReverseConfidenceArith PhraseGeom PhraseRandom0 5 10 15 20 250.1450.150.1550.160.1650.170.175Added Sentences (multiple of 200)German to EnglishHASReverseConfidenceArith PhraseGeom PhraseRandom0 5 10 15 20 250.20.2050.210.2150.220.2250.23Added Sentences (multiple of 200)Spanish to EnglishHASReverseConfidenceArith PhraseGeom PhraseRandom0 5 10 15 20 250.190.1950.20.2050.210.2150.220.225Added Sentences (multiple of 200)French to EnglishGeom 4?gramGeom 1?gramSimilarityCombinedRandom0 5 10 15 20 250.1450.150.1550.160.1650.170.175Added Sentences (multiple of 200)German to EnglishGeom 4?gramGeom 1?gramSimilarityCombinedRandom0 5 10 15 20 250.20.2050.210.2150.220.2250.23Added Sentences (multiple of 200)Spanish to EnglishGeom 4?gramGeom 1?gramSimilarityCombinedRandomFigure 2: BLEU scores for different sentence selection strategies per iteration of the AL algorithm.
Plots at the topshow the performance of sentence selection methods which depend on the target language in addition to the sourcelanguage (hierarchical adaptive sampling, reverse model, decoder confidence, average and geometric phrase-basedscore), and plots at the bottom show methods which are independent of the target language (geometric 4-gram and1-gram, similarity to L, and random sentence selection baseline).lect and remove 200 sentence from U in each itera-tion and add them together with translations to L for25 iterations.
Each experiment which involves ran-domness, such as random sentence selection base-line and HAS, is averaged over three independentruns.
Selecting sentences based on the phrase-basedutility score outperforms the strong random sentenceselection baseline and other methods (Table 2).
De-coder confidence performs poorly as a criterion forsentence selection in this setting, and HAS whichis built on top of confidence and similarity scoresoutperforms both of them.
Although choosing sen-tences based on their n-gram score ignores the re-lationship between source and target languages, thismethods outperforms random sentence selection.4.2 Realistic Low Density Language PairWe apply active learning to the Bangla-English ma-chine translation task.
Bangla is the official lan-guage of Bangladesh and second most spoken lan-guage in India.
It has more than 200 million speak-ers around the world.
However, Bangla has fewavailable language resources, and lacks resourcesfor machine translation.
In our experiments, we usetraining data provided by the Linguistic Data Con-sortium5 containing ?11k sentences.
It containsnewswire text from the BBC Asian Network andsome other South Asian news websites.
A bilingualBangla-English dictionary collected from differentwebsites was also used as part of the training setwhich contains around 85k words.
Our monolingualcorpus6 is built by collecting text from the ProthomAlo newspaper, and contains all the news availablefor the year of 2005 ?
including magazines and pe-riodicals.
The corpus has 18,067,470 word tokensand 386,639 word types.
For our language model weused data from the English section of EuroParl.
The5LDC Catalog No.
: LDC2008E29.6Provided by the Center for Research on Bangla LanguageProcessing, BRAC University, Bangladesh.420development set used to optimize the model weightsin the decoder, and test set used for evaluation wastaken from the same LDC corpus mentioned above.We applied our active learning framework to theproblem of creating a larger Bangla-English paralleltext resource.
The second author is a native speakerof Bangla and participated in the active learningloop, translating 100 sentences in each iteration.
Wecompared a smaller number of alternative methodsto keep the annotation cost down.
The results areshown in Fig.
3.
Unlike the simulated setting, in thisrealistic setting for AL, adding more human transla-tion does not always result in better translation per-formance7.
Geom 4-gram and Geom phrase are thefeatures that prove most useful in extracting usefulsentences for the human expert to translate.4.3 Domain AdaptationIn this section, we investigate the behavior of theproposed methods when unlabeled data U and testdata T are in-domain and parallel training text L isout-of-domain.We report experiments for French to Englishtranslation task where T and development sets arethe same as those in section 4.1 but the bilingualtraining data come from Hansards8 corpus.
The do-main is similar to EuroParl, but the vocabulary isvery different.
The results are shown in Fig.
4, andsummarized in Table 3.
As expected, unigram basedsentence selection performs well in this scenariosince it quickly expands the lexicon set of the bilin-gual data in an effective manner (Fig 5).
By ignor-7This is likely due to the fact that the translator in the ALloop was not the same as the original translator for the labeleddata.8The transcription of official records of the Cana-dian Parliament as distributed at http://www.isi.edu/natural-language/download/hansardLang.
Geom Phrase Random (baseline)Pair bleu% per% wer% bleu% per% wer%Fr-En 22.49 27.99 38.45 21.97 28.31 38.80Gr-En 17.54 31.51 44.28 17.25 31.63 44.41Sp-En 23.03 28.86 39.17 23.00 28.97 39.21Table 2: Phrase-based utility selection is comparedwith random sentence selection baseline with respect toBLEU, wer (word error rate), and per (position indepen-dent word error rate) across three language pairs.method bleu% per% wer%Geom 1-gram 14.92 34.83 46.06Confidence 14.74 35.02 46.11Random (baseline) 14.11 35.28 46.47Table 3: Comparison of methods in domain adaptationscenario.
The bold numbers show statistically significantimprovement with respect to the baseline.ing sentences for which the translations are alreadyknown based on L, it does not waste resources.
Onthe other hand, it raises the importance of high fre-quency words in U .
Interestingly, decoder confi-dence is also a good criterion for sentence selectionin this particular case.5 Related WorkDespite the promise of active learning for SMTfor domain adaptation and low-density/low-resourcelanguages, there has been very little work publishedon this issue.
A Ph.D. proposal by Chris Callison-Burch (Callison-burch, 2003) lays out the promiseof AL for SMT and proposes some algorithms.However, the lack of experimental results means thatperformance and feasibility of those methods can-not be compared to ours.
(Mohit and Hwa, 2007)provide a technique to classify phrases as difficultto translate (DTP), and incorporate human transla-tions for these phrases.
Their approach is differ-ent from AL: they use human translations for DTPsin order to improve translation output in the de-coder.
There is work on sampling sentence pairs forSMT (Kauchak, 2006; Eck et al, 2005) but the goal0 1 2 3 4 50.050.0510.0520.0530.0540.0550.0560.057Added Sentences (multiple of 100)BLEUscoreBangla to EnglishGeom PhraseHASGeom 4?gramRandomFigure 3: Improving Bangla to English translation perfor-mance using active learning.4210 5 10 15 20 250.1250.130.1350.140.1450.15Added Sentences (multiple of 200)BLEUscoreFrench to EnglishHASReverseConfidenceArith PhraseGeom PhraseRandom0 5 10 15 20 250.1250.130.1350.140.1450.15Added Sentences (multiple of 200)BLEUscoreFrench to EnglishGeom 4?gramGeom 1?gramCombinedRandomFigure 4: Performance of different sentence selectionmethods for domain adaptation scenario.has been to limit the amount of training data in orderto reduce the memory footprint of the SMT decoder.To compute this score, (Eck et al, 2005) use n-gramfeatures very different from the n-gram features pro-posed in this paper.
(Kato and Barnard, 2007) imple-ment an AL system for SMT for language pairs withlimited resources (En-Xhosa, En-Zulu, En-Setswanaand En-Afrikaans), but the experiments are on a verysmall simulated data set.
The only feature used isthe confidence score of the SMT system, which weshowed in our experiments is not a reliable feature.6 ConclusionsWe provided a novel active learning framework forSMT which utilizes both labeled and unlabeled data.Several sentence selection strategies were proposedand comprehensively compared across three simu-lated language pairs and a realistic setting of Bangla-English translation with scarce resources.
Basedon our experiments, we conclude that paying atten-tion to units of translations, i.e.
words and candi-date phrases in particular, is essential to sentence se-Fr2En Ge2En Sp2En Ha2EnAvg # of trans1.30 1.26 1.27 1.301.24 1.25 1.20 1.261.22 1.23 1.19 1.241.22 1.24 1.19 1.24Avg phrase len2.85 2.56 2.85 2.853.47 2.74 3.54 3.173.95 3.34 3.94 3.483.58 2.94 3.63 3.36# of phrases27,566 29,297 30,750 27,56678,026 64,694 93,593 108,78779,343 63,191 93,276 115,17777,394 65,198 94,597 115,671# unique events31,824 33,141 34,937 31,824103,124 84,512 125,094 117,21486,210 69,357 100,176 127,31484,787 72,280 101,636 128,912Table 4: Average number of english phrases per sourcelanguage phrase, average length of the source languagephrases, number of source language phrases, and numberof phrase pairs which has been seen once in the phrase ta-bles across three language pairs (French text taken fromHansard is abbreviated by ?Ha?).
From top to bottomin each row, the numbers belong to: before starting AL,and after finishing AL based on ?Geom Phrase?, ?Confi-dence?, and ?Random?.lection in AL-SMT.
Increasing the coverage of thebilingual training data is important but is not theonly factor (see Table 4 and Fig.
5).
For exam-ple, decoder confidence for sentence selection haslow coverage (in terms of new words), but performswell in the domain adaptation scenario and performspoorly otherwise.
In future work, we plan to ex-plore selection methods based on potential phrases,adaptive sampling using features other than decoderconfidence and the use of features from confidenceestimation in MT (Ueffing and Ney, 2007).0 5 10 15 20 2520004000600080001000012000140001600018000Added Sentences (multiple of 200)Number of NewWordsFrench to EnglishGeom 4?gramHASReverseConfidenceSimilarityRandomGeom 1?gramGeom PhraseFigure 5: Number of words in domain adaptation sce-nario.422ReferencesChris Callison-burch.
2003.
Active learning for statisti-cal machine translation.
In PhD Proposal, EdinburghUniversity.David Cohn, Les Atlas, and Richard Ladner.
1994.
Im-proving generalization with active learning.
In Ma-chine Learning Journal.Sanjoy Dasgupta and Daniel Hsu.
2008.
Hierarchicalsampling for active learning.
In proceedings of Inter-national Conference on Machine Learning.Matthias Eck, Stephan Vogel, and Alex Waibel.
2005.Low cost portability for statistical machine translationbased in n-gram frequency and tf-idf.
In proceedingsof International Workshop on Spoken Language Trans-lation (IWSLT).R.S.M.
Kato and E. Barnard.
2007.
Statistical transla-tion with scarce resources: a south african case study.SAIEE Africa Research Journal, 98(4):136?140, De-cember.David Kauchak.
2006.
Contribution to research on ma-chine translation.
In PhD Thesis, University of Cali-fornia at San Diego.Behrang Mohit and Rebecca Hwa.
2007.
Localizationof difficult-to-translate phrases.
In proceedings of the2nd ACL Workshop on Statistical Machine Transla-tions.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In proceedings ofAnnual Meeting of the Association for ComputationalLinguistics (ACL).Roi Reichart, Katrin Tomanek, Udo Hahn, and Ari Rap-poport.
2008.
Multi-task active learning for linguisticannotations.
In proceedings of Annual Meeting of theAssociation for Computational Linguistics (ACL).Andreas Stolcke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
In proceedings of Interna-tional Conference on Spoken Language Processing(ICSLP).Marco Turchi, Tijl De Bie, and Nello Cristianini.
2008.Learning performance of a machine translation sys-tem: a statistical and computational analysis.
In pro-ceedings of the Third Workshop on Statistical MachineTranslation.
Association for Computational Linguis-tics (ACL).Nicola Ueffing and Hermann Ney.
2007.
Word-levelconfidence estimation for machine translation.
Com-putational Linguistics, 33(1):9?40.N.
Ueffing, M. Simard, S. Larkin, and J. H. Johnson.2007a.
NRC?s Portage system for WMT 2007.
InProc.
ACL Workshop on SMT.Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar.2007b.
Transductive learning for statistical machinetranslation.
In proceedings of Annual Meeting of theAssociation for Computational Linguistics (ACL).423
