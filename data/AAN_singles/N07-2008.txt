Proceedings of NAACL HLT 2007, Companion Volume, pages 29?32,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsA Fast Method for Parallel Document IdentificationJessica Enright and Grzegorz KondrakDepartment of Computing ScienceUniversity of AlbertaEdmonton, AB, T6G 2E8, Canada{enright,kondrak}@cs.ualberta.caAbstractWe present a fast method to identifyhomogeneous parallel documents.
Themethod is based on collecting counts ofidentical low-frequency words betweenpossibly parallel documents.
The candi-date with the most shared low-frequencywords is selected as the parallel document.The method achieved 99.96% accuracywhen tested on the EUROPARL corpusof parliamentary proceedings, failing onlyin anomalous cases of truncated or oth-erwise distorted documents.
While otherwork has shown similar performance onthis type of dataset, our approach pre-sented here is faster and does not requiretraining.
Apart from proposing an effi-cient method for parallel document iden-tification in a restricted domain, this pa-per furnishes evidence that parliamentaryproceedings may be inappropriate for test-ing parallel document identification sys-tems in general.1 IntroductionParallel documents are documents that are mutualtranslations.
There are a number of reasons onemight want to either identify parallel documents, orconfirm that a pair of documents are in fact parallel.Most prominently, one could use pairs of automat-ically detected parallel documents to build parallelcorpora.
Parallel corpora have many uses in naturallanguage processing, and their dearth has been iden-tified as a major bottleneck (Diab, 2004).
They havebeen employed in word sense disambiguation (Diaband Resnik, 2002), automatic construction of bilin-gual dictionaries (McEwan et al, 2002), and induc-ing statistical machine translation models (Koehn etal., 2003).
In addition to building parallel corpora,one can envision other uses for parallel documentidentification, such as cross-language informationretrieval (Chen and Nie, 2000).Much work on identifying pairs of parallel doc-uments focuses on the use of external features ofthe documents, rather than content.
Chen and Nie(2000) describe PTMiner, a cross-language informa-tion retrieval system.
They consider a number offactors in determining if a pair of documents are par-allel, including document size, date, URL, and lan-guage flag.
For example, if a document is availablein both French and English, it is common for theFrench document?s URL to contain .fr and the En-glish to contain .en In addition to these measures,they consider website structure.McEwan et al (2002) find parallel documentswhich they then use to automatically build a bilin-gual dictionary.
In their system, they first gener-ate a set of candidate pairs based on manual selec-tion, or advanced search engine use.
They then filterthe pairs to remove non-parallel pairs.
First, theyconfirm that one of each pair is in each of the de-sired languages using tuned lists of stop-words, thenthey compare the documents based on length in to-kens, and HTML markup.
Resnik and Smith (2003)use a similar idea of candidates and filters in theirSTRAND system.
STRAND filters the documentsbased on aligning them by length in tokens and lo-cation of HTML markup in the documents.Apart form the work done on external metrics,Patry and Langlais (2005) investigated a number ofcontent-based metrics.
They consider several docu-29ment features, including the numbers, proper namesand punctuation contained within, as well as docu-ment length, and alignment scores between candi-date pairs.
The features are then used to train anAda-Boost classifier, which makes decisions basedon edit-distance and cosine scores.
They experi-mented with several combinations of features, oneof which achieved 100% correctness when tested on487 out of 488 parallel documents that constitute theEnglish-Spanish portion of the EUROPARL corpus.They conclude that a bag-of-words approach is infe-rior to one that considers feature order.In this work, we demonstrate that a much sim-pler approach can achieve equally good results.
Ourmethod does not depend on hand-coded linguisticknowledge and requires no training data, which maybe unavailable for some language pairs.
In addition,thanks to its simplicity, our method is very fast.2 Parallel document identificationOne can consider the parallel document identifica-tion problem to be as follows:Given one document dA in language A,and a set of documents DB in language B,identify exactly one document dB ?
DBthat is the parallel, or translation, of dA.We initially designed a cognate-based approach tothe problem, which employed a combination of or-thographic word similarity measures to identify cog-nates such as French nombres and English numbersbetween documents.
In order to make the methodcomputationally feasible, potential cognates werefiltered based on word order, location in the docu-ment, frequency, and length.
However, we foundthat a faster and simpler procedure, which is de-scribed below, performed extremely well, eliminat-ing the need for a more sophisticated approach.We propose to identify parallel documents bycounting the number of unique words that appear inboth documents.
The documents are treated as bagsof words, that is, their word order is not considered.From each document, we extract a set of words thatare at least 4 characters long and have frequency 1.Given a document in language A, we select the doc-ument in language B that shares the largest numberof these words.
An implementation based on hashtables ensures speed.Since identical words of frequency 1 are almostcertainly cognates, this method can be seen as anextremely conservative approach to cognate detec-tion.
In practice, most of unique identical words areproper nouns.3 Experimental setupWe performed experiments on two different par-liamentary corpora.
The English-French CanadianHansards from the 36th sitting of the CanadianParliament (Germann, 2001) was selected as thedevelopment dataset.
In testing on the CanadianHansards, English was used as the Language A, andFrench as the Language B.
Our approach correctlyidentified all parallel documents.In order to allow for a direct comparison with thework of Patry and Langlais (2005), we adopted theEUROPARL corpus of parliamentary proceedings(Koehn, 2002) as our test dataset.
However, ratherthan focusing on a single language pair, we per-formed tests on all 110 language pairs involving thefollowing 11 languages: German, English, Greek,Finnish, Swedish, Dutch, French, Danish, Italian,Spanish and Portuguese.
Diacritics were strippedfrom the documents of all languages.
Since Greekutilizes a different script from the rest of the docu-ments.
we used a straightforward context-free map-ping to convert every Greek character to its nearestroman equivalent.Some of the 488 documents available in EU-ROPARL were missing in Finnish, Swedish, Greekand Danish.
In particular, Greek had 392 docu-ments, Danish had 487 documents, and Swedish andFinnish had 433 each.
In such cases, the parallelsof those missing documents were excluded from thelanguage A for that test.The EUROPARL documents range in size from114 tokens (13 lines) to 138,557 tokens (11,101lines).
The mean number of tokens is 59,387 (2,826lines).
Each orientation of each language pair wastested.
For example, for the language pair English-Dutch, tests were run twice - once with English aslanguage A and Dutch as language B, and oncethe other way around.
The results for a given lan-guage pair are not necessarily symmetric.
Hence-forth when referring to a language pair, we list thelanguage A as the first one.30For each document and each language pair, an in-dividual test was run.
An individual test consistedof finding, for a given document in language A, itsparallel in the language B set.
Since we did not takeadvantage of the pigeon-hole constraint, the individ-ual tests were independent from each other.No changes were made to the approach once test-ing on the EUROPARL corpus began, in order toavoid adapting it to work on any particular data set.4 ResultsIn total, only 20 of the 49872 tests did not pro-duce the correct result (0.04% error rate).
Therewas one incorrect selection in the English-Spanishlanguage pair, one in the English-German pair, aswell as in each of 18 language pairs involving Dan-ish or English as a Language A.
All of the incorrectresults can be traced to mistranslation, or to miss-ing/truncated documents.
In particular, one of thedocuments is severely truncated in Danish and En-glish, one of the German documents missing a por-tion of its text, and the Spanish version of one of thedocuments contains a number of phrases and sen-tences of English, apparently belonging to the En-glish version of the text.Effectively, when this method fails it is becausethe input does not match the problem definition.
Re-call that the problem was defined as selecting a doc-ument dB from a set of documents DB in languageB that is the correct parallel to dA, a document inlanguage A.
Failure cases occurred because therewas no correct parallel to the dA in DB .
In fact,each of the ?incorrect?
results is a manifestation ofan editorial error in the EUROPARL corpus.
Onecould see this approach being used as an aid to iden-tifying fragmentary documents and mistranslationsin parallel corpora.Encouraged by the excellent accuracy of ourmethod, we decided to try an even simpler approach,which is based on words of frequency 1 in the entireset of documents in a given language, rather than ina single document.
For every document from a lan-guage A, we select as its parallel the document fromlanguage B that shares the most of those words withit.
However, the results obtained with this methodwere clearly inferior, with the error rates rangingfrom 2.9% for Dutch to 27.3% for Finnish.5 DiscussionThe implications of this work are two-fold.
First,it shows a simple, fast, and effective method foridentifying parallel documents.
Second, it calls intoquestion the usefulness of parliamentary proceed-ings for the evaluation of parallel document identifi-cation schemes.The method described in this paper is sufficientlysimple as to be used as a baseline for comparisonwith other methods.
No information is shared be-tween trials, no word similarity measures are used,and word order is ignored.
The method does notincorporate any language-specific linguistic knowl-edge, and it has shown itself to be robust across lan-guages without any alterations.
The only constraintis that the languages must share an alphabet, or canbe converted into a common alphabet.
Furthermore,it requires no training phase, which would likelyhave to be repeated for every pair of languages.Our method achieves 99.9% accuracy on theEnglish-Spanish language pair, which roughlymatches the best result reported by Patry andLanglais (2005) (who apparently removed one doc-ument pair from the collection).
However, theirmethod requires a training phase on aligned paralleldocuments, making it time consuming and inconve-nient to adapt their approach to a new language pair,even in cases where such document-aligned corporaare available.
In addition, their top accuracy valuecorresponds to only one of several combination offeatures ?
the results with classifiers based on othercombinations of features were lower.We implemented our method using hash tables,which store the words occurring in a document to-gether with their frequencies.
This makes the entiresearch for a parallel document roughly linear in thetotal number of words in all the documents.
Averagetotal wall-clock time spent for one test with one lan-guage A document and 488 language B documentswas 59.4 seconds.
on a AMD Athlon(tm) 64 Proces-sor 3500+.
Profiling showed that on average 99.7%of the wall-clock time was spent on I/O operations,with the remainder taken by hash table lookups andstring equality checks.
Clearly, little speed improve-ment is possible.
In contrast to the speed of ourapproach, the approach used by Patry and Langlais(2005) requires not only the time to train a classifier,31but also the time to compute edit distance betweenmany document pairs.In addition to yielding a simple, accurate and fastmethod for parallel document identification, our re-sults suggest that relatively ?clean?
collections ofparliamentary proceedings of the EUROPARL typemay be inappropriate for testing parallel documentidentification schemes in general.
If a very simpleapproach can achieve near perfect accuracy in sucha domain, perhaps the task is too easy.
Future gen-eral parallel document identification systems shouldbe tested on more challenging datasets.6 Future WorkWhile the approach presented here has been verysuccessful thus far, there are a number of extensionsthat could be made to make it more applicable ingeneral.
More work could allow it to deal with casesof missing parallel documents, datasets with fewerproper names, and even yield knowledge of the dif-ficulty of the problem in general.First, the problem definition could be expanded toinclude cases where there is no valid parallel for agiven language A document in the language B doc-ument set.
This could take the form of establishinga score or significance threshold.
For example, ifthere were no document in the language B set thatshared more than the minimum number of uniquewords with the document dA in language A, then theapproach might return no parallel for that document.Second, it might be revealing to run further testswith this approach on other types of text than parlia-mentary proceedings.
What types of text would re-quire a more sophisticated approach?
The answer tothat question might have implications for the rangeof text types that ought to be used to comprehen-sively test parallel document identification systems.The exact matching of words is a critical featureof our approach, which enables it to perform quickcomparisons of documents by representing them assets of low-frequency words stored in hash tables.However, it is also a limitation because many cross-language cognates are not orthographically identi-cal.
A system relying on non-binary word similar-ity measures rather than on total identity of wordswould be more complex and slower, but also morerobust across different domains of text.7 ConclusionWe have presented a viable, simple method foridentification of homogeneous parallel documents.This method uses less resources and time than othercontent-based methods, a valuable asset when manylanguages lack linguistic resources.
In addition toshowing the effectiveness of our approach, the re-sults of the experiments suggest that parliamentaryproceedings may be inappropriate for parallel docu-ment identification scheme testing.AcknowledgmentsWe would like to thank Colin Cherry and othermembers of the NLP research group at University ofAlberta for their helpful comments and suggestions.This research was supported by the Natural Sciencesand Engineering Research Council of Canada.ReferencesJiang Chen and Jian-Yun Nie.
2000.
Parallel web textmining for cross-language IR.
In In Proc.
of RIAO,pages 62?77.Mona Diab and Philip Resnik.
2002.
An unsupervisedmethod for word sense tagging using parallel corpora.In Proc.
of ACL, pages 255?262.Mona Diab.
2004.
Relieving the data acquisition bottle-neck for word sense disambiguation.
In Proc.
of ACL,pages 303?310.Ulrich Germann.
2001.
Aligned Hansards of the36th Parliament of Canada, Release 2001-1a.
Avail-able at http://www.isi.edu/natural-language/download/hansard/.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proc.of HLT-NAACL, pages 48?54.Philipp Koehn.
2002.
Europarl: A multilingual cor-pus for evaluation of machine translation.
Availableat http://people.csail.mit.edu/koehn/.Craig J.
A. McEwan, Iadh Ounis, and Ian Ruthven.
2002.Building bilingual dictionaries from parallel web doc-uments.
In Proc.
of ECIR, pages 303?323.Alexandre Patry and Philippe Langlais.
2005.
Auto-matic identification of parallel documents with light orwithout linguistic resources.
In Proc.
of Canadian AI,pages 354?365.Philip Resnik and Noah A. Smith.
2003.
The web as aparallel corpus.
Comput.
Linguist., 29(3):349?380.32
