Automatic Extraction of Word SequenceCorrespondences in Parallel CorporaMihoko K i tamuraKansai  LaboratoryOki Electric Indust ry  Co., Ltd.kit a@kansai, oki.
co. jpYuji MatsumotoGraduate  School of Information ScienceNara Inst i tute of Science and Technologymat su@is, aist-nara, ac.
jpAbstractThis paper proposes a method of finding correspondences of arbitrary length word sequencesin aligned parallel corpora of Japanese and English.
Translation candidates of word sequences areevaluated by a similarity measure between the sequences defined by the co-occurrence frequencyand independent frequency of the word sequences.
The similarity measure is an extension of Dicecoefficient.
An iterative method with gradual threshold lowering is proposed for getting a highquality translation dictionary.
The method is tested with parallel corpora of three distinct domainsand achieved over 80~0 accuracy.1 Introduct ionA high quality translation dictionary is indispensable for machine translation systems with goodperformance, specially for domains of expertise.
Such dictionaries are only effectively usable fortheir own domains, much human labour will be mitigated if such a dictionary is obtained in anautomatic way from a set of translation examples.This paper proposes a method to construct a translation dictionary that consists of not onlyword pairs but pairs of arbitrary length word sequences of the two languages.
All of the pairs areextracted from a parallel corpus of a specific domain.
The method is proposed and is evaluatedwith Japanese-English parallel corpora of three distinct domains.Several attempts have been made for similar purposes, but with different settings.
(see \[Kupiec93\]\[Kumano & Hirakawa 94\]\[Smadja 96\])Kupiec and Kumano ~ Hirakawa propose a method of obtaining translation patterns of nouncompound from bilingual corpora.
Kumano & Hirakawa stand on a different setting from the otherworks in that they assume ordinary bilingual dictionary and use non-parallel (non-aligned) corpora.Their target is to find correspondences not only of word level but of noun phrases and unknownwords.
However, the target noun phrases and unknown words are decided in the preprocessingstage.Brown et al use a probabilistic measure for estimating word similarity of two languages intheir statistical approach of language translation \[Brown 88\].
In their work of aligning of paralleltexts, Kay & RSscheisen used the Dice coefficient as the word similarity for insuring sentence l velcorrespondence \[Kay & RSscheisen 93\].Kitamura & Matsumoto use the same measure to calculate word similarity in their work ofextraction of translation patterns.
The similarity measure is used as the basis of their structuralmatching of parallel sentences soas to extract structural translation patterns.
In texts of expertise anumber of word sequence correspondences, notword-word correspondences, areabundant especiallyin the form of noun compounds or of fixed phrases, which are keys for better performance.
Thoughthe method proposed in this paper deals only with consecutive s quences ofwords and is intendedto provide a better base for the structural matching that follows, the results themselves show veryuseful and informative translation patterns for the domain.Our method extends the usage of the Dice coefficient in two ways: It deals not only with cor-respondence b tween the words but with correspondence b tween word-sequences, and it modifiesthe formula measure so that more plausible corresponding pairs are identified earlier.792 Re lated Work and Some Resul tsBrown et.
al., used mutual information to construct corresponding pairs of French and Englishwords.
A French word f is considered to be translated into English word ej that gives the maximummutual information:P(e.~ l f)MI(ej, f) = log P(ej)Probabilities P(ej I f) and P(ej) are calculated from parallel corpus by counting the occurrencesand co-occurrences of ej and f.Kay & Rbscheisen used the following Dice coefficient for calculating the similarity betweenEnglish word we and French word w I.
In the formula, f(we), f(wl) represent the numbers ofoccurrences ofwe and wl, and f(we, wl) is the number of simultaneous occurrences of those wordsin corresponding sentences.2f(we, w f)sire(we, = f(w ) + f(wj)Kitamura & Matsumoto used the same formula for calculating word similarity from Japanese-English parallel corpora.
A comparison between the above two method is done on a parallel corpusand the results are reported in \[Ohmori 96\].
They applied both approaches to a French-Englishcorpus of about one thousand sentence pairs.
The results are shown in Table 1 where the correctnessis checked by human inspection.
Since both methods how very inaccurate results for the wordsof one occurrence, only the words of two or more occurrences are selected for inspection.
Table 1shows the proportion that a French word is paired with the correct English words checked with thetop, three and five highest candidates.Num.
of wordsMutual Information 697Dice coefficient 5741st candidate within best 3 within best 543.6% 60.0% 65.4%46.2% 65.0% 66.5%Table 1: Comparison of Mutual Information and Dice coefficientThe results how that though Dice coefficient gives a slightly better correctness both methodsdo not generate satisfactory translation pairs.\[Kupiec 93\] and \[Kumano & Hirakawa 94\] broaden the target o correspondences between wordsequences such as compound nouns.
Kupiec uses NP recognizer for both English and French andproposed a method to calculate the probabilities of correspondences using an iterative algorithmlike the EM algorithm.
He reports that in one hundred highest ranking correspondences ninety ofthem were correct.
Although the NP recognizers detect about 5000 distinct noun phrases in bothlanguages, the correctness ratio of the total data is not reported.Kumono & Hirakawa's objective is to obtain English translation of Japanese compound nouns(noun sequences) and unknown words using a statistical method similar to Brown's together withan ordinary Japanese-English dictionary.
Japanese compound nouns and unknown words are de-tected by the morphological nalysis tage and are determined before the later processes.
Thoughthey assume unaligned Japanese-English parallel corpora, alignment is performed beforehand.
Inan experiment with two thousand sentence pairs, 72.9% correctness is achieved by the best corre-spondences and 83.8% correctness by the top three candidates in the case of compound nouns.
Thecorrectness ratios for unknown words are 54.0% and 65.0% respectively.Smadja proposes a method of finding translation patterns of continuous as well as discontinu-ous collocations between English and French \[Smadja 96\].
The method first extracts meaningfulcollocations in the source language(English) in advance by the XTRACT system.
Then, alignedcorpora are statistically analized for finding the corresponding collocation patterns in the targetlanguage(French).
To avoid possible combinational explosion, some heuristics i introduced to filterimplausible correspondences.Getting translation pairs of complex expression is of great importance specially for technicaldomains where most domain specific terminologies appear as complex nouns.
There are still a80.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
_P~((eJ.C_9.~or~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Japanese Corpus English CorpusI ............
I l............... ..................... ; ; :  ........................................................... ..... ; ; ; ; ;1.
Morphological Analysis ---ff-~..~"~- .
.
.
.
.
.  "
--'"1 Morphological Analysis ...... ~ ~'~Content Word Extraction \[ r,.~'.
?f?_.
\[ Content Word Extraction I English |~__,~uunm~j Word Sequence ~action ~ctionary__.~ 2.
Word_Selquenc e ExtractionI | _3.
Setting of Minu~um Occurence Condition~-ranslation |~ i~ ..... 4.
Extraction of Translation Canditates re  e r  o5.
Similarity Calculation thresholddecrement.
.
.
.
.
.
.
.
.
:: ..........  6:.O?
r?J.ation -'4?f rransistion.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
_ _ _ _ _  7~7, ;g ' - "  .~ .
.
.
.~Japanese-English Pair ~ .
.
.
.
.
. yes.Figure 1: The flow of finding the correspondences of word sequencesnumber of other interesting and meaningful expression that should be translated in a specific way.We propose a method of finding corresponding translation pairs of arbitrary length word sequencesappearing in parallel corpora and an algorithm that gradually produces "good" correspondencesearlier so as to reduce noises when extracting less plausible correspondences.3 Overview of the MethodFigure 1 shows the flow of the process to find the correspondences of Japanese and English wordsequences.
Both Japanese and English texts are analyzed morphologically.We make use of two types of co-occurrences: Word co-occurrences within each language corpusand corresponding co-occurrences of those in the parallel corpus.
In the current setting, all wordsand word sequences oftwo or more occurrences are taken into account.
Since frequent co-occurrencesuggests higher plausibility of correspondence, we set a similarity measure that takes co-occurrencefrequencies into consideration.
Deciding the similarity measure in this way reduces the computa-tional overhead in the later processes.
If every possible correspondence of word sequences i  to becalculated, the combination is large.
Since high similarity value is supported by high co-occurrencefrequency, a gradual strategy can be taken by setting a threshold value for the similarity and byiteratively lowering it.
Though our method oes not assume any bilingual dictionary in advance,once words or word sequences are identified in an earlier stage, they are regarded as decisive en-tries of the translation dictionary.
Such translation pairs are taken away from the co-occurrencedata, then only the remaining word sequences need be taken into consideration i  the subsequentiterative steps.
Next section describes the details of the algorithm.4 The Algor ithmThe step numbering of the following procedure corresponds to the numbers appearing in Figure 1.In the current implementation, the Translation Dictionary is empty at the beginning.
Steps 1 and2 are performed on each language corpus separately.1.
Japanese and English texts are analyzed morphologically and all content words (nouns, verbs,adjectives and adverbs) are identified.812.
All content words of two or more occurrences are extracted.
Then, word sequences of lengthtwo that are headed by a previously extracted word are extracted, provided they appear atleast twice in the corpus.
In the same way, a word sequence w of length i + 1 is taken intoconsideration only when its prefix of length i has been extracted and w appears at leasttwice in the corpus.
This process is repeated until no new word sequences are obtained.
Thesubsequent steps handle only those extracted word sequences.
It would be natural to set amaximum length for the candidate word sequences, which we really have it be between 5 and10 in the experiments.3.
A threshold for minimum frequency of occurrence (.f,~in) is decided, and the following processis repeated, every time decrementing the threshold by some extent.4.
For the word sequence occurring more than fmin times, the numbers of total occurrence andtotal bilingual co-occurrence are counted.
This is done for all the pairs of such Japanese andEnglish word sequences.
It is not the case for a pair that already appeared in the TranslationDictionary.5.
For each pair of bilingual word sequences, the following similarity value (sim(w.r, wE)) iscalculated, where wj and WE are Japanese and English word sequences, and f j ,  fe and fieare the total frequency of wj in the Japanese corpus, that of wE in the English corpus andthe total co-occurrence frequency of wj and WE appearing in corresponding sentences.sim(wj,wE) = (log2 fje) fj2~ feThis formula is a modification of the Dice coefficient, weighting their similarity measure bylogarithm of the pair's co-occurrence frequency.
Only the pairs with their sire(w j, wE) valuegreater than log 2 frain are  considered in this step.
The fact that no word sequence occurringless than frnin times cannot yield greater similarity value than log 2 frnin assures  that allpairs of word sequences with the occurrence more than fmin times are surely taken intoconsideration.6.
The most plausible correspondences are then identified using the similarity values so calcu-lated:(a) For an English word sequence WE, let WJ = {Wj l ,Wj2," ' ,wjn} be the set of allJapanese word sequences uch that sim(wji, wE) > log2 f,~i,~.
The set is called thecandidate set for WE.
For each Japanese word sequence w.t its candidate set is constructedin the same way.
(b) Of the candidate set WJ for wE, if the candidate with the highest similarity value(w.ti = arg max sim(wjk,WE)) again selects wE as the candidate with the highestw~kEWJsimilarity (wE = arg max sirn(wji,WEm)), where WE is the candidate set for w.tl,wEmEWEthe pair (wji, WE) is regarded as a translation pair.7.
The approved translation pairs are registered in the Translation Dictionary until no new pairis obtained, then the threshold value fmin is lowered, and the steps 4 through 6 are repeateduntil fmin reaches a predetermined value.5 Exper iments of Translation Pair Extract ion5.1  The  set t ingsWe used parallel corpora of three distinct domains: (1) a computer manual (9,792 sentence pairs),(2) a scientific journal (12,200 sentence pairs), and (3) business contract letters (10,016 sentencepairs).
All the Japanese and English sentences are aligned and morphologically analyzed 1.The settings of the experiments are as follows: The maximum length of the extracted wordsequences i  set at 10.
The initial value of .fmi, is set at the half of the highest number of occurrencesof extracted word sequences and is lowered by dividing by two until it reaches to or under 10, thenit is lowered by one in each iteration until 2.1 Japanese and English morphological nalyzers of Machine Translation System PENSIVE were used.
PENSI~E is atrademark of Osaka Gas corporation, OGIS-RI, and Oki Electric Industry Co.,Ltd.82BusinessScienceManualsingle word word seq.total occurrence > 2Eng.
Jap.
Eng.
Jap.2,300 3,739 2,218 '3,5687,254 9,415 6,764 8,8563,701 4,926 3,478 4,799occurrence _> 2Eng.
Jap.73,026 72,57416,555 24,99832,049 38,796Table 2: Numbers of extracted words and word sequencesNum.
of threshold correct pairs1151575287143713517109876543total2341219481031645367821341633187551,927nearmiss2 0 03 0 04 0 012 0 018 1 048 0 0101 2 0155 8 151 2 063 4 075 6 1114 20 0145 15 3257 50 11502 195 591,550 302 75correctness accumulative incorrect (+near)  correctness%100(100) 100(100)100(100)100(100)100(100)94.7(100)100(100)98.1(100)94.5(99.4)96.2(100)94.0(100)91.5(98.8)85.1(100)89.0(98.2)80.8(96.5)66.5(92.2)100(100)100(100)100(100)97.5(100)98.9(100)99.0(100)96.6(99.7)96.6(99.8)96.2(99.8)95.5(99,6)93.5(99.7)92.6(99.4)89.4(98.6)80.4(96.1)Table 3: Results of Business LetterTable 2 summarizes the numbers of word sequences extracted by Step 2.
For each corpus thetable shows the numbers of distinct content words, those of two or more occurrences, and thenumbers of word sequences of two or more occurrences.5.2 The  resu l t sTables 3, 4 and 5 shows the statistics obtained from the experiments.
The columns pecify thenumbers of approved translation pairs.
The correctness of the translation pairs are checked by ahuman inspector.
A "near miss" means that the pair is not perfectly correct but some parts of thepair constitute the correct ranslation.It is noticeable that the pairs with high frequencies give very accurate translation i  the casesof the computer manual and the business letters, whereas the scientific journal does not necessarilygives high accuracy to highly frequent pairs.
The reason is that the former two corpora are reallyin a homogeneous domain, while the corpus of scientific journal is a complex of distinct scientificfields.
The former two corpora reveal a worse performance with the pairs with low frequencythreshold.
This is because those corpora frequently contain a number of lengthy fixed expressionor particular collocations.
One such example is that "p type (silicon)" frequently collocates with"n type (silicon)," making the correspondence uncertain.The science journal shows a stable accuracy of translation pair extraction.
The accuracy exceeds90% in most of the stages.
The reason would be that scientific papers do not repeat fixed expressionand the terminologies are used not in a fixed way.Table 6 summarizes the combination of the length of English and Japanese word sequences.The fraction in each entry shows the number of correct pairs over the number of extracted pairs.This table indicates that translation pairs of lengthy or unbalanced sequences are safely regarded83Num.
of threshold pairs6834171098765432total121691425269661051682925361,307(500)2,828(2,021)near correct miss1 019 164 5133 849 369 063 299 6155 12263 25494 34(445) (46)(1,854) (129)incorrect01011010148(9)correctness(+near)%lOO(lOO)90.5(95.2)92.8(10o)93.7(99.3)94.2(98.1)100(100)95.5(98.5)94.3(100)92.3(98.8)90.1(98.6)92.2(97.2)89.0(97.4)accumulativecorrectness%100(100)90.9(95.5)92.3(98.9)93.1(99.1)93.3(97.9)94.6(99.2)94.7(99.0)94.7(99.2)94.1(99.1)92.9(99.0)92.6(98.4)91.7(98.1)(38) 91.7(98.1)Table 4: Results of Science Journalthreshold Num.
of i correctpairs2091045226131098765432total1419551458158751061262143676291,401(500)3,281(2,380)near ~ incorrectmiss1 0 04 0 019 0 054 0 1140 5 076 5 055 2 168 5 299 7 0118 7 1198 13 3330 26 11519 97 13(395 / (87) (18)(2,076) (254) (50)correctness(+near)%100(100)100(100)100(100)98.1(98.1)96.6(100)93.8(100)94.8(98.3)90.7(93.6)93.4(100)93.7(99.2)92.5(98.6)89.9(97.0)82.5(97.9)79.0(96.4)87.2(97.9)accumulativecorrectness%100(100)lOO(lOO)100(100)98.7(98.7)97.3(99.6)96.4(99.7)96.1(99.4)95.2(99.1)94.9(99.3)94.6(99.3)94.1(99.1)92.9(98.5)89.4(98.3)87.2(97.9)Table 5: Results of Computer Manual-Business Length of Eng.
Seq.Letters 1 2 3 4 5 6 7 8 9 10LengthofJap.Seq.12345678910823/843 43/58 0/6 0/1 032/45 401/450 17/55 1/23 0/50 79/122 72/90 7/23 0/80 6/21 29/45 15/23 2/50 3/10 2/13 7/14 3/100 0 2/4 2/3 0/10 0/1 0 0/2 00 0/1 0 0/1 0/10 0 0 0 0o o/1 o/1 o o0 0 0 0 00/4 0/1 0 0/1 0o/4 o/4 o o o1/2 0/1 0 0 0/12/3 0 0/1 0/1 0/10/2 0 0/1 0/1 0/20/1 0 0/1 0 00/1 0 0 0 0/10 0 0 0 01/1 o o o 0/6Table 6: Length Combination of Word Sequences and their Accuracy (Business Letter)84Japanese English Similarity- -  1. Business Letter - -~?
(~) ~~,  (/?)
~z~ ~ t~- -  2.
Science Journal - -u.x 79..~.x I~!.?
~F .
rn ~ "~9 ~-~~4,P .x  $.~ I - '7 -~- -  3.
Computer Manual - -4 >'#$'~'  l- 7VPX.
'f > '#~ 1- 7"= b~V I Pexclusive license 4.95dispute(,) controversy (or) difference (which may) arise 4.34trade secret 3.72effective date (of this) agreement 3.12business hour 2.92utility model(,) trademark(,) design (or) copyright 2.81irrevocable confirm(ed) letter (of) credit 2.81technique manufacture know-how 2.62patent(s)(,) know-how (or) technical information 1.06hemorrhage f ver virus 3.19methyl acrylate 3.17Los Alamos national aboratory 2n type 1.78p type 1.78university (of) California (at) Davis 1.58wireless network 1.19fiber(-)optic network 1.19hemorrhage f ver 1.14internet 5.25internet address 2.83double precision float point 1.79internet protocol IP 1.78internet protocol 1.66DoD internet 1.6name (to) address map(ping) 1.58internet service 1.45indicates "near miss" and * indicates "incorrect".Table 7: Samples of Corresponding Word Sequencesas incorrect correspondences.Tables 7 and 8 list samples of translation pairs extracted from the experiments.
Table 7 listssome of typical word sequence pairs.
Many of Japanese translation of English technical terms areautomatically detected.
Table 8 lists the top 30 pairs from the experiment on the business contractletters.The method is capable of getting interesting translation patterns.
For example, "~ l~ l~"  and"~ l l~"  are found to correspond to "trade secret" and "business hour" respectively.
Note thatJapanese word "~"  is translated into different English words according to their occurrences withdistinct word.Table 9 shows the recall ratio based on the results of the experiments.
The figures show thenumbers of words that are included at least one extracted translation pairs.
The recall ratesare shown in parentheses, which indicates how much proportion of the words with two or moreoccurrences in the corpora are finally participated in at least one translation pair.
The majorreason that the recall is not sufficiently high is that we decided to use a rather severe condition onselecting a translation pairs in Step 6 in the algorithm.
The condition may be loosen to get betterrecall ratio though we may lose high precision.
We have not yet tested our method with otherconditions.85Japanese English- -  Freq.Stage 1151 - -AA~}?
company,1' ~ ~ 5,'-- licenseeFreq.Stage 575 - -~ distributor~i~ ~ product9 -~ sellerFreq.Stage 287 - -~ -  buyer~ party~ writingarticleFreq.Stage 143-b ba aA B C ABC~ informationX Y Z XYZ~ patent~ technical~ J  right~ trademarkC C~:t~ territory~,~ necessaryFreq.Stage 71 - -~ ~ technical information~ consignee4 "Y )l, ~" 4 royalty~gJ PAT hereinafterd d~ sale~ exclusive~ manufacturei~  obligation:10.7310.479.559.269.248.928.848.398.348.078.017.997.877.777.657.647.607.507.417.267.267.086.996.846.826.766.756.746.726.593952243614712511999940127675477833232435448932745552066436921866833221422529519812662623557822840812521156229961039970139486083734533536254933354555886940123169335622724437722313080427893025547202715167931271116111215848589553443403885613705056707694382261033410241259331220130920271648287A indicates "near miss".Table 8: Sample of Top Correspondences (Business Letter(Best 30))Corpus EnglishBusiness 867Science 2,240Manual 1,922(recall) Japanese (recall)(39.1%) 1,005 (28.2%)(33.1%) 2,359 (26.6%)(55.3%) 2,224 (46.3%)Table 9: Numbers of words identified866 ConclusionA method for obtaining translation dictionary from parallel corpora was proposed, in which notonly word-word correspondences but arbitrary length word sequence correspondences areextracted.This work is originally motivated for the purpose of improving the performance ofour translationpattern extraction from parallel corpora \[Kitamura & Matsumoto 95\], in which translation patternsare extracted by syntactically analyzing both Japanese and English sentences and by structurallymatching them.
Some discrepancy is caused by poor quality of translation dictionary.
This is whywe tried to pursue a way to obtain better translation dictionary from parallel corpora.
We believethat the proposed method gives results of good performance ompared with previous related work.The translation pairs obtained through our method are directly usable as the base resource for MTsystems based on translation memory \[Lehmann 95\].We hope to acquire better translation patterns by combining the current results with our workof structural matching for finding out fine grained correspondence.ReferencesP.F.
Brown.
A Statistical Approach to Language Translation.
In COLING-88, volume 1, pages71-76, 1988.M.
Kay and M. RSscheisen.
Text-Translation Alignment.
Computational Linguistics, 19(1):121-142, 1993.M.
Kitarnura and Y. Matsumoto.
A Machine Translation System based 6n Translation RulesAcquired from Parallel Corpora.
In Recent Advances in Natural Language Processing, pages27-44, 1995.A.
Kumano and H. Hirakawa.
Building an MT Dictionary from Parallel Texts Based on Linguisticand Statistical Information.
In COLING-94, volume 1, pages 76-81, 1994.J.
Kupiec.
An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora.
In31st Annual Meeting of the Association for Computational Linguistics * Proceedings of theConference (ACL93), pages 23-30, 1993.H.
Lehmann.
Machine Translation for Home and Business Users.
In Proceedings of MT SummitV,1995K.
Ohmori, J. Tsutsumi, and M. Nakanishi.
Building Bilingual Word Dictionary Based on Statisti-cal Information.
In Proceedings of The Second Annual Meeting of The Association for NaturalLanguage Processing, pages 49-52, 1996.
(in Japanese)F. Smadja, K.R.
McKeown and V. Hatzivassiloglou.
Translating Collocations for Bilingual Lexi-cons: A Statistical Approach.
Computational Linguistics, 22(1):1-38, 1996.87
