Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 647?655,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPCapturing Salience with a Trainable Cache Model for Zero-anaphoraResolutionRyu IidaDepartment of Computer ScienceTokyo Institute of Technology2-12-1, ?Ookayama, Meguro,Tokyo 152-8552, Japanryu-i@cl.cs.titech.ac.jpKentaro Inui Yuji MatsumotoGraduate School of Information ScienceNara Institute of Science and Technology8916-5, Takayama, IkomaNara 630-0192, Japan{inui,matsu}@is.naist.jpAbstractThis paper explores how to apply the notionof caching introduced by Walker (1996) tothe task of zero-anaphora resolution.
Wepropose a machine learning-based imple-mentation of a cache model to reduce thecomputational cost of identifying an an-tecedent.
Our empirical evaluation withJapanese newspaper articles shows that thenumber of candidate antecedents for eachzero-pronoun can be dramatically reducedwhile preserving the accuracy of resolvingit.1 IntroductionThere have been recently increasing concernswith the need for anaphora resolution to makeNLP applications such as IE and MT more reli-able.
In particular, for languages such as Japanese,anaphora resolution is crucial for resolving aphrase in a text to its referent since phrases, es-pecially nominative arguments of predicates, arefrequently omitted by anaphoric functions in dis-course (Iida et al, 2007b).Many researchers have recently explored ma-chine learning-based methods using considerableamounts of annotated data provided by, for exam-ple, the Message Understanding Conference andAutomatic Context Extraction programs (Soon etal., 2001; Ng and Cardie, 2002; Yang et al, 2008;McCallum and Wellner, 2003, etc.).
These meth-ods reach a level comparable to or better than thestate-of-the-art rule-based systems (e.g.
Baldwin(1995)) by recasting the task of anaphora resolutioninto classification or clustering problems.
How-ever, such approaches tend to disregard theoreticalfindings from discourse theories, such as Center-ing Theory (Grosz et al, 1995).
Therefore, one ofthe challenging issues in this area is to incorporatesuch findings from linguistic theories into machinelearning-based approaches.A typical machine learning-based approachto zero-anaphora resolution searches for an an-tecedent in the set of candidates appearing in allthe preceding contexts.
However, computationaltime makes this approach largely infeasible forlong texts.
An alternative approach is to heuristi-cally limit the search space (e.g.
the system dealswith candidates only occurring in the N previoussentences).
Various research such as Yang et al(2008) has adopted this approach, but it also leadsto problems when an antecedent is located far fromits anaphor, causing it to be excluded from targetcandidate antecedents.On the other hand, rule-based methods derivedfrom theoretical background such as CenteringTheory (Grosz et al, 1995) only deal with thesalient discourse entities at each point of the dis-course status.
By incrementally updating the dis-course status, the set of candidates in questionis automatically limited.
Although these meth-ods have a theoretical advantage, they have aserious drawback in that Centering Theory onlyretains information about the previous sentence.A few methods have attempted to overcome thisfault (Suri and McCoy, 1994; Hahn and Strube,1997), but they are overly dependent upon the re-strictions fundamental to the notion of centering.We hope that by relaxing such restrictions it willbe possible for an anaphora resolution system toachieve a good balance between accuracy and com-putational cost.From this background, we focus on the issueof reducing candidate antecedents (discourse en-tities) for a given anaphor.
Inspired by Walker?sargument (Walker, 1996), we propose a machinelearning-based caching mechanism that capturesthe most salient candidates at each point of thediscourse for efficient anaphora resolution.
Morespecifically, we choose salient candidates for eachsentence from the set of candidates appearing inthat sentence and the candidates which are already647in the cache.
Searching only through the set ofsalient candidates, the computational cost of zero-anaphora resolution is effectively reduced.
In theempirical evaluation, we investigate how efficientlythis caching mechanism contributes to reducing thesearch space while preserving accuracy.
This pa-per focuses on Japanese though the proposed cachemechanism may be applicable to any language.This paper is organized as follows.
First,Section 2 presents the task of zero-anaphora res-olution and then Section 3 gives an overviewof previous work.
Next, in Section 4 we pro-pose a machine learning-based cache model.Section 5 presents the antecedent identification andanaphoricity determination models used in the ex-periments.
To evaluate the model, we conduct sev-eral empirical evaluations and report their resultsin Section 6.
Finally, we conclude and discuss thefuture direction of this research in Section 7.2 Zero-anaphora resolutionIn this paper, we consider only zero-pronounsthat function as an obligatory argument of a predi-cate.
A zero-pronoun may or may not have its an-tecedent in the discourse; in the case it does, we saythe zero-pronoun is anaphoric.
On the other hand,a zero-pronoun whose referent does not explicitlyappear in the discourse is called a non-anaphoriczero-pronoun.
A zero-pronoun is typically non-anaphoric when it refers to an extralinguistic entity(e.g.
the first or second person) or its referent isunspecified in the context.The task of zero-anaphora resolution can bedecomposed into two subtasks: anaphoricity de-termination and antecedent identification.
Inanaphoricity determination, the model judgeswhether a zero-pronoun is anaphoric (i.e.
a zero-pronoun has an antecedent in a text) or not.
If azero-pronoun is anaphoric, the model must detectits antecedent.
For example, in example (1) themodel has to judge whether or not the zero-pronounin the second sentence (i.e.
the nominative argu-ment of the predicate ?to hate?)
is anaphoric, andthen identify its correct antecedent as ?Mary.?
(1) Maryi-wa Johnj-ni (?j-ga) tabako-oMaryi-TOP Johnj-DAT (?j-NOM) smoking-OBJyameru-youni it-ta .quit-COMP say-PAST PUNCMary told John to quit smoking.
(?i-ga) tabako-o kirai-dakarada .
(?i-NOM) smoking-OBJ hate-BECAUSE PUNCBecause (she) hates people smoking.3 Previous workEarly methods for zero-anaphora resolution weredeveloped with rule-based approaches in mind.Theory-oriented rule-based methods (Kameyama,1986; Walker et al, 1994), for example, focuson the Centering Theory (Grosz et al, 1995) andare designed to collect the salient candidate an-tecedents in the forward-looking center (Cf ) list,and then choose the most salient candidate, Cp,as an antecedent of a zero-pronoun according toheuristic rules (e.g.
topic > subject > indirect ob-ject > direct object > others1).
Although thesemethods have a theoretical advantage, they havea serious drawback in that the original CenteringTheory is restricted to keeping information aboutthe previous sentence only.
In order to loosen thisrestriction, the Centering-based methods have beenextended for reaching an antecedent appearing fur-ther from its anaphor.
For example, Suri and Mc-Coy (1994) proposed a method for capturing twokinds of Cp, that correspond to the most salientdiscourse entities within the local transition andwithin the global focus of a text.
Hahn and Strube(1997) estimate hierarchical discourse segments ofa text by taking into account a series of Cp and thenthe resolution model searches for an antecedent inthe estimated segment.
Although these methodsremedy the drawback of Centering, they still overlydepend on the notion of Centering such as Cp.On the other hand, the existing machinelearning-based methods (Aone and Bennett, 1995;McCarthy and Lehnert, 1995; Soon et al, 2001;Ng and Cardie, 2002; Seki et al, 2002; Isozakiand Hirao, 2003; Iida et al, 2005; Iida et al,2007a, etc.)
have been developed with less atten-tion given to such a problem.
These methods ex-haustively search for an antecedent within the listof all candidate antecedents until the beginning ofthe text.
Otherwise, the process to search for an-tecedents is heuristically carried out in a limitedsearch space (e.g.
the previous N sentences of ananaphor) (Yang et al, 2008).4 Machine learning-based cache modelAs mentioned in Section 2, the procedure forzero-anaphora resolution can be decomposed intotwo subtasks, namely anaphoricity determinationand antecedent identification.
In this paper,these two subtasks are carried out according tothe selection-then-classification model (Iida et al,1?A > B?
means A is more salient than B.6482005), chosen because it it has the advantage ofusing broader context information for determiningthe anaphoricity of a zero-pronoun.
It does this byexamining whether the context preceding the zero-pronoun in the discourse has a plausible candidateantecedent or not.
With this model, antecedentidentification is performed first, and anaphoricitydetermination second, that is, the model identifiesthe most likely candidate antecedent for a givenzero-pronoun and then it judges whether or not thezero-pronoun is anaphoric.As discussed by Iida et al (2007a), intra-sentential and inter-sentential zero-anaphora reso-lution should be dealt with by taking into accountdifferent kinds of information.
Syntactic patternsare useful clues for intra-sentential zero-anaphoraresolution, whereas rhetorical clues such as con-nectives may be more useful for inter-sententialcases.
Therefore, the intra-sentential and inter-sentential zero-anaphora resolution models are sep-arately trained by exploiting different feature setsas shown in Table 2.In addition, as mentioned in Section 3, inter-sentential cases have a serious problem where thesearch space of zero-pronouns grows linearly withthe length of the text.
In order to avoid this prob-lem, we incorporate a caching mechanism origi-nally addressed by Walker (1996) into the follow-ing procedure of zero-anaphora resolution by lim-iting the search space at step 3 and by updating thecache at step 5.Zero-anaphora resolution process:1.
Intra-sentential antecedent identification: Fora given zero-pronoun ZP in a given sentence S,select the most-likely candidate antecedent A1from the candidates appearing in S by the intra-sentential antecedent identification model.2.
Intra-sentential anaphoricity determination:Estimate plausibility p1that A1is the true an-tecedent, and return A1if p1?
?intra2 or go to3 otherwise.3.
Inter-sentential antecedent identification: Se-lect the most-likely candidate antecedent A2from the candidates appearing in the cache asexplained in Section 4.1 by the inter-sententialantecedent identification model.4.
Inter-sentential anaphoricity determination:Estimate plausibility p2that A2is the true an-tecedent, and return A2if p2?
?inter3 or return2?intrais a preselected threshold.3?interis a preselected threshold.non-anaphoric otherwise.5.
After processing all zero-pronouns in S, thecache is updated.
The resolution process is con-tinued until the end of the discourse.4.1 Dynamic cache modelBecause the original work of the cache model byWalker (1996) is not fully specified for implemen-tation, we specify how to retain the salient candi-dates based on machine learning in order to captureboth local and global foci of discourse.In Walker (1996)?s discussion of the cachemodel in discourse processing, it was presumed tooperate under a limited attention constraint.
Ac-cording to this constraint, only a limited number ofcandidates can be considered in processing.
Ap-plying the concept of cache to computer hardware,the cache represents working memory and the mainmemory represents long-term memory.
The cacheonly holds the most salient entities, while the restare moved to the main memory for possible laterconsideration as a cache candidate.
If a new can-didate antecedent is retrieved from main memoryand inserted into the cache, or enters the cache di-rectly during processing, other candidates in thecache have to be displaced due to the limited ca-pacity of the cache.
Which candidate to displace isdetermined by a cache replacement policy.
How-ever, the best policy for this is still unknown.In this paper, we recast the cache replacementpolicy as a ranking problem in machine learning.More precisely, we choose the N best candidatesfor each sentence from the set of candidates ap-pearing in that sentence and the candidates that arealready in the cache.
Following this cache model,named the dynamic cache model, anaphora resolu-tion is performed by repeating the following twoprocesses.1.
Cache update: cache Cifor sentence Siis cre-ated from the candidates in the previous sen-tence Si?1and the ones in the previous cacheCi?1.2.
Inter-sentential zero-anaphora resolution:cache Ciis used as the search space forinter-sentential zero-anaphora resolution insentence Si(see Step 3 of the aforementionedzero-anaphora resolution process).For each cache update (see Figure 1), a currentcache Ciis created by choosing the N most salientcandidates from the M candidates in Si?1and theN candidates in the previous cache Ci?1.
In orderto implement this mechanism, we train the model649...1)1( ?ic2)1( ?icMic)1( ?...2)1( ?ieNie)1( ?1?iS1?iCiCcache sentencecache updateantecedent identification1)1( ?ie...2ieiNe1ieij?Figure 1: Anaphora resolution using the dynamiccache modelso that it captures the salience of each candidate.To reflect this, each training instance is labeledas either retained or discarded.
If an instance is re-ferred to by an zero-pronoun appearing in any ofthe following sentences, it is labeled as retained;otherwise, it is labeled as discarded.
Training in-stances are created in the algorithm detailed inFigure 2.
The algorithm is designed with the fol-lowing two points in mind.First, the cache model must capture the salienceof each discourse entity according to the recencyof its entity at each discourse status because typi-cally the more recently an entity appears, the moresalient it is.
To reflect this, training instancesare created from candidates as they appear in thetext, and are labeled as retained from the point oftheir appearance until their referring zero-pronounis reached, at which time they are labeled as dis-carded if they are never referred to by any zero-pronouns in the succeeding context.Suppose, the situation shown in Figure 3, wherecijis the j-th candidate in sentence Si.
In thissituation, for example, candidate c12is labeledas retained when creating training instances forsentence S1, but labeled as discarded from S2onwards, because of the appearance of its zero-pronoun.
Another candidate c13which is never re-ferred to in the text is labeled as discarded for alltraining instances.Second, we need to capture the ?relative?salience of candidates appearing in the current dis-course for each cache update, as also exploited inthe tournament-based or ranking-based approachesto anaphora resolution (Iida et al, 2003; Yang etal., 2003; Denis and Baldridge, 2008).
To solveit, we use a ranker trained on the instances createdas described above.
In order to train the ranker,we adopt the Ranking SVM algorithm (Joachims,2002), which learns a weight vector to rank candi-dates for a given partial ranking of each discourseentity.
Each training instance is created from theset of retained candidates, Ri, paired with the setof discarded candidates, Di, in each sentence.
ToFunction makeTrainingInstances (T : input text)C := NULL // set of preceding candidatesS := NULL // set of training instancesi := 1; // initwhile (exists si) // si: i-th sentence in TEi:= extractCandidates(si)Ri:= extractRetainedInstances(Ei, T )Di:= Ei\Riri:= extractRetainedInstances(C, T )Ri:= Ri?
riDi:= Di?
(C\ri)S := S ?
{?Ri, Di?
}C := updateSalienceInfo(C)C := C ?
Eii := i + 1endwhilereturn SendFunction extractRetainedInstances (S, T )R := NULL // initwhile (elm ?
S)if (elm is anaphoric with a zero-pronoun locatedin the following sentences of T )R := R ?
elmendifendwhilereturn RendFunction updateSalienceInfo (C, si)while (c ?
C)if (c is anaphoric with a zero pronoun in si)c.position := i; // update the position informationendifendwhilereturn CendFigure 2: Pseudo-code for creating training in-stances1S11c12c13c14c2S21c22c23ci?j?3S31c32c33ck?retained discarded11c12c13c14cl?training instancesretained discarded11c22c13c14c21c23c12cFigure 3: Creating training instnacesdefine the partial ranking of candidates, we simplyrank candidates in Rias first place and candidatesin Dias second place.4.2 Static cache modelOther research on discourse such as Grosz andSidner (1986) has studied global focus, which gen-erally refers to the entity or set of entities thatare salient throughout the entire discourse.
Sinceglobal focus may not be captured by Centering-based models, we also propose another cachemodel which directly captures the global salienceof a text.To train the model, all the candidates in a textwhich have an inter-sentential anaphoric relationwith zero-pronouns are used as positive instancesand the others used as negative ones.
Unlike the650Table 1: Feature set used in the cache modelsFeature DescriptionPOS Part-of-speech of C followed byIPADIC4.IN QUOTE 1 if C is located in a quoted sentence;otherwise 0.BEGINNING 1 if C is located in the beginnig of a text;otherwise 0.CASE MARKER Case marker, such as wa (TOPIC) andga (SUBJECT), of C.DEP END 1 if C has a dependency relation withthe last bunsetsu unit (i.e.
a basic unitin Japanese) in a sentence ; otherwise 0.CONN* The set of connectives intervening be-tween C and Z.
Each conjunction is en-coded into a binary feature.IN CACHE* 1 if C is currently stored in the cache;otherwise 0.SENT DIST* Distance between C and Z in terms of asentence.CHAIN NUM The number of anaphoric chain, i.e.
thenumber of antecedents of Z in the situa-tion that zero-pronouns in the precedingcontexts are completely resolved by thezero-anaphora resolution model.C is a candidate antecedent, and Z stands for a target zero-pronoun.
Features marked with an asterisk are only used inthe dynamic cache model.dynamic cache model, this model does not updatethe cache dynamically, but simply selects for eachgiven zero-pronoun the N most salient candidatesfrom the preceding sentences according to the rankprovided by the trained ranker.
We call this modelthe static cache model.4.3 Features used in the cache modelsThe feature set used in the cache model is shownin Table 1.
The ?CASE MARKER?
feature roughlycaptures the salience of the local transition dealtwith in Centering Theory, and is also intended tocapture the global foci of a text coupled with theBEGINNING feature.
The CONN feature is expectedto capture the transitions of a discourse relation be-cause each connective functions as a marker of adiscourse relation between two adjacent discoursesegments.In addition, the recency of a candidate an-tecedent can be even important when an entity oc-curs as a zero-pronoun in discourse.
For example,when a discourse entity e appearing in sentence siis referred to by a zero-pronoun later in sentencesj(i<j), entity e is considered salient again at thepoint of sj.
To reflect this way of updating salience,we overwrite the information about the appearanceposition of candidate e in sj, which is performed bythe function updateSalienceInfo in Figure 2.
Thisallows the cache model to handle updated salience4http://chasen.naist.jp/stable/ipadic/features such as CHAIN NUM in proceeding cacheupdates.5 Antecedent identification and anaphoric-ity determination modelsAs an antecedent identification model, we adoptthe tournament model (Iida et al, 2003) becausein a preliminary experiment it achieved better per-formance than other state-of-the-art ranking-basedmodels (Denis and Baldridge, 2008) in this tasksetting.
To train the tournament model, the traininginstances are created by extracting an antecedentpaired with each of the other candidates for learn-ing a preference of which candidate is more likelyto be an antecedent.
At the test phase, the modelconducts a tournament consisting of a series ofmatches in which candidate antecedents competewith one another.
Note that in the case of inter-sentential zero-anaphora resolution the tournamentis arranged between candidates in the cache.
Forlearning the difference of two candidates in thecache, training instances are also created by onlyextracting candidates from the cache.For anaphoricity determination, the model has tojudge whether a zero-pronoun is anaphoric or not.To create the training instances for the binary clas-sifier, the most likely candidate of each given zero-pronoun is chosen by the tournament model andthen it is labeled as anaphoric (positive) if the cho-sen candidate is indeed the antecedent of the zero-pronoun5, or otherwise labeled as non-anaphoric(negative).To create models for antecedent identificationand anaphoricity determination, we use a SupportVector Machine (Vapnik, 1998)6 with a linear ker-nel and its default parameters.
To use the featureset shown in Table 2, morpho-syntactic analysis ofa text is performed by the Japanese morpheme ana-lyzer Chasen and the dependency parser CaboCha.In the tournament model, the features of two com-peting candidates are distinguished from each otherby adding the prefix of either ?left?
or ?right.
?6 ExperimentsWe investigate how the cache model contributesto candidate reduction.
More specifically, we ex-5In the original selection-then-classification model (Iida etal., 2005), positive instances are created by all the correct pairsof a zero-pronoun and its antecedent, however in this paper weuse only antecedents selected by the tournament model as themost likely candidates in the set of candidates because thismethod leads to better performance.6http://svmlight.joachims.org/651Table 2: Feature set used in zero-anaphora resolutionFeature Type Feature DescriptionLexical HEAD BF Characters of right-most morpheme in NP (PRED).PRED FUNC Characters of functional words followed by PRED.Grammatical PRED VOICE 1 if PRED contains auxiliaries such as ?(ra)reru?
; otherwise 0.POS Part-of-speech of NP (PRED) followed by IPADIC (Asahara and Matsumoto, 2003).PARTICLE Particle followed by NP, such as ?wa (topic)?, ?ga (subject)?, ?o (object)?.Semantic NE Named entity of NP: PERSON, ORGANIZATION, LOCATION, ARTIFACT, DATE, TIME,MONEY, PERCENT or N/A.SELECT PREF The score of selectional preference, which is the mutual information estimated from alarge number of triplets ?Noun, Case, Predicate?.Positional SENTNUM Distance between NP and PRED.BEGINNING 1 if NP is located in the beggining of sentence; otherwise 0.END 1 if NP is located in the end of sentence; otherwise 0.PRED NP 1 if PRED precedes NP; otherwise 0.NP PRED 1 if NP precedes PRED; otherwise 0.Discourse CL RANK A rank of NP in forward looking-center list.CL ORDER A order of NP in forward looking-center list.CONN** The connectives intervesing between NP and PRED.Path PATH FUNC* Characters of functional words in the shortest path in the dependency tree betweenPRED and NP.PATH POS* Part-of-speech of functional words in shortest patn in the dependency tree betweenPRED and NP.NP and PRED stand for a bunsetsu-chunk of a candidate antecedent and a bunsetsu-chunk of a predicate which has a targetzero-pronoun respectively.
The features marked with an asterisk are used during intra-sentential zero-anaphora resolution.
Thefeature marked with two asterisks is used during inter-sentential zero-anaphora resolution.plore the candidate reduction ratio of each cachemodel as well as its coverage, i.e.
how of-ten each cache model retains correct antecedents(Section 6.2).
We also evaluate the performanceof both antecedent identification on inter-sententialzero-anaphora resolution (Section 6.3) and theoverall zero-anaphora resolution (Section 6.4).6.1 Data setIn this experiment, we take the ellipsis of nom-inative arguments of predicates as target zero-pronouns because they are most frequently omittedin Japanese, for example, 45.5% of the nominativearguments of predicates are omitted in the NAISTText Corpus (Iida et al, 2007b).As the data set, we use part of the NAIST TextCorpus, which is publicly available, consisting of287 newspaper articles in Japanese.
The data setcontains 1,007 intra-sentential zero-pronouns, 699inter-sentential zero-pronouns and 593 exophoriczero-pronouns, totalling 2299 zero-pronouns.
Weconduct 5-fold cross-validation using this data set.A development data set consists of 60 articles forsetting parameters of inter-sentential anaphoricitydetermination, ?inter, on overall zero-anaphora res-olution.
It contains 417 intra-sentential, 298 inter-sentential and 174 exophoric zero-pronouns.6.2 Evaluation of the caching mechanismIn this experiment, we directly compare the pro-posed static and dynamic cache models with theheuristic methods presented in Section 2.
Note that0.50.550.60.650.70.750.80.850.90.950.2  0.4  0.6  0.8  1coverage# of classification in antecedent identification processn=5n=10n=15 n=20n=allCMSM (s=1)SM (s=2)SM (s=3)DCM (w/o ZAR)DCM (with ZAR)SCMCM: centering-based cache model, SM: sentence-based cachemodel, SCM: static cache model, DCM (w/o ZAR): dynamiccache model disregarding updateSalienceInfo, DCM (withZAR): dynamic cache model using the information of correctzero-anaphoric relations, n: cache size and s: # of sentences.Figure 4: Coverage of each cache modelthe salience information (i.e.
the function update-SalienceInfo) in the dynamic cache model is disre-garded in this experiment because its performancecrucially depends on the performance of the zero-anaphora resolution model.
The performance ofthe cache model is evaluated by coverage, whichis a percentage of retained antecedents when ap-pearing zero-pronouns refer to an antecedent in apreceding sentence, i.e.
we evaluate the cases ofinter-sentential anaphora resolution.As a baseline, we adopt the following two cachemodels.
One is the Centering-derived model whichonly stores the preceding ?wa?
(topic)-marked or652?ga?
(subject)-marked candidate antecedents in thecache.
It is an approximation of the model pro-posed by Nariyama (2002) for extending the lo-cal focus transition defined by Centering Theory.We henceforth call this model the centering-basedcache model.
The other baseline model stores can-didates appearing in the N previous sentences of azero-pronoun to simulate a heuristic approach usedin works like Soon et al (2001).
We call this modelthe sentence-based cache model.
By comparingthese baselines with our cache models, we can seewhether our models contribute to more efficientlystoring salient candidates or not.The above dynamic cache model retains thesalient candidates independently of the results ofantecedent identification conducted in the preced-ing contexts.
However, if the zero-anaphora res-olution in the current utterance is performed cor-rectly, it will be available for use as informationabout the recency of candidates and the anaphoricchain of each candidate.
Therefore, we also in-vestigate whether correct zero-anaphora resolutioncontributes to the dynamic cache model or not.To integrate zero-anaphora resolution information,we create training instances of the dynamic cachemodel by updating the recency using the function?updateSalienceInfo?
shown in Figure 2 and alsousing an additional feature, CHAIN NUM, definedin Table 1.The results are shown in Figure 47.
We cansee the effect of the machine learning-based cachemodels in comparison to the other two heuristicmodels.
The results demonstrate that the formerachieves good coverage at each point compared tothe latter.
In addition, the difference between thestatic and dynamic cache models demonstrates thatthe dynamic one is always better then the static.
Itmay be this way because the dynamic cache modelsimultaneously retains global focus of a given textand the locally salient entities in the current dis-course.By comparing the dynamic cache model usingcorrect zero-anaphora resolution (denoted by DCM(with ZAR) in Figure 4) and the one without it(DCM (w/o ZAR)), we can see that correct zero-anaphora resolution contributes to improving thecaching for every cache size.
However, in thepractical setting the current zero-anaphora resolu-7Expressions such as verbs were rarely annotated as an-tecedents, so these are not extracted as candidate antecedentsin our current setting.
This is the reason why the coverage ofusing all the candidates is less than 1.0.tion system sometimes chooses the wrong candi-date as an antecedent or does not choose any can-didate due to wrong anaphoricity determination,negatively impacting the performance of the cachemodel.
For this reason, in the following two exper-iments we decided not to use zero-anaphora reso-lution in the dynamic cache model.6.3 Evaluation of inter-sentential zero-anaphora resolutionWe next investigate the impact of the dynamiccache model shown in Section 4.1 on the an-tecedent identification task of inter-sentential zero-anaphora resolution altering the cache size from5 to the number of all candidates.
We comparethe following three cache model within the taskof inter-sentential antecedent identification: thecentering-based cache model, the sentence-basedcache model and the dynamic cache model disre-garding updateSalienceInfo (i.e.
DCM (w/o ZAR)in Figure 4).
We also investigate the computationaltime of the process of inter-sentential antecedentidentification with each cache model altering its pa-rameter 8.The results are shown in Table 3.
From theseresults, we can see the antecedent identificationmodel using the dynamic cache model obtains al-most the same accuracy for every cache size.
Itindicates that if the model can acquire a small num-ber of the most salient discourse entities in the cur-rent discourse, the model achieves accuracy com-parable to the model which searches all the pre-ceding discourse entities, while drastically reduc-ing the computational time.The results also show that the current antecedentidentification model with the dynamic cache modeldoes not necessarily outperform the model with thebaseline cache models.For example, the sentence-based cache modelusing the preceding two sentences (SM (s=2))achieved an accuracy comparable to the dynamiccache model with the cache size 15 (DCM (n=15)),both spending almost the same computational time.This is supposed to be due to the limited accu-racy of the current antecedent identification model.Since the dynamic cache models provide much bet-ter search spaces than the baseline models as shownin Figure 4, there is presumably more room for im-provement with the dynamic cache models.
Moreinvestigations are to be concluded in our future8All experiments were conducted on a 2.80 GHz IntelXeon with 16 Gb of RAM.653Table 3: Results on antecedent identificationmodel accuracy runtime coverage(Figure 4)CM 0.441 (308/699) 11m03s 0.651SM(s=1) 0.381 (266/699) 6m54s 0.524SM(s=2) 0.448 (313/699) 13m14s 0.720SM(s=3) 0.466 (326/699) 19m01s 0.794DCM(n=5) 0.446 (312/699) 4m39s 0.664DCM(n=10) 0.441 (308/699) 8m56s 0.764DCM(n=15) 0.442 (309/699) 12m53s 0.858DCM(n=20) 0.443 (310/699) 16m35s 0.878DCM(n=1000) 0.452 (316/699) 53m44s 0.928CM: centering-based cache model, SM: sentence-based cachemodel, DCM: dynamic cache model, n: cache size, s: numberof the preceding sentences.work.6.4 Overall zero-anaphora resolutionWe finally investigate the effects of introducingthe proposed model on overall zero-anaphora res-olution including intra-sentential cases.
The res-olution is carried out according to the proceduredescribed in Section 4.
By comparing the zero-anaphora resolution model with different cachesizes, we can see whether or not the model usinga small number of discourse entities in the cacheachieves performance comparable to the originalone in a practical setting.For intra-sentential zero-anaphora resolution, weadopt the model proposed by Iida et al (2007a),which exploits syntactic patterns as features thatappear in the dependency path of a zero-pronounand its candidate antecedent.
Note that for sim-plicity we use bag-of-functional words and theirpart-of-speech intervening between a zero-pronounand its candidate antecedent as features insteadof learning syntactic patterns with the Bact algo-rithm (Kudo and Matsumoto, 2004).We illustrated the recall-precision curve of eachmodel by altering the threshold parameter of intra-sentential anaphoricity determination, which isshown in Figure 5.
The results show that all mod-els achieved almost the same performance whendecreasing the cache size.
It indicates that it isenough to cache a small number of the most salientcandidates in the current zero-anaphora resolutionmodel, while coverage decreases when the cachesize is smaller as shown in Figure 4.7 ConclusionWe propose a machine learning-based cachemodel in order to reduce the computational cost ofzero-anaphora resolution.
We recast discourse sta-tus updates as ranking problems of discourse en-tities by adopting the notion of caching originally0.10.20.30.40.50.60.70.80.910  0.1  0.2  0.3  0.4  0.5  0.6precisionrecalln=5n=10n=15n=20n=1000Figure 5: Recall-precision curves on overall ze-ro-anaphora resolutionintroduced by Walker (1996).
More specifically,we choose the N most salient candidates for eachsentence from the set of candidates appearing inthat sentence and the candidates which are alreadyin the cache.
Using this mechanism, the compu-tational cost of the zero-anaphora resolution pro-cess is reduced by searching only the set of salientcandidates.
Our empirical evaluation on Japanesezero-anaphora resolution shows that our learning-based cache model drastically reduces the searchspace while preserving accuracy.The procedure for zero-anaphora resolutionadopted in our model assumes that resolution iscarried out linearly, i.e.
an antecedent is inde-pendently selected without taking into account anyother zero-pronouns.
However, trends in anaphoraresolution have shifted from such linear approachesto more sophisticated ones which globally opti-mize the interpretation of all the referring expres-sions in a text.
For example, Poon and Domingos(2008) has empirically reported that such globalapproaches achieve performance better than theones based on incrementally processing a text.
Be-cause their work basically builds on inductive logicprograming, we can naturally extend this to incor-porate our caching mechanism into the global op-timization by expressing cache constraints as pred-icate logic, which is one of our next challenges inthis research area.ReferencesC.
Aone and S. W. Bennett.
1995.
Evaluating automatedand manual acquisition of anaphora resolution strategies.In Proceedings of 33th Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 122?129.M.
Asahara and Y. Matsumoto, 2003.
IPADIC User Manual.Nara Institute of Science and Technology, Japan.B.
Baldwin.
1995.
CogNIAC: A Discourse Processing En-gine.
Ph.D. thesis, Department of Computer and Informa-tion Sciences, University of Pennsylvania.P.
Denis and J. Baldridge.
2008.
Specialized models andranking for coreference resolution.
In Proceedings of the2008 Conference on Empirical Methods in Natural Lan-guage Processing, pages 660?669.654B.
J. Grosz and C. L. Sidner.
1986.
Attention, intentions,and the structure of discourse.
Computational Linguistics,12:175?204.B.
J. Grosz, A. K. Joshi, and S. Weinstein.
1995.
Centering: Aframework for modeling the local coherence of discourse.Computational Linguistics, 21(2):203?226.U.
Hahn and M. Strube.
1997.
Centering in-the-large: com-puting referential discourse segments.
In Proceedings ofthe 8th conference on European chapter of the Associationfor Computational Linguistics, pages 104?111.R.
Iida, K. Inui, H. Takamura, and Y. Matsumoto.
2003.
In-corporating contextual cues in trainable models for coref-erence resolution.
In Proceedings of the 10th EACL Work-shop on The Computational Treatment of Anaphora, pages23?30.R.
Iida, K. Inui, and Y. Matsumoto.
2005.
Anaphora resolu-tion by antecedent identification followed by anaphoricitydetermination.
ACM Transactions on Asian Language In-formation Processing (TALIP), 4(4):417?434.R.
Iida, K. Inui, and Y. Matsumoto.
2007a.
Zero-anaphoraresolution by learning rich syntactic pattern features.
ACMTransactions on Asian Language Information Processing(TALIP), 6(4).R.
Iida, M. Komachi, K. Inui, and Y. Matsumoto.
2007b.Annotating a japanese text corpus with predicate-argumentand coreference relations.
In Proceeding of the ACL Work-shop ?Linguistic Annotation Workshop?, pages 132?139.H.
Isozaki and T. Hirao.
2003.
Japanese zero pronoun res-olution based on ranking rules and machine learning.
InProceedings of the 2003 Conference on Empirical Methodsin Natural Language Processing, pages 184?191.T.
Joachims.
2002.
Optimizing search engines using click-through data.
In Proceedings of the ACM Conferenceon Knowledge Discovery and Data Mining (KDD), pages133?142.M.
Kameyama.
1986.
A property-sharing constraint in cen-tering.
In Proceedings of the 24th ACL, pages 200?206.T.
Kudo and Y. Matsumoto.
2004.
A boosting algorithm forclassification of semi-structured text.
In Proceedings of the2004 EMNLP, pages 301?308.A.
McCallum and B. Wellner.
2003.
Toward conditional mod-els of identity uncertainty with application to proper nouncoreference.
In Proceedings of the IJCAI Workshop on In-formation Integration on the Web, pages 79?84.J.
F. McCarthy and W. G. Lehnert.
1995.
Using decisiontrees for coreference resolution.
In Proceedings of the 14thInternational Joint Conference on Artificial Intelligence,pages 1050?1055.S.
Nariyama.
2002.
Grammar for ellipsis resolution injapanese.
In Proceedings of the 9th International Confer-ence on Theoretical and Methodological Issues in MachineTranslation, pages 135?145.V.
Ng and C. Cardie.
2002.
Improving machine learning ap-proaches to coreference resolution.
In Proceedings of the40th ACL, pages 104?111.H.
Poon and P. Domingos.
2008.
Joint unsupervised corefer-ence resolution with Markov Logic.
In Proceedings of the2008 Conference on Empirical Methods in Natural Lan-guage Processing, pages 650?659.K.
Seki, A. Fujii, and T. Ishikawa.
2002.
A probabilisticmethod for analyzing japanese anaphora integrating zeropronoun detection and resolution.
In Proceedings of the19th COLING, pages 911?917.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
A ma-chine learning approach to coreference resolution of nounphrases.
Computational Linguistics, 27(4):521?544.L.
Z. Suri and K. F. McCoy.
1994.
Raft/rapr and center-ing: a comparison and discussion of problems related toprocessing complex sentences.
Computational Linguistics,20(2):301?317.V.
N. Vapnik.
1998.
Statistical Learning Theory.
Adaptiveand Learning Systems for Signal Processing Communica-tions, and control.
John Wiley & Sons.M.
Walker, M. Iida, and S. Cote.
1994.
Japanese discourseand the process of centering.
Computational Linguistics,20(2):193?233.M.
A. Walker.
1996.
Limited attention and discourse struc-ture.
Computational Linguistics, 22(2):255?264.X.
Yang, G. Zhou, J. Su, and C. L. Tan.
2003.
Coreferenceresolution using competition learning approach.
In Pro-ceedings of the 41st ACL, pages 176?183.X.
Yang, J. Su, J. Lang, C. L. Tan, T. Liu, and S. Li.
2008.An entity-mention model for coreference resolution withinductive logic programming.
In Proceedings of ACL-08:HLT, pages 843?851.655
