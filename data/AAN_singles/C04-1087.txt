Enhancing automatic term recognition through recognition of variationGoran Nenadi?
*Department of ComputationUMISTManchester, UK, M60 1QDG.Nenadic@umist.ac.ukSophia Ananiadou*Computer ScienceUniversity of SalfordSalford, UK, M5 4WTS.Ananiadou@salford.ac.ukJohn McNaught*Department of ComputationUMISTManchester, UK, M60 1QDJ.McNaught@umist.ac.uk* Co-affiliation: National Centre for Text Mining, Manchester, UKAbstractTerminological variation is an integral part of thelinguistic ability to realise a concept in many ways,but it is typically considered an obstacle toautomatic term recognition (ATR) and termmanagement.
We present a method that integratesterm variation in a hybrid ATR approach, in whichterm candidates are recognised by a set oflinguistic filters and termhood assignment is basedon joint frequency of occurrence of all termvariants.
We evaluate the effectiveness ofincorporating specific types of term variation bycomparing it to the performance of a baselinemethod that treats term variants as separate terms.We show that ATR precision is enhanced byconsidering joint termhoods of all term variants,while recall benefits by the introduction of newcandidates through consideration of differentvariation types.
On a biomedical test corpus weshow that precision can be increased by 20?70%for the top ranked terms, while recall improvesgenerally by 2?25%.1 IntroductionTerminological processing has long beenrecognised as one of the crucial aspects ofsystematic knowledge acquisition and of manyNLP applications (IR, IE, corpus querying, etc.
).However, term variation has been under-discussedand is rarely accounted for in such applications.When naming a new concept, scientists andspecialists usually follow some predefined termformation patterns, a process which does notexclude the usage of term variations or alternativenames for concepts.
Term variations are veryfrequent: approximately one third of termoccurrences are variants (Jacquemin, 2001).
Theyoccur not only in text, but also in controlled,manually curated terminological resources (e.g.UMLS (NLM, 2004)).The task of an automatic term recognition (ATR)system is not only to suggest the most likelycandidate terms from text, but also to correlatethem with synonymous term variants.
In this paper,we briefly present an analysis of term variationphenomena, whose results are subsequentlyincorporated into a corpus-based ATR method inorder to enhance its performance.The paper is organised as follows.
In Section 2,we analyse the main types of term variation, andbriefly examine how existing ATR systems treatthem.
Our approach to incorporating variants intoATR is presented in Section 3.
In Section 4, weevaluate our approach by comparing it to abaseline method (the method without variation re-cognition), and we conclude the paper in Section 5.2 BackgroundTerms are linguistic units that are assigned toconcepts and used by domain specialists todescribe and refer to specific concepts in a domain.In this sense, terms are preferred designators ofconcepts.
In text, however, concepts are frequentlydenoted by different surface realisations ofpreferred terms, which we denote as their termvariants.
Consequently, a concept can belinguistically represented using any of the surfaceforms that are variants of the correspondingpreferred term.
We consider the following types ofterm variation:(i) orthographic: e.g.
usage of hyphens and slashes(amino acid and amino-acid), lower and uppercases (NF-KB and NF-kb), spelling variations(tumour and tumor), different Latin/Greektranscriptions (oestrogen and estrogen), etc.
(ii) morphological: the simplest variations arerelated to inflectional phenomena (e.g.
singular,plural).
Derivational transformations can lead tovariants in some cases (cellular gene and cellgene), but not always (activated factor vs.activating factor);(iii) lexical: genuine lexical synonyms, which maybe interchangeably used (carcinoma andcancer, haemorrhage and blood loss);(iv) structural: e.g.
possessive usage of nounsusing prepositions (clones of human and humanclones), prepositional variants (cell in blood,cell from blood), term coordinations (adrenalglands and gonads);(v) acronyms and abbreviations: very frequentterm variation phenomena in technicalsublanguages, especially in biomedicine;sometimes they may be even preferred terms(DNA for deoxyribonucleic acid).Note that variation types (i) ?
(iii) affectindividual constituents, while (iv) and (v) involvevariation in structure of the preferred term.
In anycase, they do not ?change?
the meaning as theyrefer to the same concept.
Daille et al (1996) andJacquemin (1999, 2001) further identified types ofvariation that modified the meaning of terms.Although many authors mention the problemsrelated to term variation, few have dealt withlinking the corresponding term variants.
Also, therecognition of variants is typically performed as aseparate operation, and not as part of ATR.The simplest technique to handle some types ofterm variation (e.g.
morphological) is based onstemming: if two term forms share a stemmedrepresentation, they are considered as mutualvariants (Jacquemin and Tzoukermann, 1999;Ananiadou et al, 2000).
However, stemming mayresult in ambiguous denotations related to ?over-stemming?
(i.e.
resulting in the conflation of termswhich are not real variants) and ?under-stemming?(i.e.
resulting in the failure to link real termvariants).Other approaches to the recognition of termvariants use preferred terms and known synonymsfrom existing term dictionaries and approximatestring matching techniques to link or generatedifferent term variants (Krauthammer et al, 2001;Tsuruoka and Tsujii, 2003).Jacquemin (2001) presents a rule-based system,FASTR, which supports several hundred meta-rules dealing with morphological, syntactic (i.e.structural) and semantic term variation.
Termvariation recognition is based on thetransformation of basic term structures into variantstructures.
However, the variants recognised byFASTR are more conceptual variants thanterminological ones, as non-terminological units(such as verb phrases, extended insertions, etc.)
arealso linked to terms in order to improve indexingand retrieval.3 Incorporating term variation into ATROur approach to ATR combines the C-valuemethod (Frantzi et al, 2000) with the recognitionof term variation, which is incorporated as anintegral part of the term extraction process.C-value is a hybrid approach combining termformation patterns with corpus-based statisticalmeasures.
Term formation patterns act as linguisticfilters to a POS tagged corpus: filtered sequencesare considered as potential realisations of domainconcepts (term candidates).
They are subsequentlyassigned termhoods (i.e.
likelihood to representterms) according to a statistical measure.
Themeasure amalgamates four corpus-basedcharacteristics of a term candidate, namely itsfrequency of occurrence, its frequency ofoccurrence as a form nested within other candidateterms, the number of candidate terms inside whichit is nested, and the number of words it contains.The original C-value method treats term variantsthat correspond to the same concept as separateterm candidates.
Consequently, by providingseparate frequencies of occurrence for individualvariants instead of a single frequency ofoccurrence calculated for a term candidate unifyingall variants, the corpus-based measures andtermhoods are distributed across different variants.Therefore, we aim at enhancing the statisticalevaluation of termhoods through conflation ofdifferent surface representations of a given term,and through joint frequencies of occurrence of allequivalent surface forms that correspond to asingle concept.In order to conflate equivalent surfaceexpressions, we carry out linguistic normalisationof individual term candidates (see examples inTable 1).
Firstly, each term candidate is mapped toa specific canonical representative (CR) bysemantically isomorphic transformations.
Then, weestablish an equivalence relation, where two termcandidates are related iff they share the same CR.The partitions of this relation are denoted assynterms: a synterm contains surface termrepresentations sharing the same CR.synterm canonical representativehuman cancerscancer in humanshuman?s cancerhuman carcinoma } human cancerTable 1: Term normalisation examplesOur aim is to form synterms prior to the syntacticestimation of termhoods for term candidates.Therefore, after the extraction of individual termcandidates, we subsequently normalise them inorder to generate synterms, where thenormalisation is performed according to thetypology of variations described in Section 2.
Moreprecisely, we consider separately the normalisationof variations that affect term candidate constituentsand variations that involve structural changes.
Thegeneral architecture of our ATR approach ispresented in Figure 1.P O S  taggerIn flec tiona l n orm alisa tio nS tructura l  n orm alisationO rthographic  no rm alisa tionE x trac ted  syn term sInp u t d ocu m entsT erm h ood  es tim ationE xtrac tio n  of term  cand id atesA cron ym  acq uis itionFigure 1: The architecture of the ATR process3.1 Normalising term constituent variationIn the case of variations that do not affect thestructure of terms, the formation of CRs is basedon a POS tagger (for inflectional variation) andsimple heuristics (for orthographic normalisation).For example, different transcriptions ofneoclassical combining forms are treated byreplacements of specific character combinations(ae ?
e, ph ?
f) in such forms (and only in suchforms).
Inflectional normalisation is based on POStagging: a canonical term candidate form is asingular form containing no possessives (Down?ssyndrome ?
down syndrome).In order to address lexical variants, one can usedictionaries of synonyms where the preferred termsare used for normalisation purposes ({hepaticmicrosomes, liver microsomes} ?
livermicrosomes).
In experiments reported here, we didnot attempt to normalise lexical variation.3.2 Normalising term structure variationVariations affecting term structure are less frequentbut more complex.
Here we consider two types ofterm variation: prepositional term candidates andcoordinated term candidates (for a detailed analysisof these variations see (Nenadic et al, 2004)).Prepositional term candidates are normalised bytransformation into corresponding expressionswithout prepositions.
Using prepositions of, in, forand by as anchors, we generate semanticallyisomorphic CRs by inversion.
For example, thecandidate nuclear factor of activated T cell istransformed into activated T cell nuclear factor.Here is a simplified example of a rule describingthe transformation of a term candidate thatcontains the preposition of:if  structure of  term candidate is(A|N)1* N1 Prep(of) (A|N)2* N2then   CR = (A|N)2* N2 (A|N)1* N1In order to address the problems of determiningthe boundaries of term constituents in text (to theright and left of prepositions), for eachprepositional term candidate we generate allpossible nested candidates?
and their correspondingCRs.
For example, for the candidate regulation ofgene expression, we generate both gene regulationand gene expression regulation.
Since thisapproach also generates a number of falsecandidates, additional heuristics are used toenhance precision, such as removing adverbialsand determiners, using a stop list ofterminologically irrelevant prepositionalexpressions (e.g.
number of ..., list of ..., case of ...,in presence of ...), etc.A similar approach is used for the recognition ofcoordinated term candidates: coordinatingconjunctions (and, or, but not, as well as, etc.)
areused as anchors, and when a coordinating structureis recognised in text, the corresponding CRs of thecandidate terms involved are generated.We differentiate between head coordination(where term heads are coordinated, e.g.
adrenalglands and gonads) and argument coordination(where term arguments/modifiers are coordinated,e.g.
SMRT and Trip-1 mRNAs).The recognition and extraction of coordinatedterms is highly ambiguous even for humanspecialists, since coordinated terms and termconjunctions share the same structures (see Table2).
Also, similar patterns cover both argument andhead coordinations, which makes it difficult toextract coordinated constituents (i.e.
terms).
Notonly is the recognition of term coordinations andtheir subtypes ambiguous, but also internalboundaries of coordinated terms are blurred.
In aseparate study, we have shown thatmorphosyntactic features are insufficient both forthe successful recognition of coordinations and forthe extraction of coordinated terms: in many cases,the correct interpretation and decoding of termcoordinations is only possible with sufficientbackground knowledge (Nenadic et al, 2004).?
Each constituent extracted from a nested pre-positional term candidate has to follow a pattern usedfor the extraction of individual candidate terms.example adrenal  glands and gonadsheadcoordination [adrenal [glands and gonads]]termconjunction  [adrenal glands] and [gonads]Table 2: Ambiguities within coordinated structuresIn order to address the problems of structuralambiguities and boundaries of coordinated terms,we also generate all possible nested coordinationexpressions and corresponding term candidates.For example, from a candidate coordination viralgene expression and replication we generate twopairs of coordinated term candidates:viral gene expression  and  viral gene replicationviral gene expression  and  viral replicationPatterns for the extraction of term candidatesfrom coordinations have been acquired semi-manually for a subset of term coordinations.
Foreach pattern, we define a procedure for theextraction of coordinated term candidates andgeneration of the corresponding CRs (see Table 3for examples).
The generated candidates fromcoordinated structures are subsequently treated asindividual term candidates.3.3 Normalising acronym variationWe treat acronym extraction as part of the ATRprocess (see Figure 1).
In (Nenadic et al, 2002) wesuggested a simple procedure for acquiringacronyms and their expanded forms (EFs), whichwas mainly based on using orthographic andsyntactic features of contexts where acronymswere introduced.
The model is based on three typesof patterns: acronym patterns (defining commoninternal acronym structures and forms), definitionpatterns (based on syntactic patterns whichdescribe typical contexts where acronyms areintroduced in text) and matching patterns (the setof matching rules between acronyms and theircorresponding EFs).Acronyms also exhibit variation (e.g.
RAR alpha,RAR-alpha, RARA, RARa, RA receptor alpha etc.are all acronyms for retinoic acid receptor alpha).Therefore, in addition to extracting acronyms, wefurther gather all acronym variants and their EFs,and we map them into a single CR.
Since in thispaper acronyms are taken as term variants, we?replace?
acronym occurrences by the CR of theirEFs.
In order to bypass the problem of acronymambiguity, we replace/normalise only acronymsthat are introduced in a given document.
(N|A)1 & (N|A)2 (N+)3candidate1 = (N|A)2 (N+)3candidate2 = (N|A)1 nested(N+3 )e.g.
B and T cell antigenT cell antigenB cell antigen, B antigenN1 & N2 A3 N+4candidate1 = N2 A3 N+4candidate2 = N1 A3 N+4e.g.
function or surface antigenic profilesurface antigenic profilefunction antigenic profileN+1 N2 & (N|A)3candidate1 = N+1 N2candidate2 = nested(N+1) (N|A)3e.g.
breast cancer therapy and preventionbreast cancer therapybreast caner prevention, breast  preventionN+1 (A+)2  A3 &  A4candidate1 = N+1 (A+)2 A3candidate2 = N+1 (A+)2 A4e.g.
RNA polymerases II and IIIRNA polymerasis IIRNA polymerasis IIITable 3: Examples of patterns used for theextraction of term candidates from coordinations(nested denotes the generation of all possiblelinearly nested substrings)3.4 Calculating termhoods with variantsTerm variants sharing the same CR are groupedtogether into synterms, and the calculation of C-values (i.e.
termhoods) is performed for the wholesynterm rather than for individual term candidates.The main reason for doing this is to avoid thedistribution of frequencies of occurrence of termcandidates across different variants, as thesefrequencies have a significant impact on estimatingtermhoods.
Instead of providing separatefrequencies of occurrence and obtaining termhoodsfor individual term candidates, we provide a singlefrequency of occurrence and joint termhoodcalculated for a synterm, which unifies all variants.Similarly to the estimation of C-values forindividual term candidates (Frantzi et al, 2000),the formula for calculating the termhoods forsynterms is as follows:????????=?
?nestednot  is CR),(||lognested is CR,))(||1)((||log  )value(-C22CRfCRbfTCRfCRc CRTbCRwhere c denotes a synterm whose elements share acanonical representative (denoted as CR in theformula), f(CR) corresponds to the cumulativefrequency with which all term candidates from thesynterm c occur in a given corpus, |CR| denotesthe average length of the term candidates (thenumber of constituents), and TCR is a set of allsynterms whose CRs contain the given CR as anested substring.This approach ensures that all term variants arenaturally dealt with jointly, thus supporting the factthat they denote the same concept.
As aconsequence, we expect that precision would beenhanced by considering joint frequencies ofoccurrence and termhoods for all variants ofcandidate terms, while recall would benefit by theintroduction of new candidates throughconsideration of different variation types.4 Evaluation and discussionIn order to assess the effectiveness of incorporatingspecific types of term variation into ATR, wecompared the performance of the baseline C-valuemethod (without considering variations) with theapproach including recognition and conflation ofterm variants.
Here we are not interested in anabsolute measure of the ATR performance, butrather in the comparison of results obtainedthrough handling different variation types.We conducted two sets of experiments: in thefirst experiment, we analysed the incorporation ofterm candidates resulting from considering termvariations individually, while, in the second, weexperimented with the integration of combinedvariations in the ATR process.The evaluation was carried out using the GENIAcorpus (GENIA, 2004), which contains 2,000abstracts in the biomedical domain with 76,592manually marked occurrences of terms.
Theseoccurrences (which include different term variants)correspond to 29,781 different, unique terms.
Eachoccurrence of a term in the corpus (exceptoccurrences of acronyms) is linked to thecorresponding ?normalised?
term (typically asingular form), while coordinated terms areidentified, marked and normalised within termcoordinations.
A third of occurrences of GENIAterms are affected by inflectional variations, andalmost half of GENIA terms have inflectionalvariants appearing in the corpus.
On the otherhand, only 0.5% of terms contain a preposition,while 2% of all term occurrences are coordinated,involving 9% of distinct GENIA terms (for adetailed analysis of GENIA terms see (Nenadic etal., 2004)).We used the list of GENIA terms as a goldstandard for the evaluation.
Since our ATR methodproduces a ranked list of suggested synterms, weconsidered precision at fixed rank cut-offs(intervals): precision was calculated as the ratiobetween the number of correctly recognised termsand the total number of entities recognised in agiven interval (where an interval included all termsfrom the top ranked synterms).?
The baselinemethod (original C-value) was treated in the sameway, as term candidates suggested by the originalC-value could be seen as singleton synterms.
Inorder to estimate the influence on recall, we alsoused all variants from suggested synterms.The incorporation of individual variationsaffecting term constituents into ATR hadconsiderable positive effects, especially on themost frequently occurring terms (see Figures 2aand 2b): for some intervals, inflectional variants,for example, improved precision by almost 50%.Similarly, the integration of acronyms improvedprecision, in particular for frequent terms (up to70%), as acronyms are typically introduced forsuch terms.
As one would expect, the combinedconstituent-level variations further improvedinterval precisions compared both to the baselinemethod and individual variations (see Figure 2c).However, the incorporation of structural variants(in particular for prepositional terms) negativelyinfluenced precision compared to the baselinemethod, as many false candidates were introduced.In order to assess the quality of extractedprepositional term candidates, we evaluated a setof the 117 most frequently occurring candidateswith prepositions: 80% of suggested expressionswere deemed relevant by domain experts, althoughthey were not included in the gold GENIAstandard (such as expression of genes or binding ofNF kappa B).
Still, the recognition of prepositionalterm candidates is difficult as they are infrequentand there are no clear morphosyntactic cues thatcan differentiate between terminologically relevantand irrelevant prepositional phrases.The incorporation of coordinated term candidateshad only marginal influence on precision, mainlybecause they were not frequent in the GENIAcorpus.
Furthermore, simple term conjunctions?
It was an open question whether to count therecognition of each term form (e.g.
singular and pluralforms, an acronym and its EF, prepositional and non-prepositional forms) separately (i.e.
as two positive?hits?)
or as one positive ?hit?
(see also (Church,1995)).
Since the evaluation of the baseline method(original C-value) typically counts such hits separately,we decided to follow this approach, and consequentlycount all positive hits from synterms.were far more frequent than term coordinations,which made their extraction highly ambiguous.Still, using only the patterns from Table 3, we havecorrectly extracted 35.76% of all GENIAcoordinated terms, with more than a half of allsuggested candidates being found among those thatappeared exclusively in coordinations.
However,these patterns also generated a number of falsecoordination expressions, and consequently anumber of false term candidates.The integration of term variants was also usefulfor re-ranking of true positive term candidates: thecombined rank was typically higher than theseparate ranks of term variants.
Furthermore, someterms, not suggested by the baseline method at all,were ranked highly when variants were conflated(for example, the term T-lymphocyte wasrecognised only as a coordinated term candidate,while replication of HIV-1 was extracted only byconsidering prepositional term candidates).
Inorder to estimate the overall influence on recall ofATR, we used all terms from the respectivesynterms (see Table 4 for the detailed results).
Ingeneral, the incorporation of inflectional variantsincreased recall by ?, while acronyms improvedrecall by almost ?
when only the most frequentterms were considered.
It is interesting thatacronym acquisition can further improve recall byextracting variants that have more complex internalstructures (such as EFs containing prepositions(REA = repressor of estrogen activity) and/orcoordinations (SMRT = silencing mediator ofretinoic and thyroid receptor)).
Prepositional andcoordination candidate terms had some influenceon recall, in particular as they increased thelikelihood of some candidates to be suggested asterms.
Low recall of term coordinations may beincreased by adding more patterns (which wouldprobably negatively affect precision).Summarising, experiments performed on theGENIA corpus have shown that the incorporationof term variations into the ATR process resulted insignificantly better precision and recall.
In general,acronyms and inflectional unification are the mostimportant variation types (at least in the domain ofbiomedicine).
Individually, they increasedprecision by 20?70% for the top ranked syntermintervals, while recall is generally improved, insome cases up to 25%.
Other term variations hadonly marginal influence on the performance,mainly because they were infrequent in the testcorpus (compared to the total number of termoccurrences, and not only with regard to specificindividual candidates, but also in general).
Forthese variations, larger-scale corpora may showtheir stronger influence.01250 100 150 250 500 100015003000500010000 allprepositions inflectional acronymsFigure 2a: Comparison of interval ATR precisionof the baseline method (=1) to ATR precisions withintegrated recognition of individual term variants(terms with frequency > 5)01250 100 150 250 500 100015003000500010000 allprepositions inflectional acronymsFigure 2b: Comparison of interval ATR precisionof the baseline method (=1) to ATR precisions withintegrated recognition of individual term variants(terms with frequency > 0)01250 100 150 250 500 100015003000500010000 allinflectional infl & acro allFigure 2c: Comparison of interval ATR precisionof the baseline method (=1) to ATR precisions withintegrated recognition of combined term variants(terms with frequency > 0)term sets prep.
coord.
infl.
acro.freq.
?
5 +5.30% +12.42% +17.52% +60.49%freq.
> 0 +2.36% +2.53% +25.25% +8.52%Table 4: Improvement in recall when variationsare considered as an integral part of ATR5 ConclusionIn this paper we discussed possibilities for theextraction and conflation of different types ofvariation of term candidates.
We demonstrated thatthe incorporation of treatment of term variationenhanced the performance of an ATR system, andthat tackling term variation phenomena was anessential step for ATR.
In our case, precision wasboosted by considering joint frequencies ofoccurrence and termhoods for all candidate termsfrom candidate synterms, while recall benefitedfrom the introduction of new candidates throughconsideration of different variation types.
Althoughwe experimented with a biomedical corpus, ourtechniques are general and can be applied to otherdomains.Variations affecting single term candidateconstituents are the most frequent phenomena, andalso straightforward for implementation as part ofan ATR process.
The conflation of such termcandidate variants can be further tuned for aspecific domain by using lists of combining formsand affixes.
The incorporation of acronyms had asignificant high positive effect, in particular onmore frequent terms (since acronyms areintroduced for terms that are used morefrequently).However, more complex structural phenomenahad a moderate positive influence on recall, but, ingeneral, the negative effect on precision.
The mainreason for such performances is structural andterminological ambiguity of these expressions, inaddition to their low frequency of occurrence(compared to the total number of termoccurrences).
For handling such complex variants,a knowledge-intensive and domain-specificapproach is needed, as coordinated term candidatesor candidates with prepositions need to beadditionally semantically analysed in order tosuggest more reliable term candidates, and tointroduce fewer false candidates.Apart  from being useful for boosting precisionand recall, the integration of term variation intoATR is particularly important for smaller corpora(where linking related occurrences is vital forsuccessful terminology management) as well as formany text-mining tasks (such as IR, IE, term ordocument clustering and classification, etc.
).Finally, as future work, we plan to investigatemore knowledge intensive, domain-specifictreatment of prepositional and coordinated terms,as well as pronominal term references.6 AcknowledgementsThis research has been partially supported by theJISC-funded National Centre for Text Mining(NaCTeM), Manchester, UK.ReferencesS.
Ananiadou, S. Albert and D. Schuhmann.
2000.Evaluation of Automatic Term Recognition ofNuclear Receptors from Medline.
GenomeInformatics Series, vol.
11.K.W.
Church.
1995.
One Term or Two?
Proc.
ofSIGIR-95, pp.
310-318.B.
Daille, B. Habert and C. Jacquemin.
1996.Empirical Observation of Term Variation andPrinciples for Their Description.
Terminology3(2), pp.
197?258.K.
Frantzi, S. Ananiadou and H. Mima.
2000.Automatic Recognition of Multi-Word Terms:the C/NC value method.
International Journal ofDigital Libraries, vol.
3:2, pp.
115?130.C.
Jacquemin.
1999.
Syntagmatic and paradigmaticrepresentations of term variation.
Proc.
of 37thAnnual Meeting of ACL, pp.
341?348.C.
Jacquemin.
2001.
Spotting and DiscoveringTerms through NLP.
MIT Press, Cambridge MA.C.
Jacquemin and E. Tzoukermann.
1999.
NLP forTerm Variant Extraction: A Synergy ofMorphology, Lexicon and Syntax, in T.Strzalkowski (ed.
), Natural LanguageInformation Retrieval, Kluwer, pp.
25-74M.
Krauthammer, A. Rzhetsky, P. Morozov, andC.
Friedman.
2001.
Using BLAST foridentifying gene and protein names in journalarticles.
Gene, 259(1?2): pp.
245?52.GENIA.
2004.
GENIA resources.
Available athttp://www.tsujii.is.u-tokyo.ac.jp/~Genia/G.
Nenadic, I. Spasic and S. Ananiadou.
2002.Automatic Acronym Acquisition and TermVariation Management within Domain-SpecificTexts.
Proc.
of LREC 2002, pp.
2155?2162.G.
Nenadic, I. Spasic and S. Ananiadou.
2004.Mining Biomedical Abstracts: What?s in aTerm?
Proc.
of IJC-NLP, pp.
247-254.NLM.
2004.
National Library of Medicine, UnifiedMedical Language System.Y.
Tsuruoka and J. Tsujii.
2003.
ProbabilisticTerm Variant Generator for Biomedical Terms.Proc.
of 26th Annual ACM SIGIR Conference.
