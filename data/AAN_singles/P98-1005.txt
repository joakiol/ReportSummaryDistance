Parole et traduction automatique :le module de reconnaissance RAPHAELMohammad AKBARGEOD, CLIPS/IMAGUniversit6 Joseph Fourier, BP.
5338041 Grenoble cedex 9, FranceMohammad.Akbar@imag.frJean CAELENGEOD, CLIPS/IMAGUniversit6 Joseph Fourier, BP.
5338041 Grenoble cedex 9, FranceJean.Caelen@imag.frR~sum~Pour la traduction de parole, il estn6cessaire de disposer d'un syst~me dereconnaissance d  la parole spontan6e grandvocabulaire, tournant en temps r6el.
Lemodule RAPHAEL a 6t6 con~u sur la plate-forme logicielle de JANUS-III d6velopp6eau laboratoire ISL (Interactive SystemsLaboratory) des universit6s Karlsruhe etCarnegie Mellon.
Le corpus BREF-80(textes lus extraits du Journal Le Monde) a6t6 utilis6 pour le d6veloppement,l'apprentissage et l'6valuation du module.Les r6sultats obtenus ont de l'ordre de 91%de bonne reconnaissance d mots.
L'articled6crit l'architecture du module dereconnaissance et son int6gration ~ unmodule de traduction automatique.Introduct ionLa traduction des documents 6crits a fait de r6elsprogr6s pendant ces derni6res ann6es.
Nouspouvons constater l'6mergence de nouveauxsyst~mes de traduction de textes qui proposentune traduction soign6e en diff~renteslangues\[1\].
I1 semble envisageable de lesadapter pour la traduction de l'oral, ~ conditiond'en am61iorer le temps de r6ponse et larobustesse : c'est le ~ challenge >> pos6 /~ cessyst~mes mais aussi au module dereconnaissance de Ia parole.
Un syst6me detraduction de l'oral repose sur l'int6gration desmodules de reconnaissance et de synth~se de laparole et des modules de traduction, pour obtenirune boucle complete d'analyse t de synth~seentre les deux intedocuteurs \[Fig.
1\].
Le projetCSTAR-II \[3\] est un projet international dartslequel toutes les 6quipes travaillent sur touslesaspects de ce module.Pour permettre /l deux personnes decommuniquer, il faut deux s&ies de processussym6triques dans les deux langues : un modulede reconnaissance pour acqu6rir et transcrire les6nonc6s dits par un locuteur dans sa langue palsun module de traduction qui traduit latranscription dans la langue du destinateur oudans un format d'6change standard (IF =Interchange Format) et enfin un module desynth~se de la parole (et de g6n6ration si onutilise le format IF) dans la langue cible duSynth~se ~ Traductionde la parole instantan6?
/ Transmission du texteI Reconnaissance Traduction ?
~ de la parole .
instantan6~Reconnaissance 1 de la parole \]Synth6se \]de la paroleFig.
1.
L'architecture d'un syst~me de traduction instantan6e.36destinateur.
Dans le cadre du projet C-STAR IInous avons en charge la conception et lar6alisation du module de reconnaissance d laparole continue ~ grand vocabulaire pour lefrangais.
Nous collaborons avec l'6quipe GETAdu laboratoire CLIPS-IMAG et le laboratoireLATL pour la traduction automatique t lelaboratoire LAIP pour la synth6se de la parole.Ce consortium s'est fix6 l'objectif de r6aliser unsyst+me de traduction de l'oral pour le frangais.Dans cet article nous allons tout d'abordpr6senter l'architecture du syst6me de traductionet la plate-forme de d6veloppement JANUS-III\[2\], puis les diff6rentes 6tapes du d6veloppementdu module RAPHAEL et enfin, les premiersr6sultats obtenus.1 RAPHAEL  pour  la TraductionL'architecture du syst~me de traduction deparole est compos6e de trois modules essentiels(la reconnaissance, la traduction et la synth~sede la parole) \[Fig.
2\].
Dans ce projet nousutilisons ARIANE et GB \[3\] pour la traductionet LAIP-TTS \[4\] pour la synth~se.
LeI Reconnaissance de la Parole \]RAPHAEL (CLIPS/IMAG-ISL)Texte Contr01eI Traduction Automatique 1ARIANE (GETA), GB (LATL)I Synth~se de la Parole \]LAIP-TTS (LAIP)Fig.
2.
Les composants du syst~med~veloppement du module de reconnaissanceRAPHAEL a 6t6 effectu6 sur la plate-formelogicielle de JANUS-Ill. RAPHAEL donne ensortie un treillis de mots sous le protocoleTCP/IP.
Le traducteur utilise ce r6sultat pour endonner une version traduite.
Cette version estensuite envoy6e au synth6tiseur de la parole.Dans cet article nous nous int6resseronsseulement au module de reconnaissanceRAPHAEL.
Pour l'instant la strat6gie d'6changeentre les modules est enti6rement s6quentielle.Afin d'am61iorer le r6sultat final (surtout dupoint de vue de la robustesse) nous envisageonsl'int~gration d'une seconde couche de contr61epour permettre le ~ restoring >> des hypothesesen tenant compte des taux de confiance associ~saux diff~rents mots de l'~nonc~ reconnu.1.1 P late- forme de JANUS- I l lCette plate-forme de traduction a 6t~ d~velopp~edans le laboratoire d'ISL des universit6sCarnegie Mellon et Karlsruhe t contient touslescomposants n6cessaires au d~veloppernent d'unsyst/~me de reconnaissance phon~mique ~ grandvocabulaire /l base de Chaines de MarkovCach~es (CMC) et de r~seaux de neurones.
Lafacilit6 d'~crire un module de reconnaissance enlangage Tcl/Tk avec JANUS-Ill nous permetd'adapter ses capacit~s selon les besoinsd'application et les caract~ristiques du frangais.De cette plate-forme, seul le moteur dereconnaissance est directement exploitS.
Mais letravail de preparation des bases de donn~es,l'apprentissage des modules de phonemes,l'6valuation sont ~galement effectu~s dans cetenvironnement de programmation.
Le langagePERL est en grand partie utilis6 parall~lementpour traitement du texte du corpus.Les d~tails techniques de JANUS-Ill sontdonn~s dans \[2\], \[5\], \[6\].
Cependant nous enpr~sentons bri~vement quelques points ci-apr~s.2 Le Module  RAPHAELL'architecture du module de reconnaissanceRAPHAEL est pr6sent6e sur la \[Fig.
3\].L'analyse de la parole produit une suite devecteurs de param6tres acoustiques.
Cesvecteurs ont utilis6s par un moteur de recherchebase de CMC pour estimer la suite desphon6mes 6none6s.
Un module de langagestochastique /~ bigramme t trigramme, et undictionnaire des variantes phon6tiques sont enparall61e xploit6s pour restreindre l  champ derecherche I.
Au cours de la recherche ledictionnaire phon6tique fournit le(s) phon6me(s)suivant(s).
Le mod61e probabiliste de langagebase de bigramme t de trigramme st utilis6lors de la transition entre deux mots pour fournirun ensemble de mots \[Fig.
4\].I Avec 45 phonemes n moyenne une suite de cinqphonemes se transforme th~oriquement  un arbrede d6cision de 455= 184,528,125 feuilles !37tion  1 la paroleTraitement um6rique, Estimation desparam~tres acoustiquesModUle stochastique de langage(bigramme et trigramme)I Base de donn6es des param~tres \]des Chaines de Markov Cach6es~ Cha~nes deMarkov Cach~es pour 1la reconnaissance phon6miqueDictionnaire phon~tique(vocabulaire d reconnaissance)no.j~,j,chsmbr~.Fig.
3.
Schema du module de reconnaissance phon~mique RAPHAEL.2.1 Cha\[ne de Markov  Cach~esPour utiliser les CMC il faut conduire une phased'apprentissage pr6alable dans laquelle onadapte les probabilit6s des transitions et dessymboles sortis pour un phon6me donn6 demani~re /~ ce que la probabilit6 du processusassoci6 soit maximale.
Les param~tres desmodules et la transcription phon6tique des6nonc6s du corpus sont deux 616ments essentielsd'apprentissage.RAPHAEL comporte 45 CMC repr6sentant 42phonemes de base du frangais et 3 mod61es pourle silence et le bruit.
A quelques exceptions prosles CMC se composent de trois 6tats.
Le vecteurde param~tres d'entr6e st de dimension 122.
LesCMC ont 16 distributions Gaussiennes pourchaque 6tat.Lors de l'apprentissage nous produisons latranscription phon6tique correspondante /~chaque 6nonc6 (cela se fait /~ l'aide dudictionnaire phon6tique).
Pour chaque 6nonc6les CMC correspondant aux phon6mes ontconcat6n6es pour cr6er une longue chaSne.Ensuite l'algorithme de Viterbi \[5\] propose unalignement de l'6nonc6 avec cette chaine.
Avec2 Les coefficients MFCC \[5\] d'ordre 16 sont calcul6ssur une trame de 16 ms de parole, avec un pasd'avancement de 10ms.
La parole est 6chantillonn6e16 kHz et sur 16 bits.
Les MFCC, l'6nergie dusignal, et leurs premi6re et seconde d6riv6es (51valeurs) subissent ensuite une analyse encomposantes principales (ACP) pour r6duire ladimension du vecteur /~ 12.
La matrice d'ACP estcalcul6e avant la phase d'apprentissage, surun grandcorpus enregistr6.cet algnement l'algorithme de Baum-Welch \[5\]proc~de ~ l'estimation des param6tres de chaqueCMC pr6sente dans la cha~ne.
Ce proc6d6 estr6p6t6 pour tous les 6nonc6s du corpusd'apprentissage t cela plusieurs fois.
Lapr6sence des diff6rents contextes phon6miquespermet / l ce  proc6d6 de minimiser le tauxd'erreur de reconnaissance.
L'6valuation du tauxd'erreur /l la fin de chaque it6ration permetd'6tudier l'avancement del'apprentissage.2.2 ModUle de langage stoehast iqueAfin de r6duire le champ de recherche, unmod61e de langage doit ~tre utilis6.
Bien quedans les syst6mes /l commande vocale quiutilisent une syntaxe r6duite les grammairesfinies ou r6currentes peuvent ~tre utilis6es,celles-ci ne sont pas capables de d6crire tous lesph6nom6nes de la langue parl6e (ellipses,h6sitations, r6p6titions, etc.).
Pour cette raison ilest souhaitable d'utiliser un module stochastiquequi estime dans un contexte donn6, la probabilit6de succession des mots.
Dans le mod61e actuelles contextes gauches d'ordres un et deux(bigramme t trigramme) sont en m~me tempsexploit6s.
Le bigramme est utilis6 dans lapremiere phase de recherche pour cr6er untreillis de mots, puis le trigramme st utilis6 pourraffiner le r6sultat et d6terminer les N meilleursphrases plausibles.
Le mod61e de langage secharge en m~me temps de la r6solution del 'accord en frangais.Le calcul des param~tres de ce module a ~t~effectu6 ~ partir des corpus enregistr6s ettranscrits.
Dans l'6tat actuel un vocabulaire de7000 mots a 6t6 s61ectionn6.38dRepr6sentation d'un phon6meDarts un mot ledictionnairephon6tique estutilis~ pour trouveret encha~ner lesphonemes suiv~mtsselon les variantesphon6tiquesdisponibles.L'hypoth6se de mot #1 ~-.....Pour d6terminer lesroots et les phon6messuivants le mod61estochastique dulangage t levocabulaire transcriten phon6tique sont enm~me temps utilis6s.L'hypoth6se de mot #2Fig.
4.
Repr6sentation deI'algorithme de recherche2.3 Dict ionnaire  Phon6tiqueLa conversion d'une chalne d'hypoth6sesphon6tiques en une chaine orthographique s fait/t partir d'un dictionnaire phon6tique.
Pourcouvrir un grand hombre de prononciationsdiff6rentes dues aux diff6rents dialectes de lalangue et aux habitudes des locuteurs, cedictionnaire contient pour chaque mot unensemble de variantes phon6tiques.
A chaquehypoth6se de mot propos6 par le mod61e delangage on associe cet ensemble de variantes.Ind6pendamment done de la variante utilis6edans l'6nonc6, nous obtenons la m~metranscription orthographique.
Nous utilisonssp6cifiquement cette technique pour couvrir lesvariantes produites par la liaison, par exemple :Je suis parti de la maison.
(-Z& sHi paRti ...)Je suis alld ~ la maison.
(Z& sHiz ale ...)ensemble de BREF-80 comprenant les 6nonc6sde 4 femmes et 4 hommes a 6t6 utilis6 pourl'6valuation 4.
Le vocabulaire a 6t6 transcrit soitmanuellement, soit /l partir du dictionnairephon6tique BDLEX-23000.
Le mod61e delangage a 6t6 estim6 h partir de BREF-80 et uncorpus de texte d'/t peu pr6s 10 millions de motsextrait du journal Le Monde.Pour l'initialisation des CMC, au lieu d'utiliserles valeurs al6atoires (technique habituelle),nous avons choisi d'utiliser les modules issus duprojet GlobalPhone \[7\].
Pour chaque phonemede notre module nous avons manuellementchoisi un phon6me dans une des languessupport6es par GlobalPhone (principalementallemande) et nous avons utilis6 ses param6trescomme valeurs initiales de nos CMC.
Ensuiteces mod61es ont 6t6 adapt6s au fran~ais aumoyen de l'algorithme d'apprentissage d6crit en2.1.
A la fin de chaque it6ration et ce pour 33 L'apprentissageLe corpus BREF-80 \[8\] comportant 53306nonc6s par 80 loeuteurs (44 femmes et 36hommes) 3 a 6t6 utilis6 pour les phasesd'apprentissage t d'6valuation.
Un sous-3 BREF-80 contient 3747 textes diff6rents et environ150,000 mots.4 Les sous-corpus de l'apprentissage t del'6valuation n'ont aucun 6none6 et locuteur encommun.
En r6alit6, nous avons enlev6 tous les6nonc6s en communs entre ces deux sous corpus.Ainsi le sous-corpus d'apprentissage comprend 4854~nonc6s et le sous-corpus d'6valuation 371 6nonc6s.Nous avons retir6 105 6nonc6s pour assurer ladisjonetion des deux sous-corpus.39itdrations, le syst~me a 6t6 6valu6 avec le souscorpus de l'dvaluation.4 R6sultatsLes r6sultats d'6valuation en terme de taux dereconnaissance sont donn6s dans le \[Tableau 1\].Syst~mes % mots reconnusModUles issus de GlobalPhone 29Premi&e itdration 88,8Troisidme itdration 91,1Tableau 1.
Les r6sultats de l'6valuation4.1 CommentairesUne tr~s bonne initialisation de certainesconsonnes identiques dans des diffdrenteslangues (p, t, k, b, d, g, etc.)
a rapidement permisd'obtenir un syst~me fonctionnel.On constate une saturation tr~s rapide du taux dereconnaissance d~s la troisi~me itdration.
Nouspouvons distinguer trois types de probldme quinous em#chent  d'atteindre un meilleur taux dereconnaissance :?
Fautes de frappe darts le texte du corpus,?
Transcription erronde ou insuffisammentddtai116e des 6noncds,?
La couverture partielle de toutes lesvariantes phondtiques d'un mot.Ces trois probl~mes ont les causes d'un grandnombre d'erreurs d'alignement qui vontdirectement influencer le rdsultat final.
Nousdevons donc effectuer une vdrification compldtedu corpus et du dictionnaire phondtique.Les mots hors du vocabulaire sont /~ l'origined'un pourcentage important d'erreurs.
En effet,dans 371 6noncds du sous-corpus de l'dvaluationnous rencontrons environ 300 mots horsvocabulaire.
Ces mots reprdsentent environ3,5 % de la taille du vocabulaire.
I1 ne sont pasreprdsentds dans le corpus d'apprentissage etleur transcription n'existe pas darts ledictionnaire phon&ique.Conclusion et perspectivesDans cet article nous avons bri~vement ddcrit,en termes d'avancement deprojet, notre syst~mede reconnaissance RAPHAEL /l grandvocabulaire et rapport6 des premiers rdsultatsobtenus.
Notre but est d'amdliorer le taux dereconnaissance par l'utilisation des moddlesphondtiques contextuels et d'61argir levocabulaire utilis6/t plus de 10000 mots.
Pouratteindre ce but nous allons spdcialiser levocabulaire dans le domaine du tourisme etutiliser d'autres corpus de la parole spontandedans ce domaine avec un nombre plus importantde locuteurs.
En mdme temps nous ddfinirons unprotocole d'dchange plus 6labor6 avec le modulede traduction afin de permettre lacommunication d'informations linguistiques etstatistiques au module de traduction, toujourdans le but d'amdliorer les performances denotre systdme.RemerciementNous remercions Alex Waibel pour la mise /ldisposition de JANUS-III et Tanja Schultz pourson support scientifique et technique dansl'utilisation des rdsultats du projet GlobalPhone.Rdfdrences1 Hutchins W. J.
(1986) Machine Translation : Past,Present, Future.
Ellis Horwood, John Wiley &Sons, Chichester, England, 382 p.2 Finke M., Geutner P., Hild H., Kemp T., Ries K.,Westphal M. (1997) : The Karlsruhe- VerbmobilSpeech Recognition Engine, Proc.
of ICASSP,Munich, Germany.3 Boitet Ch., (1986) GETA's MTmethodology and ablueprint for its adaptation to speech translationwithin C-STARII, ATR International Workshop onSpeech Translation, Kyoto, Japan.4 Keller, E. (1997).
Simplification of TTSarchitecture versus Operational quality,Proceedings of EuroSpeech'97, Rhodes, Greece.5 Rabiner L., Juang B.H.
(1993), Fundamentals ofSpeech Recognition, Prentice Hall, 507 p.6 Haton J.P., Pierrel J.M., Perennou G., Caelen J.,Gauvain J.L.
(1991), Reconnaissance automatiquede laparole, BORDAS, Paris, 239 p.7 Schultz T. Waibel A., Fast Bootstrapping ofL VCSR systems with multilingual phonem sets,Proceedings of EuroSpeech'97, Rhodes, Greece.8 Lamel L.F., Gauvain J.L., Eskenazi M. (1991),BREF, a Large Vocabulary Spoken Corpus forFrench, Proceedings of.
EuroSpeech'91, Genoa,Italy.40
