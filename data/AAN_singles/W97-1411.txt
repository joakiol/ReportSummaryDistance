Referring to Displays in Multimodal InterfacesDaqing  He  Graeme R i tch ieDept.
of Artificial Intelligence,University of Edinburgh,80 South Bridge,Edinburgh EH1 1HN, Scotlanddaq ingd ,  g raeme~da i ,  ed.
ac .
ukJohn  LeeHuman Communicat ion  Research Centre,University of Edinburgh2 Buccleuch Place,Edinburgh EH8 9LW, Scotlandj ohn@cogsci ,  ed.
ac .
ukAbst rac tA system which displays informationgraphically, and also allows natural lan-guage queries, should allow these queries tointerrogate he displayed (visual) informa-tion.
Ideally this would use some uniformmethod for processing queries both aboutthe display and about the world model.Such a system would have to cope with am-biguities introduced by these two sources ofinformation.
These ambiguities, and a pre-liminary proposal for a system to deal withit, are the main topics of this paper.1 In t roduct ionProjects which have attempted to' integrate nat-ural language (NL) with graphical displays (B~s andGuillotin, 1992; Neal and Shapiro, 1991; Pineda,1989) have mainly focussed on one of two problems:1.
How can output text be coordinated withgraphical information displayed on the screen?2.
How can pointing estures be coordinated withNL input?We are interested in a slightly different issue,namely:How can NL terms be used, in a relativelyuniform way, to refer to visual objectson the screen as well as the objects (forexample, database items) which theymay denote?The situation we have in mind is where the computersystem has some stored knowledge base, databaseor model, and is able to graphically display selecteditems from that store.
The user wishes to inter-act with the system, and may wish to ask questionswhich either allude to visual features of the display(e.g.
Is the blue zone inside the city boundary?)
orare directly about the meaning of the display (e.g.What does the blue marking represent?).
Such quer-ies require that the system have access to some rep-resentation ofwhat is represented onthe screen, andthat this representation beamenable to NL or mul-timodal (MM) querying.
12 Wor ld  Mode l  and  D isp lay  Mode lIt is common in systems which present visual in-formation on the screen (e.g.
GISs) for there to bea display model.
This is an explicit representationof what items are currently on the screen and whattheir characteristics are.
This is distinct from theworld model which represents the facts about theworld that the system has, which may not be dis-played on the screen.
In such systems, the main roleof the display model is to maintain the visual displayin an orderly fashion, and to connect screen objectsto world (or database) objects.
It must be updatedsystematically as items appear, disappear or moveon the screen.
Very often, the display model is quitea low-level structure, as it performs basic housekeep-ing for the display.Our proposal is that, for NL querying of the visualdisplay to be possible, the display model must con-tain suitable high level information i  a form whichis accessible to an NL front-end; preferably, this formwould be similar to, or related to, the representationthe NL front-end uses to access the world model.3 I l lustrat ive ExamplesA non-spatial domainIt might seem that queries about he visual displaywould make sense only in a domain where spatial in-1We shall discuss natural language, but with the as-sumption that working systems in a few years' timewould operate with speech input.80 D. He, G. Ritchie and J. Leeformation is directly relevant, such as a street mapor room plan.
However, if an iconic display is beingused to represent some non-spatial set of objects,it might still be desirable to use visual attributes torefer to these abstract icons.
To make these remarksslightly more concrete, let us consider a (fictitious)example system.
This system does not handle spa-tial information, but it uses iconic representationson the screen to convey database facts to the user.The application is a car-sales catalogue, in whicha number of (presumably used/second-hand/pre-owned) cars are available for the user to browsethrough.
Icons on the screen represent individualcars, and various characteristics of the icons conveyattributes of the corresponding cars (Figure 1).
Thennnunn Nun7,000-7,500 \ [ \ ]  blue -> 1993 N NissanP Peugeot 7,500-8,000 \ [ \ ]  red -> 1994v Vauxhall\[ 8,000-8 00 \[ \]    n.,1995 F FordFigure 1: A ear selection systemsize of an icon conveys the price band, the colourconveys the year of production, and the letter oneach icon indicates the initial of the manufacturer.The user can point to icons, move icons round, orask questions about them, such as What is the insur-ance group of the ear in the top right hand corner?,Is the green car a hatehback?.
Notice that spatialphrases (in the top right hand corner) can be used,even though this is a non-spatial domain.
Also, thecolour adjective green would (given the coding inFigure 1) probably refer to the colour of the icon onthe screen rather than the colour of the actual car,but a similar scenario can be imagined where a col-our term would be used to denote the colour of theactual world object.
In some cases, both might bepossible, leading to ambiguity (Wilson and Conway,1991).What is clear from this is that the mapping fromthe world model (database) to the display model iscentrally important.
In particular, if we wish to beable to handle questions which are explicitly aboutthe visual representation, such as What does greenrepresent?, the mapping itself must be accessible tosome form of symbol querying by the NL/MM inter-face.A spat ia l  domainLet us now consider a (fictitious) spatial domain.In this domain, a 2D graphic display is being used tohelp the user plan the layout of a room.
The displayrepresents he overall plan, and icons are stylised im-ages of furnishings and fittings.
In such a situation,the user might pose queries such as What kind ofchair is to the right of the table ?, Would a cupboardfit above the table ?.
Here, spatial relations are againused, but there is potential ambiguity as to whetherthey refer to relations in the world being modelled,or on the screen.
An object might be "above" thetable in the image, but "to the left" of it in reality.4 Leve ls  o f  ambigu i tyAs argued above, certain forms of reference (e.g.
col-our, spatial relations) can be ambiguous betweenvisual characteristics of the display and actual char-acteristics of the world being modelled.
For referringexpressions, there are two levels to this ambiguity:Descr ibed  re ferent .
When the query interpreteris processing a referring expression, it has todetermine in which model - the display modelor the world model - the features of the object(e.g.
colour, size) are being described, and henceused to indicate the referent.
During this pro-cess, the objects in the world model and those inthe display model should be counted as differ-ent even in cases where a representation relationexists between them.There may, as noted above, be ambiguity here,between the two models.I n tended re ferent .
Even if a unique object is de-termined (a display object such as an icon ora world object such as a database item), it isconceivable that this object is being used asa surrogate to refer to the corresponding ob-ject under the mapping relation.
This can beillustrated using the "car" domain introducedearlier.
In a query such as What is the price ofthe blue one?, the colour blue may be (unam-biguously) a display feature, indicating a blueicon, but the intended referent (for use in theprice predicate) is the corresponding world ob-ject, not the icon (cars have prices, icons doReferring to Displays in Mult imodal Interfaces 81not).
Conversely, in a command Move the 1.5litre car to the top of the screen, the noun phraseuses domain attributes to indicate a domain ob-ject, but the action of move is to operate on thecorresponding display object.
The third, andsimplest, possibility is that there is no interven-ing use of the mapping relation - the describedreferent is itself the intended referent.This level of indirection can lead to ambiguitywhen the noun phrase is viewed in isolation,since the choice of intended referent often needsinformation from the rest of the sentence, orfrom the context, to disambiguate it.The consequence of this added level of ambiguityis that the normal way of considering the "sense"and "reference" of an NL phrase has to be recon-sidered.
Instead of the usual two-level approach inwhich a symbolic description (the sense) is evalu-ated, matched, or otherwise processed to producea particular set of objects (the reference), we needa three-level approach allowing for sense, describedreferent, and intended referent.
All of these have tobe managed systematically, sothat the correct rela-tionships are maintained, and utilised, between thevarious objects./y'-x \User query user query respoose(semantic form) (referents resolved) to userFigure 2: Proposed architecture for allowing referenceto display, world and mapping5 Our  a imThe aim of our project is to devise a uniform, generaland flexible architecture and representation mechan-ism by which a NL/MM query system can processqueries about objects displayed on the screen, aboutobjects in the database or world model, and aboutthe relationship between these two.
By "general",we mean that the mechanisms should not be hard-wired or domain-specific.
We intend to produce amethod whereby a given database and a formallyspecified visual representation scheme for the data-base entities can be used to interface directly witha domain independent NL front-end system, thusbuilding a working multi-media system.6 P re l iminary  P roposa lsIn order to facilitate inter-module communication,and to allow for possible symbolic reasoning, a high-level symbolic representation is needed (see figure 2).Pointing facilities are included in the system, com-bining with the graphic display and NL interpreterto form a multimodal system.
Pointing should as-sist in resolving ambiguity (of described referent, notintended referent), but the main component for deal-ing with these ambiguities i  the reference model.It is clear that the resolving of references in such asystem could, in general, depend upon a wide varietyof sources of knowledge, including the following:Local Semant ic  P roper t ies  The noun phrase it-self will supply the most immediate constraintson choice of (described) referent, in terms of thehead noun and its modifiers such as adjectivesand prepositional phrases.Semantic Relat ions Processing of referents mustalso take account of relations which are notshown in the noun phrase but which involve thereferent(s) and other display/world objects.Mutua l  Bel iefs The user and the system shouldknow the referent object and its described fea-tures, and at the same time both should ac-knowledge that the other knows the object andits features as well ((Clark and Marshall, 1981),p57).
In a multimodal environment, here arevarious ways for an object to be acknowledgedby both dialogue participants: either it is dis-played on the screen, or it is mentioned in pre-vious dialogue, or it is part of common senseknowledge for both speaker and listener.
Avariety of pragmatic inferences might be pos-sible.
For example, in the query 2 What colouris this/~ ?, it may be possible that either modelis in question, but it is unlikely that the displayproperty is intended because it is already clearlyvisible.
Moreover, as we suggested, the displayproperty may represent some other property inthe world model, so that if the user says What isthe price band of this/2 ?, it may be inferrableboth that he user must mean the car (ratherthan the icon), and also that it would be appro-priate to give a reminder (e.g.
Colour represents2The/~ means a pointing act happens here.82 D. He, G. Ritchie and J. Leeprice band) about the depictive mapping, sincethe user is querying a directly depicted worldproperty.Coherence The coherence of the proceeding dia-logue should not be damaged by an object be-coming the referent of the expression (Groszand Sidner, 1986).It follows that the disambiguation process shouldbe based on the following information sources: theworld model and the display model for the sources ofcandidates and the examination of various restric-tions, the dialogue model for providing coherence in-formation about the dialogue and the user model forthe modelling of mutual beliefs.
In practice, our pro-ject is too limited to explore all of these issues, andwe intend to leave aside issues of mutual belief (thatis, our "user model" will be degenerately simple).It seems plausible that the consideration of de-scribed referents could be restricted, in this morelimited project, to the use of "Local Semantic Prop-erties" (in the above list).
As argued in anothercontext (Ritchie, 1976; Ritchie, 1983), broader se-mantic onstraints ( uch as relations to other objectsor even existence inthe current situation) are largelyconcerned with the eventual referent, rather than su-perficial aspects of how it happens to be described.Even the question of whether a phrase is a semantic-ally compatible subject or object of a particular verbis a constraint on the referent, not the symbolic ex-pression describing it.
In the revised three-level ar-rangement suggested earlier, such constraints wouldbe on the intended referent rather than the describedreferent.
That is, in a sentence like "What kind offuel-injection system does the blue one have?"
theconstraint that the referent must be a type of ob-ject which can have a fuel-injection system is to beimposed upon the intended referent.This suggests, at least superficially, that thedescribed referent might be calculated relativelysimply using just the properties of the noun phrase,without much inference.
The more difficult ques-tion of determining the intended referent would theninvolve potentially complicated inference about do-main objects, etc.
This would allow a two stagereferent determination approach: find the describedreferent, then compute possible intended referents.As a benefit of this approach, a pointing action,which can be seen as a short way to indicate adescribed referent, could be included in a modularfashion.During these inferences (particularly the searchfor intended referents), a variety of sources of in-formation may affect the result.
It is therefore ne-cessary to have some mechanisms which allow theinteraction of these disparate sources.
It is possiblethat some of the constraint-satisfaction suggestionsof (Mellish, 1985) might be useful.If none of the available sources of information re-solve the ambiguities, then the query as a whole isambiguous, but it seems unlikely that this wouldhappen in practice.
The challenge is that the pro-cessing method should be equally effective at makinguse of these sources of disambiguation.
Our object-ive is to allow for as much flexibility as we can inthe referential phenomena, but we acknowledge in-evitable limitations.Acknowledgements: The first author (DaqingHe) is supported by a Colin & Ethel Gordon Schol-arship from the University of Edinburgh.ReferencesB~s, G. and Guillotin, T. (1992).
A natural lan-guage and graphics interface, results and perspect-ives the A CORD project.
Springer-Verlag, Berlin,Germany.Clark, H. and Marshall, C. (1981).
Definite refer-ence and mutual knowledge.
In Joshi, A., Webber,B., and Sag, I., editors, Elements of discourse un-derstanding, chapter 1, pages 10-63.
CambridgeUniversity Press, Cambridge, UK.Grosz, B. J. and Sidner, C. (1986).
Attention, In-tentions, and the Structure of Discourse.
Compu-tational Linguistics, 12(3):175-204.Mellish, C. S. (1985).
Computer interpretationof natural language descriptions.
Ellis Horwoodseries in artificial intelligence.
Ellis Horwood.Neal, J. and Shapiro, S. (1991).
Intelligent Multi-media Interface Technology.
In Sullivan, J. andTyler, S., editors, Intelligent User Interfaces,pages 11-44.
ACM Press.Pineda, L. A.
(1989).
GRAFLOG: A Theory of Se-mantics fro Graphics with Applications to Human-Computer Interaction and CAD Systems.
PhDthesis, University of Edinburgh, Edinburgh UK.Ritchie, G. (1976).
Problems in local semantic pro-cessing.
In Proceedings of AISB Conference, pages234-241, Edinburgh, Scotland.Ritchie, G. (1983).
Semantics in parsing.
In King,M., editor, Parsing Natural Language, pages 199-217.
Academic Press, North Holland.Wilson, M. and Conway, A.
(1991).
Enhanced inter-action style for user interfaces.
IEEE ComputerGraphics and Applications, 11 (2) :79-90.m
