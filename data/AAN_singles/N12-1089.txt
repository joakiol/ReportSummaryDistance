2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 710?719,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsAutonomous Self-Assessment of Autocorrections: Exploring Text MessageDialoguesTyler BaldwinDepartment of ComputerScience and EngineeringMichigan State UniversityEast Lansing, MI 48824baldwi96@cse.msu.eduJoyce Y. ChaiDepartment of ComputerScience and EngineeringMichigan State UniversityEast Lansing, MI 48824jchai@cse.msu.eduAbstractText input aids such as automatic correctionsystems play an increasingly important role infacilitating fast text entry and efficient com-munication between text message users.
Al-though these tools are beneficial when theywork correctly, they can cause significantcommunication problems when they fail.
Toimprove its autocorrection performance, it isimportant for the system to have the capabil-ity to assess its own performance and learnfrom its mistakes.
To address this, this pa-per presents a novel task of self-assessment ofautocorrection performance based on interac-tions between text message users.
As part ofthis investigation, we collected a dataset of au-tocorrection mistakes from true text messageusers and experimented with a rich set of fea-tures in our self-assessment task.
Our exper-imental results indicate that there are salientcues from the text message discourse that al-low systems to assess their own behaviors withhigh precision.1 IntroductionThe use of SMS text messaging is widespread andgrowing.
Users of text messaging often rely on smallmobile devices with limited user interfaces to com-municate with each other.
To support efficient com-munication between users, many tools to aid text in-put such as automatic completion (autocompletion)and automatic correction (autocorrection) have be-come available.
When they work correctly, thesetools allow users to maintain clear communicationwhile potentially increasing the rate at which theyinput their message, improving efficiency in com-munication.
However, when these tools make a mis-take, they can cause problematic situations.
Con-sider the following example:A1: Euthanasia doing tonight?B1: Euthanasia?
!A2: I typed whatcha and stupid autotype.In this example, the automatic correction systemon person A?s phone interpreted his attempt to writethe word whatcha as an attempt to write euthanasia(due to the keyboard adjacency of the w and e keys,etc.).
This completely changed the meaning of themessage, which confused person B.
Although thisinstance was eventually discovered and corrected,the natural flow of conversation was interrupted andthe participants were forced to make extra effort toclarify this confusion.This example indicates that the cost of a mistakein autocorrection is potentially high.
This is exacer-bated by the fact that users will often fail to noticethese mistakes in a timely manner, due to their focusbeing on the keyboard (Paek et al, 2010) and thequick and casual conversation style of text messag-ing.
Because of this, autocorrection systems musthave high accuracy to be useful for text messaging.This example also indicates that, when an autocor-rection mistake happens (i.e., mistaken correctionof euthanasia), it often causes confusion which re-quires dialogue participants to use the follow-up dia-logue to clarify the intent.
What this suggests is thatthe discourse between text message users may pro-vide important information for autocorrection sys-710tems to assess whether an attempted correction isindeed what the user intended to type.Self-assessment of its correction performance willallow an autocorrection system to detect correctionmistakes, learn from such mistakes, and potentiallyimprove its correction performance for future opera-tions.
For instance, if a system is able to identify thatits current autocorrection policy results in too manymistakes it may choose to adopt a more cautious cor-rection policy in the future.
Additionally, if it is ableto discover not only that a mistake has taken placebut what the ideal action should have been, it will beable to use this data to learn a more refined policyfor future attempts.Motivated by this observation, this paper inves-tigates the novel task of self-assessment of auto-correction performance based on interactions be-tween dialogue participants.
In particular, weformulate this task as the automatic identificationof correction mistakes and their corresponding in-tended words based on the discourse.
For instance,in the previous example, the system should automat-ically detect that the attempted correction ?euthana-sia?
is a mistake and the true term (i.e., intendedword) should have been ?whatcha?.
To support ourinvestigation, we collected a dataset of autocorrec-tion mistakes from true text message users.
We fur-ther experimented with a rich set of features in ourself-assessment task.
Our experimental results in-dicate that there are salient cues from the text mes-sage discourse that potentially allow systems to as-sess their own behavior with high precision.In the sections that follow, we first introduce andgive an analysis of our dataset.
We then highlightthe two interrelated problems that must be solved forsystem self-assessment, and outline and evaluate ourapproach to each of these problems.
Finally, we ex-amine the results of applying the system assessmentprocedure end-to-end and discuss potential applica-tions of autocorrection self-assessment.2 Related WorkSpelling autocorrection systems grew naturally outof the well studied field of spell checking.
Most spellchecking systems are based on a noisy channel for-mulation (Kernighan et al, 1990).
Later refinementsallowed for string edit operations of arbitrary length(Brill and Moore, 2000) and pronunciation modeling(Toutanova and Moore, 2002).
More recent workhas examined the use of the web as a corpus to builda spell checking and autocorrection system withoutthe need for labeled training data (Whitelaw et al,2009).Traditional spell checking systems generally as-sume that misspellings are unintentional.
However,much of the spelling variation that appears in textmessages may be produced intentionally.
For in-stance, text message authors make frequent use ofacronyms and abbreviations.
This motivates thetask of text message normalization (Aw et al, 2006;Kobus et al, 2008), which attempts to transform allnon-standard spellings in a text message into theirstandard form.
The style of misspelling in text mes-sages is often quite different from that of standardprose.
For instance, Whitelaw et.
al.
(2009) appliedthe Aspell spell checker1 on a corpus of mistakes inEnglish prose and achieved an error rate of under5%.
Conversely, the same spell checker was foundto have an error rate of over 75% on text messagedata (Choudhury et al, 2007).Autocorrection in text messaging is similar to pre-dictive texting and word completion technologies(Dunlop and Crossan, 2000).
These technologiesattempt to reduce the number of keystrokes a usermust type (MacKenzie, 2002), potentially speedingup text entry.
There are 2 primary sources of liter-ature on text prediction.
In one (often called auto-completion), systems attempt to predict the intendedterm before the user has finished typing it (Darraghet al, 1990; Chaudhuri and Kaushik, 2009).
In thesecond, the system attempts to interpret ambiguoususer input typed on a keyboard with a small numberof keys, such as the 12 key keyboards found on manymobile phones (MacKenzie and Tanaka-Ishii, 2007).Few studies have looked at the effects SMS writingstyle has on predictive text performance.
How andKan (2005) analyze a corpus of 10,000 text mes-sages and conclude that changing the standard map-ping of letters to keys on 12 key keyboards couldimprove input performance on SMS data.Although never examined in the context of auto-correction systems, system self-assessment has beenstudied in other domains.
One of the most com-1http://aspell.net/711Figure 1: Example text message dialogue from our cor-pus with an automatic correction mistakemon application domains is spoken dialogue sys-tems (Levow, 1998; Hirschberg et al, 2001; Litmanet al, 2006), where detecting problematic situationscan help the system better adapt to user behavior.These systems often make use of prosody and taskspecific dialogue acts, two feature sources unavail-able in general text message dialogues.In summary, while a large body of work addressessimilar problems, to our knowledge no previouswork has looked into the aspect of self-assessmentof autocorrection based on dialogues between textmessage users.
The work presented in this paperrepresents a first step in this direction.3 Data SetTo support our investigation, we collected a cor-pus of data containing true experiences with auto-correction provided by text message users.
Thewebsite ?Damn You Auto Correct?2 (DYAC) postsscreenshots of text message conversations that con-tain mistakes caused by phone automatic correctionsystems, as sent in by cellphone users.
An examplescreenshot is shown is Figure 1.Speech bubbles originating from the left of theimage in Figure 1 are messages sent by one dialogueparticipant while those originating from the right ofthe image are sent by the other.
In this example, theautomatic correction system incorrectly decides thatthe user?s attempt to write the non-standard wordform thaaaats was an attempt to write the word Tus-saud.
This confuses the reader, and several dialogueturns are used to resolve the confusion.
The author2www.damnyouautocorrect.comexplicitly corrects her mistake by writing ?I meantthaaaats?.Note that, in this example, the word Tussaudcould be an autocompletion or an autocorrectionby the system.
However, there may be no signifi-cant distinction between these two operations froma user?s point of view.
These two operations couldalso take place at the same time.
For instance, asystem may both suggest possible completions afterthe user has only typed a small number of charactersand perform autocorrection once the user presses thespace bar to go on to the next word.
Therefore, forthe purposes of our discussion here, we use autocor-rection to refer to any changes made by the system(either by autocompletion or autocorrection) with-out the user explicitly selecting the correction them-selves.Throughout the paper, we use the term attemptedcorrection to refer to any autocorrection made bythe system; for example, Tussaud is an attemptedcorrection in Figure 1.
Some attempted correctionscould correct to the word that the user intended,which will be referred to as unproblematic cor-rections or non-erroneous corrections.
Other at-tempted corrections may mistakenly choose a wordthat the user did not intend to write, which will be re-ferred to as correction mistakes or erroneous cor-rections.
For example, Tussaud is an erroneous cor-rection.
We use the term intended word to refer tothe term that the user was attempting to type whenthe autocorrection system intervened.
For instance,in the erroneous correction in Figure 1, the intendedterm was thaaaats.To build our dataset, screenshots were extractedfrom the site and transcribed, and correction mis-takes were annotated with their intended words, ifthe intended word appeared in the dialogue.
Be-cause the website presents autocorrection mistakesthat submitters find to be humorous or egregious,there may be an incentive for users to submit fal-sified instances.
To combat this, we performed aninitial filtering phase to remove instances that wereunlikely to have been produced by a typical autocor-rection system (e.g., instances that substituted lettersthat were far from each other on the keyboard andnot phonetically similar) or that were otherwise be-lieved to be falsified.
Using this methodology wecompiled a development set of 300 dialogues and an712Figure 2: Text message dialogue with several correctionmistakes for the same intended term.additional 635 dialogues for evaluation.Some dialogues contained several correction mis-takes.
It was common for multiple correction mis-takes to be produced in an attempt at typing a singleword; an example is shown in Figure 2, in whichthe intended term cookies is erroneously correctedat first as commies and then as cockles.We will use the term message to refer to one SMStext message sent in the course of the conversation,while a turn encompasses all messages sent by a userbetween messages from the other participant.
Forinstance, the first 3 speech bubbles in Figure 2 allrepresent separate messages, but they are all part ofthe same turn.While this dataset provides us with instances ofautocorrection mistakes, in order to differentiate be-tween problematic and unproblematic correction at-tempts we will need a dataset of unproblematic at-tempts as well.
It should be noted that, from the per-spective of the reader, a successful autocorrection at-tempt is equivalent to the user typing correctly with-out any intervention from the system at all.
To builda dataset of unproblematic instances, we collectedtext message conversations from pairs of users with-out the aid of autocorrection.
Users were then askedto correct any mistakes they produced.
Snippetsof these conversations that did not contain mistakeswere then extracted to act as a set of unproblematicautocorrection instances.
In total 554 snippets wereextracted.
These snippets were combined with theproblematic instances from the DYAC data to makethe final dataset used for training and evaluation.4 Autocorrection Self-AssessmentIt is desirable for an autocorrection system to havethe capability to assess its own performance.
Foreach correction attempt it makes, if the system canevaluate its performance based on the dialogue it canacquire valuable information to learn from its ownmistakes and thus improve its performance for fu-ture operations.
Next we describe how we formulatethe task of self-assessment and what features can beused for this task.Because each correction attempt is system gener-ated, an autocorrection system should have knowl-edge of all correction attempts it has made.
Let Cbe the set of all correction attempts performed by anautocorrection system over the course of a dialogueand let W be the set of all words in this dialoguewhich occur after the correction attempt.
We modelthis problem as two distinct subtasks: 1) identify at-tempted corrections ci ?
C which are erroneous (ifthere are any), and 2) for each erroneous correctionci, identify a word wj ?
W which is the intendedword for ci (i.e., Intended(ci) = wj).4.1 Identifying Erroneous CorrectionsThe first task involves a simple binary decision;given an arbitrarily sized dialogue snippet contain-ing an automatic correction attempt, we must decidewhether or not the system acted erroneously whenmaking the correction.
We thus model the task asa binary classification problem in which we classifyevery correction attempt c ?
C as either erroneousor non-erroneous.The proposed method follows a standard proce-dure for supervised binary classification.
First wemust build a set of labeled training data in whicheach instance is represented as a vector of featuresand a ground truth class label.
Given this, we cantrain a classifier to differentiate between the twoclasses.
For the purposes of this work we use a sup-port vector machine (SVM) classifier.4.1.1 Feature SetIn order to detect problematic corrections, wemust identify dialogue behaviors that signify an er-ror has occurred.
We examined the dialogues inour development set to understand which dialoguebehaviors are indicative of autocorrection mistakes.While in unproblematic dialogues users are able toconverse freely, in problematic dialogues users mustspend dialogue turns reestablishing common ground(Clark, 1996).
Our feature set will focus on twocommon ways these attempts to establish common713ground manifest themselves: as confusion and as at-tempts to correct the mistake.Confusion Detection Features.
Because autocor-rection mistakes often result in misleading or se-mantically vacuous utterances, they are apt to con-fuse the reader, who will often express this confu-sion in the dialogue in order to gain clarification.These features examine the dialogue of the uncor-rected user (the dialogue participant that reads theautomatic correction mistake, not the one that wasautomatically corrected).
One sign of confusion isthe use of the question mark, so one feature capturedthe presence of question marks in the messages sentby the uncorrected user.
Similarly, users may oftenuse a block or repeated punctuation of show supriseor confusion, so another feature detected instancesof repeated question marks and exclamation points(??
?, !?!
!, etc.).
When confused, readers will oftenretype the confusing word as a request for clarifica-tion (e.g., Tussaud?
), or simply type ?what??.
Wetherefore include features that detect whether or notthe corrected term appears in the first message sentby the uncorrected user after the correction mistakehas occurred, and whether or not this message con-tains the word ?what?
as its own clause.Clarification Detection Features.
In contrast to ut-terances of confusion which are generally producedby the reader of the autocorrection mistake, clarifi-cation attempts are usually initiated by the user thatwas corrected.
Several methods are used to indicatethat the term shown by the system was incorrect.One convention is to use an asterisk (*) either be-fore or after the corrected term:A1: Indeed SidA2: Sir*Another common method is to explicitly statewhat was intended using phrases such as ?I meantto type?, ?that was supposed to say?, etc.
We in-cluded several features to capture these word pat-terns.
Another method is to simply quickly replywith the word that was intended, so we included afeature to record whether the next message after thecorrection attempt contains only a single word.
Asusers often feel the need to explain why the mistakeoccurred, we included a feature that recorded anymention or autocompletion, autocorrection or spellFeatures Precision Recall F-MeasureAll Features .861 .751 .803-Confusion .857 .725 .786-Clarification .848 .676 .752-Dialogue .896 .546 .679Baseline .568 1 .724Table 1: Feature ablation results for identifying autocor-rection mistakeschecking.
One additional feature recorded whetheror not the corrected user?s dialogue contained wordswritten in all capital letters.Dialogue Features.
A few features captured infor-mation more closely tied to the flow of the dialoguethan to confusion or clarification.
In our develop-ment set, we observed a few common dialogue for-mats.
In one, a correction mistake is immediatelyfollowed by confusion, which is then immediatelyfollowed by clarification.
The dialogue in Figure 1gives an example of this.
To capture this form, weincluded a feature that recorded whether a confusionfeature was present in the message immediately fol-lowing the correction attempt and whether a clarifi-cation feature was present in the message immediatefollowing the confusion message.
Similarly, clarifi-cation attempts are often tried immediately after themistake even if no confusion was present, so an ad-ditional feature captured whether the first messageafter the mistake by the corrected user was a clari-fication attempt.
Additionally, we observed that au-tocorrection mistakes frequently appeared in the lastword in a message, which was recorded by anotherbinary feature.
Finally, we recorded a count of howoften the corrected term appeared in the dialogue.4.1.2 EvaluationTo build our classifier we used the SVMLight3implementation of a support vector machine clas-sifier with an RBF kernel.
To ensure validity andaccount for the relatively small size of our dataset,evaluation was done via leave-one-out cross valida-tion.Results are shown in Table 1.
A majority classbaseline is given for comparison.
As shown, usingthe entire feature set, the classifier achieves abovebaseline precision of 0.861, while still producing re-call of 0.751.3Version 6.02, http://svmlight.joachims.org/714Although F-measure is reported, it is unlikely thatprecision and recall should be weighted equally.
Be-cause one of the primary reasons we may wish todetect problematic situations is to automatically col-lect data to improve future performance by the au-tocorrection system, it is imperative that the datacollected have high precision in order to reduce theamount of noise present in the collected dataset.Conversely, because problematic situation detectioncan monitor a user?s input continuously for an in-definite period of time in order to collect more data,recall is less of a concern.To study the effect of each feature source, we per-formed a feature ablation study, the results of whichare included in Table 1.
For each run, one featuretype was removed and the model was retrained andreassessed.
As shown, removing any feature sourcehas a relatively small effect on the precision but amore substantial effect on the recall.
Confusion de-tection features seem to be the least essential, caus-ing a comparatively small drop in precision and re-call values when removed.
Removing the dialoguefeatures results in the greatest drop in recall, return-ing only slightly above half of the problematic in-stances.
However, as a result, the precision of theclassifier is higher than when all features are used.4.2 Identifying The Intended TermNote that one purpose of the proposed self-assessment is to collect information online and thusmake it possible to build better models.
In orderto do so, we need to know not only whether thesystem acted erroneously, but also what it shouldhave done.Therefore, once we have extracted a set ofproblematic instances (and their corresponding dia-logues), we must identify the term which the userwas attempting to type when the system intervened.First, assume that via the classification task de-scribed in Section 4.1 we have identified a set of er-roneous correction attempts, EC.
Now the problembecomes, for every erroneous correction c ?
EC,identify w ?
W such that w = Intended(c).
Wemodel this as a ranking task, in which all w ?
Ware ranked by their likelihood of being the intendedterm for c. We then predict that the top ranked wordis the true intended term.4.2.1 Feature SetTo support the above processing, we explored adiverse feature set, consisting of five different fea-ture sources: contextual, punctuation, word form,similarity, and pattern features, crafted from an ex-amination of our development data.
Several of thefeatures are related to those used in the initial clas-sification phase.
However, unlike our classificationfeatures, these feature focus on the relationship be-tween the erroneous correction c and a candidate in-tended term w.Contextual Features.
Contextual features capturerelevant phenomena at the discourse level.
After anerror is discovered by a user, they may type an in-tended term several times or type it in a message byitself in order to draw attention to it.
These phe-nomena are captured in the word repetition and onlyword features.
Another common discourse relatedcorrection technique is to retype some of the origi-nal context, which is captured by the word overlapfeature.
The same author feature indicates whetherc and w are written by the same author.
The authorof the original mistake is likely the one to correct it,as they know their true intent.Punctuation Features.
Punctuation is occasionallyused by text message writers to signal a correction ofan earlier mistake, as noted previously.
We includedfeatures to capture the presence of several differentpunctuation marks occurring before or after a candi-date word such as *,?,!, etc.
Each punctuation markis represented by a separate feature.Word Form Features.
Word form features cap-ture variations in how a word is written.
One wordform feature captures whether a word was typed inall capital letters, a technique used by text messagewriters to add emphasis.
Two word form featureswere designed to capture words that were potentiallyunknown to the system, out-of-vocabulary wordsand words with letter repetition (e.g., ?yaaay?).
Be-cause the system does not know these words, itwill consider them misspellings and may attempt tochange them to an in-vocabulary term.Similarity Features.
Our similarity feature cap-tured the character level distance between a wordchanged by the system and a candidate intendedword.
We calculated the normalized levenshtein editdistance between the two words as a measure of sim-71500.20.40.60.810  0.2  0.4  0.6  0.8  1PrecisionRecallAll Features-Contextual-Punctuation-SimilarityBaselineFigure 3: Precision-recall curve for intended term selec-tion, including feature ablation resultsilarity.Pattern Features.
Pattern features attempt to cap-ture phrases that are used to explicitly state a cor-rection.
These include phrases such as ?
(I) meantto write w?, ?
(that was) supposed to say w?, ?
(that)should have read w?, ?
(I) wrote w?, etc.4.2.2 EvaluationTo find the most likely intended term for a cor-rection mistake, we rank every candidate word in Wand predict that the top ranked word is the intendedterm.
We used the ranking mode of SVMlight totrain our ranker.
By thresholding our results to onlytrust predictions in which the ranker reported a highranking value for the top term, we were able to ex-amine the precision at different recall levels.
Thatis, if the top ranked term does not meet the thresh-old, we simply do not predict an intended term forthat instance, hurting recall but hopefully improv-ing precision by removing instances that we are notconfident about.
This thresholding process may alsoallow the ranker to exclude instances in which the in-tended term does not appear in the dialogue, whichare hopefully ranked lower than other cases.
As be-fore, evaluation was done via leave-one-out crossvalidation.Results are shown in Figure 3.
As a methodof comparison we report a baseline that selects theword with the smallest edit distance as the intendedterm.
As shown, using the entire feature set resultsin consistently above baseline performance.As before, we are more concerned with the pre-cision of our predictions than the recall.
It is diffi-cult to assess the appropriate precision-recall trade-off without an in-depth study of autocorrection us-age by text messagers.
However, a few observationscan be made from the precision-recall curve.
Mostcritically, we can observe that the model is able topredict the intended term for an erroneous correc-tion with high precision.
Additionally, the precisionstays relatively stable as recall increases, sufferinga comparatively small drop in precision for an in-crease in recall.
At its highest achieved recall valuesof 0.892, it maintains high precision at 0.869.Feature ablation results are also reported in Fig-ure 3.
The most critical feature source was wordsimilarity; without the similarity feature the perfor-mance is consistently worse than all other runs, evenfalling below baseline performance at high recalllevels.
This is not suprising, as the system?s incor-rect guess must be at least reasonably similar to theintended term, or the system would be unlikely tomake this mistake.
Although not as substantial asthe similarity feature, the contextual and punctuationfeatures were also shown to have a significant effecton overall performance.
Conversely, removing wordform or pattern features did not cause a significantchange in performance (not shown in Figure 3 to en-hance readability).5 An End-To-End SystemIn order to see the actual effect of the full system,we ran it end-to-end, with the output of the initialerroneous correction identification phase used as in-put when identifying the intended term.
Results areshown in Figure 4.
The results of the intended termclassification task on gold standard data from Figure3 are shown as an upper bound.As expected, the full end-to-end system producedlower overall performance than running the tasks inisolation.
The end-to-end system can reach a recalllevel of 0.674, significantly lower than the recall ofthe ground truth system.
However, the system stillpeaks at precision of 1, and was able to produce pre-cision values that were competitive with the groundtruth system at lower recall levels, maintaining a pre-cision of above 0.90 until recall reached 0.396.It is worth mentioning that the current evalua-71600.20.40.60.810  0.2  0.4  0.6  0.8  1PrecisionRecallGold StandardEnd To EndFigure 4: Precision-recall curve for the end-to-end sys-temtion is based on a balanced dataset with roughlyeven numbers of problematic and unproblematic in-stances.
It is likely that in a realistic setting an au-tocorrection system will get many more instancescorrect than wrong, leading to a data distributionskewed in favor of unproblematic instances.
Thissuggests that the evaluation given here may overes-timate the performance of a self-assessment systemin a real scenario.
Although the size of our datasetis insufficient to do a full analysis on skewed data,we can get a rough estimate of the performance bysimply counting false positives and false negativesunevenly.
For instance, if the cost of mispredictinga unproblematic case as problematic is nine timesmore severe than the cost of missing a problematiccase, this can give us an estimate of the performanceof the system on a dataset with a 90-10 skew.We examined the 90-10 skew case to see if theprocedure outlined here was still viable.
Results ofan end-to-end system with this data skew are con-sistently lower than the balanced data case.
Theskewed data system can keep performance of 90%or better until it reaches 13% recall, and 85% or bet-ter until it reaches 22%.
These results suggest thatthe system could still potentially be utilized.
How-ever, its performance drops off steadily, to the pointwhere it would be unlikely to be useful at higher re-call levels.
We leave the full exploration of this tofuture work, which can utilize larger data sets to geta more accurate understanding of the performance.6 DiscussionWhen an autocorrection system attempts a correc-tion, it has perfect knowledge of the behavior of bothitself and the user.
It knows the button presses theuser used to enter the term.
It knows the term itchose as a correction.
It knows the surrounding con-text; it has access to both the messages sent and re-ceived by the user.
It has a large amount of the infor-mation it could use to improve its own performance,if only it were able to know when it made a mis-take.
The techniques described here attempt to ad-dress this critical system assessment step.
Users mayvary in the speed and accuracy at which they type,and input on small or virtual keyboards may varybetween users based on the size and shape of theirfingers.
The self-assessment task described here canpotentially facilitate the development of autocorrec-tion models that are tailored to specific user behav-iors.Here is a brief outline of how our self-assessmentmodule might potentially be used in building user-specific correction models.
As a user types input, thesystem performs autocorrection by starting with ageneral model (e.g., for all text message users).
Eachtime a correction is performed, the system exam-ines the surrounding context to determine whetherthe correction it chose was actually what the userhad intended to type.
Over the course of severaldialogues, the system builds a corpus of erroneousand non-erroneous correction attempts.
This corpusis then used to train a user-specific correction modelthat is targeted toward system mistakes that are mostfrequent with this user?s input behavior.
The user-specific model is then applied on future correctionattempts to improve overall performance.
This mon-itoring process can be continued for months or evenlonger.
The results from self-assessment will al-low the system to continuously and autonomouslyimprove itself for a given user (Baldwin and Chai,2012).In order to learn a user-specific model that is ca-pable of improving performance, it is important thatthe self-assessment system provides it with trainingdata without a large amount of noise.
This suggeststhat the self-assessment system must be able to iden-tify erroneous instances with high precision.
Con-versely, because the system can monitor user behav-717ior indefinitely to collect more data, the overall re-call may not be as critical.
It might then be reason-able for a self-assessment system to be built to focuson collecting high accuracy pairs, even if it missesmany system mistakes.
Although a full examinationof this tradeoff is left for future work which maymore closely examine user input behavior, we feelthat the results presented here show promise for col-lecting accurate data in a timely manner.7 Conclusions and Future WorkThis paper describes a novel problem of assessingits own correction performance for an autocorrectionsystem based on dialogue between two text mes-saging users.
Our evaluation results indicate thatgiven a problematic situation caused by an auto-correction system, the discourse between users pro-vides important cues for the system to automati-cally assess its own correction performance.
Byexploring a rich set of features from the discourse,our proposed approach is able to both differentiatebetween problematic and unproblematic instancesand identify the term the user intended to type withhigh precision, achieving significantly above base-line performance.
As discussed in Section 6, thisself-assessment task can potentially be important forbuilding user-specific autocorrection models to im-prove auto-correction performance.The results presented in this paper represent afirst look at autocorrection self-assessment.
Thereare several areas of future work.
There is certainlya need to examine additional feature sources.
Be-cause automatic correction mistakes can potentiallycreate semantically vacuous utterances, a computa-tional semantics based approach, similar to thoseused in semantic autocompletion systems (Hyvnenand Mkel, 2006), may prove fruitful.
Addition-ally, although this work focused solely on dialogue-related features, future work may wish to take acloser look at the autocorrection mistakes them-selves (e.g., which words are most likely to be mis-takenly corrected, etc.).
Lastly, although our currentwork demonstrated some potential, more thoroughevaluation in realistic settings will allow a more fullunderstanding of the impact and limitations of theproposed self-assessment approach.AcknowledgmentsThis work was supported in part by Award #0957039from the National Science Foundation and Award#N00014-11-1-0410 from the Office of Naval Re-search.
The authors would like to thank the review-ers for their valuable comments and suggestions.ReferencesAiTi Aw, Min Zhang, Juan Xiao, and Jian Su.
2006.
Aphrase-based statistical model for sms text normaliza-tion.
In Proceedings of the COLING/ACL on Mainconference poster sessions, pages 33?40, Morristown,NJ, USA.
Association for Computational Linguistics.Tyler Baldwin and Joyce Chai.
2012.
Towards on-line adaptation and personalization of key-target resiz-ing for mobile devices.
In Proceedings of the 2012ACM international conference on Intelligent User In-terfaces, IUI ?12, pages 11?20, New York, NY, USA.ACM.Eric Brill and Robert C. Moore.
2000.
An improvederror model for noisy channel spelling correction.
InACL ?00: Proceedings of the 38th Annual Meetingon Association for Computational Linguistics, pages286?293, Morristown, NJ, USA.
Association for Com-putational Linguistics.Surajit Chaudhuri and Raghav Kaushik.
2009.
Extend-ing autocompletion to tolerate errors.
In Proceed-ings of the 35th SIGMOD international conference onManagement of data, SIGMOD ?09, pages 707?718,New York, NY, USA.
ACM.Monojit Choudhury, Rahul Saraf, Vijit Jain, AnimeshMukherjee, Sudeshna Sarkar, and Anupam Basu.2007.
Investigation and modeling of the structureof texting language.
Int.
J. Doc.
Anal.
Recognit.,10(3):157?174.Herbert H. Clark.
1996.
Using Language.
CambridgeUniversity Press.J.J.
Darragh, I.H.
Witten, and M.L.
James.
1990.
Thereactive keyboard: a predictive typing aid.
Computer,23(11):41 ?49, November.Mark Dunlop and Andrew Crossan.
2000.
Predictive textentry methods for mobile phones.
Personal and Ubiq-uitous Computing, 4:134?143.
10.1007/BF01324120.Julia Hirschberg, Diane J. Litman, and Marc Swerts.2001.
Identifying user corrections automatically inspoken dialogue systems.
In Proceedings of the Sec-ond Meeting of the North American Chapter of the As-sociation for Computational Linguistics.Yijue How and Min yen Kan. 2005.
Optimizing pre-dictive text entry for short message service on mobile718phones.
In in Human Computer Interfaces Interna-tional (HCII 05).
2005: Las Vegas.Eero Hyvnen and Eetu Mkel.
2006.
Semantic autocom-pletion.
In Proceedings of the first Asia Semantic WebConference (ASWC 2006, pages 4?9.
Springer-Verlag.Mark D. Kernighan, Kenneth W. Church, and William A.Gale.
1990.
A spelling correction program based on anoisy channel model.
In Proceedings of the 13th con-ference on Computational linguistics, pages 205?210,Morristown, NJ, USA.
Association for ComputationalLinguistics.Catherine Kobus, Franc?ois Yvon, and Ge?raldineDamnati.
2008.
Normalizing SMS: are two metaphorsbetter than one ?
In Proceedings of the 22nd Interna-tional Conference on Computational Linguistics (Col-ing 2008), pages 441?448, Manchester, UK, August.Coling 2008 Organizing Committee.Gina-Anne Levow.
1998.
Characterizing and recogniz-ing spoken corrections in human-computer dialogue.In Proceedings of the 36th Annual Meeting of the As-sociation for Computational Linguistics and 17th In-ternational Conference on Computational Linguistics,Volume 1, pages 736?742, Montreal, Quebec, Canada,August.
Association for Computational Linguistics.Diane Litman, Julia Hirschberg, and Marc Swerts.
2006.Characterizing and predicting corrections in spokendialogue systems.
Comput.
Linguist., 32:417?438,September.I.
Scott MacKenzie and Kumiko Tanaka-Ishii.
2007.Text Entry Systems: Mobility, Accessibility, Universal-ity (Morgan Kaufmann Series in Interactive Technolo-gies).
Morgan Kaufmann Publishers Inc., San Fran-cisco, CA, USA.I.
Scott MacKenzie.
2002.
Kspc (keystrokes per charac-ter) as a characteristic of text entry techniques.
In Pro-ceedings of the 4th International Symposium on Mo-bile Human-Computer Interaction, Mobile HCI ?02,pages 195?210, London, UK.
Springer-Verlag.Tim Paek, Kenghao Chang, Itai Almog, Eric Badger,and Tirthankar Sengupta.
2010.
A practical exami-nation of multimodal feedback and guidance signalsfor mobile touchscreen keyboards.
In Proceedings ofthe 12th international conference on Human computerinteraction with mobile devices and services, Mobile-HCI ?10, pages 365?368, New York, NY, USA.
ACM.Kristina Toutanova and Robert Moore.
2002.
Pronun-ciation modeling for improved spelling correction.
In40th Annual Meeting of the Association for Computa-tional Linguistics(ACL 2002).Casey Whitelaw, Ben Hutchinson, Grace Y Chung, andGed Ellis.
2009.
Using the Web for language indepen-dent spellchecking and autocorrection.
In Proceedingsof the 2009 Conference on Empirical Methods in Nat-ural Language Processing, pages 890?899, Singapore,August.
Association for Computational Linguistics.719
