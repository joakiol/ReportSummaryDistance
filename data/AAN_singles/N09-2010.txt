Proceedings of NAACL HLT 2009: Short Papers, pages 37?40,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsIdentifying Types of Claims in Online Customer ReviewsShilpa Arora, Mahesh Joshi and Carolyn P. Rose?Language Technologies InstituteSchool of Computer ScienceCarnegie Mellon University, Pittsburgh PA 15213{shilpaa,maheshj,cprose}@cs.cmu.eduAbstractIn this paper we present a novel approach tocategorizing comments in online reviews aseither a qualified claim or a bald claim.
We ar-gue that this distinction is important based ona study of customer behavior in making pur-chasing decisions using online reviews.
Wepresent results of a supervised algorithm forlearning this distinction.
The two types ofclaims are expressed differently in languageand we show that syntactic features capturethis difference, yielding improvement over abag-of-words baseline.1 IntroductionThere has been tremendous recent interest in opin-ion mining from online product reviews and it?s ef-fect on customer purchasing behavior.
In this work,we present a novel alternative categorization of com-ments in online reviews as either being qualifiedclaims or bald claims.Comments in a review are claims that reviewersmake about the products they purchase.
A customerreads the reviews to help him/her make a purchas-ing decision.
However, comments are often opento interpretation.
For example, a simple commentlike this camera is small is open to interpretationuntil qualified by more information about whetherit is small in general (for example, based on a pollfrom a collection of people), or whether it is smallcompared to some other object.
We call such claimsbald claims.
Customers hesitate to rely on such baldclaims unless they identify (from the context or oth-erwise) themselves to be in a situation similar to thecustomer who posted the comment.
The other cate-gory of claims that are not bald are qualified claims.Qualified claims such as it is small enough to fiteasily in a coat pocket or purse are more preciseclaims as they give the reader more details, and areless open to interpretation.
Our notion of qualifiedclaims is similar to that proposed in the argumenta-tion literature by Toulmin (1958).
This distinctionof qualified vs. bald claims can be used to filterout bald claims that can?t be verified.
For the quali-fied claims, the qualifier can be used in personalizingwhat is presented to the reader.The main contributions of this work are: (i) an an-notation scheme that distinguishes qualified claimsfrom bald claims in online reviews, and (ii) a super-vised machine learning approach that uses syntacticfeatures to learn this distinction.
In the remainderof the paper, we first motivate our work based ona customer behavior study.
We then describe theproposed annotation scheme, followed by our su-pervised learning approach.
We conclude the paperwith a discussion of our results.2 Customer Behavior StudyIn order to study how online product reviews areused to make purchasing decisions, we conducteda user study.
The study involved 16 pair of gradu-ate students.
In each pair there was a customer andan observer.
The goal of the customer was to de-cide which camera he/she would purchase using acamera review blog1 to inform his/her decision.
Asthe customer read through the reviews, he/she was1http://www.retrevo.com/s/camera37asked to think aloud and the observer recorded theirobservations.The website used for this study had two types ofreviews: expert and user reviews.
There were mixedopinions about which type of reviews people wantedto read.
About six customers could relate more withuser reviews as they felt expert reviews were morelike a ?sales pitch?.
On the other hand, about fivepeople were interested in only expert reviews as theybelieved them to be more practical and well rea-soned.From this study, it was clear that the customerswere sensitive to whether a claim was qualified ornot.
About 50% of the customers were concernedabout the reliability of the comments and whetherit applied to them.
Half of them felt it was hardto comprehend whether the user criticizing a featurewas doing so out of personal bias or if it representeda real concern applicable to everyone.
The other halfliked to see comments backed up with facts or ex-planations, to judge if the claim could be qualified.Two customers expressed interest in comments fromusers similar to themselves as they felt they couldbase their decision on such comments more reli-ably.
Also, exaggerations in reviews were deemeduntrustworthy by at least three customers.3 Annotation SchemeWe now present the guidelines we used to distin-guish bald claims from qualified claims.
A claimis called qualified if its validity or scope is limitedby making the conditions of its applicability moreexplicit.
It could be either a fact or a statement thatis well-defined and attributed to some source.
Forexample, the following comments from our data arequalified claims according to our definition,1.
The camera comes with a lexar 16mb startercard, which stores about 10 images in fine modeat the highest resolution.2.
I sent my camera to nikon for servicing, tookthem a whole 6 weeks to diagnose the problem.3.
I find this to be a great feature.The first example is a fact about the camera.
Thesecond example is a report of an event.
The thirdexample is a self-attributed opinion of the reviewer.Bald claims on the other hand are non-factualclaims that are open to interpretation and thus cannotbe verified.
A straightforward example of the dis-tinction between a bald claim and a qualified claimis a comment like the new flavor of peanut butter isbeing well appreciated vs. from a survey conductedamong 20 people, 80% of the people liked the newflavor of peanut butter.
We now present some exam-ples of bald claims.
A more detailed explanation isprovided in the annotation manual2:?
Not quantifiable gradable3 words such asgood, better, best etc.
usually make a claimbald, as there is no qualified definition of beinggood or better.?
Quantifiable gradable words such as small,hot etc.
make a claim bald when used withoutany frame of reference.
For example, a com-ment this desk is small is a bald claim whereasthis desk is smaller than what I had earlier is aqualified claim, since the comparative smallercan be verified by observation or actual mea-surement, but whether something is small ingeneral is open to interpretation.?
Unattributed opinion or belief: A commentthat implicitly expresses an opinion or beliefwithout qualifying it with an explicit attribu-tion is a bald claim.
For example, Expectationis that camera automatically figures out whento use the flash.?
Exaggerations: Exaggerations such as on ev-ery visit, the food has blown us away do nothave a well defined scope and hence are notwell qualified.The two categories for gradable words defined aboveare similar to what Chen (2008) describes as vague-ness, non-objective measurability and imprecision.4 Related workInitial work by Hu and Liu (2004) on the productreview data that we have used in this paper focuseson the task of opinion mining.
They propose an ap-proach to summarize product reviews by identifyingopinionated statements about the features of a prod-uct.
In our annotation scheme however, we classify2www.cs.cmu.edu/?shilpaa/datasets/opinion-claims/qbclaims-manual-v1.0.pdf3http://en.wikipedia.org/wiki/English_grammar#Semantic_gradability38all claims in a review, not restricting to commentswith feature mentions alone.Our task is related to opinion mining, but with aspecific focus on categorizing statements as eitherbald claims that are open to interpretation and maynot apply to a wide customer base, versus qualifiedclaims that limit their scope by making some as-sumptions explicit.
Research in analyzing subjec-tivity of text by Wiebe et al (2005) involves identi-fying expression of private states that cannot be ob-jectively verified (and are therefore open to interpre-tation).
However, our task differs from subjectivityanalysis, since both bald as well as qualified claimscan involve subjective language.
Specifically, objec-tive statements are always categorized as qualifiedclaims, but subjective statements can be either baldor qualified claims.
Work by Kim and Hovy (2006)involves extracting pros and cons from customer re-views and as in the case of our task, these pros andcons can be either subjective or objective.In supervised machine learning approaches toopinion mining, the results using longer n-grams andsyntactic knowledge as features have been both pos-itive as well as negative (Gamon, 2004; Dave et al,2003).
In our work, we show that the qualified vs.bald claims distinction can benefit from using syn-tactic features.5 Data and Annotation ProcedureWe applied our annotation scheme to the product re-view dataset4 released by Hu and Liu (2004).
Weannotated the data for 3 out of 5 products.
Eachcomment in the review is evaluated as being quali-fied or bald claim.
The data has been made availablefor research purposes5.The data was completely double coded such thateach review comment received a code from the twoannotators.
For a total of 1, 252 review comments,the Cohen?s kappa (Cohen, 1960) agreement was0.465.
On a separate dataset (365 review com-ments)6, we evaluated our agreement after remov-ing the borderline cases (only about 14%) and there4http://www.cs.uic.edu/?liub/FBS/CustomerReviewData.zip5www.cs.cmu.edu/?shilpaa/datasets/opinion-claims/qbclaims-v1.0.tar.gz6These are also from the Hu and Liu (2004) dataset, but notincluded in our dataset yet.was a statistically significant improvement in kappato 0.532.
Since the agreement was low, we resolvedour conflict by consensus coding on the data that wasused for supervised learning experiments.6 Experiments and ResultsFor our supervised machine learning experiments onautomatic classification of comments as qualified orbald, we used the Support Vector Machine classifierin the MinorThird toolkit (Cohen, 2004) with the de-fault linear kernel.
We report average classificationaccuracy and average Cohen?s Kappa using 10-foldcross-validation.6.1 FeaturesWe experimented with several different features in-cluding standard lexical features such as word uni-grams and bigrams; pseudo-syntactic features suchas Part-of-Speech bigrams and syntactic featuressuch as dependency triples7.
Finally, we also usedsyntactic scope relationships computed using the de-pendency triples.
Use of features based on syntacticscope is motivated by the difference in how quali-fied and bald claims are expressed in language.
Weexpect these features to capture the presence or ab-sence of qualifiers for a stated claim.
For example,?I didn?t like this camera, but I suspect it will be agreat camera for first timers.?
is a qualified claim,whereas a comment like ?It will be a great camerafor first timers.?
is not a qualified claim.
Analysis ofthe syntactic parse of the two comments shows thatin the first comment the word ?great?
is in the scopeof ?suspect?, whereas this is not the case for the sec-ond comment.
We believe such distinctions can behelpful for our task.We compute an approximation to the syntacticscope using dependency parse relations.
Giventhe set of dependency relations of the formrelation, headWord, dependentWord, such asAMOD,camera,great, an in-scope feature is de-fined as INSCOPE headWord dependentWord (IN-SCOPE camera great).
We then compute a tran-sitive closure of such in-scope features, similar toBikel and Castelli (2008).
For each in-scope featurein the entire training fold, we also create a corre-7We use the Stanford Part-of-Speech tagger and parser re-spectively.39Features QBCLAIM HL-OPMajority .694(.000) .531(.000)Unigrams .706(.310) .683(.359)+Bigrams .709(.321) .693(.378)+POS-Bigrams .726*(.353*) .683(.361)+Dep-Triples .711(.337) .692(.376)+In-scope .706(.340) .688(.367)+Not-in-scope .726(.360*) .687(.370)+All-scope .721(.348) .699(.396)Table 1: The table shows accuracy (& Cohen?s kappa in paren-theses) averaged across ten folds.
Each feature set is individ-ually added to the baseline set of unigram features.
* - Re-sult is marginally significantly better than unigrams-only (p <0.10, using a two-sided pairwise T-test).
HL-OP - Opinion an-notations from Hu and Liu (2004).
QBCLAIM - Qualified/BaldClaim.sponding not-in-scope feature which triggers wheneither (i) the dependent word appears in a comment,but not in the transitive-closured scope of the headword, or (ii) the head word is not contained in thecomment but the dependent word is present.We evaluate the benefit of each type of featureby adding them individually to the baseline set ofunigram features.
Table 1 presents the results.
Weuse the majority classifier and unigrams-only perfor-mance as our baselines.
We also experimented withusing the same feature combinations to learn theopinion category as defined by Hu and Liu (2004)[HL-OP] on the same subset of data.It can be seen from Table 1 that using purelyunigram features, the accuracy obtained is notany better than the majority classifier for quali-fied vs. bald distinction.
However, the Part-of-Speech bigram features and the not-in-scope fea-tures achieve a marginally significant improvementover the unigrams-only baseline.For the opinion dimension from Hu and Liu(2004), there was no significant improvement fromthe type of syntactic features we experimented with.Hu and Liu (2004)?s opinion category covers severaldifferent types of opinions and hence finer linguis-tic distinctions that help in distinguishing qualifiedclaims from bald claims may not apply in that case.7 ConclusionsIn this work, we presented a novel approach to re-view mining by treating comments in reviews asclaims that are either qualified or bald.
We arguedwith examples and results from a user study as towhy this distinction is important.
We also proposedand motivated the use of syntactic scope as an ad-ditional type of syntactic feature, apart from thosealready used in opinion mining literature.
Our eval-uation demonstrates a marginally significant posi-tive effect of a feature space that includes these andother syntactic features over the purely unigram-based feature space.AcknowledgmentsWe would like to thank Dr. Eric Nyberg for thehelpful discussions and the user interface for doingthe annotations.
We would also like to thank all theanonymous reviewers for their helpful comments.ReferencesDaniel Bikel and Vittorio Castelli.
Event Matching Usingthe Transitive Closure of Dependency Relations.
Pro-ceedings of ACL-08: HLT, Short Papers, pp.
145?148.Wei Chen.
2008.
Dimensions of Subjectivity in NaturalLanguage.
In Proceedings of ACL-HLT?08.
Colum-bus Ohio.Jacob Cohen.
1960.
A Coefficient of Agreement for Nom-inal Scales.
Educational and Psychological Measure-ment, Vol.
20, No.
1., pp.
37-46.William Cohen.
2004.
Minorthird: Methods for Iden-tifying Names and Ontological Relations in Text us-ing Heuristics for Inducing Regularities from Data.http://minorthird.sourceforge.net/Kushal Dave, Steve Lawrence and David M. Pennock2006.
Mining the Peanut Gallery: Opinion Extrac-tion and Semantic Classification of Product Reviews.In Proc of WWW?03.Michael Gamon.
Sentiment classification on customerfeedback data: noisy data, large feature vectors, andthe role of linguistic analysis.
Proceedings of the In-ternational Conference on Computational Linguistics(COLING).Minqing Hu and Bing Liu.
2004.
Mining and Summariz-ing Customer Reviews.
In Proc.
of the ACM SIGKDDInternational Conference on Knowledge Discovery &Data Mining.Soo-Min Kim and Eduard Hovy.
2006.
Automatic Iden-tification of Pro and Con Reasons in Online Reviews.In Proc.
of the COLING/ACL Main Conference PosterSessions.Stephen Toulmin 1958 The Uses of Argument.
Cam-bridge University Press.Janyce Wiebe, Theresa Wilson, and Claire Cardie 2005.Annotating expressions of opinions and emotions inlanguage.
Language Resources and Evaluation, vol-ume 39, issue 2-3, pp.
165-210.40
