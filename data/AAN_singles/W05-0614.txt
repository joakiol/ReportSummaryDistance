Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL),pages 104?111, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsIntentional Context inSituated Natural Language LearningMichael Fleischman and Deb RoyCognitive MachinesThe Media LaboratoryMassachusetts Institute of Technologymbf@mit.edu, dkroy@media.mit.eduAbstractNatural language interfaces designed forsituationally embedded domains (e.g.cars, videogames) must incorporateknowledge about the users?
context toaddress the many ambiguities of situatedlanguage use.
We introduce a model ofsituated language acquisition that operatesin two phases.
First, intentional context isrepresented and inferred from user actionsusing probabilistic context free grammars.Then, utterances are mapped onto thisrepresentation in a noisy channelframework.
The acquisition model istrained on unconstrained speech collectedfrom subjects playing an interactive game,and tested on an understanding task.1 IntroductionAs information technologies move off of ourdesktops and into the world, the need for NaturalLanguage Processing (NLP) systems that exploitinformation about the environment becomesincreasingly apparent.
Whether in physicalenvironments (for cars and cell phones) or invirtual ones (for videogames and trainingsimulators), applications are beginning to demandlanguage interfaces that can understandunconstrained speech about constrained domains.Unlike most text-based NLP research, whichfocuses on open-domain problems, work we referto as situated NLP focuses on improving languageprocessing by exploiting domain-specificinformation about the non-linguistic situationalcontext of users?
interactions.
For applicationswhere agents interact in shared environments, suchinformation is critical for successfulcommunication.Previous work in situated NLP has focused onmethods for grounding the meaning of words inphysical and virtual environments.
The motivationfor this work comes from the inability of text-based NLP technologies to offer viable models ofsemantics for human computer interaction inshared environments.
For example, imagine asituation in which a human user is interacting witha robotic arm around a table of different coloredobjects.
If the human were to issue the command?give me the blue one,?
both the manually-coded(Lenat, 1995; Fellbaum, 1998) and statisticalmodels (Manning and Schutze, 2000) of meaningemployed in text-based NLP are inadequate; for, inboth models, the meaning of a word is based onlyon its relations to other words.
However, in orderfor the robot to successfully ?give me the blueone,?
it must be able to link the meaning of thewords in the utterance to its perception of theenvironment (Roy, Hsiao, & Mavridis, 2004).Thus, recent work on grounding meaning hasfocused on how words and utterances map ontophysical descriptions of the environment: either inthe form of perceptual representations (Roy, inpress, Siskind, 2001, Regier, 1996) or controlschemas (Bailey, 1997 Narayanan, 1999).1While such physical descriptions are usefulrepresentations for some classes of words (e.g.,colors, shapes, physical movements), they areinsufficient for more abstract language, such asthat which denotes intentional action.
Thisinsufficiency stems from the fact that intentionalactions (i.e.
actions performed with the purpose ofachieving a goal) are highly ambiguous whendescribed only in terms of their physicallyobservable characteristics.
For example, imagine asituation in which one person moves a cup towardsanother person and utters the unknown word1 Note that Narayanan?s work moves away from purelyphysical to metaphorical levels of description.104?blicket.?
Now, based only on the physicaldescription of this action, one might come to thinkof ?blicket?
as meaning anything from ?give cup?,to ?offer drink?, to ?ask for change.?
Thisambiguity stems from the lack of contextualinformation that strictly perceptual descriptions ofaction provide.This research presents a methodology formodeling the intentional context of utterances anddescribes how such representations can be used ina language learning task.
We decompose languagelearning into two phases: intention recognition andlinguistic mapping.
In the first phase, we modelintentional action using a probabilistic context freegrammar.
We use this model to parse sequences ofobserved physical actions, thereby inferring ahierarchical tree representation of a user?sintentions.
In the second phase, we use a noisychannel model to learn a mapping betweenutterances and nodes in that tree representation.We present pilot situated language acquisitionexperiments using a dataset of paired spontaneousspeech and action collected from human subjectsinteracting in a shared virtual environment.
Weevaluate the acquired model on a situated languageunderstanding task.2 Intention RecognitionThe ability to infer the purpose of others?
actionshas been proposed in the psychological literatureas essential for language learning in children(Tommasello, 2003, Regier, 2003).
In order tounderstand how such intention recognition mightbe modeled in a computational framework, it isuseful to specify the types of ambiguities that makeintentional actions difficult to model.
Using as anexample the situation involving the cup describedabove, we propose that this interactiondemonstrates two distinct types of ambiguity.
Thefirst type, which we refer to as a vertical ambiguitydescribes the ambiguity between the ?move cup?vs.
?offer drink?
meanings of ?blicket.?
Here theambiguity is based on the level of description thatthe speaker intended to convey.
Thus, while bothmeanings are correct (i.e., both meaningsaccurately describe the action), only onecorresponds to the word ?blicket.
?The second type of ambiguity, referred to ashorizontal ambiguity describes the ambiguitybetween the ?offer drink?
vs. ?ask for change?interpretations of ?blicket.?
Here there is anambiguity based on what actually is the intentionbehind the physical action.
Thus, it is the case thatonly one of these meaning corresponds to ?blicket?and the other meaning is not an accuratedescription of the intended action.Figure 1 shows a graphical representation ofthese ambiguities.
Here the leaf nodes represent abasic physical description of the action, while theroot nodes represent the highest-level actions forwhich the leaf actions were performed2.
Such atree representation is useful in that it shows boththe horizontal ambiguity that exists between thenodes labeled ?ask for change?
and ?offer drink,?as well as the vertical ambiguity that exits betweenthe nodes labeled ?offer drink?
and ?move cup.
?Figure 1:  Graphical representation of vertical andhorizontal ambiguities for actions.In order to exploit the intuitive value of such atree representation, we model intention recognitionusing probabilistic context free grammars(PCFG)3.
We develop a small set of productionrules in which the left hand side represents a higherorder intentional action (e.g., ?offer drink?
), andthe right hand side represents a sequence of lowerlevel actions that accomplish it (e.g.
?grasp cup?,?move cup?, ?release cup?).
Each individualaction (i.e.
letter in the alphabet of the PCFG) isfurther modeled as a simple semantic frame thatcontains roles for an agent, an object, an action,and multiple optional modifier roles (see insetfigure 1).
While in this initial work productionsare created by hand (a task made feasible by the2 In other words, high-level actions (e.g.
?be polite) arepreformed by means of the performance of lower-levelactions (e.g.
?offer drink?
).3 The idea of a ?grammar of behavior?
has a rich historyin the cognitive sciences dating back at least to Miller etal., 1960O ffe r  D r in kM o v e  C u po b s e r v e d  a c t io nA c tio n :   O f fe rA g e n t:  P e r s o n 1P a t ie n t:  P e r s o n 2O b je c t:   D r in kA s k  fo r  C h a n g eB e  P o l i teL i f t  C u p S l id e  C u p?
B lic k e t?105constrained nature of situated domains) learningsuch rules automatically is discussed in section 4.2.Just as in the plan recognition work of Pynadath,(1999), we cast the problem of intentionrecognition as a probabilistic parsing problem inwhich sequences of physical actions are used toinfer an abstract tree representation.
Resolvinghorizontal ambiguities thus becomes equivalent todetermining which parse tree is most likely given asequence of events.
Further, resolving verticalambiguities corresponds to determining whichlevel node in the inferred tree is the correct level ofdescription that the speaker had in mind.3 Linguistic MappingGiven a model of intention recognition, theproblem for a language learner becomes one ofmapping spoken utterances onto appropriateconstituents of their inferred intentionalrepresentations.
Given the intention representationabove, this is equivalent to mapping all of thewords in an utterance to the role fillers of theappropriate semantic frame in the inducedintention tree.
To model this mapping procedure,we employ a noisy channel model in which theprobability of inferring the correct meaning givenan utterance is approximated by the (channel)probability of generating that utterance given thatmeaning, times the (source) prior probability of themeaning itself (see Equation 1).?
)|( utterancemeaningp               (1))1()()|( ??
??
meaningpmeaningutterancepHere utterance refers to some linguistic unit(usually a sentence) and meaning refers to somenode in the tree (represented as a semantic frame)inferred during intention recognition4.
We can usethe probability associated with the inferred tree (asgiven by the PCFG parser) as the sourceprobability.
Further, we can learn the channelprobabilities in an unsupervised manner using avariant of the EM algorithm similar to machinetranslation (Brown et al, 1993), and statisticallanguage understanding (Epstein, 1996).4 Pilot Experiments4.1 Data Collection4 ?
refers to a weighting coefficient.In order to avoid the many physical and perceptualproblems that complicate work with robots andsensor-grounded data, this work focuses onlanguage learning in virtual environments.
Wefocus on multiplayer videogames , which supportrich types of social interactions.
The complexitiesof these environments highlight the problems ofambiguous speech described above, anddistinguish this work from projects characterizedby more simplified worlds and linguisticinteractions, such as SHRDLU (Winograd, 1972).Further, the proliferation of both commercial andmilitary applications (e.g., Rickel et al, 2002)involving such virtual worlds suggests that theywill continue to become an increasingly importantarea for natural language research in the future.Figure 2: Screen shot of Neverwinter Nights game usedin experimentation.In order to test our model, we developed a virtualenvironment based on the multi-user videogameNeverwinter Nights.5  The game, shown in Figure2, provides useful tools for generating modules inwhich players can interact.
The game wasinstrumented such that all players?
speech/textlanguage and actions are recorded during gameplay.
For data collection, a game was designed inwhich a single player must navigate their waythrough a cavernous world, collecting specificobjects, in order to escape.
Subjects were pairedsuch that one, the novice, would control the virtualcharacter, while the other, the expert, guided herthrough the world.
While the expert could sayanything in order to tell the novice where to go andwhat to do, the novice was instructed not to speak,but only to follow the commands of the expert.5 http://nwn.bioware.com/106RightClickDoor RightClickFloor RightClickFloor RightClickFloor LeftClickDoor?ok go into the room?
?go over to that door?
?now open the door?Expert?s utterances:Novice?s actions:RightClickDoor RightClickFloor RightClickFloor RightClickFloor LeftClickDoorMoveThruRoomOpenDoor OpenDoorFindAxe PickUpAxeGetAxeIntention RecognitionAction:  GetAgent:   PlayerObject:  AxeGetAxe -> GoToAxe TakeAxeFindAxe -> Open Move OpenOpenDoor -> ClickDoorBehavior GrammarAction:  OpenAgent:   PlayerObject:  DoorRightClickDoor RightClickFloor RightClickFloor RightClickFloor LeftClickDoorMoveThruRoomOpenDoor OpenDoorFindAxe PickUpAxeGetAxeLinguistic Mapping?now open the door?P(words|roles)Figure 3.
Experimental methodology: a) subjects?
speech and action sequences are recorded; b) an intentional tree isinferred over the sequence of observed actions using a PCFG parser; c) the linguistic mapping algorithm examinesthe mappings between the utterance and all possible nodes to learn the best mapping of words given semantic roles.The purpose behind these restrictions was to elicitfree and spontaneous speech that is onlyconstrained by the nature of the task.
Thisenvironment seeks to emulate the type of speechthat a real situated language system mightencounter: i.e., natural in its characteristics, butlimited in its domain of discourse.The subjects in the data collection wereuniversity graduate and undergraduate students.Subjects (8 male, 4 female) were staggered suchthat the novice in one trial became the expert in thenext.
Each pair played the game at least five times,and for each of those trials, all speech from theexpert and all actions from the novice wererecorded.
Table 1 shows examples of utterancesrecorded from game play, the observed actionsassociated with them, and the actions?
inferredsemantic frame.Utterance Action Frameok this time you aregonna get the axe firstMOVEROOM1act: GETobj: AXEthrough the red archwayon your rightMOVEROOM2act: MOVEgoal: ARCHmanner: THRUnow open that door CLICK_ONLEVERact: OPENobj: DOORok now take the axe CLICK_ONCHESTact: TAKEobj: AXEsource: CHESTTable 1: Representative test utterances collected fromsubjects with associated game actions and framesData collection produces two parallel streams ofinformation: the sequence of actions taken by thenovice and the audio stream produced by theexpert (figure 3a).
The audio streams areautomatically segmented into utterances using aspeech endpoint detector, which are thentranscribed by a human annotator.
Each action inthe sequence is then automatically parsed, and eachnode in the tree is replaced with a semantic frame(figure 3b).6  The data streams are then fed into thelinguistic mapping algorithms as a parallel corpusof the expert?s transcribed utterances and theinferred semantic roles associated with thenovice?s actions (figure 3c).4.2 AlgorithmsIntention RecognitionAs described in section 2, we represent the taskmodel associated with the game as a set ofproduction rules in which the right hand sideconsists of an intended action (e.g.
?find key?)
andthe left hand side consists of a sequence of sub-actions that are sufficient to complete that action(e.g.
?go through door, open chest, pick_up key?
).By applying probabilities to the rules, intentionrecognition can be treated as a probabilistic contextfree parsing problem, following Pynadath, 1999.For these initial experiments we have hand-annotated the training data in order to generate thegrammar used for intention recognition, estimatingtheir maximum likelihood probabilities over thetraining set.
In future work, we intend to examinehow such grammars can be learned in conjunctionwith the language itself; extending research onlearning task models (Nicolescu and Mataric,2003) and work on learning PCFGs (Klein andManning, 2004) with our own work onunsupervised language learning.Given the PCFG, we use a probabilistic Earleyparser (Stolcke, 1994), modified slightly to output6 We use 65 different frames, comprised of 35 uniquerole fillers.107partial trees (with probabilities) as each action isobserved.
Figure 4 shows a time slice of aninferred intention tree after a player mouse clickedon a lever in the game.
Note that both the verticaland horizontal ambiguities that exist for this actionin the game parallel the ambiguities shown inFigure 1.
As described above, each node in thetree is represented as a semantic frame (see figure4 insets), whose roles are aligned to the words inthe utterances during the linguistic mapping phase.Linguistic MappingThe problem of learning a mapping betweenlinguistic labels and nodes in an inferredintentional tree is recast as one of learning thechannel probabilities in Equation 1.
Each node ina tree is treated as a simple semantic frame and therole fillers in these frames, along with the words inthe utterances, are treated as a parallel corpus.This corpus is used as input to a standardExpectation Maximization algorithm that estimatesthe probabilities of generating a word given theoccurrence of a role filler.
We follow IBM Model1 (Brown et al, 1993) and assume that each wordin an utterance is generated by exactly one role inthe parallel frameUsing standard EM to learn the role to wordmapping is only sufficient if one knows to whichlevel in the tree the utterance should be mapped.However, because of the vertical ambiguityinherent in intentional actions, we do not know inadvance which is the correct utterance-to-levelmapping.
To account for this, we extend thestandard EM algorithm as follows (see figure 3c):1) set uniform likelihoods for all utterance-to-level mappings2) for each mapping, run standard EM3) merge output distributions of EM (weightingeach by its mapping likelihood)4) use merged distribution to recalculatelikelihoods of all utterance-to-level mappings5) goto step 24.3 ExperimentsMethodologies for evaluating language acquisitiontasks are not standardized.
Given our model, thereexists the possibility of employing intrinsicmeasures of success, such as word alignmentaccuracy.
However, we choose to measure thesuccess of learning by examining the related (andmore natural) task of language understanding.For each subject pair, the linguistic mappingalgorithms are trained on the first four trials ofgame play and tested on the final trial.
(This giveson average 130 utterances of training data and 30utterances of testing data per pair.)
For eachutterance in the test data, we calculate thelikelihood that it was generated by each frame seenin testing.
We select the maximum likelihoodframe as the system?s hypothesized meaning forthe test utterance, and examine both how often themaximum likelihood estimate exactly matches thetrue frame (frame accuracy), and how many of therole fillers within the estimated frame match therole fillers of the true frame (role accuracy).7Figure 4: Inferred intention tree (with semanticframes) from human subject game play.For each subject, the algorithm?s parameters areoptimized using data from all other subjects.
Weassume correct knowledge of the temporalalignment between utterances and actions.
Infuture work, we will relax this assumption toexplore the effects of not knowing which actionscorrespond to which utterances in time.To examine the performance of the model, threeexperiments are presented.
Experiment 1examines the basic performance of the algorithmson the language understanding task describedabove given uniform priors.
The system is testedunder two conditions: 1) using the extended EMalgorithm given an unknown utterance-to-levelalignment, and 2) using the standard EM algorithmgiven the correct utterance-to-level alignment.Experiment 2 tests the benefit of incorporatingintentional context directly into languageunderstanding.
This is done by using the parseprobability of each hypothesized intention as the7 See Fleischman and Roy (2005) for experimentsdetailing performance on specific word categories.F in d  K e y  E x it  L e v e lG o  T h r o u g h  D o o rO p e n  D o o rP u l l  L e v e r T u r n  K n o bc l ic k _ o n  l e v e rA c t io n :  M o v eA g e n t:  P la y e rO b je c t:  D o o rM a n n e r : T h ro u g hA c tio n :  G e tA g e n t:  P la y e rO b je c t:  K e yS o u r c e : C h e s tA c t io n :  E x itA g e n t:P la y e rO b je c t:  L e v e lA c t io n :  O p e nA g e n t:P la y e rO b je c t:  D o o r108source probability in Equation 1.
Thus, given anutterance to understand, we cycle through allpossible actions in the grammar, parse each one asif it were observed, and use the probabilitygenerated by the parser as its prior probability.
Bychanging the weighting coefficient (?)
between thesource and channel probabilities, we show therange of performances of the system from using nocontext at all (?=1) to using only context itself(?=0) in understanding.Figure 5: Comparison of models trained with utterance-to-level alignment both known and unknown.Performance is on a language understanding task(baseline equivalent to choosing most frequent frame)Experiment 3 studies to what extent inferred treestructures are necessary when modeling languageacquisition.
Although, in section 1, we havepresented intuitive reasons why such structures arerequired, one might argue that inferring trees oversequences of observed actions might not actuallyimprove understanding performance whencompared to a model trained only on the observedactions themselves.
This hypothesis is tested bycomparing a model trained given the correctutterance-to-level alignment (described inexperiment 1) with a model in which eachutterance is aligned to the leaf node (i.e.
observedaction) below the correct level of alignment.
Forexample, in figure 4, this would correspond tomapping the utterance ?go through the door?, notto ?GO THROUGH DOOR?, but rather to?CLICK_ON LEVER.
?4.4 ResultsExperiment 1: We present the average performanceover all subject pairs, trained with the correctutterance-to-level alignment both known andunknown, and compare it to a baseline of choosingthe most frequent frame from the training data.Figure 5 shows the percentage of maximumlikelihood frames chosen by the system thatexactly match the intended frame (frameaccuracy), as well as, the percentage of roles fromthe maximum likelihood frame that overlap withroles in the intended frame (role accuracy).As expected, the understanding performancegoes down for both frames and roles when thecorrect utterance-to-level alignment is unknown.Interestingly, while the frame performancedeclines by 14.3%, the performance on roles onlydeclines 6.4%.
This difference is due primarily tothe fact that, while the mapping from words toaction role fillers is hindered by the need toexamine all alignments, the mapping from wordsto object role fillers remains relatively robust.
Thisis due to the fact that while each level of intentioncarries a different action term, often the objectsdescribed at different levels remain the same.
Forexample, in figure 4, the action fillers ?TAKE?,?MOVE?, ?OPEN?, and ?PULL?
occur only oncealong the path.
However, the object filler?DOOR?
occurs multiple times.
Thus, the chancethat the role filler ?DOOR?
correctly maps to theword ?door?
is relatively high compared to the rolefiller ?OPEN?
mapping to the word ?open.
?8Figure 6: Frame accuracy as a function of ?
value (Eq.1) trained on unknown utterance-to-level alignments.Experiment 2: Figure 6 shows the average frameaccuracy of the system trained without knowingthe correct utterance-to-level alignment, as afunction of varying the ?
values from Equation 1.The graph shows that including intentional contextdoes improve system performance when it is notgiven too much weight (i.e., at relatively highalpha values).
This suggests that the benefit ofintentional context is somewhat outweighed by thepower of the learned role to word mappings.8 This asymmetry for learning words about actions vs.objects is well known in psychology (Gleitman, 1990)and is addressed directly in Fleischman and Roy, 2005.2 5 %2 7 %2 9 %3 1 %3 3 %3 5 %3 7 %3 9 %4 1 %4 3 %4 5 %4 7 %4 9 %0 .
2 0 .
4 0 .
6 0 .
8 1?FrameAccuracy0 %1 0 %2 0 %3 0 %4 0 %5 0 %6 0 %7 0 %8 0 %9 0 %f r a m e  a c c u r a c y r o le  a c c u r a c yb a s e l in e u n k n o w n  le v e l k n o w n  le v e l109Looking closer, we find a strong negativecorrelation (r=-0.81) between the understandingperformance using only channel probabilities (?=1)and the improvement obtained by including theintentional context.
In other words, the better onedoes without context, the less context improvesperformance.
Thus, we expect that in noisierenvironments (such as when speech recognition isemployed) where channel probabilities are lessreliable, employing intentional context will beeven more advantageous.Experiment 3: Figure 7 shows the averageperformance on both frame and role accuracy forsystems trained without using the inferred treestructure (on leaf nodes only) and on the full treestructure (given the correct utterance-to-levelalignment).
Baselines are calculated by choosingthe most frequent frame from training.90%10%20%30%40%50%60%70%80%90%frame accuracy role accuracybaseline (observed) observed baseline (inferred) inferredFigure 7: Comparison of models trained on inferredintentional tree vs. directly on observed actionsIt is clear from the figure that understandingperformance is higher when the intentional tree isused in training.
This is a direct result of the factthat speakers often speak about high-levelintentions with words that do not directly refer tothe observed actions.
For example, after opening adoor, experts often say: ?go through the door,?
forwhich the observed action is a simple movement(e.g., ?MOVE ROOMx?).
Also, by referring tohigh-level intentions, experts can describesequences of actions that are not immediatelyreferred to.
For example, an expert might say: ?getthe key?
to describe a sequence of actions thatbegins with ?CLICK_ON CHEST.?
Thus, theresult of not learning over a parsed hierarchical9 Note that baselines are different for the two conditions,because there are a differing number of frames used inthe leaf node only condition.representation of intentions is increased noise, andsubsequently, poorer understanding performance.5 DiscussionThe results from these experiments, althoughpreliminary, indicate that this model of languageacquisition performs well above baseline on alanguage understanding task.
This is particularlyencouraging given the unconstrained nature of thespeech on which it was trained.
Thus, even freeand spontaneous speech can be handled whenmodeling a constrained domain of discourse.10In addition to performing well given difficultdata, the experiments demonstrate the advantagesof using an inferred intentional representation bothas a contextual aid to understanding and as arepresentational scaffolding for language learning.More important than these preliminary results,however, is the general lesson that this worksuggests about the importance of knowledgerepresentations for situated language acquisition.As discussed in section 2, learning languageabout intentional action requires dealing with twodistinct types of ambiguity.
These difficultiescannot be handled by merely increasing theamount of data used, or switching to a moresophisticated learning algorithm.
Rather, dealingwith language use for situated applications requiresbuilding appropriate knowledge representationsthat are powerful enough for unconstrainedlanguage, yet scalable enough for practicalapplications.
The work presented here is an initialdemonstration of how the semantics ofunconstrained speech can be modeled by focusingon constrained domains.As for scalability, it is our contention that forsituated NLP, it is not a question of being able toscale up a single model to handle open-domainspeech.
The complexity of situated communicationrequires the use of domain-specific knowledge formodeling language use in different contexts.
Thus,with situated NLP systems, it is less productive tofocus on how to scale up single models to operatebeyond their original domains.
Rather, as moreindividual applications are tackled (e.g.
cars,10 Notably, situated applications for which naturallanguage interfaces are required typically have limiteddomains (e.g., talking to one?s car doesn?t require open-domain language processing).110phones, videogames, etc.)
the interesting questionbecomes one of how agents can learn to switchbetween different models of language as theyinteract in different domains of discourse.6 ConclusionWe have introduced a model of languageacquisition that explicitly incorporates intentionalcontexts in both learning and understanding.
Wehave described pilot experiments on pairedlanguage and action data in order to demonstrateboth the model?s feasibility as well as the efficacyof using intentional context in understanding.Although we have demonstrated a first step towardan advanced model of language acquisition, thereis a great deal that has not been addressed.
First,what is perhaps most obviously missing is anymention of syntax in the language learning processand its role in bootstrapping for languageacquisition.
Future work will focus on movingbeyond the IBM Model 1 assumptions, to developmore syntactically-structured models.Further, although the virtual environment used inthis research bears similarity to situatedapplications that demand NL interfaces, it is notknown exactly how well the model will perform?in the real world.?
Future work will examineinstalling models in real world applications.
Inparallel investigations, we will explore our methodas a cognitive model of human language learning.Finally, as was mentioned previously, the taskmodel for this domain was hand annotated and,while the constrained nature of the domainsimplified this process, further work is required tolearn such models jointly with language.In summary, we have presented first stepstoward tackling problems of ambiguity inherent ingrounding the semantics of situated language.
Webelieve this work will lead to practical applicationsfor situated NLP, and provide new tools formodeling human cognitive structures andprocesses underlying situated language use(Fleischman and Roy, 2005).AcknowledgmentsPeter Gorniak developed the software to capturedata from the videogame used in our experiments.ReferencesD.
Bailey, J Feldman, S.
Narayanan., & G.
Lakoff..Embodied lexical development.
19th CognitiveScience Society Meeting.
Mahwah, NJ, 1997.P.
F. Brown, V. J. Della Pietra, S. A. Della Pietra &R. L. Mercer.
?The Mathematics of Sta-tisticalMachine Translation: Parameter Estimation,?Computational Linguistics 19(2).
1993.M Epstein  Statistical Source Channel Models forNatural Language Understanding Ph.
D. thesis,New York University, September, 1996C.
Fellbaum WordNet: An On-line Lexical Databaseand Some of its Applications.
MIT Press, 1998.M.
Fleischman and D.K.
Roy.
Why Verbs areHarder to Learn than Nouns: Initial Insights from aComputational Model of Intention Recognition inSituated Word Learning.
CogSci.
Italy, 2005.L.
Gleitman.
"The structural sources of verbmeanings."
Language Acquisition, 1(1), 1990.D.
Klein and C. Manning, "Corpus-Based Inductionof Syntactic Structure: Models of Dependency andConstituency", Proc.
of the 42nd ACL, 2004 [D. B Lenat,.
CYC: A Large-Scale Investment inKnowledge Infrastructure".
Comm.
of ACM, 1995.C.
Manning, H. Schutze,.
Foundations of StatisticalNatural Language Processing.
MIT Press, 2001.G.
A. Miller, E. Galanter, and K. Pribram 1960.
Plansand the Structure of Behavior.
New York: Halt.S.
Narayanan.. Moving right along: A computationalmodel of metaphoric reasoning about events.
InProc.
of AAAI.
Orlando, FL, 1999.M.
Nicolescu, M.
Mataric?, Natural Methods forRobot Task Learning: Instructive Demonstration,Generalization and Practice, AGENTS, Australia, 2003.D.
Pynadath, 1999.
Probabilistic Grammars for PlanRecognition.
Ph.D. Thesis, University of Michigan.T.
Regier.
The human semantic potential.
MIT Press,Cambridge, MA, 1996.T.
Regier.
Emergent constraints on word-learning: Acomputational review.
TICS, 7, 263-268, 2003.J.
Rickel, S. Marsella, J. Gratch, R. Hill, D. Traumand W. Swartout, "Towards a New Generation ofVirtual Humans for Interactive Experiences," inIEEE Intelligent Systems July/August 2002.D.Roy, K. Hsiao, and N. Mavridis.
Mental imageryfor a conversational robot.
IEEE Trans.
onSystems, Man, and Cybernetics, 34(3) 2004.D.
Roy.
(in press).
Grounding Language in theWorld: Schema Theory Meets Semiotics.
AI.J.
Siskind.
Grounding the Lexical Semantics ofVerbs in Visual Perception using Force Dynamicsand Event Logic.
JAIR, 2001.A.
Stolcke.
Bayesian Learning of ProbabilisticLanguage Models.
Ph.d., UC Berkeley, 1994.M.
Tomasello.
Constructing a Language: A Usage-Based Theory of Language Acquisition.
HarvardUniversity Press, 2003.T.
Winograd.
Understanding Natural Language.Academic Press, 1972.111
