Collocation Translation Acquisition Using Monolingual CorporaYajuan L?Microsoft Research Asia5F Sigma Center,No.
49 Zhichun Road, Haidian District,Beijing, China, 100080t-yjlv@microsoft.comMing ZHOUMicrosoft Research Asia5F Sigma Center,No.
49 Zhichun Road, Haidian District,Beijing, China, 100080mingzhou@microsoft.comAbstractCollocation translation is important formachine translation and many other NLP tasks.Unlike previous methods using bilingualparallel corpora, this paper presents a newmethod for acquiring collocation translationsby making use of monolingual corpora andlinguistic knowledge.
First, dependency triplesare extracted from Chinese and Englishcorpora with dependency parsers.
Then, adependency triple translation model isestimated using the EM algorithm based on adependency correspondence assumption.
Thegenerated triple translation model is used toextract collocation translations from twomonolingual corpora.
Experiments show thatour approach outperforms the existingmonolingual corpus based methods independency triple translation and achievespromising results in collocation translationextraction.1 IntroductionA collocation is an arbitrary and recurrent wordcombination (Benson, 1990).
Previous work incollocation acquisition varies in the kinds ofcollocations they detect.
These range from two-word to multi-word, with or without syntacticstructure (Smadja 1993; Lin, 1998; Pearce, 2001;Seretan et al 2003).
In this paper, a collocationrefers to a recurrent word pair linked with a certainsyntactic relation.
For instance, <solve, verb-object,problem> is a collocation with a syntactic relationverb-object.Translation of collocations is difficult for non-native speakers.
Many collocation translations areidiosyncratic in the sense that they areunpredictable by syntactic or semantic features.Consider Chinese to English translation.
Thetranslations of ????
can be ?solve?
or ?resolve?.The translations of ????
can be ?problem?
or?issue?.
However, translations of the collocation???
~ ???
as ?solve~problem?
or ?resolve~issue?
is preferred over ?solve~issue?
or ?resolve~problem?.
Automatically acquiring thesecollocation translations will be very useful formachine translation, cross language informationretrieval, second language learning and many otherNLP applications.
(Smadja et al, 1996; Gao et al,2002; Wu and Zhou, 2003).Some studies have been done for acquiringcollocation translations using parallel corpora(Smadja et al 1996; Kupiec, 1993; Echizen-ya etal., 2003).
These works implicitly assume that abilingual corpus on a large scale can be obtainedeasily.
However, despite efforts in compilingparallel corpora, sufficient amounts of suchcorpora are still unavailable.
Instead of heavilyrelying on bilingual corpora, this paper aims tosolve the bottleneck in a different way: to minebilingual knowledge from structured monolingualcorpora, which can be more easily obtained in alarge volume.Our method is based on the observation thatdespite the great differences between Chinese andEnglish, the main dependency relations tend tohave a strong direct correspondence (Zhou et al,2001).
Based on this assumption, a new translationmodel based on dependency triples is proposed.The translation probabilities are estimated fromtwo monolingual corpora using the EM algorithmwith the help of a bilingual translation dictionary.Experimental results show that the proposed tripletranslation model outperforms the other threemodels in comparison.
The obtained tripletranslation model is also used for collocationtranslation extraction.
Evaluation resultsdemonstrate the effectiveness of our method.The remainder of this paper is organized asfollows.
Section 2 provides a brief description onthe related work.
Section 3 describes our tripletranslation model and training algorithm.
Section 4extracts collocation translations from twoindependent monolingual corpora.
Section 5evaluates the proposed method, and the last sectiondraws conclusions and presents the future work.2 Related workThere has been much previous work done onmonolingual collocation extraction.
They can ingeneral be classified into two types: window-basedand syntax-based methods.
The former extractscollocations within a fixed window (Church andHanks 1990; Smadja, 1993).
The latter extractscollocations which have a syntactic relationship(Lin, 1998; Seretan et al, 2003).
The syntax-basedmethod becomes more favorable with recentsignificant increases in parsing efficiency andaccuracy.
Several metrics have been adopted tomeasure the association strength in collocationextraction.
Thanopoulos et al (2002) givecomparative evaluations on these metrics.Most previous research in translation knowledgeacquisition is based on parallel corpora (Brown etal., 1993).
As for collocation translation, Smadja etal.
(1996) implement a system to extractcollocation translations from a parallel English-French corpus.
English collocations are firstextracted using the Xtract system, thencorresponding French translations are sought basedon the Dice coefficient.
Echizen-ya et al (2003)propose a method to extract bilingual collocationsusing recursive chain-link-type learning.
Inaddition to collocation translation, there is alsosome related work in acquiring phrase or termtranslations from parallel corpus (Kupiec, 1993;Yamamoto and Matsumoto 2000).Since large aligned bilingual corpora are hard toobtain, some research has been conducted toexploit translation knowledge from non-parallelcorpora.
Their work is mainly on word level.Koehn and Knight (2000) presents an approach toestimating word translation probabilities usingunrelated monolingual corpora with the EMalgorithm.
The method exhibits promising resultsin selecting the right translation among severaloptions provided by bilingual dictionary.
Zhou etal.
(2001) proposes a method to simulate translationprobability with a cross language similarity score,which is estimated from monolingual corporabased on mutual information.
The method achievesgood results in word translation selection.
Inaddition, (Dagan and Itai, 1994) and (Li, 2002)propose using two monolingual corpora for wordsense disambiguation.
(Fung, 1998) uses an IRapproach to induce new word translations fromcomparable corpora.
(Rapp, 1999) and (Koehn andKnight, 2002) extract new word translations fromnon-parallel corpus.
(Cao and Li, 2002) acquirenoun phrase translations by making use of webdata.
(Wu and Zhou, 2003) also make full use oflarge scale monolingual corpora and limitedbilingual corpora for synonymous collocationextraction.3 Training a triple translation model frommonolingual corporaIn this section, we first describe the dependencycorrespondence assumption underlying ourapproach.
Then a dependency triple translationmodel and the monolingual corpus based trainingalgorithm are proposed.
The obtained tripletranslation model will be used for collocationtranslation extraction in next section.3.1 Dependency correspondence betweenChinese and EnglishA dependency triple consists of a head, adependant, and a dependency relation.
Using adependency parser, a sentence can be analyzed intodependency triples.
We represent a triple as(w1,r,w2), where w1 and w2 are words and r is thedependency relation.
It means that w2 has adependency relation r with w1.
For example, atriple (overcome, verb-object, difficulty) means that?difficulty?
is the object of the verb ?overcome?.Among all the dependency relations, we onlyconsider the following three key types that wethink, are the most important in text analysis andmachine translation: verb-object (VO), noun-adj(AN), and verb- adv(AV).It is our observation that there is a strongcorrespondence in major dependency relations inthe translation between English and Chinese.
Forexample, an object-verb relation in Chinese(e.g.(?
?, VO, ??))
is usually translated intothe same verb-object relation in English(e.g.
(overcome, VO, difficulty)).This assumption has been experimentallyjustified based on a large and balanced bilingualcorpus in our previous work (Zhou et al, 2001).We come to the conclusion that more than 80% ofthe above dependency relations have a one-onemapping between Chinese and English.
We canconclude that there is indeed a very strongcorrespondence between Chinese and English inthe three considered dependency relations.
Thisfact will be used to estimate triple translationmodel using two monolingual corpora.3.2 Triple translation modelAccording to Bayes?s theorem, given a Chinesetriple ),,( 21 crcc ctri = , and the set of its candidateEnglish triple translations ),,( 21 eree etri = , thebest English triple )?,,?(?
21 eree etri = is the one thatmaximizes the Equation (1):)|()(maxarg)(/)|()(maxarg)|(maxarg?tritritrietritritritrietritrietriecpepcpecpepcepetritritri===(1)where )( triep is usually called the language modeland )|( tritri ecp is usually called the translationmodel.Language ModelThe language model )( triep  is calculated withEnglish triples database.
In order to tackle with thedata sparseness problem, we smooth the languagemodel with an interpolation method, as describedbelow.When the given English triple occurs in thecorpus, we can calculate it as in Equation (2).Nerefreqep etri),,()( 21=                   (2)where ),,( 21 erefreq e  represents the frequency  oftriple trie .
N represents the total counts of all theEnglish triples in the training corpus.For an English triple ),,( 21 eree etri = , if weassume that two words 1e and 2e are conditionallyindependent given the relation er , Equation (2) canbe rewritten as in (3)(Lin, 1998).
)|()|()()( 21 eeetri repreprpep =        (3)whereNrfreqrp ee,*)(*,)( = ,,*)(*,,*),()|( 11eee rfreqrefreqrep = ,,*)(*,),(*,)|( 222eerfreqerfreqrep = .The wildcard symbol * means it can be any wordor relation.
With Equations (2) and (3), we get theinterpolated language model as shown in (4).
)|()|()()1()()( 21 eeetritri repreprpNefreqep ??
?+=  (4)where 10 << ?
.
?
is calculated as below:)(111triefreq+?=?
(5)Translation ModelWe simplify the translation model according thefollowing two assumptions.Assumption 1: Given an English triple trie , andthe corresponding Chinese dependency relation cr ,1c and 2c are conditionally independent.
We have:)|(),|(),|()|,,()|(2121trictrictrictrictritrierpercpercpecrcpecp==    (6)Assumption 2: For an English triple trie ,assume that ic  only depends on {1,2})  (i ?ie ,and cr  only depends on er  .
Equation (6) isrewritten as:)|()|()|()|(),|(),|()|(221121ectrietrictrictritrirrpecpecperpercpercpecp==       (7)Notice that )|( 11 ecp and )|( 22 ecp  aretranslation probabilities within triples, they aredifferent from the unrestricted probabilities such asthe ones in IBM models (Brown et al, 1993).
Wedistinguish translation probability between head( )|( 11 ecp ) and dependant ( )|( 22 ecp ).
In therest of the paper, we use )|( ecphead and)|( ecpdep to denote the head translationprobability and dependant translation probabilityrespectively.As the correspondence between the samedependency relation across English and Chinese isstrong, we simply assume 1)|( =ec rrp for thecorresponding er  and cr , and 0)|( =ec rrp for theother cases.
)|( 11 ecphead   and )|( 22 ecpdep cannot beestimated directly because there is no triple-alignedcorpus available.
Here, we present an approach toestimating these probabilities from twomonolingual corpora based on the EM algorithm.3.3 Estimation of word translationprobability using the EM algorithmChinese and English corpora are first parsedusing a dependency parser, and two dependencytriple databases are generated.
The candidateEnglish translation set of Chinese triples isgenerated through a bilingual dictionary and theassumption of strong correspondence ofdependency relations.
There is a risk that unrelatedtriples in Chinese and English can be connectedwith this method.
However, as the conditions thatare used to make the connection are quite strong(i.e.
possible word translations in the same triplestructure), we believe that this risk, is not verysevere.
Then, the expectation maximization (EM)algorithm is introduced to iteratively strengthen thecorrect connections and weaken the incorrectconnections.EM AlgorithmAccording to section 3.2, the translationprobabilities from a Chinese triple tric  to anEnglish triple trie can be computed using theEnglish triple language model )( triep and atranslation model from English to Chinese)|( tritri ecp .
The English language model can beestimated using Equation (4) and the translationmodel can be calculated using Equation (7).
Thetranslation probabilities )|( ecphead and)|( ecpdep are initially set to a uniform distributionas follows:?????
??
?==otherwisecifecpecp eedephead,0)(    ,1)|()|(      (8)Where e?
represents the translation set of theEnglish word e.Then, the word translation probabilities areestimated iteratively using the EM algorithm.Figure 1 gives a formal description of the EMalgorithm.Figure 1:  EM algorithmThe basic idea is that under the restriction of theEnglish triple language model )( triep  andtranslation dictionary, we wish to estimate thetranslation probabilities )|( ecphead  and)|( ecpdep that best explain the Chinese tripledatabase as a translation from the English tripledatabase.
In each iteration, the normalized tripletranslation probabilities are used to update theword translation probabilities.
Intuitively, afterfinding the most probable translation of theChinese triple, we can collect counts for the wordtranslation it contains.
Since the English triplelanguage model provides context information forthe disambiguation of the Chinese words, only theappropriate occurrences are counted.Now, with the language model estimated usingEquation (4) and the translation probabilitiesestimated using EM algorithm, we can compute thebest triple translation for a given Chinese tripleusing Equations (1) and (7).4 Collocation translation extraction from twomonolingual corporaThis section describes how to extract collocationtranslation from independent monolingual corpora.First, collocations are extracted from amonolingual triples database.
Then, collocationtranslations are acquired using the triple translationmodel obtained in section 3.4.1 Monolingual collocation extractionAs introduced in section 2, much work has beendone to extract collocations.
Among all themeasure metrics, log likelihood ratio (LLR) hasproved to give better results (Duning, 1993;Thanopoulos et al, 2002).
In this paper, we takeLLR as the metric to extract collocations from adependency triple database.For a given Chinese triple ),,( 21 crcc ctri = , theLLR score is calculated as follows:NNdcdcdbdbcacababaddccbbaaLogllog)log()()log()()log()()log()(loglogloglog+++?++?++?++?+++=(9)where,.),,,(),(*,),,,(,*),(),,,(21221121cbaNdcrcfreqcrfreqccrcfreqrcfreqbcrcfreqaccccc??
?=?=?==N is the total counts of all Chinese triples.Those triples whose LLR values are larger than agiven threshold are taken as a collocation.
Thissyntax-based collocation has the advantage that itcan represent both adjacent and long distance wordassociation.
Here, we only extract the three maintypes of collocation that have been mentioned insection 3.1.4.2 Collocation translation extractionFor the acquired collocations, we try to extracttheir translations from the other monolingualTrain language model for English triple )( triep ;Initialize word translation probabilities )|( ecpheadand )|( ecpdep uniformly as in Equation (8);IterateSet )|( ecscorehead and )|( ecscoredep to 0 for alldictionary entries (c,e);for all Chinese triples ),,( 21 crcc ctri =for all candidate English triple translations),,( 21 eree etri =compute triple translation probability)|( tritri cep by)|()|()|()( 2211 ecdepheadtri rrpecpecpepend fornormalize )|( tritri cep , so that their sum is 1;for all triple translation ),,( 21 eree etri =add )|( tritri cep to )|( 11 ecscoreheadadd )|( tritri cep to )|( 22 ecscoredependforendforfor all translation pairs (c,e)set )|( ecphead  to normalized )|( ecscorehead ;set )|( ecpdep  to normalized )|( ecscoredep ;endforenditeratecorpus using the triple translation model trainedwith the method proposed in section 3.Our objective is to acquire collocationtranslations as translation knowledge for a machinetranslation system, so only highly reliablecollocation translations are extracted.
Figure 2describes the algorithm for Chinese-Englishcollocation translation extraction.
It can be seenthat the best English triple candidate is extracted asthe translation of the given Chinese collocationonly if the Chinese collocation is also the besttranslation candidate of the English triple.
But theEnglish triple is not necessarily a collocation.English collocation translations can be extracted ina similar way.Figure 2: Collocation translation extraction4.3 Implementation of our approachOur English corpus is from Wall Street Journal(1987-1992) and Associated Press (1988-1990),and the Chinese corpus is from People?s Daily(1980-1998).
The two corpora are parsed using theNLPWin parser1 (Heidorn, 2000).
The statistics forthree main types of dependency triples are shownin tables 1 and 2.
Token refers to the total numberof triple occurrences and Type refers to the numberof unique triples in the corpus.
Statistic for theextracted Chinese collocations and the collocationtranslations is shown in Table 3.Class #Type #TokenVO 1,579,783 19,168,229AN 311,560 5,383,200AV 546,054 9,467,103Table 1:  Chinese dependency triples1  The NLPWin parser is a rule-based parserdeveloped at Microsoft research, which parses severallanguages including Chinese and English.
Its output canbe a phrase structure parse tree or a logical form whichis represented with dependency triples.Class #Type #TokenVO 1,526,747 8,943,903AN 1,163,440 6,386,097AV 215,110 1,034,410Table 2:  English dependency triplesClass #Type #TranslatedVO 99,609 28,841AN 35,951 12,615AV 46,515 6,176Table 3:  Extracted Chinese collocationsand E-C translation pairsThe translation dictionaries we used in trainingand translation are combined from two dictionaries:HITDic and NLPWinDic 2 .
The final E-Cdictionary contains 126,135 entries, and C-Edictionary contains 91,275 entries.5 Experiments and evaluationTo evaluate the effectiveness of our methods,two experiments have been conducted.
The firstone compares our method with three othermonolingual corpus based methods in tripletranslation.
The second one evaluates the accuracyof the acquired collocation translation.5.1 Dependency triple translationTriple translation experiments are conductedfrom Chinese to English.
We randomly selected2000 Chinese triples (whose frequency is largerthan 2) from the dependency triple database.
Thestandard translation answer sets were builtmanually by three linguistic experts.
For eachChinese triple, its English translation set containEnglish triples provided by anyone of the threelinguists.
Among 2000 candidate triples, there are101 triples that can?t be translated into Englishtriples with same relation.
For example, theChinese triple (?, VO, ??)
should be translatedinto ?bargain?.
The two words in triple cannot betranslated separately.
We call this kind ofcollocation translation no-compositionaltranslations.
Our current model cannot deal withthis kind of translation.
In addition, there are also157 error dependency triples, which result fromparsing mistakes.
We filtered out these two kindsof triples and got a standard test set with 1,742Chinese triples and 4,645 translations in total.We compare our triple translation model withthree other models on the same standard test setwith the same translation dictionary.
As the2 These two dictionaries are built by Harbin Instituteof Technology and Microsoft Research respectively.For each Chinese collocation colc :a.
Acquire the best English triple translationtrie?
using C-E triple translation model:)|()(maxarg?
tritritrietri ecpepetri=b.
For the acquired trie?
, calculate  the bestChinese triple translation tric?
using E-Ctriple translation model:)|?()(maxarg?
tritritrictri cepcpctri=c.
If colc = tric?
, add colc ?
trie?
to collocationtranslation database.baseline experiment, Model A selects the highest-frequency translation for each word in triple;Model B selects translation with the maximaltarget triple probability, as proposed in (Dagan1994); Model C selects translation using bothlanguage model and translation model, but thetranslation probability is simulated by a similarityscore which is estimated from monolingual corpususing mutual information measure (Zhou et al,2001).
And our triple translation model is model D.Suppose ),,( 21 crcc ctri = is the Chinese triple tobe translated.
The four compared models can beformally expressed as follows:Model A:))((maxarg,)),((maxarg( 2)(1)(max2211efreqrefreqecTranseecTranse ?
?=Model B:),,(maxarg)(maxarg 21)()(max2211erepepe ecTransecTransetrietri?
?==Model C:)),Sim(),Sim()((maxarg))|(likelyhood)((maxarg2211)()(max2211ceceepecepetricTransecTransetritritrietri??=?=?
?where, ),Sim( ce is similarity score between eand c (Zhou et al, 2001).Model D (our model):))|()|()|()((maxarg))|()((maxarg2211)()(max2211ecdepheadtricTransecTransetritritrierrpecpecpepecpepetri?
?==Accuracy(%)  Cove- Rage(%) Top 1 Top 3Oracle(%)Model A 17.21 ----Model B 33.56 53.79Model C 35.88 57.74Model D83.9836.91 58.5866.30Table 4:  Translation results comparisonThe evaluation results on the standard test set areshown in Table 4, where coverage is thepercentages of triples which can be translated.Some triples can?t be translated by Model B, C andD because of the lack of dictionary translations ordata sparseness in triples.
In fact, the coverage ofModel A is 100%.
It was set to the same as othersin order to compare accuracy using the same testset.
The oracle score is the upper bound accuracyunder the conditions of current translationdictionary and standard test set.
Top N accuracy isdefined as the percentage of triples whose selectedtop N translations include correct translations.We can see that both Model C and Model Dachieve better results than Model B.
This showsthat the translation model trained frommonolingual corpora really helps to improve theperformance of translation.
Our model alsooutperforms Model C, which demonstrates theprobabilities trained by our EM algorithm achievebetter performance than heuristic similarity scores.In fact, our evaluation method is very rigorous.To avoid bias in evaluation, we take humantranslation results as standard.
The real translationaccuracy is reasonably better than the evaluationresults.
But as we can see, compared to the oraclescore, the current models still have much room forimprovement.
And coverage is also not high due tothe limitations of the translation dictionary and thesparse data problem.5.2 Collocation translation extraction47,632 Chinese collocation translations areextracted with the method proposed in section 4.We randomly selected 1000 translations forevaluation.
Three linguistic experts tag theacceptability of the translation.
Those translationsthat are tagged as acceptable by at least twoexperts are evaluated as correct.
The evaluationresults are shown in Table 5.Total Acceptance Accuracy (%)VO 590 373 63.22AN 292 199 68.15AV 118 60 50.85All 1000 632 63.20ColTrans 334 241 72.16Table 5:  Extracted collocation translation resultsWe can see that the extracted collocationtranslations achieve a much better result than tripletranslation.
The average accuracy is 63.20% andthe collocations with relation AN achieve thehighest accuracy of 68.15%.
If we only considerthose Chinese collocations whose translations arealso English collocations, we obtain an even betteraccuracy of 72.16% as shown in the last row ofTable 5.
The results justify our idea that we canacquire reliable translation for collocation bymaking use of triple translation model in twodirections.These acquired collocation translations are veryvaluable for translation knowledge building.Manually crafting collocation translations can betime-consuming and cannot ensure high quality ina consistent way.
Our work will certainly improvethe quality and efficiency of collocation translationacquisition.5.3 DiscussionAlthough our approach achieves promisingresults, it still has some limitations to be remediedin future work.
(1) Translation dictionary extensionDue to the limited coverage of the dictionary, acorrect translation may not be stored in thedictionary.
This naturally limits the coverage oftriple translations.
Some research has been done toexpand translation dictionary using a non-parallelcorpus (Rapp, 1999; Keohn and Knight, 2002).
Itcan be used to improve our work.
(2) Noise filtering of parsersSince we use parsers to generate dependencytriple databases, this inevitably introduces someparsing mistakes.
From our triple translation testdata, we can see that 7.85% (157/2000) types oftriples are error triples.
These errors will certainlyinfluence the translation probability estimation inthe training process.
We need to find an effectiveway to filter out mistakes and perform necessaryautomatic correction.
(3) Non-compositional collocation translation.Our model is based on the dependencycorrespondence assumption, which assumes that atriple?s translation is also a triple.
But there are stillsome collocations that can?t be translated word byword.
For example, the Chinese triple (?
?, VO,??)
usually be translated into ?be effective?
; theEnglish triple (take, VO, place) usually betranslated into ????.
The two words in triplecannot be translated separately.
Our current modelcannot deal with this kind of non-compositionalcollocation translation.
Melamed (1997) and Lin(1999) have done some research on non-compositional phrases discovery.
We will considertaking their work as a complement to our model.6 Conclusion and future workThis paper proposes a novel method to train atriple translation model and extract collocationtranslations from two independent monolingualcorpora.
Evaluation results show that itoutperforms the existing monolingual corpus basedmethods in triple translation, mainly due to theemployment of EM algorithm in cross languagetranslation probability estimation.
By making useof the acquired triple translation model in twodirections, promising results are achieved incollocation translation extraction.Our work also demonstrates the possibility ofmaking full use of monolingual resources, such ascorpora and parsers for bilingual tasks.
This canhelp overcome the bottleneck of the lack of alarge-scale bilingual corpus.
This approach is alsoapplicable to comparable corpora, which are alsoeasier to access than bilingual corpora.In future work, we are interested in extendingour method to solving the problem of non-compositional collocation translation.
We are alsointerested in incorporating our triple translationmodel for sentence level translation.7 AcknowledgementsThe authors would like to thank John Chen,Jianfeng Gao and Yunbo Cao for their valuablesuggestions and comments on a preliminary draftof this paper.ReferencesMorton Benson.
1990.
Collocations and general-purpose dictionaries.
International Journal ofLexicography.
3(1):23?35Yunbo Cao, Hang Li.
2002.
Base noun phrasetranslation using Web data and the EM algorithm.The 19th International Conference onComputational Linguistics.
pp.127-133Kenneth W. Church and Patrick Hanks.
1990.Word association norms, mutural information,and lexicography.
Computational Linguistics,16(1):22-29Ido Dagan  and Alon Itai.
1994.
Word sensedisambiguation using a second languagemonolingual corpus.
Computational Linguistics,20(4):563-596Ted Dunning.
1993.
Accurate methods for thestatistics of surprise and coincidence.Computational  Linguistics.
19(1):61-74Hiroshi Echizen-ya, Kenji Araki, Yoshi Momouchi,Koji Tochinai.
2003.
Effectiveness of automaticextraction of bilingual collocations usingrecursive chain-link-type learning.
The 9thMachine Translation Summit.
pp.102-109Pascale Fung, and Yee Lo Yuen.
1998.
An IRapproach for translating new words fromnonparallel, comparable Texts.
The 36th  annualconference of the Association for ComputationalLinguistics.
pp.
414-420Jianfeng Gao, Jianyun Nie, Hongzhao He, WeijunChen, Ming Zhou.
2002.
Resolving querytranslation ambiguity using a decaying co-occurrence model and syntactic dependencerelations.
The 25th Annual International ACMSIGIR Conference on Research andDevelopment in Information Retrieval.
pp.183 -190G.
Heidorn.
2000.
Intelligent writing assistant.
InR.
Dale, H. Moisl, and H. Somers, editors, AHandbook of Natural Language Processing:Techniques and Applications for the Processingof Language as Text.
Marcel Dekker.Philipp Koehn and Kevin Knight.
2000.
Estimatingword translation probabilities from unrelatedmonolingual corpora using the EM algorithm.National Conference on Artificial Intelligence.pp.711-715Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.Unsupervised Lexical Acquisition: Workshop ofthe ACL Special Interest Group on the Lexicon.pp.
9-16Julian Kupiec.
1993.
An algorithm for findingnoun phrase correspondences in bilingualcorpora.
The 31st Annual Meeting of theAssociation for Computational Linguistics, pp.23-30Cong Li, Hang Li.
2002.
Word translationdisambiguation using bilingual bootstrapping.The 40th annual conference of the Associationfor Computational Linguistics.
pp: 343-351Dekang Lin.
1998.
Extracting collocation fromText corpora.
First Workshop on ComputationalTerminology.
pp.
57-63Dekang Lin 1999.
Automatic identification of non-compositional phrases.
The 37th Annual Meetingof the Association for Computational Linguistics.pp.317--324Ilya Dan Melamed.
1997.
Automatic discovery ofnon-compositional compounds in parallel data.The 2nd Conference on Empirical Methods inNatural Language Processing.
pp.
97~108Brown P.F., Pietra, S.A.D., Pietra, V. J. D., andMercer R. L. 1993.
The mathematics of machinetranslation: parameter estimation.
ComputationalLinguistics, 19(2):263-313Reinhard Rapp.
1999.
Automatic identification ofword translations from unrelated English andGerman corpora.
The 37th annual conference ofthe Association for Computational Linguistics.pp.
519-526Violeta Seretan, Luka Nerima, Eric Wehrli.
2003.Extraction of Multi-Word collocations usingsyntactic bigram composition.
InternationalConference on Recent Advances in NLP.
pp.424-431Frank Smadja.
1993.
Retrieving collocations fromtext: Xtract.
Computational Linguistics,19(1):143-177Frank Smadja, Kathleen R. Mckeown, VasileiosHatzivassiloglou.
1996.
Translation collocationsfor bilingual lexicons: a statistical approach.Computational Linguistics, 22:1-38Aristomenis Thanopoulos, Nikos Fakotakis,George Kokkinakis.
2002.
Comparativeevaluation of collocation extraction metrics.
The3rd International Conference on LanguageResource and Evaluation.
pp.620-625Hua Wu, Ming Zhou.
2003.
Synonymouscollocation extraction using translationInformation.
The 41th annual conference of theAssociation for Computational Linguistics.
pp.120-127Kaoru Yamamoto, Yuji Matsumoto.
2000.Acquisition of phrase-level bilingualcorrespondence using dependency structure.
The18th International Conference on ComputationalLinguistics.
pp.
933-939Ming Zhou, Ding Yuan and Changning Huang.2001.
Improving translation selection with a newtranslation model trained by independentmonolingual corpora.
Computaional Linguistics& Chinese Language Processing.
6(1): 1-26
