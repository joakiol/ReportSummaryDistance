Semiautomatic labelling of semantic featuresArantza D?az de Ilarraza, Aingeru Mayor and Kepa SarasolaIXA Group.
Computer Science Faculty.
University of the Basque CountryDonostia/San Sebastian.
The Basque Countryjipdisaa/jibmamaa/jipsagak@si.ehu.esAbstractThis paper presents the strategy and designof a highly efficient semiautomatic method forlabelling the semantic features of commonnouns, using semantic relationships betweenwords, and based on the information extractedfrom an electronic monolingual dictionary.
Themethod, that uses genus data, specific relatorsand synonymy information, obtains an accuracyof over 99% and a scope of 68,2% with regard toall the common nouns contained in a real corpusof over 1 million words, after the manuallabelling of only 100 nouns.1 IntroductionSemantic information is essential in a lot ofNLP applications.
In our case, the feature[?animate] is necessary to disambiguate betweenthe possible Basque translations for the Englishpreposition "of" and the Spanish preposition"de", when referring to location or possession.This ambiguity appears very often whentranslating to Basque [D?az de Ilarraza et al,2000].
A complete manual labelling of semanticinformation would prove extremely expensive.This study aims to outline the strategy anddesign of a semiautomatic method for labellingsemantic features of common nouns in Basque,expanding and improving the idea outlined in[D?az de Ilarraza et al 2000].
Due to the poorresults obtained, this study dismissed thepossibility of an initial approach aimed atextracting the information corresponding to the(?animate) feature automatically from corpus.Instead, an alternative idea was proposed, i.e.that of using semantic relationships betweenwords extracted from the Basque monolingualdictionary Euskal Hiztegia (Sarasola 1996).
Inthis context, we used genus data and specificrelators, together with a few words manuallylabelled, to extract the informationcorresponding to the (?animate) feature.
Theresults obtained were very promising: 8,439common nouns were labelled automatically afterthe manual labelling of just 100.This paper describes the work carried out withthe aim of expanding this idea this idea throughthe inclusion of information about synonymy,repeating the automatic process iteratively inorder to obtain better results  and, monitoring thereliability of the labelling of each individualnoun.
After studying the ideal relationshipbetween the manual part of the operation and thescope of the automatic process, we generalisedthe process in order to adapt it to other semanticfeatures.
We obtained very satisfactory resultsconsidering the labelling of common nounscontained in the dictionary: for the [?animate]feature, we labelled 12,308 nouns with anaccuracy of 99.2%, after the manual labelling ofonly 100.This paper is organised as follows: section 2presents the semantic relationships betweenwords extracted from the Basque monolingualdictionary, and used by our semiautomaticlabelling method.
The method itself is describedin section 3.
The experiments carried out withthe aim of optimising the efficiency of themethod are described in section 4, and section 5outlines the accuracy and scope of the labellingprocess for the [?animate] semantic feature.Finally, section 6 describes how the method wasgeneralised to cover other semantic features.
Thestudy finishes by underlining the results obtainedand suggesting future research.2 Superficial semantic relationshipsbetween words in dictionariesAccording to Smith and Maxwell, there arethree basic methods for defining a lexical entry[Smith and Maxwell., 1980]:?
By means of a synonym: a word with thesame sense as the lexical entry.finish.
conclude(sin), terminate(sin)?
By means of a classical definition: ?genus +differentia?.
The genus is the generic term orFigure 1.
Implementation of the automatic process using genus and relater informationprocedure Labelling_of_the_dictionary {foreach (common Noun of the dictionary) {(Label, Reliability) = Find_its_label (Noun)  }}procedure Find_its_label (Noun) {foreach (Sense with Noun Genus/Relator) {if (Genus/Relator labelled){ Sense.Label  = Genus/Relator.LabelSense.Reliability = Genus/Relator.Reliability}else {(  Sense.Label,Sense.Reliability) = Find_its_label(Genus) } #recursionif (Noun.Label != Sense.Label) { Noun.Label = [?]
}else  { Noun.Label =  Sense.Label }} # end foreachNoun.Reliability = ?
Reliability labelled senses / number of sensesreturn (Noun.Label, Noun.Reliability)}hyperonym, and the lexical entry a morespecific term or hyponym.aeroplane.
vehicle (genus) that can fly(differentia)?
By means of specific relators, that will oftendetermine the semantic relationship betweenthe lexical entry and the core of thedefinition.horsefly.
Name given to (relator) certaininsects (related term) of the Tabanidae familyOne method for identifying the semanticrelationship that exists between different wordsis to extract the information from monolingualdictionaries.Agirre et al (2000) applied it for Basque,using the definitions contained in themonolingual dictionary Euskal Hiztegia.
We usefor our research the information about genus,specific relators and synonymy extracted bythem.3 Semiautomatic labelling using genus,specific relators and synonymyIn order to label the common nouns thatappear in the dictionary, we used the definitionsof the 26,461 senses of the 16,380 commonnouns defined by means of genus/relators(14,569) or synonyms (11,892).The experiment was carried out as follows:firstly, we used the information relative to genusand specific relators to extract the informationregarding the [?animate] feature (3.1).Subsequently, we also incorporated theinformation relative to synonymy (3.2).
Finally,we repeated the automatic process iteratively inorder to obtain better results (3.3).
An exampleof the whole process is given in section 3.4.3.1 Labelling using information relative togenus and specific relatorsOur strategy consisted of manually labellingthe semantic feature for a small number of wordsthat appear most frequently in the dictionary asgenus/relators.
We used these words to infer thevalue of this feature for as many other words aspossible.This inference is possible because in thehyperonymy/hyponymy relationship, thatcharacterises the genus, semantic attributes areinherited.
For example, if ?langile?
(worker) hasthe [+animate] feature, all its hyponyms (or inother words, all the words whose hyperonym is?langile?)
will have the same [+animate] feature.Certain genus are ambiguous, since theycontain senses with opposing semantic features.For example ?buru?
(head/boss) has the [-animate] feature when it means ?head?
and the[+animate] feature when it means ?boss?.
Thesemantic feature of the sense defined can also bededuced from some specific relators.
In this way,the semantic feature of words whose relator is?nolakotasuna?
(quality) would be [-animate],such as in the case of ?aitatasuna?
(paternity), forexample.
There are also certain relators that offerno information, such as ?mota?
(type), ?izena?
(name), and ?banako?
(unit, individual).We used four types of labels during themanual operation: [+], [-], [?]
and [x].
[?]
forambiguous cases; and [x] for relators that do notoffer information regarding this semantic feature.In order to establish the reliability of theautomatic labelling process for a particular noun,we considered the number of senses labelled,taking into account the reliability of the labels ofthe genus (or relator) that provided theinformation.
The result was calculated asfollows:Rel_noun = ?
Rel_genus_per_sense / n_sensesDuring manual labelling, we assignedreliability value 1 to all labels, since all thesenses of these nouns are taken into account.Figure 1 shows the algorithm used.
For eachcommon noun defined in the dictionary, we take,one by one, all their senses containing genus orrelator, assigning in each case the first labelassociated to a genus or relator in the hierarchyof hyperonyms.
When the sign of all the labelsare coincident we use it to label the entry, inother case, we use the label [?].
In all cases, theirreliability is calculated.When we detect a cycle, the search isinterrupted and the sense to be tagged remainsunlabelled.3.2 Labelling using synonymy informationLabelling using genus and relators can beexpanded by using synonymy.
Since thesynonymy relationship shares semantic features,we can deduce the semantic label of a sense ifwe know the label of its synonymes.Therefore, the information obtained during theprevious phase can now be used to label newnouns.
It also serves to increase the reliability ofnouns already been labelled thanks to the genusinformation of some of their senses.
If thesynonymy information provided corroborates thegenus information, the noun?s reliability ratingincreases.
If, on the other hand, the new labeldoes not coincide with the previous one, aspecial label: [?]
is assigned to the nounindicating this ambiguity.The automatic process using synonymy wasimplemented in the same way as in the previousprocess.3.3 Iterative repetition of the automaticprocessOur next idea was to repeat the process; sincethe information gathered so far using synonymymay also be applied hereditarily through thegenus?
hyperonymy relationship.We therefore repeated the process from thebeginning, trying to label all the senses of thenouns that had not been fully labelled during theinitial operations, by using the informationcontained in the senses of the nouns that hadbeen fully labelled (reliability 1).As with the initial operation, we first usedinformation about genus and relators, and then,synonymy.This process can be repeated any number oftimes, thereby labelling more and more wordswhile increasing the reliability of the labellingitself.
However, repetition of the process alsoincreases the number of words labelled asambiguous [?
], since more senses are labelledduring each iteration, thereby increasing thechances of inconsistencies.
As we shall see, thisiterative process improves the resultslogarithmically up to a certain number ofrepetitions, after which it has no furtheradvantageous effects.3.4 Example of semiautomatic labelling forthe [?animate] featureThe 100 words that are most frequently usedas genus (g) or relators (r) were labelledmanually for the [?animate] feature, as shown intable 2 (tables 3, 4 and 5 contain the Basquewords processed during the explained operation,along with their English translation in italics).Noun  ?anim Freq Gen/relnolakotasun (quality) - 531   Relatorpertsona (person) + 377   Genusmultzo (collection)  - 362   Relatortxikigarri (collection)  x  213 Relatorzati (part) - 230   Relatorgai (material)  - 202   Genustresna (instrument)  - 188   Genus...buru (head) ?
54 GenusTable 2.
Manual labellingWe shall now trace the implementation of theautomatic labelling process for certain nouns.Table 3 shows the results of the first labellingprocess using information about genus andrelators.
The words printed in bold in the resultscolumn are nouns that were labelled during themanual labelling process.
We can see how thenoun ?babesgarri?
(protector) is labelled as [-]thanks to the information provided by the relatorof its only sense, which was manually labelled.ThIn(rntihr(wgaNb(a(a(i(g(g(e(a(a(a(f(i(j(z(oun N. sense N. genus Result of process using genus and relators  Lab Rel.abesgarriprotector)1 1 (zer[-]1)(thing)[-] 1rmaduraarmour)3 3 (multzo[-]1) (babesgarri[-]1)(soineko[])(collection) (protector)     (garment)[-] 0.66mamother)5 3 (emakume[+]1)(animalia[+]1)(eme[])(woman)      (animal)      (female)[+] 0.4turburuspring)3 1 (aterabide[])(outlet)[] 0ertaeraevent)1 1 (gauza[-]1)(thing)[-] 1iltzapeprison)2 1 (toki[-]1)(place)[-] 0.5spetxejail)2 2 (eraikuntza[-]1)(leku[-]1)(construction)  (place)[-] 1diskide 1 1 (pertsona[+]1) [+] 1 e noun therefore has a reliability rating of 1.the same way, 2 of the 3 senses of ?armadura?1.
The reliability rating obtained for ?zinismo?was therefore 0.87 (f=(1+0.75)/2=0.87).friend)   (person)diskidetzakofriend)1 1 (lagun[])(companion)[] 0piocelery)2 2 (jateko[])  (landare[-]1)(food)      (plant)[-] 0.5ilosofiaphilosophy)2 2 (jakintza[-]1)(multzo[-]1)(knowledge)   (collection)[-] 1kusguneviewpoint)2 1 (gune[-]1)(point)[-] 0.5arreraattitude)2 2 (era[-]1)(ikusgune[-]0.5)(way)    (viewpoint)[-] 0.75inismocynicism)2 2 (filosofia[-]1)(jarrera[-]0.75 )(philosophy)   (attitude)[-] 0.87Table 3.
Result of automatic labelling using genus and relator information armour) had coincident labels, thereby giving aeliability rating of 0.66 (f=(1+1)/3=0.66).
Theoun ?ama?
(mother) was labelled as [+], thankso the information about genus and relator of 2 ofts 3 senses, out of a total of 5 (the remaining twoave synonymy information).
The reliabilityating was therefore calculated as 0.4f=(1+1)/5=0.4).
The word ?zinismo?
(cynicism)as labelled as [-] thanks to the fact that theenus of its 2 senses were both labelled as such,lthough one did not have a reliability rating ofTable 4 shows some examples of the processusing synonym information.As we can see, ?iturburu?
(spring), which theprevious process had not managed to tag, is nowlabelled as [-] thanks to the synonymyinformation associated to one of the two senses.The resulting reliability rating is 0.06(f=0.2/3=0.06).
If we look at the term ?ama?,which had previously been labelled as [+] on thebasis of genus information, we see that thesynonyms of the two senses that use synonymyNoun Genus lab.
N. sens N. syn Results of the process using synonymy Lab.
Relia.iturburu(spring)[] 3 2 (etorki[])  (hasiera[-]0.20)(origin)    (start)[-] 0.06ama(mother)[+] 5 2 (iturburu[-])(jatorri[-])(spring)     (origin)[?]
1gertakuntza(event)1 1 (gertaera[-]1)(happening)[-] 1lagun(companion)1 1 (adiskide[+]1)(friend)[+] 1jateko(food)1 1 (janari[-]1)(food)[-] 1giltzape(prison)[-] 2 1 (espetxe[-]1)(jail)[-] 1ikusgune(viewpoint)[-] 2 1 (ikuspen[-]0.33)(view)[-] 0.66Table 4.
Results of automatic labelling using synonymy informationNounarmadur(armouradiskid(friendapio(celeryikusgun(viewpojarrera(attituzinismo(cyniciinformainconsiThe(compapreviouthanks to synonym information.
The words?giltzape?
(prison) and ?ikusgune?
(viewpoint),which had had one sense labelled on the basis ofgenus, now have both senses labelled.
Thereliability rating for ?ikusgune?
is calculated asf=(1+0.33)/2=0.66.We then repeated the process using first thegenus/relator information (table 4) followed bythe synonymy information (table 5).The aim of this repetition was to label onlythose words that had not been fully labelled,using the information provided by the terms thathad been and that had a reliability rating of 1,such as  ?babesgarri?, ?gertaera?, ?espetxe?,?adiskide?, ?filosofia?, ?ama?, ?gertakuntza?,?lagun?, ?jateko?
and ?giltzape?
(tables 4 and 5).This process succeeded in labelling the sensesinformation.
On the other hand, ?ikusgune?
(viewpoint), ?jarrera?
(attitude) and ?zinismo?
(cynicism), did not benefit from this repetition.Following this process, we applied thesynonymy information, thus completing thesecond iteration.
The process may be repeated asmany times as you wish.4 Experiments for optimising theefficiency of the methodWe carried out a number of different tests forthe [?animate] semantic feature labelling the 2,5, 10, 50, 100, 125 and 150 words mostfrequently used as genus/relators, and repeatingthe whole process (using both genus and relatorand synonymy information) 1, 2 and 3 times.The first 5 terms that appear most frequently020004000600080001000012000140000 20 40 60 80 100 120 140Manual labellingAutomaticlabelling0400800120016002000RelativeincreaseFig.
2.
Automatic labelling and relative increase N. sense N. genus Result of process using genus and relators  Lab.
Relia.a)3 3 (multzo[-]1)(babesgarri[-]1)(soineko[-]1)(collection)  (protector)     (garment)[-] 1etzako)1 1 (lagun[+]1)(companion)[+] 1)2 2 (jateko[-]1)(landare[-]1)(food)    (plant)[-] 1eint)2 2 (gune[-]1)(point)[-] 0.5de)2 2 (era[-]1)(ikusgune[-]0.5)(way)   (viewpoint)[-] 0.75sm)2 2 (filosofia[-]1)(jarrera[-]0.75 )(philosophy)    (attitude)[-] 0.87Table 5.
Results of the 2nd iteration of automatic labelling using genus and relator informationtion are labelled as [-].
Due to thisstency, the word is now labelled as [?
].terms ?gertakuntza?
(event), ?lagun?nion) and ?jateko?
(food), whichsly only had one sense, are now labelledof ?armadura?
(protector), ?adiskidetzako?
(friend) and ?apio?
(celery), previously leftunlabelled, since their genus ?soineko?
(garment), ?lagun?
(friend) and ?jateko?
(food)had been fully labelled using the synonymas genus/relators are also the most productiveduring the automatic labelling process.
Fromhere on, the rate of increase gradually falls, untilonly 7 terms are labelled automatically for everynoun labelled manually.On average, the first 2 nouns each enabled1840 terms to be labelled, the next 3 enabled1112 while the next 5 enabled only 250.
Afterthe hundredth noun, this average dropped to just7 new terms labelled automatically for everyterm labelled manually.
These results areillustrated in figure 2.For efficiency reasons, we decided that whenlabelling other semantic features, we will labelmanually the 100 nouns most frequently used asgenus/relators.In order to decide the number of iterationsrequired for optimum results, we compared theresults obtained after 1 to 10 iterations aftermanually labelling 100 nouns (Figure 3).Although no increase was recorded for thenumber of nouns with reliability rating 1 (i.e.with all senses labelled) after the 3rd iteration, theresults for other reliability ratings continued toincrease up until the 8th iteration, since as moreand more information is gathered, newcontradictions are generated and the number ofambiguous labels increases.
When the resultsstabilise, we can affirm that all the availableinformation has been used and the most accurateresults possible with this manual labellingoperation have been obtained.
It is important tocheck that the process does indeed stabilise, andthat it does so after a fairly low number ofiterations (in this case, after 8).The repetition of the process does notsignificantly increase execution time.
10iterations of the automatic labelling process forthe [?animate] feature takes just 11 minutes 33seconds using the total capacity of the CPU of aSun Sparc 10 machine with 512 Megabytes ofmemory running at 360 MHz.We can therefore conclude that the method isviable and that, in the automatic process forother semantic features, the necessary iterationsshould be carried out until the results are totallystabilised.5 Accuracy and scope of the labellingprocess for the [?animate] featureIn order to calculate the accuracy of theautomatic labelling process, we took 1% of thelabelled words as a sample and checked themmanually.
The results are shown in table 6.Reliabilityf=1 1>f>0.5 0.5>f>0 TotalAccuracy 100% 100% 94% 99.2%Table 6.
Accuracy of automatic labellingAlthough we initially planned to use only thelabels with a reliability rating of 1, after seeingthe accuracy of the others, we decided to use allthe labels obtained during the process, therebyachieving an overall accuracy rating of 99.2%.We can affirm that the semiautomatic processdesigned and implemented here is very efficient.The scope for the automatic labelling of the[?animate] feature (table 7) was 75.14% of allthe nouns contained in the dictionary (12,308 of16,380), having manually labelled 100 nouns and020004000600080001000012000140000 2 4 6 8 10 12Number of iterationsAutomaticlabellingAutomatic labellingf=11>f>0.50.5>f>0?Fig.
3.
Automatic labelling according to number of iterationscarried out 8 iterations.Labellingf=1 1>f>0.5 0.5>f>0?6132 4513 1663 Autolab.
12308 (75.14%)1301Table 7.
Scope of the dictionaryWe also calculated the scope of this labellingin a real context, using the corpus gathered fromthe newspaper Euskaldunon Egunkaria, whichcontains 1,267,453 words and 311,901 commonnouns, of which 7,219 are different nouns.
Table8 shows the results ?
a scope of 69.2% withregard to the nouns that appear in the text (47.6%of the total number of different common nounscontained in the corpus).
In other words, aftercarrying out a very minor manual operation, wemanaged to label two out of every three nounsthat appear in the corpus.
Similarly, we notedthat of the 500 nouns that appear most frequentlyin the corpus, 348 (69.6%) were labelled.Appearances inthe corpusDifferentnounsTotal 311,901 7,219Labelled (68.2%) 212,887 (47.6%) 3,434[+] 17,408 356[-] 195,479 3,078Table 8.
Scope of labelling within the corpus6 Generalisation for use with othersemantic featuresGiven the process?s efficiency, it can begeneralised for use with other semantic features.To this end, we have adapted its implementationto enable the automatic process to be carried outon the basis of the manual labelling of anysemantic feature.So far, we have carried out the labellingprocess for the [?animate], [?human] and[?concrete] semantic features.
Table 12 showsthe corresponding results.Label ?animate ?human ?concrete[+] 1,643 1,118 7,611[-] 10,665 10,684 1,143Total 12,308 11,802 8,754Table 12.
Labelling data for different semanticfeaturesConclusionsWe have presented a highly efficientsemiautomatic method for labelling the semanticfeatures of common nouns, using the study ofgenus, relators and synonymy as contained in theEuskal Hiztegia dictionary.
The results obtainedhave been excellent, with an accuracy of over99% and a scope of 68,2% with regard to all thecommon nouns contained in a real corpus of over1 million words, after the manual labelling ofonly 100 nouns.As far as we know, no so method of semanticfeature labelling has been described in theliterature, although many authors [Pustejovsky,2000; Sheremetyeva & Nirenburg, 2000] claimthe significance of semantic features in general,and [animacy] in particular, for NLP systems.One of the possible applications of theseexperiments is to enrich the Basque LexicalDatabase, EDBL, using the semantic informationobtained.AcknowledgementsThe Basque Government Department ofEducation, Universities and Research sponsoredthis study.BibliographyAgirre E., Ansa O., Arregi X., Artola X., D?az deIlarraza A., Lersundi M., Martinez D., Sarasola K.,Urizak R., 2000, ?Extraction of semantic relationsfrom a Basque monolingual dictionary usingConstraint Grammar?, EURALEX?2000.Diaz de Ilarraza A., Lersundi M., Mayor A., SarasolaK., 2000.
Etiquetado semiautom?tico del rasgosem?ntico de animicidad para su uso en un sistemade traducci?n autom?tica.
SEPLN?2000.
Vigo..Diaz de Ilarraza A., Mayor A., Sarasola K., 2000.?Reusability of Wide-Coverage LinguisticResources in the Construction of a Multilingual MTSystem?.MT 2000.
Exeter.
UK.Pustejovsky J., 2000.
?Syntagmatic Processes?.Handbook of Lexicology and Lexicography.
deGruyter, 2000.Sheremetyeva S. and Nirenburg S., 2000.
"Towards AUniversal Tool for NLP Resource Acquisition".LREC2000.
Greece.Smith, R.N., Maxwell, E., 1980, ?An Englishdictionary for computerised syntactic and semanticprocessing systems?, Proceedings of theInternational Conference on ComputationalLinguistics.
1980.
