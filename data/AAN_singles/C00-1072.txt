The Automated Acquisit ion of Topic Signatures for TextSummarizat ionChin -Yew L in  and  Eduard  HovyIn fo rmat ion  S(:i(umes I l l s t i tu teUn ivers i ty  of Southern  Ca l i fo rn iaMar ina  del Rey, CA  90292, USA{ cyl,hovy }C~isi.eduAbst rac tIn order to produce, a good summary, one hasto identify the most relevant portions of a giventext.
We describe in this t)at)er a method for au-tomatically training tel)it, signatures--sets of relatedwords, with associated weights, organized aroundhead topics and illustrate with signatm'es we cre-;tt.ed with 6,194 TREC collection texts over 4 se-lected tot)ics.
We descril)e the l)ossible integrationof' tolli(: signatures with ontoh)gies and its evaluatonon an automate(l text summarization system.1 I n t roduct ionThis t)aper describes the automated (:reation of whatwe call topic signatures, constructs that can I)lay acentral role.
in automated text summarization andinformation retrieval.
ToI)ic signatures can lie usedto identify the t)resence of a (:omph~x conce.pt aconcept hat consists of several related coinl)onentsin fixed relationships.
\]~.c.sta'uvant-'uisit, for examph~,invoh,es at h,ast the concel)ts lltCgFIt, t'.
(tt, pay, andpossibly waiter, all(l Dragon Boat PcstivaI (in Tat-wan) involves the Ct)llC(!l)t,S cal(tlzt'lt,s (a talisman toward off evil), rnoza (something with the t)ower ofpreventing pestilen(:e and strengthening health), pic-tures of Ch, un9 Kuei (a nemesis of evil spirits), eggsstanding on end, etc.
Only when the concepts co-occur is one licensed to infer the comph:x concept;cat or moza alone, for example, are not sufficient.
Atthis time, we do not c.onsider the imerrelationshipsamong tile concepts.Since many texts may describe all the compo-nents of a comI)lex concept without ever exI)lic-itly mentioning the mlderlying complex concel/t--atol)ic--itself, systems that have to identify topic(s),for summarization or information retrieval, requirea method of infcu'ring comt)h'x concelltS fl'om theircomponent words in the text.2 Re la ted  WorkIn late 1970's, \])e.long (DeJong, 1982) developed asystem called I"tIUMP (Fast Reading Understand-ing and Memory Program) to skim newspaper sto-ries and extract the main details.
FRUMP usesa data structure called sketchy script to organizeits world knowh'dge.
Each sketchy script is whatFRUMI ) knows al)out what can occur in l)articu-lar situations such as denmnstrations, earthquakes,labor strike.s, an(t so on.
FRUMP selects a t)artic-ular sketchy script based on clues to styled eventsin news articles.
In other words, FRUMP selects aneml)t3 ~ t(uni)late 1whose slots will be tilled on the flyas t"F\[UMP reads a news artMe.
A summary is gen-erated })ased on what has been (:al)tured or filled inthe teml)Iate.The recent success of infornmtion extractk)n re-search has encore'aged the FI{UM1 ) api)roach.
TheSUMMONS (SUMMarizing Online News artMes)system (McKeown and Radev, 1999) takes tem-l)late outputs of information extra(:tion systems de-velofmd for MUC conference and generating smn-maries of multit)le news artMes.
FRUMP and SUM-MONS both rely on t/rior knowledge of their do-mains, th)wever, to acquire such t)rior knowledgeis lal)or-intensive and time-consuming.
I~)r exam--l)le, the Unive.rsity of Massa(:husetts CIRCUS sys-l.enl use(l ill the MUC-3 (SAIC, 1998) terrorism do-main required about 1500 i)erson-llours to define ex-traction lmtterns 2 (Rilotf, 1996).
In order to makethem practical, we need to reduce the knowhxlge n-gineering bottleneck and iml)rove the portability ofFI{UMI ) or SUMMONS-like systems.Since the worhi contains thousands, or perhal)smillions, of COml)lex (:on(:et)ts , it is important; to beable to learn sketchy scripts or extraction patternsautomatically from corpora -no existing knowledgebase contains nearly enough information.
(Rilotf aimLorenzen, 1999) 1)resent a system AutoSlog-TS thatgenerates extraction i)atterns and learns lexical con-straints automatically fl'om t)rec\]assified text to al-leviate the knowledge ngineering I)ottleneck men-tioned above.
Although Riloff al)plied AutoSlog-TSl\Ve viewed sketchy s(:lil)tS and teml)lates as equivalent(ollstrllctS ill the sense that they sl)ecil ~, high level entitiesand relationships for specific tot)its.2Aii extra(:l;iOll pattt!rlk is essentially ;t case fraine containsits trigger word, enabling conditions, variable slots, and slotconstraints.
C IRCUS uses a database of extraction patternsto t~alSe texts (l{ilolI', 1996).495to text categorization and information extraction,the concept of relevancy signatures introduced byher is very similar to the topic si.qnatures we pro-posed in this paper.
Relevancy signatures and topicsignatures arc both trained on preclassitied ocu-ments of specific topics and used to identify thepresence of the learned topics in previously unseendocuments.
The main differences to our approachare: relevancy signatures require a parser.
They aresentence-based and applied to text categorization.On the contrary, topic signatures only rely on cor-pus statistics, arc docmnent-based a and used in textsmnmarization.In the next section, we describe the automatedtext smmnarization system SUMMARIST that weused in the experiments to provide the context ofdiscussion.
We then define topic signatures and de-tail the procedures for automatically constructingtopic signatures.
In Section 5, we give an overviewof the corpus used in the evaluation.
In Section 6 wepresent he experimental results and the possibilityof enriching topic signatures using an existing ontol-ogy.
Finally, we end this paper with a conclusion.3 SUMMARISTSUMMARIST (How and Lin, 1999) is a systemdesigned to generate summaries of multilingual in-put texts.
At this time, SUMMARIST can processEnglish, Arabic, Bahasa Indonesia, Japanese, Ko-rean, and Spanish texts.
It combines robust naturallanguage processing methods (morl)hologieal trans-formation and part-of-speech tagging), symbolicworld knowledge, and information retrieval tech-niques (term distribution and frequency) to achievehigh robustness and better concept-level generaliza--tion.The core of SUMMARIST is based on the follow-ing 'equation!
:summarization = topic identification +topic interpretation + generation.These three stages are:Topic Ident i f ieat lon:  Identify the most imtmrtant(central) topics of the texts.
SUMMARISTuses positional importance, topic signature, andterm frequency.
Importance based on discoursestructure will be added later.
This is tile mostdeveloped stage in SUMMARIST.Topic I n te rpretat ion :  ~i~-) fllse concepts such aswaiter, menu, and food into one generalizedconcept restaurant, we need more than the sin>pie word aggregation used in traditional infor-mation retrieval.
We have investigated conceptaWe would like to use only the relevant parts of documentsto generate topic signatures in the future, qkext segmentationalgorithms uch as TextTiling (Ilearst, 1997) can be used tofind subtopic segments in text.ABCNEWS.cona  : De lay  in  Hand ing  F l ight  990  \ [ ' robe  to  FB IN'I 'SI3 C l la i tn lan  Jarl leS t la l l  says  Egypt ian  clff icials Iv811l to  I,~view res t l l t sof  t i le  invest igat ion  intcl lhe  cras l l  o f  l lggyptA i r  F l ight  990 before  t i le  casei~ lu r l led  over  Ic, t i le Fi31,Nt lv.
IG - U S. i lxvestigl~lo\[~ lLppear to  be leat l i l lg i i Iore thg l l  eveF low~trdt i le poss ib i l i ty  that  one  o f  the  cc~-pilot~ o f  EgyptA i r  F l ight  990 may havede \ [ ihera le ly  c rashed t i le p lane  las t  I lafl l lth, k i l l i ng  all 217 peop le  on  board .f la i l ' ever .
US .
o f f i c ia ls  say  t i le  Nat iona l  T ran~por ' ta t ion  Sa fety  Board  wi l lde lay  t rans fer r ing  tile invegt iga l ion  o f  the  Oct  31 c rash  to  tilt: FI31 - theagency  that  wot l id  lead i~ c r imina l  p robe  - for at  least  tt few days .
to  M IowEgypt ian  exper ts  to rev iew ev idence  ill t i le case.gtts l ) ic iot l~ of  fou l  p lay  were  ra i sed  a f te r  invest igators  l i s ten ing  to  rt tapeftol l l  l i l t  cockp i t  vo ice recorder  i so la ted  a re l ig ious  prayer  or s ta te l l l e l l tmade by t i le co -p i lo t  jus t  be fore  t i le  p lane 's  autop i lo t  was turned  o f fs l id  the  p lane  began i ts  in i t ia l  p lunge  in to  t i le A t lant i c  Ocean of f  Mas -s r tcht tset t$ '  Na l l tucket  \ [s ia l ld .Over  tile' pas t  week .
a f te r  muc i l  e f fo r t ,  t i le  NTSJB and  t i le  Navy  succeededill I ocat i l lg  the  p lane 's  two  "b lack  boxes , "  th~ cockp i t  vo ice recorder  andlhe  f l ight  data  recorder .The  tape  ind icates  t l l a t  shor t ly  a f te r  the  p lane  leve led ~ff  a t  i ts c ru i s inga l t i tude  o f  as ,000  feet ,  t i le  cl~ief p i lo t  o f  t i le a i rc ra f t  left  the  p lane 'scockp i t ,  l eav ing  one  o f  t i le  twc~ co-p i lo ts  nIol le t i lere as the  a i rc ra f t  beganits descent .Figure 1: A Nov. 16 1999 ABC News page sumnmrygenerated by SUMMARIST.counting and topic signatures to tackle tile fll-sion problem.Summary Generat ion :  SUMMARIST can pro-duce keyword and extract type summaries.Figure 1 shows an ABC News page summaryabout EgyptAir Flight 990 by SUMMARIST.
SUM-MARIST employs several different heuristics in tiletopic identification stage to score terms and sen-tences.
The score of a sentence is simply the sumof all the scores of content-bearing terms in the sen-tence.
These heuristics arc implemented in separatemodules using inputs from preprocessing modulessuch as tokenizer, part-of-speech tagger, morpholog-ical analyzer, term frequency and tfidf weights cal-culator, sentence length calculator, and sentence lo-cation identifier.
\Ve only activate the position mod-ule, tile tfidfmodule, and the.
topic signature modulefor comparison.
We discuss the effectiveness of thesemodules in Section 6.4 Top ic  S ignaturesBefore addressing the problem of world knowledgeacquisition head-on, we decided to investigate whattype of knowledge would be useflfl for summariza-tion.
After all, one can spend a lifetime acquir-ing knowledge in just a small domain.
But whatis tile minimum amount of knowledge we need toenable effective topic identification ms illustrated bythe restaurant-visit example?
Our idea is simple.We would collect a set of terms 4 that were typi-cally highly correlated with a target concept from apreclassified corpus such as TREC collections, andthen, during smnmarization, group the occurrence ofthe related terms by the target concept.
For exam-pie, we would replace joint instances of table, inert'u,waiter, order, eat, pay, tip, and so on, by the singlephrase restaurant-visit, in producing an indicative4Terms can be stemmed words, bigrams, or trigrams.496sulnlllary.
\Ve thus defined a tot)it signat.ure as afamily of related terms, as follows:~I'S = { topic, sifl~zutu.rc.
}= {topic,< ( t , ,w l ) , .
.
.
, ( t , , ,w , , )  >} (1)where topic is the target concet)t and .,d.q)zat~Lrc isa vector of related ternls.
Each t, is an term ldghlycorrelated to topic with association weight w/.
Thenumber of related terms 7z can tie set empiricallyaccording to a cutot\[ associated weight.
We.
describehow to acquire related terms and their associatedweights in the next section.4.1  S ignature  Term Ext rac t ion  and  WeightEs t imat ion()n the assumption that semantically related termstend to co-occur, on(' can construct topic signa-tures fl'om preclassified text using the X 2 test, mu-.tual information, or other standard statistic testsand infornlation-theoreti(: measures.
Instead of X '2,we use likclih.ood ratio (Dunniug, 1993) A, sin(:e Ai,; more apI)rot)riate for si/arse data than X 2 testand the quantity -21o9A is asymi)t(/tically X~ dis-tril)ute(15.
Therefore, we Call (leterndnc the (:onti-( lence level for a specific -21o9A value l/y looking ut)X :~ (tistril)ution table and use tlm value to sel(,,ct anat)i)rot)riate cutoff associated weight.We have documents l)\['e.classitied into a :;('~t, "R. ofrelevant exts and a set ~.
of nonrelewmt exl;s for agiven topic.
Assuming the following two hyl)othe,'~es:t typothes is  1 ( I f l ) :  t'(~Pvlti) = P = P('PvltT/), i.e.the r(.,lewmcy of a d()(:|lment is in(teI)en(hmt, oft i .I \ ] \ [ypothes is  2 ( t t2) :  I'('Pv\[ti) == lh ~ 1)'2 -t)('Pvlt, i), i.e.
th(~ t)r(.
':;(;n(:(~ of t i indi(:~Lt(.~.
'; strongr(~levan(:y ~ssunling \]h >> 1)2 ?and the following 2-10=2 contingency tabl(;:where Ol~ is the fiequency of term ti occurring inthe.
l 'e lev;tnt  set ,  012 is the \ [ r ( !qu(nlcy of Lerm t i t)c-curring in the  \] lol lreleval lt ,  set ,  O21 is the  f le(l l lel l( :yof tt;rnl \ [ i?
ti occurring in the rtdevant set, O._,~ isthe fl'equ(mcy of term l.i ?
ti o(:curring in the non-l ' e leva i i t  seL.-kssmning a l)inomial distril)ution:C;) b(~; ,,., :/.)
= :,:~(1 - .~:)(" ") (2 )5This assumes |ha l  the ratio is between the inaximuni like>\[ihood est, im&t.(!
over a .qll})part of l;}l(!
i)alatlllC't(~r sl)a(:(~ ;tll(\] l.h(!lllaxillUllll likelihood (}sI.i|II}tlA~ ov(!r the (Hltill!
i)al'aillt~tt!r si);t(:e.Set!
(Manning ;tnd Sch/itze, I999) t)ag, es 172 l.o 175 for d(!t.ails.then the likelihood for HI is:L(H~) = b(Ot~; 0~ + Ou,,p)b(O:,~; 0:,, + Om,,p)and for //2 is:L(H2)  = D(OI 1; O11 Jr" (')12, Pl )b(O21; (')21 Jr- (,)22,1)2)The -2log,\ value is then computed ms follows:1.
(f/1 )m --21o 9 - -L( i t  2 )b(O 11 ; O I  1 + O12,  P) I J (021 : O21 + 022 , P)- -21o 91'((-)1 l ; ( )11  + O1'-),  P I )h (O21 ; O21 q- ( )22  , P2 ): - -2 ( (O l l  +021) lo r_ Jp+( ( )12+022) lo9(1 - - l~) - -  (,~1)(? )
l l l o ' JP l+Ol21og( l  " t '1 )+0211ogp2-~0221o0(1- f~2) ) )-- '.2.,~' x (~ ' i (7~) -  ;~(~19- ) )  (4 )= 2,'v x Z(P~;  T )  (5 )whel 'e  N = O l t  -F O12 -1- O21 -I- 022 is the  to ta l  l lum-.her of t, ernl occurrence, in the corpus, 7/('/~) is theentropy of terms over relevant and nonrelevant setsof documents, 7/ ( ' fe l t  ) is the entropy of a given termOVel" relev;inL ~/nd nonl ' ( .qeval l t  sets  of doel l inel lLS, ~tll(1Z('R.
; T) i:; the inutual information between docu-ment relevancy and a given t('.rm.
Equation 5 indi-cates that mutual inforntation 6 is an e(tuiwdent mea-sur(.'
t() lik(.qiho(id ratio when we assume a binomialdistribution and a 2-by-2 ('ontingency table.To crest(; topic .~dgnature for a given tot)ic , we:1.
(:lassify doctunents as relevant or nonrclcwmtaccording t() tile given topic2.
comt)ut.e the -21oflA wdue using Equation 3 foreach Lcrm in the document colle(:Lion"{.
rank t, erms according 1o their -2lo9~ value4.
select a c(mfid(mce l , vel fi'om the A;: (listril)utiotltable; (letermin(~ the cutotf associated weight,mid the numl)(n" of t(nms to he included iIl thesignatures5 The CorpusThe training data derives Kern the Question andAnswering summary evahmtion data provided l)yT IPSTEI / .
-SUMMAC (Mani et al, 1998) that is asttbset of the TREC collectioliS.
The TREC data is acollection of texts, classified into various topics, usedfor formal ewduaLions of information retrieval sys-tems in a seri(~s of annual (:omparisons.
This data set:contains essential text fragnients (phrases, (:Iausos,iuld sentences) which must 1)e included in SUllltIlariosto ~tnswer some TI{EC tel)its.
These fl'agments areeach judged 1)y a hmnan judge.
As described in Se(:-tion 3, SUMMAI~IST employs several independentnlo(hlles to assign a score to each SelltA:llCe~ and ChellCOlll})illeS the st.'or(.
'.% L() decide which sentences to ex-tract from the input text;.
()n0.
can gauge the efticacy(>l'he lllll\[lla} inrormalion is defined according to chapter 2of ((;over and Thomas, i991) and is not tile i)airwis(~ mutualinforlnalion us(!d in ((;hur(:h and llanks, 1990).497TREC Top ic  Da~cr lp t ion(nunQ Number :  151( t i t le}  Top ic :  Co, p ing  w i th  overc rowded pr i sons(dese} Deser i l l t io l l :The  doeu l laent  will p rov ide  in f ,~rn lat ion ol~ jai l  and  pr ison overc rowd iuKand  how i r lmates  are forced to cope  wi th  th,~se cond i t ions ;  or it wil lrevea l  p lan~ to  re l ieve  ti le overc rowded ?o l ld i t lon .
(nar t )  Nar ra t ive :A re levant  docunaent  will descr ibe  scene~ of overcro~vdi l lg that  havebeco lne  all too  crlllllllOll ill ja i l s  and  pr i sons  a ro t tnd  the  count ry ,  T i ledocument  will i dent i fy  how inmates  are forced to  cope w i th  those  over -crowded cond i t ion~,  and/or  what  ti le Cc l r reet iona l  Syste l l l  is do ing ,  orph lnn ing  to do,  to a l lev ia te  ti le c rowded col ld i t io l l .
(/top)Test  Quest ionsQI  Me'hat are  name and/or  locat ion  of ti le cor rec t ion  fae i l i l ieswhere  the  repor ted  ~vercrowd ing  ex is ts?Q2 x~Vhat negat ive  exper iences  have  there  been  at t i le overc rowdedfac i l i t ies  (whether  or not tile)" are thought  to have  been  causedby  the  overc rowd lng)?Q3 What  measures  have  been  taken/p la ia i led / recommended (e tc .
)to aecon l lnod~te  more  i l l l l la Ies zlt pena l  fac i l i t ies ,  e .g .
,  doub l i l l gtip, Ile~y COllStructlon?Q,I ~,Vhat measures  have  been  taken/planned/rec~mnlel,ded (etc .
}to reduce  ti le l lt l l l lber of Dew il l l i \]ate$, e .g .
,  morator iumson admisMon,  a l te rnat ive  pena l t ies ,  p rograme to reducec r ime/ rec ld iv i sm?Q5 What  measures  have  been  taken/p lanned/ recommended (e tc .
)to reduce  ti le number  of ex i s t ing  inmates  at an overcrc~wdedfac i l i ty ,  e .g .
.
g rant ing  ear ly  re lease ,  t rnns fer ing  to  uncrowdedfac i l i t ies?Sample  Answer  Keys(DOCNO)  AP891027-0063 ( /DOCNO)(F ILE ID)  AP -NR-  10-27-89 0615EDT( /F ILE ID)( IST_L INE) r  a PM-Cha ined Inmates  10-27 0335( / IST .L INE)(2ND-L INE)PM-Cha ined  lnmates ,0344 ( /2ND_L INE)( I IEAD)  lnmates  Cha ined  to 1.Vails in 13Mtimore Po l i ceS ta t ions ( / l lEAD)(DATEL INE)BALT IMOIT IE  (AP)  ( /DATEL INE}('tEXT)(Q ,q )pr i soner~ are  kept  cha ined  to the wall~ of local po l ice  lcJekup~ foras long as th ree  days  at a t ln~e I)ecattse of overc rowd ing  ill regu la r  je l lcel ls ,  pol ice sa id .
( /Q3}Overcrowd ing  at  the  (Q1) lqMt l rnore  County  Detent ion  Center ( /Q1)h~ forced pn l lee  tn  .
.
(/TEXT)Table 1: TREC topic description for topic 151, testquestions expected to be answered by relewmt doc-uments, and a smnple document with answer key, s.of each module by comparing, for ditferent amountsof extraction, how many :good' sentences the moduleselects by itself.
We rate a sentence as good simplyif it also occurs in the ideal human-made xtract,and measure it using combined recall and precision(F-score).
We used four topics r of total 6,194 doc-uments from the TREC collection.
138 of them arerelevant documents with T IPSTER-SUMMAC pro-vided answer keys for the question and answeringevaluation.
Model extracts are created automati-cally from sentences contailfing answer keys.
Table1 shows TREC topic description for topic 151, testquestions expected to be answered by relevant doc-uments , and a sample relevant document with an-swer keys markup.7These four topics are:topic 151: Overcrowded Prisons, 1211 texts, 85 relevant;topic 257: Cigarette Consumption, 1727 texts, 126 relevant;topic 258: Computer Security, 1701 texts, 49 relevant;topic 271: Solar Power, 1555 texts, 59 relevant.SA relevant: document only needs to answer at least one ofthe five questions.6 Experimental ResultsIn order to assess the utility of topic signatures intext sununarization, we follow the procedure de-scribed at the end of Section 4.1 to create topicsignature for each selected TREC topic.
Docu-ments are separated into relevant and nom'elevantsets according to their TREC relevancy judgmentsfor each topic.
We then run each document hrougha part-of-speech tagger and convert each word intoits root form based on the \\h)rdNct lexical database.We also collect individual root word (unigram) fi'e-quency, two consecutive non-stopword 9 (bigram) fi'e-quency, and three consecutive non-stopwords (tri-gram) fi'equeney to facilitate the computation of the-21ogA value for each term.
We expect high rank-ing bigram and trigram signature terms to be veryinformative.
We set the cutoff associated weight at10.83 with confidence level ~t = 0.001 by looking upa X 2 statistical table.Table 2 shows the top 10 unigrmn, bigram, and tri-gram topic signature terms for each topic m. Severalconclusions can be drawn directly.
Terms with high-21ogA are indeed good indicators for their corre-sponding topics.
The -2logA values decrease as thenumber of words in a term increases.
This is rea-sonable, since longer terms usually occur less oftenthan their constituents.
However, bigram terms aremore informative than nnigrant erms as we can ob-serve: jail//prison overervwding of topic 151, tobaccoindustry of topic 257, computer security of topic 258,and solar e'n, ergy/imwer of topic 271.
These mLto-matically generated signature terms closely resembleor equal the given short TREC topic descriptions.Although trigram terms shown in the table, suchas federal court order, philip morris 7~r, jet propul..sion laboratory, and mobile telephone s:qstem are alsomeaningflfl, they do not demonstrate he closer termrelationship among other terms in their respectivetopics that is seen in tlm bigram cases.
We expectthat more training data can improve tile situation.We notice that the -2logA values for topic 258are higher than those of the other three topics.
Asindicated by (Mani et al, 1998) the majority of rel-evant documents for topic 258 have the query topicas their main theme; while the others mostly havethe query topics as their subsidiary themes.
Thisimplies that it is too liberal to assume all the termsin relevant documents of the other three topics arerelevant.
We plan to apply text segmentation algo-rithms such as TextTiling (Hearst, t997) to segmentdocuments into subtopic units.
We will then per-form the topic signature creation procedure only ontile relevant units to prevent inchlsion of noise terms.9\,Ve use the stopword list supplied with the SMAIIT re-trieval system.l?q'he -2logA values are not comparable across ngram cat-egories, since each ngraln category has its own sample space.498Top icI :ll h~l al l l  -21,~gX \ ] l i~ la l l I  -21,,9Xj a i l  t)3L I)1,1 e()tH~t 2, ja i l  Dit) 27:1c+,l l l l l} .IIJN ~21 eae ly  le+\]+.~lSt ?
N,'~ :{t;\], )v , . )
, '~ , ,wd ln~;  :?12:1.
I~ ~ta l , .
D l~.
, ,n  7.1 R72i l l ln?lt ," 2 : t l  7d5  s ta l , "  1,) i~, ,n, .
i  67  ,3(~t~~h+.
l i f \ [  IF, I .
i l o  ,1:~ 3 fill," l ; l  t(;2")s ta le  151 9t t~ ia i l  r l%l ' lctr~%vI\] l r ld I;1 ~\[ iI}l l~t l l i l ' l  I I  ~" I ";~' C(,tlt I + , l , i " t  t{ll.O!
)l}i+tl-s,,rl 1,17, 3t),i h .
.a l  j a i l  56  t i t+C l )y  133177 p l l .
, )D  ( )vcy lc l , , i v th l l~  55 37:  +,, , v , .
r , .
r , ,wd ,+d 12N I)t)S i-(*lllt :l\[ fac i l i t  3 52 9o910 S ignat t t ro  Torms o f  Tup ic  151  Ovorcrowdod Pr i sons"I'I I~I al I l  -21,,~11\f - , I t .
l~t l  c , ,u l~ <, l t t , .
l  -I.
', :),;11C, , l l l p \ ]y  c+,ll~('lll ,\]+'c\[+++" 3,5 12L+l,.kali+ i'i)iI i,\[~' +h, ' l l \ [ \ [  \[15 121~,11  i,) t l ; ,nk  :;.5 L21j , )o t l ; l l l k  IH ) l i5  :~.
',.1'21pl l~C, l l , ' r  c+)l l : l l~ la i l  :~5 12191: i f , .
\ ] ) l l~t ) l l  i21) l l l t l~ ~N t).l\[\]t put  pl is+, l l  .2t~ :t-IIc+~uuly  jaiL ~l ; l l , .
2 t~31 lh,,hl l,~e~l ja i l  2d  :l I ITop ic  10  S ig l ln t t l re  Tern ls  o f  Top ic  257  - ( l igar~t t~ Co| l s l l l ) l | ) t lo | ll :n i<r tun  21ogX I+i ~.rarll -- 2 / , , f / .
\  'i r i4~am - 21, ,~Ac lgrt l , .
I t?+ .171; \[}:iN ~tlb:xt'c+) LIt( \ ] l l~l l~ ~il 7)iN I ,h i l ip  I I l , ) l l i+ t j l  2.~ ~DSIl ( )ht lcc~) : l l ; l  017  hn  t - lg / l l , - l l t -  t ;7 t2}I I r ) l \ ] i l I l a l l s  beDs~, l l  h<.(\[~f.
211 ~)t~\[ls I I IOk i l l~  28.t  19~ ph i l ip  t l l ( , l \ [ i~  5t  ()7;~ \[1111~ L'ikll('e\[ d '+\ [ l l l l  22 21. t~n l~,ke  15913.1  clarxl<'t1, :  %, 'at  t80 .
t5  q t t  iri l ln cl l~ '.2'1 I ISI ,~ lh l l l a l l?
156.
)375 to lh l l l l l l l~  i t l Y , ' l I l a t l t ) l lgk l  -t.t .13.1 qt l  q t t  f i~ ln  21 - I lS, ,~ha  I .
tS 372  tobac?
, )  elll()k.~ 112){}I  bll  b\[i bl l  20  22t is ,~i la 12)i .121 ~il pat r i ck  t0 .
t55  c+)l lst l l l l l} l lo l l  bn  c lgar , .
l te  2022dIlltll 113 ~+1~) c l~at+' l l~"  c~l l lpa l lV  :ID \[$1)D ~\[t+gtt a l l l .
r \ [ iCtt l l  ~llI,lk?
'(}llt 20226al l l , )k( ' l  10.1 I i0  ('el l l  l l l a lk+' l  36223 \[ l l l l~ Ca l l t 'e \ [  ht:gl\[ I  2(~ 22{ib\[~t 79 .90:1  ?~IN illt+ll+il++t :1t;.22:1 i l l a \ [ay~ia l l  +illk~\[tl>,ll+e t'4)l l lpi l l IV 2( I .22t \ ]Top ic  I0 S ignatur .
"I'~r)ns of Top ic  258 -- Co)nputor  Secur i tyI ~llial /lilt "2Ionia I t  i+/,r al l l  21,QIX "I'1 i~ratn  --21o9, X(:+lll l l)l ltOr 115!~ :151 C4, l l lp I l l l ' t  ae l ' t l l l l y  213331 )e l  I l t t /p l l \ [~i() l l  \ ] l th t )h l t ( l l y  \ [~  ~5.tv i rus  927.G7-1 ~\[ ; idt lgt l , "  s l t l \ [ t l ' l l l  17~ 5NN I l lh . '
l l  I lilt) 9R 85, thacker  867 .377 FOl l lp t l t , ' t  +yS le l l l  1 -16.32~ C,+ltl++\]l I l l l iVet~il~,'  ~ lad l l \ [ t le  7}) IJNIin,) l  rl+ +i+;+~ 2i13'.! )
l , .~+-arch c,+ulte\[  l ; i2  .l I :i l awte l l c l "  b , ' rk , '  *'j~ lal l , ) l  al+,l  ,,.
79.0N \[c , , rn , ' l l  3P+5 6+4 c , : ,ml ,u t , ' r  wrus  12~k033 I~+,++, je t  p tO l , t l L+ io t+ 79 .0~1un lv+' l?
i ty  31)5 .95~ corne l i  U lX iVe le i ty  1(1~4 7-t l  U l ; iV ,q+i )y  ~; radu lx t , .
+tx ldt .
lll 79U~1+ysl+' l l l  290 .3"17  Iltl(:l,P;ll %t++npl)ll 107 .283 lawt l l l e ,+ l i v+: r tn ( .
te  I igt l i () l lal  i\]\[) l\[I;~I / tb , .
ra lL : ) ly  2N7 521 in i l i ta ry  t ' ( , l l lp , l l .
: r  106 .522 l iv~qll l ,) l?"
i lu) i ,maL  lubora lo ry  {59195\ [ab  225 .51) ;  v i tu~ plo~t<' l l l l  1U6 522 c,) l l lp l l I (~r S ,~CUl i ly  eXpet l  66 .19GmecLa ly  128 .515 %vesl ~et l l l a l l  82  2 \ [0  ~ecu\ [ i t?
, '  cenl{~\[  13ethesda  -19423Top ic  10  S ignature  Ter lns  o f  Top ic  271  So lar  PowerI ' l l i g ta ln  - -21oqX t i ig t  ~ltn --2logX "I'r i ~;r hi l l  - -21o!~Aso la r  -1S- l .315 e,~la~ e l te t l4y  2{Di 521 d iv i~ i ,m Inu l l ip l ,~  acress  31 3-17) t lazd i t  :10Pt 0IY) s<,lal l , t lw , ' t  9,1 210  n l , )b i l , :  l , , l , -ph , ,n , .
#c iv ic , ,  313 .17le,) 271; .932  ( 'h r i~t ia l l  a id  8 f i .211  b l i l l sh  It .cl l l l i l l l )R}' g \ [ , , l l p  23510it JtLi It l l l  2.5N.71):"+ l++,a S3'Sl,*III 711 5:{5 el l l I} l  he iNht  llXile 23+5111pax+lh , ,n  2133 81 I ill++tlllt.
Ie i t ' j ) l l l ) l le  (115;l+i I'illllllCilll I lack i l l+;  I l Jd l l l l l l  22i+51(1i)(~tltld 12 / ,121  i t i , l i un l  p l , , j , .
c l  112.697 ~l,~l lal  In r )h i l ,  + sa l , ' l l i te  23  511Jt , lw~r  12G.35:1 lei l i  <+, , ,d -  61.~111 ha l ld l le ld  IIled~il," t , ' l eph , , l l , :  '23510\ [ , , , , k , ,u t  125 .ll3t; scie.
l lc, ,  pa lk  ~'>.1 NS{) i l l ( ,h i le  ~ate l l l l .
,  .
v>tetn  23  510i i l \ [ l l l i lSRl  1O9728 ~()llkl t ' i l l l t ' l ' l l t l i l I l , l  51t ~5{} I l l l l t l l lvl i l l  i g id i l ln l  I> l , l j ec t  23 ,510hc ,ydsh , t l  7N :173 l)p s l l la l  ?+1 ; /17  act iv t -  s+,la\[ *ys tern  15673Tattle 2: Top 10 signat.m'e t.erm.~; of mfigram, bigram, and trigram for fore" TREe  t.opics.6.1 Comparing Summary ExtractionEffectiveness Using Topic Signatures+TFII)t",  and Bas(,line Algor i thmsIn orde)" I() (~vahla(.
(~ the (d\[+:ct.iv(,im.~s nf l(>l)i(: .~dgna-l;lll'(~S llS(~(\] ill SlllllIIN/l'y (~Xtl'it(:t;iOll, W{,  ~ CtIllll)~ll'(~ +flit!Sllltllll~tl'y StHII~011('CS ex(~ract,(~d 1)y the tol) ic si~Ilil\[lll'0,module+, basulin(.'
module, and tfidf lnothll(~s with lm-nta'n annot,  at(~(l lllo(lo,\] Sllllllll}ll'ios.
\VC III(+~}/SIlI'(+ + l;h(;l)c'rfl)rmanc(~' using a c()ml)ined umasure of l'n'call (I~)and pr(~cisi(m (P), F. F-score is defined by:I " - -  (1 +H'2)I'l?
where/3-'P + I~t )2 \7 . )
,.f'~rlnfVln~\,,# of  .sc,tcncc.~ c:rtratcd th,t  olsoatqwar in.
tim model ,s.mn)?lr!l# of  sc+lt(!ncc,s i11 tim nlo,h:l .~um.tav!l# of  ,s('./Itclwcs c:rlv?lclcd t)1,t ll*c .Sll.Slclnrclatic'c iml,ortancc of  l~ aml 1:'(6)(7)\Ve as.~um(~ (,(lual importance of re(:all iIIld preci-sion aim set H to 1 in our (+,Xl)('+rimtml;s. The Imselitm(I)ositi(m) module scores ('at:h S(!llt(':llC{} hy its I)osi-ti(>n in the text.
The first sent(race gets the high-esc s(:ortL the last S(HIt(H1Co the lowest.
The l)as(~liIl(~method is eXlmCted to lm ('.f\[ectiv(~ for news gem'e.The tfidf module assigns a score t.o a tt++rllI ti at:cord-ing to the product; of its flequc, ncy within a dot:-lllll(Hlt .j ( t f i j )  and its illV(~I'S(} doctmmnt  t?equoncy(idfi lo.q ,~).
N is the total mmfl)or of document.sin the (:()rlms and dfj is the, numl)er of (Io(:HnloAll;.q(:OlH:nining te rm ti.The topic sigjlla(.lll(++ module sciliis each ,q(~llt;(H1C(~:assigning to ('ach word that occurs in a topic signa-(ure thu weigh(, of that, keyword in t.hc' tol)ic signa-tltl'tL Eit{'h s(++llt(,+ItC(~ Ill(ill l'(:c(:ive.q a top ic  s ignaturescore equal to tlm total of all signature word scores it(:Olllailis, normalizc'd 1) 3' the.
highest sentence score.This s(:ol( 3 indical.es l;h(~ l'(!l(wall(:(~ of l.h(; S(!llt.t~n(:(!
tot, lw sigmmlre topic.SU.~\[.MAt/IST In'oduced (!xttat:ts of tlm samul(~xI.q sui)aralely for each ,,lodul0, for a s(~l'i(,s of ex-tracts ranging from ()cX; to 100% of the.
original l;(}xI.Althottgh many rel<want docttments are avaita})l+,for each t01>ic, Ollly SOlll0 o\[ \[h0111 htlv(~ allSWOl kc!y499markut)s. The mnnber of documents with answerkeys are listed in the row labeled: "# of RelevantDoes Used in Training".
To ensure we utilize allthe available data and conduct a sound evaluation,we perform a three-fold (:ross validation.
We re-serve one-third of documents as test set, use the restas training set, and ret)eat three times with non-overlapl)ing test set.
Furthernmre, we use only uni-gram topic signatures fin" evaluation.The result is shown in Figure 2 and TaMe 3.
Wefind that the topic signature method outperformsthe other two methods and the tfidfmethod performspoorly.
Among 40 possibh,, test points fl)r four topicswith 10% SUmlnary length increment (0% means se-lect at least one sentence) as shown in Table 3, thetopic signature method beats the baseline method34 times.
This result is really encouraging and in-dicates that the topic signature method is a worthyaddition to a variety of text summarization methods.6.2 Enriching Topic Signatures UsingExisting OntologiesWe have shown in the previous sections that topicsignatures can be used to al)I)roximate topic iden-tification at the lexieal level.
Although the au-tomatically acquired signature terms for a specifictopic seem to 1)e bound by unknown relationships asshown in Table 2, it is hard to image how we canenrich the inherent fiat structure of tol)ie signaturesas defined in Equation 1 to a construct as complexas a MUC template or script.As discussed in (Agirre et al, 2000), we proposeusing an existing ontology such as SENSUS (Knightand Luk, 1994) to identify signature term relations.The external hierarchical framework can be used togeneralize topic signatures and suggest richer rep-resentations for topic signatures.
Automated entityrecognizers can be used to (:lassify unknown enti-ties into their appropriate SENSUS concept nodes.We are also investigating other approaches to attto-matieally learn signature term relations.
The ideamentioned in this paper is just a starting point.
'7 Conc lus ionIn this paI)er we l)resented a t)rocedure to automati-(:ally acquire topic signatures and valuated the eflk~c-tiveness of applying tol)i(: signatures to extract ot)i(:relevant senten(:es against two other methods.
Thetot)ie signature method outt)erforms the baseline andthe tfidfmethods for all test topics.
Topic signaturescan not only recognize related terms (topic identifi-(:ation), but grout) related terms togetlmr under onetarget concept (topic interpretation).
'IbI)i(: identi-fication and interpretation are two essential steps ina typical automated text summarization system aswe l)resent in Section 3.
'\]))pic: signatures (:an also been vie.wed as an in-verse process of query expansion.
Query expansionintends to alleviate the word mismatch ln'oblenl ininfornmtion retrieval, since documents are normallywritten in different vocabulary, ttow to atttomati-(ally identify highly e(nrelated terms and use themto improve information retrieval performance hasbeen a main research issue since late 19611's.
Re-cent advances in the query expansion (Xu and Croft,1996) can also shed some light on the creation oftopic signatures.
Although we focus the ltse of topicsignatures to aid text summarization i this paper,we plan to explore the possibility of applying topicsignatures to perform query expansion in the future.The results reported are encouraging enough toallow us to contimm with topic signatures as the ve-hMe for a first approximation to worht knowledge.We are now busy creating a large nmnber of signa-ture.s to overcome the world knowledge acquisitionproblem and use them in topic interpretation.8 AcknowledgementsYVe thank the anonymous reviewers for very use-tiff suggestions.
This work is supported in part byDARPA contract N66001-97-9538.ReferencesEneko .~girre, Olatz Ansa, Edum'd Hovy, and DavidMartinez.
2000.
Enriching very large ontologiesusing the www.
In Proceedings of the Work,,;hopon Ontology Construction of the European Con-fl:rencc of AI (ECAI).Kenneth Church and Patrick Hanks.
1990.
Word as-sociation IIOrlllS, mutual information and lexicog-raphy.
In Proceedings of the 28th Annual Meetingof the Association for Computational Lingui.vtic.~"(,4CL-90), pages 76~-83.Thomas Cover and Joy A. Thomas.
1991.
Elcment.~of Information Theory..John Wiley & Sons.Gerald DeJong.
1982.
An overview of the FRUMPsystem.
In ~2mdy G. Lehnert and Martin H.Ringle, editors, Strategies for natural languageprocessing, pages 149-76.
Lawrence Erlbaum A.s-so(lares.Ted Dunning.
1993.
A~i:eurate methods for thestatistics of surprise and coincidence.
Computa-tional Li'nguistics, 19:61--7'4.Marti Itearst.
1997.
TextTiling: Segmenting textinto nmlti-l)aragraph subtopic passages.
Compu-tational Linguistics, 23:33-64.Eduard Hovy and Chin-Yew Lin.
1999.
Automatedtext summarization i SUMMAIRIST.
In Inder-jeer Mani and Mark T. Maybury, editors, Ad-vances in Automatic 71xxt Summarization, chap-ter 8, pages 81 94.
MIT Press.Kevin Knight and Steve K. Luk.
1994.
Building alarge knowledge base for machine translation, htProceedings of the Eleventh National Coy@re'neeon Arti\]icial Intelligence (AAAI-9/~).500-~  ..~:,., .
;~ ,5. "
' - -=-"  _..  _ .
.&ass0 50000 n ~ .~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
n ~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
~ .
.
.
.
.
.
.
.
.
.- - ' - .
, ,q ,~  .
.
.
.
+ +.
,x.  o + ~ ?.
.
.
.
.
1,* '+  .~  *+-  .
.
.
.
- -.
.
; -5; , :~:;  .
.
.
.
h ~.
:~.7~.~ ~ ~ ^' - -~- .
.. .
.
.
.
.
.
.
, ?
- -g2  .
.
.
.
.
.
.
.
.
.
o 400OO f , ' " +- ~-" + ~ -, "~2x-+,\[ ?
.
.
.
.
: .
.
.
.
.
.
.
:\[ - ...... ; ""7 ........ 2,=_~ 0 =0000 j '  +J" J j  1" ".,::i'ff "4.
4 "A- .
I  - i+ ~.
:4" .,~t .
-a  + -a--  -#.
- .
-~-- - .a  ~ ' .0 ~o00o 'd-;9~7~ -7 '+ 5~:7~:=-+': ; :  ~ .
.
.
.
=-~++:7:: ~ -:'~ +--~ ....... " ~5_~Ztt::~:ll;: ; iI " , ; .
A ' / , -?~-  <F" ~. "
"~" ~ 25744" ?o ;oo~ ._~-.c_-__~ /0 00000I000 005 010 015 020 025 030 ,335 040 045 050 055 060 065 070 o75 050 085 090 095 ~00.~ umrn~i-~ LenqthFigure 2:  F-measur(: w;.
summary length for all fimr topics.
~bi)ic signature cl(mrly outperforin tfidf andbaselin(', ex(:ei)t for tit(: case of topic 258 where t)(~rforman(:(; for tim thr(;e methods are roughly equal.I__ I - - - - - -~~g-  lO% I ___~o~a -ao~~a--- -  4o~ I ~0%- - \ [  ~o~ \[ ~,o~ ~o% I 9o~ I lOO% I\[ ~.+,_~.,~dl .... i .
.
:ms o.a-~9 I o..~.o o.aa4 o .
,~:c -  I ...ao=, \[ '__2 :~r'  I~  o.ara oar , ;  I .
.a t , ,  I e.a.~w-I+4.58 +7.48 +15.6a +14.17 +8.66 +3.
I 51_ top lc .
s i~  I -2 ,7d  -2 .19- -\[ 257-h , , * , , l i  .... r--- (1.1-}98 {~.15.__.5 I c,,, ,,.is., ".
'~L I o.,~~--F--,~.~,, I - -o  t,l o.1~, I ?.
!s~\[ '_,.~r_,a,,r \[ -55.11- -38.56 I -'".5U ~">' ~".0'; ' ' " '+ '  I S '~: ' '  I ~ ~ " " "  I +r  0 '~t  .
.
.
.
.
,257_,~i,ic.~ig +45.5~ +64.06 +31.88 ~ +20.40 \[ +20.60 \[ 4_-~01 +12.4&- I14 .24  - O.
(h.~\]\[_ 25u_h~,~.,li .
.
.
.
L_  o l  tk_ o 270 I "'4'-'2 ~' *'~:~ I ,, ~,r_, L_  "47t_ J  .4 r , ,  1 - - ~ - ' 1  o.~,'__,+~ o s'_,Z._J\[ 271_l,aseli .
.
.
.
I <,at tT_.._,~.
:,,~; T--,Ta77--- ..a:~ _L ,, :s:,r, .L .... ~~~~:~- i~-  T -  o.ae~ \] , ) .
:~:~~\[--~.
.
.
.
.
.
.
+a~.
lO  j _ _  + 4 ~ _ ~ ~ s .
r o .
~  +~.a,~ I +~.~o_ l l  0.,~, \]Table 3: F..measul'e t)erformanc(~ differen(:e compared to 1)aselin(~ nt(:thod in t)ercentage.
Cohmms indicateat diffe.rent summary lengths related to fldl length docum(mts.
Values in the 1)aselin(,.
rows are F-measures(:ores.
Vahms in the tfidf and tot)i(: signatur(~ rows arc i)('.rformmlc(~ increase or (h,.crease divide(l by their(:orr(.,sI)ontling baseline scores and shown in I)er(:(mtag(!.Inderje(?t Mani, David House, Gary KMn, Lyn(~tt(~ttirschman, Leo ()brst, Thdr6se Firmin, Micha(dChrzanowski, and Beth Sundheim.
1998.The T IPSTER SUMMAC t~xl smmnm'iza-tion evaluation final r(:t)ort.
%~(:hnical I/,ol)orl;MTR98W0000138, The MITRE Corporation.Christopher Manning and Hinrich Schiitzc.
1999.t'}mdatious of Statistical Natural Language Pro~cessi'ng.
MIT Press .Kathh~(m M(:K(!own and l)rag(mfir R. I ladev.
1999.
( 'TO.
I I (  ra t ,  i l l g  S l l l l l l l l ; l l ' i ( : s  o f  I l t l l l t ,  i \ [ ) l \ [~  l l ( !~vs  articles.In hMtu.iet~t Mani and Mark T. Maybury, edit,ors, Admm.ces i'n Automatic Text Sv,.mmarization,chapter 24, pagc+s 381 :/89.
MiT Press.Ellen Riloff and Jeffrey Lorenzen.
1999.
Ext:raction-t)a:;e,d text cateI,dorization: Generating donmin-qmcitic role relationships atttonmtically.
InTomek Strzalkowski, editor, Natural Language In-formation, Retrieval.
Kluwer Academic Publishc, r.q.Ellen tlilolf.
1996.
An ompirical study of automateddictionary construction for information extractionin three domains.
Artificial Intelligence ,Journal,85, August.SAIC.
1998.
Introduction to information extraction.http://www.mu(:.sai(:.
(:om.Jinxi Xu and W. Bruc(!
Croft.
1996.
Query ex-pal>ion using local and gh)bal document analysis.In l'rocee.dings of the 17th Annual Inter'nationalA(JM SIGIR Co't@rence.
on Research and Devel-opment in Information l{et'rieval, pages 4 -11.50 I
