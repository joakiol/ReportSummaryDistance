Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 152?160,Beijing, August 2010Exploiting Background Knowledge for Relation ExtractionYee Seng Chan and Dan RothUniversity of Illinois at Urbana-Champaign{chanys,danr}@illinois.eduAbstractRelation extraction is the task of recog-nizing semantic relations among entities.Given a particular sentence supervised ap-proaches to Relation Extraction employedfeature or kernel functions which usu-ally have a single sentence in their scope.The overall aim of this paper is to pro-pose methods for using knowledge and re-sources that are external to the target sen-tence, as a way to improve relation ex-traction.
We demonstrate this by exploit-ing background knowledge such as rela-tionships among the target relations, aswell as by considering how target rela-tions relate to some existing knowledgeresources.
Our methods are general andwe suggest that some of them could be ap-plied to other NLP tasks.1 IntroductionRelation extraction (RE) is the task of detectingand characterizing semantic relations expressedbetween entities in text.
For instance, given thesentence ?Cone, a Kansas City native, was origi-nally signed by the Royals and broke into the ma-jors with the team.
?, one of the relations we mightwant to extract is the employment relation betweenthe pair of entity mentions ?Cone?
and ?Royals?.RE is important for many NLP applications suchas building an ontology of entities, biomedical in-formation extraction, and question answering.Prior work have employed diverse approachestowards resolving the task.
One approach is tobuild supervised RE systems using sentences an-notated with entity mentions and predefined targetrelations.
When given a new sentence, the RE sys-tem has to detect and disambiguate the presence ofany predefined relations that might exist betweeneach of the mention pairs in the sentence.
In build-ing these systems, researchers used a wide varietyof features (Kambhatla, 2004; Zhou et al, 2005;Jiang and Zhai, 2007).
Some of the common fea-tures used to analyze the target sentence includethe words appearing in the sentence, their part-of-speech (POS) tags, the syntactic parse of the sen-tence, and the dependency path between the pairof mentions.
In a related line of work, researchershave also proposed various kernel functions basedon different structured representations (e.g.
de-pendency or syntactic tree parses) of the targetsentences (Bunescu and Mooney, 2005; Zhou etal., 2007; Zelenko et al, 2003; Zhang et al,2006).
Additionally, researchers have tried to au-tomatically extract examples for supervised learn-ing from resources such as Wikipedia (Weld et al,2008) and databases (Mintz et al, 2009), or at-tempted open information extraction (IE) (Bankoet al, 2007) to extract all possible relations.In this work, we focus on supervised RE.
Inprior work, the feature and kernel functions em-ployed are usually restricted to being defined onthe various representations (e.g.
lexical or struc-tural) of the target sentences.
However, in recog-nizing relations, humans are not thus constrainedand rely on an abundance of implicit world knowl-edge or background information.
What quantifiesas world or background knowledge is rarely ex-plored in the RE literature and we do not attemptto provide complete nor precise definitions in thispaper.
However, we show that by considering therelationship between our relations of interest, as152well as how they relate to some existing knowl-edge resources, we improve the performance ofRE.
Specifically, the contributions of this paperare the following:?
When our relations of interest are clusteredor organized in a hierarchical ontology, weshow how to use this information to improveperformance.
By defining appropriate con-straints between the predictions of relationsat different levels of the hierarchy, we obtainglobally coherent predictions as well as im-proved performance.?
Coreference is a generic relationship thatmight exists among entity mentions and weshow how to exploit this information by as-suming that co-referring mentions have noother interesting relations.
We capture thisintuition by using coreference information toconstraint the predictions of a RE system.?
When characterizing the relationship be-tween a pair of mentions, one can use alarge encyclopedia such as Wikipedia to in-fer more knowledge about the two mentions.In this work, after probabilistically map-ping mentions to their respective Wikipediapages, we check whether the mentions arerelated.
Another generic relationship thatmight exists between a pair of mentions iswhether they have a parent-child relation andwe use this as additional information.?
The sparsity of features (especially lexicalfeatures) is a common problem for super-vised systems.
In this work, we show thatone can make fruitful use of unlabeled data,by using word clusters automatically gath-ered from unlabeled texts as a way of gen-eralizing the lexical features.?
We combine the various relational predic-tions and background knowledge through aglobal inference procedure, which we for-malize via an Integer Linear Programming(ILP) framework as a constraint optimizationproblem (Roth and Yih, 2007).
This allowsus to easily incorporate various constraintsthat encode the background knowledge.Roth and Yih (2004) develop a relation extrac-tion approach that exploits constraints among en-tity types and the relations allowed among them.We extend this view significantly, within a simi-lar computational framework, to exploit relationsamong target relations, background informationand world knowledge, as a way to improve rela-tion extraction and make globally coherent predic-tions.In the rest of this paper, we first describe thefeatures used in our basic RE system in Section 2.We then describe how we make use of backgroundknowledge in Section 3.
In Section 4, we showour experimental results and perform analysis inSection 5.
In Section 6, we discuss related work,before concluding in Section 7.2 Relation Extraction SystemIn this section, we describe the features used inour basic relation extraction (RE) system.
Givena pair of mentions m1 and m2 occurring withinthe same sentence, the system predicts whetherany of the predefined relation holds between thetwo mentions.
Since relations are usually asym-metric in nature, hence in all of our experi-ments, unless otherwise stated, we distinguish be-tween the argument ordering of the two mentions.For instance, we consider m1:emp-org:m2 andm2:emp-org:m1 to be distinct relation types.Most of the features used in our system arebased on the work in (Zhou et al, 2005).
In thispaper, we propose some new collocation featuresinspired by word sense disambiguation (WSD).We give an overview of the features in Table 1.Due to space limitations, we only describe the col-location features and refer the reader to (Zhou etal., 2005) for the rest of the features.2.1 Collocation FeaturesFollowing (Zhou et al, 2005), we use a singleword to represent the head word of a mention.Since single words might be ambiguous or poly-semous, we incorporate local collocation featureswhich were found to be very useful for WSD.Given the head word hwm of a mention m, thecollocation feature Ci,j refers to the sequence oftokens in the immediate context of hwm.
The off-sets i and j denote the position (relative to hwm)153Category FeatureLexical hw of m1hw of m2hw of m1, m2BOW in m1BOW in m2single word between m1, m2BOW in between m1, m2bigrams in between m1, m2first word in between m1, m2last word in between m1, m2Collocations C?1,?1, C+1,+1C?2,?1, C?1,+1, C+1,+2Structural m1-in-m2m2-in-m1#mentions between m1, m2any word between m1, m2M-lvl M-lvl of m1, m2and m1, m2 E-maintypeE-type m1, m2 E-subtypem1, m2 M-lvl and E-maintypem1, m2 M-lvl and E-subtypem1, m2 E-subtype and m1-in-m2m1, m2 E-subtype and m2-in-m1Dependency path between m1, m2bag-of dep labels between m1, m2hw of m1 and dep-parenthw of m2 and dep-parentTable 1: Features in the basic RE system.
Theabbreviations are as follows.
hw: head word, M-lvl: mention level, E-type: entity type, dep-parent:the word?s parent in the dependency tree.of the first and last token of the sequence respec-tively.
For instance, C?1,+1 denotes a sequence ofthree tokens, consisting of the single token on theimmediate left of hwm, the token hwm itself, andthe single token on the immediate right of hwm.For each mention, we extract 5 features: C?1,?1,C+1,+1, C?2,?1, C?1,+1, and C+1,+2.3 Using Background KnowledgeNow we describe how we inject additional knowl-edge into our relation extraction system.3.1 Hierarchy of RelationsWhen our relations of interest are arranged in ahierarchical structure, one should leverage this in-formation to learn more accurate relation predic-tors.
For instance, assume that our relations arearranged in a two-level hierarchy and we learntwo classifiers, one for disambiguating betweenthe first level coarse-grained relations, and an-other for disambiguating between the second levelfine-grained relations.Since there are a lot more fine-grained relationtypes than coarse-grained relation types, we pro-pose using the coarse-grained predictions whichshould intuitively be more reliable, to improve thefine-grained predictions.
We show how to achievethis through defining appropriate constraints be-tween the coarse-grained and fine-grained rela-tions, which can be enforced through the Con-strained Conditional Models framework (aka ILP)(Roth and Yih, 2007; Chang et al, 2008).
Dueto space limitations, we refer interested readersto the papers for more information on the CCMframework.By doing this, not only are the predictions ofboth classifiers coherent with each other (thus ob-taining better predictions from both classifiers),but more importantly, we are effectively using the(more reliable) predictions of the coarse-grainedclassifier to constrain the predictions of the fine-grained classifier.
To the best of our knowledge,this approach for RE is novel.In this paper, we work on the NIST AutomaticContent Extraction (ACE) 2004 corpus.
ACE de-fines several coarse-grained relations such as em-ployment/membership, geo-political entity (GPE)affiliation, etc.
Each coarse-grained relation isfurther refined into several fine-grained relations1and each fine-grained relation has a unique par-ent coarse-grained relation.
For instance, the fine-grained relations employed as ordinary staff, em-ployed as an executive, etc.
are children relationsof employment/membership.Let mi and mj denote a pair of mentions i andj drawn from a document containing N mentions.Let Ri,j denote a relation between mi and mj , andlet R = {Ri,j}, where 1?i, j?N ; i 6=j denote theset of relations in the document.
Also, we denotethe set of predefined coarse-grained relation typesand fine-grained relation types as LRc and LRfrespectively.
Since there could possibly be no re-lation between a mention pair, we add the null la-bel to LRc and LRf , allowing our classifiers topredict null for Ri,j .
Finally, for a fine-grained re-lation type rf , let V(rf) denote its parent coarse-grained relation type.1With the exception of the Discourse coarse-grained re-lation.154We learn two classifiers, one for disambiguat-ing between the coarse-grained relations and onefor disambiguating between the fine-grained rela-tions.
Let ?c and ?f denote the feature weightslearned for predicting coarse-grained and fine-grained relations respectively.
Let pR(rc) =logPc(rc|mi,mj ; ?c) be the log probability thatrelation R is predicted to be of coarse-grainedrelation type rc.
Similarly, let pR(rf) =logPf (rf |mi,mj ; ?f ) be the log probability thatrelation R is predicted to be of fine-grained re-lation type rf .
Let x?R,rc?
be a binary variablewhich takes on the value of 1 if relation R is la-beled with the coarse-grained label rc.
Similarly,let y?R,rf?
be a binary variable which takes on thevalue of 1 if relation R is labeled with the fine-grained label rf .
Our objective function is then:max?R?R?rc?LRcpR(rc) ?
x?R,rc?+?R?R?rf?LRfpR(rf) ?
y?R,rf?
(1)subject to the following constraints:?rc?LRcx?R,rc?
= 1 ?R ?
R (2)?rf?LRfy?R,rf?
= 1 ?R ?
R (3)x?R,rc?
?
{0, 1} ?R ?
R, rc ?
LRc (4)y?R,rf?
?
{0, 1} ?R ?
R, rf ?
LRf (5)Equations (2) and (3) require that each relationcan only be assigned one coarse-grained label andone fine-grained label.
Equations (4) and (5) indi-cate that x?R,rc?
and y?R,rf?
are binary variables.Two more constraints follow:x?R,rc?
??
{rf?LRf |V(rf)=rc}y?R,rf?
?R ?
R , rc ?
LRc (6)y?R,rf?
?
x?R,V(rf)?
?R ?
R, rf ?
LRf (7)The logical form of Equation (6) can be writtenas: x?R,rc?
?
y?R,rf1?
?
y?R,rf2?
.
.
.
?
y?R,rfn?,where rf1, rf2, .
.
.
, rfn are (child) fine-grainedrelations of the coarse-grained relation rc.
Thisstates that if we assign rc to relation R, then wemust also assign to R a fine-grained relation rfart: Ei ?
{gpe, org, per},Ej ?
{fac, gpe, veh, wea}emp-org: Ei ?
{gpe, org, per},Ej ?
{gpe, org, per}gpe-aff: Ei ?
{gpe, org, per},Ej ?
{gpe, loc}other-aff: Ei ?
{gpe, org, per},Ej ?
{gpe, loc}per-soc: Ei ?
{per}, Ej ?
{per}Table 2: Entity type constraints.which is a child of rc.
The logical form of Equa-tion (7) can be written as: y?R,rf?
?
x?R,V(rf)?.This captures the inverse relation and states thatif we assign rf to R, then we must also assign toR the relation type V(rf), which is the parent ofrf .
Together, Equations (6) and (7) constrain thepredictions of the coarse-grained and fine-grainedclassifiers to be coherent with each other.
Finally,we note that one could automatically translate log-ical constraints into linear inequalities (Chang etal., 2008).This method is general and is applicable toother NLP tasks where a hierarchy exists, suchas WSD and question answering.
For instance,in WSD, one can predict coarse-grained and fine-grained senses using suitably defined sense inven-tories and then perform inference via ILP to obtaincoherent predictions.3.2 Entity Type ConstraintsEach mention in ACE-2004 is annotated with oneof seven coarse-grained entity types: person (per),organization (org), location (loc), geo-political en-tity (gpe), facility (fac), vehicle (veh), and weapon(wea).Roth and Yih (2007) had shown that entity typeinformation is useful for constraining the possiblelabels that a relation R can assume.
For instance,both mentions involved in a personal/social re-lation must be of entity type per.
In this work,we gather such information from the ACE-2004documentation and inject it as constraints (on thecoarse-grained relations) into our system.
Dueto space limitations, we do not state the con-straint equations or objective function here, butwe list the entity type constraints we imposed foreach coarse-grained relation mi-R-mj in Table15522, where Ei (Ej) denotes the allowed set of en-tity types for mention mi (mj).
Applying the en-tity type information improves the predictions ofthe coarse-grained classifier and this in turn couldimprove the predictions of the fine-grained classi-fier.3.3 Using Coreference InformationWe can also utilize the coreference relationsamong entity mentions.
Assuming that we knowmentions mi and mj are coreferent with eachother, then there should be no relation betweenthem3.
Let z?i,j?
be a binary variable which takeson the value of 1 if mentions mi and mj are coref-erent, and 0 if they are not.
When z?i,j?=1, we cap-ture the above intuition with the following con-straints:z?i,j?
?
x?Ri,j ,null?
(8)z?i,j?
?
y?Ri,j ,null?
(9)which can be written in logical form as: z?i,j?
?x?Ri,j ,null?, and z?i,j?
?
y?Ri,j ,null?.
We add thefollowing to our objective function in Equation(1):?mi,mj?m2co?i,j?
?
z?i,j?+ c?o?i,j?
?
(1?
z?i,j?)
(10)where m is the set of mentions in a document,co?i,j?
and c?o?i,j?
are the log probabilities of pre-dicting that mi and mj are coreferent and notcoreferent respectively.
In this work, we assumewe are given coreference information, which isavailable from the ACE annotation.3.4 Using Knowledge from WikipediaWe propose two ways of using Wikipedia togather features for relation extraction.
Wikipediais a huge online encyclopedia and mainly containsarticles describing entities or concepts.The first intuition is that if we are able to cor-rectly map a pair of mentions mi and mj to theircorresponding Wikipedia article (assuming they2We do not impose entity type constraints on the coarse-grained relations disc and phys.3In this work, we assume that no relations are reflexive.After the experiments in this paper are performed, we ver-ified that in the ACE corpus we used, less than 1% of therelations are reflexive.are represented in Wikipedia), we could use thecontent on their Wikipedia pages to check whetherthey are related.In this work, we use a Wiki system (Rati-nov et al, 2010) which performs context-sensitivemapping of mentions to Wikipedia pages.
Intheir work, the authors first identify phrases ormentions that could be mapped.
The correctWikipedia article for each mention is then prob-abilistically predicted using a combination of fea-tures based on Wikipedia hyperlink structure, se-mantic coherence, etc.
The authors?
own evalua-tion results indicate that the performance of theirsystem ranges from 70?80%.
When given a pairof mentions and the system returns the Wikipediapage for either one of the mentions, we introducea feature:w1(mi,mj) =??
?1, if Ami(mj)or Amj (mi)0, otherwisewhere Ami(mj) returns true if the head extentof mj is found (via simple string matching) inthe predicted Wikipedia article of mi.
The in-terpretation of Amj (mi) is similar.
We introducea new feature into the RE system by combiningw1(mi,mj) with mi,mj E-maintype (defined asin Table 1).The second feature based on Wikipedia is asfollows.
It will be useful to check whether thereis any parent-child relationship between two men-tions.
Intuitively, this will be useful for recogniz-ing several relations such as physical part-whole(e.g.
a city is part of a state), subsidiary (a com-pany is a child-company of another), citizenship(a person is a citizen of a country), etc.Given a pair of mentions mi and mj , we use aParent-Child system (Do and Roth, 2010) to pre-dict whether they have a parent-child relation.
Toachieve this, the system first gathers all Wikipediaarticles that are related to mi and mj .
It then usesthe words in these pages and the category ontol-ogy of Wikipedia to make its parent-child predic-tions, while respecting certain defined constraints.In this work, we use its prediction as follows:w2(mi,mj) ={1, if parent-child(mi,mj)0, otherwise156Figure 1: An example of Brown word cluster hi-erarchy from (Koo et al, 2008).where we combine w2(mi,mj) with mi,mj E-maintype, introducing this as a new feature intoour RE system.3.5 Using Word ClustersAn inherent problem faced by supervised systemsis that of data sparseness.
To mitigate such is-sues in the lexical features, we use word clusterswhich are automatically generated from unlabeledtexts.
In this work, we use the Brown clusteringalgorithm (Brown et al, 1992), which has beenshown to improve performance in various NLPapplications such as dependency parsing (Koo etal., 2008), named entity recognition (Ratinov andRoth, 2009), and relation extraction (Boschee etal., 2005).
The algorithm performs a hierarchicalclustering of the words and represents them as abinary tree.Each word is uniquely identified by its pathfrom the root and every path is represented witha bit string.
Figure 1 shows an example clusteringwhere the maximum path length is 3.
By usingpath prefixes of different lengths, one can obtainclusterings at different granularity.
For instance,using prefixes of length 2 will put apple and pearinto the same cluster, Apple and IBM into the samecluster, etc.
In our work, we use clusters gener-ated from New York Times text and simply use apath prefix of length 10.
When Brown clusters areused in our system, all lexical features consistingof single words will be duplicated.
For instance,for the feature hw of m1, one new feature which isthe length-10 bit string path representing the orig-inal lexical head word of m1, will be introducedand presented to the classifier as a string feature.4 ExperimentsWe used the ACE-2004 dataset (catalogLDC2005T09 from the Linguistic Data Con-sortium) to conduct our experiments.
ACE-2004defines 7 coarse-grained relations and 23 fine-grained relations.
In all of our experiments,unless otherwise stated, we explicitly model theargument order (of the mentions) when askedto disambiguate the relation between a pair ofmentions.
Hence, we built our coarse-grainedclassifier with 15 relation labels to disambiguatebetween (two for each coarse-grained relationtype and a null label when the two mentions arenot related).
Likewise, our fine-grained classifierhas to disambiguate between 47 relation labels.In the dataset, relations do not cross sentenceboundaries.For our experiments, we trained regularized av-eraged perceptrons (Freund and Schapire, 1999),implemented within the Sparse Network of Win-now framework (Carlson et al, 1999), one for pre-dicting the coarse-grained relations and anotherfor predicting the fine-grained relations.
Since thedataset has no split of training, development, andtest sets, we followed prior work (Jiang and Zhai,2007) and performed 5-fold cross validation to ob-tain our performance results.
For simplicity, weused 5 rounds of training and a regularization pa-rameter of 1.5 for the perceptrons in all our exper-iments.
Finally, we concentrate on the evaluationof fine-grained relations.4.1 Performance of the Basic RE systemAs a gauge on the performance of our basic rela-tion extraction system BasicRE using only the fea-tures described in Section 2, we compare againstthe state-of-the-art feature-based RE system ofJiang and Zhai (2007).
However, we note that inthat work, the authors performed their evaluationusing undirected coarse-grained relations.
That is,they do not distinguish on argument order of men-tions and the classifier has to decide among 8 re-lation labels (7 coarse-grained relation types and anull label).
Performing 5-fold cross validation onthe news wire (nwire) and broadcast news (bnews)corpora in the ACE-2004 dataset, they reported aF-measure of 71.5 using a maximum entropy clas-sifier4.
Evaluating BasicRE on the same setting,4After they heuristically performed feature selection andapplied the heuristics giving the best evaluation performance,they obtained a result of 72.9.157All nwire 10% of nwireFeatures Rec% Pre% F1% Rec% Pre% F1%BasicRE 49.9 51.0 50.5 33.2 29.0 31.0+Hier +1.3 +1.3 +1.3 +1.1 +1.2 +1.1+Hier+relEntC +1.5 +2.0 +1.8 +3.3 +3.5 +3.4+Coref ?
+1.4 +0.7 ?0.1 +1.0 +0.5+Wiki +0.2 +1.9 +1.0 +1.5 +2.5 +2.0+Cluster ?0.2 +3.2 +1.4 ?0.7 +3.9 +1.7+ALL +1.5 +6.7 +3.9 +4.7 +10.2 +7.6Table 3: BasicRE gives the performance of our basic RE system on predicting fine-grained relations,obtained by performing 5-fold cross validation on only the news wire corpus of ACE-2004.
Each sub-sequent row +Hier, +Hier+relEntC, +Coref, +Wiki, and +Cluster gives the individual contributionfrom using each knowledge.
The bottom row +ALL gives the performance improvements from adding+Hier+relEntC+Coref+Wiki+Cluster.
?
indicates no change in score.we obtained a competitive F-measure of 71.25.4.2 Experimental Settings for EvaluatingFine-grained RelationsTwo of our knowledge sources, the Wiki systemdescribed in Section 3.4 and the word clusters de-scribed in Section 3.5, assume inputs of mixed-cased text.
We note that the bnews corpus ofACE-2004 is entirely in lower-cased text.
Hence,we use only the nwire corpus for our experimentshere, from which we gathered 28,943 relation in-stances and 2,226 of those have a valid (non-null)relation6.We also propose the following experimentalsetting.
First, since we made use of coreferenceinformation, we made sure that while performingour experiments, all instances from the same doc-ument are either all used as training data or allused as test data.
Prior work in RE had not en-sured this, but we argue that this provides a morerealistic setting.
Our own experiments indicatethat this results in a 1-2% lower performance onfine-grained relations.Secondly, prior work calculate their perfor-mance on relation extraction at the level of men-tions.
That is, each mention pair extracted isscored individually.
An issue with this way ofscoring on the ACE corpus is that ACE annota-5Using 10 rounds of training and a regularization param-eter of 2.5 improves the result to 72.2.
In general, we foundthat more rounds of training and a higher regularization valuebenefits coarse-grained relation classification, but not fine-grained relation classification.6The number of relation instances in the nwire and bnewscorpora are about the same.tors rarely duplicate a relation link for coreferentmentions.
For instance, assume that mentions mi,mj , and mk exist in a given sentence, mentionsmi and mj are coreferent, and the annotator es-tablishes a particular relation type r between mjand mk.
The annotator will not usually duplicatethe same relation r between mi and mk and thusthe label between these two mentions is then null.We are not suggesting that this is an incorrect ap-proach, but clearly there is an issue since an im-portant goal of performing RE is to populate orbuild an ontology of entities and establish the re-lations existing among the entities.
Thus, we eval-uate our performance at the entity-level.7 That is,given a pair of entities, we establish the set of re-lation types existing between them, based on theirmention annotations.
Then we calculate recalland precision based on these established relations.Of course, performing such an evaluation requiresknowledge about the coreference relations and inthis work, we assume we are given this informa-tion.4.3 Knowledge-Enriched SystemEvaluating our system BasicRE (trained only onthe features described in Section 2) on the nwirecorpus, we obtained a F1 score of 50.5, as shownin Table 3.
Next, we exploited the relation hier-archy as in Section 3.1 and obtained an improve-ment of 1.3, as shown in the row +Hier.
Next,we added the entity type constraints of Section7Our experiments indicate that performing the usual eval-uation on mentions gives similar performance figures and thetrend in Table 3 stays the same.1583.2.
Remember that these constraints are imposedon the coarse-grained relations.
Thus, they wouldonly affect the fine-grained relation predictions ifwe also exploit the relation hierarchy.
In the ta-ble, we show that all the background knowledgehelped to improve performance, providing a to-tal improvement of 3.9 to our basic RE system.Though the focus of this work is on fine-grainedrelations, our approach also improves the perfor-mance of coarse-grained relation predictions.
Ba-sicRE obtains a F1 score of 65.3 on coarse-grainedrelations and exploiting background knowledgegives a total improvement of 2.9.5 AnalysisWe explore the situation where we have very littletraining data.
We assume during each cross val-idation fold, we are given only 10% of the train-ing data we originally had.
Previously, when per-forming 5-fold cross validation on 2,226 valid re-lation instances, we had about 1780 as traininginstances in each fold.
Now, we assume we areonly given about 178 training instances in eachfold.
Under this condition, BasicRE gives a F1score of 31.0 on fine-grained relations.
Adding allthe background knowledge gives an improvementof 7.6 and this represents an error reduction of39% when measured against the performance dif-ference of 50.5 (31.0) when we have 1780 train-ing instances vs. 178 training instances.
Onthe coarse-grained relations, BasicRE gives a F1score of 51.1 and exploiting background knowl-edge gives a total improvement of 5.0.We also tabulated the list of fine-grained re-lations that improved by more than 1 F1 scorewhen we incorporated +Wiki, on the experimentusing all of nwire data: phys:near (physicallynear), other-aff:ideology (ideology affiliation),art:user-or-owner (user or owner of artifact), per-soc:business (business relationship), phys:part-whole (physical part-whole), emp-org:subsidiary(organization subsidiary), and gpe-aff:citizen-or-resident (citizen or resident).
Most of these intu-itively seemed to be information one would findbeing mentioned in an encyclopedia.6 Related WorkFew prior work has explored using backgroundknowledge to improve relation extraction perfor-mance.
Zhou et al (2008) took advantage ofthe hierarchical ontology of relations by propos-ing methods customized for the perceptron learn-ing algorithm and support vector machines.
Incontrast, we propose a generic way of using therelation hierarchy which at the same time, givesglobally coherent predictions and allows for easyinjection of knowledge as constraints.
Recently,Jiang (2009) proposed using features which arecommon across all relations.
Her method is com-plementary to our approach, as she does not con-sider information such as the relatedness betweendifferent relations.
On using semantic resources,Zhou et al (2005) gathered two gazettes, onecontaining country names and another containingwords indicating personal relationships.
In relat-ing the tasks of RE and coreference resolution, Jiet al (2005) used the output of a RE system torescore coreference hypotheses.
In our work, wereverse the setting and explore using coreferenceto improve RE.7 ConclusionIn this paper, we proposed a broad range of meth-ods to inject background knowledge into a rela-tion extraction system.
Some of these methods,such as exploiting the relation hierarchy, are gen-eral in nature and could be easily applied to otherNLP tasks.
To combine the various relation pre-dictions and knowledge, we perform global infer-ence within an ILP framework.
Besides allowingfor easy injection of knowledge as constraints, thisensures globally coherent models and predictions.Acknowledgements This research was partlysponsored by Air Force Research Laboratory(AFRL) under prime contract no.
FA8750-09-C-0181.
We thank Ming-Wei Chang and JamesClarke for discussions on this research.ReferencesBanko, Michele, Michael J. Cafarella, Stephen Soder-land, Matthew Broadhead, and Oren Etzioni.
2007.159Open information extraction from the web.
In Pro-ceedings of IJCAI-07, pages 2670?2676.Boschee, Elizabeth, Ralph Weischedel, and Alex Za-manian.
2005.
Automatic information extraction.In Proceedings of the International Conference onIntelligence Analysis.Brown, Peter F., Vincent J. Della Pietra, Peter V. deS-ouza, Jenifer C. Lai, and Robert L. Mercer.
1992.Class-based n-gram models of natural language.Computational Linguistics, 18(4):467?479.Bunescu, Razvan C. and Raymond J. Mooney.
2005.A shortest path dependency kernel for relation ex-traction.
In Proceedings of HLT/EMNLP-05, pages724?731.Carlson, Andrew J., Chad M. Cumby, Jeff L. Rosen,and Dan Roth.
1999.
The SNoW learning archi-tecture.
Technical Report UIUCDCS-R-99-2101,UIUC Computer Science Department, May.Chang, Ming-Wei, Lev Ratinov, Nicholas Rizzolo, andDan Roth.
2008.
Learning and inference with con-straints.
In Proceedings of AAAI-08, pages 1513?1518.Do, Quang and Dan Roth.
2010.
On-the-fly constraint-based taxonomic relation identifica-tion.
Technical report, University of Illinois.http://L2R.cs.uiuc.edu/?danr/Papers/DoRo10.pdf.Freund, Yoav and Robert E. Schapire.
1999.
Largemargin classification using the perceptron algo-rithm.
Machine Learning, 37(3):277?296.Ji, Heng, David Westbrook, and Ralph Grishman.2005.
Using semantic relations to refine corefer-ence decisions.
In Proceedings of HLT/EMNLP-05,pages 17?24.Jiang, Jing and ChengXiang Zhai.
2007.
A system-atic exploration of the feature space for relation ex-traction.
In Proceedings of HLT-NAACL-07, pages113?120.Jiang, Jing.
2009.
Multi-task transfer learning forweakly-supervised relation extraction.
In Proceed-ings of ACL-IJCNLP-09, pages 1012?1020.Kambhatla, Nanda.
2004.
Combining lexical, syntac-tic, and semantic features with maximum entropymodels for information extraction.
In Proceedingsof ACL-04, pages 178?181.Koo, Terry, Xavier Carreras, and Michael Collins.2008.
Simple semi-supervised dependency parsing.In Proceedings of ACL-08:HLT, pages 595?603.Mintz, Mike, Steven Bills, Rion Snow, and Daniel Ju-rafsky.
2009.
Distant supervision for relation ex-traction without labeled data.
In Proceedings ofACL-IJCNLP-09, pages 1003?1011.Ratinov, Lev and Dan Roth.
2009.
Design challengesand misconceptions in named entity recognition.
InProceedings of CoNLL-09, pages 147?155.Ratinov, Lev, Doug Downey, and DanRoth.
2010.
Wikification for informa-tion retrieval.
Technical report, Univer-sity of Illinois.
http://L2R.cs.uiuc.edu/?danr/Papers/RatinovDoRo10.pdf.Roth, Dan and Wen Tau Yih.
2004.
A linear program-ming formulation for global inference in natural lan-guage tasks.
In Proceedings of CoNLL-04, pages1?8.Roth, Dan and Wen Tau Yih.
2007.
Global infer-ence for entity and relation identification via a lin-ear programming formulation.
In Getoor, Lise andBen Taskar, editors, Introduction to Statistical Rela-tional Learning.
MIT Press.Weld, Daniel S., Raphael Hoffman, and Fei Wu.
2008.Using wikipedia to bootstrap open information ex-traction.
ACM SIGMOD Special Issue on ManagingInformation Extraction, 37(4):62?68.Zelenko, Dmitry, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relation ex-traction.
Journal of Machine Learning Research,3:1083?1106.Zhang, Min, Jie Zhang, Jian Su, and GuoDong Zhou.2006.
A composite kernel to extract relations be-tween entities with both flat and structured features.In Proceedings of COLING-ACL-06, pages 825?832.Zhou, Guodong, Jian Su, Jie Zhang, and Min Zhang.2005.
Exploring various knowledge in relation ex-traction.
In Proceedings of ACL-05.Zhou, GuoDong, Min Zhang, DongHong Ji, andQiaoMing Zhu.
2007.
Tree kernel-based re-lation extraction with context-sensitive structuredparse tree information.
In Proceedings of EMNLP-CoNLL-07, pages 728?736.Zhou, Guodong, Min Zhang, Dong-Hong Ji, andQiaoming Zhu.
2008.
Hierarchical learning strat-egy in semantic relation extraction.
InformationProcessing & Management, 44(3):1008?1021.160
