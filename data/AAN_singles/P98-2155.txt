Constituent-based Accent PredictionChristine H. NakataniAT&T Labs - Research180 Park Avenue, Florham Park NJ 07932-097 I, USAemail: chn @ research.att.comAbstractNear-perfect automatic accent assignment is at-tainable for citation-style speech, but better com-putational models are needed to predict accentin extended, spontaneous discourses.
This paperpresents an empirically motivated theory of the dis-course focusing nature of accent in spontaneousspeech.
Hypotheses based on this theory lead to anew approach to accent prediction, in which pat-terns of deviation from citation form accentuation,defined at the constituent or noun phrase level,are atttomatically earned from an annotated cor-pus.
Machine learning experiments on 1031 nounphrases from eighteen spontaneous direction-givingmonologues how that accent assignment can besignificantly improved by up to 4%-6% relative toa hypothetical baseline system that wotdd produceonly citation-form accentuation, giving error ratereductions of 11%-25%.1 IntroductionIn speech synthesis systems, near-perfect (98%) ac-cent assignment is automatically attainable for read-aloud, citation-style speech (Hirschberg, 1993).
Butfor unrestricted, extended spontaneous discourses,highly natural accentuation is often achieved onlyby costly human post-editing.
A better understand-ing of the effects of discourse context on accentualvariation is needed not only to fully model this fun-damental prosodic feature for text-to-speech (TTS)synthesis systems, but also to further the integrationof prosody into speech understanding and concept-to-speech (CTS) synthesis ystems at the appropri-ate level of linguistic representation.This paper presents an empirically motivated the-ory of the discourse focusing function of accent.The theory describes for the first time the interactingcontributions to accent prediction made by factorsrelated to the local and global attentional status ofdiscourse referents in a discourse model (Grosz andSidner, 1986).
The ability of the focusing featuresto predict accent for a blind test corpus is examinedusing machine learning.
Because attentional statusis a property of referring expressions, a novel ap-proach to accent prediction is proposed to allow forthe integration of word-based and constituent-basedlinguistic features in the models to be learned.The task of accent assignment is redefined asthe prediction of patterns of deviation from citationform accentuation.
Crucially, these deviations arecaptured at the constituent level.
This task redefi-nition has two novel properties: (1) it bootstraps di-rectly on knowledge about citation form or so-called"context-independent" prosody embodied in currentTTS technology; and (2) the abstraction from wordto constituent allows for the natural integration offocusing features into the prediction methods.Results of the constituent-based accent predictionexperiments show that for two speakers from a cor-pus of spontaneous direction-giving monologues,accent assignment can be improved by up to 4%-6%relative to a hypothetical baseline system that wouldproduce only citation-form accentuation, giving er-ror rate reductions of 11%-25%.2 Accent and attentionMuch theoretical work on intonational meaning hasfocused on the association of accent with NEW in-formation, and lack of accent with GIVEN informa-tion, where given and new are defined with respectto whether or not the information is already repre-sented in a discourse model.
While this associationreflects a general tendency (Brown, 1983), empir-ical studies on longer discourses have shown thissimple dichotomy cannot explain important sub-classes of expressions, uch as accented pronouns,cf.
(Terken, 1984; Hirschberg, 1993).We propose a new theory of the relationship be-tween accent and attention, based on an enrichedtaxonomy of given/new information status providedby both the LOCAL (centering) and GLOBAL (fo-cus stack model) attentional state models in Groszand Sidner's discourse modeling theory (1986).939Analysis of a 20-minute spontaneous story-tellingmonologue t identified separate but interacting con-tributions of grammatical function, form of refer-ring expression and accentuation 2 in conveying theattentional status of a discourse referent.
These in-teractions can be formally expressed in the frame-work of attentional modeling by the following prin-ciples of interpretation:?
The LEXICAL FORM OF A REFERRING EXPRES-SION indicates the level of attentional processing,i.e., pronouns involve local focusing while full lex-ical forms involve global focusing (Grosz et al,1995).?
The GRAMMATICAL FUNCTION of a referring ex-pression reflects the local attentional status of thereferent, i.e., subject position generally holds thehighest ranking member of the forward-lookingcenters list (Cf list), while direct object holds thenext highest ranking member of the Cf list (Groszet al, 1995; Kameyama, 1985).?
The ACCENTING of a referring expression servesas an inference cue to shift attention to a newbackward-looking center (Cb), or to mark theglobal (re)introduction f a referent; LACK OF AC-CENT serves as an inference cue to maintain atten-tional focus on the Cb, Cf list members or globalreferents (Nakatani, 1997).The third principle concerning accent interpreta-tion defines for the first time how accent serves uni-formly to shift attention and lack of accent serves tomaintain attention, at either the local or global levelof discourse structure.
This principle describing thediscourse focusing functions of accent directly ex-plains 86.5% (173/200) of the referring expressionsin the spontaneous narrative, as shown in Table 1.
Ifperformance factors (e.g.
repairs, interruptions) andspecial discourse situations (e.g.
direct quotations)are also considered accounted for, then coverage in-creases to 96.5% (193/200).3 Constituent-based experimentsTo test the generality of the proposed account of ac-cent and attention, the ability of local and global fo-cusing features to predict accent for a blind corpusis examined using machine learning.
To rigorouslyassess the potential gains to be had from these at-tentional features, we consider them in combinationwith lexical and syntactic features identified in theliterature as strong predictors of accentuation (AI-tenberg, 1987; Hirschberg, 1993; Ross et al, 1992).The narrative was collected by Virginia Merlini.~Accented expressions are identified by the presence ofPITCH ACCENT (Pierrehumbert, 1980).SUBJECT PRONOUNS (N=I 11)25 prominent 23%16 shift in Cb6 contrast3 emphasis86 nonprominent 77%75 continue or resume Cb3 repair2 dialogue tag1 interruption from interviewer5 unaccounted forDIRECT OBJECT PRONOUNS (N=I5)1 prominent 7%1 contrast14 nonprominent 93%10 maintain on-Cb in Cf list3 inter-sentential anaphora1 repairSUBJECT EXPLICIT FORMS (N=54)49 prominent 91%44 introduce new global ref as Cp2 quoted context1 repair2 unaccounted fornonprominent 9%2 top-level global focus1 quoted contextl repair1 interruption from interviewerDIRECT OBJECT EXPLICIT FORMS (N=20)11 prominent 55%11 introduce new global referent9 nonprominent 45%7 maintain ref in global focus2 quoted contextTable 1: Coverage of narrative data.
The discoursefocusing functions of accent appear in italics.Previous studies, nonetheless, were aimed at pre-dicting word accentuation, and so the features weborrow are being tested for the first time in learningthe abstract accentuation patterns of syntactic on-stituents, specifically noun phrases (NPs).3.1 MethodsAccent prediction models are learned from a cor-pus of unrestricted, spontaneous direction-givingmonologues from the Boston Directions Corpus(Nakatani et al, 1995).
Eighteen spontaneousdirection-giving monologues are analyzed from twoAmerican English speakers, H1 (male) and H3 (fe-male).
The monologues range from 43 to 631 wordsin length, and comprise 1031 referring expressionsmade up of 2020 words.
Minimal, non-recursive940Accent class TTS-assigned accenting Actual accentingcitation a LITTLE SHOPPING AREA a LITTLE SHOPPING AREAwe wesuprareducedonea PRETTY nice AMBIANCEthe GREEN LINE SUBWAYYET ANOTHER RIGHT TURNONEa PRETTY NICE AMBIANCEthe GREEN Line SUBWAYyet ANOTHER RIGHT TURNshift a VERY FAST FIVE MINUTE lunch a VERY FAST FIVE minute LUNCHTable 3: Examples of citation-based accent classes.
Accented words appear in boldface.NP constituents, referred to as BASENPs, are au-tomatically identified using Collins' (1996) lexicaldependency parser.
In the following complex NP,baseNPs appear in square brackets: \[the brownstoneapartment building\] on \[the corner\] of\[Beacon andMass Ave\].
BaseNPs are semi-automatically la-beled for lexical, syntactic, local focus and globalfocus features.
Table 2 provides summary corpusstatistics.
A rule-based machine learning program,Corpus measuretotal no.
of wordsbaseNPswords in baseNPs% words in baseNPsH1 H32359 1616621 4101203 81751.0% 50.6%Total39751031202050.8%Table 2: Word and baseNP corpus measures.Ripper (Cohen, 1995), is used to acquire accentclassification systems from a training corpus of cor-rectly classified examples, each defined by a vectorof feature values, or predictors.
33.2 Citation-based Accent ClassificationThe accentuation of baseNPs is coded according tothe relationship of the actual accenting (i.e.
ac-cented versus unaccented) on the words in thebaseNP to the accenting predicted by a TTS systemthat received each sentence in the corpus in isola-tion.
The actual accenting is determined by prosodiclabeling using the ToBI standard (Pitrelli et al,1994).
Word accent predictions are produced by theBell Laboratories NewTTS system (Sproat, 1997).NewTTS incorporates complex nominal accentingrules (Sproat, 1994) as well as general, word-basedaccenting rules (Hirschberg, 1993).
It is assumedZRipper is similar to CART (Breiman et al, 1984), but itdirectly produces IF-THEN logic rules instead of decision treesand also utilizes incremental error eduction techniques incom-bination with novel rule optimization strategies.for the purposes of this study that NewTTS gener-ally assigns citation-style accentuation when passedsentences in isolation.For each baseNP, one of the following four ac-centing patterns is assigned:?
CITATION FORM: exact match between actual and"ITS-assigned word accenting.?
SUPRA: one or more accented words are predictedunaccented by TFS; otherwise, "ITS predictionsmatch actual accenting.?
REDUCED: one or more unaccented words are pre-dicted accented by TTS; otherwise, "FrS predic-tions match actual accenting.?
SHIFT: at least one accented word is predicted un-accented by "ITS, and at least one unaccented wordis predicted accented by "ITS.Examples from the Boston Directions Corpus foreach accent class appear in Table 3.Table 4 gives the breakdown of coded baseNPs byaccent class.
In contrast to read-aloud citation-styleAccentclassH3 baseNPsN %H1 baseNPsN %citation 471 75.8% 247 60.2%supra 73 11.8%.
68 16.6%reduced 68 11.9% 83 20.2%shift 9 1.4% 12 2.9%total 621 100% 410 100%Table 4: Accent class distribution for all baseNPs.speech, in these unrestricted, spontaneous mono-logues, 30% of referring expressions do not bearcitation form accentuation.
The citation form ac-cent percentages serve as the baseline for the accentprediction experiments; correct classification ratesabove 75.8% and 60.2% for H1 and H3 respectivelywould represent performance above and beyond the941state-of-the-art citation form accentuation models,gained by direct modeling of cases of supra, reducedor shifted constituent-based accentuation.3.3 Predictors3.3.1 Lexical featuresThe use of set features, which are handled by Rip-per, extends lexical word features to the constituentlevel.
Two set-valued features, BROAD CLASS SE-QUENCE and LEMMA SEQUENCE, represent lexicalinformation.
These features consist of an orderedlist of the broad class part-of-speech (POS) tags orword lemmas for the words making up the baseNP.For example, the lemma sequence for the NP, theHarvard Square T stop, is {the, Harvard, Square, T,stop}.
The corresponding broad class sequence is{determiner, noun, noun, noun, noun}.
Broad classtags are derived using Brill's (1995) part-of-speechtagger, and word lemma information is produced byNewTTS (Sproat, 1997).POS information is used to assign accenting innearly all speech synthesis ystems.
Initial word-based experiments on our corpus showed that broadclass categories performed slightly better than boththe function-content distinction and the POS tagsthemselves, giving 69%-81% correct word predic-tions (Nakatani, 1997).3.3.2 Syntactic constituency featuresThe CLAUSE TYPE feature represents global syn-tactic constituency information, while the BASENPTYPE feature represents local or NP-internal syntac-tic constituency information.
Four clause types arecoded: matrix, subordinate, predicate complementand relative.
Each baseNP is semi-automatically as-signed the clause type of the lowest level clause ornearest dominating clausal node in the parse tree,which contains the baseNP.
As for baseNP types,the baseNP type of baseNPs not dominated by anyNP node is SIMPLE-BASENP.
BaseNPs that occurin complex NPs (and are thus dominated by at leastone NP node) are labeled according to whether thebaseNP contains the head word for the dominatingNP.
Those that are dominated by only one NP nodeand contain the head word for the dominating NPare HEAD-BASENPS; all other NPs in a complex NPare CHILD-BASENPS.
Conjoined noun phrases in-volve additional categories of baseNPs that are col-lapsed into the CONJUNCT-BASENP category.
Ta-ble 5 gives the distributions of baseNP types.Focus projection theories of accent, e.g.
(Gussen-hoven, 1984; Selkirk, 1984), would predict a largebaseNP type H1%H3% N Nsimple 447 72.0% 280 68.3%head 61 9.8% 46 11.2%child 74 11.9% 65 15.9%conjunct 39 6.3% 19 4.5%total 621 100% 410 100%Table 5: Distribution of baseNP types for allbaseNPs.role for syntactic onstituency information in de-termining accent, especially for noun phrase con-stituents.
Empirical evidence for such a role, how-ever, has been weak (Altenberg, 1987).3.3.3 Local focusing featuresThe local attentional status of baseNPs is repre-sented by two features commonly used in centeringtheory to compute the Cb and the Cf list, GRAM-MATICAL FUNCTION and FORM OF EXPRESSION(Grosz et al, 1995).
Hand-labeled grammaticalfunctions include sttbject, direct object, indirect ob-ject, predicate complement, adfimct.
Form of ex-pression feature values are .adverbial noun, cardi-nal, definite NP, demonstrative NP, indefinite NP,pronoun, proper name, quantifier NP, verbal noun,etc.3.3.4 Global focus featureThe global focusing status of baseNPs is computedusing two sets of analyses: discourse segmenta-tions and coreference coding.
Expert discoursestructure analyses are used to derive CONSENSUSSEGMENTATIONS, consisting of discourse bound-aries whose coding all three labelers agreed upon(Hirschberg and Nakatani, 1996).
The consensuslabels for segment-initial boundaries provide a lin-ear segmentation of a discourse into discourse seg-ments.
Coreferential relations are coded by two la-belers using DTT (Discourse Tagging Tool) (Aoneand Bennett, 1995).
To compute coreference chains,only the relation of strict coference is used.
TwoNPs, npl and np2, are in a strict coreference rela-tionship, when np2 occurs after npl in the discourseand realizes the same discourse ntity that is real-ized by npl.
Reference chains are then automat-ically computed by linking noun phrases in strictcoference relations into the longest possible chains.Given a consensus linear segmentation a d refer-ence chains, global focusing status is determined.For each baseNP, if it does not occur in a refer-ence chain, and thus is realized only once in the dis-942course, it is assigned the SINGLE-MENTION focus-ing status.
The remaining statuses apply to baseNPsthat do occur in reference chains.
If a baseNP in achain is not previously mentioned in the discourse,it is assigned the FIRST-MENTION status.
If its mostrecent coreferring expression occurs in the currentsegment, the baseNP is in IMMEDIATE fOCUS; if itoccurs in the immediately previous segment, thebaseNP is in NEIGHBORING fOCUS; if it occurs inthe discourse but not in either the current or imme-diately previous segments, then the baseNP is as-signed STACK focus.4 Results4.1 Individual featuresExperimental results on individual features are re-ported in Table 4.1 in terms of the average per-cent correct classification and standard eviation.
4A trend emerges that lexical features (i.e.
wordExperiment H1 H3LexicalBroad cl seq 78.58 4- 1.30 59.51 4- 2.72Lemma seq 80.05 4- 1.85 62.93 + 2.68SyntacticbaseNP type 75.86 4- 2.52 60.24 4- 2.97Clause type 75.85 4- 1.14 60.24 4- 3.49Local focusGram fn 75.83 4- 1.93 62.68 4- 2.74Form ofexpr 78.104- 1.54 61.95 4- 1.89Global focusGlobal focus 75.85 4- 2.07Baseline 75.8 60.2Table 6: Average percentages correct classificationand standard eviations for individual feature xper-iments.lemma and broad class sequences, and form of ex-pression) enable the largest improvements in clas-sification, e.g.
2.7% and 2.3% for H1 using broadclass sequence and form of expression informationrespectively.
These results suggest that the abstractlevel of lexical description supplied by form of ex-pression does the equivalent work of the lower-levellexical features.
Thus, for CTS, accentuation classmight be predicted when the more abstract form ofexpression information is known, and need not be4Ripper experiments are conducted with 10-fold cross-validation.
Statistically significant differences in the perfor-mance of two systems are determined by using the Student'scurve approximation tocompute confidence intervals, follow-ing Litman (1996).
Significant results at p <.05 or strongerappear in italics.delayed until the tactical generation of the expres-sion is completed.
Conversely, for TTS, simple cor-pus analysis of lemma and POS sequences may per-form as well as higher-level lexical analysis.4.2 Combinations of classes of featuresExperiments on combinations of feature classes arereported in Table 7.ExperimentLocal/syntaxLocal/lexLocal/lex/syntaxLocal/globalLoc/glob/lex/synThe average classification rateHI77.61 4- 1.3978.74 4- 1.4879.06 4- 1.5378.11 4- 1.2879.22 4- 1.96H360.98 + 2.6063.17 4- 1.9061.95 4- 2.27mBaseline 75.8 60.2Table 7: Average percentages correct classifica-tion and standard eviations for combination exper-iments.of 63.17% for H3 on the local focus and lexical fea-ture class model, is the best obtained for all H3 ex-periments, increasing prediction accuracy by nearly3%.
The highest classification rate for H1 is 79.22%for the model including local and global focus, andlexical and syntactic feature classes, showing an im-provement of 3.4%.
These results, however, do notattain significance.4.3 Experiments on simple-baseNPsThree sets of experiments that showed strong per-formance gains are reported for the non-recursivesimple-baseNPs.
These are: (1) word lemma se-quence alone, (2) lemma and broad class sequencestogether, and (3) local focus and lexical featurescombined.
Table 8 shows the accent class distribu-tion for simple-baseNPs.AccentclassH1 simple-baseNPsN %H3 simple-baseNPsN %citation 334 74.7 167 59.6supra 62 13.9 47 16.8reduced 46 10.3 56 0.20shift 5 1.1 10 3.6total 447 100 280 100Table 8: Accent class distribution for simple-baseNPs.Results appear in Table 9.
For H3, the lemmasequence model delivers the best performance,65.71%, for a 4.3% improvement over the baseline.The best classification rate of 80.93% for H1 on thelocal focus and lexical feature model represents a6.23% gain over the baseline.
These figures repre-sent an 11% reduction in error rate for H3, and a94325% reduction in error rate for HI, and are statis-tically significant improvements over the baseline.Experiment HI H3Lemma seq 80.74 + 1.87 65.71 + 2.70Lemma, broad ci 80.80 + 1.41 62.14-4- 2.58Local/lexical 80.93-4- 1.35 63.21 -4- 1.78Baseline 74.7 59.6Table 9: Average percentages correct classificationand standard eviations for simple-baseNP experi-ments.In the rule sets learned by Ripper for the H1 lo-cal focus/lexical model, interactions of the differentfeatures in specific rules can be observed.
Two rulesets that performed with error rates of 13.6% and13.7% on different cross-validation runs are pre-sented in Figure 1.5 Inspection of the rule setsH1 local focus/lexical model rule set 1reduced :- form of expr=proper name, broad classseq --- det, lemma seq ,-~ Harvard.supra :- broad class seq --~ adverbial.supra :- gram ill=adjunct, lemma seq --, this.supra :- gram fn=adjunct, lemma seq --~ Cowper-waithe.supra :- lemma seq ,-- I.default citation.H1 local focus/lexical model rule set 2reduced:- broad class seq ,-, n, lemma seq ,-- the,lemma seq ,-- Square.supra :- form of expr=adverbial.supra :- gram fn=adjunct, lemma seq --, Cowper-waithe.supra :- lemma seq --~ this.supra :- lemma seq ,-~ I.default citation.Figure 1: Highest performing learned rule sets forH1, local focus/lexical model.reveals that there are few non-lexical rules learned.The exception seems to be the rule that adverbialnoun phrases belong to the supra accent class.
How-ever, new interactions of local focusing features(grammatical function and form of expression) withlexical information are discovered by Ripper.
It alsoappears that as suggested by earlier experiments,5In the rules themselves, written in Prolog-style notation,the tilde character is a two-place operator, X -,~ Y, signifyingthat Y is a member ofthe set-value for feature X.lexical features trade-off or one other as well aswith form of expression information.
In comparingthe first rules in each set, for example, the clausesbroad class seq ,,~ det and lemma seq ,~ the sub-stitute for one another.
However, in the first ruleset the less specific broad class constraint must becombined with another abstract constraint, form ofexpr=proper name, to achieve a similar descrip-tion of a rule for reduced accentuation  commonplace names, such as the Harvard Square T stop.5 Conc lus ionAccent prediction experiments on noun phrase con-stituents demonstrated that deviations from citationform accentuation (supra, reduced and shift classes)can be directly modeled.
Machine learning experi-ments using not only lexical and syntactic features,but also discourse focusing features identified bya new theory of accent interpretation i  discourse,showed that accent assignment can be improved byup to 4%-6% relative to a hypothetical baseline sys-tem that would produce only citation-form accen-tuation, giving error rate reductions of 11%-25%.In general, constituent-based accentuation is mostaccurately learned from lexical information readilyavailable in TTS systems.
For CTS systems, com-parable performance may be achieved using onlyhigher level attentional features.
There are severalother lessons to be learned, conceming individualspeaker, domain dependent and domain indepen-dent effects on accent modeling.First, it is perhaps counterintuitively harder topredict deviations from citation form accentuationfor speakers who exhibit a great deal of non-citation-style accenting behavior, such as speakerH3.
Accent prediction results for H1 exceeded thosefor H3, although about 15% more of H3's tokensexhibited non-citation form accentuation.
Findingthe appropriate parameters by which to describe theprosody of individual speakers i  an important goalthat can be advanced by using machine learningtechniques toexplore large spaces of hypotheses.Second, it is evident from the strong performanceof the word lemma sequence models that deviationsfrom citation-form accentuation may often be ex-pressed by lexicalized rules of some sort.
Lexical-ized rules in fact have proven useful in other areas ofnatural language statistical modeling, such as POStagging (Brill, 1995) and parsing (Collins, 1996).The specific lexicalized rules learned for many ofthe models would not have followed from any the-oretical or empirical proposals in the literature.
Itmay be that domain dependent training using au-944tomatic learning is the appropriate way to developpractical models of accenting patterns on differentcorpora.
And especially for different speakers in thesame domain, automatic learning methods eem tobe the only efficient way to capture perhaps idiolec-tical variation in accenting.Finally, it should be noted that notwithstandingindividual speaker and domain dependent effects,domain independent factors identified by the newtheory of accent and attention do contribute to ex-perimental performance.
The two local focusingfeatures, grammatical function and form of refer-ring expression, enable improvements above thecitation-form baseline, especially in combinationwith lexical information.
Global focusing informa-tion is of limited use by itself, but as may havebeen hypothesized, contributes to accent predictionin combination with local focus, lexical and syntac-tic features.AcknowledgmentsThis research was supported by a NSF Graduate Re-search Fellowship and NSF Grants Nos.
IRI-90-09018, IRI-93-08173 and CDA-94-01024 at Har-vard University.
The author is grateful to BarbaraGrosz, Julia Hirschberg and Stuart Shieber for valu-able discussion on this research; to Chinatsu Aone,Scott Bennett, Eric Brill, William Cohen, MichaelCollins, Giovanni Flammia, Diane Litman, BeckyPassonneau, Richard Sproat and Gregory Ward forsharing and discussing methods and tools; and toDiane Litman, Marilyn Walker and Steve Whittakerfor suggestions for improving this paper.ReferencesB.
Ahenberg.
1987.
Prosodic Patterns in Spoken En-glish: Studies in the Correlation Between Prosody andGrammar for Text-to-Speech Conversion.
Lund Uni-versity Press, Lund, Sweden.C.
Aone and S. W. Bennett.
1995.
Evaluating auto-mated and manual acquisition of anaphora resolutionstrategies.
In Proceedings of the 33rd Annual Meet-ing, Boston.
Association for Computational Linguis-tics.Leo Breiman, Jerome H. Friedman, Richard A. Olshen,and Charles J.
Stone.
1984.
Classification and Re-gression Trees.
Wadsworth and Brooks, Pacific GroveCA.Eric Brill.
1995.
Transformation-based error-drivenlearning and natural language processing: a case studyin part of speech tagging.
Computational Lingusitics.G.
Brown.
1983.
Prosodic structure and the Given/Newdistinction.
In A. Cutler and D. R. Ladd, editors,Prosody: Models and Measurements, pages 67-78.Springer-Verlag, Berlin.William A. Cohen.
1995.
Fast effective rule induction.In Proceedings of the Twelfth International Confer-ence on Machine Learning.Michael John Collins.
1996.
A new statistical parserbased on bigram lexical dependencies.
In Proceed-ings of the 34th Annual Meeting of the Association forComputational Linguistics.Barbara Grosz and Candaee Sidner.
1986.
Attention,intentions, and the structure of discourse.
Computa-tional Linguistics, 12(3): 175-204.Barbara J. Grosz, Aravind K. Joshi, and Scott Weinstein.1995.
Centering: a framework for modelling the lo-cal coherence of discourse.
Computational Linguis-tics, 21(2), June.Carlos Gussenhoven.
1984.
On the Grammar and Se-mantics of Sentence Accents.
Foris Publications, Dor-drecht.Julia Hirschberg and Christine Nakatani.
1996.
Aprosodic analysis of discourse segments in direction-giving monologues.
In Proceedings of the 34th An-nual Meeting of the ACL, Santa Cruz.
Association forComputational Linguistics.Julia Hirschberg.
1993.
Pitch accent in context: predict-ing intonational prominence from text.
Artificial In-telligence, 63(1-2):305-340.M.
Kameyama.
1985.
Zero anaphora: the case inJapanese.
Ph.D. thesis, Stanford University.Diane J. Litman.
1996.
Cue phrase classification usingmachine learning.
Journal of Artificial Intelligence,pages 53-94.Christine H. Nakatani, Barbara Grosz, and JuliaHirschberg.
1995.
Discourse structure in spoken lan-guage: studies on speech corpora.
In Proceedings ofthe AAA!
Spring Symposium on Empirical Methods inDiscourse Interpretation and Generation, Palo Alto,CA, March.
American Association for Artificial Intel-ligence.Christine H. Nakatani.
1997.
The Computational Pro-cessing of Intonational Prominence: a FunctionalProsody Perspective.
Ph.D. thesis, Harvard Univer-sity, Cambridge, MA, May.Janet Pierrehumbert.
1980.
The Phonology and Phonet-ics of English h~tonation.
Ph.D. thesis, MassachusettsInstitute of Technology, September.
Distributed bythe Indiana University Linguistics Club.John Pitrelli, Mary Beckman, and Julia Hirschberg.1994.
Evaluation of prosodic transcription labelingreliability in the ToBI framework.
In Proceedings ofthe 3rd International Conference on Spoken LanguageProcessing, volume 2, pages 123-126, Yokohama,Japan.K.
Ross, M. Ostendorf, and S. Shattuck-Hufnagel.
1992.Factors affecting pitch accent placement.
In Proceed-ings of the 2nd International Conference on SpokenLanguage Processing, pages 365-368, Banff, Canada,October.E.
Selkirk.
1984.
Phonology and Syntax.
MIT Press,Cambridge MA.Richard Sproat.
1994.
English noun-phrase accent pre-diction for text-to-speech.
Computer Speech andLan-guage, 8:79-94.Richard Sproat, editor.
1997.
Multilingual Text-to-Speech Synthesis: The Bell Labs Approach.
KluwerAcademic, Boston.J.
Terken.
1984.
The distribution of pitch accents in in-structions as a function of discourse structure.
Lan-guage and Speech, 27:269-289.945
