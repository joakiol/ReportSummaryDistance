Learning to Shift the Polarity of Words for Sentiment ClassificationDaisuke Ikeda?
Hiroya Takamura?
Lev-Arie Ratinov??
Manabu Okumura?
?Department of Computational Intelligence and Systems Science, Tokyo Institute of Technologyikeda@lr.pi.titech.ac.jp?
?Department of Computer Science, University of Illinois at Urbana-Champaignratinov2@uiuc.edu?Precision and Intelligence Laboratory, Tokyo Institute of Technology{takamura,oku}@pi.titech.ac.jpAbstractWe propose a machine learning basedmethod of sentiment classification of sen-tences using word-level polarity.
The polari-ties of words in a sentence are not always thesame as that of the sentence, because therecan be polarity-shifters such as negation ex-pressions.
The proposed method modelsthe polarity-shifters.
Our model can betrained in two different ways: word-wise andsentence-wise learning.
In sentence-wiselearning, the model can be trained so that theprediction of sentence polarities should beaccurate.
The model can also be combinedwith features used in previous work suchas bag-of-words and n-grams.
We empiri-cally show that our method almost alwaysimproves the performance of sentiment clas-sification of sentences especially when wehave only small amount of training data.1 IntroductionDue to the recent popularity of the internet, individ-uals have been able to provide various informationto the public easily and actively (e.g., by weblogsor online bulletin boards).
The information often in-cludes opinions or sentiments on a variety of thingssuch as new products.
A huge amount of work hasbeen devoted to analysis of the information, whichis called sentiment analysis.
The sentiment analysishas been done at different levels including words,sentences, and documents.
Among them, we focuson the sentiment classification of sentences, the taskto classify sentences into ?positive?
or ?negative?,because this task is fundamental and has a wide ap-plicability in sentiment analysis.
For example, wecan retrieve individuals?
opinions that are related toa product and can find whether they have the positiveattitude to the product.There has been much work on the identification ofsentiment polarity of words.
For instance, ?beauti-ful?
is positively oriented, while ?dirty?
is negativelyoriented.
We use the term sentiment words to referto those words that are listed in a predefined polar-ity dictionary.
Sentiment words are a basic resourcefor sentiment analysis and thus believed to have agreat potential for applications.
However, it is stillan open problem how we can effectively use sen-timent words to improve performance of sentimentclassification of sentences or documents.The simplest way for that purpose would be themajority voting by the number of positive words andthe number of negative words in the given sentence.However, the polarities of words in a sentence arenot always the same as that of the sentence, be-cause there can be polarity-shifters such as nega-tion expressions.
This inconsistency of word-levelpolarity and sentence-level polarity often causes er-rors in classification by the simple majority votingmethod.
A manual list of polarity-shifters, whichare the words that can shift the sentiment polarity ofanother word (e.g., negations), has been suggested.However, it has limitations due to the diversity ofexpressions.Therefore, we propose a machine learning basedmethod that models the polarity-shifters.
The modelcan be trained in two different ways: word-wise296and sentence-wise.
While the word-wise learn-ing focuses on the prediction of polarity shifts, thesentence-wise learning focuses more on the predic-tion of sentence polarities.
The model can also becombined with features used in previous work suchas bag-of-words, n-grams and dependency trees.
Weempirically show that our method almost always im-proves the performance of sentiment classificationof sentences especially when we have only smallamount of training data.The rest of the paper is organized as follows.
InSection 2, we briefly present the related work.
InSection 3, we discuss well-known methods that useword-level polarities and describe our motivation.
InSection 4, we describe our proposed model, how totrain the model, and how to classify sentences usingthe model.
We present our experiments and resultsin Section 5.
Finally in Section 6, we conclude ourwork and mention possible future work.2 Related WorkSupervised machine learning methods includingSupport Vector Machines (SVM) are often used insentiment analysis and shown to be very promising(Pang et al, 2002; Matsumoto et al, 2005; Kudo andMatsumoto, 2004; Mullen and Collier, 2004; Ga-mon, 2004).
One of the advantages of these meth-ods is that a wide variety of features such as depen-dency trees and sequences of words can easily be in-corporated (Matsumoto et al, 2005; Kudo and Mat-sumoto, 2004; Pang et al, 2002).
Our attempt in thispaper is not to use the information included in thosesubstructures of sentences, but to use the word-levelpolarities, which is a resource usually at hand.
Thusour work is an instantiation of the idea to use a re-source on one linguistic layer (e.g., word level) tothe analysis of another layer (sentence level).There have been some pieces of work which fo-cus on multiple levels in text.
Mao and Lebanon(2006) proposed a method that captures local senti-ment flow in documents using isotonic conditionalrandom fields.
Pang and Lee (2004) proposed toeliminate objective sentences before the sentimentclassification of documents.
McDonald et al (2007)proposed a model for classifying sentences and doc-uments simultaneously.
They experimented withjoint classification of subjectivity for sentence-level,and sentiment for document-level, and reported thattheir model obtained higher accuracy than the stan-dard document classification model.Although these pieces of work aim to predict notsentence-level but document-level sentiments, theirconcepts are similar to ours.
However, all the abovemethods require annotated corpora for all levels,such as both subjectivity for sentences and senti-ments for documents, which are fairly expensive toobtain.
Although we also focus on two different lay-ers, our method does not require such expensive la-beled data.
What we require is just sentence-levellabeled training data and a polarity dictionary of sen-timent words.3 Simple Voting by Sentiment WordsOne of the simplest ways to classify sentences us-ing word-level polarities would be a majority voting,where the occurrences of positive words and thoseof negative words in the given sentence are countedand compared with each other.
However, this major-ity voting method has several weaknesses.
First, themajority voting cannot take into account at all thephenomenon that the word-level polarity is not al-ways the same as the polarity of the sentence.
Con-sider the following example:I have not had any distortion problemswith this phone and am more pleased withthis phone than any I?ve used before.where negative words are underlined and positivewords are double-underlined.
The example sentencehas the positive polarity, though it locally containsnegative words.
The majority voting would misclas-sify it because of the two negative words.This kind of inconsistency between sentence-levelpolarity and word-level polarity often occurs andcauses errors in the majority voting.
The reasonis that the majority voting cannot take into ac-count negation expressions or adversative conjunc-tions, e.g., ?I have not had any ...?
in the exampleabove.
Therefore, taking such polarity-shifting intoaccount is important for classification of sentencesusing a polarity dictionary.
To circumvent this prob-lem, Kennedy and Inkpen (2006) and Hu and Liu(2004) proposed to use a manually-constructed listof polarity-shifters.
However, it has limitations dueto the diversity of expressions.297Another weakness of the majority voting is thatit cannot be easily combined with existing methodsthat use the n-gram model or tree structures of thesentence as features.
The method we propose herecan easily be combined with existing methods andshow better performance.4 Word-Level Polarity-Shifting ModelWe assume that when the polarity of a word is dif-ferent from the polarity of the sentence, the polarityof the word is shifted by its context to adapt to thepolarity of the sentence.
Capturing such polarity-shifts will improve the classification performance ofthe majority voting classifier as well as of more so-phisticated classifiers.In this paper, we propose a word polarity-shiftingmodel to capture such phenomena.
This model isa kind of binary classification model which deter-mines whether the polarity is shifted by its context.The model assigns a score sshift(x, S) to the senti-ment word x in the sentence S. If the polarity of xis shifted in S, sshift(x, S) > 0.
If the polarity of xis not shifted in S, sshift(x, S) ?
0.
Let w be a pa-rameter vector of the model and ?
be a pre-definedfeature function.
Function sshift is defined assshift(x, S) = w ?
?
(x, S).
(1)Since this model is a linear discriminative model,there are well-known algorithms to estimate the pa-rameters of the model.Usually, such models are trained with each occur-rence of words as one instance (word-wise learning).However, we can train our model more effectivelywith each sentence being one instance (sentence-wise learning).
In this section, we describe how totrain our model in two different ways and how toapply the model to a sentence classification.4.1 Word-wise LearningIn this learning method, we train the word-levelpolarity-shift model with each occurrence of sen-timent words being an instance.
Training exam-ples are automatically extracted by finding sentimentwords in labeled sentences.
In the example of Sec-tion 3, for instance, both negative words (?distor-tion?
or ?problems?)
and a positive word (?pleased?
)appear in a positive sentence.
We regard ?distortion?and ?problems?, whose polarities are different fromthat of the sentence, as belonging to the polarity-shifted class.
On the contrary, we regard ?pleased?,whose polarity is the same as that of the sentence, asnot belonging to polarity-shifted class.We can use the majority voting by those (possi-bly polarity-shifted) sentiment words.
Specifically,we first classify each sentiment word in the sentenceaccording to whether the polarity is shifted or not.Then we use the majority voting to determine thepolarity of the sentence.
If the first classifier classi-fies a positive word into the ?polarity-shifted?
class,we treat the word as a negative one.
We expect thatthe majority voting with polarity-shifting will out-perform the simple majority voting without polarity-shifting.
We actually use the weighted majority vot-ing, where the polarity-shifting score for each senti-ment word is used as the weight of the vote by theword.
We expect that the score works as a confi-dence measure.We can formulate this method as follows.
Here,N and P are respectively defined as the sets of neg-ative sentiment words and positive sentiment words.For instance, x ?
N means that x is a negative word.We also write x ?
S to express that the word x oc-curs in S.First, let us define two scores, scorep(S) andscoren(S), for the input sentence S. The scorep(S)and the scoren(S) respectively represent the num-ber of votes for S being positive and the numberof votes for S being negative.
If scorep(S) >scoren(S), we regard the sentence S as having thepositive polarity, otherwise negative.
We supposethat the following relations hold for the scores:scorep(S) =?x?P?S?sshift(x, S) +?x?N?Ssshift(x, S), (2)scoren(S) =?x?P?Ssshift(x, S) +?x?N?S?sshift(x, S).
(3)When either a polarity-unchanged positive word(sshift(x, S) ?
0) or a polarity-shifted negativeword occurs in the sentence S, scorep(S) increases.We can easily obtain the following relation betweentwo scores:scorep(S) = ?scoren(S).
(4)298Since, according to this relation, scorep(S) >scoren(S) is equivalent to scorep(S) > 0, we useonly scorep(S) for the rest of this paper.4.2 Sentence-wise LearningThe equation (2) can be rewritten asscorep(S) =?x?Ssshift(x, S)I(x)=?x?Sw ?
?
(x, S)I(x)= w ?{?x?S?
(x, S)I(x)}, (5)where I(x) is the function defined as follows:I(x) =????
?+1 if x ?
N ,?1 if x ?
P ,0 otherwise.
(6)This scorep(S) can also be seen as a linear discrimi-native model and the parameters of the model can beestimated directly (i.e., without carrying out word-wise learning).
Each labeled sentence in a corpuscan be used as a training instance for the model.In this method, the model is learned so that thepredictive ability for sentence classification is opti-mized, instead of the predictive ability for polarity-shifting.
Therefore, this model can remain indeci-sive on the classification of word instances that havelittle contextual evidence about whether polarity-shifting occurs or not.
The model can rely moreheavily on word instances that have much evidence.In contrast, the word-wise learning trains themodel with all the sentiment words appearing in acorpus.
It is assumed here that all the sentimentwords have relations with the sentence-level polar-ity, and that we can always find the evidence of thephenomena that the polarity of a word is differentfrom that of a sentence.
Obviously, this assump-tion is not always correct.
As a result, the word-wiselearning sometimes puts a large weight on a contextword that is irrelevant to the polarity-shifting.
Thismight degrade the performance of sentence classifi-cation as well as of polarity-shifting.4.3 Hybrid ModelBoth methods described in Sections 4.1 and 4.2are to predict the sentence-level polarity only withthe word-level polarity.
On the other hand, sev-eral methods that use another set of features, for ex-ample, bag-of-words, n-grams or dependency trees,were proposed for the sentence or document classi-fication tasks.
We propose to combine our methodwith existing methods.
We refer to it as hybridmodel.In recent work, discriminative models includingSVM are often used with many different features.These methods are generally represented asscore?p(X) = w?
?
??
(X), (7)where X indicates the target of classification, for ex-ample, a sentence or a document.
If score?p(X) > 0,X is classified into the target class.
??
(X) is a fea-ture function.
When the method uses the bag-of-words model, ??
maps X to a vector with each ele-ment corresponding to a word.Here, we define new score function scorecomb(S)as a linear combination of scorep(S), the scorefunction of our sentence-wise learning, andscore?p(S), the score function of an existingmethod.
Using this, we can write the function asscorecomb(S) = ?scorep(S) + (1 ?
?
)score?p(S)= ?
?x?Sw ?
?
(x, S)I(x) + (1 ?
?)w?
?
??
(S)= wcomb ????x?S?
(x, S)I(x), (1 ?
?)??(S)?.
(8)Note that ??
indicates the concatenation of two vec-tors, wcomb is defined as ?w, w??
and ?
is a param-eter which controls the influence of the word-levelpolarity-shifting model.
This model is also a dis-criminative model and we can estimate the param-eters with a variety of algorithms including SVMs.We can incorporate additional information like bag-of-words or dependency trees by ??
(S).4.4 Discussions on the Proposed ModelFeatures such as n-grams or dependency trees canalso capture some negations or polarity-shifters.
Forexample, although ?satisfy?
is positive, the bigrammodel will learn ?not satisfy?
as a feature corre-lated with negative polarity if it appears in the train-ing data.
However, the bigram model cannot gener-alize the learned knowledge to other features such299Table 1: Statistics of the corpuscustomer movie# of Labeled Sentences 1,700 10,662Available 1,436 9,492# of Sentiment Words 3,276 26,493Inconsistent Words 1,076 10,674as ?not great?
or ?not disappoint?.
On the otherhand, our polarity-shifter model learns that the word?not?
causes polarity-shifts.
Therefore, even if therewas no ?not disappoint?
in training data, our modelcan determine that ?not disappoint?
has correlationwith positive class, because the dictionary contains?disappoint?
as a negative word.
For this reason,the polarity-shifting model can be learned even withsmaller training data.What we can obtain from the proposed method isnot only a set of polarity-shifters.
We can also obtainthe weight vector w, which indicates the strength ofeach polarity-shifter and is learned so that the pre-dictive ability of sentence classification is optimizedespecially in the sentence-wise learning.
It is impos-sible to manually determine such weights for numer-ous features.It is also worth noting that all the models proposedin this paper can be represented as a kernel function.For example, the hybrid model can be seen as thefollowing kernel:Kcomb(S1, S2) = ?
?xi?S1?xj?S2K((xi, S1), (xj , S2))+(1 ?
?
)K ?
(S1, S2).
(9)Here, K means the kernel function betweenwords and K ?
means the kernel function be-tween sentences respectively.
In addition,?xi?xjK((xi, S1), (xj , S2)) can be seen asan instance of convolution kernels, which wasproposed by Haussler (1999).
Convolution kernelsare a general class of kernel functions which arecalculated on the basis of kernels between substruc-tures of inputs.
Our proposed kernel treats sentencesas input, and treats sentiment words as substructuresof sentences.
We can use high degree polynomialkernels as both K which is a kernel between sub-structures, i.e.
sentiment words, of sentences, andK ?
which is a kernel between sentences to make theclassifiers take into consideration the combinationof features.5 Evaluation5.1 DatasetsWe used two datasets, customer reviews 1 (Huand Liu, 2004) and movie reviews 2 (Pang andLee, 2005) to evaluate sentiment classification ofsentences.
Both of these two datasets are oftenused for evaluation in sentiment analysis researches.The number of examples and other statistics of thedatasets are shown in Table 1.Our method cannot be applied to sentences whichcontain no sentiment words.
We therefore elimi-nated such sentences from the datasets.
?Available?in Table 1 means the number of examples to whichour method can be applied.
?Sentiment Words?shows the number of sentiment words that are foundin the given sentences.
Please remember that senti-ment words are defined as those words that are listedin a predefined polarity dictionary in this paper.
?In-consistent Words?
shows the number of the wordswhose polarities conflicted with the polarity of thesentence.We performed 5-fold cross-validation and usedthe classification accuracy as the evaluation mea-sure.
We extracted sentiment words from GeneralInquirer (Stone et al, 1996) and constructed a polar-ity dictionary.
After some preprocessing, the dictio-nary contains 2,084 positive words and 2,685 nega-tive words.5.2 Experimental SettingsWe employed the Max Margin Online LearningAlgorithms for parameter estimation of the model(Crammer et al, 2006; McDonald et al, 2007).In preliminary experiments, this algorithm yieldedequal or better results compared to SVMs.
As thefeature representation, ?
(x, S), of polarity-shiftingmodel, we used the local context of three wordsto the left and right of the target sentiment word.We used the polynomial kernel of degree 2 forpolarity-shifting model and the linear kernel for oth-1http://www.cs.uic.edu/?liub/FBS/FBS.html2http://www.cs.cornell.edu/people/pabo/movie-review-data/300Table 2: Experimental results of the sentence classi-ficationmethods customer movieBaseline 0.638 0.504BoW 0.790 0.7242gram 0.809 0.7563gram 0.800 0.762Simple-Voting 0.716 0.624Negation Voting 0.733 0.658Word-wise 0.783 0.699Sentence-wise 0.806 0.718Hybrid BoW 0.827 0.748Hybrid 2gram 0.840 0.755Hybrid 3gram 0.837 0.758Opt 0.840 0.770ers, and feature vectors are normalized to 1.
In hy-brid models, the feature vectors,?x?S ?
(x, S)I(x)and ??
(S) are normalized respectively.5.3 Comparison of the MethodsWe compared the following methods:?
Baseline classifies all sentences as positive.?
BoW uses unigram features.
2gram uses uni-grams and bigrams.
3gram uses unigrams, bi-grams, and 3grams.?
Simple-Voting is the most simple majority vot-ing with word-level polarity (Section 3).?
Negation Voting proposed by Hu andLiu (2004) is the majority voting that takesnegations into account.
As negations, weemployed not, no, yet, never, none, nobody,nowhere, nothing, and neither, which are takenfrom (Polanyi and Zaenen, 2004; Kennedy andInkpen, 2006; Hu and Liu, 2004) (Section 3).?
Word-wise was described in Section 4.1.?
Sentence-wise was described in Section 4.2.?
Hybrid BoW, hybrid 2gram, hybrid 3gramare combinations of sentence-wise model andrespectively BoW, 2gram and 3gram (Section4.3).
We set ?
= 0.5.Table 2 shows the results of these experiments.Hybrid 3gram, which corresponds to the proposedmethod, obtained the best accuracy on customer re-view dataset.
However, on movie review dataset,the proposed method did not outperform 3gram.
InSection 5.4, we will discuss this result in details.Comparing word-wise to simple-voting, the accu-racy increased by about 7 points.
This means thatthe polarity-shifting model can capture the polarity-shifts and it is an important factor for sentiment clas-sification.
In addition, we can see the effectivenessof sentence-wise, by comparing it to word-wise inaccuracy.?Opt?
in Table 2 shows the results of hybrid mod-els with optimal ?
and combination of models.
Theoptimal results of hybrid models achieved the bestaccuracy on both datasets.We show some dominating polarity-shifters ob-tained through learning.
We obtained many nega-tions (e.g., no, not, n?t, never), modal verbs (e.g.,might, would, may), prepositions (e.g., without, de-spite), comma with a conjunction (e.g., ?, but?
asin ?the case is strong and stylish, but lacks a win-dow?
), and idiomatic expressions (e.g., ?hard resist?as in ?it is hard to resist?, and ?real snooze?
).5.4 Effect of Training Data SizeWhen we have a large amount of training data, the n-gram classifier can learn well whether each n-gramtends to appear in the positive class or the negativeclass.
However, when we have only a small amountof training data, the n-gram classifier cannot capturesuch tendency.
Therefore the external knowledge,such as word-level polarity, could be more valuableinformation for classification.
Thus it is expectedthat the sentence-wise model and the hybrid modelwill outperform n-gram classifier which does nottake word-level polarity into account, more largelywith few training data.To verify this conjecture, we conducted experi-ments by changing the number of the training ex-amples, i.e., the labeled sentences.
We evaluatedthree models: sentence-wise, 3gram model and hy-brid 3gram on both customer review and movie re-view.Figures 1 and 2 show the results on customer re-view and movie review respectively.
When the sizeof the training data is small, sentence-wise outper-301Figure 1: Experimental results on customer reviewFigure 2: Experimental results on movie reviewforms 3gram on both datasets.
We can also see thatthe advantage of sentence-wise becomes smaller asthe amount of training data increases, and that thehybrid 3gram model almost always achieved the bestaccuracy among the three models.
Similar behaviourwas observed when we ran the same experimentswith 2gram or BoW model.
From these results, wecan conclude that, as we expected above, the word-level polarity is especially effective when we haveonly a limited amount of training data, and that thehybrid model can combine two models effectively.6 ConclusionWe proposed a model that captures the polarity-shifting of sentiment words in sentences.
We alsopresented two different learning methods for themodel and proposed an augmented hybrid classifierthat is based both on the model and on existing clas-sifiers.
We evaluated our method and reported thatthe proposed method almost always improved theaccuracy of sentence classification compared withother simpler methods.
The improvement was moresignificant when we have only a limited amount oftraining data.For future work, we plan to explore new featuresets appropriate for our model.
The feature sets weused for evaluation in this paper are not necessar-ily optimal and we can expect a better performanceby exploring appropriate features.
For example, de-pendency relations between words or appearances ofconjunctions will be useful.
The position of a wordin the given sentence is also an important factor insentiment analysis (Taboada and Grieve, 2004).
Fur-thermore, we should directly take into account thefact that some words do not affect the polarity of thesentence, though the proposed method tackled thisproblem indirectly.
We cannot avoid this problemto use word-level polarity more effectively.
Lastly,since we proposed a method for the sentence-levelsentiment prediction, our next step is to extend themethod to the document-level sentiment prediction.AcknowledgementThis research was supported in part by Overseas Ad-vanced Educational Research Practice Support Pro-gram by Ministry of Education, Culture, Sports, Sci-ence and Technology.ReferencesKoby Crammer, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
Online Passive-Aggressive Algorithms.
In Journal of Machine Learn-ing Research, Vol.7, Mar, pp.551?585, 2006.Michael Gamon.
Sentiment classification on customerfeedback data: noisy data, large feature vectors, andthe role of linguistic analysis.
In Proceedings of the20th International Conference on Computational Lin-guistics (COLING-2004) , pp.841?847, 2004.David Haussler.
Convolution Kernels on Discrete Struc-tures, Technical Report UCS-CRL-99-10, Universityof California in Santa Cruz, 1999.Minqing Hu and Bing Liu.
Mining Opinion Featuresin Customer Reviews.
In Proceedings of NineteethNational Conference on Artificial Intellgience (AAAI-2004) , pp.755?560, San Jose, USA, July 2004.302Alistair Kennedy and Diana Inkpen.
Sentiment Classi-fication of Movie and Product Reviews Using Con-textual Valence Shifters.
In Workshop on the Analysisof Formal and Informal Information Exchange duringNegotiations (FINEXIN-2005), 2005.Taku Kudo and Yuji Matsumoto.
A Boosting Algorithmfor Classification of Semi-Structured Text.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing (EMNLP-2004), pp.301?308, 2004.Yu Mao and Guy Lebanon.
Isotonic Conditional Ran-dom Fields and Local Sentiment Flow.
In Proceedingsof the Newral Information Processing Systems (NIPS-2006), pp.961?968, 2006.Shotaro Matsumoto, Hiroya Takamura, and ManabuOkumura.
Sentiment Classification using Word Sub-Sequences and Dependency Sub-Trees.
In Proceed-ings of the 9th Pacific-Asia International Conferenceon Knowledge Discovery and Data Mining (PAKDD-2005), pp.301?310 , 2005.Ryan McDonald, Kerry Hannan, Tyler Neylon, MikeWells, and Jeff Reynar.
Structured Models for Fine-to-Coarse Sentiment Analysis.
In Proceedings of the 45thAnnual Meeting of the Association for ComputationalLinguistics (ACL-2007), pp.432?439, 2007.Tony Mullen and Nigel Collier.
Sentiment analysis us-ing support vector machines with diverse informa-tion sources.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP-2004), pp.412?418, 2004.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.Thumbs up?
Sentiment Classification using MachineLearning Techniques.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP-2002), pp.76?86, 2002.Bo Pang and Lillian Lee.
A Sentimental Education:Sentiment Analysis Using Subjectivity SummarizationBased on Minimum Cuts.
In Proceedings of the 42thAnnual Meeting of the Association for ComputationalLinguistics (ACL-2004), pp.271?278, 2004.Bo Pang and Lillian Lee.
Seeing stars: Exploiting classrelationships for sentiment categorization with respectto rating scales.
In Proceedings of the 43rd AnnualMeeting of the Association for Computational Linguis-tics (ACL-2005), pp.115?124, 2005.Livia Polanyi and Annie Zaenen.
Contextual ValenceShifters.
In AAAI Spring Symposium on Exploring At-titude and Affect in Text: Theories and Applications(AAAI-EAAT2004), 2004.Philip J.
Stone, Dexter C. Dunphy, Marshall S. Smith,and Daniel M. Ogilvie.
The General Inquirer: A Com-puter Approach to Content Analysis.
The MIT Press,1996.Maite Taboada and Jack Grieve.
Analyzing AppraisalAutomatically.
In AAAI Spring Symposium on Explor-ing Attitude and Affect in Text: Theories and Applica-tions (AAAI-EAAT2004), pp.158?161, 2004.303
