A Study of Automatic Pitch Tracker Doubling/Halving ?Errors?Kathleen MurrayDepartment of CISMoore School Building200 South 33rd St.19104 Philadelphia, PA USkmurray@voicenet.comAbstractManually verified pitch data were comparedwith output from a commonly used pitch-tracking algorithm.
The manual pitch datamade statistically significantly better ?finalrise?
predictions than the automatic pitchdata, in spite of great similarity between thetwo sets of measurements.
Pitch Trackingdoubling/halving errors are described.IntroductionAutomatically captured prosodic information isrelevant to both automatic speech recognitionand speech synthesis.
Pitch information, thoughregarded as highly relevant, has not beenscrutinized in detail as with respect to automaticpitch trackers.
This study presents a comparisonof hand-verified pitch measurements (?hand?
)with measurements from a commonly used pitchtracking algorithm (?automatic?
), Talkin (1995).For this paper pitch will be defined as the aurallyperceived information that loosely correlateswith the fundamental frequency of a section of aspeech waveform.
The organization of this paperis as follows: First, the corpus used is describedand justified.
The next section describescomparisons of the hand-corrected pitchmeasurements and the automatic pitch trackeroutput.
Next, results are presented with respectto the detection of utterance-final rises and falls.Lastly, the future work section connectsconclusions from this specific study to relatedwork on pitch and perception, and describesdiscourse-related applications that could benefitfrom a study of this kind.1 Corpus DescriptionThe 1992 and the 1993 dialogs from theTRAINS corpus Heeman and Allen (1995) weredeveloped to facilitate the study of collaborativedialogs.
In these dialogs, one person guided a?user?
through a railroad freight systemtransportation task, and a monitor recorded thespeech without interruption.
Trainedphoneticians labeled a subset of this speech withToBI information Beckman and Ayers1994/1997.
Around 26 minutes of speech froma subset of these dialogs were analysed withrespect to pitch.
"Wedw" software was usedBunnell et al (1992) by a linguistically trainedannotator first in automatic mode.
Handconsistency checks then examined glottal pulselocations in a wideband spectrogram.
Wedw'swideband spectrogram displays an extremelydarkened region where the glottis closes,approximating glottal pulse locations.
Hess(1983) recommended use of a widebandspectrogram for manual verification of pitchtracks, but he conceded that widebandspectrograms do not provide sufficientresolution for the eye.
In addition to use of awideband spectrogram, the annotator carefullyregarded the shape of the signal waveform, to besure that glottal pulse locations were labeledconsistently with respect to local peaks in theactual speech waveform.
These dialogues werechosen for future in-depth investigations of whatintonation-based features could be integratedinto an automated dialogue system fordetermining user intentions and generatingappropriate system responses.2 Pitch Tracking ComparisonOne concern in automatic pitch tracking is howto handle occasional events where an octavehalving appears in the speech signal, but is notreadily perceived by a human listener.
Thealgorithm in Talkin (1995) addresses this issuewith special constraints on dynamicprogramming cleanup of the pitch trackeroutput.
Figure 1 below illustrates difficulties inmaking comparisons between pitch trackers interms of doubling errors.
Figure 1 plots amanually annotated pitch track that ranges from75 Hz to 189 Hz, and an automatically generatedpitch track that ranges from 74 Hz to 102 Hz, forthe interval [1.37,1.98] of a 2.5 secondutterance.
The words of the utterance are ?andpick up three boxcars how long is that?.
A finalrise can be heard at the end of the utterance,indicating a user?s request for information fromthe system.
The complete ToBI string associatedwith the utterance is ?H* L-L% L* H-H%?.The last voiced section of utt10 shows thespeaker vacillating between one octave andanother, but the last ToBI string associated withthe utterance is ?H-H%?, meaning a high phraseaccent followed by a high boundary tone.
Itwould be surprising for the speaker to bespeaking in the 90-100 Hz range reported by thepitch tracker, because the previous section ofspeech is actually an octave higher, in the 200-235 Hz range.
An octave pitch drop would notmake sense in the context of a combination ofhigh ToBI labels.
The speaker is female.
Initialcomparisons are difficult because neithermethod precisely specifies the pitch information,so no pitch gold standard could be producedwithout significant manual verification ofcontext-dependent doubling rules.
When asection of speech appears to be halved in pitch,that halving could be a perceptually significantdrop, or it could be a pitch tracker error.For the 320 utterances used in the evaluation(see Section 3), it was determined that roughly40,419 10 ms frames had occurred where bothmethods predicted a voiced frame.
When theratio was taken of X/Y, where X was theautomatic measurement, and Y, the handmeasurement, it was the case that 96% of thetime, this ratio was between .8 and 1.2, meaningthat the automatic measurement was 20% off thehand measurement for 96% of the relevantcases.
The distance of 20% can be used as a goalfor past comparisons of pitch tracker outputswith a ?gold standard?, although some studieshave reported an allowance of 30 Hz Niemannet.
al (1994).
Using the 20% distance, these twomethods of pitch look very similar.For determining halving amounts, one canconsider the percentage of time that the ratio ofthe hand measurement to the automaticmeasurement was between 1.7 and 2.2.
For theroughly 40,000 10 ms voicing-coincident 10 msframes, .5% of them could be counted as ahalving by the automatic pitch tracker for thefemale speakers, and .4% of the male speechwas halved in pitch.
One speaker, ?JT?, female,comprised half of the female pitchmeasurements, and had a 1% pitch halving rate.One reason these proportions are so small is thatthe hand-verified data still has some halved datain it, as Figure 1 shows.
For somemeasurements, pitch halvings are not ?errors?
atall, because they can directly reflect theinformation in the speech signal.
When speechfrom the speaker ?JT?
of Figure 1 was correc tedfor halving, 36% of the ratios between the hand-verified and the automatic data were between1.7 and 2.2.3 Detection of ?Rise?/?Falls?This section reports the results of applying asimple classification rule with respect to thedifferent pitch methods.
The idea comes fromDaly (1994).
Often, the last label in a ToBI-labeled utterance is a final boundary tone.
For320 utterances, this was the case, and anassociation was made between the ?H%?
(high)boundary tone and a ?Rise?
and the ?L%?
(low)boundary tone and a ?Fall?.
When the authorlistened to these utterances, thirteen were ruledout as not contributing a readily perceived tone.This coarse classification is a firstapproximation towards a perceptually basedevaluation of pitch trackers that focuses on asection of an utterance considered linguisticallyspecial Pierrehumbert and Hirschberg (1990).The last part of an utterance can signal a user?sintention, such as asking a question.For classifying final tones, firstly the averagepitch value for the last voiced region wascalculated, ?avgL?, and the average pitch valueof the remaining voiced regions was calculated,avgR?.
Next, the longest slope for the last voicedsection was calculated, ?slopeL?.
Where ?avg L?was greater than ?avgR?, or ?slope L?
waspositive, a final high tone was classified.
Where?avgL?
was less than ?avgR?, or ?slopeL?
wasnegative, a final low tone was classified.This combination of slope calculations andsimple comparisons were an improvement overthe method used in Murray (2001).
No otherstudy of this magnitude (the hand labelingsyielded roughly 100,000 data points) has beenpublished that combines wideband spectrogramsand signal shape to hand measure pitch tracks ofconversational speech.
Section 2 showed that formany cases, the outputs of the methods aresimilar.
The hand-verified data could be used toclosely examine contexts where a pitch trackerpredicts a subharmonic of the perceived pitch.More sophisticated tone classification rulesbesides this preliminary one could be developedonce the accuracy of pitch measurement onconversational speech has been improved.Table 1 below shows results of this simpleclassification with respect to hand-verified pitchmeasurements and automatic ones, and pvaluesfrom a paired t-test.
Overall, the hand verifiedmeasurements performed better in predictingrises and falls at a p<.001 level of significance.The preliminary classification rule used slightlyfavored female speech over male speech.4 Future and Related WorkA further step would be to coordinatedescriptions of pitch tracking errors with respectto categorizations of laryngealization, such asthat of Batliner et al (1993).
A pitch value thatis in a ?subharmonic?
or a ?diplophonic?laryngealization, (from M?SLI) may need to bedoubled, and context-dependent doubling rulescould make use of the M?SLI classification.Different kinds of final tone classification can beinvestigated, once the post-processing of pitchmeasurements has been better established.Murray (2001) used automatic doubling rules,and a different classification scheme, resulting inlower performance than this study.Shriberg (1999) mentions laryngealizations inthe context of "cut-off" words, ie, those wordsthat a speaker did not complete.
In a corpus ofhuman-computer dialogues on air travelplanning (ATIS), cut-off words had a form oflaryngealization corresponding to creaky voiceusually on the last 20-50 ms of the word.
Betterrecognition of glottal pulses may lead toimproved recognition of cut-off words, whichare difficult phenomena for an ASR system.Br?ndsted (1997) reported that for a specificdialect of Danish, the presence of a glottalconsonant ?st?d?
can cause a pitch tracker toincorrectly report a halved value.
Further use ofwideband spectrograms to facilitate conventionsof locations of glottal pulses and their influenceon perceived pitch could assist dialogue researchfor other languages that have glottalizedconsonants.
Black and Campbell (1995)presented a model for generating intonationpatterns based on high-level discourse featuresautomatically extracted from dialogue speech.One particular discourse act label, the so-called"d-yu-Q" label, w as reported to rise up tosignificantly higher pitch values than otherdiscourse act labels.
Once pitch halvings anddoublings are better understood, additionalrelationships between pitch changes anddiscourse acts might be discovered.
Lastly, itwould be useful to compare this data to outputsof other pitch trackers, such as that of Praat, PaulBoersma and David Weenink.
(2001), or anupdated version of ?EDWave?
Bunnell  (2001).More sophisticated mathematical models wouldbe interesting to use for the final toneclassification, especially with respect to differentkinds of pitch tracking algorithms.5 ConclusionsA task-oriented conversational speech databasewas manually annotated for pitch, but workremains to make the database precise enough forintonation research.
This work focussed onpotential halving and doubling errors of pitchtrackers, and on evaluation of pitch trackers withrespect to a final boundary tone classification.Statistically significantly better classificationresults were achieved with manual verificationof pitch data based on wideband spectrogramsand speech waveform information.
These resultswere achieved even though the handmeasurements appeared to be very similar to theautomatic measurements.
Based on the verypreliminary results of this study, the followingtwo conclusions can be made at this time: one,that automatic pitch measurements still mightnot be as accurate as needed in order to makegeneralizations about intonation contours inconversational speech; and secondly, that thecombination of a wideband spectrogram andsignal shape is a useful starting point forcreating large-scale hand-verified pitch tracks ofconversational speech.AcknowledgementsMy thanks go to James Allen and LucianGalescu for their support of the corpusannotations.
This material is based upon workpartially supported by the National  ScienceFoundation grant number IRI-9711009.
Anyopinions, findings, and conclusions orrecommendations expressed in this material arethose of the author and do not necessarily reflectthe views of the National Science Foundation.ReferencesA.
Batliner et.
al.
(1993) M?SLI: A ClassificationScheme For Laryngealizations.
In D. House and P.Touati, editors, Working Papers, ProsodyWorkshop, pp.
176-179, Sweden.Beckman, M.E.
& Ayers Elam, G. (1994/1997)?Guide to ToBI Labelling ?
Version 3.0?,electronic text and accompanying audio examplefiles available athttp://ling.ohiostate.edu/Phonetics/E_ToBI/etobi_homepage.html.Black, A. and Campbell, N. (1995) ?Predicting theintonation of discourse segments from examples indialogue speech?, ESCA workshop on spokendialogue systems, Denmark.Paul Boersma and David Weenink.
(2001)  PraatTool, Institute of Phonetics Sciences of theUniversity of Amsterdam.Br?ndsted T. (1997) "Intonation Contours "distorted"by Tone Patterns of Stress Groups and WordAccent", Intonation: Theory, Models andApplications,  Athens (Athanasopoulos).Bunnell H. T., and Mohammed O.
(1992) "EDWave -A PC-based Program for Interactive GraphicalDisplay, Measurement and Editing of Speech andOther Signals."
Software presented at the 66thAnnual Meeting of the Linguistic Society ofAmerica.Bunnell  (2001) ?Wedw?
pitch tracking software,http://www.asel.udel.edu/speech/Spch_proc/software.html.Daly N. (1994) ?Acoustic-Phonetic and LinguisticAnalyses of Spontaneous Speech: Implications forSpeech Understanding?, PhD thesis, Department ofElectrical Engineering, Massachusetts Institute ofTechnology.A.
Hagen, S. Shattuck-Hufnagel and E. Noeth,(1999) "A Study on Glottalizations and theirAutomatic Detection".
ICPhS  Workshop on Non-Modal Vocal-Fold Vibration an d Voice QualityPoster Session, San Francisco.Heeman P.A.
and J.F.
Allen (1995) The Trainsspoken dialog corpus.
CD-ROM, Linguistics DataConsortium.Hess W. (1983) Pitch determination of speech signals: algorithms and devices.
New York: Springer-Verlag.Murray K. (2001)  A Corpus-Based ApproachT owards Automatic Correction of Pitch TrackerErrors, Proceedings of the NAACL Workshop onAdaptation in Dialogue Systems, Pittsburgh, PA.N?th E. et.
al.
(2000) Verbmobil: The Use of Prosodyin the Linguistic Components of a SpeechUnderstanding System.
TransSAP, 8(5):519-532.H.
Niemann et.
al.
(1994).
Pitch DeterminationConsidering Laryngealization Effects in SpokenDialogs , Proceedings of ICNN, Vol.
7: 4457-4461Orlando.Pierrehumbert, Janet, and Julia Hirschberg.
(1990)The meaning of intonational contours in discourse.In Philip R. Cohen, Jerry Morgan, and Martha E.Pollack (eds.
), Intentions in Communicat ion.Cambridge, MA: MIT Press.Shriberg E. (1999).
Phonetic Consequences ofSpeech Disfluency.
Symposium on The Phoneticsof Spontaneous Speech (S. Greenberg and P.Keating, organizers), Proc.
International Congressof Phonetic Sciences, Vol.
1: 619-622, SanFrancisco.Talkin D. (1995) ?A Robust Algorithm for PitchTracking (RAPT)?, from Speech Coding andSynthesis, Kleijn, W.B., Paliwal, K.K.
ed.Amsterdam, the Netherlands: Elsevier,  495-518.Table 1: Final Rise/Falls: %Correct,  pvaluesFigure 1: Pitch Plot of Utt10/d93-20.1, X axis istime in seconds, Y axis is frequency in Hz, squaresare automatic measurements, diamonds, handmeasurements, time ranges from 1.34 ?
1.98 sType (Total) Hand Automatic pvalueMale (258) 76 68 0.01Female (49) 82 69 0.06Overall (307) 77 68 0.001
