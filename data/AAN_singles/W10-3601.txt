Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 1?7,the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010Boosting N-gram Coverage for Unsegmented Languages  UsingMultiple Text Segmentation ApproachSolomon Teferra AbateLIG Laboratory,CNRS/UMR-5217solomon.abate@imag.frLaurent BesacierLIG Laboratory,CNRS/UMR-5217laurent.besacier@imag.frSopheap SengLIG Laboratory,CNRS/UMR-5217MICA Center, CNRS/UMI-2954sopheap.seng@imag.frAbstractAutomatic  word  segmentation  errors,for  languages  having  a  writing  systemwithout word boundaries, negatively af-fect the performance of language mod-els.
As a solution, the use of  multiple,instead of unique, segmentation has re-cently  been  proposed.
This  approachboosts  N-gram  counts  and  generatesnew  N-grams.
However,  it  also  pro-duces bad N-grams that  affect the lan-guage models' performance.
In this pa-per, we study more deeply the contribu-tion  of  our  multiple  segmentation  ap-proach  and experiment on an efficientsolution to minimize the effect of addingbad N-grams.1 IntroductionA language model  is  a  probability assignmentover  all  possible  word  sequences  in  a  naturallanguage.
It assigns a relatively large probabili-ty to meaningful, grammatical, or frequent wordsequences and a low probability or a zero proba-bility  to  nonsensical,  ungrammatical  or  rareones.
The statistical  approach used in N-gramlanguage modeling requires a large amount oftext data in order to make an accurate estimationof probabilities.
These data are not available inlarge  quantities  for  under-resourced  languagesand the lack of text data has a direct impact onthe performance of language models.
While theword is  usually  a  basic  unit  in  statistical  lan-guage  modeling,  word  identification  is  not  asimple  task  even  for  languages  that  separatewords by a special character (a white space ingeneral).
For  unsegmented  languages,  whichhave a writing system without obvious word de-limiters, the N-grams of words are usually esti-mated  from  the  text  corpus  segmented  intowords employing automatic methods.
Automat-ic segmentation of text is not a trivial task andintroduces errors due to the ambiguities in natu-ral language and the presence of out of vocabu-lary words in the text.While the lack of text resources has a nega-tive  impact  on  the  performance  of  languagemodels,  the  errors  produced by the  word seg-mentation make those data even less usable.
Theword N-grams not found in the training corpuscould be due not only to the errors introducedby the automatic segmentation but  also to thefact  that  a  sequence  of  characters  could  havemore than one correct segmentation.In  previous  article  (Seng  et  al.,  2009),  wehave proposed a method to estimate an N-gramlanguage  model  from  the  training  corpus  onwhich each sentence is segmented into multipleways instead of a unique segmentation.
The ob-jective of multiple segmentation is to generatemore N-grams from the training corpus to use inlanguage modeling.
It was possible to show thatthis  approach  generates  more  N-grams  (com-pared  to  the  classical  dictionary-based  uniquesegmentation method) that are potentially usefuland relevant in language modeling.
The applica-tion of multiple segmentation in language mod-eling  for  Khmer  and  Vietnamese  showed im-provement in terms of tri-gram hits and recogni-tion error rate in Automatic Speech Recognition(ASR) systems.This work is a continuation of our previouswork on the use of multiple segmentation.
It isconducted on Vietnamese only.
A close analysisof N-gram counts shows that the approach hasin fact two contributions: boosting the N-gram1counts that are generated with first best segmen-tation  and  generating  new N-grams.
We havealso identified that there are N-grams that nega-tively  affect  the  performance  of  the  languagemodels.
In this paper, we study the contributionof boosting N-gram counts and  of new N-gramsto the performance of the language models andconsequently  to  the  recognition  performance.We also present experiments where rare or badN-grams are cut off in order to minimize theirnegative effect on the performance of the lan-guage models.The paper is organized as follows: section 2presents the theoretical background of our mul-tiple  segmentation  approach;  in  section  3  wepoint out the set up of our experiment; in sec-tion 4 we present the results of our detailed sta-tistical analysis of N-grams generated by multi-ple  segmentation  systems.
Section  5  presentsthe  evaluation  results  of  our  language  modelsfor  ASR  and  finally,  we  give  concluding  re-marks.2 Multiple Text SegmentationText segmentation is a fundamental task in nat-ural language processing (NLP).
Many NLP ap-plications require the input text segmented intowords before making further progress becausethe word is considered the basic semantic unit innatural  languages.
For unsegmented languagessegmenting text into words is not a trivial task.Because of ambiguities in human languages, asequence  of  characters  may  be  segmented  inmore than one way to  produce a  sequence ofvalid words.
This is due to the fact  that thereare different segmentation conventions and thedefinition of  word in a language is  often am-biguous.Text  segmentation  techniques  generally  usean  algorithm  which  searches  in  the  text  thewords corresponding to those in a dictionary.
Incase of ambiguity, the algorithm selects the onethat  optimizes  a  parameter  dependent  on  thechosen  strategy.
The  most  common optimiza-tion strategies consist of maximizing the lengthof  words  (?longest  matching?)
or  minimizingthe  number  of  words  in  the  entire  sentence(?maximum matching?).
These techniques relyheavily on the availability and the quality of thedictionaries and while it is possible to automati-cally generate a dictionary from an unsegment-ed text corpus using unsupervised methods, dic-tionaries are often created manually.
The state-of-the-art methods generally use a combinationof hand-crafted, dictionary and statistical tech-niques to obtain a better result.
However, statis-tical  methods  need  a  large  corpus  segmentedmanually  beforehand.
Statistical  methods  andcomplex training methods are not appropriate inthe context of under-resourced languages as theresources  needed to  implement  these  methodsdo not exist.
For an under-resourced language,we seek segmentation methods that allow betterexploitation of the limited resources.
In our pre-vious paper (Seng et al, 2009) we have indicat-ed the  problems of  existing text  segmentationapproaches  and  introduced  a  weighted  finitestate  transducer  (WFST)  based  multiple  textsegmentation algorithm.Our approach is implemented using the AT &T FSM Toolkit (Mohri et al, 1998).
The algo-rithm is inspired with the work on the segmen-tation of Arabic words (Lee et al, 2003).
Themultiple segmentation of a sequence of charac-ters is made using the composition of three con-trollers.
Given  a  finite  list  of  words  we  canbuild a finite state transducer M (or word trans-ducer) that, once composed with an acceptor Iof the input string that represent a single charac-ter  with  each  arc,  generates  a  lattice  of  thewords that represent all of the possible segmen-tations.
To handle out-of-vocabulary entries, wemake a model of any string of characters by astar closure operation over all the possible char-acters.
Thus,  the  unknown  word  WFST  canparse any sequence of characters and generate aunique  unk word symbol.
The word transducercan,  therefore,  be  described  in  terms  of  theWFST  operations  as  M  =  (WD   UNK)+?where WD is a WFST that represents the dictio-nary  and  UNK represents  the  unknown  wordWFST.
Here,  and + are the union and Kleene??+?
closure operations.
A language model L isused to score the lattice of all possible segmen-tations obtained by the composition of our wordtransducer M and the input string I.
A languagemodel  of  any  order  can  be  represented  by  aWFST.
In our case, it is important to note thatonly a simple uni-gram language model is used.The uni-gram model is estimated from a smalltraining  corpus  segmented  automatically  intowords  using  a  dictionary  based  method.
Thecomposition  of  the  sequence  of  input  string  I2with the word transducer M yields a transducerthat represents all possible segmentations.
Thistransducer is then composed with the languagemodel  L,  resulting  in  a  transducer  that  repre-sents  all  possible  segmentations  for  the  inputstring  I,  scored  according  to  L.  The  highestscoring paths of the compound transducer is thesegmentation m that can be defined as:P ?m ?=maxP ?mk ?The segmentation procedure can then be ex-pressed formally as:m=bestpath ?
I?M?L ?where ?
is the composition operator.
The N-best segmentations are obtained by decoding thefinal lattice to output the N-best highest scoringpaths and will be used for the N-gram count.3 Experimental Setup3.1 Language ModelingFirst,  it  is  important  to  note  that  Vietnamesetexts are naturally segmented into syllables (notwords).
Each  syllable  tends  to  have  its  ownmeaning and thus  a  strong identity.
However,the  Vietnamese  monosyllable  is  not  automati-cally a word as we would define a word in Eng-lish.
Often, two syllables go together to form asingle word, which can be identified by the wayit  functions  grammatically  in  a  sentence.
Tohave a word-based language model, word seg-mentation would, therefore, be a must in Viet-namese.A Vietnamese training corpus that contains 3millions sentences from broadcast news domainhas been used in this experiment.
A Vietnamesedictionary of 30k words has been used both forthe  segmentation  and  counting  the  N-grams.Therefore, in the experiments, the ASR vocabu-lary always remains the same and only the lan-guage model is changing.
The segmentation ofthe  corpus  with  dictionary  based,  ?longestmatching?
unique segmentation method gives acorpus  of  46  millions  words.
A  developmentcorpus of 1000 sentences, which has been seg-mented automatically to obtain 44k words, hasbeen used to evaluate the tri-gram hits and theperplexity.
The performance of  each languagemodel  produced will  be evaluated in  terms ofthe tri-gram hits and perplexity on the develop-ment corpus and in terms of ASR performanceon a separate speech test set (different from thedevelopment set).First of all, a language model named lm_1 istrained using the SRILM toolkit (Stolcke 2002)from  the  first  best  segmentation  (Segmul1),which has the highest scoring paths (based onthe transducer explained in section 2) of  eachsentence in the whole corpus.
Then,  additionallanguage  models  have  been  trained  using  thecorpus  segmented  with  N-best  segmentation:the number of N-best segmentations to generatefor each sentence is fixed to 2, 5, 10, 50, 100and 1000.
The resulting texts are named accord-ingly  as  Segmul2,  Segmul5,  Segmul10,  Seg-mul50,  Segmul100,  Segmul1000.
Using  theseas  training  data,  we  have  developed  differentlanguage models.
Note that a tri-gram that ap-pears several times in multiple segmentations ofa single sentence has a count set to one.3.2 ASR SystemOur automatic speech recognition systems usethe CMU?s Sphinx3 decoder.
The decoder usesHidden Markov Models (HMM) with continu-ous  output  probability  density  functions.
Themodel topology is a 3-state, left-to-right HMMwith 16 Gaussian mixtures per state.
The pre-processing of the system consists of extracting a39 dimensional  features vector  of  13 MFCCs,the  first  and  second  derivatives.
The  CMU?sSphinxTrain has been used to train the acousticmodels used in our experiment.The  Vietnamese  acoustic  modeling  trainingcorpus is  made up of  14 hours  of  transcribedread  speech.
More  details  on  the  automaticspeech recognition system for Vietnamese lan-guage can be found in (Le et al, 2008).
Whilethe evaluation metric WER (Word Error Rate)is  generally used to evaluate and compare theperformance  of  the  ASR  systems,  this  metricdoes not fit well for unsegmented languages be-cause the errors introduced during the segmen-tation of the references and the output hypothe-sis may prevent a fair comparison of differentASR system outputs.
We,  therefore,  used  theSyllable Error Rate (SER) as Vietnamese text iscomposed  of  syllables  naturally  separated  bywhite space.
The automatic speech recognitionis  done  on  a  test  corpus  of  270  utterances(broadcast news domain).34 Statistical  Analysis  of  N-grams  inMultiple Text SegmentationThe  change  in  the  N-gram  count  that  resultsfrom  multiple  segmentation  is  two  fold:  firstthere is a boosting of the counts of the N-gramsthat  are  already found with the first  best  seg-mentation,  and  secondly  new  N-grams  areadded.
As  we have made a  closed-vocabularycounting, there are no new uni-grams resultingfrom  multiple segmentation.
For the counting,the SRILM toolkit  (Stolcke 2002) is used set-ting the -gtnmin option to zero so that all the N-gram counts can be considered.Figure  1  shows  the  distribution  of  tri-gramcounts for the unique and multiple segmentationof the training corpus.
It  can be seen that  themajority  of  the  tri-grams  have  counts  in  therange of one to three.Figure 1: Distribution of tri-gram countsThe boosting (the counts of the tri-grams thatare already found with the first best segmenta-tion) effect of the multiple segmentation is indi-cated in table 1.
We can see from the table thatSegmul2, for example, reduced the  number ofrare tri-grams (count range 1-3) from 19.04 to16.15  million.
Consequently,  the  ratio  of  raretri-grams to all tri-grams that are in Segmul1 isreduced  from 94% (19.04/20.31*100)  of  Seg-mul1  only  to  79%  (15.96/20.31*100)  by  theboosting effect of Segmul1000, which increasedthe number of tri-grams with count range of 4-9from 0.91M to 3.34M.
This implies, in the con-text of under-resourced languages, that multiplesegmentation  is  boosting  the  N-gram  counts.However, one still has to verify if this boostingis relevant or not for ASR.MultipleSeg.Counts Range1?3(M)4-9(M)10-99(M)100-999(M)?1000(M)Segmul1 19.04 0.91 0.34 0.016 0.00054Segmul2 16.15 3.23 0.89 0.043 0.0017Segmul5 16.06 3.28 0.92 0.045 0.0017Segmul10 16.03 3.30 0.93 0.045 0.0017Segmul50 15.99 3.33 0.95 0.046 0.0017Segmul100 15.98 3.33 0.95 0.046 0.0017Segmul1000 15.96 3.34 0.96 0.046 0.0017Table 1. boosting tri-gram countsWe have also analyzed the statistical behav-ior of the newly added tri-grams with regard totheir count distribution (see figure 2).
As we cansee from the figure, the distribution of the newtri-grams is somehow similar to the distributionof the whole tri-grams that is indicated in figure1.As  shown  in  table  2,  the  total  number  ofnewly  added  tri-grams  is  around  15  millions.We can see from the table that the rate of newtri-gram contribution of each segmentation in-creases as N increases in the N-best segmenta-tion.
However, as it is indicated in figure 2, themajor  contribution  is  in  the  area  of  rare  tri-grams.Figure 2: Distribution of new tri-gram counts1?3 4?9 10?99 100-999 ?100005,000,00010,000,00015,000,00020,000,00025,000,00030,000,00035,000,00040,000,000Segmul1Segmul2Segmul5Segmul10Segmul50Segmul100Segmul1000Counts RangeNo.
of tri-gram s1?3 4?9 10?99 100-999 ?100002,000,0004,000,0006,000,0008,000,00010,000,00012,000,00014,000,00016,000,000Segmul 2Segmul 5Segmul 10Segmul 50Segmul 100Segmul 1000Counts RangeNumberoftri-grams4Mul.
Segmentation No.
%Segmul2 4,125,881 26,05Segmul5 8,249,684 52,09Segmul10 10,355,433 65,39Segmul50 13,002,700 82,11Segmul100 14,672,827 92,65Segmul1000 15,836,120 100,0Table 2. tri-gram contribution of multiple seg-mentation5 Experimental ResultsIn this section we present the various languagemodels  we  have  developed  and  their  perfor-mance in terms of perplexity, tri-gram hits andASR performance (syllable error rate).We use the results obtained with the methodpresented in (Seng et al, 2009) as baseline.
Thismethod  consists  in  re-estimating  the  N-gramcounts  using the  multiple  segmentation of  thetraining data and add one to the count of a tri-gram that appears several times in multiple seg-mentations of a single sentence.
These baselineresults  are  presented  in  Table  3.
The  resultsshow an increase of the tri-gram coverage andslight improvements of the ASR performance.LanguageModels3gs(M) 3g hit(% ) Ppl SERLm_1 20.31 46.9 126.6 27lm_2 24.06 48.6 118.1 26.2Lm_5 28.92 49.2 125.9 27Lm_10 32.82 49.4 129.0 26.5Lm_50 34.20 49.7 133.4 26.7lm_100 34.93 49.7 134.8 26.9lm_1000 36.11 49.88 137.7 27.3Table 3.
Results of experiments using the base-line method presented in (Seng et al, 2009)5.1 Separate  effect  of  boosting  tri-gramcountsTo see  the  effect  of  boosting  tri-gram countsonly,  we  have  updated  the  counts  of  the  tri-grams  obtained  from  the  1-best  segmentation(baseline  approach)  by  the  tri-gram counts  ofdifferent  multiple  segmentations.
Note  that  nonew tri-grams are added here, and we evaluateonly the effect  and,  therefore,  the tri-gram hitremains the same as that of lm_1.We have then developed different  languagemodels using the uni-gram and bi-gram countsof  the first  best  segmentation and the updatedtrigram counts after multiple segmentation.
Theperformance of the language models have beenevaluated in terms of perplexity and their contri-bution  to  the  performance  improvement  of  aspeech recognition system.
We have observed(detailed  results  are  not  reported  here)  thatboosting only the tri-gram counts has not con-tributed any improvement in the performance ofthe  language  models.
The  reason  is  probablydue  to  the  fact  that  simply  updating  tri-gramcounts without updating the uni-grams and thebi-grams lead to a biased and inefficient LM.5.2 Separate effect of new tri-gramsTo  explore  the  contributions  of  only  newlyadded tri-grams, we have added their counts tothe N-gram counts of Segmul1.
It is importantto note that the model obtained in that case isdifferent from the baseline model whose resultsare presented in Table 3 (the counts of the tri-grams already found in the unique segmentationare different between models).
As it is presentedin table 4, including only the newly added tri-grams  consistently  improved  tri-gram  hits,while the improvement in perplexity stopped atSegmul10.
Moreover, the use of only new tri-grams do not reduce the speech recognition er-ror rate.LanguageModels3gs(M)3ghit(% )ppl SERlm_1 20.3 46.9 126.6 27lm_2_new 24.4 48.7 119.1 26.9lm_5_new 28.6 49.0 122.5 27.8lm_10_new 30.7 49.2 124.2 27.9lm_50_new 33.3 49.4 126.8 27.8lm_100_new 35 49.8 127.8 28lm_1000_new 36.1 49.9 129.7 27.9Table 4.
Contributions of new tri-grams5.3 Pooling unique and multiple segmenta-tion modelsWe have developed language models by poolingunique and multiple segmentation models alto-gether.
For  instance,  all  the  N-grams of  lm_5multiple  segmentation  are  pooled  with  all  N-grams of lm_1 unique segmentation before esti-mating the language model probabilities.
In oth-er  words,  ngram-count  command is  used withmultiple count files.
The results are presented intable 5.As it can be noted from table 5, we have got asignificant  improvement  in  all  the  evaluationcriteria  as  compared  with  the  performance  oflm_1 that has perplexity of 126.6, tri-gram hit5of 46.91% and SER of 27.
The best result ob-tained (25.4) shows a 0.8 absolute SER reduc-tion  compared  to  the  best  result  presented  in(Seng et al, 2009).LanguageModels3gs(M)3ghit(% )ppl SERlm_1 20.31 46.9 126.6 27lm_2+lm_1 24.4 48.7 120.9 25.4lm_5+lm_1 29.12 49.2 123.2 26.2lm_10+lm_1 31.4 49.4 124.2 26lm_50+lm_1 34.3 49.7 126 26lm_100+lm_1 35 49.8 126.5 26.2lm_1000+lm_1 36.2 49.9 128 26.2Table 5.
Performance with pooling5.4 Cutting off rare tri-gramsWith  the  assumption  that  bad  N-grams  occurrarely, we cut off rare tri-grams from the countsin developing language models.
We consider alltri-grams with a count of 1 to be rare.
Our hope,here, is that using this cut off we will removebad  N-grams  introduced  by  the  multiple  seg-mentation approach, while keeping correct newN-grams in the model.
Table 6 shows the per-formance  of  the  language  models  developedwith or without tri-gram cut off for the baselinemethod (the results presented on the lines indi-cating All3gs are the same as the ones presentedin Table 3) .Language models Evaluation Criteria3gs(M)3g hit(%)ppl SERlm_1 All 3gs 20.31 46.91 126.6 27Cut off 4.17 38.09 129.3 26.6lm_2 All 3gs 24.06 48.6 118.1 26.2Cut off 5.11 39.6 121.0 26.7lm_5 All 3gs 28.92 49.2 125.9 27Cut off 6.4 40.11 129.2 26.6lm_10 All 3gs 32.82 49.41 129.0 26.5Cut off 6.98 40.27 132.4 26.6lm_50 All 3gs 34.20 49.68 133.4 26.7Cut off 7.8 40.51 136.9 26.9lm_100 All 3gs 34.93 49.74 134.8 26.9Cut off 7.98 40.59 138.4 26.8lm_1000 All 3gs 36.11 49.88 137.7 27.3Cut off 8.33 40.71 141.3 26.8Table 6.
Performance with cut off.The result shows that cutting off reduced thenumber of tri-grams highly (4 tri-grams over 5are removed in that case).
It, therefore, reducesthe  size  of  the  language  models  significantly.Although  the  results  obtained  are  not  conclu-sive, a reduction of  recognition error rate hasbeen  observed  in  four  out  of  the  seven  caseswhile the perplexity increased and the tri-gramhits decreased in all cases.5.5 Hybrid  of  pooling  and  cutting  offmethodsAs it has been already indicated, cutting off in-creased the perplexity of  the language modelsand decreased the tri-gram hits.
To reduce thenegative  effect  of  cutting  off  on  tri-gram hitsand  perplexity,  we  have  developed  languagemodels using both pooling and cut off methods.We then cut off tri-grams of count 1 from thepooled N-grams.
The result, as presented in ta-ble 7, shows that we can gain significant reduc-tion in recognition error rate and  improvementin tri-gram hits as compared to lm_1 that is de-veloped with cut off, even if no improvement inperplexity is observed.The best  result  obtained (25.9) shows a 0.3absolute  SER reduction  compared  to  the  bestsystem presented in (Seng et al, 2009).Language Models 3gs(M)3g hit(% )ppl SERlm_1 (no cutoff) 20.3 46.9 126.6 27lm_1 (cutoff) 4.2 38.1 129.3 26.6lm_2+lm_1 (cutoff) 5.2 39.7 126.4 26.8lm_5+lm_1 (cutoff) 6.4 40.2 129.5 25.9lm_10+lm_1 (cutoff) 7.0 40.3 131.1 26.3lm_50+lm_1 (cutoff) 7.8 40.5 133.5 26.4lm_100+lm_1 (cutoff) 8.0 40.6 134.3 26.4lm_1000+lm_1 (cutoff) 8.3 40.7 161.5 26.7Table 7.
Performance with hybrid method6 ConclusionThe  two  major  contributions  of  multiple  seg-mentation are generation of new N-grams andboosting N-gram counts of those found in firstbest  segmentation.
However,  it  also  producesbad N-grams that affect the performance of lan-guage models.
In this paper, we studied the con-tribution  of  multiple  segmentation  approachmore deeply and conducted experiments on effi-cient solutions to minimize the effect of addingbad N-grams.
Since only boosting the tri-gramcounts  of  first  best  segmentation  and  addingonly new tri-grams did not  reduce recognitionerror  rate,  we  have  proposed  to  pool  all  N-grams of N-best  segmentations to that  of  firstbest  segmentation  and  got  a  significant  im-provement in perplexity and tri-gram hits from6which we obtained the maximum (0.8 absolute)reduction in recognition error rate.To   minimize  the  effect  of  adding  bad  N-grams,  we  have  cut  off  rare  tri-grams in  lan-guage modeling and got  reduction in  recogni-tion error rate.
The significant reduction of tri-grams that  resulted  from the  cut  off  revealedthat the majority of tri-grams generated by mul-tiple  segmentation  have  counts  1.
Cutting  offsuch a big portion of the trigrams reduced tri-gram hits and as a solution, we  proposed a hy-brid of both pooling  and cutting off tri-gramsfrom which we obtained a significant reductionin recognition error rate.It  is  possible  to  conclude  that  our  methodsmake the multiple segmentation approach moreuseful by minimizing the effect of bad N-gramsthat it generates and utilizing the contribution ofdifferent multiple segmentations.However,  we  still  see  rooms  for  improve-ment.
A systematic selection of new tri-grams(for example, based on the probabilities of theN-grams and/or application of simple linguisticcriteria  to  evaluate  the  usefulness  of  new tri-grams), with the aim of reducing bad tri-grams,might lead to performance improvement.
Thus,we will do experiments in this line.
We will alsoapply these methods to other languages, such asKhmer.ReferencesLee, Young-Suk, Papineni, Kishore, Roukos, SalimEmam,  Ossama  and  Hassan,  Hany.
2003.
Lan-guage model based arabic word segmentation.
InProceedings of the ACL?03, pp.
399?406.Le,  Viet-Bac,  Besacier,  Laurent,  Seng,  Sopheap,Bigi,  Brigite and Do, Thi-Ngoc-Diep.
2008.
Re-cent  advances  in  automatic  speech  recognitionfor vietnamese.
SLTU?08, Hanoi Vietnam.Mohri,  Mehryar,  Fernando  C.  N.  Pereira,  andMichael Riley, ?A rational design for a weightedfinite-state transducer library,?
in Lecture Notes inComputer Science.
Springer, 1998, pp.
144?158.Seng,  Sopheap,  Besacier,  Laurent,  Bigi,  Brigitte,Castelli,  Eric.
2009.
Multiple Text Segmentationfor  Statistical  Language  Modeling.
InterSpeech,Brighton, UK,Stolcke, Andreas.
2002.
SRILM: an extensible lan-guage  modeling  toolkit.
Proceedings  of  Interna-tional Conference on Spoken Language Process-ing, volume II, 901?904 .
129.88.65.1157
