Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 38?42,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsMining human interactions to construct a virtual guide for a virtual fairAndr?es LunaLIIS Group, FaMAFUniversidad Nacional de C?ordobaC?ordoba, Argentinaandres.ignacio.luna@gmail.comLuciana BenottiLIIS Group, FaMAFUniversidad Nacional de C?ordobaC?ordoba, Argentinaluciana.benotti@gmail.comAbstractIn this paper we describe how we mine in-teractions between a human guide and ahuman visitor to build a virtual guide.
Avirtual guide is an agent capable of fulfill-ing the role of a human guide.
Its goal isto guide visitors to each booth of a virtualfair and to provide information about thecompany or organization through interac-tive objects located at the fair.The guide decides what to say, using agraph search algorithm, and decides howto say using generation by selection basedon contextual features.
The guide decideswhere to speak at the virtual fair by creat-ing clusters using a data classification al-gorithm to learn in what positions the hu-man guide decided to talk.1 Introduction and previous workFairs are spaces where companies that offer simi-lar products and services meet to promote them.
Avirtual fair emulates a real fair and can be availablebefore the real fair happens in order to promote itto its potential visitors.The virtual fair used in this work is a tourismfair that took place in Mexico, where visitors couldfind in each company?s booth interactive video andlinks to tourist companies?
websites promotingparticular products.
The goal of the virtual guideis to walk the user through the virtual fair, provid-ing information about the companies?
booths andinviting them to click on interactive objects to ob-tain more information.In (Jan et al., 2009) the authors describe a vir-tual guide used to promote an island in the onlinegame Second Life whose goal was to provide in-formation to US army veterans.
Our approach dif-fers to that of (Jan et al., 2009) in that the virtualguide learns where to speak and how to realizeits contributions from an automatically annotatedcorpus, rather than by using manually designedrules.
However, our guide is not able to interpretutterances from the visitor, its decisions are onlybased on the visitor behavior.
Natural languagegeneration is achieved by adapting the generationby selection method described in (Benotti and De-nis, 2011a; Benotti and Denis, 2011b).The generation by selection method affords theuse of complex and human-like sentences, andit does not need rule writing by a dialogue ex-pert or manual annotations, among other of theirmany advantages.
The disadvantage of corpusbased generation is that the resulting dialogue maynot be fully coherent.
Shawar and Atwell (2003;2005) present a method for learning pattern match-ing rules from corpora in order to obtain thedialogue manager for a chatbot.
Gandhe andTraum (2007a; 2007b) investigate several dia-logue models for negotiating virtual agents that aretrained on an unannotated human-human corpus.Both approaches report that the dialogues obtainedby these methods are still to be improved becausethe lack of dialogue history management resultsin incoherence.
Since in task-based systems, thedialogue history is restricted by the structure ofthe task, the absence of dialogue history manage-ment is alleviated by tracking the current state ofthe task.In Section 2 we introduce the corpus used bythis work.
We discuss the clustering method usedon the corpus in Section 3; the clustering is usedto decide where to speak.
After that, we describein Section 4 the mechanisms for instruction gener-ation and graph search used to guide the visitors.Later, in Section 5 we show the results obtainedin the evaluation process and compare our sys-tem?s performance with other virtual instructors.Finally, in Section 6 we elaborate a conclusionabout the virtual guide performance and capabili-ties, as well as discuss the possible improvements.382 Virtual guide human-human corpusWe collected a corpus using a human guide in awizard of Oz setup (Kelley, 1983).
The corpus iscomprised by 5 correct sessions in total performedby the same virtual tour guide, and according tothe desired behavior and actions as specified forboth participants.
We recorded 2 hours and 2 min-utes of virtual fair guided visits which produceda total of 136 utterances, having employed 18.02words and 89.29 characters in average per utter-ance.
9 different interactive objects were clickedlocated in 4 different booths in average per ses-sion.
In Figure 1 we show an aerial view of the vir-tual fair and the occurrence of utterances, markedin blue.Figure 1: Map of registered utterances in corpus.A higher color intensity denotes a higher utterancedensity in the area.3 Behavior-based utterance clusteringThe generation by selection method that we use inthis work is based on contextual features, in partic-ular it is based on the position of the visitor insidethe virtual fair and the actions that are affordablefrom that region in the fair.
Deciding whether twopositions in the fair have the same affordances, or,as we call it, fall into the same region is critical toselect appropriate utterances from the corpus de-pending on the guide?s location and task progress.The discretization employed in (Benotti andDenis, 2011a) was geometrical discretization, di-viding the world in regions based on the area vis-ible to the guide.
Instead of doing a geometri-cal discretization our virtual fair discretization wasbehavior-oriented which means that regions aredelimited by clustering utterances that were ut-tered in a close position from each other.
In thecorpus utterances tend to cluster around decisionpoints, locations there is more than one affordableand salient action available to the user and whenthe help and direction of the guide is required.Geometrical region identification based on vis-ibility normally requires a larger corpus in orderto get a correct utterance generation, because thechance of having a region without any utteranceoccurrence inside is higher.
In such discretiza-tion, different regions may contain a very differ-ent number of utterances while using behavior-oriented discretization results in regions with asimilar number of utterances each.
That is whythe behavior-oriented discretization is an advan-tage for our virtual guide, since our corpus is con-siderably smaller to that used in (Benotti and De-nis, 2011a).We ran a modified version of the k-means clus-tering algorithm (Pakhira, 2009) that avoids emptyclusters over our corpus to group instructions.
Asparaphrase instructions, while performing a task,occur in a same decision point, then we wantedclose instructions to be in the same cluster, andtherefore our criteria of ?similarity?
between themwas euclidean distance.
Ideally, different decisionpoints should be in different clusters to guaranteeselected utterances are appropriate in every situa-tion.Let us visualize virtual fair as a directed graph(V,E) where V = regions, and if a, b ?
Vthen (a, b) ?
E if and only if there is at leastone utterance in the corpus whose immediate re-action was moving from region a to the region b.If we choose a low number of clusters the k-meansclustering algorithm would cluster instructions ofdifferent nature, and conversely a too high valuewould make the virtual fair disconnected.
Then, toobtain an optimal clustering -and therefore an op-timal discretization- we maximize the k parametersuch that the virtual fair?s graph is still connected.Discretization is finally obtained by matchingevery position (x, y) in the environment to thenearest cluster?s centroid.
We show in Figure 2 thevirtual fair discretized in k = 22 regions, as thatnumber was the maximum number of clusters we39could reach without breaking the graph connectiv-ity.
Regions are delimited by lines and centroidsare represented by white squares.Figure 2: Virtual fair divided in k = 22 regions4 The virtual guideThe virtual guide must direct visitors through thefair to interactive objects in order to complete itspromotion duty in each visit session.
We show inFigure 3 a situation in which a visitor is near aninteractive object and the virtual guide encourageshim/her to click it generating an utterance whosetranslation is ?If you click on the green cube youwill access Lawson?s website where you can learnmore about them and the communication servicesthey offer?.We can see the use of a referring expression, anegative politeness strategy (Brown and Levinson,1987) to suggest an action but not impose it whilesome information about the Lawson firm is given.In subsection 4.1 we discuss about the corpusautomatic annotation.
Then we describe how ut-terances are selected in subsection 4.2.4.1 Corpus annotationOur annotation process was simpler and morestraightforward than (Benotti and Denis, 2011a),where artificial intelligence planning is used tonormalize reactions, mainly due to the fact thatusers can not change the virtual fair state duringtheir visit, they can only change their own posi-Figure 3: The virtual guide took the visitor to aninteractive object and encourages him/her to ma-nipulate ittion and visibility area (defined by the orientationin the virtual fair) and manipulate interactive ob-jects.In a virtual fair visit, the set of user?s relevantactions are:?
Move from one region to another?
Change orientation to left or right?
Click on an interactive objectConsequently, the set of atoms representing avirtual fair?s state was simplified to?
user-region(region)?
user-orientation(x,y,z,w)1?
clicked(anInteractiveObject)In short, to do automatic annotation on the vir-tual guide?s corpus, it was sufficient to observe thesubsequent action to each utterance by looking fora change on any of the atoms shown above, andannotating and associating the corresponding reac-tion to the utterance and the valid atoms set whenit was said.4.2 Selecting what to sayThe virtual guide?s goal is to make the visitor visita number of given objectives, namely a set ofstands and interactive objects.
Using the virtualfairs discretization and taking the directed graphrepresentation we presented in Section 3, the vir-tual guide uses the A* algorithm to obtain a path,that is a sequence of actions, from its current po-sition to the region where the next objective is lo-cated.
In case the visitor got lost or simply tookan alternative path, the virtual guide recalculatesthe shortest path and proceeds to guide the visitorthrough it.1In quaternion representation40Clearly, in order to do this calculation it is criti-cal that every objective is reachable from any nodein the graph, so choosing a k parameter in the dis-cretization process must be done taking care ofthat.The virtual guide gives the visitor a new instruc-tion depending on next actions to perform usingthe selection algorithm taken from (Benotti andDenis, 2011a), shown in Algorithm 1.
The al-gorithm obtains set of utterances C, all of whichhave a reaction that corresponds to the sequenceof actions that the virtual guide wants the visitorto perform next.Algorithm 1 Virtual guide?s selection algorithmC ?
?action?
nextAction(currentObjective)for all Utterance U ?
Corpus doif action ?
U.Reaction thenC ?
C ?
Uend ifend for5 Evaluation resultsIn the evaluation process 11 evaluators partici-pated, completing the proposed visit to the virtualfair, each manipulating 9 interactive objects.
Eval-uators were also asked to complete a questionnaireafter the tour, in which we wanted to obtain severalsubjective metrics.
We were particularly interestedin the questions?
S1: I had difficulties identifying the objectsthat the system described for me?
S2: The Utterances sounded robotic?
S3: The system was repetitivewhere we previously supposed the virtual guidewould have better results than other virtual instruc-tors, if we consider the results showed in (Benottiand Denis, 2011a).We compared our virtual guide results with thetwo best symbolic systems built for another vir-tual environment, the GIVE-2 Challenge.
Thosesystems were NA from INRIA and SAAR fromUniversity of Saarland (see (Koller et al., 2010)).Furthermore, we checked if the virtual guide re-sults were similar to another virtual instructor, alsobuilt for GIVE-2, called OUR, in which generationby selection was applied to make natural languagegeneration possible.In Table 1 we show the results for each virtualinstructor in the three categories we are interested.We can see that the virtual guide obtained signif-icantly better results than the SAAR and NA andin questions S1, S2 and S3, as we had supposed.All three questions range from 1 (one) to 9 (nine),the lower the number the better the system (sincequestions are negative).Table 1: Results comparison between virtual guideand three GIVE-2 systemsQuestion NA SAAR OUR VPS1 4.1 4 3 1.81S2 5.2 4.75 3.6 1.82S3 6.55 6.3 5.4 26 Conclusions and future workIn this paper we described the construction of avirtual guide for a virtual fair with the purpose ofguiding visitors through the stands and to interac-tive objects located inside the fair.
Inmersive vir-tual fairs and expositions constitute a promisingway to promote such events.On our evaluation, the virtual guide had com-parable results than the virtual instructor GIVE-2implemented using generation by selection, usinga much smaller corpus.
Our guide got better re-sults that the two best performing symbolic sys-tems.
These results are preliminary, but also en-couraging.A possible extension of this work could be thatvirtual guide can continue to improve its behaviorby learning online when input from a human guideof the fair is available.
If more corpus is availablein this way the virtual guide could discard thoseutterances that do not lead most visitors to performthe intended reaction.As a result of this work we conclude that vir-tual guide met the basic functions of navigationand natural language generation that we expectedand that the resulting prototype is ready to bedeployed at the virtualization of events websitehttp://www.inixiavf.com/.ReferencesLuciana Benotti and Alexandre Denis.
2011a.
Givinginstructions in virtual environments by corpus basedselection.
In Proceedings of the SIGDIAL 201141Conference, SIGDIAL ?11, pages 68?77, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Luciana Benotti and Alexandre Denis.
2011b.
Pro-totyping virtual instructors from human-human cor-pora.
In Proceedings of the ACL-HLT 2011 Sys-tem Demonstrations, pages 62?67, Portland, Ore-gon, June.
Association for Computational Linguis-tics.Penelope Brown and Stephen Levinson.
1987.
Polite-ness: Some Universals in Language Usage.
Studiesin Interactional Sociolinguistics.
Cambridge Univer-sity Press.Sudeep Gandhe and David Traum.
2007a.
Creatingspoken dialogue characters from corpora without an-notations.
In Proceedings of 8th Conference in theAnnual Series of Interspeech Events, pages 2201?2204, Belgium.Sudeep Gandhe and David Traum.
2007b.
First stepstoward dialogue modelling from an un-annotatedhuman-human corpus.
In IJCAI Workshop onKnowledge and Reasoning in Practical DialogueSystems, Hyderabad, India.Dusan Jan, Antonio Roque, Anton Leuski, Jacki Morie,and David Traum.
2009.
A virtual tour guide forvirtual worlds.
In Proceedings of the 9th Interna-tional Conference on Intelligent Virtual Agents, IVA?09, pages 372?378, Berlin, Heidelberg.
Springer-Verlag.John F. Kelley.
1983.
An empirical methodology forwriting user-friendly natural language computer ap-plications.
In Proceedings of the SIGCHI Confer-ence on Human Factors in Computing Systems, CHI?83, pages 193?196, New York, NY, USA.
ACM.Alexander Koller, Kristina Striegnitz, Andrew Gargett,Donna Byron, Justine Cassell, Robert Dale, JohannaMoore, and Jon Oberlander.
2010.
Report on thesecond nlg challenge on generating instructions invirtual environments (give-2).
In Proceedings ofthe 6th International Natural Language GenerationConference, INLG ?10, pages 243?250, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Malay K. Pakhira.
2009.
A modified k-means algo-rithm to avoid empty clusters.
International Journalof Recent Trends in Engineering, 1(1):220?226.Bayan Abu Shawar and Eric Atwell.
2003.
Usingdialogue corpora to retrain a chatbot system.
InProceedings of the Corpus Linguistics Conference,pages 681?690, United Kingdom.Bayan Abu Shawar and Eric Atwell.
2005.
Usingcorpora in machine-learning chatbot systems.
vol-ume 10, pages 489?516.42
