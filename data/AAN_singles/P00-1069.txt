Word Sense Disambiguation by Learning from Unlabeled DataSeong-Bae Parky, Byoung-Tak Zhangyand Yung Taek KimzArticial Intelligence Lab (SCAI)School of Computer Science and EngineeringSeoul National UniversitySeoul 151-742, Koreayfsbpark,btzhangg@scai.snu.ac.krzytkim@cse.snu.ac.krAbstractMost corpus-based approaches tonatural language processing suerfrom lack of training data.
Thisis because acquiring a large num-ber of labeled data is expensive.This paper describes a learningmethod that exploits unlabeled datato tackle data sparseness problem.The method uses committee learn-ing to predict the labels of unla-beled data that augment the exist-ing training data.
Our experimentson word sense disambiguation showthat predictive accuracy is signi-cantly improved by using additionalunlabeled data.1 IntroductionThe objective of word sense disambiguation(WSD) is to identify the correct sense of aword in context.
It is one of the most criticaltasks in most natural language applications,including information retrieval, informationextraction, and machine translation.
Theavailability of large-scale corpus and variousmachine learning algorithms enabled corpus-based approach to WSD (Cho and Kim, 1995;Hwee and Lee, 1996; Wilks and Stevenson,1998),but a large scale sense-tagged corpusor aligned bilingual corpus is needed for acorpus-based approach.However, most languages except Englishdo not have a large-scale sense-tagged cor-pus.
Therefore, any corpus-based approachto WSD for such languages should considerthe following problems: There's no reliable and available sense-tagged corpus. Most words are sense ambiguous. Annotating the large corpora requireshuman experts, so that it is too expen-sive.Because it is expensive to construct sense-tagged corpus or bilingual corpus, many re-searchers tried to reduce the number of ex-amples needed to learn WSD (Atsushi et al,1998; Pedersen and Bruce, 1997).
Atsushi etal.
(Atsushi et al, 1998) adopted a selec-tive sampling method to use small number ofexamples in training.
They dened a train-ing utility function to select examples withminimum certainty, and at each training it-eration the examples with less certainty weresaved in the example database.
However, ateach iteration of training the similarity amongword property vectors must be calculated dueto their k-NN like implementation of trainingutility.While labeled examples obtained from asense-tagged corpus is expensive and time-consuming, it is signicantly easier to ob-tain the unlabeled examples.
Yarowsky(Yarowsky, 1995) presented, for the rst time,the possibility that unlabeled examples canbe used for WSD.
He used a learning algo-rithm based on the local context under theassumption that all instances of a word havethe same intended meaning within any xeddocument and achieved good results with onlya few labeled examples and many unlabeledones.
Nigam et al (Nigam et al, 2000) alsoshowed the unlabeled examples can enhancethe accuracy of text categorization.Attribute SubstanceGFUNC the grammatical function of wPARENT the word of the node modied by wSUBJECT whether or not PARENT of w has a subjectOBJECT whether or not PARENT of w has an objectNMODWORD the word of the noun modier of wADNWORD the head word of the adnominal phrase of wADNSUBJ whether or not the adnominal phrase of w has a subjectADNOBJ whether or not the adnominal phrase of w has an objectTable 1: The properties used to distinguish the sense of an ambiguous Korean noun w.In this paper, we present a new approachto word sense disambiguation that is basedon selective sampling algorithm with commit-tees.
In this approach, the number of train-ing examples is reduced, by determining byweighted majority voting of multiple classi-ers, whether a given training example shouldbe learned or not.
The classiers of the com-mittee are rst trained on a small set of la-beled examples and the training set is aug-mented by a large number of unlabeled exam-ples.
One might think that this has the pos-sibility that the committee is misled by unla-beled examples.
But, the experimental resultsconrm that the accuracy of WSD is increasedby using unlabeled examples when the mem-bers of the committee are well trained withlabeled examples.
We also theoretically showthat performance improvement is guaranteedby a mild requirement, i.e., the base classi-ers need to guess better than random selec-tion.
This is because the possibility misled byunlabeled examples is reduced by integratingoutputs of multiple classiers.
One advantageof this method is that it eectively performsWSD with only a small number of labeled ex-amples and thus shows possibility of buildingword sense disambiguators for the languageswhich have no sense-tagged corpus.The rest of this paper is organized as fol-lows.
Section 2 introduces the general proce-dure for word sense disambiguation and thenecessity of unlabeled examples.
Section 3 ex-plains how the proposed method works usingboth labeled and unlabeled examples.
Section4 presents the experimental results obtainedby using the KAIST raw corpus.
Section 5draws conclusions.2 Word Sense DisambiguationLet S 2 fs1; : : : ; skg be the set of possiblesenses of a word to be disambiguated.
Todetermine the sense of the word, we needto consider the contextual properties.
Letx =< x1; : : : ; xn> be the vector for rep-resenting selected contextual features.
If wehave a classier f(x; ) parameterized with ,then the sense of a word with property vec-tor x can be determined by choosing the mostprobable sense s:s= argmaxs2Sf(x; ):The parameters  are determined by trainingthe classier on a set of labeled examples, L =f(x1; s1); : : : ; (xN; sN)g.2.1 Property SetsIn general, the rst step of WSD is to extracta set of contextual features.
To select particu-lar properties for Korean, the language of ourcencern, the following characteristics shouldbe considered: Korean is a partially free-order language.The ordering information on the neigh-bors of the ambiguous word, therefore,does not give signicantly meaningful in-formation in Korean. In Korean, ellipses appear very oftenwith a nominative case or objective case.Therefore, it is di?cult to build a largescale database of labeled examples withcase markers.Considering both characteristics and re-sults of previous work, we select eight prop-erties for WSD of Korean nouns (Table 1).Three of them (PARENT, NMODWORD,ADNWORD) take morphological form astheir value, one (GFUNC) takes 11 values ofgrammatical functions1, and others take onlytrue or false.2.2 Unlabeled Data for WSDMany researchers tried to develop automatedmethods to reduce training cost in languagelearning and found out that the cost can bereduced by active learning which has controlover the training examples (Dagan and Engel-son, 1997; Liere and Tadepalli, 1997; Zhang,1994).
Though the number of labeled exam-ples needed is reduced by active learning, thelabel of the selected examples must be givenby the human experts.
Thus, active learn-ing is still expensive and a method for auto-matic labeling unlabeled examples is neededto have the learner automatically gather in-formation (Blum and Mitchell, 1998; Peder-sen and Bruce, 1997; Yarowsky, 1995).As the unlabeled examples can be obtainedwith ease without human experts it makesWSD robust.
Yarowsky (Yarowsky, 1995)presented the possibility of automatic label-ing of training examples in WSD and achievedgood results with only a few labeled exam-ples and many unlabeled examples.
On theother hand, Blum and Mitchell tried to clas-sify Web pages, in which the description ofeach example can be partitioned into distinctviews such as the words occurring on thatpage and the words occurring in hyperlinks(Blum and Mitchell, 1998).
By using bothviews together, they augmented a small setof labeled examples with a lot of unlabeledexamples.The unlabeled examples in WSD can pro-vide information about the joint probability1These 11 grammatical functions are fromthe parser, KEMTS (Korean-to-English MachineTranslation System) developed in Seoul National Uni-versity, Korea.distribution over properties but they also canmislead the learner.
However, the possibilityof being misled by the unlabeled examples isreduced by the committee of classiers sincecombining or integrating the outputs of sev-eral classiers in general leads to improvedperformance.
This is why we use active learn-ing with committees to select informative un-labeled examples and label them.3 Active Learning withCommittees for WSD3.1 Active Learning Using UnlabeledExamplesThe algorithm for active learning using unla-beled data is given in Figure 1.
It takes twosets of examples as inputs.
A Set L is the onewith labeled examples and D = fx1; : : : ;xTgis the one with unlabeled examples where xiis a property vector.
First of all, the trainingset L(1)j(1  j  M) of labeled examples isconstructed for each base classier Cj.
Thisis done by random resampling as in Bagging(Breiman, 1996).
Then, each base classierCjis trained with the set of labeled examplesL(1)j.After the classiers are trained on labeledexamples, the training set is augmented bythe unlabeled examples.
For each unlabeledexample xt2 D, each classier computes thesense yj2 S which is the label associated withit, where S is the set of possible sense of xt.The distribution W over the base classi-ers represents the importance weights.
Asthe distribution can be changed each iter-ation, the distribution in iteration t is de-noted by Wt.
The importance weight of clas-sier Cjunder distribution Wtis denoted byWt(j).
Initially, the base classiers have equalweights, so that Wt(j) = 1=M .The sense of the unlabeled example xtis de-termined by majority voting among Cj's withweight distribution W .
Formally, the sense ytof xtis predicted byyt(xt) = argmaxy2SXj:Cj(xt)=yWt(j):If most classiers believe that ytis the correctGiven an unlabeled example set D = fx1; : : : ;xTgand a labeled example set Land a word sense set S 2 fs1; : : : ; skg for xi,Initialize W1(j) =1M,where M is the number of classiers in thecommittee.Resample L(1)jfrom L for each classier Cj,where jL(1)jj = jLj as done in Bagging.Train base classier Cj(1  j  M) from L(1)j.For t = 1; : : : ; T :1.
Each Cjpredicts the sense yj2 S for xt2 D.Y =< y1; : : : ; yM>2.
Find the most likely sense ytfrom Y usingdistribution W :yt= argmaxy2SXj:Cj(xt)=yWt(j):3.
Sett=1 tt, wheret=No.
of Cj's whose predictions are not ytM:4.
Iftis larger than a certainty threshold ,then update Wt:Wt+1(j) =Wt(j)Zttif yj= yt1 otherwise,where Ztis a normalization constant.5.
Otherwise, every classier Cjis restructuredfrom new training set L(t+1)j:L(t+1)j= L(t)j+ f(xt; yt)g:Output the nal classier:f(x) = argmaxy2SXj:Cj(x)=yWT(j):Figure 1: The active learning algorithmwith committees using unlabeled examples forWSD.sense of xt, they need not learn xtbecausethis example makes no contribution to reducethe variance over the distribution of exam-ples.
In this case, instead of learning the ex-ample, the weight of each classier is updatedin such a way that the classiers whose pre-dictions were correct get a higher importanceweight and the classiers whose predictionswere wrong get a lower importance weightunder the assumption that the correct senseof xtis yt.
This is done by multiplying theweight of the classier whose prediction is ytby certaintyt.
To ensure the updated Wt+1form a distribution, Wt+1is normalized byconstant Zt.
Formally, the importance weightis updated as follows:Wt+1=Wt(j)Zttif yj= yt;1 otherwise.The certaintytis computed from error t.Because we trust that the correct sense of xtis yt, the error tis the ratio of the number ofclassiers whose predictions are not yt.
Thatis,tis computed ast=1  ttwhere tis given ast=No.
of Cj's whose predictions are not ytM:Note that the smaller t, the larger the valueoft.
This implies that, if the sense of xtis certainly ytand a classier predicts it, ahigher weight is assigned to the classier.
Weassume that most classiers believe that ytisthe sense of xtif the value of ytis larger thana certainty threshold  which is set by trial-and-error.However, if the certainty is below thethreshold, the classiers need to learn the ex-ample xtyet with belief that the sense of itis yt.
Therefore, the set of training examples,L(t)j, for the classier Cjis expanded byL(t+1)j= L(t)j+ f(xt; yt)g:Then, each classier Cjis restructured withL(t+1)j.This process is repeated until the unlabeledexamples are exhausted.
The sense of a newexample x is then determined by weightedmajority voting among the trained classiers:f(x) = argmaxy2SXj:Cj(x)=yWT(j);where WT(j) is the importance weight of clas-sier Cjafter the learning process.3.2 Theoretical AnalysisPrevious studies show that using multipleclassiers rather than a single classier leadsto improved generalization (Breiman, 1996;Freund et al, 1992) and learning algorithmswhich use weak classiers can be boostedinto strong algorithms (Freund and Schapire,1996).
In addition, Littlestone and Warmuth(Littlestone and Warmuth, 1994) showed thatthe error of the weighted majority algorithmis linearly bounded on that of the best mem-ber when the weight of each classier is de-termined by held-out examples.The performance of the proposed methoddepends on that of initial base classiers.This is because it is highly possible for unla-beled examples to mislead the learning algo-rithm if they are poorly trained in their initialstate.
However, if the accuracy of the initialmajority voting is larger than12, the proposedmethod performs well as the following theo-rem shows.Theorem 1 Assume that every unlabeleddata xtis added to the set of training ex-amples for all classiers and the importanceweights are not updated.
Suppose that p0bethe probability that the initial classiers donot make errors andt(0 t 1) be theprobability by which the accuracy is increasedin adding one more correct example or de-creased in adding one more incorrect exampleat iteration t. If p012, the accuracy doesnot decrease as a new unlabeled data is addedto the training data set.Proof.
The probability for the classiersto predict the correct sense at iteration t = 1,p1, isp1= p0(p0+0) + (1  p0)(p0 0)= p0(20+ 1) 0because the accuracy can be increased or de-creased by0with the probability p0and1   p0, respectively.
Therefore, without lossof generality, at iteration t = i+ 1, we havepi+1= pi(2i+ 1) i:To ensure the accuracy does not decrease, thecondition pi+1 pishould be satised.pi+1  pi= pi(2i+ 1) i  pi= pi(2i) i 0) pi12The theorem follows immediately from thisresult.
3.3 Decision Trees as Base ClassiersAlthough any kind of learning algorithmswhich meet the conditions for Theorem 1 canbe used as base classiers, Quinlan's C4.5 re-lease 8 (Quinlan, 1993) is used in this paper.The main reason why decision trees are usedas base classiers is that there is a fast restruc-turing algorithm for decision trees.
Adding anunlabeled example with a predicted label tothe existing set of training examples makesthe classiers restructured.
Because the re-structuring of classiers is time-consuming,the proposed method is of little practical usewithout an e?cient way to restructure.
Ut-go et al (Utgo et al, 1997) presented twokinds of e?cient algorithms for restructuringdecision trees and showed experimentally thattheir methods perform well with only smallrestructuring cost.We modied C4.5 so that word match-ing is accomplished not by comparing mor-phological forms but by calculating similar-ity between words to tackle data-sparsenessproblem.
The similarity between two Ko-rean words is measured by averaged distancein WordNet of their English-translated words(Kim and Kim, 1996).Word No.
of Senses No.
of Examples Sense Percentagepear 6.2%ship 55.2%bae 4 876times 13.7%stomach 24.9%person 46.2%bun 3 796 minute 50.8%indignation 3.0%the former 28.6%jonja 2 350electron 71.4%bridge 30.9%dari 2 498leg 69.1%Table 2: Various senses of Korean nouns used for the experiments and their distributions inthe corpus.4 Experiments4.1 Data SetWe used the KAIST Korean raw corpus2forthe experiments.
The entire corpus consistsof 10 million words but we used in this pa-per the corpus containing one million wordsexcluding the duplicated news articles.
Ta-ble 2 shows various senses of ambiguous Ko-rean nouns considered and their sense distri-butions.
The percentage column in the tabledenotes the ratio that the word is used withthe sense in the corpus.
Therefore, we canregard the maximum percentage as a lowerbound on the correct sense for each word.4.2 Experimental ResultsFor the experiments, 15 base classiers areused.
If there is a tie in predicting senses,the sense with the lowest order is chosen asin (Breiman, 1996).
For each noun, 90% ofthe examples are used for training and theremaining 10% are used for testing.Table 3 shows the 10-fold cross validationresult of WSD experiments for nouns listedin Table 2.
The accuracy of the proposedmethod shown in Table 3 is measured whenthe accuracy is in its best for various ratios ofthe number of labeled examples for base clas-siers to total examples.
The results show2This corpus is distributed by the Korea Termi-nology Research Center for Language and KnowledgeEngineering.that WSD by selective sampling with com-mittees using both labeled and unlabeled ex-amples is comparable to a single learner us-ing all the labeled examples.
In addition, themethod proposed in this paper achieves 26.3%improvement over the lower bound for `bae',41.5% for `bun', 22.1% for `jonja', and 4.2%for `dari', which is 23.6% improvement on theaverage.
Especially, for `jonja' the proposedmethod shows higher accuracy than the singleC4.5 trained on the whole labeled examples.Figure 2 shows the performance improvedby using unlabeled examples.
This guredemonstrates that the proposed method out-performs the one without using unlabeled ex-amples.
The initial learning in the guremeans that the committee is trained on la-beled examples, but is not augmented by un-labeled examples.
The dierence between twolines is the improved accuracy obtained byusing unlabeled examples.
When the accu-racy of the proposed method gets stabilizedfor the rst time, the improved accuracy byusing unlabeled examples is 20.2% for `bae',9.9% for `bun, 13.5% `jonja', and 13.4% for`dari'.
It should be mentioned that the resultsalso show that the accuracy of the proposedmethod may be dropped when the classiersare trained on too small a set of labeled data,as is the case in the early stages of Figure 2.However, in typical situations where the clas-siers are trained on minimum training setUsing Partially Using AllWordLabeled Data Labeled DataLower Boundbae 81.5  7.7% 82.3%  5.9% 55.2%bun 92.3  7.7% 94.3%  5.7% 50.8%jonja 93.5  6.5% 90.6%  9.4% 71.4%dari 73.3  14.2% 80.8  10.9% 69.1%Average 85.2% 87.0% 61.6%Table 3: The accuracy of WSD for Korean nouns by the proposed method.size, this does not happen as the results ofother nouns show.
In addition, we can nd inthis particular experiment that the accuracyis always improved by using unlabeled exam-ples if only about 22% of training examples,on the average, are labeled in advance.In Figure 2(a), it is interesting to observejumps in the accuracy curve.
The jump ap-pears because the unlabeled examples misleadthe classiers only when the classiers arepoorly trained, but they play an importantrole as information to select senses when theclassiers are well trained on labeled exam-ples.
Other nouns show similar phenomenathough the percentage of labeled examples isdierent when the accuracy getsat.5 ConclusionsIn this paper, we proposed a new methodfor word sense disambiguation that is basedon unlabeled data.
Using unlabeled data isespecially important in corpus-based naturallanguage processing because raw corpora areubiquitous while labeled data are expensiveto obtain.
In a series of experiments on wordsense disambiguation of Korean nouns we ob-served that the accuracy is improved up to20.2% using only 32% of labeled data.
Thisimplies, the learning model trained on a smallnumber of labeled data can be enhanced byusing additional unlabeled data.
We also the-oretically showed that the predictive accuracyis always improved if the individual classiersdo better than random selection after beingtrained on labeled data.As the labels of unlabeled data are es-timated by committees of multiple decisiontrees, the burden of manual labeling is min-imized by using unlabeled data.
Thus, theproposed method seems especially eectiveand useful for the languages for which a large-scale sense-tagged corpus is not available yet.Another advantage of the proposed methodis that it can be applied to other kinds oflanguage learning problems such as POS-tagging, PP attachment, and text classica-tion.
These problems are similar to wordsense disambiguation in the sense that unla-beled raw data are abundant but labeled dataare limited and expensive to obtain.AcknowledgementsThis research was supported in part by theKorean Ministry of Education under theBK21 Program and by the Korean Ministryof Information and Communication throughIITA under grant 98-199.ReferencesF.
Atsushi, I. Kentaro, T. Takenobu, andT.
Hozumi.
1998.
Selective sampling of ef-fective example sentence sets for word sensedisambiguation.
Computational Linguistics,24(4):573{597.A.
Blum and T. Mitchell.
1998.
Combining la-beled and unlabeled data with co-training.
InProceedings of COLT-98, pages 92{100.L.
Breiman.
1996.
Bagging predictors.
MachineLearning, 24:123{140.J.-M. Cho and G.-C. Kim.
1995.
Korean verbsense disambiguation using distributional infor-mation from corpora.
In Proceedings of NaturalLanguage Processing Pacic Rim Symposium,pages 691{696.I.
Dagan and S. Engelson.
1997.
Committee-based sampling for training probabilistic classi-505560657075808510 20 30 40 50 60 70 80 90 100Accuracy(%)Ratio of The Number of Labeled Examples to The Number of Total Examples (%)Initial LearningThe Proposed Method(a) bae40506070809010 20 30 40 50 60 70 80 90 100Accuracy(%)Ratio of The Number of Labeled Examples to The Number of Total Examples (%)Initial LearningThe Proposed Method(b) bun203040506070809010 20 30 40 50 60 70 80 90 100Accuracy(%)Ratio of The Number of Labeled Examples to The Number of Total Examples (%)Initial LearningThe Proposed Method(c) jonja30405060708010 20 30 40 50 60 70 80 90 100Accuracy(%)Ratio of The Number of Labeled Examples to The Number of Total Examples (%)Initial LearningThe Proposed Method(d) dariFigure 2: Improvement in accuracy by using unlabeled examples.ers.
In Proceedings of the Fourteenth Interna-tional Conference on Machine Learning, pages150{157.Y.
Freund and R. Schapire.
1996.
Experimentswith a new boosting algorithm.
In Proceedingsof the Thirteenth International Conference onMachine Learning, pages 148{156.Y.
Freund, H. Seung, E. Shamir, and N. Tishby.1992.
Selective sampling with query by com-mittee algorithm.
In Proceedings of NIPS-92,pages 483{490.T.
Hwee and H. Lee.
1996.
Integrating multipleknowledge sources to disambiguate word sense:An exemplar-based approach.
In Proceedingsof the 34th Annual Meeting of the ACL, pages40{47.Nari Kim and Y.-T. Kim.
1996.
Ambiguity reso-lution of korean sentence analysis and korean-english transfer based on korean verb patterns.Journal of KISS, 23(7):766{775. in Korean.R.
Liere and P. Tadepalli.
1997.
Active learn-ing with committees for text categorization.
InProceedings of AAAI-97, pages 591{596.N.
Littlestone and M. Warmuth.
1994.
Theweighted majority algorithm.
Information andComputation, 108(2):212{261.K.
Nigam, A. McCallum, S. Thrun, andT.
Mitchell.
2000.
Learning to classify textfrom labeled and unlabeled documents.
Ma-chine Learning, 39:1{32.T.
Pedersen and R. Bruce.
1997.
Distinguishingword senses in untagged text.
In Proceedings ofthe Second Conference on Empirical Methods inNatural Language Processing, pages 399{401.R.
Quinlan.
1993.
C4.5: Programs For MachineLearning.
Morgan Kaufmann Publishers.P.
Utgo, N. Berkman, and J. Clouse.
1997.
De-cision tree induction based on e?cient tree re-structuring.
Machine Learning, 29:5{44.Y.
Wilks andM.
Stevenson.
1998.
Word sense dis-ambiguation using optimised combinations ofknowledge sources.
In Proceedings of COLING-ACL '98, pages 1398{1402.D.
Yarowsky.
1995.
Unsupervised word sense dis-ambiguation rivaling supervised methods.
InProceedings of the 33rd Annual Meeting of theACL, pages 189{196.B.-T. Zhang.
1994.
Accerlated learning by ac-tive example selection.
International Journalof Neural Systems, 5(1):67{75.
