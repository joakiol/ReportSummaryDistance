Resolving Translation Ambiguity and Target Polysemyin Cross-Language Information RetrievalHsin-Hsi Chen, Guo-Wei Bian and Wen-Cheng LinDepartment ofComputer Science and Information EngineeringNational Taiwan University,Taipei, TAIWAN, R.O.C.E-mail: hh_chen@csie.ntu.edu.tw, {g bian, denislin}@nlg2.csie.ntu.edu.twAbstractThis paper deals with translation ambiguity andtarget polysemy problems together.
Twomonolingual balanced corpora are employed tolearn word co-occurrence for translationambiguity resolution, and augmented translationrestrictions for target polysemy resolution.Experiments show that the model achieves62.92% of monolingual information retrieval, andis 40.80% addition to the select-all model.Combining the target polysemy resolution, theretrieval performance is about 10.11% increase tothe model resolving translation ambiguity only.1.
IntroductionCross language information retrieval (CLIR)(Oard and Dorr, 1996; Oard, 1997) deals with theuse of queries in one language to accessdocuments in another.
Due to the differencesbetween source and target languages, querytranslation is usually employed to unify thelanguage in queries and documents.
In querytranslation, translation ambiguity is a basicproblem to be resolved.
A word in a sourcequery may have more than one sense.
Wordsense disambiguation identifies the correct senseof each source word, and lexical selectiontranslates it into the corresponding target word.The above procedure is similar to lexical choiceoperation in a traditional machine translation (MT)system.
However, there is a significantdifference between the applications of MT andCLIR.
In MT, readers interpret he translatedresults.
If the target word has more than onesense, readers can disambiguate its meaningautomatically.
Comparatively, the translatedresult is sent to a monolingual informationretrieval system in CLIR.
The target polysemyadds extraneous senses and affects the retrievalperformance.Some different approaches have been proposedfor query translation.
Dictionary-based approachexploits machine-readable dictionaries andselection strategies like select all (Hull andGrefenstette, 1996; Davis, 1997), randomly selectN (Ballesteros and Croft, 1996; Kwok 1997) andselect best N (Hayashi, Kikui and Susaki, 1997;Davis 1997).
Corpus-based approaches exploitsentence-aligned corpora (Davis and Dunning,1996) and document-aligned corpora (Sheridanand Ballerini, 1996).
These two approaches arecomplementary.
Dictionary provides translationcandidates, and corpus provides context to fit userintention.
Coverage of dictionaries, alignmentperformance and domain shift of corpus are majorproblems of these two approaches.
Hybridapproaches (Ballesteros and Croft, 1998; Bian andChen, 1998; Davis 1997) integrate both lexicaland corpus knowledge.All the above approaches deal with thetranslation ambiguity problem in query translation.Few touch on translation ambiguity and targetpolysemy together.
This paper will study themultiplication effects of translation ambiguity andtarget polysemy in cross-language informationretrieval systems, and propose a new translationmethod to resolve these problems.
Section 2shows the effects of translation ambiguity andtarget polysemy in Chinese-English and English-Chinese information retrievals.
Section 3presents several models to revolve translationambiguity and target polysemy problems.Section 4 demonstrates the experimental results,and compares the performances of the proposedmodels.
Section 5 concludes the remarks.2.
Effects of AmbiguitiesTranslation ambiguity and target polysemy aretwo major problems in CLIR.
Translationambiguity results from the source language, andtarget polysemy occurs in target language.
TakeChinese-English information retrieval (CEIR) andEnglish-Chinese information retrieval (ECIR) asexamples.
The former uses Chinese queries to215Table 1.
Statistics of Chinese and English ThesaurusEnglish ThesaurusChinese ThesaurusTotal Words  Average # of Senses Average # ofSensesfor Top 1000Words29,380 !.687 3.52753,780 1.397 1.504retrieve English documents, while the lateremploys English queries to retrieve Chinesedocuments.
To explore the difficulties in thequery translation of different languages, we gatherthe sense statistics of English and Chinese words.Table 1 shows the degree of word sense ambiguity(in terms of number of senses) in English and inChinese, respectively.
A Chinese thesaurus, i.e.,~~$~k (tong2yi4ci2ci21in2), (Mei, et al,1982) and an English thesaurus, i.e., Roget'sthesaurus, are used to count the statistics of thesenses of words.
On the average, an Englishword has 1.687 senses, and a Chinese word has1.397 senses.
If the top 1000 high frequentwords are considered, the English words have3.527 senses, and the bi-character Chinese wordsonly have 1.504 senses.
In summary, Chineseword is comparatively unambiguous, so thattranslation ambiguity is not serious but targetpolysemy is serious in CEIR.
In contrast, anEnglish word is usually ambiguous.
Thetranslation disambiguation is important in ECIR.Consider an example in CEIR.
The Chineseword ",~,It" (yin2hang2) is unambiguous, but itsEnglish translation "bank" has 9 senses (Longman,1978).
When the Chinese word " ,~ 45- "(yin2hang2) is issued, it is translated into theEnglish counterpart "bank" by dictionary lookupwithout difficulty, and then "bank" is sent o an IRsystem.
The IR system will retrieve documentsthat contain this word.
Because "bank" is notdisambiguated, irrelevant documents will bereported.
On the contrary, when "bank" issubmitted to an ECIR system, we mustdisambiguate itsmeaning at first.
If we can findthat its correct ranslation is "-~g-#5"" (yin2hang2),the subsequent operation is very simple.
That is,"~'~5-" (yin2hang2) is sent into an IR system, andthen documents containing "~l~5"" (yin2hang2)will be presented.
In this example, translationdisambiguation should be done rather than targetpolysemy resolution.The above examples do not mean translationdisambiguation is not required in CEIR.
SomeChinese words may have more than one sense.For example, "k-~ ~ " (yun4dong4) has thefollowing meanings (Lai and Lin, 1987): (1) sport,(2) exercise, (3) movement, (4) motion, (5)campaign, and (6) lobby.
Each correspondingEnglish word may have more than one sense.For example, "exercise" may mean a question orset of questions to be answered by a pupil forpractice; the use of a power or right; and so on.The multiplication effects of translation ambiguityand target polysemy make query translationharder.3.
Translation Ambiguity and PolysemyResolution ModelsIn the recent works, Ballesteros and Croft(1998), and Bian and Chen (1998) employdictionaries and co-occurrence statistics trainedfrom target language documents to deal withtranslation ambiguity.
We will follow ourprevious work (Bian and Chen, 1998), whichcombines the dictionary-based and corpus-basedapproaches for CEIR.
A bilingual dictionaryprovides the translation equivalents of each queryterm, and the word co-occurrence informationtrained from a target language text collection isused to disambiguate the translation.
Thismethod considers the content around thetranslation equivalents to decide the best targetword.
The translation of a query term can bedisambiguated using the co-occurrence of thetranslation equivalents of this term and otherterms.
We adopt mutual information (Church, etal., 1989) to measure the strength.
Thisdisambiguation method performs goodtranslations even when the multi-term phrases arenot found in the bilingual dictionary, or thephrases are not identified in the source language.Before discussion, we take Chinese-Englishinformation retrieval as an example to explain ourmethods.
Consider the Chinese query ",~I~'~5-"(yin2hang2) to an English collection again.
Theambiguity grows from none (source side) to 9senses (target side) during query translation.How to incorporate the knowledge from sourceside to target side is an important issue.
Toavoid the problem of target polysemy in query216translation, we have to restrict he use of a targetword by augmenting some other words thatusually co-occur with it.
That is, we have tomake a context for the target word.
In ourmethod, the contextual information is derivedfrom the source word.We collect the frequently accompanying nounsand verbs for each word in a Chinese corpus.Those words that co-occur with a given wordwithin a window are selected.
The wordassociation strength of a word and itsaccompanying words is measured by mutualinformation.
For each word C in a Chinesequery, we augment i with a sequence of Chinesewords trained in the above way.
Let these wordsbe CW~, CW2, ..., and CWm.
Assume thecorresponding English translations of C, CW~,CW2, ..., and CWm are E, EW,, EW2, ..., and EWm,respectively.
EWe, EW2, ..., and EWm form anaugmented translation restriction of E for C. Inother words, the list (E, EW1, EW2, ..., EWm) iscalled an augmented translation result for C.EWe, EWe, ..., and EWm are a pseudo Englishcontext produced from Chinese side.
Considerthe Chinese word "~I~gS"" (yin2hang2).
Somestrongly co-related Chinese words in ROCLINGbalanced corpus (Huang, et al, 1995) are: "I!.g.~,"(tie 1 xian4), "~ ~"  (ling3chu 1), "_-~_.
~"  (li3ang2),"~ 1~" (yalhui4), ";~ ~"  (hui4dui4), etc.
Thusthe augmented translation restriction of "bank" is(rebate, show out, Lyons, negotiate, transfer, ...).Unfortunately, the query translation is not sosimple.
A word C in a query Q may beambiguous.
Besides, the accompanying wordsCW~ (1 < i < m) trained from Chinese corpus maybe translated into more than one English word.An augmented translation restriction may adderroneous patterns when a word in a restrictionhas more than one sense.
Thus we devise severalmodels to discuss the effects of augmentedrestrictions.
Figure 1 shows the different modelsand the model refinement procedure.
A Chinesequery may go through translation ambiguityresolution module (left-to-right), target polysemyresolution module (top-down), or both (i.e., thesetwo modules are integrated at the right corner).In the following, we will show how each moduleis operated independently, and how the twomodules are combined.For a Chinese query which is composed of nwords C~, C2, ..., Ca, find the correspondingEnglish translation equivalents in a Chinese-English bilingual dictionary.
To discuss thepropagation errors from translation ambiguityresolution part in the experiments, we consider thefollowing two alternatives:(a) select all (do-nothing)The strategy does nothing on the translationdisambiguation.
All the English translationequivalents for the n Chinese words are selected,and are submitted to a monolingual informationretrieval system.
(b) co-occurrence model (Co-Model)We adopt the strategy discussed previouslyfor translation disambiguation (Bian and Chen,1998).
This method considers the contentaround the English translation equivalents todecide the best target equivalent.For target polysemy resolution part in Figure 1,we also consider two alternatives.
In the firstalternative (called A model), we augmentrestrictions to all the words no matter whetherthey are ambiguous or not.
In the secondalternative (called U model), we neglect hose Csthat have more than one English translation.Assume Co~), C~2) .... , Co~p) (p < n) have only oneEnglish translation.
The restrictions areaugmented toCo~), C~2) ..... Co~p) only.
We applythe above corpus-based method to find therestriction for each English word selected by thetranslation ambiguity resolution model.
Recallthat the restrictions are derived from Chinesecorpus.
The accompanying words trained fromChinese corpus may be translated into more thanone English word.
Here, the translationambiguity may occur when translating therestrictions.
Three alternatives are considered.In U1 (or A1) model, the terms without ambiguity,i.e., Chinese and English words are one-to-onecorrespondent in a Chinese-English bilingualdictionary, are added.
In UT (or AT) model, th/~terms with the same parts of speech (POSes) areadded.
That is, POS is used to select Englishword.
In UTT (or ATT) model, we use mutualinformation to select op 10 accompanying termsof a Chinese query word, and POS is used toobtain the augmented translation restriction.217Chinese Query IC~, C2 ..... CnTarget Polysemy ResolutionA MOdel__~ Chinese Query \[Ct, C2 ..... CnTranslation Ambiguity ResolutionSelect All(baseline)Co Model(Co-occurrence model)English Query } ~(Eu,., Eth), (E21, .
E2t,) ..... (Enl,.., Ent,)English Query"1 EL, E2, ..., EnChinese Restriction{CWll... CWt~j,{CW21.., CW2m:} .....{CW.t ..... CWm)TranslatedEnglish Restriction{EW.
.
.
.
.
.
ZWlk 0,I tzw2, ...... EW~k~} ....\[ {EW., ..... EW*k}A1 Model ..j(Unique Translation) "IAT Model ~j(POS Tag Matched) "tATT Model k\[(Top 10 & POS Tag Matched)tER-A 1 IER-AT \] !ER.A  \] IArgumentedEnglish QueryEl, {EWij }U Model UI Model "J ER-U1 I \[ ~ ~(Unique Translation) vl I , ~Chinese Query(1) Only one English Translation: ~ Chinese RestrictionC o(I), Ca(2) .... , Co(p)  {CWotl) Z ..... CWo(l)ml} ' UT Model "J ER-UT \] ~ \ ]~ ' -~(2) More than one English Translation: " {CWof2)t{CWa(p) I ..... .. CWo(2)m.,}C~/a(p) raF~ ..... (POS Tag Matched) "l I/ C a(~-i~, C o(p+2) ..... C o{.)
~.
UTT Model ~l ER-UTT I(Top 10 & POS Tag Matched)lXFigure 1.
Models for Translation Ambiguity and Target Polysemy ResolutionIn the above treatment, a word C~ in a query Qis translated into (Ei, EWil, EWi2 .
.
.
.
, EWimi).
Eiis selected by Co-Model, and EWi~, EWi2 .
.
.
.
,EWimi are augmented by different target polysemyresolution models.
Intuitively, Ei, EWil, EWi2 .. .
.
,EWim~ should have different weights.
Ei isassigned a higher weight, and the words EWil,EWi2 ..... Eim~ in the restriction are assigned lowerweights.
They are determined by the followingformula, where n is number of words in Q and mkis the number of words in a restriction for Ek.1 weight(Ei) -n+l1weight(EWij) = n(n + 1) * E mkk=lThus six new models, i.e., A1W, ATW, ATTW,U1W, UTW and UTTW, are derived.
Finally,we apply Co-model again to disambiguate thepseudo contexts and devise six new models(A1WCO, ATWCO, ATTWCO, U1WCO,UTWCO, and UTTWCO).
In these six models,only one restriction word will be selected from thewords  EWil, EWiz, ..., EWim i via disambiguationwith other estrictions.4.
Experimental ResultsTo evaluate the above models, we employTREC-6 text collection, TREC topics 301-350(Harman, 1997), and Smart information retrievalsystem (Salton and Buckley, 1988).
The textcollection contains 556,077 documents, and isabout 2.2G bytes.
Because the goal is toevaluate the performance of Chinese-Englishinformation retrieval on different models, wetranslate the 50 English queries into Chinese byhuman.
The topic 332 is considered as anexample in the following.
The original Englishversion and the human-translated Chinese versionare shown.
A TREC topic is composed ofseveral fields.
Tags <num>, <title>, <des>, and<narr> denote topic number, title, description, andnarrative fields.
Narrative provides a completedescription of document relevance for the218assessors.
In our experiments, only the fields oftitle and description are used to generate queries.<top><num> Number: 332<title> Income Tax Evasion<desc> Description:This query is looking for investigations that havetargeted evaders of U.S. income tax.<narr> Narrative:A relevant document would mention investigationseither in the U.S. or abroad of people suspected of evadingU.S.
income tax laws.
Of particular interest areinvestigations involving revenue from illegal activities, asa strategy to bring known or suspected criminals to justice.</top><top><num> Number: 332<C-title><C-desc> Description:<C-narr> Narrative:.~l~ ~.&.~-~-  ?
:~,J-~, ~ ~ ~ - ~  ~ ~.~-~ ,</top>Totally, there are 1,017 words (557 distinctwords) in the title and description fields of the 50translated TREC topics.
Among these, 401words have unique translations and 616 wordshave multiple translation equivalents in ourChinese-English bilingual dictionary.
Table 2shows the degree of word sense ambiguity inEnglish and in Chinese, respectively.
On theaverage, an English query term has 2.976 senses,and a Chinese query term has 1.828 senses only.In our experiments, LOB corpus is employed totrain the co-occurrence statistics for translationambiguity resolution, and ROCLING balancedcorpus (Huang, et al, 1995) is employed to trainthe restrictions for target polysemy resolution.The mutual information tables are trained using awindow size 3 for adjacent words.Table 3 shows the query translation of TRECtopic 332.
For the sake of space, only title fieldis shown.
In Table 3(a), the first two rows listthe original English query and the Chinese query.Rows 3 and 4 demonstrate the English translationby select-all model and co-occurrence model byresolving translation ambiguity only.
Table 3(b)shows the augmented translation results usingdifferent models.
Here, both translationambiguity and target polysemy are resolved.The following lists the selected restrictions in A1model.i~_~(evasion): ~ .~_N (N: poundage), ~/t~_N (N:scot), ~ .
tkV  (V: stay)?~-(income): I~g~_N (N: quota)~(tax): i /~_V (N: evasion), I~_N (N:surtax), ~t~,_N (N: surplus), ,g '~_N (N: sales tax)Augmented translation restrictions (poundage,scot, stay), (quota), and (evasion, surtax, surplus,sales tax) are added to "evasion", "income", and"tax", respectively.
From Longman dictionary,we know there are 3 senses, 1 sense, and 2 sensesfor "evasion", "income", and "tax", respectively.Augmented restrictions are used to deal withtarget polysemy problem.
Compared with A1model, only "evasion" is augmented with atranslation restriction in U1 model.
This isbecause " "~ ~ " (tao21uo4) has only onetranslation and "?~-"  (suo3de2) and "~"  (sui4)have more than one translation.
Similarly, theaugmented translation restrictions are omitted inthe other U-models.
Now we consider ATmodel.
The Chinese restrictions, which have thematching POSes, are listed below:i~  (evasion):~_N (N: poundage), ~l~t~0~,_N (N: scot), L~_V (V:stay), ~N (N: droit, duty, geld, tax), li~l~f~ N (N:custom, douane, tariff), /~.~ V (V: avoid, elude,wangle, welch, welsh; N: avoidance, elusion, evasion,evasiveness, miss, runaround, shirk, skulk), i.~)~_V(V: contravene, infract, infringe; N: contravention,infraction, infringement, sin, violation)~" ~- (income):~_V (V: impose; N: division), ~.&~,_V (V: assess, put,tax; N: imposition, taxation), ~A~_N (N: Swiss,Switzer), i~_V  (V: minus, subtract), I~I\[$~_N (N:quota), I~l ~_N (N: commonwealth, folk, land, nation,nationality, son, subject)(tax):I~h~_N (N: surtax), .~t~g, N (N: surplus), ~ '~_N (N: sales tax), g~V (V: abase, alight, debase,descend), r~_N (N: altitude, loftiness, tallness; ADJ:high; ADV: loftily), ~V (V: comprise, comprize,embrace, ncompass), -~V (V: compete, mulate, vie;N: conflict, contention, duel, strife)Table  2.
Statistics o f  TREC Topics  301-350# of Distinct Words Average # of SensesOriginal English Topics 500 (370 words found in our dictionary) 2.976Human-translated Chinese Topics 557 (389 words found in our dictionary) 1.828219Table 3.
Query Translation of Title Field of TREC Topic 332(a) Resolving Translation Ambiguity Onlyoriginal English query income tax evasionChinese translation by human ~ (tao21uo4) ?~- (suo3de2) $~, (sui4)by select all model (evasion), (earning, finance, income, taking), (droit, duty, geld, tax)by co-occurrence model evasion, income, tax(b) Resolving both Translation Ambiguity and Target Polysemyby AI modelby UI modelby AT modelby UT model:by ATT modelby UTT modelb-y ATWCO modelby UTWCO modelby ATTWCO modelby UTTWCO model(evasion, poundage, scot, stay), (income, quota),(tax, evasion, surtax, surplus, ales tax)(evasion, poundage, scot, stay), (income), (tax)(evasion; poundage; scot; stay; droit, duty, geld, tax; custom, douane, tariff; avoid, elude, wangle,welch, welsh; contravene, infract, infringe), (income; impose; assess, put, tax; Swiss, Switzer; minussubtract; quota; commonwealth, folk, land, nation, nationality, son, subject),(tax; surtax; surplus; sales tax; abase, alight, debase, descend; altitude, loftiness, tallness; comprise,comprize, mbrace, ncompass; compete, mulate, vie)(evasion; poundage, scot, stay, droit, duty, geld, tax, custom, douane, tariff, avoid, elude, wangle, welch,welsh, contravene, infract, infringe), (income), (tax)(evasion, poundage, scot, stay, droit, duty, geld, tax, custom, douane, tariff), (income), (tax)(evasion, poundage, scot, stay, droit, duty, geld, tax, custom, douane, tariff), (income), (tax)(evasion, tax), (income, land), (tax, surtax)(evasion, poundage), (income), (tax)(evasion, tax), (income), (tax)(evasion, poundage), (income), (tax)Those English words whose POSes are thesame as the corresponding Chinese restrictions areselected as augmented translation restriction.For example, the translation o f "~"_V  (tao2bi4)has two possible POSes, i.e., V and N, so only"avoid", "elude", "wangle", "welch", and "welsh"are chosen.
The other terms are added in thesimilar way.
Recall that we use mutualinformation to select the top 10 accompanyingterms of a Chinese query term in ATT model.The 5 ~ row shows that the augmented translationrestrictions for "?
)i"~-" (suo3de2) and "~," (sui4)are removed because their top 10 Chineseaccompanying terms do not have Englishtranslations of the same POSes.
Finally, weconsider ATWCO model.
The words "tax","land", and "surtax" are selected from the threelists in 3 rd row of Table 3(b) respectively, by usingword co-occurrences.Figure 2 shows the number of relevantdocuments on the top 1000 retrieved documentsfor Topics 332 and 337.
The performances arestable in all of the +weight (W) models and theenhanced CO restriction (WCO) models, eventhere are different number of words in translationrestrictions.
Especially, the enhanced COrestriction models add at most one translatedrestriction word for each query tenn.
They canachieve the similar performance to those modelsthat add more translated restriction words.Surprisingly, the augmented translation resultsmay perform better than the monolingual retrieval.Topic 337 in Figure 2 is an example.Table 4 shows the overall performance of 18different models for 50 topics.
Eleven-pointaverage precision on the top 1000 retrieveddocuments i adopted to measure the performanceof all the experiments.
The monolingualinformation retrieval, i.e., the original Englishqueries to English text collection, is regarded as abaseline model.
The performance is 0.1459under the specified environment.
The select-allmodel, i.e., all the translation equivalents arepassed without disambiguation, has 0.0652average precision.
About 44.69% of theperformance of the monolingual informationretrieval is achieved.
When co-occurrencemodel is employed to resolve translationambiguity, 0.0831 average precision (56.96% ofmonolingual information retrieval) is reported.Compared to do-nothing model, the performanceis 27.45% increase.Now we consider the treatment of translationambiguity and target polysemy together.Augmented restrictions are formed in A1, AT,ATT, U1, UT and UTT models, however, theirperformances are worse than Co-model(translation disambiguation only).
The major220Figure 2.
The Retrieved Performances ofTopics 332 and 3379080706050403020100# of relevant documents are retrieved- ~ < <model =.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Table 4.
Performance ofDifferent Models (11-point Average Precision)+ 3 3 2-= - ,7  I;MonolingualIRResolving ResolvingTranslation Ambiguity Translation Ambiguity and Target PolysemyS?
!e6( English .... UnambigU~ W6rds All W0rdsAll Co Mode!
UI L IT  UTT A i  AT ATTi i i ' i i .
.
.
.
i .
.
.
.
.
i i i' i i i i0.0797 0.0574 0.0709 .... 0.0674 0.0419 " 0.0660(54.63%) (39.34%) (48.59% (46.20%) (28.72%) (45.24%0.1459 0.0652 0.0831(44.69%) (56.96%),, U!WCO UTWCO~ !UTTWCO A1WCO A~W.CO0.0916 0.0915 0.0914 0.0914 0.0913 0.0914(62.78%) (62.71%) (62.65%) (62.65%) (62.58%), (62.65%)~ Weight, E~lishi~0 M0d~i for ?
Weighti English CoMod~l forResection Translation Res~ietion TranslationATTWCO0.0918 0.0917 0.0915 0 .0917 0.0917 0.0915(62.92%) (62.85%) (62.71%) (62.85%) (62.85%) (62.71%)reason is the restrictions may introduce errors.That can be found from the fact that models U 1,UT, and UTT are better than A1, AT, and ATT.Because the translation of restriction from sourcelanguage (Chinese) to target language (English)has the translation ambiguity problem, the models(U1 and A1) introduce the unambiguousrestriction terms and perform better than othermodels.
Controlled augmentation shows higherperformance than uncontrolled augmentation.When different weights are assigned to theoriginal English translation and the augmentedrestrictions, all the models are improvedsignificantly.
The performances of A1W, ATW,ATTW, U1W, UTW, and UTTW are about10.11% addition to the model for translationdisambiguation only.
Of these models, theperformance change from model AT to modelATW is drastic, i.e., from 0.0419 (28.72%) to0.0913 (62.58%).
It tells us the original Englishtranslation plays a major role, but the augmentedrestriction still has a significant effect on theperformance.We know that restriction for each Englishtranslation presents a pseudo English context.Thus we apply the co-occurrence model again onthe pseudo English contexts.
The performancesare increased a little.
These models add at mostone translated restriction word for each queryterm, but their performances are better than thosemodels that adding more translated restrictionwords.
It tells us that a good translatedrestriction word for each query term is enough forresolving target polysemy problem.
U1WCO,which is the best in these experiments, gains62.92% of monolingual information retrieval, and40.80% increase to the do-nothing model (select-all).2215.
Concluding RemarksThis paper deals with translation ambiguity andtarget polysemy at the same time.
We utilizetwo monolingual balanced corpora to learn usefulstatistical data, i.e., word co-occurrence fortranslation ambiguity resolution, and translationrestrictions for target polysemy resolution.Aligned bilingual corpus or special domain corpusis not required in this design.
Experiments howthat resolving both translation ambiguity andtarget polysemy gains about 10.11% performanceaddition to the method for translationdisambiguation in cross-language informationretrieval.
We also analyze the two factors: wordsense ambiguity in source language (translationambiguity), and word sense ambiguity in targetlanguage (target polysemy).
The statistics ofword sense ambiguities have shown that targetpolysemy resolution is critical in Chinese-Englishinformation retrieval.This treatment is very suitable to translate veryshort query on Web, The queries on Web are1.5-2 words on the average (Pinkerton, 1994;Fitzpatrick and Dent, 1997).
Because the majorcomponents of queries are nouns, at least oneword of a short query of length 1.5-2 words isnoun.
Besides, most of the Chinese nouns areunambiguous, so that translation ambiguity is notserious comparatively, but target polysemy iscritical in Chinese-English Web retrieval.
Thetranslation restrictions, which introduce pseudocontexts, are helpful for target polysemyresolution.
The applications of this method tocross-language Internet searching, theapplicability of this method to other languagepairs, and the effects of human-computerinteraction on resolving translation ambiguity andtarget polysemy will be studied in the future.ReferencesBallesteros, L. and Croft, W.B.
(1996) "Dictionary-basedMethods for Cross-Lingual Information Retrieval.
"Proceedings of the 7 h International DEXA Conference onDatabase and Expert Systems Applications, 791-801.Ballesteros, L. and Croft, W.B.
(1998) "Resolving Ambiguityfor Cross-Language Retrieval."
Proceedings of 21"' ACMSIGIR, 64-71.Bian, G.W.
and Chen, H.H.
(1998) "Integrating QueryTranslation and Document Translation in a Cross-Language Information Retrieval System."
MachineTranslation and Information Soup, Lecture Notes inComputer Science, No.
1529, Spring-Verlag, 250-265.Church, K. et al (1989) "Parsing, Word Associations andTypical Predicate-Argument Relations."
Proceedings ofInternational Workshop on Parsing Technologies, 389-398.Davis, M.W.
(1997) "New Experiments in Cross-LanguageText Retrieval at NMSU's Computing Research Lab.
"Proceedings of TREC 5, 39-1-39-19.Davis, M.W.
and Dunning, T. (1996) "A TREC Evaluation ofQuery Translation Methods for Multi-lingual TextRetrieval."
Proceedings of TREC-4, 1996.Fitzpatrick, L. and Dent, M. (1997) "Automatic FeedbackUsing Past Queries: Social Searching. "
Proceedings of2ff h ACM SIGIR, 306-313.Harman, D.K.
(1997) TREC-6 Proceedings, Gaithersburg,Maryland.Hayashi, Y., Kikui, G, and Susaki, S. (1997) "TITAN: ACross-linguistic Search Engine for the WWW."
WorkingNotes of AAAI-97 Spring Symposiums on Cross-LanguageText and Speech Retrieval, 58-65.Huang, C.R., et al (1995) "Introduction to Academia SinicaBalanced Corpus. "
Proceedings of ROCLING VIII,Taiwan, 81-99.Hull, D.A.
and Grefenstette, G. (1996) "Querying AcrossLanguages: A Dictionary-based Approach to MultilingualInformation Retrieval."
Proceedings of the 19 'h ACMSIGIR, 49-57.Kowk, K.L.
(1997) "Evaluation of an English-Chinese Cross-Lingual Retrieval Experiment."
Working Notes of AAAI-97Spring Symposiums on Cross-Language Text and SpeechRetrieval, i 10-114.Lai, M. and Lin, T.Y.
(1987) The New Lin Yutang Chinese-English Dictionary.
Panorama Press Ltd, Hong Kong.Longman (1978) Longman Dictionary of ContemporaryEnglish.
Longman Group Limited.Mei, J.; et al (1982) tong2yi4ci2ci2lin2.
ShanghaiDictionary Press.Oar& D.W. (1997) "Alternative Approaches for Cross-Language Text Retrieval."
Working Notes of AAAI-97Spring Symposiums on Cross-Language Text and SpeechRetrieval, 131-139.Oard, D.W. and Dorr, B.J.
(1996) A Survey of MultilingualText Retrieval.
Technical Report UMIACS-TR-96-19,University of Maryland, Institute for Advanced ComputerStudies.
http://www.ee.umd.edu/medlab/filter/paperslmlir.ps.Pinkerton, B.
(1994) "Finding What People Want:Experiences with the WebCrawler."
Proceedings of WWW.Salton, G. and Buckley, C. (1988) "Term WeightingApproaches in Automatic Text Retrieval."
InformationProcessing and Management, Vol.
5, No.
24, 513-523.Sheridan, P. and Ballerini, J.P. (1996) "Experiments inMultilingual Information Retrieval Using the SPIDERSystem."
Proceedings of the l ff h ACM SIGIR, 58-65.222
