Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
458?467, Prague, June 2007. c?2007 Association for Computational LinguisticsAutomatic Identification of Important Segments and Expressions for Miningof Business-Oriented Conversations at Contact CentersHironori Takeuchi?, L Venkata Subramaniam?, Tetsuya Nasukawa?, and Shourya Roy?
?IBM Research, Tokyo Research Laboratory ?IBM Research, India Research LaboratoryShimotsuruma 1623-14, Yamato-shi Institutional Area 4, Block-C, Vasant KunjKanagawa 2428502 Japan New Delhi 110070 India{hironori, nasukawa}@jp.ibm.com {lvsubram, rshourya}@in.ibm.comAbstractTextual records of business-oriented conver-sations between customers and agents needto be analyzed properly to acquire usefulbusiness insights that improve productivity.For such an analysis, it is critical to iden-tify appropriate textual segments and ex-pressions to focus on, especially when thetextual data consists of complete transcripts,which are often lengthy and redundant.
Inthis paper, we propose a method to iden-tify important segments from the conversa-tions by looking for changes in the accuracyof a categorizer designed to separate differ-ent business outcomes.
We extract effectiveexpressions from the important segments todefine various viewpoints.
In text mining aviewpoint defines the important associationsbetween key entities and it is crucial that thecorrect viewpoints are identified.
We showthe effectiveness of the method by using realdatasets from a car rental service center.1 Introduction?Contact center?
is a general term for customer ser-vice centers, help desks, and information phonelines.
Many companies operate contact centers tosell their products, handle customer issues, and ad-dress product-related and services-related issues.
Incontact centers, analysts try to get insights for im-proving business processes from stored customercontact data.
Gigabytes of customer contact recordsare produced every day in the form of audio record-ings of speech, transcripts, call summaries, email,etc.
Though analysis by experts results in insightsthat are very deep and useful, such analysis usuallycovers only a very small (1-2%) fraction of the totalcall volume and yet requires significant workload.The demands for extracting trends and knowledgefrom the whole text data collection by using textmining technology, therefore, are increasing rapidly.In order to acquire valuable knowledge throughtext mining, it is generally critical to identify im-portant expressions to be monitored and comparedwithin the textual data.
For example, given a largecollection of contact records at the contact centerof a manufacturer, the analysis of expressions forproducts and expressions for problems often leads tobusiness value by identifying specific problems in aspecific product.
If 30% of the contact records withexpressions for a specific product such as ?ABC?contain expressions about a specific trouble suchas ?cracked?, while the expressions about the sametrouble appear in only 5% of the contact records forsimilar products, then it should be a clue that theproduct ?ABC?
may actually have a crack-relatedproblem.
An effective way to facilitate this typeof analysis is to register important expressions in alexicon such as ?ABC?
and ?cracked?
as associatedrespectively with their categories such as ?product?and ?problem?
so that the behavior of terms in thesame category can be compared easily.
It is actu-ally one of the most important steps of text miningto identify such relevant expressions and their cate-gories that can potentially lead to some valuable in-sights.
A failure in this step often leads to a failurein the text mining.
Also, it has been considered anartistic task that requires highly experienced consul-458tants to define such categories, which are often de-scribed as the viewpoint for doing the analysis, andtheir corresponding expressions through trial and er-ror.In this paper, we propose a method to identify im-portant segments of textual data for analysis fromfull transcripts of conversations.
Compared to thewritten summary of a conversation, a transcriptionof an entire conversation tends to be quite lengthyand contains various forms of redundancy.
Manyof the terms appearing in the conversation are notrelevant for specific analysis.
For example, theterms for greeting such as ?Hello?
and ?Welcometo (Company A)?
are unlikely to be associated withspecific business results such as purchased-or-notand satisfied-or-not, especially because the conver-sation is transcribed without preserving the nonver-bal moods such as tone of voice, emotion etc.
Thusit is crucial to identify key segments and notableexpressions within conversations for analysis to ac-quire valuable insights.We exploit the fact that business conversationsfollow set patterns such as an opening followed by arequest and the confirmation of details followed bya closing, etc.
By taking advantage of this feature ofbusiness conversations, we have developed a methodto identify key segments and the notable expressionswithin conversations that tend to discriminate be-tween the business results.
Such key segments, thetrigger segments, and the notable expressions asso-ciated with certain business results lead us to easilyunderstand appropriate viewpoints for analysis.Application of our method for analyzing nearlyone thousand conversations from a rental car reser-vation office enabled us to acquire novel insights forimproving agent productivity and resulted in an ac-tual increase in revenues.Organization of the Paper: We start by describ-ing the properties of the conversation data used inthis paper.
Section 3 describes the method for iden-tifying useful viewpoints and expressions that meetthe specified purpose.
Section 4 provides the resultsusing conversational data.
After the discussion inSection 5, we conclude the paper in Section 6.2 Business-Oriented Conversation DataWe consider business-oriented conversation datacollected at contact centers handling inbound tele-phone sales and reservations.
Such business orientedconversations have the following properties.?
Each conversation is a one-to-one interactionbetween a customer and an agent.?
For many contact center processes the conver-sation flow is well defined in advance.?
There are a fixed number of outcomes and eachconversation has one of these outcomes.For example, in car rentals, the following conversa-tion flow is pre-defined for the agent.
In practicemost calls to a car rental center follow this call flow.?
Opening - contains greeting, brand name, nameof agent?
Pick-up and return details - agent asks location,dates and times of pick up and return, etc.?
Offering car and rate - agent offers a car spec-ifying rate and mentions applicable special of-fers.?
Personal details - agent asks for customer?s in-formation such as name, address, etc.?
Confirm specifications - agent recaps reserva-tion information such as name, location, etc.?
Mandatory enquiries - agent verifies clean driv-ing record, valid license, etc.?
Closing - agent gives confirmation number andthanks the customer for calling.In these conversations the participants speak in turnsand the segments can be clearly identified.
Figure 1shows part of a transcribed call.Each call has a specific outcome.
For example,each car rental transaction has one of two call types,reservation or unbooked, as an outcome.Because the call process is pre-defined, the con-versations look similar in spite of having differentresults.
In such a situation, finding the differences inthe conversations that have effects on the outcomes459is very important, but it is very expensive and dif-ficult to find such unknown differences by humananalysis.
We show that it is possible to define properviewpoints and corresponding expressions leadingto insights on how to change the outcomes of thecalls.AGENT: Welcome to CarCompanyA.
My name is Albert.
How may Ihelp you?.........AGENT: Allright may i know the location you want to pick thecar from.CUSTOMER: Aah ok I need it from SFO.AGENT: For what date and time..........AGENT: Wonderful so let me see ok mam so we have a 12 or 15passenger van avilable on this location on those dates andfor that your estimated total for those three dates just300.58$ this is with Taxes with surcharges and with freeunlimited free milleage..........AGENT : alright mam let me recap the dates you want to pickit up from SFO on 3rd August and drop it off on august 6th inLA alrightCUSTOMER : and one more questions Is it just in states orcould you travel out of states.........AGENT : The confirmation number for your booking is 221 384.CUSTOMER : ok ok Thank youAgent : Thank you for calling CarCompanyA and you have agreat day good byeFigure 1: Transcript of a car rental dialog (partial)3 Trigger Segment Detection and EffectiveExpression ExtractionIn this section, we describe a method for automat-ically identifying valuable segments and conceptsfrom the data for the user-specified difference anal-ysis.
First, we present a model to represent the con-versational data.
After that we introduce a methodto detect the segments where the useful concepts forthe analysis appear.
Finally, we select useful expres-sions in each detected trigger segment.3.1 Data ModelEach conversational data record in the collection Dis defined as di.
Each di can be seen as a sequenceof conversational turns in the conversational data,and then di can be divided asdi = d1i + d2i + ?
?
?+ dMii , (1)where dki is the k-th turn in di and Mi is the totalnumber of turns in di.
The + operator in the aboveequation can be seen as an equivalent of the stringconcatenation operator.
We define d?ji as the por-tion of di from the beginning to turn j.
Using thesame notation, d?ji = d1i + d2i + ?
?
?
+ dji .
Thecollection of d?mki constitutes the ChronologicallyCumulative Data up to turn mk (Dk).
Dk is repre-sented asDk = (d?mk1 ,d?mk2 , .
.
.
,d?mkn ).
(2)Figure 2 shows an image of the data model.
We setsome mk and prepare the chronologically cumula-tive data set as shown in Figure 3.
We represent bi-nary mutually exclusive business outcomes such assuccess and failure resulting from the conversationsas ?A?
and ?not A?.di= di1+?+diMiNumber of turns0 1 2 3 Midi1 di2 di3 diMimkdi~mk= i1+?+dimkFigure 2: Conversation data modelm5 turnm1 m2 m3 m40 1 2 5 10 15Ddidi~m5D5di~m4D4di~m3D3D2D1di~m2di~m1m1=1, m2=2, m3=5, m4=10, m5=15Figure 3: Chronologically cumulative conversa-tional data3.2 Trigger Segment DetectionTrigger segments can be viewed as portions of thedata which have important features which distin-guish data of class ?A?
from data of class ?not A?.460To detect such segments, we divide each chrono-logically cumulative data set Dk into two data sets,training data Dtrainingk and test data Dtestk .
Start-ing from D1, for each Dk we trained a classifierusing Dtrainingk and evaluated it on Dtestk .
Usingaccuracy, the fraction of correctly classified docu-ments, as a metric of performance (Yang and Liu,1999), we denote the evaluation result of the cat-egorization as acc(categorizer(Dk)) for each Dkand plot it along with its turn.
Figure 4 shows theeffect of gradually increasing the training data forthe classification.
The distribution of expressionsm1 m2 m3 m4 m5acc(categorizer(Di))trigger triggerD1D2 D3D4D5 D allturnFigure 4: Plot of acc(categorizer(Dk))in a business-oriented conversation will change al-most synchronously because the call flow is pre-defined.
Therefore acc(categorizer(Dk)) will in-crease if features that contribute to the categorizationappear in Dk.
In contrast, acc(categorizer(Dk))will decrease if no features that contribute tothe categorization are in Dk.
Therefore, fromthe transitions of acc(categorizer(Dk)), we canidentify the segments with increases as triggerswhere the features that have an effect on the out-come appear.
We denote a trigger segment asseg(start position, end position).
Because the to-tal numbers of turns can be different, we do notdetect the last section as a trigger.
In Figure 4,seg(m1,m2) and seg(m4,m5) are triggers.
It isimportant to note that using the cumulative data iskey to the detection of trigger segments.
Using non-cumulative segment data would give us the catego-rization accuracy for the features within that seg-ment but would not tell us whether the features ofthis segment are improving the accuracy or decreas-ing it.
It is this gradient information between seg-ments that is key to identifying trigger segments.Many approaches have been proposed for docu-ment classification (Yang and Liu, 1999).
In thisresearch, however, we are not interested in the clas-sification accuracy itself but in the increase and de-crease of the accuracy within particular segments.For example, the greeting, or the particular methodof payment may not affect the outcome, but themention of a specific feature of the product mayhave an effect on the outcome.
Therefore in ourresearch we are interested in identifying the partic-ular portion of the call where this product featureis mentioned, along with its mention, which has aneffect on the outcome of the call.
In our experi-ments we used the SVM (Support Vector Machine)classifier (Joachims, 1998), but almost any classifiershould work because our approach does not dependon the classification method.3.3 Effective Expression ExtractionIn this section, we describe our method to extracteffective expressions from the detected trigger seg-ments.The effective expressions in Dk are those whichare representative in the selected documents andappear for the first time in the trigger segmentsseg(mi,mj).
Numerous methods to select featuresexist (Hisamitsu and Niwa, 2002) (Yang and Ped-ersen, 1997).
We use the ?2 statistic for each ex-pression in Dk as a representative metric.
For thetwo-by-two contingency table of a expression w anda class ?A?
shown in Table 1, the ?2 statistic is cal-culated asTable 1: Contingency table for calculating the ?2statistic# of documents # of documentsincluding w not including wA n11 n12not-A n21 n22?2 = N(n11n22 ?
n12n21)2(n11 + n12)(n11 + n21)(n12 + n22)(n21 + n22) (3)where N is the number of documents.
This statis-tic can be compared to the ?2 distribution with onedegree of freedom to judge representativeness.We also want to extract the expressions that havenot had an effect on the outcome before Dk.
To de-tect the new expressions in Dk, we define the metric461new(w) = w(Dk)max(w(Dk?1), 1)/mkmk?1?sign(w(DAk )?
w(DnotAk )), (4)where w(Dk) is the frequency of expression w inthe chronologically cumulative data Dk, max(a, b)selects the larger value in the arguments, mk is thenumber of turns in Dk, w(DAk ) is the frequency ofw in Dk with the outcome of the corresponding databeing ?A?, and sign(?)
is the signum function.
Whenw in class ?A?
appears in Dk much more frequentlythan Dk?1 compared with the ratio of their turns,this metric will be more than 1.
We detect signifi-cant expressions by considering the combined score?2(w) ?
new(w).
Using this combined score, wecan filter out the representative expressions that havealready appeared before Dk and distinguish signifi-cant expressions that first appear in Dk for each class?A?
and ?not A?.3.4 Appropriate Viewpoint SelectionIn a text mining system, to get an association thatleads to a useful insight, we have to define appro-priate viewpoints.
Viewpoints refer to objects in re-lation to other objects.
In analysis using a conven-tional text mining system (Nasukawa and Nagano,2001), the viewpoints are selected based on expres-sions in user dictionaries prepared by domain ex-perts.
We have identified important segments of theconversations by seeing changes in the accuracy of acategorizer designed to segregate different businessoutcomes.
We have also been able to extract effec-tive expressions from these trigger segments to de-fine various viewpoints.
Hence, viewpoint selectionis now based on the trigger segments and effectiveexpressions identified automatically based on speci-fied business outcomes.
In the next section we applyour technique to a real life dataset and show that wecan successfully select useful viewpoints.4 Experiments and Results4.1 Experiment Data and SystemWe collected 914 recorded calls from the car rentalhelp desk and manually transcribed them.
Figure 1shows part of a call that has been transcribed.There are three types of calls:1.
Reservation Calls: Calls which got converted.Here, ?converted?
means the customer made areservation for a car.
Reserved cars can getpicked-up or not picked-up, so some reservedcars do not eventually get picked-up by cus-tomers (no shows and cancellations).2.
Unbooked Calls: Calls which did not get con-verted.3.
Service Calls: Customers changing or enquir-ing about a previous booking.The distribution of the calls is given in Table 2.Table 2: Distribution of callsUnbooked Calls 461Reservation Calls (Picked-Up) 72Reservation Calls (Not Picked-Up) 65Service Calls 326Total Calls 914The reservation calls are most important in thiscontext, so we focus on those 137 calls.
In the reser-vation calls, there are two types of outcomes, carpicked-up and car not picked-up.
All reservationcalls look similar in spite of having different out-comes (in terms of pick up).
The reservation hap-pens during the call but the pick up happens at alater date.
If we can find differences in the conver-sation that affect the outcome, it is expected that wecould improve the agent productivity.
Reservationcalls follow the pre-defined reservation call flow thatwe mentioned in Section 2 and it is very difficultto find differences between them manually.
In thisexperiment, by using the proposed method, we tryto extract trigger segments and expressions to findviewpoints that affect the outcome of the reservationcalls.For the analysis, we constructed a text mining sys-tem for the difference analysis ?picked-up?
vs. ?notpicked-up?.
The experimental system consists oftwo parts, an information extraction part and a textmining part.
In the information extraction part wedefine dictionaries and templates to identify usefulexpressions.
In the text mining part we define appro-priate viewpoints based on the identified expressionsto get useful associations leading to useful insights.4624.2 Results of Trigger Segment Detection andEffective Expression ExtractionBased on the pre-defined conversation flow de-scribed in Section 2, we set m1=1, m2=2,m3=5, m4=10, m5=15, and m6=20 and preparedD1, .
.
.
, D6 and D. The features of di consist ofnouns, compound nouns, specified noun phrases(e.g.
adjective+noun), and verbs.
For each Dkwe calculated acc(categorizer(Dk)) for the classes?picked-up?
and ?not picked-up.?
In this process, weuse a SVM-based document categorizer (Joachims,2002).
Of the 137 calls, we used 100 calls fortraining the categorizer and 37 calls for triggersegment detection.
Figure 5 shows the results ofacc(categorizer(Dk)) for picked-up.
The accuracyof classification using the data of entire conversa-tions (acc(categorizer(D)) is 67.6% but we are try-ing to detect important segments by considering notthe accuracy values themselves but the gradients be-tween segments.
From these results, seg(1, 2) and010203040506070800 5 10 15 20 25 30 35 40 45Turn (m_j)Accuracy[%]D1D2D3D4D5DD6Figure 5: Result of acc(categorizer(Dk))seg(10, 15) are detected as trigger segments.
Wenow know that these segments are highly correlatedto the outcome of the call.For each detected trigger segment, we extract ef-fective expressions in each class using the metric de-scribed in Section 3.3.
Table 3 shows some expres-sions with high values for the metric for each trigger.In this table, ?just NUMERIC dollars?
is a canonicalexpression and an expression such as ?just 160 dol-lars?
is mapped to this canonical expression in theinformation extraction process.
From this result, inseg(1, 2), ?make?, ?reservation?
are correlated with?pick up?
and ?rate?
and ?check?
are correlated withTable 3: Selected expressions in trigger segmentsTrigger Selected expressionspick up not picked upseg(1, 2) make, return, tomorrow, rate, check, seeday, airport, look, want, weekassist, reservation, tonightseg(10, 15) number, corporate program, go, impalacontract, card, have,tax surcharge,just NUMERIC dollars,discount, customer club,good rate, economy?not-picked up?.
By looking at some documentscontaining these expressions, we found customer in-tention phrases such as ?would like to make a reser-vation?, ?want to check a rate?, etc.
Therefore, itcan be induced that the way a customer starts thecall may have an impact on the outcome.
From ex-pressions in seg(10, 15), it can be said that discount-related phrases and mentions of the good rates by theagent can have an effect on the outcome.We can directly apply the conventional methodsfor representative feature selection to D. The fol-lowing expressions were selected as the top 20 ex-pressions from whole conversational data by usingthe ?2 metric defined in (3).corporate program, contract, counter, September,mile, rate, economy, last name,valid driving license,BRAND NAME, driving,telephone, midsize, tonight, use, credit, moment,airline, afternoonFrom these results, we see that looking at the call asa whole does not point us to the fact that discount-related phrases, or the first customers-utterance, af-fect the outcome.
Detecting trigger segments andextracting important expressions from each triggersegment are key to identifying subtle differences be-tween very similar looking calls that have entirelyopposite outcomes.4.3 Results of Text Mining Analysis usingSelected Viewpoints and ExpressionsFrom the detected segments and expressions we de-termined that the customer?s first utterance alongwith discount phrases and value selling phrases af-fected the call outcomes.
Under these hypotheses,we prepared the following semantic categories.463?
Customer intention at start of call: From thecustomer?s first utterance, we extract the fol-lowing intentions based on the patterns.?
strong start: would like to make a booking,need to pick up a car, .
.
.?
weak start: would like to check the rates,want to know the rate for vans, .
.
.Under our hypotheses, the customer with astrong start has the intention of booking a carand we classify such a customer as a book-ing customer.
The customer with a weak startusually just wants to know the rates and is clas-sified as a rates customer.?
discount-related phrases: discount, corporateprogram, motor club, buying club .
.
.
are reg-istered into the domain dictionary as discount-related phrases.?
value selling phrases: we extract phrases men-tioning good rates and good vehicles by match-ing patterns related to such utterances.?
mentions of good rates: good rate, won-derful price, save money, just need to paythis low amount, .
.
.?
mentions of good vehicles: good car, fan-tastic car, latest model, .
.
.Using these three categories, we tried to find insightsto improve agent productivity.Table 4 shows the result of two-dimensional as-sociation analysis for 137 reservation calls.
This ta-ble shows the association between customer typesbased on customer intention at the start of a calland pick up information.
From these results, 67%Table 4: Association between customer types andpick up informationCustomer types extracted from texts Pick up informationbased on customer intent at start of call pick up not-picked upbooking customer (w/ strong start) (70) 47 23rates customer (w/ weak start) (37) 13 24(47 out of 70) of the booking customers picked upthe reserved car and only 35% (13 out of 37) of therates customers picked it up.
This supports our hy-pothesis and means that pick up is predictable fromthe customer?s first or second utterance.It was found that cars booked by rates customerstend to be ?not picked up,?
so if we can find anyactions by agents that convert such customers into?pick up,?
then the revenue will improve.
In thebooking customer case, to keep the ?pick up?
high,we need to determine specific agent actions that con-cretize the customer?s intent.Table 5 shows how mentioning discount-relatedphrases affects the pick up ratios for rates customersand booking customers.
From this table, it canTable 5: Association between mention of discountphrases and pick up informationRates customer Pick up informationMention of discount phrases by agents pick up not-picked upyes (21) 10 11no (16) 3 13Booking customer Pick up informationMention of discount phrases by agents pick up not picked upyes (40) 30 10no (30) 17 13be seen that mentioning discount phrases affectsthe final status of both types of customers.
In therates customer case, the probability that the bookedcar will be picked up, P (pick-up) is improved to0.476 by mentioning discount phrases.
This meanscustomers are attracted by offering discounts andthis changes their intention from ?just checking rate?to ?make a reservation here?.
We found similartrends for the association between mention of valueselling phrases and pick up information.4.4 Improving Agent ProductivityFrom the results of the text mining analysis experi-ment, we derived the following actionable insights:?
There are two types of customers in reservationcalls.?
Booking customer (with strong start)tends to pick up the reserved car.?
Rates customer (with weak start) tendsnot to pick up the reserved car.?
In the rates customer case, ?pick up?
is im-proved by mentioning discount phrases.By implementing the actionable insights derivedfrom the analysis in an actual car rental process, weverified improvements in pick up.
We divided the83 agents in the car rental reservation center intotwo groups.
One of them, consisting of 22 agents,was trained based on the insights from the text min-ing analysis.
The remaining 61 agents were nottold about these findings.
By comparing these two464groups over a period of one month we hoped to seehow the actionable insights contributed to improv-ing agent performance.
As the evaluation metric, weused the pick up ratio - that is the ratio of the numberof ?pick-ups?
to the number of reservations.Following the training the pick up ratio of thetrained agents increased by 4.75%.
The averagepick up ratio for the remaining agents increased by2.08%.
Before training the ratios of both groupswere comparable.
The seasonal trends in this indus-try mean that depending on the month the bookingsand pickups may go up or down.
We believe thisis why the average pick up ratio for the remainingagents also increased.
Considering this, it can be es-timated that by implementing the actionable insightsthe pick up ratio for the pilot group was improved byabout 2.67%.
We confirmed that this difference ismeaningful because the p-value of the t-test statisticis 0.0675 and this probability is close to the stan-dard t-test (?=0.05).
Seeing this, the contact centertrained all of its agents based on the insights fromthe text mining analysis.5 DiscussionThere has been a lot of work on specific tools foranalyzing the conversational data collected at con-tact centers.
These include call type classificationfor the purpose of categorizing calls (Tang et al,2003) (Zweig et al, 2006), call routing (Kuo andLee, 2003) (Haffner et al, 2003), obtaining call logsummaries (Douglas et al, 2005), agent assistingand monitoring (Mishne et al, 2005), and buildingof domain models (Roy and Subramaniam, 2006).Filtering problematic dialogs automatically from anautomatic speech recognizer has also been studied(Hastie et al, 2002) (Walker et al, 2002).
In con-trast to these technologies, in this paper we con-sider the task of trying to find insights from a col-lection of complete conversations.
In (Nasukawaand Nagano, 2001), such an analysis was attemptedfor agent-entered call summaries of customer con-tacts by extracting phrases based on domain-expert-specified viewpoints.
In our work we have shownthat even for conversational data, which is morecomplex, we could identify proper viewpoints andprepare expressions for each viewpoint.
Call sum-maries by agents tend to mask the customers?
inten-tion at the start of the call.
We get more valuableinsights from the text mining analysis of conversa-tional data.
For such an analysis of conversationaldata, our proposed method has an important role.With our method, we find the important segmentsin the data for doing analyses.
Also our analyses areclosely linked to the desired outcomes.In trigger detection, we created a chronologicallycumulative data set based on turns.
We can alsouse the segment information such as the ?opening?and ?enquiries?
described in Section 2.
We prepareddata with segment information manually assigned,made the chronologically cumulative data and ap-plied our trigger detection method.
Figure 6 showsthe results of acc(categorizer(Dk)).
The trend in4045505560call start -->openingcall start -->detailscall start -->offeringcall start -->personaldetailscall start -->confirmation,mandatoryquestions,closingConversation flowAccuracy[%]Figure 6: Result of acc(categorizer(Dk)) usingsegment informationFigure 6 is similar to that in Figure 5.
From thisresult, it is observed that ?opening?
and ?offering?segments are trigger segments.
Usually, segmenta-tion is not done in advance and to assign such infor-mation automatically we need data with labeled seg-mentation information.
The results show that evenin the absence of labeled data our trigger detectionmethod identifies the trigger segments.
In the exper-iments in Section 4, we set turns for each chrono-logically cumulative data by taking into account thepre-defined call flow.In Figure 5 we observe that the accuracy of thecategorizer is decreasing even when using increas-ing parts of the call.
Even the accuracy using thecomplete call is less than using only the first turn.This indicates that the first turn is very informative,but it also indicates that the features are not beingused judiciously.
In a conventional classificationtask, the number of features are sometimes restricted465when constructing a categorizer.
It is known that se-lecting only significant features improves the clas-sification accuracy (Yang and Pedersen, 1997).
Weused Information Gain for selecting features fromthe document collection.
This method selects themost discriminative features between two classes.As expected the classification accuracy improvedsignificantly as we reduced the total number of fea-tures from over 2,000 to the range of 100 to 300.Figure 7 shows the changes in accuracy.
In the pro-40455055606570758085900 5 10 15 20 25 30 35 40 45Turn (m_j)Accuracy[%}100200300D1D2D3D4 D5 DD6Figure 7: Result of acc(categorizer(Dk)) with top100 to 300 features selected using information gainposed method, we detect trigger segments using theincreases and decreases of the classification accu-racy.
By selecting features, the noisy features are notadded in the segments.
Decreasing portions, there-fore are not observed.
In this situation, as a triggersegment, we can detect the portion where the gra-dient of the accuracy curve increases.
Also usingfeature selection, we find that the classification ac-curacy is highest when using the entire document,which is expected.
However, we notice that the trig-ger segments obtained with and without feature se-lection are almost the same.In the experiment, we use manually transcribeddata.
As future work we would like to use the noisyoutput of an automatic speech recognition system toobtain viewpoints and expressions.6 ConclusionIn this paper, we have proposed methods for iden-tifying appropriate segments and expressions auto-matically from the data for user specified differenceanalysis.
We detected the trigger segments using theproperty that a business-oriented conversation fol-lows a pre-defined flow.
After that, we identifiedthe appropriate expressions from each trigger seg-ment.
It was found that in a long business-prientedconversation there are important segments affectingthe outcomes that can not been easily detected byjust looking through the conversation, but such seg-ments can be detected by monitoring the changesof the categorization accuracy.
For the trigger seg-ment detection, we do not use semantic segment in-formation but only the positional segment informa-tion based on the conversational turns.
Because ourmethod does not rely on the semantic information inthe data, therefore our method can be seen as robust.Through experiments with real conversational data,using identified segments and expressions we wereable to define appropriate viewpoints and conceptsleading to insights for improving the car rental busi-ness process.AcknowledgmentThe authors would like to thank Sreeram Balakr-ishnan, Raghuram Krishnapuram, Hideo Watanabe,and Koichi Takeda at IBM Research for their sup-port.
The authors also appreciate the efforts of JatinJoy Giri at IBM India in providing domain knowl-edge about the car rental process and thank him forhelp in constructing the dictionaries.ReferencesS.
Douglas, D. Agarwal, T. Alonso, R. M. Bell,M.
Gilbert, D. F. Swayne, and C. Volinsky.
2005.Mining customer care dialogs for ?daily news?.IEEE Transaction on Speech and Audio Processing,13(5):652?660.P.
Haffner, G. Tur, and J. H. Wright.
2003.
Optimizingsvms for complex call classification.
In Proceedings ofIEEE International Conference on Acoustics, Speech,and Signal Processing (ICASSP), pages 632?635.H.
W. Hastie, R. Prasad, and M. A. Walker.
2002.
What?sthe trouble: Automatically identifying problematic di-alogues in darpa communicator dialogue systems.
InProceedings of the 40th Annual Meeting of the ACL,pages 384?391.T.
Hisamitsu and Y. Niwa.
2002.
A measure of term rep-resentativeness based on the number of co-occurringsailent words.
In Proceedings of the 19th InternationalConference on Computational Linguistics (COLING),pages 1?7.466T.
Joachims.
1998.
Text categorization with support vec-tor machines: Learning with many relevant features.In Proceedings of the 10th European Conference onMachine Learning (ECML), pages 137?142.T.
Joachims.
2002.
Optimizing search engines usingclickthrough data.
In Proceedings of the ACM Con-ference on Knowledge Discovery and Data Mining(KDD), pages 133?142.H.-K J. Kuo and C.-H. Lee.
2003.
Discriminative train-ing of natural language call routers.
IEEE Transactionon Speech and Audio Processing, 11(1):24?35.G.
Mishne, D. Carmel, R. Hoory, A. Roytman, andA.
Soffer.
2005.
Automatic analysis of call-centerconversations.
In Proceedings of ACM Conferenceon Information and Knowledge Management (CIKM),pages 453?459.T.
Nasukawa and T. Nagano.
2001.
Text analysis andknowledge mining system.
IBM Systems Journal,pages 967?984.S.
Roy and L. V. Subramaniam.
2006.
Automaticgeneration of domain models for call centers fromnoisy transcriptions.
In Proceedings of the 21st In-ternational Conference on Computational Linguisticsand 44th Annual Meeting of the ACL (COLING/ACL),pages 737?744.M.
Tang, B. Pellom, and K. Hacioglu.
2003.
Call-type classification and unsupervised training for thecall center domain.
In Proceesings of IEEE Workshopon Automatic Speech Recognition and Understanding,pages 204?208.M.
A. Walker, I. Langkilde-Geary, H. W. Hastie,J.
Wright, and A. Gorin.
2002.
Automatically train-ing a problematic dialogue predictor for a spoken di-alogue system.
Journal of Artificial Intelligence Re-search, 16:393?319.Y.
Yang and X. Liu.
1999.
A re-examination of text cate-gorization methods.
In Proceedings of the 22th AnnualInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, pages 42?49.Y.
Yang and J. O. Pedersen.
1997.
A comparative studyon feature selection in text categorization.
In Proceed-ings of the 14th International Conference on MachineLearning (ICML), pages 412?420.G.
Zweig, O. Shiohan, G. Saon, B. Ramabhadran,D.
Povey, L. Mangu, and B. Kingsbury.
2006.
Au-tomatic analysis of call-center conversations.
In Pro-ceedings of IEEE Internatinal Conference of Acous-tics, Speech and Signal Processing (ICASSP), pages589?592.467
