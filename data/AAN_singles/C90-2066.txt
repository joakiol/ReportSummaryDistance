WHY HUMAN TRANSLATORS STILL SLEEP IN PEACE?
~FOUR ENGINEERING AND LINGUISTIC GAPS IN NI.P~Paola VelardiI s t i tu to  d' Informatica, via Brecce Bianche, Ancona, I ta lyABSTRACTBecause they wilt keep their job quite for a few.l h i s  paper has been inspired by a recent ed i to r ia lon the Financial  Times, that gives a discouragingoverview of commercial natura l  Language processingsystems (~the computer that  can sustain a naturallanguage conversat ion .
.
,  is un l i ke ly  to ex is t  forseveral decades') .
Computational L inguists arenot so much concerned with app l icat ions  butcomputer sc ient i s ts  have the u l t imate  ob ject ive  tobu i ld  systems that  can ' increase theacceptab i l i ty  of computers in everydays i tuat ions . '
Eventual ly ,  l i ngu is ts  as well  wouldpro f i t  by a s ign i f i cant  break-through in naturalL~ulguage processing.This paper is a b r ie f  d i sser ta t ion  on fourerlgineering and l ingu is t i c  issues we bel ievec r i t i ca l  for  a more s t r i k ing  success of NLP:extensive acqu is i t ion  of the semantic lexicon,formal performance eva luat ion  methods to evaluatesystems, development of shel l  systems for  rapidprototyping and customizat ion,  and f ina l ly  a morelinguistically motivated approach to wordcategor i za t ion .THE ENTANGLED FORESTIn the last decade, formal methods to expresssyntact ic  and semantic knowledge (whether in anintegrated fashion or not) ,  p ro l i fe ra ted  to forman entangled fo res t .
New comers seem to preferinvent ing a brand-new method, or at least abrand-new name, rather  than t ry ing  to make senseof the dozens of .
.
.
.
.
.
.
.
* -un i f i ca t ion -G* -~. '
i~ ,  etc.
Semantic languages arere la t ive ly  fewer, but even fewer are the corr~onlyagr'eed pr inc ip ia  about the type and qua l i ty  oflanguage phenomena to be expressed.Different are also the perspectives under whichlinguists and computer scientists proceed in theirwork:Linguists  and psychologists are concerned with thenature of human communication, and use thecomputer as a tool  to model very spec i f i c ,  andyet meaningful aspects of language.
To them, anyphenomenon is worth to bee Looked at ,  no matterhow frequent, because the focus in on humans, noton computes.Computer sc ient i s ts  are interested in bu i ld ingcomputer programs that can u l t imate ly  be useful insome relevant f ie ld  of social l i f e ,  as machinet rans la t ion ,  informat ion re t r ieva l ,  tu tor ing ,  etc.In order for a NLP system to be successful,  i tmust cover the major i ty  of language phenomena thatare prominent to a given app l i ca t ion .
Coveragehere is a primary demand, because the focus is onthe use of computers, not on the modeling of mind.I believe that failing to state clearly thesedifferences has been a source of misunderstandingand scarce cooperation.
Recently Jacobs pointedout (Jacobs 1989) that Linguists measure the powerof a parser against pathological cases, and thisvery fact 'has been damaging to natural languageprocessing as a field'.
Linguists may as wellcomgtain that the proliferation of NLP paperslisting in detail the computational features of'THE SYSTEM X' and claiming some 5% betterperformances, has been damaging to computationallinguistics as a field.The author of th is  paper does not consider herpast (and current)  work untouched by thesec r i t i c i sms ,  but wishes that some more exp l i c i t  andgeneral re - th ink ing  be shared by the computationall ingu is t i cs  + natural  language processingcommunity.
This paper was inspired by a recented i to r ia l  on the Financial  Times (Cookson 1989)that presents an overview of commercial andresearch systems based on NLP technology.
Thepanorama of commercial systems is quitediscouraging: the editorial is spread with suchsentences as 'not yet robust enough' 'theirgrammatical coverage is modest' 'no computer hasthe background knowledge to resolve enough.,383l i ngu is t i c  ambiguit ies '  and concludes: 'thecomputer that can sustain a natural f ree- f lowingconversation on a subject of your choice isun l ike ly  to ex is t  for several decades.'
On theother' side, the author h igh l ights  several timesthe importance of th is  d i sc ip l ine  and i t s  possibleappl icat ions.
He also quotes the UK bank'sinnovation manager David Barrow who says 'Naturallanguage processing w i l l  be a key technology inincreasing the acceptab i l i ty  of computers ineveryday s i tuat ion ' .Yet, natural  language processing began to appearas a d i sc ip l ine  since 1950.
Progress has beencer ta in ly  made, but i t  is not a s t r i k ing  one, withrespect to other d i sc ip l ines  equal ly mature.
Whyis that?
The reader of th is  paper should be awareby now he run across one of thosewhere-are-we-now-and-where-are-we-going kind ofpapers; but we hope he will keep following us in abrief walk through the rough pathway of NLP.
Butplease remember.., some (not all) viewpointsexpressed hereafter would seem narrow-minded ifapplied to corM3utational linguistics, but areperfectly reasonable if the perspective is robustNLP.In n~view,  the major obstacle to a wider adoptionof NLP systems is ident i f ied  by four engineeringand l ingu is t i c  'gaps' .
Engineering gaps are:1.
Lack of format evaluation methods (Section 1);2.
Lack of tools  and engineering techniques forrapid prototyping and test ing of NLP modules(Section 4).L inguis t ic  gaps are:1.
Poor encoding of the semantic lexicon (Section2);2.
Poorly motivated models of word categor izat ion(Section 3).This paper has two s t r i c t ly  related guidel ineideas, that I would l i ke  to state at thebeginning:1.
Breadth is more important than depth:  Inevaluating the pros and cons of l ingu is t i c  andcoa~uter methods for  NLP we should always keepin mind the i r  breadth.
Methods that cannot beappl ied extensively and systematical ly  aresimply uninterest ing.
I t  is per fect lyreasonable, and in fact very useful (despitewhat Hans Karlgren thinks about) to work onsub-languages, provided that the experimentswe set to process such domains arereproducible on any other sub-domain.
It isperfectly reasonable to define veryfine-grained knowledge representation andmanipulation frameworks to express deep2.language phenomena, provided we candemonstrate that such knowledge can be encodedon an extensive basis.
As long as the field oflinguistic knowledge representation willneglect the related issues of knowledgeidentification and acquisition, we cannot hopein a breakthrough of NLP.Domain-dependency is not so bad.
One of theearly errors in AI was the attempt of devisinggeneral purpose methods for general purposeproblems.
Expert systems have been successfulbut they lie on the other extreme.
Current Atresearch is seeking for a better compromisebetween generality and knowledge power.Linguistic knowledge is very vast and a fullcodification is unrealistic for the timebeing.
I believe that a central issue is toaccept the unavoidable reality ofdomain-dependent linguistic knowledge, andseek for generalizable methods to acquire onesuch knowledge.
As discussed in section 3, Ialso believe that useful linguistic insightscan be gathered by the study of languagesub-domains.I.
THE 'TRULY VIABLE' APPROACHLet us maintain our forest-and-path methaphor.
Whyis it so difficult to get oriented?
The cunningreader of technical papers might have noticed avery frequent concluding remark: 'we demonstratedthat XYZ is a viable approach to sentence(discourse, anaphora) analysis (generat ion) ' .But what is ' v iab le '?
Other d i sc ip l ines  developedmodels and experiments to evaluate a system: onecould never claim XYZ viable without a good d ia lof tables, f igures and graphs.
Why is i t  sod i f f i cu l t  in the f ie ld  of NLP?Very few papers have been published on theevaluation of NLP systems.
Some well documentedreport on large NLP projects provides suchperformance figures as accuracy,in_telligibility and ua~\[~t, however thesefigures are not uniformly defined and measured.One good example is the Japanese Project (Nagao1988).
The evaluation is performed by humans,applying some scoring to the system output (e.g.translation quality).Other papers provide a l i s t  of language phenomenadealt  with by the i r  systems, or an excerpt ofsentence types the system is able to process.These results give at best some feel ing about thereal power of a system, but by no means can betaken as a formal performance measure.3 8,4 2Two papers address the problem of performanceewJluation in a systemetic way: (Guido 1896) and(Reed 1988).
The approaches are rather d i f fe rent :Guido and Mauri attempt an appl icat ion  of standardperformance evaluat ion methods to the NLPdiscipline, introducing a formal expression forthe =_performance measure of a NLP system.
Thisi s  an hard task, as i t  comes out of the lastsection of the paper, where the formula is appl iedto a simple system.
Nevertheless, we bel ieve th iswork being seminal: formal methods are the mostsu i tab le  for  an uniform evaluat ion of NLP systems.In (Read 1988) a 'sourcebook approach' is pursued.The authors propose a f ine-gra ined cataloguing oflanguage phenomena, to be used as a reference forthe evaluat ion of NLP systems.
This method in ourview is not in contrast with, but rathercomplementary to, a formal evaluation.
However,the final results of this research are not readilyavailable as yet.
A second remark is that inmeasuring the competence of a system, linguisticissues should be weighed by the 'importance' theyhere in a given application.
It is unrealistic topretend that a system can address every possiblephenoalenon, but it must be able to address thosephenomena that are prominent to the applicationdomain.One interesting question is: How do we evaluatethe l inguist ic  closure of a sub-language?
Here isa l i s t  of measures, that have the interesting (tome) feature of being acquirable with the use ofcomputers:1.2.3.ident i f i ca t ion  of the sub-language by a p lotof d i f fe rent  rootoform types per corpus size;Ident i f i ca t ion  of contexts, by and analysis ofword co-occurrences, and ident i f i ca t ion  ofsemantic re la t ions ,  by an analysis offunctional  words;Measures of complexity, to predict  theco~N~Jtational t rac tab i l i ty  of a corpus.
Someof these measures are l i s ted  in (Kittredge1987), e.g.
presence of copula, conjunctions,quant i f ie rs ,  long nominal compounds, etc.Others are suggested in the very interest ingstudies on readab i l i ty ,  or ig inated by (Flesh1946).
To our knowledge these methods havenever been appl ied to the study of l ingu is t i cclosure in NLP, even though they reached aremarkable prec is ion at measuring the ef fectof sentence structures and choice of words onlanguage corr~)rehension by humans (andconsequently by computers).2.
THE WORLD IN A BOXLanguage resides in the lexicon: word knowledge isworld knowledge.
One of the major l im i ta t ion  ofcurrent NLP systems is a poor encoding of \ [exicatsemantic knowledge: the world f i t s  a small box.The problem with lexica is twofold:  F i r s t ,  thereis no shared agreement about the type and qua l i tyof phenomena to be described in a lexicon.
\[n(Evens 1988) three major c~npeting approaches tomeaning representation in lexica are l i s ted :re la t iona l  semantics, s t ructura l  semantics aridcon~oonential/feature analysis.
In (Leech 1981) 7types of meaning are dist inguished.Relational semantics, but for  the type and numberof conceptual re lat ions (or cases) to be used,shows some uni formity  among i ts  supporters forwhat concerns the structure of the lexicon and theway this  information is used to perform semanticanalysis.
The other approaches h igh l ight  muchdeeper phenomena than the semantic re la t ionsbetween the words in a sentence, lout i t  is a hardtask to induce from the l i te ra ture  any f i rmpr inc ip le  or shared agreement on the type ofinformation to be represented.In (Velardi forthcoming) i t  is o t te r ) ted  a meredetai led cataloguing of meaning types as found inNLP l i te ra ture .
I t  is shown that a l l  types ofsemantic knowledge are in pr inc ip le  useful for thepurpose of language understanding appl icat ions,but cannot be acquired on an extensive basisbecause the primary source of such knowledge arel inguists  ar~f psycholonguistic experiments.Again, re lat iona l  semantics is somehow morein tu i t i ve  than other methods and i t  is easier toacquire, because i t  can be induced using theevidence provided by texts rather than deduced bypre-defined conceptual p r imi t ives .
But even then,acquiring n~re than a few hundred word de f in i t ionsbecame a proh ib i t i ve  task because of consistency,completeness, and boredom problems.Some work on com$)uter aided acqu is i t ion  of \[exicarecently started (Catzolar i  1988) (Velardi1989a,b) (Zernik 1989a) (Jacobs 1988) (8inot1987); during IJCA!
1989, a workshop was held onthis  topic (Zernik 1989b).
Al l .
the above worksuse corpora or on- l ine d ic t ionar ies  as e source ofsemantic learning, but the methodologies employedto manipulate this  texts are very d i f fe rent  ands t i l l  inadequate to the task.
Personally, webel ieve corpora a mere adequate source ofinformation than d ic t ionar ies ., on- l ine d ic t ionar ies  are not eas i ly  ava i lab leto the sc ient i f i c  community;.
d ic t ionar ies  mostly include taxonomic3 385information, that is hardly extracted becauseof circularity and consistency probtems, andbecause there is no clear method to extractand describe multiple senses in absence ofexamples;the information is not uniform with in  a givend ic t ionary ,  and may be very d i f fe rent  fromd ic t ionary  to d ic t ionary  depending upon the i rpurpose (e.g.
etymological d ic t ionar ies ,  s ty led ic t ionar ies ,  e tc . )
.most of a l l ,  the information in d ic t ionar iesis very general,  whereas in NLP often arerequired domain-specific categories anddefinitions.Corpora provide r ich examples of word uses,including idioms and metonymies.
I t  is possible toident i fy  d i f fe rent  senses of a word by a contextanalysis (Vetardi 1989a) (Jacobs 1988).
Inaddition, if the corpus used for lexicatacquisition is the application domain, one canderive a catalogue of relevant language issues.In any case, both research on corpora andd ic t ionar ies  is very promising, and hopeful ly w i l lprovide in the near future more insight andexperimontat support to meaning theories.3.
THE "IS A" DILEMMAThe core of any meaning representation method is aconceptual hierarchy, the \[S_A hierarchy.
Peoplethat have experience on this, know how muchtime-consuming, and unrewarding, is the task ofarranging words in a plausible hierarchy.
The moreconcepts you put in, the more entangled becomesthe hierarchy, and nobody is never fullysat i s f ied .
In (Niremburg 1987) a system ispresented to assist  humans in entering andmaintaining the consistency of a type hierarchy.But th is  does not a l lev ia te  the inherentcomplexity of grouping concepts in classes.One could maintain that type hierarchies in NLPsystems should not mimic human conceptualp r imi t ives ,  but rather they are a computer methodto express semantic knowledge in a compact formand simulate som~ very par t ia l  reasoning act iv i ty .Even under th is  conservative perspective, i t  isquite natural  for  the human hierarchy bui lder  totry to make sense of his own taxonomic activity(and get confused) rather than stay with what thespecific application requires.
Why not introducingsuch categories as MENTAL ACT andSOCIAL_PHENOMENON even though the texts to beprocessed only deals with files and disks?Several ins t i tu t ions  devoted large e f fo r tstowards the definition of IS A hierarchies forNLP.
Some of these hierarchies are claimed'general-purpose':  to me, th is  claim is a minus,rather than a plus.NLP systems have been often presented as a modelof human activities.
Now, our taxonomic activityis precisely one good example of activity thatworks very differently than in computers.
Incomputers, hierarchies are used to assert that,if X has the feature Y, and Z is-a X, then Z hasthe feature Y.
Things are in the same category iffthey have certain properties in common.
This isan 9bjectivist view of categorization that hasbeen proved in several studies inadequate to modelhuman behavior.
Objectivism has been arguedagainst in experimental studies by psychologists,anthropologists, and linguists.
In his beautifulbook (Lakoff 1987) Lakoff lists several phenomenarelevant to the activity of categorization, like:family resemblance, centrality, generat iy i t~chaining, conceptual and funct!onalembodiment etc.
Only the f i r s t  of these phenomenahas to do with the c lass ica l  theory of propertyinheritance.
But Lakoff shows that the elements ofa category can be re lated without sharing anycommon property.
The t i t le  of his book 'woman,f i re  and dangerous things'  is an examples ofapparently unrelated members of a s ing le  categoryin an aborigenal language of Aust ra l ia .
Thecategor izat ion pr inc ip le  that re lates theseelements is called by Lakoff thedomain-of-experience princip!e.
Woman and fireare associated in myth.
Fighting and fightingimplements are in the same domain of experiencewith fire, and hence are in the same class.Birds also are in the same class, because they arebelieved to be the spirits of dead human-females.Other elements are 'catted' in a class by achaining princip!e.
Element x calls element y thatcalls z etc.I t  is outside the scope of th is  paper tosummarize, or even l i s t ,  the f indings of lakof fand other researchers on human taxonomic ac t iv i ty .However the l i te ra ture  provides evidence andmatter of thoughts concerning the inadequacy ofproperty inheritance as a method to s t ructurel ingu is t i c  knowledge in NLP systems.But even if we stay with property inheritance?
weshould at \[east abandon the idea of seeking forgeneral purpose taxonomies.
Again, corpora are auseful basis to study categor izat ion insub-worlds.
Categories in d ic t ionar ies  are  theresult of a conceptualization effort by alinguist.
Corpora instead are a 'naive' example ofa culturally homogeneous group of people, thatdraw much unconsciously on their knowledge on theuse, and meaning, of words.
Corpora are moreinteresting than dictionaries to studycategorization, just like tribes are more4 386in terest ing  than ' c iv i l i zed 't~nthropetogists.cultures to4?
GET ACCUSTOMED TO CUSTOMIZATIONThe main obstacle to a wider adoption of NLPsystems in such ac t iv i t ies  as informat ionre t r ieva l  and automatic t rans la t ion  arere l iab i l i ty  and customizat ion.
These two issuesare c lear ly  re la ted:  NLP make errors  not becausethe programs have bugs, but because theirknowledge base is very limited.
To cope with poorknowledge encoding, ad-hoc techniques are widelyadopted, even though the use of ad-hoc techniquesi=!
; not advertised in papers, for obvious reasons.Ad-hoc techniques are the main cause of tongcustomization time, when switching from onea~l i ca t ion  domain to a s l ight ly  d i f fe rent  one.Customization and re l iab i l i ty  are in turn re latedwith what we said so far :.
we can ' t  pred ic t  the time spent forcustomizat ion,  as i t  happens in databasesystems, because methods for knowledgeacquisition and knowledge structuring do notexist or are far from being assessed;.
we can't evaluate reliability, because thereare not formal evaluation methods for NLPsystems.Ag~in, we came to the same problems.
But i f  wemu~;t fo rce fu l ly  abandon the idea of genera\[purpose language processors, at \[east we shouldequip ourselves with shel l  systems andhuman-computer inter faces  that  can assist  hu~lansin the creat ion ,  tes t ing  and maintenance of a l ldata=entry ac t iv i t ies  in, st ied by NLP systems.Thi:~ paper shewed that in semantics there are notas yet assessed theor ies .
In syntax, we have toomany, but not sys temat ica l ly  tested.
Shel ls andinterfaces are useful at:1. performing a wider experimentation ofdifferent theories;2. i~k ing the data -ent ry  ac t iv i ty  by hLcnans mereconstrained or at least supervised;3. render the customizat ion ac t iv i ty  to someextent forecastab\[e;4. ensure consistency with the linguisticprincipia embraced by the system designers.In the f ie ld  of Expert Systems, shel ls  began toappe~r when the expert system technology was weltasse~;sed.
May be she l ls  and inter faces have beendisregarded so far  by the computational l ingu is t i cco~Jnity because they are felt i,~ature, giventhe =~;~ate of art, or just because we are so muchaf fec t ionate  toward the idea of encoding theworld .
.
.
.
However, several ac t iv i t ies  concernedwith NLP systems can be co,~uterized orco.~ter-assisted.
We already mentioned the workby Niremburg et at.
to assist the creation of sconcept ontology.
A special extension of thissystem is under experimentation to guide theacqu is i t ion  of a re la t iona l  lexicon (Nirenhburg1989).
Other systems have been presented forprototyping and test ing of syntact ic  parsers(Briscoe 1987) (Bougarev 1988) (Marotta 1990).5. !
DON'T HAVE THE READY RECIPEI know you knew it!
Where-are-we-now papers neveroffer a panacea.
This is a position paper: it didnot present solutions, rather it pinpointed toproblems and, where available, to currentpromising research (rather i,~1odestty, some is ofour one).
The following is a summary list of whatthe author considers her own guidelines for futurework:, Performance eva luat ion:  never say a method is' v iab le '  i f  you can ' t  prove i t  fo rmal ly .Lexical semantics: don ' t  t ry  to seek for  the' rea l  meaning' of things.
Use evidenceprovided by on=l ine corpora as a source, andtest-bed, of lex ica l  acqu is i t ion  methods.. ~ :  property inher i tance isinadequate.
Is i t  poss ib le to i ,~ le ,~nt  on acomputer some of the observed human mechanismsof categor izat ion?Customization: genera\[ purpese systems areunrea l i s t i c .
Bui ld she l ls  arKt in ter facesystems to a l low for  a faster  andwel l=assisted customization ac t iv i ty .ACKNOWLEDGEMENTSThis work has been supported by the EuropeanCo~ni ty  under grant PRO-ART 1989REFERENCES(g inot  1988) Binot J .
\ [ .
,  Jensen K. J ) ict ionarzEntr ies as a source of know\[ed e f~q_e f2?._syntactic andother disambiguatioqs PrQc.
o f2nd  Conf on Appl iedNatural Language Processing Austin,  February 19883875(Boguraev 1988) Boguraev B., Carrot J., BriscoeE., Grover C. Software support for practicalgra~nar development in COLING 88 Budapest 1988(Briscoe 1987) Briscoe E., Grover C., Boguraev B.,Carroll J.
A formalism and environment for thedevelopment of a large grammar of English in IJCAI198____77 Mitano, 1987(Calzotari 1988) N. Calzolari The Dictionarz andthe thesaurus can be combined in Relational Modelsof the Lexicon Cambridge University Press, 1988(Cookson 1989) C. Cookson Wh c ters need tolearn ~ in Financial Times September 20,1989(Evens 1988) M. Evens Introduction in RelationalModels of the lexicon M. Evens ed.
CambridgeUniversity Press 1988(Flesh 1946) R. Flesh The Art of Plain Talk in~ Z  and Brothers 1946(Guida 1986) Guida G., Mauri G. Evaluation ofNatural Language Processing Systems: Issue_.=s andApproaches in Proceedings of the IEEE vot.74, n.7July 1986(Jacobs 1988) P. Jacobs, U. Zernik LearningPhrases from Texts: A Case Study in AAAI 88 St.Paul, 1988(Jacobs 1989) P. Jacobs Making sense of texicatacquisition in Proc.
of 1st.
I JCAI LexicatAcquisition Workshop Detroit 1989(Lakoff 1987) G. Lakoff Woman, FireThings: what  categories revealUniversity of Chicago press, 1987and Dangerousabout mind(Leech 1981) G. Leech Semantics Penguin books 1981(Marotta 1990) Marotta, Pazienza, Pettinelli,Vetardi On Parsing ....... F o rm-pars in~submitted, 1990(Nagao 1988) M.Nagao, Tsujii J., Nakamura J .
,  Th.___eeJ_rapanese Gover~ent Project for MachineTranslation in Machin_eTranslation Systems ed.by J.Slocum, Cambridge University Press, 1988(Niremburg 1987) S. Nirenburg , V. Raskin Thesubworld concept lexicon a~d.. the Lexiconmanagement S=ystem in C~_A~utationalLi_~uistics n. 13, 1987(Niremburg 1989) Niremburg S., Raskin V.,McCardetl R. Ontology based lexicalac_.c_quisition in Proc.
1st.
\ [ JCA!
LexicalAcquisition gq~Detro i t ,  1987(Read 1988) Read No, Quilici A., Reeves J., DyerM., Baker E. Evatuatin~ n a t ~ q e ~ \ [a sourcebook apprqach in COLING 88 Budapest 1988(Vetardi 1989a)ac_E_quisition ofVancouver, 1989Vetardi, Pazienza ~ter  aidedlexical cooccurrences in ACL 89(Vetardi 1989b) Vetardi, Pazienza, MagriniAcquisition of semantic patterns from a naturalcorq.qEl~gs of texts in ACM-SIGART special issue onknowledge acquisition n. 107 , 1989(Velardi forthcoming) P. Vetardi Ac_c_q~Jirin~Semantic Lexicon for Natural Lanu?1u.ag.eProcessin~ in U. Zernik ed., Karl Erlbaum assoc.,forthcoming(Zernik 1989) U. Zernik Lexicon Acquisition:Learning from Corpus by Capitalizing on LexicalCategories in IJCAI 1989 Detroit 1989(Zernik 1989b) U.Zernik ed.
First Int.
LexicalAcquisition Workshop Proceeding Detroit 1989388 6
