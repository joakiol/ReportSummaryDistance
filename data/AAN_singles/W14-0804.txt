Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 26?32,Gothenburg, Sweden, 26-27 April 2014.c?2014 Association for Computational LinguisticsThe Relevance of Collocations for ParsingEric WehrliLATL-CUIUniversity of GenevaEric.Wehrli@unige.chAbstractAlthough multiword expressions(MWEs) have received an increasingamount of attention in the NLP com-munity over the last two decades, fewpapers have been dedicated to the spe-cific problem of the interaction betweenMWEs and parsing.
In this paper, we willdiscuss how the collocation identificationtask has been integrated in our rule-based parser and show how collocationknowledge has a positive impact on theparsing process.
A manual evaluationhas been conducted over a corpus of4000 sentences, comparing outputs ofthe parser used with and without thecollocation component.
Results of theevaluation clearly support our claim.1 IntroductionCollocations and more generally multiword ex-pressions (MWEs) have received a large and in-creasing amount of attention in the NLP com-munity over the last two decades, as attestedby the number of workshops, special interestgroups, and ?of course?
publications.
The im-portance of this phenomenon is now clearly rec-ognized within the NLP community.It is fair to say that collocation extraction hasbeen the main focus of attention, and a greatdeal of research has been devoted to developingtechniques for collocation extraction from cor-pora (Church & Hanks, 1990; Smadja, 1993;Evert, 2004; Seretan & Wehrli, 2009, amongmany others).
Much less attention has been paidto the interaction between collocations and theparsing process1.
In this paper, we will argue (i)that collocation detection should be consideredas a component of the parsing process, and (ii)that contrary to a common view, collocations(and more generally MWEs) do not constitutea problem or a hurdle for NLP (cf.
Green et al.,2011; Sag et al., 2002), but rather have a posi-tive impact on parsing results.Section 2 shows how collocation identifica-tion has been integrated into the parsing pro-cess.
An evaluation which compares the re-sults of the parse of a corpus with and withoutthe collocation identification component will bediscussed in section 3.2 Parsing collocationsThat syntactic information is useful ?
indeednecessary ?
for a proper identification of collo-cations is widely acknowledged by now.
Morecontroversial, however, is the dual point, that is1Preprocessing, that is, the detection of MWEs duringtokenisation (ie.
before parsing) is used in several sys-tems ?
for instance, ParGram (Butt et al., 1999), or morerecently, Talismane (Urieli, 2013).
However, this tech-nique can only be successfully applied to MWEs whosecomponents are adjacent (or near-adjacent), leaving asidemost of the cases that will be discussed below.26that collocation identification is useful for pars-ing.Several researchers (cf.
Seretan et al., 2009;Seretan, 2011, and references given there) haveconvincingly argued that collocation identifica-tion crucially depends on precise and detailedsyntactic information.
One main argument sup-porting that view is the fact that in some col-locations, the two constituents can be far awayfrom each other, or in reverse order, depend-ing on grammatical processes such as extraposi-tion, relativization, passive, etc.
Based on suchconsiderations, we developed a collocation ex-traction system based on our Fips multilingualrule-based parser(cf.
Wehrli, 2007; Wehrli etal., 2010).
Although quite satisfactory in termsof extraction precision, we noticed some short-comings in terms of recall, due to the fact thatthe parser would not always return the most ap-propriate structure.
A closer examination ofsome of the cases where the parser failed toreturn the structure containing a collocation ?and therefore failed to identify it ?
showed thatheuristics had (wrongly) favoured an alternativestructure.
Had the parser known that there wasa collocation, the correct structure could havereceived a higher score.These observations led us to revise our po-sition and consider that parsing and the identi-fication of collocations are in fact interrelatedtasks.
Not only does collocation identifica-tion rely on syntactic dependencies, and thus onparsed data, but the parser can fruitfully use col-locational knowledge to favour some analysesover competing ones.
A new version of the Fipsparser has since been developed, in which col-locations are identified as soon as the relevantstructure is computed, that is as soon as the sec-ond term of the collocation is attached to thestructure.The collocation identification process is trig-gered by the (left or right) attachment of alexical element marked [+partOfCollocation]2.Governing nodes are iteratively considered,halting at the first node of major category (noun,verb, adjective, adverb).
If that second nodeis itself marked [+partOfCollocation], then wecheck whether the two terms correspond to aknown collocation.Consider first some simple cases, as illus-trated in (1).(1)a.
He had no loose change.b.
Paul took up a new challenge.The collocation loose change in sentence (1a)is identified when the adjective loose is (left-)attached to the noun change.
Both elements arelexically marked [+partOfCollocation], the pro-cedure looked up the collocation database fora [NP[APloose ] change ] collocation.
Inthe second example (1b), the procedure is trig-gered by the attachment of the noun challengeto the determiner phrase (DP) a, which is al-ready attached as direct object subconstituentof the verb took (up).
As pointed out above,the procedure checks the governing nodes un-til finding a node of major category ?
in thiscase the verb.
Both the verb and the noun aremarked [+partOfCollocation], so that the pro-cedure looks up the database for a collocationof type verb-direct object.Let us now turn to somewhat more complexcases, such as the ones illustrated (2):(2)a.
Which record did Paul break?b.
The record Paul has just broken was veryold.c.
This record seems difficult to break.d.
This record, Paul will break at the nextOlympic Games.2The collocation identification process only concernslexicalized collocations, that is collocations that we haveentered into the parser?s lexical database.27e.
Which record did Paul consider difficult tobreak?f.
The record will be broken.g.
The record is likely to be broken.h.
Ce d?efi, Jean le consid`ere comme difficile`a relever.
?This challenge, Jean considers [it] as dif-ficult to take up?Sentence (2a) is a wh-interrogative clause,in which the direct object constituent occursat the beginning of the sentence.
Assuminga generative grammar analysis, we considerthat such preposed constituents are connectedto so-called canonical positions.
In this case,the fronted element being a direct object, thecanonical position is the typical direct objectposition in an English declarative sentence, thatis a postverbal DP position immediately dom-inated by the VP node.
The parser establishessuch a link and returns the structure below,where [DPe]istands for the empty category(the ?trace?)
of the preposed constituent whichrecord.
(3) [CP[DPwhich record]i] did [TP[DPPaul] break [DPe]i]In such cases, the collocation identificationprocess is triggered by the insertion of theempty constituent in the direct object positionof the verb.
Since the empty constituent is con-nected to the preposed constituent, such exam-ples can be easily treated as a minor variant ofcase (1b).All so-called wh-constructions3are treated ina similar fashion, that is relative clause (2b) andtopicalization (2c).
Sentence (2d) concerns thetough-movement construction, that is construc-tions involving adjectives such as tough, easy,3See Chomsky (1977) for a general analysis of wh-constructions.difficult, etc.
governing an infinitival clause.
Insuch constructions, the matrix subject is con-strued as the direct object of the infinitival verb.In dealing with such structures, the parser willhypothesize an abstract wh-operator in the spec-ifier position of the infinitival clause, whichis linked to the matrix subject.
Like all wh-constituents, the abstract operator will itself beconnected to an empty constituent later on in theanalysis, giving rise to a chain connecting thesubject of the main clause and the direct objectposition of the infinitival clause.
The structureas computed by the parser is given in (4), withthe chain marked by the index i.
(4) [TP[DPthis record]iseems [APdifficult[CP[DPe]i[TPto [VPbreak [DPe]i] ] ]] ]Finally, examples (2f,g) concern the passiveconstruction, in which we assume that the directobject is promoted to the subject position.
Inthe tradition of generative grammar, we couldsay that the ?surface?
subject is interpreted asthe ?deep?
direct object of the verb.
Given suchan analysis of passive, the parser will connectthe subject constituent of a passive verb with anempty constituent in direct object position, asillustrated in (5).
(5) [TP[DPthe record]iwill [VPbe [VPbroken[DPe]i] ] ]The detection of a verb-object collocation ina passive sentence is thus triggered by the inser-tion of the empty constituent in direct object po-sition.
The collocation identification procedurechecks whether the antecedent of the (empty)direct object and the verb constitute a (verb-object) collocation.2.1 Why collocations helpThe parser can benefit from collocation knowl-edge in two ways.
The improvement comes ei-ther from a better choice of lexical element (in28case of ambiguous words), or from a more fe-licitous phrase attachment.
Both cases are illus-trated below, by means of examples taken fromour evaluation corpus.
Consider first colloca-tions of the noun-noun type containing syntac-tically ambiguous words (in the sense that theycan be assigned more than one lexical category)as in (6):(6)a. balancing acteating habitsnursing careliving standardsworking conditionsb.
austerity measuresopinion pollstax cutsprotest marchesAs illustrated by Chomsky?s famous exampleFlying planes can be dangerous, -ing forms ofEnglish transitive verbs are quite systematicallyambiguous, between a verbal reading (gerund)and an adjectival reading (participle use).
Theexamples given in (6a) are all cases of colloca-tions involving a present participle modifying anoun.
All those examples were wrongly inter-preted as gerunds by the parser running withoutthe collocation identification procedure.
Thenoun-noun collocations in (6b) all have a nounhead which is ambiguous between a nominaland a verbal reading.
Such examples werealso wrongly interpreted with the verbal read-ing when parsed without the identification pro-cedure.The second way in which collocationalknowledge can help the parser has to do withstructural ambiguities.
This concerns particu-larly collocations which include a prepositionalphrase, such as the noun-preposition-noun col-locations, as in (7):(7) bone of contentionstate of emergencystruggle for lifeflag of convenienceThe attachment of prepositional phrases isknown to be a very difficult task for parsers (cf.Church & Patil, 1982).
So, knowing that a par-ticular prepositional phrase is part of a colloca-tion (and giving priority to such analyses con-taining collocations over other possible analy-ses) is an effective way to solve many cases ofPP attachments.3 EvaluationTo evaluate the effect of collocational knowl-edge on parsing, we compared the results pro-duced by the parser with and without the col-location identification procedure.
The corpusused for this evaluation consists of 56 arti-cles taken from the magazine The Economist,corresponding to almost 4000 sentences.
Wefirst compared the number of complete analy-ses achieved by both runs, with the results inFigure 14:with collocations without collocations70.3% 69.2%Figure 1: Percentage of complete analysesAlthough the number of complete parses(sentences for which the parser can assign acomplete structure) varies very slightly (a littlemore than a percent point better for the versionwith collocation identification, at 70.3%), thecontent of the analyses may differ in significantways, as the next evaluation will show.A manual evaluation of the results was con-ducted over the corpus, using a specific user in-terface.
To simplify the evaluation, we selectedthe POS-tagging mode of the parser, and further4By complete analysis, we mean a single constituentcovering the whole sentence.
When the Fips parser failsto achieve a complete analysis, it returns a sequence ofchunks (usually 2 or 3) covering the whole sentence.29diff.
diff N vs V with coll.
without coll.416 148 116 32Figure 3: Differences with and without collocationrestricted the output to the triple (word, pos-tag,position)5.
For the POS tagset, we opted for theuniversal tagset (cf.
Petrov et al., 2012).
Bothoutput files could then easily be manually com-pared using a specific user interface as illus-trated in figure 2 below, where differences aredisplayed in red.Notice that in order to facilitate the manualevaluation, we only took into account differ-ences involving the NOUN and VERB tags.
Inthe screenshot the two result files are displayed,on the left the results obtained by the parserwith (W) the collocation identification compo-nent, on the right the results obtained with theparser without (WO) the collocation identifica-tion component.
For each file, one line containsthe input lexical item (simple word or com-pound), its tag, and its position with respect tothe beginning of file (article).
Differences (re-stricted here to NOUN vs VERB tags) betweenthe two files are indicated in red.
For each dif-ference, the user selects the best choice, usingthe Better left or Better right button or theSkip button if the difference is irrelevant (or ifneither tag is correct).
After each choice, thenext difference is immediately displayed.The results are given in figure 3.
Column 1gives the total number of differences, column2 the number of differences for the NOUN vsVERB tags, columns 3 and 4 show how manytimes the result (NOUN / VERB) is better withthe collocation component (column 3) or with-out it (column 4).This manual evaluation clearly shows that5Using Fips in POS-tagging mode only means that theoutput will restricted to word and POS-tags.
The analysisitself is identical whether we use Fips in parsing mode orin Pos-tagging mode.the quality of the parses improves significantlywhen the parser ?knows?
about collocations,that is when collocation detection takes placeduring the parse.
The comparison of the resultsobtained with and without collocation knowl-edge shows a total 416 differences of POS-tags,of which 148 concern the difference betweenNoun vs Verb tags.
In 116 cases (nearly 80%)the choice was better when the parser had collo-cational knowledge, while in 32 cases (approx.21%) the choice was better without the colloca-tional knowledge.The fact that in a little over 20% of the casesthe parser makes a better choice without col-locational knowledge may seem a bit odd orcounter-intuitive.
Going through several suchcases revealed that in all of them, the parsercould not achieve a full parse and returned a se-quence of chunks.
It turns out that in its currentstate, the Fips parser does not use collocationalknowledge to rank chunks.
Nor can it iden-tify collocations that spread over two chunks.Clearly something to be updated.4 Concluding remarks and futureworkIn this paper, we have argued that collocationidentification and parsing should be viewed asinterrelated tasks.
One the one hand, colloca-tion identification relies on precise and detailedsyntactic information, while on the other handthe parser can fruitfully use collocation knowl-edge in order to rank competing analyses and,more interestingly, to disambiguate some other-wise difficult cases.This preliminary study focused primarily onthe NOUN vs VERB ambiguity, an ambiguitywhich is very common in English and whichmay have a devastating effect when the wrongreading is chosen.
For instance, in a translationtask, such mistakes are very likely to lead to in-comprehensible results.30Figure 2: Manual evaluation user interface31In future work, we intend (i) to perform aevaluation over a much larger corpus, (ii) to takeinto account all types of collocations, and (iii) toconsider other languages, such as French, Ger-man or Italian.5 ReferencesButt, M., T.H.
King, M.-E. Ni?no & F. Segond,1999.
A Grammar Writer?s Cookbook,Stanford, CSLI Publications.Church, K. & P. Hanks, 1990.
?Word as-sociation norms, mutual information, andlexicography?, Computational Linguistics16(1), 22-29.Church, K. & R. Patil, 1982.
?Coping with Syn-tactic Ambiguity or How to Put the Blockin the Box on the Table?, American Journalof Computational Linguistics, vol.
8, num-ber 3-4, 139-150.Chomsky, N. 1977.
?On Wh-Movement?,in Peter Culicover, Thomas Wasow, andAdrian Akmajian, eds., Formal Syntax,New York: Academic Press, 71-132.Evert, S., 2004.
The Statistics of WordCooccurrences: Word Pairs and Colloca-tions, PhD dissertation, IMS, University ofStuttgart.Green S., M.-C. de Marneffe, J. Bauer &Ch.D.
Manning, 2011.
?Multiword Ex-pression Identification with Tree Substitu-tion Grammars: A Parsing tour de forcewith French?, Proceedings of the 2011Conference on Empirical Methods in Nat-ural Language Processing, 725-735.Petrov, S., D. Das & R. McDonald, 2012.?A Universal Part-of-Speech Tagset?, Pro-ceedings of LREC-2011.Sag, I., T. Baldwin, F. Bond, A. Copestake &D. Flickinger (2002), ?Multiword Expres-sions: A Pain in the Neck for NLP?, Pro-ceedings of Cicling 2002, Springer-Verlag.Seretan, V., 2011.
Syntax-Based CollocationExtraction, Springer Verlag.Seretan, V. & E. Wehrli, 2009.
?Multilin-gual Collocation Extraction with a Syntac-tic Parser?, Language Resources and Eval-uation 43:1, 71-85.Smadja, F., 1993.
?Retrieving collocations fromtext: Xtract?, Computational Linguistics19(1), 143-177.Urieli, A., 2013.
Robust French SyntaxAnalysis: reconciling statistical meth-ods and linguistic knowledge in the Tal-ismane toolkit, PhD dissertation, Uni-versity of Toulouse.
[http://redac.univ-tlse2.fr/applications/talismane/biblio/URIELI-thesis-2013.pdf]Wehrli, E., 2007.
?Fips, a deep linguistic multi-lingual parser?
in Proceedings of the ACL2007 Workshop on Deep Linguistic Pro-cessing, Prague, Czech Republic, 120-127.Wehrli, E., V. Seretan & L. Nerima, 2010.
?Sen-tence Analysis and Collocation Identifi-cation?
in Proceedings of the Workshopon Multiword Expressions: from The-ory to Applications (MWE 2010), Beijing,China, 27-35.32
