Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 148?155,Columbus, June 2008. c?2008 Association for Computational LinguisticsModeling Vocal Interaction for Text-IndependentParticipant Characterization in Multi-Party ConversationKornel LaskowskiCognitive Systems LabsUniversita?t KarlsruheKarlsruhe, Germanykornel@ira.uka.deMari OstendorfDept.
of Electrical EngineeringUniversity of WashingtonSeattle WA, USAmo@ee.washington.eduTanja SchultzCognitive Systems LabsUniversita?t KarlsruheKarlsruhe, Germanytanja@ira.uka.deAbstractAn important task in automatic conversationunderstanding is the inference of social struc-ture governing participant behavior.
We ex-plore the dependence between several socialdimensions, including assigned role, gender,and seniority, and a set of low-level featuresdescriptive of talkspurt deployment in a mul-tiparticipant context.
Experiments conductedon two large, publicly available meeting cor-pora suggest that our features are quite usefulin predicting these dimensions, excepting gen-der.
The classification experiments we presentexhibit a relative error rate reduction of 37% to67% compared to choosing the majority class.1 IntroductionAn important task in automatic conversation under-standing is the inference of social structure govern-ing participant behavior; in many conversations, themaintenance or expression of that structure is animplicit goal, and may be more important than thepropositional content of what is said.There are many social dimensions along whichparticipants may differ (Berger, Rosenholtz andZelditch, 1980).
Research in social psychology hasshown that such differences among participants en-tail systematic differences in observed turn-takingand floor-control patterns (e.g.
(Bales, 1950), (Tan-nen, 1996), (Carletta, Garrod and Fraser-Krauss,1998)), and that participant types are not indepen-dent of the types and sizes of conversations in whichthey appear.
In the present work, we consider thedimensions of assigned role, gender, and senior-ity level.
We explore the predictability of thesedimensions from a set of low-level speech activ-ity features, namely the probabilities of initiatingand continuing talkspurts in specific multipartici-pant contexts, estimated from entire conversations.For our purposes, talkspurts (Norwine and Murphy,1938) are contiguous intervals of speech, with in-ternal pauses no longer than 0.3 seconds.
Featuresderived from talkspurts are not only easier to com-pute than higher-level lexical, prosodic, or dialogueact features, they are also applicable to scenarios inwhich only privacy-sensitive data (Wyatt et al 2007)is available.
At the current time, relatively little isknown about the predictive power of talkspurt tim-ing in the context of large multi-party corpora.As stated, our primary goal is to quantify the de-pendence between specific types of speech activityfeatures and specific social dimensions; however,doing so offers several additional benefits.
Mostimportantly, the existence of significant dependencewould suggest that multiparticipant speech activitydetectors (Laskowski, Fu?gen and Schultz, 2007) re-lying on models conditioned on such attributes mayoutperform those relying on general models.
Fur-thermore, conversational dialogue systems deployedin multi-party scenarios may be perceived as morehuman-like, by humans, if their talkspurt deploy-ment strategies are tailored to the personalities theyare designed to embody.Computational work which is most similar to thatpresented here includes the inference of static dom-inance (Rienks and Heylen, 2005) and influence(Rienks et al, 2006) rankings.
In that work, the au-thors employed several speech activity features dif-fering from ours in temporal scale and normaliza-148tion.
Notably, their features are not probabilitieswhich are directly employable in a speech activitydetection system.
In addition, several higher-levelfeatures were included, such as topic changes, par-ticipant roles, and rates of phenomena such as turnsand interruptions, and these were shown to yield themost robust performance.
Our aim is also similarto that in (Vinciarelli, 2007) on radio shows, wherethe proposed approach relies on the relatively fixedtemporal structure of production broadcasts, a prop-erty which is absent in spontaneous conversation.Although (Vinciarelli, 2007) also performs single-channel speaker diarization, he does not explore be-havior during vocalization overlap.Aside from the above, the focus of the major-ity of existing research characterizing participantsis the detection of dynamic rather than static roles(i.e.
(Banerjee and Rudnicky, 2004), (Zancanaro etal, 2006), (Rienks et al, 2006)).
From a mathe-matical perspective, the research presented here isa continuation of our earlier work on meeting types(Laskowski, Ostendorf and Schultz, 2007), and werely on much of that material in the presentationwhich follows.2 Characterizing ParticipantsImportantly, we characterize participants in entiregroups, rather than characterizing each participantindependently.
Doing so allows us to apply con-straints on the group as a whole, eliminating theneed for hypothesis recombination (in the event thatmore than one participant is assigned a role whichwas meant to be unique).
Additionally, treatinggroups holistically allows for modeling the interac-tions between specific pairs of participant types.For each conversation or meeting1 of K partici-pants, we compute a feature vector F, in which allone-participant and two-participant speech activityfeatures are found in a particular order, typically im-posed by microphone channel or seating assignment(the specific features are described in Section 4).The goal is to find the most likely group assignmentof participant labels that account for the observedF.
In (Laskowski, Ostendorf and Schultz, 2007), itwas shown that meeting types in a large meeting cor-1?Conversation?
and ?meeting?
will be used interchange-ably in the current work.pus can be successfully inferred from F using thisapproach; here, we employ the same framework toclassify participant types in the K-length vector g,for the group as a whole:g?
= arg maxg?GP (g |F )= arg maxg?GP (g )?
??
?MMP (F |g )?
??
?BM, (1)where MM and BM are the membership and behav-ior models, respectively, and G is the set of all pos-sible assignments of g.In the remainder of this section, we define theparticipant characteristics we explore, which includeassigned role, gender, and seniority.
We treat theseas separate tasks, applying the same classificationframework.
We also show how our definitions pro-vide search space constraints on Equation 1.2.1 Conversations with Unique RolesGiven a meeting of K participants, we consider a setof roles R = {R1, R2, ?
?
?
, RK} and assign to eachparticipant k, 1?k?K, exactly one role in R. Anexample group assignment is the vector r1 of lengthK, where r1 [k] = Rk.
The set R of group assign-ment alternatives r ?
R is given by permutations?
: R 7?
R, where ?
?
SK , the symmetric group onK symbols2.
The number of elements in R is iden-tically the number of unique permutations in SK , aquantity known as its order |SK | = K!.To identify the most likely group assignment r?
=??
(r1) given the set F of observables, we iterateover the K!
elements of SK using??
= arg max?
?SKP (F |?
(r1) ) , (2)where we have elided the prior P (? )
assuming thatit is uniform.
Following the application of Equa-tion 2, the most likely role of participant k is givenby ??
(r1) [k].Alternately, we may be interested in identifyingonly a subset of the roles in R, namely a leader, ora manager.
In this case, participant roles are drawnfrom L = {L,?L}, under the constraint that exactlyone participant is assigned the role L. The set L of2For an overview of group theoretic notions and notation,we refer the reader to (Rotman, 1995).149alternative group assignments has K indicator vec-tor members lj , 1?j?K, where lj [k] is L for k = jand ?L otherwise.3 We iterate over the indicatorvectors to obtainj?
= arg maxj?{1,??
?,K}P (F | lj ) , (3)assuming uniform priors P ( lj ).
Following the ap-plication of Equation 3, j?
is the index of the mostlikely L participant.We note that this framework for unique role clas-sification is applicable to classifying unique ranks,without first having to collapse them into non-unique rank classes as was necessary in (Rienks etal., 2006).2.2 Conversations with Non-Unique RolesThe second type of inference we consider is for di-mensions in which roles are not unique, i.e.
whereparticipants are in principle drawn independentlyfrom a set of alternatives.
This naturally includesdimensions such as gender, seniority, age, etc.As an example, we treat the case of gender.
Par-ticipant genders are drawn independently from H ={~,|}.
The set of group assignment alternatives his given by the Cartesian product HK , of 2K uniqueelements.
We search for the most likely group as-signment h?, given the observables F, by iteratingover these elements usingh?
= arg maxh?HKP (h ) P (F |h ) .
(4)Once h?
is found, the gender of each participant k isavailable in h?
[k].A similar scenario is found for seniority, whenit is not uniquely ranked.
We assume a set ofNS mutually exclusive seniority levels Si ?
S ={S1, S2, ?
?
?
, SNS}, 1?i?NS .
During search, eachparticipant?s seniority level is drawn independentlyfrom S , leading to group assignments s ?
SK , ofwhich there are NKS .
As for gender, we iterate overthese to finds?
= arg maxs?SKP ( s ) P (F | s ) .
(5)The seniority of participant k, following the applica-tion of Equation 5, is s?
[k].3For completeness, we note that each lj corresponds to apermutation ?
: L 7?
L of l1, and that ?
?
??
?, the cyclic sub-group generated by ?
, where ?
is the permutation (1, 2, ?
?
?
,K).3 DataIn the current work, we use two different corpora ofmulti-party meetings.
The first, the scenario subsetof the AMI Meeting Corpus (Carletta, 2007), con-sists of meetings involving K = 4 participants whoplay different specialist roles in a product designteam.
We have observed the recommended divisionof this data into: AMITRAINSET of 98 meetings;AMIDEVSET of 20 meetings; and AMIEVALSET,also of 20 meetings.
Although each participant takespart in approximately 4 meetings, the 3 sets are dis-joint in participants.
We use only the provided wordalignments of these meetings.
The corpus is accom-panied by metadata which specifies the gender andassigned role of each participant.The second corpus consists of the Bed, Bmr,and Bro meeting types in the ICSI Meeting Cor-pus (Janin et al, 2003).
Each meeting is identifiedby one of {Bed,Bmr,Bro}, as well as a numericalidentifier d. We have divided these meetings into:ICSITRAINSET, consisting of the 33 meetings forwhich d mod 4 ?
{1, 2}; ICSIDEVSET, consist-ing of the 18 meetings for which d mod 4 ?
3;and ICSIEVALSET, consisting of the 16 meetings forwhich d mod 4 ?
0.
These three sets are not dis-joint in participants, and the number of instrumentedparticipants K varies from meeting to meeting, be-tween 3 and 9.
The corpus is accompanied by meta-data specifying the gender, age, and education levelof each participant.
We use only the forced align-ments of these meetings, available in the accompa-nying MRDA Corpus (Shriberg et al 2004).4 FeaturesOur observation space is the complete K-participantvocal interaction on-off pattern description for ameeting C, a discretized version of which we denoteas qt ?
{0, 1}K for 1?t?T , where T is the dura-tion of C in terms of the number of 100 ms frames.Details regarding the discretization (and subsequentfeature computation) can be found in (Laskowski,Ostendorf and Schultz, 2007).We compute from qt the following features4which are the elements of F: fV Ik , the probabil-4Feature type superscripts indicate talkspurt initiation (I) orcontinuation (C), for either single-participant vocalization (V )or vocalization overlap (O).150ity that participant k initiates vocalization at time twhen no-one else was speaking at t ?
1; fV Ck , theprobability that participant k continues vocalizationat time t when no-one else was speaking at t ?
1;fOIk,j , the probability that participant k initiates vo-calization at time t when participant j was speakingat t ?
1; and fOCk,j the probability that participant kcontinues vocalization at time t when participant jwas speaking at t?
1.
Values of the features, whichare time-independent probabilities, are estimated us-ing a variant of the Ising model (cf.
(Laskowski, Os-tendorf and Schultz, 2007)).
Additionally, we com-pute a feature fVk , the probability that participantk vocalizes at time t, and single-participant aver-ages of the two-participant features: ?fOIk,j ?j , ?fOIj,k ?j ,?fOCk,j ?j , and ?fOCj,k ?j .
The complete feature vectorfor a conversation of K participants then consists of7K one-participant features, and 2(K2 ?
K) two-participant features.We note that multiple phenomena contribute tothe overlap features.
The features fOIk,j are basedon counts from interruptions, backchannels, and pre-cise floor handoffs.
The features fOCk,j are based oncounts from interruptions, attempts to hold the floor,and backchannels.
Both feature types also containcounts incurred during schism, when the conversa-tion splits into two sub-conversations.5 ModelsSince K may change from meeting to meeting, thesize of the feature vector F must be considered vari-able.
We therefore factor the behavior model, as-suming that all features are mutually independentand that each is described by its own univariateGaussian model N(?, ?2).
These parameters aremaximum likelihood estimates from the fk and fk,jvalues in a training set of conversations.
In most ofthese experiments, where the number of classes issmall, no parameter smoothing is needed.For the cases where the group prior is not uniformand participant types are not unique, the member-ship model assumes independent participant typesand has the general formP (g ) =K?k=1P (g [k] ) , (6)where P (g [k] ) is the probability that the k-th par-ticipant is type g [k].
This model is used for gen-der (P (h)) and seniority (P (s)).
The probabilitiesof specific types are maximum likelihood estimatesfrom the training data.6 Assigned Role Classification6.1 Classifying Unique RolesFor unique role classification, we use the AMI Meet-ing Corpus.
All meetings consist of K = 4 par-ticipants, and each participant is assigned one offour roles: project manager (PM), marketing expert(ME), user interface designer (UI), or industrial de-signer (ID).As mentioned in Section 2.1, classifying theunique role of all participants, jointly, involvesenumerating over the possible permutations of{PM, ME, UI, ID}.
We use AMITRAINSET to trainthe behavior model, and then classify AMIDEVSETusing Equation 2, one feature type at a time, to iden-tify the best 3 feature types for this task; develop-ment experiments suggest that classification rateslevel off after a small handful of the best perform-ing feature types is included.
Those feature typeswere found to be fV Ik , ?fOIk,j ?j , and fOIk,j , capturingthe probability of initiating a talkspurt in silence, ofinitiating a talkspurt when someone else is speak-ing, and of initiating a talkspurt when a participantin a specific other role is speaking, respectively.
OnAMIEVALSET, these feature types lead to single-feature-type 4-way classification rates of 41%, 29%,and 53%, respectively.
When all three types are usedtogether (3K+K2 features in total), the rate is 53%.Accuracy when all feature types are used is 46%, in-dicating that some feature types are detrimental tothis task.The confusion matrix for classification using thethree best feature types is shown in Table 1.
Thematrix shows that association between the referenceassignment of PM, as well as of UI, and the hypoth-esized assignment based on the three feature typesmentioned is statistically significant.
On the otherhand, assignment of ID and ME does not deviatesignificantly from chance.6.2 Finding the ManagerUsing the same data as above, we explore the sim-plified task of finding a specific participant type.
We151HypRefID ME PM UIID 8 6 4 2ME 5 8 4 3PM 3 4 ++12 ?
1UI 4 2 ??
0 ++14Table 1: Confusion matrix for role classification onAMIEVALSET; reference assignment is found in the rows,hypothesized assignment in columns.
Correctly classifiedroles, along the diagonal, are highlighted in bold.
Statis-tical significance of association at the p < 0.005 levelper class, using a 2?2 ?2-test, is shown using ?++?
and???
?, for above chance and below chance values, re-spectively; the same is true of ?+?
and ??
?, for signifi-cance at the 0.005 ?
p < 0.05 level.equate the project manager role with L, and the re-maining roles with ?L.
This is justified by the AMImeeting scenario, in which participant groups take aproduct design from start to prototype, and in whichthe project manager is expected to make the grouprun smoothly.The behavior model, trained on AMITRAINSET,is applied using Equation 3 to determine the mostlikely index j?
of the leader L, given the observedF, from among the K = 4 alternatives.
To selectthe best 3 feature types, we once again use AMIDE-VSET; these turn out to be the same as those for roleclassification, namely fV Ik , ?fOIk,j ?j , and fOIk,j .
Usingthese three feature types individually, we are ableto identify the leader PM in 12 of the 20 meetingsin AMIEVALSET.
When all three are used together,the identification rate is 60%.
However, when allfeature types are used, the identification rate climbsto 75%.
Since all participants are equally likely tobe the leader, the baseline for comparison is randomguessing (25% accuracy).Figure 1 shows the distribution of two of the se-lected features, fV Ik and fOIk,j , for the data in AMI-TRAINSET; we also show the first standard de-viation of the single-Gaussian diagonal-covariancemodels induced.
We first note that fV Ik and fOIk,jare correlated, i.e.
that the probability of beginninga talkspurt in silence is correlated with the proba-bility of beginning a talkspurt when someone elseis speaking.
L consistently begins more talkspurts,both in silence and during other people?s speech.
It0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.0400.0050.010.0150.020.025(?L,?L)(?L,L)(L,?L)feature fVIfeaturefOI(?L,?L)(?L,L)(L,?L)Figure 1: Distribution of (fV Ik , fOIk,j ) pairs for each of(?L,?L), (?L,L), and (L,?L).
Ellipses are centeredon AMITRAINSET means and encompass one standarddeviation.is also interesting that ?L is slightly less likely toinitiate a talkspurt when L is already speaking thanwhen another ?L is.
This suggests that ?L partic-ipants consistently observe the L-status of the al-ready speaking party when contemplating talkspurtproduction.
Finally, we note that neither the proba-bility of continuing a talkspurt fV Ck (related to talk-spurt duration) nor fVk (related to overall amount oftalk) are by themselves good L/?L discriminators.7 Gender ClassificationGender classification is an example of a task with aCartesian search space.
For these experiments, weuse the AMI Meeting Corpus and the ICSI Meet-ing Corpus.
In both corpora, gender is encoded inthe first letter of each participant?s unique identifier.The ratio of male to female occurrences is 2 : 1in AMITRAINSET, and 4 : 1 in ICSITRAINSET.Choosing the majority class leads to gender classi-fication rates of 65% and 81% on AMIEVALSET andICSIEVALSET, respectively.We enumerate alternative group assignments us-ing Equation 4.
Somewhat surprisingly, no singlefeature type leads to AMIEVALSET or ICSIEVALSETclassification rates higher than those obtained by hy-pothesizing all participants to be male.
On AMIDE-VSET, one feature type (fOIk,j ) yields negligibly bet-ter accuracy, but does not generalize to the corre-152sponding evaluation data.
Furthermore, the associ-ation between reference gender labels and hypothe-sized gender labels, on both evaluation sets, does notappear to be statistically significant at the p < 0.05level.
This finding that males and females do notdiffer significantly in their deployment of talkspurtsis likely a consequence of the social structure of theparticular groups studied.
The fact that AMI rolesare acted may also have an effect.8 Seniority ClassificationAs a second example of non-unique roles, we at-tempt to classify participant seniority.
For theseexperiments, we use the ICSI Meeting corpus, inwhich each participant?s education level appears asan optional, self-reported attribute.
We have man-ually clustered these attributes into NS = 3 mu-tually exclusive seniority categories.5 Each partic-ipant?s seniority is drawn independently from S ={GRAD, PHD, PROF}; a breakdown for ICSITRAIN-SET is shown in Table 2.
Choosing the majorityclass (P (PHD) = 0.444 on ICSITRAINSET) yieldsa classification accuracy of 45% on ICSIEVALSET.We note that in this data, education level is closelycorrelated with age group.Number ofSeniorityspkrs occur meetsGRAD 15 81 33PHD 13 87 29PROF 3 28 28all 31 196 33Table 2: Breakdown by seniority S in ICSITRAINSET bythe number of unique participants (spkrs), the number ofoccurrences (occur), and the number of meetings (meets)in which each seniority occurs.8.1 Classifying Participant TypesIndependently of Conversation TypesWe first treat the problem of classifying participantseniority levels independently of the type of conver-sation being studied.
We identify the most likely se-5GRAD includes ?Grad?, as well as ?Undergrad?,?B.A.
?, and ?Finished BA in 2001?, due to their smallnumber of exemplars; PHD includes ?PhD?
and ?Postdoc?
;and PROF includes ?Professor?
only.niority assignment for all participants using Equa-tion 5.
The best three feature types, determinedusing ICSIDEVSET, are fVk , fOIk,j , and fOCk,j (repre-senting the probability of speaking, of beginning atalkspurt when a specific seniority participant is al-ready speaking, and of continuing a talkspurt whena specific seniority participant is speaking), yield-ing single-feature-type classification rates of 52%,59%, and 59%, respectively.
When used together,these three feature types produce the confusion ma-trix shown in Table 3 and a rate of 61%, better thanwhen all feature types are used (58%).
This rep-resents a 28% relative error reduction over chance.As can be seen in the table, association between thereference and hypothesized seniority assignments isstatistically significant on unseen data.
It is alsoevident that confusion between GRAD and PROF islower than between more proximate seniority levels.HypRefGRAD PHD PROFGRAD ++11 26 3PHD ?
2 ++41 ?
3PROF 0 ??
6 ++10Table 3: Confusion matrix for seniority classification onICSIEVALSET; reference assignment is found in the rows,hypothesized assignment in columns.
Highlighting anduse of ?++?, ?+?, ??
?, and ????
as in Table 1.Figure 2 shows the distribution of (fVk , fOCk,j )pairs in ICSITRAINSET, together with the first stan-dard deviation, for each combination of the al-ready speaking seniority participant and the senior-ity participant initiating a new talkspurt (except for(PROF, PROF), since there is at most one PROF ineach ICSITRAINSET meeting).As is clear from the figure, PROF participants inthis data talk more than either of the two other se-niority types.
The figure also demonstrates a differ-ence of behavior during speech overlap.
The fourellipses describing GRAD behavior when overlap-ping with any of the other three classes, as well asPHD behavior when overlapping with GRAD partic-ipants, are relatively broad and indicate the absenceof strong tendency or preference.
However, PHDparticipants are more likely to continue vocalizing inoverlap with other PHD participants, and even morelikely to continue through overlap with PROF partic-1530 0.2 0.40.30.40.50.60.70.80.91(GRAD,*)(PHD,GRAD)(PHD,PHD)(PHD,PROF)(PROF,GRAD)(PROF,PHD)feature fVfeaturefOC(GRAD,GRAD)(GRAD,PHD)(GRAD,PROF)(PHD,GRAD)(PHD,PHD)(PHD,PROF)(PROF,GRAD)(PROF,PHD)Figure 2: Distribution of (fVk , fOCk,j ) feature value pairsfor each of the (k, j) participant pairs (GRAD, GRAD),(GRAD, PHD), (GRAD, PROF), (PHD, GRAD),(PHD, PHD), (PHD, PROF), (PROF, GRAD), and(PROF, PHD).
Ellipses are centered on ICSITRAIN-SET means and encompass one standard deviation.ipants.
A similar trend is apparent for PROF partici-pants: the mean likelihood that they continue vocal-izing in overlap with GRAD participants lies below???
(bottom 17%) of their model with PHD partic-ipants.
We believe that the senior researchers in thisdata are consciously minimizing their overlap withstudents, who talk less, to make it easier for the lat-ter to speak up.8.2 Conditioning on Conversation TypeWe now repeat the experiments in the previous sec-tion, but condition the behavior and membershipmodels on meeting type t:s?
= arg maxs?SK?t?TP ( t ) P ( s | t )P (F | s , t ) , (7)where t ?
T = {Bed,Bmr,Bro}.Performance using maximum likelihood esti-mates for the behavior model P (F | s , t ) resultsin a seniority classification rate on ICSIEVALSET of61%, i.e.
no improvement over conversation-type-independent classification.
We suspect this is dueto the smaller amounts of training material.
To ver-ify this assumption, we smooth the maximum like-lihood estimates, ?Si,t, ?2Si,t, towards the maximumlikelihood conversation-type-independent estimates,?Si , ?Si , using?
?Si,t = ?
?Si,t + (1 ?
?
)?Si , (8)?
?2Si,t = ?
?Si,t + (1 ?
?)
?2Si , (9)where the value of ?
= 0.7 was selected usingICSIDEVSET.
This leads to a rate of 63% on IC-SIEVALSET.
Furthermore, if instead of estimatingthe prior on conversation type P (t) from the train-ing data, we use our meeting type estimates from(Laskowski, Ostendorf and Schultz, 2007), the clas-sification rate increases to 67%.
A control experi-ment in which the true type ttest of each test meetingis known, i.e.
P (t) = 1 if ttest = t and 0 otherwise,shows that the maximum accuracy achievable underoptimal P (t) estimation is 73%.9 ConclusionsWe have explored several socially meaningful parti-tions of participant populations in two large multi-party meeting corpora.
These include assigned role,leadership (embodied by a manager position), gen-der, and seniority.
Our proposed classifier, whichcan represent participants in groups rather than in-dependently, is able to leverage the observed differ-ences between specific pairs of participant classes.Using only low-level features capturing when partic-ipants choose to vocalize relative to one another, itattains relative error rate reductions on unseen dataof 37%, 67%, and 40% over chance on classifyingrole, leadership, and seniority, respectively.
We havealso shown that the same classifier, using the samefeatures, cannot discriminate between genders in ei-ther corpus.A comparison of the proposed feature types andtheir performance on the tasks we have explored isshown in Table 4.
Consistently, the most useful fea-ture types appear to be the probability of initiatinga talkspurt in silence, and the probability of initiat-ing a talkspurt when a participant of a specific typeis already speaking.
Additionally, on the ICSI Meet-ing Corpus, the probability of speaking appears to bedependent on seniority, and the probability of con-tinuing to vocalize in overlap with another partici-pant appears to depend on the seniority of the lat-ter.
Finally, we note that, for seniority classificationon the unseen ICSIEVALSET, the top 3 feature typesoutperform the best single feature type, indicating a154degree of feature type complementarity; this is alsotrue for L-detection on AMIEVALSET when all fea-ture types, as opposed to the single best feature type,are used.Feature AMI ICSIType R L H H S S|t?fVk 44 ?
?
?
*52 *57fV Ik *41 *60 ?
?
52 56fV Ck 34 ?
?
?
?
62?fOIj,k ?j 44 ?
?
?
47 56?fOIk,j ?j *29 *60 ?
?
49 59fOIk,j *53 *60 64 ?
*59 *59?fOCj,k ?j 24 ?
?
?
?
57?fOCk,j ?j ?
?
?
?
54 59fOCk,j ?
?
?
?
*59 *63top 3* 53 60 ?
?
61 67all 46 75 43 47 58 57priors 25 25 65 81 45 45Table 4: Comparative classification performance for 3experiments on AMIEVALSET and 3 experiments on IC-SIEVALSET, per feature type; R, L, H, and S as definedin Section 2.
Also shown is performance on the best threefeature types (selected using development data) and allfeature types, as well as that when choosing the major-ity class (?prior?
), informed by training data priors; forR and L classification, ?prior?
performance is equal torandom guessing.
???
indicates that a feature type, byitself, did not perform above the corresponding ?prior?rate; top-3 feature type selection indicated by ?
*?.Our results not only suggest new, easy-to-compute, low-level features for the automatic clas-sification of participants into socially meaningfultypes, but also offer scope for informing turn-takingor talkspurt-deployment policies in conversationalagents deployed in multi-party settings.
Addition-ally, they suggest that implicit models of certainequivalence classes may lead to improved perfor-mance on other tasks, such as multi-participant vo-cal activity detection.AcknowledgmentsWe would like to thank Jean Carletta for help-ful comments during the final preparation of thismanuscript, and Liz Shriberg for access to the ICSIMRDA Corpus.ReferencesR.
Bales.
1950.
Interaction Process Analysis.
Addison-Wesley Press, Inc.S.
Banerjee and A. Rudnicky.
2004.
Using simple speechbased features to detect the state of a meeting andthe roles of the meeting participants.
Proc.
INTER-SPEECH, pp.2189-2192.J.
Berger, S. Rosenholtz, M. Zelditch Jr. 1980.
StatusOrganizing Processes.
Annual Review of Sociology,6:479-508.J.
Carletta, S. Garrod, and H. Fraser-Krauss.
1998.
Com-munication and placement of authority in workplacegroups ?
The consequences for innovation.
SmallGroup Research, 29(5):531-559.J.
Carletta.
2007.
Unleashing the killer corpus: Expe-riences in creating the multi-everything AMI MeetingCorpus.
Language Resources and Evaluation Journal,41(2):181?190.A.
Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart, N.Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke,and C. Wooters.
2003.
The ICSI Meeting Corpus.Proc.
ICASSP, pp.364?367.K.
Laskowski, M. Ostendorf, and T. Schultz.
2007.
Mod-eling vocal interaction for text-independent classifica-tion of conversation type.
Proc.
SIGdial, pp.194-201.K.
Laskowski, C. Fu?gen, and T. Schultz.
2007.
Simulta-neous multispeaker segmentation for automatic meet-ing recognition.
Proc.
EUSIPCO, pp.1294-1298.A.
Norwine and O. Murphy.
1938.
Characteristic timeintervals in telephonic conversation.
Bell System Tech-nical Journal, 17:281-291.R.
Rienks and D. Heylen.
2005.
Dominance detectionin meetings using easily obtainable features.
Proc.MLMI.R.
Rienks, D. Zhang, D. Gatica-Perez, and W. Post.2006.
Detection and application of influence rankingsin small-group meetings.
Proc.
ICMI.J.
Rotman.
1995.
An Introduction to the Theory ofGroups.
Springer-Verlag New York, Inc.E.
Shriberg, R. Dhillon, S. Bhagat, J. Ang, and H. Car-vey.
2004.
The ICSI Meeting Recorder Dialog Act(MRDA) Corpus.
Proc.
SIGdial, pp.97?100.D.
Tannen.
1996.
Gender & Discourse.
Oxford Univer-sity Press, USA.A.
Vinciarelli.
2007.
Speakers role recognition in mul-tiparty audio recordings using social network analysisand duration distribution modeling.
IEEE Trans.
Mul-timedia, 9(6):1215-1226.D.
Wyatt, J. Bilmes, T. Choudhury, and H. Kautz.2007.
A privacy-sensitive approach to modelingmulti-person conversations.
Proc.
IJCAI, pp.1769?1775.M.
Zancanaro, B. Lepri, and F. Pianesi.
2006.
Automaticdetection of group functional roles in face to face in-teractions.
Proc.
ICMI.155
