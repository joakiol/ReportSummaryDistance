COMPUTATIONAL ASPECTS OF DISCOURSE INTHE CONTEXT OF MUC-3Lucja Iwanska (GE), Douglas Appelt (SRI), Damaris Ayuso (BBN) ,Kathy Dahlgren (ITP), Bonnie Glover Stalls (LSI), Ralph Grishman (NYU) ,George Krupka (GE), Christine Montgomery (LSI) and Ellen Riloff (UMass)INTRODUCTIO NDiscourse comprises those phenomena that usually do not arise when processing a single sentence .
It appearsto be the most difficult and probably the least understood aspect of automated message understanding.
Fiveout of fifteen sites on a MUC-3 survey listed discourse as their main weakness and an area in which t oconcentrate future research .
Virtually all systems presented here take a sentence-by-sentence approac hto text understanding .
Parsing and domain-dependent interpretation of sentences or sentence fragments(usually the latter) are followed by modules that attempt to connect these interpretations into a coheren twhole.
This paper gives an overview of the modules that make the transition from the interpretation ofsentences to the interpretation of the text that contains these sentences .
Systems presented in this paperexhibit various degrees of the following discourse understanding capabilities :?
identifying portions of text that describe different domain events ; this includes the capability of recog-nizing a single event and the capability of distinguishing multiple events ;?resolving references:?
pronoun references, e .g ., finding the referent of It in the sentence It took place this morning ,?
proper name references, e .g ., understanding that Luis Galan may be referred to as Senator Galan ;?definite references, e .g ., deciding what is the referent for The attack in the sentence The attacklook us by surprise .?
discourse representation : representation at the message level .Though these capabilities emerged' as critical for performing MUC-3 tasks they are important for an ytext understanding .
MUC-3 specificity is reflected in the fact that one deals with terrorist events only, an dthat one tends to ignore information irrelevant for the MUC-3 slot fillers .The systems exhibited much commonality in their approaches to accomplishing these tasks .
For example ,distinguishing different events is typically accomplished by some form of merging compatible events an dresolving definite references .
This commonality illustrates what was practically achievable 2 within limitedfinancial resources and limited time for porting the existing modules or developing new ones .Many more discourse understanding capabilities exist in the literature than were exhibited in the systemsthat participated in MUC-3 ; for example, explicit script (plan) knowledge, speakers' beliefs, reasoning abou t1 The sites represented by the authors of this paper were asked to describe their discourse-related capabilities .
We did notspecify which problems should or should not be included .2 We consider the fifteen systems that participated in MUC-3 as a representative sample of implemented natural languag etext processing systems in the USA .256actions, discourse structure etc [15] [6] .
Moreover, other versions of some of the text understanding system srepresented in MUC-3 have incorporated such capabilities for discourse analysis in narrow domains (se ereferences in the following sections) .
While there have been implementations of much more detailed discours eanalysis for narrow domains [26] [11] no implementation of discourse analyses for broad domains exist whic hcould guide efforts on the MUC-3 domain .If implemented, those missing capabilities would most certainly improve system performance .
There areseveral reasons why the MUC-3 versions of the participating systems lack them at this point .
First, given timeconstraints (it has been proposed to hold MUC annually) and the fact that the existing capabilities directl ycontribute to the performance in the MUC-3 domain, their improvement takes priority over implementin gnew ones .
Second, the significant effort required to research and implement any of these capabilities maynot be proportional to the increase in performance .Many aspects of discourse, e .g ., constructing a theoretical and computational model of the relation thatholds between different sentences of a text, are still open research problems [18] [22] .
A typical MUC- 3message contains fairly unrestricted text with long and complex sentences .
A fair amount of knowledge i srequired in order to correctly interpret it .
Both solving theoretical aspects of these problems and implement-ing them on such a broad and complex domain as MUC-3 3 is an extremely challenging goal, practicall yunachievable within the limited resources most systems have at their disposal .The purpose of this paper is to :1. present and compare the approaches used in the systems represented here in addressing the threediscourse understanding capabilities mentioned previousl y2.
briefly discuss directions for future discourse research .This paper is organized as follows : First, seven sites describe their discourse modules or discourse-relate dcapabilities that were used for the official MUC-3 run 4 .
The two final sections discuss the identified tasks ,along with the solutions offered by different sites and plans for future research .BBN'S PLUM : THE DISCOURSE COMPONEN TThe discourse component of BBN 's PLUM message processing system (also described in BBN 's SystemSummary in these proceedings) is responsible for extracting events of interest from what is normally ver yfragmentary syntactic and semantic information .
Using a model of the relevant events in the domain (e .g .
,"murder"), it attempts to derive any information which was not already found by the semantic interpreter .The primary output of the discourse module is a sequence of frame-like event structures, which are in tur nthe input to the template generator .The discourse module of PLUM is new (as are all the other PLUM components except the parser), an din flux?what is reported here is its state as of the MUC-3 test .
This module is a significant departurefrom the discourse module in BBN 's Janus [3] and the related module in BBN ' s Delphi [4, 5] .
The discoursecomponents of those systems, which were developed primarily for question-answering applications in limiteddomains, are able to take advantage of having complete analyses of the input sentences .
For example ,syntactic information is used to constrain intra-sentential anaphora [19] ; complete semantic representations(including quantification information) are used in generating discourse entities in a principled way [2] ; andcentering heuristics [7, 12] are used for tracking focus, improving anaphora resolution .3 For a more detailed characterization of the MUC-3 corpus see the introduction to these proceedings .4 If the description includes an existing module not used for MUC-3, then a brief explanation as to why it was not used i sgiven .257A fundamental characteristic of PLUM, however, is the emphasis on fragmentary processing at all levels ,and the assumption that a non-trivial amount of an input message may not be understood .
This led usto focus more on approaches that depend less on reliable complete understanding of the text .
Thus, fo rexample, most of the mechanisms mentioned above from our previous work are not yet present in PLUM .Instead we are taking advantage of expectations encoded in representations of the events in the domain i norder to reconstruct missing information of relevance to the templates from less than perfect syntactic an dsemantic processing 5 .Our discourse module operates on the output of the semantic interpreter, which operates on fragment sresulting from parsing and fragment combination .
Fragments are non-overlapping and together span all th einput .
The interpreter assigns a list of semantic forms to each fragment, where a form has 4 fields : a categor y(e .g ., KNOWN-ENTITY), a variable (unique identifier, e .g ., ?45), a semantic type (e .g ., PERSON), and alist of predicates (e .g ., (NAME-OF ?48 'FMLN')) .
For a particular fragment, the generated list of formscontains all the semantic information local to the fragment .
The discourse module performs the followingprimary steps in generating discourse events :1 .
For each semantic form (processed roughly in the order they arise in the text) :?
reference resolution to a previous entity is attempted if the form corresponds to a pronoun ,?
co-reference with a previous proper name is checked if the form is that of a proper name ,?
if the input corresponds to a new entity stemming from a noun phrase, it is added to a table o fentities ,?
the predicates in the form are added to a discourse predicate database which supports unificationof variables (used in reference resolution) and quick lookup, and?
if this form is relevant, the current list of discourse events is updated?this may involve creatin gan event, filling slots, and/or merging events as necessary .2 .
Once all semantic forms have been processed, heuristic rules attempt to fill in any unfilled event slots .Possible referents for a pronoun are looked up in the entity lists (which themselves can be resolve dpronouns) corresponding to the current and previous sentences?they must match the pronoun in semanti ctype and number .
Given the assumption that understanding is fragmentary, we expect that searching furthe rwould increase the possibility of obtaining an incorrect referent, though we have not yet verified this .
Aglobal list of the proper names corresponding to persons or unknown entities is kept, and any new name i slooked up in the list for a possible co-referent .
When a reference/referent pair is found, their variables ar eunified in the database .
In case of reference ambiguity the closest referent is used ; in the future we woul dlike to maintain parallel discourse databases which would represent any ambiguity or divergent inference .A semantic form may affect the list of current discourse events in various ways .
It may create a ne wevent if it is one of the semantic types of interest and it passes any arbitrary tests associated with th ecorresponding discourse event type (e .g ., a terrorist incident may not have a terrorist target) .
It may als ofill a slot of an event .
Event slots are usually filled in directly, by finding a predicate in the semantic swhich corresponds directly to a discourse-event slot, and relates the form which 'triggered' the event with afiller .
Normally only information local to the fragment will be available for filling slots in this way, since thesemantic interpreter operates at the fragment level (through the unification done during reference resolution ,some non-local slot-filling information may also be available) .
As an example, in the first sentence inDEV-MUC3-0001, `**THE ARCE BATTALION COMMAND HAS REPORTED THAT ABOUT 50 PEASANTS OF VAR-IOUS AGES HAVE BEEN KIDNAPPED** BY TERRORISTS OF THE FARABUNDO MARTI NATIONAL LIBERATIO NFRONT [FMLN) IN SAN MIGUEL DEPARTMENT, '5 Current work in the ATIS (Air Traffic Information Service) application of Delphi is also making use of event expectation sin order to better use information from context, and to aid in fragmentary fall-back processing .258the portion delimited by ** is parsed into a single fragment .
One of its relevant semantic forms and thediscourse event it generates follow :(KNOWN-EVENT ?45 KIDNAPPIN G((TI-PERP-OF ?45 733) (OBJECT-OF ?45 ?18 )(PERFECT-TENSE ?45 "HAVE") (PRESENT-TENSE ?45) (PASSIVE ?45)) )Discourse event :(KIDNAPPING trigger : ?45 "HAVE BEEN KIDNAPPED "slots :(TI-PERP-OF : ?33 "TERRORISTS" )(OBJECT-OF : ?18 "ABOUT 50 PEASANTS"))Once a new event is created and all the local slots found by the semantic interpreter are filled in, it wil lbe merged (if possible) with the closest existing event of the same type whose filled slots are compatible .Information which would make two events incompatible may be present in the new (or old) event's sur-rounding text, but to be recognized (as of MUC-3) it needs to be parsed into the same fragment as the eventtrigger and the semantic interpreter needs to interpret it (and its relation to the trigger) correctly .
Note thatthe merging process frequently has the effect of performing resolution of definite references?for example alater mention, e .g., `the kidnapping', will get merged with an earlier event if the information found wit hthe two is compatible .
However, only events of the same type are merged, which currently prevents a vagu ereference from merging with a previous specific event, i .e ., if instead of `the kidnapping' the reference is `th eattack' .
Analyzing further the conditions under which such things should be merged is one of the topics w ewill address for MUC-4 .
As an example, continuing DEV-MUC3-0001, in the second sentence the portion i n** was parsed into a fragment :'**ACCORDING TO THAT GARRISON, THE MASS KIDNAPPING TOOK PLACE ON 30 DECEMBER** IN SA NLUIS DE LA REINA' .A new event first gets created for this kidnapping and is then merged with the previous kidnapping event .Finally once all the forms have been processed, heuristic rules are applied to try to fill in any unfille ddiscourse event slots .
Most of these rules simply look outward from the forms which triggered the even t(more than one form triggers an event when event merging has occurred) looking for any form of the correctsemantic type and which passes arbitrary tests defined for that slot .
A score is assigned to indicate how faraway the filler was found .
A global parameter defines a cutoff distance for the search?for MUC-3 the searchwent no further than adjacent paragraphs.
When multiple possible fillers are found, the template-filler wil lpick the one with the highest score (the closest one), and in the case of ambiguity will arbitrarily pick one .Note that this heuristic slot filling is done after any event merging has occurred .
Because we have not yetdetermined the reliability of this fall-back heuristic, only the information found directly by the semanti cinterpreter is considered reliable and therefore used during merging .
Continuing with our example, below isa portion of the final kidnapping event after the whole message is processed :(KIDNAPPING (?45 ?73) "HAVE BEEN KIDNAPPED" "THE MASS KIDNAPPING "slots : (TI-PERP-OF :?33 score : 0 "TERRORISTS ":732 score : 1 "FARABUNDO MARTI NATIONAL LIBERATION FRONT" )(EVENT-LOCATION-OF : ?54 score : 2 "SAN MIGUEL DEPARTMENT" )(TI-RESULT-OF : ?182 score : 6 "WERE WOUNDED" )(OBJECT-OF : ?18 score : 0 "ABOUT 50 PEASANTS") )A score of 0 indicates a filler which was found directly by the semantics, 1 is a filler found in the samefragment as a trigger (though it was not connected by the semantics), and 2 is a filler found in the sam esentence, but a different fragment .
The injury result from ` WERE WOUNDED ' is incorrect (it belongs witha separate incident), the score of 6 indicates it was found in an adjacent paragraph .Although many aspects of our discourse module are preliminary, we were impressed with how well i tperformed for MUC-3 .
However, there are many areas we want to pursue in developing the module further ,25 9for example, we plan to add some tracking of tense and time, explore further the issues of merging of events ,and add a representation of ambiguity at various levels .GE'S NLTOOLSET: DPM AND TRUMPETDiscourse processing is the ability to understand connected text .
This includes the ability to recognizefragments of text that describe individual events .
We do discourse-related processing in two stages : beforeparsing, the Discourse Processing Module (DPM) [20], produces an initial segmentation of the input story int ofragments relevant for different events ; then, after parsing, the top-down expectation module (TRUMPET )[28] uses special domain knowledge to connect the representations of individual sentences relating to th esame event .Our intuition is that discourse should drive text understanding, including parsing and interpretation .Placing DPM before parsing is the first step toward this mode of text understanding .
DPM and TRUMPE Tcurrently overlap somewhat in their discourse-related processing .
We maintain them as independent modulesin order to ensure fewer errors by employing multiple strategies, to evaluate the performance of the syste min different configurations and to experiment with different control strategies .DPMDPM is a heuristically driven program that identifies segments of a story describing different domain events .The input to DPM is a story with sentence and paragraph boundaries marked .
DPM outputs text segments ,where a segment is a set of fragments of the story that could describe a single event .First, DPM searches for phrases that identify domain events .
For example, the expression set the buildin gon fire identifies an arson event, and the expression serious condition may signify the continuation of an yevent .
Primary phrases are used to decide whether a new event starts or the previous event continues .Secondary phrases are used to decide the closing boundaries of the fragments judged as relevant to th eprevious event .
Three factors influence the decision as to whether a subsequent paragraph or sentenc econtinues describing an event or starts describing a new event : (1) whether an event type that the currentprimary phrase has identified is different from the previous one ; for example, bombing versus robbery (allac kis the only type that is in general consistent with all other event types) ; (2) the definiteness of a primar yphrase; for nouns, it usually coincides with the definiteness of the noun phrase that describes an event ; (3)the amount of text with no secondary phrases that separates the current and previous primary phrases .
Theresult of this first step is a set of segments, each containing only one text fragment .Second, the program uses several heuristics to further split the segments by identifying new events .For example, one heuristic is based on the occurrence of cue phrases, e .g .
meanwhile, combined with theoccurrence of a primary phrase not in definite form .Third, the program attempts to merge certain segments, i .e ., replace them with a new segment whichcombines all their text fragments : For example, DPM merges two consecutive segments if they have consistenttypes and the first primary phrase in the second segment is in definite form .
In certain cases, DPM recognizesevents whose description is embedded in the description of other events .
In this case, the order of the segmentfragments does not correspond to the original text .We have tested DPM on 500 stories from the MUC-3 corpus (400 from DEV and 100 from TST1) .
Weattribute the good performance of DPM to the fact that it combines rudimentary anaphora resolution anda rudimentary notion of topic shift with other clues about the discourse structure .260TRUMPETTRUMPET is a domain-driven program that coordinates with the parser in order to interpret connectedtext .
It uses the following discourse-related features : (1) a simple anaphora resolution mechanism ; (2) basi cknowledge of causality that connects events with their effects ; (3) knowledge of common scenarios in adomain that connect events with their subevents ; and (4) rudimentary temporal and spatial reasoning tha tdetermines event compatibility .The input to TRUMPET is the conceptual representation of each sentence .
As its output, TRUMPETproduces a set of structures containing information about distinct domain events .For each sentence, TRUMPET applies rules to map the conceptual representation into domain even tstructures, or EStructs.
Primary EStructs roughly correspond to the MUC-3 templates (e .g .
kidnapping), andsecondary EStructs represent effect (e .g .
injury) or subevents (e .g .
hostage-release) .
Each EStruct contain sexpectations about what information may also appear in the text .
These expectations weakly representcause-effect and event-subevent relationships which are used to connect EStructs together .
CEStruct, aset of connected EStructs, corresponds to a single domain incident .
TRUMPET focuses its processing onthe active CEStruct of the message (i .e .
the most recently encountered), and stores previously deactivate dCEStructs for final post-processing .After the representation of a sentence is mapped to EStructs, TRUMPET tries to connect them .
Next ,TRUMPET checks the compatibility of the current primary EStructs with those of the active CEStruct .
ForMUC-3, two primary EStructs are incompatible if either (1) their incident types do not match ; (2) their date sare different ; or (3) their locations are different .
An attack incident type matches any other incident type .
I fthe current EStructs are compatible, then TRUMPET merges them with the active CEStruct .
By mergingEStructs, TRUMPET is in effect resolving certain references .
If the current EStructs are not compatible ,TRUMPET deactivates the current CEStruct and creates a new active CEStruct which is initialized wit hthe current EStructs .TRUMPET performs well when the text contains descriptions of domain events which include "dis-tinguishing" conceptual information.
However, TRUMPET 's performance suffers in the absence of suchinformation, since it ignores discourse information in the text .Interaction between DPM and TRUMPE TTRUMPET has difficulty distinguishing consecutive events of compatible types if it does not receive enoug hkey information to properly judge compatibility .
This may happen either when parsing or interpretationerrors occur, or when key information is missing or distributed throughout the text .
DPM addresses theseproblems as well as increases our capability to recognize discourse information in the text .
TRUMPET usesthe text segmentation produced by DPM to separate conceptual representations concerning different events .However, in certain cases, TRUMPET may override this segmentation in an attempt to overcome DP Mlimitations or errors .
We present four examples that demonstrate both the capabilities of the two module sand their interaction .1.
DPM prevents TRUMPET from merging two different events .
Message DEV-MUC3-0340contains consecutive descriptions of two bombing events .
DPM recognizes that these events are differen tbased on the indefiniteness of explosion and marks the boundary as shown below .
TRUMPET would fail t odistinguish these events due to its rudimentary spatial reasoning component, which would fail to differentiat ethe two locations .THE MOST SERIOUS INCIDENT WAS CAUSED BY UNIDENTIFIED PERSONS WHO THREW A GRENAD EAT A PRIVATELY OWNED PASSENGER BUS ON KILOMETER 6 OF THE ROAD LINKING GUATEMALA CIT YWITH PUERTO BARRIOS, ON THE ATLANTIC COAST .
ONE PERSON WAS KILLED AND AT LEAST FIVE WEREWOUNDED IN THE ATTACK .
THE FATALITY WAS AN UNIDENTIFIED WOMAN .261*boundary*ANOTHER EXPLOSION TOOK PLACE SIMULTANEOUSLY IN ZONE 5 OF GUATEMALA CITY, IN FRONT O FTHE CHURCH OF THE HOLY PRIEST OF ARS, WHOSE PARISH PRIEST, JOSE MARIA RUIZ (FATHER CHEMITA) ,WAS PREPARING TO SAY MASS .
[ the continuation of the description omitted ]2.
DPM prevents TRUMPET from over-splitting .
Message TST2-MUC3-0004 contains a longdescription of one bombing event, with an embedded single-sentence description of an attack and a murder.DPM correctly recognizes the continuation of the bombing event and prevents TRUMPET from treatin gthese descriptions as two distinct bombing events .
Unlike the previous example, TRUMPET would not b eable to merge the continuation with the first segment because it fails to recognize that the descriptions havethe same target .
[ long description of a bombing event omitted ]*boundary *THE "ZARATE WILLKA" GROUP CLAIMED RESPONSIBILITY IN AUGUST 1988 FOR THE ATTACK AGAINS TTHEN U .S .
SECRETARY OF STATE GEORGE SHULTZ AND THE KILLING OF TWO MORMON MISSIONARIES .
*boundary *TODAY'S BOMB EXPLOSION DAMAGED THE SHELVES OF A BOOK STORE, THE "PEOPLE'S PERUVIA NBANK," THE STATE BANK [NOT FURTHER IDENTIFIED] ; THE MARISCAL BALLIVIAN BUILDING, AND OTHE RSHOPS, ALL OF WHICH ARE LOCATED NEAR THE U .S .
EMBASSY.
[ the continuation of the description omitted ]3.
TRUMPET further refines DPM segmentation .
Message TST1-MUC3-0040 contains the descrip-tions of four distinct events as shown below .
DPM produces a single segment : (1) the descriptions of the firs ttwo (bombing and bombing) and the last two events (attack and bombing) are not split since they are withinthe same sentence ; and (2) the fourth event cannot be distinguished because blew up is neither definite orindefinite .
TRUMPET is able to distinguish the three bombings because they differ in location and time .However, TRUMPET is unable to distinguish the attack from the third bombing because it has no explici ttemporal or spatial information .
[ text omitted ]*boundary*ON 2 SEPTEMBER, A CAR BOMB DESTROYED THE INSTALLATIONS OF "EL ESPECTADOR" NEWSPAPE RIN BOGOTA AND 5 WEEKS LATER ANOTHER CAR BOMB CAUSED SIMILAR DAMAGE TO THE "VANGUARDI ALIBERAL" NEWSPAPER IN BUCARAMANGA, IN NORTHEASTERN COLOMBIA .SEVERAL SECURITY FORCES HEADQUARTERS HAVE ALSO BEEN HIT BY THESE ATTACKS AND AN AVIANC AAIRLINES PLANE BLEW UP IN MIDAIR ON 27 NOVEMBER KILLING ALL 107 PASSENGERS AND CREW.
*boundary*[ text omitted ]4.
TRUMPET overcomes DPM over-splitting .
Message TST1-MUC3-0083 contains a long descriptio nof one murder event, with an embedded description of a kidnapping event .
The text segmentation of DP Mis shown below .
DPM fails to recognize that the descriptions of the murder after the kidnapping are acontinuation of the same murder.
TRUMPET is able to rectify the problem by merging the last two segmentswith the first one, because the descriptions are not incompatible and they have the same target .SAN SALVADOR, 26 APR 89 (ACAN-EFE) - [TEXT] A SALVADORAN COURT YESTERDAY PRESENTED ASWORN DECLARATION BY PRESIDENT JOSE NAPOLEON DUARTE IN WHICH HE LINKS RIGHTIST LEADE RROBERTO D'AUBUISSON TO THE MARCH 1980 ASSASSINATION OF ARCHBISHOP OSCAR ARNULFO ROMERO .262[ DPM deleted irrelevant text ]THE LIST OF PLOTTERS INCLUDES RIGHTIST DEPUTY D'AUBUISSON, FOUNDER OF THE NATIONALISTREPUBLICAN ALLIANCE (ARENA) ?
THE WINNER IN THE RECENT ELECTIONS ?
AND CAPTAIN ALVARO SAR-AVIA, WHOM THE PRESIDENT ACCUSED OF BEING THE MASTERMINDS OF THE ASSASSINATION OF TH ECLERGYMAN .
*boundary *THE LIST ALSO INCLUDES THE NAMES OF CIVILIANS INVOLVED IN THE KIDNAPPING OF SEVERAL SAL-VADORAN BUSINESSMEN EARLY IN THE DECADE .
*boundary*ACCORDING TO DUARTE'S DECLARATION, 1ST INFANTRY BRIGADE SOLDIERS ARRESTED THE 24 COU PPLOTTERS IN 1980, AND SEVERAL DOCUMENTS WERE SEIZED FROM THEM, INCLUDING A NOTEBOOK WIT HPLANS FOR KILLING ROMERO .
*boundary*['DPM deleted irrelevant text ]THE ARCHBISHOP WAS KILLED BY A SNIPER WHILE SAYING MASS AT A HOSPITAL FOR CANCER PA-TIENTS .Future Direction sWe plan to further transition toward discourse-driven message understanding .
We want to be able to takeadvantage of the type of a story and in some cases, e .g ., journal articles, to recognize and utilize thei rstructure .
We plan to develop a representation of the stories that would allow the system to draw logica land plausible inferences necessary to handle questions about the story that people genrally are capabl eof answering .
Producing MUC-3 templates should be properly subsumed by such a representation .
Suchresearch will significantly extend current capabilities of our system, also for other tasks or domains 6 .
We willalso investigate the possibility of doing scenario analysis on a larger scale .
Other potential implementationa lplans include improving temporal and spatial reasoning and distributive anaphora resolution .ITP : DISCOURSE PROCESSIN GThe hallmark of the ITP approach is detailed, formal linguistic analysis .
ITP handles discourse phenomenaon a number of levels : the formal semantic level with Discourse Representation Theory [21] [1] and anaphoraresolution, the pragmatic level with naive semantics and coherence, and the discourse structure level wit hsegmentation and topic identification .Discourse Representation Theory directly displays in logical form the difference between given and ne winformation .
Objects and events which have already been introduced into a discourse are given referenc emarkers which are mapped to the entity (in a world model) which a discourse entity denotes .
Those entitie swhich are not accessible for anaphor resolution are structurally noted in the representation .
While DRTdoes not by any means solve all of the problems of formal semantic representation, it refreshingly recognizesas a formalism that meaning extends beyond the sentence .A Discourse Representation Structure (DRS) consists of reference markers (one for each entity introduce dinto the discourse), and conditions (predications of those entities) .
The critical point in the context of dat a6 We hope that one of the future MUC's will reformulate the task to the capability of answering certain questions that ar eanswerable after reading a story .
This would more closely correspond to understanding of a story263extraction is that formal semantic properties of the discourse are directly displayed in the DRS .
For example ,a negated verb phrase is represented in a subDRS which is inaccessible to anaphor resolution and can b eignored in reasoning .
The sentence `The government did not find a bomb' results in a DR Sdrsl : { thel }government(thel), not(drs2) drs2 : { al, el }bomb(al), el find(thel,al )The truth conditions for this DRS involved neither a bomb nor a `finding' event in the actual world .Similarly, sentences with semantically negative verbs such as `deny' are translated into formal representation swith the appropriate truth conditions .DRT is designed to formalize a variety of phenomena which complicate anaphor resolution .
The ITPanaphor resolution algorithm goes far beyond the mechanisms offered by DRT, incorporating surface syntacti cproperties (a preference for resolving to prior main clause subjects, etc), the formal semantic propertie sreflected in accessibility properties of DRS 's, and naive semantic properties .
The use of naive semantics i nanaphora resolution is illustrated in a text like `The government charged the guerrillas with illegal acts .
Theyhad stolen food ' .
In finding the antecedent of `they', with three possible plural NP 's as candidates, ITP'sword sense disambiguation algorithm uses naive semantics to find the verbal reading of the verb charge .` charge with ' is then an accusation making `guerrillas' agent of `acts ' .
Naive semantics knows that `acts 'refers to events, excluding that NP as antecedent of `they' .
The algorithm prefers prior subjects, but it alsoreasons about implications of events represented in the naive semantic lexicon .
Those implications suggestthat as `stealing ' is an illegal act .
Thus plausibly the intended subject of `steal ' is `guerrillas' rather than`government', as they are the agents of illegal acts in the prior sentence .In DRT different types of entities are distinguished : individuals, events, states, propositions and so on .The ITP approach to discourse makes use of these distinctions for anaphor resolution and coherence .
In theexample above, the noun `act' gets an event type reference marker rather than a individual type referenc emarker, providing the mechanism for excluding it as antecedent of a pronoun which is subject of a ver brequiring sentients as subject .
Conversely, in a text like `There were bombings last night in San Isidro .
Theattacks took place after midnight', `bombings' and `attacks ' both get event type reference markers, so tha tthe anaphor resolution algorithm looks for plausible events rather than individuals as potential antecedentsof `attack' .
The coherence relation assignment algorithm [8] similarly seeks to find relationships betwee nevent or state entities .ITP segmentation is the result of detailed linguistic analysis from syntax through formal semantics t odiscourse structure .
For MUC-3 ITP implemented a mechanism for finding temporal and locative expression sin the text .
For each clause the event reference marker in the DRS had a temporal and/or locative predicatio nadded if any new information was added in the clause .
This made segmentation very simple : new time, newplace or segmenting clue phrase (such as `meanwhile' or `in summary ') means new segment .
These thre eindicators signal that a new segment has begun .
Thus in message 99, new segments began at sentences4,8,11 and 14 .
Clues were :Sentence 1 : the place changes from San Isidro to Orrantia Sentence 8: the time changes with the phras e` in the past' Sentence 11 : the time changes with the phrase `some three years ago' Sentence 14 : the timechanges with the adverb `today 'These clues were recognized automatically by comparing the temporal and locative predications of th eevent just previously added to the DRS, with the temporal and locative predications of events introduce din the current sentence .
Segmenting phrases are recognized as adverbial predications of an event introduce dby the current sentence .
Antecedents of anaphors are sought only within the segments .The five sister segments discovered by this algorithm (see tree in the ITP System Summary) enabled th etemplate-filling code to accurately and automatically segregate the various terrorist events from each othe rand correctly posit three terrorist events and three templates .
The template reasoning code was invoked264segment by segment .
All information in the same segment was assumed to apply to the same terroristincident, if any .
This approach avoids problems of `template merging' which plague systems which invoke aterrorism template for every terror word in the text .The ITP approach to segmentation employed in MUC-3 used only three of the six factors which ar eimportant clues to discourse structure : 1) segmenting clue phrase 2) change of time, 3) change of place, 4 )certain changes of tense, 5) certain changes of aspect, 6) shift of topic .
These clues to discourse structur ewere determined in an empirical study of a novel and a corpus of newspaper articles, following a survey ofthe discourse literature .For MUC-3, the algorithm was simplified because of the syntactic complexity of the texts .
Use of topi cidentification would have permitted an even finer-grained, more correct segmentation .
This is because inmany texts a dominating topic segment can contain antecedents of anaphora, and play a role inside dominate dsegments .
In a proper anaphora resolution algorithm, antecedents should be sought in the current segmentand certain dominating segments .
The tree ITP constructed for message 99 does not fully recover th ediscourse structure of message 99, which actually has a dominating segment consisting of sentences 1,2,3 an d14 .
Sentence 15 `pops ' up to the dominating segment [13] [14] .
If this dominance structure is represented, itis then possible to find the correct antecedent for `the attacks ' in sentence 5, which refers to the attack o nthe two embassies .
Its antecedent can be found in sentence 1 of the dominating segment .Future research will enable the ITP discourse segmentation algorithm to recover discourse dominanc erelations and become sensitive to tense, aspect and topic .LSI'S DBG MESSAGE UNDERSTANDING SYSTEM :DISCOURSE PROCESSIN GLSI 's approach to discourse processing is based on the notion of text grammar, which was originally definedby Propp [27] and has more recently been elaborated by van Dijk [9], [10], and others .A text grammar is comprised of a set of rules for analyzing or generating texts conforming to a give nrule set .
In generation, the rules embody the text plan .
In analysis (e .g ., understanding the text of militarymessages in various domains), the rules embody a set of expectations about the structure and content of adiscourse that can provide a valuable knowledge source for resolving object, temporal, and spatial reference sand for coping with unexpected inputs (new or erroneous material) .
The rules embody a set of expectation sabout the structure and content of a discourse at all levels of granularity, ranging from phrase to messag eor text level .Our notion of text grammar has served us well in previous work on military message corpora, as describe din our system summary in these proceedings .
Detailed descriptions of the text grammars for two Air Forc ecorpora are contained in Montgomery and Glover [25] and in Stalls et al.
[29] .
For MUC3, however, textgrammar rules were implemented in the DBG (Data Base Generator) system only at the message level a tthe time of final testing (May 1991), since our resources had been focused on a major redevelopment o fthe grammar and parsing mechanism to a syntactic analyzer based on Government Binding principles (a sdescribed in our system summary and site report in these proceedings) .The DBG system output for the processing of each message is a text level knowledge representation fo rthe message content consisting of a set of instantiated event and object frames called templates .
7 This set oftemplates is an instantiation of the text grammar that reflects the structure and content of the given message .7 It is important to note that the term template in the DBG system is a label for the generic message level semantic andpragmatic representational units, not an application-oriented structure like the MUC templates .
The DBG templates are theglass box output or internal representational output, as opposed to the MUC templates, which are black box outputs mappe dto the external representation required by a given application : currently, extraction of specific data elements for describin gterrorist incidents in 9 Latin American countries .265The information contained in these internal templates is then mapped to the external application-oriente ddata structures, in this case the MUC-3 templates .The first internal template generated by our system is a Report template .
The Report template is a`meta template', which considers the message itself as a reporting event over and above the actual event sdescribed in the message .
Such header information can be extremely complex, as in military messages fo rthe air activity and space event domains (see our system summary and references) .
The header may eve nsupply information assumed, but not provided explicitly within the accompanying message text, such a sspecific equipment designations, which are referred to only by generic names in the text .
Because our textgrammar for MUC-3 was only partially implemented at the time of testing, just a few of the report attribute sidentified (e .g ., date of the report and country of the reporting source) were actually recorded in the Reporttemplates .In addition to header slots containing information about the reporting event itself, the Report templatecontains a set of slots that point to the internal (DBG) event/action templates generated for the text .
Theseslots may be qualified by attributes reflecting degree of certitude concerning the event pointed to (e .g.
,`probable', `possible', `apparently', etc .)
.
In turn, the event/action templates pointed to by the Reporttemplate contain slots that contain or point to objects and actions related to the given event (e .g ., agent ,patient), (which may also be qualified by degree of certitude expressions, as described above) .
So, for example ,for Message TST2-MUC3-0055, a `kidnap' event/action template was generated, with an agent slot filled b yby `commando of the pro-che guevara group tupac amaru revolutionary movement' and a patient slot fille dby `delgado parker' .
All of these templates are instantiated based on object and event/action frames in th esemantic frame hierarchy, which includes class membership, part-whole, and other semantic relations amon gframes and slots .The text grammar provides rules for Action and Object template generation and instantiation, as wel las rules for locating information in the message text .
The Template Unexpected Input Module (TUX) of th eDBG system, which tries to fill empty template slots using unexpected information encountered in the text ,uses discourse information about text (e .g ., form of the information, its location within a particular textsegment) to assist in determining whether a particular unused input string is a possible valid instantiatio nfor a particular slot .
This module was not implemented in the redesigned DBG system at the time of MUC- 3testing, however we have used it previous versions of our system to recover coordinate locations and othe rspecific expected information occurring in unexpected syntactic and semantic contexts in military domains .For MUC-3, the TUX module could be used, for example, to retrieve such expected information as th epossible identities of perpetrators and victims from event summary sentences even when the syntactic pars efails badly.
This capability is particulary valuable for MUC-3 because many such sentences are syntacticall yquite unwieldy .In the MUC3 corpus, the class of messages containing the majority of the relevant material consist sessentially of reports of events in journalistic style, where the initial sentence summarizes the most salien tfeatures of the event, and following sentences give more details .
In this respect, this discourse structure issimilar to the air activity message corpus described in Stalls et al.
[29] .
In this domain, apart from th esubject line or title sentence, which is essentially a press-style headline summarizing the first sentence, thetext grammar or discourse model for an air activity report comprises two types of sentences :1. a summary sentence type, which gives an overview of the activity ;2. a flight event sentence type, which describes the individual flight events that comprise the activity .Each unique activity description in a message will begin with a summary sentence, followed by 0 - nflight event sentences .
These sentence types are syntactically and semantically distinct, and both are quit ecomplex .
Also ?
although some messages describe a single activity carried out by one aircraft or one grou pof aircraft ?
more typically, two or more activities involving two or more groups of aircraft are described .Thus references to aircraft, activities, time, and space become extremely complex to sort out, parallelin g266the problem of resolving references to the various sets of incidents/humans/groups/inanimate objects, etc .
,represented in the MUC messages .Another complication found in messages of this type is the introduction of contextually-relevant bu tnon-primary incidents for the sake of comparison or assessment .
An example is the following sentence fro mMessage DEV-MUC3-0008 :CASTELLAR IS TH ESECOND MAYOR THAT HAS BEEN MURDERED IN COLOMBIA IN THE LAST 3 DAYS .In [25], we discuss the implications for processing of such statements of assessment as they occur i nthe space event corpus, as, for example, in : `Terrex 592 is the third low density crop enhancement/fifthgeneration corn agricultural satellite (BR02E) launched this year' .A text grammar for the MUC-3 domain is difficult to construct because , there is little similarity o fstructure across messages of a given type .
Military messages, for example, are typically designed to conve yparticular types of information precisely, whereas the broader, journalistic function of the MUC-3 messagesmakes the particular details mentioned less predictable, and stylistic variation appears to be more highlyvalued in a non-military domain, such as MUC-3 .
Some of the MUC messages seem to have been translate dfrom Spanish, which introduces additional variations .
Moreover, the sentences in the MUC-3 messages arecharacterized by a non-hypotactic or `loose' syntactic structure, relying heavily on postposed apposition ,coordination, and subordination, which makes them cumbersome to process .
An example is the MUC- 3summary sentence from Message DEV-MUC3-0008 :RICARDO ALFONSO CASTELLAR, MAYOR OF ACHI, IN THE NORTHERN DEPARTMENT OF BOLIVAR, WHO WAS KIDNAPPED ON 5 JANUARY ,APPARENTLY BY ARMY OF NATIONAL LIBERATION (ELN) GUERRILLAS, WAS FOUND DEAD TODAY, ACCORDING TO AUTHORITIES .In comparison, modifiers of noun phrases in the air activities domain (whether attributive or event-related) tended to be preposed and tightly constructed, as in the following example of a summary sentence :ONE UGANDAN KAMPALA AIR ARMY HEAVY BOMBER AVIATION DIVISION (KAl23) GULU (0335N 03315E) B-60 (BUFF C )AND TWO UGANDAN KAMPALA AIR ARMY HEAVY BOMBER DIVISION (KA456) MASAKA (0000N 00000E) BASED ,TORORO (0000N 00000E) DEPLOYED, F-TYPES (BUNNY) CONTINUE ACTIVE OVER THE GULF OF NDEGE ON 8 AUGUST 2023 .The summary sentences in the two domains exhibit other differences as well .
In the air activities exampleabove, extremely complex descriptions are used to specify the objects constituting the main topic of th emessage, which are referred to anaphorically by very simple expressions later in the discourse (typically :`the B-60 ' , `the F-types') .
In the MUC-3 texts, the simpler description (e .g ., `the kidnapping') often appear sfirst, as a sort of summary of a more detailed description appearing later in the text .In addition, the MUC texts contain many distributive referring expressions, indicating a whole sequenc eof events, which might be limited to that described in the foregoing paragraphs of a given text, or migh talso include events described earlier in other texts, such as `bloodbath ' or `violence' (e .g ., `deputies ask fo rend to violence') .
This type of referring expression did not occur in the air activities messages, although wehave noted similar anaphora in other military domains (e .g ., 'additional activity was observed in the coasta larea') .The difficulty of distinguishing events in multiple event reports is more complex for the MUC-3 message sthan for some other domains .
The description of an event in the MUC-3 corpus may consist of an NP (e .g .
,`Galan's murder ' , a sentence, a paragraph, several paragraphs, or an entire message .
In contrast, in militarymessages the paragraphs or sections describing separate events or sets of events are generally separatel ynumbered.
Even where this convention is violated, it is usually possible to detect event boundaries base don the text grammar (e .g ., encountering a summary type sentence in the air activities messages) .
.
Also, in267military message corpora, message types exist to report a type of event or activity that continues to occur .In the MUC domain, on the other hand, the prominent events and objects?terrorist incidents and huma nbeings?are by their nature unpredictable .Because of the homogeneity of military message content and structure, a text grammar is an especiall yvaluable tool .
It can predict the structure of the knowledge representation (i .e ., the internal template set )for a given message/event type that can be identified early on in processing (e .g ., launch or deorbit messagesin the space event corpus), as well as where in the text to find what kinds of information .
This same degreeof predictability cannot be achieved for the more heterogeneous MUC-3 corpus, for the reasons given above .This does not mean, however, that a text grammar approach has little to contribute to processing a corpu slike MUC-3.
On the contrary, such a corpus requires an array of well-developed analytical tools becaus eno single approach has as yet been shown to be completely successful .
It appears that a text grammar fo rthis type of corpus has to be more dynamic than that for military messages, and will probably be mor euseful for some text types than for others (e .g ., event reports vs .
speeches) .
Rather than relying on messagetype or paragraph numbering, the text grammar could identify summary sentences or paragraphs (usuall ythe first paragraph of a message or the first describing a `new' event within a message) for example, fo rcritical event reports .
As noted previously, these text segments usually contain basic information about th eevent type, the perpetrators, and the targets of the attack .
.
Later sentences and paragraphs then fill in th edetails .
Finally, there may be one or more assessment sentences, which compare the primary event to othe rsimilar events.
Also, certain critical event reporting combinations are more common than others, such a skidnapping-murder, and multiple bombings .Although the utility of a text grammar approach has yet to be established for this corpus, we envision suc han approach to be useful in sorting out which event particular information in a text describes ; guiding analy-sis of syntactic and semantic structure of different sentence types (e .g ., summary sentences introducing a ne wevent vs .
assessment sentences) ; and providing a model for text level analysis and generation/consolidationof knowledge representations for events and entities discussed in the text .
This approach can also charac-terize domain differences (e .g ., the types of anaphoric reference described above), and is therefore useful inextensions to new domains .
Our research is focusing on these areas .Although a text grammar approach will not solve all of the discourse processing problems presented b ythe MUC-3 corpus, it does provide a framework for directing the text understanding process based on textua lexpectations at the phrase, sentence, and discourse levels .NYU: INTERSENTENTIAL PROCESSING IN PROTEU SThe main task of intersentential processing in our system is to identify references to the same objects an devents and to merge this information to form a single richer description of each object and event .This merging is performed by two separate components : a reference resolution component (following se-mantic analysis) and a frame-merging component of the template generator .
Reference resolution is intende dprimarily to handle references by definite noun phrases and pronouns to entities and events introduced pre-viously in the discourse .
This component is independent of the domain and discourse structure, although i tdoes refer to the concept hierarchy for the domain .
The frame-merging component, on the other hand, ha sbeen coded specifically for the current task and is intended to handle the particular discourse patterns o fthe newspaper articles (the brief introductory description of an event which may be followed by one or mor eelaborations) .268Reference Resolutio nAs we describe in our system summary, reference resolution is applied to the output of semantic analysis .
Atthis point, the logical form is a set of nested EVENT and ENTITY structures .
Each noun phrase in the textwill have been mapped by semantic analysis into an event (if it is a nominalization) or an entity (otherwise) .Reference resolution examines each such event or entity to determine whether it can be an anaphoric referenc eto some prior event/entity.
Each potential anaphor is compared to prior entities or events (starting with th emost recent), looking for a suitable antecedent such that the class of the anaphor (in the concept hierarchy )is equal to or more general than that of the antecedent, the anaphor and antecedent match in number, th erestrictive modifiers in the anaphor have corresponding arguments in the antecedent, and the non-restrictiv emodifiers (e .g ., apposition) of the anaphor are not inconsistent with those of the antecedent .If a suitable antecedent is found, references to the new entity/event (the anaphor) are replaced byreferences to the antecedent .
In addition, for entities, if the anaphor contains non-restrictive modifiers fo rwhich there is no corresponding value in the antecedent, information from the anaphor is added to th eantecedent .
For example, message TST1?0065 mentions `TWO ITALIAN ENGINEERS' in the opening sentenceand later refers to `THE TWO ITALIANS, ROBERTO ROASCIO OF MILAN AND MARIO ACCURSO OF ROME', s oreference resolution needs to add the information about names to the prior entity, which gives informatio nabout occupations .Special tests are provided for names (people may be referred to a subset of their names) and for referrin gto groups by typical members (`terrorist column' .
.
.
`terrorists') .
In the latter case reference resolutionestablishs a `part-of' link between the group (the `column') and its members ('terrorists') ; this link is late rused to permit frame merging .Frame MergingReference resolution will handle explicit indications of prior reference, such as `The building was bombe dlast week .
The FMLN claimed responsibility for the attack .'
(Here attack will be resolved to the bombing) .On the other hand, it will not help in dealing with the repeated elaborations of events which are typical o fnewspaper style : `The EXXON building was attacked last night .
Five terrorists from the Shining Path firedtwo rockets at the EXXON building .'
These cases are handled as part of template generation .Template generation begins by converting EVENT structures for those events which are relevant to th efinal reporting task into FRAME structures .
In this process, the event-type (ultimately, the incident typ eof the template), the date, and the location are reduced to normalized forms so that it will be easier todetermine whether two FRAMES might refer to the same event .Once these FRAMEs are generated, the system attempts to merge them if one of three criteria are met :- they involve a common targe t- they come from the same sentence- they consist of an attack followed by a possible effect of an attack (damage, death, etc .
)The merging will not take place, however, if the FRAMEs are incompatible with respect to type of attack ,date, or location .These heuristics are effective when targets are explicitly mentioned .
For example, in DEV-0011 we ar etold in several ways about the death of Lopez Albujar :AUTHORITIES HAVE REPORTED THAT FORMER PERUVIAN DEFENSE MINISTER GENERAL ENRIQUE LOPE ZALBUJAR DIED TODAY .
.
.
AS A RESULT OF A TERRORIST ATTACK.
LOPEZ ALBUJAR .
.
.
WAS RIDDLED WITH269BULLETS .
.
..
HE WAS SHOT EIGHT TIMES IN THE CHEST .
THE FORMER MINISTER WAS RUSHED TO THE AI RFORCE HOSPITAL WHERE HE DIED .Reference resolution will first apply to resolve the pronouns .
FRAME merging can then combine `SHOT 'and `RIDDLED WITH BULLETS' (which are both mapped by semantics into SHOOT events) .
Richer heuristicswill be needed for cases without explicit targets (e .g ., TST1-0027 : ` .
.
.A BOMB ATTACK OCCURRED EARLYTHIS MORNING SOMEWHERE NEAR THE PLACE WHERE BOLIVIAN PRESIDENT JAIME PAZ ZAMORA AN DPERUVIAN PRESIDENT GARCIA ARE TO MEET TODAY.
NAVY LIEUTENANT JUSTO MARTINEZ .
.. REPORTE DTHAT A BOMB EXPLODED IN THE PERUVIAN TOVVN OF YUNGUYO.
.
.
.'
.ShortcomingsThe most serious shortcoming of the system is its lack of domain and world knowledge .
This is reflectedin the serious gaps still existing in our set of lexico-semantic models .
It is also reflected in the extremelylimited rules we have at present for coalescing events .
The only two semantically-based criteria we have, a snoted just above, are that two events have the same target or that an attack is followed by a description ofa possible effect of an attack .
Simple examples of knowledge the system should include in order to merg eevents properly : if you are riding in a vehicle and the vehicle is blown up, you might be injured or die ; ifyou are carrying explosives, you may be trying to bomb something .
(Of course, the knowledge the syste mmight potentially need is open ended, but we may hope that a core of knowledge associated with attackin gthings will be of substantial benefit) .Given the paucity of knowledge that we were able to enter into our system in the time alloted for MUC-3 ,we decided not to attempt to build explicit discourse structures (which would in many cases be dependen ton this knowledge) at this time .
As a result, we often failed to combine events into a single template whenappropriate .
If we are able to enrich the knowledge structures adequately for MUC-4, it may then mak esense to build discourse links as a separate step prior to template generation .Our system is also somewhat weak in handling set/element relationships .
Specifically, it will not relate aplural noun phrase to the individuals with which it coreferential unless these individuals appear syntacticall yconjoined in the text .
In other words, it will not form new groupings of individuals .
Thus, it would no thandle `X was attacked .
Y was attacked .
The attacks were conducted by Z .'
Nor is the system able tofigure out that the `TWO VEHICLES' mentioned in TST1-MUC3-0099 are the CAR-BOMB and USS REMBASSY VEHICLE, since these antecedents do not appear conjoined .SRI'S TACITUS : DISCOURSE PROCESSIN GThe TACITUS system employs the general method of abductive explanation to understand texts [16].
Thismethod of explanation is quite well suited to the narrative texts of the MUC-3 domain, because the text sconsist almost entirely of declarative sentences that are intended to convey information to the reader .
TAC-ITUS does not have an explicit discourse processing module, and does not currently employ any theory o fdiscourse structure, but rather relies on the assumption that the correct resolution of anaphora and indi-viduation of events will be a consequence of generating the best explanation for the truth of its constituentsentences, subject to minimizing the extension of certain predicates .
The justification for this assumption i sdescribed below .270Abductive InterpretationTACITUS processes each sentence S incrementally, seeking the best explanation for why that sentence woul dbe true, given its domain knowledge, D, and all of the text that it has processed up to the given point in th emessage, T .
An explanation consists of finding some minimal set of premises, A, such that DU T U A F- Ls ,where Ls is the logical form of sentence S .
The minimality of alternative sets of premises is evaluated byadding the assumption cost of each literal in A .
The assumption costs of each literal comprising the logica lform is assigned initially in accordance with heuristics reflecting the relative importance of that literal ' scontribution to the interpretation.
Assumption costs can be passed from consequent literals to anteceden tliterals in Horn clause axioms by means of weighting factors associated with each literal .
When the bestinterpretation of a sentence is found, the set of premises is added to the text theory T, which then formspart of the base theory for the interpretation of the next sentence in the text .
At any time, the contents ofthe set T can be examined by the analysis component of the system to generate a set of templates reflectin gthe text as it has been analyzed up to that point .In addition to proving and assuming literals, an important part of the abduction proof involves minimizin gthe extension of certain predicates through factoring .
If 3xP(x) is an assumption, and 3yP(y) is a goal ,then it is possible to factor the literals through unification, setting the resulting assumption cost to th eminimum assumption cost of the two literals .
This factoring operation entails the assumption that x = y ,which amounts to assuming that individuals that share property P are identical .Only a subset of the predicates in a domain should be minimized .
For example, causation is a relation thatholds among many events .
Simply because we know that event e l causes e 2 and e 3 causes e 4 is rather poorgrounds for assuming that e l and e 2 are the same.
Apparently, causation is not one of the predicates thatshould be factored.
However, predicates corresponding to natural kinds probably refer to specific entities ,and are good candidates for minimization .
Similarly, predicates relating event types to tokens should b eminimized .
If an article mentions a kidnapping twice, then it is often reasonable to assume that the sam eevent is being described .Clearly, assumption of a goal literal is not a sound operation, because the assumption might be inconsis-tent with the base theory.
This means that every set of assumptions must be checked for internal consistenc yand consistency with the base theory .
In general this is a computationally expensive process (in the casesthat it is even decidable .
TACITUS therefore uses a restricted theory to check consistency of a set of as-sumptions so that the consistency check can be computed with very little effort .
Any assumption set isrejected as inconsistent that meets any of the following criteria :?
P(a) and Q(a) are both assumptions, and a class hierarchy indicates that P and Q have disjoin textensions .?
P(a) and Q(a) are both assumptions, and P and Q are distinct predicates corresponding to propernames .?
If s l and s2 are both sets, and s l and s2 are identified through factoring, and s l and s2 have differentcardinality .This basic assumption and consistency checking mechanism drives all of the discourse processing in th ecurrent TACITUS system .Why does Minimization Work?It may not be obvious that minimization of events and individuals of a given natural kind should lead t oa correct interpretation of the text .
After all, there is no a priori justification in the world for assuming271that two individuals of a given type are the same .
Strictly on the basis of probability, it is in fact highlyunlikely.
The minimization heuristic relies on the fact that one is interpreting a coherent text that conform sto the Gricean maxim of relevance .
By assuming that a text is coherent, one can assume that the events anindividuals mentioned are related in some systematic way.
The abductive interpretation of the text makesthese relations explicit as part of the process of explaining the truth of the sentences .
Minimization ofselected relations is one way of maximizing the connections of each sentence with the text that preceeds it .Discourse Processing in TACITU STo illustrate the basic principles of discourse interpretation in TACITUS we refer to the following messag efrom the MUC-3 training corpus :LIMA, 30 MAR 89 - [TEXT] A CARGO TRAIN RUNNING FROM LIMA TO LOROHIA WAS DERAILED BEFOR EDAWN TODAY AFTER HITTING A DYNAMITE CHARGE .
INSPECTOR EULOGIO FLORES DIED IN THE EXPLO-SION .THE POLICE REPORTED THAT THE INCIDENT TOOK PLACE PAST MIDNIGHT IN THE CARAHUAICHI-JAURIN AREA .Resolving NP AnaphoraInterpreting the first sentence of this text requires making certain assumptions based on general worl dknowledge .
For example, the knowledge base expresses the fact that dynamite is an explosive substance, a`substance object' compound nominal referers to an object that is composed of the substance, an object tha tis composed of an explosive substance is a bomb, and hitting a bomb results in an explosion, and explosion scause damage, and derailing is damage .
By minimizing the extension of damage, we conclude that the hittingof the dynamite charge caused an explosion (which is a terrorist bombing incident), and the bombing cause dthe train to derail .The next sentence mentions a death in an explosion .
Correct interpretation of this sentence requiresassociation between the explicitly mentioned explosion and the explosion resulting from hitting the dynamit echarge .
Otherwise the system may conclude that two bombing events were involved .
Minimization ofexploding events results in the correct resolution .Resolving Pronominal Anaphor aThe descriptive content of pronouns is very limited, since it includes only number, gender, and animatenes sinformation .
In general this descriptive content is insufficient alone to facilitate identification of the an-tecedent .
In addition, syntactic relationships can rule out certain coreferentiality possibilities that would b econsistent with the descriptive content of the pronoun, and make others more likely.
Therefore, TACITUSuses a differnt method for resolving pronominal references than for NPs with noun heads .Hobbs [17] describes an algorithm for pronominal anaphora resolution based only on criteria of syntacti cstructure and matching of basic selectional constraints .
A statistical study by Hobbs demonstrated that thi salgorithm correctly identifies pronominal antecedents 91 .7% of the time in the texts he studied .
TACITUSemploys this algorithm to produce an ordered disjunction of coreference possiblities as part of the logica lform.
During abductive interpretation, the variable representing the referent of the prounoun is bound t othe the first alternative on this list, and if this binding passes the consistency check, it is assumed to b ethe correct resolution .
If not, successive bindings are chosen from progressively less likely alternatives a sdetermined by the resolution algorithm, until a consistent interpretation is found .
This resolution metho d272thus allows the syntactic algorithm to be improved by the incorporation of pragmatic information, althoug hno evaluation has yet been undertaken to quantify the success of this approach .Individuating EventsTACITUS does not employ any means of individuating events other than the general heuristic of finding aconsistent interpretation with the minimal number of events of each type .
There are a number of problemsposed by the MUC-3 domain that require some extensions to this basic minimization strategy .
In interpretin gthe final sentence of the above example, TACITUS relies on its knowledge that any type of event can b edescribed as an incident .
Minimization of events can be done by resolving the `incident' to either the implici texplosion, the death of Flores, or the derailing, and thus associating the locative and temporal informationcontained in this sentence with one of the events we already know about .
Since all of these events areessentially concurrent, the template generation process can correctly fill the template, no matter whic hevent is chosen as the resoution of ` incident .
'Events in the MUC-3 domain have multiple agents, objects, and instruments .
Therefore, two eventsof the same type with different agents and objects can consistently be collapsed into a single event wit hmultiple agents and objects .
The reliable individuating criteria are time and location .
However, the tem-poral reasoning necessary to accurately determine whether two intervals or locations are different can b equite complex, and do not fit within the class hierarchy or simple consistency checking mechanisms tha tare employed by the abductive theorem prover .
Therefore, these sorts of inconsistencies are not detectedduring pragmatics processing and must be left for the final analysis-template filling phase .
At this stage ofdevelopment, there is no opportunity to backtrack to earlier stages of processing if the consistency checkin gmechanism is not powerful enough to detect the relevant inconsistencies .
The incorporation of locative an dtemporal consistency checking into the abductive proof process is a current topic of investigation .Problems for Future ResearchA serious problem with this general approach to discourse processing is the combinatorics of the problem o fminimizing the predicates while at the same time searching for the cheapest abductive proof.
Each time thetheorem prover attempts to prove a goal, it could have three choices : it can prove it, assume it, or factor itwith something it already assumed .
It is easy to see that each choice point increases the size of the searc hspace exponentially .One approach to dealing with this combinatorial problem is to limit the choices by processing onl ysentences that pass a statistical relevance filter .
Another strategy along these lines is careful selection ofthe predicates to be minimized .
If predicates are related by a chain of entailments, only the most genera lpredicates in the chain should be considered for minimization .Another problem is that the approach requires a relatively rich knowledge base for consistency checking .When information outside the scope of the knowledge base is encountered, the minimization strategy i sgenerally too agressive .
The absence of information allows it to assume that almost anything is the same asanything else without contradiction .
Knowledge base construction is, of course, part of the long-term effor twe are addressing .Finally, methods must be found for expanding the consistency checking to include various temporal an dlocative inconsistencies, as well as some other problems .
For example, current consistency checking method shave trouble dealing with singular and plural entities properly, as well as collective anaphora .One type of discourse related resolution problem that the approach outlined here cannot solve is anaphor athat depends on syntactic parallelism to resolve, because all information about parallel structure of phrase sis lost by the time the abductive reasoning process operates .
However, the actual number of texts in whic h273this consideration is crucial for performing the MUC-3 task seems to be quite small, and therefore th eshortcoming is not a severe handicap for this task .Our current experience with the TACITUS system suggests that this simple but powerful method o fabductive interpretation can be quite successful at handling many of the discourse problems that arise i nthis task.
In many cases, anaphora is correctly resolved, and correct causal relationships between actions ar epostulated .
Although the system in its current state of implementation still makes mistakes, these mistake scan often be traced to inadequacies in the knowledge base .
While the ultimate success of the general approachis still an open question, current experience suggests that there is still much room for improvement befor einherent limitations are reached .UMASS' CIRCUS : CONSOLIDATIO NThe UMass system (see [24] and our system summary in these proceedings) as used for MUC-3 is compose dof a conceptual sentence analyzer, CIRCUS [23], and a discourse analysis component called `consolidation' .These two modules work together in a pipelined fashion : CIRCUS generates conceptual meaning representa-tions for individual sentences and consolidation maps these representations onto a set of response templates .We use two distinct methods for generating templates from parser output : rule-based consolidation andcase-based consolidation .Our case-based reasoning (CBR) module is an optional component that may be used to augment th eoutput of rule-based consolidation .
We used the CBR component in our official MUC-3 test run becaus eit increases recall by generating templates that rule-based consolidation may have missed.
However, theincreased recall comes at the expense of precision because many of the additional templates turn out to b espurious.
We demonstrated this recall/precision tradeoff by doing an optional MUC-3 test run without th eCBR component ; as expected, our system had lower recall but better precision (see our site report in theseproceedings) .Rule-Based ConsolidationRule-based consolidation merges the meaning representations produced by CIRCUS into a set of responsetemplates .
This process consists of 4 phases : constructing task-specific representations, partitioning, rule-based merging, and normalization .The CIRCUS parser produces task-independent meaning representations (concept nodes) for individualsentences .
Concept nodes are frame-like structures that are triggered by relevant words or phrases an dfilled by local syntactic constituents using semantic constraints and preferences .
For example, the followin gconcept node is generated from the sentence below it :TYPE = MURDERACTOR = (FMLH commandos )VICTIM = (Salvadoran leftist leader Hector Oqueli Colindres )`Salvadoran leftist leader Hector Oqueli Colindres was killed by FMLN commandos .
'Consolidation, however, must be able to reason with task-specific knowledge so it immediately convert seach concept node into a task-specific knowledge structure called a c-structure .
s During this process, explici tmemory objects are created for victims, physical targets, perpetrators, dates, and locations .
A simple8 shortfor `consolidation structure'274pronoun resolution algorithm also tries to locate pronominal referents in preceding sentences ; if it succeed sthen the referent is substituted for the pronoun in the c-structure .
The following c-structure is generatedfrom the concept node above :$MURDERACTOR = $Perp- 1ID = (FMLH commandos), ORG = (FMLN) ,HORD-SENSES = (vs-terrorist vs-organization) ,CONFIDENCE = nil, HEW-INFO = nilVICTIM = $Victim- 1ID = (Hector Oqueli Colindres), TITLE = (Salvadoran leftist leader) ,NATIONALITY = El Salvador, NUM = 1, TYPE = (vs-proper-name vs-politician )EFFECTS = (death)The second phase of consolidation, partitioning, identifies groups of c-structures that belong to the sam eincident .
The c-structures are divided into partitions that reflect a weak organization of the text .
All c -structures within a single partition are assumed to refer to the same incident, but different partitions ma yor may not correspond to the same incident .
Partitions are created by exploiting textual cues, includin gspecific phrases and patterns, as well as domain-dependent heuristics .
There are four classes of textua lcues : new-event-markers 9 introduce a new incident (e .g .
`meanwhile'), generic-event-markers suggesta generic or irrelevant event (e .g .
` wave of'), and separate-event-markers identify references to multipl eevents within a single sentence (e .g .
`the day before') .
Domain-dependent heuristics are also applied to infe rboundaries between multiple events .
For example, if a partition contains two event types that were not inthe preceding partition then we infer that this partition refers to a new incident .
During the partitioningphase, c-structures that represent irrelevant events are discarded and c-structures that contain certain type sof summary information are removed from the merging process and put aside to be used elsewhere .Once the c-structures have been partitioned, they are sequentially merged into a set of response templates .This merging process is guided by a rule base of 139 rules .
10 Most rules are condition-action pairs wherethe condition specifies whether a particular c-structure and template are compatible and the action dictate show to merge the c-structure into the template .
There are also default rules and special rules to generate anew template instead of merging the c-structure with an existing template .
As templates are created, the yare pushed onto a context stack.
Given a c-structure to be merged, the rules are applied to each templateon the stack, in turn, until one template is found to be compatible with the c-structure or until the stack i sexhausted .
If a compatible template is found then the rule fires, merges the c-structure into that template ,and moves the template to the top of the stack .
11 If no compatible template is found then default rule sdecide whether a new template should be created from the c-structure .Each rule has its own criteria for judging whether a c-structure and template are compatibile .
Somerules require only that the respective dates and locations are consistent whereas other rules may also requirecompatible targets, victims, instruments, etc .
When a rule fires, memory objects that refer to the sameentity are unified as a side effect of the merging process ; this involves proper name resolution, updating typ eand nationality information, etc .Rule-based merging also involves maintaining families of events .
Texts often contain information abou tmultiple events that were perpetrated by the same people on the same day and in the same location .
Wecall this a family of events .
To keep these events together, each template is tagged with a family id number .This is where the partitions come into play.
All c-structures within a partition are forced to merge wit htemplates in the same family .
For example, if the first c-structure in a partition is merged into a template i nfamily #2, then the remaining c-structures in that partition must also be merged into templates in famil y#2.
Therefore the first c-structure in a partition effectively commits the entire group to a particular family .9 These include possible-new-event-markers that signal a context switch only under specific conditions .10 There is a separate subset of rules for each type of c-structure.
"Hence, this is not strictly a stack since templates are not always removed from top .
However the templates are checked forcompatibility from top to bottom .275The last stage of consolidation is normalization .
This phase integrates summary information, normalizesfamilies to ensure that all incidents in the same family share perpetrators, dates, and locations, adds defaul tslot fillers, and discards templates that are deemed to be irrelevant .
Currently, we only deal with summaryinformation about similar incidents that took place in multiple locations .
If the rule-based merging processhas not already created templates for each of these incidents, then the missing templates are generated .Case-Based ConsolidationOur system also has an optional case-based reasoning (CBR) component that can be used to augmen tthe set of response templates generated by rule-based consolidation .
CBR allows us to benefit from th edevelopment corpus by examining how parser output correlated with key templates in previous texts .
TheCBR module currently contains 254 cases drawn from 383 texts.
A case is constructed from each key templateby determining which concept nodes contain slot fillers that belong in the key .
12 For example, suppose aMURDER key template contains a perpetrator and human target that correspond to the perpetrator slo tfiller in a $murder concept node from sentence 1 and a victim slot filler in a Smurder concept node fro msentence 2, respectively .
The following case would be constructed :(MURDER (0 (perp)) (1 (victim)) )This case represents concept nodes in adjacent sentences that contain a perpetrator and victim, respectively .The concept nodes generated by the parser are compared with the cases in the case base .
Some subset 1 3of cases will be retrieved .
Each retrieved case recognizes a pattern of concept nodes that resulted in a ke ytemplate in a previous message ; therefore, it recommends that this type of template should be generate dfor this text .
If rule-based consolidation has not already generated such a template, then the CBR modulewill create one from the concept nodes that retrieved the case.
In this manner, CBR can suggest additionaltemplates that rule-based consolidation may have missed or incorrectly discarded .Future WorkThere are several problems with our system that suggest directions for future research .
In general, consolida-tion does not have access to information that was not picked up by a concept node .
For instance, secondaryinformation about victims (titles, types, full names, etc .)
is often provided by text that surrounds the sen-tence(s) that actually describe the event .
Our system currently has no facility for getting this information .Along different lines, although our rule base served us well in MUC-3, we suspect that we could do better b yorganizing events in a more intelligent manner .
For example, our system might merge a bombing of target Xwith a different but compatible bombing near the top of the stack despite the fact that a bombing templat efor target X is already on the stack but has gotten buried underneath a different bombing .
An intelligentmemory organization would allow us to find the best match more naturally .
In addition, it should allow usto handle forms of summary information that could not be handled easily by our current architecture .We are also excited about the prospects for case-based consolidation .
Our CBR module was developedvery late in the project so there are still many avenues to explore .
One possible approach is to integrat erule-based and case-based consolidation .
By starting with only a small set of rules, the cases could be use dto augment the rule base and expand its coverage .
We would also like to experiment with different retrieva lalgorithms, case representations, and case bases .
We find CBR to be particularly appealing because it holdsgreat promise for improving portability and scale-up problems ; since cases can be acquired automatically, asuccessful case-based solution could be transferred quickly and easily to new domains .12 The current implementation only looks at the perpetrator, human target, and physical target slots in the key.
"Possibly empty if no similar cases are retrieved276OVERVIEW OF SELECTED ASPECTS OF DISCOURS EI: Recognizing a single event and distinguishing multiple event sThe tasks of recognizing a single event and distinguishing multiple events were considered to be themost important aspect of discourse-related processing .
For the messages in the MUC-3 corpus, these task sare particularly difficult because the description of a single event may be as short as one sentence or as lon gas an entire message (several paragraphs), and because many messages report on multiple events .The capability of recognizing a single event is important both for overgeneration and recall.
Ifthe system fails to recognize that the text describes the same event, it will produce one or more spuriou stemplates .
At the same time, it will also distribute the information about a single event across multipl etemplates .
Since only one template will be scored against the key template, the system effectively gets n ocredit for information that it correctly extracted but attributed to a different event .All systems except ITP and SRI recognize a single event primarly by checking the compatibility offrame-like data structures .
These structures contain all the information, understood or inferred from th etext, about the events encountered so far .
Events are assumed to be compatible if they are of compatibl etypes, have the same targets, and if their locations and times are not incompatible .
The event compatibilitycheck usually involves heuristics .
For this task, UMass uses an elaborate set of rules which reflect relevan tproperties of the MUC-3 corpus and in certain cases embody knowledge about text structure .
If two eventsare compatible, then the structures that represent them are merged .
This merging is usually done on th efly, with possible further merging at a final post-processing stage .GE, NYU and UMass depart somewhat from the above scheme .
GE enhances merging with an initial pre -parsing segmentation of a story into portions of text that are relevant for different events .
This segmentatio nis based on heuristics that combine weak anaphora resolution and a weak notion of topic shift with som eclues about the discourse structure .After semantic analysis, NYU performs pronoun and definite anaphora resolution .
If a definite referenceis encountered and its resolvent is found, then the event continues .
Merging of compatible data structuresis attempted only after the definite anaphora component .After parsing but before merging, UMass segments texts using textual cues and heuristics that identifyboundaries between multiple events .For SRI, a sentence continues the description of an event if an abductively derived explanation ca nbe constructed for it .
Merging of events (but not frame-like data structures) takes place down inside theabductive reasoning process .
The system hypothesizes that an event may be identical to one it alread yknows about, which if true would produce a better explanation than hypothesizing multiple events, provide dthat the identification is consistent .
Checking consistency of the facts that it knows about those events hassimilar effect as checking the compatibility of frame-like data structures .The ITP system skips merging.
It performs a post-parsing segmentation of a story based on the com-patibility of time and location of the events, as well as some clues about the discourse structure .
An even tcontinues (a new segment is not created) if there is no information about the incompatibility of time o rlocation.
In such cases, other systems will also recognize the continuation of an event and merge relevan tdata structures .The capability of recognizing the continuation of the description of a single event is closely related t odistinguishing multiple events .
It is especially difficult for the systems to distinguish multiple events ofthe same type or to distinguish attacks from other events .
As in the case of recognizing a single event, themost popular technique is to avoid merging incompatible events .
Two events are assumed to be different iftheir types, locations, times or targets are not compatible .277As before, GE, SRI and UMass depart somewhat from this scheme .
Before the merging stage of theprocessing, GE and UMass attempt to segment the text into pieces that correspond to different events .
Bothsystems use cue phrases combined with heuristics about patterns of key phrases in order to identify even tboundaries .
There are three differences between GE and UMass text segmentation : (1) a GE text segmentis intended to correspond to a single event and a UMass text segment to a group of events that share certai nproperties (e .g .
perpetrator or location), (2) GE initial text segmentation never results in multiple segment sfor a single sentence (this is done later by the merging component) and UMass sometimes produces multipl esegments for a single sentence, (3) GE segments texts before parsing, and UMass after parsing .SRI does not employ a separate merging module .
Instead, event merging takes place inside the abductivereasoner .
Two events are considered to be different if they are of different types, or if it is inconsistent wit hwhat the system knows to assume that they are the same .ITP does not use the merging technique and relies on its post-parsing text segmentation .
The similarit yin text segmentation is in the fact that GE, UMass and ITP use cue phrases for this task .
The difference sare in the fact that GE and UMass merge events, and ITP avoids the merging technique, and that GE an dUMass text segmentation is based on patterns of key phrases 14 and ITP text segmentation is based onparsed sentences .All three systems, GE, ITP and UMass, use temporal and spatial information for this task .
ITP uses i twhile segmenting texts, and GE and UMass employ the same information in their merging modules .II: Resolving references: definite references, pronouns and proper namesGE (to some extent), ITP and NYU do definite reference resolution as an independent activity.
Onlyresolution of noun phrases that involve relevant words (key words) is attempted .
GE indirectly resolvesdefinite references at the pre-processing stage by using heuristics about key word patterns .
ITP resolvesreferences based on surface syntactic constraints, referent accessability and knowledge about the world an drelations between entities in different situations .
NYU uses interpreted sentences and performs a typ esubsumption check when looking for the resolvent .Other systems do not perform definite reference resolution .
Instead, references are oftentimes resolved asthe side-effect of some other activity .
For BBN, this activity is merging compatible data structures .
For SRI ,it is constructing an abductive explanation .
If an entity is referred to by a unique set of properties, thenresolving the referent to some known entity that shares all of the properties will correspond to the cheapes tproof obtained with factoring, other things being equal .No systems handles distributive references ; for example, when the phrase the attacks refers to a subsetof attacks described earlier in the text .
Similarly no system even attempts to resolve references to event sassumed to be familiar to the reader from other messages .All systems perform pronoun resolution to various degrees .
Typically checked properties when resolv-ing pronouns are number and some semantic type constraints .
For example, the referent for she must besingular and of type person .
Some systems also employ gender check when searching for the antecedent .
Forexample, the referent for she must have female property .
ITP uses knowledge about the world and relation sbetween entities in different situations to resolve pronouns .
For SRI, a candidate for a referent must satisfycertain syntactic constraints and selectional restrictions .Most systems maintain a global list of all proper names encountered in the text .
Many can handlepartial matches and recognize that Luis Galan may be referred to as Senator Galan or Mr. Galan .14 Patterns are expressions of a regular language whose grammar contains shallow rules .
Using patterns does not meanavoiding parsing but rather doing efficient parsing of a very restricted regular language .
When we say "parsing" in this paperwe mean parsing for a context-free grammar with context-sensitive extensions that possibly allows for left- or right recursion .278Reference resolution is usually done on the fly .
Some systems delay this decision for certain references unti lthe end of the message.
For pronominal anaphora, SRI maintains a preferentially ordered list of candidat ereferents .
If the top element in the list does not pass consistency check, then the next one is considered .III: Discourse representationMost systems take a combination of bottom-up and top-down approach to discourse .
The bottom-up aspect consists in interpreting individual sentences independently and key phrase-based activation o fframe-like data structures .
The top-down aspect consists in realizing expectations encoded as slots, usuall ywith some restrictions on fillers in the activated data structures .
Merging compatible data structures, textsegmentation into portions describing different events and search for the best abductive explanations are th ethree exhibited methods to compute a coherence relation that ties pieces of text together .Usually, individual sentences are processed independently .
Satisfying expectations is one way to influenc ethe uderstanding of a subsequent sentence by the previously understood text .
Another way of doing such anincremental understanding is building an abductive proof that may depend heavily on the previous context .Most systems do not produce an explicit discourse representation .
Systems store the understoo drelevant aspects of the text in a variety of ways .
The most common are frame-like data structures thatstore information about some objects or events .
Some systems consider only events or objects relevant fo rthe MUC-3 templates .
Others, like BBN, create semantic representations of all the input that is processed .BBN, GE, LSI and UMass store understood text in such frame-like structures .In case of LSI, these structures are instantiated by a text grammar .
For some messages, they encod eexpectations about text structure and content .
NYU stores a list of sentence interpretations (logical forms )with resolved references which are subsequently transformed into frame-like structures .
ITP uses a forma ldiscourse representation, Kamp's discourse representation structures .
The main advantage of this represen-tation is making explicit the availability of an entity for anaphora resolution .
SRI stores a list of logica lforms of the sentences along with a list of premises that, combined with domain knowledge, entail all th epreviously understood sentences .Some general observation sA characteristic property of understanding MUC-3 messages is locality .
Missing fillers are looked for i nthe immediate neighborhood of the key phrases that activated the data structure, typically no further thanthe same or adjacent paragraph .
Antecedents of anaphora are looked for in the same segment .
Searchfor a pronoun resolvent typically does not go beyond the current and previous sentence .
Ambiguities, forexample, in reference resolution, are not propagated, but instead are resolved immediately .
It is difficult fo rsome systems to use information contained in a sentence different from the one containing the key phrasethat activated the structure .
As the result, systems have troubles with relating information distributedthroughout the text .
Some of this information may be recovered through merging or reference resolution .Few systems recognize and are able to take advantage of discourse structure .
For example, the dis-tribution of relevant information may depend on the style of a message .
An editorial report may contain aone-paragraph summary of the events followed by a more detailed description, but in an interview, infor-mation about the same events may be distributed throughout the text .
In certain cases, not recognizin gdiscourse structure does not hurt the performance, because the same effect may be achieved through som eother computation .
For example, if the brief introductory description of an event is followed by one or moreelaborations, then merging may be an indirect way of recognizing elaboration of the same event .
UMassdeals with summary information in the case of similar events that took place in multiple locations .279FUTURE RESEARC HFor most systems, the decision about the future research is based on the desire to perform well on MUC- 4and to qualitatively improve systems' capabilities of performing well on other tasks or in different domains .The two do not always coincide .
For example, understanding temporal relations in a text is crucial notonly for MUC, but in general .
However, NYU verified that for the TST1 set of stories, a part of this task ,undestanding semantics of temporal subordinate conjunctions, e .g ., while or since, will not contribute to th eincrease in performance .
More data characterizing the MUC-3 corpus, for example, frequency of occurenc eof different phenomena, is needed .Interestingly enough, only LSI listed improvement of its parser as a focus for future research .
All othersystems perceive handling discourse-related phenomena as the most promising area, possibly because dis-course capabilities allow one to balance the above mentioned trade-off.Recognizing a single event and distinguishing multiple events have been recognized by most sites as acentral problem of message understanding, both for MUC and in general .
Many planned extensions can beviewed as means of solving thes problems .
They include reference resolution (particularly, distributed definit eanaphora and vague references), temporal and spatial reasoning, better strategies for resolving ambiguities ,more semantic criteria for merging events, and expanding existing knowledge bases .Some sites consider discourse structure to be a promising path to explore .
One identified structure i srelatively common for journal articles .
It consists of an introductory paragraph that provides some generalor salient information about a group of events, and several paragraphs that describe individual events an dprovide more specific and possibly new information .
The capability of taking advantage of such structure sinvolves, among others, the capability of computing more sophisticated temporal and spatial relations .Some systems plan to develop a more adequate discourse representation that would subsume a MU Ctask.
This involves search for computationally feasible coherence relations .Text understanding is computationally very expensive .
Most systems control this complexity byreading only relevant fragments of text .
This usually means sacrificing completeness, because a portion o ftext judged irrelevant may contain the antecedent of an anaphor that would allow the connection of tex tfragments .
Processing only relevant text fragments also means relying more heavily on heuristics .
Somesites plan to investigate more reliable methods, for example, statistical methods, of identifying the relevanceof a text fragment .CONCLUSIO NWe discussed discourse-related processing in the context of MUC-3 conference .
MUC-3 participants exhibiteda striking commonality both in their choice of central problems and approaches to their solutions .
Threediscourse-related tasks, (1) identifying portions of text that describe different domain events, (2) resolvingreferences, and (3) discourse representation, have been identified as crucial not only for MUC but for tex tunderstanding in general .
We compared the approaches of different sites, stressing both similarities an ddifferences 1 5MUC-3 participants represented in this paper plan to invest their effort in improving or extending thei rdiscourse-related capabilities .
The identified tasks are both challenging and expensive, in terms of time an dother resources .
They involve not only implementation of known techniques, but also extensive originalresearch .15 Space limitations do not allow us to perform a more detailed analyis, but we have included references to the relevan tliterature .280References[ 1 ] N .
Asher .
A typology for attitude verbs and their anaphoric properties .
Linguistics and Philosophy,10 :125?198, 1987 .
[2] D .
Ayuso .
Discourse entities in Janus .
In Proceedings of the 27th Annual Meeting of the ACL, pages243-250, 1989 .
[3] D. Ayuso, G .
Donlon, R. Bobrow, D .
MacLaughlin, L .
Ramshaw, V .
Shaked, and R. Weischedel .
Re-search and development in natural language understanding as part of the Strategic Computing Program ?Final Report .
Vol .
3 : A guide to IRUS-II application development .
BBN Report 7191, BBN Systemsand Technologies Corp ., Cambridge, MA, 1990 .
[4] R. Bobrow, R. Ingria, and D. Stallard.
Syntactic and semantic knowledge in the Delphi unificationgrammar .
In Proceedings of the DARPA Speech and Natural Language Workshop, pages 230?236, June1990 .
[5] R. Bobrow, R. Ingria, and D .
Stallard .
The mapping unit approach to subcategorization .
In Proceedingsof the DARPA Speech and Natural Language Workshop, February 1991 .
[6] Michael Brady and Robert C .
Berwick (editors) .
Computational models of discourse .
MIT Press ,Cambridge, 1986 .
[7] S. Brennan, Friedman M ., and C. Pollard .
A centering approach to pronouns .
In Proceedings of th e25th Annual Meeting of the ACL, pages 155-162 .
ACL, 1987 .
[8] K .
Dahlgren .
Coherence relation assignment .
In Proceedings of Cognitive Science Society, pages 588?596 ,1989 .
[9] T. A .
Dijk .
Some aspects of text grammar.
Mouton, the Hague, 1972 .
[10] T. A. Dijk .
Macrostructures.
Lawrence Erlbaum, Hillsdale, NJ, 1980 .
[11] Ralph Grishman and Tomasz Ksiezyk .
Causal and temporal text analysis : the role of the domain model .In Proceedings of COLING-90, pages 126?131, 1990 .
[12] B .
Grosz, A. Joshi, and S .
Weinstein .
Providing a unified account of definite noun phrases in discourse .In Proceedings of the 21st Annual Meeting of the ACL, pages 44?50 .
ACL, 1983 .
[13] B .
Grosz and C .
Sidner .
Attention, intentions and the structure of discourse .
a review .
Computationa lLinguistics, 7 :85-98, 1986 .
[14] B. Grosz and C .
Sidner .
Attention, intentions and the structure of discourse .
a review .
ComputationalLinguistics, 12 :175?204, 1986 .
[15] Erhard Hinrichs .
Tense, quantifiers, and contexts .
Computational Linguistics, 14 :3?14, 1988 .
[16] J .
Hobbs, M .
Stickel, P. Martin, and D .
Edwards .
Interpretation as abduction .
In Proceedings of th e26th Annual Meeting of the ACL, pages 95-103, 1988 .
[17] Jerry R. Hobbs.
Resolving pronoun references .
Lingua, 44 :311?338, 1978 .
[18] Jerry R. Hobbs .
Coherence and coreference .
Cognitive Science, 3 :67?90, 1979 .
[19] R. Ingria and D .
Stallard .
A computational mechanism for pronominal reference .
In Proceedings of th e27th Annual Meeting of the ACL, pages 262-271 .
ACL, 1989 .
[20] Lucja Iwariska .
Discourse processing module .
Technical Report forthcoming, GE Research and Devel-opment Center, Schenectady, NY, 1991 .281[21] H .
Kamp .
A theory of truth and semantic representation .
In T. Groenendijk, Janssen, and M .
Stokhof,editors, Formal Methods in the Study of Language .
Mathematisch Centrum, Amsterdam, 1981 .
[22] Alex Lascarides and Nicholas Asher .
Discourse relations and defeasible knowledge .
In Proceedings ofthe 29th Annual Meeting of the ACL, pages 55-62, 1991 .
[23] W. Lehnert .
Symbolic/Subsymbolic Sentence Analysis : Exploiting the Best of Two Worlds .
In J .
Barn-den and J .
Pollack, editors, Advances in Connectionist and Neural Computation Theory, Vol .
1 .
AblexPublishers, Norwood, NJ, 1990 .
[24] W. Lehnert, C .
Cardie, D .
Fisher, E .
Riloff, and R. Williams .
The CIRCUS System as Used in MUC-3 .Technical Report forthcoming, University of Massachusetts, Amherst, MA, 1991 .
[25] C. A. Montgomery and B .C .
Glover .
A sublanguage for reporting and analysis of space events .
InAnalyzing language in restricted domains .
Lawrence Erlbaum, Hillsdale, NJ, 1986 .
[26] Rebecca J .
Passonneau .
A computational model of the semantics of tense and aspect .
ComputationalLinguistics, 14 :44-60, 1988 .
[27] V. Propp .
Morphology of the folktale .
Indiana University Press, Bloomington, 1958 .
[28] Lisa Rau and Paul Jacobs .
Integrating top-down and bottom-up strategies in a text processing system .
InProceedings of Second Conference on Applied Natural Language Processing, pages 129-135, Morristown ,NJ, Feb 1988 .
ACL .
[29] B .
G. Stalls, R .
E. Stumberger, and C.A .
Montgomery.
Long range air (Ira) data base generator (dbg) .Technical Report RADC-TR-89-366, Rome Air Development Center, Griffiss AFB, NY, 1990 .282
