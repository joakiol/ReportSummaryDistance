DEVELOPMENT, IMPLEMENTATION AND TESTING OF ADISCOURSE MODEL FOR NEWSPAPER TEXTSElizabeth D. Liddy 1, Kenneth A. McVearry 2, Woojin Paik 1, Edmund Yu 3, Mary McKenna 11 Syracuse UniversitySchool of  Information StudiesSyracuse, NY 132442 Coherent Research, Inc.1 Adler DriveEast Syracuse, NY 130573 Syracuse UniversityCollege of  Engineering and Computer ScienceSyracuse, NY 13244ABSTRACTTexts of a particular type evidence a discernible, predictableschema.
These schemata can be delineated, and as such providemodels of their respective text-types which are of use inautomatically structuring texts.
We have developed a TextStructurer module which recognizes text-level structure for usewithin a larger information retrieval system to delineate thediscourse-level organization of each document's contents.This allows those document components which are more likelyto contain the type of information suggested by the user'squery to be selected for higher weighting.
We chosenewspaper text as the first text type to implement.
Severaliterations of manually coding a randomly chosen sample ofnewspaper articles enabled us to develop a newspaper textmodel.
This process suggested that our intellectualdecomposing of texts relied on six types of linguisticinformation, which were incorporated into the Text Structurermodule.
Evaluation of the results of the module led to arevision of the underlying text model and of the Text Structureritself.1.
D ISCOURSE-LEVEL  TEXT MODELSA discourse-level model of a text type can be likened to aninterpretation model \[Breuker & Wielinga, 1986\] in that itspecifies the necessary classes of knowledge to be identifiedin order to develop the skeletal conceptual structure for aclass of entities.
The establishment of text-type modelsderives from research in discourse linguistics which hasshown that writers who repeatedly produce texts of aparticular type are influenced by the schema of that text-type and, when writing, consider not only the specificcontent they wish to convey but also what the usualstructure is for that type of text based on the purpose it isintended to serve \[Jones, 1983\].
As a result, one basictenet of discourse linguistics is that texts of a particulartype evidence the schema that exists in the minds of thosewho produce the texts.
These schemata can be delineated,and as such provide models of their respective text-typeswhich we suggest would be of use in automaticallystructuring texts.The existence of and need for such predictable structures intexts is consistent with findings in cognitive psychologysuggesting that human cognitive processes are facilitatedby the ability to 'chunk' the vast amounts of informationencountered in daily life into larger units of organized ata\[Rumelhart, 1977\].
Schema theories posit that duringchunking we recode individual units of perception intoincreasingly larger units, until we reach the level of aschema.
Humans are thought to possess chema for a widerange of concepts, events, and situations \[Rumelhart,1980\].
Discourse linguists have extended this notion tosuggest hat schema exist for text-types that participateregularly in the shared communication of a particularcommunity of users.What is delineated when a text schema is explicated is itsdiscernible, predictable structure, referred to as the text'sSuperstructure.
Superstructure is the text-level syntacticorganization of semantic ontent; the global schematicstructure; the recognizable template that is filled withdifferent meaning in each particular example of that text-type \[van Dijk, 1980\].
Among the text-types for whichschemas or models have been developed with varyingdegrees of detail are: folk-tales \[Propp, 1958\], newspaperarticles \[van Dijk, 1980\], arguments \[Cohen, 1987\],historical journal articles \[Tibbo, 1989\], and editorials\[Alvarado, 1990\], empirical abstracts \[Liddy, 1991\], andtheoretical bstracts \[Francis & Liddy, 1991\].159The goal of our current effort is to develop a componentthat can recognize text-level structure within a largerdocument detection system (DR-LINK) to enable thesystem to produce better etrieval results.
For this system,we have focused our first efforts on newspaper texts, sincethe corpus we must process includes both the WEll StreetJoornal and the Associated Press Newswire.2.
DR-L INKDR-LINK is a multi-stage document detection systembeing developed under the auspices of DARPA's TIPSTERProject.
The purpose of TIPSTER is to significantlyadvance the state of the art in document detection and dataextraction from large, real-world data collections.
Thedocument detection part of the project focuses on retrievingrelevant documents from gigabyte-sized ocumentcollections, based on descriptions of users' informationneeds called topic statements.
The data extraction partprocesses a much smaller set of documents, presumed to berelevant to a topic, in order to extract information which isused to fill a database.The overall goal of DR-LINK is to simultaneously 1)focus the flow of texts through the system by selecting asubset of texts on the basis of subject content and thenhighlighting those sub-parts of a document which arelikely spots of relevant text while 2) enriching thesemantic representation f text content by: a) delineatingeach text's discourse-level structure; b) detecting relationsamong concepts; c) expanding lexical representation withsemantically-related rms; and d) representing conceptsand relations in Conceptual Graphs.The purpose of the Text Structurer component in DR-LINK is to delineate the discourse-level organization ofdocuments' contents o that processing at later stages canfocus on those components where the type of informationsuggested in a query is most likely to be found.
Forexample, in newspaper texts, opinions are likely to befound in EVALUATION components, basic facts of the newsstory are likely to be found in MAIN EVENT, andpredictions are likely to be found in EXPECTATION.
TheText Structurer produces an enriched representation f eachdocument by decomposing it into smaller, conceptuallylabelled components.
Operationally, DR-LINK evaluateseach sentence in the input text, comparing it to the knowncharacteristics of the prototypical sentence of eachcomponent of the text-type model, and then assigns acomponent label to the sentence.In a form of processing parallel to the Text Structurer, theTopic Statement Processor evaluates each topic statementto determine if there is an indication that a particular textmodel component in the documents should be more highlyweighted when matched with the topic statementrepresentation.
For example, topic statement indicatorterms such as predict or anticipate or proposed reveal thatthe time frame of the event in question must be in thefuture in order for the document to be relevant.
Therefore,documents in which this event is reported in a piece of textwhich has been marked by the Text Structurer as beingEXPECTATION would be ranked more highly than those inwhich this event is reported in a different ext modelcomponent3.
DEVELOPMENT OF  THE NEWSSCHEMA MODELThe need for a text model specifically for newspaper text isnecessitated by the fact that the journalistic style forsakesthe linear logic of storytelling and presents the variouscategories of information in a recurrent cyclical mannerwhereby categories and the topics contained within themare brought up, dropped, and then picked up again forfurther elaboration later in the news article.
This internaltopical disorganization makes a story grammar, as well asthe expository text models \[Britton & Black, 1985\] notappropriate as text models.Therefore, we took as a starting point, the uniquelyjournalistic, hierarchical newspaper text model proposed byvan Dijk \[1988\].
With this as a preliminary model, severaliterations of coding of a sample of 149 randomly chosenWall Street Journal articles from 1987-1988 resulted in arevised News Schema which took from van Dijk's modelthe terminal node categories and organized them accordingto a more temporally oriented perspective, to support hecomputational task for which our model was to be used.We retained the segmentation f the overall structure intovan Dijk's higher level categories, namely: Summary,Story and Comment, but added several terminalcomponents a warranted by the data.The News Schema Components which comprise the modelare the categories of information which account for all thetext in the sample of articles.
The components are:CIRCUMSTANCE - context in which main event occursCONSEQUENCE - definite causal result of main eventCREDENTIAL - credentials of authorDEFINITION - definition of special terminologyERROR - mention of error that was made (in a correction)EVALUATION - author's comments on eventsEXPECTATION - likely or possible result of main event160HISTORY - non-recent past history of main eventLEAD - first sentence or paragraph which introduces orsummarizes articleMAIN EVENT - text which advances the plot or main threadof the storyNO COMMENT - refusal or unavailability of source tocommentPREVIOUS EVENT - immediate past context for main eventREFERENCE - reference to related article (title and date)VERBAL REACTION - quoted reaction from source to maineventWhile coding the sample, we developed both definingfeatures and properties for each component.
The definingfeatures convey the role and purpose of that componentwithin the News Schema while the properties providesuggestive clues for the recognition of that component in anews article.
The manual coding suggested to us that wewere in fact relying on six different ypes of linguisticinformation during our coding.
The data which wouldprovide these evidence sources was then analyzedstatistically and translated into computationallyrecognizable text characteristics.
Briefly defined, the sixsources of evidence used in the original Text Structurer are:L ikel ihood ~ Component  Occurring The unit ofanalysis for the first source of evidence is the sentence andis based on the observed frequency of each component inour coded sample set.Order ~f Components - This source of evidence relies onthe tendency of components to occur in a particular,relative order.
For this source of evidence, we calculatedacross the coded files we had of each of the sampledocuments, looking not at the content of the individualdocuments, but the component label.
We used this data tocompute the frequency with which each componentfollowed every other component and the frequency withwhich each component preceded every other component.The results are contained in two 19 by 19 matrices (one forprobability of which component follows a givencomponent and one for probability of which componentprecedes a given component).
These two can be used inconjunction when there is a sentence lying between twoother sentences which have already been coded forcomponent or even when only the component of thepreceding or following sentence is known.
For example, ifa series of sentences, a-b-c, the component label forsentence b is unknown, but the labels for sentence a and care known, these matrices provide evidence of thelikelihood that b might be any of the components in themodel.Lexical Clues - The third source of evidence is a set ofone, two and three word phrases for each component.
Theset of lexical clues for each component was chosen basedon observed frequencies and distributions.
We were lookingfor words with sufficient occurrences, tatistically skewedobserved frequency of occurrence ina particular component,and semantic indication of the role or purpose of eachcomponent.
For example, all the clues for VERBALREACTION reveal the distinctly informal nature of quotedcomments and the much more personal nature of thiscomponent when compared to the other components in anewspaper text.Syntactic Sources We make use of two types ofsyntactic evidence: 1) typical sentence l ngth as measuredin average number of words per sentence for eachcomponent; 2) individual part-of-speech distribution basedon the output of the part-of-speech tagging of eachdocument, using POST.
This evidence helps to recognizethose components which, because of their nature, tend tohave a disproportionate number of their words be of aparticular part of speech.
For example, EVALUATIONcomponent sentences tend to have more adjectives thansentences in other components.Tense Distribution - Some components, as might beexpected by their name alone, tend to contain verbs of aparticular tense more than verbs of other tenses.
Forexample, DEFINITION sentences seldom contain past tense,whereas the predominate nse in HISTORY and PREVIOUSEVENT sentences i  the past tense, based on POST tags.Continuation Clues The sixth and final source ofevidence is based on the conjunctive relations uggested inHalliday and Hasan's Cohes ion  i...nEn~lish.
Thecontinuation clues are lexical clues which occur in asentence-initial position and were observed in our codedsample data to predictably indicate either that the currentsentence continues the same component as the priorsentence (e.g.
And or In addition) or that there is a changein the component (e.g.
However or Thus).4.
EMPIR ICAL  TEST ING OF  THEMODELThe above computational method of instantiating adiscourse-level model of the newspaper text-model has beenincorporated in an operational system (DR-LINK).
Theoriginal Text-Structurer evaluated each sentence of an inputnewspaper article against hese six evidence sources for thepurpose of assigning a text-level label to each sentence.This implementation uses the Dempster-Shafer Theory ofEvidence Combination \[Shafer, 1976\] to coordinateinformation from some very complex matrices of statisticalvalues for the various evidence sources which were161generated from the intellectual analysis of the sample of149 _~.fiU Slre?\[ Journal articles.attribute is multi-valued: its possible values are "past","present", past or present", and "future".Operationally, the text is processed a sentence at a time,and each source of evidence assigns a number between 0and 1 to indicate the degree of support hat evidence sourceprovides to the belief that a sentence is of a particularnews-text component.
Then, a simple supporting functionfor each component is computed and the component withthe greatest support is selected.The Text Structurer was tested using five of the sixevidence sources.
(The algorithms for incorporatingevidence from the continuation clues were not complete atthe time of testing, so that evidence source was not addedto the system.)
We tested the Text Structurer on a set of116 Wall Street Journal articles, consisting of over twothousand sentences.The first run and evaluation of the original Text Structurerresulted in 72% of the sentences being correctly identified.A manual simulation of one small, heuristic adjustmentwas tested and improved the system's performance to74%of the sentences correctly identified.
A second manualadjustment for a smaller sample of sentences resulted in80% correct identification of components for sentences.6.
CURRENT MODELAs a result of our analysis of text based on its attributes,we revised both the text-type model and the algorithmsused by the Text Structurer.
Revisions to the modelfocused primarily on subdividing components and addingnew components o fill in gaps in the model and make itmore precise.
Revisions to the processing algorithmsinclude: 1) restricting the sources of evidence used tolexical clues only; 2) establishing an order of precedencefor components; 3) moving from a single lexicon to alexicon for each component; 4) discontinuing the use ofthe Dempster-Shafer method of evidence combination; 5)moving the level of analysis from the sentence to theclause level.The new components:CIRCUMSTANCE-STOCK - closing price of stock mentionedin the ~ticleCONSEQUENCE-PAST/PRESENT - past or present causalresult of main event5.
ATTRIBUTE MODELAfter evaluating the preliminary results from the TextStructurer, we became dissatisified with some aspects ofthe model we developed and the processing based on thatmodel.
We needed a more precise way to define thecomponents in the model, and we saw that frequently asentence contained information for more than onecomponent.As a result, we developed a set of attributes of newspapertext in order to first better distinguish between similarcomponents, and then to assign the attributes to textindependent of component labels.
These attributes areusually binary in nature.
We identified eight attributes:Time, Tense, Importance, Attribution, Objectivity,Definiteness, Completion, and Causality.CONSEQUENCE-FUTURE - future causal result of maineventEVALUATION - opinion attributed to a sourceEVALUATION-JOURNALIST - opinion not attributed to asomeEXPECTATION-JOURNALIST - likely or possible result ofmain event not attributed to a sourceFIGURE DESCRIPTION - text which describes a nearbyfigure, table, etc.LEAD-ATTENTION - attention-getting lead (does notsummarize)LEAD-FUTURE - lead which refers to the futureFor example, the Importance attribute has two possiblevalues: "foreground" and "background".
Componentswhich are in the foreground include LEAD and MAINEVENT; background components include CIRCUMSTANCE,DEFINITION, PREVIOUS EVENT, HISTORY, VERBALREACTION, and NO COMMENT.
The Objectivity attributeis also binary: its possible values are "objective" and"subjective".
Object ive components includeCIRCUMSTANCE, MAIN EVENT, PREVIOUS EVENT, andHISTORY; subjective components include VERBALREACTION, EVALUATION, and EXPECTAION.
The TimeLEAD-HISTORY - lead which refers to the non-recent pastLEAD-PREVIOUS - lead which refers to the recent pastMAIN-EXAMPLE - specific instance or example of maineventMAIN-FUTURE - main event set in the futureMAIN2 - alternate main event (new story)PAST - undated past context of main event1627.
FUTURE WORKThere are several areas we would like to explore, both inimproving the operation of the Text Structurer and indemonstrating its applicability.
One obvious way toimprove the accuracy and coverage of the Text Structurer isto expand the lexicons for each component, via corpus-guided acquisition of synonyms.
Another possibility isthat ordering and continuation evidence can in fact be usedto augment lexical evidence, e.g.
for sentences whichshould be labeled HISTORY and which follow a HISTORYlexical clue but which themselves do not contain anyHISTORY clues.
One area which needs improvement isdistinguishing between foreground and backgroundcomponents, e.g.
MAIN EVENT vs.
CIRCUMSTANCE.
It isclear that purely lexical information is not sufficient omake the distinction, and that patterns of verbs and otherwords, ordering, and other information are required, if notsome internal understanding of the subject of the text.There are several possible uses of the Text Structurermodule in a document detection system.
Within DR-LINK, it can be used as a focusing mechanism (filter orweighting) for other modules, e. g. the Relation-ConceptDetector, which identifies concepts and relations betweenconcepts in text.
For example, the Relation-ConceptDetector can be set to emphasize those sentences which arelabeled with a foreground component (LEAD, MAIN EVENT,etc.)
by the Text Structurer.
Another application outside ofDR-LINK is as an intermeditate process between documentdetection and data extraction.
Once a document isdetermined to be relevant, he Text Structurer can focus thedata extraction process on those sentences or sentencefragments which are most likely to contain the informationrequired to fill the database.8.
CONCLUSIONSAlthough we are clearly in the early stages of developmentof the Text Structurer, we find these results quitepromising and are eager to share our empirical results andexperiences in creating an operational system with othercomputational linguists.
To our knowledge, no similar,operational discourse structuring system has yet beenreported in the literature.We have applied the newspaper text-type model to textfrom a different source, by coding a sample of APNewswire articles.
This effort verified that the model wasgeneral enough to handle news text from various sources;in fact, a subset of the model covered all cases seen in theAP text.We are in the process of evaluating the latest version of theText Structurer based on the current newspaper text model.We will next apply a similar methodology to thedevelopment of a model and processing component forautomatically structuring full-length, technical journalarticles.2.3.4.5.6.7.8..10.11.12.REFERENCESAlvarado, S.J.
(1990).
Understanding editorial text:A computer model of argument comprehension.Boston, MA: Kluwer Academic Publishers.Breuker & Wielinga.
(1986).
Models o_.!.
exnertise.ECAI.Britton, B.
& Black, J.
(1985).
"Understandingexpository text: From structure to process and worldknowledge."
In B. Britton & J.
Black (Eds.
),Understanding e~lpositorv texts: ,dk theoretical andpractical handbook fo._.
!, analvzin2 exolanatorv text.(pp.
1-9).
Hillsdale, NJ: Lawrence Erlbaum Associates.Cohen, R. (1987).
"Analyzing the structure ofargumentative discourse."
Computational Linguistics.13, pp.
11-24.Francis, H. & Liddy, E. D. (1991).
"Structuredrepresentation f theoretical abstracts: Implicationsfor user interface design."
In Dillon, M.
(Ed.
),Interfaces for information retrieval and onlinesystems.
NY: Greenwood Press.Halliday, M. A. K. & Hasan, R. (1976).London, Longmans.Jones, L. B.
(1983).
Pragmatic asvects 9_\[Englishtext structure.
Arlington, TX: Summer Institute ofLinguistics.Liddy, E. D. (1991).
"The discourse-level structure ofempirical abstracts: An exploratory study.
"Information Processing & Management.
(pp.
55-81).Meteer, M., Schwartz, R. & Weischeidel, R.
(1991).
"POST: Using probabilities in language processing.
"Proceedings of the Twelfth International Conferenceon Artificial Intelligence.
Sydney, Australia.Propp, V. (1958).
Mornhologvg.\[tll.~folk-tale.
(L.Scott, Trans.).
Bloomington: Indiana UniversityPress.
(Original work published 1919).Rumelhart, D. (1977).
"Understanding andsummarizing brief stories."
In D. LaBerge & S. J.Samuels (Eds.
), Basic nrocesses ill. reading:Percention and comorehension (pp.
265-303).Hillsdale, NJ: Lawrence Earlbaum Associates.Rumelhart, D. (1980).
"Schemata: the building blocksof cognition."
In R. Spiro, B. Bruce, & W.
Brewer(Eds.
), Theoretical i~sue$ in reading comvrehension:Perspectives from cognitive psychology, linguistics.artificial intelligence and education (pp.
33-58).Hillsdale, NJ: Lawrence Earlbaum Associates.16313.
Shafer, G. (1976).
A mathematical theory of evidence.Princeton, N J: Princeton University Press.14.
Tibbo, H. R. (1989).
Abstracts.
olaline searching, andthe humanities: An analysis of the structure andcontent of abstracts of historical discourse.
Ph.D.Dissertation, College of Library and informationScience,15.
van Dijk, T. A.
(1980).
Macrostructures: Aninterdisciplinary study of global structures indiscourse, interaction, and cognition.
Hillsdale, NJ:Lawrence Earlbaum Associates.16.
van Dijk, T. A.
(1988).
News analysis: Case studies ofilaterna~ional and national news in the oress.Hillsdale, NJ: Lawrence Earlbaum Associates.164
