Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 46?56,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsIdentifying Argumentative Discourse Structures in Persuasive EssaysChristian Stab?and Iryna Gurevych??
?Ubiquitous Knowledge Processing Lab (UKP-TUDA)Department of Computer Science, Technische Universit?at Darmstadt?Ubiquitous Knowledge Processing Lab (UKP-DIPF)German Institute for Educational Researchwww.ukp.tu-darmstadt.deAbstractIn this paper, we present a novel ap-proach for identifying argumentative dis-course structures in persuasive essays.
Thestructure of argumentation consists of sev-eral components (i.e.
claims and premises)that are connected with argumentative re-lations.
We consider this task in twoconsecutive steps.
First, we identify thecomponents of arguments using multiclassclassification.
Second, we classify a pairof argument components as either supportor non-support for identifying the struc-ture of argumentative discourse.
For bothtasks, we evaluate several classifiers andpropose novel feature sets including struc-tural, lexical, syntactic and contextual fea-tures.
In our experiments, we obtain amacro F1-score of 0.726 for identifyingargument components and 0.722 for argu-mentative relations.1 IntroductionArgumentation is a crucial aspect of writing skillsacquisition.
The ability of formulating persuasivearguments is not only the foundation for convinc-ing an audience of novel ideas but also plays a ma-jor role in general decision making and analyzingdifferent stances.
However, current writing sup-port is limited to feedback about spelling, gram-mar, or stylistic properties and there is currently nosystem that provides feedback about written argu-mentation.
By integrating argumentation miningin writing environments, students will be able toinspect their texts for plausibility and to improvethe quality of their argumentation.An argument consists of several components.
Itincludes a claim that is supported or attacked by atleast one premise.
The claim is the central compo-nent of an argument.
It is a controversial statementthat should not be accepted by the reader withoutadditional support.1The premise underpins thevalidity of the claim.
It is a reason given by anauthor for persuading readers of the claim.
Argu-mentative relations model the discourse structureof arguments.
They indicate which argument com-ponents are related and constitute the structure ofargumentative discourse.
For example, the argu-ment in the following paragraph contains four ar-gument components: one claim (in bold face) andthree premises (underlined).?
(1) Museums and art galleries providea better understanding about arts thanInternet.
(2) In most museums and artgalleries, detailed descriptions in termsof the background, history and authorare provided.
(3) Seeing an artwork on-line is not the same as watching it withour own eyes, as (4) the picture onlinedoes not show the texture or three-di-mensional structure of the art, which isimportant to study.
?In this example, the premises (2) and (3) sup-port the claim (1) whereas premise (4) is a supportfor premise (3).
Thus, this example includes threeargumentative support relations holding betweenthe components (2,1), (3,1) and (4,3) signaling thatthe source component is a justification of the targetcomponent.
This illustrates two important proper-ties of argumentative discourse structures.
First,argumentative relations are often implicit (not in-dicated by discourse markers; e.g.
the relationholding between (2) and (1)).
Indeed, Marcu andEchihabi (2002) found that only 26% of the ev-idence relations in the RST Discourse Treebank(Carlson et al., 2001) include discourse markers.1We use the term claim synonymously to conclusion.In our definition the differentiation between claims andpremises does not indicate the validity of the statements butsignals which components include the gist of an argumentand which are given by the author as justification.46Second, in contrast to Rhetorical Structure Theory(RST) (Mann and Thompson, 1987), argumenta-tive relations also hold between non-adjacent sen-tences/clauses.
For instance, in the corpus com-piled by Stab and Gurevych (2014) only 37% ofthe premises appear adjacent to a claim.
There-fore, existing approaches of discourse analysis,e.g.
based on RST, do not meet the require-ments of argumentative discourse structure iden-tification, since they only consider discourse re-lations between adjacent sentences/clauses (Peld-szus and Stede, 2013).
In addition, there are nodistinct argumentative relations included in com-mon approaches like RST or the Penn DiscourseTreebank (PDTB) (Prasad et al., 2008), since theyare focused on identifying general discourse struc-tures (cp.
section 2.2).Most of the existing argumentation miningmethods focus solely on the identification of ar-gument components.
However, identifying argu-mentative discourse structures is an important task(Sergeant, 2013) in particular for providing feed-back about argumentation.
First, argumentativediscourse structures are essential for evaluating thequality of an argument, since it is not possibleto examine how well a claim is justified withoutknowing which premises belong to it.
Second,methods that recognize if a statement supports agiven claim enable the collection of additional ev-idence from other sources.
Third, the structure ofargumentation is needed for recommending betterarrangements of argument components and mean-ingful usage of discourse markers.
Both foster ar-gument comprehension and recall (Britt and Lar-son, 2003) and thus increase the argumentationquality.
To the best of our knowledge, there iscurrently only one approach that aims at identi-fying argumentative discourse structures proposedby Mochales-Palau and Moens (2009).
However,it relies on a manually created context-free gram-mar (CFG) and is tailored to the legal domain,which follows a standardized argumentation style.Therefore, it is likely that it will not achieve ac-ceptable accuracy when applied to more generaltexts in which discourse markers are missing oreven misleadingly used (e.g.
student texts).In this work, we present a novel approachfor identifying argumentative discourse structureswhich includes two consecutive steps.
In the firststep, we focus on the identification of argumentcomponents using a multiclass classification ap-proach.
In the second step, we identify argumen-tative relations by classifying a pair of argumentcomponents as either support or non-support.
Inparticular, the contributions of this work are thefollowing: First, we introduce a novel approachfor identifying argumentative discourse structures.Contrary to previous approaches, our approachis capable of identifying argumentative discoursestructures even if discourse markers are missing ormisleadingly used.
Second, we present two novelfeature sets for identifying argument componentsas well as argumentative relations.
Third, we eval-uate several classifiers and feature groups for iden-tifying the best system for both tasks.2 Related Work2.1 Argumentation MiningPrevious research on argumentation mining spansseveral subtasks, including (1) the separation ofargumentative from non-argumentative text units(Moens et al., 2007; Florou et al., 2013), (2)the classification of argument components orargumentation schemes (Rooney et al., 2012;Mochales-Palau and Moens, 2009; Teufel, 1999;Feng and Hirst, 2011), and (3) the identificationof argumentation structures (Mochales-Palau andMoens, 2009; Wyner et al., 2010).The separation of argumentative from non-argumentative text units is usually considered asa binary classification task and constitutes one ofthe first steps in an argumentation mining pipeline.Moens et al.
(2007) propose an approach for iden-tifying argumentative sentences in the Araucariacorpus (Reed et al., 2008).
The argument an-notations in Araucaria are based on a domain-independent argumentation theory proposed byWalton (1996).
In their experiments, they ob-tain the best accuracy (73.75%) using a combi-nation of word pairs, text statistics, verbs, and alist of keywords indicative for argumentative dis-course.
Florou et al.
(2013) report a similar ap-proach.
They classify text segments crawled witha focused crawler as either containing an argu-ment or not.
Their approach is based on severaldiscourse markers and features extracted from thetense and mood of verbs.
They report an F1-scoreof 0.764 for their best performing system.One of the first approaches focusing on theidentification of argument components is Argu-mentative Zoning proposed by Teufel (1999).
Theunderlying assumption of this work is that argu-47ment components extracted from a scientific arti-cle provide a good summary of its content.
Eachsentence is classified as one of seven rhetoricalroles including claim, result or purpose.
The ap-proach obtained an F1-score of 0.462using struc-tural, lexical and syntactic features.
Rooney etal.
(2013) also focus on the identification of ar-gument components but in contrast to the work ofTeufel (1999) their scheme is not tailored to a par-ticular genre.
In their experiments, they identifyclaims, premises and non-argumentative text unitsin the Araucaria corpus and report an overall ac-curacy of 65%.
Feng and Hirst (2011) also usethe Araucaria corpus for their experiments but fo-cus on the identification of argumentation schemes(Walton, 1996), which are templates for forms ofarguments (e.g.
argument from example or argu-ment from consequence).
Since their approach isbased on features extracted from mutual informa-tion of claims and premises, it requires that the ar-gument components are reliably identified in ad-vance.
In their experiments, they achieve an accu-racy between 62.9% and 97.9% depending on theparticular scheme and the classification setup.In contrast to all approaches mentioned above,the work presented in this paper focuses be-sides the separation of argumentative from non-argumentative text units and the classification ofargument components on the extraction of the ar-gumentative discourse structure to identify whichcomponents of the argument belong together forachieving a more fine-grained and detailed analy-sis of argumentation.
We are only aware of one ap-proach (Mochales-Palau and Moens, 2009; Wyneret al., 2010) that also focuses on the identifica-tion of argumentative discourse structures.
How-ever, this approach is based on a manually createdCFG that is tailored to documents from the legaldomain, which follow a standardized argumenta-tion style.
Therefore, it does not accommodate ill-formatted arguments (Wyner et al., 2010), whichare likely in argumentative writing support.
In ad-dition, the approach relies on discourse markersand is therefore not applicable for identifying im-plicit argumentative discourse structures.2.2 Discourse RelationsIdentifying argumentative discourse structures isclosely related to discourse analysis.
As illustrated2Calculated from the precision and recall scores providedfor individual rhetorical roles in (Teufel, 1999, p. 225).in the initial example, the identification of argu-mentative relations postulates the identification ofimplicit as well as non-adjacent discourse rela-tions.
Marcu and Echihabi (2002) present the firstapproach focused on identifying implicit discourserelations.
They exploit several discourse mark-ers (e.g.
?because?
or ?but?)
for collecting largeamounts of training data.
For their experimentsthey remove the discourse markers and discoverthat word pair features are indicative for implicitdiscourse relations.
Depending on the utilized cor-pus, they obtain accuracies between 64% and 75%for identifying a cause-explanation-evidence rela-tion (the most similar relation of their work com-pared to argumentative relations).With the release of the PDTB, the identifica-tion of discourse relations gained a lot of interestin the research community.
The PDTB includesimplicit as well as explicit discourse relations ofdifferent types, and there are multiple approachesaiming at automatically identifying implicit rela-tions.
Pitler et al.
(2009) experiment with polaritytags, verb classes, length of verb phrases, modal-ity, context and lexical features and found thatword pairs with non-zero Information Gain yieldbest results.
Lin et al.
(2009) show that besidelexical features, production rules collected fromparse trees yield good results, whereas Louis etal.
(2010) found that features based on named-entities do not perform as well as lexical features.However, current approaches to discourse analy-sis like the RST or the PDTB are designed to ana-lyze general discourse structures, and thus includea large set of generic discourse relations, whereasonly a subset of those relations is relevant for ar-gumentative discourse analysis.
For instance, theargumentation scheme proposed by Peldszus andStede (2013) includes three argumentative rela-tions (support, attack and counter-attack), whereasStab and Gurevych (2014) propose a scheme in-cluding only two relations (support and attack).The difference between argumentative relationsand those included in general tagsets like RST andPDTB is best illustrated by the work of Biran andRambow (2011), which is to the best of our knowl-edge the only work that focuses on the identifica-tion of argumentative relations.
They argue thatexisting definitions of discourse relations are onlyrelevant as a building block for identifying argu-mentative discourse and that existing approachesdo not contain a single relation that corresponds to48a distinct argumentative relation.
Therefore, theyconsider a set of 12 discourse relations from theRST Discourse Treebank (Carlson et al., 2001) asa single argumentative relation in order to identifyjustifications for a given claim.
They first extracta set of lexical indicators for each relation fromthe RST Discourse Treebank and create a wordpair resource using the English Wikipedia.
In theirexperiments, they use the extracted word pairs asfeatures and obtain an F1-score of up to 0.51 usingtwo different corpora.
Although the approach con-siders non-adjacent relations, it is limited to theidentification of relations between premises andclaims and requires that claims are known in ad-vance.
In addition, the combination of severalgeneral relations to a single argumentative relationmight lead to consistency problems and to noisycorpora (e.g.
not each instance of a contrast rela-tion is relevant for argumentative discourse).3 DataFor our experiments, we use a corpus of per-suasive essays compiled by Stab and Gurevych(2014).
This corpus contains annotations of ar-gument components at the clause-level as wellas argumentative relations.
In particular, it in-cludes annotations of major claims, claims andpremises, which are connected with argumentativesupport and attack relations.
Argumentative rela-tions are directed (there is a specified source andtarget component of each relation) and can holdbetween a premise and another premise, a premiseand a (major-) claim, or a claim and a major claim.Except for the last one, an argumentative relationdoes not cross paragraph boundaries.Three raters annotated the corpus with an inter-annotator agreement of ?U= 0.72 (Krippendorff,2004) for argument components and ?
= 0.81 forargumentative relations.
In total, the corpus com-prises 90 essays including 1,673 sentences.
Sinceit only contains a low number of attack relations,we focus in this work solely on the identificationof argument components and argumentative sup-port relations.
However, the proposed approachcan also be applied to identify attack relations infuture work.4 Identifying Argument ComponentsWe consider the identification of argument com-ponents as a multiclass classification task.
Eachclause in the corpus is either classified as majorclaim, claim, premise or non-argumentative.
Sothis task includes besides the classification of ar-gument components also the separation of argu-mentative and non-argumentative text units.
Welabel each sentence that does not contain an ar-gument component as class ?none?.
Since manyargument components cover an entire sentence(30%), this is not an exclusive feature of this class.In total, the corpus contains 1,879 instances.Table 1 shows the class distribution among theinstances.
The corpus includes 90 major claims(each essay contains exactly one), 429 claims and1,033 premises.
This proportion between claimsand premises is common in argumentation sinceclaims are usually supported by several premisesfor establishing a stable standpoint.MajorClaim Claim Premise None90 (4.8%) 429 (22.8%) 1,033 (55%) 327 (17.4%)Table 1: Class distribution among the instances.The corpus contains 1552 argument componentsand 327 non-argumentative instances.For our experiments, we randomly split the datainto a 80% training set and a 20% test set withthe same class distribution and determine the bestperforming system using 10-fold cross-validationon the training set only.
In our experiments, weuse several classifiers (see section 4.2) from theWeka data mining software (Hall et al., 2009).For preprocessing the corpus, we use the StanfordPOS-Tagger (Toutanova et al., 2003) and Parser(Klein and Manning, 2003) included in the DKProFramework (Gurevych et al., 2007).
After thesesteps, we use the DKPro-TC text classificationframework (Daxenberger et al., 2014) for extract-ing the features described in the following section.4.1 FeaturesStructural features: We define structural featuresbased on token statistics, the location and punc-tuations of the argument component and its cov-ering sentence.
Since Biran and Rambow (2011)found that premises are longer on the average thanother sentences, we add the number of tokens ofthe argument component and its covering sentenceto our feature set.
In addition, we define the num-ber of tokens preceding and following an argumentcomponent in the covering sentence, the token ra-tio between covering sentence and argument com-ponent, and a Boolean feature that indicates if the49argument component covers all tokens of its cov-ering sentence as token statistics features.For exploiting the structural properties of per-suasive essays, we define a set of location-basedfeatures.
First, we define four Boolean featuresthat indicate if the argument component is presentin the introduction or conclusion of an essay andif it is present in the first or the last sentence ofa paragraph.
Second, we add the position of thecovering sentence in the essay as a numeric fea-ture.
Since major claims are always present in theintroduction or conclusion of an essay and para-graphs frequently begin or conclude with a claim,we expect that these features are good indicatorsfor classifying (major-) claims.Further, we define structural features based onthe punctuation: the number of punctuation marksof the covering sentence and the argument compo-nent, the punctuation marks preceding and follow-ing an argument component in its covering sen-tence and a Boolean feature that indicates if thesentence closes with a question mark.Lexical features: We define n-grams, verbs,adverbs and modals as lexical features.
We con-sider all n-grams of length 1-3 as a Boolean featureand extract them from the argument component in-cluding preceding tokens in the sentence that arenot covered by another argument component.
So,the n-gram features include discourse markers thatindicate certain argument components but whichare not included in the actual annotation of argu-ment components.Verbs and adverbs play an important role foridentifying argument components.
For instance,certain verbs like ?believe?, ?think?
or ?agree?
of-ten signal stance expressions which indicate thepresence of a major claim and adverbs like ?also?,?often?
or ?really?
emphasize the importance of apremise.
We model both verbs and adverbs asBoolean features.Modal verbs like ?should?
and ?could?
are fre-quently used in argumentative discourse to signalthe degree of certainty when expressing a claim.We use the POS tags generated during preprocess-ing to identify modals and define a Boolean fea-ture which indicates if an argument componentcontains a modal verb.Syntactic features: To capture syntactic prop-erties of argument components, we define featuresextracted from parse trees.
We adopt two featuresproposed by (Mochales-Palau and Moens, 2009):the number of sub-clauses included in the coveringsentence and the depth of the parse tree.
In addi-tion, we extract production rules from the parsetree as proposed by Lin et al.
(2009) to capturesyntactic characteristics of an argument compo-nent.
The production rules are collected for eachfunction tag (e.g.
VP, NN, S, etc.)
in the sub-tree of an argument component.
The feature setincludes e.g.
rules like V P ?
V BG,NP orPP ?
IN,NP .
We model each production ruleas a Boolean feature and set it to true if it appearsin the subtree of an argument component.Since premises often refer to previous eventsand claims are usually in present tense, we capturethe tense of the main verb of an argument compo-nent as proposed by Mochales-Palau and Moens(2009) and define a feature that indicates if an ar-gument component is in the past or present tense.Indicators: Discourse markers often indicatethe components of an argument.
For example,claims are frequently introduced with ?therefore?,?thus?
or ?consequently?, whereas premises con-tain markers like ?because?, ?reason?
or ?further-more?.
We collected a list of discourse markersfrom the Penn Discourse Treebank 2.0 AnnotationManual (Prasad et al., 2007) and removed markersthat do not indicate argumentative discourse (e.g.markers which indicate temporal discourse).
In to-tal, we collected 55 discourse markers and modeleach as a Boolean feature set to true if the particu-lar marker precedes the argumentative component.In addition, we define five Boolean featureswhich denote a reference to the first person in thecovering sentence of an argument component: ?I?,?me?, ?my?, ?mine?, and ?myself?.
An additionalBoolean feature indicates if one of them is presentin the covering sentence.
We expect that those fea-tures are good indicators of the major claim, sinceit is often introduced with expressions referring tothe personal stance of the author.Contextual features: The context plays a ma-jor role for identifying argument components.
Forinstance, a premise can only be classified as such,if there is a corresponding claim.
Therefore, wedefine the following features each extracted fromthe sentence preceding and following the coveringsentence of an argument component: the numberof punctuations, the number of tokens, the numberof sub-clauses and a Boolean feature indicating thepresence of modal verbs.504.2 Results and AnalysisFor identifying the best performing system, weconducted several experiments on the training setusing stratified 10-fold cross-validation.
We de-termine the evaluation scores by accumulating theconfusion matrices of each fold into one confusionmatrix, since it is the less biased method for evalu-ating cross-validation studies (Forman and Scholz,2010).
In a comparison of several classifiers (Sup-port Vector Machine, Na?
?ve Bayes, C4.5 DecisionTree and Random Forest), we found that each ofthe classifiers significantly outperforms a majoritybaseline (McNemar Test (McNemar, 1947) withp = 0.05) and that a Support Vector Machine(SVM) achieves the best results using 100 top fea-tures ranked by Information Gain.3It achieves anaccuracy of 77.3% on the test set and outperformsthe majority baseline with respect to overall accu-racy as well as F1-score (table 2).Baseline Human SVMAccuracy 0.55 0.877 0.773Macro F1 0.177 0.871 0.726Macro Precision 0.137 0.864 0.773Macro Recall 0.25 0.879 0.684F1 MajorClaim 0 0.916 0.625F1 Claim 0 0.841 0.538F1 Premise 0.709 0.911 0.826F1 None 0 0.812 0.884Table 2: Results of an SVM for argument com-ponent classification on the test set compared to amajority baseline and human performance.The upper bound for this task constitutes thehuman performance which we determine by com-paring each annotator to the gold standard.
Sincethe boundaries of an argument component in thegold standard can differ from the boundaries iden-tified by a human annotator (the annotation taskincluded the identification of argument componentboundaries), we label each argument componentof the gold standard with the class of the maximumoverlapping annotation of a human annotator fordetermining the human performance.
We obtain achallenging upper bound of 87.7% (accuracy) byaveraging the scores of all three annotators on thetest set (table 2).
So, our system achieves 88.1%of human performance (accuracy).Feature influence: In subsequent experiments,we evaluate each of the defined feature groups onthe entire data set using 10-fold cross-validation to3Although the Na?
?ve Bayes classifier achieves lowest ac-curacy, it exhibits a slightly higher recall compared to SVM.find out which features perform best for identify-ing argument components.
As assumed, structuralfeatures perform well for distinguishing claimsand premises in persuasive essays.
They also yieldhigh results for separating argumentative fromnon-argumentative text units (table 3).Feature group MajorClaim Claim Premise NoneStructural 0.477 0.419 0.781 0.897Lexical 0.317 0.401 0.753 0.275Syntactic 0.094 0.292 0.654 0.427Indicators 0.286 0.265 0.730 0Contextual 0 0 0.709 0Table 3: F1-scores for individual feature groupsand classes (SVM with 10-fold cross-validation onthe entire data set)Interestingly, the defined indicators are notuseful for separating argumentative from non-argumentative text units though they are helpfulfor classifying argument components.
A reasonfor this could be that not each occurrence of anindicator distinctly signals argument components,since their sense is often ambiguous (Prasad etal., 2008).
For example ?since?
indicates temporalproperties as well as justifications, whereas ?be-cause?
also indicates causal links.
Syntactic fea-tures also contribute to the identification of argu-ment components.
They achieve an F1-score of0.292 for claims and 0.654 for premises and alsocontribute to the separation of argumentative fromnon-argumentative text units.
Contextual featuresdo not perform well.
However, they increase theaccuracy by 0.7% in combination with other fea-tures.
Nevertheless, this difference is not signifi-cant (p = 0.05).Error analysis: The system performs well forseparating argumentative and non-argumentativetext units as well as for identifying premises.However, the identification of claims and majorclaims yields lower performance.
The confusionmatrix (table 4) reveals that the most common er-ror is between claims and premises.
In total, 193claims are incorrectly classified as premise.
Ina manual assessment, we observed that many ofthese errors occur if the claim is present in the firstparagraph sentence and exhibits preceding indica-tors like ?first(ly)?
or ?second(ly)?
which are alsofrequently used to enumerate premises.
In thesecases, the author introduces the claim of the argu-ment as support for the major claim and thus itscharacteristic is similar to a premise.
To prevent51this type of error, it might help to define featuresrepresenting the location of indicators or to disam-biguate the function of indicators.PredictedActualMC Cl Pr NoMC 38 34 18 0Cl 19 210 193 7Pr 6 104 904 19No 0 12 23 292Table 4: Confusion matrix (SVM) for argumentcomponent classification (MC = Major Claim; Cl= Claim; Pr = Premise; No = None)We also observed, that some of the misclassifiedclaims cover an entire sentence and don?t includeindicators.
For example, it is even difficult for hu-mans to classify the sentences ?Competition helpsin improvement and evolution?
as a claim withoutknowing the intention of the author.
For prevent-ing these errors, it might help to include more so-phisticated contextual features.5 Identifying Argumentative RelationsWe consider the identification of argumentative re-lations as a binary classification task of argumentcomponent pairs and classify each pair as eithersupport or non-support.
For identifying argumen-tative relations, all possible combinations of argu-ment components have to be tested.
Since this re-sults in a heavily skewed class distribution, we ex-tract all possible combinations of argument com-ponents from each paragraph of an essay.4So, weomit argumentative relations between claims andmajor claims which are the only relations in thecorpus that cross paragraph boundaries, but ob-tain a better distribution between true (support)and false (non-support) instances.
In total, we ob-tain 6,330 pairs, of which 15.6% are support and84.4% are non-support relations (table 5).Support Non-support989 (15.6%) 5341 (84.4%)Table 5: Class distribution of argument componentpairsEquivalent to the identification of argumentcomponents, we randomly split the data in a 80%training and a 20% test set and determine the bestperforming system using 10-fold cross-validation4Only 4.6% of 28,434 possible pairs are true instances(support), if all combinations are considered.on the training set.
We use the same preprocessingpipeline as described in section 4 and DKPro-TCfor extracting the features described below.5.1 FeaturesStructural features: We define structural fea-tures for each pair based on the source and tar-get components, and on the mutual information ofboth.
Three numeric features are based on tokenstatistics.
Two features represent the number oftokens of the source and target components andthe third one represents the absolute difference inthe number of tokens.
Three additional numericfeatures count the number of punctuation marksof the source and target components as well asthe absolute difference between both.
We extractboth types of features solely from the clause an-notated as argument component and do not con-sider the covering sentence.
In addition, we de-fine nine structural features based on the positionof both argument components: two of them repre-sent the position of the covering sentences in theessay, four Boolean features indicate if the argu-ment components are present in the first or lastsentence of a paragraph, one Boolean feature forrepresenting if the target component occurs beforethe source component, the sentence distance be-tween the covering sentences, and a Boolean fea-ture which indicates if both argument componentsare in the same sentence.Lexical features: We define lexical featuresbased on word pairs, first words and modals.
Ithas been shown in previous work that word pairsare effective for identifying implicit discourse re-lations (Marcu and Echihabi, 2002).
We defineeach pair of words between the source and targetcomponents as a Boolean feature and investigateword pairs containing stop words as well as stopword filtered word pairs.In addition, we adopt the first word featuresproposed by Pitler et al.
(2009).
We extract thefirst word either from the argument componentor from non-annotated tokens preceding the ar-gument component in the covering sentence ifpresent.
So, the first word of an argument com-ponent is either the first word of the sentence con-taining the argument component, the first wordfollowing a preceding argument component in thesame sentence or the first word of the actual ar-gument component if it commences the sentenceor directly follows another argument component.52So, we ensure that the first word of an argumentcomponent includes important discourse markerswhich are not included in the annotation.
We de-fine each first word of the source and target com-ponents as a Boolean feature and also add the pairsof first words to our feature set.Further, we define a Boolean feature for thesource as well as for the target component thatindicates if they contain a modal verb and a nu-merical feature that counts the number of commonterms of the two argument components.Syntactic features: For capturing syntacticproperties, we extract production rules from thesource and target components.
Equivalent to thefeatures extracted for the argument componentclassification (section 4.1), we model each rule asa Boolean feature which is true if the correspond-ing argument component includes the rule.Indicators: We use the same list of discoursemarkers introduced above (section 4.1) as indi-cator features.
For each indicator we define aBoolean feature for the source as well as for thetarget component of the pair and set it to true ifit is present in the argument component or in itspreceding tokens.Predicted type: The argumentative type (majorclaim, claim or premise) of the source and targetcomponents is a strong indicator for identifying ar-gumentative relations.
For example, there are noargumentative relations from claims to premises.Thus, if the type of the argument component isreliably identified many potential pairs can be ex-cluded.
Therefore, we define two features that rep-resent the argumentative type of the source and tar-get components identified in the first experiment.5.2 Results and AnalysisThe comparison of several classifiers reveals thatan SVM achieves the best results.
In our exper-iments, all classifiers except the C4.5 DecisionTree significantly outperform a majority baselinewhich classifies all pairs as non-support (p =0.05).
We also conducted several experimentsusing word pair features only and found in con-trast to Pitler et al.
(2009) that limiting the num-ber of word pairs decreases the performance.
Inparticular, we compared the top 100, 250, 500,1000, 2500, 5000 word pairs ranked by Informa-tion Gain, non-zero Information Gain word pairsand non-filtered word pairs.
The results showthat non-filtered word pairs perform best (macroF1-score of 0.68).
Our experiments also revealthat filtering stop words containing word pairs de-creases the macro F1-score to 0.60.
We obtain thebest results using an SVM without any feature se-lection method.
Due to the class imbalance, theSVM only slightly outperforms the accuracy of amajority baseline on the test set (table 6).
How-ever, the macro F1-score is more appropriate forevaluating the performance if the data is imbal-anced since it assigns equal weight to the classesand not to the instances.
The SVM achieves amacro F1-score of 0.722 and also outperforms thebaseline with respect to the majority class.Baseline Human SVMAccuracy 0.843 0.954 0.863Macro F1 0.458 0.908 0.722Macro Precision 0.422 0.937 0.739Macro Recall 0.5 0.881 0.705F1 Support 0 0.838 0.519F1 Non-Support 0.915 0.973 0.92Table 6: Results of an SVM for classifying argu-mentative relations on the test set compared to amajority baseline and human performance.We determined the upper bound constituted bythe human performance by comparing the annota-tions of all three annotators to the gold standard.The scores in table 6 are the average scores of allthree annotators.
Our system achieves 90.5% ofhuman performance (accuracy).Feature influence: A comparison of the de-fined feature groups using 10-fold cross-validationon the entire data set shows that lexical featuresperform best.
They achieve an F1-score of 0.427for support and 0.911 for non-support pairs (ta-ble 7).
The syntactic features also perform wellfollowed by the indicators.
It turned out that struc-tural features are not effective for identifying argu-mentative relations though they are the most effec-tive features for identifying argument components(cp.
section 4.2).
However, when omitted fromthe entire feature set the performance significantlydecreases by 0.018 macro F1-score (p = 0.05).Interestingly, the predicted types from our firstexperiment are not effective at all.
Although theargumentative type of the target component ex-hibits the highest Information Gain in each foldcompared to all other features, the predicted typedoes not yield a significant difference when com-bined with all other features (p = 0.05).
It onlyimproves the macro F1-score by 0.001 when in-53cluded in the entire feature set.Feature group Support Non-SupportStructural 0 0.915Lexical 0.427 0.911Syntactic 0.305 0.911Indicators 0.159 0.916Predicted types 0 0.915Table 7: F1-scores for individual feature groupsusing an SVM and the entire data setError analysis: For identifying frequent er-ror patterns, we manually investigated the mis-takes of the classifier.
Although our system identi-fies 97.5% of the non-support pairs from claim topremise correctly, there are still some false posi-tives that could be prevented if the argument com-ponents had been classified more accurately.
Forinstance, there are 18 non-support relations fromclaim to another claim, 32 from claim to premise,5 from major claim to premise and 4 from majorclaim to claim among the false positives.
How-ever, the larger amount of errors is due to not iden-tified support relations (false negatives).
We foundthat some errors might be related to missing con-textual information and unresolved coreferences.For instance, it might help to replace ?It?
with ?Ex-ercising?
for classifying the pair ?It helps relievetension and stress?
?
?Exercising improves self-esteem and confidence?
as support relation or to in-clude contextual information for the premise ?Thiscan have detrimental effects on health?
support-ing the claim ?There are some serious problemsspringing from modern technology?.6 DiscussionIn our experiments, we have investigated the clas-sification of argument components as well as theidentification of argumentative relations for recog-nizing argumentative discourse structures in per-suasive essays.
Both tasks are closely related andwe assume that sharing mutual information be-tween both tasks might be a promising directionfor future research.
On the one hand, knowing thetype of argument components is a strong indica-tor for identifying argumentative relations and onthe other hand, it is likely that information aboutthe argumentative structure facilitates the identi-fication of argument components.
However, ourexperiments revealed that the current accuracy foridentifying argument components is not sufficientfor increasing the performance of argumentativerelation identification.
Nevertheless, we obtainalmost human performance when including thetypes of argument components of the gold stan-dard (macro F1-score >0.85) in our argument re-lation identification experiment and when includ-ing the number of incoming and outgoing supportrelations for each argument component in our firstexperiment (macro F1-score >0.9).
Therefore, itcan be assumed, that if the identification of argu-ment components can be improved, the identifica-tion of argumentative relations will achieve betterresults and vice versa.The results also show that the distinction be-tween claims and premises is the major challengefor identifying argument components.
It turnedout that structural features are the most effectiveones for this task.
However, some of those featuresare unique to persuasive essays, and it is an openquestion if there are general structural propertiesof arguments which can be exploited for separat-ing claims from premises.Our experiments show that discourse markersyield only low accuracies.
Using only our definedindicator features, we obtain an F1-score of 0.265for identifying claims, whereas Mochales-Palauand Moens (2009) achieve 0.673 for the same taskin legal documents using a CFG.
This confirms ourinitial assumption that approaches relying on dis-course markers are not applicable for identifyingargumentative discourse structures in documentswhich do not follow a standardized form.
In ad-dition, it shows that discourse markers are eitherfrequently missing or misleadingly used in studenttexts and that there is a need for argumentativewriting support systems that assist students in em-ploying discourse markers correctly.7 Conclusion and Future WorkWe presented a novel approach for identifying ar-gumentative discourse structures in persuasive es-says.
Previous approaches on argument recog-nition suffer from several limitations: Existingapproaches focus either solely on the identifica-tion of argument components or rely on manu-ally created rules which are not able to identifyimplicit argumentative discourse structures.
Ourapproach is the first step towards computationalargument analysis in the educational domain andenables the identification of implicit argumenta-tive discourse structures.
The presented approachachieves 88.1% of human performance for identi-54fying argument components and 90.5% for identi-fying argumentative relations.For future work, we plan to extend our stud-ies to larger corpora, to integrate our classifiers inwriting environments, and to investigate their ef-fectiveness for supporting students.AcknowledgementsThis work has been supported by the Volk-swagen Foundation as part of the Lichtenberg-Professorship Program under grant No.
I/82806.We thank Krish Perumal and Piyush Paliwal fortheir valuable contributions and we thank theanonymous reviewers for their helpful comments.ReferencesOr Biran and Owen Rambow.
2011.
Identifying jus-tifications in written dialogs by classifying text asargumentative.
International Journal of SemanticComputing, 05(04):363?381.M.
Anne Britt and Aaron A. Larson.
2003.
Construct-ing representations of arguments.
Journal of Mem-ory and Language, 48(4):794 ?
810.Lynn Carlson, Daniel Marcu, and Mary EllenOkurowski.
2001.
Building a discourse-tagged cor-pus in the framework of rhetorical structure theory.In Proceedings of the Second SIGdial Workshop onDiscourse and Dialogue - Volume 16, SIGDIAL ?01,pages 1?10, Aalborg, Denmark.Johannes Daxenberger, Oliver Ferschke, IrynaGurevych, and Torsten Zesch.
2014.
DKPro TC:A Java-based framework for supervised learningexperiments on textual data.
In Proceedings ofthe 52nd Annual Meeting of the Association forComputational Linguistics.
System Demonstrations,pages 61?66, Baltimore, MD, USA.Vanessa Wei Feng and Graeme Hirst.
2011.
Classi-fying arguments by scheme.
In Proceedings of the49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies - Volume 1, HLT ?11, pages 987?996, Portland,OR, USA.Eirini Florou, Stasinos Konstantopoulos, AntonisKoukourikos, and Pythagoras Karampiperis.
2013.Argument extraction for supporting public policyformulation.
In Proceedings of the 7th Workshopon Language Technology for Cultural Heritage, So-cial Sciences, and Humanities, pages 49?54, Sofia,Bulgaria.George Forman and Martin Scholz.
2010.
Apples-to-apples in cross-validation studies: Pitfalls in clas-sifier performance measurement.
SIGKDD Explor.Newsl., 12(1):49?57.Iryna Gurevych, Max M?uhlh?auser, Christof Mueller,Juergen Steimle, Markus Weimer, and TorstenZesch.
2007.
Darmstadt Knowledge ProcessingRepository based on UIMA.
In Proceedings of theFirst Workshop on Unstructured Information Man-agement Architecture at Biannual Conference ofthe Society for Computational Linguistics and Lan-guage Technology, Tuebingen, Germany.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The weka data mining software: An update.SIGKDD Explor.
Newsl., 11(1):10?18.Dan Klein and Christopher D. Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics - Volume 1, ACL ?03, pages 423?430, Sapporo, Japan.Klaus Krippendorff.
2004.
Measuring the Reliabilityof Qualitative Text Analysis Data.
Quality & Quan-tity, 38(6):787?800.Ziheng Lin, Min-Yen Kan, and Hwee Tou Ng.
2009.Recognizing implicit discourse relations in the PennDiscourse Treebank.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 1, EMNLP ?09, pages343?351, Stroudsburg, PA, USA.Annie Louis, Aravind Joshi, Rashmi Prasad, and AniNenkova.
2010.
Using entity features to classifyimplicit discourse relations.
In Proceedings of the11th Annual Meeting of the Special Interest Groupon Discourse and Dialogue, SIGDIAL ?10, pages59?62, Stroudsburg, PA, USA.William C. Mann and Sandra A. Thompson.
1987.Rhetorical structure theory: A theory of text orga-nization.
Technical Report ISI/RS-87-190, Informa-tion Sciences Institute.Daniel Marcu and Abdessamad Echihabi.
2002.
Anunsupervised approach to recognizing discourse re-lations.
In Proceedings of the 40th Annual Meetingon Association for Computational Linguistics, ACL?02, pages 368?375.Quinn McNemar.
1947.
Note on the sampling errorof the difference between correlated proportions orpercentages.
Psychometrika, 12(2):153?157.Raquel Mochales-Palau and Marie-Francine Moens.2009.
Argumentation mining: The detection, classi-fication and structure of arguments in text.
In Pro-ceedings of the 12th International Conference on Ar-tificial Intelligence and Law, ICAIL ?09, pages 98?107, New York, NY, USA.
ACM.Marie-Francine Moens, Erik Boiy, Raquel MochalesPalau, and Chris Reed.
2007.
Automatic detectionof arguments in legal texts.
In Proceedings of the11th International Conference on Artificial Intelli-gence and Law, ICAIL ?07, pages 225?230, Stan-ford, California.55Andreas Peldszus and Manfred Stede.
2013.
FromArgument Diagrams to Argumentation Mining inTexts: A Survey.
International Journal of Cogni-tive Informatics and Natural Intelligence (IJCINI),7(1):1?31.Emily Pitler, Annie Louis, and Ani Nenkova.
2009.Automatic sense prediction for implicit discourse re-lations in text.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP, ACL ?09, pages683?691, Suntec, Singapore.
Association for Com-putational Linguistics.Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, AlanLee, Aravind Joshi, Livio Robaldo, and Bonnie L.Webber.
2007.
The Penn Discourse Treebank 2.0annotation manual.
Technical report, Institute forResearch in Cognitive Science, University of Penn-sylvania.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, and BonnieWebber.
2008.
The Penn Discourse Treebank 2.0.In Proceedings of the Sixth International Conferenceon Language Resources and Evaluation (LREC?08),Marrakech, Morocco.Chris Reed, Raquel Mochales-Palau, Glenn Rowe, andMarie-Francine Moens.
2008.
Language resourcesfor studying argument.
In Proceedings of the SixthInternational Conference on Language Resourcesand Evaluation, LREC ?08, pages 2613?2618, Mar-rakech, Morocco.Niall Rooney, Hui Wang, and Fiona Browne.
2012.Applying kernel methods to argumentation min-ing.
In Proceedings of the Twenty-Fifth Interna-tional Florida Artificial Intelligence Research So-ciety Conference, FLAIRS ?12, pages 272?275,Marco Island, FL, USA.Alan Sergeant.
2013.
Automatic argumentation ex-traction.
In Proceedings of the 10th European Se-mantic Web Conference, ESWC ?13, pages 656?660,Montpellier, France.Christian Stab and Iryna Gurevych.
2014.
Annotat-ing argument components and relations in persua-sive essays.
In Proceedings of the 25th InternationalConference on Computational Linguistics (COLING2014), pages 1501?1510, Dublin, Ireland, August.Simone Teufel.
1999.
Argumentative Zoning: Infor-mation Extraction from Scientific Text.
Ph.D. thesis,University of Edinburgh.Kristina Toutanova, Dan Klein, Christopher D. Man-ning, and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency network.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology,NAACL ?03, pages 173?180, Edmonton, Canada.Douglas N Walton.
1996.
Argumentation schemes forpresumptive reasoning.
Routledge.Adam Wyner, Raquel Mochales Palau, Marie-FrancineMoens, and David Milward.
2010.
Approaches totext mining arguments from legal cases.
In SemanticProcessing of Legal Texts, volume 6036 of LectureNotes in Computer Science, pages 60?79.56
