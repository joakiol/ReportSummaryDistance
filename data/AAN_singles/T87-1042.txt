Bidirectional Grammars and theDesign of Natural Language Generation SystemsDouglas E. AppeltArtificial Intelligence CenterCenter for the Study of Language and InformationSRI International1 B id i rec t iona l  Grammars  for Generat ionIntuitively considered, a grammar is bidirectional if it can be used by processes of approx-imately equal computational complexity to parse and generate sentences of a language.Because we, as computational linguists, are concerned with the meaning of the sentenceswe process, a bidirectional grammar must specify a correspondence b tween sentences andmeaning representations, and this correspondence must be represented in a manner thatallows one to be computed from the other.
Most research in computational linguistics hasfocused on one or the other of the two sides of the problem, with the result that relativelylittle attention has been given to the issues raised by the incorporation of a single grammarinto a system for tasks of both comprehension and generation.Clearly, if it were possible to have truly bidirectional grammars in which both pars-ing and generation processes were efficient, there would be some compelling reasons foradopting them.
First, Occam's razor suggests that, if language behavior can be explainedby hypothesizing only one linguistic representation, such an explanation is clearly prefer-able to two that are applicable in complementary circumstances.
Also, from the practicalstandpoint of designing systems that will carry on sophisticated dialogues with their users,a single unified formalism for specifying the syntax and semantics of the language is likelyto result in a simpler, more robust implementation.
The problems of maintaining consis-tency between comprehension and generation components when one of them changes havebeen eliminated.
The lexicon is also simpler because its entries need be made but once,and there is no problem of maintaining consistency between different lexical entries forunderstanding and generation.It is obvious that not all grammars are bidirectional.
The most fundamental require-ment of any bidirectional grammar is that it be represented declaratively.
If any informa-tion is represented procedurally, it must of necessity be represented differently for parsingand generation processes, resulting in an asymmetry between the two.
Any change inthe grammar would have to be made in two places to maintain the equivalence betweenthe syntactic and semantic analyses given to sentences by each process.
A grammar likeDIAGRAM \[8\] is an example of a grammar for which the encoding of linguistic information206is primarily procedural; it is inconceivable how it could be used for generation.Also, reversibility requires that the grammar define a one-to-one mapping from surfacestrings to some meaning representation.
Presumably this representation would consistof a logical form specifying the predicate argument structure of the sentence, togetherwith a set of functional features that distinguish sentences according to their pragmatic orfunctional role.
For example, active and passive sentences have the same logical form, butdifferent functional features.The PATR-II formalism \[9\], which is based on the unification of feature structures, hasproperties that make a bidirectional grammar possible.
This  formalism has been demon-strated to be very useful in encoding linguistic information and accommodates a widevariety of linguistic theories \[10,12\].
The PATR-II formalism has many elegant formalproperties, including a denotational semantics \[7\], but the one most important for bidi-rectionality is that the unification operation is associative and commutative.
This impliesthat the result of unifying feature structures is independent of the order in which theyare unified.
This characteristic allows one to write grammar ules that satisfy the twoproperties cited above, without incorporating into the structure of the rules themselvesany assumptions about the process that will employ these rules.
Shieber I has developed ageneration system based on PATR-II grammar ules.
The grammar is bidirectional; givena logical form that a parser would have produced had it been given the sentence to parse,the generator will produce the same sentence.
All features of the analysis are identicalin both cases.
If the combination of logical form and functional features is insufficient todetermine a unique sentence, the generator can produce a set of sentences whose meaningsunify with the specification.2 Implications of Bidirectionality for System DesignAdopting a bidirectional grammar for a language-understanding a d -generation systemimplies certain constraints on the system's design.
Because the grammar for such a systemmust consist of declarative rules to be interpreted, it must provide exactly the same in-formation to both parsing,and generation processes.
This implies that at least the lowestlevel of these processes must be symmetric.The role the grammar plays in most understanding systems is to define a mapping fromsurface utterances to a logical form that abstracts predicate-argument structure and quan-tifier scoping from the sentence.
This logical form provides a basis from which inferencesare drawn, both to resolve anaphora and to determine the speaker's intentions behindthe utterance.
The symmetry requirement specifies that the generation process must pro-duce a logical form (together with functional features) that determines the utterance tobe produced.
Figure 1 illustrates this basic design.1Work in progress.207Rnaphora Resolut ionPlan Recognit ionInFerence~ Ooaain Planning ~ oi ,cour, , /  Utterance PllnninqStrategic ~*-.~Logical \[ Parserl~ Form I JI,,Logical J For l  -I GeneratorTacticalFigure 1: Organization of a Bidirectional SystemIn most understanding systems there is an easily identifiable boundary between theparsing/morphological omponent and the part of the system that draws inferences fromthe resulting logical form.
The former is the only component that is concerned irectlywith the form and content of the grammatical rules, while the latter is the only one thatis called upon to do general reasoning.
It has been argued that intermediate fragmentsshould undergo semantic and pragmatic analysis as an aid in resolving ambiguities such asprepositional-phrase attachment, as well as for inferring the intentions behind ill-formedinput.
At present, however, syntactic analysis has been sufficiently cheaper than semanticand pragmatic analysis to nullify any advantage that might be gained from integrationof parsing and general inference.
In any case, the inference procedures, while perhapsrequiring access to certain features of the syntactic and semantic analysis, need not beconcerned with the rules themselves.
This modularity is clearly beneficial.
The grammar,parser, and morphological nalyzer, being a more or less self-contained unit, are portableamong different applications, domains, and knowledge representation languages.Because it is so plausible to assume there is a clearly defined "division of labor" amongmodules in the understanding part of the system, it is natural to wonder whether a similarmodularization could exist on the generation side.
Such a division of labor has beenreferred to as a distinction between strategy and tactics, \[6,11\] which can be very roughlycharacterized as a distinction between "deciding what to say" and "deciding how to sayit."
This distinction has been adopted in some form in nearly every language generationsystem built to date (Appelt \[1\] and Danlos \[2\] are among the few to publish objections)although, as might be expected, different researchers have drawn the boundary in differentways.In a bidirectionaJ system, the obvious choice for a strategic/tactical modularization isat the point indicated in Figure 1.
The strategic omponent of the system is the partthat produces a logical form plus a set of functional features, while the tactical componentrealizes the strategic specification as an utterance.
The implication of drawing the line assuggested is that there are such significant differences on either side of the line between the208respective processes and the information they need to access that it makes sense to modu-larize the system in this manner.
By symmetry with understanding, such a modularizationis reasonable if, as in understanding, the strategic component need not be concerned withthe specific details of grammar rules and, moreover, the tactical component does not haveto perform general reasoning.3 The Problem Posed by Strategic/TacticalModularizationShieber ~has observed a serious problem that arises as a result of the disparate treatmentof logical forms by the strategic and tactical modules, which I shall refer to as the problemof logical-form equivalence.
As far as the strategic omponent is concerned, logical formsare constructed because of their meaning.
This does not mean that the strategic processis as simple as figuring out what propositions the hearer needs to know, then using thosepropositions as logical forms for utterances.
In the KAMP system \[1\], for example, high-level actions were planned to satisfy requirements about the mental state of the hearer,but those specifications were refined into surface speech-acts.
The propositional contentof the surface speech act serves as the logical form of the utterance finally produced.
Agood deal of reasoning is involved in the expansion of a plan to perform illocutionary actsinto a plan incorporating particular surface speech acts.
In fact, there is no one-to-onecorrespondence b tween illocutionary acts and the surface speech acts that realize them.If detailed knowledge of grammar ules is to be avoided by the strategic omponent,the logical forms of surface speech acts must be planned because of their meaning.
Anyequivalent logical form is as good as the one actually chosen as long as it means the samething.
However, to a tactical generation component (as well as a parser), the logical formis an object that is important primarily because its syntax is related to an utterance in acertain way.
Just as the logical form doesn't actually mean anything to a parser, it doesn'tmean anything to the tactical generation component in this typical bidirectional system.To see why this is a problem, consider a task from a domain of circuit repairs inwhich the speaker (the system) wants to inform the hearer that a particular esistor has aresistance of 500 ohms.
The strategic planner may decide that its goal would be satisfiedif it uttered a declarative sentence with the propositional contentResistance-of(R1, ohm(500)).
(i)If the grammar is constructed properly, this logical form might result in the production ofthe sentence "The resistance of R1 is 500 ohms."
However, it is unlikely that this statementwould be specified by a general grammar of English as the logical form for the utterance,aPersonaJ communication.209 .because its constituents bear no simple relationship to the constituents of any sentence.
Itis much more likely that the following statement would be the desired logical form:~x Resistance-of(R1, x)(x = ohm(500)).
(2)Logical form (2) is more suitable as a representation f the intended utterance than (1) be-cause there is a more natural mapping from constituents of the logical form to constituentsof the sentence.
It introduces the equality predicate, corresponding to the verb be, andthe subject and predicate noun phrases correspond irectly to  arguments to the equalitypredicate.But here is the problem: how can a procedure that cares only about the meaning ofthe logical form decide to produce (2) rather than (1)?
Or how is it to avoid producing(3)*.Lx Resistance-of(R1, x)(ohm(500) = x).
(3)Commutativity of equality guarantees the logical equivalence of (2) and (3), but (3) is likelyto produce the sentence "Five hundred ohms is the resistance of RI."
If the functionalfeatures state that the resistance is the topic of the sentence, then that plus (3) constituesan inconsistent specification; consequently no output will be produced at all.Because the syntax of the logical form is significant, as well as its meaning, knowledgeof what constitutes a legitimate logical form must be incorporated into the module thatproduces logical forms.
Because the determination of which of several possible equivalentvariations of a logical form actually corresponds to an utterance depends on the details ofthe grammar, the surface speech act planner must have detailed knowledge of the grammarthus rendering meaningless the symmetric strategic/tactical modularization suggestedabove.
The only other alternative would be to have the tactical generation componentproduce logically equivalent variations on the logical form until one is found that succeeds.There are two problems with this approach: (1) there are a great many possibilities forgenerating equivalent expressions, and (2) it may  be possible to propose logical forms that,while logically equivalent to the intended utterance, are quite inappropriate.
For example,the sentence ~The resistance of R1 is 500 ohms and Bruce Springsteen is the Boss or BruceSpringsteen is not the Boss, ~ is not ruled out in principle.Obviously, a number of language generation systems have been developed that donot seem to suffer from this problem, so there must be a way out.
If you examine acollection of better-known generation systems (e.g.
KAMP \[1\], TEXT \[6\], MUMBLE \[5\],N IGEL /PENMAN \[3\]) you will see that, in spite of vast differences in general approach,coverage, application domain, grammar representation, and system interface, there is onevery striking similarity: none of the grammars employed by these systems has an ezplicitlyrepresented formal semantics.
In theory, KAMP (to choose the example with which theauthor is most familiar) plans a surface speech act whose propositional content is intended210as the logical form of the utterance produced.
This is really in the nature of a white lie: theactual situation is that the logical form of the utterance is something logically equivalentto the propostional content of the surface speech act.
There is a procedure that uses thepropositional content of the surface speech act as a specification to create an initial featurestructure for the unification grammar.
Knowledge about the way feature structures relateto the logical form (i.e.
the semantics of the grammar) is embedded in this procedure.Although the details differ in each case, an analogous story can be told for each of thegeneration systems under consideration.
There is no problem of logical-form equivalencebecause the logical form of the utterance plays no direct role in the generation process forany of these systems.Of course, this procedural embedding of semantics is unsuitable for bidirectional sys-tems.
Naturally, none of the authors of the generation systems have made any positiveclaims about the suitability of their grammars for understanding.
In fact, MUMBLE \[4\],unlike the others, does not even represent its grammar as a set of rules that one can con-sider in isolation from the rest of the generation system.
For those systems with explicitgrammars, it may  be possible to integrate an explicit formal semantics into the grammarand use it for understanding, but as long as a different procedurally embedded semanticsis being used for generation, the grammar cannot be considered bidirectional.At this time it is not clear what would be the best solution to the problem of logical-form equivalence for bidirectional systems, but there are several approaches that mayprove fruitful.
One approach is to allow the tactical component to substitute equivalentlogical forms whenever it is necessary to produce a sentence, but to restrict the types ofinferences that can be drawn.
For example, if we assume that a PATR-II grammar is usedby the parser and generator, allowing the unification algorithm to assume that equality andlogical connectives in logical forms are associative and commutative is one way of making itpossible for a limited class of inferences to be drawn during the tactical generation process.Whatever solution is ultimately adopted, it is our belief that the advantages inherent inbidirectional systems are su~cient to warrant a close examination of the problems entailedin a bidirectional design.AcknowledgementsThis research was sponsored by the Nippon Telegraph and Telephone Corporation undera contract with SRI International.
The author is grateful for comments by Phil Cohen onan earlier draft of this article.211References\[1\] Douglas E. Appelt.
Planning English Sentences.
Cambridge University Press, Cam-bridge, England, 1985.\[2\] Laurence Dardos.
Conceptual and linguistic decisions in generation.
In Proceedingsof the Tenth International Conference on Computational Linguistics, pages 501-504,1984.\[3\] William C. Mann.
An overview of the PENMAN text generation system.
In Proceed-ings of the National Conference, pages 261-265, American Association for ArtificialIntelligence, 1983.\[4\] David D. McDonald.
Natural Language Generation: Complexities and Techniques.Counselor Project Tecnical Memo 14, University of Massachusetts, 1986.\[5\] David D. McDonald.
Natural Language Generation as a Process of Decision Makingunder Constraint.
PhD thesis, Massachusetts Institute of Technology, 1980.\[6\] Kathleen McKeown.
Text Generation.
Cambridge University Press, Cambridge, Eng-land, 1985.\[7\] Fernando Pereira and Stuart Shieber.
The semantics of grammar formalisms eenas computer languages.
In Proceedings of the Tenth International Conference onComputational Linguistics, pages 123-129, 1984.\[8\]g Jane Robinson.
DIAGRAM: a grammar for dialogues.
Communications of the A CM,25(I):27-47, 1982.\[9\] Stuart Shieber.
An Introduction to Unification-Based Approaches to Grammar.
Lec-ture Note Series Vol.
4, Center For the Study of Language and Information, StanfordUniversity, 1986.\[I0\] Stuart Shieber.
A simple reconstruction of GPSG.
In Proceedings of the EleventhInternational Conference on Computational Linguistics, pages 211-215, 1986.\[11\] Henry Thompson.
Strategy and tactics: a model for language production.
In Papersfrom the Thirteenth Regional Meeting, Chicago Linguistics Society, 1977.\[12\] Hans Uszkoreit.
Categorial unification grammars.
In Proceedings of the EleventhInternational Conference on Computational Linguistics, pages 187-194, 1986.212
