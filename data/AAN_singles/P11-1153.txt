Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1526?1535,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsStructural Topic Model for Latent Topical Structure AnalysisHongning Wang, Duo Zhang, ChengXiang ZhaiDepartment of Computer ScienceUniversity of Illinois at Urbana-ChampaignUrbana IL, 61801 USA{wang296, dzhang22, czhai}@cs.uiuc.eduAbstractTopic models have been successfully appliedto many document analysis tasks to discovertopics embedded in text.
However, existingtopic models generally cannot capture the la-tent topical structures in documents.
Sincelanguages are intrinsically cohesive and coher-ent, modeling and discovering latent topicaltransition structures within documents wouldbe beneficial for many text analysis tasks.In this work, we propose a new topic model,Structural Topic Model, which simultaneouslydiscovers topics and reveals the latent topi-cal structures in text through explicitly model-ing topical transitions with a latent first-orderMarkov chain.
Experiment results show thatthe proposed Structural Topic Model can ef-fectively discover topical structures in text,and the identified structures significantly im-prove the performance of tasks such as sen-tence annotation and sentence ordering.1 IntroductionA great amount of effort has recently been made inapplying statistical topic models (Hofmann, 1999;Blei et al, 2003) to explore word co-occurrence pat-terns, i.e.
topics, embedded in documents.
Topicmodels have become important building blocks ofmany interesting applications (see e.g., (Blei andJordan, 2003; Blei and Lafferty, 2007; Mei et al,2007; Lu and Zhai, 2008)).In general, topic models can discover word clus-tering patterns in documents and project each doc-ument to a latent topic space formed by such wordclusters.
However, the topical structure in a docu-ment, i.e., the internal dependency between the top-ics, is generally not captured due to the exchange-ability assumption (Blei et al, 2003), i.e., the doc-ument generation probabilities are invariant to con-tent permutation.
In reality, natural language textrarely consists of isolated, unrelated sentences, butrather collocated, structured and coherent groups ofsentences (Hovy, 1993).
Ignoring such latent topi-cal structures inside the documents means wastingvaluable clues about topics and thus would lead tonon-optimal topic modeling.Taking apartment rental advertisements as an ex-ample, when people write advertisements for theirapartments, it?s natural to first introduce ?size?
and?address?
of the apartment, and then ?rent?
and?contact?.
Few people would talk about ?restric-tion?
first.
If this kind of topical structures are cap-tured by a topic model, it would not only improvethe topic mining results, but, more importantly, alsohelp many other document analysis tasks, such assentence annotation and sentence ordering.Nevertheless, very few existing topic models at-tempted to model such structural dependency amongtopics.
The Aspect HMM model introduced in(Blei and Moreno, 2001) combines pLSA (Hof-mann, 1999) with HMM (Rabiner, 1989) to performdocument segmentation over text streams.
However,Aspect HMM separately estimates the topics in thetraining set and depends on heuristics to infer thetransitional relations between topics.
The HiddenTopic Markov Model (HTMM) proposed by (Gru-ber et al, 2007) extends the traditional topic modelsby assuming words in each sentence share the sametopic assignment, and topics transit between adja-cent sentences.
However, the transitional structuresamong topics, i.e., how likely one topic would fol-low another topic, are not captured in this model.1526In this paper, we propose a new topic model,named Structural Topic Model (strTM) to model andanalyze both latent topics and topical structures intext documents.
To do so, strTM assumes: 1) wordsin a document are either drawn from a content topicor a functional (i.e., background) topic; 2) words inthe same sentence share the same content topic; and3) content topics in the adjacent sentences follow atopic transition that satisfies the first order Markovproperty.
The first assumption distinguishes the se-mantics of the occurrence of each word in the doc-ument, the second requirement confines the unreal-istic ?bag-of-word?
assumption into a tighter unit,and the third assumption exploits the connection be-tween adjacent sentences.To evaluate the usefulness of the identified top-ical structures by strTM, we applied strTM to thetasks of sentence annotation and sentence ordering,where correctly modeling the document structureis crucial.
On the corpus of 8,031 apartment ad-vertisements from craiglist (Grenager et al, 2005)and 1,991 movie reviews from IMDB (Zhuang etal., 2006), strTM achieved encouraging improve-ment in both tasks compared with the baseline meth-ods that don?t explicitly model the topical structure.The results confirm the necessity of modeling thelatent topical structures inside documents, and alsodemonstrate the advantages of the proposed strTMover existing topic models.2 Related WorkTopic models have been successfully applied tomany problems, e.g., sentiment analysis (Mei etal., 2007), document summarization (Lu and Zhai,2008) and image annotation (Blei and Jordan, 2003).However, in most existing work, the dependencyamong the topics is loosely governed by the priortopic distribution, e.g., Dirichlet distribution.Some work has attempted to capture the interre-lationship among the latent topics.
Correlated TopicModel (Blei and Lafferty, 2007) replaces Dirichletprior with logistic Normal prior for topic distribu-tion in each document in order to capture the cor-relation between the topics.
HMM-LDA (Griffithset al, 2005) distinguishes the short-range syntacticdependencies from long-range semantic dependen-cies among the words in each document.
But inHMM-LDA, only the latent variables for the syn-tactic classes are treated as a locally dependent se-quence, while latent topics are treated the same as inother topic models.
Chen et al introduced the gen-eralized Mallows model to constrain the latent topicassignments (Chen et al, 2009).
In their model,they assume there exists a canonical order amongthe topics in the collection of related documents andthe same topics are forced not to appear in discon-nected portions of the topic sequence in one docu-ment (sampling without replacement).
Our methodrelaxes this assumption by only postulating transi-tional dependency between topics in the adjacentsentences (sampling with replacement) and thus po-tentially allows a topic to appear multiple times indisconnected segments.
As discussed in the pre-vious section, HTMM (Gruber et al, 2007) is themost similar model to ours.
HTMM models thedocument structure by assuming words in the samesentence share the same topic assignment and suc-cessive sentences are more likely to share the sametopic.
However, HTMM only loosely models thetransition between topics as a binary relation: thesame as the previous sentence?s assignment or drawa new one with a certain probability.
This simpli-fied coarse modeling of dependency could not fullycapture the complex structure across different docu-ments.
In contrast, our strTM model explicitly cap-tures the regular topic transitions by postulating thefirst order Markov property over the topics.Another line of related work is discourse analysisin natural language processing: discourse segmen-tation (Sun et al, 2007; Galley et al, 2003) splits adocument into a linear sequence of multi-paragraphpassages, where lexical cohesion is used to link to-gether the textual units; discourse parsing (Soricutand Marcu, 2003; Marcu, 1998) tries to uncover amore sophisticated hierarchical coherence structurefrom text to represent the entire discourse.
One workin this line that shares a similar goal as ours is thecontent models (Barzilay and Lee, 2004), where anHMM is defined over text spans to perform infor-mation ordering and extractive summarization.
Adeficiency of the content models is that the identi-fication of clusters of text spans is done separatelyfrom transition modeling.
Our strTM addresses thisdeficiency by defining a generative process to simul-taneously capture the topics and the transitional re-1527lationship among topics: allowing topic modelingand transition modeling to reinforce each other in aprincipled framework.3 Structural Topic ModelIn this section, we formally define the StructuralTopic Model (strTM) and discuss how it captures thelatent topics and topical structures within the docu-ments simultaneously.
From the theory of linguisticanalysis (Kamp, 1981), we know that document ex-hibits internal structures, where structural segmentsencapsulate semantic units that are closely related.In strTM, we treat a sentence as the basic structureunit, and assume all the words in a sentence share thesame topical aspect.
Besides, two adjacent segmentsare assumed to be highly related (capturing cohesionin text); specifically, in strTM we pose a strong tran-sitional dependency assumption among the topics:the choice of topic for each sentence directly de-pends on the previous sentence?s topic assignment,i.e., first order Markov property.
Moveover, tak-ing the insights from HMM-LDA that not all thewords are content conveying (some of them mayjust be a result of syntactic requirement), we intro-duce a dummy functional topic zB for every sen-tence in the document.
We use this functional topicto capture the document-independent word distribu-tion, i.e., corpus background (Zhai et al, 2004).
Asa result, in strTM, every sentence is treated as a mix-ture of content and functional topics.Formally, we assume a corpus consists of D doc-uments with a vocabulary of size V, and there arek content topics embedded in the corpus.
In a givendocument d, there arem sentences and each sentencei hasNi words.
We assume the topic transition prob-ability p(z|z?)
is drawn from a Multinomial distribu-tionMul(?z?
), and the word emission probability un-der each topic p(w|z) is drawn from a Multinomialdistribution Mul(?z).To get a unified description of the generationprocess, we add another dummy topic T-START instrTM, which is the initial topic with position ?-1?for every document but does not emit any words.In addition, since our functional topic is assumed tooccur in all the sentences, we don?t need to modelits transition with other content topics.
We use aBinomial variable pi to control the proportion be-tween content and functional topics in each sen-tence.
Therefore, there are k+1 topic transitions, onefor T-START and others for k content topics; and kemission probabilities for the content topics, with anadditional one for the functional topic zB (in totalk+1 emission probability distributions).Conditioned on the model parameters ?
=(?, ?, pi), the generative process of a document instrTM can be described as follows:1.
For each sentence si in document d:(a) Draw topic zi from Multinomial distribu-tion conditioned on the previous sentencesi?1?s topic assignment zi?1:zi ?
Mul(?zi?1)(b) Draw each word wij in sentence si fromthe mixture of content topic zi and func-tional topic zB:wij ?
pip(wij |?, zi)+(1?pi)p(wij |?, zB)The joint probability of sentences and topics inone document defined by strTM is thus given by:p(S0, S1, .
.
.
, Sm, z|?, ?, pi) =m?i=1p(zi|?, zi?1)p(Si|zi)(1)where the topic to sentence emission probability isdefined as:p(Si|zi) =Ni?j=0[pip(wij |?, zi) + (1?
pi)p(wij |?, zB)](2)This process is graphically illustrated in Figure 1.zmz0 ??..wm?
?..NmDK+1w0N0K+1z1w1N1TstartFigure 1: Graphical Representation of strTM.From the definition of strTM, we can see that thedocument structure is characterized by a document-specific topic chain, and forcing the words in one1528sentence to share the same content topic ensures se-mantic cohesion of the mined topics.
Although wedo not directly model the topic mixture for each doc-ument as the traditional topic models do, the wordco-occurrence patterns within the same documentare captured by topic propagation through the transi-tions.
This can be easily understood when we writedown the posterior probability of the topic assign-ment for a particular sentence:p(zi|S0, S1, .
.
.
, Sm,?
)=p(S0, S1, .
.
.
, Sm|zi,?
)p(zi)p(S0, S1, .
.
.
, Sm)?
p(S0, S1, .
.
.
, Si, zi)?
p(Si+1, Si+2, .
.
.
, Sm|zi)=?zi?1p(S0, .
.
.
, Si?1, zi?1)p(zi|zi?1)p(Si|zi)?
?zi+1p(Si+1, .
.
.
, Sm|zi+1)p(zi+1|zi) (3)The first part of Eq(3) describes the recursive in-fluence on the choice of topic for the ith sentencefrom its preceding sentences, while the second partcaptures how the succeeding sentences affect thecurrent topic assignment.
Intuitively, when we needto decide a sentence?s topic, we will look ?back-ward?
and ?forward?
over all the sentences in thedocument to determine a ?suitable?
one.
In addition,because of the first order Markov property, the localtopical dependency gets more emphasis, i.e., theyare interacting directly through the transition proba-bilities p(zi|zi?1) and p(zi+1|zi).
And such interac-tion on sentences farther away would get damped bythe multiplication of such probabilities.
This resultis reasonable, especially in a long document, sinceneighboring sentences are more likely to cover sim-ilar topics than two sentences far apart.4 Posterior Inference and ParameterEstimationThe chain structure in strTM enables us to performexact inference: posterior distribution can be ef-ficiently calculated by the forward-backward algo-rithm, the optimal topic sequence can be inferredusing the Viterbi algorithm, and parameter estima-tion can be solved by the Expectation Maximization(EM) algorithm.
More technical details can be foundin (Rabiner, 1989).
In this section, we only discussstrTM-specific procedures.In the E-Step of EM algorithm, we need to col-lect the expected count of a sequential topic pair(z, z?)
and a topic-word pair (z, w) to update themodel parameters ?
and ?
in the M-Step.
In strTM,E[c(z, z?)]
can be easily calculated by forward-backward algorithm.
But we have to go one stepfurther to fetch the required sufficient statistics forE[c(z, w)], because our emission probabilities aredefined over sentences.Through forward-backward algorithm, we can getthe posterior probability p(si, z|d,?).
In strTM,words in one sentence are independently drawn fromeither a specific content topic z or functional topiczB according to the mixture weight pi.
Therefore,we can accumulate the expected count of (z, w) overall the sentences by:E[c(z, w)] =?d,s?dpip(w|z)p(s, z|d,?
)c(w, s)pip(w|z) + (1?
pi)p(w|zB)(4)where c(w, s) indicates the frequency of word w insentence s.Eq(4) can be easily explained as follows.
Sincewe already observe topic z and sentence s co-occur with probability p(s, z|d,?
), each word win s should share the same probability of be-ing observed with content topic z.
Thus the ex-pected count of c(z, w) in this sentence would bep(s, z|d,?
)c(w, s).
However, since each sentenceis also associated with the functional topic zB , theword w may also be drawn from zB .
By applyingthe Bayes?
rule, we can properly reallocate the ex-pected count of c(z, w) by Eq(4).
The same strategycan be applied to obtain E[c(zB, w)].As discussed in (Johnson, 2007), to avoid theproblem that EM algorithm tends to assign a uni-form word/state distribution to each hidden state,which deviates from the heavily skewed word/statedistributions empirically observed, we can apply aBayesian estimation approach for strTM.
Thus weintroduce prior distributions over the topic transi-tion Mul(?z?)
and emission probabilities Mul(?z),and use the Variational Bayesian (VB) (Jordan et al,1999) estimator to obtain a model with more skewedword/state distributions.Since both the topic transition and emission prob-abilities are Multinomial distributions in strTM,the conjugate Dirichlet distribution is the natural1529choice for imposing a prior on them (Diaconis andYlvisaker, 1979).
Thus, we further assume:?z ?
Dir(?)
(5)?z ?
Dir(?)
(6)where we use exchangeable Dirichlet distributionsto control the sparsity of ?z and ?z .
As ?
and ?
ap-proach zero, the prior strongly favors the models inwhich each hidden state emits as few words/states aspossible.
In our experiments, we empirically tuned?
and ?
on different training corpus to optimize log-likelihood.The resulting VB estimation only requires a mi-nor modification to the M-Step in the original EMalgorithm:?
?z =?
(E[c(z?, z)] + ?)?
(E[c(z)] + k?)(7)?
?z =?
(E[c(w, z)] + ?)?
(E[c(z)] + V ?
)(8)where ?
(x) is the exponential of the first derivativeof the log-gamma function.The optimal setting of pi for the proportion of con-tent topics in the documents is empirically tuned bycross-validation over the training corpus to maxi-mize the log-likelihood.5 Experimental ResultsIn this section, we demonstrate the effectivenessof strTM in identifying latent topical structuresfrom documents, and quantitatively evaluate how themined topic transitions can help the tasks of sen-tence annotation and sentence ordering.5.1 Data SetWe used two different data sets for evaluation: apart-ment advertisements (Ads) from (Grenager et al,2005) and movie reviews (Review) from (Zhuang etal., 2006).The Ads data consists of 8,767 advertisements forapartment rentals crawled from Craigslist website.302 of them have been labeled with 11 fields, in-cluding size, feature, address, etc., on the sentencelevel.
The review data contains 2,000 movie reviewsdiscussing 11 different movies from IMDB.
Thesereviews are manually labeled with 12 movie featurelabels (We didn?t use the additional opinion anno-tations in this data set.)
, e.g., VP (vision effects),MS (music and sound effects), etc., also on the sen-tences, but the annotations in the review data set ismuch sparser than that in the Ads data set (see in Ta-ble 1).
The sentence-level annotations make it pos-sible to quantitatively evaluate the discovered topicstructures.We performed simple preprocessing on thesetwo data sets: 1) removed a standard list of stopwords, terms occurring in less than 2 documents;2) discarded the documents with less than 2 sen-tences; 3) aggregated sentence-level annotationsinto document-level labels (binary vector) for eachdocument.
Table 1 gives a brief summary on thesetwo data sets after the processing.Ads ReviewDocument Size 8,031 1,991Vocabulary Size 21,993 14,507Avg Stn/Doc 8.0 13.9Avg Labeled Stn/Doc 7.1* 5.1Avg Token/Stn 14.1 20.0*Only in 302 labeled adsTable 1: Summary of evaluation data set5.2 Topic Transition ModelingFirst, we qualitatively demonstrate the topical struc-ture identified by strTM from Ads data1.
We trainedstrTM with 11 content topics in Ads data set, usedword distribution under each class (estimated bymaximum likelihood estimator on document-levellabels) as priors to initialize the emission probabil-ity Mul(?z) in Eq(6), and treated document-level la-bels as the prior for transition from T-START in eachdocument, so that the mined topics can be alignedwith the predefined class labels.
Figure 2 shows theidentified topics and the transitions among them.
Toget a clearer view, we discarded the transitions be-low a threshold of 0.1 and removed all the isolatednodes.From Figure 2, we can find some interesting top-ical structures.
For example, people usually startwith ?size?, ?features?
and ?address?, and endwith ?contact?
information when they post an apart-1Due to the page limit, we only show the result in Ads dataset.1530TELEPHONEappointmentinformationcontactemailparkingkitchenroomlaundrystoragecloseshoppingtransportationbartlocationhttpphotosclickpicturesviewdepositmonthleaserentyearpetskitchencatnegotiatesmokingwatergarbageincludedpaidutilitiesNUMbedroombathroomlargeFigure 2: Estimated topics and topical transitions in Ads data setment ads.
Also, we can discover a strong transitionfrom ?size?
to ?features?.
This intuitively makessense because people usually write ?it?s a two bed-rooms apartment?
first, and then describe other ?fea-tures?
about the apartment.
The mined topics arealso quite meaningful.
For example, ?restrictions?are usually put over pets and smoking, and parkingand laundry are always the major ?features?
of anapartment.To further quantitatively evaluate the estimatedtopic transitions, we used Kullback-Leibler (KL) di-vergency between the estimated transition matrixand the ?ground-truth?
transition matrix as the met-ric.
Each element of the ?ground-truth?
transitionmatrix was calculated by Eq(9), where c(z, z?)
de-notes how many sentences annotated by z?
immedi-ately precede one annotated by z. ?
is a smoothingfactor, and we fixed it to 0.01 in the experiment.p?(z|z?)
= c(z, z?)
+ ?c(z) + k?
(9)The KL divergency between two transition matri-ces is defined in Eq(10).
Because we have a k ?
ktransition matrix (Tstart is not included), we calcu-lated the average KL divergency against the ground-truth over all the topics:avgKL=?ki=1 KL(p(z|z?i)||p?(z|z?i))+KL(p?
(z|z?i)||p(z|z?i))2k(10)where p?(z|z?)
is the ground-truth transition proba-bility estimated by Eq(9), and p(z|z?)
is the transi-tion probability given by the model.We used pLSA (Hofmann, 1999), latent permuta-tion model (lPerm) (Chen et al, 2009) and HTMM(Gruber et al, 2007) as the baseline methods for thecomparison.
Because none of these three methodscan generate a topic transition matrix directly, weextended them a little bit to achieve this goal.
ForpLSA, we used the document-level labels as priorsfor the topic distribution in each document, so thatthe estimated topics can be aligned with the prede-fined class labels.
After the topics were estimated,for each sentence we selected the topic that hadthe highest posterior probability to generate the sen-tence as its class label.
For lPerm and HTMM, weused Kuhn-Munkres algorithm (Lova?sz and Plum-mer, 1986) to find the optimal topic-to-class align-ment based on the sentence-level annotations.
Af-ter the sentences were annotated with class labels,we estimated the topic transition matrices for all ofthese three methods by Eq(9).1531Since only a small portion of sentences are an-notated in the Review data set, very few neighbor-ing sentences are annotated at the same time, whichintroduces many noisy transitions.
As a result, weonly performed the comparison on the Ads data set.The ?ground-truth?
transition matrix was estimatedbased on all the 302 annotated ads.pLSA+prior lPerm HTMM strTMavgKL 0.743 1.101 0.572 0.372p-value 0.023 1e-4 0.007 ?Table 2: Comparison of estimated topic transitions onAds data setIn Table 2, the p-value was calculated based on t-test of the KL divergency between each topic?s tran-sition probability against strTM.
From the results,we can see that avgKL of strTM is smaller than theother three baseline methods, which means the esti-mated transitional relation by strTM is much closerto the ground-truth transition.
This demonstratesthat strTM captures the topical structure well, com-pared with other baseline methods.5.3 Sentence AnnotationIn this section, we demonstrate how the identifiedtopical structure can benefit the task of sentence an-notation.
Sentence annotation is one step beyond thetraditional document classification task: in sentenceannotation, we want to predict the class label foreach sentence in the document, and this will be help-ful for other problems, including extractive summa-rization and passage retrieval.
However, the lack ofdetailed annotations on sentences greatly limits theeffectiveness of the supervised classification meth-ods, which have been proved successful on docu-ment classifications.In this experiment, we propose to use strTM to ad-dress this annotation task.
One advantage of strTMis that it captures the topic transitions on the sen-tence level within documents, which provides a reg-ularization over the adjacent predictions.To examine the effectiveness of such structuralregularization, we compared strTM with four base-line methods: pLSA, lPerm, HTMM and NaiveBayes model.
The sentence labeling approaches forstrTM, pLSA, lPerm and HTMM have been dis-cussed in the previous section.
As for Naive Bayesmodel, we used EM algorithm 2 with both labeledand unlabeled data for the training purpose (we usedthe same unigram features as in topics models).
Weset weights for the unlabeled data to be 10?3 inNaive Bayes with EM.The comparison was performed on both data sets.We set the size of topics in each topic model equalto the number of classes in each data set accord-ingly.
To tackle the situation where some sentencesin the document are not strictly associated with anyclasses, we introduced an additional NULL contenttopic in all the topic models.
During the trainingphase, none of the methods used the sentence-levelannotations in the documents, so that we treated thewhole corpus as the training and testing set.To evaluate the prediction performance, we cal-culated accuracy, recall and precision based on thecorrect predictions over the sentences, and averagedover all the classes as the criterion.Model Accuracy Recall PrecisonpLSA+prior 0.432 0.649 0.457lPerm 0.610 0.514 0.471HTMM 0.606 0.588 0.443NB+EM 0.528 0.337 0.612strTM 0.747 0.674 0.620Table 3: Sentence annotation performance on Ads datasetModel Accuracy Recall PrecisonpLSA+prior 0.342 0.278 0.250lPerm 0.286 0.205 0.184HTMM 0.369 0.131 0.149NB+EM 0.341 0.354 0.431strTM 0.541 0.398 0.323Table 4: Sentence annotation performance on Reviewdata setAnnotation performance on the two data sets isshown in Table 3 and Table 4.
We can see that strTMoutperformed all the other baseline methods on mostof the metrics: strTM has the best accuracy and re-call on both of the two data sets.
The improvementconfirms our hypothesis that besides solely depend-ing on the local word patterns to perform predic-2Mallet package: http://mallet.cs.umass.edu/1532tions, adjacent sentences provide a structural reg-ularization in strTM (see Eq(3)).
Compared withlPerm, which postulates a strong constrain over thetopic assignment (sampling without replacement),strTM performed much better on both of these twodata sets.
This validates the benefit of modeling lo-cal transitional relation compared with the global or-dering.
Besides, strTM achieved over 46% accu-racy improvement compared with the second bestHTMM in the review data set.
This result showsthe advantage of explicitly modeling the topic tran-sitions between neighbor sentences instead of usinga binary relation to do so as in HTMM.To further testify how the identified topical struc-ture can help the sentence annotation task, we firstrandomly removed 100 annotated ads from the train-ing corpus and used them as the testing set.
Then,we used the ground-truth topic transition matrix es-timated from the training data to order those 100 adsaccording to their fitness scores under the ground-truth topic transition matrix, which is defined inEq(11).
We tested the prediction accuracy of differ-ent models over two different partitions, top 50 andbottom 50, according to this order.fitness(d) = 1|d||d|?i=0log p?
(ti|ti?1) (11)where ti is the class label for ith sentence in doc-ument d, |d| is the number of sentences in docu-ment d, and p?
(ti|ti?1) is the transition probabilityestimated by Eq(9).Top 50 p-value Bot 50 p-valuepLSA+prior 0.496 4e-12 0.542 0.004lPerm 0.669 0.003 0.505 8e-4HTMM 0.683 0.004 0.579 0.003NB + EM 0.492 1e-12 0.539 0.002strTM 0.752 ?
0.644 ?Table 5: Sentence annotation performance according tostructural fitnessThe results are shown in Table 5.
From this table,we can find that when the testing documents followthe regular patterns as in the training data, i.e., top50 group, strTM performs significantly better thanthe other methods; when the testing documents don?tshare such structure, i.e., bottom 50 group, strTM?sperformance drops.
This comparison confirms thatwhen a testing document shares similar topic struc-ture as the training data, the topical transitions cap-tured by strTM can help the sentence annotation taska lot.
In contrast, because pLSA and Naive Bayesdon?t depend on the document?s structure, their per-formance does not change much over these two par-titions.5.4 Sentence OrderingIn this experiment, we illustrate how the learned top-ical structure can help us better arrange sentences ina document.
Sentence ordering, or text planning, isessential to many text synthesis applications, includ-ing multi-document summarization (Goldstein et al,2000) and concept-to-text generation (Barzilay andLapata, 2005).In strTM, we evaluate all the possible orderingsof the sentences in a given document and selectedthe optimal one which gives the highest generationprobability:??
(m) = argmax?(m)?zp(S?
[0], S?
[1], .
.
.
, S?
[m], z|?
)(12)where ?
(m) is a permutation of 1 to m, and ?
[i] isthe ith element in this permutation.To quantitatively evaluate the ordering result, wetreated the original sentence order (OSO) as the per-fect order and used Kendall?s ?(?)
(Lapata, 2006) asthe evaluation metric to compute the divergency be-tween the optimum ordering given by the model andOSO.
Kendall?s ?(?)
is widely used in informationretrieval domain to measure the correlation betweentwo ranked lists and it indicates how much an order-ing differs from OSO, which ranges from 1 (perfectmatching) to -1 (totally mismatching).Since only the HTMM and lPerm take the orderof sentences in the document into consideration, weused them as the baselines in this experiment.
Weranked OSO together with candidate permutationsaccording to the corresponding model?s generationprobability.
However, when the size of documentsbecomes larger, it?s infeasible to permutate all theorderings, therefore we randomly permutated 200possible orderings of sentences as candidates whenthere were more than 200 possible candidates.
The15332bedroom 1bath in very nice complex!
Pool,carport, laundry facilities!!
Call Don (650)207-5769 to see!
Great location!!
Also available,2bed.2bath for $1275 in same complex.=?2bedroom 1bath in very nice complex!
Pool, car-port, laundry facilities!!
Great location!!
Alsoavailable, 2bed.2bath for $1275 in same complex.Call Don (650)207-5769 to see!2 bedrooms 1 bath + a famyly room in a cul-de-sac location.
Please drive by and call Marilyn forappointment 650-652-5806.
Address: 517 PriceWay, Vallejo.
No Pets Please!=?2 bedrooms 1 bath + a famyly room in a cul-de-sac location.
Address: 517 Price Way, Vallejo.
NoPets Please!
Please drive by and call Marilyn forappointment 650-652-5806.Table 6: Sample results for document ordering by strTMexperiment was performed on both data sets with80% data for training and the other 20% for testing.We calculated the ?(?)
of all these models foreach document in the two data sets and visualizedthe distribution of ?(?)
in each data set with his-togram in Figure 3.
From the results, we could ob-serve that strTM?s ?(?)
is more skewed towards thepositive range (with mean 0.619 in Ads data set and0.398 in review data set) than lPerm?s results (withmean 0.566 in Ads data set and 0.08 in review dataset) and HTMM?s results (with mean 0.332 in Adsdata set and 0.286 in review data set).
This indi-cates that strTM better captures the internal structurewithin the documents.
?1 ?0.8 ?0.6 ?0.4 ?0.2 0 0.2 0.4 0.6 0.8 10100200300400500600700800900?(?
)# of DocumentsAdslPermHTMMstrTM?1 ?0.8 ?0.6 ?0.4 ?0.2 0 0.2 0.4 0.6 0.8 1020406080100120140160?(?
)# of DocumentsReviewlPermHTMMstrTM(a) Ads (b) ReviewFigure 3: Document Ordering Performance in ?(?
).We see that all methods performed better on theAds data set than the review data set, suggestingthat the topical structures are more coherent in theAds data set than the review data.
Indeed, in theAds data, strTM perfectly recovered 52.9% of theoriginal sentence order.
When examining some mis-matched results, we found that some of them weredue to an ?outlier?
order given by the original docu-ment (in comparison to the ?regular?
patterns in theset).
In Table 6, we show two such examples wherewe see the learned structure ?suggested?
to movethe contact information to the end, which intuitivelygives us a more regular organization of the ads.
It?shard to say that in this case, the system?s ordering isinferior to that of the original; indeed, the system or-der is arguably more natural than the original order.6 ConclusionsIn this paper, we proposed a new structural topicmodel (strTM) to identify the latent topical struc-ture in documents.
Different from the traditionaltopic models, in which exchangeability assumptionprecludes them to capture the structure of a docu-ment, strTM captures the topical structure explicitlyby introducing transitions among the topics.
Experi-ment results show that both the identified topics andtopical structure are intuitive and meaningful, andthey are helpful for improving the performance oftasks such as sentence annotation and sentence or-dering, where correctly recognizing the documentstructure is crucial.
Besides, strTM is shown to out-perform not only the baseline topic models that failto model the dependency between the topics, butalso the semi-supervised Naive Bayes model for thesentence annotation task.Our work can be extended by incorporating richerfeatures, such as named entity and co-reference, toenhance the model?s capability of structure finding.Besides, advanced NLP techniques for documentanalysis, e.g., shallow parsing, may also be used tofurther improve structure finding.7 AcknowledgmentsWe thank the anonymous reviewers for their use-ful comments.
This material is based upon worksupported by the National Science Foundation un-der Grant Numbers IIS-0713581 and CNS-0834709,and NASA grant NNX08AC35A.1534ReferencesR.
Barzilay and M. Lapata.
2005.
Collective content se-lection for concept-to-text generation.
In Proceedingsof the conference on Human Language Technology andEmpirical Methods in Natural Language Processing,pages 331?338.R.
Barzilay and L. Lee.
2004.
Catching the drift: Proba-bilistic content models, with applications to generationand summarization.
In Proceedings of HLT-NAACL,pages 113?120.D.M.
Blei and M.I.
Jordan.
2003.
Modeling annotateddata.
In Proceedings of the 26th annual internationalACM SIGIR conference, pages 127?134.D.M.
Blei and J.D.
Lafferty.
2007.
A correlated topicmodel of science.
The Annals of Applied Statistics,1(1):17?35.D.M.
Blei and P.J.
Moreno.
2001.
Topic segmentationwith an aspect hidden Markov model.
In Proceedingsof the 24th annual international ACM SIGIR confer-ence, page 348.
ACM.D.M.
Blei, Andrew Y. Ng, and Michael I. Jordan.
2003.Latent dirichlet alocation.
The Journal of MachineLearning Research, 3(2-3):993 ?
1022.H.
Chen, SRK Branavan, R. Barzilay, and D.R.
Karger.2009.
Global models of document structure using la-tent permutations.
In Proceedings of HLT-NAACL,pages 371?379.P.
Diaconis and D. Ylvisaker.
1979.
Conjugate pri-ors for exponential families.
The Annals of statistics,7(2):269?281.M.
Galley, K. McKeown, E. Fosler-Lussier, and H. Jing.2003.
Discourse segmentation of multi-party conver-sation.
In Proceedings of the 41st Annual Meeting onAssociation for Computational Linguistics-Volume 1,pages 562?569.J.
Goldstein, V. Mittal, J. Carbonell, and M. Kantrowitz.2000.
Multi-document summarization by sentence ex-traction.
In NAACL-ANLP 2000 Workshop on Auto-matic summarization, pages 40?48.T.
Grenager, D. Klein, and C.D.
Manning.
2005.
Un-supervised learning of field segmentation models forinformation extraction.
In Proceedings of the 43rd an-nual meeting on association for computational linguis-tics, pages 371?378.T.L.
Griffiths, M. Steyvers, D.M.
Blei, and J.B. Tenen-baum.
2005.
Integrating topics and syntax.
Advancesin neural information processing systems, 17:537?544.Amit Gruber, Yair Weiss, and Michal Rosen-Zvi.
2007.Hidden topic markov models.
volume 2, pages 163?170.T.
Hofmann.
1999.
Probabilistic latent semantic index-ing.
In Proceedings of the 22nd annual internationalACM SIGIR conference on Research and developmentin information retrieval, pages 50?57.E.H.
Hovy.
1993.
Automated discourse generation usingdiscourse structure relations.
Artificial intelligence,63(1-2):341?385.M.
Johnson.
2007.
Why doesn?t EM find good HMMPOS-taggers.
In Proceedings of the 2007 Joint Confer-ence on Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learn-ing (EMNLP-CoNLL), pages 296?305.M.I.
Jordan, Z. Ghahramani, T.S.
Jaakkola, and L.K.Saul.
1999.
An introduction to variational methodsfor graphical models.
Machine learning, 37(2):183?233.H.
Kamp.
1981.
A theory of truth and semantic repre-sentation.
Formal methods in the study of language,1:277?322.M.
Lapata.
2006.
Automatic evaluation of informationordering: Kendall?s tau.
Computational Linguistics,32(4):471?484.L.
Lova?sz and M.D.
Plummer.
1986.
Matching theory.Elsevier Science Ltd.Y.
Lu and C. Zhai.
2008.
Opinion integration throughsemi-supervised topic modeling.
In Proceeding ofthe 17th international conference on World Wide Web,pages 121?130.Daniel Marcu.
1998.
The rhetorical parsing of naturallanguage texts.
In ACL ?98, pages 96?103.Q.Mei, X. Ling, M.Wondra, H. Su, and C.X.
Zhai.
2007.Topic sentiment mixture: modeling facets and opin-ions in weblogs.
In Proceedings of the 16th interna-tional conference on World Wide Web, pages 171?180.L.R.
Rabiner.
1989.
A tutorial on hidden Markov modelsand selected applications in speech recognition.
Pro-ceedings of the IEEE, 77(2):257?286.R.
Soricut and D. Marcu.
2003.
Sentence level dis-course parsing using syntactic and lexical information.In Proceedings of the 2003 Conference of the NAACL-HTC, pages 149?156.B.
Sun, P. Mitra, C.L.
Giles, J.
Yen, and H. Zha.
2007.Topic segmentation with shared topic detection andalignment of multiple documents.
In Proceedings ofthe 30th ACM SIGIR, pages 199?206.ChengXiang Zhai, Atulya Velivelli, and Bei Yu.
2004.A cross-collection mixture model for comparative textminning.
In Proceeding of the 10th ACM SIGKDDinternational conference on Knowledge discovery indata mining, pages 743?748.L.
Zhuang, F. Jing, and X.Y.
Zhu.
2006.
Movie re-view mining and summarization.
In Proceedings ofthe 15th ACM international conference on Informationand knowledge management, pages 43?50.1535
