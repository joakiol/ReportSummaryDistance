Testing The Psychological Realityof a Representational ModelDedre GentnerBolt Beranek and Newman Inc.ABSTRACTA research program is described in whicha particular representational format formeaning is tested as broadly as possible.
Inthis format, developed by the LNR researchgroup at The University of California at SanDiego, verbs are represented as interconnectedsets of subpredicates.
These subpredicatesmay be thought of as the almost inevitableinferences that a listener makes when a verbis used in a sentence.
They confer a meaningstructure on the sentence in which the verb isused.
To be psychologically valid, theserepresentations should capture (at least):I. Similarity of meaningThe more similar two verbs seem inmeaning to people, the more theirrepresentations should overlap.2.
ConfusabilityThe more confusable two verb meaningsare, the more their representationsshould overlap.3.
Memory for sentences containing theverbThe sentence structures set up by theverb's meaning should in partdetermine the way in which sentencesare remembered.4.
Semantic integrationThe representations should allow forthe integration of information fromdifferent sentences into discoursestructure5.
Acquisition patternsThe structural partitions in therepresentations should correspond tothe structures children acquire whenthey are learning the meanings of theverbs.6.
Patterns of extensionThe representations should beextendible so as to reflect the waysin which people interpret verbmeanings when the verbs are usedoutside their normal context.7.
Reaction timesThe time taken to comprehend asentence using a given verb shouldreflect the structural complexity ofthe verb meaning.Experiments concerned with predictionsI-5 are described here.
The results arepromising for a general approach ofrepresentation of meaning in terms ofinterrelated subpredicates, but do not clearlydistinguish between several similarrepresentations.
For example, to testprediction (2), I read people sentencescontaining verbs with similar meanings, andasked them to recall the sentences.
Thedegree of overlap in the semantic structureswas a good predictor of the number ofconfusions between sentences.
In anothersentence-memory experiment (prediction (3)),semantically complex verbs that provided moreunderlying interconnections between the nounsin a sentence led to better memory for thenouns in the sentence than simple generalverbs, or than other complex verbs that didnot provide such extra interconnections.
Totest  prediction (5), I tested children'scomprehension of a set of possession verbs.Both the order of acquisition among the verbsand the kinds of errors fitted well with anaccount of the acquisition of verb meaning interms of interconnected subpredicates.This research illustrates a breadth-firstapproach to testing a representation.
In thebreadth-first approach, many differentpsychological predictions are made.
Eachdifferent area of prediction requires a set ofprocess assumptions, and in each case theprocess assumptions used are those that seemmost plausible given previous research in thefield.
If one representational format canmake correct predictions about a number ofdifferent kinds of psychological phenomena,then that representation stands a greaterchance of being generally useful than onewhich was tested in only one depth-first way.This paper describes a program ofresearch that tests a representational formatfor verb meaning.
This research grew out ofthe LNR (Footnote I) attempt to the representthe meanings of words in a psychologicallysatisfying way.
Verb meaning seemed a naturalplace to start for two reasons: (I) verbs areimportant: it is arguable that they providethe central organizing semantic structures insentence meanings; and (2) verbs aretractable: their meanings are more easilyanalyzed than those of, for example, commonnouns.Since different disciplines look atmeaning in different ways, it may beworthwhile to describe the stance we took.What we wanted was a system of representationin which we could capture our intuitions aboutwhat a word typically conveys; or morespecifically about the inferences a personnormally makes (or believes should be made)when a word is used.
The assumption is thatthe same representations operate when a personuses the word in speech as when the personcomprehends it; however the methodology ofexperimental psychology makes it natural tospend more time pondering the input processthan the output process.
This approachdiffers from thinking of meaning in terms ofnecessary and sufficient truth-conditions, asmany philosophers have done, or from thinkingabout meaning in generation rather than incomprehension, as many linguists have done.Each of those stances leads to usefulintuitions.
Overall, there has been areassuring degree of convergence between therepresentations proposed.Representation of Verb Me~ningThere are many notational systems forrepresentation of verb meaning (e.g.,Abrahamson, 1975; Chafe, 1970; Fillmore, 1971;Gentner, 1975; Lakoff, 1970; McCawley, 1968;Rumelhart & Levin, 1975; Schank, 1972, 1975;Talmy, 1975).
These models of verb meaningdiffer from one another in detail, but thereis widespread agreement on the idea that verbmeanings can be represented in terms ofinterrelated sets of subpredicates, such asCAUSE or CHANGE.
These subpredicates are notmerely concatenated within a word'srepresentation.
Rather, they areinterrelated, in specific ways.Representations of verb meaning includenotation for specifying the relationshipsamong the subpredicates that make up a word'smeaning.
The notation developed by the LNRGroup is a network format.
In this system ofrepresentation, verb meanings are expressedin terms of subpredicates that stand forstates, changes of state, aetionals, etc.The E l~ents  of Verb Meaning.
Verbsprovide a system in which people can talkabout happenings in the world, implicitlydistinguishing several types of conceptualpossibilities.
The simplest of these is thestate.
A stative predicate conveys arelationship that endures for a period of timebetween two arguments, normally an object (orperson) and an object or value within theconceptual field specified by the stative.For example, consider the sentence shown inFigure I.Ida owned a Cadillac from 1970 to 1977.The verb o~n conveys that a relationship ofpossession existed between Ida and theCadillac for some duration.
Besides stativesfor possession, there are a large number ofother statives, including location (to be a~,$o remain a~, etc.)
and emotion (to hate, to~ ,  etc.)
.In addition to simple stativerelationships, verbs can be used to conveychanges of state.
Following Chafe (1970) Iwill refer to a change of state as a oroces~.For example, the sentenceIda receives $10.00.tells us(I) that Ida now has $10.00(2) that someone else had the $10.00 before;(3) that a change has taken place from thisprevious state of possession to thepresent state.More commonly, verbs express not simplechanges of state but causal changes of state.We seem to be very interested in processesthat are volitionally caused by humans andother sentient beings.
Figure 2 shows therepresentation of the sentence:Ida gives Sam a rose.An agent may cause a change of state thatrelates to another object.
Or the same personmay act on both agent and experiencer of thechange of state.
The locational verb move canbe used in either way, as in the followingexamples:a. Ida moved the car.b.
Ida moved to the front seat.In both these casesthe  action taken by Ida isunspecified.
We often don't care exactly whatsomeone did to cause some process to occur.However, there are also verbs in which thecausal action is partially or whollyspecified: e.g., ~L~!_k, saunte~r, meander,stride, ru~, sprint, race, ~rob, log.
(SeeMiller (1972) and Miller & Johnson-Laird(1976) for a more extensive discussion of theverbs of location.
)Thus, this system allows for therepresentation of verbs as states, changes ofstate, causal changes of state, simpleactions, and complex cases in which specificactions cause changes of state.
Furtherdiscussion of the LNR system of verb semanticscan be found in the articles by Abrahamson,Gentner, Munro, Rumelhart & Levin, andRumelhart & Norman in the Norman & Rumelhart(1975) volume.There are certainly gaps in the system,and aspects of verb meaning that are notexpressible in this simple vocabulary.
Someunresolved issues are discussed later in thepaper.
However, the system seems plausible atthe first level, and allows a fair range ofverb meanings to be captured at least roughly.At this point in the research it seemedappropriate to begin testing the psychologicalrightness of the system as so far statedbefore going on to refine it.Psychological Tests of ~he ModelOne advantage of psychologicalexperimentation (or of computerimplementation) is that it forces one to makeexplicit the assumptions underlyingrepresentation and process.
At least some ofthe choices made can then be tested ashypotheses.
Some important assumptions are(I) a verb's representation captures theset of immediate inferences that peoplenormally make when they hear or read asentence containing the verb;(2) in general, one verb leads to manyinferences(3) these networks of meaning componentsare accessed during comprehension, by animmediate and largely automatic process(4) the set of components associated witha given word is reasonably stable acrosstasks and contexts(5) surface memory for exact words fadesquite rapidly, so that after a short time,only the representational network remains.In testing these representations, Itook a very literal interpretation of thenotion of representation -- namely thatthe nodes and arrows in a representationcorrespond to the concepts andrelationships that are stored when aperson comprehends a sentence containing averb.
The more ferociously literal theinterpretation, the better the chances ofdiscovering counter-evidence.Semantic overlao.
One psychologicalcriterion is that the representations shouldagree with people's intuitive notions ofsynonymity and similarity in meaning.
Onestraightforward measure of this overlap is thedegree to which people rate verbs as similarin meaning.
In a study of about 60 selectedverbs, I found that people's average rating ofthe semantic similarity between two verbsagreed very closely with the degree ofsemantic overlap between theirrepresentations.A more subtle measure of psychologicalsimilarity is the degree to which peopleunconsciously confuse things in memory.People in a sentence-memory experimentprobably try to keep their sentence tracesclear.
But, suppose that within a short timeafter hearing a verb in a sentence, a personhas only the representational network ofconcepts and relationships, and not thesurface verb.
Assume further that some piecesof the memory representation may be lost orunaccessible at any time (the "fallibility ofhuman memory" assumption).
Then the more twoverb representations overlap, the more likelyit is that sentences containing the two verbswill be confused in memory, despite people'sattempts to keep them straight.
In anexperiment in sentence memory, using verbs ofvarying semantic overlap, I found thatsubjects did indeed confuse the verbs inexactly the way predicted by the theory(Gentner, 1974).
The correlation between thenumber of confusions subjects made between twoverbs and the semantic overlap between theverbs, as predicated from the representations,was quite high.
In fact, the correlationbetween representational overlap and number ofconfusions was slightly higher (though notsignificantly so) than the correlation betweenthe number of confusions and the ratedsimilarity between the verbs.
(The similarityratings were taken from the first-mentionedstudy, with a different set of subjects).Semantic complexity.
Semantic complexityrefers to the number of underlyingsubpredicates and interconnections that makeup the basic meaning of a verb.
More complexmeanings correspond to more specific actionsor events.
For example, stride is morespecific than go.
Its meaning contains moresubpredicates.
We know more having heardsentence (a) than sentence (b).
(a) Ida strode across the field.
(b) Ida went across the field.Various researchers have looked for evidencethat semantic complexity ~ay affectcomprehensibility, generally on the assumptionthat more complex semantic structures areharder to process (Kintsch 1974; Thorndyke,1977).
However, the results have beennegative.
There is no evidence that morecomplex words lead either to longerreaction-times or to greater processing loadsthan do simpler words.
I believe that it'sincorrect to assume across the board thatcomplexity is psychologically hard.
Someresearch of mine suggests that the effects ofsemantic complexity in memory are moreparticular.Semantic Complexity and Connectivity.Although the view that semantic complexityleads to difficulty has not been supported,there is another side to the complexity issue.The additional semantic components in acomplex verb may set up additional connectionsamong the nouns in the sentence.
In thiscase, more complex verbs should lead to aricher and more highly interwoven sentencerepresentation, and thus to better memory forthe nouns in the sentence.Notice that this prediction derives froma fanatically literal interpretation of theverb representations: more paths in therepresentation means more conceptual paths inmemory.
This prediction is quite specific.It is not simply a question of certain complexversus simple verbs having some overalleffect, but rather of complex verbs providingextra connections between the particular nounsin question.
This is clearly true for Ida andher tenants in the case of sell versus give,as can be seen in Fig 3a and 3b.I tested for this kind of improvement inconnectivity in a series of experiments insentence memory (Gentner, 1977).
I readpeople sentences that differed in the semanticconnectivity of their verbs, such as thefollowing pair of sentences:Ida gave her tenants a clock.
(simple)Ida sold her tenants a clock.
(complexconnective)Then I gave the people the names of thecharacters and asked them to recall thesentences.
As predicted, they were betterable to recall the noun tenants when thecomplex connective verb sell was used thenwhen the simple verb give was used.
Moresemantic connections between the two nouns ledto stronger memory connections.To see the specificity of the prediction,consider a complex verb that merely amplifiesthe simple verb and does not add connectionsbetween the key nouns.
For example, the verbmail (Fig 3c) adds the information that themethod of transfer was by mailing or some suchlong-distance transfer.
Using mail leads tomore inferences (a more specific eventdescription) than using give.
However, theknowledge that the object was mailed leads tofew, if any, additional connections betweenthe agent, Ida, and the recipient, tenants.Therefore, the prediction was that use of suchnon-connecting specific verbs would lead to noimprovement over use of general verbs inmemory between the nouns.The results were exactly as predicted:The object nouns of complex connective verbswere recalled better than those of generalverbs and non-connecting complex verbs.
Thesedifferences were not traceable to differencesin imagery or word-frequency.
Thusconnectivity is beneficial to sentence memoryin a very specific way.Accuis~ion.
There may be a more directrelationship between complexity and difficultyin children than in adults.
Young childrenoften fail to comprehend the full meanings ofsemantically complex terms (e.g., Bowerman,1975; Clark, 1973; Gentner, 1975, in press).Working with the verbs of possession, I haveobserved that children act out the simpleverbs gLve and takacorrectly before they actout the more complex verbs b~?
and trade.Still later they learn the yet more complexverbs bu?, sell and spend.
The order in whichthe verbs are learned is exactly the order ofincreasing semantic complexity.
Thiscomplexity ordering can be made quite precise,since the verbs are closely related inmeaning.
The representation of a verb at thenth level of simplicity is properly nestedwithin the representation of a verb at the(n+1)th level.
Further, when children around4-6 years are asked to act out sell (as in"Make Ernie sell Bert a boat.")
they act outgive instead (A boat is transferred from Ernieto Bert).
Similarly, bu~ is acted out astake.
They systematically act out complexverbs like simple verbs; and moresurprisingly, they choose the appropriatesimple verb.
My interpretation, consistentwith Clark's (1973) semantic featuresanalysis, is that children learn these complexverb meanings gradually, by adding componentsto their partially correct representations.At any given time, the child comprehendslanguage in terms of the components that hehas so far acquired.Semantic ~ntegration.
Another importantpsychological requirement is combinability.The basic notions of state, change of state,cause, and so on must be combinable intonetworks larger than the individual sentence.When two verbs share parts of their underlyingstructure, this redundancy should be utilizedto combine the two representations into onediscourse structure.
How can we test whetherthis happens?
One way is to arrange things sothat collapsing the redundancies between twoverbs should create the representation of athird verb.
Then the prediction is thatpeople should use this third verb in recall.In a study of semantic integration, Iread people short passages and tested theirmemory by having them fill in blanks (Gentner,1978).
Every passage contained a generalverb, such as give.
Half the passages alsocontained additional semantic information,such as the fact that the giver actually owedthe money he was giving.
According to therepresentational model, the integration of therepresentation of give with that of owingshould have created the structure of pay.
Ifwhat people have in their minds after hearingthe verbs is the network representations, andif these representations are integrated duringdiscourse comprehension, then people who heardgive and owe should end up with therepresentation of DaY.
As predicted, subjectshearing the extra material falsely recalledthe verb which best fit the compositestructure (e.g.
nay) rather than the verbactually presented.Further lssuesI have made the assumption that a verbcarries with it a set of inferences that arenormally made during comprehension, as well asseveral supporting assumptions.
This view hasbeen fairly well supported by the researchpresented here, but nevertheless it seems tome an oversimplification.
There remain agreat many questions, some large and somesmall.
(I) Where should the line be drawn around aword's meaning?
As Clark and Clark (1977)have put it, is word meaning more like adictionary or an encyclopedia?
The extreme ofthe dictionary approach would be to take aminimal contrast approach, storing with a wordonly enough to distinguish it from all otherwords.
The extreme of the encyclopediaapproach would be to access the entirelong-term memory whenever any word is used.The question is, how to define a reasonablemiddle ground.
(2) What is the process of expansion into asemantic representation during comprehension?a) Are there invariable inferences?
Whenan incoming word is processed, is therea set of inferences (such as the set Ihave called the "almost-inevitableinferences" that is always made duringcomprehension, or is there variation inwhich inferences get made?b) If there is variation, is itquantitative or qualitative?
Do contextand the person's interests and attentiondetermine W~c~ inferences get made, sothat there are qualitative differencesin what inferences get made?
Or is thedifference merely quantitative, with theradius of expansion varying with theamount of attention (or energy, orinterest) that the person brings tobear?The notion of at least quantitativevariation a seems hard to avoid.
It is afairly strong intuition that we process wordmeanings with varying degrees of energy.Further, the phenomenon of in~tantiation(Anderson, R.C., Stevens, K.C., Shifrin, Z., &Osborn, J.; 1977) makes it clear that a modelof sentence comprehension must allow forqualitative differences in the final set ofinferences stored.
For example, compare thesentencesRover ate his dinner.Mr.
Pritchard ate his dinner.The verb eat conveys vastly different actionsequences when used with different agents,though its causal change-of-state structureremains more-or-less constant.
It is possiblethat this qualitative variation can beaccounted for by simple underlyingquantitative processes spreading activation.We may have to settle for a more complexmodel, in which some parts of a verb's meaningare almost always accessed while otherinferences develop out of the interaction ofthe verb with its context, including itspragmatic context.
In Hewitt's (1976) terms,there may be both if-added inferences andif-needed inferences.
Where in this model(and whether) we want to draw a line betweenmeaning and knowledge-of-the-world is not atall clear to me.
(3) Carrying the notion ofvariable verb meaning still further, how doesmetaphorical extension work?
Most commonverbs can be used in several related ways.For example, consider the range of meaningsthat give can convey depending on the nouns itis used with:Ida gave Sama rose.a job.an heir.an excuse.a talking to.all his best ideas.the time of his life.Clearly the subpredicate structure variesacross these sentences, so much so that somemight want to describe this as a collection ofentirely different senses of the same word.This misses the structural similarities.
Somekind of metaphorical extension of meaningseems a necessary part of a theory of verbmeaning, since it is generally the verb thatdoes most of the adjusting.
A series ofstudies by Albert Stevens and me suggests thatpeople faced with an odd sentence assume thatsome of the subpredicates normally conveyed bythe verb are not meant to apply in thesentence at hand.
A current project is tomodel the rules for which subpredicates applyin different contexts.
(4) I have so far treated nouns as nodes inthe semantic representation.
Clearly in orderto analyze sentence interactions it isnecessary to have a representation of nounmeaning.
Some progress been made withabstract nouns, such as kinship terms.
Butthe truly nounlike nouns ---basic-levelnouns--- resist analysis.
I believe thatthese differences in amendability to analysisreflect differences in the kind of meaningthat verbs and nouns have, and that a usefulrepresentation of concrete noun meaning may bequite different from that used for verbs,prepositions and even abstract nouns.
(5) There are several aspects of therepresentational scheme that need furtherthought.
To single out one issue, considerthe notion of change of state.
The LNRrepresentation represents a verb like get asconveying a change from an initial state ofpossession to a final state of possession.Schank's Conceptual Dependency theory wouldrepresent the entire sequence as a primitiveact.
Many generative semanticists haverepresented only the inchoative part of thechain (the change to the final state) asbelonging to the assertion of the verb,considering the initial state to be more inthe nature of a presupposition (e.g.
Fillmore,1966).
All these positions seem to me to havemerit.
The LNR use of change from initial tofinal state allows a change-of-state verb tohook automatically with relevant stateinformation.
The use of acts as primitivescaptures the psychological wholeness ofchange.
The use of the inchoative capturesthe intuition that people seem more interestedin the results of an event --i.e.
in the finalstate-- than in the setting state.
Theexplicit change-of-state formats (LNR formatand inchoative format) have a natural way ofcapturing some kinds of metaphoricalextension: by substituting a different stativewhile preserving the rest of the verb'sstructure.SummaryThis work is just beginning.
Neither therepresentations nor the processes that areassumed to operate on them come very close tocapturing the subtlety of human language use.Still, the results of the experimentalinvestigation are promising some kind ofdecompositional model along these lines.e x p e r ~Ida Cadillac 1970 1977Figure i. Ida owned a Cadillac from1970-1977.event~resu l tExperiencey Object~i #bjec, ~.periencerIda rose SamFigure 2.
Ida gives Sam a rose.Ida mailed her tenants a clock.
.
.
.
.
- "  .
.
.
.
.
.
.
.
.
.
.
.
..o o '~ '~, ,  ..*"" ' , , /  ~ ? '
"  ' ' .
.,;o ,d~ o,o.
; ,en~.s .
~o \,o:k ,e~ontsSPECIFIC VERB (FEW CONNECTING P~HS)Figure 3e,Footnotei.
The repres~,~t~Eional format shown here wasdeveloped by a group of researchers at theUniversity.of California at San Diego:Adele A. Abrahamson, Dedre Gentner, James A,Levin, Stephen E. Palmer, and David E.Rumelhart.
The system is explained in detailin Norman & Rumelhart, 1975.Ida gav.ee her tenants a clockE ~  I!Ida clock tenantsGENERAL VERB (FEW CONNECTING PATHS)Figure 3a.Ida sold her tenants a clock~~,?
...... ~- "  ~;( ~\  , , .Ida ..-" ~ .... .
Ida tenants ~_Jus~.'"
EvenJ~ - -  ~Result "",, Resu l t /~  ~Even ."
j ~', ".. y ~.~.~/ \o O/ E \ i /~  '~o O,'---\SIda clock tenani~': money Ida ?
.
.
.
,  o. , , ,  , o .
, , , , ?
.
.
.
.
.
.
.
.
.
.
.
, .
,-"SPECIFIC VERB (MANY CONNECTING PATHS)Figure 35.ReferencesAbrahamson, A.A.
Experimental analysis of thesemantics of movement.
In D.A.
Norman, & D.E.Rumelhart, (Eds.
), Explorations in Cognition.San Francisco: W.H.
Freeman & Co., 1975.Anderson, R.C., Stevens, K.C., Shifrin, Z., &Osborn, J.
~nstantation of Word Meanings inChildren, May 1977.Bendix, E.H. Com~onential an~ly~s Qf generalvocabulary: The semantic str~c~re of a ~e~of verbs in English, Hindi.
and J~p~es~.
TheHague; Mouton, 1966.Bowerman, M. The acquisition of word meaning:An investigation of some current conflicts.Paper presented at the Third InternationalChild Language Symposium, London, September1975.Chafe, W.L.
Meanin~ and the strqctq~e oflanguage.
Chicago: University of ChicagoPress, 1970.Clark, E.V.
What's in a word: On the child'sacquisition of semantics in his firstlanguage.
In T.E.
Moore (Ed.
), Cognitivedevelopm~q~ and the ~cqui~itiQn of language,New York: Academic Press, 1973.Clark, H.H.
& Clark, E.V.
~sychologv andLanguage.
New York: Harcourt BraceJovanovich, Inc., 1977.Fillmore, C.J.
Review of Bendix's ~Qm~onentialanalysis ok ~eneral vocabulary: The ~mant icstructure of a se% ~f verbs in English.
Hindi,a~d Japanese.
Intern~t~Qnal Journ~l  QfAmer ica~uis t?cs ,  1966, 32, Part II, No.2.
Publication 41.Gentner, D. Towards a psychological theory ofthe meaning of the possession verbs.Unpublished doctoral dissertation, Universityof California, San Diego, 1974.Gentner, D. Evidence for the psychologicalreality of semantic components: The verbs ofpossession.
In D.A.
Norman and D.E.Rumelhart, ExDlorat~Qn~ in ~n i t ion ,  SanFrancisco: W.H.
Freeman & Co., 1975.Gentner, D. On relational meaning: Theacquisition of verb meaning.
ChildD~veloDme~t, in press.Gentner, D. Semantic integration of wordmeanings.
Bolt Beranek and Newman Inc. ReportNo.
3826, May 1978.
Also to appear as aCenter for the Study of Reading TechnicalReport.Hewitt, C. Viewing control structures aspatterns of passing messages.
M.I.T.
AIWorking Paper 92, 1976.Lakoff, G. Adverb,_And modal o~ec~tor~.Indiana University Linguistics Club Reprint.Bloomington: Indiana University LinguisticsClub, 1970(a).Lakoff, G. ~rregularitx and ~?~ax.
New York:Holt, Rinehart and Winston, 1970(c).McCawley, J.D.
The role of semantics in agrammar.
In E. Bach and R.T. Harms (Eds.
),U~iversals i~lin~uistic theorv.
New York:Holt, Rinehart and Winston, 1968(b).Norman, D. A., Rumelhart, D.E.
& the LNRResearch Group.
Explorations in cognition.San Francisco: W.H.
Freeman & Company, 1975.Rumelhart, D.R.
& Levin, J.A.
A languagecomprehension system.
In D.A.
Norman & D.E.Rumelhart, Explorations in cognition, SanFrancisco: W.H.
Freeman & Co., 1975.Schank, R. Conceptual Dependency: A Theory ofNatural Language Understanding, Cognitiv~?svchQIogv, 1972, ~, 552-631.Schank, R.C.
The structure of episodes inmemory.
In D. Bobrow & A. Collins (Eds.
),Representation and understanding.
New York:Academic Press, 1975.Talmy, L. Semantic structures in English andA~augewi ~ Unpublished doctoral dissertation,University of California, Berkeley, 1972.Thorndyke, P.W.
Cognitive structures incomprehension and memory of narrativediscourse.
Cognitive ~svchQlogv, 1977, ~,77-110.
