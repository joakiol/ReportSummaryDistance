Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41?48,New York City, June 2006. c?2006 Association for Computational LinguisticsCatching MetaphorsMatt Gedigian, John Bryant, Srini Narayanan, and Branimir CiricInternational Computer Science Institute1947 Center Street.
Suite 600Berkeley, CA 94704, USA{gedigian, jbryant, snarayan}@icsi.berkeley.eduAbstractMetaphors are ubiquitous in language anddeveloping methods to identify and dealwith metaphors is an open problem inNatural Language Processing (NLP).
Inthis paper we describe results from us-ing a maximum entropy (ME) classifierto identify metaphors.
Using the WallStreet Journal (WSJ) corpus, we anno-tated all the verbal targets associated witha set of frames which includes frames ofspatial motion, manipulation, and health.One surprising finding was that over 90%of annotated targets from these framesare used metaphorically, underscoring theimportance of processing figurative lan-guage.
We then used this labeled data andeach verbal target?s PropBank annotationto train a maximum entropy classifier tomake this literal vs. metaphoric distinc-tion.
Using the classifier, we reduce thefinal error in the test set by 5% over theverb-specific majority class baseline and31% over the corpus-wide majority classbaseline.1 IntroductionTo move beyond ?factoid?
style questions, questionanswering systems must rely on inferential mecha-nisms.
To answer such commonplace questions asWhich train should I take to get to the airport?
re-quires justifications, predictions and recommenda-tions that can only be produced through inference.One such question answering system (Narayananand Harabagiu, 2004) takes PropBank/FrameNet an-notations as input, uses the PropBank targets to in-dicate which actions are being described with whicharguments and produces an answer using probabilis-tic models of actions as the tools of inference.
Initi-ating these action models is called simulation.Such action models provide deep inferential capa-bilities for embodied domains.
They can also, whenprovided with appropriate metaphoric mappings, beextended to cover metaphoric language (Narayanan,1997).
Exploiting the inferential capabilities of suchaction models over the broadest domain requires asystem to determine whether a verb is being used lit-erally or metaphorically.
Such a system could thenactivate the necessary metaphoric mappings and ini-tiate the appropriate simulation.2 MetaphorWork in Cognitive Semantics (Lakoff and Johnson,1980; Johnson, 1987; Langacker, 1987; Lakoff,1994) suggests that the structure of abstract actions(such as states, causes, purposes, and means) arecharacterized cognitively in terms of image schemaswhich are schematized recurring patterns from theembodied domains of force, motion, and space.Consider our conceptualization of events as ex-emplified in the mapping called the Event StructureMetaphor.?
States are locations (bounded regions in space).?
Changes are movements (into or out ofbounded regions).41?
Causes are forces.?
Actions are self-propelled movements.?
Purposes are destinations.?
Difficulties are impediments to motion.This mapping generalizes over an extremely widerange of expressions for one or more aspects of eventstructure.
For example, take states and changes.
Wespeak of being in or out of a state, of entering orleaving it, of getting to a state or emerging from it.This is a rich and complex metaphor whose partsinteract in complex ways.
To get an idea of howit works, consider the submapping Difficulties areimpediments to motion.
In the metaphor, purpose-ful action is self-propelled motion toward a destina-tion.
A difficulty is something that impedes suchmotion.
Metaphorical difficulties of this sort comein five types: blockages; features of the terrain; bur-dens; counterforces; lack of an energy source.
Hereare examples of each: Blockages: He?s trying to getaround the regulations.
We?ve got him boxed intoa corner.
Features of the terrain: It?s been uphill allthe way.
We?ve been hacking our way through a jun-gle of regulations.
Burdens: He?s carrying quite aload.
Get off my back!
Counterforces: Quit pushingme around.
She?s leading him around by the nose.Lack of an energy source: I?m out of gas.
We?re run-ning out of steam.In summary, these metaphors are ontologicalmappings across conceptual domains, from thesource domain of motion and forces to the target do-main of abstract actions.
The mapping is conven-tional, that is, it is a fixed part of our conceptual sys-tem, one of our conventional ways of conceptualiz-ing actions.
Conventional metaphors capture gener-alizations governing polysemy, over inference pat-terns, and governing novel metaphorical language(Lakoff and Turner, 1989).2.1 Metaphors vs.
Different Word SensesPresumably, one could treat the metaphoric usage ofrun as a different sense, much in the same way thatmove forward on a business plan is treated as a dif-ferent sense from literal move forward.
From a pars-ing/information extraction point of view, these twoapproaches are equivalent in terms of their represen-tational requirements.The benefit of employing the metaphor-based ap-proach, as suggested in the introduction, comeswhen performing inference.
As shown by(Narayanan, 1997), a metaphorical usage and a lit-eral usage share inferential structure.
For example,the aspectual structure of run is the same in eitherdomain whether it is literal or metaphorical usage.Further, this sharing of inferential structure betweenthe source and target domains simplifies the repre-sentational mechanisms used for inference makingit easier to build the world models necessary forknowledge-intensive tasks like question answering(Sinha and Narayanan, 2005).3 ObjectiveWhile this work in Cognitive Semantics is sugges-tive, without a corpus-based analysis, it is hard toaccurately estimate the importance of metaphoric in-formation for Natural Language Processing (NLP)tasks such as Question Answering or InformationDistillation.
Our work is a first step to remedy thissituation.
We start with our computational defini-tion of metaphor as a mapping from concrete to ab-stract domains.
We then investigate the Wall StreetJournal (WSJ) corpus, selecting a subset of its ver-bal targets and labeling them as either metaphoricor literal.
While we had anticipated the pervasive-ness of metaphor, we could not anticipate just howpervasive with over 90% of the labeled data beingmetaphoric.Provided with labeled training data, our task is toautomatically classify the verbal targets of unseenutterances as either metaphoric or literal.
Motivatedby the intuition that the types of a target?s argumentsare important for making this determination, we ex-tracted information about the arguments from thePropBank (Kingsbury et al, 2002) annotation foreach sentence, using WordNet (Fellbaum, 1998) asthe type hierarchy.3.1 Using Verbal ArgumentsA metaphor is a structured mapping between theroles of two frames that makes it possible to describea (usually) more abstract concept in terms of a moreconcrete one (Lakoff and Johnson, 1980).
The moreabstract concept is referred to as the target domainwhile the more concrete concept is referred to as the421.
MET : Texas Air has {run} into difficulty...2.
LIT : ?I was doing the laundry and nearlybroke my neck {running} upstairs to see ...Figure 1: Examples taken from the WSJ Corpus.MET indicates a metaphoric use of the target verband LIT indicates a literal use.source domain.
More precisely, the metaphor mapsroles of the target frame onto the source frame.Figure 1 shows some example sentences with aparticular verbal target run in curly braces.
Example1 is a metaphoric usage (marked by MET) of runwhere the destination role is filled by the state ofdifficulty.
Example 2 is a literal usage (marked byLIT) of run.The arguments of a verb are an important fac-tor for determining whether that verb is being usedmetaphorically.
If they come from the source do-main frame, then the likelihood is high that the verbis being used literally.
In the example literal sen-tence from Figure 1, the theme is a person, which isa physical object and thus part of the source domain.If, on the other hand, the arguments come fromthe target domain, then it is likely that the verb isbeing used metaphorically.
Consider the metaphor-ical run from Figure 1.
In that case, both the themeand the goal of the action are from the target domain.Thus any approach that tries to classify sentences asliteral or metaphoric must somehow incorporate in-formation about verbal arguments.4 DataBecause no available corpus is labeled for themetaphoric/literal distinction, we labeled a subsetof the WSJ corpus for our experiments.
To focusthe task, we concentrated on motion-related framesthat act as the source domain for the Event StructureMetaphor and some additional non-motion basedframes including Cure and Placing.
Figure 2 showsthe selected frames along with example lexical unitsfrom each frame.To identify relevant sentences we first obtainedfrom FrameNet a list of lexical units that evokethe selected source frames.
Since WSJ is labeledwith PropBank word senses, we then had to deter-mine which PropBank senses correspond to theseFrame Example LUsMotion float, glide, go, soarMotion-directional drop, fall, plummetSelf-motion amble, crawl, hobbleCause-motion catapult, haul, throw, yankCotheme accompany, escort, pursuePlacing cram, heap, pocket, tuckCure cure, ease, heal, treatFigure 2: The frames selected for annotation andsome of the lexical units that evoke them.Cure Frame LU PropBank Sensealleviate alleviate.01cure cure.01ease ease.02heal heal.01rehabilitate rehabilitate.01resuscitate resuscitate.01treat treat.03Figure 3: The lexical units that evoke the Cure frameand each unit?s associated PropBank sense2.FrameNet lexical items.
The lexical items that evokethe Cure frame and the corresponding PropBanksenses are shown in Figure 3.As anyone who has inspected both PropBank andFrameNet can attest, these two important lexicalresources have chosen different ways to describeverbal senses and thus in many cases, determiningwhich PropBank sense corresponds to a particularFrameNet sense is not a straightforward process.Verbs like slide have a single PropBank sense usedto describe both the slid in The book slid off the ta-ble and the slid in I slid the book off the table.
WhileFrameNet puts slide both in the Motion frame andin the Cause-motion frame, PropBank uses the argu-ment labeling to distinguish these two senses.Periodically, PropBank has two senses, one forthe literal interpretation and one for the metaphoricinterpretation, where FrameNet uses a single sense.Consider the word hobble and its two senses in Prop-Bank:?
hobble.01 ?walk as if feet tied together??
hobble.02 ?tie the feet of, metaphorically ?hin-der?
?43Frame #MET #LIT Total %METCause-motion 461 44 505 91Cotheme 926 8 934 99Motion-directional 1087 21 1108 98Placing 888 110 998 89Self-motion 424 86 510 83Cure 105 26 131 80All Frames 3891 295 4186 93Figure 4: The number of targets annotatedmetaphoric or literal, broken down by frame.Because we intended to classify both literal andmetaphoric language, both PropBank senses of hob-ble were included.
However most verbs do not havedistinct literal and metaphoric senses in PropBank.The final step in obtaining the relevant portion oftheWSJ corpus is to use the lists of PropBank sensesthat corresponding to the FrameNet frames and ex-tract sentences with these targets.
Because the Prop-Bank annotations label which PropBank sense is be-ing annotated, this process is straightforward.Having obtained the WSJ sentences with itemsthat evoke the selected source frames, we labeled thedata using a three-way split:?
MET: indicating metaphoric use of the target?
LIT: indicating literal use of the target?
?
: indicating a target that the annotator wasunsure ofFor our experiments, we concentrated only on thosecases where the label was MET or LIT and ignoredthe unclear cases.As is shown in Figure 4, the WSJ data is heav-ily weighted towards metaphor over all the framesthat we annotated.
This tremendous bias towardsmetaphoric usage of motion/cause-motion lexicalitems shows just how prevalent the Event StructureMetaphor is, especially in the domain of economicswhere it is used to describe market fluctuations andpolicy decisions.Figure 5 shows the breakdown for each lexicalitem in the Cure frame.
Note that most of the fre-quently occurring verbs are strongly biased towardseither a literal or metaphoric usage.
Ease, for ex-ample, in all 81 of its uses describes the easing of anLexical Unit #MET #LITalleviate 8 0cure 7 3ease 81 0heal 3 0rehabilitate 1 0resuscitate 2 0treat 3 23Figure 5: The lexical units that evoke the Cure frameand each unit?s counts for metaphoric (#MET) andliteral (#LIT) usage.economic condition and not the easing of pain.
Treaton the other hand, is overwhelmingly biased towardsthe treating of physical and psychological disordersand is only rarely used for an abstract disorder.5 The ApproachAs has been discussed in this paper, there are atleast two factors that are useful in determiningwhether the verbal target of an utterance is beingused metaphorically:1.
The bias of the verb2.
The arguments of the verbal target in that utter-anceTo determine whether the arguments suggesta metaphoric or a literal interpretation, the sys-tem needs access to information about which con-stituents of the utterance correspond to the argu-ments of the verbal target.
The PropBank annota-tions fill this role in our system.
For each utterancethat is used for training or needs to be classified, thegold standard PropBank annotation is used to deter-mine the verbal target?s arguments.For every verbal target in question, we used thefollowing method to extract the types of its argu-ments:1.
Used PropBank to extract the target?s argu-ments.2.
For each argument, we extracted its head usingrules closely based on (Collins, 1999).44Feature Schema Example Instantiation Commentverb verb=treat The verbal targetARG0 TYPE uninstantiated ARG0 (Doctor role) not presentARG1 TYPE uninstantiated ARG1 (Patient role) not presentARG2 TYPE ARG2 TYPE=anemia The WordNet type is anemia.ARG3 TYPE ARG3 TYPE=drug The WordNet type is drug.Figure 6: The feature schemas used for classification.
The instantiated features are drawn from the sentenceThe drug is being used primarily to {treat} anemias.3.
If the head is a pronoun, use the pronoun type(without coreference resolution) as the type ofthe argument.4.
If the head is a named entity, use the Identi-finder tag as the type of the argument (BBNIdentifinder, 2004).5.
If neither, use the name of the head?s WordNetsynset as the type of the argument.Consider the sentence The drug is being used pri-marily to {treat} anemias.
The PropBank annota-tion of this sentence marks the drug as ARG3 andanemias as ARG2.
We turned this information intofeatures for the classifier as shown in Figure 6.The verb feature is intended to capture the biasof the verb.
The ARGX TYPE feature captures thetype of the arguments directly.
To measure the trade-offs between various combinations of features, werandomly partitioned the data set into a training set(65% of the data), a validation set (15% of the data),and a test set (20% of the data).6 Results6.1 Classifier ChoiceBecause of its ease of use and Java compatibility,we used an updated version of the Stanford condi-tional log linear (aka maxent) classifier written byDan Klein (Stanford Classifier, 2003).
Maxent clas-sifiers are designed to maximize the conditional loglikelihood of the training data where the conditionallikelihood of a particular class c on training examplei is computed as:1Zexp(fi ?
?c)Here Z is a normalizing factor, fi is the vector offeatures associated with example i and ?c is the vec-tor of weights associated with class c. Additionally,the Stanford classifier uses by default a Gaussianprior of 1 on the features, thus smoothing the fea-ture weights and helping prevent overfitting.6.2 BaselinesWe use two different baselines to assess perfor-mance.
They correspond to selecting the major-ity class of the training set overall or the major-ity class of verb specifically.
The strong bias to-ward metaphor is reflected in the overall baseline of93.80% for the validation set.
The verb baseline ishigher, 95.50% for the validation set, due to the pres-ence of words such as treat which are predominantlyliteral.6.3 Validation Set ResultsFigure 7 shows the performance of the classifier onthe feature sets described in the previous section.The overall and verb baselines are 605 and 616 outof 645 total examples in the validation set.The first feature set we experimented with wasjust the verb.
We then added each argument in turn;trying ARG0 (Feature Set 2), ARG1 (Feature Set 3),ARG2 (Feature Set 4) and ARG3 (Feature Set 5).Adding ARG1 gave the best performance gain.ARG1 corresponds to the semantic role of moverin most of PropBank annotations for motion-relatedverbs.
For example, stocks is labeled as ARG1 inboth Stocks fell 10 points and Stocks were beingthrown out of windows3.
Intuitively, the mover roleis highly informative in determining whether a mo-tion verb is being used metaphorically, thus it makessense that adding ARG1 added the single biggest3This is an actual sentence from the training set.45FSet Feature Schemas M L Total %Tot1 verb 599/605 20/40 619/645 95.972 verb, ARG0 TYPE 601/605 17/40 618/645 95.813 verb, ARG1 TYPE 602/605 19/40 621/645 96.284 verb, ARG2 TYPE 600/605 19/40 619/645 95.975 verb, ARG3 TYPE 599/605 20/40 619/645 95.976 verb, ARG1 TYPE, ARG3 TYPE 602/605 19/40 621/645 96.287 verb, ARG1 TYPE, ARG2 TYPE, ARG3 TYPE 601/605 18/40 619/645 95.978 verb, ARG0 TYPE, ARG1 TYPE, ARG2 TYPE 602/605 18/40 620/645 96.129 verb, ARG0 TYPE, ARG1 TYPE, ARG2 TYPE, ARG3 TYPE 602/605 17/40 619/645 95.97Figure 7: For each Feature Set, the feature schemas that define it, along with the ratio of correct to totalexamples on the validation set for metaphor (M), literal (L) and total (Total) is shown.jump in performance compared to the other argu-ments.Once we determined that ARG1 was the best ar-gument to add, we also experimented with combin-ing ARG1 with the other arguments.
Validation re-sults are shown for these other feature combinations(Feature Sets 6,7, 8 and 9)Using the best feature sets (Feature Sets 3,6), 621targets are correctly labeled by the classifier.
Theaccuracy is 96.98%, reducing error on the validationset by 40% and 17% over the baselines.6.4 Test Set ResultsWe retrained the classifier using Feature Set 3 overthe training and validation sets, then tested it on thetest set.
The overall and verb baselines are 800 and817 out of 861 total examples, respectively.
Theclassifier correctly labeled 819 targets in the test set.The results, broken down by frame, are shown inFigure 8.
The final accuracy of 95.12%, representsa reduction of error by 31% and 5% over the base-lines.6.5 DiscussionA comprehensive assessment of the classifier?sperformance requires a measure of interannotatoragreement.
Interannotator agreement represents aceiling on the performance that can be expected onthe classification task.
Due to the very high base-line, even rare disagreements by human annotatorsaffects the interpretation of the classifier?s perfor-mance.
Unfortunately, we did not have the resourcesavailable to redundantly annotate the corpus.We examined the 42 remaining errors and catego-rized them into four types:?
13 fixable errors?
27 errors caused by verbal biases?
2 errors caused by bias in the training setThe fixable errors are those that could be fixedgiven more experimentation with the feature sets andmore data.
Many of these errors are probably causedby the verbal bias, but a verbal bias that should notbe insurmountable (for example, 2 or 3 metaphor toeach 1 literal).The 27 errors caused by verbal biases are oneswhere the verb is so strongly biased to a particu-lar metaphoric class that it is unsurprising that a testexample of the opposite class was missed.
Verbslike treat (0 metaphoric to 20 literal) and lead (345metaphoric to 0 literal) are in this category.The two remaining errors are cases where the verbwas not present in the training data.7 Related WorkPrevious work on automated metaphor detectionincludes Fass (1991), Martin (1990), and Mason(2004).
Whereas our aim is to classify unseensentences as literal or metaphorical, these projectsaddress the related but distinct task of identifyingmetaphorical mappings.
All three use the selectionalpreferences of verbs to identify metaphors.
In lit-eral usage, the arguments that fill particular roles ofa verb are frequently of a common type.
For in-stance, in the MEDICAL domain, the object of the46Frame M L Total %Tot %OBL %VBLCause motion 78/78 1/10 79/88 89.77 88.64 88.64Cotheme 179/179 0/2 179/181 98.90 98.90 98.90Cure 26/30 3/3 29/33 87.88 90.91 90.91Motion directional 242/242 0/2 242/244 99.18 99.18 99.18Placing 176/181 13/25 189/206 91.75 87.86 91.26Self motion 87/90 14/19 101/109 92.66 82.57 91.74All Frames 788/800 31/61 819/861 95.12 92.92 94.89Figure 8: The results of the classifier on the test set, using Feature Set 6.
For each frame, the ratio of correctto total examples for metaphor (M), literal (L) and total (Total) is shown.
The total percent correct for theframe (%Tot), the overall baseline percentage (%OBL), and the verb baseline percentage (%VBL) are alsoshown.
The cumulative performance over all frames is located in the bottom row of the table.verb treat is usually a pathological state.
In the FI-NANCE domain, the object of treat is usually aneconomic problem.
This difference in selectionalpreference suggests metaphorical usage.
Further-more, it suggests a metaphorical mapping betweenhealth problems and economic problems.The systems described by Fass and Martin exhibitimpressive reasoning capabilities such as identify-ing novel metaphors, distinguishing metaphor frommetonymy, and interpreting some metaphorical sen-tences.
But they require hand-coded knowledgebases and thus have limited coverage and are dif-ficult to extend.
More similar to our efforts, Ma-son?s CorMet uses a corpus-based approach.
InCorMet, domains are characterized by certain key-words which are used to compile domain-specificcorpora from the internet.
Based on differences inselectional preferences between domains, CorMetseeks to identify metaphorical mappings betweenconcepts in those domains.One shortcoming of using syntactic argumentsis reflected by CorMet?s mistaken identification ofa mapping between institutions and liquids.
Thisarises from sentences like The company dissolvedand The acid dissolved the compound.
Such sen-tences suggest a mapping between the subjects inthe target domain, institutions, and the subjects insource domain, liquids.
Using semantic roles avoidsthis source of noise.
This is not to suggest that thesyntactic features are unimportant, indeed the selec-tional preferences determined by CorMet could beused to select which arguments to use for features inour classifier.Our approach considers each sentence in isola-tion.
However the distribution of metaphorical us-age is not uniform in the WSJ corpus (Martin,1994),.
It is therefore possible that the informationabout surrounding sentences would be useful in de-termining whether a usage is metaphorical.
CorMetincorporates context in a limited way, computinga confidence rating, based in part upon whether ametaphoric mapping co-occurs with others in a sys-tematic way.8 ConclusionMetaphors are a ubiquitous phenomenon in lan-guage, and our corpus analysis clearly bears this out.It is somewhat gratifying that with a judicious com-bination of the available wide-coverage resources(WordNet, FrameNet, PropBank) we were able tobuild classifiers that could outperform the baselineeven in the most skewed cases.
Our results show theutility of our approach and more generally the matu-rity of the current NLP technology to make progressin attacking the challenging and important problemof interpreting figurative language.However, this is only the first step.
As with allsemantic extraction methods and technologies, theproof of utility is not in how good the extractor isbut how much it helps in an actual task.
As faras we can tell, this problem remains open for theentire semantic parsing/role labeling/extraction fielddespite the flurry of activity in the last four years.
Inthe case of metaphor interpretation, we have someinitial encouragement from the results published by(Narayanan, 1997) and others.47Our classifier relies on PropBank senses, so wecan use the high performance classifiers availablefor PropBank.
The price is that we have to con-struct mappings from FrameNet frames to PropBanksenses.
However, this is a one-time effort pursuedby many groups, so this should not present a prob-lem to extending our approach to cover all framesand metaphors.
Additionally, we are in the processof linking the metaphor detector to a metaphor infer-ence system.
We hope to have initial results to reporton by conference time.ReferencesBBN Identifinder.
2004.http://www.bbn.com/for government customers/data indexing and mining/identifinder.html.Michael Collins.
1999.
Head-Driven Statistical Modelsof Natural Language Parsing.
Ph.D. thesis, Universityof Pennsylvania.Dan Fass.
1991.
Met*: a method for discriminatingmetonymy and metaphor by computer.
Comput.
Lin-guist., 17(1):49?90.Christine Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.Mark Johnson.
1987.
The Body in the Mind: The BodilyBasis of Meaning, Imagination and Reason.
Univer-sity of Chicago Press.Paul Kingsbury, Martha Palmer, and Mitchell Marcus.2002.
Adding semantic annotation to the penn tree-bank.
In Proceedings of the Human Language Tech-nology Conference.George Lakoff and Mark Johnson.
1980.
Metaphors WeLive By.
University of Chicago Press.George Lakoff and Mark Turner.
1989.
More Than CoolReason: A Field Guide to Poetic Metaphor.
Universityof Chicago Press.George Lakoff.
1994.
The contemporary theory ofmetaphor.
In Andrew Ortony, editor, Metaphor andThought.
Cambridge University Press.Ronald Langacker.
1987.
Foundations of CognitiveGrammar I: Theoretical Prerequisites.
Stanford Uni-versity Press.James Martin.
1990.
Computational Model of MetaphorInterpretation.
Academic Press.J.H.
Martin.
1994.
A corpus-based analysis of contexteffects on metaphor comprehension.
Technical report,Boulder: University of Colorado: Computer ScienceDepartment.Zachary J. Mason.
2004.
Cormet: a computational,corpus-based conventional metaphor extraction sys-tem.
Comput.
Linguist., 30(1):23?44.Srini Narayanan and Sanda Harabagiu.
2004.
Questionanswering based on semantic structures.
In Proceed-ings of the International Conference on ComputationalLinguistics.Srini Narayanan.
1997.
Knowledge-Based Action Rep-resentations for Metaphor and Aspect.
Ph.D. thesis,University of California at Berkeley.Steve Sinha and Srini Narayanan.
2005.
Model-basedanswer selection.
In Proceedings of the AAAI Work-shop on Inference for Textual Question Answering.Stanford Classifier.
2003.http://nlp.stanford.edu/software/classifier.shtml.48
