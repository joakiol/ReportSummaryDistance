AUTOMATED TRANSLATION AT GRENOBLE UNIVERSITYBernard Vauquois and Christian BoitetGroupe d'Etudes pour ia Traduction AutomatiqueBoite Postale 68Universit~ de Grenoble38402 Saint-Martin-d'H/~res, FranceINTRODUCTIONThe authors thank Dr. Slocum for the opportunity topresent the work on machine translation at Grenoble.The plan he has proposed for the contributions to thisspecial issue was certainly a very good starting point, as acommon frame to present various systems around theworld.It is, however, inevitable that we could not completelyfit into it, so that we have sometimes taken some libertyfor which we hope to be excused.1 PROJECT HISTORYI.I DATES AND FUNDING SOURCESFounded in 1972, GETA is one of the laboratories of theComputer Science Department at Grenoble University.From its inception it was supported by CNRS, the FrenchNational Center for Research, by means of associationcontracts renewed every four years, and by the Universi-ty, having the status of "University Research Team asso-ciated with CNRS".
Also, several projects have beenpartially supported by contracts from the Ministries ofDefense, Telecommunications, and Industry.Before that, in 1961, CNRS had created CETA(Centre d'Etudes pour la Traduction Automatique) as a"laboratoire propre", that is, a laboratory supported byCNRS funds and various contracts but not by the Univer-sity.From 1961 to 1971, CETA elaborated some basicsoftware tools for MT, and experimented with it mainlyon translation from Russian into French.
Some investi-gations were also carried out into the analysis of Germanand Japanese.
In 1971, a corpus including about400,000 running words had been translated from Russianinto French, after several years of development of thevarious grammars and dictionaries (the "lingware", so tospeak).The system was typically second generation: finite-state morphological analysis, augmented context-freesyntactic analysis, direct mapping into a dependencyanalysis, procedural semantic analysis (using a special-ized low-level programming language to transform treestructures) into an interlingua (the famous "languagepivot", or "pivot language"), lexical transfer, syntacticgeneration (using the same low-level tree-transformationlanguage), and morphological generation (beginning witha recursive top-down procedure applied to the tree to getthe correct order of the leaves, to be transformed intowords).Since 1972, another approach as been followed thatrelies more on the use of SLLPs (Specialized Languagesfor Linguistic Programming); that is, on procedural tech-niques like controlled production systems and heuristicprogramming.
Also, a main goal has been to design thebasic software and the various lingwares with a view tomultilingual translation.A completely integrated programming environment(ARIANE-78) has been developed and used to build avariety of linguistic models, in order to test the generalmultilingual design and the various facilities for lingwarepreparation, debugging, and actual use, as well as forhuman pre- and post-editing.1.2 LANGUAGES TRANSLATED; PROJECTAND SYSTEM SIZESThe first three subsections below describe the kinds ofexperiments performed at GETA.1.2.1 WRITING OF VERY REDUCED SCALE MODELSThe writing of very reduced scale models is mainlyoriented to training researchers in the methodology ofMT and the use of the various SLLPs available underARIANE-78.As an example, Feng Zhi Wei (ISTIC, Beijing) haswritten a small multilingual translation system fromChinese into Japanese, French, English, German, andRussian, that (of course) uses the same analysis modulesfor all language pairs.Copyright1985 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted provided thatthe copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
To copyotherwise, or to republish, requires a fee and/or specific permission.0362-613X/85/010028-36503.0028 Computational Linguistics, Volume 11, Number 1, January-March 1985Bernard Vauquois and Christian Boitet Automated Translation at Grenoble UniversityA transfer from English (using a bigger model ofEnglish analysis) to Chinese and a generation of Chinesehas been produced by Ping Yang (ISTIC).
In a similarway, using the same analysis of English, Professor Jun-Ichi Tsujii (of Kyoto University) conducted an exper-iment into English-Japanese translation.1.2.2 CONSTRUCTION OF SMALL SCALE MODELSThe construction of small scale models - that is, withsmall dictionaries but medium size grammars - has beendone for feasibility studies and training.A French-English system was constructed by J,Ph.Guilbaud and M. Dymetman i  the framework of a feasi-bility study for the Ministry of Telecommunicationsduring 1981.
This system has recently been reused toimplement a rough "self grading" technique to be used inconnection with a translator work station (A. Melby,BYU).Another example is the development of a German-French system, using the same generation as theRussian-French system (see below).
This work wasstarted around 1979, with J. Ph.
Guilbaud of GETA incharge of morphological analysis and transfer, andProfessor Stahl (Paris) in charge of structural analysis.In cooperation with IFCI (Institut de Formation et deConseil en Informatique, Grenoble), another system,BEX-FEX, has been developed for teaching purposes (B.Roudaud, S. Chappuy, and E. Guilbaud).
The analysis isa simplified version of the IN1 analysis (see below), andthe dictionaries are purposely very small (500 lexicalunits for each language).In order to give an idea of the complexity of such asystem, rather than measure the number of grammaticalrules, because they can be very simple or very complex,we measured the number of source lines of the grammarswritten in the SLLPs ATEF, ROBRA, or SYGMOR.BEX-FEX contains420 lines for the morphological nalysis2500 lines for the structural analysis300 lines for the structural transfer1000 lines for the syntactic generation100 lines for the morphological generationAlso in connection with IFCI, a feasibility study for anEnglish-Arabic system was started in 1984.!.2.3 BUILDING OF LARGE SCALE SYSTEMSLarge scale systems have been built at the level of labo-ratory prototypes.The largest system with regard to the vocabulary, andthe most experimented with, is the Russian-Frenchsystem RUB-FRB.
According to an estimate made in June1984, the dictionaries contain 7000 Russian lexical units(about 17000 words) and 5600 French lexical units(about 16000 words).By "words", we mean here lenuna, that is, a normalform of an occurrence, usually used to identify an item ina "natural" dictionary.
The various grammars contain1350 lines for the morphological nalysis3100 lines for the structural analysis380 lines for the structural transfer930 lines for the syntactic generation120 lines for the morphological generationSince 1983 this system has been used to test an exper-imental "translation unit" using a production-orientedsubset of ARIANE-78, PROTRA.
Photocopies of techni-cal abstracts from the Referativnyij Zhurnal are regularlyreceived by the unit, manually inputted, checked fortyping errors (by using the morphological analyzer),machine translated, manually revised (using a multiwin-dow editor), and sent back.
The revision effort includesthe search for the source of errors encountered.As it is, and taking into account hat manual inputrepresents the major bottleneck, around 50 to 60abstracts per month (5000 to 7500 running words) areprocessed.
Fields covered include space sciences andmetallurgy.Next comes the English-Malay system (IN1-BM1).
In1979, a cooperative project with USM (Universti SainsMalaysia, Penang) was launched.
The aim of the projectis to produce an English-Malay system for the translationof teaching material in technical fields.
The level of labo-ratory prototype should be attained by the end of 1984,when systematic tests will be performed.The analysis part has been jointly developed by GETAand USM.
It is the same that was mentioned earlier:having initially been started for this project, it has beenreused for experiments of translation into otherlanguages.
As far as size is concerned, the dictionariescontain 1800 English lexical units (about 3000 words)and 1800 Malay lexical units (about 2700 words).
Thevarious grammars contain420 lines for the morphological nalysis5000 lines for the structural analysis600 lines for the structural transfer1500 lines for the syntactic generation670 lines for the morphological generationMore recently, a similar project was started withseveral Universities of Thailand (Chulalongkorn andRakhamhaeng in Bangkok, Prince of Songkla in Had-Yai) for translation from English into Thai.Last but not least, ARIANE-78 and the related linguis-tic techniques have been selected as the basis for anindustrial development, in the framework of the FrenchNational Project.
After a preparation phase in 1982-83(ESOPE project), this project was formally launched inlate 1983, with a group of private companies around SG2as industrial partners.1.2.4 PROJECT SIZESAS far as the number of people "engaged in the project"is concerned, no easy answer may be given, because ofthe multiplicity of the experiments.
GETA itself has acore of about ten people engaged in software or ling-ware, plus a varying number of students, not workingComputational Linguistics, Volume 11, Number 1, January-March 1985 29Bernard Vauquois and Christian Boitet Automated Translation at Grenoble Universitydirectly on MT, and some visitors.
The core includes twoprofessors ant\] eight research engineers and linguistics(supported by the CNRS), four of them constituting theRussian-French team.For the National Project, about nine or ten peoplefrom GETA or IFCI are working part or full time, whileabout the same number, coming from the industrial part-ners, are working full time (as of mid-1984).2 APPLICATION ENVIRONMENT2.1 PRE-/POST-EDITINGPre-editing is optional.
In our terminology, pre-editingmeans that some conventional marks are inserted in theinput text, which is not otherwise modified, by replacingwords with "synonyms" or by rewriting parts to changethe syntactical structure.
When pre-editing is used, theinserted marks refer to some lexical ambiguity (for exam-ple, ambiguity between noun and verb), or indicate thescope of a coordination, the antecedent of a relativepronoun, etc.The structural analysis grammars are then organized insuch a way that these marks, if any, are used first by thedisambiguation modules.
Until now, this technique hasonly been employed in the analysis of Portuguese (POR),by P. Daun-Fraga.Post-editing is necessary in all cases where high quali-ty of the output must be attained, as opposed to situ-ations where information gathering is the main purpose.ARIANE-78 contains a subenvironment for post-editing(REVISION), under which the revisor may simply use themultiwindow editor, or call the THAM subsystem, underwhich special tools are offered for manipulating andaccessing a terminology file.2.2 HUMAN INTERACTIONDuring translation, there is normally no human inter-action, with the possible exception of morphologicalanalysis, where the operator may correct spelling errors,or insert items in dynamic dictionaries.
We don't normal-ly operate this way.Of course, for debugging purposes, the system mayoperate in a step-by-step way.2.3 INTEGRATION OF THE SYSTEMARIANE-78 is a complete integrated environment forlinguistic programming, debugging, and actual operation.3 GENERAL TRANSLATION APPROACHThe method followed in all current systems written inARIANE-78 is based on a combination of transfer andinterlingua techniques.
The process of translation isdivided into three phases: analysis, transfer, and gener-"ation.
The word "synthesis" might be more appropriate,but "generation", as in "code generation" for compilers,is used.3.2 ANALYSISThis phase is performed by a sequence of two separatesub-phases: morphological analysis and structural analy-sis.3.1.1 MORPHOLOGICAL ANALYSISThe input is the source text, in ARIANE-78's internaltranscription, with optional pre-editing marks, SCRIPTformatting commands, and special occurrences to standfor the hors-texte (figures, charts, equations, and otheruntranslatable material).The output is a "decorated" (annotated) AND/ORtree structure.
The root identifies the text, and its deco-ration contains ULTXT as value of the UL (lexical unit)"variable" (property, in other terminologies).The nodes directly under the root correspond to thesentences, and contain the lexical unit ULFRA (FRA forphrase, meaning 'sentence' in French).The nodes at level 2, under the sentence nodes, corre-spond to the occurrences (running words), and containthe lexical unit ULOCC.Nodes at level 3 correspond to the result(s) of themorphological nalysis.
If a given result is "simple", thenode contains the corresponding lexical unit, and allgrammatical properties, as computed by the grammar.
If,on the other hand, a result corresponds to the analysis ofthe occurrence as a compound word, the node at level 3contains the lexical unit ULMCP, and dominates asequence of nodes containing the result of the morpho-logical analysis of the elements of the compound.The information contained in a solution node (alwaysa leaf) is of the following types:?
the lexical reference, or lexieai unit - a stnng;?
grammatical information computed by the grammarfrom the information on the segments (affixes, root),coming from the dictionaries, such as derivation status,negation status, syntactic category and subcategory,number, tense, person, etc.;?
the syntactic properties of the lexical unit (e.g., thesyntactic valencies of a verb or an adjective), whichcome from the dictionaries;?
the semantic properties of the lexical unit (semanticfeatures and valencies), which also come from thedictionaries.3.1.2 STRUCTURAL ANALYSISThe goal of the structural analysis phase is to reach alevel of interpretation that is far enough removed fromthe morphological and syntactic peculiarities ofexpression in the considered natural language to repre-sent in the same way various expressions having the same"meaning".
Furthermore, the interface structure (theresult of the structural analysis) keeps a trace of variousmore "superficial" levels.To be more concrete, the interface structure of a textis again a decorated tree structure, with the ULTXT and30 Computational Linguistics, Volume 11, Number 1, January-March 1985Bernard Vauquois and Christian Boitet Automated Translation at Grenoble UniversityULFRA nodes at levels 0 and 1.
In a subtree correspond-ing to a sentence,?
the geometry of the tree structure represents only abracketing of the sentence in terms of syntagmaticclasses (non-terminal categories) such as verbal clause,noun phrase, adjectival phrase, etc.?
the relations between words or groups of words areexpressed by linguistic attributes (called variables inARIANE-78's terminology), such as syntactic function(SF), logical relation (RL), or semantic relation (RS).The syntactic functions may be "subject of a verb","attribute of the subject", "attribute of the object","modifier of a clause", etc.
The logical relation variableexpresses the relations between a predicate (predicativelexical unit such as a verb or certain type of adjective)and its arguments.
For example, in the following utter-ances, the lexical units COMPOUND and CARBON are,respectively, argument 0 and 1 of the predicative lexicalunit INCLUDE.The COMPOUND INCLUDES CARBON...CARBON is INCLUDED in the COMPOUNDThe INCLUSION of CARBON in the COMPOUNDArguments of predicates are sometimes elsewherecalled inner cases.
When a word or a group of words isrelated to a predicative unit, without being one of itsarguments, we express this relation by some value of thesemantic relation property.
This is the case for circum-stantial complements ( ometimes known as outer cases).Possible values of RS include cause, condition, conse-quence, manner, quantification, etc.Many other properties are contained in the nodes ofthe structure.
Some are only ,"traces", that is, surfacevariables uch as number or gender.
Others are of higherlevel, for example the determination or actualizationproperties.As the units of translation are not restricted to besentences, but may well include several sentences orparagraphs, it is possible to use the available context tosolve anaphora, in case no suitable candidate is found inthe sentence.
The solution is expressed by copying someof the information relative to the referred element ontothe node representing the anaphoric element.
This nodehas the "reference" property set to the adequate value,as well as the "representative" syntactic ategory.3.2 TRANSFERThe transfer is also performed in two sequential sub-phases: lexical transfer and structural transfer.3.2.1 LEXICAL TRANSFERDuring this step, target language lexical units are substi-tuted for the source language lexical units.
Several casesmust be considered.?
simple-to-simple substitution?
simple-to-complex substitution (a single source unit istranslated by several target units, e.g., avec -*.
by meansof)?
complex-to-simple or complex-to-complex substitution(e.g., computer  science ~ informat ique,  let .
.
.
knowinformer) .Moreover, the ~election of an appropriate substitutionfor a given lexical unit may be conditional.
The condi-tion may be local, that is, it bears on the properties of thenode under consideration (and perhaps some immediateneighbors), or global, in which case a wider context mustbe examined.Let us give two examples.?
syntactic valency: the English verb look has at least fourvalues for the object valency (for argument 1), namely,at, for ,  like, after.
According to the syntactic structurethat has been built, only one possibility remains afteranalysis (on the node containing look).
We may thenexpress the conditional substitution by an item in aTRANSF dictionary of the following (simplified) form:LOOK : if VALI=AT then 'REGARDER'elseif VALI=FOR then 'CHERCHER'elseif VALI=LIKE then 'S/OCCUPER'else 'RESSEMBLER'?
presence or absence of an argument: the usual trans-lation of give is donner  in French; however, if there is nofirst argument explicit in the sentence (e.g., John wasgiven a book) ,  the translation of give may be recevoir,with the indication that the third argument of givebecomes the first argument of recevoir (e.g., Jean a recuon livre).Basically, the TRANSF SLLP provides the means towrite bilingual multi-choice dictionaries.
Each node ofthe input tree is replaced by a subtree in the output tree.This subtree may be selected from several possibilities,according to the evaluation of a predicate on the attri-butes of the input node and its immediate neighbors.In simple cases, the selected subtree is reduced to onenode.
In more complex cases, the selected subtree may:?
give several possible equivalents, for further testing insubsequent phases, or production of a multiple equiv-alent in the final translation (e.g., process ~ processus orprocede from Engfish into French).?
express the prediction that the considered element maybe part of a complex expression in the source language(e.g., let .
.
.
know) .
In this case, the subtree willcontain nodes describing the type of complex predicted,the other elements of the complex, and the translationof the complex (which may again be simple orcomplex).
It will then be one of the tasks of the struc-tural transfer to confirm or disconfirm this prediction,by using the whole available context, and Co take appro-priate action; use the translation of the complex if"yes", leave the simple translation if "no".Computational Linguistics, Volume 11, Number 1, January-March 1985 31Bernard Vauquois and Christian Boitet Automated Translation at Grenoble UniversityThis organization has been consciously designed inorder to limit tlhe cost of indexing in dictionaries: the lexi-cographers don't have to write complex tree-transforma-tion rules.
Instead, they write (static) subtrees ofwell-defined (sort of and/or) forms, in which some ofthe information is later used as an indirect call to trans-formational procedures written by specialized computa-tional linguists in the structural transfer grammar.3.2.2 STRUCTURAL TRANSFERWe have already begun to explain the role of the struc-tural transfer.?
It must finish a part of the lexical transfer, by usingthe appropriate context to choose between severalremaining equivalents (e.g., on the basis of the seman-tic features of other elements in the clause), and tohandle the translation of complex expressions asexplained above.?
If there is no satisfactory universal representation ofsome phenomenon, the corresponding attributes of thetarget language are computed in a eontrastive way.This is now the case for aspect, tense, and modality ofverbs, as well as for determination of noun phrases.?
Finally, it may be necessary to perform true structuraltransfer operations, although this seldom occurs.
Inpractice, we use this as a "safety net", in cases wherethe higher levels of interpretation have not beencomputed by the analysis on some part of the text, sothat a mapping between low-level structures is betterthan nothing.3.3 GENERATIONGeneration too is composed of syntactic followed bymorphological generation.3.3.1 SYNTACTIC GENERATIONNormally, the purpose of syntactic generation is tocompute a surface syntactic structure from the interfacestructures.
Starting with the semantic and logicalrelations, the syntactic functions have to be determinedfirst, and then the syntagmatic classes are computed, in atop-down recursive manner.The choice between various syntactic structures maybe guided by the values of the low-level attributes, astransferred or transformed by the transfer phase.
Forinstance, we may give priority to a passive constructionover an active construction, if the (target) interfacestructure contains the indication of passive.
But thispassive mark may well have been computed by the trans-fer (e.g., for an impersonal construction i French prefer-ably translated by a passive in English).Syntactic transfer will also be used to compute thecorrect order of the elements in the final translation, aswell as all low-level information ecessary for morpho-logical generation, such as number, person, tense, gender,etc.3.3.2 MORPHOLOGICAL GENERATIONThe left-to-fight sequence of the leaves of the tree result-ing from syntactic generation is the input to morphologi-cal generation (written in SYGMOR).The grammar directs the construction of the outputoccurrence(s) by testing the values of the attributes ofthe current node (and some other bounded context) andreferring to dictionaries of strings, accessed by the UL orother variables, to get the various morphs to be combined(root, prefix, affixes, suffix .
.
.
.
).Also, purely morphological variations are handled byusing string-transformation functions (e.g., elision inFrench, or generation of upper/lower case codes).4 LINGUISTIC TECHNIQUESBasically, every linguistic phase is constructed by succes-sively writing two different sets of descriptions.The first is the analog of the set of specifications for aconventional program.
We call it the static description ofthe desired correspondence, which is usually many-to-many.B.
Vauquois and S. Chappuy have developed aformalism called static grammars (Chappuy 1983), notunlike M. Kay's unification grammar formalism but suit-able for the kind of structures we are accustomed tomanipulate.A static grammar describes the correspondencebetween the strings of a natural anguage and their inter-face structures.
Such a description is neutral with respectto analysis and generation, and does not express anyparticular strategy for computing the correspondence.We have yet to devise a similar formalism to describethe correspondence b tween interface structures of twogiven natural anguages.The second part of the work consists in writing anddebugging the dynamic (procedural) grammars in theappropriate SLLPs (ATEF and ROBRA for analysis,ROBRA and SYGMOR for generation).
In the mostrecent applications, the analysis and generation structuralgrammars are, in effect, (manually) generated from thestatic grammar of the considered language.
Moreover, itis possible to construct several dynamic grammars refer-ring to the same static grammar, in order to experimentwith different strategies, trying to make the best of thevarious possibilities of heuristic programming available inthe SLLPs.4.1 LOW LEVELMorphological ambiguities are detected by the morpho-logical analysis phase and handed over to the structuralanalysis phase.
If the analysis is successful, these ambi-guities are solved in the process (e.g., noun/verb, etc.
).Some polysemic words may be handled .as well, if thesemantic features associated to the different meaningsare distinct enough to be separated by the agreementconditions incorporated in the grammar rules.32 Computational Linguistics, Volume 11, Number 1, January-March 1985Bernard Vauquois and Christian Boitet Automated Translation at Grenoble University4.2 HIGH LEVELAlthough the units of translation are broader thansentences, the bulk of analysis and generation operatesessentially at the sentence level.
In all current applica-tions, there is no discourse analysis leading to somerepresentation of the "hypersyntax" or "hyperse-mantics" of the complete unit.Nevertheless, the possibility to use a wider context isuseful in some cases.
We have already mentionedanaphoric resolution in anal3~sis.
During transfer orgeneration, it also happens that a sentence of the sourcetext is segmented into several shorter sentences, for styl-istic reasons.All dynamic grammars are written by using productionrules (not phrase structure rules) of the various kindsavailable in the SLLPs.
An important feature ofARIANE-78 is that all steps (from morphological nalysisto morphological generation) may be ultimately consid-ered as describing transducers, not analyzers.5 COMPUTATIONAL TECHNIQUES5.1 DICTIONARIESDictionaries are written in the SLLPs, and then compiledinto some internal representation that includes a fastaccess method.
At execution time, the dictionaries residein virtual memory.ATEF dictionaries use a two-step hash-coding scheme,followed by an ordered-table r presentation (for morphsof the same length sharing the same initial or final char-acter).
Access to a given item involves less than 100machine operations.TRANSF dictionaries use a quasi-perfect hash-codingscheme.
SYGMOR dictionary access relies on dichotomyfor the lexical units and on sequential search for/othervariables.
But, then, the latter dictionaries are alwayssmall and of bounded size anyway: they contain theprefixes, affixes, and endings.As a matter of fact, due to the compactness of theinternal coding and to the speed of the access methods,dictionaries don't raise any computational problem.5.2 GRAMMARSIn ATEF, the grammar describes a finite-state non-deter-ministic transducer.
It is implicitly divided into as manysubgrammars as "morphological formats" (classes).Each item in a dictionary has such a format, whichcontains ome static grammatical information, and is alsoreferenced in the l.h.s, of one of several rules, which willbe called in a non-deterministic way.The underlying mechanism for handling non-determin-ism is simple backtrack.
However, heuristic functionsmay be called by the rules.
Their effect is to "prune" thesearch space in several predetermined ways.
Forinstance, one of these functions says something like: ifthe application of the current rule leads to some solution,then don't compute the solutions that might be obtainedfrom segments of strictly shorter length than the currentone beginning at the same character.
Another heuristicfunction is used to simply state that, if the rule leads to asolution, this solution should be the only one; previouslycomputed solutions are discarded, and further possibil-ities are not examined.In ROBRA, there are several levels of control.
First, agiven transformational system (TS) has a given store oftransformational rules (TR), which operate by substi-tution.
Then there is a collection of grammars (TG), eachmade of an ordered subset of the TRs.
The order is localto the grammar, and is interpreted as a priority order.Each TR may contain a recursive call to a (sub)TG or toa transformational subsystem (sub-TS).
The top level ofcontrol corresponds to the TS (and its sub-TSs), and isdescribed by means of a control graph (CG).
The nodesof the CG are the TGs, and a special "exit grammar"(&NUL).
Arcs bear conditions of the same type as l.h.s.of rules.ROBRA's interpreter submits the input tree to theinitial grammar of the considered (sub)TS, and uses abuilt-in back-tracking mechanism to find the first pathleading from this initial node to the next node, therebyapplying the TGs found in the nodes, and traversing thearcs only if the attached conditions are verified by thecurrent ree.
In case of success, the result is the tree thatreaches &NUL.
In case of failure, the output is set equalto the input.A "simple" execution of a given TG is carried out intwo steps.
First, a parallel application of the TRs of theTG is performed, by selecting the maximal (according tosome parameters) family of non-overlapping occurrencesof rule schemas (l.h.s.)
and applying the correspondingrules.
Then, the recursive calls, if any, are executed, bysubmitting the appropriate subtrees to the called sub-TGor sub-TS.The execution of a TG in " exhaustive" mode consistsin iterating simple executions of this TG until no rule isapplicable any more.
In "controlled" mode, a markingalgorithm is used in order to strictly diminish the numberof possible occurrences of rules at each iteration, ensur-ing termination of the process.
Hence, it is possible forthe compiler to statically detect possible sources of unde-cidability, just by checking the modes of the TGs, testingfor loops in the CG, and verifying a simply condition onthe form of the recursive calls.This kind of organization makes it possible to use text-driven strategies, which will operate differently on differ-ent parts of the (tree corresponding to the) unit oftranslation.The case of SYGMOR is more simple, because theunderlying model is a finite-state deterministic transduc-er.
For each new node (leaf of the input tree), the inter-preter selects the first rtile whose l.h.s, is verified andexecutes it.
Then, it uses the control part of the rule,Computational Linguistics, Volume 11, Number 1, January-March 1985 33Bernard Vauquois and Christian Boitetwhich consists of an ordered sequence of rules to beapplied, some of which may be optional.
Usually,SYGMOR grammars are fairly small.5.3 EFFICIENCYThe basic software is programmed at various levels.
Thecompilers and interpreters of the SLLPs are written inassembler or PL360, the monitor and the macro for theeditor (XEDIT) in EXEC/XEDIT (IBM's VM/CMS's shelllanguage).
We can say something about efficiency ontwo levels.First, the efficiency of the programming itself.
Appli-cations such as Russian-French use roughly 1 to1.5 Mipw (million instructions per word translated) ofVCPU (virtual CPU), measured on a 4321, a 370, a 3081,or an Amdahl.
More than 88% of this is used byROBRA's pattern-matching mechanism, and less than10% by the "dictionary phases" (morphological nalysisand generation, lexical transfer).
Translation isperformed using 2.5 Mbytes of virtual memory, withoutany access to secondary storage during processing itself.Recently, we made a comparison with Kyoto Universi-ty's system, whose design is similar to ARIANE-78's.
Inparticular, the bulk of the computing time is used byGRADE, a SLLP of the ROBRA family.
The system isprogrammed in UT-LISP and runs on a FACOM computer(Fujitsu), which is IBM-compatible and very fast (20Mips).It turns out that this MT system uses roughly 100times more Mipw than ARIANE-78, and 40 times morespace.
Taking into account the fact that there is only4 Mbytes of virtual memory (divided by 2 for thepurpose of garbage collection), that the garbage collectorgobbles up 40% of the VCPU, and that the runtimeaccess to the 30 to 40 Mbytes of secondary storage(holding the lingware) takes 20% more, we end up withthe net result that a LISP implementation (of this type ofsystem) is 40 times more voracious in computer time andspace than a low-level implementation.Of course, the amount of programming and mainte-nance effort is higher for the latter type of implementa-tion.
At this point, it is worth remembering that inFrance, contrary to many countries, research labs usuallyhave access to severely limited computer esources, andmust pay for it.
Natural Language Processing is verymuch an experimental science, and the designers ofARIANE-78 have felt they couldn't provide the linguistswith a system they might use for experimentations onlyabout one or two weeks a year because of financialconstraints.One possible reward of this painful kind of implemen-tation is that it seems possible to run the complete systemon the PC/XT370, according to the specifications anddescriptions published in Europe.A second level of comparison is by the computationalmethods used.
For that, we may use old data from theAutomated Translation at Grenoble Universityformer CETA system (before 1971), or data from currentsystems uch as METAL (University of Texas at Austin),or KATE (KDD, Tokyo), based on augmented context-free formalisms.
From some demonstrations and privatecommunications, we got again the figure of 1 to1.5 Mipw, for systems written in LISP, and about40 times less for assembler-level implementation of thebasic software.Our (perhaps too hasty) conclusion is that pattern-matching-based techniques are roughly 40 times costlier inVCPU than classical combinatorial methods (ifprogrammed in a smart way, of course).However, we have tried the latter kind of approach inthe past, and ended up finding it quite difficult to main-tain a large scale system and to raise its overall quality.See Section 7 for further comments.6 PRACTICAL EXPERIENCE; EXPERIMENTAL RESULTS6.1 COST OF SYSTEM MAINTENANCE AND EXTENSIONThis cost is quite low, in terms of compute resources andof human effort.
The compilers are quite efficient, thestructure of dictionary and annex tools is designed tosimplify indexing and correcting, and the modular char-acter of the grammars makes it quite easy to modify anddebug them.6.2 HOW IS TESTING PERFORMED?Take the Russian-French application as an example.
Fortesting, we use a set of corpora we retranslate ach timea significant set of modifications has been incorporatedin the lingware, and of course we translate new corporathat have just been inputted and checked for spellingerrors.
We then compare old and new translations of thefirst set, and revise the second.6.3 WHAT IS MEASURED?6.3.1 SPEEDAs mentioned earlier, we measure the VCPU time anddeduce from it an estimate in terms of Mipw, which hasproven to be quite stable over a variety of machines.Due to the differences in real memory size and process-ing speed, the real time (even in a mono-user situation)may lay anywhere from 100 words per hour to 5 wordsper second.6.3.2 QUALITYThis is a difficult thing to measure.
During revision, wedo such a qualitative valuation, by detecting all trans-lation errors and trying to find their origin, hence theirgravity.However, we would prefer to simply measure the timefor human revision (without error hunting), as comparedwith the time for human revision of an average humanrough translation of the same text.
This kind of exper-iment has yet to be performed in a meaningful way.34 Computational Linguistics, Volume 11, Number 1, January-March 1985Bernard Vauquois and Christian Boitet6.4 COST EFFECTIVENESS, SUBJECTIVE FACTORSThis has to be measured in some real situation, as saidearlier.
We strongly hope that the setting of the NationalProject will allow that kind of measurement to take placein a systematic way.7 ARGUMENTS RE CHOSEN TECHNIQUES7.1 AGAINST ALTERNATIVE METHODS7.1.1 INTERLINGUAFirst of all, we have tried an approximation of the inter-lingua ("pivot") approach, and found it wanting.
In theformer CETA system, the pivot representation was of ahybrid sort, using as vocabulary the lexical units of agiven natural language, and as relations so-called"universals" corresponding to our current logical andsemantic relations, plus abstract features uch as seman-tic markers, abstract ime and aspect, and so on.
Theproblem here is threefold.?
It is very difficult to design such a pivot in the firstplace, and ever more so if the vocabulary must also beindependent of any particular natural anguage.?
The absence of surface-level information makes itimpossible to use contrastive knowledge of twolanguages to guide the choice between several possibleparaphrases at generation time.?
If the high-level representation cannot be computed onpart of the unit of translation, the whole unit gets norepresentation, and hence no translation, or a word-by-word translation.
This is already bad enough at thesentence level, and quite insufferable if the units arelarger, in order to access a bigger context.7.1.2 PS-RULESPhrase structure (PS) grammars don't seem adequate forour purposes, even with all (not so recent) additions andniceties such as attributes, validation/invalidationbetween rules, attached transformations, etc.
This ismainly so because the structures associated with thestrings are grammar-dependent, al hough they should belanguage-dependent invariants.Another problem comes from the monolithic aspect ofsuch grammars, which makes them very difficult and ulti-mately impossible to understand and modify, althougheverything seems right at the beginning, with a fewhundred rules.
Stratification of the grammar in theMETAL sense is just a device allowing conservation ofresults obtained in simple cases while rules are added totake care of more complex situations.
For the latter, thegrammar is just the collection of all rules, with no modu-larity.7.1.3 PURELY COMBINATORIAL METHODSAmbiguity is a fundamental problem in NaturalLanguage Processing.
Combinatorial methods tend toAutomated Translation at Grenoble Universitycompute all possibilities, perhaps weighting them, and tofilter out the first one, the first N ones, or all of them.No heuristic programming is possible.If more than one result of analysis (or transfer) isproduced, the source of the ambiguity is lost, so that thesystem must produce several distinct translations for theunit.
Again, this is difficult to accept at the sentencelevel, and certainly unacceptable at the paragraph level.7.2 FOR CHOSEN METHODS7.2.1 CONSTRASTIVITY AND TRANSFER APPROACHIf we are some day to attain the level of performance ofan average or good translator, it is unavoidable to some-times rely on "rules of thumb", which use surface-levelinformation, and embody some contrastive knowledge ofthe languages at hand.Moreover, if the units of translation grow larger, theprobability that some part cannot be completely analyzedat the most abstract levels of interpretation approachescertainty.Hence, we feel that the use of one (and not several)so-called "multilevel structure" for representing each unitis appropriate.
As a matter of fact, we consider such astructure as a generator of the various structures thathave been implicitly computed at each level of interpreta-tion.This technique may be compared with the"blackboard" technique of some AI systems.
Duringanalysis, the different levels of linguistic knowledge areused in a cooperative way, and not sequentially, as inprevious ystems.For example, some semantic information may be usedto disambiguate at the syntactic level, as in the ?ollowingsentences:John drank a bottle of beer.John broke a bottle of beer.7.2.2 TRANSDUCERS RATHER THAN ANALYZERSAlthough procedural programming is notoriously moredifficult than writing a collection of static rules used by astandard algorithm, leading to a yes or no answer, weconsider it a lot better in the situation of incomplete andfuzzy knowledge ncountered in MT.
It happens that thesame position has recently gained ground in AI, with theconstruction of "expert systems" that embody a lot ofknowledge in their control and domain-specific heuristics.In our case, this amounts to using our SLLPs for"language ngineering", in much the same way as usualprogramming languages are used for software engineer-ing.
Starting from a kind of functional specification(expressed by means of static grammars), the computa-tional linguist constructs a corresponding transducer inthe time-honoured way of top-down decomposition andstep-wise refinement.Computational Linguistics, Volume I 1, Number 1, January-March 1985 35Bernard Vauquois and Christian Boitet Automated Translation at Grenoble University7.2.3 TEXT-DRIVEN HEURISTIC PROGRAMMINGHeurist ic programming and text-dr iven strategies eemmore adequate than the use of a very complex grammar,whose rules are all tried, even in simple cases.
Exper-iments have show that the flow of control  ( from TG toTG) is significantly different on different parts (subtrees)of the translation units.7.2.4 FAIL-SOKI" MECHANISMSIn the setting of second-generat ion systems, based onimplicit rathe S than explicit understanding, a parallel canbe made with compilers for programming languages.
Wedon' t  want  our "supercompi lers"  (for natural  language,that is) to stop and produce nothing if they encounter  ani l l - formed clause somewhere in the unit of translation.Rather,  we want them to produce the best translat ionthey can, under all c ircumstances, annotat ing it withspecial marks, analogous to error and warning messages,to  be used later during the post-edit ing and technicalrevision of the document.The "safety net"  made of the multipl icity of levels ofinterpretat ion available on the same structure makes itpossible to use a broad spectrum between high-level andword-by-word  translation.8 FUTURE DIRECTIONS8.1 APPLICATION PLANSImmediate appl icat ion plans are all essential ly those ofthe French Nat ional  Project.
As first target, some kindof aircraft manuals have been selected for translat ionfrom French into English.
Computer  manuals to betranslated from English into French may follow.We also hope to develop current cooperat ive ffortsand initiate new ones.8.2 RESEARCH PLANSLexical knowledge processing is one of the most impor-tant research topics, from a practical point of view.
Weaim at designing a kind of " integrated ict ionary"  wherethe "coded"  and "natura l"  aspects are mixed.
Suchdictionaries could be used as reference or interface struc-tures, e.g., to generate coded dictionaries in dif ferentSLLPs for various steps of MT, or for other tasks, such asspell ing correction, etc.Grammat ica l  knowledge processing is being investi-gated.
The formalism of static grammars is being ref inedand exper imented with for the str ing-to-tree correspond-ences, and a small team is currently designing a set ofsoftware tools to handle a data base of static grammars.The formal ism should also be extended to t ree-to-treecorrespondences.
Many useful ideas can be taken overfrom current work on specif ication, proof,  and val idationof programming languages.A promising topic is the introduct ion of expert  systemscomponents into second-generat ion MT systems in orderto add some level of "expl icit  understanding" in the formof domain-specif ic  "extral inguist ic knowledge"  andtypology-specif ic  "metal inguist ic knowledge".Research on better data-  and control-structures foradequate SLLPs has been carded out.
It should becont inued and exper imented with.A c KNOWLEDGMENTSWe thank the referee for helping us remove some linguis-tic bugs from this paper,  and for indicating some pointsthat needed clarif ication.
We hope we have provided abetter  explanat ion of these.REFERENCESBachut, D. and Verastegui, N. 1984 Software Tools for the Environ-ment of a Computer-Aided Translation System.
Proceedings offCOL1NG-84.
Stanford, California.Boitet, C. 1976 Un essai de rrponse/l quelques questions throriques etpratiques lires A la Traduction Automatique.
Drfinition d'unsystrme prototype.
Thrse d'Etat.
Grenoble.Boitet, C. 1984 Research and Development on MT and Related Tech-niques at Grenoble University (GETA).
Lugano Tutorial onMachine Translation.Boitet, C. and Gerber, R. 1984 Expert Systems and Other New Tech-niques in MT.
Proceedings of COLING-84.
Stanford, California.Boitet, C~; Guillaume, P.; and Qurzel-Ambrunaz, M. 1978 Manipu-lation d'arborescences t parallrlisme: le syst~me ROBRA.Proceedings of COLING- 78.
Bergen.Boitet, C.; Guillaume, P.; and Qurzel-Ambrunaz, M. 1982ARIANE-78: an Integrated Environment for Automated Translationand Human Revision.
Proceedings of COLING-82.Boitet, C. and Nedobejkine, N. 1981 Recent Developments inRussian-French Machine Translation at Grenoble.
Linguistics 19:199-271.Chappuy, S. 1983 Formalisation de la description des niveauxd'interprrtation des langues naturelles.
Therse de 36 cycle.
Greno-ble.Chauchr, J.
1974 Transducteurs et arborescences.
Etude etr~alisation de syst~mes appliqurs aux grammaires transformation-nelles.
Th~se d'Etat.
Grenoble.Clemente-Salazar, M. 1982 Etudes et alorithmes lires/t une nouvellestructure de donnres en TA: les E-graphes.
Thrse deDocteur-Ingrnieur.
USMG and INPG, Grenoble.
See alsoProceedings of COLING-82.
Prague.Gerber, R. 1984 Etude des possiblitrs de cooprration entre unsystrme fond6 sur des techniques de comprrhension implicite(syst/~me logico-syntaxique) t un syst~me fond6 sur des techniquesde comprrhension explicite (syst~me xpert).
These de 36 cycle.Grenoble.Mozota, T. 1984 Un formalisme d'expressions pour la sp6cification ducontrble dans les systrmes de production.
These de 36 cycle.Grenoble.Vauquois, B.
1975 La Traduction Automatique ~Grenoble.
Docu-ment de Linguistique Quantitative 29.
Dunod, Paris.Vauquois, B.
1979 Aspects of Automatic Translation i  1979.
Scien-tific Program, IBM, Japan.Vauquois, B.
1983 Automatic Translation.
Proceedings of the SummerSchool "'The Computer and the Arabic Language.
'"Rabat: Chapter 9.Verastegui, N. 1982 Etude du parallrlisme applique /l la traductionautomatisre par ordinateur.
STAR-PALE: un systrme parall~le.Thrse de Docteur Ingrnieur.
USMG and INPG, Grenoble.
See alsoProceedings of COLING-82.
Prague.36 Computational Linguistics, Volume 11, Number 1, January-March 1985
