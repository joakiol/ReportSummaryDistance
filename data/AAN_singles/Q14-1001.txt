Heterogeneous Networks and Their Applications: Scientometrics, NameDisambiguation, and Topic ModelingBen King, Rahul JhaDepartment of EECSUniversity of MichiganAnn Arbor, MI{benking,rahuljha}@umich.eduDragomir R. RadevDepartment of EECSSchool of InformationUniversity of MichiganAnn Arbor, MIradev@umich.eduAbstractWe present heterogeneous networks as a way tounify lexical networks with relational data.
Webuild a unified ACL Anthology network, tyingtogether the citation, author collaboration, andterm-cooccurence networks with affiliation andvenue relations.
This representation proves tobe convenient and allows problems such as namedisambiguation, topic modeling, and the mea-surement of scientific impact to be easily solvedusing only this network and off-the-shelf graphalgorithms.1 IntroductionGraph-based methods have been used to great ef-fect in NLP, on problems such as word sense disam-biguation (Mihalcea, 2005), summarization (Erkanand Radev, 2004), and dependency parsing (McDon-ald et al., 2005).
Most previous studies of networksconsider networks with only a single type of node,and in some cases using a network with a single typeof node can be an oversimplified view if it ignoresother types of relationships.In this paper we will demonstrate heterogeneousnetworks, networks with multiple different types ofnodes and edges, along with several applications ofthem.
The applications in this paper are not pre-sented so much as robust attempts to out-perform thecurrent state-of-the-art, but rather attempts at beingcompetitive against top methods with little effort be-yond the construction of the heterogeneous network.Throughout this paper, we will use the data fromthe ACL Anthology Network (AAN) (Bird et al.,2008; Radev et al., 2013), which contains additionalmetadata relationships not found in the ACL Anthol-ogy, as a typical heterogeneous network.
The resultsin this paper should be generally applicable to otherheterogeneous networks.1.1 Heterogeneous AAN schemaWe build a heterogeneous graph G(V,E) fromAAN, where V is the set of vertices and E is theset of edges connecting vertices.
A vertex can beone of five semantic types: {paper, author, venue,institution, term}.
An edge can also be one of fivetypes, each connecting different types of vertices:?
author ?
[writes] ?
paper?
paper ?
[cites] ?
paper?
paper ?
[published in] ?
venue1?
author ?
[affiliated with] ?
institution2?
paper ?
[contains] ?
termAll of this data, except for the terms, is availablefor all papers in the 2009 release of AAN.
Terms areextracted from titles by running TextRank (Mihal-cea and Tarau, 2004) on NP-chunks from titles andmanually filtering out bad terms.We show the usefulness of this representationin several applications: the measurement of scien-tific impact (Section 2), name disambiguation (Sec-tion 3), and topic modeling (Section 4).
The hetero-geneous network representation provides a simpleframework for combining lexical networks (like theterm co-occurence network) with metadata relationsfrom a source like AAN and allows us to begin todevelop NLP-aware methods for problems like sci-entometrics and name disambiguation, which are notusually framed in an NLP perspective.1For a joint meeting of venues A and B publishing a paperx, two edges (x,A) and (x,B) are created.2Author-affiliation edges are weighted according to thenumber of papers an author has published from an institution.1Transactions of the Association for Computational Linguistics, 2 (2014) 1?14.
Action Editor: Lillian Lee.Submitted 3/2013; Revised 6/2013; Published 2/2014.
c?2014 Association for Computational Linguistics.2 Scientific Impact MeasurementThe study of scientometrics, which attempts toquantify the scientific impact of papers, authors, etc.has received much attention recently, even withinthe NLP community.
In the past few years, therehave been many proposed measures of scientific im-pact based on relationships between entities.
Intu-itively, a model that can take into account many dif-ferent types of relationships between entities shouldbe able to measure scientific impact more accu-rately than simpler measures like citation counts orh-index.We propose using Pagerank on the heterogeneousAAN (Page et al., 1999) to measure scientific impact.Since changes in the network schema can affect therelative rankings between different types of entities,this method is probably not appropriate for compar-ing entities of two different types against each other.But between nodes of the same type, this measure isan appropriate (and as we will show, accurate) wayto compare impacts.We see this method as a first logical step in thedirection of heterogeneous network-based sciento-metrics.
This method could easily be extended touse a directed schema (Kurland and Lee, 2005) or aschema that is aware of the lexical content of citationsentences, such as sentiment-based signed networks(Hassan et al., 2012).Determining the intrinsic quality of scientific im-pact measures can be difficult since there is noway to collect gold standard measurements for real-world entities.
Previous studies have attempted toshow that their measures give high scores to a fewknown high-impact entities, e.g.
Nobel prize win-ners (Hirsch, 2005), or have performed a statisticalcomponent analysis to find the most important mea-sures in a group of related statistics (Bollen et al.,2009).
Our approach, instead, is to generate real-istic data from synthetic entities whose impacts areknown.We had considered alternative formulations thatdid not rely on synthetic data, but each of thempresented problems.
When we attempted manualprominence annotation for AAN data, the inter-judge agreement (measured by Spearman correla-tion) in our experiments ranged from decent (0.9in the case of institutions) to poor (0.3 for authors)to nearly random (0.03 for terms), far too low touse in most cases.
We also considered evaluatingprominence measures by their ability to predict fu-ture citations to an entity.
Citations are often usedas a proxy for impact, but our measurements havefound that correlation between past citations and fu-ture citations is too high for citation prediction to bea meaningful evaluation3.2.1 Creating a synthetic AANIn network theory, a common technique for testingnetwork algorithms when judgments of real-worlddata are expensive or impossible to obtain is to testthe algorithm on a synthetic network.
To create sucha synthetic network, the authors define a simple, butrealistic generative process by which the real-worldnetworks of interest may arise.
The properties ofthe network are measured to ensure that it replicatescertain observable behaviors of the real-world net-work.
They can then test network algorithms to seehow well they are able to recover the hidden param-eters that generated the synthetic network.
(Pastor-Satorras and Vespignani, 2001; Clauset et al., 2009;Karrer and Newman, 2011)We take a two-step approach to generating thissynthetic data, first generating entities with knownimpacts, and second, linking these entities togetheraccording to their latent impacts.
Our heuristic isthat high impact entities should be linked to otherhigh impact entities and vice-versa.
As in the net-work theory literature, we must show that this datareflects important properties observed in the trueAAN.One such property is that the number of citationsper paper follows a power law distribution (Redner,1998).
We observe this behavior in AAN along withseveral other small-world behaviors, such as a smalldiameter, a small average shortest path length, and ahigh clustering coefficient in the coauthorship graph.We strive to replicate these properties in our syn-thetic data.3Most existing impact measurements require access to atleast one year?s worth of citation information.
The Spearmancorrelation between the number of citations received after oneyear and after five years is 0.79 with correlation between suc-cessive years as high as 0.99.
Practically this means that themeasures that best correlate with citations after five years areexactly those that best correlate with citations after one year.2Since scientific impact measures attempt to quan-tify the true impact of entities, we can use these mea-sures to help understand how the true impact mea-sures are distributed across different entities.
In fact,citation counts, being a good estimate of impact, canbe used to generate these latent impact variables foreach entity.
For each type of entity (papers, authors,institutions, venues, and terms), we create a latentimpact by sampling from the appropriate citationcount distribution.
After sampling, all the impactsare normalized to fall in the [0, 1] interval, with thehighest-impact entity of each type having a latentimpact of 1.
Additive smoothing is used to avoidhaving an impact of 0.Once we have created the entities, our methodfor placing edges is most similar to the Erdo?s-Re?yni method for creating random graphs (Erdo?sand Re?nyi, 1960), in which edges are distributeduniformly at random between pairs of vertices.
In-stead of distributing links uniformly, links betweenentities are sampled proportionally to I(a)I(b)(1 ?
(I(a) ?
I(b))2), where I(x) is the latent impact ofentity x.We tried several other formulae that failed toreplicate the properties of the real AAN.
TheI(a)I(b) part of the formula above reflects a pref-erence for nodes of any type to connect with high-impact entities (e.g., major conferences receivemany submissions even though most submissionswill be rejected), but the 1 ?
(I(a) ?
I(b))2 partalso reflects the reality that entities of similar promi-nence are most likely to attach to each other (e.g.,well-known authors publish in major conferences,while less well-known authors may publish mostlyin lesser-known workshops).Using this distribution, we randomly sample linksbetween papers and authors; authors and institu-tions; papers and venues; and papers and terms.
Theonly exception to this was paper-to-paper citationlinks, for which we did not expect this same be-havior to apply, as low-impact papers regularly citehigh-impact papers, but not vice-versa.
To model ci-tations, we selected citing papers uniformly at ran-dom and cited papers in proportion to their impacts.
(Albert and Baraba?si, 2002)Finally, we generated a network equal in size toAAN, that is, with the exact same numbers of pa-pers, authors, etc.
and the exact same number ofRelationship True value Synth.
valuePaper-citations powerlaw coeff.
1.82 2.12Diameter 9 8Avg.
shortest path 4.27 4.05Collaboration networkclustering coeff.
0.34 0.26Table 1: Network properties of the synthetic AANcompared with the true AAN.paper-author links, paper-venue links, etc.
Table 1compares the observed properties of the true AANwith the observed properties of this synthetic versionof AAN.
None of the statistics are exact matches, butwhen building random graphs, it is not uncommonfor measures to differ by many orders of magnitude,so a model that has measures that are on the sameorder of magnitude as the observed data is generallyconsidered to be a decent model (Newman and Park,2003).2.2 Measuring impact on the synthetic AANThis random network is, of course, still imperfectin some regards.
First of all, it has no time aspect,so it is not possible for impact to change over time,which means we cannot test against some impactmeasures that have a time component like CiteR-ank (Maslov and Redner, 2008).
Second, there aresome constraints present in the real world that arenot enforced here.
Because the edges are randomlyselected, some papers have no venues, while othershave multiple venues.
There is also nothing to en-force certain consistencies, such as authors publish-ing many papers from relatively few institutions, orrepeatedly collaborating with the same authors.We had also considered using existing randomgraph models such as the Baraba?si-Albert model(Baraba?si and Albert, 1999), which are known toproduce graphs that exhibit power law behavior.These models, however, do not provide a way to re-spect the latent impacts of the entities, as they addlinks in proportion only to the number of existinglinks a node has.We measure the quality of impact measures bycomparing ranked lists: the ordering of the entities3Paper measure AgreementHeterogeneous network Pagerank 0.773Citation network Pagerank 0.558Citation count 0.642Author measure AgreementHeterogeneous network Pagerank 0.461Coauthorship network Pagerank 0.244h-index (Hirsch, 2005) 0.292Aggregated citation count 0.236i10-index 0.235Institution measure AgreementHeterogeneous network Pagerank 0.373h-index (Mitra, 2006) 0.334Aggregated citation count 0.327Venue measure AgreementHeterogeneous network Pagerank 0.449h-index (Braun et al., 2006) 0.425Aggregated citation count 0.370Impact factor 0.092Venue citation network Pagerank (Bollenet al., 2006) 0.366Table 2: Agreement of various impact measureswith the true latent impact.by their true (but hidden) impact against their order-ing according to the impact measure.
The agree-ment between these lists is measured by Kendall?sTau.
Table 2 compares several well-known impactmeasures with our impact measure, Pagerank cen-trality on the heterogeneous AAN network.
We findthat some popular methods, such as h-index (Hirsch,2005) are too coarse to accurately capture muchof the underlying variation.
There is a version ofKendall?s Tau that accounts for ties, and while thismetric slightly helps the coarser measures, Pagerankon the heterogeneous network is still the clear win-ner.When comparing different ordering methods, itis natural to wonder which of entities the orderingsdisagree on.
In general, non-heterogeneous mea-sures like h-index or collaboration network Pager-ank, which only focus on one type of relationshipcan suffer when the entity in question has an impor-tant relationship of another type.
For example, if anauthor is highly cited, but mostly works alone, his1985 1990 1995 2000 2005 201020406080100120RelativePagerankACLEMNLPCOLINGNAACLFigure 1: Evolution of conference impacts.
The y-axis measures relative Pagerank, the entity?s Pager-ank relative to the average Pagerank in that year.contribution would be undervalued in the collabo-ration network, but would be more accurate in theheterogeneous network.The majority of the differences between the im-pact measures, though, tend to be in how they han-dle entities of low prominence.
It seems that, for themost part, there is relatively little disagreement inthe orderings of high-impact entities between differ-ent impact measures.
That is, most highly prominententities tend to be highly rated by most measures.But when an author or a paper, for example, only hasone or two citations, it can be advantageous to lookat more types of relationships than just citations.The paper may be written by an otherwise prominentauthor, or published at a well-known venue, and hav-ing many types of relations at its disposal can help amethod like heterogeneous network Pagerank betterdistinguish between two low-prominence entities.2.3 Top-ranked entities according toheterogeneous network PageRankTable 3 shows the papers, authors, institutions,venues, and terms that received the highest Pager-ank in the heterogeneous AAN.
It is obvious that thetop-ranked entities in this network are not simply themost highly cited entities.This ranking also does not have any time biastoward the entities that are currently prominent, assome of the top authors were more prolific in previ-ous decades than at the current time.
We also seethis effect with COLING, which for many of theearly years, is the only venue in the ACL Anthology.4Top Papers Top Authors Top Institutions Top Venues TopTerms?
Building A Large Annotated Corpus OfEnglish: The Penn Treebank 4 15 Jun?ichi Tsujii 4 8Carnegie MellonUniversity 4 1 COLING ?
translation?
The Mathematics Of Statistical MachineTranslation: Parameter Estimation 4 7Aravind K.Joshi 4 1University ofEdinburgh 5 1 ACL 4 3 speech?
Attention, Intentions, And The Structure OfDiscourse 4 18RalphGrishman 5 2University ofPennsylvania 4 2 HLT 5 1 parsing?
A Maximum Entropy Approach To NaturalLanguage Processing 4 75 Hitoshi Isahara 5 2MassachusettsInstitute ofTechnology4 4 EACL 5 1 machinetranslation?
BLEU: a Method for Automatic Evaluationof Machine Translation 4 20YujiMatsumoto 4 12SaarlandUniversity 4 7 LREC 4 3 generation?
A Maximum-Entropy-Inspired Parser 4 7 Kathleen R.McKeown 5 2IBM T.J. WatsonResearch Center ?
NAACL 4 3 evaluation4 2 A Stochastic Parts Program And NounPhrase Parser For Unrestricted Text 4 13 Eduard Hovy 4 39 CNRS 5 3 EMNLP 4 6 grammar5 1 A Systematic Comparison of VariousStatistical Alignment Models 4 10Christopher D.Manning 4 26University ofTokyo 5 5ComputationalLinguistics 4 16 dialogue4 4Transformation-Based Error-DrivenLearning and Natural Language Processing:a Case Study in Part-of-Speech Tagging4 93 Yorick Wilks 5 4 StanfordUniversity 4 4 IJCNLP 4 10knowl-edge4 1 A Maximum Entropy Model forPart-of-Speech Tagging 5 9 Hermann Ney 4 3 BBN Technologies 4 1Workshop onSpeech andNaturalLanguage4 1 discourseTable 3: The entities of each type receiving the highest scores from the heterogeneous network Pagerankimpact measure along with their respective changes in ranking when compared to a simple citation countmeasure.One possible way to address this is to use a narrowertime window when creating the graph, such as onlyincluding edges from the previous five years.
Weapply this technique in the following section.2.4 Entity impact evolutionThe heterogeneous graph formalism also provides anatural way to study the evolution of impact overtime, as in (Hall et al., 2008), but at a much finergranularity.
Hall et al.
measured the year-by-yearprominence of statistical topics, but we can measureyear-by-year prominence for any entity in the graph.To measure the evolution of impacts over theyears, we iteratively create year-by-year versions ofthe heterogeneous AAN.
Each of these graphs con-tains all entities along with all edges occurring in afive year window.
Due to space, we cannot com-prehensively exhibit this technique and the data itproduces, but as a brief example, in Figure 1, weshow how the impacts of some major NLP confer-ences changes over time.The graph shows that NAACL and EMNLP havebeen steadily gaining prominence since their intro-ductions, but also shows that ACL has had to makeup a lot of ground since 1990 to surpass COLING.We also notice that all the major conferences havegrown in impact since 2005, and believe that as thefield continues to grow, the major conferences willcontinue to become more and more important.3 Name DisambiguationWe frame network name disambiguation in a linkprediction setting (Taskar et al., 2003; Liben-Nowelland Kleinberg, 2007).
The problems of name dis-ambiguation and link prediction share many char-acteristics, and we have found that if two ambigu-ous name nodes are close enough to be selected by alink-prediction method, then they likely correspondto the same real-world author.We intend to show that the heterogeneous biblio-graphic network can be used to better disambiguateauthor names than the author collaboration network.The heterogeneous network for this problem con-tains papers, authors, terms, venues, and institutions.We compare several well-known network similaritymeasures from link prediction by transforming the5Network Distance Measure Precision Recall F1-score Rand index Purity NMIHeterogeneous Truncated Commute Time 0.59 0.78 0.63 0.63 0.71 0.43Heterogeneous Shortest Path 0.90 0.79 0.83 0.87 0.94 0.76Heterogeneous PropFlow 0.89 0.83 0.84 0.87 0.93 0.77Coauthorship Truncated Commute Time 0.47 0.80 0.54 0.47 0.60 0.18Coauthorship Shortest Path 0.54 0.73 0.60 0.61 0.67 0.31Coauthorship PropFlow 0.57 0.76 0.64 0.66 0.71 0.43Coauthorship GHOST 0.89 0.60 0.69 0.81 0.94 0.63Table 4: Performance of different networks and distance measures on the author name disambiguation task.The performance measures are averaged over the sets of two, three, and four authors.
Rand index is from(Rand, 1971) and NMI is an abbreviation for normalized mutual information (Strehl and Ghosh, 2003)similarities to distances and inducing clusters of au-thors based on these distances.We compare three distance measures: shortestpath, truncated commute time (Sarkar et al., 2008),and PropFlow (Lichtenwalter et al., 2010).
Short-est path distance can be a useful metric for authordisambiguation because it is small when two am-biguous nodes are neighbors in the graph or sharea neighbor.
Its downside is that it only considers onepath between nodes, the shortest, and cannot takeadvantage of the fact that there may be many shortpaths between two nodes.Truncated commute time is a variant of commutetime where all paths longer than some threshold aretruncated.
The truncation threshold l should be setsuch that no semantically meaningful path is trun-cated.
We use a value of ten for l in the heteroge-neous graph and three in the coauthorship graph4.The advantage of truncated commute time over or-dinary commute time is simpler calculation, as nopaths longer than l need be considered.
The down-side of this method is that large branching factorstend to lead to less agreement between commutetime and truncated commute time.PropFlow is a quantity that measures the proba-bility that a non-intersecting random walk starting atnode a reaches node b in l steps or fewer, where l isagain a threshold.
As before, l should be a bound onthe length of semantically meaningful paths, so weuse the same values for l as with truncated commutetime.
Of course, PropFlow is not a metric, which is4This is a standard coauthorship graph with the edge weightsequal to the number of publications shared between authors.The heterogeneous network does not have author-to-authorlinks, as authors are linked by paper nodes.required for some clustering methods.
We use thefollowing equation to transform PropFlow to a met-ric: d(a, b) = 1PropF low(a,b) ?
1.With each of the distance measures, we applythe same clustering method: partitioning aroundmedoids, with the number of clusters automaticallydetermined using the gap statistic method (Tibshi-rani et al., 2001).
We create the null distributionneeded for the gap statistic method by many itera-tions of randomly sampling distances from the com-plete distance matrix between all nodes in the graph.The gap statistic method automatically selects thenumber of clusters from two, three, or four authorclusters.We compare our methods against GHOST (Fan etal., 2011), a high-performance author disambigua-tion method based on the coauthorship graph.3.1 DataTo generate name disambiguation data, we use thepseudoword method of (Gale et al., 1992).
Specif-ically, we choose two or more completely randomauthors and conflate them by giving all instancesof both authors the same name.
We let each paperwritten by this pseudoauthor be an instance to beclustered.
The clusters produced by any author dis-ambiguation method can then be compared againstthe papers actually written by each of the two au-thors.
This method, of course, relies on having all ofthe underlying authors completely disambiguated,which AAN provides.This method is used to create 100 distambiguationsets with two authors, 100 for three authors, and 100for four authors.63.2 ResultsTable 4 shows the performance of author name dis-ambiguation with different networks and distancemetrics.
F1-score is the measure that is most of-ten used to compare author disambiguation methods.Both PropFlow and shortest path similarity on theheterogeneous network perform quite well accord-ing this measure, as well as the other reported mea-sures.
While comparable recall can be achieved us-ing only the coauthorship graph, the heterogeneousgraph allows for much higher precision.4 Random walk topic modelHere we present a topic model based entirely ongraph random walks.
This method is not truly astatistical model as there are no statistical parame-ters being learned, but rather a topic-discovery and-assignment method, attempting to solve the sameproblem as statistical topic models such as proba-bilistic latent semantic analysis (pLSA) (Hofmann,1999) or latent Dirichlet allocation (LDA) (Blei etal., 2003).
In the absence of better terminology, weuse the name random walk topic model.While this method does not have the robust math-ematical foundation that statistical topic models pos-sess, in its favor it has modularity, simplicity, andinterpretability.
This language model is modular asit completely separates the discovery of topics fromthe association of topics with entities.
It is sim-ple because it requires only a clustering algorithmand random walk algorithms, instead of complex in-ference algorithms.
The method also does not re-quire any modification if the topology of the net-work changes, whereas statistical models may needan entirely different inference procedure if, e.g., au-thor topics are desired in addition to paper topics.Thirdly this method is easily interpretable with top-ics provided by clustering in the word-relatednessgraph and topic association based on random walksfrom entities to topics.4.1 Topics from word graph clusteringFrom the set of ACL anthology titles, we createtwo graphs: (1) a word relatedness graph by cre-ating a weighted link between each pair of wordscorresponding to the PropFlow (Lichtenwalter et al.,2010) measure between them on the full heteroge-neous graph and (2) a word co-occurence graph bycreating a weighted link between each pair of wordscorresponding to the number of titles in which bothwords occur.Both of these graphs are then clustered usingGraph Factorization Clustering (GFC).
GFC is a softclustering algorithm for graphs that models graphedges as a mixture of latent node-cluster associationvariables.
(Yu et al., 2006)Given a word graph G with vertices V and ad-jacency matrix [w]ij , GFC attempts to fit a bipar-tite graph K(V,U) with adjacency matrix [b]ij ontothis data, with the m nodes of U representing theclusters.
Whereas in G, similarity between twowords i and j can be measured with wij , we cansimilarly measure their similarity in K with w?ij =?mp=1bipbjp?p where ?p =?ni=1 bip is the degree ofvertex p ?
U .Essentially the bipartite graph attempts to approx-imate the transition probability between i and j inGwith the sum of transition probabilities from i to jthrough any of the m nodes in U .
Yu, et al.
(2006)present an algorithm for minimizing the divergencedistance `(X,Y) =?ij(xijlog xijyij ?
xij + yij) be-tween [w]ij and [w?
]ij .We run GFC with this distance metric and m =100 clusters on the word graph until convergence(change in log-likelihood < 0.1%).
After conver-gence, the nodes in U become the clusters and theweights bip (constrained to sum to 1 for each clus-ter) become the topic-word association scores.Examples of some topics found by this methodare shown in Table 5.
From manual inspection ofthese topics, we found them to be very much liketopics created by statistical topic models.
We findinstances of all the types of topics listed in (Mimnoet al., 2011): chained, intruded, random, and unbal-anced.
For an evaluation of these topics see Sec-tion 4.3.1.4.2 Entity-topic associationTo associate entities with topics, we first createthe heterogeneous network as in previous sections,adding links between papers and their title words,along with links between words and the topics thatwere discovered in the previous section.
Word-topiclinks are also weighted according to the weights7Word sense induction sense disambiguation word induction unsupervised clustering senses based similarity chineseCRFs + their applications entity named recognition random conditional fields chinese entities biomedical segmentationDependency parsing parsing dependency projective probabilistic incremental deterministic algorithm data syntactic treesTagging models tagging model latent markov conditional random parsing unsupervised segmentationMulti-doc summarization summarization multi document text topic based query extractive focused summariesChinese word segmentation word segmentation chinese based alignment character tagging bakeoff model crfLexical semantics lexical semantic distributional similarity wordnet resources lexicon acquistion semantics representationCross-lingual IR cross lingual retrieval document language linguistic multi person multilingual coreferenceGeneration for summar.
sentence based compression text summarization ordering approach ranking generationSpoken language speech recognition automatic prosodic tagging spontaneous news broadcast understanding conversationalFrench function words de la du des le automatique analyse une en pourQuestion answering question answering system answer domain retrieval web based open systemsUnsupervised learning unsupervised discovery learning induction knowledge graph acquisition concept clustering patternSVMs for NLP support vector machines errors space classification correcting word parsing detectingMaxEnt models entropy maximum approach based attachment model models phrase prepositional disambiguationDialogue systems dialogue spoken systems human conversational multi interaction dialogues utterances multimodalSemantic role-labeling semantic role labeling parsing syntactic features ill dependency formed framenetSMT based translation machine statistical phrase english approach learning reordering modelCoreference resolution resolution coreference anaphora reference pronoun ellipsis ambiguity resolving approach pronominalSemi- and weak-supervision learning supervised semi classification active data clustering approach graph weaklyInformation retrieval based retrieval similarity models semantic space model distance measures documentDiscourse discourse relations structure rhetorical coherence temporal representation text connectives theoryCFG parsing context free grammars parsing linear probabilistic rewriting grammar systems optimalMin.
risk train.
and decod.
minimum efficient training error rate translation risk bayes decoding statisticalPhonology phoneme conversion letter phonological grapheme rules applying transliteration syllable soundSentiment sentiment opinion reviews classification mining polarity analysis predicting product featuresNeural net speech recog.
speech robust recognition real network time neural networks language environmentsFinite state methods state finite transducers automata weighted translation parsing incremental minimal constructionMechanical Turk mechanical turk automatic evaluation amazon techniques data articles image scientificTable 5: Top 10 words for several topics created by the co-occurence random walk topic model.
The leftcolumn is a manual label.Topic 59 Topic 82translation 0.1953 parsing 0.1715machine 0.1802 dependency 0.1192statistical 0.0784 projective 0.0138Machine Translation 0.0018 K-best Spanning Tree Parsing 0.0025Better Hypothesis Testing for StatisticalMachine Translation: Controlling forOptimizer Instability0.0016 Pseudo-Projective Dependency Parsing 0.0024Filtering Antonymous, Trend- Contrasting, andPolarity-Dissimilar Distributional Paraphrasesfor Improving Statistical Machine Translation0.0015 Shift-Reduce Dependency DAG Parsing 0.0017Knight, Kevin 0.0083 Nivre, Joakim 0.0120Koehn, Philipp 0.0074 Johnson, Mark 0.0085Ney, Hermann 0.0072 Nederhof, Mark-Jan 0.0064RWTH Aachen University 0.0212 Vaxjo University 0.0113Carnegie Mellon University 0.0183 Brown University 0.0107University of Southern California 0.0177 University of Amsterdam 0.0094Workshop on Statistical Machine Translation 0.0590 ACL 0.0512EMNLP 0.0270 EMNLP 0.0259COLING 0.0173 CoNLL 0.0223Table 6: Examples of entities associated with selected topics.8determined by GCF.
We then simply take randomwalks from topics to entities and measure the pro-portion at which the random walk arrives at each en-tity of interest.
These proportions become the entity-topic association scores.For example, if we wanted to find the authorsmost associated with topic 12, we would take a num-ber of random walks (say 50,000) starting at topic12 and terminating as soon as the random walk firstreaches an author node.
Measuring the proportionat which random walks arrive at each allows us tocompute an association score between topic 12 andeach author.A common problem in random walks on largegraphs is that the walk can easily get ?lost?
betweentwo nodes that should be very near by taking a justa few steps in the wrong direction.
To keep the ran-dom walks from taking these wrong steps, we adjustthe topology of the network using directed links tokeep the random walks moving in the ?right?
direc-tion.
We design the graph such that if we desire arandom walk from nodes of type s to nodes of type t,the random walk will never be able to follow an out-going link that does not decrease its distance fromthe nodes of t.As shown in section 2.3, there are certain nodes atwhich a random walk (like Pagerank) arrives at moreoften than others simply because of their positions inthe graph.
This suggests that there may be stationaryrandom walk distributions over entities, which wewould need to adjust for in order to find the mostsignificant entities for a topic.Indeed this is what we do find.
As an example, ifwe sample topics uniformly and take random walksto author nodes, by chance we end up at Jun?ichiTsujii on 0.3% of random walks, Eduard Hovy on0.2% of walks, etc.
These values are about 1000times greater than would be expected at random.To adjust for this effect, when we take a randomwalk from a topic x to an entity type t, we subtractout this stationary distribution for t, which corre-sponds to the proportion of random walks that endat any particular entity of type t by chance, and notby virtue of the fact that the walk started at topic x.The resulting distribution yields the entities of t thatare most significantly associated with topic x. Ta-ble 6 gives examples of the most significant entitiesfor a couple of topics.
?200 ?150 ?100 ?50RW-coocRW-simRTMLDACoherenceFigure 2: Distribution of topic coherences for thefour topic models.4.3 Topic Model EvaluationWe provide two separate evaluations in this section,one of the topics alone, and one extrinstic evaluationof the entire paper-topic model.
The variants of ran-dom walk topic models are compared against LDAand the relational topic model (RTM), each with 100topics (Chang and Blei, 2010).
As RTM allows onlya single type of relationship between documents, weuse citations as the inter-document relationships.4.3.1 Topic CoherenceThe coherence of a topic is evaluated using the co-herence metric introduced in (Mimno et al., 2011).Given the top M words V (t) = (v(t)1 , ..., v(t)M ) for atopic t, the coherence of that topic can be calculatedwith the following formula:C(t;V (t)) =M?m=2m?1?l=1log(D(v(t)m , v(t)l ) + 1D(v(t)l )),where D(v) is the number of documents contain-ing v and D(v, v?)
is the number of documents con-taining both v and v?.This measure of coherence is highly correlatedwith manual annotations of topic quality, with ahigher coherence score corresponding to a more co-herent, higher quality topic.
After calculating the co-herence for each of the 100 topics for RTM and therandom-walk topic model, the average coherence forRTM topics was -135.2 and the average coherencefor word-similarity random walk topics was -122.2,with statistical significance at p < 0.01.
Figure 2demonstrates this, showing that the word similarity-based random walk method generates several highlycoherent topics.
The average coherence for the LDAand the co-occurence random walk model were sig-nificantly lower.94.3.2 Extrinsic EvaluationOne difficulty in evaluating this random-walktopic model intrinsically against a statistical topicmodel like RTM is that existing evaluation measuresassume certain statistical properties of the topic, forexample, that the topics are generated according to aDirichlet prior.
Because of this, we choose instead toevaluate this topic model extrinsically with a down-stream application.
We choose an information re-trieval application, returning a ranked list of similardocuments, given a reference document.We evaluate five different methods: citation-RTM, LDA, the two versions of the random-walktopic model, and a simple word vector similaritybaseline.
Similarity between documents with thetopic models are determined by cosine similarity be-tween the topic vectors of the two documents.
Wordvector similarity determines the similarity betweendocuments by taking the cosine similarity of theirword vectors.
From these similarity scores, a rankedlist is produced.The document set for this task is the set of all pa-pers appearing at ACL between 2000 and 2011.
Thetop 10 results returned by each method are pooledand manually evaluated with a relevance score be-tween 1 and 10.
Thirty such result sets were manu-ally annotated.
We then evaluate each method ac-cording to its discounted cumulative gain (DCG)(Ja?rvelin and Keka?la?inen, 2000).Performance of these methods is summarized inTable 7.
The co-occurence-based random walk topicmodel performed comparably with the best per-former at this task, LDA, and there was no signifi-cant difference between the two at p < 0.05.Going forward, an important problem is to rec-oncile the co-occurence- and word-similarity-basedformulations of this topic model, as the two formu-lations perform very differently in our two evalua-tions.
Heuristically, the co-occurence model seemsto create good human-readable topics, while theword-similarity model creates topics that are moremathematically-coherent, but less human-readable.5 Related WorkHeterogeneous networks have been studied in anumber of different fields, such as biology (Sio-son, 2005), transportation networks (Lozano andMethod DCGWord vector 1.345 ?
0.007LDA 3.302 ?
0.008RTM 3.058 ?
0.011Random-walk (cooc) 3.295 ?
0.006Random-walk (sim) 2.761 ?
0.007Table 7: DCG Performance of the various topicmodels and baselines on the related document find-ing task.
A 95% confidence interval is provided.Storchi, 2002), social networks (Lambiotte and Aus-loos, 2006), and bibliographic networks (Sun et al.,2011).
These networks are also sometimes knownby the name complex networks or multimodal net-works, but both these terms have other connotations.We prefer ?heterogeneous networks?
as used by Sunet al.
(2009).There has also been some study of these networksin general, in community detection (Murata, 2010),clustering (Long et al., 2008; Sun et al., 2012), anddata mining (Muthukrishnan et al., 2010), but therehas not yet been any comprehensive study.
Recently,NLP has seen several uses of heterogeneous net-works (though not by that name) for use with labelpropagation algorithms (Das and Petrov, 2011; Spe-riosu et al., 2011) and random walks (Toutanova etal., 2004; Kok and Brockett, 2010).Several authors have proposed the idea of usingnetwork centrality measures to rank the impacts ofjournals, authors, papers, etc.
(Bollen et al., 2006;Bergstrom et al., 2008; Chen et al., 2007; Liu et al.,2005), and it has even been proposed that central-ity can be applicable in bipartite networks (Zhou etal., 2007).
We propose that Pagerank on any gen-eral heterogeneous network is appropriate for creat-ing ranked lists for each type of entity.
Most previ-ous papers also lack a robust evaluation, demonstrat-ing agreement with previous methods or with someexternal awards or recognitions.
We use a randomgraph that replicates the properties of the real-worldnetwork to show that Pagerank on the heterogeneousnetwork outperforms other methods.Name disambiguation has been studied in a num-ber of different settings, including graph-based set-tings.
It is common to use the coauthorship graph(Kang et al., 2009; Fan et al., 2011), but authors10have also used lexical similarity graphs (On and Lee,2007), citation graphs (McRae-Spencer and Shad-bolt, 2006), or social networks (Malin, 2005).
Al-most all graph methods are unsupervised.There have been some topic models developedspecifically for relational data (Wang et al., 2006;Airoldi et al., 2008), but both of these models havelimitations in the types of relational data they areable to model.
The group topic model described in(Wang et al., 2006) is able to create stronger topicsby considering associations between words, events,and entities, but is very coarse in the way it han-dles the behavior of entities, and does not generalizeto multiple different types of entities.
The stochas-tic blockmodel of (Airoldi et al., 2008) can createblocks of similar entities in a graph and is generalin the types of graphs it can handle, but producesless meaningful results on graphs that have specificschemas.6 Conclusion and Future DirectionsIn this paper, we present a heterogeneous net-work treatment of the ACL Anthology Network anddemonstrate several applications of it.
Using onlyoff-the-shelf graph algorithms with a single data rep-resentation, the heterogeneous AAN, we are able tovery easily build a scientific impact measure that ismore accurate than existing measures, an author dis-ambiguation system better than existing graph-basedauthor disambiguation systems, and a random-walk-based topic model that is competitive with statisticaltopic models.While there are many other tasks, such as citation-based summarization, that could likely be ap-proached using this framework with the appropri-ate addition of new types of nodes into the hetero-geneous AAN network, there are even some poten-tial synergies between the tasks described in this pa-per that have yet to be explored.
For example, wemay consider that the methods of the author disam-biguation or topic modeling tasks could be to findthe highest-impact papers associated with a term (forsurvey generation, perhaps) or high-impact authorsassociated with a workshop?s topic (to select goodreviewers for it).
We believe that heterogeneousgraphs are a flexible framework that will allow re-searchers to find simple, flexible solutions for a va-riety of problems.AcknowledgmentsThis research is supported by the Intelligence AdvancedResearch Projects Activity (IARPA) via Department ofInterior National Business Center (DoI/NBC) contractnumber D11PC20153.
The U.S. Government is autho-rized to reproduce and distribute reprints for Governmen-tal purposes notwithstanding any copyright annotationthereon.
Disclaimer: The views and conclusions con-tained herein are those of the authors and should not beinterpreted as necessarily representing the official poli-cies or endorsements, either expressed or implied, ofIARPA, DoI/NBC, or the U.S. Government.ReferencesEdoardo M. Airoldi, David M. Blei, Stephen E. Fienberg,and Eric P. Xing.
2008.
Mixed membership stochasticblockmodels.
The Journal of Machine Learning Re-search, 9:1981?2014.Re?ka Albert and Albert-La?szlo?
Baraba?si.
2002.
Statisti-cal mechanics of complex networks.
Reviews of mod-ern physics, 74(1):47.A.L.
Baraba?si and R. Albert.
1999.
Emergence of scal-ing in random networks.
Science, 286(5439):509?512.Carl T. Bergstrom, Jevin D. West, and Marc A. Wiseman.2008.
The eigenfactor metrics.
The Journal of Neuro-science, 28(45):11433?11434.Steven Bird, Robert Dale, Bonnie J Dorr, Bryan Gib-son, Mark Joseph, Min-Yen Kan, Dongwon Lee, BrettPowley, Dragomir R Radev, and Yee Fan Tan.
2008.The ACL anthology reference corpus: A referencedataset for bibliographic research in computational lin-guistics.
In Proc.
of the 6th International Conferenceon Language Resources and Evaluation Conference(LREC08), pages 1755?1759.D.M.
Blei, A.Y.
Ng, and M.I.
Jordan.
2003.
Latentdirichlet allocation.
the Journal of machine Learningresearch, 3:993?1022.Johan Bollen, Marko A. Rodriguez, and Herbert Vande Sompel.
2006.
Journal status.
CoRR,abs/cs/0601030.Johan Bollen, Herbert Van de Sompel, Aric Hagberg, andRyan Chute.
2009.
A principal component analysis of39 scientific impact measures.
PloS one, 4(6):e6022.Tibor Braun, Wolfgang Gla?nzel, and Andra?s Schubert.2006.
A hirsch-type index for journals.
Scientomet-rics, 69(1):169?173.Jonathan Chang and David M Blei.
2010.
Hierarchicalrelational models for document networks.
The Annalsof Applied Statistics, 4(1):124?150.11Peng Chen, Huafeng Xie, Sergei Maslov, and Sid Redner.2007.
Finding scientific gems with googles pagerankalgorithm.
Journal of Informetrics, 1(1):8?15.Aaron Clauset, Cosma Rohilla Shalizi, and Mark EJNewman.
2009.
Power-law distributions in empiricaldata.
SIAM review, 51(4):661?703.Dipanjan Das and Slav Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projec-tions.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 600?609.Paul Erdo?s and Alfre?d Re?nyi.
1960.
On the evolution ofrandom graphs.
Magyar Tud.
Akad.
Mat.
Kutato?
Int.Ko?zl, 5:17?61.Gu?nes Erkan and Dragomir R. Radev.
2004.
Lexrank:Graph-based lexical centrality as salience in text sum-marization.
J. Artif.
Intell.
Res.
(JAIR), 22:457?479.Xiaoming Fan, Jianyong Wang, Xu Pu, Lizhu Zhou, andBing Lv.
2011.
On graph-based name disambigua-tion.
J.
Data and Information Quality, 2(2):10:1?10:23, February.William A. Gale, Kenneth W. Church, and DavidYarowsky.
1992.
Work on statistical methods for wordsense disambiguation.
In Working Notes of the AAAIFall Symposium on Probabilistic Approaches to Natu-ral Language, volume 54, page 60.David Hall, Daniel Jurafsky, and Christopher D. Man-ning.
2008.
Studying the history of ideas using topicmodels.
In Proceedings of the Conference on Empir-ical Methods in Natural Language Processing, pages363?371.
ACL.Ahmed Hassan, Amjad Abu-Jbara, and Dragomir Radev.2012.
Extracting signed social networks from text.TextGraphs-7, page 6.Jorge E. Hirsch.
2005.
An index to quantify an indi-vidual?s scientific research output.
Proceedings of theNational Academy of Sciences of the United states ofAmerica, 102(46):16569.Thomas Hofmann.
1999.
Probabilistic latent semanticindexing.
In Proceedings of the 22nd annual interna-tional ACM SIGIR conference on Research and devel-opment in information retrieval, pages 50?57.
ACM.Kalervo Ja?rvelin and Jaana Keka?la?inen.
2000.
IR evalua-tion methods for retrieving highly relevant documents.In Proceedings of the 23rd annual international ACMSIGIR conference on Research and development in in-formation retrieval, pages 41?48.
ACM.In-Su Kang, Seung-Hoon Na, Seungwoo Lee, HanminJung, Pyung Kim, Won-Kyung Sung, and Jong-HyeokLee.
2009.
On co-authorship for author disam-biguation.
Information Processing & Management,45(1):84?97.Brian Karrer and Mark EJ Newman.
2011.
Stochas-tic blockmodels and community structure in networks.Physical Review E, 83(1):016107.Stanley Kok and Chris Brockett.
2010.
Hitting the rightparaphrases in good time.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 145?153.
ACL.Oren Kurland and Lillian Lee.
2005.
Pagerank withouthyperlinks: Structural reranking using links inducedby language models.
In SIGIR ?05.Renaud Lambiotte and Marcel Ausloos.
2006.
Collabo-rative tagging as a tripartite network.
ComputationalScience?ICCS 2006, pages 1114?1117.David Liben-Nowell and Jon Kleinberg.
2007.
The link-prediction problem for social networks.
Journal of theAmerican society for information science and technol-ogy, 58(7):1019?1031.R.N.
Lichtenwalter, J.T.
Lussier, and N.V. Chawla.
2010.New perspectives and methods in link prediction.
InProceedings of the 16th ACM SIGKDD internationalconference on Knowledge discovery and data mining,pages 243?252.
ACM.Xiaoming Liu, Johan Bollen, Michael L. Nelson, andHerbert Van de Sompel.
2005.
Co-authorship net-works in the digital library research community.
Infor-mation processing & management, 41(6):1462?1480.Bo Long, Zhongfei Zhang, and Tianbing Xu.
2008.Clustering on complex graphs.
In Proc.
the 23rd Conf.AAAI 2008.Angelica Lozano and Giovanni Storchi.
2002.
Shortestviable hyperpath in multimodal networks.
Transporta-tion Research Part B: Methodological, 36(10):853?874.Bradley Malin.
2005.
Unsupervised name disambigua-tion via social network similarity.
In Workshop onLink Analysis, Counterterrorism, and Security, vol-ume 1401, pages 93?102.Sergei Maslov and Sidney Redner.
2008.
Promiseand pitfalls of extending google?s pagerank algorithmto citation networks.
The Journal of Neuroscience,28(44):11103?11105.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-projective dependency pars-ing using spanning tree algorithms.
In Proceedings ofthe conference on Human Language Technology andEmpirical Methods in Natural Language Processing,pages 523?530.
ACL.Duncan M. McRae-Spencer and Nigel R. Shadbolt.2006.
Also by the same author: Aktiveauthor, a cita-tion graph approach to name disambiguation.
In Pro-ceedings of the 6th ACM/IEEE-CS joint conference onDigital libraries, pages 53?54.
ACM.12Rada Mihalcea and Paul Tarau.
2004.
Textrank: Bring-ing order into texts.
In Proceedings of EMNLP, vol-ume 4, pages 404?411.
Barcelona, Spain.Rada Mihalcea.
2005.
Unsupervised large-vocabularyword sense disambiguation with graph-based algo-rithms for sequence data labeling.
In Proceedings ofHLT-EMNLP, pages 411?418.
ACL.David Mimno, Hanna M. Wallach, Edmund Talley,Miriam Leenders, and Andrew McCallum.
2011.
Op-timizing semantic coherence in topic models.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing, pages 262?272.
ACL.Panchanan Mitra.
2006.
Hirsch-type indices for rank-ing institutions scientific research output.
Current Sci-ence, 91(11):1439.Tsuyoshi Murata.
2010.
Detecting communities fromtripartite networks.
In Proceedings of the 19th inter-national conference on World wide web, pages 1159?1160.
ACM.Pradeep Muthukrishnan, Dragomir Radev, and QiaozhuMei.
2010.
Edge weight regularization over mul-tiple graphs for similarity learning.
In Data Mining(ICDM), 2010 IEEE 10th International Conference on,pages 374?383.
IEEE.Mark E.J.
Newman and Juyong Park.
2003.
Why socialnetworks are different from other types of networks.Physical Review E, 68(3):036122.Byung-Won On and Dongwon Lee.
2007.
Scalable namedisambiguation using multi-level graph partition.
InProceedings of the 7th SIAM international conferenceon data mining, pages 575?580.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1999.
The pagerank citation ranking:bringing order to the web.Romualdo Pastor-Satorras and Alessandro Vespignani.2001.
Epidemic spreading in scale-free networks.Physical review letters, 86(14):3200?3203.Dragomir R. Radev, Pradeep Muthukrishnan, VahedQazvinian, and Amjad Abu-Jbara.
2013.
The ACLanthology network corpus.
Language Resources andEvaluation, pages 1?26.William M. Rand.
1971.
Objective criteria for the eval-uation of clustering methods.
Journal of the AmericanStatistical association, 66(336):846?850.S.
Redner.
1998.
How popular is your paper?
an empir-ical study of the citation distribution.
The EuropeanPhysical Journal B-Condensed Matter and ComplexSystems, 4(2):131?134.P.
Sarkar, A.W.
Moore, and A. Prakash.
2008.
Fast incre-mental proximity search in large graphs.
In Proceed-ings of the 25th international conference on Machinelearning, pages 896?903.
ACM.Allan A. Sioson.
2005.
Multimodal networks in biology.Ph.D.
thesis, Virginia Polytechnic Institute and StateUniversity.Michael Speriosu, Nikita Sudan, Sid Upadhyay, and Ja-son Baldridge.
2011.
Twitter polarity classificationwith label propagation over lexical links and the fol-lower graph.
In Proceedings of the First workshop onUnsupervised Learning in NLP, pages 53?63, Edin-burgh, Scotland, July.
ACL.Alexander Strehl and Joydeep Ghosh.
2003.
Clusterensembles?a knowledge reuse framework for com-bining multiple partitions.
The Journal of MachineLearning Research, 3:583?617.Yizhou Sun, Jiawei Han, Peixiang Zhao, Zhijun Yin,Hong Cheng, and Tianyi Wu.
2009.
Rankclus: inte-grating clustering with ranking for heterogeneous in-formation network analysis.
In Proceedings of the12th International Conference on Extending DatabaseTechnology: Advances in Database Technology, pages565?576.
ACM.Yizhou Sun, Rick Barber, Manish Gupta, and Jiawei Han.2011.
Co-author relationship prediction in heteroge-neous bibliographic networks.Yizhou Sun, Charu C. Aggarwal, and Jiawei Han.
2012.Relation strength-aware clustering of heterogeneousinformation networks with incomplete attributes.
Pro-ceedings of the VLDB Endowment, 5(5):394?405.Ben Taskar, Ming-Fai Wong, Pieter Abbeel, and DaphneKoller.
2003.
Link prediction in relational data.
InNeural Information Processing Systems, volume 15.Robert Tibshirani, Guenther Walther, and Trevor Hastie.2001.
Estimating the number of clusters in a dataset via the gap statistic.
Journal of the Royal Sta-tistical Society: Series B (Statistical Methodology),63(2):411?423.Kristina Toutanova, Christopher D Manning, and An-drew Y Ng.
2004.
Learning random walk modelsfor inducing word dependency distributions.
In Pro-ceedings of the twenty-first international conferenceon Machine learning, page 103.
ACM.Xuerui Wang, Natasha Mohanty, and Andrew McCallum.2006.
Group and topic discovery from relations andtheir attributes.
Technical report, DTIC Document.Kai Yu, Shipeng Yu, and Volker Tresp.
2006.
Softclustering on graphs.
Advances in Neural InformationProcessing Systems, 18:1553.Ding Zhou, Sergey A. Orshanskiy, Hongyuan Zha, andC.
Lee Giles.
2007.
Co-ranking authors and docu-ments in a heterogeneous network.
In Data Mining,2007.
ICDM 2007.
Seventh IEEE International Con-ference on, pages 739?744.
IEEE.1314
