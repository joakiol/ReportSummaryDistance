Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 842?849,Sydney, July 2006. c?2006 Association for Computational LinguisticsUsing Word Support Model to Improve Chinese Input SystemJia-Lin TsaiTung Nan Institute of Technology, Department of Information ManagementTaipei 222, Taiwantsaijl@mail.tnit.edu.twAbstractThis paper presents a word supportmodel (WSM).
The WSM can effec-tively perform homophone selectionand syllable-word segmentation to im-prove Chinese input systems.
The ex-perimental results show that: (1) theWSM is able to achieve tonal (sylla-bles input with four tones) and tone-less (syllables input without four tones)syllable-to-word (STW) accuracies of99% and 92%, respectively, among theconverted words; and (2) while apply-ing the WSM as an adaptation proc-essing, together with the MicrosoftInput Method Editor 2003 (MSIME)and an optimized bigram model, theaverage tonal and toneless STW im-provements are 37% and 35%, respec-tively.1 IntroductionAccording to (Becker, 1985; Huang, 1985; Gu etal., 1991; Chung, 1993; Kuo, 1995; Fu et al,1996; Lee et al, 1997; Hsu et al, 1999; Chen etal., 2000; Tsai and Hsu, 2002; Gao et al, 2002;Lee, 2003; Tsai, 2005), the approaches of Chi-nese input methods (i.e.
Chinese input systems)can be classified into two types: (1) keyboardbased approach: including phonetic and pinyinbased (Chang et al, 1991; Hsu et al, 1993; Hsu,1994; Hsu et al, 1999; Kuo, 1995; Lua and Gan,1992), arbitrary codes based (Fan et al, 1988)and structure scheme based (Huang, 1985); and(2) non-keyboard based approach: includingoptical character recognition (OCR) (Chung,1993), online handwriting (Lee et al, 1997) andspeech recognition (Fu et al, 1996; Chen et al,2000).
Currently, the most popular Chinese in-put system is phonetic and pinyin based ap-proach, because Chinese people are taught towrite phonetic and pinyin syllables of each Chi-nese character in primary school.In Chinese, each Chinese word can be amono-syllabic word, such as ??
(mouse)?, a bi-syllabic word, such as ???
(kangaroo)?, or amulti-syllabic word, such as ????(Mickeymouse).?
The corresponding phonetic and pin-yin syllables of each Chinese word is called syl-lable-words, such as ?dai4 shu3?
is the pinyinsyllable-word of ???(kangaroo).?
Accordingto our computation, the {minimum, maximum,average} words per each distinct mono-syllable-word and poly-syllable-word (including bi-syllable-word and multi-syllable-word) in theCKIP dictionary (Chinese Knowledge Informa-tion Processing Group, 1995) are {1, 28, 2.8}and {1, 7, 1.1}, respectively.
The CKIP diction-ary is one of most commonly-used Chinese dic-tionaries in the research field of Chinese naturallanguage processing (NLP).
Since the size ofproblem space for syllable-to-word (STW) con-version is much less than that of syllable-to-character (STC) conversion, the most pinyin-based Chinese input systems (Hsu, 1994; Hsu etal., 1999; Tsai and Hsu, 2002; Gao et al, 2002;Microsoft Research Center in Beijing; Tsai,2005) are addressed on STW conversion.
On theother hand, STW conversion is the main task ofChinese Language Processing in typical Chinesespeech recognition systems (Fu et al, 1996; Leeet al, 1993; Chien et al, 1993; Su et al, 1992).As per (Chung, 1993; Fong and Chung, 1994;Tsai and Hsu, 2002; Gao et al, 2002; Lee, 2003;Tsai, 2005), homophone selection and syllable-word segmentation are two critical problems indeveloping a Chinese input system.
Incorrecthomophone selection and syllable-word seg-842mentation will directly influence the STW con-version accuracy.
Conventionally, there are twoapproaches to resolve the two critical problems:(1) linguistic approach: based on syntax parsing,semantic template matching and contextual in-formation (Hsu, 1994; Fu et al, 1996; Hsu et al,1999; Kuo, 1995; Tsai and Hsu, 2002); and (2)statistical approach: based on the n-gram mod-els where n is usually 2, i.e.
bigram model (Linand Tsai, 1987; Gu et al, 1991; Fu et al, 1996;Ho et al, 1997; Sproat, 1990; Gao et al, 2002;Lee 2003).
From the studies (Hsu 1994; Tsaiand Hsu, 2002; Gao et al, 2002; Kee, 2003; Tsai,2005), the linguistic approach requires consider-able effort in designing effective syntax rules,semantic templates or contextual information,thus, it is more user-friendly than the statisticalapproach on understanding why such a systemmakes a mistake.
The statistical language model(SLM) used in the statistical approach requiresless effort and has been widely adopted in com-mercial Chinese input systems.In our previous work (Tsai, 2005), a word-pair (WP) identifier was proposed and shown asimple and effective way to improve Chineseinput systems by providing tonal and tonelessSTW accuracies of 98.5% and 90.7% on theidentified poly-syllabic words, respectively.
In(Tsai, 2005), we have shown that the WP identi-fier can be used to reduce the over weightingand corpus sparseness problems of bigram mod-els and achieve better STW accuracy to improveChinese input systems.
As per our computation,poly-syllabic words cover about 70% charactersof Chinese sentences.
Since the identified char-acter ratio of the WP identifier (Tsai, 2005) isabout 55%, there are still about 15% improvingroom left.The objective of this study is to illustrate aword support model (WSM) that is able to im-prove our WP-identifier by achieving betteridentified character ratio and STW accuracy onthe identified poly-syllabic words with the sameword-pair database.
We conduct STW experi-ments to show the tonal and toneless STW accu-racies of a commercial input product (MicrosoftInput Method Editor 2003, MSIME), and anoptimized bigram model, BiGram (Tsai, 2005),can both be improved by our WSM and achievebetter STW improvements than that of thesesystems with the WP identifier.The remainder of this paper is arranged asfollows.
In Section 2, we present an auto word-pair (AUTO-WP) generation used to generatethe WP database.
Then, we develop a word sup-port model with the WP database to performSTW conversion on identifying words from theChinese syllables.
In Section 3, we report andanalyze our STW experimental results.
Finally,in Section 4, we give our conclusions and sug-gest some future research directions.2 Development of Word Support ModelThe system dictionary of our WSM is comprisedof 82,531 Chinese words taken from the CKIPdictionary and 15,946 unknown words auto-found in the UDN2001 corpus by a ChineseWord Auto-Confirmation (CWAC) system (Tsaiet al, 2003).
The UDN2001 corpus is a collec-tion of 4,539624 Chinese sentences extractedfrom whole 2001 UDN (United Daily News,2001) Website in Taiwan (Tsai and Hsu, 2002).The system dictionary provides the knowledgeof words and their corresponding pinyin sylla-ble-words.
The pinyin syllable-words weretranslated by phoneme-to-pinyin mappings, suchas ????-to-?ju2.
?2.1 Auto-Generation of WP DatabaseFollowing (Tsai, 2005), the three steps of auto-generating word-pairs (AUTO-WP) for a givenChinese sentence are as below: (the details ofAUTO-WP can be found in (Tsai, 2005))Step 1.
Get forward and backward word seg-mentations: Generate two types of wordsegmentations for a given Chinese sen-tence by forward maximum matching(FMM) and backward maximum match-ing (BMM) techniques (Chen et al, 1986;Tsai et al, 2004) with the system diction-ary.Step 2.
Get initial WP set: Extract all the com-binations of word-pairs from the FMMand the BMM segmentations of Step 1 tobe the initial WP set.Step 3.
Get finial WP set: Select out the word-pairs comprised of two poly-syllabicwords from the initial WP set into the fin-ial WP set.
For the final WP set, if theword-pair is not found in the WP data-843base, insert it into the WP database andset its frequency to 1; otherwise, increaseits frequency by 1.2.2 Word Support ModelThe four steps of our WSM applied to identifywords for a given Chinese syllables is as follows:Step 1.
Input tonal or toneless syllables.Step 2.
Generate all possible word-pairs com-prised of two poly-syllabic words for theinput syllables to be the WP set of Step 3.Step 3.
Select out the word-pairs that match aword-pair in the WP database to be theWP set.
Then, compute the word sup-port degree (WS degree) for each dis-tinct word of the WP set.
The WS degreeis defined to be the total number of theword found in the WP set.
Finally, ar-range the words and their correspondingWS degrees into the WSM set.
If thenumber of words with the same syllable-word and WS degree is greater than one,one of them is randomly selected into theWSM set.Step 4.
Replace words of the WSM set in de-scending order of WS degree with the in-put syllables into a WSM-sentence.
If nowords can be identified in the input sylla-bles, a NULL WSM-sentence is produced.Table 1 is a step by step example to show thefour steps of applying our WSM on the Chinesesyllables ?sui1 ran2 fu3 shi2 jin4 shi4 sui4 yue4xi1 xu1(??????????).?
For thisinput syllables, we have a WSM-sentence ???????????.?
For the same syllables,outputs of the MSIME, the BiGram and the WPidentifier are ???????????,?
????????????
and ???
fu3 shi2 ?
?sui4 yue4 xi1 xu1.
?3 STW ExperimentsTo evaluate the STW performance of our WSM,we define the STW accuracy, identified charac-ter ratio (ICR) and STW improvement, by thefollowing equations:STW accuracy = # of correct characters / # oftotal characters.
(1)Identified character ratio (ICR) = # of charactersof identified WP / # of total characters in testingsentences.
(2)STW improvement (I) (i.e.
STW error reductionrate) = (accuracy of STW system with WP ?accuracy of STW system)) / (1 ?
accuracy ofSTW system).
(3)Step # ResultsStep.1 sui1 ran2 fu3 shi2 jin4 shi4 sui4 yue4 xi1 xu1(?
?
?
?
?
?
?
?
?
?
)Step.2 WP set (word-pair / word-pair frequency) ={??-?
?/6 (key WP for WP identifier),??-?
?/4, ??-?
?/4, ??-??/3,??-?
?/2, ??-?
?/2, ??-??/2,??-?
?/2, ??-?
?/2, ??-??/2,??-?
?/2}Step.3 WSM set (word / WS degree) ={?
?/5, ?
?/4, ?
?/4, ?
?/4, ??/4,?
?/1}Replaced word set =??
(sui1 ran2), ??
(fu3 shi2),??
(jin4 shi4), ??
(sui4 yue4),??
(xi1 xu1)Step.4 WSM-sentence:?????????
?Table 1.
An illustration of a WSM-sentence forthe Chinese syllables ?sui1 ran2 fu3 shi2 jin4shi4 sui4 yue4 xi1 xu1(??????????).
?3.1 BackgroundTo conduct the STW experiments, firstly, usethe inverse translator of phoneme-to-character(PTC) provided in GOING system to converttesting sentences into their corresponding sylla-bles.
All the error PTC translations of GOINGPTC were corrected by post human-editing.Then, apply our WSM to convert the testinginput syllables back to their WSM-sentences.Finally, calculate its STW accuracy and ICR byEquations (1) and (2).
Note that all test sen-tences are composed of a string of Chinesecharacters in this study.The training/testing corpus, closed/open testsets and system/user WP database used in thefollowing STW experiments are described asbelow:844(1) Training corpus: We used the UDN2001corpus as our training corpus, which is a col-lection of 4,539624 Chinese sentences ex-tracted from whole 2001 UDN (United DailyNews, 2001) Website in Taiwan (Tsai andHsu, 2002).
(2) Testing corpus: The Academia Sinica Bal-anced (AS) corpus (Chinese Knowledge In-formation Processing Group, 1996) wasselected as our testing corpus.
The AS corpusis one of most famous traditional Chinese cor-pus used in the Chinese NLP research field(Thomas, 2005).
(3) Closed test set: 10,000 sentences were ran-domly selected from the UDN2001 corpus asthe closed test set.
The {minimum, maximum,and mean} of characters per sentence for theclosed test set are {4, 37, and 12}.
(4) Open test set: 10,000 sentences were ran-domly selected from the AS corpus as theopen test set.
At this point, we checked thatthe selected open test sentences were not inthe closed test set as well.
The {minimum,maximum, and mean} of characters per sen-tence for the open test set are {4, 40, and 11}.
(5) System WP database: By applying theAUTO-WP on the UDN2001 corpus, we cre-ated 25,439,679 word-pairs to be the systemWP database.
(6) User WP database: By applying ourAUTO-WP on the AS corpus, we created1,765,728 word-pairs to be the user WP data-base.We conducted the STW experiment in a pro-gressive manner.
The results and analysis of theexperiments are described in Subsections 3.2and 3.3.3.2 STW Experiment Results of the WSMThe purpose of this experiment is to demon-strate the tonal and toneless STW accuraciesamong the identified words by using the WSMwith the system WP database.
The comparativesystem is the WP identifier (Tsai, 2005).
Table2 is the experimental results.
The WP databaseand system dictionary of the WP identifier issame with that of the WSM.From Table 2, it shows the average tonal andtoneless STW accuracies and ICRs of the WSMare all greater than that of the WP identifier.These results indicate that the WSM is a betterway than the WP identifier to identify poly-syllabic words for the Chinese syllables.Closed   Open    Average (ICR)Tonal (WP)    99.1%    97.7%    98.5% (57.8%)Tonal (WSM)    99.3%    97.9%    98.7% (71.3%)Toneless (WP)     94.0%    87.5%    91.3% (54.6%)Toneless (WSM)    94.4%    88.1%    91.6% (71.0%)Table 2.
The comparative results of tonal andtoneless STW experiments for the WP identifierand the WSM.3.3 STW Experiment Results of ChineseInput Systems with the WSMWe selected Microsoft Input Method Editor2003 for Traditional Chinese (MSIME) as ourexperimental commercial Chinese input system.In addition, following (Tsai, 2005), an opti-mized bigram model called BiGram was devel-oped.
The BiGram STW system is a bigram-based model developing by SRILM (Stolcke,2002) with Good-Turing back-off smoothing(Manning and Schuetze, 1999), as well as for-ward and backward longest syllable-word firststrategies (Chen et al, 1986; Tsai et al, 2004).The system dictionary of the BiGram is samewith that of the WP identifier and the WSM.Table 3a compares the results of the MSIME,the MSIME with the WP identifier and theMSIME with the WSM on the closed and opentest sentences.
Table 3b compares the results ofthe BiGram, the BiGram with the WP identifierand the BiGram with the WSM on the closedand open test sentences.
In this experiment, theSTW output of the MSIME with the WP identi-fier and the WSM, or the BiGram with the WPidentifier and the WSM, was collected by di-rectly replacing the identified words of the WPidentifier and the WSM from the correspondingSTW output of the MSIME and the BiGram.Ms         Ms+WP (I)a         Ms+WSM (I)bTonal     94.5%    95.5% (18.9%)    95.9% (25.6%)Toneless    85.9%    87.4% (10.1%)    88.3% (16.6%)a STW accuracies and improvements of the words identi-fied by the MSIME (Ms) with the WP identifierb STW accuracies and improvements of the words identi-fied by the MSIME (Ms) with the WSMTable 3a.
The results of tonal and toneless STWexperiments for the MSIME, the MSIME withthe WP identifier and with the WSM.845Bi          Bi+WP (I)a        Bi+WSM (I)bTonal     96.0%    96.4% (8.6%)     96.7% (17.1%)Toneless    83.9%    85.8% (11.9%)    87.5% (22.0%)a STW accuracies and improvements of the words identi-fied by the BiGram (Bi) with the WP identifierb STW accuracies and improvements of the words identi-fied by the BiGram (Bi) with the WSMTable 3b.
The results of tonal and toneless STWexperiments for the BiGram, the BiGram withthe WP identifier and with the WSM.From Table 3a, the tonal and toneless STWimprovements of the MSIME by using the WPidentifier and the WSM are (18.9%, 10.1%) and(25.6%, 16.6%), respectively.
From Table 3b,the tonal and toneless STW improvements ofthe BiGram by using the WP identifier and theWSM are (8.6%, 11.9%) and (17.1%, 22.0%),respectively.
(Note that, as per (Tsai, 2005), thedifferences between the tonal and toneless STWaccuracies of the BiGram and the TriGram areless than 0.3%).Table 3c is the results of the MSIME and theBiGram by using the WSM as an adaptationprocessing with both system and user WP data-base.
From Table 3c, we get the average tonaland toneless STW improvements of the MSIMEand the BiGram by using the WSM as an adap-tation processing are 37.2% and 34.6%, respec-tively.Ms+WSM (ICR, I)a   Bi+WSM (ICR, I) bTonal   96.8% (71.4%, 41.7%)   97.3% (71.4%, 32.6%)Toneless  90.6% (74.6%, 33.2%)   97.3% (74.9%, 36.0%)a STW accuracies, ICRs and improvements of the wordsidentified by the MSIME (Ms) with the WSMb STW accuracies, ICRs and improvements of the wordsidentified by the BiGram (Bi) with the WSMTable 3c.
The results of tonal and toneless STWexperiments for the MSIME and the BiGramusing the WSM as an adaptation processing.To sum up the above experiment results, weconclude that the WSM can achieve a betterSTW accuracy than that of the MSIME, the Bi-Gram and the WP identifier on the identified-words portion.
(Appendix A presents two casesof STW results that were obtained from thisstudy).3.4 Error AnalysisWe examine the Top 300 STW conversions inthe tonal and toneless from the open testing re-sults of the BiGram with the WP identifier andthe WSM, respectively.
As per our analysis, theSTW errors are caused by three problems, theyare:(1) Unknown word (UW) problem: For ChineseNLP systems, unknown word extraction isone of the most difficult problems and acritical issue.
When an STW error is causedonly by the lack of words in the system dic-tionary, we call it unknown word problem.
(2) Inadequate Syllable-Word Segmentation(ISWS) problem: When an error is causedby ambiguous syllable-word segmentation(including overlapping and combinationambiguities), we call it inadequate syllable-word segmentation problem.
(3) Homophone selection problem: The remain-ing STW conversion error is homophoneselection problem.Problem                      CoverageTonal              TonelessWP, WSM             WP, WSMUW          3%,  4%             3%,   4%ISWS   32%, 32%          58%, 56%HS   65%, 64%          39%, 40%# of error characters 170, 153             506, 454# of error characters of 100, 94              159, 210mono-syllabic words# of error characters of     70, 59              347, 244poly-syllabic wordsTable 4.
The analysis results of the STW errorsfrom the Top 300 tonal and toneless STW con-versions of the BiGram with the WP identifierand the WSM.Table 4 is the analysis results of the three STWerror types.
From Table 4, we have three obser-vations:(1) The coverage of unknown word problem fortonal and toneless STW conversions issimilar.
In most Chinese input systems, un-known word extraction is not specifically aSTW problem, therefore, it is usually takencare of through online and offline manualediting processing (Hsu et al 1999).
Theresults of Table 4 show that the most STWerrors should be caused by ISWS and HS846problems, not UW problem.
This observa-tion is similarly with that of our previouswork (Tsai, 2005).
(2) The major problem of error conversions intonal and toneless STW systems is differ-ent.
This observation is similarly with thatof (Tsai, 2005).
From Table 4, the majorimproving targets of tonal STW perform-ance are the HS errors because more than50% tonal STW errors caused by HS prob-lem.
On the other hand, since the ISWS er-rors cover more than 50% toneless STWerrors, the major targets of improving tone-less STW performance are the ISWS errors.
(3) The total number of error characters of theBiGram with the WSM in tonal and tone-less STW conversions are both less thanthat of the BiGram with the WP identifier.This observation should answer the ques-tion ?Why the STW performance of Chi-nese input systems (MSIME and BiGram)with the WSM is better than that of thesesystems with the WP-identifier?
?To sum up the above three observations and allthe STW experimental results, we conclude thatthe WSM is able to achieve better STW im-provements than that of the WP identifier is be-cause: (1) the identified character ratio of theWSM is 15% greater than that of the WP identi-fier with the same WP database and dictionary,and meantime (2) the WSM not only can main-tain the ratio of the three STW error types butalso can reduce the total number of error charac-ters of converted words than that of the WPidentifier.4 Conclusions and Future DirectionsIn this paper, we present a word support model(WSM) to improve the WP identifier (Tsai,2005) and support the Chinese Language Proc-essing on the STW conversion problem.
All ofthe WP data can be generated fully automati-cally by applying the AUTO-WP on the givencorpus.
We are encouraged by the fact that theWSM with WP knowledge is able to achievestate-of-the-art tonal and toneless STW accura-cies of 99% and 92%, respectively, for the iden-tified poly-syllabic words.
The WSM can beeasily integrated into existing Chinese inputsystems by identifying words as a post process-ing.
Our experimental results show that, by ap-plying the WSM as an adaptation processingtogether with the MSIME (a trigram-like model)and the BiGram (an optimized bigram model),the average tonal and toneless STW improve-ments of the two Chinese input systems are37% and 35%, respectively.Currently, our WSM with the mixed WP da-tabase comprised of UDN2001 and AS WP da-tabase is able to achieve more than 98%identified character ratios of poly-syllabicwords in tonal and toneless STW conversionsamong the UDN2001 and the AS corpus.
Al-though there is room for improvement, we be-lieve it would not produce a noticeable effect asfar as the STW accuracy of poly-syllabic wordsis concerned.We will continue to improve our WSM tocover more characters of the UDN2001 and theAS corpus by those word-pairs comprised of atleast one mono-syllabic word, such as ???(we)-?(are)?.
In other directions, we will ex-tend it to other Chinese NLP research topics,especially word segmentation, main verb identi-fication and Subject-Verb-Object (SVO) auto-construction.ReferencesBecker, J.D.
1985.
Typing Chinese, Japanese, andKorean, IEEE Computer 18(1):27-34.Chang, J.S., S.D.
Chern and C.D.
Chen.
1991.
Con-version of Phonemic-Input to Chinese TextThrough Constraint Satisfaction, Proceedingsof ICCPOL'91, 30-36.Chen, B., H.M. Wang and L.S.
Lee.
2000.
Retrievalof broadcast news speech in Mandarin Chinesecollected in Taiwan using syllable-level statisti-cal characteristics, Proceedings of the 2000 In-ternational Conference on Acoustics Speechand Signal Processing.Chen, C.G., Chen, K.J.
and Lee, L.S.
1986.
A modelfor Lexical Analysis and Parsing of ChineseSentences, Proceedings of 1986 InternationalConference on Chinese Computing, 33-40.Chien, L.F., Chen, K.J.
and Lee, L.S.
1993.
A Best-First Language Processing Model Integratingthe Unification Grammar and Markov Lan-guage Model for Speech Recognition Applica-tions, IEEE Transactions on Speech and AudioProcessing, 1(2):221-240.Chung, K.H.
1993.
Conversion of Chinese PhoneticSymbols to Characters, M. Phil.
thesis, De-partment of Computer Science, Hong Kong847University of Science and Technology.Chinese Knowledge Information Processing Group.1995.
Technical Report no.
95-02, the contentand illustration of Sinica corpus of AcademiaSinica.
Institute of Information Science, Aca-demia Sinica.Chinese Knowledge Information Processing Group.1996.
A study of Chinese Word Boundaries andSegmentation Standard for Information proc-essing (in Chinese).
Technical Report, Taiwan,Taipei, Academia Sinica.Fong, L.A. and K.H.
Chung.
1994.
Word Segmenta-tion for Chinese Phonetic Symbols, Proceed-ings of International Computer Symposium,911-916.Fu, S.W.K, C.H.
Lee and Orville L.C.
1996.
A Sur-vey on Chinese Speech Recognition, Communi-cations of COLIPS, 6(1):1-17.Gao, J., Goodman, J., Li, M. and Lee K.F.
2002.
To-ward a Unified Approach to Statistical Lan-guage Modeling for Chinese, ACMTransactions on Asian Language InformationProcessing, 1(1):3-33.Gu, H.Y., C.Y.
Tseng and L.S.
Lee.
1991.
Markovmodeling of mandarin Chinese for decoding thephonetic sequence into Chinese characters,Computer Speech and Language 5(4):363-377.Ho, T.H., K.C.
Yang, J.S.
Lin and L.S.
Lee.
1997.Integrating long-distance language modeling tophonetic-to-text conversion, Proceedings ofROCLING X International Conference onComputational Linguistics, 287-299.Hsu, W.L.
and K.J.
Chen.
1993.
The Semantic Analy-sis in GOING - An Intelligent Chinese InputSystem, Proceedings of the Second Joint Con-ference of Computational Linguistics, Shiamen,1993, 338-343.Hsu, W.L.
1994.
Chinese parsing in a phoneme-to-character conversion system based on semanticpattern matching, Computer Processing of Chi-nese and Oriental Languages 8(2):227-236.Hsu, W.L.
and Chen, Y.S.
1999.
On Phoneme-to-Character Conversion Systems in ChineseProcessing, Journal of Chinese Institute ofEngineers, 5:573-579.Huang, J.K. 1985.
The Input and Output of Chineseand Japanese Characters, IEEE Computer18(1):18-24.Kuo, J.J. 1995.
Phonetic-input-to-character conver-sion system for Chinese using syntactic connec-tion table and semantic distance, ComputerProcessing and Oriental Languages, 10(2):195-210.Lee, L.S., Tseng, C.Y., Gu, H..Y., Liu F.H., Chang,C.H., Lin, Y.H., Lee, Y., Tu, S.L., Hsieh, S.H.,and Chen C.H.
1993.
Golden Mandarin (I) - AReal-Time Mandarin Speech Dictation Machinefor Chinese Language with Very Large Vocabu-lary, IEEE Transaction on Speech and AudioProcessing, 1(2).Lee, C.W., Z. Chen and R.H. Cheng.
1997.
A pertur-bation technique for handling handwritingvariations faced in stroke-based Chinese char-acter classification, Computer Processing ofOriental Languages, 10(3):259-280.Lee, Y.S.
2003.
Task adaptation in Stochastic Lan-guage Model for Chinese Homophone Disam-biguation, ACM Transactions on AsianLanguage Information Processing, 2(1):49-62.Lin, M.Y.
and W.H.
Tasi.
1987.
Removing the ambi-guity of phonetic Chinese input by the relaxa-tion technique, Computer Processing andOriental Languages, 3(1):1-24.Lua, K.T.
and K.W.
Gan.
1992.
A Touch-Typing Pin-yin Input System, Computer Processing of Chi-nese and Oriental Languages, 6:85-94.Manning, C. D. and Schuetze, H. 1999.
Fundationsof Statistical Natural Language Processing,MIT Press: 191-220.Microsoft Research Center in Beijing,?http://research.microsoft.com/aboutmsr/labs/beijing/?Qiao, J., Y. Qiao and S. Qiao.
1984.
Six-Digit CodingMethod, Commun.
ACM 33(5):248-267.Sproat, R. 1990.
An Application of Statistical Opti-mization with Dynamic Programming to Pho-nemic-Input-to-Character Conversion forChinese, Proceedings of ROCLING III, 379-390.Stolcke A.
2002.
SRILM - An Extensible LanguageModeling Toolkit, Proc.
Intl.
Conf.
SpokenLanguage Processing, Denver.Su, K.Y., Chiang, T.H.
and Lin, Y.C.
1992.
A Uni-fied Framework to Incorporate Speech andLanguage Information in Spoken LanguageProcessing, ICASSP-92, 185-188.Thomas E. 2005.
The Second International ChineseWord Segmentation Bakeoff, In Proceedings ofthe Fourth SIGHAN Workshop on Chinese Lan-guage Processing, Oct. Jeju, Koera, 123-133.Tsai, J.L.
and W.L.
Hsu.
2002.
Applying an NVEFWord-Pair Identifier to the Chinese Syllable-to-Word Conversion Problem, Proceedings of 19thCOLING 2002, 1016-1022.Tsai, J,L, Sung, C.L.
and Hsu, W.L.
2003.
ChineseWord Auto-Confirmation Agent, Proceedingsof ROCLING XV, 175-192.848Tsai, J.L., Hsieh, G. and Hsu, W.L.
2004.
Auto-Generation of NVEF knowledge in Chinese,Computational Linguistics and Chinese Lan-guage Processing, 9(1):41-64.Tsai, J.L.
2005.
Using Word-Pair Identifier to Im-prove Chinese Input System, Proceedings ofthe Fourth SIGHAN Workshop on ChineseLanguage Processing, IJCNLP2005, 9-16.United Daily News.
2001.
On-Line United DailyNews, http://udnnews.com/NEWS/Appendix A.
Two cases of the STW re-sults used in this study.Case I.
(a) Tonal STW results for the Chinese tonal syl-lables ?guan1 yu2 liang4 xing2 suo3 sheng1zhi1 shi4 shi2?
of the Chinese sentence ??????????
?Methods  STW resultsWP set  ??-?
?/4  (key WP),??-?
?/3, ??-??/1,??-?
?/1WSM Set ??
(guan1 yu2)/3, ??
(liang4 xing2)/2,??
(shi4 shi2)/2, ??
(zhi1 shi4)/1WP-sentence ??
liang4 xing2 suo3 sheng1??
shi2WSM-sentence ????
suo3 sheng1 zhi1?
?MSIME  ????????
?MSIME+WP ????????
?MSIME+WSM      ????????
?BiGram  ????????
?BiGram+WP ????????
?BiGram+WSM ?????????
(b) Toneless STW results for the Chinese tone-less syllables ?guan yu liang xing suo sheng zhishi shi?
of the Chinese sentence ??????????
?Methods  STW resultsWP set  ??/?
?/4 (key WP),??/?
?/4, ??/??/3,??/?
?/2, ??/??/2,??/?
?/2, ??/??/1,??/?
?/1, ??/??/1,??/?
?/1, ??/??/1,??/?
?/1WSM Set ??
(guan yu)/7, ??
(shi shi)/4,??
(liang xing)/3, ??
(liang xing)/2,??
(zhi shi)/2, ??
(shi shi)/2,??
(shi shi)/1, ??
(guan yu)/1,??
(shengzhi)/1WP-sentence ??
liang xing suo sheng zhi?
?WSM-sentence ????
suo???
?MSIME  ????????
?MSIME+WP ????????
?MSIME+WSM      ????????
?BiGram  ????????
?BiGram+WP ????????
?BiGram+WSM ????????
?Case II.
(a) Tonal STW results for the Chinese tonal syl-lables ?you2 yu2 xian3 he4 de5 jia1 shi4?
of theChinese sentence ????????
?Methods  STW resultsWP set  ??/?
?/6 (key WP),??/?
?/2, ??/??/2??/?
?/1, ??/?
?/1WSM set  ??
(you2 yu2)/4, ??
(xian 3he4)/2,??
(jia1 shi4)/2, ??
(jia1 shi4)/1WP-sentence ??
xian2 he4 de5?
?WSM-sentence ????
de?
?MSIME  ??????
?MSIME+WP ??????
?MSIME+SWM      ??????
?BiGram  ??????
?BiGram+WP ??????
?BiGram+SWM ???????
(b) Toneless STW results for the Chinese tone-less syllables ?you yu xian he de jia shi?
of theChinese sentence ????????
?Methods  STW resultsWP set  ??-?
?/14 (key WP),??-?
?/6, ??-??/6??/?
?/2, ??/??/2??/?
?/1, ??/?
?/1WSM set  ??
(you yu)/6, ??
(xian he)/2,??
(jia shi)/2, ??
(jia shi)/1WP-sentence ??
xian he de?
?WSM-sentence ????
de?
?MSIME  ??????
?MSIME+WP ??????
?MSIME+SWM      ??????
?BiGram  ??????
?BiGram+WP ??????
?BiGram+SWM ??????
?849
