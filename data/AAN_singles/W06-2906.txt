Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 37?44, New York City, June 2006. c?2006 Association for Computational LinguisticsResolving and Generating Definite Anaphoraby Modeling Hypernymy using Unlabeled CorporaNikesh Garera and David YarowskyDepartment of Computer ScienceCenter for Language and Speech ProcessingJohns Hopkins UniversityBaltimore, MD 21218, USA{ngarera,yarowsky}@cs.jhu.eduAbstractWe demonstrate an original and success-ful approach for both resolving and gen-erating definite anaphora.
We proposeand evaluate unsupervised models for ex-tracting hypernym relations by mining co-occurrence data of definite NPs and po-tential antecedents in an unlabeled cor-pus.
The algorithm outperforms a stan-dard WordNet-based approach to resolv-ing and generating definite anaphora.
Italso substantially outperforms recent re-lated work using pattern-based extractionof such hypernym relations for corefer-ence resolution.1 IntroductionSuccessful resolution and generation of definiteanaphora requires knowledge of hypernym and hy-ponym relationships.
For example, determining theantecedent to the definite anaphor ?the drug?
in textrequires knowledge of what previous noun-phrasecandidates could be drugs.
Likewise, generating adefinite anaphor for the antecedent ?Morphine?
intext requires both knowledge of potential hypernyms(e.g.
?the opiate?, ?the narcotic?, ?the drug?, and?the substance?
), as well as selection of the most ap-propriate level of generality along the hypernym treein context (i.e.
the ?natural?
hypernym anaphor).Unfortunately existing manual hypernym databasessuch as WordNet are very incomplete, especiallyfor technical vocabulary and proper names.
Word-Nets are also limited or non-existent for most of theworld?s languages.
Finally, WordNets also do notinclude notation of the ?natural?
hypernym level foranaphora generation, and using the immediate par-ent performs quite poorly, as quantified in Section 5.In first part of this paper, we propose a novel ap-proach for resolving definite anaphora involving hy-ponymy relations.
We show that it performs substan-tially better than previous approaches on the task ofantecedent selection.
In the second part we demon-strate how this approach can be successfully ex-tended to the problem of generating a natural def-inite NP given a specific antecedent.In order to explain the antecedent selection task fordefinite anaphora clearly, we provide the follow-ing example taken from the LDC Gigaword corpus(Graff et al, 2005).
(1)...pseudoephedrine is found in an allergy treat-ment, which was given to Wilson by a doctor whenhe attended Blinn junior college in Houston.
In aunanimous vote, the Norwegian sports confedera-tion ruled that Wilson had not taken the drug to en-hance his performance...In the above example, the task is to resolvethe definite NP the drug to its correct antecedentpseudoephedrine, among the potential antecedents<pseudoephedrine, allergy, blinn, college, hous-ton, vote, confederation, wilson>.
Only Wilson canbe ruled out on syntactic grounds (Hobbs, 1978).To be able to resolve the correct antecedent fromthe remaining potential antecedents, the system re-quires the knowledge that pseudoephedrine is adrug.
Thus, the problem is to create such a knowl-edge source and apply it to this task of antecedentselection.
A total of 177 such anaphoric examples37were extracted randomly from the LDC Gigawordcorpus and a human judge identified the correct an-tecedent for the definite NP in each example (given acontext of previous sentences).1 Two human judgeswere asked to perform the same task over the sameexamples.
The agreement between the judges was92% (of all 177 examples), indicating a clearly de-fined task for our evaluation purposes.We describe an unsupervised approach to this taskthat extracts examples containing definite NPs froma large corpus, considers all head words appearingbefore the definite NP as potential antecedents andthen filters the noisy<antecedent, definite-NP> pairusing Mutual Information space.
The co-occurencestatistics of such pairs can then be used as a mecha-nism for detecting a hypernym relation between thedefinite NP and its potential antecedents.
We com-pare this approach with a WordNet-based algorithmand with an approach presented by Markert and Nis-sim (2005) on resolving definite NP coreference thatmakes use of lexico-syntactic patterns such as ?Xand Other Ys?
as utilized by Hearst (1992).2 Related workThere is a rich tradition of work using lexical and se-mantic resources for anaphora and coreference res-olution.
Several researchers have used WordNet asa lexical and semantic resource for certain types ofbridging anaphora (Poesio et al, 1997; Meyer andDale, 2002).
WordNet has also been used as an im-portant feature in machine learning of coreferenceresolution using supervised training data (Soon etal., 2001; Ng and Cardie, 2002).
However, sev-eral researchers have reported that knowledge incor-porated via WordNet is still insufficient for definiteanaphora resolution.
And of course, WordNet is notavailable for all languages and is missing inclusionof large segments of the vocabulary even for cov-ered languages.
Hence researchers have investigateduse of corpus-based approaches to build a Word-Net like resource automatically (Hearst, 1992; Cara-1The test examples were selected as follows: First, allthe sentences containing definite NP ?The Y?
were extractedfrom the corpus.
Then, the sentences containing instancesof anaphoric definite NPs were kept and other cases of defi-nite expressions (like existential NPs ?The White House?,?Theweather?)
were discarded.
From this anaphoric set of sentences,177 sentence instances covering 13 distinct hypernyms wererandomly selected as the test set and annotated for the correctantecedent by human judges.ballo, 1999; Berland and Charniak, 1999).
Also,several researchers have applied it to resolving dif-ferent types of bridging anaphora (Clark, 1975).Poesio et al (2002) have proposed extracting lexicalknowledge about part-of relations using Hearst-stylepatterns and applied it to the task of resolving bridg-ing references.
Poesio et al (2004) have suggestedusing Google as a source of computing lexical dis-tance between antecedent and definite NP for mere-ological bridging references (references referring toparts of an object already introduced).
Markert et al(2003) have applied relations extracted from lexico-syntactic patterns such as ?X and other Ys?
for Other-Anaphora (referential NPs with modifiers other oranother) and for bridging involving meronymy.There has generally been a lack of work in the exist-ing literature for automatically building lexical re-sources for definite anaphora resolution involvinghyponyms relations such as presented in Example(1).
However, this issue was recently addressed byMarkert and Nissim (2005) by extending their workon Other-Anaphora using lexico syntactic pattern ?Xand other Y?s to antecedent selection for definite NPcoreference.
However, our task is more challeng-ing since the anaphoric definite NPs in our test setinclude only hypernym anaphors without includingthe much simpler cases of headword repetition andother instances of string matching.
For direct eval-uation, we also implemented their corpus-based ap-proach and compared it with our models on identicaltest data.We also describe and evaluate a mechanism for com-bining the knowledge obtained from WordNet andthe six corpus-based approaches investigated here.The resulting models are able to overcome the weak-nesses of a WordNet-only model and substantiallyoutperforms any of the individual models.3 Models for Lexical Acquisition3.1 TheY-ModelOur algorithm is motivated by the observation that ina discourse, the use of the definite article (?the?)
in anon-deictic context is primarily licensed if the con-cept has already been mentioned in the text.
Hence asentence such as ?The drug is very expensive?
gen-erally implies that either the word drug itself waspreviously mentioned (e.g.
?He is taking a new drugfor his high cholesterol.?)
or a hyponym of drug was38previously mentioned (e.g.
?He is taking Lipitor forhis high cholesterol.?).
Because it is straightforwardto filter out the former case by string matching, theresidual instances of the phrase ?the drug?
(withoutprevious mentions of the word ?drug?
in the dis-course) are likely to be instances of hypernymic def-inite anaphora.
We can then determine which nounsearlier in the discourse (e.g.
Lipitor) are likely an-tecedents by unsupervised statistical co-occurrencemodeling aggregated over the entire corpus.
All weneed is a large corpus without any anaphora annota-tion and a basic tool for noun tagging and NP headannotation.
The detailed algorithm is as follows:1.
Find each sentence in the training corpus thatcontains a definite NP (?the Y?)
and does notcontain ?a Y?, ?an Y?
or other instantiations ofY2 appearing before the definite NP within afixed window.32.
In the sentences that pass the above definite NPand a/an test, regard all the head words (X) oc-curring in the current sentence before the defi-nite NP and the ones occurring in previous twosentences as potential antecedents.3.
Count the frequency c(X,Y) for each pair ob-tained in the above two steps and pre-store it ina table.4 The frequency table can be modifiedto give other scores for pair(X,Y) such as stan-dard TF-IDF and Mutual Information scores.4.
Given a test sentence having an anaphoric def-inite NP Y, consider the nouns appearing be-fore Y within a fixed window as potential an-tecedents.
Rank the candidates by their pre-computed co-occurence measures as computedin Step 3.Since we consider all head words preceding the defi-nite NP as potential correct antecedents, the raw fre-quency of the pair (X ,Y ) can be very noisy.
Thiscan be seen clearly in Table 1, where the first col-umn shows the top potential antecedents of definiteNP the drug as given by raw frequency.
We nor-malize the raw frequency using standard TF-IDF2While matching for both ?the Y?
and ?a/an Y?, we also ac-count for Nouns getting modified by other words such as adjec-tives.
Thus ?the Y?
will still match to ?the green and big Y?.3Window size was set to two sentences, we also experi-mented with a larger window size of five sentences and the re-sults obtained were similar.4Note that the count c(X,Y) is asymmetricRank Raw freq TF-IDF MI1 today kilogram amphetamine2 police heroin cannabis3 kilogram police cocaine4 year cocaine heroin5 heroin today marijuana6 dollar trafficker pill7 country officer hashish8 official amphetamine tabletTable 1: A sample of ranked hyponyms proposed forthe definite NP The drug by TheY-Model illustrat-ing the differences in weighting methods.Acc Acctag Av RankMI 0.531 0.577 4.82TF-IDF 0.175 0.190 6.63Raw Freq 0.113 0.123 7.61Table 2: Results using different normalization tech-niques for the TheY-Model in isolation.
(60 millionword corpus)and Mutual Information scores to filter the noisypairs.5 In Table 2, we report our results for an-tecedent selection using Raw frequency c(X,Y), TF-IDF 6 and MI in isolation.
Accuracy is the fractionof total examples that were assigned the correct an-tecedent and Accuracytag is the same excluding theexamples that had POS tagging errors for the cor-rect antecedent.7 Av Rank is the rank of the trueantecedent averaged over the number of test exam-ples.8 Based on the above experiment, the rest ofthis paper assumesMutual Information scoring tech-nique for TheY-Model.5Note that MI(X,Y ) = log P (X,Y )P (X)P (Y ) and this is directlyproportional to P (Y |X) = c(X,Y )c(X) for a fixed Y .
Thus, wecan simply use this conditional probability during implementa-tion since the definite NP Y is fixed for the task of antecedentselection.6For the purposes of TF-IDF computation, document fre-quency df(X) is defined as the number of unique definite NPsfor which X appears as an antecedent.7Since the POS tagging was done automatically, it is possi-ble for any model to miss the correct antecedent because it wasnot tagged correctly as a noun in the first place.
There were 14such examples in the test set and none of the model variants canfind the correct antecdent in these instances.8Knowing average rank can be useful when a n-best rankedlist from coreference task is used as an input to other down-stream tasks such as information extraction.39Acc Acctag Av RankTheY+WN 0.695 0.755 3.37WordNet 0.593 0.644 3.29TheY 0.531 0.577 4.82Table 3: Accuracy and Average Rank showing com-bined model performance on the antecedent selec-tion task.
Corpus Size: 60 million words.3.2 WordNet-Model (WN)Because WordNet is considered as a standard re-source of lexical knowledge and is often used incoreference tasks, it is useful to know how wellcorpus-based approaches perform as compared toa standard model based on the WordNet (version2.0).9 The algorithm for the WordNet-Model is asfollows:Given a definite NP Y and its potential antecedentX, choose X if it occurs as a hyponym (either director indirect inheritance) of Y.
If multiple potential an-tecedents occur in the hierarchy of Y, choose the onethat is closest in the hierarchy.3.3 Combination: TheY+WordNet ModelMost of the literature on using lexical resourcesfor definite anaphora has focused on using individ-ual models (either corpus-based or manually buildresources such as WordNet) for antecedent selec-tion.
Some of the difficulties with using WordNet isits limited coverage and its lack of empirical rank-ing model.
We propose a combination of TheY-Model andWordNet-Model to overcome these prob-lems.
Essentially, we rerank the hypotheses foundin WordNet-Model based on ranks of TheY-modelor use a backoff scheme if WordNet-Model does notreturn an answer due to its limited coverage.
Givena definite NP Y and a set of potential antecedents Xsthe detailed algorithm is specified as follows:1.
Rerank with TheY-Model: Rerank the potentialantecedents found in the WordNet-Model ta-ble by assiging them the ranks given by TheY-Model.
If TheY-Model does not return a rankfor a potential antecedent, use the rank given by9We also computed the accuracy using a weaker baseline,namely, selecting the closest previous headword as the correctantecedent.
This recency based baseline obtained a low accu-racy of 15% and hence we used the stronger WordNet basedmodel for comparison purposes.the WordNet-Model.
Now pick the top rankedantecedent after reranking.2.
Backoff: If none of the potential antecedentswere found in the WordNet-Model then pickthe correct antecedent from the ranked list ofThe-Y model.
If none of the models return ananswer then assign ranks uniformly at random.The above algorithm harnesses the strength ofWordNet-Model to identify good hyponyms and thestrength of TheY-model to identify which are morelikely to be used as an antecedent.
Note that thiscombination algorithm can be applied using anycorpus-based technique to account for poor-rankingand low-coverage problems of WordNet and theSections 3.4, 3.5 and 3.6 will show the results forbacking off to a Hearst-style hypernym model.
Ta-ble 4 shows the decisions made by TheY-model,WordNet-Model and the combined model for a sam-ple of test examples.
It is interesting to see how boththe models mutually complement each other in thesedecisions.
Table 3 shows the results for the modelspresented so far using a 60 million word training textfrom the Gigaword corpus.
The combined model re-sults in a substantially better accuracy than the indi-vidual WordNet-Model and TheY-Model, indicatingits strong merit for the antecedent selection task.103.4 OtherY-ModelfreqThis model is a reimplementation of the corpus-based algorithm proposed by Markert and Nissim(2005) for the equivalent task of antecedent selec-tion for definite NP coreference.
We implement theirapproach of using the lexico-syntactic pattern X andA* other B* Y{pl} for extracting (X,Y) pairs.The A*and B* allow for adjectives or other modifiers to beplaced in between the pattern.
The model presentedin their article uses the raw frequency as the criteriafor selecting the antecedent.3.5 OtherY-ModelMI (normalized)We normalize the OtherY-Model using Mutual In-formation scoring method.
Although Markert andNissim (2005) report that using Mutual Informationperforms similar to using raw frequency, Table 5shows that using Mutual Information makes a sub-stantial impact on results using large training cor-pora relative to using raw frequency.10The claim is statistically significant with a p < 0.01 ob-tained by sign-test40Summary Keyword True TheY Truth WordNet Truth TheY+WN Truth(Def.
Ana) Antecedent Choice Rank Choice Rank Choice RankBoth metal gold gold 1 gold 1 gold 1correct sport soccer soccer 1 soccer 1 soccer 1TheY-Model drug steroid steroid 1 NA NA steroid 1helps drug azt azt 1 medication 2 azt 1WN-Model instrument trumpet king 10 trumpet 1 trumpet 1helps drug naltrexone alcohol 14 naltrexone 1 naltrexone 1Both weapon bomb artillery 3 NA NA artillery 3incorrect instrument voice music 9 NA NA music 9Table 4: A sample of output from different models on antecedent selection (60 million word corpus).3.6 Combination: TheY+OtherYMI ModelOur two corpus-based approaches (TheY and Oth-erY) make use of different linguistic phenomena andit would be interesting to see whether they are com-plementary in nature.
We used a similar combina-tion algorithm as in Section 3.3 with the WordNet-Model replaced with the OtherY-Model for hyper-nym filtering, and we used the noisy TheY-Modelfor reranking and backoff.
The results for this ap-proach are showed as the entry TheY+OtherYMI inTable 5.
We also implemented a combination (Oth-erY+WN) of Other-Y model and WordNet-Modelby replacing TheY-Model with OtherY-Model in thealgorithm described in Section 3.3.
The respectiveresults are indicated as OtherY+WN entry in Table5.4 Further Anaphora Resolution ResultsTable 5 summarizes results obtained from all themodels defined in Section 3 on three different sizesof training unlabeled corpora (from Gigaword cor-pus).
The models are listed from high accuracy tolow accuracy order.
The OtherY-Model performsparticularly poorly on smaller data sizes, where cov-erage of the Hearst-style patterns maybe limited,as also observed by Berland and Charniak (1999).We further find that the Markert and Nissim (2005)OtherY-Model and our MI-based improvement doshow substantial relative performance growth at in-creased corpus sizes, although they still underper-form our basic TheY-Model at all tested corpussizes.
Also, the combination of corpus-based mod-els (TheY-Model+OtherY-model) does indeed per-forms better than either of them in isolation.
Fi-nally, note that the basic TheY-algorithm still doesAcc Acctag Av Rank60 million wordsTheY+WN 0.695 0.755 3.37OtherYMI+WN 0.633 0.687 3.04WordNet 0.593 0.644 3.29TheY 0.531 0.577 4.82TheY+OtherYMI 0.497 0.540 4.96OtherYMI 0.356 0.387 5.38OtherYfreq 0.350 0.380 5.39230 million wordsTheY+WN 0.678 0.736 3.61OtherYMI+WN 0.650 0.705 2.99WordNet 0.593 0.644 3.29TheY+OtherYMI 0.559 0.607 4.50TheY 0.519 0.564 4.64OtherYMI 0.503 0.546 4.37OtherYfreq 0.418 0.454 4.52380 million wordsTheY+WN 0.695 0.755 3.47OtherYMI+WN 0.644 0.699 3.03WordNet 0.593 0.644 3.29TheY+OtherYMI 0.554 0.601 4.20TheY 0.537 0.583 4.26OtherYMI 0.525 0.571 4.20OtherYfreq 0.446 0.485 4.36Table 5: Accuracy and Average Rank of Models de-fined in Section 3 on the antecedent selection task.41relatively well by itself on smaller corpus sizes,suggesting its merit on resource-limited languageswith smaller available online text collections and theunavailability of WordNet.
The combined modelsof WordNet-Model with the two corpus-based ap-proaches still significantly (p < 0.01) outperformany of the other individual models.115 Generation TaskHaving shown positive results for the task of an-tecedent selection, we turn to a more difficult task,namely generating an anaphoric definite NP givena nominal antecedent.
In Example (1), this wouldcorrespond to generating ?the drug?
as an anaphorknowing that the antecedent is pseudoephedrine.This task clearly has many applications: current gen-eration systems often limit their anaphoric usage topronouns and thus an automatic system that doeswell on hypernymic definite NP generation can di-rectly be helpful.
It also has strong potential appli-cation in abstractive summarization where rewritinga fluent passage requires a good model of anaphoricusage.There are many interesting challenges in this prob-lem: first of all, there maybe be multiple acceptablechoices for definite anaphor given a particular an-tecedent, complicating automatic evaluation.
Sec-ond, when a system generates a definite anaphora,the space of potential candidates is essentially un-bounded, unlike in antecdent selection, where it islimited only to the number of potential antecedentsin prior context.
In spite of the complex natureof this problem, our experiments with the humanjudgements, WordNet and corpus-based approachesshow a simple feasible solution.
We evaluate ourautomatic approaches based on exact-match agree-ment with definite anaphora actually used in the cor-pus (accuracy) and also by agreement with definiteanaphora predicted independently by a human judgein an absence of context.11Note that syntactic co-reference candidate filters such asthe Hobbs algorithm were not utilized in this study.
To assessthe performance implications, the Hobbs algorithm was appliedto a randomly selected 100-instance subset of the test data.
Al-though the Hobbs algorithm frequently pruned at least one ofthe coreference candidates, in only 2% of the data did such can-didate filtering change system output.
However, since both ofthese changes were improvements, it could be worthwhile toutilize Hobbs filtering in future work, although the gains wouldlikely be modest.5.1 Human experimentWe extracted a total of 103 <true antecedent, defi-nite NP> pairs from the set of test instances used inthe resolution task.
Then we asked a human judge (anative speaker of English) to predict a parent classof the antecedent that could act as a good definiteanaphora choice in general, independent of a par-ticular context.
Thus, the actual corpus sentencecontaining the antecedent and definite NP and itscontext was not provided to the judge.
We tookthe predictions provided by the judge and matchedthem with the actual definite NPs used in the corpus.The agreement between corpus and the human judgewas 79% which can thus be considered as an upperbound of algorithm performance.
Table 7 shows asample of decisions made by the human and howthey agree with the definite NPs observed in the cor-pus.
It is interesting to note the challenge of thesense variation and figurative usage.
For example,?corruption?
is refered to as a ?tool?
in the actualcorpus anaphora, a metaphoric usage that would bedifficult to predict unless given the usage sentenceand its context.
However, a human agreement of79% indicate that such instances are relatively rareand the task of predicting a definite anaphor with-out its context is viable.
In general, it appears fromour experiements that humans tend to select froma relatively small set of parent classes when gener-ating hypernymic definite anaphora.
Furthermore,there appears to be a relatively context-independentconcept of the ?natural?
level in the hypernym hi-erarchy for generating anaphors.
For example, al-though <?alkaloid?, ?organic compound?, ?com-pound?, ?substance?, ?entity?> are all hypernymsof ?Pseudoephederine?
in WordNet, ?the drug?appears to be the preferred hypernym for definiteanaphora in the data, with the other alternatives be-ing either too specific or too general to be natural.This natural level appears to be difficult to define byrule.
For example, using just the immediate parenthypernym in the WordNet hierarchy only achieves4% match with the corpus data for definite anaphorgeneration.5.2 AlgorithmsThe following sections presents our corpus-based al-gorithms as more effective alternatives.42Agreement Agreementw/ human w/ corpusjudgeTheY+OtherY+WN 47% 46%OtherY +WN 43% 43%TheY+WN 42% 37%TheY +OtherY 39% 36%OtherY 39% 36%WordNet 4% 4%Human judge 100% 79%Corpus 79% 100%Table 6: Agreement of different generation modelswith human judge and with definite NP used in thecorpus.5.2.1 Individual ModelsFor the corpus-based approaches, the TheY-Modeland OtherY-Model were trained in the same manneras for the antecedent selection task.
The only differ-ence was that in the generation case, the frequencystatistics were reversed to provide a hypernym givena hyponym.
Additionally, we found that raw fre-quency outperformed either TF-IDF or Mutual In-formation and was used for all results in Table 6.The stand-alone WordNet model is also very simple:Given an antecedent, we lookup its direct hypernym(using first sense) in the WordNet and use it as thedefinite NP, for lack of a better rule for preferred hy-pernym location.5.2.2 Combining corpus-based approaches andWordNetEach of the corpus-based approaches was combinedwith WordNet resulting in two different models asfollows: Given an antecedent X, the corpus-basedapproach looks up in its table the hypernym of X,for example Y, and only produces Y as the output ifY also occurs in the WordNet as hypernym.
ThusWordNet is used as a filtering tool for detecting vi-able hypernyms.
This combination resulted in twomodels: ?TheY+WN?
and ?OtherY+WN?.We also combined all the three approaches, ?TheY?,?OtherY?
and WordNet resulting in a single model?TheY+OtherY+WN?.
This was done as follows: Wefirst combine the models ?TheY?
and ?OtherY?
usinga backoff model.
The first priority is to use the hy-Antecedent Corpus Human TheY+OtherYDef Ana Choice +WNracing sport sport sportazt drug drug drugmissile weapon weapon weaponalligator animal animal animalsteel metal metal metalosteporosis disease disease conditiongrenade device weapon devicebaikonur site city stationcorruption tool crime activityTable 7: Sample of decisions made by hu-man judge and our best performing model(TheY+OtherY+WN) on the generation task.pernym from the model ?OtherY?, if not found thenuse the hypernym from the model ?TheY?.
Given adefinite NP from the backoff model, apply theWord-Net filtering technique, specifically, choose it as thecorrect definite NP if it also occurs as a hypernym inthe WordNet hierarchy of the antecedent.5.3 Evaluation of Anaphor GenerationWe evaluated the resulting algorithms from Section5.2 on the definite NP prediction task as describedearlier.
Table 6 shows the agreement of the algo-rithm predictions with the human judge as well aswith the definite NP actually observed in the corpus.It is interesting to see that WordNet by itself per-forms very poorly on this task since it does not haveany word-specific mechanism to choose the correctlevel in the hierarchy and the correct word sense forselecting the hypernym.
However, when combinedwith our corpus-based approaches, the agreementincreases substantially indicating that the corpus-based approaches are effectively filtering the spaceof hypernyms that can be used as natural classes.Likewise, WordNet helps to filter the noisy hyper-nyms from the corpus predictions.
Thus, this inter-play between the corpus-based and WordNet alo-rithm works out nicely, resulting in the best modelbeing a combination of all three individual modelsand achieving a substantially better agreement withboth the corpus and human judge than any of the in-dividual models.
Table 7 shows decisions made bythis algorithm on a sample test data.436 ConclusionThis paper provides a successful solution to theproblem of incomplete lexical resources for definiteanaphora resolution and further demonstrates howthe resources built for resolution can be naturally ex-tended for the less studied task of anaphora genera-tion.
We first presented a simple and noisy corpus-based approach based on globally modeling head-word co-occurrence around likely anaphoric definiteNPs.
This was shown to outperform a recent ap-proach byMarkert and Nissim (2005) that makes useof standard Hearst-style patterns extracting hyper-nyms for the same task.
Even with a relatively smalltraining corpora, our simple TheY-model was ableto achieve relatively high accuracy, making it suit-able for resource-limited languages where annotatedtraining corpora and full WordNets are likely notavailable.
We then evaluated several variants of thisalgorithm based on model combination techniques.The best combined model was shown to exceed 75%accuracy on the resolution task, beating any of theindividual models.
On the much harder anaphorageneration task, where the stand-alone WordNet-based model only achieved an accuracy of 4%, weshowed that our algorithms can achieve 35%-47%accuracy on blind exact-match evaluation, thus mo-tivating the use of such corpus-based learning ap-proaches on the generation task as well.AcknowledgementsThanks to Charles Schafer for sharing his tools onPOS/Headword tagging for the Gigaword corpus.ReferencesM.
Berland and E. Charniak.
1999.
Finding parts invery large corpora.
In Proceedings of the 37th AnnualMeeting of the Association for Computational Linguis-tics, pages 57?64.S.
Caraballo.
1999.
Automatic construction of ahypernym-labeled noun hierarchy from text.
In Pro-ceedings of the 37th Annual Meeting of the Associationfor Computational Linguistics, pages 120?126.H.
H. Clark.
1975.
Bridging.
In Proceedings of theConference on Theoretical Issues in Natural LanguageProcessing, pages 169?174.D.
Connoly, J. D. Burger, and D. S. Day.
1997.
A ma-chine learning approach to anaphoric reference.
InProceedings of the International Conference on NewMethods in Language Processing, pages 133?144.D.
Graff, J. Kong, K. Chen, and K. Maeda.
2005.
En-glish Gigaword Second Edition.
Linguistic Data Con-sortium, catalog number LDC2005T12.S.
Harabagiu, R. Bunescu, and S. J. Maiorano.
2001.Text and knowledge mining for coreference resolu-tion.
In Proceedings of the Second Meeting of theNorth American Chapter of the Association for Com-putational Linguistics, pages 55?62.M.
Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proceedings of the 14th In-ternational Conference on Computational Linguistics,pages 539?545.J.
Hobbs.
1978.
Resolving pronoun references.
Lingua,44:311?338.K.
Markert and M. Nissim.
2005.
Comparing knowl-edge sources for nominal anaphora resolution.
Com-putational Linguistics, 31(3):367?402.K.
Markert, M. Nissim, and N. N. Modjeska.
2003.
Us-ing the web for nominal anaphora resolution.
In Pro-ceedings of the EACL Workshop on the ComputationalTreatment of Anaphora, pages 39?46.J.
Meyer and R. Dale.
2002.
Mining a corpus to sup-port associative anaphora resolution.
In Proceedingsof the Fourth International Conference on DiscourseAnaphora and Anaphor Resolution.V.
Ng and C. Cardie.
2002.
Improving machine learn-ing approaches to coreference resolution.
In Proceed-ings of the 40th Annual Meeting of the Association forComputational Linguistics, pages 104?111.M.
Poesio, R. Vieira, and S. Teufel.
1997.
Resolvingbridging references in unrestricted text.
In Proceed-ings of the ACL Workshop on Operational Factors inRobust Anaphora, pages 1?6.M.
Poesio, T. Ishikawa, S. Schulte im Walde, andR.
Viera.
2002.
Acquiring lexical knowledge foranaphora resolution.
In Proccedings of the Third Con-ference on Language Resources and Evaluation, pages1220?1224.M.
Poesio, R. Mehta, A. Maroudas, and J. Hitzeman.2004.
Learning to resolve bridging references.
In Pro-ceedings of the 42nd Annual Meeting of the Associa-tion for Computational Linguistics, pages 143?150.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
A ma-chine learning approach to coreference resolution ofnoun phrases.
Computational Linguistics, 27(4):521?544.M.
Strube, S. Rapp, and C. Mu?ller.
2002.
The influ-ence of minimum edit distance on reference resolution.In Proceedings of the 2002 Conference on EmpiricalMethods in Natural Language Processing, pages 312?319.R.
Vieira and M. Poesio.
2000.
An empirically-basedsystem for processing definite descriptions.
Computa-tional Linguistics, 26(4):539?593.X.
Yang, G. Zhou, J. Su, and C. L. Tan.
2003.
Corefer-ence resolution using competition learning approach.In Proceedings of the 41st Annual Meeting of the Asso-ciation for Computational Linguistics, pages 176?183.44
