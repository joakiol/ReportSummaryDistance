TWO DISCOURSE GENERATORSWilliam C. MannUSC Information Sciences InstituteWHAT IS DISCOURSE GENERATION?The task of discourse generation is to produce multisentential text innatural language which (when heard or read) produces effects(informing, motivating, etc.)
and impressions (conciseness,correctness, ease of reading, etc.)
which are appropriate to a need orgoal held by the creator of the text.Because even little children can produce multieententiaJ text, the task ofdiscourse generation appears deceptively easy.
It is actually extremelycomplex, in part because it usually involves many different kinds ofknowledge.
The skilled writer must know the subiect matter, the beliefsof the reader and his own reasons for writing.
He must also know thesyntax, semantics, inferential patterns, text structures and words of thelanguage.
It would be complex enough if these were all independentbodies of knowledge, independently employed.
Unfortunately, they areall interdependent in intricate ways.
The use of each must becoordinated with all of the others.For Artificial Intelligence, discourse generation is an unsolved problem.There have been only token efforts to date, and no one has addressedthe whole problem.
Still, those efforts reveal the nature of the task,what makes it diffic;,It and how the complexities can be controlled.In comparing two AI discourse generators here we can do no more thansuggest opportunities and attractive options for future exploration.Hopefully we can convey the benefits of hindsight without too muchdetailed description of the individual systems.
We describe them only interms of a few of the techniques which they employ, partly becausethese tschnk:lUes seem more vaJuable than the system designs in whichthey happen to have been used.THE TWO SYSTEMSThe systems which we study here are PROTEUS, by Anthony Davey atEdinburgh \[Davey 79\], and KDS by Mann and Moore at ISI \[Mann andMoore 801.
As we will see, each is severely limited and idiosyncratic inscope and technique.
Comparison of their individual skills reveals sometechnical opportunities.Why do we study these systems rather then others?
Both of themrepresent recent developments, in Davey's case, recently published.Neither of them has the appearance of following a hand-drawn map orsome' other humanly-produced sequential presentation.
Thus theirperformance represents capabilities of the programs more thancs4)abilities of the programmer.
Also, they are relatively unfamiliar tothe AI audience.
Perhaps most importantly, they have written someof the best machine-produced iscourse of the existing art.Rrst we identify particular techniclues in each system which contributestrongly to the quality of the resulting text.
Then we compare the twoSystems discussing their common failings and the possibilities forcreating a system having the best of both.DAVEY'S PROTEUSPROTEUS creates commentary on games of tic.tac-toe (noughts andcrosses.)
Despite the apparent simplicity of this task, the possibilities ofproducing text are rich and diverse.
(See the example in Appendix .
)The commentary is intended both to convey the game (except forinsignificant variations of rotation and reflection), and also to conveythe significance of each move, including showing errors and missedopportunities.PROTEUS can be construed as consisting of three 13rincipalprocessors, as shown in Figure 1.Move characterization employs a ranked set of move generators,each identified as defensive or offensive, and each identified furtherwith a named tactic such as blocking, forking or completing a win.
Amove is characterized as being a use of the tactic which isassociated with the highest-ranked move generator which cangenerate that move in the present situation?
The purpose of movecharacterizaiton is to intefl:ret he facts so that they become significantto the reader.
(Implicitly, the system embodies a theory of thesignificance of facts.
)Game TranscriptinI i i=.
ASTO=O   l I Move AN0 I' 1!
I C)~'TP..~MtNATION I ISENTENCEGENERATIONCommentaryoutFigure 1 : Principal Processors of PROTEUSContrast arises between certain time-adiacent moves and alsobetween an actual move and alternative possibilities at the same point.For example:?
Best move VS. Actual move: The move generators areused to compute the "best" move, which is compared tothe actual one.
If the move generator for the best move hashigher rank than any generator proposing the actual move,then the actual move is treated as s mistake, putting thebest move and the actual move in contrast..Threat VS. Block: A threat contrasts with animmediately following block.
This contrast is a fixedreflexof the system.
It seems accedteble to mark any goal pursuitfollowed by blocking of the goaJ as contrastive.Sentence scope is determined by several heuristic rules includingI.
Express as many contrasts as possible explicitly.
(Thisleeds to immediate selection of words such as "but" and"however".)432.
Limit sentences to ,3 clauses.3.
Put as many clauses in a sentence as possible.4.
Expmas only the worst of several mistakes.The main clause struotum is built before entering the grammar,Both the move characterization process and the use of contrasts as theprincipal ~ of sentence scope contribute a great deal to the qualityof the resuRing text.
However, Davey's central concern was not withthese two 9rocessos but with the third one, sentence generation.
Hissystem includes an elaborate Systemic Grammar, which he de,scribes indatall in \[Devey 79\].
The grammar draws on work of Halliday \[Halliday76\], Hudson \[Hudson 71\], Winograd \[Winograd 72\], Sinctalr \[Sinclair72\], i~uddleston \[Huddlaston 71\] and F_ K. Brown, following H,..,d_~_nmost closely.1Hudson's work offers a number of significant advantages to anyonecomddering implementing adiscoume generation system.I.
ComDrehensivaness- Its coverage of English is moreextensive than comparable work.2.
Explicitness.
the rules are spelled out in full in formalnotation.3.
Unity.
Since the grammar is defined in a single pubilcalionwith a single 8uthomhiD, the is*ups of compatibility Of partsare minimized,It is intemsUng that Oevey does not employ the Systemk: Grlmm~lrdehvstJon rules at the highest level Although the grammer is defined interms of the generation of sentences, Devoy entem it at the clause levelwith 8 sents~cs desc~Dtlon whi?
;h conforms to Systemic Grammar butwas built by other means.
A sentence st this level is temporalprincipally of Ctl-_,,~__.
but the surface conjunotlens have alreadybeen chosen.Although Oavey real(as no claim, this may redrasent a gener~d resultabout text generation systems.
Above some level of al:atnm~on in thetext planning proces~ planning is not conditioned by the content of thegrammar.
The obvious place to exbeot planning tO becomeindegendertt of the grammar is at the sentence I~ .
But in bothPROTEUS and KD.~ Operations independent of the grammar extenddown to the level of independent c lm within sentences.
Top leve~coniunctlons am not within such ci~,~__; so they are determined byDlenning p r ~  before the grammar is enter~l.It would be extremely awkward to implement Oavey'$ sentence s?obeheuristics in a syetamic grammar.
The formalism is not well suited foroDer~tion~ such as maximizing the total number of explicit contrastive(dements.
However, the problem is not just a i~rololem with theformalism; grammars generally do not deal with this sort of operations,and so are ~oorly equil~ped to do so.them i~ no need to "rw~nm" it.
G~mo~ ~ dlvid~d imo ~ Id~ ~ &?~Iv~.mle-ll3t~lca~nL A sylmlm of choi?.e~ (surJ1 u t~e ch~?~ i~lt~men - d ~  -ind"~mm,e" kT,~,-,~ de.minim *,vh~J~ cm "ai~-ttve') is mech~ ~ othercboP~a ~d w is ?ond i~m?.
but cny ch~?e.
~?e mechU,  ".. , .m,~m~rair,~L .
Ru~S~lUenc~ femunl-emL ejcn ~ t l~  "We~l."
~ml?~ enet~le i ed?~ m,l~?ltu~enl n~ tm'efenemmnLAlthough the computer scientist who tries to learn from \[Oavey 79} willfind that it presents difficulties, the underlying system is interestingenough to be worth the trouble.
Devey's imDiementation generallyallam~s to be orthodox, conforming to \[Hudson 71\].
Daveyregularizes some of the rules toward type uniformity, and thus reducesthe apparent correspondence to Hudson's formulabons.
However, thelinguistic babe does not appear to have been compromised by theimplementation.One of the major strengths of the work is that it takes advantage of scomprehenal~, explicit and linguistically justified grammar.Text quality is also enhanced by some simple filtering (of what will beexpressed) based on demmdencies between known facts.
Some factsdominate otherJ in the choice of what tO Say.
If them is only one moveon the board having a certain significance, say "threat", then the moveis described by its significance alone, e.g.
"you threatened me" withoutlocation informatic, n, since the reader can infer the locations.
Similarly,only the most significant defensive and offensive aspects of a move atedescribed even though all are known.The resulting text is d ivn)  and of good quality.
Although them ereawlo~mrdn __es,~__~ the immense advantage conferred by using asophisticated grammar prevails.MANN AND MOORE'S KDSMajor Modules of KDSSOace precJudes a thocou0h description of KDS, but fuller deecriptioneare mml~ie \[Mann and Moore 80\], \[Mann 79\], \[Moore 7%KDS consists Of five me~r modules, as indicated in Figure 2.
AFrl~lmentM is re~oonalble for eXtnL~ing the relevant knowledge fromthe notation given to it and dividing that knowledge into smallexl:nmalble units, which we call fragments or pmtosentance?
AProd=~m Solver, a goal-Oumuit engine in the AI tradition, is responsiblefor seeotlng the I~eUntmlm~d style of me text and ~ for iml~l~ngthe grol8 ol~glmlze~Ion onto the text accordlng to m8~ style.
AKnowk~ge Rater removes protasentencas that need not be expressedbecause they would be redundant to the medsr.KDS MODULf:S MODULE RESPONSIBILITIESi?
ExtmcHon of knowledgeFRAGMENTER from exteffmJ notation?
D;v~sion ;ere express;bJe clauses"P'ROBLEM SOLVER ?
Style se|ection?
Gross erc, l'cm;zat|on of textKNOWLEDGE FILTER * Cogn;tive redundancy removalHILL CLIMBER * Composltion of concepts?
Sentence quaJ;~ seek|n~e Fermi text ~'m=tion SURFACE SENTENCEMAKERFigure 2: KDS Module ResgonsibilltissThe I~est  and moat interesting r~__,_,~e is the Hill Climber, which hasthree raspon~billtis?
tO compose complex i:rotoasntences from simpMone~ tO judge relative quality among the units resulting fromcompo~dtton, and to repeatedly improve the set of protosentencas onthe Ioasm of those judgments so thM it is of the highest eyeful quality.Finally.
s very simple Surface Sentence Maker cremes the sentences ofme final text out of protoaec~lmc~.44The data flow of these modules can be thought of as a simple pipeline,each module processing the relevant knowledge in turn.The principal contributors to the quality of the output text are:1.
The Fragment and Compose Paradigm: The informationwhich will be expressed is first broken down into anunorganized collection of subsententiai (?oproximstelyclause-level) propositional fragments.
Each fragment iscrested by methods which guarantee that it is expressibleby a sentence (usually a very short one, This makes itpossible to organize the remainder of the processing sothat the text production problen~ is treated as animprovement problem rather than as a search for feasiblesolutions, a significant advantage.)
The fragments are thenorganized and combined in the remaining processing.2.
Aggregation Rules: Clause-combining patterns of Englishare represented in a distinct set of rules.
The rules specifytransactions on the set of propositional fragments andprevious aggregation results.
In each transection severalfragments are extracted and an aggregate structure(capable of representation as a sentence) is inserted.
Arepresentative rule, named "Common Cause," shows howto combine the facts for "Whenever C then X" and"Whenever C then Y" into "Whenever C then X and Y" at spropositional level.3.
Preference Assessment: Every propositional fragment oraggregate is scored using a set of scoring rules.
The scorerepresents measure of sentence quality.4, Hill Ctimbing: Aggregation and Preference Assessment areaJternated under the control of a hill-climbing algorithmwhich seek.
's to maximize the overall quality of thecollection, i.e.
of the complete text.
This allows a cleanseparation of the knowledge of what could be said from thechoice of whet should be said.5.
Knowledge Filtering: Propositions identified by an extolicitmodel of the Reader's knowledge as known to the readerare not exl:resasd.The knowledge domain of KDS' largest example is a Fire Crisis domain,the knowledge of what happens when there is a fire in a computerroom.
The task was to cause the reader, a computer operator, to knowwhat to do in all contingencies of fire.SYSTEI~ 1 (~OMPARISONSThe most striking impression in comparing the two systems is that theyhave very little in common.
In particular,1.
KDS has sentence scoring and a quslity.based selection ofI~ow to say things; PROTEUS has no counterp;u't.2.
PROTEUS has a sophisticated grammar for which KOS hasonly a rudimentary counterpart,3.
PROTEUS has only a dynamic, redundancy-basedP, nowledge filtering, whereas the filtering in KOS removesprincipally St=~tic, foreknown information.4.
KDS has clause-combining rules which make little use ofconjunctions, whereas PROTEUS has no such rules butmakes elaborate use of coniunctions.5.
KOS selects for brevity above all, whereas PROTEUSselects for contrast =hove all.6.
PROTEUS takes great advantage of fact significanceassessment, which KDS does not use.They have little in common technically, yet both produce high qualitytext relative to predecessors.
This raises an obvious question-- Couldthe techniques of the two systems be combined in an even moreeffective system?There is one prominent exception to this general lack of sharedfunctions and characteristics, Recent text synthesis systems \[Davey79\], \[Mann end Moore 80\], \[Weiner 80\], \[Swartout 77\],\[Swartoutthesis 81\], all include a facility for keeping certain facts orideas from being expressed.
There is an implicit or explicit model of thereader's knowledge.
Any knowledge which is somehow seen asobvious to the reader is suppressed.All of the implemented facilities of this sort are rudimentary; manyconsist only of manually-ornduced lists or marks.
However, it is clearthat they cover a deep intellectual problem.
Discourse generation mustmake differing uses of what the reader knows and what the reader doesnot know.It is absolutely essential to avoid tedious statement of "the obvious.
"Proper use of presupposition (which has not yet been attemptedcomputationally) likewise depends on this knowledge, and many of thetechniques for maintaining coherence depend on it as well.
Butidentification of what is obvious to a reader is a difficult and mostlyunexplored problem.
Clearly, inference is deeply involved, but what is"obvious" does not match what is validly inferable.
It appears that ascomputer-generated texts become larger the need for a robust model ofthe obvious will increase rapidly.POSSIBILITIES FOR SYNTHESISThis section views the collection of techniques which have beendiscussed so far from the point of view of a designer of a future textsynthesis system.
What are the design constraints which affect thepossibility of particular combinations of these techniques?
Whatcombinations are advantageous?
Since each system represents acompatible collection of techniques, it is only necessary to examinecompatibility of the techniques of one system within the framework ofthe other.We begin by examining the hypothetical introduction of the KDStechniques of fragmentation, the explicit reader model, aggregation,preference scoring and hill climbing into PROTEUS.
We then examinethe hypothetical introduction of PROTEUS' grammar, fact significanceassessments and use of the contrast heuristic into KDS.
Finally weconsider use of each system on the other's knowledge domain.Introducing KDS teohniques into PROTEUSFragment and Compose is clearly usable within PROTEUS, since theinformation on the sequence of moves, particularmove locations and the significance of each moveall can be regarded as composed of manyincleDendent propositions (fragments of the wholestructure.)
However, Fragment and Composeappears to give only small benefits, principallybecause the linear sequences of tic-tac-toe gametranscripts give an acceptable organization and donot preclude many interesting texts.Aggregation is also useable, and would appear to allow for a greater45diverSity of sentence forms than Oavey's Secluentialassembly torocedures allow.
In KDS, andpresumably in PROTEUS as well, aggregation rulescan be used to make text brief, in effect, PROTEUSalready has some aggregation, since the way itsuses of conjunction shorten the text is similar toeffects of aggregation rules in KDS.Prefei'ence judgment and Hill climbing are interQependent in KDS.Introducing both into PROTEUS would appear togive great improvement, especially in avoiding thelong awkward referring phrases which PROTEUSi=roduced.
The system could detect the excessivelylong constructs and give them lower scores, leadingto choice of shorter sentences in those cases.The Explicit Reader model could also be used directly in PROTEUS; itwould not help much however, since relatively littleforeknowledge is involved in any tic-tac-toe gamecommentary/.Introducing PROTEUS techniques into KDSSystemic Grammar could be introduced into KDS to great advantage.The KDS grammar was deliberately chosen to berudimentary in order to facilitate exploration abovethe sentence level.
(In fact.
KDS could not beextended in any interesting way without ulxJradingits grammar.)
Even with a Systemic Grammar inKDS, aggregation rules would remain, functioningas sentence design elements.Fact significance assessments are also compatible with the KDSdesign.
As in PROTEUS they would immediatelyfollow aoduialtion of the basic grogositianeL Theycould improve the text significantly.The contrast heuristic (and other PROTEUS heuristics) would fit wellinto KDS, not as an a priori sentence design devicebut as a basis for assigning preference.
Higherscore for contrast would improve the text.In summary, the principal techniques appear to be completelycompatible, and the combination would surely produce bettertext than either system alone.Exchange of Knowledge DomainsThe tic-tac-toe domain would fit early into KDS` but the KOStext-organization Drocesles (not discuased in this I:~ger) would havelittJe to do.
The fire crisis domain would be too complex for PROTEUS.It involves several actorS at once, several parallel contingencies and nosingle clear organizing principle.
PROTEUS lacks the necessarytext-organization methods.SHARED SHORTCOMINGSThese systems share (with many others) the i=rimitive state of thecomputer.be,sad discourse-generation a~.
Their groce~,~l are\[=rimarily devoted to activities that go without notice among literateI~eogle.
The deeper linguistic and metorical phenomena usuallyassociated with the term "discourse" are hardly touched.
Thesesystems make little attempt at coherence, and they do not respond inamy way to the coherence (or lack of it) which they achieve.Presupposition, topic, focus, theme, the pro~er role of inference,imglicature, direct and indirect Sl:~ech act performance and a host ofother relevant concepts all go unrepresented.
Even wome, the46underlying conceotual agpars.tus in both systems is extremely adhocand idiosyncratic, severely limiting the I=OSSiblities for using generalknowledge of the semantics of English.Despite these deficiencies, the systems produce relatively smoothreadable texL They are significant principally as collections of methodswhich may well survive to become l=arts of more competent andgeneral.purOose systems of the future.CONCLUSIONSPROTEUS and KDS are distinct collections of discourse generationtechniques.
There is little overlap between them, and no a~patentconflict involved in using the techniques in combination.
A systemwhich combined the strengths of both would be significantly better thaneither.APPENDIX: TEXT SAMPLES FROM THE T~NO SYSTEMSKDS: Fire-Alarm Text for Computer OperstorsWhenever there is a fire, the alarm system is started,which soul!de a bell and starts a timer.
Ninety seconds after?
e timer startlk unless the alarm system is cancelled, thesystem calls Wells Fargo.
When Wells Fargo is called, they,in turn, call the Fire Department.When you hear the alarm bell or smell smoke, stopwhatever you are doing, determine whether or not there is a?
fire, and decide whether to permit the ala~;m system or tocancel it.
When you determine whether there is a fire, ifthere is, permit the alarm system, othewvise cancel iL Whenyou i~?mit the alarm system, call the Fire Department ifpossible, then evacuate.
When you cancel the alarm system,if it is more then 90 seconds since the timer started, thesystem will have called Wells Fargo already, c th~continue what you were doing..
?oo??o~.oo?
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.PROTEUS: The move sequence 3169547Position4 6 numberingThe move=:3 3 1 3169 316954 3169547The game started with my taking a comer, and you tookan adjacent one.
I threatened you by taking the middle ofthe edge.opposite that and adjacent to the one which 1 hadjust taken but you blocked it and threatened me.
I blockedyour diagonal and forked you.
If you had blocked mine, youwould have forked me, but you took the middle of the edgeoppoalte the corner which I took first and the one which youhad just taken and so I won by completing my diagoned.References\[Oavey79\]\[H=liday76\]\[Huddleston 71\]\[Hudson 71 \]\[Mann and Moore\[Mann 79\]Davey, Anthony.Discourse Production.Edinburgh University Press, Edinburgh, 1979.Krese, G. R. (editor).System and Function in Language.Oxford University Press, London, 1976.Huddleston, R. D.The sentence in written English: a syntactic studybased on an analysis of scientific texts.Cambridge University Press, London, 1971.Hudson, R. A.North Holland Linguistic Series.
Volume 4" Englishcomplex sentences.North Holland, London and Amsterdam, 1971.80\]Mann, William C., and James A. Moore.Computer as Author-Results and Prospects.Research regort 79-82, USC/Informetion SciencesInstitute, 1980.Mann, William C. and James A. Moore.ComDutar Generation of MultiDaregraDh EnglishText.1979.AJCL, forthcoming.\[Moore 79\]\[Sinclair 72\]\[Swartout 77\]\[Swartout 81 |\[Weiner 80\]\[Winogred 72\]Moore, James A., and W. C. Mann.A snapshot of KDS, a knowledge delivery system.In Proceedings ot the Conference.
17th AnnualMeeting of the Association for ComputationalLinguistics, pages 51-52.
August, 1979.Sinclair, J. Moll.A course in sl~oken English: Grammar.1972.Swartout, William.A Digitalis Therapy Advisor with Explanations.Technical Rel~ort, MIT Laboratory for ComputerScience, February, 1977.Swartout, William R.Producing Explanations and Justifications of ExpertConsulting Programs.Technical Report Massachusetts InstituteTechnology/LCS/TR-251, MassachusettsInstitute Technology, January, 1981.Weiner, J. L.BLAH, A System Which ExDlains its Reasoning.Artificial Intelligence 15:19-48, November, 1980.Winograd, Terry.Understanding Natural Language.Academic Press, Edinburgh, 1972.4"/
