Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications , pages 34?42,Baltimore, Maryland USA, June 26, 2014. c?2014 Association for Computational LinguisticsTranslation Class Instruction as Collaborationin the Act of TranslationLars AhrenbergDepartment of Computer andInformation Science,Link?ping Universitylars.ahrenberg@liu.seLjuba TarviUniversity of HelsinkiHelsinki, Finlandljuba.tarvi@welho.comAbstractThe paper offers an effective way ofteacher-student computer-based collabo-ration in translation class.
We show howa quantitative-qualitative method ofanalysis supported by word alignmenttechnology can be applied to studenttranslations for use in the classroom.
Thecombined use of natural-language pro-cessing and manual techniques enablesstudents to ?co-emerge?
during highlymotivated collaborative sessions.
Withinthe advocated approach, students are pro-active seekers for a better translation(grade) in a teacher-centered computer-based peer-assisted translation class.1 IntroductionTools for computer-assisted translation (CAT),including translation memories, term banks, andmore, are nowadays standard tools for transla-tors.
The proper use of such tools and resourcesare also increasingly becoming obligatory partsof translator training.
Yet we believe that transla-tion technology has more to offer translatortraining, in particular as a support for classroominteraction.
Our proposal includes a quantitativeanalysis of translations, supported by wordalignment technology, to enable joint presenta-tion, discussion, and assessment of individualstudent translation in class.
For comparisonswith related work, see section 4.From the pedagogical point of view, the sug-gested procedure embraces at least four types ofevaluation: students?
implied self-evaluation, apreliminary computer evaluation, teacher?s eval-uation after manually correcting the imperfectcomputer alignment and assessment, and peerevaluation during the collaborative team work inclass, when the versions produced by the stu-dents are simultaneously displayed, discussedand corrected if necessary.Theoretically, translations are viewed here asmappings between two languages through emer-gent conceptual spaces based on an intermediatelevel of representation (e.g., Honkela et.
al.,2010).
In terms of praxis, the basic approach isrooted in the idea (Vinay & Darbelnet, 1958) ofconsecutive numbering of the tokens (words) inthe original text.
This simple technique enables -finding and labeling, in accordance with a cho-sen set of rules, certain isomorphic correspond-ences between the source and target tokens.Finding such correspondences is what currentmachine translation approaches attempt toachieve by statistical means in the trainingphase.The quantitative-qualitative technique we usehere is the Token Equivalence Method (TEM)(Tarvi 2004).
The use of the TEM in translationteaching originated as an argument (involvingthe second author) in a teacher-student debateover the relevance of a grade.
The considerabletime spent on the manual preparation of texts fortranslation using the TEM proved to be fairlywell compensated for by the evident objectivityof the grades - the argument that, say, only 65%of the original text has been retained in a transla-tion is difficult to brush aside.
Later, the methodwas applied in research.
Tarvi (2004) comparedthe classical Russian novel in verse by A. Push-kin Eugene Onegin (1837) with its nineteen Eng-lish translations.
Figures calculated manually on10% of the text of the novel showed an excellentfit with the results on the same material obtainedelsewhere by conventional comparative meth-ods.
Thus, we believe that characterizations ofrelations between source and target texts in ob-34jective terms is a good thing for translation eval-uation.1.1 The TEM: Basics and ExampleMethodologically, the TEM focuses not ontranslation ?shifts?
but on what has been kept intranslation.
The basic frame for analysis in theTEM is the Token Frame (2.2.1), which accountsfor the number of the original tokens retained intranslations.
The other four frames (2.2.2-3,2.3.1-2), although useful in gauging the compar-ative merits of the translations and the individualstrategies, are optional.To concisely illustrate the method, one sen-tence will be used ?
the famous 13-token open-ing sentence of Leo Tolstoy?s Anna Karenina:Vse  schastlivye  semyi  pohozhi drug na druga,kazhdaya neschastlivaya semya neschastliva  posvoemu.
(All happy families resemble one an-other, every unhappy  family is unhappy in itsown way.
)Eight English translations of this sentence(2.1) will be used for analysis.The source text and all its translations are to-kenized and analyzed linguistically in differentways.
NLP tools  such as lemmatizers, part-of-speech taggers and parsers can be applied.
Mostimportantly, however, to support the computa-tion of the Token Frames (2.2.1), they must beword-aligned with the source text (2.6).
Theteacher or the students are expected to review thealignments and correct them if they are not ac-ceptable.
Given the corrected alignments, thealigned data can be used by the teacher and thestudents in the classroom.After this introduction of the basics of thetheoretical approach and relevant automaticmethods for their implementation, the paper isbuilt around the basic structural foci of any in-struction unit: before class (2), in class (3), andoutside class (4).2 Before classThis section describes the techniques of pro-cessing Source Texts (ST) and Target Texts (TT)by teachers and students.2.1 Token Numbering and LabelingThe procedure starts with consecutive number-ing of the original tokens:(1)Vse (2)schastlivye (3)semyi (4)pohozhi (5)drug (6)na(7)druga, (8)kazhdaya (9)neschastlivaya (10)semya(11)neschastliva (12)po (13)svoemu.The second step is establishing, via the proce-dure of (corrected) alignment, the correspond-ences between the Source tokens (St) and Targettokens (Tt).
As a result, every corresponding TTtoken (Tt), if found, is designated with the num-ber of its source counterpart (St).
Besides, sinceno Tt may remain unlabeled, two types of Ttswhich have no counterparts in the ST are labeledas Extra tokens (2.3.1) and Formal tokens(2.3.2).
Here are the eight translations of the ex-ample sentence:Leo Wiener: (1899):(1)All (2)happy (3)families (4)resemble (5-6-7)one an-other; (8)every (9)unhappy (10)family (Ft)is(11)unhappy (12)in (Ft)its (13)own way.Constance Garnett (1901):(2)Happy (3)families (Ft)are (1)all (4)alike; (8)every(9)unhappy (10)family (Ft)is (11)unhappy (12)in (Ft)its(13)own way.Rochelle S. Townsend (1912):(1)All (2)happy (3)families (Ft)are (Et)more (Et)or(Et)less (4)like (5-6-7)one another; (8)every (9)unhappy(10)family (Ft)is (11)unhappy (12)in (Ft)its (13)own(Et)particular way.Aylmer & Louise Maude (1918):(1)All (2)happy (3)families (4)resemble (5-6-7)one an-other, (Et)but (8)each (9)unhappy (10)family (Ft)is(11)unhappy (12)in (Ft)its (13)own way.Rosemary Edmonds (1954):(1)All (2)happy (3)families (Ft)are (4)alike; (Et)but(Ft)an (9)unhappy (10)family (Ft)is (11)unhappy(12)after (Ft)its (13)own fashion.Joel Carmichael (1960):(2)Happy (3)families (Ft)are (1)all (4)alike; (8)every(9)unhappy (10)family (Ft)is (11)unhappy (12)in (Ft)its(13)own way.David Magarschack (1961):(1)All (2)happy (3)families (Ft)are (4)like (5-6-7)oneanother; (8)each (9)unhappy (10)family (Ft)is(11)unhappy (12)in (Ft)its (13)own way.Richard Pevear & Larisa Volokhonsky (2000):(1)All (2)happy (3)families (Ft)are (4)alike; (8)each(9)unhappy (10)family (Ft)is (11)unhappy (12)in (Ft)its(13)own way.As is seen, two of the versions are clones(Carmichael, Pevear-Volokhonsky), one transla-tion (Garnett) differs from the original only bythe choice of the adjective (St 8), while the re-maining five versions are more diverse.
Note themode of denoting Tts suggested here: only the35meaningful denotative tokens get labeled, e.g.,are (4)alike, or is (11)unhappy; if not one Tt buta group of tokens is used as an isomorph to asingle St, the whole group is underlined, e.g.,(13)own way, or (13)own fashion.Although St 4 has been rendered as are alike(Edmonds, Pevear-Volokhonsky, Garnett, Car-michael), are like (Townsend, Magarschack),and resemble (Wiener, the Maudes), all theserendering are viewed as retaining the denotativemeaning of the original token.
Or, for instance,St 12, whether rendered as after (Edmonds) or in(all the rest), is also viewed as retained in trans-lation.
The connotative shades of meaning mostsuitable for the outlined goals can be discussedin class (3.2).This mode of displaying the isomorphismscan be converted to the style of representationused in word alignment systems such as Giza++(Och and Ney, 2003) as follows: Extra tokensand Formal tokens give rise to null links.
Groupsof tokens that correspond yield groups of links.Thus, the analysis for Wiener?s translation wo-uld come out as below:1-1 2-2 3-3 4-4 5-5 5-6 6-5 6-6 7-5 7-6 8-7 9-810-9 0-10 11-11 12-12 0-13 13-14 13-15.In gauging the content, two types of basic andoptional analytical frames, content and formal,are used.
Based on the way of calculating theresults, the analytical frames will be consideredhere in two sections, percentage frames (2.2) andcount frames (2.3).2.2  The TEM: Percentage FramesThe results in these frames are calculated as per-centages of the ST information retained in trans-lations.2.2.1 Basic Content Frame (Token Frame)After finding the isomorphic counterparts, thepercentages of the retained tokens are presentedin Table 1 (column I).
As one can see, Wiener,the Maudes, Magarschack and Townsend trans-lated all thirteen tokens and, hence, scored 100%each; Garnett, Carmichael and Pevear-Volokhonsky omitted Sts 5-6-7 and thus scored76%, while Edmonds left out four tokens, Sts 5-6-7-8, thus retaining 69% of the original.2.2.2 Optional Formal Frame 1 (MorphologyFrame)In this frame, if a token is rendered with thesame part of speech as in the original, the Tt inquestion gets a count.
As can be seen in Table 1(column II), only two translators, Wiener and theMaudes, kept the same type of predicate 1 (St 4)as in the original ?
resemble ?
while in the re-maining six translations the type of predicate 1has been changed into a compound one: arealike (Edmonds, Pevear-Volokhonsky, Garnett,Carmichael), and are like (Townsend,Magarschack).
Therefore, in this frame, Wienerand the Maudes get a 100% each; Edmonds,with her two changed parts of speech, gets 84%,while the remaining five translators, whochanged one part of speech each, score 92%.2.2.3 Optional Formal Frame 2 (Syntax)Another possible way of gauging the ?presence?of the original in its translation is monitoring thesyntactic changes.
If at least two tokens are ren-dered in the same sequence as in the original andpreserve the same syntactic functions, they areconsidered syntactically kept.
Non-translated Stsare viewed as non-kept syntactic positions.
Table1 (column III) shows that Edmonds, who lostfour syntactic positions, scores 76%, Garnett,Magarschack and Townsend get 92% each, therest translators score a 100%.2.2.4 The Translation Quotient (TQ)As a result of either manual or computer-assistedtranslation processing, the teacher gets a tabulat-ed picture (Table 1) of the three analyzed frames(columns I, II, III).In an attempt to combine the obtained figuresin a meaningful whole, the Translation Quotientparameter (TQ, column IV) is used: it is thearithmetic mean of the percentages in the moni-tored frames.
If one adds up the percentage re-sults in all three frames and divides the obtainedfigure by the number of frames, one gets a TQ,measured in percentage points (pp), which re-flects a general quantitative picture of the con-tent-form rendering of the original.
This cumula-tive parameter has shown a perfect fit with theresults obtained by other methods of compara-tive assessment (Tarvi 2004).
Table 1 shows fourgroups of TQ results, from 100% (2 versions)through 97% (2) through 86% (3) to 74% (1).2.3 The TEM: Count FramesTo further differentiate the translations in theircloseness to the original, pure counts of somequantitative parameters can be added to the pic-ture in Table 1: column V (extra tokens, Ets) andVI (formal Tokens, Fts).362.3.1 Optional Content Frame 1This frame is a useful tool of assessment, as itshows what has been added to the translation,i.e., the Tts that have no counterparts in the orig-inal, labeled as extra Tokens (Et).
Table 1 (col-umn V) shows that Wiener, Magarschack, Gar-nett, Carmachael, and Pevear-Volokhonsky add-ed no extra Tokens (Ets), the Maudes and Ed-monds added by one Et each, while Townsend ?four.2.3.2 Optional Formal Frame 3In this frame, the center of attention is formalTokens (Fts) ?
articles, tense markers, etc.
Table1 (column VI) shows that Fts are employed indifferent quantities: Wiener and the Maudes usedtwo Fts each, Edmonds used four, the rest trans-lators ?
three Fts each.2.4 TEM Results: the 13-Token SentenceThe table below gives a cumulative picture ofthe results in each of the five frames considered:Table 1.
Cumulative Overall Table (13 tokens): Rank OrderI II III IV V VITF MF SF TQ Et Ft(2.2.1) (2.2.2) (2.2.3) (2.2.4) (2.2.5) (2.2.6)(%) (%) (%) (pp) (count) (count)Leo Wiener (1899)100  100  100  100 0 2Aylmer & Louise Maude (1918)100  100  100  100 1 2David Magarschack (1961)100  92  100  97 0 3Rochelle S. Townsend (1912)100  92  100  97 4 3Constance Garnett (1901)76  92  92  86 0 3Joel Carmichael (1960)76  92  92  86 0 3Pevear & Volokhonsky (2000)76  92  92  86 0 3Rosemary Edmonds (1954)69  84  69  74 1 4As is seen, there are four groups of the TQ re-sults.
In the 100% group, Wiener has a slightadvantage (in terms of isomorphism) over theMaudes, since he introduced no extra tokens.
Inthe 97% group, Townsends?s translation inferior-ity (in terms of closeness) is expressed in fourextra tokens as compared to no extra tokens inMagarschack?s version.
In the 86% block, nodistinctions can be made because they are word-for-word clones, except for Pevear-Volokhonsky?s use of ?each?
instead of ?every?
(St 8).
Edmonds?
version (TQ = 74%) has a rec-ord (for this sample) number of formal tokens,four.
It does not imply that the translation is bad?
this kind of judgment can arise only after adiscussion in classroom (3.3).The one-sentence example, used here peda-gogically to explain the TEM techniques, cannotbe considered to be fairly representative of thequantitative parameters and their qualitative im-plications of translated texts.
Therefore, we offerthe results obtained for a much bigger samplefrom Anna Karenina.2.4.1 TEM Results: the 405-Token ExcerptSheldon (1997) performs a detailed conventionalcomparative analysis of the four ?focal points?
ofthe novel: the opening sentence consideredabove (13 tokens), the ball scene (73 tokens), theseduction scene (103 tokens) and the suicidescene (216 tokens).
He analyzed the seven trans-lations considered here, except for the version byPevear and Volokhonsky, which was publishedthree years later.
Sheldon concluded that it wasCarmichael who showed the best fit with theoriginal.Here are the quantitative results obtained withthe TEM applied to the same excerpts.Table 2.
Cumulative Overall Table (405 tokes): Rank OrderLost Kept TQ Ft Ettokens tokens  used  used(count) (count) (%) (count) (count)David Magarshack (1961)9 396 97,7 96 14Joe Carmichael (1960)18 387 95,5 95 15Constance Garnett (1901)20 385 95,0 90 8Aylmer & Louise Maude (1918)30 375 92,5 91 17Rosemary Edmonds (1954)34 371 91,6 87 14Leo Wiener (1899)57 348 85,9 74 20Rochelle S. Townsend (1912)69 336 82,9 79 42As is seen, the TQs range from 97,7% to82,9%.
Since the TEM does not cover all aspectsof Sheldon?s analysis, it favors Magarshack?sversion, with Carmichael?s translation lauded bySheldon following it closely.2.5 Language pair independenceIn our example with translation from Russian toEnglish, there is an asymmetry in that formaltokens are largely to be seen only on the targetside.
However, the TEM frames can equally beapplied in the reverse direction or to any lan-guage pair.
Whether or not we choose to excludesome formal tokens from the counting, the37frames are applied in the same way to all transla-tions and their relative differences will be re-vealed.2.6 Computational analysisIt has been suggested before that virtual learningenvironments are useful for translation teaching(e.g., Fictumova (2007)).
Our point here is thatfine-grained quantitative methods, such as theTEM, can be put to use given support from com-putational linguistic tools.
The proposed envi-ronment consists of a central server and a num-ber of client systems for the students.
Communi-cation between them is handled as in any e-learning environment, where exercises, gradesand other course materials can be stored and ac-cessed.
The server includes several modules formonolingual text analysis, such as sentencesegmentation, tokenization, lemmatization andPoS-tagging.
A parser may also be included tosupport the computation of the syntax frame.More importantly, there are modules for sen-tence and word alignments, since this is what isrequired to support the TEM analysis.
In addi-tion, there are modules for reviewing and cor-recting outputs from all analyzers.2.6.1 TokenizationIn principle, tokenization, numbering and label-ing of tokens (2.1), are processes that computerscan handle with ease.
It is important, though,that the tokenization is done in a way that sup-ports the purpose to which it will be used.
In thiscase, a tokenization module that only looks atspaces and separators will not be optimal, as theprimary unit of TEM is semantic, and may spanseveral text words.
Moreover, punctuation marksare not treated as separate tokens in the TEM.This problem could be overcome by tokenizingin two steps.
In the first step punctuation marksare removed, lexical tokens are identified usingword lists and then formatted as character stringsthat have no internal spaces.
In the second stagespaces are used to identify and number the to-kens.
Formal tokens can to a large extent beidentified as part of this process, using wordlists, but extra tokens cannot be identified untilafter the word alignment.2.6.2 Sentence alignmentIn some cases the translation task may requirestudents not to change sentence boundaries and aone-to-one correspondence between source sen-tences and sentences of the translations can beassumed to hold when translations are delivered.If not, a sentence alignment tool such ashunalign (Varga et al., 2005) can be used.2.6.3 Word alignmentThe accuracy of word alignment systems arequite far from 100%.
The best performing sys-tems are either statistical, such as Giza++ (Och& Ney, 2003), or hybrid (Moore et al., 2006) andrequire vast amounts of text to perform well.
Inthe translation class context, the source text willbe fairly short, perhaps a few thousand words asa maximum.
Even with, say, 20 student transla-tions, the total bitext, consisting of the sourcetext repeated once for each student translationand sentence-aligned with it, will be too short fora statistical aligner to work well.
For this reason,a hybrid system that relies on a combination ofbilingual resources and statistics for the wordalignment seems to be the best choice (cf.Ahrenberg & Tarvi, 2013).An advantage of having a short source text isthat the teacher can develop a dictionary for it inadvance to be used by the word aligner.
While ateacher cannot predict all possible translationsthat a student may come up with, this is a re-source that can be re-used and extended overseveral semesters and student groups.Table 3.
Alignment performance on an excerpt fromAnna Karenina using different combinations of statisti-cal alignment and lexical resources.Prec  Recall F-scoreGiza++ 0.499 0.497 0.498Wordlist based 0.881 0.366 0.517Combination 0.657 0.610 0.633Comb + filters 0.820 0.508 0.628Table 3 shows some results for the Russian-English 405-token excerpt discussed above withdifferent combinations of Giza++-output andlexicon-based alignments.
Standard tokenizationwas used except that punctuation marks weredeleted.
The source then consists of eight itera-tions of the excerpt, altogether 3304 tokens1 andthe target text consisting of eight different trans-lations has 4205 tokens.
The files were lemma-tized before alignment.The bilingual resources used are a word list ofEnglish function words such as articles and pos-sessives that are likely to have no formal coun-terpart in the source and a bilingual word listcreated by looking up content words in Google1Standard tokenization does not recognize multitokenunits.38Translate.
Not all translations suggested byGoogle have been included.
The mean numberof translations per Russian lemma is 1.5.
In thecombinations priority has been given to thealignments proposed by the word lists as they aredeemed to have a higher precision.2 So, the thirdrow means that Giza++ alignments have beenreplaced by null links and lexical links inducedby the word lists in all cases where there was acontradiction.
The fourth row is the result of ap-plying a set of filters based on word frequenciesin the corpus and alignment topology to the pre-vious combination.Obviously, if a complete alignment is calledfor it is clear that the output of the system mustbe reviewed and hand-aligned afterwards.
Thereare several interactive word-alignment tools thatcan be used for this purpose (Tiedemann, 2011),but it will still be time-consuming.
However, theburden can be shared between teacher and stu-dents, and efforts may be focused on a part ofthe text only.2.7 WorkflowAfter selection of a ST to be used for a transla-tion exercise, the system will have it segmentedinto sentences, tokenized, and numbered.
Thenthe teacher checks the outcome and corrects it ifnecessary.
The files are then sent to the students.Within the suggested approach, the students areasked to use the client version of the system fortranslation and then upload their translations totheir teacher by a set date before class, or tobring them to class on memory sticks.When a student translation is in place in theserver system, it can be aligned and graded au-tomatically.
Of course, the significance of thegrades depends on the accuracy of the alignment,but both the student and the teacher can contrib-ute to the reviewing.
For instance, the teachermight have marked some words and phrases asespecially significant and the student can reviewthe alignments for them in the system for his orher particular translation.3 In ClassWhen translations and their alignments are inplace in the server system, they can be used as2The fact that precision is not 100% for wordlist ba-sed alignment has two major causes.
First, some con-tent words appear two or three times in a sentence andthe system does not manage to pick the right occur-rence.
Also, some common English prepositions getaligned when they shouldn?t.input to various visualization tools.
This we seeas a further advantage of our approach whichwill stimulate discussion and reflections amongthe students.
Students?
translations can be dis-played individually or collectively, on a sentencebasis or a phrase basis.
Using again the openingsentence of Anna Karenina as our example, theoutcome for one sentence can look as in Figure1, where also some of the token frames de-scribed above are automatically computed fromthe alignment.3 Within this format, the teacher isacting as a post-editing human agent who cancombine both manners of assessment ?
comput-er-assisted and manual.Since the method combines human and com-puter resources, it might raise the effectivenessof translation class instruction manifold(Lengyel 2006: 286).
The TEM also depersonal-izes the problem of grading.Figure 1.
Alignment screenshot for Segment 1 ofTranslation 1 (Joel Carmichael, 1960) with metrics.3.1 From Translation Quotients toGradesAs has been demonstrated, the TEM allows oneto get a certain ?cline of fidelity?
from the mostfaithful translation to the freest version.
Basedon these relative assessments, one can convertthe cumulative figures obtained on a number ofquantitative parameters to grades.
It should beremembered that although the analytical ad-3Alignments of the excerpts from Anna Karenina canbe accessed at http://www.ida.liu.se/~lah/AnnaK/39vantage of the frames is that they are minimallysubjective, the step from TQ to grades is neithercontext- nor value-free but depends heavily onthe translation task.Table 4.
From TQs to GradesTQ  Rank GradeMagarshack 97,7 1 ExcellentCarmichael 95,5 2 GoodGarnett 95,0 3 GoodThe Maudes 92,5 4 Good -Edmonds 91,6 5 Good -Wiener 85,9 6 SatisfactoryTownsend 82,9 7 Satisfactory -3.2 Gauging QualityThe highlight of the approach is class teamwork, in the course of which students are ex-pected to have a chance to insert meaningful cor-rections into their translations and thus improvetheir ?home?
grades by the end of class.
Becausethe tokens are numbered, the teacher can easilybring any St, or a group of Sts, on the screen to-gether with all the versions of its or their transla-tions.It is at this stage that the qualitative side ofthe TEM comes into play with the aim of im-proving the final quantitative grade.
Let us, forinstance, consider the way a group of two tokensfrom the sentence-example has been rendered.As can be seen here in the manual (Table 5) andcomputer (Figure 2) versions, this pair of sourcetokens has been rendered in three different ways.In a computer-equipped class, the requiredchanges can be immediately introduced into thetranslated texts under discussion.3.3 Final GradingAs was mentioned in Section 1, the suggestedprocedure embraces the four basic types of trans-lation evaluation.
The method generates absolutescore (overall estimates) based on relative scoresin separate frames (Table 1).The first monitoring gives a quantitative esti-mate of students?
homework.
After class discus-sion, which is supposed, like any post-editing, tochange the home translations for the better, onemore monitoring is carried out, using the sameframes.
If the system is made incremental, thefinal grade, which is an arithmetic mean of thehome and class grades, can be registered auto-matically.
If, at the end of class, the final gradesare exhibited on screen in their ranking order, itmight be the best possible motivation for stu-dents to work diligently both at home and inclass.Table 5.
Renderings of Source tokens 12-13LW:  (12)in (Ft)its (13)own way.CG: (12)in (Ft)its (13)own way.ALM:  (12)in (Ft)its (13)own way.JC:  (12)in (Ft)its (13)own way.DM:  (12)in (Ft)its (13)own way.RPLV:  (12)in (Ft)its (13)own way.RE:  (12)after (Ft)its (13)own fashion.RT: (12)in (Ft)its (13)own (Et)particular way.Figure 2.
Renderings of Source tokens 12-13(computed alignments)4 Outside ClassWithin machine translation research, work hasbeen going on for several years, and is still veryactive, for the search of metrics that assess thesimilarity of a system translation with humanreference translations.
Metrics, such as BLEU(Papineni et al.. 2002), TER (Snover et al..2006), and Meteor (Lavie and  Denkowski:2009), could also be included in the proposedenvironment.
Published translations or transla-tions that the teacher recognizes as particularlygood can be used as reference translations.
How-ever, the scores of these metrics do not give asmuch qualitative information as the TEMframes.The role of corpora in translation and transla-tion training is a topic of some interest (e.g.Zanettin et al.
: 2003).
In translator training, thecorpora are mostly seen as resources for the stu-dent to use when practicing translation (Lopez-40Rodriguez and Tercedor-Sanchez: 2008).
This isorthogonal to what we are proposing here, i.e.,enabling immediate comparisons and assess-ments of students?
translations as a class-basedactivity.
A system with a similar purpose is re-ported in Shei and Pain (2002: 323) who de-scribe it as an ?intelligent tutoring system de-signed to help student translators learn to appre-ciate the distinction between literal and liberaltranslation?.
Their system allows students tocompare their own translations with referencetranslations and have them classified in terms ofcategories such as literal, semantic, and commu-nicative.
The comparisons are made one sen-tence at a time, using the Dice coefficient, i.e.,by treating the sentences as bags of words.
Ourproposal, in contrast, uses more advanced com-putational linguistics tools and provides text lev-el assessment based on word alignment.Michaud and McCoy (2013) describe a sys-tem and a study where the goal, as in our pro-posal, is to develop automatic support for trans-lator training.
They focus on the inverted TERpmetric (Snover et al., 2009) for evaluation ofstudent translations.
TERp requires a referencetranslation but can represent the difference be-tween a given translation and the reference interms of editing operations such as insertion,deletion, change of word order and matches ofdifferent kinds.
A weak positive correlation withinstructor-based grades (using Pearson?s r) couldbe demonstrated in the study and the authors ar-gue that TERp is sufficiently reliable to providefeed-back to students in a tutoring environment.The main difference between their proposaland ours is that we start with a metric that hasbeen developed for the task of grading humantranslations, while TERp is originally an MTmetric.
Thus, TEM does not require referencetranslations, but on the other hand its computa-tion has not been automated and so, that is whereour current efforts are focused.
It should be em-phasized that the teacher?s load within this ap-proach remains quite heavy but the reviewingwork may be shared between teachers and stu-dents.Both the TEM and TERp provide quantitativemeasurements that can lay the foundation forqualitative discussions and feedback to studentsbut as the TEM does not require a reference itgives the students more freedom in improvingtheir work.As a more or less objective way of measuringthe quantity with allowances made for quality,the method can also be used by teachers at ex-ams, by editors for choosing a translation, bymanagers recruiting new in-house translators, bytranslators for self-monitoring, etc.
The comput-er-generated figures are obtained right on thespot ?
they may not be exactly accurate but theygive a rough general picture at the level of con-tent-form ?presence?
of the original in its transla-tions.AcknowledgementWe are grateful to the anonymous reviewers whoprovided useful comments and additional refer-ences.ReferencesAhrenberg, Lars and Tarvi, Ljuba.
2013.
Natural lan-guage processing for the translation class.
Proceed-ings of the second workshop on NLP for comput-er-assisted language learning at NODALIDA 2013(May 22, Oslo).
NEALT Proceedings Series 17 /Link?ping Electronic Conference Proceedings 86:1?10.Carmichael, Joel.
1960.
Anna Karenina, by Lev Tol-stoy.
New York: Bantam Books, 1980.Edmonds, Rosemary.
1954.
Anna Karenina, by LevTolstoy.
London: The Folio Society, 1975.Garnett, Constance.
1901.
Anna Karenina, by LeoTolstoy, with revisions by Leonard J. Kent and Ni-na Berberova.
New York: Modern Library, 1993.Honkela, Timo et al.
2010.
GIGA: GroundedIntersubjective Concept Analysis: A Method forEnhancing Mutual Understanding and Participa-tion, Espoo: Aalto University School of Scienceand Technology.Lavie, Alon and Denkowski, Michael J.
2009.
?TheMeteor metric for automatic evaluation of machinetranslation,?
Machine Translation, Vol 23 (2-3)105-115.Lengyel, Istv?n.
2006.
?Book reviews.
Ljuba Tarvi:Comparative Translation Assessment: QuantifyingQuality,?
Across Languages and Cultures 7 (2)2006, 284-286.Liang, Percy, Taskar, Ben, and Klein, Dan.
2006.?Alignment by Agreement.?
In Proceedings of theHuman Language Technology Conference of theNorth American Chapter of the Association forComputational Linguistics, 2006, 104-111.L?pez-Rodr?guez, Clara In?s and Tercedor-S?nchez,Mar?a Isabel.
2008.
?Corpora and Students' Auton-omy in Scientific and Technical Translation train-ing,?
Journal of Specialized Translation(JoSTrans), Issue 09 (2008), 2-19.41Magarschack, David.
1961.
Anna Karenina, by LevTolstoy.
New York: The New American Library.Maude, Louise and Maude, Aylmer.
1918.
AnnaKarenina, by Lev Tolstoy, a Norton Critical Edi-tion, ed.
George Gabian, with the Maude transla-tion as revised by George Gibian.
2d edition.
NewYork: Norton and Co, 1995.Michaud, Lisa N. and McCoy, Patricia Ann.
2013.Applying Machine Translation Metrics to Student-Written Translations.
Proceedings of the EighthWorkshop on Innovative Use of NLP for BuildingEducational Applications (BEA8), 2013, 306-311.Moore, Robert C, Yih, Wen-tau, and Bode, Anders.2006.
?Improved Discriminative Bilingual WordAlignment.?
In Proceedings of the 21st Interna-tional Conference on Computational Linguisticsand 44th Annual Meeting of the ACL, 2006, 513-520.Papineni, Kishore, Roukos, Salim, Ward, Todd, andZhu, Wei-Jing.
2002.
?BLEU: a method for auto-matic evaluation of machine translation.?
In Pro-ceedings of the 40th Annual Meeting on Associa-tion for Computational Linguistics, 311-318.Pevear, Richard & Volokhonsky, Larissa.
2000.
LeoTolstoy.
Anna Karenina.
Penguin Books.Shei, Chi-Chiang and Pain, Helen.
2002.
?Computer-Assisted Teaching of Translation Methods.?
Liter-ary & Linguistic Computing, Vol, 17, No 3 (2002),323-343.Sheldon, Richard.
1997.
?Problems in the EnglishTranslation of Anna Karenina.?
Essays in the Artand Theory of Translation, Lewiston-Queenston-Lampeter: The Edwin Mellen Press, 1997Snover, Matthew, Dorr, Bonnie, Schwartz, Richard,Micciulla, Linnea and Makhoul, John.
2006.
?AStudy of Translation Edit Rate with Targeted Hu-man Annotation.?
Proceedings of the 7th Confer-ence of the Association for Machine Translation inthe Americas, 223-231.Snover, Matthew, Madnani, Nitin, Dorr, Bonnie J.,and Schwartz, Richard.
2009.
Fluency, adequacy,or HTER?
Exploring different judgments with atunable MT metric.
Proceedings of the EACLFourth Workshop on Statistical Machine Transla-tion, Athens, Greece, March 30-31, 2009: 259-268.Tarvi, Ljuba.
2004.
Comparative Translation As-sessment: Quantifying Quality, Helsinki: HelsinkiUniversity Press.Tiedemann.
2011.
Bitext Alignment.
Morgan & Clay-pool Publishers.Townsend, Rochelle S. 1912.
Anna Karenina, byCount Leo Tolstoi.
London & Toronto: J.M.
Dent& Sons; New york: E.P.
Dutton and Co, 1928.Varga, Daniel, N?meth, Laszlo, Hal?csy, Peter,Kornai, Andras, Tr?n, Viktor, and Viktor Nagy,2005.
Parallel corpora for medium density lan-guages.
Proceedings of RANLP 2005.Vinay, Jean-Paul & Darbelnet, Jean.
1995 [1958].Comparative Stylistics of French and English.
AMethodology for Translation, Amsterdam: JohnBenjamins.Wiener, Leo.
1899.
Anna Karenina, by Lyof N.Tolstoi, vols II-IV: The Novels and Other Works ofLyof N. Tolstoi.
New York: Charles Scribner?sSons, 1904.Zanettin, Federico, Bernardini, Silvia, and Stewart,Dominic (eds.).
2003.
Corpora in Translator Edu-cation, Manchester.42
