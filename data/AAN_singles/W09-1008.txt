Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 49?57,Athens, Greece, 30 March 2009. c?2009 Association for Computational LinguisticsOn statistical parsing of French with supervised and semi-supervisedstrategiesMarie Candito*, Beno?t Crabb?
* and Djam?
Seddah?
* Universit?
Paris 7UFRL et INRIA (Alpage)30 rue du Ch?teau des RentiersF-75013 Paris ?
France?
Universit?
Paris 4LALIC et INRIA (Alpage)28 rue SerpenteF-75006 Paris ?
FranceAbstractThis paper reports results on grammati-cal induction for French.
We investigatehow to best train a parser on the FrenchTreebank (Abeill?
et al, 2003), viewingthe task as a trade-off between generaliz-ability and interpretability.
We compare,for French, a supervised lexicalized pars-ing algorithm with a semi-supervised un-lexicalized algorithm (Petrov et al, 2006)along the lines of (Crabb?
and Candito,2008).
We report the best results knownto us on French statistical parsing, that weobtained with the semi-supervised learn-ing algorithm.
The reported experimentscan give insights for the task of grammat-ical learning for a morphologically-richlanguage, with a relatively limited amountof training data, annotated with a ratherflat structure.1 Natural language parsingDespite the availability of annotated data, therehave been relatively few works on French statis-tical parsing.
Together with a treebank, the avail-ability of several supervised or semi-supervisedgrammatical learning algorithms, primarily set upon English data, allows us to figure out how theybehave on French.Before that, it is important to describe the char-acteristics of the parsing task.
In the case of sta-tistical parsing, two different aspects of syntacticstructures are to be considered : their capacity tocapture regularities and their interpretability forfurther processing.Generalizability Learning for statistical parsingrequires structures that capture best the underlyingregularities of the language, in order to apply thesepatterns to unseen data.Since capturing underlying linguistic rules isalso an objective for linguists, it makes senseto use supervised learning from linguistically-defined generalizations.
One generalization istypically the use of phrases, and phrase-structurerules that govern the way words are grouped to-gether.
It has to be stressed that these syntacticrules exist at least in part independently of seman-tic interpretation.Interpretability But the main reason to use su-pervised learning for parsing, is that we wantstructures that are as interpretable as possible, inorder to extract some knowledge from the anal-ysis (such as deriving a semantic analysis froma parse).
Typically, we need a syntactic analysisto reflect how words relate to each other.
Thisis our main motivation to use supervised learn-ing : the learnt parser will output structures asdefined by linguists-annotators, and thus inter-pretable within the linguistic theory underlying theannotation scheme of the treebank.
It is importantto stress that this is more than capturing syntacticregularities : it has to do with the meaning of thewords.It is not certain though that both requirements(generalizability / interpretability) are best met inthe same structures.
In the case of supervisedlearning, this leads to investigate different instan-tiations of the training trees, to help the learning,while keeping the maximum interpretability of thetrees.
As we will see with some of our experi-ments, it may be necessary to find a trade-off be-tween generalizability and interpretability.Further, it is not guaranteed that syntactic rulesinfered from a manually annotated treebank pro-duce the best language model.
This leads to49methods that use semi-supervised techniques ona treebank-infered grammar backbone, such as(Matsuzaki et al, 2005; Petrov et al, 2006).The plan of the paper is as follows : in thenext section, we describe the available treebankfor French, and how its structures can be inter-preted.
In section 3, we describe the typical prob-lems encountered when parsing using a plain prob-abilistic context-free grammar, and existing algo-rithmic solutions that try to circumvent these prob-lems.
Next we describe experiments and resultswhen training parsers on the French data.
Finally,we discuss related work and conclude.2 Interpreting the French treesThe French Treebank (Abeill?
et al, 2003) is apublicly available sample from the newspaper LeMonde, syntactically annotated and manually cor-rected for French.<SENT><NP fct="SUJ"><w cat="D" lemma="le" mph="ms" subcat="def">le</w><w cat="N" lemma="bilan" mph="ms" subcat="C">bilan</w></NP><VN><w cat="ADV" lemma="ne" subcat="neg">n?</w><w cat="V" lemma="?tre" mph="P3s" subcat="">est</w></VN><AdP fct="MOD"><w compound="yes" cat="ADV" lemma="peut-?tre"><w catint="V">peut</w><w catint="PONCT">-</w><w catint="V">?tre</w></w><w cat="ADV" lemma="pas" subcat="neg">pas</w></AdP><AP fct="ATS"><w cat="ADV" lemma="aussi">aussi</w><w cat="A" lemma="sombre" mph="ms" subcat="qual">sombre</w></AP><w cat="PONCT" lemma="."
subcat="S">.</w></SENT>Figure 1: Simplified example of the FTBTo encode syntactic information, it uses a com-bination of labeled constituents, morphologicalannotations and functional annotation for verbaldependents as illustrated in Figure 1.
This con-stituent and functional annotation was performedin two successive steps : though the original re-lease (Abeill?
et al, 2000) consists of 20,648 sen-tences (hereafter FTB-V0), the functional annota-tion was performed later on a subset of 12351 sen-tences (hereafter FTB).
This subset has also beenrevised, and is known to be more consistently an-notated.
This is the release we use in our experi-ments.
Its key properties, compared with the PennTreebank, (hereafter PTB) are the following :Size : The FTB is made of 385 458 tokens and12351 sentences, that is the third of the PTB.
Theaverage length of a sentence is 31 tokens in theFTB, versus 24 tokens in the PTB.Inflection : French morphology is richer than En-glish and leads to increased data sparseness forstatistical parsing.
There are 24098 types in theFTB, entailing an average of 16 tokens occurringfor each type (versus 12 for the PTB).Flat structure : The annotation scheme is flatterin the FTB than in the PTB.
For instance, thereare no VPs for finite verbs, and only one sententiallevel for sentences whether introduced by comple-mentizer or not.
We can measure the corpus flat-ness using the ratio between tokens and non ter-minal symbols, excluding preterminals.
We obtain0.69 NT symbol per token for FTB and 1.01 for thePTB.Compounds : Compounds are explicitly annotated(see the compound peut-?tre in Figure 1 ) and veryfrequent : 14,52% of tokens are part of a com-pound.
They include digital numbers (written withspaces in French 10 000), very frozen compoundspomme de terre (potato) but also named entitiesor sequences whose meaning is compositional butwhere insertion is rare or difficult (garde d?enfant(child care)).Now let us focus on what is expressed in theFrench annotation scheme, and why syntactic in-formation is split between constituency and func-tional annotation.Syntactic categories and constituents capture dis-tributional generalizations.
A syntactic categorygroups forms that share distributional properties.Nonterminal symbols that label the constituentsare a further generalizations over sequences of cat-egories or constituents.
For instance about any-where it is grammatical to have a given NP, it isimplicitly assumed that it will also be grammati-cal - though maybe nonsensical - to have insteadany other NPs.
Of course this is known to be falsein many cases : for instance NPs with or with-out determiners have very different distributions inFrench (that may justify a different label) but theyalso share a lot.
Moreover, if words are taken intoaccount, and not just sequences of categories, thenconstituent labels are a very coarse generalization.Constituents also encode dependencies : for in-stance the different PP-attachment for the sen-tences I ate a cake with cream / with a fork re-flects that with cream depends on cake, whereaswith a fork depends on ate.
More precisely, asyntagmatic tree can be interpreted as a depen-dency structure using the following conventions :50for each constituent, given the dominating symboland the internal sequence of symbols, (i) a headsymbol can be isolated and (ii) the siblings of thathead can be interpreted as containing dependentsof that head.
Given these constraints, the syntag-matic structure may exhibit various degree of flat-ness for internal structures.Functional annotation Dependencies are en-coded in constituents.
While X-bar inspired con-stituents are supposed to contain all the syntac-tic information, in the FTB the shape of the con-stituents does not necessarily express unambigu-ously the type of dependency existing between ahead and a dependent appearing in the same con-stituent.
Yet this is crucial for example to ex-tract the underlying predicate-argument structures.This has led to a ?flat?
annotation scheme, com-pleted with functional annotations that inform onthe type of dependency existing between a verband its dependents.
This was chosen for Frenchto reflect, for instance, the possibility to mix post-verbal modifiers and complements (Figure 2), orto mix post-verbal subject and post-verbal indi-rect complements : a post verbal NP in the FTBcan correspond to a temporal modifier, (most of-ten) a direct object, or an inverted subject, and inthe three cases other subcategorized complementsmay appear.SENTNP-SUJDuneNlettreVNVavaitV?t?Venvoy?eNP-MODDlaNsemaineAderni?rePP-AOBJPauxNPNsalari?sSENTNP-SUJDLeNConseilVNVaVnotifi?NP-OBJDsaNd?cisionPP-AOBJP?NPDlaNbanqueFigure 2: Two examples of post-verbal NPs : adirect object and a temporal modifier3 Algorithms for probabilistic grammarlearningWe propose here to investigate how to apply statis-tical parsing techniques mainly tested on English,to another language ?
French ?.
In this section webriefly introduce the algorithms investigated.Though Probabilistic Context Free Grammars(PCFG) is a baseline formalism for probabilisticparsing, it suffers a fundamental problem for thepurpose of natural language parsing : the inde-pendence assumptions made by the model are toostrong.
In other words all decisions are local to agrammar rule.However as clearly pointed out by (Johnson,1998) decisions have to take into account non lo-cal grammatical properties: for instance a nounphrase realized in subject position is more likely tobe realized by a pronoun than a noun phrase real-ized in object position.
Solving this first method-ological issue, has led to solutions dubbed here-after as unlexicalized statistical parsing (Johnson,1998; Klein and Manning, 2003a; Matsuzaki etal., 2005; Petrov et al, 2006).A second class of non local decisions to betaken into account while parsing natural languagesare related to handling lexical constraints.
Asshown above the subcategorization properties ofa predicative word may have an impact on the de-cisions concerning the tree structures to be asso-ciated to a given sentence.
Solving this secondmethodological issue has led to solutions dubbedhereafter as lexicalized parsing (Charniak, 2000;Collins, 1999).In a supervised setting, a third and practicalproblem turns out to be critical: that of datasparseness since available treebanks are generallytoo small to get reasonable probability estimates.Three class of solutions are possible to reduce datasparseness: (1) enlarging the data manually or au-tomatically (e.g.
(McClosky et al, 2006) uses self-training to perform this step) (2) smoothing, usu-ally this is performed using a markovization pro-cedure (Collins, 1999; Klein and Manning, 2003a)and (3) make the data more coarse (i.e.
clustering).3.1 Lexicalized algorithmThe first algorithm we use is the lexicalized parserof (Collins, 1999).
It is called lexicalized, as itannotates non terminal nodes with an additionallatent symbol: the head word of the subtree.
Thisadditional information attached to the categoriesaims at capturing bilexical dependencies in orderto perform informed attachment choices.The addition of these numerous latent sym-bols to non terminals naturally entails an over-specialization of the resulting models.
To en-sure generalization, it therefore requires to addadditional simplifying assumptions formulated asa variant of usual na?ve Bayesian-style simplify-ing assumptions: the probability of emitting a non51head node is assumed to depend on the head andthe mother node only, and not on other siblingnodes1.Since Collins demonstrated his models to sig-nificantly improve parsing accuracy over barePCFG, lexicalization has been thought as a ma-jor feature for probabilistic parsing.
However twoproblems are worth stressing here: (1) the reasonwhy these models improve over bare PCFGs is notguaranteed to be tied to the fact that they capturebilexical dependencies and (2) there is no guar-antee that capturing non local lexical constraintsyields an optimal language model.Concerning (1) (Gildea, 2001) showed that fulllexicalization has indeed small impact on results :he reimplemented an emulation of Collins?
Model1 and found that removing all references to bilex-ical dependencies in the statistical model2, re-sulted in a very small parsing performance de-crease (PARSEVAL recall on WSJ decreased from86.1 to 85.6).
Further studies conducted by (Bikel,2004a) proved indeed that bilexical informationwere used by the most probable parses.
The ideais that most bilexical parameters are very similarto their back-off distribution and have therefore aminor impact.
In the case of French, this fact canonly be more true, with one third of training datacompared to English, and with a much richer in-flection that worsens lexical data sparseness.Concerning (2) the addition of head word an-notations is tied to the use of manually definedheuristics highly dependent on the annotationscheme of the PTB.
For instance, Collins?
mod-els integrate a treatment of coordination that is notadequate for the FTB-like coordination annotation.3.2 Unlexicalized algorithmsAnother class of algorithms arising from (John-son, 1998; Klein and Manning, 2003a) attemptsto attach additional latent symbols to treebank cat-egories without focusing exclusively on lexicalhead words.
For instance the additional annota-tions will try to capture non local preferences like1This short description cannot do justice to (Collins,1999) proposal which indeed includes more fine grained in-formations and a backoff model.
We only keep here the keyaspects of his work relevant for the current discussion.2Let us consider a dependent constituent C with headword Chw and head tag Cht, and let C be governed by a con-stituent H, with head word Hhw and head tag Hht.
Gildeacompares Collins model, where the emission of Chw is con-ditioned on Hhw, and a ?mono-lexical?
model, where theemission of Chw is not conditioned on Hhw.the fact that an NP in subject position is morelikely realized as a pronoun.The first unlexicalized algorithms set up in thistrend (Johnson, 1998; Klein and Manning, 2003a)also use language dependent and manually de-fined heuristics to add the latent annotations.
Thespecialization induced by this additional annota-tion is counterbalanced by simplifying assump-tions, dubbed markovization (Klein and Manning,2003a).Using hand-defined heuristics remains prob-lematic since we have no guarantee that the latentannotations added in this way will allow to extractan optimal language model.A further development has been first introducedby (Matsuzaki et al, 2005) who recasts the prob-lem of adding latent annotations as an unsuper-vised learning problem: given an observed PCFGinduced from the treebank, the latent grammar isgenerated by combining every non terminal of theobserved grammar to a predefined set H of latentsymbols.
The parameters of the latent grammarare estimated from the observed trees using a spe-cific instantiation of EM.This first procedure however entails a combi-natorial explosion in the size of the latent gram-mar as |H| increases.
(Petrov et al, 2006) (here-after BKY) overcomes this problem by using thefollowing algorithm: given a PCFG G0 inducedfrom the treebank, iteratively create n grammarsG1 .
.
.
Gn (with n = 5 in practice), where eachiterative step is as follows :?
SPLIT Create a new grammar Gi from Gi?1by splitting every non terminal of Gi intwo new symbols.
Estimate Gi?s parameterson the observed treebank using a variant ofinside-outside.
This step adds the latent an-notation to the grammar.?
MERGE For each pair of symbols obtainedby a previous split, try to merge them back.If the likelihood of the treebank does notget significantly lower (fixed threshold) thenkeep the symbol merged, otherwise keep thesplit.?
SMOOTH This step consists in smoothing theprobabilities of the grammar rules sharing thesame left hand side.This algorithm yields state-of-the-art results on52English3.
Its key interest is that it directly aimsat finding an optimal language model without (1)making additional assumptions on the annotationscheme and (2) without relying on hand-definedheuristics.
This may be viewed as a case of semi-supervised learning algorithm since the initial su-pervised learning step is augmented with a secondstep of unsupervised learning dedicated to assignthe latent symbols.4 Experiments and ResultsWe investigate how some treebank features impactlearning.
We describe first the experimental pro-tocol, next we compare results of lexicalized andunlexicalized parsers trained on various ?instan-tiations?
of the xml source files of the FTB, andthe impact of training set size for both algorithms.Then we focus on studying how words impact theresults of the BKYalgorithm.4.1 ProtocolTreebank setting For all experiments, the tree-bank is divided into 3 sections : training (80%),development (10%) and test (10%), made ofrespectively 9881, 1235 and 1235 sentences.We systematically report the results with thecompounds merged.
Namely, we preprocess thetreebank in order to turn each compound into asingle token both for training and test.Software and adaptation to French For theCollins algorithm, we use Bikel?s implementation(Bikel, 2004b) (hereafter BIKEL), and we reportresults using Collins model 1 and model 2, withinternal tagging.
Adapting model 1 to Frenchrequires to design French specific head propaga-tion rules.
To this end, we adapted those de-scribed by (Dybro-Johansen, 2004) for extractinga Stochastic Tree Adjoining Grammar parser onFrench.
And to adapt model 2, we have furtherdesigned French specific argument/adjunct identi-fication rules.For the BKY approach, we use the Berkeleyimplementation, with an horizontal markovizationh=0, and 5 split/merge cycles.
All the requiredknowledge is contained in the treebank used fortraining, except for the treatment of unknown orrare words.
It clusters unknown words using ty-pographical and morphological information.
We3(Petrov et al, 2006) obtain an F-score=90.1 for sentencesof less than 40 words.adapted these clues to French, following (Arunand Keller, 2005).Finally we use as a baseline a standard PCFGalgorithm, coupled with a trigram tagger (we referto this setup as TNT/LNCKY algorithm4).Metrics For evaluation, we use the standard PAR-SEVAL metric of labeled precision/recall, alongwith unlabeled dependency evaluation, which isknown as a more annotation-neutral metric.
Unla-beled dependencies are computed using the (Lin,1995) algorithm, and the Dybro-Johansen?s headpropagation rules cited above5.
The unlabeleddependency F-score gives the percentage of in-put words (excluding punctuation) that receive thecorrect head.As usual for probabilistic parsing results, the re-sults are given for sentences of the test set of lessthan 40 words (which is true for 992 sentences ofthe test set), and punctuation is ignored for F-scorecomputation with both metrics.4.2 Comparison using minimal tagsetsWe first derive from the FTB a minimally-informed treebank, TREEBANKMIN, instantiatedfrom the xml source by using only the major syn-tactic categories and no other feature.
In each ex-periment (Table 1) we observe that the BKY al-gorithm significantly outperforms Collins models,for both metrics.parser BKY BIKEL BIKEL TNT/metric M1 M2 LNCKYPARSEVAL LP 85.25 78.86 80.68 68.74PARSEVAL LR 84.46 78.84 80.58 67.93PARSEVAL F1 84.85 78.85 80.63 68.33Unlab.
dep.
Prec.
90.23 85.74 87.60 79.50Unlab.
dep.
Rec.
89.95 85.72 86.90 79.37Unlab.
dep.
F1 90.09 85.73 87.25 79.44Table 1: Results for parsers trained on FTB withminimal tagset4The tagger is TNT (Brants, 2000), and the parseris LNCKY, that is distributed by Mark Johnson(http://www.cog.brown.edu/?mj/Software.htm).Formally because of the tagger, this is not a strict PCFGsetup.
Rather, it gives a practical trade-off, in which thetagger includes the lexical smoothing for unknown and rarewords.5For this evaluation, the gold constituent trees are con-verted into pseudo-gold dependency trees (that may con-tain errors).
Then parsed constituent trees are convertedinto parsed dependency trees, that are matched against thepseudo-gold trees.534.3 Impact of training data sizeHow do the unlexicalized and lexicalized ap-proaches perform with respect to size?
We com-pare in figure 3 the parsing performance BKY andCOLLINSM1, on increasingly large subsets of theFTB, in perfect tagging mode6 and using a moredetailed tagset (CC tagset, described in the nextexperiment).
The same 1235-sentences test setis used for all subsets, and the development set?ssize varies along with the training set?s size.
BKYoutperforms the lexicalized model even with smallamount of data (around 3000 training sentences).Further, the parsing improvement that would re-sult from more training data seems higher for BKYthan for Bikel.2000 4000 6000 8000 1000076788082848688Number of training sentencesF?scoreBikelBerkeleyFigure 3: Parsing Learning curve on FTB with CC-tagset, in perfect-taggingThis potential increase for BKY results if wehad more French annotated data is somehow con-firmed by the higher results reported for BKYtraining on the Penn Treebank (Petrov et al, 2006): F1=90.2.
We can show though that the 4 pointsincrease when training on English data is not onlydue to size : we extracted from the Penn Treebanka subset comparable to the FTB, with respect tonumber of tokens and average length of sentences.We obtain F1=88.61 with BKY training.4.4 Symbol refinementsIt is well-known that certain treebank transfor-mations involving symbol refinements improve6For BKY, we simulate perfect tagging by changingwords into word+tag in training, dev and test sets.
We ob-tain around 99.8 tagging accuracy, errors are due to unknownwords.PCFGs (see for instance parent-transformation of(Johnson, 1998), or various symbol refinements in(Klein and Manning., 2003b)).
Lexicalization it-self can be seen as symbol refinements (with back-off though).
For BKY, though the key point is toautomatize symbol splits, it is interesting to studywhether manual splits still help.We have thus experimented BKY training withvarious tagsets.
The FTB contains rich mor-phological information, that can be used to splitpreterminal symbols : main coarse category (thereare 13), subcategory (subcat feature refining themain cat), and inflectional information (mph fea-ture).We report in Table 2 results for the four tagsets,where terminals are made of : MIN: main cat,SUBCAT: main cat + subcat feature, MAX: cat +subcat + all inflectional information, CC: cat + ver-bal mood + wh feature.Tagset Nb of tags Parseval Unlab.
dep TaggingF1 F1 AccMIN 13 84.85 90.09 97.35SUBCAT 34 85.74 ?
96.63MAX 250 84.13 ?
92.20CC 28 86.41 90.99 96.83Table 2: Tagset impact on learning with BKY (owntagging)The corpus instantiation with CC tagset is ourbest trade-off between tagset informativeness andobtained parsing performance7 .
It is also the bestresult obtained for French probabilistic parsing.This demonstrates though that the BKY learningis not optimal since manual a priori symbol refine-ments significantly impact the results.We also tried to learn structures with functionalannotation attached to the labels : we obtain PAR-SEVAL F1=78.73 with tags from the CC tagset +grammatical function.
This degradation, due todata sparseness and/or non local constraints badlycaptured by the model, currently constrains us touse a language model without functional informa-tions.
As stressed in the introduction, this limitsthe interpretability of the parses and it is a trade-off between generalization and interpretability.4.5 Lexicon and Inflection impactFrench has a rich morphology that allows somedegree of word order variation, with respect to7The differences are statistically significant : using a stan-dard t-test, we obtain p-value=0.015 between MIN and SUB-CAT, and p-value=0.002 between CC and SUBCAT.54English.
For probabilistic parsing, this can havecontradictory effects : (i) on the one hand, thisinduces more data sparseness : the occurrencesof a French regular verb are potentially split intomore than 60 forms, versus 5 for an Englishverb; (ii) on the other hand, inflection encodesagreements, that can serve as clues for syntacticattachments.Experiment In order to measure the impactof inflection, we have tested to cluster wordforms on a morphological basis, namely to partlycancel inflection.
Using lemmas as word formclasses seems too coarse : it would not allow todistinguish for instance between a finite verb anda participle, though they exhibit different distri-butional properties.
Instead we use as word formclasses, the couple lemma + syntactic category.For example for verbs, given the CC tagset, thisamounts to keeping 6 different forms (for the 6moods).To test this grouping, we derive a treebank wherewords are replaced by the concatenation of lemma+ category for training and testing the parser.Since it entails a perfect tagging, it has to becompared to results in perfect tagging mode :more precisely, we simulate perfect taggingby replacing word forms by the concatenationform+tag.Moreover, it is tempting to study the impact ofa more drastic clustering of word forms : that ofusing the sole syntactic category to group wordforms (we replace each word by its tag).
Thisamounts to test a pure unlexicalized learning.Discussion Results are shown in Figure 4.We make three observations : First, comparingthe terminal=tag curves with the other two, itappears that the parser does take advantage oflexical information to rank parses, even for this?unlexicalized?
algorithm.
Yet the relatively smallincrease clearly shows that lexical informationremains underused, probably because of lexicaldata sparseness.Further, comparing terminal=lemma+tag and ter-minal=form+tag curves, we observe that groupingwords into lemmas helps reducing this sparseness.And third, the lexicon impact evolution (i.e.the increment between terminal=tag and termi-nal=form+tag curves) is stable, once the trainingsize is superior to approx.
3000 sentences8 .This suggests that only very frequent wordsmatter, otherwise words?
impact should be moreand more important as training material augments.0 2000 4000 6000 8000 1000076788082848688Number of training sentencesParsevalF?scoreBky terminal=form+tagBky terminal=lemma+tagBky terminal=tagFigure 4: Impact of clustering word forms (train-ing on FTB with CC-tagset, in perfect-tagging)5 Related WorkPrevious works on French probabilistic parsing arethose of (Arun and Keller, 2005), (Schluter andvan Genabith, 2007), (Schluter and van Genabith,2008).
One major difficulty for comparison is thatall three works use a different version of the train-ing corpus.
Arun reports results on probabilisticparsing, using an older version of the FTB and us-ing lexicalized models (Collins M1 and M2 mod-els, and the bigram model).
It is difficult to com-pare our results with Arun?s work, since the tree-bank he has used is obsolete (FTB-V0).
He obtainsfor Model 1 : LR=80.35 / LP=79.99, and for thebigram model : LR=81.15 / LP=80.84, with min-imal tagset and internal tagging.
The results withFTB (revised subset of FTB-V0) with minimal8 This is true for all points in the curves, except forthe last step, i.e.
when full training set is used.
We per-formed a 10-fold cross validation to limit sample effects.
Forthe BKYtraining with CC tagset, and own tagging, we ob-tain an average F-score of 85.44 (with a rather high stan-dard deviation ?=1.14).
For the clustering word forms ex-periment, using the full training set, we obtain : 86.64 forterminal=form+tag (?=1.15), 87.33 for terminal=lemma+tag(?=0.43), and 85.72 for terminal=tag (?=0.43).
Hence ourconclusions (words help even with unlexicalized algorithm,and further grouping words into lemmas helps) hold indepen-dently of sampling.55tagset (Table 1) are comparable for COLLINSM1,and nearly 5 points higher for BKY.It is also interesting to review (Arun and Keller,2005) conclusion, built on a comparison with theGerman situation : at that time lexicalization wasthought (Dubey and Keller, 2003) to have no siz-able improvement on German parsing, trained onthe Negra treebank, that uses a flat structures.
So(Arun and Keller, 2005) conclude that since lex-icalization helps much more for parsing French,with a flat annotation, then word-order flexibilityis the key-factor that makes lexicalization useful(if word order is fixed, cf.
French and English)and useless (if word order is flexible, cf.
German).This conclusion does not hold today.
First, it canbe noted that as far as word order flexibility is con-cerned, French stands in between English and Ger-man.
Second, it has been proven that lexicalizationhelps German probabilistic parsing (K?bler et al,2006).
Finally, these authors show that markoviza-tion of the unlexicalized Stanford parser gives al-most the same increase in performance than lex-icalization, both for the Negra treebank and theT?ba-D/Z treebank.
This conclusion is reinforcedby the results we have obtained : the unlexicalized,markovized, PCFG-LA algorithm outperforms theCollins?
lexicalized model.
(Schluter and van Genabith, 2007) aim at learn-ing LFG structures for French.
To do so, and inorder to learn first a Collins parser, N. Schlutercreated a modified treebank, the MFT, in order (i)to fit her underlying theoretical requirements, (ii)to increase the treebank coherence by error min-ing and (iii) to improve the performance of thelearnt parser.
The MFT contains 4739 sentencestaken from the FTB, with semi-automatic trans-formations.
These include increased rule stratifi-cation, symbol refinements (for information prop-agation), coordination raising with some manualre-annotation, and the addition of functional tags.MFT has also undergone a phase of error min-ing, using the (Dickinson and Meurers, 2005) soft-ware, and following manual correction.
She re-ports a 79.95% F-score on a 400 sentence testset, which compares almost equally with Arun?sresults on the original 20000 sentence treebank.So she attributes her results to the increased co-herence of her smaller treebank.
Indeed, we ranthe BKY training on the MFT, and we get F-score=84.31.
While this is less in absolute thanthe BKY results obtained with FTB (cf.
results intable 2), it is indeed very high if training data sizeis taken into account (cf.
the BKY learning curvein figure 3).
This good result raises the open ques-tion of identifying which modifications in the MFT(error mining and correction, tree transformation,symbol refinements) have the major impact.6 ConclusionThis paper reports results in statistical parsingfor French with both unlexicalized (Petrov et al,2006) and lexicalized parsers.
To our knowledge,both results are state of the art on French for eachparadigm.Both algorithms try to overcome PCFG?s sim-plifying assumptions by some specialization of thegrammatical labels.
For the lexicalized approach,the annotation of symbols with lexical head isknown to be rarely fully used in practice (Gildea,2001), what is really used being the category ofthe lexical head.We observe that the second approach (BKY)constantly outperforms the lexicalist strategy ?
la(Collins, 1999).
We observe however that (Petrovet al, 2006)?s semi-supervised learning procedureis not fully optimal since a manual refinement ofthe treebank labelling turns out to improve theparsing results.Finally we observe that the semi-supervisedBKY algorithm does take advantage of lexical in-formation : removing words degrades results.
Thepreterminal symbol splits percolates lexical dis-tinctions.
Further, grouping words into lemmashelps for a morphologically rich language such asFrench.
So, an intermediate clustering standingbetween syntactic category and lemma is thoughtto yield better results in the future.7 AcknowledgmentsWe thank N. Schluter and J. van Genabith forkindly letting us run BKY on the MFT, and A.Arun for answering our questions.
We also thankthe reviewers for valuable comments and refer-ences.
The work of the second author was partlyfunded by the ?Prix Diderot Innovation 2007?,from University Paris 7.56ReferencesAnne Abeill?, Lionel Cl?ment, and Alexandra Kinyon.2000.
Building a treebank for french.
In Proceed-ings of the 2nd International Conference LanguageResources and Evaluation (LREC?00).Anne Abeill?, Lionel Cl?ment, and Fran?ois Toussenel,2003.
Building a treebank for French.
Kluwer, Dor-drecht.Abhishek Arun and Frank Keller.
2005.
Lexicalizationin crosslinguistic probabilistic parsing: The case offrench.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguis-tics, pages 306?313, Ann Arbor, MI.Daniel M. Bikel.
2004a.
A distributional analysisof a lexicalized statistical parsing model.
In Proc.of Empirical Methods in Natural Language Pro-cessing (EMNLP 2004), volume 4, pages 182?189,Barcelona, Spain.Daniel M. Bikel.
2004b.
Intricacies of Collins?
ParsingModel.
Computational Linguistics, 30(4):479?511.Thorsten Brants.
2000.
Tnt ?
a statistical part-of-speech tagger.
In Proceedings of the 6th AppliedNLP Conference (ANLP), Seattle-WA.Eugene Charniak.
2000.
A maximum-entropy-inspired parser.
In Proceedings of the Annual Meet-ing of the North American Association for Com-putational Linguistics (NAACL-00), pages 132?139,Seattle, Washington.Michael Collins.
1999.
Head driven statistical modelsfor natural language parsing.
Ph.D. thesis, Univer-sity of Pennsylvania, Philadelphia.Benoit Crabb?
and Marie Candito.
2008.
Exp?riencesd?analyse syntaxique statistique du fran?ais.
InActes de la 15?me Conf?rence sur le Traitement Au-tomatique des Langues Naturelles (TALN?08), pages45?54, Avignon.Markus Dickinson and W. Detmar Meurers.
2005.Prune diseased branches to get healthy trees!
howto find erroneous local trees in treebank and whyit matters.
In Proceedings of the 4th Workshopon Treebanks and Linguistic Theories (TLT 2005),Barcelona, Spain.Amit Dubey and Frank Keller.
2003.
Probabilis-tic parsing for german using sister-head dependen-cies.
In In Proceedings of the 41st Annual Meet-ing of the Association for Computational Linguis-tics, pages 96?103.Ane Dybro-Johansen.
2004.
Extraction automatiquede grammaires ?
partir d?un corpus fran?ais.
Mas-ter?s thesis, Universit?
Paris 7.Daniel Gildea.
2001.
Corpus variation and parser per-formance.
In Proceedings of the First Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 167?202.Mark Johnson.
1998.
PCFG models of linguis-tic tree representations.
Computational Linguistics,24(4):613?632.Dan Klein and Christopher D. Manning.
2003a.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics-Volume 1, pages 423?430.
Asso-ciation for Computational Linguistics Morristown,NJ, USA.Dan Klein and Christopher D. Manning.
2003b.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Meeting of the Association for ComputationalLinguistics.Sandra K?bler, Erhard W. Hinrichs, and WolfgangMaier.
2006.
Is it really that difficult to parse ger-man?
In Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Process-ing, pages 111?119, Sydney, Australia, July.
Asso-ciation for Computational Linguistics.Dekang Lin.
1995.
A dependency-based method forevaluating broad-coverage parsers.
In InternationalJoint Conference on Artificial Intelligence, pages1420?1425, Montreal.Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii.2005.
Probabilistic cfg with latent annotations.
InProceedings of the 43rd Annual Meeting of the Asso-ciation for Computational Linguistics (ACL), pages75?82.David McClosky, Eugene Charniak, and Mark John-son.
2006.
Effective self-training for parsing.
InProceedings of the Human Language TechnologyConference of the NAACL, Main Conference, pages152?159, New York City, USA, June.
Associationfor Computational Linguistics.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, andinterpretable tree annotation.
In Proceedings ofthe 21st International Conference on ComputationalLinguistics and 44th Annual Meeting of the Associ-ation for Computational Linguistics, Sydney, Aus-tralia, July.
Association for Computational Linguis-tics.Natalie Schluter and Josef van Genabith.
2007.Preparing, restructuring, and augmenting a frenchtreebank: Lexicalised parsers or coherent treebanks?In Proceedings of PACLING 07.Natalie Schluter and Josef van Genabith.
2008.Treebank-based acquisition of lfg parsing resourcesfor french.
In European Language Resources As-sociation (ELRA), editor, Proceedings of the SixthInternational Language Resources and Evaluation(LREC?08), Marrakech, Morocco, may.57
