Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 37?42,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsDKPro WSD ?
A Generalized UIMA-based Frameworkfor Word Sense DisambiguationTristan Miller1 Nicolai Erbs1 Hans-Peter Zorn1 Torsten Zesch1,2 Iryna Gurevych1,2(1) Ubiquitous Knowledge Processing Lab (UKP-TUDA)Department of Computer Science, Technische Universita?t Darmstadt(2) Ubiquitous Knowledge Processing Lab (UKP-DIPF)German Institute for Educational Research and Educational Informationhttp://www.ukp.tu-darmstadt.de/AbstractImplementations of word sense disam-biguation (WSD) algorithms tend to betied to a particular test corpus format andsense inventory.
This makes it difficult totest their performance on new data sets, orto compare them against past algorithmsimplemented for different data sets.
In thispaper we present DKPro WSD, a freelylicensed, general-purpose framework forWSD which is both modular and exten-sible.
DKPro WSD abstracts the WSDprocess in such a way that test corpora,sense inventories, and algorithms can befreely swapped.
Its UIMA-based architec-ture makes it easy to add support for newresources and algorithms.
Related taskssuch as word sense induction and entitylinking are also supported.1 IntroductionWord sense disambiguation, or WSD (Agirre andEdmonds, 2006)?the task of determining whichof a word?s senses is the one intended in a par-ticular context?has been a core research problemin computational linguistics since the very incep-tion of the field.
Despite the task?s importanceand popularity as a subject of study, tools and re-sources supporting WSD have seen relatively littlegeneralization and standardization.
That is, mostprior implementations of WSD systems have beenhard-coded for particular algorithms, sense inven-tories, and data sets.
This makes it difficult to com-pare systems or to adapt them to new scenarioswithout extensive reimplementation.In this paper we present DKPro WSD, ageneral-purpose framework for word sense disam-biguation which is both modular and extensible.Its modularity means that it makes a logical sep-aration between the data sets (e.g., the corporato be annotated, the answer keys, manually anno-tated training examples, etc.
), the sense invento-ries (i.e., the lexical-semantic resources enumerat-ing the senses to which words in the corpora areassigned), and the algorithms (i.e., code which ac-tually performs the sense assignments and prereq-uisite linguistic annotations), and provides a stan-dard interface for each of these component types.Components which provide the same functional-ity can be freely swapped, so that one can easilyrun the same algorithm on different data sets (irre-spective of which sense inventory they use), or testseveral different algorithms on the same data set.While DKPro WSD ships with support for anumber of common WSD algorithms, sense inven-tories, and data set formats, its extensibility meansthat it is easy to adapt to work with new meth-ods and resources.
The system is written in Javaand is based on UIMA (Lally et al 2009), anindustry-standard architecture for analysis of un-structured information.
Support for new corpusformats, sense inventories, and WSD algorithmscan be added by implementing new UIMA com-ponents for them, or more conveniently by writingUIMA wrappers around existing code.
The frame-work and all existing components are released un-der the Apache License 2.0, a permissive free soft-ware licence.DKPro WSD was designed primarily to supportthe needs of WSD researchers, who will appre-ciate the convenience and flexibility it affords intuning and comparing algorithms and data sets.However, as a general-purpose toolkit it could alsobe used to implement a WSD module for a real-world natural language processing application.
Itssupport for interactive visualization of the disam-biguation process also makes it a powerful tool forlearning or teaching the principles of WSD.The remainder of this paper is organized as fol-lows: In ?2 we review previous work in WSD fileformats and implementations.
In ?3 we describe37our system and further explain its capabilities andadvantages.
Finally, in ?4 we discuss our plans forfurther development of the framework.2 BackgroundIn the early days of WSD research, electronicdictionaries and sense-annotated corpora tendedto be small and hand-crafted on an ad-hoc ba-sis.
It was not until the growing availability oflarge-scale lexical resources and corpora in the1990s that the need to establish a common plat-form for the evaluation of WSD systems was rec-ognized.
This led to the founding of the Sens-eval (and later SemEval) series of competitions,the first of which was held in 1998.
Each com-petition defined a number of tasks with prescribedevaluation metrics, sense inventories, corpus fileformats, and human-annotated test sets.
For eachtask it was therefore possible to compare algo-rithms against each other.
However, sense inven-tories and file formats still vary across tasks andcompetitions.
There are also a number of increas-ingly popular resources used outside Senseval andSemEval, each with their own formats and struc-tures: examples of sense-annotated corpora in-clude SemCor (Miller et al 1994), MASC (Ide etal., 2010), and WebCAGe (Henrich et al 2012),and sense inventories include VerbNet (Kipper etal., 2008), FrameNet (Ruppenhofer et al 2010),DANTE (Kilgarriff, 2010), BabelNet (Navigli andPonzetto, 2012), and online community-producedresources such as Wiktionary and Wikipedia.
Sodespite attempts at standardization, the canon ofWSD resources remains quite fragmented.The few publically available implementa-tions of individual disambiguation algorithms,such as SenseLearner (Mihalcea and Csomai,2005), SenseRelate::TargetWord (Patwardhan etal., 2005), UKB (Agirre and Soroa, 2009), andIMS (Zhong and Ng, 2010), are all tied to a partic-ular corpus and/or sense inventory, or define theirown custom formats into which existing resourcesmust be converted.
Furthermore, where the al-gorithm depends on linguistic annotations such aspart-of-speech tags, the users are expected to sup-ply these themselves, or else must use the anno-tators built into the system (which may not alwaysbe appropriate for the corpus language or domain).One alternative to coding WSD algorithms fromscratch is to use general-purpose NLP toolkitssuch as NLTK (Bird, 2006) or DKPro (Gurevychet al 2007).
Such toolkits provide individualcomponents potentially useful for WSD, such asWordNet-based measures of sense similarity andreaders for the odd corpus format.
However, thesetoolkits are not specifically geared towards devel-opment and evaluation of WSD systems; there isno unified type system or architecture which al-lows WSD-specific components to be combined orsubstituted orthogonally.The only general-purpose dedicated WSD sys-tem we are aware of is I Can Sense It (Joshi et al2012), a Web-based interface for running and eval-uating various WSD algorithms.
It includes I/Osupport for several corpus formats and implemen-tations of a number of baseline and state-of-the-art disambiguation algorithms.
However, as withprevious single-algorithm systems, it is not possi-ble to select the sense inventory, and the user isresponsible for pre-annotating the input text withPOS tags.
The usability and extensibility of thesystem are greatly restricted by the fact that it is aproprietary, closed-source application fully hostedby the developers.3 DKPro WSDOur system, DKPro WSD, is implemented as aframework of UIMA components (type systems,collection readers, annotators, CAS consumers,resources) which the user combines into a dataprocessing pipeline.
We can best illustrate thiswith an example: Figure 1 shows a pipeline forrunning two disambiguation algorithms on the Es-tonian all-words task from Senseval-2.
UIMAcomponents are the solid, rounded boxes in thelower half of the diagram, and the data and algo-rithms they encapsulate are the light grey shapesin the upper half.
The first component of thepipeline is a collection reader which reads thetext of the XML-formatted corpus into a CAS (aUIMA data structure for storing layers of dataand stand-off annotations) and marks the wordsto be disambiguated (the ?instances?)
with theirIDs.
The next component is an annotator whichreads the answer key?a separate file which as-sociates each instance ID with a sense ID fromthe Estonian EuroWordNet?and adds the gold-standard sense annotations to their respective in-stances in the CAS.
Processing then passes toanother annotator?in this case a UIMA wrap-per for TreeTagger (Schmid, 1994)?which addsPOS and lemma annotations to the instances.38corpusreaderanswer keyannotatorlinguisticannotatorWSDannotatorWSDannotatorsimplifiedLeskevaluatorsenseinventorySenseval-2Estonianall-wordstest corpusSenseval-2Estonianall-wordsanswer keyresults andstatistics     JMWNLEstonianEuro-WordNetdegreecentralityTree-TaggerEstonianlanguagemodelFigure 1: A sample DKPro WSD pipeline for the Estonian all-words data set from Senseval-2.Then come the two disambiguation algorithms,also modelled as UIMA annotators wrapping non-UIMA-aware algorithms.
Each WSD annotator it-erates over the instances in the CAS and annotatesthem with sense IDs from EuroWordNet.
(Euro-WordNet itself is accessed via a UIMA resourcewhich wraps JMWNL (Pazienza et al 2008) andwhich is bound to the two WSD annotators.)
Fi-nally, control passes to a CAS consumer whichcompares the WSD algorithms?
sense annotationsagainst the gold-standard annotations produced bythe answer key annotator, and outputs these senseannotations along with various evaluation metrics(precision, recall, etc.
).A pipeline of this sort can be written with justa few lines of code: one or two to declare eachcomponent and if necessary bind it to the appro-priate resources, and a final one to string the com-ponents together into a pipeline.
Moreover, oncesuch a pipeline is written it is simple to substitutefunctionally equivalent components.
For example,with only a few small changes the same pipelinecould be used for Senseval-3?s English lexicalsample task, which uses a corpus and sense inven-tory in a different format and language.
Specif-ically, we would substitute the collection readerwith one capable of reading the Senseval lexicalsample format, we would pass an English insteadof Estonian language model to TreeTagger, andwe would substitute the sense inventory resourceexposing the Estonian EuroWordNet with one forWordNet 1.7.1.
Crucially, none of the WSD algo-rithms need to be changed.The most important features of our system areas follows:Corpora and data sets.
DKPro WSD currentlyhas collection readers for all Senseval and Sem-Eval all-words and lexical sample tasks, the AIDACoNLL-YAGO data set (Hoffart et al 2011), theTAC KBP entity linking tasks (McNamee andDang, 2009), and the aforementioned MASC,SemCor, and WebCAGe corpora.
Our prepack-aged corpus analysis modules can compute statis-tics on monosemous terms, average polysemy,terms absent from the sense inventory, etc.Sense inventories.
Sense inventories are ab-stracted into a system of types and interfaces ac-cording to the sort of lexical-semantic informationthey provide.
There is currently support for Word-Net (Fellbaum, 1998), WordNet++ (Ponzetto andNavigli, 2010), EuroWordNet (Vossen, 1998), theTurk Bootstrap Word Sense Inventory (Biemann,2013), and UBY (Gurevych et al 2012), whichprovides access to WordNet, Wikipedia, Wik-tionary, GermaNet, VerbNet, FrameNet, Omega-Wiki, and various alignments between them.
Thesystem can automatically convert between vari-ous versions of WordNet using the UPC mappings(Daude?
et al 2003).Algorithms.
As with sense inventories, WSDalgorithms have a type and interface hierarchy ac-cording to what knowledge sources they require.Algorithms and baselines already implemented in-clude the analytically calculated random sensebaseline; the most frequent sense baseline; theoriginal, simplified, extended, and lexically ex-panded Lesk variants (Miller et al 2012); various39graph connectivity approaches from Navigli andLapata (2010); Personalized PageRank (Agirreand Soroa, 2009); the supervised TWSI system(Biemann, 2013); and IMS (Zhong and Ng, 2010).Our open API permits users to program supportfor further knowledge-based and supervised algo-rithms.Linguistic annotators.
Many WSD algorithmsrequire linguistic annotations from segmenters,lemmatizers, POS taggers, parsers, etc.
Off-the-shelf UIMA components for producing such an-notations, such as those provided by DKPro Core(Gurevych et al 2007), can be used in a DKProWSD pipeline with little or no adaptation.Visualization tools.
We have enhanced somefamilies of algorithms with animated, interactivevisualizations of the disambiguation process.
Forexample, Figure 2 shows part of a screenshot fromthe interactive running of the degree centrality al-gorithm (Navigli and Lapata, 2010).
The system isdisambiguating the three content words in the sen-tence ?I drink milk with a straw.?
Red, green, andblue nodes represent senses (or more specifically,WordNet sense keys) of the words drink, milk,and straw, respectively; grey nodes are senses ofother words discovered by traversing semantic re-lations (represented by arcs) in the sense inven-tory.
The current traversal (toast%2:34:00:: tofuddle%2:34:00::) is drawn in a lighter colour.Mouseover tooltips provide more detailed infor-mation on senses.
We have found such visualiza-tions to be invaluable for understanding and de-bugging algorithms.Parameter sweeping.
The behaviour of manycomponents (or entire pipelines) can be altered ac-cording to various parameters.
For example, forthe degree centrality algorithm one must specifythe maximum search depth, the minimum vertexdegree, and the context size.
DKPro WSD canperform a parameter sweep, automatically runningthe pipeline once for every possible combinationof parameters in user-specified ranges and con-catenating the results into a table from which theoptimal system configurations can be identified.Reporting tools.
There are several reportingtools to support evaluation and error analysis.
Rawsense assignments can be output in a variety of for-mats (XML, HTML, CSV, Senseval answer key,etc.
), some of which support colour-coding toFigure 2: DKPro WSD?s interactive visualizationof a graph connectivity WSD algorithm.highlight correct and incorrect assignments.
Thesystem can also compute common evaluation met-rics (Agirre and Edmonds, 2006, pp.
76?80) andplot precision?recall curves for each algorithm inthe pipeline, as well as produce confusion matri-ces for algorithm pairs.
Users can specify backoffalgorithms, and have the system compute resultswith and without the backoff.
Results can also bebroken down by part of speech.
Figure 3 showsan example of an HTML report produced by thesystem?on the left is the sense assignment table,in the upper right is a table of evaluation metrics,and in the lower right is a precision?recall graph.DKPro WSD also has support for tasks closelyrelated to word sense disambiguation:Entity linking.
Entity linking (EL) is the task oflinking a named entity in a text (e.g., Washington)to its correct representation in some knowledgebase (e.g., either George Washington or Washing-ton, D.C. depending on the context).
EL is verysimilar to WSD in that both tasks involve connect-ing ambiguous words in a text to entries in someinventory.
DKPro WSD supports EL-specificsense inventories such as the list of Wikipediaarticles used in the Knowledge Base Populationworkshop of the Text Analysis Conference (TACKBP).
This workshop, held annually since 2009,provides a means for comparing different EL sys-tems in a controlled setting.
DKPro WSD containsa reader for the TAC KBP data set, componentsfor mapping other sense inventories to the TACKBP inventory, and evaluation components for the40Figure 3: An HTML report produced by DKPro WSD.official metrics.
Researchers can therefore miti-gate the entry barrier for their first participation atTAC KBP and experienced participants can extendtheir systems by making use of further WSD algo-rithms.Word sense induction.
WSD is usually per-formed with respect to manually created sense in-ventories such as WordNet.
In word sense induc-tion (WSI) a sense inventory for target words isautomatically constructed from an unlabelled cor-pus.
This can be useful for search result cluster-ing, or for general applications of WSD for lan-guages and domains for which a sense inventoryis not yet available.
It is usually necessary to per-form WSD at some point in the evaluation of WSI.DKPro WSD supports WSI by providing state-of-the art WSD algorithms capable of using arbitrarysense inventories, including induced ones.
It alsoincludes readers and writers for the SemEval-2007and -2013 WSI data sets.4 Conclusions and future workIn this paper we introduced DKPro WSD, a Java-and UIMA-based framework for word sense dis-ambiguation.
Its primary advantages over exist-ing tools are its modularity, its extensibility, andits free licensing.
By segregating and providinglayers of abstraction for code, data sets, and senseinventories, DKPro WSD greatly simplifies thecomparison of WSD algorithms in heterogeneousscenarios.
Support for a wide variety of commonlyused algorithms, data sets, and sense inventorieshas already been implemented.The framework is under active development,with work on several new features planned or inprogress.
These include implementations or wrap-pers for further algorithms and for the DANTEand BabelNet sense inventories.
A Web inter-face is in the works and should be operationalby the time of publication.
Source code, bi-naries, documentation, tutorials, FAQs, an issuetracker, and community mailing lists are avail-able on the project?s website at https://code.google.com/p/dkpro-wsd/.AcknowledgmentsThis work has been supported by the VolkswagenFoundation as part of the Lichtenberg Professor-ship Program under grant No?
I/82806.41ReferencesEneko Agirre and Philip Edmonds, editors.
2006.Word Sense Disambiguation: Algorithms and Appli-cations.
Springer.Eneko Agirre and Aitor Soroa.
2009.
PersonalizingPageRank for word sense disambiguation.
In Proc.EACL, pages 33?41.Chris Biemann.
2013.
Creating a system for lexi-cal substitutions from scratch using crowdsourcing.Lang.
Resour.
and Eval., 47(1):97?122.Steven Bird.
2006.
NLTK: The natural languagetoolkit.
In Proc.
ACL-COLING (Interactive Presen-tation Sessions), pages 69?72.Jordi Daude?, Llu?
?s Padro?, and German Rigau.
2003.Validation and tuning of WordNet mapping tech-niques.
In Proc.
RANLP, pages 117?123.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.Iryna Gurevych, Max Mu?hlha?user, Christof Mu?ller,Ju?rgen Steimle, Markus Weimer, and Torsten Zesch.2007.
Darmstadt Knowledge Processing Reposi-tory Based on UIMA.
In Proc.
UIMA Workshop atGLDV.Iryna Gurevych, Judith Eckle-Kohler, Silvana Hart-mann, Michael Matuschek, Christian M. Meyer, andChristian Wirth.
2012.
UBY ?
A large-scale unifiedlexical-semantic resource.
In Proc.
EACL, pages580?590.Verena Henrich, Erhard Hinrichs, and Tatiana Vodola-zova.
2012.
WebCAGe ?
A Web-harvested corpusannotated with GermaNet senses.
In Proc.
EACL,pages 387?396.Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-dino, Hagen Fu?rstenau, Manfred Pinkal, Marc Span-iol, Bilyana Taneva, Stefan Thater, and GerhardWeikum.
2011.
Robust disambiguation of namedentities in text.
In Proc.
EMNLP, pages 782?792.Nancy Ide, Christiane Fellbaum, Collin Baker, and Re-becca Passonneau.
2010.
The Manually AnnotatedSub-Corpus: A community resource for and by thepeople.
In Proc.
ACL (Short Papers), pages 68?73.Salil Joshi, Mitesh M. Khapra, and Pushpak Bhat-tacharyya.
2012.
I Can Sense It: A comprehensiveonline system for WSD.
In Proc.
COLING (DemoPapers), pages 247?254.Adam Kilgarriff.
2010.
A detailed, accurate, exten-sive, available English lexical database.
In Proc.NAACL-HLT, pages 21?24.Karin Kipper, Anna Korhonen, Neville Ryant, andMartha Palmer.
2008.
A large-scale classification ofEnglish verbs.
Lang.
Resour.
and Eval., 42(1):21?40.Adam Lally, Karin Verspoor, and Eric Nyberg, editors.2009.
Unstructured Information Management Ar-chitecture (UIMA) Version 1.0.
OASIS.Paul McNamee and Hoa Trang Dang.
2009.
Overviewof the TAC 2009 knowledge base population track.In Proc.
TAC.Rada Mihalcea and Andras Csomai.
2005.
Sense-Learner: Word sense disambiguation for all wordsin unrestricted text.
In Proc.
ACL (System Demos),pages 53?56.George A. Miller, Martin Chodorow, Shari Landes,Claudio Leacock, and Robert G. Thomas.
1994.
Us-ing a semantic concordance for sense identification.In Proc.
HLT, pages 240?243.Tristan Miller, Chris Biemann, Torsten Zesch, andIryna Gurevych.
2012.
Using distributional similar-ity for lexical expansion in knowledge-based wordsense disambiguation.
In Proc.
COLING, pages1781?1796.Roberto Navigli and Mirella Lapata.
2010.
An experi-mental study of graph connectivity for unsupervisedword sense disambiguation.
IEEE Trans.
on PatternAnal.
and Machine Intel., 32(4):678?692.Roberto Navigli and Simone Paolo Ponzetto.
2012.An overview of BabelNet and its API for multilin-gual language processing.
In Iryna Gurevych andJungi Kim, editors, The People?s Web Meets NLP:Collaboratively Constructed Language Resources.Springer.Siddharth Patwardhan, Satanjeev Banerjee, and TedPedersen.
2005.
SenseRelate::TargetWord ?
A gen-eralized framework for word sense disambiguation.In Proc.
ACL (System Demos), pages 73?76.Maria Teresa Pazienza, Armando Stellato, and Alexan-dra Tudorache.
2008.
JMWNL: An extensible mul-tilingual library for accessing wordnets in differentlanguages.
In Proc.
LREC, pages 28?30.Simone Paolo Ponzetto and Roberto Navigli.
2010.Knowledge-rich word sense disambiguation rivalingsupervised systems.
In Proc.
ACL, pages 1522?1531.Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.Petruck, Christopher R. Johnson, and Jan Schef-fczyk.
2010.
FrameNet II: Extended Theory andPractice.
International Computer Science Institute.Helmud Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proc.
NeMLaP.Piek Vossen, editor.
1998.
EuroWordNet: A Multi-lingual Database with Lexical Semantic Networks.Springer.Zhi Zhong and Hwee Tou Ng.
2010.
It Makes Sense:A wide-coverage word sense disambiguation systemfor free text.
In Proc.
ACL (System Demos), pages78?83.42
