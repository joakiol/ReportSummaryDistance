Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1949?1954,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsCharacter Sequence Models for Colorful WordsKazuya Kawakami ?, Chris Dyer??
Bryan R. Routledge?
Noah A.
Smith?
?School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA?Google DeepMind, London, UK?Tepper School of Business, Carnegie Mellon University, Pittsburgh, PA, USA?Computer Science & Engineering, University of Washington, Seattle, WA, USA{kkawakam,cdyer}@cs.cmu.edu, routledge@cmu.edu, nasmith@cs.washington.eduAbstractWe present a neural network architecture topredict a point in color space from the se-quence of characters in the color?s name.Using large scale color?name pairs obtainedfrom an online color design forum, we eval-uate our model on a ?color Turing test?
andfind that, given a name, the colors predicted byour model are preferred by annotators to colornames created by humans.
Our datasets anddemo system are available online at http://colorlab.us.1 IntroductionColor is a valuable vehicle for studying the associa-tion between words and their nonlinguistic referents.Perception of color has long been studied in psy-chology, and quantitative models linking physicalstimuli and psychological perception have been inplace since the 1920s (Broadbent, 2004).
Althoughperceptually faithful color representations requireonly a few dimensions (?2), linguistic expressionsof color often rely on association and figurative lan-guage.
There are, for example, 34,000 examples of?blue?
in our data.
The varieties of blue range canbe emotional, descriptive, metaphoric, literal, andwhimsical.
Consider these examples (best viewedin color): murkey blue, blueberry muffin, greenyblue, and jazzy blue.This rich variety of descriptive names of colorsprovides an ideal way to study linguistic creativity,its variation, and an important aspect of visual un-derstanding.
This paper uses predictive modeling toexplore the relationship between colors (representedin three dimensions) and casual, voluntary linguis-tic descriptions of them by users of a crafting anddesign website (?3).1In this dataset?s creative vocabulary, word-levelrepresentations are so sparse as to be useless, so weturn to models that build name representations out ofcharacters (?4).
We evaluate our model on a ?colorTuring test?
and find that, given a name, it tends togenerate a color that humans find matches the namebetter than the color that actually inspired the name.We also investigate the reverse mapping, from colorsto names (?5).
We compare a conditional LSTM lan-guage model used in caption generation (Karpathyand Fei-Fei, 2014) to a new latent-variable model,achieving a 10% perplexity reduction.We expect such modeling to find purchase incomputational creativity applications (Veale and Al-Najjar, 2015), design and marketing aids (Deng etal., 2010), and new methods for studying the inter-face between the human visual and linguistic sys-tems (Marcus, 1991).2 Color SpacesIn electronic displays and other products, colors arecommonly represented in RGB space where eachcolor is embedded in {0, .
.
.
, 255}3, with coordi-nates corresponding to red, green, and blue levels.While convenient for digital processing, distancesin this space are perceptually non-uniform.
We in-stead use a different three-dimensional representa-tion, Lab, which was originally designed so thatEuclidean distances correlate with human-perceiveddifferences (Hunter, 1958).
Lab is also continu-1http://www.colourlovers.com1949Number of pairs Unique namesTrain 670,032 476,713Dev.
53,166 52,753Test 53,166 52,760ggplot2 66 66Paint 956 956Table 1: Datasets used in this paper.
The train/dev./test split ofthe COLOURlovers data was random.
For ggplot2 and Paint,we show the number of test instances which are not in Train set.ous, making it more suitable for the gradient-basedlearning used in this paper.
The transformation fromRGB to Lab is nonlinear.3 Task and DatasetWe consider the task of predicting a color inLab space given its name.
Our dataset is acollection of user-named colors downloaded fromCOLOURlovers,1 a creative community where peo-ple create and share colors, palettes, and patterns.Our dataset contains 776,364 pairs with 581,483unique names.
Examples of the color/name pairsfrom COLOURlovers are the following: SugarHearts You, Vitamin C, Haunted milk.We considered two held-out datasets from othersources; these do not overlap with the training data.ggplot2: the 141 officially-named colors used in gg-plot2, a common plotting package for the R pro-gramming language (e.g., MidnightBlue.
Medium-SeaGreen),2Paint: The paint manufacturer Sherwin Williamshas 7,750 named colors (e.g., Pompeii Red, ButterUp).34 Names to ColorsOur word-to-color model is used to predict a colorin Lab space given the sequence of characters ina color?s name, c = ?c1, c2, .
.
.
, c|c|?, where eachci is a character in a finite alphabet.
Each charac-ter ci is represented by learned vector embedding inR300.
To build a color out of the sequence, we usean LSTM (Hochreiter and Schmidhuber, 1997) with300 hidden units.
The final hidden state is used as a2http://sape.inf.usi.ch/quick-reference/ggplot2/colour3http://bit.ly/PaintColorNamesModel Test ggplot2 PaintUnigram 1018.35 814.58 351.54Bigram 977.46 723.61 364.41RNN 750.26 431.90 305.051-layer LSTM 664.11 355.56 303.032-layer LSTM 652.49 343.97 274.83Table 2: MSE in Lab space on held-out datasets.vector representation h ?
R300 of the sequence.
Theassociated color value in Lab space is then definedto be y?
= ?
(Wh + b), where W ?
R3?300 andb ?
R3 transform h.This model instantiates the one proposed by Linget al (2015) for learning word embeddings builtfrom representations of characters.To learn the parameters of the model (i.e., the pa-rameters of the LSTMs, the character embeddings,and W and b), we use reference color labels yfrom our training set and minimize squared error,||y ?
y?||2, averaged across the training set.
Learn-ing is accomplished using backpropagation and theAdam update rule (Kingma and Ba, 2014).4.1 EvaluationWe evaluated our model in two ways.
First, wecomputed mean-squared error on held-out data us-ing several variants of our model.
The baselinemodels are linear regression models, which predicta color from a bag of character unigrams and bi-grams.
We compare an RNN and LSTMs with oneand two layers.
Table 2 shows that the two-layerLSTM achieves lower error than the unigram andbigram baselines and an RNN.
We see the same pat-tern of results on the out-of-domain test sets.The Color Turing Test.
Our second evaluation at-tempts to assess whether our model?s associationsare human-like.
For this evaluation, we asked hu-man judges to choose the color better described bya name from one of our test sets: our model?s pre-dicted color or the color in the data.
For each dataset,we randomly selected 20 examples.
111 judgesconsidered each instance.4 Judges were presentedinstances in random order and forced to make achoice between the two and explicitly directed to4We excluded results from an additional 19 annotators whomade more than one mistake in a color blindness test (Oliver,1888).1950Preference Test ggplot2 PaintActual color 43.2% 32.6% 31.0%Predicted color 56.7% 67.3% 69.0%Table 3: Summary of color Turing test results.make an arbitrary choice if neither was better.5 Thetest is shown at http://colorlab.us/turk.Results are shown in Table 3; on the ggplot2 andPaint datasets, our prediction is preferred to the ac-tual names in a majority of cases.
The Test datasetfrom COLOURlovers is a little bit challenging, withmore noisy and creative names; still, in the majorityof cases, our prediction is preferred.4.2 Visualization and ExplorationTo better understand our model, we provide illustra-tions of its predictions on several kinds of inputs.Character by character prediction.
We considerhow our model reads color names character by char-acter.
Fig.
1 shows some examples, such as blue,variously modified.
The word deep starts darkbrown, but eventually modifies blue to a dark blue.Our model also performs sensibly on colors namedafter things (mint, cream, sand).Figure 1: Visualization of character-by-character prediction.Genre and color.
We can use our model to inves-tigate how colors are evoked in text by predicting thecolors of each word in a text.
Fig.
3 shows a coloredrecipe.
Noting that many words are rendered in neu-tral grays and tans, we investigated how our modelcolors words in three corpora: 3,300 English poems(1800?present), 256 recipes from the CURD dataset5A preliminary study that allowed a judge to say that therewas no difference led to a similar result.Figure 2: Distribution of Euclidean distances in Lab from esti-mated colors of words in each corpus to RGB (128, 128, 128).
(Tasse and Smith, 2008),6 and 6,000 beer reviews.7For each corpus, we examine the distribution of Eu-clidean distances of y?
from the Lab representation ofthe ?middle?
color RGB (128, 128, 128).
The Eu-clidean distances from the mean are measuring thevariance of the color of words in a document.
Fig.
2shows these distributions; recipes and beer reviewsare more ?colorful?
than poems, under our model?slearned definition of color.Figure 3: A recipe from greatist.com.5 Generating Names from ColorsThe first of our two color naming models generatescharacter sequences conditioned on Lab color rep-resentations, following other sequence-to-sequenceapproaches (Sutskever et al, 2014; Karpathy andFei-Fei, 2014).
The transformation is as follows:First, a linear transformation maps the color vectorinto 300 dimensions, together comprising the initial6http://www.cs.cmu.edu/?ark/CURD/7http://beeradvocate.com1951hidden and memory vectors.
Next a character LSTMis iteratively applied to the hidden, memory, andnext-character vectors, and the next character pro-duced by applying affine and then softmax functionsto the hidden vector.
The model is trained to maxi-mize conditional likelihood of each character givenits history.
We used 300 dimensions for characterembeddings and recurrence weights.
The output vo-cabulary size was 98 without lowercasing.We also propose a model to capture variations incolor description with latent variables by extendingthe variational autoencoder (Kingma and Welling,2013) to a conditional model.
We want to modelthe conditional probability of word y and latent vari-ables z given color x.
The latent variable gives themodel capacity to account for the complexity of thecolor?word mapping.
Since p(y, z | x) = p(z)p(y |x, z), the variational objective is:Eq?(z|x)[?
log q?
(z | x) + log p?
(y, z | x)]= Eq?(z|x)[?
log q?
(z | x) + log p?
(y | x, z)p(z)]' ?DKL(q?
(z | x) || p(z)) +1LL?l=1log p?
(y | x, zl)The first term regularizes the shape of posterior,q(z | x), to be close to prior p(z) where it is aGaussian distribution, p(z) = N (0, I).
The sec-ond term is the log likelihood of the character se-quence conditioned on color values.
To optimize ?and ?, we reparameterize the model, we write z interms of a mean and variance and samples from astandard normal distribution, i.e., z = ?
+ ? with ?
N (0, I).
We predict mean and log variance ofthe model with a multi-layer perceptron and initial-ize the decoder-LSTM with h0 = tanh(Wz + b).We trained the model with mini-batch size 128 andAdam optimizer.
The sample size L was set to 1.Evaluation.
We evaluated our models by estimat-ing perplexity on the Test set (Table 1).
Our base-line is a character-level unconditional LSTM lan-guage model.
Conditioning on color improved per-character perplexity by 7% and the latent variablegave a further 3%; see Table 4.A second dataset we evaluate on is the MunroeColor Corpus8 which contains 2,176,417 color de-scription for 829 words (i.e., single words have mul-tiple color descriptions).
Monroe et al (2016) have8https://blog.xkcd.com/2010/05/03/color-survey-results/Model PerplexityLSTM-LM 5.9VAE 5.9color-conditioned LSTM-LM 5.5color-conditioned VAE 5.3Table 4: Comparison of language models.developed word-based (rather character-based) re-current neural network model.Our character-based model with 1024 hiddenunits achieved 12.48 per-description perplexity,marginally better than 12.58 obtained with a word-based neural network model reported in that work.Thus, we see that modeling color names as se-quences of characters is wholly feasible.
However,since the corpus only contains color description for829 words, the model trained on the Munroe ColorCorpus does not provide suitable supervision forevaluation on our more lexically diverse dataset.6 Related Work and DiscussionColor is one of the lowest-level visual signals play-ing an important role in cognition (Wurm et al,1993) and behavior (Maier et al, 2008; Lichtenfeldet al, 2009).
It plays a role in human object recog-nition: to name an object, we first need to encodevisual information such as shape and surface infor-mation including color and texture.
Given a visualencoding, we search our memory for a structural, se-mantic and phonological description (Humphreys etal., 1999).
Adding color information to shape signif-icantly improves naming accuracy and speeds cor-rect response times (Rossion et al, 2004).Colors and their names have some association inour cognition.
The Stroop (1935) effect is a well-known example showing interference of colors andcolor terms: when we see a color term printed in adifferent color?blue?it takes us longer to name theword, and we are more prone to naming errors thanwhen the ink matches?blue (De Houwer, 2003).Recent evidence suggests that colors and wordsare associated in the brain.
The brain uses differentregions to perceive various modalities, but process-ing a color word activates the same brain region asthe color it denotes (del Prado Mart?
?n et al, 2006;Simmons et al, 2007).Closer to NLP, the relationship between visual1952stimuli and their linguistic descriptions by humanshas been explored extensively through automatictext generation from images (Kiros et al, 2014;Karpathy and Fei-Fei, 2014; Xu et al, 2015).
Colorassociation with word semantics has also been in-vestigated in several previous papers (Mohammad,2011; Heer and Stone, 2012; Andreas and Klein,2014; McMahan and Stone, 2015).7 ConclusionIn this paper, we introduced a computational modelto predict a point in color space from the sequenceof characters in the color?s name.
Using a large setof color?name pairs obtained from a color designforum, we evaluate our model on a ?color Turingtest?
and find that, given a name, the colors pre-dicted by our model are preferred by annotators tocolor names created by humans.
We also investi-gate the reverse mapping, from colors to names.
Wecompare a conditional LSTM language model to anew latent-variable model, achieving a 10% perplex-ity reduction.AcknowledgmentsWe thank Lucas Beyer for very helpful commentsand discussions, and we also appreciate all the par-ticipants of our color Turing test.ReferencesJacob Andreas and Dan Klein.
2014.
Grounding lan-guage with points and paths in continuous spaces.
InCoNLL, pages 58?67.Arthur D. Broadbent.
2004.
A critical review of the de-velopment of the CIE1931 RGB color-matching func-tions.
Color Research & Application, 29(4):267?272.Jan De Houwer.
2003.
On the role of stimulus-responseand stimulus-stimulus compatibility in the Stroop ef-fect.
Memory & Cognition, 31(3):353?359.Ferm?
?n Moscoso del Prado Mart?
?n, Olaf Hauk, andFriedemann Pulvermu?ller.
2006.
Category specificityin the processing of color-related and form-relatedwords: An erp study.
Neuroimage, 29(1):29?37.Xiaoyan Deng, Sam K. Hui, and J. Wesley Hutchin-son.
2010.
Consumer preferences for color com-binations: An empirical analysis of similarity-basedcolor relationships.
Journal of Consumer Psychology,20(4):476?484.Jeffrey Heer and Maureen Stone.
2012.
Color namingmodels for color selection, image editing and palettedesign.
In Proc.
CHI.Sepp Hochreiter and Ju?rgen Schmidhuber.
1997.
Longshort-term memory.
Neural computation, 9(8):1735?1780.Glyn W. Humphreys, Cathy J.
Price, and M. Jane Rid-doch.
1999.
From objects to names: A cognitive neu-roscience approach.
Psychological Research, 62(2-3):118?130.Richard S. Hunter.
1958.
Photoelectric color differencemeter.
Josa, 48(12):985?993.Andrej Karpathy and Li Fei-Fei.
2014.
Deep visual-semantic alignments for generating image descrip-tions.
arXiv preprint arXiv:1412.2306.Diederik Kingma and Jimmy Ba.
2014.
Adam: Amethod for stochastic optimization.
arXiv preprintarXiv:1412.6980.Diederik P. Kingma and Max Welling.
2013.Auto-encoding variational Bayes.
arXiv preprintarXiv:1312.6114.Ryan Kiros, Ruslan Salakhutdinov, and Rich Zemel.2014.
Multimodal neural language models.
In Pro-ceedings of the 31st International Conference on Ma-chine Learning (ICML-14), pages 595?603.Stephanie Lichtenfeld, Markus A. Maier, Andrew J. El-liot, and Reinhard Pekrun.
2009.
The semantic red ef-fect: Processing the word red undermines intellectualperformance.
Journal of Experimental Social Psychol-ogy, 45(6):1273?1276.Wang Ling, Isabel Trancoso, Chris Dyer, and Alan WBlack.
2015.
Character-based neural machine transla-tion.
CoRR, abs/1511.04586.Markus A. Maier, Andrew J. Elliot, and Stephanie Licht-enfeld.
2008.
Mediation of the negative effect of redon intellectual performance.
Personality and SocialPsychology Bulletin.Aaron Marcus.
1991.
Graphic design for electronic doc-uments and user interfaces.
ACM.Brian McMahan and Matthew Stone.
2015.
A Bayesianmodel of grounded color semantics.
Transactions ofthe Association for Computational Linguistics, 3:103?115.Saif Mohammad.
2011.
Colourful language: Measuringword-colour associations.
In Proceedings of the 2ndWorkshop on Cognitive Modeling and ComputationalLinguistics, pages 97?106.
Association for Computa-tional Linguistics.Will Monroe, Noah D. Goodman, and Christopher Potts.2016.
Learning to generate compositional color de-scriptions.
In Proc.
EMNLP.Charles A Oliver.
1888.
Tests for color-blindness.Transactions of the American Ophthalmological Soci-ety, 5:86.1953Bruno Rossion, Gilles Pourtois, et al 2004.
Revisitingsnodgrass and vanderwart?s object pictorial set: Therole of surface detail in basic-level object recognition.PERCEPTION-LONDON-, 33(2):217?236.W.
Kyle Simmons, Vimal Ramjee, Michael S.Beauchamp, Ken McRae, Alex Martin, andLawrence W. Barsalou.
2007.
A common neu-ral substrate for perceiving and knowing about color.Neuropsychologia, 45(12):2802?2810.J.
Ridley Stroop.
1935.
Studies of interference in serialverbal reactions.
Journal of experimental psychology,18(6):643.Ilya Sutskever, Oriol Vinyals, and Quoc VV Le.
2014.Sequence to sequence learning with neural networks.In Advances in neural information processing systems,pages 3104?3112.Dan Tasse and Noah A Smith.
2008.
Sour cream: To-ward semantic processing of recipes.
Technical report,Technical Report CMU-LTI-08-005, Carnegie MellonUniversity, Pittsburgh, PA.Tony Veale and Khalid Al-Najjar.
2015.
Unweaving thelexical rainbow: Grounding linguistic creativity in per-ceptual semantics.Lee H. Wurm, Gordon E. Legge, Lisa M. Isenberg, andAndrew Luebker.
1993.
Color improves object recog-nition in normal and low vision.
Journal of Exper-imental Psychology: Human perception and perfor-mance, 19(4):899.Kelvin Xu, Jimmy Ba, Ryan Kiros, Aaron Courville,Ruslan Salakhutdinov, Richard Zemel, and YoshuaBengio.
2015.
Show, attend and tell: Neural im-age caption generation with visual attention.
arXivpreprint arXiv:1502.03044.1954
