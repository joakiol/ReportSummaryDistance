Proceedings of the 7th Workshop on Statistical Machine Translation, pages 312?316,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsMachine Learning for Hybrid Machine TranslationSabine HunsickerDFKI GmbHLanguage Technology LabSaarbru?cken, Germanysabine.hunsicker@dfki.deChen YuDFKI GmbHLanguage Technology LabSaarbru?cken, Germanyyu.chen@dfki.deChristian FedermannDFKI GmbHLanguage Technology LabSaarbru?cken, Germanycfedermann@dfki.deAbstractWe describe a substitution-based system forhybrid machine translation (MT) that has beenextended with machine learning componentscontrolling its phrase selection.
The approachis based on a rule-based MT (RBMT) systemwhich creates template translations.
Basedon the rule-based generation parse tree andtarget-to-target algnments, we identify the setof ?interesting?
translation candidates fromone or more translation engines which couldbe substituted into our translation templates.The substitution process is either controlled bythe output from a binary classifier trained onfeature vectors from the different MT engines,or it is depending on weights for the decisionfactors, which have been tuned using MERT.We are able to observe improvements in termsof BLEU scores over a baseline version of thehybrid system.1 IntroductionIn recent years, machine translation (MT) systemshave achieved increasingly better translation quality.Still each paradigm has its own challenges: whilestatistical MT (SMT) systems suffer from a lack ofgrammatical structure, resulting in ungrammaticalsentences, RBMT systems have to deal with a lackof lexical coverage.
Hybrid architectures intend tocombine the advantages of the individual paradigmsto achieve an overall better translation.Federmann et al (2010) and Federmann and Hun-sicker (2011) have shown that using a substitution-based approach can improve the translation qualityof a baseline RBMT system.
Our submission toWMT12 is a new, improved version following theseapproaches.
The output of an RBMT engine servesas our translation backbone, and we substitute nounphrases by translations mined from other systems.2 System ArchitectureOur hybrid MT system combines translation outputfrom:a) the Lucy RBMT system, described in moredetail in (Alonso and Thurmair, 2003);b) the Linguatec RBMT system (Aleksic andThurmair, 2011);c) Moses (Koehn et al, 2007);d) Joshua (Li et al, 2009).Lucy provides us with the translation skeleton,which is described in more detail in Section 2.2while systems b)?d) are aligned to this translationtemplate and mined for substitution candidates.
Wegive more detailed information on these systems inSection 2.3.2.1 Basic ApproachWe first identify ?interesting?
phrases inside therule-based translation and then compute the mostprobable correspondences in the translation outputfrom the other systems.
For the resulting phrases,we apply a factored substitution method that decideswhether the original RBMT phrase should be kept orrather be replaced by one of the candidate phrases.A schematic overview of our hybrid system and itsmain components is given in Figure 1.312Figure 1: Schematic overview of the architecture of oursubstitution-based, hybrid MT system.In previous years, it turned out that the alignmentof the candidate translations to the source containedtoo many errors.
In this version of our system, wethus changed the alignment method that connects theother translations.
Only the rule-based template isaligned to the source.
As we make use of the LucyRBMT analysis parse trees, this alignment is verygood.
The other translations are now connected tothe rule-based template using a confusion networkapproach.
This also reduces computational efforts,as we now can compute the substitution candidatesdirectly from the template without detouring overthe source.
During system training and tuning, thisnew approach has resulted in a reduced number oferroneous alignment links.Additionally, we also changed our set of decisionfactors, increasing their total number.
Whereas anolder version of this system only used four factors,we now consider the following twelve factors:1. frequency: frequency of a given candidatephrase compared to total number of candidatesfor the current phrase;2.
LM(phrase): language model (LM) score ofthe phrase;3.
LM(phrase+1): phrase with right-context;4.
LM(phrase-1): phrase with left-context;5.
Part-of-speech match?
: checks if the part-of-speech tags of the left/right context match thecurrent candidate phrase?s context;6.
LM(pos) LM score for part-of-speech (PoS);7.
LM(pos+1) PoS with right-context;8.
LM(pos-1) PoS with left-context;9.
Lemma checks if the lemma of the candidatephrase fits the reference;10.
LM(lemma) LM score for the lemma;11.
LM(lemma+1) lemma with right-context;12.
LM(lemma-1) lemma with left-context.The language model was trained using the SRILMtoolkit (Stolcke, 2002), on the EuroParl (Koehn,2005) corpus, and lemmatised or part-of-speechtagged versions, respectively.
We used the Tree-Tagger (Schmid, 1994) for lemmatisation as well aspart-of-speech tagging.The substitution algorithm itself was also adapted.We investigated two machine learning approaches.In the previous version, the system used a hand-written decision tree to perform the substitution:1. the first of the two new approaches consistedof machine learning this decision tree fromannotated data;2. the second approach was to assign a weight toeach factor and using MERT tuning of theseweights on a development set.Both approaches are described in more detail later inSection 2.4.2.2 Rule-Based Translation TemplatesThe Lucy RBMT system provides us with parse treestructures for each of the three phases of its transfer-based translation approach: analysis, transfer andgeneration.
Out of these structures, we can extractlinguistic phrases which later represent the ?slots?for substitution.
Previous work has shown that thesestructures are of a good grammatical quality due tothe grammar Lucy uses.3132.3 Substitution Candidate TranslationsWhereas in our previous work, we solely relied oncandidates retrieved from SMT systems, this timewe also included an additional RBMT system intothe architecture.
Knowing that statistical systemsmake similar errors, we hope to balance out this factby exploiting also a system of a different paradigm,namely RBMT.To create the statistical translations, we used state-of-the-art SMT systems.
Both our Moses and Joshuasystems were trained on the EuroParl corpus andNews Commentary1 training data.
We performedtuning on the ?newstest2011?
data set using MERT.We compile alignments between translationswith the alignment module of MANY (Barrault,2010).
This module uses a modified version ofTERp (Snover et al, 2009) and a set of differentcosts to create the best alignment between any twogiven sentences.
In our case, each single candidatetranslation is aligned to the translation template thathas been produced by the Lucy RBMT system.
Aswe do not use the source in this alignment tech-nique, we can use any translation system, regardlessof whether this system provides us with a source-to-target algnment.In earlier versions of this system, we compiled thesource-to-target algnments for the candidate trans-lations using GIZA++ (Och and Ney, 2003), butthese alignments contained many errors.
By usingtarget-to-target algnments, we are able to reduce theamount of those errors which is, of course, preferred.2.4 Substitution ApproachesUsing the parse tree structures provided by Lucy, weextract ?interesting?
phrases for substitution.
Thisincludes noun phrases of various complexity, thensimple verb phrases consisting of only the mainverb, and finally adjective phrases.
Through thetarget-to-target algnments we identify and collectthe set of potential substitution candidates.
Phrasesubstitution can be performed using two methods.2.4.1 Machine-Learned Decision TreePrevious work used hand-crafted rules.
These arenow replaced by a classifier which was trained onannotated data.
Our training set D can formally be1Available at http://www.statmt.org/wmt12/represented asD = {(xi, yi)|xi ?
Rp, yi ?
{?1, 1}}ni=1 (1)where each xi represents the feature vector for somesentence i while the yi value contains the annotatedclass information.
We use a binary classificationscheme, simply defining 1 as ?good?
and ?1 as?bad?
translations.In order to make use of machine (ML) learn-ing methods such as decision trees (Breiman et al,1984), Support Vector Machines (Vapnik, 1995),or the Perceptron (Rosenblatt, 1958) algorithm, wehave to prepare our training set with a sufficientlylarge amount of annotated training instances.To create the training data set, we computed thefeature vectors and all possible substitution candi-dates for the WMT12 ?newstest2011?
developmentset.
Human annotators were then given the task toassign to each candidate whether it was a ?good?
ora ?bad?
substitution.
We used Appraise (Federmann,2010) for the annotation, and collected a set of24,996 labeled training instances with the help of sixhuman annotators.
Table 1 gives an overview of thedata sets characteristics.
The decision tree learnedfrom this data replaces the hand-crafted rules.2.4.2 Weights Tuned with MERTAnother approach we followed was to assignweights to the chosen decision factors and to useMinimal Error Rate Training to get the best weights.Using the twelve factors described in Section 2.1,we assign uniformly distributed weights and createn-best lists.
Each n-best lists contains a total ofn+2 hypotheses, with n being the number of candi-date systems.
It contains the Lucy template trans-lations, the hybrid translation using the best can-didates as well as a hypothesis for each candidatesystem.
In the latter translation, each potential can-didate for substitution is selected and replaces theoriginal sub phrase in the baseline.
The n-best list isTranslation CandidatesTotal ?good?
?bad?Count 24,996 10,666 14,330Table 1: Training data set characteristics314Hybrid Systems Baseline SystemsBaseline +Decision Tree +MERT Lucy Linguatec Joshua MosesBLEU 13.9 14.2 14.3 14.0 14.7 14.6 15.9BLEU-cased 13.5 13.8 13.9 13.7 14.2 13.5 14.9TER 0.776 0.773 0.768 0.774 0.775 0.772 0.774Table 2: Experimental results for all component and hybrid systems applied to the WMT12 ?newstest2012?
test setdata for language pair English?German.sorted by the final score of the feature vectors mak-ing up each hypothesis.
We used Z-MERT (Zaidan,2009) to optimise the set of feature weights on the?newstest2011?
development set.3 EvaluationUsing the ?newstest2012?
test set, we created base-line translations for the four MT systems used in ourhybrid system.
Then we performed three runs of ourhybrid system:a) a baseline run, using the factors and uniformlydistributed weights;b) a run using the weights trained on the develop-ment set;c) a run using the decision tree learned from an-notated data.Table 2 shows the results for automatic metrics?scores.
Besides BLEU (Papineni et al, 2001), wealso report its case-sensitive variant, BLEU-cased,and TER (Snover et al, 2006) scores.Comparing the scores, we see that both advancedhybrid methods perform better than the original,baseline hybrid as well as the Lucy baseline system.The MERT approach performs slightly better thanthe decision tree.
This proves that using machine-learning to adapt the substitution approach results inbetter translation quality.Other baseline systems, however, still outperformthe hybrid systems.
In part this is due to the fact thatwe are preserving the basic structure of the RBMTtranslation and do not reorder the new hybrid trans-lation.
To improve the hybrid approach further, thereis more research required.4 Conclusion and OutlookIn this paper, we have described how machine-learning approaches can be used to improve thephrase substitution component of a hybrid machinetranslation system.We reported on two different approaches, the firstusing a binary classifier learned from annotated data,and the second using feature weights tuned withMERT.
Both systems achieved improved automaticmetrics?
scores on the WMT12 ?newstest2012?
testset for the language pair English?German.Future work will have to investigate ways how toachieve a closer integration of the individual base-line translations.
This might be done by also takinginto account reordering of the linguistic phrases asshown in the tree structures.
We will also need toexamine the differences between the classifier andMERT approach, to see whether we can integratethem to improve the selection process even further.Also, we have to further evaluate the machinelearning performance via, e.g., cross-validation-based tuning, to improve the prediction rate of theclassifier model.
We intend to explore other machinelearning techniques such as SVMs as well.AcknowledgmentsThis work has been funded under the SeventhFramework Programme for Research and Techno-logical Development of the European Commissionthrough the T4ME contract (grant agreement no.:249119).
It was also supported by the EuroMatrix-Plus project (IST-231720).
We are grateful to theanonymous reviewers for their valuable feedback.Special thanks go to Herve?
Saint-Amand for helpwith fixing the automated metrics scores.315ReferencesVera Aleksic and Gregor Thurmair.
2011.
PersonalTranslator at WMT 2011.
In Proceedings of the SixthWorkshop on Statistical Machine Translation, pages303?308, Edinburgh, Scotland, July.
Association forComputational Linguistics.Juan A. Alonso and Gregor Thurmair.
2003.
The Com-prendium Translator System.
In Proceedings of theNinth Machine Translation Summit.Lo?
?c Barrault.
2010.
MANY : Open Source MachineTranslation System Combination.
Prague Bulletinof Mathematical Linguistics, Special Issue on OpenSource Tools for Machine Translation, 93:147?155,January.L.
Breiman, J. Friedman, R. Olshen, and C. Stone.
1984.Classification and Regression Trees.
Wadsworth andBrooks, Monterey, CA.Christian Federmann and Sabine Hunsicker.
2011.Stochastic parse tree selection for an existing rbmt sys-tem.
In Proceedings of the Sixth Workshop on Sta-tistical Machine Translation, pages 351?357, Edin-burgh, Scotland, July.
Association for ComputationalLinguistics.Christian Federmann, Andreas Eisele, Yu Chen, SabineHunsicker, Jia Xu, and Hans Uszkoreit.
2010.
Fur-ther experiments with shallow hybrid mt systems.
InProceedings of the Joint Fifth Workshop on StatisticalMachine Translation and MetricsMATR, pages 77?81,Uppsala, Sweden, July.
Association for ComputationalLinguistics.Christian Federmann.
2010.
Appraise: An Open-SourceToolkit for Manual Phrase-Based Evaluation of Trans-lations.
In Nicoletta Calzolari (Conference Chair),Khalid Choukri, Bente Maegaard, Joseph Mariani,Jan Odijk, Stelios Piperidis, Mike Rosner, and DanielTapias, editors, Proceedings of the Seventh Interna-tional Conference on Language Resources and Evalu-ation (LREC?10), Valletta, Malta, May.
European Lan-guage Resources Association (ELRA).Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
In Pro-ceedings of ACL Demo and Poster Sessions, pages177?180.
Association for Computational Linguistics,June.Philipp Koehn.
2005.
Europarl: A Parallel Corpus forStatistical Machine Translation.
In Proceedings of theMT Summit 2005.Zhifei Li, Chris Callison-Burch, Chris Dyer, SanjeevKhudanpur, Lane Schwartz, Wren Thornton, JonathanWeese, and Omar Zaidan.
2009.
Joshua: An OpenSource Toolkit for Parsing-Based Machine Transla-tion.
In Proceedings of the Fourth Workshop on Sta-tistical Machine Translation, pages 135?139, Athens,Greece, March.
Association for Computational Lin-guistics.Evgeny Matusov, Nicola Ueffing, and Hermann Ney.2006.
Computing Consensus Translation from Multi-ple Machine Translation Systems Using Enhanced Hy-potheses Alignment.
In Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 33?40, Stroudsburg, PA, USA, April.
Asso-ciation for Computational Linguistics.Franz Josef Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, 29(1):19?51, March.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a Method for Automatic Eval-uation of Machine Translation.
IBM Research ReportRC22176(W0109-022), IBM.F.
Rosenblatt.
1958.
The Perceptron: A ProbabilisticModel for Information Storage and Organization in theBrain.
Psychological Review, 65:386?408.Helmut Schmid.
1994.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees.
In Proceedings of the In-ternational Conference on New Methods in LanguageProcessing, Manchester, UK.Toby Segaran.
2007.
Programming Collective In-telligence: Building Smart Web 2.0 Applications.O?Reilly, Beijing.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A Study ofTranslation Edit Rate with Targeted Human Annota-tion.
In Proceedings of the Conference of the Associ-ation for Machine Translation in the Americas, pages223?231.Matthew Snover, Nitin Madnani, Bonnie Dorr, andRichard Schwartz.
2009.
Fluency, Adequacy, orHTER?
Exploring Different Human Judgments witha Tunable MT Metric.
In Proceedings of the FourthWorkshop on Statistical Machine Translation at the12th Meeting of the European Chapter of the Asso-ciation for Computational Linguistics (EACL-2009),Athens, Greece, March.Andreas Stolcke.
2002.
SRILM - An Extensible Lan-guage Modeling Toolkit.
In Proceedings of the Inter-national Conference on Spoken Language Processing,pages 257?286, November.V.
N. Vapnik.
1995.
The Nature of Statistical LearningTheory.
Springer, New York.Omar F. Zaidan.
2009.
Z-MERT: A fully configurableopen source tool for minimum error rate training ofmachine translation systems.
The Prague Bulletin ofMathematical Linguistics, 91:79?88, January.316
