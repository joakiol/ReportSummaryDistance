Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 77?86,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsAutomatically Producing Plot Unit Representations for Narrative TextAmit GoyalDept.
of Computer ScienceUniversity of MarylandCollege Park, MD 20742amit@umiacs.umd.eduEllen RiloffSchool of ComputingUniversity of UtahSalt Lake City, UT 84112riloff@cs.utah.eduHal Daume?
IIIDept.
of Computer ScienceUniversity of MarylandCollege Park, MD 20742hal@umiacs.umd.eduAbstractIn the 1980s, plot units were proposed as aconceptual knowledge structure for represent-ing and summarizing narrative stories.
Ourresearch explores whether current NLP tech-nology can be used to automatically produceplot unit representations for narrative text.
Wecreate a system called AESOP that exploitsa variety of existing resources to identify af-fect states and applies ?projection rules?
tomap the affect states onto the characters in astory.
We also use corpus-based techniquesto generate a new type of affect knowledgebase: verbs that impart positive or negativestates onto their patients (e.g., being eaten isan undesirable state, but being fed is a desir-able state).
We harvest these ?patient polar-ity verbs?
from a Web corpus using two tech-niques: co-occurrence with Evil/Kind Agentpatterns, and bootstrapping over conjunctionsof verbs.
We evaluate the plot unit representa-tions produced by our system on a small col-lection of Aesop?s fables.1 IntroductionIn the 1980s, plot units (Lehnert, 1981) were pro-posed as a knowledge structure for representing nar-rative stories and generating summaries.
Plot unitsare fundamentally different from the story represen-tations that preceded them because they focus on theaffect states of characters and the tensions betweenthem as the driving force behind interesting and co-hesive stories.
Plot units were used in narrative sum-marization studies, both in computer science andpsychology (Lehnert et al, 1981), but previous com-putational models of plot units relied on tremendousamounts of manual knowledge engineering.The last few decades have seen tremendous ad-vances in NLP and the emergence of many resourcesthat could be useful for plot unit analysis.
So we em-barked on a project to see whether plot unit repre-sentations can be generated automatically using cur-rent NLP technology.
We created a system calledAESOP that uses a variety of resources to iden-tify words that correspond to positive, negative, andmental affect states.
AESOP uses affect projectionrules to map the affect states onto the characters inthe story based on verb argument structure.
Addi-tionally, affect states are inferred based on syntacticproperties, and causal and cross-character links arecreated using simple heuristics.Affect states often arise from actions that producegood or bad states for the character that is actedupon.
For example, ?the cat ate the mouse?
pro-duces a negative state for the mouse because beingeaten is bad.
Similarly, ?the man fed the dog?
pro-duces a positive state for the dog because being fedis generally good.
Knowledge about the effects ofactions (i.e., state changes) on patients is not readilyavailable in existing semantic resources.
We createa new type of lexicon consisting of patient polarityverbs (PPVs) that impart positive or negative stateson their patients.
These verbs reflect world knowl-edge about desirable/undesirable states for animatebeings; for example, being fed, paid or adopted aregenerally desirable states, while being eaten, chasedor hospitalized are generally undesirable states.We automatically generate a lexicon of ?patientpolarity verbs?
from a Web corpus using two tech-77The Father and His Sons(s1) A father had a family of sons who were perpetuallyquarreling among themselves.
(s2) When he failed toheal their disputes by his exhortations, he determinedto give them a practical illustration of the evils of dis-union; and for this purpose he one day told them tobring him a bundle of sticks.
(s3) When they had doneso, he placed the faggot into the hands of each of themin succession, and ordered them to break it in pieces.
(s4) They tried with all their strength, and were notable to do it.
(s5) He next opened the faggot, took thesticks separately, one by one, and again put them intohis sons?
hands, upon which they broke them easily.
(s6) He then addressed them in these words: ?My sons,if you are of one mind, and unite to assist each other,you will be as this faggot, uninjured by all the attemptsof your enemies; but if you are divided among your-selves, you will be broken as easily as these sticks.?
(a) ?Father and Sons?
FableFather Sons(quarreling)a1(stop quarreling)a3(annoyed)a2(exhortations)a4(exhortations fail)a5mma(teach lesson)a6m(get sticks & break)a7m (get sticks & break)a8(cannot break sticks)a9a(cannot break sticks)a10a(bundle & break)a11 (bundle & break)a12(break sticks)a13a(break sticks)a14amasharedrequestrequestmixedshareds2s2s2s2s2s2s4s5s5s1s2s4s5s5(lesson succeeds)a15s5(b) Plot Unit Analysis for ?Father and Sons?
FableFigure 1: Sample Fable and Plot Unit Representationniques: patterns that identify co-occurrence withstereotypically evil or kind agents, and a bootstrap-ping algorithm that learns from conjunctions ofverbs.
We evaluate the plot unit representations pro-duced by our system on a small collection of fables.2 Overview of Plot UnitsPlot unit structures consist of affect states for eachcharacter, and links defining the relationships be-tween them.
Plot units include three types of affectstates: positive (+), negative (-), and mental (M).Affect states can be connected by causal links andcross-character links, which explain how the nar-rative hangs together.
Causal links exist betweenaffect states for the same character and have fourtypes: motivation (m), actualization (a), termination(t) and equivalence (e).
Cross-character links indi-cate that a single event affects multiple characters.For instance, if one character requests something ofanother, then each character is assigned an M stateand a cross-character link connects the states.To see a concrete example of a plot unit represen-tation, a short fable, ?The Father and His Sons,?
isshown in Figure 1(a) and our annotation of its plotunit structure is shown in Figure 1(b).
In this fable,there are two characters, the ?Father?
and (collec-tively) the ?Sons?, who go through a series of affectstates depicted chronologically in the two columns.The first affect state (a1) is produced from sen-tence #1 (s1) and is a negative state for the sons be-cause they are quarreling.
This state is shared by thefather (via a cross-character link) who has a nega-tive annoyance state (a2).
The father decides thathe wants to stop the sons from quarreling, whichis a mental event (a3).
The causal link from a2 toa3 with an m label indicates that his annoyed state?motivated?
this decision.
His first attempt is by ex-hortations (a4).
The first M (a3) is connected to thesecond M (a4) with an m (motivation) link, whichrepresents subgoaling.
The father?s overall goal isto stop the quarreling (a3), and to do so he creates asubgoal of exhorting the sons to stop (a4).
The ex-hortations fail, which produces a negative state (a5)for the father.
The a causal link indicates an ?actu-alization?, representing the failure of his plan (a4).This failure motivates a new subgoal: teach thesons a lesson (a6).
At a high level, this subgoalhas two parts, indicated by the two gray regions(a7 ?
a10 and a11 ?
a14).
The first gray regionbegins with a cross-character link (M to M), whichindicates a request (in this case, to break a bundleof sticks).
The sons fail at this, which upsets them(a9) but pleases the father (a10).
The second grayregion depicts the second part of the father?s sub-goal; he makes a second request (a11 to a12) to sep-arate the bundle and break the sticks, which the sonssuccessfully do, making them happy (a13) and thefather happy (a14) as well.
This latter structure (thesecond gray region) is an HONORED REQUEST plotunit structure.
At the end, the father?s plan succeeds(a15) which is an actualization (a link) of his goalto teach the sons a lesson (a6).783 Where Do Affect States Come From?We briefly overview the variety of situations that canbe represented by affect states in plot units.Direct Expressions of Emotion: Affect states cancorrespond to positive/negative emotional states, ashave been studied in the realm of sentiment anal-ysis.
For example, ?Max was disappointed?
pro-duces a negative affect state for Max, and ?Max waspleased?
produces a positive affect state for Max.Situational Affect States: Positive and negative af-fect states can represent good and bad situationalstates that characters find themselves in.
Thesestates do not represent emotion, but indicate whethera situation (state) is good or bad for a characterbased on world knowledge.
e.g., ?The wolf had abone stuck in his throat.?
produces a negative affectstate for the wolf.
Similarly, ?The woman recoveredher sight.?
produces a positive affect state for thewoman.Plans and Goals: The existence of a plan or goal isrepresented as a mental state (M).
Plans and goalscan be difficult to detect automatically and can berevealed in many ways, such as:?
Direct expressions of plans/goals: a plan/goalmay be explicitly stated (e.g., ?John wants food?).?
Speech acts: a plan or goal may be revealedthrough a speech act.
For example, ?the wolf askedan eagle to extract the bone?
is a directive speechact that indicates the wolf?s plan to resolve itsnegative state (having a bone stuck).
This exampleillustrates how a negative state (bone stuck) canmotivate a mental state (plan).
When a speech actinvolves multiple characters, it produces multiplemental states.?
Inferred plans/goals: plans and goals are some-times inferred from actions.
e.g., ?the lion hunteddeer?
implies that the lion has a plan to obtain food.Similarly, ?the serpent spat poison at John?
impliesthat the serpent wants to kill John.?
Plan/Goal completion: Plans and goals produce+/- affect states when they succeed or fail.
Forexample, if the eagle successfully extracts the bonefrom the wolf?s throat, then both the wolf and theeagle will have positive affect states because bothwere successful in their respective goals.We observed that situational and plan/goal statesoften originate from an action.
When a character isacted upon (the patient of a verb), then the charac-ter may be in a positive or negative state depend-ing upon whether the action was good or bad forthem based on world knowledge.
For example, be-ing fed, paid or adopted is generally desirable, butbeing chased, eaten, or hospitalized is usually unde-sirable.
Consequently, we decided to create a lex-icon of patient polarity verbs that produce positiveor negative states for their patients.
In Section 4.2,we present two methods for automatically harvest-ing these verbs from a Web corpus.4 AESOP: Automatically Generating PlotUnit RepresentationsOur system, AESOP, automatically creates plot unitrepresentations for narrative text.
AESOP has fourmain steps: affect state recognition, character iden-tification, affect state projection, and link creation.During affect state recognition, AESOP identifieswords that may be associated with positive, nega-tive, and mental states.
AESOP then identifies themain characters in the story and applies affect pro-jection rules to map the affect states onto these char-acters.
During this process, some additional affectstates are inferred based on verb argument structure.Finally, AESOP creates cross-character links andcausal links between affect states.
We also presenttwo corpus-based methods to automatically producea new resource for affect state recognition: a patientpolarity verb lexicon.4.1 Plot Unit Creation4.1.1 Recognizing Affect StatesThe basic building blocks of plot units are af-fect states which come in three flavors: positive,negative, and mental.
In recent years, many pub-licly available resources have been created for sen-timent analysis and other types of semantic knowl-edge.
We considered a wide variety of resources andultimately decided to experiment with five resourcesthat most closely matched our needs:?
FrameNet (Baker et al, 1998): We manuallyidentified 87 frame classes that seem to be associ-ated with affect: 43 mental classes (e.g., COMMU-NICATION and NEEDING), 22 positive classes (e.g.,ACCOMPLISHMENT and SUPPORTING), and 22 neg-ative classes (e.g., CAUSE HARM and PROHIBIT-79ING).
We use the verbs listed for these classes toproduce M, +, and - affect states.
?MPQA Lexicon (Wilson et al, 2005b): We usedthe words listed as having positive or negative senti-ment polarity to produce +/- states, when they occurwith the designated part-of-speech.?
OpinionFinder (Wilson et al, 2005a) (Version1.4) : We used the +/- labels assigned by its con-textual polarity classifier (Wilson et al, 2005b) tocreate +/- states and the MPQASD tags producedby its Direct Subjective and Speech Event Identifier(Choi et al, 2006) to produce mental (M) states.?
Semantic Orientation Lexicon (Takamura et al,2005): We used the words listed as having posi-tive or negative polarity to produce +/- affect states,when they occur with the designated part-of-speech.?
Speech Act Verbs: We used 228 speech actverbs from (Wierzbicka, 1987) to produce M states.4.1.2 Identifying the CharactersFor the purposes of this work, we made two sim-plifying assumptions: (1) There are only two char-acters per fable1, and (2) Both characters are men-tioned in the fable?s title.
The problem of corefer-ence resolution for fables is somewhat different thanfor other genres, primarily because the charactersare often animals (e.g., he=owl).
So we hand-crafteda simple rule-based coreference system.
First, weapply heuristics to determine number and genderbased on word lists, WordNet (Miller, 1990) andpart-of-speech tags.
If no determination of a char-acter?s gender or number can be made, we employ aprocess of elimination.
Given the two character as-sumption, if one character is known to be male, butthere are female pronouns in the fable, then the othercharacter is assumed to be female.
The same is donefor number agreement.
Finally, if there is only onecharacter between a pronoun and the beginning ofa document, then we resolve the pronoun with thatcharacter and the character assumes the gender andnumber of the pronoun.
Lastly, WordNet providessome additional resolutions by exploiting hypernymrelations, for instance, linking peasant with man.4.1.3 Mapping Affect States onto CharactersPlot unit representations are not just a set of af-fect states, but they are structures that capture the1We only selected fables that had two main characters.chronological ordering of states for each characteras the narrative progresses.
Consequently, every af-fect state needs to be attributed to a character.
Sincemost plots revolve around events, we use verb argu-ment structure as the primary means for projectingaffect states onto characters.We developed four affect projection rules that or-chestrate how affect states are assigned to the char-acters.
We used the Sundance parser (Riloff andPhillips, 2004) to produce a shallow parse of eachsentence, which includes syntactic chunking, clausesegmentation, and active/passive voice recognition.We normalized the verb phrases with respect to ac-tive/passive voice to simplify the rules.
We made theassumption that the Subject of the VP is its AGENTand the Direct Object of the VP is its PATIENT.2The rules only project affect states onto AGENTSand PATIENTS that refer to a character in the story.The four projection rules are presented below.1.
AGENT VP : This rule applies when the VPhas no PATIENT or the PATIENT corefers with theAGENT.
All affect tags assigned to the VP are pro-jected onto the AGENT.
Example: ?Mary laughed(+)?
projects a + affect state onto Mary.2.
VP PATIENT : This rule applies when the VPhas no agent, which is common in passive voice con-structions.
All affect tags assigned to the VP areprojected onto the PATIENT.
Example: ?John wasrewarded (+), projects a + affect state onto John.3.
AGENT VP PATIENT : This rules applieswhen both an AGENT and PATIENT are present, donot corefer, and at least one of them is a character.
Ifthe PATIENT is a character, then all affect tags asso-ciated with the VP are projected onto the PATIENT.If the AGENT is a character and the VP has an Mtag, then we also project an M tag onto the AGENT(representing a shared, cross-character mental state).4.
AGENT VERB1 to VERB2 PATIENT : Thisrule has two cases: (a) If the AGENT and PATIENTrefer to the same character, then we apply Rule #1.Example: ?Bo decided to teach himself...?
(b) If theAGENT and PATIENT are different, then we applyRule #1 to VERB1 and Rule #2 to VERB2.Finally, if an adverb or adjectival phrase has af-fect, then that affect is mapped onto the precedingVP and the rules above are applied.
For all of the2This is not always correct, but worked ok in our fables.80rules, if a clause contains a negation word, then weflip the polarity of all words in that clause.4.1.4 Inferring Affect StatesRecognizing plans and goals depends on worldknowledge and inference, and is beyond the scopeof this paper.
However, we identified two caseswhere affect states often can be inferred based onsyntactic properties.
The first case involves verbphrases (VPs) that have both an AGENT and PA-TIENT, which corresponds to projection rule #3.
Ifthe VP has polarity, then rule #3 assigns that po-larity to the PATIENT, not the AGENT.
For exam-ple, ?John killed Paul?
imparts negative polarity onPaul, but not necessarily on John.
Unless we aretold otherwise, one assumes that John intentionallykilled Paul, and so in a sense, John accomplishedhis goal.
Consequently, this action should produce apositive affect state for John.
We capture this notionof accomplishment as a side effect of projection rule#3: if the VP has +/- polarity, then we produce aninferred positive state for the AGENT.The second case involves infinitive verb phrasesof the form: ?AGENT VERB1 TO VERB2 PA-TIENT?
(e.g., ?Susan tried to warn Mary?).
Theinfinitive VP construction suggests that the AGENThas a goal or plan that is being put into motion (e.g.,tried to, wanted to, attempted to, hoped to, etc.).
Tocapture this intuition, in rule #4 if VERB1 does notalready have an affect state assigned to it then weproduce an inferred mental state for the AGENT.4.1.5 Causal and Cross-Character LinksOur research is focused primarily on creating af-fect states for characters, but plot unit structuresalso include cross-character links to connect statesthat are shared across characters and causal linksbetween states for a single character.
As an ini-tial attempt to create complete plot units, AESOPproduces links using simple heuristics.
A cross-character link is created when two characters in aclause have affect states that originated from thesame word.
A causal link is created between eachpair of (chronologically) consecutive affect statesfor the same character.
Currently, AESOP only pro-duces forward causal links (motivation (m), actual-ization (a)) and does not produce backward causallinks (equivalence (e), termination (t)).
For forwardlinks, the causal syntax only allows for five cases:M m?
M , + m?
M , ?
m?
M , M a?
+, M a?
?.So when AESOP produces a causal link betweentwo affect states, the order and types of the two statesuniquely determine which label it gets (m or a).4.2 Generating PPV LexiconsDuring the course of this research, we identified agap in currently available knowledge: we are notaware of existing resources that identify verbs whichproduce a desirable/undesirable state for their pa-tients even though the verb itself does not carry po-larity.
For example, the verb eat describes an actionthat is generally neutral, but being eaten is clearlyan undesirable state.
Similarly, the verb fed does nothave polarity, but being fed is a desirable state for thepatient.
In the following sections, we try to fill thisgap by using corpus-based techniques to automati-cally acquire a Patient Polarity Verb (PPV) Lexicon.4.2.1 PPV Harvesting with Evil/Kind AgentsThe key idea behind our first approach is to iden-tify verbs that frequently occur with evil or kindagents.
Our intuition was that an ?evil?
agent willtypically perform actions that are bad for the patient,while a ?kind?
agent will typically perform actionsthat are good for the patient.We manually identified 40 stereotypically evilagent words, such as monster, villain, terrorist, andmurderer, and 40 stereotypically kind agent words,such as hero, angel, benefactor, and rescuer.
Wesearched the Google Web 1T N-gram corpus toidentify verbs that co-occur with these words asprobable agents.
For each agent term, we appliedthe pattern ?
* by [a,an,the] AGENT?
and extractedthe matching N-grams.
Then we applied a part-of-speech tagger to each N-gram and saved the wordsthat were tagged as verbs (i.e., the words in the *position).3 This process produced 811 negative (evilagent) PPVs and 1362 positive (kind agent) PPVs.4.2.2 PPV Bootstrapping over ConjunctionsOur second approach for acquiring PPVs is basedon an observation from sentiment analysis researchthat conjoined adjectives typically have the same po-larity (e.g.
(Hatzivassiloglou and McKeown, 1997)).3The POS tagging quality is undoubtedly lower than if tag-ging complete sentences but it seemed reasonable.81Our hypothesis was that conjoined verbs often sharethe same polarity as well (e.g., ?abducted andkilled?
or ?rescued and rehabilitated?).
We exploitthis idea inside a bootstrapping algorithm to itera-tively learn verbs that co-occur in conjunctions.Bootstrapping begins with 10 negative and 10positive PPV seeds.
First, we extracted triples ofthe form ?w1 and w2?
from the Google Web 1TN -gram corpus that had frequency ?
100 and werelower case.
We separated each conjunction intotwo parts: a primary VERB (?w1?)
and a CONTEXT(?and w2?
), and created a copy of the conjunctionwith the roles of w1 and w2 reversed.
For example,?rescued and adopted?
produces:VERB=?rescued?
CONTEXT=?and adopted?VERB=?adopted?
CONTEXT=?and rescued?Next, we applied the Basilisk bootstrapping al-gorithm (Thelen and Riloff, 2002) to learn PPVs.Basilisk identifies semantically similar words basedon their co-occurrence with seeds in contextual pat-terns.
Basilisk was originally designed for semanticclass induction using lexico-syntactic patterns, buthas also been used to learn subjective and objectivenouns (Riloff et al, 2003).Basilisk first identifies the pattern contexts thatare most strongly associated with the seed words.Words that occur in those contexts are labeled ascandidates and scored based on the strength of theircontexts.
The top 5 candidates are selected and thebootstrapping process repeats.
Basilisk produces alexicon of learned words as well as a ranked list ofpattern contexts.
Since we bootstrapped over verbconjunctions, we also extracted new PPVs from thecontexts.
We ran the bootstrapping process to createa lexicon of 500 words, and we collected verbs fromthe top 500 contexts as well.5 EvaluationPlot unit analysis of narrative text is enormouslycomplex ?
the idea of creating gold standard plotunit annotations seemed like a monumental task.So we began with relatively simple and constrainedtexts that seemed appropriate: fables.
Fables havetwo desirable attributes: (1) they have a small castof characters, and (2) they typically revolve arounda moral, which is exemplified by a short and conciseplot.
Even so, fables are challenging for NLP due toanthropomorphic characters, flowery language, andsometimes archaic vocabulary.We collected 34 Aesop?s fables from a web site4,choosing fables that have a true plot (some only con-tain quotes) and exactly two characters.
We dividedthem into a development set of 11 stories, a tuningset of 8 stories, and a test set of 15 stories.Creating a gold standard was itself a substantialundertaking, and training non-experts to producethem did not seem feasible in the short term.
Sothe authors discussed and iteratively refined manualannotations for the development and tuning sets un-til we produced similar results and had a commonunderstanding of the task.
Then two authors inde-pendently created annotations for the test set, and athird author adjudicated the differences.5.1 Evaluation ProcedureFor evaluation, we used recall (R), precision (P),and F-measure (F).
In our gold standard, each af-fect state is annotated with the set of clauses thatcould legitimately produce it.
In most cases (75%),we were able to ascribe the existence of a state toprecisely one clause.
During evaluation, the system-produced affect states must be generated from thecorrect clause.
However, for affect states that couldbe ascribed to multiple clauses in a sentence, theevaluation was done at the sentence level.
In thiscase, the system-produced affect state must comefrom the sentence that contains one of those clauses.Coreference resolution is far from perfect, so wecreated gold standard coreference annotations forour fables and used them for most of our experi-ments.
This allowed us to evaluate our approachwithout coreference mistakes factoring in.
In Sec-tion 5.5, we re-evaluate our final results using auto-matic coreference resolution.5.2 Evaluation of Affect States using ExternalResourcesOur first set of experiments evaluates the quality ofthe affect states produced by AESOP using only theexternal resources.
The top half of Table 1 shows theresults for each resource independently.
FrameNetproduced the best results, yielding much higher re-call than any other resource.
The bottom half of Ta-4www.pacificnet.net/?johnr/aesop/82Affect State M (59) + (47) - (37) All (143)Resource(s) R P F R P F R P F R P FFrameNet .49 .51 .50 .17 .57 .26 .14 .42 .21 .29 .51 .37MPQA Lexicon .07 .50 .12 .21 .24 .22 .22 .38 .28 .15 .31 .20OpinionFinder .42 .40 .41 .00 .00 .00 .03 .17 .05 .18 .35 .24Semantic Orientation Lexicon .07 .44 .12 .17 .40 .24 .08 .38 .13 .10 .41 .16Speech Act Verbs .36 .53 .43 .00 .00 .00 .00 .00 .00 .15 .53 .23FrameNet+MPQA Lexicon .44 .52 .48 .30 .28 .29 .27 .38 .32 .35 .40 .37FrameNet+OpinionFinder .53 .39 .45 .17 .38 .23 .16 .33 .22 .31 .38 .34FrameNet+Semantic Orientation Lexicon .49 .51 .50 .26 .36 .30 .22 .42 .29 .34 .45 .39FrameNet+Speech Act Verbs .51 .48 .49 .17 .57 .26 .14 .42 .21 .30 .49 .37Table 1: Evaluation results for AESOP using external resources.
The # in parentheses is the # of gold affect states.Affect State M (59) + (47) - (37) All (143)Resource(s) R P F R P F R P F R P F- Evil Agent PPVs .07 .50 .12 .21 .40 .28 .46 .46 .46 .22 .44 .29- Neg Basilisk PPVs .07 .44 .12 .11 .45 .18 .24 .45 .31 .13 .45 .20- Evil Agent and Neg Basilisk PPVs .05 .43 .09 .21 .38 .27 .46 .40 .43 .21 .39 .27+ Kind Agent PPVs (?>1) .03 .33 .06 .28 .17 .21 .00 .00 .00 .10 .19 .13+ Pos Basilisk PPVs .08 .56 .14 .02 .12 .03 .03 1.00 .06 .05 .39 .09FrameNet+SOLex+EvilAgentPPVs .49 .54 .51 .30 .38 .34 .46 .42 .44 .42 .46 .44FrameNet+EvilAgentPPVs .49 .54 .51 .28 .45 .35 .46 .46 .46 .41 .49 .45FrameNet+EvilAgentPPVs+PosBasiliskPPVs .49 .53 .51 .30 .41 .35 .49 .49 .49 .43 .48 .45Table 2: Evaluation results for AESOP with PPVs.
The # in parentheses is the # of gold affect states.ble 1 shows the results when combining FrameNetwith other resources.
In terms of F score, the onlyadditive benefit came from the Semantic OrientationLexicon, which produced a better balance of recalland precision and an F score gain of +2.5.3 Evaluation of Affect States using PPVsOur second set of experiments evaluates the qualityof the automatically generated PPV lexicons.
Thetop portion of Table 2 shows the results for the neg-ative PPVs.
The PPVs harvested by the Evil Agentpatterns produced the best results, yielding recalland precision of .46 for negative states.
Note thatM and + states are also generated from the negativePPVs because they are inferred during affect projec-tion (Section 4.1.4).
The polarity of a negative PPVcan also be flipped by negation to produce a + state.Basilisk?s negative PPVs achieved similar preci-sion but lower recall.
We see no additional recalland some precision loss when the Evil Agent andBasilisk PPV lists are combined.
The precision dropis likely due to redundancy, which creates spuriousaffect states.
If two different words have negativepolarity but refer to the same event, then only onenegative affect state should be generated.
But AE-SOP will generate two affect states, so one will bespurious.The middle section of Table 2 shows the resultsfor the positive PPVs.
Both positive PPV lexiconswere of dubious quality, so we tried to extract a high-quality subset of each list.
For the Kind Agent PPVs,we computed the ratio of the frequency of the verbwith Evil Agents versus Kind Agents and only savedverbs with an Evil:Kind ratio (?)
> 1, which yielded1203 PPVs.
For the positive Basilisk PPVs, we usedonly the top 100 lexicon and top 100 context verbs,which yielded 164 unique verbs.
The positive PPVsdid generate several correct affect states (includinga - state when a positive PPV was negated), but alsomany spurious states.The bottom section of Table 2 shows the impactof the learned PPVs when combined with FrameNetand the Semantic Orientation Lexicon (SOLex).Adding the Evil Agent PPVs improved AESOP?s Fscore from 39% to 44%, mainly due to a +8 recallgain.
The recall of the - states increased from 22%to 46% with no loss of precision.
Interestingly, ifwe remove SOLex and use only FrameNet with ourPPVs, precision increases from 46% to 49% and re-call only drops by -1.
Finally, the last row of Table832 shows that adding Basilisk?s positive PPVs pro-duces a small recall boost (+2) with a slight drop inprecision (-1).Evaluating the impact of PPVs on plot unit struc-tures is an indirect way of assessing their quality be-cause creating plot units involves many steps.
Also,our test set is small so many verbs will never appear.To directly measure the quality of our PPVs, we re-cruited 3 people to manually review them.
We devel-oped annotation guidelines that instructed each an-notator to judge whether a verb is generally good orbad for its patient, assuming the patient is animate.They assigned each verb to one of 6 categories: ?
(not a verb), 2 (always good), 1 (usually good), 0(neutral, mixed, or requires inanimate patient), -1(usually bad), -2 (always bad).
Each annotator la-beled 250 words: 50 words randomly sampled fromeach of our 4 PPV lexicons5 (Evil Agent PPVs, KindAgent PPVs, Positive Basilisk PPVs, and NegativeBasilisk PPVs) plus 50 verbs labeled as neutral inthe MPQA lexicon.First, we measured agreement based on threegroupings: negative (-2 and -1), neutral (0), or pos-itive (1 and 2).
We computed ?
scores to measureinter-annotator agreement for each pair of annota-tors.6, but the ?
scores were relatively low becausethe annotators had trouble distinguishing the posi-tive cases from the neutral ones.
So we re-computedagreement using two groupings: negative (-2 and -1) and not-negative (0 through 2), and obtained ?scores of .69, .71, and .74.
We concluded that peo-ple largely agree on whether a verb is bad for thepatient, but they do not necessarily agree if a verb isgood for the patient.
One possible explanation is thatmany ?bad?
verbs represent physical harm or dan-ger: these verbs are both plentiful and easy to rec-ognize.
In contrast, ?good?
verbs are often more ab-stract and open to interpretation (e.g., is being ?en-vied?
or ?feared?
a good thing?
).We used the labels produced by the two an-notators with the highest ?
score to measure theaccuracy of our PPVs.
Both the Evil Agent andNegative Basilisk PPVs were judged to be 72.5%accurate, averaged over the judges.
The Kind Agent5The top-ranked Evil/Kind Agent PPV lists (?
> 1) whichyields 1203 kind PPVs, and 477 evil PPVs, the top 164 positiveBasilisk verbs, and the 678 (unique) negative Basilisk verbs.6We discarded words labeled as not a verb.PPVs were only about 39% accurate, while thePositive Basilisk PPVs were nearly 50% accurate.These results are consistent with our impressionsthat the negative PPVs are of relatively high quality,while the positive PPVs are mixed.
Some examplesof learned PPVs that were not present in our otherresources are:- : censor, chase, fire, orphan, paralyze, scare, sue+ : accommodate, harbor, nurse, obey, respect, value5.4 Evaluation of LinksWe represented each link as a 5-tuple?src-clause, src-state, tgt-clause, tgt-state, link-type?,where source/target denotes the direction of thelink, the source/target-states are the affect state type(+,-,M) and link-type is one of 3 types: actualization(a), motivation (m), or cross-character (xchar).
Asystem-produced link is considered correct if all 5elements of the tuple match the human annotation.Gold Aff States System Aff StatesLinks R P F R P Fxchar (56) .79 .85 .82 .18 .43 .25a (51) .90 .94 .92 .04 .07 .05m (26) 1.0 .57 .72 .15 .10 .12Table 3: Link results; parentheses show # of gold links.The second column of Table 3 shows the perfor-mance of AESOP when using gold standard affectstates.
Our simple heuristics for creating links worksurprisingly well for xchar and a links when givenperfect affect states.
However, these heuristics pro-duce relatively low precision for m links, albeit with100% recall.
This reveals that m links primarily doconnect adjacent states, but we need to be more dis-criminating when connecting them.
The third col-umn of Table 3 shows the results when using system-generated affect states.
We see that performance ismuch lower.
This is not particularly surprising, sinceAESOP?s F-score is 45%, so over half of the indi-vidual states are wrong, which means that less thana quarter of the pairs are correct.
From that perspec-tive, the xchar link performance is reasonable, butthe causal a and m links need improvement.5.5 AnalysisWe performed additional experiments to evaluatesome assumptions and components.
First, we cre-ated a Baseline system that is identical to AESOP84except that it does not use the affect projection rules.Instead, it naively projects every affect state in aclause onto every character in that clause.
The firsttwo rows of the table below show that AESOP?s pre-cision is double the Baseline, with nearly the samerecall.
This illustrates the importance of the projec-tion rules for mapping affect states onto characters.R P FBaseline .44 .24 .31AESOP, gold coref .43 .48 .45AESOP, gold coref, infstates .39 .48 .43AESOP, auto coref, infstates .24 .56 .34Our gold standard includes pure inference affectstates that are critical to the plot unit structure butcome from world knowledge outside the story itself.Of 157 affect states in our test set, 14 were pure in-ference states.
We ignored these states in our previ-ous experiments because our system has no way togenerate them.
The third row of the table shows thatincluding them lowers recall by -4.
Generating pureinferences is an interesting challenge, but they seemto be a relatively small part of the problem.The last row of the table shows AESOP?s perfor-mance when we use our automated coreference re-solver (Section 4.1.2) instead of gold standard coref-erence annotations.
We see a -15 recall drop coupledwith a +8 precision gain.
We were initially puz-zled by the precision gain but believe that it is pri-marily due to the handling of quotations.
Our goldstandard includes annotations for characters men-tioned in quotations, but our automated coreferenceresolver ignores quotations.
Most fables end witha moral, which is often a quote that may not men-tion the plot.
Consequently, AESOP generates morespurious affect states from the quotations when us-ing the gold standard annotations.6 Related Work and ConclusionsOur research is the first effort to fully automatethe creation of plot unit structures.
Other prelimi-nary work has begun to look at plot unit modellingfor single character stories (Appling and Riedl,2009).
More generally, our work is related to re-search in narrative story understanding (e.g., (El-son and McKeown, 2009)), automatic affect stateanalysis (Alm, 2009), and automated learning ofscripts (Schank and Abelson, 1977) and other con-ceptual knowledge structures (e.g., (Mooney andDeJong, 1985; Fujiki et al, 2003; Chambers and Ju-rafsky, 2008; Chambers and Jurafsky, 2009; Kaschand Oates, 2010)).
Our work benefitted from priorresearch in creating semantic resources such asFrameNet (Baker et al, 1998) and sentiment lex-icons and classifiers (e.g., (Takamura et al, 2005;Wilson et al, 2005b; Choi et al, 2006)).
We showedthat affect projection rules can effectively assign af-fect states to characters.
This task is similar to, butnot the same as, associating opinion words with theirtargets or topics (Kim and Hovy, 2006; Stoyanovand Cardie, 2008).
Some aspects of affect state iden-tification are closely related to Hopper and Thomp-son?s (1980) theory of transitivity.
In particular, theirnotions of aspect (has an action completed?
), benefitand harm (how much does an object gain/lose froman action?)
and volition (did the subject make a con-scious choice to act?
).AESOP produces affect states with an F score of45%.
Identifying positive states appears to be moredifficult than negative or mental states.
Our sys-tem?s biggest shortcoming currently seems to hingearound identifying plans and goals.
This includesthe M affect states that initiate plans, the +/- com-pletion states, as well as their corresponding links.We suspect that the relatively low recall on positiveaffect states is due to our inability to accurately iden-tify successful plan completions.
Finally, these re-sults are based on fables; plot unit analysis of othertypes of texts will pose additional challenges.AcknowledgmentsThe authors gratefully acknowledge the support ofDepartment of Homeland Security Grant N0014-07-1-0152, NSF grant IIS-0712764, and the DefenseAdvanced Research Projects Agency (DARPA) Ma-chine Reading Program under Air Force ResearchLaboratory (AFRL) prime contract no.
FA8750-09-C-0172.
Any opinions, findings, and conclusionor recommendations expressed in this material arethose of the author(s) and do not necessarily reflectthe view of the DARPA, AFRL, or the U.S. gov-ernment.
Thanks to Peter Jensen, Emily Schlichter,and Clay Templeton for PPV annotations, NathanGilbert for help with the coreference resolver, andthe anonymous reviewers for many helpful com-ments.85ReferencesCecilia Ovesdotter Alm.
2009.
Affect in Text and Speech.VDM Verlag Dr. Mller.D.
Scott Appling and Mark O. Riedl.
2009.
Representa-tions for learning to summarize plots.
In Proceedingsof the AAAI Spring Symposium on Intelligent Narra-tive Technologies II.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet Project.
In In Proceed-ings of COLING/ACL, pages 86?90.Nathanael Chambers and Dan Jurafsky.
2008.
Unsuper-vised learning of narrative event chains.
In Proceed-ings of the Association for Computational Linguistics.Nathanael Chambers and Dan Jurafsky.
2009.
Unsuper-vised learning of narrative schemas and their partici-pants.
In Proceedings of the Association for Compu-tational Linguistics.Yejin Choi, Eric Breck, and Claire Cardie.
2006.
Jointextraction of entities and relations for opinion recogni-tion.
In EMNLP ?06: Proceedings of the 2006 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 431?439, Morristown, NJ, USA.
Asso-ciation for Computational Linguistics.David Elson and Kathleen McKeown.
2009.
Extendingand evaluating a platform for story understanding.
InProceedings of the AAAI 2009 Spring Symposium onIntelligent Narrative Technologies II.Toshiaki Fujiki, Hidetsugu Nanba, and Manabu Oku-mura.
2003.
Automatic acquisition of script knowl-edge from a text collection.
In Proceedings of the Eu-ropean Association for Computational Linguistics.Vasileios Hatzivassiloglou and Kathy McKeown.
1997.Predicting the semantic orientation of adjectives.
InProceedings of the 35th Annual Meeting of the Associ-ation for Computational Linguistics, pages 174?181,Madrid, Spain.Paul J. Hopper and Sandra A. Thompson.
1980.Transitivity in grammar and discourse.
Language,56:251299.Niels Kasch and Tim Oates.
2010.
Mining script-likestructures from the web.
In NAACL-10 Workshop onFormalisms and Methodology for Learning by Read-ing (FAM-LbR).S.
Kim and E. Hovy.
2006.
Extracting Opinions, Opin-ion Holders, and Topics Expressed in Online NewsMedia Text.
In Proceedings of ACL/COLING Work-shop on Sentiment and Subjectivity in Text.W.
Lehnert, J.
Black, and B. Reiser.
1981.
Summariz-ing Narratives.
In Proceedings of the Seventh Interna-tional Joint Conference on Artificial Intelligence.W.
G. Lehnert.
1981.
Plot Units and Narrative Summa-rization.
Cognitive Science, 5(4):293?331.G.
Miller.
1990.
Wordnet: An On-line Lexical Database.International Journal of Lexicography, 3(4).Raymond Mooney and Gerald DeJong.
1985.
LearningSchemata for Natural Language Processing.
In Pro-ceedings of the Ninth International Joint Conferenceon Artificial Intelligence, pages 681?687.E.
Riloff and W. Phillips.
2004.
An Introduction to theSundance and AutoSlog Systems.
Technical ReportUUCS-04-015, School of Computing, University ofUtah.E.
Riloff, J. Wiebe, and T. Wilson.
2003.
Learning Sub-jective Nouns using Extraction Pattern Bootstrapping.In Proceedings of the Seventh Conference on NaturalLanguage Learning (CoNLL-2003), pages 25?32.Roger C. Schank and Robert P. Abelson.
1977.
Scripts,plans, goals and understanding.
Lawrence Erlbaum.V.
Stoyanov and C. Cardie.
2008.
Topic Identificationfor Fine-Grained Opinion Analysis.
In Conference onComputational Linguistics (COLING 2008).Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientations of words usingspin model.
In ACL ?05: Proceedings of the 43rd An-nual Meeting on Association for Computational Lin-guistics.M.
Thelen and E. Riloff.
2002.
A Bootstrapping Methodfor Learning Semantic Lexicons Using Extraction Pattern Contexts.
In Proceedings of the 2002 Conferenceon Empirical Methods in Natural Language Process-ing, pages 214?221.A.
Wierzbicka.
1987.
English speech act verbs: a se-mantic dictionary.
Academic Press, Sydney, Orlando.T.
Wilson, P. Hoffmann, S. Somasundaran, J. Kessler,J.
Wiebe, Y. Choi, C. Cardie, E. Riloff, and S. Patward-han.
2005a.
OpinionFinder: A system for subjectivityanalysis.
In Proceedings of HLT/EMNLP 2005 Inter-active Demonstrations.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005b.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of HumanLanguage Technology Conference and Conference onEmpirical Methods in Natural Language Processing,pages 347?354.
Association for Computational Lin-guistics.86
