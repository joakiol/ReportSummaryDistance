Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 116?117,New York City, June 2006. c?2006 Association for Computational LinguisticsRefactoring CorporaHelen L. JohnsonCenter for Computational PharmacologyU.
of Colorado School of Medicinehelen.johnson@uchsc.eduWilliam A. Baumgartner, Jr.Center for Computational PharmacologyU.
of Colorado School of Medicinewilliam.baumgartner@uchsc.eduMartin KrallingerProtein Design GroupUniversidad Auto?noma de Madridmartink@cnb.uam.esK.
Bretonnel CohenCenter for Computational PharmacologyU.
of Colorado School of Medicinekevin.cohen@gmail.comLawrence HunterCenter for Computational PharmacologyU.
of Colorado School of Medicinelarry.hunter@uchsc.eduAbstractWe describe a pilot project in semi-automatically refactoring a biomedicalcorpus.
The total time expended was justover three person-weeks, suggesting thatthis is a cost-efficient process.
The refac-tored corpus is available for download athttp://bionlp.sourceforge.net.1 IntroductionCohen et al (2005) surveyed the usage rates of anumber of biomedical corpora, and found that mostbiomedical corpora have not been used outside ofthe lab that created them.
Empirical data on corpusdesign and usage suggests that one major factor af-fecting usage is the format in which it is distributed.These findings suggest that there would be a largebenefit to the community in refactoring these cor-pora.
Refactoring is defined in the software en-gineering community as altering the internal struc-ture of code without altering its external behav-ior (Fowler et al, 1999).
We suggest that in the con-text of corpus linguistics, refactoring means chang-ing the format of a corpus without altering its con-tents, i.e.
its annotations and the text that they de-scribe.
The significance of being able to refactor alarge number of corpora should be self-evident: alikely increase in the use of the already extant pub-licly available data for evaluating biomedical lan-guage processing systems, without the attendant costof repeating their annotation.We examined the question of whether corpusrefactoring is practical by attempting a proof-of-concept application: modifying the format of theProtein Design Group (PDG) corpus described inBlaschke et al (1999) from its current idiosyncraticformat to a stand-off annotation format (WordF-reak1) and a GPML-like (Kim et al, 2001) embed-ded XML format.2 MethodsThe target WordFreak and XML-embedded formatswere chosen for two reasons.
First, there is someevidence suggesting that standoff annotation andembedded XML are the two most highly preferredcorpus annotation formats, and second, these for-mats are employed by the two largest extant curatedbiomedical corpora, GENIA (Kim et al, 2001) andBioIE (Kulick et al, 2004).The PDG corpus we refactored was originallyconstructed by automatically detecting protein-protein interactions using the system described inBlaschke et al (1999), and then manually review-ing the output.
We selected it for our pilot projectbecause it was the smallest publicly available cor-pus of which we were aware.
Each block of text hasa deprecated MEDLINE ID, a list of actions, a list ofproteins and a string of text in which the actions andproteins are mentioned.
The structure and contentsof the original corpus dictate the logical steps of therefactoring process:1.
Determine the current PubMed identifier, giventhe deprecated MEDLINE ID.
Use the PubMedidentifier to retrieve the original abstract.1http://venom.ldc.upenn.edu/resources/info/wordfreak ann.html1162.
Locate the original source sentence in the titleor abstract.3.
Locate the ?action?
keywords and the entities(i.e., proteins) in the text.4.
Produce output in the new formats.Between each file creation step above, human cu-rators verify the data.
The creation and curation pro-cess is structured this way so that from one step tothe next we are assured that all data is valid, therebygiving the automation the best chance of performingwell on the subsequent step.3 ResultsThe refactored PDG corpus is publicly available athttp://bionlp.sourceforge.net.
Total time expendedto refactor the PDG corpus was 122 hours and 25minutes, or approximately three person-weeks.
Justover 80% of the time was spent on the programmingportion.
Much of that programming can be directlyapplied to the next refactoring project.
The remain-ing 20% of the time was spent curating the program-matic outputs.Mapping IDs and obtaining the correct abstractreturned near-perfect results and required very littlecuration.
For the sentence extraction step, 33% ofthe corpus blocks needed manual correction, whichrequired 4 hours of curation.
(Here and below, ?cu-ration?
time includes both visual inspection of out-puts, and correction of any errors detected.)
Thesource of error was largely due to the fact that thesentence extractor returned the best sentence fromthe abstract, but the original corpus text was some-times more or less than one sentence.For the protein and action mapping step, about40% of the corpus segments required manual cor-rection.
In total, this required about 16 hours of cu-ration time.
Distinct sources of error included par-tial entity extraction, incorrect entity extraction, andincorrect entity annotation in the original corpus ma-terial.
Each of these types of errors were corrected.4 ConclusionThe underlying motivation for this paper is the hy-pothesis that corpus refactoring is practical, eco-nomical, and useful.
Erjavec (2003) converted theGENIA corpus from its native format to a TEI P4format.
They noted that the translation processbrought to light some previously covert problemswith the GENIA format.
Similarly, in the process ofthe refactoring we discovered and repaired a numberof erroneous entity boundaries and spurious entities.A number of enhancements to the corpus are nowpossible that in its previous form would have beendifficult at best.
These include but are not limitedto performing syntactic and semantic annotation andadding negative examples, which would expand theusefulness of the corpus.
Using revisioning soft-ware, the distribution of iterative feature additionsbecomes simple.We found that this corpus could be refactored withabout 3 person-weeks?
worth of time.
Users can takeadvantage of the corrections that we made to the en-tity component of the data to evaluate novel namedentity recognition techniques or information extrac-tion approaches.5 AcknowledgmentsThe authors thank the Protein Design Group at the UniversidadAuto?noma de Madrid for providing the original PDG protein-protein interaction corpus, Christian Blaschke and Alfonso Va-lencia for assistance and support, and Andrew Roberts for mod-ifying his jTokeniser package for us.ReferencesChristian Blaschke, Miguel A. Andrade, and Christos Ouzou-nis.
1999.
Automatic extraction of biological informationfrom scientific text: Protein-protein interactions.K.
Bretonnel Cohen, Lynne Fox, Philip Ogren, and LawrenceHunter.
2005.
Empirical data on corpus design and usage inbiomedical natural language processing.
AMIA 2005 Sym-posium Proceedings, pages 156?160.Tomaz Erjavec, Yuka Tateisi, Jin-Dong Kim, and Tomoko Ohta.2003.
Encoding biomedical resources in TEI: the case of theGENIA corpus.Martin Fowler, Kent Beck, John Brant, William Opdyke, andDon Roberts.
1999.
Refactoring: improving the design ofexisting code.
Addison-Wesley.Jin-Dong Kim, Tomoko Ohta, Yuka Tateisi, Hideki Mima, andJun?ichi Tsujii.
2001.
Xml-based linguistic annotation ofcorpus.
In Proceedings of The First NLP and XML Work-shop, pages 47?53.S.
Kulick, A. Bies, M. Liberman, M. Mandel, R. McDonald,M.
Palmer, A. Schein, and L. Ungar.
2004.
Integrated anno-tation for biomedical information extraction.
Proceedings ofthe HLT/NAACL.117
