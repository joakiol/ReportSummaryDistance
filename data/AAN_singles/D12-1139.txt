Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1522?1533, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsCharacterizing Stylistic Elements in Syntactic StructureSong Feng Ritwik Banerjee Yejin ChoiDepartment of Computer ScienceStony Brook UniversityNY 11794, USAsongfeng, rbanerjee, ychoi@cs.stonybrook.eduAbstractMuch of the writing styles recognized inrhetorical and composition theories involvedeep syntactic elements.
However, mostprevious research for computational sty-lometric analysis has relied on shallowlexico-syntactic patterns.
Some very re-cent work has shown that PCFG modelscan detect distributional difference in syn-tactic styles, but without offering much in-sights into exactly what constitute salientstylistic elements in sentence structurecharacterizing each authorship.
In thispaper, we present a comprehensive ex-ploration of syntactic elements in writingstyles, with particular emphasis on inter-pretable characterization of stylistic ele-ments.
We present analytic insights withrespect to the authorship attribution taskin two different domains.1 IntroductionMuch of the writing styles recognized in rhetor-ical and composition theories involve deep syn-tactic elements in style (e.g., Bain (1887), Kem-per (1987) Strunk and White (2008)).
However,previous research for automatic authorship at-tribution and computational stylometric analy-sis have relied mostly on shallow lexico-syntacticpatterns (e.g., Mendenhall (1887), Mostellerand Wallace (1984), Stamatatos et al(2001),Baayen et al(2002), Koppel and Schler (2003),Zhao and Zobel (2007), Luyckx and Daelemans(2008)).Some very recent works have shown thatPCFG models can detect distributional differ-ence in sentence structure in gender attribution(Sarawgi et al 2011), authorship attribution(Raghavan et al 2010), and native languageidentification (Wong and Dras, 2011).
However,still very little has been understood exactly whatconstitutes salient stylistic elements in sentencestructures that characterize each author.
Al-though the work of Wong and Dras (2011) hasextracted production rules with highest informa-tion gain, their analysis stops short of providinginsight any deeper than what simple n-gram-level analysis could also provide.1 One mighteven wonder whether PCFG models are hing-ing mostly on leaf production rules, and whetherthere are indeed deep syntactic differences at all.This paper attempts to answer these questions.As an example of syntactic stylistic elementsthat have been much discussed in rhetorical the-ories, but have not been analyzed computation-ally, let us consider two contrasting sentencestyles: loose (cumulative) and periodic:2 a loosesentence places the main clause at the begin-ning, and then appends subordinate phrases andclauses to develop the main message.
In con-trast, a periodic sentence starts with subordi-nate phrases and clauses, suspending the most1For instance, missing determiners in English textwritten by Chinese speakers, or simple n-gram anomalysuch as frequent use of ?according to?
by Chinese speak-ers (Wong and Dras, 2011).2Periodic sentences were favored in classical times,while loose sentences became more popular in the modernage.1522Hobbs Joshi Lin McDonS?ROOT ?
S , CC S PP?PRN ?
IN NP NP?S ?
NN CD NP?NP ?
DT NN POSNP?PP ?
DT NP?PP ?
NP PRN SBAR NP?NP ?
DT NN NNS WHNP?SBAR ?
INVP?VP ?
TO VP S?ROOT ?
PP NP VP .
S?ROOT ?
SBAR , NP VP .
NP?PP ?
NP SBARPP?PP ?
IN S PRN?NP ?
-LRB- PP -RRB- NP?PP ?
NP : NP SBAR?PP ?
WHADVP SNP?PP ?
NP , PP NP?NP ?
NNP S?ROOT ?
PP , NP VP .
SBAR?S ?
WHNP SVP?S ?
VBZ ADJP S S?SBAR ?
PP NP VP NP?NP ?
PDT DT NNS PP?NP ?
IN SBARVP?SINV ?
VBZ S?ROOT ?
LST NP VP .
NP?VP ?
DT NN SBAR SBAR?NP ?
WHNP SVP?S ?
VBD S CONJP?NP ?
RB RB IN SBAR?S ?
WHADVP S SBAR?PP ?
SBAR CC SBARVP?S ?
VBG PP NP?PP ?
NP PRN PP PRN?NP ?
-LRB- NP -RRB- PP?VP ?
INADVP?VP ?
RB PP NP?NP ?
NP , NP NP?PP ?
NN NN S?SBAR ?
VPTable 1: Top 10 most discriminative production rules for each author in the scientific domain.loose Christopher Columbus finallyreached the shores of San Salvadorafter months of uncertainty atsea, the threat of mutiny, and ashortage of food and water.periodic After months of uncertainty at sea,the threat of mutiny, and a short-age of food and water, ChristopherColumbus finally reached the shoresof San Salvador.Table 2: Loose/Periodic sentence with identical setof words and POS tagsimportant part to the end.
The example in Ta-ble 2 highlights the difference:Notice that these two sentences comprise of anidentical set of words and part-of-speech.
Hence,shallow lexico-syntactic analysis will not be ableto catch the pronounced stylistic difference thatis clear to a human reader.One might wonder whether we could gain in-teresting insights simply by looking at the mostdiscriminative production rules in PCFG trees.To address this question, Table 1 shows thetop ten most discriminative production rulesfor authorship attribution for scientific articles,3ranked by LIBLINEAR (Fan et al 2008).4 Notethat terminal production rules are excluded soas to focus directly on syntax.It does provide some insights, but not to a sat-isfactory degree.
For instance, Hobbs seems tofavor inverted declarative sentences (SINV) andadverbs with prepositions (RB PP).
While thelatter can be easily obtained by simple part-of-3See Section 2 for the description of the dataset.4We use Berkeley PCFG parser (Petrov and Klein,2007) for all experiments.speech analysis, the former requires using parsetrees.
We can also observe that none of thetop 10 most discriminative production rules forHobbs includes SBAR tag, which represents sub-ordinate clauses.
But examining discriminativerules alone is limited in providing more compre-hensive characterization of idiolects.Can we unveil something more in deep syntac-tic structure that can characterize the collectivesyntactic difference between any two authors?For instance, what can we say about distribu-tional difference between loose and periodic sen-tences discussed earlier for each author?
As canbe seen in Table 1, simply enumerating most dis-criminative rules does not readily answer ques-tions such as above.In general, production rules in CFGs do notdirectly map to a wide variety of stylistic el-ements in rhetorical and composition theories.This is only as expected however, partly becauseCFGs are not designed for stylometric analysisin the first place, and also because some syntac-tic elements can go beyond the scope of contextfree grammars.As an attempt to reduce this gap betweenmodern statistical parsers and cognitively recog-nizable stylistic elements, we explore two com-plementary approaches:1.
Translating some of the well known stylisticelements of rhetorical theories into PCFGanalysis (Section 3).2.
Investigating different strategies of analyz-ing PCFG trees to extract author charac-teristics that are interesting as well as in-terpretable (Sections 4 & 5).1523Algorithm 1 Sentence Type-1 IdentificationInput: Parse tree t(Nr) of sentence sOutput: Type of s.if S ?
Ltop thenif SBAR /?
?
(Nr) thenreturn COMPOUNDelsereturn COMPLEX-COMPOUNDelseif VP ?
Ltop thenif SBAR /?
?
(Nr) thenreturn SIMPLEelsereturn COMPLEXreturn OTHERWe present analytic insights with respect tothe authorship attribution task in two distinctdomains.2 DataFor the empirical analysis of authorship attri-bution, we use two different datasets describedbelow.
Sections 3, 4 & 5 provide the details ofour stylometric analysis.Scientific Paper We use the ACL Anthol-ogy Reference Corpus (Bird et al 2008).
Sinceit is nearly impossible to determine the gold-standard authorship of a paper written by multi-ple authors, we select 10 authors who have pub-lished at least 8 single-authored papers.
We in-clude 8 documents per author, and remove cita-tions, tables, formulas from the text using sim-ple heuristics.5Novels We collect 5 novels from 5 English au-thors: Charles Dickens, Edward Bulwer-Lytton,Jane Austen, Thomas Hardy and Walter Scott.We select the first 3000 sentences from eachnovel and group every 50 consecutive sentencesinto 60 documents per novel per author.5Some might question whether the size of the datasetused here is relatively small in comparison to typicaldataset comprised of thousands of documents in conven-tional text categorization.
We point out that authorshipattribution is fundamentally different from text catego-rization in that it is often practically impossible to collectmore than several documents for each author.
Therefore,it is desirable that the attribution algorithms to detectthe authors based on very small samples.Algorithm 2 Sentence Type-II IdentificationInput: Parse tree t(Nr) of sentence sOutput: Type of s.k ?
1while k ?
?
doif Ltopk 6= VP thenif S ?
?
(Ltopk ) or SBAR ?
?
(Ltopk ) thenreturn PERIODICelseif S ?
?
(Ltopk ) or SBAR ?
?
(Ltopk ) thenreturn LOOSEreturn OTHER3 Sentence TypesIn this section, we examine well-known sentencetypes that are recognized in the literature, buthave not been analyzed computationally.Type-I Identification ?
Simple/Complex/Compound/Complex-Compound: PCFGtrees do not provide this information directly,hence we must construct an algorithm to deriveit.
The key to identifying these sentences is theexistence of dependent and independent clauses.For the former, we rely on the SBAR tag, whilefor the latter, we first define the sequence ofnodes right below the root (e.g., [NP VP .]
shownin the horizontal box in Figure 1).
We call thisthe top structural level.
We then check whetherS (in addition to the root S) appears in thissequence.Formally, let Ltop = {Ni} be the set of nodesin the top structural level, and ?
= |Ltop|.
Lett(Nr) be the tree rooted at Nr, and ?
(Nr) de-note the set of nodes in t(Nr).
Algorithm 1shows the procedure to determine the type-Iclass of a sentence based on its PCFG tree.6Type-II Identification ?
Loose/Periodic:A sentence can also be classified as loose orperiodic, and we present Algorithm 2 for thisidentification.
We perform a mini-evaluation on20 previously unseen sentences for each type7.Our algorithm was able to perform type-I iden-tification on all sentences correctly.
In type-II6Note that Algorithm 1 & 2 rely on the use of Berkeleyparser (Petrov and Klein, 2007).7These were gathered from several online quizzesfor English learners.
E.g., http://grammar.about.com,http://a4esl.org1524Type Hobbs Joshi Lin McDonsimple 40.0 41.7 50.2 27.9cplex 40.8 40.7 37.6 48.4cpnd 7.9 5.6 3.9 5.5cpxnd 8.5 9.2 7.7 15.5other 2.8 2.8 0.6 2.7loose 27.6 26.4 26.9 30.8perio 11.1 11.7 15.2 16.4other 61.3 61.9 57.9 52.8Table 3: Sentence Types (%) in scientific data.identification, it labeled all loose sentences cor-rectly, and achieved 90% accuracy on periodicsentences.Discussion Tables 3 & 4 show the sentencetype distribution in scientific data and novels,respectively.8 We see that different authors arecharacterized by different distribution of sen-tence types.
For instance, in Table 3, Lin isa prolific user of simple sentences while McDonprefers employing complex sentences.
McDonalso uses complex-compound sentences quite of-ten (15.5%), more than twice as frequently asLin.
Notice that all authors use loose sen-tences much more often than periodic sentences,a known trend in modern English.In Table 4, we see the opposite trend among19th-century novels: with the exception of JaneAusten, all authors utilize periodic sentencescomparatively more often.
We also noticethat complex and complex-compound sentencesabound, as expected from classic literary proses.Can we determine authorship solely based on thedistribution of sentence types?We experiment with a SVM classifier using just6 features (one feature for each sentence type inTable 3), and we achieve accuracy 36.0% withthe scientific data.
Given that a random base-line would achieve only about 10% accuracy, thisdemonstrates that the distribution of sentencetypes does characterize an idiolect to some de-gree.8Due to space limitation, we present analyses basedon 4 authors from the scientific data.Type Dickens B-Lyt Austen Hardy Scottsimple 26.0 21.2 23.9 25.6 17.5cplex 24.4 21.8 24.8 25.6 31.8cpnd 15.3 15.2 12.6 16.3 11.7cpxnd 20.8 23.3 31.1 18.9 28.7other 13.5 18.5 7.6 13.6 10.3loose 11.5 10.8 17.9 14.5 15.3perio 19.5 13.6 14.0 16.2 18.0other 69.0 75.6 68.1 69.3 66.7Table 4: Sentence Types (%) in Novels4 Syntactic Elements Based onProduction RulesIn this section, we examine three different as-pects of syntactic elements based on productionrules.4.1 Syntactic VariationsWe conjecture that the variety of syntacticstructure, which most previous research in com-putational stylometry has not paid much atten-tion to, provides an interesting insight into au-thorship.
One way to quantify the degree of syn-tactic variations is to count the unique produc-tion rules.
In Tables 5, we show the extent ofsyntactic variations employed by authors usingthe standard deviation ?
and the coverage of anauthor:C(a) :=|R(a)|| ?a R(a)|?
100whereR(a) denotes the set of unique productionrules used by author a, and ?a iterates over allauthors.
In order to compare among authors,we also show these parameters normalized withrespect to the highest value.
Our default settingis to exclude all lexicalized rules in the produc-tions to focus directly on the syntactic varia-tions.
In our experiments (Section 6), however,we do augment the rules with (a) ancestor nodesto capture deeper syntactic structure and (b)lexical (leaf) nodes.As hypothesized, these statistics provide usnew insights into the authorship.
For instance,we find that McDon employs a wider variety ofsyntactic structure than others, while Lin?s writ-ing exhibits relatively the least variation.
More-over, comparing Joshi and Hobbs, it is inter-esting to see the standard deviation differ a lot1525Hobbs Joshi Lin McDon Dickens B-Lyt Austen Hardy ScottC 36.0 37.6 32.8 42.6 30.9 28.8 36.2 30.0 24.1Cnorm 0.84 0.88 0.77 1.0 0.85 0.79 1.0 0.83 0.67?
51.5 39.2 63.3 44.4 88.3 81.6 98.0 125.3 114.7?norm 0.81 0.62 1.0 0.7 0.7 0.65 0.78 1.0 0.92Table 5: Syntactic variations of different authors in the scientific domain.Hobbs Joshi Lin McDon# 136 # 142 # 124 # 161S ?
S CC S .
S ?
ADVP PP NP VP .
S ?
SBAR NP VP .
S ?
S NP VP .S ?
CC NP VP .
S ?
PP NP ADVP VP .
FRAG ?
NP : S .
S ?
S : S .S ?
S VP .
S ?
NP VP S ?
NP VP .
S ?
SBAR VP .S ?
NP NP VP .
S ?
S S CC S .
S ?
PP VP .
S ?
SBAR S CC S .S ?
PP NP VP .
S ?
ADVP NP VP .
S ?
NP ADVP VP .
S ?
NP PP VP .Table 6: Most discriminative sentence outlines in the scientific data.
#N shows the number of uniquesentence outlines of each author.
(51.5 and 39.2), in spite of their C scores beingsimilar: 36.0% and 37.6%, respectively.
Thisindicates that Hobbs tends to use a certain sub-set production rules much more frequently thanJoshi.
Lin exhibits the highest standard devia-tion in spite of having least syntactic variation,indicating that he uses a much smaller subset ofproductions regularly, while ocassionally deviat-ing to other rules.Similarly, among novels, Jane Austen?s writ-ing has the highest amount of variation, whileWalter Scott?s writing style is the least varied.Even though authors from both datasets displaysimilar C scores (Table 5), the difference in ?
isnoteworthy.
The significantly higher linguisticvariation is to be expected in creative writingof such stature.
It is interesting to note thatthe authors with highest coverage ?
Austen andDickens ?
have much lower deviation in theirsyntactic structure when compared to Hardyand Scott.
This indicates that while Austen andDickens consistently employ a wider variety ofsentence structures in their writing, Hardy andScott follow a relatively more uniform style withsporadic forays into diverse syntactic constructs.4.2 Sentence OutlinesAlthough the approach of Section 4.1 give us abetter and more general insight into the char-acteristics of each author, its ability to provideinsight on deep syntactic structure is still lim-ited, as it covers production rules at all levels ofthe tree.
We thus shift our focus to the top levelof the trees, e.g., the second level (marked in ahorizontal box) in Tree (1) of Figure 1, whichgives us a better sense of sentence outlines.Tables 6 and 7 present the most discrimina-tive sentence outlines of each author in the scien-tific data and novels, respectively.
We find thatMcDon is a prolific user of subordinate clauses,indicating his bias towards using complex sen-tences.
The rule ?S ?
SBAR S CC S?
showshis inclination towards complex-compound sen-tences as well.
These inferences are further sup-ported by the observations in Table 3.
Anotherobservation of possible interest is the tendencyof Joshi and Lin to begin sentences with prepo-sitional phrases.In comparing Table 6 and Table 7, noticethe significantly higher presence of complex andcompound-complex structures in the latter9.The most discriminating sentence outlines forJane Austen, for instance, are all indicative ofcomplex-compound sentences.
This is furthersupported by Table 4.5 Syntactic Elements Based on TreeTopologyIn this section, we investigate quantitative tech-niques to capture stylistic elements in the tree9The presence of ?FRAG?
is not surprising.
Inten-tional use of verbless sentence fragments, known as sce-sis onomaton, was often employed by authors such asDickens and Bulwer-Lytton (Quinn, 1995).1526Dickens Bulwer-Lytton Austen Hardy Scott# 1820 # 1696 # 2137 # 1772 # 1423SQ ?
NNP .
SBARQ ?
WHNP S .
S ?
S : CC S .
S ?
S NP VP .
S ?
NP PRN VP .FRAG ?
NP .
FRAG ?
INTJ NP .
S ?
S CC S : CC S .
S ?
ADVP NP VP .
S ?
PP NP VP .SINV ?
NP VP NP .
S ?
S : S CC S .
S ?
S : CC S : CC S .
S ?
FRAG : S .
S ?
S S : S .INTJ ?
UH .
FRAG ?
CC NP .
S ?
S : S : CC S .
S ?
INTJ NP VP .
S ?
NP PP VP .SBARQ ?
WHNP SQ .
FRAG ?
NP ADJP .
S ?
SBAR S : CC S .
S ?
NP VP .
S ?
ADVP PRN NP VP .Table 7: Most discriminative sentence outlines in the novel data.
#N shows the number of unique sentenceoutlines of each author.Metrics Scientific Data NovelsHobbs Joshi Lin McDon Dickens B-Lyt Austen Hardy Scottsen-len avg 23.7 26.0 21.0 32.2 24.1 26.7 31.4 21.5 34.1hT avg 5.8 5.3 5.9 4.8 4.7 5.0 5.4 4.9 5.9hF avg 2.4 2.1 2.5 1.9 1.9 1.9 2.1 1.9 2.1wL avg 5.0 4.8 5.5 4.2 4.1 4.4 4.7 3.8 4.9?H avg 1.2 1.1 1.1 1.0 1.1 1.1 1.3 1.2 1.4?S avg 1.9 1.8 1.8 1.7 1.0 1.1 1.2 1.0 1.4Table 8: Tree topology metrics for scientific data and novels.topology.
Figure 1 shows three different parsetrees to accompany our discussion.10 Noticethat sentence (1) is a loose sentence, and sen-tence (2) is periodic.
In general, loose sentencesgrow deep and unbalanced, while periodic sen-tences are relatively more balanced and wider.For a tree t rooted at NR with a height n, letT be the set of leaf nodes, and let F be the setof furcation nodes, and let ?
(Ni, Nj) denote thelength of the shortest path from Ni to Nj .
In-spired by the work of Shao (1990), we analyzetree topology with the following four measure-ments:?
Leaf height (hT = {hTi , Ni ?
T }), wherehTi = ?
(Ni, NR) Ni ?
T .
For instance, theleaf height of ?free?
of Tree (2) in Fig.
1is 6.?
Furcation height (hF = {hFi , Ni ?
F}),where hFi is the maximum leaf height withinthe subtree rooted at Ni.
In Figure 1, forexample, the furcation height of the VP inTree (2) (marked in triangle) is 3.?
Level width (wL = {wl, 1 ?
l ?
n}),where wl = |{Ni : ?
(Ni, NR) = l}|.
E.g., w4of Tree (1) in Figure 1 is 6.10Example sentences are taken from Lin (1997), Joshi(1992), and Lin (1995).?
Horizontal ?H = {?Hi , Ni ?
F} , andVertical Imbalance ?S = {?Si , Ni ?
F}.Let C be the set of child nodes of Nk.
If|C| ?
2, then?Hk =????
1n|C|?i=1(hFi ?H)2where H = 1|C|?|C|i=1 hFi .
Similarly,?Sk =????
1n|C|?i=1(s(Ni)?
S)2where S = 1|C|?|C|i=1 s(Ni) and s(Ni) is thenumber of leaf nodes of tree rooted at Ni.As shown in Figure 1, the imbalance of theinternal node VP in Tree (2) (marked intriangle) is 0.5 horizontally, and 0.5 verti-cally.To give an intuition on the relation betweenthese measurements and different tree struc-tures, Table 9 provides the measurements of thethree trees shown in Figure 1.Note that all three sentences are of similarlength but show different tree structures.
Tree(1) and Tree (2) differ in that Tree (1) ishighly unbalanced and grows deep, while Tree1527Figure 1: Parsed treesMetrics Tree (1) Tree (2) Tree (3)# of tokens 15 13 13maxi {hTi } 11 6 6maxi {wLi } 6 9 9maxi {?Hi } 4.97 1.6 1.7maxi {?Si } 4 1.5 4.7Table 9: Tree Topology Statistics for Figure 1.
(2) is much better balanced and grows shorterbut wider.
Comparing Tree (2) and Tree (3),they have the same max Leaf height, Levelwidth, and Horizontal Imbalance, but thelatter has bigger Vertical Imbalance, whichquantifies the imbalance in terms of the textspan covered by subtrees.We provide these topological metrics for au-thors from both datasets in Table 8.6 Experiments & EvaluationIn our experiments, we utilize a set of featuresmotivated by PCFG trees.
These consist of sim-ple production rules and other syntactic featuresbased on tree-traversals.
Table 10 describesthese features with examples from Tree (2), us-ing the portion marked by the triangle.These sets of production rules and syntax fea-tures are used to build SVM classifiers using LI-BLINEAR (Fan et al 2008), wherein all fea-ture values are encoded as term-frequencies nor-malized by document size.
We run 5-fold cross-validation with training and testing split first as80%/20%, and then as 20%/80%.We would like to point out that the latter con-figuration is of high practical importance in au-thorship attribution, since we may not alwayshave sufficient training data in realistic situa-tions, e.g., forensics (Luyckx and Daelemans,2008).Lexical tokens provide strong clues by creat-ing features that are specific to each author: re-search topics in the scientific data, and propernouns such as character names in novels.
Tolessen such topical bias, we lemmatize and rankwords according to their frequency (in the entiredataset), and then consider the top 2,000 wordsonly.
Leaf-node productions with words outsidethis set are disregarded.Our experimental results (Tables 11 & 12)show that not only do deep syntactic featuresperform well on their own, but they also signif-icantly improve over lexical features.
We alsoshow that adding the style11 features furtherimproves performance.1528Featurespr Rules excluding terminal productions.E.g., VP ?
VBG NPsynv Traversal from a non-leaf node to its grand-parent (embedded rising).E.g., VP?S ?
PPsynh Left-to-right traversal in the set of all non-leaf children of a node.E.g., VBG ?
NP (for node VP)synv+h synv ?
synhsyn0 No tree traversal.
Feature comprises inte-rior nodes only.syn?
Union of all edges to child nodes, exceptwhen child is a leaf node.E.g., {VP ?
VBG, VP ?
NP}synl syn?
?
{ edge to parent node}style11 The set of 11 extra stylistic features.
6 val-ues from the distribution of sentence types(Section 3), and 5 topological metrics (Sec-tion 5) characterizing the height, width andimbalance of a tree.Variationsp?r Each production rule is augmented with thegrandparent node.?
Terminal (leaf) nodes are included.Table 10: Features and their lexico-syntactic varia-tions.
Illustration: p?r?
denotes the set of productionrules pr (including terminal productions) that areaugmented with their grandparent nodes.To quantify the amount of authorship infor-mation carried in the set style11, we experi-ment with a SVM classifier using only 11 fea-tures (one for each metric), and achieve accu-racy of 42.0% and 52.0% with scientific dataand novels, respectively.
Given that a random-guess baseline would achieve only 10% and 20%(resp.
), and that the classification is based onjust 11 features, this experiment demonstrateshow effectively the tree topology statistics cap-ture idiolects.
In general, lexicalized featuresyield higher performance even after removingtopical words.
This is expected since tokenssuch as function words play an important rolein determining authorship (e.g., Mosteller andWallace (1984), Garcia and Martin (2007), Arg-amon et al(2007)).A more important observation, however, isthat even after removing the leaf productionrules, accuracy as high as 93% (scientific) and92.2% (novels) are obtained using syntactic fea-Features Scientific Novels+style11 +style11style11 20.6 ?
43.1 ?Unigram 56.9 ?
69.3 ?synh 53.7 53.7 68.3 67.9syn0 22.9 31.1 57.8 62.5syn?
43.4 44.0 63.6 65.7synl 51.1 51.7 71.3 72.8synv+h 54.0 55.7 72.0 73.2syn?h 63.1 64.0 72,1 73.2syn?0 56.6 56.0 73.1 74.1syn??
56.3 57.2 74.0 74.9syn?l 64.6 65.4 74.9 75.3syn?v+h 64.0 67.7 74.0 74.7pr 50.3 53.4 67.0 66.7p?r 59.1 60.6 69.7 68.7pr?
63.7 65.1 71.5 73.2p?r?
66.3 69.4 73.6 74.9Table 11: Authorship attribution with 20% train-ing data.
Improvement with addition of style11shown in bold.tures, which demonstrates that there are syn-tactic patterns unique to each author.
Also no-tice that using only production rules, we achievehigher accuracy in novels (90.1%), but the ad-dition of style11 features yields better resultswith scientific data (93.0%).Using different amounts of training data pro-vides insight about the influence of lexical clues.In the scientific dataset, increasing the amountof training data decreases the average perfor-mance difference between lexicalized and unlex-icalized features: 13.5% to 11.6%.
In novels,however, we see the opposite trend: 6.1% in-creases to 8.1%.We further observe that with scientific data,increasing the amount of training data improvesthe average performance across all unlexicalizedfeature-sets from 50.0% to 82.9%, an improve-ment of 32.8%.
For novels, the correspondingimprovement is small in comparison: 17.0%.This difference is expected.
While authorssuch as Dickens or Hardy have their unique writ-ing styles that a classifier can learn based on fewdocuments, capturing idiolects in the more rigiddomain of scientific writing is far from obviouswith little training data.1529Features Scientific Novels+style11 +style11style11 42.0 ?
52.0 ?Unigram 88.0 ?
92.7 ?synh 85.0 85.0 87.6 88.9syn0 40.0 53.0 66.4 72.3syn?
78.0 82.0 80.3 82.3synl 85.0 92.0 89.3 92.2synv+h 89.0 93.0 90.1 91.2syn?h 93.0 93.0 93.7 93.9syn?0 92.0 94.0 92.1 93.2syn??
93.0 94.0 93.4 94.5syn?l 93.0 95.0 94.9 95.2syn?v+h 94.0 96.0 94.7 94.8pr 85.0 86.0 86.7 86.7p?r 87.0 89.0 88.2 89.3pr?
93.0 94.0 92.1 93.2p?r?
94.0 95.0 94.5 95.1Table 12: Authorship attribution with 80% train-ing data.Turning to lexicalized features, we note thatwith more training data, lexical cues performbetter in scientific domain than in novels.
With80% data used for training, the average per-formance of lexicalized feature-sets with sciencedata is 94.4%, and slightly lower at 94.3% fornovels.
With less training data, however, thesefigures are 63.5% and 74.3% respectively.Finally, we point out that adding the stylefeatures derived from sentence types and treetopologies almost always improves the perfor-mance.
In scientific data, syn?v+h with style11features shows the best performance (96%),while syn?l yields the best results for novels(95.2%).
For unlexicalized features, addingstyle11 to synv+h and synl yields respectiveimprovements of 4.0% and 2.9% in the twodatasets.7 Related WorkThere are several hurdles in authorship attribu-tion.
First and foremost, writing style is ex-tremely domain-dependent.
Much of previousresearch has focused on several domains of writ-ing, such as informal modern writing in blogsand online messages (Zheng et al 2006), rela-tively formal contemporary texts such as newsarticles (Raghavan et al 2010), or classical lit-erature like novels and proses (e.g., (Burrows,2002), (Hoover, 2004)).The nature of these features have also var-ied considerably.
Character level n-grams havebeen used by several researchers; most notablyby Peng et al(2003), by Houvardas and Sta-matatos (2006) for feature selection, and by Sta-matatos (2006) in ensemble learning.
Keselj etal.
(2003) employed frequency measures on n-grams for authorship attribution.Others, such as Zhao and Zobel (2005), Arg-amon and Levitan (2004), Garcia and Martin(2007), have used word-level approaches instead,incorporating the differential use of functionwords by authors.More sophisticated linguistic cues have beenexplored as well: parts-of-speech n-grams(Diederich et al 2003), word-level statistics to-gether with POS-sequences (Luyckx and Daele-mans, 2008), syntactic labels from partial pars-ing (Hirst and Feiguina, 2007), etc.
The useof syntactic features from parse trees in au-thorship attribution was initiated by Baayen etal.
(1996), and more recently, Raghavan et al(2010) have directly employed PCFG languagemodels in this area.Syntactic features from PCFG parse treeshave also been used for gender attribution(Sarawgi et al 2011), genre identification (Sta-matatos et al 2000), native language identifi-cation (Wong and Dras, 2011) and readabilityassessment (Pitler and Nenkova, 2008).
Theprimary focus of most previous research, how-ever, was to attain better classification accuracy,rather than providing linguistic interpretationsof individual authorship and their stylistic ele-ments.Our work is the first to attempt authorshipattribution of scientific papers, a contemporarydomain where language is very formal, and thestylistic variations have limited scope.
In ad-dition to exploring this new domain, we alsopresent a comparative study expounding therole of syntactic features for authorship attri-bution in classical literature.
Furthermore, ourwork is also the first to utilize tree topological1530features (Chan et al 2010) in the context ofstylometric analysis.8 ConclusionIn this paper, we have presented a comprehen-sive exploration of syntactic elements in writingstyles, with particular emphasis on interpretablecharacterization of stylistic elements, thus dis-tinguishing our work from other recent work onsyntactic stylometric analysis.
Our analyticalstudy provides novel statistically supported in-sights into stylistic elements that have not beencomputationally analyzed in previous literature.In the future, we plan to investigate the use ofsyntactic feature generators for text categoriza-tion (e.g., Collins and Duffy (2002), Moschitti(2008), Pighin and Moschitti (2009)) for stylom-etry analysis.Acknowledgments Yejin Choi is partiallysupported by the Stony Brook University Officeof the Vice President for Research.
We thankreviewers for many insightful and helpful com-ments.ReferencesShlomo Argamon and Shlomo Levitan.
2004.
Mea-suring the usefulness of function words for author-ship attribution.
Literary and Linguistic Comput-ing, pages 1?3.Shlomo Argamon, Casey Whitelaw, Paul Chase,Sobhan Raj Hota, Navendu Garg, and ShlomoLevitan.
2007.
Stylistic text classification usingfunctional lexical features: Research articles.
J.Am.
Soc.
Inf.
Sci.
Technol., 58(6):802?822.H.
Baayen, H. Van Halteren, and F. Tweedie.
1996.Outside the cave of shadows: Using syntactic an-notation to enhance authorship attribution.
Lit-erary and Linguistic Computing, 11(3):121.H.
Baayen, H. van Halteren, A. Neijt, andF.
Tweedie.
2002.
An experiment in authorshipattribution.
In 6th JADT.
Citeseer.A.
Bain.
1887.
English Composition and Rhetoric:Intellectual elements of style.
D. Appleton andcompany.S.
Bird, R. Dale, B.J.
Dorr, B. Gibson, M.T.
Joseph,M.Y.
Kan, D. Lee, B. Powley, D.R.
Radev, andY.F.
Tan.
2008.
The acl anthology referencecorpus: A reference dataset for bibliographic re-search in computational linguistics.
In Proc.of the 6th International Conference on LanguageResources and Evaluation Conference (LREC08),pages 1755?1759.J.
Burrows.
2002.
Delta: A measure of stylistic dif-ference and a guide to likely authorship.
Literaryand Linguistic Computing, 17(3):267?287.Samuel W. K. Chan, Lawrence Y. L. Cheung, andMickey W. C. Chong.
2010.
Tree topological fea-tures for unlexicalized parsing.
In Proceedings ofthe 23rd International Conference on Computa-tional Linguistics: Posters, COLING ?10, pages117?125, Stroudsburg, PA, USA.
Association forComputational Linguistics.Michael Collins and Nigel Duffy.
2002.
New rankingalgorithms for parsing and tagging: kernels overdiscrete structures, and the voted perceptron.
InProceedings of the 40th Annual Meeting on Asso-ciation for Computational Linguistics, ACL ?02,pages 263?270, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.J.
Diederich, J. Kindermann, E. Leopold, andG.
Paass.
2003.
Authorship attribution withsupport vector machines.
Applied Intelligence,19(1):109?123.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh,Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIB-LINEAR: A library for large linear classification.Journal of Machine Learning Research, 9:1871?1874.Antonion Miranda Garcia and Javier Calle Mar-tin.
2007.
Function words in authorship attribu-tion studies.
Literary and Linguistic Computing,22(1):49?66.Graeme Hirst and Olga Feiguina.
2007.
Bigrams ofsyntactic labels for authorship discrimination ofshort texts.
Literary and Linguistic Computing,22(4):405?417.D.
L. Hoover.
2004.
Testing burrow?s delta.
Literaryand Linguistic Computing, 19(4):453?475.J.
Houvardas and E. Stamatatos.
2006.
N-gram fea-ture selection for author identification.
In Proc.of the 12th International Conference on ArtificialIntelligence: Methodology, Systems and Applica-tions, volume 4183 of LNCS, pages 77?86, Varna,Bulgaria.
Springer.Aravind K. Joshi.
1992.
Statistical language mod-eling.
In Proceedings of a Workshop Held at Har-riman, New York, February 23-26, 1992.
Associa-tion for Computational Linguistics.S.
Kemper.
1987.
Life-span changes in syntacticcomplexity.
Journal of gerontology, 42(3):323.Vlado Keselj, Fuchun Peng, Nick Cercone, andCalvin Thomas.
2003.
N-gram-based author pro-files for authorship attribution.
In Proc.
of the1531Pacific Association for Computational Linguistics,pages 255?264.M.
Koppel and J. Schler.
2003.
Exploiting stylisticidiosyncrasies for authorship attribution.
In Pro-ceedings of IJCAI, volume 3, pages 69?72.
Cite-seer.D.
Lin.
1995.
University of manitoba: descrip-tion of the pie system used for muc-6.
In Pro-ceedings of the 6th conference on Message under-standing, pages 113?126.
Association for Compu-tational Linguistics.D.
Lin.
1997.
Using syntactic dependency as localcontext to resolve word sense ambiguity.
In Pro-ceedings of the 35th Annual Meeting of the Asso-ciation for Computational Linguistics and EighthConference of the European Chapter of the Associ-ation for Computational Linguistics, pages 64?71.Association for Computational Linguistics.Kim Luyckx and Walter Daelemans.
2008.
Author-ship attribution and verification with many au-thors and limited data.
In COLING ?08, pages513?520.T.C.
Mendenhall.
1887.
The characteristic curves ofcomposition.
Science, ns-9(214S):237?246.Alessandro Moschitti.
2008.
Kernel methods, syntaxand semantics for relational text categorization.In Proceedings of the 17th ACM conference on In-formation and knowledge management, CIKM ?08,pages 253?262, New York, NY, USA.
ACM.Frederick Mosteller and David L. Wallace.
1984.
Ap-plied Bayesian and Classical Inference: The Caseof the Federalist Papers.
Springer-Verlag.Fuchun Peng, Dale Schuurmans, Shaojun Wang, andVlado Keselj.
2003.
Language independent au-thorship attribution using character level languagemodels.
In Proceedings of the tenth conference onEuropean chapter of the Association for Compu-tational Linguistics - Volume 1, EACL ?03, pages267?274, Stroudsburg, PA, USA.
Association forComputational Linguistics.S.
Petrov and D. Klein.
2007.
Improved inference forunlexicalized parsing.
In Proceedings of NAACLHLT 2007, pages 404?411.Daniele Pighin and Alessandro Moschitti.
2009.
Re-verse engineering of tree kernel feature spaces.
InProceedings of the 2009 Conference on Empiri-cal Methods in Natural Language Processing: Vol-ume 1 - Volume 1, EMNLP ?09, pages 111?120,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Emily Pitler and Ani Nenkova.
2008.
Revisitingreadability: a unified framework for predictingtext quality.
In Proceedings of the Conference onEmpirical Methods in Natural Language Process-ing, EMNLP ?08, pages 186?195, Stroudsburg, PA,USA.
Association for Computational Linguistics.Arthus Quinn.
1995.
Figures of Speech: 60 Ways ToTurn A Phrase.
Routledge.Sindhu Raghavan, Adriana Kovashka, and RaymondMooney.
2010.
Authorship attribution usingprobabilistic context-free grammars.
In Proceed-ings of the ACL 2010 Conference Short Papers,pages 38?42, Uppsala, Sweden.
Association forComputational Linguistics.Ruchita Sarawgi, Kailash Gajulapalli, and YejinChoi.
2011.
Gender attribution: tracing stylo-metric evidence beyond topic and genre.
In Pro-ceedings of the Fifteenth Conference on Compu-tational Natural Language Learning, CoNLL ?11,pages 78?86, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.K.T.
Shao.
1990.
Tree balance.
Systematic Biology,39(3):266.Efstathios Stamatatos, George Kokkinakis, andNikos Fakotakis.
2000.
Automatic text catego-rization in terms of genre and author.
Comput.Linguist., 26(4):471?495.E.
Stamatatos, N. Fakotakis, and G. Kokkinakis.2001.
Computer-based authorship attributionwithout lexical measures.
Computers and the Hu-manities, 35(2):193?214.E.
Stamatatos.
2006.
Ensemble-based author iden-tification using character n-grams.
ReCALL, page4146.W.
Strunk and E.B.
White.
2008.
The elements ofstyle.
Penguin Group USA.Sze-Meng Jojo Wong and Mark Dras.
2011.
Exploit-ing parse structures for native language identifica-tion.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,EMNLP ?11, pages 1600?1610, Stroudsburg, PA,USA.
Association for Computational Linguistics.Ying Zhao and Justin Zobel.
2005.
Effectiveand scalable authorship attribution using func-tion words.
In Proceedings of the Second Asiaconference on Asia Information Retrieval Technol-ogy, AIRS?05, pages 174?189, Berlin, Heidelberg.Springer-Verlag.Y.
Zhao and J. Zobel.
2007.
Searching with style:Authorship attribution in classic literature.
InProceedings of the thirtieth Australasian confer-ence on Computer science-Volume 62, pages 59?68.
Australian Computer Society, Inc.Rong Zheng, Jiexun Li, Hsinchun Chen, and ZanHuang.
2006.
A framework for authorship identi-fication of online messages: Writing-style features1532and classification techniques.
J.
Am.
Soc.
Inf.
Sci.Technol., 57(3):378?393.1533
