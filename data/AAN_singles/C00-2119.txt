Using a Broad-Coverage Parser for Word-Breaking in JapaneseHisami Suzuki, Chris Brockett and Gary KacmarcikMicrosoft ResearchOne Microsoft WayRedmond WA 98052 USA{ hisamis, chrisbkt, garykac }@ microsoft.cornAbstractWe describe a method of word segmentation iJapanese in which a broad-coverage parser selectsthe best word sequence while producing a syntacticanalysis.
This technique is substantially differentfrom traditional statistics- or heuristics-basedmodels which attempt o select the best wordsequence before handing it to the syntacticcomponent.
By breaking up the task of finding thebest word sequence into the identification of words(in the word-breaking component) and the selectionof the best sequence (a by-product of parsing), wehave been able to simplify the task of eachcomponent and achieve high accuracy over a widevaricty of data.
Word-breaking accuracy of oursystem is currently around 97-98%.1.
IntroductionWord-breaking is an unavoidable and crucial firststep toward sentence analysis in Japanese.
In asequential model of word-breaking and syntacticanalysis without a feedback loop, the syntacticanalyzer assumes that the results of word-breakingare correct, so for the parse to be successful, theinput from the word-breaking component mustinclude all words needed for a desired syntacticanalysis.
Previous approaches to Japanese wordsegmentation have relied on heuristics- orstatistics-based models to find the single mostlikely sequence of words for a given string, whichcan then be passed to the syntactic omponent forfurther processing.
The most commonheuristics-based approach utilizes a connectivitymatrix between parts-of-speech and wordprobabilities.
The most likely analysis can beobtained by searching for the path with theminimum connective cost (Hisamitsu and Nitta1990), often supplemented by additional heuristicdevices such as the longest-string-match or theleast-number-of-bunsetsu (phrase).
Despite itspopularity, the connective cost method has a majordisadvantage in that hand-tuning is not onlylabor-intensive but also unsafe, since adjusting thecost for one string may cause another to break.Various heuristic (e.g.
Kurohashi and Nagao 1998)and statistical (e.g.
Takeuchi and Matsumoto 1997)augmentations of the minimum connective costmethod have been proposed, bringingsegmentation accuracy up to around 98-99% (e.g.Kurohashi and Nagao 1998, Fuchi and Takagi1998).Fully stochastic language models (e.g.
Nagata1994), on the other hand, do not allow such manualcost manipulation and precisely for that reason,improvements in segmentation accuracy are harderto achieve.
Attaining a high accuracy using fullystochastic methods is particularly difficult forJapanese due to the prevalence of orthographicvariants (a word can be spelled in many differentways by combining different character sets), whichexacerbates the sparse data problem.
As a result,the performance of stochastic models is usually notas good as the heuristics-based language models.The best accuracy reported for statistical methodsto date is around 95% (e.g.
Nagata 1994).Our approach contrasts with the previousapproaches in that the word-breaking componentitself does not perform the selection of the bestsegmentation analysis at all.
Instead, theword-breaker returns all possible words that spanthe given string in a word lattice, and the best wordsequence is determined by applying the syntacticrules for building parse trees.
In other words, thereis no task of selecting the best segmentation per se;the best word-breaking analysis is merely aconcomitant of the best syntactic parse.
Wedemonstrate hat a robust, broad-coverage parsercan be implemented irectly on a word latticeinput and can be used to resolve word-breakingambiguities effectively without adverseperformance effects.
A similar model ofword-breaking is reported for the problem ofChinese word segmentation (Wu and Jiang 1998),but the amount of ambiguity that exists in the word822lattice is nmch larger in Japanese, which requires adifferent treatment.
In the l'ollowing, we firstdescribe the word-breaker and the parser in moredetail (Section 2); we then report the results ofsegmentation accuracy (Section 3) and the resultsof related experinaents a sessing the effects of thesegmentation ambiguities in the word lattice toparsing (Section 4).
In Conclusion, we discussimplications for future research.2.
Using a broad-coverage parser forword-breakingThe word-breaking and syntactic componentsdiscussed in the current study are implelnentedwithin a broad-coverage, multi-purpose naturalhmguage understanding system being developed atMicrosoft Research, whose ultimate goal is toachieve deep Selnantic understanding of naturallanguage I.
A detailed escription of the system isfound in Heidom (in press).
Though we focus onthe word-breaking and syntactic components inthis paper, the syntactic analysis is by no meansthe final goal of the system; rather, a parse tree isconsidered to be an approxilnate first step toward amore useful meaning representation.
We also aimat being truly broad-coverage, i.e., returning usefulanalyses irrespective of the genre or the subjectmatter of the input text, be it a newspaper articlc ora piece of e-mail.
For the proposed model ofword-breaking to work well, the followingproperties of the parser are particularly important.?
The bottom-up chart parser creates syntacticanalyses by building incrementally arger phrasesfl'om individual words and phrases (Jensen et al1993).
The analyses that span the entire inputstring are the complete analyses, and the wordsused in that analysis constitutes the word-breakinganalysis for the string.
Incorrect words returned bythe word-breaker are filtered out by the syntacticrules, and will not make it into the final completeparse.?
All the grammar rules, written in theformalism of Augmented Phrase StructureGrammar (lteidorn 1975), are binary, a featurecrucial for dealing with free word-order andi Japanese is one of the seven languages underdevelopment in our lab, along with Chinese, English,French, German, Korean and Spanish.missing constituents (Jensen 1987).
Not only hasthe rule formalism proven to be indispensable forparsing a wide range of English texts, it is all tilemore critical 1'o1 parsing Japanese, as the freeword-order and missing constituents are the normfor Japanese sentences.?
There is very little semantic dependency in thegrammar rules, which is essential if the grammar isto be domain-independent.
However, the grammarrules are elaborately conditioned on morphologicaland syntactic l'eatums, enabling much finer-grainedparsing analyses than just relying on a smallnumber of basic parts-of speech (POS).
This givesthe grammar the power to disambiguate multipleword analyses in the input lattice.13ecause we do not utilize semantic information,we perforln no selnantically motivated attachlnentof phrases during parsing.
Instead, we parse theminto a default analysis, which can then be expandedand disambiguatcd at later stages of processingusing a large semantic knowledge base(Richardson 1997, Richardson et al 1998).
One ofthe goals o1' Ihis paper is to show that the syntacticinformation alone can resolve the ambiguities inthe word lattice sufficiently well to select the bestbreaking analysis in the absence of elaboratesemantic information.
Figure 1 (see Appendix)shows the default attachment of the relative clauseto the closest NP.
Though this structure may besemantically implausible, the word-breakinganalysis is correct.The word-breaking colnponent of out" system isdescribed in detail in Kacmarcik et al (2000).
Forthe lmrpose of robust parsing, the component isexpected to solve the following two problems:?
Lemmatization: Find possible words in theinput text using a dictionary and its inflectionalmorphology, and return the dictionary entry forms(lemmas).
Note that multiple lemmas are oftenpossible for a given inflected form (e.g.
surfaceform /o,~z -(- (kalte) could be an inflected form ofthe verbs /9~3 (kau "buy"), /0~o (katu "win")or/o,~ (karu "trim"), in which case all these formsmust be returned.
The dictionary the word-breakeruses has about 70,000 unique entries.?
Orthography norlnalization: Identify andnorlnalize orthographic variants.
This is anon-trivial task in Japanese, as words can bespelled using any colnbination of the tout" chanmter8234.3 Parser precisionAn initial concern in implementing the presentmodel was that parsing ambiguous input mightproliferate syntactic analyses.
In theory, thenumber of analyses might grow exponentially asthe input sentence length increased, making thereliable ranking of parse results unmanageable.
Inpractice, however, pathological proliferation ofsyntactic analyses is not a problem s. Figure 4tallies the average number of parses obtained inrelation to sentence l ngth for all successful parsesin the 5,000-sentence t st corpus (corpus A inTable 1).
There were 4,121 successful parses in thecorpus, corresponding to 82.42% coverage.
FromFigure 4, we can see that the number of parsesdoes increase as the sentence grows longer, but theincrement is linear and the slope is very moderate.Even in the highest-scoring range, the meannumber of parses is only 2.17.
Averaged over allsentence lengths, about 68% of the successfullyparsed sentences receive only one parse, and 22%receive two parses.
Only about 10% of sentencesreceive more than 2 analyses.
From these resultswe conclude that the overgeneration f parse treesis not a practical concern within our approach.3"6 2E==t1-10 11- 21- 31- 41- 51- 61- 71- 81- 91- >10120 30 40 50 60 70 80 90 100sentence length (in char)Figure 4.
Average number ol'parses for corpus A(5,000 sentences)4.4 PerformanceA second potential concern was performance:would the increased number of records in the chartcause unacceptable degradation of system speed?5 A similar observation is made by Charniak et al(forthcoming), who find that the number ot' final parsescaused by additional POS tags is far less than thetheoretical worst case in reality.This concern also proved unfounded in practice.
Inanother experiment, we evaluated the processingspeed of the system by measuring the time it takesper character in the input sentence (inmilliseconds) relative to the sentence length.
Theresults are given in Figure 5.
This figure showsthat the processing time per-character growsmoderately as the sentence grows longer, due tothe increased number of intermediate analysescreated during the parsing.
But the increase islinear, and we interpret these results as indicatingthat our approach is fully viable and realistic interms of processing speed, and robust against inputsentence length.
The current average parsing timefor our 15,000-sentence corpus (with averagesentence length of 49.02 characters) is 23.09sentences per second on a Dell 550MHz PentiumIII machine with 512MB of RAM.1.51.41.31.21.110.90.80.715 25 35 45 55 65 75 85 95 105 115 125 135sentence length (in char)Figure 5.
Processing speed on a 15,000-sentence corpus5.
ConclusionWe have shown that a practical, broad-coverageparser can be implemented without requiring theword-breaking component to return a singlesegmentation a alysis, and that it can at the sametime achieve high accuracy in POS-labeledword-breaking.
Separating the tasks of wordident~/'l'cation a d best sequence selection offersflexibility in enhancing both recall and precisionwithout sacrificing either at the cost of the other.Our results show that morphological nd syntacticinformation alone can resolve most word-breakingambiguities.
Nonetheless, some ambiguitiesrequire semantic and contextual information.
Forexample, the following sentence allows two parsescorresponding to two word-breaking analyses, ofwhich the first is semantically preferred:826(1) ocha-ni haitte-irtt arukaroidotea-in contain-ASP alkaloid"the alkaloid contained in lea"(2) ocha-ni-ha itte-iru arukatwidotea-in-TOP go-ASP alkaloid?
?
the alkaloid that has gone to the tea"Likewise, the sentence below allows two differentinterpretations of the morpheme de, either as alocative marker (1) or as a copula (2).
Bothinterpretations are syntactically and semanticallywflid; only contextual information can resolve theambiguity.
(1) minen-ha isuraeru-de arunext year-TOP Israel-LOC be-held"It will be held in Israel next year".
(2) rainen-ha isuraeru de-arttnext year-TOP Israel be-PP, ES"It will be Israel next year".In both these sentences, we create syntactic treesfor all syntactically valid interpretations, leavingthe ambiguity intact.
Such ambiguities can only beresolved with semantic and contextual informationeventually made available by higher processingcomponents.
This will be Ihe focus of our ongoingrese.arclt.AcknowledgementsWe: would like to thank Mari Bmnson and KazukoRobertshaw for annotating corpora for targetword-breaking and POS tagging.
We also thankthe anonymous reviewers and the members of theMSR NLP group for their comments on the earlierversion of the paper.ReferencesCharniak, Eugene, Glenn Carroll, John Adcock, AntonyCassandra, Yoshihiko Gotoh, Jeremy Katz, MichaelLittmaa, and John McCann.
Forthcoming.
Taggers l'orparsers.
To appear in Artificial Intelligence.Fuchi, Takeshi and Shinichiro Takagi.
1998.
JapaneseMorphological Analyzer Using Word Co-Occurrence-JTAG-.
Proceeding of ACL-COLING: 409-413.Gamon, Michael, Carmen Lozano, Jessie Pinkham andTom Reutter.
1997.
Practical Experience withGrammar Sharing in Multilingual NLP.
Jill Burstcinand Chmdia Leacock (eds.
), From Research toCommercial Applications: Making NLP Work inPractice (Proceedings of a Workshop Sponsored bythe Association for Computational Linguistics).pp.49-56.Heidorn, George.
1975.
Attgmented Phrase StructureGrammars.
In B.L.
Webber and R.C.
Schank (eds.
),Theoretical Issues in Natural Language Processing.ACL 1975: 1-5.Heidorn, George.
In press.
Intelligent WritingAssistance.
To appear in Robert Dale, Hermann Moisland Harold Seiners (eds.
), lfandbook of NaturalLanguage Processing.
Chapter 8.Hisamitsu, T. and Y. Nitta.
1990.
MorphologicalAnalysis by Minimum Connective-Cost Method.Technical Report, SIGNLC 90-8.
IEICE pp.17-24 (inJapanese).Jensen, Karen.
1987.
Binary Rules and Non-BinaryTrees: Breaking Down the Concept o1' PhraseStructure.
In Alexis Manasler-Ramer (ed.
),Mathematics of Language.
Amsterdam: JohnBenjamins Publishing.
pp.65-86.Jensen, Karen, George E. Hektorn and Stephen D.Richardson (eds.).
1993.
Natural LanguageProcessing: The PLNLP approach.
Kluwer: Boston.Kacmareik, Gary, Chris Brockett and Hisami St, zuki.2000.
Robust Segmentation of Japanese Text into al,attice for Parsing.
Proceedings of COLING 2000.Kurohashi, Sadao and Makoto Nagao.
1998.
Building aJapanese Parsed Corpus While hnproving the ParsingSystem.
First LREC Proceedings: 719-724.Murakami, J. and S. Sagayama.
1992.
Hidden MarkovModel Applied to Morphological Analysis.
lPSJ 3:161 - 162 (in Japanese).Nagata, Masaaki.
1994.
A Stochastic JapaneseMorphological Analyzer Using a Forward-DPBackward-A* N-Best Search Algorithm.
Proceedingso1' COLING '94:201-207.Richardson, Stephen D. 1997.
Determining Similarityand Inferring Relatkms in a Lexical Knowledge Base.Ph.D.
dissertation.
The City University of New York.Richardson, Stephen D., William B. Dolan and LucyVanderwende.
1998.
MindNet: acquiring andstructuring semantic information f l 'om text.Proceedings of COLING-ACL OS: 1098-1102.Taket,chi, Koichi and Yuji Matsumoto.
1997.
HMMParameter Learning for Japanese MorphologicalAnalyzer.
IPSJ: 38-3 (in Japanese).Wu, Andi and Zixin Jiang.
1998.
Word Segmentation inSentence Analysis.
Technical Report, MSR-TR-99-10.Microsoft Reseamh.827Appendix"(It) has been annoyed by the successive interventions by the neighboring country".~b~O<" VERB1~t~ NOUN1~t~ VERB2:::::::: O< ~ VERB3::: : : : : : : : : : : : : :  ~ NOUN2: : : : : : : : : : : : : : : : : : : : : : : :  ~ NOUN3: : : : : : : : : : : : : : : : : : : : : : : :  ~ PRONI: : : : : : : : : : : : : : : : : : : : : : : :  ~ POSPI: : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ NOUN4: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  \[C~ NOUN5: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  \[: VERB4: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  \[C POSP2: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ VERB5: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~NOUN6: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ VERB~: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ IJl: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ POSP3: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ VERB7: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ Ia2: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ POSP4: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~NOUN7: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ VERB8: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  ~ CONJI: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  b%~NOUN8: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  L%~ VERB9DECL I  NP I  NP2  RELCL I  VERB1*  "~%O?
"NOUN2*  "~"PP I  POSP I*  "~"NOUN4*  "=~\]~"PP2 POSP2*  "\[C"VERBS* "~&~"AUXPI  VERB9*  " ~ "CHAR1 "o".
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(successive)(neighboring country)(GEN)(intervention)(by)(annoyed)(be)Figure 1.
Example of ambiguous attachment.
RELCL I  can syntactically modify either NOUN2 or NOUNa.NOUN4 (non-local attachment) is the semantically correct choice.
Shown above the parse tree is theinput word lattice returned from the word-breaker.94~-~l~:{~,,~,W~\[7_-tk~bvEl,~Teo "Classical Thai literature is based on tradition and history".F ITTED1 NP INP2NOUN1*  "9-1" i~  ~ "  (classical Thai literature)PPI POSP i* " \ [~"  (TOP IC)UP3 NOUn2 * "{~"  (tradition)posp2 * ,, k" ,, (and)NP4 NOUN3 * "~"  (history)PP2 POSP3 * "17-" (on)VPI  VERB1*  ":6~'-5t VC"  (based)AUXPI  VERB2 * ,, I, xT~ ,, (be)CHAR1 " o "Figure 2.
Example of an incomplete parse with correct word-breaking results.828
