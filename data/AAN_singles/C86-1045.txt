Categor ia l  Un i f i ca t ion  Grammars*Hans UszkoreitArtificial Intell igence CenterSRI International andCenter for the Study of Languageand Information at Stanford UniversityAbstractCategorial unification grammars (CUGs) embodythe essential properties of both unification and categorialgrammar formalisms.
Their efficient and uniform way ofencoding linguistic knowledge in well-understood andwidely used representations makes them attractive forcomputational applications and for linguistic research.In this paper, the basic concepts of CUGs and simpleexamples of their application will be presented.
It will beargued that the strategies and potentials of CUGs justifytheir further exploration i  the wider context of researchon unification grammars.
Approaches to selectedlinguistic phenomena such as long-distancedependencies, adjuncts, word order, and extrapositionare discussed.0.
IntroductionThe work on merging strategies from unificationgrammars and categorial grammars has its origins inseveral research efforst that have been pursued inparallel.
One of them is the grammar development onthe PATR system (Shieber et al, 1983; Shieber, 1984) atSRI.
For quite a while now I have been using theexcellent facilities of PATR for the design and testing ofexperimental\[ CUGs.
Such grammars currently run ontwo PATR implementations: Stuart Shieber's Zetalispversion on the Symbolics 3600 and Lauri Karttunen'sInterlisp-D w:rsion on the XEROX 1109.
The work onCUGs has influenced our efforts to develop a largerPATR grammar, and will do so even more in the future.On the theoretical side, this work is part of ongoingresearch on such topics as word order variation,modification, and German syntax within projects at SRIand CSLI (Stanford University).The structure of the paper eflects the diverse natureof the enterprise.
In the first section, I will introduce thebasic notions of CUGs and demonstrate them throughexamples in PATR notation.
The second sectiondiscusses the motivation for this work and some of itstheoretical implications.
The third section sketches alinguistically motivated CUG framework with a stronglexical syntax that accomodates word order variation.The paper concludes with a brief discussion of possibleCUG approaches tolong-distance d pendencies.1.
Basic Notions of Categorial UnificationGrammars1.2.
Unif ication Grammars  and CategorialGrammarsBoth terms, unification grammar (UG) andcategorial grammar (CG), stand for whole families ofrelated grammar formalisms whose basic notions arewidely known.l Yet, for the characterization f the classof formalisms I want to discuss, it will be useful to reviewthe most central concepts of both UG and CG.Unification grammar formalisms employ complexfeature structures as their syntactic representations.These structures encode partial information aboutconstituents.
Either term or graph unification is utilizedas the main operation for checking, propagating, andmerging of the information in these complexrepresentations.
Most unification grammars also use thecomplex feature structures for the linking of syntacticand semantic information.In traditional categorial grammars, all informationabout possible syntactic ombinations of constituents isencoded in their categories.
Those grammars allow onlybinary combinations.
One of the two combinedconstituents, the functor, encodes the combinationfuntion, the other constituent serves as the argument tothis function.
Instead ot7 phrase structure rules, thegrammar contains one or, in some formalisms, twocombination rules that combine a functor and anargument by applying the function encoded in thefunctor to the argument constituent.
Most categorialgrammars only combine constituents whose terminalstrings concatenate in the input string, but this need notbe so.
In most categorial grammar formalisms, it isassumed that the syntactic functor-argument structurein the corresponding compositional semantics.187There are usually two types of grammaticalcategories in a categorial grammar, basic and derivedones.
Basic categories are just category symbols, derivedcategories are functions from one (derived or basic)category to another.
A derived category that encodes afunction from category A to category B might be writtenB/A if the functor combines with an argument to its rightor B~,  if it expects the argument to its left.
Thus, if weassume just two basic categories, N and S, then N/S, S/N,N\S, S\N, (S\N)/N, (N/S\(S\(N/N)), etc.
are also categories.Not all of these categories will ever occur in thederivation of sentences.
The set of actually occurringcategories depends on the lexical categories of thelanguage.Assume the following simple sample grammar:(2) Basic categories: N, Slexical categories: N (Paul, Peter)(S\N)fN (likes)The grammar is used for the sample derivation in (3):(3) Peter likes PaulN (S\N)fin NSkNSIt should be clear from my brief description that thedefining characteristics of unification grammar havenothing to do with the ones of categorial grammar.
Wewill see that the properties of both grammar typesactually complement each other quite wetl.1.2.
A Sample CUG in PATR Notat ionSince the first categorial unification grammars werewritten in the PATR formalism and tested on the PATRsystems implemented at SRI, and since PATR isespecially well suited for the emulation of othergrammar formalisms, I will use its notation.The representations in PATR are directed acyclicgraphs (DAGs) 2 .
Rules have two parts, a head and abody.
The head is a context-free rewrite rule and thebody is a DAG.
Here is an example, a simple rule thatforms a sentence by combining anoun phrase with a verbphrase.188(4) head XO -~ X1, X2body in unification otation<X0 cat> = S<X1 cat> = NP<X2cat> = VP<X1 agr> = <X2agr>body in graph notationxorS NPThe rule states that two constituents X1 and X2 cancombine to form a constituent X0 if the terminal stringcovered by X1 immediately precedes the terminal stringof X2 and if the DAGs of X0, X1, and X2 unify with theX0, X1, and X2 subgraphs of the rule body, respectively.I will now show the most straight-forward encodingof a categorial grammar in this notation.
There are twotypes of constituent graphs.
Constituent graphs for basiccategories are of the following form:(5)N SOf course, there might be more features associated withthe constituent:(6)/oe 7N S Finite 3 SgDerived constituents have graphs of the following form:(7)arg(t0b) Backward Functional Application (BFA)value -~ functor argument< value > = < functor va l><argument> = <functor a rg><f lmctor  d i r> :--: Left.This is the graph associated with the VP likes Paul:in graph notation:(8),.
/~  Left /~  agrca~//pers / form cat/pers~nu mS Finite N 3 SgIt corresponds to the derived-category s mboh(9)S \ Nform : Finite pers : 3num: Sg(10a) and (10b) are the rules that combine constituents.As in tradit ional categorial grammars,  two such rulessufice.
(10a) Forward Functional Application (FFA)value -~ functor argument<va lue> = <functorva l><argument> = <functorarg><functor  d i r> = Right.in graph notation:val u e~J -~~'~./ funct?
r l  .
~rguRightmentval u e ~- - J  J -~-~rg  u ment/LeftIf Backward Functional Application is used tocombine the constituents Peter and likes Paul, the resultis a finite sentence.However, if the same rule is applied to the identicalconstituents likes Paul and likes Paul, again a finitesentence is obtained.
'\]\['his is so because the graph forlikes Paul actually unifies with the value of arg in thesame graph.
This can be easily remedied by modifyingthe graph for the VP slightly.
By st ipulat ing that theargument must not have an unfilled argument  position,one can rule out derivcd categories as subject argumentstbr the VP:(II)/0o-i /?e?TumS Finite N 3 Sg1.3.
Extens ions  to the Basic Formal i smIn this subsection \[want to discuss very briefly a fewextensions of' the basic model that make it more suitablefor the encoding of natural- language rammars.
The firstone is the sorting of fimctors according to their ownsyntactic category.
This move might  be describedalternat ively as defining the type of a constituent asbeing defined by both a set of syntactic (and semantic)189attributes and a function from categories to categories.This function is also expressed as the value of anattribute.
For a basic category the value of the functionattribute is NIL.
The following graph is a simplifiedexample of a functor category (prenominal djective in alanguage with case and number agreement within theNP).~ ~/ ~ ~'~unctionca;~/ ~s: :m - -~grThe combination rules needaccordingly.
This is the modifiedfunctional application.to be changedrule of forwardvalue -~ functor argument<value> = <functor function val>< argument > = < functor function arg ><functor function dir> = Right.In a traditional categorial grammar, a derivedcategory is exhaustively described by the argument andvalue categories.
But often, syntacticians want to makemore fine grained distinctions.
An example is VPmodification.
In a traditional categorial grammar, twodifferent VP modifiers, lets say an adverb and anadverbial clause, would receive the same translation.
(12) Peter called him angrilyN (S\N)fN N (S\N)/(S~q)(13) Peter called him at workN (S\N)/N N (S\N)/(S~aN)190But what should be the category for very?
If it receivesthe category ((S\N)\(S\N))/((S\N)\(S~N)) to allow thederivation of (14), the ungrammatical sentence (15) isalso permitted.
(14) Peter called him very angrilyN (S\N)/N N ((S\N)\(SLN))/ (S\N)/(S~X\[)((S\N)\(S~N'))(15) *Peter called him veryN (S\N)/N N ((S\N)\(S~))/((S\N)\(S\N))at work(S\N)/(S~)If functor categories are permitted to carry featuresof their own that are not necessarily bound to to anyfeatures of their argument and value categories, thisproblem disappears.
Adverbs and adverbial clauses couldreceive different features even if their categories encodethe same combination function.Another solution to the problem involves theencoding of the difference in the value part of the functor.Yet this solution is not only unintuitive but alsocontradicts a linguistic generalization.
It is unintuitivebecause there is no difference in the distribution of theresulting VPs.
The only difference holds between themodifiers themselves.
The gene~:alization that is violatedby the encoding of the difference in the value subgraphsis the endocentricity of the VP.
The modified VP sharesall syntactic features with its head, the lower VP.
Yetthe feature that indicates the difference between adverbsand adverbial phrases could not be in both the argumentand the value parts of the functor, otherwise iterations ofthe two types of modifiers as they occur in the followingpair of sentences would be ruled out.
(16a) Peter called him very angrily at work.
(16b) Peter called him at work very angrily.Another augmentation is based on the PATRstrategy for linking syntax and semantics.
Mostgrammars written in PATR use the constituent graphsalso for encoding semantic information.
Everyconstituent has an attribute called trans or semantics.The value of this attribute contains minimally theinternal semantic fnnction-argument structure of theconstituent, but may also encode additional semanticinformation.
The separate encoding of the semanticsallows for a compositional semantics even in constructionin which syntactic and semantic structure divert as incertain raising constructions.
The following graph for aficticious prenominal adjective that was introducedearlier contains translation attributes for the functor,the argument and the value.
The meaning of theadjective is indicated by the atom Red.cat ~ / functi% ~ransAdjAcc ing ~._~gRedAt first glance, the lexical graphs--even the onesthat are used in the highly simplified examples--seem toexhibit an excessive degree of complexity andredundancy.
However, the lexical approach to syntax isbuilt on the assumption that the lexicon is structured.
Tocreate a lexicon that is structured according to linguisticgeneralizations, weintroduced lexical templates early onin the development of PATR.Templates are graphs that contain structure sharedby a class of lexical entries.
Lexical graphs can bepartially or fully defined in terms of templates, whichthemselves can be defined in terms of templates.
If atemplate name appeam in the definition of some graph,the graph is simply unified with the graph denoted by thetemplate.The next augmentation is already built into theformalism.
Categorial grammarians have recognized thelimitations of fimctional application as the sole mode ofcombining constituents for a long time.
One of theobvious extensions to classical categorial grammar wasthe utilization of functional composition as a furthercombination mode.
A good example of a categorialgrammar that employs both functional application andfunctional composition is Steedman (1985).
Forwardfunctional composition permits the followingcombination ofcategories:(21) A/B + B/C = A/CThe resulting category inherits the argument place for Cfrom the argument B/C.Neither Steedman's nor any other CG I am aware ofpermits functional composition i  its full generality.
Inorder to prevent overgeneration, functional compositionas well as other combination modes that are discussed bySteedman are restricted to apply to certain categoriesonly.
This somehow violates the spirit of a categorialgrammar.
Steedman's combination rules, for instance,are net universal.In CUG, functional composition is subsumed underfunctional application.
It is the functor category thatdetermines whether simple functional application, orfunctional composition, or either one may take place.Conjunction is a good case for demonstrating theversatility.Consider the following sentences: 3(22a) Peter andPaul like bananas.
(22b) Peter likes bananas and Paul likes oranges.
(22c) Peter likes and buys bananas.The conjunction and may combine two simpleargument categories (22a), two functors with one unfilledargument position (22b), or two functors with more thanone unfilled argument position (22c).
If the conjunctshave unfilled argument positions, the conjoined phraseneeds to inherit them through functional composition.The simplified lexical graph for and is given under (23).In order to avoid a thicket of crossing edges, I haveexpressed some of the relevant bindings by indices.191(23) c ~.. r (The most appealing feature of this way of utilizingfunctional composition is that no additional combinatorsare required.
No restriction on such a rule need to beformulated.
It is only the lexical entries for functors thateither demand, permit, or forbid functional composition.Extensions to the formalism that I haveexperimented with that cannot be discussed in the frameof this paper are the use of multiple stacks for leftwardand rightward arguments and the DCG-like encoding ofthe ordering positions in the graphs.
In Sections 3.
and4., I will discuss further extensions ofthe formalism andspecific linguistic analyses.
The following sectioncontains a summary of the motivations for working onand with CUG and the main objectives of this work.2.
Motivation and Theoretical implicationsBoth terms, unification grammar and categorialgrammar are used for classes of grammar formalisms, forindividual grammar formalisms, and finally forgrammars that are written in these formalisms.
Inaddition, they might also be used by linguists to denotelinguistic theories that are built around or on top of sucha formalism.
This is the type of terminologicaloverloading that linguists have learned to live with--orat least gotten accustomed to.As I indicated in the previous section, I considerCUG to stand for a family of grammar formalisms thatmight be described as the intersection of categorial and192unification grammar formalisms.
What has beenproposed so far is therefore not a new grammarformalism and even less a linguistic framework.The proposal is simply to further explore theusefulness and formal properties of subclasses of CUG.This proposal can be supported by a number of reasons.Both types of formalisms have clear advantages.Categorial grammars have been hailed for theirconceptual c arity and their potentials for l inking syntaxand semantics.
The fact that they have been around for along time and that they are currently enjoying arenaissance in the works of Steedman, Bach, Dowty, andmany others demonstrates their virtues.
Unificationgrammars are spreading last and lend themselves topowerfifl but efficient computer implementations.Traditionally, categorial grammars have beenlacking syntactic sophistication.
In a functor categorysuch as A/B, only domain and range of the function arespecified but nothing is said about bow they are related;how, for instance, the features of the argument influencethe features of the value.
The graph notation expressesthe relation between argument and value categoriesquite well; it is expressed in a set of bindings betweensubgraphs ofthe two categories.In the context of this discussion, some remarks are inorder on the specific role PATR has played for theexperiments with CUGs.
The philosophy behind thedevelopment of PATR has been to provide a tool forwriting, testing, and comparing grammars of verydifferent types in a powerful formalism withwell-understood formal properties and a well-definedsemantics (Shieber 1984).Thus PATR could be useful for writing grammars,designing rammar formalisms, and for exploring classesof such formalisms.
The work on exploring categorialunification formalisms has not only benefitted from thefeatures of PATR but it has in a way also influenced thedevelopment of the PATR formalism.
It was, forinstance, essential for the writing of categorialgrammars to allow category variables in the context-freephrase structure part of the rules.
How else could oneformulate the rules of functional application.
Theimplementation f this facility through Stuart Shieber,however, raised interesting problems in connection withthe prediction aspect of the Earley-parser.
OriginalEarley prediction works on category symbols.
An answerto these problems was presented by Shieber (1985) whoproposed to do Earley prediction on the basis of somefinite quotient of all constituent DAGs which can bespecified by the grammar writer.Another example for the influence of the CUG effortson the development of PATR is a new template notationintroduced by Lauri Karttunen in his Interlisp-D versionof PATR.
Since categorial grammars exhibit  anextensive embedding of categories within othercategories, it is useful to unify templates not only withthe whole lexical DAG but also with its categorialsubgraphs.
The @-notation permits this use of templates(Karttunen, 1986)33.
A CUG Grammar  Model that Aecomodates WordOrder Variat ionWorder order variation has always been one of thehardest problems for categorial grammars.
Functionalcomposition together with type-raising can be used toobtain all permutations of the sentences that aregenerated by a traditional categorial grammar.
Totallyfree word order does therefore not pose anunsurmountable problem to the categorial approach.
Aswith other types of grammar formalisms, it is semi-freeword order that is difficult o accommedate.GPSG, LFG, and FUG all have mechanisms forencoding ordering regularities.
Such a device does notexist in the categorial grammars that i am aware of.However, Uszkoreit (1985a,b) argues (on the basis ofdata fl'om German) for an application of l/nearprecedence rules to the valency list of syntactic functors.This approach presupposes that the valency list containsadjuncts as well as complements as the flmetor'ssyntactic arguments)The model can be summarized as follows.
Thelexicon lists uninstantiated ntries.
For functors, theseentries contain a set of thematic roles.
Theuninstantiated lexical entry may also state whetherthematic roles have to be filled, whether they may befilled more than once, and whether idiosyncraticproperties of the fnnetor predetermine the syntacticfeatures of certain syntactic arguments.There are three types of rules that instantiate l xicalentries: feature instantiation rules, valencyinstantiation rules, and order instantiation rules.An instantiated functor has an ordered valency listcontaining syntactic specifications of complements andadjuncts together with the appropriate semanticbindings.
The model can account for the interspersing ofcomplements and adjuncts as they occur in manylanguages including English.
The model can alsoaccount for right-extraposition phenomena.tTherefore, the valency list may constain adjunctsthat do not fill a thematic role of the functor but combinesemantically with some constituent inside a linearilypreceding member of the same valency listfiIn the proposed model, the dependency between theextraposed phrase and its antecendent is neitherestablished by functional application/composition n r byfeature passing.
It is assumed that there is a differentmatching process that combines the noncontiguousphrases.
A process of this kind is independently neededfor the matching of adjuncts with thematic roles that areembedded in the meaning of the functor:(26a) Tellme about French history.
(26b) Start in 1700.The year 1700 is obviously not the start time for thetelling.
(27a) His call was very urgent.
(27b) lie tried desperately from every phone booth oncampus.It is not try that supplies here the source role but theimplicit heme of try.
If the theme role is filled, everybodywould analyze the from PP as semantically belonging tothe theme of try:(28) He tried to call her desperately from every phonebooth on campus.I want to conclude this discussion with a remark onthe parsing problem connected with the proposed model.In older PATR Phrase-Structure grammars as well as inthe categorial PATR grammars, all graphs that may beconnected with a word in the input string are eitherretrieved from the lexicon or from a cache of ah'eady builtlexical graphs, or they are constructed on the spot fi'omthe \[exical entries through the morphology and throughlexical rules.For obvious reasons, this approach cannot be used inconjunction with the categorial model just proposed.
Ifall adjuncts are included in the valency list, and ifmoreover all acceptable linearizations are performed inthe extended lexicon, there is no upper bound on thenumber of acceptable lexieal graphs for functors.
Thismeans that lexical entries cannot be fully instantiatedwhen the word is recognized.
\]'hey need to beinstantiated incrementally as potential arguments areencountered.In Uszkoreit (1985b) it is argued that the orderedvalency lists of a functor admitted by the lexical\[nstantiation rules form a regular language.
\[f furtherresearch confirms this hypothesis, the incremental{nstantiation f valency lists could be performed throughsets of finite state machines.1934.
A Note on Long-d is tance  Dependenc ies  in CUGsIn Steedman's (1985) categorial grammars,long-distance dependencies are endcoded in thefunct ion-argument structure of categories, Thecategories that  form the path between filler and gap in aderivation tree all carry a valency slot for the filler.
Thisuniform encoding of both subeategorization andlong-distance dependencies in the argument  structure ofcategories seems at first glance superior to the HPSG orPATR approaches to long-distance dependencies, inwhich the two types of information are marked indifferent feature sets.
However, it turns out that theSteedman grammars have to mark the long-distancevalency slots in order to dist inguish them from othervalency slots.There could still be a justif ication for encoding thetwo types of dependencies in the same argument  stack.One might  loose important  nesting information byseparat ing the two types of slots.
However, I have not yetseen a convincing example of nesting constraints amongsubcategorization and long-distance dependencies.Therefore, I consider the question of the appropriateplace for encoding long-distance dependencies still open.A last remark on long-distance dependencies.
In aunification based system like PATR it is not trivial toensure that  gap information is passed up from onedaughter  const i tuent only when a rule is applied.
Thereare two ways to enforce this constraint.
The first oneinvolves a multipl ication of rules.
For a binary rule A--> B C, for instance, one could introduce three newrules, one of which does not do any gaP passing, anotherone the passing of a gap from B to A, and the third thepassing of a gap from C to A.PATR uses a little more elegant method which hasbeen first suggested by Fernando Pereira.
Two featuresare threaded through every tree, one of which carries agap up a tree, passing through all the constituents o theleft of the gap, and a second one that  is set to NIL if a gaphas been found and that  is then sent through all theconst ituents to the r ight of the gap, unifying it on theway with potential gaps.
It requires that informationabout the two special features be added to every rule.
InPATR a preprocessor f rules adds this information forall rules in which the grammar writer did not includeany gap threading information herself, e.g., for encodingisland constraints.In a CUG that  only contains two (or at least very?
few) rules, the first method of duplicating rules appearspreferrable over the gap threading approach.
Rules thatpropagate gap information might also include rules thatpermit parasitic gaps along the lines of Steedman's rulesof functional substitution.194ReferencesBar Hillel, Y.
(1964) Language and information.
Wesley, Reading,Mass.Johnson, M. (1986) "Fronting and the Internal structure of the VP inGerman."
ms. Stanford University.Karttunen, L. (1986) "D-PATR: A development environment forunification-based grammars."
in this volmneShieber, S. M., If.
Uszkoreit, F.C.N.
Pereira, J J .
Robinson, and M.Tyson (1983) "The Formalism and implementation f PA'PR-\[I "in: Research on Interactive hcqui~'ition and Use nf Knowledge.Artificial intelligence Center, SRI International.
~,lenlo Park,California.Shieber, S. (1984) "The Design of a Computer t, anguagc, tbrLinguistic Intbrmation."
in Shieber, S., L. Karttunen, and FPereh'a (eds.
), Notes fi'om the Unification Underground ACompilation ~f Papers on Unification.based GrammarFormalisms, Technical Note 327, SRI-lnternational, MenloPark, CalShieber, S. {1985) "Using Restriction to Extend Parsing AlgorithmsFor Complex Feature Based Formalisms," in: Proceedings of theACL I985.Steedman, M. (1985) "l)ependency and Coordination in theGrammar of Dutch and English."
Language 61: 523-568.Uszkoreit, H. (1982) "German Word Order in GPSG."
In I).Flickinger, M. Macken, and N. Wiegand (Eds.
), Proceedings ofthe First West Coast Conference on Formal Linguistics, StanfordUniversity, Stanford, California.Uszkoreit, H. (1985a) "Problematische Konstruktionen ffikontextfreie Phrasenstrukturgrammatiken des Deutschen."
inKlenk, U.
(Ed.)
Strukturen und Verfuhren in der maschinellenSprachverarbeitung, AQ-Vetlag, DudweilerUszkoreit, H. (1985b) "Linear Precedence in DiscontinuousConstituents."
paper presented at the Conference onDiscontinuous Constituency, July 1985, Chicago', Illinois, (toappear in Syntax and Semantics 201Uszkoreit, H. {1986) "Constraints on Order " CSLI Report 46,Stanford University (also to appear in Linguistics.
)Notes*The research for this paper was made possible through agift by theSystem l)evelopment Foundation.tFor an introduction to the family of unification grammar modelsrefer to Shieber (forthcmning).
A good introduction to the basicnotions ofcategorial grammar isBar \[tiliel (1964).2The PATti implementations that arc currently used at SR\[ actuallypermit cyc lic graphs.
:IRight-Node-Raising (RNR) which leads to sentences a : Peter likesand Paul buys bananas will be neglected here (although RNR is anattractive lopic for catcgorial grammarians and one of my grammars~ctnally handles many cases of RNR.
)IAn even lilt)re general notation can })e used that does notdistinguish between root templates and subgraph templates.
As longas template names are marked by some typographic onvention.could be freely used wherever agraph is described.~The version of t!le linear precedence rule component proposed b~Uszkoreit {1982.
1986) is {\tlI> compatible with this approach.
The.,proposal permit> the formalization of partially free word order as \[tresults fl'om the interaction of potentially conflicting orderingprinciples and as it probably occurs to some degree in all naturallanguages6Sag (1985) proposes a mechanism for IIPSG that allows thesyntactic binding of an extraposcd phrase to a complement oradjunct slot of a complement or adjunct.
However, this approach istoo restricted.
Although there is a strong tendency toonly extraposecomplements and adiunets of top-level complements and adjuncts,there is certainly no such constraint in languages like English orGerman.
The following sentence could not be handled since theextraposed relative clause modifies an adjunct of the subject.Petitions from those people were considered who had not filed acomplaint before.7Mark Johnson (1986) has worked out a quasi-categorial solution ofthis phenomenon in the framework of HPSG.
