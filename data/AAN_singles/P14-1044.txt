Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 468?478,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsA Robust Approach to Aligning Heterogeneous Lexical ResourcesMohammad Taher Pilehvar and Roberto NavigliDepartment of Computer ScienceSapienza University of Rome{pilehvar,navigli}@di.uniroma1.itAbstractLexical resource alignment has been anactive field of research over the lastdecade.
However, prior methods for align-ing lexical resources have been either spe-cific to a particular pair of resources, orheavily dependent on the availability ofhand-crafted alignment data for the pair ofresources to be aligned.
Here we present aunified approach that can be applied to anarbitrary pair of lexical resources, includ-ing machine-readable dictionaries with nonetwork structure.
Our approach leveragesa similarity measure that enables the struc-tural comparison of senses across lexicalresources, achieving state-of-the-art per-formance on the task of aligning WordNetto three different collaborative resources:Wikipedia, Wiktionary and OmegaWiki.1 IntroductionLexical resources are repositories of machine-readable knowledge that can be used in virtuallyany Natural Language Processing task.
Notableexamples are WordNet, Wikipedia and, more re-cently, collaboratively-curated resources such asOmegaWiki and Wiktionary (Hovy et al, 2013).On the one hand, these resources are heteroge-neous in design, structure and content, but, onthe other hand, they often provide complemen-tary knowledge which we would like to see inte-grated.
Given the large scale this intrinsic issuecan only be addressed automatically, by means oflexical resource alignment algorithms.
Owing toits ability to bring together features like multilin-guality and increasing coverage, over the past fewyears resource alignment has proven beneficial toa wide spectrum of tasks, such as Semantic Pars-ing (Shi and Mihalcea, 2005), Semantic Role La-beling (Palmer et al, 2010), and Word Sense Dis-ambiguation (Navigli and Ponzetto, 2012).Nevertheless, when it comes to aligning textualdefinitions in different resources, the lexical ap-proach (Ruiz-Casado et al, 2005; de Melo andWeikum, 2010; Henrich et al, 2011) falls shortbecause of the potential use of totally differentwordings to define the same concept.
Deeper ap-proaches leverage semantic similarity to go be-yond the surface realization of definitions (Nav-igli, 2006; Meyer and Gurevych, 2011; Niemannand Gurevych, 2011).
While providing good re-sults in general, these approaches fail when thedefinitions of a given word are not of adequatequality and expressiveness to be distinguishablefrom one another.
When a lexical resource can beviewed as a semantic graph, as with WordNet orWikipedia, this limit can be overcome by meansof alignment algorithms that exploit the networkstructure to determine the similarity of conceptpairs.
However, not all lexical resources provideexplicit semantic relations between concepts and,hence, machine-readable dictionaries like Wik-tionary have first to be transformed into semanticgraphs before such graph-based approaches can beapplied to them.
To do this, recent work has pro-posed graph construction by monosemous linking,where a concept is linked to all the concepts asso-ciated with the monosemous words in its definition(Matuschek and Gurevych, 2013).
However, thisalignment method still involves tuning of parame-ters which are highly dependent on the character-istics of the generated graphs and, hence, requireshand-crafted sense alignments for the specific pairof resources to be aligned, a task which has to bereplicated every time the resources are updated.In this paper we propose a unified approachto aligning arbitrary pairs of lexical resourceswhich is independent of their specific structure.Thanks to a novel modeling of the sense entriesand an effective ontologization algorithm, our ap-proach also fares well when resources lack rela-tional structure or pair-specific training data is ab-sent, meaning that it is applicable to arbitrary pairs468without adaptation.
We report state-of-the-art per-formance when aligning WordNet to Wikipedia,OmegaWiki and Wiktionary.2 Resource AlignmentPreliminaries.
Our approach for aligning lexi-cal resources exploits the graph structure of eachresource.
Therefore, we assume that a lexicalresource L can be represented as an undirectedgraph G = (V,E) where V is the set of nodes,i.e., the concepts defined in the resource, andE is the set of undirected edges, i.e., seman-tic relations between concepts.
Each conceptc ?
V is associated with a set of lexicalizationsLG(c) = {w1, w2, ..., wn}.
For instance, Word-Net can be readily represented as an undirectedgraph G whose nodes are synsets and edges aremodeled after the relations between synsets de-fined in WordNet (e.g., hypernymy, meronymy,etc.
), and LGis the mapping between each synsetnode and the set of synonyms which express theconcept.
However, other resources such as Wik-tionary do not provide semantic relations betweenconcepts and, therefore, have first to be trans-formed into semantic networks before they can bealigned using our alignment algorithm.
We ex-plain in Section 3 how a semi-structured resourcewhich does not exhibit a graph structure can betransformed into a semantic network.Alignment algorithm.
Given a pair of lexicalresources L1and L2, we align each concept in L1by mapping it to its corresponding concept(s) inthe target lexicon L2.
Algorithm 1 formalizes thealignment process: the algorithm takes as input thesemantic graphs G1and G2corresponding to thetwo resources, as explained above, and producesas output an alignment in the form of a set A ofconcept pairs.
The algorithm iterates over all con-cepts c1?
V1and, for each of them, obtains the setof concepts C ?
V2, which can be considered asalignment candidates for c1(line 3).
For a conceptc1, alignment candidates in G2usually consist ofevery concept c2?
V2that shares at least one lex-icalization with c1in the same part of speech tag,i.e., LG1(c1) ?
LG2(c2) 6= ?
(Reiter et al, 2008;Meyer and Gurevych, 2011).
Once the set of targetcandidates C for a source concept c1is obtained,the alignment task can be cast as that of identifyingthose concepts in C to which c1should be aligned.To do this, the algorithm calculates the similaritybetween c1and each c2?
C (line 5).
If their sim-ilarity score exceeds a certain value denoted by ?Algorithm 1 Lexical Resource AlignerInput: graphs H = (VH, EH), G1= (V1, E1) and G2=(V2, E2), the similarity threshold ?, and the combinationparameter ?Output: A, the set of all aligned concept pairs1: A?
?2: for each concept c1?
V13: C ?
getCandidates(c1, V2)4: for each concept c2?
C5: sim?
calculateSimilarity(H,G1, G2, c1, c2, ?
)6: if sim > ?
then7: A?
A ?
{(c1, c2)}8: return A(line 6), the two concepts c1and c2are aligned andthe pair (c1, c2) is added to A (line 7).Different resource alignment techniques usuallyvary in the way they compute the similarity of apair of concepts across two resources (line 5 in Al-gorithm 1).
In the following, we present our novelapproach for measuring the similarity of conceptpairs.2.1 Measuring the Similarity of ConceptsFigure 1 illustrates the procedure underlying ourcross-resource concept similarity measurementtechnique.
As can be seen, the approach consistsof two main components: definitional similarityand structural similarity.
Each of these compo-nents gets, as its input, a pair of concepts belong-ing to two different semantic networks and pro-duces a similarity score.
These two scores are thencombined into an overall score (part (e) of Figure1) which quantifies the semantic similarity of thetwo input concepts c1and c2.The definitional similarity component computesthe similarity of two concepts in terms of the simi-larity of their definitions, a method that has alsobeen used in previous work for aligning lexicalresources (Niemann and Gurevych, 2011; Hen-rich et al, 2012).
In spite of its simplicity, themere calculation of the similarity of concept defi-nitions provides a strong baseline, especially forcases where the definitional texts for a pair ofconcepts to be aligned are lexically similar, yetdistinguishable from the other definitions.
How-ever, as mentioned in the introduction, definitionsimilarity-based techniques fail at identifying thecorrect alignments in cases where different word-ings are used or definitions are not of high qual-ity.
The structural similarity component, instead,is a novel graph-based similarity measurementtechnique which calculates the similarity betweena pair of concepts across the semantic networksof the two resources by leveraging the semantic469Figure 1: The process of measuring the similarity of a pair of concepts across two resources.
The methodconsists of two components: definitional and structural similarities, each measuring a similarity score forthe given concept pair.
The two scores are combined by means of parameter ?
in the last stage.structure of those networks.
This component goesbeyond the surface realization of concepts, thusproviding a deeper measure of concept similarity.The two components share the same backbone(parts (b) and (d) of Figure 1), but differ in somestages (parts (a) and (c) in Figure 1).
In the follow-ing, we explain all the stages involved in the twocomponents (gray blocks in the figure).2.1.1 Semantic signature generationThe aim of this stage is to model a given conceptor set of concepts through a vectorial semanticrepresentation, which we refer to as the seman-tic signature of the input.
We utilized Person-alized PageRank (Haveliwala, 2002, PPR), a ran-dom walk graph algorithm, for calculating seman-tic signatures.
The original PageRank (PR) algo-rithm (Brin and Page, 1998) computes, for a givengraph, a single vector wherein each node is as-sociated with a weight denoting its structural im-portance in that graph.
PPR is a variation of PRwhere the computation is biased towards a set ofinitial nodes in order to capture the notion of im-portance with respect to those particular nodes.PPR has been previously used in a wide variety oftasks such as definition similarity-based resourcealignment (Niemann and Gurevych, 2011), textualsemantic similarity (Hughes and Ramage, 2007;Pilehvar et al, 2013), Word Sense Disambigua-tion (Agirre and Soroa, 2009; Faralli and Navigli,2012) and semantic text categorization (Navigli etal., 2011).
When applied to a semantic graph byinitializing the random walks from a set of con-cepts (nodes), PPR yields a vector in which eachconcept is associated with a weight denoting itssemantic relevance to the initial concepts.Formally, we first represent a semantic networkconsisting of N concepts as a row-stochastic tran-sition matrix M ?
RN?N.
The cell (i, j) in thematrix denotes the probability of moving from aconcept i to j in the graph: 0 if no edge existsfrom i to j and 1/degree(i) otherwise.
Then thePPR vector, hence the semantic signature Svofvector v is the unique solution to the linear sys-tem: Sv= (1 ?
?
)v + ?MSv, where v is thepersonalization vector of size N in which all theprobability mass is put on the concepts for whicha semantic signature is to be computed and ?
is thedamping factor, which is usually set to 0.85 (Brinand Page, 1998).
We used the UKB1off-the-shelfimplementation of PPR.Definitional similarity signature.
In the defini-tional similarity component, the two concepts c1and c2are first represented by their correspondingdefinitions d1and d2in the respective resourcesL1and L2(Figure 1(a), top).
To improve expressive-ness, we follow Niemann and Gurevych (2011)and further extend diwith all the word forms asso-ciated with concept ciand its neighbours, i.e., theunion of all lexicalizations LGi(x) for all conceptsx ?
{c??
Vi: (c, c?)
?
Ei}?
{c}, where Eiis theset of edges in Gi.
In this component the person-alization vector viis set by uniformly distributingthe probability mass over the nodes correspond-ing to the senses of all the content words in theextended definition of diaccording to the senseinventory of a semantic network H .
We use thesame semantic graph H for computing the seman-tic signatures of both definitions.
Any semanticnetwork with a dense relational structure, provid-ing good coverage of the words appearing in thedefinitions, is a suitable candidate for H .
For thispurpose we used the WordNet (Fellbaum, 1998)graph which was further enriched by connecting1http://ixa2.si.ehu.es/ukb/470each concept to all the concepts appearing in itsdisambiguated gloss.2Structural similarity signature.
In the struc-tural similarity component (Figure 1(b), bottom),the semantic signature for each concept ciis com-puted by running the PPR algorithm on its corre-sponding graph Gi, hence a different Miis builtfor each of the two concepts.2.1.2 Signature unificationAs mentioned earlier, semantic signatures are vec-tors with dimension equal to the number of nodesin the semantic graph.
Since the structural similar-ity signatures Sv1and Sv2are calculated on differ-ent graphs and thus have different dimensions, weneed to make them comparable by unifying them.We therefore propose an approach (part (c) of Fig-ure 1) that finds a common ground between thetwo signatures: to this end we consider all theconcepts associated with monosemous words inthe two signatures as landmarks and restrict thetwo signatures exclusively to those common con-cepts.
Leveraging monosemous words as bridgesbetween two signatures is a particularly reliabletechnique as typically a significant portion of allwords in a lexicon are monosemous.3Formally, let IG(w) be an inventory mappingfunction that maps a term w to the set of con-cepts which are expressed by w in graph G. Then,given two signatures Sv1and Sv2, computed onthe respective graphs G1and G2, we first obtainthe setM of words that are monosemous accord-ing to both semantic networks, i.e., M = {w :|IG1(w)|=1 ?
|IG2(w)|=1}.
We then transformeach of the two signatures Sviinto a new sub-signature S?viwhose dimension is |M|: the kthcomponent of S?vicorresponds to the weight in Sviof the only concept ofwkin IGi(wk).
As an exam-ple, assume we are given two semantic signaturescomputed for two concepts in WordNet and Wik-tionary.
Also, consider the noun tradeoff whichis monosemous according to both these resources.Then, each of the two unified sub-signatures willcontain a component whose weight is determinedby the weight of the only concept associated withtradeoffnin the corresponding semantic signature.As a result of the unification process, we obtaina pair of equally-sized semantic signatures withcomparable components.2http://wordnet.princeton.edu3For instance, we calculated that more than 80% of thewords in WordNet are monosemous, with over 60% of all thesynsets containing at least one of them.2.1.3 Signature comparisonHaving at hand the semantic signatures for thetwo input concepts, we proceed to comparingthem (part (d) in Figure 1).
We leverage a non-parametric measure proposed by Pilehvar et al(2013) which first transforms each signature intoa list of sorted elements and then calculates thesimilarity on the basis of the average ranking ofelements across the two lists:Sim(Sv1,Sv2) =?|T |i=1(r1i+ r2i)?1?|T |i=1(2i)?1(1)where T is the intersection of all concepts withnon-zero probability in the two signatures and rjiis the rank of the ithentry in the jthsorted list.The denominator is a normalization factor to guar-antee a maximum value of one.
The method pe-nalizes the differences in the higher rankings morethan it does for the lower ones.
The measure wasshown to outperform the conventional cosine dis-tance when comparing different semantic signa-tures in multiple textual similarity tasks (Pilehvaret al, 2013).2.1.4 Score combinationFinally (part (e) of Figure 1), we calculate theoverall similarity between two concepts as a lin-ear combination of their definitional and struc-tural similarities: ?
Simdef(Sv1,Sv2) + (1 ??)Simstr(Sv1,Sv2).
In Section 4.2.1, we explainhow we set, in our experiments, the values of ?and the similarity threshold ?
(cf.
alignment algo-rithm in Section 2).3 Lexical Resource OntologizationIn Section 2, we presented our approach for align-ing lexical resources.
However, the approach as-sumes that the input resources can be viewed assemantic networks, which seems to limit its ap-plicability to structured resources only.
In or-der to address this issue and hence generalize ouralignment approach to any given lexical resource,we propose a method for transforming a givenmachine-readable dictionary into a semantic net-work, a process we refer to as ontologization.Our ontologization algorithm takes as input alexicon L and outputs a semantic graph G =(V,E) where, as already defined in Section 2, V isthe set of concepts in L and E is the set of seman-tic relations between these concepts.
Introducingrelational links into a lexicon can be achieved indifferent ways.
A first option is to extract binary471relations between pairs of words from raw text.Both words in these relations, however, shouldbe disambiguated according to the given lexicon(Pantel and Pennacchiotti, 2008), making the taskparticularly prone to mistakes due to the high num-ber of possible sense pairings.Here, we take an alternative approach whichrequires disambiguation on the target side only,hence reducing the size of the search space sig-nificantly.
We first create the empty undirectedgraph GL= (V,E) such that V is the set of con-cepts in L and E = ?.
For each source con-cept c ?
V we create a bag of content wordsW = {w1, .
.
.
, wn} which includes all the con-tent words in its definition d and, if available, ad-ditional related words obtained from lexicon rela-tions (e.g., synonyms in Wiktionary).
The prob-lem is then cast as a disambiguation task whosegoal is to identify the intended sense of each wordwi?
W according to the sense inventory of L: ifwiis monosemous, i.e., |{IGL(wi)}| = 1, we con-nect our source concept c to the only sense cwiofwiand set E := E ?
{{c, cwi}}; else, wihas mul-tiple senses in L. In this latter case, we choose themost appropriate concept ci?
IGL(wi) by findingthe maximal similarity between the definition of cand the definitions of each sense of wi.
To do this,we apply our definitional similarity measure intro-duced in Section 2.1.
Having found the intendedsense c?wiof wi, we add the edge {c, c?wi} to E.As a result of this procedure, we obtain a semanticgraph representation G for the lexicon L.As an example, consider the 4thsense of thenoun cone in Wiktionary (i.e., cone4n) which is de-fined as ?The fruit of a conifer?.
The definitioncontains two content words: fruitnand conifern.The latter word is monosemous in Wiktionary,hence we directly connect cone4nto the only senseof conifern.
The noun fruit, however, has 5 sensesin Wiktionary.
We therefore measure the similar-ity between the definition of cone4nand all the 5definitions of fruit and introduce a link from cone4nto the sense of fruit which yields the maximalsimilarity value (defined as ?
(botany) The seed-bearing part of a plant...?
).4 ExperimentsLexical resources.
To enable a comparison withthe state of the art, we followed Matuschekand Gurevych (2013) and performed an align-ment of WordNet synsets (WN) to three differentcollaboratively-constructed resources: Wikipedia(WP), Wiktionary (WT), and OmegaWiki (OW).We utilized the DKPro software (Zesch et al,2008; Gurevych et al, 2012) to access the infor-mation in the foregoing three resources.
For WP,WT, OW we used the dump versions 20090822,20131002, and 20131115, respectively.Evaluation measures.
We followed previouswork (Navigli and Ponzetto, 2012; Matuschek andGurevych, 2013) and evaluated the alignment per-formance in terms of four measures: precision, re-call, F1, and accuracy.
Precision is the fraction ofcorrect alignment judgments returned by the sys-tem and recall is the fraction of alignment judg-ments in the gold standard dataset that are cor-rectly returned by the system.
F1 is the harmonicmean of precision and recall.
We also report re-sults for accuracy which, in addition to true posi-tives, takes into account true negatives, i.e., pairswhich are correctly judged as unaligned.Lexicons and semantic graphs.
Here, we de-scribe how the four semantic graphs for our fourlexical resources (i.e., WN, WP, WT, OW) wereconstructed.
As mentioned in Section 2.1.1, webuild the WN graph by including all the synsetsand semantic relations defined in WordNet (e.g.,hypernymy and meronymy) and further populatethe relation set by connecting a synset to all theother synsets that appear in its disambiguatedgloss.
For WP, we used the graph provided byMatuschek and Gurevych (2013), constructed bydirectly connecting an article (concept) to all thehyperlinks in its first paragraph, together with thecategory links.
Our WN and WP graphs have 118Kand 2.8M nodes, respectively, with the averagenode degree being roughly 9 in both resources.The other two resources, i.e., WT and OW, donot provide a reliable network of semantic rela-tions, therefore we used our ontologization ap-proach to construct their corresponding semanticgraphs.
We report, in the following subsection,the experiments carried out to assess the accuracyof our ontologization method, together with thestatistics of the obtained graphs for WT and OW.4.1 Ontologization ExperimentsFor ontologizing WT and OW, the bag of con-tent words W is given by the content words insense definitions and, if available, additional re-lated words obtained from lexicon relations (seeSection 3).
In WT, both of these are in word sur-face form and hence had to be disambiguated.
ForOW, however, the encoded relations, though rela-472Source Type WT OWDefinitionAmbiguous 76.6% 50.7%Unambiguous 18.3% 32.9%RelationAmbiguous 2.8% -Unambiguous 2.3% 16.4%Total number of edges 2.1M 255KTable 1: The statistics of the generated graphsfor WT and OW.
We report the distribution ofthe edges across types (i.e., ambiguous and un-ambiguous) and sources (i.e., definitions and rela-tions) from which candidate words were obtained.tively small in number, are already disambiguatedand, therefore, the ontologization was just per-formed on the definition?s content words.The resulting graphs for WT and OW contain430K and 48K nodes, respectively, each provid-ing more than 95% coverage of concepts, with theaverage node degree being around 10 for both re-sources.
We present in Table 1, for WT and OW,the total number of edges together with their dis-tribution across types (i.e., ambiguous and unam-biguous) and sources (i.e., definitions and rela-tions) from which candidate words were obtained.The edges obtained from unambiguous entriesare essentially sense disambiguated on both sideswhereas those obtained from ambiguous termsare a result of our similarity-based disambigua-tion.
Hence, given that a large portion of edgescame from ambiguous words (see Table 1), wecarried out an experiment to evaluate the accu-racy of our disambiguation method.
To this end,we took as our benchmark the dataset providedby Meyer and Gurevych (2010) for evaluating re-lation disambiguation in WT.
The dataset con-tains 394 manually-disambiguated relations.
Wecompared our similarity-based disambiguation ap-proach against the state of the art on this dataset,i.e., the WKTWSD system, which is a WT rela-tion disambiguation algorithm based on a series ofrules (Meyer and Gurevych, 2012b).Table 2 shows the performance of our disam-biguation method, together with that of WKTWSD,in terms of Precision (P), Recall (R), F1, and ac-curacy.
The ?Human?
row corresponds to theinter-rater F1 and accuracy scores, i.e., the upper-bound performance on this dataset, as calculatedby Meyer and Gurevych (2010).
As can be seen,our method proves to be very accurate, surpassingthe performance of the WKTWSD system in termsof precision, F1, and accuracy.
This is particularlyApproach P R F1 AWKTWSD 0.780 0.800 0.790 0.840Our method 0.852 0.767 0.807 0.857Human - - 0.890 0.910Table 2: The performance of relation disam-biguation for our similarity-based disambiguationmethod, as well as for the WKTWSD system.interesting as the WKTWSD system uses a rule-based technique specific to relation disambigua-tion in WT, whereas our method is resource inde-pendent and can be applied to arbitrary words inthe definition of any concept.
We also note that thegraph constructed by Meyer and Gurevych (2010)had an average node degree of around 1.More recently, Matuschek and Gurevych (2013)leveraged monosemous linking (cf.
Section 5) inorder to create denser semantic graphs for OW andWT.
Our approach, however, thanks to the con-nections obtained through ambiguous words, canprovide graphs with significantly higher coverage.As an example, for WT, Matuschek and Gurevych(2013) generated a graph where around 30% ofthe nodes were in isolation, whereas this numberdrops to around 5% in our corresponding graph.These results show that our ontologization ap-proach can be used to obtain dense semantic graphrepresentations of lexical resources, while at thesame time preserving a high level of accuracy.Now that all the four resources are transformedinto semantic graphs, we move to our alignmentexperiments.4.2 Alignment Experiments4.2.1 Experimental setupDatasets.
As our benchmark we tested onthe gold standard datasets used in Matuschekand Gurevych (2013) for three alignmenttasks: WordNet-Wikipedia (WN-WP), WordNet-Wiktionary (WN-WT), and WordNet-OmegaWiki(WN-OW).
However, the dataset for WN-OW wasoriginally built for the German language and,hence, was missing many English OW conceptsthat could be considered as candidate targetalignments.
We therefore fixed the dataset for theEnglish language and reproduced the performanceof previous work on the new dataset.
The threedatasets contained 320, 484, and 315 WN conceptsthat were manually mapped to their correspondingconcepts in WP, WT, and OW, respectively.473Approach Training typeWN-WP WN-WT WN-OWP R F1 A P R F1 A P R F1 ASB Cross-val.
0.780 0.780 0.780 0.950 0.670 0.650 0.660 0.910 0.749 0.691 0.716 0.886DWSA Tuning on subset 0.750 0.670 0.710 0.930 0.680 0.270 0.390 0.890 0.651 0.372 0.473 0.830SB+DWSA Cross-val.
+ tuning 0.750 0.870 0.810 0.950 0.680 0.710 0.690 0.920 0.794 0.688 0.735 0.898SemAlignUnsupervised 0.709 0.929 0.805 0.943 0.642 0.799 0.712 0.923 0.664 0.761 0.709 0.872Tuning on subset 0.877 0.792 0.833 0.960 0.672 0.799 0.730 0.930 0.750 0.717 0.733 0.893Cross-val.
0.852 0.835 0.840 0.965 0.680 0.769 0.722 0.931 0.778 0.725 0.749 0.900Tuning on WN-WP - - - - 0.754 0.627 0.684 0.931 0.825 0.584 0.684 0.889Tuning on WN-WT 0.738 0.934 0.824 0.950 - - - - 0.805 0.677 0.736 0.900Tuning on WN-OW 0.744 0.925 0.824 0.950 0.684 0.766 0.723 0.930 - - - -Table 3: The performance of different systems on the task of aligning WordNet to Wikipedia (WN-WP),Wiktionary (WN-WT), and OmegaWiki (WN-OW) in terms of Precision (P), Recall (R), F1, and Accuracy(A).
We present results for different configurations of our system (SemAlign), together with the state ofthe art in definition similarity-based alignment approaches (SB) and the best configuration of the state-of-the-art graph-based system, Dijkstra-WSA (Matuschek and Gurevych, 2013, DWSA).Configurations.
Recall from Section 2 that ourresource alignment technique has two parameters:the similarity threshold ?
and the combination pa-rameter ?, both defined in [0, 1].
We performedexperiments with three different configurations:?
Unsupervised, where the two parameters areset to their middle values (i.e., 0.5), hence,no tuning is performed for either of the pa-rameters.
In this case, both the definitionaland structural similarity scores are treatedas equally important and two concepts arealigned if their overall similarity exceeds themiddle point of the similarity scale.?
Tuning, where we follow Matuschek andGurevych (2013) and tune the parameters ona subset of the dataset comprising 100 items.?
Cross-validation, where a 5-fold cross vali-dation is carried out to find the optimal valuesfor the parameters, a technique used in mostof the recent alignment methods (Niemannand Gurevych, 2011; Meyer and Gurevych,2012a; Matuschek and Gurevych, 2013).4.2.2 ResultsWe show in Table 3 the alignment performance ofdifferent systems on the task of aligning WN-WP,WN-WT, and WN-OW in terms of Precision (P), Re-call (R), F1, and Accuracy.
The SB system corre-sponds to the state-of-the-art definition similarityapproaches for WN-WP (Niemann and Gurevych,2011), WN-WT (Meyer and Gurevych, 2011), andWN-OW (Gurevych et al, 2012).
DWSA standsfor Dijkstra-WSA, the state-of-the-art graph-basedalignment approach of Matuschek and Gurevych(2013).
The authors also provided results forSB+Dijkstra-WSA, a hybrid system where DWSAwas tuned for high precision and, in the case whenno alignment target could be found, the algorithmfell back on SB judgments.
We also show the re-sults for this system as SB+DWSA in the table.For our approach (SemAlign) we show the re-sults of six different runs each corresponding to adifferent setting.
The first three (middle part of thetable) correspond to the results obtained with thethree configurations of SemAlign: unsupervised,with tuning on subset, and cross-validation (seeSection 4.2.1).
In addition to these, we performedexperiments where the two parameters of SemA-lign were tuned on pair-independent training data,i.e., a training dataset for a pair of resources dif-ferent from the one being aligned.
For this setting,we used the whole dataset of the corresponding re-source pair to tune the two parameters of our sys-tem.
We show the results for this setting in thebottom part of the table (last three lines).The main feature worth remarking upon is theconsistency in the results across different resourcepairs: the unsupervised system gains the best re-call among the three configurations (with the im-provement over SB+DWSA being always statisti-cally significant4) whereas tuning, both on a subsetor through cross-validation, consistently leads tothe best performance in terms of F1 and accuracy(with the latter being statistically significant withrespect to SB+DWSA on WN-WP and WN-WT).Moreover, the unsupervised system proves to bevery robust inasmuch as it provides competitiveresults on all the three datasets, while it surpassesthe performance of SB+DWSA on WN-WT.
This4All significance tests are done using z-test at p < 0.05.474ApproachWN-WP WN-WT WN-OWP R F1 A P R F1 A P R F1 ADijkstra-WSA 0.750 0.670 0.710 0.930 0.680 0.270 0.390 0.890 0.651 0.372 0.473 0.830SemAlignstr0.877 0.788 0.830 0.959 0.604 0.643 0.623 0.907 0.654 0.602 0.627 0.853Table 4: Performance of SemAlign when using only the structural similarity component (SemAlignstr)compared to the state-of-the-art graph-based alignment approach, Dijkstra-WSA (Matuschek andGurevych, 2013) for our three resource pairs: WordNet to Wikipedia (WN-WP), Wiktionary (WN-WT),and OmegaWiki (WN-OW).is particularly interesting as the latter system in-volves tuning of several parameters, whereas Se-mAlign, in its unsupervised configuration, doesnot need any training data nor does it involve anytuning.
In addition, as can be seen in the table,SemAlign benefits from pair-independent trainingdata in most cases across the three resource pairswith performance surpassing that of SB+DWSA, asystem which is dependent on pair-specific train-ing data.
The consistency in the performance ofSemAlign in its different configurations and acrossdifferent resource pairs indicates its robustnessand shows that our system can be utilized effec-tively for aligning any pair of lexical resources, ir-respective of their structure or availability of train-ing data.The system performance is generally higher onthe alignment task for WP compared to WT andOW.
We attribute this difference to the dictionarynature of the latter two, where sense distinctionsare more fine-grained, as opposed to the relativelyconcrete concepts in the WP encyclopedia.4.3 Similarity Measure AnalysisWe explained in Section 2.1 that our concept sim-ilarity measure consists of two components: thedefinitional and the structural similarities.
Mea-suring the similarity of two concepts in terms oftheir definitions has been investigated in previ-ous work (Niemann and Gurevych, 2011; Hen-rich et al, 2012).
The structural similarity compo-nent of our approach, however, is novel, but at thesame time one of the very few measures which en-ables the computation of the similarity of conceptsacross two resources directly and independently ofthe similarity of their definitions.
A comparableapproach is the Dijkstra-WSA proposed by Ma-tuschek and Gurevych (2013) which, as also men-tioned earlier in the Introduction, first connects thetwo resources?
graphs by leveraging monosemouslinking and then aligns two concepts across thetwo graphs on the basis of their shortest distance.To gain more insight into the effectiveness of ourstructural similarity measure in comparison to theDijkstra-WSA method, we carried out an experi-ment where our alignment system used only thestructural similarity component, a variant of oursystem we refer to as SemAlignstr.
Both systems(i.e., SemAlignstrand Dijkstra-WSA) were tunedon 100-item subsets of the corresponding datasets.We show in Table 4 the performance of the twosystems on our three datasets.
As can be seen inthe table, SemAlignstrconsistently improves overDijkstra-WSA according to recall, F1 and accu-racy with all the differences in recall and accu-racy being statistically significant (p < 0.05).
Theimprovement is especially noticeable for pairs in-volving either WT or OW where, thanks to the rel-atively denser semantic graphs obtained by meansof our ontologization technique, the gap in F1 isabout 0.23 (WN-WT) and 0.15 (WN-OW).In addition, as we mentioned earlier, for WN-WPwe used the same graph as that of Dijkstra-WSA,since both WN and WP provide a full-fledged se-mantic network and thus neither needed to beontologized.
Therefore, the considerable perfor-mance improvement over Dijkstra-WSA on thisresource pair shows the effectiveness of our novelconcept similarity measure independently of theunderlying semantic network.5 Related WorkResource ontologization.
Having lexical re-sources represented as semantic networks ishighly beneficial.
A good example is WordNet,which has been exploited as a semantic networkin dozens of NLP tasks (Fellbaum, 1998).
A re-cent prominent case is Wikipedia (Medelyan etal., 2009; Hovy et al, 2013) which, thanks toits inter-article hyperlink structure, provides a richbackbone for structuring additional information(Auer et al, 2007; Suchanek et al, 2008; Moroand Navigli, 2013; Flati et al, 2014).
How-ever, there are many large-scale resources, suchas Wiktionary for instance, which by their verynature are not in the form of a graph.
This is475usually the case with machine-readable dictionar-ies, where structuring the resource involves thearduous task of connecting lexicographic sensesby means of semantic relations.
Surprisingly,despite their vast potential, little research hasbeen conducted on the automatic ontologization ofcollaboratively-constructed dictionaries like Wik-tionary and OmegaWiki.
Meyer and Gurevych(2012a) and Matuschek and Gurevych (2013) pro-vided approaches for building graph representa-tions of Wiktionary and OmegaWiki.
The result-ing graphs, however, were either sparse or had aconsiderable portion of the nodes left in isolation.Our approach, in contrast, aims at transforming alexical resource into a full-fledged semantic net-work, hence providing a denser graph with mostof its nodes connected.Resource alignment.
Aligning lexical resourceshas been a very active field of research in thelast decade.
One of the main objectives in thisarea has been to enrich existing ontologies bymeans of complementary information from otherresources.
As a matter of fact, most efforts havebeen concentrated on aligning the de facto com-munity standard sense inventory, i.e.
WordNet, toother resources.
These include: the Roget?s the-saurus and Longman Dictionary of ContemporaryEnglish (Kwong, 1998), FrameNet (Laparra andRigau, 2009), VerbNet (Shi and Mihalcea, 2005)or domain-specific terminologies such as the Uni-fied Medical Language System (Burgun and Bo-denreider, 2001).
More recently, the growthof collaboratively-constructed resources has seenthe development of alignment approaches withWikipedia (Ruiz-Casado et al, 2005; Auer et al,2007; Suchanek et al, 2008; Reiter et al, 2008;Navigli and Ponzetto, 2012), Wiktionary (Meyerand Gurevych, 2011) and OmegaWiki (Gurevychet al, 2012).
Last year Matuschek and Gurevych(2013) proposed Dijkstra-WSA, a graph-based ap-proach relying on shortest paths between twoconcepts when the two corresponding resourcesgraphs were combined by leveraging monosemouslinking.
Their method when backed off with otherdefinition similarity based approaches (Niemannand Gurevych, 2011; Meyer and Gurevych, 2011),achieved state-of-the-art results on the mapping ofWordNet to different collaboratively-constructedresources.
This approach, however, in addition tosetting the threshold for the definition similaritycomponent by means of cross validation, also re-quired other parameters to be tuned, such as theallowed path length (?)
and the maximum num-ber of edges in a graph.
The optimal value for the?
parameter varied from one resource pair to an-other, and even for a specific resource pair it hadto be tuned for each configuration.
This made theapproach dependent on the training data for thespecific pair of resources that were to be aligned.Instead of measuring the similarity of two con-cepts on the basis of their distance in the com-bined graph, our approach models each conceptthrough a rich vectorial representation we refer toas semantic signature and compares the two con-cepts in terms of the similarity of their semanticsignatures.
This rich representation leads to ourapproach having a good degree of robustness suchthat it can achieve competitive results even in theabsence of training data.
This enables our systemto be applied effectively for aligning new pairs ofresources for which no training data is available,with state-of-the-art performance.6 ConclusionsThis paper presents a unified approach for align-ing lexical resources.
Our method leveragesa novel similarity measure which enables a di-rect structural comparison of concepts across dif-ferent lexical resources.
Thanks to an effec-tive ontologization method, our alignment ap-proach can be applied to any pair of lexical re-sources independently of whether they providea full-fledged network structure.
We demon-strate that our approach achieves state-of-the-art performance on aligning WordNet to threecollaboratively-constructed resources with differ-ent characteristics, i.e., Wikipedia, Wiktionary,and OmegaWiki.
We also show that our approachis robust across its different configurations, evenwhen the training data is absent, enabling it to beused effectively for aligning new pairs of lexicalresources for which no resource-specific trainingdata is available.
In future work, we plan to ex-tend our concept similarity measure across differ-ent natural languages.
We release all our data athttp://lcl.uniroma1.it/semalign.AcknowledgmentsThe authors gratefully acknowledgethe support of the ERC StartingGrant MultiJEDI No.
259234.We would like to thank Michael Matuschek forproviding us with Wikipedia graphs and alignmentdatasets.476ReferencesEneko Agirre and Aitor Soroa.
2009.
PersonalizingPageRank for Word Sense Disambiguation.
In Pro-ceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 33?41, Athens, Greece.S?oren Auer, Christian Bizer, Georgi Kobilarov, JensLehmann, Richard Cyganiak, and Zachary Ive.2007.
DBpedia: A nucleus for a web of open data.In Proceedings of 6th International Semantic WebConference joint with 2nd Asian Semantic Web Con-ference (ISWC+ASWC 2007), pages 722?735, Bu-san, Korea.Sergey Brin and Michael Page.
1998.
Anatomy of alarge-scale hypertextual Web search engine.
In Pro-ceedings of the 7thConference on World Wide Web,pages 107?117, Brisbane, Australia.Anita Burgun and Olivier Bodenreider.
2001.
Compar-ing terms, concepts and semantic classes in WordNetand the Unified Medical Language System.
In Pro-ceedings of NAACL Workshop, WordNet and OtherLexical Resources: Applications, Extensions andCustomizations, pages 77?82, Pittsburgh, USA.Gerard de Melo and Gerhard Weikum.
2010.
Pro-viding multilingual, multimodal answers to lexicaldatabase queries.
In Proceedings of the SeventhInternational Conference on Language Resourcesand Evaluation (LREC?10), pages 348?355, Val-letta, Malta.Stefano Faralli and Roberto Navigli.
2012.
ANew Minimally-supervised Framework for DomainWord Sense Disambiguation.
In Proceedings ofthe 2012 Joint Conference on Empirical Meth-ods in Natural Language Processing and Compu-tational Natural Language Learning, pages 1411?1422, Jeju, Korea.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Database.
MIT Press, Cambridge, MA.Tiziano Flati, Daniele Vannella, Tommaso Pasini, andRoberto Navigli.
2014.
Two is bigger (and bet-ter) than one: the Wikipedia Bitaxonomy Project.In Proceedings of the 52nd Annual Meeting ofthe Association for Computational Linguistics (ACL2014), Baltimore, Maryland.Iryna Gurevych, Judith Eckle-Kohler, Silvana Hart-mann, Michael Matuschek, Christian M. Meyer, andChristian Wirth.
2012.
UBY - a large-scale uni-fied lexical-semantic resource based on LMF.
InProceedings of the 13th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 580?590, Avignon, France.Taher H. Haveliwala.
2002.
Topic-sensitive PageRank.In Proceedings of the 11th international conferenceon World Wide Web, pages 517?526, Hawaii, USA.Verena Henrich, Erhard Hinrichs, and Tatiana Vodola-zova.
2011.
Semi-automatic extension of GermaNetwith sense definitions from Wiktionary.
In Pro-ceedings of 5th Language & Technology Conference(LTC 2011), pages 126?130, Pozna, Poland.Verena Henrich, Erhard W. Hinrichs, and Klaus Sut-tner.
2012.
Automatically linking GermaNet toWikipedia for harvesting corpus examples for Ger-maNet senses.
In Journal for Language Technologyand Computational Linguistics (JLCL), 27(1):1?19.Eduard H. Hovy, Roberto Navigli, and Simone PaoloPonzetto.
2013.
Collaboratively built semi-structured content and Artificial Intelligence: Thestory so far.
Artificial Intelligence, 194:2?27.Thad Hughes and Daniel Ramage.
2007.
Lexical se-mantic relatedness with random graph walks.
InProceedings of the 2007 Joint Conference on Em-pirical Methods in Natural Language Processing,pages 581?589, Prague, Czech Republic.Oi Yee Kwong.
1998.
Aligning WordNet withadditional lexical resources.
In COLING-ACL98Workshop on Usage of WordNet in Natural Lan-guage Processing Systems, pages 73?79, Montreal,Canada.Egoitzand Laparra and German Rigau.
2009.
Inte-grating WordNet and FrameNet using a knowledge-based Word Sense Disambiguation algorithm.
InProceedings of Recent Advances in Natural Lan-guage Processing (RANLP09), pages 1?6, Borovets,Bulgaria.Michael Matuschek and Iryna Gurevych.
2013.Dijkstra-WSA: A graph-based approach to wordsense alignment.
Transactions of the Association forComputational Linguistics (TACL), 1:151?164.Olena Medelyan, David Milne, Catherine Legg, andIan H. Witten.
2009.
Mining meaning fromWikipedia.
International Journal of Human-Computer Studies, 67(9):716?754.Christian M. Meyer and Iryna Gurevych.
2010.
?worthits weight in gold or yet another resource?
; a com-parative study of Wiktionary, OpenThesaurus andGermaNet.
In Proceedings of the 11th InternationalConference on Computational Linguistics and Intel-ligent Text Processing, CICLing?10, pages 38?49,Iasi, Romania.Christian M. Meyer and Iryna Gurevych.
2011.
Whatpsycholinguists know about Chemistry: AligningWiktionary and WordNet for increased domain cov-erage.
In Proceedings of the 5th International JointConference on Natural Language Processing, pages883?892, Chiang Mai, Thailand.Christian M. Meyer and Iryna Gurevych.
2012a.
On-toWiktionary: Constructing an ontology from thecollaborative online dictionary Wiktionary.
In Semi-Automatic Ontology Development: Processes andResources, pages 131?161.
IGI Global.477Christian M. Meyer and Iryna Gurevych.
2012b.To exhibit is not to loiter: A multilingual, sense-disambiguated Wiktionary for measuring verb sim-ilarity.
In Proceedings of the 24th InternationalConference on Computational Linguistics (COLING2012), pages 1763?1780, Mumbai, India.Andrea Moro and Roberto Navigli.
2013.
Integratingsyntactic and semantic analysis into the Open Infor-mation Extraction paradigm.
In Proceedings of the23rdInternational Joint Conference on Artificial In-telligence (IJCAI 2013), pages 2148?2154, Beijing,China.Roberto Navigli and Simone Paolo Ponzetto.
2012.BabelNet: The automatic construction, evaluationand application of a wide-coverage multilingual se-mantic network.
Artificial Intelligence, 193:217?250.Roberto Navigli, Stefano Faralli, Aitor Soroa, Oierde Lacalle, and Eneko Agirre.
2011.
Two birdswith one stone: Learning semantic models for textcategorization and Word Sense Disambiguation.
InProceedings of the 20th ACM Conference on Infor-mation and Knowledge Management (CIKM), pages2317?2320, Glasgow, UK.Roberto Navigli.
2006.
Meaningful clustering ofsenses helps boost word sense disambiguation per-formance.
In Proceedings of the 44th Annual Meet-ing of the Association for Computational Linguis-tics joint with the 21st International Conference onComputational Linguistics (COLING-ACL 2006),pages 105?112, Sydney, Australia.Elisabeth Niemann and Iryna Gurevych.
2011.
Thepeople?s web meets linguistic knowledge: Auto-matic sense alignment of Wikipedia and WordNet.In Proceedings of the Ninth International Confer-ence on Computational Semantics, pages 205?214,Oxford, United Kingdom.Martha Palmer, Daniel Gildea, and Nianwen Xue.2010.
Semantic Role Labeling.
Synthesis Lectureson Human Language Technologies.
Morgan & Clay-pool Publishers.Patrick Pantel and Marco Pennacchiotti.
2008.
Auto-matically harvesting and ontologizing semantic rela-tions.
In Proceedings of the 2008 Conference on On-tology Learning and Population: Bridging the GapBetween Text and Knowledge, pages 171?195, Am-sterdam, The Netherlands.Mohammad Taher Pilehvar, David Jurgens, andRoberto Navigli.
2013.
Align, Disambiguate andWalk: a Unified Approach for Measuring SemanticSimilarity.
In Proceedings of the 51st Annual Meet-ing of the Association for Computational Linguis-tics, pages 1341?1351, Sofia, Bulgaria.Nils Reiter, Matthias Hartung, and Anette Frank.2008.
A resource-poor approach for linking ontol-ogy classes to Wikipedia articles.
In Johan Bos andRodolfo Delmonte, editors, Semantics in Text Pro-cessing, volume 1 of Research in Computational Se-mantics, pages 381?387.
College Publications, Lon-don, England.Maria Ruiz-Casado, Enrique Alfonseca, and PabloCastells.
2005.
Automatic assignment of Wikipediaencyclopedic entries to WordNet synsets.
In Pro-ceedings of the Third International Conference onAdvances in Web Intelligence, pages 380?386, Lodz,Poland.Lei Shi and Rada Mihalcea.
2005.
Putting pieces to-gether: Combining FrameNet, VerbNet and Word-Net for robust semantic parsing.
In Proceedings ofthe 6th International Conference on ComputationalLinguistics and Intelligent Text Processing, pages100?111, Mexico City, Mexico.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2008.
Yago: A large ontology fromWikipedia and WordNet.
Journal of Web Semantics,6(3):203?217.Torsten Zesch, Christof M?uller, and Iryna Gurevych.2008.
Using Wiktionary for computing semantic re-latedness.
In Proceedings of the 23rd national con-ference on Artificial intelligence - Volume 2, pages861?866, Chicago, Illinois.478
