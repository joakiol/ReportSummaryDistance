Mining the Web for Relations between Digital Devices using a ProbabilisticMaximum Margin ModelOksana YakhnenkoIowa State UniversityAmes, IA, 50010oksayakh@cs.iastate.eduBarbara RosarioIntel ResearchSanta Clara, CA, 95054barbara.rosario@intel.comAbstractSearching and reading the Web is one of theprincipal methods used to seek out infor-mation to resolve problems about technol-ogy in general and digital devices in partic-ular.
This paper addresses the problem oftext mining in the digital devices domain.
Inparticular, we address the task of detectingsemantic relations between digital devices inthe text of Web pages.
We use a Na?
?ve Bayesmodel trained to maximize the margin andcompare its performance with several othercomparable methods.
We construct a noveldataset which consists of segments of textextracted from the Web, where each segmentcontains pairs of devices.
We also proposea novel, inexpensive and very effective wayof getting people to label text data using aWeb service, the Mechanical Turk.
Our re-sults show that the maximum margin modelconsistently outperforms the other methods.1 IntroductionIn the digital home domain, home networksare moving beyond the common infrastructureof routers and wireless access points to includeapplication-oriented devices like network attachedstorage, Internet telephones (VOIP), digital videorecorders (e.g., Tivo), media players, entertainmentPCs, home automation, and networked photo print-ers.
There is an ongoing challenge associated withdomestic network design, technology education, de-vice setup, repair, and tuning.
In this digital homesetting, searching the Web is one of the principlemethods used to seek out information and to resolveproblems about technology in general and about dig-ital devices in particular (Bly et al, 2006).This paper addresses the problem of automatictext mining in the digital networks domain.
Under-standing the relations between entities in natural lan-guage sentences is a crucial step toward the goal oftext mining.
We address the task of identifying andextracting the sentences from Web pages which ex-pressed a relation between two given digital devicesin contrast to sentences in which these devices co-occur.As an example, consider a user who is lookingfor information on digital video recorders (DVR),in particular, on how she can use a DVR with aPC.
This user will not be satisfied with finding Webpages that simply mention these devices (such asthe many products catalogs or shopping sites), butrather, the user is interested in retrieving and read-ing only the Web pages in which a specific relationbetween the two devices is expressed.
The user isinterested to learn that, for example, ?Any modernWindows PC can be used for DVR duty?
or that it ispossible to transfer data from a DVR to a PC (?Youcan simply take out the HD from the DVR, hook it upto the PC, and copy the videos over to the PC?
).1The specific task addressed in this paper is the fol-lowing: given a pair of devices, search the Web andextract only the sentences in which the devices areactually involved in an activity or a relation in theretrieved Web pages.Note that we do not attempt to identify the type1In italic are real sentences extracted from Web pages.273of relationship between devices but rather we clas-sify sentences into whether the relation or activityis present or not, and thus we frame the problem asa binary text classification problem.2 We proposea directed maximum margin probabilistic model tosolve this classification task.
Maximum marginprobabilistic models have received a lot of atten-tion in the machine learning and natural languageprocessing literature.
These models are trained tomaximize the smallest difference between the proba-bilities of the true class and the best alternative class.Approaches such as maximum margin Markov net-works (M3N) (Taskar et al, 2003) have been con-sidered in prediction problems in which the goal isto assign a label to each word in the sentence or adocument (such as part of speech tagging).
It hasalso been shown that training of Bayesian networksby maximizing the margin can result in better per-formance than M3N in a flat-table structured domain(simulated and UCI repository datasets) and a struc-tured prediction problem (protein secondary struc-ture) (Guo et al, 2005).
Given this background,we draw our attention to the application of maxi-mum margin probabilistic models to a text classifi-cation task.
We consider a directed model, wherethe parameters represent a probability distributionfor words in each class (maximum margin equiv-alent of a Na?
?ve Bayes).
We evaluate the maxi-mum margin model and compare its performancewith the equivalent joint likelihood model (Na?
?veBayes), conditional likelihood model (logistic re-gression) and support vector machines (SVM) on therelationship extraction task described above, as wellas several other classification methods.
Our resultsshow that the maximum margin Na?
?ve Bayes outper-forms the other methods in terms of classificationaccuracy.
To train such a model, manually labeleddata is required, which is usually slow and expensiveto acquire.
To address this, we propose a novel, inex-pensive and very effective way of getting people tolabel text data using the Mechanical Turk, an Ama-zon website3 where people earn ?micro-money?
for2Classifying or clustering the relation types would involvethe tricky task of defining the possible semantic relations be-tween devices as well as relations.
We plan of addressing thisin the future work, however, we believe that such binary distinc-tion is already quite useful for many tasks in this domain.3Available at http://www.mturk.comcompleting tasks which are simple for humans to ac-complish.The paper is organized as follows: in Section 2we discuss related work.
In Section 3 we reviewjoint likelihood and conditional likelihood modelsand maximum margin Na?
?ve Bayes.
In Section 4we describe the collection of the training sentences,and how Mechanical Turk was used to construct thelabels for the data.
Section 5 introduces the exper-imental setup and presents performance results foreach of the algorithms.
We analyze Na?
?ve Bayes,maximum margin Na?
?ve Bayes and logistic regres-sion in terms of the learned probability distributionsin Section 6.
Section 7 concludes with discussion.2 Related work2.1 Relation extractionThere has been a spate of work on relation extrac-tion in recent years.
However, many papers actuallyaddress the task of role extraction: (usually two) en-tities are identified and the relationship is impliedby the co-occurrence of these entities or by somelinguistic expression (Agichtein and Gravano, 2000;Zelenko et al, 2003).Several papers propose the use of machine learn-ing models and probabilistic models for relation ex-traction: Na?
?ve Bayes for the relation subcellular-location in the bio-medical domain (Craven, 1999)or for person-affiliation and organization-location(Zelenko et al, 2003).
Rosario and Hearst (2005)have used a more complicated dynamic graphicalmodel to identify interaction types between proteinsand to simultaneously extract the proteins.2.2 Maximum margin modelsProbabilistic graphical models and different ap-proaches to training them have received a lot of at-tention in application to natural language process-ing.
McCallum and Nigam (1998) showed thatNa?
?ve Bayes can be a very accurate model for textcategorization.Since probabilistic graphical models representjoint probability distributions whereas classificationfocuses on the conditional probability, there hasbeen debate regarding the objective that should bemaximized in order to train these models.
Ng andJordan (2001) have compared a joint likelihood274model (Na?
?ve Bayes) and its discriminative coun-terpart (logistic regression), and they have shownthat while for large number of examples logistic re-gression has a lower error rate, Na?
?ve Bayes oftenoutperforms logistic regression for smaller data sets.However, Klein and Manning (2002) showed thatfor natural language and text processing tasks, con-ditional models are usually better than joint likeli-hood models.
Yakhnenko et al (2005) also showedthat conditional models suffer from overfitting intext and sequence structured domains.In recent years, the interest in learning parametersof probabilistic models by maximizing the proba-bilistic margin has developed.
Taskar et al (2003)have solved the problem of learning Markov net-works (undirected graphs) by maximizing the mar-gin.
Their work has focused on likelihood basedstructured classification where the goal is to assigna class to each word in the sentence or a document.Guo et al (2005) have proposed a solution to learn-ing parameters of the maximum margin BayesianNetworks.Surprisingly, little has been done in applyingprobabilistic models trained to maximize the mar-gin to simple classification tasks (to the best ofour knowledge).
Therefore, since the Na?
?ve Bayesmodel has been shown to be a successful algorithmfor many text classification tasks (McCallum andNigam, 1998) we suggest learning the parametersof Na?
?ve Bayes model to maximize the probabilis-tic margin.
We apply the Na?
?ve Bayes model trainedto maximize the margin to a relation extraction task.3 Joint and conditional likelihood modelsand maximum marginWe now describe the background in probabilisticmodels as well as different approaches to parame-ter estimation for probabilistic models.
In particular,we describe Na?
?ve Bayes, logistic regression (analo-gous to conditionally trained Na?
?ve Bayes) and thenintroduce Na?
?ve Bayes trained to maximize the mar-gin.First, we introduce some notation.
Let D be acorpus that consists of training examples.
Let T bethe size of D. We represent each example with atuple ?s, c?
where s is a sentence or a document, andc is a label from a set of all possible labels, c ?
C ={c1...cm}.
Let D={?si, ci?
}where superscript 1 ?i ?
T is the index of the document in the corpus, andci is the label of example si.
Let V be vocabulary ofD, so that every document s consists of elementsof V .
We will use sj to denote a word from s inposition j, where 1 ?
j ?
length(s).3.1 Generative and discriminative Na?
?ve BayesmodelsA probabilistic model assigns to each instance sa joint probability of the instance and the classP (s, c).
If the probability distribution is known,then a new instance snew can be classified by giv-ing it a label which has the highest probability:c = arg maxck?CP (ck|snew) (1)Joint likelihood models learn the parameters bymaximizing the probability of an example and itsclass, P (s, c).
Na?
?ve Bayes multinomial, for in-stance, assumes that all words in the sentence areindependent given the class, and computes this prob-ability as P (c)?length(s)j=1 P (sj |c).
Each of P (sj |c)and P (c) are estimated from the training data usingrelative frequency estimates.
From here on we willrefer to joint likelihood Na?
?ve Bayes multinomial asNB-JL.Since the conditional probability is needed for theclassification task, it has been suggested to solve themaximization problem and train the model so thatthe choice of the parameters maximizes P (c|s) di-rectly.
One can use a joint likelihood model to ob-tain joint probability distribution P (s, c) and thenuse the definition of conditional probability to getP (c|s) = P (s, c)/?ck?C P (s, ck).
The solutionsthat maximize this objective function are searchedfor by using gradient ascent methods.
Logistic re-gression is a conditional model that assumes the in-dependence of features given the class, and it is aconditional counterpart to NB-JL (Ng and Jordan,2001).We will now introduce a probabilistic maximummargin objective and describe a maximum marginmodel that is analogous to Na?
?ve Bayes and logisticregression.2753.2 Maximum margin training of Na?
?ve BayesmodelsThe basic idea behind maximum margin models is tochoose model parameters that for each example willmake the probability of the true class and the exam-ple as high as possible while making the probabilityof the nearest alternative class as low as possible.Formally, the maximum margin objective is?
=Tmini=1minc 6=ciP (ci|si)P (c|si) =Tmini=1minc 6=ciP (si, ci)P (si, c) (2)Here P (s, c) is modeled by a generative model, andparameter learning is reduced to solving a convexoptimization problem (Guo et al, 2005).In order for the example to be classified correctly,the probability of the true class given the examplehas to be higher than the probability of getting thewrong class or?i = log p(ci|si) ?
log p(cj |si) > 0 (3)where j 6= i and ci is the true label of example si.The larger the margin ?i is, the more confidence wehave in the prediction.We consider a Na?
?ve Bayes model trained tomaximize the margin and refer to this model asMMNB.
Using exponential family notation, letP (sj |c) = ewsj |c .
The likelihood is P (s, c) =ewc?len(s)j=1 ewsj |c.
Then the log-likelihoodlogP (s, c) = wc+len(s)?j=1count(sj)wsj |c = w??
(s, c)(4)where w is the weight vector for all the parame-ters that need to be learned, and ?
(s, c) is the vectorof counts of words associated with each parameter?
(s, c) = (...count(sjc)....) in s for class c.The general formulation for Bayesian networkswas given in Guo et al, and we adapt their formu-lation for training a Na?
?ve Bayes model.
The para-meters are learned by solving a convex optimizationproblem.
If the margin ?
is the smallest log-ratio,then ?
needs to be maximized, where the constraintis that for each instance the log-ratio of the proba-bility of predicting the instance correctly and pre-dicting it incorrectly is at least ?.
Such formulationalso allows for the use of slack variables ?
so that theclassifier ?gives up?
on the examples that are diffi-cult to classify.minimize ?,w,?1?2 + BT?i=1?isubject to w(?
(i, ci) ?
?
(i, c)) ?
??
(ci, c) ?
?iand?si?Vewsi,c ?
1?c ?
Cand ?
?
0This problem is convex in the variables ?,w, ?.
B isa regularization parameter, and ?
(ci, c) = 1 if ci 6= cand 0 otherwise.
The inequality constraint for prob-abilities is needed to preserve convexity of the prob-lem, and in the case of Na?
?ve Bayes, the probabilitydistribution over the parameters (the equality con-straint) can be easily obtained by renormalizing thelearned parameters.The minimization problem is somewhat similar to?2-norm support vector machine with a soft margin(Cristianini and Shawe-Taylor, 2000).
The first con-straint imposes that for each example the log of theratio between the example under the true class andthe example under some alternative class is greaterthan the margin allowing for some slack.
The sec-ond constraint enforces that the parameters do notget very large and that the probabilities sum to lessthan 1 to maintain valid probability distribution (theinequality constraint is required to preserve convex-ity, and the probability distribution can be obtainedafter training by renormalization).Following Guo et al (2005), we find parame-ters using a log-barrier method (Boyd and Vanden-berghe, 2004), the sum of the logarithms of con-straints are subtracted from the objective and scaledby a parameter ?.
The problem is solved sequen-tially using a fixed ?
and gradually lowering ?
to 0.The solution for a fixed ?
is obtained using (typ-ically) a second order method to guarantee fasterconvergence.
This solution is then used as the ini-tial parameter values for the next ?.
In our imple-mentation we used a limited memory quasi-Newtonmethod (Nocedal and Liu, 1989).2764 Data and labels4.1 The problem of labeling dataOne major problem of natural language processingis the sparsity of data; to accurately learn a linguis-tic model, one needs to label a large amount of text,which is usually an expensive requirement.
For in-formation extraction, the labeling process is particu-larly difficult and time consuming.
Moreover, in dif-ferent applications one needs different labeled datafor each domain.
We propose a creative way of con-vincing many people to label data quickly and atlow cost to us by using the Mechanical Turk.
Sim-ilarly, Luis von Ahn (2006) creates very successfuland compelling computer games in such a way thatwhile playing, people provide labels for images onthe Web.4.2 Collecting data and label agreementanalysisTo collect the data, we identified 58 pairs of dig-ital devices, as well as their synonyms (for exam-ple, computer, laptop, PC, desktop, etc), and differ-ent manufacturers for a given device (for exampleToshiba, Dell, IBM, etc).
The devices alone wereused to construct the query (for example ?computer,camera?, as well as a combination of manufacturerand devices (for example ?dell laptop, cannon cam-era?).
Each of these pairs was used as a query inGoogle, and the sentences that contain both deviceswere extracted resulting in a total of 3624 sentences.We use the word ?sentence?
when referring to theexamples, however we note that not all text excerptsare sentences, some are chunks of text data.To label the data we used the Mechanical Turk(MTurk), a Web service that allows you to createand post a task for humans to solve; typical tasks arelabeling pictures, choosing the best among severalphotographs, writing product descriptions, proof-reading and transcribing podcasts.
After the task iscompleted the requesters can then review the sub-missions and reject them if the results are poor.We created a total of 121 unique surveys consist-ing of 30 questions.
Each question consisted of oneof the extracted statements with the devices high-lighted in red.
The task for the labeler was to choosebetween ?Yes?, if the statement contained a relationbetween the devices, ?No?
if it did not, or ?not ap-worker3worker1 worker2 yes no n/ayes yes 1091 237 23no 226 281 22n/a 19 18 6no yes 217 199 8no 186 870 56n/a 14 39 8n/a yes 17 13 5no 6 32 6n/a 4 12 9Table 1: Summary of the labels assigned by the MT workersto all the sentences.plicable?
if the text extract was not a sentence, or ifthe query words were not used as different devices(as for noun compounds such as computer stereo).4Each survey was assigned to 3 distinct workers, thushaving 3 possible labels for all 3624 sentences.5We used Fleiss?s kappa (Fleiss, 1971) (a general-ization of kappa statistic which takes into accountmultiple raters and measures inter-rater reliability)in order to determine the degree of agreement andto determine whether the agreement was accidental.Kappa statistics is a number between 0 and 1 where0 is random agreement, and 1 is perfect agreement.In order to compute kappa statistic, since the com-putation requires that the raters are the same foreach survey, we mapped workers into ?worker1?,?worker2?, ?worker3?
with ?worker1?
being thefirst worker to complete each of the 121 surveys,?worker2?
the second, and so on.
The responses aresummarized in Table 1.The overall Fleiss?s kappa was 0.416, and there-fore, it can be concluded that the agreement betweenthe workers was not accidental.We had perfect agreement for 49% of all sen-tences, 5% received all three labels (these exampleswere discarded) and for the remaining 46% two la-4This dataset, including all theMTurk?s workers responses is available athttp://www.cs.iastate.edu/?oksayakh/relation data.html5The requirement for the workers to be different was im-posed by the MTurk system, which checks their Amazon iden-tity; however, this still allows for the same person who has mul-tiple identities to complete the same task more than once.6The kappa coefficients for categories ?Yes?
and ?No?
were0.45 and 0.41 respectively (moderate agreement) and for cate-gory ?not applicable?
was 0.15 (slight agreement).277bels were assigned (the majority vote was used todetermine the final label).
For these cases, we no-ticed that some of the labels were wrong (howeverin most cases the majority vote results in the correctlabel) but other sentences were ambiguous and ei-ther label could be right.
To assign the final label weused majority vote, and we discarded sentences forwhich ?not applicable?
was the majority label.We rewarded the users with between 15 and 30cents per survey (resulting in less than a cent for atext segment) and we were able to obtain labels for3594 text segments for under $70.
It also took any-where between a few minutes to a half-hour fromthe time the survey was made available until it wascompleted by all three users.
We find MechanicalTurk to be a quite interesting, inexpensive, fairly ac-curate and fast way to obtain labeled data for naturallanguage processing tasks.We used this data to evaluate the classificationmodels as described in the next section.5 Experimental setup and resultsThe words were stemmed, and the data wassmoothed by mapping all the words that appearedonly once to a unique token smoothing token (re-sulting in a total of approximately 2,800 wordsin the vocabulary).
We performed 10-fold cross-validation, with smoothed test data where all the un-seen words in the test data were mapped to the tokensmoothing token.
We used the exact same data inthe folds for all four algorithms ?
MMNB, NB-JL,logistic regression and SVM.
Since MMNB, SVM,and logistic regression allows for regularization, weused tuning to find the optimal performance of themodels.
At each fold we withheld 30% of the train-ing data for validation purposes (thus resulting in 3disjoint sets at each fold).
The model was trainedon the resulting 70% of the training data for differ-ent values of the regularization parameters, and thevalue which yielded the highest accuracy on the val-idation set was used to train the model that was eval-uated on the test set.As a baseline, we consider a classifier which as-signs the most frequent label (?Yes?
); such a classi-fier results in 53% accuracy.Table 2 summarizes the performance of MMNBand other algorithms as determined by 10-fold cross-Algorithm AccuracyMMNB 80.23%SVM-RBF 76.49%NB-JL 75.62%Perceptron 74.04%SVM-2 72.72%SVM-3 71.54%DT 70.76%LR 69.95%SVM-1 69.94%Baseline 53.8%Table 2: Classification accuracies as determined by 10-fold cross-validation.
SVM-1 uses linear kernel, SVM-2 usesquadratic kernel, SVM-3 uses cubic kernel, SVM-RBF usesRBF kernel with parameter ?
= 0.1.
The Decision Tree (DT)uses binary splits.
LR is logistic regression.validation with tuning data.
We compared the accu-racies of the maximum margin model with the accu-racy of generative Na?
?ve Bayes, logistic regressionand SVM as shown in Table 2.
The MMNB has thehighest accuracy followed by NB-JL and then SVMwith RBF kernel.
Even after tuning, logistic regres-sion did not reach the performance of MMNB andNB-JL.Since MMNB is trained to maximize the mar-gin, we compared it with the Support Vector Ma-chine (linear maximum margin classifier).
Countsof words were used as features (resulting in thebag of words representation7).
We ran our experi-ments with linear, quadratic, cubic and RBF kernels.SVM was tuned using the validation set similarly toMMNB.
We also experimented with Perceptron andDecision Tree using binary splits with reduced error-pruning, which are methods commonly used for textclassification (due to lack of space, we will not de-scribe these methods and their applications, but referthe reader to Manning and Schu?tze (1999)).
Amongall the known methods, the maximum margin Na?
?veBayes is the algorithm with the highest accuracy,suggesting that it is a competitive algorithm in re-lation extraction and text classification tasks.7This representation allows for additional or alternative fea-tures such as k-grams of words, whether the words are capital-ized, where on the page the sentence was located, etc.
Evalu-ating MMNB and other methods with additional features is ofinterest in the future2786 Analysis of behavior of Na?
?ve Bayes,maximum margin Na?
?ve Bayes andlogistic regressionWe analyzed the behavior of the parameters of theprobabilistic models (Na?
?ve Bayes, MMNB and lo-gistic regression) on the training data.
For each ex-ample in the training data we computed the probabil-ity P (c = noRelation|s) using the parameters fromthe model, and examined the probabilities assignedto examples from both classes.
We show these plotsin Figure 1.Figure 1: Probability distribution of P (c = noRelation|s)learned by the Na?
?ve Bayes (upper left), logistic regression (up-per right) and maximum margin Na?
?ve Bayes(lower).
In grayare class-conditional probabilities assigned to positive exam-ples, and in black are class-conditional probabilities assignedto negative examples.As we see, the logistic regression discriminatesbetween the majority of the examples by assigningextreme probabilities (0 and 1).
However, there aresome examples which are extremely borderline, andthus it does not generalize well on the test set.
On theother had, Na?
?ve Bayes does not have such ?sharp?discrimination.
Maximum margin Na?
?ve Bayes has?sharper?
discrimination than Na?
?ve Bayes, howeverthe discrimination is smoother than for logistic re-gression.
The examples which are more difficult toclassify have probabilities that are more spread out(away from 0.5), as opposed to the case of logisticregression, which assigns these difficult examples toprobability close to 0.5.
This suggests that maxi-mum margin Na?
?ve Bayes, possibly has a better gen-eralization ability than both logistic regression andNa?
?ve Bayes, however to make such a claim addi-tional experiments are needed.7 ConclusionsThe contribution of this paper is threefold.
First, weaddressed the important problem of identifying thepresence of semantic relations between entities intext, focusing on the digital domain.
We presentedsome encouraging results; it remains to be seenhowever, how this would transfer to better results inan information retrieval task.
Secondly, we consid-ered a probabilistic model trained to maximize themargin, that achieved the highest accuracy for thistask, suggesting that it could be a competitive algo-rithm for relation extraction and text classificationin general.
However in order to fully evaluate theMMNB method for relation classification it needsto be applied to other classification and or relationprediction tasks.
We also empirically analyzed thebehavior of the parameters learned by maximummargin model and showed that the parameters allowfor better generalization power than Na?
?ve Bayes orlogistic regression models.
Finally, we suggested aninexpensive way of getting people to label text datavia Mechanical Turk.Acknowledgment The authors would like tothank the reviewers for their feedback and com-ments; William Schilit for invaluable insight andhelp and for first suggesting using the MTurk togather labeled data; David McDonald for help withdeveloping survey instructions; and numerous MTworkers for providing the labels.ReferencesEugene Agichtein and Luis Gravano.
2000.
Snowball:Extracting relations from large plain-text collections.In Proceedings of Digital Libraries.Sara Bly, William Schilit, David McDonald, BarbaraRosario, and Ylian Saint-Hilaire.
2006.
Broken ex-pectations in the digital home.
In Proceedings of Com-puter Human Interaction (CHI).Stephen Boyd and Lieven Vandenberghe.
2004.
ConvexOptimization.
Cambridge University Press.Mark Craven.
1999.
Learning to extract relations fromMedline.
In AAAI-99 Workshop.279Nello Cristianini and John Shawe-Taylor.
2000.
AnIntroduction to Support Vector Machines and OtherKernel-based Learning Methods.
Cambridge Univer-sity Press.Joseph L. Fleiss.
1971.
Measuring nominal scale agree-ment among many raters.
Psychological Bulletin,76(5):378?382.Yuhong Guo, Dana Wilkinson, and Dale Schuurmans.2005.
Maximum margin bayesian networks.
In Pro-ceedings of the 21th Annual Conference on Uncer-tainty in Artificial Intelligence (UAI-05), page 233.Dan Klein and Christopher Manning.
2002.
Conditionalstructure versus conditional estimation in nlp models.In Empirical Methods in Natural Language Process-ing (EMNLP).Christopher D. Manning and Hinrich Schu?tze.
1999.Foundations of Statistical Natural Language Process-ing.
The MIT Press, June.Andrew McCallum and Kamal Nigam.
1998.
A com-parison of event models for naive bayes text classifi-cation.
In AAAI-98 Workshop on Learning for TextCategorization.Andrew Y. Ng and Michael I. Jordan.
2001.
On dis-criminative vs. generative classifiers: A comparison oflogistic regression and naive bayes.
In Proceedings ofNeural Information Processing Systems (NIPS), pages841?848.Jorge Nocedal and Dong C. Liu.
1989.
On the limitedmemory method for large scale optimization.
Mathe-matical Programming, 3(45):503?528.Barbara Rosario and Marti Hearst.
2005.
Multi-way re-lation classification: Application to protein-protein in-teractions.
In Empirical Methods in Natural LanguageProcessing (EMNLP).Benjamin Taskar, Carlos Guestrin, and Daphne Koller.2003.
Max-margin markov networks.
In Proceedingsof Neural Information Processing Systems (NIPS).Luis von Ahn.
2006.
Games with a purpose.
Computer,39(6):92?94.Oksana Yakhnenko, Adrian Silvescu, and VasantHonavar.
2005.
Discriminatively trained markovmodel for sequence classification.
In Proceedings ofInternational Conference on Data Mining (ICDM).Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relationextraction.
In Proceedings of Empirical Methods inNatural Language Processing (EMNLP).280
