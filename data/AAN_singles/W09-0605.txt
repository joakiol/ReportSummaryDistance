Proceedings of the 12th European Workshop on Natural Language Generation, page 33,Athens, Greece, 30 ?
31 March 2009. c?2009 Association for Computational LinguisticsProbabilistic Approaches for Modeling Text Structure and theirapplication to Text-to-Text GenerationRegina BarzilayComputer Science and Artificial Intelligence LaboratoryMassachusetts Institute of Technologyregina@csail.mit.eduText-to-text generation aims to produce a coher-ent text by extracting, combining and rewriting in-formation given in input texts.
Examples of its ap-plications include summarization, answer fusionin question-answering and text simplification.
Atfirst glance, text-to-text generation seems a mucheasier task than the traditional generation set-upwhere the input consists of a non-linguistic rep-resentation.
Research in summarization over thelast decade proved that the opposite is true ?
textsgenerated by these methods rarely match the qual-ity of those written by humans.
One of the keyreasons is the lack of coherence in the generatedtext.In contrast to the traditional set-up in concept-to-text generation, these applications do not haveaccess to semantic representations and domain-specific communication knowledge.
Therefore,traditional approaches for content selection cannotbe employed in text-to-text applications.
Theseconsiderations motivate the development of novelapproaches for document organization that can ex-clusively rely on information available in textualinput.In this talk, I will present models of documentstructure that can be effectively used to guide con-tent selection in text-to-text generation.
First, Iwill focus on unsupervised learning of domain-specific content models.
These models capturethe topics addressed in a text, and the order inwhich these topics appear; they are close in theirfunctionality to the content planners traditionallyused in concept-to-text generation.
I will presentan effective method for learning content modelsfrom unannotated domain-specific documents, uti-lizing hierarchical Bayesian methods.
Incorpora-tion of these models into information ordering andsummarization applications yields substantial im-provement over previously proposed methods.Next, I will present a method for assessingthe coherence of a generated text.
The keypremise of our work is that the distribution of en-tities in coherent texts exhibits certain regulari-ties.
The models I will be presenting operate overan automatically-computed representation that re-flects distributional, syntactic, and referential in-formation about discourse entities.
This represen-tation allows us to induce the properties of coher-ent texts from a given corpus, without recourseto manual annotation or a predefined knowledgebase.
I will show how these models can be effec-tively integrated in text-to-text applications suchas summarization and answer fusion.This is joint work with Branavan, Harr Chen,Mirella Lapata and Lillian Lee.33
