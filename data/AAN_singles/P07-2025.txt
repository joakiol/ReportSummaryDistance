Proceedings of the ACL 2007 Demo and Poster Sessions, pages 97?100,Prague, June 2007. c?2007 Association for Computational LinguisticsExploration of Term Dependence in Sentence RetrievalKeke Cai, Jiajun Bu, Chun Chen, Kangmiao LiuCollege of Computer Science, Zhejiang UniversityHangzhou, 310027, China{caikeke,bjj,chenc,lkm}@zju.edu.cnAbstractThis paper focuses on the exploration ofterm dependence in the application ofsentence retrieval.
The adjacent terms ap-pearing in query are assumed to be relatedwith each other.
These assumed depend-ences among query terms will be furthervalidated for each sentence and sentences,which present strong syntactic relation-ship among query terms, are consideredmore relevant.
Experimental results havefully demonstrated the promising of theproposed models in improving sentenceretrieval effectiveness.1 IntroductionSentence retrieval is to retrieve sentences in re-sponse to certain requirements.
It has been widelyapplied in many tasks, such as passage retrieval(Salton et al 1994), document summarization(Daum?
and Marcu, 2006), question answering(Li, 2003) and novelty detection (Li and Croft2005).
A lot of different approaches have beenproposed for this service, but most of them arebased on term matching.
Compared with docu-ment, sentence always consists of fewer terms.Limited information contained in sentence makesit quite difficult to implement such term basedmatching approaches.Term dependence, which means that the pres-ence or absence of one set of terms provides in-formation about the probabilities of the presenceor absence of another set of terms, has beenwidely accepted in recent studies of informationretrieval.
Taking into account the limited infor-mation about term distribution in sentence, thenecessary of incorporating term dependence intosentence retrieval is clear.Two kinds of dependence can be considered inthe service of sentence retrieval.
The first oneoccurs among query or sentence terms and an-other one occurs between query and sentenceterms.
This paper mainly focuses on the first kindof dependence and correspondingly proposes anew sentence retrieval model (TDSR).
In general,TDSR model can be achieved through the follow-ing two steps:The first step is to simulate the dependencesamong query terms and then represent query as aset of term combinations, terms of each of whichare considered to be dependent with each other.The second step is to measure the relevance ofeach sentence by considering the syntactic rela-tionship of terms in each term combinationformed above and then sort sentences accordingto their relevance to the given query.The remainder is structured as follows: Section2 introduces some related studies.
Section 3 de-scribes the proposed sentence retrieval model.
InSection 4, the experimental results are presentedand section 5 concludes the paper.2 Related WorksSentence retrieval is always treated as a specialtype of document retrieval (Larkey et al 2002;Schiffman, 2002; Zhang et al 2003).
Weightfunction, such as tfidf algorithm, is used to con-struct the weighted term vectors of query andsentence.
Similarity of these two vectors is thenused as the evidence of sentence relevance.
Infact, document retrieval differs from sentenceretrieval in many ways.
Thus, traditional docu-97ment retrieval approaches, when implemented inthe service of sentence retrieval, cannot achievethe expected retrieval performance.Some systems try to utilize linguistic or otherfeatures of sentences to facilitate the detection ofsentence relevance.
In the study of White (2005),factors used for ranking sentences include theposition of sentence in the source document, thewords contained in sentence and the number ofquery terms contained in sentence.
In anotherstudy (Collins-Thompson et al, 2002), semanticand lexical features are extracted from the initialretrieved sentences to filter out possible non-relevant sentences.
Li and Croft (2005) choosesto describe a query by patterns that include bothquery words and required answer types.
Thesepatterns are then used to retrieve sentences.Term dependence also has been tried in somesentence retrieval models.
Most of these ap-proaches realize it by referring to query expan-sion or relevance feedback.
Terms that are se-mantically equivalent to the query terms or co-occurred with the query terms frequently can beselected as expanded terms (Schiffman, 2002).Moreover, query also can be expanded by usingconcept groups (Ohgaya et al, 2003).
Sentencesare then ranked by the cosine similarity betweenthe expanded query vector and sentence vector.In (Zhang et al, 2003), blind relevance feedbackand automatic sentence categorization basedSupport Vector Machine (SVM) are combinedtogether to finish the task of sentence retrieval.
Inrecent study, a translation model is proposed formonolingual sentence retrieval (Murdock andCroft, 2005).
The basic idea is to use explicit re-lationships between terms to evaluate the transla-tion probability between query and sentence.
Al-though the translation makes an effective utiliza-tion of term relationships in the service of sen-tence retrieval, the most difficulty is how to con-struct the parallel corpus used for term translation.Studies above have shown the positive effectsof term dependence on sentence retrieval.
How-ever, it is considered that for the special task ofsentence retrieval the potentialities of term de-pendence have not been fully explored.
Sentence,being an integrated information unit, always hasspecial syntactic structure.
This kind of informa-tion is considered quite important to sentencerelevance.
How to incorporate this kind of infor-mation with information about dependences inquery to realize the most efficient sentence re-trieval is the main objective of this paper.3 TDSR ModelAs discussed above, the implementation of TDSRmodel consists of two steps.
The following willgive the detail description of each step.3.1 Term Dependences in QueryPast studies have shown the importance of de-pendences among query terms and different ap-proaches have been proposed to define the stylesof term dependence in query.
In this paper, theassumption of term dependence starts by consid-ering the possible syntactic relationships of terms.For that the syntactic relationships can happenamong any set of query terms, hence the assump-tion of dependence occurring among any queryterms is considered more reasonable.The dependences among all query terms willbe defined in this paper.
Based on this definition,the given query Q can be represented as: Q ={TS1, TS2, ?, TSn}, each item of which containsone or more query terms.
These assumed depend-ences will be further evaluated in each retrievedsentence and then used to define the relevance ofsentence3.2 Identification of Sentence RelevanceTerm dependences defined above provide struc-ture basis for sentence relevance estimate.
How-ever, their effects to sentence relevance identifi-cation are finally decided by the definition of sen-tence feature function.
Sentence feature functionis used to estimate the importance of the esti-mated dependences and then decides the rele-vance of each retrieved sentence.In this paper, feature function is defined fromthe perspective of syntactic relationship of termsin sentence.
The specific dependency grammar isused to describe such relationship in the form ofdependency parse tree.
A dependency syntacticrelationship is an asymmetric relationship be-tween a word called governor and another wordcalled modifier.
In this paper, MINIPAR isadopted as the dependency parser.
An example ofa dependency parse tree parsed by MINIPAR isshown in Figure 1, in which nodes are labeled bypart of speeches and edges are labeled by relationtypes.98Figure 1.
Dependency parse tree of sentence ?Ev-erest is the highest mountain?.As we know, terms within a sentence can bedescribed by certain syntactic relationship (director indirect).
Moreover, different syntactic rela-tionships describe different degrees of associa-tions.
Given a query, the relevance of each sen-tence is considered different if query terms pre-sent different forms of syntactic relationships.This paper makes an investigation of syntacticrelationships among terms and then proposes anovel feature function.To evaluate the syntactic relationship of terms,the concept of association strength should be de-fined to each TSi ?Q with respect to each sen-tence S. It describes the association of terms inTSi.
The more closely they are related, the higherthe value is.
In this paper, the association strengthof TSi is valued from two aspects:z Size of TSi.
Sentences containing morequery terms are considered more relevant.z Distance of TSi.
In the context of depend-ency parse tree, the link between two termsmeans their direct syntactic relationship.
Forterms with no direct linkage, their syntactic rela-tionship can be described by the path betweentheir corresponding nodes in tree.
For example, inFigure 1 the syntactic relationship between terms?Everest?
and ?mountain?
can be described bythe path:This paper uses term distance to evaluate termssyntactic relationship.
Given two terms A and B,their distance distance(A, B) is defined as thenumber of linkages between A and B with noconsideration of direction.
Furthermore, for theterm set C, their distance is defined as:qqdistanceNCD jiCqq ji),(1)(,??=?
(1)where N is the number of term pairs of C.Given the term set TSi, the association strengthof TSi in sentence S is defined as:)()(1),( ii TSDTSSi STSAS ??
?=                               (2)where S(TSi) is the size of term set TSi and pa-rameters ?
and ?
are valued between 0 and 1 andused to control the influence of each componenton the computation of AS(TSi).Based on the definition of association strength,the feature function of S can be further defined as:),(max),( STSASQSF iQTSi?=                                     (3)Taking the maximum association strength toevaluate sentence relevance conforms to the Dis-junctive Relevance Decision principle (Kong etal., 2004).
Based on the feature function definedabove, sentences can be finally ranked accordingto the obtained maximum association strength.4 ExperimentsIn this paper, the proposed method is evaluatedon the data collection used in TREC novelty track2003 and 2004 with the topics N1-N50 and N51-N100.
Only the title portion of these TREC topicsis considered.To measure the performance of the suggestedretrieval model, three traditional sentence re-trieval models are also performed, i.e., TFIDFmodel (TFIDF), Okapi model (OKAPI) and KL-divergence model with Dirichlet smoothing(KLD).
The result of TFIDF provides the base-line from which to compare other retrieval mod-els.Table 1 shows the non-interpolated averageprecision of each different retrieval models.
Thevalue in parentheses is the improvement over thebaseline method.
As shown in the table, TDSRmodel outperforms TFIDF model obviously.
Theimprovements are respectively 15.3% and 10.2%.N1-N50 N51-N100TFIDF 0.308 0.215OKAPI 0.239 (-22.4) 0.165 (-23.3%)KLD 0.281 (-8.8) 0.204 (-5.1%)TDSR 0.355 (15.3%) 0.237 (10.2%)Table 1.
Average precision of each different re-trieval modelsEverest Be mountains predBe (VBE)Everest (N) mountain  (N)the  (Det) highest  (A)Everest (N)s predsubjdet mod99Figure 2 and Figure 3 further depict the preci-sion recall curve of each retrieval model whenimplemented on different query sets.
The im-provements of the proposed retrieval model indi-cated in these figures are clear.
TDSR outper-forms other retrieval models at any recall point.00.20.40.60.810 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1RecallPrecision TFIDFOKAPIKLTDSRFigure 2.
Precision-Recall Curve of Each Re-trieval Model (N1-N50)00.20.40.60.810 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1RecallPrecision TFIDFOKAPIKLTDSRFigure 3.
Precision-Recall Curve of Each Re-trieval Model (N51-N100)5 ConclusionsThis paper presents a novel approach for sentenceretrieval.
Given a sentence, its relevance is meas-ured by the degree of its support to the depend-ences between query terms.
Term dependence,which has been widely considered in the studiesof document retrieval, is the basis of this retrievalmodel.
Experimental results show the promisingof the proposed models in improving sentenceretrieval performance.ReferencesBarry Schiffman.
2002.
Experiments in Novelty De-tection at Columbia University.
In Proceedings ofthe 11th Text REtrieval Conference, pages 188-196.Gerard Salton, James Allan, and Chris Buckley.
1994.Automatic structuring and retrieval of large textfiles.
Communication of the ACM, 37(2): 97-108.Hal Daum?
III and Daniel Marcu.
2006.
Bayesianquery-focused summarization.
In Proceedings ofthe 21st International Conference on Computa-tional Linguistics and the 44th annual meeting ofthe ACL, pages 305-312, Sydney, Australia.Kevyn Collins-Thompson, Paul Ogilvie, Yi Zhang,and Jamie Callan.
2002.
Information filtering, Nov-elty detection, and named-page finding.
In Proceed-ings of the 11th Text REtrieval Conference, Na-tional Institute of Standards and Technology.Leah S. Larkey, James Allan, Margaret E. Connell,Alvaro Bolivar, and Courtney Wade.
2002.
UMassat TREC 2002: Cross Language and NoveltyTracks.
In Proceeding of the Eleventh Text Re-trieval Conference, pages 721?732, Gaithersburg,Maryland.Min Zhang, Chuan Lin, Yiqun Liu, Le Zhao, LiangMa, and Shaoping Ma.
2003.
THUIR at TREC2003: Novelty, Robust, Web and HARD.
In Pro-ceedings of 12th Text Retrieval Conference, pages137-148.Ryen W. White, Joemon M. Jose, and Ian Ruthven.2005.
Using top-ranking sentences to facilitate ef-fective information access.
Journal of the AmericanSociety for Information Science and Technology,56(10): 1113-1125.Ryosuke Ohgaya, Akiyoshi Shimmura, Tomohiro Ta-kagi, and Akiko N. Aizawa.
2003.
Meiji Universityweb and novelty track experiments at TREC 2003.In Proceedings of the Twelfth Text Retrieval Con-ference.Vanessa Murdock and W. Bruce Croft.
2005.
A trans-lation Model for Sentence retrieval.
HLT/EMNLP.In Proceedings of the Conference on Human Lan-guage Technologies and Empirical Methods inNatural Language Processing, pages 684-691.Xiaoyan Li.
2003.
Syntactic Features in Question An-swering.
In Proceedings of the 26th Annual Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval, pages 455-456, Toronto, Canada.Xiaoyan Li and W. Bruce Croft.
2005.
Novelty detec-tion based on sentence level patterns.
In Proceed-ings of ACM Fourteenth Conference on Informationand Knowledge Management (CIKM), pages 744-751, Bremen, Germany.Y.K.
Kong, R.W.P.
Luk, W. Lam, K.S.
Ho and F.L.Chung.
2004.
Passage-based retrieval based on pa-rameterized fuzzy operators, ACM SIGIR Workshopon Mathematical/Formal Methods for InformationRetrieval.100
