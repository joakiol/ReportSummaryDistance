Combining Linguistic Features with Weighted Bayesian Classifierfor Temporal Reference ProcessingGuihong CaoDepartment of ComputingThe Hong Kong Polytechnic University, Hong Kongcsghcao@comp.polyu.edu.hkWenjie LiDepartment of ComputingThe Hong Kong Polytechnic University, Hong Kongcswjli@comp.polyu.edu.hkKam-Fai WongDepartment of Systems Engineering and EngineeringManagementThe Chinese University of Hong Kong, Hong Kongkfwong@se.cuhk.edu.hkChunfa YuanDepartment of Computer Science and TechnologyTsinghua University, Beijing, China.cfyuan@tsinghua.edu.cnAbstractTemporal reference is an issue of determininghow events relate to one another.
Determiningtemporal relations relies on the combination ofthe information, which is explicit or implicit ina language.
This paper reports a computationalmodel for determining temporal relations inChinese.
The model takes into account the ef-fects of linguistic features, such as tense/aspect,temporal connectives, and discourse structures,and makes use of the fact that events are repre-sented in different temporal structures.
A ma-chine learning approach, Weighted BayesianClassifier, is developed to map their combinedeffects to the corresponding relations.
An em-pirical study is conducted to investigate differ-ent combination methods, including lexical-based, grammatical-based, and role-basedmethods.
When used in combination, theweights of the features may not be equal.
Incor-porating with an optimization algorithm, theweights are fine tuned and the improvement isremarkable.1 IntroductionTemporal information describes changes and timeof the changes.
In a language, the time of an eventmay be specified explicitly, for example ????1997???????????
(They solved the traf-fic problem of the city in 1997)?
; or it may be relatedto the time of another event, for example ???????
?, ????????????
(They solved thetraffic problem of the city after the street bridge hadbeen built?.
Temporal reference describes howevents relate to one another, which is essential tonatural language processing (NLP).
Its major appli-cations cover syntactic structural disambiguation(Brent, 1990), information extraction and questionanswering (Li, 2002), language generation and ma-chine translation (Dorr, 2002).Many researchers have attempted to characterizethe nature of temporal reference in a discourse.
Iden-tifying temporal relations1 between two events de-1 The relations under examined include both intra-sentence and inter-pends on a combination of information resources.This information is provided by explicit tense andaspect markers, implicit event classes or discoursestructures.
It has been used to explain semantics oftemporal expressions (Moens, 1988; Webber, 1988),to constrain possible temporal interpretations(Hitzeman, 1995; Sing, 1997), or to generate appro-priate temporally conjoined clauses (Dorr, 2002).The purpose of our work is to develop a computa-tional model, which automatically determines tempo-ral relations in Chinese.
While temporal referenceinterpretation in English has been well studied, Chi-nese has been rarely discussed.
In our study, thirteenrelated features are identified from linguistic per-spective.
How to combine these features and how tomap their combined effects to the corresponding rela-tions are the critical issues to be addressed in thispaper.Previous work was limited in that they just con-structed constraint or preference rules for some rep-resentative examples.
These methods are ineffectivefor computing purpose, especially when a largenumber of the features are involved and the interac-tion among them is unclear.
Therefore, a machinelearning approach is applied and the empirical stud-ies are carried out in our work.The rest of this paper is organized as follows.
Sec-tion 2 introduces temporal relation representations.Section 3 provides linguistic background of temporalreference and investigates linguistic features for de-termining temporal relations in Chinese.
Section 4explains the methods used to combine linguistic fea-tures with Bayesian Classifier.
It is followed by adescription of the optimization algorithm which isused for estimating feature weights in Section 5.
Fi-nally, Section 6 concludes the paper.2 Representing Temporal RelationsWith the growing interests to temporal informationprocessing in NLP, a variety of temporal systemshave been introduced to accommodate the character-istics of temporal information.
In order to processtemporal reference in a discourse, a formal represen-sentence relations.tation of temporal relations is required.
Among thosewho worked on representing or explaining temporalrelations, some have taken the work of Reichenbach(Reichenbach, 1947) as a starting point, while othersbased their works on Allen?s (Allen, 1983).Reichenbach proposed a point-based temporal the-ory.
Reichenbach?s representation associated Englishtenses and aspects with three time points, namelyevent time (E), speech time (S) and reference time(R).
The reference of E-R and R-S was either before(or after in reverse order) or simultaneous.
This the-ory was later enhanced by Bruce who defined seventemporal relations (Bruce, 1972).
Given two durativeevents, the interval relations between them weremodeled by the order between the greatest lowerbounding point and least upper bounding point of thetwo events.
In the other camp, instead of adoptingtime points, Allen took intervals as temporal primi-tives to facilitate temporal reasoning and introducedthirteen basic relations.
In this interval-based repre-sentation, points were relegated to a subsidiary statusas ?meeting places?
of intervals.
An extension toAllen?s theory, which treated both points and inter-vals as primitives on an equal footing, was later in-vestigated by Knight and Ma (Knight, 1994).In natural languages, events described can be ei-ther punctual or durative in nature.
A punctual event,e.g., ??
(explore), occurs instantaneously.
It takestime but does not last in a sense that it lacks of aprocess of change.
It is adequate to represent a punc-tual event with a simple point structure.
Whilst, adurative event, e.g., ??
(built a house), is morecomplex and its accomplishment as a whole involvesa process spreading in time.
Representing a durativeevent requires an interval representation.
For thisreason, Knight and Ma?s model is adopted in ourwork (see Figure 1).
Taking the sentence ???????
?, ????????????
(They solved thetraffic problem of the city after the street bridge hadbeen built)?
as an example, the relation held betweenbuilding the bridge (i.e., an interval) and solving theproblem (i.e., a point) is BEFORE.Figure 1 13 relations represented with points and intervals3 Linguistic Background of Temporal Refer-ence in a Discourse3.1 Literature ReviewThere were a number of theories in the literatureabout how temporal relations between events can bedetermined in English.
Most of the researches ontemporal reference were based on Reichenbach?snotion of tense/aspect structure, which was known asBasic Tense Structure (BTS).
As for relating twoevents adjoined by a temporal/causal connective,Hornstein (Hornstein, 1990) proposed a neo-Reichenbach structure which organized the BTSsinto a Complex Tense Structure (CTS).
It has beenargued that all sentences containing a matrix and anadjunct clause were subject to linguistic constraintson tense structure regardless of the lexical words in-cluded in the sentence.
Generally, constraints wereused to support syntactic disambiguation (Brent,1990) or to generate acceptable sentences (Dorr,2002).In a given CTS, a past perfect clause should pre-cede the event described by a simple past clause.However, the order of two events in CTS does notnecessarily correspond to the order imposed by theinterpretation of the connective (Dorr, 2002).
Tem-poral/casual connective, such as ?after?, ?before?
or?because?, can supply explicit information about thetemporal ordering of events.
Passonneau (Passon-neau, 1988), Brent (Brent, 1990 and Sing (Sing, 1997)determined intra-sentential relations by accountingfor temporal or causal connectives.
Dorr and Gaast-erland (Dorr, 2002), on the other hand, studied howto generate the sentences which reflect event tempo-ral relations by selecting proper connecting words.However, temporal connectives can be ambiguous.For instance, a ?when?
clause permits many possibletemporal relations.Several researchers have developed the modelsthat incorporated aspectual types (such as those dis-tinct from states, processes and events) to interprettemporal relations between clauses connected with?when?.
Moens and Steedmen (Moens, 1988) devel-oped a tripartite structure of events2, and emphasizedit was the notion of causation and consequence thatplayed a central role in defining temporal relations ofevents.
Webber (Webber, 1988) improved upon theabove work by specifying rules for how events arerelated to one another in a discourse and Sing andSing defined semantic constraints through whichevents can be related (Sing, 1997).
The importanceof aspectual information in retrieving proper aspectsand connectives for sentence generation was alsorecognized by Dorr and Gaasterland (Dorr, 2002).Some literature claimed that discourse structuressuggested temporal relations.
Lascarides and Asher(Lascarides, 1991) investigated various contextualeffects on rhetorical relations (such as narration,elaboration, explanation, background and result).They corresponded each of the discourse relations toa kind of temporal relation.
Later, Hitzeman (Hitze-man, 1995) described a method for analyzing tempo-ral structure of a discourse by taking into account theeffects of tense, aspect, temporal adverbials and rhe-2  The structure comprises a culmination, an associated preparatoryprocess and a consequence state.A punctual event (i.e.
represented in time point)A durative event (i.e.
represented in time interval)BEFORE/AFTERMEETS/MET-BYOVERLAPS/OVERLAPPED-BYSTARTS/STARTED-BYDURING/CONTAINSFINISHES/FINISHED-BYSAME-AStorical relations.
A hierarchy of rhetorical and tempo-ral relations was adopted so that they could mutuallyconstrain each other.To summarize, the interpretation of temporal rela-tions draws on the combination of various informa-tion resources, including explicit tense/aspect andconnectives (temporal or otherwise), temporalclasses implicit in events, or rhetorical relations hid-den in a discourse.
This conclusion, although drawnfrom the studies of English, provides the commonunderstanding on what information is required fordetermining temporal relations across languages.3.2 Linguistic Features for Determining Tem-poral Relations in ChineseThirteen related linguistic features are recognizedfor determining Chinese temporal relations in thispaper (See Table 1).
The selected features are scat-tered in various grammatical categories due to theunique nature of language, but they fall into the fol-lowing three groups.
(1) Tense/aspect in English is manifested by verbinflections.
But such morphological variations areinapplicable to Chinese verbs.
Instead, they areconveyed lexically.
In other words, tense and as-pect in Chinese are expressed using a combinationof, for example, time words, auxiliaries, temporalposition words, adverbs and prepositions, andparticular verbs.
They are known as Tense/AspectMarkers.
(2) Temporal Connectives in English primarily in-volve conjunctions, such as ?after?
and ?before?,which are the key components in discourse struc-tures.
In Chinese, however, conjunctions, conjunc-tive adverbs, prepositions and position words, ortheir combinations are required to representconnectives.
A few verbs that express cause/effectimply a temporal relation.
They are also regardedas a feature relating to discourse structure3.
Thewords which contribute to the tense/aspect andtemporal connective expressions are explicit in asentence and generally known as Temporal Indica-3 The casual conjunctions such as ?because?
are included in thisgroup.tors.
(3) Event Classes are implicit in a sentence.
Eventscan be classified according to their inherent tem-poral characteristics, such as the degree of telicityand atomicity.
The four widespread accepted tem-poral classes are state, process, punctual event anddeveloping event (Li, 2002).
Based on theirclasses, events interact with the tense/aspect ofverbs to determine the temporal relations betweentwo events.Temporal indicators and event classes are both re-ferred to as Linguistic Features.
Table 1 shows theassociation between a temporal indicator and its ef-fects.
Note that the association is not one-to-one.
Forexample, adverbs affect tense/aspect (e.g.
?, being)as well as discourse structure (e.g.
?, at the sametime).
For another example, tense/aspect can bejointly affected by auxiliary words (e.g.
?
,were/was), trend verbs (?
?, begin to), and so on.Obviously, it is not a simple task to map the com-bined effects of the thirteen linguistic features to thecorresponding relations.
Therefore, a machine learn-ing approach is proposed, which investigates howthese features contribute to the task and how theyshould be combined.4 Combining Linguistic Features with MachineLearning ApproachPrevious efforts in corpus-based NLP have incor-porated machine learning methods to coordinate mul-tiple linguistic features, for example, in accent resto-ration (Yarowsky, 1994) and event classification(Siegel, 1998).Temporal relation determination can be modeledas a relation classification task.
We formulate thethirteen temporal relations (see Figure 1) as theclasses to be decided by a classifier.
The classifica-tion process is to assign an event pair to one classaccording to their linguistic features.
There existednumerous classification algorithms based upon su-pervised learning principle.
One of the most effectiveclassifiers is Bayesian Classifier, introduced by Dudaand Hart (Duda, 1973) and analyzed in more detailby Langley and Thompson (Langley, 1992).
Its pre-dictive performance is competitive with state-of-the-Linguistic Feature Symbol POS Tag Effect ExampleWith/Without punctuations PT Not Applicable Not Applicable Not ApplicableSpeech verbs VS TI_vs Tense ?
?, ?
?, ?Trend verbs TR TI_tr Aspect ?
?, ?
?Preposition words P TI_p Discourse Structure/Aspect ?, ?, ?Position words PS TI_f Discourse Structure ?, ?, ?
?Verbs with verb objects VV TI_vv Tense/Aspect ?
?, ?
?, ?Verbs expressing wish/hope VA TI_va Tense ?
?, ?, ?Verbs related to causality VC TI_vc Discourse Structure ?
?, ?
?, ?
?Conjunctive words C TI_c Discourse Structure ?, ?
?, ?
?Auxiliary words U TI_u Aspect ?, ?, ?Time words T TI_t Tense ?
?, ?
?, ?
?Adverbs D TI_d Tense/Aspect/Discourse Structure ?, ?, ?
?, ?Event class EC E0/E1/E2/E3 Event Classification State, Punctual Event, De-veloping Event, ProcessTable 1 Linguistic features: eleven temporal indicators and one event classart classifiers, such as C4.5 and SVM (Friedman,1997).4.1 Bayesian ClassifierGiven the class c , Bayesian Classifier learns fromtraining data the conditional probability of each at-tribute.
Classification is performed by applyingBayes rule to compute the posterior probability of cgiven a particular instance x , and then predicting theclass with the highest posterior probability ratio.
Let],...,,,,[ 2121 nttteex = , Eee ?21 ,  are the two eventclasses and Tttt n ?,...,, 21 are the temporal indicators(i.e.
the words).
E is the set of event classes.
T is theset of temporal indicators.
Then x is classified as:???????
?=),...,,,,|(),...,,,,|(logmaxarg21212121*nnc ttteecPttteecPc  (E1)where c denotes the classes different from c .
As-suming event classes are independent of temporalindicators given c , we have:????????=????????)()|,...,,,,()()|,...,,,,(log),...,,,,|(),...,,,,|(log2121212121212121cPcttteePcPcttteePttteecPttteecPnnnn(E2)????????+????????+???????
?=)|,...,,()|,...,,(log)|,()|,(log)()(log21212121ctttPctttPceePceePcPcPnnAssuming temporal indicators are independent ofeach other, we have?== ni iinnctPctPctttPctttP12121)|()|()|,...,,()|,...,,( ,    ( ni ,...2,1= ) (E3)A Na?ve Bayesian Classifier assumes strict inde-pendence among all attributes.
However, this as-sumption is not satisfactory in the context of tempo-ral relation determination.
For example, if therelation between 1e  and 2e  is SAME_AS, 1e  and 2ehave to be identical.
We release the independenceassumption for 1e and 2e , and decompose the secondpart of (E2) as:),|()|(),|()|()|,()|,(1211212121ceePcePceePcePceePceeP =  (E4)Estimation of ),|( 12 ceep is motivated by AbsoluteDiscounting N-Gram language model (Goodman,2001):????
?=>?=0),,( if     )|(),(0),,( if),(),,(),|(12211211212ceeCcePceceeCceCDceeCceP e?
(E5)here D is the discount factor and is set to 0.5 experi-mentally.
From the fact that 1),|(212 =?eceeP , we get:??>>??=0),,(|20),,(|121122122)|(1),|(1),(ceeCeceeCecePceePce?
(E6))|( ctp i and )|( cep i  are estimated by MLE withDirichlet Smoothing method:?
?++=TtiiiiTuctCuctCctP||),(),()|(      ( ni ,...2,1= )(E7)?
?++=EeiiiiEuceCuceCceP||),(),()|(     ( 2,1=i )(E8)where u (=0.5) is the smoothing factor.
Then,)|( ctp i , )|( cep i and ),|( 12 ceeP  can be estimatedwith (E5) - (E8) by substituting c  with c .4.2 Estimating )|,...,( 21 ctttP n  with Lexical-POSInformationThe effects of a temporal indicator are constrainedby its positions in a sentence.
For instance, the con-junctive word ??
(because) may represent the dif-ferent relations when it occurs before or after the firstevent.
Therefore, in estimating )|,...,( 21 ctttp n , weconsider an indicator located in three positions: (1)BEFORE the first event; (2) AFTER the first eventand BEFORE the second and it modifies the firstevent; (3) the same as (2) but it modifies the secondevent; and (4) AFTER the second event.
Note thatcases (2) and (3) are ambiguous.
The positions of thetemporal indicators are the same.
But it is uncertainwhether these indicators modify the first or the sec-ond event if there is no punctuation (such as comma,period, exclamation or question mark) separatingtheir roles.
The ambiguity is resolved by using POSinformation.
We assume that an indicator modifiesthe first event if it is an auxiliary word, a trend wordor a position word; otherwise it modifies the second.Thus, we rewrite )|,...,( 21 ctttP n as ,,...,( 1111 nttP)|,...,,...,,,...,432 441331221ctttttt nnn , where jn is the totalnumber of the temporal indicators occurring in theposition j .
4,3,2,1=j  represents the four positionsand nnjj =?=41.
Assuming jit are independent of eachother, then ?=nii ctP1)|( in (E3) is revised as?
?= =41 1)|(jnijijctP .
Accordingly, (E7) is revised as:?
?++=TtjijijijiTuctCuctCctP||),(),()|(( 4,3,2,1=j  and jni ,...2,1= )(E7?
)In addition to taking positions into account, wefurther classify the temporal indicators into twogroups according to their grammatical categories orsemantic roles.
The rationale of grouping will bedemonstrated in Section 4.3.4.3 Experimental ResultsSeveral experiments have been designed to evalu-ate the proposed Bayesian Classifier in combininglinguistic features for temporal relation determinationand to reveal the impact of linguistic features onlearning performance.
700 instances are extractedfrom Ta Kong Pao (a local Hong Kong Chinesenewspaper) financial version.
Among them, 500 areused as training data, and 200 as test data, which arepartitioned equally into two sets.
One is similar astraining data in class distribution, while the other isquite different.
209 lexical words, gathered from lin-guistic books and corpus, are used as the temporalindicators and manually marked with the tags givenin Table 1.4.3.1 Impact of Individual FeaturesFrom linguistic perspective, the thirteen features(see Table 1) are useful for temporal relation deter-mination.
To examine the impact of each individualfeature, we feed a single linguistic feature to theBayesian Classifier learning algorithm one at a timeand study the accuracy of the resultant classifier.
Theexperimental results are given in Table 2.
It showsthat event classes have greatest accuracy, followedby conjunctions in the second place, and adverbs inthe third in the close test.
Since punctuation showsno contribution, we only use it as a syntactic featureto differentiate cases (2) and (3) mentioned in Sec-tion 4.2.4.3.2 Features in CombinationWe now use Bayesian Classifier introduced in Sec-tions 4.1 and 4.2 to combine all the related temporalindicators and event classes, since none of the fea-tures can achieve a good result alone.
The simplestway is to combine the features without distinction.The conditional probability )|( ctP ji is estimated by(E7?).
This model is called Ungrouped Model (UG).However, as illustrated in table 1, the temporal in-dicators play different roles in building temporal ref-erence.
It is not reasonable to treat them equally.
Weclaim that the temporal indicators have two functions,i.e., representing the connections of the clauses, orrepresenting the tense/aspect of the events.
We iden-tify them as connective words or tense/aspect mark-ers and separate them into two groups.
This allowsfeatures to be compared with those in the same group.Let ],[ 21 TTT = , where 1T is the set of connectivewords and 2T is the set of tense/aspect markers.
Wehave 111211 ,..,, Tttt m ?
and 222221 ,..,, Tttt l ?
, m and l arethe number of the connective words and thetense/aspect markers in a sentence respectively.
Weassume that the occurrences of the two groups areindependent.
By taking both grouping and positionfeatures into account, we replace ?=nii ctP1)|(  with??
?= = =2141 1)|(k jnikjikjctP , 2,1=k  represents the two groupsand jkkj nn =?=21.
To build the grouping-based Bayes-ian Classifier, (E7?)
is modified as:?
?++=kkji Ttkkjikjikji TuctCuctCctP||),(),()|(( 2,1=k , 4,3,2,1=j  and jni ,...2,1= )(E7??
)4.3.3 Grouping Features by Grammatical Cate-gories or Semantic RolesWe partition temporal indicators into connectivewords and tense/aspect markers in two ways.
One issimply based on their grammatical categories (i.e.POS information).
It separates conjunctions (e.g., ?
?, after; ?
?, because) and verbs relating to causal-ity (e.g., ?
?, cause) from others.
They are assumedto be connective words (i.e.
1T?
), while others aretense/aspect markers (i.e.
2T?
).
This model is calledGrammatical Function based Grouping Model (GFG).Unfortunately, such a separation is ineffective.
Incomparison with UG, the performance of GFG de-creases as shown in figure 2.
This reveals the com-plexity of Chinese in connecting expressions.
Itarises from the fact that some other words, such asadverbs (e.g., ??
?, meanwhile), prepositions (e.g.,?, at) and position words (e.g., ?
?, before), canalso serve such a connecting function (see Table 1).Actually, the roles of the words falling into thesegrammatical categories are ambiguous.
For instance,the adverb?
can express an event happened in thepast, e.g., ?????????
(He just finished thereport)?.
It can be also used in a connecting expres-sion (such as ????
), e.g., ?????????????
(He went to the library after he had finishedthe report)?.This finding suggests that temporal indicatorsshould be divided into two groups according to theirsemantic roles rather than grammatical categories.Therefore we propose the third model, namelySemantic Role based Grouping Model (SRG), inwhich the indicators are manually re-marked asTI_j_pos or TI_at_pos4.Figure 2 shows the accuracies of four models (i.e.DM.
UG, GFG and SRG) based on the three tests.Test 1 is the close test carried out on training dataand tests 2 and 3 are open tests performed on differ-ent test data.
DM (i.e., Default Model) assigns allincoming cases with the most likely class and it isused as evaluation baseline.
In our case, it isSAME_AS, which holds 50.2% in training data.SRG model outperforms UG and GFG models.These results validate our previous assumption em-pirically.4 ?j?
and ?at?
are the tags representing connecting and tense/aspectroles respectively.
?pos?
is the POS tag of the temporal indicator TI.Accuracy AccuracyFeature ClosetestOpentest 1Opentest 2Feature ClosetestOpentest 1Opentest 2VS 53.4% 48% 30% VA 57% 50% 37%VC 56.6% 56% 49% C 62.6% 52% 45%TR 50.2% 46% 28% U 51.8% 50% 32%P 52.4% 49% 30% T 57.2% 48% 32%PS 59% 53% 38% D 59.6% 55% 47%VV 51% 49% 29% EC 72.4% 69% 68%Table 2 Impact of each individual linguistic feature20%30%40%50%60%70%80%90%Close Test Open Test1 Open Test2AccuracyDM UG GFG SRGFigure 2 Comparing DM, UG, GFG and SRG models4.3.4 Impact of Semantic Roles in SRG ModelWhen the temporal indicators are classified intotwo groups based on their semantic roles in SRGmodel, there are three types of linguistic featuresused in the Bayesian Classifier, i.e., tense/aspectmarkers, connective words and event classes.
A setof experiments are conducted to investigate the im-pacts of each individual feature type and the impactswhen they are used in combination (shown in Table3).
We find that the performance of methods 1 and 2in the open tests drops dramatically compared withthose in the close test.
But the predictive strength ofevent classes in method 3 is surprisingly high.
Twoconclusions are thus drawn.
Firstly, the models usingtense/aspect markers and connective words are morelikely to encounter over-fitting problem with insuffi-cient training data.
Secondly, different features havevaried weights.
We then incorporate an optimizationapproach to adjust the weights of the three types offeatures, and propose an algorithm to tackle over-fitting problem in the next section.Method Semantic GroupsClosetestOpentest 1Opentest 21 Tense/aspect markers 71% 58% 40%2 Connective words 75% 65% 57%3 Event classes 66.6% 69% 68%4 1+2 84.8% 70% 56%5 1+3 76.6% 72% 66%6 2+3 82.4% 84% 81%7 1+2+3 89.8% 84% 80%8 Default 50.2% 46% 28%Table 3: Impact of Semantic Role based Groups5.
Weighted Bayesian ClassifierLet 1?
, 2?
, 3?
be the weights of event classes, con-nective words and tense/aspect markers respectively.Then the Weighted Bayesian Classifier is:????????),...,,,,|(),...,,,,|(log21212121nnttteecPttteecP????????+???????
?=)|,()|,(log)()(log21211 ceePceePcPcP ?
(E9)????????+???????
?+)|,...,,()|,...,,(log)|,...,,()|,...,,(log 2222122221311211112112 ctttPctttPctttPctttPllmm ?
?In order to estimate the weights, we need a suit-able optimization approach to search for the opti-mal value of ],,[ 321 ???
automatically.5.1 Estimating Weights with Simulated Anneal-ing AlgorithmQuite a lot optimization approaches are availableto compute the optimal value of ],,[ 321 ???
.
Here,Simulated Annealing algorithm is employed to per-form the task, which is a general and powerful opti-mization approach with excellent global convergence(Kirkpatrick, 1983).
Figure 3 shows the procedure ofsearching for an optimal weight vector with the algo-rithm.1.
1=k , )( 1?= kk tTt2.
Generates a random change from the current weight vec-tor iv .
The updated weight vector is denoted by jv .
Thencomputes the increasement of the objective function, i.e.
)()( ij vfvf ?=?
.3 Accepts jv as an optimal vector and substitutes iv with thefollowing accept rate:?????????
<>= 0 if  )exp(0 if             1)(kjitvvP4 If kLk < , lets 1+= kk , goes to step 2.5 Else if fk Tt < , goes to step 1.6 Else stops looping and outputs the current optimal weightvector.Figure 3 Simulated Annealing algorithmIn Figure 3, Markov chain length 20=kL ; tem-perature update function ttT *9.0)( = ; starting point],,[ 0302010 ??
?=v =[1,1,1]; initial temperature 200 =tand final temperature 810?=ft .
Note that the initialtemperature is critical for a simulated annealing algo-rithm (Kirkpatrick, 1983).
Its value should assurethat the initial accept rate is greater than 90%.5.2 K-fold Cross-ValidationThe accuracy of the classifier is defined as the ob-jective function of the Simulated Annealing algo-rithm illustrated in Figure 3.
If it is evaluated withthe accuracy over all training data, the WeightedBayesian Classifier may trap into over-fitting prob-lem and lower the performance due to insufficientdata.
To avoid this, we employ K-fold Cross-Validation technique.
It partitions the original set ofdata into K parts.
One part is selected arbitrarily asevaluating data and the other K-1 parts as trainingdata.
Then K accuracies on evaluating data are ob-tained after K iterations and their average is used asthe objective function.5.3 Experimental ResultsTable 4 shows the result of the experiment whichcompares WSRG (Weighted SRG) with SRG.
Weuse error reduction to evaluate the benefit from in-corporating weight parameters into Bayesian Classi-fier.
It is defined as:SRGWSRGSRGrateerrorrateerrorrateerror___reductionerror?=The experimental results show that the WeightedBayesian Classifier outperforms the Bayesian Classi-fier significantly in the two open tests and it tacklesthe over-fitting problem well.
To test Simulated An-nealing algorithm?s global convergence, we ran-domly choose several initial values and they finallyconverge to a small area [7.2?0.09, 5.8?0.02,3.0?0.02].
The empirical result demonstrates that theoutput of a Simulated Annealing algorithm is aglobal optimal weighting vector.6 ConclusionsTemporal reference processing has received grow-ing attentions in last decades.
However this topic hasnot been well studied in Chinese.
In this paper, weproposed a method to determine temporal relations inChinese by employing linguistic knowledge and ma-chine learning approaches.
Thirteen related linguisticfeatures were recognized and temporal indicatorswere further grouped with respect to grammaticalfunctions or semantic roles.
This allows features tobe compared with those in the same group.
To ac-commodate the fact that the different types of fea-tures support varied importance, we extended Na?veBayesian Classifier to Weighted Bayesian Classifierand applied Simulated Annealing algorithm to opti-mize weight parameters.
To avoid over-fitting prob-lem, K-fold Cross-Validation technique was incorpo-rated to evaluate the objective function of the optimi-zation algorithm.
Establishing the temporal relationsbetween two events could be extended to provide adetermination of the temporal relations among multi-ple events in a discourse.
With such an extension,this temporal analysis approach could be incorpo-rated into various NLP applications, such as questionanswering and machine translation.AcknowledgementsThe work presented in this paper is partially sup-ported by Research Grants Council of Hong Kong(RGC reference number PolyU5085/02E) and CUHKStrategic Grant (account number 4410001).ReferencesAllen J., 1983.
Maintaining Knowledge about TemporalIntervals.
Communications of the ACM, 26(11):832-843.Brent M., 1990.
A Simplified Theory of Tense Repre-sentations and Constraints on Their Composition, InProceedings of the 28th Annual Conference of the As-sociation for Computational Linguistics, pages 119-126.
Pittsburgh.Bruce B., 1972.
A Model for Temporal References andits Application in Question-Answering Program.
Arti-ficial Intelligence, 3(1):1-25.Dorr B. and Gaasterland T., 2002.
Constraints on theGeneration of Tense, Aspect, and Connecting Wordsfrom Temporal Expressions.
submitted to Journal ofArtificial Intelligence Research.Duda, R. O. and P. E. Hart, 1973.
Pattern Classificationand Scene Analysis.
New York.Friedman N., Geiger D. and Goldszmidt M., 1997.Bayesian Network Classifiers.
Machine Learning29:131-163, Kluwer Academic Publisher.Goodman J., 2001.
A Bit of Progress in Language Mod-eling.
Microsoft Research Technical Report MSR-TR-2001-72.Hitzeman J., Moens M. and Grover C., 1995.
Algo-rithms for Analyzing the Temporal Structure of Dis-course.
In Proceedings of the 7th European Meetingof the Association for Computational Linguistics,pages 253-260.
Dublin, Ireland.Hornstein N., 1990.
As Time Goes By.
MIT Press, Cam-bridge, MA.Kirkpatrick, S., Gelatt C.D., and Vecchi M.P., 1983.Optimization by Simulated Annealing.
Science,220(4598): 671-680.Knight B. and Ma J., 1997.
Temporal Management Us-ing Relative Time in Knowledge-based Process Con-trol, Engineering Applications of Artificial Intelli-gence, 10(3):269-280.Langley, P.W.
and Thompson K., 1992.
An Analysis ofBayesian Classifiers.
In Proceedings of the 10th Na-tional Conference on Artificial Intelligence, pages223?228.
San Jose, CA.Lascarides A. and Asher N., 1991.
Discourse Relationsand Defensible Knowledge.
In Proceedings of the 29thMeeting of the Association for Computational Lin-guistics, pages 55-62.
Berkeley, USA.Li W.J.
and Wong K.F., 2002.
A Word-based Approachfor Modeling and Discovering Temporal RelationsEmbedded in Chinese Sentences, ACM Transactionon Asian Language Processing, 1(3):173-206.Moens M. and Steedmen M., 1988.
Temporal Ontologyand Temporal Reference.
Computational Linguistics,14(2):15-28.Passonneau R., 1988.
A Computational Model of theSemantics of Tense and Aspect.
Computational Lin-guistics, 14(2):44-60.Reichenbach H., 1947.
The Elements of Symbolic Logic.The Free Press, New York.Siegel E.V.
and McKeown K.R., 2000.
Learning Meth-ods to Combine Linguistic Indicators: Improving As-pectual Classification and Revealing Linguistic In-sights.
Computational Linguistics, 26(4):595-627.Singh M. and Singh M., 1997.
On the Temporal Struc-ture of Events.
In Proceedings of AAAI-97 Workshopon Spatial and Temporal Reasoning, pages 49-54.Providence, Rhode Island.Webber B., 1988.
Tense as Discourse Anaphor.
Compu-tational Linguistics, 14(2):61-73.Yarowsky D., 1994.
Decision Lists for Lexical Ambi-guity Resolution: Application to the Accent Restora-tion in Spanish and French.
In Proceeding of the 32ndAnnual Meeting of the Association for ComputationalLinguistics, pages 88-95.
San Francisco, CA.Error RateModelClose Test Open Test1 Open Test2SRG 10.2% 16% 20%WSRG 12.4%% 11% 13%Error Reduction -21.57% 31.25% 35%Table 4 Compare WSRG with SRG on error rates
