Chinese Word Segmentat ionbased on Max imum Matching and Word Binding ForcePak-kwong Wong and  Chork in  ChanDeI )ar tment  of Computer  Scien(;(~The  Univ(;rsil;y of I tong  Kongl )ok fu lam ih)a,dthmg Kongpkwong((~cs.hku.hk and  ( :chan?~cs.hku.hkAbst ractA Chinese word Seglnentation algorithmbased on forward icnaxinnlln matchingand word binding force is t)roposed inthis pai)er.
This algorithm Iilays a keyrole in post-processing the outtmt of acharacter or st/eech recognizer in deter-mining the proper word sequence c(/rre-st)onding to an input line of cha.raeterimages or a speech wav(~,fol'tn.
~FO sup-port this algorithm, a text; (:orims of over63 millions characters i employed to en-rich an 80,O00-words lexi(:on in terlns ofits word entries and word binding forces.As it stands now, given an input line oftext, the word segmentor can proce, ss onthe average 210,000 characters per se(:-ond when running on an IBM RISC Sys-tem/6000 3BT workstation with a co lrect word identitication rate of 99.74%.1 In t roduct ionA language model as a t)ost-processor is esse, ntialto a recognizer of speech or characters in orderto determine the approi)riate word se, que, n(:e andhenc.e the semantics of an inI)ut line of text or ut-terance.
It is well known that an N-gram statisticslanguage model is just as effective as, t)ut nmchmore eificient than, a syntactk:/semantic analyserin determining the correct word sequence.
A nec-essary condition to successflfl collection of N-gramstatistics is the existence of a coInprehensive l ,x-icon and a large text corpus.
The latter musttie lexically analysed in order to identify all thewords, from which, N-gram statistics can be de-rived.About 5,000 characters are being used in mod-ern Chinese and they are the building blocks of allwor(ls.
Ahnost every character is a word and inostwords are of one or two characters long but thereare also abundant wor(ls longer than two charac-ters.
Before it; is seginented into words, a line oftext is just a sequence of characters and there arenumerous word segmentation alternatives.
Usu-ally, all but one of these alternatives arc syntac-tically and/or semantically incorrect.
This is l;hecase because unlike texts in English, Chinese texl;shave no word nlarkers.
A tirst step towmds buiht-ing a language model based on N-gram statistics isto de, vek)p an etIMent lexical analyser to id(!ntifyall the words in the, corpus.Word segmentation algorithlns behmg to one oftwo types ill general, viz., the structural (Wang etal., 1991) and the statistical type (Lua, 1990)(Luaand Gan, 1994)(Sproat and Shih, 1990) rt;spec-tively.
A structural algorithm resolves egmenta-tion mnbiguities by examining the structural rcla-tionships between words, while a statistical algo--rithm compares the usage flequencies of the wordsand their ordered combinations inste, ad.
Both ap-proaches ln~ve serious liinitat;ions.2 Max imum Match ing  Method forSegmentat ionMaximum matching (l,iu et al, /994) is one of themost I)opular structural segmentation algorithmsfor Chinese texts.
This method favours long wordsan(1 is a gree(ty algorithm by (lesign, hen(:e, sub-optimal.
Segmenl;ation may start from either endof the line without any difference in segmenta-tion results.
In this paper, the forward directionis adopted.
The major advantage of inaximummatching is its etHciency while its segmentationaccuracy can be expected to lie around 95%.3 Word  F requency  Method forSegmentat ionIn this statistical approach in terms of word fre-quencies, a lexicon needs not only a rich repertoireof word entries, lint also the usage frequency ofe, ach word.
To segment a line of text, each possi-ble segmentation alternative is ewduated accord-ing to the product of the word fi'equencies of thewords Seglnented.
The word sequence, with thehighest fi'equency product is accepted a.s correct.This method is simple but its a(:curacy (h,,lmndsheavily on the accuracy of the usage fi'equencies.The usage frequency of a word differs greatly from200one tytm (t\[ do(:umcnts to a.noth(n', say, a l)assag(:of world news as a,ga,hlsl; a, t(',(:hnical r(~,port.
Sil~c('~(,here, a.r('.
I;(uls o\[ l,h(/llsa.Ii(ls o\[ words a,cl;ively us('.
(l,Oil(', nc(;ds a giganti(: (:oll(~(:ti(ll: ()f texts to mak(~;m a,(',(:urat,(~ estimal;(~, l int t)y t;h(~.u, the  (~stimat;(~is jusl, an averag(~ a,n(l it; ma.y not; t)(,, suital)le forany tyt)(!
(/\[ (h)(:mn(mt at all.
/n oth(n' words, 1,}mvariml(:(~ of ml(:h &ll (~st;illl~tl;(~ is to() great makingI;h(; (~stiirlat(!
l ist less.4 The LexiconMost  Chines(;  l inguists ac(',(;1)t he (h',:linition of awor(1 as thc min imum unit tha,t is scmanticMly(',omt/h',t(~ and (',all lie, I)Ut; tog('%her as t/uihtingt)lo('ks to form a, sent(ulc(u llow(:vex, in Chines(:,wor(ls can t)(~ unit(:d t(/ fi)rm (:Oml)()mM words,a.n(l they in turn, (',;/.
): (:oral/in(: furth(',r 1:() t'()rm 3,('.1,higher (>r(lcr('d (:omt)(/und words.
As ;1 ma.tt(~r oft~lC\[;~ COlllI)o1111(l WOl'ds ,~LI'(; ~,xtr(un(~ly C(/IlllllOIl ;/11(~they exist in large numbers.
R is imI)ossit)h', t;(/in(:lud(', all (:Olil\[)()lllld words into the, h!xi(:(m t)utjust to kcc t) (,host: which are  \['re(tu(;nt;ly Uso(l a,n(iha.v(', the word (:omtl(mcnts unit('d clos(',ly.
A lex-icon was at:quirt;(1 from th(; Inst;il;ulx'~ o\[ \[nf()rm;l-t;i()ii S(;i(~,ll(:(~,, Acad(',nlia, Sini(:a. in Taiwan.
Thcr('~are 78410 word (mtri(:s in l:his h~xi(:(tn, (~n(:h associ-ated with a usage frextu(;n(:y.
A (:O:'lnls (/t: over 63mill ion (:hara('.t(:rs o\[ news lines was acquired \[romChina.
l)u(~ t(/ (:ultural difl'(:r(m(:(:s of tim two st)-(:i('t;ios, there arc many words en(:(nmt(~r(:(1 in th(:(:()rpllS t)llt II()t in t:h(~ lexi(:on, rl'h(!
lal;t(!r mustt, heretbre lie em'ichcd 1)efor(~ it can 1)e a t)pli(:d 1:(/t)(wt'orln the lexical a.nalysis.
The tits( st, el/ t()-wa,r(ls this end is to merge a h~xi(:(m l/ut)lishcd inChina into this one, in(:r(',asing the numt)(u' of wordent;ries to 85,855.5 The  Proposed  WordSegmentation AlgorithmTllc t)rot/os(:d a lgor i thm of this t)al>(:r makes use (t\['a f(/rward ma.ximmn matching st, ra.t(;gy to i(hultifyw()r(\[s, In this r(:sl)(~(:l; ~ this a lgor i thm is a struc-tural  atll)roa(:h. (hMer this sl;ratcgy, errors are,usually a.ssot;iated with singh',-(:haract(~r words, illth('~ first (:hm'a,(:ter (if a litm is i(hmtili(~d ns a single-(:haract(~r word, what  it nlcans is that; ther(~ isno mult i -character  word entry in the l(~xi(:on th;d;starts  with such a chara(:tcr.
In that  case, there isnot much on(, can do about  it,.
On the other hand,when a character  is khmtifie, d as a single-cha.ra(:tcrword fl following another word (t in th(: line, one(:annot he, ltl wondca.'
ing whether tim sole chm'acter(:omt)osing/~ shouhl not 1)(', combined with th(' suf-fix of (t to form another word instea.d, even il thatmetals ('hanging (~ int() a shorter w(tr(\[.
In thatcase, every t)ossil/h~ w(/rd sO,(lll(~n(;(?
a l ternat ive  (:or-respond ing  to the  Sllt)-s(:qilo, i icc of (;hari-l(:t(ws fr()illc~ and /3 together will 1)e evaluated according tothe produ(:t o\[ its const i tuent word binding for(',es.Tt le  binding force of a. wor(l is a. rues.sure of howstrongly the charact(',rs conll)osing th(,, word arebound t()g(~ther as a single unit;.
This for(x: is oLten equated to tim usage fr(~qu(mcy of the word.In this l'(!Sl)(:(;l; , the pr()l>()s(;(1 algorit lun is a, sta.tis-ti(:al apl)roach.
It is as (,,tti(:i(:nt as tim maximumlna.tching moth(/(1 I)(~(;aus(!
wor(l binding f()r(:(!s ;u'(~uti l ized only in (,x(:(~pti(mal cases, th)w(wer, muchof the word amt/iguities are climilmt(~d, h~a(lingto a vc'ry high word identif ication accuracy.
S('g-m(:ntation errors ass(/ciat('d with multi-cha.ract(,,rwords can 11(: r(~(h:(:cd 1)y adding or (leh~ting woMsto or from the h',xi(:on as well as adjust ing wordt)in(ling forces.6 St ructure  o f  the  Lex iconWords  in the h:xi(-(in are divided into 5 groupsa, ccording to woM h;ngths.
They corr(:spond towords ()t' l ,  2, 3, 4, and more than 4 cha,ra(>ters with group sizes equal t() 7025, 53532, 12939,11269, and 1090 rt;stmctively.
Since iilOSt of tlw,l;iule spent ill mm,lyzing a line, o\[ text is ill l indinga match among the h;xicon (',ntries, a chwcr or-ganizat ion o\[ the lexicon Slmcds up the s(',mching1)rot'(~ss trclnc, lMously.
Most Chin(,a*, words are o\[(mr: or two cha.racJx;rs ()lily.
Search ing  for l(mg(!rWOl:dS I)(~\['Ol(: sho l t (w OliOS ~/s ln 'at : t ised iu ma.xi-mum nu:tching recalls Sl)en(ling a great ileal oft ime s(,,arching for ram-existent; argets.
To over-come this problem, I;11(', following measur(',s arc,takc, n to organize tim h:xicon for fast s(:m'(:h:?
All sinp;h; (:ha.la.c.t,(:r w()t'(t,q a,l.O, sI;or(;d ill ;-/ I;a-ble of 32768 bins.
Since tilt; itll;Cl'llld cod(: Ofa cha.rat'tcr takes 2 bytes, bits l -15 m'e usedas th(!
bin address for the, wor:l.?
All 2-charat't(',r words are stored ill a se, parat(;tabh: of 655"{6 bins.
'I'll(', two low order bytesof the two (:hara(:ttn's arc used as a short iwt:(:g(',l" for bin address.
Should t\]mrt~ be otherwords (:ont(',sting for the, same biu, they a, rekept in a linked list.?
Any 3-ttha.ra, cl;t;r word is split into a 2-(',ha.ra,('.t(;r p e\[ix and a, i\[-chara(:ter sutlix.
Theprt!lix will tm si,ored in the bin tabh: for 2-('\]lar~l(:t(',r words with (:lear indi(:ation of itsl)rcfix st&(liB.
Thc Sill\[ix will bc stored in thebin table for l-(:harac, t(:r words, again, wiLhclear indicat ion of its suffix status.
All (tut/li-(;ate entries are coral)trier1, i.e., if (~ is a wordas well as a suflix, tilt; two entries arc com-bined into one with a,n indicat ion that it; canserve as a word as well as a suffix.?
Any d-t:haract;ex word is divided up into a 2-chara(',ttu" prefix and a 2-(:haract(n' suffix, 1)othstored in tile bin table :\[or 2-character words,with ch:ar indications of tll(;ir r('~spc(:tivc sta-tus.
Each prefix po ints  to a link(;d list of as-soc iated suffixes.201?
Any word longer than 4 characters will be di-vided into a 2-character prefix, a 2-characterinfix and a suffix.
The prefix and tile infix arestored in the bin table for 2-character words,with clear indications of their status.
Eachprefix points to a linked list of associated in-fixes and each infix in turn, points to a linkedlist of associated suffixes.Maximum matching segmentation of a sequenceof characters "...abcdefghij.. 2' at the character "a"starts with matching "ab" against he 2-characterwords table.
If no match is found, then, "a" is as-sumed a 1-character word and maximum match-ing moves on to "b".
If a match is found, then,"ab" is investigated to see if it can be a prefix.If it cannot, then "ab" is a 2-character word andmaximum matching moves on to "c".
If it can,then one examines if it can be associated with aninfix.
If it can, then one examines if "cd" can bean infix associated with "ab".
If the answer isnegative, then the possibility of "abed" being aword is considered.
If that fails again, then "c"in the table of 1-character words is examined tosee if it can be a suffix.
If it; can, then "abe" willbe examined to see if can be a word by search-ing the 1-chara(q;er suffix linked list pointed at by"ab".
Otherwise, one has to accept hat "ab" is a2-character word and moves on to start Inatchingat "c".
If "cd" can be an infix preceded by "ab",the linked list pointed at; by "cd" as an infix willbe searched for the longest possible sutfix to com-bine with "abed" as its prefix.
If no match can befound, then one has to give up "cd" as an infix to"ab':.7 Tra in ing of  the  SystemDespite the fact thai; the lexicon acquired fromTaiwan has been augmented with words fl'om an-other lexicon developed in China, when it is ap-plied to segment 1.2 million chm'acter news pas-sages in blocks of 10,000 characters each randomlyselected over the text corpus, an average word seg-inentation error rate (IZ) of 2.51% was found witha standard deviation (c,) of 0.57%, mostly causedby uncommon words not included in the enrichedlexicon.
Then it is decided that the lexicon shouldbe fllrther enriched with new words and adjustedword binding forces over a number of generations.In generation i, n new blocks of text are pickedrandomly from the corpus and words segmentedusing the lexicon enriched in the previous genera-tion.
This process will stop when I* levels off overseveral generations.
The 100(1 - a)% confidenceinterval of t* in generation i is :tzto.a~,~,__l~r/v~where a is the standard deviation of error ratesin generation i -  1, and n is the number of blocksto be segmented in generation i. to.5~,n-1 is thedensity function of (0.5a, n - 1) degrees of free-dom(Devore, 1991).
Throughout he experimentsbelow, n is always chosen to be 20 so that the 90%confidence interval (i.e., (t = 0.1) of t z is about:k0.23%.8 Exper imenta l  Resu l tsThe lexicon has been updated over six generationsafter being applied to word segment 1.2 millioncharacters.
Tile vocabulary increases from 85855words to 87326 words.
The segmentation errorrates over seven generations of the training processare shown in the table below:LexiconGenerationNumberError Rate 1 ~, over a textof 200 000 CharactersMax.
Mat;.5.71%5.20%4.66%- 4U~Sg-0 --2.60%2.4:7%Max.
Mat.
~Word Bind.
t~brce2.32%- -2.16070------1.88%1.69,%---0.43%0.30%6 2.44% 0.26%Most of these errors occur in proper nouns notincluded in the lexicon.
They are hard to avoidunless they become l)opular enough to be addedto the lexicon.
The CPU time used for segmentinga text; of 1,200,000 characters i 5.7 seconds on anIBM I{ISC System/6000 3BT computer.9 Conc lus ionLexical analysis is a basic process of analyzing andunderstanding a language.
The proposed algo-rithm provides a highly accurate and highly effi-cient way for word segmentation of Chinese texts.Due to cultural differences, tile same languageused in different geographical regions and difl'crentapplications can be quite diffferent causing prob-lems in lexical analysis.
However, by introducingnew words into and adjusting word binding threesin the lexicon, such difficulties can be greatly mit-igated.This word segmentor will be applied to wordsegment the entire corpus of 63 million charactersbefore N-gram statistics will be collected for post-processing recognizer outputs.ReferencesJay L. Devore.
1991.
Probability and Statisticsfor Engineering and Sciences.
Du:rbury Press,pages 272 276.Ynan Liu, Qiang Tan, and Kun Xu Shen.
1994.The Word Segmentation Rules and AutomaticWord Segmentation Methods for Chinese Infor-mation Processing (in Chinese).
Qing Hua Uni-versity Press and Guang Xi Science and Tee\]t-nology Press, page 36.202Kim-Teng Lua mid Kok-Wcc Gan.
1994.
AnApplicat;ion of \]nibrmal;ion Theory in (\]hincso.Word Segmental:ion.
Comp'ttter l'~'oce,,ssi'lzg ofCh, incsc and Or'ienlal Languages, Vol.
8, No.
1,pages 115 123, 2unc'.K.T.
lma.
1990.
From Chm'aclx',r l;o Word AnAt)plication of hfformai;ion Theory.
ComputerProccssin 9 of Chinese and Oriental Languages,Vol.
4, No.
4, pages 304 313, March.Limtg-Jyh Wm~g, Tzusheng l'ei, Wci-(\]huan IA,and Lih-Ching 11,.
Ilmmg.
1991.
A ParsingMethod for hh',ntit~ying Words in Mandarin Chi-nes(,, S('m~(,am(,~s.
In l'roccssiugs of 121,h lnt(:>'national ,loin/, Conference on Artificial httelligcncc, pages 1018 1.023~ l)~rrling IIarl)our, Syd-ney, Austr~dia, 24-30 August.l{ictmrd Sproat ~md Chilin Shih.
1990.
A St, ads-deal Method for Finding Word Boundaries inChinese Text.
Computer l'rocessin.q of Uhineseand Oriental Lo, n.q,tta.qes, Vol.
4, No.
4, pages336 349, Mm'ch.203
