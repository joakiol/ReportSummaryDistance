Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 364?368, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsAMI&ERIC: How to Learn with Naive Bayes and Prior Knowledge:an Application to Sentiment AnalysisMohamed Dermouche1,2, Leila Khouas1,1AMI Software R&D1475 av.
A. Einstein34000 Montpellier, Francemde@amisw.comlkh@amisw.comJulien Velcin2 and Sabine Loudcher22Universite?
de Lyon, ERIC (Lyon 2)5 av.
P. Mende`s-France69676 Bron Cedex, Francejulien.velcin@univ-lyon2.frsabine.loudcher@univ-lyon2.frAbstractIn this paper, we describe our system that par-ticipated in SemEval-2013, Task 2.B (senti-ment analysis in Twitter).
Our approach con-sists of adapting Naive Bayes probabilities inorder to take into account prior knowledge(represented in the form of a sentiment lex-icon).
We propose two different methods toefficiently incorporate prior knowledge.
Weshow that our approach outperforms the clas-sical Naive Bayes method and shows compet-itive results with SVM while having less com-putational complexity.1 IntroductionWith the advent of Internet microblogging, socialnetworks, like Twitter1 and Facebook2, have broughtabout a real revolution in our way of communi-cating.
People share their opinions of everydaylife without taboos or restrictions thanks to theanonymity offered by these tools, which makes thema valuable source of information rather rich of sub-jective data.
These data can be mined using sen-timent analysis as a means to understand people?sfeelings towards a political cause or what people arethinking about a product or a service.
Recent worksshowed that Twitter sentiments can be correlated tobox-office revenues (Asur and Huberman, 2010) orpolitical polls (O?Connor et al 2010).Machine learning methods, like Naive Bayes(NB) and Support Vector Machines (SVM), havebeen widely used in sentiment analysis (Pang et al1http://www.twitter.com/2http://www.facebook.com/2002; Pak and Paroubek, 2010).
One major problemwith these methods, and in particular NB, is that themodel is built only on the learning data which canlead to overfitting.
In this paper, we describe our ap-proach that participated in SemEval-2013, Task 2.B(sentiment analysis in Twitter) (Wilson et al 2013).Our approach consists of learning with both NB andprior knowledge.
We show that our approach out-performs the classical NB method and gives com-petitive results compared to SVM while having lesscomputational complexity.The remainder of this paper is organized as fol-lows: prior works on sentiment analysis are dis-cussed in Section 2.
The proposed approach is de-tailed in Section 3.
Then, experiments and resultsare given in Section 4 and 5.2 BackgroundSentiment analysis is a text mining task which dealswith the feelings expressed explicitly or implicitlyin a textual content.
It concerns subjectivity anal-ysis (subjective/objective), opinion mining (posi-tive/negative/neutral), strength analysis, etc.
Al-though the term ?sentiment analysis?
includes allthese tasks, it often refers to opinion mining.
Sen-timent analysis methods can be categorized into ma-chine learning, linguistic and hybrid methods.Machine learning methods are usually supervised.A model is built based on a learning dataset com-posed of annotated texts and represented by a bag ofwords.
The model is then deployed to classify newtexts.
Pang et al(2002) use machine learning meth-ods (NB, SVM and MaxEnt) to detect sentiments onmovie reviews.
Pak and Paroubek (2010) use NB to364perform sentiment analysis on Twitter data.Linguistic methods use lexicons and manually-crafted rules to detect sentiments.
Kennedy andInkpen (2006) use syntactic analysis to capture lan-guage aspects like negation and contextual valenceshifters.
Other works (Turney and Littman, 2003;Kamps et al 2004) propose to use a term similaritymeasure which can be statistical (e.g., Mutual Infor-mation, LSA) or semantic (e.g., WordNet-based).Hybrid methods use both statistical and linguisticapproaches.
Esuli and Sebastiani (2011), which isthe closest work to ours, propose to use annotatedlexical resources to improve opinion extraction.
Thebag-of-word text representation is enriched by newtags (e.g.
subjectivity, polarity).
Then, an SVM-based system is used for opinion classification.3 Our approachNB is a machine learning method that builds a clas-sification model based only on the learning datawhich makes it highly dependent on this data.
Forexample, in a sentiment analysis task, if the termactor appears more frequently within a negativecontext than in a positive one, it will be classified asnegative while actually it is not.
Moreover, NB tendssometimes to predict the class of majority (observedon learning data) which increases classification er-rors on unbalanced data.
Our approach consists ofincorporating prior knowledge into the NB model tomake it less dependent on learning data.To be efficiently used, prior knowledge must berepresented in a structured form.
We choose, here,to represent it by a sentiment lexicon (a set of pos-itive and negative terms).
Several lexicons have al-ready been developed to address sentiment analysisissues.
Some of them are publicly available like theMPQA subjectivity lexicon (Wilson et al 2005),Liu?s opinion lexicon (Ding et al 2008), Senti-WordNet (Esuli and Sebastiani, 2006).
We believethat such knowledge can be quite useful if used cor-rectly and efficiently by machine learning methods.In the following, we settle for a 2-way classi-fication task (positive vs. negative).
Texts arerepresented by a vector space model (Salton etal., 1975) and terms are weighted according totheir presence/absence in the text because previousworks (Pang et al 2002; Pak and Paroubek, 2010)showed that Boolean model performs better thanother weighting schemes in sentiment analysis.
Wedenote by w and w?
the presence, respectively ab-sence, modality of a word w. A ?term?
stands, here,for any type of text features (smileys, n-grams).3.1 Sentiment lexiconWe represent the prior knowledge by a 2-class sen-timent lexicon: a list of subjective terms (words,n-grams and smileys) manually annotated with twoscores: positive (scorec+) and negative (scorec?
).Each term has a score of 1 on a class polarity (we callit right class) and 0 on the other one (wrong class).For example, the word good has scorec+ = 1 andscorec?
= 0.
Then, c+ is the right class of the wordgood and c?
is the wrong class.3.2 NB methodNB is based on calculating class-wise term prob-abilities on a learning dataset D where each textd ?
D is annotated with a class c ?
{c+, c?}.
Inthe learning step, probability values p(w|c) are esti-mated from D as follows:p(w|c) =1nb(c)?
nb(w, c) (1)Where nb(c) denotes the number of texts of class cand nb(w, c) is the number of texts of class c thatcontain the term w.Once these probabilities are calculated for eachcouple (w, c), the model can be used to classify newtexts.
We choose to assign a new text d to theclass that maximizes the probability p(c|d).
UsingBayes?
theorem and independence assumption be-tween term distributions, this probability is calcu-lated as follows (the denominator can be droppedbecause it is not dependent on the class c):p(c|d) =p(c) ?
?w?d p(w|c)p(d)(2)3.3 Incorporating prior knowledgePrior knowledge is incorporated by adapting NB for-mulas.
We propose two different methods to do this:Add & Remove and Transfer.
These methods differin the way to calculate the class-wise term proba-bilities p(w|c) but use the same classification rule:class(d) = arg maxc?{c+,c?}
p(c|d).365Add & Remove.
This method consists of artifi-cially adding some occurrences of term w to theright class and removing some occurrences from thewrong class.
The lexicon is used to determine foreach term its right and wrong classes.
To ensurethat probability values do not exceed 1, we introducenb(w?, c), the number of texts of class c that do notcontain the term w, which is also equal to the maxi-mum number of occurrences of w that can be addedto the class c. Thus, the number of added occur-rences is a ratio ?c of this maximum (0 ?
?c ?
1).Likewise, if c was the wrong class of w, the numberof removed occurrences from the class c is a ratio ?cof the maximum number that can be removed fromthe class c, nb(w, c), with 0 ?
?c ?
1.
Formally,term probabilities are calculated as follows:p(w|c)=1nb(c)?
[nb(w, c)+?c ?scorec(w)?nb(w?, c)?
?c ?
scorec?
(w) ?
nb(w, c)] (3)Transfer.
This method consists of transferringsome occurrences of a term w from the wrong classto the right class.
The number of transferred occur-rences is such that the final probability is not greaterthan 1 and the number of transferred occurrences isnot greater than the actual number of occurrences inthe wrong class.
To meet these constraints, we in-troduce max(w, c): the maximum number of occur-rences ofw that can be transferred to the class c fromthe other class c?.
This number must not be greaterthan both the number of texts from c?
containing wand the number of texts from c not containing w.max(w, c) = min{nb(w, c?
), nb(w?, c)} (4)Finally, the number of occurrences actually trans-ferred is a ratio ?c of max(w, c) with 0 ?
?c ?
1.Term probabilities are estimated as follows:p(w|c)=1nb(c)?
[nb(w, c)+?c?scorec(w)?max(w, c)?
?c ?
scorec?
(w) ?max(w, c?)]
(5)Both methods, Add & Remove and Transfer, con-sist of removing occurrences from the wrong classand adding occurrences to the right class with thedifference that in Transfer, the number of added oc-currences is exactly the number of removed ones.4 Experiment4.1 Sentiment lexiconFor SemEval-2013 contest (Wilson et al 2013),we have developed our own lexicon based on Liu?sopinion lexicon (Ding et al 2008) and enrichedwith some ?microblogging style?
terms (e.g., luv,xox, gd) manually collected on the Urban Dic-tionary3.
The whole lexicon contains 7720 Englishterms (words, 2-grams, 3-grams and smileys) where2475 are positive and 5245 negative.4.2 Dataset and preprocessingTo evaluate the proposed approach, we useSemEval-2013 datasets: TW (tweets obtained bymerging learn and development data) and SMS, inaddition to MR (English movie reviews of Pang andLee (2004)).
Concerning SMS, the classification isperformed using the model learned on tweets (TW)in order to assess how it generalizes on SMS data.Note that our approach is adapted to binary clas-sification but can be used for 3-way classification(which is the case of TW and SMS).
We do thisby adapting only positive and negative probabilities,neutral ones remain unchanged.Texts are preprocessed by removing stopwords,numerics, punctuation and terms that occur onlyonce (to reduce vocabulary size and data sparse-ness).
Texts are then stemmed using Porter stemmer(Porter, 1997).
We also remove URLs and Twitterkeywords (via, RT) from tweets.4.3 ToolsAs we compare our approach to SVM method,we have used SVMmulticlass (Crammer and Singer,2002).
For a compromise between processing timeand performance, we set the trade-off parameter c to4 on MR dataset and 20 on TW and SMS (based onempirical results).5 Results and discussionIn addition to the two proposed methods: Add &Remove (A&R) and Transfer (TRA), texts are clas-sified using NB and SVM with two kernels: linear(SVM-L) and polynomial of degree 2 (SVM-P).
Allthe scores given below correspond to the average3http://www.urbandictionary.com/366F-score of positive and negative classes, even for3-way classification.
This measure is also used inSemEval-2013 result evaluation and ranking (Wil-son et al 2013).5.1 General resultsGeneral results are obtained only with unigrams andsmileys.
Figure 1 presents the results obtained onthe different datasets on both 2-way (left) and 3-way (right) classifications.
For 2-way classification,neutral texts are ignored and the model is evaluatedusing a 5-fold cross validation.
For 3-way classifi-cation, the model is evaluated on the provided testdata.
Compared with NB, our approach performsbetter on all datasets.
It also outperforms SVM, thatachieves poor results, except on MR.Method 2-class 3-classTW MR TW SMSNB 74.07 73.06 59.43 48.80SVM-L 49.79 74.56 37.56 32.13SVM-P 49.74 84.64 37.56 32.13A&R 76.05 80.57 60.57 49.42TRA 76.00 75.53 60.27 51.35Figure 1: General results (unigrams and smileys)Parameter effect.
To examine the effect of pa-rameters, we perform a 2-way classification on TWand MR datasets using 5-fold cross validation (Fig-ure 2).
We take, for A&R method, ?c+ = ?c?
= 0and for both methods, ?c+ = ?c?
(denoted ?
).This configuration does not necessarily give the bestscores.
However, empirical tests showed that scoresare not significantly lower than the best ones.
Wechoose this configuration for simplicity (only oneparameter to tune).Figure 2 shows that best scores are achieved withdifferent values of ?
depending on the used method(A&R, TRA) and the data.
Therefore, parametersmust be fine-tuned for each dataset separately.5.2 SemEval-2013 resultsFor SemEval-2013 contest, we have enriched textrepresentation by 2-grams and 3-grams and usedA&R method with: ?c+ = ?c?
= 0.003, ?c+ =0.04 and ?c?
= 0.02.
All of these parameters havebeen fine-tuned using the development data.
Wehave also made an Information Gain-based feature0.0010.00250.0050.01 0.02 0.03 0.05 0.07 0.08 0.09 0.1 0.15 0.2 0.2570758085?F-score0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.970758085TW MR?F-scoreFigure 2: Effect of the parameter ?
on a 2-way classifica-tion using methods: A&R (top) and TRA (bottom)selection (Mitchell, 1997).
Only the best 2000 termsare kept to which we have added terms of the lexi-con.
Under these conditions, our approach achievedthe scores 62.55% on tweets (ranked 6th/35) and53.63% on SMS (ranked 9th/28).Dataset Class Pecision Recall F-scorepositive 62.12 74.49 67.75TW negative 46.23 75.54 57.36neutral 76.74 44.27 56.15positive 39.59 78.86 52.72SMS negative 45.64 67.77 54.55neutral 90.93 39.82 55.38Figure 3: SemEval-2013 results (A&R method)Regarding F-score of each class (Figure 3), ourapproach gave better results on the negative class(under-represented in the learning data) than NB(49.09% on TW and 47.63% on SMS).6 ConclusionIn this paper, we have presented a novel approachto sentiment analysis by incorporating prior knowl-edge into NB model.
We showed that our approachoutperforms NB and gives competitive results withSVM while better handling unbalanced data.As a future work, further processing may be re-quired on Twitter data.
Tweets, in contrast to tra-ditional text genres, show many specificities (shortsize, high misspelling rate, informal text, etc.
).Moreover, tweets rely on an underlying structure(re-tweets, hashtags) that may be quite useful tobuild more accurate analysis tools.367ReferencesSitaram Asur and Bernardo A. Huberman.
Predict-ing the future with social media.
In Proceedings ofthe 2010 IEEE/WIC/ACM International Conferenceon Web Intelligence and Intelligent Agent Technology(WI-IAT?10), pages 492?499, Washington, DC, USA,2010.
IEEE Computer Society.Koby Crammer and Yoram Singer.
On the algorithmicimplementation of multiclass kernel-based vector ma-chines.
The Journal of Machine Learning Research,2:265?292, 2002.Xiaowen Ding, Bing Liu, and Philip S. Yu.
A holisticlexicon-based approach to opinion mining.
In Pro-ceedings of the 2008 International Conference on WebSearch and Data Mining (WSDM ?08), pages 231?240,New York, NY, USA, 2008.
ACM.Andrea Esuli and Fabrizio Sebastiani.
Sentiwordnet: Apublicly available lexical resource for opinion mining.In Proceedings of the 5th Conference on LanguageResources and Evaluation (LREC06), pages 417?422,Genova, IT, 2006.Andrea Esuli and Fabrizio Sebastiani.
Enhancing opin-ion extraction by automatically annotated lexical re-sources.
In Proceedings of the 4th conference on Hu-man language technology: challenges for computerscience and linguistics (LTC?09), pages 500?511, Poz-nan, Poland, 2011.
Springer-Verlag.Vasileios Hatzivassiloglou and Kathleen R Mckeown.Predicting the Semantic Orientation of Adjectives.
InProceedings of the eighth conference of the Europeanchapter of the Association for Computational Linguis-tics (EACL?97), pages 174?181, Madrid, Spain, 1997.ACL.Jaap Kamps, Maarten Marx, Robert J. Mokken, andMaarten de Rijke.
Using WordNet to measure seman-tic orientations of adjectives.
In Proceedings of the 4thInternational Conference on Language Resources andEvaluation (LREC-04), pages 1115?1118, Lisbon, PT,2004.Alistair Kennedy and Diana Inkpen.
Sentiment clas-sification of movie reviews using contextual valenceshifters.
Computational Intelligence, 22(2):110?125,May 2006.Brendan O?Connor, Ramnath Balasubramanyan,Bryan R. Routledge, and Noah A. Smith.
From tweetsto polls: Linking text sentiment to public opiniontime series.
In Proceedings of the 4th InternationalAAAI Conference on Weblogs and Social Media,Washington, DC, USA, 2010.Alexander Pak and Patrick Paroubek.
Twitter asa corpus for sentiment analysis and opinion min-ing.
In Proceedings of the Seventh conference onInternational Language Resources and Evaluation(LREC?10), pages 1320?1326, Valletta, Malta, 2010.ELRA.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.Thumbs up?
: sentiment classification using machinelearning techniques.
In Proceedings of the ACL-02conference on Empirical methods in natural languageprocessing (EMNLP?02), pages 79?86.
ACL, 2002.Bo Pang and Lillian Lee.
A sentimental education: Senti-ment analysis using subjectivity summarization basedon minimum cuts.
In Proceedings of the 42nd An-nual Meeting on Association for Computational Lin-guistics (ACL?04), pages 271?278, Barcelona, Catalo-nia, Spain, 2004.
ACL.Thomas M. Mitchell.
Machine Learning.
McGraw-Hill,Inc., New York, NY, USA, 1 edition, 1997.Martin F. Porter.
An algorithm for suffix stripping.
InReadings in information retrieval, number 3, pages313?316.
Morgan Kaufmann Publishers Inc., SanFrancisco, CA, USA, 1997.Peter D. Turney and Michael L. Littman.
Measuringpraise and criticism: Inference of semantic orientationfrom association.
ACM Transactions on InformationSystems (TOIS), 21(4):315?346, 2003.Gerard Salton, Andrew K. C. Wong, and Chung S. Yang.A vector space model for automatic indexing.
Com-munications of the ACM, 18(11):613?620, 1975.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
Rec-ognizing contextual polarity in phrase-level sentimentanalysis.
In Proceedings of the conference on HumanLanguage Technology and Empirical Methods in Natu-ral Language Processing (HLT/EMNLP-2005), pages347?354, Vancouver, British Columbia, Canada, 2005.ACL.Theresa Wilson, Zornitsa Kozareva, Preslav Nakov,Sara Rosenthal, Veselin Stoyanov, and Alan Ritter.SemEval-2013 Task 2: Sentiment Analysis in Twit-ter.
In Proceedings of the International Workshop onSemantic Evaluation (SemEval?13), Atlanta, Georgia,USA, 2013.
ACL.368
