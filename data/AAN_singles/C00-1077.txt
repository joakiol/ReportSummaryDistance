Identifying Terms by their Family and FriendsDiana MaynardDept.
of Computer ScienceUniversity of SheffieldRegent Court, 211 Portobello StSheffield, $1 4DP, UKd.
maynard0dcs, shef.
ac.
ukSophia Anan iadouComputer Science, School of SciencesUniversity of Saltbrd, Newton BuildingSaltbrd, M5 4WT, U.K.s.
ananiadou@salf ord.
ac.
ukAbstractMulti-word terms are traditionally identified usingstatistical techniques or, more recently, using hybridtechniques combining statistics with shallow linguis-tic information.
Al)proaches to word sense disam-biguation and machine translation have taken ad-vantage of contextual information in a more mean-ingflfl way, but terminology has rarely followed suit.We present an approach to term recognition whichidentifies salient parts of the context and measurestheir strength of association to relevant candidateterms.
The resulting list of ranked terms is shownto improve on that produced by traditional method-s, in terms of precision and distribution, while theinformation acquired in the process can also be usedfor a variety of other applications, such as disam-biguation, lexical tuning and term clustering.1 IntroductionAlthough statistical approaches to automatic termrecognition, e.g.
(Bourigault, 1992; Daille et al,1994; Enguehard and Pantera, 1994; 3usteson andKatz, 1995; Lauriston, 1996), have achieved rela-tive success over the years, the addition of suitablelinguistic information has the potential to enhanceresults still further, particularly in the case of smallcorpora or very specialised omains, where statis-tical information may not be so accurate.
One ofthe main reasons for the current lack of diversity inapproaches to term recognition lies in the difficul-ty of extracting suitable semantic information fromspeeialised corpora, particularly in view of the lackof appropriate linguistic resources.
The increasingdevelopment of electronic lexieal resources, coupledwith new methods for automatically creating andfine-tuning them from corpora, has begun to pavethe way for a more dominant appearance of naturallanguage processing techniques in the field of termi-nology.The TRUCKS approach to term recognition (Ter-m Recognition Using Combined Knowledge Sources)focuses on identifying relevant contextual informa-tion from a variety of sources, in order to enhancetraditional statistical techniques of term recognition.Although contextual information has been previous-ly used, e.g.
in general language (Grefenstette, 1994)mid in the NC-Value method for term recognition(Frantzi, 1998; Frantzi and Ananiadou, 1999), onlyshallow syntactic information is used in these cas-es.
The TRUCKS approach identifies different; el-ements of the context which are combined to formthe Information Weight, a measure of how strong-ly related the context is to a candidate term.
Thehffbrmation Weight is then combined with the sta-tistical information about a candidate term and itscontext, acquired using the NC-Value method, toform the SNC-Value.
Section 2 describes the NC-Value method.
Section 3 discusses the importanceof contextual information and explains how this isacquired.
Sections 4 and 5 describe the hffbrmationWeight and the SNC-VMue respectively.
We finishwith an evaluation of the method and draw someconclusions about the work and its fllture.2 The NC-Value methodThe NC-Value method uses a combination of lin-guistic and statistical information.
Terms are firstextracted from a corpus using the C-Value method(Frantzi and Ananiadou, 1999), a measure based onfrequency of occurrence and term length.
This isdefined formally as:is not nestedC-Value(a) = Zo.q~l(~l l~('n,) ~b~T~ f(b))a is nestedwherea is the candidate string,f(a) is its frequency in the corpus,eT, is the set of candidate terms that contain a,P(Ta) is the number of these candidate terms.Two different cases apply: one for terms that arefound as nested, and one for terms that are not.
If acandidate string is not found as nested, its termhoodis calculated from its total frequency and length.
Ifit is found as nested, termhood is calculated from itstotal frequency, length, frequency as a nested string,530and the tmmber of longer candidate terms it; ai)l)earsin.The NC-Value metho(1 builds oil this by incorl)o-rating contextual information in the form of a con-text factor for each candidate term.
A context wordcan be any noun, adjective or verb apI)earing with-in a fixed-size window of tim candidate term.
Eachcontext word is assigned a weight, based on how fre-quently it appears with a ca lldidate term.
Ttmseweights m'e titan SUllslned for all colltext words rel-ative to a candidate term.
The Context l"actor iscombined with the C-Value to form tlm NC-Value:NCvaluc(a) = 0.8 * Cvalue(a) + 0.2 * C l,'(a) (1)wherea is tile candidate term,Cvahte(a) is the Cvalue fin' tlm candidate term,CF(a) is the context factor tbr the candidateterm.3 Contextua l  In fo rmat ion :  a Term'sSocial LifeJust as a person's social life can provide valuableclues al)out their i)ersonality, so we can gather muchinformation about the nature of a term by investi-gating the coral)any it keeps.
We acquire this knowl-edge by cxtra{:ting three different ypes of contextualinformation:1. syntactic;2. terminologic~fl;3. semantic.3.1 Syntact i c  knowledgeSyntactic knowledge is based on words in the con-text which occur immediately t)efore or afl;er a can-didatc term, wtfich we call boundary words.
Follow-ing "barrier word" al)proaches to term recoglfition(Bourigault, 1992; Nelson et al, 1995), where par-titular syntactic ategories are used to delimit era>didate terms, we develop this idea fllrther by weight-ing boundary words according to tlmir category.
Theweight for each category, shown in Table 1, is all{)-cate(1 according to its relative likelihood of occur-ring with a term as opposed to a non-term.
A verb,therefore, occurring immediately before or after acandidate, term, is statistically a better indicator ofa term than an adjective is.
By "a better indica-tor", we mean that a candidate term occurring withit is more likely to be valid.
Each candidate term isassigned a syntactic weight, calculated by summingthe category weights tbr the context bomsdary wordsoccurring with it.Category WeightVerb 1.2Prep 1.1Noun 0.9Adj 0.7Table 1: We.ights for categories of boundary words3.2 Termino log ica l  knowledgeTernfinological knowledge concerns the terminologi-cal sta.tus of context words.
A context word whicllis also a term (whicll we call a context erm) is like-ly to 1)e a better indicator than one wlfich is not.The terminological status is determined by applyingthe NC-Value at)proach to the corlms, and consider-ing tile top third of the list; of ranked results as validterms.
A context erm (CT) weight is then producedfin" each candidate term, based on its total frequencyof occurrence with all relewmt context terms.
TheCT weight is formally described as follows:wherea is the candidate term,7', is the set: of context erms of a,d is a word from Ta,fa(d) is the frequency of d as a context term of a.3.3 Semant ic  knowledgeSemantic knowledge is obtained about context ermsusing the UMLS Metathesaurus and Semantic Net-work (NLM, 1997).
The former provides a seman-tic tag for each term, such as Acquired Abnormality.The latte, r provides a hierarchy of semantic type-s, from wlfich we compute the similarity between acandidate term and the context I;erms it occurs with.An example of part of tim network is shown in Figure\].Similarity is measured because we believe that acontext erm which is semantically similar to a can-didate term is more likely to be significant han onewlfieh is less similar.
We use tim method for seman-tic distance described in (M~\ynard and Ananiadou,1999a), wtfich is based on calculating the verticalposition and horizontal distance between odes in ahierarchy.
Two weights are cMculated:?
positionah measured by the combined istancefrom root to each node?
commonality: measured by the number ofshared common ancestors multiplied by themunber of words (usuMly two).Similarity between the nodes is calculated by divid-ing tim commomflity weight by the 1)ositional weightto t)roduce a figure between 0 and 1, I being the ease5311'1'1\['rMENTII'?\[ 'rAi lPIIYSICM, ()IHECr/ ,/\[TAIIIOIIGANISMITAIItl rrAtl21PI,ANT I"UN(;USITAIIlllALGA\['rlqEVI,:NT\[TA2ICONCEI~I'UAI, ~N'I'I'I'YITAI21ANATOMII2AL STIIUCTURI,:/ /ITAI211 \[TAI221EMIIRYONIC ANA'I'OM \[IUA 1,STllUC'I'UItE AIINOILMALrI'YFigure 1: Fragment of the Semantic Networkwhere tile two nodes are identical, and 0 being thecase where there is no common ancestor.
This isformally defined as follows:sim(w,.
.
.w, , )  - com(w,...w,,) (3)pOS(~Ul...Wn)wherecorn(w1 ...w,~) is the commonality weight of words1.
.
.npos('wl...w,~) is the positional weight of wordsl...n.Let us take an example from the UMLS.
The sim-ilarity between a term t)elonging to the semanticcategory Plant and one belonging to the categoryFungus would be calculated as follows:-?
Plant has the semantic ode TA l l l  and Fungushas the semantic ode TAl l2.?
The commonality weight is the number of nodesin common, multiplied by the number of termswe are considering.
TA l l l  and TA l l2  have 4nodes in common (T, TA, TA1 and TAl l ) .
Sothe weight will be 4 * 2 = 8.?
The positional weight is the total height of eachof the terms (where tile root node has a height of1).
TA l l l  has a height of 5 (T, TA, TA1, TA l land TAl l1) ,  and TAl12 also has a height of 5(T, TA, TA1, TA l l  and TAl l2) .
The weightwill therefore be 5 + 5 = 10.?
The similarity weight is tile comlnonalityweight divided by the positional weight, i.e.8/10 = 0.8.4 The  In fo rmat ion  WeightThe three individual weights described above arecalculated for all relevant context words or contextterms.
The total weights for the context are thencombined according to the following equation:IW(a) = ~ .syria(b) + ~ f,(d) .
sim,(d) (4)beC.
(l~7~wherea is the candidate term,Cais the set of context words of a,b is a word from C,,f,(b) is tlm frequency of b as a context word of a,syn~(b) is the syntactic weight of b as a contextword of a,T.
is the set of context terms of a,d is a word fl'om T.,fi,(d) is the frequency of d as a context erm of a,sims(d) is the similarity weight of d as a contextterm of a.This basically means that the Infornlation Weightis composed of the total terminological weight, 511151-tiplied by tile total semantic weight, and then addedto the total syntactic weight of all the context wordsor context erms related to the candidate term.5 The  SNC-Va lueTile Information Weight gives a score for each candi-date term based on the ilnt)ortance of the contextualintbrmation surrounding it.
To obtain the final SNC-Value ranking, the Information Weight is combinedwith the statistical information obtained using theNC-Vahm nmthod, as expressed formally below:SlVCV,a.,c(a) = NCVal~u~(a) + IW(a) (5)wherea is the candidate termNCValue(a) is the NC-Value of aIW is the Inqmrtance Weight of aFor details of the NC-Value, see (l:5'antzi and Ana-niadou, 1999).An example of the final result is shown in Table2.
This corot)ares tile top 20 results from the SNC-Value list with the top 20 from the NC-Value list.The terms in italics are those which were consideredas not valid.
We shall discuss the results in more de-tail in the next section, but we can note here threepoints.
Firstly, the weights for the SNC-Value aresubstantially greater than those for the NC-Vahm.This, in itself, is not important, since it, is the posi-tion in the list, i.e.
the relative weight, rather thanthe absolute weight, which is important.
Secondly,we can see that there are more valid terms in theSNC-Value results than in the NC-Value results.
It532Term SNC '\].L'rm NCl)owlllall ~S_lllelllbralle\]nalignant_melanomahyaline_fibrous_tissueplanes_of_sectiontral) ecularJneshworkkeratinous_del)risl)ruch~s_inenll)r &lieplane_of_section=mclanoma_of_choroidlymphocytieAnfiltrationciliary_processescellularAibrous_tissuesquamous_ct)itheliumoI)tic_nerve_headl)Ul)illary_border(:orlmal_el)itheliumseleraldnw~siongranulation_tissuestratified_squamous_epitheliumocular~structures60578223123721584317001615735310164494996.290109.471.615.15382252355.751486.846928.939054.536510.831.335.931017.428010.127445.526143.6pla'ne_@sectiondencelnel;~s_ill(~.llll)r~/iEebasal_cell_carcinomastump_of_optic_nerve1)asal_cell_l)at)illomaplanc_of_section=rnclano,na_of_ch, oroidpla'ncs_@scctionmalignant _melanomaoptic_nerveAmadciliaryq)rocesses1)ruth's_membranekeratinous_eystellipse_of_skinwcdgc_of_lid_ma~yinscaT"_tT'ackconImctive_tissuevertical_planecarcinoma_of_lidexcision_biopsy1752.711.345.761.268.21993.15616.614506.517497.673453.716448.591422.211421.204413.027392.944267.636211.41.4228.217167.053167.015164155.257Table 2: Top 20 results for the SNC-VaIue and NC-Valuein hard to make flu:ther judgements based on thislist alone, 1)ecause we cmmot s~3; wlmther on(; ter-\]u is 1)etter than another, if tiE(; two terms are bothvalid.
Thirdly, we can nee that more of the top 20terms are valid tin' tim SNC-Vahm than for the NC-Value: 17 (851X,) as ot)t)osed to 10 (50%).6 Eva luat ionThe SNC-Value method wan initially t(;sted on a eor-l)US of 800,000 eye t)athoh)gy reI)ortn , which had1)een tagged with the Brill t)art-of-nl)eeeh tagger(Brill, 1992).
The ca.ndidate terms we,'e first ex-tracted using the NC-Value method (lhantzi, 1998),and the SNC-Value was then (:alculated.
To exvdu-ate the results, we examined the p(.
'rformanee of thesimilarity weight alone, and the overall 1)erformanceof the system.6.1 Evaluation methodsThe main evaluation i)rocedure was carried out withresl)ect o a manual assessment of tim list of termsl)y 2 domain exI)erts.
There are, however, 1)roblemsassociated with such an evaluation.
Firstly, there ixno gold standm:d of evaluation, and secondly, man-ual evaluation is both fallil)le and sul)jective.
Toavoid this 1)rol)lem, we measure the 1)erformance ofthe system ill relative termn rather than in abso-lute terms, by measuring the improveln(mt over theresults of tile NC-Value as eomt)ared with mmmalevahlation.
Although we could have used the listof terms 1)rovided in the UMLS, instead of a manu~ally evahlated list, we found that there was a hugediscrei)an(:y 1)etween this lint and the lint validatedby the manual experts (only 20% of the terms theyjudged valid were fOtlEl(1 ill the UMLS).
There arealso further limitations to the UMLS, such as thefact that it is only nl)e(:ific to medicine in general,1)ut not to eye t)athology, and the fact that it; is or-ganised ill nllch a way that only the preferred terms,and not lexical variants, m'e actively and (:onnistent-ly 1)r(~sent.We first evaluate the similarity weight individu-ally, since this is the main 1)rinciple on which theSNC-\Sflue method relies.
We then ewduate theSNC-VaIue as a whole t)y comparing it with the NC-Value, so I;hat we can ewfluate the impact of tile ad-dition of the deel)er forms of linguistic informationincorl)orated in {:he hnI)ortance Weight.6.2 Similarity WeightOne of the 1)roblems with our method of calculat-ing similarity is that it relies on a 1)re-existing lexi-(:al resource, which Eneans it is 1)rone to errors andomissions.
Bearing in mind its innate inadequacies,we can nevertheless evaluate the expected theoreticalperformance of tilt measure by concerning ourselvesonly with what is covered by the thesaurus.
Thismeans that we assume COml)leteness (although weknow that this in not the case) and evahtate it ac-cordingly, ignoring anything which may be inissing.The semantic weight ix based on the premise thattile more similar a context term is to the candidateterm it occurs with, the better an indicator that con-text term is.
So the higher the total semantic weight533Section Term Non-Termtop set 76% 24%middle set 56% 44%bottom set 49% 51%Table 3: Semantic weights of terms and non-termsfor the candidate term, the higher the ranking of theterm and the better the chance that the candidateterm is a valid one.
To test the performmme of thesemantic weight, we sorted the terms in descendingorder of their semantic weights and divided the listinto 3, such that the top third contained the termswith the highest semantic weights, and the bottomthird contained those with the lowest.
We then com-pared how many valid and non-valid terms (accord-ing to the manual evaluation) were contained in eachsection of the list,.Tile results, depicted in Table 3, can be interpret-ed as follows.
In the top third of the list;, 76% wereterms and 24% were non-terms, whilst in the middlethird, 56% were terms and 44% were non-terms, andso on.
This means that most of the valid terms arecontained in the top third of tile list mid the fewestvalid terms are contained in the bottom third of thelist.
Also, the proportion of terms to non-terms intile top of tile list is such that there are more termsthan non-terms, whereas in the bottom of the list;there are more non-terms than ternis.
This there-fore demonstrates two things:?
more of' the terms with the highest semanticweights are valid, and fewer of those with thelowest semmitic weights are valid;?
more valid terms have high semantic weightsthan non-terms, mid more non-terms have lowersemantic weights than valid terms.We also tested the similarity measure to seewhether adding sosne statistical information wouldimprove its results, and regulate any discrepanciesin tile uniformity of the hierarchy.
The method-s which intuitively seem most plausible are basedon information content, e.g.
(Resnik, 1995; Smeatonand Quigley, 1996).
The informatiosl content of a n-ode is related to its probability of occurrence in thecorpus.
Tile snore fi'equently it appears, the snorelikely it is to be important in terms of conveyinginformation, and therefore the higher weighting itshould receive.
We performed experiments to cosn-pare two such methods with our similarity measure.The first considers the probability of the MSCA ofthe two terms (the lowest node which is an ancestorof both), whilst the second considers the probabilityof the nodes of the terms being colnpared.
However,the tindings showed a negligible difference betweenthe three methods, so we conchlde that there is noSNC-Value NC-VahmSection Valid Precision Valid Precision1 163 64% 160 62%2 84 aa% 98 38%3 89 35% 69 27%4 89 35% 78 30%5 76 30% 87 34%6 57 22% 78 30%7 66 26% 92 36%8 75 29% 100 39%9 70 27% 42 16%10 59 23% 68 27%Table 4: Precision of SNC-Vahle and NC-Valueadvantage to be gained by adding statistical int'or-mation, fbr this particular corpus.
It; is possible thatwith a larger corlms or different hierarchy, this mightslot be the case.6.3 Overall Evaluat ion of the SNC-ValueWe first; compare the precision rates for the SNC-Value and the NC-Value (Table 4), by dividing tileranked lists into 10 equal sections.
Each section con-tains 250 terms, marked as valid or invalid by themanual experts.
In the top section, the precision ishigher for the SNC-Value, and in the bottom section,it is lower.
This indicates that the precision span isgreater fl~r the SNC-Value, and therefore that theranking is improved.
The distribution of valid termsis also better for the SNC-Value, since of the validterms, more appear at the top of the list than at thebottom.Looking at Figure 2, we can see that the SNC-Value graph is smoother than that of the NC-Vahle.We can compare the graphs niore accurately usinga method we call comparative upward trend.
Be-cruise there is no one ideal graph, we instead mea-sure how much each graph deviates from a mono-tonic line downwards.
This is calculated by dividingthe total rise in precision percentage by the lengthof the graph.
A graph with a lower upward trendwill therefore be better than a graph with a higherupward trend.
If we compare the upward trends ofthe two graphs, we find that the trend for the SNC-Value is 0.9, whereas the trend for the NC-Value is2.7.
This again shows that the SNC-Value rmikingis better thmi the NC-Value ranking, since it is moreconsistent.Table 5 shows a more precise investigation of thetop portion of the list, (where it is to be expectedthat ternis are most likely to be wflid, and whichis therefore the inost imi)ortant part of the list) Wesee that the precision is most iml)roved here, bothin terms of accuracy and in terms of distributionof weights.
At the I)ottom of the top section, the5349OU{}71}60PlccJshm 50,1113021110SN{" Vah,c.
.
.
.
NC-Vah,c\\T ~  T T II 3 4 ~ 6 7 8 9 10Scct iono l l i s tFigure 2: Precision of SNC-Value and NC-VatueSNC-\SflueSection Valid I Precision1 21 184%2 19 176%3 ~" '68% i i4: 16 164%5 1.8 172%6 12 148%7 13 152%8 : 7 : 68{/{)9 \] 3 I 52%10 \] 4 i 56%\] N C-ValueValid Precisionz19 76%23 92%21 84%13 52%13 52%19 76%18 72%14 56%10 40%8 32%Table 5: Precision of SNC-\Sdue and NC-Vahm fortop 250 termsprecision is much higher for the SNC-Value.
This isimportant because ideally, all the terms in this partof the list should be valid,7 Conc lus ionsIn this paper, we have described a method for multi-word term extraction which improves on traditionalstatistical at)proaches by incorporating more specificcontextual information.
It focuses particularly onmeasuring the strength of association (in semanticterms) l)etween a candidate term and its context.Evahlation shows imi)rovement over the NC-Vahmapproach, although the percentages are small.
Thisis largely l)ecmlse we have used a very small corpusfor testing.The contextuM information acquired can also beused for a mmlber of other related tasks, such asdisambiguation and clustering.
At present, the se-mantic information is acquired from a 1)re-existingdomain-slmcitic thesaurus, but there m:c 1)ossibili-tics for creating such a thesaurus automatically, orentrancing an existing one, using the contextual in-formation we acquire (Ushioda, 1996; MaynaM andAnmfiadou, 1999b).There is much scope tbr filrther extensions of thisresearch.
Firstly, it; could be extended to other (lo-mains and larger corpora, in order to see the truebenefit of such a.n apl)roach.
Secondly, the thesauruscould be tailored to the corpus, as we have men-tioncd.
An incremental approach might be possible,whereby the similarity measure is combined with s-tatistical intbrmation to tune an existing ontology.Also, the UMLS is not designed as a linguistic re-source, but as an information resource.
Some kindof integration of the two types of resource would beusefifl so that, for example, lexical variation couldbe more easily handled.ReferencesD.
Bourigault.
1992.
Surface grammatical analysisfor tile extraction of terminological noun phras-es.
In Proc.
of l~th International Co~@rcnccon Computational Linguistics (COL\[NG), pages977-981, Nantes, bYance.Eric Brill.
1992.
A simple rule-based part of speechtagger.
In Pwc.
of 3rd Confc~vnce of Applied Nat-ural Language Processing.B.
l)aille, E. Gaussicr, and J.M.
Lang5.
1994.
To-wards automatic extraction of monolingual andt)ilingual terminology.
In Proc.
of iSth Interna-tional Conference on Computational Linguistics(COLIN(;), pages 515-521.Chantal Enguehard and Lmu'ent Pantera.
1994.Autoumtic natural a(:quisition of a terminology.Journal of Quantitative Linguistics, 2(1):27-32.K.T.
li'r;mtzi and S. Ananiadou.
1.999.
The C-Value/NC-Vahm domain independent method ~brmulti-word term extraction.
Journal of NaturalLanguage PTvccssing, 6(3):1.45 179.K.T.
Frantzi.
1.998.
Automatic Recognition ofMulti-Word Terms.
Ph.D. thesis, ManchesterMetropolitan University, England.G.
Grefenstette.
1994.
E:rplorations in AutomaticThesaurus Discovcry.
Kluwer Aca(temic Publish-ers .J.S.
Justcson and S.M.
Katz.
1995.
Technical ter-minology: some linguistic properties and an algo-rithm for identification in text.
Natural LanguageEngineering, 1:9-27.Andy Lauriston.
1996.
Automatic term recognition:performance of lin9uistic and statistical learningtechniques.
Ph.D. thesis, UMIST, Manchester,UK.D.G.
Maynard and S. Anmfiadou.
1999a.
hlentify-ing contextual information tbr term extraction.
Ini}Tvc, of 5th International Congress on 7~rminol-535ogy and Knowlc@c Engineering (TKE '99), pt~ges212-221, Innsbruck, Austria.D.G.
Maynard and S. Anmfiadou.
1999b.
A linguis-tic ~I)proach to context clustering.
In Proc.
of Nat-n~nl Language Proecssinfl Pacific \]~im Symposium(NLPRS), pages 346-351, Beijing, China.S.J.
Nelson, N.E.
Olson, L. Fuller, M.S.
Turtle, W.G.Cole, and D.D.
Sherertz.
1995.
Identifying con-cepts in medical knowledge.
In Proc.
of 8th WorldCongress on Medical Informatics (MEDINFO),1)~ges 33-36.NLM, 1997.
UMLS K?wwlcdgc Sourccs.
NationalLibrary of Medicine, U.S. Dept.
of Health and Hu-man Services, 8th edition, January.P.
Resnik.
1995.
Disambiguating noun groupingswith respect o WordNet senses.
In Proc.
of 3rdWorkshop on Very Large Corpora.
MIT.A.
Smeaton and I. Quigley.
1996.
Experiments onusing semantic distances between words in imagecaption retrieval.
In Proc.
of 19t.h htternationaIConferc'ncc on Research and Development i~.
I'n-formation Retrieval, Zurich, Switzerland.Akira Ushioda.
1996.
IIierarchical clustering ofwords.
In Proc.
of 16th I'ntcrnational ConfcT~cnccon Computational Linguistics (COLING), pages1159 1162.536
