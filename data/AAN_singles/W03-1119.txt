A Sentence Reduction Using Syntax ControlNguyen Minh LeThe Graduate School ofInformation Science JAISTIshikawa, 923-1292, Japannguyenml@jaist.ac.jpSusumu HoriguchiThe Graduate School ofInformation Science JAISTIshikawa, 923-1292, Japanhori@jaist.ac.jpAbstractThis paper present a method based on thebehavior of nonnative speaker for reduc-tion sentence in foreign language.
Wedemonstrate an algorithm using seman-tic information in order to produce tworeduced sentences in two difference lan-guages and ensure both grammatical andsentence meaning of the original sentencein reduced sentences.
In addition, the or-ders of reduced sentences are able to bedifferent from original sentences.1 IntroductionMost of the researches in automatic summarizationwere focused on extraction or identifying the im-portant clauses and sentences, paragraphs in texts(Inderject Mani and Mark Maybury, 1999).
How-ever, when humans produce summaries of docu-ments, they used to create new sentences that aregrammatical, that cohere with one another, and cap-ture the most salient parts of information in the orig-inal document.
Sentence reduction is the problem toremove some redundant words or some phrases fromthe original sentence by creating a new sentence inwhich the gist meaning of the original sentence wasunchanged.Methods of sentence reduction have been usedin many applications.
Grefenstette (G.Grefenstette,1998) proposed removing phrases in sentences toproduce a telegraphic text that can be used to pro-vide audio scanning services for the blind.
Dolan(S.H.
Olivers and W.B.Dolan, 1999) proposed re-moving clauses in sentences before indexing docu-ment for information retrieval.
Those methods re-move phrases based on their syntactic categories butnot rely on the context of words, phrases and sen-tences around.
Without using that information canbe reduced the accuracy of sentence reduction prob-lem.
Mani and Maybury also present a process ofwriting a reduced sentence by reversing the originalsentence with a set of revised rules to improve theperformance of summarization.
(Inderject Mani andMark Maybury, 1999).Jing and McKeown(H. Jing, 2000) studied a newmethod to remove extraneous phrase from sentencesby using multiple source of knowledge to decidewhich phrase in the sentences can be removed.
Themultiple sources include syntactic knowledge, con-text information and statistic computed from a cor-pus that consists of examples written by human pro-fessional.
Their method prevented removing somephrases that were relative to its context around andproduced a grammatical sentence.Recently, Knight and Marcu(K.Knight andD.Marcu, 2002) demonstrated two methods for sen-tence compression problem, which are similar tosentence reduction one.
They devised both noisy-channel and decision tree approach to the prob-lem.
The noisy-channel framework has been usedin many applications, including speech recognition,machine translation, and information retrieval.
Thedecision tree approach has been used in parsing sen-tence.
(D. Magerman, 1995)(Ulf Hermijakob andJ.Mooney, 1997) to define the rhetorical of text doc-uments (Daniel Marcu, 1999).Most of the previous methods only produce ashort sentence whose word order is the same as thatof the original sentence, and in the same language,e.g., English.When nonnative speaker reduce a long sentencein foreign language, they usually try to link themeaning of words within the original sentence intomeanings in their language.
In addition, in somecases, the reduced sentence and the original sen-tence had their word order are difference.
Therefore,two reduced sentences are performed by non-nativespeaker, one is the reduced sentence in foreign lan-guage and another is in their language.Following the behavior of nonnative speaker, twonew requirements have been arisen for sentence re-duction problem as follows:1) The word order of the reduced sentence may dif-ferent from the original sentence.2) Two reduced sentences in two difference lan-guages can be generated.With the two new perspectives above, sentence re-duction task are useful for many applications suchas: information retrieval, query text summarizationand especially cross-language information retrieval.To satisfy these new requirements, we proposed anew algorithm using semantic information to simu-late the behavior of nonnative-speaker.
The seman-tic information obtained from the original sentencewill be integrated into the syntax tree through syntaxcontrol.
The remainder of this paper will be orga-nized as follows: Section 2 demonstrated a methodusing syntactic control to reduced sentences.
Sec-tion 3 shows implementation and experiments.
Sec-tion 4 gives some conclusions and remained prob-lems to be solved in future.2 Sentence reduction using syntax control2.1 FormulationLet E and V be two difference languages.
Given along sentence e : e1, e2, ..., en in the language E.The task of sentence reduction into two languagesE and V is to remove or replace some redundantwords in the sentence e to generate two new sen-tences e?1, e?2, ..., e?m and v1, v2, ..., vk in language Eand V so that their gist meanings are unchanged.In practice, we used English language as a sourcelanguage and the target language are in English andVietnamese.
However, the reader should understandthat our method can apply for any pair of languages.In the following part we present an algorithm of sen-tence reduction using syntax control with rich se-mantic information.2.2 Sentence reduction algorithmWe present an algorithm based on a semantic parsingin order to generate two short sentences into differ-ence languages.
There are three steps in a reductionalgorithm using syntax control.
In the first step, theinput sentence e will be parsed into a syntax tree tthrough a syntax parser.In the second step, the syntax tree will be addedrich semantic information by using a semanticparser, in which each node of the syntax tree is asso-ciated with a specific syntax control.
The final step isa process of generating two deference sentences intolanguage E and V language from the syntax tree tthat has been annotated with rich semantic informa-tion.2.2.1 Syntax parsingFirst, We parse a sentence into a syntax tree.
Oursyntax parser locates the subject, object, and headword within a sentence.
It also recognizes phraseverbs, cue phases or expressions in English sen-tences.
These are useful information to reduce sen-tence.
The Figure 2 explains the equivalent of ourgrammar symbol with English grammar symbol.Figure 1 shows an example of our syntax pars-ing for the sentence ?Like FaceLift, much of ATM?sscreen performance depends on the underlying ap-plication?.To reduce the ambiguity, we design a syntactic pars-ing base on grammar symbols, which classified indetail.
Part of speech of words was extended to copewith the ambiguity problem.
For example, in Figure2, ?noun?
was dived into ?private noun?
and ?gen-eral noun?.The bilingual dictionary was built including about200,000 words in English and its meaning in Viet-namese.
Each English word entry includes severalmeanings in Vietnamese and each meaning was as-sociated with a symbol meaning.
The set of sym-bol meanings in each word entry is defined by usingWordNet database.(C.
Fellbaum, 1998) The dictio-nary also contained several phrases, expressions inFigure 1: An example of syntax tree of ?LikeFaceLift, much of ATM?s screen performance de-pends on the underlying application?English and its equivalent to Vietnamese.2.2.2 Semantic parsing using syntax controlAfter producing a syntax tree with rich informa-tion, we continue to apply a semantic parsing for thatsyntax tree.Let N be an internal node of the syntax tree t and Nhas k children nodes: n1, n2, ...nk .The node N based on semantic information fromits n children nodes to consider what the remainedpart in the reducing sentence should be.When parsing semantic for the syntax tree t, eachN must be used the information of children nodesto define its information.
We call that information issemantic-information of the node N and define it asN.sem .
In addition, each semantic-information ofa given node N was mapped with a meaning in theFigure 2: Example of symbol Equivalenttarget language.For convince, we define SI is a set of semantic-information and assume that the jth semantic-information of the node nj is nj [i].To understand what the meaning of the node Nshould be, we have to know the meaning of eachchildren node and know how to combine them intomeanings for the node N .Figure 3: Syntax controlFigure 3 shows two choices for sequence mean-ings of the node N in a reduction process .It is easy for human to understand exactly whichmeaning of ni should be and then decoding them asobjects to memorize.
With this basic idea, we designa control language to do this task.The k children nodes n1, n2, ...nk are associatedwith a set of a syntax control to conduct the reducingsentence process.
The node N and its children areassociated with a set of rules.
To present the set ofrules we used a simple syntax of a control languageas follows:1) Syntax to present the order of children nodes andnodes to be removed.2) Syntax to constraint each meaning of a childrennode with meanings of other children nodes.3) Syntax to combine sequence meanings intoone symbol meaning (this process called a inheritprocess from the node N to its children).A syntax rule control will be encoded as one-generation rules and a set of condition rules so thatthe generation rule has to satisfy.
With a specifica-tion condition rule, we can define its generation ruledirectly.Condition ruleA condition rule is formulated as follows: ifnj1 .sem = v1 ?
nj2 .sem = v2... ?
njm .sem = vmthen N.sem = v with v and vj ?
SIGeneration ruleA generation rule is a sequence of symbols in orderto transfer the internal node N into the internal nodeof a reduced sentence.
We used two generationrules, one for E and other one for V .
Given asequence symbols g : g1g2...gm , in which gi is aninteger or a string.
The equation gi = j means thechildren node be remained at position j in the targetnode.
If gi = ?v1v2...vl?, we have that string will inthe children node ni of the target node.Figure 1 shows a syntax tree of the input sentence:?Much of ATM?s performance depends on the un-derlying application.?.
In this syntax tree, the syntaxrule:?S1=Bng-daucau Subj cdgt Bng-cuoicau?
willbe used the syntax control bellow to reduce< Con > default < /Con >< Gen > 1 2 < /Gen >The condition rule is ?default?
mean the generationrule is applied to any condition rule.
The generationrule be ?1 2?
mean only the node (Subj) in theindex 1 and the node (cdgt) in the index 2 of therule ?S1=Bng-daucau Subj cdgt Bng-cuoicau?
areremained in the reduced sentence.If the syntax control is changed to< Con > Subj = HUMAN < /Con >< Gen > 1 2 < /Gen >This condition rule means that only the case thesemantic information in the children node ?Subj?is ?HUMAN?
the generation rule ?1 2?
is appliedfor reduction process.
Using the default conditionrule the reduced sentences to be generated asfollows.Original sentence: Like FaceLift, much of ATM?sscreen performance depends on the underlyingapplication.Reduced sentence in English: Much of ATM?s per-formance depends on the underlying application.Reduced sentence in Vietnamese: Nhieu hieu suatcua ATM phu thuoc vao nhung ung dung tiem an.In order to generating reduced sentence in Viet-namese language, the condition rule and generationis also designed.
This process is used the same wayas transfer translation method.Because the gist meaning of a short sentence is un-changed in comparing with the original sentence, thegist meaning of a node after applying the syntax con-trol will be unchanged.
With this assumption, wecan reuse the syntax control for translating the origi-nal sentence into other languages (English into Viet-namese) for translating the reduced sentence.
There-fore, our sentence reduction program can producetwo reduced sentences in two difference languages.Our semantic parsing used that set of rules to selectsuitable rules for the current context.
The problemof selecting a set of suitable rules for the current con-text of the current node N is to find the most likelycondition rule among the set of syntax control rulesthat associated with it.
Thus, semantic parsing usingsyntax control problem can be described mathemat-ically as follows:Given a sequence of children nodes n1, n2, ..., nkof a node N , each node ni consist of a list of mean-ing, in which each meaning was associated with asymbol meaning.
The syntax rule for the node Nwas associated with a set of condition rules.
In ad-dition, one condition rule is mapped with a specifi-cation generation rule.Find the most condition rules for that node se-quences.This problem can be solved by using a variant of theViterbi algorithm (A.J.
Viterbi, 1967).Firstly, we define each semantic-information of achildren node with all index condition rules.
Sec-ondly, we try to find all sequences that come fromthe same condition rules.Algorithm 1 A definition of condition rules algo-rithm.
FindRule(N )Require: Input: N is a nodeEnsure: A syntax control for a rule{Initialization step:}1: for i = 1 to k do2: for j = 1 to Ki do3: Set stack s[i]=all index rules in the set ofcondition rules satisfy ni.sem = ni[j]4: end for5: for i = 1 to K1 do6: Cost[0][i] = 1;7: Back[0][i] = 0;8: end for9: end for{Interaction step:}10: for i = 1 to k do11: for j=1 to Ki do12: Cost[i][j] = maxCost[i ?
1][l] ?V alue(s[i][j], s[i?
1][l]) with l = 1,KiBack[i][j]= all the index gave max13: end for14: end for{Identification step:}15: Set a list LS= all index rules gave max valuesCost[k][j] with j = 1,Kk.16: Update all semantic-information of each condi-tion rule in the list LS to node N .17: Function Value (i, j)BeginIf i==j return 2;Else return 1;EndAfter defining a set of semantic-information foreach internal node, we have a frame of semanticparsing algorithm as shown in Algorithm 2.
Our se-mantic parsing using syntax control is fast becauseof finding syntax control rule for each node tree isapplied dynamic programming.Algorithm 2 Semantic parsing algorithmRequire: Given a syntax tree , a set of syntax con-trol for each node of the syntax tree.Ensure: a syntax tree with rich semantic informa-tion{SemanticParsingTree}1: if N is leaf then2: Update all symbol-meaning in word entry3: else4: FindRules(N);5: end if{main procedure}6: SemanticParsingNode(root);2.2.3 Generation reduced sentencesThe input of this process is a syntax tree whichassociated with rich information after applying thesemantic parsing process.
Browsing the syntax treefollowing bottom-up process, in which, a node treecan be generated a short sub-sentence by using thecorresponding generation rule.
Because we havetwo generation rules for each node tree, so we havetwo reduced sentences in two difference languages.3 Experiments and Discussion3.1 Experiment DataWe used the same corpus(K.Knight and D.Marcu,2002) with 1067 pair of sentence and its reduction.We manually changed the order of some reducedsentences in that corpus while keep their meaning.We manually build a set of syntax control for thatcorpus for our reduction algorithm using syntax con-trol.
The set of semantic symbols was describedsuch as, HUMAN, ANIMAL, THINGS, etc.
Wemake 100 pair of sentences with the order of a reduc-tion sentence is different from its original sentence.Afterward, those sentences are to be combined withthe corpus above in order to confirm that our methodcan deal with the changeable word order problem.3.2 Experiment MethodTo evaluate our reduction algorithms, we randomlyselected 32 pair of sentences from our parallelcorpus, which will refer to as the Test corpus.We used 1035 sentence pairs for training withthe reduction based decision tree algorithm.
Weused test corpus to confirm that our methods us-ing semantic-information will outperform than thedecision tree method without semantic-information(K.Knight and D.Marcu, 2002).
We presented eachoriginal sentence in the test corpus to three judgeswho are Vietnamese and specialize in English, to-gether with three sentence reductions of it: The hu-man generated reduction sentence, the outputs of thesentence reduction based syntax control and the out-put of the baseline algorithm.
The judges were toldthat all outputs were generated automatically.
Theorder of the outputs was scrambled randomly acrosstest cases.
The judges participated in two experi-ments.
In the first experiment, they were asked todetermine on a scale from 1 to 10 how well the sys-tems did with respect to selecting the most importantwords in the original sentence.
In the second exper-iment, they were asked to determine on a scale from1 to 10 how grammatical the outputs were.
The out-puts of our methods include both reduced sentencesin English and Vietnamese.
In the third experiment,we tested on the randomly of 32 sentences from 100sentences whose had word order between input andoutput are different.3.3 Experiment ResultsUsing the first and the second experiment method,we had two table results as follows.Table 1: Experiment results with outputs in EnglishMethod comp Grammatically ImportanceBaseline 57.19 8.6?
2.8 7.18?
1.92Syn.con 6.5 8.7?
1.2 7.3?
1.6Human 53.33 9.05?
0.3 8.5?
0.8Table 2: Experiment results with outputs in Viet-nameseMethod comp Grammatically ImportanceBaseline x x xSyn.con 67 6.5?
1.7 6?
1.3Human 63 8.5?
0.3 8.7?
0.7Using the third experiments method we achieveda result to be shown in Table5.Table 3: Experiment results with the changeable or-derMethod comp Grammatically ImportanceBaseline 56.2 7.4?
3.1 6.5?
1.3Syn.con 66 8.4?
2.1 7.2?
1.7Human 53.33 9.2?
0.3 8.5?
0.83.4 DiscussionTable 1 shows the compression of three reduc-tion methods in comparing with human for Englishlanguage.
The grammatically of semantic controlachieved a high results because we used the syntaxcontrol from human expert.
The sentence reductiondecision based is yielded a smallest result.
We sus-pect that the requirement of word order may affectthe grammatically.
Table 1 and Table 3 also indi-cates that our new method achieved the importanceof words are outperform than the baseline algorithmdue to semantic information.
This was because ourmethod using semantic information to avoid deletingimportant words.
Following our point, the base linemethod should integrate with semantic informationwithin the original sentence to enhance the accuracy.Table 2 shows the outputs of our method into Viet-namese language, the baseline method cannot gener-ate the output into Vietnamese language.
The syntaxcontrol method achieved a good enough results inboth grammatically and importance aspects.The comparison row in the Table 1 and the Table 2also reported that the baseline yields a shorter outputthan syntax control method.Table 3 shows that when we selected randomly 32sentence pairs from 100 pairs of sentences those hadwords order between input and output are different,we have the syntax method change a bit while thebaseline method achieved a low result.
This is dueto the syntax control method using rule knowledgebased while the baseline was not able to learn withthat corpus that.4 ConclusionsWe have presented an algorithm that allows rewrit-ing a long sentence into two reduced sentences intwo difference languages.
We compared our meth-ods with the other methods to show advantages aswell as limits of the method.
We claim that the se-mantic information of the original sentence throughusing syntax control is very useful for sentence re-duction problem.We proposed a method for sentence reductionusing semantic information and syntactic parsingso-called syntax control approach.
Our methodachieved a higher accuracy and the outputted reduc-tion sentences in two different languages e.g.
En-glish and Vietnamese.
Thus, it is closed to the out-puts of non-native speaker in reduction manner.Investigate machine learning to generate syntaxcontrol rules automatically from corpus available arepromising to enhance the accuracy of sentence re-duction using syntax control .AcknowledgementsWe would like to thank to Dr. Daniel Marcus aboutthe data corpus for sentence reduction task.
This re-search was supported in part by the international re-search project grant, JAIST.ReferencesIndeject Mani and Mark Maybury.
1999.
Advances inAutomatic Text Summarization.
The MIT press.G.Grefenstette.
1998.
Producing intelligent telegraphictext reduction to provide an audio scanning service forthe blind.
In Working notes of the AAAI Spring Sym-posium on Intelligent Text summarization, pp.111-118.S.H.Olivers and W.B.Dolan.
1999.
Less is more; elimi-nating index terms from subordinate clauses.
In Pro-ceedings of the 37th Annual Meeting of the Associationfor Computational Linguistic, pp.349-356.H.Jing.
2000.
Sentence reduction for automatic textsummarization.
In Proceeding of the First AnnualMeeting of the North American Chapter of the Asso-ciation for Computational Linguistics NAACL-2000.Kevin Knight and Daniel Marcu.
2002.
Summarizationbeyond sentence extraction: A Probabilistic approachto sentence compression.
Artificial Intelligent, 139:91?107.D.
Magerman.
1995.
Statistical decision tree models forparsing.
In Proceedings of the 33rd Annual Meeting ofthe Association for Computational Linguistic, pp.276-283.Ulf Hermijakob and Raymond J. Mooney.
1997.
Learn-ing parse and translation decision from examples withrich context.
In Proceeding of ACL/EACL?97, pp 482-489.Daniel Marcu.
1999.
A decision- based approach toRhetorical parsing.
In Proc.
Of ACL?99, pp.365-372.C.Fellbaum.
1998.
WORDNET: An Electronic LexicalDatabase.
The Mit Press.A.J.Viterbi.
1967.
Error bounds for convolution codesand an asymptotically optimal decoding algorithm.IEEE Trans on Information Theory,13: 260?269.
