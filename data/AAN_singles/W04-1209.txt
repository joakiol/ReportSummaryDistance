Support Vector Machine Approach to ExtractingGene References into Function from Biological DocumentsChih Lee, Wen-Juan Hou and Hsin-Hsi ChenNatural Language Processing LaboratoryDepartment of Computer Science and Information EngineeringNational Taiwan University1 Roosevelt Road, Section 4, Taipei, Taiwan, 106{clee, wjhou}@nlg.csie.ntu.edu.tw, hh_chen@csie.ntu.edu.twAbstractIn the biological domain, extracting newlydiscovered functional features from themassive literature is a major challenging issue.To automatically annotate Gene Referencesinto Function (GeneRIF) in a new literature isthe main goal of this paper.
We tried to findGRIF words in a training corpus, and thenapplied these informative words to annotate theGeneRIFs in abstracts with several differentweighting schemes.
The experiments showedthat the Classic Dice score is at most 50.18%,when the weighting schemes proposed in thepaper (Hou et al, 2003) were adopted.
Incontrast, after employing Support VectorMachines (SVMs) and the definition of classesproposed by Jelier et al (2003), the scoregreatly improved to 56.86% for Classic Dice(CD).
Adopting the same features, SVMsdemonstrated advantage over the Na?ve BayesClassifier.
Finally, the combination of theformer two models attained a score of 59.51%for CD.1 IntroductionText Retrieval Conference (TREC) has beendedicated to information retrieval and informationextraction for years.
TREC 2003 introduced a newtrack called Genomics Track (Hersh andBhupatiraju, 2003) to address the informationretrieval and information extraction issues in thebiomedical domain.
For the information extractionpart, the goal was to automatically reproduce theGene Reference into Function (GeneRIF) resourcein the LocusLink database (Pruitt et al, 2000.
)GeneRIF associated with a gene is a sentencedescribing the function of that gene, and is currentlymanually generated.This paper presents the post-conference work onthe information extraction task (i.e., secondary task).In the official runs, our system (Hou et al, 2003)adopted several weighting schemes (described inSection 3.2) to deal with this problem.
However,we failed to beat the simple baseline approach,which always picks the title of a publication as thecandidate GeneRIF.
Bhalotia et al (2003)converted this task into a binary classificationproblem and trained a Na?ve  Bayes classifier withkernels, achieving 53.04% for CD.
In their work,the title and last sentence of an abstract wereconcatenated and features were then extracted fromthe resulting string.
Jelier et al (2003) observed thedistribution of target GeneRIFs in 9 sentencepositions and converted this task into a 9-classclassification problem, attaining 57.83% for CD.Both works indicated that the sentence position isof great importance.
We therefore modified oursystem to incorporate the position information withthe help of SVMs and we also investigated thecapability of SVMs versus Na?ve  Bayes on thisproblem.The rest of this paper is organized as follows.Section 2 presents the architecture of our extractingprocedure.
The basic idea and the experimentalmethods in this study are introduced in Section 3.Section 4 shows the results and makes somediscussions.
Finally, Section 5 concludes theremarks and lists some future works.2 Architecture OverviewA complete annotation system may be done at twostages, including (1) extraction of molecularfunction for a gene from a publication and (2)alignment of this function with a GO term.
Figure1 shows an example.
The left part is an MEDLINEabstract with the function description highlighted.The middle part is the corresponding GeneRIF.The matching words are in bold, and the similarwords are underlined.
The right part is the GOannotation.
This figure shows a possible solution ofmaintaining the knowledge bases and ontologyusing natural language processing technology.
Weaddressed automation of the first stage in this paper.The overall architecture is shown in Figure 2.First, we constructed a training corpus in such away that GeneRIFs were collected from LocusLinkand the corresponding abstracts were retrieved from54MEDLINE.
?GRIF words?
and their weights werederived from the training corpus.
Then SupportVector Machines were trained using the derivedcorpus.
Given a new abstract, a sentence is selectedfrom the abstract to be the candidate GeneRIF.3 MethodsWe adopted several weighting schemes to locate theGeneRIF sentence in an abstract in the official runs(Hou et al, 2003).
Inspired by the work by Jelier etal.
(2003), we incorporated their definition ofclasses into our weighting schemes, converting thistask into a classification problem using SVMs asthe classifier.
We ran SVMs on both sets offeatures proposed by Hou et al (2003) and Jelier etal.
(2003), respectively.
Finally, all the featureswere combined and some feature selection methodswere applied to train the classifier.3.1 Training and test material preparationSince GeneRIFs are often cited verbatim fromabstracts, we decided to reproduce the GeneRIF byselecting one sentence in the abstract.
Therefore,for each abstract in our training corpus, the sentencemost similar to the GeneRIF was labelled as theGeneRIF sentence using Classic Dice coefficient assimilarity measure.
Totally, 259,244 abstracts wereused, excluding the abstracts for testing.
The testdata for evaluation are the 139 abstracts used inTREC 2003 Genomics track.3.2 GRIF words extraction and weightingschemeWe called the matched words between GeneRIFand the selected sentence as GRIF words in thispaper.
GRIF words represent the favoritevocabulary that human experts use to describe genefunctions.
After stop word removal and stemmingoperation, 10,506 GRIF words were extracted.In our previous work (Hou et al, 2003), we firstgenerated the weight for each GRIF word.
Givenan abstract, the score of each sentence is the sum ofweights of all the GRIF words in this sentence.Finally, the sentence with the highest score isselected as the  candidate GeneRIF.
This method isdenoted as OUR weighting scheme, and severalheuristic weighting schemes were investigated.Here, we only present the weighting scheme used inSVMs classification.
The weighting scheme is asfollows.
For GRIF word i, the number ofoccurrence Gin  in all the GeneRIF sentences and thenumber of occurrence Ain  in all the abstracts werecomputed and AiGi nn /  was assigned to GRIF word ias its weight.3.3 Classification3.3.1 Class definition and feature extractionThe distribution of GeneRIF sentences showed thatthe position of a sentence in an abstract is animportant clue to where the answer sentence is.Jelier et al (2003) considered only the title, the firstthree and the last five sentences, achieving the bestperformance in TREC official runs.
Their Na?veBayes model is as follows.
An abstract a isassigned a class vj by calculating vNB:ExistingGeneRIFsonLocusLinkCorrespondingMedlineAbstractsGRIF WordExtractorWeighted GRIFWordsGeneratingTraining DataTraining SVMsNewAbstractGeneRIFSentence LocatorCandidateGeneRIFFigure 2: Architecture of Extracting Candidate GeneRIFFigure 1: An Example of Complete Annotation from a Literature to Gene OntologyextractionalignmentThe Bcl10 gene was recently isolatedfrom the breakpoint region oft(1;14)(p22;q32) in mucosa-associatedlymphoid tissue (MALT) lymphomas.Somatic mutations of Bcl10 were foundin not only t(1;14)-bearing MALTlymphomas, but also a wide range ofother tumors.
?
?
Our results stronglysuggest that somatic mutations  of Bcl10are extremely rare in malignantcartilaginous tumors  and do notcommonly contribute to their molecularpathogenesis.PMID: 11836626MEDLINE abstractMutations,relativelycommon inlymphomas,are extremelyrare inmalignantcartilaginoustumors.GeneRIFl GO:0005515term: protein bindingdefinition: Interacting selectively with any protein, orprotein complex (a complex of two or more proteins thatmay include other nonprotein molecules).l GO:0008181term: tumor suppressorl GO:0006917term: induction of apoptosisl GO:0005622term: intracellularl GO:0016329term: apoptosis regulator activitydefinition: The function held by products which directlyregulate any step in the process of apoptosis.l GO:0045786term: negative regulation of cell cycleGO annotation55CD MUD MBD MBDP1 Jelier (Sentence-wise bag of words + Na?ve  Bayes) 57.83% 59.63% 46.75% 49.11%2 Sentence-wise bag of words + SVMs 58.92% 61.46% 47.86% 50.84%3 OUR Weighting scheme 50.18% 46.71% 33.47% 38.83%4 OUR Weighting scheme + SVMs 56.86% 58.81% 45.08% 48.10%5 Combined 59.51% 62.16% 48.17% 51.25%6 Combined + gene/protein names 57.59% 59.95% 46.69% 49.68%7 Combined + BWRatio feature selection 57.59% 59.90% 47.11% 50.08%8 Combined + Graphical feature selection 58.81% 61.09% 47.98% 50.92%9 Optimal Classifier 67.60% 70.74% 59.28% 62.09%10 Baseline 50.47% 52.60% 34.82% 37.91%Table 2: Comparison of performances on the 139 abstracts,,argmax ( ) ( | )j a iNB j k i jv V i S k Wv P v P w v?
?
?= ??
?where vj is one of the nine positions aforementioned,S is the set of 9 sentence positions, Wa,i is the set ofall word positions in sentence i in abstract a, wk,i isthe occurrence of the normalized word at position kin sentence i and V is the set of 9 classes.We, therefore, represented each abstract by afeature vector composed of the scores of 9sentences.
Furthermore, with a list of our 10,506GRIF words at hand, we also computed theoccurrences of these words in each sentence, givenan abstract.
Each abstract is then represented by thenumber of occurrences of these words in the 9sentences respectively, i.e., the feature vector is94,554 in length.
Classification based on this typeof features is denoted the sentence-wise bag ofwords model in the rest of this paper.
Combiningthese two models, we got totally 94,563 features.Since we are extracting sentences discussing genefunctions, it?s reasonable to expect gene or proteinnames in the GeneRIF sentence.
Therefore, weemployed Yapex (Olsson et al, 2002) andGAPSCORE (Chang et al, 2004) protein/genename detectors to count the number of protein/genenames in each of the 9 sentences, resulting in94,581 features.3.3.2 Training SVMsThe whole process related to SVM was done viaLIBSVM ?
A Library for Support Vector Machines(Hsu et al, 2003).
Radial basis kernel was adoptedbased on our previous experience.
However,further verification showed that the combinedmodel with either linear or polynomial kernel onlyslightly surpassed the baseline, attaining 50.67% forCD.
In order to get the best-performing classifier,we tuned two parameters, C and gamma.
They arethe penalty coefficient in optimization and aparameter for the radial basis kernel, respectively.Four-fold cross validation accuracy was used toselect the best parameter pair.3.3.3 Picking up the answe r sentenceTest instances were first fed to the classifier to getthe predicted positions of GeneRIF sentences.
Incase that the predicted position doesn?t have asentence, which would happen when the abstractdoesn?t have enough sentences, the sentence withthe highest score is picked for the weightingscheme and the combined model, otherwise the titleis picked for the sentence-wise bag of words model.4 Results and DiscussionsThe performance measures are based on Dicecoefficient, which calculates the overlap betweenthe candidate GeneRIF and actual GeneRIF.Classic Dice (CD) is the classic Dice formula usinga common stop word list and the Porter stemmingalgorithm.
Due to lack of space, we referred you tothe Genomics track overview for the other threemodifications of CD (Hersh and Bhupatiraju, 2003).The evaluation results are shown in Table 2.
The1st row shows the official run of Jelier?s team, thefirst place in the official runs.
The 2nd row showsthe performance when the Na?ve Bayes classifieradopted by Jelier is replaced with SVMs.
The 3rdrow is the performance of our weighting schemewithout a classifier.
The 4th row then lists theperformance when our weighting scheme iscombined with SVMs.
The 5th row is the resultwhen our weighting scheme and the sentence-wisebag of words model are combined together.
The 6throw is the result when two gene/protein namedetectors are incorporated into the combined model.The next two rows were obtained after two featureselection methods were applied.
The 9th row showsthe performance when the classifier alwaysproposes a sentence most similar to the actualGeneRIF.
The last row lists the baseline, i.e., titleis always picked.A comparative study on text categorization(Joachims, 1998) showed that SVMs outperformother classification methods, such as Na?ve  Bayes,C4.5, and k-NN.
The reasons would be that SVMsare capable of handling large feature space, textcategorization has few irrelevant features, anddocument vectors are sparse.
The comparison56between SVMs and the Na?ve  Bayes classifier againdemonstrated the superiority of SVMs in textcategorization (rows 1, 2).The performance greatly improved afterintroducing position information (rows 3, 4),showing the sentence position plays an importantrole in locating the GeneRIF sentence.
The 2%difference between rows 2 and 4 indicates that thefeatures under sentence-wise bag of words modelare more informative than those under ourweighting scheme.
However, with only 9 features,our weighting scheme with SVMs performed fairlywell.
Comparing the performance before and aftercombining our weighting scheme and the sentence-wise bag of words model (rows 2, 5 and rows 4, 5),we can infer from the performance differences thatboth models provide mutually exclusiveinformation in the combined model.
The resultshown in row 6 indicates that the information ofgene/protein name occurrences did not help identifythe GeneRIF sentences in these 139 test abstracts.We performed feature selection on the combinedmodel to reduce the dimension of feature space.There were two methods applied: a supervisedheuristic method (denoted as BWRatio featureselection in Table 2) (S. Dutoit et al, 2002) andanother unsupervised method (denoted as Graphicalfeature selection in Table 2) (Chang et al, 2002).The number of features was then reduced to about4,000 for both methods.
Unfortunately, theperformance did not improve after either methodwas applied.
This may be attributed to over-fittingtraining data, because the cross-validationaccuracies are indeed higher than those withoutfeature selection.
The result may also imply thereare little irrelevant features in this case.5 Conclusion and Future workThis paper proposed an automatic approach tolocate the GeneRIF sentence in an abstract with theassistance of SVMs, reducing the human effort inupdating and maintaining the GeneRIF field in theLocusLink database.We have to admit that the 139 abstracts providedin TREC 2003 are too few to verify theperformance among models, and the results basedon these 139 abstracts may be slightly biased.
Ournext step would aim at measuring the cross-validation performances using Dice coefficient.The syntactic  information is worth exploring,since the sentences describing gene functions mayshare some common structural patterns.
Moreover,how the weighting scheme affects the performanceis also very interesting.
We are currently trying toobtain a weighting scheme that can best distinguishGeneRIF sentence from non-GeneRIF sentencewithout classifiers.ReferencesG.
Bhalotia, P.I.
Nakov, A.S. Schwartz, and M.A.Hearst.
2003.
BioText Team Report for the TREC2003 Genomics Track.
TREC 2003 work notes:158-166.Y.C.
I. Chang, H. Hsu and L.Y.
Chou.
2002.Graphical Features Selection Method.
IntelligentData Engineering and Automated Learning,Edited by H. Yin, N. Allinson, R. Freeman, J.Keane, and S. Hubband.J.T.
Chang, H. Schutze, R.B.
Altman.
2004.GAPSCORE: finding gene and protein names oneword at a time.
Bioinformatics, 20(2):216-225.S.
Dutoit, Y.H.
Yang, M.J. Callow and T.P.
Speed.2002.
Statistical methods for identifyingdifferentially expressed genes in replicated cDNAmicroarray experiments.
J. Amer.
Statis.
Assoc.97:77-86.W.
Hersh and Ravi Teja Bhupatiraju.
2003.
TRECGenomics Track Overview.
TREC 2003 worknotes.W.J.
Hou, C.Y.
Teng, C. Lee and H.H.
Chen.
2003.SVM Approach to GeneRIF Annotation.Proceedings of TREC 2003.C.W.
Hsu, C.C Chang and C.J.
Lin.
2003.
APractical Guide to Support Vector Classification.http://www.csie.ntu.edu.tw/~cjlin/libsvm/index.html.R.
Jelier, M. Schuemie, C.V.E.
Eijk, M. Weeber,E.V.
Mulligen, B. Schijvenaars, B. Mons and J.Kors.
2003.
Searching for geneRIFs: concept-based query expansion and Bayes classification.TREC 2003 work notes: 167-174.T.
Joachims.
1998.
Text Categorization withSupport Vector Machines: Learning with ManyRelevant Features.
Proceedings of ECML-98,137-142.F.
Olsson, G. Eriksson, K. Franz?n, L. Asker and P.Lid?n.
2002.
Notions of Correctness whenEvaluating Protein Name Taggers.
Proceedings ofthe 19th International Conference onComputational Linguistics 2002, 765-771.K.D.
Pruitt, K.S.
Katz, H. Sicotte and D.R.
Maglott.2000.
Introducing RefSeq and LocusLink:Curated Human Genome Resources at the NCBI.Trends Genet, 16(1):44-47.T.
Sekimizu, H.S.
Park and J. Tsujji.
1998.Identifying the Interaction Between Genes andGene Products Based on Frequently Seen Verbsin Medline Abstracts.
Genome Information, 9:62-7157
