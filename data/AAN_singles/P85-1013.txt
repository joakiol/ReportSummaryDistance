MODULAR LOGIC GRAMMARSMichael C. McCordIBM Thomas J. Watson Research CenterP.
O.
Box 218Yorktown Heights,  NY 10598ABSTRACTThis report describes a logic grammar formalism,Modular Logic Grammars, exhibit ing a high degreeof modularity between syntax and semantics.
Thereis a syntax rule compiler (compiling into Prolog)which takes care of the bui lding of analysisstructures and the interface to a clearly separatedsemantic interpretation component dealing withscoping and the construction of logical forms.
Thewhole system can work in either a one-pass mode ora two-pass mode.
\[n the one-pass mode, logicalforms are built directly during parsing throughinterleaved calls to semantics, added automatical lyby the rule compiler.
\[n the two-pass mode, syn-tactic analysis trees are built automatical ly inthe first pass, and then given to the (one-pass)semantic component.
The grammar formalism includestwo devices which cause the automatical ly builtsyntactic structures to differ from derivation treesin two ways: \[I) There is a shift operator, fordeal ing with left-embedding constructions such asEnglish possessive noun phrases while using right-rezursive rules (which are appropriate for Prologparsing).
(2) There is a dist inction in the syn-tactic formalism between strong non-terminals andweak non-terminals, which is important for distin-guishing major levels of grammar.I.
INTRODUCTIONl'he term logic grammar will be used here, inthe context of natural language processing, to meana logic programming system (implemented normallyin P?olog), which associates semantic represent-ations Cnormally in some version of preaicate logic)with natural language text.
Logic grammars may havevarying degrees on modularity in their treatmentsof syntax and semantics.
Th, ere may or may not bean isolatable syntactic component.In writ ing metamorpilosis grammars (Colmerauer,1978), or definite clause grammars, DCG's, (a spe-cial case of metamorphosis grammars, Pereira andWarren.
1980), it is possible to build logical formsdirectly in the syntax rules by letting non-terminals have arguments that represent partiallogical forms being manipulated.
Some of the ear-ties= logic grammars (e.g., Dahl, 1977) used thisapproach.
There is certainly an appeal in beingdicect, but there are some disadvantages in thislack of modularity.
One disadvantage is that itseems difficulZ to get an adequate treatment of thescoping of quantif iers (and more general lyfocalizers, McCord, 1981) when the building of log-ical forms is too closely bonded to syntax.
Anotherdisadvantage is just a general result of lack ofmodularity: it can be harder to develop and un-derstand syntax rules when too much is going on inthem.The logic grammars described in McCord (1982,1981) were three-pass systems, where one of the mainpoints of the modularity was a good treatment ofscoping.
The first pass was the syntactic compo-nent, written as a definite clause grammar, wheresyntactic structures were explicit ly built up inthe arguments of the non-terminals.
Word senseselection and slot-f i l l ing were done in this firstpass, so that the output analysis trees were actu-ally partial ly semantic.
The second pass was aprel iminary stage of semantic interpretation inwhich the syntactic analysis tree was reshaped toreflect proper scoping of modifiers.
The third passtook the reshaped tree and produced logical formsin a straightforward way by carrying out modificationof nodes by their daughters using a modular systemof rules that manipulate semantic items -- consist-ing of logical forms together with terms that de-termine how they can combine.The CHAT-80 system (Pereira and Warren, 1982,Pereira, 1983) is a three-pass system.
The firstpass is a purely syntactic component using anextrapositJon grammar  (Pereira, 1981) and producingsyntactic analyses in r igh~ost  normal form.
Thesecond pass handles word sense selection and slot-filling, and =he third pass handles some scopingphenomena and the final semantic interpretation.One gets a great deal of modularity between syntaxand semantics in that the first component has noelements of semantic interpretation at all.In McCocd (1984) a one-pass semantic inter-pretation component, SEM, for the EPISTLE system{Miller, Heidorn and Jensen, 1981) was described.SEM has been interfaced both to the EPISTLE NLPgrammar (Heidorn, 1972, Jensen and Heidorn, 1983),as well as to a logic grammar, SYNT, written as aDCG by the author.
These grammars are purely syn-tactic and use the EPISTLE notion (op.
cir.)
ofapproximate parse, which is similar to Pereira'snotzon of r igh~s~ normal form, but was developedindependently.
Thus SYNT/SEM is a two-pass systemwith a clear modularity between syntax and seman-tics.104In DCG's and extraposition grammars, thebuilding of analysis structures .
(either logicalforms or syntactic trees) must be specified ex-plicitly in the syntax rules.
A certain amoun~ ofmodularity is then lost, because the grammar writermust be aware of manipulating these structures, andthe possibility of using the grammar in differentways is reduced.
\[n Dahl and McCord (1983), a logicgrammar formalism was described, modifier structuregrammars  (HSG's), in which structure-building (ofannotated derivation trees) is implicit in theformalism.
MSG's look formally like extrapositiongrammars, with the additional ingredient that se-mantic items (of the type used in McCord (1981))can be indicated on the left-hand sides of rules,and contribute automatically to the constructionof a syntactico-semantic tree much like that inHcCord (1981).
These MSG's were used interpretivelyin parsing, and then (essentially) the two-passsemantic interpretation system of  McCord (1981) wasused to get logical forms.
So, totally there werethree passes in this system.\[n this report, \[ wish to  describe a logicgrammar system, modular logic grammars  (MLG's),with the following features:There is a syntax rule compiler which takes careof the building of analysis structures and theinterface to semantic interpretation.There is a clearly separated semantic inter-pretation component dealing with scoping andthe construction of logical forms.The whole system (syntax and semantics) can workoptionally in either a one-pass mode or a two-pass mode.In the one-pass mode, no syntactic structuresare built, but logical forms are built directlyduring parsing through interleaved calls to thesemantic interpretation component, added auto-matically by the rule compiler.in the two-pass mode, the calls to the semanticinterpretation component are not interleaved,but are made in a second pass, operating onsyntactic analysis trees produced (automat-ically) in the first pass.The syntactic formalism includes a t device,called the shift operator, for dealing withleft-embedding constructions such as Englishpossessive noun phrases ("my wife's brother'sfriend's car") and Japanese relative clauses.~ne shift operator instructs the rule compilerto build the structures appropriate for left-embedding.
These structures are not derivationtrees, because the syntax rules are right-re-cursive, because of the top-down parsing asso-ciated with Prolo E.There is a distinction in the syntacticformalism between strong non-terminals and weaknon-terminals, which is important for distin-guishing major levels of grammar and whichsimplifies the.
working of semantic interpreta-tion.
This distinction also makes the (auto-matically produced) syntactic analysis treesmuch more readable and natural linguistically.In the absence of shift constructions, thesetrees are like derivation trees, but only withnodes corresponding to strong non-terminals.\[n an experimental MLG, the semantic componenthandles all the scoping phenomena handled bythat in McCord (1981) and more than the semanticcomponent in McCord (1984).
The logical formlanguage is improved over that in the previoussystems.The MLG formalism allows for a great deal of modu-larity in natural language grammars, because thesyntax rules can be written with very littleawareness of semantics or the building of analysisstructures, and the very same syntactic componentcan be used in either the one-pass or the two-passmode described above.Three other logic grammar systems designed withmodularity in mind are Hirschman and Puder (1982),Abramson (1984) and Porto and Filgueiras (198&).These will be compared with MLG's in Section 6.2.
THE MLG SYNTACTIC  FORMALISMThe syntactic component for an MLG consistsof a declaration of the s t rong  non-terminals, fol-lowed by a sequence of MLG syntax rules.
The dec-\[aration of strong non-terminals is of the formstrongnonterminals(NTI.NT2 .
.
.
.
.
NTn.nil).where the NTi are the desired strong non-terminals(only their principal functors are indicated).Non-terminals that are not declared strong arecalled weak.
The significance of the strong/weakdistinction will be explained below.MLG syntax  rules are of the formA ~---> Bwhere A is a non- termina l  and B is a ru le  body .
Aru le  body  is any combinat ion  of  surlCace te rmina ls ,logical terminals, goals, sh i f ted  non- termina ls ,non-tprminals, the symbol 'nil', and the cut symbol'/', using the sequencing operator ':' and the 'or'symbol 'l' (We represent left-to-right sequencingwith a colon instead of a comma, as is often donein logic grammars.)
These rule body elements areProlog terms (normally with arguments), and theyare distinguished formally as follows.A su~e terminal is of the form +A, where Ais any Prolog term.
Surface terminals corre-spond to ordinary terminals in DCG's (they matchelements of the surface word string), and thenotation is often \[A\] in DCG's.A logical  termina l  is o f  the form 0p-L~, whereOp is a modi f icat ion operator  and LF is a log ica lform.
Logical terminals are  special cases ofsemantic items, the significance of which willbe explained below.
Formally, the rule compiler105recognizes them as being terms of the form A-B.There can be any number of them in a rule body.A goal is of the form $A, where A is a term re-presenting a Prolog goal.
(This is the usualprovision for Prolog procedure calls, which areoften indicated by enclosure in braces inDCG's.
)A sh i f ted  non-terminal is either of the form%A,or of the form F%A, where A i s  a weak non-terminal and F is any ~erm.
(In practice, Fwill be a list of features.)
As indicated inthe introduction, the shift operator '~' is usedto handle left-embedding constructions in aright-recursive ~ule system.Any rule body element not of the above fourforms and not 'nil' or the cut symbol is takento be a non-terminal.A terminal is either a surface terminal or alogical ~erminal.
Surface ~erminals are buildingblocks for the word string being analyzed, andlogical terminals are building blocks for theamalysis structures.A syntax rule is called strong or weak,  .,u-cording as the non-terminal on its left-hand sideis strong or weak.It can be seen that on a purely formal level,the only differences between HLG syntax rules andDCG's are (1) the appearance of logical terminalsin rule bodies of MLG's, (2) the use of ~he shiftoperator, and (3) the distinction between strongand weak non-terminals.
However, for a given lin-guistic coverage, the syntactic component of an MLGwill normally be more compact than the correspondingDCG because structure-bui lding must be ,~xplicit inDCG's.
In this report, the arrow '-->' (as opposedto ' :> ' )  will be used for for DCG rules, and thesame notation for sequencing, terminals, etc.. willbe used for DCG's as for MLG's.What is the signif icance of the strong/weakdistinction for non-terminals and rules?
Roughly,a strong rule should be thought of as introducinga new l?vel of grammar, whe\[eas a weak rule definesanalysis within a level.
Major categories likesentence and noun phrase are expanded by strongrules, but auxil iary rules like the reoursive rulesthat find the postmodifiers of a verb are weakrules.
An analogy with ATN's (Woods, 1970) is t~atstrong non-tecminals are like the start categoriesof subnetworks (with structure-bui lding POP arcsfor termination), whereas weak non-terminals arellke internal nodes.In the one-pass mode, the HLG rule compilermakes the following distinction for strong and weakrules.
In the Horn clause ~ranslatiDn of a strong~11e, a call to the semantic interpretation compo-nent is compiled in at the end of the clause.
Thenon-terminals appearing in rules (both strong andweak) are given extra arguments which manipu!aKesemantic structures used in the call to semanticinterpretation.
No such call to semantics is com-piled in for weak rules.
Weak rules only gatherinformation to be used in the call to semantics madeby the next higher strong rule.
(Also, a shiftgenerates a call to semantics.
)In the two-pass mode, where syntactic analysistrees are built during the first pass, the rulecompiler builds in the construction of a tree nodecorresponding to  every strong rule.
The node islabeled essential ly by the non-terminal appearingon the left-hand side of the strong rule.
(A shiftalso generates the construction of a tree node.
)Details of rule compilation will be given in thenext section.As indicated above, logical terminals, and moregenerally semantic items, are of the formOperator-LogicalForm.The Operator is a term which determines how thesemantic item can combine with other semantic itemsduring semantic interpretation.
(In this combina-tion, new semantic items are formed which ;ire nolonger logical terminals.)
Logical terminals aremost typically associated with lexical items, al-though they ar~ also used to produc~, certain non-lexical ingredients in logical form analys is .
Anexample for the lexical item "each" might beQ/P - each(P ,Q) .Here the operator Q/P is such that when the "each"item modifies, say, an item having logical formman(X), P gets unified with man(X), and the re-sulting semantic item is@Q - each(~.an(X),Q)where @q is an operator which causes Q to get uni-fied wi~h the logical form of a further modificand.Details ,Jr the dse of semantic items will be givenin Section A.Now let us look at the syntactic component ofa sample HLG which covers the same ground as awelt-known DCG.
The following DCG is taken essen-tially from Pereira and Warren (1980).
It is thesort of DCG that builds logical forms directly Dymanipulating partial logical forms in arguments ofthe grammar symbols.sentfP) --> np(X,PI,P): vp(X,Pl).np(X,P~,P) --~ detfP2,PI,P): noun(X,P3):re lc lause(X ,P3 ,P2) .np(X ,P ,P )  - -> name(X).vp(X,P)  - -> t ransverb fX ,Y ,P l ) :  np(Y ,P l ,P ) .vpfX,P~ - -> in t ransverb(X ,P ) .re lcbtuse(X ,P l ,P l&P2)  - -> +that :  vp(X ,P2) .re lc~ause(* ,P ,P )  - -> n i l .det (P I ,P2 ,P )  - -> +D: $dt~D,P I ,P2 ,P ) .nounfX,P) --> +N: SnfN,X,P).name(X) - ->  +X: $nm(X).t ransverb(X ,Y ,P )  - -> +V: $ tv (V ,X ,Y ,P ) .in t ransverb(X ,P )  - -> +V: $ iv (V ,X ,P ) ./~  Lexicon * /n(maa,X,man(X) ).
n(woman, X,woman (X)).~( john) .
nm(mary).106dt (every ,P1 ,P2 ,a l l (P1 ,P2) ) .dt(a,PI,P2,ex(Pl,P2)).tv(loves,X,Y,love(X,Y)).iv(l ives,X,l ive(X)).The syntactic component of an analogous HLG is asfollows.
The lexicon is exactly the same as thatof the preceding DCG.
For reference below, thisgrammar will be called MLGRAH.strongnonterminals(sent.np.relclause.det.ni l) .sent ~> np(X): vp(X).np(X) => dec: noun(X): relclause(X).np(X) ~> name(X).vp(X) ~> transverb(X,Y): np(Y).vp(X) ~> intransverb(X).relclause(X) ~> +that: vp(X).relclause(*) ~> nil.det  ~> +O: Sdt (D ,P1 ,P2 ,P ) :  PZ /P I -P .noun(X) ----> +N: Sn(N,X ,P) :  I -P .name(X) ~> +X: Snm(X).transverb(X,Y) :>  +V: $tv(V,X,Y,P): I-P.intransverb(X) => +V: $iv(V,X,P): l-PThis small grammar illustrates all the ingredientsof HLG syntax rules except the shift operator.
Theshift will be il lustrated below.
Note that 'sent'and 'np' are strong categories but 'vp' is weak.A result is that there will be no call to semanticsat the end of the 'vp' rule.
Instead, the semanticstructures associated with the verb and object arepassed up to the 'sent' level, so that the subjectand object are "thrown into the same pot" for se-mantic combination.
(However, their surface orderis not forgotten.
)There are only two types of modif ication op-erators appearing in the semantic items of this MLG:'I' and P2/PI.
The operator 'i' means 'left-conlotn .
Its effect is to left-conjoin its asso-ciated logical form to the logical form of themodif icand (although its use in this small grammaris almost trivial).
The operator P2/PI is associ-ated with determiners, and its effect has been il-lustrated above.The semantic component will be given below inSection &.
A sa~_ple semantic analysis for thesentence "Every man that lives loves a woman" isal l(man(Xl)&live(Xl),ex(woman(X2), love(Xl,X2))).This is the same as for the above DCG.
We will alsoshow a sample parse in the next section.A fragment of an MLG illustrating the use ofthe shift in the treatment of possessive nounphrases is as follows:np ~---> deC: np l .np l  => premods: noun: np2.vp2 ~> postmods.np2 ~> poss :  %npl._The idea of this fragment can be described in arough procedural way, as follows.
In parsing annp, one reads an ordinary determiner (deC), thengoes to  np l .
In np l ,  one reads  several premodifiers(premods), say adjectives, then a head noun, thengoes to np2.
\[n np2, one may either finish byreading postmodifiers (postmods), OR one may readan apostrophe-s (poss) and then SHIFT back to npl.I l lustration for the noun phrase, "the old man'sdusty hat":the old man 'snp det npl premods noun np2 poss %npldusty hat (nil)premods noun np2 postmodsWhen the shift is encountered, the syntacticstructures (in the two-pass mode) are manipulated(in the compiled rules) so that the initial np ("theold man") becomes a left-embedded sub-structure ofthe larger np (whose head is "hat").
But if noapostrophe-s is encountered, then the structure for"the old man" remains on the top level.3.
COMPILAT ION OF MLG SYNTAX RULESIn describing rule compilation, we will firstlook at the two-pass mode, where syntactic struc-tures are built in the first pass, because the re-lationship of the analysis structures to the syntaxrules is more direct in this case.The syntactic structures manipulated by thecompi led  rules are represented as syntact i c  i tems,which are  terms o f  the formsyn(Features,Oaughters)where Features is a feature list (to be defined), andDaughters is a list consisting of syntactic itemsand terminals.
Both types of terminal (surface andlogical) are included in Daughters, but the dis-playing procedures for syntactic structures canoptionally filter out one or the other of the twotypes.
A feature  l i s t  is of the form nt:Argl, wherent is the principal fun=tot of a strong non-terminaland Argl is its first argument.
(If nt has no ar-guments, we take Argl=nil.)
It is convenient, inlarge grammars, to use this first argument Argl tohold a list (based on the operator ':') of gram-matical features of the phrase analyzed by thenon-terminal (like number  and person  for nounphrases).\[n compiling DCG rules into Prolog clauses,each non-terminal gets two extra arguments treatedas a difference list representing the word stringanalyzed by the non-terminal.
In compiling MLGrules, exactly the same thing is done to handle wordstrings.
For handling syntactic structures, theMLG rule compiler adds additional arguments whichmanipulate 'syn' structures.
The number of addi-tional arguments and the way they are used dependon whether :he non-terminal is strong or weak.
Ifthe original non-terminal is strong and has the formnt(Xl .
.
.
.
, Xn)then in the compiled version we will have107nt(Xl .
.
.
.
.
Xn, Syn, Strl,Str2).Here there is a single syntactic structure argument,Syn, representing the syntactic structure of thephrase associated by nt with the word string givenby the difference list (Strl, Sir2).On the other hand, when the non-terminal ntis weak, four syntactic structure arguments areadded, producing a compiled predication of the formnt(Xl, .... Xn, SynO,Syn, Hodsl,Hods2, Strl,Str2).Here the  pair (Hodsl, Hods2) holds a difference listfor the sequence of structures analyzed by the weaknon-terminal nt.
These structures could be 'syn'structures or terminals, and they will be daughters(modifiers) for a 'syn' structure associated withthe closest higher call to a strong non-terminal-- let  us call this higher 'syn structure the ma-t r ix  'syn' s t ructure.
The other pair  (SynO, Syn)represents the changing view of  what the matrix'syn' structure actua l ly  should be, a view that maychange because a sh i f t  is encountered while sa t i s -fy ing nt.
SynO represents the version before sat-i s fy ing  nt, and Syn represents the version a f te rsatisfying nt.
If no shift is encountered whilesatisfying nt, then Syn will  just equal SynO.
Butif a shift is encountered, the old version SynO willbecome a daughter node in the new version Syn.In compil ing a rule with several non-terminalsin the rule body, linked by the sequencing operator':', the argument pairs (SynO, Syn) and (Hodsl,Hods2) for weak non-terminals are linked, respec-tively, across adjacent non-terminals in a mannersimilar to the linking of the difference lists forword-str ing arguments.
Calls to strong non-terminals associate 'syn' structure elements withthe modifier lists, just as surface terminals areassociated with elements of the word-str ing lists.Let us look now at the compilation of a setof rules.
We will take the noun phrase grammarfragment il lustrating the shift and shown above inSection 2, and repeated for convenience here, to-gether with declarations of strong non-terminals.strongnon~erminals(np.det.noun.poss.ni l) .np => det: npl.npl => premods: noun: np2.np2 ----~-> postmods.rip2 => poss: %npl.The compiled rules are as follows:np\[Syn, Strl,Str3) <-det(Hod, Strl,Str2) &npl(syn(np:ni l ,Hod:Hods),Syn,Hods,nil, Str2,Str3).npl(Synl,Syn3, Hodsl,Hods3, Strl,Str4) <-premods(Synl,Syn2, Hodsl,Hod:Hods2,Strl,Str2) &noun(Hod, Str2,Str3) &np2(Syn2,Syn3, Hods2,Hods3, Str3,Str4).np2(Synl,Syn2, Hodsl,Hods2, Strl,Str2) <-postmods(Synl,Syn2, Hodsl,Hods2, Strl,Str2).np2(syn(Feas,HodsO),Syn, Hod:Hodsl,Hodsl,Strl,Str3) <-poss(Mod,  Strl,Str2) &npl(syn(Feas,syn(Feas,HodsO):Hods2),Syn,Hods2,nil, Str2,Str3).In the first compiled rule, the structure Synto be associated with the call to 'np' appears againin the second matrix structure argument of 'npl'The first matrix structure argument of 'npl' issyn(np:ni l ,Mod:Hods).and this will turn out to be the value of Syn ifno shifts are encountered.
Here Hod is the 'syn'structure associated with the determiner 'det', andHods is the list of modifiers determined furtherby 'npi'.
The feature list np:nil is constructedfrom the leading non-terminal 'np' of this strongrule.
(It would have been np:Argl if np had a(first) argument Argl.
)\[n the second and third compiled rules, thematrix structure pairs (first two arguments) andthe modif ier difference list pairs are linked in astraightforward way to reflect sequencing.\]'be fourth rule shows the effect of the shift.Here syn(Feas,HodsO), the previous "conjecture" forthe matrix structure, is now made simply the firstmodif ier in the larger structuresyn(Feas,syn(Feas,HodsO):Hods2)which becomes the new "conjecture" by being placedin the first argument of the further call to 'npl'.If the shift operator had been used in its binaryform FO%npl, then the new conjecture would besyn(NT:F,syn(NT:FO,Mods0):Hods2)where the old conjecture was syn(NT:F,HodsO).
\[nlarger grammars, this allows one to have a com-pletely correct feature list NT:FO for the left-embedded modifier.To illustrate the compilation of terminalsymbols, let us look at the ruledet => +O: Sdt(D,PI,P2,P): P2/Pt-P.from the grammar HLGRAM in Section 2.
The compiledrule isdet(syn(det:ni l ,+D:P2/PI-P:ni l) ,  D.Str,Str) <-dt(D,PI,P2,P).Note that both the surface terminal +D and thelogical terminal P2/PI-P are entered as modif iersof the 'det' node.
The semantic interpretationcomponent looks only at the logical terminals, butin certain applications it is useful to be able tosee the surface terminals in the syntactic struc-tures.
As mentioned above, the display proceduresfor syntac=i?
structures can optional ly show onlyone type of terminal .108The display of the syntactic structure of thesentence "Every man loves a woman" produced byMLGRAM is as follows.sentence:nilnp:Xldet:nilX2/X3-alI(X3,X2)l-man(Xl)l-love(Xl,XA)np:XAdet:nilXS/X6-ex(X6,XS)l-woman(X&)Note that no 'vp' node is shown in the parse tree;'vp' is a weak non-terminal.
The logical formproduced for this tree by the semantic componentgiven in the next section isall(man(Xl), ex(woman(X2),love(XI,X2))).Now let us look at the compilation of syntaxrules for the one-pass mode.
In this mode, syn-tactic structures are not built, but semanticstructures are built up directly.
The rule compileradds extra arguments to non-terminals for manipu-lation of semantic structures, and adds calls tothe top-level semantic interpretation procedure,'semant'.The procedure 'semant' builds complex semanticstructures out of simpler ones, where the originalbuilding blocks are the logical terminals appearingin the MLG syntax rules.
In this process of con-struction, it would be possible to work with se-mantic items (and in fact a subsystem of the rulesdo work directly with semantic items), but it ap-pears to be more efficient to work with slightlymore elaborate structures which we call augmentedsemantic items.
These' are terms of the formsem(Feas,Op,LP),where Op and \[2 are such that Op-LF is an ordinarysemantic item, and Fees is either a feature listor the list terminal:nil.
The latter form is usedfor the initial augmented semantic items associatedwith logical terminals.As in the two-pass mode, the number of analysisstructure arguments added to a non-terminal by thecompiler depends on whether the non-terminal isstrong or weak.
If the original non-terminal isstrong and has the formnt(Xl, .
.
.
,  Xn)then in the compiled version we will havent(Xl, ..., Xn, Semsl,Sems2, Strl,Str2).Here (Semsl, Sems2) is a difference list of aug-mented semantic items representing the list of se-mantic s~ruotures for the phrase associated by n~with the word s~ring given by the difference list(Strl, Sir2).
In the syntactic (two-pass) mode,only one argument (for a 'syn') is needed here, butnow we need a list of structures because of araising phenomenon necessary for proper scoping,which we will  discuss in Sections A and 5.When the non-terminal nt is weak, five extraarguments are added, producing a compiled predi-cation of the formnt(Xl, ..., Xn, Fees, SemsO,Sems, Semsl,Sems2,Strl,Str2).Here Fees is the feature list for the matrix strongnon-terminal.
The pair (SemsO, Sems) representsthe changing "conjecture" for the complete list of.daughter (augmented) semantic items for the matrixnode, and is analogous to first extra argument pairin the two-pass mode.
The pair (Semsl, Sems2) holdsa difference list for the sequence of semantic itemsanalyzed by the weak non-terminal nt.
Semsl willbe a final sublist of SemsO, and Sems2 will ofcourse be a final sub|ist of Semsl.For each strong rule, a cal-i to 'semant' isadded at the end of the compiled form of the rule.The form of the call issemant(Feas, Sems, Semsl,Sems2).Here teas is the feature list for the non-terminalon the left-hand side of the rule.
Sems is the finalversion of the list of daughter semantic items(after all adjustments for shifts) and (SemsL,Sems2) is the difference list of semantic itemsresulting from the semantic interpretation for thislevel.
(Think of Fees and Sems as input to'semant', and (Semsl, Sems2) as output.)
CSemsl,Sems2) will be the structure arguments for thenon-terminal on the left-hand side of the strongrule.
A call to 'semant' is also generated when ashift is encountered, as we will see below.
Theactual working of 'semant' is the topic of the nextsection.For the shift grammar fragment shown above,the compiled rules are as follows.np(Sems,Sems0, Strl,Str3) <-det(Semsl,Sems2, Strl,Str2) &npl(np:nil, Semsl,Sems3, Sems2,nil, Str2,Scr3) asemant(np:nil, Sems3, Sems,SemsO).npl(Feas, Semsl,Sems3, Semsa,Sems7, Strl,St\[~) <-premods(Feas, Semsl,Sems2, SemsA,Sems5,Strl,Str2) &noun(Sems5,Sems6, Str2,Str3) &np2(Feas, Sems2,Sems3, Sems6,SemsT, Str3,StrA).np2(Feas, Semsl,Sems2, Sems3,Semsd, Strl,Str2) <-postmods(Feas, Semsl,Sems2, Sems3,SemsA,Strl,Str2).npE(Feas, Semsl.SemsA, SemsS,Sems6, Strl,Str3) <-poss(SemsS,Sems6, Strl,Str2) &semant(Feas, Semsl, Sems2,Sems3) &npl(Feas, Sems2,Sems~, Sems3,nil, Str2,Str3).In the first compiled rule (a strong rule), the pair(Seres, SemsO) is a difference list of the semanticitems analyzing the noun phrase.
(Typically there109will just be one element in this list, but therecan be more when modifiers of the noun phrasescontain quantif iers that cause the modifiers to getpromoted semantically to be sisters of the nounphrase . )
Th is  d i f fe rence  l i s t  is  the  output  of  theca l l  to ' semant '  compi led in at  the  end of  the  f i r s trule.
The input to this call is the list Sems3(along with the feature list np:nil).
We arriveat Sems3 as follows.
The list Semsl is started by, !the call to det ; its first element is thedeterminer (if there is one), and the list is con-tinued in the list Sems2 of modif iers determinedfurther by the call to 'npl'.
In this call to 'npl',the initial list Semsl is given in the second ar-gument of 'npl' as the "initial verslon for thefinal list of modifiers of the noun phrase.
Sems3,being in the next argument of 'npl', is the "finalversion" of the np modifier list, and this is thelist given as input to 'semant'.
\[f the processingof 'npl' encounters no shifts, then Sems3 will justequal 5ems I.\[n the second compiled rule (for 'npl'), the"versions" of the total list of modifiers are \[inkedin a chain(Semsl, 5ems2, Sems3)in the second and third arguments of the weak non-terminals.
The actual modifiers produced by thisrule are linked in a chain(SemsA, Sems51 Sems6, SemsT)in the fourth and fifth arguments of the weak non-terminals and the first and second arguments of thestrong non-terminals.
A similar situation holdsfor the first of the 'np2' rules.\[n the second 'npZ' rule, a shift is encount-ered, so a call to 'semant' is generated.
This isnecessary because of the shift of levels; the mod-ifiers produced so far represent all the modifiersin an np, and these must be combined by 'semant'to get the analysis of this np.
As input to thiscall to 'semant', we take the list Semsl, which isthe current version of the modif iers of the matrixnp.
The output is the difference list .(Sems2,gems3).
Sems2 is given to the succeeding call to'npl' as the new current version of the matrixmodifier list.
The tail Sems3 of the differencelist output by 'semant' is given to 'npl' in itsfourth argument to receive further modifiers.
SemsAis the f~.nal uersion of the matrix modifier list,determined by 'npi I , and this information is alsoput in the third a,'gument of 'np2'.
The differencelist (Sems5, Semsb) contains the single elementproduced by 'poss', and this list tails off the listSemsl.When a semantic item Op-LF occurs in a rulebody, the rule compiler inserts the augmented se-mantic item sem(terminal:nil ,Op,LF).
As an example,the weak ruletransverb(X,Y) ~> +V: $tv(V,X,Y,P): I-P.compiles into the clausetransverb(X,Y, Feas, Semsl,Semsl,sem(terminal:ni l , l ,P):Sems2,Sems2,V.Str,Str) <-tv(V,X,Y,P).The strong ruledet -----> +D: Sdt(D,PI,P2,P): P2/PI-P.compiles into the clausedet(Semsl,Sems2, D.SemsA,Sems&)<-dt(D,P1,P2,P)  &semant(det:nil,sem(terminal:ni l ,P2/PI,P):ni l ,Semsl,Sems2).4.
SEMANTIC INTERPRETATION FOR MLG'SThe semantic interpretation schemes for boththe one-pass mode and the two-pass mode share alarge core of common procedures; they differ onlyat the top level.
In both schemes, augmented se-mantic items are combined with one another, formingmore and more complex items, until a single itemis constructed which represents the structure ofthe whole sentence.
In this final structure, onlythe logical form component is of interest; the othertwo components are discarded.
We will describe thetop levels for both modes, then describe the commoncore.The top level for  the one-pass mode is simpler,because semantic interpretation works in tandem withthe parser, and does not itself have to go throughthe parse tree.
The procedure 'semant', which hasinterleaved calls in the compiled syntax rules,essential ly is the top-level procedure, but thereis some minor cleaning up that has to be done.
Ifthe top-level non-terminal is 'sentence' (with noarguments), then the top-level analysis procedurefor the one-pass mode can beanalyzeCSent) <-sentence(Sems,ni l ,Sent,ni l)  &semant(top:nil,Sems,sem(*,e,iF):nil,nil) &outlogform(LF).Normally, the first argument, Sems, of 'sentence'will be a list containing a single augmented se-mantic item, and its logical form component willbe the desired logical form.
However, for somegrammars, the ~dditional call to 'semant' is neededto complete the modification process.
The procedure'outlogform' simplifies the logical form and outputsit.~ne definition of 'semant' itself is given ina single clause:semant (Feas ,Sems,Sems2,Sems3)  <-reorder (Sems,Sems l )  &modlist(Semsl,sem(Feas,id,t),Sem,Sems2,Sem:Sems3).Here, the  procedure  ' reorder '  takes  the  l i s t  Semsof augmented semantic items to be combined and re-110orders it (permutes it), to obtain proper (or mostlikely) scoping.
This procedure belongs to thecommon core of the two methods of semantic inter-pretation, and will be discussed further below.The procedure 'modlist' does the following.
A callmodlist(Sems,SemO,Sem,Semsl,Sems2)takes a list Sems of (augmented) semantic items andcombines them with (lets them modify) the item SemO,producing an item Sem (as the combination), alongwith a difference list (Semsl, Sems2) of items whichare promoted to be sisters of gem.
The leftmostmember of Sems acts as the outermost modifier.Thus, in the definition of 'semant', the result listSemsl of reordering acts on the trivial itemsem(Feas,id,t) to form a difference list (gems2,Sem:Sems3) where the result Sem is right-appendedto its sisters.
'modlist' also belongs to thecommon core, and will be defined below.The top level for the two-pass system can bedefined as follows.analyze2(Sent) <-sentence(gyn,Sent,nil) &synsem(Syn,Sems,nil) &semant(top:nil ,gems,sem(*,e,LF):nit,ni I)  &outlogform(LF).The only difference between this and 'analyze' aboveis that the call to 'sentence' produces a syntacticitem Syn, and this is given to the procedure'synsem'.
The latter is the main recursive proce-dure of the two-pass system.
A callsynsem(Syn,SemsI,Sems2)takes a syntactic item Syn and produces a differencelist (Semsl, Sems2) of augmented semantic itemsrepresenting the semantic structure of Syn.
(Typ-i ca l l y ,  this list will just have one element, butit can have more if modifiers get promoted to sis-ters of the node.
)The definition of 'synsem' is as follows.synsem(syn(Feas,Mods),Sems2,Sems3) <-synsemlist(Mods,Sems) &reorder(Sems,Semsl) &modlist(Semsl,sem(Feas,id,t),Sem,Sems2,Sem:Sems3).Note that this differs from the definition of'semant' only in that 'synsem' must firstrecursively process the daughters Mode of its inputsyntactic item before call ing 'reorder' and'modlist' The procedure 'synsemlist' that proc-esses the daughters is defined as follows.synsemlist(syn(Feas,Mods0):Mods,Semsl) <- /&synsem(syn(Feas,ModsO),SemsI,Sems2) &synsemlist(Mods,Sems2).synsemlist((Op-LF):Mods,sem(terminal:ni l ,Op,LF):Sems) <- /&synsemlist(Mods,Sems).synsemlist(Nod:Mods,Sems) <-synsemlist(Mods,Sems).synsemlist(nil,nil).The first clause calls 'synsem' recursively whenthe daughter is another 'syn' structure.
The secondclause replaces a logical terminal by an augmentedsemantic item whose feature list is terminal:nil.The next clause ignores any other type of daughter(this would normally be a surface terminal).Now we can proceed to the common core of thetwo semantic interpretation systems.
The procedure'modlist' is defined recursively in a straightfor-ward way:modlist(Sem:Sems, Sem0, Sem2, Semsl,Sems3) <-modlist(Sems, SemO, Seml, Sems2,Sems3) &modify(Sem, Seml, Sem2, Semsl,Sems2).modlist(nil, Sem, gem, Sems,Sems).Here 'modify' takes a single item Sem and lets itoperate on Seml, giving Sem2 and a difference list(Semsl, Sems2) of sister items.
Its definlt ion ismodify(Sem, Seml, Seml, Sem2:Sems,Sems~ <-raise(Sem,Seml,Sem2) &/.modify(sem(*,Op,LF),sem(Feas,Opl,LFI),sem(Feas,Op2,LF2), Sems,Sems) <-mod(Op-LF, OpI-LFI, Op2-LF2).Here 'raise' is responsible for raising theitem Seml so that it becomes a sister of the itemSeml; gem2 is a new version of Seml after theraising, although in most cases, gem2 equals geml.Raising occurs for a noun phrase like "a chickenin every pot", where the quantifier "every" hashigher scope than the quantifier "a".
The semanticitem for "every pot" gets promoted to a left sisterof that for "a chicken".
'raise' is defined bas-ically by a system of unit clauses which look atspecific types of phrases.
For the small grammarMLGRAM of Section 2, no raising is necessary, andthe definit ion of 'raise' can just be omitted.The procedures 'raise' and 'reorder' are twokey ingredients of reshaping (the movement of se-mantic items to handle scoping problems), which wasdiscussed extensively in McCord (1982, 1981).
\[nthose two systems, reshaping was a separate passof semantic interpretation, but },ere, as in McCord(198&), reshaping is interleaved with the rest ofsemantic interpretation.
In spite of the new top-level organization for semantic interpretation ofMLG's, the low-level procedures for raising andreordering are basically the same as in the previoussystems, and we refer to the previous reports forfurther discussion.The procedure 'mod', used in the second clausefor 'modify', is the heart of semantic interpreta-tion.mod(Sem, Seml, Sem2)means that the (non-augmented) semantic item Semmodifies (combines with) the item Semi to give theitem Sem2.
'mod' is defined by a system consistingbasically of unit clauses which key off the mod-ification operators appearing in the semantic items.111In the experimental MLG described in the next sec-tion, there are 22 such clauses.
For the grammarMLGRAM of Section 2, the following set of clausessuffices.mod(id -~, Sem, Sem) <- / .mod(Sem, id -~, Sem) <- /.mod(l-P, Op-Q, Op-R) <- and(P,Q,R).mod(P/Q-R, Op-Q, @P-R).mod(@P-Q, Op-P, Op-Q).The first two clauses say that the operator 'id'acts like an identity.
The second clause defines'i' as a left-conjoining operator (its correspondinglogical form gets left-conjoined to that of themodificand).
The call and(P,Q,R) makes R=P&Q, ex-cept that it treats 't' ('true') as an identity.The next clause for 'mod' allows a quantif ier se-mantic item like P/Q-each(Q,P) to operate on an itemlike I-man(X) to give the item @P-each(man(X),P).The final clause then allows this item to operateon I-live(X) to give l-each(man(X),l ive(X)).The low-level procedure 'mod' is the same (inpurpose) as the procedure 'trans' in HcCord (1981),amd has close similarit ies to 'trans' in McCord(1982) and 'mod' in McCord (198&), so we refer tothis previous work for more il lustrations of thisapproach to modification.For MLGRAH, the only ingredient of semanticinterpretation remaining to be defined is 'reorder'.We can define it in a way that is somewhat moregeneral than is necessary for this small grammar,but which employs a technique useful for largergrammars.
Each augmented semantic item is assigneda precedence number, and the reordering (sorting)is done so that wh@n item B has higher precedencenumber than item A, then B is ordered to the leftof A; otherwise items are kept in their originalorder.
The following clauses then define 'reorder'in a way suitable for MLGRAM.reorder(A:L,H) <-reorder(L,Ll) & insert(A,Li,M).reordef(nit,n?1).insert(A,B:L,S:Ll) <-prec(A,PA) & prec(B,PB) & gt(PB,PA) &/&insert(A,L,Li).insert(A,L,a:L~.prec(sem(term~nal:*,e,~),2) <- /.pruc(sem(relc!ause:e,e,e), l)  <- /.prec(e,3).~nus terminals are ordered to the end, except  notafter relative clauses.
In particular, the subjectand object of a sentence are ordered before the verb(~ terminal in the sentence), and this allows thessraightforward process of modif ication in :mod'to scope the quantif iers of the subject and objectover the material of the verb.
One can alter thedefinit ion of 'prec' to get finer distinctions in~coping, and for this we refer to McCord (1982,1981).For a grammar as small as MLGRAM, which hasno treatment of scoping phenomena, the total tom-plexity of the MLG, including the semantic inter-pretation component we have given in this Section,is certainly greater than that of the comparableDCG in Section 2.
However, for larger grammars,the modularity is definitely worthwhile -- concep-tually, and probably in the total size of the sys-tem.5.
AN EXPERIMENTAL  MLGThis section describes briefly an experimentalMLG, called HODL, which covers the same linguisticground as the grammar (called HOD) in HcCord (198l).The syntactic component of HOD, a DCG, is essen-tially the same as that in HcCord (1982).
Onefeature of these syntactic components is a system-atic use of slot-f i l l ing to treat complements ofverbs and nouns.
This method increases modularitybetween syntax and lexicon, and is described indetail in McCord (1982).One purpose of HOD, which is carried over toMODL, is a good treatment of scoping of modifiersand a good specif ication of logical form.
Thelogical form language used by >IODL as the targetof semantic interpretation has been improved some-what over that used for HOD.
We describe here someof the characteristics of the new logical formlanguage, called LFL, and give sample LFL analysesobtained by MODL, but we defer a more detailed de-scription of LFL to a later report.The main predicates of LFL are word-senses  forwords in the natural language being analyzed, for'example, believel(X,Y) in the sense "X believes thatY holds".
Quantifiers, like 'each', are specialcases of word-senses.
There are also a small numberof non-lexJcal predicates in LFL, some of which areassociated with inflections of words, like 'past'for past tense, or syntactic constructions, like'yesno' for yes-no questions, or have signif icanceat discourse level, dealing for instance withtopic/comment.
The arguments for predicates of LFLcan be constants, variables, or other logical forms(expressions of LFL).Expressions of LFL are either predications (inthe sense just indicated) or combinations of LFLexpressions using the conjunction '&' and the in-dex ing operator ':'.
Specifically, if P is a log-ical form and E is a variable, then P:E (read "Pindexed by E"~ is also a logical form.
When anindexed logical form P:E appears as part of a largerlogical form Q, and the index variable E is usedelsewhere in Q. then E can be thought of roughlyas standing for P together with its "context".Contexts include references to time and place whichare normally left implicit in natural language.When P specifies an event, as in see(john,mary),writ ing P:E and subsequently using E will guaranteethat E refers to the same event.
In the logicalform language used in McCord (1981), event variables(as arguments of verb and noun senses) were usedfor indexing.
But the indexing operator is morepowerful because it can index complex logical forms.For some applications, it is sufficient to ignorecontexts, and in such cases we just think of P:Eas verifying P and binding E to an instantiation112of P. In fact, for PROLOG execution of logicalforms without contexts, ':' can be defined by thesingle clause: P:P <- F.A specific purpose of the MOD system in McCord(1981) was to point out the importance of a classof predicates called focaiizers, and to offer amethod for dealing with them in semantic interpre-tation.
Focalizers include many determiners,adverbs, and adjectives (or their word-senses), aswell as certain non-lexical predicates like 'yesno'.Focalizers take two logical form arguments calledthe base and the fOCUS:focalizer(Base,Focus).The Focus is often associated with sentence stress,hence the name.
The pair (Base, Focus) is calledthe SCOpe of the focalizer.The adverbs 'only' and 'even' are focalizerswhich most clearly exhibit the connection withstress.
The predication only(P,Q) reads "the onlycase where P holds is when Q also holds".
We getdifferent analyses depending on focus.John only buys books at Smith's.only(at(smith,buy(john,X1)), book(X1)).John only buys books at Smith's.only(book(Xl)&at(X2,buy(john,Xl)), X2=smith).quantificational adverbs like 'always' and'seldom', studied by David Lewis (1975), are alsofocalizers.
Lewis made the point that thesequantifiers are properly considered unseJKtJve, inthe sense that they quantify over all the freevariables in (what we call) their bases.
For ex-ample, inJohn always buys books at Smith's.always(book(Xl)&at(X2,buy(john,Xl)), X2=smith) ?the quantification is over both X1 and X2.
(Aparaphrase is "Always, if X1 is a book and John buysX1 at X2, then X2 is Smith's".
)Quantificational determiners are alsofocalizers (and are unselective quantifiers); theycorrespond closely in meaning to thequantificational adverbs ('all' - 'always', 'many''often', 'few' - 'seldom', etc.).
We have theparaphrases:Leopards often attack monkeys in trees.often(leopard(Xl)&tree(X2)&in(X2,attack(Xl,X3)),monkey(X3)).Many leopard attacks in trees are (attacks)on monkeys.many(leopard(Xl)&tree(X2)&in(X2,attack(Xi,X3)),monkey(X3)).Adverbs and adjectives involving comparisonor degree along some scale of evaluation (a wideclass) are also focalizers.
The base specifies thebase of comparison, and the focus singles out whatis being compared to the base.
This shows up mostclearly in the superlative forms.
Consider theadverb "fastest":John ran fastest yesterday.fastest(run(john):E, yesterday(E)).John ran fastest yesterday.fastest(yesterday(run(X)), X=john).In the first sentence, with focus on "yesterday",the meaning is that, among all the events of John'srunning (this is the base), John's running yesterdaywas fastest.
The logical form illustrates the in-dexing operator.
\[n the second sentence, with focuson "John", the meaning is that among all the eventsof running yesterday (there is an implicit locationfor these events), John's running was fastest.As an example of a non-lexical focalizer, wehave yesno(P,q), which presupposes that a case ofP holds, and asks whether P & Q holds.
(The pair(P, Q) is like Topic/Comment for yes-no questions.
)Example:Did John see M@ry yesterday?yesno(yesterday(see(john,X)), X=mary).It is possible to give Prolog definitions formost of the focalizers discussed above which aresuitable for extensional evaluation and which amountto model-theoretic definitions of them.
This willbe discussed in a later report on LFL.A point of the grammar HODL is to be able toproduce LFL analyses of sentences using the modularsemantic interpretation system outlined in thepreceding section, and to arrive at the right (ormost likely) scopes for focalizers and other modi-fiers.
The decision on scoping can depend onheuristics involving precedences, on very reliablecues from the syntactic position, and even on thespecification of loci by explicit underlining in~he input string (which is most relevant foradverbial focalizers).
Although written text doesnot often use such explici~ specification ofadverbial loci, it is important that the system canget the right logical form after having some spec-ification of the adverbial focus, because thisspecification might be obtained from prosody inspoken language, or might come from the use ofdiscourse information.
\[t also is an indicationof the modularity of the system that it can use thesame syntactic rules and parse path no matter wherethe adverbial focus happens to lie.Most of the specific linguistic informationfor semantic interpretation is encoded in theprocedures 'mod', 'reorder', and 'raise', whichmanipulate semantic items.
In MODL there are 22clauses for the procedure 'mod', most of which areunit clauses.
These involve ten different modifi-cation operators, four of which were illustratedin the preceding section.
The definition of 'mo<l'in MODL is taken fairly directly from the corre-sponding procedure 'trans' in HOD (McCord, 1981),although there are some changes involved in handlingthe new version of the logical form language (LFL),113especially the  indexing operator.
The definitionsof 'reorder' and 'raise' are essential ly the sameas for procedures in HOD.An il lustration of analysis in the two-passmode in HODL is now given.
For the sentence"Leopards only attack monkeys in trees", the syn-tactic analysis tree is as follows.sentnounphl-leopard(X)avp(P<Q)-only(P,Q)l-attack(X,Y)nounphl-monkey(Y)prepph@@R-in(Z,R)nounphl-tree(Z)Here we display complete logical terminals in theleaf nodes of the tree.
An indicat\[on of themeanings of the operators (P<Q) and @@R will begiven below.\[n the semantic interpretation of the prepo-sitional phrase, the 'tree' item gets promoted (by'raise') to be a left-sister of the the 'in' item,and the list of daughter items (augmented semanticitems) of the 'sent' node is the following.nounph i leopard(X)avp P<Q only(P,Q)terminal I attack(X,Y)nounph 1 monkey(Y)nounph I tree(Z)prepph @@R in(Z,R).Here we di~:play each augmented semantic itemsem(nt:Feas,Op,LF) simply in the form nt Op LF.The material in the first field of the 'monkey' itemactually shows that it is stressed.
The reshapingp~ocedure 'reorder' rearran6es these items into theorder:nounph I leopard(X)nounph 1 tree(Z)prepph @@R in(Z,R)terminal I attack(X,Y)avp P<Q only(P,Q)nounph 1 monkey(Y)Next, these items successively modify (accordingto the rules for 'mod') the matrix item, sent idt, with the rightmost daughter acting as innermostoodifier.
The rules for 'mod' involving the oper-ator (P<Q) associated with only(P,Q) are designedso that the logical form material to the right of'only' goes into the focus Q of 'only' and the ma-terial to the left goes into the base P. The ma-terial to the right is just monkey(Y).
The itemson the left ('leopard', 'tree', 'in', 'attack') areallowed to combine (through 'mod') in an independentway before being put into the base of 'only'.
Theoperator ~@R associated with in(Z,R) causes R tobe botmd to the logical form of the modif icand --attack(X,Y).
The combination of items on the leftof 'only' isleopard(X)&tree(Z)&in(Z,attack(X,Y))This goes into the base, so the whole logical formisonly( leopard(X)&tree(Z)&in(Z,attack(X,Y)),monkey(Y)).For detai led traces of logical form constructionby this method, see McCord (1981).An i l lustration of the treatment of left-embedding in HODL in a two-pass analysis of thesentence "John sees each boy's brother's teacher"is as follows.sentnounph\[-(X=john)l-see(X,W)nounphnounphnounphdeterminerQ/P-each(P,Q)l-boy(Y)l-possl-brother(Z,Y)1-poss1-teacher(W,Z)Logical form...each(boy(Y),the(brother(Z,Y),the(teacher(W,Z),see(john,W)))).The MODL noun phrase rules include the shift (in away that is an elaboration of the shift grammarfragment in Section 2), as well as rules for slot-filling for nouns like 'brother' and 'teacher' whichhave more than one argument in logical form.
Ex-actly the same logical form is obtained by MODL forthe sentence "John sees the teacher of the brotherof each boy".
Both of these analyses involveraising.
\[n =he first, the 'poss' node resultingfrom the apostrophe-s is raised to become a definitearticle.
In the second, the prepositional phrases(their semantic structures) are promoted to besisters of the "teacher" node, and the order of thequantlfiers ts (correctly) reversed.The syntactic component of MODL was adaptedas closely as possible from that of HOD (a DCG) inorder to get an idea of the eff iciency of HLG's.The fact that the MLG rule compiler produces morestructure-building arguments than are in the DCGwould tend to |engthen analysis times, but it ishard to predic~ the effect of the different organ-ization of the semantic interpreter (from a three-pass system to a one-pass and a two-pass versionof MODL).
7"no followin E five sentences were usedfor timing tests.Who did John say that the man introduced Mary to?Each book Mary said was given to Bill114was written by a woman.Leopards only attack monkeys in trees.John saw each boy's brother's teacher.Does anyone wanting to see the teacher knowwhether there are any hooks left in this room?Using Waterloo Prolog (an interpreter) on an IBM3081, the following average times to  get the logicalforms for the five sentences were obtained (notincluding ~ime for \[/0 and initial word separation):MODL, one-pass mode - 40 mill iseconds.MODL, two-pass mode - 42 mill iseconds.MOD - 35 mill iseconds.So there was a loss of speed, but not a significantone.
MODL has also been implemented in PSC Prolog(on a 3081).
Here the average one-pass analysistime for the five sentences was improved to 30mill iseconds per sentence.On the other hand, the MLG grammar (in sourceform) ls more compact and easier to understand.The syntactic components for MOD and MODL werecompared numerically by a Prolog program that totalsup the sizes of all the grammar rules, where the sizeof a compound term is defined to be I plus the sumof the sizes of its arguments, and the size of anyother term is I.
The total for MODL was l&33, andfor MOD was 1807, for a ratio of 79%.So far, nothing has been said in this reportabout semantic constraints in HODL.
Currently, MODLexercises constraints by unification of semantictypes.
Prolog terms representing type requirementson slot-fi l lers must be unified with types of actualfillers.
The types used in MODL are t%/pe trees.A type t r~ is either a variable {unspecified type)or a term whose principal functor is an atomic type(like 'human'), and whose arguments are subordinatetype trees.
A type tree T1 is subordinate to a typetree T2 if either T1 is a variable or the principalfunctor of T1 is a subtype (ako) of the principalfunctor of T2.
Type trees are a generalization ofthe type  l ists used by Dahl (1981), which are listsof the form TI:T2:T3:..., where T1 is a supertypeof T2, T2 is a supertype of TS, ..., and the tailof the list may be a variable.
The point of thegeneralization is to allow cross-classification.Multiple daughters of a type node cross-classifyit.
The lexicon in MODL includes a preprocessorfor lexical entries which allows the original lex-ical entries to specify type constraints in a com-pact, non-redundant way.
There is a Pro|o Krepresentation for type-hierarchies, and the \[exi-cal preprocessor manufactures full type trees froma specif ication of their leaf nodes.\[n the one-pass mode for analysis with MLG's,logical forms get built up during parsing, so log-ical forms are available for examination by semanticchecking procedures of the sort outl ined in McCord(198&).
If such methods are arguably best, thenthere may be more argument for a one-pass system(with interleaving of semantics).
The generalquestion of the number of passes in a natural lan-guage understander is an interesting one.
The MLGformalism makes this easier to investigate, becausethe same syntactic component can he used with one-pass or two-pass interpretation.In MODL, there is a small dict ionary storeddirectly in Prolog, but MODL is also interfaced toa large dict ionary/morphology system (Byrd, 1983,1984) which produces syntactic and morphologicalinformation for words based on over 70,000 lemmata.There are plans to include enough semantic infor-mation in this dictionary to provide semantic con-straints for a large MLG.Alexa HcCray is working on the syntactic com-ponent for an MLG with very wide coverage.
I wishto thank her for useful conversations about thenature of the system.6.
COMPARISON WITH OTHER SYSTEMSThe Restriction Grammars  (RG's) of HLrschmanand Puder (1982) are logic grammars that were de-signed with modularity \[n mind.
Restriction Gram-mars derive from the Linguistic String Project{Sager, 1981).
An RG consists of conLexE-freephrase structure rules to  which restrictions areappended.
The rule compiler {written in ProIo K andcompiling into Prolog), sees to it that derivationtrees are constructed automatical ly during parsing.The restrictions appended to the rules are basicallyProlog procedures which can walk around, during theparse, in the partial ly constructed parse tree, andcan look at the words remaining in the input stream.Thus there is a modularity between the phrase-structure parts of the syntax rules and the re-strictions.
The paper contains an interestingdiscussion of Prolog representations of parse treesthat make it easy to walk around in them.A disadvantage of RG's is that the automat-ically constructed analysis tree is just a deriva-tion tree.
With MLG's, the shift operator and thedeclaration of strong non-terminals produce analy-sis structures which are more appropriate seman-tically and are easier to read for large grammars.\[n addition, MLG analysis trees contain logicalterminals as building blocks for a modular semanticinterpretation system.
The method of walking aboutin the partial ly constructed parse tree is powerfuland is worth exploring further; but the more commonway of exercising constraints in logic grammars byparameter passing and unification seems to be ade-quate linguistically and notationally more compact,as well as more efficient for the compiled Prologprogram.Another type of logic grammar developed withmodularity in mind is the Definite Clause Trans-lation Grammars (DCTG's) of Abramson (1984).
Thesewere inspired partial ly by RG's (Hirschman andPuder, 1982), by MSG's {Dahl and McCord, 1983), andby Attribute Grammars (Knuth, 1968).
A DCTG ruleis like a DCG rule with an appended list of clauseswhich compute the semantics of the node resultingfrom use of the rule.
The non-terminals on theright-hand side of the syntactic portion of the rulecan be indexed by variables, and these index vari-ables can be used in the semantic portion to linkto  the syntactic portion.
For exa~le ,  the DCG rule115sent(P) --> np(X,P1,P): vp(X,Pl).from the DCG in Section 2 has the DCTG equivalent:sent ::= np@N: vp@V <:>logic(P) ::- N@Iogic(X,PI,P) & V@logic(X,Pl).
(Our notation is sl ightly different from Abramson'sand is designed to fit the Prolog syntax of thisreport.)
Here the indexing operator is '@'.
Thesyntactic portion is separated from the semanticportion by the operator '<:>'.
The non-terminalsin DCTG's can have arguments, as in DCG's, whichcould be used to exercise constraints (re-strictions), but it is possible to do everythingby referring to the indexing variables.
The DCTGrule compiler sees to the automatic constructionof a derivation tree, where each node is labelednot only by the expanded non-terminal but also bythe list of clauses in the semantic portion of theexpanding rule.
These clauses can then be used incomputing the semantics of the node.
When an in-dexed non-terminal NT@X appears on the right-handside of a rule, the indexing variable X getsiastantiated to the tree node corresponding to theexpansion of NT.There is a definite separation of DCTG rulesinto a syntactic portion and a semantic portion,with a resulting increase of modularity.
Proceduresinvolving different sorts of constraints can beseparated from one another, because of the deviceof referring to the indexing variables.
However,it seems that once the reader (or writer) knows thatcertain variables in the DCG rule deal with theconstruction of logical forms, the original DCG ruleis just as easy (if not easier) to read.
The DCTGrule is definitely longer than the DCG rule.
Thecorresponding MLG rule:sent :>  np(X): vp(X).is shorter, and does not need to mention logicalforms at  all.
Of course, there are relevantportions of the semantic component that are appliedin connection with this rule, but many parts of thesemantic component are relevant to several syntaxrules, thus reducing the total size of the system.A claimed advantage for DCTG's is that thesemantics for each rule is listed locally with eachrule.
There is certainly an appeal in that, becausewith MLG's (as well as the methods in McCord (1982,lq81)), the semantics seems to float off more onits own.
Semantic items do have a life of theirown, and they can move about in the tree (implic-itly, in some versions of the semantic interpreter)because of raising and reordering.
This is not asneat theoretically, but it seems more appropriatefur capturing actual natural language.Another disadvantage of DCTG's (as with RG~s)is that the analysis trees that are constructedautomatically are derivation trees.The last system to be discussed here, that inPor to  and F i lgue i ras  (198&) ,  does  not  invo lve  a newgrammar fo rmal i sm,  but  a methodo logy  fo r  wr i t ingDCG's.
The authors define a notion of in termediatesemantic representat ion  ( ISR)  including ent i t ies  andpredications, where the pred icat ions  can be viewedas log ica l  forms.
In wr i t ing  DCG ru les ,  one sys-temat ica l l y  inc ludes at the end of  the ru le  a ca l lto a semantic procedure ( spec i f i c  to the g iven ru le )which combines ISR's obta ined in arguments of  thenon-terminals  on the r ight -hand  s ide of  the ru le .Two DCG rules in th i s  s ty le  (g iven by the authors)are as fo l lows :sent(S) --> np(N): vp(V): $ssv(N,V,S).vp(S) --> verb(V,trans): np(N): Ssvo(V,N,S).Here 'ssv' and 'svo' are semantic procedures thatare specific to the 'sent' rule and the 'vp' rule,respectively.
The rules that define 'ssv' and 'svo'can include some general rules, but also a mass ofvery specific rules tied to  specif ic words.
Twospecif ic rules given by the authors for analyzing"All Viennese composers wrote ~ waltz" are as fol-lows.svo(wrote,M:X,wrote(X)) <- is_a(M,music).ssv(P:X,wrote(Y),author_of(Y,X)) <-is_a(P,person).Note that the verb 'wrote' changes from the surfaceform 'wrote', to the intermediate form wrote(X),then to the form author of(Y,X).
\[n most logicgrammar systems (including MOD and MODL), some formof argument fil l ing is done for predicates; infor-mation is added by binding argument variables,rather than changing the whole form of the predi-cation.
The authors claim that it is less efficientto do argument filling, because one can make anearly choice of a word sense which may lead tofailure and backtracking.
An intermediate form likewrote(X) above may only make a partial decisionabout the sense.The value of the "changing" method over the"adding" method would appear to hinge a lot on thequestion of parse-time efficiency, because the"changing" method seems more complicated conceptu-ally.
I t .
seems simpler to have the notion thatthere are word-senses which are predicates with acertain number of arguments, and to deal only withthese, rather than inventing intermediate forms thathelp in discrimination during the parse.
So it ispartly an empirical question which would be decidedafter logic grammars dealing semantical ly withmassive dictionaries are developed..There is modularity in rules written in thestyle of Porto and Filgueiras, because all the se-mantic structure-bui lding is concentrated in thesemantic procedures added (by the grammar writer)at the ends of the rules, in MLG's, in the one-passmode, the same semantic procedure call, to 'semant',is added at the ends of strong rules, automatical lyby the compiler.
The diversity comes in the an-cil iary procedures for ' semant ' ,  especial ly 'mod'.In fact, 'mod' (or 'trans' in McCord, 1981) hassomething in common with the Porto-Fi lgueiras pro-cedures in that it takes two intermediate repres-entations (semantic items) in its first twoarguments and produces a new intermediate repre-sentation in its third argument.
However, the116changes that 'mod' makes all involve themodification-operator components of semantic items,rather than the logical-form components.
It mightbe interesting and worthwhile to look at a combi-nation of the two approaches.Both a strength and a weakness of the Porco-Filgueiras semantic procedures (compared with'mod') is that there are many of them, associatedwith specific syntactic rules.
The strength is thata specific procedure knows that it is looking atthe "results" of a specific rule.
But a weaknessis that generalizations are missed.
For example,modification by a quantified noun phrase (afterslot-filling or the equivalent) is often the same,no matter where it comes from.
The method in MLG'sallows semantic items to move about and then actby one 'mod' rule.
The reshaping procedures arefree to look at specific syntactic information, evenspecific words when necessary, because they workwith augmented semantic items.
Of course, anotherdisadvantage of the diversity of the Porto-Filgueiras procedures is that they must be explic-itly added by the writer of syntax rules, so thatthere is not as much modularity as in MLG's.REFERENCESAbramson, H. (1984) "Definite clause translationgrammars," Proc.
1984 International Symposium onLogic Prograem, ing, pp.
233-240, Atlantic City.Byrd, R. J.
(1983) "Word formation in natural lan-guage processing systems," Proc.
8th InternationalJoint Conference on Artificial \[ntelli~ence, pp.704-706, Karlsruhe.Byrd, R. J.
(1984) "The Ultimate Dictionary Users'Guide," IBM Research Internal Report.Colmerauer, A.
(1978) "Metamorphosis grammars," inL.
Bolt (Ed.
), Natural Language Communication withComputers, Springer-Verlag.Dahl, V. (1977) "Un systeme deductif d'interrogationde banques de donnees en espagnol," Grouped'Intelligence Artificielle, Univ.
d'Aix-Marseille.Dahl, V. (1981) "Translating Spanish into logicthrough logic," American Journal of ComputationalLinguistics, vol.
7, pp.
149-164.Dahl, V, and HcCord, M. C. (1983) "Treating coor-dination in logic grammars," American Journal ofComputational Linguistics , vol.
9, pp.
69-91.Heidorn, G. E. (1972) Natural Language Inputs to  aSimulation Programming System, Naval PostgraduateSchool Technical Report No.
NPS-55HD7210IA.Hirschman, ~.
and Puder, K. (1982) "Restrictiongrammar in Prolog," Proc.
First International LogicProgramming Conference, pp.
85-90, Marseille.Jensen, K. and Heidorn, G. E. (1983) "The fittedparse: 100% parsing capability in a syntacticgrammar of English," IBM Research Report RC 9729.Knuth, D. E. (1968) "Semantics of context-freelanguages," Mathematical Systems Theory, vol.
2,pp.
127-145.Lewis, D. (1975) "Adverbs of quantification," InE.L.
Keenan (Ed.
), Formal Semantics of NaturalLanguage, pp.
3-15, Cambridge University Press.McCord, M. C. (1982) "Using slots and modifiers inlogic grammars for natural language," ArtificialIntelli~ence, vol 18, pp.
327-367.
(Appeared firstas 1980 Technical Report, University of Kentucky.
)McCord, M. C. (1981) "Focalizers, the scop ingproblem, and semantic interpretation rules in logicgrammars," Technical Report, University ofKentucky.
To appear in Logic Programming and itsApplications, D. Warren and M: van Caneghem, Eds.McCord, M. C. (1984) "Semantic interpretation forthe EPISTLE system," Proc.
Second InternationalLogic Programming Conference, pp.
65-76, Uppsala.Miller, L. A., Heidorn, G. E., and Jensen, K.(1981) "Text-critiquing with the EPISTLE system:an author's aid to better syntax," AFIPS ConferenceProceedings, vol.
50, pp.
649-655.Pereira, F. (1981) "Extraposition grammars," Amer-ican Journal of Computational Linguistics, vol.
7,pp.
243-256.Pereira, F. (1983) "Logic for natural languageanalysis," SRI International, Technical Note 275.Pereira, F. and Warren, D. (1980) "Definite clausegrammars for language analysis - a survey of theformalism and a comparison with transition net-works," Artificial Intelligence , vol.
13, pp.231-278.Pereira, F. and Warren, D. (1982) "An efficienteasily adaptable system for interpreting naturallanguage queries," American Journal of Computa-tional Linguistics, vol.
8, pp.
110-119.Porto, A. and Filgueiras, M. (1984) "Natural lan-guage semantics: A logic programming approach,"Proc.
198A International Symposium on Logid Pro-gramming, pp.
228-232, Atlantic City.Sager, N. (1981) Natural Language InformationProcessing: A Computer Grammar of English and ItsApplications, Addison-Wesley.Woods, W. A.
(1970) "Transition network grammarsfor natural language analysis," C. ACM, vol.
13,pp.
591-606.117
