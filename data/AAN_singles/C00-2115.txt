Extracting semantic lusters from the alignment of definitionsGerardo SIERRAInstitute de Ingenierfa, UNAMApdo.
Postal 70-472Mdxico 04510, D.F.gsm @pumas.iingen.unanunxJohn McNAUGHTDepartment of Language Engineering, UMISTPO Box 88Manchester M60 IQD, UKJohn.McNaught @unlist.ac.ukAbstractThrough tile alignment of definitions fronltwo or more dilTerent sources, it ispossible to retrieve pairs of words that canbe used indistinguishably in the samesentence without changing tile meaning ofthe concept.
As lexicographic workexploits common defining schemes, suchas genus and dilTerentia, a concept issimihu'ly defined by different dictionaries.The dilTerence in words used between twolexicographic sources lets us extend lhelexical knowledge base, so that clusteringis available through merging two or moredictionaries into a single database andthen using an approlwiate alignmenttechlaique.
Since aligmnent starts from thcsame entry of two dictionaries, clusteringis l~lster than any other technique.Tile algorithm introduced here is analogy-based, and starts from calculating theLevenshtein distance, which is a variationo1' the edit distance, and allows us to alignthe definitions.
As a measure of similarity,the concept el' longest collocation coupleis introduced, which is the basis ofclustering similar words.
The processiterates, replacing similar pairs of wordsin tile definitions until no new clusters arefound.IntroductionClustering methods to identify semanticallysimilar words are usually divided in relation-based and distribution-based approaches\[Hirawaka, Xu and Haase 1996\].
Relation-basedclustering methods rely on the relations in asemantic network or ontology to judge thesimilarity between two concepts, either bymeasuring the shortest length that connects twoconcepts in the hierarchical net \[Agirrc andRigau 199611, oi" by comparing tile informationcontent shared by the members unde," tile samecluster \[Morris and Hirst 1991, Resnik 1997\].ltowever, even although these ontologiesdescribe a huge number of members for acluster, few words of a category may beinterchangeable in the same context and thenused as members of tile same cluster.
Thismeans that not all words in a category arcnecessary.Conversely, distribution-based clusteringmethods depend on pure statistical analysis ofthe lexical occurrences ill running texts.
A relierdrawback is that distribution-based methodsrequire us to process a large amount of data inorder to get more reliable results.
Moreover, tileuse el hu'ge corpora is not always practical, dueto economic, time or capabilities factors.
Gao11199711 states that tile problem for statisticalalignment algorilhms, such as those based on tilefacts described by Gale and Church \[1991\], isthe low frequency of words that occur in parallelcorpora.
The consequences for lacking hu'gecorpora include results based on low-frequencywords, which are quite unrepresentative forclustering.From a methodological point of view, there is, inaddition to the above two approaches, a littleknown approach called the analogy-basedapproach.
This employs an inferential processand is used ill computatkmal linguistics andartificial intelligence as an alternative to currentrule-based linguistic models.1 Analogy-based clusteringJones \[11996\] suggests corpus alignment as afeasible analogy-based approach, ill order toalign two sentences in tile same language,Waterman \[1996\] uses a technique formeasuring tile similarity between lexical strings,named edit distance.
This matches tile words of795two sentences in linear order and determinestheir correspondence.
For example, given thefollowiug two definitions for alkalimeter:?
An apparatus for determining theconcentration o1' alkalis in solution \[CED\]?
An instrument for ascertaining the amountof alkali in a solution \[OED2\]Alignment may identil'y which words in thesedefinitions are equivalents of each other.
Aquick observation of the sentences lets usidentify three pairs of words: (apparatus,instrument), (determining, ascertaining) and(concentration, amount).The appeal of using definitions as corpora foralignment is l'ounded on two reasons.
Firstly,dictionaries contain all necessary information asa knowledge base for extracting keywords\[Boguraev and Pustejovsky 1996\].
Secondly, itis much easier to find the sentences for aligning,since definitions are distinguished by entryheadword.Taking into account Waterman's tudies, wepropose an analogy-based method to identifyautomatically semantic lusters.
The differencein words used between two or morelexicographic definitions enables us to inferparadigms by merging the dictionary definitionsinto a single database and then using our ownalignment technique.2 Clustering algorithmTile overall structure of the clustering algorithn\]is shown in figure l, and its description is givenbelow.2.1 Processing definitionsOur algorithms are used in an overall systemcalled "onomasiological search system" (OSS),whose aim is to allow the user to find terms bygiving a description o1' a concept.
Lexicographicand terminological definitions constitute themain lexical resources.
Our algorithms clusterwords that are used in the same context, thusoperate on pairs of definitions for a same entryword, drawn fi'om two different dictionaries.
Ifdictionary 1 does not have an entry word thatexists in dictionary J, then this entry word isomitted from consideration.
In order to balancethe number of strings when an entry word in thedictionary 1 has two or more senses, the entryword in dictionary J is repeated as many timesas necessary to equal the number of senses ofdictionary I.
We thus derive two files I and Jcontaining an equal number of strings S~ and S 2,respectively.
Each string consists of an entryterm followed by its definition, the definitiongiving only one sense of the entry term.
For eachstring S 1 there is a string S 2.Our experiments focus on 314 terms formeasuring instruments extracted with theirdefinitions from CED \[199411 and OED2 \[1994\],resulting in 387 strings from each dictionary.match S t and S 2/ S  1 and S 2/ definitionstprocessingH///>ste ln l l lercalculate Levenshteindistance H align S~ and S 2I"'-I J replace strings ~ identify bindings<c lusters  ),~__~ cluster bindingsFigure 1 Clustering algorithmstoplist \[,LI find Ice @0796The strings consist ()1' the entry term and thedefinition, so that etymology, part of speech,inl'lected t'orms ol' the cntry term, examples andother inl'ormation were deleted.
Subject-fieldlabels, such as 'astronomy' and 'meteorology',were preserved, either in full or slightlyabbreviated, as they are helpful to resolve whichsense o1' a word to choose, and usually constitutea l'undamental property of the concept.It should be noted that none of the 387 stringssuffered any additional transformation, apartl'rom a few cases in order to complete adel'inition when it had been broken in two pm'tsby the dictionary editor, such as when a coremeaning appears just once at the beginning ofseveral subsequent senses.
Althongh someabbreviations ('U.S.A.
'), initials of propernames ('C.T.R.
Wilson') and possessives ( :un srays') will come out as two or more words al'terdeleting punctuation marks and therefore canalter the efficiency el' the algorithm, they werepreserved to observe their effect.2.2 Aligning definitionsIn order to compare two strings of woMs, we usethe Levenshtein distance \[Levenshtein 196611, asimilar method to the edit distance.
This methodmeasures the edit transl'ormations that changeone string into other.
The Levenshtein distancearrangcs the strings in a matrix, with the wordsel' Sj heading the columns and those of S 2heading the rows.
A null word is inserted at thebeginning of each string S~ and S 2, in positioni=0,.j=0.
The matrix is filled with the costs ofinsertion, deletion and substitution using thel'ollowing formtfla ?D(ai,  b i_, ) + Di,,.
,, (bi)D(a i ,b j )=  rain D(ai_j,bi)+Di,,.,.
(ai)D(aH,  b /< ) + D ,I, (ai, b j)Where the cost of insertion.
D~,,.,(), is 1. and thecost of substitution.
D,,i,(), is 0 or 1, according towhether a~ and bj differ or not.Our experimental results have shown that theapplication of the Levenshtein distance usingstem forms gives better matches than nsing fullforms.
Therefore, we shall fill the matrix withthe cost for the stem l'orms, although the stringspreserve the fnll forms both l'or the followingsteps and in the output table.
We used thestmnming algorithm or' Porter \[1980\], whichremoves endings l'ronl words.Building on the Levenshtein distance, Wagnerand Fisher \[1974\] propose a dynamict~rogramming method to align the elements oftwo strings.
Their procedure to return theordered pairs of the alignment starts with the lastcell of the matrix with cost\[n\]\[m\] and worksback until either i or j equals 0, according towhich o1' its neighbours a cell was derived l'rom.I1' it is derived either from the previoushorizontal or vertical cell (\[i-l\]\[j\] or \[i\]lj-l\]respectively) then the difference in cost is.just 1,otherwise it is derived l'rom the diagonal.2.3 Extracting tripletsThe alignment gives us a list of triplets formedby ~.ll, J,l~, cost\[i\]\[j\]), in decreasing orderaccording to cost\[i\]\[jl, where./.)'
I, and ./\]~ arc fullforms from the strings S~ and S e, respectively.There are three possible pairings of words:"Equal couple" is defined as the pair (1-\[i, .ffj) offull forms such that the corresponding stemforms are equal (,s.'/' I = 4)""Matched couple" is a pair (/.
)~i, .Oj) such that .sf~# .ff~.
This couple represents a potential pair ot'similar words.
"Null couple" is a pair (.g, .g) such that ,s:/I ()r 4is missing.With respect to the Levcnshtein distance, theequal couple means these words do not need anychange to make both equal, while for thematched couple we shall replace one word withthe other progressively, and for the null couplewe must either insert one word into the givenstring or delete it from the given string.The purpose of clustering is to match differentpairs of words (matched couples), thus neitherpairs of equal words (equal couples) nor pairswith a null word (null couples) are relevant.2.4 Measuring similarityAs a measure of the similarity between amatched couple, we quantify the surroundingequal couples above and below it.
This conceptis similar to the "longest common subsequence"of two strings suggested by Wagner and Fisher\[1974\], which is del'ined as the commonsubsequence of two strings having maximallength, although in our case both strings differby the single matched couple.
By analogy, weuse longest collocation couple, henceforth797abbreviated lcc, since we refer to couples insteadof a single string.
Besides, the word"collocation" is more representative for a pair o1'words and their neighbourhood, being the coreof two longest common subsequences.
Wedefine longest collocation couple as the maximalsequence of pairs of words formed by equalcouples surrounding a matched couple.Given the alignment of the strings S~ and S 2consisting of a list of triplets formed by (ffi., ff ,cost\[ill/\]), in decreasing order according tocost\[i\]\[j\], where.ff I, and fl~ are, respectively, fullfomas l'rom S~ and $2, the lcc is the longestconsecutive sequence of triplets (~i., f~,cost\[i\]\[j\]) formed by one matched couple, suchthat it meets 3 conditions:?
The cost dilTerence between the first tripletand the last triplet is 1.?
There is no null couple.?
The matched couple is neither the first northe last triplet.By these conditions, only the matched couplebecomes the core el' a Icc: we constrain amatched couple 1o be between two or moreequal couples, and eliminate the possibility thatthe matched couple appears at the beginning orend o1' a phrase.As a result, we get a new triplet Off, .\[f~, Icco),where (If, J\[~) is the matched couple and lcc,a isthe length of the longest collocation couple.
Asan example, for the definitions of "dynameter"in table 1, there is only one matched couple,"determining-measuring", whose lcc is 9 (theextent o1' the Icc is indicated by arrows).telescopesofpowermagnifyingthedeterminingforinslrulnentandynameter,/,/;telescopeaofpowermagnifyingthemeasuringforinstrumentAndynametercost\[il\[jl2211I110000Table 1 Triplets for "dynameter"<-?U>II?o?J<--Ranking all triplets found by lcc in decreasingorder, we observe that the greater the value o1'lcc, the greater the similarity between the wordsof the matched couple.2.5 Removing flmetion wordsSo far, function words and other noise wordswill also be clustered by our algorithms, ingeneral, such words interfere in theidentification of clusters and can give morewrong than good results.
We use a stoplist toautomatically identify any pair of words where anon-relevant word appears and exclude it, on thegrounds that they are not very useful words forclustering.
Thus, when the program comesacross a matched pair of different words in acontext and il' that matched pair contains a wordfrom the stoplist, then the pair is rejected.Essentially, this is the same thing as using atagger and looking at the tags as well as thewords, since one would not want to choose anoun pairing with a determiner or a relative.By inspection, we observe that, after stoplistdiscrimination, the best potential clusters arefound at higher values ot' Icc.
Our experimentalresults show us that a length of lcc equal to 5 is areliable threshold.
Although there are also goodmatches for values equal to 4 and 3, the majorityof these are duplicates of higher values.2.6 ClusteringWe introduce the terln binding to represent acandidate cluster, i.e.
two words that may beused in the same context without changing themeaning o1' a definition.
A binding is a matchedcouple (J.l~, .\[/'9 formed by the full forms .\[f~ andft;, after stoplist discrimination, drawn t'rom thestrings S, and S~, respectively, in such a way thatthe stem forms are equivalent, in a determinedcontext, according to a determined threshold'.The threshold associated with a binding is thelength of the lcc, and we consider only bindingsof matched couples where lcc >_ 5.Each binding can be considered as an initialcluster.
Clusters represent sets o1' words that areused with the same meaning in particularcontexts.
In a consecutive sequence of bindings,it may happen that a stem form occurs in two ormore dilTerent bindings.
In this case, one cancluster all bindings with a common stem formaccording to the transitive property.in order to cluster bindings, we use an algorithmconsisting o1' three loops.
First, it assigns acluster number to each binding, so thosebindings with a common word have the samecluster number.
Secondly, it clusters bindingswith the same cluster number, but removes798duplicate stem forms in tile same cluster.Thirdly, it checks if it is possible to inerge newclusters with those of previous cycles.
Thisprocess will typically result in a set ofoverlapping clusters, reflecting the natm'al statewhere concepts may belong to more than oneconceptual class.2.7 CyclingAs bindings represent pairs of words such thatthe stem forms can be substituted in a particularcontext without changing the meaning, sJi = aJ~we can replace any of the full formsf?
with thefull l'orms ffj according to each binding, so thatthe corresponding definition preserves the samemeaning.
After substituting bindings, weobserve that several pairs of words will nowtypically present a high lcc score, even thosepairs of words which initially did not yieldmatches with any word.
It is then advantageousto replace thus the bindings in the definitionsalld to repeat the entire process until no newclusters are found.
The first cycle runs from thereading o1' definitkms up to merging of clusters.All subsequent cycles will start by replacingretained bindings in the definitions, thus eachsubsequent cycle works with new data.3 Experimental resultsThe current clustering algorithm was developedby analysing definitions on the following basis:?
Language dictionaries.
The use of languagedictionaries has been preferred because thereare enough to extract data from.
As they arein machine-readable form, it is possible tocopy definitions, avoiding likely mistakeswhile typewriting.?
Corpus on 314 "measuring instruments".This domain has the advantage that it is easyto search for the terms that correspond to it,as they usually end in "-meter", "-scope" or"-graph".
As a conscqueuce o1' applying theclustering program to the 387 strings, it isevident that the maiority of clusters wererelated to "measure" and "instrument".?
Alignment of two strings.
We have shownthat two sources of data (pairs of del'inition)are sufficient for clustering to yield goodresults.?
No manipulation el'data.
After ktentificationof the term and the definitions, these weretruncated to 200 characters and punctuationmarks were removed.
No words indefinitions were replaced or moved, to "tidyup" the data, before being submitted to themain process.?
Stemming algorithm.
The stemmeralgorithm presents both overstemming andunderstemming, but nevertheless theclustering program yiekts good results.?
Stoplist discrimination.
The stoplist hasbeen used as a tagger, i.e.
as a filter to avoidmatching words with dil'ferent parts ot'speech.?
Bindings for Ice _> 5.
The best clusters havebeen observed for bindings with lcc> 5, andthe results presented m'e good.Table 2 presents ome cluster results after twocycles of the clustering procedure starting fromthe Levcnshtein distance.
In addition to theseclusters, 14 other clusters of two or threeelements were obtained.I.
apparalus inslrumcnt telescope2.
analyse ascerlaining determining estimatinglocation measuring recording lakins testing3.
amotmt concenlration intensity percentageproportion rate salinity strengthTable 2 Cluster results for "measuringillstFunlents"The procedure then stops, as no more matchedwords with lcc _> 5 have been found for our data.The following sections analyse variations ofthese considerations.3.1 Using multiple resourcesGeneral language dictionaries present theadvantage of using well-establishedlexicographic riteria to normalise definitions.These criteria, as for example the use ofanalytical definitious by genus and differentia,have been nowadays implemented byterminological or specialiscd ictionaries, withthe addition of a richer vocabulary and theidentification of properties that are not alwaysconsidered relevant in other resources.Unfortunately, these are more oriented to aspecific domain, so that it is sometimesnecessary to search in two or more resources tocompile the data.We used many online lexical resources, some ofthem available on the lnternct.
This allowed usto easily use different databases to extract799
