Proceedings of the Linguistic Annotation Workshop, pages 41?44,Prague, June 2007. c?2007 Association for Computational LinguisticsDiscontinuity Revisited: An Improved Conversion toContext-Free RepresentationsAdriane BoydDepartment of LinguisticsThe Ohio State University1712 Neil Ave.Columbus, OH 43210adriane@ling.osu.eduAbstractThis paper introduces a new, reversiblemethod for converting syntactic structureswith discontinuous constituents into tradi-tional syntax trees.
The method is appliedto the Tiger Corpus of German and resultsfor PCFG parsing requiring such context-free trees are provided.
A labeled depen-dency evaluation shows that the new conver-sion method leads to better results by pre-serving local relationships and introducingfewer inconsistencies into the training data.1 IntroductionUnlike traditional treebanks, the Negra and TigerCorpora (Brants et al, 2002) allow crossingbranches in the syntactic annotation to handle cer-tain features of German.
In order to use the Ne-gra or Tiger Corpus data to train a PCFG parser, itis necessary to convert the syntactic annotation intocontext-free syntax trees.
In previous work (see sec-tion 3.1), a non-reversible method has been used thatraises nodes in the tree to eliminate discontinuities.This method effectively introduces inconsistenciesinto the data and disrupts the grammatical depen-dency annotation in the trees.
This paper presentsa new, reversible method for converting Negra andTiger syntactic structures into context-free syntaxtrees appropriate for training a PCFG parser.
A re-versible conversion allows the original grammati-cal dependency relations to be reconstructed fromthe PCFG parser output.
This paper focuses on thenewer, larger Tiger Corpus, but methods and resultsare very similar for the Negra Corpus.2 Tiger CorpusThe Tiger Corpus was a joint project between Saar-land University, the University of Stuttgart, and Uni-versity of Potsdam.
The Tiger Corpus Version 2 con-tains 50,474 sentences of newspaper text.
The Tigerannotation combines features from phrase structuregrammar and dependency grammar using a tree-likesyntactic structure with grammatical functions la-beled on the edges of the tree (Brants et al, 2002).Flat sentence structures are used in many placesto avoid attachment ambiguities and non-branchingphrases are not allowed.
The annotation schemeemphasizes the use of the tree structure to encodeall grammatical relations in local trees regardless ofwhether a grammatical dependency is local within inthe sentence.
This leads to the use of discontinuousconstituents to handle flexible word order, extraposi-tion, partial constituent fronting, and other phenom-ena.
An example of a Tiger tree with discontinuousconstituents (both VPs) is shown in Figure 1.3 Conversion to Context-Free SyntaxTreesFor research involving PCFG parsing models trainedon Tiger Corpus data, it is necessary to convert thesyntax graphs with crossing branches into traditionalsyntax trees in order to extract context-free grammarrules from the data.
Approximately 30% of sen-tences in Tiger contain at least one discontinuousconstituent.3.1 Existing Tiger Corpus ConversionIn previous research, crossing branches have beenresolved by raising non-head nodes out of discon-41MitAPPRdemARTBauNNsollVMFIN1997CARDbegonnenVVPPwerdenVAINFAC NK NKPPOP MO HDVPOC HDVPOCHDS?Construction should start in 1997.?(lit.
with the construction should 1997 begun be)Figure 1: Discontinuous Tiger treetinuous constituents until no more branches cross.The converted sentence from Figure 1 is shown inFigure 2.
In any sentence, multiple nodes couldeach be raised one or more times, so it is difficultto automatically reconstruct the original sentence.Previous work on PCFG parsing using Negra orTiger has either used the provided Penn Treebank-style versions of the corpora included with Ne-gra and Tiger Version 1 (Dubey and Keller, 2003;Dubey, 2004) or used a program provided with theNegra/Tiger Annotate software (Plaehn and Brants,2000) which performs the raising algorithm (Ku?bler,2005; Ku?bler et al, 2006).
This conversion will bereferred to as the ?raising method?.3.2 A New Approach to EliminatingDiscontinuitiesThe raising method has the advantages of preservingthe number of nodes in the tree, but it is not easilyreversible and disrupts local trees.
Raising non-headnodes is not an ideal way of eliminating disconti-nuities because it does not preserve the relationshipbetween a head and a dependent that is representedin a local tree in the Tiger annotation.
After raisingone or more nodes in 30% of the sentences in thecorpus, local trees are no longer consistent acrossthe treebank.
Some VPs may contain all their ob-jects while others do not.
For example, in Figure 2the PP object Mit dem Bau is no longer in the localtree with its head begonnen.
The PCFG has lessenedchance of capturing generalizations from the result-ing inconsistent training data.Preferable to the raising method is a conversionthat is reversible and that preserves local trees asMitAPPRdemARTBauNNsollVMFIN1997CARDbegonnenVVPPwerdenVAINFAC NK NKPPOP HD OCSMO HDVPOC HDVPFigure 2: Result of conversion by raisingMitAPPRdemARTBauNNsollVMFIN1997CARDbegonnenVVPPwerdenVAINFOC HD OCSOCVP*OPVP*AC NK NKPPOC HDVP*MO HDVP*Figure 3: Result of conversion by splittingmuch as possible.
The new approach to the con-version involves splitting discontinuous nodes intosmaller ?partial nodes?.
Each subset of the originalchildren with a continuous terminal yield becomes apartial node.
In this way, it is possible to removecrossing branches while preserving the parent re-lationships from the original tree.
Because partialnodes retain their original parents, the reverse con-version is greatly simplified.In order to make the conversion easily reversible,the partial nodes need to be marked in some wayso that they can be identified in the reverse conver-sion.
A simple method is to use a single mark (*)on all partial nodes.1 For example, a discontinu-ous VP with the children NN-OA (noun acc.
obj.
)and VVINF-HD (infinitive) would be converted intoa VP* with an NN-OA child and a VP* with aVVINF-HD child.
The method of creating partialnodes with a single mark will be called the ?splittingmethod?.
It is completely reversible unless there aretwo discontinuous sisters with the same label.
Whileit is not unusual for a Tiger tree to have multiple dis-1This approach was inspired by Joakim Nivre?s paperPseudo-Projective Dependency Parsing (Nivre, 2005), in whichnon-projective dependency structures are converted to easier-to-parse projective dependency structures in a way that limits thenumber of new labels introduced, but is mostly reconstructible.42continuous nodes with same label (as in Figure 1),two nodes with the same label are never sisters so theconversion is reversible for all sentences.
Each treeis converted with the following algorithm, which is apostorder traversal that starts at the root node of thetree.
The postorder traversal guarantees that everychild of a node is continuous before the node itselfis evaluated, so splitting the node under considera-tion into partial nodes will resolve the discontinuity.SPLIT-DISC-NODES(Node)for each Child of NodeSPLIT-DISC-NODES(Child)if Node?s terminal yield is discontinuousChildren := immediate children of NodeContSets := divide Children into subsetswith continuous terminal yieldsfor each ChildSubset in ContSetsPNode := new nodePNode?s label := Node?s label with mark (*)PNode?s parent := Node?s parentfor each Child in ChildSubsetChild?s parent := PNoderemove Node from treeThe splitting conversion of the sentence from Fig-ure 1 can be seen in Figure 3.
To convert the splitversion back to the original version, the tree is ex-amined top-down, rejoining any marked sister nodeswith the same label.4 ResultsAll parsing was performed using the unlexicalizedparsing model from the left corner parser LoParSchmid (2000).
The input data was labeled with per-fect tags from the corpus to prevent errors in taggingfrom affecting the parsing results.4.1 Data PreparationFor the following experiments, the Tiger CorpusVersion 2 was divided into training, development,and testing sections.
Following the data split fromDubey (2004), 90% of the corpus was used as train-ing data, 5% as development data, and 5% as testdata.
In preprocessing, all punctuation was removedbecause it is not attached within the sentence.
6.5%of sentences are excluded because they contain noannotation beyond the word level or because theycontain multiple root nodes.
After preprocessing,there are 42,612 sentences in the training set.
Forevaluation, only sentences with 40 words or fewerare used, leaving 2,312 test sentences.
The raisedversion is created using the Annotate software andthe split version is created using the method de-scribed in section 3.2.
For the split version, partialnodes are rejoined before evaluation.In the Penn Treebank-style versions of the corpusappropriate for training a PCFG parser, each edge la-bel has been joined with the phrase or POS label onthe phrase or word immediately below it.
Because ofthis, the edge labels for single-word arguments (e.g.,pronoun subjects) are attached to the POS tag ofthe word, which provides the parser with the perfectgrammatical function label when perfect lexical tagsare provided.
This amounts to providing the perfectgrammatical function labels for approximately one-third of arguments in Tiger, so to avoid this prob-lem, non-branching phrase nodes are introduced forsingle-word arguments.
Phrase nodes are introducedabove all single-word subjects, accusative objects,dative objects, and genitive objects.
The category ofthe inserted phrase depends on the POS tag on theword (NP, VP, or AP as appropriate).4.2 Experiment 1: Reversibility of SplittingConversionAll sentences in the test set were converted into syn-tax trees by splitting discontinuous nodes accordingto the algorithm in section 3.2.
All 2,312 sentencesin the test set can be converted back to their originalversions with no errors.
The most frequently splitnodes are VP (?55%) and NP (?20%).4.3 Experiment 2: Labeled DependencyEvaluationA labeled dependency evaluation is chosen insteadof a typical PARSEVAL evaluation for two reasons:1) PARSEVAL is unable to evaluate trees with dis-continuous constituents; 2) a bracketing evaluationexamines all types of brackets in the sentence andmay not reflect how accurately significant grammat-ical dependencies have been identified.It is useful to look at an evaluation on gram-matical functions that are important for determiningthe functor-argument structure of the sentence.
Inthis evaluation, subjects, accusative objects, prepo-43Raised SplitGF P R F P R FSubj 74.8 71.6 73.2 74.7 73.5 74.1AccObj 46.3 48.9 47.4 49.2 53.7 51.4PPObj 20.4 10.7 15.6 31.9 15.6 23.8DatObj 20.1 11.5 15.8 25.5 14.3 19.9Table 1: Labeled Dependency Evaluationsitional objects, and dative objects are considered aspart of labeled dependency triples consisting of thelexical head verb, the grammatical function label,and the dependent phrase bearing the grammaticalfunction label.
The internal structure of the depen-dent phrase is not considered.In Tiger annotation, the head of an argument isthe sister marked with the grammatical function la-bel HD.
HD labels are found with an f-score of 99%by the parser, so this evaluation mainly reflects howwell the arguments in the dependency triple are iden-tified.
This evaluation uses lexical heads, so if thesister with the label HD is a phrase, then a recursivesearch for heads within that phrase finds the lexicalhead.
For 5.7% of arguments in the gold standard, itis not possible to find a lexical head.
Further meth-ods could be applied to find the remaining headsheuristically, but the additional parameters this in-troduces for the evaluation are avoided by ignoringthese cases.The results for a labeled dependency evaluationon important grammatical function labels are shownin Table 4.3.
Grammatical functions are listed in or-der of decreasing frequency.
The results for subjectsremain similar between the raised and split version,as expected, and the results for all other types of ar-guments improve 4-8% for the split version.Subjects are rarely affected by the raising methodbecause S nodes are rarely discontinuous, so it is notsurprising that the results for subjects are similar forboth methods.
However, VPs are by far the mostfrequently discontinuous nodes, and since the rais-ing method can move an object away from its head,the difference between the two conversion methodsis most evident in the object relations.
Data sparsityplays a role in the lower scores for the objects, sincethere are approximately twice as many subjects asaccusative objects and twelve times as many sub-jects as dative objects.5 Future WorkFurther research will extend the dependency evalu-ation presented in this paper to include more or allof the grammatical functions.
There is significantwork on a dependency conversion for Negra by thePartial Parsing Project (Daum et al, 2004) that couldbe adapted for this purpose.6 ConclusionBy using an improved conversion method to re-move crossing branches from the Negra/Tiger cor-pora, it is possible to generate trees without cross-ing branches that can be converted back to the orig-inal format with no errors.
This is a significant im-provement over the previously used conversion byraising, which was not reversible and had the ef-fect of introducing inconsistencies into the corpus.The new splitting conversion method shows a 4-8%improvement in a labeled dependency evaluation onaccusative, prepositional, and dative objects.ReferencesSabine Brants, Stefanie Dipper, Silvia Hansen, WolfgangLezius and George Smith, 2002.
The TIGER Tree-bank.
In Proceedings of TLT 2002.Michael Daum, Kilian Foth and Wolfgang Menzel, 2004.Automatic transformation of phrase treebanks to de-pendency trees.
In Proceedings of LREC 2004.Amit Dubey, 2004.
Statistical Parsing for German: Mod-eling Syntactic Properties and Annotation Differences.Ph.D.
thesis, Universita?t des Saarlandes.Amit Dubey and Frank Keller, 2003.
Probabilistic Pars-ing Using Sister-Head Dependencies.
In Proceedingsof ACL 2006.Sandra Ku?bler, 2005.
How do treebank annotationschemes influence parsing results?
Or how not to com-pare apples and oranges.
In Proceedings of RANLP2005.Sandra Ku?bler, Erhard W. Hinrichs and Wolfgang Maier,2006.
Is it really that difficult to parse German?
InProceedings of EMNLP 2006.Joakim Nivre, 2005.
Pseudo-Projective DependencyParsing.
In Proceedings of ACL 2005.Oliver Plaehn and Thorsten Brants, 2000.
Annotate ?
AnEfficient Interactive Annotation Tool.
In Proceedingsof ANLP 2000.Helmut Schmid, 2000.
LoPar: Design and Implementa-tion.
Technical report, Universita?t Stuttgart.44
