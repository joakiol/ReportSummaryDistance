Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task, pages 74?82,Baltimore, Maryland, 26-27 July 2014.c?2014 Association for Computational LinguisticsGrammatical Error Detection and Correctionusing a Single Maximum Entropy Model?Peilu Wang, Zhongye Jia and Hai Zhao?Key Laboratory of Shanghai Education Commission forIntelligent Interaction and Cognitive Engineering,Center for Brain-Like Computing and Machine IntelligenceDepartment of Computer Science and Engineering, Shanghai Jiao Tong University800 Dongchuan Road, Shanghai 200240, China{plwang1990,jia.zhongye}@gmail.com,zhaohai@cs.sjtu.edu.cnAbstractThis paper describes the system of Shang-hai Jiao Tong Unvierity team in theCoNLL-2014 shared task.
Error correc-tion operations are encoded as a group ofpredefined labels and therefore the taskis formulized as a multi-label classifica-tion task.
For training, labels are obtainedthrough a strict rule-based approach.
Fordecoding, errors are detected and correct-ed according to the classification results.A single maximum entropy model is usedfor the classification implementation in-corporated with an improved feature selec-tion algorithm.
Our system achieved pre-cision of 29.83, recall of 5.16 and F 0.5of 15.24 in the official evaluation.1 IntroductionThe task of CoNLL-2014 is grammatical error cor-rection which consists of detecting and correctingthe grammatical errors in English essays writtenby non-native speakers (Ng et al., 2014).
The re-search of grammatical error correction can poten-tially help millions of people in the world who arelearning English as foreign language.
Althoughthere have been many works on grammatical errorcorrection, the current approaches mainly focus onvery limited error types and the result is far fromsatisfactory.The CoNLL-2014 shared task, compared withthe previous Help Our Own (HOO) tasks (Dale etal., 2012) considering only determiner and prepo-sition errors and the CoNLL-2013 shared task fo-?This work was partially supported by the National Natu-ral Science Foundation of China (Grant No.60903119, GrantNo.61170114, and Grant No.61272248), the National Ba-sic Research Program of China (Grant No.2013CB329401),the Science and Technology Commission of Shanghai Mu-nicipality (Grant No.13511500200), and the European UnionSeventh Framework Program (Grant No.247619).
?Corresponding authorcusing on five major types of errors, requires tocorrect all 28 types of errors (Ng et al., 2014).One traditional strategy is designing a systemcombined of a set of sub-models, where each sub-model is specialized for a specific subtask, for ex-ample, correcting one type of errors.
This strat-egy is computationally efficient and can adopt d-ifferent favorable features for each subtask.
Topranked systems in CoNLL-2013 (Rozovskaya etal., 2013; Kao et al., 2013; Xing et al., 2013;Yoshimoto et al., 2013; Xiang et al., 2013) arebased on this strategy.
However, the division ofthe model relies on prior-knowledges and the de-signing of different features for each sub-modelrequires a large amount of manual works.
Thisshortage is especially notable in CoNLL-2014shared task, since the number of error types ismuch larger and the composition of errors is morecomplicated than before.In contrast, we follow the work in (Jia et al.,2013a; Zhao et al., 2009a), integrating everythinginto one model.
This integrated system holds amerit that a one-way feature selection benefits thewhole system and no additional process is neededto deal with the conflict or error propagation of ev-ery sub-models.
Here is a glance of this method: Aset of more detailed error types are generated auto-matically from the original 28 types of errors.
Thedetailed error type can be regarded as the label ofa word, thus the task of grammatical error detec-tion is transformed to a multi-label classificationtask using maximum entropy model (Berger et al.,1996; Zhao et al., 2013).
A feature selection ap-proach is introduced to get effective features fromlarge amounts of feature candidates.
Once errorsare detected through word label classification, arule-based method is used to make corrections ac-cording to their labels.The rest of the paper is organized as follows.Section 2 describes the system architecture.
Sec-tion 3 introduces the feature selection approach74and the features we used.
Experiments and result-s are presented in section 5, followed by conclu-sion.2 System ArchitectureIn our approach, the grammatical error detectionis regarded as a multi-label classification task.
Atfirst, each token in training corpus is assigned a la-bel according to the golden annotation.
The con-struction of labels is rule based using an extend-ed version of Levenshtein edit distance algorith-m which will be discussed in the following sub-section.
Each label maps an edit operation to dothe correction, thus the generated labels are muchmore detailed than the originial 28 error types.Then, a maximum entropy (ME) model is adoptedas the classifier.
With the labeled data, the processof grammatical error correction is just applying theedit operation mapped by each label, which is ba-sically the reverse of the labeling phase.2.1 Data LabelingIn CoNLL-2014 shared task, there are 28 errortypes but they can not be used directly as class la-bels, since these types are too general that they canhardly be corrected by applying one rule-basededit.
For example, the correction of Vform (ver-b form) error type includes all verb form inflec-tions such as converting a verb to its infinitive for-m, gerund form, past form and past participle andso on.
Previous works (Dahlmeier et al., 2012;Rozovskaya et al., 2012; Kochmar et al., 2012)manually decompose each error types to more de-tailed subtypes.
For example, in (Dahlmeier et al.,2012), the determinater errors are decomposed in-to:?
replacement determiner (RD): { a ?
the }?
missing determiner (MD): { ?
?
a }?
unwanted determiner (UD): { a ?
?
}For a task with a few error types such as merelydeterminative and preposition error in HOO 2012,manually decomposition may be sufficient.
How-ever, for CoNLL-2014, all 28 error types are re-quired to be corrected and some of these typessuch as Rloc- (Local redundancy) and Um (Un-clear meaning) are quite complex that the manu-al decomposition is time consuming and requireslots of grammatical knowledges.
Therefore, an au-tomatica decomposition method is proposed.
It isextended from the Levenshtein edit distance algo-rithm and can divide error types into more detailedsubtypes that each subtype can be corrected by ap-plying one simple rule.
How to calculate the ex-tended Levenshtein edit distance is described inAlgorithm 1.Algorithm 1 Extended Levenshtein Edit DistanceINPUT: tokssrc, toksdstOUTPUT: E,Plsrc, ldst?
len(tokssrc), len(toksdst)D[0 .
.
.
lsrc][0 .
.
.
ldst]?
0B[0 .
.
.
lsrc][0 .
.
.
ldst]?
(0, 0)E[0 .
.
.
lsrc][0 .
.
.
ldst]?
?for i?
1 .
.
.
lsrcdoD[i][0]?
iB[i][0]?
(i-1, 0)E[i][0]?
Dend forfor j ?
1 .
.
.
ldstdoD[0][j]?
jB[0][j]?
(0, j-1)E[0][j]?
Aend forfor i?
1 .
.
.
lsrc; dofor j ?
1 .
.
.
ldstdoif tokssrc[i-1] = toksdst[j-1] thenD[i][j]?
D[i-1][j-1]B[i][j]?
(i-1, j-1)E[i][j]?
Uelsem = min(D[i-1][j-1], D[i-1][j], D[i][j-1])if m = D[i-1][j-1] thenD[i][j]?
D[i-1][j-1] + 1B[i][j]?
(i-1, j-1)if lemma(tokssrc[i-1])= lemma(toksdst[j-1]) thenE[i][j]?
SelseE[i][j]?
Iend ifelse if m = D[i-1][j] thenD[i][j]?
D[i-1][j] + 1B[i][j]?
(i-1, j)E[i][j]?
Delse if m = D[i][j-1] thenD[i][j]?
D[i][j-1] + 1B[i][j]?
(i, j-1)E[i][j]?
Aend ifend ifend forend fori, j ?
lsrc, ldstwhile i > 0 ?
j > 0 doinsert E[i][j] into head of Einsert toksdst[j ?
1] into head of P(i, j)?
B[i][j]end whilereturn (E,P)In this algorithm, tokssrcrepresents the tokensthat are annotated with one grammatical error andtoksdstrepresents the corrected tokens of tokssrc.At first, three two dimensional matrixes D, B and75E are initialized.
For all i and j, D[i][j] holdsthe Levenshtein distance between the first i tokensof tokssrcand first j tokens of toksdst.
B storesthe path of the Levenshtein distance and E storesthe edit operations in this path.
The original Lev-enshtein edit distance has 4 edit operations: un-change (U ), addition (A), deletion (D) and substi-tution (S).
We extend the ?substitution?
edit intotwo types of edits: inflection (I) and the originalsubstitution (S).
If two different words have thesame lemma, the substitution operation is I, else isS.
lemma(x) returns the lemma of token x. Thisalgorithm returns the edit operations E and the pa-rameters of these operations P. Here is a simplesample illustrating this algorithm.
For the goldenedit {a red apple is ?
red apples are}, tokssrcisa red apple is, toksdstis red apples are, the outputedits E will be {D,U , I,S}, and the parameters Pwill be {-, red, apples, are}.Then with the output of this extended Leven-shtein distance algorithm, labels can be generatedby transforming these edit operations into readablesymbols.
For those tokens without errors, we di-rectly assign a special label ???
to them.
A trickypart of the labeling process is the problem of theedit ?addition?,A.
A new token can only be addedbefore or after an existing token.
Thus for edit op-eration with addition, we must find an existing to-ken that the label can be assigned to, and this sortof token is defined as pivot.
A pivot can be a tokenthat is not changed in an edit operation, such as the?apple?
in edit {apple ?
an apple}, or some oth-er types of edit such as the inflection of ?look?
to?looking?
in edit {look ?
have been looking at}.The names of these labels are based on BNFsyntax which is defined in Figure 1.
The non-terminal ?word?
can be substituted by all wordsin the vocabulary.
The non-terminal ?inflection-rules?
can be substituted by terminals of inflectionrules that are used for correcting the error types ofnoun number, verb form, and subject-verb agree-ment errors.
All the inflection rules are listed inTable 1.With the output of extended Levenshtein editsdistance algorithm, Algorithm 2 gives the processto generate labels whose names are based on thesyntax defined in Figure 1.
It takes the output E, Pof Algorithm 1 as inputs and returns the generat-ed set of labels L. Each label in L corresponds toone token in tokssrcin order.
For our previous ex-ample of edit {a red apple is ?
red apples are},?label?
::= ?simple-label?
| ?compound-label??simple-label?
::= ?pivot?
| ?add-before?
|?add-after??compound-label?
::= ?add-before?
?pivot?| ?pivot?
?add-after?| ?add-before?
?pivot?
?add-after??pivot?
::= ?unchange?
| ?substitution?
|?inflection?| ?deletion??add-before?
::= ?word?
?| ?word???add-before??add-after?
::= ?
?word?| ??word??add-after??substitution?
::= ?word??inflection?
::= ?inflection-rules??unchange?
::= ??deletion?
::= ?Figure 1: BNF syntax of labelRules DescriptionLEMMA change word to its lemmaNPLURAL change noun to its plural formVSINGULAR change verb to its singular formGERUND change verb to its gerund formPAST change verb to its past formPART change verb to its past partici-pleTable 1: Inflection rulesthe L returned by Algorithm 2 is {?, ?, NPLU-RAL, ARE} corresponding to the tokens {a, red,apple, is} in tokssrc.
Some other examples of thegenerated labels are presented in Table 2.These labels are elaborately designed that eachof them can be interpreted easily as a series of ed-it operations.
Once the labels are determined byclassifier, the correction of the grammatical errorsis conducted by applying the edit operations inter-preted from these labels.76Algorithm 2 Labeling Algorithm1: INPUT: E,P2: OUTPUT: L3: pivot?
number of edits in E that are not A4: L?
?5: L??
?6: while i < length(E) do7: if E[i] = A then8: L?
L+ label of edit E[i] with P[i]9: i?
i + 110: else11: l?
L+ label of edit E[i] with P[i]12: pivot?
pivot?
113: if pivot = 0 then14: i?
i + 115: while i < length of E do16: l?
l +?+ P[i]17: i?
i + 118: end while19: end if20: push l into L21: L??
?22: end if23: end while24: L?
upper case of L25: return LTokens Edit Labelto{to reveal?revealing}?reveal GERUNDa{a woman?women}?woman NPLURALdeveloping {developing world THE?wold ?the developing world} ?a {a?
?}
?in {in?on} ONapple {apple?an apple} AN?Table 2: Examples of labeling2.2 Label ClassificationUsing the approach described above, the trainingcorpus is converted to a sequence of words withlabels.
Maximum entropy model is used as theclassifier.
It allows a very rich set of features to beused in a model and has shown good performancein similiar tasks (Zhao et al., 2013).
The featureswe used are discussed in the next section.3 Feature Selection and GenerationOne key factor affecting the performance of maxi-mum entropy classifier is the features it used.
Agood feature that contains useful information toguide classification will significantly improve theperformance of the classifier.
One direct way toinvolve more good features is involving more fea-tures.In our approach, large amounts of candidatefeatures are collected at first.
We carefully exam-ine the factors involved in a wide range of fea-tures that have been or can be used to the wordlabel classification task.
Many features that areconsidered effective in various of previous work-s (Dahlmeier et al., 2012; Rozovskaya et al.,2012; Han et al., 2006; Rozovskaya et al., 2011;Tetreault, Joel R and Chodorow, Martin, 2008)are included.
Besides, features that are used inthe similar spell checking tasks (Jia et al., 2013b;Yang et al., 2012) and some novel features show-ing effectiveness in other NLP tasks (Wang et al.,2013; Zhang and Zhao, 2013; Xu and Zhao, 2012;Ma and Zhao, 2012; Zhao, 2009; Zhao et al.,2009b) are also included.
However, using toomany features is time consuming.
Besides, it in-creases the probability of overfitting and may leadto a poor solution of the maximum-likelihood pa-rameter estimate in the ME training.Algorithm 3 Greedy Feature Selection1: INPUT: all feature candidates F2: OUTPUT: selected features S3: S = {f0, f1, .
.
.
, fk}, a random subset of F4: while do5: C = RECRUITMORE(S)6: if C = {} then7: return S8: end if9: S?= SHAKEOFF(S+C)10: if scr(M(S)) ?
scr(M(S?))
then11: return S12: end if13: S = S?14: end while15: function RECRUITMORE(S)16: C = {}, and p = scr(M(S))17: for each f ?
F ?
S do18: if p < scr(M(S + {f})) then19: C = C + {f}20: end if21: end for22: end function23: function SHAKEOFF(S)24: while do25: S?= S0= S26: for each f ?
S do27: if scr(M(S?))
< scr(M(S??
{f})) then28: S?= S??
{f}29: end if30: end for31: S = S?32: if S?= S0then33: return S?34: end if35: end while36: end functionTherefore a feature selection algorithm is intro-duced to filter out ?bad?
features at first and the re-maining features will be used to generate new fea-tures.
The feature selection algorithm has shown77effectiveness in (Zhao et al., 2013) and is present-ed in Algorithm 3.In this algorithm, M(S) represents the modelusing feature set S and scr(M) represents the e-valuation score of model M on a development da-ta set.
It repeats two main steps until no furtherperformance gain is achievable:1.
Include any features from the rest of F intothe current set of candidate features if the in-clusion would lead to a performance gain.2.
Exclude any features from the current set ofcandidate templates if the exclusion wouldlead to no deterioration in performance.By repeatedly adding the useful and removingthe useless features, the algorithm aims to returna better and smaller set of features for next round.Only 55 of the 109 candidate features remain af-ter using this algorithm and they are presented inTable 4.
Table 3 gives an interpretation of the ab-breviations used in Table 4.
Each feature of a wordis set to that listed in feature column if the wordsatisfies the condition listed in current word col-umn, else the feature is set to ?NULL?.
For ex-ample, if the current word satisfies the conditionin the first row of Table 4 which is the first wordin the left of a NC, feature 1 of this word is set toall words in the NC, otherwise, feature 1 is set to?NULL?.4 Experiment4.1 Data SetsThe CoNLL-2014 training data is a corpus oflearner English provided by (Dahlmeier et al.,2013).
This corpus consists of 1,397 articles, 12Ksentences and 116K tokens.
The official blind testdata consists of 50 articles, 245 sentences and 30Ktokens.
More detailed information about this datais described in (Ng et al., 2014; Dahlmeier et al.,2013).In development phase, the entire training corpusis splited by sentence.
80% sentences are pickedup randomly and used for training and the rest20% are used as the developing corpus.
For the fi-nal submission, the entire corpus is used for train-ing.Abbreviation DescriptionNP Noun PhraseNC Noun Compound and is ac-tive if second to last word inNP is tagged as nounVP Verb Phrasecw Current Wordpos part-of-speech of the currentwordX.lithe ith word in the left of XX.rithe ith word in the right of XNP[0] the first word of NPNP.head the head word of NPNP.
(DT orIN or TO)word in NP whose pos is DTor IN or TOVP.verb word in VPwhose pos is ver-bVP.NP NP in VPdp the dependency relation gen-erated by standford depen-dency parserdp.dep the dependent in the depen-dency relationdp.head the head in the dependencyrelationdp.rel the type of the dependencyrelationTable 3: The interpretation of the abbrevations inTable 44.2 Data LabelingThe labeling algorithm described in section 2.1 isfirstly applied to the training corpus.
Total 7047labels are generated and those whose count is larg-er than 15 is presented in Table 5.
Directly ap-plying these 7047 labels for correction receives anM2score of precision=90.2%, recall=87.0% andF 0.5=89.5%.
However, the number of labelsis too large that the training process is time con-suming and those labels appears only few timeswill hurt the generalization of the trained model.Therefore, labels with low frequency which ap-pear less than 30 times are cut out and 109 labelsremain.
The M2score of the system using this re-fined labels is precision=83.9%, recall=64.0% andF 0.5=79.0%.
Note that even applying all labels,the F 0.5 is not 100%.
It is because some annota-tions in the training corpus are not consistency.78current word featureNC.l1NCNP.l1NPNP[0] NP.l1.posNC.l1NCNC.l1NC.l1.posNC.l1and pos=DT NCNC.l1and pos=VB NCNP.l1and pos=VB NPpos=VB cwpos=DT cwthe cw.r1a cw.r1an cw.r1NP[0] cwNP[0] NP.l1NP[0] NP.l2NP[0] NP.l3NP[0] NP.l1.posNP[0] NP.l2.posNP[0] NP.l3.posNP.l1NP.headNP.l1NP.head.posNP.head NP.
headNP.head NP.
head.bagNP.head NP.
head.posNP.head NP.
head.pos.bagNP.head NP.
(JJ or CC)NP.
(DT or IN or TO) NPNP.
(DT or IN or TO) NP.headNP.
(DT or IN or TO) NP.head.posdp.dep dp.headdp.head dp.depdp.dep dp.head.posdp.head dp.dep.posdp.dep dp.reldp.head dp.relVP.verb VP.NPVP.verb VP.NP.headVP.NP.head VP.verbVP.verb VP.NP.head.posVP.NP.head VP.verb.poscw cw.li, i ?
{0, 1, 2, 3}cw cw.ri, i ?
{1, 2, 3}cw cw.li.pos, i ?
{0, 1, 2, 3}cw cw.ri.pos, i ?
{1, 2, 3}Table 4: Remained features after the feature selec-tion.Count Label1091911 ?31507 ?3637 NPLURAL2822 THE?2600 LEMMA948 ,?300?900 A?
PAST THE IN TO .
IS OF ARE FORGERUND ,50?100 AND ON AN?
A VSINGULAR WAS THEIR20?50 ELDERLY IT OF?
THEY WITH TO?WERE THIS ; ITS .?
THAT ?S?
AND?THAT?
HAVE?
CAN AS HAVE?PARTFROM BE WOULD BY15?20 HAVE HAS?WILL HAS AT AN THESE ?,THEM IN?
INTO #?
ARE?
WHICH PEO-PLE HAS?PART ECONOMIC IS?
BE?
SOCOULD TO?LEMMA MANY PART MAYLESS IT?
FOR?
BEING?15?20 NOT ABOUT WILL?LEMMA SHOULDHIS BECAUSE AGED SUCH ALSOWHICH?
HAVE?PAST WILL?
WHOWHEN MUCH15?20 ON?
?
THROUGH BE?PAST MOREIF HELP THE?ELDERLY ?S ONE AS?THERE THEIR?
WITH?
HAVE?
?ECONOMY DEVELOPMENT CON-CERNED PEOPLE?
PROBLEMS BUTMEANS THEREFORE HOWEVER BE-ING : UP PROBLEM ??
THE?LEMMAIN?ADDITION HOWEVER?,?
AMONG;?
WHERE THUS ONLY HEALTHHAS?PAST FUNDING EXTENT ALSO?TECHNOLOGICAL ?
OR HAD WOULD?VERY .
?THIS ITS?
IMPORTANT DEVEL-OPED ?BEEN AGE ABOUT?WHO?
USETHEY?
THAN NUMBER HOWEVER?,GOVERNMENT FURTHERMORE DURINGBUT?
YOUNGER RIGHT POPULATIONPERSON?
FEWER ENVIRONMENTAL-LY WOULD?LEMMA OTHER MAY?LIMITED HE COULD?HAVE BEEN STIL-L SPENDING SAFETY OVER ONE?
?SMAKE MADE LIFE HUMAN HAD?FUNDS CARE ARGUED ALL ??
WHEN?TIME THOSE SOCIETY RESEARCHPROVIDE OLD NEEDS INCREASING DE-VELOPING BECOME BE??
ADDITIONTable 5: Labels whose count is larger than 15.current word featureNC.l1NC, cw, cw.l1, cw.l1.pos,cw.r1, cw.r1.posNP[0] NP.head, NP.l1, NP.l2,cw, cw.l1, cw.l1.pos,NP.head NP[0], NP.l1, NP.l2, cw,cw.l1, cw.l1.pos,dp.head cw, cw.l1, cw.l2dp.dep,dp.dep.pos, dp.relTable 6: Examples of the new generated features.794.3 Data RefinementThe training corpus is refined before used that sen-tences which do not contain errors are filtered out.Only 38% of the total sentences remain.
With lesstraining corpus, it takes less time to train the MEmodel.
Table 7 presents the performance of sys-tems using the unrefined training corpus and re-fined corpus.System Presicion Recall F 0.5unrefined 26.99% 1.67% 6.71%refined 11.17% 3.1% 7.34%Table 7: Comparison of systems with differen-t training corpus.All sets of these systems are kept the same ex-cept the training corpus they use.
It can be seenthat the refinement also improves the performanceof the system.4.4 Feature SelectionFigure 2 shows the results of systems with dif-ferent feature sets.
sys 10 is the system withFigure 2: Performance of systems with differentfeatures.10 randomly chosen features which are used asthe initial set of features in Algorithm 3, sys 55is the system with the refined 55 features.
Withthese refined features, various of new features aregenerated by combining different features.
Thiscombination is conducted empirically that featureswhich are considered having relations are com-bined to generate new features.
Using this method,165 new features are generated and total 220 fea-tures are used in sys 220.
Table 6 gives a fewof examples showing the combined features.
Theperformance is evaluated by the precision, recal-l and F 0.5 score of the M2scorer accordingto (Dahlmeier and Ng, 2012).
It can be seenthat sys 220 with the most number of featuresachieves the best performance.4.5 Evaluation ResultThe final system we use is sys 220 with refinedtraining data, the performance of our system on thedeveloping corpus and the blind official test data ispresented in Table 8.
The score is calculated usingM2scorer.Data Set Precision Recall F 0.5DEV 13.52% 6.41% 11.07%OFFICIAL 29.83% 5.16% 15.24%Table 8: Evaluation Results5 ConclusionIn this paper, we describe the system of Shang-hai Jiao Tong Univerity team in the CoNLL-2014shared task.
The grammatical error detection is re-garded as a multi-label classification task and thecorrection is conducted by applying a rule-basedapproach based on these labels.
A single max-imum entropy classifier is introduced to do themulti-label classification.
Various features are in-volved and a feature selection algorithm is usedto refine these features.
Finally, large amounts offeature templates that are generated by the combi-nation of the refined features are used.
This systemachieved precision of 29.83%, recall of 5.16% andF 0.5 of 15.24% in the official evaluation.ReferencesAdam L Berger, Vincent J Della Pietra, and StephenA Della Pietra.
1996.
A maximum entropy ap-proach to natural language processing.
Computa-tional linguistics, 22(1):39?71.Daniel Dahlmeier and Hwee Tou Ng.
2012.
Betterevaluation for grammatical error correction.
In Pro-ceedings of the 2012 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Human Language Technologies (NAA-CL 2012), pages 568?572, Montreal, Canada.Daniel Dahlmeier, Hwee Tou Ng, and Eric Jun FengNg.
2012.
NUS at the HOO 2012 Shared Task.
InProceedings of the Seventh Workshop on Building E-ducational Applications Using NLP, pages 216?224,Montr?eal, Canada, June.
Association for Computa-tional Linguistics.80Daniel Dahlmeier, Hwee Tou Ng, and Siew Mei Wu.2013.
Building a large annotated corpus of learnerenglish: The nus corpus of learner english.
In Pro-ceedings of the Eighth Workshop on Innovative Useof NLP for Building Educational Applications (BEA2013), pages 22?31, Atlanta, Georgia, USA.Robert Dale, Ilya Anisimoff, and George Narroway.2012.
Hoo 2012: A report on the preposition anddeterminer error correction shared task.
In Proceed-ings of the Second Workshop on Building Education-al Applications Using NLP, pages 54?62, Montr?eal,Canada, June.
Association for Computational Lin-guistics.NA-RAE Han, Martin Chodorow, and Claudia Lea-cock.
2006.
Detecting Errors in English ArticleUsage by Non-Native Speakers.
Natural LanguageEngineering, 12:115?129, 5.Zhongye Jia, Peilu Wang, and Hai Zhao.
2013a.Grammatical error correction as multiclass classi-fication with single model.
In Proceedings of theSeventeenth Conference on Computational NaturalLanguage Learning: Shared Task, pages 74?81,Sofia, Bulgaria, August.
Association for Computa-tional Linguistics.Zhongye Jia, Peilu Wang, and Hai Zhao.
2013b.
Graphmodel for chinese spell checking.
In Proceedingsof the Seventh SIGHAN Workshop on Chinese Lan-guage Processing, pages 88?92, Nagoya, Japan, Oc-tober.
Asian Federation of Natural Language Pro-cessing.Ting-hui Kao, Yu-wei Chang, Hsun-wen Chiu, Tzu-HsiYen, Joanne Boisson, Jian-cheng Wu, and Jason S.Chang.
2013.
Conll-2013 shared task: Grammati-cal error correction nthu system description.
In Pro-ceedings of the Seventeenth Conference on Compu-tational Natural Language Learning: Shared Task,pages 20?25, Sofia, Bulgaria, August.
Associationfor Computational Linguistics.Ekaterina Kochmar, ?istein Andersen, and TedBriscoe.
2012.
HOO 2012 Error Recognition andCorrection Shared Task: Cambridge University Sub-mission Report.
In Proceedings of the SeventhWorkshop on Building Educational Applications Us-ing NLP, pages 242?250, Montr?eal, Canada, June.Association for Computational Linguistics.Xuezhe Ma and Hai Zhao.
2012.
Fourth-order depen-dency parsing.
In Proceedings of COLING 2012:Posters, pages 785?796, Mumbai, India, December.The COLING 2012 Organizing Committee.Hwee Tou Ng, Siew Mei Wu, Ted Briscoe, ChristianHadiwinoto, Raymond Hendy Susanto, and Christo-pher Bryant.
2014.
The conll-2014 shared taskon grammatical error correction.
In Proceedings ofthe Eighteenth Conference on Computational Natu-ral Language Learning: Shared Task (CoNLL-2014Shared Task), Baltimore, Maryland, USA.Alla Rozovskaya, Mark Sammons, Joshua Gioja, andDan Roth.
2011.
University of Illinois System inHOO Text Correction Shared Task.
In Proceedingsof the 13th European Workshop on Natural Lan-guage Generation, pages 263?266.
Association forComputational Linguistics.Alla Rozovskaya, Mark Sammons, and Dan Roth.2012.
The UI System in the HOO 2012 Shared Taskon Error Correction.
In Proceedings of the SeventhWorkshop on Building Educational Applications Us-ing NLP, pages 272?280, Montr?eal, Canada, June.Association for Computational Linguistics.Alla Rozovskaya, Kai-Wei Chang, Mark Sammons,and Dan Roth.
2013.
The university of illinois sys-tem in the conll-2013 shared task.
In Proceedings ofthe Seventeenth Conference on Computational Natu-ral Language Learning: Shared Task, pages 13?19,Sofia, Bulgaria, August.
Association for Computa-tional Linguistics.Tetreault, Joel R and Chodorow, Martin.
2008.
TheUps and Downs of Preposition Error Detection inESL Writing.
In Proceedings of the 22nd Inter-national Conference on Computational Linguistics-Volume 1, pages 865?872.
Association for Compu-tational Linguistics.Rui Wang, Masao Utiyama, Isao Goto, Eiichro Sumi-ta, Hai Zhao, and Bao-Liang Lu.
2013.
Convert-ing continuous-space language models into n-gramlanguage models for statistical machine translation.In Proceedings of the 2013 Conference on Empiri-cal Methods in Natural Language Processing, pages845?850, Seattle, Washington, USA, October.
Asso-ciation for Computational Linguistics.Yang Xiang, Bo Yuan, Yaoyun Zhang, Xiaolong Wang,Wen Zheng, and Chongqiang Wei.
2013.
A hybridmodel for grammatical error correction.
In Proceed-ings of the Seventeenth Conference on Computation-al Natural Language Learning: Shared Task, pages115?122, Sofia, Bulgaria, August.
Association forComputational Linguistics.Junwen Xing, Longyue Wang, Derek F. Wong, Lidi-a S. Chao, and Xiaodong Zeng.
2013.
Um-checker:A hybrid system for english grammatical error cor-rection.
In Proceedings of the Seventeenth Confer-ence on Computational Natural Language Learn-ing: Shared Task, pages 34?42, Sofia, Bulgaria, Au-gust.
Association for Computational Linguistics.Qiongkai Xu and Hai Zhao.
2012.
Using deep lin-guistic features for finding deceptive opinion spam.In Proceedings of COLING 2012: Posters, pages1341?1350, Mumbai, India, December.
The COL-ING 2012 Organizing Committee.Shaohua Yang, Hai Zhao, Xiaolin Wang, and Baoliang Lu.
2012.
Spell checking for chinese.In Nicoletta Calzolari (Conference Chair), KhalidChoukri, Thierry Declerck, Mehmet U?gur Do?gan,Bente Maegaard, Joseph Mariani, Jan Odijk, and81Stelios Piperidis, editors, Proceedings of the EighthInternational Conference on Language Resourcesand Evaluation (LREC-2012), pages 730?736, Is-tanbul, Turkey, May.
European Language ResourcesAssociation (ELRA).
ACL Anthology Identifier:L12-1423.Ippei Yoshimoto, Tomoya Kose, Kensuke Mitsuza-wa, Keisuke Sakaguchi, Tomoya Mizumoto, YutaHayashibe, Mamoru Komachi, and Yuji Matsumo-to.
2013.
Naist at 2013 conll grammatical errorcorrection shared task.
In Proceedings of the Seven-teenth Conference on Computational Natural Lan-guage Learning: Shared Task, pages 26?33, Sofi-a, Bulgaria, August.
Association for ComputationalLinguistics.Jingyi Zhang and Hai Zhao.
2013.
Improving functionword alignment with frequency and syntactic infor-mation.
In Proceedings of the Twenty-Third inter-national joint conference on Artificial Intelligence,pages 2211?2217.
AAAI Press, August.Hai Zhao, Wenliang Chen, and Chunyu Kit.
2009a.Semantic dependency parsing of nombank and prop-bank: An efficient integrated approach via a large-scale feature selection.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing, pages 30?39, Singapore, August.Association for Computational Linguistics.Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.2009b.
Cross language dependency parsing using abilingual lexicon.
In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACL andthe 4th International Joint Conference on NaturalLanguage Processing of the AFNLP, pages 55?63,Suntec, Singapore, August.
Association for Compu-tational Linguistics.Hai Zhao, Xiaotian Zhang, and Chunyu Kit.
2013.
In-tegrative semantic dependency parsing via efficien-t large-scale feature selection.
Journal of ArtificialIntelligence Research, 46:203?233.Hai Zhao.
2009.
Character-level dependencies in chi-nese: Usefulness and learning.
In Proceedings ofthe 12th Conference of the European Chapter of theACL (EACL 2009), pages 879?887, Athens, Greece,March.
Association for Computational Linguistics.82
