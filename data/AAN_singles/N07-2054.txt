Proceedings of NAACL HLT 2007, Companion Volume, pages 213?216,Rochester, NY, April 2007. c?2007 Association for Computational LinguisticsSpeech Summarization Without Lexical Featuresfor Mandarin Broadcast NewsJian ZhangHuman Language Technology CenterElectronic and Computer EngineeringUniversity of Science and TechnologyClear Water Bay,Hong Kongzjustin@ust.hkPascale FungHuman Language Technology CenterElectronic and Computer EngineeringUniversity of Science and TechnologyClear Water Bay,Hong Kongpascale@ee.ust.hkAbstractWe present the first known empirical studyon speech summarization without lexi-cal features for Mandarin broadcast news.We evaluate acoustic, lexical and struc-tural features as predictors of summarysentences.
We find that the summarizeryields good performance at the average F-measure of 0.5646 even by using the com-bination of acoustic and structural featuresalone, which are independent of lexicalfeatures.
In addition, we show that struc-tural features are superior to lexical fea-tures and our summarizer performs sur-prisingly well at the average F-measureof 0.3914 by using only acoustic features.These findings enable us to summarizespeech without placing a stringent demandon speech recognition accuracy.1 IntroductionSpeech summarization, a technique of extractingkey segments that convey the main content froma spoken document or audio document, has be-come a new area of study in the last few years.There has been much significant progress made inspeech summarization for English or Japanese textand audio sources (Hori and Furui, 2003; Inoue etal., 2004; Koumpis and Renals, 2005; Maskey andHirschberg, 2003; Maskey and Hirschberg, 2005).Some research efforts have focused on summariz-ing Mandarin sources (Chen et al, 2006; Huanget al, 2005), which are dependent on lexical fea-tures.
Considering the difficulty in obtaining highquality transcriptions, some researchers proposedspeech summarization systems with non-lexical fea-tures (Inoue et al, 2004; Koumpis and Renals,2005; Maskey and Hirschberg, 2003; Maskey andHirschberg, 2006).
However, there does not existany empirical study on speech summarization with-out lexical features for Mandarin Chinese sources.In this paper, we construct our summarizer withacoustic and structural features, which are indepen-dent of lexical features, and compare acoustic andstructural features against lexical features as predic-tors of summary sentences.In Section 2 we review previous work on broad-cast news summarization.
We describe the Mandarinbroadcast news corpus on which our system operatesin Section 3.
In Section 4 we describe our summa-rizer and these features used in experiments.
We setup our experiments and evaluate the results in Sec-tion 5, followed by our conclusion in Section 6.2 Previous WorkThere have been many research efforts on speechsummarization.
Some methods dependent on lexi-cal features are presented (Inoue et al, 2004; Chenet al, 2006; Huang et al, 2005).
(Inoue et al,2004) uses statistical methods to identify words toinclude in a summary, based on linguistic and acous-tic/prosodic features of the Japanese broadcast newstranscriptions; while (Chen et al, 2006) proposesthe use of probabilistic latent topical information forextractive summarization of Mandarin spoken docu-ments.
(Huang et al, 2005) presents Mandarin spo-213ken document summarization scheme using acous-tic, prosodic, and semantic information.
Alterna-tively, some methods which are independent of lex-ical features are presented (Maskey and Hirschberg,2003; Maskey and Hirschberg, 2006).
(Maskeyand Hirschberg, 2003) extracts structural informa-tion from audio documents to help summarization.
(Maskey and Hirschberg, 2006) focuses on how touse acoustic information alone to help predict sen-tences to be included in a summary and shows anovel way of using continuous HMMs for summa-rizing speech documents without transcriptions.It is advantageous to build speech summarizationmodels without using lexical features: we can sum-marize speech data without placing a stringent de-mand on the speech recognition accuracy.
In this pa-per, we propose one such model on Mandarin broad-cast news and compare the effectiveness of acous-tic and structural features against lexical features aspredictors of summary sentences.3 The Corpus and Manual SummariesWe use a portion of the 1997 Hub4 Mandarin corpusavailable via LDC as experiment data.
The relatedaudio data were recorded from China Central Tele-vision(CCTV) International News programs.
Theyinclude 23-day broadcast from 14th January, 1997to 21st April, 1997, which contain 593 stories andweather forecasts.
Each broadcast lasts approxi-mately 32 minutes, and has been hand-segmentedinto speaker turns.
For evaluation, we manuallyannotated these broadcast news, and extracted seg-ments as reference summaries.
We divide thesebroadcast news stories into 3 types: one-turn news,weather forecast, and several-turns news.
The con-tent of each several-turn news is presented by morethan one reporter, and sometimes interviewees.
Weevaluate our summarizer on the several-turns newscorpus.
The corpus has 347 stories which contain4748 sentences in total.4 Features and Methodology4.1 Acoustic/Prosodic FeaturesAcoustic/prosodic features in speech summarizationsystem are usually extracted from audio data.
Re-searchers commonly use acoustic/prosodic variation?
changes in pitch, intensity, speaking rate ?
and du-ration of pause for tagging the important contentsof their speeches (Hirschberg, 2002).
We also usethese features for predicting summary sentences onMandarin broadcast news.Our acoustic feature set contains thirteen features:DurationI, DurationII, SpeakingRate, F0I, F0II,F0III, F0IV, F0V, EI, EII, EIII, EIV and EV.
Du-rationI is the sentence duration.
DurationII is theaverage phoneme duration.
General phonetic stud-ies consider that the speaking rate of sentence is re-flected in syllable duration.
So we use average syl-lable duration for representing SpeakingRate.
F0I isF0?s minimum value.
F0II is F0?s maximum value.F0III equals to the difference between F0II and F0I.F0IV is the mean of F0.
F0V is F0 slope.
EI is min-imum energy value.
EII is maximum energy value.EIII equals to the difference between EII and EI.EIV is the mean of energy value.
EV is energy slope.We calculate DurationI from the annotated manualtranscriptions that align the audio documents.
Wethen obtain DurationII and SpeakingRate by pho-netic forced alignment.
Next we extract F0 fea-tures and energy features from audio data by usingPraat (Boersma and Weenink, 1996).4.2 Structural FeaturesEach broadcast news of the 1997 Hub4 Mandarincorpus has similar structure, which starts with an an-chor, followed by the formal report of the story byother reporters or interviewees.Our structural feature set consists of 4 features:Position, TurnI, TurnII and TurnIII.
Position is de-fined as follows: one news has k sentences, then weset (1?
(0/k)) as Position value of the first sentencein the news, and set (1?
((i?1)/k)) as Position valueof the ith sentence.
TurnI is defined as follows: onenews has m turns, then we set (1?
(0/m)) as TurnIvalue of the sentences which belong to the first turn?scontent, and set (1?
((j?1)/m)) as TurnI values ofthe sentences which belong to the jth turn?s content.TurnII is the previous turn?s TurnI value.
TurnIII isthe next turn?s TurnI value.4.3 Reference Lexical FeaturesMost methods for text summarization mainly utilizelexical features.
We are interested in investigatingthe role of lexical features in comparison to otherfeatures.
All reference lexical features are extracted214from the manual transcriptions.Our lexical feature set contains eight features:LenI, LenII, LenIII, NEI, NEII, NEIII, TFIDFand Cosine.
For a sentence, we set the number ofwords in the sentence as LenI value.
LenII is theprevious sentence?s LenI value.
LenIII is the nextsentence?s LenI value.
For a sentence, we set thenumber of Named Entities in the sentence as theNEI value.
We define the number of Named Enti-ties which appear in the sentence at the first time ina news as NEII value.
NEIII value equals to the ra-tio of the number of unique Named Entities to thenumber of all Named Entities.TFIDF is the product of tf and idf.
tf is the frac-tion: the numerator is the number of occurrencesof the considered word and the denominator is thenumber of occurrences of all words in a story.
idf isthe logarithm of the fraction: the numerator is the to-tal number of sentences in the considered news andthe denominator is the number of sentences wherethe considered word appears.
Cosine means cosinesimilarity measure between two sentence vectors.4.4 SummarizerOur summarizer contains the preprocessing stageand the estimating stage.
The preprocessing stageextracts features and normalizes all features byequation (1).Nj = wj ?mean(wj)dev(wj) (1)Here, wj is the original value of feature j which isused to describe sentence i; mean(wj) is the meanvalue of feature j in our training set or test set;dev(wj) is the standard deviation value of featurej in our training set or test set.The estimating stage predicts whether each sen-tence of the broadcast news is in a summary or not.We use Radial Basis Function(RBF) kernel for con-structing SVM classifier as our estimator referring toLIBSVM (Chang and Lin, 2001), which is a libraryfor support vector machines.5 Experiments and EvaluationWe use the several-turn news corpus, described inSection 3, in our experiments.
We use 70% of thecorpus consisting of 3294 sentences as training setTable 1: Feature set Evaluation by F-measureFeature Set SR10% SR15% SR20% AveAc+St+Le .5961 .546 .5544 .5655Ac+St .5888 .5489 .5562 .5646St .5951 .5616 .537 .5645Le .5175 .5219 .5329 .5241Ac .3068 .4092 .4582 .3914Baseline .21 .32 .43 .32Ac: Acoustic; St: Structural; Le: Lexicaland the remaining 1454 sentences as held-out testset, upon which our summarizer is tested.We measure our summarizer?s performance byprecision, recall, and F-measure (Jing et al, 1998).We explain these metrics as follows:precision = Sman?SsumSsum (2)recall = Sman?SsumSman (3)F-Measure = 2?
precision ?
recallprecision + recall (4)In equation (2), (3) and (4), Sman is the sentenceset of manual summaries or reference summaries;Ssum is the sentence set of predicted summaries pro-vided by our summarizer.We have three versions of reference summariesbased on summarization ratio(SR): 10%, 15% and20% respectively.
So we build three baselines re-ferring to different versions of reference summaries.When using SR 10% summaries, we build the base-lines by choosing the first 10% of sentences fromeach story.
Our baseline results in F-measure scoreare given in Table 1.We perform three sets of experiments with differ-ent summarization ratios.By using acoustic and structural features alone,the summarizer produces the same performance asby using all features.
We can find the evidence fromTable 1 and Figure 1.
On average, the combinationof acoustic and structural features yields good per-formance: F-measure of 0.5646, 24.46% higher thanthe baseline, only 0.09% lower than the average F-measure produced by using all features.
This find-ing makes it possible to summarize speech without215A L AS S ALS0.000.050.100.150.200.250.300.350.400.450.500.550.600.65A:Acoustic, S: Structural, L:LexicalPositive PrecisionPositive RecallPositive F-measureScoreFeature setsFigure 1: Performance comparison on SR10%placing a stringent demand on the speech recogni-tion accuracy.In the same Mandarin broadcast program, the dis-tribution and flow of summary sentences are rela-tively consistent.
Therefore, compared with speechsummarization on English sources, we can achievethe different finding that structural features playa key role in speech summarization for Mandarinbroadcast news.
Table 1 shows the evidence.
Onaverage, structural features are superior to lexicalfeatures: F-measure of 0.5645, 24.45% higher thanthe baseline and 4,04% higher than the average F-measure produced by using lexical features.Another conclusion we can draw from Table 1is that acoustic features are important for speechsummarization on Mandarin broadcast news.
Onaverage, even by using acoustic features alone oursummarizer yields competitive result: F-measure of0.3914, 7.14% higher than the baseline.
The similarconclusion also holds for speech summarization onEnglish sources (Maskey and Hirschberg, 2006).6 ConclusionIn this paper, we have presented the results of anempirical study on speech summarization for Man-darin broadcast news.
From these results, we foundthat by using acoustic and structural features alone,the summarizer produces good performance: aver-age F-measure of 0.5646, the same as by using allfeatures.
We also found that structural features makemore important contribution than lexical features tospeech summarization because of the relatively con-sistent distribution and flow of summary sentencesin the same Mandarin broadcast program.
Moreover,we have shown that our summarizer performed sur-prisingly well by using only acoustic features: av-erage F-measure of 0.3914, 7.14% higher than thebaseline.
These findings also suggest that high qual-ity speech summarization can be achieved withoutstringent requirement on speech recognition accu-racy.ReferencesP.
Boersma and D. Weenink.
1996.
Praat, a system for doingphonetics by computer, version 3.4.
Institute of PhoneticSciences of the University of Amsterdam, Report, 132:182.Chih-Chung Chang and Chih-Jen Lin, 2001.
LIBSVM: a libraryfor support vector machines.B.
Chen, Y.M.
Yeh, Y.M.
Huang, and Y.T.
Chen.
2006.
Chi-nese Spoken Document Summarization Using ProbabilisticLatent Topical Information.
Proc.
ICASSP.J.
Hirschberg.
2002.
Communication and prosody: Functionalaspects of prosody.
Speech Communication, 36(1):31?43.C.
Hori and S. Furui.
2003.
A new approach to automaticspeech summarization.
Multimedia, IEEE Transactions on,5(3):368?378.C.L.
Huang, C.H.
Hsieh, and C.H.
Wu.
2005.
Spoken Docu-ment Summarization Using Acoustic, Prosodic and Seman-tic Information.
Multimedia and Expo, 2005.
ICME 2005.IEEE International Conference on, pages 434?437.A.
Inoue, T. Mikami, and Y. Yamashita.
2004.
Improvement ofSpeech Summarization Using Prosodic Information.
Proc.of Speech Prosody.H.
Jing, R. Barzilay, K. McKeown, and M. Elhadad.
1998.Summarization evaluation methods: Experiments and anal-ysis.
AAAI Symposium on Intelligent Summarization.K.
Koumpis and S. Renals.
2005.
Automatic summariza-tion of voicemail messages using lexical and prosodic fea-tures.
ACM Transactions on Speech and Language Process-ing (TSLP), 2(1):1?24.S.
Maskey and J. Hirschberg.
2003.
Automatic summarizationof broadcast news using structural features.
Proceedings ofEurospeech 2003.S.
Maskey and J. Hirschberg.
2005.
Comparing lexical, acous-tic/prosodic, structural and discourse features for speechsummarization.
Interspeech 2005 (Eurospeech).S.
Maskey and J. Hirschberg.
2006.
Summarizing SpeechWithout Text Using Hidden Markov Models.
Proc.
NAACL.216
