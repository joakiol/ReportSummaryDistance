Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 357?368,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsGrounding Strategic Conversation:Using negotiation dialogues to predict trades in a win-lose gameAna?
?s CadilhacIRITUniv.
Toulouse, Francecadilhac@irit.frNicholas AsherIRIT, CNRSToulouse, Franceasher@irit.frFarah BenamaraIRITUniv.
Toulouse, Francebenamara@irit.frAlex LascaridesSchool of InformaticsUniv.
Edinburgh, UKalex@inf.ed.ac.ukAbstractThis paper describes a method that predictswhich trades players execute during a win-lose game.
Our method uses data collectedfrom chat negotiations of the game The Set-tlers of Catan and exploits the conversationto construct dynamically a partial model ofeach player?s preferences.
This in turn yieldsequilibrium trading moves via principles fromgame theory.
We compare our method againstfour baselines and show that tracking howpreferences evolve through the dialogue andreasoning about equilibrium moves are bothcrucial to success.1 IntroductionRational agents act so as to maximise their expectedutilities?an optimal trade off between what theyprefer and what they believe they can achieve (Sav-age, 1954).
Solving a game problem involves find-ing equilibrium strategies: an optimal action foreach player that maximises his expected utility, as-suming that the other players perform their speci-fied action (Shoham and Leyton-Brown, 2009).
Cal-culating equilibria thus requires knowledge of theother players?
preferences but almost all bargaininggames occur under the handicap of imperfect infor-mation about this (Osborne and Rubinstein, 1994).Players therefore try to extract their opponents?
pref-erences from what they say, likewise revealing theirown preferences in their own utterances.
Theseelicited preferences guide an agent?s decisions, likechoosing to make such and such a bargain with suchand such a person.
Tracking preferences throughdialogue is thus crucial for analyzing the agents?strategic reasoning in real game scenarios.In this paper, we design a model that maps whatpeople say in a win-lose game into a prediction ofexactly which players, if any, trade with each other,and exactly what resources they exchange.
We useboth statistics and logic: we use a corpus of nego-tiation dialogues to learn classifiers that map eachutterance to its speech act and to other acts perti-nent to bargaining; and we develop a symbolic al-gorithm that, from the classifiers?
output, dynami-cally constructs a model of each player?s preferencesas the conversation proceeds (for instance, the pref-erence to receive a certain resource, or to accept acertain trade).
This preference model uses CP-nets(Boutilier et al 2004), a representation of prefer-ences for which algorithms for computing equilib-rium strategies exist.
We adapt those algorithms topredict the trades executed in the game.The algorithm for construcing CP-nets uses onlythe output of our classifiers, which in turn rely en-tirely on shallow features in the raw text and robustparsers.
Together they provide an end to end model,from raw text to a prediction of which trade, if any,occurred.
We evaluate the various components ofthis (pipeline) algorithm separately, as well as theend to end model.Our study exploits a corpus of negotiation dia-logues from an online version of the win lose gameThe Settlers of Catan.
Sections 2 and 3 describethe corpus and its annotation.
Section 4 introducesour method for constructing the agents?
preferencesfrom the dialogues.
We use this in Section 5 to pre-dict whether a trade is executed as a result of the357players?
negotiations, and if so we predict who tookpart in the trade, and what they exchanged.
Ourmethod shows promising results, beating baselinesthat don?t adequately track or reason about prefer-ences.
We compare our model to related work inSection 6 and point to future work in Section 7.2 The gameThe Settlers of Catan (www.catan.com) is a win-lose game that involves negotiations over restrictedresources.
Each player (three or more) acquires re-sources (of 5 types: ore, wood, wheat, clay, sheep),which they use in different combinations to buildroads, settlements and cities, which in turn earnsthem points towards winning.
The first player to10 points wins.
Players acquire resources in sev-eral ways, in particular through agreed trades withother players.
Some methods (e.g., robbing) are hid-den from view, so players lack complete informationabout their opponents?
resources.Our corpus contains conversations of humansplaying an online version of Settlers (Afantenos etal., 2012).
Players must converse in a chat inter-face to carry out trades.
Each game contains severaldozen self-contained bargaining dialogues.
Our ex-periments use 10 Settlers games, consisting of morethan 2000 individual dialogue turns (see Section 3).Table 1 is a sample dialogue from the corpus.
Thesentences in the corpus have a relatively simple syn-tax, though many also exhibit long distance depen-dencies.
However, these conversations are pragmat-ically complex.
They exhibit complex anaphoric de-pendences (e.g., utterance ID 4 in Table 1).
Otherpragmatic inferences, which are dependent on rea-soning about intentions, speech acts and discoursestructure, are also ubiquitous.
For example, thequestion Have you got any ore?
implies an offer forthe speaker to receive ore in exchange for somethingfrom someone unspecified, and its response I?ve gotwheat not only implies a willingness to exchangewheat for something, but as a response to the ques-tion it also implies a refusal to give any ore.More generally, a dialogue turn in our corpus canexpress an offer, a counteroffer, an acceptance or re-jection of an offer, or a commentary on the aboveor on moves in the game.
All except the last pro-vide clues about preferences: e.g., which playersa speaker wants to execute a trade with; or whatresources to exchange.
For instance, the utteranceAnybody have any sheep for wheat?
conveys sev-eral preferences.
First, it conveys the speaker?s pref-erence to trade with someone unspecified.
Otherinformative but underspecified preferences include:the speaker?s preference to acquire some sheep overalternatives; and in a context where she receivessheep, a preference to give away some of her wheatover the alternatives.
Crucially, it does not conveya preference to give away wheat in a context whereshe receives nothing or something other than sheep.In line with a non-cooperative bargaining game,the preferences and offers that a speaker reveals areless specific than an executable trade requires, wherethe trading partners and the type of resources offeredand received must all be defined.
Such general dia-logue moves are essentially information seeking?evidence that humans playing Settlers have imper-fect information about their opponents?
preferences.In fact, many offers to trade result in no trade be-ing agreed to and executed.
While observed negoti-ation failure would be puzzling in a bargaining gamewith perfect information (Osborne and Rubinstein,1994), it occurs relatively frequently in Settlers.3 AnnotationWe have a multi-layered dialogue annotationscheme that includes: (1) a pre-annotation that seg-ments the dialogue into turns which are further seg-mented into Elementary Discourse Units (EDUs)with the author of each turn automatically given;(2) a characterization of each EDU in terms of ba-sic speech acts (assertion, question, request) as wellas dialogue acts that are specific to bargaining (of-fers, counteroffers, etc.
); and (3) associated infor-mation about the givable and/or receivable resourcesthat EDUs express.Two annotators received training on 77 dialogues,totaling 699 EDUs.
They then both annotated theremaining dialogues independently (2741 EDUs and511 dialogues in total).
Kappas for inter-annotatoragreement are given below.3.1 Dialogue act annotation (Kappa=0.79)Each turn logs what a player enters in the chat win-dow and also aspects of the game state at the time:358ID Dialogue Act Text Speaker Addressee Resource1 Offer i need clay, any1 have?
Rainbow All Receivable (clay, ?
)2 Refusal Nope, sorry inca Rainbow3 Refusal Not at the moment, unfortunately.
ariachiba Rainbow4 Refusal need mine sorry Kittles Rainbow Not givable (Anaphoric, ?
)Anaphora Link:(mine , clay )5 Offer no one has ore to giv?
Rainbow All Receivable (ore, ?
)6 Accept oh yeah me Kittles Rainbow7 Counteroffer ore for wheat again?
Kittles Rainbow Givable (ore, ?)
Receivable (wheat, ?
)8 Accept ya Rainbow Kittles9 Accept ok Kittles RainbowTable 1: Example of an annotated negotiation dialogue.his resources, the state of the game board and a timestamp.
The pre-annotation divides each turn intoEDUs.
The annotators then have to specify the dia-logue act of each EDU: Offer, Counteroffer, Acceptor Refusal (of an offer addressed to the emitter), andOther.
Other labels units that either comment onstrategic moves in the game or are not directly perti-nent to bargaining.
Annotators also specify the ad-dressee of the EDU and its surface type: Question,Request or Assertion.3.2 Resource type annotation (Kappa=0.80)Annotators also specify for each EDU and its dia-logue act an associated feature structure, which cap-tures (partial) information that the EDU expressesabout the type and quantity of resources that are ofthe following four attributes: Givable, Not Givable,Receivable or Not Receivable.
These attributes cantake Boolean combinations of resources as valuesvia two operators AND and OR, that respectivelystand for conjunction (the agent expresses two pref-erences and he prefers to achieve one of them if hecannot have both, such as I need clay and wood) anddisjunction (free choice) of preferences (e.g., I cangive you clay or wood).
We allow attributes to haveunknown values: the annotation tool inserts a ?
inthese cases.
We also insist that the annotators re-solve anaphoric dependencies when specifying val-ues to attributes, as shown in EDU (4) in Table 1.4 Dialogue act and resource predictionPredicting the executed trades from the dialoguesstarts with three sub-tasks: automatically identify-ing each EDU?s dialogue act; detecting the EDU?sresources; and specifying the attributes of those re-sources (i.e., Givable, Receivable, etc.
).4.1 Identifying dialogue actsAs is well established, one EDU?s dialogue actdepends on previous dialogue acts (Stolcke et al2000).
In our corpus, Accept or Reject frequentlyfollow Offer and Counteroffer.
Since labeling is se-quential, we use Conditional Random Fields (CRFs)to learn dialogue acts.
CRFs have been shown toyield better results in dialogue act classification ononline chat than HMM-SVN and Naive Bayes (Kimet al 2012).We use three types of features: lexical, syntacticand semantic.
And we exploit them as unigrams andbigrams: unigrams associate the value of the featurewith the current output class (level 0); bigrams takeaccount of the value of the feature associated witha combination of the current output class and pre-vious output class (level -1).
6 features were usedexclusively as unigrams: the EDU?s position in thedialogue, its first and last words, its subject lemma,a boolean feature to indicate if the current speaker isthe one that initiates the dialogue and the position ofthe speaker?s first turn in the dialogue.We have 15 unigram and bigram features (at lev-els 0 and -1), as well as templates that combinefeature values for the two levels.
These include14 boolean features that indicate if the EDU con-tains: bargaining verbs (e.g.
trade, offer), refer-ences to another player (e.g.
you), resource tokensas encoded in a task dedicated lexicon (e.g.
wheat,clay), quantifiers (e.g.
one, none), anaphoric pro-nouns, occurrences of ?for?
prepositional phrases(e.g.
wheat for clay), acceptance words (e.g.
OK),negation words, emoticons, opinion words (from(Benamara et al 2011)), words of politeness, ex-clamation marks, questions, and finally whether theEDU?s speaker has talked previously in the dialogue.359The last feature gives the EDU speaker lemma.
Inaddition, 3 unigram and bigram booleans indicatewhether the current EDU contains the most frequenttokens, couple of tokens and syntactic patterns in ourcorpus.
Finally, we use 2 composed bigram featuresthat encode whether the EDU contains an accep-tance or refusal word, given that the previous EDUis a question.To assign sequential tags of dialogue acts withina negotiation dialogue, we use the CRF++ tool(crfpp.googlecode.com).
Our data consists of2741 EDUs in 511 dialogues.
Each EDU is asso-ciated with a dialogue act resulting in 410 Offer,197 Counteroffer, 179 Accept, 398 Refusal and 1557Other.
We use 10-fold cross-validation to evalu-ate our model, computing precision, recall and F-score for each class and global accuracy from thetotal number of true positives, false positives, falsenegatives and true negatives obtained by summingover all fold decisions.
The results (in percent) aregiven in Table 2 (MaF is the average of F-scoresof all the classes).
Our model significantly out-performs the frequency-based baseline (MaF=14.5;Accuracy=56.8), with the best F-score achieved forOther.
The least good results are for the two leastfrequent classes in our data.
In addition to the fre-quency problem, the lower score for Counteroffer ismainly due to the model confusing it with Offer.
Er-rors in the Accept class were often due to misspellingor to chat style conversation; e.g., kk, yup.Dialogue act Precision Recall F-scoreOther 87.4 93.1 90.1Offer 80.0 81.0 80.5Counterof.
64.8 53.3 58.5Accept 65.1 53.1 58.5Refusal 81.7 73.9 77.6Macro-averaged F-score (MaF) 73.0Accuracy 83.0Table 2: Results for dialogue act classification.4.2 Finding resource text spansSince the resource vocabulary in The Settlers ofCatan is a closed set composed of words denotingspecific resources (e.g., clay, wood) and their syn-onyms (brick), we use a simple rule to detect them:a noun phrase (NP) is a resource text span if andonly if it contains a lemma from our resource lexi-con.
A closed set resource vocabulary is common tomany different types of negotiation dialogues.
Weused the Stanford parser (Klein and Manning, 2003)to obtain the NPs: there are 4361 NPs, where (by thegold standard annotations) 21% are resources and79% are not.
We obtain an F-score of 96.9% and ac-curacy of 97.9%, clearly beating both the frequencyand random baselines for this task.4.3 Recognizing the type of resourcesRecall that each resource within an EDU can be thevalue of four types of attributes: Givable, Receiv-able, Not Givable or Not Receivable (cf.
Section3.2).
We predict these attributes using CRFs with thefollowing features.
8 features are used as unigram atthe current and the previous EDU level: the speaker,the EDU?s subject, the dialogue act, and (if present)the lemma of a bargaining verb, and 4 boolean fea-tures indicate if the EDU contains an opinion word,a reference to another speaker, if the resource comesafter a ?for?
and if it contains a refusal word.
Thesefeatures also serve as bigrams at the current EDUlevel.
Additionally, we have a set of unigram andbigram boolean features that indicate if the currentEDU contains the most frequent verbs in the corpus.And finally, we use a feature that encodes the com-bination subject/bargaining verb in the current EDU.We used CRF++ to implement our classifier.
Ourcorpus data consists of 1077 Resources, split into510 Receivable, 432 Givable, 116 Not Givable and19 Not Receivable.
We use again 10-fold cross-validation to evaluate our model and compute theresults by summing over all fold decisions.
Wepresent them (in percent) in Table 3.
They beatthe frequency-based baseline (MaF=16.1; Accu-racy=47.4), although performance on the Not Re-ceivable class is poor probably due to its low fre-quency in the data.Ambiguities make this task challenging.
For in-stance, anyone wheat for clay?
can mean that thespeaker wants to receive wheat and give clay or theopposite, and resolving which meaning is intendedinvolves reasoning not only with the previous and/orthe following EDU, but also sometimes EDUs withlong distance attachments, which are not supportedby our classifier and require a full discourse parser.360Res.
type Precision Recall F-scoreReceivable 66.8 71.4 69.0Givable 62.6 59.7 61.1Not Giv.
88.1 89.7 88.9Not Rec.
0 0 0Macro-averaged F-score (MaF) 54.8Accuracy 67.4Table 3: Results for resource type classification.5 Predicting Players?
Strategic ActionsWe aim to capture the evolution of commitments tocertain preferences as the dialogue proceeds so asto predict the agents?
bargaining behavior.
In otherwords, we wish to predict which of the 61 possi-ble trade actions is executed at the end of each dia-logue.
The possible trades vary over which partnerthe player whose turn it is trades with (3 options in a4 player game), the resources exchanged (assumingeach partner gives one type of resource and receivesanother type yields 5?4 = 20 possibilities), or thereis no trade; i.e., (3 ?
20) + 1 = 61 possible actionsin the hypothesis space (we predict the types of re-sources that are exchanged, but not their quantity).We predict the executed action by identifying theequilibrium trade entailed by the model of the play-ers?
preferences, which in turn we construct dynam-ically from the output of the classifiers in Section 4.We use the attributes of resources in the EDUs (Giv-able, etc.)
to identify the preference that a speakerconveys in the EDU, and we use the dialogue acts(Offer, Accept, etc.)
to update a model of the pref-erences expressed so far in the dialogue with thisnew preference (see Section 5.2).
Our model ofpreferences consists of a set of partial CP-nets, onefor each player (see Section 5.1 for details).
Theresulting CP-nets are then used to infer the exe-cuted trading action (if any) automatically, via well-understood principles from game theory for identi-fying rational behavior (Bonzon, 2007).5.1 CP-NetsFollowing Cadilhac et al(2011), we use CP-nets(Boutilier et al 2004) to model preferences andtheir dependencies.
CP-nets are compatible with thekind of partial information about preferences that ut-terances reveal, and inference with CP-nets is com-putationally efficient.Just as Bayesian nets are a graphical model thatexploits probabilistic conditional independence toprovide a compact representation of a joint probabil-ity distribution (Pearl, 1988), CP-nets are a graphi-cal model that exploits conditional preferential in-dependence to provide a compact representation ofthe preference order over all outcomes.
The CP-net structures the decision maker?s preferences un-der a ceteris paribus assumption: outcomes are com-pared, other things being equal.More formally, let V be a finite set of variableswhose combination of values determine all out-comes O.
Then a preference relation  over O isa reflexive and transitive binary relation with strictpreference  defined as: o  o?
and o?
6 o. Indif-ference, written o ?
o?, means o  o?
and o?
 o.Definition 1 defines conditional preference indepen-dence and Definition 2 defines CP-nets: the graphi-cal component G of a CP-net specifies for each vari-able X ?
V its parent variables Pa(X) that affectthe agent?s preferences over the values of X , suchthatX is conditionally preferentially independent ofV \ ({X} ?
Pa(X)) given Pa(X).Definition 1 Let V be a set of variables, each vari-able Xi with a domain D(Xi).
Let {X,Y, Z} bea partition of V .
X is conditionally preferentiallyindependent of Y givenZ if and only if ?z ?
D(Z),?x1, x2 ?
D(X) and ?y1, y2 ?
D(Y ), x1y1z x2y1z iff x1y2z  x2y2z.Definition 2 NV = ?G, T ?
is a CP-net on variablesV , where G is a directed graph over V , and T is aset of Conditional Preference Tables (CPTs).
Thatis, T = {CPT(Xj): Xj ?
V }, where CPT(Xj)specifies for each combination p of values of the par-ent variables Pa(Xj) either p : xj  xj , p : xjxj or p : xj ?
xj where the ??
symbol sets the vari-able to false.We discuss below how a CP-net predicts rationalaction, but first we describe how CP-nets are con-structed from the dialogues.
In the Settlers cor-pus, preferences involve a quadruplet (o, a, <r,q>)where: o is the preference owner, a is the ad-dressee, r is the resource and q is its quantity.
Soeach variable in the CP-nets we construct is such aquadruplet, and for each variable the possibles val-ues are Givable (Giv), Not Givable (Giv), Receiv-361able (Rcv) and Not Receivable (Rcv).For example, the utterance Anyone want to giveme a wheat for a clay?
expresses two prefer-ences: one for receiving wheat, represented by thevariable Pw = (A,All,<wheat,1>); and given thispreference, another for giving clay, represented byPc = (A,All,<clay,1>) (where A is the name of thespeaker).
The corresponding CP-Net is Figure 1.PwPcCPT(Pw) = Rcv  RcvCPT(Pc) = Rcv Pw : Giv  GivFigure 1: An example CP-net5.2 Modeling players?
preferencesAs stated above, we first automatically acquire a CP-net from each EDU by using the EDU?s dialogue actand the attributes (Givable, etc.)
of its resources.We then apply the rules presented in (Cadilhac et al2011) to dynamically construct a preference modelof the dialogue overall: this uses an equivalencebetween their coherence relations and our dialogueacts.
Our CP-nets reasoning model handles uncer-tain information and noise because it use as inputonly the outputs of the statistical models describedin Section 4, and these prior models handle uncer-tain information and noise.
The symbolic rules forconstructing CP-nets have complete coverage overany possible combination of classes that are outputby the statistical models, and so they are robust.
Wegive our rules below where pii stands for EDU ID i.Offers.
Because an Offer may specify or refine anexisting preference or offer, we must model how thepreferences expressed in an EDU that?s an Offer up-dates the prior declared preferences.
So, while ourannotations treat Offer as a property of EDUs, wetreat them here as binary relations: Offer(pi1, pi2),where the second term, pi2, is the actual EDU whosedialogue act is Offer and pi1 is the set of EDUs oc-curring between pi2 and the last EDU uttered bythe same speaker.
Offers then have a similar effecton the CP-net as the coherence relation Elaborationpresented in (Cadilhac et al 2011).
That is, to auto-matically update the CP-net constructed so far witha current EDU that?s an Offer, the two step rule forOffer(pi1, pi2) is:1. to update the speaker?s CP-net according to thepreferences expressed in pi1, and2.
if pi2 expresses preferences, to enrich the CP-net with these new preferences so that eachvariable in pi2 depends on each variable in pi1.Counteroffers.
They specify or modify the termsof a previous Offer or Counteroffer.
Their purposeis to give new information to refine the negotiation.Like Offers they must also receive a contextually de-pendent interpretation.
The rule is quite similar tothat for Offer; however, Counteroffer can modify orcorrect elements in a previously introduced offer.
Sofor Counteroffer(pi1, pi2), the rule is :1. to partially update the speaker?s CP-net accord-ing to the preferences expressed in pi1 which donot have the same resource type (Givable, Re-ceivable) than the ones in pi2.2.
same as step 2 Offer rule.Accepts and Refusals.
As they are answers toOffers and Counteroffers, they behave like questionanswer pairs (QAPs) presented in (Cadilhac et al2011).
Because we are not doing full discourse pars-ing, we once again approximate its effects by mak-ing Accepts and Refusals respond to the set of EDUsbetween the current EDU and the speaker?s last turn.Accepts are positive responses to Offers or Coun-teroffers and are de facto similar to QAP(pi1, pi2)where pi2 is Yes.
Thus, the rule is, as for Offer, toupdate and enrich the CP-net.Refusals are instead negative responses and be-have like QAP(pi1, pi2) where pi2 is No.
ForRefusal(pi1, pi2), there is no update of the prefer-ences expressed in pi1.
Instead, we enrich the CP-netwith the Non Givable and Non Receivable informa-tion obtained from the negation of the preferencesexpressed in the previous Offer or Counteroffer.
Wethen enrich the CP-net based on any new preferencesexpressed in pi2.
If there is a conflict between thevalue of a variable to be updated and the currentvalue in the CP-net, we apply the Correction rule:all occurrences of the old value are replaced by thenew value in pi2.Other.
This category pertains to content that doesnot directly relate to trading in the game, and so wechoose to ignore resources expressed in the EDUswith this dialogue act.At the end of the negotiation dialogue, to predictexactly what trade is executed (if any), the method362checks if there are complete and reciprocal prefer-ences expressed in the CP-nets that respectively rep-resent the declared preferences of two agents A andB.
This is done in two steps.
First, we use the logicof CP-nets to determine each agent?s best outcomebestOA and bestOB from their respective CP-nets(we?ll discuss how shortly).
Secondly, we comparethese best outcomes: if they correspond to the sametrade, we predict that this trade was executed; ifnot, we predict no trade is executed.
Specifically,bestOA (resp.
bestOB) corresponds to a prefer-ence for receiving a resource r1 from an agent B(or from all the agents indifferently) and for givinga resource r2 to this (or these) agent(s).
We predictthat A gives B r2 and B gives A r1 if and only if:bestOA = Rcv(A, B, r1) ?
Giv(A, B, r2) andbestOB = Rcv(B, A, r2) ?Giv(B, A, r1).The first step?computing each agent?s best out-come from his CP-net?can be found in linear timeusing the forward sweep algorithm (Boutilier et al2004): sweep through the CP-net?s graph from top tobottom, instantiating each variable with its preferredvalue, given the values that are (already) assigned toits parents.
This algorithm is sound with respect tothe semantics of CP-nets.Example.
We apply this method for constructingCP-nets and determining the executed trade to thenegotiation dialogue presented in Table 1.pi1 The EDU is an Offer, so Rainbow?s CP-net isupdated according to pi1?s content.CPT(R,All,<clay,?>) = Rcv  Rcvpi2 It?s a Refusal, so we update inca?s CP-net withthe negation of the preferences expressed in Rain-bow?s offer.CPT(I,R,<clay,?>) = Giv  Givpi3 Idem for ariachiba.CPT(A,R,<clay,?>) = Giv  Givpi4 Idem for Kittles where the preferences ex-pressed in this EDU are redundant with the negationof the preferences in Rainbow?s offer.CPT(K,R,<clay,?>) = Giv  Givpi5 It?s an Offer, so Rainbow?s CP-net is first up-dated according to previous EDUs (pi2 to pi4 until hislast speaking), then according to the content of pi5.CPT(R,All,<clay,?>) = Rcv  Rcv (inactive)CPT(R,I,<clay,?>) = Rcv  RcvCPT(R,A,<clay,?>) = Rcv  RcvCPT(R,K,<clay,?>) = Rcv  RcvCPT(R,All,<ore,?>) = Rcv(R,I,<clay,?>) ?
Rcv(R,A,<clay,?>) ?
Rcv(R,K,<clay,?>): Rcv  RcvThe introduction of the preference to receive oreconflicts with the prior one for receiving clay.
Sothe method adds to the associated CPT the label ?in-active?
to indicate that this is older and should beignored if the preference about ore is satisfied.pi6 The EDU is an Accept, so Kittles?s CP-net isupdated according to previous EDUs (only pi5).1CPT(K,R,<ore,?>) = Giv(K,R,<clay,?>): Giv  Givpi7 The EDU is a Counteroffer.
Since she is thelast speaker, her CP-net gets updated only accordingto the content of the current EDU, to obtain:CPT(K,R,<ore,?>) = Giv(K,R,<clay,?>): Giv  GivCPT(K,R,<wheat,?>) = Giv(K,R,<clay,?>) ?Giv(K,R, <ore,?>) : Rcv  Rcvpi8 The EDU is an Accept, so Rainbow?s CP-netis updated according to previous EDUs (pi6 and pi7):CPT(R,K,<ore,?>) = Rcv(R,I,<clay,?>) ?
Rcv(R,A,<clay,?>) ?
Rcv(R,K,<clay,?>) : Rcv  RcvCPT(R,K,<wheat,?>) =Rcv(R,I,<clay,?>) ?Rcv(R,A,<clay,?>) ?
Rcv(R,K,<clay,?>) ?
Rcv(R,K,<ore,?>) :Giv  Givpi9 It?s an Accept with nothing new to update.At the end of the dialogue, these agents?
CP-nets(correctly) predict that Kittles gave ore to Rainbowin exchange for wheat.5.3 Evaluation and resultsWe compare our model against four baselines.
Sincenone of these baselines support reasoning aboutequilibrium moves, they all rely on the presence ofan Accept act to predict there was a trade, and itsabsence to predict there wasn?t.
The baselines dif-fer, however, in how they identify the trading part-ners and resources in an executed trade.
The firstbaseline predicts a trade according to the first Of-fer and the last person to Accept, and if the Offerdoesn?t specify one of the resources then it is chosenrandomly (similar random choices complete all par-tial predictions in all the models we consider here):e.g., for Table 1 this would predict that Kittles gaveclay to Rainbow (which is incorrect) in exchange for1Due to lack of space, in the following CP-nets, we do notcopy the inactive CPTs and CPTs about Not Givable or Not Re-ceivable resources.363something that?s chosen randomly (which will prob-ably be incorrect).
The second baseline uses thelast Offer and the last person to Accept: e.g., forTable 1 this predicts that Kittles gave ore to Rain-bow (correct) for something random (probably in-correct).
The third baseline uses the last Offer orCounteroffer, whichever is latest, and the last per-son to Accept: e.g., for Table 1 this correctly pre-dicts that Kittles gave ore to Rainbow in exchangefor wheat.
And the fourth baseline, uses defaultunification between the prior Offers or Counterof-fers and the current one to resolve any of the cur-rent offer?s elided parts and to replace specific val-ues in prior offers with conflicting specific values inthe current offer (Ehlen and Johnston, 2013).
Onethen takes the executed trade to be the result of thisunification process at the point where the last Acceptoccurs.
This makes the same predictions as the thirdbaseline for Table 1, but outperforms it in the corpusexample (1) by predicting the correct and completetrade (i.e., Rainbow gave Kittles sheep for wheat,rather than for something random):(1) Rainbow: i need clay ore or wheatKittles: i got wheatRainbow: i cn giv sheepKittles: okWe performed the evaluation on the data pre-sented in Sections 3 and 4: 254 dialogues in totalsince we ignore dialogues that contain only Others.90 of these dialogues end with a trade being exe-cuted and 2 of them end with 2 trades.
A randombaseline would give 1.6% accuracy (given the 61possible trading actions) and a frequency baseline(always choose no trade) gives 64.1% accuracy.Table 4 presents the accuracy figures for all themodels when calculated from the gold standard la-bels rather than the classifiers?
predicted labels fromSection 4, so that we can compare the models inisolation of the classifiers?
errors.
McNemar?s testshows that our model significantly outperforms allthe baselines (p < 0.05).
A predicted trade counts ascorrect only if it specifies the right participants andthe correct type of resources offered and received(we ignore their quantity).
True Positives (TP) arethus examples where the model correctly predictsnot only that a trade happened, but also the correctpartners and resources; Wrong Positives (WP), onthe other hand, constitute a correct prediction thatthere was a trade but errors on the partners and/orresources involved (so WPs undermine accuracy).True Negatives (TN) are examples where the modelcorrectly predicts there was no trade (so TPs andTNs contribute to accuracy).
False Positives (FP)and False Negatives (FN) are respectively incorrectpredictions that there was a trade, or that there wasno trade.While Table 4 does not reflect this, the first threebaselines tend to predict incomplete informationabout the trade even when what they do predict iscorrect: that is, they predict the correct addresseeand the owner but resort to random choice for a re-source that?s missing from the Offer or Counterof-fer that predicts which trade occurred.
For the firstbaseline 34 examples are like this; for the secondand third baselines it?s 32.
In contrast, this prob-lem occurs only once with the fourth baseline, andall the trades predicted by our method are complete,making random choice unnecessary.
Moreover, thefirst three baselines often make incorrect predictionsabout the addressee or resources exchanged becausein contrast to our model and the fourth baseline, theydon?t track how potential trades evolve through a se-quence of offers and counteroffers.Even though the fourth baseline, which uses de-fault unification to track the content of the currentoffer, is smart and gives good results, it has statis-tically significant lower accuracy than our model.One major problem with the fourth baseline is that,in contrast to our model, it does not track eachplayer?s attitude towards the current offer.
Instead,like all our baselines, it relies on the presence of anAccept act to predict that there?s a trade.2 But sev-eral corpus examples are like (2), in which a tradeis executed but there?s no Accept act, thus yielding aFalse Negative (FN) for all four baselines:(2) Joel: anyone have sheep or wheatCardlinger: neither :(Joel: will give clay or oreEuan: not just nowJon: got a wheat for a clay(Joel gives clay to Jon and receives wheat)2We tried a baseline that doesn?t rely on the presence of anAccept act, but rather predicts a trade whenever default unifica-tion yields a complete offer.
It performed worse than the fourthbaseline.364So overall, our analysis shows that using CP-netssignificantly outperforms all baselines that don?tmodel how preferences evolve in the dialogue, anderror analysis yields evidence that our model outper-forms the fourth baseline because our model sup-ports reasoning about player preferences, rationalbehavior and equilibrium strategies.1st baseline: first Offer/last AcceptTP FP FN TN WP Accuracy24 14 30 150 38 68.02nd baseline: last Offer/last AcceptTP FP FN TN WP Accuracy29 6 32 158 31 73.03rd baseline: last (Counter)Offer/last AcceptTP FP FN TN WP Accuracy39 4 23 160 30 77.74th baseline: default unificationTP FP FN TN WP Accuracy64 4 23 160 5 87.5Our methodTP FP FN TN WP Accuracy75 4 15 160 2 91.8Table 4: Results for trade prediction.
TP, FP, FN, TNand WP are the True and False Positives, False and TrueNegatives and Wrong Positives.Table 5 presents the results for the end to endevaluation, where trade predictions are made fromthe classifiers?
output from Section 4 rather than thegold standard labels.
As expected, performance de-creases due to the classifiers?
errors, mainly on thetype of resources (Givable, etc.).
But our methodstill significantly outperforms all the baselines withan accuracy of 73.4% when the baselines obtain val-ues between 60.9% and 68.4%.4th baseline: default unificationTP FP FN TN WP Accuracy23 12 37 152 32 68.4Our methodTP FP FN TN WP Accuracy34 10 43 154 15 73.4Table 5: Results for the end to end trade prediction.6 Related Work6.1 Dialogue act modelingMost work on dialogue act modeling focuses on spo-ken dialogue (Stolcke et al 2000; Ferna?ndez et al2005; Keizer et al 2002).
But live chats introducespecific complications (Kim et al 2012): ill-formeddata, abbreviations and acronyms, emotional indi-cators and entanglement (especially for multi-partychat).
Among related work in this emerging field,Joty et al(2011) use unsupervised learning to modeldialogue acts in Twitter, Ivanovic (2008) and Kim etal.
(2010) analyze one-to-one online chat in a cus-tomer service domain, and Wu et al(2002) and Kimet al(2012) predict dialogue acts in a multi-partysetting.
We used a similar classifier to predict dia-logue acts as the one reported in (Kim et al 2012)and evaluation yields similar results.This paper proposes an approach to dialogue actidentification in online chat that aims to predictstrategic actions like bargaining.
Compared to (Sid-ner, 1994) and DAMSL (Core and Allen, 1997), ourdomain level annotation is much more detailed: wenot only predict moves like Accept but also featureslike the Givable and Receivable resources.
Our gen-eral speech act typology of EDUs lacks intentionaldescriptions of speech acts, however.
This reflectsa conscious choice to specify the semantics of eachact purely by the public commitments made to offeror to receive goods.6.2 Preference extractionWhile preference extraction from non-linguistic ac-tions is well studied (Chen and Pu, 2004; Fu?rnkranzand Hu?llermeier, 2011), their extraction from spon-taneous conversation has received little attention.
Toour knowledge, the only existing work is (Asheret al 2010; Cadilhac et al 2011; Cadilhac et al2012) which we build on.
Cadilhac et al(2011)compute CP-nets from coherence relations, found inthe annotation of the Verbmobil corpus (Baldridgeand Lascarides, 2005).
Here we adapt their algo-rithm from coherence relations to unary dialogueacts.
Further, while they assume that preferences aregiven, here we apply versions of the NLP techniquesfrom Cadilhac et al2012) to estimate the prefer-ences of EDUs automatically.
And we go furtherthan any of these works by using the elicited pref-365erences to infer the domain-level actions that resultfrom information exchanged in the conversation.In this respect, our work relates to models forgrounding language, where semantic parsing tech-niques are used to automatically map linguistic in-structions to domain-level actions (Artzi and Zettle-moyer, 2013; Kim and Mooney, 2013).
Our do-main of application is more challenging, however:to our knowledge, this is the first attempt to mapnon-cooperative dialogues into predictions aboutdomain-level actions.
We can tackle these strategicscenarios because we exploit a logic of preferencesas part of our model, yielding inferences about ratio-nal action even when agents?
preferences conflict.Compared to previous work, our task is new.
Ouraim is not to predict what dialogue act to performnext, but what non verbal action should be per-formed, mapping dialogue acts to non verbal ac-tions.
The difference between our work and otherwork on grounding is that we are grounding non-cooperative dialogue rather than instructions in a co-operative setting.
There is no prior work of whichwe?re aware that maps a non-cooperative dialogueinto a prediction about which joint non-verbal ac-tion the agents will do as a result of what they?velearned about their opponent through conversation.Furthermore, both the CP-net and the fourth base-line, whose accuracy is quite high (making it a hardbaseline to beat), use the dialogue history as they in-crementally build up the preference model.6.3 Predicting strategic actionsModeling player behavior in real-time strategygames is a growing research area in AI.
These mod-els can be used to identify common strategic states,discover new strategies as they emerge or predictan opponents future actions and so help players tooptimize their choices.
For example, Schadd etal.
(2007) develop a hierarchical opponent model inthe game Spring, Dereszynski et al(2011) reasonabout strategic behavior in StarCraft using hiddenMarkov models and Amato and Shani (2010) use re-inforcement learning to acquire a policy for switch-ing among high-level strategies in Civilization IV.In comparison, we propose a novel approach forpredicting strategic action based on the symbolicallyformalized preferences that each agent commits to inspontaneous conversation.
Our approach thus dealswith imperfect information by exploiting the agents?declared preferences.
By predicting what bargain (ifany) will take place, we are able to verify the cor-rectness of our preference descriptions.
Our task isa subtask of learning a strategy over an entire gamespace, but our approach yields good predictive re-sults on relatively little data?an advantage of ex-ploiting CP-nets and the symbolic rules that guidetheir evolution from observable evidence.7 ConclusionWe have proposed a linguistic approach to strategyprediction in spontaneous conversation, exploitingdialogue acts to build a partial model of the agents?declared preferences.
Our method tracks how pref-erences evolve during the dialogue, which we use toinfer their bargaining behavior, i.e.
what resources,if any, are exchanged, and by whom.We based our study on a corpus collected using anonline version of The Settlers of Catan.
Negotiationsin this game mirror complex real life negotiationsand provide a fruitful arena to study strategic con-versation.
Evaluation shows that our approach pro-vides more accurate and complete information abouttrades than baselines that don?t track how an offerevolves through the dialogue, and we also arguedthat game-theoretic reasoning about rational behav-ior has advantages over relying on the presence orabsence of an Accept act to make predictions.Our approach, however, does not exploit dis-course structure, which is needed to properly handlelong distance dependencies of offers on prior mate-rial.
We will exploit this in future work to improveour results.
We also plan to investigate other aspectsof strategic reasoning on a larger dataset.We have proposed a method that relies on a typol-ogy of dialogue acts that is domain sensitive.
How-ever, in other work we have shown how to adaptour algorithms to several domains (Cadilhac et al2012).
In future work, we plan to link our prefer-ence extraction algorithms to an automatically ac-quired discourse structure for a given text.
This willprovide a domain independent means for extractingpreferences from dialogue.AcknowledgmentsThis work is supported by ERC grant 269427 STAC.366ReferencesStergos Afantenos, Nicholas Asher, Farah Benamara,Ana?
?s Cadilhac, Ce?dric De?gremont, Pascal Denis,Markus Guhe, Simon Keizer, Alex Lascarides, OliverLemon, Philippe Muller, Soumya Paul, Verena Rieser,and Laure Vieu.
2012.
Developing a corpus of strate-gic conversation in the settlers of catan.
In Pro-ceedings of the 1st Workshop on Games and NLP(GAMNLP-12).Christopher Amato and Guy Shani.
2010.
High-level reinforcement learning in strategy games.
InProceedings of the 9th International Conference onAutonomous Agents and Multiagent Systems (AA-MAS?10), pages 75?82.Yoav Artzi and Luke Zettlemoyer.
2013.
Weakly su-pervised learning of semantic parsers for mapping in-structions to actions.
Transactions of the Associationfor Computational Linguistics, 1:49?62.Nicholas Asher, Elise Bonzon, and Alex Lascarides.2010.
Extracting and modelling preferences from dia-logue.
In IPMU, pages 542?553.Jason Baldridge and Alex Lascarides.
2005.
Annotatingdiscourse structures for robust semantic interpretation.In Proceedings of the 6th IWCS.Farah Benamara, Baptiste Chardon, Yannick Mathieu,and Vladimir Popescu.
2011.
Towards context-basedsubjectivity analysis.
In Proceedings of 5th Interna-tional Joint Conference on Natural Language Process-ing, pages 1180?1188, Chiang Mai, Thailand.Elise Bonzon.
2007.
Mode?lisation des interactions en-tre agents rationnels : les jeux boole?ens.
PhD thesis,Universite?
Paul Sabatier, Toulouse.Craig Boutilier, Craig Brafman, Carmel Domshlak, Hol-ger H. Hoos, and David Poole.
2004.
Cp-nets: A toolfor representing and reasoning with conditional ceterisparibus preference statements.
Journal of Artificial In-telligence Research, 21:135?191.Ana?
?s Cadilhac, Nicholas Asher, Farah Benamara, andAlex Lascarides.
2011.
Commitments to preferencesin dialogue.
In Proceedings of SIGDIAL, pages 204?215.
ACL.Ana?
?s Cadilhac, Nicholas Asher, Farah Benamara,Vladimir Popescu, and Mohamadou Seck.
2012.
Pref-erence extraction from negotiation dialogues.
In Eu-ropean Conference on Artificial Intelligence (ECAI),pages 211?216.
IOS Press.Li Chen and Pearl Pu.
2004.
Survey of preference elici-tation methods.
Technical report.Mark G. Core and James F. Allen.
1997.
Coding di-alogs with the DAMSL annotation scheme.
In Work-ing Notes of the AAAI Fall Symposium on Communica-tive Action in Humans and Machines.Ethan W. Dereszynski, Jesse Hostetler, Alan Fern,Thomas G. Dietterich, Thao-Trang Hoang, and MarkUdarbe.
2011.
Learning probabilistic behavior mod-els in real-time strategy games.
In AIIDE.Patrick Ehlen and Michael Johnston.
2013.
A multi-modal dialogue interface for mobile local search.
InIUI Companion, pages 63?64.Raquel Ferna?ndez, Jonathan Ginzburg, and Shalom Lap-pin.
2005.
Using machine learning for non-sententialutterance classification.
In Proceedings of the 6th SIG-dial Workshop on Discourse and Dialogue, pages 77?86.Johannes Fu?rnkranz and Eyke Hu?llermeier, editors.2011.
Preference Learning.
Springer.Edward Ivanovic.
2008.
Automatic instant messagingdialogue using statistical models and dialogue acts.
InMasters thesis, The University of Melbourne.Shafiq R. Joty, Giuseppe Carenini, and Chin-Yew Lin.2011.
Unsupervised modeling of dialog acts in asyn-chronous conversations.
In Proceedings of the 22ndInternational Joint Conference on Artificial Intelli-gence, pages 1807?1813.Simon Keizer, Rieks op den Akker, and Anton Nijholt.2002.
Dialogue act recognition with bayesian net-works for dutch dialogues.
In Proceedings of the 3rdSIGdial Workshop on Discourse and Dialogue, pages88?94.
Association for Computational Linguistics.Joohyun Kim and Raymond J. Mooney.
2013.
Adaptingdiscriminative reranking to grounded language learn-ing.
In Proceedings of the 51st Annual Meeting ofthe Association for Computational Linguistics (ACL-2013), Sofia, Bulgaria.Su Nam Kim, Lawrence Cavedon, and Timothy Baldwin.2010.
Classifying dialogue acts in 1-to-1 live chats.In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, pages 862?871.Su Nam Kim, Lawrence Cavedon, and Timothy Bald-win.
2012.
Classifying dialogue acts in multi-partylive chats.
In 26th Pacific Asia Conference on Lan-guage,Information and Computation, pages 463?472.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stMeeting of the Association for Computational Linguis-tics, pages 423?430.Martin Osborne and Ariel Rubinstein.
1994.
A Course inGame Theory.
MIT Press.Judea Pearl.
1988.
Probabilistic Reasoning in Intelli-gent Systems: Networks of Plausible Inference.
Mor-gan Kauffmann.Leonard Savage.
1954.
The Foundations of Statistics.John Wiley.367Frederik Schadd, Sander Bakkes, and Pieter Spronck.2007.
Opponent modeling in real-time strategy games.In Games and Simulation GAMEON, pages 61?68.Yoav Shoham and Kevin Leyton-Brown.
2009.
Multia-gent Systems: Algorithmic, Game-Theoretic and Logi-cal Foundations.
Cambridge University Press.Candace Sidner.
1994.
An artificial discourse languagefor collaborative negotiation.
In AAAI, volume 1,pages 814?819.
MIT Press, Cambridge.Andreas Stolcke, Klaus Ries, Noah Coccaro, ElizabethShriberg, Rebecca Bates, Daniel Jurafsky, Paul Tay-lor, Rachel Martin, Carol V. Ess-dykema, and MarieMeteer.
2000.
Dialogue act modeling for automatictagging and recognition of conversational speech.
InComputational Linguistics, pages 26:339?373.Tianhao Wu, Faisal M. Khan, Todd A. Fisher, Lori A.Shuler, and William M. Pottenger.
2002.
Postingact tagging using transformation-based learning.
InFoundations of Data Mining and knowledge Discov-ery, pages 319?331.
Springer.368
