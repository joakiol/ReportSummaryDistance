Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 329?334,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsTypes of Common-Sense KnowledgeNeeded for Recognizing Textual EntailmentPeter LoBue and Alexander YatesTemple UniversityBroad St. and Montgomery Ave.Philadelphia, PA 19130{peter.lobue,yates}@temple.eduAbstractUnderstanding language requires both linguis-tic knowledge and knowledge about how theworld works, also known as common-senseknowledge.
We attempt to characterize thekinds of common-sense knowledge most ofteninvolved in recognizing textual entailments.We identify 20 categories of common-senseknowledge that are prevalent in textual entail-ment, many of which have received scarce at-tention from researchers building collectionsof knowledge.1 IntroductionIt is generally accepted that knowledge about howthe world works, or common-sense knowledge, isvital for natural language understanding.
Thereis, however, much less agreement or understandingabout how to define common-sense knowledge, andwhat its components are (Feldman, 2002).
Existinglarge-scale knowledge repositories, like Cyc (Guhaand Lenat, 1990), OpenMind (Stork, 1999), andFreebase1, have steadily gathered together impres-sive collections of common-sense knowledge, butno one yet believes that this job is done.
Other da-tabases focus on exhaustively cataloging a specifickind of knowledge ?
e.g., synonymy and hyper-nymy in WordNet (Fellbaum, 1998).
Likewise, mostknowledge extraction systems focus on extractingone specific kind of knowledge from text, often fac-tual relationships (Banko et al, 2007; Suchanek etal., 2007; Wu and Weld, 2007), although other spe-cialized extraction techniques exist as well.1http://www.freebase.com/If we continue to build knowledge collections fo-cused on specific types, will we collect a sufficientstore of common sense knowledge for understand-ing language?
What kinds of knowledge might lieoutside the collections that the community has fo-cused on building?
We have undertaken an empir-ical study of a natural language understanding taskin order to help answer these questions.
We focuson the Recognizing Textual Entailment (RTE) task(Dagan et al, 2006), which is the task of recogniz-ing whether the meaning of one text, called the Hy-pothesis (H), can be inferred from another, calledthe Text (T).
With the help of five annotators, wehave investigated the RTE-5 corpus to determine thetypes of knowledge involved in human judgments ofRTE.
We found 20 distinct categories of common-sense knowledge that featured prominently in RTE,besides linguistic knowledge, hyponymy, and syn-onymy.
Inter-annotator agreement statistics indicatethat these categories are well-defined.
Many of thecategories fall outside of the realm of all but the mostgeneral knowledge bases, like Cyc, and differ fromthe standard relational knowledge that most auto-mated knowledge extraction techniques try to find.The next section outlines the methodology of ourempirical investigation.
Section 3 presents the cate-gories of world knowledge that we found were mostprominent in the data.
Section 4 discusses empiricalresults of our survey.2 MethodologyWe follow the methodology outlined in Sammons etal.
(2010), but unlike theirs and other previous stud-ies (Clark et al, 2007), we concentrate on the world329#56 - ENTAILMENTT: (CNN) Nadya Suleman, the Southern Cali-fornia woman who gave birth to octuplets in Jan-uary, [...] She now has four of the octuplets athome, along with her six other children.1) ?octuplets?
are 8 children (definitional)2) 8 + 6 = 14 children (arithmetic)H: Nadya Suleman has 14 children.Figure 1: An example RTE label, Text, a condensed?proof?
(with knowledge categories for the back-ground knowledge) and Hypothesis.knowledge rather than linguistic knowledge requiredfor RTE.
First, we manually selected a set of RTEdata that could not be solved using linguistic knowl-edge and WordNet alne.
We then sketched step-by-step inferences needed to show ENTAILMENTor CONTRADICTION of the hypothesis.
We iden-tified prominent categories of world knowledge in-volved in these inferences, and asked five annotatorsto label the knowledge with the different categories.We judge the well-definedness of the categories byinter-annotator agreement, and their relative impor-tance according to frequency in the data.To select an appropriate subset of the RTE data,we discarded RTE pairs labeled as UNKNOWN.We also discarded RTE pairs with ENTAILMENTand CONTRADICTION labels, if the decision re-lies mostly or entirely on a combination of linguisticknowledge, coreference decisions, synonymy, andhypernymy.
These phenomena are well-known tobe important to language understanding and RTE(Mirkin et al, 2009; Roth and Sammons, 2007).Many synonymy and hypernymy databases alreadyexist, and although coreference decisions may them-selves depend on world knowledge, it is difficult toseparate the contribution of world knowledge fromthe contribution of linguistic cues for coreference.Some sample phenomena that we explicitly choseto disregard include: knowledge of syntactic vari-ations, verb tenses, apposition, and abbreviations.From the 600 T and H pairs in RTE-5, we selected108 that did not depend only on these phenomena.For each of the 108 pairs in our data, we createdproofs, or a step-by-step sketch of the inferences thatlead to a decision about entailment of the hypothesis.Figure 1 shows a sample RTE pair and (condensed)proof.
Each line in the proof indicates either a newpiece of background knowledge brought to bear, ora modus ponens inference from the information inthe text or previous lines of the proof.
This labor-intensive process was conducted by one author overmore than three months.
Note that the proofs maynot be the only way of reasoning from the text to anentailment decision about the hypothesis, and thatalternative proofs might require different kinds ofcommon-sense knowledge.
This caveat should bekept in mind when interpreting the results, but webelieve that by aggregating over many proofs, wecan counter this effect.We created 20 categories to classify the 221 di-verse statements of world knowledge in our proofs.These categories are described in the next section.2In some cases, categories overlap (e.g., ?Canberra ispart of Australia?
could be in the Geography cate-gory or the part of category).
In cases where weforesaw the overlaps, we manually specified whichcategory should take precedence; in the above exam-ple, we gave precedence to the Geography category,so that statements of this kind would all be includedunder Geography.
This approach has the drawbackof biasing somewhat the frequencies in our data settowards the categories that take precedence.
How-ever, this simplification significantly reduces the an-notation effort of our survey participants, who al-ready face a complicated set of decisions.We evaluate our categorization to determine howwell-defined and understandable the categories are.We conducted a survey of five undergraduate stu-dents, who were all native English speakers but oth-erwise unfamiliar with NLP.
The 20 categories wereexplained using fabricated examples (not part of thesurvey data).
Annotators kept these fabricated ex-amples as references during the survey.
Each anno-tator labeled each of the pieces of world knowledgefrom the proofs using one of the 20 categories.
Fromthis data we calculate Fleiss?s ?
for inter-annotatoragreement3 in order to measure how well-definedthe categories are.
We compute ?
once over all ques-2The RTE pairs, proofs, and category judgments from ourstudy are available athttp://www.cis.temple.edu/?yates/data/rte-study-data.zip3Fleiss?s ?
handles more than two annotators, unlike themore familiar Cohen?s ?.330tions and all categories.
Separately, we also compute?
once for each category C, by treating all annota-tions for categories C ?
6= C as the same.3 Categories of KnowledgeBy manual inspection, we arrived at the following20 prominent categories of world knowledge in oursubset of the RTE-5 data.
For each category, we givea brief definition and example, along with the ID ofan RTE pair whose proof includes the example.
Ourcategories can be loosely organized into form-basedcategories and content-based categories.
Note that,as with most common-sense knowledge, our exam-ples are intended as rules that are usually or typicallytrue, rather than categorically or universally true.3.1 Form-based CategoriesThe following categories are defined by how theknowledge can be described in a representation lan-guage, such as logic.1.
Cause and Effect: Statements in this category re-quire that a predicate p holds true after an event oraction A.#542: Once a person is welcomed into an organiza-tion, they belong to that organization.2.
Preconditions: For a given action or event A attime t, a precondition p is a predicate that must holdtrue of the world before time t, in order for A to havetaken place.#372: To become a naturalized citizen of a place,one must not have been born there.3.
Simultaneous Conditions: Knowledge in this cat-egory indicates that a predicate p must hold true atthe same time as an event or second predicate p?.#240: When a person is an employee of an organi-zation, that organization pays his or her salary.4.
Argument Types: Knowledge in this categoryspecifies the types or selectional preferences for ar-guments to a relationship.#311: The type of thing that adopts children is thetype person.5.
Prominent Relationship: Texts often specify thatthere exists some relationship between two entities,without specifying which relationship.
Knowledgein this category specifies which relationship is mostlikely, given the types of the entities involved.#42: If a painter is related to a painting somehow(e.g., ?da Vinci?s Mona Lisa?
), the painter mostlikely painted the painting.6.
Definition: Any explanation of a word or phrase.#163: A ?seat?
is an object which holds one person.7.
Functionality: This category lists relation-ships R which are functional; i.e., ?x,y,y?R(x, y) ?R(x, y?)
?
y = y?.#493: fatherOf is functional ?
a person can haveonly one father.8.
Mutual Exclusivity: Related to functionality, mu-tual exclusivity knowledge indicates types of thingsthat do not participate in the same relationship.#229: Government and media sectors usually do notemploy the same person at the same time.9.
Transitivity: If we know that R is transitive, andthat R(a, b) and R(b, c) are true, we can infer thatR(a, c) is true.#499: The supports relation is transitive.
Thus, be-cause Putin supports the United Russia party, andthe United Russia party supports Medvedev, we caninfer that Putin supports Medvedev.3.2 Content-based CategoriesThe following categories are defined by the content,topic, or domain of the knowledge in them.10.
Arithmetic: This includes addition and subtrac-tion, as well as comparisons and rounding.#609: 115 passengers + 6 crew = 121 people11.
Geography: This includes knowledge such as?Australia is a place,?
?Sydney is in Australia,?
and?Canberra is the capital of Australia.?12.
Public Entities: This category is for well-knownproperties of highly-recognizable named-entities.#142: Berlusconi is prime minister of Italy.13.
Cultural/Situational: This category includesknowledge of or shared by a particular culture.#207: A ?half-hour drive?
is ?near.?14.
is member of: Statements of this category indi-cate that an entity belongs to a larger organization.#374: A minister is part of the government.15.
has parts: This category expresses what compo-nents an object or situation is comprised of.#463: Forests have trees.16.
Support/Opposition: This includes knowledgeof the kinds of actions or relationships toward X thatindicate positive or negative feeling toward X .#357: P founds X ?
P supports X33117.
Accountability: This includes any knowledgethat is helpful for determining who or what is re-sponsible for an action or event.#158: A nation?s military is responsible for that na-tion?s bombings.18.
Synecdoche: Synecdoche is knowledge that aperson or thing can represent or speak for an organi-zation or structure he or she is a part of.#410: The president of Russia represents Russia.3.3 Miscellaneous Categories19.
Probabilistic Dependency: Multiple phrases inthe text may contribute to the hypothesis being moreor less likely to be true, although each phrase on itsown might not be sufficient to support the hypothe-sis.
Knowledge in this category indicates that theseseparate pieces of evidence can combine in a proba-bilistic, noisy-or fashion to increase confidence in aparticular inference.#437: Stocks on the ?Nikkei 225?
exchange andToyota?s stock both fell, which independently sug-gest that Japan?s economy might be struggling,but in combination they are stronger evidence thatJapan?s economy is floundering.20.
Omniscience: Certain RTE judgments are onlypossible if we assume that the text includes all in-formation pertinent to the story, so that we may dis-credit statements that were not mentioned.#208: T states that ?Fitzpatrick pleaded guilty tofraud and making a false report.?
H, which is markedas a CONTRADICTION, states that ?Fitzpatrick isaccused of robbery.?
In order to prove the falsehoodof H, we had to assume that no charges were madeother than the ones described in T.4 Results and DiscussionOur headline result is that the above twenty cat-egories overall are well-defined, with a Fleiss?s ?score of 0.678, and that they cover the vast majorityof the world knowledge used in our proofs.
This hasimportant implications, as it suggests that concen-trating on collecting these kinds of world knowledgewill make a large difference to RTE, and hopefully tolanguage understanding in general.
Naturally, morestudies of this issue are warranted for validation.Many of the categories ?
has parts, member of,geography, cause and effect, public entities, andCategory Occurrences ?Functionality 19.2 (8.7%) 0.663Definitions 17.2 (7.8%) 0.633Preconditions 15.8 (7.1%) 0.775Cause and Effect 10.8 (4.9%) 0.591Prominent Relationship 8.4 (3.8%) 0.145Argument Types 6.8 (3.1%) 0.180Simultaneous Conditions 6.2 (2.8%) 0.203Mutual Exclusivity 6 (2.7%) 0.640Transitivity 3 (1.4%) 0.459Geography 36.4 (16.5%) 0.927Support/Opposition 14.6 (6.6%) 0.684Arithmetic 13.4 (6.1%) 0.968is member of 11.6 (5.2%) 0.663Synecdoche 9.8 (4.4%) 0.829has parts 8.8 (4.0%) 0.882Accountability 7.2 (3.3%) 0.799Cultural/Situational 4.6 (2.1%) 0.267Public Entities 3.2 (1.4%) 0.429Omniscience 7.2 (3.3%) 0.828Probabilistic Dependency 4.8 (2.2%) 0.297All 215 (97%) 0.678Table 1: Frequency and inter-annotator agreement foreach category of world knowledge in the survey.
Fre-quencies are averaged over the five annotators, and agree-ment is calculated using Fleiss?s ?.support/opposition ?
will be familiar to NLP re-searchers from resources like WordNet, gazetteers,and text mining projects for extracting causal knowl-edge, properties of named entities, and opinions.
Yetthese familiar categories make up only about 40%of the world knowledge used in our proofs.
Com-mon knowledge types, like definitional knowledge,arithmetic, and accountability, have for the most partbeen ignored by research on automated knowledgecollection.
Others have only earned very scarce andrecent attention, like preconditions (Sil et al, 2010)and functionality (Ritter et al, 2008).Several interesting form-based categories, in-cluding Prominent relationships, Argument Types,and Simultaneous Conditions, had quite low inter-annotator agreement.
We continue to believe thatthese are well-defined categories, and suspect that332further studies with better training of the annotatorswill support this.
One issue during annotation wasthat certain pieces of knowledge could be labeled asa content category or a form category, and instruc-tions may not have been clear enough on which isappropriate under these circumstances.
Neverthe-less, considering the number of annotators and theuneven distribution of data points across the cate-gories (both of which tend to decrease ?
), ?
scoresare overall quite high.In an effort to discover if some of the categoriesoverlap enough to justify combining them into a sin-gle category, we tried combining categories whichannotators frequently confused with one another.While we could not find any combination that sig-nificantly improved the overall ?
score, several com-binations provided minor improvements.
As an ex-ample of a merge that failed, we tried merging Ar-gument Types and Mutual Exclusivity, with the ideathat if a system knows about the selectional prefer-ences of different relationships, it should be able todeduce which relationships or types are mutually ex-clusive.
However, the ?
score for this combined cat-egory was 0.410, significantly below the ?
of 0.640for Mutual Exclusivity on its own.
One merge thatimproves ?
is a combination of Prominent Relation-ship with Argument Types (combined ?
of 0.250, ascompared with 0.145 for Prominent Relationship and0.180 for Argument Types).
However, we believethis is due to unclear wording in the proofs, ratherthan a real overlap between the two categories.
Forinstance, ?Painters paint paintings?
is an exampleof the Prominent Relationship category, and it looksvery similar to the Argument Types example, ?Peo-ple adopt children.?
The knowledge in the first caseis more properly described as, ?If there exists anunspecified relationship R between a painter and apainting, then R is the relationship ?painted?.?
Inthe second case, the knowledge is more properlydescribed as, ?If x participates in the relationship?adopts children?, then x is of type ?person?.?
Statedin this way, these kinds of knowledge look quite dif-ferent.
If one reads our proofs from start to finish,the flow of the argument indicates which of theseforms is intended, but for annotators quickly read-ing through the proofs, the two kinds of knowledgecan look superficially very similar, and the annota-tors can become confused.The best category combination that we discoveredis a combination of Functionality and Mutual Exclu-sivity (combined ?
of 0.784, compared with 0.663for Functionality and 0.640 for Mutual Exclusivity).This is a potentially valid alternative to our classi-fication of the knowledge.
Functional relationshipsR imply that if x and x?
have different values y andy?, then x and x?
must be distinct, or mutually exclu-sive.
We intended that Mutual Exclusivity apply tosets rather than individual items, but annotators ap-parently had trouble distinguishing between the twocategories, so in future we may wish to revise ourset of categories.
Further surveys would be requiredto validate this idea.The 20 categories of knowledge covered 215(97%) of the 221 statements of world knowledgein our proofs.
Of the remaining 6 statements, twowere from recognizable categories, like knowledgefor temporal reasoning (#355) and an application ofthe frame axiom (#265).
We left these out of the sur-vey to cut down on the number of categories that an-notators had to learn.
The remaining four statementswere difficult to categorize at all.
For instance,#177: ?Motorcycle manufacturers often sponsorteams in motorcycle sports.?
The other three of thesedifficult-to-categorize statements came from proofsfor #265, #336, and #432.
We suspect that if futurestudies analyze more data for common-sense knowl-edge types, more categories will emerge as impor-tant, and more facts that lie outside of recognizablecategories will also appear.
Fortunately, however, itappears that at least a very large fraction of common-sense knowledge can be captured by the sets of cate-gories we describe here.
Thus these categories serveto point out promising areas for further research incollecting common-sense knowledge.ReferencesM.
Banko, M. J. Cafarella, S. Soderland, M. Broadhead,and O. Etzioni.
2007.
Open information extractionfrom the web.
In IJCAI.Peter Clark, William R. Murray, John Thompson, PhilHarrison, Jerry Hobbs, and Christiane Fellbaum.2007.
On the role of lexical and world knowledge inrte3.
In Proceedings of the ACL-PASCAL Workshop onTextual Entailment and Paraphrasing, RTE ?07, pages54?59, Morristown, NJ, USA.
Association for Com-putational Linguistics.333I.
Dagan, O. Glickman, and B. Magnini.
2006.
The PAS-CAL Recognising Textual Entailment Challenge.
Lec-ture Notes in Computer Science, 3944:177?190.Richard Feldman.
2002.
Epistemology.
Prentice Hall.Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
Bradford Books.R.V.
Guha and D.B.
Lenat.
1990.
Cyc: a mid-term re-port.
AI Magazine, 11(3).V.
Vydiswaran M. Sammons and D. Roth.
2010.
Asknot what textual entailment can do for you...
In Proc.of the Annual Meeting of the Association of Computa-tional Linguistics (ACL), Uppsala, Sweden, 7.
Associ-ation for Computational Linguistics.Shachar Mirkin, Ido Dagan, and Eyal Shnarch.
2009.Evaluating the inferential utility of lexical-semantic re-sources.
In EACL.Alan Ritter, Doug Downey, Stephen Soderland, and OrenEtzioni.
2008.
It?s a contradiction ?
No, it?s not:A case study using functional relations.
In EmpiricalMethods in Natural Language Processing.Dan Roth and Mark Sammons.
2007.
Semantic and log-ical inference model for textual entailment.
In Pro-ceedings of ACL-WTEP Workshop.Avirup Sil, Fei Huang, and Alexander Yates.
2010.
Ex-tracting action and event semantics from web text.
InAAAI Fall Symposium on Common-Sense Knowledge(CSK).D.
G. Stork.
1999.
The OpenMind Initiative.
IEEE Ex-pert Systems and Their Applications, 14(3):19?20.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: A core of semantic knowledge.In Proceedings of the 16th International Conferenceon the World Wide Web (WWW).Fei Wu and Daniel S. Weld.
2007.
Automatically se-mantifying wikipedia.
In Sixteenth Conference on In-formation and Knowledge Management (CIKM-07).334
