Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 335?337,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsThe CODA System for Monologue-to-Dialogue GenerationSvetlana StoyanchevCentre for Research in ComputingThe Open UniversityWalton Hall, Milton Keynes, UKs.stoyanchev@open.ac.ukPaul PiwekCentre for Research in ComputingThe Open UniversityWalton Hall, Milton Keynes, UKp.piwek@open.ac.ukAbstractThis paper describes an implemented mono-lingual Text-to-Text generation system.
Thesystem takes monologue and transforms it totwo-participant dialogue.
The system usesmappings between discourse relations in textand dialogue acts in dialogue.
These map-pings are extracted from a parallel monologueand dialogue corpus.1 IntroductionThis paper describes the CODA system,1 a Text-to-Text generation system that converts text parsed withdiscourse relations (Mann and Thompson, 1988)into information-delivering dialogue between twocharacters.
By information-delivering dialogue, wemean dialogue (akin to that used by Plato) that isused primarily to convey information and possiblyalso to make an argument; this in contrast with dra-matic dialogue which focuses on character develop-ment and narrative.Several empirical studies show that deliveringinformation as dialogue, rather than monologue,can be particularly effective for education (Craiget al, 2000; Lee et al, 1998) and persuasion(Suzuki and Yamada, 2004).
Information-deliveringdialogue also lends itself well for presentationthrough computer-animated agents (Prendinger andIshizuka, 2004).1CODA stands for COherent Dialogue Automatically gen-erated from text (see http://computing.open.ac.uk/coda/).
TheCODA project is funded by the UK?s Engineering and PhysicalSciences Research Council under Grant EP/G020981/1.With most information locked up in text (books,newspapers, leaflets, etc.
), automatic generation ofdialogue from text in monologue makes it possibleto convert information into dialogue on demand.In contrast to previous Text-to-Dialogue sys-tems (Piwek et al, 2007), the CODA system is data-driven and modular.
The system is composed ofthree modules: Dialogue Modeller, Verbalizer, andDialogue Merger.The Dialogue modeller determines appropriatedialogue act sequences that can be used for con-verting a segment of input text containing a sin-gle discourse relation into dialogue.
The mod-ule is data-oriented in that the mappings it usesbetween discourse structure and dialogue act se-quences have been derived from the CODA paral-lel monologue/dialogue corpus (Stoyanchev and Pi-wek, 2010).The Verbalizer converts text segments togetherwith a specification of the target dialogue act typesinto dialogue utterances.The Dialogue modeller and verbaliser compo-nents overgenerate possible outputs for each dis-course relation in monologue.
The Dialogue Mergercomponent selects one of the proposed outputs foreach text segment of the input and merges them intoa single coherent dialogue.2 System DesignIn this section we describe the three components ofthe system: dialogue modeller, verbalizer, and dia-logue merger.Before we look at each of the modules, we, how-ever, first need to specify more precisely what the335Input MANNER-MEANS [In September,Ashland settled the long-simmeringdispute] [by agreeing to pay Iran$325 million.
]Dialogue 1.
(ComplexQ; Explain)Modeller 2.
(Explain; ComplexQ; Explain)3.
(Explain; YesNoQ; Explain)VerbalizerDA Seq1A: How did Ashland settle the long-simmering dispute in September?B: By agreeing to pay Iran $325million.VerbalizerDA Seq2A: In September, Ashland settledthe long-simmering dispute.B: How?A: By agreeing to pay Iran $325million.VerbalizerDA Seq3A: In September, Ashland settledthe long-simmering dispute.B: By agreeing to pay Iran $325million?A: Correct.DialogueMergerSelect one of the DA sequencesbased on overall dialogueTable 1: Example of the output from each componentinput for our system is.
The system expects text thathas already been annotated with a discourse struc-ture.
There have been recent encouraging advancesin the automatic parsing of discourse structure, e.g.,see duVerle and Prendinger (2009), but the state-of-the-art is not yet at a point where it provides suffi-ciently reliable inputs for our purposes.
To demon-strate the functionality of our system without relyingon still imperfect discourse parsing, we use the RST-parsed Wall Street Journal corpus as input (Carlsonet al, 2001).Throughout the remainder of this section, we usethe outputs for each of the modules in Table 1 as arunning example.2.1 Dialogue ModellerThe Dialogue Modeller component takes as input asnippet of monologue text annotated with discoursestructure.
For each input Discourse Relation struc-ture (DR), the dialogue modeller outputs a set of dia-logue act (DA) sequences appropriate for expressingthe same information, but now in dialogue form.The Dialogue modeller uses a configuration XMLfile to look up possible DA sequences for the inputDA sequenceYesNoQ; ExplainYesNoQ; Yes; ExplainExplain; ComplexQ; ExplainComplexQ; ExplainExplain; YesNoQ; Resp-Answer-YesExplain; ContradictFactoid-Info-Req;Factoid-Resp;ExplainExlain; Resp-Agree;ExplainTable 2: Dialogue act sequencesdiscourse structure.
In the current system configu-ration we extract these mappings from the CODAparallel corpus of professionally authored dialoguesand parallel monologues.
We use the eight most fre-quent DA sequences (see Table2) that occur on thedialogue side of discourse relations in the paralleldataset.
Each discourse relation is mapped to oneor more DA sequences with a score indicating fre-quency of this mapping in the CODA corpus.The dialogue modeller can be customised withmappings from other sources such as a different cor-pus, manually authored mappings or a mapping ar-rived at through experimental methods.The current version of the dialogue modeller sup-ports input with only one level of discourse structureannotation.
As a result, all input structures containparts made of two segments and one discourse rela-tion between these segments.
In the future work, weplan to implement a dialogue modeller that acceptsmore complex (nested) discourse structures.2.2 VerbalizerThe verbalizer is rule-based and has three types ofrules: discourse relation (DR)-specific, generic, andcanned.
All of the rules take as input a monologuesegment and a target dialogue act.
DR-specific rulesalso use the discourse relation and segment nuclear-ity of the input segment.2 The verbalization rules areordered according to their priority with DR-specificrules having a higher priority.Generic and DR-specific rules use the CMU ques-tion generation tool (Heilman and Smith, 2010) incombination with syntactic and lexical manipulationrules.
Canned text rules are used to generate An-swerYes, Agree and Clarify dialogue acts by proba-2Nucleus is the more salient segment in a relation.336bilistic selection from a set of utterances extractedfrom the CODA corpus.
For example, the Agreedialogue act is verbalized as one of the statements:I agree with you; I agree; I couldn?t agree more;I completely agree; Absolutely; Very true; Right;True.
Probabilistic selection from a list allows usto generate non-repetitive dialogues.
The system isextendible, such that new rules can be easily addedto the implementation.2.3 Dialogue MergerThe Dialogue Merger component takes as input ver-balized dialogue act sequences.
The tasks of the Di-alogue Merger include: 1) selecting the best ver-balized sequence and 2) assigning speaker roles(TEACHER or STUDENT) to dialogue turns.We aim to create diverse dialogues, in particular,by avoiding repetitive use of the same dialogue actsequences.
This is achieved as follows.
Selection ofDA sequence is incremental, considering one rela-tion at a time.
For each relation, the dialogue mergerselects a dialogue act sequence that has been suc-cessfully verbalized by the verbalizer and which, sofar, has been used the smallest number of times (outof all the sequences that have been used up to thispoint).Although in the original authored dialogues, bothTEACHER and STUDENT ask questions and give ex-planations, in our preliminary experiments observersmade negative comments about mixing initiative be-tween the STUDENT and the TEACHER in the gen-erated dialogues.
In the current version, the speakerroles are assigned based on the dialogue act.
Allquestions and clarification requests are assigned tothe STUDENT and other dialogue acts are assignedto the TEACHER.As an additional post-processing step, to main-tain perspective in the dialogue, we change pronounsin the dialogue turns.
The turns assigned to theTEACHER character remain unchanged.
The turnsassigned to the STUDENT character change the per-spective: non-possessive pronouns are inverted, e.g.you ?
I, we ?
us, my ?
your.3 Conclusions and Further WorkIn this paper, we described a Text-to-Dialogue gen-eration system that converts text annotated with dis-course relations into dialogue.
The system is modu-lar, data-driven, and takes advantage of state-of-the-art question generation tools.
Our evaluation of thedialogue modeller and verbalizer components de-scribed in (Piwek and Stoyanchev, 2011) shows thatboth accuracy and fluency of generated dialoguesare not worse than that of human-written dialogues.We plan to release the CODA Text-to-Dialoguesystem as open source code later this year.
The sys-tem can be used as a starting point for researchersinterested in evaluating NLP tools for question gen-eration, dialogue modelling and paraphrasing in adialogue generation task.ReferencesL.
Carlson, D. Marcu, and M. E. Okurowski.
2001.Building a discourse-tagged corpus in the frameworkof rhetorical structure theory.
In Proceedings of theSecond SIGdial Workshop on Discourse and Dialogue,SIGDIA.S.
Craig, B. Gholson, M. Ventura, A. Graesser, and theTutoring Research Group.
2000.
Overhearing dia-logues and monologues in virtual tutoring sessions.International Journal of Artificial Intelligence in Ed-ucation, 11:242?253.D.
duVerle and H. Prendinger.
2009.
A novel discourseparser based on support vector machines.
In Procs ofACL-IJCNLP), pages 665?673, Singapore, August.M.
Heilman and N. A. Smith.
2010.
Good question!statistical ranking for question generation.
In Proc.
ofNAACL/HLT, Los Angeles.J.
Lee, F. Dinneen, and J. McKendree.
1998.
Supportingstudent discussions: it isn?t just talk.
Education andInformation Technologies, 3:217?229.W.
C. Mann and S. A. Thompson.
1988.
Rhetoricalstructure theory: Toward a functional theory of textorganization.
Text, 8(3):243?281.P.
Piwek and S. Stoyanchev.
2011.
Data-orientedMonologue-to-Dialogue Generation.
In Procs of ACL.P.
Piwek, H. Hernault, H. Prendinger, and M. Ishizuka.2007.
T2D: Generating Dialogues between VirtualAgents Automatically from Text.
In Procs of IVA07,LNAI 4722, pages 161?174.
Springer Verlag.H.
Prendinger and M. Ishizuka, editors.
2004.
Life-LikeCharacters: Tools, Affective Functions, and Applica-tions.
Cognitive Technologies Series.
Springer, Berlin.S.
Stoyanchev and P. Piwek.
2010.
Constructing theCODA corpus.
In Procs of LREC, Malta.S.
V. Suzuki and S. Yamada.
2004.
Persuasion throughoverheard communication by life-like agents.
In Procsof the 2004 IEEE/WIC/ACM International Conferenceon Intelligent Agent Technology, Beijing.337
