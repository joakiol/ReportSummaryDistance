Improving Bitext Word Alignmentsvia Syntax-based Reordering of EnglishElliott Franco Dra?bek and David YarowskyDepartment of Computer ScienceJohns Hopkins UniversityBaltimore, MD 21218, USA{edrabek,yarowsky}@cs.jhu.eduAbstractWe present an improved method for automated wordalignment of parallel texts which takes advantageof knowledge of syntactic divergences, while avoid-ing the need for syntactic analysis of the less re-source rich language, and retaining the robustness ofsyntactically agnostic approaches such as the IBMword alignment models.
We achieve this by usingsimple, easily-elicited knowledge to produce syntax-based heuristics which transform the target lan-guage (e.g.
English) into a form more closely resem-bling the source language, and then by using stan-dard alignment methods to align the transformedbitext.
We present experimental results under vari-able resource conditions.
The method improvesword alignment performance for language pairs suchas English-Korean and English-Hindi, which exhibitlonger-distance syntactic divergences.1 IntroductionWord-level alignment is a key infrastructural tech-nology for multilingual processing.
It is crucial forthe development of translation models and transla-tion lexica (Tufis?, 2002; Melamed, 1998), as well asfor translingual projection (Yarowsky et al, 2001;Lopez et al, 2002).
It has increasingly attracted at-tention as a task worthy of study in its own right(Mihalcea and Pedersen, 2003; Och and Ney, 2000).Syntax-light alignment models such as the fiveIBM models (Brown et al, 1993) and their rela-tives have proved to be very successful and robustat producing word-level alignments, especially forclosely related languages with similar word orderand mostly local reorderings, which can be cap-tured via simple models of relative word distortion.However, these models have been less successful atmodeling syntactic distortions with longer distancemovement.
In contrast, more syntactically informedapproaches have been constrained by the often weaksyntactic correspondences typical of real-world par-allel texts, and by the difficulty of finding or induc-ing syntactic parsers for any but a few of the world?smost studied languages.Our approach uses simple, easily-elicited knowl-edge of divergences to produce heuristic syntax-based transformations from English to a form(English?)
more closely resembling the source lan-English TransformTracesRetraceSource| \|EnglishEnglish?Run GIZA++Source|/ |English?SourceLanguage-specificHeuristicsFigure 1: System Architectureguage, and then using standard alignment methodsto align the transformed version to the target lan-guage.
This approach retains the robustness of syn-tactically agnostic models, while taking advantageof syntactic knowledge.
Because the approach reliesonly on syntactic analysis of English, it can avoidthe difficulty of developing a full parser for a newlow-resource language.Our method is rapid and low cost.
It requiresonly coarse-grained knowledge of basic word order,knowledge which can be rapidly found in even thebriefest grammatical sketches.
Because basic wordorder changes very slowly with time, word order ofrelated languages tends to be very similar.
For ex-ample, even if we only know that a language is ofthe Northern-Indian/Sanskrit family, we can easilyguess with high confidence that it is systematicallyhead-final.
Because our method can be restrictedto only bi-text pre-processing and post-processing,it can be used as a wrapper around any existingword-alignment tool, without modification, to pro-vide improved performance by minimizing alignmentdistortion.2 Prior WorkThe 2003 HLT-NAACL Workshop on Building andUsing Parallel Texts (Mihalcea and Pedersen, 2003)reflected the increasing importance of the word-alignment task, and established standard perfor-mance measures and some benchmark tasks.There is prior work studying systematic cross-English:Hindi:use of plutonium is to manufacture nuclear weaponsplutoniyama kaa?sistemaalauseparamaanunuclearhathiyaara banaanemanufactureke lie hotaa haiistheNPNPPPSVPVPVPNPplutonium weapons toFigure 2: Original Hindi-English sentence pair with gold-standard word-alignments.English?
:Hindi: plutoniyamaplutoniumkaa?sistemaalauseparamaanunuclearhathiyaara banaane ke lie hotaa haiisplutonium of the use nuclear weapons manufacture to isSVPPPNP VPVPNP NPweapons manufacture toFigure 3: Transformed Hindi-English?
sentence pair with gold-standard word-alignments.
Rotated nodes aremarked with an arc.linguistic structural divergences, such as the DUSTersystem (Dorr et al, 2002).
While the focus on ma-jor classes of structural variation such as manner-of-motion verb-phrase transformations have facilitatedboth transfer and generation in machine translation,these divergences have not been integrated into asystem that produces automatic word alignmentsand have tended to focus on more local phrasal varia-tion rather than more comprehensive sentential syn-tactic reordering.Complementary prior work (e.g.
Wu, 1995) hasalso addressed syntactic transduction for bilingualparsing, translation, and word-alignment.
Much ofthis work depends on high-quality parsing of bothtarget and source sentences, which may be unavail-able for many ?lower density?
languages of interest.Tree-to-string models, such as (Yamada and Knight,2001) remove this dependency, and such models arewell suited for situations with large, cleanly trans-lated training corpora.
By contrast, our method re-tains the robustness of the underlying aligner to-wards loose translations, and can if necessary useknowledge of syntactic divergences even in the ab-sence of any training corpora whatsoever, using onlya translation lexicon.3 SystemFigure 1 shows the system architecture.
We startby running the Collins parser (Collins, 1999) on theEnglish side of both training and testing data, andapply our source-language-specific heuristics to theLanguage VP AP NPEnglish VO AO AN, NRHindi OV OA AN, RNKorean OV OA AN, RNChinese VO AOA AN, RNRomanian VO AO NA, NRTable 1: Basic word order for three major phrasetypes ?
VP: verb phrases with Verb and Object,AP: appositional (prepositional or postpositional)phrases with Apposition and Object, and NP: nounphrases withNoun andAdjective orRelative clause.Chinese has both prepositions and postpositions.resulting trees.
This yields English?
text, along withtraces recording correspondences between English?words and the English originals.
We use GIZA++(Och and Ney, 2000) to align the English?
with thesource language text, yielding alignments in termsof the English?.
Finally, we use the traces to mapthese alignments to the original English words.Figure 2 shows an illustrative Hindi-English sen-tence pair, with true word alignments, and parse-tree over the English sentence.
Although it is onlya short sentence, the large number of crossing align-ments clearly show the high-degree of reordering,and especially long-distance motion, caused by thesyntactic divergences between Hindi and English.Figure 3 shows the same sentence pair after En-glish has been transformed into English?
by our sys-tem.
Tree nodes whose children have been reordered20253035404550556065703  3.2  3.4  3.6  3.8  4  4.2  4.4  4.6  4.8F-measurelog(number of training sentences)E?
MethodDirectFigure 4: Hindi alignment performance05101520253  3.2  3.4  3.6  3.8  4  4.2  4.4F-measurelog(number of training sentences)E?
MethodDirectFigure 5: Korean alignment performanceare marked by a subtended arc.
Crossings have beeneliminated, and the alignment is now monotonic.Table 1 shows the basic word order of three majorphrase types for each of the languages we treated.
Ineach case, our heuristics transform the English treesto achieve these same word orders.
For the Chinesecase, we apply several more language-specific trans-formations.
Because Chinese has both prepositionsand postpositions, we retain the original prepositionand add an additional bracketing postposition.
Wealso move verb modifiers other than noun phrases tothe left of the head verb.4 ExperimentsFor each language we treated, we assembledsentence-aligned, tokenized training and test cor-pora, with hand-annotated gold-standard wordalignments for the latter1.
We did not apply anysort of morphological analysis beyond basic word to-kenization.
We measured system performance withwa eval align.pl, provided by Rada Mihalcea andTed Pedersen.Each training set provides the aligner with infor-mation about lexical affinities and reordering pat-terns.
For Hindi, Korean and Chinese, we also testedour system under the more difficult situation of hav-ing only a bilingual word list but no bitext available.This is a plausible low-resource language scenario253035404550553  3.5  4  4.5  5F-measurelog(number of training sentences)E?
MethodDirectFigure 6: Chinese alignment performance3540455055606570753  3.2  3.4  3.6  3.8  4  4.2  4.4  4.6F-measurelog(number of training sentences)E?
MethodDirectFigure 7: Romanian alignment performance# Train Direct English?Sents P R F P R FHindiDict only 16.4 13.8 15.0 18.5 15.6 17.01000 26.8 23.0 24.8 28.4 24.4 26.23162 35.7 31.6 33.5 38.4 33.5 35.810000 46.6 42.7 44.6 50.4 45.2 47.631622 60.1 56.0 58.0 63.6 58.5 61.063095 64.7 61.7 63.2 66.3 62.2 64.2KoreanDict only 26.6 12.3 16.9 27.5 12.9 17.61000 9.4 7.3 8.2 11.3 8.7 9.83162 13.2 10.2 11.5 16.0 12.4 14.010000 15.2 12.0 13.4 17.0 13.3 14.930199 21.5 16.9 18.9 21.9 17.2 19.3ChineseDict only 44.4 30.4 36.1 44.5 30.5 36.21000 33.0 22.2 26.5 30.8 22.6 26.13162 44.6 28.9 35.1 41.7 30.0 34.910000 51.1 34.0 40.8 50.7 35.8 42.031622 60.4 39.0 47.4 55.7 39.7 46.4100000 66.0 43.7 52.6 63.7 45.4 53.0Romanian1000 49.6 27.7 35.6 50.1 28.0 35.93162 57.9 33.4 42.4 57.6 33.0 42.010000 72.6 45.5 55.9 71.3 45.0 55.248441 84.7 57.8 68.7 83.5 57.1 67.8Table 2: Performance in Precision, Recall, and F-measure (per cent) of all systems.Source # Test Mean CorrelationLanguage Sents Length Direct E?Hindi 46 16.3 54.1 60.1Korean 100 20.2 10.2 31.6Chinese 88 26.5 60.2 63.7Romanian 248 22.7 81.1 80.6Table 3: Test set characteristics, including numberof sentence pairs, mean length of English sentences,and correlation r2 between English and source-language normalized word positions in gold-standarddata, for direct and English?
situations.and a test of the ability of the system to take soleresponsibility for knowledge of reordering.Table 3 describes the test sets and shows the cor-relation in gold standard aligned word pairs betweenthe position of the English word in the English sen-tence and the position of the source-language wordin the source-language sentence (normalizing the po-sitions to fall between 0 and 1).
The baseline (di-rect) correlations give quantitative evidence of dif-fering degrees of syntactic divergence with English,and the English?
correlations demonstrate that ourheuristics do have the effect of better fitting sourcelanguage word order.5 ResultsFigures 4, 5, 6 and 7 show learning curves for sys-tems trained on parallel sentences with and with-out the English?
transforms.
Table 2 provides fur-ther detail, and also shows the performance of sys-tems trained without any bitext, but only with ac-cess to a bilingual translation lexicon.
Our sys-tem achieves consistent, substantial performance im-provement under all situations for English-Hindiand English-Korean language pairs, which exhibitlonger distance SOV?SVO syntactic divergence.For English-Romanian and English-Chinese, neithersignificant improvement nor degradation is seen, butthese are language pairs with quite similar sententialword order to English, and hence have less opportu-nity to benefit from our syntactic transformations.6 ConclusionsWe have developed a system to improve the per-formance of bitext word alignment between Englishand a source language by first reordering parsedEnglish into an order more closely resembling that1Hindi training: news text from the LDC for the 2003DARPA TIDES Surprise Language exercise; Hindi testing:news text from Rebecca Hwa, then at the University of Mary-land; Hindi dictionary: The Hindi-English Dictionary, v. 2.0from IIIT (Hyderabad) LTRC; Korean training: UnboundBible; Korean testing: half from Penn Korean Treebank andhalf from Universal declaration of Human Rights, aligned byWoosung Kim at the Johns Hopkins University; Korean dic-tionary: EngDic v. 4; Chinese training: news text from FBIS;Chinese testing: Penn Chinese Treebank news text aligned byRebecca Hwa, then at the University of Maryland; Chinesedictionary: from the LDC; Romanian training and testing:(Mihalcea and Pedersen, 2003).of the source language, based only on knowledgeof the coarse basic word order of the source lan-guage, such as can be obtained from any cross-linguistic survey of languages, and requiring no pars-ing of the source language.
We applied the sys-tem to the task of aligning English with Hindi, Ko-rean, Chinese and Romanian.
Performance improve-ment is greatest for Hindi and Korean, which exhibitlonger-distance constituent reordering with respectto English.
These properties suggest the proposedEnglish?
word alignment method can be an effectiveapproach for word alignment to languages with bothgreater cross-linguistic word-order divergence and anabsence of available parsers.ReferencesP.
F. Brown, S. A. Della Pietra, V. J. Della Pietra,and R. L. Mercer.
1993.
The mathematics of sta-tistical machine translation: Parameter estima-tion.
Computational Linguistics, 19(2):263?311.M.
Collins.
1999.
Head-Driven Statistical Models forNatural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania.B.
J. Dorr, L. Pearl, R. Hwa, and N. Habash.
2002.DUSTer: A method for unraveling cross-languagedivergences for statistical word-level alignment.In Proceedings of AMTA-02, pages 31?43.A.
Lopez, M. Nosal, R. Hwa, and P. Resnik.
2002.Word-level alignment for multilingual resource ac-quisition.
In Proceedings of the LREC-02 Work-shop on Linguistic Knowledge Acquisition andRepresentation.I.
D. Melamed.
1998.
Empirical methods for MTlexicon development.
Lecture Notes in ComputerScience, 1529:18?9999.R.
Mihalcea and T. Pedersen.
2003.
An evalua-tion exercise for word alignment.
In Rada Mi-halcea and Ted Pedersen, editors, Proceedings ofthe HLT-NAACL 2003 Workshop on Building andUsing Parallel Texts, pages 1?10.F.
J. Och and H. Ney.
2000.
A comparison of align-ment models for statistical machine translation.In Proceedings of COLING-00, pages 1086?1090.D.
I. Tufis?.
2002.
A cheap and fast way to builduseful translation lexicons.
In Proceedings ofCOLING-02, pages 1030?1036.D.
Wu.
1995.
Stochastic inversion transductiongrammars, with application to segmentation,bracketing, and alignment of parallel corpora.
InProceedings of IJCAI-95, pages 1328?1335.K.
Yamada and K. Knight.
2001.
A syntax-basedstatistical translation model.
In Proceedings ofACL-01, pages 523?530.D.
Yarowsky, G. Ngai, and R. Wicentowski.
2001.Inducing multilingual text analysis tools via ro-bust projection across aligned corpora.
In Pro-ceedings of HLT-01, pages 161?168.
