2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 518?522,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsPredicting Overt Display of Power in Written DialogsVinodkumar PrabhakaranComputer Science Dept.Columbia UniversityNew York, NY 10027, USAvinod@cs.columbia.eduOwen RambowCCLSColumbia UniversityNew York, NY 10027, USArambow@ccls.columbia.eduMona DiabCCLSColumbia UniversityNew York, NY 10027, USAmdiab@ccls.columbia.eduAbstractWe analyze overt displays of power (ODPs)in written dialogs.
We present an email cor-pus with utterances annotated for ODP andpresent a supervised learning system to predictit.
We obtain a best cross validation F-measureof 65.8 using gold dialog act features and 55.6without using them.1 IntroductionAnalyzing written dialogs (such as email exchanges)to extract social power relations has generated greatinterest recently.
This paper introduces a new taskwithin the general field of finding power relationsin written dialogs.
In written dialog, an utterancecan represent an overt display of power (ODP) onthe part of the utterer if it constrains the addressee?sactions beyond the constraints that the underlyingdialog act on its own imposes.
For example, a re-quest for action is the first part of an adjacency pairand thus requires a response from the addressee, butdeclining the request is a valid response.
However,the utterer may formulate her request for action in away that attempts to remove the option of decliningit (?Come to my office now!?).
In so doing, she re-stricts her addressee?s options for responding moreseverely than a simple request for action would.
Ournew task is to classify utterances in written dialogas to whether they are ODPs or not.
Such a classifi-cation can be interesting in and of itself, and it canalso be used to study social relations among dialogparticipants.After reviewing related work (Section 2), we de-fine ?overt display of power?
(Section 3) and thenpresent manual annotations for ODP in a small sub-set of Enron email corpus.
In Section 5, we present asupervised learning system using word and part-of-speech features along with features indicating dialogacts.2 Related WorkMany studies in sociolinguistics have shown thatpower relations are manifested in language use(e.g., (O?Barr, 1982)).
Locher (2004) recognizes?restriction of an interactant?s action-environment?
(Wartenberg, 1990) as a key element by which ex-ercise of power in interactions can be identified.Through ODP we capture this action-restriction atan utterance level.
In the computational field, sev-eral studies have used Social Network Analysis(e.g., (Diesner and Carley, 2005)) for extracting so-cial relations from online communication.
Only re-cently have researchers started using NLP to analyzethe content of messages to deduce social relations(e.g., (Diehl et al, 2007)).
Bramsen et al (2011) useknowledge of the actual organizational structure tocreate two sets of messages: messages sent from asuperior to a subordinate, and vice versa.
Their taskis to determine the direction of power (since all theirdata, by construction of the corpus, has a power re-lationship).
Their reported results cannot be directlycompared with ours since their results are on classi-fying aggregations of messages as being to a supe-rior or to a subordinate, whereas our results are onpredicting whether a single utterance has an ODP ornot.5183 Overt Display of Power (ODP)Dialog is successful when all discourse participantsshow cooperative dialog behavior.
Certain types ofdialog acts, notably requests for actions and requestsfor information (questions), ?set constraints on whatshould be done in a next turn?
(Sacks et al, 1974).Suppose a boss sends an email to her subordinate:?It would be great if you could come to my of-fice right now?.
He responds by politely declining(?Would love to, but unfortunately I need to pick upmy kids?).
He has met the expectation to respondin one of the constrained ways that the request foraction allows (other acceptable responses include acommitment to performing the action, or actuallyperforming the action, while unacceptable responsesinclude silence, or changing the topic).
However, di-alog acts only provide an initial description of theseconstraints.
Other sources of constraints includethe social relations between the utterer and the ad-dressee, and the linguistic form of the utterance.
As-sume our email example had come, say, from theCEO of the company.
In this case, the addressee?sresponse would not meet the constraints set by theutterance, even though it is still analyzed as the samedialog act (a request for action).
Detecting suchpower relations and determining their effect on di-alog is a hard problem, and it is the ultimate goal ofour research.
Therefore, we do not use knowledgeof power relations as features in performing a finer-grained analysis of dialog acts.
Instead, we turn tothe linguistic form of an utterance.
Specifically, theutterer can choose linguistic forms in her utteranceto signal that she is imposing further constraints onthe addressee?s choice of how to respond, constraintswhich go beyond those defined by the standard setof dialog acts.
For example, if the boss?s email is?Please come to my office right now?, and the ad-dressee declines, he is clearly not adhering to theconstraints the boss has signaled, though he is ad-hering to the general constraints of cooperative dia-log by responding to the request for action.
We areinterested in these additional constraints imposed onutterances through choices in linguistic form.
Wedefine an utterance to have Overt Display of Power(ODP) if it is interpreted as creating additional con-straints on the response beyond those imposed bythe general dialog act.
Note that use of polite lan-ID Sample utterances1 If there is any movement of these people betweengroups can you please keep me in the loop.s2 I need the answer ASAP, as ....s3 Please give me your views ASAP.s4* Enjoy the rest of your week!s5 Would you work on that?s6* ... would you agree that the same law firm advise onthat issue as well?s7* can you BELIEVE this bloody election?s8 ok call me on my cell later.Table 1: Sample utterances from the corpus; * next to IDdenotes an utterance without an ODPguage does not, on its own, determine the presenceor absence of an ODP.
Furthermore, the presence ofan ODP does not presuppose that the utterer actuallypossess social power: the utterer could be attempt-ing to gain power.Table 1 presents some sample utterances cho-sen from our corpus (the * indicates those withoutODP).
An utterance with ODP can be an explicit or-der or command (s3, s8) or an implicit one (s2, s5).It can be a simple sentence (s3) or a complex one(s1).
It can be an imperative (s3), an interrogative(s5) or even a declarative (s2) sentence.
But not allimperatives (s4) or interrogatives (s6, s7) are ODPs.s5, s6 and s7 are all syntactically questions.
How-ever, s5?s discourse function within an email is torequest/order to work on ?that?
which makes it aninstance of ODP, while s6 is merely an inquiry ands7 is a rhetorical question.
This makes the problemof finding ODP in utterances a non-trivial one.4 Data and AnnotationsFor our study, we use a small corpus of Enron emailthreads which has been previously annotated withdialog acts (Hu et al, 2009).
The corpus contains122 email threads with 360 messages, 1734 utter-ances and 20,740 word tokens.
We trained an anno-tator using the definition for ODP given in Section3.
She was given full email threads whose messageswere already segmented into utterances.
She iden-tified 86 utterances (about 5%) to have an ODP.1 In1These annotations were done as part of a larger annotationeffort (Prabhakaran et al, 2012).
The annotated corpus can beobtained at http://www.cs.columbia.edu/?vinod/powerann/.519order to validate the annotations, we trained anotherannotator using the same definitions and examplesand had him annotate 46 randomly selected threadsfrom the corpus, which contained a total of 595 ut-terances (34.3% of whole corpus).
We obtained areasonable inter annotator agreement, ?
value, of0.669, which validates the annotations while con-firming that the task is not a trivial one.5 Automatic ODP TaggingIn this section, we present a supervised learningmethod to tag unseen utterances that contain an ODPusing a binary SVM classifier.
We use the tokenizer,POS tagger, lemmatizer and SVMLight (Joachims,1999) wrapper that come with ClearTK (Ogren etal., 2008).
We use a linear kernel with C = 1 forall experiments and present (P)recision, (R)ecall and(F)-measure obtained on 5-fold cross validation onthe data.
Our folds do not cross thread boundaries.5.1 Handling Class ImbalanceIn its basic formulation, SVMs learn a decision func-tion f from a set of positive and negative training in-stances such that an unlabeled instance x is labeledas positive if f(x) > 0.
Since SVMs optimize ontraining set accuracy to learn f , it performs betteron balanced training sets.
However, our dataset ishighly imbalanced (?
5% positive instances).
Weexplore two ways of handling this class imbalanceproblem: an instance weighting method, InstWeight,where training errors on negative instances are out-weighed by errors on positive instances, and SigTh-resh, a threshold adjusting method to find a betterthreshold for f(x).
For InstWeight, we used the joption in SVMlight to set the outweighing factorto be the ratio of negative to positive instances inthe training set for each cross validation fold.
Inst-Weight is roughly equivalent to oversampling by re-peating positive instances.
For SigThresh, we useda threshold based on a posterior probabilistic score,p = Pr(y = 1|x), calculated using the ClearTK im-plementation of Lin et al (2007)?s algorithm.
It usesPlatt (1999)?s approximation of p to a sigmoid func-tion PA,B(f) = (1 + exp(Af + B))?1, where Aand B are estimated from the training set.
Then, wepredict x as positive if p > 0.5 which in effect shiftsthe threshold for f(x) to a value based on its distri-ExperimentInstWeight SigThreshP R F P R FALL-TRUE 5.0 100.0 9.5 5.0 100.0 9.5RANDOM 5.7 58.1 10.4 5.7 58.1 10.4WORD-UNG 43.1 29.1 34.7 63.0 39.5 48.6PN,MN,FV,DA 66.7 48.8 56.4 72.3 54.7 62.3PN,MN,DA 64.5 46.5 54.1 75.8 58.1 65.8LN,PN,MN,FV 64.4 44.2 52.4 65.2 50.0 56.6Table 2: ResultsClass Imbalance Handling: InstWeight: Instance weighting andSigThresh: Sigmoid thresholdingFeatures: WORD-UNG: Word unigrams, LN: Lemma ngrams, PN:POS ngrams, MN: Mixed ngrams, FV: First verb, DA: Dialog actsbution on positive and negative training instances.5.2 FeaturesWe present experiments using counts of three typesof ngrams: lemma ngrams (LN), POS ngrams (PN)and mixed ngrams (MN).2 Mixed ngram is a re-stricted formulation of lemma ngram where open-class lemmas (nouns, verbs, adjectives and adverbs)are replaced by POS tags.
E.g., for the utterances2, LN would capture patterns {i, need, i need, .
.
.
},while PN would capture {PRP, VBP, PRP VBP, .
.
.
}and MN would capture {i VBP the NN, .
.
.}.
Wealso used a feature (FV) to denote the first verblemma in the utterance.
Since ODPs, like dialogacts, constrain how the addressee should react, wealso include Dialog Acts as features (DA).
We usethe manual gold dialog act annotations present inour corpus, which use a very small dialog act tagset.
An utterance has one of 5 dialog acts: Reques-tAction, RequestInformation, Inform, Commit andConventional (see (Hu et al, 2009) for details).
Forexample, for utterance s2, FV would be ?need?
andDA would be ?Inform?.35.3 Results and AnalysisWe present two simple baselines ?
ALL-TRUE,where an utterance is always predicted to have anODP, and RANDOM, where an utterance is pre-dicted at random, with 50% chance to have an ODP.We also present a strong baseline WORD-UNG,2LN performed consistently better than word ngrams.3We also explored other features including the number oftokens, the previous or following dialect act, none of which im-proved the results and.
We omit a detailed discussion for rea-sons of space.520which is trained using surface-form word unigramsas features.
ALL-TRUE and RANDOM obtained Fscores of 9.5 and 10.4 respectively, while WORD-UNG obtained an F score of 34.7 under InstWeight,and improved it to 48.6 under SigThresh.For LN, PN and MN, we first found the best valuefor n to be 1, 2 and 4, respectively.
We then didan exhaustive search in all combinations of LN, PN,MN, FV and DA under both InstWeight and SigTh-resh.
Results obtained for best feature subset underboth configurations are presented in Table 2 in rows3 and 4.
SigThresh outweighed InstWeight in all ourexperiments.
(Combining these two techniques fordealing with class imbalance performed worse thanusing either one.)
In both settings, we surpassed theWORD-UNG baseline by a high margin.
We foundMN and DA to be most useful: removing either fromthe feature set dropped the F significantly in bothsettings.
We obtained a best F score of 65.8 usingPN, MN and DA under the SigThresh.Following (Guyon et al, 2002), we inspected fea-ture weights of the model created for the last fold ofour best performing feature configuration as a post-hoc analysis.
The binary feature DA:RequestActiongot the highest positive weight of 2.5.
The topten positive weighted features included patternslike you VB, * VB, MD PRP, VB VB and * MD,where * denotes the utterance boundary.
DA:Informgot the most negative weight of -1.4, followed byDA:Conventional with -1.0.
The top ten negativeweighted features included patterns like MD VB,VB you, what, VB VB me VB and WP.
In bothcases, DA features got almost 2.5 times higherweight than the highest weighted ngram pattern,which reaffirms their importance in this task.
Also,mixed ngrams helped to capture long patterns like?please let me know?
by VB VB me VB without in-creasing dimensionality as much as word ngrams;they also distinguish VB you with a negative weightof -0.51 from VB me with a positive weight of 0.32,which pure POS ngrams couldn?t have captured.5.4 Not Using Gold Dialog ActsWe also evaluate the performance of our ODP taggerwithout using gold DA tags.
We instead use the DAtagger of Hu et al (2009), which we re-trained us-ing the training sets for each of our cross validationfolds, applying it to the test set of that fold.
We thendid cross validation for the ODP tagger using golddialog acts for training and automatically tagged di-alog acts for testing.
However, for our best perform-ing feature set so far, this reduced the F score from65.8 to 52.7.
Our best result for ODP tagging with-out using gold DAs is shown in row 5 in Table 2,56.9 F score under SigThresh.
The features used areall of our features other than the DA tags.
On fur-ther analysis, we find that even though the dialogact tagger has a high accuracy (85.8% in our crossvalidation), it obtained a very low recall of 28.6%and precision of 47.6% for the RequestAction dia-log act.
Since RequestAction is the most importantfeature (weighted 1.7 times more than the next fea-ture), the DA-tagger?s poor performance on Reques-tAction hurt ODP tagging badly.
The performancereduction in this setting is probably partly due to us-ing gold DAs in training and automatically taggedDAs in testing; however, we feel that improving thedetection of minority classes in dialog act tagging(RequestAction constitutes only 2.5% in the corpus)is a necessary first step towards successfully usingautomatically tagged DAs in ODP tagging.6 ConclusionWe have introduced a new binary classification taskon utterances in dialogs, namely predicting OvertDisplay of Power.
An ODP adds constraints on thepossible responses by the addressee.
We have in-troduced a corpus annotated for ODP and we haveshown that using supervised machine learning withgold dialog acts we can achieve an F-measure of66% despite the fact that ODPs are very rare in thecorpus.
We intend to develop a better dialog act tag-ger which we can use to automatically obtain dialogact labels for ODP classification.7 AcknowledgmentsThis work is supported, in part, by the Johns Hop-kins Human Language Technology Center of Ex-cellence.
Any opinions, findings, and conclusionsor recommendations expressed in this material arethose of the authors and do not necessarily reflectthe views of the sponsor.
We thank several anony-mous reviewers for their constructive feedback.521ReferencesPhilip Bramsen, Martha Escobar-Molano, Ami Patel, andRafael Alonso.
2011.
Extracting social power rela-tionships from natural language.
In ACL, pages 773?782.
The Association for Computer Linguistics.Christopher P. Diehl, Galileo Namata, and Lise Getoor.2007.
Relationship identification for social networkdiscovery.
In AAAI, pages 546?552.
AAAI Press.Jana Diesner and Kathleen M. Carley.
2005.
Explorationof communication networks from the enron email cor-pus.
In In Proc.
of Workshop on Link Analysis, Coun-terterrorism and Security, SIAM International Confer-ence on Data Mining 2005, pages 21?23.Isabelle Guyon, Jason Weston, Stephen Barnhill, andVladimir Vapnik.
2002.
Gene selection for cancerclassification using support vector machines.
Mach.Learn., 46:389?422, March.Jun Hu, Rebecca Passonneau, and Owen Rambow.
2009.Contrasting the interaction structure of an email and atelephone corpus: A machine learning approach to an-notation of dialogue function units.
In Proceedings ofthe SIGDIAL 2009 Conference, London, UK, Septem-ber.
Association for Computational Linguistics.Thorsten Joachims.
1999.
Making Large-Scale SVMLearning Practical.
In Bernhard Scho?lkopf, Christo-pher J.C. Burges, and A. Smola, editors, Advancesin Kernel Methods - Support Vector Learning, Cam-bridge, MA, USA.
MIT Press.Hsuan-Tien Lin, Chih-Jen Lin, and Ruby C. Weng.
2007.A note on platt?s probabilistic outputs for support vec-tor machines.
Mach.
Learn., 68:267?276, October.Miriam A. Locher.
2004.
Power and politeness in ac-tion: disagreements in oral communication.
Lan-guage, power, and social process.
M. de Gruyter.William M. O?Barr.
1982.
Linguistic evidence: lan-guage, power, and strategy in the courtroom.
Studieson law and social control.
Academic Press.Philip V. Ogren, Philipp G. Wetzler, and Steven Bethard.2008.
ClearTK: A UIMA toolkit for statistical naturallanguage processing.
In Towards Enhanced Interoper-ability for Large HLT Systems: UIMA for NLP work-shop at Language Resources and Evaluation Confer-ence (LREC).John C. Platt.
1999.
Probabilistic outputs for supportvector machines and comparisons to regularized like-lihood methods.
In ADVANCES IN LARGE MARGINCLASSIFIERS, pages 61?74.
MIT Press.Vinodkumar Prabhakaran, Owen Rambow, and MonaDiab.
2012.
Annotations for power relations onemail threads.
In Proceedings of the Eighth confer-ence on International Language Resources and Eval-uation (LREC?12), Istanbul, Turkey, May.
EuropeanLanguage Resources Association (ELRA).Sacks, E Schegloff, and G Jefferson.
1974.
A simplestsystematics for the organization of turn-taking for con-versation.
Language, 50:696?735.Thomas E. Wartenberg.
1990.
The forms of power:from domination to transformation.
Temple Univer-sity Press.522
