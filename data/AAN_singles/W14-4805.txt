Proceedings of the 4th International Workshop on Computational Terminology, pages 33?41,Dublin, Ireland, August 23 2014.NPMI driven recognition of nested termsMa?gorzata MarciniakInstitute of Computer Science, PASJana Kazimierza 5,01-248 Warsaw, Polandmm@ipipan.waw.plAgnieszka MykowieckaInstitute of Computer Science, PASJana Kazimierza 5,01-248 Warsaw, Polandagn@ipipan.waw.plAbstractIn the paper, we propose a new method of identifying terms nested within candidates for theterms extracted from domain texts.
The list of all terms is then ranked by the process of automaticterm recognition.
Our method of identifying nested terms is based on two aspects: grammaticalcorrectness and normalised pointwise mutual information (NPMI) counted for all bigrams onthe basis of a corpus.
NPMI is typically used for recognition of strong word connections but inour solution we use it to recognise the weakest points within phrases to suggest the best place fordivision of a phrase into two parts.
By creating only two nested phrases in each step we introducea binary hierarchical term structure.
In the paper, we test the impact of the proposed nested termsrecognition method applied together with the C-value ranking method to the automatic termrecognition task.1 IntroductionThe Automatic Term Recognition (ATR) task consists in identifying linguistic expressions that refer todomain concepts.
This is usually realised in two steps.
In the first one, candidates for terms are identifiedin a corpus of domain texts.
This step usually consists in identifying grammatically correct phrases bymeans of linguistically motivated grammars describing noun phrases in a given language.
However,sometimes no linguistic knowledge is utilised and candidates for terms are just frequent n-grams as in(Wermter and Hahn, 2005).
The second processing step consists in ranking the extracted candidatesand selecting those which are most important for a considered domain.
This task is usually based onstatistics.The ranking procedure can be based on different measures which are characterised as either?termhood-based?
or ?unithood-based?.
Kageura and Umino (1996) defined the termhood-based meth-ods measure as ?the degree that a linguistic unit is related to domain-specific concepts?, i.e.
the likelihoodthat a phrase is a valid domain term.
The unithood-based methods measure the collocation strength ofword sequences, usually with the help of log-likelihood, pointwise mutual information or T-score mea-sures, described in (Manning and Sch?tze, 1999), while ATR applications based on them are describedin e.g., (Pantel and Lin, 2001), (Sclano and Velardi, 2007).
A comparison of these approaches is givenin (Pazienza et al., 2005).
Some hybrid solutions to the ATR problem have also been proposed (Vu et al.,2008) or (Ventura et al., 2014).
In the paper (Korkontzelos et al., 2008), the comparison between thesetwo groups of methods led the authors to the conclusion that the termhood-based methods outperformthe unithood-based ones.This paper is devoted to the problem of selecting candidates for terms from an annotated domaincorpus.
Our approach is based on the C-value method, (Frantzi et al., 2000).
An important feature of thismethod that attracted our attention was the focus on nested terms.
Frantzi et al.
(2000) described nestedterms as terms that appear within other longer terms, and may or may not appear by themselves in thecorpus.
They show that recognition of nested terms is very important in terms extraction, but they alsogive examples when a nested phrase constructed according to the grammar rules is not a term.
One ofThis work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/33these examples is the phrase real time clock which has two nested phrases: real time and time clock, butthe second one is not a good term.
The authors define the C-value measure that is used to rank candidateterms extracted from a domain corpus, together with their nested terms.
It is counted on the basis of thefrequency of the term as a whole phrase in the corpus, its frequency as a nested phrase in other terms,the number of different phrases in which that nested phrase occurred, and its length.
The authors expectthat phrases that aren?t considered as terms should be placed at the end of the list ordered according tothis coefficient value.We applied the C-value method to extract terminology from a corpus of hospital discharge documentsin Polish.
Experiments, where different methods of counting the C-value were tested, are described in(Marciniak and Mykowiecka, 2014).
Unfortunately, a few grammatically correct but semantically oddphrases were always placed in the top part of the ranking list of terms.
Examples of such phrases, placedamong the 200 top positions, are: USG jamy ?USG of cavity?
being a nested phrase of the very frequentphrase USG jamy brzusznej ?USG of abdominal cavity?, infekcja g?rnych dr?g ?infection of upper tract?or powie?kszony we?ze?
?enlarged node?.We propose a method that prevents the creation and promotion of such nested phrases to be consid-ered as terms.
The main idea is to use a unithood-based method e.g., Normalised Pointwise MutualInformation (NPMI) (Bouma, 2009) for driving recognition of nested phrases.
Our solution is based onthe division of each considered phrase into only two parts.
The places where a phrase is divided mustcreate nested phrases that are consistent with grammar rules.
Usually, there are several possible placesfor division of a phrase.
From all of them, we choose the weakest point according to NPMI counted forbigrams on the basis of the whole corpus.
So, as a bigram constitutes a strong collocation, it prevents thephrase from being dividing in this place, and does not usually lead to the creation of semantically oddnested phrases, of which examples are given above.The analysed corpus of Polish medical texts is described in Section 2.
In the following two sectionswe present the method in detail.
Then, in Section 5, we describe the comparison of the resulting lists ofterms ranked according to the C-value measure, for two methods of recognition of nested phrases , i.e.
:for all possible phrases fulfilling grammatical rules, and for the method proposed in the paper.2 Corpus descriptionThe domain corpus consists of 3116 hospital discharge documents gathered at a hospital in Poland.Texts came from six departments and were written by several physicians of different specialties.
Thecollected texts were analysed using standard general purpose NLP tools.
The morphological tagger Pan-tera (Aceda?nski, 2010), cooperating with the Morfeusz analayser (Woli?nski, 2006), was used to dividethe text into tokens and annotate them with morhosyntactic tags.
They included a part of speech name(POS), a base form, as well as case, gender and number information, where they were appropriate.
Thisinformation is used by shallow grammars recognising the boundaries of nominal phrases ?
term can-didates and, also,sources for nested phrases.
The corpus consists of about 2 million tokens in which ashallow grammar recognised more than 22 thousand noun phrases.The corpus contains quite a lot of words unrecognised by Morfeusz as the vocabulary of the clinicaldocuments significantly differs from general Polish texts.
Additionally, the texts are not very well editeddespite the spelling correction tools being usually turned on, so they contain quite a lot of misspelledwords.
This results in 22,000 unrecognised tokens (many of them are medications, acronyms and units)that are not taken into account when nominal phrases are recognised.
Consequently, it lowers the numberof phrases, and affects the quality of some of them.
In (Marciniak and Mykowiecka, 2011), the problemsof morphological annotation of hospital documents in Polish are presented and the reasons for the manyunrecognised tokens are highlighted.3 Nested phrases recognitionIn this section, we describe the way to create a list of term candidates that takes into account nestedphrases.
This task is usually supported by linguistic knowledge that allows for identifying candidates forterms which are syntactically valid.34In the extraction step, we identified complex noun phrases consisting of nouns with adjectival andnominal modifiers obeying Polish grammar rules (in particular, case, gender and number agreement).The types of Noun Phrases under consideration can be schematically defined as below:AdjPhrase Noun AdjPhraseAdjPhrase NounNoun AdjPhraseNounPhrase NounPhrase-in-genitiveNoun Phrases were extracted from the corpus using a cascade of shallow grammars.
As Polish is ahighly inflected language, we operate on simplified base forms of phrases in our computations, con-sisting of lemmas of subsequent words.
This approach, proposed for ATR in Polish in (Marciniak andMykowiecka, 2013), allows us to unify forms of phrases in different cases and numbers.
For example:przewlek?e zapalenie gard?a, przewlek?e zapalenia gard?a, przewlek?ego zapalenia gard?a, przewlek?ychzapalen?
gard?a are forms of ?chronic pharyngitis?
in nominative singular and plural and genitive in bothnumbers.1The extracted phrases constitute a foundation for creating the list of term candidates.
Thenwe add nested phrases, recognised within those phrases, to the list of term candidates.
The rules foridentifying nested terms are described in the rest of this section.3.1 MotivationsThe original C-value method (Frantzi et al., 2000) recommends that all grammatical phrases, createdfrom the maximal phrases identified in a corpus, should be considered as term candidates.
But usingthis method, we quite frequently obtain nested grammatical subphrases which are syntactically correct,but semantically odd.
One such phrase is infekcja g?rnych dr?g ?infection (of the) upper tract?
that iscreated from infekcja g?rnych dr?g oddechowych ?infection (of the) upper respiratory tract?.2The lastphrase has many different longer phrases in which it is nested, eg: (cze?sta, drobna, ostra, bakteryjna...)infekcja g?rnych dr?g oddechowych ?
(often, minor, acute, bacterial...) infection (of the) upper respiratorytract?, but it always concerns drogi oddechowe ?respiratory tract?.
We observe that the bigram drogioddechowe ?respiratory tract?
constitutes a strong collocation.
So the original phrase shouldn?t be dividedin this place to create a phrase containing the word drogi ?tract?
without adding its type, i.e., oddechowe?respiratory?
in this case.
Nominal phrases are usually constructed from two parts (except for coordinatedphrases and nouns with more complex subcategoriaztion frames, which usually do not fulfill agreementconstraints in Polish).
For nominal phrases from domain corpora, we suggest that the best place for thedivision is indicated by the weakest bigram.After considering patterns of nominal phrases in Polish, we realised that the weakest connectionsare usually between two nominal phrases (the last pattern).
So, an adjective more likely modifiesthe nearest noun and not the whole phrase, as in: prawid?owaadjmikrofloranoung?rnychadjdr?gnounoddechowychadj?normal microflora (of the) upper respiratory tract?.
In this phrase, all the outermostadjectives are important parts of nominal phrases constructed around their nearest nouns, and it shouldbe divided into two nominal phrases: prawid?owa mikroflora ?normal microflora?
and g?rne drogi odde-chowe ?upper respiratory tract?.
However, it is not the universal rule.
Let us consider another example:cze?ste infekcje g?rnych dr?g oddechowych ?frequent infections (of the) upper respiratory tract?, wherecze?ste ?frequent?
modifies the whole phrase.
To account for this observation, we may slightly preferdivisions into two nominal phrases instead of an adjective and a nominal phrase.3.2 AlgorithmFrom several methods for counting the strength of bigrams we chose the normalised pointwise mutualinformation proposed by Bouma, (2009), as it is less sensitive to occurrence frequency.
We were lookingfor a method for which the bigram, consisting of a rare and a frequent token, will be high if the rare tokenonly appears in connection with the frequent token, as, for example, for esowate skrzywienie ?S-shapedcurvature?.
The definition of this measure for the ?x y?
bigram, where x and y are lemmas of sequence1Further in the paper we will use phrases in the nominal case and singular number forms.
These forms may differ slightlyfrom the same phrases being nested ones (in genitive).2The word order of the translation is different.35tokens, is given in (1), where p(x,y) is a probability of the ?x y?
bigram in the considered corpus, andp(x), p(y) are probabilities of ?x?
and ?y?
unigrams respectively.NPMI(x, y) =(lnp(x, y)p(x)p(y))/?
ln p(x, y) (1)First, we extract all the grammatical phrases from the corpus, taking into account only the maximalone.
Then, for each phrase we identify all places where it can be divided according to grammar rules.We count NPMI for those and indicate the weakest connection in the phrase.
Then, we divide it into twoparts in this position.
There are two possible situations: the first, when the phrase is divided into twonominal phrases; the second, when one phrase is a nominal phrase while the second one is an adjectivephrase.
In the first case, we add both parts to the list of term candidates and process the obtained parts ofthe phrase in the same way.
In the second case, only a nominal phrase is added to the list and only thisphrase is further divided.nested_phrases (phr)if length(phr) > 1find all i positions where phr can be divided according to the grammatic rulesfor all i positionscount NPMI(i-th bigram of phr)sort NPMIs from the lowest to the highest valuej := position with the lowest NPMIif the j-th position divides phr into two nominal phrasesdivide phr into phr1 and phr2 on j-th positionadd phr1 and phr2 to the list of nested termsnested_phrases(phr1)nested_phrases(phr2)elsen := position with the lowest NPMI where phr is divided into two nominal phrasesif (120% NPMI(j)) > NPMI (n)divide phr into phr1 and phr2 on n-th positionadd phr1 and phr2 to the list of nested termsnested_phrases(phr1)nested_phrases(phr2)elseif phr is divided on j position into adjective phrase to the left of nominal phrasecut off the outermost left element from phrelsecut off the outermost right element from phradd phr to the list of nested termsnested_phrases(phr)Figure 1: Procedure of nested phrases recognitionTo take into account the specificity of adjectives in Polish nominal phrases described in 3.1, we decidedto introduce a slight modification to the basic algorithm.
If the weakest connection prefers the cutting ofan adjective part from a phrase, we find the nearest place where the phrase is divided into two nominalphrases.
Then, we compare the NPMI value referring to this bigram with 120% (fixed experimentally)of the lowest NPMI value.
If it is still lower, we cut off one outermost element (adjective or adverb)from this adjectival part of the phrase and add the slightly shorter phrase to the term list.
In other case,we divide the original phrase in that second place into two nominal phrases.
The algorithm is given inFigure 1.36The grammatically correct nested phrases The nested phrases divided with help of NPMI?infection?
?upper?
?tract?
?respiratory?
?infection?
?upper?
?tract?
?respiratory?infekcja g?rnych dr?g oddechowych infekcja g?rnych dr?g oddechowychinfekcja g?rnych dr?g ?infekcja infekcjag?rne drogi oddechowe g?rne drogi oddechoweg?rne drogi ?drogi oddechowe drogi oddechowedrogi drogiTable 1: The nested phrases for two methodsbigram translation NPMIinfekcja g?rna ?infection upper?
0.65658g?rna droga ?upper tract?
0.78773droga oddechowy ?tract respiratory?
0.95089Table 2: The NPMI value for the bigrams of the phrase: infekcja g?rnych dr?g oddechowych3.3 ExamplesLet us consider examples illustrating the method.
We compare nested phrases obtained from the phraseinfekcja g?rnych dr?g oddechowych ?infection (of the) upper respiratory tract?
for the two followingmethods: creating all grammatically correct nested phrases, and the NPMI driven method.
The consid-ered phrase is constructed according to the following pattern: NounjAdjiNouniAdjiwhere indexesindicate agreement constraints, so a grammatically correct phrase may consist of: NounjAdjiNouni,but can?t be constructed as: NounjAdji.
Thus, infekcja g?rnych dr?g ?infection of the upper tract?
isgrammatically correct, while infekcja g?rnych ?infection of upper?
is not.
The phrase can be dividedin one of two places indicated by the ?|?
character: infekcja | g?rnych dr?g | oddechowych, ?infection| upper tract | respiratory?3and it is possible to create six grammatically correct phrases, see Table 1.Applying our method, we first count NPMI for the places of possible divisions.
The NPMI value fortwo bigrams infekcja g?rny ?infection upper?
and droga oddechowy ?tract respiratory?
counted for thecorpus described in Section 2 are given in Table 2.
The lower value is for the first bigram so the phrasecan be divided into: infekcja ?infection?
and g?rne drogi oddechowe ?upper respiratory tract?.
Both partsconstitute nominal phrases so the phrase is divided in this place and both parts are added to the list ofterm candidates.
In the next step only the second phrase can be recursively divided.
The weaker connec-tion is for: g?rny droga ?upper tract?.
So the adjective g?rna ?upper?
is cut off the phrase and only thenested phrase drogi oddechowe ?respiratory tract?
is accepted as a term candidate.
Table 1 contains allthe nested phrases obtained by both methods for the considered phrase.
It may be noted that our method,correctly, does not extract two semantically odd nested phrases from the six obtained by the first method.Let us consider a phrase where the lowest NPMI indicates division into an adjective and a nominalphrase: boczneadjskrzywienienounkre?gos?upanoun?lateral curvature (of the) spine?.
The phrase canbe divided in both places: boczne | skrzywienie | kre?gos?upa ?lateral | curvature | spine?.
The weakestconnection is for the bigram: boczny skrzywienie ?lateral curvature?, it indicates division into the nominalphrase skrzywienie kre?gos?upa ?curvature (of the) spine?, and the adjective boczne ?lateral?.
The otherplace of division causes the phrase to be divided into two nominal phrases.
So we compare the NPMI forskrzywienie kre?gos?up ?curvature spine?, with 120% NPMI boczny skrzywienie ?lateral curvature?, seeTable 3.
As the first value is lower than the second one, the method prefers to divide the phrase intotwo nominal phrases boczne skrzywienie ?lateral curvature?
and kre?gos?up ?spine?.
The basic algorithm,without multiplying NPMI values in some cases by 120%, creates a good term skrzywienie kre?gos?upa?curvature (of the) spine?
instead of two nominal phrases: boczne skrzywienie ?lateral curvature?
and3The word for word translation.37bigram translation NPMI 120% NPMIboczny skrzywienie ?lateral curvature?
0.67619 0.81143skrzywienie kre?gos?up ?curvature spine?
0.80151Table 3: The NPMI value for the bigrams of the phrase: boczne skrzywienie kre?gos?upakre?gos?up spine.There are a few cases when the phrase division driven by the NPMI value prefers cutting off an ad-jective in the first step instead of dividing it into two nominal phrases, see: oko?oporodoweadjuszkodze-nienounsplotunounramiennegoadjprawegoadj?perinatal damage (of) right brachial plexus?.
Despite thefact that oko?oporodowe uszkodzenie splotu ramiennego ?perinatal damage (of) brachial plexus?
is a goodterm, we would prefer the division into two nominal phrases oko?oporodowe uszkodzenie ?perinatal dam-age?
and splot ramienny prawy ?right brachial plexus?.
The last division reflects the internal constructionof the phrase that might be important in an ontology construction task which is one of the intended usesof the method.
In this case, we want to recognise nested phrases representing two concepts which are ina relationship.
The method still (correctly) cuts off the adjective cze?sty ?frequent?
from the phrase cze?steinfekcje g?rnych dr?g oddechowych ?frequent infections (of the) upper respiratory tract?.4 Terms orderingTo test to what extent our approach to the phrase selection problem influences the ultimate results of theterm selection algorithm, we used the C-value coefficient (Frantzi et al., 2000) to order extracted phrases.The standard equation for this coefficient is given in (2) where p is the phrase under consideration, freq(p)is a number of occurrences of this phrase both nested and in isolation, LP is a set of phrases containingp, r(LP) ?
the number of different phrases in LP, and l(p) = log2(length(p)).C-value(p) ={l(p) ?
(freq(p)?1r(LP )?lp?LPfreq(lp)), if r(LP ) > 0,l(p) ?
freq(p), if r(LP ) = 0(2)The C-value ranking method is focused on deciding which nested phrases should be considered asterms.
It assigns higher values to phrases which, having the same frequency rate, occur more frequentlyin isolation or occur in a larger number of different longer phrases, i.e., have different lexical contextswithin a set of initially extracted phrases.
To account for the fact that long phrases tend to occur morerarely than shorter ones, the result is multiplied by the logarithm of the phrase length.
If a phrase occursonly in isolation, its frequency rate defines the C-value.
When a phrase occurs only in one context,its C-value gets the value 0 as it is properly assumed to be incomplete.
If a nested phrase occurs in alot of different contexts, its chances of constituting a domain term increase.
A slight modification ofthe method also allows for processing phrases of length 1, which originally all got a 0 value.
For thispurpose, for one word phrases, the logarithm of the length (used in the original solution) is replaced witha non zero constant.
In (Barr?n-Cedeno et al., 2009), where this method was applied to Spanish texts,the authors set it to 1, arguing that if it is lower, one word terms are located too low on the ranking list(it cannot be greater than 1 for obvious reasons).
Our experiments proved that in our data, such a changeresults in very many one word elements at the top of the list, we used a 0.1 value as the equivalent oflogarithm of length for one word phrases.The results obtained using the C-value method depend on the details concerning the way in whichwe distinguish different phrases, i.e., how we count r(LP).
First, for inflectional languages like Polish,a method for recognising inflected forms of a multiword phrase has to be established.
In our experi-ment, we used base form sequences for this purpose.
Secondly, the way of counting contexts has to beelaborated.
For example, it should be decided, whether red blood cells and white blood cells are twodifferent contexts for cell or only one.
For languages with more relaxed word order, like Polish, the samephrase can appear in different orders, e.g., liczne krwinki bia?e ?numerous white blood cells?
or krwinkibia?e liczne ?white blood cells numerous?.
As the C-value coefficient is drastically different for frequentphrases which occur in one and in two different contexts, we tried to limit the number of phrase types38length all =1 =2 3?5 >5s-phrases 32809 4918 13442 13984 465npmi-phrases 28328 4918 11693 11313 393s&npmi-phrases 26671 4918 10420 10929 404frequency =1 2-10 11-50 51-100 101-1000 >1000in isolation 13304 6776 1506 300 415 81s-phrases 18572 10417 2461 523 704 132s&npmi-phrases 15210 8296 2002 420 625 118C-value 0 0<c<1 1?c<5 5?c<10 10 ?c<100 >100s-phrases 8946 2500 16891 1804 2312 357s&npmi-phrases 3428 2508 16652 1672 2074 337Table 4: The number of recognised phrasestotal removed loweredchanges all correctly all incorrectly correctly questionablenmpi/s-phrases 39 39 30 0 - - -s&nmpi1/s-phrases 137 28 26 109 19 73 17s&nmpi/s-phrases 132 27 27 105 20 70 15Table 5: The number of correct changes for the first 2000 positionswhich differ only in order or are included one in another.
We discussed different methods of countingcontexts in (Marciniak and Mykowiecka, 2014) and concluded there that none of the tested ranking pro-cedures were able to filter out all semantically odd noun phrases from the top of the list of terms.
Thebest results we obtained taking only the nearest context of a phrase into account, i.e.
the closest word tothe left or to the right of a phrase.
We used the greater number of these different left and right contexts.This solution can lower the actual number of contexts, but it prevents us from counting the same contextwords placed before and after the phrase twice.5 Results and evaluationWe applied the C-value method to two sets of term candidates.
The first set contains all possible phrasesfulfilling the grammatical rules, while the second one is obtained by the method described in the previoussections.
It is worth noting that we consider contexts of nested phrases only when they are recognisedin phrases by the method.
As both methods recognised different numbers of phrases,4Table 4 givesthe comparison of their numbers.
In this table, s-phrases refers to the baseline solution in which allgrammatically correct nested phrases are taken into account, npmi-phrases refers to the solution obtainedwhile recognising nested phrases using only NPMI value and s&nmpi-pharses is a name used for thefinal solution in which both grammar rules and NPMI values are utilised.
Initially, 32809 phrases wereextracted.
The number of candidate phrases was significantly lower after applying NPMI selection (by15%), but some of them were not grammatically correct.
When applying both selection criteria weobtained about 80% of the phrases (only grammatically correct) from the s-phrases set.
The reductionconcerned phrases irrespective of their occurrences within texts.
As to the distribution of the C-value, itmay be seen that we finally obtained much fewer phrases with a 0 C-value.In the paper (Marciniak and Mykowiecka, 2014), an evaluation of different aspects of the original C-value method applied to the same domain corpus is given.
In this paper, we want to verify the tendencies4The set of phrases recognised by the proposed method is included in that consisting of phrases recognised by the standardmethod based on all valid phrases.39of changes introduced by the proposed method.
To focus on this task, we analysed all phrases that wereincluded in the top 2000 positions ranked by the first method and whose position was moved belowthe 3000 in the final list, see Table 5.
This comparison shows that our solution removed 6.6% (132) ofphrases from the top of the list of terms, and 73.5% (97) among them were semantically odd phrases.We compared the baseline with the version in which, the minimum of NPMI value was always used toindicate phrase division (s&nmpi1) and with the final version, in which the division into two noun phraseswas preferred (i.e.
if the NPMI at the division position was not significantly higher than the minimuminside phrase).
In the first case, we observed the elimination of only 39 phrases from the top 2000.From these sequences, 9 were incorrectly removed from the candidates list.
Using both NPMI value andgrammaticality test resulted in 137 changes inside the top 2000.
This time, from 28 removed elementsonly 2 could be considered correct.
In the final solution, all 27 phrases eliminated form the first 2000were correctly eliminated, while from the remaining 105 phrases, whose positions were significantlylowered, 70 were not terms.
For some phrases it is difficult to judge whether they are domain relatedphrases or are rather related to other topics.
These cases were labelled as ?questionable?
in the table.As the proposed method does not change the way of counting whole phrases recognised in the corpus,we cannot expect that every incorrect phrase will be eliminated.
For example, the phrase infekcja g?rnychdr?g ?infection (of the) upper tract?
cannot disappear from our list of term candidates, as it occurred threetimes as a whole phrase due to a spelling error in the word oddechowy ?respiratory?.
We only expect thatits position is similar to the position of this phrase ranked according to the frequency of the whole phrase.We obtained this required effect.
The semantically odd phrase, considered above, changed its positionfrom 144 to 4374.The presented results show that integrating NPMI with syntactic rules resulted both in better selectionand ranking of candidates.
The final decision to prefer division into two noun phrases had rather smallbut positive effects.6 ConclusionIn the paper, we described a method for recognising nested phrases based on normalised pointwise mutualinformation.
We proved that the method has a strong tendency not to recognise semantically odd phrasesonce they are nested, and allows for the elimination of incorrect unfinished phrases from the top part ofthe ranking list.
The method can be applied to any language: it requires the existence of a POS tagger andseveral rules describing noun phrase structure.
Taking into account information on the internal syntacticstructure of terms improved the results.There are several possible directions for further research.
First, we plan to test the method on differentdatasets.
Then, some extensions of the method are planned.
The potentially easiest one concerns theproblem of how to extend the method to take into account more complex phrases (i.e.
prepositionalphrases and coordinated phrases) and count NPMI effectively for them.
The second problem refers tolonger phrases that are strongly connected but only when all elements appear together.
An example ofsuch a phrase is wyk?adnik stanu zapalnego ?inflammation exponent?
where stan zapalny ?inflammation?can appear in different contexts, but wyk?adnik stanu ?exponent (of the) state?
implies the word zapalny?inflammatory?.
The third problem is to explore whether the proposed method provides a good startingpoint for recognising pieces of information that should be represented in a domain ontology.ReferencesSzymon Aceda?nski.
2010.
A morphosyntactic Brill tagger for inflectional languages.
In Hrafn Loftsson, Eir?kurR?gnvaldsson, and Sigr?n Helgad?ttir, editors, Advances in Natural Language Processing, volume 6233 ofLecture Notes in Computer Science, pages 3?14.
Springer.Alberto Barr?n-Cedeno, Gerardo Sierra, Patrick Drouin, and Sophia Ananiadou.
2009.
An improved automaticterm recognition method for Spanish.
In Computational Linguistics and Intelligent Text Processing, LNCS5449, pages 125?136.
Springer.Gerlof Bouma.
2009.
Normalized (pointwise) mutual information in collocation extraction.
In From Form to40Meaning: Processing Texts Automatically, Proceedings of the Biennial GSCL Conference 2009, volume Nor-malized, pages 31?40, T?bingen.Katerina Frantzi, Sophia Ananiadou, and Hideki Mima.
2000.
Automatic recognition of multi-word terms: theC-value/NC-value method.
Int.
Journal on Digital Libraries, 3:115?130.Kyo Kageura and Bin Umino.
1996.
Method for automatic term recognition.
A review.
Terminology, 3:2:259?289.Ioannis Korkontzelos, Ioannis P. Klapaftis, and Suresh Manandhar.
2008.
Reviewing and evaluating automaticterm recognition techniques.
In Advances in Natural Language Processing, LNAI 5221, volume 5221, pages248?259.
Springer.Christopher D. Manning and Hinrich Sch?tze.
1999.
Foundations of Statistical Natural Language Processing.MIT Press, Cambridge, MA, USA.Ma?gorzata Marciniak and Agnieszka Mykowiecka.
2011.
Towards Morphologically Annotated Corpus of Hos-pital Discharge Reports in Polish.
In Proceedings of BioNLP 2011, pages 92?100.Ma?gorzata Marciniak and Agnieszka Mykowiecka.
2013.
Terminology extraction from domain texts in Polish.In R. Bembenik, L. Skonieczny, H. Rybinski, M. Kryszkiewicz, and M. Niezgodka, editors, Intelligent Toolsfor Building a Scientific Information Platform.
Advanced Architectures and Solutions, volume 467 of Studies inComputational Intelligence, pages 171?185.
Springer-Verlag.Ma?gorzata Marciniak and Agnieszka Mykowiecka.
2014.
Terminology extraction from medical texts in polish.Journal of Biomedical Semantics, 5:24.Patrick Pantel and Dekang Lin.
2001.
A statistical corpus-based term extractor.
In Proceedings of the 14thBiennial Conference of the Canadian Society on Computational Studies of Intelligence: Advances in ArtificialIntelligence, pages 36?46, London, UK, UK.
Springer-Verlag.Maria T. Pazienza, Marco Pennacchiotti, and Fabio M. Zanzotto.
2005.
Terminology Extraction: An Analysis ofLinguistic and Statistical Approaches.
In S. Sirmakessis, editor, Knowledge Mining Series: Studies in Fuzzinessand Soft Computing.
Springer Verlag.Francesco Sclano and Paola Velardi.
2007.
Termextractor: a web application to learn the shared terminologyof emergent web communities.
In Ricardo Jardim-Gon?alves, J?rg P. M?ller, Kai Mertins, and Martin Zelm,editors, Enterprise Interoperability II, pages 287?290.
Springer.Juan A. Lossio Ventura, Clement Jonquet, Mathieu Roche, and Maguelonne Teisseire.
2014.
Towards a mixedapproach to extract biomedical terms from documents.
International Journal of Knowledge Discovery in Bioin-formatics, 4(1).Thuy Vu, Ai Ti Aw, and Min Zhang.
2008.
Term extraction through unithood and termhood unification.
InProceedings of International Joint Conference on Natural Language Processing.Joachim Wermter and Udo Hahn.
2005.
Massive biomedical term discovery.
In Discovery Science, LNCS 3735,pages 281?293.
Springer Verlag.Marcin Woli?nski.
2006.
Morfeusz ?
a practical solution for the morphological analysis of Polish.
In IntelligentInformation Processing and Web Mining.
Proceedings of the International IIS:IIPWM?06 Conference held inUstron, Poland.
Springer-Verlag.41
