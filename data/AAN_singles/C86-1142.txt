The procedure to construct a word predictor in a speech understanding systemfrom a task-specific grammar defined ill a CFG or a DCGYasuhisa Nilmi, Shigeru Uzuhara and Yutaka KobayashiDepartment of Computer ScienceKyoto Institute of TechnologyMatsugasaki, Sakyo-ku, Kyoto 606, JapanAbstractThis paper describes a method for converting atask-dependent grammar into a word predictor of aspeech understanding system, Since tile wordprediction is a top-down operation, left  recursiverules induces an in f in i te  looping.
We have solvedthis problem by applying an algorithm for bottom-upparsing,1.
Introductionwhich tile ends terminate at different portions on thephonetic sequence, and the other represents the se-quences of syntactic categories (called categorysequences), each of which is associated with one ofthe word strings, ln this situation, the controllerchooses the word string with tile highest score,sends tile associated category sequence to the wordpredictor and asks i t  to predict those syntacticcategories which can syntactically follow the se-lected sequence.In this paper we present a method for converting atask-specific gravmnar into a word predictor, an im-portant component of a speech understanding system.A context free grammar (CFG) or an augmented transi-tion network grammar (ATNG) have been used to des-cribe task-speclfic constraint.
When a CFG is used,Early's algorithm\[l\], one of the most eff icient top-down parsing algorithms, has been used to make wordprediction\[2\].
When an ATNG is used, word predictionis simply made by tentatively traveling along arcsgoing out freln a state in an ATNG\[3\],\[4\],\[5\].
Sincethe word prediction is a top-down operation, i t  isd i f f i cu l t  to avoid fal l ing into an inf inite loop i fthe task-specific grammar includes a left  recurslverule.F.
Perelra and D. Warren have developed a definiteclause grammar (DCG)\[6\].
The rules described in a DCGare directly converted into a set of Pro\]og clauses,which works as a parser with an aid of tile powerfulpattern matching mechanism of Prolog.
Thus syntacticanalysis can be done without writing a specia\] parserworking on the rules of the grammar.
Since tile syn-tactic analysis based on a DCG parser also works intop-down fashion, i t  shares the same d i f f i cu l ty  asthe top-down parsers have.
?.
Matsumoto et at.
havedeveloped a method for converting a set of rulesdescribed in a DCG into a bottom-up parser which hasovercome thls d i f f i cu l ty  without any loss of theadvantages of a DCG\[7\].We discuss an application of this method to a wordpredictor, that is, the method for transforming task-specific l inguistic constraint defined in a CFG or aDCG into a Prolog program which acts as a lef t - to-right word predictor.2.
Word predictlon in a ~eech understandlnq~sj(stemFig.l shows a typical configuration of a speechunderstanding system based on a hierarchical model.An acoustic-phonetic processor analyzes of an inpututtereance and transforms i t  into a sequence of pho-netically labeled segments.
Provided that a part ofan utterance has been dealt with, the controllermanages its interpretations in the two kinds of treesi l lustrated in Fig.2; one represents word strings, ofl inguistic processorpredicted categor ies~tegory  sequence~ .
r o l  ler )predicted words T- rocog, i ed wordsI lexlcal processor \]Phonetic latt iceI ac?ustic-ph?neticprocessor Ispeec~ waveFig.
I A typical configuration of a speechunderstanding system.categorytreeword treesequenceofphoneticsegmentsC3 #3Cl #I' ~ C2 '~ ~ ,I \  !
t % i ~  I "?
', /'r" i,l~ .L ~ \ \ IW1i'1 ' I \Fig.
2 A search space of a speech understandingsystem.605The word predictor could parse a given categorysequence and predict the categories which can followi t .
I t  is, however, inefficient to analyze the givensequence whenever asked to predict.
In fact, eachnode of the category tree is associated with a par-sing history on how rules of the grammar have beenapplied to analyze the category sequence.
The wordpredictor receives a node and its parsing historyfrom the controller and predicts the syntactic cate~gories following the node.3_.
The bottom-up parser and its application to wordpredictionWe give a br ie f  explanatlon of the bottom-up par-ser proposed by Y. Matsumoto e ta l .
Assume simplythat the rules of the grammar are described in a CFG.Then, without loss of general i ty  each of the rulescan be expressed as e i ther  of the fol lowings.c -> Cl,C2,..,c n(c, c i (i=l .
.
.
.
n): nonterminals) l)c -> w (w: a terminal) 2)( l )  These rules are transformed into the followingProlog clauses.cI(G,XI,X ) : -  link(c,G),goal(c2,Xi,X2) .
.
.
.goal(cn,Xn_l,Xn), c(G,Xn, X).
l ' )dict(c,\[wJX\],X).
?
')X and X~ (i=l .
.
.
.
n) are arguments to denoteword strifig to be analyzed as a l i s t .
'link(C,G)is a predicate to express that a string of whichthe left  most symbol is a nonterminal C can bereduced to a nonterminal G. G is called a goalargument in this sense. '
l ink '  is defined asfollows: i f  the rule I) is included in the gram-mar, then ' l ink (c l , c ) '  holds, and i f  ' l ink(a,b) 'and ' l ink(b,c) '  &old, then ' l ink(a,c) '  holds(transitive law), and ' l ink(c,c) '  holds for everynonterminal c (reflective law).
A predicate'dict(C,X,Y)', searching the dictionary for thef i r s t  word of a word string X, unifies C with itssyntactic category and Y with the remainingstring.
(2) A predicate goal(G,X,Z) is defined as follows.goal(G,X,Z) :-  dict(C,X,Y),link(C,G),exec(C,G,Y,Z).
3)where 'exec' is a predicate to execute a predi-cate 'c(G,Y,Z)'.
(3) Furthermore, fGr any nonterminal C, the fol-lowing assertion called a terminal conditionholds:c(c,X,X).
4)The parser for the given grammar consists of al lthese Prolog clauses.In order to use the bottom-up parser as a lef t -to-right word predictor, we change the predicate'goal' as follows:goal(G,\[ \] , \ [ \ ])  : -  llnk(C,G),terminal(C),output(C),fai}.
3 ' - I )606goal(G,X,Z) : -  dict(C,X,Y),link(C,G),exec(C,G,Y,Z).
3'-2)where 'terminal(C)' is a predicate to be true when anonterminal C appears in the left-hand side of aproductlonof 2).The modified parser, receiving a word string fromthe controller, executes the second of 'goal' clausesin which the second argument X is unified with thegiven word string.
Syntactic analysis of X is con-tinued until X becomes empty.
Then, the f i r s t  of'goal' clauses is invoked and predicts all the syn-tactic categories which make both 'link(C,G)' and'terminal(C)' hold.4.
Word grediction under a le f t - to - r i~In this section we discuss the method for conver-tion of a set of productions defined in a CFG into aset of Prolog clauses which acts as a lef t - to-r ightword predictor.
In order that this predictor can workwithout re-analyzing a given category sequence, wemust )lave a table (named a history table) whichcontains an association of a category sequence withits parsing history, that is, a history on how pro-ductions are used to parse the sequence.Considering a transition network depicted in Fig.3for a production 'c->clc~..c ', we express a parsinghistory with a l i s t  of Lpai~s of a state name in atransition network and a goal argument appearing inbottom-up parsing.
For the grammar shown in Fig.4, acategory sequence 'N N' is parsed as shown inFig.5(a) and the corresponding state transition isshown in Fig.5(b).
A parsing history for this se-quence can be expressed as a l i s t  \[nps2,s\].
Thestate name 'nps2' indicates that the last 'N' of theC l C 2 C nFig.
3 A transition network for a ruleC - ,  C I C 2 .
.
.
C n.S -> NP VP NP -> NNP -> NP N VP -> V NPNP -> ART NPFig.
4 An example of context free grammar.. ~.>_>-.s /IN N(a) (b)Fig.
5 The parse tree of 'N N' and thecorresponding state transition.sequence 'N N' has been parsed as 'N' in the produc-Lion 'NP->NP N', and the goal a rgument ' s '  indicatesthat the sequence is the le f t  most part of the str ingderived by the s tar t  symbol ' s ' .Now we shal l  describe the procedure to transform aset of productions described in a CFG into  a wordpredictor .
( I )  For a production 'c ->c.c~.
.c  ', tile fo l lowing set?
/ L: n of Prolog clauses Is generated:cI(\[GIH\]) :- link(c,G),al(\[GIHI).al(E ) :-.
pred(c2,\[a21E\]).a2(E ) :-- pred(c3,\[a31E\]),an~l(E) : -  pred(cn,\[anJE\]) ,an(E) : - c (E ) .
4 - I )where H and E are the arguments to store parsingh i s to r ies ,  the f i r s t  element of H is a state nameand that of E is a goal argument.
(2) For a nonterminal c, the fo l lowing terminal con-d i t ion  holds:c(\[c,alE\]) :- exec(a,E), 4-2)(3) Corresponding to 'goal '  in the bottom-up parser,a predicate 'pred' is defined as fo l lows:pred(G,H) : -  l ink(C,G) , terminal (C) ,newface(No),hand to(No,C),makenode(No,C,\[GTH\]),fail.
4-3)A predicate 'newface(No)' generates a new nodenumber in 'No', 'hand_to(No,C)' sends a pair  of anode number 'No' and a predicted syntact ic  cate-gory C to the cont ro l le r ,  and 'makenode()' storesa node number and i t s  corresponding parsing his-tory  expressed as 'C(\[GIN\]) '  in the h i s to rytable.
(4) The cont ro l le r  in a speech understanding systemcommunicates the word predictor  through a predi -cate 'wantword' which sends to the word predictora node number associated with a category sequencewhich the cont ro l le r  has selected, whi le the wordpredictor  returns through 'hand to '  a set of thesyntact ic  categories which can fo l low the se-lected category sequence.
The de f in i t ion  of'wantword' is as follows:wantword(O) : -  !
,p red(s , \ [ \ ] ) .
4-4)wantword(No) : -  p ick_up(No,Z) , !
,ca l l (Z) .
4-5)The symbol s in 4-4) s ign i f ies  the s tar t  symbol,and the clause 4-4) is used to make a pred ict ionat the le f t  most part  of an utterance.
Thepredicate 'pick up(No,Z)' looks up the h is torytable  for  a node number 'No', and picks up i tsassociated h is tory  expressed as 'C( \ [GIH\] ) ' ,  theexecution of which invokes the clause of 4 - I )  or4-2).5.
ConclusionsIn this paper we have proposed the procedure toconvert a grammar defined in a CFG or a DCG into aProlog program which functions as a word predictor .The procedure is give@ for the le f t - to - r ight  contro l ,but i t  is not d i f f i cu l t  to expand i t  for the is land-driven contro l .To s impl i fy  the descr ipt ion,  we have given theconversion procedure for a grammar defined in a CFG,but i t  is easy to expand i t  for  a grammar defined ina DCG, As long as one concernes on a speech under-standing system in which syntax and semantics arewell defined, one could take an advantage of a DCG inwhich a nonterminal can have some arguments as para-meters, and could use semantic res t r i c t ions  e f fec -t i ve ly  to in terpret  an utterance.
In developing aspeech understanding system of which the task is toaccess a database, we use semantic markers to des-cribe semantic res t r i c t ions  between an ad ject ive  anda noun, a noun phrase and a postposit ion ( in  Japan-ese), and case slots of a verb and i ts  f i l l e rs .
Inth is  case a rule can be expressed as fol lows:C(So) -> \[Po(So, S I )}CI (S I ){PI (S I ,S2)}C2(S2) .
.
.
{Pn_l(Sn_l,Sn))Cn(Sn),where S~ ( i=O,l  .
.
.
.
n) is a l i s t  of semantic markers,Pi ( i= l ,2  .
.
.
.
n) is a predicate to denote a constra intamong semantic markers.
Considering a t rans i t ionnetwork for  th is  DCG rule,  we associate P. with i ts  \]i - th  state and le t  Pi function as a converter ofsemantic markers.
Since Pi would be defined in theform of a table,  this converter could workb id i rec t iona l ly .
In addit ion,  stacking a pair" of asyntact ic goal var iab le  and a l i s t  of semanticmarkers in the parsing h is tory ,  we can develop aprocedure to transform a grammar described in a DCGinto a word predictor .AcknowledgementThis research was supported by the grant - in -a idfor the special pro ject  research ' In te l l igent  Proces-sing and Integrat ion of Knowledge Informations inMult i -Media'  by the Min is t ry  of Education, Scienceand Culture of Japan.References\ [ I \ ]  J.
Early: An e f f i c ient  context - f ree parsing algo-rithm, Comm, ACM, 13--2 (1970).\[2\] T. Sakai and S. Nakagawa: A speech understandingsystem of simple Japanese sentences in a taskdomain, Trans.
of IECEJ, E60-1 (1977).\[3\] W.A.
Woods et a l .
:  Speech understanding systems- -  Final technical progress report 30 October1974 to 29 October 1976, BBN Tech.
Rep.  3438,vol .
4 (1976).\[4\] D.R.
Reddy et a l .
;  Speech understanding system- -  Summary of results  of tile f i ve  year researche f fo r t  at Carnegie-Me\]Ion Univ., Carnegie-MellonUniv.
Tech.
Rep. (1977).\[5\] Y. Niimi and Y. Kobayashi: A vo ice- input  program-ming system using BASIC-like language, Proc.
IEEEInt .
Conf.
ASSP (1978).\[6\] F.C.N.
Pereira and D.II.D.
Warren: Def in i te  clausegrammar for language analysis - -  A survey of theformalism and comparison with augmented t rans i -t ion networks, Ar t i f i c ia l  In te l l igence,  13(1980).\[7\] Y. Matsumoto et a l .
:  BUP ---A bottom-up parserembedded in Prolog, New Generation Computing, I -2(1983).607
