SESSION 14: NEW DIRECTIONS/APPLICATIONSRichard Stern, ChairDepartment of  Electrical and Computer Engineeringand School of  Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213As in recent years, the last session of the Workshop focussed onnew directions and unusual appfications of spoken language tech-nology.
Five papers were presented.One of the highlights of the meeting was a presentation by JuliePayette, an astronaut for the Canadian Space Agency, who dis-cussed the use of speech recognition i  space travel.
Some of thereasons why voice input and output are potentially valuable inspace include the naturalness of the speech modality, the need tohave hands and eyes available for performing applications tasks,and the overwhelming number of displays and controls to be inter-rogated and manipulated.
The harsh environment of space and thesevere consequences of failure demand that designers producesystems that are highly accurate, reliable, and robust.Payette described a pilot experiment in which a commercialspeaker-dependent isolated-word ecognizer was used to controlthe position and functions of the closed-circuit television system.While subjective reports by the users were favorable, it is clearthat accuracy and reliability will have to increase for speech to beused to control mission-critical functions.
Recognition accuracydid not appear to be adversely affected by the microgravity envi-ronment in space.The second paper, presented by Suzanne Liebowitz Taylor of Uni-sys, described recent progress in Unisys's ongoing work on intelli-gent document understanding.
The long-term goal of this researchhas been to develop methodologies for analyzing, classifying, andsummarizing text from printed ocuments for which on-line ver-sions are not available.This paper discussed three ways in which natural language under-standing techniques was used to augment image analysis.
First, acombination of string-matching techniques, imple grammars, andstatistical nalysis of syntactic structure were used to re-integratetext which had been fragmented into physically-separated s g-ments, as is commonly the case for stories that are written for pop-ular magazines.
Second, the PUNDIT natural language systemwas employed to correct errors introduced in the optical characterrecognition process.
The use of natural language reduced errorrate by more than 15 percent in an ATIS-like task for scanned text,compared to the error rate obtained using spelling correctionalone.
Third, case-frame parsing was used to provide semanticanalysis of scanned ocuments.
Two applications were describedin the areas of text retrieval and hypertext generation.The next two papers, from SUNY Buffalo and BBN, eachdescribe ways in which speech recognition technology has beenapplied to the automatic recognition of handwritten text.
JohnMakhoul described an extremely interesting demonstration byThad Starner and colleagues at BBN that "with essentially nomodification, a speech recognition system can perform accurateon-line handwriting recognition".Starner and colleagues used conventional HMM techniques torecognize continuous cursive writing on a writer-independentbasis.
The features used for classification i cluded the temporalevolution of the writing angle and its derivative, as well aschanges of pen position, and identified pen up/pen down events.Homologs for handwriting analysis were developed for the famil-iar phonetic models, representations of context dependencies, andstatistical grammars.
The system was trained and tested on writtensentences derived from the ATIS and WSJ tasks.
It was found thatthe use of both context and statistical grammar provided markedimprovements to recognition accuracy.
Observed word error rateswere 1.1 percent for the 3050-word, 52-symbol ATIS task, and4.1 percent for the 25,000-word, 86-symbol WSJ task, using aversion of BYBLOS with virtually no fine tuning for cursivehandwriting.The work described by Rohini Srihari of SUNY Buffalo focuseson the improvement torecognition accuracy for handwriting thatcan be obtained by application of two rule-based and statisticalsyntactic analysis procedures.
The first procedure isbased on themutual information associated with word collocations within aphrase.
The use of collocation information increased provided a16.%percent relative decrease of errors among top-choice wordcandidates.
Under some circumstances this information can alsobe used to insert highly-probable visually-confusible altemates tothe hypothesized words.
The second approach made use a statisti-cal model of syntax based on part-of-speech (POS) tags.
Theresults reconfirm that the use of statistical grammars can siguifi-candy improve recognition accuracy.The final paper of the Workshop, presented by Steve Lowe ofDragon Systems, concerned the use of large-vocabulary speechrecognition systems to perform language identification, based oncumulated likelihood scores.
To redoce the confounding variabil-ity introduced by differences in the quality of the acoustic match,normalized scores are obtained by dividing by the best-pessibleacoustic score on a frame-by-frame basis.
This strategy producedgood results in performing English-Spanish discriminations forhigh-query speech in WSJ-type domain, but the results of subse-quent experiments using telephone speech and a less restricteddomain were more ambiguous.
It is believed that this approachremains apromising one and work is continuing on the topic.415
