Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 1511?1521, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsA Discriminative Model for Query Spelling Correction with LatentStructural SVMHuizhong Duan, Yanen Li, ChengXiang Zhai and Dan RothUniversity of Illinois at Urbana-Champaign201 N Goodwin AveUrbana, IL 61801{duan9, yanenli2, czhai, danr}@illinois.eduAbstractDiscriminative training in query spelling cor-rection is difficult due to the complex inter-nal structures of the data.
Recent work onquery spelling correction suggests a two stageapproach a noisy channel model that is usedto retrieve a number of candidate corrections,followed by discriminatively trained rankerapplied to these candidates.
The ranker, how-ever, suffers from the fact the low recall of thefirst, suboptimal, search stage.This paper proposes to directly optimize thesearch stage with a discriminative modelbased on latent structural SVM.
In this model,we treat query spelling correction as a multi-class classification problem with structured in-put and output.
The latent structural informa-tion is used to model the alignment of wordsin the spelling correction process.
Experimentresults show that as a standalone speller, ourmodel outperforms all the baseline systems.
Italso attains a higher recall compared with thenoisy channel model, and can therefore serveas a better filtering stage when combined witha ranker.1 IntroductionQuery spelling correction has become a crucial com-ponent in modern information systems.
Particularly,search engine users rely heavily on the query cor-rection mechanism to formulate effective queries.Given a user query q, which is potentially mis-spelled, the goal of query spelling correction is tofind a correction of the query c that could lead to abetter search experience.
A typical query spellingcorrection system employs a noisy channel model(Kernighan et al 1990).
The model assumes thatthe correct query c is formed in the user?s mind be-fore entering the noisy channels, e.g., typing, andget misspelled.
Formally, the model maximizes theposterior probability p(c|q):c?
= arg maxcp(c|q).
(1)Applying Bayes rule, the formulation can berewritten as:c?
= arg maxcp(q|c)p(c)= arg maxc[log p(q|c) + log p(c)].
(2)The model uses two probabilities.
The prior prob-ability p(c) represents how likely it is that c is theoriginal correct query in the user?s mind.
The prob-ability is usually modeled by a language model es-timated from a sizable corpus.
The transformationprobability p(q|c) measures how likely it is that q isthe output given that c has been formed by the user.This probability can be either heuristic-based (editdistance) or learned from samples of well alignedcorrections.
One problem with the noisy channelmodel is that there is no weighting for the two kindsof probabilities, and since they are estimated fromdifferent sources, there are usually issues regardingtheir scale and comparability, resulting in subopti-mal performance (Gao et al 2010).
Another limita-tion of this generative model is that it is not able totake advantage of additional useful features.1511A discriminative model may solve these problemsby adding the flexibility of using features and apply-ing weights.
But training such a model is not easy.The difficulty is that the output space of query cor-rection is enormous, as the candidate corrections foreach a query term could be the entire vocabulary.This is even worse when word boundary errors (i.e.merging and splitting of words) exist.
The problemis intractable with standard discriminative models aswe cannot enumerate every candidate correction.To solve the problem, (Gao et al 2010) proposeda two stage approach.
In this approach, a ranker istrained to score each candidate correction of a query.When a query is issued, the system first uses thenoisy channel model with a standard search algo-rithm to find the 20 best candidates.
Then the rankeris used to re-rank these candidates and find the bestcorrection for the query.
This ranker based systemhas one critical limitation, though.
Since the rankingstage is decoupled from the search, it relies on theoutsourced search algorithm to find the candidates.Because query spelling correction is an online oper-ation, only a small number of candidates can enterthe ranker due to efficiency concerns, thus limitingthe ability of the ranker to the ceiling of recall set bythe suboptimal search phase.The research question we address here is whetherwe can directly optimize the search phase of queryspelling correction using a discriminative modelwithout loss of efficiency.
More specifically, wewant 1) a learning process that is aware of thesearch phase and interacts with its result; 2) an ef-ficient search algorithm that is able to incorporatethe learned model and guide the search to the targetspelling correction.In this paper, we propose a new discriminativemodel for query correction that maintains the ad-vantage of a discriminative model in accommodat-ing flexible combination of features and naturally in-corporates an efficient search algorithm in learningand inference.
Similarly to (Chang et al 2010) wecollapse a two stage process into a single discrim-inatively trained process, by considering the outputof the first stage as an intermediate latent represen-tation for the joint learning process.
Specifically, wemake use of the latent structural SVM (LS-SVM)(Yu and Joachims, 2009) formulation.
We formu-late the problem query spelling correction as a multi-class classification problem on structured inputs andoutputs.
The advantage of the structural SVM modelis that it allows task specific, customizable solutionsfor the inference problem.
This allows us to adaptthe model to make it work directly with the searchalgorithm we use for finding the best correction ofthe query.
To account for word boundary errors, wemodel the word alignment between the query andthe correction as a latent structural variable.
TheLS-SVM model allows us to jointly search over theoutput space and the latent structure space.As the inference algorithm in the proposed dis-criminative model we use an algorithm that resem-bles a traditional noisy channel model.
To adaptthe LS-SVM model to enable the efficient search ofquery spelling correction, we study how features canbe designed.
We analyze the properties of featuresthat can be used in the search algorithm and proposea criteria for selecting and designing new features.We demonstrate the use of the criteria by design-ing separate features for different types of spellingerrors (e.g.
splitting, merging).
With the proposeddiscriminative model, we can directly optimize thesearch phase of query spelling correction withoutloss of efficiency.
Our model can be used not only asa standalone speller with high accuracy, but also asa high recall candidate generation stage for a rankerbased system.Experiments verify the effectiveness of the dis-criminative model, as the accuracy of correction canbe improved significantly over baseline systems in-cluding an award winning query spelling system.Even though the optimization is primarily based onthe top correction, the weights trained by LS-SVMcan be used to search for more candidate corrections.The improvement in recall at different levels over thenoisy channel model demonstrates that our model issuperior even when used in the two-stage approach..2 Related WorkSpelling correction has a long history (Levenshtein,1966).
Traditional techniques were on small scaleand depended on having a small trusted lexicons(Kukich, 1992).
Later, statistical generative mod-els were shown to be effective in spelling correc-tion, where a source language model and an er-ror model were identified as two major components1512(Brill and Moore, 2000).
Note that we are not deal-ing here with the standard models in context sen-sitive spelling (Golding and Roth, 1999) where theset of candidate correction is a known ?confusionset?.
Query spelling correction, a special form ofthe problem, has received much attention in recentyears.
Compared with traditional spelling correc-tion task, query spelling deals with more complextypes of misspellings and a much larger scale of lan-guage.
Research in this direction includes utiliz-ing large web corpora and query log (Chen et al2007; Cucerzan and Brill, 2004; Ahmad and Kon-drak, 2005), employing large-scale n-gram models,training phrase-based error model from clickthroughdata (Sun et al 2010) and developing additional fea-tures (Gao et al 2010).Query alteration/refinement is a very relevanttopic to query spelling correction.
The goal ofquery alteration/refinement is to modify the inef-fective query so that it could .
Researches on thistrack include query expansion (Xu and Croft, 1996;Qiu and Frei, 1993; Mitra et al 1998), query con-traction(Kumaran and Allan, 2008; Bendersky andCroft, 2008; Kumaran and Carvalho, 2009) andother types of query reformulations for bridging thevocabulary gap (Wang and Zhai, 2008).
(Guo et al2008) proposed a unified model to perform a broadset of query refinements including correction, seg-mentation and stemming.
However, it has very lim-ited ability in query correction.
In this paper, westudy the discriminative training of query spellingcorrection, which is potentially beneficial to manyexisting studies.Noisy channel model (or source channel model)has been widely used in NLP.
Many approaches havebeen proposed to perform discriminative training ofthe model (McCallum et al 2000; Lafferty, 2001).However, these approaches mostly deal with a rela-tively small search space where the number of can-didates at each step is limited (e.g.
POS tagging).
Atypically used search algorithm is dynamic program-ming.
In spelling correction, however, the searchspace is much bigger and the existing approachesfeaturing dynamic programming are difficult to beapplied.Structural learning and latent structural learninghas been studied a lot in NLP in recent years(Changet al 2010; Dyer et al 2011), and has beenshown to be useful in a range of NLP applicationsfrom Textual Entailment, Paraphrasing and Translit-eration (Chang et al 2010) to sentiment analysis(Yessenalina et al 2010).Work has also been done on integrating discrimi-native learning in search.
Freitag and Khadivi used aperceptron algorithm to train for sequence alignmentproblem.
A beam search algorithm was utilized inthe search (Freitag and Khadivi, 2007).
Daume etal.
proposed the Searn framework for search basedstructural prediction (Daume et al 2009).
Ourmodel differs from the Searn framework in that itlearns to make global decisions rather than accumu-lating local decisions.
The global decision was madepossible by an efficient search algorithm.Query spelling correction also shares many sim-ilarities with statistical machine translation (SMT).Sun et al(2010) has formulated the problem withinan SMT framework.
However, SMT usually in-volves more complex alignments, while in queryspelling correction search is the more challengingpart.
Our main contribution in this paper is a novelunified way to directly optimize the search phase ofquery spelling correction with the use of LS-SVM.3 Discriminative Model for Query SpellingCorrection Based on LS-SVMIn this section, we first present the discriminativeformulation of the problem of query spelling correc-tion.
Then we introduce in detail the model we usefor solving the problem.3.1 The Discriminative Form of Query SpellingCorrectionIn query spelling correction, given a user enteredquery q, which is potentially misspelled, the goal isto find a correction c, such that it could be a moreeffective query which improves the quality of searchresults.
A general discriminative formulation of theproblem is of the following form:f(q) = arg maxc?V?
[w ??
(q, c)], (3)where ?
(q, c) is a vector of features and w is themodel parameter.
This discriminative formulation ismore general compared to the noisy channel model.It has the flexibility of using features and applying1513weights.
The noisy channel model is a special caseof the discriminative form where only two features,the source probability and the transformation proba-bility, are used and uniform weightings are applied.However, this problem formulation does not give usmuch insight on how to proceed to design the model.Especially, it is unclear how ?
(q, c) can be com-puted.To enhance the formulation, we explore the factthat spelling correction follows a word-by-word pro-cedure.
Let us first consider a scenario where wordboundary errors does not exist.
In this scenario,each query term matches and only matches to a sin-gle term in the correction.
Formally, let us denoteq = q1, ..., qn and c = c1, ..., cm as structured ob-jects from the space of V?, where V is our vocabu-lary of words and V?
is all possible phrases formedby words in V .
Both q and c have an intrinsic se-quential structure.
When no word boundary errorexists, |c| = |q| holds for any candidate correctionc.
qi and ci establish a one-to-one mapping.
In thiscase, we have a more detailed discriminative form:f(q) = arg maxc?V|q|[w ?
(?0 +|q|?i=1?1(qi, ci))], (4)where ?0 is a vector of normalizing factors,?1(qi, ci) is the decomposed computation of ?
(q, c)for each query term qi and ci, for i = 1 to |q|.Equation 4 is a clearer formulation.
The majorchallenge of solving this discriminative problem isthe complexity.
Theoretically, each term has |V|candidates and it is impossible to enumerate overall possible combinations.
To make it even worse,merging and splitting errors are quite common inmisspelling.
As a result, the assumption of one-to-one mapping does not hold in practice.To account for these word boundary errors andenhance the discriminative formulation, we intro-duce a latent variable a to model the unobservedstructural information.
More specifically, a =a1, a2, ...a|a| is the alignment between q and c. Eachalignment node at is a represented by a quadruple(qstart, qend, cstart, cend).
Figure 1 shows a com-mon merge error and its best alignment.
The phrase?credit card?, in this case, is incorrectly merged intoone word ?creditcard?
by the user.
Figure 2 showsFigure 1: Example of Merge Error and AlignmentFigure 2: Example of Split Error and Alignmentthe best alignment for a common split error, wherethe word ?gamespot?
is incorrectly split into a twoword phrase ?game spot?.Taking into consideration the latent variable, wearrive at our final discriminative form of queryspelling correction:f(q) = arg max(c,a)?Vn?A[w ??
(q, c, a)]= arg max(c,a)?V?
?A[w ?
(?0+?|a|t=0 ?1(qat , cat , at))],(5)The challenges of successfully applying a dis-criminative model to this problem formulation are1) how can we design a learning algorithm to learnthe model parameter w to directly optimize the max-imization problem; 2) how can we solve the maxi-mization efficiently without having to enumerate allcandidates; 3) how can we design features to guar-antee the correctness of the search algorithm.
In thefollowing subsections we introduce our solutions tothe three challenges in detail.3.2 Latent Structural SVMWe employ the latent structural SVM (LS-SVM)model for learning the discriminative model of queryspelling correction.
LS-SVM is a large marginmethod that deals with structured prediction prob-lems with latent structural information (Yu andJoachims, 2009).
LS-SVM has the merit of allowing1514task specific, customizable solutions for the infer-ence problem.
This makes it easy to adapt to learn-ing the model parameters for different problems.The following is a brief introduction of LS-SVMthat largely mirrors the work by (Yu and Joachims,2009).Without loss of generality, let us aim at learninga prediction function f : X ?
Y that maps inputx ?
X to an output y ?
Y with latent structuralinformation h ?
H. The decision function is of thefollowing form:f(x) = arg max(y,h)?Y?H[w ??
(x, y, h)], (6)where ?
(x, y, h) is the set of feature functions de-fined jointly over the input x, the output y and thelatent variable h. w is the parameter of the model.Given a set of training examples that consist of inputand output pairs {(x1, y1), ...(xn, yn)} ?
(X ?Y)n,the LS-SVM method solves the following optimiza-tion problem:minw12?w?2+Cn?i=1max(y?,h?
)?Y?H[w ??
(xi, y?, h?)
+ ?
(yi, y?
)]?Cn?i=1maxh?H[w ??
(xi, yi, h)],(7)where ?
(yi, y?)
is the loss function for the ith ex-ample.
The details of the derivation is omitted inthis paper.
Readers who are interested can read morefrom (Yu and Joachims, 2009).There are two maximization problems that are es-sential in Equation 7.
The first one is the loss aug-mented decision function:max(y?,h?
)?Y?H[w ??
(xi, y?, h?)
+ ?
(yi, y?
)], (8)and the second is the inference of latent variablegiven the label of the training data:maxh?H[w ??
(xi, yi, h)].
(9)The Latent Structural SVM framework does notspecify how the maximization problems in Equation8 and Equation 9 are solved, as well as the infer-ence problem in 6.
These maximization problemsare task dependent.
Being able to efficiently solvethem is the key to successfully applying the LatentStructural SVM method.
We will show in detail howwe solve these maximization problems to make LS-SVM work for query spelling correction in the fol-lowing subsection.For training the LS-SVM model, a Concave-Convex Procedure (CCCP) was proposed to solvethis optimization problem (Yu and Joachims, 2009).The method resembles the Expect-Maximization(EM) training method as it updates the model by it-eratively recomputing the latent variable.
However,rather than performing ?sum-product?
training as inEM where a distribution over the hidden variable ismaintained, the CCCP method used for LS-SVM ismore similar to the ?max-product?
paradigm wherewe ?guess?
the best hidden variable in each iteration,except here we ?guess?
by minimizing a regularizedloss function instead of maximizing the likelihood.3.3 Solving the Inference ProblemsThe essential inference problem is to find the correc-tion that maximizes the scoring function accordingto the model (i.e., the decision function in Equation6).
For this purpose we design a best first search al-gorithm similar to the standard search algorithm inthe noisy channel model.
The essence of the searchalgorithm is to bound the score of each candidateso that we could evaluate the most promising candi-dates first.
The algorithm is given in Algorithm 1.Essentially, the algorithm maintains a priorityqueue of all search paths.
Each time the best path isde-queued, it is expanded with up to m ?
1 wordsin q by searching over a vocabulary trie of up tom-gram.
Each path is represented as a quadruple(pos, str, sc, a), representing the current term posi-tion in query, the string of the path, the path?s scoreand the alignment so far.
The priority queue is sortedaccording to the score of each path in descending or-der.
The GetSuggestions() function retrieves thetop n similar words to the given word with a vocab-ulary trie according to an error model.Splitting errors are dealt with in Algorithm 1 by?looking forward?
m words in the query when gen-erating candidate words.
Merging errors are ac-counted for by including up to m-gram in the vocab-1515ulary trie.
It is worth mentioning that performanceof Algorithm 1 could be further improved by com-puting heuristic scores for each path.Algorithm 1: Best First Search AlgorithmInput: Vocabulary Trie V , query q, output size k,max order m, candidate pool size nOutput: List l of top k corrections for q1 Initialize List l;2 Initialize PriorityQueue pq;3 Enqueue to pq a start path with position set to 0,string set to empty string, score set to w ?
?0, andpath alignment set to empty set;4 while pq is not Empty do5 Path pi ?
pq.Dequeue();6 if pi.pos < q.terms.length then7 for i?
0 tom do8 ph?
q.terms[pi.pos+ 1...pi.pos+ i];9 sug ?
GetSuggestions(ph, V, n);10 foreach s in sug do11 pos?
?
pi.pos+ i;12 str?
?
concat(pi.str, s.str);13 a?
?
pi.a ?
s.a;14 sc?
?
pi.sc+w ?
?1(qs.a, cs.a, s.a);15 Enqueue pq with the new path(pos?, str?, sc?, a?
);16 else17 Add suggestion string pi.str to l;18 if l.Count > k then return l;19 return l;As Algorithm 1 originates from the noisy channelmodel, the two known features that work with thealgorithm are log p(c) and log p(q|c) from the noisychannel model.
However, it is unknown whetherother features can work with the search algorithmand how we can develop new features to ensure it.After analyzing the properties of the features and thesearch algorithm, we find that a feature ?
has to sat-isfy the following monotonicity constraint in orderto be used in Algorithm 1.Monotonicity Property.
Given query q, forany alignment At = At?1 ?
{at} at time t,?
(qAt , cAt , At) ?
?
(qAt?1 , cAt?1 , At?1), whereqAt is the concatenation of qa0 to qat and cAt is theconcatenation of ca0 to cat .That is, the value of the feature (which is com-puted in an accumulative manner) cannot increaseas the candidate is extended with a new term atany search step.
This ensures that the score of thebest candidate at any search step is guaranteed to behigher than the score of any future candidates.
Italso implies ?t(qat , cat , at) ?
0 for any t ?
T .
Themonotonicity feature ensures the correctness of Al-gorithm 1.
We show how we design features withthe guidance of the monotonicity constraint in Sec-tion 4.The solution to to the loss augmented inferencedepends on the loss function we use.
In spelling cor-rection, usually only one correction is valid for aninput query.
Therefore, we apply the 0-1 loss to ourmodel:?
(c, c?)
={0 c = c?1 c 6= c?
(10)Given this loss function, the loss augmented infer-ence problem can be solved easily with an algorithmsimilar to Algorithm 1.
This is done by initializingthe loss to be 1 at the beginning of each search path.During the search procedure, we check if the lossdecreases to 0 given the correction string so far.
Ifthis is the case, we decreases the score by 1 and addthe path back to the priority queue.
More advancedfunctions may also be used (Dreyer et al 2006),which may lead to better training performance.
Weplan to further study different loss functions in ourfuture work.The inference of the latent alignment variable canbe solved with dynamic programming, as the num-ber of possible alignments is limited given the queryand the correction.4 FeaturesIn the following discussions, we will describe howthe features in our discriminative model are devel-oped under the guidance of the monotonicity con-straint.4.1 Source Probability and TransformationProbabilityWe know from empirical experience that the sourceprobability and the transformation probability arethe two most important features in query spellingcorrection.
We include them in our model in a nor-malized form.
Taking the source probability for ex-ample, we define the following feature:1516?
(q, c, a) = ?+?|a|1 log p(c)?= 1 +?|a|1log p(c)?
,(11)where ?
is a normalizing factor computed as:?
= ?|q| log pmin, (12)where pmin is the smallest probability we use inpractice.The formula fits the general form we define in 5in that ?0 = 1 and ?1(qat , cat , at) =log p(c)?
for anyt = 1 to |a|.Similarly, we have the follow feature for the trans-formation probability:??
(q, c, a) = ?+?|a|1 log p(q|c)?= 1 +?|a|1log p(q|c)?
.
(13)We use the web Microsoft n-gram model1 to com-pute source model p(c).
We train the unigram trans-formation model for the transformation probabilityp(q|c) according to (Duan and Hsu, 2011).In generative models, we treat transformationprobabilities from merging and splitting errors in thesame way as single word errors.
In our discrimi-native model we can assign separate weight to thetransformation probabilities resulted from differenttypes of errors.
This allows fine tuning of the queryspelling correction system, making it more adaptiveto environments where the ratio of different types oferrors may vary.
Moreover, the model also allowsus to include language models trained over differentresources, such as query log, title of webpages oranchor texts.4.2 Local Heuristic FeaturesDespite the goal of query spelling correction is todeal with misspellings, in real world most queriesare correctly spelled.
A good query spelling correc-tion system shall prevent as much as possible frommisjudging an correctly spelled query as misspelled.With this idea in mind, we invent some heuristicfunctions to avoid misjudging.1http://research.microsoft.com/en-us/collaboration/focus/cs/web-ngram.aspxLocal Heuristic 1.
When a query term is matchedagainst trustable vocabulary, it increases the chancethat the term is already in its correct form.
For ex-ample, we extract a reliable vocabulary from the titlefield of Wikipedia2.
We therefore design the follow-ing feature:?
(q, c, a) = 1 +|a|?t=1?1(qat , cat , at), (14)where ?1(qat , cat , at) is defined as:?1(qat , cat , at) =??
?0 qat /?
W0 qat ?
W, qat = ct?
1|q| qat ?
W, qat 6= cat(15)where W is the vocabulary of Wikipedia titles.Since |q| > |a| always holds, the feature is normal-ized between 0 and 1.Local Heuristic 2.
Another heuristic is thatwords with numbers in it, despite usually not in-cluded in any vocabulary, should be treated care-fully as they tend to be correct words.
Such wordscould be a model, a serial number or a special en-tity name.
Since the number keys on keyboard areaway from the letter keys, they are more likely to beintentionally typed in if found in user queries.
Simi-lar to Heuristic 1, we design the following feature tocapture this heuristic:??
(q, c, a) = 1 +|a|?t=1?
?1(qat , cat , at), (16)where ?
?1(qat , cat , at) is defined as:?
?1(qat , cat , aat) =??
?0 [0...9] /?
qat0 [0...9] ?
qat , qat = cat?
1|q| [0...9] ?
qat , qat 6= cat(17)4.3 Global Heuristic FeaturesSome global heuristics are also important in queryspelling correction.
For instance, the total number2http://www.wikipedia.org1517of words being corrected in the query may be anindicator of whether the system has leaned towardsovercorrecting.
To account for this global heuristic,we design the following feature:?
(q, c, a) ={1 wc(q, c, a) < wcmax0 otherwise(18)where wc(q, c, a) is the number of word changesat step t, wcmax is the maximum number of wordchanges we allow in our system (in a soft way).
Sim-ilarly, other thresholded features can be designedsuch as the number of total edit operations.
The useof global features is similar to the use of loss func-tion in the search algorithm.5 ExperimentsIn order to test the effectiveness and efficiency of ourproposed discriminative training method, in this sec-tion we conduct extensive experiments on two webquery spelling datasets.
Below we first present thedataset and evaluation metrics, followed by the ex-periment results on query spelling correction.5.1 Dataset PreparationThe experiments are conducted on two queryspelling correction datasets.
One is the TRECdataset based on the publicly available TRECqueries (2008 Million Query Track).
This datasetcontains 5892 queries and the corresponding correc-tions annotated by the MSR Speller Challenge 3 or-ganizers.
There could be more than one plausiblecorrections for a query.
In this dataset only 5.3% ofqueries are judged as misspelled.We have also annotated another dataset that con-tains 4926 MSN queries, where for each query thereis at most one correction.
Three experts are involvedin the annotation process.
For each query, we con-sult the speller from two major search engines (i.e.Google and Bing).
If they agree on the returnedresults (including the case if the query is just un-changed), we take it as the corrected form of the in-put query.
If the results are not the same from thetwo, as least one human expert will manually anno-tate the most likely corrected form of the query.
Fi-nally, about 13% of queries are judged as misspelled3http://web-ngram.research.microsoft.com/spellerchallenge/in this dataset, which is close to the error rate of realweb queries.
We?ve made this dataset publicly avail-able to all researchers4.Both the two datasets are split randomly into twoequal subsets for training and testing.5.2 Evaluation MetricsWe evaluate our system based on the evaluation met-rics proposed in Microsoft Speller Challenge, in-cluding expected precision, expected recall and ex-pected F1 measure.Let q be a user query and C(q) = (c1, c2, , ck)be the set of system output with posterior probabil-ities P (ci|q).
Let S(q) denote the set of plausiblespelling variations annotated by the human expertsfor q.
Expected Precision is computed as:Precision =1|Q|?q?Q?c?C(q)Ip(c, q)P (c|q), (19)where Ip(c, q) = 1 if c ?
S(q), and 0 otherwise.And expected recall is defined as:Recall =1|Q|?q?Q?a?S(q)Ir(C(q), a)/|S(q)|, (20)where Ir(C(q), a) = 1 if a ?
C(q) for a ?
S(q),and 0 otherwise.
We use R@N to denote recall forsystems limited to output top N corrections.Expected F1 measure can be computed as:F1 =2 ?
precision ?
recallprecision+ recall(21)5.3 Experiment ResultsTable 1 compares the performance of our LS-SVMbased model with two strong baseline systems.
Thefirst baseline system is an Echo system which sim-ply echos the input.
The echo system is usually con-sidered as a strong baseline in query spelling cor-rection as the majority of the queries are correctlyspelled queries.
The second baseline Lueck-2011we use is a award winning speller system5 (Luec,2011), which was ranked at the first place in Mi-crosoft Spelling Challenge 2011.4http://times.cs.uiuc.edu/duan9/msn speller.tar.gz5http://www.phraselink.com1518Table 1: LSSVM vs Baselines Serving as Standalone SpellerAll Queries Misspelled QueriesDataset Method Precision R@10 F1 Precision R@10 F1Echo 0.949 0.876 0.911 0 0 0TREC Lueck-2011 0.963 0.932 0.947 0.391 0.479 0.430LS-SVM 0.955 0.944 0.949 0.331 0.678?
0.445?Echo 0.869 0.869 0.869 0 0 0MSN Lueck-2011 0.896 0.921 0.908 0.334 0.397 0.363LS-SVM 0.903 0.953 0.928 0.353?
0.662?
0.461?We show performances for the entire query setsas well as the query sets consisting only the mis-spelled queries.
As we can see, our system out-performs both baseline systems on almost all met-rics, except the precision of Lueck-2011 is betterthan ours on TREC dataset.
We perform statisticaltest and measures where our system shows statisti-cal significant improvement over both baseline sys-tems are noted by ?.
It is theoretically impossibleto achieve statistical significance in the entire queryset as majority queries have almost identical perfor-mance in different systems due to the large amountof correct queries.
But our method shows signifi-cant improvement in the dealing with the misspelledqueries.
This experiment verified the effectivenessof our proposed discriminative model.
As a stan-dalone speller, our system achieves very high accu-racy.Despite we are primarily focused on optimizingthe top correction in our discriminative model, wecan also use the trained system to output multiplecandidate corrections.
Table 2 compare our systemwith the noisy channel model (N-C) in terms of re-call at different levels of cutoff.
For all levels, we seethat our system achieves higher recall than the noisychannel model.
This indicates that when used to-gether with a secondary ranker, our system serves asa better filtering method than the unoptimized noisychannel model.
Since the ranker makes use of arbi-trary features, it has the potential of further improv-ing the accuracy of query spelling correction.
Weplan to further explore this idea as a future work.In Table 3 we study the effect of treating the trans-formation probability of merging and splitting er-rors as separate features and including the local andglobal heuristic features (rich features).
We see thatTable 2: LS-SVM vs Noisy Channel Model Serving asFiltering MethodDataset Method R@5 R@10 R@20TREC N-C 0.896 0.899 0.901LS-SVM 0.923 0.944 0.955MSN N-C 0.870 0.873 0.876LS-SVM 0.950 0.953 0.960the precision of query spelling correction can bene-fits from the use of rich features.
However, it doesnot result in much improvement in recall.
This isreasonable as the additional features are primarilydesigned to improve the accuracy of the top correc-tion generated by the system.
In doing so, it actu-ally regularizes the ability of the system in retrievingdiversified results.
For instance, the global heuris-tic feature on the number of word change tries toprevent the system from returning candidates hav-ing more than a certain number of changed words.For the TREC collection where more than one cor-rections can be labeled for a query, this phenomenais aggravated.Table 3: LSSVM w/ and w/o Rich FeaturesDataset Method Precision R@10 F1TREC w/o 0.942 0.946 0.944w/ 0.955 0.944 0.949MSN w/o 0.898 0.952 0.924w/ 0.903 0.953 0.9286 ConclusionsIn this paper, we present a novel discriminativemodel for query spelling correction.
The paper madethe following contributions:1519First, to the best of our knowledge, this is a novelexploration of directly optimizing the search phasein query spelling correction with a discriminativemodel.
By modeling word alignment as the latentstructural information, our formulation also dealswith word boundary errors.
We propose to use LS-SVM for learning the discriminative model whichnaturally incorporates search in the learning process.Second, we develop an efficient search algorithmthat solves the inference problems in the LS-SVMbased model.
We analyze the criteria for selectingand designing features to ensure the correctness andefficiency of the search algorithm.
Third, we exploreeffective features to improve the accuracy of themodel.
Finally, experiments are conducted to verifythe effectiveness of the proposed model.
It is shownthat as a standalone speller our system achieves highaccuracy.
When used in a two stage approach, it at-tains higher recall than the noisy channel model andcan thus serve as a superior method for candidategeneration.
We also verify that through the use ofrich features, we can further improve the accuracyof our query spelling correction system.7 AcknowledgmentsThis paper is based upon work supported in part byMIAS, the Multimodal Information Access and Syn-thesis center at UIUC, part of CCICADA, a DHSCenter of Excellence, and by the National ScienceFoundation under grant CNS-1027965, and by a Mi-crosoft grant.ReferencesF.
Ahmad and G. Kondrak.
2005.
Learning a spellingerror model from search query logs.
In HLT/EMNLP.The Association for Computational Linguistics.M.
Bendersky and W. B. Croft.
2008.
Discovering keyconcepts in verbose queries.
In Proceedings of the 31stannual international ACM SIGIR conference on Re-search and development in information retrieval, SI-GIR ?08.
ACM, New York, NY, USA, 491-498.E.
Brill and R. Moore.
2000.
An improved error modelfor noisy channel spelling correction.
In Proceed-ings of the 38th Annual Meeting of the Association forComputational Linguistics, Hong Kong.M.
Chang, D. Goldwasser, D. Roth and V. Srikumar.2010.
Discriminative Learning over Constrained La-tent Representations.
In Proceedings of NAACL.Q.
Chen, M. Li, and M. Zhou.
2007.
Improvingquery spelling correction using web search results.
InEMNLP-CoNLL, pages 181?189.S.
Cucerzan and E. Brill.
2004.
Spelling correction as aniterative process that exploits the collective knowledgeof web users.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).H.
Daume, J. Langford and D. Marcu.
2009.
Search-based Structured Prediction.
Machine Learning Jour-nal (MLJ).M.
Dreyer, D. Smith and N. Smith.
2006.
Vine parsingand minimum risk reranking for speed and precision.In Proceedings of the Tenth Conference on Computa-tional Natural Language Learning.
201-205.H.
Duan and B.-J.
P. Hsu.
2011.
Online spelling correc-tion for query completion.
In Proceedings of the 20thinternational conference on World wide web, WWW?11, pages 117?126, New York, NY, USA.C.
Dyer, J. H. Clark, A. Lavie, and N. A. Smith.
2011.Unsupervised Word Alignment with Arbitrary Fea-tures.
In Proceedings of ACL.D.
Freitag, S. Khadivi.
2007.
A Sequence AlignmentModel Based on the Averaged Perceptron.
In Pro-ceedings of the 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning.
238-247.J.
Gao, X. Li, D. Micol, C. Quirk, and X.
Sun.
2010.A large scale ranker-based system for search queryspelling correction.
In COLING, pages 358?366.A.
R. Golding and D. Roth 1999.
A Winnow based ap-proach to Context-Sensitive Spelling Correction.
InMachine Learning, vol 34, pages 107?130.J.
Guo, G. Xu, H. Li, and X. Cheng.
2008.
A unified anddiscriminative model for query refinement.
In Pro-ceedings of the 31st annual international ACM SIGIR,SIGIR ?08, pages 379?386, New York, NY, USA.C.
John Yu and T. Joachims.
2009.
Learning structuralSVMs with latent variables.
In Proceedings of the 26thAnnual International Conference on Machine Learn-ing (ICML ?09).
ACM, New York, NY, USA, 1169-1176.M.
D. Kernighan , K. W. Church , W. A. Gale.
1990.
Aspelling correction program based on a noisy channelmodel.
In Proceedings of the 13th conference on Com-putational linguistics.
205-210.
August 20-25, 1990,Helsinki, Finland.K.
Kukich.
1992.
Techniques for automatically correct-ing words in text.
ACM computing surveys, 24(4).G.
Kumaran and J. Allan.
2008.
Effective and efficientuser interaction for long queries.
In Proceedings ofthe 31st annual international ACM SIGIR conferenceon Research and development in information retrieval,SIGIR ?08.
ACM, New York, NY, USA.1520G.
Kumaran and V. R. Carvalho.
2009.
Reducing longqueries using query quality predictors.
In Proceed-ings of the 32nd international ACM SIGIR conferenceon Research and development in information retrieval,SIGIR ?09.
ACM, New York, NY, USA, 564-571.J.
Lafferty.
2001.
Conditional random fields: Probabilis-tic models for segmenting and labeling sequence data.In Proceedings of the Eighteenth International Con-ference on Machine Learning (ICML ?01).
282?289.V.
I. Levenshtein.
1966.
Binary codes capable of cor-recting deletions, insertions, and reversals.
In SovietPhysics Doklady, 10(8), 707-710.G.
Luec.
2011.
A data-driven approach for correctingsearch quaries.
In Spelling Alteration for Web SearchWorkshop.A.
McCallum, D. Freitag, and F. Pereira.
2000.
Maxi-mum Entropy Markov Models for Information Extrac-tion and Segmentation.
In Proceedings of the Seven-teenth International Conference on Machine Learning(ICML ?00).
591-598.M.
Mitra, A. Singhal, and C. Buckley.
1998.
Improvingautomatic query expansion.
In Proceedings of the 21stannual international ACM SIGIR conference on Re-search and development in information retrieval, SI-GIR ?98.Y.
Qiu and H. Frei.
1993.
Concept based query expan-sion.
In Proceedings of the 16th annual internationalACM SIGIR conference on Research and developmentin information retrieval, SIGIR ?93.
ACM, New York,NY, USA, 160-169.X.
Sun, J. Gao, D. Micol, and C. Quirk.
2010.
Learningphrase-based spelling error models from clickthroughdata.
In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics, ACL?10, pages 266?274, Stroudsburg, PA, USA.X.
Wang, C. Zhai.
2008.
Mining Term Association Pat-terns from Search Logs for Effective Query Reformu-lation.
In Proceedings of the 17th ACM InternationalConference on Information and Knowledge Manage-ment 2008, CIKM?08.
479-488.J.
Xu and W. B. Croft.
1996.
Query expansion usinglocal and global document analysis.
In Proceedings ofthe 19th annual international ACM SIGIR conferenceon Research and development in information retrieval,SIGIR ?96.
ACM, New York, NY.A.
Yessenalina, Y. Yue, C. Cardie.
2010.
Multi-level Structured Models for Document-level SentimentClassification.
In Proceedings of the 2010 Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP ?10).
10461056.1521
