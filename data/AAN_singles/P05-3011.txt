Proceedings of the ACL Interactive Poster and Demonstration Sessions,pages 41?44, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsSPEECH OGLE: Indexing Uncertainty for Spoken Document SearchCiprian Chelba and Alex AceroMicrosoft ResearchMicrosoft CorporationOne Microsoft WayRedmond, WA 98052{chelba, alexac}@microsoft.comAbstractThe paper presents the Position SpecificPosterior Lattice (PSPL), a novel lossyrepresentation of automatic speech recog-nition lattices that naturally lends itselfto efficient indexing and subsequent rele-vance ranking of spoken documents.In experiments performed on a collec-tion of lecture recordings ?
MIT iCam-pus data ?
the spoken document rank-ing accuracy was improved by 20% rela-tive over the commonly used baseline ofindexing the 1-best output from an auto-matic speech recognizer.The inverted index built from PSPL lat-tices is compact ?
about 20% of the sizeof 3-gram ASR lattices and 3% of the sizeof the uncompressed speech ?
and it al-lows for extremely fast retrieval.
Further-more, little degradation in performance isobserved when pruning PSPL lattices, re-sulting in even smaller indexes ?
5% ofthe size of 3-gram ASR lattices.1 IntroductionEver increasing computing power and connectivitybandwidth together with falling storage costs resultin an overwhelming amount of data of various typesbeing produced, exchanged, and stored.
Conse-quently, search has emerged as a key application asmore and more data is being saved (Church, 2003).Text search in particular is the most active area, withapplications that range from web and private net-work search to searching for private information re-siding on one?s hard-drive.Speech search has not received much attentiondue to the fact that large collections of untranscribedspoken material have not been available, mostlydue to storage constraints.
As storage is becomingcheaper, the availability and usefulness of large col-lections of spoken documents is limited strictly bythe lack of adequate technology to exploit them.Manually transcribing speech is expensive andsometimes outright impossible due to privacy con-cerns.
This leads us to exploring an automatic ap-proach to searching and navigating spoken docu-ment collections (Chelba and Acero, 2005).2 Text Document Retrieval in the EarlyGoogle ApproachAside from the use of PageRank for relevance rank-ing, the early Google also uses both proximity andcontext information heavily when assigning a rel-evance score to a given document (Brin and Page,1998), Section 4.5.1.For each given query term qi one retrieves the listof hits corresponding to qi in document D. Hitscan be of various types depending on the context inwhich the hit occurred: title, anchor text, etc.
Eachtype of hit has its own type-weight and the type-weights are indexed by type.For a single word query, their ranking algorithmtakes the inner-product between the type-weightvector and a vector consisting of count-weights (ta-pered counts such that the effect of large counts isdiscounted) and combines the resulting score with41PageRank in a final relevance score.For multiple word queries, terms co-occurring in agiven document are considered as forming differentproximity-types based on their proximity, from adja-cent to ?not even close?.
Each proximity type comeswith a proximity-weight and the relevance score in-cludes the contribution of proximity information bytaking the inner product over all types, including theproximity ones.3 Position Specific Posterior LatticesAs highlighted in the previous section, position in-formation is crucial for being able to evaluate prox-imity information when assigning a relevance scoreto a given document.In the spoken document case however, we arefaced with a dilemma.
On one hand, using 1-bestASR output as the transcription to be indexed is sub-optimal due to the high WER, which is likely to leadto low recall ?
query terms that were in fact spo-ken are wrongly recognized and thus not retrieved.On the other hand, ASR lattices do have a much bet-ter WER ?
in our case the 1-best WER was 55%whereas the lattice WER was 30% ?
but the posi-tion information is not readily available.The occurrence of a given word in a lattice ob-tained from a given spoken document is uncertainand so is the position at which the word occurs in thedocument.
However, the ASR lattices do contain theinformation needed to evaluate proximity informa-tion, since on a given path through the lattice we caneasily assign a position index to each link/word inthe normal way.
Each path occurs with a given pos-terior probability, easily computable from the lattice,so in principle one could index soft-hits which spec-ify (document id, position, posterior probability) foreach word in the lattice.A simple dynamic programming algorithm whichis a variation on the standard forward-backward al-gorithm can be employed for performing this com-putation.
The computation for the backward proba-bility ?n stays unchanged (Rabiner, 1989) whereasduring the forward pass one needs to split the for-ward probability arriving at a given node n, ?n, ac-cording to the length of the partial paths that start atthe start node of the lattice and end at node n:?n[l] =?pi:end(pi)=n,length(pi)=lP (pi)The posterior probability that a given node n occursat position l is thus calculated using:P (n, l|LAT ) = ?n[l] ?
?nnorm(LAT )The posterior probability of a given word w occur-ring at a given position l can be easily calculatedusing:P (w, l|LAT ) =?n s.t.
P (n,l)>0 P (n, l|LAT ) ?
?
(w,word(n))The Position Specific Posterior Lattice (PSPL) isnothing but a representation of the P (w, l|LAT )distribution.
For details on the algorithm and prop-erties of PSPL please see (Chelba and Acero, 2005).4 Spoken Document Indexing and SearchUsing PSPLSpeech content can be very long.
In our case thespeech content of a typical spoken document wasapproximately 1 hr long.
It is customary to segmenta given speech file in shorter segments.
A spokendocument thus consists of an ordered list of seg-ments.
For each segment we generate a correspond-ing PSPL lattice.
Each document and each segmentin a given collection are mapped to an integer valueusing a collection descriptor file which lists all doc-uments and segments.The soft hits for a given word arestored as a vector of entries sorted by(document id, segment id).
Documentand segment boundaries in this array, respectively,are stored separately in a map for convenience ofuse and memory efficiency.
The soft index simplylists all hits for every word in the ASR vocabulary;each word entry can be stored in a separate file if wewish to augment the index easily as new documentsare added to the collection.4.1 Speech Content Relevance Ranking UsingPSPL RepresentationConsider a given query Q = q1 .
.
.
qi .
.
.
qQ anda spoken document D represented as a PSPL.
Ourranking scheme follows the description in Section 2.42For all query terms, a 1-gram score is calculatedby summing the PSPL posterior probability acrossall segments s and positions k. This is equivalentto calculating the expected count of a given queryterm qi according to the PSPL probability distribu-tion P (wk(s)|D) for each segment s of documentD.
The results are aggregated in a common valueS1?gram(D,Q):S(D, qi) = log[1 +?s?kP (wk(s) = qi|D)]S1?gram(D,Q) =Q?i=1S(D, qi) (1)Similar to (Brin and Page, 1998), the logarithmic ta-pering off is used for discounting the effect of largecounts in a given document.Our current ranking scheme takes into accountproximity in the form of matching N -grams presentin the query.
Similar to the 1-gram case, we cal-culate an expected tapered-count for each N-gramqi .
.
.
qi+N?1 in the query and then aggregate the re-sults in a common value SN?gram(D,Q) for eachorder N :S(D, qi .
.
.
qi+N?1) =log[1 +?s?k?N?1l=0 P (wk+l(s) = qi+l|D)]SN?gram(D,Q) =Q?N+1?i=1S(D, qi .
.
.
qi+N?1) (2)The different proximity types, one for each N -gram order allowed by the query length, are com-bined by taking the inner product with a vector ofweights.S(D,Q) =Q?N=1wN ?
SN?gram(D,Q)It is worth noting that the transcription for any givensegment can also be represented as a PSPL with ex-actly one word per position bin.
It is easy to see thatin this case the relevance scores calculated accord-ing to Eq.
(1-2) are the ones specified by 2.Only documents containing all the terms in thequery are returned.
We have also enriched the querylanguage with the ?quoted functionality?
that al-lows us to retrieve only documents that contain exactPSPL matches for the quoted phrases, e.g.
the query?
?L M??
tools will return only documents con-taining occurrences of L M and of tools.5 ExperimentsWe have carried all our experiments on the iCam-pus corpus (Glass et al, 2004) prepared by MITCSAIL.
The main advantages of the corpus are: re-alistic speech recording conditions ?
all lectures arerecorded using a lapel microphone ?
and the avail-ability of accurate manual transcriptions ?
whichenables the evaluation of a SDR system against itstext counterpart.The corpus consists of about 169 hours of lec-ture materials.
Each lecture comes with a word-levelmanual transcription that segments the text into se-mantic units that could be thought of as sentences;word-level time-alignments between the transcrip-tion and the speech are also provided.
The speechwas segmented at the sentence level based on thetime alignments; each lecture is considered to be aspoken document consisting of a set of one-sentencelong segments determined this way.
The final col-lection consists of 169 documents, 66,102 segmentsand an average document length of 391 segments.5.1 Spoken Document RetrievalOur aim is to narrow the gap between speech andtext document retrieval.
We have thus taken as ourreference the output of a standard retrieval engineworking according to one of the TF-IDF flavors.
Theengine indexes the manual transcription using an un-limited vocabulary.
All retrieval results presentedin this section have used the standard trec_evalpackage used by the TREC evaluations.The PSPL lattices for each segment in the spokendocument collection were indexed.
In terms of rel-ative size on disk, the uncompressed speech for thefirst 20 lectures uses 2.5GB, the ASR 3-gram lat-tices use 322MB, and the corresponding index de-rived from the PSPL lattices uses 61MB.In addition, we generated the PSPL representa-tion of the manual transcript and of the 1-best ASRoutput and indexed those as well.
This allows us tocompare our retrieval results against the results ob-tained using the reference engine when working onthe same text document collection.435.1.1 Query Collection and Retrieval SetupWe have asked a few colleagues to issue queriesagainst a demo shell using the index built from themanual transcription.We have collected 116 queriesin this manner.
The query out-of-vocabulary rate (Q-OOV) was 5.2% and the average query length was1.97 words.
Since our approach so far does not in-dex sub-word units, we cannot deal with OOV querywords.
We have thus removed the queries whichcontained OOV words ?
resulting in a set of 96queries.5.1.2 Retrieval ExperimentsWe have carried out retrieval experiments in theabove setup.
Indexes have been built from: trans,manual transcription filtered through ASR vocabu-lary; 1-best, ASR 1-best output; lat, PSPL lat-tices.
Table 1 presents the results.
As a sanity check,trans 1-best lat# docs retrieved 1411 3206 4971# relevant docs 1416 1416 1416# rel retrieved 1411 1088 1301MAP 0.99 0.53 0.62R-precision 0.99 0.53 0.58Table 1: Retrieval performance on indexes builtfrom transcript, ASR 1-best and PSPL latticesthe retrieval results on transcription ?
trans ?match almost perfectly the reference.
The small dif-ference comes from stemming rules that the baselineengine is using for query enhancement which are notreplicated in our retrieval engine.The results on lattices (lat) improve signifi-cantly on (1-best) ?
20% relative improvementin mean average precision (MAP).
Table 2 shows theretrieval accuracy results as well as the index size forvarious pruning thresholds applied to the lat PSPL.MAP performance increases with PSPL depth, asexpected.
A good compromise between accuracyand index size is obtained for a pruning thresholdof 2.0: at very little loss in MAP one could use anindex that is only 20% of the full index.6 Conclusions and Future workWe have developed a new representation for ASRlattices ?
the Position Specific Posterior Lattice ?pruning MAP R-precision Index Sizethreshold (MB)0.0 0.53 0.54 160.1 0.54 0.55 210.2 0.55 0.56 260.5 0.56 0.57 401.0 0.58 0.58 622.0 0.61 0.59 1105.0 0.62 0.57 30010.0 0.62 0.57 4601000000 0.62 0.57 540Table 2: Retrieval performance on indexes builtfrom pruned PSPL lattices, along with index sizethat lends itself to indexing speech content.
Theretrieval results obtained by indexing the PSPL are20% better than when using the ASR 1-best output.The techniques presented can be applied to in-dexing contents of documents when uncertainty ispresent: optical character recognition, handwritingrecognition are examples of such situations.7 AcknowledgmentsWe would like to thank Jim Glass and T J Hazenat MIT for providing the iCampus data.
We wouldalso like to thank Frank Seide for offering valuablesuggestions on our work.ReferencesSergey Brin and Lawrence Page.
1998.
The anatomy ofa large-scale hypertextual Web search engine.
Com-puter Networks and ISDN Systems, 30(1?7):107?117.Ciprian Chelba and Alex Acero.
2005.
Position specificposterior lattices for indexing speech.
In Proceedingsof ACL, Ann Arbor, Michigan, June.Kenneth Ward Church.
2003.
Speech and language pro-cessing: Where have we been and where are we going?In Proceedings of Eurospeech, Geneva, Switzerland.James Glass, Timothy J. Hazen, Lee Hetherington, andChao Wang.
2004.
Analysis and processing of lec-ture audio data: Preliminary investigations.
In HLT-NAACL 2004 Workshop: Interdisciplinary Approachesto Speech Indexing and Retrieval, pages 9?12, Boston,Massachusetts, USA, May 6.L.
R. Rabiner.
1989.
A tutorial on hidden markov mod-els and selected applications in speech recognition.
InProceedings IEEE, volume 77(2), pages 257?285.44
