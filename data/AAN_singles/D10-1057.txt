Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 585?595,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsWe?re Not in Kansas Anymore: Detecting Domain Changes in Streams?
?Mark Dredze and ?
?Tim Oates and ?
?Christine Piatko?Human Language Technology Center of Excellence,?Center for Language and Speech Processing,?Applied Physics LabJohns Hopkins University?University of Maryland, Baltimore Countymdredze@cs.jhu.edu, oates@umbc.edu, christine.piatko@jhuapl.eduAbstractDomain adaptation, the problem of adaptinga natural language processing system trainedin one domain to perform well in a differ-ent domain, has received significant attention.This paper addresses an important problem fordeployed systems that has received little at-tention ?
detecting when such adaptation isneeded by a system operating in the wild,i.e., performing classification over a streamof unlabeled examples.
Our method uses A-distance, a metric for detecting shifts in datastreams, combined with classification marginsto detect domain shifts.
We empirically showeffective domain shift detection on a variety ofdata sets and shift conditions.1 IntroductionConsider a named entity recognition system trainedon newswire stories.
Given annotated documentscontaining sentences like ?Tony Hayward has facedfresh criticism for taking time off to go sailing .
.
.
?we would like to learn a model that will allow us torecognize that ?Obama?
and ?BP?
are named enti-ties in a sentence like ?Obama summoned BP ex-ecutives .
.
.?.
When all of the documents comefrom one data distribution, like newswire articles,this tends to work well.
However, the sentence?OBAMA SUMMONED BP EXECUTIVES .
.
.
?from transcribed broadcast news, and others like it,will probably lead to poor results because the fea-tures it relies on have changed.
For example, capi-talization patterns are no longer a good indicator ofthe presence of a named entity and appositives arenot indicated by punctuation.
This problem of do-main shift is a pervasive problem in NLP in whichany kind of model ?
a parser, a POS tagger, a senti-ment classifier ?
is tested on data that do not matchthe training data.Given a model and a stream of unlabeled in-stances, we are interested in automatically detectingchanges in the feature distribution that negativelyimpact classification accuracy.
For example, a senti-ment classification model trained on book reviewsmay heavily weight n-grams features like ?uplift-ing?
and ?page turner?.
Those features may neveroccur in reviews of kitchen appliances that get mixedin at test time, and useful features in this new do-main like ?efficient?
and ?noisy compressor?
willhave never been seen during training and thereforenot be in the model.
Furthermore, we do not assumelabeled instances are available to help detect theseharmful changes.
Other tasks related to changesin data distributions, like detecting concept drift inwhich the labeling function changes, may require la-beled instances, but that is not the focus of this paper.There is significant work on the related problemof adapting a classifier for a known domain shift.Versions of this problem include adapting using onlyunlabeled target domain data (Blitzer et al, 2006;Blitzer et al, 2007; Jiang and Zhai, 2007), adapt-ing using a limited amount of target domain labeleddata (Daume?, 2007; Finkel and Manning, 2009), andlearning across multiple domains simultaneously inan online setting (Dredze and Crammer, 2008b).However, in practical settings, we do not know ifthe data distribution will change, and certainly notwhen.
Additionally, we will not know to what do-585main the shift will happen.
A discussion forum de-voted to science fiction books may change over timeto focus more on fantasy and then narrow to discus-sions of vampire fiction.
Maybe this shift is harm-less and it is possible to identify the sentiment of thediscussants with the original model with no loss inaccuracy.
If not, we seek methods that detect thisshift and trigger the use of an adaptation method.Our domain shift detection problem can be de-composed into two subproblems: detecting distribu-tional changes in streams of real numbers, and rep-resenting a stream of examples as a stream of realnumbers informative for distribution change detec-tion.
We select the A-distance metric (Kifer et al,2004) to solve the first subproblem since it has beenpreviously used in other domain adaptation work(Blitzer et al, 2006; Blitzer et al, 2007).
Our maincontribution is towards the second problem, repre-senting examples as real numbers for this task.
Wedemonstrate that classification margins, which in-corporate information about features that most im-pact system accuracy, can effectively solve the sec-ond subproblem.
Furthermore, we show that the pre-viously proposed Confidence Weighted learning al-gorithm (Dredze et al, 2008) can provide a moreinformative measure than a simple margin for thistask.
Our experiments include evaluations on com-monly used domain adaptation data and false changescenarios, as well as comparisons to supervised de-tection methods that observe label values, or haveknowledge of the target domain.We begin with a description of our task and pre-vious applications to language data.
After describ-ing the data used in this paper, we discuss the A-distance metric and how it has previously been usedfor adaptation.
We then show that margin basedmethods effectively capture information to detectdomain shifts, and propose an alternate way of gen-erating informative margin values.
Finally, we com-pare our results to settings with supervised knowl-edge, and close with a survey of related work.2 Domain Shifts in Language DataThe study of domain shifts in language data has beenthe purview of domain adaptation and transfer learn-ing, which seek to adapt or transfer a model learnedon one source domain with labeled data to anothertarget domain with few or no labeled examples.
For-mally, errors from such transfers have two sources:differences in feature distributions and changes to la-beling functions (annotation standards) (Ben-Davidet al, 2006; Ben-David et al, 2009).
Empirical workon NLP domain shifts has focused on the former.For example, Blitzer et al (2007) learned correspon-dences between features across domains and Jiangand Zhai (2007) weighted source domain examplesby their similarity to the target distribution.We continue in this tradition by making two as-sumptions about our setting.
First, a change in do-main will be signaled by a change in the featuredistributions.
That is, new words, phrases, syntac-tic structures, etc.
signal that the system has shiftedto a new domain.
Second, while there may be achange in the labeling function, i.e., features have adifferent meaning in each domain, this will be a sec-ondary concern.
For example, both Daume?
(2007)and Dredze and Crammer (2008b) assume that do-mains are more similar than different.A similar problem to the one we consider is thatof concept drift, where a stream of examples arelabeled with a shifting labeling function (concept)(Nishida and Yamauchi, 2007; Widmer and Kubat,1996).
While concept drift is similar there are twoimportant differences.
First, concept drift can bemeasured using a stream of labeled examples, sosystem accuracy is directly measured.
For exam-ple, Klinkenberg and Joachims (2000) detect con-cept drift with support vector machines, using es-timates of leave-one-out performance to adaptivelyadjust and maintain a training window that mini-mizes estimated generalization error.
This is pos-sible only because class labels arrive with the exam-ples in the stream.
Another concept drift detectionalgorithm, STEPD, uses a statistical test to continu-ally monitor the possibly changing stream, measur-ing system accuracy directly, again using the labelsit receives for each example (Nishida, 2008).
Ob-viously, no such labels are available in our unsuper-vised setting.
Second, concept drift assumes onlychanges in the labeling function, whereas domainadaptation relies on feature distribution changes.Several properties of detecting domain shifts innatural language streams distinguish it from tradi-tional domain adaptation, concept drift, and otherrelated tasks:586?
No Target Distribution Examples Blitzer etal.
(2007) estimate the loss in accuracy fromdomain shift by discriminating between twodata distributions.
In our setting, we have noknowledge of the target distribution.?
No Labeled Target Data Some approaches todomain adaptation assume a limited number oflabeled examples (Daume?, 2007; Dredze andCrammer, 2008b; Finkel and Manning, 2009).We assume no labels in our setting.?
Online Setting Domain adaptation typicallyassumes a batch transfer between two domains.We consider a purely stream (online) setting.?
Computationally Constrained Our approachmust be fast, as we expect to run our domainshift detector alongside a deployed NLP sys-tem.
This limits both computation and storage.?
Unknown Adaptation A critical assumptionof previous work is that a domain change hasoccurred.
We must ascertain this ourselves.Despite these challenges, we show unsupervisedstream-based methods that effectively identify shiftsin domain in language data.
Furthermore, our meth-ods are tied directly to the learning task so are sen-sitive to changes in actual task accuracy.
Our meth-ods have low false positive rates of change detection,which is important since examples within a singledomain display a large amount of variance, whichcould be mistaken for a domain change.Once a change is detected, any number of actionsmay be appropriate.
The maintainer of the systemmay be notified that performance is suffering, la-bels can be obtained for a sample of instances fromthe stream for retraining, or large volumes of unla-beled instances can be used for instance reweighting(Jiang and Zhai, 2007).3 DatasetsWe begin the presentation of our methods by de-scribing the data used in our experiments.
We se-lected three data sets commonly used in domainadaptation: spam (Jiang and Zhai, 2007), ACE 2005named entity recognition (Jiang and Zhai, 2007),and sentiment (Blitzer et al, 2007).
Sentiment andspam are binary and ACE is multi-class.
Note thatin all experiments, a shift in the domain yields a de-crease in system accuracy.The goal of the spam data is to classify an email(bag-of-words) as either spam or ham (not-spam).Each email user may have different preferences andfeatures.
We used unigram and bigram features, fol-lowing Dredze and Crammer (2008b) for feature ex-traction, and used the three task A users as threedomains.
The ACE 2005 named entity recognitiondataset includes 7 named entity class labels (person,organization, location, geopolitical entity, facility,vehicle, weapon) for 5 text genres (newswire, broad-cast news, broadcast conversations, conversationaltelephone speech, weblogs).
We use 4000 examplesfrom each genre and used Jiang and Zhai?s feature-extracted data.1 The sentiment data contains reviewsfrom Amazon for four product types: books, dvds,electronics, and kitchen.
We include an additionaltwo types (music and video from Dredze and Cram-mer) in our false shift experiments and use unigramand bigram features, following Blitzer et al4 The A-DistanceOur approach to detecting domain shifts in datastreams that negatively impact system accuracy isbased on the ability to (1) detect distributionalchanges in streams of real numbers and (2) con-vert document streams to streams of informative realnumbers.
This section describes how we achieve theformer, and the next section describes the latter.Theoretical work on domain adaptation showedthat the A-distance (Kifer et al, 2004), a streambased measure of difference between two arbitraryprobability distributions P and P ?, can be used toevaluate the difference between two domain distri-butions (Ben-David et al, 2006).
In a batch set-ting this corresponds to learning a linear classi-fier to discriminate the domains, and Blitzer et al(2007) showed correlations with the error from do-main adaptation.
Given our interest in streamingdata we return to the original stream formulation ofA-distance.The A-distance detects differences between twoarbitrary probability distributions by dividing therange of a random variable into a set of (possibly1We thank Jing Jiang for the feature-extracted ACE data.587Figure 1: The A-distance is computed between two win-dows (P and P ?
in a stream of real-valued data.
The sam-ples in each window are divided into intervals, and theA-distance measures the change in the distributions overthese intervals between the two windows.overlapping) intervals, and then measures changesin the probability that a value drawn for that variablefalls into any one of the intervals.
If such a change islarge, a change in the underlying distribution is de-clared.
LetA be a set of real intervals and letA ?
Abe one such interval.
For that interval, P (A) is theprobability that a value drawn from some unknowndistribution falls in A.
The A-distance between Pand P ?, i.e.
the difference between two distributionsover the intervals, is defined as follows:dA(P, P?)
= 2 sup A?A|P (A)?
P?
(A)|.Two distributions are said to be different when, fora user-specified threshold , dA(P, P ?)
> .
TheA-distance is distribution independent.
That is, itmakes no assumptions about the form of the under-lying distribution nor about the form of the changethat might occur, either algorithmically or in the un-derlying theory.
Unlike the L1 norm, theA-distancecan be shown to require finitely many samples to de-tect distribution differences, a property that is crucialfor streaming, sample-based approaches.Since the A-distance processes a stream of realnumbers, we need to represent an example using areal number, such as the classification margin forthat example.
The first n of these numbers in thestream are a sample from P , and the most recentn are a sample from P ?.
We signal a domain shiftwhen the A-distance between P and P ?
is large(greater than ).
Larger values of n result in moreaccurate estimates of P (A) and slower detection ofchanges.The two windows of samples of size n are showngraphically in Fig.
1.
Each increment on the hori-zontal axis represents the arrival of a new document.The vertical axis is some value computed from eachdocument, such as its classification margin.
To com-pute P and P ?, one needs to specifyA and n, whichare shown as two stacks of boxes that are identicalexcept for their position.
The width of each box isn, the number of examples used to estimate P (A)and P (A?)
for A ?
A, where the real interval A cor-responds to the vertical span of the box.
The valueP (A) is simply the number of documents whose realvalue falls inside that interval A divided by n. Notethat the first n documents in the stream are used tocompute P , and as each new document arrives thelocation of the stack of boxes used to compute P ?
isshifted to the right by one.In Fig.
1, the number of examples whose realvalue falls in the top two intervals for P is approxi-mately the same, with no example?s value falling inthe lower two intervals.
For P ?, almost every oneof the n document values falls in the second intervalfrom the top, virtually assuring that dA(P, P ?)
willbe large.
Though the intervals in the figure do notoverlap, they typically do.Given n and intervals A, the value of  is chosenby randomization testing.
Because theA-distance isdistribution independent, a sample of size m n isdrawn from any distribution that spansA.
This sam-ple is treated as a stream as described above, andthe largest value of dA(P, P ?)
is stored.
The sam-ple is permuted and this process is repeated l times.Note that any change detection would be a false pos-itive because all values were sampled from the samedistribution.
The values dA(P, P ?)
are sorted fromlargest to smallest, and  is chosen to be the b?lcthsuch value where parameter ?
is a user specifiedfalse positive probability.Both the time and space complexity of our ap-proach based on the A-distance are small.
Givenn and A, n instances must be stored in the slidingwindow and 2|A| counters are required to representP and P ?.
Note that both values are constants basedon user specified parameters, not on the size of thestream.
Processing a new instance involves comput-ing its margin and updating P and P ?, all of whichcan occur in constant time.588Figure 2: Each column of plots is a representative result using an SVM on a single run over a sentiment data shift:dvds?
electronics, electronics?
books, and kitchen?
books, from left to right.
The horizontal axis is the numberof instances from the stream processed by the classifier.
The top plot is the accuracy of the classifier on the last 100instances.
The bottom plot is the absolute value of the SVM classification margin.
The vertical line at 500 instancesmarks the point of domain shift.
Horizontal dotted lines indicate the mean of the accuracy/margin before and after thedomain shift.
Note that in all cases, the mean accuracy drops, as do the mean margin values, demonstrating that bothcan indicate domain shifts.5 A-Distance Over MarginsSince shifts in domains correlate with changes indistributions, it is natural to begin by considering theobserved features in each example.
When we shiftfrom a source domain (e.g., book reviews) to a targetdomain (e.g., dvd reviews) we expect a change in thedistribution for common source words (?author?
and?plot?
become less common).
Since the A-distanceassumes a stream of single values, we can apply anA-distance detector to each feature (e.g., unigramand bigram count) individually.
However, our exten-sive experiments with this approach (omitted here)show that it suffers from a number of flaws, such asa high false positive rate if all features are tracked,the difficult problem of identifying an informativesubset of features for tracking, and deciding howmany such features need to change before a shift hasoccurred, which turns out to be highly variable be-tween shifts.Therefore, our goal is to use a single A-distancetracker by collapsing each example to a single value.One way of doing this is to consider the classifica-tion margin produced by the classifier.
The mar-gin weighs features by their importance in classi-fication.
When more important features disappear,we expect the magnitude of the margin to decrease.Additionally, features that change but do not in-fluence system performance are effectively ignoredsince they do not influence the margin.
This ap-proach has the advantage of task sensitivity, onlytracking changes that impact task accuracy.
Initialexperiments showed effectiveness with the unsigned(absolute value of the) margin, which we use in allexperiments.We begin by examining visually the informationcontent of the margin with regards to predicting adomain shift.
The caption of Fig.
2 describes thesetup, and the first row of the figure illustrates theeffects of the shift on the source domain classifier?sempirical accuracy, measured on a window of theprevious 100 examples.
The horizontal dashed linesindicate the average accuracy before and after theshift.
Note that in each case, average classificationaccuracy drops after the shift.
However, at any onepoint the accuracy displays considerable variance.Thus, while classification accuracy clearly suffers, itis difficult to measure this even in a supervised set-ting with labeled examples when considering a smallportion of the stream.The second row of Fig.
2 shows the average un-signed margin value of an SVM classifier computedover the previous 100 examples in the stream.
Thetwo dashed horizontal lines indicate the averagemargin value over source and target examples.
Thereis a clear drop in the average margin value after theshift.
This difference suggests that the margin canbe examined directly to detect a domain shift.
How-ever, these values vary considerably so extractinguseful information is not trivial.We evaluated the ability of A-distance trackers todetect such changes in margin values by simulat-ing domain shifts using each domain pair in a task(books to dvds, weblogs to newswire, etc.).
Foreach domain shift setting, we first trained a classi-fier on 1000 source domain instances.
In our ex-periments, we used three different classification al-gorithms: Support Vector Machines (SVM) (Chang5890 200 400 600 800 1000 1200 1400CWPM0200400600800100012001400SVMspamace2005sentiment 0 200 400 600 800 1000 1200 1400CWPM0200400600800100012001400MIRA0 200 400 600 800 1000 1200CWPM020040060080010001200CW0 50 100 150 200 250 300CWPM050100150200250300SVM0 50 100 150 200 250 300CWPM050100150200250300MIRA0 50 100 150 200 250 300CWPM050100150200250300CWFigure 3: The mean number of instances after a domain change at which theA-distance tracker detects a change.
Eachpoint represents the mean number of instances for CWPM (x-axis) and the SVM, MIRA and CW methods (y-axis).Datasets are indicated by different markers.
The second row zooms each plot to the bottom left corner of the first row.Points above the diagonal indicate SVM, MIRA or CW took longer to detect a change than CWPM.and Lin, 2001), MIRA (Crammer et al, 2006) andConfidence Weighted (CW) learning (Dredze et al,2008).
We evaluated each trained classifier on 500test examples to measure accuracy on the source do-main, and then used it to label examples in a stream.The first 500 examples in the stream were used forcalibrating our change detection methods.
The next500 examples were from the source domain, fol-lowed by 1500 examples from the target domain.Over these 2000 examples we ran each of our de-tection methods.
Experiments were repeated over10 fixed random data permutations.We automatically select A-distance intervals asfollows.
First, we computed the mean and varianceof the 500 calibration margins and then added inter-vals for .5 standard deviations away from the meanin each direction, .5 to 1 standard deviation in eachdirection, and intervals for 1 standard deviation to??.
We also added three evenly spaced overlap-ping intervals.
To calibrate a FP rate of 0.05 wesampled from a Gaussian with the above mean andvariance and used n = 200, m = 10000 and l = 50.The results for each experiment (38 shifts re-peated averaged over 10 runs each) are shown inFig.
3.2 Each plot represents one of the three classi-fiers (SVM, MIRA, CW) plotted on the vertical axis,where each point?s y-value indicates the number ofexamples observed after a shift occurred before theA-distance detector registered a change.
Smallervalues (lower points) are preferred.
The second rowof plots highlights the 0 to 300 region of the firstrow.
(The x-axis will be discussed in the next sec-tion.)
Notice that in many cases, a change was reg-istered within 300 examples, showing that domainshifts can be reasonably detected using the marginvalues alone.Equally important to detecting changes is robust-ness to false changes.
We evaluated the margin de-tector for false positives in two ways.
First, welogged any incorrectly detected changes before theshift.
For all three algorithms, there were very fewfalse positives (Table 1).
The highest false positiverate was about 1% (CW), while for the SVM experi-ments, not a single detector fired prematurely in anyexperiment.2The method plotted on the x-axis will be introduced inthe next section.
To evaluate the three methods in this section(SVM, MIRA, CW) compare the y-values.590Second, we sought to test the robustness of themethod over a long stream of examples where nochange occurred.
In this experiment, we selected 11domains that had a sufficient number of examplesto consider a long stream of source domain exam-ples.3 Rather than use 500 source domain examplesfollowed by 1500 target domain examples, all 2000examples were from the source domain.
All othersettings were the same.
For the SVM detector, outof 110 runs we detected 6 false positives, 3 of whichwere for the same data set (kitchen) (see Table 1.
)6 Confidence Weighted MarginsIn the previous section, we showed that margin val-ues could be used to detect domain shifts.
We nowexplore ways to reduce the number of target domainexamples needed to detect domain shift by improv-ing the margin values.Margin values are often taken as a measure ofprediction confidence.
From this perspective, theA-distance margin tracker identifies when predic-tion confidence drops.
Another task that relies onmargins as measures of confidence is active learn-ing, where uncertainty sampling for margin basedsystems is determined based on the magnitude ofthe predicted margin.
Dredze and Crammer (2008a)showed how Confidence Weighted (CW) learningcould be used to generate a more informative mea-sure of confidence for active learning.CW is an online algorithm inspired by the MIRAupdate (Crammer et al, 2006), which ensures a pos-itive margin while minimizing parameter change.CW replaces the Euclidean distance used in theMIRA update with the KL divergence over Gaussiandistributions.
CW learning maintains a Gaussiandistribution over linear weight vectors with mean?
?
RN and diagonal covariance ?
?
RN?N .Maintaining a distribution over prediction func-tions is appropriate for our task where we con-sider margin values as confidence.
We re-place the margin |w ?
x|, where w is a stan-dard linear classifier, with a probabilistic margin|(Prw?N (?i,?i) [sign(w ?
z) = 1])?12 | .Dredze andCrammer showed that this probabilistic margin canbe translated into a corrected geometric margin,3ACE: bc, bn, cts, nw, wl; Sentiment: books, dvd, electron-ics, kitchen, music, videowhich is computed as the normalized margin as M?
=M/?V , whereM is the meanM = ?
?x and V thevariance V = x>?x of a univariate Gaussian dis-tribution over the unsigned-margin M = w ?
x. Wecall this method CWPM, for Confidence WeightedProbabilistic Margin.We compared using CWPM to the standard mar-gins produced by an SVM, MIRA and CW classifierin the last section.
Fig.
3 shows the results of thesecomparisons.
In each plot, CWPM (normalized mar-gin) is plotted on the x-axis, indicating how manyexamples from the target domain were observed be-fore the detector identified a change.
The y-axis ineach plot is the number of instances observed forthe SVM, MIRA and CW methods.
As before, eachpoint is the average of the 10 randomized runs usedabove (assuming that detectors that did not fire do soat the end of the stream.)
Points above the diagonalindicate that CWPM detected a change sooner thanthe comparative method.
Of the 38 shifts, CWPMdetected domain shifts faster than an SVM 34 times,MIRA 26 times and CW 27 times.We repeated the experiments to detect false posi-tives for each margin based method.
Table 1 showsthe false positives for the 38 domain shifts consid-ered as well as the 11 false shift domain shifts.
Thefalse positive rates are among the lowest for CWPM.This shows that CWPM is a more useful indicatorfor detecting domain changes.7 Gradual ShiftsWe have shown detection of sudden shifts betweenthe source and target domains.
However, some shiftsmay happen gradually over time.
We evaluate thisby modifying the stream as follows: the first 500instances come from the source domain, and the re-maining 1500 are sampled randomly from the sourceand target domains.
The probability of an instancebeing drawn from the target domain at time i ispi(x = target) = i1500 , where i counts from the startof the shift at index 500.
The probability of sam-pling target domain data increases uniformly overthe stream.
At index 750 after the start of the shifteach domain is equally likely.
The ACE and Sen-timent datasets had sufficient data to be evaluatedin this setting.
Fig.
4 shows CWPM still performsbest, but results are close (SVM: 22 of 32, MIRA &5910 200 400 600 800 1000 1200 1400 1600CWPM02004006008001000120014001600SVMace2005sentiment 0 200 400 600 800 1000 1200 1400 1600CWPM02004006008001000120014001600MIRA0 200 400 600 800 1000 1200 1400 1600CWPM02004006008001000120014001600CWFigure 4: Gradual shift detection with SVM, MIRA or CW vs. CWPM.
There were no false positives.Domain Shift FPsAlgorithm True Shift False ShiftSec.
5: SVM 0 6Sec.
6: MIRA 2 13Sec.
6: CW 5 10Sec.
6: CWPM 1 6Total tests 380 110Table 1: False positives (FPs) observed in true domainshift and false domain shift experiments for methods incorresponding sections.
Each setting was run 10 times,resulting in 380 true domain shifts and 110 false shifts.CW: 17 of 32).
As expected, detections happen laterin the stream.
The closer results are likely due tothe increased difficulty of the task.
With less clearinformation, there it is more difficult for all the al-gorithms to recognize a change, and performanceacross the methods begins to equalize.
Even in thismore difficult setting, CWPM is the best performer.8 Comparison to Supervised InformationSo far we have considered applying A-distancetracking to information freely available in a realworld system: the classification margins.
As a use-ful baseline for comparison, we can measure usingsupervised sources of information, where additionalinformation is provided that is not normally avail-able.
In particular, we investigate two types of su-pervised knowledge: the labels of examples in thestream and knowledge of the target domain.
In eachcase, we compare using the A-distance and CWPMversus applying the A-distance to supervised infor-mation.8.1 Classifier AccuracyIn Sec.
4 we showed that both the margin and recentclassifier accuracy indicate when shifts in domainsoccur (Fig.
2).
We developed techniques based onthe margin, which is available at test time.
We nowconsider knowledge of the true labels for these testexamples, which allows for tracking classifier accu-racy.
We can use the A-distance to detect when un-expected changes in accuracy occur.For each test example classified by the system,we evaluated whether the system was correct in itsprediction by examining the label.
If the classifierwas correct, we output a 1; otherwise, we output a0.
Over this 1/0 stream produced by checking clas-sifier accuracy we ran an A-distance detector, withintervals set for 1s and 0s (10,000 uniform samplesto calibrate the threshold for a false positive rate of0.05.)
If an unusual number of 0s or 1s occur ?more or less mistakes than on the source domain ?
achange is detected.4 Results on this accuracy streamare compared to CWPM (Fig.
5.)
Despite this su-pervised information, CWPM still detects domainchanges faster than with labeled examples.
Consideragain Fig.
2, which shows both accuracy and marginvalues over time.
While the average accuracy drops,the instantaneous value is very noisy, suggesting thateven this additional information may not yield bet-ter domain shift detection.
This will be interestingto explore in future work.4An alternate approach would be to measure accuracy di-rectly as a real valued number.
However, our experimentsshowed the discrete approach to be more effective.5920 200 400 600 800 1000 1200 1400 1600CWPM02004006008001000120014001600AccuracyDetector0 50 100 150 200 250 300CWPM050100150200250300AccuracyDetectorFigure 5: An A-distance accuracy detector, run over a stream of 1s and 0s indicating correct and incorrect predictionsof the classifier on examples in a stream.
The bulk of points above the line indicate that CWPM is more effective atdetecting domain change.
CWPM had a single false positive and the accuracy detector had no false positives.8.2 Domain ClassificationNext, we consider another source of supervision:a selection of examples known to be from the tar-get domain.
In this setting, we know that a shiftwill occur and we know to which domain it will oc-cur.
This requires a sample of (unlabeled) target do-main examples when the target domain is not knownahead of time.
Using a common approach to detect-ing domain differences when data is available fromboth domains (Ben-David et al, 2009; Blitzer et al,2007; Rai et al, 2010), we train a binary classifierto differentiate between the source and target do-main.
We learn a CW classifier on 1000 examples(500 from each domain) that do not appear in thetest stream.
We then label each example as either?source?
or ?target?
and output a 1 or 0 accordingly.Over this 0/1 stream, we run an A-distance detectorwith two intervals, one for 1s and one for 0s.
Theremaining setup is identical to theA-distance exper-iments above.Fig.
6 shows the detection rate of CWPM versusA-distance over the domain classifier stream.
As ex-pected, the detection rate for the domain classifieris very fast, in almost every case (save 1) less than400 examples after the shift happens.
When CWPMis slow to detect a change (over 400 examples), thedomain classifier is the clear winner.
However, inthe majority of experiments, especially for ACE andspam data, both detectors register a change quickly.These results suggest that while a sample of targetdomain examples is very helpful, our CWPM ap-proach can also be effective when such samples arenot available.9 Related WorkEarly NLP work in the unsupervised setting moni-tored classification confidence values, setting a con-fidence threshold based on a break-even heuristic,monitoring the rate of (presumed) irrelevant exam-ples based on this threshold, and signaling a changewhen this rate increased (Lanquillon, 1999).Confidence estimation has been used for specificNLP components such as information extraction.The correctness of fields extracted via a conditionalrandom field extractor has been shown to corre-late well to an estimate obtained by a constrainedforward-backward technique (Culotta and McCal-lum, 2004).
EM-based confidence estimation hasbeen used to estimate the confidence of patternsderived from partially supervised relation extrac-tion (Agichtein, 2006).
Confidence estimation hasalso been used to improve the overall effectivenessof NLP systems.
Confidence estimates obtained vianeural networks have shown gains for speech recog-nition, spoken language understanding, and machinetranslation (Gandrabur et al, 2006).
Pipeline modelsusing confidence estimates at one stage as weightsfor further downstream stages improve over base-line dependency parsing and named entity recogni-tion pipeline models (Bunescu, 2008).An alternative formulation of domain adaptationtrains on different corpora from many different do-mains, then uses linear combinations of modelstrained on the different corpora(McClosky et al,2010).Work in novelty detection is relevant to the taskof detecting domain shifts (Scholkopf et al, 2000),5930 200 400 600 800 1000 1200CWPM020040060080010001200Domain Classifier0 50 100 150 200 250 300CWPM050100150200250300Domain ClassifierFigure 6: A-distance over a stream of 1s and 0s produced by a supervised classifier trained to differentiate betweenthe source and target domain.
Samples from the unseen target domain is very effective.
However, for many shifts, themargin based A-distance detector is still competitive.
CWPM had a single false positive while the domain classifierstream had 2 false positives in these experiments.though the rate of occurrence of novel instances ismore informative in our setting than the mere factthat novel instances are observed.We are also motivated by the problem of detect-ing genre shift in addition to domain shift, as in theACE 2005 data set shifts from newswire to tran-scripts and blogs.
Different text genres occur in tra-ditional settings, such as broadcast news transcriptsand newswire, and have begun to proliferate withthe variety of social media technologies now avail-able including weblogs.
Static genre classificationhas been explored using a variety of techniques, in-cluding exploiting punctuation (Kessler et al, 1997;Dewdney et al, 2001), TF-IDF statistics (Lee andMyaeng, 2002), and part-of-speech statistics andhistograms (Finn and Kushmerick, 2006; Feldmanet al, 2009).Finally, statistical estimation in a streaming con-text has been considered in data mining applica-tions (Muthukrishnan, 2005).
Change detectionvia sequential hypothesis testing has been effectivefor streaming applications such as network intrusiondetection (Muthukrishnan et al, 2007).
Detectingnew events in a stream of Twitter posts can be doneusing constant time and space similarity measuresbased on a modification of locality sensitive hash-ing (Petrovic?
et al, 2010).10 ConclusionWhile there are a number of methods for domainadaptation, a system first needs to determine that adomain shift has occurred.
We have presented meth-ods for automatically detecting such domain shiftsfrom a stream of (unlabeled) examples that requirelimited computation and memory by virtue of op-erating on fixed-size windows of data.
Our meth-ods were evaluated empirically on a variety of do-main shifts using NLP data sets and are shown tobe sensitive to shifts while maintaining a low rate offalse positives.
Additionally, we showed improveddetection results using a probabilistic margin basedon Confidence Weighted learning.
Comparisons todetection with supervised information show that ourresults are effective even in unlabeled settings.
Ourmethods are promising as tools to accompany the de-ployment of domain adaptation algorithms, so that acomplete system can first identify when a domainshift has occurred before automatically adapting tothe new domain.AcknowledgmentsThanks to the HLTCOE text processing group formany helpful discussions.ReferencesEugene Agichtein.
2006.
Confidence estimation meth-ods for partially supervised information extraction.
InSDM.Shai Ben-David, John Blitzer, Koby Crammer, and Fer-nando Pereira.
2006.
Analysis of representations fordomain adaptation.
In NIPS.Shai Ben-David, John Blitzer, Koby Crammer, AlexKulesza, Fernando Pereira, and Jennifer Vaughan.2009.
A theory of learning from different domains.Machine Learning.594John Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In EMNLP.John Blitzer, Mark Dredze, and Fernando Pereira.
2007.Biographies, Bollywood, boom-boxes and blenders:Domain adaptation for sentiment classification.
In As-sociation for Computational Linguistics (ACL).Razvan C. Bunescu.
2008.
Learning with probabilisticfeatures for improved pipeline models.
In EMNLP.Chih-Chung Chang and Chih-Jen Lin, 2001.
LIB-SVM: a library for support vector machines.
Soft-ware available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer.
2006.
Online passive-aggressive algorithms.
Journal of Machine LearningResearch (JMLR).Aron Culotta and Andrew McCallum.
2004.
Confidenceestimation for information extraction.
In North Amer-ican Chapter of the Association for ComputationalLinguistics - Human Language Technologies (NAACL-HLT).Hal Daume?.
2007.
Frustratingly easy domain adaptation.In Association for Computational Linguistics (ACL).Nigel Dewdney, Carol VanEss-Dykema, and RichardMacMillan.
2001.
The form is the substance: clas-sification of genres in text.
In Workshop on HumanLanguage Technology and Knowledge Management.Mark Dredze and Koby Crammer.
2008a.
Active learn-ing with confidence.
In Association for ComputationalLinguistics (ACL).Mark Dredze and Koby Crammer.
2008b.
Online meth-ods for multi-domain learning and adaptation.
InEMNLP.Mark Dredze, Koby Crammer, and Fernando Pereira.2008.
Confidence-weighted linear classification.
InICML.S.
Feldman, M. A. Marin, M. Ostendorf, and M. R.Gupta.
2009.
Part-of-speech histograms for genreclassification of text.
In International Conference onAcoustics, Speech, and Signal Processing (ICASSP).Jenny Rose Finkel and Christopher D. Manning.
2009.Hierarchical Bayesian domain adaptation.
In NAACL-HLT.Aidan Finn and Nicholas Kushmerick.
2006.
Learning toclassify documents according to genre: Special topicsection on computational analysis of style.
J.
Am.
Soc.Inf.
Sci.
Technol., 57(11):1506?1518.Simona Gandrabur, George Foster, and Guy Lapalme.2006.
Confidence estimation for NLP applications.ACM Trans.
Speech Lang.
Process., 3(3):1?29.Jing Jiang and ChengXiang Zhai.
2007.
Instance weight-ing for domain adaptation in NLP.
In Association forComputational Linguistics (ACL).Brett Kessler, Geoffrey Numberg, and Hinrich Schu?tze.1997.
Automatic detection of text genre.
In Associa-tion for Computational Linguistics (ACL).Daniel Kifer, Shai Ben-David, and Johannes Gehrke.2004.
Detecting change in data streams.
In Very LargeData Bases (VLDB).Ralf Klinkenberg and Thorsten Joachims.
2000.
Detect-ing concept drift with support vector machines.
In In-ternational Conference on Machine Learning (ICML).C.
Lanquillon.
1999.
Information filtering in changingdomains.
In IJCAI.Yong-Bae Lee and Sung Hyon Myaeng.
2002.
Textgenre classification with genre-revealing and subject-revealing features.
In SIGIR.David McClosky, Eugene Charniak, and Mark Johnson.2010.
Automatic domain adaptation for parsing.
InNAACL-HLT, pages 28?36, Los Angeles, California,June.
Association for Computational Linguistics.S.
Muthukrishnan, Eric van den Berg, and Yihua Wu.2007.
Sequential change detection on data streams.
InIEEE International Conference on Data Mining Work-shops (ICDMW).S.
Muthukrishnan.
2005.
Data streams: Algorithms andapplications.
Foundations and Trends in TheoreticalComputer Science, 1(2).Kyosuke Nishida and Koichiro Yamauchi.
2007.
Detect-ing concept drift using statistical testing.
In DiscoveryScience.Kyosuke Nishida.
2008.
Learning and Detecting Con-cept Drift.
Ph.D. thesis, Hokkaido University, Japan.Sas?a Petrovic?, Miles Osborne, and Victor Lavrenko.2010.
Streaming first story detection with applicationto twitter.
In NAACL-HLT, pages 181?189, June.P.
Rai, A. Saha, H. Daume?
III, and S. Venkatasubrama-nian.
2010.
Domain Adaptation meets Active Learn-ing.
In Workshop on Active Learning for Natural Lan-guage Processing (ALNLP), page 27.Bernhard Scholkopf, Robert Williamson, Alex Smola,John Shawe-Taylor, and John Platt.
2000.
Supportvector method for novelty detection.
In NIPS.Gerhard Widmer and Miroslav Kubat.
1996.
Learningin the presence of concept drift and hidden contexts.Machine Learning, 23:69?101.595
