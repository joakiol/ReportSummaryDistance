Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 49?54,Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational LinguisticsArgument extraction for supporting public policy formulationEirini FlorouDept of Linguistics, Faculty of PhilosophyUniversity of Athens, Greeceeirini.florou@gmail.comlStasinos KonstantopoulosInstitute of Informatics andTelecommunications, NCSR ?Demokritos?konstant@iit.demokritos.grAntonis Kukurikos Pythagoras KarampiperisInstitute of Informatics and Telecommunications, NCSR ?Demokritos?, Athens, Greece{kukurik,pythk}@iit.demokritos.grAbstractIn this paper we describe an applicationof language technology to policy formula-tion, where it can support policy makersassess the acceptance of a yet-unpublishedpolicy before the policy enters public con-sultation.
One of the key concepts is thatinstead of relying on thematic similarity,we extract arguments expressed in supportor opposition of positions that are generalstatements that are, themselves, consistentwith the policy or not.
The focus of thispaper in this overall pipeline, is identify-ing arguments in text: we present and em-pirically evaluate the hypothesis that ver-bal tense and mood are good indicators ofarguments that have not been explored inthe relevant literature.1 IntroductionThe large-scale acquisition, thematic classifica-tion, and sentiment analysis of Web content hasbeen extensively applied to brand monitoring, dig-ital reputation management, product development,and a variety of similar applications.
More re-cently, it has also seen application in public policyvalidation, where the ?brand?
to be monitored isa publicized and widely commented governmentpolicy.All these methods typically rely on the seman-tic similarity between a given text or set of termsand Web content; often using domain-specific on-tological and terminological resources in order tomeasure this similarity.
This approach, howeverrequires that all parties involved discourse on thesame topic; that is to say, that we are seeking thecollective opinion of the Web on a topic that hasbeen publicized enough to attract the attention ofthe Web.In this paper we present a slightly different ap-proach, where we are looking for arguments ex-pressed in support or opposition of opinions withlittle semantic similarity to our topic of interest.As a rough example, consider how drafting envi-ronmental policy can benefit from access to statis-tics about how people felt about industrial growthat the expense of environmental concerns whenother policy in completely different domains wason public consultation: many of the argumentsabout the relative merits of industrial growth andenvironmental concerns can retain their structureand be thematically transferred to the new domain,helping draft a policy that best addresses people?sconcerns.Of paramount importance for implementingsuch an approach is the linguistic tools for identi-fying arguments.
In this paper, we first motivatethe inclusion of argument extraction inside thelarger policy formulation and validation cycle andpresent the position of an argument extraction toolinside a computational system for supporting thiscycle (Section 2).
We then proceed to a present theargument extraction literature (Section 3) and ourhypothesis that verbal morpho-syntactic featuresare good discriminators of arguments (Section 4).We close the paper by presenting and discussingempirical results (Section 5) and concluding (Sec-tion 6).2 Policy formulation and validationOur work is carried out in the context of a projectthat develops computational tools for the earlyphases of policy making, before policy drafts havebeen made available for public consultation.1At that stage, the policy?s impact on publicopinion cannot be estimated by similarity-basedsearching for relevant Web content, since the pol-icy text has not been announced yet ?
or evenfully authored for that matter.
One of the core1Full details about the project have been suppressed topreserve anonymity, but will be included in the camera-ready.49ideas of the project is that in order to assist thepolicy formulation process, a tool needs to esti-mate the acceptance of a yet unpublished docu-ment based on Web content that is not themati-cally similar, but is rather supporting or opposing amore general position or maxim that also supportsor opposes the policy under formulation.To make this more concrete, consider a new pol-icy for increasing the penetration of wind powerproduction, setting specific conditions and prior-ities.
The project is developing an authoring en-vironment where specific policy statements arelinked to more general statements, such as:(1) Greenhouse gas emissions should not be aconcern at all.
(2) It is desired to reduce greenhouse gasemissions, but this should be balancedagainst other concerns.
(3) It is desired to reduce greenhouse gasemissions at all costs.We have, thus, created a formulation of ?relevantcontent?
that includes Examples 1 and 2 below.These are taken from different domains, are com-menting policies and laws that are already formu-lated and made public, and can be used to inferthe level of support for the new wind power policyalthough no textual similarity exists.
(4) In case hard packaging is made compulsoryby law, producers will be forced to consumemore energy, leading to more greenhousegas emissions.
(5) Tidal power production does not emitgreenhouse gases, but other environmentalproblems are associated with its widespreaddeployment.Leaving aside the ontological conceptualizationthat achieves this matching, which is reported else-where, we will now discuss the language process-ing pipeline that retrieves and classifies relevantWeb content.Content is acquired via focused crawling, us-ing search engine APIs to retrieve public Webpages and social network APIs to retrieve con-tent from social content sharing platforms.
Con-tent is searched and filtered (in case of feed-likeAPIs) based on fairly permissive semantic similar-ity measures, emphasising a high retrieval rate atthe expense of precision.
As a second step, cleantext is extracted from the raw Web content usingthe Boilerpipe library (Kohlschu?tter et al 2010)in order to remove HTML tags, active compo-nents (e.g.
JavaScript snippets), and content thatis irrelevant to the main content (menus, ad sec-tions, links to other web pages), and also to replaceHTML entities with their textual equivalent, e.g.,replacing ?&amp;?
with the character ?&?.The resulting text is tokenized and sentence-splitted and each sentence classified as relevant ornot using standard information retrieval methodsto assess the semantic similarity of each sentenceto the general policy statements.
This is based onboth general-purpose resources2 and the domainontology for the particular policy.
Consecutivesentences that are classified as positive are joinedinto a segment.The main objective of the work described hereis the classification of these segments as beingrepresentative of a stance that would also supportor oppose the policy being formulated, given thepremise of the general statements (1)?(3).
Our ap-proach is to apply the following criteria:?
That they are semantically similar to the gen-eral statements associated with the policy.?
That they are arguments, rather than state-ments of fact or other types of prose.?
That their polarity towards the general state-ments is expressed.In order to be able to assess segments, we thusneed a linguistic pipeline that can calculate seman-tic similarity, identify arguments, and extract theirstructure (premises/consequences) and polarity (insupport or opposition).The focus of the work described here is iden-tifying arguments, although we also outline howthe features we are proposing can also be used inorder to classify chunks of text as premises or con-sequences.3 Related WorkThe first approaches of argument extraction wereconcentrated on building wide-coverage argument2WordNets are publicly available for both English andGreek, that is the language of the experiments reported here.Simpler semantic taxonomies can also be used; the accuracyof the semantic similarity measured here does not have a ma-jor bearing on the argument extraction experiments that arethe main contribution of this paper.50structure lexicons, originally manually Fitzpatrickand Sager (1980, 1981) and later from elec-tronic versions of conventional dictionaries, sincesuch dictionaries contain morpho-syntactic fea-tures Briscoe et al(1987).
More recently, the fo-cus shifted to automatically extracting these lex-ical resources from corpora Brent (1993) and tohybrid approaches using dictionaries and corpora.Works using syntactic features to extract top-ics and holders of opinions are numerous (Bethardet al 2005).
Semantic role analysis has alsoproven useful: Kim and Hovy (2006) used aFrameNet-based semantic role labeler to deter-mine holder and topic of opinions.
Similarly, Choiand Cardie (2006) successfully used a PropBank-based semantic role labeler for opinion holder ex-traction.Somasundaran et al(2008; 2010) argued thatsemantic role techniques are useful but not com-pletely sufficient for holder and topic identifica-tion, and that other linguistic phenomena must bestudied as well.
In particular, they studied dis-course structure and found specific cue phrasesthat are strong features for use in argument extrac-tion.
Discourse markers that are strongly associ-ated with pragmatic functions can be used to pre-dict the class of content, therefore useful featuresinclude the presence of a known marker such as?actually?, ?because?, ?but?.Tseronis (2011) describes three main ap-proaches to describing argument markers: GenevaSchool, Argument within Language Theory andthe Pragma-dialectical Approach.
According theGeneva School, there are three main types ofmarkers/connective, organisation markers, illocu-tionary function markers (the relations betweenacts) and interactive function markers.
Argumentwithin Language Theory is a study of individualwords and phrases.
The words identified are argu-ment connectors: these describe an argumentativefunction of a text span and change the potentialof it either realising or de-realising the span.
ThePragma-dialectical Approach looks at the contextbeyond words and expressions that directly refer tothe argument.
It attempts to identify words and ex-pressions that refer to any moves in the argumentprocess.
Similarly to Marcu and Echihabi (2002),the approach is to create a model of an ideal argu-ment and annotate relevant units.4 Approach and Experimental SetupAs seen above, shallow techniques are typicallybased on connectives and other discourse mark-ers in order to define shallow argument patterns.What has not been investigated is whether shallowmorpho-syntactic features, such as the tense andmood of the verbal constructs in a passage, canalso indicate argumentative discourse.Our hypothesis is that future and conditionaltenses and moods often indicate conjectures andhypotheses which are commonly used in argumen-tation techniques such as illustration, justification,rebuttal where the effects of a position counter tothe speaker?s argument are analysed.
Naturally,such features cannot be the sole basis of argumentidentification, so we need to experiment regardingtheir interaction with discourse markers.To make this more concrete, consider the exam-ples in Section 2: although both are perfectly validarguments that can help us infer the acceptance orrejection of a policy, in the first one future tenseis used to speculate about the effects of a policy;in the second example there is no explicit markerthat the effects of large-scale tidal power produc-tion are also a conjecture.Another difficulty is that conditional and fu-ture verbal groups are constructed using auxil-iary verbs and (in some languages) other auxil-iary pointers.
Consider, for example, the follow-ing PoS-tagged and chunked Greek translation ofExample 4:(6) [oi[the-NomPlparagogoi]npproducers-NounNomPl][tha[Pointer-Futipochreothoun]vpforce-Perf-3PP][na[Pointer-Subjkatanalosoun]vpconsume-Inf]?producers will be forced to consume?In order to be able to correctly assign simple fu-ture, information from the future pointer ?tha?needs to be combined with the perfective featureof finite verb form.
Conditionals, future perfect,past perfect, and similar tenses or moods like sub-juncive also involve the tense of the auxiliary verb,besides the future pointer and the main verb.We have carried out our experiments in Greeklanguage texts, for which we have developed aJAPE grammar3 that extract the tense and mood of3JAPE is finite state transducer over GATE annota-51Table 1: Categories of morpho-syntactic features extracted from text segments.Label Description FeaturesDM Absolute number of occurrences of discourse markers 5 numerical featuresfrom a given categoryRel Relative frequency of each of the 6 tenses and each of the 6 moods 12 numerical featuresRCm Relative frequency of each tense/mood 9 numerical featurescombination (only for those that actually appear).Bin Appearance of each of the 6 tenses and each of the 6 moods 12 binary featuresDom Most frequent tense, mood, and tense/mood combination 3 string featuresTOTAL 41 featureseach verb chunk.
The grammar uses patterns thatcombine the features of pointers and auxiliary andmain verbs, without enforcing any restrictions onwhat words (e.g., adverbs) might be interjected inthe chunk.
That is to say, the chunker is responsi-ble for identifying verb groups and our grammar isrestricted to propagating and combining the rightfeatures from each of the chunk?s constituents tothe chunk?s own feature structure.PoS-tagging and chunking annotations havebeen previously assigned by the ILSP suite ofGreek NLP tools (Papageorgiou et al 2000;Prokopidis et al 2011), as provided by the rele-vant ILSP Web Services4 to get PoS tagged andchunked texts in the GATE XML format.At a second layer of processing, we create onedata instance for each segment (as defined in Sec-tion 2 above) and for each such segment we ex-tract features relating to verbal tense/mood and tothe appearance of discourse markers.
The formerare different ways to aggregate the various tensesand moods found in the whole segment, by mea-suring relative frequencies, recording the appear-ance of a tense or mood even once, and namingthe predominant (most frequent) tense and mood;tense and mood are seen both individually and astense/mood combinations.Furthermore, we have defined five absolute fre-quency features which record the matching againstthe several patterns and keywords provided for thefollowing five categories of arguments:?
justification, matching patterns such as ?be-cause?, ?the reason being?, ?due to?, etc.tions.
Please see http://gate.ac.uk/sale/tao/splitch8.html The JAPE grammar we have developedwill be made available on-line; location cannot be yet dis-closed in order to preserve anonymity.4Currently at http://ilp.ilsp.gr?
explanation, matching patterns such as ?inother words?, ?for instance?, quotesfor thisreason(s), etc.?
deduction, ?as a consequence?, ?in accor-dance with the above?, ?proving that?, etc.?
rebuttal, ?despite?, ?however?, etc.?
conditionals, ?supposing that?, ?in case that?,etc.All features extracted by this process are givenon Table 1.5 Results and DiscussionWe have used the method described in Section 2in order to obtain 677 text segments, with a sizeranging between 10 and 100 words, with an av-erage of 60 words.
Of these, 332 were manuallyannotated to not be arguments; the remaining 345positive examples were obtained by oversamplingthe 69 segments in our corpus that we have manu-ally annotated to be arguments.5We have then applied the feature extraction de-scribed in Section 4 in order to set up a classifi-cation task for J48, the Weka6 implementation ofthe C4.5 decision tree learning algorithm (Quin-lan, 1992).
We have applied a moderate confi-dence factor of 0.25, noting that experimentingwith the confidence factor did not yield any sub-stantially different results.In order to better understand the feature space,we have run a series of experiments, with quan-titative results summarized in Table 2.
The first5The data and relevant scripts for carrying out theseexperiments are available at http://users.iit.demokritos.gr/?konstant/dload/arguments.tgz6Please see http://www.cs.waikato.ac.nz/ml/weka52Table 2: Precision and recall for retrieving arguments using different feature mixtures.
Please cf.
Table 1for an explanation of the feature labels.
The results shown are the 10-fold cross-validation mean.Morpho-syntactic With Discourse Markers Without Discourse Markersfeatures used Prec.
Rec.
F?=1 Prec.
Rec.
F?=1All 75.8% 71.9% 73.8% 75.5% 70.4% 72.9%no Dom 79.8% 73.3% 76.4% 74.0% 71.9% 72.9%no Rel 74.5% 72.8% 73.8% 73.1% 69.3% 71.1%no RCm 76.3% 71.0% 73.6% 76.8% 70.1% 73.3%no Bin 70.0% 70.4% 70.2% 66.7% 69.6% 68.1%Rel 73.4% 75.9% 74.6% 70.3% 72.2% 71.2%Dom 57.1% 98.8% 72.4% 54.9% 94.2% 69.4%RCm 69.3% 66.7% 67.9% 71.9% 62.9% 67.1%Bin 71.7% 49.9% 58.8% 70.1% 44.9% 54.8%None 67.9% 20.9% 31.9% ?observation is that both morpho-syntactic featuresand discourse markers are needed, because if ei-ther category is omitted results deteriorate.
How-ever, not all morpho-syntactic features are needed:note how omitting the Dom, Rel, or RCm cate-gories yields identical or improved results.
On theother hand, the binary presence feature categoryBin is significant (cf.
5th row).
We cannot, how-ever, claim that only the Bin category is sufficient,and, in fact, if one category has to be chosen thatwould have to be that of relative frequency fea-tures (cf.
rows 6-9).6 ConclusionWe describe here an application of language tech-nology to policy formulation, and, in particular, tousing Web content to assess the acceptance of ayet-unpublished policy before public consultation.The core of the idea is that classifying Web con-tent as similar to the policy or not does apply, be-cause the policy document has not been made pub-lic yet; but that we should rather extract argumentsfrom Web content and assess whether these arguein favour or against general concepts that are (orare not) consistent with the policy being formu-lated.As a first step to this end, our paper focuseson the identification of arguments in Greek lan-guage content using shallow features.
Based onour observation that verb tense appears to be a sig-nificant feature that is not exploited by the rele-vant literature, we have carried out an empiricalevaluation of this hypothesis.
We have, in partic-ular, demonstrated that the relative frequency ofeach verb tense/mood and the binary appearanceof each verb tense/mood inside a text segment areas discriminative of argumentative text as the (typ-ically used) discourse markers; and that classifica-tion is improved by combining discourse markerfeatures with our verbal tense/mood features.
Fordoing this, we developed a regular grammar thatcombines the PoS tags of the members of a verbchunk in order to assign tense and mood to thechunk.
In this manner, our approach depends onPoS taggin and chunking only.In subsequent steps of our investigation, we areplanning to refine our approach to extracting ar-gument structure: it would be interesting to testif argument premises tend to correlate with cer-tain tenses or moods, distinguishing them fromfrom conclusions.
Further experiments can alsoexamine if the simultaneous appearance of con-crete tenses at the same sentence is an indicatorof an argument.
Finally, we plan to examine thepredicates of an argument, and especially if thehead word of each sentence (be it verb or deverbalnoun) and its seat at the boundaries of the sentencemay contribute to extract an argument or not, espe-cially for impersonal, modal, and auxiliary verbs.AcknowledgementsThe research leading to these results has re-ceived funding from the European Union?s Sev-enth Framework Programme (FP7/2007-2013) un-der grant agreement no 288513.
For more de-tails, please see the NOMAD project?s website,http://www.nomad-project.eu53ReferencesSteven Bethard, Hong Yu, Ashley Thornton,Vasileios Hatzivassiloglou, and Dan Jurafsky.2005.
Extracting opinion propositions and opin-ion holders using syntactic and lexical cues.
InJames G. Shanahan, Yan Qu, and Janyce Wiebe,editors, Computing Attitude and Affect in Text:Theory and Applications.
Springer.Michael Brent.
1993.
From grammar to lexi-con: unsupervised learning of lexical syntax.In Computational Linguistics - Special issue onusing large corpora: II, Volume 19 Issue 2,pages 243?262.Ted Briscoe, Claire Grover, Bran Boguraev, andJohn.
Carroll.
1987.
The derivation of agrammatically-indexed lexicon from the long-man dictionary of contemporary english.
InProceeding of ACL ?87.Yejin Choi and Claire Cardie.
2006.
Joint extrac-tion of entities and relations for opinion recog-nition.
In Proceedings of EMNLP 2006.Eileen Fitzpatrick and Naomi Sager.
1980.
TheLexical subclasses of the LSP English Gram-mar.
Linguistic String Project, New York Uni-versity.Eileen Fitzpatrick and Naomi Sager.
1981.
Thelexical subclasses of the lsp english grammar.In N. Sager (ed), Natural Language InformationProcessing, Addison- Wesley, Reading, Ma.Soo-Min Kim and Eduard Hovy.
2006.
Extract-ing opinions, opinion holders, and topics ex-pressedin online news media text.
In Proceed-ings of ACL/COLING Workshop on Sentimentand Subjectivity in Text.Christian Kohlschu?tter, Peter Fankhauser, andWolfgang Nejdl.
2010.
Boilerplate detection us-ing shallow text features.
In Proc.
3rd ACMInternational Conference on Web Search andData Mining (WSDM 2010) New York, USA.Daniel Marcu and Abdessamad Echihabi.
2002.An unsupervised approach to recognizing dis-course relations.
In Proc.
ACL ?02.Haris Papageorgiou, Prokopis Prokopidis, VoulaGiouli, and Stelios Piperidis.
2000.
A unifiedPOS tagging architecture and its application toGreek.
In Proceedings of the 2nd LanguageResources and Evaluation Conference (LREC2000), Athens, Greece, pages 1455?1462.Prokopis Prokopidis, Byron Georgantopoulos, andHaris Papageorgiou.
2011.
A suite of NLP toolsfor Greek.
In Proceedings of the 10th Interna-tional Conference of Greek Linguistics (ICGL2011), Komotini, Greece.J.
Ross Quinlan.
1992.
C4.5: Programs for Ma-chine Learning.
Morgan Kaufmann, San Mateo,CA, USA.Swapna Somasundaran and Janyce Wiebe.
2010.Recognizing stances in ideological on-line de-bates.
In Proc.
NAACL HLT Workshop on Com-putational Approaches to Analysis and Genera-tion of Emotion in Text (CAAGET 2010)Swapna Somasundaran, Janyce Wiebe, and JosephRuppenhofer.
2008.
Discourse level opinion in-terpretation.
In Proceedings of the 22nd Inter-national Conference on Computational Linguis-tics - Volume 1, COLING ?08, Stroudsburg, PA,USA.
Association for Computational Linguis-tics.Assimakis Tseronis.
2011.
From connectives toargumentative markers: A quest for markersof argumentative moves and of related aspectsof argumentative discourse.
Argumentation,25(4):427?444.54
