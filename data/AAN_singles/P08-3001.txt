Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 1?6,Columbus, June 2008. c?2008 Association for Computational LinguisticsA Supervised Learning Approach to Automatic Synonym Identificationbased on Distributional FeaturesMasato HagiwaraGraduate School of Information ScienceNagoya UniversityFuro-cho, Chikusa-ku, Nagoya 464-8603, JAPANhagiwara@kl.i.is.nagoya-u.ac.jpAbstractDistributional similarity has been widely usedto capture the semantic relatedness of words inmany NLP tasks.
However, various parame-ters such as similarity measures must be hand-tuned to make it work effectively.
Instead, wepropose a novel approach to synonym iden-tification based on supervised learning anddistributional features, which correspond tothe commonality of individual context typesshared by word pairs.
Considering the inte-gration with pattern-based features, we havebuilt and compared five synonym classifiers.The evaluation experiment has shown a dra-matic performance increase of over 120% onthe F-1 measure basis, compared to the con-ventional similarity-based classification.
Onthe other hand, the pattern-based features haveappeared almost redundant.1 IntroductionSemantic similarity of words is one of the most im-portant lexical knowledge for NLP tasks includingword sense disambiguation and automatic thesaurusconstruction.
To measure the semantic relatednessof words, a concept called distributional similarityhas been widely used.
Distributional similarity rep-resents the relatedness of two words by the common-ality of contexts the words share, based on the distri-butional hypothesis (Harris, 1985), which states thatsemantically similar words share similar contexts.A number of researches which utilized distri-butional similarity have been conducted, including(Hindle, 1990; Lin, 1998; Geffet and Dagan, 2004)and many others.
Although they have been success-ful in acquiring related words, various parameterssuch as similarity measures and weighting are in-volved.
As Weeds et al (2004) pointed out, ?it isnot at all obvious that one universally best measureexists for all application,?
thus they must be tuned byhand in an ad-hoc manner.
The fact that no theoreticbasis is given is making the matter more difficult.On the other hand, if we pay attention to lexicalknowledge acquisition in general, a variety of sys-tems which utilized syntactic patterns are found inthe literature.
In her landmark paper in the field,Hearst (1992) utilized syntactic patterns such as?such X as Y?
and ?Y and other X,?
and extractedhypernym/hyponym relation of X and Y. Roark andCharniak (1998) applied this idea to extraction ofwords which belong to the same categories, utiliz-ing syntactic relations such as conjunctions and ap-positives.
What is worth attention here is that super-vised machine learning is easily incorporated withsyntactic patterns.
For example, Snow et al (2004)further extended Hearst?s idea and built hypernymclassifiers based on machine learning and syntacticpattern-based features, with a considerable success.These two independent approaches, distributionalsimilarity and syntactic patterns, were finally inte-grated by Mirkin et al (2006).
Although they re-ported that their system successfully improved theperformance, it did not achieve a complete integra-tion and was still relying on an independent mod-ule to compute the similarity.
This configuration in-herits a large portion of drawbacks of the similarity-based approach mentioned above.
To achieve a fullintegration of both approaches, we suppose that re-1formalization of similarity-based approach wouldbe essential, as pattern-based approach is enhancedwith the supervised machine learning.In this paper, we propose a novel approach toautomatic synonym identification based on super-vised learning technique.
Firstly, we re-formalizesynonym acquisition as a classification problem:one which classifies word pairs into synonym/non-synonym classes, without depending on a singlevalue of distributional similarity.
Instead, classi-fication is done using a set of distributional fea-tures, which correspond to the degree of common-ality of individual context types shared by wordpairs.
This formalization also enables to incorporatepattern-based features, and we finally build five clas-sifiers based on distributional and/or pattern-basedfeatures.
In the experiment, their performances arecompared in terms of synonym acquisition precisionand recall, and the differences of actually acquiredsynonyms are to be clarified.The rest of this paper is organized as follows: inSections 2 and 3, distributional and pattern-basedfeatures are defined, along with the extraction meth-ods.
Using the features, in Section 4 we build fivetypes of synonym classifiers, and compare their per-formances in Section 5.
Section 6 concludes thispaper, mentioning the future direction of this study.2 Distributional FeaturesIn this section, we firstly describe how we extractcontexts from corpora and then how distributionalfeatures are constructed for word pairs.2.1 Context ExtractionWe adopted dependency structure as the context ofwords since it is the most widely used and well-performing contextual information in the past stud-ies (Ruge, 1997; Lin, 1998).
In this paper the sophis-ticated parser RASP Toolkit 2 (Briscoe et al, 2006)was utilized to extract this kind of word relations.We use the following example for illustration pur-poses: The library has a large collection of classicbooks by such authors as Herrick and Shakespeare.RASP outputs the extracted dependency structure asn-ary relations as follows:(ncsubj have library _)(dobj have collection)(det collection a)(ncmod _ collection large)(iobj collection of)(dobj of book)(ncmod _ book by)(dobj by author)(det author such)(ncmod _ author as)... ,whose graphical representation is shown in Figure 1.While the RASP outputs are n-ary relations ingeneral, what we need here is co-occurrences ofwords and contexts, so we extract the set of co-occurrences of stemmed words and contexts by tak-ing out the target word from the relation and replac-ing the slot by an asterisk ?*?
:library - (ncsubj have * _)library - (det * The)collection - (dobj have *)collection - (det * a)collection - (ncmod _ * large)collection - (iobj * of)book - (dobj of *)book - (ncmod _ * by)book - (ncmod _ * classic)author - (dobj by *)author - (det * such)...Summing all these up produces the raw co-occurrence count N(w, c) of the word w and thecontext c. In the following, the set of context typesco-occurring with the word w is denoted as C(w),i.e., C(w) = {c|N(w, c) > 0}.2.2 Feature ConstructionUsing the co-occurrences extracted above, we definedistributional features fDj (w1, w2) for the word pair(w1, w2).
The feature value fDj is determined so thatit represents the degree of commonality of the con-text cj shared by the word pair.
We adopted point-wise total correlation, one of the generalizations ofpointwise mutual information, as the feature value:fDj (w1, w2) = logP (w1, w2, cj)P (w1)P (w2)P (cj).
(1)The advantage of this feature construction is that,given the independence assumption between thewords w1 and w2, the feature value is easily calcu-lated as the simple sum of two corresponding point-wise mutual information weights as:fDj (w1, w2) = PMI(w1, cj) + PMI(w2, cj), (2)2The library has a large collection of classic books by such authors as Herrick and Shakespeare.ncsubjdobjdetncmod iobjdobj ncmod dobjdetncmoddobjconjconjncmoddet(dobj)(dobj)Figure 1: Dependency structure of the example sentence, along with conjunction shortcuts (dotted lines).where the value of PMI, which is also the weightswgt(wi, cj) assigned for distributional similarity, iscalculated as:wgt(wi, cj) = PMI(wi, cj) = logP (wi, cj)P (wi)P (cj).
(3)There are three things to note here: whenN(wi, cj) = 0 and PMI cannot be defined, thenwe define wgt(wi, cj) = 0.
Also, because it hasbeen shown (Curran and Moens, 2002) that negativePMI values worsen the distributional similarity per-formance, we bound PMI so that wgt(wi, cj) = 0if PMI(wi, cj) < 0.
Finally, the feature valuefDj (w1, w2) is defined as shown in Equation (2) onlywhen the context cj co-occurs with both w1 and w2.In other words, fDj (w1, w2) = 0 if PMI(w1, cj) =0 and/or PMI(w2, cj) = 0.3 Pattern-based FeaturesThis section describes the other type of features, ex-tracted from syntactic patterns in sentences.3.1 Syntactic Pattern ExtractionWe define syntactic patterns based on dependencystructure of sentences.
Following Snow et al(2004)?s definition, the syntactic pattern of wordsw1, w2 is defined as the concatenation of the wordsand relations which are on the dependency path fromw1 to w2, not including w1 and w2 themselves.The syntactic pattern of word authorsand books in Figure 1 is, for example,dobj:by:ncmod, while that of authors and Her-rick is ncmod-of:as:dobj-of:and:conj-of.Notice that, although not shown in the figure,every relation has a reverse edge as its counterpart,with the direction opposite and the postfix ?-of?attached to the label.
This allows to follow therelations in reverse, increasing the flexibility andexpressive power of patterns.In the experiment, we limited the maximumlength of syntactic path to five, meaning that wordpairs having six or more relations in between weredisregarded.
Also, we considered conjunction short-cuts to capture the lexical relations more precisely,following Snow et al (2004).
This modification cutsshort the conj edges when nouns are connected byconjunctions such as and and or.
After this shortcut,the syntactic pattern between authors and Herrick isncmod-of:as:dobj-of, and that of Herrick andShakespeare is conj-and, which is a newly intro-duced special symmetric relation, indicating that thenouns are mutually conjunctional.3.2 Feature ConstructionAfter the corpus is analyzed and patterns are ex-tracted, the pattern based feature fPk (w1, w2), whichcorresponds to the syntactic pattern pk, is definedas the conditional probability of observing pk giventhat the pair (w1, w2) is observed.
This definition issimilar to (Mirkin et al, 2006) and is calculated as:fPk (w1, w2) = P (pk|w1, w2) =N(w1, w2, pk)N(w1, w2).
(4)4 Synonym ClassifiersNow that we have all the features to consider, weconstruct the following five classifiers.
This sectiongives the construction detail of the classifiers andcorresponding feature vectors.Distributional Similarity (DSIM) DSIM classi-fier is simple acquisition relying only on distribu-tional similarity, not on supervised learning.
Simi-lar to conventional methods, distributional similar-ity between words w1 and w2, sim(w1, w2), is cal-culated for each word pair using Jaccard coefficient:?c?C(w1)?C(w2) min(wgt(w1, c),wgt(w2, c))?c?C(w1)?C(w2) max(wgt(w1, c),wgt(w2, c)),3considering the preliminary experimental result.
Athreshold is set on the similarity and classification isperformed based on whether the similarity is aboveor below of the given threshold.
How to optimallyset this threshold is described later in Section 5.1.Distributional Features (DFEAT) DFEAT clas-sifier does not rely on the conventional distributionalsimilarity and instead uses the distributional featuresdescribed in Section 2.
The feature vector ~v of aword pair (w1, w2) is constructed as:~v = (fD1 , ..., fDM ).
(5)Pattern-based Features (PAT) This classifierPAT uses only pattern-based features, essentially thesame as the classifier of Snow et al (2004).
Thefeature vector is:~v = (fP1 , ..., fPK).
(6)Distributional Similarity and Pattern-based Fea-tures (DSIM-PAT) DSIM-PAT uses the distribu-tional similarity of pairs as a feature, in additionto pattern-based features.
This classifier is essen-tially the same as the integration method proposedby Mirkin et al (2006).
Letting fS = sim(w1, w2),the feature vector is:~v = (fS , fP1 , ..., fPK).
(7)Distributional and Pattern-based Features(DFEAT-PAT) The last classifier, DFEAT-PAT,truly integrates both distributional and pattern-basedfeatures.
The feature vector is constructed byreplacing the fS component of DSIM-PAT withdistributional features fD1 , ..., fDM as:~v = (fD1 , ..., fDM , fP1 , ..., fPK).
(8)5 ExperimentsFinally, this section describes the experimental set-ting and the comparison of synonym classifiers.5.1 Experimental SettingsCorpus and Preprocessing As for the corpus,New York Times section (1994) of English Giga-word 1, consisting of approx.
46,000 documents,1http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogId=LDC2003T05922,000 sentences, and 30 million words, was an-alyzed to obtain word-context co-occurrences.This can yield 10,000 or more context types, thuswe applied feature selection and reduced the dimen-sionality.
Firstly, we simply applied frequency cut-off to filter out any words and contexts with lowfrequency.
More specifically, any words w suchthat?c N(w, c) < ?f and any contexts c such that?w N(w, c) < ?f , with ?f = 5, were removed.
DF(document frequency) thresholding is then applied,and context types with the lowest values of DF wereremoved until 10% of the original contexts were left.We verified through a preliminary experiment thatthis feature selection keeps the performance loss atminimum.
As a result, this process left a total of8,558 context types, or feature dimensionality.The feature selection was also applied to pattern-based features to avoid high sparseness ?
only syn-tactic patterns which occurred more than or equal to7 times were used.
The number of syntactic patterntypes left after this process is 17,964.Supervised Learning Training and test sets werecreated as follows: firstly, the nouns listed in theLongman Defining Vocabulary (LDV) 2 were cho-sen as the target words of classification.
Then, allthe LDV pairs which co-occur more than or equalto 3 times with any of the syntactic patterns, i.e.,{(w1, w2)|w1, w2 ?
LDV,?p N(w1, w2, p) ?
3}were classified into synonym/non-synonym classesas mentioned in Section 5.2.
All the positive-markedpair, as well as randomly chosen 1 out of 5 negative-marked pairs, were collected as the example set E.This random selection is to avoid extreme bias to-ward the negative examples.
The example set Eended up with 2,148 positive and 13,855 negativeexamples, with their ratio being approx.
6.45.The example set E was then divided into five par-titions to conduct five-fold cross validation, of whichfour partitions were used for learning and the one fortesting.
SVMlight was adopted for machine learn-ing, and RBF as the kernel.
The parameters, i.e.,the similarity threshold of DSIM classifier, gammaparameter of RBF kernel, and the cost-factor j ofSVM, i.e., the ratio by which training errors on pos-itive examples outweight errors on negative ones,2http://www.cs.utexas.edu/users/kbarker/working notes/ldoce-vocab.html4Table 1: Performance comparison of synonym classifiersClassifier Precision Recall F-1DSIM 33.13% 49.71% 39.76%DFEAT 95.25% 82.31% 88.30%PAT 23.86% 45.17% 31.22%DSIM-PAT 30.62% 51.34% 38.36%DFEAT-PAT 95.37% 82.31% 88.36%were optimized using one of the 5-fold cross valida-tion train-test pair on the basis of F-1 measure.
Theperformance was evaluated for the other four train-test pairs and the average values were recorded.5.2 EvaluationTo test whether or not a given word pair (w1, w2)is a synonym pair, three existing thesauri were con-sulted: Roget?s Thesaurus (Roget, 1995), CollinsCOBUILD Thesaurus (Collins, 2002), and WordNet(Fellbaum, 1998).
The union of synonyms obtainedwhen the head word is looked up as a noun is usedas the answer set, except for words marked as ?id-iom,?
?informal,?
?slang?
and phrases comprised oftwo or more words.
The pair (w1, w2) is marked assynonyms if and only if w2 is contained in the an-swer set of w1, or w1 is contained in that of w2.5.3 Classifier PerformanceThe performances, i.e., precision, recall, and F-1measure, of the five classifiers were evaluated andshown in Table 1.
First of all, we observed a drasticimprovement of DFEAT over DSIM ?
over 120%increase of F-1 measure.
When combined withpattern-based features, DSIM-PAT showed a slightrecall increase compared to DSIM, partially recon-firming the favorable integration result of (Mirkin etal., 2006).
However, the combination DFEAT-PATshowed little change, meaning that the discrimina-tive ability of DFEAT was so high that pattern-basedfeatures were almost redundant.
To note, the perfor-mance of PAT was the lowest, reflecting the fact thatsynonym pairs rarely occur in the same sentence,making the identification using only syntactic pat-tern clues even more difficult.The reason of the drastic improvement is that, asfar as we speculate, the supervised learning mayhave favorably worked to cause the same effect asautomatic feature selection technique.
Features withhigh discriminative power may have been automat-ically promoted.
In the distributional similarity set-ting, in contrast, the contributions of context typesare uniformly fixed.
In order to elucidate what ishappening in this situation, the investigations on ma-chine learning settings, as well as algorithms otherthan SVM should be conducted as the future work.5.4 Acquired SynonymsIn the second part of this experiment, we further in-vestigated what kind of synonyms were actually ac-quired by the classifiers.
The targets are not LDV,but all of 27,501 unique nouns appeared in the cor-pus, because we cannot rule out the possibility thatthe high performance seen in the previous exper-iment was simply due to the rather limited targetword settings.
The rest of the experimental settingwas almost the same as the previous one, except thatthe construction of training set is rather artificial ?we used all of the 18,102 positive LDV pairs andrandomly chosen 20,000 negative LDV pairs.Table 2 lists the acquired synonyms of video andprogram.
The results of DSIM and DFEAT are or-dered by distributional similarity and the value ofdecision function of SVM, respectively.
Notice thatbecause neither word is included in LDV, all thepairs of the query and the words listed in the tableare guaranteed to be excluded from the training set.The result shows the superiority of DFEAT overDSIM.
The irrelevant words (marked by ?*?
byhuman judgement) seen in the DSIM list are de-moted and replaced with more relevant words in theDFEAT list.
We observed the same trend for lowerranked words and other query words.6 Conclusion and Future DirectionIn this paper, we proposed a novel approach to au-tomatic synonym identification based on supervisedmachine learning and distributional features.
Forthis purpose, we re-formalized synonym acquisitionas a classification problem, and constructed the fea-tures as the total correlation of pairs and contexts.Since this formalization allows to integrate pattern-based features in a seamless way, we built five clas-sifiers based on distributional and/or pattern-basedfeatures.
The result was promising, achieving morethan 120% increase over conventional DSIM classi-5Table 2: Acquired synonyms of video and programFor query word: videoRank DSIM DFEAT1 computer computer2 television television3 movie multimedia4 film communication5 food* entertainment6 multimedia advertisement7 drug* food*8 entertainment recording9 music portrait10 radio movieFor query word: programRank DSIM DFEAT1 system project2 plan system3 project unit4 service status5 policy schedule6 effort* organization*7 bill* activity*8 company* plan9 operation scheme10 organization* policyfier.
Pattern-based features were partially effectivewhen combined with DSIM whereas with DFEATthey were simply redundant.The impact of this study is that it makes unneces-sary to carefully choose similarity measures such asJaccard?s ?
instead, features can be directly inputto supervised learning right after their construction.There are still a great deal of issues to address as thecurrent approach is only in its infancy.
For example,the formalization of distributional features requiresfurther investigation.
Although we adopted totalcorrelation this time, there can be some other con-struction methods which show higher performance.Still, we believe that this is one of the best ac-quisition performances achieved ever and will be animportant step to truly practical lexical knowledgeacquisition.
Setting our future direction on the com-pletely automatic construction of reliable thesaurusor ontology, the approach proposed here is to be ap-plied to and integrated with various kinds of lexicalknowledge acquisition methods in the future.AcknowledgmentsThe author would like to thank Assoc.
Prof. Katsu-hiko Toyama and Assis.
Prof. Yasuhiro Ogawa fortheir kind supervision and advice.ReferencesTed Briscoe, John Carroll and Rebecca Watson.
2006.The Second Release of the RASP System.
Proc.
of theCOLING/ACL 06 Interactive Presentation Sessions,77?80.Collins.
2002.
Collins Cobuild Major New Edition CD-ROM.
HarperCollins Publishers.James R. Curran and Marc Moens.
2002.
Improve-ments in automatic thesaurus extraction.
In Workshopon Unsupervised Lexical Acquisition.
Proc.
of ACLSIGLEX, 231?238.Christiane Fellbaum.
1998.
WordNet: an electronic lexi-cal database, MIT Press.Maayan Geffet and Ido Dagan.
2004.
Feature VectorQuality and Distributional Similarity.
Proc.
of COL-ING 04, 247?253.Zellig Harris.
1985.
Distributional Structure.
Jerrold J.Katz (ed.)
The Philosophy of Linguistics.
Oxford Uni-versity Press, 26?47.Marti A. Hearst.
1992.
Automatic Acquisition of Hy-ponyms from Large Text Corpora.
Proc.
of COLING92, 539?545.Donald Hindle.
1990.
Noun classification frompredicate-argument structures.
Proc.
of ACL 90, 268?275.Dekang Lin.
1998.
Automatic retrieval and clustering ofsimilar words.
Proc.
of COLING/ACL 98, 786?774.Shachar Mirkin, Ido Dagan, and Maayan Geffet.
2006.Integrating pattern-based and distributional similaritymethods for lexical entailment acquisition.
Proc.
ofCOLING/ACL 06, 579?586.Brian Roark and Eugene Charniak.
1998.
Nounphrase cooccurrence statistics for semi-automatic lex-icon construction.
Proc.
of COLING/ACL 98, 1110?1116.Roget.
1995.
Roget?s II: The New Thesaurus, 3rd ed.Houghton Mifflin.Gerda Ruge.
1997.
Automatic detection of thesaurus re-lations for information retrieval applications.
Founda-tions of Computer Science: Potential - Theory - Cogni-tion, LNCS, Volume 1337, 499?506, Springer Verlag.Rion Snow, Daniel Jurafsly, and Andrew Y. Ng.
2004.Learning syntactic patterns for automatic hypernymdiscovery.
Advances in Neural Information Process-ing Systems (NIPS) 17.Julie Weeds, David Weir and Diana McCarthy.
2004.Characterising Measures of Lexical DistributionalSimilarity.
Proc.
of COLING 04, 1015?1021.6
