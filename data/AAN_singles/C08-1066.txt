Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 521?528Manchester, August 2008Modeling Semantic Containment and Exclusionin Natural Language InferenceBill MacCartneyStanford Universitywcmac@cs.stanford.eduChristopher D. ManningStanford Universitymanning@cs.stanford.eduAbstractWe propose an approach to natural lan-guage inference based on a model of nat-ural logic, which identifies valid infer-ences by their lexical and syntactic fea-tures, without full semantic interpretation.We greatly extend past work in naturallogic, which has focused solely on seman-tic containment and monotonicity, to in-corporate both semantic exclusion and im-plicativity.
Our system decomposes an in-ference problem into a sequence of atomicedits linking premise to hypothesis; pre-dicts a lexical entailment relation for eachedit using a statistical classifier; propagatesthese relations upward through a syntaxtree according to semantic properties of in-termediate nodes; and composes the result-ing entailment relations across the edit se-quence.
We evaluate our system on theFraCaS test suite, and achieve a 27% re-duction in error from previous work.
Wealso show that hybridizing an existing RTEsystem with our natural logic system yieldssignificant gains on the RTE3 test suite.1 IntroductionA necessary (if not sufficient) condition for truenatural language understanding is a mastery ofopen-domain natural language inference (NLI):the task of determining whether a natural-languagehypothesis can be inferred from a given premise.Indeed, NLI can enable more immediate applica-tions, such as semantic search and question an-c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.swering (Harabagiu and Hickl, 2006).
In recentyears a spectrum of approaches to robust, open-domain NLI have been explored within the con-text of the Recognizing Textual Entailment chal-lenge (Dagan et al, 2005).
Up to now, the mostsuccessful approaches have used fairly shallowsemantic representations, relying on measures oflexical or semantic overlap (Jijkoun and de Ri-jke, 2005), pattern-based relation extraction (Ro-mano et al, 2006), or approximate matching ofpredicate-argument structure (Hickl et al, 2006).Such methods, while robust and often effective,are at best partial solutions, unable to explain evensimple forms of logical inference.
For example,most shallow approaches would fail to license theintroduction of large in the following example:(1) Every firm saw costs grow more than expected,even after adjusting for inflation.Every large firm saw costs grow.At the other extreme, some researchers have ap-proached NLI as logical deduction, building onwork in theoretical semantics to translate sentencesinto first-order logic (FOL), and then applyinga theorem prover or model builder (Akhmatova,2005; Fowler et al, 2005).
Regrettably, such ap-proaches tend to founder on the myriad complexi-ties of full semantic interpretation, including tense,aspect, causality, intensionality, modality, vague-ness, idioms, indexicals, ellipsis, and many otherissues.
(What is the right FOL representation of(1), for example?)
FOL-based systems that haveattained high precision (Bos and Markert, 2006)have done so at the cost of very poor recall.This work explores a middle way, by develop-ing a computational model of what Lakoff (1970)called natural logic, which characterizes valid pat-terns of inference in terms of syntactic forms re-521sembling natural language as much as possible.1For example, natural logic might sanction (1) byobserving that: in ordinary (upward monotone)contexts, deleting modifiers preserves truth; indownward monotone contexts, inserting modifierspreserves truth; and every is downward monotonein its restrictor NP.
A natural logic system can thusachieve the expressivity and precision needed tohandle a great variety of simple logical inferences,while sidestepping the difficulties of full semanticinterpretation.2 A theory of natural logicThe natural logic approach originated in traditionallogic (e.g., Aristotle?s syllogisms), and was re-vived in a formal form by van Benthem (1986) andS?anchez Valencia (1991), who proposed a naturallogic based on categorial grammar to handle infer-ences involving containment relations and upwardand downward monotonicity, such as (1).
Theirmonotonicity calculus explains inferences involv-ing even nested inversions of monotonicity, but be-cause it lacks any representation of exclusion (asopposed to containment), it cannot explain simpleinferences such as (38) and (205) in table 2, below.Another model which arguably follows the nat-ural logic tradition (though not presented as such)was developed by Nairn et al (2006) to explain in-versions and nestings of implicative (and factive)predicates, as in Ed did not forget to force Dave toleave |= Dave left.
Their implication projection al-gorithm bears some resemblance to the monotonic-ity calculus, but does not incorporate containmentrelations or explain interactions between implica-tives and monotonicity, and thus fails to licenseJohn refused to dance |= John didn?t tango.We propose a new model of natural logic whichgeneralizes the monotonicity calculus to cover in-ferences involving exclusion, and (partly) unifiesit with Nairn et al?s model of implicatives.
We(1) augment the set of entailment relations usedin monotonicity calculus to include representationsof exclusion; (2) generalize the concept of mono-tonicity to one of projectivity, which describes howthe entailments of a compound expression dependon the entailments of its parts; and (3) describe aweak proof procedure based on composing entail-ment relations across chains of atomic edits.1Natural logic should not be confused with natural deduc-tion, a proof system for first-order logic.Entailment relations.
We employ an inventoryof seven mutually exclusive basic entailment rela-tions, defined by analogy with set relations: equiv-alence (couch = sofa); forward entailment (crow@ bird) and its converse (European A French);negation, or exhaustive exclusion (human ?
non-human); alternation, or non-exhaustive exclusion(cat | dog); cover, or non-exclusive exhaustion (an-imal ` nonhuman); and independence (hungry #hippo), which covers all other cases.
As in themonotonicity calculus, we define these relationsfor expressions of every semantic type: sentences,common and proper nouns, transitive and intran-sitive verbs, adjectives, and so on.
For example,among generalized quantifiers, we find that all =every, every @ some, some?no, no | every, at leastfour ` at most six, and most # ten or more.2Projectivity.
In order to explain the entailmentsof a compound expression as a function of theentailments of its parts, we categorize semanticfunctions according to their projectivity class, aconcept which generalizes both S?anchez Valen-cia?s monotonicity classes (upward, downward,and non-monotone) and the nine implication sig-natures of Nairn et al The projectivity class ofa function f describes how the entailment rela-tion between f(x) and f(y) depends on the en-tailment relation between x and y.
Consider sim-ple negation (not).
Like most functions, it projects= and # without change (not happy = not gladand isn?t swimming # isn?t hungry).
As a down-ward monotone function, it swaps @ and A (didn?tkiss A didn?t touch).
But we can also establishthat it projects ?
without change (not human ?
notnonhuman) and swaps | and ` (not French ` notGerman, not more than 4 | not less than 6).
Bycontrast, an implicative like refuse, though it alsoswaps@ andA (refuse to tangoA refuse to dance),projects ?
as | (refuse to stay | refuse to go) andprojects both | and ` as # (refuse to tango #refuse to waltz).Projectivity thus allows us to determine the en-tailments of a compound expression recursively,by propagating entailments upward through a se-mantic composition tree according to the projec-tivity class of each node on the path to the root.
Forexample, the semantics of Nobody can enter with-2Some of these assertions assume existential import, i.e.,that the predicates to which the quantifiers are applied havenon-empty denotations.
This assumption, standard in tradi-tional logic, seems justifiable in the context of informal natu-ral language inference (B?ottner, 1988).522out a shirt might be represented by the tree (no-body (can ((without (a shirt)) enter))).
Since shirt@ clothes, and since without is downward mono-tone, we have without shirt A without clothes.Since nobody is also downward monotone, it fol-lows that Nobody can enter without a shirt @ No-body can enter without clothes.Inference.
Let x?= e(x) be the result of ap-plying an atomic edit e (the insertion, deletion, orsubstitution of a subexpression) to a compound ex-pression x.
The entailment relation between x andx?is found by projecting the entailment relationgenerated by e upward through x?s semantic com-position tree.
Substitutions generate relations ac-cording to the meanings of the substituends.
Mostdeletions generate the @ relation (red socks @socks).
(Insertions are symmetric: they typicallygenerate A.)
However, some items have specialbehavior.
For example, deleting (or inserting) notgenerates?
(not hungry?hungry).If two expressions are connected by a chain ofatomic edits, we can determine the entailment re-lation between them by composing (as in Tarskianrelation algebra) the entailment relations generatedby each edit.
The result may be a basic entailmentrelation, or may be a union of such relations, withlarger unions conveying less information about en-tailment.
This possibility, coupled with the needto find a chain of atomic edits which preserves rel-evant entailment relations, limits the power of theproof procedure described.Implicatives.
The account of implicatives andfactives given by Nairn et al hinges on a classi-fication of implicative and factive operators intonine implication signatures, according to theirimplications?positive (+), negative (?
), or null(?
)?in both positive and negative contexts.
Thusrefuse has implication signature ?/?, because it car-ries a negative implication in a positive context (re-fused to dance implies didn?t dance), and no impli-cation in a negative context (didn?t refuse to danceimplies neither danced nor didn?t dance).Most of the phenomena observed by Nairn et alcan be explained within our framework by spec-ifying, for each signature, the relation generatedwhen an operator of that signature is deleted from acompound expression.
For example, deleting sig-nature ?/?
generates | (Jim refused to dance | Jimdanced); under negation, this is projected as `(Jim didn?t refuse to dance ` Jim didn?t dance).By contrast, deleting signature ?/?
generates A(Jim attempted to dance A Jim danced); undernegation, this is projected as @ (Jim didn?t attemptto dance @ Jim didn?t dance).3We can also account for monotonicity ef-fects of implicative and factive operatorsby describing the projectivity properties ofeach implication signature: signatures +/?,+/?, and ?/?
are upward monotone (attemptto tango @ attempt to dance); signatures?/+, ?/?, and ?/+ are downward monotone (refuseto dance @ refuse to tango); and signatures +/+,?/?, and ?/?
are non-monotone (think dancing isfun # think tangoing is fun).3 The NatLog systemOur implementation of natural logic, the NatLogsystem, uses a multi-stage architecture like thoseof (Marsi and Krahmer, 2005; MacCartney et al,2006), comprising (1) linguistic analysis, (2) align-ment, (3) lexical entailment classification, (4) en-tailment projection, and (5) entailment composi-tion.
We?ll use the following inference as a run-ning example:(2) Jimmy Dean refused to move without blue jeans.James Dean didn?t dance without pants.The example is admittedly contrived, but it com-pactly exhibits containment, exclusion, and im-plicativity.
How the NatLog system handles thisexample is depicted in table 1.Linguistic analysis.
Relative to other NLI sys-tems, the NatLog system does comparatively lit-tle linguistic pre-processing.
We rely on the Stan-ford parser (Klein and Manning, 2003), a PennTreebank-trained statistical parser, for tokeniza-tion, lemmatization, part-of-speech tagging, andphrase-structure parsing.By far the most important analysis performedat this stage, however, is projectivity marking, inwhich we compute the effective projectivity foreach token span in each input sentence.
In thepremise of (2), for example, we want to determinethat the effective projectivity is upward monotone3Factives, however, do not fit as neatly as implicatives:For example, deleting signature +/+ generates @ (Jim forgotthat dancing is fun @ dancing is fun); yet under negation, thisis projected not as A, but as | (Jim didn?t forget that danc-ing is fun | dancing isn?t fun).
The problem arises because theimplication carried by a factive is not an entailment, but a pre-supposition.
As is well known, the projection behavior of pre-suppositions differs from that of entailments (van der Sandt,1992).
In the current work, we set presuppositions aside.523premise Jimmy Dean refused to move without blue jeanshypothesis James Dean did n?t dance without pantsedit index 1 2 3 4 5 6 7 8edit type SUB DEL INS INS SUB MAT DEL SUBlex features str sim=0.67 implic:+/?
cat:aux cat:neg hyponym hypernymlex entrel = | = ?
A = @ @projectivity ?
?
?
?
?
?
?
?atomic entrel = | = ?
@ = @ @composition = | | @ @ @ @ @Table 1: An example of the operation of the NatLog model.unary operator: withoutpattern: IN < /?
[Ww]ithout$/argument 1: projectivity ?
on dominating PPpattern: __ > PP=projbinary operator: mostpattern: JJS < /?
[Mm]ost$/ !> QPargument 1: projectivity 6??
on dominating NPpattern: __ >+(NP) (NP=proj !> NP)argument 2: projectivity ?
on dominating Spattern: __ >> (S=proj !> S)Figure 1: Some projectivity operator definitions.for Jimmy Dean and refused to, downward mono-tone for move and without, and upward monotonefor blue and jeans.
Our choice of a Treebank-trained parser (driven by the goal of broad cov-erage) complicates this effort, because the nestingof constituents in phrase-structure parses does notalways correspond to the structure of idealized se-mantic composition trees.
Our solution is imper-fect but effective.
We define a list of operator typesaffecting projectivity (e.g., implicatives like refuseto, prepositions like without), and for each type wespecify its arity and a Tregex tree pattern (Levy andAndrew, 2006) which permits us to identify its oc-currences in our Treebank parses.
We also specify,for each argument position of each type, both theprojectivity class and another Tregex pattern whichhelps us to determine the sentence span over whichthe operator?s effect is projected.
(Figure 1 showssome example definitions.)
The marking processcomputes these projections, performs projectivitycomposition where needed, and marks each tokenspan with its final effective projectivity.Alignment.
Next, we establish an alignment be-tween the premise P and hypothesis H , repre-sented by a sequence of atomic edits over spansof word tokens.
This alignment representationis symmetric and many-to-many, and is generalenough to include various other alignment repre-sentations as special cases.
We define four edittypes: deletion (DEL) of a span from P , insertion(INS) of a span into H , substitution (SUB) of an Hspan for a P span, and match (MAT) of an H spanto a P span.
Each edit is parameterized by the to-ken indices at which it operates, and edit indicesmay ?cross?, permitting representation of move-ment.
The first four lines of table 1 depict a possi-ble alignment for our example problem.An alignment decomposes an inference probleminto a sequence of atomic inference problems, onefor each atomic edit.
Note that edits are ordered,and that this ordering defines a path from P to Hthrough intermediate forms.
(Edit order need notcorrespond to sentence order, though it does in ourexample.)
The relative ordering of certain kindsof edits (e.g., the insertion of not) may influencethe effective projectivity applicable for other edits;consequently, the NatLog system can reorder editsto maximize the benefit of the projectivity markingperformed during linguistic analysis.This paper does not present new algorithms foralignment; we focus instead on identifying en-tailment relations between aligned sentence pairs.The experiments described in sections 4 and 5 usealignments from other sources.Lexical entailment classification.
Much of theheavy lifting in the NatLog system is done by thelexical entailment model, which uses a classifierto predict an entailment relation for each atomicedit based solely on features of the lexical items in-volved, independent of context.
(For example, thismodel should assign the entailment relation A tothe edit SUB(move, dance), regardless of whetherthe effective projectivity at the locus of the edit isupward monotone, downward monotone, or some-thing else.)
In the case of a SUB edit, the featuresinclude:?
WordNet-derived measures of synonymy,hyponymy, and antonymy between sub-524stituends;?
other features indicating semantic related-ness: the WordNet-based Jiang-Conrath mea-sure (Jiang and Conrath, 1997) and a featurebased on NomBank (Meyers et al, 2004);?
string similarity features based on Leven-shtein string-edit distance between lemmas;?
lexical category features, indicating whetherthe substituends are prepositions, possessives,articles, auxiliaries, pronouns, proper nouns,operator adjectives, punctuation, etc.;?
quantifier category features, which identifyclasses of quantifiers with similar properties;?
a feature for unequal numeric expressionsFor DEL edits, we use only the lexical cate-gory features and a feature based on a custom-built resource which maps implicatives and fac-tives to their implication signatures.
(As noted insection 2, however, most DEL edits just have @ asthe target lexical entailment relation.)
INS edits aretreated symmetrically.The model uses a decision tree classifier trainedon 2,449 hand-annotated training examples (1,525SUB edits and 924 DEL/INS edits).
The decisiontree is minimally pruned, and contains about 180leaves.
When tested on the training data, the clas-sifier achieves >99% accuracy, indicating that ourfeature representation successfully captures nearlyall relevant distinctions between examples.Lexical features and lexical entailment relationsfor our example appear on lines 5 and 6 of table 1.Entailment projection.
The lexical entailmentrelations generated by each atomic edit can now beprojected upward to determine the correspondingatomic entailment relations, that is, the entailmentrelations between successive intermediate formson the path from P to H , as defined by the align-ment.
Strictly speaking, the effective projectivityfor a particular edit should be computed based onthe intermediate form upon which the edit oper-ates, since the projectivity properties of this formcan depend on preceding edits.
However, the Nat-Log system minimizes the need to compute projec-tivity in intermediate forms by reordering the editsin an alignment in such a way that effective projec-tivity can, in most cases, simply be taken from theprojectivity marking of P and H performed duringthe linguistic analysis stage.The effective projectivity and resulting atomicentailment relation for each edit in our running ex-ample are depicted in lines 7 and 8 of table 1.
Forall (non-MAT) edits but one, the effective projec-tivity is upward monotone, so that the atomic en-tailment relation is identical with the lexical en-tailment relation.
However, the SUB(move, dance)edit occurs in a downward monotone context, sothat the lexical relation A is converted to @ at theatomic level.Entailment composition.
Finally, the atomicentailment relations predicted for each edit arecombined, via relation composition, to produce anoverall prediction for the inference problem.
Re-lation composition is deterministic, and for themost part follows intuitive rules: @ composed with@ yields @; A composed with A yields A; #composed with any relation yields #; = com-posed with any relation yields that relation, andso on.
Composition tends to ?degenerate?
towards#, in the sense that the composition of a chainof randomly-selected relations tends toward # asthe chain grows longer.
This chaining of entail-ments across edits can be compared to the methodpresented in (Harmeling, 2007); however, that ap-proach assigns to each edit merely a probability ofpreserving truth, not an entailment relation.The last line of table 1 shows the cumulativecomposition of the atomic entailment relations inthe line above.
Particular noteworthy is the factthat | and?compose to yield @.
(To illustrate: if Aexcludes B (fish | human) and B is the negation ofC (human ?
nonhuman), then A entails C (fish @nonhuman).)
The final entailment relation in thisline, @, is NatLog?s final (and correct) answer forour example problem.4 Evaluating on FraCaS problemsThe FraCaS test suite (Cooper et al, 1996) con-tains 346 NLI problems, divided into nine sections,each focused on a specific category of semanticphenomena (listed in table 3).
Each problem con-sists of one or more premise sentences, a questionsentence, and one of three answers: yes (the unionof @ and =), no (the union of | and )?, or unknown(the union of A, `, and #).
Table 2 shows someexample problems.To facilitate comparison with previous work, wehave evaluated our system using a version of theFraCas data prepared by (MacCartney and Man-ning, 2007), in which multiple-premise problems(44% of the total) and problems lacking a hypoth-esis or a well-defined answer (3% of the total) areexcluded; question sentences have been converted525?
ID Premise Hypothesis Ans1 38 No delegate finished the report.
Some delegate finished the report on time.
no1 48 At most ten commissioners spend time at home.
At most ten c...s spend a lot of time at home.
yes2 83 Either Smith, Jones or Anderson signed the contract.
Jones signed the contract.
unk5 205 Dumbo is a large animal.
Dumbo is a small animal.
no6 233 ITEL won more orders than APCOM.
ITEL won some orders.
yes9 335 Smith believed that ITEL had won the contract in 1992.
ITEL won the contract in 1992. unkTable 2: Illustrative examples from the FraCaS test suiteSystem # P % R % Acc %most common class 183 55.74 100.00 55.74MacCartney07 183 68.89 60.78 59.56NatLog 183 89.33 65.69 70.49?
Section # P % R % Acc %1 Quantifiers 44 95.24 100.00 97.732 Plurals 24 90.00 64.29 75.003 Anaphora 6 100.00 60.00 50.004 Ellipsis 25 100.00 5.26 24.005 Adjectives 15 71.43 83.33 80.006 Comparatives 16 88.89 88.89 81.257 Temporal 36 85.71 70.59 58.338 Verbs 8 80.00 66.67 62.509 Attitudes 9 100.00 83.33 88.891, 2, 5, 6, 9 108 90.38 85.45 87.04Table 3: Performance on FraCaS problems (three-way classification).
The columns show the numberof problems, precision and recall for the yes class,and accuracy.
Results for NatLog are broken outby section.to declarative hypotheses; and alignments betweenpremise and hypothesis have been automaticallygenerated and manually corrected.Results are shown in table 3.
We achieve over-all accuracy of 70.49%, representing a 27% errorreduction from (MacCartney and Manning, 2007).In the section concerning quantifiers, which is boththe largest and the most amenable to natural logic,all problems but one are answered correctly.4Wealso answer all but one problems correctly in the(admittedly small) section on attitudes, which in-volves implicatives and factives.
Unsurprisingly,performance is mediocre in four sections concern-ing semantic phenomena (e.g., ellipsis) not rele-vant to natural logic and not modeled by the sys-tem.
But in the other five sections (about 60%of the problems), we achieve accuracy of 87.04%,an error reduction of 61% from (MacCartney and4In fact, the sole exception is disputable, since it hinges onwhether many refers to proportion (apparently, the view heldby the FraCaS authors) or absolute quantity.guessyes no unk totalyes 67 4 31 102answer no 1 16 4 21unk 7 7 46 60total 75 27 81 183Table 4: Confusions on FraCaS data (all sections)Manning, 2007).
What?s more, precision is high innearly every section: even outside its areas of ex-pertise, the system rarely predicts entailment whennone exists.Since the NatLog system was developed withFraCaS problems in mind, these results do not con-stitute a proper evaluation on unseen test data.
Onthe other hand, the system does no training on Fra-CaS data, and has had no opportunity to learn itsbiases.
(Otherwise, accuracy on ?4 could not fallso far below the baseline.)
The system not only an-swers most problems correctly, but usually does sofor valid reasons, particular within its areas of ex-pertise.
All in all, the results fulfill our main goalin testing on FraCaS: to demonstrate the represen-tational and inferential adequacy of our model ofnatural logic.The confusion matrix shown in table 4 revealsan interesting property of the NatLog system.
Thecommonest confusions are those where the answeris yes but we guess unknown.
This reflects boththe bias toward yes in the FraCaS data, and thesystem?s tendency to predict unknown (entailmentrelation #) when confused: given the compositionrules for entailment relations, the system can pre-dict yes only if all atomic-level predictions are ei-ther @ or =.5 Evaluating on RTE problemsNLI problems from the PASCAL RTE Challenge(Dagan et al, 2005) differ from FraCaS problemsin several important ways.
(See table 5 for ex-amples.)
Instead of textbook examples of seman-526ID Premise Hypothesis Answer71 As leaders gather in Argentina ahead of this weekendsregional talks, Hugo Ch?avez, Venezuela?s populist pres-ident is using an energy windfall to win friends and pro-mote his vision of 21st-century socialism.Hugo Ch?avez acts as Venezuela?s president.
yes788 Democrat members of the Ways and Means Committee,where tax bills are written and advanced, do not havestrong small business voting records.Democrat members had strong small businessvoting records.noTable 5: Illustrative examples from the RTE3 development settic phenomena, RTE problems are more natural-seeming, with premises collected ?in the wild?from newswire.
The premises are much longer,averaging 35 words (vs. 11 words for FraCaS).Also, RTE aims at binary classification: the RTEno combines the no and unk answers in FraCaS.Due to the character of RTE problems, we donot expect NatLog to be a good general-purposesolution to solving all RTE problems.
First, mostRTE problems depend on forms of inference, suchas paraphrase, temporal reasoning, or relation ex-traction, which NatLog is not designed to address.Second, in most RTE problems, the edit distancebetween premise and hypothesis is relatively large.More atomic edits means a greater chance that er-rors made in lexical entailment classification orprojection will propagate, via entailment compo-sition, to the system?s final output.
Rather, in ap-plying NatLog to RTE, we hope to make reliablepredictions on a subset of RTE problems, tradingrecall for precision.
If we succeed, then we maybe able to hybridize with a broad-coverage RTEsystem to obtain better results than either systemindividually?the same strategy that was adoptedby (Bos and Markert, 2006) for their FOL-basedsystem.
For this purpose, we have chosen to usethe Stanford RTE system described in (de Marn-effe et al, 2006).
We also use the Stanford systemto generate alignments when evaluating NatLog onRTE problems.Table 6 shows the performance of NatLogon RTE3 data.
Relative to the Stanford sys-tem, NatLog achieves high precision on itsyes predictions?above 70%?suggesting that hy-bridizing may be effective.
For comparison, theFOL-based system reported in (Bos and Markert,2006) attained a similarly high precision of 76%on RTE2 problems, but was able to make a pos-itive prediction in only about 4% of cases.
Nat-Log makes positive predictions far more often?inabout 25% of cases.The Stanford system makes yes/no predictionsSystem Data % Yes P % R % Acc %Stanford dev 50.25 68.66 66.99 67.25test 50.00 61.75 60.24 60.50NatLog dev 22.50 73.89 32.38 59.25test 26.38 70.14 36.10 59.38Hybrid, bal.
dev 50.00 70.25 68.20 68.75test 50.00 65.50 63.90 64.25Hybrid, opt.
dev 56.00 69.20 75.24 70.00test 54.50 64.45 68.54 64.50Table 6: Performance of various systems on RTE3(two-way classification).
The columns show thedata set used (800 problems each), the proportionof yes predictions, precision and recall for the yesclass, and accuracy.by thresholding a real-valued inference score.
Toconstruct a hybrid system, we adjust the Stanfordinference scores by +?
or ?
?, depending onwhether or not NatLog predicts yes.
We choose?
by optimizing development set accuracy, whileadjusting the threshold to generate balanced pre-dictions (that is, equal numbers of yes and no pre-dictions).
As an additional experiment, we fix ?at this value and then adjust the threshold to op-timize development set accuracy, resulting in anexcess of yes predictions.
(Since this optimiza-tion is based solely on development data, its useon test data is fully legitimate.)
Results for thesetwo cases are shown in table 6.
The parameterstuned on development data gave good results ontest data.
The optimized hybrid system attainedan absolute accuracy gain of 4% over the Stanfordsystem, corresponding to an extra 32 problems an-swered correctly.
This result is statistically signifi-cant (p < 0.05, McNemar?s test, 2-tailed).The gains attributable to NatLog are exempli-fied by problem 788 (table 5).
NatLog sanctionsthe deletion of a restrictive modifier and an appos-itive from the premise, and recognizes that delet-ing a negation generates a contradiction; thus itcorrectly answers no.
On the other hand, there527are many RTE problems where NatLog?s precisionworks against it.
For example, NatLog answers noto problem 71 because it cannot account for theinsertion of acts as in the hypothesis.
Fortunately,both the Stanford system and the hybrid system an-swer this problem correctly.6 ConclusionWe do not claim natural logic to be a universalsolution for NLI.
Many important types of infer-ence are not amenable to natural logic, includ-ing paraphrase (Eve was let go |= Eve lost herjob), verb alternation (he drained the oil |= theoil drained), relation extraction (Aho, a trader atUBS, ... |= Aho works for UBS), common-sensereasoning (the sink overflowed |= the floor gotwet), and so on.Moreover, because natural logic has a weakerproof theory than FOL, some inferences lie beyondits deductive power.
For example, it cannot explaininferences involving De Morgan?s laws for quanti-fiers, as in Not all birds fly = Some birds don?t fly.However, by incorporating semantic contain-ment, semantic exclusion, and implicativity, themodel of natural logic developed in this paper suc-ceeds in explaining a great variety of everyday pat-terns of inference.
Ultimately, open-domain NLIis likely to require combining disparate reasoners,and a facility for natural logic inference is a goodcandidate to be a component of such a solution.Acknowledgements The authors wish to thankthe anonymous reviewers for their helpful com-ments.
This work was supported in part byARDA?s Advanced Question Answering for Intel-ligence (AQUAINT) Program.ReferencesAkhmatova, Elena.
2005.
Textual entailment resolution viaatomic propositions.
In Proceedings of the PASCAL Chal-lenges Workshop on Recognising Textual Entailment.Bos, Johan and Katja Markert.
2006.
When logical inferencehelps determining textual entailment (and when it doesn?t).In Proceedings of the Second PASCAL Challenges Work-shop on Recognizing Textual Entailment.B?ottner, Michael.
1988.
A note on existential import.
StudiaLogica, 47(1):35?40.Dagan, Ido, Oren Glickman, and Bernardo Magnini.
2005.The PASCAL Recognising Textual Entailment Challenge.In Proceedings of the PASCAL Challenges Workshop onRecognising Textual Entailment.de Marneffe, Marie-Catherine, Bill MacCartney, TrondGrenager, Daniel Cer, Anna Rafferty, and Christopher D.Manning.
2006.
Learning to distinguish valid textual en-tailments.
In Proceedings of the Second PASCAL Chal-lenges Workshop on Recognizing Textual Entailment.Fowler, Abraham, Bob Hauser, Daniel Hodges, Ian Niles,Adrian Novischi, and Jens Stephan.
2005.
Applying CO-GEX to recognize textual entailment.
In Proceedings ofthe PASCAL Challenges Workshop on Recognising TextualEntailment.Harabagiu, Sanda and Andrew Hickl.
2006.
Using scenarioknowledge in automatic question answering.
In Proceed-ings of the Workshop on Task-Focused Summarization andQuestion Answering, pages 32?39, Sydney.Harmeling, Stefan.
2007.
An extensible probabilistictransformation-based approach to the Third RecognizingTextual Entailment Challenge.
In ACL-07 Workshop onTextual Entailment and Paraphrasing, Prague.Hickl, Andrew, John Williams, Jeremy Bensley, Kirk Roberts,Bryan Rink, and Ying Shi.
2006.
Recognizing textualentailment with LCC?s GROUNDHOG system.
In Pro-ceedings of the Second PASCAL Challenges Workshop onRecognizing Textual Entailment.Jiang, Jay J. and David W. Conrath.
1997.
Semantic simi-larity based on corpus statistics and lexical taxonomy.
InProceedings of the International Conference on Researchin Computational Linguistics.Jijkoun, Valentin and Maarten de Rijke.
2005.
Recognizingtextual entailment using lexical similarity.
In Proceedingsof the PASCAL Challenges Workshop on Recognizing Tex-tual Entailment, pages 73?76.Klein, Dan and Christopher D. Manning.
2003.
Accurateunlexicalized parsing.
In Proceedings of ACL-03, Sapporo.Lakoff, George.
1970.
Linguistics and natural logic.
Synthese,22:151?271.Levy, Roger and Galen Andrew.
2006.
Tregex and Tsurgeon:tools for querying and manipulating tree data structures.
InProceedings of LREC-06, Genoa.MacCartney, Bill and Christopher D. Manning.
2007.
Naturallogic for textual inference.
In ACL-07 Workshop on TextualEntailment and Paraphrasing, Prague.MacCartney, Bill, Trond Grenager, Marie-Catherine de Marn-effe, Daniel Cer, and Christopher D. Manning.
2006.Learning to recognize features of valid textual entailments.In Proceedings of NAACL-06, New York.Marsi, Erwin and Emiel Krahmer.
2005.
Classification ofsemantic relations by humans and machines.
In ACL-05 Workshop on Empirical Modeling of Semantic Equiv-alence and Entailment, Ann Arbor.Nairn, Rowan, Cleo Condoravdi, and Lauri Karttunen.
2006.Computing relative polarity for textual inference.
In Pro-ceedings of ICoS-5 (Inference in Computational Seman-tics), Buxton, UK.Romano, Lorenza, Milen Kouylekov, Idan Szpektor, Ido Da-gan, and Alberto Lavelli.
2006.
Investigating a genericparaphrase-based approach for relation extraction.
In Pro-ceedings of EACL 2006.S?anchez Valencia, Victor.
1991.
Studies on Natural Logic andCategorial Grammar.
Ph.D. thesis, University of Amster-dam.van Benthem, Johan.
1986.
Essays in logical semantics.
Rei-del, Dordrecht.van der Sandt, Rob A.
1992.
Presupposition projection asanaphora resolution.
Journal of Semantics, 9(4):333?377.528
