A SYNTAX PARSER BASED ON THE CASE DEPENDENCYGRAMMAR AND ITS EFFICIENCYToru Hitaka and Sho YoshidaDepartment of Electronics, Kyushu University, Fukuoka, JapanS UMMARYAugumented transit ion networkgrammars (ATNGs) or augumented context-free grammars are generally used innatural language processing systems.The advantages of ATNGs may be summa-rized as i) eff iciency of representa-tion, 2) perspicuity, 3) generativepower, and the disadvantage of ATNGs isthat it is diff icult to get an effi-cient parsing algorithm becuase of theflexibil ity of their complicatedadditional functions.In this paper, the syntax ofJapanese sentences , based on casedependency relations are stated first,and then we give an bottom-up andbreadth-f irst parsing algoritbxnwhichparses input sentence using time O(n 3)and memory space O(n2), where n is thelength of input sentence.
Moreover,it is shown that this parser requirestime O(n2), whenever each B-phrase ininput sentence is unambiguous in itsgrammatical structure.
Therefore, theeff iciency of this parser is nearlyequal to the Earley's parser which isthe most eff icient parsing method forgeneral context-free grammars.1.
FUNDAMENTALS OF JAPANESE SENTENCEThe Japanese sentence is ordinari lywritten in kana (phonetic) letters andkanji (ideographic) characters withoutleaving a space between words.
Fromthe viewpoint of machine processing,however, it is necessary to expressclearly the units composing thesentence in such a way as to leave aspace between every word as in English.We have no standard way of spacing theunits though the need for this hasbeen demanded for a long time.We give some examples in Figure i.The first sentence in the figure isof ordinary written form.The second indicates a way ofspacing (i.e.
putting a space betweenevery word).The third indicates another way ofspacing (i.e.
putting a space betweenevery B-phrase).Nowadays, many other spacing methodshave been tried in several institutesin Japan.In this paper, input sentences aregiven in colloquial style in which aspacing symbol is placed between twosuccessive B-phrases.In Japanese sentences, BUNSETSUs(B-phrase) are the minimal morphologicalunits of case dependency, and the syntaxof Japanese sentences consists of (i)the syntax of B-phrase as a string ofwords, and (2) the syntax of a sentenceas a string of B-phrases.A B-phrase usually pronouncedwithout pausing consists of two parts- -ma in  part \[or equally an independentpart in the conventional school gramma-tical term\] and an annex part which ispost positioned.
We denote the connec-tion of two parts in a B-phrase by adot if necessary.
A main part, which isa conceptual word \[or equally an inde-pendent word\] (e.g.
noun, verb,adjective or adverb) provides mainly theinformation of the concept.
On theother hand, an annex part, a possiblynull string of suffix words (e.g.
auxi-liary verbs or particles) provides theinformation concerning the kakariukerelation and/or the supplementaryinformation (e.g.
the speaker's attitudetowards the contents of the sentence,tense, etc.
)A word w has it's spell ing W, partof speech H and inflexion K. We call(W,H,K) the word structure of w.Suppose that a string b of length nbe a B-phrase.
Then, there exist anindependent word w 0 and suffix wordsWl, w z, ... , w~, andb=w0w I .
?
?
w~Cont(Hk,Kk,Hk+1) (0=k<i) ...(i)Termi (H?,K Z) ?
?
?
(2)where (Wi,Hi,Ki) is the word structureof w i (0~i~?
), Cont(Hk,Kk,Hk+1) meansa word whose part of speech and inflexionare Hk, K k respectively can be followedby a word whose part of speech is Hk+lin-15--B-phrases and Termi(HQ,Kz) means a wordwhose part of speech ~nd inflexion areH?, KZ respectively can be a right-mostsubword of B-phrases.
(i), (2) are called the rules of B-phrase structure, and(W0,H0,K 0) (Wi,HI,K ~) "''(Wz,H~,K ~)?
.
.
(3 )is called B-phrase structure of b.
If(3) satisfies the condition (i), w0wlw?
.
.w  Z is called to be a left partial 2B-phrase.The kakariuke relation is the depen-dency relation between two B-phrases ina sentence.
A B-phrase has the syn-tactic functions of governor anddependent.
The function of governor ismainly represented by the independentword of B-phrase.
The function ofdependent is mainly represented by thestring of particles which is the right-most substring of B-phrase and by theword in front of it (right-most non-particle word).Every particle has the syntactic andpartial ly semantic dependent functionwith its own degree of power.
Theparticle whose power of dependentfunction is strongest of all particlesappearing in the string of particles iscalled the representative particle.Therefore, the syntactic function ofdependent of a B-phrase is mainlyrepresented by the representativeparticle and by the right-most non-particle word.Let (W0,H0,K0) , (Wi,Hi,Ki) , (W~,H~,K~)be the word structures of independent Jword, right-most non-particle word andrepresentative particle of a B-phrase,respectively.
Then, <W^,H^>_, <W..,Hi, u u ~ &Hj> d are called the inrormatlon orgovernor and the information of depen-dent of the B-phrase respectively, andthe pair (<W0,H0>~,<Wi,Hi,Hj>d) iscalled dependency~informati6n of theB-phrase.There are many types of dependencyrelation such as agent, patient,instrument, location, time, etc.
LetC be the set of all types of dependencyrelation.
The set of all possibledependency relations from a B-phrase b lto a B-phrase b 2 is founded on theinformation of dependent of b I and theinformation of governor of b 2.
There-fore, there is a function 6 which com-putes the set of all possible dependen-cy relations ~(a,8) between a B-phraseof dependency information ~ and anotherB-phrase of dependency information 8.The function ~ is realized by thedependency dictionary retrieved withthe key of two dependency informations.The order of B-phrase is relativelyfree in a simple sentence, except forone constraint that the predicativeB-phrase governing the whole sentencemust be in the sentence's final posi-tion.
Japanese is a post positionalin this sense.The pattern of the dependencyrelations in a sentence has somestructural property which is called therules of dependency structure, and thedependency relations in a sentence arecalled the dependency structure of asentence.
The dependency structureof a sentence is shown in figure 2,where arrows indicate dependency rela-tions of various types.
The rules ofdependency structure consist of follow-ing three conditions.i Each B-phrase except one at thesentence final is a dependent ofexactly one B-phrase appearingafter it.ii A dependency relation between anytwo B-phrases does not cross withanother dependency relations in asentence.iii No two dependency relationsdepending on the same governorare the same.Let N be the number of B-phrases ina input sentence, and all B-phrases arenumbered descendingly from right toleft (see figure 2).
We shall fix aninput sentence, throughout this chapter.Let DI(i) be the set of all dependencyinformations of i-th B-phrase.Definition: A dependency file DF ofa sentence is a finite set of 5-tuples.
(i,j,ai,ej,c) 6 DF.... _~ { N=i>j=l, a i E DI (i),cde .
~j 6 DI(j) and c E~(ai,aj).Definition: If a subset of DFsatisfies following conditions i) to5), it is called a dependency structurefrom the Z-th B-phrase to the m-th B-phrase (N~Z>m~i) and denoted by DS(?,m)or DS' (i,m).i) If (i,J,ei,~j,c) 6 DS(?,m), then?~i>jAm.2) For arbitrary i(ZAi>m), thereexists unique j,ai,ej,c such that(i,j,ai,ej,c) ~ DS(Z,m).
(Uniqueness of Dependent)3) If (i,j,a~,a~,c) 6 DS(?,m) and, , ~ o (j,k,~j,~k,C) % DS(Z,m), then ~ = ~~,  O J "  (Uniqueness of B-phrase structure), 4)  If (i,J,~i,~j,c) ~ DS(?,m),(i ,j,~f ,~j, ,c ) E DS(?,m) and i>i'>j,then j,hj.
(Nest Structure of Dependency)16 ?5) If ( i , j ,@i,~,c)  e DS(?,m)(i',j,a i, ,~j,c') ~ D~(?,m) and ~ i ' ,then c ~ c'.
(Inhibition of Duplication of a Case)The set of all dependency st ructur~from i-th B-phrase to m-th B-phrase isdenoted by ~(~,m).
Any DS(N,i)~ ~(N,i)is called a dependency structure of theinput sentence.
The dependency infor-mation of j-th B-phrase is unique inDS(i,m), since 2) and 3) hold.
LetJDiDS(Z,m) and jGDS(Z,m) be the depen-dency information of the j-th B-phraseinD~?,m)  and~set  of all the depen-dency relations that the j-th B-phrasegoverns in DS(?,m), respectively.def ~ i ,~ ,C)  JGDS(i,m) u__.
{c I ( i , J~Ds(~m) }Definition: If the k-th B-phrase(i~k~_m) in DS(?,m) has the followingproperty, k(the k-th B-phrase) iscalled a joint of DS(?,m):For any ( i , j ,ai ,~j,c)~ DS(~,m) ,k~i or J~k.Let j~(=?)
> j, > Jl > "'" > j (=m) beu ,the descendlng sequence of ale thejoints of DS(i,m) (see figure &).Then, the Jk-th B-phrase is called thek-th joint of DS(?,m).
There is adependency relation from k-th joint(dependent) to k+i-th joint(governor)in DS(?,m).
Let J.DS(?,m) be a set ofall the joints of DS(?,m).
DS(?,m/i,j)a subset of DS(Z,m), is defined asfollows:DS(?,m/i,j)-~{ (p,q,av,~o,c) I(p,q,ap,aq,C) ~ DS(~,my, i~p>q~j}.Lemma i.
For any positive integer?, i, j, m (N~?~i>j~m), the followingpropositions hold.
(i) DS(i,m/i, j)6 ~(i, j), if j is ajoint of DS(i,m).
(ii) DS(I,j) U DS(j,m)~ ~(?,m), if andonly if JDiDS(Z,j) = JDiDS(j,m) .
(iii) { (Z+i,j ,~, ~,c) }uDS (~,~) 6 ~(Z+i,m) if and only if (i+l,j,e,8,c)E DF,8=JDiDS(Z,m), j E J.DS(?,m)and c~ jGDS(Z,m).
(iv) If (jk,Jk+1,ak,ek+1,c) ~ DS(j ,m)(k=0,1,2,-..), then Jk is the k-th joint of DS(J0,m).Syntax analysis of a Japanesesentence is defined as giving B-phrasestructures and dependency structure ofthe sentence.2.
THE PARSING ALGORITHMAND ITS EFFICIENCYIn this chapter, we shall give aparsing method which will parse aninput sentence using time O(n ~) andspace O(n~), where n is the length ofinput sentence.
Moreover, if thedependency information of each B-phraseis unambiguous, the time variation isquadratic.The essence of the parsing algorithmis theconst ruct ion  of B-phrase parselist BL and dependency parse list DLwhich are constructed essential ly by a"dynamic programming" method.
Theparsing algorithm consists of fourminor algorithms that are the construc-tion of BL, the obtaining of B-phrasestructure, the construction of DL andthe obtaining of dependency structure.13-PHRASE PARSE LISTLet b be a string of n length andb(i) denote the i-th character fromthe left end of it.b=b(1)  (2) ... b(n).The B-phrase parse list of bconsists of n minor lists BL(1), BL(2),?
.. , BL(n).\ [ \ ]Form of items in BL(j)(i, WS, DI)where, IL_i < j~n,  WS is a wordstructure and DI is a dependencyinformation.\ [ \ ]  Semantics (i, WS, DI)EBL(j) of(i, WS, DI)E BL(j), if andonly if there exists a sequence ofwords w o, w l, ... , w?
satisfyingfollowing two conditions:i) b(1)b(2) ... b(i)=w0w I .. ?
w~_ I,b(i+l)b(i+2) ...
b(j)=w?, andWS is the word structure of w?.2) The string of word w_w I ... w Z is?
D a left parclal B-phrase of depen-dency information DI.ALGORITHM FOR THE CONSTRUCTION OF BLInput.
An input string b=b(1)(2)?
?
.b (n )  .Output.
The B-phrase parse listBL(1), BL(2), ... , BL(n).Method.
Step i: Find all theindependent word which are the left-most subwords of b, using independentword dictionary and for each indepen-dent word w=b(1)b(2) ''.
b(j), add(0, (W,H,K),a) to BL(j) where, (W,H,K)is the word structure of w and ~=(<W,H>K, <W,H,-> d) .
Then, set thecontroI word i to 1 and repeat Step 2until ~ = n ?Step 2: Obtain all the suffixwords which are the left-most subwordsof B(i+l)B(i+2) ... b(n) and for eachsuffix word w=b( i+l )b( i+2)  ... b(k)of word structure (W' ,H' ,K') , and foreach item (j, <W,H,K>,a) # BL(i), add(i,(W',H',K'), (W',H')oe) to BL(k) if--17C(H,K,K').
(W',H')0a is a dependencyinformation defined as follows.i If H' is a auxil iary verb?
then(W',H')o~ def (<~>g,<W,,H,,_>d)where?
<a>g is the information ofgovernor or a.ii Let <W",H",H"' > be the informa-tion of dependent of ~.
When H'is a particle,(W,,H,)o a def.
.
.
.
(<a>g,<W",H",H'>d)if the power of dependencyfunction of H' is stronger thanthat of H"' , and else(W,,H,)o ~ def ~.There exists upper limit in thelength of words and there exists upperlimit in the number of dependencyinformations of all left partial B-phrase of a(1)a(2) ... a(i).
Therefore,there exists upper limit for thenecessary size of memory space of BL(i)and the theorem 1 follows.Theorem i.Algorithm for the construction ofBL requires O(n) memory space andO(n) elementary operations.We shall now describe how to find aB-phrase structure of specif ied depen-dency information from BL.
The methodis given as follows.ALGORITHM FOR OBTAINING A B-PHRASESTRUCTURE OF AN INPUT STR INGInput.
The specified dependencyinformation ~ and BL.Output.
A B-phrase structure ofdependency information a or the errorsignal "error".Method.
STEP i: Search any item(i,(W,H,K),a) in BL(n) such as Termi(H,H).
If there is no such item, thenemit "error" and halt.
Otherwise,output the word structure (W,H,K), setthe register R to (i,(W,H,K),a) andrepeat the step 2 until i = 0.STEp 2: Let R be (i,(W,H,K),e).Search any item (i',(W',H',K'),a') inBL(i) such as C(H',K',H) and (W,H) o~=a.There exist at least one element whichsatisfies above conditions.
"Outputthe word structure (W',H',K') andR?
(i',(W',H',K'),a').It is easy to know theorem 2 holds.Theorem 2.A B-phrase structure of specif ieddependency information is output bythe above algorithm, if and only if theinput string has at least one B-phrasestructure of specified dependencyinformation and it takes constantmemory space and O(n) elementaryoperations to operate the abovealgorithm.The set of all the dependencyinformations DI of input string b isobtained from BL(n), sinceDI={a I (i, (W,H,K) ,a)?SL(n) , C(H,K) }.DEPENDENCY PARSE LIST DLLet s be a input sentence of N B-phrases.
The set of all the depen-dency informations DI(i) of the i-thB-phrase is obtained by operating thealgorithm of construction of BL onthe string of the i-th B-phrase.The dependency parse list DL of sconsists of N-i minor lists DL(2),DL(3) , ''- ,DL(N) .\ [ \ ]  of items in Form DL(i).
(ai,J,aj,~,P) I(ai?J,aj, ,P)where, N~i  > j~ l ,  aie DI(i), ajE DI(j),ce ~, P~ and $ is a specially intro-duced symbol.I~  Semant ics  of (ai,J,aj,c,P)6DL(i).
(ai,J,aj,c,P) ~ DL\]i) ?
if andonly if there is a dependency struc-ture DS(i,i) of s, where(i,J,ai,a~,c) ~ DS(i,i),jGDS (i,l) < P.~ Semantics of (ai ?
j ?~,S,P)6DL(i).
(ai?J,?j ,$,P) e Dn(1), if andonly if there is a dependency structureDS(i,i) of s, whereai=iDiDS(i i) a. :JDiDS(i,i), ?
r Jj is a joint of DS(i,i) exceptO-th or 1st joint,jGDS(i,i) =P.ALGORITHM FOR THE CONSTRUCTION OF DLInput.
The sequence of the sets ofall dependency informations DI(1) ,DI(2) , ''" ?DI(N) .Output.
Dependency list DL(2),DL(3) , ''" ,DL(N).Method.
STEP 1 (Construction ofDL(2))~ For each a e DI(2)?
a16 DI(1)and cE ~ such that ~ e6(c~2,c~i) , add(a2,l,al,c,{c}) to DL(2)?
set i to 2and repeat the STEP 2 and the STEP 3until i = N.STEP 2 (Registration of items ofthe form (ai+l,j,aA,c,P)) : For any(ai,J,aj?c,P) ~ DL(i) and ~i+16 DI(i+l) ,compute 6 (ai+ I,~i) and add every(ai+l,i,ai,c',{c'}) to DL(i+i) suchthat c'6 6(ei+1,~i).
And, for any(c~i,J,aj,A,P) 6 DL(i) where A~ ~ ~'{$}and ai+1?
DI(i+l), compute ~(c~i+1,aA)and add every (ai+l,j,c~j,c',PU {c'}~to DL(i+i) such that c'6 ~(ai+1,a j)and c'} P. Go to Step 3.18STEP 3 (Registration of items ofthe form (ai+1,j,ej,$,P)): For any(ai+1,j,al,c,P) ~ DL(i+i) and (al,k,ek,A,P') # DL~j), add (ei+1,k,ak,$,~') toDL(i+i).
Then, set i to i+; and goto STEP 2.Theorem 3.If there exist no ambiguity in thedependency information of B-phrases ofinput sentence, then the step 3 inthe above algorithm can be replaced tothe following step 3'.STEP 3': For each (~Ki+!,j,~A,A,P)6 DL(Ki+~), add (~i+~,j,aj,~,P) ?oDL(i+i), wherede----~ max{k I (ai+l k ~k,C,P) Ki+l , ,DL ( i+l )}.Then, set i to i+l and go to STEP 2.The efficiency of each step ofabove algorithm is as follows.The memory size of DL(i) is O(N).The step i, the step 2 and the step3 take constant, O(N) and O(N ~)elementary operations, respectively.The step 3' takes O(N) elementaryoperations since it takes O(N)elementary operations to compute Ki+ ~ .Therefore, the theorem 4 holds.Theorem 4.The algorithm for the constructionof DL requires O(N ~) memory space andO(N ~) elementary operations.
Moreover,if there exist no ambiguity in thedependency information of each B-phrases, the algorithm requires O(N ~)elementary operations by replacing thestep 3 with the step 3'We shall now describe how to find adependency structure of input sentencefrom DL.
To begin with, we shallexplain items of partial dependencystructure list PDSL.Form of items in PDSL(i,j,a~,a~,P#)where, Nh i  ~j ~ i  a# ~ DI(i) ~ {#},~ % DI(j) U {~,  P~ i~ a subset of C or#Oand# is specially introduced symbol.~ Semantics of (i,j,~#,e#.p#) .~  i j-The item (i,j,a~,e~,P#) % PDSLmeans to be a dependenceS- structureDS(i, j)~ ~(i,j) such that followingconditions i),2) and 3) hold.i) If a~=~i(%#), then iDiDS (i,j) =e i ?2) If e#=aj(~#!,~ then JDiDS(i,j)=aj.3) If P~=P(~#).
then JGDS(i,j)=P.Therefore, (N,i,#,#,#) means to be adependency structure of the inputsentence.ALGORITHM FOR OBTAINING A DEPENDENCYSTRUCTURE FROM DLInput.
DL.Output.
A dependency structure ofinput sentence or the signal "error".Method.
STEP i: If DL(N) is empty,emit the message "error", else,initialize PDSL to {(N,i,#,#,#)} andrepeat step 2 until PDSL becomes empty.STEP 2: Take an item freely out ofPDSL and delete it from PDSL.
Accord-ing to the form of the item, executei) or 2) or 3).i) If the item is (N,i,#,#,#) ofthe form and (aN,J,ej,c,P) ~ DL(N) ,then output (N,J,eN,ej,c), add (N-i,j,#,aj,P/{c}) to PDSL i~ N-i ~ j and add(j,l,aj,#,#) to PDSL if j ~ i.2) If the item is (i,l,ei,#,#) ofthe form and (j,~i,ej,c,P)E DL(i),then output (i,J,ei,e~,c), add (i-l,j,#,aj,P/{c}) to PDSL i~ i-i @ j and add(j,l,a~,#,#) to PDSL if j @ 13) aIf the item is ( i , j ,~,e~,P) ofthe form, where ~#=~= or #, anda(ai,j,~ ,c ,P )  E DL(i), then?output (i,J,~i,e~,c) and add (i-l,j,#,~j,P/{c}) toPDSL if i-i % j.
When there is notsuch item in DL(i), searcha pair ofitems (ei,k,ak,C,P') E DL(i) and (ak,J,ej,A,P) ~ DL(k), then output (i,k,ei,ak,cy , add (i-l,k,#,~k,P'/{c}) to PDSLif i-i @k and add (k,j,~k,ej,P) to PDSL.PDSL needs O(N) memory space andSTEP i, STEP 2 take constant, O(N)elementary operations, respectively.Theorem 5.A-igorithm for obtaining a dependencystructure from DL requires O(N) memoryspace and O(N 2) elementary operations.PARSING ALGORITHMInput.
A Japanese sentence in collo-quial style.Output.
A dependency structure DS(N,i) of the input sentence and a B-phrasestructure of the j-th B-phrase, whosedependency information is JDiDS(N,i),for every j(j=l,2, "'" ,N).Method.
STEP i: Construct N B-phraseparse lists of all B-phrases of theinput sentence and get the sets ofdependency informations DI(1), DI(2),?
."
, D I (N) .STEP 2: Construct dependency parselist DPL from DI(1), DI(2), ... ,DI(N).STEP 3: Obtain a dependencystructure DS(N,i) of the input sentencefrom DL.STEP 4: Obtain a B-phrase structureof the j-th B-phrase, whose dependencyinformation is JDiDS(N,i), for everyj (j=l,2, ... ,N) and stop.-19--Let n~ be the length of j-th B-phrase (~=i,2, ?-- ,N), and N,n denotethe number of B-phrases and the lengthof input sentence, respectively.
Then,n1+n2+ ... +n N =nN LnBy theorem i, theorem 2, theorem 4and theorem 5, next theorem holds.Theorem 6.The parsing algorithm requiresO(n 2) memory space and O(n 3) elementaryoperations.
Moreover, if the dependen-cy information of each B-phrase isunambiguous, it requires O(n 2) elemen-tary operations.3.
CONCLUSIONSyntax of Japanese sentences isstated and a efficient parsingalgorithm is given.
A Japanese sen-tence in colloquial style is parsed b Ythe parsing algorithm, using time O(n ~)and memory space O(n2), where n is thelength of input sentence.
Moreover,it is parsed using time O(n 2) wheneverdependency information of every B-phrase is unambiguous.REFERENCESi.
Aho, Ullman : "The Theory ofParsing, Translation, and Compil-ing", Prentice Hall vol.
1 (1975).2.
Woods : "Transition NetworkGrammars for Natural LanguageAnalysis", Communication of theACM, 13 (1970).3.
Pratt : "LINGOL -- A ProgressReport", Proc.
IJCAI 4 (1975).
(~) (~s) (s) (2) 0-)J0 =5) Jl (=4) J2 (=3) J3 (=i): main part a: agent- - :  annex part p: patientJ0,Jl,J~,J3 : the sequence of jointFigure 2.
Dependency StructureExample: Taro read the compositionwritten by Hanako.Figure i.
Ways of Spacing20
