Proceedings of the ACL 2010 Student Research Workshop, pages 85?90,Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational LinguisticsAutomatic Sanskrit Segmentizer Using Finite State TransducersVipul MittalLanguage Technologies Research Center, IIIT-H,Gachibowli, Hyderabad, India.vipulmittal@research.iiit.ac.inAbstractIn this paper, we propose a novel methodfor automatic segmentation of a Sanskritstring into different words.
The input forour segmentizer is a Sanskrit string eitherencoded as a Unicode string or as a Ro-man transliterated string and the output isa set of possible splits with weights associ-ated with each of them.
We followed twodifferent approaches to segment a Sanskrittext using sandhi1 rules extracted from aparallel corpus of manually sandhi splittext.
While the first approach augmentsthe finite state transducer used to analyzeSanskrit morphology and traverse it to seg-ment a word, the second approach gener-ates all possible segmentations and vali-dates each constituent using a morph an-alyzer.1 IntroductionSanskrit has a rich tradition of oral transmissionof texts and this process causes the text to un-dergo euphonic changes at the word boundaries.In oral transmission, the text is predominantly spo-ken as a continuous speech.
However, continuousspeech makes the text ambiguous.
To overcomethis problem, there is also a tradition of recitingthe pada-pa?t.ha (recitation of words) in addition tothe recitation of a sam.hita?
(a continuous sandhiedtext).
In the written form, because of the domi-nance of oral transmission, the text is written as acontinuous string of letters rather than a sequenceof words.
Thus, the Sanskrit texts consist of a very1Sandhi means euphony transformation of words whenthey are consecutively pronounced.
Typically when a wordw1is followed by a word w2, some terminal segment of w1merges with some initial segment of w2to be replaced bya ?smoothed?
phonetic interpolation, corresponding to mini-mizing the energy necessary to reconfigurate the vocal organsat the juncture between the words.long sequence of phonemes, with the word bound-aries having undergone euphonic changes.
Thismakes it difficult to split a continuous string intowords and process the text automatically.Sanskrit words are mostly analyzed by build-ing a finite state transducer (Beesley, 1998).
Inthe first approach, this transducer was modifiedby linking the final states to appropriate interme-diate states incorporating the sandhi rules.
Thisapproach then allows one to traverse the stringfrom left to right and generate all and only possiblesplits that are morphologically valid.
The secondapproach is very closely based on the OptimalityTheory (Prince and Smolensky, 1993) where wegenerate all the possible splits for a word and vali-date each using a morphological analyzer.
We useone of the fastest morphological analyzers avail-able viz.
the one developed by Apertium group2.The splits that are not validated are pruned out.Based on the number of times the first answer iscorrect, we achieved an accuracy of around 92%using the second approach while the first approachperformed with around 71% accuracy.2 Issues involved in Sanskrit ProcessingThe segmentizer is an important component ofan NLP system.
Especially, languages suchas Chinese (Badino, 2004), Japanese, Thai(Haruechaiyasak, 2008) or Vietnamese (Thang etal.
, 2008) which do not mark word bound-aries explicitly or highly agglutinative languageslike Turkish need segmentizers.
In all these lan-guages, there are no explicit delimiters to spec-ify the word boundaries.
In Thai, each syllableis transcribed using several characters and thereis no space in the text between syllables.
So theproblem of segmentation is basically twofold: (1)syllable segmentation followed by (2) word seg-mentation itself.
A sentence in these languages2http://wiki.apertium.org/wiki/lttoolbox; It processesaround 50,000 words per sec.85is segmented by predicting the word boundaries,where euphonic changes do not occur across theword boundaries and it is more like mere concate-nation of words.
So the task here is just to choosebetween various combinations of the words in asentence.However, in Sanskrit, euphonic changes occuracross word boundaries leading to addition anddeletion of some original part of the combiningwords.
These euphonic changes in Sanskrit intro-duce non-determinism in the segmentation.
Thismakes the segmentation process in Sanskrit morecomplex than in Chinese or Japanese.
In case ofhighly agglutinative languages like Turkish, thecomponents are related to each other semanticallyinvolving dependency analysis.
Whereas inSanskrit, only the compounds involve a certainlevel of dependency analysis, while sandhi is justgluing of words together, without the need forwords to be related semantically.
For example,consider the following part of a verse,San: na?radam paripapracchava?lm?
?kirmunipun?gavamgloss: to the Narada asked Valmiki-to the wisest among sagesEng: Valmiki asked the Narada, the wisest amongthe sages.In the above verse, the words va?lm?
?kih.and mu-nipun?gavam (wisest among the sages - an adjec-tive of Narada) are not related semantically, butstill undergo euphonic change and are glued to-gether as va?lm?
?kirmunipun?gavam.Further, the split need not be unique.
Here isan example, where a string ma?tura?jn?a?mparipa?layamay be decomposed in two different ways afterundergoing euphonic changes across word bound-aries.?
ma?tuh a?jn?a?m paripa?laya (obey the order ofmother) and,?
ma?
a?tura?jn?a?m paripa?laya (do not obey theorder of the diseased).There are special cases where the sandhiedforms are not necessarily written together.
Insuch cases, the white space that physically marksthe boundary of the words, logically refers toa single sandhied form.
Thus, the white spaceis deceptive, and if treated as a word boundary,the morphological analyzer fails to recognize theword.
For example, considers?rutva?
ca na?rado vacah..In this example, the space between s?rutva?
andca represent a proper word boundary and theword s?rutva?
is recognized by the morphologicalanalyzer whereas the space between na?rado andvacah.does not mark the word boundary makingit deceptive.
Because of the word vacah., na?radah.has undergone a phonetic change and is renderedas na?rado.
In unsandhied form, it would bewritten as,San: s?rutva?
ca na?radah.vacah..gloss: after listening and Narada?s speechEng: And after listening to Narada?s speechThe third factor aggravating Sanskrit segmen-tation is productive compound formation.
UnlikeEnglish, where either the components of a com-pound are written as distinct words or are sepa-rated by a hyphen, the components of compoundsin Sanskrit are always written together.
Moreover,before these components are joined, they undergothe euphonic changes.
The components of a com-pound typically do not carry inflection or in otherwords they are the bound morphemes used only incompounds.
This forces a need of a special mod-ule to recognize compounds.Assuming that a sandhi handler to handle thesandhi involving spaces is available and a boundmorpheme recognizer is available, we discuss thedevelopment of sandhi splitter or a segmentizerthat splits a continuous string of letters intomeaningful words.
To illustrate this point, wegive an example.Consider the text,s?rutva?
caitattrilokajn?o va?lm?
?kerna?rado vacah..We assume that the sandhi handler handling thesandhi involving spaces is available and it splitsthe above string as,s?rutva?
caitattrilokajn?ah.va?lm?
?kerna?radah.vacah..The sandhi splitter or segmentizer is supposedto split this into86s?rutva?
ca etat triloka-jn?ah.va?lm?
?keh.na?radah.vacah..This presupposes the availability of rules corre-sponding to euphonic changes and a good cover-age morphological analyzer that can also analyzethe bound morphemes in compounds.A segmentizer for Sanskrit developed by Huet(Huet, 2009), decorates the final states of its fi-nite state transducer handling Sanskrit morphol-ogy with the possible sandhi rules.
However, itis still not clear how one can prioritize varioussplits with this approach.
Further, this system incurrent state demands some more work before thesandhi splitter of this system can be used as a stan-dalone system allowing plugging in of differentmorphological analyzers.
With a variety of mor-phological analyzers being developed by variousresearchers3, at times with complementary abili-ties, it would be worth to experiment with vari-ous morphological analyzers for splitting a sand-hied text.
Hence, we thought of exploring otheralternatives and present two approaches, both ofwhich assume the existence of a good coveragemorphological analyzer.
Before we describe ourapproaches, we first define the scoring matrix usedto prioritize various analyses followed by the base-line system.3 Scoring MatrixJust as in the case of any NLP systems, with thesandhi splitter being no exception, it is always de-sirable to produce the most likely output when amachine produces multiple outputs.
To ensure thatthe correct output is not deeply buried down thepile of incorrect answers, it is natural to prioritizesolutions based on some frequencies.
A Parallelcorpus of Sanskrit text in sandhied and sandhi splitform is being developed as a part of the Consor-tium project in India.
The corpus contains textsfrom various fields ranging from children stories,dramas to Ayurveda texts.
Around 100K wordsof such a parallel corpus is available from whicharound 25,000 parallel strings of unsandhied andcorresponding sandhied texts were extracted.
Thesame corpus was also used to extract a total of2650 sandhi rules including the cases of mere con-catenation, and the frequency distribution of thesesandhi rules.
Each sandhi rule is a triple (x, y, z)3http://sanskrit.uohyd.ernet.in,http://www.sanskritlibrary.org, http://sanskrit.jnu.ernet.inwhere y is the last letter of the first primitive, z isthe first letter of the second primitive, and x is theletter sequence created by euphonic combination.We define the estimated probability of the occur-rence of a sandhi rule as follows:Let Ridenote the ith rule with fRias the fre-quency of occurrence in the manually split paralleltext.
The probability of rule Riis:PRi=fRi?ni=1fRiwhere n denotes the total number of sandhi rulesfound in the corpus.Let a word be split into a candidate Sjwith kconstituents as < c1, c2, ..ck> by applying k ?
1sandhi rules < R1, R2, ..Rk?1> in between theconstituents.
It should be noted here that the rulesR1, ..Rk?1and the constituents c1, ..ckare inter-dependent since a different rule sequence will re-sult in a different constituents sequence.
Also, ex-cept c1and ck, all intermediate constituents takepart in two segmentations, one as the right wordand one as the left.The weight of the split Sjis defined as:WSj=?k?1x=1(Pcx+ Pcx+1) ?
PRxkwhere Pcxis the probability of occurrence of theword cxin the corpus.
The factor of k was intro-duced to give more preference to the split with lessnumber of segments than the one with more seg-ments.4 Baseline SystemWe define our own baseline system which assumesthat each Sanskrit word can be segmented only intwo constituents.
A word is traversed from left toright and is segmented by applying the first appli-cable rule provided both the constituents are validmorphs.
Using the 2,650 rules, on a test data of2,510 words parallel corpus, the baseline perfor-mance of the system was around 52.7% where thefirst answer was correct.5 Two ApproachesWe now present the two approaches we exploredfor sandhi splitting.5.1 Augmenting FST with Sandhi rulesIn this approach, we build an FST, using Open-Fst (Allauzen et al, 2007) toolkit, incorporating87sandhi rules in the FST itself and traverse it to findthe sandhi splittings.We illustrate the augmentation of a sandhi rulewith an example.
Let the two strings be xaXi(dadhi)4 and awra (atra).
The initial FST withoutconsidering any sandhi rules is shown in Figure 1.Figure 1: Initial FST accepting only two wordsxaXi and awra.As the figure depicts, 0 is the start state and 4 isthe final state.
Each transition is a 4-tuple <c, n,i, o> where c is current state, n is the next state,i is the input symbol and o is the output.
TheFST marks word boundaries by flushing out cer-tain features about the words whenever it encoun-ters a valid word.
Multiple features are separatedby a ?|?.
E.g., the output for xaXi is lc,s|vc,s andfor awra it is vc,s where lc,s stands for locative,singular and vc,s is vocative, singular.
The FSTin Figure 1 recognize exactly two words xaXi andawra.One of the sandhi rule states that i+a ?
yawhich will be represented as a triple (ya, i, a).
Ap-plying the sandhi rule, we get: xaXi + awra ?xaXyawra.
After adding this sandhi rule to theFST, we get the modified FST that is representedin Figure 2.Figure 2: Modified FST after inserting the rule.???
indicates the newly added transition.Here, a transition arc is added depicting the rulewhich says that on receiving an input symbol yaat state 3, go to state 5 with an output i+a ?
ya.4A Roman transliteration scheme called WX translitera-tion is used, which is one-to-one phoneme level representa-tion of Devana?gar??
script.Thus the new FST accepts xaXyawra in additionto xaXi and awra.Thus, we see that the original transducer getsmodified with all possible transitions at the endof a final phoneme, and hence, also explodes thenumber of transitions leading to a complex trans-ducer.The basic outline of the algorithm to split thegiven string into sub-strings is:Algorithm 1 To split a string into sub-strings1: Let the FST for morphology be f.2: Add sandhi rules to the final states of f1 link-ing them to the intermediary states to get f ?.3: Traverse f ?
to find all possible splits for aword.
If a sandhi rule is encountered, split theword and continue with the remaining part.4: Calculate the weights of the possible outputswith the formula discussed in section 3.The pseudo-code of the algorithm used to insertsandhi rules in the FST is illustrated here:Algorithm 2 To insert sandhi rules in the FST1: I = Input Symbol; X = last character of theresult of the rule.2: for each transition in the FST transition tabledo3: if next state is a final state then4: for all rules where I is the last characterof first word do5: S = next state from the start state onencountering X;6: Y = first character of the result of therule;7: transition T = current state, S, Y, rule;8: Add T into the FST;9: end for10: end if11: end forThe main problem with this approach is that ev-ery finite state can have as many transitions as thenumber of euphonic rules resulting in phonemechange.
This increases the size of the FST con-siderably.
It should be noted that, we have not in-cluded the cases, where there is just a concatena-tion.
In such cases, if the input string is not ex-hausted, but the current state is a final state, we goback to the start state with the remaining string asthe input.885.1.1 ResultsThe performance of this system measured in termsof the number of times the highest ranked segmen-tation is correct, with around 500 sandhi rules, andonly noun morphology tested on the same test dataused for testing baseline system gave the followingrank-wise distribution presented in Table 1.Rank % of output1 71.25092 5.645433 3.853244 3.356515 1.56123>5 14.33268Table 1: Rank-wise Distribution for Approach-1.The system was slow consuming, on an average,around 10 seconds per string of 15 letters.5.With the increase in the sandhi rules, thoughsystem?s performance was better, it slowed downthe system further.
Moreover, this was tested onlywith the inflection morphology of nouns.
The verbinflection morphology and the derivational mor-phology were not used at all.
Since, the system issupposed to be part of a real time application viz.machine translation, we decided to explore otherpossibilities.5.2 Approach based on Optimality TheoryOur second approach follows optimality the-ory(OT) which proposes that the observed formsof a language are a result of the interaction be-tween the conflicting constraints.
The three basiccomponents of the theory are:1.
GEN - generates all possible outputs, or can-didates.2.
CON - provides the criteria and the con-straints that will be used to decide betweencandidates.3.
EVAL - chooses the optimal candidate basedon the conflicts on the constraints.OT assumes that these components are univer-sal and the grammars differ in the way they rankthe universal constraint set, CON.
The grammar of5Tested on a system with 2.93GHz Core 2 Duo processorand 2GB RAMeach language ranks the constraints in some dom-inance order in such a way that every constraintmust have outperformed every lower ranked con-straint.
Thus a candidate A is optimal if it per-forms better than some other candidate B on ahigher ranking constraint even if A has more vi-olations of a lower ranked constraint than B.The GEN function produces every possible seg-mentation by applying the rules wherever appli-cable.
The rules tokenize the input surface forminto individual constituents.
This might containsome insignificant words that will be eventuallypruned out using the morphological analyser inthe EVAL function thus leaving the winning can-didate.
Therefore, the approach followed is veryclosely based on optimality theory.
The morphanalyser has no role in the generation of the can-didates but only during their validation thus com-posing the back-end of the segmentizer.
In orig-inal OT, the winning candidate need not satisfyall the constraints but it must outperform all theother candidates on some higher ranked constraint.While in our scenario, the winning candidate mustsatisfy all the constraints and therefore there couldbe more than one winning candidates.Currently we are applying only two constraints.We are planning to introduce some more con-straints.
The constraints applied are:?
C1 : All the constituents of a split must bevalid morphs.?
C2 : Select the split with maximum weight,as defined in section 3.The basic outline of the algorithm is:1: Recursively break a word at every possible po-sition applying a sandhi rule and generate allpossible candidates for the input.2: Pass the constituents of all the candidatesthrough the morph analyzer.3: Declare the candidate as a valid candidate, ifall its constituents are recognized by the mor-phological analyzer.4: Assign weights to the accepted candidates andsort them based on the weights.5: The optimal solution will be the one with thehighest salience.5.2.1 ResultsThe current morphological analyzer can recognizearound 140 million words.
Using the 2650 rules89and the same test data used for previous approach,we obtained the following results:?
Almost 93% of the times, the highest rankedsegmentation is correct.
And in almost 98%of the cases, the correct split was among thetop 3 possible splits.?
The system consumes around 0.04 secondsper string of 15 letters on an average.The complete rank wise distribution is given in Ta-ble 2.% of outputRank Approach-1 Approach-21 71.2509 92.87712 5.64543 5.446933 3.85324 1.070764 3.35651 0.418995 1.56123 0.09311>5 14.33268 0.0931Table 2: Complete rank-wise Distribution.6 ConclusionWe presented two methods to automatically seg-ment a Sanskrit word into its morphologicallyvalid constituents.
Though both the approachesoutperformed the baseline system, the approachthat is close to optimality theory gives better re-sults both in terms of time consumption and seg-mentations.
The results are encouraging.
But thereal test of this system will be when it is inte-grated with some real application such as a ma-chine translation system.
This sandhi splitter be-ing modular, wherein one can plug in differentmorphological analyzer and different set of sandhirules, the splitter can also be used for segmentiza-tion of other languages.Future Work The major task would be to ex-plore ways to shift rank 2 and rank 3 segmenta-tions more towards rank 1.
We are also explor-ing the possibility of including some semantic in-formation about the words while defining weights.The sandhi with white spaces also needs to be han-dled.AcknowledgmentsI would like to express my gratitude to AmbaKulkarni and Rajeev Sangal for their guidance andsupport.ReferencesAkshar Bharati, Amba P. Kulkarni, and V Sheeba.2006.
Building a wide coverage Sanskrit mor-phological analyzer: A practical approach.
TheFirst National Symposium on Modelling and Shal-low Parsing of Indian Languages, IIT-Bombay.Alan Prince and Paul Smolensky.
1993.
OptimalityTheory: Constraint Interaction in Generative Gram-mar.
RuCCS Technical Report 2 at Center for Cog-nitive Science, Rutgers University, Piscataway.Amba Kulkarni and Devanand Shukla.
2009.
SanskritMorphological analyzer: Some Issues.
To appear inBh.K Festschrift volume by LSI.Choochart Haruechaiyasak, Sarawoot Kongyoung, andMatthew N. Dailey.
2008.
A Comparative Study onThai Word Segmentation Approaches.
ECTI-CON,Krabi.Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wo-jciech Skut, and Mehryar Mohri.
2007.
OpenFst: AGeneral and Efficient Weighted Finite-State Trans-ducer Library.
CIAA?07, Prague, Czech Republic.Deniz Yuret and Ergun Bic?ici.
2009.
Modeling Mor-phologically Rich Languages Using Split Words andUnstructured Dependencies.
ACL-IJCNLP?09, Sin-gapore.DINH Q. Thang, LE H. Phuong, NGUYEN T. M.Huyen, NGUYEN C. Tu, Mathias Rossignol, andVU X. Luong.
2008.
Word Segmentation ofVietnamese Texts: a Comparison of Approaches.LREC?08, Marrakech, Morocco.Ge?rard Huet.
2009.
Formal structure of Sanskrittext: Requirements analysis for a mechanical San-skrit processor.
Sanskrit Computational Linguistics1 & 2, pages 266-277, Springer-Verlag LNAI 5402.John C. J. Hoeks and Petra Hendriks.
2005.
OptimalityTheory and Human Sentence Processing: The Caseof Coordination.
Proceedings of the 27th AnnualMeeting of the Cognitive Science Society, Erlbaum,Mahwah, NJ, pp.
959?964.Kenneth R. Beesley.
1998.
Arabic morphology usingonly finite-state operations Proceedings of the ACLWorkshop on Computational Approaches to SemiticLanguages, Montre?al, Que?bec.Leonardo Badino.
2004.
Chinese Text Word-Segmentation Considering Semantic Links amongSentences.
INTERSPEECH 2004 - ICSLP , Jeju,Korea.90
