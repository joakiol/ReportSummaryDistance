Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 61?66,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsThe OpenGrm open-source finite-state grammar software librariesBrian Roark?
Richard Sproat??
Cyril Allauzen?
Michael Riley?
Jeffrey Sorensen?
& Terry Tai?
?Oregon Health & Science University, Portland, Oregon ?Google, Inc., New YorkAbstractIn this paper, we present a new collectionof open-source software libraries that pro-vides command line binary utilities and libraryclasses and functions for compiling regularexpression and context-sensitive rewrite rulesinto finite-state transducers, and for n-gramlanguage modeling.
The OpenGrm librariesuse the OpenFst library to provide an efficientencoding of grammars and general algorithmsfor building, modifying and applying models.1 IntroductionThe OpenGrm libraries1 are a (growing) collec-tion of open-source software libraries for build-ing and applying various kinds of formal gram-mars.
The C++ libraries use the OpenFst library2for the underlying finite-state representation, whichallows for easy inspection of the resulting grammarsand models, as well as straightforward combinationwith other finite-state transducers.
Like OpenFst,there are easy-to-use command line binaries for fre-quently used operations, as well as a C++ libraryinterface, allowing library users to create their ownalgorithms from the basic classes and functions pro-vided.The libraries can be used for a range of com-mon string processing tasks, such as text normal-ization, as well as for building and using large sta-tistical models for applications like speech recogni-tion.
In the rest of the paper, we will present each ofthe two libraries, starting with the Thrax grammarcompiler and then the NGram library.
First, though,we will briefly present some preliminary (infor-mal) background on weighted finite-state transduc-ers (WFST), just as needed for this paper.1http://www.opengrm.org/2http://www.openfst.org/2 Informal WFST preliminariesA weighted finite-state transducer consists of a setof states and transitions between states.
There is aninitial state and a subset of states are final.
Each tran-sition is labeled with an input symbol from an inputalphabet; an output symbol from an output alpha-bet; an origin state; a destination state; and a weight.Each final state has an associated final weight.
Apath in the WFST is a sequence of transitions whereeach transition?s destination state is the next transi-tion?s origin state.
A valid path through the WFST isa path where the origin state of the first transition isan initial state, and the the last transition is to a finalstate.
Weights combine along the path according tothe semiring of the WFST.If every transition in the transducer has the sameinput and output symbol, then the WFST representsa weighted finite-state automaton.
In the OpenFstlibrary, there are a small number of special sym-bols that can be used.
The  symbol represents theempty string, which allows the transition to be tra-versed without consuming any symbol.
The ?
(orfailure) symbol on a transition also allows it to betraversed without consuming any symbol, but it dif-fers from  in only allowing traversal if the symbolbeing matched does not label any other transitionleaving the same state, i.e., it encodes the semanticsof otherwise, which is useful for language models.For a more detailed presentation of WFSTs, see Al-lauzen et al (2007).3 The Thrax Grammar CompilerThe Thrax grammar compiler3 compiles grammarsthat consist of regular expressions, and context-dependent rewrite rules, into FST archives (fars) ofweighted finite state transducers.
Grammars may3The compiler is named after Dionysius Thrax (170?90BCE), the reputed first Greek grammarian.61be split over multiple files and imported into othergrammars.
Strings in the rules may be parsedin one of three different ways: as a sequence ofbytes (the default), as utf8 encodings, or accord-ing to a user-provided symbol table.
With the--save symbols flag, the transducers can besaved out into fars with appropriate symbol tables.The Thrax libraries provide full support for dif-ferent weight (semiring) classes.
The command-lineflag --semiring allows one to set the semiring,currently to one of: tropical (default), log or log64semirings.3.1 General DescriptionThrax revolves around rules which, typically, con-struct an FST based on a given input.
In the simplestcase, we can just provide a string that represents a(trivial) transducer and name it using the assignmentoperator:pear = "pear";In this example, we have an FST consisting of thecharacters ?p?, ?e?, ?a?, and ?r?
in a chain, assignedto the identifier pear:This identifier can be used later in order to buildfurther FSTs, using built-in operators or using cus-tom functions:kiwi = "kiwi";fruits = pear | kiwi; # unionIn Thrax, string FSTs are enclosed by double-quotes(") whereas simple strings (often used as pathnamesfor functions) are enclosed in single-quotes (?
).Thrax provides a set of built-in functions thataid in the construction of more complex expres-sions.
We have already seen the disjunction ?|?
inthe previous example.
Other standard regular op-erations are expr*, expr+, expr?
and expr{m,n},the latter repeating expr between m and n times,inclusive.
Composition is notated with ?@?
sothat expr1 @ expr2 denotes the composition ofexpr1 and expr2.
Rewriting is denoted with ?
:?where expr1 : expr2 rewrites strings that matchexpr1 into expr2.
Weights can be added to expres-sions using the notation ?<>?
: thus, expr<2.4>adds weight 2.4 to expr.
Various operations onFSTs are also provided by built-in functions, includ-ing Determinize, Minimize, Optimize andInvert, among many others.3.2 Detailed DescriptionA Thrax grammar consists of a set of one or moresource files, each of which must have the extension.grm.
The compiler compiles each source file to asingle FST archive with the extension .far.
Eachgrammar file has sections: Imports and Body, eachof which is optional.
The body section can includestatements interleaved with functions, as specifiedbelow.
Comments begin with a single pound sign(#) and last until the next newline.3.2.1 ImportsThe Thrax compiler compiles source files (withthe extension .grm) into FST archive files (withthe extension .far).
FST archives are an Open-Fst storage format for a series of one or more FSTs.The FST archive and the original source file thenform a pair which can be imported into other sourcefiles, allowing a Python-esque include system that ishopefully familiar to many.
Instead of working witha monolithic file, Thrax allows for a modular con-struction of the final rule set as well as sharing ofcommon elements across projects.3.2.2 FunctionsThrax has extensive support for functions that cangreatly augment the capabilities of the language.Functions in Thrax can be specified in two ways.The first is inline via the func keyword within grmfiles.
These functions can take any number of inputarguments and must return a single result (usually anFST) to the caller via the return keyword:func DumbPluralize[fst] {# Concatenate with "s"...result = fst "s";# ...and then return to caller.return result;}Alternatively, functions can be written C++ andadded to the language.
Regardless of the func-tion implementation method (inline in Thrax orsubclassed in C++), functions are integrated intothe Thrax environment and can be called directlyby using the function name and providing thenecessary arguments.
Thus, assuming someone haswritten a function called NetworkPluralizethat retrieves the plural of a word from some web-site, one could write a grammar fragment as follows:62apple = "apple";plural_apple = DumbPluralize[apple];plural_tomato = NetworkPluralize["tomato",?http://server:port/...?
];3.2.3 StatementsFunctions can be interleaved with grammar state-ments that generate the FSTs that are exported to theFST archive as output.
Each statement consists of anassignment terminating with a semicolon:foo = "abc";export bar = foo | "xyz";Statements preceded with the export keyword willbe written to the final output archive.
Statementslacking this keyword define temporaries that be usedlater, but are themselves not output.The basic elements of any grammar are stringFSTs, which, as mentioned earlier, are defined bytext enclosed by double quotes ("), in contrast toraw strings, which are enclosed by single quotes (?
).String FSTs can be parsed in one of three ways,which are denoted using a dot (.)
followed by ei-ther byte, utf8, or an identifier holding a symbol ta-ble.
Note that within strings, the backslash character(\) is used to escape the next character.
Of partic-ular note, ?\n?
translates into a newline, ?\r?
intoa line feed, and ?\t?
into the tab character.
Literalleft and right square brackets also need escaping, asthey are used to generate symbols (see below).
Allother characters following the backslash are unin-terpreted, so that we can use \?
and \?
to insert anactual quote (double) quote symbol instead of termi-nating the string.Strings, by default, are interpreted as sequencesof bytes, each transition of the resulting FSTcorresponding to a single 1-byte character of theinput.
This can be specified either by leaving off theparse mode ("abc") or by explicitly using the bytemode ("abc".byte).
The second way is to useUTF8 parsing by using the special keyword, e.g.
:Finally, we can load a symbol table and splitthe string using the fst field separator flag(found in fst/src/lib/symbol-table.cc)and then perform symbol table lookups.
Symbol ta-bles can be loaded using the SymbolTable built-infunction:arctic_symbol_table =SymbolTable[?/path/to/bears.symtab?
];pb = "polar bear".arctic_symbol_table;One can also create temporary symbols on thefly by enclosing a symbol name inside bracketswithin an FST string.
All of the text inside thebrackets will be taken to be part of the symbolname, and future encounters of the same symbolname will map to the same label.
By default, la-bels use ?Private Use Area B?
of the unicode ta-ble (0x100000 - 0x10FFFD), except that the last twocode points 0x10FFFC and 0x10FFFD are reservedfor the ?[BOS]?
and ?[EOS]?
tags discussed below.cross_pos = "cross" ("" : "_[s_noun]");pluralize_nouns = "_[s_noun]" : "es";3.3 Standard Library Functions andOperationsBuilt-in functions are provided that operate on FSTsand perform most of the operations that are availablein the OpenFst library.
These include: closure, con-catenation, difference, composition and union.
Inmost cases the notation of these functions followsstandard conventions.
Thus, for example, for clo-sure, the following syntax applies: fst* (accepts fst0 or more times); fst+ (accepts fst 1 or more times);fst?
(accepts fst 0 or 1 times) fst{x,y} (accepts fst atleast x but no more than y times).The operator ?@?
is used for composition: a @b denotes a composed with b.
A ?:?
is used to de-note rewrite, where a : b denotes a transducerthat deletes a and inserts b.
Most functions can alsobe expressed using functional notation:b = Rewrite["abc", "def"];The delimiters< and> add a weight to an expres-sion in the chosen semiring: a<3> adds the weight3 (in the tropical semiring by default) to a.Functions lacking operators (hence only calledby function name) include: ArcSort, Connect,Determinize, RmEpsilon, Minimize,Optimize, Invert, Project and Reverse.Most of these call the obvious underlying OpenFstfunction.One function in particular, CDRewrite is worthfurther discussion.
This function takes a transducerand two context acceptors (and the alphabet ma-chine), and generates a new FST that performs acontext dependent rewrite everywhere in the pro-vided contexts.
The context-dependent rewrite algo-rithm used is that of Mohri and Sproat (1996), and63see also Kaplan and Kay (1994).
The fourth argu-ment (sigma star) needs to be a minimized ma-chine.
The fifth argument selects the direction ofrewrite; we can either rewrite left-to-right or right-to-left or simultaneously.
The sixth argument selectswhether the rewrite is optional.CDRewrite[tau, lambda, rho,sigma_star,?ltr?|?rtl?|?sim?,?obl?|?opt?
]For context-dependent rewrite rules, two built-insymbols ?[BOS]?
and ?[EOS]?
have a special mean-ing in the context specifications: they refer to thebeginning and end of string, respectively.There are also built-in functions that performother tasks.
In the interest of space we concentratehere on the StringFile function, which loads afile consisting of a list of strings, or tab-separatedpairs of strings, and compiles them to an acceptorthat represents the union of the strings.StringFile[?strings_file?
]While it is equivalent to the union of the individualstring (pairs), StringFile uses an efficient algo-rithm for constructing a prefix tree (trie) from thelist and can be significantly more efficient than com-puting a union for large lists.
If a line consists of atab-separated pair of strings a, b, a transducer equiv-alent to Rewrite[a, b] is compiled.The optional keywords byte (default), utf8 orthe name of a symbol table can be used to specifythe parsing mode for the strings.
ThusStringFile[?strings_file?, utf8, my_symtab]would parse a sequence of tab-separated pairs, usingutf8 parsing for the left-hand string, and the symboltable my symtab for the right-hand string.4 NGram LibraryThe OpenGrm NGram library contains tools forbuilding, manipulating and using n-gram languagemodels represented as weighted finite-state trans-ducers.
The same finite-state topology is used to en-code raw counts as well as smoothed models.
Herewe briefly present this structure, followed by detailson the operations manipulating it.An n-gram is a sequence of n symbols: w1 .
.
.
wn.Each state in the model represents a prefix historyof the n-gram (w1 .
.
.
wn?1), and transitions in themodel represent either n-grams or backoff transi-tions following that history.
Figure 1 lists conven-tions for states and transitions used to encode then-grams as a WFST.This representation is similar to that used in otherWFST-based n-gram software libraries, such as theAT&T GRM library (Allauzen et al, 2005).
Onekey difference is the implicit representation of <s>and </s>, as opposed to encoding them as symbolsin the grammar.
This has the benefit of including allstart and stop symbol functionality while avoidingcommon pitfalls that arise with explicit symbols.Another difference from the GRM library repre-sentation is explicit inclusion of failure links fromstates to their backoff states even in the raw countfiles.
The OpenGrm n-gram FST format is consis-tent through all stages of building the models, mean-ing that model manipulation (e.g., merging of twoFigure 1: List of state and transition conventions used to encode collection of n-grams in WFST.An n-gram is a sequence of n symbols: w1 .
.
.
wn.
Its proper prefixes include all sequences w1 .
.
.
wk for k < n.?
There is a unigram state in every model, representing the empty string.?
Every proper prefix of every n-gram in the model has an associated state in the model.?
The state associated with an n-gram w1...wn has a backoff transition (labeled with ) to the state associatedwith its suffix w2...wn.?
An n-gram w1...wn is represented as a transition, labeled with wn, from the state associated with its prefixw1...wn?1 to a destination state defined as follows:?
If w1...wn is a proper prefix of an n-gram in the model, then the destination of the transition is the stateassociated with w1...wn?
Otherwise, the destination of the transition is the state associated with the suffix w2...wn.?
Start and end of the sequence are not represented via transitions in the automaton or symbols in the symboltable.
Rather?
The start state of the automaton encodes the ?start of sequence?
n-gram prefix (commonly denoted<s>).?
The end of the sequence (often denoted </s>) is included in the model through state final weights, i.e.,for a state associated with an n-gram prefix w1...wn, the final weight of that state represents the weightof the n-gram w1...wn</s>.64(a)??
?a/0a/-1.1b/-1.1b/0b/-0.69a/-0.6900(b)?/0.69?/0.916a/0.6a/0.b/0.b/0.99b/0.6a/0.60.961.6?/0.916Figure 2: FST representations of (a) bigram and unigramcounts; and (b) smoothed bigram model, when trained on thesingle string ?a b a b b a?models or count files, or pruning them) can be pro-cessed by the same operations.
By convention, allcounts and probabilities are stored as negative logs,and the FSTs are in the Tropical semiring.
The sym-bol table provided during counting is kept with themodel FSTs.4.1 N-gram CountingThe command line binary ngramcount takes asinput an FST archive (far) consisting of a collectionof acyclic WFSTs and outputs an n-gram WFST ofthe specified order.
The acyclic WFSTs can be linearautomata representing strings from a corpus ?
easilycompiled using the farcompilestrings com-mand of OpenFst ?
or weighted word lattices outputfrom, say, a speech recognition or machine transla-tion system.
In such a way, expected frequencies ofn-grams can be counted.
To count all trigrams, bi-grams and unigrams in the compiled (far) corpus:ngramcount -order=3 in.far >3g.cnt.fstFor example, counting with the -order=2 flag(bigrams) from a corpus consisting of a single string?a b a b b a?
yields the FST in Figure 2(a).Each state represents a prefix history: the leftmoststate is the initial state, representing the <s> his-tory; the central state is the unigram state, represent-ing the  history; the topmost state represents the his-tory ?a?
; and the bottom state represents the history?b?.
Since this is a bigram model, histories consist ofat most one prior symbol from the vocabulary.
Dou-ble circles represent final states, which come with afinal weight encoding the negative log count of end-ing the string at that state.
Only the ?a?
history stateand the unigram state are final states, since our ex-ample string ends with the symbol ?a?.
(The unigramstate is always final.)
The  transitions are backofftransitions, and the weights on each n-gram transi-tion are negative log counts of that symbol occurringfollowing the history that the state represents.
Hencethe bigram ?b b?
occurs once, yielding a negativelog of zero for the transition labeled with ?b?
leavingthe state representing the history ?b?.4.2 N-gram Model Parameter EstimationGiven counts, one can build a smoothed n-grammodel by normalizing and smoothing, which is ac-complished with the ngrammake command linebinary.
The library has several available smooth-ing methods, including Katz (1987), absolute dis-counting (Ney et al, 1994), Kneser-Ney (1995) and(the default) Witten-Bell (1991).
See Chen andGoodman (1998) for a detailed presentation of thesesmoothing methods.
Each of these smoothing meth-ods is implemented as a relatively simple derivedsubclass, thus allowing for straightforward exten-sion to new and different smoothing methods.
Tomake a smoothed n-gram model from counts:ngrammake 3g.cnt.fst >3g.mod.fstFigure 2(b) shows the model built using the de-fault Witten-Bell smoothing from the count FST in2(a).
The topology remains identical, but now then-gram transition weights and final weights are neg-ative log probabilities.
The backoff transitions (la-beled with ) have the negative log backoff weights,which ensure that the model is correctly normalized.Models, by default, are smoothed by interpolat-ing higher- and lower-order probabilities.
This iseven true for methods more typically associated withbackoff (rather than mixture) smoothing styles, suchas Katz.
While the smoothing values are estimatedusing interpolation, the model is encoded as a back-off model by pre-summing the interpolated proba-bilities, so that the backoff transitions are to be tra-versed only for symbols without transitions out ofthe current state.
While these backoff transitions arelabeled with , see Section 4.4 for discussion of ap-plying them as failure transitions.654.3 N-gram Model Merging and PruningTwo n-gram count FSTs or two model FSTs can bemerged into a single FST using ngrammerge, withcommand line flags to allow for scaling of each ofthe two, and to indicate whether to carry out full nor-malization.
This approach allows for various sorts ofMAP adaptation approaches for the n-gram models(Bacchiani et al, 2006).
To merge two input FSTmodels with no scaling:ngrammerge in.mod1 in.mod2 >mrg.modN-gram model pruning is provided with three dif-ferent methods: count pruning based on a threshold;the method from Seymore and Rosenfeld (1996);and relative entropy pruning of Stolcke (1998).
Likesmoothing, each of these pruning methods is imple-mented as a relatively simple derived subclass, thusallowing for straightforward extension to new anddifferent pruning methods.
To prune a smoothed n-gram model:ngramshrink -theta=4 in.mod >prn.mod4.4 N-gram UtilitiesIn addition to the above detailed core operations onlanguage models, the OpenGrm NGram library hasa number of utilities that make building and usingthe models very easy.
There are utilities relatedto input and output, including ngramsymbols,which produces a symbol table from a corpus;ngramread, which reads in textual count filesand models in ARPA format and encodes themas an FST; ngramprint which prints n-gramcounts or ARPA format text files; and ngraminfowhich displays information about the model, suchas number of n-grams of various orders.
Thereare also utilities related to the use of the models,including ngramapply, which applies the modelto an input FST archive (far); ngramrandgenwhich randomly generates strings from the model;and ngramperplexity which calculates the per-plexity of a corpus given the model.
Note thatngramapply includes options for interpreting thebackoff transitions as failure transitions.AcknowledgmentsThis work was supported in part by a Google Fac-ulty Research Award, NSF grant #IIS-0811745 andDARPA #HR0011-09-1-0041.
Any opinions, find-ings, conclusions or recommendations expressed inthis publication are those of the authors and do notnecessarily reflect the views of the NSF or DARPA.ReferencesCyril Allauzen, Mehryar Mohri, and Brian Roark.
2005.The design principles and algorithms of a weightedgrammar library.
International Journal of Founda-tions of Computer Science, 16(3):403?421.Cyril Allauzen, Michael Riley, Johan Schalkwyk, Woj-ciech Skut, and Mehryar Mohri.
2007.
OpenFst: Ageneral and efficient weighted finite-state transducerlibrary.
In Proceedings of the Twelfth InternationalConference on Implementation and Application of Au-tomata (CIAA 2007), Lecture Notes in Computer Sci-ence, volume 4793, pages 11?23.Michiel Bacchiani, Michael Riley, Brian Roark, andRichard Sproat.
2006.
MAP adaptation of stochas-tic grammars.
Computer Speech and Language,20(1):41?68.Stanley Chen and Joshua Goodman.
1998.
An empiricalstudy of smoothing techniques for language modeling.Technical report, TR-10-98, Harvard University.Ronald M. Kaplan and Martin Kay.
1994.
Regular mod-els of phonological rule systems.
Computational Lin-guistics, 20:331?378.Slava M. Katz.
1987.
Estimation of probabilities fromsparse data for the language model component of aspeech recogniser.
IEEE Transactions on Acoustics,Speech, and Signal Processing, 35(3):400?401.Reinhard Kneser and Hermann Ney.
1995.
Improvedbacking-off for m-gram language modeling.
In Pro-ceedings of the IEEE International Conference onAcoustics, Speech, and Signal Processing (ICASSP),pages 181?184.Mehryar Mohri and Richard Sproat.
1996.
An efficientcompiler for weighted rewrite rules.
In Proceedings ofthe 34th Annual Meeting of the Association for Com-putational Linguistics, pages 231?238.Hermann Ney, Ute Essen, and Reinhard Kneser.
1994.On structuring probabilistic dependences in stochasticlanguage modeling.
Computer Speech and Language,8:1?38.Kristie Seymore and Ronald Rosenfeld.
1996.
Scalablebackoff language models.
In Proceedings of the Inter-national Conference on Spoken Language Processing(ICSLP).Andreas Stolcke.
1998.
Entropy-based pruning of back-off language models.
In Proc.
DARPA Broadcast NewsTranscription and Understanding Workshop, pages270?274.Ian H. Witten and Timothy C. Bell.
1991.
The zero-frequency problem: Estimating the probabilities ofnovel events in adaptive text compression.
IEEETransactions on Information Theory, 37(4):1085?1094.66
