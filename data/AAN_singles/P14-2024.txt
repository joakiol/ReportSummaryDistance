Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 143?149,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsOn the Elements of an AccurateTree-to-String Machine Translation SystemGraham Neubig, Kevin DuhGraduate School of Information ScienceNara Institute of Science and Technology8916-5 Takayama-cho, Ikoma-shi, Nara, Japan{neubig,kevinduh}@is.naist.jpAbstractWhile tree-to-string (T2S) translation the-oretically holds promise for efficient, ac-curate translation, in previous reports T2Ssystems have often proven inferior to othermachine translation (MT) methods such asphrase-based or hierarchical phrase-basedMT.
In this paper, we attempt to clarifythe reason for this performance gap byinvestigating a number of peripheral ele-ments that affect the accuracy of T2S sys-tems, including parsing, alignment, andsearch.
Based on detailed experimentson the English-Japanese and Japanese-English pairs, we show how a basic T2Ssystem that performs on par with phrase-based systems can be improved by 2.6-4.6BLEU, greatly exceeding existing state-of-the-art methods.
These results indi-cate that T2S systems indeed hold muchpromise, but the above-mentioned ele-ments must be taken seriously in construc-tion of these systems.1 IntroductionIn recent years, syntactic parsing is being viewedas an ever-more important element of statisticalmachine translation (SMT) systems, particularlyfor translation between languages with large dif-ferences in word order.
There are many ways ofincorporating syntax into MT systems, includingthe use of string-to-tree translation (S2T) to ensurethe syntactic well-formedness of the output (Gal-ley et al, 2006; Shen et al, 2008), tree-to-string(T2S) using source-side parsing as a hint duringthe translation process (Liu et al, 2006), or pre-or post-ordering to help compensate for reorder-ing problems experienced by non-syntactic meth-ods such as phrase-based MT (PBMT) (Collins etal., 2005; Sudoh et al, 2011).
Among these, T2Stranslation has a number of attractive theoreticalproperties, such as joint consideration of global re-ordering and lexical choice while maintaining rel-atively fast decoding times.However, building an accurate T2S system isnot trivial.
On one hand, there have been multiplereports (mainly from groups with a long historyof building T2S systems) stating that systems us-ing source-side syntax greatly out-perform phrase-based systems (Mi et al, 2008; Liu et al, 2011;Zhang et al, 2011; Tamura et al, 2013).
On theother hand, there have been also been multiple re-ports noting the exact opposite result that source-side syntax systems perform worse than Hiero,S2T, PBMT, or PBMT with pre-ordering (Ambatiand Lavie, 2008; Xie et al, 2011; Kaljahi et al,2012).
In this paper, we argue that this is due to thefact that T2S systems have the potential to achievehigh accuracy, but are also less robust, with a num-ber of peripheral elements having a large effect ontranslation accuracy.Our motivation in writing this paper is to pro-vide a first step in examining and codifying themore important elements that make it possible toconstruct a highly accurate T2S MT system.
To doso, we perform an empirical study of the effect ofparsing accuracy, packed forest input, alignmentaccuracy, and search.
The reason why we choosethese elements is that past work that has reportedlow accuracy for T2S systems has often neglectedto consider one or all of these elements.As a result of our tests on English-Japanese (en-ja) and Japanese-English (ja-en) machine transla-tion, we find that a T2S system not consideringthese elements performs only slightly better than astandard PBMT system.
However, after account-ing for all these elements we see large increases ofaccuracy, with the final system greatly exceedingnot only standard PBMT, but also state-of-the-artmethods based on syntactic pre- or post-ordering.1432 Experimental Setup2.1 Systems ComparedIn our experiments, we use a translation modelbased on T2S tree transducers (Graehl and Knight,2004), constructed using the Travatar toolkit (Neu-big, 2013).
Rules are extracted using the GHKMalgorithm (Galley et al, 2006), and rules withup to 5 composed minimal rules, up to 2 non-terminals, and up to 10 terminals are used.We also prepare 3 baselines not based on T2Sto provide a comparison with other systems in theliterature.
The first two baselines are standard sys-tems using PBMT or Hiero trained using Moses(Koehn et al, 2007).
We use default settings, ex-cept for setting the reordering limit or maximumchart span to the best-performing value of 24.
Asour last baselines, we use two methods based onsyntactic pre- or post-ordering, which are state-of-the-art methods for the language pairs.
Specifi-cally, for en-ja translation we use the head finaliza-tion pre-ordering method of (Isozaki et al, 2010b),and for ja-en translation, we use the syntactic post-ordering method of (Goto et al, 2012).
For allsystems, T2S or otherwise, the language model isa Kneser-Ney 5-gram, and tuning is performed tomaximize BLEU score using minimum error ratetraining (Och, 2003).2.2 Data and EvaluationWe perform all of our experiments on en-jaand ja-en translation over data from the NTCIRPatentMT task (Goto et al, 2011), the most stan-dard benchmark task for these language pairs.
Weuse the training data from NTCIR 7/8, a total ofapproximately 3.0M sentences, and perform tun-ing on the NTCIR 7 dry run, testing on the NTCIR7 formal run data.
As evaluation measures, we usethe standard BLEU (Papineni et al, 2002) as wellas RIBES (Isozaki et al, 2010a), a reordering-based metric that has been shown to have highcorrelation with human evaluations on the NTCIRdata.
We measure significance of results usingbootstrap resampling at p < 0.05 (Koehn, 2004).In tables, bold numbers indicate the best systemand all systems that were not significantly differ-ent from the best system.2.3 Motivational ExperimentBefore going into a detailed analysis, we firstpresent results that stress the importance of the el-ements described in the introduction.
To do so,en-ja ja-enSystem BLEU RIBES BLEU RIBESPBMT 35.84 72.89 30.49 69.80Hiero 34.45 72.94 29.41 69.51Pre/Post 36.69 77.05 29.42 73.85T2S-all 36.23 76.60 31.15 72.87T2S+all 40.84 80.15 33.70 75.94Table 1: Overall results for five systems.we compare the 3 non-T2S baselines with twoT2S systems that vary the settings of the parser,alignment, and search, as described in the follow-ing Sections 3, 4, and 5.
The first system ?T2S-all?
is a system that uses the worst settings1foreach of these elements, while the second system?T2S+all?
uses the best settings.2The results forthe systems are shown in Table 1.The most striking result is that T2S+all signif-icantly exceeds all of the baselines, even includ-ing the pre/post-ordering baselines, which providestate-of-the-art results on this task.
The gains areparticularly striking on en-ja, with a gain of over 4BLEU points over the closest system, but still sig-nificant on the ja-en task, where the use of source-side syntax has proven less effective in previouswork (Sudoh et al, 2011).
The next thing to noticeis that if we had instead used T2S-all, our conclu-sion would have been much different.
This systemis able to achieve respectable accuracy comparedto PBMT or Hiero, but does not exceed the morecompetitive pre/post-ordering systems.3With thisresult in hand, we will investigate the contributionof each of these elements in detail in the followingsections.
In the remainder of the paper settingsfollow T2S+all except when otherwise noted.3 Parsing3.1 Parsing OverviewAs T2S translation uses parse trees both in train-ing and testing of the system, an accurate syntacticparser is required.
In order to test the extent thatparsing accuracy affects translation, we use two1Stanford/Eda, GIZA++, pop-limit 5000 cube pruning.2Egret forests, Nile, pop-limit 5000 hypergraph search.3We have also observed similar trends on other genres andlanguage pairs.
For example, in a Japanese-Chinese/Englishmedical conversation task (Neubig et al, 2013), forests,alignment, and search resulted in BLEU increases of en-ja24.55?30.81, ja-en 19.28?22.46, zh-ja 15.22?20.67, ja-zh30.88?33.89.144different syntactic parsers and examine the trans-lation accuracy realized by each parser.For English, the two most widely referencedparsers are the Stanford Parser and BerkeleyParser.
In this work, we compare the StanfordParser?s CFG model, with the Berkeley Parser?slatent variable model.
In previous reports, it hasbeen noted (Kummerfeld et al, 2012) that the la-tent variable model of the Berkeley parser tends tohave the higher accuracy of the two, so if the accu-racy of a system using this model is higher then itis likely that parsing accuracy is important for T2Stranslation.
Instead of the Berkeley Parser itself,we use a clone Egret,4which achieves nearly iden-tical accuracy, and is able to output packed forestsfor use in MT, as mentioned below.
Trees areright-binarized, with the exception of phrase-finalpunctuation, which is split off before any other el-ement in the phrase.For Japanese, our first method uses the MST-based pointwise dependency parser of Flannery etal.
(2011), as implemented in the Eda toolkit.5In order to convert dependencies into phrase-structure trees typically used in T2S translation,we use the head rules implemented in the Travatartoolkit.
In addition, we also train a latent variableCFG using the Berkeley Parser and use Egret forparsing.
Both models are trained on the JapaneseWord Dependency Treebank (Mori et al, 2014).In addition, Mi et al (2008) have proposed amethod for forest-to-string (F2S) translation us-ing packed forests to encode many possible sen-tence interpretations.
By doing so, it is possible toresolve some of the ambiguity in syntactic inter-pretation at translation time, potentially increasingtranslation accuracy.
However, the great majorityof recent works on T2S translation do not considermultiple syntactic parses (e.g.
Liu et al (2011),Zhang et al (2011)), and thus it is important toconfirm the potential gains that could be acquiredby taking ambiguity into account.3.2 Effect of Parsing and Forest InputIn Table 2 we show the results for Stanford/Edawith 1-best tree input vs. Egret with trees orforests as input.
Forests are those containing alledges in the 100-best parses.First looking at the difference between the twoparsers, we can see that the T2S system using4http://code.google.com/p/egret-parser5http://plata.ar.media.kyoto-u.ac.jp/tool/EDAen-ja ja-enSystem BLEU RIBES BLEU RIBESStan/Eda 38.95 78.47 32.56 73.03Egret-T 39.26 79.26 32.97 74.94Egret-F 40.84 80.15 33.70 75.94Table 2: Results for Stanford/Eda, Egret with treeinput, and Egret with forest input.1 0 100Forest n-best Cutoff0.00.20.40.60.81.0BLEU 394041421.752.032.583.06 3.21 3.703.734.61en-jaja-en1 10 100323334351.21 1.321.39 1.501.61 1.74 2.052.07Figure 1: BLEU scores using various levels of for-est pruning.
Numbers in the graph indicate decod-ing time in seconds/sentence.Egret achieves greater accuracy than that using theother two parsers.
This improvement is particu-larly obvious in RIBES, indicating that an increasein parsing accuracy has a larger effect on globalreordering than on lexical choice.
When goingfrom T2S to F2S translation using Egret, we seeanother large gain in accuracy, although this timewith the gain in BLEU being more prominent.
Webelieve this is related to the observation of Zhangand Chiang (2012) that F2S translation is not nec-essarily helping fixing parsing errors, but insteadgiving the translation system the freedom to ignorethe parse somewhat, allowing for less syntacticallymotivated but more fluent translations.As passing some degree of syntactic ambigu-ity on to the decoder through F2S translation hasproven useful, a next natural question is how muchof this ambiguity we need to preserve in our forest.The pruning criterion that we use for the forest isbased on including all edges that appear in one ormore of the n-best parses, so we perform transla-tion setting n to 1 (trees), 3, 6, 12, 25, 50, 100, and200.
Figure 1 shows results for these settings withregards to translation accuracy and speed.
Over-all, we can see that every time we double the sizeof the forest we get an approximately linear in-145crease in BLEU at the cost of an increase in decod-ing time.
Interestingly, the increases in BLEU didnot show any sign of saturating even when settingthe n-best cutoff to 200, although larger cutoffs re-sulted in exceedingly large translation forests thatrequired large amounts of memory.4 Alignment4.1 Alignment OverviewThe second element that we investigate is align-ment accuracy.
It has been noted in many previ-ous works that significant gains in alignment accu-racy do not make a significant difference in trans-lation results (Ayan and Dorr, 2006; Ganchev etal., 2008).
However, none of these works have ex-plicitly investigated the effect on T2S translation,so it is not clear whether these results carry over toour current situation.As our baseline aligner, we use the GIZA++ im-plementation of the IBM models (Och and Ney,2003) with the default options.
To test the effectof improved alignment accuracy, we use the dis-criminative alignment method of Riesa and Marcu(2010) as implemented in the Nile toolkit.6Thismethod has the ability to use source- and target-side syntactic information, and has been shown toimprove the accuracy of S2T translation.We trained Nile and tested both methods onthe Japanese-English alignments provided withthe Kyoto Free Translation Task (Neubig, 2011)(430k parallel sentences, 1074 manually alignedtraining sentences, and 120 manually aligned testsentences).7As creating manual alignment data iscostly, we also created two training sets that con-sisted of 1/4 and 1/16 of the total data to test ifwe can achieve an effect with smaller amounts ofmanually annotated data.
The details of data sizeand alignment accuracy are shown in Table 3.4.2 Effect of Alignment on TranslationIn Table 4, we show results when we vary thealigner between GIZA++ and Nile.
For reference,we also demonstrate results when using the samealignments for PBMT and Hiero.From this, we can see that while for PBMT andHiero systems the results are mixed, as has beennoted in previous work (Fraser and Marcu, 2007),6http://code.google.com/p/nile7This data is from Wikipedia articles about Kyoto City,and is an entirely different genre than our MT test data.
It islikely that creating aligned data that matches the MT genrewould provide larger gains in MT accuracy.Name Sent.
Prec.
Rec.
F-measGIZA++ 0 60.46 55.48 57.86Nile/16 68 70.21 60.81 65.17Nile/4 269 72.85 62.70 67.40Nile 1074 72.73 63.97 68.07Table 3: Alignment accuracy (%) by method andnumber of manually annotated training sentences.en-ja ja-enSystem BLEU RIBES BLEU RIBESPBMT-G 35.84 72.89 30.49 69.80PBMT-N 36.05 71.84 30.77 69.75Hiero-G 34.45 72.94 29.41 69.51Hiero-N 33.90 72.63 28.90 69.83T2S-G 39.57 78.94 32.62 75.19T2S-N/16 40.79 80.05 32.82 74.89T2S-N/4 40.97 80.32 33.35 75.46T2S-N 40.84 80.15 33.70 75.94Table 4: Results varying the aligner (GIZA++ vs.Nile), including results for Nile when using 1/4 or1/16 of the annotated training data.Figure 2: Probabilities for SVO?SOV rules.improving the alignment accuracy gives signifi-cant gains for T2S translation.
The reason for thisdifference is two-fold.
The first is that in ruleextraction in syntax-based translation (Galley etal., 2006), a single mistaken alignment crossingphrase boundaries results not only in a bad rule be-ing extracted, but also prevents the extraction of anumber of good rules.
This is reflected in the sizeof the rule table; the en-ja system built using Nilecontains 92.8M rules, while the GIZA++ systemcontains only 83.3M rules, a 11.2% drop.The second reason why alignment is importantis that while one of the merits of T2S models istheir ability to perform global re-ordering, it is dif-ficult to learn good reorderings from bad align-ments.
We show an example of this in Figure 2.When translating SVO English to SOV Japanese,we expect rules containing a verb and a followingnoun phrase (VO) to have a high probability of be-ing reversed (to OV), possibly with the addition of146the Japanese direct object particle ?wo.?
From thefigure, we can see that the probabilities learned byNile match this intuition, while the probabilitieslearned by GIZA heavily favor no reordering.Finally, looking at the amount of data needed totrain the model, we can see that a relatively smallamount of manually annotated data proves suffi-cient for large gains in alignment accuracy, witheven 68 sentences showing a 7.31 point gain in F-measure over GIZA++.
This is because Nile?s fea-ture set uses generalizable POS/syntactic informa-tion and also because mis-alignments of commonfunction words (e.g.
a/the) will be covered evenby small sets of training data.
Looking at the MTresults, we can see that even the smaller data setsallow for gains in accuracy, although the gains aremore prominent for en-ja.5 Search5.1 Search OverviewFinally, we examine the effect that the choice ofsearch algorithm has on the accuracy of transla-tion.
The most standard search algorithm for T2Stranslation is bottom-up beam search using cubepruning (CP, Chiang (2007)).
However, there area number of other search algorithms that havebeen proposed for tree-based translation in gen-eral (Huang and Chiang, 2007) or T2S systemsin particular (Huang and Mi, 2010; Feng et al,2012).
In this work, we compare CP and the hy-pergraph search (HS) method of Heafield et al(2013), which is also a bottom-up pruning algo-rithm but performs more efficient search by group-ing together similar language model states.5.2 Effect of SearchFigure 3 shows BLEU and decoding speed resultsusing HS or CP on T2S and F2S translation, us-ing a variety of pop limits.
From this, we can seethat HS out-performs CP for both F2S and T2S,especially with smaller pop limits.
Comparing thegraphs for F2S and T2S translation, it is notablethat the shapes of the graphs for the two meth-ods are strikingly similar.
This result is somewhatsurprising, as the overall search space of F2S islarger and it would be natural for the characteris-tics of the search algorithm to vary between thesetwo settings.
Finally, comparing ja-en and en-ja,search is simpler for the former, a result of the factthat the Japanese sentences contain more words,and thus more LM evaluations per sentence.100 0 10000Pop Limit0.00.20.40.60.81.0BLEU(F2S)3738394041420.330.420.72 1.07 1.813.73 5.60 9.590.330.430.66 1.041.77 4.439.60 17.40en-ja HSen-ja CP100 1000 100003031323334350.220.30 0.41 0.58 0.91 2.05 3.54 6.440.240.320.43 0.711.01 2.29 4.73 9.18ja-en HSja-en CP100 0 10000Pop Limit0.00.20.40.60.81.0BLEU(T2S)3637383940410.080.120.25 0.430.76 1.75 2.96 4.800.080.090.270.38 0.711.75 4.34 8.73en-ja HSen-ja CP100 1000 100002930313233340.10 0.14 0.25 0.37 0.57 1.21 2.22 3.970.100.130.24 0.44 0.641.60 3.83 5.74ja-en HSja-en CPFigure 3: Hypergraph search (HS) and cubepruning (CP) results for F2S and T2S.
Numbersabove and below the lines indicate time in sec-onds/sentence for HS and CP respectively.6 ConclusionIn this paper, we discussed the importance of threeperipheral elements that contribute greatly to theaccuracy of T2S machine translation: parsing,alignment, and search.
Put together, a T2S sys-tem that uses the more effective settings for thesethree elements greatly outperforms a system thatuses more standard settings, as well as the currentstate-of-the-art on English-Japanese and Japanese-English translation tasks.Based on these results we draw three conclu-sions.
The first is that given the very competitiveresults presented here, T2S systems do seem tohave the potential to achieve high accuracy, evenwhen compared to strong baselines incorporatingsyntactic reordering into a phrase-based system.The second is that when going forward with re-search on T2S translation, one should first be sureto account for these three elements to ensure asturdy foundation for any further improvements.Finally, considering the fact that parsing and align-ment for each of these languages is far from per-fect, further research investment in these fieldsmay very well have the potential to provide ad-ditional gains in accuracy in the T2S framework.Acknowledgments: This work was supportedby JSPS KAKENHI Grant Number 25730136.147ReferencesVamshi Ambati and Alon Lavie.
2008.
Improving syn-tax driven translation models by re-structuring diver-gent and non-isomorphic parse tree structures.
InProc.
AMTA, pages 235?244.Necip Ayan and Bonnie Dorr.
2006.
Going beyondAER: an extensive analysis of word alignments andtheir impact on MT.
In Proc.
ACL.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
Computational Linguistics, 33(2):201?228.Michael Collins, Philipp Koehn, and Ivona Kucerova.2005.
Clause restructuring for statistical machinetranslation.
In Proc.
ACL, pages 531?540.Yang Feng, Yang Liu, Qun Liu, and Trevor Cohn.2012.
Left-to-right tree-to-string decoding with pre-diction.
In Proc.
EMNLP, pages 1191?1200.Daniel Flannery, Yusuke Miyao, Graham Neubig, andShinsuke Mori.
2011.
Training dependency parsersfrom partially annotated corpora.
In Proc.
IJCNLP,pages 776?784.Alexander Fraser and Daniel Marcu.
2007.
Measuringword alignment quality for statistical machine trans-lation.
Computational Linguistics, 33(3):293?303.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve DeNeefe, Wei Wang, and IgnacioThayer.
2006.
Scalable inference and training ofcontext-rich syntactic translation models.
In Proc.ACL, pages 961?968.Kuzman Ganchev, Joa?o V. Grac?a, and Ben Taskar.2008.
Better alignments = better translations?
InProc.
ACL.Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, andBenjamin K. Tsou.
2011.
Overview of the patentmachine translation task at the NTCIR-9 workshop.In Proceedings of NTCIR, volume 9, pages 559?578.Isao Goto, Masao Utiyama, and Eiichiro Sumita.
2012.Post-ordering by parsing for Japanese-English sta-tistical machine translation.
In Proc.
ACL, pages311?316.Jonathan Graehl and Kevin Knight.
2004.
Trainingtree transducers.
In Proc.
HLT, pages 105?112.Kenneth Heafield, Philipp Koehn, and Alon Lavie.2013.
Grouping language model boundary words tospeed k?best extraction from hypergraphs.
In Proc.NAACL, pages 958?968.Liang Huang and David Chiang.
2007.
Forest rescor-ing: Faster decoding with integrated language mod-els.
In Proc.
ACL, pages 144?151.Liang Huang and Haitao Mi.
2010.
Efficient incre-mental decoding for tree-to-string translation.
InProc.
EMNLP, pages 273?283.Hideki Isozaki, Tsutomu Hirao, Kevin Duh, KatsuhitoSudoh, and Hajime Tsukada.
2010a.
Automaticevaluation of translation quality for distant languagepairs.
In Proc.
EMNLP, pages 944?952.Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, andKevin Duh.
2010b.
Head finalization: A simplereordering rule for SOV languages.
In Proc.
WMTand MetricsMATR.Rasoul Samad Zadeh Kaljahi, Raphael Rubino, JohannRoturier, and Jennifer Foster.
2012.
A detailedanalysis of phrase-based and syntax-based machinetranslation: The search for systematic differences.In Proc.
AMTA.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProc.
ACL, pages 177?180.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proc.
EMNLP.Jonathan K Kummerfeld, David Hall, James R Cur-ran, and Dan Klein.
2012.
Parser showdown at thewall street corral: an empirical investigation of er-ror types in parser output.
In Proc.
EMNLP, pages1048?1059.Yang Liu, Qun Liu, and Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machinetranslation.
In Proc.
ACL.Yang Liu, Qun Liu, and Yajuan Lu?.
2011.
Adjoin-ing tree-to-string translation.
In Proc.
ACL, pages1278?1287.Haitao Mi, Liang Huang, and Qun Liu.
2008.
Forest-based translation.
In Proc.
ACL, pages 192?199.Shinsuke Mori, Hideki Ogura, and Tetsuro Sasada.2014.
A Japanese word dependency corpus.
InProc.
LREC.Graham Neubig, Sakriani Sakti, Tomoki Toda, SatoshiNakamura, Yuji Matsumoto, Ryosuke Isotani, andYukichi Ikeda.
2013.
Towards high-reliabilityspeech translation in the medical domain.
In Proc.MedNLP, pages 22?29.Graham Neubig.
2011.
The Kyoto free translationtask.
http://www.phontron.com/kftt.Graham Neubig.
2013.
Travatar: A forest-to-stringmachine translation engine based on tree transduc-ers.
In Proc.
ACL Demo Track, pages 91?96.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.148Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proc.
ACL, pages160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proc.
ACL,pages 311?318.Jason Riesa and Daniel Marcu.
2010.
Hierarchicalsearch for word alignment.
In Proc.
ACL, pages157?166.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2008.
Anew string-to-dependency machine translation algo-rithm with a target dependency language model.
InProc.
ACL, pages 577?585.Katsuhito Sudoh, Xianchao Wu, Kevin Duh, HajimeTsukada, and Masaaki Nagata.
2011.
Post-orderingin statistical machine translation.
In Proc.
MT Sum-mit.Akihiro Tamura, Taro Watanabe, Eiichiro Sumita, Hi-roya Takamura, and Manabu Okumura.
2013.
Part-of-speech induction in dependency trees for statisti-cal machine translation.
In Proc.
ACL, pages 841?851.Jun Xie, Haitao Mi, and Qun Liu.
2011.
A noveldependency-to-string model for statistical machinetranslation.
In Proc.
EMNLP, pages 216?226.Hui Zhang and David Chiang.
2012.
An explorationof forest-to-string translation: Does translation helpor hurt parsing?
In Proc.
ACL, pages 317?321.Hao Zhang, Licheng Fang, Peng Xu, and Xiaoyun Wu.2011.
Binarized forest to string translation.
In Proc.ACL, pages 835?845.149
