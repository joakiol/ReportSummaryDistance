Proceedings of the Workshop on BioNLP: Shared Task, pages 41?49,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsA Markov Logic Approach to Bio-Molecular Event ExtractionSebastian Riedel?
?Hong-Woo Chun?
?Toshihisa Takagi?
?Jun'ichi Tsujii???
?Database Center for Life Science, Research Organization of Information and System, Japan?Department of Computer Science, University of Tokyo, Japan?Department of Computational Biology, University of Tokyo, Japan?School of Informatics, University of Manchester, UK?National Centre for Text Mining, UK{sebastian,chun,takagi}@dbcls.rois.ac.jptsujii@is.s.u-tokyo.ac.jpAbstractIn this paper we describe our entry to theBioNLP 2009 Shared Task regarding bio-molecular event extraction.
Our work canbe described by three design decisions: (1)instead of building a pipeline using localclassifier technology, we design and learna joint probabilistic model over events ina sentence; (2) instead of developing spe-cific inference and learning algorithms forour joint model, we apply Markov Logic, ageneral purpose Statistical Relation Learn-ing language, for this task; (3) we representevents as relational structures over the to-kens of a sentence, as opposed to structuresthat explicitly mention abstract event en-tities.
Our results are competitive: weachieve the 4th best scores for task 1 (inclose range to the 3rd place) and the bestresults for task 2 with a 13 percent pointmargin.1 IntroductionThe continuing rapid development of the Inter-net makes it very easy to quickly access largeamounts of data online.
However, it is impossi-ble for a single human to read and comprehend asignificant fraction of the available information.Genomics is not an exception, with databasessuch as MEDLINE storing a vast amount ofbiomedical knowledge.A possible way to overcome this is informa-tion extraction (IE) based on natural languageprocessing (NLP) techniques.
One specific IEsub-task concerns the extraction of molecularevents that are mentioned in biomedical liter-ature.
In order to drive forward research in thisdomain, the BioNLP Shared task 2009 (Kimet al, 2009) concerned the extraction of suchevents from text.
In the course of the shared taskthe organizers provided a training/developmentset of abstracts for biomedical papers, annotatedwith the mentioned events.
Participants wererequired to use this data in order to engineera event predictor which was then evaluated onunseen test data.The shared task covered three sub-tasks.
Thefirst task concerned the extraction of eventsalong with their clue words and their main argu-ments.
Figure 1 shows a typical example.
Thesecond task was an extension of the first one,requiring participants to not only predict thecore arguments of each event, but also the cel-lular locations the event is associated with inthe text.
The events in this task were simi-lar in nature to those in figure 1, but wouldalso contain arguments that are neither eventsnor proteins but cellular location terms.
In con-trast to the protein terms, cellular location termswere not given as input and had to be predicted,too.
Finally, for task 3 participants were askedto extract negations and speculations regardingevents.
However, in our work we only tackledTask 1 and Task 2, and hence we omit furtherdetails on Task 3 for brevity.Our approach to biomedical event extractionis inspired by recent work on Semantic Role La-belling (Meza-Ruiz and Riedel, 2009; Riedel andMeza-Ruiz, 2008) and can be characterized bythree decisions that we will illustrate in the fol-lowing.
First, we do not build a pipelined sys-tem that first predicts event clues and cellularlocations, and then relations between these; in-41stead, we design and learn a joint discrimina-tive model of the complete event structure fora given sentence.
This allows us to incorporateglobal correlations between decisions in a prin-cipled fashion.
For example, we know that anyevent that has arguments which itself are events(such as the positive regulation event in figure1) has to be a regulation event.
This means thatwhen we make the decision about the type ofan event (e.g., in the first step of a classifica-tion pipeline) independently from the decisionsabout its arguments and their type, we run therisk of violating this constraint.
However, in ajoint model this can be easily avoided.Our second design choice is the following: in-stead of designing and implementing specific in-ference and training methods for our structuredmodel, we useMarkov Logic, a Statistical Re-lational Learning language, and define our globalmodel declaratively.
This simplified the imple-mentation of our system significantly, and al-lowed us to construct a very competitive eventextractor in three person-months.
For example,the above observation is captured by the simpleformula:eventType (e, t) ?
role (e, a, r) ?
event (a) ?regType (t) (1)Finally, we represent event structures as rela-tional structures over tokens of a sentence,as opposed to structures that explicitly mentionabstract event entities (compare figure 1 and 2).The reason is as follows.
Markov Logic, for now,is tailored to link prediction problems where wemay make inferences about the existence of rela-tions between given entities.
However, when theidentity and number of objects of our domain isunknown, things become more complicated.
Bymapping to relational structure over groundedtext, we also show a direct connection to recentformulations of Semantic Role Labelling whichmay be helpful in the future.The remainder of this paper is organized asfollows: we will first present the preprocessingsteps we perform (section 2), then the conversionto a link prediction problem (section 3).
Subse-quently, we will describe Markov Logic (section4) and our Markov Logic Network for event ex-!
"# !
"$ !
"%&'()*+,*-*+,*-*+,*-*1 2 3 4 5 6 7 8 9Figure 1: Example gold annotation for task 1 of theshared task.1 2 3 4 5 6 7 8 9Figure 2: Link Prediction version of the events infigure 1.traction (section 5).
Finally, we present our re-sults (in section 6) and conclude (section 7).2 PreprocessingThe original data format provided by the sharedtask organizers consists of (a) a collectionbiomedical abstracts, and (b) standoff anno-tation that describes the proteins, events andsites mentioned in these abstracts.
The organiz-ers also provided a set of dependency and con-stituent parses for the abstracts.
Note that theseparses are based on a different tokenisation of thetext in the abstracts.In our first preprocessing step we convert thestandoff annotation in the original data to stand-off annotation for the tokenisation used in theparses.
This allows us to formulate our proba-bilistic model in terms of one consistent tokeni-sation (and be able to speak of token instead ofcharacter offsets).
Then we we retokenise theinput text (for the parses) according the proteinboundaries that were given in the shared taskdata (in order to split strings such as p50/p55).Finally, we use this tokenisation to once againadapt the stand-off annotation (using the previ-ously adapted version as input).3 Link Prediction RepresentationAs we have mentioned earlier, before we learnand apply our Statistical Relational Model, weconvert the task to link prediction over a se-quence of tokens.
In the following we will presentthis transformation in detail.42To simplify our later presentation we will firstintroduce a formal representation of the events,proteins and locations mentioned in a sentence.Let us simply identify both proteins and cellularlocation entities with their token position in thesentence.
Furthermore, let us describe an event eas a tuple (i, t, A) where i is the token position ofthe clue word of e and t is the event type of e; Ais a set of labelled arguments (a, r) where each ais either a protein, location or event, and r is therole a plays with respect to e. We will identifythe set of all proteins, locations and events for asentence with P , L and E, respectively.For example, in figure 1 we have P ={4, 7} , L = ?
and E = {e13, e14, e15} withe15 = (5, gene_expr, {(4,Theme)})e14 = (2, pos_reg, {(e15,Theme) , (7,Cause)})e13 = (1, neg_reg, {(e14,Theme)})3.1 Events to LinksAs we mentioned in section 1, Markov Logic (orits interpreters) are not yet able to deal withcases where the number and identity of entities isunknown, while relations/links between knownobjects can be readily modelled.
In the follow-ing we will therefore present a mapping of anevent structure E to a labelled relation over to-kens.
Essentially, we project E to a pair (L,C)where L is a set of labelled token-to-token links(i, j, r), and C is a set of labelled event clues(i, t).
Note that this mapping has another ben-efit: it creates a predicate-argument structurevery similar to most recent formulations of Se-mantic Role Labelling (Surdeanu et al, 2008).Hence it may be possible to re-use or adapt thesuccessful approaches in SRL in order to improvebio-molecular event extraction.
Since our ap-proach is inspired by the Markov Logic role la-beller in (Riedel and Meza-Ruiz, 2008), this workcan be seen as an attempt in this direction.For a sentence with given P , L and E, algo-rithm 1 presents our mapping from E to (L,C).For brevity we omit a more detailed descriptionof the algorithm.
Note that for our running ex-ample eventsToLinks would returnC = {(1, neg_reg) , (2, pos_reg) , (5, gene_expr)}(2)Algorithm 1 Event to link conversion/* returns all clues C and links L givenby the events in E */1 function eventsToLinks (E):2 C ?
?, L?
?3 for each event (i, t, A) ?
E do4 C ?
C?
{(i, t)}5 for each argument (a, r) ?
A do6 if a is an event (i?, t?, A?)
do7 L?
L?
{(i, i?, r)} with a = (i?, t?, A?
)8 else9 L?
L ?
{(i, a, r)}10 return (C,L)andL = {(1, 2,Theme) , (2, 5,Theme) ,(2, 7,Cause) , (5, 4,Theme)} .
(3)3.2 Links to EventsThe link-based representation allows us to sim-plify the design of our Markov Logic Network.However, after we applied the MLN to our data,we still need to transform this representationback to an event structure (in order to use orevaluate it).
This mapping is presented in al-gorithm 2 and discussed in the following.
Notethat we expect the relational structure L to becycle free.
We again omit a detailed discussion ofthis algorithm.
However, one thing to notice isthe special treatment we give to binding events.Roughly speaking, for the binding event clue cwe create an event with all arguments of c inL.
For a non-binding event clue c we first col-lect all roles for c, and then create one event perassignment of argument tokens to these roles.If we would re-convert C and L from equation2 and 3, respectively, we could return to our orig-inal event structure in figure 1.
However, con-verting back and forth is not loss-free in general.For example, if we have a non-binding event inthe original E set with two arguments A and Bwith the same role Theme, the round-trip con-version would generate two events: one with Aas Theme and one with B as Theme.4 Markov LogicMarkov Logic (Richardson and Domingos, 2006)is a Statistical Relational Learning language43Algorithm 2 link to event conversion.
Assume:no cycles; tokens can only be one of protein, siteor event; binding events have only protein argu-ments./* returns all events E specifiedby clues C and links L */1 function linksToEvents (C,L)2 return S(i,t)?C resolve (i, C, L)/* returns all events forthe given token i */1 function resolve (i, C, L)2 if no t with (i, t) ?
C return {i}3 t?
type (i, C)4 if t = binding return {(i, t, A)} with5 A = {(a, r) | (i, a, r) ?
L}6 Ri ?
{r?|?a : (i, a, r) ?
L}7 for each role r ?
Ri do8 Ar ?
{a| (i, a, r) ?
L}9 Br ?Sa?Ar {(resolve (a) , r)}10 return SA?expand(Br1 ,...,Brn ) {(i, t, A)}/* returns all possible argumentsets for Br1 , .
.
.
, Brn */1 function expand (Br1 , .
.
.
, Brn )2 if n = 1 return Brn3 returnSa?Br1SA?expand(Br2 ,...,Brn ) {(a, r1)} ?Abased on First Order Logic and Markov Net-works.
It can be seen as a formalism that ex-tends First Order Logic to allow formulae thatcan be violated with some penalty.
From an al-ternative point of view, it is an expressive tem-plate language that uses First Order Logic for-mulae to instantiate Markov Networks of repet-itive structure.Let us introduce Markov Logic by consideringthe event extraction task (as relational structureover tokens as generated by algorithm 1).
InMarkov Logic we can model this task by firstintroducing a set of logical predicates such aseventType(Token,Type), role(Token,Token,Role)and word(Token,Word).
Then we specify a set ofweighted first order formulae that define a distri-bution over sets of ground atoms of these pred-icates (or so-called possible worlds).
Note thatwe will refer predicates such as word as observedbecause they are known in advance.
In contrast,role is hidden because we need to infer its groundatoms at test time.Ideally, the distribution we define with theseweighted formulae assigns high probability topossible worlds where events are correctly iden-tified and a low probability to worlds where thisis not the case.
For example, in our running ex-ample a suitable set of weighted formulae wouldassign a higher probability to the world{word (1, prevented) , eventType (1, neg_reg) ,role(1, 2,Theme), event(2), .
.
.
}than to the world{word (1, prevented) , eventType (1, binding) ,role(1, 2,Theme), event(2), .
.
.
}In Markov Logic a set of weighted first order for-mulae is called a Markov Logic Network (MLN).Formally speaking, an MLN M is a set of pairs(?,w) where ?
is a first order formula and w areal weigh t. M assigns the probabilityp (y) = 1Z exp??
?
(?,w)?Mw?c?C?f?c (y)??
(4)to the possible world y.
Here C?
is the set of allpossible bindings of the free variables in ?
withthe constants of our domain.
f?c is a featurefunction that returns 1 if in the possible world ythe ground formula we get by replacing the freevariables in ?
by the constants in the bindingc is true and 0 otherwise.
Z is a normalisationconstant.4.1 Inference and LearningAssuming that we have an MLN, a set of weightsand a given sentence, we need to predict thechoice of event clues and roles with maximala posteriori probability (MAP).
To this endwe apply a method that is both exact and ef-ficient: Cutting Plane Inference Riedel (2008,CPI) with Integer Linear Programming (ILP) asbase solver.In order to learn the weights of the MLNwe use the 1-best MIRA Crammer and Singer(2003) Online Learning method.
As MAP infer-ence method that is applied in the inner loop ofthe online learner we apply CPI, again with ILPas base solver.
The loss function for MIRA is a44weighted sum FP +?FN where FP is the num-ber of false positives, FN the number of falsenegatives and ?
= 0.01.5 Markov Logic Network for EventExtractionWe define four hidden predicates our task:event(i) indicates that there is an event withclue word i; eventType(i,t) denotes that at tokeni there is an event with type t; site(i) denotes acellular location mentioned at token i; role(i,j,r)indicates that token i has the argument j withrole r. In other words, the four hidden predicatesrepresent the set of sites L (via site), the set ofevent clues C (via event and eventType) and theset of links L (via role) presented in section 3.There are numerous observed predicates weuse.
Firstly, the provided information aboutprotein mentions is captured by the predicateprotein(i), indicating there is a protein mentionending at token i.
We also describe event typesand roles in more detail: regType( t) holds foran event type t iff it is a regulation event type;task1Role(r) and task2Role(r) hold for a role rif is a role of task 1 (Theme, Cause) or task 2(Site, CSite, etc.
).Furthermore, we use predicates that de-scribe properties of tokens (such as the wordor stem of a token) and token pairs (suchas the dependency between two tokens); thisset is presented in table 1.
Here the pathand pathNL predicates may need some fur-ther explanation.
When path(i,j,p,parser) istrue, there must be a labelled dependencypath p between i and j according to theparser parser.
For example, in figure 1 wewill observe path(1,5,dobj?prep_of?,mcclosky-charniak).
pathNL just omits the depen-dency labels, leading to path(1,5,?
?,mcclosky-charniak) for the same example.We use two parses per sentence: the outputsof a self-trained reranking parser Charniak andJohnson (2005); McClosky and Charniak (2008)and a CCG parser (Clark and Curran, 2007),provided as part of the shared task dataset.
Asdictionaries we use a collection of cellular lo-cation terms taken from the Genia event cor-pus (Kim et al, 2008), a small handpicked set ofevent triggers and a list of English stop words.Predicate Descriptionword(i,w) Token i has word w.stem(i,s) i has (Porter) stem s.pos(i,p) i has POS tag p.hyphen(i,w) i has word w after last hyphen.hyphenStem(i,s) i has stem s after last hyphen.dict(i,d) i appears in dictionary d.genia(i,p) i is event clue in the Geniacorpus with precision p.dep(i,j,d,parser) i is head of token j withdependency d according toparser parser.path(i,j,p,parser) Labelled Dependency pathaccording to parser parserbetween tokens i and j is p.pathNL(i,j,p,parser) Unlabelled dependency pathaccording to parser p betweentokens i and j is path.Table 1: Observable predicates for token and tokenpair properties.5.1 Local FormulaeA formula is local if its groundings relate anynumber of observed ground atoms to exactly onehidden ground atom.
For example, the ground-ingdep (1, 2, dobj, ccg) ?
word (1, prevented) ?eventType (2, pos_reg) (5)of the local formuladep(h, i, d, parser) ?
word (h,+w) ?eventType(i,+t) (6)connects a single hidden eventType ground atomwith an observed word and dep atom.
Note thatthe + prefix for variables indicates that there isa different weight for each possible pair of wordand event type (w, t).5.1.1 Local Entity FormulaeThe local formulae for the hidden event/1predicate can be summarized as follows.
First,we add a event (i) formula that postulates theexistence of an event for each token.
The weightof this formulae serves as a general bias for oragainst the existence of events.45Next, we add one formulaT (i,+t) ?
event (i) (7)for each simple token property predicate T intable 1 (those in the first section of the table).For example, when we plug in word for T we geta formula that encourages or discourages the ex-istence of an event token based on the word formof the current token: word (i,+t) ?
event (i).We also add the formulagenia (i, p) ?
event (i) (8)and multiply the feature-weight product for eachof its groundings with the precision p. This iscorresponds to so-called real-valued feature func-tions, and allows us to incorporate probabili-ties and other numeric quantities in a principledfashion.Finally, we add a version of formula 6 wherewe replace eventType(i,t) with event(i).For the cellular location site predicate weuse exactly the same set of formulae but re-place every occurrence of event(i) with site(i).This demonstrates the ease with which we couldtackle task 2: apart from a small set of globalformulae we introduce later, we did not have todo more than copy one file (the event model file)and perform a search-and-replace.
Likewise, inthe case of the eventType predicate we simplyreplace event(i) with eventType(i,+t).5.1.2 Local Link FormulaeThe local formulae for the role/3 predicateare different in nature because they assess twotokens and their relation.
However, the first for-mula does look familiar: role (i, j,+r).
This for-mula captures a (role-dependent) bias for the ex-istence of a role between any two tokens.The next formula we add isdict (i,+di) ?
dict (j,+dj) ?
role (i, j,+r) (9)and assesses each combination of dictionariesthat the event and argument token are part of.Furthermore, we add the formulapath (i, j,+p,+parser) ?
role (i, j,+r) (10)that relates the dependency path between twotokens i and j with the role that j plays withrespect to i.
We also add an unlabelled versionof this formula (using pathNL instead of path).Finally, we add a formulaP (i, j,+p,+parser) ?
T (i,+t) ?role (i, j,+r) (11)for each P in {path,pathNL} and T in{word,stem,pos,dict,protein}.
Note that forT=protein we replace T (i,+t) with T (i).5.2 Global FormulaeGlobal formulae relate two or more hiddenground atoms.
For example, the formula inequation 1 is global.
While local formulae can beused in any conventional classifier (in the formof feature functions conditioned only on the in-put data) this does not hold for global ones.We could enforce global constraints such as theformula in equation 1 by building up structureincrementally (e.g.
start with one classifier forevents and sites, and then predict roles betweenevents and arguments with another).
However,this does not solve the typical chicken-and-eggproblem: evidence for possible arguments couldhelp us to predict the existence of event clues,and evidence for events help us to predict argu-ments.
By contrast, global formulae can capturethis type of correlation very naturally.Table 2 shows the global formulae we use.
Wedivide them into three parts.
The first set of for-mulae (CORE) ensures that event and eventTypeatoms are consistent.
In all our experiments wewill always include all CORE formulae; withoutthem we might return meaningless solutions thathave events with no event types, or types with-out events.The second set of formulae (VALID) consistof CORE and formulae that ensure that the linkstructure represents a valid set of events.
Forexample, this includes formula 12 that enforceseach event to have at least one theme.Finally, FULL includes VALID and two con-straints that are not strictly necessary to enforcevalid event structures.
However, they do help usto improve performance.
Formula 14 forbids atoken to be argument of more than one event.
Infact, this formula does not hold all the time, but46# Formula Description1 event (i)?
?t.eventType (i, t) If there is an event there should be an event type.2 eventType (i, t)?
event (i) If there is an event type there should be an event.3 eventType (i, t) ?
t 6= o?
?eventType (i, o) There cannot be more than one event type per token.4 ?site (i) ?
?event (i) A token cannot be both be event and site.5 role (i, j, r)?
event (i) If j plays the role r for i then i has to be an event.6 role (i, j, r1) ?
r1 6= r2 ?
?role (i, j, r2) There cannot be more than one role per argument.7 eventType (e, t) ?
role (e, a, r) ?
event (a)?
regType (t) Only reg.
type events can have event arguments.9 role (i, j, r) ?
taskOne (r)?
event (j) ?
protein (j) For task 1 roles arguments must be proteins or events10 role (i, j, r) ?
taskTwo (r)?
site (j) Task 2 arguments must be cellular locations (site).11 site (j)?
?i, r.role (i, j, r) ?
taskTwo (r) Sites are always associated with an event.12 event (i)?
?j.role (i, j,Theme) Every events need a theme.13 eventType (i, t) ?
?allowed (t, r)?
?role (i, j, r) Certain events may not have certain roles.14 role (i, j, r1) ?
k 6= i?
?role (k, j, r2) A token cannot be argument of more than one event.15 j < k ?
i < j ?
role (i, j, r1)?
?role (i, k, r2) No inside outside chains.Table 2: All three sets of global formulae used: CORE (1-3), VALID (1-13), FULL (1-15).by adding it we could improve performance.
For-mula 15 is our answer to a type of event chainthat earlier models would tend to produce.Note that all formulae but formula 15 are de-terministic.
This amounts to giving them a veryhigh/infinite weight in advance (and not learn-ing it during training).6 ResultsIn table 3 we can see our results for task 1 and2 of the shared task.
The measures we presenthere correspond to the approximate span, ap-proximate recursive match criterion that countsan event as correctly predicted if all argumentsare extracted and the event clue tokens approx-imately match the gold clue tokens.
For moredetails on this metric we refer the reader to theshared task overview paper.To put our results into context: for task 1 wereached the 4th place among 20 participants, arein close range to place 2 and 3, and significantlyoutperform the 5th best entry.
Moreover, wehad highest scoring scores for task 2 with a 13%margin to the runner-up.
Using both trainingand development set for training (as allowed bythe task organisers), our task 1 score rises to45.1, slightly higher than the score of the currentthird.In terms of accuracy across different eventtypes our model performs worse for binding, reg-ulation type and transcription events.
Bindingevents are inherently harder to correctly extractbecause they often have multiple core argumentswhile other non-regulation events have only one;just missing one of the binding arguments willlead to an event that is considered as error withno partial credit given.
If we would give creditfor binding with partially correct arguments ourF-score for binding events would rise to 49.8.One reason why regulation events are difficultto extract is the fact that they often have argu-ments which themselves are events, too.
In thiscase our recall is bound by the recall for argu-ment events because we can never find a regu-lation event if we cannot predict the argumentevent.
Note that we are still unsure about tran-scription events, in particular because we ob-serve 49% F-score for such events in the devel-opment set.How does our model benefit from the globalformulae we describe in section 5 (and whichrepresent one of the core benefits of a MarkovLogic approach)?
To evaluate this we compareour FULL model with CORE and VALID fromtable 2.
Note that because the evaluation inter-face rejects invalid event structures, we cannotuse the evaluation metrics of the shared task.Instead we use table 4 to present an evaluationin terms of ground atom F1-score for the hiddenpredicates of our model.
This amounts to a per-47Task 1 Task 2R P F R P FLoc 37.9 88.0 53.0 32.8 76.0 45.8Bind 23.1 48.2 31.2 22.4 47.0 30.3Expr 63.0 75.1 68.5 63.0 75.1 68.5Trans 16.8 29.9 21.5 16.8 29.9 21.5Cata 64.3 81.8 72.0 64.3 81.8 72.0Phos 78.5 77.4 77.9 69.1 70.1 69.6Total 48.3 68.9 56.8 46.8 67.0 55.1Reg 23.7 40.8 30.0 22.3 38.5 28.2Pos 26.8 42.8 32.9 26.7 42.3 32.7Neg 27.2 40.2 32.4 26.1 38.6 31.2Total 26.3 41.8 32.3 25.8 40.8 31.6Total 36.9 55.6 44.4 35.9 54.1 43.1Table 3: (R)ecall, (P)recision, and (F)-Score for task1 and 2 in terms of event types.role, per-site and per-event-clue evaluation.
Thenumbers here will not directly correspond to ac-tual scores, but generally we can assume that ifwe do better in our metrics, we will likely havebetter scores.In table 4 we notice that ensuring consistencybetween all predicates has a significant impacton the performance across the board (see theVALID results).
Furthermore, when adding ex-tra formulae that are not strictly necessary forconsistency, but which encourage more likelyevent structure, we again see significant improve-ments (see FULL results).
Interestingly, al-though the extra formulae only directly considerrole atoms, they also have a significant impacton event and particularly site extraction perfor-mance.
This reflects how in a joint model deci-sions which would appear in the end of a tradi-tional pipeline (e.g., extracting roles for events)can help steps that would appear in the begin-ning (extracting events and sites).For the about 7500 sentences in the trainingset we need about 3 hours on a MacBook Prowith 2.8Ghz and 4Gb RAM to learn the weightsof our MLN.
This allowed us to try different setsof formulae in relatively short time.7 ConclusionOur approach the BioNLP Shared Task 2009 canbe characterized by three decisions: (a) jointlyCORE VALID FULLeventType 52.8 63.2 64.3role 44.0 53.5 55.7site 42.0 46.0 51.5Total 50.7 60.1 61.9Table 4: Ground atom F-scores for global formulae.modelling the complete event structure for agiven sentence; (b) using Markov Logic as gen-eral purpose-framework in order to implementour joint model; (c) framing the problem as alink prediction problem between tokens of a sen-tence.Our results are competitive: we reach the 4thplace in task 1 and the 1st place for task 2 (witha 13% margin).
Furthermore, the declarative na-ture of Markov Logic helped us to achieve theseresults with a moderate amount of engineering.In particular, we were able to tackle task 2 bycopying the local formulae for event prediction,and adding three global formulae (4, 10 and 11in table 2).
Finally, our system was fast to train(3 hours) .
This greatly simplified the search forgood sets of formulae.We have also shown that global formulae sig-nificantly improve performance in terms of eventclue, site and argument prediction.
While a sim-ilar effect may be possible with reranking archi-tectures, we believe that in terms of implemen-tation efforts our approach is at least as simple.In fact, our main effort lied in the conversion tolink prediction, not in learning or inference.
Infuture work we will therefore investigate meansto extend Markov Logic (interpreter) in order todirectly model event structure.AcknowledgementsWe thank Dr. Chisato Yamasaki and Dr.Tadashi Imanishi, BIRC, AIST, for their help.This work is supported by the IntegratedDatabase Project (MEXT, Japan), the Grant-in-Aid for Specially Promoted Research (MEXT,Japan) and the Genome Network Project(MEXT, Japan).48ReferencesCharniak, Eugene and Mark Johnson.
2005.Coarse-to-fine n-best parsing and maxent dis-criminative reranking.
In Proceedings of the43rd Annual Meeting of the Association forComputational Linguistics (ACL' 05).
pages173180.Clark, Stephen and James R. Curran.
2007.Wide-coverage efficient statistical parsingwith ccg and log-linear models.
Comput.
Lin-guist.
33(4):493552.Crammer, Koby and Yoram Singer.
2003.
Ultra-conservative online algorithms for multiclassproblems.
Journal of Machine Learning Re-search 3:951991.Kim, Jin D., Tomoko Ohta, and Jun'ichi Tsujii.2008.
Corpus annotation for mining biomedi-cal events from literature.
BMC Bioinformat-ics 9(1).Kim, Jin-Dong, Tomoko Ohta, Sampo Pyysalo,Yoshinobu Kano, and Jun'ichi Tsujii.
2009.Overview of bionlp'09 shared task on event ex-traction.
In Proceedings of Natural LanguageProcessing in Biomedicine (BioNLP) NAACL2009 Workshop.
To appear.McClosky, David and Eugene Charniak.
2008.Self-training for biomedical parsing.
InProceedings of the 46rd Annual Meeting ofthe Association for Computational Linguistics(ACL' 08).Meza-Ruiz, Ivan and Sebastian Riedel.
2009.Jointly identifying predicates, arguments andsenses using markov logic.
In Joint HumanLanguage Technology Conference/AnnualMeeting of the North American Chapter ofthe Association for Computational Linguistics(HLT-NAACL '09).Richardson, Matt and Pedro Domingos.
2006.Markov logic networks.
Machine Learning62:107136.Riedel, Sebastian.
2008.
Improving the accuracyand efficiency of map inference for markovlogic.
In Proceedings of the 24th Annual Con-ference on Uncertainty in AI (UAI '08).Riedel, Sebastian and Ivan Meza-Ruiz.
2008.Collective semantic role labelling with markovlogic.
In Proceedings of the 12th Conferenceon Computational Natural Language Learning(CoNLL' 08).
pages 193197.Surdeanu, Mihai, Richard Johansson, AdamMeyers, Llu?s M?rquez, and Joakim Nivre.2008.
The CoNLL-2008 shared task on jointparsing of syntactic and semantic dependen-cies.
In Proceedings of the 12th Conferenceon Computational Natural Language Learning(CoNLL-2008).49
