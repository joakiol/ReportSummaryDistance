Concept Identif ication and Presentat ion in the Context  ofTechnical Text Summarizat ionHorac io  Sagg ion*and Guy  Lapa lmeDdpartement d' Informatique et Recherche Op~rationnelleUniversit~ de MontrealCP 6128, Succ Centre-VilleMontreal, Quebec, Canada, H3C 3J7Fax: +1-514-343-5834{sagg ion ,  lapalme}@iro,  umontrea l ,  caAbst rac tWe describe a method of text summarizationthat produces indicative-informative abstracts/for technical papers.
The abstracts are gener-ated by a process of conceptual identification,topic extraction and re-generation.
We havecarried out an evaluation to assess indicative-ness and text acceptability relying on humanjudgment.
The results o far indicate good per-formance in both tasks when compared withother summarization technologies.1 In t roduct ionWe have specified a method of text summa-rization which produces indicative-informativeabstracts for technical documents.
The methodwas designed to identify the "topics" of adocument and present them in an indicativeabstract.
Eventually, they can be elaborated in.specific ways.In Figure 1, we present an indicative abstractfor the document "Facilitating designer-.?
customer communication i the World WideWeb" (Internet Research: Electronic Net-working Applications and Policy, Vol 8, Issue5,1998) produced with our implementationof this method.
The abstract includes a listof topics which are terms appearing in theautomatic abstract (e.g.
WebShaman)  orobtained from the source document by theprocess of term expansion (e.g.
WWWtechnique obtained from technique).
It also* The first author is supported by Agence Canadiennede D~veloppement International (ACDI) and FundaciSnAntorchas (A-13671/1-47), Argentin a.
He was previ-ously supported by Ministerio de EducaciSn de la Naci6nde la Repfiblica Argentina (ResoluciSn 1041/96) and De-partamento de ComputaciSn, Facultad e Ciencias Exac-tas y Naturales, UBA, Argentina.includes term elaborations which can be usedto answer specific questions about the topicssuch as what  is topic?
how top ic  is used?who developed topic?
and what  are theadvantages of topic?.In this paper, we will describe how we dealtwith the problem of content selection andpresentation and how we have evaluated ourmethod of text summarization.2 Text  Summar izat ionThe process of producing a summary froma source text consists of the following steps:(i) the interpretation of the text; (ii) theextraction of the relevant information whichideally includes the "topics" of the source; (iii)the condensation of the extracted informationand construction of a summary representation;and (iv) the presentation of the summary rep-resentation to the reader in natural anguage.While some techniques exist for producingsummaries for domain independent texts(Luhn, 1958; Marcu, 1997) it seems thatdomain specific texts require domain specifictechniques (DeJong, 1982; Paice and Jones,1993).
In our case, we are dealing with techni-cal articles which are the result of the complexprocess of scientific inquiry that starts withthe.
identification of a knowledge problem andeventually culminates with the discovery ofan answer to it.
Even if authors of technicalarticles write about several concepts in theirarticles, not all of them are topics.
In order toaddress the issue of topic identification, contentselection and presentation, we have studiedalignments (manually produced) of sentencesfrom professional bstracts with sentences fromAbst ract  In t roduc ing  the Topics!
!Virtual prototyping is a technique which has been suggested for use in, for example, telecommuni-cation product development asa high-end technology to achieve a quick digital model that couldbe used in the same way as a real prototype.
Presents the design rationale of WebShaman, startingfrom the concept design perspective by introducing a set of requirements to support communicationvia a concept model between i dustrial designer and a customer.
In the article, the authors uggestthat virtual prototyping in collaborative use between designers i a potential technique to facilitatedesign and alleviate the problems created by geographical distance and complexities in the workbetween different parties.
The technique, was implemented in the VRP project, allows compo-nent level manipulation ofa virtual prototype in a WWW (World Wide Web) browser.
The userservices, the software architecture, and the techniques ofWebShaman were developed iterativelyduring the fieldwork in order to illustrate the ideas and the feasibility of the system.
The server isnot much different from the other servers constructed tosupport synchronous collaboration.Identif ied Topics: 3D mode l  - V IRP I  p ro jec t  - WWW - WW-vV techn ique  - WebShaman -CAD sys tem - conceptua l .mode l -  cus tomer  - ob jec t -o r iented  mode l -  p roduct  - p roductconcept  - p roduct  des ign  - requ i rement  - s imu la t ion  mode l  - smar t  v i r tua l  p ro to type- so f tware  component  - sys tem-  techn ique  - techno logy  - use  - v i r tua l  component -v i r tua l  p ro to type  - v i r tua l  p ro to type  sys tem-  v i r tua l  p ro to typ ingI n fo rmat ion  about  the  Top icsAn example of a conceptual model, a pen-shaped 'w i re less  user  in ter face  for a mobiletelephone.A v i r tua l  p ro to type  is a computer -based  s imulat ion  of a prototype or a subsystem with adegree of functional realism, comparable to that of a physical prototype.A computer system implementing the high-end aspects  o f  v i r tua l  prototyping has beendeve loped in the VRP project (VRP, 1998) at VTT Electronics, in Oulu, Finland.The two-and-a-half-year VIRPI pro jec t  cons is ts  o f  th ree  parts.Nowadays, CAD (computer -a ided  des ign)  sys tems are  used  as an aid in industrial, mechan-ical and electronics design for the specification and deve lopment  o f  a product .A v i r tua l  p ro to type  sys tem can  be  used  for concept testing in the early phase of productdevelopment.Figure h Indicative Abstract, Topics and Topic ElaborationIIiliHIiIIIsource documents.
One of the alignments ispresented in Table 1.
The first column containsthe information of the professional abstract.The second and third columns contain the infor-mation from the source document that matchesthe sentences of the professional bstract, andits location in the source document.
We haveproduced 100 of these tables containing atotal of 309 sentences of professional bstractsaligned with 568 sentences ofsource documents.These alignments allowed us to identify onone hand, concepts, relations and types ofinformation usually conveyed in abstracts; andon the other hand, valid transformations inthe source in order to produce a compact andcoherent ext.
The transformations includeverb transformation, concept deletion, conceptreformulation, structural deletion, parentheticaldeletion, clause deletion, acronym expansion,2Professional  Abst ractPresents a more efficientDistributed Breadth-FirstSearch algorithm for anasynchronous communicationnetwork.Source DocumentEfficient distributed breadth-first earch algo-rithm.In this paper we have presented a more effi-cient distributed algorithm which construct abreadth-first search tree in an asynchronouscommunication networkP /T-/TitleLst/-Presents a model and gives an First we present a model and give overview of lst/-overview of related research, related research.Analyzes the complexity of the algo- We analyse the complexity of our algorithm, lst/-rithm, and gives some examples of per- and give some examples of performance onformance on typical networks, typical networks.Table 1: LISA Abstract 1955 - Source Document: "Efficient distributed breadth-first search algo-rithm."
S.A.M.
Makki.
Computer Communications, 19(8) Jul 96, p628-36.abbreviation, merge and split.
In our corpus,89% of the sentences from the professionalabstracts included at least one transformation.Results of the corpus study are detailed in(Saggion and Lapalme, 1998) and (Saggion andLapalme, 2000).We have identified a total of 52 differenttypes of information (coming from the corpusand from technical articles) for technical textsummarization that we use to identify some ofthe main themes.
These types include: theexplicit topic of the document, the  situa-tion, the  ident i f icat ion of the  problem, the' identif ication of the  solution, the  researchgoal ,  the  explicit topic of a section, the?
authors '  deve lopment ,  he  inferences, thedescr ipt ion of a topical entity, the  def init ion?
of a topical entity, the  re levance of a topicalenthy, the  advantages,  etc.
Informationtypes are classified as indicative or informativedepending on the type of abstract they con-tribute to (i.e.
the  topic of a document isindicative while the  descr ipt ion of a topicalentity is informative).
Types of information areidentified in sentences of the source documentusing co-occurrence of concepts and relationsand specific linguistic patterns.
Technicalarticles from different domains refer to specificconcepts and relations (diseases and treatmentsin Medicine, atoms and chemical reactionsin Chemistry, and theorems and proofs inMathematics).
We have focused on conceptsand relations that are common across domainssuch as problem, solution, research need,experiment, relevance, researchers~ etc.3 Text  In terpretat ionOur approach to text summarization is basedon a superficial analysis of the source docu-ment and on the implementation f some textre-generation techniques such as merging of top-ical information, re-expression of concepts andacronym expansion.
The article (plain textin English without mark-up) is segmented inmain units (title, author information, authorabstract, keywords, main sections and refer-ences) using typographic information and somekeywords.
Each unit is passed through a bi-pos statistical tagger.
In each unit, the sys-tem identifies titles, sentences and paragraphs,and then, sentences are interpreted using finitestate transducers identifying and packing lin-guistic constructions and domain specific con-structions.
Following that, a conceptual dictio-nary that relates lexical items to domain con-cepts and relations is used to associate seman-tic tags to the different structural elements inthe sentence.
Subsequently, terms (canonicalform of noun groups), their associated semantic(head of the noun group) and theirs positionsare extracted from each sentence and stored inan AVL tree (te~ t ree)  along with their fre-quency.
A conceptual  index is created whichspecifies to which particular type of informa-tion each sentence could contribute.
Finally,terms and words are extracted from titles and3stored in a list (the top ica l  s t ructure)  andacronyms and their expansions are recorded.3.1 Content  Select ionIn order to represent types of information we usetemplates.
In Table 2, we present he Topicof the  Document ,  Topic of the  Sect ionand Signal ing In fo rmat ion  templates.
Alsopresented are some indicative and informativepatterns.
Indicative patterns contain variables,syntactic constructions, domain concepts andrelations.
Informative patterns also include onespecific position for the topic under considera-tion.
Each element of the pattern matches oneor more elements of the sentence (conceptual,syntactic and lexical elements match one ele-ment while variables match zero or more).3.1.1 Ind icat ivenessThe system considers entences ~hat were iden-tified as carrying indicative information (theirposition is found in the conceptual  index).Given a sentence?
S and a type of informationT the system verifies if the sentence matchessome of the patterns associated with type T.For each matched pattern, the system extractsinformation from the sentence and instantiatesa template of type T. For example, theContent slot of the prob lem ident i f icat iontemplate is instantiated with all the sentence?
:(avoiding references, structural elements andparenthetical expressions) while the What slot'of the topic of the  document  template isinstantiated with a parsed sentence fragment?
to the left or to the right of the make knownrelation depending on the attribute voice of theverb (active vs. passive).
All the instantiatedtemplates constitute the Indicative Data Base(IDB).The system matches the topical structurewith the topic candidate slots from the IDB.The system selects one template for each termin that structure: the one with the greatestweight (heuristics are applied if there are morethan one).
The selected templates constitutethe indicative content and the terms ap-pearing in the topic candidate slots and theirexpansions constitute the potential topicsof the document.
Expansions are obtainedlooking for terms in the term tree sharingthe semantic of some terms in the indicative4content.The ind icat ive  content  is sorted usingpositional information and the following con-ceptual order: s i tuat ion ,  need for research,problem,  solut ion, ent i ty  in t roduct ion ,topical  in format ion,  goal of concep-tua l  ent i ty,  focus of conceptua l  ent i ty,methodo log ica l  aspects,  inferences ands t ruc tura l  in format ion.
Templates of thesame type are grouped together if they ap-peared in sequence in the list.
The typesconsidered in this process are: the  topic,sect ion topic and s t ruc tura l  in format ion.The sorted templates constitute the text  plan.3.1.2 InformativenessFor each potential: topic and sentence whereit appears (that information is found on theterm tree) the system verifies if the sentencecontains an informative marker (conceptualindex) and satisfies an informative pattern.
Ifso, the potential topic is considered a topicof the document and a link will be created be-tween the topic and the sentence which will bepart of the informative abstract.4 Content  P resentat ionOur approach to text generation is basedon the regularities observed in the corpusof professional abstracts and so, it does notimplement a general theory of text generationby computers.
Each element in the text  p lanis used to produce a sentence.
The structure ofthe sentence depends on the type of template.The information about the s i tuat ion,  theproblem, the need for research,  etc.
isreported as in the original document with fewmodifications (concept re-expression).
Insteadother types require additional re-generation:for the topic of the  document  template thegeneration procedure is as follows: (i) the verbform for the predicate in the Pred icate  slotis generated in the present  tense (topicalinformation is always reported in presenttense), 3rd person of s ingu lar  in ac t ivevoice at the beginning of the sentence;(ii) the parsed sentence fragment from the N'hatslot is generated in the middle of the sentence(so the appropriate case for the first elementIIIiITopic of the Documenttopic Type:Id:Predicate:Where:Who:What:Position:Topic candidates:Weight:integer identifierinstance of make knowninstance of {research paper, study, work, research}instance of{research paper, author,  study, work, research,  none}parsed sentence fragmentsection and sentence idlist of terms from the What fillernumberTopic o f  Sect ionType:Id:Predicate:Section:Argument:Position:Topic candidates:Weight:sec_descinteger identifierinstance of make knowninstance of paper componentparsed sentence fragmentsection and sentence idlist of terms from the Argument fillernumberType:Id:Predicate :Structural :Argument :Po s it ion:Topic candidates :Weight :structure-2integer identifierinstance of show graphical materialinstance of structural elementparsed sentence fragmentsection and sentence idlist of terms from the Argument fillernumberSignaling(indicative)Topic  (indica-tive)SKIP1 + s t ructura l  + SKIP2 + show graphica l ly  + ARGUMENT + eosnoun group + author + make known + prepos i t ion + research paper +DESCRIPT ION + eosAuthor 's  Goal SKIP1 + goal of author + def ine + GOAL + eos(indicative)Goal of SKIP  + goal + preposi t ion + TOPIC + def ine + GOAL + eosTOPIC (in-formative)Definition SKIP  + TOPIC + def ine + noun groupof TOPIC(informative)Table 2: Templates and Patterns.has, to be generated); and (iii) a full stop isgenerated.
This schema of generation avoidsthe formulation of expressions like "X will bepresented", "X have been presented" or "Wehave presented here X" which are usually foundon source documents but which are awkwardin the context of the abstract ext-type.
Notethat each type of information prescribes itsown schema of generation.Some elements in the parsed sentence frag-ment require re-expression while others arepresented in "the words of the author."
If thesystem detects an acronym without expansionin the string it would expand it and record thatsituation in order to avoid repetitions.
Notethat as the templates contain parsed sentencefragments, the correct punctuation has tobe re-generated.
For merged templates thegenerator implements the following patternsof production: if n adjacent emplates are tobe presented using the same predicate, onlyone verb will be generated whose argument isthe conjunction of the arguments from the ntemplates.
If the sequence of templates haveno common predicate, the information willbe presented as a conjunction of propositions.These patterns of sentence production areexemplified in Table 3.The elaboration of the topics is presentedupon reader's demand.
The information is pre-sented in the order of the original text.
The in-formative abstract is the information obtainedby this process as it is shown in Figure 1.5 L imi ta t ions  o f  the  ApproachOur approach is based on the empirical ex-amination of abstracts published by secondservices.
In our first study, we examined 100abstracts and source documents in order todeduce a conceptual and linguistic model forthe task of summarization of technical articles.Then, we expanded the corpus with 100 moreitems in order to validate the model.
Webelieve that the concepts, relations and types.of information identified account for interesting,phenomena appearing in the corpus and con-stitute a sound basis for text summarization.
'Nevertheless, we have identified only a few?
linguistic expressions used in order to express-particular elements of the conceptual model(241 domain verbs, 163 domain nouns, 129adj.ectives , 174 indicative patterns, 87 informa-tive patterns).
This is because we are mainlyconcerned with the development of a generalmethod of automatic abstracting and the taskof constructing such linguistic resources i timeconsuming as recent work have shown (Minelet al, 2000).The implementation f our method relies?
onState-of-the-art techniques in natural anguageprocessing including noun and verb group iden-tification and conceptual tagging.
The inter-preter relies on the output produced by a shal-low text segmenter and on a statistical POS-tagger.
Our prototype only analyses entencesfor the specific purpose of text summarizationand implements some patterns of generation ob-served in the corpus.
Additional analysis couldbe done on the obtained representation to pro-duce better esults.6 Re la ted  Work(Paice and Jones, 1993) have already addressedthe issue of content identification and expressionin technical summarization using templates, butwhile they produced indicative abstracts for aspecific domain, we are producing domain inde-pendent indicative-informative abstracts.
Beingdesigned for one specific domain, their abstractsare fixed in structure while our abstracts aredynamically constructed.
Radev and McKeown(1998) also used instantiated templates, but inorder to produce summaries of multiple docu-ments in one specific domain.
They focus onthe generation of the text while we are address-ing the overall process of automatic abstracting.Our concern regarding the presentation of theinformation is now being addressed by other re-searchers as well (Jing and McKeown, 1999).7 Eva luat ing  Content  and  Qua l i ty  inText  Summar izat ionAbstracts are texts used in tasks such as assess-ing the content of the document and decidingif the source is worth reading.
If text summa-rization systems are designed to fulfill those re-quirements, the generated texts have to be eval-uated according to their intended function andits quality.
The quality and success of humanproduced abstracts have already been addressedin the literature (Grant, 1992; Gibson, 1993) us-ing linguistic criteria such as cohesion and co-herence, thematic structure, sentence structureand lexical density.
But in automatic text sum-marization, this is an emergent research topic.
(Minel et al, 1997) have proposed two meth-ods of evaluation addressing the content of theabstract and its quality.
For content evalua-tion, they asked human judges to classify sum-maries in broad categories and also verify ifthe key ideas of source documents are appropri-ately expressed in the Summaries.
For text qual-ity, they asked human judges to identify prob-lems such as dangling anaphora nd broken tex-tual segments and also to make subjective judg-ments about readability.
In the context of theTIPSTER program, (Firmin and Chrzanowski,6IIIiIIIIIIRe-Generated Sentences Sentences from Source DocumentsIllustrates the principle of virtual prototyping andthe different echniques and models required.Presents the mechanical and electronic design o\]the robot harvester including all subsystems,namely, fruit localisation module, harvesting armand gripper-cutter as well as the integration ofsubsystems and the specific mechanical design ofthe picking arm addressing the reduction ofundesirable dynamic effects during high velocityoperation.Shows configuration of the robotic fruit harvesterAgribot and schematic view of the detaching tool.PAWS (the programmable automated welding sys-tem) was designed to provide an automated meansof planning, controlling, and performing criticalwelding operations for improving productivity andquality.Describes HuDL (local autonomy) in greaterdetail; discusses ystem integration and the 1MA(the intelligent machine architecture); and alsogives an example implementation.Figure 1 Virtual prototyping models and techniquesillustrates the principle of virtual prototyping and thedifferent techniques and models required.After a brief introduction, we present the mechanicaland electronic design of the robot harvester includ-ing all subsystems, namely, fruit localisation module,harvesting arm and gripper-cutter aswell as the inte-gration of subsystems.Throughout this work, we present the specific mechan-ical design of the picking arm addressing the reductionof undesirable dynamic effects during high velocity op-eration.The final prototype consists of two jointed harvestingarms mounted on a human guided vehicle as shownschematically in Figure 1 Configuration ofthe robotic.
fruit' harvester Agribot.Schematic representation f the operations involved inthe detaching step can be seen in Figure 5 Schematicview of the detaching tool and operation.PAWS was designed to provide an automated means ofplanning, controlling, and performing critical weldingoperations for improving productivity and quality.Section 2 describes HuDL in greater detail and section3 discusses system integration and the IMA.An example implementation is given in section 4 andsection 5 contains the conclusions.Table 3: Re-Generated Sentences1999) and (Mani et al, 1998) also used a cat -.egorization task using TREC topics.
For textquality, they addressed subjective aspects uch?
as the length of the summary, its intelligibilityand its usefulness.
We have carried out an eval-?
uation of our summarization method in order toassess the function of the abstract and its textquality.7.1 Exper imentWe compared abstrac?s produced by ourmethod with abstracts produced by Mi-crosoft'97 Summarizer and with otherspublished with source documents (usually au-thor abstracts).
We have chosen Microsoft'97Summarizer because, even if it only producesextracts, it was the only summarizer availablein order to carry out this evaluation andbecause it has already been used in other eval-uations (Marcu, 1997; Barzilay and Elhadad,1997).In order to evaluate content, we presentedjudges with randomly selected abstracts andfive lists of keywords (content indicators).
Thejudges had to decide to which list of keywordsthe abstract belongs given that different listsshare some keywords and that they belongto the same technical domain.
Those.
listswere obtained from the journals where thesource documents were published.
The ideabehind this evaluation is to see if the abstractconvey the very essential content of the sourcedocument.In Order to evaluate the quality of the text, weasked the judges to provide an acceptabilityscore between 0-5 for the abstract (0 for un-acceptable and 5 for acceptable) based on thefollowing criteria taken from (Rowley, 1982)(they were only suggestions to the evaluatorsand were not enforced): good spelling andgrammar; clear indication of the topic of7the  source document; impersonal style; oneparagraph; conciseness; readable and under-standable; acronyms are presented along withtheir expansions; and other criteria that thejudge considered important as an experiencedreader of abstracts of technical documents.We told the judges that we would considerthe abstracts with scores above 2.5 as accept-able.
Some criteria are more important hanother, for example judges do not care aboutimpersonal style but care about readability.7.1.1 Mater ia lsSource  Documents :  we used twelve sourcedocuments from the journal Industrial Robotsfound on the Emerald Electronic Library (alltechnical articles).
The articles were down-loaded in plain text format.
These documentsare quite long texts with an average of 23Kcharacters (minimum of l lK  characters and amaximum of 41K characters).
They containan average of 3472 words (minimum of 1756words and a maximum of 6196 words excludingpunctuation), and an average of 154 sentences(with a minimum of 85 and a maximum of 288).Abstracts :  we produced twelve abstracts us-:ing our method and computed the compression,ratio in number of words, then we producedtwelve abstracts by Microsoft'97 Summarizer 1us ing  a compression rate at least as high asour (i.e.
if our method produced an abstractwith a compression rate of 3.3% of the source,we produced the Microsoft abstract with acompression rate of 4% of the source).
Weextracted the twelve abstracts and the twelvelists of keywords publ ished with the sourcedocuments.
We thus obtained 36 differentabstracts and twelve lists of keywords.Forms:  we produced 6 different forms each con-taining six different abstracts randomly 2 chosenout of twelve different documents (for a total of36 abstracts).
Each abstract was printed in a1We had to format the source document in order forthe Microsoft Summarizer to be able to recognize thestructure of the document (titles, sections, paragraphsand sentences).2Random numbers for this evaluation were producedusing software provided by SICSTus Prolog.different page.
It included 5 lists of keywords, afield to be completed with the quality score as-sociated to the abstract and a field to be f i l ledwith comments about the abstract.
One of thelists of keywords was the one published with thesource document, he other four were randomlyselected from the set of 11 remaining keywordlists, they were printed in the form in randomorder.
One page was also available to be com-pleted with comments about the task, in partic-ular with the time it took to the judges to com-plete the evaluation.
We produced three copiesof each form for a total of 18 forms.7.1.2 Sub jec tsWe had a total of 18 human judges or eval-uators.
Our evaluators were 18 students ofthe M.Sc.
program in Information Science atMcGill Graduate School of Library & Informa-tion Studies.
All of the subjects had good read-ing and comprehension skills in English.
Thisgroup was chosen because they have knowledgeabout what constitutes a good abstract andthey are educated to become professionals in In-formation Science.7.1.3 Eva luat ion  ProcedureThe evaluation was performed in one hour ses-sion at McGill University.
Each human judgereceived a form (so he/she evaluated six dif-ferent abstracts) and an instruction booklet.No other material was required for the evalu-ation (i.e.
dictionary).
We asked the judges toread carefully the abstract.
They had to decidewhich was the list of keywords that matchedthe abstract (they could chose more than oneor none at all) and then, they had to associatea numeric score to the abstract representing itsquality based on the given criteria.
This pro-cedure produced three different evaluations ofcontent and text quality for each of the 36 ab-stracts.
The overall evaluation was completedin a maximum of 40 minutes.7.2 Resu l tsFor each abstract, we computed the averagequality using the scores given by the judges.We considered that the abstract indicated theessential content of the source document if twoor more judges were able to chose the correctlist of keywords for the abstract.
The results forindividual articles and the average information8IIiigIIiIIIIIIiIIIIIIIIIiMicrosoft Abstract# Art.
Indic?
Quality1 yes 2.662 no 1.363 no 1.164 yes 3.005 no 2.166 yes 2.167 no 0.838 yes 2.339 yes 2.1610 yes 2.1611 yes 2.4012 no 1.16Average 70% 1.98\] Average lOur MethodIndic?
Qualityyes 2.93yes 3.66no 3.00yes 4.00no 1.76yes 4.00yes 2.50yes 3.00no 2.66yes 4.00no 2.70no 3.3370% 3.15S.D.
AbstractIndic?
Qualityyes 4.16yes 4.00no 4.06yes 4.33yes 4.00no 4.53yes 4.40yes 4.00yes 3.66yes 3.31no 4.26no 4.0080% 4.04Results with Different Documents and Subjects80% I 1.46\[ 80%\] 3.23\[ 100% \[ 4.25 ITable 4: Results of Human Judgment about Indicativeness and Text Qualityare shown in Table 4.
For a given source docu-ment and type of abstract, the value in column'Indic?'
contains the value 'yes' if the majorityof the evaluator have chosen the source docu-ment list of keywords for the abstract and 'no'on the contrary.
The value in column 'Qual-ity' is the average acceptability for the abstract.Content:  In 80% of the cases, the abstractspublished with the source documents werecorrectly classified by the evaluators.
Instead,the automatic abstracts were correctly classi-fied in 70% of the cases.
It is worth noting"that the automatic systems did not use the?
journal abstracts nor the lists of keywords orthe.information about the journal.Quality: The figures about text acceptabil-ity indicate that the abstracts produced byMicrosoft'97 Summarizer are below the accept-abil!ty level of 2.5, the abstracts produced byour method are above the acceptability level of2.5 and that the human abstracts are highlyacceptable.In a run of this experiment using 30 ab-stracts from a different set of 10 articles and 15judges from \]~cole de Biblioth6conomie et desSciences de l'Information (EBSI) at Universit6de Montr@al we have obtained similar results(last row in Table 4).8 Conc lus ionsIn this paper, we have presented a method oftext summarization which produces indicative-informative abstracts.
We have described thetechniques we are using to implement ourmethod and some experiments howing theviability of the approach.Our method was specified for summarizationof one specific type of text: the scientific andtechnical document.
Nevertheless, it is domainindependent because the concepts, relationsand types of information we use are commonacross different domains.
The question of thecoverage of the model will be addressed inour future work.
Our method was designedwithout any particular reader in mind andwith the assumption that a text does havea "main" topic.
If readers were known, theabstract could be tailored towards their specificprofiles.
User profiles could be used in order toproduce the informative abstracts elaboratingthose specific aspects the reader is "usually"interested in.
This aspect will be elaborated infuture work.The experiments reported here addressed9the evaluation of the indicative abstracts usinga categorization task.
Using the automaticabstracts reader have chosen the correctcategory for the articles in 70% of the casescompared with 80% of the cases when using theauthor abstracts.
Readers found the abstractsproduced by our method of better quality thana sentence-extraction based system.AcknowledgmentsWe would like to thank three anonymous re-viewers for their comments which helped us im-prove the final version of this paper.
We aregrateful to Professor Mich~le Hudon from Uni-versit~ de Montreal for fruitful discussion and toProfessor John E. Leide from McGill Universityand to Mme Gracia Pagola from Universit~ deMontreal for their help in recruiting informantsfor the experiments.ReferencesR.
Barzilay and M. Elhadad.
1997.
UsingLexical Chains for Text Summarization.
InProceedings of the A CL/EA CL '97 Workshopon Intelligent Scalable Text Summarization,pages 10-17, Madrid, Spain, July.G.
DeJong.
1982.
An Overview of the FRUMPSystem.
In W.G.
Lehnert and M.H.
Ringle,editors, Strategies for Natural Language Pro-cessing, pages 149-176.
Lawrence Erlbaum.
Associates, Publishers.T.
Firmin and M.J. Chrzanowski.
1999.
AnEvaluation of Automatic Text Summariza-tion Systems.
In I. Mani and M.T.
Maybury,.editors, Advances in Automatic Text Summa-~ization, pages 325-336.T.R.
Gibson.
1993.
Towards a Discourse The-ory of Abstracts and Abstracting.
Depart-ment of English Studies.
University of Not-tingham.P.
Grant.
1992.
The Integration of Theory andPractice in the Development of Summary-Writting Strategies.
Ph.D. thesis, Universit~de Montreal.
Facult~ des ~tudes up~rieures.H.
Jing and K.R.
McKeown.
1999.
The Decom-position of Human-Written Summary Sen-tences.
In M. Hearst, Gey.
F., and R. Tong,editors, Proceedings of SIGIR '99.
22nd Inter-national Conference on Research and Devel-opment in Information Retrieval, pages 129-136, University of California, Beekely, Au-gust.H.P.
Luhn.
1958.
The Automatic Creation of "Literature Abstracts.
IBM Journal of Re-search Development, 2(2):159-165.I.
Mani, D. House, G. Klein, L. Hirshman,L.
Obrst, T. Firmin, M. Chrzanowski, andB.
Sundheim.
1998.
The TIPSTER SUM-MAC Text Summarization Evaluation.
Tech-nical report, The Mitre Corporation.D.
Marcu.
1997.
From Discourse Structuresto Text Summaries.
In The Proceedings ofthe A CL '97lEA CL '97 Workshop on Intelli-gent Scalable Text Summarization, pages 82-88, Madrid, Spain, July 11.J-L. Minel, S. Nugier, and G. Piat.
1997.
Com-ment Appr~cier la Qualit~ des R~sum~s Au-tomatiques de Textes?
Les Exemples des Pro-tocoles FAN et MLUCE et leurs R~sultatssur SERAPHIN.
In ldres Journdes Scientific-ques et Techniques du Rdseau Francophonede l'Ingdnierie de la Langue de I'AUPELF-UREF., pages 227-232, 15-16 avril.J-L. Minel, J-P. Descl~s, E. Cartier,G.
Crispino, S.B.
Hazez, and A. Jack-iewicz.
2000.
R~sum~ automatique parfiltrage s~mantique d'informations dans destextes.
TSI, X(X/2000):l-23.C.D.
Paice and P.A.
Jones.
1993.
The Iden-tification of Important Concepts in HighlyStructured Technical Papers.
In R. Korfhage,E.
Rasmussen, and P. Willett, editors, Proc.of the 16th ACM-SIGIR Conference, pages69-78.D.R.
Radev and K.R.
McKeown.
1998.
Gen-erating Natural Language Summaries fromMultiple On-Line Sources.
ComputationalLinguistics, 24(3):469-500.J.
Rowley.
1982.
Abstracting and Indexing.Clive Bingley, London.H.
Saggion and G. Lapalme.
1998.
Where doesInformation come from?
Corpus Analysis forAutomatic Abstracting.
In RIFRA'98.
Ren-contre Internationale sur l'extraction le Fil-trage et le Rdsumd Automatique, pages 72-83.H.
Saggion and G. Lapalme.
2000.
Evaluationof Content and Text Quality in the Contextof Technical Text Summarization.
In Pro-ceedings of RIAO'2000, Paris, France, 12-14April, 2000.10IIIiIIIIIIIII!I,IIIIi,
