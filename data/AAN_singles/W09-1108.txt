Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 48?56,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsSuperior and Efficient Fully Unsupervised Pattern-based ConceptAcquisition Using an Unsupervised ParserDmitry Davidov1 Roi Reichart1 Ari Rappoport21ICNC , 2Institute of Computer ScienceHebrew University of Jerusalem{dmitry@alice.nc|roiri@cs|arir@cs}.huji.ac.ilAbstractSets of lexical items sharing a significantaspect of their meaning (concepts) are fun-damental for linguistics and NLP.
Unsuper-vised concept acquisition algorithms havebeen shown to produce good results, and arepreferable over manual preparation of con-cept resources, which is labor intensive, er-ror prone and somewhat arbitrary.
Some ex-isting concept mining methods utilize super-vised language-specific modules such as POStaggers and computationally intensive parsers.In this paper we present an efficient fullyunsupervised concept acquisition algorithmthat uses syntactic information obtained froma fully unsupervised parser.
Our algorithmincorporates the bracketings induced by theparser into the meta-patterns used by a sym-metric patterns and graph-based concept dis-covery algorithm.
We evaluate our algorithmon very large corpora in English and Russian,using both human judgments and WordNet-based evaluation.
Using similar settings asthe leading fully unsupervised previous work,we show a significant improvement in con-cept quality and in the extraction of multiwordexpressions.
Our method is the first to usefully unsupervised parsing for unsupervisedconcept discovery, and requires no language-specific tools or pattern/word seeds.1 IntroductionComprehensive lexical resources for many domainsand languages are essential for most NLP applica-tions.
One of the most utilized types of such re-sources is a repository of concepts: sets of lexicalitems sharing a significant aspect of their meanings(e.g., types of food, tool names, etc).While handcrafted concept databases (e.g., Word-Net) are extensively used in NLP, manual compila-tion of such databases is labor intensive, error prone,and somewhat arbitrary.
Hence, for many languagesand domains great efforts have been made for au-tomated construction of such databases from avail-able corpora.
While language-specific and domain-specific studies show significant success in develop-ment of concept discovery frameworks, the majorityof domains and languages remain untreated.
Hencethere is a need for a framework that performs wellfor many diverse settings and is as unsupervised andlanguage-independent as possible.Numerous methods have been proposed for seed-based concept extraction where a set of concept pat-terns (or rules), or a small set of seed words for eachconcept, is provided as input to the concept acqui-sition system.
However, even simple definitions forconcepts are not always available.To avoid requiring this type of input, a number ofdistributional and pattern-based methods have beenproposed for fully unsupervised seed-less acquisi-tion of concepts from text.
Pattern-based algorithmswere shown to obtain high quality results while be-ing highly efficient in comparison to distributionalmethods.
Such fully unsupervised methods do notincorporate any language-specific parsers or taggers,so can be successfully applied to diverse languages.However, unsupervised pattern-based methodssuffer from several weaknesses.
Thus they are fre-quently restricted to single-word terms and are un-able to discover multiword expressions in efficientand precise manner.
They also usually ignore poten-tially useful part-of-speech and other syntactic in-formation.
In order to address these weaknesses,several studies utilize language-specific parsing or48tagging systems in concept acquisition.
Unfortu-nately, while improving results, this heavily affectsthe language- and domain- independence of suchframeworks, and severely impacts efficiency sinceeven shallow parsing is computationally demanding.In this paper we present a method to utilize the in-formation induced by unsupervised parsers in an un-supervised pattern-based concept discovery frame-work.
With the recent development of fast fully un-supervised parsers, it is now possible to add parser-based information to lexical patterns while keep-ing the language-independence of the whole frame-work and still avoiding heavy computational costs.Specifically, we incorporate the bracketings inducedby the parser into the meta-patterns used by a sym-metric patterns and graph-based unsupervised con-cept discovery algorithm.We performed a thorough evaluation on two En-glish corpora (the BNC and a 68GB web corpus)and on a 33GB Russian corpus.
Evaluations weredone using both human judgments and WordNet, insimilar settings as that of the leading unsupervisedprevious work.
Our results show that utilization ofunsupervised parser both improves the assignmentof single-word terms to concepts and allows high-precision discovery and assignment of of multiwordexpressions to concepts.2 Previous WorkMuch work has been done on lexical acquisition ofall sorts and the acquisition of concepts in particu-lar.
Concept acquisition methods differ in the type ofcorpus annotation and other human input used, andin their basic algorithmic approach.
Some methodsdirectly aim at concept acquisition, while the directgoal in some is the construction of hyponym (?is-a?)hierarchies.
A subtree in such a hierarchy can beviewed as defining a concept.A major algorithmic approach is to representword contexts as vectors in some space and use dis-tributional measures and clustering in that space.Pereira (1993), Curran (2002) and Lin (1998) usesyntactic features in the vector definition.
(Panteland Lin, 2002) improves on the latter by clusteringby committee.
Caraballo (1999) uses conjunctionand appositive annotations in the vector representa-tion.
Several studies avoid requiring any syntacticannotation.
Some methods are based on decompo-sition of a lexically-defined matrix (by SVD, PCAetc), e.g.
(Schu?tze, 1998; Deerwester et al, 1990).While great effort has been made for improv-ing the computational complexity of distributionalmethods (Gorman and Curran, 2006), they still re-main highly computationally intensive in compari-son to pattern approaches (see below), and most ofthem do not scale well for very large datasets.The second main approach is to use lexico-syntactic patterns.
Patterns have been shown to pro-duce more accurate results than feature vectors, ata lower computational cost on large corpora (Pan-tel et al, 2004).
Since (Hearst, 1992), who used amanually prepared set of initial lexical patterns, nu-merous pattern-based methods have been proposedfor the discovery of concepts from seeds.
Otherstudies develop concept acquisition for on-demandtasks where concepts are defined by user-providedseeds.
Many of these studies utilize information ob-tained by language-specific parsing and named en-tity recognition tools (Dorow et al, 2005).
Pantel etal.
(2004) reduce the depth of linguistic data used,but their method requires POS tagging.TextRunner (Banko et al, 2007) utilizes a setof pattern-based seed-less strategies in order to ex-tract relational tuples from text.
However, this sys-tem contains many language-specific modules, in-cluding the utilization of a parser in one of the pro-cessing stages.
Thus the majority of the existingpattern-based concept acquisition systems rely onpattern/word seeds or supervised language-specifictools, some of which are very inefficient.Davidov and Rappoport (2006) developed aframework which discovers concepts based on highfrequency words and symmetry-based pattern graphproperties.
This framework allows a fully unsuper-vised seed-less discovery of concepts without rely-ing on language-specific tools.
However, it com-pletely ignores potentially useful syntactic or mor-phological information.For example, the pattern ?X and his Y?
is usefulfor acquiring the concept of family member types,as in ?his siblings and his parents?.
Without syn-tactic information, it can capture noise, as in ?...
inireland) and his wife)?
(parentheses denote syntac-tic constituent boundaries).
As another example, theuseful symmetric pattern ?either X or Y?
can appearin both good examples (?choose either Chihuahua49or Collie.?)
and bad ones (?either Collie or Aus-tralian Bulldog?).
In the latter case, the algorithmboth captures noise (?Australlian?
is now consid-ered as a candidate for the ?dog type?
concept), andmisses the discovery of a valid multiword candidate(?Australlian Bulldog?).
While symmetry-based fil-tering greatly reduces such noise, the basic problemremains.
As a result, incorporating at least someparsing information in a language-independent andefficient manner could be beneficial.Unsupervised parsing has been explored for sev-eral decades (see (Clark, 2001; Klein, 2005) for re-cent reviews).
Recently, unsupervised parsers havefor the first time outperformed the right branch-ing heuristic baseline for English.
These includeCCM (Klein and Manning, 2002), the DMV andDMV+CCM models (Klein and Manning, 2004),(U)DOP based models (Bod, 2006a; Bod, 2006b;Bod, 2007), an exemplar based approach (Den-nis, 2005), guiding EM using contrastive estimation(Smith and Eisner, 2006), and the incremental parserof Seginer (2007) which we use here.
These workslearn an unlabeled syntactic structure, dependencyor constituency.
In this work we use constituencytrees as our syntactic representation.Another important factor in concept acquisitionis the source of textual data used.
To take advan-tage of the rapidly expanding web, many of the pro-posed frameworks utilize web queries rather thanlocal corpora (Etzioni et al, 2005; Davidov et al,2007; Pasca and Van Durme, 2008; Davidov andRappoport, 2009).
While these methods have a defi-nite practical advantage of dealing with the most re-cent and comprehensive data, web-based evaluationhas some methodological drawbacks such as limitedrepeatability (Kilgarriff, 2007).
In this study we ap-ply our framework on offline corpora in settings sim-ilar to that of previous work, in order to be able tomake proper comparisons.3 Efficient Unsupervised ParsingOur method utilizes the information induced by un-supervised parsers.
Specifically, we make use of thebracketings induced by Seginer?s parser1 (Seginer,2007).
This parser has advantages in three major as-1The parser is freely available athttp://staff.science.uva.nl/?yseginer/cclpects relevant to this paper.First, it achieves state of the art unsupervisedparsing performance: its F-score2 is 75.9% for sen-tences of up to 10 words from the PennTreebankWall Street Journal corpus (WSJ) (Marcus, 1993),and 59% for sentences of the same length from theGerman NEGRA (Brants, 1997) corpus.
These cor-pora consists of newspaper texts.Second, to obtain good results, manually createdPOS tags are used as input in all the unsupervisedparsers mentioned above except of Seginer?s, whichuses raw sentences as input.
(Headden et al, 2008)have shown that the performance of algorithms thatrequire POS tags substantially decreases when usingPOS tags induced by unsupervised POS taggers in-stead of manually created ones.
Seginer?s incremen-tal parser is therefore the only fully unsupervisedparser providing high quality parses.Third, Seginer?s parser is extremely fast.
Duringits initial stage, the parser builds a lexicon.
Our Pen-tium 2.8GHB machines with 4GHB RAM can storein memory the lexicon created by up to 0.2M sen-tences.
We thus divided our corpora to batches of0.2M sentences and parsed each of them separately.Note that in this setup parsing quality might be evenbetter than the quality reported in (Seginer, 2007),since in the setup reported in that paper the parserwas applied to a few thousand sentences only.
Onaverage, the parsing time of a single batch was 5minutes (run time did not significantly differ acrossbatches and corpora).Parser description.
The parser utilizes the novelcommon-cover link representation for syntacticstructure.
This representation resembles depen-dency structure but unlike the latter, it can be trans-lated into a constituency tree, which is the syntacticrepresentation we use in this work.The parsing algorithm creates the common-coverlinks structure of a sentence in an incremental man-ner.
This means that the parser reads the words ofa sentence one after the other and, as each word isread, it is only allowed to add links that have one oftheir ends at that words (and update existing ones).Words which have not yet been read are not avail-2F = 2?R?PR+P , where R and P are the recall and precision ofthe parsers?
bracketing compared to manually created bracket-ing of the same text.
This is the accepted measure for parsingperformance (see (Klein, 2005)).50able to the parser at this stage.
This restriction isinspired by psycholinguistics research which sug-gests that humans process language incrementally.This results in a significant restriction of the parser?ssearch space, which is the reason it is so fast.During its initial stage the parser builds a lexiconcontaining, for each word, statistics helping the deci-sion of whether to link that word to other words.
Thelexicon is updated as any new sentence is read.
Lex-icon updating is also done in an incremental mannerso this stage is also very fast.4 Unsupervised Pattern DiscoveryIn the first stage of our algorithm, we run the unsu-pervised parser on the corpus in order to produce abracketing structure for each sentence.
In the sec-ond stage, described here, we use these bracketingsin order to discover, in a fully unsupervised manner,patterns that could be useful for concept mining.Our algorithm is based on the concept acquisitionmethod of (Davidov and Rappoport, 2006).
We dis-cover patterns that connect terms belonging to thesame concept in two main stages: discovery of pat-tern candidates, and identification of the symmetricpatterns among the candidates.Pattern candidates.
A major idea of (Davidovand Rappoport, 2006) is that a few dozen high fre-quency words (HFW) such as ?and?
and ?is?
con-nect other, less frequent content terms into relation-ships.
They define meta-patterns, which are shortsequences of H?s and C?s, where H is a slot fora HFW and C is a slot for a content word (laterto become a word belonging to a discovered con-cept).
Their method was shown to produce goodresults.
However, the fact that it does not considerany syntactic information causes problems.
Specif-ically, it does not consider the constituent structureof the sentence.
Meta-patterns that cross constituentboundaries are likely to generate noise ?
two contentwords (C?s) in a meta-pattern that belong to differ-ent constituents are likely to belong to different con-cepts as well.
In addition, meta-patterns that do notoccupy a full constituent are likely to ?cut?
multi-word expressions (MWEs) into two parts, one partthat gets treated as a valid C word and one part thatis completely ignored.The main idea in the present paper is to use thebracketings induced by unsupervised parsers in or-der to avoid the problems above.
We utilize brack-eting boundaries in our meta-patterns in additionto HFW and C slots.
In other words, their origi-nal meta-patterns are totally lexical, while ours arelexico-syntactic meta-patterns.
We preserve the at-tractive properties of meta-patterns, because bothHFWs and bracketings can be found or computed ina language independent manner and very efficiently.Concretely, we define a HFW as a word appearingmore than TH times per million words, and a C asa word or multiword expression containing up to 4words, appearing less than TC times per million.We require that our patterns include two slots forC?s, separated by at least a single HFW or bracket.We allow separation by a single bracket because thelowest level in the induced bracketing structure usu-ally corresponds to lexical items, while higher levelscorrespond to actual syntactic constituents.In order to avoid truncation of multiword expres-sions, we also require the meta pattern to start andend by a HFW or bracket.
Thus our meta-patternsmatch the following regular expression:{H|B}?
C1 {H|B}+ C2 {H|B}?where ?*?
means zero or more times, and ?+?
meansone or more time and B can be ?(?,?)?
brackets pro-duced by the parser (in these patterns we do notneed to guarantee that brackets match properly).
Ex-amples of such patterns include ?
((C1)in C2))?,?
(C1)(such(as(((C2)?, and ?(C1)and(C2)?3.
Wedismiss rare patterns that appear less than TP timesper million words.Symmetric patterns.
Many of the pattern candi-dates discovered in the previous stage are not usable.In order to find a usable subset, we focus on the sym-metric patterns.
We define a symmetric pattern as apattern in which the same pair of terms (C words)is likely to appear in both left-to-right and right-to-left orders.
In order to identify symmetric patterns,for each pattern we define a pattern graph G(P ), asproposed by (Widdows and Dorow, 2002).
If termpair (C1, C2) appears in pattern P in some context,3This paper does not use any punctuation since the parseris provided with sentences having all non-alphabetic charactersremoved.
We assume word separation.
C1,2 can be a word or amultiword expression.51we add nodes c1, c2 to the graph and a directed edgeEP (c1, c2) between them.
In order to select sym-metric patterns, we create such a pattern graph forevery discovered pattern, and create a symmetricsubgraph SymG(P) in which we take only bidirec-tional edges from G(P ).
Then we compute threemeasures for each pattern candidate as proposed by(Davidov and Rappoport, 2006):M1(P ) := |{c1|?c2EP (c1, c2) ?
?c3EP (c3, c1)}||Nodes(G(P ))|M2(P ) := |Nodes(SymG(P ))||Nodes(G(P ))|M3(P ) := |Edges(SymG(P ))||Edges(G(P ))|For each measure, we prepare a sorted list of all can-didate patterns.
We remove patterns that are not inthe top ZT (we use 100, see Section 6) in any of thethree lists, and patterns that are in the bottom ZB inat least one of the lists.5 Concept DiscoveryAt the end of the previous stage we have a set ofsymmetric patterns.
We now use them in order todiscover concepts.
The concept discovery algorithmis essentially the same as used by (Davidov and Rap-poport, 2006) and has some similarity with the oneused by (Widdows and Dorow, 2002).
In this sectionwe outline the algorithm.The clique-set method.
The utilized approach toconcept discovery is based on connectivity struc-tures in the all-pattern term relationship graph G,resulting from merging all of the single-patterngraphs for symmetric patterns selected in the previ-ous stage.
The main observation regarding G is thathighly interconnected words are good candidates toform a concept.
We find all strong n-cliques (sub-graphs containing n nodes that are all interconnectedin both directions).
A clique Q defines a concept thatcontains all of the nodes in Q plus all of the nodesthat are (1) at least unidirectionally connected to allnodes in Q, and (2) bidirectionally connected to atleast one node in Q.
Using this definition, we createa concept for each such clique.Note that a single term can be assigned to severalconcepts.
Thus a clique based on a connection of theword ?Sun?
to ?Microsoft?
can lead to a concept ofcomputer companies, while the connection of ?Sun?to ?Earth?
can lead to a concept of celestial bodies.Reducing noise: merging and windowing.
Sinceany given term can participate in many cliques, thealgorithm creates overlapping categories, some ofwhich redundant.
In addition, due to the nature oflanguage and the imperfection of the corpus somenoise is obviously to be expected.
We enhance thequality of the obtained concepts by merging themand by windowing on the corpus.
We merge twoconcepts Q,R, iff there is more than a 50% overlapbetween them: (|Q?R| > |Q|/2) ?
(|Q?R| >|R|/2).
In order to increase concept quality and re-move concepts that are too context-specific, we usea simple corpus windowing technique.
Instead ofrunning the algorithm of this section on the wholecorpus, we divide the corpus into windows of equalsize and perform the concept discovery algorithm ofthis section (without pattern discovery) on each win-dow independently.
We now have a set of conceptsfor each window.
For the final set, we select onlythose concepts that appear in at least two of the win-dows.
This technique reduces noise at the potentialcost of lowering coverage.A decrease in the number of windows should pro-duce more noisy results, while discovering moreconcepts and terms.
In the next section we show thatwhile windowing is clearly required for a large cor-pus, incorporation of parser data increases the qual-ity of the extracted corpus to the point where win-dowing can be significantly reduced.6 ResultsIn order to estimate the quality of concepts and tocompare it to previous work, we have performedboth automatic and human evaluation.
Our basiccomparison was to (Davidov and Rappoport, 2006)(we have obtained their data and utilized their al-gorithm), where we can estimate if incorporation ofparser data can solve some fundamental weaknessesof their framework.
In the following description, wecall their algorithm P and our parser-based frame-work P+.
We have also performed an indirect com-parison to (Widdows and Dorow, 2002).While there is a significant number of other re-lated studies4 on concept acquisition (see Section 2),4Most are supervised and/or use language-specific tools.52direct or even indirect comparison to these works isproblematic due to difference in corpora, problemdefinitions and evaluation strategies.
Below we de-scribe the corpora and parameters used in our evalu-ation and then show and discuss WordNet-based andHuman evaluation settings and results.Corpora.
We performed in-depth evaluation intwo languages, English and Russian, using threecorpora, two for English and one for Russian.The first English corpus is the BNC, containingabout 100M words.
The second English corpus,DMOZ(Gabrilovich and Markovitch, 2005), is aweb corpus obtained by crawling URLs in the OpenDirectory Project (dmoz.org), resulting in 68GBcontaining about 8.2G words from 50M web pages.The Russian corpus (Davidov and Rappoport, 2006)was assembled from web-based Russian reposito-ries, to yield 33GB and 4G words.
All of these cor-pora were also used by (Davidov and Rappoport,2006) and BNC was used in similar settings by(Widdows and Dorow, 2002).Algorithm parameters.
The thresholdsTH , TC , TP , ZT , ZB , were determined mostlyby practical memory size considerations: we com-puted thresholds that would give us the maximalnumber of terms, while enabling the pattern accesstable to reside in main memory.
The resultingnumbers are 100, 50, 20, 100, 100.
Corpus windowsize was determined by starting from a smallwindow size, extracting at random a single window,running the algorithm, and iterating this processwith increased ?2 window sizes until reaching adesired vocabulary concept participation percentage(before windowing) (i.e., x% of the different wordsin the corpus participate in terms assigned intoconcepts.
We used 5%.).
We also ran the algorithmwithout windowing in order to check how well theprovided parsing information can help reduce noise.Among the patterns discovered are the ubiquitousones containing ?and?,?or?, e.g.
?
((X) or (a Y))?,and additional ones such as ?from (X) to (Y)?.Influence of parsing data on number of discov-ered concepts.
Table 1 compares the concept ac-quisition framework with (P+) and without (P) uti-lization of parsing data.We can see that the amount of different wordsV W C ASP P+ P P+ P P+DMOZ 16 330 504 142 130 12.8 16.0BNC 0.3 25 42 9.6 8.9 10.2 15.6Russ.
10 235 406 115 96 11.6 15.1Table 1: Results for concept discovery with (P+) andwithout (P) utilization of parsing data.
V is the total num-ber (millions) of different words in the corpus.
W is thenumber (thousands) of words belonging to at least one ofthe terms for one of the concepts.
C is the number (thou-sands) of concepts (after merging and windowing).
ASis the average(words) category size.covered by discovered concepts raises nearly 1.5-fold when we utilize patterns based on parsing datain comparison to pure HFW patterns used in previ-ous work.
We can also see nearly the same increasein average concept size.
At the same time we ob-serve about 15% reduction in the total number ofdiscovered concepts.There are two opposite factors in P+ which mayinfluence the number of concepts, their size and cov-erage in comparison to P. On one hand, utilization ofmore restricted patterns that include parsing infor-mation leads to a reduced number of concept terminstances being discovered.
Thus, the P+ pattern ?
(X(or (a Y))?
will recognize ?
(TV (or (a movie))?
in-stance and will miss ?
(lunch) or (a snack))?, whilethe P pattern ?X or a Y?
will capture both.
This leadsto a decrease in the number of discovered concepts.On the other hand, P+ patterns, unlike P ones, al-low the extraction of multiword expressions5, andindeed more than third of the discovered terms us-ing P+ were MWEs.
Utilization of MWEs not onlyallows to cover a greater amount of different words,but also increases the number of discovered conceptssince new concepts can be found using cliques ofnewly discovered MWEs.
From the results, we cansee that for a given concept size and word coverage,the ability to discover MWEs overcomes the disad-vantage of ignoring potentially useful concepts.Human judgment evaluation.
Our human judge-ment evaluation closely followed the protocol (Davi-dov and Rappoport, 2006).We used 4 subjects for evaluation of the English5While P method can potentially be used to extract MWEs,preliminary experimentation shows that without significantmodification, quality of MWEs obtained by P is very low incomparison to P+53concepts and 4 subjects for Russian ones.
In orderto assess subjects?
reliability, we also included ran-dom concepts (see below).
The goal of the exper-iment was to examine the differences between theP+ and P concept acquisition frameworks.
Subjectswere given 50 triplets of words and were asked torank them using the following scale: (1) the wordsdefinitely share a significant part of their meaning;(2) the words have a shared meaning but only insome context; (3) the words have a shared mean-ing only under a very unusual context/situation; (4)the words do not share any meaning; (5) I am notfamiliar enough with some/all of the words.The 50 triplets were obtained as follows.
We haverandomly selected 40 concept pairs (C+,C): C+ inP+ and C in P using five following restrictions: (1)concepts should contain at least 10 words; (2) fora selected pair, C+ should share at least half of itssingle-word terms with C, and C should share atleast half of its words with C+; (3) C+ should con-tain at least 3 MWEs; (4) C should contain at least 3words not appearing in C+; (5) C+ should contain atleast 3 single-word terms not appearing in C.These restrictions allow to select concept pairssuch that C+ is similar to C while they still carryenough differences which can be examined.
We se-lected the triplets as following: for pairs (C+, C) tentriplets include terms appearing in both C+ and C(Both column in Table 2), ten triplets include single-word terms appearing in C+ but not C (P+ singlecolumn), ten triplets include single-word terms ap-pearing in C but not C+ (P column), ten triplets in-clude MWEs appearing in C+ (P+ mwe column) andten triplets include random terms obtained from P+concepts (Rand column).P+ P Both Randmwe single% sharedmeaningDMOZ 85 88 68 81 6BNC 85 90 61 88 0Russ.
89 95 70 93 11tripletscore (1-4)DMOZ 1.7 1.4 2.5 1.7 3.8BNC 1.6 1.3 2.1 1.5 4.0Russ.
1.5 1.1 2.0 1.3 3.7Table 2: Results of evaluation by human judgment ofthree data sets.
P+ single/mwe: single-word/MWE termsexisting only in P+ concept; P: single-word terms existingonly in P concept; Both: terms existing in both concepts;Rand: random terms.
See text for detailed explanations.The first part of Table 2 gives the average per-centage of triplets that were given scores of 1 or 2(that is, ?significant shared meaning?).
The secondpart gives the average score of a triplet (1 is best).In these lines scores of 5 were not counted.
Inter-evaluator Kappa between scores are 0.68/0.75/0.76for DMOZ, BNC and Russian respectively.
We cansee that terms selected by P and skipped by P+receive low scores, at the same time even single-word terms selected by P+ and skipped by P showvery high scores.
This shows that using parser data,the proposed framework can successfully avoid se-lection of erroneous terms, while discovering high-quality terms missed by P. We can also see that P+performance on MWEs, while being slightly infe-rior to the one for single-word terms, still achievesresults comparable to those of single-word terms.Thus our algorithm can greatly improve the re-sults not only by discovering of MWEs but also byimproving the set of single word concept terms.WordNet-based evaluation.
The major guidelinein this part of the evaluation was to compare our re-sults with previous work (Davidov and Rappoport,2006; Widdows and Dorow, 2002) without the pos-sible bias of human evaluation.
We have followedtheir methodology as best as we could, using thesame WordNet (WN) categories and the same cor-pora.
This also allows indirect comparison to severalother studies, thus (Widdows and Dorow, 2002) re-ports results for an LSA-based clustering algorithmthat are vastly inferior to the pattern-based ones.The evaluation method is as follows.
We tookthe exact 10 WN subsets referred to as ?subjects?
in(Widdows and Dorow, 2002), and removed all multi-word items.
We then selected at random 10 pairs ofwords from each subject.
For each pair, we foundthe largest of our discovered concepts containing it.The various morphological forms or clear typos ofthe same word were treated as one in the evaluation.We have improved the evaluation framework forRussian by using the Russian WordNet (Gelfenbey-nand et al, 2003) instead of back-translations asdone in (Davidov and Rappoport, 2006).
Prelim-inary examination shows that this has no apparenteffect on the results.For each found concept C containing N words,we computed the following: (1) Precision: the num-54ber of words present in both C and WN divided byN ; (2) Precision*: the number of correct words di-vided by N .
Correct words are either words thatappear in the WN subtree, or words whose entry inthe American Heritage Dictionary or the Britannicadirectly defines them as belonging to the given class(e.g., ?murder?
is defined as ?a crime?).
This wasdone in order to overcome the relative poorness ofWN; (3) Recall: the number of words present inboth C and WN divided by the number of wordsin WN; (4) The percentage of correctly discoveredwords (according to Precision*) that are not in WN.Table 3 compares the macro-average of these 10categories to corresponding related work.
We do notPrec.
Prec.
* Rec.
%NewDMOZP 79.8 86.5 22.7 2.5P+ 79.5 91.3 28.6 3.7BNCP 92.76 95.72 7.22 0.4P+ 93.0 96.1 14.6 1.7Widdows 82.0 - - -RussianP 82.39 89.64 20.03 2.1P+ 83.5 92.6 29.6 4.0Table 3: WordNet evaluation in comparison to P (Davi-dov and Rappoport, 2006) and to Widdows(Widdows andDorow, 2002).
Columns show average precision, preci-sion* (as defined in text), recall, and % of new wordsadded to corresponding WN subtree.observe apparent rise in precision when comparingP+ and P, but we can see significant improvementin both recall and precision* for all of three cor-pora.
In combination with human judgement results,this suggests that the P+ framework successfully dis-covers more correct terms not present in WN.
Thiscauses precision to remain constant while precision*improves significantly.
Rise in recall also shows thatthe P+ framework can discover significantly morecorrect terms from the same data.Windowing requirement.
As discussed in Sec-tion 5, windowing is required for successful noisereduction.
However, due to the increase in patternquality with parser data, it is likely that less noisewill be captured by the discovered patterns.
Hence,windowing could be relaxed allowing to obtain moredata with sufficiently high precision.In order to test this issue we applied our algo-rithms on the DMOZ corpus with 3 different win-dowing settings: (1) choosing window size as de-scribed above; (2) using ?4 larger window; (3)avoiding windowing altogether.
Each time we ran-domly sampled a set of 100 concepts and tagged (bythe authors) noisy ones.
A concept is considered tobe noisy if it has at least 3 words unrelated to eachother.
Table 4 shows results of this test.Reg.
Window ?4 Window No windowingP 4 18 33P+ 4 5 21Table 4: Percentage of noisy concepts as a function ofwindowing.We can see that while windowing is still essentialeven with available parser data, using this data wecan significantly reduce windowing requirements,allowing us to discover more concepts from thesame data.Timing requirements are modest, considering weparsed such large amounts of data.
BNC pars-ing took 45 minutes, and the total single-machineprocessing time for the 68Gb DMOZ corpus was4 days6.
In comparison, a state-of-art supervisedparser (Charniak and Johnson, 2005) would processthe same amount of data in 1.3 years7.7 DiscussionWe have presented a framework which utilizes anefficient fully unsupervised parser for unsupervisedpattern-based discovery of concepts.
We showedthat utilization of unsupervised parser in pattern ac-quisition not only allows successful extraction ofMWEs but also improves the quality of obtainedconcepts, avoiding noise and adding new termsmissed by the parse-less approach.
At the same time,the framework remains fully unsupervised, allowingits straightforward application to different languagesas supported by our bilingual evaluation.This research presents one more step towards themerging of fully unsupervised techniques for lex-ical acquisition, allowing to extract semantic datawithout strong assumptions on domain or language.While we have aimed for concept acquisition, theproposed framework can be also useful for extrac-tion of different types of lexical relationships, bothamong concepts and between concept terms.6In fact, we used a PC cluster, and all 3 corpora were parsedin 15 hours.7Considering the reported parsing rate of 10 sentences persecond55ReferencesMishele Banko, Michael J Cafarella , Stephen Soderland,Matt Broadhead, Oren Etzioni, 2007.
Open Informa-tion Extraction from the Web.
IJCAI ?07.Rens Bod, 2006a.
An All-Subtrees Approach to Unsu-pervised Parsing.
ACL ?06.Rens Bod, 2006b.
Unsupervised Parsing with U-DOP.CoNLL X.Rens Bod, 2007.
Is the End of Supervised Parsing inSight?
ACL ?07.Thorsten Brants, 1997.
The NEGRA Export Format.CLAUS Report, Saarland University.Sharon Caraballo, 1999.
Automatic Construction of aHypernym-labeled Noun Hierarchy from Text.
ACL?99.Eugene Charniak and Mark Johnson, 2005.
Coarse-to-Fine n-Best Parsing and MaxEnt DiscriminativeReranking.
ACL ?05.Alexander Clark, 2001.
Unsupervised Language Acqui-sition: Theory and Practice.
Ph.D. thesis, Universityof Sussex.James R. Curran, Marc Moens, 2002.
Improvements inAutomatic Thesaurus Extraction SIGLEX 02?, 59?66.Dmitry Davidov, Ari Rappoport, 2006.
Efficient Un-supervised Discovery of Word Categories using Sym-metric Patterns and High Frequency Words.
COLING-ACL ?06.Dmitry Davidov, Ari Rappoport, Moshe Koppel, 2007.Fully Unsupervised Discovery of Concept-SpecificRelationships by Web Mining.
ACL ?07.Dmitry Davidov, Ari Rappoport, 2009.
Translation andExtension of Concepts Across Languages.
EACL ?09.Scott Deerwester, Susan Dumais, George Furnas,Thomas Landauer, Richard Harshman, 1990.
Index-ing by Latent Semantic Analysis.
J. of the AmericanSociety for Info.
Science, 41(6):391?407.Simon Dennis, 2005.
An exemplar-based approach tounsupervised parsing.
Proceedings of the 27th Con-ference of the Cognitive Science Society.Beate Dorow, Dominic Widdows, Katarina Ling, Jean-Pierre Eckmann, Danilo Sergi, Elisha Moses, 2005.Using curvature and Markov clustering in Graphs forLexical Acquisition and Word Sense Discrimination.MEANING ?05.Oren Etzioni, Michael Cafarella, Doug Downey, S. Kok,Ana-Maria Popescu, Tal Shaked, Stephen Soderland,Daniel Weld, Alexander Yates, 2005.
UnsupervisedNamed-entity Extraction from the Web: An Experi-mental Study.
Artificial Intelligence, 165(1):91134.Evgeniy Gabrilovich, Shaul Markovitch, 2005.
Fea-ture Generation for Text Categorization Using WorldKnowledge.
IJCAI ?05.Ilya Gelfenbeyn, Artem Goncharuk, Vladislav Lehelt,Anton Lipatov, Victor Shilo, 2003.
Automatic Trans-lation of WordNet Semantic Network to Russian Lan-guage (in Russian) International Dialog 2003 Work-shop.James Gorman, James R. Curran, 2006.
Scaling Distri-butional Similarity to Large Corpora.
COLING-ACL?06.William P. Headden III, David McClosky and EugeneCharniak, 2008.
Evaluating Unsupervised Part-of-Speech tagging for Grammar Induction.
COLING ?08.Marti Hearst, 1992.
Automatic Acquisition of Hy-ponyms from Large Text Corpora.
COLING ?92.Adam Kilgarriff, 2007.
Googleology is Bad Science.Computational Linguistics ?08, Vol.33 No.
1,pp147-151.
.Dan Klein and Christopher Manning, 2002.
A genera-tive constituent-context model for improved grammarinduction.
Proc.
of the 40th Meeting of the ACL.Dan Klein and Christopher Manning, 2004.
Corpus-based induction of syntactic structure: Models of de-pendency and constituency.
ACL ?04.Dan Klein, 2005.
The unsupervised learning of naturallanguage structure.
Ph.D. thesis, Stanford University.Hang Li, Naoki Abe, 1996.
Clustering Words with theMDL Principle.
COLING ?96.Dekang Lin, 1998.
Automatic Retrieval and Clusteringof Similar Words.
COLING ?98.Marcus Mitchell P., Beatrice Santorini and Mary AnnMarcinkiewicz, 1993.
Building a large annotated cor-pus of English: The Penn Treebank.
ComputationalLinguistics, 19(2):313?330Marius Pasca, Benjamin Van Durme, 2008.
Weakly-supervised Acquisition of Open-domain Classes andClass Attributes from Web Documents and QueryLogs.
ACL 08.Patrick Pantel, Dekang Lin, 2002.
Discovering WordSenses from Text.
SIGKDD ?02.Patrick Pantel, Deepak Ravichandran, Eduard Hovy,2004.
Towards Terascale Knowledge Acquisition.COLING ?04.Fernando Pereira, Naftali Tishby, Lillian Lee, 1993.
Dis-tributional Clustering of English Words.
ACL ?93.Hinrich Schu?tze, 1998.
Automatic Word Sense Discrim-ination.
Computational Linguistics , 24(1):97?123.Yoav Seginer, 2007.
Fast Unsupervised IncrementalParsing.
ACL ?07.Noah A. Smith and Jason Eisner, 2006.
Annealing Struc-tural Bias in Multilingual Weighted Grammar Induc-tion .
ACL ?06.Dominic Widdows, Beate Dorow, 2002.
A Graph Modelfor Unsupervised Lexical Acquisition.
COLING ?02.56
