Speech-Based Retrieval UsingSemantic Co-Occurrence FilteringJulian Kupiec, Don Kimber and Vijay BalasubramanianXerox Palo Alto Research Center3333 Coyote Hill RoadPalo Alto, CA 94304ABSTRACTIn this paper we demonstrate that speech recognition can beeffectively applied to information retrieval (IR) applications.Our system exploits the fact that the intended words of a spo-ken query tend to co-occur in text documents in close proxim-ity whereas word combinations that are the result of recogni-tion errors are usually not semantically correlated and thusdo not appear together.
Termed "Semantic Co-occurrenceFiltering" this enables the system to simultaneously disam-biguate word hypotheses and find relevant ext for retrieval.The system is built by integrating standard IR and speechrecognition techniques.
An evaluation of the system is pre-seated and we discuss everal refinements o the functionality.1.
IntroductionIn applying speech recognition techniques to retrieve infor-mation from large unrestricted text corpora, several issuesimmediately arise.
The recognition vocabulary is very large(being the same size as the corpus vocabulary).
Each newcorpus may cover a different domain, requiring new spe-cialized vocabulary.
Furthermore the constraint afforded bydomain-dependent language models may be precluded ue tothe expense involved in constructing them.One approach to these problems obviates the need for anyword vocabulary to be defined \[1, 2\].
This is done by defininga phonetic inventory based on phonetically stable sub-wordunits which have corresponding orthographic ounterparts.This scheme has the potential advantage that both speechand text can be indexed in terms of the same units and thusspeech might be used to access text and vice-versa.
Sub-word units are considered to be independent and matching isperformed using vector-space similarity measures.Our concern in this paper is to provide speech access to textand our approach differs from the former in that whole wordsare used to constrain matching; we believe this to be moreeffective than splitting words into smaller independent units.We use boolean retrieval with proximity constraints ratherthan vector-space measures.
Our approach also accommo-dates standard phonetic alphabets (we employ a set of 39phones in contrast o the former technique which uses about1000 phonetic units).To demonstrate the feasibility of our approach we have im-plemented a prototype.
The user speaks each word of a queryseparately and is presented with the most relevant itles, eachaccompanied by the relevant word hypotheses.
The combina-tion of speech processing and retrieval currently takes about37320-30 seconds.
Figure 1 shows all titles produced for thequery "Maltese Falcon".The IR system acts as a novel kind of language model.
Thetext corpus is used directly; it is not necessary to pre-computestatistical estimates, only to index the text as appropriate forthe retrieval system.1.
Maltese Falcon, The (maltese falcon)2.
Astor, Mary (maltese falcon)3. film noir (maltese falcon)4.
Bogart, Humphrey (maltese falcon)5.
Huston, John (maltese falcon)6.
Hammett, Dashiell (maltese falcon)7.
Louis XV, King of France (marquise faction)8. rum (indies factor)9. drama (please fashion)Figure I: Presentation of Search Results2.
System ComponentsThe overall architecture of the system is shown in Figure 2.We will first describe the IR and speech systems and thenthe ancillary components that integrate them.2.1.
Retrieval SystemWe use the Text Database \[3\] for indexing and for booleansearch with proximity constraints.
We have experimentedwith Grolier's encyclopedia \[4\] which is a corpus of modestsize (SM words) spanning diverse topics.
There are 27,000 ar-ticles in the encyclopedia and an uninflected word dictionaryfor it contains 100,000 entries.
We use a stop list 1 containingapproximately 100 words.
The fact that short common wordsare included in the stop list is fortuitous for our speech-basedretrieval because they are difficult to recognize.2.2.
Phonetic RecognizerThe phonetic recognition component of the system uses stan-dard hidden Markov model (HMM) based speech recogni-tion methods.
The system currently operates in a speaker-dependent, isolated-word mode as this was the simplest tointegrate and known to be more robust operationally.
Input1A stop list contains common words that are not indexed be-cause they are not useful as query terms.PhoneticHMM'sSpeechiPhoneticRecognizerI I____J II  ro,s  l.__.__.J Encycl?pedia I IN-BestAlgorithmInformationRetrievalPresidentKennedyHypothesized Phone Sequence/pehziddernU/kehneh ntiy/IRanked Word HypothesesIp recedent, prescient, president, ...) kennerly, kennedy, kemeny, ...)Relevant (President Kennedy)ArticlesFigure 2: System Componentsto the system was from a Sennheiser HMD-414 microphone,sampled at a rate of 16KHz.
Feature vectors consisted of 14Mel-scaled cepstra, their derivatives and a log energy deriva-tive.
These were computed from 20 msec frames taken at arate of I00 per second.
Training data for each speaker wastaken from 1000 words spoken in isolation.
Each phoneticmodel is a three state HMM with Gaussian output distribu-tions having diagonal covariance matrices.
The topology ofthe phonetic models is shown in Figure 3.
Continuous train-ing was used to avoid the need for phonetically labelling train-ing data by hand.
The models were initialized from speakerindependent models trained on the TIMIT speech database\[5\].
For recognition, the models were placed in a networkwith probabilities reflecting the phonetic bigram statistics ofthe lexicon.
For each spoken word, a hypothesized phonesequence was determined by the maximum likelihood statesequence through the network, computed using the Viterbialgorithm.2.3.
Phonetic DictionaryTo use the IR system with speech we construct a phoneticdictionary which is a table giving a basic phonetic spelling foreach entry in the word dictionary.
For example the phoneticspelling for the word "president" is the string of phoneticsymbols "P R EH Z IH D EH N T ' .
In our implementationwe assodate a single phonetic spelling with each word.
Moregenerally, phonological variants, alternative pronunciationsNull lrmalSt lvFigure 3: Topology of a Phone HMMor even translations into other languages can also be placedin the phonetic dictionary.
In our arrangement the user needsto speak the uninflected word form that corresponds to theuninflected spelling that is used for indexing.
(Again, we candispense with this by including the phonetic spellings of wordinflections.
)The question remains as to how we find phonetic spellings forall the entries in the word dictionary.
We have sprit this prob-lem into two parts.
The first is to obtain a list of words andtheir phonetic spellings.
We have adapted a list containingphonetic spellings for 175,000 words \[6\].
Of the 100,000 wordtypes in the encyclopedia, 43,000 were covered by this list.Although this is less than half of the total vocabulary size,it nevertheless does represent the majority of actual word in-stances in the encyclopedia.
To cover the rest of the wordswe propose the application of techniques for automaticallyproducing phonetic spellings, e.g.
\[7, 8\].
Such techniques areprevalent in text-to-speech synthesis.3.
N-Best MatchingFor each spoken word, the recognizer outputs the most likelycorresponding phone sequence.
As a result of recognition er-rors, the phonetic sequence may not match any entry in thephonetic dictionary, or worse, might match an incorrect word.For example, when a speaker intended the word "president"the recognizer output "P R EH S EH D EH N T" would in-correctly match the word "precedent".
We therefore mploya statistical model of the errors typically made by the recog-nizer and use it to determine what words were likely to havebeen said.Given the phonetic sequence produced by the recognizer, anda statistical model of recognition errors, we want to efficientlydetermine the n most likely entries in the phonetic dictio-nary to have been the actual spoken word.
As will becomeapparent, our objective is to make sure the intended wordis somewhere in the list.
We have investigated two methodsfor producing the n-best word hypotheses.
The first followsa generate-and-test strategy and the second, more successfulapproach involves an HMM-based search through the pho-netic dictionary.In the remainder of this section we will discuss the character-ization and estimation of error statistics, and then describethe n-best algorithms.3743.1.
Character iz ing Recognizer ErrorsErrors made by the recognizer are described by matrices con-taining probabilities of various substitution, deletion and in-sertion errors.
We produce the error matrices by using analignment program that compares phonetic recognizer out-put for a set of spoken words with the correct phonetic tran-scriptions for those words.
(This set comprises 1000 words).Speaker characteristics are also modelled in the error matri-ces, as axe systematic pronunciation differences between thephonetic dictionary and the speaker.
For words that are gen-erated automatically (as mentioned in Section 2.3) we wouldexpect a separate distribution to be helpful because the char-acteristics of an automatic system are likely to have errorsdistributed in a different way.The results described in this paper are based on a contextindependent error model.
However, recognition errors arestrongly correlated with context, and an improved modelwould use context dependent statistics.
Both of the n-bestmethods described below are easily adapted to the use ofcontext dependent statistics.Given the relatively small amount of training data used forestimating error statistics, some form of smoothing is desir-able.
We employ a Laplacian estimator - if phone i occurs atotal of Ni times and is recognized as phone j a total of Ni~times, the estimated probability of such a substitution ispsus( j l i  ) _ N~j + 1N i+Mwhere M is the size of the phonetic alphabet (M ---- 39 forour phone set.)3.2.
Generate and TestOur initial method for determining the n-best word hypothe-ses employed a best-first approach.
The most likely phonesubstitutions/insertions/deletions are applied in a best-firstorder to the phone string produced by the recognizer.
Aftereach such modification if the resulting phone string is presentin the phonetic index, it is added to the n-best list with itsassociated probability (being the product of the probabilitiesof the modifications applied to the original string in orderto obtain it).
Finite-state recognizers are used to determinewhether a phone string is present in the index.
This searchmethod has the potential advantage that it does not requirematching against every entry 'in the phonetic index to pro-duce the n-best hypotheses.3.3.
HMM SearchThis involves matching the recognizer output against a spe-cial HMM network for each phonetic entry in the index (n.b.these HMM's are quite separate from those used by the pho-netic recognizer).Let p(wlyl, y2 , .
.
.
, y , )  be the probability that word to wasspoken given that the phonetic output produced by the rec-ognizer is yl, y2 , .
.
.
,  y, .
It is necessary to find the n wordsfor which p(to\[yl, y2, .
- .
,  y , )  is greatest.
By Bayes law:p(to\[y,, ~2 .
.
.
.
.
Yr,) = p(zta, y2 , .
.
.
,  y ,dw)P(w)p(~,,y~ .
.
.
.
,y .
)375The prior probabilities P(to) are assumed uniform here andp(yl, y2, .
.
.
,  y, )  is independent of w, so the problem is to findthe n words for which P(yl, y2, - .
.
,  y,\[w) is maximum.If the phonetic dictionary entry for word to is z l ,  z2 , .
.
.
,  z,~,then given the error statistics, the probabilitycan be computed by adding the probability of every sequenceof substitutions, deletions and insertions, which when ap-plied to za, x2 , .
.
.
,  z,n results in the sequence ya, y2, .
.
.
.
y, .Assuming that these types of errors are statistically inde-pendent, the calculation can be performed efficiently usingdynamic programming.
By defining a discrete HMM for w,in which the output symbols are phones, the calculation re-duces to the computation of the probability that y~, y2, .
.
.
,  y ,would be produced by the HMM (i.e.
the "forward" proba-bility).For example, the structure of the HMM for the word ,go,consisting of phonemes /g /  and /ow/ i s  shown in Figure 4.The large states represent the phones of the word, and haveoutput probabilities determined from the substitution prob-abilities.
The remaining output states (smaller and gray inthe figure) model possible insertions.
The output probabili-ties for these states are the estimated insertion probabilities,conditioned on the event that an insertion occurs.
Self loopson these states allow for the possibility of multiple insertions.The null state underneath each large phone state models thedeletion of that phone, and the null states underneath inser-tion states allow for the possibility that no insertion occursat that position.
The transition probabilities are determinedfrom estimated insertion and deletion probabilities.The HMM structure shown in Figure 4 could be replacedby a structure having no null states.
However the structurechosen is preferable for two reasons.
First, the computationof p(yt, y2 .
.
.
.
, ynlza, z2 .
.
.
.
.
zm) requires only O(mn) oper-ations rather than O(m2n) which would be required withoutnull states.
Second, the computation for this structure is eas-ily implemented using the phonetic pronunciation for eachword to index a table of transition and output probabilities,so that an HMM does not need to be explicitly stored foreach word.We have implemented the n-best search efficiently and a passthrough 43,000 phonetic index entries takes a few seconds.Including the signal processing (also done in software) thesystem takes between 5-10 seconds to produce the n-best hy-potheses per spoken word (running on a Sun SPARC-10, us-ing a value of n = 30).
After the HMM search is completewe have a list of the most likely matching words and theirassociated probabilities.4.
Semantic Co-Occurrence Fi lteringLet us consider an example where the user speaks the words"president" and "kennedy" into the system.
These mightresult in the following rank ordered lists of word hypotheses:p res ident :  (precedent, prescient, president...)kennedy:  (kennerty, kennedy, kemeny, remedy...)Rank N-Best After Semantic FilterFirst 111 (64%) 165 (95%)Top 5 \]53 (ss%) \]74 (\]00%)Top 10 163 (94%) 174 (100%)Top 30 174 (100%) 174 (100%)Table 1: Effect of filtering on word rank, for successful queriesPhone StateInsertion State?
Null StateFigure 4: HMM for Word MatchingIn neither case is the intended word the most likely, althoughboth are present and near the tops of the lists.
The next stepeffectively uses the text of the encyclopedia ( ccessed via theIR system) as a semantic filter.
In the encyclopedia the onlymembers of the above lists which co-occur in close proximityare =president" and "kennedy".
The intended words of thequery are semantically related and thus co-occur close to eachother (many times in this example) but the hypotheses thatare the result of recognition errors do not.Each spoken word is represented by an OR term containingits most likely word hypotheses.
These terms are combinedwith an AND operator having a proximity constraint on itsmembers.
For our example we might have:17 unsuccessful queries all failed because the correct wordwas not present in the top 30 hypotheses.
For each spokenword we compared the rank of the correct phonetic hypoth-esis output from the n-best component with that producedafter semantic o-occurrence filtering.
Table 1 shows thatsuch filtering finds relevant documents while simultaneouslyimproving recognition performance.Some of the successful queries are shown below (practicallyall of the test queries comprise two or three words).Example Queries:1 first atomic bomb2 assassinate kennedy3 xerox corporation4 planet jupiter5 gecko lizard6 chester carlson7 solid state physic8 discover penicillin9 dinosaur extinct10 mary queen scot(AND 15 (OR precedent, prescient, president, resident.
.
.
)(OR kennerty, kennedy, kemeny, remedy.. .
))This query is submitted to the IR system and segments oftext that satisfy the constraints are retrieved.
The word hy-potheses involved in each text segment are then identified.They are used to score the segments and also to rank the bestword hypotheses.
Scoring includes the phonetic likelihood ofthe hypotheses, the total number of occurrences of specifichypothesis combinations in all retrieved text segments, andtypical IR word weighting.5.
Eva luat ionWe created 100 queries, each composed of a few words thatcharacterize a topic of interest (e.g.
=Apollo space program").To evaluate the benefit of semantic co-occurrence filteringdirectly, we verified that the words we selected had entries inthe phonetic dictionary and that the encyclopedia containedat least one relevant article.Of the 100 queries, 83 were successful (i.e.
retrieved at leastone relewnt article in the top 25 titles).
If only the top wordhypotheses from the n-best component were inserted in theboolean queries, only 32 of the queries would succeed.
TheIn constructing the test queries, sometimes only a single wordimmediately came to mind for some topics.
In such cases wefound that a useful strategy for adding another word was touse either a name, hyponym or hypernym.
Thus the word=ant" was augmented by adding =insect" as a second word.Although less robust, single word queries are not precluded.Either their length may distinguish them (e.g.
=savonarola"and =nitroglycerin") or the IR query can be constructed byduplicating the OR term for the single word (the constraintis then word recurrence which still has value for filtering).6.
Discuss ionOur system demonstrates the feasibility of speech access toan information retrieval system in spite of the large vocabu-lary requirements of the task.
Although the system employsa fairly basic phonetic recognizer, it is able to locate articlesrelevant o a multi-word query even in eases where none ofthe words of the query are ranked topmost.
The applicabilityof semantic o-occurrence filtering is not limited to phonet-icaily oriented speech recognition.
The technique could beused with any recognizer that can produce rank ordered wordhypotheses.There are many opportunities for further development of the376system both in terms of performance improvement and ex-tensions to the interface and functionality.An improvement in recognition accuracy is expected by em-ploying context dependent phone models and error matri-ces.
Likewise, tied Ganssian mixture output distributionsgenerally provide better ecognition accuracy than the singleGanssian distributions we are currently using \[9\].
We alsoanticipate moving from speaker dependent recognition to aspeaker adaptive mode which will require far less trainingdata for new speakers.Concerning the interface, the necessity to speak uninflectedforms is awkward.
For example, a query about the film"Gone With The Wind" had to be stated as ``Go Wind".As described in Section 2.3, this can obviated by includinginflected phonetic spellings in the phonetic dictionary.
If therecognizer were adapted to recognize aset of command wordsthe system would gain considerable flexibility as aspects ofsearch and presentation could be directed by the user, partic-ularly user feedback based on the titles shown on the displayscreen.
The small number of words involved in the display ofthe titles constitutes a strong constraint on their recognition.Ideally, we would like to extend the system to handle con-tinuous speech and identify function words.
In this regard,integration with the MURAX system \[10\] would be an inter-esting development path.Phonetic Baseforms", Proceedings of the IEEE Interna-tional Conference on Acoustics, Speech and Signal Pro-cessing, 1984, pp.
42.5.1-4.8.
Dedina, M. J. and Nusbaum, H. C., "PRONOUNCE:A Program for Pronunciation by Analogy", ComputerSpeech and Language, vol.
5, 1991, pp.
55-64.9.
Rabiner, L. R. and Juang, B. H., Fundamentals ofSpeechRecognition, Prentice-Hall, Englewood Cliffs, New Jer-sey, 1992.10.
Kupiec, J. M., ``MURAX: A Robust Linguistic Ap-proach for Question-Answering Using an On-Line En-cydopedia", Proceedings of the Sixteenth InternationalACM SIGIR Conference on Research and Developmentin Information Retrieval, June, 1993, pp.
181-190.7.
AcknowledgmentsWe would like to thank our colleagues at Xerox PARC fortheir support and assistance, particularly Marcia Bush, JanPedersen and Doug Cutting.
The HMM structure for wordmatching resulted from a conversation with David Hanssler.This work was partially funded by National Science Founda-tion grant IRI-8719595.Re ferences1.
Glavitsch, U. and Schguble P., "A System for RetrievingSpeech Documents", Proceedings of the Fifteenth Inter-national AGM SIGIR Conference on Research and De-velopment in Information Retrieval, June 1992, pp.
168-176.2.
Olavitsch, U. and Sch~uble P., "Assessing the RetrievalEffectiveness ofa Speech Retrieval System by SimulatingRecognition Errors", These Proceedings.3.
Cutting, D. R., Pedersen, J. Halvorsen P.-K., "AnObject-Oriented Architecture for Text Retrieval", Con.ferenee Proceedings of RIAO'91, Intelligent Text andImage Handling, Barcelona, Spain, April 1991, pp.
285-298.4.
The Academic American Encyclopedia, Grolier Elec-tronic Publishing, Danbury, Connecticut, 1990.5.
Lamel, L., Kassel, R. and Seneff, S., "Speech databasedevelopment: Design and analysis of the acoustic-phonetic corpus.
", Proceedings, DARPA Speech Recog-nition Workshop, Rpt.
No.
SAIC-86/1546, 1986, pp.
1-61-68.6.
Moby Pronunciator II, Grady Ward, Arcata CA, 1993.7.
Lucassen, J. M. and Mercer, R. L., ``An InformationTheoretic Approach to the automatic Determination of377
