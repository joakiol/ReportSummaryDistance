CONTENT SELECTION AND ORGANIZATIONAS A PROCESS INVOLVING COMPROMISESHelmut HoracekUniversitiit Bielefeld, Fakult/it ffiir Linguistik und LiteraturwissenschaftUniversitiitsstr.
25, 33615 Bielefeld, DeutschlandABSTRACTUnderstanding a fairly complex message may demand anincreasing degree of effort on behalf of the addressee, a factthat has been neglected almost completely in automated ap-proaches to natural language generation so far.
Encounteringthis problam requires making compromises by reducing thedegree of detail in which information is presented, or byexplicitly expressing information left implicit otherwise.We identify factors that influence the comprehension effort,and we develop a model that indicates a rough quantifiedestimate for this effort.
We illustrate these ideas by exam-ples of explanations comprising a considerable number ofarguments, and we discuss potential impacts of  thesemeasurements on the process of composing a message bymaking compromises.1.
MOTIVATIONCommunication i  natural language may occasionally fail ifthe effort associated with mentally captaring the informationconveyed becomes too'high.
In order to avoid this problem,generation programs must have moderately accurate stimat-es at their disposal, that capture the concepts "degree o fex -plicitness/implicimess" and Mrnount o f  information~ degreeo f  detail" to give an indication of the effort associated withunderstanding the messages they create 1.We illustrate these considerations by'discussing expla-nations that illustrate proposals made by an expert system.The system assigns employees to rooms, thereby meetingrequirements o provide resources needed, to avoid socialconflicts, etc.
These requirements break down intoconstraints, which are relevant for the problem solvingprocess, and into justifications, which give the domain-specific rationale behind these constraints.
When the systemcomes up with a set of kssignments for employees (here: A,B, C, and D) to rooms (here: 1, 2, and 3), the user may askquestions about hypothetical ssignments deviating fromthe proposed solution,l expecting the system to find out arelevant part of the problem specifications which are respon-sible for the infeasibility of the assignments focussed on.Figure 1 represents he text plan of an explanation tellingwhy C and D must be ifi room 3.
The plan breaks down intotwo subplans addressing rooms 1 and 2, respectively, eachof which consists of arguments and justifications.We believe that hese considerations apply to oral as well as towritten presentations, since being forced to reread portions of a textfrequently iz hardly desirable.
A similar problem to this issue lies inadequately determining the node size in a hypertext document.There are several possibilities to express this text plan (orsome portion of it) in terms of natural anguage texts.
Thesimplest version (only comprising propositions 1 ands) is1) Room I must be assigned to a. and room 2 must be assignedroB.which is easily comprehensible, but hardly informative.Hence, more details hould be added, yielding, for instance2) Room 1 must be assigned to A because A is a group leader.and room 2 mus?
be assigned to B because B is a smoker(additionally comprising propositions It and ~).3) Room 1 must be assigned to a because a as a group leadermust be in a big single room and room I is the only bigsingle room available.
Room 2 must be assigned to $because B must not share a room with either C or D, since Bis" a smoker, and room 2 is" the last single room out of  tworooms left (comprising propositions I to ~).Neither of these explanations seems to be entirely satis-factory.
Whereas text 2) leaves too much burden on theaddressee's inferential capabilities, text 3) is simply toolong.
Much is left implicit in text ~2), which might berecoverable in principle, provided the addressee is wellacquainted with the domain regularities (for instance, thatgroup leaders must be assigned to big single rooms), but itis doubtful whether the addressee will really succeed in doingso.
In text 3), we suspect, the addressee might easily forgetsome part of the argumentation before the explanation iscompleted.
Hence, some compromise is required, like:REA~)NI room 1 isassigned toJ USTIFICATIONn~ sA must be ina big single roomELABORATIONA is a group leader4 1 is the onlbig single room~STREASON ?/$ room2is \assigned toB\LIST~6 room 2is the last singlek room out of two rooms leftJUSTIFICATION~ Bisa smoker~B "s room must be dtt'lerentfrom C's and D's roomsFigure 1: A text structure including arguments in fifll detail2217th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 19944) Room 1 must be assigned to a because A mast be in a bigsingle room, and room 2 must be assigned to B because Bmast not share a room with either C or D, and because room 2is the last single room out o f  tree rooms left (comprisingpropositions 1, 2, $, 6 and Z cutting off  the justifications).5) Room 1 mast be assigned to a because a as a group leadermust be in a big single room and room 1 is the only bigsingle room available.
And room 2 must be assigned to B(comprising propositions I to 4, and elaborating on 1).We believe that variants 4) and 5) are fairly comprehensibleand provide some useful information, but not all that isavailable.
However, if the explanation seeking person isinterested in further detail, he/she may ask for justificationsto text 4), and for elaborations of text 5~In the following, we briefly review the contributions to theconcepts "effort required to understand a message" and "degreeo f  detail  entailed in a message" made in the field so far.
Wedescribe a first sketch of a formal model that captures thesetwo concepts and accounts for the compensative effectbetween them.
We discuss examples which illustrate thetension between informativeness and comprehensibilityincluding possible compromises between these two factors.2.
PREVIOUS APPROACHESThere is ample evidence from psychological experimentsthat humans draw causal inferences during reading to dosegaps left implicit in narrative texts (\[ 12\]).
This reasoning ispresumably done by building forward-oriented xpectationsand by drawing backward-driven inferences \[5\].
In assessingthe processing effort associated with understanding therelation between two subsequent sentences, \[ 18\] distinguishbetween "direct causes", which can easily be understood, and"indirect causes" and "urtrelated facts ~, which both requireconsiderable r asoning effort - to infer or, at l~ast, guess arelation or to resign in the attempt of doing so.
Thedistinction between "direct" and "indirect causes" has beenmade on a statistical basis, which expresses comrnonalitiesabout default expectations holding across a set of subjects 2.In automated approaches tonatural language generation, theaddressee's comprehension process is anticipated in a fewaspects only.
They comprise: the avoidance of a potentialambiguity caused by a particular referring expression \[10\],the inferability of additional information to convey fromthose propositions uttered explicitly \[7\], and the proper useof basic level categories like "dog" and "house" to avoid falseimplicatures \[ 16\].
However, the mechanisms developed aremainly motivated by detecting potential sotrrces of misinter-pretations and by avoiding the production of redundant text.In addition, active checking of the user's understanding hasbeen incorporated in a system concerned with providingexplanations 12\], and a selection mechanism is used in areactive approach by Moore and Swartout \[15\], which incor-Within the cases classified as "indirect causes', some xpectationstriggered by the fact presented in f'ust place constituted " irestcauseg" of the fact presented in second place, while the "directcauses" of some facts presented in second place were too specific tobe expectations triggered by the facts presented in first place.porates decisions about the most promising explanationstrategy under the context of a given situation.Some series of experiments have been carried out to obtainempirical evidence about how much information humanscan typically understand, and what can be considered toomuch to be memorized without problems.
Efficiency inlanguage processing is then influenced to a great extent byfinding an optimal mixtt~e of old and new informationaccording to the working memory's capacity \[11\], which isa capability that may vary strongly among individualshence, it is almost impossible to identify precise qtmntifi-cations on general grounds.
The only relevant experimentswe know of have been reported on a long time ago in I131,which have resulted in the concept of  the magical numberseven plus~minus two.
The major reason for this situationis that the variety of knowledge that helps humans in build-ing conceptual chunks is enormous, and this knowledgecauses ignificant differences in their memory capabilities.Very few systems developed in the field have the capabilityof producing messages in significantly varying degrees ofdetail when starting from comparable content specifications.Hierarchical organization is exploited for content selection(in BLAH \[19\] and in EPICURE \[4\]).
The hierarchy is cutoff at some level, eventually due to the user's assumeddomain expertise, and only more abstract specifications areincluded in the message to be composed.
Some other appro-aches addressing this issue are PAULINE 19\] and the appro-ach by Bateman and Paris \[1\].
Hence, the motivationsunderlying the texts produced are time constraints and otherpragmatic parameters, and effective term selectiontechniques based on the addressee's rol~ and commaud ofdomain knowledge.
However, there is no evidence in thesesystems about the relation between the pieces of textactually generated and the precise communicative effect heymight achieve (\[1\] constitutes an exception in this sense).As \[14\] have pointed out, the assumption underlying manyof today's text planners 3 that discourse is composed of hier-archically structured segments ina completely recatrsive wayis inadequate for extended explanations.
Hence, if saying "X"is assumed to be comprehensible, and saying "Y" as well.then it is concluded that saying "X and Y" is also a suitablemessage.
Within a certain range, this assumption is reason-able (for instance, mentioning the track in addition to atrain's departure time is perfect), but this is clearly notwithout limitations (for instance, the description of a non-trivial route may easily become too complex).Hence, generationsystems never have developed a quantifiedmodel of the communicative effort involved in.
under-standing their messages - but this has not been necessary sofar: The situation description from which a communicativeact is to be produced is hardly detailed and accurate noughto allow tor the rich variety of reactions humans are able toproduce under comparable circumstances, and the amount ofinformation to convey is hardly ever so large that techniquesto mamtam the addressee's attention are a serious concern.3 This assumption is based on Cohen and Levesquc's model ofrational action and interaction 13\].222117th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 19943.
TOWARDS A FORMAL MODEL3.1.
Choos ing  Degrees  o f  Exp l i c i tnessIn general terms, the goal in selecting a suitable degree ofexplicitness and implicitness lies in following the coneeptidentified in the course of the experiments carried out by\[18\], namely leaving: "direct causes" to be inferred by thereader, and expressing "indirect causes" explicitly.
Thiso i  ?
?
strategy tends to achieve a balance between pieces of refor-mation expressed exlSlieitly and others left implicit, in thespirit of the discussion of explanations given in section 1.In the approach adopted in \[8\], we have envisioned this goalby exploiting inference patterns based on the relationsbetween generic regularities and indivuals involved inprinciple-based explanations, thereby also taking scalarimplicature \[6\] nto account.
This reasoning is based on therelevance that each oflthese pieces of information bears in anexplanation context for understanding the rationale behindthe decisions made (see also the examples in sections I and3.2).
As argued in \[8.1, the mechanism developed is extend-able to capture at least he following types of inferences:?
Inferring plausible sequences of actions; by exploitingexpectations about intermediate steps indescriptions ofaction seqtfences can and should be omitted to produceless verbose and more natural text (see \[12\] and \[18\]).- Inferring causal relations between action and theirresults; reference to a problem-solving step to beaccomplished can be established by the action to be per-formed or by the State to be achieved, according to thelinguistic repertoire available (see \[ I7\]).In our application, the distinction between "direct" and"indirect causes" is implemented by leaving the results ofchained inference steps implicit under particular circum-stances only: the results of scalar implicature (and logicaldeduction) are left to be uncovered by the addressee's infer-ence capability, even if combined with other inferences to bemade.
Eventually, this strategy may be refined if the effectof default expectations in the domain at hand is betterunderstood and can be captured more systematically.We conceive that it is also possible to pursue otherstrategies, either by producing more concise utterances andthereby increasing the burden on the addressee's inferentialcapability, or by expressing more inference steps explicitly.However, we do not igo into potential variations of thisaspect here, we simply adopt the approach of selecting the"best" balance between expressing information explicitly orimplicitly, on the basis of the heuristics incorporated.3.2.
Deciding Upon Degrees of DetailIn order to decide whether the complexity of a message isbeyond what the addressee can reasonably be assumed tounderstand with convenience, we propose the computationof three measures that serve as partial indications for thispurpose: (1) The number of entities entailed in the proposi-tional representation f the message; (2) The number of pre-dicates used to build assertions about hese entities; (3) The?
number of relations holding between entities and predicates.In order to define entities and predicates for this purpose, werely on the domain ontology of the underlying world model.The motivation behind lies in the assumption that, if thecommunicative purpose of the message is recognized, theconceptualization of the addressee should mirror to a largeextent his categorization.
I  the office planniug domain, forinstance, "employees', "rooms', "resources" constituteentities, while "next-to', "assigned-to" constitute predicates.As a total measure for complexity we propose the formulamax (e+p, r, 2*0, where.p, e, r, i represent the number ofentities, predicates, relations, and inferences, respectively.
Inthe texts we are dealing with, these factors tend to be rough-ly the same; by the consideration fall factors, we intend totreat also other types of texts adequately: in enumerations,for instance, the number of relations decreases in compar-ison to the number of entities and predicates involved, whileit increases if network:like r lations between a set of entitiesand a set of predicates are to be expressed.Returning back to the examples discussed in section 1, weare able to justify our assessments in some formal sense.Figure 2 illustrates the complexity measures computed foreach of these sentences, confirming the intuitive assessmentmade in section 1: the measurements introduced indicate afair correspondence with Miller's magical number seven.The categorization into what constitutes an entity and whatconstitutes a predicate is problematical, since there areseveral sources of inaccuracies in this approach: for instance,complications due to vague xpressions and due to qlmntifi-cation relations, and conceptualizations made by theaddressee, which may differ significantly from those embo-died in the system's conception consisting of entities andrelations.
We may encounter this problem by incrementingthe calculations in case terminological transformations orlexical operations involve significant changes in the repre-sentation of the message.
Eventually, the calculationschema must be augmented in case involved quantificationrelations occur more frequently than in our application.In cases where the complexity assessments indicate potentialcomprehension problems on behalf of the addressee, severalstrategies are possible: a simple, but risky one, in which thecomplex utterance is fully elaborated, and two more sensiblestrategies, One of them consists in reducing the degree ofdetail in a coherent way (i.e., not leaving out detailsarbitrarily, but orienting this reduction on structuralregularities), especially if demanded by time and/or spacelinfitations, and the other one consists in re, organizing thetext so that additional structuring hints in the text producedenable the addressee to perform intermediate conceptuali-zation already with parts of the information' presented.sentence numbernumber of entities (e)number of predicates (p)number of relations (r)number of inferences (i)total = max (e+p, r, 2"i)1) 2)4 61 14 6o43) 4) 5)10 7 63 3 113 9 7110 1 3 7Figure 2: Complexity assessments for some example sentences2237th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994The choice among alternatives hould prefereably beinterest-based.
For instance, the choice between alternatives4) and 5) in section I may be made in favor of text 4) if theuser wants to vary the relative significance of constraints indefning problem specifications (therefore, he/she wants toknow which ones prove relevant for the aspect in question).Alternative 5) is preferable for a user who wants to learn therationale behind system decisions, which particularlyincludes associating justifications with constraints.4, CONCLUSIONA mechanism assessing the comprehension effort of theaddressee of a text or an utterance certainly seems to be ofinterest for theoretical models of natural language generationprocesses.
While the proposal entailed in our method canhardly be considered a psychologically motivated approach,we believe that it contributes to the understanding of whatingredients a performance-oriented mo el of natural languagegeneration should consist of, and how interaction betweenthese ingredients can suitably be organized.Apart from a purely theoretical perspective, we believe thatthese considerations are also relevant in practice, even if anassessment of the comprehension effort of the addressee doesnot manifest itself in the majority of generator programsthemselves - which also may not even prove necessary in agood deal of applications.
Hence, for simpler, eventuallyapplication-oriented systems, taking these considerationsinto account will help in making explicit the assumptionsunderlying the simplifications embodied, so that conditionsfor an eventual transfer to other domains become moreevident - hence, the assumptions must hold across domains.However, it will be important to know about a system'slimitations, where they manifest themselves, and when theyare likely to weaken the system's usefulness.Conditions under which assessing the complexity of amessage to be generated may prove benefieial, hold in atleast the following types of application:?
Presenting a significant quantity of records elected froma database; when envisioning an ambitious, flexiblepresentation, summary facilities play a crucial role basedon suitable assessments in the spirit of our method.?
Generating business reports including a considerableamount of (heterogeneous) data, where summaries alsoplay an important role; in that genre, it is the contextualinferability of information from some key propositionsconveyed, which constitute the main difficulty.
Hence, aquality assessment function has to take this particularaspect into account, whereas other influences on the easeof comprehension can be widely neglected.?
Explaining an issue of at least moderate complexity (forinstance, presenting a chain of rules or a set ofconstraints with underlying justifications) inexplanationgeneration; all aspects neglected in report generation(degree of detail, slructure, acquaintance with terms) beara significant amount of relevance here, and they shouldbe incorporated in a suitable quality function.REFERENCES\[1\] J. Bateman, C. Paris: Phrasing a Text in Terms the Usercan Understand.
In Proc.
of IJCAI-89, pp.
1511-1517,Detroit, 1989.\[2\] A. Cawsey: Generating Explanatory Discourse.
In CurrentIssues in Natural Lanzuage Generation, R. Dale, C.Mellish, M. Zock (eds.
), pp.
75-102, Academic Press,1990.\[3l P. Cohen, H. Levesque: Speech Acts and Rationality.
InProe.
of ACL-85, pp.
49-60, 1985.\[4\] R. Dale: Cooking Up Referring Expressions.
In Proe.
ofA CL-89, pp.
68-75, Vancouver, 1989.\[5\] A. Gamham: Testing Psychological Theories about Infer-ence Making.
In Memory and Cognition 10(4), pp.
341-349, 1982.\[6\] J. Hirsehberg: A Theory of Scalar bnplicature.
GarlandPress, New York, 1991.\[7\] H. Horaeek: Exploiting Conversational lmplicature forGenerating Concise Explanations.
In Proc.
of EACL-9!,Vol.
1, pp.
191-193, Berlin, 1991.\[8\] H. Horacek: How to Avoid Explaning Obvious Things(Without Omitting Central Information), to appear inECAI-94.\[91 E. Hovy: Pragmatics and Natural Language Generation.
InArtificial Intelligence, 43, pp.
153-197, 1990.\[10\] T. Jameson, W. Wahlster: User Modeling in AnaphoraGeneration."
Ellipsis and Definite Description.
In Proe.
ofECAI-82, pp.
222-227, Orsay, 1982.\[11\] M. Just, P. Carpenter: A Capacity Theory of Compre-hension: Individual Differences in Working Memory.
InPsychological Review 99, pp.
122-149, 1992.\[12\] W. Kintseh, J. Keenan, G. McKoon: Memory for Infor-mation Inferred During Reading.
In The Representation fMeaning in Memory, W. Kintsch (ed.
), Earlbaum,HiUsdale, New Jersey, 1974.\[13J G. Miller: The Magical Number Seven Plus or Minus Two:Some Limits on Our Capacity for Processing Information.In Psychological Review 63, pp.
81-97, 1956.\[141 D. Mooney, S. Carberry, K. McCoy: The Generation ofHigh-Level Structure for Extended Explanations.
In Proc.of COLING-90, pp.
276~281, Helsinki, 1990.\[15\] J. Moore, W. Swartout: A Reactive Approach to Eapla-nation.
In Proe.
of IJCAI-89, pp.
1504-1510, Detroit,1989.\[16\] E. Reiter: Generating Descriptions that Exploit a User'sDomain Knowledge.
In Current Issues in Natural LanguaeeGeneration, R. Dale, C. MeUish, M. Zoek (eds.
), pp.
257-285, Academic Press, New York, 1990.\[17\] D. R6sner: Intentions, Rhetoric, or Discourse Relations?A Case .from Multilingual Document Generation.
InIntentionalitv and Structure in Discourse .Relations,Workshop held at the ACL-93, O. Rambow (ed.
), pp.
106-109, Columbus, Ohio, 1993.\[181 M. Thfiring, K. Wender: Ober kausale inferenzen beimLesen.
In Spraehe und Ko~nition 2. pp.
76-86, 1985.\[191 J. Weiner: BLAH: A System which Explains itsReasoning.
In Artificial Intelligence, 15(1), pp.
19-48.1980.224
