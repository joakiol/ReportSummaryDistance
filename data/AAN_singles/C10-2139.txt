Coling 2010: Poster Volume, pages 1211?1219,Beijing, August 2010Word-Based and Character-Based Word Segmentation Models:Comparison and CombinationWeiwei SunDepartment of Computational Linguistics, Saarland UniversityGerman Research Center for Artificial Intelligence (DFKI)wsun@coli.uni-saarland.deAbstractWe present a theoretical and empiricalcomparative analysis of the two domi-nant categories of approaches in Chineseword segmentation: word-based modelsand character-based models.
We showthat, in spite of similar performance over-all, the two models produce different dis-tribution of segmentation errors, in a waythat can be explained by theoretical prop-erties of the two models.
The analysis isfurther exploited to improve segmentationaccuracy by integrating a word-based seg-menter and a character-based segmenter.A Bootstrap Aggregating model is pro-posed.
By letting multiple segmentersvote, our model improves segmentationconsistently on the four different data setsfrom the second SIGHAN bakeoff.1 IntroductionTo find the basic language units, i.e.
words,segmentation is a necessary initial step for Chi-nese language processing.
There are two domi-nant models for Chinese word segmentation.
Thefirst one is what we call ?word-based?
approach,where the basic predicting units are words them-selves.
This kind of segmenters sequentiallydecides whether the local sequence of charac-ters make up a word.
This word-by-word ap-proach ranges from naive maximum matching(Chen and Liu, 1992) to complex solution basedon semi-Markov conditional random fields (CRF)(Andrew, 2006).
The second is ?character-based?approach, where basic processing units are char-acters which compose words.
Segmentation isformulated as a classification problem to predictwhether a character locates at the beginning of,inside or at the end of a word.
This character-by-character method was first proposed in (Xue,2003), and a number of sequence labeling algo-rithms have been exploited.This paper is concerned with the behavior ofdifferent segmentation models in general.
Wepresent a theoretical and empirical comparativeanalysis of the two dominant approaches.
The-oretically, these approaches are different.
Theword-based models do prediction on a dynamicsequence of possible words, while character-based models on a static character sequence.
Theformer models have a stronger ability to representword token features for disambiguation, while thelatter models can better induce a word from its in-ternal structure.
For empirical analysis, we im-plement two segmenters, both using the Passive-Aggressive algorithm (Crammer et al, 2006) toestimate parameters.
Our experiments indicatethat despite similar performance in terms of over-all F-score, the two models produce differenttypes of errors, in a way that can be explained bytheoretical properties.
We will present a detailedanalysis that reveals important differences of thetwo methods in Sec.
4.The two types of approaches exhibit differ-ent behaviors, and each segmentation model hasstrengths and weaknesses.
We further consider in-tegrating word-based and character-based modelsin order to exploit their complementary strengthsand thereby improve segmentation accuracy be-yond what is possible by either model in isola-tion.
We present a Bootstrap Aggregating modelto combine multiple segmentation systems.
By1211letting multiple segmenters vote, our combinationmodel improves accuracy consistently on all thefour different segmentation data sets from the sec-ond SIGHAN bakeoff.
We also compare our inte-grating system to the state-of-the-art segmentationsystems.
Our system obtains the highest reportedF-scores on three data sets.2 Two Methods for Word SegmentationFirst of all, we distinguish two kinds of ?words?
:(1) Words in dictionary are word types; (2) Wordsin sentences are word tokens.
The goal of wordsegmentation is to identify word tokens in a run-ning text, where a large dictionary (i.e.
list ofword types) and annotated corpora may be avail-able.
From the view of token, we divide segmen-tation models into two main categories: word-based models and character-based models.
Thereare two key points of a segmentation model: (1)How to decide whether a local sequence of char-acters is a word?
(2) How to do disambiguation ifambiguous segmentation occurs?
For each model,we separately discuss the strategies for word pre-diction and segmentation disambiguation.2.1 Word-Based ApproachIt may be the most natural idea for segmentationto find word tokens one by one.
This kind ofsegmenters read the input sentences from left toright, predict whether current piece of continu-ous characters is a word token.
After one wordis found, segmenters move on and search for nextpossible word.
There are different strategies forthe word prediction and disambiguation problems.Take for example maximum matching, which wasa popular algorithm at the early stage of research(Chen and Liu, 1992).
For word prediction, if asequence of characters appears in a dictionary, itis taken as a word candidate.
For segmentationdisambiguation, if more than one word types arematched, the algorithm chooses the longest one.In the last several years, machine learning tech-niques are employed to improve word-based seg-mentation, where the above two problems aresolved in a uniform model.
Given a sequence ofcharacters c ?
Cn (n is the number of characters),denote a segmented sequence of words w ?
Wm(m is the number of words, i.e.
m varies with w),and a function GEN that enumerates a set of seg-mentation candidates GEN(c) for c. In general,a segmenter solves the following ?argmax?
prob-lem:w?
= arg maxw?GEN(c)?>?
(c,w) (1)= arg maxw?GEN(c)?>|w|?i=1?
(c, w[1:i]) (2)where ?
and ?
are global and local feature mapsand ?
is the parameter vector to learn.
The innerproduct ?>?
(c, w[1:i]) can been seen as the con-fidence score of whether wi is a word.
The dis-ambiguation takes into account confidence scoreof each word, by using the sum of local scoresas its criteria.
Markov assumption is neces-sary for computation, so ?
is usually defined ona limited history.
Perceptron and semi-MarkovCRFs were used to estimate ?
in previous work(Zhang and Clark, 2007; Andrew, 2006).2.2 Character-Based ApproachMost previous data-driven segmentation solutionstook an alternative, character-based view.
This ap-proach observes that by classifying characters asdifferent positions in words, segmentation can betreated as a sequence labeling problem, assigninglabels to the characters in a sentence indicatingwhether a character ci is a single character word(S) or the begin (B), middle (I) or end (E) of amulti-character word.
For word prediction, wordtokens are inferred based on the character classes.The main difficulty of this model is character am-biguity that most Chinese characters can occur indifferent positions within different words.
Linearmodels are also popular for character disambigua-tion (i.e.
segmentation disambiguation).
Denotea sequence of character labels y ?
Yn, a linearmodel is defined as:y?
= arg maxy?Y |c|?>?
(c,y) (3)= arg maxy?Y |c|?>|c|?i=1?
(c, y[1:i]) (4)Note that local feature map ?
is defined onlyon the sequence of characters and their labels.1212Several discriminative models have been ex-ploited for parameter estimation, including per-ceptron, CRFs, and discriminative latent variableCRFs (Jiang et al, 2009; Tseng, 2005; Sun et al,2009b).2.3 Theoretical ComparisonTheoretically, the two types of models are differ-ent.
We compare them from four aspects.2.3.1 Internal Structure of WordsChinese words have internal structures.
In mostcases, Chinese character is a morpheme whichis the smallest meaningful unit of the language.Though we cannot exactly infer the meaning of aword from its character components, the characterstructure is still meaningful.
Partially characteriz-ing the internal structures of words, one advantageof character-based models is the ability to inducenew words.
E.g., character ?/person?
is usuallyused as a suffix meaning ?one kind of people?.
Ifa segmenter never sees ?/worker?
in train-ing data, it may still rightly recognize this wordby analyzing the prefix ?/work?
with label BIand the suffix ??
with label E. In contrast, cur-rent word-based models only utilize the weightedfeatures as word prediction criteria, and thus wordformation information is not well explored.
Formore details about Chinese word fomation, see(Sun et al, 2009a).2.3.2 Linearity and NonlinearityA majority of structured prediction models arelinear models in the sense that the score func-tions are linear combination of parameters.
Bothprevious solutions for word-based and character-based systems utilize linear models.
However,both ?linear?
models incur nonlinearity to someextent.
In general, a sequence classification it-self involves nonlinearity in a way that the featuresof current token usually encode previous state in-formation which is linear combination of featuresof previous tokens.
The interested readers mayconsult (Liang et al, 2008) for preliminary dis-cussion about the nonlinearity in structured mod-els.
This kind of nonlinearity exists in both word-based and character-based models.
In addition, inmost character-based models, a word should takea S label or start with a B label, end with E label,and only have I label inside.
This inductive wayfor word prediction actually behaves nonlinearly.2.3.3 Dynamic Tokens or Static TokensSince word-based models take the sum of partscore of each individual word token, it increasesthe upper bound of the whole score to segmentmore words.
As a result, word-based segmentertends to segment words into smaller pieces.
A dif-ficult case occurs when a word token w consistsof some word types which could be separated aswords on their own.
In such cases a word-basedsegmenter more easily splits the word into indi-vidual words.
For example, in the phrase ?/4300 /meter (4300 meters)?, the numeral??
consists of two individual numeraltypes ? (4000)?
and ?(300)?.
A word-based segmenter more easily made a mistake tosegment two word tokens.
This phenomenon isvery common in named entities.2.3.4 Word Token or Word Type FeaturesIn character-based models, features are usuallydefined by the character information in the neigh-boring n-character window.
Despite a large setof valuable features that could be expressed, it isslightly less natural to encode predicted word to-ken information.
On the contrary, taking wordsas dynamic tokens, it is very easy to define wordtoken features in a word-based model.
Word-based segmenters hence have greater representa-tional power.
Despite of the lack of word tokenrepresentation ability, character-based segmenterscan use word type features by looking up a dic-tionary.
For example, if a local sequence of char-acters following current token matches a word ina dictionary; these word types can be used as fea-tures.
If a string matches a word type, it has a veryhigh probability (ca.
90%) to be a word token.So word type features are good approximation ofword token features.3 Baseline SystemsFor empirical analysis, we implement segmentersin word-based and character-based architecturesrespectively.
We introduce them from three as-pects: basic models, parameter estimation andfeature selection.1213Algorithm 1: The PA learning procedure.input : Data {(xt,yt), t = 1, 2, ..., n}Initialize: w ?
(0, ..., 0)1for I = 1, 2, ... do2for t = 1, ..., n do3Predict: y?t =4arg maxy?GEN(xt) w>?
(xt,y)Suffer loss: lt = ?
(yt,y?t ) +5w>?
(xt,y?t )?
w>?
(xt,yt)Set: ?t = lt||?
(xt,y?t )??
(xt,yt)||2+0.5C6Update:7w ?
w + ?t(?(xt,yt)??
(xt,y?t ))end8end93.1 ModelsFor both word-based and character-based seg-menters, we use linear models introduced in thesection above.
We use a first order Markovmodels for training and testing.
In particu-lar, for word-based segmenter, the local featuremap ?
(c, w[1:i]) is defined only on c, wi?1 andwi, and thereby Eq.
2 is defined as w?
=arg maxw?GEN(c) ?>?|w|i=1 ?
(c, wi?1, wi).
Thismodel has a first-order Semi-Markov structure.For decoding, Zhang and Clark (2007) used abeam search algorithm to get approximate solu-tions, and Sarawagi and Cohen (2004) introduceda Viterbi style algorithm for exact inference.
Sincethe exact inference algorithm is efficient enough,we use this algorithm in our segmenter at bothtraining and testing time.For our character-based segmenter, the localfeature map ?
(c, y[1:i]) is defined on c, yi?1and yi, and Eq.
4 is defined as y?
=arg maxy?Y |c| ?>?|c|i=1 ?
(?, yi?1, yi).
In ourcharacter-based segmenter, we also use a Viterbialgorithm for decoding.3.2 LearningWe adopt Passive-Aggressive (PA) framework(Crammer et al, 2006), a family of margin basedonline learning algorithms, for the parameter es-timation.
It is fast and easy to implement.
Alg.1 illustrates the learning procedure.
The param-eter vector w is initialized to (0, ..., 0).
A PAlearner processes all the instances (t is from 1to n) in each iteration (I).
If current hypothe-sis (w) fails to predict xt, the learner update wthrough calculating the loss lt and the differencebetween ?
(xt,y?t ) and ?
(xt,yt) (line 5-7).
Thereare three variants in the update step.
We here onlypresent the PA-II rule1, which performs best in ourexperiments.The PA algorithm utilizes a paradigm of cost-sensitive learning to resolve structured prediction.A cost function ?
is necessary to calculate the losslt (line 5).
For every pair of labels (y?,y), usersshould define a cost ?
(y?,y) associated with pre-dicting y?
when the correct label is y. ?
should bedefined differently for different purposes.
Thereare two natural costs for segmentation: (1) sumof the number of wrong and missed word predic-tions and (2) sum of the number of wrongly clas-sified characters.
We tried both cost functions forboth models.
We find that the first one is suitablefor word-based segmenter and the second one issuitable for character-based segmenter.
We do notreport segmentation performance with ?weaker?cost in later sections.
C (in line 6) is the slack vari-able.
In our experiments, the segmentation per-formance is not sensitive to C .
In the followingexperiments, we set C = 1.3.3 Features3.3.1 Word-based SegmenterFor the convenience of illustration, we de-note a candidate word token wi with a contextcj?1[wi?1cj ...ck][wick+1...cl]cl+1.The character features includes,Boundary character unigram: cj , ck, ck+1, cland cl+1; Boundary character bigram: ckck+1 andclcl+1.Inside character unigram: cs (k + 1 < s < l);Inside character bigram: cscs+1 (k + 1 < s < l).Length of current word.Whether ck+1 and ck+1 are identical.Combination Features: ck+1 and cl,The word token features includes,Word Unigram: previous word wi?1 and cur-rent word wi; Word Bigram: wi?1wi.1See the original paper for more details.1214The identity of wi, if it is a Single characterword.Combination Features: wi?1 and length of wi,wi and length of wi?1.
ck+1 and length of wi, cland length of wi.3.3.2 Character-based SegmenterWe use the exact same feature templates dis-cribed in (Sun et al, 2009b).
The features are di-vided into two types: character features and wordtype features.
Note that the word type featuresare indicator functions that fire when the localcharacter sequence matches a word unigram orbigram.
Dictionaries containing word unigramsand bigrams was collected from the training data.Limited to the document length, we do not givethe discription for the features.
We suggest read-ers to refer to the original paper for details.4 Empirical AnalysisWe present a series of experiments that relate seg-mentation performance to a set of properties of in-put words.
We argue that the results can be corre-lated to specific theoretical aspects of each model.4.1 Experimental SettingWe used the data provided by the second SIGHANBakeoff (Emerson, 2005) to test the two segmen-tation models.
The data contains four corporafrom different sources: Academia Sinica Corpus(AS), City University of Hong Kong (CU), Mi-crosoft Research Asia (MSR), and Peking Univer-sity (PKU).
There is no fixed standard for Chineseword segmentation.
The four data sets above areannotated with different standards.
To catch gen-eral properties, we do experiments on all the fourdata sets.
Three metrics were used for evaluation:precision (P), recall (R) and balanced F-score (F)defined by 2PR/(P+R).4.2 Baseline PerformanceTab.
1 shows the performance of our two seg-menters.
Numbers of iterations are respectivelyset to 15 and 20 for our word-based segmenter andcharacter-based segmenter.
The word-based seg-menter performs slightly worse than the character-based segmenter.
This is different from the exper-iments reported in (Zhang and Clark, 2007).
WeModel P(%) R(%) FAS Character 94.8 94.7 94.7Word 93.5 94.8 94.2CU Character 95.5 94.6 95.0Word 94.4 94.7 94.6MSR Character 96.1 96.5 96.3Word 96.0 96.3 96.1PKU Character 94.6 94.9 94.8Word 94.7 94.3 94.5Table 1: Baseline performance.think the main reason is that we use a differentlearning architecture.4.3 Word Frequency Factors6065707580859095100OOV1 2 3-5 6-1011-100101-10001001-Recall (%)word occurances in training dataAS data setcharacter-basedword-based707580859095100OOV1 2 3-5 6-1011-100101-10001001-Recall (%)word occurances in training dataCU data setcharacter-basedword-based6065707580859095100OOV1 2 3-5 6-1011-100101-10001001-Recall (%)word occurances in training dataMSR data setcharacter-basedword-based6065707580859095100OOV1 2 3-5 6-1011-100101-10001001-Recall (%)word occurances in training dataPKU data setcharacter-basedword-basedFigure 1: Segmentation recall relative to goldword frequency.Our theoretical analysis also suggests thatcharacter-based has stronger word induction abil-ity because it focuses more on word internal struc-tures and thereby expresses more nonlinearity.
Totest the word induction ability, we present the re-call relative to word frequency.
If a word appearsin a training data many times, the learner usuallyworks in a ?memorizing?
way.
On the contrary,infrequent words should be correctly recognizedin a somehow ?inductive?
way.
Fig.
1 showsthe recall change relative to word frequency ineach training data.
Note that, the words with fre-quency 0 are out-of-vocabulary (OOV) words.
Wecan clearly see that character-based model outper-forms word-based model for infrequent word, es-pecially OOV words, recognition.
The ?memoriz-12157678808284868890929496981  2  3  4Precision(%)word lengthAS data setcharacter-basedword-based84868890929496981  2  3  4Precision(%)word lengthCU data setcharacter-basedword-based88899091929394959697981  2  3  4Precision(%)word lengthMSR data setcharacter-basedword-based78808284868890929496981  2  3  4Precision(%)word lengthPKU data setcharacter-basedword-based7678808284868890929496981  2  3  4Recall (%)word lengthAS data setcharacter-basedword-based78808284868890929496981  2  3  4Recall (%)word lengthCU data setcharacter-basedword-based88899091929394959697981  2  3  4Recall (%)word lengthMSR data setcharacter-basedword-based84868890929496981  2  3  4Recall (%)word lengthPKU data setcharacter-basedword-basedFigure 2: Segmentation precision/recall relative to gold word length in training data.ing?
ability of the twomodels is similar; on the ASand CU data sets, the word-based model performsslightly better.
Neither model is robust enoughto reliably segment unfamiliar words.
The recallof OOV words is much lower than in-vocabularywords.4.4 Length FactorsLength AS CU MSR PKU1 61254 19116 48092 459112 52268 18186 49472 498613 6990 2682 4652 51324 1417 759 2711 20595(+) 690 193 1946 656Table 2: Word length statistics on test sets.Tab.
2 shows the statistics of word countsrelative to word length on each test data sets.There are much less words with length more than4.
Analysis on long words may not be statis-tical significant, so we only present length fac-tors on small words (length is less than 5).
Fig.2 shows the precision/recall of both segmenta-tion models relative sentence length.
We can seethat word-based model tends to predict more sin-gle character words, but making more mistakes.Since about 50% word tokens are single-characterwords, this is one main source of error for word-segmenter.
This can be explained by theoreticalproperties of dynamic token prediction discussedin Sec.
2.3.3.
The score of a word boundaryassignment in a word-based segmenter is definedlike ?>?|w|i=1 ?
(c, w[1:i]).
The upper bound of thisscore varies with the length |w|.
If a segmen-tation result is with more fragments, i.e.
|w| islarger, the upper bound of its score is higher.
Asa result, in many cases, a word-based segmenterprefers shorter words, which may cause errors.4.5 Feature FactorsWe would like to measure the effect of featuresempirically.
In particular, we do not use dy-namic word token features in our word-based seg-menter, and word type features in our character-based segmenter as comparison with ?standard?segmenters.
The difference in performance can beseen as the contribution of word features.
Thereare obvious drops in both cases.
Though it isnot a fair comparison, word token features seemmore important, since the numerical decrease inthe word-based experiment is larger.word-based character-based?
+ ?
+AS 93.1 94.2 94.1 94.7CU 92.6 94.6 94.2 95.0MSR 95.7 96.1 95.8 96.3PKU 93.3 94.5 94.4 94.8Table 3: F-score of two segmenters, with (?)
andwithout (+) word token/type features.4.6 DiscussionThe experiments highlight the fundamental dif-ference between word-based and character-basedmodels, which enlighten us to design new mod-els.
The above analysis indicates that the theoret-ical differences cause different error distribution.1216The two approaches are either based on a particu-lar view of segmentation.
Our analysis points outseveral drawbacks of each one.
It may be help-ful for both models to overcome their shortcom-ings.
For example, one weakness of word-basedmodel is its word induction ability which is par-tially caused by its neglect of internal structure ofwords.
A word-based model may be improved bysolving this problem.5 System CombinationThe error analysis also suggests that there is stillspace for improvement, just by combining the twoexisting models.
Here, we introduce a classifierensemble method for system combination.5.1 Upper Bound of System CombinationTo get an upper bound of the improvement thatcan be obtained by combining the strengths ofeach model, we have performed an oracle exper-iment.
We think the optimal combination systemshould choose the right prediction when the twosegmenters do not agree with each other.
Thereis a gold segmenter that generates gold-standardsegmentation results.
In the oracle experiment, welet the three segmenters, i.e.
baseline segmentersand the gold segmenter, vote.
The three seg-menters output three segmentation results, whichare further transformed into IOB2 representa-tion (Ramshaw and Marcus, 1995).
Namely, eachcharacter has three B or I labels.
We assign eachcharacter an oracle label which is chosn by at leasttwo segmenters.
When the baseline segmentersare agree with each other, the gold segmenter can-not change the segmentation whether it is rightor wrong.
In the situation that the two baselinesegmenters disagree, the vote given by the goldsegmenter will decide the right prediction.
Thiskind of optimal performance is presented in Tab.4.
Compared these results with Tab.
1, we see asignificant increase in accuracy for the four datasets.
The upper bound of error reduction with sys-tem combination is over 30%.5.2 Our ModelBootstrap aggregating (Bagging) is a machinelearning ensemble meta-algorithm to improveclassification and regression models in terms ofP(%) R(%) F ER (%)AS 96.6 96.9 96.7 37.7CU 97.4 97.1 97.3 46.0MSR 97.5 97.7 97.6 35.1PKU 96.8 96.2 96.5 32.7Table 4: Upper bound for combination.
The errorreduction (ER) rate is a comparison between theF-score produced by the oracle combination sys-tem and the character-based system (see Tab.
1).stability and classification accuracy (Breiman,1996).
It also reduces variance and helps to avoidoverfitting.
Given a training set D of size n, Bag-ging generates m new training sets Di of sizen?
?
n, by sampling examples from D uniformly.The m models are fitted using the above m boot-strap samples and combined by voting (for classi-fication) or averaging the output (for regression).We propose a Bagging model to combine mul-tiple segmentation systems.
In the training phase,given a training set D of size n, our model gener-ates m new training sets Di of size 63.2% ?
n bysampling examples from D without replacement.Namely no example will be repeated in each Di.Each Di is separately used to train a word-basedsegmenter and a character-based segmenter.
Us-ing this strategy, we can get 2m weak segmenters.Note that the sampling strategy is different fromthe standard one.
Our experiment shows that thereis no significant difference between the two sam-pling strategies in terms of accuracy.
However,the non-placement strategy is more efficient.
Inthe segmentation phase, the 2m models outputs2m segmentation results, which are further trans-formed into IOB2 representation.
In other words,each character has 2m B or I labels.
The final seg-mentation is the voting result of these 2m labels.Note that since 2m is an even number, there maybe equal number of B and I labels.
In this case,our system prefer B to reduce error propagation.5.3 ResultsFig.
4 shows the influence of m in the baggingalgorithm.
Because each new data set Di in bag-ging algorithm is generated by a random proce-dure, the performance of all bagging experimentsare not the same.
To give a more stable evaluation,we repeat 5 experiments for each m and show the121793.59494.59595.59696.5AS CU MSR PKUPrecision(%)character-basedword-basedbagging9494.59595.59696.59797.5AS CU MSR PKURecall (%)character-basedword-basedbagging9494.59595.59696.597AS CU MSR PKUF-measurecharacter-basedword-basedbaggingFigure 3: Precision/Recall/F-score of different models.averaged F-score.
We can see that the baggingmodel taking two segmentation models as basicsystems consistently outperform the baseline sys-tems and the bagging model taking either modelin isolation as basic systems.
An interesting phe-nomenon is that the bagging method can also im-prove word-based models.
In contrast, there is nosignificant change in character-based models.9393.59494.59595.51  2  3  4  5  6  7  8  9  10 11 12 13F-measureNumber of sampling data sets mAS data setbaseline (C)baseline (W)character-baggingword-baggingbagging93.59494.59595.5961  2  3  4  5  6  7  8  9  10 11 12 13F-measureNumber of sampling data sets mCU data setbaseline (C)baseline (W)character-baggingword-baggingbagging93.59494.59595.59696.5971  2  3  4  5  6  7  8  9  10 11 12 13F-measureNumber of sampling data sets mMSR data setbaseline (C)baseline (W)character-baggingword-baggingbagging93.493.693.89494.294.494.694.89595.21  2  3  4  5  6  7  8  9  10 11 12 13F-measureNumber of sampling data sets mPKU data setbaseline (C)baseline (W)character-baggingword-baggingbaggingFigure 4: F-score of bagging models with differ-ent numbers of sampling data sets.
Character-bagging means that the bagging system builton the single character-based segmenter.
Word-bagging is named in the same way.Fig.
3 shows the precision, recall, F-score ofthe two baseline systems and our final system forwhich we generate m = 15 new data sets forbagging.
We can see significant improvementson the four datasets in terms of the balanced F-score.
The improvement of precision and recallare not consistent.
The improvement of AS andCU datasets is from the recall improvement; theimprovement of PKU datasets is from the preci-sion improvement.
We think the different perfor-mance is mainly because the four datasets are an-notated by using different standards.AS CU MSR PKU(Zhang et al, 2006) 95.1 95.1 97.1 95.1(Zhang and Clark, 2007) 94.6 95.1 97.2 94.5(Sun et al, 2009b) N/A 94.6 97.3 95.2This paper 95.2 95.6 96.9 95.2Table 5: Segmentation performance presented inprevious work and of our combination model.Tab.
5 summarizes the performance of our finalsystem and other systems reported in a majority ofprevious work.
The left most column indicates thereference of previous systems that represent state-of-the-art results.
The comparison of the accuracybetween our integrating system and the state-of-the-art segmentation systems in the literature in-dicates that our combination system is competi-tive with the best systems, obtaining the highestreported F-scores on three data sets.6 ConclusionWe have presented a thorough study of the dif-ference between word-based and character-basedsegmentation approaches for Chinese.
The the-oretical and empirical analysis provides insightsleading to better models.
The strengths and weak-nesses of the two methods are not exactly thesame.
To exploit their complementary strengths,we propose a Bagging model for system combi-nation.
Experiments show that the combinationstrategy is helpful.AcknowledgmentsThe work is supported by the project TAKE(Technologies for Advanced Knowledge Extrac-tion), funded under contract 01IW08003 by theGerman Federal Ministry of Education and Re-search.
The author is also funded by German Aca-demic Exchange Service (DAAD).1218ReferencesGalen Andrew.
2006.
A hybrid markov/semi-markov conditional random field for sequencesegmentation.
In Proceedings of the 2006 Con-ference on Empirical Methods in Natural Lan-guage Processing, pages 465?472.
Associationfor Computational Linguistics, Sydney, Aus-tralia.Leo Breiman.
1996.
Bagging predictors.
MachineLearning, 24(2):123?140.Keh-Jiann Chen and Shing-Huan Liu.
1992.
Wordidentification for mandarin Chinese sentences.In Proceedings of the 14th conference on Com-putational linguistics, pages 101?107.
Associ-ation for Computational Linguistics, Morris-town, NJ, USA.Koby Crammer, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
2006.
On-line passive-aggressive algorithms.
JOUR-NAL OF MACHINE LEARNING RESEARCH,7:551?585.Thomas Emerson.
2005.
The second internationalChinese word segmentation bakeoff.
In In Pro-ceedings of the Second SIGHAN Workshop onChinese Language Processing, pages 123?133.Wenbin Jiang, Liang Huang, and Qun Liu.
2009.Automatic adaptation of annotation standards:Chinese word segmentation and pos tagging ?a case study.
In Proceedings of the Joint Con-ference of the 47th Annual Meeting of the ACLand the 4th International Joint Conference onNatural Language Processing of the AFNLP,pages 522?530.
Association for ComputationalLinguistics, Suntec, Singapore.Percy Liang, Hal Daume?, III, and Dan Klein.2008.
Structure compilation: trading structurefor features.
In ICML ?08: Proceedings ofthe 25th international conference on Machinelearning, pages 592?599.
ACM, New York,NY, USA.L.
A. Ramshaw and M. P. Marcus.
1995.
Textchunking using transformation-based learning.In Proceedings of the 3rd ACL/SIGDAT Work-shop on Very Large Corpora, Cambridge, Mas-sachusetts, USA, pages 82?94.Sunita Sarawagi and William W. Cohen.
2004.Semi-markov conditional random fields for in-formation extraction.
In In Advances in Neu-ral Information Processing Systems 17, pages1185?1192.Weiwei Sun, Zhifang Sui, Meng Wang, and XinWang.
2009a.
Chinese semantic role label-ing with shallow parsing.
In Proceedings ofthe 2009 Conference on Empirical Methodsin Natural Language Processing, pages 1475?1483.
Association for Computational Linguis-tics, Singapore.Xu Sun, Yaozhong Zhang, Takuya Matsuzaki,Yoshimasa Tsuruoka, and Jun?ichi Tsujii.2009b.
A discriminative latent variable Chinesesegmenter with hybrid word/character informa-tion.
In Proceedings of Human Language Tech-nologies: The 2009 Annual Conference of theNorth American Chapter of the Association forComputational Linguistics, pages 56?64.
Asso-ciation for Computational Linguistics, Boulder,Colorado.Huihsin Tseng.
2005.
A conditional random fieldword segmenter.
In In Fourth SIGHAN Work-shop on Chinese Language Processing.Nianwen Xue.
2003.
Chinese word segmentationas character tagging.
In International Journalof Computational Linguistics and Chinese Lan-guage Processing.Ruiqiang Zhang, Genichiro Kikui, and EiichiroSumita.
2006.
Subword-based tagging by con-ditional random fields for Chinese word seg-mentation.
In Proceedings of the Human Lan-guage Technology Conference of the NAACL,Companion Volume: Short Papers, pages 193?196.
Association for Computational Linguis-tics, New York City, USA.Yue Zhang and Stephen Clark.
2007.
Chinese seg-mentation with a word-based perceptron algo-rithm.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Lin-guistics, pages 840?847.
Association for Com-putational Linguistics, Prague, Czech Republic.1219
