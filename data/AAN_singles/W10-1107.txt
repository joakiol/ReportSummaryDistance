Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 46?52,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsAutomated Identification of Synonyms in BiomedicalAcronym Sense Inventories?Genevieve B. Melton SungRim MoonInstitute for Health Informatics & Dept of Surgery Institute for Health InformaticsUniversity of Minnesota University of MinnesotaMinneapolis, MN 55455 USA Minneapolis, MN 55455 USAgmelton@umn.edu moonx086@umn.eduBridget McInnes  Serguei PakhomovCollege of Pharmacy College of PharmacyUniversity of Minnesota University of MinnesotaMinneapolis, MN 55455 USA Minneapolis, MN 55455 USAbthomson@umn.edu  pakh0002@umn.edu?AbstractAcronyms are increasingly prevalent in bio-medical text, and the task of acronym disam-biguation is fundamentally important forbiomedical natural language processing sys-tems.
Several groups have generated sense in-ventories of acronym long form expansionsfrom the biomedical literature.
Long formsense inventories, however, may contain con-ceptually redundant expansions that negative-ly affect their quality.
Our approach toimproving sense inventories consists of map-ping long form expansions to concepts in theUnified Medical Language System (UMLS)with subsequent application of a semantic si-milarity algorithm based upon conceptualoverlap.
We evaluated this approach on a ref-erence standard developed for ten acronyms.A total of 119 of 155 (78%) long formsmapped to concepts in the UMLS.
Our ap-proach identified synonymous long formswith a sensitivity of 70.2% and a positive pre-dictive value of 96.3%.
Although further re-finements are needed, this study demonstratesthe potential value of using automated tech-niques to merge synonymous biomedicalacronym long forms to improve the quality ofbiomedical acronym sense inventories.1 IntroductionAcronyms and abbreviations are increasingly usedin biomedical text.
This is in large part due to theexpansive growth of the biomedical literature esti-mated to be close to one million articles annually(Stead et al 2005).
Ambiguous acronyms representa challenge to both human readers and compute-rized processing systems for resolving theacronym?s meaning within a particular context.
Forany given acronym, there are often multiple possi-ble long form expansions.
Techniques to determinethe context-specific meaning or sense of an ambi-guous acronym are fundamentally important forbiomedical natural language processing and canassist with important tasks such as information re-trieval and information extraction (Friedman2000).Acronym ambiguity resolution represents a spe-cial case of word sense disambiguation (WSD)with unique challenges.
In particular, there are in-creasing numbers of new acronyms (i.e., shortforms) as well as increasing numbers of newsenses (i.e., long forms) for existing acronymswithin biomedical text.
Acronyms in biomedicinealso range from those that are common, to thosethat are infrequent which appear to be created in anad hoc fashion resulting essentially in neologismsdistinct to small sets of biomedical discourse.Sense inventories are important tools that canassist in the task of disambiguation of acronymsand abbreviations.
The relative formal nature ofbiomedical literature discourse lends itself well tobuilding these inventories because long forms aretypically contained within the text itself, providinga ?definition?
on its first mention in an article, nextto a parenthetical expression containing the shortform or vice versa (Schwartz and Hearst 2003).
Incontrast, clinical documents are less structured and46typically lack expanded long forms for acronymsand abbreviations, leaving sense inventories basedon documents in the clinical domain not as welldeveloped as the sense inventories developed fromthe biomedical literature (Pakhomov et al 2005).Compilation of sense inventories for acronymsin clinical documents typically relies on vocabula-ries contained in the Unified Medical LanguageSystem (UMLS) as well as other resources such asADAM (Zhou et al 2006).
However, with the ad-vantage of using rich and diverse resources likeADAM and the UMLS comes the challenge ofhaving to identify and merge synonymous longform expansions which can occur for a given shortform.
Having synonymous long forms in a senseinventory for a given acronym poses a problem forautomated acronym disambiguation because thesense inventory dictates that the disambiguationalgorithm must be able to distinguish between se-mantically equivalent senses.
This is an importantproblem to address because effective identificationof synonymous long forms allows for a clean senseinventory, and it creates the ability for long formexpansions to be combined while preserving thevariety of expression occurring in natural lan-guage.
By automating the merging of synonymousexpansions and building a high quality sense in-ventory, the task of acronym disambiguation willbe improved resulting in better biomedical NLPsystem performance.Our approach to reducing multiple synonymousvariants of the same long form for a set of ten bio-medical acronyms is based on mapping sense in-ventories for biomedical acronyms to the UMLSand using a semantic similarity algorithm based onconceptual overlap.
This study is an exploratoryevaluation of this approach on a manually createdreference standard.2 Background2.1 Similarity measures in biomedicineThe area of semantic similarity in biomedicineis a major area within biomedical NLP and know-ledge representation research.
Semantic similarityaids NLP systems, improves the performance ofinformation retrieval tasks, and helps to reveal im-portant latent relationships between biomedicalconcepts.
Several investigators have studied con-ceptual similarity and have used relationships incontrolled biomedical terminologies, empiric sta-tistical data from biomedical text, and other know-ledge sources (Lee et al 2008; Caviedes andCimino 2004).
However, most of these techniquesfocus on generating measures between a single pairof concepts and do not deal directly with the taskof comparing two groups of concepts.Patient similarity represents an important ana-logous problem that deals with sets of concepts.The approach used by Melton et al (2006) was torepresent each patient case as a set of nodes withina controlled biomedical terminology (SNOMEDCT).
The investigators then applied several meas-ures to ascertain similarity between patient cases.These measures ranged from techniques indepen-dent of the controlled terminology (i.e.
set overlapor Hamming distance) to methods heavily reliantupon the controlled terminology based upon pathtraversal between pair of nodes using defined rela-tionships (either IS-A relationships or other seman-tic relationships) within the terminology.2.2 Lesk algorithm for measuring similarityusing sets of definitional wordsA variety of techniques have been used for thegeneral problem of WSD that range from highlylabor intensive that depend upon human data tag-ging (i.e.
supervised learning) to unsupervised ap-proaches that are completely automated and relyupon non-human sources of information, such ascontext and other semantic features of the sur-rounding text or definitional data.The Lesk algorithm (Lesk 1986) is one exampleof an unsupervised method that uses dictionaryinformation to perform WSD.
This algorithm usesthe observation that words co-occurring in a sen-tence refer to the same topic and that dictionarydefinition words will have topically related senses,as well.
The classic form of this algorithm returns ameasure of word overlap.
Lesk depends upon find-ing common words between dictionary definitions.One shortcoming of Lesk, however, it that it canperform worse for words with terse, few word de-finitions.As a modification of Lesk, researchers haveproposed using WordNet (Felbaum 1998) to en-hance its performance.
WordNet has additionalsemantic information that can aid in the task ofdisambiguation, such as relationships between theterm of interest and other terms.
Banerjee and Pe-47dersen (2002) demonstrated that modifications toLesk improved performance significantly with theaddition of semantic relationship information.2.3 Biomedical literature sense inventoriesA number of acronym and abbreviation sense in-ventories have been developed from the biomedi-cal literature using a variety of approaches.
Changet al (2002) developed the Stanford biomedicalabbreviation server1 using titles and abstracts fromMEDLINE, lexical heuristic rules, and supervisedlogistic regression to align text and extract shortform/long form pairs that matched well withacronym short form letters.
Similarly, Adar (2004)developed the Simple and Robust AbbreviationDictionary (SaRAD)2.
This inventory, in additionto providing the abbreviation and definition, alsoclusters long forms using an N-gram approachalong with classification rules to disambiguate de-finitions.
This resource, while analogous with re-spect to its goal of merging and aligning long formexpansions, is not freely available.
Adar measureda normalized similarity between N-gram sets andthen clustered long forms to create a clusteredsense inventory resource.One of the most comprehensive biomedicalacronym and abbreviation databases is ADAM(Zhou et al 2006) an open source database3 thatwe used for this study.
Once identified, shortform/long form pairs were filtered statistically witha rule of length ratio and an empirically-based cut-off value.
This sense inventory is based onMEDLINE titles and abstracts from 2006 and con-sists of over 59 thousand abbreviation/long formpairs.
The authors report high precision withADAM (97%) and up to 33% novel abbreviationsnot contained within the UMLS or Stanford Ab-breviation dictionary.2.4 MetaMap resource for automated map-ping to the UMLSAn important resource for mapping words andphrases to the UMLS Metathesaurus is MetaMap.This resource was developed at the National Li-brary of Medicine (Aronson 2001) to map text ofbiomedical abstracts to the UMLS.
MetaMap uses1 http://abbreviation.stanford.edu2 http://www.hpl.hp.com/shl/projects/abbrev.html3 http://arrowsmith.psych.uic.edua knowledge intensive approach that relies uponcomputational linguistic, statistical, and symbol-ic/lexical techniques.
While MetaMap was initiallydeveloped to help with indexing of biomedical lite-rature, it has been applied and expanded success-fully to a number of diverse applications includingclinical text.With each mapping, an evaluation functionbased upon centrality, variation, coverage, and co-hesiveness generates a score for a given mappingfrom 0 to 1000 (strongest match).
A cut-off scoreof 900 or greater is considered to represent a goodconceptual match for MetaMap and was used inthis study as the threshold to select valid mappings.3  MethodsTen randomly selected acronyms with between 10to 20 long forms were selected from the ADAMresource database for this pilot study.3.1 Long form mappings to UMLSEach acronym long-form was mapped to theUMLS with MetaMap using two settings.
First,MetaMap was run with its default setting on eachlong form expansion.
Second, MetaMap was run inits ?browse mode?
(options ?-zogm?)
which allowsfor term processing, overmatches, concept gaps,and ignores word order.Processing each long form with MetaMap thenresulted in a set of Concept Unique Identifiers(CUIs) representing the long form.
Each CUI witha score over 900 was included in the overall set ofCUIs for a particular long form expansion.
For agiven pair of long form expansions the two sets ofCUIs that each long form mapped to were com-pared for concept overlap, in an analogous fashionto the Lesk algorithm.
The overlap between con-cept sets was calculated between each pair of longform expansions and expressed as a ratio:?????????????
?????????
????????????????
??????????
?????????????
.For this study, an overlap of 50% or greater wasconsidered to indicate a potential synonymous pair.Now let us assume that we have two conceptsets: The first one is {A, B} and the second one is{A, B, C}, with each CUI having a score over 900.In this example, the overlap of concepts for thefirst concept set between it and the other is 100%,and for the second that is 66.7%.
Because overlaps48are greater than 50%, they are a potential syn-onymous pair, and the overlap ratio is calculated as??????????
???
= 1 (100%).3.2 Expert-derived reference standardTwo physicians were asked to judge the similaritybetween each pair combination of long forms ex-pansions on a continuous scale for our initial refer-ence standard.
Physicians were instructed to ratepairs of long forms for conceptual similarity.
Longforms were presented on a large LCD touch-screendisplay (Hewlett-Packard TouchSmart 22?
desk-top) along with a continuous scale for the physi-cians to rate long form pairs as dissimilar (far leftscreen) or highly similar (far right screen).
Therating was measured on a scale from 1 to 1500 pix-els representing the maximum width of the touchsensitive area of the display (along the x-coordinate).
Inter-rater agreement was assessedusing Pearson correlation.Expert scores were then averaged and plottedon a histogram to visualize expert ratings.
We sub-sequently used a univariate clustering approachbased on the R implementation of the PartitioningAround Medoids (PAM) method to estimate a cut-off point between similar and dissimilar termsbased on the vector of the average responses by thetwo physicians.
The responses were clustered intotwo and three clusters based on an informal obser-vation of the distribution of responses on the histo-gram showing evidence of at least a bimodal andpossibly a trimodal distribution.As a quality measure, a third physician manual-ly reviewed the mean similarity ratings of the firsttwo physicians to assess whether their similarityjudgments represented the degree of synonymybetween long form expansions necessary to war-rant merging the long form expansions.
This re-view was done using a binary scale (0=notsynonymous, 1=synonymous).3.3 Evaluation of automated methodsLong form pair determinations based on the map-pings to the UMLS were compared to our refer-ence standard as described in Section 3.2.
Wecalculated overall results of all long form paircomparisons and on all long form pairs thatmapped to the UMLS with MetaMap.
Performanceis reported as sensitivity, specificity, and positivepredictive value.4 ResultsA total of 10 random acronyms were used in thisstudy.
All long forms for these 10 acronyms werefrom the sense inventory ADAM (Zhou et al,2006).
This resulted in a total of 155 long formexpansions (median 16.5 per acronym, range 11-19) (Table 1).Acronym N of LFexpansionsLF expansionsmapped by MetaMapTotal 155 119 (78%)ALT 13 9 (70%)CK 14 9 (64%)CSF 11 7 (74%)CTA 19 14 (74%)MN 19 17 (89%)NG 17 15 (88%)PCR 17 8 (47%)PET 17 15 (88%)RV 16 14 (88%)TTP 12 11(92%)Table 1.
Number of acronym long forms inADAM and mapping to the UMLS4.1 Long form mappings to UMLSThe default mode of MetaMap resulted in 119(78%) long forms with mappings to the UMLSwith MetaMap (Table 1).
Use of MetaMap?sbrowse mode did not increase the total number ofmapped long forms but did change some of themapped concepts returned by MetaMap (not de-picted).Acronym N pairs Pearson rTotal 1125 0.78*ALT 78 0.79*CK 91 0.77*CSF 55 0.80*CTA 136 0.92*MN 171 0.69*NG 136 0.68*PCR 136 0.89*PET 136 0.78*RV 120 0.67*TTP 66 0.76*Table 2.
Pearson correlation coefficient for ratings over-all and for individual acronyms.
*p<0.000149Figure 1.
Two-way and three-way clustering solution ofexpert ratings of long form pairs.4.2 Expert-derived reference standardFor the 1125 total comparison pairs, two raters as-sessed similarity between long form pairs on a con-tinuous scale.
The overall mean correlationbetween the two raters was 0.78 (standard devia-tion 0.08).
Pearson correlation coefficients for eachacronym are depicted in Table 2.Two-way and three-way clustering demonstrat-ed an empirically determined ?cutoff?
of 525 pix-els from the left of the screen.
This separationpoint between clusters (designated as ?low cutoff?
)was evident on both the two-way and three-wayclustering approaches using the PAM method toestimate a cut-off point between similar and dissi-milar terms based on the vector of the average res-ponses by the two physicians (Figure 1).
Intuitivelythis low cutoff includes manual ratings indicativeof moderate to low similarity (as 525 pixels alonga 1500 pixel-wide scale is approximately one-thirdof the way from the left ?dissimilar?
edge of thetouch-sensitive screen).
To isolate terms that wererated as highly similar, we also created an arbitrary?high cutoff?
of 1200 pixels.Figure 2.
Examples of terms originally rated as highlysimilar but not synonymous by the curating physician.Expert curation of the ratings by the third phy-sician demonstrated that conceptual similarity rat-ings were sometimes not equivalent to synonymythat would warrant the collapse of long form pairs.Of 1125 total pairs of long forms, 70 (6%) origi-CTA:?CT hepatic arteriography?
?CT angiography?MN:?median nerve?
?motor neuron?RV:?rabies virus?
?rotavirus?
?right ventricular free wall?
?right ventricle?TTP:?thiamine triphosphate?
?thymidine triphosphate?Default Mode: MetaMap Browse Mode: MetaMapAll LF Mapped LF only All LF Mapped LF onlyHigh CutoffSensitivity  21.6% 39.6% 23.8% 43.8%Specificity  98.1% 96.8% 99.4% 99.0%PPV  48.7% 48.7% 77.8% 77.8%NPV  93.6% 95.5% 93.9% 95.9%Expert CurationSensitivity  34.3% 64.9% 37.1% 70.2%Specificity  98.6% 97.7% 99.9% 99.8%PPV 61.5% 61.5% 96.3% 96.3%NPV  95.8% 98.0% 96.0% 98.3%Table 3.
Performance of automated techniques for merging biomedical long form sensesfor all long forms and for long forms that mapped to the UMLS only.PPV, positive predictive value; NPV, negative predictive value.50nally classified as similar were re-classified asconceptually different by the third physician.
Sev-eral examples of long form pairs that were origi-nally rated as highly similar but were judged as notsynonymous are contained in Figure 2.4.3 Evaluation of automated methodsThe performance of our algorithm is shown in Ta-ble 3 using MetaMap in the default mode andbrowse mode and then applying our referencestandard using the ?low cutoff?, ?high cutoff?, andexpert curation (Table 3).
Performance is reportedfor all 155 long forms (All LF) and for the subsetof 119 long forms that mapped to the UMLS(Mapped LF only).
Compared to the ?low cutoff?reference standard, the ?high cutoff?
and expertcuration were positively associated with more con-sistent performance.
The browse mode identifiedfewer potential terms to merge and had higher ac-curacy than the default MetaMap mode.5 ConclusionsThe results of this pilot study are promising anddemonstrate high positive predictive value andmoderate sensitivity for our algorithm, which indi-cates to us that this technique with some additionalmodifications has value.
We found that mappinglong form expansions to a controlled terminologyto not be straightforward.
Although approximately80% of long forms mapped, another 20% were notconverted to UMLS concepts.
Because each longform resulted in multiple paired comparisons, a20% loss of mappings resulted globally in a 40%loss in overall system performance.
While longform expansions were entered into MetaMap usinga partially normalized representation of the longform, it is possible that additional normalizationwill improve our mapping.An important observation from our expert-derived reference standard was that terms judgedby physicians as semantically highly similar maynot necessarily be synonymous (Figure 2).
Whilesemantic similarity is analogous, there may besome fundamentally different cognitive determina-tions between similarity and synonymy for humanraters.The current technique that we present comparessets of mapped concepts in an analogous fashion tothe Lesk algorithm and other measures of similari-ty between groups of concepts previously reported.This study did not utilize features of the controlledterminology nor statistical information about thetext to help improve performance.
Despite the lackof additional refinement to the presented tech-niques, we found a flat overlap measure to bemoderately effective in our evaluation.6 Future WorkThere are several lines of investigation that we willpursue as an extension of this study.
The most ob-vious would be to use semantic similarity measuresbetween pairs of concepts that capitalize upon fea-tures and relationships in the controlled terminolo-gy.
We can also expand upon the type of similaritymeasures for the overall long form comparisonwhich requires a measure of similarity betweengroups of concepts.
In addition, an empiric weight-ing scheme based on statistical information ofcommon senses may be helpful for concept map-pings to place more or less emphasis on importantor less important concepts.
We plan to determinethe impact of automatically reduced sense invento-ries on the evaluation of WSD algorithms used formedical acronym disambiguation.Finally, we would like to utilize this work tohelp improve the contents of a sense inventory thatwe are currently developing for acronyms and ab-breviations.
This sense inventory is primarilybased on clinical documents but incorporates in-formation from a number of diverse sources in-cluding ADAM, the UMLS, and a standardmedical dictionary with abbreviations and acro-nyms.AcknowledgmentsThis work was supported by the University ofMinnesota Institute for Health Informatics and De-partment of Surgery and by the National Library ofMedicine (#R01 LM009623-01).
We would like tothank Fairview Health Services for ongoing sup-port of this research.ReferencesEytan Adar (2004) SaRAD: A simple and robust ab-breviation dictionary.
Bioinformatics 20:527?33.Alan R Aronson (2001) Effective mapping of biomedi-cal text to the UMLS Metathesaurus: the MetaMapprogram.
Proc AMIA Symp.
2001:17-21.51Satanjeev Banerjee, Ted Pedersen.
2002.
An AdaptedLesk Algorithm for Word Sense Disambiguation Us-ing WordNet, Proceedings of the Third InternationalConference on Computational Linguistics and Intel-ligent Text Processing, p.136-145, February 17-23.Jorge E. Caviedes JE, James J Cimino.
(2004) Towardsthe development of a conceptual distance metric forthe UMLS.
J Biomed Inform.
Apr;37(2):77?85.Jeffrey T Chang, Hinrich Schutze, Russ B Altman(2001) Creating an online dictionary of abbreviationsfrom Medline.
J Am Med Inform Assoc 9:612?20.Christiane Fellbaum, editor.
1998.
WordNet: An elec-tronic lexical database.
MIT Press.Carol Friedman.
2000.
A broad-coverage natural lan-guage processing system.
Proc AMIA Symp., 270?274.Wei-Nchih Lee, Nigam Shah, Karanjot Sundlass, MarkMusen (2008) Comparison of Ontology-based Se-mantic-Similarity Measures.
AMIA Annu SympProc.
2008.
384?388.Michael E. Lesk.
1986.
Automatic sense disambiguationusing machine readable dictionaries: How to tell apine cone from a ice cream cone.
In Proceedings ofSIGDOC ?86.Genevieve B. Melton, Simon Parsons, Frances P. Mor-rison, Adam S. Rothschild, Marianthi Markatou,George Hripcsak.
2006.
Inter-patient distance metricsusing SNOMED CT defining relationships, Journalof Biomedical Informatics, 39(6), 697-705.Serguei Pakhomov, Ted Pedersen, Christopher G.Chute.
2005.
Abbreviation and Acronym Disambigu-ation in Clinical Discourse.
American Medical In-formatics Association Annual Symposium, 589-593.Ariel S Schwartz and Marti A. Hearst.
2003.
A SimpleAlgorithm for Identifying Abbreviation Definitionsin Biomedical Text.
Pacific Symposium on Biocom-puting p451-462.William W Stead, Brian J Kelly, Robert M Kolodner.2005.
Achievable steps toward building a NationalHealth Information infrastructure in the UnitedStates.
J.
Am.
Med.
Inform.
Assoc., 12, 113?120.Wei Zhou, Vetle I Torvik, Neil R Smalheiser (2006)ADAM: Another database of abbreviations in Med-line.
Bioinformatics 22:2813?
8.52
