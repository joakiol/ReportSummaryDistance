Proceedings of the 12th Conference of the European Chapter of the ACL, pages 398?405,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsGenerating a Non-English Subjectivity Lexicon:Relations That MatterValentin Jijkoun and Katja HofmannISLA, University of AmsterdamAmsterdam, The Netherlands{jijkoun,k.hofmann}@uva.nlAbstractWe describe a method for creating a non-English subjectivity lexicon based on anEnglish lexicon, an online translation ser-vice and a general purpose thesaurus:Wordnet.
We use a PageRank-like algo-rithm to bootstrap from the translation ofthe English lexicon and rank the wordsin the thesaurus by polarity using the net-work of lexical relations in Wordnet.
Weapply our method to the Dutch language.The best results are achieved when usingsynonymy and antonymy relations only,and ranking positive and negative wordssimultaneously.
Our method achieves anaccuracy of 0.82 at the top 3,000 negativewords, and 0.62 at the top 3,000 positivewords.1 IntroductionOne of the key tasks in subjectivity analysis isthe automatic detection of subjective (as opposedto objective, factual) statements in written doc-uments (Mihalcea and Liu, 2006).
This task isessential for applications such as online market-ing research, where companies want to know whatcustomers say about the companies, their prod-ucts, specific products?
features, and whether com-ments made are positive or negative.
Anotherapplication is in political research, where pub-lic opinion could be assessed by analyzing user-generated online data (blogs, discussion forums,etc.
).Most current methods for subjectivity identi-fication rely on subjectivity lexicons, which listwords that are usually associated with positive ornegative sentiments or opinions (i.e., words withpolarity).
Such a lexicon can be used, e.g., to clas-sify individual sentences or phrases as subjectiveor not, and as bearing positive or negative senti-ments (Pang et al, 2002; Kim and Hovy, 2004;Wilson et al, 2005a).
For English, manually cre-ated subjectivity lexicons have been available fora while, but for many other languages such re-sources are still missing.We describe a language-independent methodfor automatically bootstrapping a subjectivity lex-icon, and apply and evaluate it for the Dutch lan-guage.
The method starts with an English lexi-con of positive and negative words, automaticallytranslated into the target language (Dutch in ourcase).
A PageRank-like algorithm is applied to theDutch wordnet in order to filter and expand the setof words obtained through translation.
The Dutchlexicon is then created from the resulting rankingof the wordnet nodes.
Our method has several ben-efits:?
It is applicable to any language for which awordnet and an automatic translation serviceor a machine-readable dictionary (from En-glish) are available.
For example, the Eu-roWordnet project (Vossen, 1998), e.g., pro-vides wordnets for 7 languages, and free on-line translation services such as the one wehave used in this paper are available for manyother languages as well.?
The method ranks all (or almost all) entries ofa wordnet by polarity (positive or negative),which makes it possible to experiment withdifferent settings of the precision/coveragethreshold in applications that use the lexicon.We apply our method to the most recent versionof Cornetto (Vossen et al, 2007), an extension ofthe Dutch WordNet, and we experiment with vari-ous parameters of the algorithm, in order to arriveat a good setting for porting the method to otherlanguages.
Specifically, we evaluate the quality ofthe resulting Dutch subjectivity lexicon using dif-ferent subsets of wordnet relations and informa-tion in the glosses (definitions).
We also examine398the effect of the number of iterations on the per-formance of our method.
We find that best perfor-mance is achieved when using only synonymy andantonymy relations and, moreover, the algorithmconverges after about 10 iterations.The remainder of the paper is organized as fol-lows.
We summarize related work in section 2,present our method in section 3 and describe themanual assessment of the lexicon in section 4.
Wediscuss experimental results in section 5 and con-clude in section 6.2 Related workCreating subjectivity lexicons for languages otherthan English has only recently attracted attentionof the research community.
(Mihalcea et al, 2007)describes experiments with subjectivity classifica-tion for Romanian.
The authors start with an En-glish subjectivity lexicon with 6,856 entries, Opin-ionFinder (Wiebe and Riloff, 2005), and automat-ically translate it into Romanian using two bilin-gual dictionaries, obtaining a Romanian lexiconwith 4,983 entries.
A manual evaluation of a sam-ple of 123 entries of this lexicon showed that 50%of the entries do indicate subjectivity.In (Banea et al, 2008) a different approachbased on boostrapping was explored for Roma-nian.
The method starts with a small seed set of60 words, which is iteratively (1) expanded byadding synonyms from an online Romanian dic-tionary, and (2) filtered by removing words whichare not similar (at a preset threshold) to the orig-inal seed, according to an LSA-based similaritymeasure computed on a half-million word cor-pus of Romanian.
The lexicon obtained after 5iterations of the method was used for sentence-level sentiment classification, indicating an 18%improvement over the lexicon of (Mihalcea et al,2007).Both these approaches produce unordered setsof positive and negative words.
Our method,on the other hand, assigns polarity scores towords and produces a ranking of words by polar-ity, which provides a more flexible experimentalframework for applications that will use the lexi-con.Esuli and Sebastiani (Esuli and Sebastiani,2007) apply an algorithm based on PageRank torank synsets in EnglishWordNet according to pos-itive and negativite sentiments.
The authors viewWordNet as a graph where nodes are synsets andsynsets are linked with the synsets of terms usedin their glosses (definitions).
The algorithm is ini-tialized with positivity/negativity scores providedin SentiWordNet (Esuli and Sebastiani, 2006), anEnglish sentiment lexicon.
The weights are thendistributed through the graph using an the algo-rithm similar to PageRank.
Authors conclude thatlarger initial seed sets result in a better rankingproduced by the method.
The algorithm is alwaysrun twice, once for positivity scores, and once fornegativity scores; this is different in our approach,which ranks words from negative to positive inone run.
See section 5.4 for a more detailed com-parison between the existing approaches outlinedabove and our approach.3 ApproachOur approach extends the techniques used in(Esuli and Sebastiani, 2007; Banea et al, 2008)for mining English and Romanian subjectivity lex-icons.3.1 Boostrapping algorithmWe hypothesize that concepts (synsets) that areclosely related in a wordnet have similar meaningand thus similar polarity.
To determine relatednessbetween concepts, we view a wordnet as a graphof lexical relations between words and synsets:?
nodes correspond to lexical units (words) andsynsets; and?
directed arcs correspond to relations betweensynsets (hyponymy, meronymy, etc.)
and be-tween synsets and words they contain; in oneof our experiments, following (Esuli and Se-bastiani, 2007), we also include relations be-tween synsets and all words that occur in theirglosses (definitions).Nodes and arcs of such a graph are assignedweights, which are then propagated through thegraph by iteratively applying a PageRank-like al-gorithm.Initially, weights are assigned to nodes and arcsin the graph using translations from an English po-larity lexicon as follows:?
words that are translations of the positivewords from the English lexicon are assigneda weight of 1, words that are translations ofthe negative words are initialized to -1; ingeneral, weight of a word indicates its polar-ity;399?
All arcs are assigned a weight of 1, exceptfor antonymy relations which are assigneda weight of -1; the intuition behind the arcweights is simple: arcs with weight 1 wouldusually connect synsets of the same (or simi-lar) polarity, while arcs with weight -1 wouldconnect synsets with opposite polarities.We use the following notation.
Our algorithmis iterative and k = 0, 1, .
.
.
denotes an iteration.Let aki be the weight of the node i at the k-th iter-ation.
Let wjm be the weight of the arc that con-nects node j with nodem; we assume the weight is0 if the arc does not exist.
Finally, ?
is a dampingfactor of the PageRank algorithm, set to 0.8.
Thisfactor balances the impact of the initial weight ofa node with the impact of weight received throughconnections to other nodes.The algorithm proceeds by updating the weightsof nodes iteratively as follows:ak+1i = ?
?
?jakj ?
wji?m |wjm|+ (1?
?)
?
a0iFurthermore, at each iterarion, all weights ak+1iare normalized by maxj |ak+1j |.The equation above is a straightforward exten-sion of the PageRank method for the case whenarcs of the graph are weighted.
Nodes propagatetheir polarity mass to neighbours through outgoingarcs.
The mass transferred depends on the weightof the arcs.
Note that for arcs with negative weight(in our case, antonymy relation), the polarity oftransferred mass is inverted: i.e., synsets with neg-ative polarity will enforce positive polarity in theirantonyms.We iterate the algorithm and read off the result-ing weight of the word nodes.
We assume wordswith the lowest resulting weight to have negativepolarity, and word nodes with the highest weightpositive polarity.
The output of the algorithm is alist of words ordered by polarity score.3.2 Resources usedWe use an English subjectivity lexicon of Opinion-Finder (Wilson et al, 2005b) as the starting pointof our method.
The lexicon contains 2,718 Englishwords with positive polarity and 4,910 words withnegative polarity.
We use a free online translationservice1 to translate positive and negative polar-ity words into Dutch, resulting in 974 and 1,5231http://translate.google.comDutch words, respectively.
We assumed that aword was translated into Dutch successfully if thetranslation occurred in the Dutch wordnet (there-fore, the result of the translation is smaller than theoriginal English lexicon).The Dutch wordnet we used in our experimentsis the most recent version of Cornetto (Vossen etal., 2007).
This wordnet contains 103,734 lexicalunits (words), 70,192 synsets, and 157,679 rela-tions between synsets.4 Manual assessmentsTo assess the quality of our method we re-usedassessments made for earlier work on comparingtwo resources in terms of their usefulness for au-tomatically generating subjectivity lexicons (Jij-koun and Hofmann, 2008).
In this setting, thegoal was to compare two versions of the DutchWordnet: the first from 2001 and the other from2008.
We applied the method described in sec-tion 3 to both resources and generated two subjec-tivity rankings.
From each ranking, we selectedthe 2000 words ranked as most negative and the1500 words ranked as most positive, respectively.More negative than positive words were chosen toreflect the original distribution of positive vs. neg-ative words.
In addition, we selected words forassessment from the remaining parts of the rankedlists, randomly sampling chunks of 3000 words atintervals of 10000 words with a sampling rate of10%.
The selection was made in this way becausewe were mostly interested in negative and positivewords, i.e., the words near either end of the rank-ings.4.1 Assessment procedureHuman annotators were presented with a list ofwords in random order, for each word its part-of-speech tag was indicated.
Annotators were askedto identify positive and negative words in this list,i.e., words that indicate positive (negative) emo-tions, evaluations, or positions.Annotators were asked to classify each word onthe list into one of five classes:++ the word is positive in most contexts (stronglypositive)+ the word is positive in some contexts (weaklypositive)0 the word is hardly ever positive or negative(neutral)400?
the a word is negative in some contexts(weakly negative)??
the word is negative in most contexts(strongly negative)Cases where assessors were unable to assign aword to one of the classes, were separately markedas such.For the purpose of this study we were only inter-ested in identifying subjective words without con-sidering subjectivity strength.
Furthermore, a pi-lot study showed assessments of the strength ofsubjectivity to be a much harder task (54% inter-annotator agreement) than distinguishing betweenpositive, neutral and negative words only (72%agreement).
We therefore collapsed the classes ofstrongly and weakly subjective words for evalua-tion.
These results for three classes are reportedand used in the remainder of this paper.4.2 AnnotatorsThe data were annotated by two undergraduateuniversity students, both native speakers of Dutch.Annotators were recruited through a universitymailing list.
Assessment took a total of 32 work-ing hours (annotating at approximately 450-500words per hour) which were distributed over a to-tal of 8 annotation sessions.4.3 Inter-annotator AgreementIn total, 9,089 unique words were assessed, ofwhich 6,680 words were assessed by both anno-tators.
For 205 words, one or both assessors couldnot assign an appropriate class; these words wereexcluded from the subsequent study, leaving uswith 6,475 words with double assessments.Table 1 shows the number of assessed wordsand inter-annotator agreement overall and perpart-of-speech.
Overall agreement is 69% (Co-hen?s ?=0.52).
The highest agreement is for ad-jectives, at 76% (?=0.62) .
This is the samelevel of agreement as reported in (Kim and Hovy,2004) for English.
Agreement is lowest for verbs(55%, ?=0.29) and adverbs (56%, ?=0.18), whichis slightly less than the 62% agreement on verbsreported by Kim and Hovy.
Overall we judgeagreement to be reasonable.Table 2 shows the confusion matrix between thetwo assessors.
We see that one assessor judgedmore words as subjective overall, and that morewords are judged as negative than positive (thisPOS Count % agreement ?noun 3670 70% 0.51adjective 1697 76% 0.62adverb 25 56% 0.18verb 1083 55% 0.29overall 6475 69% 0.52Table 1: Inter-annotator agreement per part-of-speech.can be explained by our sampling method de-scribed above).?
0 + Total?
1803 137 39 19790 1011 1857 649 3517+ 81 108 790 979Total 2895 2102 1478 6475Table 2: Contingency table for all words assessedby two annotators.5 Experiments and resultsWe evaluated several versions of the method ofsection 3 in order to find the best setting.Our baseline is a ranking of all words in thewordnet with the weight -1 assigned to the trans-lations of English negative polarity words, 1 as-signed to the translations of positive words, and0 assigned to the remaining words.
This corre-sponds to simply translating the English subjec-tivity lexicon.In the run all.100 we applied our method to allwords, synsets and relations from the DutchWord-net to create a graph with 153,386 nodes (70,192synsets, 83,194 words) and 362,868 directed arcs(103,734 word-to-synset, 103,734 synset-to-word,155,400 synset-to-synset relations).
We used 100iterations of the PageRank algorihm for this run(and all runs below, unless indicated otherwise).In the run syn.100 we only used synset-to-word, word-to-synset relations and 2,850 near-synonymy relations between synsets.
We added1,459 near-antonym relations to the graph toproduce the run syn+ant.100.
In the runsyn+hyp.100 we added 66,993 hyponymy and66,993 hyperonymy relations to those used in runsyn.100.We also experimented with the information pro-vided in the definitions (glosses) of synset.
Theglosses were available for 68,122 of the 70,192401synsets.
Following (Esuli and Sebastiani, 2007),we assumed that there is a semantic relationshipbetween a synset and each word used in its gloss.Thus, the run gloss.100 uses a graph with 70,192synsets, 83,194 words and 350,855 directed arcsfrom synsets to lemmas of all words in theirglosses.
To create these arcs, glosses were lemma-tized and lemmas not found in the wordnet wereignored.To see if the information in the glosses can com-plement the wordnet relations, we also generateda hybrid run syn+ant+gloss.100 that used arcs de-rived from word-to-synset, synset-to-word, syn-onymy, antonymy relations and glosses.Finally, we experimented with the number ofiterations of PageRank in two setting: using allwordnet relations and using only synonyms andantonyms.5.1 Evaluation measuresWe used several measures to evaluate the qualityof the word rankings produced by our method.We consider the evaluation of a ranking parallelto the evaluation for a binary classification prob-lem, where words are classified as positive (resp.negative) if the assigned score exceeds a certainthreshold value.
We can select a specific thresh-old and classify all words exceeding this score aspositive.
There will be a certain amount of cor-rectly classified words (true positives), and someincorrectly classified words (false positives).
Aswe move the threshold to include a larger portionof the ranking, both the number of true positivesand the number of false positives increase.We can visualize the quality of rankings by plot-ting their ROC curves, which show the relation be-tween true positive rate (portion of the data cor-rectly labeled as positive instances) and false pos-itive rate (portion of the data incorrectly labeledas positive instances) at all possible threshold set-tings.To compare rankings, we compute the area un-der the ROC curve (AUC), a measure frequentlyused to evaluate the performance of ranking clas-sifiers.
The AUC value corresponds to the proba-bility that a randomly drawn positive instance willbe ranked higher than a randomly drawn negativeinstance.
Thus, an AUC of 0.5 corresponds to ran-dom performance, a value of 1.0 corresponds toperfect performance.
When evaluating word rank-ings, we compute AUC?
and AUC+ as evalua-Run ?k Dk AUC?
AUC+baseline 0.395 0.303 0.701 0.733syn.10 0.641 0.180 0.829 0.837gloss.100 0.637 0.181 0.829 0.835all.100 0.565 0.218 0.792 0.787syn.100 0.645 0.177 0.831 0.839syn+ant.100 0.650 0.175 0.833 0.841syn+ant+gloss.100 0.643 0.178 0.831 0.838syn+hyp.100 0.594 0.203 0.807 0.810Table 3: Evaluation resultstion measures for the tasks of identifying wordswith negative (resp., positive) polarity.Other measures commonly used to evalu-ate rankings are Kendall?s rank correlation, orKendall?s tau coefficient, and Kendall?s dis-tance (Fagin et al, 2004; Esuli and Sebastiani,2007).
When comparing rankings, Kendall?s mea-sures look at the number of pairs of ranked itemsthat agree or disagree with the ordering in the goldstandard.
The measures can deal with partiallyordered sets (i.e., rankings with ties): only pairsthat are ordered in the gold standard are used.Let T = {(ai, bi)}i denote the set of pairs or-dered in the gold standard, i.e., ai ?g bi.
LetC = {(a, b) ?
T | a ?r b} be the set of con-cordant pairs, i.e., pairs ordered the same way inthe gold standard and in the ranking.
Let D ={(a, b) ?
T | b ?r a} be the set of discordantpairs and U = T \ (C ?
D) the set of pairs or-dered in the gold standard, but tied in the rank-ing.
Kendall?s rank correlation coefficient ?k andKendall?s distance Dk are defined as follows:?k =|C| ?
|D||T |Dk =|D|+ p ?
|U ||T |where p is a penalization factor for ties, which weset to 0.5, following (Esuli and Sebastiani, 2007).The value of ?k ranges from -1 (perfect dis-agreement) to 1 (perfect agreement), with 0 indi-cating an almost random ranking.
The value ofDk ranges from 0 (perfect agreement) to 1 (per-fect disagreement).When applying Kendall?s measures we assumethat the gold standard defines a partial order: fortwo words a and b, a ?g b holds when a ?
Ng, b ?Ug ?
Pg or when a ?
Ug, b ?
Pg; here Ng, Ug, Pgare sets of words judged as negative, neutral andpositive, respectively, by human assessors.5.2 Types of wordnet relationsThe results in Table 3 indicate that the method per-forms best when only synonymy and antonymy402Negative polarityFalse positive rateTrue positiverate0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0baselineall.100gloss.100syn+ant.100syn+hyp.100Positive polarityFalse positive rateTrue positiverate0.0 0.2 0.4 0.6 0.8 1.00.00.20.40.60.81.0baselineall.100gloss.100syn+ant.100syn+hyp.100Figure 1: ROC curves showing the impact of using different sets of relations for negative and positivepolarity.
Graphs were generated using ROCR (Sing et al, 2005).relations are considered for ranking.
Adding hy-ponyms and hyperonyms, or adding relations be-tween synsets and words in their glosses substan-tially decrease the performance, according to allfour evaluation measures.
With all relations, theperformance degrades even further.
Our hypothe-sis is that with many relations the polarity mass ofthe seed words is distributed too broadly.
This issupported by the drop in the performance early inthe ranking at the ?negative?
side of runs with allrelations and with hyponyms (Figure 1, left).
An-other possible explanation can be that words withmany incoming arcs (but without strong connec-tions to the seed words) get substantial weights,thereby decreasing the quality of the ranking.Antonymy relations also prove useful, as usingthem in addition to synonyms results in a smallimprovement.
This justifies our modification ofthe PageRank algorithm, when we allow negativenode and arc weights.In the best setting (syn+ant.100), our methodachieves an accuracy of 0.82 at top 3,000 negativewords, and 0.62 at top 3,000 positive words (esti-mated from manual assessments of a sample, seesection 4).
Moreover, Figure 1 indicates that theaccuracy of the seed set (i.e., the baseline transla-tions of the English lexicon) is maintained at thepositive and negative ends of the ranking for mostvariants of the method.5.3 The number of iterationsIn Figure 2 we plot how the AUC?
measurechanges when the number of PageRank iterationsincreases (for positive polarity; the plots are al-most identical for negative polarity).
Although theabsolute maximum of AUC is achieved at 110 iter-ation (60 iterations for positive polarity), the AUCclearly converges after 20 iterations.
We concludethat after 20 iterations all useful information hasbeen propagated through the graph.
Moreover, ourversion of PageRank reaches a stable weight dis-tribution and, at the same time, produces the bestranking.5.4 Comparison to previous workAlthough the values in the evaluation results are,obviously, language-dependent, we tried to repli-cate the methods used in the literature for Roma-nian and English (section 2), to the degree possi-ble.Our baseline replicates the method of (Mihal-cea et al, 2007): i.e., a simple translation of theEnglish lexicon into the target language.
Therun syn.10 is similar to the iterative method usedin (Banea et al, 2008), except that we do not per-form a corpus-based filtering.
We run PageRankfor 10 iterations, so that polarity is propagatedfrom the seed words to all their 5-step-synonymyneighbours.
Table 3 indicates that increasing thenumber of iterations in the method of (Banea et4030 50 100 150 2000.700.750.800.850.90Number of iterationsAUCall relationssynsets+antonymsFigure 2: The number of iterations and the rankingquality (AUC), for positive polarity.
Rankings fornegative polarity behave similarly.al., 2008) might help to generate a better subjec-tivity lexicon.The run gloss.100 is similar to the PageRank-based method of (Esuli and Sebastiani, 2007).The main difference is that Esuli and Sebastianiused the extended English WordNet, where wordsin all glosses are manually assigned to their cor-rect synsets: the PageRank method then uses re-lations between synsets and synsets of words intheir glosses.
Since such a resource is not avail-able for our target language (Dutch), we used rela-tions between synsets and words in their glosses,instead.
With this simplification, the PageRankmethod using glosses produces worse results thanthe method using synonyms.
Further experimentswith the extended English WordNet are neces-sary to investigate whether this decrease can be at-tributed to the lack of disambiguation for glosses.An important difference between our methodand (Esuli and Sebastiani, 2007) is that the lat-ter produces two independent rankings: one forpositive and one for negative words.
To evalu-ate the effect of this choice, we generated runsgloss.100.N and gloss.100.P that used only nega-tive (resp., only positive) seed words.
We comparethese runs with the run gloss.100 (that starts withboth positive and negative seeds) in Table 4.
Toallow a fair comparison of the generated rankings,the evaluation measures in this case are calculatedseparately for two binary classification problems:words with negative polarity versus all words, andwords with positive polarity versus all.The results in Table 4 clearly indicate that in-Run ?
?k D?k AUC?gloss.100 0.669 0.166 0.829gloss.100.N 0.562 0.219 0.782?+k D+k AUC+gloss.100 0.665 0.167 0.835gloss.100.P 0.580 0.210 0.795Table 4: Comparison of separate and simultaneousrankings of negative and positive words.formation about words of one polarity class helpsto identify words of the other polarity: negativewords are unlikely to be also positive, and viceversa.
This supports our design choice: rankingwords from negative to positive in one run of themethod.6 ConclusionWe have presented a PageRank-like algorithm thatbootstraps a subjectivity lexicon from a list ofinitial seed examples (automatic translations ofwords in an English subjectivity lexicon).
The al-gorithm views a wordnet as a graph where wordsand concepts are connected by relations such assynonymy, hyponymy, meronymy etc.
We initial-ize the algorithm by assigning high weights to pos-itive seed examples and low weights to negativeseed examples.
These weights are then propagatedthrough the wordnet graph via the relations.
Aftera number of iterations words are ranked accordingto their weight.
We assume that words with lowerweights are likely negative and words with highweights are likely positive.We evaluated several variants of the method forthe Dutch language, using the most recent versionof Cornetto, an extension of Dutch WordNet.
Theevaluation was based on the manual assessmentof 9,089 words (with inter-annotator agreement69%, ?=0.52).
Best results were achieved whenthe method used only synonymy and antonymyrelations, and was ranking positive and negativewords simultaneously.
In this setting, the methodachieves an accuracy of 0.82 at the top 3,000 neg-ative words, and 0.62 at the top 3,000 positivewords.Our method is language-independent and caneasily be applied to other languages for whichwordnets exist.
We plan to make the implemen-tation of the method publicly available.An additional important outcome of our experi-ments is the first (to our knowledge) manually an-notated sentiment lexicon for the Dutch language.404The lexicon contains 2,836 negative polarity and1,628 positive polarity words.
The lexicon will bemade publicly available as well.
Our future workwill focus on using the lexicon for sentence- andphrase-level sentiment extraction for Dutch.AcknowledgmentsThis work was supported by projects DuO-MAn and Cornetto, carried out within theSTEVIN programme which is funded by theDutch and Flemish Governments (http://www.stevin-tst.org), and by the Nether-lands Organization for Scientific Research (NWO)under project number 612.061.814.ReferencesCarmen Banea, Rada Mihalcea, and Janyce Wiebe.2008.
A bootstrapping method for building subjec-tivity lexicons for languages with scarce resources.In LREC.Andrea Esuli and Fabrizio Sebastiani.
2006.
Senti-wordnet: A publicly available lexical resource foropinion mining.
In Proceedings of LREC 2006,pages 417?422.Andrea Esuli and Fabrizio Sebastiani.
2007.
Pager-anking wordnet synsets: An application to opinionmining.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguistics,pages 424?431.Ronald Fagin, Ravi Kumar, Mohammad Mahdian,D.
Sivakumar, and Erik Vee.
2004.
Com-paring and aggregating rankings with ties.
InPODS ?04: Proceedings of the twenty-third ACMSIGMOD-SIGACT-SIGART symposium on Princi-ples of database systems, pages 47?58, New York,NY, USA.
ACM.Valentin Jijkoun and Katja Hofmann.
2008.Task-based Evaluation Report: Building aDutch Subjectivity Lexicon.
Technical report.Technical report, University of Amsterdam.http://ilps.science.uva.nl/biblio/cornetto-subjectivity-lexicon.Soo-Min Kim and Eduard Hovy.
2004.
Determin-ing the sentiment of opinions.
In Proceedings ofthe 20th International Conference on ComputationalLinguistics (COLING).R.
Mihalcea and H. Liu.
2006.
A corpus-based ap-proach to finding happiness.
In Proceedings ofthe AAAI Spring Symposium on Computational Ap-proaches to Weblogs.Rada Mihalcea, Carmen Banea, and Janyce Wiebe.2007.
Learning multilingual subjective language viacross-lingual projections.
In Proceedings of the 45thAnnual Meeting of the Association of ComputationalLinguistics, pages 976?983, Prague, Czech Repub-lic, June.
Association for Computational Linguis-tics.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
sentiment classification usingmachine learning techniques.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP 2002), pages 79?86.T.
Sing, O. Sander, N. Beerenwinkel, and T. Lengauer.2005.
ROCR: visualizing classifier performance inR.
Bioinformatics, 21(20):3940?3941.P.
Vossen, K. Hofman, M. De Rijke, E. TjongKim Sang, and K. Deschacht.
2007.
The cornettodatabase: Architecture and user-scenarios.
In Pro-ceedings of 7th Dutch-Belgian Information RetrievalWorkshop DIR2007.Piek Vossen, editor.
1998.
EuroWordNet: a mul-tilingual database with lexical semantic networks.Kluwer Academic Publishers, Norwell, MA, USA.Janyce Wiebe and Ellen Riloff.
2005.
Creating sub-jective and objective sentence classifiers from unan-notated texts.
In Proceeding of CICLing-05, In-ternational Conference on Intelligent Text Process-ing and Computational Linguistics, volume 3406 ofLecture Notes in Computer Science, pages 475?486.Springer-Verlag.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005a.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of HumanLanguage Technology Conference and Conferenceon Empirical Methods in Natural Language Pro-cessing (HLT/EMNLP 2005), pages 347?354.Theresa Wilson, Janyce Wiebe, and Paul Hoff-mann.
2005b.
Recognizing contextual polarity inphrase-level sentiment analysis.
In Proceedings ofHLTEMNLP 2005.405
