Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 69?76, New York City, June 2006. c?2006 Association for Computational LinguisticsCan Human Verb Associations Help IdentifySalient Features for Semantic Verb Classification?Sabine Schulte im WaldeComputational LinguisticsSaarland UniversitySaarbr?ucken, Germanyschulte@coli.uni-sb.deAbstractThis paper investigates whether human as-sociations to verbs as collected in a webexperiment can help us to identify salientverb features for semantic verb classes.Assuming that the associations model as-pects of verb meaning, we apply a clus-tering to the verbs, as based on the as-sociations, and validate the resulting verbclasses against standard approaches to se-mantic verb classes, i.e.
GermaNet andFrameNet.
Then, various clusterings ofthe same verbs are performed on the basisof standard corpus-based types, and eval-uated against the association-based clus-tering as well as GermaNet and FrameNetclasses.
We hypothesise that the corpus-based clusterings are better if the instan-tiations of the feature types show moreoverlap with the verb associations, andthat the associations therefore help toidentify salient feature types.1 IntroductionThere are a variety of manual semantic verb clas-sifications; major frameworks are the Levin classes(Levin, 1993), WordNet (Fellbaum, 1998), andFrameNet (Fontenelle, 2003).
The different frame-works depend on different instantiations of seman-tic similarity, e.g.
Levin relies on verb similarityreferring to syntax-semantic alternation behaviour,WordNet uses synonymy, and FrameNet relies onsituation-based agreement as defined in Fillmore?sframe semantics (Fillmore, 1982).
As an alterna-tive to the resource-intensive manual classifications,automatic methods such as classification and clus-tering are applied to induce verb classes from cor-pus data, e.g.
(Merlo and Stevenson, 2001; Joanisand Stevenson, 2003; Korhonen et al, 2003; Steven-son and Joanis, 2003; Schulte im Walde, 2003; Fer-rer, 2004).
Depending on the types of verb classesto be induced, the automatic approaches vary theirchoice of verbs and classification/clustering algo-rithm.
However, another central parameter for theautomatic induction of semantic verb classes is theselection of verb features.Since the target classification determines the sim-ilarity and dissimilarity of the verbs, the verb fea-ture selection should model the similarity of inter-est.
For example, Merlo and Stevenson (2001) clas-sify 60 English verbs which alternate between an in-transitive and a transitive usage, and assign them tothree verb classes, according to the semantic role as-signment in the frames; their verb features are cho-sen such that they model the syntactic frame alterna-tion proportions and also heuristics for semantic roleassignment.
In larger-scale classifications such as(Korhonen et al, 2003; Stevenson and Joanis, 2003;Schulte im Walde, 2003), which model verb classeswith similarity at the syntax-semantics interface, itis not clear which features are the most salient.
Theverb features need to relate to a behavioural com-ponent (modelling the syntax-semantics interplay),but the set of features which potentially influencethe behaviour is large, ranging from structural syn-tactic descriptions and argument role fillers to ad-verbial adjuncts.
In addition, it is not clear howfine-grained the features should be; for example,how much information is covered by low-level win-dow co-occurrence vs. higher-order syntactic framefillers?69In this paper, we investigate whether human asso-ciations to verbs can help us to identify salient verbfeatures for semantic verb classes.
We collected as-sociations to German verbs in a web experiment, andhope that these associations represent a useful ba-sis for a theory-independent semantic classificationof the German verbs, assuming that the associationsmodel a non-restricted set of salient verb meaningaspects.
In a preparatory step, we perform an un-supervised clustering on the experiment verbs, asbased on the verb associations.
We validate the re-sulting verb classes (henceforth: assoc-classes) bydemonstrating that they show considerable overlapwith standard approaches to semantic verb classes,i.e.
GermaNet and FrameNet.
In the main body ofthis work, we compare the associations underlyingthe assoc-classes with standard corpus-based featuretypes: We check on how many of the associations wefind among the corpus-based features, such as ad-verbs, direct object nouns, etc.
; we hypothesise thatthe more associations are found as instantiations in afeature set, the better is a clustering as based on thatfeature type.
We assess our hypothesis by applyingvarious corpus-based feature types to the experimentverbs, and comparing the resulting classes (hence-forth: corpus-classes) against the assoc-classes.
Onthe basis of the comparison we intend to answer thequestion whether the human associations help iden-tify salient features to induce semantic verb classes,i.e.
do the corpus-based feature types which areidentified on the basis of the associations outperformprevious clustering results?
By applying the fea-ture choices to GermaNet and FrameNet, we addressthe question whether the same types of features aresalient for different types of semantic verb classes?In what follows, the paper presents the associationdata in Section 2 and the association-based classes inSection 3.
In Section 4, we compare the associationswith corpus-based feature types, and in Section 5 weapply the insights to induce semantic verb classes.2 Verb Association DataWe obtained human associations to German verbsfrom native speakers in a web experiment (Schulteim Walde and Melinger, 2005).
330 verbs were se-lected for the experiment (henceforth: experimentverbs), from different semantic categories, and dif-ferent corpus frequency bands.
Participants weregiven 55 verbs each, and had 30 seconds per verbto type as many associations as they could.
299native German speakers participated in the experi-ment, between 44 and 54 for each verb.
In total,we collected 81,373 associations from 16,445 trials;each trial elicited an average of 5.16 responses witha range of 0-16.All data sets were pre-processed in the followingway: For each target verb, we quantified over all re-sponses in the experiment.
Table 1 lists the 10 mostfrequent response types for the verb klagen ?com-plain, moan, sue?.
The responses were not distin-guished according to polysemic senses of the verbs.klagen ?complain, moan, sue?Gericht ?court?
19jammern ?moan?
18weinen ?cry?
13Anwalt ?lawyer?
11Richter ?judge?
9Klage ?complaint?
7Leid ?suffering?
6Trauer ?mourning?
6Klagemauer ?Wailing Wall?
5laut ?noisy?
5Table 1: Association frequencies for target verb.In the clustering experiments to follow, the verbassociations are considered as verb features.
Theunderlying assumption is that verbs which are se-mantically similar tend to have similar associations,and are therefore assigned to common classes.
Ta-ble 2 illustrates the overlap of associations for thepolysemous klagen with a near-synonym of one ofits senses, jammern ?moan?.
The table lists those as-sociations which were given at least twice for eachverb; the total overlap was 35 association types.klagen/jammern ?moan?Frauen ?women?
2/3Leid ?suffering?
6/3Schmerz ?pain?
3/7Trauer ?mourning?
6/2bedauern ?regret?
2/2beklagen ?bemoan?
4/3heulen ?cry?
2/3nervig ?annoying?
2/2no?len ?moan?
2/3traurig ?sad?
2/5weinen ?cry?
13/9Table 2: Association overlap for target verbs.703 Association-based Verb ClassesWe performed a standard clustering on the 330 ex-periment target verbs: The verbs and their featureswere taken as input to agglomerative (bottom-up)hierarchical clustering.
As similarity measure inthe clustering procedure (i.e.
to determine the dis-tance/similarity for two verbs), we used the skewdivergence, a smoothed variant of the Kullback-Leibler divergence (Lee, 2001).
The goal of theseexperiments was not to explore the optimal featurecombination; thus, we rely on previous experimentsand parameter settings, cf.
Schulte im Walde (2003).Our claim is that the hierarchical verb classesand their underlying features (i.e.
the verb as-sociations) represent a useful basis for a theory-independent semantic classification of the Germanverbs.
To support this claim, we validated theassoc-classes against standard approaches to seman-tic verb classes, i.e.
GermaNet as the German Word-Net (Kunze, 2000), and the German counterpart ofFrameNet in the Salsa project (Erk et al, 2003).
De-tails of the validation can be found in (Schulte imWalde, 2006); the main issues are as follows.We did not directly compare the assoc-classesagainst the GermaNet/FrameNet classes, since notall of our 330 experiments verbs were coveredby the two resources.
Instead, we replicated theabove cluster experiment for a reduced number ofverbs: We extracted those classes from the resourceswhich contain association verbs; light verbs, non-association verbs, other classes as well as singletonswere disregarded.
This left us with 33 classes fromGermaNet, and 38 classes from FrameNet.
Theseremaining classifications are polysemous: The 33GermaNet classes contain 71 verb senses which dis-tribute over 56 verbs, and the 38 FrameNet classescontain 145 verb senses which distribute over 91verbs.
Based on the 56/91 verbs in the two goldstandard resources, we performed two cluster anal-yses, one for the GermaNet verbs, and one for theFrameNet verbs.
As for the complete set of ex-periments verbs, we performed a hierarchical clus-tering on the respective subsets of the experimentverbs, with their associations as verb features.
Theactual validation procedure then used the reducedclassifications: The resulting analyses were evalu-ated against the resource classes on each level inthe hierarchies, i.e.
from 56/91 classes to 1 class.As evaluation measure, we used a pair-wise measurewhich calculates precision, recall and a harmonic f-score as follows: Each verb pair in the cluster anal-ysis was compared to the verb pairs in the gold stan-dard classes, and evaluated as true or false positive(Hatzivassiloglou and McKeown, 1993).The association-based clusters show overlap withthe lexical resource classes of an f-score of 62.69%(for 32 verb classes) when comparing to GermaNet,and 34.68% (for 10 verb classes) when comparingto FrameNet.
The corresponding upper bounds are82.35% for GermaNet and 60.31% for FrameNet.1The comparison therefore demonstrates consider-able overlap between association-based classes andexisting semantic classes.
The different results forthe two resources are due to their semantic back-ground (i.e.
capturing synonymy vs. situation-basedagreement), the numbers of verbs, and the degreesof ambiguity (an average of 1.6 senses per verb inFrameNet, as compared to 1.3 senses in GermaNet).The purpose of the validation against semanticresources was to demonstrate that a clustering asbased on the verb associations and a standard clus-tering setting compares well with existing semanticclasses.
We take the positive validation results asjustification to use the assoc-classes as source forcluster information: The clustering defines the verbsin a common association-based class, and the fea-tures which are relevant for the respective class.
Forexample, the 100-class analysis contains a class withthe verbs bedauern ?regret?, heulen ?cry?, jammern?moan?, klagen ?complain, moan, sue?, verzweifeln?become desperate?, and weinen ?cry?, with themost distinctive features Trauer ?mourning?, weinen?cry?, traurig ?sad?, Tra?nen ?tears?, jammern ?moan?,Angst ?fear?, Mitleid ?pity?, Schmerz ?pain?.4 Exploring Semantic Class FeaturesOur claim is that the features underlying theassociation-based classes help us guide the featureselection process in future clustering experiments,because we know which semantic classes are based1The upper bounds are below 100%, because the hierarchi-cal clustering assigns a verb to only one cluster, but the lexicalresources contain polysemy.
We created a hard version of thelexical resource classes where we randomly chose one sense ofeach polysemous verb, to calculate the upper bounds.71on which associations/features.
We rely on theassoc-classes in the 100-class analysis of the hier-archical clustering2 and features which exist for atleast two verbs in a common class (and thereforehint to a minimum of verb similarity), and comparethe associations underlying the assoc-classes withstandard corpus-based feature types: We check onhow many of the associations we find among thecorpus-based features, such as adverbs, direct objectnouns, etc.
There are various possibilities to deter-mine corpus-based features that potentially cover theassociations; we decided in favour of feature typeswhich have been suggested in related work:a) Grammar-based relations: Previous workon distributional similarity has focused either ona specific word-word relation (such as Pereira etal.
(1993) and Rooth et al (1999) referring to a directobject noun for describing verbs), or used any syn-tactic relationship detected by a chunker or a parser(such as Lin (1998) and McCarthy et al (2003)).
Weused a statistical grammar (Schulte im Walde, 2003)to filter all verb-noun pairs where the nouns repre-sent nominal heads in NPs or PPs in syntactic rela-tion to the verb (subject, object, adverbial function,etc.
), and to filter all verb-adverb pairs where the ad-verbs modify the verbs.b) Co-occurrence window: In previous work(Schulte im Walde and Melinger, 2005), we showedthat only 28% of all noun associates were identi-fied by the above statistical grammar as subcate-gorised nouns, but 69% were captured by a 20-wordco-occurrence window in a 200-million word news-paper corpus.
This finding suggests to use a co-occurrence window as alternative source for verbfeatures, as compared to specific syntactic relations.We therefore determined the co-occurring words forall experiment verbs in a 20-word window (i.e.
20words preceding and following the verb), irrespec-tive of the part-of-speech of the co-occurring words.Relying on the verb information extracted for a)and b), we checked for each verb-association pairwhether it occurred among the grammar or windowpairs.
Table 3 illustrates which proportions of theassociations we found in the two resource types.For the grammar-based relations, we checked argu-2The exact number of classes or the verb-per-class ratio arenot relevant for investigating the use of associations.ment NPs and PPs (as separate sets and together),and in addition we checked verb-noun pairs in themost common specific NP functions: n refers to the(nominative) intransitive subject, na to the transi-tive subject, and na to the transitive (accusative) ob-ject.
For the windows, all checks on co-occurrenceof verbs and associations in the whole 200-millionword corpus.
cut also checks the whole corpus, butdisregards the most and least frequent co-occurringwords: verb-word pairs were only considered if theco-occurrence frequency of the word over all verbswas above 100 (disregarding low frequency pairs)and below 200,000 (disregarding high frequencypairs).
Using the cut-offs, we can distinguish therelevance of high- and low-frequency features.
Fi-nally, ADJ, ADV, N, V perform co-occurrence checksfor the whole corpus, but breaks down the all resultswith respect to the association part-of-speech.As one would have expected, most of the as-sociations (66%) were found in the 20-word co-occurrence window, because the window is neitherrestricted to a certain part-of-speech, nor to a certaingrammar relation; in addition, the window is poten-tially larger than a sentence.
Applying the frequencycut-offs reduces the overlap of association types andco-occurring words to 58%.
Specifying the windowresults for the part-of-speech types illustrates thatthe nouns play the most important role in describingverb meaning (39% of the verb association types inthe assoc-classes were found among the nouns in thecorpus windows, 16% among the verbs, 9% amongthe adjectives, and 2% among the adverbs).3The proportions of the nouns with a specificgrammar relationship to the verbs show that we findmore associations among direct objects than intran-sitive/transitive subjects.
This insight confirms theassumption in previous work where only direct ob-ject nouns were used as salient features in distribu-tional verb similarity, such as Pereira et al (1993).However, the proportions are all below 10%.
Con-sidering all NPs and/or PPs, we find that the pro-portions increase for the NPs, and that the NPs playa more important role than the PPs.
This insightconfirms work on distributional similarity where notonly direct object nouns, but all functional nouns3Caveat: These numbers correlate with the part-of-speechtypes of all associate responses: 62% of the responses werenouns, 25% verbs, 11% adjectives, and 2% adverbs.72Features grammar relationsn na na NP PP NP&PP ADVCov.
(%) 3.82 4.32 6.93 12.23 5.36 14.08 3.63Features co-occurrence: window-20all cut ADJ ADV N VCov.
(%) 66.15 57.79 9.13 1.72 39.27 15.51Table 3: Coverage of verb association features by grammar/window resources.were considered as verb features, such as Lin (1998)and McCarthy et al (2003).
Of the adverb associ-ations, we find only a small proportion among theparsed adverbs.
All in all, the proportions of asso-ciation types among the nouns/adverbs with a syn-tactic relationship to the verbs are rather low.
Com-paring the NP/PP proportions with the window nounproportions shows that salient verb features are notrestricted to certain syntactic relationships, but alsoappear in a less restricted context window.5 Inducing Verb Classes withCorpus-based FeaturesIn the final step, we applied the corpus-based fea-ture types to clusterings.
The goal of this step wasto determine whether the feature exploration helpedto identify salient verb features, and whether we canoutperform previous clustering results.
The cluster-ing experiments were as follows: The 330 experi-ment verbs were instantiated by the feature types weexplored in Section 4.
As for the assoc-classes, wethen performed an agglomerative hierarchical clus-tering.
We cut the hierarchy at a level of 100 clus-ters, and evaluated the clustering against the 100-class analysis of the original assoc-classes.
We ex-pect that feature types with a stronger overlap withthe association types result in a better clustering re-sult.
The assumption is that the associations aresalient feature for verb clustering, and the betterwe model the associations with grammar-based orwindow-based features, the better the clustering.For checking the clusterings with respect to thesemantic class type, we also applied the corpus-based features to GermaNet and FrameNet classes.?
GermaNet: We randomly extracted 100 verbclasses from all GermaNet synsets, and createda hard classification for these classes, by ran-domly deleting additional senses of a verb soas to leave only one sense for each verb.
Thisselection made the GermaNet classes compara-ble to the assoc-classes in size and polysemy.The 100 classes contain 233 verbs.
Again, weperformed an agglomerative hierarchical clus-tering on the verbs (as modelled by the differentfeature types).
We cut the hierarchy at a levelof 100 clusters, which corresponds to the num-ber of GermaNet classes, and evaluated againstthe GermaNet classes.?
FrameNet: In a pre-release version from May2005, there were 484 verbs in 214 GermanFrameNet classes.
We disregarded the high-frequency verbs gehen, geben, sehen, kommen,bringen which were assigned to classes mostlyon the basis of multi-word expressions they arepart of.
In addition, we disregarded two largeclasses which contained mostly support verbs,and we disregarded singletons.
Finally, we cre-ated a hard classification of the classes, by ran-domly deleting additional senses of a verb so asto leave only one sense for each verb.
The clas-sification then contained 77 classes with 406verbs.
Again, we performed an agglomerativehierarchical clustering on the verbs (as mod-elled by the different feature types).
We cut thehierarchy at a level of 77 clusters, which corre-sponds to the number of FrameNet classes, andevaluated against the FrameNet classes.For the evaluation of the clustering results, we calcu-lated the accuracy of the clusters, a cluster similaritymeasure that has been applied before, cf.
(Stevensonand Joanis, 2003; Korhonen et al, 2003).4 Accuracyis determined in two steps:4Note that we can use accuracy for the evaluation becausewe have a fixed cut in the hierarchy as based on the gold stan-dard, as opposed to the evaluation in Section 3 where we ex-plored the optimal cut level.73frames grammar relationsf-pp f-pp-pref n na na NP PP NP&PP ADVAssoc 37.50 37.80 35.90 37.18 39.25 39.14 37.97 41.28 38.53GN 46.98 49.14 58.01 53.37 51.90 53.10 54.21 51.77 51.82FN 33.50 32.76 29.46 30.13 32.74 34.16 28.72 33.91 35.24co-occurrence: window-20all cut ADJ ADV N VAssoc 39.33 39.45 37.31 36.89 39.33 38.84GN 51.53 52.42 50.88 47.79 52.86 49.12FN missing 32.84 31.08 31.00 34.24 31.75Table 4: Accuracy for induced verb classes.1.
For each class in the cluster analysis, the goldstandard class with the largest intersection ofverbs is determined.
The number of verbs in theintersection ranges from one verb only (in caseall clustered verbs are in different classes in thegold standard) to the total number of verbs ina cluster (in case all clustered verbs are in thesame gold standard class).2.
Accuracy is calculated as the proportion of theverbs in the clusters covered by the same goldstandard classes, divided by the total numberof verbs in the clusters.
The upper bound of theaccuracy measure is 1.Table 4 shows the accuracy results for the threetypes of classifications (assoc-classes, GermaNet,FrameNet), and the grammar-based and window-based features.
We added frame-based features, asto compare with earlier work: The frame-based fea-tures provide a feature description over 183 syntac-tic frame types including PP type specification (f-pp), and the same information plus coarse selec-tional preferences for selected frame slots, as ob-tained from GermaNet top-level synsets (f-pp-pref),cf.
(Schulte im Walde, 2003).
The following ques-tions are addressed with respect to the result table.1.
Do the results of the clusterings with respectto the underlying feature types correspond tothe overlap of associations and feature types,cf.
Table 3?2.
Do the corpus-based feature types which wereidentified on the basis of the associations out-perform previous clustering results?3.
Do the results generalise over the semanticclass type?First of all, there is no correlation between theoverlap of associations and feature types on the onehand and the clustering results as based on the fea-ture types on the other hand (Pearson?s correlation,p>.1), neither for the assoc-classes or the GermaNetor FrameNet classes.
The human associations there-fore did not contribute to identify salient featuretypes, as we had hoped.
In some specific cases, wefind corresponding patterns; for example, the clus-tering results for the intransitive and transitive sub-ject and the transitive object correspond to the over-lap values for the assoc-classes and FrameNet: n <na < na.
Interestingly, the GermaNet clusterings be-have in the opposite direction.Comparing the grammar-based relations witheach other shows that for the assoc-classes usingall NPs is better than restricting the NPs to (sub-ject) functions, and using both NPs and PPs is best;similarly for the FrameNet classes where using allNPs is the second best results (but adverbs).
Differ-ently, for the GermaNet classes the specific functionof intransitive subjects outperforms the more gen-eral feature types, and the PPs are still better thanthe NPs.
We conclude that not only there is no cor-relation between the association overlap and featuretypes, but in addition the most successful featuretypes vary strongly with respect to the gold stan-dard.
None of the differences within the featuregroups (n/na/na and NP/PP/NP&PP) are significant(?2, df = 1, ?
= 0.05).
The adverbial featuresare surprisingly successful in all three clusterings, insome cases outperforming the noun-based features.Comparing the grammar-based clustering resultswith previous results, the grammar-based featuresoutperform the frame-based features in all cluster-ings for the GermaNet verbs.
For the FrameNet74verbs and the experiment verbs, they outperform theframe-based features only in specific cases.
Theadverbial features outperform the frame-based fea-tures in any clustering.
However, none of the differ-ences between the frame-based clusterings and thegrammar-based clusterings are significant (?2, df =1, ?
= 0.05).For all gold standards, the best window-basedclustering results are below the best grammar-basedresults.
Especially the all results demonstrateonce more the missing correlation between associa-tion/feature overlap and clustering results.
However,it is interesting that the clusterings based on win-dow co-occurrence are not significantly worse (andin some cases even better) than the clusterings basedon selected grammar-based functions.
This meansthat a careful choice and extraction of specific rela-tionships for verb features does not have a signifi-cant impact on semantic classes.Comparing the window-based features againsteach other shows that even though we discovereda much larger proportion of association types in anunrestricted window all than elsewhere, the resultsin the clusterings do not differ accordingly.
Apply-ing the frequency cut-offs has almost no impact onthe clustering results, which means that it does noharm to leave away the rather unpredictable features.Somehow expected but nevertheless impressive isthe fact that only considering nouns as co-occurringwords is as successful as considering all words inde-pendent of the part-of-speech.Finally, the overall accuracy values are muchbetter for the GermaNet clusterings than for theexperiment-based and the FrameNet clusterings.The differences are all significant (?2, df = 1, ?
=0.05).
The reason for these large differences couldbe either (a) that the clustering task was easier forthe GermaNet verbs, or (b) that the differences arecaused by the underlying semantics.
We argueagainst case (a) since we deliberately chose the samenumber of classes (100) as for the association-basedgold standard; however, the verbs-per-class ratio forGermaNet vs. the assoc-classes and the FrameNetclasses is different (2.33 vs. 3.30/5.27) and we can-not be sure about this influence.
In addition, theaverage verb frequencies in the GermaNet classes(calculated in a 35 million word newspaper corpus)are clearly below those in the other two classifica-tions (1,040 as compared to 2,465 and 1,876), andthere are more low-frequency verbs (98 out of 233verbs (42%) have a corpus frequency below 50, ascompared to 41 out of 330 (12%) and 54 out of 406(13%)).
In the case of (b), the difference in the se-mantic class types is modelling synonyms with Ger-maNet as opposed to situation-based agreement inFrameNet.
The association-based class semanticsis similar to FrameNet, because the associations areunrestricted in their semantic relation to the experi-ment verb (Schulte im Walde and Melinger, 2005).6 SummaryThe questions we posed in the beginning of this pa-per were (i) whether human associations help iden-tify salient features to induce semantic verb classes,and (ii) whether the same types of features aresalient for different types of semantic verb classes.An association-based clustering with 100 classesserved as source for identifying a set of potentiallysalient verb features, and a comparison with stan-dard corpus-based features determined proportionsof feature overlap.
Applying the standard featurechoices to verbs underlying three gold standard verbclassifications showed that (a) in our experimentsthere is no correlation between the overlap of associ-ations and feature types and the respective clusteringresults.
The associations therefore did not help in thespecific choice of corpus-based features, as we hadhoped.
However, the assumption that window-basedfeatures do contribute to semantic verb classes ?
thisassumption came out of an analysis of the associ-ations ?
was confirmed: simple window-based fea-tures were not significantly worse (and in some caseseven better) than selected grammar-based functions.This finding is interesting because window-basedfeatures have often been considered too simple forsemantic similarity, as opposed to syntax-based fea-tures.
(b) Several of the grammar-based nomi-nal and adverbial features and also the window-based features outperformed feature sets in previ-ous work, where frame-based features (plus prepo-sitional phrases and coarse selectional preferenceinformation) were used.
Surprisingly well did ad-verbs: they only represent a small number of verbfeatures, but obviously this small selection can out-perform frame-based features and even some nomi-75nal features.
(c) The clustering results were signif-icantly better for the GermaNet clusterings than forthe experiment-based and the FrameNet clusterings,so the chosen feature sets might be more appropri-ate for the synonymy-based than the situation-basedclassifications.Acknowledgements Thanks to Christoph Clodoand Marty Mayberry for their system administrativehelp when running the cluster analyses.ReferencesKatrin Erk, Andrea Kowalski, Sebastian Pado?, and Man-fred Pinkal.
2003.
Towards a Resource for Lexical Se-mantics: A Large German Corpus with Extensive Se-mantic Annotation.
In Proceedings of the 41st AnnualMetting of the Association for Computational Linguis-tics, Sapporo, Japan.Christiane Fellbaum, editor.
1998.
WordNet ?
An Elec-tronic Lexical Database.
Language, Speech, andCommunication.
MIT Press, Cambridge, MA.Eva Esteve Ferrer.
2004.
Towards a Semantic Classi-fication of Spanish Verbs based on SubcategorisationInformation.
In Proceedings of the 42nd Annual Meet-ing of the Association for Computational Linguistics,Barcelona, Spain.Charles J. Fillmore.
1982.
Frame Semantics.
Linguisticsin the Morning Calm, pages 111?137.Thierry Fontenelle, editor.
2003.
FrameNet and FrameSemantics, volume 16(3) of International Journal ofLexicography.
Oxford University Press.
Special issuedevoted to FrameNet.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1993.
Towards the Automatic Identification of Ad-jectival Scales: Clustering Adjectives According toMeaning.
In Proceedings of the 31st Annual Meet-ing of the Association for Computational Linguistics,pages 172?182, Columbus, Ohio.Eric Joanis and Suzanne Stevenson.
2003.
A GeneralFeature Space for Automatic Verb Classification.
InProceedings of the 10th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, Budapest, Hungary.Anna Korhonen, Yuval Krymolowski, and Zvika Marx.2003.
Clustering Polysemic Subcategorization FrameDistributions Semantically.
In Proceedings of the 41stAnnual Meeting of the Association for ComputationalLinguistics, pages 64?71, Sapporo, Japan.Claudia Kunze.
2000.
Extension and Use of GermaNet,a Lexical-Semantic Database.
In Proceedings of the2nd International Conference on Language Resourcesand Evaluation, pages 999?1002, Athens, Greece.Lillian Lee.
2001.
On the Effectiveness of the Skew Di-vergence for Statistical Language Analysis.
ArtificialIntelligence and Statistics, pages 65?72.Dekang Lin.
1998.
Automatic Retrieval and Cluster-ing of Similar Words.
In Proceedings of the 17th In-ternational Conference on Computational Linguistics,Montreal, Canada.Diana McCarthy, Bill Keller, and John Carroll.
2003.Detecting a Continuum of Compositionality in PhrasalVerbs.
In Proceedings of the ACL-SIGLEX Workshopon Multiword Expressions: Analysis, Acquisition andTreatment, Sapporo, Japan.Paola Merlo and Suzanne Stevenson.
2001.
AutomaticVerb Classification Based on Statistical Distributionsof Argument Structure.
Computational Linguistics,27(3):373?408.Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993.Distributional Clustering of English Words.
In Pro-ceedings of the 31st Annual Meeting of the Associationfor Computational Linguistics, pages 183?190.Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Car-roll, and Franz Beil.
1999.
Inducing a SemanticallyAnnotated Lexicon via EM-Based Clustering.
In Pro-ceedings of the 37th Annual Meeting of the Associationfor Computational Linguistics, Maryland, MD.Sabine Schulte im Walde and Alissa Melinger.
2005.Identifying Semantic Relations and Functional Prop-erties of Human Verb Associations.
In Proceedings ofthe joint Conference on Human Language Technologyand Empirial Methods in Natural Language Process-ing, pages 612?619, Vancouver, Canada.Sabine Schulte im Walde.
2003.
Experiments on the Au-tomatic Induction of German Semantic Verb Classes.Ph.D.
thesis, Institut fu?r Maschinelle Sprachverar-beitung, Universita?t Stuttgart.
Published as AIMS Re-port 9(2).Sabine Schulte im Walde.
2006.
Human Verb Associa-tions as the Basis for Gold Standard Verb Classes: Val-idation against GermaNet and FrameNet.
In Proceed-ings of the 5th Conference on Language Resources andEvaluation, Genoa, Italy.Suzanne Stevenson and Eric Joanis.
2003.
Semi-supervised Verb Class Discovery Using Noisy Fea-tures.
In Proceedings of the 7th Conference on NaturalLanguage Learning, pages 71?78, Edmonton, Canada.76
