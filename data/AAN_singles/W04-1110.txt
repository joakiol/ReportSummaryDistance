Automated Alignment and Extraction of Bilingual Domain Ontology forMedical Domain Web SearchJui-Feng Yeh*?, Chung-Hsien Wu*, Ming-Jun Chen* and Liang-Chih Yu**Department of Computer Science and Information EngineeringNational Cheng Kung University, Taiwan, R.O.C.
{chwu, jfyeh, mjchen,lcyu}@csie.ncku.edu.tw?Department of Computer Application EngineeringFar East College, Taiwan, R.O.C.AbstractThis paper proposes an approach to automatedontology alignment and domain ontologyextraction from two knowledge bases.
First,WordNet and HowNet knowledge bases arealigned to construct a bilingual universalontology based on the co-occurrence of thewords in a parallel corpus.
The bilingualuniversal ontology has the merit that itcontains more structural and semanticinformation coverage from twocomplementary knowledge bases, WordNetand HowNet.
For domain-specific applications,a medical domain ontology is further extractedfrom the universal ontology using the island-driven algorithm and a medical domain corpus.Finally, the domain-dependent terms and someaxioms between medical terms based on amedical encyclopaedia are added into theontology.
For ontology evaluation,experiments on web search were conductedusing the constructed ontology.
Theexperimental results show that the proposedapproach can automatically align and extractthe domain-specific ontology.
In addition, theextracted ontology also shows its promisingability for medical web search.1 IntroductionIn intelligent mining, in order to obviate theunnecessary keyword expansion, some knowledgebase should be involved in the intelligentinformation system.
In recent years, considerableprogress has been invested in developing theconceptual bases for building technology thatallows knowledge reuse and sharing.
Asinformation exchangeability and communicationbecomes increasingly global, multiple-languagelexical resources that can provide transnationalservices are becoming increasingly important.Over the last few years, significant effort has beenmade to construct the ontology manually accordingto the domain expert?s knowledge.
Manualontology merging using conventional editing toolswithout intelligent support is difficult, laborintensive and error prone.
Therefore, severalsystems and frameworks for supporting theknowledge engineer in the ontology merging taskhave recently been proposed.
To avoid thereiteration in ontology construction, the algorithmof ontology merge (UMLShttp://umlsks.nlm.nih.gov/) (Langkilde and Knight1998) and ontology alignment (Vossen and Peters1997) (Weigard and Hoppenbrouwers 1998)(Asanoma 2001) were invested.
The final ontologyis a merged version of the original ontologies.
Thetwo original ontologies persist, with linksestablished between them in alignment.
Alignmentusually is performed when the ontologies coverdomains that are complementary to each other.
Inthe past, domain ontology was usually constructedmanually according to the knowledge orexperience of the experts or ontology engineers.Recently, automatic and semi-automatic methodshave been developed.
OntoExtract (Fensel et al2002) (Missikoff et al 2002) provided an ontologyengineering chain to construct the domain ontologyfrom WordNet and SemCor.On the other hand, multi-lingual ontology is veryimportant for natural language processing, such asmachine translation (MT), web mining and crosslanguage information retrieval (CLIR).
Generally,a multi-lingual ontology maps the keyword set ofone language to another language, or compute theco-occurrence of the words among languages.
Inaddition, a key merit for multilingual ontology isthat it can increase the relation and structuralinformation coverage by aligning two or morelanguage-dependent ontologies with differentsemantic features.Nowadays large collections of information invarious styles are available on the Internet.
Andfinding desired information on the World WideWeb is becoming a critical issue.
Some general-purpose search engine like Google(http://www.google.com) and Altavista(http://www.altavista.com/) provide the facility tomine the web.
There are three major research areasabout web mining: web content mining, webstructure mining and web usage mining.
This paperproposes a novel method to web content miningwith unstructured web pages.
There are manyapproaches in the view of natural languageprocessing.
According to the representation of webpages, there are three kinds of the content: bag ofwords (with order or not) (Kargupta et al 1997)(Nahm and Mooney, 2000), phrases (Ahonen et al1998) (Frank et al 1999)(Yang et al 1999),relational terms (Cohen, 1998) (Junker 1999) andconcept categories.
We proposed an ontology-based web search approach.
Unfortunately, thereare some irrelevant pages obtained and these pagesresult in low precision rate and recall rate due tothe problem of polysemy.
To solve this problem,domain knowledge becomes necessary.
Thedomain-specific web miners like SPIRAL, Cora(Cohen, 1998), WebKB (Martin and  Eklund 2000)and HelpfulMed (Chen et al 2003) are employedas the special search engine for the interestingtopic.
These ones dedicated to recipes are lesslikely to return irrelevant web pages when thequery is entered.In this paper, WordNet and HowNet knowledgebases are aligned to construct a bilingual universalontology based on the co-occurrence of the wordsin a parallel corpus.
For domain-specificapplications, a medical domain ontology is furtherextracted from the universal ontology using theisland-driven algorithm (Lee et al 1995) and amedical domain corpus.
Finally, the axiomsbetween medical terms are derived based onsemantic relations.
A web search system formedical domain based on the extracted domainontology is realized to demonstrate the feasibilityof the methods proposed in this paper.The rest of the paper is organized as follows.Section 2 describes ontology construction processand the web searching system framework.
Section3 presents the experimental results for theevaluation of our approach.
Section 4 gives someconcluding remarks.2 MethodologiesFigure 1 shows the block diagram for ontologyconstruction and the framework of the domain-specific web search system.
There are four majorprocesses in the proposed system: bilingualontology alignment, domain ontology extraction,knowledge representation and domain-specific websearch.2.1 Bilingual Ontology AlignmentIn this approach, the cross-lingual ontology isconstructed by aligning the words in WordNet withtheir corresponding words in HowNet.
First, theSinorama (Sinorama 2001) database is adopted asthe bilingual language parallel corpus to computethe conditional probability of the words inWordNet, given the words in HowNet.
Second, abottom up algorithm is used for relation mapping.Figure 1 Ontology construction framework and the domain-specific web search systemIn WordNet a word may be associated with manysynsets, each corresponding to a different sense ofthe word.
When we look for a relation between twodifferent words we consider all the synsetsassociated with each word (Christiane 1998).
InHowNet, each word is composed of primaryfeatures and secondary features.
The primaryfeatures indicate the word?s category.
The purposeof this approach is to increase the relation andstructural information coverage by aligning theabove two language-dependent ontologies,WordNet and HowNet, with different semanticfeatures.The relation ?is-a?
defined in WordNetcorresponds to the primary feature defined inHowNet.
Equation (1) shows the mapping betweenthe words in HowNet and the synsets in WordNet.Given a Chinese word, iCW  , the probability of theword related to synset, ksynset  , can be obtainedvia its corresponding English synonyms,,  1,...,kjEW j m=  , which are the elements inksynset  .
The probability is estimated as follows.11Pr( | )Pr( , | )(Pr( | , ) Pr( | ))kim k kj ijm k k kj i j ijsynset CWsynset EW CWsynset EW CW EW CW=== ?= ??
(1)where( ) ( )( ), ,Pr | ,, ,k kj j ik kj il kj j ilN synset EW CWsynset EW CWN synset EW CW=?
(2)In the above equation, ( ), ,k kj j iN synset EW CWrepresents the number of co-occurrences of iCW  ,kjEW  and kjsynset .
The probability ( )Pr |kj iEW CW   isset to one when at least one of the primary features,( )li iPF CW , of the Chinese word defined in theHowNet matches one of the ancestor nodes ofsynset , ( )kj jsynset EW  except the root nodes inthe hierarchical structures of the noun and verb;Otherwise set to zero.
That is,( )( )( )( )Pr |{ , , , }1( ( )) { , , , }0j ili ilkj jkEW CWPF CW entity event act playifancestor synset EW entity event act playotherwise?
??
?= ?
?
?
??????
?
?
(3)where {enitity,event,act,play} is the concept set inthe root nodes of HowNet and WordNet.Finally, the Chinese concept,iCW  , has beenintegrated into the synset , kjsynset   , in WordNet aslong as the probability, Pr k i(synset |CW )  , is notzero.
Figure 2 shows the concept tree generated byaligning WordNet and HowNet.Figure 2.
Concept tree generated by aligningWordNet and HowNet.
The nodes with bold circlerepresent the operative nodes after conceptextraction.
The nodes with gray backgroundrepresent the operative nodes after relationexpansion.2.2 Domain ontology extractionThere are two phases to construct the domainontology: 1) extract the ontology from the cross-language ontology by island-driven algorithm, and2) integrate the terms and axioms defined in amedical encyclopaedia into the domain ontology.2.2.1 Extraction by island-driven algorithmOntology provides consistent concepts and worldrepresentations necessary for clear communicationwithin the knowledge domain.
Even in domain-specific applications, the number of words can beexpected to be numerous.
Synonym pruning is aneffective alternative to word sense disambiguation.This paper proposes a corpus-based statisticalapproach to extracting the domain ontology.
Thesteps are listed as follows:Step 1: Linearization: This step decomposed thetree structure in the universal ontology shown inFigure 2 into the vertex list that is an ordered nodesequence starting at the leaf nodes and ending at theroot node.Step 2: Concept extraction from the corpus: Thenode is defined as an operative node when the Tf-idf value of word iW   in the domain corpus ishigher than that in its corresponding contrastive(out-of-domain) corpus.
That is,_ ( )1,     ( ) ( )0,iDomain i Contrastive ioperative node Wif Tf idf W Tf idf WOtherwise?
> ?
?= ??
(4)where, ,,,, ,,,( ) log( ) logi Domain i ContrastiveDomain i i Domaini Domaini Domain i ContrastiveContrastive i i Contrastivei Contrastiven nTf idf W freqnn nTf idf W freqn+?
= ?+?
= ?In the above equations, Domainifreq ,   andeContrastivifreq ,   are the frequencies of word iW   inthe domain documents and its contrastive (out-of-domain) documents, respectively.
Domainin ,   and,i Contrastiven  are the numbers of the documentscontaining word iW   in the domain documents andits contrastive documents, respectively.
The nodeswith bold circle in Figure 2 represent the operativenodes.Step 3: Relational expansion using the island-driven algorithm: There are some domain conceptsnot operative after the previous steps due to theproblem of insufficient data.
From the observationin ontology construction, most of the inoperativeconcept nodes have operative hypernym nodes andhyponym nodes.
Therefore, the island-drivenalgorithm is adopted to activate these inoperativeconcept nodes if their ancestors and descendants areall operative.
The nodes with gray backgroundshown in Figure 2 are the activated operative nodes.Step 4: Domain ontology extraction: The finalstep is to merge the linear vertex list sequence intoa hierarchical tree.
However, some noisy conceptsnot belonging to this domain ontology are operativeafter step 3.
These noisy nodes with inoperativenoisy concepts should be filtered out automatically.Finally, the domain ontology is extracted and thefinal result is shown in Figure 3.After the above steps, a dummy node is added asthe root node of the domain concept tree.Figure 3 The domain ontology after filtering out theisolated concepts2.2.2 Axiom and terminology integrationIn practice, specific domain terminologies andaxioms should be derived and introduced into theontology for domain-specific applications.
In ourapproach, 1213 axioms derived from a medicalencyclopaedia have been integrated into the domainontology.
Figure 4 shows an example of the axiom.In this example, the disease ?diabetes?
is tagged aslevel ?A?
which represents that this disease isfrequent in occurrence.
And the degrees for thecorresponding syndromes represent the causalitybetween the disease and the syndromes.
The axiomsalso provide two fields ?department of the clinicalcare?
and ?the category of the disease?
for medicalinformation retrieval.Figure 4   axiom example2.3 Domain-specific web searchThis paper proposed a medical web search enginebased on the constructed medical domain ontology.The engine consists of natural language interface,web crawler and indexer, relation inference moduleand axiom inference module.
The functions andtechniques of these modules are described asfollows.2.3.1 Natural language interface and webcrawler and indexerNatural language interface is generallyconsidered as an enticing prospect because it offersmany advantages: it would be easy to learn andeasy to remember, because its structure andvocabulary are already familiar to the user; it isparticularly powerful because of the multitude ofways in which to accomplish a search action byusing the natural language input.
A naturallanguage query is transformed to obtain the desiredrepresentation after the word segmentation,removing the stop words, stemming and taggingprocess.The web crawler and indexer are designed to seekmedical web pages from Internet, extract thecontent and establish the indices automatically.2.3.2 Concept inference moduleFor semantic representation, traditionally, thekeyword-based systems will introduce twoproblems.
First, ambiguity usually results from thepolysemy of words.
The domain ontology will givea clear description of the concepts.
In addition, notall the synonyms of the word should be expandedwithout constraints.
Secondly, relations between theconcepts should be expanded and weighted in orderto include more semantic information for semanticinference.
We treat each of the user?s input and thecontent of web pages as a sequence of words.
Thismeans that the sequence of words is treated as a bagof words regardless of the word order.
For the wordsequence of the user?s input,q=Wq=wq1, wq2 ,?, wqK ,and the word sequence of the web page,A=WA=wA1, wA2, ?, wAL,The similarity between input query and the page isdefined as the similarity between the two bags ofwords.
The similarity measure based on keyconcepts in the ontology is defined as follows.
( )( )1 2 1 2,1, 1,,( , ,..., , , ,..., )ii i irelation irelation A qrelation A A A L q q qKK Lklk lSim A qSim W WSim w w w w w wH= ==== ?
(5)where Hkl  is concept similarity of wAl and wqk.
Mostof the keyword expansion approaches use theextension of scope by the synonyms.
In this paperthe similarity, Hkl, is defined as,2 ,1  and  are identicaland  are hypernyms1is the number of levels in between2and  are synonyms11is the number of their common concepts 20 othersAl qkAl qkrklAl qkrw ww wrHw wr????
?= ???
???
???
????
(6)2.3.3 Axiom inference moduleSome axioms, such as ?result in?
and ?resultfrom,?
that are expected to affect the performanceof a web search system in a technical domain aredefined to describe the relationship betweensyndromes and diseases.
This aspect is the use ofspecific terms used in the medical domain.
Wecollected the data about syndromes and diseasesfrom a medical encyclopedia and tagged thediseases with three levels according to itsoccurrence and syndromes with four levelsaccording to its significance to the specific disease.The ?result in?
relation score is defined as ( , )iRI A qif a disease occurs in the input query and itscorresponding syndromes appear in the web page.Similarly, if syndrome occurs in the input query andits corresponding disease appears in the web page,the ?result from?
relation score is defined as( , )iRF A q .
The relation score is estimated as follows.
( )1 2 1 21 2 1 2, ,1, 1 1, 1, max{ ( , ), ( , )}max{ ( , ,..., , , ,..., ),( , ,..., , , ,..., )}max{ , },i i ii i ii i iA A A P q q qRA A A P q q qRP R P RRI RFpr prp r p rAxiom A q RI A q RF A qRI w w w w w wRF w w w w w wd d= = = ==== ?
?
(7)where 11/ 2RI nprd?=  if disease Apw  results insyndrome qrw  and qrw  is the top-n feature of Apw .Similarly, 11/ 2RF nprd?=  if syndrome Apw  resultsfrom disease qrw  and Apw  is the top-n feature ofqrw .
The conditional probability of the i-th webpages with respect to aspect ,2As  and query q isdefined as( ) ( )( ),,,iaxiom iiiAxiom A qSim A qAxiom A q= ?.3 EvaluationTo evaluate the proposed approach, a medicalweb search system was constructed.
The web pageswere collected from several Websites and totally2322 web pages for medical domain and 8133 webpages for contrastive domain were collected.On the other hand, the training and test queriesfor training and evaluating the system performancewere also collected.
Forty users, who do not takepart in the system development, were asked toprovide a set of queries given the collected webpages.
After post-processing, the duplicate queriesand the queries out of the medical domain areremoved.
Finally, 3207 test queries mixed Chinesewith English words using natural language wereobtained.3.1 Keyword-Based VSM Approach: Abaseline system for comparisonIn recent years, most of the information retrievalapproaches were based on the Vector-Space Model(VSM).
Assuming that the query is denoted as avector 1 2q ( , ,..., )nq q q=  and the web page isrepresented as a vector 1 2( , ,..., )nA a a a= .
TheTf-idf measure is employed and the similarity canbe measured by the cosine function defined asfollows.12 21 1( , ) cos(a,q)ni iikeyword based i n ni ii ia qSim A qa q=?= == =???
?
(8)where a 1= .
This approach for key termexpansion based on synonym set is also adopted inthe baseline system.
The results and discussions aredescribed in the following sections.3.2 Weight determination using 11-avgP scoreThe medical domain web search system ismodeled by the linear combination of relationalinference model and axiom inference model.
Thenormalized weight factor, ?
, is employed forconcept expansion as follows.
( , ) (1 ) ( , ) ( , )i relation i axiom iSim A q Sim A q Sim A q?
?= ?
+ ?
(9)This experiment is conducted on the estimation ofthe combination weights for each model.
Theresults are shown in Figure 5.
The performancemeasure called 11-AvgP [Eichmann and Srinivasan1998] was used to summarize the precision andrecall rates.
The best 11-AvgP score will beobtained when the weight 0.428?
= .0.540.580.620.660.70 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?11-avgPscoreFigure 5 The 11-avgP score with different values of ?3.3 Evaluation on different inference modulesIn the following experiments, web pages wereseparately evaluated by focusing on one inferencemodule based on the domain-specific ontology at atime.
That is, the mixture weight is set to 1 for oneinference module and the other is set to 0 in eachevaluation.
For comparison, the keyword-basedVSM approach and the ontology-based system arealso evaluated and shown in Figure 6.
The precisionand recall rates are used as the evaluation measures.And the ontology based approach means thecombination of concept inference and axiominference described in the section 3.2.01020304050607080901000 10 20 30 40 50 60 70 80 90 100Recall rate (%)Precisionrate(%)Ontology basedBaseline+concept infernecemoduleBaseline+axiom inferencemoduleBaselineFigure 6 The precision rates and recall rates of theproposed method and  the baseline system4 ConclusionThis paper has presented an approach toautomated ontology alignment and domainontology extraction from two knowledge bases.
Inthis approach, a bilingual ontology is developedusing a corpus-based statistical approach from twowell established language-dependent knowledgebases, WordNet and HowNet.
A domain-dependentontology is further extracted from the universalontology using the island-driven algorithm and adomain corpus.
In addition, domain-specific termsand axioms are also added into the domain ontology.We have applied the domain-specific ontology tothe web page search in medical domain.
Theexperimental results show that the proposedapproach outperformed the keyword-based  andsynonym expansion approaches.ReferencesN.
Asanoma.
2001 Alignment of Ontologies:WordNet and Goi-Taikei.
WordNet and OtherLexical Resources Workshop Program,NAACL2001.
89-94Christiane Fellbaum, 1998 WordNet an electronicLexical Database, The MIT Press 1998. pp307-308Fensel, D., Bussler, C., Ding, Y., Kartseva1, V.,Klein, M., Korotkiy, M., Omelayenko, B. andSiebes R. 2002 Semantic Web Application Areas,the 7th International Workshop on Applicationsof Natural Language to Information Systems(NLDB02).M.
Missikoff,, R. Navigli, and P. Velardi.
2002Integrated approach to Web ontology learningand engineering, Computer , Volume: 35 Issue:11 .
60 ?63N.F.
Noy, and M. Musen,.
2000 PROMPT:Algorithm and Tool for Automated OntologyMerging and Alignment, Proceedings of theNational Conference on Artificial Intelligence.AAAI2000.
450-455Sinorama Magazine and Wordpedia.com Co. 2001Multimedia CD-ROMs of Sinorama from 1976 to2000, Taipei.P.
Vossen, and W. Peters, 1997 Multilingual designof EuroWordNet, Proceedings of the Delosworkshop on Cross-language InformationRetrieval.H.
Weigard, and S. Hoppenbrouwers, 1998,Experiences with a multilingual ontology-basedlexicon for news filtering, Proceedings in the 9thInternational Workshop on Database and ExpertSystems Applications.
160-165H.
Kargupta, I. Hamzaoglu, and B. Stafford.
1997.Distributed data mining using an agent basedarchitecture.
In Proceedings of KnowledgeDiscovery and Data Mining, 211-214.U.
Y. Nahm and R. J. Mooney.
2000.
A mutuallybeneficial integration of data mining andinformation extraction.
In Proceeding of theAAAI-00.H.
Ahonen, O. Heinoen, M. Klemettinen, and A.Verkamo.
1998.
Applying data mining techniquesfor descriptive phrase extraction in digitaldocument collections.
In Advence in DigitalLibraries.E.
Frank, G. W. Paynter, I. H. Witten, C. Gutwin,and C. G. Nevill-Manning.
1999.
Domain-specific keyphrase extraction.
In proceding ofIJCAI-99, 668-673.Y.
Yang, J. Carbonell, R. Brown, T. Pierce, B. T.Archibald, and X. Liu.
1999.
Learningapproaches for detecting and tracking newsevents.
IEEE Intelligent Systems, 14(4):32-43.W.
W. Cohen.
1998.
A web-based informationsystem that reasons with structured collocationsof text.
In Proceedings of 2nd Agent'98M.
Junker, M. Sintek, and M. Rinck.
1999 Learningfor text categorization and information extractionwith ilp.
In Proceedings of the Workshop onLearning Language in Logic, Bled, SloveniaS.
Oyama, T. Kokubo, and T. Ishida.
2004 Domain-Specific Web Search with Keyword Spice.
IEEETransactions on Knowledge and DataEngineering, Vol 16,NO.
1, 17-27.Sankar K. Pal, Varun Talwar, and Pabitra Mitra.2002.
Web Minging in Soft ComputingFramework: Relevance, State of the Art andFuture Directions.
IEEE Transactions on NeuralNetworks, Vol.
13, NO.
5.T.
Hofmann.
1999.
The cluster-abstraction model:Unsupervised learning of topic hierarchies fromtext data.
In Proceedings of 16th IJCAI, 682-687,P.
Martin and P. Eklund.
2000.
KnowledgeIndexation and Retrieval and the Word WideWeb.
IEEE Intelligent Systems, special issue"Knowledge Management and KnowledgeDistribution over the Internet"H. Chen, A. M. Lally, B. Zhu, and M. Chau.
,2003HelpfulMed: Intelligent Searching for MedicalInformation over the internet.
Journal od theAmerican Society for Information Science andTechnology, 54(7):683-694.D.
Eichmann, , Ruiz, M., Srinivasan, P., 1998Cross-language information retrieval with theUMLS Metathesaurus, Proceeding of ACMSpecial Interest Group on Information Retreival(SIGIR), ACM Press, NY (1998), 72-80.
