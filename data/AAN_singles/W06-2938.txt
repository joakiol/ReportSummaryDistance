Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X),pages 246?250, New York City, June 2006. c?2006 Association for Computational LinguisticsDependency Parsing as a Classication ProblemDeniz YuretKoc?
UniversityIstanbul, Turkeydyuret@ku.edu.trAbstractThis paper presents an approach to depen-dency parsing which can utilize any stan-dard machine learning (classification) al-gorithm.
A decision list learner was usedin this work.
The training data providedin the form of a treebank is converted to aformat in which each instance representsinformation about one word pair, and theclassification indicates the existence, di-rection, and type of the link between thewords of the pair.
Several distinct mod-els are built to identify the links betweenword pairs at different distances.
Thesemodels are applied sequentially to give thedependency parse of a sentence, favoringshorter links.
An analysis of the errors,attribute selection, and comparison of dif-ferent languages is presented.1 IntroductionThis paper presents an approach to supervised learn-ing of dependency relations in a language using stan-dard machine learning techniques.
The treebanks(Hajic?
et al, 2004; Chen et al, 2003; Bo?hmova?et al, 2003; Kromann, 2003; van der Beek et al,2002; Brants et al, 2002; Kawata and Bartels, 2000;Afonso et al, 2002; Dz?eroski et al, 2006; Civit Tor-ruella and Mart??
Anton?
?n, 2002; Nilsson et al, 2005;Oflazer et al, 2003; Atalay et al, 2003) provided forthe CoNLL shared task(Buchholz et al, 2006) wereconverted to a set of instances each of which con-sists of the attributes of a candidate word pair witha classification that indicates the existence, directionand type of the dependency link between the pair.An initial model is built to identify dependencyrelations between adjacent word pairs using a deci-sion list learning algorithm.
To identify longer dis-tance relations, the adjacent modifiers are droppedfrom the sentence and a second order model is builtbased on the word pairs that come into contact.
Atotal of three models were built using this techniquesuccessively and used for parsing.All given attributes are considered as candidatesin an attribute selection process before building eachmodel.
In addition, attributes indicating suffixes ofvarious lengths and character type information wereconstructed and used.To parse a given sentence, the models are appliedsequentially, each one considering candidate wordpairs and adding new links without deleting the ex-isting links or creating conflicts (cycles or crossings)with them.
Thus, the algorithm can be considered abottom-up, multi-pass, deterministic parser.
Givena candidate word pair, the models may output ?nolink?, or give a link with a specified direction andtype.
Thus labeling is an integrated step.
Wordpair candidates that may form cycles or crossingsare never considered, so the parser will only gen-erate projective structures.Section 2 gives the details of the learning algo-rithm.
Section 3 describes the first pass model oflinks between adjacent words.
Section 4 detailsthe approach for identifying long distance links andpresents the parsing results.2462 The Learning AlgorithmThe Greedy Prepend Algorithm (Yuret and Ture,2006) was used to build decision lists to identify de-pendency relations.
A decision list is an ordered listof rules where each rule consists of a pattern and aclassification (Rivest, 1987).
The first rule whosepattern matches a given instance is used for its clas-sification.
In our application the pattern specifies theattributes of the two words to be linked such as partsof speech and morphological features.
The classi-fication indicates the existence and the type of thedependency link between the two words.Table 1 gives a subset of the decision list that iden-tifies links between adjacent words in German.
Theclass column indicates the type of the link, the pat-tern contains attributes of the two candidate words Xand Y, as well as their neighbors (XL1 indicates theleft neighbor of X).
For example, given the part ofspeech sequence APPR-ART-NN, there would be anNK link between APPR and ART (matches rule 3), butthere would be no link between ART and NN (rule 1overrides rule 2).Rule Class Pattern1 NONE XL1:postag=APPR2 L:NK X:postag=ART Y:postag=NN3 R:NK X:postag=APPR4 NONETable 1: A four rule decision list for adjacent worddependencies in GermanThe average training instance for the depen-dency problem has over 40 attributes describing thetwo candidate words including suffixes of differentlengths, parts of speech and information on neigh-boring words.
Most of this information may be re-dundant or irrelevant to the problem at hand.
Thenumber of distinct attribute values is on the orderof the number of distinct word-forms in the train-ing set.
GPA was picked for this problem becauseit has proven to be fairly efficient and robust in thepresence of irrelevant or redundant attributes in pre-vious work such as morphological disambiguationin Turkish (Yuret and Ture, 2006) and protein sec-ondary structure prediction (Kurt, 2005).3 Dependency of Adjacent WordsWe start by looking at adjacent words and try to pre-dict whether they are linked, and if they are, whattype of link they have.
This is a nice subproblem tostudy because: (i) It is easily converted to a standardmachine learning problem, thus amenable to com-mon machine learning techniques and analysis, (ii)It demonstrates the differences between languagesand the impact of various attributes.
The machinelearning algorithm used was GPA (See Section 2)which builds decision lists.Table 2 shows the percentage of adjacent tokensthat are linked in the training sets for the languagesstudied1 .
Most languages have approximately halfof the adjacent words linked.
German, with 42.15%is at the low end whereas Arabic and Turkish withabove 60% are at the high end.
The differences maybe due to linguistic factors such as the ubiquity offunction words which prefer short distance links, orit may be an accident of data representation: for ex-ample each token in the Turkish data represents aninflectional group, not a whole word.Arabic 61.02 Japanese 54.81Chinese 56.59 Portuguese 50.81Czech 48.73 Slovene 45.62Danish 55.93 Spanish 51.28Dutch 55.54 Swedish 48.26German 42.15 Turkish 62.60Table 2: Percentage of adjacent tokens linked.3.1 AttributesThe five attributes provided for each word in thetreebanks were the wordform, the lemma, thecoarse-grained and fine-grained parts of speech, anda list of syntactic and/or morphological features.
Inaddition I generated two more attributes for eachword: suffixes of up to n characters (indicatedby suffix[n]), and character type information, i.e.whether the word contains any punctuation charac-ters, upper case letters, digits, etc.Two questions to be answered empirically are: (i)How much context to include in the description ofeach instance, and (ii) Which attributes to use foreach language.1Including non-scoring tokens247Table 3 shows the impact of using varyingamounts of context in Spanish.
I used approximately10,000 instances for training and 10,000 instancesfor testing.
Only the postag feature is used foreach word in this experiment.
As an example, con-sider the word sequence w1 .
.
.
wiwi+1 .
.
.
wn, andthe two words to be linked are wi and wi+1.
Con-text=0 means only information about wi and wi+1is included, context=1 means we also include wi?1and wi+2, etc.
The table also includes the numberof rules in each decision list.
The results are typicalof the experiments performed with other languagesand other attribute combinations: there is a statisti-cally significant improvement going from context=0to context=1.
Increasing the context size furtherdoes not have a significant effect.Context Rules Accuracy0 161 83.171 254 87.312 264 87.053 137 87.14Table 3: Context size vs. accuracy in Spanish.A number of experiments were run to determinethe best attribute combinations for each language.Table 4 gives a set of results for single attributes inSpanish.
These results are based on 10,000 traininginstances and all experiments use context=1.
Postagwas naturally the most informative single attributeon all languages tested, however the second bestor the best combination varied between languages.Suffix[3] indicates all suffixes up to three charactersin length.
The FEATS column was split into its con-stituent features each of which was treated as a bi-nary attribute.Attributes Rules Accuracypostag 254 87.31cpostag 154 85.72suffix[3] 328 77.15lemma 394 76.78form 621 75.06feats 66 71.95ctype 47 53.40Table 4: Attributes vs. accuracy in Spanish.There are various reasons for performing at-tribute selection.
Intuitively, including more infor-mation should be good, so why not use all the at-tributes?
First, not every machine learning algo-rithm is equally tolerant of redundant or irrelevantattributes.
Naive Bayes gets 81.54% and C4.5 gets86.32% on the Spanish data with the single postagattribute using context=1.
One reason I chose GPAwas its relative tolerance to redundant or irrelevantattributes.
However, no matter how robust the algo-rithm, the lack of sufficient training data will pose aproblem: it becomes difficult to distinguish informa-tive attributes from non-informative ones if the datais sparse.
About half of the languages in this studyhad less than 100,000 words of training data.
Fi-nally, studying the contribution of each attribute typein each language is an interesting research topic inits own right.
The next section will present the bestattribute combinations and the resulting accuracy foreach language.3.2 ResultsLanguage Attributes AccuracyArabic ALL 76.87Chinese postag, cpostag 84.51Czech postag, lemma 79.25Danish postag, form 86.96Dutch postag, feats 85.36German postag, form 87.97Japanese postag, suffix[2] 95.56Portuguese postag, lemma 90.18Slovene ALL 85.19Spanish postag, lemma 89.01Swedish postag, form 83.20Turkish ALL 85.27Table 5: Adjacent word link accuracy.Table 5 gives the best attribute combinations fordetermining adjacent word links for each languagestudied.
The attribute combinations and the corre-sponding models were determined using the trainingsets, and the accuracy reported is on the test sets.These attribute combinations were used as part ofthe model in the final evaluation.
I used context=1for all the models.
Because of time limitations at-tribute combinations with more than two attributes248could not be tested and only the first 100,000 train-ing instances were used.
Exceptions are indicatedwith ?ALL?, where all attributes were used in themodel ?
these are cases where using all the attributesoutperformed other subsets tried.For most languages, the adjacent word link accu-racy is in the 85-90% range.
The outliers are Ara-bic and Czech at the lower end, and Japanese at thehigher end.
It is difficult to pinpoint the exact rea-sons: Japanese has the smallest set of link types,and Arabic has the greatest percentage of adjacentword links.
Some of the differences between thelanguages come from linguistic origins, but manyare due to the idiosyncrasies of our particular dataset: number of parts of speech, types of links, qual-ity of the treebank, amount of data are all arbitraryfactors that effect the results.
One observation is thatthe ranking of the languages in Table 5 according toperformance is close to the ranking of the best re-sults in the CoNLL shared task ?
the task of linkingadjacent words via machine learning seems to be agood indicator of the difficulty of the full parsingproblem.4 Long Distance DependenciesRoughly half of the dependency links are betweennon-adjacent words in a sentence.
To illustrate howwe can extend the previous section?s approach tolong distance links, consider the phrase ?kick thered ball?.
The adjacent word linker can only findthe red-ball link even if it is 100% accurate.
How-ever once that link has been correctly identified, wecan drop the modifier ?red?
and do a second passwith the words ?kick the ball?.
This will identify thelink the-ball, and dropping the modifier again leavesus with ?kick ball?.
Thus, doing three passes overthis word sequence will bring all linked words intocontact and allow us to use our adjacent word linker.Table 6 gives the percentage of the links discoveredin each pass by a perfect model in Spanish.Pass: 1 2 3 4 5Link%: 51.09 23.56 10.45 5.99 3.65Table 6: Spanish links discovered in multiple passes.We need to elaborate a bit on the operation of?dropping the modifiers?
that lead from one pass tothe next.
After the discovery of the red-ball linkin the above example, it is true that ?red?
can nolonger link with any other words to the right (it can-not cross its own head), but it can certainly link withthe words to the left.
To be safe, in the next passwe should consider both the-red and the-ball as can-didate links.
In the actual implementation, given apartial linkage, all ?potentially adjacent?
word pairsthat do not create cycles or link crossings were con-sidered as candidate pairs for the next pass.There are significant differences between the firstpass and the second pass.
Some word pairs willrarely be seen in contact during the first pass (e.g.
?kick ball?).
Maybe more importantly, we willhave additional ?syntactic?
context during the sec-ond pass, i.e.
information about the modifiers dis-covered in the first pass.
All this argues for buildinga separate model for the second pass, and maybe forfurther passes as well.In the actual implementation, models for threepasses were built for each language.
To create thetraining data for the n?th pass, all the links that canbe discovered with (n-1) passes are taken as given,and all word pairs that are ?potentially adjacent?given this partial linkage are used as training in-stances.
To describe each training instance, I usedthe attributes of the two candidate words, their sur-face neighbors (i.e.
the words they are adjacent toin the actual sentence), and their syntactic neighbors(i.e.
the words they have linked with so far).To parse a sentence the three passes were run se-quentially, with the whole sequence repeated twice2.Each pass adds new links to the existing partial link-age, but does not remove any existing links.
Table 7gives the labeled and unlabeled attachment score forthe test set of each language using this scheme.5 ConclusionI used standard machine learning techniques to in-vestigate the lower bound accuracy and the impactof various attributes on the subproblem of identify-ing dependency links between adjacent words.
Thetechnique was then extended to identify long dis-tance dependencies and used as a parser.
The modelgives average results for Turkish and Japanese but2This counterintuitive procedure was used because it gavethe best results on the training set.249Language LAS UASArabic 52.42 68.82Chinese 72.72 78.37Czech 51.86 66.36Danish 71.56 78.16Dutch 62.75 66.17German 63.82 67.71Japanese 84.35 87.31Portuguese 70.35 79.46Slovene 55.06 70.60Spanish 69.63 73.89Swedish 65.23 73.25Turkish 60.31 71.54Table 7: Labeled and unlabeled attachment scores.generally performs below average.
The lack of aspecialized parsing algorithm taking into accountsentence wide constraints and the lack of a prob-abilistic component in the model are probably toblame.
Nevertheless, the particular decompositionof the problem and the simplicity of the resultingmodels provide some insight into the difficulties as-sociated with individual languages.ReferencesA.
Abeille?, editor.
2003.
Treebanks: Building and Us-ing Parsed Corpora, volume 20 of Text, Speech andLanguage Technology.
Kluwer Academic Publishers,Dordrecht.S.
Afonso, E. Bick, R. Haber, and D. Santos.
2002.
?Flo-resta sinta?(c)tica?
: a treebank for Portuguese.
In Proc.of the Third Intern.
Conf.
on Language Resources andEvaluation (LREC), pages 1698?1703.N.
B. Atalay, K. Oflazer, and B.
Say.
2003.
The annota-tion process in the Turkish treebank.
In Proc.
of the 4thIntern.
Workshop on Linguistically Interpreteted Cor-pora (LINC).A.
Bo?hmova?, J.
Hajic?, E.
Hajic?ova?, and B. Hladka?.
2003.The PDT: a 3-level annotation scenario.
In Abeille?
(Abeille?, 2003), chapter 7.S.
Brants, S. Dipper, S. Hansen, W. Lezius, and G. Smith.2002.
The TIGER treebank.
In Proc.
of theFirst Workshop on Treebanks and Linguistic Theories(TLT).S.
Buchholz, E. Marsi, A. Dubey, and Y. Krymolowski.2006.
CoNLL-X shared task on multilingual depen-dency parsing.
In Proc.
of the Tenth Conf.
on Com-putational Natural Language Learning (CoNLL-X).SIGNLL.K.
Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,and Z. Gao.
2003.
Sinica treebank: Design criteria,representational issues and implementation.
In Abeille?
(Abeille?, 2003), chapter 13, pages 231?248.M.
Civit Torruella and Ma A.
Mart??
Anton??n.
2002.
De-sign principles for a Spanish treebank.
In Proc.
of theFirst Workshop on Treebanks and Linguistic Theories(TLT).S.
Dz?eroski, T. Erjavec, N. Ledinek, P. Pajas,Z.
Z?abokrtsky, and A.
Z?ele.
2006.
Towards a Slovenedependency treebank.
In Proc.
of the Fifth Intern.Conf.
on Language Resources and Evaluation (LREC).J.
Hajic?, O.
Smrz?, P. Zema?nek, J.
S?naidauf, and E. Bes?ka.2004.
Prague Arabic dependency treebank: Develop-ment in data and tools.
In Proc.
of the NEMLAR In-tern.
Conf.
on Arabic Language Resources and Tools,pages 110?117.Y.
Kawata and J. Bartels.
2000.
Stylebook for theJapanese treebank in VERBMOBIL.
Verbmobil-Report 240, Seminar fu?r Sprachwissenschaft, Univer-sita?t Tu?bingen.M.
T. Kromann.
2003.
The Danish dependency treebankand the underlying linguistic theory.
In Proc.
of theSecond Workshop on Treebanks and Linguistic Theo-ries (TLT).Volkan Kurt.
2005.
Protein structure prediction usingdecision lists.
Master?s thesis, Koc?
University.J.
Nilsson, J.
Hall, and J. Nivre.
2005.
MAMBA meetsTIGER: Reconstructing a Swedish treebank from an-tiquity.
In Proc.
of the NODALIDA Special Session onTreebanks.K.
Oflazer, B.
Say, D. Zeynep Hakkani-Tu?r, and G. Tu?r.2003.
Building a Turkish treebank.
In Abeille?
(Abeille?, 2003), chapter 15.Ronald L. Rivest.
1987.
Learning decision lists.
Ma-chine Learning, 2:229?246.L.
van der Beek, G. Bouma, R. Malouf, and G. van No-ord.
2002.
The Alpino dependency treebank.
In Com-putational Linguistics in the Netherlands (CLIN).Deniz Yuret and Ferhan Ture.
2006.
Learning mor-phological disambiguation rules for Turkish.
In HLT-NAACL 06.250
