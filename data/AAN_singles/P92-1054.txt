Sense-L inking in a Machine Readable Dict ionaryRober t  KrovetzDepar tment  of  Computer  Sc ienceUn ivers i ty  of Massachuset ts ,  Amhers t ,  MA 01003Abst ract  (LDOCE),  is a dictionary for learners of English asDictionaries contain a rich set of relation-ships between their senses, but often theserelationships are only implicit.
We reporton our experiments to automatically iden-tify links between the senses in a machine-readable dictionary.
In particular, we au-tomatically identify instances of zero-affixmorphology, and use that information tofind specific linkages between senses.
Thiswork has provided insight into the perfor-mance of a stochastic tagger.1 I n t roduct ionMachine-readable dictionaries contain a rich setof relationships between their senses, and indicatethem in a variety of ways.
Sometimes the relation-ship is provided explicitly, such as with a synonym orantonym reference.
More commonly the relationshipis only implicit, and needs to be uncovered throughoutside mechanisms.
This paper describes our ef-forts at identifying these links.The purpose of the research is to obtain a bet-ter understanding of the relationships between wordmeanings, and to provide data for our work on word-sense disambiguation and information retrieval.
Ourhypothesis is that retrieving documents on the basisof word senses (instead of words) will result in bet-ter performance.
Our approach is to treat the in-formation associated with dictionary senses (part ofspeech, subcategorization, subject area codes, etc.
)as multiple sources of evidence (cf.
Krovetz \[3\]).This process is fundamentally a divisive one, andeach of the sources of evidence has exceptions (i.e.,instances in which senses are related in spite of be-ing separated by part of speech, subcategorization,or morphology).
Identifying related senses will helpus to test the hypothesis that unrelated meaningswill be more effective at separating relevant fromnonrelevant documents than meanings which are re-lated.We will first discuss some of the explicit indica-tions of sense relationships as found in usage notesand deictic references.
We will then describe ourefforts at uncovering the implicit relationships viastochastic tagging and word collocation.2 Explicit Sense LinksThe dictionary we are using in our research,the Longman Dictionary of Contemporary Englisha second language.
As such, it provides a greatdeal of information about word meanings in theform of example sentences, usage notes, and gram-mar codes.
The Longman dictionary is also uniqueamong learner's dictionaries in that its definitionsare generally written using a controlled vocabularyof approximately 2200 words.
When exceptions oc-cur they are indicated by means of a different font.For example, consider the definition of the wordgravity:?
g rav i ty  n lb.
worrying importance: Hedoesn't understand the gravity of  his i l lness -see GRAVE 2?
grave adj 2. important and needing attentionand (often) worrying: This is grave news - -  Thesick man's condition is graveThese definitions serve to illustrate how wordscan be synonymous 1 even though they have differentparts of speech.
They also indicate how the Long-man dictionary not only indicates that a word is asynonym, but sometimes specifies the sense of thatword (indicated in this example by the superscriptfollowing the word *GRAVE').
This is extremely im-portant because synonymy is not a relation thatholds between words, but between the senses ofwords.Unfortunately these explicit sense indications arenot always consistently provided.
For example, thedefinition of *marbled' provides an explicit indica-tion of the appropriate sense of *marble' (the stoneinstead of the child's toy), but this is not done withinthe definition of *marbles'.LDOCE also provides explicit indications of senserelationships via usage notes.
For example, the def-inition for argument mentions that it derives fromboth senses of argue - to quarrel (to have an ar-gument), and to reason (to present an argument).The notes also provide advice regarding similar look-ing variants (e.g., the difference between distinct anddistinctive, or the fact that an attendant is not some-one who attends a play, concert, or religious ser-vice).
Usage notes can also specify information thatis shared among some word meanings, but not others(e.g., the note for venture mentions that both verband noun carry a connotation of risk, but this isn'tnecessarily true for adventure).Finally, LDOCE provides explicit connections be-tween senses via deictic reference (links created by1We take two words to be synonymous if they havethe same or closely related meanings.330'this', 'these', ' that' ,  'those', 'its', 'itself', and 'sucha/an') .
That  is, some of the senses use these wordsto refer to a previous sense (e.g., 'the fruit of thistree', or 'a plant bearing these seeds').
These rela-tionships are important because they allow us to geta better understanding of the nature of polysemy(related word meanings).
Most of the literature onpolysemy only provides anecdotal examples; it usu-ally does not provide information about how to de-termine whether word meanings are related, whatkind of relationships there are, or how frequentlythey occur.
The grouping of senses in a dictionaryis generally based on part of speech and etymology,but part of speech is orthogonal to a semantic rela-tionship (cf.
Krovetz \[3\]), and word senses can be re-lated etymologically, but be perceived as distinct atthe present ime (e.g., the 'cardinal' of a church and'cardinal' numbers are etymologically related).
Byexamining deictic reference we gain a better under-standing of senses that are truly related, and it alsohelps us to understand how language can be usedcreatively (i.e., how senses can be productively ex-tended).
Deictic references are also important in thedesign of an algorithm for word-sense disambigua-tion (e.g., exceptions to subcategorization).The primary relations we have identified sofar are: substance/product ( ree:fruit or wood,plant:flower or seeds), substance/color (jade, amber,rust), object/shape (pyramid, globe, lozenge), ani-mal/ food (chicken, lamb, tuna), count-noun/mass-noun, 2 language/people (English, Spanish, Dutch),animal/skin or fur (crocodile, beaver, rabbit), andmusic/dance (waltz, conga, tango).
33 Zero -A f f ix  Morpho logyDeictic reference provides us with different types ofrelationships within the same part of speech.
We canalso get related senses that differ in part of speech,and these are referred to as instances of zero-affixmorphology or functional shift.
The Longman dic-tionary explicitly indicates some of these relation-ships by homographs that have more than one partof speech.
It usually provides an indication of therelationship by a leading parenthesized expression.For example, the word bay is defined as N,ADJ, andthe definition reads ' (a horse whose color is) reddish-brown'.
However, out of the 41122 homographs de-fined, there are only 695 that have more than onepart of speech.
Another way in which LDOCE pro-vides these links is by an explicit sense reference fora word outside the controlled vocabulary; the def-~These may or may not be related; consider 'com-puter vision' vs. 'visions of computers'.
The relatedsenses are usually indicated by the defining formula: 'anexample of this'.3The related senses are sometimes merged into one;for example, the definition of/oztrot is '(a piece of musicfor) a type of formal dance... 'inition of anchor (v) reads: 'to lower an anchor  1(1) to keep (a ship) from moving'.
This indicates areference to sense 1 of the first homograph.Zero-affix morphology is also present implicitly,and we conducted an experiment to try to identifyinstances of it using a probabilistic tagger \[2\].
Thehypothesis is that if the word that's being defined(the definiendum) occurs within the text of its owndefinition, but occurs with a different part of speech,then it will be an instance of zero-affix morphology.The question is: How do we tell whether or not wehave an instance of zero-affix morphology when thereis no explicit indication of a suffix?
Part of the an-swer is to rely on subjective judgment, but we canalso support these judgments by making an anal-ogy with derivational morphology.
For example, theword wad is defined as 'to make a wad of'.
That is,the noun bears the semantic relation of formation tothe verb that defines it.
This is similar to the effectthat the morpheme -ize has on the noun union inorder to make the verb unionize (cf.
Marchand \[5\]).The experiment not only gives us insight into se-mantic relatedness across part of speech, it also en-abled us to determine the effectiveness of tagging.We initially examined the results of the tagger onall words starting with the letter 'W';  this letter waschosen because it provided a sufficient number ofwords for examination, but wasn't so small as to betrivial.
There were a total of 1141 words that wereprocessed, which amounted to 1309 homographs and2471 word senses; of these senses, 209 were identifiedby the tagger as containing the definiendum with adifferent part of speech.
We analyzed these instancesand the result was that only 51 of the 209 instanceswere found to be correct (i.e., actual zero-morphs).The instances that are indicated as correct arecurrently based on our subjective judgment; we arein the process of examining them to identify the typeof semantic relation and any analog to a derivationalsuffix.
The instances that were not found to be cor-rect (78 percent of the total) were due to incorrecttagging; that is, we had a large number of false pos-itives because the tagger did not correctly identifythe part of speech.
We were surprised that the num-ber of incorrect tags was so high given the perfor-mance figures cited in the literature (more than a90 percent accuracy rate).
However, the figures re-ported in the literature were based on word tokens,and 60 percent of all word tokens have only one partof speech to begin with.
We feel that the perfor-mance figures should be supplemented with the tag-ger's performance on word types as well.
Most wordtypes are rare, and the stochastic methods do notperform as well on them because they do not havesufficient information.
Church has plans for improv-ing the smoothing algorithms used in his tagger, andthis would help on these low frequency words.
Inaddition, we conducted a failure analysis and it in-dicated that 91% the errors occurred in idiomatic331expressions (45 instances) or example sentences (98instances).
We therefore liminated these from fur-ther processing and tagged the rest of the dictionary.We are still in the process of analyzing these results.4 Der ivat iona l  Morpho logyWord collocation is one method that has been pro-posed as a means for identifying word meanings.The basic idea is to take two words in context, andfind the definitions that have the most words in com-mon.
This strategy was tried by Lesk using the Ox-ford Advanced Learner's Dictionary \[4\].
For exam-ple, the word 'pine' can have two senses: a tree,or sadness (as in 'pine away'), and the word 'cone'may be a geometric structure, or a fruit of a tree.Lesk's program computes the overlap between thesenses of 'pine' and 'cone', and finds that the sensesmeaning 'tree' and 'fruit of a tree' have the mostwords in common.
Lesk gives a success rate of fiftyto seventy percent in disambiguating the words overa small collection of text.
Later work by Becker onthe New OED indicated that Lesk's algorithm didnot perform as well as expected \[1\].The difficulty with the word overlap approach isthat a wide range of vocabulary can be used in defin-ing a word's meaning.
It is possible that we will bemore likely to have an overlap in a dictionary witha restricted efining vocabulary.
When the sensesto be matched are further restricted to be morpho-logical variants, the approach seems to work verywell.
For example, consider the definitions of theword 'appreciate' and 'appreciation':* apprec ia teI.
to be thankful or grateful for2.
to understand and enjoy the good qualitiesof3.
to understand fully4.
to understand the high worth of5.
(of property, possessions, etc.)
to increasein value?
apprec ia t ionI.
judgment, as of the quality, worth, or factsof something2.
a written account of the worth of something3.
understanding of the qualities or worth ofsomething4.
grateful feelings5.
rise in value, esp.
of land or possessionsThe word overlap approach pairs up sense 1 withsense 4 (grateful), sense 2 with sense 3 (understand;qualities), sense 3 with sense 3 (understand), sense 4with sense 1 (worth), and sense 5 with sense 5 (value;possessions).
The matcher we are using ignoresclosed class words, and makes use of a simple mor-phological analyzer (for inflectional morphology).
Itignores words found in example sentences (prelim-inary experiments indicated that this didn't helpand sometimes made matches worse), and it alsoignores typographical codes and usage labels (for-real/informal, poetic, literary, etc.).
It also doesn'ttry to make matches between word senses that areidiomatic (these are identified by font codes).
Weare currently in the process of determining the effec-tiveness of the approach.
The experiment involvescomparing the morphological variations for a set ofqueries used in an information retrieval test collec-tion.
We have manually identified all variations ofthe words in the queries as well as the root forms.Those variants that appear in LDOCE will be com-pared against all root forms and the result will beexamined to see how well the overlap method wasable to identify the correct sense of the variant withthe correct sense of the root.5 Conc lus ionThe purpose of this work is to gain a better under-standing of the relationships between word mean-ings, and to help in development of an algorithm forword sense disambiguation.
Our approach is basedon treating the information associated with dictio-nary senses (part of speech, subcategorization, sub-ject area codes, etc.)
as multiple sources of evidence(of.
Krovetz \[3\]).
This process is fundamentally adivisive one, and each of the sources of evidence hasexceptions (i.e., instances in which senses are relatedin spite of being separated by part of speech, sub-categorization, or morphology).
Identifying the rela-tionships we have described will help us to determinethese exceptions.Re ferences\[1\] Becker B., "Sense Disambiguation using theNew Ozford English Dictionary", Masters The-sis, University of Waterloo, 1989.\[2\] Church K., "A Stochastic Parts Program andNoun Phrase Parser for Unrestricted Text",in Proceedings of the ~nd Conference on Ap-plied Natural Language Processing, pp.
136-143,1988.\[3\] Krovetz R., "Lexical Acquisition and Informa-tion Retrieval", in Lezical Acquisition: Build-ing the Lezicon Using On-Line Resources, U.Zernik (ed), pp.
45-64, 1991.\[4\] Lesk M., "Automatic Sense Disambiguation Us-ing Machine Readable Dictionaries: How to tella Pine Cone from an Ice Cream Cone", Proceed-ings of SIGDOC, pp.
24-26, 1986.\[5\] Marchand H, "On a Question of Contrary Anal-ysis with Derivational Connected but Mor-phologically Uncharacterized Words", EnglishStudies, 44, pp.
176-187, 1963332
