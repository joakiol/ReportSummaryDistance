Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 689?697,Beijing, August 2010Exploring variation across biomedical subdomainsTom Lippincott and Diarmuid O?
Se?aghdha and Lin Sun and Anna KorhonenComputer LaboratoryUniversity of Cambridge{tl318,do242,ls418,alk23}@cam.ac.ukAbstractPrevious research has demonstrated theimportance of handling differences be-tween domains such as ?newswire?
and?biomedicine?
when porting NLP systemsfrom one domain to another.
In this paperwe identify the related issue of subdomainvariation, i.e., differences between subsetsof a domain that might be expected to be-have homogeneously.
Using a large corpusof research articles, we explore how subdo-mains of biomedicine vary across a varietyof linguistic dimensions and discover thatthere is rich variation.
We conclude thatan awareness of such variation is necessarywhen deploying NLP systems for use insingle or multiple subdomains.1 IntroductionOne of the most noticeable trends in the pastdecade of Natural Language Processing (NLP) re-search has been the deployment of language pro-cessing technology to meet the information re-trieval and extraction needs of scientists in otherdisciplines.
This meeting of fields has proven mu-tually beneficial: scientists increasingly rely onautomated tools to help them cope with the expo-nentially expanding body of publications in theirfield, while NLP researchers have been spurred toaddress new conceptual problems in theirs.
Amongthe fundamental advances from the NLP perspec-tive has been the realisation that tools which per-form well on textual data from one source may failto do so on another unless they are tailored to thenew source in some way.
This has led to signifi-cant interest in the idea of contrasting domains andthe concomitant problem of domain adaptation,as well as the production of manually annotateddomain-specific corpora.1One definition of domain variation associatesit with differences in the underlying probabilitydistributions from which different sets of data aredrawn (Daume?
III and Marcu, 2006).
The conceptalso mirrors the notion of variation across thematicsubjects and the corpus-linguistic notions of reg-ister and genre (Biber, 1988).
In addition to thedifferences in vocabulary that one would expectto observe, domains can vary in many linguisticvariables that affect NLP systems.
The scientificdomain which has received the most attention (andis the focus of this paper) is the biomedical domain.Notable examples of corpus construction projectsfor the biomedical domain are PennBioIE (Kulicket al, 2004) and GENIA (Kim et al, 2003).
Thesecorpora have been used to develop systems for arange of processing tasks, from entity recognition(Jin et al, 2006) to parsing (Hara et al, 2005) tocoreference resolution (Nguyen and Kim, 2008).An implicit assumption in much previous workon biomedical NLP has been that particular subdo-mains of biomedical literature ?
typically molec-ular biology ?
can be used as a model of biomed-ical language in general.
For example, GENIAconsists of abstracts dealing with a specific setof subjects in molecular biology, while PennBioIEcovers abstracts in two specialised domains, cancergenomics and the behaviour of a particular classof enzymes.
This assumption of representative-ness is understandable because linguistic annota-tion is labour-intensive and it may not be worth-while to produce annotated corpora for multiplesubdomains within a single discipline if there is lit-1A workshop dedicated to domain adaptation is collocatedwith ACL 2010.689tle task-relevant variation across those subdomains.However, such conclusions should not be madebefore studying the actual degree of difference be-tween the subdomains of interest.One of the principal goals of this paper is to maphow the concept of ?biomedical language?, oftenconstrued as a monolithic entity, is composed ofdiverse patterns of behaviour at more fine-grainedtopical levels.
Hence we study linguistic variationin a broad biomedical corpus of abstracts and fullpapers, the PMC Open Access Subset.2 We selecta range of lexical and structural phenomena forquantitative investigation.
The results indicate thatcommon subdomains for resource development arenot representative of biomedical text in general andfurthermore that different linguistic features oftenpartition the subdomains in quite different ways.2 Related WorkA number of researchers have explored the dif-ferences between non-technical and scientific lan-guage.
Biber and Gray (2010) describe twodistinctive syntactic characteristics of academicwriting which set it apart from general English.Firstly, in academic writing additional informationis most commonly integrated by pre- and post-modification of phrases rather than by the addi-tion of extra clauses.
Secondly, academic writingplaces greater demands on the reader by omittingnon-essential information, through the frequentuse of passivisation, nominalisation and noun com-pounding.
Biber and Gray also show that these ten-dencies towards ?less elaborate and less explicit?language have become more pronounced in recenthistory.We now turn to corpus studies that focus onbiomedical writing.
Verspoor et al (2009) usemeasurements of lexical and structural variationto demonstrate that Open Access and subscription-based journal articles in a specific domain (mousegenomics) are sufficiently similar that research onthe former can be taken as representative of the lat-ter.
While their primary goal is different from oursand they do not consider variation across multipledomains, they do compare their mouse genomicscorpus with small reference corpora drawn from2http://www.ncbi.nlm.nih.gov/pmc/about/openftlist.htmlnewswire and general biomedical sources.
Thisanalysis unsurprisingly finds differences betweenthe domain and newswire corpora across manylinguistic dimensions; more interestingly for ourpurposes, the comparison of domain text to thebroader biomedical superdomain shows a morecomplex picture with similarities in some aspects(e.g., passivisation and negation) and dissimilari-ties in others (e.g., sentence length, semantic fea-tures).Friedman et al (2002) document the ?sublan-guages?
associated with two biomedical domains:clinical reports and molecular biology articles.They set out restricted ontologies and frequent co-occurrence templates for the two domains and dis-cuss the similarities and differences between them,but they do not perform any quantitative analysis.Other researchers have focused on specific phe-nomena, rather than cataloguing a broad scopeof variation.
Cohen et al (2008) carry out a de-tailed analysis of argument realisation with respectto verbs and nominalisations, using the GENIAand PennBioIE corpora.
Nguyen and Kim (2008)compare the behaviour of anaphoric pronouns innewswire and biomedical corpora; they improvethe performance of a pronoun resolver by incorpo-rating their observations, thus demonstrating theimportance of capturing domain-specific phenom-ena.
Nguyen and Kim?s findings are discussed inmore detail in Section 5.4 below.3 Subdomains in the OpenPMC CorpusThe Open Access Subset of PubMed (OpenPMC)is the largest publicly available corpus of full-textarticles in the biomedical domain.
OpenPMC iscomprised of 169,338 articles drawn from 1233medical journals, totalling approximately 400 mil-lion words.
The NIH maintains a one-to-manymapping from journals to 122 subject areas (NIH,2009b).
This covers about 400 of the OpenPMCjournals, but these account for over 70% of thedatabase by byte size and word count.
Journals areassigned up to five subject areas with the majorityassigned one (69%) or two (26%) subjects.
In thispaper we adopt the OpenPMC subject areas (e.g.
?Pulmonary Medicine?, ?Genetics?, ?Psychiatry?
)as the basis for subdomain comparison.6900 10 20 30 40Word count (millions)EthicsComplementary TherapiesEducationObstetricsPharmacologyGeriatricsGastroenterologyPediatricsVeterinary MedicineBiomedical EngineeringPsychiatryEmbryologyGenetics, MedicalOphthalmologyVascular DiseasesBotanyVirologyEndocrinologyPulmonary MedicinePhysiologyTropical MedicineCritical CareRheumatologyCell BiologyCommunicable DiseasesScienceNeurologyBiotechnologyMedicineMicrobiologyEnvironmental HealthPublic HealthBiochemistryMolecular BiologyNeoplasmsMedical InformaticsGeneticsFigure 1: OpenPMC word count by subdomain,dark colouring indicates data assigned single sub-domain, each lighter shade indicates an additionaloverlapping subdomain4 Methodology4.1 Data selection and preprocessingAn important initial question was how to treat datawith multiple classifications: we only considerjournals assigned a single subdomain, to avoidthe added complexity of interactions in data fromoverlapping subdomains.
To ensure sufficient datafor comparing a variety of linguistic features, wediscard the subdomains with less than one mil-lion words meeting the single-subdomain criterion.After review, we also drop the ?Biology?
subdo-main, which appears to function as a catch-all formany loosely related areas.
Figure 1 shows thedistribution of data across the subjects we use, byword-count, with lighter-coloured areas represent-ing data that is assigned multiple subjects.
Thesesubjects provide a convenient starting point for di-viding the corpus into subdomains (hereafter, ?sub-domain?
will be used rather than ?subject?).
Wealso add a reference subdomain, ?Newswire?, com-posed of a 6 million word random sample from theEnglish Gigaword corpus (Graff et al, 2005).
Thefinal data set has a total of 39 subdomains.Articles in the OpenPMC corpus are formattedaccording to a standard XML tag set (NIH, 2009a).We first convert each article to plain text, ignoring?non-content?
elements such as tables and formulas,and split the result into sentences, aggregating theresults by subdomain.4.2 Feature extractionWe investigate subdomain variation in our cor-pus across a range of lexical, syntactic, sententialand discourse features.
The corpus is lemmatised,tagged and parsed using the C&C pipeline (Cur-ran et al, 2007) with the adapted part-of-speechand lexical category tagging models produced byRimell and Clark (2009) for biomedical parsing.From this output we count occurrences of noun,verb, adjective and adverb lemmas, part-of-speech(POS) tags, grammatical relations (GRs), chunks,and lexical categories.
The lemma features areZipfian-distributed items from an open class, sowe have experimented with filtering low-frequencyitems at various thresholds to reduce noise andimprove processing speed.
The other feature setscan be viewed as closed classes, where filtering isunnecessary.Since verbs are central to the meaning and struc-ture of sentences, we consider their special behav-ior by constructing features for each verb?s dis-tribution over other grammatical properties.
Sev-eral grammatical properties are captured by pairingeach verb with its POS (indicating e.g.
tense, suchas present, past, and present participle).
Voice is de-termined from additional annotation output by theC&C parser.
Table 1 shows the POS-distributionfor the verb ?restrict?, in two subdomains fromthe corpus.
Finally, we record distributions oververb subcategorization frames (SCFs) taken byeach verb, and over the GRs it participates in.691Subdomain VB VBG VBN VBP VBZMedical Informatics .35 .29 .06 .09 .21Cell Biology .14 .43 .05 .10 .29Table 1: Distribution over POS tags for verb ?re-strict?, in two subdomainsSCFs were extracted using a system of Preiss et al(2007).To facilitate a more robust and interpretable anal-ysis of vocabulary differences, we estimate a ?topicmodel?
of the corpus with Latent Dirichlet Analy-sis (Blei et al, 2003) using the MALLET toolkit.3As preprocessing we divide the corpus into arti-cles, removing stopwords and words shorter than3 characters.
The Gibbs sampling procedure isparameterised to induce 100 topics, each giving acoherent cluster of related words learned from thedata, and to run for 1000 iterations.
We collate thepredicted distribution over topics for each articlein a subdomain, weighted by article wordcount, toproduce a topic distribution for the subdomain.4.3 Measurements of divergenceOur goal is to illustrate the presence or absenceof differences between the feature sets, and to doso we calculated the Jensen-Shannon divergenceand the Pearson correlation.
Jensen-Shannon diver-gence is a finite symmetric measurement of the di-vergence between probability distributions, whilePearson correlation quantifies the linear relation-ship between two real-valued samples.The count-features are weighted, for a givensubdomain, by the feature?s log-likelihood be-tween the subdomain?s data and the rest of thecorpus.
Log-likelihood has been shown to performwell when comparing counts of potentially low-frequency features (Rayson and Garside, 2000)such as found in Zipfian-distributed data.
Thisserves to place more weight in the comparison onitems that are distinctive of the subdomain withrespect to the entire corpus.While the count-features are treated as a singledistribution for the purposes of JSD, the verbwise-features are composed of many distributions, onefor each verb lemma.
Our approach is to com-bine the JSD of the verbs, weighted by the log-3http://mallet.cs.umass.edulikelihood of the verb lemma between the twosubdomains in question, and normalize the dis-tances to the interval [0, 1].
Using the lemma?s log-likelihood assumes that, when a verb?s distributionbehaves differently in a subdomain, its frequencychanges as well.We present the results as dendrograms andheat maps.
Dendrograms are tree structures thatillustrate the results of hierarchical clustering.We perform hierarchical clustering on the inter-subdomain divergences for each set of features.The algorithm begins with each instance (in ourcase, subdomains) as a singleton cluster, and re-peatedly joins the two most similar clusters untilall the data is clustered together.
The order of thesemerges is recorded as a tree structure that can bevisualized as a dendrogram in which the length ofa branch represents the distance between its childnodes.
Similarity between clusters is calculated us-ing average distance between all members, knownas ?average linking?.Heat maps show the pairwise calculation ofa metric in a grid of squares, where square(x, y) is shaded according to the value ofmetric(subx, suby).
For our measurements ofJSD, black represents 0 (i.e.
identical distributions)and white represents the metric?s theoretical maxi-mum of 1.
We also inscribe the actual value insideeach square.
Dendrograms are tree structures thatillustrate the hierarchical clustering procedure de-scribed above.
The dendrograms present all 39subdomains, while for readability the heatmapspresent 12 subdomains selected for representative-ness.5 ResultsDifferent thresholds for filtering low-frequencyterms had little effect on the divergence measures,and served mainly to improve processing time.
Wetherefore report results using a cutoff of 150 occur-rences (over the entire 234 million word data set)and log-likelihood weights.
The results of Pearsoncorrelation and JSD show similar trends, and dueto its specific design for comparing distributionswe only report the latter.6925.1 Vocabulary and lexical featuresDifferences in vocabulary are what first comes tomind when describing subdomains.
Word featuresare fundamental components for systems such asPOS taggers and lexicalised parsers; one thereforeexpects that these systems will be affected by vari-ation in lexical distributions.
Figure 2a uses JSDcalculated on each subdomain?s distribution over100 LDA-induced topics to compare vocabularydistributions.
Subdomains related to molecularbiology (Genetics, Molecular Biology) show thesmallest divergences, an interesting fact since theseare heavily used in building resources for BioNLP.The dendrogram shows a rough division into ?pub-lic policy?, ?patient-centric?, ?applied?
and ?mi-croscopic?
subdomains, with the distance betweenunrelated subdomains such as Biochemistry andPediatrics almost as large as their respective differ-ences from Newswire.We omit figures for variation over noun, verband adjective lemmas due to space restrictions; ingeneral, these correlate with the variation in LDAtopics though there are some differences.
Figure 2bshows JSD calculated on distributions over adverblemmas.
Part of the variation is due to character-istic markers of scientific argument (?therefore?,?significantly?, ?statistically?).
A more interestingfactor is the coining of domain-specific adverbs,an example of the tendency in scientific text to usecomplex lexical items and premodifiers rather thanadditional clauses.
This also has the effect of mov-ing subdomain-specific objects and processes fromverbs and nouns to adverbs.
This behavior seemsnon-continuous, in that subdomains either makeheavy, or almost no, use of it: for example, Pedi-atrics has no subdomain-specific items among theits ten top adverbs by log-likelihood, while Neo-plasms has ?histologically?, ?immunohistochemi-cally?
and ?subcutaneously?.
These information-dense terms could prove useful for tasks like auto-matic curation of subdomain vocabularies, wherethey imply relationships between their components,the items they modify, etc.5.2 Verb distributional behaviorModelling verb behavior is important for both syn-tactic (Collins, 2003) and semantic (Korhonen etal., 2008) processing, and subdomains are knownto conscript verbs into specific roles that change thedistributions of their syntactic properties (Rolandand Jurafsky, 1998).
The four properties we con-sidered verbs?
distributions over (SCF, POS, GRand voice) produced similar inter-subdomain JSDvalues.
Figure 2c demonstrates how verbs differbetween subdomains with respect to SCFs.
Forexample, while the Pediatrics subdomain uses theverb ?govern?
in a single SCF among its 12 pos-sibilities, the Genetics subdomain distributes itsusage over 7 of them.
Two subdomains may bothuse ?restrict?
with high frequency (e.g.
MolecularBiology and Ethics), but with different frequencydistributions over SCFs.5.3 SyntaxIt is difficult to measure syntactic complexity accu-rately without access to a hand-annotated treebank,but it is well-known that sentence length corre-lates strongly with processing difficulty (Collins,1996).
The first column of Table 2 gives averagesentence lengths (excluding punctuation and ?sen-tences?
of fewer than three words) for selecteddomains.
All standard errors are < 0.1.
It is clearthat all biomedical subdomains typically use longersentences than newswire, though there is also vari-ation within biomedicine, from an average lengthof 27 words in Molecular Biology to 24.5 wordsin Pediatrics.?Packaging?
information in complex pre- and/orpost-modified noun phrases is a characteristic fea-ture of academic writing (Biber and Gray, 2010).This increases the information density of a sen-tence but brings with it syntactic and semanticambiguities.
For example, the difficulty of resolv-ing the internal structure of noun-noun compoundsand strings of prepositional phrases has been the fo-cus of ongoing research in NLP; these phenomenahave also been identified as significant challengesin biomedical language processing (Rosario andHearst, 2001; Schuman and Bergler, 2006).
Thesecond and third columns of Table 2 present aver-age lengths for full noun phrases, defined as everyword dominated by a head noun in the grammat-ical relation graph for a sentence, and for basenominals, defined as nouns plus premodifying ad-jectives and nouns only.
All standard errors are?
0.01.
Newswire text uses the simplest noun693(a) LDA-induced distribution over topics(b) Adverb lemma frequencies(c) Verb distributions over subcategorization framesFigure 2: Subdomain variation plotted as heat maps and dendrograms694Sentence length Full NP length Base nominal lengthMol.
Biology 27.0 Biochemistry 4.03 Biochemistry 1.85Genetics 26.6 Genetics 3.90 Neoplasms 1.85Cell Biology 26.3 Critical Care 3.86 Mol.
Biology 1.84Ethics 26.2 Neoplasms 3.85 Genetics 1.83PMC Average 25.9 PMC Average 3.85 PMC Average 1.80Biochemistry 25.8 Pediatrics 3.84 Cell Biology 1.80Neoplasms 25.5 Med.
Informatics 3.84 Critical Care 1.80Psychiatry 25.3 Comm.
Diseases 3.81 Med.
Informatics 1.78Critical Care 25.0 Therapeutics 3.80 Comm.
Diseases 1.78Therapeutics 24.9 Mol.
Biology 3.79 Therapeutics 1.75Comm.
Diseases 24.9 Psychiatry 3.77 Psychiatry 1.75Med.
Informatics 24.6 Ethics 3.69 Pediatrics 1.73Pediatrics 24.6 Cell Biology 3.55 Ethics 1.65Newswire 19.1 Newswire 3.18 Newswire 1.60Table 2: Average sentence, NP and base nominal lengths across domainsphrase structures; there is notable variation acrossPMC domains.
Full NP and base nominal lengthsdo not always correlate; for example, Cell Biol-ogy uses relatively long base NPs (nominalisationsand multitoken names in particular) but relativelysimple full NP structures.5.4 CoreferenceResolving coreferential terms is a crucial and chal-lenging task when extracting information fromtexts in any domain.
Nguyen and Kim (2008)compare the use of pronouns in the newswireand biomedical domains, using the GENIA cor-pus as representative of the latter.
Among the dif-ferences observed between the domains were theabsence of any personal pronouns other than third-person neuter pronouns in the GENIA corpus, anda greater proportion of demonstrative pronouns inGENIA than in the ACE or MUC newswire cor-pora.
Corroborating the importance of domainmodelling, Nguyen and Kim demonstrate that tai-loring a pronoun resolution system to specific prop-erties of the biomedical domain improves perfor-mance.As our corpus is not annotated for coreferencewe restrict our attention to types that are reliablycoreferential: masculine/feminine personal pro-nouns (he, she and case variations), neuter personalpronouns (they, it and variations) and definite NPswith demonstrative determiners such as this andthat.
To filter out pleonastic pronouns we used acombination of the C+C parser?s pleonasm tag andheuristics based on Lappin and Leass (1994).
Tofilter out the most common class of non-anaphoricdemonstrative NPs we simply discarded any match-ing the pattern this.
.
.
paper|study|article.Table 3 presents statistics for selected types ofcoreferential noun phrases in a number of domains.The results generally agree with the findings ofNguyen and Kim (2008): biomedical text is onaverage 200 times less likely than news text touse gendered pronouns and twice as likely to useanaphoric definite noun phrases.
At the domainlevel, however, there is clear variation within thebiomedical corpus.
In contrast to Nguyen andKim?s observations about GENIA some domainsdo make non-negligible use of gendered pronouns,most notably Ethics (usually to refer to other schol-ars) and domains such as Psychiatry and Pediatricswhere studies of actual patients are common.
Allbiomedical domains use demonstrative NPs morefrequently than newswire and only one (Ethics)matches newswire for frequent use of neuter 3rd-person pronouns.6 ConclusionIn this paper we have explored the phenomenonof linguistic variation at a finer-grained level thanprevious NLP research, focusing on subdomains695Pronouns (neuter, 3rd) Pronouns (non-neuter, 3rd) Demonstrative NPsEthics 0.0658 Newswire 0.0591 Genetics 0.0275Newswire 0.0607 Ethics 0.0037 Med.
Informatics 0.0263Therapeutics 0.0354 Pediatrics 0.0015 Biochemistry 0.0263Med.
Informatics 0.0346 Psychiatry 0.0009 Ethics 0.0260Psychiatry 0.0342 Comm.
Diseases 0.0009 Mol.
Biology 0.0251Pediatrics 0.0308 Therapeutics 0.0005 PMC Average 0.0226PMC Average 0.0284 PMC Average 0.0005 Cell Biology 0.0210Genetics 0.0275 Critical Care 0.0004 Comm.
Diseases 0.0207Critical Care 0.0272 Neoplasms 0.0002 Neoplasms 0.0205Mol.
Biology 0.0258 Med.
Informatics 0.0002 Psychiatry 0.0201Biochemistry 0.0251 Genetics 0.0001 Critical Care 0.0201Neoplasms 0.0227 Mol.
Biology 2.5?
10?5 Therapeutics 0.0192Cell Biology 0.0217 Biochemistry 2.0?
10?5 Pediatrics 0.0191Comm.
Diseases 0.0213 Cell Biology 1.5?
10?5 Newswire 0.0118Table 3: Frequency of coreferential types (proportion of all NPs) across domainsrather than traditional domains such as ?newswire?and ?biomedicine?.
We have identified patterns ofvariation across dimensions of vocabulary, syntaxand discourse that are known to be of importancefor NLP applications.
While the magnitude of vari-ation between subdomains is unsurprisingly lesspronounced than between coarser domains, sub-domain variation clearly does exist and should betaken into account when considering the generalis-ability of systems trained and evaluated on specificsubdomains, for example molecular biology.Future work includes directly evaluating the ef-fect of subdomain variation on practical tasks, in-vestigating further dimensions of variation suchas nominalisation usage and learning alternativesubdomain taxonomies directly from the corpustext.
Ultimately, we expect that a more nuancedunderstanding of subdomain effects will have tan-gible benefits for many applications of scientificlanguage processing.AcknowledgementsThis work was supported by EPSRC grantEP/G051070/1, the Royal Society (AK) and aDorothy Hodgkin Postgraduate Award (LS).ReferencesBiber, Douglas and Bethany Gray.
2010.
Challeng-ing stereotypes about academic writing: Complex-ity, elaboration, explicitness.
Journal of English forAcademic Purposes, 9(1):2?20.Biber, Douglas.
1988.
Variation Across Speech andWriting.
Cambridge University Press, Cambridge.Blei, David M., Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet alocation.
Journal of Ma-chine Learning Research, 3:993?1022.Cohen, K. Bretonnel, Martha Palmer, and LawrenceHunter.
2008.
Nominalization and alternations inbiomedical language.
PLoS ONE, 3(9):e3158.Collins, Michael John.
1996.
A new statistical parserbased on bigram lexical dependencies.
In Proceed-ings of ACL-96, Santa Cruz, CA.Collins, Michael.
2003.
Head-driven statistical mod-els for natural language parsing.
ComputationalLinguistics, 29(4):589?637.Curran, James, Stephen Clark, and Johan Bos.
2007.Linguistically motivated large-scale NLP with C&Cand Boxer.
In Proceedings of the ACL-07 Demo andPoster Sessions, Prague, Czech Republic.Daume?
III, Hal and Daniel Marcu.
2006.
Domainadaptation for statistical classifiers.
Journal of Ar-tificial Intelligence Research, 26:101?126.Friedman, Carol, Pauline Kraa, and Andrey Rzhetsky.2002.
Two biomedical sublanguages: a descriptionbased on the theories of Zellig Harris.
Journal ofBiomedical Informatics, 35(4):222?235.Graff, David, Junbo Kong, Ke Chen, and KazuakiMaeda, 2005.
English Gigaword Corpus, 2nd Edi-tion.
Linguistic Data Consortium.696Hara, Tadayoshi, Yusuke Miyao, and Jun?ichi Tsu-jii.
2005.
Adapting a probabilistic disambiguationmodel of an HPSG parser to a new domain.
In Pro-ceedings of IJCNLP-05, Jeju Island, South Korea.Jin, Yang, Ryan T. McDonald, Kevin Lerman, Mark A.Mandel, Steven Carroll, Mark Y. Liberman, Fer-nando C. Pereira, Raymond S. Winters, and Peter S.White.
2006.
Automated recognition of malignancymentions in biomedical literature.
BMC Bioinfor-matics, 7:492.Kim, J.-D., T. Ohta, Y. Tateisi, and J. Tsujii.
2003.GENIA corpus - a semantically annotated corpus forbio-textmining.
Bioinformatics, 19(Suppl.
1):i180?i182.Korhonen, Anna, Yuval Krymolowski, and Nigel Col-lier.
2008.
The choice of features for classifica-tion of verbs in biomedical texts.
In Proceedingsof COLING-08, Manchester, UK.Kulick, Seth, Ann Bies, Mark Liberman, Mark Mandel,Ryan McDonald, Martha Palmer, Andrew Schein,Lyle Ungar, Scott Winters, and Pete White.
2004.Integrated annotation for biomedical information ex-traction.
In Proceedings of the HLT-NAACL-04Workshop on Linking Biological Literature, Ontolo-gies and Databases, Boston, MA.Lappin, Shalom and Herbert J. Leass.
1994.
An algo-rithm for pronominal anaphora resolution.
Compu-tational Linguistics, 20(4):535?561.Nguyen, Ngan L.T.
and Jin-Dong Kim.
2008.
Explor-ing domain differences for the design of a pronounresolution system for biomedical text.
In Proceed-ings of COLING-08, Manchester, UK.NIH.
2009a.
Journal publishing tag set.http://dtd.nlm.nih.gov/publishing/.NIH.
2009b.
National library ofmedicine: Journal subject terms.http://wwwcf.nlm.nih.gov/serials/journals/index.cfm.Preiss, Judita, E.J.
Briscoe, and Anna Korhonen.
2007.A system for large-scale acquisition of verbal, nom-inal and adjectival subcategorization frames fromcorpora.
In Proceedings of ACL-07, Prague, CzechRepublic.Rayson, Paul and Roger Garside.
2000.
Comparingcorpora using frequency profiling.
In Proceedingsof the ACL-00 Workshop on Comparing Corpora,Hong Kong.Rimell, Laura and Stephen Clark.
2009.
Port-ing a lexicalized-grammar parser to the biomedi-cal domain.
Journal of Biomedical Informatics,42(5):852?865.Roland, Douglas and Daniel Jurafsky.
1998.
Howverb subcategorization frequencies are affected bycorpus choice.
In Proceedings of COLING-ACL-98,Montreal, Canada.Rosario, Barbara and Marti Hearst.
2001.
Classify-ing the semantic relations in noun compounds viaa domain-specific lexical hierarchy.
In Proceedingsof EMNLP-01, Pittsburgh, PA.Schuman, Jonathan and Sabine Bergler.
2006.
Post-nominal prepositional phrase attachment in pro-teomics.
In Proceedings of the HLT-NAACL-06BioNLP Workshop on Linking Natural Languageand Biology, New York, NY.Verspoor, Karin, K Bretonnel Cohen, and LawrenceHunter.
2009.
The textual characteristics of tradi-tional and Open Access scientific journals are simi-lar.
BMC Bioinformatics, 10:183.697
