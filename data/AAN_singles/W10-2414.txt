Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 85?92,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsClassifying Wikipedia Articles into NE?s using SVM?s with ThresholdAdjustmentIman SalehFaculty of Computers andInformation, Cairo UniversityCairo, Egyptiman.saleh@fci-cu.edu.egKareem DarwishCairo Microsoft InnovationCenterCairo, Egyptkareemd@microsoft.comAly FahmyFaculty of Computers andInformation, Cairo UniversityCairo, Egypta.fahmy@fci-cu.edu.egAbstractIn this paper, a method is presented torecognize multilingual Wikipedia named entityarticles.
This method classifies multilingualWikipedia articles using a variety of structuredand unstructured features and is aided bycross-language links and features inWikipedia.
Adding multilingual features helpsboost classification accuracy and is shown toeffectively classify multilingual pages in alanguage independent way.
Classification isdone using Support Vectors Machine (SVM)classifier at first, and then the threshold ofSVM is adjusted in order to improve the recallscores of classification.
Threshold adjustmentis performed using beta-gamma thresholdadjustment algorithm which is a post learningstep that shifts the hyperplane of SVM.
Thisapproach boosted recall with minimal effect onprecision.1 IntroductionSince its launch in 2001, Wikipedia has grown tobe the largest and most popular knowledge baseon the web.
The collaboratively authoredcontent of Wikipedia has grown to include morethan 13 million articles in 240 languages.1  Ofthese, there are more than 3 million Englisharticles covering a wide range of subjects,supported by 15 million discussion,disambiguation, and redirect pages.2 Wikipediaprovides a variety of structured, semi-structuredand unstructured resources that can be valuablein areas such information retrieval, informationextraction, and natural language processing.
Asshown in Figure 1, these resources include pageredirects, disambiguation pages, informationalsummaries (infoboxes), cross-language linksbetween articles covering the same topic, and a1http://en.wikipedia.org/wiki/Wikipedia2http://en.wikipedia.org/wiki/Special:Statisticshierarchical tree of categories and their mappingsto articles.Many of the Wikipedia pages provideinformation about concepts and named entities(NE).
Identifying pages that provide informationabout different NE?s can be of great help in avariety of NLP applications such as named entityrecognition, question answering, informationextraction, and machine translation (Babych andHartley, 2003; Dakka and Cucerzan, 2008).
Thispaper attempts to identify multilingual Wikipediapages that provide information about differenttypes of NE, namely persons, locations, andorganizations.
The identification is done using aSupport Vector Machines (SVM) classifier thatis trained on a variety of Wikipedia features suchas infobox attributes, tokens in text, and categorylinks for different languages aided by cross-language links in pages.
Using features fromdifferent languages helps in two ways, namely:clues such infobox attributes may exist in onelanguage, but not in the other, and this allows fortagging pages in multiple languagessimultaneously.
To improve SVM classificationbeta-gamma threshold adjustment was used toimprove recall of different NE classes andconsequently overall F measure.The separating hyperplane suggested by theSVM typically favors precision at the cost ofrecall and needs to be translated (via thresholdadjustment) to tune for the desired evaluationmetric.Beta-gamma threshold adjustment wasgenerally used when certain classes do not have asufficient number of training examples, whichmay lead to poor SVM recall scores (Shanahanand Roma, 2003).
It was used by Shanahan andRoma (2003) to binary classify a set of articlesand proved to improve recall with little effect onprecision.85However, the technique seems to generalizebeyond cases where very few training examplesare present, and it is shown in this paper to yieldimprovements in recall and overall F-measure inthe presence of hundreds of training examples,performing better than threshold adjustmentusing cross validation for the specific task athand.The contribution of this paper lies in:introducing a language independent system thatutilizes multilingual features from Wikipediaarticles in different languages and can be used toeffectively classify Wikipedia articles written inany language to the NE classes of types person,location, and organization; and modifying beta-gamma threshold adjustment to improve overallclassification quality even when many trainingexamples are available.
The features andtechniques proposed in this paper are comparedto previous work in the literature.The rest of the paper is organized as follows:Section 2 provides information about thestructure and feature of Wikipedia; Section 3surveys prior work on the problem; Section 4describes the classification approach includingfeatures and threshold adjustment algorithm;Section 5 describes the datasets used forevaluation; Section 6 presents the results of theexperiments; and Section 7 concludes the paper.2 Wikipedia PagesWikipedia pages have a variety of typesincluding:?
Content pages which constitute entries inWikipedia (as in Figure 1).
Content pagestypically begin with an abstract containing abrief description of the article.
They maycontain semi-structured data such asinfoboxes and persondata, which providefactoids about concepts or entities in pagesusing attribute-value pairs.
Persondatastructures are found only in people pages.Most of the articles in Wikipedia belong toone or more category, and the categories apage belongs to are listed in the footer of thepage.
As in Figure 1, the entry for AlexanderPushkin belongs to categories such as?Russian Poets?
and ?1799 births?.
Contentpages provide information about commonconcepts or named entities of type person,location, or organization (Dakka andCucerzan, 2008).
A page in Wikipedia islinked to its translations in other languagesthrough cross language links.
These linksredirects user to the same Wikipedia articlewritten in different language.?
Category pages which lists content pages thatbelong to a certain category.
SinceFigure 1.
Sample Wikipedia article86categories are hierarchical, a category pagelists its parent category and sub-categoriesbelow it.?
Disambiguation pages which helpdisambiguate content pages with the sametitles.
For example, a disambiguation pagefor ?jaguar?
provides links to jaguar the cat,the car, the guitar, etc.?
Redirect pages redirect users to the correctarticle if the name of the article entered wasnot exactly the same.
For example,?President Obama?
is redirected to ?BarakObama?.3 Related WorkThis section presents some of the effortpertaining to identifying NE pages in Wikipediaand some background on SVM thresholdadjustment.3.1 Classifying Wikipedia ArticlesToral and Munoz (2006) proposed an approachto build and maintain gazetteers for NER usingWikipedia.
The approach makes use of a nounhierarchy obtained from WordNet in addition tothe first sentence in an article to recognizearticles about NE?s.
A POS tagger can be usedin order to improve the effectiveness of thealgorithm.
They reported F-measure scores of78% and 68% for location and person classesrespectively.
The work in this paper relies onusing the content of Wikipedia pages only.Watanabe et al (2007) considered theproblem of tagging NE?s in Wikipedia as theproblem of categorizing anchor texts in articles.The novelty of their approach is in exploitingdependencies between these anchor texts, whichare induced from the HTML structure of pages.They used Conditional Random Fields (CRF) forclassification and achieved F-measure scores of79.8 for persons, 72.7 for locations, and 71.6 fororganizations.
This approach tags only NE?sreferenced inside HTML anchors in articles andnot Wikipedia articles themselves.Bhole et al (2007) and Dakka and Cucerzan(2008) used SVM classifiers to classifyWikipedia articles.
Both used a bag of wordsapproach to construct feature vectors.
In Bhole etal.
(2007), the feature vector was constructedover the whole text of an article.
They used alinear SVM and achieved 72.6, 70.5, and 41.6 F-measure for tagging persons, locations, andorganizations respectively.
For a Wikipediaarticle, Dakka and Cucerzan (2008) used featurevectors constructed using words in the full text ofthe article, the first paragraph, the abstract, thevalues in infoboxes, and the hypertext ofincoming links with surrounding words.
Theyreported 95% and 93% F-measure for person andlocation respectively.
Using a strictly bag ofwords approach does not make use of thestructure of Wikipedia articles and is comparedagainst in the evaluation.Richman and Schone (2008) and Nothman etal.
(2008) annotated Wikipedia text with NE tagsto build multilingual training data for NEtaggers.
The approach of Richman and Schone(2008) is based on using Wikipedia categorystructure to classify Wikipedia titles.
IdentifyingNE?s in other languages is done using crosslanguage links of articles or categories ofarticles.
Nothman et al  (2008) used abootstrapping approach with heuristics based onthe head nouns of categories and the openingsentence of an article.
Evaluating the system isdone by training a NE tagger using the generatedtraining data.
They reported an average 92% F-measure for all NE?s.Silberer et al (2008) presented work on thetranslation of English NE to 15 differentlanguages based on Wikipedia cross-languagelinks with a reported precision of 95%.
Theresulting NE?s were not classified.
This paperextends the work on cross language links anduses features from multilingual pages to aidclassification and to enable simultaneous taggingof entities across languages.3.2 SVM Threshold AdjustmentSupport Vector Machines (SVM) is a popularclassification technique that was introduced byVapnik (Vapnik, 1995).
The technique is used intext classification and proved to provideexcellent performance compared to otherclassification techniques such as k-nearestneighbor and na?ve Bayesian classifiers.
As inFigure 2, SVM attempts to find a maximummargin hyperplane that separates positive andnegative examples.
The separating hyperplanecan be described as follows: <W, X> + b = 0 or?
Where W is the normal to thehyperplane, X is an input feature vector, and b isthe bias (the perpendicular distance from theorigin to the hyperplane).
When the number ofexamples for each class is not equivalent, theSVM may overfit the class that has fewertraining examples.
Further, the SVM training isnot informed by the evaluation metric.
Thus,SVM training may lead to a sub-optimal87separating hyperplane.
Several techniques wereproposed to rectify the problem by translating thehyperplane by only adjusting bias b, which ishenceforth referred to as threshold adjustment.Some of these techniques adjust SVMthreshold during learning (Vapnik 1998; Lewis2001), while others consider thresholdadjustment as a post learning step (Shanahan andRoma, 2003).
One type of the later is beta-gamma threshold adjustment algorithm(Shanahan and Roma, 2003; Zhai et al, 1998),which is a post learning algorithm that has beenshown to provide significant improvements forclassification tasks in which very few trainingexamples are present such as in adaptive textfiltering.
Such threshold adjustment allows forthe tuning of an SVM to the desired measure ofgoodness (ex.
F1 measure).
A full discussion ofbeta-gamma threshold adjustment is provided inthe experimental setup section.
In the presenceof many training examples, some of the trainingexamples are set aside as a validation set to helppick an SVM threshold.
Further, multi-fold crossvalidation is often employed.Figure 2.
SVMs try to maximize the margin ofseparation between positive and negativeexamples4 Classification ApproachFeatures:  The classification featuresincluded content-based features such as words inpage abstracts and structure-based features suchcategory links.
All the features are binary.
Thefeatures are:?
Stemmed content words extracted fromabstracts:  an abstract for a NE may includekeywords that may tell of the entity type.For example, an abstract for an NE of typeperson would typically include words such as?born?, ?pronounced?, and more specificwords that point to profession, role, or job(ex.
president, poet, etc.).?
White space delimited attribute names frominfoboxes:  in the presence of infoboxesstructures, the attribute names provide hintsof the entity type.
For example, an infoboxof location may include attribute names suchas ?latitude?, ?longitude?, ?area?, and?population?.?
White space delimited words in categorylinks for a page:  category names mayinclude keywords that would helpdisambiguate a NE type.
For example,categories of NE of type person may includethe words ?births?, ?deaths?, ?people?,occupation such as ?poet?
or ?president?,nationality such ?American?
or ?Russian?,etc.?
Persondata structure attributes:  persondataonly exist if the entity refers to a person.The features used herein combine structuralas well as content-based features from multiplelanguages unlike features used in the literaturewhich were monolingual.
Using multilingualfeatures enables language independentclassification of any Wikipedia article written inany language.
Moreover, using primarilystructural features in classification instead of thewhole content of the articles allows for theeffective use of multilingual pages without theneed for language specific stemmers andstopword lists, the absence of which mayadversely affect content based features.Classification:  Classifying Wikipedia pageswas done in two steps: First training an SVMclassifier; and then adjusting SVM thresholdsbased on beta-gamma adjustment to improverecall.
Beta-gamma threshold adjustment wascompared to cross-fold validation thresholdadjustment.
All Wikipedia articles wereclassified using a linear SVM.
Classification wasdone using the Liblinear SVM package which isoptimized for SVM classification problems withthousands of features (Fan et al, 2008).
Avariant of the beta-gamma threshold adjustmentalgorithm as described by (Shanahan and Roma,2003; Zhai et al, 1998) is used to adjust thethreshold of SVM.
The basic steps of thealgorithm are as follows:?
Divide the validation set into n folds suchthat each fold contains the same number ofpositive examples?
For each fold i,88o Classify examples in a fold and sort them indescending order based on SVM scores,where the SVM score of SVM is theperpendicular distance between an exampleand the separating hyperplane.o Calculate F-measure, which is the goodnessmeasure used in the paper, at each example.o Determine the point of maximum F-measure and set ?Ni to the SVM score at thispoint.o Repeat previous steps for the set consistingof all folds other than i and set ?Max = ?Niand ?Min = ?Mi, where ?Mi is the SVM scoreat the point of minimum F-measure.o Compute???
The optimal threshold is obtained byinterpolating between ?Max and ?Min obtainedfrom the whole validation set as follows:?
???
??
?where               ,  M is thenumber of documents in the validation set,and   is the inverse of the estimated numberof documents at the point of the optimalthreshold (Zhai et al, 1998).
In this work, itis assigned a value that is equivalent to theinverse of the number of examples at ?Max.Since the number of training examples inShanahan and Roma (2003) were small, n-foldcross-validation was done using the training set.In this work, the validation and training sets werenon-overlapping.
Further, in the work ofShanahan and Roma (2003), ?Min was set to thepoint that yields utility = 0 as they used afiltering utility measure that can produce a utilityof 0.
Since no F-measure was found to equalzero in this work, minimum F-measure point wasused instead.For comparison, n-fold cross validation wasused to obtain ?Ni for each of the folds and then?opt as the average of all ?Ni.
Further, using abag-of-words approach is used for comparison,where a feature vector in constructed based onthe full text of an article.5 Data SetTo train and test the tagging of Wikipedia pageswith NE tags, a dataset of 4,936 EnglishWikipedia pages was developed by the authorsand with split using a 60/20/20 training,validation, and testing split.
The characteristicsof the dataset, which is henceforth referred to asMAIN, are presented in Table 1.
The Englisharticles had links to 128 different languages,with: 16,912 articles having cross-languagelinks; 93.3 pages on average per language; 97languages with fewer than 100 links; with aminimum of 1 page per language (for 14languages); and a maximum of 918 pages forFrench.
To compare the inclusion ofmultilingual pages in training and testing, twovariants of MAIN were used, namely:  MAIN-Ewhich has only English pages, and MAIN-EMwhich has English and multilingual pages from13 languages with the most pages ?
Spanish,French, Finnish, Dutch, Polish, Portuguese,Italian, Norwegian, German, Danish, Hungarian,Russian, and Swedish.
Other languages had toofew pages.
To stem text, Porter stemmer wasused for English and snowball stemmers3 wereused for the other 13 languages.
For all thelanguages, stopwords were removed.
Forcompleteness, another set was constructed toinclude all 128 languages to which the Englishpages had cross language links.
This set isreferred to as the MAIN-EM+ set.
The authorsdid not have access to stemmers and stopwordlists in all these languages, so simpletokenization was performed by breaking text onwhitespaces and punctuation.
Since manyEnglish pages don?t have cross language linksand most languages have too few pages, a newdataset was constructed as a subset of theaforementioned dataset such that each documentin the collection has an English page with at leastone cross language link to one of the 13languages with the most pages in the biggerdataset.
Table 2 details the properties of thesmaller dataset, which is henceforth referred toas SUB.
SUB had five variants, namely:?
SUB-E with English pages only?
SUB-EM with English and multilingualpages from the 13 languages in MAIN-EM?
SUB-M which the same as SUM-EMexcluding English.?
SUB-EM+ with English pages andmultilingual pages in 128 languages.?
SUB-M+ which is the same as SUB-EM+excluding English.The articles used in the experiments wererandomly selected out of all the content articlesin Wikipedia, about 3 million articles.
Articleswere randomly assigned to training and test sets3 http://snowball.tartarus.org/89and manually annotated in accordance to theCONLL ?
2003 annotation guidelines4 which arebased on (Chinchor et al, 1999).
Annotation wasbased on reading the contents of the article andthen labeling it with the appropriate class.
All thedata, including first sentence in an article,infobox attributes, persondata attributes, andcategory links, were parsed from a 2010Wikipedia XML dump.6 Evaluation and ResultsThe results of classifying Wikipedia articlesusing SVM and threshold adjustment for MAIN-E, MAIN-EM, and MAIN-M are reported inTables 3, 4, and 5 respectively.
Tables 6, 7, 8, 9,and 10 report results for SUB-E, SUB-EM, SUB-M, SUB-EM+, and SUB-M+ respectively.
In all,n is the number of cross folds used to calculate  ,with n ranging between 3 and 10.
The first row isthe baseline scores of SVM classification withoutthreshold adjustment.
The remaining rows are thescores of SVM classification after adjustingthreshold.
The adjustment is performed byadding      to the bias value b learned by theSVM.
A t-test with 95% confidence (p-value <0.05) is used to determine statistical significance.For the MAIN-E dataset, SVM thresholdrelaxation yielded statistically significantimprovement over the baseline of using an SVMdirectly for location named entity.
For othertypes of named entities improvements were notstatistically significant.Threshold adjustment led to statisticallysignificant improvement for: all NE types forSUB-EM and SUB-EM+; for organizations forSUB-E and SUB-M+; and for locations andorganization for SUB-EM.
The improvementswere most pronounced when recall was very low.For example, F1 measure for organization in theSUB-M dataset improved by 18 points due to a26 point improvement in recall ?
though at theexpense of precision.It seems that threshold adjustment tends tobenefit classification more when: using smallertraining sets ?
as is observed when comparingthe results for MAIN and SUB datasets, andwhen classification leads to very low recall ?
asindicated by organization NE for SUB datasets.Tables 11 and 12 compare the results for thedifferent variations of the MAIN and SUBdatasets respectively.
As indicated in the Tables11 and 12, the inclusion of more and more4http://www.cnts.ua.ac.be/conll2003/ner/annotation.txtlanguage pages with English led to improvedclassification with consistent improvements inprecision and recall for MAIN and consistentimprovements in precision for SUB.
For theSUB-M and SUB-M+ datasets, the exclusion ofEnglish led to degradation on F1 measure, withthe degradation being particularly pronouncedfor organizations.
The drop can be attributed tothe loss of much valuable training examples,because there are more English pages comparedto other languages.
Despite the loss, properidentification of persons and locations remainedhigh enough for many practical applications.Further, the results suggest that given moretraining data in the other languages, the featuressuggested in the paper would likely yield goodclassification results.
Unlike the MAIN datasets,the inclusion of more languages for training andtesting (from SUB-M to SUB-M+ & from SUB-EM to SUB-EM+) did not yield anyimprovements except for location andorganization types from SUB-EM to SUB-EM+.This requires more investigation.Tables 13 and 14 report the results of usingterm frequency representation of the entire pageas features ?
a bag of words (BOWs)?
as inBhole et al (2007).
Using semi-structured data asclassification features is better than using BOWrepresentation.
This could be due to the smallernumber of features of higher value.
In the BOWresults with multilingual page inclusion, exceptfor location NE type only in the SUB dataset, theuse of term frequencies of multilingual wordshurt F1-measure for the SUB and MAINdatasets.
This can be attributed to the increasedsparseness of the training and test data.7 ConclusionsThis paper presented a language independentmethod for identifying multilingual Wikipediaarticles referring to named entities.
An SVMwas trained using multilingual features that makeuse of unstructured and semi-structured portionsof Wikipedia articles.
It was shown that usingmultilingual features was better than usingfeatures obtained from English articles only.Multilingual features can be used in classifyingmultilingual articles and is particularly useful forlanguages other than English, where fewer usefulfeatures are present.
The number of Infoboxproperties and category links in English MAINwas 32,262 and 9,221 respectively, while inGerman there are 4,618 properties and 1,657category links.
These numbers are even lower inall other languages.90Table 1.
Characteristics of MAIN dataset: the numberof Wikipedia pages in the datasetTable 2.
Characteristics of SUB dataset: the numberof Wikipedia pages in the datasetcrossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 98.7 90.4 94.4 94.6 85.7 89.9 90 73.6 81.0n = 3 97.9 92.0 94.9 94.4 89.0 91.6 87.2 74.5 80.4n = 4 96.7 92.0 94.3 94.4 89.0 91.6 87.2 74.5 80.4n = 5 96.6 92.0 94.3 94.4 89.0 91.6 80.0 76.4 78.0n =6 96.7 92.4 94.5 94.4 89.4 91.9 85.6 75.4 80.2n =7 96.7 92.8 94.7 94.4 89.4 91.9 85.6 75.4 80.2n =8 96.7 92.8 94.7 94.0 90.6 92.3 80.0 76.4 78.0n =9 95.2 94.0 94.6 94.0 89.8 91.9 80.8 76.4 78.5n = 10 94.8 94.0 94.4 94.0 90.6 92.3 77.9 80.0 78.9Table 3.
Results for MAIN-E: Best F1 bolded anditalicized if significantly better than baseline.crossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 99.1 91.6 95.2 94.7 87.2 90.8 91.0 73.6 81.4n = 3 99.7 91.2 95.2 94.7 87.2 90.8 90.1 74.5 81.6n = 4 99.1 91.6 95.2 94.7 87.9 91.2 90.2 75.4 82.2n = 5 99.1 92.4 95.7 94.4 89 91.6 86.4 75.4 80.6n =6 98.3 92.4 95.3 94.7 87.9 91.2 87.4 75.4 81.0n =7 98.3 92.4 95.3 93.7 90.2 91.9 82.3 76.4 79.2n =8 98.3 92.8 95.5 93.7 90.2 91.9 85.7 76.4 80.8n =9 98.3 92.8 95.5 92.4 92.4 92.4 82.3 76.4 79.2n = 10 97.9 92.8 95.3 92.8 92.1 92.4 82.3 76.4 79.2Table 4.
Results for MAIN-EM: Best F1 bolded anditalicized if significantly better than baseline.crossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 99.6 92.0 95.6 95.0 87.2 90.9 91.0 73.6 81.4n = 3 98.3 92.4 95.3 94.3 88.3 91.2 91.0 74.5 82.0n = 4 98.3 92.8 95.5 93.7 90.2 91.9 91.0 74.5 82.0n = 5 98.3 92.8 95.5 93.8 90.9 92.3 89.2 75.4 81.8n =6 97.9 93.2 95.5 93.0 91.3 92.2 88.3 75.4 81.4n =7 95.5 93.6 94.6 93.4 90.9 92.2 87.4 75.4 81.0n =8 95.5 93.6 94.6 91.8 92.8 92.3 85.7 76.4 80.8n =9 95.9 93.2 94.5 92.0 92.0 92.0 84.0 76.4 80.0n = 10 95.2 94.8 95.0 91.7 92.0 91.9 85.7 76.4 80.8Table 5.
Results for MAIN-EM+: Best F1 bolded anditalicized if significantly better than baseline.The effect of using SVM and beta-gammathreshold adjustment algorithm to improverecognizing NE?s in Wikipedia was alsodemonstrated.
The algorithm was shown toimprove scores of location NE?s particularly.
Theappropriate number of folds was found to be 8using our dataset.
Finally, the results suggest thatthe use of semi-structured data as classificationfeatures is significantly better than the usingunstructured data only or BOWs.
The paper alsoshowed that the use of multilingual features withBOWs was not very useful.For future work, the proposed technique canbe used to create large sets of tagged Wikipediapages in a variety of languages to aid in buildingparallel lists of named entities that can be used toimprove MT and in training transliteratorengines.
Further, this work can help in buildingresources such gazetteers and tagged NE data inmany languages for the rapid development of NEtaggers in general text.
Wikipedia has theadvantage of covering many topics beyond thosethat are typically covered in news articles.crossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 100 92.6 96.2 98.5 91.7 95 87.0 49.0 62.5n = 3 100 92.6 96.2 97.8 91.7 94.6 84 51.2 63.6n = 4 100 92.6 96.2 97.8 91.7 94.6 85.2 56 67.7n = 5 100 93.7 96.7 96.4 92.4 94.3 87.0 65.8 75.0n =6 100 93.7 96.7 95.7 93.7 94.7 85.7 58.5 69.6n =7 100 93.7 96.7 95.7 93.7 94.7 87.0 65.8 75.0n =8 100 93.7 96.7 95.7 93.7 94.7 87.0 65.8 75.0n =9 100 94.7 97.3 95.0 94.4 94.8 87.0 65.8 75.0n = 10 100 94.7 97.3 95.0 94.4 94.8 87.0 65.8 75.0Table 6.
Results for SUB-E: Best F1 bolded anditalicized if significantly better than baseline.crossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 100 91.6 95.6 99.2 88.9 93.8 100 46.3 63.3n = 3 98.9 92.6 95.6 99.2 88.2 93.3 100 53.6 69.8n = 4 98.9 92.6 95.6 98.5 91.7 95.0 92.0 56.0 69.7n = 5 98.9 92.6 95.6 99.2 88.9 93.8 92.0 56.0 69.7n =6 98.9 92.6 95.6 98.5 93.7 96.0 92.0 56.0 69.7n =7 99.0 92.6 95.6 98.5 93.7 96.0 92.0 56.0 69.7n =8 99.0 92.6 95.6 97.8 93.7 95.7 92.0 56.0 69.7n =9 98.9 95.7 97.3 95.2 95.8 95.5 92.0 56.0 69.7n = 10 98.9 95.7 97.3 93.2 96.5 94.9 92.0 56.0 69.7Table 7.
Results for SUB-EM: Best F1 bolded anditalicized if significantly better than baseline.ReferencesBabych, Bogdan, and Hartley, Anthony (2003).Improving Machine Translation quality withautomatic Named Entity recognition.
7th Int.EAMT workshop on MT and other lang.
tech.tools -- EACL?03, Budapest, Hungary.Training Validation TestPerson 822 300 251Locations 676 221 266Organizations 313 113 110Non 1085 366 414Total 2896 1000 1040Training Validation TestPerson 332 128 95Locations 360 115 144Organizations 102 30 42Non 435 150 184Total 1229 423 46591Bhole, Abhijit, Fortuna, Blaz, Grobelnik, Marko, andMladenic, Dunja.
(2007).
Extracting NamedEntities and Relating Them over Time Based onWikipedia.
Informatica (Slovenia), 31, 463-468.Chinchor, Nancy, Brown, Erica, Ferro, Lisa, andRobinson, Patty.
(1999).
1999 Named EntityRecognition Task Definition: MITRE.Dakka, Wisam., and Cucerzan, Silviu.
(2008).Augmenting Wikipedia with Named Entity Tags.3rd IJCNLP, Hyderabad, India.Fan, Rong-En, Chang, Kai-Wei, Hsieh, Cho-Jui,Wang, Xiang-Rui, and Lin, Chih-Jen.
(2008).LIBLINEAR: A Library for Large LinearClassication.
Journal of Machine LearningResearch 9, 1871-1874.Nothman, Joel, Curran, James R., and Murphy, Tara.(2008).
Transforming Wikipedia into NamedEntity Training Data.
Australian Lang.
Tech.Workshop.Richman, Alexander E., and Schone, Patrick.
(2008,June).
Mining Wiki Resources for MultilingualNamed Entity Recognition.
ACL-08: HLT,Columbus, Ohio.Shanahan, James G., and Roma, Norbert.
(2003).Boosting support vector machines for textclassification through parameter-free thresholdrelaxation.
CIKM'03.
New Orleans, LA, USSilberer, Carina, Wentland, Wolodja, Knopp,Johannes, and Hartung, Matthias.
(2008).
Buildinga Multilingual Lexical Resource for Named EntityDisambiguation, Translation and Transliteration.LREC'08, Marrakech, Morocco.Toral, Antonio, and Mu?noz, Rafael (2006).
Aproposal to automatically build and maintaingazetteers for Named Entity Recognition by usingWikipedia, EACL-2008.
Italy.Vapnik, Vladimir N. (1995).
The nature of statisticallearning theory: Springer-Verlag New York, Inc.Watanabe, Yotaro, Asahara, Masayuki, andMatsumoto, Yuji.
(2007).
A Graph-BasedApproach to Named Entity Categorization inWikipedia using Conditional Random Fields.EMNLP-CoNLL, Prague, Czech RepublicZhai, Chengxiang, Jansen, Peter, Stoica, Emilia, Grot,Norbert, and Evans, David A.
(1998).
ThresholdCalibration in CLARIT Adaptive Filtering.
TREC-7, Gaithersburg, Maryland, US.crossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 100 90.5 95 99.2 90.3 94.5 100 47.6 64.5n = 3 98.9 92.6 95.6 98.5 91.7 95 100 47.6 64.5n = 4 98.9 92.6 95.6 98.5 91 94.6 96 57 71.6n = 5 98.9 92.6 95.6 98.5 92.4 95.3 96 57 71.6n =6 98.9 92.6 95.6 95.8 94.4 95 96 57 71.6n =7 98.9 92.6 95.6 97 93 95 100 54.8 70.8n =8 98.9 92.6 95.6 95.8 94.4 95 92.6 59.5 72.5n =9 98.8 93.7 96.2 95 95 95 96 59.5 73.5n = 10 98.9 94.7 96.8 94.5 95.8 95.2 92.6 59.5 72.5Table 8.
Results for SUB-EM+: Best F1 bolded anditalicized if significantly better than baseline.crossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 97.4 77.9 86.5 97.4 78.5 86.9 100 21.9 36.0n = 3 97.4 78.9 87.2 96.7 80.5 87.9 100 24.4 39.2n = 4 97.5 82.0 89.0 95.3 84.0 89.3 71.4 36.6 48.4n = 5 97.5 82.0 89.0 94.6 84.7 89.4 100 24.4 39.2n =6 96.3 83.0 89.3 94.6 84.7 89.4 100 24.4 39.2n =7 95.2 83.0 88.8 94.6 86.0 90.2 77.8 34 47.4n =8 97.5 83.0 89.8 91.8 86.0 88.9 70.8 41.5 52.3n =9 95.2 84.2 89.4 94.6 86.0 90.0 61.3 46.3 52.8n = 10 91.2 87.4 89.2 64.9 96.5 77.6 60.6 48.8 54.0Table 9.
Results for SUB-M: Best F1 bolded anditalicized if significantly better than baseline.crossfoldsPerson Location OrganizationP R F1 P R F1 P R F1Baseline 97.3 76.8 85.9 97.4 77 86 100 19 32n = 3 97.4 77.9 86.5 95 81.2 87.6 100 23.8 38.5n = 4 97.4 77.9 86.5 95.8 78.5 86.2 91.7 26.2 40.7n = 5 97.4 80 87.9 95.9 80.5 87.5 86.7 30.9 45.6n =6 96.2 80 87.3 91 84.7 87.8 91.7 26.2 40.7n =7 96.2 80 87.3 92.4 84.7 88.4 91.7 26.2 40.7n =8 95 80 86.8 75 93.7 83.3 79.2 45.2 57.6n =9 92.8 82 87 89.3 86.8 88 79.2 45.2 57.6n = 10 90.9 84.2 87.4 65.9 97.9 78.8 79.2 45.2 57.6Table 10.
Results for SUB-M+: Best F1 bolded anditalicized if significantly better than baseline.MAINF1-measureE EM EM+Person 94.4 95.2 95.6Location 89.9 90.8 90.9Organization 81.0 81.4 81.4Table 11.
Comparing results for MAIN-{E, EM, andEM+}: Best F1 bolded and italicized if significantlybetter than MAIN-ESUBF1-MeasureE EM M EM+ M+Person 96.2 95.6 86.5 95 85.9Location 95 93.8 86.9 94.5 86Organization 62.5 63.3 36.0 64.5 32Table 12.
Comparing results for SUB-{E, EM, M,EM+, and M+}:  Best F1 boldedMAINF1-measureE EM EM+Person 86.8 85.0 84.5Location 87.4 85.8 85.5Organization 58.0 51.8 53.4Table 13.
Comparing results of BOWs for MAIN-{E,EM, and EM+}: Best F1 boldedSUBF-MeasureE EM M EM+ M+Person 82.0 80.6 68.0 79.3 61.9Location 88.5 90.7 83.8 90.0 82.3Organization 35.6 22.6 21.4 33.3 22.6Table 14.
Comparing results of BOWs for SUB-{E,EM, M, EM+, and M+}: Best F1 bolded92
