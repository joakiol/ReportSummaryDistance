NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 11?12,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsThe Future of Spoken Dialogue Systems is in their Past:Long-Term Adaptive, Conversational AssistantsDavid SchlangenFaculty of Linguistics and Literary StudiesBielefeld University, Germanydavid.schlangen@uni-bielefeld.deAbstractA sketch of dialogue systems as long-termadaptive, conversational agents.1 Introduction?Show me the lecture notes from last year?, you sayto your bow-tied virtual assistant.
It does, but un-fortunately, ?this will not do.
Pull up all the newarticles I haven?t read yet?.
Your assistant obliges,pointing your attention to a ?new article from yourfriend, Jill Gilbert?.
A video call later, your lec-ture preparation is done?Jill will actually give it,via video link?and you go on with your day.This of course describes the first scene from Ap-ple?s ?Knowledge Navigator?
concept video (AppleComputer Inc., 1987; Colligan, 2011).
Not muchof what that video showed was actually technicallypossible at the time, but it captured the promise ofpersonalized natural language interfaces that manypeople saw and hoped would be realised soon.
Hav-ing to deal with the constraints of reality, however,research and development of spoken dialogue inter-faces had to set itself the more modest aim of replac-ing, in certain settings, mouse and keyboard, ratherthan personal assistants.Recent years have seen two developments thatbring that more ambitious goal back into focus.First, the required basic technologies such as speechrecognition and speech synthesis have matured to astate where they begin to allow the necessary flexi-bility of spoken in- and output.
Second, it has be-come not only possible but completely unremark-able for large portion of the population to carry withthem sensor-rich, networked computing devices?their smartphones?during large parts of their day.In this position paper, I?d like to sketch whatthe opportunities are that this situation offers, forthe creation of dialogue systems that are long-termadaptive and conversational, and act as assistants,not interfaces.2 Long-Term Adaptive ...The fact that users carry with them the same device(or class of devices; it only matters that access isconstant), provides the chance of repeated interac-tions with what is understood to be the same system.To make use of this, the system must?
learn from errors / miscommunications, by im-proving internal models (acoustic model, languagemodel, semantic models: how are tasks structuredfor particular user); and it must?
build up personal common ground:?
What has been refered to previously, and how?Which tasks have been done together, and how??
Which situations have been shared?
(Where amulti-sensor device can have detailed situational in-formation.
)While the first point mostly describes current prac-tice (user adaptation of speech resources), there ismuch to be explored in the building up of commonground with a technical device.3 ... Conversational ...Interaction with these systems must be less driven byfixed system-intiative, and be more conversational:?
User and system must be able to mean morethan they say, by making use of context, both from11the ongoing conversation as well as from the com-mon ground that was built up over previous interac-tion.?
Systems should be responsive, incremental,providing feedback where required; realising a tightinteraction loop, not strict turn-based exchanges.?
Things will go wrong, so error handling needsto be graceful and natural, using the full rangeof conversational repair devices (Schlangen, 2004;Purver, 2004); including handing off tasks to othermodalities if expected success rate is low.?
Conversations express and project personality,emotionality, sociality; systems need to model thedynamics of this as part of their modelling of theconversation.Again, these are active areas of research (for re-sponsive systems, see e.g.
(Skantze and Schlangen,2009; Bu?
et al, 2010; Schlangen et al, 2010); forerror handling / acting under uncertainty, see e.g.
(Williams and Young, 2007); for social aspects ofdialogue, see e.g.
(Kopp, 2010)); pulling them to-gether in this kind of application will likely providenew challenges and insights for all of them.4 ... AssistantsOf course, the systems will need to provide actualservices, for it at all to come to repeated conversa-tions.
While providing the services lies outside thedomain of speech research, there are some uniquerequirements that conversational access poses:?
To be usefully embeddable into conversationalsystems, back-end applications are needed that areinteraction-ready; e.g., by providing confindence in-formation about their results, and, building on this,by suggesting ways to improve quality through ad-ditional information.?
Not all back-end services are under the controlof the application developer or provide APIs, and thesemantic web is not going to happen.
The reach of avirtual assistant can be increased if it can be taughtto do tasks like use a website to book a train.
Somepromising first work in this direction exists (Allen etal., 2007).5 ResourcesBuilding dialogue systems is always hard, as manydifferent components need to be integrated.
Systemsas sketched above bring the additional challenge ofrequiring work on mobile platforms; a frameworkthat provides the required interfaces and infrastruc-ture would be very helpful.ReferencesJames F. Allen, Nathanael Chambers, George Ferguson,Lucian Galescu, Hyuckchul Jung, Mary Swift, andWilliam Taysom.
2007.
PLOW: A collaborative tasklearning agent.
In Proceedings of the National Confer-ence on Artificial Intelligens (AAAI), Vancouver, BC,Canada.Apple Computer Inc. 1987.
The knowledge navigatorconcept video.
http://youtu.be/HGYFEI6uLy0.Okko Bu?, Timo Baumann, and David Schlangen.
2010.Collaborating on utterances with a spoken dialoguesystem using an isu-based approach to incrementaldialogue management.
In Proceedings of the SIG-dial 2010 Conference, pages 233?236, Tokyo, Japan,September.Bud Colligan.
2011.
How the knowl-edge navigator video came about, Nov.http://www.dubberly.com/articles/how-the-knowledge-navigator-video-came-about.html.Stefan Kopp.
2010.
Social resonance and embodiedcoordination in face-to-face conversation with artifi-cial interlocutors.
Speech Communication, 52(6):587?597.Matthew Purver.
2004.
The Theory and Use of Clar-ification Requests in Dialogue.
Ph.D. thesis, King?sCollege, Unversity of London, London, UK, August.David Schlangen, Timo Baumann, Hendrik Buschmeier,Okko Bu?, Stefan Kopp, Gabriel Skantze, and RaminYaghoubzadeh.
2010.
Middleware for incrementalprocessing in conversational agents.
In Proceedingsof the SIGdial 2010 Conference, pages 51?54, Tokyo,Japan, September.David Schlangen.
2004.
Causes and strategies for re-questing clarification in dialogue.
In Proceedings ofthe 5th Workshop of the ACL SIG on Discourse andDialogue, Boston, USA, April.Gabriel Skantze and David Schlangen.
2009.
Incre-mental dialogue processing in a micro-domain.
InProceedings of the 12th Conference of the EuropeanChapter of the Association for Computational Linguis-tics (EACL 2009), pages 745?753, Athens, Greece,March.Jason Williams and Steve Young.
2007.
Partially ob-servable Markov decision processes for spoken dialogsystems.
Computer Speech and Language, 21(2):231?422.12
