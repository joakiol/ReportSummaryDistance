AUTOMATED SPEECH RECOGNITION:A FRAMEWORK FOR RESEARCHAnne JohnstoneDepartment  of Ar t i f i c ia l  Inte l l igenceEd inburgh Un ivers i tyHope Park Square, Meadow LaneEd inburgh EHB 9LL.
(GB)ABSTRACTThis paper ref lects  the v iew that thedecod ing of speech, e i ther by computersystems or people, must to a large extentbe determined by the ways in which thespeaker has encoded the in format ionnecessary  for its comprehension.
Wetherefore  place great emphasis  on the useof psycho l ingu is t i cs  as a tool for theconst ruct ion  of models  essent ia l  to thecharacter i sa t ion  of the speechunderstand ing  task.We are pr imar i ly  concerned with theinteract ions  between the var ious levels atwhich a f ragment of speech can bedescr ibed (e.g.
acoust ic -phonet ic ,lexical, syntact ic,  etc), and the ways inwhich the knowledge bases assoc ia ted  witheach of these "levels" contr ibute  towardsa final in terpretat ion  of an utterance.
Wepropose to use the Chart  Parser  as ageneral  computat iona l  f ramework fors imulat ing such interact ions,  s ince itsf lex ib i l i ty  a l lows var ious models to beimplemented and evaluated.With in  this general  f ramework wediscuss problems of in format ion f low andsearch st rategy in combin ing ev idenceacross levels of descr ip t ion  and acrosstime, dur ing the extens ion of anhypothesis .
We stress the importance ofboth psycholog ica l  and computat iona ltheory in deve lop ing a par t icu lar  controlstrategy which could be implemented with inthe framework.In t roduct ionThe decoding of speech, e i ther bycomputer  systems or people, must to alarge extent be determined by the ways inwhich the speaker has encoded thein format ion  necessary  for itscomprehension.
Such a view is supported bya large body of exper imenta l  ev idenceconcern ing the ways in which var iousfactors (eg.
p red ic tab i l i ty  from context)af fect  both the acoust ic  c lar i ty  withwhich a speaker  pronounces an utterance,and the strategy the hearer appears to usein ident i fy ing  it.
The task of theGerry A l tmannDepar tment  of L ingu is t icsEd inburgh Un ivers i tyGeorge SquareEd inburgh EHB 9LL.
(GB)compu-?er system is to mimic, thoughpre ferab ly  model, this strategy.
In orderto do so, one should presumably  draw onboth computat iona l  and psycho log ica ltheor ies of process.
Such a dual approachhas been shown to be feasible, and indeeddesirable,  by research into ear ly v isualp rocess ing  (eg.
Marr  1976) which has shownthat there can come a point  whenpsycho log ica l  and computat iona ldescr ip t ions  become bare lyd is t ingu ishab le .
This ana logy with ear lyv isual  process ing is s ign i f i cant  becausecentra l  to the deve lopment  of the v is ionresearch was the not ion of 'model l ing':one can argue that a s ign i f i cantd i f fe rence  between the so-ca l led  '4thGenerat ion'  and '5th Genera?ion'techno log ies  is that with the former ad-hoc a lgor i thms are appl ied to of tenincomplete  and unre l iab le  data, whi le  with5th Generat ion  systems, a lgor i thms aredev ised by f i rst  const ruct ing  qua l i ta t ivemodels  sui ted to the task domain.We propose to use psycho l ingu is t i csas a tool for the const ruct ion  of modelsessent ia l  to the character i sa t ion  of thespeech unders tand ing  task.
We bel ieve thatthis approach is essent ia l  to thedeve lopment  of automated speechrecogn i t ion  systems, and wil l  a lso provebenef ic ia l  to psycho log ica l  models  ofhuman speech processing,  the major i ty  ofwhich are underdetermined  from acomputat iona l  point of view.
Rumelhar t  andMcCle l land  have recent ly  adopted a s imi larapproach to account  for the major f indingsin the psycho log ica l  l i terature  on letterpercept ion.
By const ruct ing  a deta i ledcomputat iona l  model  of the processesinvolved they were able to give ana l te rnat ive  descr ip t ion  of the recogn i t ionof certa in letter strings, which wassupported by subsequent  psycho l ingu is t i cexper iments.
Rumelhar t  and McCle l landemphas ise  the point  that their  resul tswere not pred ic tab le  'on paper', but werethe outcome of cons iderab leexper imentat ion  with the computat iona lmodel.239Requirements of the Computat ionalFrameworkThe experience of the ARPA speechproject, which resulted in the design of anumber of speech recognit ion systems, hasdemonstrated that the task of control l ingthe interactions between the knowledgebases which make up the system is at leastas problematic as that of def ining theknowledge bases.
Major inadequacies inthe systems developed during the ARPAproject can be attr ibuted to an earlycommitment in one or more areas of designwhich were not apparent until finaltesting and evaluation of the completesystem began.
An architecture isrequired, therefore, which will permit thedevelopment in parallel and relat ivelyindependently of component knowledge basesand methods of deploying themcomputationally.
It should also permitthe evaluation and testing of solutionswith partial ly specif ied or simulatedcomponents.
This will ensure that thedesign of one component will not inf luenceunduly the design of any other component,possibly to the detr iment of both.
Inaddition, we should have the abi l i ty todetermine the consequences of componentdesign decisions by testing theircontributions to the overall  goals ofspeech recognition.In order to fulfi l l  theserequirements we propose to use the activechart parser (e.g.
Thompson & Ritchie,1984).
This was specif ical ly designed asa flexible framework for theimplementation (both serial and para l le l )of di f ferent rule systems, and theevaluation of strategies for using theserule systems.
It is described below inmore detail.The Computational ModelThe problem in designing optimalcontrol or search strategies lies incombining evidence across dif ferent levelsof descr ipt ion (e.g.
acoustic-phonetic,morpho-phonemic, syntactic, etc.
), andacross time during the extension of ahypothesis, such that promisinginterpretations are given priority and theright one wins.
In this section we shallconsider just a few of the issuesconcerning this flow of information.Automated speech systems, inparticular those implemented during theARPA-SUR project, have been forced toconfront the errorful l  and ambiguousnature of speech, and to devise methods ofcontrol l ing the very large search space ofpartial interpretations generated duringprocessing.
Although the problem wasexacerbated by the poor performance of theacoust ic-phonetic processing used in thesesystems, the experimental  evidencesuggests that the solution will not befound simply by improving techniques forlow-level feature detection.
Thesituation appears to be analogous to thatof visual processing, where "s ign i f i cant"features may be absent.
If present, theirs igni f icance may also be open to a numberof interpretations.Combining evidence across di f ferentlevels of descr ipt ion requires thespeci f icat ion of information flow betweenthese levels.
Within the psychologicall iterature, there is a growing tendencyaway from "strong" (or "instructive")interactions towards "weak" (or"selective") interactions.
With thelatter, the only permissible flow ofinformation involves the f i l tering out, byone component, of a l ternat ives produced byother components (cf.
Mars len-Wi lson &Tyler, 1980; Crain & Steedman, 1982;Altmann & Steedman, forthcoming), so inhierarchical  terms no component determineswhat is produced by any other componentbeneath it.
A strong interaction, on theother hand, al lows one component todirect, or guide, @ctively a secondcomponent in the pursuit  of a part icularhypothesis.
Within the computat ionall iterature, weak interact ions are alsoargued for on "aesthetic" grounds such asMarr's pr inciples of modular i ty and leastcommitment (Mart, 1982).The strongly interact iveheterarchical  and blackboard modelsimplemented in HWIM and Hearsay IIrespect ively have been cr i t ic ised for theextremely complex control strategies whichthey required.
Problems arise with theheterarchical  model "because of thedi f f icult ies of generating each of theseparate interfaces and, more importantly,because of the necessity of specifying theexpl icit  control scheme."
(Reddy & Erman,1975).
Similar problems arise withexist ing blackboard models.
Theirinformation flow allows strong top-downdirect ion of components, result ing onceagain in highly complex controlstrategies.
Hierarchical  models haveother problems, in that they al low toolittle interact ion between the knowledgesources: within a str ict ly hierarchicalsystem, one cannot "interleave" theprocesses associated with each dif ferentlevel of knowledge, and hence one cannotal low the very early f i l tering out byhigher- level  components of what might onlybe partial analyses at lower levels.
Thissituation (considered disadvantageous forreasons of speed and efficiency) arisesbecause of the lack of any commonworkspace over which the separatecomponents can operate.
There is,however, much to be said for h ierarchicalsystems in terms of the relat ive240s impl ic i ty  of the control  s t rategiesneeded to manage them, a cons iderat ionwhich is fundamenta l  to the des ign of anyspeech recogn i t ion  system.The model current ly  being deve lopedembodies a weak h ierarch ica l  interact ion,s ince this seems most promis ing on bothpsycho log ica l  and computat iona l  grounds.Unl ike ex ist ing h ierarch ica l  orassoc iat ive  models, it uses a un i formglobal data structure,  a "chart".Assoc iated with this s t ructure  is theact ive chart parser.The act ive chart  parser consists  ofthe fo l lowing: -I) A un i form global  data st ructure  (theChart), represents  compet ing pathwaysthrough a search space, at d i f fe rentlevels of descr ipt ion,  and at d i f fe rentstages of analysis.
Complete  descr ip t ionsare marked by " inact ive" paths, cal lededges, spanning tempora l ly  def inedport ions of the utterance.
These inact iveedges have pointers to the lower leveldescr ipt ions  which support  them.
Part ia ldescr ipt ions  are marked by "active" edgeswhich carry representat ions  of the dataneeded to complete them.
For example, asyntact ic  edge, such as a noun phrase, mayspan any complete descr ip t ions  thatpart ia l ly  support  it, such as a determineror adject ive.
In addit ion,  it wi l l  carrya descr ipt ion  of the syntact ic  propert ies(e.g.
noun) any inact ive lexical  edge musthave to count both as add i t iona l  ev idencefor this syntact ic  descr ip t ion  and asjust i f icat ion for its extens ion orcomplet ion.
The type and complex i ty  ofthe descr ipt ions  are determined by therule based knowledge systems used by theparser, and are not determined by theparser itself.2) A mul t i - leve l  task queueing st ructure(the Agenda), which is used to order theways in which the descr ip t ions  wil l  beextended, through time and level ofabstract ion,  and thus to control  the sizeand d i rect ion of the search space.
Thisorder ing on the agenda is contro l led  byspec i f ica l ly  des igned search st rategieswhich determine the min imum amount  ofsearch compat ib le  with a low rate of errorin descr ipt ion.
The power  and f lex ib i l i tyof this approach in tack l ing complexsystem bui ld ing tasks is well  set out inBobrow et al 1976).3) An a lgor i thm which automat ica l lyschedules addi t ions  to the Chart  onto theAgenda for subsequent  process ing whereversuch extens ions are possible.
That is tosay, whenever a descr ip t ion  which iscomplete at some level (an inact ive  edge)can be used to extend a part ia ldescr ip t ion  at some higher level (anact ive edge).
The knowledge bases def inewhat extens ions  are possible,  not theparser.To summarize,  the chart  is used torepresent  and extend pathways, throught ime and level of abstract ion,  through asearch space.
With in  the chart, there ared i f ferent  types of path cor respond ing  tod i f fe rent  levels of descr ipt ion,  each ofwhich is assoc ia ted  with a par t icu larknowledge source.
To the extent thatknowledge spec i f ic  rules speci fy  whatcounts as const i tuent  pathways at thed i f fe rent  levels of abstract ion,  ah ierarch ica l  f low in in format ion  ismainta ined.
The weak in teract ion  ar isesbecause a l te rnat ive  pathways at one levelof descr ip t ion  can be f i l tered throughattempts  to bui ld pathways at the next"higher" level.
This model  d i f fers  froms t ra ight fo rward  h ierarch ica l  models, butresembles  assoc ia t ive  models, in thatknowledge sources cont r ibute  to process ingwi thout  each source necessar i l ycor respond ing  to a d is t inct  stage ofanalys is  in the process ing  sequence.Having sketched the const ruct ion  ofthe search space we must  now dec ide upon ast rategy for exp lor ing  that space.
Mostcurrent  psycho log ica l  theor ies  appear  toassume str ict  " le f t - to- r ight"  processing,a l though this requires  tack l ing  st retchesof sound immediatedly which are of pooracoust ic  qual ity,  and which are re la t ive lyunconst ra ined  by higher level knowledge.The major i ty  of systems deve loped dur ingthe ARPA pro ject  found it necessary  to uselater occurr ing in format ion  tod i sambiguate  ear l ier  parts of anutterance.
Moreover,  there ispsycho l ingu is t i c  ev idence that the" inte l l ig ib i l i ty"  of a par t icu lar  s t retchof sound increases with add i t iona lev idence from later "r ightward" s t retchesof sound (Pol lack & Pickett, 1963; Warren& Warren, 1970).
We propose to adopt  asystem using a form of le f t - to - r ightanalys is  which could approx imate  to thepower of midd le -out  analys is  (used in HWIMand Hearsay II) but w i thout  requ i r ing  theconst ruct ion  of d is t inct  " is lands" andwith less computat iona l  expense.
Thismore prec ise method of using "r ight-context  ef fects" depends on the pr ior i tyscores ass igned to paths.
Such scores canbe thought  of, for present  purposes, assome measure  of "goodness of fit".
Thescore on a spanning pathway (that is, apathway which spans other pathways"beneath" it) is determined by the scoreson its const i tuents,  and so is part lydetermined by scores towards its r ight-hand end.
By v i r tue of a f fec t ing  the"spanning score", a score on one sub-pathcan af fect  the probab i l i ty  that anothersub-path to its left (as well  as to its241right) will f inally be chosen as the bestdescript ion for the acoustic segment itrepresents.
We will use psychol inguist ictechniques to interrogate the "expert"(i.e.
stat ist ical ly rel iable experimentswith human listeners), in order todetermine both when such leftwards flowinginformation is most often used for thedisambiguation of poor quality areas, andwhat sets of paths it will affect.
Itwill be extremely useful to know whetherpeople regularly rely on information fromthe right to disambiguate precedingstretches of sound, or whether thishappens only at the beginning ofutterances as the HWIM strategy suggests.Pollack and Pickett claim that there is noeffect on intel l ig ibi l i ty of a word'sposition within a stimulus, butunfortunately they offer no inferentialstatistics to back this claim.This is only one of the many issuesin speech recognit ion which areexperimental ly addressable.
The results ofsuch experiments are obviously ofrelevance to computational systems sincethey can indicate where and when sourcesof information are most l ikely tocontribute towards identi f icat ion of anutterance.
Conversely, the attempt tobuild a working model of at least someparts of the process, will highl ight manyareas where further experimental data isneeded.Conc lud ing  RemarkWe hope that this sketch of part ofthe proposed system has given a feel forthe combined approach taken here.
Itdeveloped through a re-examination of anumber of issues which arose during theARPA speech project, and a reconsiderat ionof these issues in the light of recentcomputational and psychol inguist icadvances.
Given the success of theserecent advancements in the contr ibutingfields of research, we feel that the timeis right for the evaluation of a speechrecognit ion system along the lines laiddown here.ACKNOWLEDGEMENTSThis is a summary of a paper (Johnstone &Altmann, 1984) written as a result ofdiscussions held in the University ofEdinburgh School of Epistemics researchworkshop on Lexical Access and SpeechPerception.
We would like to thank themembers of that workshop, in particularDr.
El len Bard and Dr. Henry Thompson.The proposals contained therein have beenadopted by the Edinburgh contr ibut ion tothe Plessey Consort ium's Alvey Large ScaleDemonstrator Project on Machine AssistedSpeech Transcription.REFERENCESAltmann, G.T.
& Steedman, M.J.Forthcoming.
The Garden Path inContext: Reference and the Resolut ion ofLocal Syntactic Ambiguity.Bard, E.G.
& Anderson,  A.H. 1983.
Theunintel l ig ib i l i ty  of speech to children.Journal of Child Lanuuaqe 10, 265-292Crain, S. & Steedman, M.J. 1982.
On notbeing led up the garden path: the use ofcontext by the psychological  parser.
In(eds.)
Dowty, D., Kartunnen, L., &Zwicky, A.
Natural Lanaua~e Parsinu:psycholouical, co~putational, andtheoretical  perspectives.
In press.Johnstone, A.M. & Altmann, G.T.
1984.Automated Speech Recognition: AFramework for Research.
Department ofArt i f ic ial  Intell igence, University ufEdinburgh, Research Paper No.
233.Also appears as Speech Input Project,University of Edinburgh, Research ReportNo.
2.Marr, D. 1976.
Early Processing ofVisual Information.
Proc.
Roy.
$9c.,275.bMarslen-Wilson, W.D.
& Tyler, L.K.
1980.The Temporal Structure of SpokenLanguage Understanding.
Cognition, 8,1-71.McClelland, J .L & Rumelhart ,  D.E.
1981.An Interactive Act ivat ion Model ofContext Effects in Letter Perception:Part I.
An Account of Basic Findings.In Psvcholouical  Review, 88, 375-407.Pollack, I.
& Pickett, J.M.
1963.
Theintel l ig ibi l i ty of excerpts fromConversation.
Language add Speech, 6,165-171.Reddy, D.R.
& Ermann, L.D.
1975.Tutorial on System Organisat ion forSpeech Understanding.
In D.R.
Reddy(ed) Speech Recognition, Academic Press.Rumelhart, D.E.
& McClelland, J.L.
1982.An Interactive Act ivat ion Model ofContext Effects in Letter Perception:Part II.
The Contextual EnhancementEffect.
Some Tests and Extensions ofthe Model.
In Psychological  Review, 89,60-94.242Thompson, H.S.
& Ritchie, G.D. 1984.Techniques for Parsing Natural Language:Two Examples.
In M. Eisenstadt & T.O'Shea (eds.)
Art i f ic ial  Intel l iqenceSkills.
Harper & Row.Warren, R.M.
& Warren, R.P.
1970.Auditory Confusions and Illusions.Scientif ic American, 223, 30-36.243
