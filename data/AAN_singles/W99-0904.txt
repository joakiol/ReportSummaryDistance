Unsuperv ised  learning o f  der ivat iona l  morpho logy  f rominf lect ional  lex iconsl~ric GaussierXerox Research Centre Europe 6, Chemin de Maupertuis 38240 Meylan F.Eric.Ga.ussier@xrce.xerox.comAbstractWe present in this paper an unsupervised methodto learn suffixes and suffixation operations from aninflectional lexicon of a language.
The elements ac-quired with our method are used to build stemmingprocedures and can assist lexicographers in the de-velopment of new lexical resources.1 IntroductionDevelopment of electronic morphological resourceshas undergone several decades of research.
The firstmorphologicM analyzers focussed on inflectional pro-cesses (inflection, for English, mainly covers verbconjugation, and number and gender variations).With the development of Information Retrieval, peo-ple have looked for ways to build simple analyzerswhich are able to recognize the stem of a given word(thus addressing both inflection and derivation1).These analyzers are known as stemmers.Faced with the increasing demand for natural an-guage processing tools for a variety of languages,people have searched for procedures to (semi-)automatically acquire morphological resources.
Onthe one hand, we find work fl'om the IR communityaimed at building robust stemmers without muchattention given to the morphologicM processes ofa language.
Most of this work relies on a list ofaffixes, usually built by the system developer, anda set of rules to stem words (Lovins, 1968; Porter,1980).
Some of these works fit within an unsuper-vised setting, (Hafer and Weiss, 1974; Adamson andBoreham, 1974) and to a certain extent (Jacqueminand Tzoukerman, 1997), but do not directly addressthe problem of learning naorphological processes.
Onthe other hand, some researchers from the compu-tational inguistics community have developed tech-niques to learn affixes of a language and software tosegment words according to the identified elements.The work described in (Daelemans et al, 1999) is agood example of this trend, based on a supervised1The distinction between inflectional and derivationalmorphology is fax from clearcut.
However, in practice, sucha distinction allows one to divide the problems at hand andwas implicitly adopted in our lexicon development plan.learning approach.
However, it is difficult ill most ofthese studies to infer the underlying linguistic frame-work assumed.We present in this paper an unsupervised methodto learn suffixation operations of a language from aninflectional lexicon.
This method also leads to thedevelopment of a stemming procedure for the lan-guage under consideration.
Section 2 presents thelinguistic view we adopt on derivation.
Section 3 de-scribes the preliminary steps of our learning methodand constitutes the core of our stemming procedure.Finally, section 4 describes the learning of suffixationoperations.2 Derivation in a languageThe derivational processes of a language allow speak-ers of that language to analyse and generate newwords.
Most recent linguistic theories view theseprocesses as operations defined on words to producewords.
From a linguistic point, of view, a word can berepresented as an element made of several indepen-dent layers (feature structures, for example, couldbe chosen for this representation.
We do not wantto focus on a particular formalism here, but ratherto explain the model we will adopt).
The differentlayers and the information they contain vary fromone author to the other.
We adopt here the layersused in (Fradin, 1994), as exemplified on the Frenchnoun table:(G) table(F) (teibl)(M) fem-sg(SX) N(S) tab lewhere (G) corresponds to the graphemic form of theword, (F) to the phonological form, and (M), (SX)and (S) respectively contain morphological, syntac-tic and semantic information.
A derivation processthen operates on such a structure to produce a newstructure.
Each layer of the original structure istransformed via this operation.We can adopt the following probabilistic model toaccount for such a derivation process:24P(w,  = p(w:(G) = opG(w, (a ) ) ,Opw~(F) = Opp(wl(F)) ,  w2(M) = OpM(Wl(M)),w~(S.V) = 01,s.x(w~(,5'X)), wE(S) = Op.s.
(w~(S)))where Op is a derivation process, Opt  is the compo-nent of Op which operates on the graphemic layer,and w(G) is the graphemic layer associated to wordW.The different layers can be divided up into threemain dimensions, used in linguistic studies to iden-tify and classify suffixes of a language: the formaldimension (corresponding to G and F), the morpho-syntactic dimension (M and SX), and the semanticdimension (S).
The nature of the operation alongthese dimensions mainly depend on the language un-der consideration.
For example, for Indo-Europeanlanguages, for the formal dimension, a suffixationoperation consists in the concatenation of a suffixto the original form.
Morphographemic as well asphonological rules are then applied to turn the idealform obtained via concatenation i to a valid surfaceform.We focus in this article on concatenative lan-guages, id est languages for which derivation cor-responds, for the formal dimension, to a concate-nation operation.
We also restrict ourselves to thestudy of suffixes and suffixation.
Nevertheless, theprinciples and methods we use can be extended tonon-concatenative languages and prefixes.The a.im of the current work is two-fold.
On theone hand we want to develop stemming proceduresfor Information Retrieval.
On the other hand, wewant to develop methods to assist lexicographers inthe development of derivational lexicons.
We possesinflectional exicons for a variety of different lan-guages, and we'll use these lexicons as input to oursystem.
Furthermore, we are interested in makingthe method as language independent as possible,which means that we will explore languages with-out a priori knowledge 2 and thus we wish to rely onan unsupervised learning framework.The probabilistic model above suggests that, inorder to learn suffixation operations of a language,one should look at word pairs (wl, w2) of that lan-guage for which w2 derives from wl, In an unsu-pervised setting, such pairs are not directly accessi-ble, and we need to find ways to extract the infor-mation we are interested in from a set of pairs thewords of which are not always related via deriva-tion.
The method we designed first builds, for agiven language, relational families, which are an ap-proximation of derivational families.
These families2 In par t i cu la r ,  i t  is in teres t ing  to avo id  re ly ing  on suffixl ists,  which vary f rom one author  to the other .are then used to produce pairs of words which area first approximation of the pairs of related words.From this set of pairs, we then extract suffixes andsuffixation operations.The next section addresses the construction of re-lational families.3 Construct ion of relational famil iesOur goal is to build families which are close to thederivational families of a language.
This contructionrelies on the notion of suffix pairs that we explainbelow.3.1 Extraction of suffix pairsThe intuition behind the extraction of suffixes is thatlong words of a given language tend to be obtainedthrough derivation, and more precisely through suf-fixation, and thus could be used to identify regularsu f f i xes .We first define a measure of similarity between wordsbased on the comparison of truncations.Def in i t ion  1: two words Wl and we of a given lan-guage L are said to be p-s imi la r  if and only ifi trunc(wl,p) =- trunc(w2,p), where trunc(w,k)is composed of the first k characters of w,ii there is no q such that: q > p andt,'une(wl, q) _= trune(,v2, V)The equivalence relation (=) defined on tile alpha.-bet of L allows one to capture orthographic variants,such as the alternation c - ?
in French.
The char-acter strings sl and s2 obtained after truncation ofthe first p characters fi'om two p-similar words arecalled pseudo-suffixes.
The pair (sl,s2) will be calleda pseudo-suffix pair of the language L, and will besaid to link Wl and w2.
Note that the strings sland/or s2 may be empty: they are both empty if thewords wl and w2 differ only in their part.
of speech,in which case we speak about conversion.The above definition allows us to state that the En-glish words "deplorable" and "deploringly" are 6-similar and that (able,ingly) is an English pseudo-suffix pair.
Since "deplorable" is an adjective and"deploringly" is an adverb, we can provide a moreprecise form for the pseudo-suffix pair, and write(able+AJ,ingly+AV) (where +AJ  stands for adjec-tive and +AV fbr adverb) with the following inter-pretation: we can go from an adjective (resp.
ad-verb) to an adverb (resp.
Adjective) by removing thestring "able" (resp.
"ingly") and adding the string"ingly" (resp.
"able").Def in i t ion  2: a pseudo-suffix pair of a given lan-guage L is val id when the pseudo-suffixes involvedare actual suffixes of the language L, and when thepair can be used to describe the passage fl'om one25word of a given derivational family of L to anotherword of the same family.Two parameters are used to determine as preciselyas possible valid pseudo-suffix pairs: the p-similarityand the number of occurrences of a pseudo-suffixpair.
This last parameter accounts for the fact thatthe pseudo-suffix pairs encountered fi'equently areassociated to actual suffixation processes whereasthe less frequent ones either are associated to ir-regular phenomena or are not valid.
But, in orderto design a procedure which can be applied on sev-eral languages, and to avoid missing too many validpseudo-suffix pairs, we have set these two parame-ters in the following loose way:Def in i t ion  3: a suffix pa i r  of a language L is apseudo-suffix pair of L which occurs re, ore than oncein the set of word couples of L which are at least5-similar.Rein ar ks:?
two words are at least k-similar if they are p-similar with p >_ k,?
all the suffix pairs are not valid.
The abovedefinition provides a set of pseudo-suffix pairswhich is approximately contains the set of validpseudo-suffix pairs.
Our purpose here is not tomiss any valid pseudo-suffix pair,?
the number of occurrences of a pseudo-suffixpair is set at 2, the minilnal value one can thinkof, and which corresponds to our desire to re-main language independent,,?
the choice of the value 5 for the similarity fac-tor represents a good trade off between the no-tion of long words and the desire to be languageindependent.
We believe anyway that a slightchange in this parameter won't lead to a set ofpseudo-suffix pairs significantly different fi'omthe one we have.Here is an example of French suffix pairs extractedfrom the French lexicon, with their number of oc-cur rences :ation+N er+V 782+AJ  ment+AV 460eur+AJ ion+N 380er+V on+N 50sation+N tarisme+N 5All these suffix pairs are valid except the last onewhich is encountered in cases such as "autorisation- autoritarisme" (authorisation- authoritarianism).One can note that a valid suffix pair does not al-ways link words which belong to the same deriva-tiona.l t'amily.
For example, the pair (er+V,on+N)yields the following link "saler - salon" (salt - lounge)though the two words refer to different concepts.The notion of validity only requires that two wordsof a same derivational family can be related by thesuffix pair, which is the case for the previous pair inso far as it relates "friser - frison" (curl (+V) - curl(+N) )3.2 C luster ing  words into re lat ionalfamil iesThe problem we have to face now is the one ofgrouping words which belong to the same deriva-tional family, and to avoid grouping words which donot belong to the same derivational family.
A sim-ple idea one can try consists in adding words intoa family to the extent they are p-similar, with avalue of p to be determined, and related throughsuffix pairs.
For example, given the two English suf-fix pairs (+V,able+AJ)  and (+V,ment+N),  we canfirst group the 6-similar words "deploy" and "de-ployable", and then add to this family the word"deployment".
But such a procedure will also leadto group "depart" and "departlnent" into the samefamily.
The problem here is that suffix pairs relatewords which do not belong to the same derivationalfamily.There is however one way we can try to automatethe control of the removal of a suffix, based on thefollowing intuitive idea.
If the string "lnent" is not.
asuffix, as in "department", then it is likely that theword obtained after removal of the string, that is"depart", will support suffixes which do not usuallyco-occur with "ment", such as "ure" which produces"departure".
The underlying notion is that of suffixfamilies, notion which accounts for the fact.
that theuse of a suffix usually coincides with the use of othersuffixes, and that suffixes from different families donot co-occur.
Such an idea is used in (Debili, 1982),with manually created suffix families.To take advantage of this idea, we used hierarchi-cal agglomerative clustering methods.
The followinggeneral algorithm can be given for hierarchicM clus-tering methods:1. identify the two most similar points (with sim-ilarity greater than 0)2. combine them in a cluster3.
go back to step 1, treating clusters as points,till no more points can be merged (similarity 0)Particular methods differ in the way sinfilarity iscomputed.
In our case, the initial points consistof words, and we define the similarity between twowords, wl and w2, as the number of occurrences ofthe suffix pair of L which links wt and u,~.
If such asuffix pair does not exist, then the similarity equals0.
The similarity between clusters (or points as ref-ferred to in the above Mgorithm) depends on themethod chosen.
We tested 3 methods:26?
single link; the similarity between two clusters isdefined as the similarity between the two mostsin:dlar words,?
group average; the sin:dlarity between two clus-ters is defined as the average similarity betweenwords,?
complete link; the similarity between two clus-ters is defined as the similarity between the twoless similar words,The single link method makes no use at all ofthe notion of suffix families, and corresponds to thenaive procedure described above.
The group averagemethod makes partial use of this notion, whereas thecomplete link heavily relies on it.The clusters thus obtained represent an approx-imation of the derivational families of a language,and consitute our relational families.Here is an exemple of some relational falnilies ob-tained with the complete link method:deprecate deprecation deprecator deprecative dep-lvcativeness dep~vcativelg deprecatwity deprecatorilydep~vcato'rg dep~vcatinglydeposabilitg deposable deposableness deposablg de-pose deposer deposaldepartment departmentality departmental depart-mentalness departmentallydepart departure departer3.3 Eva luat ionWe performed an evaluation on English consideringas the gold reference a hand-built derivational lexi-con that, we have.
We extracted erivational familiesfrom this lexicon, and compared them to the rela-tional families obtained.
This comparison is basedon the number of words which have to be movedto go from one set of families to another set.
Dueto overstemming errors, which characterise the factthat some unrelated words are grouped in the samerelational family, as well as to understemming er-rors, which correspond to the fact that some relatedwords are not grouped in the same relational family,relational and derivational families often overlap.To account for this fact, we made the assumptionthat a word wi was correctly placed in a relationalfamily ri if this relational family comprised in major-ity words of the derivational family of wi, and if thederivational family of wi was composed in majorityby words of ri.
That is there must be some strongagreement between the derivational and relationalfamilies to state that a word is not to move.
All thewords which did not follow the preceding constraintswere qualified as "to move".
We directly used theratio of words "not to move" to compute the prox-imity between relational and derivational fa.milies.We, in fact, evaluated several versions of the rela-tional families we built, in order validate or inval-idate some of our hypotheses.
The following tablesummarises the results obtained for the three clus-tering methods tested, with the parameters set asdescribed above:Single link 47%Group average 77%Complete link 85%These results show the importance of the notionof suffix families, at least with the parameters weused.
As a comparison, we performed the sameevaluation with families obtained by two stemmers,the SMART and Porter's stemmer, well-known inthe Information Retrieval community.
To constructfamilies with these stemmers, we took the wholelemmatised lexicon, submitted it to the stemmersand grouped words which shared the same stem.We then ran the evaluation above and obtained thefollowing results: SMART stemmer: 0.82 Porter'sstemmer: 0.65 Not surprisingly, the SMART stem-mer, which is the result of twenty years of (level-opment, is a better approximation of derivationalprocesses than Porter's stemmer.4 From relat ional to derivationalmorphologyOnce the relational families have been constructed,they can be used to search for actual suffixes.
Ratherthan performing this search directly from our lexi-con, i.e.
from all the possible word pairs, the clus-tering made to obtain word families allows us to re-strict ourselves to a set of word pairs motivated bythe broad notion of suffix we used in the previoussection.We thus use the following general algorithm,which allows us to estimate the parameters of thegeneral probabilistic model given above:?
1. from the lexicon, build relational families,?
2. from relational families, build a set of wordpairs and suffixes,?
3. from this set, estimate some parameters ofthe general model,?
4. use these parameters to induce a derivationtree on each relational family,?
5. use these trees to refine the previous set ofword pairs and suffixes, and go back to step 3till an end criterion is found?
6. the trees obtained can then be used to ex-tract dependencies between suffixation opera-tions, as well as morphographemic rules.We will now describe steps 3, 4 and 5, and give anoutline of step 6.274.1 Extract ion of  sufl=ixation operat ionsSince our lexicons contain neither phonologicalnor semantic information, the general probabilisticmodel given in the introduction can be simplified, sothat it is based only on the graphemic and morpho-syntactic dimensions of words.
Furthermore, sincewe restrict ourselves to concatenative languages, weadopt the following form for a suffixation operationS:S= (ad=c?ncat (G?
's )  )MSo~MSdwhere G4 (MSa) stands for the graphemic (morpho-syntactic) form of the derived word produced by thesuffixation operation, Go (MSo) for the graphemic(morpho-syntactic) form of the original word onwhich the suffixation operation operates, conea* isthe concatenation operation, and s is the suff?x as-sociated to the suffixation operation S.We can then write the probability that a word w2derives, through a suffixation process, from a. wordwl as follows:P(Wl - -+w2)  == ~s p(S)p(Ga -+ G2, MS1 -+ MS',IS)= ~s p(S)p(G1 -+ G2\]S)p(MS1 ~ MSu\]G1 -+ G~, S)~- ~s  p(5')p(Gi ~ G21S)p(M& ~ M&IS)the last equation being based on an independenceassumption between the graphetnic form and themorpho-syutactic nformation attached to words.Even though some morpho-syntactic nformationcan be guessed from the graphical form of words,it is usually done via the suffixes involved in thewords.
Thus, conditioning our probabilities on themere suffixation operations represents a. good ap-proximation to the kind of dependence that existsbetween graphemic form and morpho-syntactie in-formation.The t.erm involving morpho-syntactic information,i.e.
the probability to produce MS2 from MS1knowing the suffixation operation S, can be directlyrewritten as:p(MS~ --+ MS2\]S) = ~(MS1, MSo)5(MS2, MSd)where 5 is the Kronecker symbol (6(x, y) equals 1 ifthe two arguments are equal and 0 otherwise).The words we observe do not exactly reflectthe different elements they are made of.
Mor-phographemie rules, allomorphy and truncation phe-nomena make it difficult to identify the underlyingstructure of words (see (Anderson, 1992; Corbin,1987; Bauer, 198:3) for discussions on this topic).That is, the graphemic forms we observe are the re-sults of different operations, concatenation being, inmost cases, only the first.Since: allomorphy, truncation and mor-phographemic phenomena do not depend onthe words themselves but on some subparts of thewords; direct concatenation gives a better access tothe suffix used; and suffixation usually adds elementto the original form 3, we use the following forln forp(G, ~ G21S):p(G1 ~ G2\]S) = 0 i f  l(G1) > l(G2)else p(G1 ~ G.~IS) =co i f  diff(G1, G2, s) = 0el i f  diff(Gx,G2,s) = 1e:, i f  diff(G1,G;,s) = 2ca i f  diff(G1,G~,s) = 30 otherwisewhere I(G) is the length of G, diff(str l ,  str2, suf f )represents the number of characters differing be-tween strl and str2-  su f f  (i.e.
the string obtainedvia removal of surf  from str2, proceeding backwardfrom the end of str2), and ei, 0 < i < 3 are arbitraryconstants, the stun of which equals 1, which controlthe confidence we have on a suffix with respect tothe edit distance between G1 and G2.For our first experiments, we set the four constantsco, cl , c,., ca according to the constraint:1 1 1ca = = = gc0which accounts for tile fact that we give more weight.to direct concatenation, then to concatenation withonly 1 differing character, etc.To estimate the probabilities p(S), we first builta set of suffixation operations from relational fami-lies; for each word pair (Wl, w~) found in a relationalfamily, we consider all the suffixation operations Ssuch that:( s )S = MS1 ---+ MS2with s being a sequence of letters ending G2 suchthat:p(G, --+ G21S) > 0This process yields, besides the set of suffixationoperations, a set of word pairs (wl, w:~) possiblylinked through a suffixation process.
We will denoteaDue to truncation and subtraction, there may be caseswhere the derived form is shorter or the same length as theoriginal form.
However, these eases are not frequent, andshould be recovered by the procedures which follow.28this last set by WP.
Some of the pairs in W'P arevalid, in the sense that the second element of the pairdirectly derives from the first element, whereas otherpairs relate words which may or may not belong tothe same family, through a set of deriva.tional pro-cesses.
However, since relational families representa good approximation to actual derivational fami-lies, regular suffixation processes should emerge fromWP.We then used the EM algorithm, (Dempster etal., 1977), to estimate the probabilities p(S).
Viathe introduction of Lagrange multipliers, we obtainthe following reestimation formula:po,(S) =p~(S)p(G1 ~ G~IS)p(MS1 --+ MS, IS) A-1 A-, ~s ,  po(S')p(G~ --+ G2\[S')p(MS~ --+ MS2\[S') ~,vpwhere A is a normalizing factor to assure that prob-abilities sum up to 1.This method applied to French yields the follow-ing results (we display only the first 10 suffixes, i.e.the string s associated with the suffixation opera-tion S, together with the POS of the original andderived words.
The first number corresponds to theprobability estimated ):0.071671 Noun ---+ er ~ Verb0.019032 Adj ~ er ~ Verb0.018231 Verb ~ ion ~ Noun0.017365 Noun ~ ion ---+ Noun0.017123 Noun ~ ur  --+ Noun0.012864 Noun ~ eur  ---+ Noun0.011034 Noun ~ on ~ Noun0.010780 Noun ~ te ~ Noun0.009955 Adj --+ a t ion  --+ Noun0.009881 Noun ---+ nt ---+ AdjAs can be seen on these results, certain elements,such as ur  are extracted even though the appro-priate suffix is eur,  our procedure privileging theelement with direct concatenation (this concatena-tion happens after a word ending with an e).
Note,however, that the t rue suffix is close enough to beretrieved.4.2 Ext rac t ion  of  suff ixal parad igmsThe suffixes we extracted are derived from relationalfamilies.
In these families, some words are relatedeven though they do not derive from each other.
Theset of related words in a relational family defines agraph on this family, whereas the natural represen-tation of a derivational family is a tree.
We want topresent here a method to discover such a tree.A widely used tree construction method froma graph is the Minimal(Maximum) Spanning Treemethod.
We have adapted this method in the fol-lowing way:1.
Step 1: for each word pair (w~, w~) in the family,compute a = p(tv~ --+ w~),2.
Step 2: sort the pairs in decreasing order ac-cording to their a value,3.
Step 3: select the first pair (wl, u,~), add a linkwith wl as father and w2 as daughter,4.
Step 4: for each possible suffixation operationS such that p(wl ~ w21S) > 0, add to thenode wl the potential allomorph obtained byremoving s from G2, proceeding backward fromthe end of G2,5.
Step 5: select the following pair, compute theset of allomorphs A, and add a link between theelements, if:(a) it does not create a loop,(b) if the first element of the pair, w~, is al-ready present in the tree, then the set, ofallomorphs of w~ in the tree is either emptyor has common elements with A.
In the lat-ter case, replace the set of allomorphs of w~in the tree by its intersection with A,6.
Step 6: go back to Step 5 till all the pairs havebeen examinedThis algorithm calls for the following remarks:we use allomorph in a broad sense, for lexelnes:an allomorph of a word is simply a form associ-ated to this word and which can be used as thesupport o derivation in place of the word itself,if two sets of allomorphs are not empty and donot have elements in common, then we face aconflict between which elements erve as a sup-port for the different derivation processes.
Ifthey have common elements then the commonelements can be used in the associated eriva-tion processes.
If one set is empty, then theword itself is used for one derivation process,and the allomorphs in the other.Let us illustrate this algorithm on a simple exemple.Let us assume we have, in the same relational fam-ily, the three French words produire (En.
produce),production (En.
production), producteur (En.
pro-ducer).
Step 2 yields the two ordered pairs (produire,production); (produire, producteur).
Steps 3 and 4for the first pair provide the suffixes (on, ion, tion,ction) and the associated allomorphs for produire:(produ, produc, product, p~vducti).
When examin-ing the pair (produire, producteur), we obtain thesuffixes (ur, cur, teur, cteur) with the allomorphsfor produire: (produ, produc, product).
The two setsof allomorphs have common elements.
The final setof allomorphs for produire will obtained by intersect-ing the two previous ets, leading to: (produ, produc,29product).
Note that the elimination of the form pro-ducti will lead to the rejection of the suffix on insubsequent treatment (namely the learning of suf-fixes from the trees, step 5 of the algorithm given atthe beginning of section 2).Once the trees have been constructed for all rela-tional families (note that with our procedure, morethan one tree may be used to cover the whole fam-ily), it is possible to reestimate the probabilitiesp(S).
This time, the word pairs are directly ex-tracted from the trees, and, due to the sets of al-lomorphs, the probabilities p(G1 ---+ G21S) are notnecessary anymore, since we will only rely on directconcatenation.
Lastly, as described in the general al-gorithm, the new suffixation operations can be usedagain to build new trees, and so on and so forth,until an end condition is reached.
A possible endcondition can be the stabilization of the set of suf-fixation operations.
Since our procedure graduallyrefines this set (at one iteration, the set ofsuffixationoperations i  a subset of the one used in the previousiteration), the algorithm will stop.Another extension we can think of is the extrac-tion, from the final set of trees, of morphographemicrules.
Methods borrowed to Inductive Logic Pro-gramming seem good candidates for such an extrac-tion, since these rules can be formulated as logicalclauses, and since we can start from specific exam-ples to the least general rule covering them (sev-eral researchers have addressed this problem, suchas (Dzeroski and Erjavec, 1997)).5 Conc lus ionWe have presented an unsupervised method to ac-quire derivational rules from an inflectional lexicon.In our opinion, the interesting points of our methodlie in its ability to automatically acquire suffixes, aswell as to induce a linguistically motivated structurein a lexicon.
This structure, together with the ele-ments extracted, can easily be revised and correctedby a lexicographer.AcknowledgementsI thank two anonymous reviewers for useful com-ments on a first version of this paper.ReferencesG.
Adamson and J. Boreham.
1974.
The use ofan association measure based on character struc-ture to identify semantically related pairs of wordsand ocuments titles.
Information Storage and Re-trieval, 10.S.
R. Anderson.
1992.
A-morphous morphology.Cambridge University Press.L.
Bauer.
1983.
English word-formation.
Cam-bridge University Press.V.
Cherkassky and F. Muller.
1998.
Learning ffromdata.
John Wiley and Sons.D.
Corbin.
1987.
Morphologie d(rivationnelle tstructuration du lexique.
Presses Universitaires deLille.W.
Daelemans, J. Zavrel, K. Van der Sloot, andA.
Van den Bosch.
1999.
Timbh Tilbury memorybased learner, version 2.0, reference guide.
Tech-nical report, ILK, Tilburg.J.
Dawson.
1974.
Suffix removal and word confla-tion.
ALLC Bulletin.F.
Debili.
1982.
Analyse syntaxico-sdmantiquefondde sur une acquisition automatique de rela-tions lexicales-sdmantiques.
Ph.D. thesis, Univ.Paris 11.A.
P. Dempster, N. M. Laird, and D. B. Dubin.1977.
Maximum likelihood from incomplete datavia the em algorithm.
Royal Statistical Society,39.S.
Dzeroski and T. Erjavec.
1997.
Induction ofslovene nominal paradigms.
In Proceedings of 7thInternational Workshop on Inductive Logic PTv-gramming.B.
Fradin.
1994.
L'approche ?
deux niveaux en mor-phologie computationnelle et les d6veloppementsr~cents de la morphologie.
Traitement aatoma-tique des langues, 35(2).M.
Hafer and S. Weiss.
1974.
Word segmentationby letter successor varieties.
Information Storageand Retrieval, 10.C.
Jacquemin and E. Tzoukerman.
1997.
Guessingmorphology from terms and corpora.
In Proceed-ings of A CM SIGIR.J.B.
Lovins.
1968.
Development of a stemming al-gorithm.
Mechanical Translation and Computa-tional Linguistics, 11.C.D.
Manning.
1998.
The segmentation problemin morphology learning.
In Proceedings of NewMethods in Language Processing and Computa-tional Natural Language Learning.C.
Paice.
1996.
Method for evaluation of stemmingalgorithms based on error counting.
Journal of theAmerican Society for Information Science, 47(8).M.
F. Porter.
1980.
An algorithm for suffix strip-ping.
Program, 14(3).A.
Stolcke and S. Omohundro.
1994.
Best-firstmodel merging for hidden markov model induc-tion.
Technical report, ICSI, Berkeley.30
