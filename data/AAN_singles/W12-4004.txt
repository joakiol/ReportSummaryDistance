Proceedings of the 3rd Workshop on the People?s Web Meets NLP, ACL 2012, pages 20?28,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsResolving Task Specification and Path Inconsistency in TaxonomyConstructionHui YangDepartment of Computer ScienceGeorgetown University37th and O street NWWashington, DC, 20057huiyang@cs.georgetown.eduAbstractTaxonomies, such as Library of Congress SubjectHeadings and Open Directory Project, are widelyused to support browsing-style information accessin document collections.
We call them browsingtaxonomies.
Most existing browsing taxonomiesare manually constructed thus they could not eas-ily adapt to arbitrary document collections.
In thispaper, we investigate both automatic and interactivetechniques to derive taxonomies from scratch for ar-bitrary document collections.
Particular, we focuson encoding user feedback in taxonomy construc-tion process to handle task-specification rising froma given document collection.
We also addresses theproblem of path inconsistency due to local relationrecognition in existing taxonomy construction algo-rithms.
The user studies strongly suggest that theproposed approach successfully resolve task specifi-cation and path inconsistency in taxonomy construc-tion.1 IntroductionTaxonomies, such as Library of Congress SubjectHeadings (LCSH, 2011) and Open Directory Project(ODP, 2011), are widely used to support browsing-style information access in document collections.We call them browsing taxonomies.
Browsing tax-onomies are tree-structured hierarchies built upon agiven document collection.
Each term in a browsinghierarchy categorizes a set of documents related tothis term.
Driven by their needs, users can navigatethrough a the hierarchical structure of a browsingtaxonomy to access particular documents.
A brows-ing taxonomy can benefit information access via (1)providing an overview of (important) concepts in adocument collection, (2) increasing the visibility ofdocuments ranked low in a list (e.g.
documents or-dered by search relevance), and (3) presenting to-gether documents about the same concept to allowmore focused reading.Most existing browsing taxonomies are manuallyconstructed thus they could not easily adapt to arbi-trary document collections.
However, it is not un-common that document collections are given ad-hocfor specific tasks, such as search result organiza-tion in for individual search queries (Carpineto et al,2009) and literature investigation for a new researchtopic (Chau et al, 2011).
There is a necessity to ex-plore automatic or interactive techniques to supportquick construction of browsing taxonomies for arbi-trary document collections.Most research on automatic taxonomy construc-tion focuses on identifying local relations betweenconcept pairs (Etzioni et al, 2005; Pantel and Pen-nacchiotti, 2006).
The infamous problem of pathinconsistency, which are usually caused by the lo-cal nature of most relation recognition algorithmswhen building a taxonomy, commonly exists in cur-rent research.
Oftentimes, when a connecting con-cept for two pairs of parent-child concepts has mul-tiple senses or represent mixed perspectives, theproblem shows up.
For example, while financialinstitute?bank and bank?river bank are correct;the path financial institute?bank?river bank is se-mantically inconsistent.20In this paper, we propose a semi-supervised dis-tance learning method to construct task-specific tax-onomies.
Assuming that a user is present to con-struct a taxonomy for browsing, the proposed ap-proach directly learns semantic distances from themanual guidance provided by the user to predict se-mantically meaningful browsing taxonomies.
More-over, We tackle path inconsistency by posing con-straints over root-to-leaf paths in a hierarchy to en-sure concept consistency within pathsThe contributions of our work include:?
It offers an opportunity for handling task spec-ifications.?
Unlike most algorithms, our work takes careof path consistency during taxonomy construc-tion.The remainder of this paper is organized as fol-lows: Section 2 describes the related work.
Sec-tion 3 details the proposed automated algorithm fortaxonomy construction.
Section 4 presents the in-teractive algorithm to incorporate user feedback un-der a supervised semantic distance learning frame-work.
Section 5 describes the evaluation and Section6 concludes the paper.2 Related WorkMost research conducted in the NLP community fo-cuses on extracting local relations between conceptpairs (Hearst, 1992; Berland and Charniak, 1999;Ravichandran and Hovy, 2002; Girju et al, 2003;Etzioni et al, 2005; Pantel and Pennacchiotti, 2006;Kozareva et al, 2008).
More recently, more atten-tion has been paid in building full taxonomies.
Forexample, (Kozareva and Hovy, 2010) proposed toconnect local concept pairs by finding the longestpath in a subsumption graph.
Both (Snow et al,2006) and (Yang and Callan, 2009) incrementallygrew taxonomies by adding new concepts at opti-mal positions within the existing structures.
Specifi-cally, Snow et al estimated conditional probabilitiesby using syntactic parse features and decided taxo-nomic structure via maximizing overall likelihoodof taxonomy.
Yang and Callan proposed the MEframework to model the semantic distance d(cx, cy)between concepts cx and cy as a weighted combi-nation of numerous lexical and semantic features:?j weightj ?
featurej(cx, cy) and determine the tax-onomic structure by minimizing overall distances.An advantage in ME is that it allows manipu-lations to concept positions by incorporating vari-ous constraints to taxonomic structures.
For exam-ple, ME handled concept generality-specificity bylearning different distance functions for general con-cepts (located at upper levels) and specific concepts(located at lower levels) in a taxonomy.In the Information Retrieval (IR) community,browsing taxonomies.
also often called browsinghierarchies or Web directories, has been studiedas an alternative to the ranked list representationfor search results by the Information Retrieval (IR)community.
The proposed forms of browsing struc-tures include topic clusters (Cutting et al, 1992)and monothetic concept hierarchies (Sanderson andCroft, 1999; Lawrie et al, 2001; Kummamuru et al,2004; Carpineto et al, 2009).
The latter uses singleconcepts to represent documents containing themand organizes the concepts into hierarchies; they arein fact taxonomies.
The major drawback of theseapproaches is that they often fail to produce mean-ingful taxonomic structures due to neglecting thesemantics among concepts.
For instance, (Sander-son and Croft, 1999) used document frequency and(Lawrie et al, 2001) used conditional probability toderive is-a relations.
Moreover, they also suffer frompath inconsistency when building full taxonomies.3 Browsing Taxonomy ConstructionTo build browsing taxonomy for a document collec-tion, the first step is to extract the concepts.
We takea simple but effective approach.
We exhaustively ex-amine the collection and output a large set of terms,formed by nouns, noun phrases, and named entitiesoccurring >5 times in the collection.
We then fil-ter out invalid terms due to part-of-speech errors ormisspelling by removing terms that occur <4 timesout of the top 10 returned snippets when submittingthe term to google.com as a search query.
We fur-ther conflate similar terms into clusters using LSA(Bellegarda et al, 1996) and select the most frequentterms as concepts from each term group.
We selecttheN most frequent concepts to form the concept setC.
N usually ranges from 30 to 100.
We assume thatC contains all concepts in the browsing taxonomy;21even when an important concept for the collection ismissing, we will ?make do?
with C. This may leadto some errors, but can be later corrected by usersthrough proposing new concepts interactively (Sec-tion 4).This section presents how to automatically buildtaxonomies.
We introduce the semantic distancelearning method in Section 3.1 and present how toachieve path consistency control in Section 3.2.3.1 Semantic Distance LearningTo support browsing in arbitrary collections, in thispaper, we propose to incorporate task specificationin a taxonomy.
One way to achieve it is to definetask-specific distances among concepts.
Moreover,through controlling distance scores among concepts,we can enforce path consistency in taxonomies.
Forexample, when the distance between financial in-stitute and river bank is big, the path financialinstitute?bank?river bank will be pruned and theconcepts will be repositioned.
Inspired by ME, wetake a distance learning approach to deal with pathconsistency (Section 3) and task specification (Sec-tion 4) in taxonomy construction.
In this section,we demonstrate how to estimate semantic distancesfrom training data.We assume that there are some underlying fea-ture functions that measure semantic dissimilarityfor two concepts from various aspects and a goodsemantic distance is a combination of all features.Different fromME, we model the semantic distancebetween concepts (cx, cy) as a Mahalanobis distance(Mahalanobis, 1936):dcx,cy =??
(cx, cy)TW?1?
(cx, xy) (1)dcx,cy =??
(cx, cy)TW?1?
(cx, xy), where?
(cx, cy) represents the set of pairwise underlyingfeature functions, where each feature function is?k : (cx, cy) with k=1,...,|?|.
W is a weight ma-trix, whose diagonal values weigh the underlyingfeature functions.
When only diagonal values of Ware taken into account, W is equivalent to assigningweights to different axes in the random vectors.Note that a semantic distance is still a distancemetric.
One important characteristic of a valid dis-tance metric is that it must represent valid cluster-ing partitions, which means that the clustering parti-tions represented by the distance metric should beconsistent.
Therefore, certain constraints need tobe satisfied.
An obvious one is that concepts inthe same cluster should have smaller distance scoresthan those in different clusters.
Moreover, a validdistance metric should be non-negative and satisfythe triangle inequality.
To ensure such regularities,we need to constrain W to be positive semi-definite(PSD) (Bhatia, 2006):W  0.Since we assume that a good semantic distance isa combination of all these features, we can decom-pose the task of semantic distance learning into twosubtasks - identifying good features and learning theweight matrix from training data.In our approach, we employ a wide range of fea-tures to cover various aspects in measuring dissimi-larity between concepts.
Given two concepts cx andcy, a feature is defined as a function ?
: (cx, cy) en-erating a value within [0,1].
In total, we used 31features, including lexical-syntactic patterns, con-textual, co-occurrence, syntactic dependency, anddefinitions.Similar to the linguistic approaches, we uselexical-syntactic patterns to evaluate relationsamong concepts.
Our patterns include hypernympatterns such as ?cx, and other cy?, sibling patternssuch as ?cx and cy?, and part-of patterns such as ?cxconsists of cy?.
Each feature returns a boolean valueof wether it can find instances for the pattern in text.Besides patterns, we used more semantic features.For example, since word meanings can be inferredfrom and represented by contexts, we develop sev-eral contextual features.
One is Local Context KL-Divergence, which measures the Kullback-Leiblerdivergence between two unigram language modelsbuilt for cx and cy upon all left two and right twowords surrounding them.
Moreover, we formulatethe co-occurrence features as point-wise mutual in-formation between (cx, cy):pmi(cx, cy) = logCount(cx, cy)Count(cx)Count(cy),where Count(.)
is defined as the number of docu-ments or sentences containing the concept(s), or nas in ?Results 1-10 of about n for term?
appearing22on the first page of Google search results for query-ing cx, cy, or cxcy.We also generate syntactic dependency featuresvia syntactic parse1 and semantic role labeling2.
Forexample, we measure how many overlaps exist be-tween cx?s and cy?s modifiers.
Lastly, we measuredefinition overlaps between cx and cy by countingthe number of nonstop word overlaps between theirdefinitions obtained by querying google.com with?define:cx?
and ?define:cy?.To achieve a comprehensive distance measure forconcepts, we propose to effectively combine thesefeatures.
Our goal is to find a parametric distancemetric functions which allows combining variousfeatures and assigning different weights for them.It also needs to produce distances that satisfy non-negativity and triangle inequality.We further estimateW by minimizing the squarederrors between the semantic distances d generatedfrom the training data and the expected value d?.Moreover, we constrain W to be PSD.
The parame-ter estimation is:minW|C|?x=1|C|?y=1(dcx,cy ???
(cx, cy)TW?1?
(cx, cy))2(2)subject to W  0.
The optimization can be doneby any standard semi-definite programming (SDP)solver.
We used (Sedumi, 2011) and (Yalmip, 2011)to perform the optimization.In our framework, the major source of trainingdata is user feedback.
Another source is existinghierarchies such as WordNet (Fellbaum, 1998) andODP (ODP, 2011) (Section 3).
Nonetheless, we ob-tain the semantic distance for a concept pair (cx, cy)in training data by summing up edge weights alongthe shortest path from cx to cy in a training hierar-chy.
The edge weight can be assigned based on thetypes of relations that an edge represent as in Section4.1.The learned model W can be used to predict dis-tance scores for testing concept pairs by applyingEq.
1 on them.1Done by Minipar: http://www.cs.ualberta.ca/lindek/minipar.htm.2Done by Assert: http://cemantix.org/assert/.3.2 Resolving Path InconsistencyWith the pair-wise semantic distances, we are readyto build the full taxonomy.
As in ME, we also takean incremental taxonomy construction framework,where concepts are inserted one at a time.
Partic-ularly, we propose that at each insertion, a conceptcz is tried as either a parent or a child concept to allexisting nodes in the current partial taxonomy Tn.The evaluation of the best position depends on thesemantic distances between cz and all other conceptsin the taxonomy.To enforce consistency along a path from the rootto a leaf in a taxonomy, we propose to require allconcepts on the path to be about the same topic.They need to be coherent no matter how far awaytwo concepts are apart in this path.
We achieve thisby enforcing the sum of semantic distances in a pathto be as small as possible.
Particularly, when a newconcept cz is added into a taxonomy T , we requirethat the optimal root-to-leaf path P?
containing cxshould satisfy the following condition:P?cz = arg minP ?cz?cx,cy?P ?cz ,x<yd(cx, cy) (3)where Pcz is a root-to-leaf path including cz , x < ydefines the order of the concepts so we only computea pair-wise distance between two concepts once.To incorporate path consistency into taxonomyconstruction, we introduce a variable ?
?
[0, 1] tocontrol the contributions from overall semantic dis-tance minimization (as in ME) and path distanceminimization.
We formulate the optimization as:min?u+ (1?
?
)v (4)subject to u = |?cx,cy?Cn?
{cz},x<y d(cx, cy) ?
?cx,cy?Cn,x<y d(cx, cy)|, v =?cj ,ck?P ?cz ,j<kd(cj , ck), 0 ?
?
?
1, where udenotes ?minimization of overall semantic dis-tance?, v denotes the ?path consistency?, and Cn isthe concept set for the nth partial taxonomy.4 Resolving Task SpecificationGive an arbitrary document collection and its con-cept set C, most concepts can be organized nicelyaccording to the automatic algorithm proposed inSection 3.
However, for concepts with multiple per-spectives, we need to decide which perspective the23task wants to keep in the browsing taxonomy.
More-over, Section 3 learns distance functions from Word-Net and ODP, which suggests that the algorithm willroughly follow how WordNet and ODP define rela-tions.
In practice, a task may require completely dif-ferent organizations, e.g., by question-answer pairsor by topics.
The ever-changing task specificationscan only be captured by the user/constructor who ad-justs a browsing taxonomy to suit the requirements.This section studies how to incorporate task spec-ifications in the taxonomy construction.
Particularly,how to allow the machine learning algorithm to learnfrom the user, and how to produce a task-specificbrowsing taxonomy according to the user?s guid-ance.
The framework is expected to produce tax-onomies that reflect personal preferences as a con-sequence of learning from manual guidance.We present a general framework that enables tax-onomy construction taking into account user-definedconcept organization.
Basically, to guide how to or-ganize the concepts, a user trains the supervised dis-tance learning model using a taxonomy constructiontool that supports editing functions such as draggingand dropping, adding, deleting, and renaming nodesthat allows the user to intuitively modify a taxon-omy.Particularly, an initial taxonomy is constructedby the automatic taxonomy construction frameworkpresented in Section 3.
Starting from the initial tax-onomy, a user can teach the machine learning algo-rithm by providing manual guidance to it.
The algo-rithm learns from the manual guidance and adjuststhe distance learning function and modifies the tax-onomy accordingly.
When a user put cx under cy, itindicates that the user wants a relation demonstratedby cx ?
cy to be true in this taxonomy.
We cap-ture the user inputs as manual guidance and makeuse of it to adjust the distance learning model to or-ganize other concepts agreeing with the user.
Theteaching and the learning alternate until the user issatisfied with the taxonomy.
The resulting taxonomycontains both the user?s inputs and the machine?s ad-justed organization for the concepts.4.1 Collecting and Learning from ManualGuidanceThe most challenging part of incorporating manualguidance in the machine learning process is how totranslate it into a format that the machine can easilyunderstand and incorporate into its learning models.In this research, browsing taxonomies are tree struc-tures.
Trees.
however, are not straightforward fora machine learning algorithm to manipulate.
In or-der to capture the changes between each version ofthe manual editions, the learning algorithm needsboth the training and the test data to be in a for-mat which is easy to handle.
Matrix representationcan be easily understood and manipulated by manymachine learning algorithms.
We therefore converttaxonomies from trees to matrices and use a matrixrepresentation for all the intermediate editions in thetaxonomy construction process.We propose to convert a taxonomy from a tree tomatrices of neighboring nodes and represent the dif-ferences in matrices before and after human edits asmanual guidance.
We then train the learning frame-work to adjust to it and make predictions for unor-ganized concepts.We represent the organization of concepts beforea user?s modifications as a before matrix; likewise,the new organization of concepts after her modifica-tions is represented as a after matrix.
Given thesetwo matrixes, manual guidance is a submatrix in af-ter matrix that shows the differences between beforematrix and after matrix.We compare the before matrix A and the after ma-trix B to derive the manual guidance M. The man-ual guidance is not simply the matrix difference be-tween the before matrix and the after hierarchy ma-trix.
It is part of the after matrix because it is theafter matrix that indicates where the user wants thetaxonomy to develop.
We define manual guidanceM as a submatrix which consists of some entries ofthe after matrix B; at these entries, there exist dif-ferences between the before matrix A and the aftermatrix B.For simple cases when the set of concepts re-main unchanged before and after human modifica-tions, the above definition and calculation of manualguidance work.
However, oftentimes the user adds,deletes or renames concepts, and the concept setchanges.
When the concept set changes, the abovedefinition of manual guidance M needs a slight al-teration.Figure 1 shows an example taxonomy whose con-cept set changes.
The original concept set before24Figure 1: A taxonomy before and after human modifica-tions (concept set changes; relation type = sibling).the human modification is {person, leader, presi-dent, Hu, Obama}.
The taxonomy?s before matrixA is:A =person leader president Hu Obamaperson 1 0 0 0 0leader 0 1 1 0 0president 0 1 1 0 0Hu 0 0 0 1 0Obama 0 0 0 0 1.The user modifies the taxonomy at several places.In particular, leader is deleted, Hu is moved to beunder president, and prime minister is inserted as anew concept into this taxonomy.
Therefore the con-cept set changes to {person, president, Hu, Obama,prime minister}.
The after matrix B is:B =person president Hu Obama PMperson 1 0 0 0 0president 0 1 0 0 1Hu 0 0 1 1 0Obama 0 0 1 1 0PM 0 1 0 0 1.Since the concept sets before and after the humanmodifications change, we cannot simply use matrixsubtraction to get the difference between the beforeand after matrices.
Suppose the concept set in thetaxonomy before the modifications is CA, and theconcept set after modifications is CB , we define anexpanded set of concepts CE as the union of CA andCB .For taxonomies with concept changes, we definethe manual We then define manual guidance M as asubmatrix which consists of some entries of the af-ter matrix B; at these entries, there exist differencesfrom the expanded before matrix A?
to the expandedafter matrix B?.
The expanded rows and columns inA?
and B?
are filled with 0 for non-diagonal entries,and 1 for diagonal entries.
Note that the conceptscorresponding to these entries should exist in CB ,the unexpanded set of concepts after human modifi-cations.
Formally,M = B[r; c]where r = {i : bij ?
aij 6= 0, ci ?
CB}, c = {j :bij ?
aij 6= 0, cj ?
CB}, aij is the (i, j)th entry inA?, and bij is the (i, j)th entry in B?.For the example in Figure 1, the manual guidanceM is:M = B[2, 3, 4, 5; 2, 3, 4, 5] =?
?1 0 0 10 1 1 00 1 1 01 0 0 1??
.Based on M , we can create training data D =1 ?
M , for the supervised distance learning algo-rithm, which aims to learn a good model which bestpreserves the regularity defined by the task and theuser using the techniques proposed in Section 3.1.5 EvaluationTo evaluate the effectiveness of our approach, Weconducted two user studies, one to evaluate brows-ing effectiveness and another to evaluate quality oftaxonomies.
Five users (graduate students and rela-tives of the authors) in the first study were asked toconstruct browsing taxonomies with a task in mind- ?writing a survey paper about the collection?.In the second study (24 graduates and undergrad-uates), we compared taxonomies constructed by dif-ferent users to identify where mixed perspectives intaxonomies come from in Section 5.3.
We also in-vestigated whether the differences are due to self-inconsistency in Section 5.4.
Moreover, we manu-ally select relations violating path consistency andreport our approach?s ability to handle path consis-tency in Section 5.2.5.1 DatasetsTo show that task-specific taxonomies are more suit-able for browsing than general taxonomies, we com-pared excerpts of the official North America Indus-try Classification Systems (we call them NAICS-250?0.1?0.2?0.3?0.4?0.5?0.6?0.7?0.8?0.9?1?NAICS-??2?
Web?Path?Error?w/?path?consistency?w/o?path?consistency?Figure 2: Path error w/ and w/o path consistency control.1) with comparable taxonomies derived by tech-niques presented in this paper (we call them NAICS-2).
Since the original collection used to build of-ficial NAICS taxonomies is not available, we cre-ated document collections by crawling search resultsfrom google.com for concepts in NAICS-1 excerpts.The participants worked on the collection to createNAICS-2 taxonomies.
Each NAICS-1 or NAICS-2taxonomy contains about 40 concepts.We also evaluate our techniques on Web searchresult organization.
Five Web datasets were createdby submitting 4 to 5 queries3 to and collecting thereturned Web documents from search engines Bingand Google.
Around 100 Web documents and 40concepts are collected for a topic.
We manuallyjudged relevant documents for each topic.5.2 Path ConsistencyTo evaluate how well our method can handle pathinconsistency, we compare the path error rate beforeand after applying path consistency control.
Theevaluation is only conducted for the automated algo-rithm (Section 3) on the NAICS-2 and Web datasets.No user study is involved.Two human assessors manually evaluated the patherrors4 in a taxonomy by the following procedure:(1) Starting from the root concept, perform a depth-first traverse in the taxonomy; (2) along each path,count the number of wrong ancestor-descendantpairs due to word sense ambiguity or mixed perspec-tives; (3) sum up the errors that both assessors agreeand normalize them by the taxonomy size.
Notethat path errors are evaluated for concepts are notimmediately connected, whereas differences due tomixed perspectives (Section 5.3) refer to immediaterelations.
Figure 2 shows that with path consistency3E.g., queries ?trip to DC?, ?Washington DC?, ?DC?, and?Washington?
were submitted for the topic ?plan a trip to DC?.4Other types of errors were ignored in the assessment.0 100 200 30005101520InformationNumber of concept pairsNumber of agreements0 100 200 30005101520KindergartenNumber of concept pairsNumber of agreementsFigure 3: Agreements among participants for the parent-child pairs for datasets information and kindergarten.control, we can statistically significantly reduce patherrors due to word sense ambiguity and mixed per-spectives by 500% (p-value<.001, t-test).
It stronglyindicates that our technique to control path inconsis-tency in taxonomy construction is effective.5.3 Mixed Perspectives in TaxonomiesTo better understand mixed perspectives in tax-onomies constructed, we look for commonality anddifferences among the taxonomies constructed bythe 24 participants for the same topic in the seconduser study.
We break each taxonomy into parent-child pairs, and count how many participants agreedon a pair.
The agreements range from 1 to 24.
Thetaxonomies we examined are NAICS-2 and Web.We plot the number of agreements for every con-cept pair and observe a long-tail power-law distri-bution for all datasets.
Figure 3 shows that forthe dataset ?information?, which contains about 300unique concept pairs, while in ?kindergarten?, morethan 200 unique concept pairs exist.
This suggeststhat people use rich and diverse expressions to con-struct taxonomies and organize information differ-ently within them.
Although commonality (can be ashigh as 24 out of 24) and differences co-exist in tax-onomies created for the same topic, the differencesare much more dominate than the commonality.We manually break down the types of differ-ences in producing parent-child pairs into the fol-lowing categories: mixed parents (a concept hasdifferent parent concepts due to word sense ambi-guity), mixed ancestors (a concept is assigned tograndparents, not the direct parent), mixed relationtypes (a pair show relations other than is-a, such aspart-of and affiliation), new concepts (participantsadd new concepts), morphological differences (plu-rals, -tion, etc), errors (clearly wrong relations, e.g.,26mixed?parents?23%?mixed?ancesters?10%?flat?structure?13%?mixed?rela?n?types?17%?morphological??13%?new?concepts?18%?errors?5%?
typo?1%?Figure 4: Sources of differences in NAICS-2 and Web.infant?school director), flat structure (some partic-ipants liked to assign a large portion of concepts aschildren to the root), and typo.Figure 4 illustrates the break-down of varioustypes of differences.
Mixed parents is the largestcontributor with 23% share, followed by new con-cepts (18%) and mixed relation types (17%).
Amongall the types, mixed parents, new concepts, andmixed relation types indicate mixed perspectives orword sense ambiguity; in total they contribute about58% differences in taxonomies.
Flat structure andmixed ancestors are about confusions in taxonomytopology, which contribute about 23% differences.Other differences due to morphological changes, ty-pos and errors contribute about 19% differences.The break-down reveals that mixed perspective, oneof main foci in this paper, is indeed the biggestsource of difference in taxonomy construction.5.4 Self-agreementAnother doubt is that maybe the differences comefrom randomness?
To find out if the variationsamong taxonomies is due to randomness, we de-signed a repeat phase in the second user study.
Werandomly invited 12 participants to repeat the sametasks in the same order 3 weeks5 after the initialphase and compare the taxonomies constructed inboth phases for the NAICS-2 and Web datasets.We use Fragment-Based Similarity (FBS) pro-posed by (Yang, 2011) to calculate the similaritybetween taxonomies constructed in the initial phaseand in the repeat phase by the same participant.FBS for two taxonomies Ti and Tj is calculated as:FBS(Ti, Tj) = 1max(U,V )?mp=1 simcos(tip, tjp),where U and V is the number of concepts in Tiand Tj respectively, m is the number of matched5The three week period ensured that participants only hadlimited memory of the details about the tasks.Self agreement (in FBS) Max Min Averageper participant per dataset 1 0.37 0.74per participant 0.81 0.63 0.74per dataset 0.95 0.62 0.74Table 1: Self-agreement; measured in FBS.pairs based on the highest cosine similarity, simcosis the cosine similarity between vectors for subtreesof concepts tip and tjp.Table 1 indicate the self-agreement between tax-onomies for any participant and/or any topic.
Themax self-agreement is as high as 1.
The averageself-agreement is 0.74, which is high at the range ofFBS.
It suggests that the participants are quite self-consistent when constructing taxonomies at differ-ent times.
It builds the foundation for our study onmultiple perspectives in taxonomy construction.6 ConclusionThis paper explores techniques to quickly derivetask-specific taxonomies supporting browsing in ar-bitrary document sets.
It addresses two issues in tax-onomy construction: path inconsistency due to wordsense ambiguity and mixed perspectives, and taskspecifications in arbitrary collections.
We tackleboth issues in a supervised distance learning frame-work via minimizing distances along a path and us-ing user inputs as training data, respectively.
Theuser studies strongly suggest that the proposed tech-niques are highly effective in constructing browsingtaxonomies as well as handling path consistency.ReferencesJ.
R. Bellegarda, J. W. Butzberger, Yen-Lu Chow, N. B.Coccaro, and D. Naik.
1996.
A novel word clusteringalgorithm based on latent semantic analysis.
In Pro-ceedings of the Acoustics, Speech, and Signal Process-ing, 1996. on Conference Proceedings., 1996 IEEEInternational Conference - Volume 01, ICASSP ?96,pages 172?175, Washington, DC, USA.
IEEE Com-puter Society.Matthew Berland and Eugene Charniak.
1999.
Findingparts in very large corpora.
In Proceedings of the 27thAnnual Meeting for the Association for ComputationalLinguistics (ACL 1999).Rajendra Bhatia.
2006.
Positive definite matrices(princeton series in applied mathematics).
PrincetonUniversity Press, December.27Claudio Carpineto, Stefano Mizzaro, Giovanni Romano,and Matteo Snidero.
2009.
Mobile information re-trieval with search results clustering: Prototypes andevaluations.
Journal of American Society for Informa-tion Science and Technology (JASIST), pages 877?895.Duen Horng Chau, Aniket Kittur, Jason I. Hong, andChristos Faloutsos.
2011.
Apolo: making sense oflarge network data by combining rich user interactionand machine learning.
In CHI, pages 167?176.Gouglass R. Cutting, David R. Karger, Jan R. Petersen,and John W. Tukey.
1992.
Scatter/Gather: A cluster-based approach to browsing large document collec-tions.
In Proceedings of the fifteenth Annual ACMConference on Research and Development in Informa-tion Retrieval (SIGIR 1992).Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland,Daniel S. Weld, and Alexander Yates.
2005.
Unsu-pervised named-entity extraction from the web: an ex-perimental study.
In Artificial Intelligence, 165(1):91-134, June.Christiane Fellbaum.
1998.
WordNet: an electronic lexi-cal database.
MIT Press.Roxana Girju, Adriana Badulescu, and Dan Moldovan.2003.
Learning semantic constraints for the automaticdiscovery of part-whole relations.
In Proceedings ofthe Human Language Technology Conference/AnnualConference of the North American Chapter of the As-sociation for Computational Linguistics (HLT/NAACL2003).Marti A. Hearst.
1992.
Automatic acquisition of hy-ponyms from large text corpora.
In Proceedings ofthe 14th International Conference on ComputationalLinguistics (COLING 1992).Zornitsa Kozareva and Eduard Hovy.
2010.
A semi-supervised method to learn and construct taxonomiesusing the web.
In Proceedings of the 2010 Conferenceon Empirical Methods in Natural Language Process-ing, pages 1110?1118, Cambridge, MA, October.
As-sociation for Computational Linguistics.Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008.Semantic class learning from the web with hyponympattern linkage graphs.
In Proceedings of the 46th An-nual Meeting for the Association for ComputationalLinguistics (ACL 2008).Krishna Kummamuru, Rohit Lotlikar, Shourya Roy,Karan Singal, and Raghu Krishnapuram.
2004.
A hi-erarchical monothetic document clustering algorithmfor summarization and browsing search results.
Pro-ceedings of the 13th conference on World Wide WebWWW 04, page 658.Dawn Lawrie, W. Bruce Croft, and Arnold Rosenberg.2001.
Finding topic words for hierarchical summa-rization.
In Proceedings of the 24th Annual ACM Con-ference on Research and Development in InformationRetrieval (SIGIR 2001), pages 349?357.LCSH.
2011.
Library of congress subject headings.http://www.loc.gov/.P.
C. Mahalanobis.
1936.
On the generalised distance instatistics.
In Proceedings of the National Institute ofSciences of India 2 (1): 495.ODP.
2011.
Open directory project.
http://www.dmoz.org/.Patrick Pantel and Marco Pennacchiotti.
2006.
Espresso:Leveraging generic patterns for automatically harvest-ing semantic relations.
In Proceedings of the 44th An-nual Meeting for the Association for ComputationalLinguistics (ACL 2006).Deepak Ravichandran and Eduard Hovy.
2002.
Learningsurface text patterns for a question answering system.In Proceedings of the 40th Annual Meeting for the As-sociation for Computational Linguistics (ACL 2002).Mark Sanderson and W. Bruce Croft.
1999.
Derivingconcept hierarchies from text.
In Proceedings of the22nd Annual International ACM SIGIR Conference onResearch and Development in Information Retrieval(SIGIR 1999).Sedumi.
2011. http://sedumi.mcmaster.ca.Rion Snow, Daniel Jurafsky, and Andrew Y. Ng.
2006.Semantic taxonomy induction from heterogenous evi-dence.
In Proceedings of the 21st International Con-ference on Computational Linguistics and 44th AnnualMeeting of the Association for Computational Linguis-tics (ACL/COLING 2006).Yalmip.
2011. http://users.isy.liu.se/johanl/yalmip.Hui Yang and Jamie Callan.
2009.
A metric-basedframework for automatic taxonomy induction.
In Pro-ceedings of the 47th Annual Meeting for the Associa-tion for Computational Linguistics (ACL 2009).Hui Yang.
2011.
Personalized Concept HierarchyConstruction.
Ph.D. thesis, Carnegie Mellon Univer-sity.
http://www.cs.cmu.edu/?huiyang/publication/dissertation.pdf.28
