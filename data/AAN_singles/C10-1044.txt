Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 385?393,Beijing, August 2010Comparing Language Similarity across Geneticand Typologically-Based GroupingsRyan GeorgiUniversity of Washingtonrgeorgi@uw.eduFei XiaUniversity of Washingtonfxia@uw.eduWilliam LewisMicrosoft Researchwilewis@microsoft.comAbstractRecent studies have shown the poten-tial benefits of leveraging resources forresource-rich languages to build tools forsimilar, but resource-poor languages.
Weexamine what constitutes ?similarity?
bycomparing traditional phylogenetic lan-guage groups, which are motivated largelyby genetic relationships, with languagegroupings formed by clustering methodsusing typological features only.
Usingdata from the World Atlas of LanguageStructures (WALS), our preliminary ex-periments show that typologically-basedclusters look quite different from geneticgroups, but perform as good or betterwhen used to predict feature values ofmember languages.1 IntroductionWhile there are more than six thousand languagesin the world, only a small portion of these lan-guages have received substantial attention in thefield of NLP.
With the increase in use of data-driven methods, languages with few or no elec-tronic resources have been difficult to process withcurrent methods.
The morphological tagging ofRussian using Czech resources as done by (Hanaet al, 2004) shows the potential benefit for usingthe resources of resource-rich languages to boot-strap NLP tools for related languages.
Projectingsyntactic structures across languages (Yarowskyand Ngai, 2001; Xia and Lewis, 2007) is anotherpossible way to harness existing tools, thoughsuch projection is more reliable among languageswith similar syntax.Studies such as these show the possible bene-fits of working with similar languages.
A crucialquestion is how we should define similarity be-tween languages.
While genetically related lan-guages tend to have similar typological featuresas they could inherit the features from their com-mon ancestor, they could also differ a lot due tolanguage change over time.
On the other hand,languages with no common ancestor could sharemany features due to language contact and otherfactors.It is worth noting that the goals of historical lin-guistics differ from those of language typology inthat while historical linguistics focuses primarilyon diachronic language change, typology is morefocused on a synchronic survey of features foundin the world?s languages: what typological fea-tures exist, where they are found, and why a lan-guage has a feature.These differences between the concepts of ge-netic relatedness and language similarities lead usto the following questions:Q1.
If we cluster languages based only on theirtypological features, how do the inducedclusters compare to phylogenetic groupings?Q2.
How well do induced clusters and geneticfamilies perform in predicting values for ty-pological features?Q3.
What typological features tend to stay thesame within language families, and what fea-tures are likely to differ?These questions are the focus of this study,and for the experiments, we use information fromWorld Atlas of Language Structures (Haspelmathet al, 2005), or WALS.385ID# Feature Name Category Feature Values1 Consonant Inventories Phonology (19) {1:Large, 2:Small, 3:Moderately Small, 4:Moderately Large, 5:Average}23 Locus of Marking in the Clause Morphology (10) {1:Head, 2:None, 3:Dependent, 4:Double, 5:Other}30 Number of Genders Nominal Categories (28) {1:Three, 2:None, 3:Two, 4:Four, 5:Five or More}58 Obligatory Possessive Inflection Nominal Syntax (7) {1:Absent, 2:Exists}66 The Perfect Verbal Categories (16) {1:None, 2:Other, 3:From ?finish?
or ?already?, 4:From Possessive}81 Order of Subject, Object and Verb Word Order (17) {1:SVO, 2:SOV, 3:No Dominant Order, 4:VSO, 5:VOS, 6:OVS, 7:OSV}121 Comparative Constructions Simple Clauses (24) {1:Conjoined, 2:Locational, 3:Particle, 4:Exceed}125 Purpose Clauses Complex Sentences (7) {1:Balanced/deranked, 2:Deranked, 3:Balanced}138 Tea Lexicon (10) {1:Other, 2:Derived from Sinitic ?cha?, 3:Derived from Chinese ?te?
}140 Question Particles in Sign Languages Sign Languages (2) {1:None, 2:One, 3:More than one}142 Para-Linguistic Usages of Clicks Other (2) {1:Logical meanings, 2:Affective meanings, 3:Other or none}Table 1: Sample features and their values used in the WALS database.
There are eleven feature cate-gories in WALS, one feature from each is given here.
The numbers in parentheses in the ?Category?column are the total number of features in that category.
Feature values are given with both the integersthat represent them in the database and their description in the form {#:description}.2 WALSThe WALS project consists of a database that cat-alogs linguistic features for over 2,556 languagesin 208 language families, using 142 features in 11different categories.1 Table 1 shows a small sam-ple of features, one feature from each category inWALS.
Listed are the ID number for each exam-ple, the feature category, and the possible valuesfor that feature.WALS as a resource, however, is primarily de-signed for surveying the distribution of particu-lar typological features worldwide, not compar-ing languages.
The authors of WALS compiledtheir data from a wide array of primary sources,but these sources do not always cover the samesets of features or languages.If we conceive of the WALS database as a two-dimensional matrix with languages along one di-mension and features along the other, then only16% of the cells in that matrix are filled.
An emptycell in the matrix means the feature value forthe (language, feature) pair is not-specified (NS).Even well-studied languages could have manyempty cells in WALS, and this kind of data spar-sity presents serious problems to clustering algo-rithms that cannot handle unknown values.
Toaddress the data sparsity problem, we experimentwith different pruning criteria to create a new ma-trix that is reasonably dense for our study.1Our copy of the database was downloaded from http://wals.info in June of 2009 and appears to differslightly from the statistics given on the website at the timeof writing.
Currently, the WALS website reports 2,650 lan-guages, with 141 features in use.2.1 Pruning MethodsAnswering questions Q1?Q3 is difficult if thereare too many empty cells in the data.
Pruning thedata to produce a smaller but denser subset can bedone by one or more of the following methods.Prune Languages by Minimum FeaturesPerhaps the most straightforward method ofpruning is to eliminate languages that fail to con-tain some minimum number of features.
Follow-ing Daume?
(2009), we require languages to have aminimum of 25 features for the whole-world set,or 10 features for comparing across subfamilies.This eliminates many languages that simply donot have enough features to be adequately repre-sented.Prune Features by Minimum CoverageThe values for some features, such as those spe-cific to sign languages, are provided only for avery small number of languages.
Taking this intoaccount, in addition to removing languages with asmall number of features, it is also helpful to re-move features that only cover a small portion oflanguages.
Again we choose the thresholds se-lected by Daume?
(2009) for pruning features thatdo not cover more than 10% of the selected lan-guages in the whole-world set, and 25% in com-parisons across subfamilies.Use a Dense Language FamilyFinally, using a well-studied family with a num-ber of subfamilies can produce data sets with lesssparsity.
When clustering methods are used withthis data, the groups correspond to subfamilies386Data Set Min Features Min Coverage Grouped By # Langs # Groups # Features DensityUnpruned 0 0% Family 2556 208 142 16.0%Whole-World 25 10% Family 735 121 139 39.7%Indo-European 10 25% Subfamily 87 10 64 44.9%Sino-Tibetan 10 25% Subfamily 96 14 64 38.6%Table 2: Data sets and pruning options used for this paper.
Density = |Filled Cells||Total Cells| ?
100rather than families.
In this study, we choose twofamilies: Indo-European and Sino-Tibetan.The resulting data sets after various methods ofpruning can be seen in Table 2.2.2 Features and Feature ValuesBesides dealing with the sparsity of the features,the actual representation of the features in WALSneeds to be taken into account.
As can be seenin Table 1, features are represented with a rangeof discrete integer values.
Some features, suchas #58?Obligatory Possessive Inflection?are es-sentially binary features with values ?Absent?or ?Exists?.
Others, such as #1?ConsonantInventories?appear to be indices along some di-mension related to size, ranging from small tolarge.
Features such as these might conceivablybe viewed as on a continuum where closer dis-tances between values suggests closer relationshipbetween languages.Still other features, such as #81?Order of Sub-ject, Object, and Verb?have multiple values butcannot be clearly be treated using distance mea-sures.
It?s unclear how such a distance would varybetween an SOV language and either VSO or VOSlanguages.BinarizationClustering algorithms use similarity functions,and some functions may simply check whethertwo languages have the same value for a feature.In these cases, no feature binarization is needed.If a clustering algorithm requires each data point(a language in this case) to be presented as a fea-ture vector, features with more than two categori-cal values should be binarized.
We simply treat afeature with k possible values as k binary features.There are other ways to binarize features.
For in-stance, Daume?
(2009) chose one feature value asthe ?canonical?
value and grouped the other val-ues into the second value (personal communica-tion).
We did not use this approach as it is notclear to us which values should be selected as the?canonical?
ones.3 Experimental SetupTo get a picture of how clustering methods com-pare to genetic groupings, we looked at three el-ements: cluster similarity, prediction capability,and feature selection.3.1 ClusteringOur first experiment is designed to address ques-tion Q1: how do induced clusters compare to phy-logenetic groupings?Clustering MethodsFor clustering, two clustering packages wereused.
First, we implemented the k-medoids algo-rithm, a partitional algorithm similar to k-means,but using median instead of mean distance forcluster centers (Estivill-Castro and Yang, 2000).Second, we used a variety of methods fromthe CLUTO (Steinbach et al, 2000) clusteringtoolkit: repeated-bisection (rb), a k-means im-plementation (direct), an agglomerative algo-rithm (agglo) using UPGMA to produce hierar-chical clusters, and bagglo, a variant of agglo,which biases the agglomerative algorithm usingpartitional clusters.Similarity MeasuresFor similarity measures, we used CLUTO?sdefault cosine similarity measure (cos), butalso implemented another similarity mea-sure shared overlap designed to handleempty cells.
Given two languages A andB, shared overlap(A,B) is defined to be# Of Features with Same Values# Features Both Filled Out in WALS .
This measurecan handle language pairs with many emptycells in WALS as it uses only features with cells387a is the number of language pairs found in the same set in both clusterings.b is the number of language pairs found in different sets in C1, and different sets in C2.c is the number of language pairs found in the same set in C1, but in different sets in C2.d is the number of language pairs found in different sets in C1, but the same set in C2.
(a) Variables Used In CalculationsR(C1, C2) =a + ba + b + c + d(b) Rand IndexPrecision(C1, C2) =aa + c(c) Cluster precisionRecall(C1, C2) =aa + d(d) Cluster recallFscore(C1, C2) =2 ?
(Precision ?
Recall)Precision + Recall(e) Cluster f-scoreFigure 1: Formulas for calculating the Rand Index, cluster precision, recall, and f-score of two cluster-ings C1 and C2.
C1 is the system output, C2 is the gold standard.filled out for both languages, and calculates thepercentage of features with the same values.3.2 Clustering Performance MetricsTo measure clustering performance, we treat thegenetic families specified in WALS as the goldstandard, although we are not strictly aiming torecreate them.Rand IndexThe Rand Index (Rand, 1971) is one of thestandard metrics for evaluating clustering results.It compares pairwise assignments of data pointsacross two clusterings.
For every pair of pointsthere are four possibilities, as given in Figure 1.The Rand index is calculated by dividing the num-ber of matching pairs (a+ b) by the number of allpairs.
This results in a number between 0 and 1where 1 represents an identical clustering.
Unfor-tunately, as noted by (Daume?
and Marcu, 2005),the Rand Index tends to give disproportionatelygreater scores to clusterings with a greater num-ber of clusters.
For example, the Rand Index willalways be 1.0 when each data point belongs to itsown cluster.
As a result, we have chosen to cal-culate metrics other than the Rand index: clusterprecision, recall, and f-score.Cluster Precision, Recall, and F-ScoreExtending the notation in Figure 1, precisionis defined as the proportion of same-set pairs inthe target cluster C1 that are correctly identifiedas being in the same set in the gold cluster C2,while recall is the proportion of all same-set pairsin the gold cluster C2 that are identified in the tar-get cluster C1.
F-score is calculated as the usualharmonic mean of precision and recall.
As it givesa more accurate representation of cluster similar-ity across varying amounts of clusters, we will re-port cluster similarity using cluster F-score.3.3 Prediction AccuracyOur second experiment was to answer the ques-tion posed in Q2: how do induced clusters andgenetic families compare in predicting the valuesof features for languages in the same group?To answer this question, we measure the accu-racy of the prediction when both types of groupsare used to predict the values of ?empty?
cells.
Weused 90% of the filled cells to build clusters, andthen predicted the values of the remaining 10% offilled cells.
The missing cells are filled with thevalue that occurs the most times among languagesin the same group.
If there are no other languagesin the cluster, or the other languages have no val-ues for this feature, then the cell is filled withthe most common values for that feature acrossall languages in the dataset.
Finally, the accuracyis calculated by comparing these predicted valueswith the actual values in the gold standard.
We run10-fold cross validation and report the average ac-curacy.In addition to the prediction accuracy for eachmethod of producing groupings, we calculate thebaseline result where an empty cell is filled withthe most frequent value for that feature across allthe languages in the training data.3.4 Determining Feature StabilityFinally, we look to answer Q3: what typologicalfeatures tend to stay the same within related fam-ilies?
To find an answer, we look again to pre-diction accuracy.
While prediction accuracy canbe averaged across all features, it can also be bro-ken down feature-by-feature to rank features ac-cording to how accurately they can be predicted388by language families.
Features that can be pre-dicted with high accuracy implies that these fea-tures are more likely to remain stable within a lan-guage family than others.Using prediction accuracies based on the ge-netic families, we rank features according to theiraccuracy and then perform clustering using the topfeatures to determine if the cluster similarity to thegenetic groups increases when using only the sta-ble features.4 Results & Analysis4.1 Cluster SimilarityThe graph in Figure 2(a) shows f-scores of clus-tering methods with the whole-world set.
Noneachieve an f-score greater than 0.15, and mostperform even worse when the number of clustersmatches the number of genetic families or sub-families.
This indicates that the induced clustersbased on typological features are very differentfrom genetic groupings.The question of similarity between these in-duced clusters and the genetic families is howevera separate one from how those clusters perform inpredicting typological feature values.4.2 Prediction AccuracyTo determine the amount of similarity betweenlanguages within clusters, we instead look at pre-diction accuracy across clustering methods andthe genetic groups.
These scores are similar tothose given in Daume?
(2009), though not directlycomparable due to small discrepancies in the sizeof the data set.
As can be seen by the numbersin Table 3 and the graph in 2(b), despite the lackof similarity between clustering methods and thegenetic groups, the clustering methods produceas good or better prediction accuracies.
Further-more, the agglo and bagglo hierarchical clus-tering methods which are favored for producingphylogenetically motivated clusters do indeed re-sult in higher f-score similarity to the genetic clus-ters than the partitional rb and direct methods,but produce poorer prediction-accuracy results.In fact, it is not surprising that some inducedclusters outperform the genetic groupings in pre-diction accuracy, considering that clustering algo-rithms often want to maximize the similarity be-tween languages in the same clusters.
Now thatwe know similarity between languages does notnecessarily mirror language family membership,the next question is what features tend to stay thesame among languages in the same language fam-ilies.4.3 Feature SelectionOur final experiment was to examine the featuresin WALS themselves, and look for features thatappear to vary the least within families, and act asbetter predictors of family membership.In order to do this, we again looked at predic-tion accuracy information on a feature-by-featurebasis.
The results from this experiment are shownin Table 4, which gives a breakdown of how fea-tures rank both individually and by category.Since this table is built upon genetic relation-ships, it is not surprising that the category for?Lexicon?
appears to be the most reliably stablecategory.
As noted in (McMahon, 1994), lexi-cal cognates are often used as good evidence fordetermining a shared ancestry.
We also find thatword order is rather stable within a family.We ran one further experiment where, using theagglo clustering method that provided clustersmost similar to the genetic families previously,only features that showed accuracies above 50%.This eliminated 28 features, leaving 111 higher-scoring features for the whole-world set.
Pruningthe features to use only these selected for their sta-bility within the genetic groupings yielded a verysmall increase in f-score similarity, as can be seenin Figure 3.
Although this increase is small, it sug-gests that more advanced feature selection meth-ods may be able to reveal language features thatare more resistant to language contact and lan-guage change.5 Error AnalysisThere are two main reasons for the differences be-tween induced clusters and genetic groupings.5.1 Language Similarity vs. GeneticRelatednessAs mentioned before, language similarity and ge-netic relatedness are two different concepts.
Simi-389baseline gold rb agglo bagglo direct k-medoids withsimilarity overlapk-medoids withcosine similarityWhole-World-Set (121 Clusters)F-Score 0.087 ?
0.080 0.140 0.119 0.089 0.081 0.088Acc (%) 53.72 63.43 64.33 62.86 61.44 65.47 62.11 63.36Indo-European Subset (10 Clusters)F-Score 0.319 ?
0.365 0.377 0.391 0.355 0.352 0.331Acc (%) 64.27 74.1 71.12 72.26 70.62 74.13 73.36 72.12Sino-Tibetan Subset (14 Clusters)F-Score 0.305 ?
0.224 0.340 0.333 0.220 0.285 0.251Acc (%) 58.08 61.71 63.93 63.74 63.06 65.31 64.55 63.94Table 3: Comparison of clustering algorithms when the number of clusters is set to the same number ofgenetic groupings.
The highest number in each row is in boldface.F-Score0.040.060.080.100.120.140.16Number of Clusters20 40 60 80 100 120 140 160 180 200(a) F-scores of clustering resultsPrediction Accuracy565860626466Number of Clusters20 40 60 80 100 120 140 160 180 200CLUTO-rbCLUTO-agglo CLUTO-baggloCLUTO-directKmedoid-overlap Kmedoid-cosine Gold(b) Prediction accuracyFigure 2: Comparison of the performances of different clustering methods using the whole-world dataset.
The number of groups in the gold standard (i.e., genetic grouping) is shown as a vertical dashedline in 2(a) and 2(b), and the prediction accuracy of the gold standard as a horizontal solid line in 2(b).F-Score0.090.100.110.120.130.140.150.16Number of Clusters20 40 60 80 100 120 140 160 180 200agglo - all featuresagglo - predictive featuresFigure 3: F-scores of the agglo clusteringmethod when using all the features vs. only fea-tures whose prediction accuracy by the geneticgrouping is higher than 50%.lar languages might not be genetically related anddissimilar languages might be genetically related.An example is given in Table 5.
Persian and En-glish are both Indo-European languages, but lookvery different typologically; in contrast, Finnishand English are not genetically related but theylook more similar typologically.
While Englishand Persian are related, they have been diverg-ing in geographically distant areas for thousandsof years.
Thus, the fact that English appears toshare more features with a geographically closerFinnish is expected.5.2 WALS as the DatasetPerhaps the biggest challenge we encounter in thisproject has been the dataset itself.
WALS has cer-tain properties that complicate the task.Data Sparsity and Shared FeaturesWhile the previous example shows unrelatedlanguages can be quite similar typologically, ourclustering methods put two closely related lan-guages, Eastern and Western Armenian, into dif-390Breakdown by Feature Category Breakdown By Feature: Top 10 Breakdown by Feature: Bottom 10Category Accuracy Feature Acc C V Feature Acc C VWhole-World SetLexicon 75.0% (136) M-T Pronouns 94.0% 230 3 (1) Consonant Inventories 32.6% 561 5Word Order 68.6% (18) Absence of Common Consonants 93.7% 565 6 (133) Number of Basic Color Categories 33.3% 119 7Phonology 65.9% (11) Front Rounded Vowels 91.1% 560 4 (23) Locus of Marking in the Clause 33.9% 236 5Complex Sentences 64.0% (73) The Optative 89.6% 319 2 (71) The Prohibitive 34.6% 495 4Nominal Syntax 63.2% (137) N-M Pronouns 87.9% 230 3 (22) Inflectional Synthesis of the Verb 35.1% 145 7Verbal Categories 61.9% (6) Uvular Consonants 85.0% 565 4 (56) Conjunctions and Universal Quantifiers 38.2% 116 3Simple Clauses 60.5% (130) Finger and Hand 84.4% 591 2 (117) Predicative Possession 39.4% 240 5Nominal Categories 59.1% (115) Negative Indefinite Pronouns 84.2% 206 4 (92) Position of Polar Question Particles 40.0% 775 6Morphology 53.9% (19) Presence of Uncommon Consonants 83.0% 565 7 (38) Indefinite Articles 40.4% 473 5Other 41.3% (58) Obligatory Possessive Inflection 81.4% 244 2 (50) Asymmetrical Case-Marking 40.7% 261 6Indo-European SubsetLexicon 86.4% (130) Finger and Hand 100.0% 35 2 (3) Consonant-Vowel Ratio 30.6% 31 5Morphology 83.1% (118) Predicative Adjectives 100.0% 29 3 (92) Position of Polar Question Particles 34.6% 47 6Word Order 79.6% (18) Absence of Common Consonants 100.0% 31 6 (78) Coding of Evidentiality 36.0% 23 6Simple Clauses 76.6% (107) Passive Constructions 100.0% 19 2 (1) Consonant Inventories 42.4% 31 5Nominal Categories 70.4% (88) Order of Demonstrative and Noun 97.2% 66 6 (2) Vowel Quality Inventories 44.4% 31 3Phonology 66.7% (89) Order of Numeral and Noun 95.7% 64 4 (84) Order of Object, Oblique, and Verb 47.8% 20 6Verbal Categories 62.1% (27) Reduplication 95.2% 20 3 (16) Weight Factors in Weight-SensitiveStress Systems51.1% 53 7(7) Glottalized Consonants 93.9% 31 8 (70) The Morphological Imperative 55.3% 53 5(93) Position of Interrogative Phrases in Con-tent Questions93.9% 44 3 (44) Gender Distinctions in Independent Per-sonal Pronouns56.5% 19 6(5) Voicing and Gaps in Plosive Systems 93.8% 31 5 (37) Definite Articles 59.2% 46 5Sino-Tibetan SubsetLexicon 100.0% (130) Finger and Hand 100.0% 8 2 (77) Semantic Distinctions of Evidentiality 9.1% 18 3Word Order 67.7% (82) Order of Subject and Verb 100.0% 99 3 (78) Coding of Evidentiality 17.7% 18 6Morphology 63.8% (119) Nominal and Locational Predication 100.0% 13 2 (4) Voicing in Plosives and Fricatives 20.7% 26 4Simple Clauses 60.9% (86) Order of Genitive and Noun 100.0% 73 3 (1) Consonant Inventories 22.2% 26 5Verbal Categories 60.7% (129) Hand and Arm 100.0% 8 2 (14) Fixed Stress Locations 25.0% 4 7Nominal Categories 55.8% (18) Absence of Common Consonants 100.0% 26 6 (15) Weight-Sensitive Stress 25.0% 4 8Phonology 50.7% (93) Pos.
of Interr.
Phrases in Content Q?s 100.0% 79 3 (38) Indefinite Articles 31.7% 36 5(85) Order of Adposition and Noun Phrase 97.5% 79 5 (120) Zero Copula for Predicate Nominals 37.5% 13 2(95) Relationship b/t Object and Verb and Ad-position and Noun Phrase96.3% 76 5 (2) Vowel Quality Inventories 42.9% 26 3(48) Person Marking on Adpositions 93.3% 14 4 (3) Consonant-Vowel Ratio 46.7% 26 5Table 4: Prediction accuracy figures derived from genetic groupings for each dataset and broken downby WALS feature category and feature.
Ordering is by descending accuracy for the top 10 features,and by increasing accuracy for the bottom 10 features.
The ?C?
and ?V?
columns give the numberof languages in the set that a feature appears in, and the number of possible values for that feature,respectively.ferent clusters.
A quick review shows that the rea-son for this mistake is due to a lack of shared fea-tures in WALS.
Table 6 shows that very few fea-tures are specified for both languages.
The datasparsity problem and the distribution of emptycells adversely affect clustering results.Notice that in this example, the features whosevalues are filled for both languages actually haveidentical feature values.
While using shared over-lap as a similarity measure can capture the simi-larity between these two languages, this measurebiases clustering toward features with fewer cellsfilled out.
The only way out of errors like this, itseems, is to obtain more data.There are a few other typological databasesthat might be drawn upon to define a more com-plete set of data: PHOIBLE, (Moran and Wright,2009), ODIN (Lewis, 2006), and the AUTOTYPdatabase (Nichols and Bickel, 2009).
Using thesedatabases to fill in the gaps in data may be the onlyway to fully address these issues.The Feature Set in WALSThe features in WALS are not systematicallychosen for full typological coverage; rather, thecontributors to WALS decide what features theywant to work on based on their expertise.
Also,some features in WALS overlap; for example, oneWALS feature looks at the order between subject,verb, and object, and another feature checks theorder between verb and object.
As a result, thefeature set in WALS might not be a good represen-tative of the properties of the languages covered inthe database.6 Conclusion & Further WorkBy comparing clusters derived from typologicalfeatures to genetic groups in the world?s lan-guages, we have found two interesting results.First, the induced clusters look very different fromgenetic grouping and this is partly due to the de-sign of WALS.
Second, despite the differences, in-duced clusters show similar, or even greater levels391ID: Feature Name English Finnish Persian2: Vowel Quality Invento-riesLarge (7-14) Large (7-14) Average (5-6)6: Uvular Consonants None None Uvular stops only11: Front Rounded Vow-elsNone High and Mid None27: Reduplication No productive redupli-cationNo productive redupli-cationProductive full and partialreduplication37: Definite Articles Definite word distinctfrom demonstrativeNo definite or indefinitearticleNo definite, but indefinitearticle53: Ordinal Numerals First, second, three-th First, second, three-th First/one-th, two-th,three-th81: Order of Subject, Ob-ject and VerbSVO SVO SOV85: Order of Adpositionand Noun PhrasePrepositions Postpositions Prepositions87: Order of Adjectiveand NounAdjective-Noun Adjective-Noun Noun-Adjective124: ?Want?
ComplementSubjectsSubject left implicit Subject left implicit Subject expressed overtlyNumber of Features 139 135 128Cosine Similarity to Eng 1.00 0.56 0.42Shared Overlap with Eng 1.00 0.56 0.44Table 5: A selection of ten features from English, Finnish, and Persian.
Same feature values in eachrow are in boldface.
Despite the genetic relation between English and Persian, similarity metrics placeEnglish closer to Finnish than Persian.ID# Feature Name Armenian (Eastern) Armenian (Western)1 Consonant Inventories Small ?27 Reduplication Full Reduplication Only Full Reduplication Only33 Coding of Nominal Plurality ?
Plural suffix48 Person Marking on Adj.
None ?81 Order of Subj.
Obj., and V ?
SOV86 Order of Adposition and Noun Phrase Postpositions Postpositions100 Alignment of Verbal Person Marking Accusative ?129 Hand and Arm ?
IdenticalNumber of Features 85 33Cosine Similarity 0.22Shared Overlap 1.00Table 6: Comparison of features between Eastern and Western Armenian.
Same feature values in eachrow are in boldface.
Empty cells are shown as ??
?.of typological similarity than genetic grouping asindicated by the prediction accuracy.While these initial findings are interesting, us-ing WALS as a dataset for this purpose leaves a lotto be desired.
Subsequent work that supplementsthe typological data in WALS with the databasesmentioned in ?5.2 would help alleviate the datasparsity and feature selection problems.Another useful follow-up would be to performapplication-oriented evaluations.
For instance,evaluating the performance of syntactic projectionmethods between languages determined to havesimilar syntactic patterns, or using similar mor-phological induction techniques on morphologi-cally similar languages.
With the developmentof large typological databases such as WALS, wehope to see more studies that take advantage ofresources for resource-rich languages when devel-oping tools for typologically similar, but resource-poor languages.Acknowledgment This work is supported bythe National Science Foundation Grant BCS-0748919.
We would also like to thank Emily Ben-der, Tim Baldwin, and three anonymous reviewersfor helpful comments.392ReferencesDaume?, III, Hal and Daniel Marcu.
2005.
A BayesianModel for Supervised Clustering with the Dirich-let Process Prior.
Journal of Machine Learning Re-search, 6:1551?1577.Daume?, III, Hal.
2009.
Non-Parametric BayesianAreal Linguistics.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics (HLT/NAACL), pages593?601, Boulder, Colorado, June.Estivill-Castro, Vladimir and Jianhua Yang.
2000.A fast and robust general purpose clustering algo-rithm.
In Proc.
of Pacific Rim International Con-ference on Artificial Intelligence, pages 208?218.Springer.Hana, Jiri, Anna Feldman, and Chris Brew.
2004.
AResource-light Approach to Russian Morphology:Tagging Russian using Czech resources.
In Pro-ceedings of EMNLP 2004, Barcelona, Spain.Haspelmath, Martin, Matthew S. Dryer, David Gil, andBernard Comrie.
2005.
The World Atlas of Lan-guage Structures.
Oxford University Press, Oxford,England.Lewis, William D. 2006.
ODIN: A Model for Adapt-ing and Enriching Legacy Infrastructure.
In Pro-ceedings of the e-Humanities Workshop, held in co-operation with e-Science 2006: 2nd IEEE Interna-tional Conference on e-Science and Grid Comput-ing, Amsterdam.McMahon, April M. S. 1994.
Understanding lan-guage change.
Cambridge University Press, Cam-bridge; New York, NY, USA.Moran, Steven and Richard Wright.
2009.
PhoneticsInformation Base and Lexicon (PHOIBLE).
Online:http://phoible.org.Nichols, Johanna and Balthasar Bickel.
2009.The AUTOTYP genealogy and geography database:2009 release.
http://www.uni-leipzig.de/?autotyp.Rand, William M. 1971.
Objective criteria for theevaluation of clustering methods.
Journal of theAmerican Statistical Association, 66(336):846?850.Steinbach, Michael, George Karypis, and Vipin Ku-mar.
2000.
A comparison of document clusteringtechniques.
In Proceedings of Workshop at KDD2000 on Text Mining.Xia, Fei and William D. Lewis.
2007.
Multilin-gual structural projection across interlinear text.In Proc.
of the Conference on Human LanguageTechnologies (HLT/NAACL 2007), pages 452?459,Rochester, New York.Yarowsky, David and Grace Ngai.
2001.
Inducingmultilingual pos taggers and np bracketers via ro-bust projection across aligned corpora.
In Proc.
ofthe Second meeting of the North American Chapterof the Association for Computational Linguistics onLanguage technologies (NAACL-2001), pages 1?8,Morristown, NJ, USA.393
