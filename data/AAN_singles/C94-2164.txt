A GRAMMAR AND A PARSER FORSPONTANEOUS SPEECHMikio Nakano, Akira Shimazu, and Kiyoshi KogureNTT Basic Research Laboratories3-1 Morinosato-Wakamiya, Atsugi-shi, Kanagawa, 243-01 Japan{nakano, shiraazu, kogure}~atora.nt'c.jpABSTRACTThis paper classifies distinctive phenomena occur-ring in Japanese spontaneous peech, and proposesa grammar and processing techniques for handlingthem.
Parsers using a grammar for written sentencescannot deal with spontaneous speech because in spon-taneous peech there are phenomena that do not occurin written sentences.
A grammar based on analysis oftranscripts of dialogues was therefore developed.
Ithas two distinctive features: it uses short units asinput units instead of using sentences in grammarsfor written sentences, and it covers utterances includ-ing phrases peculiar to spontaneous speech.
Since thegrammar is an augmentation of a grammar for writ-ten sentences, it can also be used to analyze complexutterances.
Incorporating the grammar into the dis-tributed natural anguage processing model describedelsewhere nables the handling of utterances includ-ing variety of phenomena peculiar to spontaneousspeech.1 INTRODUCTIONMost dialogue understanding studies have focused onthe mental states, plans, and intentions of the par-ticipants (Cohen et al, 1990).
These studies havepresumed that utterances can be analyzed syntacti-cally and semantically and that the representation ofthe speech acts performed by those ntterances canbe obtained.
Spontaneonsly spoken utterances differconsiderably from written sentences, however, so it isnot possible to analyze them syntactically and seman-tically when using a grammar for written sentences.Spontaneous peech, a sequence of spontaneouslyspoken utterances, can be distinguished from well-planned utterances like radio news and movie dia-logues.
Mnch effort has been put into incorporatinggrammatical information into speech mlderstanding(e.g., Hayes et el.
(1986), Young et al (1989), Okada(1991)), but because this work has focused on well-planned utterances, pontaneously spoken utteranceshave received little attention.
This has partly beendue to the lack of a grammar and processing techniquethat can be applied to spontaneous speech.
Conse-quently, to attain an understanding of dialogues it isnecessary to develop a way to analyze spontaneousspeech syntactically and semantically.There are two approaches to developing this kindof analysis method: one is to develop a grammarand analysis method for spontaneous speech that donot depend on syntactic constraints as much as theconventional methods for written sentences do (Den,1993), and the other is to augment he grammar usedfor written sentences and modify the conventionalanalysis method to deal with spontaneous peech.The former method would fail, however, when new in-formation is conveyed in the utterances; that is, whenthe semantic haracteristics of the dialogue topic arenot known to the hearer.
In such cases, even ill adialogue, the syntactic constraints are nsed for un-derstanding utterances.
Because methods that dis-regard syntactic constraints would not work well inthese kinds of cases, we took the latter approach.We analyzed more than a hundred dialogue tran-scripts and classified the distinctive phenomena inspontaneous Japanese speech.
To handle those phe-nomena, we develop a computational model called L'n-semble Model (Shimazu et al, 1993b), in which syn-tactic, semantic, and pragmatic processing modulesand modules that do combination of some or all ofthose processing analyze the input in i)arallel and in-dependently.
Even if some of the modules are unableto analyze the input, the other modules still outputtheir results.
This mode\] can handle various kinds ofirregular expressions, such as case particle omission,inversions, and fragmentary expressions.We also developed Grass-.\] ( GT"ammarfor spontaneous peech in Japanese), which enablesthe syntactic and semantic processing modules of t~heEnsemble Model to deal with some of the phenomenapeculiar to spontaneous speech.
Since G~'ass-.\] is anaugmentation of a grammar used to analyze writtensentences (Grat-J, Gr'ammar for lexts in Japanese),Crass-Y-based parsers can be used for syntacticallycomplex utterances.There are two distinctive features of' G~'ass-J.
Oneis that its focus is on the short units in spontaneousspeech, called utter'auce units.
An utterance uniL in-stead of a sentence as in Gral-J is used as a gram-matical category and is taken as the start symbol.
AGrass-J-based parser takes an utterance unit as in-put and outputs the representation of the speech act(illoeutionary act) performed by the unit.
The otherdistinctive feature is a focus on expressions peculiarto spontaneous speech, and here we explain how toaugment (h'at-J so that it can handle them.
Pre-vious studies of spontaneous speech analysis have fo-cused mainly on repairs and ellipses (Bear et el., 1992;l,anger, 1990; Nakatani & Hirschberg, 1993; Otsuka~; Okada, 1992), rather than expressions peculiar tospontaneous speech.This paper first describes Grat-J, and then classi-ties distinctive phenomena in Japanese spontaneousspeech.
It then describes Grass-Y and presents ev-eral analysis examples.10141.
Subcategorization ruleRule for NP (with particle) -VP constructions.M~CH(M head) = (FI head)(14 subcat) = (M subcat) U (C)(M adjacent) --- nil(H adjacent) = nil(M adjunct} = (kl adjunct}(M lexical) --(M sere index) ~ (H sere index)(M sere restric)= (C sere restric) u (H sere restric)Symbols M, C, and tt are not names of categories butvariables, or identifiers of root nodes in the graphs rep-resenting feature structures.
M, C, and H correspondto mother, complement daughter, and head daughter.The head daughter's subcat feature value is a set offeature structures.2.
Adjacency ruleRule for VP-AUXV constructions, Nf x particle construetioIlS, etc,M-+AH(M head) = {H head)(M subeat} -- (I\] subcat}(U adjacent) = (A)(M adjacent) :- nil(M adjunct) :: (H adjunct}(M lexlcal} - -(M sere index} = (H sere index)(M sem restric}= (A sem restric) U 04 sere restric)M, A, and H correspond to mother, adjacent daughter,and head daughter.
The head daughter's adjacent fea-ture value is unified with the adjacent daughter's featurestrtlcture.3.
Adjunction ruleRule for modifier modifiee constructions.M~AH(M Imad) = (H he)el)(M subcat) = (H subcat)(H adjacent) = nil(A adjunct) = {H)(M lexical) = --(M sere index) -- {H sere index)(M sere restric)= (A sem restric) U (H sem restric)M, A, and H correspond to motlmr, adjunct daughter(modifier), and head daughter (modifiee), Tile adjunctdaughter's adjunct feature value is the feature structurefor the head daughter.Fig.
1: Phrase structure rules in (;rat-.\].2 A GRAMMAR FOi l .
WRITTENSENTENCES(TrM-3, a grammar for writte.n sentences, iv a uni-fication grammar loosely based on Japanese phrasestructure gr~mlnar (JI'SG) (Gunji, 1986).
Of Lhe sixphrase structure rules used in Gral-J, the three relatedto the discussion in the following sections are shOWllin Fig.
1 in a I)A'l'll.d\] like notation (Shieber, 1986))\],exica\] items are.
represented by feature structures,and example of which is shown in Fig.
2.Grat-J-based p~trsers gellerate SOlllalll, iC representa-1 lhtles for relative cirCuses ~tl,d for verb-phr~tse coordi-mttions are not showll here.he~d \[sub<:at {~,lj;t(:ent rill~djun(:t nillexical yesselll \[pus vet b 1infl sentence-final }hea.d llOlIIIc~se g& (NGM)sere \[index *x \]head \[IO1111(:~ts(!
o (A CC,)sere \[ index *y \]index *e J~ \] f (k,ve *e) "1restric { (~tgent *e *x)\[ (p~tient *e *y)Fig.
2: Feature strueture for the word 'aisuru' (low.
).lions in logical ff)rm in l)avidsonian style.
The se-ina.ntic represealtation ill each lexical item eonsisls ofa wu'iable ealled ;m inde,: (feature, (sent index}) ;rodrestrictions i)laced on it, (feature (selll restric)).
Everytime a l)hrase, structure rule is ~q)lflied, lhese restrietions ~tre aggregated and a logical form is synthesized.For exumple, let us ~gain consider 'aisuru' (love).If, in the feature structure for the phr;me 'Taro ga'(Taro-NOM), the (sen, index) value is *p a.nd gl~,,(sere restrie) value is {(taro *p)}, after the subc.at-egorization rule is al)plid the {sere restric) v~due illthe resulting feature str/lcture for the phrase "\['aro gaais.rlC (%,'o 'oves} i~ {(~ro *x) 0ov,, *e) (ag<~t *e*x) (patient *e *y)}.(Trat-,!
cowers such fundamental Jal)~mese l)henom -ena as subcategorizal.ion, passivization, interrogatiou,coordination= and negation, and also covers copulas,relative clauses, and conjunctions.
We developed aparser based on (;rat-,l by using botton>u I) eha.rtpursing (Kay, 1980).
Unification operations are per-formed by using constraint projection, Ul efficientmethod for unifying disjunctive lhature descriptions(Nakano, 1991).
The l)arser is inq)lemented in Lucid(',ommon Lisp ver.
4.0.3 D IST INCT IVE  PHENOMENA IN, IAPANESE SPONTANEOUS SPEECt I3.1 Classif icat ion of Phc ImmenaWe analyzed 97 telephone dialogues (about 300,000bytes) ~d)out using ldli!\]X to pl'epare docunmnts and26 dialogues (about i6(),O00 bytes) obtained fromthree radio lisl;ener call-in programs (Shimctzu et al,1993a).
We found that a.ugmentiltg he gr~:mmlal's audanalysis methods requires taking into acconllL &{, least,the following six phenomena in Japanese spontaneousspeech.
(1)\[) expressions peculiar to Japanese spontaneousspeech, including fillers (or hesitations).(ex.)
'etto aru ndesnkedomo ._ ' 'kono fMru tar _,...' (wel\], we haw'~ thenl.., this file is...)(i)2) ll~rticlc (ease pnrtiete) omission(ex.)
'sore w,u.ashi y'a,'imasu' (I will do it.
)0)3) matin verb ellipsis, or fragmentary ul, l, erances1015(ex.)
'aa, shinkansen de Kyoto kara.'
(uh, fromKyoto by Shinkansen line.
)(p4) repairing phrases(ex.)
'ano chosya be, chosya no arufabetto junni naran da, indekkusu naai?'
(well, are there,aren't there indices ordered alphabetically by au-thors' names?
)(p5) inversion(ex.)
'kopii shire kudasai, sono ronbun.'
(Thatpaper, please copy.
)(p6) semantic mismatch of the theme/subject and themain verb(ex.)
'rikuesuto no uketsnkej ikan wa, 24-jikanjonji uketsuke teori masu.'
(The hours we receiveyour requests, they are received 24 hours a day.
)3.2 T reatment  of  the  Phenomena by  theEnsemble  Mode lThese kinds of phenomena can be handled by the En-semble Model.
As described in Section 1, the En-semble Model has syntactic, semantic, and pragmaticprocessing modnles and modules that; do combinationof some or all of those proeessings to analyze the in-put in parallel and independently.
Their output isunified, and even if some of the modules are unableto analyze the input, the other modules output theirown resnlts.
This makes the Ensemble Model robust.Moreover, even if some of the modules are nnable toanalyze the input in real-time, the others output theirresults in real-time.
'\['he Ensemble Model has been partially imple-mented, and Ensemble/Trio-I consists of syntactic,semantic, and syntactic-semantic modules, it canhandle (p2) above as described in detail elsewhere(Shimazu et al, 1993b).
Phenomena (p3) through(p6) can be partly handled by another implemen-tation of the Ensemble Model: Ensemble/Quartet-1, which has pragmatic processing modnle as well asthe three modules of Ensemble/'lMo-I.
The pragmaticprocessing module uses plan and domain knowledgeto handle not only well-structured sentences bnt alsoil l-structured sentences, uch as those including inversion and omission (Kognre et al, 1994).To make the system more robust by enabling thesyntactic and semantic processing modules to han-dle phenomena (pl) and (p3) through (p6), we in-corporated Grass-g into those modnles.
Grass-J dif-fers fl:om Grat-J in two ways: Grass-J has lexieal en-tries for expressions peculiar to spontaneous speech,so that it can handle (pl).
And because sentenceboundaries are not clear in spontaneous speech, it usestile concept of utterance unit (Shimazu et al, 1993a)instead of sentence.
This allows it to handle phenom-ena (p3) through (p6).
For example, an inverted sen-tence can be handled by decomposing it, at the pointwhere the inversion occurs, into two utterance units.Fig.
3 shown the architecture of Ensemble/Quartet -I.
Each processing module is based on the bottom-up (:hart analysis method (:Kay, 1980) and a disjunc-tive feature description unification method ealled con-straint projection (Nakano, 1991).
The syntactic-.semantic processing module uses Grass-J, the syntac-tic processing module uses Grass-J without seman-tic constraints uch as sortal restriction, the seman-A: 1 anoo kisokenwell the Basic Research Labs.eno ikileala o desu.neto how to go ACC'well, how to go to the Basic Re-search Labs.
'B: 2 halnh-h uh:1111-}1/111'A: 3 eholto shira nai ridewell know NOT because%ecause l don't know well'4 oshie teitadaki tai ndesukedotell IIAV E-A-FAVOR.
want' I 'd like you tell me it'Fig.
4: Dialogue I.tic processing moduh', uses Crass-.)
without syntacticconstraints uch as case information, and the prag-matic processing module uses a plan-based grammar.4 A GRAMMAR,  FOR SPONTANEOUSSPEECH'\['his ection describes Grass-Z4.1 Process ing Uni ts'Sentence' is used as the start symbol in granunarsfor written languages but sentence boundaries are notclear in spontaneous speech.
;Sentence' therefore cannot be used as the start symbol in grammars lbr spon-taneous speech.
Many studies, though, have shownthat utterances are composed of short units (I,evelt,1989: pp.
23-.24), that need not be sentences in writ-ten language.
Grass-3 uses such units instead of sen-tences.Consider, for example, Dialogue 1 in Fig.
4.
Ut-terances 1 and 3 cannot be regarded as sentences inwritten language.
Let us, however, consider 'hal' inUtterance 2.
It expresses participant B's confirma-tion of the contents of Utterance 1.
2 Each utterancein Dialogue 1 can thus be considered to be a speechact (Shimazu et al, 1993a).
These utterances are pro--cessing nulls we call "utlerance units.
They are used inGrass-J instead of the sentences used in Grat-J.
Onefeature of these units is that 'hal' can be.
intel\jectedby the hearer at the end of the unit.The boundaries for these units can be determinedby using pauses, linguistic clues described in the nextsection, syntactic form, and so on.
In using syntactic\[brm to determine utterance unit boundaries, Crass-J first stipulates what an utterance unit actually is.This stipulation is based on an investigation of dia-logue transcripts, and in the current version of Grass-.\], the following syntactic onstituents are recognizedas utterance units.?
verb phrases (including auxiliary verb phrasesand adjective phrases) that may be followed by=The roles of 'hal', ~tn interjectory response correspond-ing to ~ back-channel utterance sueh &s uh-huh in En-glish but which occurs more frequently in Japanese di;>logue, axe discussed in Shimazu et at.
(1993~t) ~tnd I(~tt~tgiri(1993).1016~ed ~ Resu l tFig.
3: Architecture of Ensemble/Quartet-l.conjunctive particles and sentence-final particles?
noml phrases, which may be followed by particles?
interjections?
conjunctionsGrass-J it:chides a bundle of phrase structure rulesused to derive speech act re.presentation from the logi-cal form of these (:onstituents.
A Grass-J-based parserinputs an utterance unit and outputs  the rel)resentt?lion of the speech act performed by the unit, which isthen input to the discourse processing system.Consider the following simple dialogue.A: 1 genkou omanuscript ACC'The manuscript'B: 2 haluh-huh'nh-huh 'A: 3 okut tekudasaisend please'please send hie'The logical form for i)tteranee 1 is ((mannscript *x)),so that its resulting speech act representation is(l) ((r~,ter %) (agent *e *4 (speaker *4 (ol,ject *,,*x) (manuscript *x)):'or, as written in usual notation,(2) l{el>r(speaker, ?x:manuscript(?x)).In the same way, the speech act representation forUtterance 3 is(3) Request(speaker, hearer, send(hearer, speaker,ry))The discourse processor would find that '?x in (2) isthe same as ?y in (3).
A detailed explanation of thisdiscourse processing is beyond the scope of this paper.a'liefer' st~nt(Is for the surface referring in Alien a.ndPerrault (\] 980).4.2 Treatment  of Expressions Pecul iar  toSpontaneous  Slme, ehClassif icationThe underlined words in l)iak)gue 1 in Fig.
d do notnormally appear in writLen sentences, We analyzedthe dialogue transcripts to identify expressions thatkequently appear in spoken sentences which includesspontaneous speech but that do not appear in writtensentences, and we cleLssitied them as follows.1.
words plmnologically dif\[erent Dora those in writ-ten sentences (words in parenthesis are corre-sponding written-sentence words)(ex.)
'shinakya' ('shinakereb?, if someone doesnot do), 'shichau' ('shiteshimatf, have done)2. fillers (or hesitations such as well in l!;nglish)(ex.)
'etto', 'anoo'3.
particles peculiar to spoken langnage(ex.)
'tte', 'nante', %oka'4.
interjectory particles (words inserted interjecto-rily after noun phrases and adverbial/adnominal-form verb phrases)(ex.)
~llel~ Cdesllne~ :sa ~5.
expressions introducing topics(ex.)
'(ila)lldeSllkedo', '(\[la) i|desukedon,(,','(n a) 12 des uga'6.
words appearing after main verb phrases(these words take l;he sentence-final form ofverbs/auxiliary verbs/adjectives)(ex.)
'yo', 'ne', 'yone', 'keredo', 'kedo', ~kere-domo', 'ga', 'kedomo', 'kate'Nagata and Kogure (1990) addressed Jai)anesesentence-final expressions peculiar to spoken J N)anesesentences but (lid not deal with all the spontaneousspeech expressions listed above.
These.
expressionsmay be analyzed morphologica.lly (Takeshita & Fuknnaga, 1991).
Because some expressions peculiar tospontaneous sl)eecb do not affect the propositiomd1017content of the sentences, disregarding those expres-sions might be a way to process spontaneons speech.Such cascaded processing of morphological analysisand syntactic and semantic analysis disables the in-cremental processing required for real-time dialogueunderstanding.
Another approach is to treat thesekinds of expressions as extra, 'noisy' words.
Althoughthis can be done by using a robust parsing technique,such as the one developed by Mellish (1989), it re-quires the sentence to be processed more than twotimes, and is therefore not suitable for real-time dia-logue understanding.
In Grass-J these expressions arehandled in the same way as expressions appearing inwritten language, so no special techniqm~.s are needed.Words  phonolog ica l ly  di f ferent froin corre-sponding words in written-languageThe words 'tern' and 'ndesu' in 'shit tern ndesuka' (do you know that'?)
correspond semantically to'teirn' and 'nodesu' in written sentences.
We investi-gated such words in the dialogue data (Fig.
5).
Oneway to handle these words is to translate them intotheir corresponding written-language words, but be-cause this requires several steps it is not suitable forincremental dialogue processing.
We therefore regardthese words as independent of their correspondingwords in written-language, ven though their lexicalentries have the same content.Fi l lersFillers such as 'anoo' and 'etto', which roughly cor-respond to wellin English, appear fl'equently in sporetaneous peech (Arita et al, 1993) and do not affectthe propositional content of sentences in which theyappear 4.
One way to handle them is to disregard themafter morphological analysis is completed.
As notedabove, however, such an approach is not suitable fordialogue processing.
We therefore treat them directlyin parsing.In Grass-J, fillers modify the following words, what-ever their grammatical categories are.
The featurestructure for fillers is as follows.head \[pos interjection\]su beat { }adjunct \[ lexical +\]adjacent nillexical 4-sem \[ restric {}\]The value of the feature lexicaI is either + or - :  itis + in lexical items and - in feature structures forphrases colnposed, by phrase structure rules, of sub-phrases.
Because these words do not affect proposi-tional contents, the value of the feature (sere restric)is empty.For exalnple, let us look at the parse tree for 'etto400-yen desu' (well, it's 400 yen).
Symbols I (Interjec-tion), NP, and VP are abbreviations for the complexfeature structures.4Although Sadanobu and 'TPakubo (1993) investigatedthe discourse management function of fillers, we do notdiscuss it here.\[.
expressions related to aspectsteku (teiku in written-language), teru (teiru), chau(tesimau), etc.2.
expressions related to topic marker 'wa'cha (tewa), char (tewa), ccha (tewa), .jr (dewa), etc.3.
expressions related to conjnnetive particle 'ha'nakerya (nakereba), nakya (nakereba), etc.4.
expressions related to formal nounsn (no), nmn (nmno), toko (tokoro), etc.5.
demonstrativeskocchi (kochira), korya (korewa), so (son), soshi-tara (soushitara), sokka (souka), socchi (sochira), son(sono), sore.jr (soredewa), sorejaa (soredewa), etc.6.
expressions related to interrogative pronoun naninanka (nanika), nante (nanito), etc.7.
othermokkai (mouikkai), etc.Fig.
5: Words that in spoken language differ fromcorresponding words in written language.VPNP VII N desuretto 400-yen'Phe filler 'etto' modifies the following word '400-yen' and the logical form of the sentence is the sameas that of '400-yen desn'.Part ic les  pecul iar  to spoken languageWords such as 2;te' in 'Kyoto tte Osaka no tsugino eki desu yone' (Kyoto is the station next to Osaka,isn't it?)
work in the same way a~s c~>e-marking/topic-marking particles.
Because they have no correspond-ing words in written language, lexical entries for then,are required.
'\['hese words do not correspond to anyspecific surface case, such as 'ga' and %'.
I,ike t, hetopic marker 'wa', the semanl ic relationships they ex-press depend on the meaning of the phrases they con-nect.In ter jec tory  part ic lesIntmjectory particles, such ~%s 'ne' and 'desune', forlow noun phrases and adverbial/adnominal-form verbphrases, and they do \]lot affect tile meaning of tileutterances.
The intmjeciory particle 'he' differs fromthe sentence-final particle 'ne' in the sense that thelatter follows sentence-final form verb phrases.
Thesekinds of words can be treated by regarding them asparticles Ibllowing noun phrases and verbs phrases.The following is the feature structure for these words.head "1subcat { }adjunct nilad jacent \ [  head* \ ]  \]sere \[ index *2\]lexical +\ [ index "2 \]sem restric { }1018The interjectory particles indicate the end of utte>ante units; they do not appear in the nliddle of utter-ante units.
They flmetion ~us, so to Sl)eak, utterane(>unit-final t)articles.
Therefore, a noun phrase followedby an interjectory particle forms a (surface) referringspeech act in the same.
way as noun phrase utter-ances, hH;er.jectory particles add nothing to logicalforms.
For example, the speech act representation of'genkou o desune' ix the.
same as (2) in Section 4.l.Express ions  in t roduc ing  top icsAs in Uttermtce 4 of l)ialogne 1, an expressionsuch as  (,,a)r, des,,k,~do(,,~o) frequently apl,ears in di-alogues, especially in the beginning.
This expres-sion introduces a new topic.
One way t.o handlean expression such as this is to break it.
down intona + ndesu + kcdo F m.o.
This process, however, prevents the system fronl detecting its role in topic intro-(luction.
We therefore consider each of these expres-sions to be one word.
'l'he reason these expressionare used is to make a topie explicit, by introdncing adiscourse referent ('Phomason, 1990).
Consequently,an 'introduce-topic' speech act is formed.
These ex-l)ressions indicate the en(I of an utterance unit as aninterjectory particle.Words  ap lmar ing  a f te r  ma in  verb  phrase\[t has already been pointed out that; sentence-\[inal|)articles, such as 'yo' and 'ne', Dequently app(:ar inspoken Japanese sentences (Kawamori, 1991).
Con-junctive particles, such as qwAo' and 'kara', are alsoused as sentenee-.final pa.rticle.s (\[h)saka et ah, 1991)and thc'y m:c treated as such in Grass-J.
They performthe function of anticipating the heater's reaction, asa trial cxt)ression does (Clark &.
Wilkes-(\]ibbs, 19!10).
'\]'hey Mso indicate the end of utterance units.5 ANALYS IS  EXAMPLESBelow we show results obtained by using a Grass-J-based parser to analyze some of the utterances inDialogue 1.
U (J means the utterance refit category.?
Utterance I: 'anoo kisoken eno ikikata o desune'(*veil, how to go to the Basic Research l,al)s.)parse tree:OONPNP PNP P desunefNP N oJ f ~ _  INP P ikikataI N enoI Ianoo kisokenspeech act representation:index = *X29res t r i c t ion  =( (REFER *X29) (OBJECT *X29 *X30)(AGENT *X29 *X31) (SPEAKER *X31)(BAS IC-RESEARCH-LABS *X32)(DEST INATION *X30 *X32)(HOW-TO-GO *X30) )?
Utterance 4: 'oshie teitadaki tai ndesukedo' (I'dlike you to tell me it)parsc t, ree:OUIVPVP PVP AUXV ndesukedoIV AUXV taiI Ioshie teitadakispeech act representation:index = *X777res t r i c t ion  =( (INTRODUCE-TOPIC *XYYY)(OBJECT *XT(7 *X778)(AGENT *X777 *xggg)(SPEAKER *X779)(TELL *X780)(AGENT *X780 *X808(OBJECT *X780 *X809(PATIENT *X780 *XOI0(HAVE-A-FAVOR *X784(OBJECT *X784 *X780(AGENT *X784 *X81J,)(SOURCE *X784 *X808(WANT *X718)(OBJECT *X778 *X784(AGENT *X778 *X811))6 CONCLUSIONWe have developed a grammar, called Cras.s-.\],for handling distinctive phenomena in spontaneousspeech.
'\['he grammatical analysis of spontaneousspeech is useful in combildng the fruits of dialogueundersl, anding research and those of speech processing research.
As describ(:d earlier, GrassoJ isused as the grammar tbr the experimental systemst~;nsemble/rli'io - 1 ancl l 'hmembleffQuartetq, which arebased on the Ensemble Model.
It enables the pro-cessing of several kinds of spontaneons speech, suchas that lacking particles.We focused on processing ~rans('ripts because agrammar and an analysis method for spontaneonsspeech can be combined with speech processing sys-tems more accurately than (:art those for written lan-guages.Finally, a.lthough we {b(;used only on Japanese'.spontaneous Sl)eech , mosl, of the techniques describedin this paper can also be used 1,o analyze spontaneousspeech in other languages.ACKNOWLEDGEMETNSWe thank Chung Pal l,ing, Yuiko Otsuka, MiyokoSou, Kaeko Matsuzawa, and Sanae Nagata, for help-ing us analyze dialogue data.1079REFERENCESAllen, J. F., & Perrault, C. R. (1980).
AnalyzingIntention in Utterances.
Artificial Intelligence,t5, 143 178.Arita, H., Kogure, K., Nogaito, I., Maeda, H., &Iida, II.
(1993).
Media-Dependent ConversationManners.
In SIG-NL-t;I, h~jbrmation Process-ing Society of Japan.
(in Japanese).Bear, J., l)owding, ,1., & Shriberg, 1",.
(1992).
In-tegrating Multiple Knowledge Sources for theDetection and Correction of Repairs in Haman-Computer Dialog.
In ACL-92, pp.
56 63.Clark, II.
H., & Wilkes-Gibbs, D. (1990).
Referringas a Collaborative Process.
In Cohen, P. R.,Morgan, J., & Pollack, M. E.
(Eds.
), Intentionsin Communication, pp.
463- 493.
MIT Press.Cohen, P. 11,., Morgan, J., & Pollack, M.
t!',.
(Eds.).(1990).
Intentions in Communication.
MITPress.Den, Y.
(1993).
A Study on Spoken l)ialogue Grammar.
SIG-,5%UD-9302-5, Japanese Society ofAI, 33 .4:0.
(in Japanese).Gnnji, '1'.
(1986).
Japanese Phrase Structure Gram-mar.
Reidel, Dordrecht.llayes, P. J., Hauptmann, A. C., Carbonell, J.
(k, &'\[bmita, M. (1986).
Parsing Spoken Language:A Semantic Caseframe Approach.
in COLING-86, pp.
587 592.ttosaka, J., Takezawa, T., & Ehara, '1'.
(1991).Constructing Syntactic Constraints for Speechl\],ecognition using Empirical )ata.
In SIG-NL-83, Information Processing Society of Japan,pp.
97 104.
(in Japanese).Katagiri, Y.
(1993).
l)ialogue Coordination Functionsof Japanese Sentenee--Hnal Particles.
In Pro-ceedings of \[nterna*ional Symposium on SpokenDialogue, pp.
145 148.Kawalnori, M. (1991 ).
Japanese Sentence Final Parti-cles and Epistemic Modality.
SIG-NI;-SL h~foT'-marion Processing Society of Japan, 41 48.
(inJapanese).Kay, M. (1980).
Algorithm Schemal, a and Data Strnc-tnres in Syntactic Processing.
Teeh.
rep. CSL-80-12, Xerox PARC.Kogure, K., Shimazu, A., L; Nakano, M. (1994).
Phm-Based Utterance Understanding.
In Proceedingsof the /~Slh Conference of \[nform.ation Process-ing Society of Japan, Vol.
3, pp.
189 190.
(ina apanese).Langer, tI.
(1990).
Syntactic Normalization of Spon-taneous Speech.
In COLfNG-gO, pp.
180 183.Levelt, W. J. M. (1989).
Speaking.
MIT Press.Mellish, C. (1989).
Some Chart-Based Techniques forParsing Ill-Formed Input.
In A CL-89, pp.
102109.Nagata, M., & Kogure, K. (1990).
tlPSG-Based Lat-tice Parser for Spoken Japanese in a SpokenLanguage Translation System.
In 1~;CAI-.90, pp.4(it 466.Nakano, M. (199\]).
Constraint Projection: An I"fffl-cient Treatment of Disjunctive Feature Descrip-tions.
In ACL-gl, pp.
307 314.Nakatani, C., & Itirschberg, J.
(1993).
A Speech-FirstModel for 1%epair Detection and Correction.
InACL-93, pp.
46.
53.Okada, M. (1991).
A Unifieation-(7;rammar-DireetedOne-Pass Search Algorithm for Parsing SpokenLanguage.
\[n Proceedings of IUASSP-9I.Otsuka, lI., & Okada, M. (1992).
Incremental Elabo-ration in Generating Spontaneons Speech.
SIG-NLC92-/tI, lnslitute of Eleclronics, informationand Communication L'ngineer.s.
(in Japanese).Sadanobu, q'., & Takubo, Y.
(1993).
The DiscourseManagement Function of Fillers a case of "eeto"and "ano(o)" .
h Proceedings oJ InternationalSymposium on Spoken Dialog, pp.
271 274.Shieber, S. M. (1986).
An Introduction to Unification-Based Approaches to Grammar.
CSLI LectureNotes Series No.
4.
Stanford: CSLI.Shimazu, A., Kawamori, M., & Kogure, K. (1993@.Analysis of Interjectory Responses in I)ialoguc.SIG~NI, C-93-9, Institute of Electronics, In-formation and Comunication l,;ngineers.
(inJapanese).Shimazn, A., Kogure, K., b. Nakano, M. (1993b).An 1,2xperimental Distributed Natural LanguageProcessing System and its Application to Ro-bust Processing.
in Proceedings of the Sympo-sium on lmplementalion of NaluraI LanguageProcessing.
Institute of Hectronies, Informa-tion and Communication Engineers/Japan So-ciety for Software Science and Technology.
(inJapanese).Takeshita, A., & Fukmmga, It.
(1991).
Morphoh)gicalAnalysis for Spokcm l,anguage.
In Proceedings ofthe 42nd Con.fcrence of Injbrmation Process*nO,5'oc~et9 of Japan, Vol.
3, pp.
5- 6.
(in Japanese).Thomason, R. iI.
(1990).
Accommodation, Meaning,and lmplicature: Interdisciplinary t)'oundationsfor Pragmatics.
In Cohen, P. 1%, Morgan, J., &Pollack, M. It;.
(Eds.
), Intentions in Uommuni-cation, pp.
325 1t64.
MIT Press.Young, S.
I%., Hauptmann, A. G., Ward, W. I1.,Smith, E. T., & Werner, P. (1989).
High bevelKnowledge Sourees in Usable Spe.ech l{ecogni-tion Systems.
Comm*lnication of the ACM,,~2(2), 183 194.1020
