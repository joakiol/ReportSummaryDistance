Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 473?480Manchester, August 2008Reading the Markets:Forecasting Public Opinion of Political Candidates by News AnalysisKevin LermanDept.
of Computer ScienceColumbia UniversityNew York, NY USAklerman@cs.columbia.eduAri Gilder and Mark DredzeDept.
of CISUniversity of PennsylvaniaPhiladelphia, PA USAagilder@alumni.upenn.edumdredze@cis.upenn.eduFernando PereiraGoogle, Inc.1600 Amphitheatre ParkwayMountain View, CA USApereira@google.comAbstractMedia reporting shapes public opinionwhich can in turn influence events, partic-ularly in political elections, in which can-didates both respond to and shape publicperception of their campaigns.
We usecomputational linguistics to automaticallypredict the impact of news on public per-ception of political candidates.
Our sys-tem uses daily newspaper articles to pre-dict shifts in public opinion as reflectedin prediction markets.
We discuss varioustypes of features designed for this problem.The news system improves market predic-tion over baseline market systems.1 IntroductionThe mass media can affect world events by sway-ing public opinion, officials and decision makers.Financial investors who evaluate the economic per-formance of a company can be swayed by positiveand negative perceptions about the company in themedia, directly impacting its economic position.The same is true of politics, where a candidate?sperformance is impacted by media influenced pub-lic perception.
Computational linguistics can dis-cover such signals in the news.
For example, De-vitt and Ahmad (2007) gave a computable metricof polarity in financial news text consistent withhuman judgments.
Koppel and Shtrimberg (2004)used a daily news analysis to predict financial mar-ket performance, though predictions could not beused for future investment decisions.
Recently,c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.a study conducted of the 2007 French presiden-tial election showed a correlation between the fre-quency of a candidate?s name in the news and elec-toral success (V?eronis, 2007).This work forecasts day-to-day changes in pub-lic perception of political candidates from dailynews.
Measuring daily public perception withpolls is problematic since they are conducted by avariety of organizations at different intervals andare not easily comparable.
Instead, we rely ondaily measurements from prediction markets.We present a computational system that usesboth external linguistic information and internalmarket indicators to forecast public opinion mea-sured by prediction markets.
We use features fromsyntactic dependency parses of the news and auser-defined set of market entities.
Successivenews days are compared to determine the novelcomponent of each day?s news resulting in featuresfor a machine learning system.
A combination sys-tem uses this information as well as predictionsfrom internal market forces to model predictionmarkets better than several baselines.
Results showthat news articles can be mined to predict changesin public opinion.Opinion forecasting differs from that of opin-ion analysis, such as extracting opinions, evaluat-ing sentiment, and extracting predictions (Kim andHovy, 2007).
Contrary to these tasks, our systemreceives objective news, not subjective opinions,and learns what events will impact public opinion.For example, ?oil prices rose?
is a fact but willlikely shape opinions.
This work analyzes news(cause) to predict future opinions (effect).
This af-fects the structure of our task: we consider a time-series setting since we must use past data to predictfuture opinions, rather than analyzing opinions inbatch across the whole dataset.473We begin with an introduction to predictionmarkets.
Several methods for new feature extrac-tion are explored as well as market history base-lines.
Systems are evaluated on prediction marketsfrom the 2004 US Presidential election.
We closewith a discussion of related and future work.2 Prediction MarketsPrediction markets, such as TradeSports and theIowa Electronic Markets1, provide a setting sim-ilar to financial markets wherein shares representnot companies or commodities, but an outcomeof a sporting, financial or political event.
For ex-ample, during the 2004 US Presidential election,one could purchase a share of ?George W. Bushto win the 2004 US Presidential election?
or ?JohnKerry to win the 2004 US Presidential election.
?A pay-out of $1 is awarded to winning sharehold-ers at market?s end, e.g.
Bush wins the election.In the interim, price fluctuations driven by supplyand demand indicate the perception of the event?slikelihood, which indicates public opinion of anevent.
Several studies show the accuracy of predic-tion markets in predicting future events (Wolfersand Zitzewitz, 2004; Servan-Schreiber et al, 2004;Pennock et al, 2000), such as the success of up-coming movies (Jank and Foutz, 2007), politicalstock markets (Forsythe et al, 1999) and sportsbetting markets (Williams, 1999).Market investors rely on daily news reports todictate investment actions.
If something positivehappens for Bush (e.g.
Saddam Hussein is cap-tured), Bush will appear more likely to win, sodemand increases for ?Bush to win?
shares, andthe price rises.
Likewise, if something negative forBush occurs (e.g.
casualties in Iraq increase), peo-ple will think he is less likely to win, sell theirshares, and the price drops.
Therefore, predic-tion markets can be seen as rapid response indi-cators of public mood concerning political candi-dates.
Market-internal factors, such as general in-vestor mood and market history, also affect price.For instance, a positive news story for a candidatemay have less impact if investors dislike the can-didate.
Explaining market behavior requires mod-eling news information external to the market andinternal trends to the market.This work uses the 2004 US Presidential elec-tion markets from Iowa Electronic Markets.
Eachmarket provides a daily average price, which indi-1www.tradesports.com, www.biz.uiowa.edu/iem/cates the overall market sentiment for a candidateon a given day.
The goal of the prediction systemis to predict the price direction for the next day (upor down) given all available information up to thecurrent day: previous days?
market pricing/volumeinformation and the morning news.
Market his-tory represents information internal to the market:if an investor has no knowledge of external events,what is the most likely direction for the market?This information can capture general trends andvolatility of the market.
The daily news is the ex-ternal information that influences the market.
Thisprovides information, independent of any internalmarket effects to which investors will respond.
Alearning system for each information source is de-veloped and combined to explain market behavior.The following sections describe these systems.3 External Information: NewsChanges in market price are likely responses tocurrent events reported in the news.
Investors readthe morning paper and act based on perceptions ofevents.
Can a system with access to this same in-formation make good investment decisions?Our system operates in an iterative (online) fash-ion.
On each day (round) the news for that day isused to construct a new instance.
A logistic re-gression classifier is trained on all previous daysand the resulting classifier predicts the price move-ment of the new instance.
The system either prof-its or loses money according to this prediction.
Itthen receives the actual price movement and labelsthe instance accordingly (up or down).
This set-ting is straightforward; the difficulty is in choosinga good feature representation for the classifier.
Wenow explore several representation techniques.3.1 Bag-of-Words FeaturesThe prediction task can be treated as a documentclassification problem, where the document is theday?s news and the label is the direction of the mar-ket.
Document classification systems typically relyon bag-of-words features, where each feature indi-cates the number of occurrences of a word in thedocument.
The news for a given day is representedby a normalized unit length vector of counts, ex-cluding common stop words and features that oc-cur fewer than 20 times in our corpus.4743.2 News Focus FeaturesSimple bag-of-words features may not capture rel-evant news information.
Public opinion is influ-enced by new events ?
a change in focus.
The dayafter a debate, most papers may declare Bush thewinner, yielding a rise in the price of a ?Bush towin?
share.
However, while the debate may bediscussed for several days after the event, publicopinion of Bush will probably not continue to riseon old news.
Changes in public opinion shouldreflect changes in daily news coverage.
Instead ofconstructing features for a single day, they can rep-resent differences between two days of news cov-erage, i.e.
the novelty of the coverage.
Given thecounts of feature i on day t as cti, where feature imay be the unigram ?scandal,?
and the set of fea-tures on day t as Ct, the fraction of news focus foreach feature is fti=cti|Ct|.
The news focus change(?)
for feature i on day t is defined as,?fti= log(fti13(ft?1i+ ft?2i+ ft?3i)), (1)where the numerator is the focus of news on fea-ture i today and the denominator is the averagefocus over the previous three days.
The resultingvalue captures the change in focus on day t, wherea value greater than 0 means increased focus and avalue less than 0 decreased focus.
Feature countswere smoothed by adding a constant (10).3.3 Entity FeaturesAs shown by Wiebe et al (2005), it is important toknow not only what is being said but about whom itis said.
The term ?victorious?
by itself is meaning-less when discussing an election ?
meaning comesfrom the subject.
Similarly, the word ?scandal?is bad for a candidate but good for the opponent.Subjects can often be determined by proximity.
Ifthe word ?scandal?
and Bush are mentioned in thesame sentence, this is likely to be bad for Bush.
Asmall set of entities relevant to a market can be de-fined a priori to give context to features.
For exam-ple, the entities ?Bush,?
?Kerry?
and ?Iraq?
wereknown to be relevant before the general election.Kim and Hovy (2007) make a similar assumption.News is filtered for sentences that mention ex-actly one of these entities.
Such sentences arelikely about that entity, and the extracted featuresare conjunctions of the word and the entity.
For ex-ample, the sentence ?Bush is facing another scan-dal?
produces the feature ?bush-scandal?
insteadof just ?scandal.
?2Context disambiguation comesat a high cost: about 70% of all sentences do notcontain any predefined entities and about 7% con-tain more than one entity.
These likely relevantsentences are unfortunately discarded, althoughfuture work could reduce the number of discardedsentences using coreference resolution.3.4 Dependency FeaturesWhile entity features are helpful they cannot pro-cess multiple entity sentences, nearly a quarter ofthe entity sentences.
These sentences may be themost helpful since they indicate entity interactions.Consider the following three example sentences:?
Bush defeated Kerry in the debate.?
Kerry defeated Bush in the debate.?
Kerry, a senator from Massachusetts, de-feated President Bush in last night?s debate.Obviously, the first two sentences have very dif-ferent meanings for each candidate?s campaign.However, representations considered so far do notdifferentiate between these sentences, nor wouldany heuristic using proximity to an entity.3Effec-tive features rely on the proper identification of thesubject and object of ?defeated.?
Longer n-grams,which would be very sparse, would succeed for thefirst two sentences but not the third.To capture these interactions, features were ex-tracted from dependency parses of the news ar-ticles.
Sentences were part of speech tagged(Toutanova et al, 2003), parsed with a depen-dency parser and labeled with grammatical func-tion labels (McDonald et al, 2006).
The result-ing parses encode dependencies for each sentence,where word relationships are expressed as parent-child links.
The parse for the third sentence aboveindicates that ?Kerry?
is the subject of ?defeated,?and ?Bush?
is the object.
Features are extractedfrom parse trees containing the pre-defined enti-ties (section 3.3), using the parent, grandparent,aunts, nieces, children, and siblings of any in-stances of the pre-defined entities we observe.
Fea-tures are conjoined indicators of the node?s lexicalentry, part of speech tag and dependency relation2Other methods can identify the subject of sentiment ex-pressions, but our text is objective news.
Therefore, we em-ploy this approximate method.3Several failed heuristics were tried, such as associatingeach word to an entity within a fixed window in the sentenceor the closer entity if two were in the window.475Feature Good ForKerry?
plan?
the Kerrypoll?
showed?
Bush Bushwon?
Kerry4Kerryagenda?
?s?
Bush KerryKerry?
spokesperson?
campaign BushTable 1: Simplified examples of features from thegeneral election market.
Arrows point from parentto child.
Features also include the word?s depen-dency relation labels and parts of speech.label.
For aunts, nieces, and children, the com-mon ancestor is used, and in the case of grand-parent, the intervening parent is included.
Eachof these conjunctions includes the discovered en-tity and back-off features are included by remov-ing some of the other information.
Note that be-sides extracting more precise information from thenews text, this handles sentences with multiple en-tities, since it associates parts of a sentence withdifferent entities.
In practice, we use this in con-junction with News Focus.
Useful features fromthe general election market are in table 1.
Notethat they capture events and not opinions.
For ex-ample, the last feature indicates that a statement bythe Kerry campaign was good for Bush, possiblybecause Kerry was reacting to criticism.4 Internal Information: Market HistoryNews cannot explain all market trends.
Momen-tum in the market, market inefficiencies, and slownews days can affect share price.
A candidate whodoes well will likely continue to do well unlessnew events occur.
Learning general market behav-ior can help explain these price movements.For each day t, we create an instance using fea-tures for the price and volume at day t ?
1 andthe price and volume change between days t ?
1and t ?
2.
We train using a ridge regression5onall previous days (labeled with their actual pricemovements) to forecast the movement for day t,which we convert into a binary value: up or down.4This feature matches phrases like ?Kerry won [the de-bate]?
and ?
[something] won Kerry [support]?5This outperformed more sophisticated algorithms, in-cluding the logistic regression used earlier.
This may be dueto the fact that many market history features (e.g.
previousprice movements) are very similar in nature to the future pricemovements being predicted.5 Combined SystemSince both news and internal market informationare important for modeling market behavior, eachone cannot be evaluated in isolation.
For example,a successful news system may learn to spot impor-tant events for a candidate, but cannot explain theprice movements of a slow news day.
A combina-tion of the market history system and news featuresis needed to model the markets.Expert algorithms for combining prediction sys-tems have been well studied.
However, experi-ments with the popular weighted majority algo-rithm (Littlestone and Warmuth, 1989) yieldedpoor performance since it attempts to learn theoptimal balance between systems while our set-ting has rapidly shifting quality between few ex-perts with little data for learning.
Instead, a sim-ple heuristic was used to select the best perform-ing predictor on each day.
We compare the 3-day prediction accuracy (measured in total earn-ings) for each system (news and market history)to determine the current best system.
The use ofa small window allows rapid change in systems.When neither system has a better 3-day accuracythe combined system will only predict if the twosystems agree and abstain otherwise.
This strategymeasures how accurately a news system can ac-count for price movements when non-news move-ments are accounted for by market history.
Thecombined system improved over individual evalu-ations of each system on every market6.6 EvaluationDaily pricing information was obtained from theIowa Electronic Markets for the 2004 US Presi-dential election for six Democratic primary con-tenders (Clark, Clinton, Dean, Gephardt, Kerryand Lieberman) and two general election candi-dates (Bush and Kerry).
Market length varied assome candidates entered the race later than others:the DNC markets for Clinton, Gephardt, Kerry,and Lieberman were each 332 days long, whileDean?s was 130 days and Clark?s 106.
The generalelection market for Bush was 153 days long, whileKerry?s was 142.7The price delta for each daywas taken as the difference between the average6This outperformed a single model built over all features,perhaps due to the differing natures of the feature types weused.7The first 11 days of the Kerry general election marketwere removed due to strange price fluctuations in the data.476price between the previous and current day.
Mar-ket data also included the daily volume that wasused as a market history feature.
Entities selectedfor each market were the names of all candidatesinvolved in the election and ?Iraq.
?News articles covering the election were ob-tained from Factiva8, an online news archive runby Dow Jones.
Since the system must make a pre-diction at the beginning of each day, only articlesfrom daily newspapers released early in the morn-ing were included.
The corpus contained approxi-mately 50 articles per day over a span of 3 monthsto almost a year, depending on the market.9While most classification systems are evaluatedby measuring their accuracy on cross-validationexperiments, both the method and the metric areunsuitable to our task.
A decision for a given daymust be made with knowledge of only the previ-ous days, ruling out cross validation.
In fact, weobserved improved results when the system wasallowed access to future articles through cross-validation.
Further, raw prediction accuracy is nota suitable metric for evaluation because it ignoresthe magnitude in price shifts each day.
A sys-tem should be rewarded proportional to the signif-icance of the day?s market change.To address these issues we used a chronologicalevaluation where systems were rewarded for cor-rect predictions in proportion to the magnitude ofthat day?s shift, i.e.
the ability to profit from themarket.
This metric is analogous to weighted accu-racy.
On each day, the system is provided with allavailable morning news and market history fromwhich an instance is created using one of the fea-ture schemes described above.
We then predictwhether the market price will rise or fall and thesystem either earns or loses the price change forthat day if it was right or wrong respectively.
Thesystem then learns the correct price movement andthe process is repeated for the next day.10Sys-tems that correctly forecast public opinions fromthe news will make more money.
In economicterms, this is equivalent to buying or short-selling asingle share of the market and then selling or cov-ering the short at the end of the day.11Scores were8http://www.factiva.com/9While 50 articles may not seem like much, humans readfar less text before making investment decisions.10This scheme is called ?online learning?
for which awhole class of algorithms apply.
We used batch algorithmssince training happens only once per day.11More complex investment schemes are possible thanwhat has been described here.
We choose a simple schemeMarket History BaselineDNC Clark 20 13Clinton 38 -8Dean 23 24Gephardt 8 1Kerry -6 6Lieberman 3 2General Kerry 2 15Bush 21 20Average (% omniscience) 13.6 9.1Table 2: Results using history features for predic-tion compared with a baseline system that investsaccording to the previous day?s result.normalized for comparison across markets usingthe maximum profit obtainable by an omniscientsystem that always predicts correctly.Baseline systems for both news and market his-tory are included.
The news baseline follows thespirit of a study of the French presidential elec-tion (V?eronis, 2007), which showed that candidatementions correlate to electoral success.
Attemptsto follow this method directly ?
predicting mar-ket movement based on raw candidate mentions ?did very poorly.
Instead, we trained our learningsystem with features representing daily mentioncounts of each entity.
For a market history base-line, we make a simple assumption about marketbehavior: the current market trend will continue,predict today?s behavior for tomorrow.There were too many features to learn in theshort duration of the markets so only features thatappeared at least 20 times were included, reduc-ing bag-of-words features from 88.8k to 28.3k andparsing features from 1150k to 15.9k.
A real worldsystem could use online feature selection.6.1 ResultsFirst, we establish performance without news in-formation by testing the market history systemalone.
Table 2 shows the profit of the history pre-diction and baseline systems.
While learning beatsthe rule based system on average, both earn im-pressive profits considering that random tradingwould break even.
These results corroborate theinefficient market observation of Pennock et al(2000).
Additionally, the general election marketssometimes both increased or decreased, an impos-sible result in an efficient zero-sum market.to make the evaluation more transparent.477Figure 1: Results for the different news features and combined system across five markets.
Bottombars can be compared to evaluate news components and combined with the stacked black bars (historysystem) give combined performance.
The average performance (far right) shows improved performancefrom each news system over the market history system.During initial news evaluations with the com-bined system, the primary election markets did ei-ther very poorly or quite well.
The news predic-tion component lost money for Clinton, Gephardt,and Lieberman while Clark, Dean and Kerry allmade money.
Readers familiar with the 2004 elec-tion will immediately see the difference betweenthe groups.
The first three candidates were minorcontenders for the nomination and were not news-makers.
Hillary Clinton never even declared hercandidacy.
The average number of mentions perday for these candidates in our data was 20.
In con-trast, the second group were all major contendersfor the nomination and an average mention of 94 inour data.
Clearly, the news system can only do wellwhen it observes news that effects the market.
Thesystem does well on both general election marketswhere the average candidate mention per day was503.
Since the Clinton, Gephardt and Liebermancampaigns were not newsworthy, they are omittedfrom the results.Results for news based prediction systems areshown in figure 1.
The figure shows the profitmade from both news features (bottom bars) andmarket history (top black bars) when evaluated asa combined system.
Bottom bars can be comparedto evaluate news systems and each is combinedwith its top bar to indicate total performance.
Neg-ative bars indicate negative earnings (i.e.
weightedaccuracy below 50%).
Averages across all mar-kets for the news systems and the market historysystem are shown on the right.
In each market,the baseline news system makes a small profit, butthe overall performance of the combined system isworse than the market history system alone, show-ing that the news baseline is ineffective.
However,all news features improve over the market historysystem; news information helps to explain marketbehaviors.
Additionally, each more advanced setof news features improves, with dependency fea-tures yielding the best system in a majority of mar-kets.
The dependency system was able to learnmore complex interactions between words in newsarticles.
As an example, the system learns thatwhen Kerry is the subject of ?accused?
his price in-creases but decreased when he is the object.
Sim-ilarly, when ?Bush?
is the subject of ?plans?
(i.e.Bush is making plans), his price increased.
Butwhen he appears as a modifier of the plural noun?plans?
(comments about Bush policies), his pricefalls.
Earning profit indicates that our systemswere able to correctly forecast changes in publicopinion from objective news text.The combined system proved an effective wayof modeling the market with both informationsources.
Figure 2 shows the profits of the depen-dency news system, the market history system, andthe combined system?s profits and decision on twosegments from the Kerry DNC market.
In the firstsegment, the history system predicts a downwardtrend in the market (increasing profit) and the sec-ond segment shows the final days of the market,where Kerry was winning primaries and the newssystem correctly predicted a market increase.V?eronis (2007) observed a connection betweenelectoral success and candidate mentions in newsmedia.
The average daily mentions in the generalelection was 520 for Bush (election winner) and478485 for Kerry.
However, for the three major DNCcandidates, Dean had 183, Clark 56 and Kerry(election winner) had the least at 43.
Most Kerryarticles occurred towards the end of the race whenit was clear he would win, while early articles fo-cused on the early leader Dean.
Also, news activitydid not indicate market movement direction; me-dian candidate mentions for a positive market daywas 210 and 192 for a negative day.Dependency news system accuracy was corre-lated with news activity.
On days when the newscomponent was correct ?
although not always cho-sen ?
there were 226 median candidate mentionscompared to 156 for incorrect days.
Additionally,the system was more successful at predicting neg-ative days.
While days for which it was incorrectthe market moved up or down equally, when it wascorrect and selected it predicted buy 42% of thetime and sell 58%, indicating that the system bet-ter tracked negative news impacts.7 Related WorkMany studies have examined the effects of news onfinancial markets.
Koppel and Shtrimberg (2004)found a low correlation between news and thestock market, likely because of the extreme effi-ciency of the stock market (Gid?ofalvi, 2001).
Twostudies reported success but worked with a verysmall time granularity (10 minutes) (Lavrenko etal., 2000; Mittermayer and Knolmayer, 2006).
Itappears that neither system accounts for the time-series nature of news during learning, instead us-ing cross-validation experiments which is unsuit-able for evaluation of time-series data.
Our ownpreliminary cross-validation experiments yieldedmuch better results than chronological evaluationsince the system trains using future information,and with much more training data than is actu-ally available for most days.
Recent work has ex-amined prediction market behavior and underlyingprinciples (Serrano-Padial, 2007).12Pennock etal.
(2000) found that prediction markets are some-what efficient and some have theorized that newscould predict these markets, which we have con-firmed (Debnath et al, 2003; Pennock et al, 2001;Servan-Schreiber et al, 2004).Others have explored the concurrent modelingof text corpora and time series, such as using stockmarket data and language modeling to identify12For a sample of the literature on prediction markets, seethe proceedings of the recent Prediction Market workshops(http://betforgood.com/events/pm2007/index.html).Figure 2: Two selections from the Kerry DNC mar-ket showing profits over time (days) for depen-dency news, history and combined systems.
Eachday?s chosen system is indicated by the bottomstripe as red (upper) for news, blue (lower) for his-tory, and black for ties.influential news stories (Lavrenko et al, 2000).Hurst and Nigam (2004) combined syntactic andsemantic information for text polarity extraction.Our task is related to but distinct from sentimentanalysis, which focuses on judgments in opin-ions and, recently, predictions given by opinions.Specifically, Kim and Hovy (2007) identify whichpolitical candidate is predicted to win by an opin-ion posted on a message board and aggregate opin-ions to correctly predict an election result.
Whilethe domain and some techniques are similar to ourown, we deal with fundamentally different prob-lems.
We do not consider opinions but instead ana-lyze objective news to learn events that will impactopinions.
Opinions express subjective statementsabout elections whereas news reports events.
Weuse public opinion as a measure of an events im-pact.
Additionally, they use generalized featuressimilar to our own identification of entities by re-placing (a larger set of) known entities with gen-eralized terms.
In contrast, we use syntactic struc-tures to create generalized ngram features.
Notethat our features (table 1) do not indicate opinionsin contrast to the Kim and Hovy features.
Finally,Kim and Hovy had a batch setting to predict elec-tion winners while we have a time-series settingthat tracked daily public opinion of candidates.8 Conclusion and Future WorkWe have presented a system for forecasting publicopinion about political candidates using news me-479dia.
Our results indicate that computational sys-tems can process media reports and learn whichevents impact political candidates.
Additionally,the system does better when the candidate appearsmore frequently and for negative events.
A newssource analysis could reveal which outlets most in-fluence public opinion.
A feature analysis couldreveal which events trigger public reactions.
Whilethese results and analyses have significance for po-litical analysis they could extend to other genres,such as financial markets.
We have shown that fea-ture extraction using syntactic parses can general-ize typical bag-of-word features and improve per-formance, a non-trivial result as dependency parsescontain significant errors and can limit the selec-tion of words.
Also, combining the internal mar-ket baseline with a news system improved perfor-mance, suggesting that forecasting future publicopinions requires a combination of new informa-tion and continuing trends, neither of which can becaptured by the other.ReferencesDebnath, S., D. M. Pennock, C. L. Giles, andS.
Lawrence.
2003.
Information incorporation inonline in-game sports betting markets.
In ElectronicCommerce.Devitt, Ann and Khurshid Ahmad.
2007.
Sentimentpolarity identification in financial news: A cohesion-based approach.
In Association for ComputationalLinguistics (ACL).Forsythe, R., T.A.
Rietz, , and T.W.
Ross.
1999.Wishes, expectations, and actions: A survey on priceformation in election stock markets.
Journal of Eco-nomic Behavior and Organization, 39:83?110.Gid?ofalvi, G. 2001.
Using news articles to predictstock price movements.
Technical report, Univ.
ofCalifornia San Diego, San Diego.Hurst, Matthew and Kamal Nigam.
2004.
Retrievingtopical sentiments from online document collections.In Document Recognition and Retrieval XI.Jank, Wolfgang and Natasha Foutz.
2007.
Using vir-tual stock exchanges to forecast box-office revenuevia functional shape analysis.
In The PredictionMarkets Workshop at Electronic Commerce.Kim, Soo-Min and Eduard Hovy.
2007.
Crystal: Ana-lyzing predictive opinions on the web.
In EmpiricalMethods in Natural Language Processing (EMNLP).Koppel, M. and I. Shtrimberg.
2004.
Good news orbad news?
let the market decide.
In AAAI SpringSymposium on Exploring Attitude and Affect in Text:Theories and Applications.Lavrenko, V., M. Schmill, D. Lawrie, P. Ogilvie,D.
Jensen, and J. Allan.
2000.
Mining of concur-rent text and time series.
In KDD.Littlestone, Nick and Manfred K. Warmuth.
1989.
Theweighted majority algorithm.
In IEEE Symposiumon Foundations of Computer Science.McDonald, R., K. Lerman, and F. Pereira.
2006.
Mul-tilingual dependency parsing with a two-stage dis-criminative parser.
In Conference on Natural Lan-guage Learning (CoNLL).Mittermayer, M. and G. Knolmayer.
2006.
News-CATS: A news categorization and trading system.
InInternational Conference in Data Mining.Pennock, D. M., S. Lawrence, C. L. Giles, and F. A.Nielsen.
2000.
The power of play: Efficiency andforecast accuracy in web market games.
TechnicalReport 2000-168, NEC Research Institute.Pennock, D. M., S. Lawrence, F. A. Nielsen, and C. L.Giles.
2001.
Extracting collective probabilistic fore-casts from web games.
In KDD.Serrano-Padial, Ricardo.
2007.
Strategic foundationsof prediction markets and the efficient markets hy-pothesis.
In The Prediction Markets Workshop atElectronic Commerce.Servan-Schreiber, E., J. Wolfers, D. M. Pennock, andB.
Galebach.
2004.
Prediction markets: Doesmoney matter?
Electronic Markets, 14.Toutanova, K., D. Klein, C. Manning, and Y. Singer.2003.
Feature-rich part-of-speech tagging with acyclic dependency network.
In HLT-NAACL.V?eronis, Jean.
2007.
La presse a fait mieux que lessondeurs.
http://aixtal.blogspot.com/2007/04/2007-la-presse-fait-mieux-que-les.html.Wiebe, Janyce, Theresa Wilson, and Claire Cardie.2005.
Annotating expressions of opinions and emo-tions in language.
LREC, 39:165?210.Williams, L.V.
1999.
Information efficiency in bettingmarkets: A survey.
Bulletin of Economic Research,51:1?30.Wolfers, J. and E. Zitzewitz.
2004.
Prediction markets.Journal of Economic Perspectives, 18(2):107?126.480
