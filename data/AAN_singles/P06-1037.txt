Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 289?296,Sydney, July 2006. c?2006 Association for Computational LinguisticsGuiding a Constraint Dependency Parser with SupertagsKilian Foth, Tomas By, and Wolfgang MenzelDepartment fu?r Informatik, Universita?t Hamburg, Germanyfoth|by|menzel@informatik.uni-hamburg.deAbstractWe investigate the utility of supertag infor-mation for guiding an existing dependencyparser of German.
Using weighted con-straints to integrate the additionally avail-able information, the decision process ofthe parser is influenced by changing itspreferences, without excluding alternativestructural interpretations from being con-sidered.
The paper reports on a series ofexperiments using varying models of su-pertags that significantly increase the pars-ing accuracy.
In addition, an upper boundon the accuracy that can be achieved withperfect supertags is estimated.1 IntroductionSupertagging is based on the combination of twopowerful and influential ideas of natural languageprocessing: On the one hand, parsing is (at leastpartially) reduced to a decision on the optimal se-quence of categories, a problem for which efficientand easily trainable procedures exist.
On the otherhand, supertagging exploits complex categories,i.e.
tree fragments which much better reflect themutual compatibility between neighbouring lexi-cal items than say part-of-speech tags.Bangalore and Joshi (1999) derived the notionof supertag within the framework of LexicalizedTree-Adjoining Grammars (LTAG) (Schabes andJoshi, 1991).
They considered supertagging a pro-cess of almost parsing, since all that needs to bedone after having a sufficiently reliable sequenceof supertags available is to decide on their combi-nation into a spanning tree for the complete sen-tence.
Thus the approach lends itself easily to pre-processing sentences or filtering parsing resultswith the goal of guiding the parser or reducing itsoutput ambiguity.Nasr and Rambow (2004) estimated that perfectsupertag information already provides for a pars-ing accuracy of 98% if a correct supertag assign-ment were available.
Unfortunately, perfectly re-liable supertag information cannot be expected;usually this uncertainty is compensated by run-ning the tagger in multi-tagging mode, expectingthat the reliability can be increased by not forcingthe tagger to take unreliable decisions but insteadoffering a set of alternatives from which a subse-quent processing component can choose.A grammar formalism which seems particularlywell suited to decompose structural descriptionsinto lexicalized tree fragments is dependencygrammar.
It allows us to define supertags on differ-ent levels of granularity (White, 2000; Wang andHarper, 2002), thus facilitating a fine grained anal-ysis of how the different aspects of supertag in-formation influence the parsing behaviour.
In thefollowing we will use this characteristic to studyin more detail the utility of different kinds of su-pertag information for guiding the parsing process.Usually supertags are combined with a parser ina filtering mode, i.e.
parsing hypotheses whichare not compatible with the supertag predic-tions are simply discarded.
Drawing on the abil-ity of Weighted Constraint Dependency Grammar(WCDG) (Schro?der et al, 2000) to deal with de-feasible constraints, here we try another option formaking available supertag information: Using ascore to estimate the general reliability of uniquesupertag decisions, the information can be com-bined with evidence derived from other constraintsof the grammar in a soft manner.
It makes possi-ble to rank parsing hypotheses according to theirplausibility and allows the parser to even overridepotentially wrong supertag decisions.Starting from a range of possible supertag mod-els, Section 2 explores the reliability with whichdependency-based supertags can be determined on289SUBJCPNATTRDETPPOBJAATTRDETSUBJDETKONJAUXSEXPLes mag sein , da?
die Franzosen kein schl?ssiges Konzept f?r eine echte Partnerschaft besitzen .Figure 1: Dependency tree for sentence 19601 of the NEGRA corpus.different levels of granularity.
Then, Section 3 de-scribes how supertags are integrated into the exist-ing parser for German.
The complex nature of su-pertags as we define them makes it possible to sep-arate the different structural predictions made by asingle supertag into components and study theircontributions independently (c.f.
Section 4).
Wecan show that indeed the parser is robust enough totolerate supertag errors and that even with a fairlylow tagger performance it can profit from the ad-ditional, though unreliable information.2 Supertagging German textIn defining the nature of supertags for depen-dency parsing, a trade-off has to be made betweenexpressiveness and accuracy.
A simple definitionwith very small number of supertags will not beable to capture the full variety of syntactic con-texts that actually occur, while an overly expres-sive definition may lead to a tag set that is so largethat it cannot be accurately learnt from the train-ing data.
The local context of a word to be en-coded in a supertag could include its edge label,the attachment direction, the occurrence of obliga-tory1 or of all dependents, whether each predicteddependent occurs to the right or to the left of theword, and the relative order among different de-pendents.
The simplest useful task that could beasked of a supertagger would be to predict the de-pendency relation that each word enters.
In termsof the WCDG formalism, this means associatingeach word at least with one of the syntactic labelsthat decorate dependency edges, such as SUBJ orDET; in other words, the supertag set would beidentical to the label set.
The example sentence1The model of German used here considers the objectsof verbs, prepositions and conjunctions to be obligatory andmost other relations as optional.
This corresponds closely tothe set of needs roles of (Wang and Harper, 2002).
?Es mag sein, da?
die Franzosen kein schlu?ssiges Konzeptfu?r eine echte Partnerschaft besitzen.?
(Perhaps the French do not have a viable concept for a truepartnership.
)if analyzed as in Figure 1, would then be de-scribed by a supertag sequence beginning withEXPL S AUX ...Following (Wang and Harper, 2002), we furtherclassify dependencies into Left (L), Right (R), andNo attachments (N), depending on whether a wordis attached to its left or right, or not at all.
Wecombine the label with the attachment directionto obtain composite supertags.
The sequence ofsupertags describing the example sentence wouldthen begin with EXPL/R S/N AUX/L ...Although this kind of supertag describes the roleof each word in a sentence, it still does not spec-ify the entire local context; for instance, it asso-ciates the information that a word functions as asubject only with the subject and not with the verbthat takes the subject.
In other words, it does notpredict the relations under a given word.
Greaterexpressivity is reached by also encoding the la-bels of these relations into the supertag.
For in-stance, the word ?mag?
in the example sentenceis modified by an expletive (EXPL) on its leftside and by an auxiliary (AUX) and a subjectclause (SUBJC) dependency on its right side.
Tocapture this extended local context, these labelsmust be encoded into the supertag.
We add thelocal context of a word to the end of its su-pertag, separated with the delimiter +.
This yieldsthe expression S/N+AUX,EXPL,SUBJC.
If wealso want to express that the EXPL precedes theword but the AUX follows it, we can insteadadd two new fields to the left and to the rightof the supertag, which leads to the new supertagEXPL+S/N+AUX,SUBJC.Table 1 shows the annotation of the example us-290Word Supertag model Jes +EXPL/R+mag EXPL+S/N+AUX,SUBJCsein +AUX/L+, +/N+da?
+KONJ/R+die +DET/R+Franzosen DET+SUBJ/R+kein +DET/R+schlu?ssiges +ATTR/R+Konzept ATTR,DET+OBJA/R+PPfu?r +PP/L+PNeine +DET/R+echte +ATTR/R+Partnerschaft ATTR,DET+PN/L+besitzen KONJ,OBJA,SUBJ+SUBJC/L+.
+/N+Table 1: An annotation of the example sentenceST Prediction of #tags Super- Com-mo- label direc- depen- order tag ponentdel tion dents accuracy accuracyA yes no none no 35 84.1% 84.1%B yes yes none no 73 78.9% 85.7%C yes no oblig.
no 914 81.1% 88.5%D yes yes oblig.
no 1336 76.9% 90.8%E yes no oblig.
yes 1465 80.6% 91.8%F yes yes oblig.
yes 2026 76.2% 90.9%G yes no all no 6858 71.8% 81.3%H yes yes all no 8684 67.9% 85.8%I yes no all yes 10762 71.6% 84.3%J yes yes all yes 12947 67.6% 84.5%Table 2: Definition of all supertag models used.ing the most sophisticated supertag model.
Notethat the notation +EXPL/R+ explicitly representsthe fact that the word labelled EXPL has no de-pendents of its own, while the simpler EXPL/Rmade no assertion of this kind.
The extended con-text specification with two + delimiters expressesthe complete set of dependents of a word andwhether they occur to its left or right.
However, itdoes not distinguish the order of the left or rightdependents among each other (we order the la-bels on either side alphabetically for consistency).Also, duplicate labels among the dependents on ei-ther side are not represented.
For instance, a verbwith two post-modifying prepositions would stilllist PP only once in its right context.
This ensuresthat the set of possible supertags is finite.
The fullset of different supertag models we used is givenin Table 2.
Note that the more complicated mod-els G, H, I and J predict all dependents of eachword, while the others predict obligatory depen-dents only, which should be an easier task.To obtain and evaluate supertag predictions, weused the NEGRA and TIGER corpora (Brants etal., 1997; Brants et al, 2002), automatically trans-formed into dependency format with the freelyavailable tool DepSy (Daum et al, 2004).
Asour test set we used sentences 18,602?19,601 ofthe NEGRA corpus, for comparability to earlierwork.
All other sentences (59,622 sentences with1,032,091 words) were used as the training set.
Foreach word in the training set, the local context wasextracted and expressed in our supertag notation.The word/supertag pairs were then used to trainthe statistical part-of-speech tagger TnT (Brants,2000), which performs trigram tagging efficientlyand allows easy retraining on different data.
How-ever, a few of TnT?s limitations had to be workedaround: since it cannot deal with words that havemore than 510 different possible tags, we system-atically replaced the rarest tags in the training setwith a generic ?OTHER?
tag until the limit wasmet.
Also, in tagging mode it can fail to processsentences with many unknown words in close suc-cession.
In such cases, we simply ran it on shorterfragments of the sentence until no error occurred.Fewer than 0.5% of all sentences were affected bythis problem even with the largest tag set.A more serious problem arises when using astochastic process to assign tags that partially pre-dict structure: the tags emitted by the model maycontradict each other.
Consider, for instance, thefollowing supertagger output for the previous ex-ample sentence:es: +EXPL/R+ mag: +S/N+AUX,SUBJCsein: PRED+AUX/L+ ...The supertagger correctly predicts that the firstthree labels are EXPL, S, and AUX.
It also pre-dicts that the word ?sein?
has a preceding PREDcomplement, but this is impossible if the two pre-ceding words are labelled EXPL and S. Such con-tradictory information is not fatal in a robust sys-tem, but it is likely to cause unnecessary workfor the parser when some rules demand the im-possible.
We therefore decided simply to ignorecontext predictions when they contradict the ba-sic label predictions made for the same sentence;in other words, we pretend that the predictionfor the third word was just +AUX/L+ rather thanPRED+AUX/L+.
Up to 13% of all predictionswere simplified in this way for the most complexsupertag model.The last columns of Table 2 give the number ofdifferent supertags in the training set and the per-formance of the retrained TnT on the test set insingle-tagging mode.
Although the number of oc-291curring tags rises and the prediction accuracy fallswith the supertag complexity, the correlation is notabsolute: It seems markedly easier to predict su-pertags with complements but no direction infor-mation (C) than supertags with direction informa-tion but no complements (B), although the tag setis larger by an order of magnitude.
In fact, the pre-diction of attachment direction seems much moredifficult than that of undirected supertags in everycase, due to the semi-free word order of German.The greater tag set size when predicting comple-ments of each words is at least partly offset bythe contextual information available to the n-grammodel, since it is much more likely that a wordwill have, e.g., a ?SUBJ?
complement when an ad-jacent ?SUBJ?
supertag is present.For the simplest model A, all 35 possible su-pertags actually occur, while in the most compli-cated model J, only 12,947 different supertags areobserved in the training data (out of a theoreticallypossible 1024 for a set of 35 edge labels).
Note thatthis is still considerably larger than most other re-ported supertag sets.
The prediction quality falls torather low values with the more complicated mod-els; however, our goal in this paper is not to opti-mize the supertagger, but to estimate the effect thatan imperfect one has on an existing parser.
Alto-gether most results fall into a range of 70?80% ofaccuracy; as we will see later, this is in fact enoughto provide a benefit to automatic parsing.Although supertag accuracy is usually deter-mined by simply counting matching and non-matching predictions, a more accurate measureshould take into account how many of the indi-vidual predictions that are combined into a su-pertag are correct or wrong.
For instance, a wordthat is attached to its left as a subject, is pre-ceded by a preposition and an attributive adjec-tive, and followed by an apposition would bearthe supertag PP,ATTR+SUBJ/L+APP.
Since theprepositional attachment is notoriously difficult topredict, a supertagger might miss it and emit theslightly different tag ATTR+SUBJ/L+APP.
Al-though this supertag is technically wrong, it is infact much more right than wrong: of the four pre-dictions of label, direction, preceding and follow-ing dependents, three are correct and only one iswrong.
We therefore define the component accu-racy for a given model as the ratio of correct pre-dictions among the possible ones, which resultsin a value of 0.75 rather than 0 for the exam-ple prediction.
The component accuracy of the su-pertag model J e. g. is in fact 84.5% rather than67.6%.
We would expect the component accuracyto match the effect on parsing more closely thanthe supertag accuracy.3 Using supertag information in WCDGWeighted Constraint Dependency Grammar(WCDG) is a formalism in which declarativeconstraints can be formulated that describewell-formed dependency trees in a particularnatural language.
A grammar composed of suchconstraints can be used for parsing by feeding itto a constraint-solving component that searchesfor structures that satisfy the constraints.Each constraint carries a numeric score or penaltybetween 0 and 1 that indicates its importance.
Thepenalties of all instances of constraint violationsare multiplied to yield a score for an entire anal-ysis; hence, an analysis that satisfies all rules ofthe WCDG bears the score 1, while lower valuesindicate small or large aberrations from the lan-guage norm.
A constraint penalty of 0, then, cor-responds to a hard constraint, since every analysisthat violates such a constraint will always bear theworst possible score of 0.
This means that of twoconstraints, the one with the lower penalty is moreimportant to the grammar.Since constraints can be soft as well as hard, pars-ing in the WCDG formalism amounts to multi-dimensional optimization.
Of two possible analy-ses of an utterance, the one that satisfies more (ormore important) constraints is always preferred.All knowledge about grammatical rules is encodedin the constraints that (together with the lexicon)constitute the grammar.
Adding a constraint whichis sensitive to supertag predictions will thereforechange the objective function of the optimiza-tion problem, hopefully leading to a higher shareof correct attachments.
Details about the WDCGparser can be found in (Foth and Menzel, 2006).A grammar of German is available (Foth et al,2004) that achieves a good accuracy on writtenGerman input.
Despite its good results, it seemsprobable that the information provided by a su-pertag prediction component could improve theaccuracy further.
First, because the optimizationproblem that WCDG defines is infeasible to solveexactly, the parser must usually use incomplete,292heuristic algorithms to try to compute the opti-mal analysis.
This means that it sometimes failsto find the correct analysis even if the languagemodel accurately defines it, because of search er-rors during heuristic optimization.
A componentthat makes specific predictions about local struc-ture could guide the process so that the correctalternative is tried first in more cases, and helpprevent such search errors.
Second, the existinggrammar rules deal mainly with structural compat-ibility, while supertagging exploits patterns in thesequence of words in its input, i. e. both modelscontribute complementary information.
Moreover,the parser can be expected to profit from supertagsproviding highly lexicalized pieces of information.Supertag Component Parsing accuracyModel accuracy accuracy unlabelled labelledbaseline ?
?
89.6% 87.9%A 84.1% 84.1% 90.8% 89.4%B 78.9% 85.7% 90.6% 89.2%C 81.1% 88.5% 91.0% 89.6%D 76.9% 90.8% 91.1% 89.8%E 80.6% 91.8% 90.9% 89.6%F 76.2% 90.9% 91.4% 90.0%G 71.8% 81.3% 90.8% 89.4%H 67.9% 85.8% 90.8% 89.4%I 71.6% 84.3% 91.8% 90.4%J 67.6% 84.5% 91.8% 90.5%Table 3: Influence of supertag integration on pars-ing accuracy.Parsing accuracyConstraint penalty unlabelled labelled0.0 3.7% 3.7%0.05 85.2% 83.5%0.1 87.6% 85.7%0.2 88.9% 87.3%0.5 91.2% 89.5%0.7 91.5% 90.1%0.9 91.8% 90.5%0.95 91.1% 89.8%1.0 89.6% 87.9%Table 4: Parsing accuracy depending on differentstrength of supertag integration.To make the information from the supertag se-quence available to the parser, we treat the com-plex supertags as a set of predictions and writeconstraints to prefer those analyses that satisfythem.
The predictions of label and direction madeby models A and B are mapped onto two con-straints which demand that each word in the anal-ysis should exhibit the predicted label and direc-tion.
The more complicated supertag models con-strain the local context of each word further.
Effec-tively, they predict that the specified dependents ofa word occur, and that no other dependents occur.The former prediction equates to an existence con-dition, so constraints are added which demand thepresence of the predicted relation types under thatword (one for left dependents and one for right de-pendents).
The latter prediction disallows all otherdependents; it is implemented by two constraintsthat test the edge label of each word-to-word at-tachment against the set of predicted dependentsof the regent (again, separately for left and rightdependents).
Altogether six new constraints areadded to the grammar which refer to the outputof the supertagger on the current sentence.Note that in contrast to most other approaches wedo not perform multi-supertagging; exactly onesupertag is assumed for each word.
Alternativescould be integrated by computing the logical dis-junctions of the predictions made by each su-pertag, and then adapting the new constraints ac-cordingly.4 ExperimentsWe tested the effect of supertag predictions ona full parser by adding the new constraints tothe WCDG of German described in (Foth et al,2004) and re-parsing the same 1,000 sentencesfrom the NEGRA corpus.
The quality of a de-pendency parser such as this can be measured asthe ratio of correctly attached words to all words(structural accuracy) or the ratio of the correctlyattached and correctly labelled words to all words(labelled accuracy).
Note that because the parseralways finds exactly one analysis with exactly onesubordination per word, there is no distinction be-tween recall and precision.
The structural accuracywithout any supertags is 89.6%.To determine the best trade-off between complex-ity and prediction quality, we tested all 10 supertagmodels against the baseline case of no supertags atall.
The results are given in Table 3.
Two observa-tions can be made about the effect of the supertagmodel on parsing.
Firstly, all types of supertag pre-diction, even the very basic model A which pre-dicts only edge labels, improve the overall accu-racy of parsing, although the baseline is alreadyquite high.
Second, the richer models of supertagsappear to be more suitable for guiding the parserthan the simpler ones, even though their own ac-curacy is markedly lower; almost one third of thesupertag predictions according to the most compli-293cated definition J are wrong, but nevertheless theirinclusion reduces the remaining error rate of theparser by over 20%.This result confirms the assumption that if su-pertags are integrated as individual constraints,their component accuracy is more important thanthe supertag accuracy.
The decreasing accuracy ofmore complex supertags is more than counterbal-anced by the additional information that they con-tribute to the analysis.
Obviously, this trend can-not continue indefinitely; a supertag definition thatpredicted even larger parts of the dependency treewould certainly lead to much lower accuracy byeven the most lenient measure, and a predictionthat is mostly wrong must ultimately degrade pars-ing performance.
Since the most complex model Jshows no parsing improvement over its succes-sor I, this point might already have been reached.The use of supertags in WCDG is comparableto previous work which integrated POS taggingand chunk parsing.
(Foth and Hagenstro?m, 2002;Daum et al, 2003) showed that the correct bal-ance between the new knowledge and the exist-ing grammar is crucial for successful integration.This is achieved by means of an additional pa-rameter, modeling how trustworthy supertag pre-dictions are considered.
Its effect is shown in Ta-ble 4.
As expected, making supertag constraintshard (with a value of 0.0) over-constrains mostparsing problems, so that hardly any analyses canbe computed.
Other values near 0 avoid this prob-lem but still lead to much worse overall perfor-mance, as wrong or even impossible predictionstoo often overrule the normal syntax constraints.The previously used value of 0.9 actually yieldsthe best results with this particular grammar.The fact that a statistical model can improve pars-ing performance when superimposed on a sophis-ticated hand-written grammar is of particular in-terest because the statistical model we used is sosimple, and in fact not particularly accurate; itcertainly does not represent the state of the artin supertagging.
This gives rise to the hope thatas better supertaggers for German become avail-able, parsing results will continue to see additionalimprovements, i.e., future supertagging researchwill directly benefit parsing.
The obvious ques-tion is how great this benefit might conceivablybecome under optimal conditions.
To obtain thisupper limit of the utility of supertags we repeatedSupertag Constraint penaltymodel 0.9 0.0A 92.7% / 92.2% 94.0% / 94.0%B 94.3% / 93.7% 96.0% / 96.0%C 92.8% / 92.4% 94.1% / 94.1%D 94.3% / 93.8% 96.0% / 96.0%E 93.1% / 92.6% 94.3% / 94.3%F 94.6% / 94.1% 96.1% / 96.1%G 94.2% / 93.7% 95.8% / 95.8%H 95.2% / 94.7% 97.4% / 97.4%I 97.1% / 96.8% 99.5% / 99.5%J 97.1% / 96.8% 99.6% / 99.6%Table 5: Unlabelled and labelled parsing accuracywith a simulated perfect supertagger.the process of translating each supertag into addi-tional WCDG constraints, but this time using thetest set itself rather than TnT?s predictions.Table 5 again gives the unlabelled and labelledparsing accuracy for all 10 different supertag mod-els with the integration strengths of 0 and 0.9.
(Note that since all our models predict the edgelabel of each word, hard integration of perfectpredictions eliminates the difference between la-belled und unlabelled accuracy.)
As expected, animproved accuracy of supertagging would leadto improved parsing accuracy in each case.
Infact, knowing the correct supertag would solve theparsing problem almost completely with the morecomplex models.
This confirms earlier findings forEnglish (Nasr and Rambow, 2004).Since perfect supertaggers are not available, wehave to make do with the imperfect ones that doexist.
One method of avoiding some errors intro-duced by supertagging would be to reject supertagpredictions that tend to be wrong.
To this end, weran the supertagger on its training set and deter-mined the average component accuracy of eachoccurring supertag.
The supertags whose averageprecision fell below a variable threshold were notconsidered during parsing as if the supertagger hadnot made a prediction.
This means that a thresholdof 100% corresponds to the baseline of not usingsupertags at all, while a threshold of 0% prunesnothing, so that these two cases duplicate the firstand last line from Table 2.As Table 6 shows, pruning supertags that arewrong more often than they are right results ina further small improvement in parsing accu-racy: unlabelled syntax accuracy rises up to 92.1%against the 91.8% if all supertags of model J areused.
However, the effect is not very noticeable,so that it would be almost certainly more useful to294Parsing accuracyThreshold unlabelled labelled0% 91.8% 90.5%20% 91.8% 90.4%40% 91.9% 90.5%50% 92.0% 90.7%60% 92.1% 91.0%80% 91.4% 90.0%100% 89.6% 87.9%Table 6: Parsing accuracy with empirically prunedsupertag predictions.improve the supertagger itself rather than second-guess its output.5 Related workSupertagging was originally suggested as amethod to reduce lexical ambiguity, and therebythe amount of disambiguation work done by theparser.
Sakar et al (2000) report that this increasesthe speed of their LTAG parser by a factor of 26(from 548k to 21k seconds) but at the price of onlybeing able to parse 59% of the sentences in theirtest data (of 2250 sentences), because too often thecorrect supertag is missing from the output of thesupertagger.
Chen et al (2002) investigate differ-ent supertagging methods as pre-processors to aTree-Adjoining Grammar parser, and they claim a1-best supertagging accuracy of 81.47%, and a 4-best accuracy of 91.41%.
With the latter they reachthe highest parser coverage, about three quarters ofthe 1700 sentences in their test data.Clark and Curran (2004a; 2004b) describe a com-bination of supertagger and parser for parsingCombinatory Categorial Grammar, where the tag-ger is used to filter the parses produced by thegrammar, before the computation of the model pa-rameters.
The parser uses an incremental method:the supertagger first assigns a small number of cat-egories to each word, and the parser requests morealternatives only if the analysis fails.
They report91.4% precision and 91.0% recall of unlabelleddependencies and a speed of 1.6 minutes to parse2401 sentences, and claim a parser speedup of afactor of 77 thanks to supertagging.The supertagging approach that is closest to oursin terms of linguistic representations is probably(Wang and Harper, 2002; Wang and Harper, 2004)whose ?Super Abstract Role Values?
are very sim-ilar to our model F supertags (Table 2).
It is in-teresting to note that they only report between 328and 791 SuperARVs for different corpora, whereaswe have 2026 category F supertags.
Part of the dif-ference is explained by our larger label set: 35,the same as the number of model A supertagsin table 2 against their 24 (White, 2000, p. 50).Also, we are not using the same corpus.
In ad-dition to determining the optimal SuperARV se-quence in isolation, Wang and Harper (2002) alsocombine the SuperARV n-gram probabilities witha dependency assignment probability into a depen-dency parser for English.
A maximum tagging ac-curacy of 96.3% (for sentences up to 100 words) isachieved using a 4-gram n-best tagger producingthe 100 best SuperARV sequences for a sentence.The tightly integrated model is able to determine96.6% of SuperARVs correctly.
The parser itselfreaches a labelled precision of 92.6% and a la-belled recall of 92.2% (Wang and Harper, 2004).In general, the effect of supertagging in the othersystems mentioned here is to reduce the ambi-guity in the input to the parser and thereby in-crease its speed, in some cases dramatically.
Forus, supertagging decreases the speed slightly, be-cause additional constraints means more work forthe parser, and because our supertagger-parser in-tegration is not yet optimal.
On the other handit gives us better parsing accuracy.
Using a con-straint penalty of 0.0 for the supertagger integra-tion (c.f.
Table 5) does speed up our parser severaltimes, but would only be practical with very hightagging accuracy.
An important point is that forsome other systems, like (Sarkar et al, 2000) and(Chen et al, 2002), parsing is not actually feasiblewithout the supertagging speedup.6 Conclusions and future workWe have shown that a statistical supertaggingcomponent can significantly improve the parsingaccuracy of a general-purpose dependency parserfor German.
The error rate among syntactic at-tachments can be reduced by 24% over an al-ready competitive baseline.
After all, the integra-tion of the supertagging results helped to reach aquality level which compares favourably with thestate-of-the-art in probabilistic dependency pars-ing for German as defined with 87.34%/90.38%labelled/unlabelled attachment accuracy on thisyears shared CoNLL task by (McDonald et al,2005) (see (Foth and Menzel, 2006) for a more de-tailed comparison).
Although the statistical modelused in our system is rather simple-minded, itclearly captures at least some distributional char-295acteristics of German text that the hand-writtenrules do not.A crucial factor for success is the defeasible in-tegration of the supertagging predictions via softconstraints.
Rather than pursuing a strict filteringapproach where supertagging errors are partiallycompensated by an n-best selection, we commit toonly one supertag per word, but reduce its influ-ence.
Treating supertag predictions as weak pref-erences yields the best results.
By measuring theaccuracy of the different types of predictions madeby complex supertags, different weights could alsobe assigned to the six new constraints.Of the investigated supertag models, the mostcomplex ones guide the parser best, althoughtheir own accuracy is not the best one, evenwhen measured by the more pertinent componentaccuracy.
Since purely statistical parsing methodsdo not reach comparable parsing accuracy onthe same data, we assume that this trend doesnot continue indefinitely, but would stop at somepoint, perhaps already reached.ReferencesS.
Bangalore and A. K. Joshi.
1999.
Supertagging: anapproach to almost parsing.
Computational Linguis-tics, 25(2):237?265.T.
Brants, R. Hendriks, S. Kramp, B. Krenn, C. Preis,W.
Skut, and H. Uszkoreit.
1997.
Das NEGRA-Annotationsschema.
Technical report, Universita?t desSaarlandes, Computerlinguistik.S.
Brants, St. Dipper, S. Hansen, W. Lezius, andG.
Smith.
2002.
The TIGER treebank.
In Proc.
Work-shop on Treebanks and Linguistic Theories, Sozopol.T.
Brants.
2000.
TnT ?
A statistical part-of-speechtagger.
In Proc.
the 6th Conf.
on Applied Natural Lan-guage Processing, ANLP-2000, pages 224?231, Seat-tle, WA.J.
Chen, S. Bangalore, M. Collins, and O. Rambow.2002.
Reranking an N-gram supertagger.
In Proc.
6thInt.
Workshop on Tree Adjoining Grammar and RelatedFrameworks.S.
Clark and J. R. Curran.
2004a.
The importance ofsupertagging for wide-coverage CCG parsing.
In Proc.20th Int.
Conf.
on Computational Linguistics.S.
Clark and J. R. Curran.
2004b.
Parsing the WSJ us-ing CCG and log-linear models.
In Proc.
42nd Meetingof the ACL.M.
Daum, K. Foth, and W. Menzel.
2003.
Constraintbased integration of deep and shallow parsing tech-niques.
In Proc.
11th Conf.
of the EACL, Budapest,Hungary.M.
Daum, K. Foth, and W. Menzel.
2004.
Au-tomatic transformation of phrase treebanks to depen-dency trees.
In Proc.
4th Int.
Conf.
on Language Re-sources and Evaluation, LREC-2004, pages 99?106,Lisbon, Portugal.K.
Foth and J. Hagenstro?m.
2002.
Tagging for robustparsers.
In 2nd Workshop on Robust Methods in Anal-ysis of Natural Language Data, ROMAND-2002, pages21 ?
32, Frascati, Italy.K.
Foth and W. Menzel.
2006.
Hybrid parsing: Us-ing probabilistic models as predictors for a symbolicparser.
In Proc.
21st Int.
Conf.
on Computational Lin-guistics, Coling-ACL-2006, Sydney.K.
Foth, M. Daum, and W. Menzel.
2004.
A broad-coverage parser for german based on defeasible con-straints.
In 7.
Konferenz zur Verarbeitung natu?rlicherSprache, KONVENS-2004, pages 45?52, Wien.R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic.2005.
Non-projective dependency parsing using span-ning tree algorithms.
In Proc.
Human LanguageTechnology Conference, HLT/EMNLP-2005, Vancou-ver, B.C.A.
Nasr and O. Rambow.
2004.
A simple string-rewriting formalism for dependency grammar.
InColing-Workshop Recent Advances in DependencyGrammar, pages 17?24, Geneva, Switzerland.A.
Sarkar, F. Xia, and A. Joshi.
2000.
Some experi-ments on indicators of parsing complexity for lexical-ized grammars.
In Proc.
COLING Workshop on Effi-ciency in Large-Scale Parsing Systems.Y.
Schabes and A. K. Joshi.
1991.
Parsing with lexi-calized tree adjoining grammar.
In M. Tomita, editor,Current Issues in Parsing Technologies.
Kluwer Aca-demic Publishers.I.
Schro?der, W. Menzel, K. Foth, and M. Schulz.
2000.Modeling dependency grammar with restricted con-straints.
Traitement Automatique des Langues (T.A.L.),41(1):97?126.W.
Wang and M. P. Harper.
2002.
The SuperARV lan-guage model: Investigating the effectiveness of tightlyintegrating multiple knowledge sources.
In Proc.
Conf.on Empirical Methods in Natural Language Process-ing, EMNLP-2002, pages 238?247, Philadelphia, PA.W.
Wang and M. P. Harper.
2004.
A statisticalconstraint dependency grammar (CDG) parser.
InProc.
ACL Workshop Incremental Parsing: BringingEngineering and Cognition Together, pages 42?49,Barcelona, Spain.Ch.
M. White.
2000.
Rapid Grammar Developmentand Parsing: Constraint Dependency Grammar withAbstract Role Values.
Ph.D. thesis, Purdue University,West Lafayette, IN.296
