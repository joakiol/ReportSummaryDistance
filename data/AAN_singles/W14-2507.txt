Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 13?17,Baltimore, Maryland, USA, June 26, 2014.c?2014 Association for Computational LinguisticsExtracting Socioeconomic Patterns from the News: Modelling Text andOutlet Importance JointlyVasileios Lampos1, Daniel Preot?iuc-Pietro2, Sina Samangooei3,Douwe Gelling2, and Trevor Cohn41Department of Computer Science, University College London ?
v.lampos@ucl.ac.uk2Department of Computer Science, The University of Sheffield ?
{d.preotiuc,d.gelling}@shef.ac.uk3Electronics and Computer Science, University of Southampton ?
ss@ecs.soton.ac.uk4Computing and Information Systems, The University of Melbourne ?
t.cohn@unimelb.edu.auAbstractInformation from news articles can be usedto study correlations between textual dis-course and socioeconomic patterns.
Thiswork focuses on the task of understandinghow words contained in the news as well asthe news outlets themselves may relate toa set of indicators, such as economic senti-ment or unemployment rates.
The bilinearnature of the applied regression model fa-cilitates learning jointly word and outletimportance, supervised by these indicators.By evaluating the predictive ability of theextracted features, we can also assess theirrelevance to the target socioeconomic phe-nomena.
Therefore, our approach can beformulated as a potential NLP tool, partic-ularly suitable to the computational socialscience community, as it can be used to in-terpret connections between vast amountsof textual content and measurable society-driven factors.1 IntroductionVast amounts of user-generated content on the Inter-net as well as digitised textual resources allow us tostudy text in connection to real world events acrosslarge intervals of time.
Over the last decade, therehas been a shift in user news consumption startingwith a move from offline to online sources (Linet al., 2005); in more recent years user-generatednews have also become prominent.
However, tra-ditional news outlets continue to be a central refer-ence point (Nah and Chung, 2012) as they still havethe advantage of being professionally authored, al-leviating the noisy nature of citizen journalism for-mats.Here, we present a framework for analysing so-cioeconomic patterns in news articles.
In contrastto prior approaches, which primarily focus on thetextual contents, our analysis shows how MachineLearning methods can be used to gain insights intothe interplay between text in news articles, the newsoutlets and socioeconomic indicators.
Our experi-ments are performed on a set of EU-related newssummaries spanning over 8 years, with the inten-tion to study two basic economic factors: EU?sunemployment rate and Economic Sentiment Index(ESI) (European Commision, 1997).
To determineconnections between the news, the outlets and theindicators of interest, we formulate our learningtask as bilinear text-based regression (Lampos etal., 2013).Approaches to learning the correlation of news,or text in general, with real world indicators havebeen performed in both unsupervised and super-vised settings.
For example, Flaounas et al.
(2010)uncover interesting patterns in EU?s Mediasphere,whereas Schumaker and Chen (2009) demonstratethat news articles can predict financial indicators.Conversely, Bentley et al.
(2014) show that emo-tions in the textual content of books reflect backon inflation and unemployment rates during the20th century.
Recently, Social Media text has beenintensively studied as a quicker, unobtrusive andcheaper alternative to traditional surveys.
Applica-tion areas include politics (O?Connor et al., 2010),finance (Bollen and Mao, 2011), health (Lamposand Cristianini, 2012; Paul and Dredze, 2011) orpsychology (De Choudhury et al., 2013; Schwartzet al., 2013).In this paper, we apply a modified version of abilinear regularised regression model (BEN) pro-posed for the task of voting intention inferencefrom Twitter content (Lampos et al., 2013).
Themain characteristic of BEN is the ability of mod-elling word frequencies as well as individual userimportance in a joint optimisation task.
By apply-ing it in the context of supervised news analysis,we are able to visualise relevant discourse to a par-ticular socioeconomic factor, identifying relevantwords together with important outlets.132 DataWe compiled a data set by crawling summarieson news articles written in English language, pub-lished by the Open Europe Think Tank.1The presssummaries are daily aggregations of news itemsabout the EU or member countries with a focuson politics; the news outlets used to compile eachsummary are listed below the summary?s text.
Thesite is updated every weekday, with the major newsbeing covered in a couple of paragraphs, and otherless prevalent issues being mentioned in one para-graph to as little as one sentence.
The news sum-maries were first published on February 2006; wecollected all of them up to mid-November 2013,creating a data set with the temporal resolution of1913 days (or 94 months).The text was tokenised using the NLTK li-brary (Bird et al., 2009).
News outlets with fewerthan 5 mentions were removed, resulting in a totalof 435 sources.
Each summary contains on average14 news items, with an average of 3 news sourcesper item; where multiple sources were present, thesummary was assigned to all the referenced newsoutlets.
After removing stop words, we ended upwith 8, 413 unigrams and 19, 045 bigrams; theirdaily occurrences were normalised using the totalnumber of news items for that day.For the purposes of our supervised analysis, weuse the response variables of ESI and unemploy-ment rate across the EU.
The monthly time seriesof these socioeconomic indicators were retrievedfrom Eurostat, EU?s statistical office (see the redlines in Fig.
1a and 1b respectively).
ESI is a com-posite indicator often seen as an early predictor forfuture economic developments (Gelper and Croux,2010).
It consists of five confidence indicators withdifferent weights: industrial (40%), services (30%),consumer (20%), construction (5%) and retail trade(5%).
The unemployment rate is a seasonally ad-justed ratio of the non employed persons over theentire EU labour force.23 ModelsA common approach to regression arises throughthe application of generalised linear models.
Thesemodels use a feature vector inputx and aim to builda linear function of x for predicting a response1http://www.openeurope.org.uk/Page/PressSummary/en/2http://epp.eurostat.ec.europa.eu/statistics_explained/index.php/Unemployment_statisticsvariable y:f(x) = xTw + ?
where x,w ?
Rm.
(1)The objective is to find an f , which minimises amodel-dependent loss function (e.g.
sum squarederror), optionally subject to a regularisation penalty?
; `2-norm regularisation (ridge regression) pe-nalises high weights (Hoerl and Kennard, 1970),while `1-norm regularisation (lasso) encouragessparse solutions (Tibshirani, 1994).
Sparsity is de-sirable for avoiding overfitting, especially whenthe dimensionality m is larger than the number oftraining examples n (Hastie et al., 2009).
ElasticNet formulates a combination of `1and `2-normregularisation defined by the objective:{w?, ??}
=argminw,?n?i=1(xTi?w + ?
?
yi)2+ ?EN(w, ?)
,(2)where ?
denotes the regularisation parameters (Zouand Hastie, 2005); we refer to this model as LEN(Linear Elastic Net) in the remainder of the script.In the context of voting intention inference fromTwitter content, Lampos et al.
(2013) extendedLEN to a bilinear formulation, where a set of twovector weights are learnt: one for words (w) andone for users (u).
This was motivated by the ob-servation that only a sparse set of users may havepredictive value.
The model now becomes:f(X) = uTXw + ?
, (3)where X is a matrix of word ?
users frequencies.The bilinear optimisation objective is formulatedas:{w?,u?, ??}
=argminw,u,?n?i=1(uTXiw + ?
?
yi)2+ ?EN(w, ?1) + ?EN(u, ?2) ,(4)where Xiis the word ?
user frequency matrix, and?1, ?2are the word and user regularisation param-eters.
This can be treated as a biconvex learningtask and be solved by iterating over two convexprocesses: fixingw and learning u, and vice versa(Lampos et al., 2013).
Regularised regression onboth user and word spaces allows for an automaticselection of the most important words and users,performing at the same time an improved noisefiltering.14In our experiments, news outlets and socioeco-nomic indicators replace users and voting intentionin the previous model formulation.
To ease the in-terpretation of the outputs, we further impose apositivity constraint on the outlet weights u, i.e.min(u) ?
0; this makes the model more restric-tive, but, in our case, did not affect the predictionperformance.
We refer to this model as BEN (Bi-linear Elastic Net).4 ExperimentsBoth models are applied to the news summariesdata set with the aim to predict EU?s ESI and rateof unemployment.
The predictive capability of thederived models, assessed by their respective infer-ence performance, is used as a metric for judgingthe degree of relevance between the learnt modelparameters ?
word and outlet weights ?
and theresponse variable.
A strong predictive performanceincreases confidence on the soundness of those pa-rameters.To match input with the monthly temporal reso-lution of the response variables, we compute themean monthly term frequencies for each outlet.Evaluation is performed via a 10-fold validation,where each fold?s training set is based on a mov-ing window of p = 64 contiguous months, and thetest set consists of the following q = 3 months;formally, the training and test sets for fold i arebased on months {q(i?
1) + 1, ..., q(i?
1) + p}and {q(i?
1) + p+ 1, ..., q(i?
1) + p+ q} re-spectively.
In this way, we emulate a scenariowhere we always train on past and predict futurepoints.Performance results for LEN and BEN are pre-sented in Table 1; we show the average Root MeanSquared Error (RMSE) as well as an error rate(RMSE over ?
(y)) across folds to allow for a bet-ter interpretation.
BEN outperforms LEN in bothtasks, with a clearer improvement when predict-ing ESI.
Predictions for all folds are depicted inFig.
1a and 1b together with the actual values.
Notethat reformulating the problem into a multi-tasklearning scenario, where ESI and unemploymentare modelled jointly did not improve inference per-formance.The relatively small average error rates (< 8.8%)make meaningful a further analysis of the model?soutputs.
Due to space limitations, we choose to fo-cus on the most recent results, depicting the modelsderived in the 10th fold.
Following the example ofSchwartz et al.
(2013), we use a word cloud visu-ESI UnemploymentLEN 9.253 (9.89%) 0.9275 (8.75%)BEN 8.209 (8.77%) 0.9047 (8.52%)Table 1: 10-fold validation average RMSEs (anderror rates) for LEN and BEN on ESI and unem-ployment rates prediction.2007 2008 2009 2010 2011 2012 2013050100actualpredictions(a) ESI2007 2008 2009 2010 2011 2012 20130510actualpredictions(b) UnemploymentFigure 1: Time series of ESI and unemploymenttogether with BEN predictions (smoothed using a3-point moving average).alisation, where the font size is proportional to thederived weights by applying BEN, flipped terms de-note negative weights and colours are determinedby the frequency of use in the corpus (Fig.
2).
Wordclouds depict the top-60 positively and negativelyweighted n-grams (120 in total) together with thetop-30 outlets; bigrams are separated by ?
?.5 Discussion and Future WorkOur visualisations (Fig.
2) present various inter-esting insights into the news and socioeconomicfeatures being explored, serving as a demonstra-tion of the potential power of the proposed mod-elling.
Firstly, we notice that in the word cloud,the size of a feature (BEN?s weight) is not tightlyconnected with its colour (frequency in the corpus).Also, the word clouds suggest that mostly differentterms and outlets are selected for the two indicators.For example, ?sky.it?
is predominant for ESI butnot for unemployment, while the opposite is truefor ?hedgefundsreview.com?.
Some of the wordsselected for ESI reflect economical issues, such as?stimulus?
and ?spending?, whereas key politicians15(a) ESI(b) UnemploymentFrequencyWordOutletWeightaaPolarityYesYes+-Figure 2: Word clouds for words and outlets visualising the outputs of BEN.like ?david cameron?
and ?berlusconi?, are majorparticipants in the word cloud for unemployment.In addition, the visualisations show a strong neg-ative relationship between unemployment and theterms ?food?, ?russia?
and ?agriculture?, but no suchrelationship with respect to ESI.
The disparity ofthese selections is evidence for our framework?scapability to highlight features of lesser or greaterimportance to a given socioeconomic time series.The exact interpretation of the selected words andoutlets is, perhaps, context-dependent and beyondthe scope of this work.In this paper, we presented a framework for per-forming a supervised analysis on news.
An impor-tant factor for this process is that the bilinear natureof the learning function allows for a joint selectionof important words and news outlets.
Predictionperformance is used as a reference point for de-termining whether the extracted outputs (i.e.
themodel?s parameters) encapsulate relevant informa-tion regarding to the given indicator.
Experimentswere conducted on a set of EU-related news sum-maries and the supervising socioeconomic factorswere the EU-wide ESI and unemployment.
BENoutperformed the linear alternative (LEN), produc-ing error rates below 8.8%.The performance of our framework motivatesseveral extensions to be explored in future work.Firstly, the incorporation of additional textual fea-tures may improve predictive capability and allowfor richer interpretations of the term weights.
Forexample, we could extend our term vocabulary us-ing n-grams with n > 2, POS tags of words andentities (people, companies, places, etc.).
Further-more, multi-task learning approaches as well asmodels which incorporate the regularised learningof weights for different countries might give us fur-ther insights into the relationship between news,geographic location and socioeconomic indicators.Most importantly, we plan to gain a better under-standing of the outputs by conducting a thoroughanalysis in collaboration with domain experts.16AcknowledgementsVL acknowledges the support from the EPSRCIRC project EP/K031953/1.
DPP, SS, DG and TCwere supported by EU-FP7-ICT project n.287863(?TrendMiner?).ReferencesR.
Alexander Bentley, Alberto Acerbi, Paul Ormerod,and Vasileios Lampos.
2014.
Books average previ-ous decade of economic misery.
PLoS ONE, 9(1).Steven Bird, Ewan Klein, and Edward Loper.
2009.Natural Language Processing with Python.
O?ReillyMedia.Johan Bollen and Huina Mao.
2011.
Twitter mood as astock market predictor.
IEEE Computer, 44(10):91?94.Munmun De Choudhury, Scott Counts, and EricHorvitz.
2013.
Social media as a measurement toolof depression in populations.
In Proceedings of ACMWebSci?13, pages 47?56.European Commision.
1997.
The joint harmonised EUprogramme of business and consumer surveys.
Euro-pean economy: Reports and studies.Ilias Flaounas, Marco Turchi, Omar Ali, Nick Fyson,Tijl De Bie, Nick Mosdell, Justin Lewis, and NelloCristianini.
2010.
The Structure of the EU Medias-phere.
PLoS ONE, 5(12), 12.Sarah Gelper and Christophe Croux.
2010.
On the con-struction of the European Economic Sentiment Indi-cator.
Oxford Bulletin of Economics and Statistics,72(1):47?62.Trevor Hastie, Robert Tibshirani, and Jerome Friedman.2009.
The Elements of Statistical Learning: DataMining, Inference, and Prediction.
Springer.Arthur E. Hoerl and Robert W. Kennard.
1970.
Ridgeregression: biased estimation for nonorthogonal prob-lems.
Technometrics, 12:55?67.Vasileios Lampos and Nello Cristianini.
2012.
Now-casting events from the Social Web with statisticallearning.
ACM TIST, 3(4):72:1?72:22.Vasileios Lampos, Daniel Preot?iuc-Pietro, and TrevorCohn.
2013.
A user-centric model of voting inten-tion from Social Media.
In Proceedings of ACL?13,pages 993?1003.Carolyn Lin, Michael B. Salwen, Bruce Garrison, andPaul D. Driscoll.
2005.
Online news as a functionalsubstitute for offline news.
Online news and the pub-lic, pages 237?255.Seungahn Nah and Deborah S. Chung.
2012.
When cit-izens meet both professional and citizen journalists:Social trust, media credibility, and perceived journal-istic roles among online community news readers.Journalism, 13(6):714?730.Brendan O?Connor, Ramnath Balasubramanyan,Bryan R. Routledge, and Noah A. Smith.
2010.From tweets to polls: linking text sentiment topublic opinion time series.
In Proceedings of AAAIICWSM?10, pages 122?129.Michael J. Paul and Mark Dredze.
2011.
YouAre What You Tweet: Analyzing Twitter for PublicHealth.
In Proceedings of AAAI ICWSM?11, pages265?272.Robert P. Schumaker and Hsinchun Chen.
2009.
Tex-tual analysis of stock market prediction using break-ing financial news: the AZFin text system.
ACMTOIS, 27(2):12:1?12:19.H.
Andrew Schwartz, Johannes C. Eichstaedt, Mar-garet L. Kern, Lukasz Dziurzynski, Stephanie M. Ra-mones, Megha Agrawal, Achal Shah, Michal Kosin-ski, David Stillwell, Martin E. P. Seligman, andLyle H. Ungar.
2013.
Personality, Gender, andAge in the Language of Social Media: The Open-Vocabulary Approach.
PLoS ONE, 8(9).Robert Tibshirani.
1994.
Regression shrinkage andselection via the lasso.
JRSS: Series B, 58:267?288.Hui Zou and Trevor Hastie.
2005.
Regularization andvariable selection via the elastic net.
JRSS: Series B,67(2):301?320.17
