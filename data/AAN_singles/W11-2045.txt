Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 350?352,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsA Just-in-Time Document Retrieval System for Dialogues or MonologuesAndrei Popescu-Belis, Majid Yazdani, Alexandre Nanchen, and Philip N. GarnerIdiap Research InstituteRue Marconi 19, Case Postale 5921920 Martigny, Switzerland{apbelis,myazdani,ananchen,pgarner}@idiap.chAbstractThe Automatic Content Linking Device is ajust-in-time document retrieval system thatmonitors an ongoing dialogue or monologueand enriches it with potentially related docu-ments from local repositories or from the Web.The documents are found using queries thatare built from the dialogue words, obtainedthrough automatic speech recognition.
Re-sults are displayed in real time to the dialogueparticipants, or to people watching a recordeddialogue or a talk.
The system can be demon-strated in both settings.1 IntroductionThe Automatic Content Linking Device (ACLD) isa system that analyzes speech input from one ormore speakers using automatic speech recognition(ASR), in order to retrieve related content, in realtime, from a variety of repositories.
This paper de-scribes the main components of the system and sum-marizes evaluation results.
The remainder of thissection introduces scenarios of use and previous sys-tems with similar goals.The first scenario of use involves people takingpart in meetings, who often mention documents con-taining facts that are relevant to the current discus-sion, but cannot search for them without interrupt-ing the discussion flow.
Our goal is to perform suchsearches automatically.
In a second scenario, searchis performed for live or recorded lectures, for in-stance in a computer-assisted learning environment.The ACLD enriches the lectures with related coursematerial, receiving real-time feedback from the user.The ACLD improves over past systems by usingspeech, by giving access to multimedia documents,and by using semantic search.
Its first precursorswere the Fixit query-free search system (Hart andGraham, 1997), the Remembrance Agent for just-in-time retrieval (Rhodes and Maes, 2000), and theImplicit Queries system (Dumais et al, 2004).
Aversion of the Remembrance Agent called Jimminywas conceived as a wearable assistant for takingnotes, but ASR was only simulated (Rhodes, 1997).Watson monitored the user?s operations in a texteditor, and selected terms for web search (Budzikand Hammond, 2000).
Another authoring assistantwas developed in the A-Propos project (Puerta Mel-guizo and al., 2008).
Recently, several speech-based search engines have been proposed, as well assystems for searching spoken documents.
For hu-man dialogues in meetings, the FAME interactivespace (Metze and al., 2006) provided multi-modalaccess to recordings of lectures via a table top in-terface, but required specific voice commands fromone user only, and did not spontaneously follow aconversation as the ACLD does.2 Description of the ACLDThe architecture of the ACLD comprises modulesfor: (1) document preparation and indexing; (2) in-put sensing and query construction; (3) search andintegration of results; (4) user interaction.2.1 Document Preparation and IndexingThe preparation of the local database of documentsavailable for search requires text extraction fromvarious file formats (like MS Office or PDF), and350document indexing, here using Apache Lucene.
Pastmeetings, when available, are automatically tran-scribed, then chunked into smaller units, and in-dexed along with the other documents.
For search-ing the Web, the system does not build indexes butuses the Google Search API.2.2 Sensing the User?s Information NeedsThe ACLD uses the AMI real-time ASR system forEnglish (Garner and al., 2009), which has an ac-ceptable accuracy for use with conversational speechin the ACLD.
When processing past recordings, theASR system can run slower than real-time to maxi-mize its accuracy.
If one or more pre-specified key-words (based on domain knowledge) are detected inthe ASR output, then their importance is increasedfor searching.
Otherwise, all the words from theASR (except stopwords) are used for constructingthe query.2.3 Querying the Document DatabaseThe Query Aggregator component uses the ASRwords in order to retrieve the most relevant docu-ments from a given database.
The latest versionof the ACLD makes use of semantic search (seebelow), but earlier versions used keyword-basedsearch from Apache Lucene for local documents.Queries are formulated and launched at regular timeintervals, typically every 15-30 seconds, or on de-mand.
The search results are integrated with previ-ous ones, using a persistence model that smoothesvariations in time by keeping track of the salience ofeach result.
Salience is initialized from the rankingof search results, then decreases in time, or increasesif the document appears again among results.
A his-tory of all results is also accessible.2.4 Semantic Search over WikipediaThe goal of semantic search is to improve the rel-evance of results with respect to the spoken words,and to make search more robust to noise from ASR.The method used here is adapted from a graph-basedmeasure of semantic relatedness between text frag-ments (Yazdani and Popescu-Belis, 2010).
Related-ness is computed using random walk in a large net-work of documents, here about 1.2 milion Wikipediaarticles from the WEX data set (Metaweb Technolo-gies, 2010).
These are linked by directional hy-Figure 1: Unobtrusive UI of the ACLD displaying docu-ment results.
The pop-up window shows more details forthe first results.perlinks, and also by lexical similarity links thatwe construct upon initialization.
The random walkmodel allows the computation of the visiting proba-bility (VP) from one document to another, and thenof the VP between sets of documents.
This functionsas a measure of semantic relatedness, and has beenapplied to several NLP problems by projecting thetext fragments to be compared onto the documentsin the network (Yazdani and Popescu-Belis, 2010).For the ACLD, the use of semantic relatedness fordocument retrieval amounts to searching, in a verylarge collection, the documents that are the mostclosely related to the words obtained from the ASRin a given time frame.
Here, we set the documentcollection to Wikipedia (WEX).
As the search ishard to perform in real time, we made a series ofjustified approximations to make it tractable.2.5 The User InterfaceThe goal of the UI is to make ACLD informationavailable in a configurable way, allowing users tosee more or less information according to their ownneeds.
The UI displays up to four widgets, whichcan be arranged at will, and contain: (1) ASR wordswith highlighted keywords; (2) tag-cloud of key-words, coding for recency and frequency; (3) linksto the current results from the local repository; (4)links to the current Web search results.Two main arrangements are intended: an infor-mative full-screen UI (not shown here from lack ofspace) and an unobtrusive UI, with superposed tabs,shown in Figure 1 with the document result widget.When hovering over a document name, a pop-upwindow displays metadata and document excerptsthat match words from the query, as an explanationfor why the document was retrieved.3513 Evaluation of the ACLDFour types of evidence for the relevance and util-ity of the ACLD are summarized here.
Firstly, theACLD was demonstrated to about 50 potential users(industrial partners, focus groups, etc.
), who foundthe concept useful, and offered positive verbal eval-uation, along with suggestions for smaller and largerimprovements.Secondly, a pilot experiment was conducted witha group using an earlier version of the UI.
Two pilotruns have shown that the ACLD was consulted aboutfive times per meeting, but many more runs are (still)needed for statistical significance of observations.Thirdly, the UI was tested in a usability evaluationexperiment with nine non-technical subjects, whorated it as ?acceptable?
(68%) on the System Usabil-ity Scale, following a series of tasks they had to per-form using it.
Additional suggestions for changeswere received.Finally, we compared offline the results of seman-tic search with the keyword-based ones.
We askedeight subjects to read a series of nine meeting frag-ments, and to decide which of the two results wasthe most useful one (they could also answer ?none?
).Of a total of 36 snippets, each seen by two subjects,there was agreement on 23 (64%) snippets and dis-agreement on 13 (36%).
In fact, if ?none?
is ex-cluded, there were only 7 true disagreements.
Overthe 23 snippets on which the subjects agreed, theresult of semantic search was judged more relevantthan that of keyword search for 19 (53% of the to-tal), and the reverse for 4 only (11%).
Alternatively,if one counts the votes cast by subjects in favor ofeach system, regardless of agreement, then semanticsearch received 72% of the votes and keyword-basedonly 28%.
Hence, semantic search already outper-forms keyword based one.4 ConclusionThe ACLD is, to the best of our knowledge, thefirst just-in-time retrieval system to use spontaneousspeech and to support access to multimedia doc-uments and to websites, using a robust semanticsearch method.
Future work should aim at improv-ing the relevance of semantic search, at modelingcontext to improve the timing of results, and at in-ferring relevance feedback from users.
The ACLDshould also be applied to specific use cases, and anexperiment with group discussions in a learning en-vironment is under way.AcknowledgmentsWe are grateful to the EU AMI and AMIDA Inte-grated Projects and to the Swiss IM2 NCCR (In-teractive Multimodal Information Management) forsupporting the development of the ACLD.ReferencesJay Budzik and Kristian J. Hammond.
2000.
User inter-actions with everyday applications as context for just-in-time information access.
In IUI 2000 (5th Interna-tional Conference on Intelligent User Interfaces), NewOrleans, LA.Susan Dumais, Edward Cutrell, Raman Sarin, and EricHorvitz.
2004.
Implicit Queries (IQ) for contextual-ized search.
In SIGIR 2004 (27th Annual ACM SIGIRConference) Demonstrations, page 534, Sheffield.Philip N. Garner and al.
2009.
Real-time ASR frommeetings.
In Interspeech 2009 (10th Annual Confer-ence of the International Speech Communication As-sociation), pages 2119?2122, Brighton.Peter E. Hart and Jamey Graham.
1997.
Query-free in-formation retrieval.
IEEE Expert: Intelligent Systemsand Their Applications, 12(5):32?37.Metaweb Technologies.
2010.
Freebase Wikipedia Ex-traction (WEX).
http://download.freebase.com/wex/.Florian Metze and al.
2006.
The ?Fame?
interactivespace.
In Machine Learning for Multimodal Interac-tion II, LNCS 3869, pages 126?137.
Springer, Berlin.Maria Carmen Puerta Melguizo and al.
2008.
A person-alized recommender system for writing in the Internetage.
In LREC 2008 Workshop on NLP Resources, Al-gorithms, and Tools for Authoring Aids, pages 21?26,Marrakech.Bradley J. Rhodes and Pattie Maes.
2000.
Just-in-timeinformation retrieval agents.
IBM Systems Journal,39(3-4):685?704.Bradley J. Rhodes.
1997.
The Wearable RemembranceAgent: A system for augmented memory.
PersonalTechnologies: Special Issue on Wearable Computing,1:218?224.Majid Yazdani and Andrei Popescu-Belis.
2010.
A ran-dom walk framework to compute textual semantic sim-ilarity: a unified model for three benchmark tasks.
InICSC 2010 (4th IEEE International Conference on Se-mantic Computing), pages 424?429, Pittsburgh, PA.352
