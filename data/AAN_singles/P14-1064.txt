Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 676?686,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsGraph-based Semi-Supervised Learning of Translation Models fromMonolingual DataAvneesh Saluja?Carnegie Mellon UniversityPittsburgh, PA 15213, USAavneesh@cs.cmu.eduHany Hassan, Kristina Toutanova, Chris QuirkMicrosoft ResearchRedmond, WA 98502, USAhanyh,kristout,chrisq@microsoft.comAbstractStatistical phrase-based translation learnstranslation rules from bilingual corpora,and has traditionally only used monolin-gual evidence to construct features thatrescore existing translation candidates.
Inthis work, we present a semi-supervisedgraph-based approach for generating newtranslation rules that leverages bilingualand monolingual data.
The proposed tech-nique first constructs phrase graphs usingboth source and target language mono-lingual corpora.
Next, graph propaga-tion identifies translations of phrases thatwere not observed in the bilingual cor-pus, assuming that similar phrases havesimilar translations.
We report resultson a large Arabic-English system and amedium-sized Urdu-English system.
Ourproposed approach significantly improvesthe performance of competitive phrase-based systems, leading to consistent im-provements between 1 and 4 BLEU pointson standard evaluation sets.1 IntroductionStatistical approaches to machine translation(SMT) use sentence-aligned, parallel corpora tolearn translation rules along with their probabil-ities.
With large amounts of data, phrase-basedtranslation systems (Koehn et al, 2003; Chiang,2007) achieve state-of-the-art results in many ty-pologically diverse language pairs (Bojar et al,2013).
However, the limiting factor in the suc-cess of these techniques is parallel data availabil-ity.
Even in resource-rich languages, learning re-liable translations of multiword phrases is a chal-lenge, and an adequate phrasal inventory is crucial?This work was done while the first author was interningat Microsoft Researchfor effective translation.
This problem is exacer-bated in the many language pairs for which par-allel resources are either limited or nonexistent.While parallel data is generally scarce, monolin-gual resources exist in abundance and are beingcreated at accelerating rates.
Can we use monolin-gual data to augment the phrasal translations ac-quired from parallel data?The challenge of learning translations frommonolingual data is of long standing interest,and has been approached in several ways (Rapp,1995; Callison-Burch et al, 2006; Haghighi etal., 2008; Ravi and Knight, 2011).
Our work in-troduces a new take on the problem using graph-based semi-supervised learning to acquire trans-lation rules and probabilities by leveraging bothmonolingual and parallel data resources.
On thesource side, labeled phrases (those with knowntranslations) are extracted from bilingual corpora,and unlabeled phrases are extracted from mono-lingual corpora; together they are embedded asnodes in a graph, with the monolingual data de-termining edge strengths between nodes (?2.2).Unlike previous work (Irvine and Callison-Burch,2013a; Razmara et al, 2013), we use higher ordern-grams instead of restricting to unigrams, sinceour approach goes beyond OOV mitigation andcan enrich the entire translation model by usingevidence from monolingual text.
This enhance-ment alone results in an improvement of almost1.4 BLEU points.
On the target side, phrases ini-tially consisting of translations from the paralleldata are selectively expanded with generated can-didates (?2.1), and are embedded in a target graph.We then limit the set of translation options foreach unlabeled source phrase (?2.3), and usinga structured graph propagation algorithm, wheretranslation information is propagated from la-beled to unlabeled phrases proportional to bothsource and target phrase similarities, we esti-mate probability distributions over translations for676Source!
Target!el gato!los gatos!un gato!
cat!the cat!
the cats!a cat!Target!
Prob.
!the cat!
0.7!cat!
0.15!?!
?!felino!canino!
el perro!Target!
Prob.!canine!
0.6!dog!
0.3!?!
?!Target!
Prob.
!the cats!
0.8!cats!
0.1!?!
?!Target!
Prob.
!the dog!
0.9!dog!
0.05!?!
?
!canine!dog!the dog!catlike!Figure 1: Example source and target graphs used in our approach.
Labeled phrases on the source side are black (with theircorresponding translations on the target side also black); unlabeled and generated (?2.1) phrases on the source and target sidesrespectively are white.
Labeled phrases also have conditional probability distributions defined over target phrases, which areextracted from the parallel corpora.the unlabeled source phrases (?2.4).
The addi-tional phrases are incorporated in the SMT sys-tem through a secondary phrase table (?2.5).
Weevaluated the proposed approach on both Arabic-English and Urdu-English under a range of sce-narios (?3), varying the amount and type of mono-lingual corpora used, and obtained improvementsbetween 1 and 4 BLEU points, even when usingvery large language models.2 Generation & PropagationOur goal is to obtain translation distributions forsource phrases that are not present in the phrasetable extracted from the parallel corpus.
Both par-allel and monolingual corpora are used to obtainthese probability distributions over target phrases.We assume that sufficient parallel resources ex-ist to learn a basic translation model using stan-dard techniques, and also assume the availabilityof larger monolingual corpora in both the sourceand target languages.
Although our technique ap-plies to phrases of any length, in this work we con-centrate on unigram and bigram phrases, whichprovides substantial computational cost savings.Monolingual data is used to construct separatesimilarity graphs over phrases (word sequences),as illustrated in Fig.
1.
The source similarity graphconsists of phrase nodes representing sequences ofwords in the source language.
If a source phraseis found in the baseline phrase table it is called alabeled phrase: its conditional empirical probabil-ity distribution over target phrases (estimated fromthe parallel data) is used as the label, and is sub-sequently never changed.
Otherwise it is called anunlabeled phrase, and our algorithm finds labels(translations) for these unlabeled phrases, with thehelp of the graph-based representation.
The la-bel space is thus the phrasal translation inventory,and like the source side it can also be representedin terms of a graph, initially consisting of targetphrase nodes from the parallel corpus.For the unlabeled phrases, the set of possibletarget translations could be extremely large (e.g.,all target language n-grams).
Therefore, we firstgenerate and fix a list of possible target transla-tions for each unlabeled source phrase.
We thenpropagate by deriving a probability distributionover these target phrases using graph propagationtechniques.
Next, we will describe the generation,graph construction and propagation steps.2.1 GenerationThe objective of the generation step is to popu-late the target graph with additional target phrasesfor all unlabeled source phrases, yielding the fullset of possible translations for the phrase.
Prior togeneration, one phrase node for each target phraseoccurring in the baseline phrase table is added tothe target graph (black nodes in Fig.
1?s targetgraph).
We only consider target phrases whosesource phrase is a bigram, but it is worth notingthat the target phrases are of variable length.The generation component is based on the ob-servation that for structured label spaces, such astranslation candidates for source phrases in SMT,even similar phrases have slightly different labels(target translations).
The exponential dependence677of the sizes of these spaces on the length of in-stances is to blame.
Thus, the target phrase inven-tory from the parallel corpus may be inadequatefor unlabeled instances.
We therefore need to en-rich the target or label space for unknown phrases.A na?
?ve way to achieve this goal would be to ex-tract all n-grams, from n = 1 to a maximum n-gram order, from the monolingual data, but thisstrategy would lead to a combinatorial explosionin the number of target phrases.Instead, by intelligently expanding the targetspace using linguistic information such as mor-phology (Toutanova et al, 2008; Chahuneau et al,2013), or relying on the baseline system to gener-ate candidates similar to self-training (McCloskyet al, 2006), we can tractably propose novel trans-lation candidates (white nodes in Fig.
1?s targetgraph) whose probabilities are then estimated dur-ing propagation.
We refer to these additional can-didates as ?generated?
candidates.To generate new translation candidates usingthe baseline system, we decode each unlabeledsource bigram to generate its m-best translations.This set of candidate phrases is filtered to includeonly n-grams occurring in the target monolingualcorpus, and helps to prune passed-through OOVwords and invalid translations.
To generate newtranslation candidates using morphological infor-mation, we morphologically segment words intoprefixes, stem, and suffixes using linguistic re-sources.
We assume that a morphological ana-lyzer which provides context-independent analysisof word types exists, and implements the functionsSTEM(f ) and STEM(e) for source and target wordtypes.
Based on these functions, source and targetsequences of words can be mapped to sequencesof stems.
The morphological generation step addsto the target graph all target word sequences fromthe monolingual data that map to the same stemsequence as one of the target phrases occurring inthe baseline phrase table.
In other words, this stepadds phrases that are morphological variants of ex-isting phrases, differing only in their affixes.2.2 Graph ConstructionAt this stage, there exists a list of source bigramphrases, both labeled and unlabeled, as well as alist of target language phrases of variable length,originating from both the phrase table and the gen-eration step.
To determine pairwise phrase similar-ities in order to embed these nodes in their graphs,we utilize the monolingual corpora on both thesource and target sides to extract distributionalfeatures based on the context surrounding eachphrase.
For a phrase, we look at the pwords beforeand the p words after the phrase, explicitly distin-guishing between the two sides, but not distance(i.e., bag of words on each side).
Co-occurrencecounts for each feature (context word) are accu-mulated over the monolingual corpus, and thesecounts are converted to pointwise mutual infor-mation (PMI) values, as is standard practice whencomputing distributional similarities.
Cosine sim-ilarity between two phrases?
PMI vectors is usedfor similarity, and we take only the k most simi-lar phrases for each phrase, to create a k-nearestneighbor similarity matrix for both source and tar-get language phrases.
These graphs are distinct,in that propagation happens within the two graphsbut not between them.While accumulating co-occurrence counts foreach phrase, we also maintain an inverted indexdata structure, which is a mapping from features(context words) to phrases that co-occur with thatfeature within a window of p.1The inverted indexstructure reduces the graph construction cost from?
(n2), by only computing similarities for a sub-set of all possible pairs of phrases, namely otherphrases that have at least one feature in common.2.3 Candidate Translation List ConstructionAs mentioned previously, we construct and fixa set of translation candidates, i.e., the label setfor each unlabeled source phrase.
The probabil-ity distribution over these translations is estimatedthrough graph propagation, and the probabilitiesof items outside the list are assumed to be zero.We obtain these candidates from two sources:21.
The union of each unlabeled phrase?s la-beled neighbors?
labels, which represents theset of target phrases that occur as transla-tions of source phrases that are similar tothe unlabeled source phrase.
For un gato inFig.
1, this source would yield the cat andcat, among others, as candidates.2.
The generated candidates for the unlabeledphrase ?
the ones from the baseline system?s1The q most frequent words in the monolingual corpuswere removed as keys from this mapping, as these high en-tropy features do not provide much information.2We also obtained the k-nearest neighbors of the transla-tion candidates generated through these methods by utilizingthe target graph, but this had minimal impact.678decoder output, or from a morphological gen-erator (e.g., a cat and catlike in Fig.
1).The morphologically-generated candidates for agiven source unlabeled phrase are initially de-fined as the target word sequences in the mono-lingual data that have the same stem sequenceas one of the baseline?s target translations for asource phrase which has the same stem sequenceas the unlabeled source phrase.
These candidatesare scored using stem-level translation probabili-ties, morpheme-level lexical weighting probabili-ties, and a language model, and only the top 30candidates are included.After obtaining candidates from these two pos-sible sources, the list is sorted by forward lexicalscore, using the lexical models of the baseline sys-tem.
The top r candidates are then chosen for eachphrase?s translation candidate list.In Figure 2 we provide example outputs ofour system for a handful of unlabeled sourcephrases, and explicitly note the source of the trans-lation candidate (?G?
for generated, ?N?
for labeledneighbor?s label).2.4 Graph PropagationA graph propagation algorithm transfers label in-formation from labeled nodes to unlabeled nodesby following the graph?s structure.
In some appli-cations, a label may consist of class membershipinformation, e.g., each node can belong to one ofa certain number of classes.
In our problem, the?label?
for each node is actually a probability dis-tribution over a set of translation candidates (targetphrases).
For a given node f , let e refer to a can-didate in the label set for node f ; then in graphpropagation, the probability of candidate e givensource phrase f in iteration t + 1 is:Pt+1(e|f) =Xj2N (f)Ts(j|f)Pt(e|j) (1)where the setN (f) contains the (labeled and unla-beled) neighbors of node f , and Ts(j|f) is a termthat captures how similar nodes f and j are.
Thisquantity is also known as the propagation proba-bility, and its exact form will depend on the typeof graph propagation algorithm used.
For our pur-poses, node f is a source phrasal node, the setN (f) refers to other source phrases that are neigh-bors of f (restricted to the k-nearest neighbors asin ?2.2), and the aim is to estimate P (e|f), theprobability of target phrase e being a phrasal trans-lation of source phrase f .A classic propagation algorithm that has beensuitably modified for use in bilingual lexicon in-duction (Tamura et al, 2012; Razmara et al, 2013)is the label propagation (LP) algorithm of Zhu etal.
(2003).
In this case, Ts(f, j) is chosen to be:Ts(j|f) =wsf,jPj02N (f)wsf,j0(2)where wsf,jis the cosine similarity (as computedin ?2.2) between phrase f and phrase j on side s(the source side).As evident in Eq.
2, LP only takes into accountsource language similarity of phrases.
To see thisobservation more clearly, let us reformulate Eq.
1more generally as:Pt+1(e|f) =Xj2N (f)Ts(j|f)Xe02H(j)Tt(e0|e)Pt(e0|j) (3)where H(j) is the translation candidate set forsource phrase j, and Tt(e0|e) is the propagationprobability between nodes or phrases e and e0on the target side.
We have simply replacedPt(e|j) withPe02H(j)Tt(e0|e)Pt(e0|j), defining itin terms of j?s translation candidate list.Note that in the original LP formulation the tar-get side information is disregarded, i.e., Tt(e0|e) =1 if and only if e = e0and 0 otherwise.
As aresult, LP is suboptimal for our needs, since it isunable to appropriately handle generated transla-tion candidates for the unlabeled phrases.
Thesetranslation candidates are usually not present astranslations for the labeled phrases (or for the la-beled phrases that neighbor the unlabeled one inquestion).
When propagating information fromthe labeled phrases, such candidates will obtainno probability mass since e 6= e0.
Thus, due tothe setup of the problem, LP naturally biases awayfrom translation candidates produced during thegeneration step (?2.1).2.4.1 Structured Label PropagationThe label set we are considering has a similaritystructure encoded by the target graph.
How canwe exploit this structure in graph propagation onthe source graph?
In Liu et al (2012), the authorsgeneralize label propagation to structured labelpropagation (SLP) in an effort to work more el-egantly with structured labels.
In particular, thedefinition of target similarity is similar to that ofsource similarity:Tt(e0|e) =wte,e0Pe002H(j)wte,e00(4)679Therefore, the final update equation in SLP is:Pt+1(e|f) =Xj2N (f)Ts(j|f)Xe02H(j)Tt(e0|e)Pt(e0|j) (5)With this formulation, even if e 6= e0, the simi-larity Tt(e0|e) as determined by the target phrasegraph will dictate propagation probability.
We re-normalize the probability distributions after eachpropagation step to sum to one over the fixed listof translation candidates, and run the SLP algo-rithm to convergence.32.5 Phrase-based SMT ExpansionAfter graph propagation, each unlabeled phraseis labeled with a categorical distribution overthe set of translation candidates defined in ?2.3.In order to utilize these newly acquired phrasepairs, we need to compute their relevant features.The phrase pairs have four log-probability fea-tures with two likelihood features and two lexicalweighting features.
In addition, we use a sophis-ticated lexicalized hierarchical reordering model(HRM) (Galley and Manning, 2008) with five fea-tures for each phrase pair.We utilize the graph propagation-estimated for-ward phrasal probabilities P(e|f) as the forwardlikelihood probabilities for the acquired phrases;to obtain the backward phrasal probability for agiven phrase pair, we make use of Bayes?
Theo-rem:P(f |e) =P(e|f)P(f)P(e)where the marginal probabilities of source and tar-get phrases e and f are obtained from the countsextracted from the monolingual data.
The baselinesystem?s lexical models are used for the forwardand backward lexical scores.
The HRM probabil-ities for the new phrase pairs are estimated fromthe baseline system by backing-off to the averagevalues for phrases with similar length.3 EvaluationWe performed an extensive evaluation to exam-ine various aspects of the approach along withoverall system performance.
Two language pairswere used: Arabic-English and Urdu-English.
TheArabic-English evaluation was used to validate thedecisions made during the development of our3Empirically within a few iterations and a wall-clock timeof less than 10 minutes in total.method and also to highlight properties of thetechnique.
With it, in ?3.2 we first analyzed theimpact of utilizing phrases instead of words andSLP instead of LP; the latter experiment under-scores the importance of generated candidates.
Wealso look at how adding morphological knowledgeto the generation process can further enrich per-formance.
In ?3.3, we then examined the effect ofusing a very large 5-gram language model train-ing on 7.5 billion English tokens to understand thenature of the improvements in ?3.2.
The Urdu toEnglish evaluation in ?3.4 focuses on how noisyparallel data and completely monolingual (i.e., noteven comparable) text can be used for a realisticlow-resource language pair, and is evaluated withthe larger language model only.
We also exam-ine how our approach can learn from noisy paralleldata compared to the traditional SMT system.Baseline phrasal systems are used both for com-parison and for generating translation candidatesfor unlabeled phrases as described in ?2.1.
Thebaseline is a state-of-the-art phrase-based system;we perform word alignment using a lexicalizedhidden Markov model, and then the phrase ta-ble is extracted using the grow-diag-finalheuristic (Koehn et al, 2003).
The 13 baselinefeatures (2 lexical, 2 phrasal, 5 HRM, and 1 lan-guage model, word penalty, phrase length featureand distortion penalty feature) were tuned usingMERT (Och, 2003), which is also used to tunethe 4 feature weights introduced by the secondaryphrase table (2 lexical and 2 phrasal, other fea-tures being shared between the two tables).
Forall systems, we use a distortion limit of 4.
We usecase-insensitive BLEU (Papineni et al, 2002) toevaluate translation quality.3.1 DatasetsBilingual corpus statistics for both language pairsare presented in Table 2.
For Arabic-English, ourtraining corpus consisted of 685k sentence pairsfrom standard LDC corpora4.
The NIST MT06and MT08 Arabic-English evaluation sets (com-bining the newswire and weblog domains for bothsets), with four references each, were used astuning and testing sets respectively.
For Urdu-English, the training corpus was provided by theLDC for the NIST Urdu-English MT evaluation,and most of the data was automatically acquiredfrom the web, making it quite noisy.
After fil-tering, there are approximately 65k parallel sen-4LDC2007T08 and LDC2008T09680Parameter Description Valuem m-best candidate list size when bootstrapping candidates in generation stage.
100p Window size on each side when extracting features for phrases.
2q Filter the q most frequent words when storing the inverted index data structure for graph construction.Both source and target sides share the same value.25k Number of neighbors stored for each phrase for both source and target graphs.
This parameter controlsthe sparsity of the graph.500r Maximum size of translation candidate list for unlabeled phrases.
20Table 1: Parameters, explanation of their function, and value chosen.tences; these were supplemented by an additional100k dictionary entries.
Tuning and test data con-sisted of the MT08 and MT09 evaluation corpora,once again a mixture of news and web text.Corpus Sentences Words (Src)Ar-En Train 685,502 17,055,168Ar-En Tune (MT06) 1,664 33,739Ar-En Test (MT08) 1,360 42,472Ur-En Train 165,159 1,169,367Ur-En Tune (MT08) 1,864 39,925Ur-En Test (MT09) 1,792 39,922Table 2: Bilingual corpus statistics for the Arabic-Englishand Urdu-English datasets used.Table 3 contains statistics for the monolingualcorpora used in our experiments.
From these cor-pora, we extracted all sentences that contained atleast one source or target phrase match to com-pute features for graph construction.
For the Ara-bic to English experiments, the monolingual cor-pora are taken from the AFP Arabic and EnglishGigaword corpora and are of a similar date rangeto each other (1994-2010), rendering them compa-rable but not sentence-aligned or parallel.Corpus Sentences WordsAr Comparable 10.2m 290mEn I Comparable 29.8m 900mUr Noisy Parallel 470k 5mEn II Noisy Parallel 470k 4.7mUr Non-Comparable 7m 119mEn II Non-Comparable 17m 510mTable 3: Monolingual corpus statistics for the Arabic-Englishand Urdu-English evaluations.
The monolingual corpora canbe sub-divided into comparable, noisy parallel, and non-comparable components.
En I refers to the English side ofthe Arabic-English corpora, and En II to the English side ofthe Urdu-English corpora.For the Urdu-English experiments, completelynon-comparable monolingual text was used forgraph construction; we obtained the Urdu sidethrough a web-crawler, and a subset of the AFPGigaword English corpus was used for English.
Inaddition, we obtained a corpus from the ELRA5,which contains a mix of parallel and monolingualdata; based on timestamps, we extracted a compa-rable English corpus for the ELRA Urdu monolin-gual data to form a roughly 470k-sentence ?noisyparallel?
set.
We used this set in two ways: ei-ther to augment the parallel data presented in Table2, or to augment the non-comparable monolingualdata in Table 3 for graph construction.For the parameters introduced throughout thetext, we present in Table 1 a reminder of their in-terpretation as well as the values used in this work.3.2 Experimental VariationsIn our first set of experiments, we looked at the im-pact of choosing bigrams over unigrams as our ba-sic unit of representation, along with performanceof LP (Eq.
2) compared to SLP (Eq.
4).
Re-call that LP only takes into account source sim-ilarity; since the vast majority of generated can-didates do not occur as labeled neighbors?
labels,restricting propagation to the source graph dras-tically reduces the usage of generated candidatesas labels, but does not completely eliminate it.
Inthese experiments, we utilize a reasonably-sized4-gram language model trained on 900m Englishtokens, i.e., the English monolingual corpus.Table 4 presents the results of these variations;overall, by taking into account generated candi-dates appropriately and using bigrams (?SLP 2-gram?
), we obtained a 1.13 BLEU gain on thetest set.
Using unigrams (?SLP 1-gram?)
actu-ally does worse than the baseline, indicating theimportance of focusing on translations for sparserbigrams.
While LP (?LP 2-gram?)
does reason-ably well, its underperformance compared to SLPunderlines the importance of enriching the trans-lation space with generated candidates and han-dling these candidates appropriately.6In ?SLP-5ELRA-W00386It is relatively straightforward to combine both unigramsand bigrams in one source graph, but for experimental claritywe did not mix these phrase lengths.681HalfMono?, we use only half of the monolingualcomparable corpora, and still obtain an improve-ment of 0.56 BLEU points, indicating that addingmore monolingual data is likely to improve thesystem further.
Interestingly, biasing away fromgenerated candidates using all the monolingualdata (?LP 2-gram?)
performs similarly to usinghalf the monolingual corpora and handling gener-ated candidates properly (?SLP-HalfMono?
).BLEUSetup Tune TestBaseline 39.33 38.09SLP 1-gram 39.47 37.85LP 2-gram 40.75 38.68SLP 2-gram 41.00 39.22SLP-HalfMono 2-gram 40.82 38.65SLP+Morph 2-gram 41.02 39.35Table 4: Results for the Arabic-English evaluation.
The LPvs.
SLP comparison highlights the importance of target sideenrichment via translation candidate generation, 1-gram vs.2-gram comparisons highlight the importance of emphasiz-ing phrases, utilizing half the monolingual data shows sensi-tivity to monolingual corpus size, and adding morphologicalinformation results in additional improvement.Additional morphologically generated candi-dates were added in this experiment as detailed in?2.3.
We used a simple hand-built Arabic morpho-logical analyzer that segments word types basedon regular expressions, and an English lexicon-based morphological analyzer.
The morphologicalcandidates add a small amount of improvement,primarily by targeting genuine OOVs.3.3 Large Language Model EffectIn this set of experiments, we examined if theimprovements in ?3.2 can be explained primar-ily through the extraction of language model char-acteristics during the semi-supervised learningphase, or through orthogonal pieces of evidence.Would the improvement be less substantial had weused a very large language model?To answer this question we trained a 5-gramlanguage model on 570M sentences (7.6B tokens),with data from various sources including the Gi-gaword corpus7, WMT and European Parliamen-tary Proceedings8, and web-crawled data fromWikipedia and the web.
Only m-best generatedcandidates from the baseline were considered dur-ing generation, along with labeled neighbors?
la-bels.7LDC2011T078http://www.statmt.org/wmt13/BLEUSetup Tune TestBaseline+LargeLM 41.48 39.86SLP+LargeLM 42.82 41.29Table 5: Results with the large language model scenario.
Thegains are even better than with the smaller language model.Table 5 presents the results of using this lan-guage model.
We obtained a robust, 1.43-BLEUpoint gain, indicating that the addition of thenewly induced phrases provided genuine transla-tion improvements that cannot be compensated bythe language model effect.
Further examination ofthe differences between the two systems yieldedthat most of the improvements are due to betterbigrams and trigrams, as indicated by the break-down of the BLEU score precision per n-gram,and primarily leverages higher quality generatedcandidates from the baseline system.
We analyzethe output of these systems further in the outputanalysis section below (?3.5).3.4 Urdu-EnglishIn order to evaluate the robustness of these resultsbeyond one language pair, we looked at Urdu-English, a low resource pair likely to benefit fromthis approach.
In this set of experiments, we usedthe large language model in ?3.3, and only usedbaseline-generated candidates.
We experimentedwith two extreme setups that differed in the dataassumed parallel, from which we built our base-line system, and the data treated as monolingual,from which we built our source and target graphs.In the first setup, we use the noisy paralleldata for graph construction and augment the non-comparable corpora with it:?
parallel: ?Ur-En Train??
Urdu monolingual: ?Ur Noisy Parallel?+?UrNon-Comparable??
English monolingual: ?En II Noisy Paral-lel?+?En II Non-Comparable?The results from this setup are presented as ?Base-line?
and ?SLP+Noisy?
in Table 6.
In the secondsetup, we train a baseline system using the data inTable 2, augmented with the noisy parallel text:?
parallel: ?Ur-En Train?+?Ur Noisy Paral-lel?+?En II Noisy Parallel??
Urdu monolingual: ?Ur Non-Comparable??
English monolingual: ?En II Non-Comparable?682!Ex Source Reference Baseline System 1 (Ar) !???#$#"!
%$??"
!
sending reinforcements strong reinforcements sending reinforcements (N) 2 (Ar)  !???$??'!+!!
with extinction OOV with extinction (N) 3 (Ar) !???#??
???
!
thwarts address  thwarted (N) 4 (Ar) !??
??
?# !
was quoted as saying attributed to was quoted as saying (G) 5 (Ar) ????"!
??!
$#?
?& !
abdalmahmood said he said abdul mahmood  mahmood said (G) 6 (Ar)  ?#"!
?????
it deems OOV it deems (G) 7 (Ur) !?"!
?$ !
I am hopeful this hope I am hopeful (N) 8 (Ur) ??!
$??
?$ !
to defend him to defend to defend himself (G) 9 (Ur) !???
????
!
while speaking In the  in conversation (N)Figure 2: Nine example outputs of our system vs. the baseline highlighting the properties of our approach.
Each example islabeled (Ar) for Arabic source or (Ur) for Urdu source, and system candidates are labeled with (N) if the candidate unlabeledphrase?s labeled neighbor?s label, or (G) if the candidate was generated.The results from this setup are presented as ?Base-line+Noisy?
and ?SLP?
in Table 6.
The two setupsallow us to examine how effectively our methodcan learn from the noisy parallel data by treating itas monolingual (i.e., for graph construction), com-pared to treating this data as parallel, and also ex-amines the realistic scenario of using completelynon-comparable monolingual text for graph con-struction as in the second setup.BLEUSetup Tune TestBaseline 21.87 21.17SLP+Noisy 26.42 25.38Baseline+Noisy 27.59 27.24SLP 28.53 28.43Table 6: Results for the Urdu-English evaluation evaluatedwith BLEU.
All experiments were conducted with the largerlanguage model, and generation only considered the m-bestcandidates from the baseline system.In the first setup, we get a huge improvement of4.2 BLEU points (?SLP+Noisy?)
when using themonolingual data and the noisy parallel data forgraph construction.
Our method obtained muchof the gains achieved by the supervised baselineapproach that utilizes the noisy parallel data inconjunction with the NIST-provided parallel data(?Baseline+Noisy?
), but with fewer assumptionson the nature of the corpora (monolingual vs.parallel).
Furthermore, despite completely un-aligned, non-comparable monolingual text on theUrdu and English sides, and a very large languagemodel, we can still achieve gains in excess of1.2 BLEU points (?SLP?)
in a difficult evaluationscenario, which shows that the technique adds agenuine translation improvement over and abovena?
?ve memorization of n-gram sequences.3.5 Analysis of OutputFigure 2 looks at some of the sample hypothesesproduced by our system and the baseline, alongwith reference translations.
The outputs producedby our system are additionally annotated with theorigin of the candidate, i.e., labeled neighbor?s la-bel (N) or generated (G).The Arabic-English examples are numbered 1to 5.
The first example shows a source bigram un-known to the baseline system, resulting in a sub-optimal translation, while our system proposes thecorrect translation of ?sending reinforcements?.The second example shows a word that was anOOV for the baseline system, while our systemgot a perfect translation.
The third and fourth ex-amples represent bigram phrases with much bet-ter translations compared to backing off to thelexical translations as in the baseline.
The fifthArabic-English example demonstrates the pitfallsof over-reliance on the distributional hypothesis:the source bigram corresponding to the name ?abdalmahmood?
is distributional similar to anothernamed entity ?mahmood?
and the English equiva-lent is offered as a translation.
The distributionalhypothesis can sometimes be misleading.
Thesixth example shows how morphological informa-tion can propose novel candidates: an OOV wordis broken down to its stem via the analyzer andcandidates are generated based on the stem.The Urdu-English examples are numbered 7to 9.
In example 7, the bigram ?par umeed?
(corresponding to ?hopeful?)
is never seen in thebaseline system, which has only seen ?umeed?(?hope?).
By leveraging the monolingual corpusto understand the context of this unlabeled bigram,we can utilize the graph structure to propose a syn-tactically correct form, also resulting in a more flu-ent and correct sentence as determined by the lan-guage model.
Examples 8 & 9 show cases wherethe baseline deletes words or translates them intomore common words e.g., ?conversation?
to ?the?,while our system proposes reasonable candidates.6834 Related WorkThe idea presented in this paper is similar in spiritto bilingual lexicon induction (BLI), where a seedlexicon in two different languages is expandedwith the help of monolingual corpora, primarily byextracting distributional similarities from the datausing word context.
This line of work, initiatedby Rapp (1995) and continued by others (Fungand Yee, 1998; Koehn and Knight, 2002) (interalia) is limited from a downstream perspective, astranslations for only a small number of words areinduced and oftentimes for common or frequentlyoccurring ones only.
Recent improvements to BLI(Tamura et al, 2012; Irvine and Callison-Burch,2013b) have contained a graph-based flavor bypresenting label propagation-based approaches us-ing a seed lexicon, but evaluation is once againdone on top-1 or top-3 accuracy, and the focus ison unigrams.Razmara et al (2013) and Irvine and Callison-Burch (2013a) conduct a more extensive evalua-tion of their graph-based BLI techniques, wherethe emphasis and end-to-end BLEU evaluationsconcentrated on OOVs, i.e., unigrams, and not onenriching the entire translation model.
As withprevious BLI work, these approaches only takeinto account source-side similarity of words; onlymoderate gains (and in the latter work, on a sub-set of language pairs evaluated) are obtained.
Ad-ditionally, because of our structured propagationalgorithm, our approach is better at handling mul-tiple translation candidates and does not need torestrict itself to the top translation.Klementiev et al (2012) propose a method thatutilizes a pre-existing phrase table and a smallbilingual lexicon, and performs BLI using mono-lingual corpora.
The operational scope of their ap-proach is limited in that they assume a scenariowhere unknown phrase pairs are provided (therebysidestepping the issue of translation candidategeneration for completely unknown phrases), andwhat remains is the estimation of phrasal proba-bilities.
In our case, we obtain the phrase pairsfrom the graph structure (and therefore indirectlyfrom the monolingual data) and a separate gener-ation step, which plays an important role in goodperformance of the method.
Similarly, Zhang andZong (2013) present a series of heuristics that areapplicable in a fairly narrow setting.The notion of translation consensus, whereinsimilar sentences on the source side are encour-aged to have similar target language translations,has also been explored via a graph-based approach(Alexandrescu and Kirchhoff, 2009).
Liu et al(2012) extend this method by proposing a novelstructured label propagation algorithm to deal withthe generalization of propagating sets of labelsinstead of single labels, and also integrated in-formation from the graph into the decoder.
Infact, we utilize this algorithm in our propagationstep (?2.4).
However, the former work operatesonly at the level of sentences, and while the latterdoes extend the framework to sub-spans of sen-tences, they do not discover new translation pairsor phrasal probabilities for new pairs at all, butinstead re-estimate phrasal probabilities using thegraph structure and add this score as an additionalfeature during decoding.The goal of leveraging non-parallel data in ma-chine translation has been explored from severaldifferent angles.
Paraphrases extracted by ?pivot-ing?
via a third language (Callison-Burch et al,2006) can be derived solely from monolingualcorpora using distributional similarity (Marton etal., 2009).
Snover et al (2008) use cross-lingualinformation retrieval techniques to find potentialsentence-level translation candidates among com-parable corpora.
In this case, the goal is totry and construct a corpus as close to parallelas possible from comparable corpora, and is afairly different take on the problem we are look-ing at.
Decipherment-based approaches (Ravi andKnight, 2011; Dou and Knight, 2012) have gen-erally taken a monolingual view to the problemand combine phrase tables through the log-linearmodel during feature weight training.5 ConclusionIn this work, we presented an approach thatcan expand a translation model extracted from asentence-aligned, bilingual corpus using a largeamount of unstructured, monolingual data in bothsource and target languages, which leads to im-provements of 1.4 and 1.2 BLEU points overstrong baselines on evaluation sets, and in somescenarios gains in excess of 4 BLEU points.
Inthe future, we plan to estimate the graph structurethrough other learned, distributed representations.AcknowledgmentsThe authors would like to thank Chris Dyer, ArulMenezes, and the anonymous reviewers for theirhelpful comments and suggestions.684ReferencesAndrei Alexandrescu and Katrin Kirchhoff.
2009.Graph-based learning for statistical machine trans-lation.
In Proceedings of Human Language Tech-nologies: The 2009 Annual Conference of the NorthAmerican Chapter of the Association for Compu-tational Linguistics, NAACL-HLT ?09, pages 119?127.
Association for Computational Linguistics,June.Ond?rej Bojar, Christian Buck, Chris Callison-Burch,Christian Federmann, Barry Haddow, PhilippKoehn, Christof Monz, Matt Post, Radu Soricut, andLucia Specia.
2013.
Findings of the 2013 Work-shop on Statistical Machine Translation.
In Pro-ceedings of the Eighth Workshop on Statistical Ma-chine Translation, pages 1?44, Sofia, Bulgaria, Au-gust.
Association for Computational Linguistics.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine trans-lation using paraphrases.
In Proceedings of theHuman Language Technology Conference of theNAACL, Main Conference, pages 17?24, New YorkCity, USA, June.
Association for ComputationalLinguistics.Victor Chahuneau, Eva Schlinger, Noah A. Smith, andChris Dyer.
2013.
Translating into morphologicallyrich languages with synthetic phrases.
In Proc.
ofEMNLP.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
Computational Linguistics, 33(2):201?228,June.Qing Dou and Kevin Knight.
2012.
Large scale deci-pherment for out-of-domain machine translation.
InProceedings of the 2012 Joint Conference on Empir-ical Methods in Natural Language Processing andComputational Natural Language Learning, pages266?275.
Association for Computational Linguis-tics, July.Pascale Fung and Lo Yuen Yee.
1998.
An ir approachfor translating new words from nonparallel, compa-rable texts.
In Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguis-tics and 17th International Conference on Computa-tional Linguistics - Volume 1, ACL ?98, pages 414?420, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Michel Galley and Christopher D. Manning.
2008.
Asimple and effective hierarchical phrase reorderingmodel.
EMNLP ?08, pages 848?856, Stroudsburg,PA, USA.
Association for Computational Linguis-tics.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of ACL-08: HLT, pages 771?779, Columbus, Ohio, June.Association for Computational Linguistics.Ann Irvine and Chris Callison-Burch.
2013a.
Com-bining bilingual and comparable corpora for low re-source machine translation.
In Proceedings of theEighth Workshop on Statistical Machine Transla-tion, pages 262?270, Sofia, Bulgaria, August.
As-sociation for Computational Linguistics.Ann Irvine and Chris Callison-Burch.
2013b.
Su-pervised bilingual lexicon induction with multiplemonolingual signals.
In Proceedings of the 2013Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 518?523, Atlanta,Georgia, June.
Association for Computational Lin-guistics.Alexandre Klementiev, Ann Irvine, Chris Callison-Burch, and David Yarowsky.
2012.
Toward sta-tistical machine translation without parallel corpora.In Proceedings of the 13th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics, pages 130?140, Avignon, France, April.Association for Computational Linguistics.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
InIn Proceedings of ACL Workshop on UnsupervisedLexical Acquisition, pages 9?16.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics on Human Language Technology - Vol-ume 1, NAACL ?03, pages 48?54, Stroudsburg, PA,USA.
Association for Computational Linguistics.Shujie Liu, Chi-Ho Li, Mu Li, and Ming Zhou.
2012.Learning translation consensus with structured la-bel propagation.
In Proceedings of the 50th AnnualMeeting of the Association for Computational Lin-guistics: Long Papers - Volume 1, ACL ?12, pages302?310, Stroudsburg, PA, USA.
Association forComputational Linguistics.Yuval Marton, Chris Callison-Burch, and PhilipResnik.
2009.
Improved statistical machine trans-lation using monolingually-derived paraphrases.
InProceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing, EMNLP?09, pages 381?390, Singapore, August.
Associationfor Computational Linguistics.David McClosky, Eugene Charniak, and Mark John-son.
2006.
Effective self-training for parsing.
InProceedings of the Human Language TechnologyConference of the NAACL, Main Conference, pages152?159, New York City, USA, June.
Associationfor Computational Linguistics.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics - Volume 1, ACL ?03, pages 160?167, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.685Kishore Papineni, Salim Roukos, Todd Ward, and Weijing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
pages 311?318.Reinhard Rapp.
1995.
Identifying word translations innon-parallel texts.
In Proceedings of the 33rd An-nual Meeting of the Association for ComputationalLinguistics, ACL ?95.Sujith Ravi and Kevin Knight.
2011.
Deciphering for-eign language.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies, pages 12?21, Portland, Oregon, USA, June.
Association forComputational Linguistics.Majid Razmara, Maryam Siahbani, Gholamreza Haf-fari, and Anoop Sarkar.
2013.
Graph propagationfor paraphrasing out-of-vocabulary words in statis-tical machine translation.
In Proceedings of the51st of the Association for Computational Linguis-tics, ACL-51, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Matthew Snover, Bonnie Dorr, and Richard Schwartz.2008.
Language and translation model adaptationusing comparable corpora.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, EMNLP ?08, pages 857?866,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.2012.
Bilingual lexicon extraction from compara-ble corpora using label propagation.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, EMNLP-CoNLL ?12,pages 24?36.Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.2008.
Applying morphology generation models tomachine translation.
In Proceedings of ACL-08:HLT, pages 514?522, Columbus, Ohio, June.
Asso-ciation for Computational Linguistics.Jiajun Zhang and Chengqing Zong.
2013.
Learninga phrase-based translation model from monolingualdata with application to domain adaptation.
In Pro-ceedings of the 51st Annual Meeting of the Associa-tion for Computational Linguistics (Volume 1: LongPapers), pages 1425?1434, Sofia, Bulgaria, August.Association for Computational Linguistics.Xiaojin Zhu, Zoubin Ghahramani, and John D. Laf-ferty.
2003.
Semi-supervised learning using gaus-sian fields and harmonic functions.
In Proceedingsof the Twentieth International Conference on Ma-chine Learning, ICML ?03, pages 912?919.686
