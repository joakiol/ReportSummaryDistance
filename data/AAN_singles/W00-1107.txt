REXTOR: A System for Generating Relationsfrom Natural LanguageBoris Katz and J immy LinMIT Artificial Intelligence Laboratory200 Technology SquareCambridge, MA 02139 USA{boris, j immylin}@ai.mit, eduAbst ractThis paper argues that a finite-statelanguage model with a ternary expres-sion representation is currently the mostpractical and suitable bridge betweennatural language processing and infor-mation retrieval.
Despite the theoreti-cal computational inadequacies of finite-state grammars, they are very cost ef-fective (in time and space requirements)and adequate for practical purposes.The ternary expressions that we useare not only linguistically-motivated, butalso amenable to rapid large-scale index-ing.
REXTOR (Relations EXtracTOR) isan implementation f this model; in oneuniform framework, the system providestwo separate grammars for extractingarbitrary patterns of text and buildingternary expressions from them.
Thesecontent representational structures serveas the input to our ternary expressionsindexer.
This approach to natural lan-guage information retrieval promises tosignificantly raise the performance ofcurrent systems.1 In t roduct ionTraditional information retrieval (IR) has beenbuilt on the "bag-of-words" assumption, whichequates the weighted component keywords of adocument with its semantic ontent.
Obviously,a document is much more than the sum of its in-dividual keywords.
Although keywords may offersome indication of "meaning," they alone cannotcapture the richness and expressiveness of natu-ral language.
Consider the following sets of sen-tences/phrases that have similar word content,but (dramatically) different meanings: 1IExamples taken from (Loper, 2000)(1) The big man ate the dog.
(1') The big dog ate the man.
(2) The meaning of life(2') A me~ningfll\] life(3) The bank of the river(3') The bank near the riverDue to the inability of keywords to capture the"meaning" of documents, a traditional informa-tion retrieval system (i.e., one using the bag-of-words paradigm) will suffer from poor precision inresponse to a user query accurately and preciselyformulated in natural anguage.The application of natural language process-ing (NLP) techniques to information retrievalpromises to generate representational structuresthat better capture the semantic ontent of docu-ments.
In particular, syntactic analysis can high-light the relationships between various terms andphrases in a sentence, which will allow us to distin-guish between the example pairs given above andanswer queries with higher precision than tradi-tional IR systems.However, a syntactically-informed representa-tional structure faces the problem of Hnguisticvariations, the phenomenon in which similar se-mantic content may be expressed in different sur-face forms.
Consider the following sets of sen-tences that express the same meaning using dif-ferent constructions:(4) What is Bill Gates' net worth?
(4')What is the net worth of Bill Gates?
(5) John gave the book to Mary.
(5') John gave Mary the book.
(5") Mary was given the book by John.
(6) The president surprised the country withhis actions.
(6') The president's actions surprised thecountry.
(7) Over 22 million people live in Taiwan.
(7') The population of Taiwan is 22 million.An effective linguistically-motivated informa-tion retrieval system must not only handle rel-67atively simple syntactic variations (e.g., (4) and(5)), alternate realization of verb arguments (e.g.,(6) and (6')), but also more complicated semanticvariations (e.g., (7) and (7')).
This can be ac-complished by linguistic normalization, a processby which linguistic variants that contain the samesemantic ontent are mapped onto the same rep-resentational structure.The precision of information retrieval systemscan be dramatically improved if they index notonly single terms, but normelized representationalstructures derived from language.
However, theoptimal structure of this representation a d theefficient generation ofthese structures remains anopen research problem.This paper argues that, for the purposes ofinformation retrieval systems, the most suitablerepresentational structure of document content isternary expressions (compared to, for example,keywords, trees or case frames).
Ternary (three-place) expressions may be thought of as typedbinary relations (e.g., subject-relation-object) ortwo-place predicates (e.g., transitive verbs like'hit'); they are linguistically-motivated an  effi-cient to index.
Also, for information retrieval, afinite-state grammar isthe most practical and costeffective method by which to extract these ternaryexpressions from documents.
Combined together,a finite-state language model and ternary expres-sion representation provide a convenient and pow-erful framework for integrating natural anguageprocessing with information retrieval.REXTOR (Relations EXtracTOR) is a docu-ment content analysis ystem designed to unifyand generalize many previous natural anguageinformation retrieval techniques into one singleframework.
The system provides two separategrammars: one for extracting arbitrary entitiesfrom documents, and the other for building re-lations from the extracted items.
REXTOI~ alsoprovides a playground and testbed for future ex-perimentation in linguistically-motivated indexingschemes.2 Mot ivat ionWe believe that, for humans, natural language isthe best mechanism for information access.
It isintuitive, easy to use, rapidly deployable, and re-quires no specialized training,The REXTOR System builds on the experi-ence of START (SynTactic Analysis using Re-versible Transformations), a natural language sys-tem available for question answering on the WorldWide Web.
2 Since December, 1993, when it first2hZZp :/\[~ww.
ai .mit.
edu/projects/infolabcame online, START has engaged in millions of ex-changes with hundreds of thousands of people allover the world, supplying users with knowledgeregarding eography, weather, movies, and manymany other areas.
Despite the successes of STARTin serving actual users, its domain of knowledge isrelatively small and expanding its knowledge baseis a time-consuming task.
The goal of REXTOR isto overcome this bottleneck and to provide a gen-eral framework for natural-language informationretrieval.
REXTOR not only draws its inspirationfrom START (in providing question answering ca-pabilities), but also borrows a simplified form ofits representational structures (Katz, 1980; Katz,1990).The START System (Katz, 1990; Katz, 1997)analyzes English text and builds a knowledge basefrom information found in the text.
The knowl-edge is expressed in the form of embedded ternaryexpressions (T-expressions) - -  subject-relation-object triples where the subject and object canthemselves be ternary expressions.
For exam-ple, "The population of Zimbabwe is 11,044,147"would be represented astwo ternary expressions:\[POPULATION-1 IS 11044147\]\[POPULATION-1 RELATED-T0 ZIMBABWE\]Experience from START has shown that a robustfull-text natural language question-answering sys-tem cannot be realistically expected any timesoon.
Numerous problems uch as intersenten-tial reference, paraphrasing, summarization, com-mon sense implication, and many more, will takea long time to solve satisfactorily.
In order to by-pass intractable complexities of language, STARTuses computer-analyzable natural language anno-tations, which consist of simplified English sen-tences and phrases, to describe various informa-tion segments (which may be text, images, or evenvideo and other multimedia content).
These nat-ural language annotations serve as metadata andinform START regarding the type of questions thata particular information segment is capable of an-swering (Katz, 1997).
By performing retrieval onnatural anguage annotations, the system is ableto provide knowledge that it may not be able toanalyze itself (either language that is too com-plex or non-textual segments).
Because these an-notations must be manually generated, expand-ing START'S knowledge base is relatively time-intensive.REXTOR attempts to eliminate the need for hu-man involvement during content analysis, and alsoaims to serve as the foundation of a natural lan-guage information retrieval system.
Ultimately,68we hope that REXTOR will serve as a steppingstone towards a comprehensive system capable ofproviding users with "just the right information"to queries posed in natural language.3 P rev ious  WorkThe concept of indexing more than simple key-words is not new; the idea of indexing (partsof) phrases, for example, is more than a decadeold (Fagan, 1987).
Arampatzis (1998) introducedthe phrase retrieval hypothesis, which assertedthat phrases are a better indication of documentcontent han keywords.
Several researchers havealso explored ifferent techniques oflinguistic nor-realization for information retrieval (Strzalkowskiet al, 1996; Zhai et al, 1996; Arampatzis etal., 2000).
The performance improvements wereneither negligible nor dramatic, but despite thelack of any significant breakthroughs, the au-thors affirmed the potential value of linguistically-motivated indexing schemes and the advantagesthey offer over traditional IR.Previous research in linguistically motivatedinformation retrieval concentrated primarily onnoun phrases and their attached prepositionalphrases.
Techniques that involve head/modifierrelations have been tried, e.g., indexing adjec-tive/noun and noun/right adjunct pairs (whichnormalizes variants such as "information re-trievai" and "retrieval of information").
How-ever, there has been little experimentation withother types of linguistic relations, e.g., apposi-tives, predicate nominatives (i.e., the i s -a  rela-tion), predicate adjectives (i.e., the has-propertyrelation), etc.
Furthermore, indexing of wordpairs and phrases in many previous ystems wasaccomplished by converting those representationsinto lexical items and atomic terms, indexed inthe same manner as single words.
The treat-ment of these representational structures using arestrictive bag-of-words paradigm limits the typeof queries that may be formulated.
For example,treating adjective/noun pairs (\[adj., noun\]) as lex-ical atoms renders it impossible to find the equiv-alent of "all big things," corresponding to the pair\[big, *\].The extraction of these relations from docu-ments has been relatively inefficient and unsys-tematic.
One approach is to first parse thedocument using a full-text parser, and then ex-tract interesting relations from the resulting parsetree (Fagan, 1987; Grishman and Sterling, 1993;Loper, 2000).
This approach isslow and inefficientbecause full-text parsing is very time-intensive.Due to current limitations of computational tech-nology, only a small fraction of the informationgathered by a full parser can be efficiently indexed.For the most part, relations that can be effec-tively utilized for information retrieval purposesonly occupy a few nodes of a (possibly dense)parse tree; thus, most of the knowledge gatheredby the parser is thrown away.
Also, extractingnon-linguistic relations from parse trees is verydifficult; many interesting relations (from an IRpoint of view) have no linguistic foundation, e.g.,adjacent word pairs.
The other approach to ex-tracting relations from text is to build simple fil-ters for every new relation.
This approach is un-systematic, and does not allow for rapid additionof new relations to a system.The REXTOR System utilizes an integratedmodel to systematically extract arbitrary textualpatterns and relations (ternary expressions) fromdocuments.
The concept of coupling structure-building actions with parsing originated with aug-mented transition etworks (ATNs)(Thorne t al.,1968; Woods, 1970).
Similarly, PLNLP (Heidorn,1972; Jensen et al, 1993) is a programming lan-guage for writing phrase structure rules that in-clude specific conditions under which the rule canbe applied.
These rules may also be augmentedby structure-building actions that are to be takenwhen the rule is applied.
However, these sys-tems that attempt full-text parsing are less effi-cient for information retrieval applications due tothe long time necessary to generate full linguisticparse trees.
REXTOR was designed with a simplelanguage model and an equally simple, yet expres-sive, representation f "meaning.
"4 Br idg ing  Natura l  Language andIn fo rmat ion  Ret r ieva lIn order to bridge the gap between atural an-guage and information retrieval, natural languagetext must be distilled into a representationalstructure that is amenable to fast, large-scale in-dexing.
We argue that a finite-state model of nat-ural language with ternary expressions is currentlythe most suitable combination for this task.4.1 Finite-State Language ModelDespite its limitations, a finite-state grammarseems to provide the best natural language modelfor information retrieval purposes.
One of themost notable computational inadequacies of thefinite-state model is the absence of a pushdownmechanism to suspend the processing of a con-stituent at a given level while using the samegrammar to process an embedded constituent(Woods, 1970).
Due to this inadequacy, certain69English constructions, such as center embedding,cannot be described by any finite-state gram-mar (Chomsky, 1959a; Chomsky, 1959b).
How-ever, Church (1980) demonstrated that the finite-state language model is adequate to describe aperformance model of language (i.e., constrainedby memory, attention, and other realistic limi-tations) that approximates competence (i.e., lan-guage ability under optimal conditions without re-source constraints).
Many phenomena that can-not be handled by fiuite-state grammars are awk-ward from a psycholinguistic point of view, andhence rarely seen.
More recently, Pereira andWright (1991) developed formal methods of ap-proximating context-free grammars with finite-state grammars, s Thus, for practical purposes,computationally simple finite-state grammars canbe utilized to adequately model natural language.Empirically, the effectiveness of the finite-state language model has been demonstrated inthe Message Understanding Conferences (MUCs),which evaluated information extraction (IE) sys-terns on a variety of domain-specific tasks.
Theconferences have shown that superficial parsingusing finite-state grammars performs better thandeep parsing using context-free grammars (at leastunder the current constraints oftechnology).
TheNYU team switched over from a system that per-formed full parsing (PROTEUS) in MUC-5 (Gr-ishman and Sterling, 1993) to a regular expres-sion matching parser in MUC-6 (Grishman, 1995).Full parsing was slow and error-prone, and theprocess of building a full syntactic analysis in-volved relatively unconstrained search which con-sumed large amounts of both time and space.
Thelonger debug-cycles that resulted from this trans-lated into fewer iterations with which to tune thesystem within a given amount of time.
Further-more, the complexity of a full context-free gram-mar contributed to maintenance problems; com-plex interactions within the grammar preventedrapid updating of the system to handle new con-structions.Finite-state grammars have been used to ex-tract entities such as proper nouns, names, lo-cations, etc., with relatively high precision.
Toa lesser extent, these grammars have proven tobe effective in identifying syntactic onstructionssuch as noun phrases and verb phrases.
FASTUS(Hobbs et al, 1996), the most notable of these sys-tems, is modeled after cascaded, nondeterrninisticfinite-state automata.
The finite-state transduc-ers are "cascaded" in that they are arranged inSHowever, these approximations overgenerate, al-though in predictable, systematic ways.series; each one maps the output structures fromthe previous transducer into structures that com-prise the input to the next transducer.There are many similarities between informa-tion extraction and building effective representa-tional structures for information retrieval.
Bothtasks involve identifying entities (e.g., phrases)and the relationships between those entities.Thus, the application of proven information ex-traction techniques (i.e., finite-state technology)to information retrieval offers promise in raisingthe performance of IR systems.4.2 Ternary ExpressionsTernary (three-place) expressions currently ap-pear to be the most suitable representationalstructure for meaning extracted from text.
Theymay be intuitively viewed as subject-relation-object riples, and can easily express many typesof relations, e.g., subject-verb-object relations,possession relations, etc.
From a syntactic point ofview, ternary expressions may be viewed as typedbinary relations.
Given the binary branching hy-pothesis of linguistic theory, ternary expressionsare theoretically capable of expressing any arbi-trary tree - -  thus, ternary expressions are com-patible with linguistic theory.
From a semanticpoint of view, ternary expressions may be viewedas two-place predicates, and can be manipulatedusing predicate logic.
Finally, ternary expressionsare highly amenable to rapid large-scale indexing,which is a necessary prerequisite of information re-trieval systems.
Although other representationalstructures (e.g., trees or case frames) may be bet-ter adapted for some purposes, they are muchmore difficult to index and retrieve efficiently dueto their size and complexity.In fact, indexing linguistic tree structures hasbeen attempted (Smeaton et al, 1994), with verydisappointing results: precision actually decreaseddue to the inability to handle variations in treestructure (i.e., the same semantic content couldbe expressed using different syntactic structures),and to the poor quality of the full-text natural lan-guage parser, which was also rather slow.
Despiterecent advances, full-text natural language parsersare still relatively error-prone; indexing incorrectparse trees is a source of performance degrada-tion.
Furthermore, matching trees and sub-trees isa computationally intensive task, especially sincefull linguistic parse trees may be relatively deep.Relations are easier to match because they aretypically much simpler than parse trees.
For ex-ample, the tree\[\[shiny happy people \] \[of \[Wonderland\]\]\]70may be "flattened" into three relations:< shiny describes people >< happy describes people >< people related-to Wonderland >Indexing chse frames has also been attempted(Croft and Lewis, 1987; Loper, 2000), but withlimited success.
Full semantic analysis is stillan open research problem, especially in the gen-eral domain.
Since full semantic analysis can-not be performed without full-text parsing, caseframe analysis inherits the unreliability of currentparsers.
Furthermore, semantic analysis requiresextensive knowledge in the lexicon, which is ex-tremely time-intensive to construct.
Finally, dueto the complex structure of case frames, they aremore difficult o store and index than ternary ex-pressions.Since ternary expressions are merely three-placerelations, they may be indexed and retrieved muchin the same way as rows within the table of a rela-tional database; 4 hence, well-known optimizationsfor databases may be applied for extremely highperformance.Previous linguistically-motivated indexingschemes may easily be reformulated using ternaryexpressions.
For example, indexing adjacentword pairs consists of indexing adjacent wordswith the adjacent relation.
In fact, all pairs(e.g., adjective-noun, head-modifier) can bereformulated as ternary expressions by assigninga type to the pair.
This finer granulaxity allowsthe capture of more intricate relations betweenwords in a document.5 The  REXTOR SystemUsing its finite-state language model, the REXTORSystem generates a set of ternary expressionsthat correspond to content of a part-of-speech-tagged input document.
Currently, the Brill Tag-ger (Brill, 1992) (with minor postprocessing) isused for the part-of-speech (POS) tagging.
Therelations construction process consists of two dis-tinct processes, each guided by its own externallyspecified grammar file.
Extraction rules are ap-plied to match arbitrary patterns of text, basedeither on one of thirty-nine POS tags or on exactwords.
Whenever an item is extracted, a corre-sponding relation rule is triggered, which handlesthe actual generation of the ternary expressions(relations).4In fact, our first implementation f a ternary ex-pressions indexer used a SQL database.5.1 Ext rac t ion  Ru lesExtraction rules are used to extract arbitrary pat-terns of text according to a grammar specification.The REXTOR grammar is written as regular ex-pression rules, which are computationally equiv-alent to finite-state automata, s Writing gram-mar rules in this fashion allows for perspicuity,the property whereby permitted types of construc-tions are readily apparent from the rules.
Sucha human-readable formulation simplifies mainte-nance of the grammar.The extraction stage of the REXTOR Systemperforms a no-lookahead left-to-right scan of ev-ery input sentence, identifies the longest match-ing pattern (from any grammar rule), reduces theinput sequence based on the matched rule, andcontinues with the next unmatched word.
If aword cannot be included in any grammar rule, itis skipped.An extraction rule takes the following form:En?ityType := template;The rule can be read as Ent?tyType is definedas template.
A successful match of the pattern intemplate signifies a successfully extracted entity.The template consists of a series of legal tokens,which are shown in Table 1.
In addition, tokenmodifiers (also in Table 1) can alter the meaningof the immediately preceding token.
Tokens sur-rounded by curly braces ({}) are saved as boundvariables, which can be later utilized to build re-lations (ternary expressions).
These variables arereferenced numerically starting at zero (e.g., the0th bound variable).5.2 Relat ion RulesA relation rule is triggered by the successful ex-traction of a particular entity (Ent?tyType).
Therelations grammar directs the construction oftheactual ternary expression.
A relation rule takesthe following form:EntityType :=> <atoml atom2 acorn3>;The EntityType is the trigger for the relation,i.e., the rule is applied whenever a string of thattype is extracted.
The right hand side of the re-lation rule is the ternary expression to be gener-ated, which is a triple composed of three atoms.Valid atoms are shown in Table 2.
They are eitherstring literals or they manipulate the bound vari-ables saved from the extraction process in somemanner.5For an algorithm converting regular expressionsto nondeterministic finite-state automata, please referto (Aho et al, 1988), Chapter 3.71POSPOS \[string\]Enl;il~yType(tokeno I tokenx I .
.
?
)Descr ipt ionThis matches any word tagged as the part-of-speech POS.This matches a specific word (string) of a specific part-of-speech (POS).This matches any extracted string of type EntityType.This expression matches any one of the alternative tokens given withinthe parentheses.
Matches are attempted in the order in which they arewritten, e.g., the first token is tried first.Token Mod i f ie r  Descr ipt ionThis modifier matches zero or more occurrences of the previous token.This modifier matches zero or one occurrence of the previous token.This modifier matches one or more occurrences of the previous token.Table 1: Valid tokens and token modif iers for ext ract ion  rules.Mod i f ie rIn \ ]{~\[Q ,Ent i tyTypel  \[3\] .
.
.
.
( alternativex l alternative21 ?
?
? )'
str ing'Descr ipt ionEvaluates to the nth bound variable of the trigger EntityType,interpreted as a string.Evaluates to the nth bound variable of the trigger EntityType,interpreted as a list of strings.
The extraction rule token insidethe bound variable is stripped of its outermost * or +, and thebound variable is broken into a list according to this pattern.
Forexample, {JJX*} is interpreted as a list of JJX, or adjectives.This expression extracts a bound variable nested inside otherbound variables.
The ith bound variable of trigger FaxtityTypeis extracted; if this item is of type FEntityTypel, then the j thbound variable is extracted (the expression returns fa l se  if theentity types do not match); each comma separated unit is inter-preted in this manner, up to an arbitrary depth.This compound expression evaluates to the disjunction of anarbitrary number of valid atoms (as defined in this table).
Eachalternative is evaluated in a left to right order; the disjunctionevaluates to the first alternative that returns a non-empty string.A literal string.Table 2: Valid atoms for the relat ion rules.Ezt ract ion  Rules:Relat ion Rules:NounGroup := (Pi~.PZIDT)?
{JJX*} {(IflfPXINI~IXIINlfPSII~INS)+};PrepositionalPhrase : = IN {NounGroup} ;ComplexNounGroup := {NounGroup} {PrepositionalPhrase};NounGroup :=> <{0} 'describes ~ \[I\]>;ComplexNounGroup : ffi>< \[0\] ,Nou~Group \[1\]re la ted- to  ~\[I\], PrepositionalPhrase \[0\] ,NounGroup \[1\] >;Figure 1: F.xample of re lat ion and extract ion rules.
(PRPZ is the part-of-speech tag for possessive pronouns,DT for determiners, JJX for adjectives, J JR for comparative adjectives, JJS for superlative adjectives, NNX forsingular or mass nouns, NNS for plural nouns, NNPX for singular proper nouns, NNPS for plural proper nouns, INfor prepositions.
)725.3 ExamplesA few extraction and relation rules are givenin Figure 1.
The first extraction rule definesa NounGroup as a sequence consisting of: anoptional possessive pronoun or determiner, anynumber of adjectives, one or more nouns (ofany type).
Also, the sequence of adjectives issaved as the 0th bound variable, and the se-quence of nouns is saved as the 1st bound vari-able.
The rules for PrepositionalPhrase andComplexNounGroup can be interpreted similarly.Consider the following noun phrase:the big, bad wolf of the dark forestREXTOR recognizes two NounGroups in theabove phrase: the big, bad wolf and the dark for-est.
The corresponding relation rule triggers, andgenerates the following relations:< (big, bad) describes wolf >< (dark) describes forest >Note that the first bound variable in NounGroupis interpreted as a list; thus, the above two re-lations expand into three distinct relations whencompletely enumerated:< big describes wolf >< bad describes wolf >< dark describes forest >The ability to interpret bound variables as a listof strings allows for easy manipulation of repeatedstructure, like textual lists or enumerations.In addition, the entire noun phrase the big, badwolf of the dark/forest will be recognized as aComplexNounGroup.
This will result in the foplowing relation:< wolf related-to forest >The relation rule associated withComplexNounGroup involves extracting nestedbound variables.
The first atom evaluates tothe lth bound variable (a NounGroup) insidethe 0th bound variable inside the trigger itemComplexNounGroup.
The third atom is similarlyevaluated.6 D iscuss ionInformal analysis of documents using REXTOR re-veals that it can potentially serve as an effectiveframework for extracting "meaning" from docu-ments.
In particular, the system is capable ofidentifying the following types of linguistic con-structions and generating relations from them:?
S imple sentences can be extracted bynoting a simple NounGroup VerbGroupNounGroup pattern.
From this, subject-verl>-object (SVO) relations can be derived.?
Predicative nominat ives can be recog-nized by identifying the "be" verb and theNounGroup directly following it.
These con-structions may be useful in establishing onto-logical hierarchies, i.e., is-a trees.?
Predicative adjectives can be recognizedby the "be" verb and a succession of one ormore adjectives (or adjectival phrase).
Theymay provide addition information regardingthe attributes of entities, e.g., has-property.?
Appositives are characteristically offset bycommas and usually contain a single nounphrase; thus, they can be recognized rela-tively easily.
Common in prose, appositivesoffer a wealth of additional information re-garding various entities, e.g., location of sites,age or position of people, etc.?
Prepositional phrases are relatively easyto extract, and may supply valuable relationsthat increase the precision of information re-trieval systems.
Ternary expressions allowfor a better representation of prepositionalphrases (compared to pairs) because they al-low the preposition to more specifically de-termine the type of relation (thus, exampleslike "boat by the water" and "boat underthe water," which have completely differentmeanings, may be indexed separately and dis-tinctly).However, the prepositional phrase attach-ment problem (in the general-domain case)is still an open research topic, and thus posessome problems to content analysis.
Regard-less, for the purposes of information retrieval,it may be acceptable to err on the side of over-generation in considering attachment, i.e.,enumerate all possible relations.
This willno doubt generate a large number of (pos-sibly incorrect) relations, and more researchis required to determine effective methods ofcontrolling this explosion.?
Relative clauses of some types can be iden-tiffed by a finite-state language model.
Theymay supply additional useful SVO relationsfor indexing purposes.We believe that future breakthroughs in natu-ral language information retrieval will occur in thegeneration of meaningful relations.
Although thefinite-state language model of REXTOR is powerful73enough to extract many linguistically interestingconstructions, the approach is not fundamentallynew.
What differentiates our system from pre-vious work such as FASTUS (Hobbs et al, 1996)is that REXTOR not only provides a mechanismfor extraction, but also introduces the paradigmof ternary expressions to capture document con-tent for information retrieval.
The relations viewof natural language documents i highly amenableto integration with information retrieval systems.Through a relations representation, REXTOR isable to distinguish the subtle differences in mean-ing between the pairs of sentences and phrasesgiven in the introduction:(1) The man ate the dog.< man is-subject-of eat >< dog is-object-of eat >(I') The dog ate the man.< man is-object-of eat >< dog is-subject-of eat >(2) The meaning of life< meaning possessive-relation life >(2') A meaningful life< meaningful describes life >(3) The bank of the river< bank possessive-relation river >(3') The bank near the river< bank near-relation river >The ability to extract subject-verb-object re-lations, e.g., (1) and (1'), allows an IR systemto distinguish between two very different state-ments.
Similarly, REXTOR can differentiate be-tween prepositional phrases (2) and adjectivalmodification (2').
Although the system does nothave any notion of semantics (e.g., word sense),syntax may offer crucial clues to meaning in casessuch as (3) and (3').Similarly, REXTOR is capable of performing lin-guistic normalization at the syntactic and mor-phological levels.
Consider these sets of examplesoriginally presented in the introduction:(4) What is Bill Gates' net worth?
(4') What is the net worth of Bill Gates?< "net worth" related-to "Bill Gates" >(5) John gave the book to Mary.
(5') John gave Mary the book.
(5") Mary was given the book by John.< John is-subject-of give >< book is-direct-object-of give >< Mary is-indirect-object-of give >(6) The president surprised the country withhis actions.< president is-subject-of surprise >< country is-object-of surprise >< surprise with actions >(6') The president's actions surprised hiscountry.< actions re la ted- to  president >< actions is-subject-of surprise >< country is-object-of surprise >(7) Over 22 million people live in Waiwan.< "22 million" is-quantity-of people >< people is-subject-of live >< live in Taiwan >(7') The population of Taiwan is 22 million.< population is "22 million" >< population related-to Taiwan >With relations, different surface forms of ex-pressing the "possession relation" may be nor-malized into the same structure, e.g., (4) and(4').
Similarly, alternative surface realization ofthe same verb-headed relation can be recognizedand equated with each other by writing differentextraction rules that generate the same relations,e.g., (5), (5'), and (5").
The process of normal-ization will hopefully lead to greater ecall in in-formation retrieval systems.
Note that (6) and(6') demonstrate a limitation of REXTOR, namelyits inability to deal with alternative r alizations ofverb arguments.
Also, the system does not haveany notion of semantics, and thus is unable toequate two sentences that have the same meaning,e.g., (7) and (7').
Although it is certainly possibleto manually encode such semantic knowledge asextraction and relation rules, this solution is farfrom elegant.A potential solution to this semantic variationsproblem is to borrow the solution employed bySTART.
A ternary expression representation ofnatural language mimics its syntactic organiza-tion, and hence sentences that differ in surfaceform but are close in meaning will not map intothe same structure.
In order to solve this problem,START deploys "S-rules" (Katz and Levin, 1988),which are reversible syntactic/semantic transfor-mational rules that render explicit he relationshipbetween alternate realizations of the same mean-ing.
For example, a buy expression is semanticallyequivalent to a sell expression, except he subjectand indirect objects are exchanged.
Because manyverbs can undergo the same alternations, they canin fact be grouped into verb classes, and hencegoverned by the same S-rules.
Thus, S-rules canbe viewed as metarules applied over ternary ex-pressions.
A similar technique for handling bothsyntactic and semantic variations can be found in(Grishman, 1995; Jacquemin et al, 1997).
Bothutilize metarules (e.g., for passive/active transfor-mation) applied over textual patterns in order togenerate and handle variations.74Below we present a concrete example of howREXTOR could potentially improve the perfor-mance of existing keyword search engines dramat-ically.
We indexed an electronic version of theWorldbook Encyclopedia at the sentence level us-ing the following two techniques:1.
A simple inverted keyword index.
All stop-words are thrown out, and all content wordsare stemmed.
Retrieval was performed bymatching content words in the query withcontent words in the encyclopedia articles.2.
A ternary expressions index using the rela-tions generated by REXTOR.
The grammarwas written to extract possessive relations,description relations (adjective-noun modifi-cation), prepositional relations, subject-verbrelations, and verb-object relations.
Re-trieval was performed by matching ternaryexpressions from the query (extracted using aseparate grammar) with ternary expressionsextracted from the encyclopedia articles.The following shows the results of the keywordsearch engine:Question: What do frogs eat?Answer:(R1) Adult frogs eat mainly insects andother small animals, including earthworms,minnows, and spiders.
(R2) Bow'fms eat mainly other fish, frogs,and crayfish.
(R3) Most cobras eat many kinds of ani-mals, such as frogs, fishes, birds, and varioussmall mammals.
(R4) One group of South American frogsfeeds mainly on other frogs.
(RS) Cranes eat a variety of foods, includingfrogs, fishes, birds, and various small mam-mals.
(R6) Frogs eat many other animals, includ-ing spiders, flies, and worms.
(R7) ...After removing stopwords from the query, oursimple keyword search engine returned 33 resultsthat contain the keywords frog and eat.
How-ever, only (R1), (R4), and (R6) correctly answerthe user query; the other results answer the ques-tion "What eats frogs?"
or otherwise coinciden-tally contain those two terms.
(Apparently, ourpoor frog has more predators than prey.)
A bag-of-words approach fundamentally cannot differen-tiate between a query in which the frog is in thesubject position and a query in which the frog is inthe object position.
However, by parsing subject-verb-object relations using REXTOR, a ternary ex-pressions indexer can effectively filter out irrele-vant results, returning the three correct responses.While indexing relations may potentially ower re-call, due to unanticipated constructions, it has atremendous potential in increasing precision.Furthermore, consider the following queries, inwhich REXTOR would outperform traditional key-word engines:(8) How many South Koreans were recentlyallowed to visit their North Korean rela-tives?
(9) Where did John see Mary?
(10) Regarding what issue did the presidentof Russia criticize China?
(11) Are electronics the biggest export fromJapan to the United States?A traditional search engine using the bag-of-words approach would suffer from poor precisionwhen faced with the above queries.
Many verbstake arguments of the same semantic type, and inmost of these sentences, reordering the verb argu-ments drastically alters their meaning.
For exam-ple, a keyword search engine would not be able todistinguish between a question regarding SouthKoreans visiting North Korea and North Kore-ans visiting South Korea (8) because both querieshave the same keyword content.
Similarly, thekeyword approach would be unable to determinewho did the seeing (9), or who did the criticiz-ing (I0).
Modification relations also pose difllcul-ties to the bag-of-words paradigm, e.g., was it theNorth Korean or South Korean relatives (8)?
Wasit the president of Russia or the president of China(10)?
Furthermore, there are some constructionswhose meaning critically depends on relations be-tween the entities, e.g., (11), because "from X toY" and "from Y to X" usually differ in meaning.The current version of REXTOR is merely apro-totype; thus, we have made minimal attemptsto optimize its processing speed.
On a PentiumIll 933 MHz Linux system with 512 megabytesof RAM,  s analyzing a sentence in the WorldbookEncyclopedia required 0.0378 seconds on average.This translates into a content analysis rate ofroughly 340 words a second, or approximately 11.4megabytes of text per hour.
Although the systemcomposed of REXTOR and the ternary expressionsindexer is slower than the simple keyword indexer,we believe that the potential to dramatically in-crease precision offsets the longer processing time.SHowever, REXTOR is not a memory-intensive sys-tem; RAM utilization during trial runs was rather low.75This paper presents only the first stage of anlinguistically-motivated information retrieval sys-tem.
Although we have presented the results ofa preliminary investigation i to the effectivenessof this approach, we cannot draw any conclu-sions until more comprehensive t sts have beenconducted.
However, many prior techniques usedin natural language information retrieval (e.g.,head/modifier pairs) can be expressed within theItEXTOR framework, and furthermore the systemprovides a playground for experimenting with newtechniques.
Thus, we believe that our approachshows great promise in moving towards higherperformance information retrieval systems.7 Conc lus ionThis paper presented a scheme for integrating nat-ural language processing and information retrievalby adopting a finite-state model of language anda ternary expression representation f documentcontent.
We provided justification for our lan-guage model and representational structures inboth linguistic and empirical terms.
ItEXTOR isan implementation of our ideas - -  it not only in-tegrates many previous natural anguage indexingtechniques, but also provides a sufficiently gen-eral framework for much future experimentation.Although we have not yet conducted comprehen-sive tests, the extraction of "meaning" from doc-uments using ItEXTOR promises to better fulfillusers' information eeds.8 AcknowledgmentsWe would like to thank Sue Felshin for her insight-ful comments in reviewing drafts of this paper.Re ferencesAlfred V. Aho, Ravi Sethi, and Jeffrey D. Ullman.1988.
Compilers- Principles, Techniques, andTools.
Addison-Wesley.Avi Arampatzis, Th.P.
van der Weide, C.H.A.Koster, and P. van Bommel.
1998.
Phrase-based information retrieval.
Information Pro-cessing and Management, 34(6):693-707, De-cember.Avi Arampatzis, Th.P.
van der Weide, C.H.A.Koster, and P. van Bommel.
2000.
Anevaluation of linguistically-motivated in exingschemes.
In Proceedings o.f BCS-IRSG 2000Colloquium on IR Research.Eric Brill.
1992.
A simple rule-based part ofspeech tagger.
In Proceedings of the Third Con-.ference on Applied Natural Language Process-ing.Noam Chomsky.
1959a.
A note on phrasestructure grammars.
Information and Control,2:393-395.Noam Chomsky.
1959b.
On certain formal prop-erties of grammars.
Information and Control,2:137-167.Kenneth W. Church.
1980.
On memory limita-tions in natural anguage processing.
TechnicalIteport Tit-245, MIT Laboratory for ComputerScience.Bruce Croft and David D. Lewis.
1987.
An ap-proach to natural anguage processing for doc-ument retrieval.
In Proceedings of the lOth An-nual International ACM SIGIR Conference onResearch and Development in Information Re-trieval (SIGIR-87).Joel L. Fagan.
1987.
Experiments in Auto-matic Phrase Indexing .for Document Retrieval:A Comparisons of Syntactic and Non-SyntacticMethods.
Ph.D. thesis, Cornell University.Ralph Grishman and John Sterling.
1993.
NewYork University: Description of the PROTEUSsystem as used for MUC-5.
In Proceedings of the5th Message Understanding Conference (MUG-5).Ralph Grishman.
1995.
The NYU system forMUC-6 or where's the syntax.
In Proceedingsof the 6th Message Understanding Conference(MUC-6).George E. Heidorn.
1972, Natural lan-guage inputs to a simulation programming sys-tems.
Technical Iteport NPS-55HD72101A,Naval Postgraduate School.Jerry It.
Hobbs, Douglas Appelt, John Bear,David Israel, Megalmi Kameyama, Mark Stickel,and Mabry Tyson.
1996.
FASTUS: A cascadedfinite-state transducer for extracting informa-tion from natural-language text.
In Roche andSchabes, editors, Finite State Devices .for Nat-ural Language Processing.
MIT Press.Christian Jacquemin, Judith L. Klavans, and Eve-lyne Tzoukermann.
1997.
Expansion of multi-word terms for indexing and retrieval usingmorphology and syntax.
In Proceedings of the35th Annual Meeting of the Association forComputational Linguistics (A CL '97).Karen Jensen, George E. Heidorn, and Stephen D.Richardson, editors.
1993.
Natural LanguageProcessing: The PLNLP Approach.
KluwerAcademic Publishers.76Boris Katz and Beth Levin.
1988.
Exploiting lex-ical regularities in designing natural languagesystems.
In Proceedings of the l~h Interna-tional Conference on Computational Linguistics(COLING '88).Boris Katz.
1980.
A three-step rocedure for lan-guage generation.
Technical Report 599, MITArtificial Intelligence Laboratory.Boris Katz.
1990.
Using English for indexing andretrieving.
In P.H.
Winston and S.A. Shellard,editors, Artificial Intelligence at MIT: Expand-ing Frontiers, volume 1.
MIT Press.Boris Katz.
1997.
Annotating the World WideWeb using natural anguage.
In Proceedings ofthe 5th RIA O Conference on Computer AssistedInformation Searching on the Internet (RIAO'97).Edward Loper.
2000.
Applying semantic rela-tion extraction to information retrieval.
Mas-ter's thesis, Massachusetts Institute of Technol-ogy.Fernando Pereira and Rebecca Wright.
1991.Finite-state approximation of phrase structuregrammars.
In Proceedings of the 29th Meetingof the ACL.Alan F. Smeaton, Ruairi O'Donnell, and FergusKelledy.
1994.
Indexing structures derivedfrom syntax in TREC-3: System description.In Proceedings of the 3rd Text REtrieval Con-ference (TREC-3).Tomek Strzalkowski, Louise Guthrie, Jussi Karl-gren, Jim Leistensnider, Fang Lin, Jose Perez-Carballo, Troy Straszheim, Jin Wang, and JonWilding.
1996.
Natural language informationretrieval: TREC-5 report.
In Proceedings of the5th Text REtrieval Conference (TREC-5).J.
Thorne, P. Bratley, and H. Dewar.
1968.
Thesyntactic analysis of English by machine.
InDonald Michie, editor, Machine Intelligence 3.Edinburgh University Press.William A.
Woods.
1970.
Transition networkgrammars for natural anguage analysis.
Com-munications of the ACM, 13(10).Chengxiang Zhai, Xiang Tong, Natasa Milic-Frayling, and David A. Evans.
1996.
Evalu-ation of syntactic phrase indexing - CLARITNLP track report.
In Proceedings of the 5thText REtrieval Conference (TREC-5).77
