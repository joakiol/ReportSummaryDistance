Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 791?796,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsPunctuation Processing for Projective Dependency Parsing?Ji Ma?, Yue Zhang?and Jingbo Zhu??
?Northeastern University, Shenyang, China?Singapore University of Technology and Design, Singapore?Hangzhou YaTuo Company, 358 Wener Rd., Hangzhou, China, 310012majineu@gmail.comyue zhang@sutd.edu.sgzhujingbo@mail.neu.edu.cnAbstractModern statistical dependency parsers as-sign lexical heads to punctuations as wellas words.
Punctuation parsing errors leadto low parsing accuracy on words.
In thiswork, we propose an alternative approachto addressing punctuation in dependencyparsing.
Rather than assigning lexicalheads to punctuations, we treat punctu-ations as properties of their neighbour-ing words, used as features to guide theparser to build the dependency graph.
In-tegrating our method with an arc-standardparser yields a 93.06% unlabelled attach-ment score, which is the best accuracy bya single-model transition-based parser re-ported so far.1 IntroductionThe task of dependency parsing is to identify thelexical head of each of the tokens in a string.Modern statistical parsers (McDonald et al, 2005;Nivre et al, 2007; Huang and Sagae, 2010; Zhangand Nivre, 2011) treat all the tokens equally, as-signing lexical heads to punctuations as well aswords.
Punctuations arguably play an importantrole in syntactic analysis.
However, there are anumber of reasons that it is not necessary to parsepunctuations:First, the lexical heads of punctuations are notas well defined as those of words.
Consequently,punctuations are not as consistently annotated intreebanks as words, making it harder to parsepunctuations.
For example, modern statisticalparsers achieve above 90% unlabelled attachmentscore (UAS) on words.
However, the UAS onpunctuations are generally below 85%.
?This work was done while the first author was visitingSUTDMoreover, experimental results showed thatparsing accuracy of content words drops on sen-tences which contain higher ratios of punctuations.One reason for this result is that projective de-pendency parsers satisfy the ?no crossing links?constraint, and errors in punctuations may pre-vent correct word-word dependencies from beingcreated (see section 2).
In addition, punctuationscause certain type of features inaccurate.
Take va-lency features for example, previous work (Zhangand Nivre, 2011) has shown that such features areimportant to parsing accuracy, e.g., it may informthe parser that a verb already has two objects at-tached to it.
However, such information mightbe inaccurate when the verb?s modifiers containpunctuations.Ultimately, it is the dependencies betweenwords that provide useful information for realworld applications.
Take machine translation orinformation extraction for example, most systemstake advantage of the head-modifier relationshipsbetween word pairs rather than word-punctuationpairs to make better predictions.
The fact that mostprevious work evaluates parsing accuracies with-out taking punctuations into account is also largelydue to this reason.Given the above reasons, we propose an alterna-tive approach to punctuation processing for depen-dency parsing.
In this method, punctuations arenot associated with lexical heads, but are treatedas properties of their neighbouring words.Our method is simple and can be easily incor-porated into state-of-the-art parsers.
In this work,we report results on an arc-standard transition-based parser.
Experiments show that our methodachieves about 0.90% UAS improvement over thegreedy baseline parser on the standard Penn Tree-bank test set.
Although the improvement becomessmaller as the beam width grows larger, we stillachieved 93.06% UAS with a beam of width 64,which is the best result for transition-based parsers791Length 1 ?
20 21?
40 41?
60Punc % 0 ?
15 15 ?
30 > 30 0 ?
15 15 ?
30 > 30 0 ?
15 15 ?
30 > 30E-F 94.56 92.88 87.67 91.84 91.82 83.87 89.83 88.01 ?A-S 93.87 92.00 90.05 90.81 90.15 75.00 88.06 88.89 ?A-S-64 95.28 94.43 88.15 92.96 92.63 76.61 90.78 88.76 ?MST 94.90 93.55 88.15 92.45 93.11 77.42 90.89 89.77 ?Table 2: Parsing accuracies vs punctuation ratios, on the development setSystem E-F A-S A-S-64 MSTDev UAS 91.83 90.71 93.02 92.56Test UAS 91.75 90.34 92.84 92.10Dev UAS-p 83.20 79.69 84.80 84.42Test UAS-p 84.67 79.64 87.80 85.67Dev?UAS 90.64 89.55 91.87 90.11Test?UAS 90.40 89.33 91.75 89.82Table 1: Parsing accuracies.
?E-F?
and ?MST?
de-note easy-first parser and MSTparser, respectively.?A-S?
and ?A-S 64?
denote our arc-standard parserwith beam width 1 and 64, respectively.
?UAS?and ?UAS-p?
denote word and punctuation unla-belled attachment score, respectively.
???
denotesthe data set with punctuations removed.reported so far.
Our code will be available athttps://github.com/majineu/Parser/Punc/A-STD.2 Influence of Punctuations on ParsingIn this section, we conduct a set of experiments toshow the influence of punctuations on dependencyparsing accuracies.2.1 SetupWe use the Wall Street Journal portion of the PennTreebank with the standard splits: sections 02-21are used as the training set; section 22 and sec-tion 23 are used as the development and test set,respectively.
Penn2Malt is used to convert brack-eted structures into dependencies.
We use our ownimplementation of the Part-Of-Speech (POS) tag-ger proposed by Collins (2002) to tag the devel-opment and test sets.
Training set POS tags aregenerated using 10-fold jack-knifing.
Parsing ac-curacy is evaluated using unlabelled attachmentscore (UAS), which is the percentage of words thatare assigned the correct lexical heads.To show that the influence of punctuationson parsing is independent of specific pars-ing algorithms, we conduct experiments us-ing three parsers, each representing a differentparsing methodology: the open source MST-Parser1(McDonald and Pereira, 2006), our ownre-implementation of an arc-standard transition-based parser (Nivre, 2008), which is trained us-ing global learning and beam-search (Zhang andClark, 2008) with a rich feature set (Zhang andNivre, 2011)2, and our own re-implementation ofthe easy-first parser (Goldberg and Elhadad, 2010)with an extended feature set (Ma et al, 2013).2.2 Punctuations and Parsing AccuracyOur first experiment is to show that, comparedwith words, punctuations are more difficult toparse and to learn.
To see this, we evaluate theparsing accuracies of the selected parsers on wordsand punctuations, separately.
Results are listedin Table 1, where row 2 and row 3 list the UASof words (all excluding punctuations) on the de-velopment and test set, respectively.
Row 4 androw 5 list accuracies of punctuations (all excludingwords) on the development and test set, respec-tively.
We can see that although all the parsersachieve above 90% UAS on words, the UAS onpunctuations are mostly below 85%.As for learning, we calculate the percentage ofparameter updates that are caused by associatingpunctuations with incorrect heads during trainingof the easy-first parser3.
The result is that morethan 31% of the parameter updates are caused dueto punctuations, though punctuations account foronly 11.6% of the total tokens in the training set.The fact that parsers achieve low accuracies onpunctuations is to some degree expected, becausethe head of a punctuation mark is linguisticallyless well-defined.
However, a related problem is1We trained a second order labelled parser with all theconfigurations set to the default value.
The code is publiclyavailable at http://sourceforge.net/projects/mstparser/2Some feature templates in Zhang and Nivre (2011) in-volve head word and head POS tags which are not avail-able for an arc-standard parser.
Interestingly, without thosefeatures our arc-standard parser still achieves 92.84% UASwhich is comparable to the 92.90% UAS obtained by the arc-eager parser of Zhang and Nivre (2011)3For the greedy easy-first parser, whether a parameter up-date is caused by punctuation error can be determined withno ambiguity.792Figure 1: Illustration of processing paired punctuation.
The property of a word is denoted by the punc-tuation below that word.that parsing accuracy on words tends to drop onthe sentences which contain high ratio of punc-tuations.
To see this, we divide the sentences inthe development set into sub-sets according thepunctuation ratio (percentage of punctuations thata sentence contains), and then evaluate parsing ac-curacies on the sub-sets separately.The results are listed in Table 2.
Since longsentences are inherently more difficult to parse,to make a fair comparison, we further divide thedevelopment set according to sentence lengths asshown in the first row4.
We can see that most of thecases, parsing accuracies drop on sentences withhigher punctuation ratios.
Note that this negativeeffect on parsing accuracy might be overlookedsince most previous work evaluates parsing accu-racy without taking punctuations into account.By inspecting the parser outputs, we found thaterror propagation caused by assigning incorrecthead to punctuations is one of the main reason thatleads to this result.
Take the sentence shown inFigure 1 (a) for example, the word Mechanismsis a modifier of entitled according to the gold ref-erence.
However, if the quotation mark, ?, is in-correctly recognized as a modifier of was, due tothe ?no crossing links?
constraint, the arc betweenMechanisms and entitled can never be created.A natural question is whether it is possible toreduce such error propagation by simply remov-ing all punctuations from parsing.
Our next ex-periment aims at answering this question.
In thisexperiment, we first remove all punctuations fromthe original data and then modify the dependencyarcs accordingly in order to maintain word-worddependencies in the original data.
We re-train theparsers on the modified training set and evaluate41694 out of 1700 sentences on the development set withlength no larger than 60 tokensparsing accuracies on the modified data.Results are listed in row 6 and row 7 of Table 1.We can see that parsing accuracies on the modifieddata drop significantly compared with that on theoriginal data.
The result indicates that by remov-ing punctuations, we lose some information that isimportant for dependency parsing.3 Punctuation as PropertiesIn our method, punctuations are treated as prop-erties of its neighbouring words.
Such propertiesare used as additional features to guide the parserto construct the dependency graph.3.1 Paired PunctuationOur method distinguishes paired punctuationsfrom other punctuations.
Here paired punctuationsinclude brackets and quotations marks, whosePenn Treebank POS tags are the following four:-LRB- -RRB- ?
?The characteristics of paired punctuations include:(1) they typically exist in pairs; (2) they serve asboundaries that there is only one dependency arcbetween the words inside the boundaries and thewords outside.
Take the sentence in Figure 1 (a)for example, the only arc cross the boundary is(Mechanisms, entitled) where entitled is the head.To utilize such boundary information, we fur-ther classify paired punctuations into two cate-gories: those that serve as the beginning of theboundary, whose POS tags are either -LRB- or ?,denoted by BPUNC; and those that serve as the endof the boundary, denoted by EPUNC.Before parsing starts, a preprocessing step isused to first attach the paired punctuations asproperties of their neighbouring words, and thenremove them from the sentence.
In particular,793unigram for p in ?0, ?1, ?2, ?3, ?0, ?1, ?2ppuncfor p in ?0, ?1, ?2, ?0, ?1ppuncpw, ppuncptbigram for p, q in (?0, ?0), (?0, ?1), (?0, ?2), (?0, ?1), (?0, ?2) ppuncqpunc, ppuncqt, ppuncqwfor p, q in (?2, ?0), (?1, ?0), (?2, ?0) ppuncqt, ppuncptqtfor p, q in (?2, ?0), (?1, ?0), (?0, ?0) dpqppuncptqtTable 3: Feature templates.
For an element p either on ?
or ?
of an arc-standard parser, we use ppunc,pwand ptto denote the punctuation property, head word and head tag of p, respectively.
dpqdenotes thedistance between the two elements p and q.we attach BPUNCs to their right neighbours andEPUNCs to their left neighbours, as shown in Fig-ure 1 (b).
Note that in Figure 1 (a), the left neigh-bour of ?
is also a punctuation.
In such cases, wesimply remove these punctuations since the exis-tence of paired punctuations already indicates thatthere should be a boundary.During parsing, when a dependency arc withlexical head whis created, the property of whisupdated by the property of its left (or right) mostchild to keep track whether there is a BPUNC (orEPUNC) to the left (or right) side of the sub-treerooted at wh, as shown in Figure 1 (c).
WhenBPUNCs and EPUNCs meet each other at wh, aPAIRED property is assigned to whto capture thatthe words within the paired punctuations form asub-tree, rooted at wh.
See Figure 1 (d).3.2 Practical IssuesIt is not uncommon that two BPUNCS appear ad-jacent to each other.
For example,(?Congress?s Environmental Buccaneers,?Sept.
18).In our implementation, BPUNC or EPUNC prop-erties are implemented using flags.
In the exam-ple, we set two flags ?
and ( on the word Con-grees?s.
When BPUNC and EPUNC meet eachother, the corresponding flags are turned off.
Inthe example, when Congrees?s is identified as amodifier of Buccaneers, the ?
flag of Buccaneersis turned off.
However, we do not assign a PAIREDproperty to Buccaneers since its ( flag is still on.The PAIRED property is assigned only when allthe flags are turned off.3.3 Non-Paired PunctuationsThough some types of non-paired punctuationsmay capture certain syntactic patterns, we do notmake further distinctions between them, and treatthese punctuations uniformly for simplicity.Before parsing starts and after the preprocessingstep for paired punctuations, our method employsa second preprocessing step to attach non-pairedpunctuations to their left neighbouring words.
Itis guaranteed that the property of the left neigh-bouring words of non-paired punctuations must beempty.
Otherwise, it means the non-paired punc-tuation is adjacent to a paired punctuation.
Insuch cases, the non-paired punctuation would beremoved in the first processing step.During parsing, non-paired punctuations arealso passed bottom-up: the property of whis up-dated by its right-most dependent to keep trackwhether there is a punctuation to the right sideof the tree rooted at wh.
The only special case isthat ifwhalready contains a BPUNC property, thenour method simply ignores the non-paired prop-erty since we maintain the boundary informationwith the highest priority.3.4 FeaturesWe incorporate our method into the arc-standardtransition-based parser, which uses a stack ?
tomaintain partially constructed trees and a buffer ?for the incoming words (Nivre, 2008).
We designa set of features to exploit the potential of usingpunctuation properties for the arc-standard parser.The feature templates are listed in Table 3.In addition to the features designed for pairedpunctuations, such as bigram punctuation featureslisted in line 3 of Table 3, we also design featuresfor non-paired punctuations.
For example, the dis-tance features in line 5 of Table 3 is used to capturethe pattern that if a word w with comma propertyis the left modifier of a noun or a verb, the distancebetween w and its lexical head is often larger than1.
In other words, they are not adjacent.4 ResultsOur first experiment is to investigate the effect ofprocessing paired punctuations on parsing accu-racy.
In this experiment, the method introducedin Section 3.1 is used to process paired punctua-tions, and the non-paired punctuations are left un-794s Baseline Paired All1 90.76 91.25 91.472 91.88 92.06 92.344 92.50 92.61 92.708 92.73 92.76 92.8216 92.90 92.94 92.9964 92.99 93.04 93.10Table 4: Parsing accuracies on the developmentset.
s denotes the beam width.touched.
Feature templates used in this experi-ment are those listed in the top three rows of Ta-ble 3 together with those used for the baseline arc-standard parser.Results on the development set are shown in thesecond column of Table 4.
We can see that whenthe beam width is set to 1, our method achieves an0.49 UAS improvement.
By comparing the out-puts of the two parsers, two types of errors madeby the baseline parser are effectively corrected.The first is that our method is able to cap-ture the pattern that there is only one depen-dency arc between the words within the paired-punctuations and the words outside, while thebaseline parser sometimes creates more depen-dency arcs that cross the boundary.The second is more interesting.
Our method isable to capture that the root, wh, of the sub-treewithin the paired-punctuation, such as ?Mecha-nisms?
in Figure 1, generally serves as a modifierof the words outside, while the baseline parser oc-casionally make whas the head of the sentence.As we increase the beam width, the improve-ment of our method over the baseline becomessmaller.
This is as expected, since beam searchalso has the effect of reducing error propagation(Zhang and Nivre, 2012), thereby alleviating theerrors caused by punctuations.In the last experiment, we examine the effectof incorporating all punctuations using the methodintroduced in Section 2.
In this experiment, weuse all the feature templates in Table 3 and thosein the baseline parser.
Results are listed in thefourth column of Table 4, which shows that pars-ing accuracies can be further improved by alsoprocessing non-paired punctuations.
The overallaccuracy improvement when the beam width is 1reaches 0.91%.
The extra improvements mainlycome from better accuracies on the sentences withcomma.
However, the exact type of errors thatare corrected by using non-paired punctuations ismore difficult to summarize.system UAS Comp RootBaseline 90.38 37.71 89.45All-Punc 91.32 41.35 92.43Baseline-64 92.84 46.90 95.57All-Punc-64 93.06 48.55 95.53Huang 10 92.10 ?
?Zhang 11 92.90 48.00 91.80Choi 13 92.96 ?
?Bohnet 12 93.03 ?
?Table 5: Final result on the test set.The final results on the test set are listed in Ta-ble 55.
Table 5 also lists the accuracies of state-of-the-art transition-based parsers.
In particular,?Huang 10?
and ?Zhang 11?
denote Huang andSagae (2010) and Zhang and Nivre (2011), re-spectively.
?Bohnet 12?
and ?Choi 13?
denoteBohnet and Nivre (2012) and Choi and Mccal-lum (2013), respectively.
We can see that ourmethod achieves the best accuracy for single-model transition-based parsers.5 Conclusion and Related WorkIn this work, we proposed to treat punctuationsas properties of context words for dependencyparsing.
Experiments with an arc-standard parsershowed that our method effectively improves pars-ing performance and we achieved the best accu-racy for single-model transition-based parser.Regarding punctuation processing for depen-dency parsing, Li et al (2010) proposed to uti-lize punctuations to segment sentences into smallfragments and then parse the fragments separately.A similar approach is proposed by Spitkovsky etal.
(2011) which also designed a set of constraintson the fragments to improve unsupervised depen-dency parsing.AcknowledgementsWe highly appreciate the anonymous reviewersfor their insightful suggestions.
This researchwas supported by the National Science Founda-tion of China (61272376; 61300097; 61100089),the Fundamental Research Funds for the Cen-tral Universities (N110404012), the research grantT2MOE1301 from Singapore Ministry of Ed-ucation (MOE) and the start-up grant SRGISTD2012038 from SUTD.5The number of training iteration is determined using thedevelopment set.795ReferencesBernd Bohnet and Joakim Nivre.
2012.
A transition-based system for joint part-of-speech tagging and la-beled non-projective dependency parsing.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning, EMNLP-CoNLL ?12, pages 1455?1465, Stroudsburg, PA,USA.
Association for Computational Linguistics.Jinho D. Choi and Andrew Mccallum.
2013.Transition-based dependency parsing with selec-tional branching.
In In Proceedings of the 51st An-nual Meeting of the Association for ComputationalLinguistics.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: theory and experi-ments with perceptron algorithms.
In Proceedingsof the ACL-02 conference on Empirical methods innatural language processing - Volume 10, EMNLP?02, pages 1?8, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Yoav Goldberg and Michael Elhadad.
2010.
An effi-cient algorithm for easy-first non-directional depen-dency parsing.
In Human Language Technologies:The 2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, HLT ?10, pages 742?750, Stroudsburg, PA,USA.
Association for Computational Linguistics.Liang Huang and Kenji Sagae.
2010.
Dynamic pro-gramming for linear-time incremental parsing.
InJan Hajic, Sandra Carberry, and Stephen Clark, ed-itors, ACL, pages 1077?1086.
The Association forComputer Linguistics.Zhenghua Li, Wanxiang Che, and Ting Liu.
2010.
Im-proving dependency parsing using punctuation.
InMinghui Dong, Guodong Zhou, Haoliang Qi, andMin Zhang, editors, IALP, pages 53?56.
IEEE Com-puter Society.Ji Ma, Jingbo Zhu, Tong Xiao, and Nan Yang.
2013.Easy-first pos tagging and dependency parsing withbeam search.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Lin-guistics (Volume 2: Short Papers), pages 110?114,Sofia, Bulgaria, August.
Association for Computa-tional Linguistics.Ryan McDonald and Fernando Pereira.
2006.
Onlinelearning of approximate dependency parsing algo-rithms.
In Proceedings of 11th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics (EACL-2006)), volume 6, pages81?88.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005.
Online large-margin training of de-pendency parsers.
In Proceedings of the 43rd An-nual Meeting on Association for Computational Lin-guistics, ACL ?05, pages 91?98, Stroudsburg, PA,USA.
Association for Computational Linguistics.Joakim Nivre, Johan Hall, Jens Nilsson, AtanasChanev, G?ulsen Eryigit, Sandra K?ubler, SvetoslavMarinov, and Erwin Marsi.
2007.
Maltparser:A language-independent system for data-driven de-pendency parsing.
Natural Language Engineering,13(2):95?135.Joakim Nivre.
2008.
Algorithms for deterministic in-cremental dependency parsing.
Computational Lin-guistics, 34(4):513?553.Valentin I. Spitkovsky, Hiyan Alshawi, and Daniel Ju-rafsky.
2011.
Punctuation: Making a point in un-supervised dependency parsing.
In Proceedings ofthe Fifteenth Conference on Computational NaturalLanguage Learning (CoNLL-2011).Yue Zhang and Stephen Clark.
2008.
A tale of twoparsers: Investigating and combining graph-basedand transition-based dependency parsing.
In Pro-ceedings of the 2008 Conference on Empirical Meth-ods in Natural Language Processing, pages 562?571, Honolulu, Hawaii, October.
Association forComputational Linguistics.Yue Zhang and Joakim Nivre.
2011.
Transition-baseddependency parsing with rich non-local features.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies, pages 188?193, Portland, Ore-gon, USA, June.
Association for Computational Lin-guistics.Yue Zhang and Joakim Nivre.
2012.
Analyzingthe effect of global learning and beam-search ontransition-based dependency parsing.
In Proceed-ings of COLING 2012: Posters, pages 1391?1400,Mumbai, India, December.
The COLING 2012 Or-ganizing Committee.796
