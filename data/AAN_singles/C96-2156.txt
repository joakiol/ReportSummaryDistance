Multi-Modal-Method:A Design Method for Building Multi-Modal SystemsHideo Shimazu and Yosuke TakashimaInt'ormation Technology l{esca.rch I,abora.tories.N i';C, Cor t )o ra .
l Jon4- 1- \[ Miya.za.ki, Miya.nia.e, Ka.wa.sa.ld, 216,J a.p a,n{shin la .zu~ yosu  Ice} <iLjoke.c l .nec.co, jpAbst rac tThis pa.per descril>es Mull;i-ModM-Method, a. design nlethod for bu ih l inggra.nnna.r-i)a.sed lnull;i iiiodaJ systeins.M u l t i -ModM-MeI J iod defhies the proce-diire, which hlllerfa.ce desiguers i i iay l'oflow hi developing niuil;i-ll iodaJ sys/,e, iiis,and provides MM- I ) ( \ ]G ,  a. gl'a.iiillia.ti-(',a.\] \[i'&lll(eW()i:k for lll/i\]i,i-illOd;i.l hlpul, illtel:prel~a.tion.
Mull, i-Moda.l Method hasbeen induct ive ly  defiiie(t through severalexperhnent.a.1 i-milt, i-inodaJ int;erfa.ce sys-teni developnie.nts.
A ca.se st, udy of aiiiu\]l;i nioda.l dra.wing l ,ool developinenl;a.iong with Mu l t i -Moda l -Method is repori;ed.1 Introduction' l 'his pa.l>e,r descril>es Mul t i  Moda.l-Mel;hod, ainelho(l for \])uil( l ing <gl:itilillia3'-.l)ased null l .
i - inoda\]sysl.eilis.The, ilio|,iva.l:iOl\] \])ellii/(t this resea.i:ch is t,l\]a,1,defil i iug such a. iiieLhod is necessa, l'y for bui ld-il ig nexl, g.::iiera.l,i(:,n iliterf0..l::es.
We believe iillilt, i-lilOda,l intel:Pa, ce is olie ()f the a, dva, i\]ced inter~fa.ce l>eyond present gra.phic user iill.erfi~.ces (GUI )such a.s Windows a.nd Ma.cintosh.
A l though therehas h.eell signif icant i:esea.rch Oil nmli, i inodaJ sys-1,ellis (Allga,yer 1989; ('.ohel/ 1,989; Cloheii 199 \[;Ila.yes 1{)87; Kol)sa.
1986; Wa\]llster 1,989), thesesystenls ha.w ~, been buill, as ta.sk-specifi(" expertsystelns, focused oil the a.l>i>lic~d, ion of tim idea.s.All,hough a. nuniber of luetliodologies ha.ve beenforinulaJ;ed l,o buihl  presenl; (\] U Is by sofLwa.re s(:ielil.isl;s a.nd c, onsull;ii\]g firii/s, i, hey a.re not; a.pplic, a-ble t,o inull;i-nioda.l systelll develo\[>inenl,, \])eca.usethe underlying principles a.re differenl, betweenpreseul, (:IUI a, nd n\]ull: i-nio(l l J  syst, eins.
Ti lus,we had to develop ()Ill' ow/l de, sign niei, hodofogy, opi, inilze(l \['or nullt;i-nioda.l sysi, elilS.
We usedthe firs/, gra.i\]n\]ia.l, icaJ \['ra.mewoi:k fol: nnill, i lilodaJsystems, Mull, i-Moda.l I)efinil,e Cla.use (71raJllilia.l"(MM- I )CG)  (Shi.m.
:,,u 1994).
Then, the Mu ld -ModM-Mei;hod wa.s i l iduct ively defined ba.<wd Oil,severa,\[ cases of gra, lJmm, r-based multi modal systern developnmnt.2 Mul t i -moda l  P rocess ing  vsEvent -dr iven  ProgrammingM uld-nmda,l interfa,ce is one oft,he a,d,,'a.nced ilHerFace beyond present 6', \[!
Is.
lJreseul, (;{!ls axe integra, l  ion of objecl orienled comImlin 9 and cvc~l-driv en prog.rav~ m in9.One of I,he nlost iH\]por(~a,v,t i.now~.t, io.s incomputer i>rogi:aniii i ing during the past <leca.deha.s been the developnle, ul, of "Object oriented"(:ouq)utiug.
Viewing sofl\[,wa.re ('OlH\[)onellt, s asif they are _r>hysicaJ objects, cha.r~cterizaJJe via.class/sut>class rela, l, ions based on sinq)le lea Jutesand/el :  how \[llnct, ions of  t;he objecl.s differ, is apower\['ul inel, a.phor.
T i le  l)i:o~ra.iiililei" (:ii.ii i lowhiia.gine coluplex sys/,eills a.s l>uill; up of  these sili ipler ol)jeci,s, l i i i ici i  a.s a. c, hiht bui lds a. la.l'ge si.i'/IC.t l ire oul, o\[" sillil)le, l>uihihig 1)locks or a.li a.rchilecl;t..i'l'{i.ligjes ;~.. Puncl, iona.1, yei, aesl.hel, ica.lly a.l)i)ea.iingedifice \['rolii COliipoiielll,s such a,s woode i i  \]>+~illliSa.iid ineta.l gh'ders. '
l \ ] i i nkh ig  o\[" the coi i lp i i terscreeN, the wh idows  Oil l, ha.l, soi'eeli, itnd eveli thebits in those wh idows  a.s shnple objec ls  coiii l)osedtogeLller int,o a, i)owerletil ed i tor  has l)eell a.I\] <;xl, reniely co inpel i ing vision for iril,er\['~lx:e designers.In f~tcl,, ot:,jecl,-oi:ien/.ed progra, innlh ig ha.s t)e.coinea, COl'llersl, Olle of inLei:fa,ce design, mid I,\]le doilli-lilt.Ill, ineta.phor il\] inter\['a.ce \[,rogra.iiil ni lig systeii is.I lowever,  SOlile r(\](;el\]l, systelllS lla.ve gOlie be-yolid ot>jeci;s for (lea.ling with inierfa, ce developluenl;.
This  is t)eca.use, especia.lly in wil ldow-basedsystelilS> SOllie tyi)e,s of inl, er\['a.ce COllipOileiils (\]oiiol; fit; well wheii viewed as "objccls."
' l 'hinldi igel" the illOtiSe ,'l.s it physicaJ e i l t i ty for the l)rogr;i l l lIller to lise iliitkes perfect sense, btlt 'viewing a,"iiiollse, (:lick;' as a, li object seeliiS less conipell ing.,qinlila.rly, other actions, such as sketchiug wi i l ia l ight I)ell, sca.iltlilig 0, ( \]ocui l lent,  or sl)ea.king a.seliteilce Ca, llilOl, t)e 1;hough of" a.s physica.l en/,itiesjbut i:a.ther iiltlSt be viewed as "'events" which occurOil a.li objeci;.
Thus> \['or exa.ilil)le , tools on \ 'Vi i idows like Visua.l Bask ha.re been lea.niug /.owa.rda, progra.i i i inhig inelLhodo\]ogy i, ha.I, a, l lows nol, oll iy925ol>je<:ts, but also event,-l>ased progra+nuning.It, is our contention t3m/{ while evenC-ba.sed programnfing is a. step ill the right direction, it.
doesnot go fa.r enough.
In pa.rticular, we <:laitu that itis the order of events in a. sequettce that is critical.This is especially true in a nmld-moda.l iuterfaeewhere eveut, s may l>e coming from a set of different;conqmtationa+l device.s, each runifing separately.In such an interface, a. mouse click, a spoken utter-a.nce, a drawing with a. light pets, and some typedcomttta.nds mat  have t.o be integra.ted into a singleinl>ut.
The ordering of the input events is clearlya critical fitctor in understanding the meaning ofsuch inputs, aim "parsing" such astr ing requires a.more principled approach than simply expectingan application t,o handh~ the plethora of <tiverseinlJuts its all ++heir forths.The major purl>ose oF this paper is to definea.
frameworl( and <\]esign methodology for a cosn-pul.illg model which can inl.erl>reC a set; of events,particuhu'ly iu the area.
of nmlti-mo(hd interfa.cedesign, lit the next section we describe this idea.more fully and develol> a simple example.Fusioncolll{linedindcpc/idcntUse of M0daliliessequential parallelAI :IT~I{NATHEX(21,USIVli( (:i:::i:i:::(/::::(: i:i .
(( / ( (SYNt!RGfSTK7CONCURI,HiNTFigure.
1" Nigay and Coutaz's tuulCi-ntodal systemcategorization3 Understanding Event StreamsN iga.y and Cou taz (1993) divided uutlCi-modal sys-l.etllS iuto four categories.
They are defined by twoindependent features; fllsior~ and 'use of r, odalily.
"l,'usion" covers the possil)le combination of differ-ent types of data.
the a.l>sence of fusion is ca.lled"indel)eudent" whereas the l)resence is referred toas "coml)il\]ed".
aUse of modaliCies" expresses thetempora.l availability of multiple ntoda.lities.
Thisdimension covers the a.bseuce or presence of Imam.1 -lelism at the user int~erface.
"Parallel lisa;' allowsthe user to employ multiple modalit ies sintulta+neously.
"~'Sequential" forces the user I,o use themodalil, ies one after another.
In this paper, we(lea\] with Cite :'synergist+it" category, the most.
dif-ficult among t, he Corn' categories.A simple example shows how difficult it, is toundersta.nd synergistic user expressions.
Considerthe example of a chiht who is using a nnlltinm-dia encyclopedia system whicls provides a, mix ofspeech recognition (and language processing) anda.
mouse.
The chiht states "Ca.n this, do this,"pointing at a picture on the screen and clicking themouse during the first %his" and then choosing allitmn front a lllelltl during the second.
The syslenlmust realize that the first, point is, say, a. pict.ur<2of a particular animal a.ud the second is the tttetmitem "fly."
Somewhere, the system itlusl, creale a.Jlinternal representation of this query that conformsto some data (or knowledge) base query la.nguage.In tile object-.orienCed metaphor,  some sort of cen-traJ application object is in cha.rge, and must sendmessages to the screeu, the mouse, and the voicesystem asldng for input upon activation.
This sys=tern then synthesizes that information and pro-duces a query such as "\[QU l,\]l{Y: Func-of <Objectl ) inosaur-bitmap-7><:ntenu item I,'I,V >\]" whichit is progra.mnmd to answer.Note, however, that as the central system ol>-ject is in cha.rge, it, must send messages (or otllerwise cosltact) the wu:ious modalit ies of intera.c-tiou to be aware of tlte.
possibil ity of input.
Thiscan be arbitrari ly hard, especially as we considerthat the number of utodalities wi\]l keep grow-ing as user interface technology design cominues.
Even R)r this simple example the same querycan be a.sked many ways: the child could speak"can a. ptera.smdon fly?
"; could choose from themenu aquery-I)utcCion," point at the dinosaur, andthen mouse "fly"; could type t.o a. conmm.ml ilac"query:f lmction PT1) Fly"; or any other COllll>i-im.tion of these capal>ilities.
The central ol<}eclcoordinating all these modalit ies I I I t lS t  sm,l appropriate messages at approl)riate times to ea.cll <)rthe drivers of the wu:ious devices, and theu iimslsyuthesize the answers that are received.Unfortunately, the situation is made even luoreconlplex by the fact that the system ca.nnot ex-tt'acC a\]\] inputs alsd colnbine them in sonle s in@eltla.Slller.
The sequence in which the inputs are.
re-ceived can be critical tha.t is, the %vent stream"must be aua.lyzed as a.n ordered set of events whichdetermine tile interaction.
If the chi\]<l says ~'lsthis (points a.t elel>hant) bigger than this (pointsaC pteranodon)?"
then the system must recognize in which order tile poiuCs and the anaphoricreferences occur.
Simply recognizing /he queryconcerning the elephant and pteranodon is uotenough; we must understand (and process) theniin the correct order.The computatiol lal met.aphor we prefer is no lChat+ of objects, but rather that of l>rocessing thestream of events in a. gra.nuna.tical mamler.
Thus,instead of having a central object initiating sollmsort of message passing, we view each of the individual interaction techniques a.s producing reportsconcerning the events which occur and the t.imitlgof these events (e.g., the mouse in the aJ>ow', s<:enario will simply report "<Mouse-Cl ick :Xpos 300:Ypos 455 :start 2700 :end 273.5>.
")Using the example, :'can this do this", we de-scribe \]tow sophisticate synergistic iuputs shouldbe processed more precisely.
Figure 2 shows four926Case 1Sgeech ModeMouse h~0ut ModeCase 2Speech ModeMouse Input ModeCase 3Speech ModeMouse Input ModeCase 4Speech Mod0Mouse Input ModeCan this do this ?~ E::::::2::3 I::::::E::3,l& ~t,Can this do lhis ?Can this ,do this ?r"-'-"~l:::::::\] ~ I::::::=:1tAi1TimooutCan this do this ?\[::2:::::~ I::::Z:z\] 1:::2:2:Z3I,'igure 2: Four inpHt t.indngs for "(:a.n this do t.his"t.itHing cases of a. user's it,put, of the exa.ttq)lc.
I%.chcase should be processed iu a+ diffet+enl ,tmnm'.r:Case 1: There u.re two nlouse it,l>t,ts, a.,td eachof t.hellt ,ua.tehes correspo,tding spce('h iuput.Tlwxel'ol:e, t t,a,l, chiug l;>oth int>u {.S iS easy.Case  :2: There is one mouse inl)ut which pointsa.t.a, specific a.ldW.a.l.ed object, "l>tera.nodoH ".
Theilll>Ut nm.t('hes the fit:st. "tJ,is".
The second "this",therefore, is iHterl>re, ted as the la.st rel+'erred a+ct.io..Case+ 3: +l'he,;e is oue mouse input, which \[>oiuts'a.t 'a.
specific a('tiou, "fly".
The inl>ut IImt.clw, s I.hesecond "this".
'l'he first "this", therefore, is inl.er-l>re.ted a.s (.he lain referre.d a.,,ittla.ted ol>ject..Case  4: T\]ml'e a.re t.w(:, mouse i,,pul.s, one ofwhich is ilq>ut lotlg a.t"ter the, first mouse input (ff)rexample, I tnimtt:e a.fter).
I ,  this case, the seeottdinouse i,\[>ut is ig.ored l>eca.use of l imeo+lt I>y t.hesyst, eln.
OI\]ly I,he first mouse inlmt is iuterpreted.
:l'hereff)re, ea.se d ix l>roc<'sse(\] tim sa, me a+s case 2.4 Multi-Modal-Method DesignProt'ess'l'he design \[>rocess of t, he Multi-Moda,l-Methodlies seve, l~ stel>s.S tep  1.: Task  sehwt ionA tluml>el: of tnulti.-l,K)da.1 int, erfa.ces ha.ve bee,,de.velol)ed.
There axe cevta.inly severa.l a.pplica.tionfieh\]s in which nmlt i  ||loda.I systems a.re a.l>l>liea.ble.
The+' include: design and editiug, pt:esenta.-t icm, infi:)rt,m.l:ion rett:ieva\], and educe.lion.Step 2: Mode.
and  med ia  se lect ionThe tmHtber ;u,d type of Jl,o(les a,ttd media.sllottl(l be deternfined.
Gettera\]\]y, niode arid lue-,:lie.
do  not .
ha.re a. ot le - t .O-O l le  eor res l>Ol lde l l ( :e .
Forexatnple, a.lt.hottgh speech inl>ttt a.H,:t keyl>oa.rd input use+ different media+, they a.re t.vea.ted a.s thesa.nm mode beta.use they a.re used and interpretedidemica, lly.S tep  3: Corpus  co l lec t ionThe eorl)us of multi-i~mda.\] expressi<ms to tlma,pplica, t io.
is collected.
This process is the su.,+as that, for tm.latra,l la, ngua,ge processing.S tep  4: Corpus  ana lys i sThe collected corl>tls is mta.lyzed, l,:a.ch expression iu the COrl>US shouht I>e a, na.lyzed I>a.sed ouL\]le R)Howiug cl:il.eria..Economy:  l)oes the exl>ression save a, tlse, r'sla.bor?
I,\]aeh expressiotl is exa.,t,iued as towhether it; ca.n sa.ve a. use, t:'s fa.bor v:hett t rmmferring his/her iut, ent io,  to the a.pplica.tioasystem.
For example, in .t+ piet+tu'e <\]ra+',vingtool, if a. user is a.llowed t<) point a.1.
a. si>eeific ol>jeet while sa,ying %Jelete", he/she ca.tlsa.ve ht.bor, be(:a.use he/she does ,of  ha:.+'e Iocha, llge, t.hc IHouse positiotl frol~l the CIILIIVIhS toit.
l l l e l l l l  item a.t t.he l l l e l l t?
| ) i l l '  a.rea., a+lld l i l le .
i l lFl:Olll the tDe l l t l  })lt.l' it.Fee, to  (:he (:3.+llV&'-;.Plausit : , i l i ty :  1,:a.eh exl>ression is exandued asto whether: it.
is likely to be used in a+ i'ea.1appliea.tiot|.
As desct'ibed t+etow, writ inggra.tlmm.rs for tuulti--tttoda.1 interfaces requiresmu,::h more effort tha.tt f<::,r single tt~<::,da.\] iJlteJq+'aees.
O .
ly  frequently used ex\[>ressi<)usshould be selected ca.refi|lly.
The sp<,.echmode is be/.l.er I"or selecting a.n itetn anmllgn ta.rge mltu\]>er of ca, ndida, tes, such as choosi ,g a.
{'it.)"
ua.me a.lllong all cities in the I .
!S:\.Ou the of.her ha+ml, a..w, uu iHterfa.
(:e is bett.er I"or sefe,::l.il~g one a.luong a+ small tmtIll>,:'.ro f e a,u did a,t,es.The set.
,:)r the select;ed expressiorts t)ecOllles timseed for the specifiea.tion of the desigm:d t,,ult.i|t|oda.1 sysl.etu.Step 5: Spec i f i ca t ion  Des ignThe difl ieulty level oft.he interface (tesig,, shouldbe (lel.er,l,hted />ased cm the a.ualysis of' sele(:le(lcorpus e+xpressio,ls.
Thet:e a.re five dil-liculty levelsof multi-modal input e?i>ressions (Ta.b\]e 1):Level  1: Single mode input :  l,',veu it, a. tl,ulti,node.1 syst, em, users oR,e|| wa,nt t,o express /heiri , Ientions with si,gle modal expressions.
For ex-ample, I:>oiul, ing a,t a,u existing object, thee selecthlg "delete;' from the menu.Lewd 2: Al l  mode inputs  express  ident i ca lcontents :  I.
',a.eh tt,ode input, expresses a.n i(hmt.ical cc:,ntelfl..
I"or exa.utl>le, poitH;ing a+/; a,n exisl.~ing ot>ject, then selecting "delete" from the lllel\]l+l,while saying "delete the reeta ugle".Leve l  3: A eo inb inat ion  of  incomifle, te  modeinputs  eomph; lnent  each other :  Each t,lod<~input does not.
expresses tf|e <::otHelltS }>y itself.927Each mode input complements other mode inputs;thus they express a. single content.
For exam-pie, pointing a.t a.n existing object, while saying"'delete".Level  4: Each mode input is contradictory:The contents generated from independent lnodeinputs axe contra.dictory one ~nother.
For exam-pie, sa.ying "delete the circle", while pointing at.a.
rectangle object which hides the specified cir-cle object on the screen.
Contra.dictions a.re oftensolved by context a.na.lysis.Level  5: A COlnbination of mode inputs stilllacks someth ing:  The contents genera.ted fromthe combination of the interpretations genera.tedfl'om individua.l mode inputs a.re insufficient.
Forexample, sa.ying "move it.
here", while pointing a.ta.
specific point.
The point should be unified with"here", a.nd a.n object specified by" "it" should beinterpreted as the last referred object.
This typeof interpreta.tion requires of context a.na.lysis.It becomes more dimcult to interpret expres-sions as the level increases.
Especia.lly, sincelevel's 4 a.nd 5 require tight iutegra.tion with con-text a.na.lysis, interfa.ce designers hould considerwhether the applica.tion users really need theselevels or not.Step 6: Arch i tec ture  DesignAny multi-moda.l system can ha.re a. multi agenta.rchitecture beta.use a.ch mode processing is ea.s-ily ma.pped to a.n independent a.gent.
There aretwo extreme types of architecture which ma.na.gethe agents.
One is bh~ckboard a.rchitecture wherea.gen ts excha.nge ilfforma.tion using a shared men,-ory ca.lled a. bla.ckboa.rd.
'l'he a.rchitecture fitsmulti-moda.1 systems whose multi-modM expressions a.re sophistica.ted a.nd integra.ted with con-text.
a.na.lyses.
The other is subsumption a.rchitec-ture where ea.ch a.gent a.cts ra.ther independently.ln forma.tion excha.nge pa.ths between a.gents a.relimited.
The a.rchit.ecture fits multi-lnodM sys-tems whose multi-moda.l expressions a.re simplea.nd slereotyped.
Ma.ny a.ctuaJ multi-modaJ sys-tem a.rchitectures are combina.tions of these ex-trelne a.rchitectures.Step 7: Grammar  rule wr i t iugEach selected mu\]ti-moda\] expression is definedby the corresponding gra.mma.r rule to interpret it.The gra.mma.tica.l ffa,lnework for the mult.i-moda.lexpressiou should ha.re the following functiona.li-ties:(1) Modes  should be in terpreted  equal lyand indei)(mdently.
If ea.ch mode is trea.tedin the same ma.nner as tha.t of a na.tura.l la.n-gua.ge mode, synta.x a.nd semantics of inputs ofea.ch mode are defined with gramlna.r fornmla.tion.Thus, complex multi-modM expressions can be de-fined declara.tively a.nd more easily.
(2) Mode interpretations shouhl  be re fer redto one another .
Inputs of ea.ch mode shouhlbe interpreted independently.
However, the inter-pretation of such inputs should be referred to byother mode interpretations.
There ~re a.mbiguitieswhich a.re solved only by integrating pa.rtiM inter-preta.tions of rehtted modes.
For example, if a. usersta.tes "this recta.ngle", pointing at a. different ypeof object overlapping the recta.ugle object, the a.mbiguity of the object pointing nmst be solved bycomparing the two mode interpreta.tions.
(3) Mode interpretation should hand le  tem-poral in for lnat ion.
Tempora.l ilfformat.ion ofinputs, such as input a.rriva.1 time a.nd the interva.1between two inputs, is importa.nt in interpretitlgmulti-rood a.1 iuputs.Multi-Moda.l 1)CG (MM-I)CG) supports thesefunctiona.lities.
MM-DCG is a superset of 1)(7(\[;(Pereh'a.
1980); everything possible in 1)CG is a.lsopossible in MM-I)CG.
MM-I)CG has two ma~jorextensions:t. MMq)CG ca.n receive ,~rbitra.ry llUlllbers Ofinput strea,ms, while 1)CG ca,n receive onlyone.
A single gnunm~r rule in MM I)C(;cain allow the coexistence of gra.nnna.tica.l ca.tegories, thus Mlowing for their iutegra.tiou.2.
hi MM-1)CG, ea.ch individual piece of inputda.ta, is required to a.tta.ch the beginning timea.nd t\]Ie end time as its time sta.mp.
Usingthe time sta.mp, MM-I)CG a.utom~tica\]ly ca.1-culates the beginning time trod the end timeof a.ny level of insta.ntia.ted gra.mma.tica.1 ca.tegories genera.ted uring parsing.
The tra.ns-la.tor of MM-I)CG to Prolog predica.tes gellera.tes code which perform this task.
1Figure '3 illustra,tes a,n a,pplica, tion written in MM-I)CG.~ ~ Multi-modal Interpreterword word MM-DCG Rulesword wordclick click\[Prolog Interpreter \]Figure 3: Multi-modM a.pplication written in M :\'I-I)CGThese processes form one cycle in the systentevolution.
Bec~use of the in crease in multi-rood a\]expressions, the qua.lity of tile system improves a.s1The details of MM-DCG ~re described ill (Shi-m~zu 1994)928~ ~  1,;x aml>~.1 single mode pointi,,g at an ob je<: t ,Te \ ] l~  "delete" fl'om tit<+' menu2 re<hmda.nt3 incoml)lel,ed <:oi,tra,dictory5 la.eldngl>oitging at, an ot>ject, select.trig "delet.e" fron\] thetnenu, while sa.ying "delete the rectangle"pointing at a.n exisl;ing object+, while saying "+'delete"saying "delete the circle", while pointinga.t.
a recla++gh-: whi<:h covers t.he specitied circlesaying "move it.
here", while pointing at a point.
'l'a.l>le 1: I,'ive.
leve ls  of' tutdt.i-Jnoda.1 i,q>ut.sfile cych: iLera.tes.
When the system rea.ches thelll;t.t;tJre sl;a..ge,, the syst:ctn is released to end users.5 Case  StudyThis section describes the design process of a.mult.i-nmda.l drawing 1,ool along with tim ttmlt.i-modal-nlethod.
The following is tile trace of the(lesigtt process.Step l: Task soh;c+tioIl Since there has I)ee!l.,dgnifica.nt research oil develot>ing mult, i .,odaldrawing tool (l\[iyoshi 199d; Niga,y 1993; \,% 1993;I~,ellik 1993), the application fiehl is l>rolnising.Step 2: Mode.
and med ia  seJection In tl,isexl>criu,ent , we R)<'+use<l on only input, t.odes.
Input.
modes include speech, keyboard a.d mouseinputs.
These input nJodes a.re synergistic.
Oub.l>ut modes include l>ictures and text, but outputsaxe llOt synergistic.Step 3: Corpus  col lect 'oi l  We co\]le<:l.edabout, two humlred nmlti-ttnoda.1 exln'essions frontpol,ent, iaJ users a+s it,st.r,Jctiol~s for t.he i~lulti:moda.1dra.wing tool.
The users had exl>erience wit+h usingcxisti.g dra:e,,ing t+ools.Step 4: Corpus  analysis The following aresome of tile result.s of l~he a.nalysis of the.
collectedcorpus.?
Users want.
to use various ,nixed modes according to the sil;ua.tions dmy are dealingwith.+D Users wa.tlt.
Lo use abridged expressions,whi<:h causes integration of multi-modal in-terpret.at.ion and cont.ext analysis.?
Users wa.ttt I.o handle exisI;ing objects a.s a set..I,'or example, "Cha+,ge+ tile col<),' of all circles.,., Users want.
\[.o ha.ndle exist.trig objects whi<:hare not shown on t.he display.
For example,asking "'how many re<:tangles a.re hid<letl ()tit,of the canvasT'.+ Users wa.nt t.o use+ l.he tuouse a.mbiguously.For exa.nq)le, saying "l)e\]ete this circle",while I>oinl.ittg a.t a point, a~u:ay fl'o,n but nearthe circle.
Such ambiguous pointing can be<:orre<-t\]y interprete.d only whett multi-,imdalexpressio, is a\]lowe, d.Step 5: Speci f icat ion Design The a.ua.lysistaught us tllaJ.
~,ulti-,,,odal drawhtg tools shouldsupport level% d and 5 (the most dill, cult levels)to meet ordinary users: rcquirenm.l.s.
The sped-\[,catkins were determiued based on these requirell\]ell\[;s.Step 6: Arch i tec tm'e  Design Since tlw, re=quired specification is tim most, difl\]ctJt synergylewJ, (.he a+rchit.ect.ure is blackl>oa.rd a.rc\],itecl;tJrcwhere, ea.ch agent can ex<'ha.t,ge infor,~m.t.ion iva.rying ways.Stell.
7': Gr3.llllllal' rule.
wr i t ing After tlu~a.nalysis, about, forty expressions were selected,a.ud va.ria.tions of ea.ch selected expression werea.lso genera.ted a.nd a.dded.
(-~rammat rules were.de.fined corresponditlg toeach mull:i, tnoda.1 expression.
Figure 4 shows a part <)f the grammar uleswritten in MM-I)CG.
The rules define how to inl.erl)reI, a.n hupera.i.ive sentence like "l)elete thiscircle" wil.h va.riet.ies of expressions.
It allows thespokeu uttera.nce mode(speech sl.rea.ul), l.he tylmit\] ,node (keyl>oa.rd strem,) ,  a.ud the mouse l>oilllittg mode 0hOUSe stxeam), l{ules iu the level I sec1.ion define single tnoda.\] e+xprcssio,m.
In tim level2 section, whethe, r di\[l'erent, mode hq>uts expressidentica.l cotg.ents is examined.
The combina.tionof the verb_by_multimodal/1 clause a+ud the secolulobject/1 clause+ is m\] exami>le of the level 3 exl>res-sions, lit the le.vel 4 sect.iou, select_right_meaning/3enclosed inside curly brackets { and } is a. Prologpredicate which detertnines the correct mea.lfit,gusing cot,text analysis whet, (lilTere.,,t tuo(le iulmtSgenera.re contradictory meanings.
Such a. l>redi-ca+i.e is defined it\] a task-specific ltlal,tleF.
Ill thelevel 5 section, find_appropriate_termt/2 enclosedinside curly brackei.s { a,d } is a. l'rolog pred,.ca.re which finds a.u a.ppropria.te term ttshkg (:outexl.
analysis whe.
the cond>inat.io,t of gcneraJedtuea.ui,g of all modes still lacks htrort\]m.tion.
Su<:}la predica.Le is also defined it, a t.a.sk-spe+cific lira,.er.
A trivial heuristic rule exmnple is "to use the,|tost recently a.ppea.red t.erm".C, ra.J,n,ar writers should understand that.
there,tuber of grammar ,:tiles for muld-tttoda.l int<:v-faces becomes much larger than for any singlemoda.1 int+erfitces.
If there are three triodes; :U\],M2, attd M3, a.nd the mJmbers of granum:u' rules929% st:ream definitionactive_stream(speech, re)us% keyboard)(/c l ,eve l  1imperative(meaning(Action, Object)\] - -  > verb(Action\], object(Object\].wrb(Aet ion) - -  > verbJ)y_menu(Action\].verb(Act ion) - -  > verbJ~y_multimodal(Action).w.rbJ~y_menu(Action)-- > menu(Menu_it.era, Act:ion\].verloJ)y_inult:im~dal(delete) - -  > (speech or keyboard\]:\[delete\].ulen u (in ellu_i t eln_2~l, delete\].object(Oh)) - -  > ,ioun_phrase(Obj).obj~-ct(Ol<i\] - -  > pointing(Oh)).noU._l)hrase(Obj) - - > article, norm(Noun), {attril)ute(type, Noun, Oh j\]}.article - -  > (speech or keyboard\]: \[this\]..oun(clrcle\] - -  > (speech ~r keyboard\]:\[circle\].poialing(Ob,i) - -  > mouse:\[lmlton(left, Ioc(X, Y)\]\],{attribute(Iocation, (X, Y), 0b j\]}.% Lewl 2verb(Actionl) - -  > verb_by_nmnu(Actionl), verb_by_multlmodal(Acl;ion2), {Actionl == Action2}.ob.ieel(Ob.il) - -  > noun_l)\]lrase(Objl), poinl:mg(Olojg), {Objl == Oh j2}.% Level 3% I,evel 4verbfAc l ion}- -  > verb._by_n'mml(Actionl\], verbJ)y_nnlltimodal(Action2),{selecta'ight-meaning(Aetionl, Action2, Action)}.objecl(Obj) - -  > noun_phrase(Objl\], poinling(Obj2\], {select_right_meaning(Objl, Ob.i2, Oh j)}.% l ,evel  5imperalive(meaningfAction, Object ) )  - -  > w.rb(Aetion)~ {fil/d_appr~Jpriat~_term(object, Object)}.imp~rat.ive(meaning(Aclion, Object\]) - -  > object(Object),{find_approl>riate_term(action, Action)}.Figure 4: Gramma.r Description of "I)elete this circle" Using MM-I)CGfor ea.ch mode a.re; (~1, G2, and Ca.
Then, thetotaJ number of the multi-nloda.l gra.mn|m' rules isthe sun1 of the gramma.r ules of a.ny combinationof these three modes.
Thus, the tota.l number,(7~o,,/ is:M~ , ;V\[~ ,Ms D_ ,5'The a.bove steps took about two ma, n month forthe first cycle.
The most.
time COl~suming stepswere step 4 and step 7.6 ConclusionThis pa.per described the nmlti-nloda.l-method, ~design method for building grammar-ba.sed nlulti-moda.l systems.
'\['he inuh.i-modal-nmt.hod de-fines t.he procedures which iuterfa.ce designers ma.yfollow in developing ra.mma.r-based multi-modalsyst.ems, a.nd provides MM-/)CG, a gramma, ticMframework for multi-roods,1 input interpreta, tion.The multi-modal-met,hod has been inductively de-fined through severa.l experimenta,l nmlti-moda,linterfa, ce system clevelopments.
A developmentprocess of a. muld-modM dra.wing tool a.long withthe multi-roods.l-method was aJso introduced.AcknowledgementsWe would like to tha.nk Prof. Ja.tnes Ilendler forhis advice during this resea.rch a.nd in writing thispa.per.ReferencesAllgayer, J., Janscn-\?mkehl, R., reddig, C., andY%eithing N.:"Bidirectional Use of Knowledge in the Multi Modal NI,Access System XTR.A', Proc of IJCAI-89, 1989.Bellik, ?, and Teil, D., "A Muldmodal dialoga~ controller formultimodal user interface management system applical:ion:A nmltimodal window manager", Adjunct Proceedings ofINTEB.CHI-93.Cohen, P.}C, Dalrympl% M.~ Moran, D.B., P~reira= F.C.N.
: <tal., "Synergistic Use of Direct Manipulation and Natul'alLanguage", Proe.
of CIII-S& 1989.Cohen, P.R., "The Role of Natural l,anguage in a MullimudalInterface", 199l Int.ernational Symposium on Next Genera-lion Humall Interface, 1991.Hayes, P.a., "Steps towards Integrating natural f,anguage andGraphical Interaction for Knowledge-based Systems", Ad-vances in Artificial Intelligence - \[l, Elsevier Science Pub-lishers, 1987.Hiyoshi, M, and Shimam h rd., "Drawing Pictures with Nalm'alLanguage and Direct Manipulation" Proc.
of COI,ING-94,1994.KtA)sa, A., Allgayer, J., l-/.eddig, C.: R,eithing, NI: Schumauks,D., Harbusch, K., and Wahlst~r, W, ~;Combining Deic-tic Gestures and Natural l,anguage for R.e%rent hlentil\]-eatiun", Proc.
of COI-,ING-8G, 1986.Nigay, \[,, and C0utaz, J., "A D~sign Space for bhfltimodalSystems: Concurrent Processing and Data Fusion" Proc.
ofINTEP~CHI-g3, lC,93.Pereira, F.= and Warren, D.H.D., i)"Defildte C.'lause Graumtnl'Sfor Language Analysis - A survey of the Formalism and aComparison with Augmented Transition Networks", Artifi-.eial Intelligence, vol.
13, no.
3, 1980.Shimazu, H., Arita, S., and Takashima, Y., "Multi-Modal I)ef-mite Clause Grammar" Proc.
of COLING-94, 1994.Vo, M.T., and Waibel, A., "A multi-modal human-computerinterface: Combination of Gesture and Speech I:/.ecogni-don", Adjtmct Proceedings of INTERCHI-93\?ahlsler, W.~ "User and discourse models for multimodal com-munication", in J.W.
Sullivan and S.W.
Tyler, editors, Intelligent User Interfaces: chapter 3: ACM Press FronliersSeries, Addison Wesley Publishing, 1989.930
