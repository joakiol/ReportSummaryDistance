Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 433?440Manchester, August 2008Generation of Referring Expressions: Managing StructuralAmbiguities?Imtiaz Hussain Khan and Kees van Deemter and Graeme RitchieDepartment of Computing ScienceUniversity of AberdeenAberdeen AB24 3UE, U.K.{i.h.khan,k.vdeemter,g.ritchie}@abdn.ac.ukAbstractExisting algorithms for the Generationof Referring Expressions tend to gen-erate distinguishing descriptions at thesemantic level, disregarding the waysin which surface issues can affect theirquality.
This paper considers how thesealgorithms should deal with surface am-biguity, focussing on structural ambi-guity.
We propose that not all ambigu-ity is worth avoiding, and suggest someways forward that attempt to avoid un-wanted interpretations.
We sketch thedesign of an algorithm motivated by ourexperimental findings.1 IntroductionA Noun Phrase (np) is a referring expressionif its communicative purpose is to identify anobject to a hearer.
The Generation of Refer-ring Expressions (gre) is an integral part ofmost Natural Language Generation (nlg) sys-tems (Reiter and Dale, 2000).
The gre taskcan informally be stated as follows.
Given anintended referent (i.e., the object to be identi-fied) and a set of distractors (i.e., other objectsthat can be confused with the referent), find adescription that allows a hearer to identify itsreferent uniquely (Dale, 1992).
Such a descrip-tion is called a Distinguishing Description(dd).
In practice, however, most gre algo-rithms build sets of semantic properties avail-able in a Knowledge Base (kb), rather thandescriptions in natural language; surface issuesare often ignored (exceptions are: (Stone and?This work is supported by a University of Ab-erdeen Sixth Century Studentship, and EPSRC grantEP/E011764/1.?c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported.Some rights reserved.Webber, 1998; Krahmer and Theune, 2002;Siddharthan and Copestake, 2004)).
This isan important limitation, for example becauseambiguities can be introduced in the step fromproperties to language descriptions.
Such ?sur-face ambiguities?
take centerstage in this pa-per.
More specifically, we shall be investigatingsituations where they lead to referential ambi-guity, that is, unclarity as to what the intendedreferent of a referring expression is.Example 1: Consider a scenario in whichthere are sheep and goats along with other an-imals, grazing in a meadow; some of the sheepand goats are black while others are eitherbrown or yellow.
Suppose our task is to singleout the black sheep and black goats from therest of the animals.
Suppose an algorithm hasgenerated the logical form1(Black ?
Sheep) ?
(Black ?
Goats), which could be realised aseither the black sheep and the black goats or,more briefly, as the black sheep and goats.
Thelatter np expresses two non-equivalent logicalformulae: (i) (Black ?
Sheep) ?
Goats, and(ii) (Black ?
Sheep) ?
(Black ?
Goats).
Sinceboth formulae correspond with a set of animalsin the domain, referential ambiguity can result.On the other hand, the black sheep and goatsis shorter and possibly more fluent.
This ex-ample highlights the possible tension betweenbrevity and lack of ambiguity.
The questionfacing us in this paper is how to balance them.This paper examines how gre should dealwith structural ambiguity, focussing on ambi-guity of the form the Adj Noun1 and Noun2,also known as coordination ambiguity.
Wecall referring expressions of this form scopallyambiguous, as the scope of Adj is unclear be-tween wide scope (Adj applies to both nouns)and narrow scope (Adj applies only to Noun1).1In this paper, we use set-theoretic operators insteadof logical connectives to represent logical forms.4332 ApproachA cursory view of corpora such as the BritishNational Corpus (bnc) reveals that there aremany instances of coordination ambiguity:1. the black cats and dogs2.
the bearded men and women3.
the old men and women in the hatsPsycholinguistic evidence suggests that, inmany cases, these ambiguities could cause con-fusion for a hearer (Tanenhaus and Trueswell,1995).
Hence, it seems justifiable to have greavoid such kind of ambiguities.
However, italso seems plausible that some readings maybe very unlikely.
For example, in (2) a wide-scope reading is, arguably, very unlikely.
Ab-ney and others have argued that every sentenceis potentially ambiguous between many parses,even though we may not even notice this ambi-guity (Abney, 1996; Wasow et al, 2005).
Thissuggests that, in gre as well, it might not befeasible to avoid all referential ambiguities allthe time, and that the choice of referring ex-pression should sometimes involve a balancingact in which degree of ambiguity is balancedagainst other properties of the generated ex-pression, such as its length or fluency.Building on earlier work by Inui et al (Inuiet al, 1992), Neumann (Neumann, 1994) sug-gested a general generate-parse-revise modelfor nlg, based on a reversible grammar.
Hisgenerator generates a string which is thenparsed to detect any structural ambiguities.
Ifa string is found to be ambiguous then revi-sion is used to produce an alternative, non-ambiguous string instead (if such a string ex-ists).
The likelihood of the different interpre-tations is not taken into account, however.Our approach to the problem is to find outthe likelihood of each interpretation of an np,and to tailor gre to avoid all distractor in-terpretations (i.e., interpretations that canbe confused with the intended one) as sug-gested in (van Deemter, 2004).
An interpre-tation can be confused with the intended oneif it is more likely or almost as likely as the in-tended one.
The problem is, how to determinethe likelihood of different interpretations.3 Getting likelihood from the bncIn scopally ambiguous referring expressions,there is a tension between wide- and narrow-scope interpretations.
This can be viewed interms of two competing forces: a CoordinationForce, whereby Noun1 and Noun2 attract eachother to form a syntactic unit, and a Modifi-cation Force, whereby Adj and Noun1 attracteach other to form a syntactic unit.
Computa-tional linguists have proposed using languagecorpora to estimate the likelihood of an inter-pretation (Wu and Furugori, 1998; Chantreeet al, 2006).
Chantree et al used informationfrom the Sketch Engine database (Kilgarriff,2003) operating on the bnc to resolve coor-dination ambiguity.
The Sketch Engine con-tains grammatical triples in the form of WordSketches for each word, with each triple ac-companied by a salience value indicating thelikelihood of occurrence of the word with itsargument in a grammatical relation.
WordSketches summarise the words?
grammaticaland collocational behavior.Chantree et al gathered a dataset of am-biguous phrases from a corpus of requirementsspecifications, and collected human judge-ments about their interpretations.
They thenused machine learning techniques combinedwith various heuristics to determine the mostlikely interpretation of a coordination.
Theyidentified two heuristics as particularly useful.One was the Coordination-Matches Heuristic:if a coordination between two head nouns oc-curs (at all) within the corpus, then a wide-scope reading is likely.
The other was theCollocation-Frequency Heuristic: if a modi-fier is collocated more frequently with the near-est head word than with the head word furtheraway, then a narrow-scope reading is likely.The best performance was achieved by combin-ing the two heuristics: wide-scope reading islikely if Coordination-Matches heuristic givesa positive result and Collocation-Frequencyheuristic gives a negative result.
We decidedto modify Chantree et al?s approach in twoways and apply the modified approach to nlg.Firstly, it seemed unlikely to us in the gen-eral case that the deciding factor is alwayswhether two words co-occur at all.
We there-fore decided to separate cooccurence percent-ages into ones that are very high and onesthat are very low.
Secondly, we observed thatChantree et al take Coordination Force intoaccount when they predict wide scope, but not434when they predict narrow scope.
It wouldbe more systematic ?
and more useful to annlg system, which has to cope with all possi-ble inputs ?
to consider all four combinations,of strong and weak, coordination and modifi-cation force.
We define that there will be aStrong Coordination Force (SCF) if the collo-cational frequency between the two nouns ishigh, and a Weak Coordination Force (WCF)otherwise.
Similarly, we define that therewill be a Strong Modification Force (SMF) ifthe collocational frequency of Adj is high withNoun1 and low with Noun2, and a Weak Mod-ification Force (WMF) otherwise.After a preliminary investigation of the data,we decided to operationalise high collocationalfrequency between two words as meaning thateither of the two words appears among the top30% collocates of the other word in a gram-matical relation (of interest); low collocationalfrequency means that neither of the two wordsappears among the top 70% collocates of theother word in a grammatical relation.
The hy-potheses resulting from the above changes areinvestigated in the following section.4 Empirical StudiesWe conducted three experiments.
The firsttwo experiments ask what interpretation ofa scopally ambiguous np is the most plau-sible, thereby testing our generalisation ofChantree?s hypotheses.
Knowing how an npis interpreted is useful for an nlg system butnot sufficient, because ambiguity needs to betraded off against other factors.
For this rea-son, our third experiment asks which of severalnps are preferred by a reader.4.1 Interpreting npsWe use all four possible combinations of coor-dination and modification forces to predict aninterpretation of a scopally ambiguous refer-ring expression (see Table-1).
An SMF wouldmake a wide-scope reading highly unlikely (cf.
(Wu and Furugori, 1998)).
For instance, in thebearded men and women there is an SCF andan SMF, but in fact this phrase would be in-terpreted as a narrow-scope reading because ofthe scarcity of bearded women.
On the otherhand, a WMF could be in favor of a wide-scopereading.
We expect that human readers wouldopt for wide- and narrow-scope readings ac-cording to Table 1.Table 1: Predicting an interpretationHypothesis 1: SCF ?
SMF ?
NSHypothesis 2: SCF ?
WMF ?
WSHypothesis 3: WCF ?
SMF ?
NSHypothesis 4: WCF ?
WMF ?
WSWS: Wide scope; NS: Narrow scopeTo test these hypotheses, we conducted twointerpretation experiments, and rather thanasking expert linguists to annotate the strings,we examined how ordinary readers interpretstructurally ambiguous strings.
In these ex-periments, given a referential domain and anEnglish np which attempts to identify a sub-set of objects in the domain, participants wereasked to find the referent set of the np.4.1.1 Experiment 1In this experiment, referential domains wereconstructed using real photographs of animalswith some of the features printed alongsideeach photograph.
Features were printed be-cause 1) in a pilot study, we observed thatsome participants had difficulty in discerningsome features in some of the photographs, and2) we attribute some unusual features to someobjects, e.g., we attributed cats with the fea-ture barking although cats don?t bark in re-ality.
Two pairs of nouns were used: one withSCF, and the other with WCF.
For each pairof nouns, four different adjectives were used:two with SMF, and two with WMF.
A trialin this experiment consists of a set of 9 pic-tures (placed in a 3 x 3 grid), and an Englishnp underneath these pictures.
A sample trialis shown in Figure 1.
Participants?
task wasto remove the pictures (by mouse clicks on thepictures) that were referred to by the np.
Aremoved picture was immediately replaced bya blank rectangle (of the same size).In each trial, we made sure that both wide-and narrow-scope readings are applicable.
Forexample, for the instruction Please, remove thered lions and horses, in the domain there were2 red lions, 2 red horses, and some (at leastone) non-red horses.
If a participant removes2 red lions and 2 red horses, we count it as awide-scope reading.
However, if (s)he removesall the horses we count it as a narrow-scopereading.
We also used 8 fillers, which do not435Figure 1: Interpreting an np (using pictures)contain a coordination in the np (e.g., the dogson the left).
60 self-reported native or fluentspeakers of English, students from various UKuniversities, did the experiment on the web.2Results and Discussion: Results were anal-ysed according to whether a participant optedfor a wide- or narrow-scope reading.
The par-ticipants?
responses are shown in Table 2.
Atwo-tailed sign binomial test was used to cal-culate statistical significance.
The data indi-cate that word distribution information can re-liably predict a wide-scope reading.
However,our predictions for a narrow-scope reading arenot confirmed.
This may have been becauseof an intrinsic bias in favour of wide-scope in-terpretations.
Another potential problem withthe experiment is that some of the nps shownto participants were rather unusual, involvingbearded women, etc.
Although the printed fea-tures underneath the pictures forced partici-pants to take these unusual cases seriously, theclash between the picture (of a woman) and theprinted feature (?bearded?)
that arose in suchcases may have made participants?
responsesunreliable.
To avoid this problem we now turnto an experimental setup where we use Eulerdiagrams instead of iconic pictures.4.1.2 Experiment 2This experiment mirrors experiment 1, butwe used Euler diagrams instead of pictures2Here and in the other experiments reported in thispaper, we ascertained that no important differences ex-isted between the two groups of subjects.
Focussing onExperiment 1, for example, no significant difference inthe percentages of wide scope interpretations was foundbetween native speakers and subjects who were merelyfluent in English.Table 2: Response proportions: Experiment 1Force PR PJ p-valueSCF SMF NS NS (25/60) 0.52SCF WMF WS WS (57/60) < 0.001WCF SMF NS NS (26/60) 0.12WCF WMF WS WS (53/60) < 0.001PR: Predicted Reading; PJ: Participants?
Judgementto represent domain entities.
Participants re-ceived a mini-tutorial on our version of Eu-ler diagrams, where shaded areas denote thesets to which an NP might refer.
The pur-pose of this tutorial was to make sure thatthe participants understand the semantics ofthese diagrams.
A sample trial is shown inFigure 2 (where we expect that participantswould remove the diagram on the right, whichis counted as a wide-scope response).
60 self-reported native or fluent speakers of English,students from various UK universities, tookpart in this web-based experiment.Figure 2: Interpreting an np (Euler diagrams)Results and Discussion: Results wererecorded according to whether a participantopted for a wide- or narrow-scope reading.
Theparticipants?
responses are shown in Table 3.A two-tailed sign binomial test was used tocalculate statistical significance of the results.This time, all four hypotheses are confirmed.We also observed, however, that in scopallyambiguous expressions, a narrow-scope read-ing tends to be particularly frequent in the ex-treme case where Adj has a zero co-occurrencewith Noun2 (in the bnc).
We note that theseresults are in line with Chantree et alA critic might argue that the problem thatwas noted in connection with Experiment 1applies to Experiment 2 as well, because itshows diagrams involving a ?problematic?
in-436Table 3: Response proportions: Experiment 2Force PR PJ p-valueSCF SMF NS NS (51/60) < 0.001SCF WMF WS WS (55/60) < 0.001WCF SMF NS NS (46/60) < 0.001WCF WMF WS WS (54/60) < 0.001tersection between, for example, bearded andwomen.
The fact that women (arguably) can-not be bearded could cause subjects to re-ject these diagrams (choosing the other dia-gram instead, as in the diagram included inFig.
3, which does not involve such an inter-section).
We would argue, however, that thisdoes not cause an unwanted bias.
The scarcityof bearded women is a legitimate reason forsubjects to believe that a diagram that assertstheir existence cannot be a proper interpreta-tion of ?bearded men and women?
; it is justone of the many things that the corpus-basedapproach captures indirectly, without repre-senting it explicitly.
It is equally applicable toexpressions like ?handsome men and women?,where the corpus tells us that ?handsome?
and?women?
do not go together well (even thoughone probably would not say they do not exist).We have seen that Word Sketches can makereasonable predictions concerning the likeli-hood of the different interpretations of the nps.But an np that is clear (i.e., not likely to bemisunderstood) may have other disadvantages.For example, it may lack fluency or it may beperceived as unnecessarily lengthy.
For thisreason, we also conducted an additional exper-iment in which we tested readers?
preferences.4.2 Choosing the best npThe question of how to choose between differ-ent nps could be approached in a number ofdifferent ways: asking hearers which of sev-eral descriptions they prefer, asking hearersto rate several descriptions, measuring inter-pretation effort (time), measuring hearers?
er-rors etc.. We conducted a readers?
preferenceexperiment where participants were asked tocompare pairs of natural language descriptionsof one and the same target set, selecting theone they found more appropriate.
Brief de-scriptions took the form the Adj Noun1 andNoun2.
Non-brief descriptions took the formsthe Adj Noun1 and the Noun2 (for NS) and theAdj Noun1 and the Adj Noun2 (for WS).
A de-scription is said to be clear if its predicted read-ing is the same as the intended one.
By def-inition a non-brief description is always clear.Each description could either be brief or not(?b) and also clear or not (?c) (but not (?b,?c), as this combination is not applicable inthe present setting).
We expected to find that:Hypothesis 5: (+c,+b) descriptions are pre-ferred over ones that are (+c,?b).Hypothesis 6: (+c,?b) descriptions are pre-ferred over ones that are (?c,+b).4.2.1 Experiment 3In this experiment, referential domains wererepresented using Euler diagrams.
In eachtrial, participants were shown an Euler dia-gram, with some of its area filled to indicatethe target referent.
They were also shown twoEnglish nps, which attempted to identify thefilled area.
A sample trial, where the intendedreading is narrow scope, is shown in Figure3.
Each hypothesis was tested under two con-Figure 3: Sample Trial: Choosing the best npditions: 1) where the intended reading (IR)was WS; and 2) where the IR was NS.
The 4comparisons thus corresponded to 4 conditions(where PR stands for predicted reading):C1.
IR = WS & PR = WS(+c,+b) vs. (+c,?b)C2.
IR = NS & PR = NS(+c,+b) vs. (+c,?b)C3.
IR = WS & PR = NS(?c,+b) vs. (+c,?b)C4.
IR = NS & PR = WS(?c,+b) vs. (+c,?b)46 self-reported native or fluent speakers of En-437glish, students from various UK universities,did the experiment on the web.Results and Discussion: Results werecoded according to whether a participant?schoice was ?b and/or ?c.
Table 4 displaysresponse proportions.
A two-tailed sign bino-mial test was used to calculate statistical sig-nificance of the results.
The results confirmour hypotheses in all conditions, being highlystatistically significant (p < 0.001).Table 4: Response proportions: Experiment 3C1 C2 C3 C4+b 91.3% 67.9% 26.1 14.5+c - - 73.9% 88.5%4.3 Summary of the Empirical DataAs hypothesised, Kilgarriff?s Word Sketchescan be used to predict the most likely read-ing of a scopally ambiguous expression.
It isalso important to note that it is the Modifi-cation Force which is the deciding factor fora particular reading.
Moreover, other thingsbeing equal, brief descriptions are preferredover longer ones.
Since Experiment 2 (and,to an extent, Experiment 1) confirmed our hy-potheses, we could have based our algorithmon these.
As was noted in section 4.1.2, how-ever, our data also suggest a slight modifica-tion of Hypotheses 1 and 3, because a pref-erence for narrow scope existed mainly whenthe Adjective and the second Noun co-occurredvery rarely.
Therefore, we shall use a modifiedversion of Strong Modification Force (SMF):SMF?will mean that Adj and Noun2 have zero(rather than below 30%) cooccurrence in thebnc.5 Applying results to greIn this section, we show how the results ofthe previous sections can be exploited in gre.The patterns explored in the above correspondto disjunctive plural references.
Disjunction isrequired whenever there is no conjunction ofatomic properties that sets the elements of aset of referents apart from all the other ob-jects in the domain.
Recall example 1 (from?1), where the aim is to single out the blacksheep and black goats from the rest of the an-imals.
This task cannot be performed by asimple conjunction (i.e., of the form ?the X?,where X contains adjectives and nouns only),so disjunctions become unavoidable.Various proposals have been made for al-lowing gre algorithms to produce referringexpressions of this kind (Stone, 2000; vanDeemter, 2002; Gardent, 2002; Horacek,2004).
Here we take as our starting point theapproach of (Gatt, 2007) (henceforth Gatt?sAlgorithm with Partitioning or gap).
gap isthe only algorithm that produces a dd in Dis-junctive Normal Form (dnf) while also guar-anteeing that every ?part?
of the partitioncontains a noun.
The dnf takes the form:S1?
S2... ?
Sn, where each Siitself expressesa conjunction of atomic properties.
(For ex-ample, S1might be Sheep ?
Black, while S2is Goat ?
Black.)
We sketch two extensions ofthis approach: the first, purely formal exten-sion ensures that a set of such logical formulaeis generated, rather than just one formula; allof these formulae are unambiguous, and logi-cally equivalent with each other; but they allmap to different strings of words.
This is be-cause we assume a very direct Linguistic Real-isation strategy in which, for example, ((Black?
Sheep) ?
Goats) is worded as the black sheepand goats; syntactic ambiguity results from thelack of brackets in the English np.
The sec-ond, empirically based extension is to choosethe ?best?
element of the set (of formulae) bymaking use of our experimental outcomes so asto balance clarity and brevity.Since our predictions are based on words,we propose a model that constructs descrip-tions from words and in which the descriptionbuilding process is driven by words.
We com-pute the extension (where the extension of aword w consists of all objects to which w ap-plies) of a potentially ambiguous word by uni-fying the extensions of all its interpretations.Let p1, p2, ..., pnbe the properties that a wordw can express.
Then the extension of w is:[[ w ]] =i=n?i=1[[ pi]] (1)In what follows, a domain consists of a set Dof objects, and a set P of properties applicableto objects in D. Given a set of target referentsR ?
D, the proposed algorithm will:?
lexicalise each p ?
P into words; Lexi-calisation takes a property as input and438returns the set of possible realisations ofthat property.
For example, a property,say, aged will be realised as (a set of)words {old, aged, senior}.?
build a dd in dnf using words, where theextension of a word is computed as indi-cated in equation 1.
Each Simust containa head noun.
For example, in the sce-nario presented in Example 1 under ?1, itwould produce a dd like: (black ?
sheep)?
(black ?
goats).?
apply transformation rules on the dd toconstruct a set of dds that are logicallyequivalent to the dd.
(See below.)?
realise each description in the set as En-glish nps using appropriate syntax.
Eachdescription is realised as one and only onenp, using the above realisation strategy.?
determine the most likely reading of eachnp, by making use of Word Sketches.?
select the np that is optimal given our em-pirical findings.
(See below.
)Transformation Rules: In connection withreference to sets, it has been proposed to usethe Q-M algorithm (McCluskey, ) to find theshortest formula equivalent to a given inputformula (van Deemter, 2002).
In the presentsetting, the shortest formula might lead to aconfusing np after linguistic realisation.
Forexample, the formula Black ?
(Cats ?
Dogs)might be realised as the black cats and dogs,which could easily be misunderstood as (Black?
Cats) ?
Dogs.
For this purpose, we proposeto use a set of transformation rules that allowus to find a set of formulae logically equivalentto the original formula; the aim is to make theset large enough that all the relevant expres-sive choices (as investigated in this paper) arerepresented.
In particular, we need the follow-ing rules that operate on dnfs (where A is anadjective; B1and B2are nouns; X and Y arecombinations of adjectives and nouns).1.
((A ?B1) ?
(A ?B2)) ?
(A ?
(B1?B2))2.
(X ?
Y ) ?
(Y ?X)After application of these transformationrules, the original description ?
(i.e., the for-mula produced by an algorithm such as gap)is replaced by a set of formulae F all of whoseelements are logically equivalent to ?.
The el-ements of F are then realised as nps.
The clar-ity of each np is determined as follows (wherePR and IR stand for predicted reading and in-tended reading, respectively).If SMF?
then PR is NSElse If WMF then PR is WSElse PR is {NS, WS}EndIfIf (PR = IR) then NP is clearElse NP is unclearEndIfIf, after transformations, several of the re-sulting descriptions are clear then the choicebetween them needs to be taken on othergrounds.
To do this, we give preference to theshortest of all descriptions that are clear (mea-sured in terms of number of words in the np).If ties still arise then we suggest that fluencyis taken into account, for example by prefer-ring np whose structure is most frequent inthe bnc.
This procedure will often result innps that are ?clear?
even though they are syn-tactically ambiguous.Example 2: Let the domain be repre-sented as: {man(e1, e2, e6), woman(e3, e4, e5),young(e5, e6), old(e1, e2, e3, e4)}.
Our taskis to single out {e1, e2, e3, e4} from rest ofthe entities.
First, properties are lexicalisedinto words.
Suppose the relevant words arethe ones in the list Q = ?man, woman, old,young?.
Then, the algorithm takes each wordw ?
Q in turn and constructs a dd: (old ?man) ?
(old ?
woman).
The transformationrules then produce {old?
(man?woman), old?
(woman?man), (old?man)?
(old?woman),(old?woman)?
(old?man)}.
These formulaeare realised as: (1) the old men and women, (2)the old women and men, (3) the old men andthe old women and (4) the old women and theold men.
The nps (1) and (2) are structurallyambiguous, but the Word Sketches rule out theunintended reading of both nps (with narrowscope for the adjective), so they are both clear.The nps (3) and (4) are structurally unam-biguous.
All nps are therefore clear, but (1)and (2) are preferred because they are shorterthan (3) and (4).
Corpus frequency suggeststhat the tie between (1) and (2) is resolved byopting for the more frequent pattern (1).6 Conclusions and future workWe highlighted that structural ambiguity,which is often ignored in the gre could cause439confusion for a hearer and, therefore, should bedealt with.
Based on psycholinguistic evidencethat avoidance of all ambiguity is hard, we sug-gested an approach that avoids referring ex-pressions that have distractor interpretations.We did: (1) interpretation experiments andfound that Word Sketches can be used to makedistractor interpretation precise; and (2) anexperiment with human readers that trades-off clarity and brevity.
A gre algorithm issketched that balances these factors based onour experimental findings.We aim to extend this work in two direc-tions.
First, we hypothesise that our ap-proach can help nlg systems handle other sur-face ambiguities, for instance involving PP-attachment.
Second, we realise that contex-tual factors are likely to affect people?s inter-pretive and generative inclinations.
Therefore,in light of the work reported in this paper, itwould be interesting to explore the effect ofco-occurrences in a given text upon the inter-pretation of nps occurring later in that sametext, since the effect of such earlier occurrenceson readers?
interpretation could conceivably?drown out?
the generic likelihoods based onWord Sketches that have formed the main sub-ject matter of this paper.ReferencesAbney, S. 1996.
Statistical methods and linguis-tics.
In Klavans, Judith and Philip Resnik, ed-itors, The Balancing Act: Combining Symbolicand Statistical Approaches to Language, pages 1?26.
The MIT Press, Cambridge, Massachusetts.Chantree, F., B. Nuseibeh, A. de Roeck, andA.
Willis.
2006.
Identifying nocuous ambigui-ties in requirements specifications.
In Proceed-ings of 14th IEEE International RequirementsEngineering conference, Minnesota, U.S.A.Dale, R. 1992.
Generating Referring Expressions:Building Descriptions in a Domain of Objectsand Processes.
MIT Press.Gardent, C. 2002.
Generating minimal definitedescriptions.
In Proceedings of the 40th AnnualMeeting of the ACL, Philadelphia, USA.Gatt, A.
2007.
Generating Coherent Referencesto Multiple Entities.
Ph.D. thesis, University ofAberdeen, Aberdeen, Scotland.Horacek, H. 2004.
On referring to sets of objectsnaturally.
In Proceedings of the 3rd InternationalConference on NLG, pages 70?79, UK.Inui, K., T. Tokunaga, and H. Tanaka.
1992.
Textrevision: A model and its implementation.
InProceedings of the 6th International Workshopon NLG, pages 215?230, Berlin, Heidelberg.Kilgarriff, A.
2003.
Thesauruses for natural lan-guage processing.
In Proceedings of NLP-KE,pages 5?13, Beijing, China.Krahmer, E. and M. Theune.
2002.
Efficientcontext-sensitive generation of referring expres-sions.
In van Deemter, K. and R. Kibble, editors,Information Sharing: Reference and Presupposi-tion in Language Generation and Interpretation,CSLI Publications, pages 223?264.McCluskey, E. J.
Introduction to the Theory ofSwitching Circuits.
McGraw-Hill Book Co.Neumann, G. 1994.
A Uniform ComputationalModel for Natural Language Parsing and Gener-ation.
Ph.D. thesis, University of the Saarland.Reiter, E. and R. Dale.
2000.
Building NaturalLanguage Generation Systems.
Cambridge Uni-versity Press.Siddharthan, A. and A. Copestake.
2004.
Gener-ating referring expressions in open domains.
InProceedings of the 42nd Annual Meeting of theACL, Barcelona, Spain.Stone, M. and B. Webber.
1998.
Textual economythrough close coupling of syntax and semantics.In Proceedings of the 9th International Workshopon NLG, pages 178?187, New Brunswick, NewJersey.Stone, M. 2000.
On identifying sets.
In Proceed-ings of the 1st INLG Conference, pages 116?123,Mitzpe Ramon.Tanenhaus, M.K.
and J.C. Trueswell.
1995.
Sen-tence comprehension.
In Miller, J. and P. Eimas,editors, Handbook of Perception and Cognition,Vol.
11: Speech, Language and Communication,pages 217?262.
New York: Academic Press.van Deemter, K. 2002.
Generating referring ex-pressions: Boolean extensions of the incrementalalgorithm.
Comp.
Linguistics, 28(1):37?52.van Deemter, K. 2004.
Towards a probabilisticversion of bidirectional OT syntax and seman-tics.
Journal of Semantics, 21(3):251?281.Wasow, T., A. Perfors, and D. Beaver.
2005.
Thepuzzle of ambiguity.
In Orgun, O. and P. Sells,editors, Morphology and The Web of Grammar:Essays in Memory of Steven G. Lapointe.
CSLIPublications.Wu, H. and T. Furugori.
1998.
A computationalmethod for resolving ambiguities in coordinatestructures.
In Proceedings of PACLIC-12, pages263?270, National University of Singapore.440
