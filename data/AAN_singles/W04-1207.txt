Event-based Information Extraction for the biomedical domain: the Caderige projectErick Alphonse**, Sophie Aubin*, Philippe Bessi?res**, Gilles Bisson****, Thierry Hamon*,Sandrine Lagarrigue***, Adeline Nazarenko*, Alain-Pierre Manine**, Claire N?dellec**,Mohamed Ould Abdel Vetah**, Thierry Poibeau*, Davy Weissenbacher**Laboratoire d?Informatique de Paris-NordCNRS UMR 7030Av.
J.B. Cl?ment 93430 F-Villetaneuse{firstname.lastname}@lipn.univ-paris13.fr**Laboratoire Math?matique, Informatique et G?nome (MIG),INRA,Domaine de Vilvert, 78352 F-Jouy-en-Josas{firstname.lastname}@jouy.inra.fr***Laboratoire de G?n?tique Animale,INRA-ENSARRoute de Saint Brieuc, 35042 Rennes Cedexlagarrig@roazhon.inra.fr****Laboratoire Leibniz ?
UMR CNRS 552246 Avenue F?lix Viallet - 38031 F-Grenoble CedexGilles.Bisson@imag.frAbstractThis paper gives an overview of theCaderige project.
This project involvesteams from different areas (biology,machine learning, natural languageprocessing) in order to develop high-level analysis tools for extractingstructured information from biologicalbibliographical databases, especiallyMedline.
The paper gives an overviewof the approach and compares it to thestate of the art.1 IntroductionDevelopments in biology and biomedicine arereported in large bibliographical databaseseither focused on a specific species (e.g.Flybase, specialized on DrosophiliaMenogaster) or not (e.g.
Medline).
This typeof  information sources is crucial for biologistsbut there is a lack of tools to explore them andextract relevant information.
While recentnamed entity recognition tools have gained acertain success on these domains, event-basedInformation Extraction (IE) is still a challenge.The Caderige project aims at designing andintegrating Natural Language Processing(NLP) and Machine Learning (ML) techniquesto explore, analyze and extract targetedinformation in biological textual databases.
Wepromote a corpus-based approach focusing ontext pre-analysis and normalization: it isintended to drain out the linguistic variationdimension, as most as possible.
Actually, theMUC (1995) conferences have demonstratedthat extraction is more efficient whenperformed on normalized texts.
The extractionpatterns are thus easier to acquire or learn,more abstract and easier to maintainBeyond extraction patterns, it is also possibleto acquire from the corpus, via ML methods, apart of the knowledge necessary for textnormalization as shown here.This paper gives an overview of currentresearch activities and achievements of theCaderige project.
The paper first presents ourapproach and compares it with the onedeveloped in the framework of a similarproject called Genia (Collier et al 1999).
Wethen propose an account of Caderigetechniques on various filtering andnormalization tasks, namely, sentence filtering,resolution of named entity synonymy,syntactic parsing, and ontology learning.Finally, we show how extraction patterns canbe learned from normalized and annotateddocuments, all applied to biological texts.2 Description of our approachIn this section, we give some details about themotivations and choices of implementation.We then briefly compare our approach with theone of the Genia project.432.1 Project organizationThe Caderige project is a multi disciplinaryFrench research project on the automaticmining of textual data from the biomedicaldomain and is mainly exploratory orientated.
Itinvolved biology teams (INRA), computerscience teams (LIPN, INRA and Leibniz-IMAG) and NLP teams (LIPN) as majorpartners, plus LRI and INRIA from 2000 to2003.2.2 Project motivationsBiologists can search bibliographic databasesvia the Internet, using keyword queries thatretrieve a large superset of relevant papers.Alternatively, they can navigate throughhyperlinks between genome databanks andreferenced papers.
To extract the requisiteknowledge from the retrieved papers, theymust identify the relevant abstracts orparagraphs.
Such manual processing is timeconsuming and repetitive, because of thebibliography size, the relevant data sparseness,and the database continuous updating.
Fromthe Medline database, the focused query?Bacillus subtilis and transcription?
whichreturned 2,209 abstracts in 2002, retrieves2,693 of them today.
We chose this examplebecause Bacillus subtilis is a model bacteriumand transcription is a central phenomenon infunctional genomics involved in genicinteraction, a popular IE problem.GerE stimulates cotD transcription andinhibits cotA transcription in vitro bysigma K RNA polymerase, as expected fromin vivo studies, and, unexpectedly,profoundly inhibits in vitrotranscription of the gene (sigK) thatencode sigma K.Figure 1: A sentence describing a genic interactionOnce relevant abstracts have been retrieved,templates should be filled by hand since thereis no available IE tool operational in genomicsType: positiveAgent: GerEInteractionTarget: transcription of thegene sigKFigure 2: A template describing a genicinteraction.Still, applying IE ?
la MUC to genomics andmore generally to biology is not an easy taskbecause IE systems require deep analysismethods to locate relevant fragments.
Asshown in the example in Figures 1 and 2,retrieving that GerE is the agent of theinhibition of the transcription of the gene sigKrequires at least syntactic dependency analysisand coordination processing.
In most of thegenomics IE tasks (function, localization,homology) the methods should then combinethe semantic-conceptual analysis of textunderstanding methods with IE through patternmatching.2.3 Comparison with the Genia projectOur approach is very close to the one of theGenia project (Collier et al, 1999).
Bothprojects rely on precise high-level linguisticanalysis to be able to perform IE.
The kind ofinformation being searched is similar,concerning mainly gene and protein interactionas most of the research in this domain.
TheGenia corpus (Ohtae et al 2001) is notspecialized on a specific species whereas oursis based on Bacillus Subtilis.Both projects develop annotation tools andDocument Type Definition (DTD), which are,for the most part, compatible.
The aim here isto build training corpus to which varioustechniques of NLP and ML are applied inorder to acquire efficient event-basedextraction patterns.
The choice of ML andNLP methods differs but their aim is similar toour: normalizing text with predicate-argumentsstructures for learning better patterns.
Forexample, Genia uses a combination of parsersto finally perform an HPSG-like analysis.
TheCaderige syntactic analysis is based on thespecialization of the Link Parser (Sleator andTemperley, 1993 see section 4) to thebiological domain.In the following two sections, we detail ourtext filtering and normalization methods.Filtering aims at pruning the irrelevant part ofthe corpus while normalization aims atbuilding an abstract representation of therelevant text.
Section 4 is devoted to theacquisition of extraction patterns from thefiltered and normalized text.3 Text filteringIR and text filtering are a prerequisite step toIE, as IE methods (including normalization andlearning) cannot be applied to large andirrelevant corpora (they are not robust enoughand they are computationally expensive).
IRhere is done through Medline interface bykeyword queries for filtering the appropriate44document subset.
Then, text filtering, reducesthe variability of textual data with thefollowing assumptions:?
desired information is local to sentences ;?
relevant sentences contain at least two genenames.These hypotheses may lead to miss some genicinteractions, but we assume that informationredundancy is such that at least one instance ofeach interaction is contained into a singlesentence in the corpus.
The documentsretrieved are thus segmented into sentencesand the sentences with at least two gene namesare selected.To identify the only relevant sentences amongthoses,  classical supervised ML methods havebeen applied to a Bacillus Subtilis corpus inwhich relevant and irrelevant sentences hadbeen annotated by a biological expert.
AmongSVMs, Na?ve Bayes (NB) methods, NeuralNetworks, decision trees (Marcotte et al,2001;  Nedellec et al, 2001), (Nedellec et al2001) demonstrates that  simple NB methodscoupled with feature selection seem to performwell by yielding around 85 % precision andrecall.
Moreover, our first experiments showthat the linguistic-based representation changessuch as the use of lemmatization, terminologyand named entities, do not lead to significantimprovements.
The relevant sentences filteredat this step are then used as input of the nexttasks, normalization and IE.4 NormalizationThis section briefly presents three textnormalization tasks: normalization of entitynames, normalization of relations between textelements through syntactic dependency parsingand semantic labeling.
The normalizationprocess, by providing an abstractrepresentation of the sentences, allows theidentification of regularities that simplify theacquisition or learning of pattern rules.4.1 Entity names normalizationNamed Entity recognition is a critical point inbiological text analysis, and a lot of work waspreviously done to detect gene names in text(Proux and al., 1998), (Fukuda and al., 1998).So, in Caderige, we do not develop anyoriginal NE extraction tool.
We focus on a lessstudied problem that is synonyms recognition.Beyond typographical variations andabbreviations, biological entities often haveseveral different names.
Synonymy of genenames is a well-known problem, partly due tothe huge amount of data manipulated (43.238references registered in Flybase forDrosophilia Melanogaster for example).
Genesare often given a temporary name by abiologist.
This name is then changed accordingto information on the concerned gene: forexample SYGP-ORF50 is a gene nametemporarily attributed by a sequencing projectto the PMD1 yeast gene.
We have shown that,in addition to available data in genomicdatabase (GenBank, SwissProt,?
), it ispossible to acquire many synonymy relationswith good precision through text analysis.
Byfocusing on synonymy trigger phrases such as"also called" or "formerly", we can extract textfragments of that type :  gene trigger gene.However, the triggers themselves are subject tovariation and the arguments of the synonymyrelation must be precisely identified.
We haveshown that it is possible to define patterns torecognize synonymy expressions.
Thesepatterns have been trained on a representativeset of sentences from Medline and then testedon a new corpus made of 106 sentencescontaining the keyword formerly.
Results onthe test corpus are the following: 97.5%precision, 75% recall.
We chose to have a highprecision since the acquired information mustbe valid for further acquisition steps(Weissenbacher, 2004).The approach that has been developed is verymodular since abstract patterns like genetrigger gene (the trigger being a linguisticmarker or a simple punctuation) can beinstantiated by various linguistic items.
Ascore can be computed for each instantiation ofthe pattern, during a learning phase on a largerepresentative corpus.
The use of a reducedtagged corpus and of a large untagged corpusjustify the use of semi-supervised learningtechniques.4.2  Sentence parsingThe extraction of structured information fromtexts requires precise sentence parsing toolsthat exhibit relevant relation between domainentities.
Contrary to (Akane et al 2001), wechose a partial parsing approach: the analysisis focused on relevant parts of texts and, fromthese chunks, on specific relations.
Severalreasons motivate this choice: among others, thefact that relevant information generally appearsin predefined syntactic patterns and, moreover,45the fact that we want to learn domainknowledge ontologies from specific syntacticrelations (Faure and Nedellec, 2000 ; Bisson etal.
2000).First experiments have been done on severalshallow parsers.
It appeared that constituentbased parsers are efficient to segment the textin syntactic phrases but fail to extract relevantfunctional relationships betweens phrases.Dependency grammars are more adequatesince they try to establish links between headsof syntactic phrases.
In addition, as describedin Schneider (1998), dependency grammars arelooser on word order, which is an advantagewhen working on  a domain specific language.Two dependency-based syntactic parsers havebeen tested (Aubin 2003): a hybrid commercialparser (henceforth HCP) that combinesconstituent and dependency analysis, and apure dependency analyzer: the Link Parser.Prasad and Sarkar (2000) promote a twofoldevaluation for parsers: on the one hand the useof a representative corpus and, on the otherhand, the use of specific manually elaboratedsentences.
The idea is to evaluate analyzers onreal data (corpus evaluation) and then to checkthe performance on specific syntacticphenomena.
In this experiment, we chose tohave only one corpus, made of sentencesselected from the Medline corpus dependingon their syntactic particularity.
This strategyensures representative results on real data.A set of syntactic relations was then selectedand manually evaluated.
This led to the resultspresented for major relations only in table 1.For each analyzer and relation, we compute arecall and precision score (recall = # relevantfound relations / # relations to be found;precision = # relevant found relations / #relations found by the system).The Link Parser generally obtains better resultsthan HCP.
One reason is that a majorparticularity of our corpus (Medline abstracts)is that sentences are often (very) long (27words on average) and contain several clauses.The dependency analyzer is more accurate toidentify relevant relationships betweenheadwords whereas the constituent parser islost in the sentence complexity.
We finallyopted for the Link Parser.
Another advantageof the Link Parser is the possibility to modifyits set of rules (see next subsection).
The Linkparser is currently used in INRA to extractsyntactic relationships from texts in order tolearn domain ontologies on the basis of adistributional analysis (Harris 1951, Faure andN?dellec, 1999).4.3 Recycling a general parser for biologyDuring the evaluation tests, we noticed thatsome changes had to be applied either to theparser or to the text itself to improve thesyntactic analysis of our biomedical corpus.The corpus needs to be preprocessed: sentencesegmentation, named entities and termsrecognition are thus performed using genericmodules tuned for the biology domain1.
Termrecognition allows the removing of numerousstructure ambiguities, which clearly benefitsthe parsing quality and execution time.1A term analyser is currently being built at LIPNusing existing term resources like Gene Ontology(see Hamon and Aubin, 2004).Link Parser HCPRel nbRel relOK R. RelTot P. RelOK R RelTot P.Subject18 13 0.72 19 0.68 14 0.78 20 0.65Object18 16 0.89 17 0.94 9 0.5 13 0.69Prep48 25 0.52 55 0.45 20 0.42 49 0.41V-GP114 13 0.93 15 0.87 9 0.64 23 0.39O-GP16 7 0.43 12 0.58 12 0.75 28 0.43NofN16 13 0.81 15 0.87 14 0.87 26 0.54VtoV10 9 0.9 9 1 7 0.7 7 1VcooV10 8 0.8 9 0.89 6 0.6 6 1NcooN10 8 0.7 10 0.8 4 0.4 6 0.67nV-Adj10 8 0.8 9 0.89 0 0 0 1PaSim18 17 0.94 18 0.94 17 0.94 22 0.77PaRel12 11 0.92 11 1 8 0.67 11 0.73Table 1: Evaluation of two parsers on various syntactic relationsRelations meaning: subject = subject-verb, Object = verb-object, Prep = prepositional phrase, V-GP = verb-prep.phrase, O-GP = Object- prep.
phrase, NofN = Noun of noun, VtoV = Verb to Verb, VcooV = Verb coord.
Verb,NcooN = Noun coord.
Noun, nV-Adj = not + Verb or adjective, PaSim = passive form, PaRel = passive relative46Concerning the Link Parser, we have manuallyintroduced new rules and lexicon to allow theparsing of syntactic structures specific to thedomain.
For instance, the Latin-derived NounAdjective phrase "Bacillus subtilis" has astructure inverse to the canonical English nounphrase (Adjective Noun).
Another major taskwas to loosen the rules constraints becauseMedline abstracts are written by biologistswho express themselves in sometimes brokenEnglish.
A typical error is the omission of thedeterminant before some nouns that requireone.
We finally added words unknown to theoriginal parser.4.4 Semantic labellingAsium software is used to semi-automaticallyacquire relevant semantic categories bydistributional semantic analysis of parsedcorpus.
These categories contribute to textnormalization at two levels, disambiguatingsyntactic parsing and typing entities andactions for IE.
Asium is based on an originalascendant hierarchical clustering method thatbuilds a hierarchy of semantic classes from thesyntactic dependencies parsed in the trainingcorpus.
Manual validation is required in orderto distinguish between different meaningsexpressed by identical syntactic structures.5 Extraction pattern learningExtraction pattern learning requires a trainingcorpus from which the relevant anddiscriminant regularities can be automaticallyidentified.
This relies on two processes: textnormalization that is domain-oriented but nottask-oriented (as described in previoussections), and task-oriented annotation by theexpert of the task.5.1 Annotation procedureThe Caderige annotation language is based onXML and a specific DTD (Document TypeDefinition that can be used to annotate bothprokaryote and eukaryote organisms by 50tags with up to 8 attributes.
Such a precision isrequired for learning feasibility and extractionefficiency.
Practically, each annotation aims athighlighting the set of words in the sentencedescribing:?
Agents (A): the entities activating orcontrolling the interaction?
Targets (T): the entities that are producedor controlled?
Interaction (I): the kind of controlperformed during the interaction?
Confidence (C): the confidence level in thisinteraction.The annotation of ?A low level of GerEactivated transcription of CotD by GerE RNApolymerase in vitro ...?
is given below.
Theattributes associated to the tag <GENIC-INTERACTION> express the fact that theinteraction is a transcriptional activation andthat it is certain.
The other tags (<IF>,<AF1>, ?)
mark  the agent (AF1 and AF2), thetarget (TF1) and the interaction (IF).<GENIC-INTERACTIONid=?1?type=?transcriptional?assertion=?exist?regulation=?activate?uncertainty=?certain?self-contained=?yes?text-clarity=?good?><IF>A<I> low level </I>of</IF><AF1><A1type=proteinrole=modulatedirect=yes> GerE</A1></AF1>,<IF><I>activated</I> transcriptionof</IF><TF1><T1 type=protein> CotD </T1></TF1> by<AF2><A2type=proteinrole=required>GerE RNA polymerase</A2></AF2>,<CF>but<C>in vitro</C></CF></GENIC-INTERACTION>5.2 The annotation editor2Annotations cannot be processed in text formby biologists.
The annotation frameworkdeveloped by Caderige provide a general XMLeditor with a graphic interface for creating,checking and revising annotated documents.For instance, it displays the text with graphicattributes as defined in the editor XML stylesheet, it allows to add the tags without strongconstraint on the insertion order and itautomatically performs some checking.The editor interface is composed of four mainparts (see Figure 3).
The editable text zone forannotation, the list of XML tags that can beused at a given time, the attributes zone to editthe values of the selected tag, and the XML2Contact one of the authors if you are interested touse this annotation tool in a research project47code currently generated.
In the text zone, theabove sentence is displayed as follows:A low level of GerE activatedtranscription of CotD by GerE RNApolymerase but in vitroThis editor is currently used by some of theCaderige project partners and at SIB (SwissInstitute of BioInformatics) with another DTD,in the framework of the European BioMintproject.
Several corpora on various specieshave been annotated using this tool, mainly bybiologists from INRA.5.3 LearningThe vast majority of approaches relies onhand-written pattern rules that are based onshallow representations of the sentences (e.g.Ono et al, 2001).
In Caderige, the deepanalysis methods increase the complexity ofthe sentence representation, and thus of the IEpatterns.
ML techniques appear therefore veryappealing to automate the process of ruleacquisition (Freitag, 1998; Califf et al, 1998;Craven et al, 1999).Learning IE rules is seen as a discriminationtask, where the concept to learn is a n-aryrelation between arguments which correspondto the template fields.
For example, thetemplate in figure 2 can be filled by learning aternary relation genic-interaction(X,Y,Z),where X,Y and Z are the type, the agent andthe target of the interaction.
The learningalgorithm is provided with a set of positive andnegative examples built from the sentencesannotated and normalized.
We use therelational learning algorithm, Propal (Alphonseet al, 2000).
The appeal of using a relationalmethod for this task is that it can naturallyrepresent the relational structure of thesyntactic dependencies in the normalizedsentences and the background knowledge ifneeded, such as for instance semantic relations.For instance, the IE rules learned by Propalextract, from the following sentence :"In thismutant, expression of the spoIIG gene, whosetranscription depends on both sigA and thephosphorylated Spo0A protein, Spo0AP, amajor transcription factor during early stagesof sporulation, was greatly reduced at 43degrees C.", successfully extract the tworelations genic-interaction(positive, sigA,spoIIG) and genic-interaction(positive,Spo0AP, spoIIG).
As preliminary experiments,we selected a subset of sentences as learningdataset, similar to this one.
The performance ofthe learner evaluated by ten-fold cross-validation is 69?6.5% of recall and 86?3.2%of precision.
This result is encouraging,showing that the normalization processprovides a good representation for learning IErules with both high recall and high precision.6 ConclusionWe have presented in this paper some resultsfrom the Caderige project.
Two major issuesare the development of a specific annotationeditor for domain specialists and a set ofmachine learning and linguistic processingtools tuned for the biomedical domain.Current developments focus on the use oflearning methods in the extraction process.These methods are introduced at differentlevels in the system architecture.
A first use isFigure 3: the Caderige annotation editor48the acquisition of domain knowledge toenhance the extraction phase.
A second useconcerns a dynamic adaptation of existingmodules during the analysis according tospecific features in a text or to specific textgenres.7 ReferencesE.
Agichtein and H. Yu (2003).
Extractingsynonymous gene and protein terms frombiological literature.
Bioinformatics, vol.
19Suppl.1, Oxford Press.E.
Alphonse and C. Rouveirol (2000).
Lazypropositionalisation for RelationalLearning.
In 14th European Conference onArtificial Intelligence (ECAI?00, W. Horn ed.
),Berlin, pp.
256-260.S.
Aubin (2003).
?valuation comparative de deuxanalyseurs produisant des relations syntaxiques.In workshop TALN and multilinguism.
Batz-sur-Mer.Y.
Akane, Y. Tateisi, Y. Miyao and J.
Tsujii.(2001).
Event extraction from biomedical papersusing a full parser.
In Proceedings of the sixthPacific Symposium on Biocomputing (PSB 2001).Hawaii, U.S.A.. pp.
408-419.G.
Bisson, C. Nedellec, L. Ca?amero 2000.Designing clustering methods for ontologybuilding: The Mo?K workbench.
In Proceedingsof Ontology Learning workshop (ECAI 2000),Berlin, 22 ao?t 2000.M.
E. Califf, 1998.
Relational Learning Techniquesfor Natural Language Extraction.
Ph.D.Disseration, Computer Science Department,University of Texas, Austin, TX.
AI TechnicalReport 98-276.N.
Collier, Hyun Seok Park, Norihiro Ogata, YukaTateisi, Chikashi Nobata, Takeshi Sekimizu,Hisao Imai and Jun'ichi Tsujii.
(1999).
TheGENIA project: corpus-based knowledgeacquisition and information extraction fromgenome research papers.
In Proceedings of theEuropean Association for ComputationalLinguistics (EACL 1999).M.
Craven et al, 1999.
Constructing BiologicalKnowledge Bases by Extracting Informationfrom Text Sources.
ISMB 1999: 77-86D.
Faure and C. Nedellec (1999).
Knowledgeacquisition of predicate argument structures fromtechnical texts using Machine Learning: thesystem ASIUM.
In EKAW'99, pp.
329-334,Springer-Verlag.D.
Freitag, 1998, Multistrategy learning forinformation extraction.
In Proceedings of theFifteenth International Conference on MachineLearning, 161-169.
Madison, WI: MorganKaufmannT.
Hamon and S. Aubin (2004).
Evaluatingterminological resource coverage for relevantsentence selection and semantic class building.LIPN internal report.K.
Fukuda, T. Tsunoda, A. Tamura, T. Takagi(1998).
Toward information extraction :identifying protein names from biological papers.Proceedings of the Pacific Symposium ofBiocomputing, pp.
707-718.Z.
Harris (1951).
Methods in Structural Linguistics.Chicago.
University of Chicago Press.E.M.
Marcotte, I. Xenarios I., and D. Eisenberg(2001).
Mining litterature for protein-proteininteractions.
In Bioinformatics, vo.
17 n?
4,pp.
359-363.MUC (1995) Proceeding of the 6thMessageunderstanding Conference.
Morgan Kaufmann.Palo Alto.C.
N?dellec, M. Ould Abdel Vetah and P. Bessi?res(2001).
Sentence Filtering for InformationExtraction in Genomics: A ClassificationProblem.
In Proceedings of the InternationalConference on Practical Knowledge Discovery inDatabases (PKDD?2001), pp.
326?338.
SpringerVerlag, LNAI 2167, Freiburg.T.
Ohta, Yuka Tateisi, Jin-Dong Kim, Hideki Mimaand Jun'ichi Tsujii.
(2001).
Ontology BasedCorpus Annotation and Tools.
In Proceedings ofthe 12th Genome Informatics 2001. pp.
469--470.T.
Ono, H. Hishigaki, A. Tanigami and T. Takagi(2001).
Automated extraction of information onprotein-protein interactions from the biologicalliterature.
Bioinformatics.
vol 17, n?
2, pp.
155-161, Oxford Press.B.
Prasad and A. Sarkar (2000) Comparing Test-suite based evaluation and Corpus-basedevaluation of a wide-coverage grammar forEnglish.
In Using Evaluation within HumanLanguage Technology.
LREC.
Athens.D.
Proux, F. Rechenmann, L. Julliard, V. Pillet, B.Jacq (1998).
Detecting gene symbols and namesin biological texts : a first step toward pertinentinformation extraction.
In Genome Informatics,vol.
9, pp.
72-80.G.
Schneider (1998).
A Linguistic Comparison ofConstituency, Dependency and Link Grammar.PhD thesis, Institut f?r Informatik der Universit?tZ?rich, Switzerland.D.
Sleator and D. Temperley (1993).
ParsingEnglish with a Link Grammar.
In ThirdInternational Workshop on ParsingTechnologies.
Tilburg.
Netherlands.D.
Weissenbacher (2004).
La relation desynonymie en g?nomique.
In Recital conference.Fes.49
