What has language to do with perception?
Some speculations on the Lingua Mentis.Zenon W. PylyshynDepartments of Psychology and Computer ScienceUniversity of Western OntarioLondon, Canadai.
Introduction.The topic under consideration in this confer-ence session (viz.
Language and Perception) is notthe one to which the greatest amount of attentionhas been devoted in philosophy of mind and philos-ophy of language.
There a major concern has beenthe relation between language and thought.
Aseveryone knows there has been a long standing dis-pute regarding whether or not it makes sense toview thought as being carried out in the medium ofnatural language or whether some other form ofrepresentation is involved.
There has not been acomparable dispute over the relationship betweenperception and language.
For one thing no one tomy knowledge has proposed that perception occursthrough the medium of natural language (thoughsome early behaviorist writings come close,especially in respect to memory for perceptualevents).
What I propose to consider in thisbrief note are some respects in which the lan-guage-thought relationship is similar to thelanguage-perception relationship.2.
Language and Thought.At least since Aristotle there has been specu-lation and argument concerning the form (or lan-guage) of thought.
Many contemporary philosophers(e.g., Quine, Sellars, Harman) as well as somepast students of language (e.g., Whorf, Humbolt)believe that we think in our "outer" naturallanguage: that knowing a language is being ableto think in it.
Harman (1975) takes a sophis-ticated approach to this position.
He arguesthat in thinking in one's spoken language oneneed not parse or disambiguage it--since thatwould get us into the vicious circle of having toparse the thought into something which itselfwould be a thought and hence in need of furtheranalysis.
In Harman's view our thoughts arecarried by "sentences under analysis" or by am-biguity-free already analysed sentence structures(e.g., P-markers).
One problem with this view isthat it denies the possibility of thought inanimals and pre-verbal children.
Other diffi-culties were recognized by psychologists.
In thebeginning of this century the Wurzburg school wasable to argue that much of our thinking was un-conscious.
A more modern view (e.g., Paivio,1975) takes the conscious experience of thoughtsas occurring in language or in imagery as itsstarting point and demonstrates by operationalmeans that at least two distinct modes of thoughtneed to be postulated.
This "dual code" approachis quite widely held in psychology although it isnot precisely clear what intrinsic properties arebeing claimed for the imagistics mode of thought.But more on this later.My own view, which I have been espousing forsome half dozen years, is that an adequate accountof the process underlying thought will show it asoccurring in a symbolic mode which has few of theproperties we would normally ascribe to eithernatural language or to images.
For example, thevehicle of thought does not require words (butonly concepts) nor does it have such intrinsicproperties as size or shape.
Rather it consists,as do all computations, of the transformation offormal symbolic expressions whose terms are givenan intentional interpretation by the theoretican.In other words, thought is a symbol manipulationprocess.
Because the data structures represent-ing thoughts have an implicit syntax and becauseits terms and composite expressions are interpre-ted, one can think of them as expressions of aninternal language-or lingua mentis--call it"mentalese".While the particular arguments and examplesI have presented in support of this position havevaried over the years the thrust of the argumentshas always been a two-pronged one.
On the onehand I maintain that criteria of explanatoryadequacy require one to give an account of certainspecifically cognitive phenomena in a manner whichneither presupposes certain crucial propertieswhich themselves require a cognitive explanation,nor avoids a complete process explanation (involv-ing a reduction to primitive mental operations) byattributing certain phenomena to intrinsic featuresof the brain.
On the other hand, the argument hasalways appealed to empirical evidence.
It is thedual requirement of meeting explanatory criteriaand empirical evidence that has, for me, been thebasis of my rejection of specific imagistic modelssuch as those of Paivio, Kosslyn, and Shepard.This is obviously the wrong forum in which tocontinue this debate especially since many of thedetails are peripheral to our present concerns.However, I do want to elaborate very briefly onwhat I referred to above as criteria of explan-atory adequacy since I believe that this is thereal crux of the debate, not only over imageryaccounts of thought but also over some of the172issues about language and perception I want toraise later.
Further details can be found inPylyshyn (1978a).The issue about explanatory adequacy is thefollowing.
Positivist doctrine not withstanding,an explanation of a phenomenon has to do more thanpredict or duplicate aspects of the phenomenon.It must also explicitly characterize the proper-ties of the system by virtue of which the observed(or predicted) behavior occurs.
Since some ofthese properties are adventitious or ad hoc whileothers are principled, such a characterization isessential.
Furthermore, the account must separateproperties which are fixed and universal from thosewhich vary from task to task.
To use an analogyfrom logic, it must separate the contribution ofthe notation, the logical axioms and inferencerules from the particular premises used in deriv-ing entailments.
In the case of a process theoryit is not sufficient to simply provide a procedurewhich generates behavior similar to that observedin humans.
We must, in addition, explicitly iso-late those properties and mechanisms which willremain fixed over all cognitive processes (theunderlying system architecture), those which canvary gradually with learning or accomodation butwhose component parts and intermediate states arenot available to the whole system (the compiledskills), and those which represent particularmethods adopted for particular tasks or whichrepresent particular knowledge which the systempossesses {and thus which can change freely).Furthermore, this parametrization or attributionof behavior to separate sources must be individu-ally empirically justified--e.g., we must showthat it is reasonable to postulate such propertiesof the architecture as we do by appealing toempirical evidence.
If we can in this way iso-late the fixed properties and show how these canbe combined to produce the observed behavior,then we would have an account of the behaviorwhich refers it to both fixed universal propertiesand to particular task specific ones.
Such anaccount would not only capture cross-task general-izations but it is the best we can do from a cog-nitive or functional point of view.
Further ex-plication would involve describing, for example,how the fixed properties are realized in neuraltissue or how and why the variable aspects gotto be the way they are given the nature of the'environment-organism interactions.
An accountpartitioned this way would provide a means ofdeducing current behavior from fixed universalproperties of mind and hence would provide abasis for explanation.My main objection to such notions as ana-logues and to such hypothesized mental operationsas scanning and rotation {to cite just two) isthat the empirical evidence does not support theposition that these are primitive properties ofthe mental architecture.
I have argued that inall the proposals I am aware of which postulateanalogues or analogue-like operations on images,there is independent evidence that the phenom-enon in question must be attributed, at least inpart, to tacit knowledge which the system (orperson) possesses or to more articulated andpiece-meal processes than those claimed.
Inother words these analogue operations cannot betaken as explanatory primitive operations in themental architecture.
Consequently to explainthe experimental findings that these terms wereintroduced to account for we are forced to showhow they could be carried out in an architecturein which scanning and rotation are not primi-tive operations.
In such an architecture theprocesses might be quite different (e.g., whilethere might be a subroutine that accomplishes scan-ning or rotation, these particular terms wouldonly be descriptive and not explanatory since thefunctions implied by them would in turn have to beexplained in terms of more detailed computationsusing other more primitive and independently justi-fied opera~ions).
The exact form of the argumentagainst the hypothesis that scanning or rotationare primitive operations in the fixed mental archi-tecture can be found in Pylyshyn (1978a, 1978b).Essentially they depend on showing that certainempirical facts (e.g., that rate of rotationdepends on properties of the figure, the probe, andthe task in general) require for their explanationthat we specify more detailed processes which carryout the function described as rotation or scanning,thus demonstrating that the function was not aprimitive.The general conclusion I draw from these argu-ments is not that talk of analogues or other non-symbolic systems is incoherent or logically ruledout, but only that none of the phenomena whichpeople typically appeal to have been shown to re-quire them--and even if they were admitted theywould, at least in these instances, not be explan-atory in the required sense, though they might wellbe predictive (but then so would a multiple regres-sion equation).
Within the information processingparadigm (i.e.~ excluding phenomenological orpurely neurophysiological explanations for reasonswhich we cannot go into here) the only remainingcandidate paradigm for explaining the nature ofthought is computation, in the sense of transfor-mations on symbolic expressions.
Of course withinthis alternative we may still posit differentsymbols, and even different composite data struc-tures for different areas of cognition.
What Iam saying, however, is that this most basic levelof symbolic representation is the modality inde-pendent medium of thought, the "mentalese" inwhich goals, beliefs, hypotheses, knowledge, andother cognitive states are expressed.What makes this point of view on the rela-tion between language and thought relevant to theperception-language discussion is that mentaleseis not only taken to be the form in which thoughtsare carried, it is also proposed as the appro-priate representation of percepts.3.
Language and Perception.Before discussing the similarities between thelanguage-perception relation and the language-thought relation it may be useful to consider whyone might be motivated to ask about the relationbetween language and perception in the first place.An obvious connection between the two is the factthat we can talk about what we perceive.
But thattells us little about how the two are related.
Weget hints that the relation may be more intimatefrom the widespread use of perceptual terms(especially spatial relation and movement or trans-fer terms) to refer to abstract relations ingeneral.
The experiments on imagery by people likeShepard, Kosslyn, Moyer, Paivio, and others show,173if nothing else, that perception and thought areclosely related.
Thus the issues raised in dis-cussing language and thought become relevant heretoo.But perhaps one of the main reasons why lan-guage and percept ion  are  inext r i cab ly  re la ted  i sthat  the  perceptua l  sys tem i s  the  pr imary  meansthrough which language acqu i res  a semant ics .
Asystem which conta ined  a body o f  data  and a lan -guage processor  might  conce ivab ly  be ab le  to  car ryon a coherent  d ia logue .
But w i thout  a perceptua lcomponent i t  would,  in  an impor tant  sense ,  notknow what i t  was ta lk ing  about .
We cou ld ,  inp r inc ip le ,  change the  ASCII coded s t r ings  in  i t slex icon  and i t  might  conduct  an equa l ly  in te l l igentconversat ion  on an ent i re ly  d i f fe rent  top ic  w i thoutanyth ing  (o ther  than  the  externa l  tokens)  hav ingchanged.
Th is  i s  poss ib le  because  the  on ly  con-s t ra in ts  in  the  sys tem are  in t ra - l ingu is t i c  onesand hence  on ly  l ingu is t i c  and data -base  cons is tencycan be detected .
In  such a sys tem there  i s  nocor respondence  between in terna l  symbols  and th ingsand hence  the  sys tem makes no re ference  to  thewor ld .
I Th is  argument  i s  made w i th  pa in fu l  fo rceby Fodor ( in  p ress ) .
I t  would be  more obv ious  topeop le  in  A .
I .
that  th i s  i s  indeed the  case  i fthey  heeded McDermi t t ' s  (1976) suggest ion  andre f ra ined  from us ing  Eng l i sh  words and phrasesins ide  the i r  p rograms and on ly  employed nonsens ica la tomic  symbols  (GENSYMS).
In  that  case  i t  would bec lear  that  on ly  the  programmer (and not  the  program)knew what i t  was ta lk ing  about .There  i s  in  fac t  a genera l  and la rge ly  ignoredprob lem of  the  d i s t r ibut ion  o f  exp lanatory  burdenbetween program and programmer that  needs  to  be  ex-p l i c i t l y  acknowledged in  d i scuss ions  in  which pro -grams are  presented  as theor ies .
I have  come torea l i ze  over  the  years  that  any c rackpot  theory  canbe imp lemented  on a computer  in  some sense  or  o thers imply  by ass ign ing  the  appropr ia te  names to  var iousth ings  in  the  program (e .g .
,  ca l l  th i s  bu f fe r  "con-sc iousness" ,  that  data  s t ruc ture  an " image"  andth i s  p rocedure  " the  mind 's  eye" ) .
E l sewhere(Py lyshyn ,  in  p reparat ion)  I have  suggested  anumber o f  ways in  which some o f  the  arb i t ra r inesscan be taken  out  o f  th i s  enterpr i se .
Theyinc lude  independent  va l idat ion  o f  the  " f i xedmechan isms"  that  a re  to  serve  as the  pr imi t ivecomponents  out  o f  which cogn i t ive  processes  areconst ructed  (what I ca l led  the  menta l  a rch i tec -tu re )  and the  independent  prov is ion  o f  a t  leas ta par t ia l  in t r ins ic  semant ics  fo r  symbols  in  thesys tem by re la t ing  them to  perceptua l  and motorsubsystems.
A fu r ther  s tep  might  a l so  be toprov ide  the  sys tem wi th  a learn ing  component ( inthe  very  genera l  sense  o f  a h i s to ry -dependentre la t ionsh ip  w i th  an env i ronment )  which woulda l so  serve  to  const ra in  the  in terpretat ion  o fsymbols by connect ing  i t  to  the  phys ica l  wor ldth rough a h i s to r i ca l  causa l  cha in  (c .
f .
,  K r ipke 's ,1972, causa l  theory  o f  re ference) .Now i f  we accept  that  in  o rder  fo r  a sys tem tohave  a semant ics ,  as opposed to  mere ly  a complexin t ra -verba l  deduct ive  sys tem operat ing  on un in ter -p re ted  symbols  (o r  " log ica l  fo rms" ) ,  i t  must  a tleas t  have a perceptua l  component ,  a number o ffundamenta l  quest ions  ar i se .
Though the  wholeissue of semantics is fraught with difficulty Iwill take advantage of the invitation to speculateby rushing in where many have been lost.
Thequestions I shall in a sketchy way comment onconcern the nature of the perception-languagecorrespondence, the way in which this correspon-dence might be represented, and how such a corre-spondence could arise in the first place.3.1 The nature of the language-perceptioncorrespondence.Since the set of perceptual patterns and theset of definite descriptions are both unbounded,the correspondence between the two cannot bethrough existing associative links.
The mappingcan only be given by a recursive procedure whichassociates subpatterns of the language with sub-parts of the percept--in other words the corre-spondence is between some analysis of both des-criptions and percepts.
We are of course no moreaware of the conceptual analysis of percepts thanwe are aware of the analysis of linguistic inputs.Given the necessity of an analysis of both, themost parsimonious story of how this occurs is onewhich assumes that both are analysed into a struc-ture in the same interlingua--viz., mentalese.Contrary to some of my critics on this point(Kosslyn & Pomerantz, 1977; Anderson, 1978) such aview is neither inconsistent nor unnecessarilycomplex.
Independent arguments suggest that atleast this much analysis or translation isnecessary and there is, to my knowledge, no con-vincing argument that more than one form ofinterlingua is needed.
Though this latter possi-bility is not ruled out, the relatively weak con-straints placed on the formal properties of therepresenting medium at present (viz., that it con-sist of sumbol structures) make this possibilityseem unlikely.
Furthermore, the freedom we havein thinking about information received through allmodalities and the readiness with which we forget(outside of experimental settings) how we came toknow something argues that at least memories andthoughts might appropriately be viewed as beingamodal.Another question that arises in connectionwith the nature of the language-perception corre-spondence is whether the formal properties of thetwo are independent or whether one might be ableto explain linguistic properties in terms of per-ceptual or general cognitive ones and vice versa.Such a possibility is most attractive since itwould increase the explanatory power of the re-sulting theories.
On the other hand, there is noa priori necessity that such an explanatory linkexist.
As Chomsky (1975) has frequently pointedout we do not expect to be able to explain whyhumans have certain physical characteristics(e.g., why they have I0 as opposed to 8 toes,etc.)
so why should we expect to explain why thenoun-verb dichotomy appears to be a linguisticuniversal.
Still one might be permitted to hopefor some economy of explanatory principles byunifying over cognitive domains.There is already reason to believe that atleast some of the lexicon can be explained interms of universal properties of perception.Perhaps the clearest and most familiar exampleis the case of color terms.
Berlin and Kay(1969) have demonstrated that color terms invarious cultures form a strict hierarchy so thatlanguages with more color terms invariabl4y in-clude the terms used by languages with few colorterms.
In this example, however, it has been174possible to go further and demonstrate universalcolor perception properties paralleling thelinguistic findings and even to relate these tovisual physiology.
Denny (in press) has cau-tiously suggested the possibility of a similarhierarchy across cultures of lexical systemsfor spatial deixis.
For example, compared toEnglish's two terms "here" and "there",Kikuyu has 8 spatial deictic terms and Eskimohas 88, all forming an inclusive hierarchy.It is not inconceivable that the structureof the lexicon will exhibit many such pointsof contact with perception--at least for concretedescriptive terms.
Is there any reason to believethat this parallel might also hold for other partsof language--specifically for grammar?
There havebeen suggestions that syntactic classes such asnoun or verb or even adjective correspond to con-ceptual categories--to ways of conceptualizing thenamed entitities.
There have even been occasionalsuggestions that grammatical rules are a reflectionof how people conceptualize what they perceive.We must be quite clear about what such claimscan mean.
There is a sense in which these claimsare very likely (but perhaps not too interestingly)true.
For example, when I choose to say "that's ared ball" as opposed to "the color of that ball isred" it seems reasonable that I select a part ofspeech and grammatical form which highlightscertain aspects of what I intend to assert.Grammar provides many options on how essentiallythe same propositional content can be asserted.These alternatives may differ in respect to whichitems are treated as figure and ground (or topicand comment).
Which option we take on a parti-cular occasion no doubt depends, at least in part,on how we conceptualize the situation.
This,however, is very different from the claim thatgrammatical categories represent conceptual cate-gories.
Even less does it suggest that syntacticrules can be expressed in terms of conceptualproperties.
In spite of considerable effort de-voted to the problem no one has, to my knowledge,provided even a glimmer of hope that any parti-cular grammatical rule of language bears anythingbut a conventional relation to things in the per-ceptual field.
It is as though syntactic struc-ture provides a sort of system of codes which canbe exploited to carry conceptual distinctionseven though the system of codes itself is inde-pendent of what it can be used to express.
Infact the linguistic code is rather severely con-strained by properties of the communicationchannel into which it encodes ideas, for ex-ample by the serial nature (i.e., low bandwidth)of our speech and hearing apparatus in contrastwith the richness of our conceptualizations andour perception in general.Since, however, language is in all likeli-hood a function of the same cognitive appa-ratus as is available for other cognitivedomains, we might expect an influence to beapparent at some level--even if not at the levelof rule structures.
For example, if figure-ground organization was a primary mode of struc-turing perception and thought one might expectsyntactic features of some kind to be used con-sistently to reflect this organization--eventhough the code could in principle also be usedto represent quite a different type of concep-tualization or the same conceptualization in adifferent way.
Thus, it is entirely conceiv-able that some predicate-argument type of char-acteristic might be found in grammar, whetherrepresented as a surface taxonomy or some lessobvious way.
Whether or notthis  is the case  isan empirical question in respect to which I don'tbelieve there is wide agreement at present.When it comes to more abstract properties oflanguage, such as some of the putative linguis-tic universals, I believe the possibility ofshowing parallels between language and otherareas of cognition may be more hopeful.
Myrather tentative view on this is based on thebelief that whereas the form of grammar may wellbe an unexplainable consequence of some propertiesof brain structure together with properties ofchannels Of communication, sentence comprehensionmust be implemented on a system with the same ar-chitecture as that used in other areas of cognition.Consequently, there may be some very general pro-cessing constraints that might show up as linguis-tic universals.
In any case, if they appear inlinguistic data at all the effects of system archi-tecture will be seen in abstract universals ratherthat particular language specific syntactic rules.For example, one very general universal prop-erty which Chomsky (1975) has cited as evidence forthe innateness of Universal Grammar is that of"structure dependent rule".
Rather than infer theapparently simplest rule (or the rule whose featuresare most evident on the surface of the set ofsamples) the child infers more complex structure-dependent ones.
For instance, rather than inferthat declaratives and questions are related byvirtue of a certain pattern of permutation of sub-strings of the sentences, the child learns that thepermutation applies over an analysis of the sentenceinto abstract phrases.
Thus, while the simple ruleaccounts for the relation between "The man is tall"and "Is the man tall?
", this would produce the in-correct transformation of "The man who is tall is inthe room" as "Is the man who tall is in the room".Yet children never make the latter error, thus sug-gesting that their hypothesis formulation capacityis constrained in ways characterized by UniversalGrammar.But structure-dependence is not only a phenom-enon of language, it is also ubiquitous in percep-tion.
Even a casual examination of what is invol-ved in visual tasks, such as the solution of geo-metrical analogy problems, makes it clear that therules employed must be sensitive to various levelof abstract structure as opposed to more superfi-cial features of the figure.
In fact it is charac-teristic of all of perception that the structuringof the perceptual field must be hierarchical.
Ifwe were to describe what a child learns in learn-ing to perceive its world we would come to thesame conclusions about vision as Chomsky does withlanguage--viz,, that the way in which the regular-ities of the visual field are captured is con-stained by innate mechanisms in a way which wouldbe described as "structure dependent".There have also been attempts to explain morespecific linguistic universals--such as theSpecified Subject or Subjacency constraints--interms of general properties of the processor (e.g.,Marcus, 1977).
Such studies are only beginningbut I have no doubt that some linguistic propertieswill eventually he attributable to architectual orstrategy properties unique to the human cognitive175system.
How much will be explainable this wayremains an open question.3.2 Representing semantics.The much misused term "semantics" refers tothe interpretation of a symbol system (in thiscase language ) into some other domain.
In a com-puter without a perceptual component the onlysymbols which strictly speaking have a semanticsare ones which are either directly executable bythe hardware or are translated into other symbolswhich are executable.
2 All other symbol struc-tures which are referred to as semantic arereally supports for the deductive apparatus.
Theysimplify the process of deducing new expressionsfrom old ones in such a way as to maintain thetruth of the expressions under a consistent inter-pretation.
This interpretation, however, is pro-vided by the user, not the system.Often what is referred to as the semanticrepresentation has some of the properties of amodel.
For example, it provides a set of objectswhich can be used to evaluate expressions, the waymodels are used in mathematics.
In a sense then,these models form a domain of interpretation.They are not, of course, the ultimate intendeddomain of interpretation.
Expressions are typi-cally intended to refer, for example, to beliefsabout objects in the real world, not to othersymbols.
But this formal model can itself be takento represent such cognitive objects and so providesa formal semantics for the symbolic expressionswhich hopefully is valid in the intended domain.The design of such formal models is a major concernin A.I.
and the computational version of suchsystems are typically hybrid mixtures of modelsand inference schemes.
I will have very littleto say about them here.In a system which does contain a perceptualcomponent there has to be some facility for trans-lating between the perceptual analysis and the lin-guistic analysis.
In order to deal with the"semantic content" of sentences and percepts wemust provide the potential for cross-modality andextra-linguistic correspondence.
I have suggestedthat the most parsimonious view of how this occursis that the end products of both perceptual andlinguistic analyses are conceptual structures, orexpressions in a single symbol system which we callmentalese.
Other alternatives are occasionallyproposed.
We shall very briefly examine one below.There have sometimes been objections to theview that percepts are conceptually analysed intoarticulated symbol systems.
Some people feel thatthis loses the holistic and continuous aspectwhich seems intuitively to characterize percepts.It is hard to know what to make of such intuitions.They seem to suggest to people something more thanthat we see distributed features (e.g., roundness)or continuous properties and therefore that thepercept must represent such properties.
Ratherthese intuitions seem further to suggest that thepercept must have such properties--i.e., it mustnot only represent the property of continuity butit must actually be continuous.
This is a danger-ous direction to pursue, however, since it couldlead one to also claim that percepts actually arelarge, blue, warm, heavy, etc., running us rightinto Leibniz's problem.The only proposals I have seen for dealingwith the holism concern are ones which propose un-analysed objects such as templates or holograms asperceptual representations.
These are not onlyatomic wholes but are clearly relatable to theproximal stimulus, at least in the case of vision.I have discussed such proposals elsewhere(Pylyshyn, 1974; 1978b).
Their inadequacy stemsfrom several sources.
One is that by consideringthe percept to be holistic in this sense one losesthe ability to attend selectively to parts oraspects of it or to notice the respects in whichtwo such representations differ.
Of course, onecan gain this facility back by positing a processof comparison or analysis which yields the moredetailed features--but this is just to postponethe translation into mentalese.
Alternatively onemight posit that the comparison itself is done bya non-symbolic holistic process like that used inmatching holograms.
But here we run into troublewith the sheer empirical facts concerning thecognitive structure of percepts.
The type anddegree of perceived similarity among stimuli can-not be matched by a uniform interpretation-indep-endent process like the hologram one.
To whatextent and in what respect two things are per-ceived to be different depends entirely on what weperceive those things to be.
In other words simi-larity must be defined over an already interpreted--and hence conceptual,nonuniformly detailed, pre-analysed, and articulated--representation.Even a compromise in which the representationis an articulated structure with something like"imagoids" or pieces of templates at its nodes willnot help.
For if those template pieces need in somecases to be further analysed then we are back withthe problems sketched above.
If, on the other hand,they do not need to be analysed then there is nodistinction between this proposal and one in whichthe templates are replaced by atomic symbols--i.e.,terms in the mentalese vocabulary.
Recall thatmentalese terms appear in the output from the per-ceptual system and thus can arise from such per-ceptual properties as "large", "round", "red" orones for which there is no single word in English,such as "sand-like texture" or ones best displayedgraphically.
What mentalese terms there are--i.e.,what well-formed perceptual categories exist--isan empirical question.Whatever merits the proposals for imagisticor analogue representations may have they clearlydo not help the language-perception interfaceproblem since sooner or later the representationmust be analysed in such a way as to be commensur-able with natural language terms.
Whether this isdone at the time of perception, or postponed bystoring an unanalysed proximal stimulus so that itmust be done at the time of sentence generation,does not affect the basic problem.
Other inde-pendent considerations, discussed in Pylyshyn(1973, 1974, 1978b), argue against the view thatunanalysed stimulation is stored in memory.3.3 The genesis of the language-perceptioncorrespondence.In an ear l ie r  paper I noted three  major pre-cond i t ions  for  learn ing  a language .(Pylyshyn,1977).1.
Sensory exper ience must be s t ruc tured .
The"blooming, buzzing confus ion" of  Wil l iam James mustbe suscept ib le  to segmentat ion,  ana lys i s ,  and re -176construction.
Some aspects must be foregroundedrelative to others so that the environment becomesarticulated or differentially noticed in somefashion.2.
Communication codes (both verbal and nonverbal)must likewise be structured.
The stream of vocal orgestural behavior must be perceived as segmented anda distinction between signifyingand nonsignifyingvariation must be made (in generation and/or percep-tion).3.
The occur rence  o f  a speech  act  must be recog-n i zed .
Th is  i s  perhaps  the  most impor tant  but  mostneg lec ted  aspect  o f  p recond i t ions  fo r  languageacqu is i t ion .
Not on ly  must a ch i ld  a t tend  to  theappropr ia te  aspects  o f  h i s  env i ronment ,  but  he mustdo i t  w i th in  the  context  o f  what Mer leau-Pontywould ca l l  ( l oose ly )  an " in tent ion  to  mean".In  th i s  sect ion  I w ish  to  dea l  p r imar i ly  w i ththe  f i r s t  o f  these  precond i t ions  and w i th  what hasto  happen in  o rder  fo r  a s imple  naming or  descr ib -ing  cor respondence  to  occur .
I w i l l  not  dwe l l  onthe  o ther  two precond i t ions  except  to  note  that ,as the  th i rd  precond i t ion  suggests ,  a s imp leassoc ia t ive  pa i r ing  w i l l  not  make one perce ivedpat tern  (e .g .
,  a word) re fer  to  another .
Thepa i r ing  must be conceptua l i zed  and subsequent lyt reated  as a par t i cu la r  k ind  o f  asymmetr ica li r re f lex ive  re la t ion  ca l led  naming or  re ference .Th is  in  tu rn  means that  one pat tern  (e .g .
,  a word)i s  not  s imp ly  an ind icator  that ,  say ,  the  o therpat tern  i s  about  to  appear  but  ra ther  becomes asymbo l i c  sur rogate  fo r  i t s  re ferent .
I t  can thenbe used in arbitrary cognitive combinations withother such surrogates.
It can be used not only in-strumentally to anticipate or to ask for objects,but also to think about, hope for, question, assertsomething about, plan for, and vicariously playwith the designated object.What I would like to consider in a general wayis how a linguistic sign or word can come to referto something in the perceptual field.
Take thesimple example of naming by ostention.
A childis shown a dog and the word "dog" is uttered.Suppose the preconditions are fulfilled.
The firstproblem to be faced is the well known difficultyof how the child is to know that what is beingpointed at is the object rather than any ofits properties.
Alternatively, how is the child toknow whether the word refers to that very objectlying on the carpet with a collar around its neckand a bone in its mouth or any member of theCocker Spaniel family or any canine or mammal orliving creature, and so on.First of all it is clear that what the speaker isreferring to must be a conceptually integral unit forhim--something he can conceptually detach from hiscognitive or phenomenal field.
Secondly, if thehearer is to have any chance of acquiring thesame referent for that word he will also have toto have conceptualized the field in such a way asto individuate the same entity as the speaker.Given the unlimited number of in-principlepossible ways of analyzing the entire ostentionsituation, nothing short of a miracle could ensurethat the same analysis was given by both parti-cipants.- Nothing, that is, except a highly con-straining universal innate mechanism that severelylimits the set of alternatives which are humanlyconceivable.
3 What this in turn comes to is theclaim that the terms of mentalese are innate.This outrageous claim, which is argued for in con-~iderab le  deta i l  by Fodor (1975) ,  i s  a l so  pressedon us by o ther  cons iderat ions  which we take  upbelow.
Th i rd ly ,  the  l i s tener  must use  both  h i spercept ion  o f  the  phys ica l  s i tuat ion  and h isunders tand ing  o f  the  soc ia l  context  to  in fe r  thein tent ions  o f  the  speaker .
Th is  g ives  de f in i t ion -by -os tent ion  a prob lem-so lv ing  character .John Macnamara (1972) has  rev ived  in teres t  inthe  v iew,  o f ten  assoc ia ted  w i th  S t .
August ine ,  that" .
.
.
in fants  learn  the i r  language by f i r s t  determin -ing ,  independent  o f  language,  the  meaning which thespeaker  in tends  to  convey to  them, and by then  work-ing  out  the  re la t ionsh ip  between the  meaning and thelanguage (p. 1 ) . "
In o ther  words the  ch i ld  hasvar ious  sources  o f  ev idence  concern ing  such th ingsas what ob jec ts ,  c lasses  and proper t ies  a re  in  h i senv i ronment  and what the  adu l t  in tends  to  convey ,say ,  by po in t ing  and speak ing  a word.
His task  i sthen  to  make the  in fe rence  to  the  best  hypothes isconcern ing  the  cor respondence  between these  events .But the  quest ion  ar i ses ,  how i s  the  hypothes isformulated?
Clearly this view assumes that therelevant aspects of thought and perception (myfirst precondition) are present prior to languagelearning.
This in turn presupposes that the termsof mentalese are also available prior to languagelearning since the hypothesis must be expressed inmentalese.
But how then is mentalese acquired?The answer is that if it is "acquired" at allno one has the slightest idea how this couldpossibly occur.
The only notion around (as Fodor,197S, has argued) regarding how a new concept (orterm of mentalese) could be learned is one whichsays that what people learn is the relation of thenew concept to some relational structure of alreadyknown concepts.
But this precludes the learning ofany concepts that are not definitional compositesof old ones, and therefore strictly eliminable.Unfortunately, this appears to include most naturalconcepts.
Like the theoretical terms in science,most natural concepts cannot be given a context-freedefinition but rather depend on the entire systemof concepts for their meaning (which is why dictio-nary definitions are invariably circular).
Whileone can speak of the accomodation of linguisticusage (e.g., thereferents of words can vary as wediscover new empirical facts--such as that bothsteam and ice are really just forms of water), theaccomodation of the mental concepts, in terms ofwhich the linguistic terms can be understood,remains a mystery.
The mystery is not lessened,moreover, by talk of motor schemata or "equili-bration" as Piaget does.
In each case ofputative conceptual change the process eitherdepends on assimilating new concepts into arrange-ments (or schemata) made up of old concepts, thusseverely limiting the type of conceptual changepossible, or it is left unexplained.
There is noexplanation, nor even the beginnings of anapproach, for dealing with the accomodation ofschemata  or  conceptua l  s t ruc tures  in to  ones notexpressable as definitional composites of exist-ing ones.
There is, in other words, no inklingas to how a completely new non-eliminable con-cept can come into being.This is in fact an extremely deep problemabout which very little sense has been made.People are sometimes mislead by certain compu-tational metaphors into believing that theproblem can be dispensed with by something likecompilation.
But however attractive that177notion is, as a way of talking about how newprocedures can come into being which are them-selves expressed in terms of new operations, itdoes not generalize to concepts in general.Such a notion works in the case of proceduresbecause the set of computable functions is closedand reduceable to elementary (Turing machine)operations in a way that the set of conceptuali-zations of the world is not.It seems to me that there are two generalavenues open for dealing with this dilemma, bothof which simply raise more questions than theyanswer.
In both cases what we are doing isopting for a different locus for the mystery,rather than resolving it.The first approach is to simply acceptwhat seems an inevitable conclusion and seewhat it entails.
This is the approach taken byFodor (1975) who simply accepts that mentaleseis innate.
This means accepting that virtuallyall unitary concepts of which we are capableare genetically determined.
Compound concepts(such as circular red object) can also be con-structed as well as definitional composites, butthese constitute a minority of our mentalese vo-cabulary.
Of course, there need not be (and infact certainly will not be) a one-one correspon-dence between concepts and words in the spokenlanguage.
It is quite likely that most words docorrespond to concepts, though there have beensuggestions that some words are represented by com-positions of more primitive concepts (e.g., kill =do something to cause to die; never = not ever).So far few, if any, of these suggestions have with-stood empirical tests (c.f., Fodor, Fodor, andGarrett, 1975).
Clearly, however, not allmentalese terms correspond to words.
Not only dosocieties differ in their basic vocabulary but theview of mentalese we have been discussing requiresterms for stable perceptual features which are notencoded in our language) at least not as single words.While the notion of all our concepts beinginnate is repugnant to the contemporary Zeitgeist,part of this attitude may be due to the connota-tions of this way of speaking.
If we thought ofthe innate mentalese vocabulary as correspondingto the fixed structural properties of the compu-tational system, together with the input-outputtransducers, this might not seem as distasteful.Even the simplest modern computer has a consider-able amount of fixed hardware (i.e., innate)structure--including a facility for discriminatingan unlimited number of formal atomic symbols.
Ifeach of these symbols had predetermined potentialreferents (say by virtue of the way they werewired to mechanisms which were eventually connec-ted to transducers), they could be considered.innate concepts.
Of course this is not the wholestory since it is hard to see how many of therequired concepts (e.g., Kant's transcendentalcategories such as space, time and cause) couldbe thought of as wired to transducers.
Theproblem here is that it is still not very clearwhat the force of the claim is when we say thatconcepts, qua interpreted symbol ~, are innate.Conceivably it could mean little more than thatthe constraints on the system of symbols is sogreat that the class of possible interpretations(like the class of realizeable grammars) is ex-tremely limited.
In fact one way that the classof possible interpretations could be characterizedmight be to formulate them interms of the requirement that the only conceptsthe organism can hold are ones expressable interms of a certain "innate vocabulary".
In thatcase, "innate vocabulary" has the same status as"universal grammar"--viz., they both somehowcharacterize the endowed cognitive capacity ofthe organism.This approach to the innateness dilemmaplaces the puzzle of conceptual development ona different mechanism from the usual one of con-cept learning.
Now the problem becomes; giventhat most of the concepts are innate why do theyonly emerge as effective after certain perceptualand cognitive experience and at various levels ofmaturation?Another approach to this dilemma is to locatethe puzzle in yet another quarter.
We think ofthe "innate concepts" as being the representationalcapacity of the fixed hardware architecture--sothat mentalese becomes identified with machinelanguage.
The innate concepts are thus not trulyconcepts but, as suggested above, symptoms of theinterpretive constraints imposed by the computa-tional architecture on the system of availablesymbols.
Now the symbols do have to be exploitedin representing the world, and for any particularmachine architecture their interpretability isconstrained in certain ways.
For example, if acertain subset of available atomic symbols is treat-ed in a certain way by the motor transducer (e.g.,cause the hand to open or the arm to reach out)then they cannot consistently be interpreted as,say, referring to phonemes.Now the problem we had was to explain hownew concepts can develop which are not definablein terms of old ones.
This is the essense ofradical conceptual change or accomodation.
Theparadox arose because the only formal mechanismwhich seemed to be available was symbolic composi-tion (or definition).
A whole new realm of possi-bilities opens up however if we allow non-symbolicchanges to occur--i.e., if we allow the actualhardwared connections or architecture to change.Concepts can then drift or mutate insofar as theconstraints on symbols can change in novel ways.The trouble with this proposal, of course, isthat it is nothing more than a burying of theproblem into hardware.
So long as the relationbetween hardware and symbolic levels is notsystematically understood--so that, for instance,we had some formal rules for how the underlyingarchitecture could change in response to programmedinstructions --then this proposal is not a realalternative.
It does, however, contain onerecurring suggestion which seems to surface in manydifferent contexts and for many different reasons(most, in my view, are invalid)--viz., that thereare some cognitive functions whose realization willrequire that we transcend the symbolic mode anddeal with physical (or, at any rate, a quitedifferent set of symbolic) processes.
Maybe that'swhat Kant had in mind when he spoke of "transcen-dental reasoning".i.FootnotesThe fact that a system without instrinsicsemantics could conceivably still pass theTuring test and meet Newell's criterion for178understanding (viz., "S understands knowledge K ifS uses K whenever appropriate") suggests thatsuch criteria may show that there is a differenceamong (a) achieving "understandin" (b) knowing whatthings, properties, etc.
in the world are beingreferred to, and (c) explaining what such under-standing consists in, or what it means to compre-hend on utterance.
As noted earlier, criteriaof performance are distinct from criteria of ex-planation.2.
Even numerals are not interpreted by themachine.
The transformations of numerals intonumerals carried out by what are called arithmeticcommands are just formal operations on symbols.The user typically interprets the symbols as desig-nating numbers and the operations as designatingthe usual arithmetic operations but he could justas well interpret the symbols as, say, propositionsand the operations as deductions (though the inter-pretation function might be quite complex)--or anyother interpretation which happens to maintain itscoherence.3.
It is understandably not easy to provide anexample of a humanly inconceivable unitary concept.Goodman's "Grue" and "Bleen", introduced to high-light certain problems of induction, may be suchexamples.
Grue is the unitary concept which inEnglish corresponds to the color description "Hasa green color up to time t and a blue color after".Thus in the new system green would be the namegiven to that strange color which is Grue up totime t and Bleen afterwards.
So far as anyoneknows7 concepts like Grue and Bleen never occur inhuman cultures.
However we must not be too pre-sumptive about what concepts actually can exist.Exotic societies frequently provide examples ofwhat are for us inconceivable ways of carving upexperience.
For example Foucault (1972, xv) quotesBorges' citation of an ancient Chinese encyclo-pedia which has the following strange taxonomy.
"Animals are divided into: (a) belonging to theEmperor, (b) embalmed, (c) tame, (d) sucking pigs,(e) sirens, (f) fabulous, (g) stray dogs, (h) in-cluded in the present classification, (i) fren-zied, (j) innumerable, (k) drawn with a veryfine camelhair brush, (i) et cetera, (m) havingjust broken the water pitcher, (n) that from along way off look like flies."
If very strangeconcepts do exist we might find it very hard todecipher them, given our constrained schemata.ReferencesAnderson, J. R. The status of arguments concerningrepresentations for mental imagery.
Psych.Review, in press.Berlin.
B., & Kay, P. Basic color terms.Berkeley: Univ.
of California Press, 1969.Chomsky, N. Reflections on language.
New York:Pantheon, 1975.Denny, J. P. Locating the universals in lexicalsystems for spatial deixis.
Papers from the14th regional meeting of the Chicago LinguisticsSociety, 1978, in press.Fodor, J.
The.
language of thought.
New York:Crowell, 1975.Fodor, J.
A., Tom Swift and his procedural grand-mother.
Cognition, in press.Fodor, J. D., Fodor, J.
A., and Garrett, M. F.The psychological unreality of semantic repre-sentations.
Linguistic Inquiry, 1975, 6, 515-531.Foucault, M. The order of things.
London:Tavistock publication, 1970.Harman, G. Thought.
Princeton, N.J.: PrincetonUniv.
Press, 1973.Kosslyn, S. M., & Pomerantz, J. R. Imagerypropositions and the form of internal repre-sentations.
Cognitive Psychology, 1977, 9,52-76.Kripke, S. A.
Naming and necessity.
In D.Davidson and G. Harman (eds.
), Semantics ofnatural language.
Dordrecht: D. Reidel, 1972.Macnamara, J. Cognitive basis of languagelearning in infants.
Psych.
Review, 1972, 79,1-13.Marcus, M. P. Theory of syntactic recognition fornatural language.
M.I.T.
Ph.D. thesis, Dept.of Electrical Engineering and Computer Science,1977.McDermitt, D. Artificial intelligence meetsnatural stupidity.
Newsletter of the ACMSpecial Interest Group on Artificial Intelli-gence (SIGART), 1976, 57, 4-9.Pa iv io ,  A. V. Neomenta l i sm.
Canadian Journa l  o fPsychology, 1975, 29, 263-291.Pylyshyn, Z. W. What the mind's eye tells themind's brain: a critique of mental imagery.Psych.
Bulletin, 1973, 80, 1-24.Pylyshyn, Z. W. The symbolic nature of mentalrepresentations.
Paper presented at a confer-ence on Objectives and Methodologies inArtificial Intelligence, Canberra, Australia,May, 1974 (mimeo).Pylyshyn, Z. W. What does it take to bootstrap alanguage.
In J. Macnamara (ed.)
Languagelearning and thought.
New York: Academic Press,1977.Pylyshyn, Z. W. The explantory adequacy of cog-nitive process models.
Paper presented at aworkshop on mental representation, M.I.T.,January, 1978a (mimeo).Pylyshyn, Z. W. Imagery and artificial intelligenceIn C. Wade Savage (ed.).
Perception and Cog-nition: Issues in the Foundation of Psychology,(Vol.
IX of Minnesota Studies in the philosophyof science).
Minneapolis, Minn.: Universityof Minnesota Press, 1978.Pylyshyn, Z. W. Towards foundations for CognitiveScience.
Book manuscript, in preparation.179
