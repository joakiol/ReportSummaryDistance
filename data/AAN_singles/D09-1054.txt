Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 514?523,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPA Structural Support Vector Method for Extracting Contexts andAnswers of Questions from Online ForumsWen-Yun Yang?
?Yunbo Cao?
?Chin-Yew Lin?
?Department of Computer Science and EngineeringShanghai Jiao Tong University, Shanghai, China?Microsoft Research Asia, Beijing, Chinawenyun.yang@gmail.com {yunbo.cao; cyl}@microsoft.comAbstractThis paper addresses the issue of extract-ing contexts and answers of questionsfrom post discussion of online forums.We propose a novel and unified model bycustomizing the structural Support VectorMachine method.
Our customization hasseveral attractive properties: (1) it gives acomprehensive graphical representation ofthread discussion.
(2) It designs specialinference algorithms instead of general-purpose ones.
(3) It can be readily ex-tended to different task preferences byvarying loss functions.
Experimental re-sults on a real data set show that our meth-ods are both promising and flexible.1 IntroductionRecently, extracting questions, contexts and an-swers from post discussions of online forums in-curs increasing academic attention (Cong et al,2008; Ding et al, 2008).
The extracted knowl-edge can be used either to enrich the knowledgebase of community question answering (QA) ser-vices such as Yahoo!
Answers or to augment theknowledge base of chatbot (Huang et al, 2007).Figure 1 gives an example of a forum threadwith questions, contexts and answers annotated.This thread contains three posts and ten sentences,among which three questions are discussed.
Thethree questions are proposed in three sentences,S3, S5 and S6.
The context sentences S1 andS2 provide contextual information for questionsentence S3.
Similarly, the context sentence S4provides contextual information for question sen-tence S5 and S6.
There are three question-context-answer triples in this example, (S3) ?
(S1,S2) ?
(S8,S9), (S5)?
(S4)?
(S10) and (S6)?
(S4)?
?This work was done while the first author visited Mi-crosoft Research Asia.Post1: <context id=1> S1: Hi I am looking fora pet friendly hotel in Hong Kong because all ofmy family is going there for vacation.
S2: my fam-ily has 2 sons and a dog.
</context> <questionid=1> S3: Is there any recommended hotel nearSheung Wan or Tsing Sha Tsui?
</question><context id=2, 3> S4: We also plan to go shoppingin Causeway Bay.
</context> <question id=2>S5: What?s the traffic situation around those com-mercial areas?
</question> <question id=3> S6:Is it necessary to take a taxi?
</question> S7: Anyinformation would be appreciated.Post2: <answer id=1> S8: The Comfort Lodgenear Kowloon Park allows pet as I know, and usu-ally fits well within normal budgets.
S9: It is alsoconveniently located, nearby the Kowloon railwaystation and subway.
</answer>Post3: <answer id=2, 3> S10: It?s very crowd inthose areas, so I recommend MTR in Causeway Baybecause it is cheap to take you around.
</answer>Figure 1: An example thread with three posts andten sentences(S10).
As shown in the example, a forum questionusually requires contextual information to com-plement its expression.
For example, the ques-tion sentence S3 would be of incomplete meaningwithout the contexts S1 and S2, since the impor-tant keyword pet friendly would be lost.The problem of extracting questions, contexts,and answers can be solved in two steps: (1) iden-tify questions and then (2) extract contexts and an-swers for them.
Since identifying questions fromforum discussions is already well solved in (Conget al, 2008), in this paper, we are focused on step(2) while assuming questions already identified.Previously, Ding et al (2008) employ general-purpose graphical models without any customiza-tions to the specific extraction problem (step 2).In this paper, we improve the existing models in514three aspects: graphical representation, inferencealgorithm and loss function.Graphical representation.
We propose a morecomprehensive and unified graphical representa-tion to model the thread for relational learning.Our graphical representation has two advantagesover previous work (Ding et al, 2008): unifyingsentence relations and incorporating question in-teractions.Three types of relation should be considered forcontext and answer extraction: (a) relations be-tween successive sentences (e.g., context sentenceS2 occurs immediately before question sentenceS3); (b) relations between context sentences andanswer sentences (e.g., context S4 presents thephrase Causeway Bay linking to answer which isabsent from question S6); and (c) relations be-tween multiple labels for one sentence (e.g., onequestion sentence is unlikely to be the answer toanother question although one sentence can serveas contexts for more than one questions).
Our pro-posed graphical representation improves the mod-eling of the three types of sentence relation (Sec-tion 2.2).Certain interactions exist among questions.
Forexample, question sentences S5 and S6 interact bysharing context sentence S4.
Our proposed graphi-cal representation can naturally model the interac-tions.
Previous work (Ding et al, 2008) performsthe extraction of contexts and answers in multiplepasses of the thread (with each pass correspondingto one question), which cannot address the interac-tions well.
In comparison, our model performs theextraction in one pass of the thread.Inference algorithm.
Inference is usually atime-consuming process for structured prediction.We design special inference algorithms, instead ofgeneral-purpose inference algorithms used in pre-vious works (Cong et al, 2008; Ding et al, 2008),by taking advantage of special properties of ourtask.
Specifically, we utilize two special propertiesof thread structure to reduce the inference (time)cost.
First, context sentences and question sen-tences usually occur in the same post while answersentences can only occur in the following posts.With this properties, we can greatly reduce context(or answer) candidate sets of a question, whichresults in a significant decrease in inference cost(Section 3).
Second, context candidate set is usu-ally much smaller than the number of sentencesin a thread.
This property enables our proposal tohave an exact and efficient inference (Section 4.1).Moreover, an approximate inference algorithm isalso given (Section 4.2).Loss function.
In practice, different applica-tion settings usually imply different requirementsfor system performance.
For example, we expecta higher recall for the purpose of archiving ques-tions but a higher precision for the purpose of re-trieving questions.
A flexible framework shouldbe able to cope with various requirements.
Weemploy structural Support Vector Machine (SVM)model that could naturally incorporate differentloss functions (Section 5).We use a real data set to evaluate our approachto extracting contexts and answers of questions.The experimental results show both the effective-ness and the flexibility of our approach.In the next section, we formalize the problemof context and answer extraction and introduce thestructural model.
In Sections 3, 4 and 5 we givethe details of customizing structural model for ourtask.
In Section 6, we evaluate our methods.
InSection 7, we discuss the related work.
Finally,we conclude this paper in Section 8.2 Problem StatementWe first introduce our notations in Section 2.1 andthen in Section 2.2 introduce how we model theproblem of extracting contexts and answers forquestions with a novel form of graphical represen-tation.
In Section 2.3 we introduce the structuredmodel based on the new representation.2.1 NotationsAssuming that a given thread contains p posts{p1, .
.
.
, pp}, which are authored by a set ofusers {u1, .
.
.
, up}.
The p posts can be furthersegmented into n sentences x = {x1, .
.
.
, xn}.Among the n sentences, m question sentences q ={xq1, .
.
.
, xqm} have been identified.
Our task isto identify the context sentences and the answersentences for those m question sentences.
Moreformally, we use four types of label {C,A,Q, P}to stand for context, answer, question and plain la-bels.
Then, our task is to predict an m ?
n labelmatrix y = (yij)1?i?m,1?j?n, except m elements{y1,q1, .
.
.
, ym,qm} which correspond to (known)question labels.
The element yijin label matrix yrepresents the role that the jth sentence plays forthe ith question.
We denote the ith row and jthcolumn of the label matrix y by yi.and y.j.515y2 y3 y5y4 y6y1 y7{C , P } {C , P } {C , P } {Q } {P } {A, P } {A, P }x1 x2 x3 x4 x5 x6 x7(a) Skip-chain modely2 y3 y5y4 y6y1 y7{C , P } {C , P } {C , P } {Q } {P } {A, P } {A, P }x1 x2 x3 x4 x5 x6 x7(b) Complete skip-chain modely12 y13 y14y11 y1ny22 y23 y24y21 y2nym 2 ym 3 ym 4ym 1 ym n(c) 2D modely12 y13 y14y11 y1ny22 y23 y24y21 y2nym 2 ym 3 ym 4ym 1 ym n(d) Label group modelFigure 2: Structured models2.2 Graphical RepresentationRecently, Ding et al (2008) use skip-chain and2D Conditional Random Fields (CRFs) (Laffertyet al, 2001) to perform the relational learning forcontext and answer extraction.
The skip-chainCRFs (Sutton and McCallum, 2004; Galley, 2006)model the long distance dependency between con-text and answer sentences and the 2D CRFs (Zhuet al, 2005) model the dependency between con-tiguous questions.
The graphical representationof those two models are shown in Figures 2(a)and 2(c), respectively.
Those two CRFs are bothextensions of the linear chain CRFs for the sakeof powerful relational learning.
However, di-rectly using the skip-chain and 2D CRFs with-out any customization has obvious disadvantages:(a) the skip-chain model does not model the de-pendency between answer sentence and multiplecontext sentences; and (b) the 2D model does notmodel the dependency between non-contiguousquestions.To better model the problem of extracting con-texts and answers of questions, we propose twomore comprehensive models, complete skip-chainmodel and label group model to improve the ca-pability of the two previous models.
These twomodels are shown in Figures 2(b) and 2(d).In Figures 2(a) and 2(b), each label node is an-notated with its allowed labels and the labels C, A,Q and P stand for context, answer, question andplain sentence labels, respectively.
Note that thecomplete skip-chain model completely links eachtwo context and answer candidates and the labelgroup model combines the labels of one sentenceinto one label group.2.3 Structured ModelFollowing the standard machine learning setup,we denote the input and output spaces by X andY , then formulate our task as learning a hypoth-esis function h : X ?
Y to predict a y whengiven x.
In this setup, x represents a thread of nsentences and m identified questions.
y representsthe m?
n label matrix to be predicted.Given a set of training examples, S ={(x(i),y(i)) ?
X ?
Y : i = 1, .
.
.
, N}, werestrict ourselves to the supervised learning sce-nario.
We focus on hypothesis functions thattake the form h(x;w) = argmaxy?YF(x,y;w)with discriminant function F : X ?
Y ?
Rwhere F(x,y;w) = wT?(x,y).
As will beintroduced in Section 4, we employ structuralSVMs (Joachims et al, 2009) to find the optimalparameters w. The structural SVMs have sev-eral competitive properties as CRFs.
First, it fol-lows from the maximum margin strategy, whichhas been shown with competitive or even better516performance (Tsochantaridis et al, 2005; Nguyenand Guo, 2007).
Second, it allows flexible choicesof loss functions to users.
Moreover, in general,it has theoretically proved convergence in polyno-mial time (Joachims et al, 2009).To use structural SVMs in relational learning,one needs to customize three steps according tospecific tasks.
The three steps are (a) definition ofjoint feature mapping for encoding relations, (b)algorithm of finding the most violated constraint(inference) for efficient trainings and (c) definitionof loss function for flexible uses.In the following Sections 3, 4 and 5, we describethe customizations of the three steps for our con-text and answer extraction task, respectively.3 Encoding RelationsWe use a joint feature mapping to model the rela-tions between sentences in a thread.
For contextand answer extraction, the joint feature mappingcan be defined as follows,?
(x,y) =???n(x,y)?h(x,y)?v(x,y)?
?,where the sub-mappings ?n(x,y), ?h(x,y), and?v(x,y) encode three types of feature mappings,node features, edge features and label group fea-tures.
The node features provide the basic infor-mation for the output labels.
The edge featuresconsist of the sequential edge features and skip-chain edge features for successive label dependen-cies.
The label group features encode the relationswithin each label group.Before giving the detail definitions of the sub-mappings, we first introduce the context and an-swer candidate sets, which will be used for thedefinitions and inferences.
Each row of the labelmatrix y corresponds to one question.
Assumingthat the ith row yi.corresponds to the questionwith sentence index qi, we thus have two candi-date sets of contexts and answers for this questiondenoted by C and A, respectively.
We denote thepost indices and the author indices for the n sen-tences as p = (p1, .
.
.
, pn) and u = (u1, .
.
.
, un).Then, we can formally define the two candidatesets for the yi.asC ={cj????
?pcj= pqi?
??
?In Question Post, cj6= qi?
??
?Not Question Sentence},A ={aj????
?paj> pqi?
??
?After Question Post, uaj6= uqi?
??
?Not by the Same User}.In the following, we describe formally about thedefinitions of the three feature sub-mappings.The node feature mapping ?n(x,y) encodesthe relations between sentence and label pairs, wedefine it as follows,?n(x,y) =m?i=1n?j=1?n(xj, yij),where ?n(xj, yij) is a feature mapping for a givensentence and a label.
It can be formally defined asfollows,?n(xj, yij) = ?(yij)?
?qi(xj), (1)where ?
denotes a tensor product, ?qi(xj) and?
(yij) denote two vectors.
?qi(xj) contains ba-sic information for output label.
?
(yij) is a 0/1vector defined as?
(yij) = [?C(yij), ?A(yij), ?P(yij)]T,where ?C(yij) equal to one if yij= C, otherwisezero.
The ?A(yij) and ?P(yij) are similarly de-fined.
Thus, for example, writing out ?n(xj, yij)for yij= C one gets,?n(xj, yij) =???qi(xj)00???
context?
answer?
plain.Note that the node feature mapping does not in-corporate the relations between sentences.The edge feature mapping ?h(x,y) is usedto incorporate two types of relation, the relationbetween successive sentences and the relation be-tween context and answer sentences.
It can be de-fined as follows,?h(x,y) =[?hn(x,y)?hc(x,y)],where ?hn(x,y) and ?hc(x,y) denote the twotypes of feature mappings corresponding to se-quential edges and skip-chain edges, respectively.Their formal definitions are given as follows,?hn(x,y) =m?i=1n?1?j=1?hn(xj, xj+1, yij, yi,j+1),517Descriptions Dimensions?qi(xj) (32 dimensions) in ?n(x,y)The cosine, WordNet and KL-divergence similarities with the question xqi3The cosine, WordNet and KL-divergence similarities with the questions other than xqi3The cosine, WordNet and KL-divergence similarities with previous and next sentences 6Is this sentence xjexactly xqior one of the questions in {xq1, .
.
.
, xqm}?
2Is this sentence xjin the three beginning sentences?
3The relative position of this sentence xjto questions 4Is this sentence xjshare the same author with the question sentence xqi?
1Is this sentence xjin the same post with question sentences?
2Is this sentence xjin the same paragraph with question sentences?
2The presence of greeting (e.g., ?hi?)
and acknowledgement words in this sentence xj2The length of this sentence xj1The number of nouns, verbs and pronouns in this sentence xj, respectively 3?h(x,y) (704 dimensions)For ?hn(x,y), the above 32 dimension features w.r.t.
4?
4 = 16 transition patterns 512For ?hc(x,y), 12 types of pairwise or merged similarities w.r.t.
16 transition patterns 192?v(x,y) (32 dimensions)The transition patterns for any two non-contiguous labels in a label group 16The transition patterns for any two contiguous labels in a label group 16Table 1: Feature descriptions and demisions?hc(x,y) =m?i=1?j?C?k?A?
??
?Complete Edges?hc(xj, xk, yij, yik),?hn(xj, xj+1, yij, yi,j+1)= ?
(yij, yi,j+1)?
?hn(xj, xj+1, yij, yi,j+1),?hc(xj, xk, yij, yik)= ?
(yij, yik)?
?hc(xj, xk, yij, yik)where ?
(yij, yik) is a 16-dimensional vector.
It in-dicates all 4?4 pairwise transition patterns of fourtypes of labels, the context, answer, question andplain.
Note that apart from previous work (Dinget al, 2008) we use complete skip-chain (context-answer) edges in ?hc(x,y).The label group feature mapping ?v(x,y) isdefined as follows,?v(x,y) =n?j=1?v(xj,y.j),where ?v(xj,y.j) encodes each label group pat-tern into a vector.The detail descriptions and vector dimensionsof the used features are listed in Table 1.4 Structural SVMs and InferenceGiven a training set S = {(x(i),y(i)) ?
X ?Y : i = 1, .
.
.
, N}, we use the structuralSVMs (Taskar et al, 2003; Tsochantaridis etal., 2005; Joachims et al, 2009) formulation, asshown in Optimization Problem 1 (OP1), to learna weight vector w.OP 1 (1-Slack Structural SVM)minw,??012||w||2+CN?s.t.
?(y?
(1), .
.
.
, y?
(N)) ?
Yn,1NwTN?i=1[?(x(i),y(i))??
(x(i), y?(i))]?1NN?i=1?
(y(i), y?(i))?
?,where ?
is a slack variable, ?
(x,y) is the jointfeature mapping and ?
(y, y?)
is the loss func-tion that measures the loss caused by the dif-ference between y and y?.
Though OP1 is al-ready a quadratic optimization problem, directlyusing off-the-shelf quadratic optimization solverwill fail, due to the large number of constraints.Instead, a cutting plane algorithm is used to ef-ficiently solve this problem.
For the details of the518{C , P } {C , P } {C , P } {Q } {P } {A, P } {A, P }(a) Original graph{P P P , P P C , P C P , P C C , C P P , C P C , C C P , C C C }{Q } {P } {A, P } {A, P }(b) Transformed graph{P P P }{Q } {P } {A, P } {A, P }{C C C }{Q } {P } {A, P } {A, P }....(c) Decomposed graphFigure 3: The equivalent transform of graphsAlgorithm 1 Exact Inference Algorithm1: Input: (Ci,Ai) for each qi, w, x, y2: for i ?
{1, .
.
.
,m} do3: for Cs?
Cido4: [R(Cs), y?i.
(Cs)] ?
Viterbi(w,x; Cs)5: end for6: C?s= argmaxCs?CiR(Cs)7: y?
?i.= y?i.
(C?s)8: end for9: return y?
?structural SVMs, please refer to (Tsochantaridis etal., 2005; Joachims et al, 2009).The most essential and time-consuming step instructural SVMs is finding the most violated con-straint, which is equivalent to solveargmaxy?YwT?
(x(i),y) + ?(y(i),y).
(2)Without the ability to efficiently find the most vio-lated constraint, the cutting plane algorithm is nottractable.In the next sub-sections, we introduce the al-gorithms for finding the most violated constraint,also called loss-augmented inference.
The algo-rithms are essential for the success of customizingstructural SVMs to our problem.4.1 Exact InferenceThe exact inference algorithm is designed for asimplified model with two sub-mappings ?nand?h, except ?v.One naive approach to finding the most violatedconstraint for the simplified model is to enumer-ate all the 2|C|+|A|cases for each row of the labelmatrix.
However, it would be intractable for largecandidate sets.An important property is that the context can-didate set is usually much smaller than the wholenumber of sentences in a thread.
This property en-ables us to design efficient and exact inference al-gorithm by transforming from the original graphrepresentation in Figure 2 to the graphs in Fig-ure 3.
This graph transform merges all the nodesin the context candidate set C to one node with 2|C|possible labels.We design an exact inference algorithm in Algo-rithm 1 based on the graph in Figure 3(c).
The al-gorithm can be summarized in three steps: (1) enu-merate all the 2|C|possible labels1for the mergednode (line 3).
(2) For each given label of themerged node, perform the Viterbi algorithm (Ra-biner, 1989) on the decomposed graph (line 4) andstore the Viterbi algorithm outputs in R and y?i..(3) From the 2|C|Viterbi algorithm outputs, selectthe one with highest score as the output (lines 6and 7).The use of the Viterbi algorithm is assured bythe fact that there exists certain equivalence be-tween the decomposed graph (Figure 3(c)) and alinear chain.
By fixing the the label of the mergednode, we could remove the dashed edges in thedecomposed graph and regard the rest graph as alinear chain, which results in the Viterbi decoding.4.2 Approximate InferenceThe exact inference cannot handle the completemodel with three sub-mappings, ?n, ?h, and?v, since the label group defeats the graph trans-form in Figure 3.
Thus, we design two ap-proximate algorithms by employing undergener-ating and overgenerating approaches (Finley andJoachims, 2008).First, we develop an undergenerating localgreedy search algorithm shown in Algorithm 2.
Inthe algorithm, there are two loops, inner and outerloops.
The outer loop terminates when no labelschange (steps 3-11).
The inner loop enumeratesthe whole label matrix and greedily determineseach label (step 7) by maximizing the Equation(2).
Since the whole algorithm terminates only if1Since the merged node is from context candidate set C,enumerating its label is equivalent to enumerating subsets Csof the candidate set C519Algorithm 2 Greedy Inference Algorithm1: Input: w, x, y2: initialize solution: y?
?
y03: repeat4: y??
y?5: for i ?
{1, .
.
.
,m} do6: for j ?
{1, .
.
.
, n} do7:y??ij?
argmaxy?ijwT?
(x, y?
)+4(y, y?
)8: y?ij?
y?
?ij9: end for10: end for11: until y?
= y?12: y???
y?13: return y?
?the label matrix does not change during the lastouter loop.
This indicates that at least a local opti-mal solution is obtained.Second, an overgenerating method can bedesigned by using linear programming relax-ation (Finley and Joachims, 2008).
To save thespace, we skip the details of this algorithm here.5 Loss FunctionsStructural SVMs allow users to customize the lossfunction 4 : Y ?
Y ?
R according to differentsystem requirements.
In this section, we introducethe loss functions used in our work.Basic loss function.
The simplest way to quan-tify the prediction quality is counting the numberof wrongly predicted labels.
Formally,4b(y, y?)
=m?i=1n?j=1I[yij6= y?ij], (3)where I[.]
is an indicative function that equals toone if the condition holds and zero otherwise.Recall-vs-precision loss function.
In practice,we may place different emphasis on recall and pre-cision according to application settings.
We couldinclude this preference into the model by definingthe following loss function,4p(y,?y) =m?i=1n?j=1I[yij6= P, y?ij= P ] ?
cr+I[yij= P, y?ij6= P ] ?
cp.
(4)This function penalizes the wrong prediction de-creasing recall and that decreasing precision withItems in the data set #itemsThread 515Post 2, 035Sentence 8, 500question annotation 1, 407context annotation 1, 962answer annotation 4, 652plain annotation 18, 198Table 2: The data statisticstwo weights crand cprespectively.
Specifically,we denote the loss function with cp/cr= 2 andthat with cr/cp= 2 by 4ppand 4rp, respectively.Various types of loss function can be defined ina similar fashion.
To save the space, we skip thedefinitions of other loss functions and only use theabove two types of loss functions to show the flex-ibility of our approach.6 Experiments6.1 Experimental SetupCorpus.
We made use of the same data set asintroduced in (Cong et al, 2008; Ding et al,2008).
Specifically, the data set includes about591 threads from the forum TripAdvisor2.
Eachsentence in the threads is tagged with the labels?question?, ?context?, ?answer?, or ?plain?
by twoannotators.
We removed 76 threads that have noquestion sentences or more than 40 sentences and6 questions.
The remaining 515 forum threadsform our data set.Table 2 gives the statistics on the data set.
Onaverage, each thread contains 3.95 posts and 2.73questions, and each question has 1.39 context sen-tences and 3.31 answer sentences.
Note that thenumber of annotations is much larger than thenumber of sentences because one sentence can beannotated with multiple labels.Experimental Details.
In all the experiments,we made use of linear models for the sake of com-putational efficiency.
As a preprocessing step, wenormalized the value of each feature value intothe interval [0, 1] and then followed the heuristicused in SVM-light (Joachims, 1998) to set C to1/||x||2, where ||x|| is the average length of inputsamples (in our case, sentences).
The tolerance pa-rameter ?
was set to 0.1 (the value also used in (Cai2TripAdvisor (http://www.tripadvisor.com/ForumHome) is one of the most popular travel forums520and Hofmann, 2004)) in all the runs of the experi-ments.Evaluation.
We calculated the standard preci-sion (P), recall (R) and F1-score (F1) for both tasks(context extraction and answer extraction).
All theexperimental results were obtained through 5-foldcross validation.6.2 Baseline MethodsWe employed binary SVMs (B-SVM), multiclassSVMs (M-SVM), and C4.5 (Quinlan, 1993) as ourbaseline methods:B-SVM.
We trained two binary SVMs for con-text extraction (context vs. non-context) and an-swer extraction (answer vs. non-answer), respec-tively.
We used the feature mapping ?qi(xj) de-fined in Equation (1) while training the binarySVM models.M-SVM.
We extended the binary SVMs bytraining multiclass SVMs for three category labels(context, answer, plain).C4.5.
This decision tree algorithm solved thesame classification problem as binary SVMs andmade use of the same set of features.6.3 Modeling Sentence Relations andQuestion InteractionsWe demonstrate in Table 3 that our approach canmake use of the three types of relation among sen-tences well to boost the performance.In Table 3, S-SVM represents the structuralSVMs only using the node features ?n(x,y).
Thesuffixes H, C, and V denote the models usinghorizontal sequential edges, complete skip-chainedges and vertical label groups, respectively.
Thesuffixes C* and V* denote the models using in-complete skip-chain edges and vertical sequentialedges proposed in (Ding et al, 2008), as shownin Figures 2(a) and 2(c).
All the structural SVMswere trained using basic loss function ?bin Equa-tion (3).
From Table 3, we can observe the follow-ing advantages of our approaches.Overall improvement.
Our structural approachsteadily improves the extraction as more types ofrelation (corresponding to more types of edge) areincluded.
The best results obtained by using thethree types of relation together improve the base-line methods binary SVMs by about 6% and 20%in terms of F1values for context extraction andanswer extraction, respectively.The usefulness of relations.
The relationsencoded by horizontal sequential edges and la-Method 4bP (%) R (%) F1(%)Context ExtractionC4.5 ?
74.2 68.7 71.2B-SVM ?
78.3 72.2 74.9M-SVM ?
68.0 77.6 72.1S-SVM 8.86 75.6 71.7 73.4S-SVM-H 8.60 77.5 75.5 76.3S-SVM-HC* 8.65 77.9 74.1 75.8S-SVM-HC 8.62 77.5 75.2 76.2S-SVM-HCV* 8.08 79.5 79.6 79.5S-SVM-HCV 7.98 79.7 80.2 79.9Answer ExtractionC4.5 ?
61.3 45.2 51.8B-SVM ?
69.7 42.0 51.8M-SVM ?
63.2 51.5 55.8S-SVM 8.86 67.0 48.0 55.6S-SVM-H 8.60 66.9 49.7 56.7S-SVM-HC* 8.65 66.5 49.4 56.4S-SVM-HC 8.62 65.7 51.5 57.4S-SVM-HCV* 8.08 65.5 58.7 61.7S-SVM-HCV 7.98 65.1 61.2 63.0Table 3: The effectiveness of our approachbel groups are useful for both context extractionand answer extraction.
The relation encoded bycomplete skip-chain edges is useful for answerextraction.
The complete skip-chain edges notonly avoid preprocessing but also boost the per-formance when compared with the preprocessedskip-chain edges.
The label groups improve thevertical sequential edges.Interactions among questions.
The interac-tions encoded by label groups are especially use-ful.
We conducted significance tests (sign test) onthe experimental results.
The test result shows thatS-SVM-HCV outperforms all the other methodswithout vertical edges statistically significantly (p-value < 0.01).
Our proposed graphical represen-tation in Figure 2(d) eases us to model the complexinteractions.
In comparison, the 2D model in Fig-ure 2(c) used in previous work (Ding et al, 2008)can only model the interaction between adjacentquestions.6.4 Loss Function ResultsWe report in Table 4 the comparison betweenstructural SVMs using different loss functions.Note that ?ppprefers precision and ?rpprefers re-call.
From Table 4, we can observe that the ex-perimental results also exhibit this kind of system521Method P (%) R (%) F1(%)Context ExtractionS-SVM-HCV-4b79.7 80.2 79.9S-SVM-HCV-4pp82.0 70.3 75.6S-SVM-HCV-4rp75.7 84.2 79.7Answer ExtractionS-SVM-HCV-4b65.1 61.2 63.0S-SVM-HCV-4pp71.8 52.2 60.2S-SVM-HCV-4rp61.8 66.1 63.7Table 4: The use of different loss functionspreference.
Moreover, we further demonstrate thecapability of the loss function ?pin Figure 4.
Thecurves are achieved by varying the ratio betweentwo parameters cp/crin Equation (4).
The curvesconfirm our intuition: when log(cp/cr) becomeslarger, the precisions increase but the recalls de-crease and vice versa.7 Related workPrevious work on extracting questions, answersand contexts is most related with our work.
Conget al (2008) proposed a supervised approach forquestion detection and an unsupervised approachfor answer detection without considering contexts.Ding et al (2008) used CRFs to detect contextsand answers of questions from forum threads.Some researches on summarizing discussionthreads and emails are related to our work, too.Zhou and Hovy (2005) segmented internet re-lay chat, clustered segments into sub-topics, andidentified responding segments of the first seg-ment in each sub-topic by assuming the first seg-ment to be focus.
In (Nenkova and Bagga, 2003;Wan and McKeown, 2004; Rambow et al, 2004),email summaries were organized by extractingoverview sentences as discussion issues.
Thework (Shrestha and McKeown, 2004) used RIP-PER as a classifier to detect interrogative questionsand their answers then used the resulting questionand answer pairs as summaries.
We also note theexisting work on extracting knowledge from dis-cussion threads.
Huang et al (2007) used SVMsto extract input-reply pairs from forums for chat-bot knowledge.
Feng et al (2006) implementeda discussion-bot which used cosine similarity tomatch students?
query with reply posts from an an-notated corpus of archived threaded discussions.Moreover, extensive researches have been donewithin the area of question answering (Burger et?1.5 ?1 ?0.5 0 0.5 1 1.50.60.70.80.91Log loss ratioPrecisionContextAnswer?1.5 ?1 ?0.5 0 0.5 1 1.50.40.60.81Log loss ratioRecallContextAnswerFigure 4: Balancing between precision and recallal., 2006; Jeon et al, 2005; Harabagiu and Hickl,2006; Cui et al, 2005; Dang et al, 2006).
Theymainly focused on using sophisticated linguisticanalysis to construct answer from a large docu-ment collection.8 Conclusion and Future WorkWe have proposed a new form of graphical rep-resentation for modeling the problem of extract-ing contexts and answers of questions from onlineforums and then customized structural SVM ap-proach to solve it.The proposed graphical representation is ableto naturally express three types of relation amongsentences: relation between successive sentences,relation between context sentences and answersentences, and relation between multiple labels forone sentence.
The representation also enables usto address interactions among questions.
We alsodeveloped the inference algorithms for the struc-tural SVM model by exploiting the special struc-ture of thread discussions.Experimental results on a real data set show thatour approach significantly improves the baselinemethods by effectively utilizing various types ofrelation among sentences.Our future work includes: (a) to summa-rize threads and represent the forum threads inquestion-context-answer triple, which will changethe organization of online forums; and (b) to en-hance QA services (e.g., Yahoo!
Answers) by thecontents extracted from online forums.AcknowledgementThe authors would like to thank the anonymous re-viewers for their comments to improve this paper.522ReferencesJohn Burger, Claire Cardie, Vinay Chaudhri, RobertGaizauskas, Sanda Harabagiu, David Israel, Chris-tian Jacquemin, Chin-Yew Lin, Steve Maiorano,George Miller, Dan Moldovan, Bill Ogden, JohnPrager, Ellen Riloff, Amit Singhal, Rohini Shrihari,Tomek Strzalkowski, Ellen Voorhees, and RalphWeishedel.
2006.
Issues, tasks and program struc-tures to roadmap research in question and answering(qna).
ARAD: Advanced Research and DevelopmentActivity (US).Lijuan Cai and Thomas Hofmann.
2004.
Hierarchi-cal document categorization with support vector ma-chines.
In Proceedings of CIKM, pages 78?87.Gao Cong, Long Wang, Chin-Yew Lin, and Young-InSong.
2008.
Finding question-answer pairs fromonline forums.
In Proceedings of SIGIR, pages 467?474.Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and Tat-Seng Chua.
2005.
Question answering passage re-trieval using dependency relations.
In Proceedingsof SIGIR, pages 400?407.Hoa Dang, Jimmy Lin, and Diane Kelly.
2006.Overview of the trec 2006 question answering track.In Proceedings of TREC, pages 99?116.Shilin Ding, Gao Cong, Chin-Yew Lin, and XiaoyanZhu.
2008.
Using conditional random field to ex-tract contexts and answers of questions from onlineforums.
In Proceedings of ACL, pages 710?718.Donghui Feng, Erin Shaw, Jihie Kim, and Eduard H.Hovy.
2006.
An intelligent discussion-bot for an-swering student queries in threaded discussions.
InProceedings of IUI, pages 171?177.Thomas Finley and Thorsten Joachims.
2008.
Trainingstructural SVMs when exact inference is intractable.In Proceedings of ICML, pages 304?311.Michel Galley.
2006.
A skip-chain conditional randomfield for ranking meeting utterances by importance.In Proceedings of the 2006 Conference on Empiri-cal Methods in Natural Language Processing, pages364?372.Sanda M. Harabagiu and Andrew Hickl.
2006.
Meth-ods for using textual entailment in open-domainquestion answering.
In Proceedings of ACL, pages905?912.Jizhou Huang, Ming Zhou, and Dan Yang.
2007.
Ex-tracting chatbot knowledge from online discussionforums.
In Proceedings of IJCAI, pages 423?428.Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee.
2005.Finding similar questions in large question and an-swer archives.
In Proceedings of CIKM, pages 84?90.Thorsten Joachims, Thomas Finley, and Chun-Nam Yu.2009.
Cutting-plane training of structural SVMs.Machine Learning.Thorsten Joachims.
1998.
Text categorization withsupport vector machines: Learning with many rele-vant features.
In Proceedings of ECML, pages 137?142.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of ICML, pages 282?289.Ani Nenkova and Amit Bagga.
2003.
Facilitatingemail thread access by extractive summary genera-tion.
In Proceedings of RANLP, pages 287?296.Nam Nguyen and Yunsong Guo.
2007.
Comparisonsof sequence labeling algorithms and extensions.
InProceedings of ICML, pages 681?688.John Quinlan.
1993.
C4.5: programs for machinelearning.
Morgan Kaufmann Publisher Incorpora-tion.Lawrence Rabiner.
1989.
A tutorial on hidden markovmodels and selected applications in speech recogni-tion.
In Proceedings of IEEE, pages 257?286.Owen Rambow, Lokesh Shrestha, John Chen, andChirsty Lauridsen.
2004.
Summarizing emailthreads.
In Proceedings of HLT-NAACL, pages 105?108.Lokesh Shrestha and Kathleen McKeown.
2004.
De-tection of question-answer pairs in email conversa-tions.
In Proceedings of COLING, pages 889?895.Charles Sutton and Andrew McCallum.
2004.
Collec-tive segmentation and labeling of distant entities ininformation extraction.
Technical Report 04-49.Benjamin Taskar, Carlos Guestrin, and Daphne Koller.2003.
Max-margin markov networks.
In Advancesin Neural Information Processing Systems 16.
MITPress.Ioannis Tsochantaridis, Thorsten Joachims, ThomasHofmann, and Yasemin Altun.
2005.
Large marginmethods for structured and interdependent outputvariables.
Journal of Machine Learning Research,6:1453?1484.Stephen Wan and Kathy McKeown.
2004.
Generatingoverview summaries of ongoing email thread discus-sions.
In Proceedings of COLING, pages 549?555.Liang Zhou and Eduard Hovy.
2005.
Digesting vir-tual ?geek?
culture: The summarization of technicalinternet relay chats.
In Proceedings of ACL, pages298?305.Jun Zhu, Zaiqing Nie, Ji-Rong Wen, Bo Zhang, andWei-Ying Ma.
2005.
2d conditional random fieldsfor web information extraction.
In Proceedings ofICML, pages 1044?1051.523
