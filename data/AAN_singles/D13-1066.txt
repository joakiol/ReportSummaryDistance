Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 704?714,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsSarcasm as Contrast between a Positive Sentiment and Negative SituationEllen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva,Nathan Gilbert, Ruihong HuangSchool Of ComputingUniversity of UtahSalt Lake City, UT 84112{riloff,asheq,alnds,ngilbert,huangrh}@cs.utah.edu, prafulla.surve@gmail.comAbstractA common form of sarcasm on Twitter con-sists of a positive sentiment contrasted with anegative situation.
For example, many sarcas-tic tweets include a positive sentiment, such as?love?
or ?enjoy?, followed by an expressionthat describes an undesirable activity or state(e.g., ?taking exams?
or ?being ignored?).
Wehave developed a sarcasm recognizer to iden-tify this type of sarcasm in tweets.
We presenta novel bootstrapping algorithm that automati-cally learns lists of positive sentiment phrasesand negative situation phrases from sarcastictweets.
We show that identifying contrast-ing contexts using the phrases learned throughbootstrapping yields improved recall for sar-casm recognition.1 IntroductionSarcasm is generally characterized as ironic or satir-ical wit that is intended to insult, mock, or amuse.Sarcasm can be manifested in many different ways,but recognizing sarcasm is important for natural lan-guage processing to avoid misinterpreting sarcasticstatements as literal.
For example, sentiment anal-ysis can be easily misled by the presence of wordsthat have a strong polarity but are used sarcastically,which means that the opposite polarity was intended.Consider the following tweet on Twitter, which in-cludes the words ?yay?
and ?thrilled?
but actuallyexpresses a negative sentiment: ?yay!
it?s a holi-day weekend and i?m on call for work!
couldn?t bemore thrilled!
#sarcasm.?
In this case, the hashtag#sarcasm reveals the intended sarcasm, but we don?talways have the benefit of an explicit sarcasm label.In the realm of Twitter, we observed that manysarcastic tweets have a common structure thatcreates a positive/negative contrast between a senti-ment and a situation.
Specifically, sarcastic tweetsoften express a positive sentiment in reference to anegative activity or state.
For example, consider thetweets below, where the positive sentiment termsare underlined and the negative activity/state termsare italicized.
(a) Oh how I love being ignored.
#sarcasm(b) Thoroughly enjoyed shoveling the drivewaytoday!
:) #sarcasm(c) Absolutely adore it when my bus is late#sarcasm(d) I?m so pleased mom woke me up withvacuuming my room this morning.
:) #sarcasmThe sarcasm in these tweets arises from the jux-taposition of a positive sentiment word (e.g., love,enjoyed, adore, pleased) with a negative activity orstate (e.g., being ignored, bus is late, shoveling, andbeing woken up).The goal of our research is to identify sarcasmthat arises from the contrast between a positive sen-timent referring to a negative situation.
A key chal-lenge is to automatically recognize the stereotypi-cally negative ?situations?, which are activities andstates that most people consider to be unenjoyable orundesirable.
For example, stereotypically unenjoy-able activities include going to the dentist, taking anexam, and having to work on holidays.
Stereotypi-cally undesirable states include being ignored, hav-ing no friends, and feeling sick.
People recognize704these situations as being negative through culturalnorms and stereotypes, so they are rarely accompa-nied by an explicit negative sentiment.
For example,?I feel sick?
is universally understood to be a nega-tive situation, even without an explicit expression ofnegative sentiment.
Consequently, we must learn torecognize phrases that correspond to stereotypicallynegative situations.We present a bootstrapping algorithm that auto-matically learns phrases corresponding to positivesentiments and phrases corresponding to negativesituations.
We use tweets that contain a sarcasmhashtag as positive instances for the learning pro-cess.
The bootstrapping algorithm begins with a sin-gle seed word, ?love?, and a large set of sarcastictweets.
First, we learn negative situation phrasesthat follow a positive sentiment (initially, the seedword ?love?).
Second, we learn positive sentimentphrases that occur near a negative situation phrase.The bootstrapping process iterates, alternately learn-ing new negative situations and new positive sen-timent phrases.
Finally, we use the learned listsof sentiment and situation phrases to recognize sar-casm in new tweets by identifying contexts that con-tain a positive sentiment in close proximity to a neg-ative situation phrase.2 Related WorkResearchers have investigated the use of lexicaland syntactic features to recognize sarcasm in text.Kreuz and Caucci (2007) studied the role that dif-ferent lexical factors play, such as interjections (e.g.,?gee?
or ?gosh?)
and punctuation symbols (e.g., ???
)in recognizing sarcasm in narratives.
Lukin andWalker (2013) explored the potential of a bootstrap-ping method for sarcasm classification in social di-alogue to learn lexical N-gram cues associated withsarcasm (e.g., ?oh really?, ?I get it?, ?no way?, etc.
)as well as lexico-syntactic patterns.In opinionated user posts, Carvalho et al(2009)found oral or gestural expressions, represented us-ing punctuation and other keyboard characters, tobe more predictive of irony1 in contrast to featuresrepresenting structured linguistic knowledge in Por-1They adopted the term ?irony?
instead of ?sarcasm?
to re-fer to the case when a word or expression with prior positivepolarity is figuratively used to express a negative opinion.tuguese.
Filatova (2012) presented a detailed de-scription of sarcasm corpus creation with sarcasmannotations of Amazon product reviews.
Their an-notations capture sarcasm both at the document leveland the text utterance level.
Tsur et al(2010) pre-sented a semi-supervised learning framework thatexploits syntactic and pattern based features in sar-castic sentences of Amazon product reviews.
Theyobserved correlated sentiment words such as ?yay!
?or ?great!?
often occurring in their most useful pat-terns.Davidov et al(2010) used sarcastic tweets andsarcastic Amazon product reviews to train a sarcasmclassifier with syntactic and pattern-based features.They examined whether tweets with a sarcasm hash-tag are reliable enough indicators of sarcasm to beused as a gold standard for evaluation, but found thatsarcasm hashtags are noisy and possibly biased to-wards the hardest form of sarcasm (where even hu-mans have difficulty).
Gonza?lez-Iba?n?ez et al(2011)explored the usefulness of lexical and pragmatic fea-tures for sarcasm detection in tweets.
They used sar-casm hashtags as gold labels.
They found positiveand negative emotions in tweets, determined throughfixed word dictionaries, to have a strong correlationwith sarcasm.
Liebrecht et al(2013) explored N-gram features from 1 to 3-grams to build a classifierto recognize sarcasm in Dutch tweets.
They made aninteresting observation from their most effective N-gram features that people tend to be more sarcastictowards specific topics such as school, homework,weather, returning from vacation, public transport,the church, the dentist, etc.
This observation hassome overlap with our observation that stereotypi-cally negative situations often occur in sarcasm.The cues for recognizing sarcasm may come froma variety of sources.
There exists a line of workthat tries to identify facial and vocal cues in speech(e.g., (Gina M. Caucci, 2012; Rankin et al 2009)).Cheang and Pell (2009) and Cheang and Pell (2008)performed studies to identify acoustic cues in sarcas-tic utterances by analyzing speech features such asspeech rate, mean amplitude, amplitude range, etc.Tepperman et al(2006) worked on sarcasm recog-nition in spoken dialogue using prosodic and spec-tral cues (e.g., average pitch, pitch slope, etc.)
aswell as contextual cues (e.g., laughter or response toquestions) as features.705While some of the previous work has identi-fied specific expressions that correlate with sarcasm,none has tried to identify contrast between positivesentiments and negative situations.
The novel con-tributions of our work include explicitly recogniz-ing contexts that contrast a positive sentiment with anegative activity or state, as well as a bootstrappedlearning framework to automatically acquire posi-tive sentiment and negative situation phrases.3 Bootstrapped Learning of PositiveSentiments and Negative SituationsSarcasm is often defined in terms of contrast or ?say-ing the opposite of what you mean?.
Our work fo-cuses on one specific type of contrast that is commonon Twitter: the expression of a positive sentiment(e.g., ?love?
or ?enjoy?)
in reference to a negativeactivity or state (e.g., ?taking an exam?
or ?being ig-nored?).
Our goal is to create a sarcasm classifier fortweets that explicitly recognizes contexts that con-tain a positive sentiment contrasted with a negativesituation.Our approach learns rich phrasal lexicons of pos-itive sentiments and negative situations using onlythe seed word ?love?
and a collection of sarcastictweets as input.
A key factor that makes the algo-rithm work is the presumption that if you find a pos-itive sentiment or a negative situation in a sarcastictweet, then you have found the source of the sar-casm.
We further assume that the sarcasm probablyarises from positive/negative contrast and we exploitsyntactic structure to extract phrases that are likelyto have contrasting polarity.
Another key factor isthat we focus specifically on tweets.
The short na-ture of tweets limits the search space for the sourceof the sarcasm.
The brevity of tweets also probablycontributes to the prevalence of this relatively com-pact form of sarcasm.3.1 Overview of the Learning ProcessOur bootstrapping algorithm operates on the as-sumption that many sarcastic tweets contain both apositive sentiment and a negative situation in closeproximity, which is the source of the sarcasm.2 Al-though sentiments and situations can be expressed2Sarcasm can arise from a negative sentiment contrastedwith a positive situation too, but our observation is that this ismuch less common, at least on Twitter.PositiveSentimentPhrasesNegativeSituationPhrasesSeed Word"love"Sarcastic Tweets1 234Figure 1: Bootstrapped Learning of Positive Sentimentand Negative Situation Phrasesin numerous ways, we focus on positive sentimentsthat are expressed as a verb phrase or as a predicativeexpression (predicate adjective or predicate nomi-nal), and negative activities or states that can be acomplement to a verb phrase.
Ideally, we wouldlike to parse the text and extract verb complementphrase structures, but tweets are often informallywritten and ungrammatical.
Therefore we try to rec-ognize these syntactic structures heuristically usingonly part-of-speech tags and proximity.The learning process relies on an assumption thata positive sentiment verb phrase usually appears tothe left of a negative situation phrase and in closeproximity (usually, but not always, adjacent).
Picto-rially, we assume that many sarcastic tweets containthis structure:[+ VERB PHRASE] [?
SITUATION PHRASE]This structural assumption drives our bootstrap-ping algorithm, which is illustrated in Figure 1.The bootstrapping process begins with a single seedword, ?love?, which seems to be the most commonpositive sentiment term in sarcastic tweets.
Givena sarcastic tweet containing the word ?love?, ourstructural assumption infers that ?love?
is probablyfollowed by an expression that refers to a negativesituation.
So we harvest the n-grams that follow theword ?love?
as negative situation candidates.
We se-lect the best candidates using a scoring metric, andadd them to a list of negative situation phrases.Next, we exploit the structural assumption in theopposite direction.
Given a sarcastic tweet that con-tains a negative situation phrase, we infer that thenegative situation phrase is preceded by a positivesentiment.
We harvest the n-grams that precede thenegative situation phrases as positive sentiment can-didates, score and select the best candidates, and706add them to a list of positive sentiment phrases.The bootstrapping process then iterates, alternatelylearning more positive sentiment phrases and morenegative situation phrases.We also observed that positive sentiments are fre-quently expressed as predicative phrases (i.e., pred-icate adjectives and predicate nominals).
For ex-ample: ?I?m taking calculus.
It is awesome.
#sar-casm?.
Wiegand et al(2013) offered a related ob-servation that adjectives occurring in predicate ad-jective constructions are more likely to convey sub-jectivity than adjectives occurring in non-predicativestructures.
Therefore we also include a step inthe learning process to harvest predicative phrasesthat occur in close proximity to a negative situationphrase.
In the following sections, we explain eachstep of the bootstrapping process in more detail.3.2 Bootstrapping DataFor the learning process, we used Twitter?s stream-ing API to obtain a large set of tweets.
We col-lected 35,000 tweets that contain the hashtag #sar-casm or #sarcastic to use as positive instances of sar-casm.
We also collected 140,000 additional tweetsfrom Twitter?s random daily stream.
We removedthe tweets that contain a sarcasm hashtag, and con-sidered the rest to be negative instances of sarcasm.Of course, there will be some sarcastic tweets that donot have a sarcasm hashtag, so the negative instanceswill contain some noise.
But we expect that a verysmall percentage of these tweets will be sarcastic, sothe noise should not be a major issue.
There will alsobe noise in the positive instances because a sarcasmhashtag does not guarantee that there is sarcasm inthe body of the tweet (e.g., the sarcastic content maybe in a linked url, or in a prior tweet).
But again, weexpect the amount of noise to be relatively small.Our tweet collection therefore contains a total of175,000 tweets: 20% are labeled as sarcastic and80% are labeled as not sarcastic.
We applied CMU?spart-of-speech tagger designed for tweets (Owoputiet al 2013) to this data set.3.3 SeedingThe bootstrapping process begins by initializing thepositive sentiment lexicon with one seed word: love.We chose this seed because it seems to be the mostcommon positive sentiment word in sarcastic tweets.3.4 Learning Negative Situation PhrasesThe first stage of bootstrapping learns new phrasesthat correspond to negative situations.
The learningprocess consists of two steps: (1) harvesting candi-date phrases, and (2) scoring and selecting the bestcandidates.To collect candidate phrases for negative situa-tions, we extract n-grams that follow a positive senti-ment phrase in a sarcastic tweet.
We extract every 1-gram, 2-gram, and 3-gram that occurs immediatelyafter (on the right-hand side) of a positive sentimentphrase.
As an example, consider the tweet in Figure2, where ?love?
is the positive sentiment:I love waiting forever for the doctor #sarcasmFigure 2: Example Sarcastic TweetWe extract three n-grams as candidate negative situ-ation phrases:waiting, waiting forever, waiting forever forNext, we apply the part-of-speech (POS) taggerand filter the candidate list based on POS patterns sowe only keep n-grams that have a desired syntacticstructure.
For negative situation phrases, our goalis to learn possible verb phrase (VP) complementsthat are themselves verb phrases because they shouldrepresent activities and states.
So we require a can-didate phrase to be either a unigram tagged as a verb(V) or the phrase must match one of 7 POS-basedbigram patterns or 20 POS-based trigram patternsthat we created to try to approximate the recogni-tion of verbal complement structures.
The 7 POS bi-gram patterns are: V+V, V+ADV, ADV+V, ?to?+V,V+NOUN, V+PRO, V+ADJ.
Note that we useda POS tagger designed for Twitter, which has asmaller set of POS tags than more traditional POStaggers.
For example there is just a single V tagthat covers all types of verbs.
The V+V pattern willtherefore capture negative situation phrases that con-sist of a present participle verb followed by a pastparticiple verb, such as ?being ignored?
or ?gettinghit?.3 We also allow verb particles to match a V tagin our patterns.
The remaining bigram patterns cap-ture verb phrases that include a verb and adverb, an3In some cases it may be more appropriate to consider thesecond verb to be an adjective, but in practice they were usuallytagged as verbs.707infinitive form (e.g., ?to clean?
), a verb and nounphrase (e.g., ?shoveling snow?
), or a verb and ad-jective (e.g., ?being alone?).
We use some simpleheuristics to try to ensure that we are at the end of anadjective or noun phrase (e.g., if the following wordis tagged as an adjective or noun, then we assumewe are not at the end).The 20 POS trigram patterns are similar in natureand are designed to capture seven general types ofverb phrases: verb and adverb mixtures, an infini-tive VP that includes an adverb, a verb phrase fol-lowed by a noun phrase, a verb phrase followed by aprepositional phrase, a verb followed by an adjectivephrase, or an infinitive VP followed by an adjective,noun, or pronoun.Returning to Figure 2, only two of the n-gramsmatch our POS patterns, so we are left with two can-didate phrases for negative situations:waiting, waiting foreverNext, we score each negative situation candidateby estimating the probability that a tweet is sarcasticgiven that it contains the candidate phrase followinga positive sentiment phrase:| follows(?candidate, +sentiment) & sarcastic || follows(?candidate, +sentiment) |We compute the number of times that the negativesituation candidate immediately follows a positivesentiment in sarcastic tweets divided by the numberof times that the candidate immediately follows apositive sentiment in all tweets.
We discard phrasesthat have a frequency < 3 in the tweet collectionsince they are too sparse.Finally, we rank the candidate phrases based onthis probability, using their frequency as a secondarykey in case of ties.
The top 20 phrases with a prob-ability ?
.80 are added to the negative situationphrase list.4 When we add a phrase to the nega-tive situation list, we immediately remove all othercandidates that are subsumed by the selected phrase.For example, if we add the phrase ?waiting?, thenthe phrase ?waiting forever?
would be removed fromthe candidate list because it is subsumed by ?wait-ing?.
This process reduces redundancy in the set of4Fewer than 20 phrases will be learned if < 20 phrases passthis threshold.phrases that we add during each bootstrapping itera-tion.
The bootstrapping process stops when no morecandidate phrases pass the probability threshold.3.5 Learning Positive Verb PhrasesThe procedure for learning positive sentimentphrases is analogous.
First, we collect phrases thatpotentially convey a positive sentiment by extract-ing n-grams that precede a negative situation phrasein a sarcastic tweet.
To learn positive sentiment verbphrases, we extract every 1-gram and 2-gram thatoccurs immediately before (on the left-hand side of)a negative situation phrase.Next, we apply the POS tagger and filter the n-grams using POS tag patterns so that we only keepn-grams that have a desired syntactic structure.
Hereour goal is to learn simple verb phrases (VPs) so weonly retain n-grams that contain at least one verb andconsist only of verbs and (optionally) adverbs.
Fi-nally, we score each candidate sentiment verb phraseby estimating the probability that a tweet is sarcasticgiven that it contains the candidate phrase precedinga negative situation phrase:| precedes(+candidateVP,?situation) & sarcastic || precedes(+candidateVP,?situation) |3.6 Learning Positive Predicative PhrasesWe also use the negative situation phrases to harvestpredicative expressions (predicate adjective or pred-icate nominal structures) that occur nearby.
Basedon the same assumption that sarcasm often arisesfrom the contrast between a positive sentiment anda negative situation, we identify tweets that containa negative situation and a predicative expression inclose proximity.
We then assume that the predicativeexpression is likely to convey a positive sentiment.To learn predicative expressions, we use 24 copu-lar verbs from Wikipedia5 and their inflections.
Weextract positive sentiment candidates by extracting1-grams, 2-grams, and 3-grams that appear immedi-ately after a copular verb and occur within 5 wordsof the negative situation phrase, on either side.
Thisconstraint only enforces proximity because predica-tive expressions often appear in a separate clause orsentence (e.g., ?It is just great that my iphone wasstolen?
or ?My iphone was stolen.
This is great.?
)5http://en.wikipedia.org/wiki/List of English copulae708We then apply POS patterns to identify n-gramsthat correspond to predicate adjective and predicatenominal phrases.
For predicate adjectives, we re-tain ADJ and ADV+ADJ n-grams.
We use a fewheuristics to check that the adjective is not part of anoun phrase (e.g., we check that the following wordis not a noun).
For predicate nominals, we retainADV+ADJ+N, DET+ADJ+N and ADJ+N n-grams.We excluded noun phrases consisting only of nounsbecause they rarely seemed to represent a sentiment.The sentiment in predicate nominals was usuallyconveyed by the adjective.
We discard all candidateswith frequency < 3 as being too sparse.
Finally,we score each remaining candidate by estimating theprobability that a tweet is sarcastic given that it con-tains the predicative expression near (within 5 wordsof) a negative situation phrase:| near(+candidatePRED,?situation) & sarcastic || near(+candidatePRED,?situation) |We found that the diversity of positive senti-ment verb phrases and predicative expressions ismuch lower than the diversity of negative situationphrases.
As a result, we sort the candidates by theirprobability and conservatively add only the top 5positive verb phrases and top 5 positive predicativeexpressions in each bootstrapping iteration.
Bothtypes of sentiment phrases must pass a probabilitythreshold of ?
.70.3.7 The Learned Phrase ListsThe bootstrapping process alternately learns pos-itive sentiments and negative situations until nomore phrases can be learned.
In our experiments,we learned 26 positive sentiment verb phrases, 20predicative expressions and 239 negative situationphrases.Table 1 shows the first 15 positive verb phrases,the first 15 positive predicative expressions, and thefirst 40 negative situation phrases learned by thebootstrapping algorithm.
Some of the negative sit-uation phrases are not complete expressions, but itis clear that they will often match negative activitiesand states.
For example, ?getting yelled?
was gener-ated from sarcastic comments such as ?I love gettingyelled at?, ?being home?
occurred in tweets about?being home alone?, and ?being told?
is often be-ing told what to do.
Shorter phrases often outrankedlonger phrases because they are more general, andwill therefore match more contexts.
But an avenuefor future work is to learn linguistic expressions thatmore precisely characterize specific negative situa-tions.Positive Verb Phrases (26): missed, loves,enjoy, cant wait, excited, wanted, can?t wait,get, appreciate, decided, loving, really like,looooove, just keeps, loveee, ...Positive Predicative Expressions (20): great,so much fun, good, so happy, better, myfavorite thing, cool, funny, nice, always fun,fun, awesome, the best feeling, amazing,happy, ...Negative Situations (239): being ignored, be-ing sick, waiting, feeling, waking up early, be-ing woken, fighting, staying, writing, beinghome, cleaning, not getting, crying, sitting athome, being stuck, starting, being told, be-ing left, getting ignored, being treated, doinghomework, learning, getting up early, going tobed, getting sick, riding, being ditched, get-ting ditched, missing, not sleeping, not talking,trying, falling, walking home, getting yelled,being awake, being talked, taking care, doingnothing, wasting, ...Table 1: Examples of Learned Phrases4 Evaluation4.1 DataFor evaluation purposes, we created a gold stan-dard data set of manually annotated tweets.
Evenfor people, it is not always easy to identify sarcasmin tweets because sarcasm often depends on con-versational context that spans more than a singletweet.
Extracting conversational threads from Twit-ter, and analyzing conversational exchanges, has itsown challenges and is beyond the scope of this re-search.
We focus on identifying sarcasm that is self-contained in one tweet and does not depend on priorconversational context.We defined annotation guidelines that instructedhuman annotators to read isolated tweets and label709a tweet as sarcastic if it contains comments judgedto be sarcastic based solely on the content of thattweet.
Tweets that do not contain sarcasm, or wherepotential sarcasm is unclear without seeing the priorconversational context, were labeled as not sarcas-tic.
For example, a tweet such as ?Yes, I meant thatsarcastically.?
should be labeled as not sarcastic be-cause the sarcastic content was (presumably) in aprevious tweet.
The guidelines did not contain anyinstructions that required positive/negative contrastto be present in the tweet, so all forms of sarcasmwere considered to be positive examples.To ensure that our evaluation data had a healthymix of both sarcastic and non-sarcastic tweets, wecollected 1,600 tweets with a sarcasm hashtag (#sar-casm or #sarcastic), and 1,600 tweets without thesesarcasm hashtags from Twitter?s random streamingAPI.
When presenting the tweets to the annotators,the sarcasm hashtags were removed so the annota-tors had to judge whether a tweet was sarcastic ornot without seeing those hashtags.To ensure that we had high-quality annotations,three annotators were asked to annotate the same setof 200 tweets (100 sarcastic + 100 not sarcastic).We computed inter-annotator agreement (IAA) be-tween each pair of annotators using Cohen?s kappa(?).
The pairwise IAA scores were ?=0.80, ?=0.81,and ?=0.82.
We then gave each annotator an addi-tional 1,000 tweets to annotate, yielding a total of3,200 annotated tweets.
We used the first 200 tweetsas our Tuning Set, and the remaining 3000 tweets asour Test Set.Our annotators judged 742 of the 3,200 tweets(23%) to be sarcastic.
Only 713 of the 1,600 tweetswith sarcasm hashtags (45%) were judged to be sar-castic based on our annotation guidelines.
There areseveral reasons why a tweet with a sarcasm hash-tag might not have been judged to be sarcastic.
Sar-casm may not be apparent without prior conversa-tional context (i.e., multiple tweets), or the sarcasticcontent may be in a URL and not the tweet itself, orthe tweet?s content may not obviously be sarcasticwithout seeing the sarcasm hashtag (e.g., ?The mostboring hockey game ever #sarcasm?
).Of the 1,600 tweets in our data set that were ob-tained from the random stream and did not have asarcasm hashtag, 29 (1.8%) were judged to be sar-castic based on our annotation guidelines.4.2 BaselinesOverall, 693 of the 3,000 tweets in our Test Setwere annotated as sarcastic, so a system that classi-fies every tweet as sarcastic will have 23% precision.To assess the difficulty of recognizing the sarcastictweets in our data set, we evaluated a variety of base-line systems.We created two baseline systems that use n-gramfeatures with supervised machine learning to createa sarcasm classifier.
We used the LIBSVM (Changand Lin, 2011) library to train two support vectormachine (SVM) classifiers: one with just unigramfeatures and one with both unigrams and bigrams.The features had binary values indicating the pres-ence or absence of each n-gram in a tweet.
The clas-sifiers were evaluated using 10-fold cross-validation.We used the RBF kernel, and the cost and gammaparameters were optimized for accuracy using un-igram features and 10-fold cross-validation on ourTuning Set.
The first two rows of Table 2 show theresults for these SVM classifiers, which achieved Fscores of 46-48%.We also conducted experiments with existing sen-timent and subjectivity lexicons to see whether theycould be leveraged to recognize sarcasm.
We exper-imented with three resources:Liu05 : A positive and negative opinion lexiconfrom (Liu et al 2005).
This lexicon contains2,007 positive sentiment words and 4,783 neg-ative sentiment words.MPQA05 : The MPQA Subjectivity Lexicon thatis part of the OpinionFinder system (Wilson etal., 2005a; Wilson et al 2005b).
This lexiconcontains 2,718 subjective words with positivepolarity and 4,910 subjective words with nega-tive polarity.AFINN11 The AFINN sentiment lexicon designedfor microblogs (Nielsen, 2011; Hansen et al2011) contains 2,477 manually labeled wordsand phrases with integer values ranging from -5(negativity) to 5 (positivity).
We considered allwords with negative values to have negative po-larity (1598 words), and all words with positivevalues to have positive polarity (879 words).We performed four sets of experiments with eachresource to see how beneficial existing sentiment710System Recall Precision F scoreSupervised SVM Classifiers1grams .35 .64 .461+2grams .39 .64 .48Positive Sentiment OnlyLiu05 .77 .34 .47MPQA05 .78 .30 .43AFINN11 .75 .32 .44Negative Sentiment OnlyLiu05 .26 .23 .24MPQA05 .34 .24 .28AFINN11 .24 .22 .23Positive and Negative Sentiment, UnorderedLiu05 .19 .37 .25MPQA05 .27 .30 .29AFINN11 .17 .30 .22Positive and Negative Sentiment, OrderedLiu05 .09 .40 .14MPQA05 .13 .30 .18AFINN11 .09 .35 .14Our Bootstrapped LexiconsPositive VPs .28 .45 .35Negative Situations .29 .38 .33Contrast(+VPs, ?Situations), Unordered .11 .56 .18Contrast(+VPs, ?Situations), Ordered .09 .70 .15& Contrast(+Preds, ?Situations) .13 .63 .22Our Bootstrapped Lexicons ?
SVM ClassifierContrast(+VPs, ?Situations), Ordered .42 .63 .50& Contrast(+Preds, ?Situations) .44 .62 .51Table 2: Experimental results on the test setlexicons could be for sarcasm recognition in tweets.Since our hypothesis is that sarcasm often arisesfrom the contrast between something positive andsomething negative, we systematically evaluated thepositive and negative phrases individually, jointly,and jointly in a specific order (a positive phrase fol-lowed by a negative phrase).First, we labeled a tweet as sarcastic if it con-tains any positive term in each resource.
The Pos-itive Sentiment Only section of Table 2 shows thatall three sentiment lexicons achieved high recall (75-78%) but low precision (30-34%).
Second, we la-beled a tweet as sarcastic if it contains any negativeterm from each resource.
The Negative SentimentOnly section of Table 2 shows that this approachyields much lower recall and also lower precisionof 22-24%, which is what would be expected of arandom classifier since 23% of the tweets are sar-castic.
These results suggest that explicit negativesentiments are not generally indicative of sarcasm.Third, we labeled a tweet as sarcastic if it containsboth a positive sentiment term and a negative senti-ment term, in any order.
The Positive and NegativeSentiment, Unordered section of Table 2 shows thatthis approach yields low recall, indicating that rela-tively few sarcastic tweets contain both positive andnegative sentiments, and low precision as well.Fourth, we required the contrasting sentiments tooccur in a specific order (the positive term must pre-cede the negative term) and near each other (no morethan 5 words apart).
This criteria reflects our obser-vation that positive sentiments often closely precedenegative situations in sarcastic tweets, so we wantedto see if the same ordering tendency holds for neg-ative sentiments.
The Positive and Negative Senti-ment, Ordered section of Table 2 shows that this or-dering constraint further decreases recall and onlyslightly improves precision, if at all.
Our hypothe-711sis is that when positive and negative sentiments areexpressed in the same tweet, they are referring todifferent things (e.g., different aspects of a product).Expressing positive and negative sentiments aboutthe same thing would usually sound contradictoryrather than sarcastic.4.3 Evaluation of Bootstrapped Phrase ListsThe next set of experiments evaluates the effective-ness of the positive sentiment and negative situa-tion phrases learned by our bootstrapping algorithm.The results are shown in the Our Bootstrapped Lex-icons section of Table 2.
For the sake of compar-ison with other sentiment resources, we first eval-uated our positive sentiment verb phrases and neg-ative situation phrases independently.
Our positiveverb phrases achieved much lower recall than thepositive sentiment phrases in the other resources, butthey had higher precision (45%).
The low recallis undoubtedly because our bootstrapped lexicon issmall and contains only verb phrases, while the otherresources are much larger and contain terms withadditional parts-of-speech, such as adjectives andnouns.Despite its relatively small size, our list of neg-ative situation phrases achieved 29% recall, whichis comparable to the negative sentiments, but higherprecision (38%).Next, we classified a tweet as sarcastic if it con-tains both a positive verb phrase and a negative sit-uation phrase from our bootstrapped lists, in anyorder.
This approach produced low recall (11%)but higher precision (56%) than the sentiment lex-icons.
Finally, we enforced an ordering constraintso a tweet is labeled as sarcastic only if it containsa positive verb phrase that precedes a negative situa-tion in close proximity (no more than 5 words apart).This ordering constraint further increased precisionfrom 56% to 70%, with a decrease of only 2 pointsin recall.
This precision gain supports our claim thatthis particular structure (positive verb phrase fol-lowed by a negative situation) is strongly indicativeof sarcasm.
Note that the same ordering constraintapplied to a positive verb phrase followed by a neg-ative sentiment produced much lower precision (atbest 40% precision using the Liu05 lexicon).
Con-trasting a positive sentiment with a negative situa-tion seems to be a key element of sarcasm.In the last experiment, we added the positive pred-icative expressions and also labeled a tweet as sar-castic if a positive predicative appeared in closeproximity to (within 5 words of) a negative situa-tion.
The positive predicatives improved recall to13%, but decreased precision to 63%, which is com-parable to the SVM classifiers.4.4 A Hybrid ApproachThus far, we have used the bootstrapped lexiconsto recognize sarcasm by looking for phrases in ourlists.
We will refer to our approach as the Contrastmethod, which labels a tweet as sarcastic if it con-tains a positive sentiment phrase in close proximityto a negative situation phrase.The Contrast method achieved 63% precision butwith low recall (13%).
The SVM classifier with un-igram and bigram features achieved 64% precisionwith 39% recall.
Since neither approach has highrecall, we decided to see whether they are comple-mentary and the Contrast method is finding sarcastictweets that the SVM classifier overlooks.In this hybrid approach, a tweet is labeled as sar-castic if either the SVM classifier or the Contrastmethod identifies it as sarcastic.
This approach im-proves recall from 39% to 42% using the Contrastmethod with only positive verb phrases.
Recall im-proves to 44% using the Contrast method with bothpositive verb phrases and predicative phrases.
Thishybrid approach has only a slight drop in precision,yielding an F score of 51%.
This result shows thatour bootstrapped phrase lists are recognizing sarcas-tic tweets that the SVM classifier misses.Finally, we ran tests to see if the performance ofthe hybrid approach (Contrast ?
SVM) is statisti-cally significantly better than the performance of theSVM classifier alone.
We used paired bootstrap sig-nificance testing as described in Berg-Kirkpatricket al(2012) by drawing 106 samples with repeti-tion from the test set.
These results showed that theContrast ?
SVM system is statistically significantlybetter than the SVM classifier at the p < .01 level(i.e., the null hypothesis was rejected with 99% con-fidence).4.5 AnalysisTo get a better sense of the strength and limitationsof our approach, we manually inspected some of the712tweets that were labeled as sarcastic using our boot-strapped phrase lists.
Table 3 shows some of the sar-castic tweets found by the Contrast method but notby the SVM classifier.i love fighting with the one i lovelove working on my last day of summeri enjoy tweeting [user] and not getting a replyworking during vacation is awesome .can?t wait to wake up early to babysit !Table 3: Five sarcastic tweets found by the Contrastmethod but not the SVMThese tweets are good examples of a positive sen-timent (love, enjoy, awesome, can?t wait) contrast-ing with a negative situation.
However, the negativesituation phrases are not always as specific as theyshould be.
For example, ?working?
was learned asa negative situation phrase because it is often neg-ative when it follows a positive sentiment (?I loveworking...?).
But the attached prepositional phrases(?on my last day of summer?
and ?during vacation?
)should ideally have been captured as well.We also examined tweets that were incorrectly la-beled as sarcastic by the Contrast method.
Somefalse hits come from situations that are frequentlynegative but not always negative (e.g., some peo-ple genuinely like waking up early).
However, mostfalse hits were due to overly general negative situa-tion phrases (e.g., ?I love working there?
was labeledas sarcastic).
We believe that an important directionfor future work will be to learn longer phrases thatrepresent more specific situations.5 ConclusionsSarcasm is a complex and rich linguistic phe-nomenon.
Our work identifies just one type of sar-casm that is common in tweets: contrast between apositive sentiment and negative situation.
We pre-sented a bootstrapped learning method to acquirelists of positive sentiment phrases and negative ac-tivities and states, and show that these lists can beused to recognize sarcastic tweets.This work has only scratched the surface of pos-sibilities for identifying sarcasm arising from posi-tive/negative contrast.
The phrases that we learnedwere limited to specific syntactic structures and werequired the contrasting phrases to appear in a highlyconstrained context.
We plan to explore methods forallowing more flexibility and for learning additionaltypes of phrases and contrasting structures.We also would like to explore new ways to iden-tify stereotypically negative activities and states be-cause we believe this type of world knowledge isessential to recognize many instances of sarcasm.For example, sarcasm often arises from a descrip-tion of a negative event followed by a positive emo-tion but in a separate clause or sentence, such as:?Going to the dentist for a root canal this after-noon.
Yay, I can?t wait.?
Recognizing the intensityof the negativity may also be useful to distinguishstrong contrast from weak contrast.
Having knowl-edge about stereotypically undesirable activities andstates could also be important for other natural lan-guage understanding tasks, such as text summariza-tion and narrative plot analysis.6 AcknowledgmentsThis work was supported by the Intelligence Ad-vanced Research Projects Activity (IARPA) via De-partment of Interior National Business Center (DoI/ NBC) contract number D12PC00285.
The U.S.Government is authorized to reproduce and dis-tribute reprints for Governmental purposes notwith-standing any copyright annotation thereon.
Theviews and conclusions contained herein are thoseof the authors and should not be interpreted asnecessarily representing the official policies or en-dorsements, either expressed or implied, of IARPA,DoI/NBE, or the U.S. Government.ReferencesTaylor Berg-Kirkpatrick, David Burkett, and Dan Klein.2012.
An empirical investigation of statistical signifi-cance in nlp.
In Proceedings of the 2012 Joint Confer-ence on Empirical Methods in Natural Language Pro-cessing and Computational Natural Language Learn-ing, EMNLP-CoNLL ?12, pages 995?1005.Paula Carvalho, Lu?
?s Sarmento, Ma?rio J. Silva, andEuge?nio de Oliveira.
2009.
Clues for detecting ironyin user-generated contents: oh...!!
it?s ?so easy?
;-).
InProceedings of the 1st international CIKM workshopon Topic-sentiment analysis for mass opinion, TSA2009.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIBSVM:A library for support vector machines.
ACM Transac-713tions on Intelligent Systems and Technology, 2:27:1?27:27.Henry S. Cheang and Marc D. Pell.
2008.
The sound ofsarcasm.
Speech Commun., 50(5):366?381, May.Henry S. Cheang and Marc D. Pell.
2009.
Acous-tic markers of sarcasm in cantonese and english.The Journal of the Acoustical Society of America,126(3):1394?1405.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Semi-supervised recognition of sarcastic sentences intwitter and amazon.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, CoNLL 2010.Elena Filatova.
2012.
Irony and sarcasm: Corpus gener-ation and analysis using crowdsourcing.
In Proceed-ings of the Eight International Conference on Lan-guage Resources and Evaluation (LREC?12).Roger J. Kreuz Gina M. Caucci.
2012.
Social and par-alinguistic cues to sarcasm.
online 08/02/2012, 25:1?22, February.Roberto Gonza?lez-Iba?n?ez, Smaranda Muresan, and NinaWacholder.
2011.
Identifying sarcasm in twitter: Acloser look.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies.Lars Kai Hansen, Adam Arvidsson, Finn Arup Nielsen,Elanor Colleoni, and Michael Etter.
2011.
Goodfriends, bad news - affect and virality in twitter.
InThe 2011 International Workshop on Social Comput-ing, Network, and Services (SocialComNet 2011).Roger Kreuz and Gina Caucci.
2007.
Lexical influenceson the perception of sarcasm.
In Proceedings of theWorkshop on Computational Approaches to FigurativeLanguage.Christine Liebrecht, Florian Kunneman, and AntalVan den Bosch.
2013.
The perfect solution for detect-ing sarcasm in tweets #not.
In Proceedings of the 4thWorkshop on Computational Approaches to Subjec-tivity, Sentiment and Social Media Analysis, WASSA2013.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: Analyzing and comparing opinionson the web.
In Proceedings of the 14th InternationalWorld Wide Web conference (WWW-2005).Stephanie Lukin and Marilyn Walker.
2013.
Really?well.
apparently bootstrapping improves the perfor-mance of sarcasm and nastiness classifiers for onlinedialogue.
In Proceedings of the Workshop on Lan-guage Analysis in Social Media.Finn Arup Nielsen.
2011.
A new anew: Evaluation ofa word list for sentiment analysis in microblogs.
InProceedings of the ESWC2011 Workshop on ?MakingSense of Microposts?
: Big things come in small pack-ages (http://arxiv.org/abs/1103.2903).Olutobi Owoputi, Brendan O?Connor, Chris Dyer, KevinGimpel, Nathan Schneider, and Noah A. Smith.
2013.Improved part-of-speech tagging for online conversa-tional text with word clusters.
In The 2013 Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics: Human LanguageTechnologies (NAACL 2013).Katherine P. Rankin, Andrea Salazar, Maria Luisa Gorno-Tempini, Marc Sollberger, Stephen M. Wilson, Dani-jela Pavlic, Christine M. Stanley, Shenly Glenn,Michael W. Weiner, and Bruce L. Miller.
2009.
De-tecting sarcasm from paralinguistic cues: Anatomicand cognitive correlates in neurodegenerative disease.Neuroimage, 47:2005?2015.Joseph Tepperman, David Traum, and ShrikanthNarayanan.
2006.
?Yeah right?
: Sarcasm recogni-tion for spoken dialogue systems.
In Proceedings ofthe INTERSPEECH 2006 - ICSLP, Ninth InternationalConference on Spoken Language Processing.Oren Tsur, Dmitry Davidov, and Ari Rappoport.
2010.ICWSM - A Great Catchy Name: Semi-SupervisedRecognition of Sarcastic Sentences in Online ProductReviews.
In Proceedings of the Fourth InternationalConference on Weblogs and Social Media (ICWSM-2010), ICWSM 2010.Michael Wiegand, Josef Ruppenhofer, and DietrichKlakow.
2013.
Predicative adjectives: An unsuper-vised criterion to extract subjective adjectives.
In Pro-ceedings of the 2013 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics: Human Language Technologies, pages 534?539, Atlanta, Georgia, June.
Association for Compu-tational Linguistics.T.
Wilson, P. Hoffmann, S. Somasundaran, J. Kessler,J.
Wiebe, Y. Choi, C. Cardie, E. Riloff, and S. Patward-han.
2005a.
OpinionFinder: A System for Subjec-tivity Analysis.
In Proceedings of HLT/EMNLP 2005Interactive Demonstrations, pages 34?35, Vancouver,Canada, October.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005b.
Recognizing contextual polarity in phrase-level sentiment analysis.
In Proceedings of the 2005Human Language Technology Conference / Confer-ence on Empirical Methods in Natural Language Pro-cessing.714
