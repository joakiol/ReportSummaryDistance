Paraphrasing Japanese noun phrases using character-based indexingTokunaga Takenobu Tanaka HozumiDepartment of Computer Science, Tokyo Institute of TechnologyTokyo Meguro ?Ookayama 2-12-1, 152-8552 Japantake@cl.cs.titech.ac.jpKimura KenjiAbstractThis paper proposes a novel method to extractparaphrases of Japanese noun phrases from aset of documents.
The proposed method con-sists of three steps: (1) retrieving passages us-ing character-based index terms given a nounphrase as an input query, (2) filtering the re-trieved passages with syntactic and seman-tic constraints, and (3) ranking the passagesand reformatting them into grammatical forms.Experiments were conducted to evaluate themethod by using 53 noun phrases and threeyears worth of newspaper articles.
The ac-curacy of the method needs to be further im-proved for fully automatic paraphrasing but theproposed method can extract novel paraphraseswhich past approaches could not.1 IntroductionWe can use various linguistic expressions to denote a con-cept by virtue of richness of natural language.
Howeverthis richness becomes a crucial obstacle when processingnatural language by computer.
For example, mismatchesof index terms cause failure of retrieving relevant docu-ments in information retrieval systems, in which docu-ments are retrieved on the basis of surface string match-ing.
To remedy this problem, the current information re-trieval system adopts query expansion techniques whichreplace a query term with a set of its synonyms (Baeza-Yates and Riberto-Neto, 1999).
The query expansionworks well for single-word index terms, but more sophis-ticated techniques are necessary for larger index units,such as phrases.
The effectiveness of phrasal indexinghas recently drawn researchers?
attention (Lewis, 1992;Mitra et al, 1997; Tokunaga et al, 2002).
However,query expansion of phrasal index terms has not been fullyinvestigated yet (Jacquemin et al, 1997).To deal with variations of linguistic expressions, para-phrasing has recently been studied for various applica-tions of natural language processing, such as machinetranslation (Mitamura, 2001; Shimohata and Sumita,2002), dialog systems (Ebert et al, 2001), QA sys-tems (Katz, 1997) and information extraction (Shinyamaet al, 2002).
Paraphrasing is defined as a process oftransforming an expression into another while keeping itsmeaning intact.
However, it is difficult to define what?keeping its meaning intact?
means, although it is thecore of the definition.
On what basis could we considerdifferent linguistic expressions denoting the same mean-ing?
This becomes a crucial question when finding para-phrases automatically.In past research, various types of clues have been usedto find paraphrases.
For example, Shinyama et al triedto find paraphrases assuming that two sentences sharingmany Named Entities and a similar structure are likelyto be paraphrases of each other (Shinyama et al, 2002).Barzilay and McKeown assume that two translationsfrom the same original text contain paraphrases (Barzi-lay and McKeown, 2001).
Torisawa used subcategoriza-tion information of verbs to paraphrase Japanese nounphrase construction ?NP1 no NP2?
into a noun phrasewith a relative clause (Torisawa, 2001).
Most of previ-ous work on paraphrasing took corpus-based approachwith notable exceptions of Jacquemin (Jacquemin et al,1997; Jacquemin, 1999) and Katz (Katz, 1997).
In par-ticular, text alignment technique is generally used to findsentence level paraphrases (Shimohata and Sumita, 2002;Barzilay and Lee, 2002).In this paper, we follow the corpus-based approachand propose a method to find paraphrases of a Japanesenoun phrase in a large corpus using information retrievaltechniques.
The significant feature of our method isuse of character-based indexing.
Japanese uses fourtypes of writing; Kanzi (Chinese characters), Hiragana,Katakana, and Roman alphabet.
Among these, Hiraganaand Katakana are phonographic, and Kanzi is an ideo-graphic writing.
Each Kanzi character itself has a certainmeaning and provides a basis for rich word formationability for Japanese.
We use Kanzi characters as indexterms to retrieve paraphrase candidates, assuming thatnoun phrases sharing the same Kanzi characters could beparaphrases of each other.
For example, character-basedindexing enables us to retrieve a paraphrase ???????
(a commuting child)?
for ????????
(a childgoing to school)?.
Note that their head is the same, ???
(child)?, and their modifiers are different but sharingcommon characters ??
(commute)?
and ??
(study)?.
Asshown in this example, the paraphrases generated basedon Japanese word formation rule cannot be classified interms of the past paraphrase classification (Jacquemin etal., 1997).The proposed method is summarized as follows.
Givena Japanese noun phrase as input, the method finds itsparaphrases in a set of documents.
In this paper, we useda collection of newspaper articles as a set of documents,from which paraphrases are retrieved.
The process is de-composed into following three steps:1. retrieving paraphrase candidates,2.
filtering the retrieved candidates based on syntacticand semantic constraints, and3.
ranking the resulting candidates.Newspaper articles are segmented into passages at punc-tuation symbols, then the passages are indexed based onKanzi characters and stored in a database.
The databaseis searched with a query, an input noun phrase, to obtain aset of passages, which are paraphrase candidates.
In gen-eral, using smaller index units, such as characters, resultsin gains in recall at the cost of precision.
To remedy this,we introduce a filtering step after retrieving paraphrasecandidates.
Filtering is performed based on syntactic andsemantic constraints.
The resulting candidates are rankedand provided as paraphrases.The following three sections 2, 3 and 4 describe eachof three steps in detail.
Section 5 describes experimentsto evaluate the proposed method.
Finally, section 6 con-cludes the paper and looks at the future work.2 Retrieving paraphrase candidates2.1 Indexing and term expansionIn conventional information retrieval, a query is given tothe system to retrieve a list of documents which are ar-ranged in descending order of relevance.
Our aim is toobtain paraphrases given a noun phrase as a query, whereretrieved objects should be smaller than documents.
Wedivide a document into a set of passages at punctuationsymbols.
These passages are retrieved by a given query,a noun phrase.The input noun phrase and the passages are segmentedinto words and they are assigned part of speech tags bya morphological analyzer.
Among these tagged words,content words (nouns, verbs, adjectives, adverbs) and un-known words are selected.
Kanzi characters containedin these words are extracted as index terms.
In addi-tion to Kanzi characters, words written in Katakana (mostof them are imported words) and numbers are also usedas index terms.
Precisely speaking, different numbersshould be considered to denote different meaning, but toavoid data sparseness problem, we abstract numbers intoa special symbol ?num?.As mentioned in section 1, the query expansion tech-nique is often used in information retrieval to solve thesurface notational difference between queries and docu-ments.
We also introduce query expansion for retrievingpassage.
Since we use Kanzi characters as index terms,we need linguistic knowledge defining groups of simi-lar characters for query expansion.
However this kind ofknowledge is not available at hand.
We obtain similar-ity of Kanzi characters from an ordinary thesaurus whichdefines similarity of words.If a word t is not a Katakana word, we expand it toa set of Kanzi characters E(t) which is defined by (1),where Ct is a semantic class including the word t, KC isa set of Kanzi characters used in words of semantic classC, fr(k,C) is a frequency of a Kanzi character k usedin words of semantic class C, and Kt is a set of Kanzicharacters in word t.E(t) = {k|k ?
KCt , k?
= argmaxl?Kt fr(l, Ct),fr(k,Ct) > fr(k?, Ct)} ?Kt?
{s|s ?
Ct, s is a Katakana word}(1)E(t) consists of Kanzi characters which is used in wordsof semantic class Ct more frequently, than the most fre-quent Kanzi character in the word t. If the word t is aKatakana word, it is not expanded.Let us see an expansion example of word ???
(hotspring)?.
Here we have t = ????
to expand, and wehave two characters that make the word, i.e.
Kt = {?, ?
}.
Suppose ????
belongs to a semantic classCt in which we find a set of words {???
(hot sprintplace), ????
(lukewarm water), ??
(warm water),??
(spa), ????
(oasis), .
.
.
}.
From this word set,we extract characters and count their occurence to obtainKCt = { ?
(35), ?
(22), ?
(20), ?
(8),.
.
.
}, wherea number in parentheses denotes the frequency of char-acters in the semantic class Ct.
Since the most frequentcharacter of Kt in KCt is ???
in this case, more fre-quently used character ???
is added to E(t).
In addi-tion, Katakana words ????
and ??????
are addedto E(t) as well.2.2 Term weightingAn index term is usually assigned a certain weight ac-cording to its importance in user?s query and documents.There are many proposals of term weighting most ofwhich are based on term frequency (Baeza-Yates andRiberto-Neto, 1999) in a query and documents.
Termfrequency-based weighting resides on Luhn?s assump-tion (Luhn, 1957) that a repeatedly mentioned expressiondenotes an important concepts.
However it is obvious thatthis assumption does not hold when retrieving paraphrasecandidates from a set of documents.
For term weighting,we use character frequency in a semantic class rather thanthat in a query and documents, assuming that a characterfrequently used in words of a semantic class representsthe concept of that semantic class very well.A weight of a term k in a word t is calculated by (2).w(k) =??????????????
?100if k is Katakana word or ?num?100?
log fr(k,Ct)?k?inE(t)log fr(k?, Ct)if k is a Kanzi(2)Katakana words and numbers are assigned a constantvalue, 100, and a Kanzi character is assigned a weight ac-cording to its frequency in the semantic class Ct, wherek is used in the word t.In the previous example of ???
?, we have obtainedan expanded term set { ?, ?, ?, ?
?, ????
}.Among this set, ????
and ??????
are assignedweight 100 because these are Katakana words, and therest three characters are assigned weight according to itsfrequency in the class.
For example, ???
is assignedweight 100?
log 35log 35+log 22+log 8 = 40.7.2.3 SimilaritySimilarity between an input noun phrase (I) and a pas-sage (D) is calculated by summing up the weights ofterms which are shared by I and D, as defined in (3).
Inthe equation, k takes values over the index terms sharedby I and D, w(k) is its weight calculated as described inthe previous section.sim(I,D) =?k?I?k?Dw(k) (3)Note that since we do not use term frequency in passages,we do not introduce normalization of passage length.3 Syntactic and semantic filteringThe proposed method utilizes Kanzi characters as indexterms.
In general, making index terms smaller units in-creases exhaustivity to gain recall, but, at the same time, itdecreases specificity to degrade precision (Sparck Jones,1972).
We aim to gain recall by using smaller units as in-dex terms at the cost of precision.
Even though Kanzi areideograms and have more specificity than phonograms,they are still less specific than words.
Therefore therewould be many irrelevant passages retrieved due to coin-cidentally shared characters.
In this section, we describea process to filter out irrelevant passages based on the fol-lowing two viewpoints.Semantic constraints : Retrieved passages should con-tain all concepts mentioned in the input noun phrase.Syntactic constraints : Retrieved passages should havea syntactically proper structure corresponding to theinput noun phrase.3.1 Semantic constraintsIn the indexing phase, we have decomposed an inputnoun phrase and passages into a set of Kanzi charactersfor retrieval.
In the filtering phase, from these charac-ters, we reconstruct words denoting a concept and verifyif concepts mentioned in the input noun phrase are alsoincluded in the retrieved passages.To achieve this, a retrieved passage is syntactically an-alyzed and dependencies between bunsetu (word phrase)are identified.
Then, the correspondence between wordsof the input noun phrase and bunsetu of the passage isverified.
This matching is done on the basis of sharingthe same Kanzi characters or the same Katakana words.Passages missing any of the concepts mentioned in theinput noun phrase are discarded in this phase.3.2 Syntactic constraintsSince passages are generated on the basis of punctuationsymbols, each passage is not guaranteed to have a syntac-tically proper structure.
In addition, a part of the passagetends to be a paraphrase of the input noun phrase ratherthan the whole passage.
In such cases, it is necessary toextract a corresponding part from the retrieved passageand transform it into a proper syntactic structure.By applying semantic constraints above, we have iden-tified a set of bunsetu covering the concepts mentionedin the input noun phrase.
We extract a minimum depen-dency structure which covers all the identified bunsetu.Finally the extracted structure is transformed into aproper phrase or clause by changing the ending of thehead (the right most element) and deleting unnecessaryelements such as punctuation symbols, particles and soon.Figure 1 illustrates the matching and transforming pro-cess described in this section.
The input noun phraseis ???
w1 ??
w2 ?
w3 ????
w4 (reduction oftelephone rate)?
which consists of four words w1 .
.
.
w4.Suppose a passage ?????????????????
(the company?s telephone rate reduction caused.
.
.
?
is re-trieved.
This passage is syntactically analyzed to give thedependency structure of four bunsetu b1 .
.
.
b4 as shownin Figure 1.Input NP ??
??
?
????
(telephone) (charge) (of) (reduction)w1 w2 w3 w4Retrieved ???
?????
?????
??
?passage (the company's) (telephone charge) (reduction) (caused)b1 b2 b3 b4???????????????????
?Extract proper structureTransform endingFigure 1: An example of matching and transformationCorrespondence between word w1 and bunsetu b2 ismade bacause they share a common character ???.
Wordw2 corresponds to bunsetu b2 as well due to characters ???
and ???.
And word w4 corresponds to bunsetu b3.Although there is no counterpart of word w3, this pas-sage is not discarded because word w3 is a function word(postposition).
After making correspondences, a mini-mum dependency structure, the shaded part in Figure 1,is extracted.
Then the ending auxiliary verb is deletedand the verb is restored to the base form.4 RankingRetrieved passages are ranked according to the similaritywith an input noun phrase as described in section 2.
How-ever this ranking is not always suitable from the view-point of paraphrasing.
Some of the retrieved passages arediscarded and others are transformed through processesdescribed in the previous section.
In this section, we de-scribe a process to rerank remaining passages accordingto their appropriateness as paraphrases of the input nounphrase.
We take into account the following three factorsfor reranking.?
Similarity score of passage retrieval?
Distance between words?
Contextual informationThe following subsections describe each of these factors.4.1 Similarity score of retrievalThe similarity score used in passage retrieval is not suffi-cient for evaluating the quality of the paraphrases.
How-ever, it reflects relatedness between the input noun phraseand retrieved passages.
Therefore, the similarity scorecalculated by (3) is taken into account when ranking para-phrase candidates.4.2 Distance between wordsIn general, distance between words which have a de-pendency relation reflects the strength of their semanticcloseness.
We take into account the distance between twobunsetu which have a dependency relation and containadjacent two words in the input noun phrase respectively.This factor is formalized as in (4), where ti is the ith wordin the input noun phrase, and dist(s, t) is the distance be-tween two bunsetu each of which contains s and t. Adistance between two bunsetu is defined as the number ofbunsetu between them.
When two words are contained inthe same bunsetu, the distance between them is definedas 0.Mdistance = 11 +?idist(ti, ti+1)(4)4.3 Contextual informationWe assume that phrases sharing the same Kanzi char-acters likely represent the same meaning.
Thereforethey could be paraphrases of each other.
However, eventhough a Kanzi denotes a certain meaning, its meaning isoften ambiguous.
This problem is similar to word senseambiguities, which have been studied for many years.
Tosolve this problem, we adopt an idea one sense per collo-cation which was introduced in word sense disambigua-tion research (Yarowsky, 1995).
Considering a newspa-per article in which the retrieved passage and the inputnoun phrase is included as the context, the context sim-ilarity is taken into account for ranking paraphrase can-didates.
More concretely, context similarity is calculatedby following procedure.1.
For each paraphrase candidate, a context vector isconstructed from the newspaper article containingthe passage from which the candidate is derived.The article is morphologically analyzed and contentwords are extracted to make the context vector.
Thetf ?
idf metric is used for term weighting.2.
Since the input is given in terms of a noun phrase,there is no corresponding newspaper article for theinput.
However there is a case where the retrievedpassages include the input noun phrase.
Such pas-sages are not useful for finding paraphrases, but use-ful for constructing a context vector of the inputnoun phrase.
The context vector of the input nounphrase is constructed in the same manner as that ofparaphrase candidates, except that all newspaper ar-ticles including the noun phrase are used.3.
Context similarity Mcontext is calculated by cosinemeasure of two context vectors as in (5), wherewi(k) and wd(k) are the weight of the k-th term ofthe input context vector and the candidate contextvector, respectively.Mcontext =?k wi(k)wd(k)?
?k w2i (k)?
?k w2d(k)(5)4.4 Ranking paraphrase candidatesParaphrase candidates are ranked in descending order ofthe product of three measures, sim(I,D) (equation (3)),Mdistance (equation (4)) and Mcontext (equation (5)).5 Experiments5.1 Data and preprocessingAs input noun phrases, we used 53 queries excerptedfrom Japanese IR test collection BMIR-J21 (Kitani et al,1998) based on the following criteria.?
A query has two or more index terms.It is less likely to retrieve proper paraphrases withonly one index term, since we adopt character-basedindexing.?
A query does not contain proper names.It is generally difficult to paraphrase proper names.We do not deal with proper name paraphrasing.?
A query contains at most one Katakana word ornumber.The proposed method utilize characteristics of Kanzicharacters, ideograms.
It is obvious that the methoddoes not work well for Kanzi -poor expressions.We searched paraphrases in three years worth of news-paper articles (Mainichi Shimbun) from 1991 to 1993.
Asdescribed in section 2, each article is segmented into pas-sages at punctuation marks and symbols.
These passagesare assigned a unique identifier and indexed, then storedin the GETA retrieval engine (IPA, 2003).
We used theJUMAN morphological analyzer (Kurohashi and Nagao,1998) for indexing the passages.
As a result of prepro-cessing described above, we obtained 6,589,537 passagesto retrieve.
The average number of indexes of a passagewas 12.5.2 Qualitative evaluationOut of 53 input noun phrases, no paraphrase was obtainedfor 7 cases.
Output paraphrases could be classified intothe following categories.1BMIR-2 contains 60 queries.
(1) The paraphrase has the same meaning as that of theinput noun phrase.e.g.
?????
(damage by cool summer) ???
(cool summer damage)2Note that this example is hardly obtained by the ex-isting approaches such as syntactic transformationand word substitution with thesaurus.
(2) The paraphrase does not have exactly the samemeaning but has related meaning.
This category isfurther divided into three subcategories.
(2-a) The meaning of the paraphrase is more specificthan that of the input noun phrase.e.g.
??
(agricultural chemicals)???????
(insecticide and herbicide)(2-b) The meaning of the paraphrase is more generalthan that of the input noun phrase.e.g.
????
(stock movement)???????????
(movement of stock and exchangerate)(2-c) The paraphrase has related meaning to the in-put but is not categorized into above two.e.g.
???
(drinks) ????????
(inter-national drink exhibition)(3) There is no relation between the paraphrase and theinput noun phrase.Among these categories, (1) and (2-a) are useful froma viewpoint of information retrieval.
By adding the para-phrase of these classes to a query, we can expect the ef-fective phrase expansion in queries.Since the paraphrase of (2-b) generalizes the conceptdenoted by the input, using these paraphrases for queryexpansion might degrade precision of the retrieval.
How-ever, they might be useful for the recall-oriented retrieval.The paraphrases of (2-c) have the similar property, sincerelatedness includes various viewpoints.The main reason of retrieval failure and irrelevant re-trieval (3) are summarized as follows:?
The system cannot generate a paraphrase, whenthere is no proper paraphrase for the input.
In partic-ular, this tends to be the case for single-word inputs,such as ???
(liquid crystal)?
and ???
(movie)?.But this does not imply the proposed method doesnot work well for single-words inputs.
We had sev-eral interesting paraphrases for single-word inputs,such as ???????
(chemicals for agricultureand gardening)?
for ???
(agricultural chemicals)?.?
We used only three years worth of newspaper ar-ticles due to the limitation of computational re-soruces.
Sometimes, the system could not generate2The left-hand side of the arrow is the input and the right-hand side is its paraphrase.the paraphrase of the input because of the limitedsize of the corpus.5.3 Quantitative evaluationSince there is no test collection available to evaluate para-phrasing, we asked three judges to evaluate the output ofthe system subjectively.
The judges classified the outputsinto the categories introduced in 5.2.
The evaluation wasdone on the 46 inputs which gave at least one output.Table 1 shows the results of judgments.
Column ?Q?denotes the query identifier, ?Len.?
denotes its length inmorphemes, ?#Para.?
denotes the number of outputs andthe columns (1) through (3) denote the number of outputswhich are classified into each category by three judges.Therefore, the sum of these columns makes a triple of thenumber of outputs.
The decimal numbers in the paren-theses denote the generalized raw agreement indices ofeach category, which are calculated as given in (6) (Ue-bersax, 2001), where K is the number of judged cases, Cis the number of categories, njk is the number of timescategory j is applied to case k, and nk is calculated bysumming up over categories on case k; nk =?Cj=1 njk.ps(j) =?Kk=1 njk(njk ?
1)?Kk=1 nk ?
1(6)In our case, K is the number of outputs (column?#Para.?
), nk is the number of judges, 3, and j movesover (1) through (3).As discussed in 5.2, from the viewpoint of informationretrieval, paraphrases of category (1) and (2-a) are use-ful for query expansion of phrasal index terms.
Column?Acc.?
denotes the ratio of paraphrases of category (1)and (2-a) to the total outputs.
Column ?Prec.?
denotesnon-interpolated average precision.
Since the precisiondiffers depending on the judge, the column is showingthe average of the precisions given by three judges.We could obtain 45 paraphrases on average for eachinput.
But the average accuracy is quite low, 10%, whichmeans only one tenth of output is useful.
Even thoughconsidering that all paraphrases not being in category (3)are useful, the accuracy only doubled.
This means filter-ing conditions should be more rigid.
However, lookingat the agreement indices, we see that category (3) ranksvery high.
Therefore, we expect finding the paraphrasesin category (3) is easy for a human.
From all this, weconclude that the proposed method need to be improvedin accuracy to be used for automatic query expansion ininformation retrieval, but it is usable to help users to mod-ify their queries by suggesting possible paraphrases.Seeing the column ?Len.
?, we find that the proposedmethod does not work for complex noun phrases.
Theaverage length of input noun phrase is 4.5 morphemes.The longer input often results in less useful paraphrases.The number of outputs also decreases for longer inputs.We require all concepts mentioned in the input to havetheir counterparts in its paraphrases as described in 3.1.This condition seems to be strict for longer inputs.
Inaddition, we need to take into account syntactic variationsof longer inputs.
Integrating syntactic transformation intothe proposed method is one of the possible extensions toexplore when dealing with longer inputs (Yoshikane etal., 2002).6 Conclusions and future workThis paper proposed a novel approach to extract para-phrases of a Japanese noun phrase from a corpus.
Theproposed method adopts both information retrieval tech-niques and natural language processing techniques.
Un-like past research, the proposed method uses Kanzi(ideograms) characters as index terms and retrieves para-phrase candidates in a set of passages.
The retrieved can-didates are then filtered out based on syntactic and se-mantic constraints.The method was evaluated by a test set of 53 nounphrases, and paraphrases were extracted for 46 cases.These paraphrases were evaluated subjectively by threeindependent judges.
The quantitative evaluation suggeststhat the performance needs to be further improved forfully automatic query expansion in information retrieval,but is usable to help users modify their queries by sug-gesting possible paraphrases.From a qualitative point of view, the proposed methodcould extract paraphrases which cannot be obtained byprevious approaches such as syntactic transformationand word substitution.
Considering characteristics ofJapanese word formation by using character-based index-ing enables us to obtain novel paraphrases.The performance of the current system needs to be im-proved for fully automatic paraphrasing.
One directionis introducing more precise filtering criteria.
The cur-rent system adopts only dependency analysis of bunsetu.We need case analysis as well, to capture relations amongthe bunsetu.
Integrating syntactic transformation into theproposed method is another research direction to explore.In this paper, we evaluated output paraphrases subjec-tively.
Task oriented evaluation should be also conducted.For example, effectiveness of phrase expansion in infor-mation retrieval systems should be investigated.Q Len.
#Para.
(1) (2-a) (2-b) (2-c) (3) Acc.
Prec.3 1 17 0 (0.00) 7 (0.86) 0 (0.00) 15 (0.60) 29 (0.83) 0.14 0.334 1 60 1 (0.00) 61 (0.74) 2 (0.50) 38 (0.47) 78 (0.69) 0.34 0.335 1 68 4 (0.75) 8 (0.62) 16 (0.00) 56 (0.14) 120 (0.62) 0.06 0.136 1 81 0 (0.00) 0 (0.00) 3 (0.33) 2 (0.00) 238 (0.99) 0.00 0.007 2 61 5 (0.60) 20 (0.70) 44 (0.45) 58 (0.66) 56 (0.73) 0.14 0.248 1 93 3 (0.00) 22 (0.68) 11 (0.64) 24 (0.42) 218 (0.91) 0.09 0.219 2 64 4 (0.75) 6 (0.67) 2 (0.50) 3 (0.33) 177 (0.99) 0.05 0.0710 3 68 24 (0.42) 37 (0.22) 14 (0.50) 83 (0.41) 45 (0.29) 0.30 0.2911 2 68 0 (0.00) 12 (0.08) 9 (0.44) 20 (0.25) 163 (0.83) 0.06 0.0812 2 53 7 (0.14) 54 (0.76) 1 (0.00) 60 (0.37) 37 (0.19) 0.38 0.3813 2 89 22 (0.32) 23 (0.30) 3 (1.00) 9 (0.11) 210 (0.98) 0.17 0.2414 3 62 13 (0.85) 0 (0.00) 16 (0.44) 8 (0.12) 149 (0.92) 0.07 0.0615 3 77 41 (0.49) 18 (0.44) 7 (0.57) 32 (0.38) 133 (0.89) 0.26 0.2918 2 76 13 (0.08) 18 (0.28) 9 (0.56) 55 (0.42) 133 (0.80) 0.14 0.2120 3 51 11 (0.82) 19 (0.95) 14 (0.71) 29 (0.62) 80 (0.82) 0.20 0.2021 2 50 0 (0.00) 4 (0.75) 3 (0.33) 0 (0.00) 143 (0.98) 0.03 0.0422 3 70 18 (0.72) 7 (0.00) 2 (0.50) 14 (0.36) 169 (0.94) 0.12 0.1624 3 64 8 (0.88) 1 (0.00) 3 (1.00) 1 (0.00) 179 (0.99) 0.05 0.0426 4 58 2 (0.50) 22 (0.18) 1 (0.00) 22 (0.27) 127 (0.78) 0.14 0.1327 6 13 1 (0.00) 7 (0.00) 0 (0.00) 0 (0.00) 31 (0.77) 0.21 0.3028 4 56 20 (0.25) 8 (0.38) 3 (0.33) 53 (0.30) 83 (0.54) 0.17 0.2229 6 34 0 (0.00) 3 (1.00) 0 (0.00) 1 (0.00) 97 (0.98) 0.03 0.2530 4 16 0 (0.00) 12 (0.33) 1 (0.00) 7 (0.14) 28 (0.64) 0.25 0.2731 6 4 0 (0.00) 0 (0.00) 0 (0.00) 0 (0.00) 12 (1.00) 0.00 0.0032 4 60 15 (0.80) 19 (0.58) 4 (0.00) 31 (0.39) 111 (0.84) 0.19 0.2433 4 67 15 (0.60) 58 (0.83) 2 (0.50) 20 (0.65) 105 (0.94) 0.36 0.5134 4 54 1 (0.00) 12 (0.67) 0 (0.00) 7 (0.57) 142 (0.99) 0.08 0.1936 7 13 0 (0.00) 1 (0.00) 0 (0.00) 1 (0.00) 37 (0.97) 0.03 0.0637 5 7 1 (0.00) 1 (0.00) 0 (0.00) 1 (0.00) 18 (0.89) 0.10 0.2238 5 64 2 (0.50) 1 (0.00) 6 (1.00) 8 (0.38) 175 (0.97) 0.02 1.0039 4 59 2 (0.50) 4 (0.00) 0 (0.00) 9 (0.56) 162 (0.97) 0.03 0.0440 4 54 0 (0.00) 11 (0.55) 30 (0.10) 2 (0.50) 119 (0.76) 0.07 0.0941 5 51 0 (0.00) 4 (0.50) 4 (0.00) 2 (0.00) 143 (0.97) 0.03 0.0743 5 65 1 (0.00) 1 (0.00) 4 (0.00) 5 (0.20) 184 (0.95) 0.01 0.0144 7 54 3 (1.00) 0 (0.00) 34 (0.35) 3 (0.00) 122 (0.81) 0.02 0.0345 6 7 0 (0.00) 0 (0.00) 0 (0.00) 0 (0.00) 21 (1.00) 0.00 0.0046 7 1 0 (0.00) 0 (0.00) 0 (0.00) 0 (0.00) 3 (1.00) 0.00 0.0047 9 5 0 (0.00) 0 (0.00) 0 (0.00) 1 (0.00) 14 (0.93) 0.00 0.0048 7 10 1 (0.00) 1 (0.00) 3 (0.00) 3 (0.00) 22 (0.86) 0.07 0.2149 8 1 0 (0.00) 0 (0.00) 0 (0.00) 0 (0.00) 3 (1.00) 0.00 0.0050 8 58 1 (0.00) 1 (0.00) 2 (0.00) 3 (0.00) 167 (0.97) 0.01 0.0651 6 18 1 (0.00) 13 (0.92) 1 (0.00) 9 (0.78) 30 (1.00) 0.26 0.3352 7 21 4 (0.00) 1 (0.00) 1 (0.00) 1 (0.00) 56 (0.95) 0.08 0.1355 7 26 2 (0.00) 1 (0.00) 0 (0.00) 4 (0.00) 71 (0.96) 0.04 0.0359 10 21 0 (0.00) 0 (0.00) 0 (0.00) 4 (0.50) 59 (0.97) 0.00 0.0060 12 2 0 (0.00) 0 (0.00) 0 (0.00) 0 (0.00) 6 (1.00) 0.00 0.00Ave.
4.5 45 5.35 (0.24) 10.8 (0.30) 5.54 (0.23) 15.3 (0.24) 97.9 (0.87) 0.10 0.17Table 1: Summary of judgmentReferencesR.
Baeza-Yates and B. Riberto-Neto.
1999.
Modern In-formation Retrieval.
Addison Wesley.R.
Barzilay and L. Lee.
2002.
Bootstrapping lexicalchoice via multiple-sequence alignment.
In Proceed-ings of 2002 Conference on Empirical Methods in Nat-ural Language Processing, pages 164?171.R.
Barzilay and K. R. McKeown.
2001.
Extracting para-phrases from a parallel corpus.
In Proceedings of 39thAnnual Meeting of the Association for ComputationalLinguistics, pages 50?57.C.
Ebert, L. Shalom, G. Howard, and N. Nicolas.
2001.Generating full paraphrases of fragments in a dialogueinterpretation.
In Proceedings of the 2nd SIGdialWorkshop on Discourse and Dialouge.IPA.
2003.
GETA: Generic Engine for Transposable As-sociation.
http://geta.ex.nii.ac.jp.C.
Jacquemin, J. L. Klavans, and E. Tzoukermann.
1997.Expansion of multi-word terms for indexing and re-trieval using morphology and syntax.
In Proceedingsof 35th Annual Meeting of the Assosiation for Compu-tational Linguistics.C.
Jacquemin.
1999.
Syntagmatic and paradigmatic rep-resentation of term variation.
In Proceedings of 37thAnnual Meeting of the Assosiation for ComputationalLinguistics, pages 341?348.B.
Katz.
1997.
Annotating the world wide web using nat-ural language.
In Proceedings of ?Computer-assistedinformation searching on Internet?
(RIAO ?97), pages136?155.T.
Kitani, Y. Ogawa, T. Ishikawa, H. Kimoto, I. Keshi,J.
Toyoura, T. Fukushima, K. Matsui, Y. Ueda,T.
Sakai, T. Tokunaga, H. Tsuruoka, H. Nakawatase,and T. Agata.
1998.
Lessons from BMIR-J2: A testcollection for Japanese IR systems.
In Proceedings ofthe Annual International ACM SIGIR Conference onResearch and Development in Information Retrieval,pages 345?346.S.
Kurohashi and M. Nagao.
1998.
Building a Japaneseparsed corpus while improving the parsing system.
InProceedings of the 1st International Conference onLanguage Resources and Evaluation, pages 719?724.D.
D. Lewis.
1992.
An evaluation of phrasal and clus-tered representations of a text categorization task.
InProceedings of the Annual International ACM SIGIRConference on Research and Development in Informa-tion Retrieval, pages 37?50.H.
P. Luhn.
1957.
A statistical approach to mechanizedencoding and searching of literary information.
IBMJournal of Research and Development, 1(4):390?317.T.
Mitamura.
2001.
Automatic rewriting for con-trolled language translation.
In The Sixth Nat-ural Language Processing Pacific Rim Symposium(NLPRS2001) Post-Conference Workshop, AutomaticParaphrasing: Theories and Applications, pages ???M.
Mitra, C. Buckley, A. Singhal, and C. Cardie.
1997.An analysis of statistical and syntactic phrases.
In Pro-ceedings of RIAO ?97, pages 200?214.M.
Shimohata and E. Sumita.
2002.
Automatic para-phrasing based on parallel corpus for normalization.In Third International Conference on Language Re-sources and Evaluation, pages 453?457.Y.
Shinyama, S. Sekine, K. Sudo, and R. Grishman.2002.
Automatic paraphrase acquisition from news ar-ticles.
In Proceedings of Human Language TechnologyConference (HLT2002), pages 40?46.K.
Sparck Jones.
1972.
A statistical interpretation ofterm specificity and its application in retrieval.
Journalof Documentation, 28(1):11?21.T.
Tokunaga, K. Kenji, H. Ogibayashi, and H. Tanaka.2002.
Selecting effective index terms using a decisiontree.
Natural Language Engineering, 8(2-3):193?207.K.
Torisawa.
2001.
A nearly unsupervised learningmethod for automatic paraphrasing of japanese nounphrase.
In The Sixth Natural Language Processing Pa-cific Rim Symposium (NLPRS2001) Post-ConferenceWorkshop, Automatic Paraphrasing: Theories and Ap-plications, pages 63?72.J.
Uebersax.
2001.
Statistical methods for rater agree-ment.
http://ourworld.compuserve.com/homepages/jsuebersax/agree.htm.D.
Yarowsky.
1995.
Unsupervised word sense disam-biguation rivaling supervised methods.
In Proceedingsof 33rd Annual Meeting of the Assosiation for Compu-tational Linguistics, pages 189?196.F.
Yoshikane, K. Tsuji, K. Kageura, , and C. Jacquemin.2002.
Detecting Japanese term variation in textualcorpus.
In Proceedings of 4th International Work-shop on Information Retrieval with Asian Languages(IRAL?99), pages 164?171.
