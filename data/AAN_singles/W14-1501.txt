Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC) @ EACL 2014, pages 1?10,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsPost-hoc Manipulations of Vector Space Modelswith Application to Semantic Role LabelingJenna Kanerva and Filip GinterDepartment of Information TechnologyUniversity of Turku, Finlandjmnybl@utu.fi, figint@utu.fiAbstractIn this paper, we introduce several vectorspace manipulation methods that are ap-plied to trained vector space models in apost-hoc fashion, and present an applica-tion of these techniques in semantic rolelabeling for Finnish and English.
Specifi-cally, we show that the vectors can be cir-cularly shifted to encode syntactic infor-mation and subsequently averaged to pro-duce representations of predicate sensesand arguments.
Further, we show that it ispossible to effectively learn a linear trans-formation between the vector representa-tions of predicates and their arguments,within the same vector space.1 IntroductionRecently, there has been much progress in the de-velopment of highly scalable methods for induc-ing vector space representations of language.
Inparticular, the word2vec method (Mikolov et al.,2013b) is capable of training on billions of tokensin a matter of hours, producing high quality rep-resentations.
An exciting property exhibited bythe vector spaces induced using word2vec is thatthey preserve a number of linguistic regularities,lending themselves to simple algebraic operationswith the vectors (Mikolov et al., 2013c) and linearmapping between different spaces (Mikolov et al.,2013a).
These can be seen as post-hoc operationsmanipulating the vector space with the significantadvantage of not requiring a new task-specific rep-resentation to be induced, as is customary.In this paper, we will investigate several addi-tional such methods.
Firstly, we will show howsyntax information can be encoded by the circularshift operation and demonstrate that such shiftedvectors can be averaged in a meaningful manner torepresent predicate arguments.
And secondly, wewill show that linear transformations of the vec-tor spaces can be successfully applied also withina single vector space, to tasks such as transform-ing the vector of a predicate into the vector of itsargument with a particular role.To test the above-mentioned operations in anextrinsic setting, we will develop these methodswithin the context of the Semantic Role Label-ing (SRL) task.
Automatic Semantic Role Label-ing is the process of identifying the semantic ar-guments of predicates, and assigning them labelsdescribing their roles.
A predicate and its argu-ments form a predicate-argument structure, whichdescribes events such as who does what to whom,when and where.The SRL task is ?semantic?
in its nature andtherefore suitable for the application and testingof vector space representations and methods fortheir manipulation.
However, rather than merelyadding features derived from vector spaces intoan existing system, we will approach the develop-ment from a different angle and test whether theserepresentations of words and the similarities theyinduce can be used for predicate argument role as-signment and predicate sense disambiguation asthe primary source of information, with little ad-ditional features.In addition to the standard English CoNLL?09dataset, we will apply the methods also to FinnishSRL, testing the applicability of word2vec and theoverall methodology that we will develop in thispaper to this highly inflective language.
With itsconsiderably larger and sparser surface form lex-icon, Finnish poses interesting challenges of itsown, and only little attention has been dedicatedto the application of distributional semantics meth-ods specifically to Finnish.
This is also partly dueto the lack of sufficiently sized corpora, which weaddress in this work by using a 1.5B token corpusof Internet Finnish.In order to be able to test the proposed meth-1ods on SRL, we need to carry out not only rolelabeling and predicate sense disambiguation, butalso argument detection.
As a secondary theme,we thus test whether dependency parse graphs inthe semantically motivated Stanford Dependen-cies (SD) scheme can be used as-is to perform ar-gument identification.
We are especially interestedin this scheme as it is designed to capture seman-tically contentful relations (de Marneffe and Man-ning, 2008) and would thus appear to be the idealchoice as the underlying syntactic representationfor SRL.2 Data and Task SettingThroughout the paper, we will use the exact sametask setting as in the CoNLL?09 Shared Task onSyntactic and Semantic Dependencies in MultipleLanguages (Haji?c et al., 2009).
The input of theSRL system are automatically generated syntacticparses and the list of predicate tokens to be con-sidered in each sentence.
For each of the predi-cates, the SRL system is expected to predict thesense of the predicate, identify all tokens whichare its arguments, and for each argument, iden-tify its role.
As the primary measure of perfor-mance, we will use the semantic F-score definedin the CoNLL shared task.
This F-score is cal-culated from the precision and recall of argumentidentification (calculated in the obvious manner)and also incorporates the sense of the predicate viaan additional ?dummy?
argument.
We use the of-ficial implementation of the metric distributed onthe Shared Task site.1We will report our results on two SRL datasets:the Finnish PropBank (Haverinen et al., 2013a)and the English SRL dataset from the CoNLL?09Shared Task.
The Finnish PropBank is built ontop of the Turku Dependency Treebank (TDT), a205K token corpus of general Finnish (Haverinenet al., 2013b) annotated using the SD scheme, in-cluding manually annotated conjunct propagationand other dependency relations from the non-basiclayer of the scheme.
These extended SD analyzesare thus not strictly trees, rather they are directedlabeled graphs (see Figure 1).
The Finnish Prop-Bank has 22 different argument roles of which 7are numbered core roles and 15 are modifier roles.The Finnish data has 164,530 training tokens with27,603 occurrences of 2,826 unique predicate-1http://ufal.mff.cuni.cz/conll2009-st/scorer.htmlHe ate.01 lunch and then washed.01 dishes .<nsubj:A0 dobj:A1> <advmod:AM-TMP dobj:A1>cc> conj><nsubj:A0 punct>Figure 1: Extended Stanford Dependenciesscheme combined with PropBank annotation.sense combinations.
The English CoNLL data isderived from the PropBank and NomBank corpora(Palmer et al., 2005; Meyers et al., 2004) and it hasa total of 54 different argument roles.
In additionto the same 22 roles as Finnish, English also hasdiscontinuous variants for each role.
The Englishdata has 958,024 training tokens with 178,988 oc-currences of 15,880 unique predicate-sense com-binations.All Finnish results are reported on the test sub-set of the Finnish PropBank, and have no previ-ously published baseline to compare with.
Theresults we report for English are produced on theofficial test section of the CoNLL?09 data and arethus directly comparable to the official results re-ported in the Shared Task.In the test phase, we follow the Shared Task set-ting whereby morphological and syntactic analy-sis is predicted as well, i.e., no gold standard dataenters the system other than the tokenization andthe information of which tokens constitute predi-cates.
We produce the Finnish morphological andsyntactic analyses for the test set with the parsingpipeline of Haverinen et al.
(2013b), composed ofa morphological analyzer and tagger (Hal?acsy etal., 2007; Pirinen, 2008; Lind?en et al., 2009), de-pendency parser (Bohnet, 2010) and a machine-learning based component for predicting the ex-tended SD dependencies (Nyblom et al., 2013).While the English data is provided with automati-cally produced dependency parses, we are specifi-cally interested in the SD scheme and therefore were-parse the corpus with the Stanford parser2tak-ing a union of the base and collapsed dependencyoutputs to match the Finnish data.The vector space models used throughout thispaper are induced using the word2vec software(skip-gram architecture with default parameters).For Finnish, the model is trained on 1.5 billion to-kens of Finnish Internet texts gathered from theCommon Crawl dataset.3The data was sentence-2Version 3.3.1, October 20133http://commoncrawl.org/2split and tokenized using the OpenNLP4toolchaintrained on TDT, and processed in the same man-ner as the above-mentioned test set.
This gives usthe opportunity to build two models, one for theword forms and the other for the lemmas.
BothFinnish models have 300 dimensions.
For En-glish, the vector representation is induced on theunion of the English Wikipedia (1.7B tokens) andthe English Gigaword corpus (4B tokens), the to-tal training data size thus being 5.7 billion tokens.5Sentence splitting and tokenization was carried outusing the relevant modules from the BRAT pack-age (Stenetorp et al., 2012).6The English modelhas 200 dimensions.3 MethodIn this section, we will describe the methods de-veloped for argument identification, argument rolelabeling and predicate sense disambiguation, thethree steps that must be implemented to obtain afull SRL system.3.1 Argument identificationIn a semantically-oriented dependency scheme,such as SD, it can be expected that a notableproportion of arguments (in the SRL sense) aredirectly attached to the predicate, and argumentidentification can be reduced to assuming that ?with a limited number of systematic exceptions ?every argument is a dependent of the predicate.The most frequent case where the assumption doesnot hold in Finnish are the copula verbs, which arenot analyzed as heads in the SD scheme.
For En-glish, a common case are the auxiliaries, whichgovern the main verb in the CoNLL data and arethus marked as arguments for other higher-levelpredicates as well.
In the SD scheme, on the otherhand, the main verb governs the auxiliary takingalso its place in the syntactic tree.
Since the fo-cus of this paper lies in role assignment, we donot go beyond developing a simple rule set to dealwith a limited number of such cases.
In Section 6,we will contrast this simple argument identifica-tion method to that of the winning CoNLL?09 sys-tem and we will show that while for Finnish theabove holds surprisingly well, the performance onthe English data is clearly sub-optimal.4http://opennlp.apache.org/5We are thankful to Sampo Pyysalo for providing us withthe English word2vec model.6http://brat.nlplab.orgFinnisheat + A1 AM-TMPsalted fish not untileggs nowwheat bread againnuts whenpickled cucumbers thenEnglishdrive + A1 drive + AM-TMPcar immediatelytruck morningcars nowvehicle afternoontires finallyTable 1: Five most similar words for the givenaverage argument vectors.
AM-TMP refers to thetemporal modifier role.
Note that the average vec-tors for Finnish modifier roles are estimated inde-pendently from the predicates (see Section 3.4).3.2 Role ClassificationOur initial role classification algorithm is based oncalculating the vector representation of an ?aver-age argument?
with a given role.
For every predi-cate x and every role r, we calculate the represen-tation of the average argument with the role asA(x, r) =?
(r,x,y)y?count, (1)where y?
refers to the L2 normalized version of y,and count to the number of training pairs that aresummed over.
We are thus averaging the normal-ized vectors of all words y seen in the training dataas an argument of the predicate x with the role r.To establish the role for some argument y duringtesting, we can simply choose the role whose av-erage argument vector has the maximal similarityto y, i.e.argmaxrsim(A(x, r), y), (2)where sim(a, b) is the standard cosine similarity.To gain an intuitive insight into whether the av-erage argument vectors behave as expected, weshow in Table 1 the top five most similar wordsto the average argument vectors for several rolesand predicates.
When evaluated with the data setsdescribed in Section 2, this initial method leads to61.32% semantic F-score for Finnish and 65.05%for English.33.3 Incorporating syntaxAs we will demonstrate shortly, incorporating in-formation about dependency relations can lead toa substantial performance gain.
To incorporate thedependency relation information into the role clas-sification method introduced above, we apply thetechnique of circular shifting of vectors.
This tech-nique was previously used in the context of Ran-dom Indexing (RI) to derive new vectors from ex-isting ones in a deterministic fashion (Basile andCaputo, 2012).
In RI, the shift operation is how-ever not used on the final vectors, but rather al-ready during the induction of the vector represen-tation.Given a vector representation of an argument y,we can encode the dependency relation of y andits predicate by circularly shifting the vector ofy by an offset assigned separately to each possi-ble dependency relation.
The assignment is arbi-trary, but such that no two relations are assignedthe same offset.
We will denote this operation asyd, meaning the vector y circularly shifted tothe right by the offset assigned to the dependencyrelation d. For instance, circularly shifting a vec-tor a = (1, 2, 3, 4, 5) to the right by an offset of 2results in a2 = (4, 5, 1, 2, 3).We can incorporate the dependency relationswhen calculating the average vectors representingarguments as follows:A(x, r) =?(r,d,x,y)y?
dcount, (3)where (r, d, x, y) iterates over all predicate-argument pairs (x, y) where y has the dependencyrelation d and role r. The role of an argument inthe test phase is established as before, by takingthe role which maximizes the similarity to the av-erage vector:argmaxrsim(A(x, r), yd) (4)In the cases, where arguments are not direct de-pendents of the predicate, we use zero as the shiftoffset.To motivate this approach and illustrate its im-plications, consider the two sentences (1) The catchases the dog.
(2) The dog chases the cat.
Inthe first sentence the dog is an object which cor-responds to the theme role A1, whereas in thesecond sentence it is a subject with the agentrole A0.
The role labeling decision is, how-ever, in both cases based on the similarity valuesim(A(chases, r), dog), predicting A1, which isincorrect in the latter case.
When we incorporatethe syntactic information by shifting the vector ac-cording to its syntactic relation to the predicate,we obtain two diverging similarity values becausedog  nsubj and dog  dobj are essentially twodifferent vectors.
This leads to the correct predic-tion in both cases.Relative to the base method, incorporatingthe syntax improves the semantic F-score from61.32% to 66.23% for Finnish and from 65.05%to 66.55% for English.
For Finnish, the gain israther substantial, while for English we see onlya moderate but nevertheless positive effect.
Thisdemonstrates that, indeed, the circular shifting op-eration successfully encodes syntactic informationboth into the average vectors A and the candidateargument vectors y.3.4 Core arguments vs. modifiersIn comparison to modifier roles, the assignmentof core (numbered) argument roles is consider-ably more influenced by the predicate sense andtherefore must be learned separately, which wealso confirmed in initial experiments.
The modi-fier roles, on the other hand, are global in the sensethat they are not tied to any particular predicate.This brings out an interesting question of whetherthe modifier roles should be learned independentlyof the predicate or not.
We find that the best strat-egy is to learn predicate-specific modifier vectorsin English and global modifier vectors in Finnish.Another problem, particularly common in theFinnish PropBank stems from the distinction be-tween core roles and modifier roles.
For instance,for the predicate to move the argument meaningthe destination of the moving action has the corerole A2, while for a number of other predicateswhich may optionally take a destination argument,the directional modifier role AM-DIR would beused.
This leads to a situation where core argu-ments receive a high score for a modifier role, andmodifier roles are over-predicted at the expenseof core argument roles.
To account for this, weintroduce the following simple heuristics.
If thepredicate lacks a core role r after prediction, iter-ate through predicted modifier roles p1.
.
.pnandchange the prediction from pito r if r has the max-imum similarity among the core roles and the dif-ference sim(pi, y) ?
sim(r, y) is smaller than athreshold value optimized on a held-out develop-4ment set distinct from the test set.We observe a 2.05pp gain in Finnish when usingthis method, whereas in English this feature is lesssignificant with an improvement of only 0.3pp.3.5 Fall-back for unknown wordsThe above-mentioned techniques based purely onvector representations with no additional featuresfail if the vector space model lacks the argumenttoken which prevents the calculation of the nec-essary similarities.
To address this problem, webuild separately for each POS a ?generic?
repre-sentation by averaging the vectors of all trainingdata tokens that have the POS and occurred onlyonce.
These vectors, representing a typical rareword of a given POS, are then used in place ofwords missing from the vector space model.Another solution taking advantage from thevector space representation is used in cases wherea predicate is not seen in the training data andtherefore we have no information about its argu-ment structure.
We query for predicates closestto the unseen predicate and take the average argu-ment vectors from the most similar predicate thatwas seen during the training.Together, these two techniques result in a mod-est gain of approximately 1pp for both languages.3.6 Sense classificationOne final step required in SRL is the disambigua-tion of the sense of the predicate.
Here we ap-ply an approach very similar to that used for roleclassification, whereby for every sense of everypredicate, we calculate an average vector repre-senting that sense.
This is done as follows: Forevery predicate sense, we average the vector rep-resentations of all dependents and governors7ofall occurrences of that sense in the training data,circularly shifted to encode their syntactic relationto the predicate.
To assign a sense to a predicateduring testing, we average the shifted vectors cor-responding to its dependents and governors in thesentence, and choose the sense whose average vec-tor is the nearest.
Using this approach, we obtain a84.18% accuracy for Finnish and 92.68% for En-glish, compared to 79.89% and 92.88% withoutthe syntax information.
This corresponds to a sub-stantial gain for Finnish but, surprisingly, a smalldrop for English.
For the rare predicates that are7Recall we use the extended SD scheme where a word canhave several governors in various situations.not seen in the training data, we have no informa-tion about their sense inventory and therefore wesimply predict the sense ?.01?
which is the cor-rect choice in 79.56% of the cases in Finnish and86.64% in English.4 Role Labeling with LinearTransformationsAs we discussed earlier, it was recently shown thatthe word2vec spaces preserve a number of lin-guistic regularities, and an accurate mapping be-tween two word2vec-induced vector spaces canbe achieved using a simple linear transformation.Mikolov et al.
(2013a) have demonstrated that alinear transformation trained on source-target lan-guage word pairs obtained from Google Translatecan surprisingly accurately map word vectors fromone language to another, with obvious applicationsto machine translation.
It is also worth noting thatthis is not universally true of all vector space rep-resentation methods, as Mikolov et al.
have shownfor example for Latent Semantic Analysis, whichexhibits this property to a considerably lesser ex-tent.
In addition to testing the applicability of theword2vec method in general, we are specificallyinterested whether these additional properties canbe exploited in the context of SRL.
In particular,we will test whether a similar linear vector spacetransformation can be used to map the vectors ofthe predicates onto those of their arguments.More formally, for each role r, we will learn atransformation matrix Wrsuch that for a vectorrepresentation x of some predicate, Wrx will beclose to the vector representation of its argumentswith the role r. For instance, if x is the represen-tation of the predicate (to) eat, we aim for WA1xto be a vector similar to the vectors representingedible items (role A1).
The transformation can betrained using the tuples (r, x, y) of predicate x andits argument y with the role r gathered from thetraining data, minimizing the error?(x,y)?Wrx?
y?2(5)over all training pairs (separately for each r).
Weminimize the error using the standard stochasticgradient descent method, whereby the transfor-mation matrix is updated separately for each pair(x, y) using the equationWr?Wr?
(Wrx?
y)xT(6)5where  is the learning rate whose suitable value isselected on the development set.
The whole proce-dure is repeated until convergence is reached, ran-domly shuffling the training data after each roundof training.Using the transformation, we can establish themost likely role for the argument y of a predicatex asargmaxrsim(Wrx, y) (7)where sim is the cosine similarity function, i.e.
inthe exact same manner as for the average argumentmethod described in the previous section, with thedifference that the vector for the average argumentis not calculated directly from the training data,but rather obtained through the linear transforma-tion of the predicate vector.As an alternative approach, we can also learnthe reverse transformation RWrsuch that RWryis close to x, i.e.
the transformation of the argu-ment y onto the predicate x.
Note that hereRWrisnot the same asWTr; we train this reverse transfor-mation separately using the same gradient descentmethod.
We then modify the method for findingthe most likely role for an argument by taking theaverage of the forward and reverse transformationsimilarities:argmaxrsim(Wrx, y) + sim(x,RWry)2(8)Note that we make no assumptions about thevector spaces where x and y are drawn from; theymay be different spaces and they do not need to bematched in their dimensionality either, as there isno requirement that W and RW be square matri-ces.
In practice, we find that the best strategy forboth Finnish and English is to represent both thepredicates and arguments using the space inducedfrom word forms, however, we have also tested onFinnish representing the predicates using the spaceinduced from lemmas and the arguments using aspace induced from word forms, with only mini-mally worse results.
This shows that the transfor-mation does not degrade substantially even whenmapping between two different spaces.With this strategy, we reach an F-score of62.71% in Finnish and 63.01% in English.
Theseresults are on par with the scores obtained withthe average argument method, showing that a lin-ear transformation is effective also in this kind ofproblems.To incorporate syntax information, we traintransformation matrices Wr,dand RWr,dfor eachdependency relation d rather than relying on thecircular shift operation which cannot be capturedby linear transformations.8As some combinationsof r and d may occur only in the test data, we usethe matrices Wrand RWras a fall-back strategy.In testing, we found that even if the (r, d) com-bination is known from the training data, a smallimprovement can be obtained by taking the aver-age of the similarities with and without syntacticinformation as the final similarity.
Incorporatingthese techniques into the basic linear transforma-tion improves the semantic F-score from 62.71%to 65.88% for Finnish and from 63.01% to 67.04%for English.
The improvement for both languagesis substantial.5 Supervised classification approachIn the previous sections, we have studied an ap-proach to SRL based purely on the vector spacerepresentations with no additional features.
Wehave addressed the choice of the argument role bysimply assigning the role with the maximum sim-ilarity to the argument.
To test the gain that couldbe obtained by employing a more advanced tech-nique for aggregating the scores and incorporatingadditional features, we train a linear multi-classsupport vector machine to assign the role to everydetected argument.
As features, we use the simi-larity values for each possible role using the bestperforming method for each language,9the senseof the predicate, and ?
separately for the predi-cate and the argument ?
the token itself, its POS,morphological tags, every dependency relation toits governors, and every dependency relation toits dependents.
The similarities are encoded asfeature weights, while all other features are bi-nary.
We use the multi-class SVM implementa-tion from the SVM-multiclass package (Joachims,1999), setting the regularization parameter on thedevelopment set using a grid search.For both languages, we observe a notable gainin performance, leading to the best scores so far.In Finnish the improvement in F-score is from66.23% to 73.83% and in English from 67.04%to 70.38%.
However, as we will further discuss inSection 6, in Finnish the contribution of the simi-larity features is modest.8Note that this does not affect the overall computationalcost, as the total number of training examples remains un-changed and the transformation matrices are small in size.9Average vectors for Finnish and transformation for En-glish (Table 2).6Finnish EnglishAverage vectorsfull method 66.23 66.55?modifier vs. core role 64.18 66.25?syntax 61.32 65.05Linear transformationfull method 65.88 67.04?syntax 62.71 63.01Supervised classificationfull method 73.83 70.38only similarity features 64.21 65.89?similarity features 73.54 67.51?lexical features 65.51 58.42Table 2: Overview of main results and a featureablation study.
Modifier vs. core role refers to thealgorithm presented in Section 3.4.
In the super-vised classification part, -lexical features refers tothe removal of features based on word forms, pred-icate sense and role similarities.6 Results and discussionAll results discussed throughout Sections 3 to 5are summarized in Table 2, which also serves asa coarse feature ablation study.
Overall, we seethat the average vector and linear transformationmethods perform roughly on par, with the aver-age vector method being slightly better for Finnishand slightly worse for English.
Both vector space-based methods gain notably from syntax informa-tion, confirming that the manner in which this in-formation is incorporated is indeed meaningful.Adding the SVM classifier on top of these twomethods results in a substantial further raise in per-formance, demonstrating that to be competitive onSRL, it is necessary to explicitly model also ad-ditional information besides the semantic similar-ity between the predicate and the argument.
Thisis particularly pronounced for Finnish where thepresent SVM method does not gain substantiallyfrom the similarity-based features, while Englishclearly benefits.
To shed some light on this differ-ence, we show in Table 3 the oracle accuracy ofrole labeling for top-1 through top-10 roles as or-dered by their similarity scores.
The performanceon English is clearly superior to that on Finnish.An important factor may be the fact that ?
interms of token count ?
the CoNLL?09 Englishtraining size is nearly six times that of the FinnishPropBank and the English vector space model wasinduced on a nearly four times larger text corpus.Finnish Englishn Recall n Recall1 58.23 1 67.392 68.29 2 82.823 74.30 3 88.494 78.71 4 91.585 82.21 5 93.206 84.74 6 94.297 87.04 7 94.918 88.98 8 95.319 90.76 9 95.6510 92.05 10 95.86Table 3: A study of how many times (%) the cor-rect role is among the top n most similar roleswhen the arguments are known in advance.
Left:Similarities taken from the average vector methodon Finnish.
Right: Similarities from the lineartransformation method on English.Finnish EnglishAverage vectors 66.23 / 89.89 66.55 / 79.57Linear transf.
65.88 / 89.92 67.04 / 80.85Supervised 73.83 / 89.29 70.38 / 78.71Table 4: Overall results separately for all mainmethods (labeled/unlabeled semantic F-score).Returning to our original question of whetherthe SD scheme can be used as-is for argumentidentification, we show in Table 4 the unlabeledF-scores for the main methods.
These scores re-flect the performance of the argument identifica-tion step in isolation.
While Finnish approaches90% which is comparable to the best systems inthe CoNLL?09 task, English lags behind by over10pp.
To test to what extent the results would beaffected if a more accurate argument identificationsystem was applied, we used the output of the win-ning (for English) CoNLL?09 Shared Task system(Zhao et al., 2009a) as the argument identifica-tion component, while predicting the roles withthe methods introduced so far.
The results aresummarized in Table 5, where we see a substan-tial gain for all the methods presented in this pa-per, achieving an F-score of 82.33%, only 3.82pplower than best CoNLL?09 system.
These resultsgive a mixed signal as to whether the extended SDscheme is usable nearly as-is for argument identi-fication (Finnish) or not (English).
Despite our ef-forts, we were unable to pinpoint the cause for thisdifference, beyond the fact that the Finnish Prop-7Semantic F-scoreCoNLL?09 best 86.15 / 91.97Average vectors 73.12 / 91.97Linear transformation 74.41 / 91.97Supervised classif.
82.33 / 91.97Table 5: Performance of suggested methods withargument identification from the top-performingCoNLL?09 system (labeled/unlabeled F-score).Bank was originally developed specifically on topof the SD scheme, while the English PropBankand NomBank corpora were not.7 Related workWhile different methods have been studied tobuild task specific vector space representations,post-hoc methods to manipulate the vector spaceswithout retraining are rare.
Current SRL systemsutilize supervised machine learning approaches,and typically a large set of features.
For instance,the winning system in the CoNLL?09 shared task(SRL-only) introduces a heavy feature engineer-ing system, which has about 1000 potential fea-ture templates from which the system discoversthe best set to be used (Zhao et al., 2009b).
Wordsimilarities are usually introduced to SRL as apart of unsupervised or semi-supervised meth-ods.
For example, Titov and Klementiev (2012)present an unsupervised clustering method ap-plying word representation techniques, and De-schacht and Moens (2009) used vector similaritiesto automatically expand the small training set tobuild semi-supervised SRL system.
Additionally,Turian et al.
(2010) have shown that word repre-sentations can be included among the features toimprove the performance of named entity recogni-tion and chunking systems.8 ConclusionsWe set out to test two post-hoc vector space ma-nipulation techniques in the context of semanticrole labeling.
We found that the circular shift op-eration can indeed be applied also to other vectorrepresentations as a way to encode syntactic infor-mation.
Importantly, the circular shift is applied toa pre-existing vector space representation, ratherthan during its induction, and is therefore task-independent.
Further, we find that such shiftedvectors can be meaningfully averaged to representpredicate senses and arguments.We also extended the study of the linear trans-formation between two vector spaces and showthat the same technique can be used also withina single space, mapping the vectors of predicatesonto the vectors of their arguments.
This map-ping produces results that are performance-wiseon par with the average vectors method, demon-strating a good generalization ability of the lin-ear mapping and the underlying word2vec vectorspace representation.
Here it is worth noting that?
if we gloss over some obvious issues of am-biguity ?
the mapping between two languagesdemonstrated by Mikolov et al.
is conceptually aone-to-one mapping, at least in contrast to the one-to-many nature of the mapping between predicatesand their arguments.
These results hint at the pos-sibility that a number of problems which can be re-duced to the ?predict a word given a word?
patternmay be addressable with this simple technique.With respect to the application to SRL, we haveshown that it is possible to carry out SRL basedpurely on the vector space manipulation meth-ods introduced in this paper, outperforming sev-eral entries in the CoNLL-09 Shared Task.
How-ever, it is perhaps not too surprising that muchmore is needed to build a competitive SRL sys-tem.
Adding an SVM classifier with few relativelysimple features derived from the syntactic analy-ses in addition to features based on vector similar-ities, and especially adding a well-performing ar-gument identification method, can result in a sys-tem close to approaching state-of-the-art perfor-mance, which is encouraging.As future work, it will be interesting to study towhich extent SRL, and similar applications wouldbenefit from addressing the one-to-many nature ofthe underlying problem.
While for some predi-cates the arguments likely form a cluster that canbe represented as a single average vector, for otherpredicates, such as to see, it is not the case.
Find-ing methods which allow us to model this propertyof the problem will constitute an interesting direc-tion with broader applications beyond SRL.AcknowledgementsThis work has been supported by the Emil Aal-tonen Foundation and Kone Foundation.
Com-putational resources were provided by CSC ?
ITCenter for Science.
We would also like to thankSampo Pyysalo and Hans Moen for comments andgeneral discussion.8ReferencesPierpaolo Basile and Annalina Caputo.
2012.
Encod-ing syntactic dependencies using Random Indexingand Wikipedia as a corpus.
In Proceedings of the3rd Italian Information Retrieval (IIR) Workshop,volume 835, pages 144?154.Bernd Bohnet.
2010.
Very high accuracy and fast de-pendency parsing is not a contradiction.
In Proceed-ings of the 23rd International Conference on Com-putational Linguistics, pages 89?97.
Association forComputational Linguistics.Koen Deschacht and Marie-Francine Moens.
2009.Semi-supervised semantic role labeling using the la-tent words language model.
In Proceedings of the2009 Conference on Empirical Methods in NaturalLanguage Processing: Volume 1-Volume 1, pages21?29.
Association for Computational Linguistics.Jan Haji?c, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Ant`onia Mart?
?, Llu?
?sM`arquez, Adam Meyers, Joakim Nivre, SebastianPad?o, Jan?St?ep?anek, et al.
2009.
The CoNLL-2009shared task: Syntactic and semantic dependenciesin multiple languages.
In Proceedings of the Thir-teenth Conference on Computational Natural Lan-guage Learning: Shared Task, pages 1?18.
Associa-tion for Computational Linguistics.P?eter Hal?acsy, Andr?as Kornai, and Csaba Oravecz.2007.
HunPos: an open source trigram tagger.
InProceedings of the 45th annual meeting of the ACLon interactive poster and demonstration sessions,pages 209?212.
Association for Computational Lin-guistics.Katri Haverinen, Veronika Laippala, Samuel Kohonen,Anna Missil?a, Jenna Nyblom, Stina Ojala, Timo Vil-janen, Tapio Salakoski, and Filip Ginter.
2013a.Towards a dependency-based PropBank of generalFinnish.
In Proceedings of the 19th Nordic Confer-ence on Computational Linguistics (NoDaLiDa?13),pages 41?57.Katri Haverinen, Jenna Nyblom, Timo Viljanen,Veronika Laippala, Samuel Kohonen, Anna Mis-sil?a, Stina Ojala, Tapio Salakoski, and Filip Ginter.2013b.
Building the essential resources for Finnish:the Turku Dependency Treebank.
Language Re-sources and Evaluation, pages 1?39.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In Advances in Kernel Meth-ods - Support Vector Learning, pages 169?184.
MITPress.Krister Lind?en, Miikka Silfverberg, and Tommi Piri-nen.
2009.
HFST tools for morphology ?
an effi-cient open-source package for construction of mor-phological analyzers.
In State of the Art in Com-putational Morphology, volume 41 of Communica-tions in Computer and Information Science, pages28?47.Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
The Stanford typed dependencies rep-resentation.
In Coling 2008: Proceedings of theworkshop on Cross-Framework and Cross-DomainParser Evaluation, pages 1?8.
Coling 2008 Organiz-ing Committee.Adam Meyers, Ruth Reeves, Catherine Macleod,Rachel Szekely, Veronika Zielinska, Brian Young,and Ralph Grishman.
2004.
The NomBank project:An interim report.
In HLT-NAACL 2004 Workshop:Frontiers in Corpus Annotation, pages 24?31.Tomas Mikolov, Quoc V. Le, and Ilya Sutskever.2013a.
Exploiting similarities among languagesfor machine translation.
CoRR (arxiv.org),abs/1309.4168.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-rado, and Jeff Dean.
2013b.
Distributed representa-tions of words and phrases and their compositional-ity.
In Advances in Neural Information ProcessingSystems 26, pages 3111?3119.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.2013c.
Linguistic regularities in continuous spaceword representations.
In Proceedings of the 2013Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 746?751.
Associa-tion for Computational Linguistics, June.Jenna Nyblom, Samuel Kohonen, Katri Haverinen,Tapio Salakoski, and Filip Ginter.
2013.
Pre-dicting conjunct propagation and other extendedStanford Dependencies.
In Proceedings of the In-ternational Conference on Dependency Linguistics(Depling 2013), pages 252?261.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The proposition bank: An annotated cor-pus of semantic roles.
Computational Linguistics,31(1):71?106.Tommi Pirinen.
2008.
Suomen kielen ?a?arellistilainenautomaattinen morfologinen j?asennin avoimenl?ahdekoodin resurssein.
Master?s thesis, Universityof Helsinki.Pontus Stenetorp, Sampo Pyysalo, Goran Topi?c,Tomoko Ohta, Sophia Ananiadou, and Jun?ichi Tsu-jii.
2012.
BRAT: a web-based tool for nlp-assistedtext annotation.
In Proceedings of the Demonstra-tions at the 13th Conference of the European Chap-ter of the Association for Computational Linguistics,pages 102?107.
Association for Computational Lin-guistics.Ivan Titov and Alexandre Klementiev.
2012.
ABayesian approach to unsupervised semantic role in-duction.
In Proceedings of the 13th Conference ofthe European Chapter of the Association for Com-putational Linguistics, pages 12?22.
Association forComputational Linguistics.9Joseph Turian, Lev Ratinov, and Yoshua Bengio.
2010.Word representations: a simple and general methodfor semi-supervised learning.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 384?394.
Association forComputational Linguistics.Hai Zhao, Wenliang Chen, Jun?ichi Kazama, KiyotakaUchimoto, and Kentaro Torisawa.
2009a.
Multilin-gual dependency learning: Exploiting rich featuresfor tagging syntactic and semantic dependencies.In Proceedings of the Thirteenth Conference onComputational Natural Language Learning: SharedTask, pages 61?66.
Association for ComputationalLinguistics.Hai Zhao, Wenliang Chen, Chunyu Kit, and GuodongZhou.
2009b.
Multilingual dependency learning:a huge feature engineering method to semantic de-pendency parsing.
In Proceedings of the ThirteenthConference on Computational Natural LanguageLearning: Shared Task, pages 55?60.
Associationfor Computational Linguistics.10
