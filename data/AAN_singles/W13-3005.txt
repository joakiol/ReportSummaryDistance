Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 41?51,Sofia, Bulgaria, August 9, 2013. c?2013 Association for Computational LinguisticsThe Frobenius Anatomy of Relative PronounsStephen ClarkUniversity of CambridgeComputer Laboratorysc609@cam.ac.ukBob CoeckeUniversity of OxfordDept.
of Computer Sciencecoecke@cs.ox.ac.ukMehrnoosh SadrzadehQueen Mary, University of LondonSchool of ElectronicEngineering and Computer Sciencemehrnoosh.sadrzadeh@eecs.qmul.ac.ukAbstractThis paper develops a compositionalvector-based semantics of relative pro-nouns within a categorical framework.Frobenius algebras are used to formalisethe operations required to model the se-mantics of relative pronouns, includingpassing information between the relativeclause and the modified noun phrase, aswell as copying, combining, and discard-ing parts of the relative clause.
We de-velop two instantiations of the abstract se-mantics, one based on a truth-theoretic ap-proach and one based on corpus statistics.1 IntroductionOrdered algebraic structures and sequent calculihave been used extensively in Computer Scienceand Mathematical Logic.
They have also beenused to formalise and reason about natural lan-guage.
Lambek (1958) used the ordered alge-bra of residuated monoids to model grammaticaltypes, their juxtapositions and reductions.
Rela-tional words such as verbs have implicative typesand are modelled using the residuals to the monoidmultiplication.
Later, Lambek (1999) simplifiedthese algebras in favour of pregroups.
Here, thereare no binary residual operations, but each elementof the algebra has a left and a right residual.In terms of semantics, pregroups do not natu-rally lend themselves to a model-theoretic treat-ment (Montague, 1974).
However, pregroups aresuited to a radically different treatment of seman-tics, namely distributional semantics (Schu?tze,1998).
Distributional semantics uses vector spacesbased on contextual co-occurrences to model themeanings of words.
Coecke et al(2010) showhow a compositional semantics can be developedwithin a vector-based framework, by exploitingthe fact that vector spaces with linear maps andpregroups both have a compact closed categor-ical structure (Kelly and Laplaza, 1980; Prellerand Lambek, 2007).
Some initial attempts at im-plementation include Grefenstette and Sadrzadeh(2011a) and Grefenstette and Sadrzadeh (2011b).One problem with the distributional approach isthat it is difficult to see how the meanings of somewords ?
e.g.
logical words such as and, or, andrelative pronouns such as who, which, that, whose?
can be modelled contextually.
Our focus in thispaper is on relative pronouns in the distributionalcompositional setting.The difficulty with pronouns is that the contextsin which they occur do not seem to provide a suit-able representation of their meanings: pronounstend to occur with a great many nouns and verbs.Hence, if one applies the contextual co-occurrencemethods of distributional semantics to them, theresult will be a set of dense vectors which donot discriminate between different meanings.
Thecurrent state-of-the-art in compositional distribu-tional semantics either adopts a simple method toobtain a vector for a sequence of words, such asadding or mutliplying the contextual vectors ofthe words (Mitchell and Lapata, 2008), or, basedon the grammatical structure, builds linear mapsfor some words and applies these to the vectorrepresentations of the other words in the string(Baroni and Zamparelli, 2010; Grefenstette andSadrzadeh, 2011a).
Neither of these approachesproduce vectors which provide a good representa-tion for the meanings of relative clauses.In the grammar-based approach, one has to as-sign a linear map to the relative pronoun, for in-stance a map f as follows:?????????????
?men who like Mary = f(???men,??????
?like Mary)However, it is not clear what this map should be.Ideally, we do not want it to depend on the fre-quency of the co-occurrence of the relative pro-noun with the relevant basis vectors.
But both41of the above mentioned approaches rely heavilyon the information provided by a corpus to buildtheir linear maps.
The work of Baroni and Zam-parelli (2010) uses linear regression and approxi-mates the context vectors of phrases in which thetarget word has occurred, and the work of Grefen-stette and Sadrzadeh (2011a) uses the sum of Kro-necker products of the arguments of the targetword across the corpus.The semantics we develop for relative pronounsand clauses uses the general operations of a Frobe-nius algebra over vector spaces (Coecke et al2008) and the structural categorical morphisms ofvector spaces.
We do not rely on the co-occurrencefrequencies of the pronouns in a corpus and onlytake into account the structural roles of the pro-nouns in the meaning of the clauses.
The computa-tions of the algebra and vector spaces are depictedusing string diagrams (Joyal and Street, 1991),which depict the interactions that occur among thewords of a sentence.
In the particular case of rel-ative clauses, they visualise the role of the rela-tive pronoun in passing information between theclause and the modified noun phrase, as well ascopying, combining, and even discarding parts ofthe relative clause.We develop two instantiations of the abstract se-mantics, one based on a truth-theoretic approach,and one based on corpus statistics, where for thelatter the categorical operations are instantiated asmatrix multiplication and vector component-wisemultiplication.
As a result, we will obtain the fol-lowing for the meaning of a subject relative clause:?????????????
?men who like Mary = ??
?men (love????
?Mary)The rest of the paper introduces the categoricalframework, including the formal definitions rel-evant to the use of Frobenius algebras, and thenshows how these structures can be used to modelrelative pronouns within the compositional vector-based setting.2 Compact Closed Categories andFrobenius AlgebrasThis section briefly reviews compact closed cate-gories and Frobenius algebras.
For a formal pre-sentation, see (Kelly and Laplaza, 1980; Kock,2003; Baez and Dolan, 1995), and for an informalintroduction see Coecke and Paquette (2008).A compact closed category has objects A,B;morphisms f : A ?
B; a monoidal tensor A?
Bthat has a unit I; and for each objectA two objectsAr andAl together with the following morphisms:A?ArrA??
I?rA??
Ar ?AAl ?AlA??
I?lA??
A?AlThese morphisms satisfy the following equalities,sometimes referred to as the yanking equalities,where 1A is the identity morphism on object A:(1A ?
lA) ?
(?lA ?
1A) = 1A(rA ?
1A) ?
(1A ?
?rA) = 1A(lA ?
1A) ?
(1Al ?
?lA) = 1Al(1Ar ?
rA) ?
(?rA ?
1Ar) = 1ArA pregroup is a partial order compact closedcategory, which we refer to as Preg.
This meansthat the objects of Preg are elements of a par-tially ordered monoid, and between any two ob-jects p, q ?
Preg there exists a morphism of typep ?
q iff p ?
q. Compositions of morphismsare obtained by transitivity and the identities byreflexivity of the partial order.
The tensor of thecategory is the monoid multiplication, and the ep-silon and eta maps are as follows:rp = p ?
pr ?
1 ?rp = 1 ?
pr ?
plp = pl ?
p ?
1 ?lp = 1 ?
p ?
plFinite dimensional vector spaces and linearmaps also form a compact closed category, whichwe refer to as FVect.
Finite dimensional vectorspaces V,W are objects of this category; linearmaps f : V ?
W are its morphisms with compo-sition being the composition of linear maps.
Thetensor product V ?W is the linear algebraic ten-sor product, whose unit is the scalar field of vec-tor spaces; in our case this is the field of reals R.As opposed to the tensor product in Preg, the ten-sor between vector spaces is symmetric; hence wehave a naturual isomorphism V ?W ?= W ?
V .As a result of the symmetry of the tensor, the twoadjoints reduce to one and we obtain the followingisomorphism:V l ?= V r ?= V ?where V ?
is the dual of V .
When the basis vectorsof the vector spaces are fixed, it is further the casethat the following isomorphism holds as well:V ?
?= V42Elements of vector spaces, i.e.
vectors, are rep-resented by morphisms from the unit of tensor totheir corresponding vector space; that is?
?v ?
V isrepresented by the morphism R??v??
V ; by linear-ity this morphism is uniquely defined when setting1 7?
?
?v .Given a basis {ri}i for a vector space V , the ep-silon maps are given by the inner product extendedby linearity; i.e.
we have:l = r : V ?
?
V ?
Rgiven by:?ijcij ?i ?
?j 7??ijcij?
?i | ?j?Similarly, eta maps are defined as follows:?l = ?r : R?
V ?
V ?and are given by:1 7?
?iri ?
riA Frobenius algebra in a monoidal category(C,?, I) is a tuple (X,?, ?, ?, ?)
where, for Xan object of C, the triple (X,?, ?)
is an internalcomonoid; i.e.
the following are coassociative andcounital morphisms of C:?
: X ?
X ?X ?
: X ?
IMoreover (X,?, ?)
is an internal monoid; i.e.
thefollowing are associative and unital morphisms:?
: X ?X ?
X ?
: I ?
XAnd finally the ?
and ?morphisms satisfy the fol-lowing Frobenius condition:(??
1X) ?
(1X ??)
= ?
?
?
= (1X ?
?)
?
(??
1X)Informally, the comultiplication ?
decomposesthe information contained in one object into twoobjects, and the multiplication ?
combines the in-formation of two objects into one.Frobenius algebras were originally introducedin the context of representation theorems for grouptheory (Frobenius, 1903).
Since then, they havefound applications in other fields of mathematicsand physics, e.g.
in topological quantum field the-ory (Kock, 2003).
The above general categoricaldefinition is due to Carboni and Walters (1987).
Inwhat follows, we use Frobenius algebras that char-acterise vector space bases (Coecke et al 2008).In the category of finite dimensional vectorspaces and linear maps FVect, any vector space Vwith a fixed basis {?
?vi}i has a Frobenius algebraover it, explicitly given by:?
:: ?
?vi 7??
?vi ??
?vi ?
::?
?vi 7?
1?
:: ?
?vi ??
?vj 7?
?ij?
?vi ?
:: 1 7??i?
?viwhere ?ij is the Kronecker delta.Frobenius algebras over vector spaces with or-thonormal bases are moreover isometric and com-mutative.
A commutative Frobenius Algebra satis-fies the following two conditions for ?
: X?Y ?Y ?X , the symmetry morphism of (C,?, I):?
??
= ?
?
?
?
= ?An isometric Frobenius Algebra is one that satis-fies the following axiom:?
??
= 1The vector spaces of distributional models havefixed orthonormal bases; hence they have isomet-ric commutative Frobenius algebras over them.The comultiplication ?
of an isometric com-mutative Frobenius Algebra over a vector spaceencodes vectors of lower dimensions into vectorsof higher dimensional tensor spaces; this oper-ation is referred to as copying.
In linear alge-braic terms, ?(?
?v ) ?
V ?
V is a diagonal matrixwhose diagonal elements are weights of ?
?v ?
V .The corresponding multiplication ?
encodes vec-tors of higher dimensional tensor spaces into lowerdimensional spaces; this operation is referred toas combining.
For ?
?w ?
V ?
V , we have that?(?
?w ) ?
V is a vector consisting only of the diag-onal elements of ?
?w .As a concrete example, take V to be a two di-mensional space with basis {?
?v1 ,?
?v2}; then the ba-sis of V ?V is {??v1??
?v1 ,??v1??
?v2 ,??v2??
?v1 ,??v2??
?v2}.For a vector v = a?
?v1 + b?
?n2 in V we have:?
(v) = ?
(ab)=(a 00 b)= a??v1???v1+b??v2??
?v2And for a matrix w = a?
?v1 ??
?v1 + b?
?v1 ??
?v2 +c?
?v2 ??
?v1 + d?
?v2 ??
?v2 in V ?
V , we have:?
(w) = ?
(a bc d)=(ad)= a?
?v1 + d?
?v2433 String DiagramsThe framework of compact closed categories andFrobenius algebras comes with a complete di-agrammatic calculus that visualises derivations,and which also simplifies the categorical and vec-tor space computations.
Morphisms are depictedby boxes and objects by lines, representing theiridentity morphisms.
For instance a morphismf : A ?
B, and an object A with the identity ar-row 1A : A?
A, are depicted as follows:fABAThe tensor products of the objects and mor-phisms are depicted by juxtaposing their diagramsside by side, whereas compositions of morphismsare depicted by putting one on top of the other;for instance the object A?B, and the morphismsf ?
g and f ?
h, for f : A ?
B, g : C ?
D, andh : B ?
C, are depicted as follows:fAB DgC fABhCA BThe  maps are depicted by cups, ?
mapsby caps, and yanking by their composition andstraightening of the strings.
For instance, the di-agrams for l : Al ?
A ?
I , ?
: I ?
A ?
Al and(l ?
1A) ?
(1A ?
?l) = 1A are as follows:AlA AlAAl A Al = AThe composition of the  and ?
maps with othermorphisms is depicted as before, that is by juxta-posing them one above the other.
For instance thediagrams for the compositions (1Bl ?
f) ?
l and?l ?
(1Al ?
f) are as follows:BfABlAl AfBAs for Frobenius algebras, the diagrams for themonoid and comonoid morphisms are as follows:(?, ?)
(?, ?
)with the Frobenius condition being depicted as:= =The defining axioms guarantee that any picture de-picting a Frobenius computation can be reduced toa normal form that only depends on the number ofinput and output strings of the nodes, independentof the topology.
These normal forms can be sim-plified to so-called ?spiders?:=?
?
??
?
??????
?In the category FVect, apart from spaces V,W ,which are objects of the category, we also havevectors ?
?v ,?
?w .
These are depicted by their repre-senting morphisms and as triangles with a numberof strings emanating from them.
The number ofstrings of a triangle denote the tensor rank of thevector; for instance, the diagrams for?
?v ?
V,??v?
?V ?W , and??v??
?
V ?W ?
Z are as follows:V W WV ZVApplication of a linear map to a vector is de-picted using composition of their correspondingmorphisms.
For instance, for f : V ?
W and?
?v ?
V , the application f(?
?v ) is depicted by thecomposition I??v??
Vf?
?W .VfW44Applications of the Frobenius maps to vectorsare depicted in a similar fashion; for instance?(?
?v ?
?
?v ) is the composition I ?
I?
?v ???v??
V ?V???
V and ?(?
?v ) is the composition I??v??V???
I , depicted as follows:V VVV4 Vector Space InterpretationsThe grammatical structure of a language is en-coded in the category Preg: objects are grammat-ical types (assigned to words of the language) andmorphisms are grammatical reductions (encodingthe grammatical formation rules of the language).For instance, the grammatical structure of the sen-tence ?Men love Mary?
is encoded in the assign-ment of types n to the noun phrases ?men?
and?Mary?
and nr ?
s?
nl to the verb ?love?, and inthe reduction map ln ?
1s ?
rn.
The applicationof this reduction map to the tensor product of theword types in the sentence results in the type s:(ln ?
1s ?
rn)(n?
(nr ?
s?
nl)?
n)?
sTo each reduction map corresponds a string dia-gram that depicts the structure of reduction:n nrsnl nMen love MaryIn Coecke et al(2010) the pregroup types andreductions are interpreted as vector spaces and lin-ear maps, achieved via a homomorphic mappingfrom Preg to FVect.
Categorically speaking, thismap is a strongly monoidal functor:F : Preg?
FVectIt assigns vector spaces to the basic types as fol-lows:F (1) = I F (n) = N F (s) = Sand to the compound types by monoidality as fol-lows; for x, y objects of Preg:F (x?
y) = F (x)?
F (y)Monoidal functors preserve the compact structure;that is the following holds:F (xl) = F (xr) = F (x)?For instance, the interpretation of a transitive verbis computed as follows:F (nr ?
s?
nl) = F (nr)?
F (s)?
F (nl) =F (n)?
?
F (s)?
F (n)?
= N ?
S ?NThis interpretation means that the meaning vectorof a transitive verb is a vector in N ?
S ?N .The pregroup reductions, i.e.
the partial ordermorphisms of Preg, are interpreted as linear maps:whenever p ?
q in Preg, we have a linear mapf?
: F (p) ?
F (q).
The  and ?
maps of Preg areinterpreted as the  and ?
maps of FVect.
For in-stance, the pregroup reduction of a transitive verbsentence is computed as follows:F (rn ?
1s ?
rn) = F (rn)?
F (1s)?
F (ln) =F (n)?
?
F (1s)?
F (n)?
= N ?
1S ?
NThe distributional meaning of a sentence is ob-tained by applying the interpretation of the pre-group reduction of the sentence to the tensor prod-uct of the distributional meanings of the wordsin the sentence.
For instance, the distributionalmeaning of ?Men love Mary?
is as follows:F (rn ?
1s ?
ln)(???Men????love????
?Mary)This meaning is depictable via the following stringdiagram:N NSN NMen love MaryThe next section applies these techniques to thedistributional interpretation of pronouns.
The in-terpretations are defined using:  maps, for appli-cation of the semantics of one word to another; ?maps, to pass information around by bridging in-termediate words; and Frobenius operations, forcopying and combining the noun vectors and dis-carding the sentence vectors.5 Modelling Relative PronounsIn this paper we focus on the subject and objectrelative pronouns, who(m), which and that.
Ex-amples of noun phrases with subject relative pro-nouns are ?men who love Mary?, ?dog which atecats?.
Examples of noun phrases with object rela-tive pronouns are ?men whom Mary loves?, ?book45that John read?.
In the final example, ?book?
is thehead noun, modified by the relative clause ?thatJohn read?.
The intuition behind the use of Frobe-nius algebras to model such cases is the following.In ?book that John read?, the relative clause actson the noun (modifies it) via the relative pronoun,which passes information from the clause to thenoun.
The relative clause is then discarded, andthe modified noun is returned.
Frobenius algebrasprovide the machinery for all of these operations.The pregroup types of the relative pronouns areas follows:nrnsln (subject)nrnnllsl (object)These types result in the following reductions:nr s nl nn nr n sl nSubject Rel-Pr Verb Objectnr s nlnn nr n nll slObject Rel-Pr Subject VerbThe meaning spaces of these pronouns are com-puted using the mechanism described above:F (nrnsln) = F (nr)?
F (n)?
F (sl)?
F (n)= N ?N ?
S ?NF (nrnnllsl) = F (nr)?
F (n)?
F (nll)?
F (sl)= N ?N ?N ?
SThe semantic roles that these pronouns play arereflected in their categorical vector space mean-ings, depicted as follows:Subj:N N S NObj:N N SNwith the following corresponding morphisms:Subj: (1N ?
?N ?
?S ?
1N ) ?
(?N ?
?N )Obj: (1N ?
?N ?
1N ?
?S) ?
(?N ?
?N )The diagram of the meaning vector of the sub-ject relative clause interacting with the head nounis as follows:N S N NN N NN SSubject Rel-Pronoun Verb ObjectThe diagram for the object relative clause is:N S NNN N NN SObject Rel-Pronoun Subject VerbThese diagrams depict the flow of information ina relative clause and the semantic role of its rel-ative pronoun, which 1) passes information fromthe clause to the head noun via the ?
maps; 2) actson the noun via the ?
map; 3) discards the clausevia the ?
map; and 4) returns the modified nounvia 1N .
The  maps pass the information of thesubject and object nouns to the verb and to the rel-ative pronoun to be acted on.
Note that there aretwo different flows of information in these clauses:the ones that come from the grammatical structureand are depicted by maps (at the bottom of the di-agrams), and the ones that come from the semanticrole of the pronoun and are depicted by ?
maps (atthe top of the diagrams).The normal forms of these diagrams are:N S N NNSubject Verb ObjectN S N NNSubject Verb ObjectSymbolically, they correspond to the followingmorphisms:(?N ?
?S ?
N )(?????Subject????Verb????
?Object)(N ?
?S ?
?N )(?????Subject????Verb????
?Object)The simplified normal forms will become useful inpractice when calculating vectors for such cases.6 Vector Space InstantiationsIn this section we demonstrate the effect of theFrobenius operations using two example instan-tiations.
The first ?
which is designed perhaps46as a theoretical example rather than a suggestionfor implementation ?
is a truth-theoretic account,similar to Coecke et al(2010) but also allow-ing for degrees of truth.
The second is based onthe concrete implementation of Grefenstette andSadrzadeh (2011a).6.1 Degrees of TruthTake N to be the vector space spanned by a setof individuals {?
?n i}i that are mutually orthogo-nal.
For example, ?
?n 1 represents the individualMary, ?
?n 25 represents Roger the dog,?
?n 10 rep-resents John, and so on.
A sum of basis vec-tors in this space represents a common noun; e.g.??
?man =?i?
?n i, where i ranges over the basis vec-tors denoting men.
We take S to be the one dimen-sional space spanned by the single vector?
?1 .
Theunit vector spanning S represents truth value 1, thezero vector represents truth value 0, and the inter-mediate vectors represent degrees of truth.A transitive verb w, which is a vector in thespace N ?
S ?N , is represented as follows:w :=?ij?
?n i ?
(?ij?
?1 )??
?n jif ?
?n i w?s?
?n j with degree ?ij , for all i, j.Further, since S is one-dimensional with itsonly basis vector being?
?1 , the transitive verb canbe represented by the following element ofN?N :?ij?ij?
?n i??
?n j if?
?n i w?s?
?n j with degree ?ijRestricting to either ?ij = 1 or ?ij = 0 providesa 0/1 meaning, i.e.
either ?
?n i w?s?
?n j or not.Letting ?ij range over the interval [0, 1] enablesus to represent degrees as well as limiting casesof truth and falsity.
For example, the verb ?love?,denoted by love, is represented by:?ij?ij?
?n i??
?n j if?
?n i loves?
?n jwith degree?ijIf we take ?ij to be 1 or 0, from the above weobtain the following:?(i,j)?Rlove?
?n i ??
?n jwhere Rlove is the set of all pairs (i, j) such that?
?n i loves?
?n j .Note that, with this definition, the sentencespace has already been discarded, and so for this?????????????????
?Subject who Verb Object :=(?N ?
N )(?????Subject????Verb????
?Object)=(?N ?
N )???k?K?
?n k ?(?ij?ij?
?n i??
?n j)??l?L?
?n l?
?=?ij,k?K,l?L?ij?N (?
?n k ??
?n i)?
N (?
?n j ??
?n l)=?ij,k?K,l?L?ij?ki?
?n i?jl=?k?K,l?L?kl?
?n kFigure 1: Meaning computation with a subject rel-ative pronouninstantiation the ?
map, which is the part of therelative pronoun interpretation designed to discardthe relative clause after it has acted on the headnoun, is not required.For common nouns????
?Subject =?k?K?
?n k and???
?Object =?l?L?
?n l, where k and l range overthe sets of basis vectors representing the respec-tive common nouns, the truth-theoretic meaning ofa noun phrase modified by a subject relative clauseis computed as in Figure 1.
The result is highly in-tuitive, namely the sum of the subject individualsweighted by the degree with which they have actedon the object individuals via the verb.
A similarcomputation, with the difference that the ?
and maps are swapped, provides the truth-theoretic se-mantics of the object relative clause:?k?K,l?L?kl?
?n lThe calculation and final outcome is best under-stood with an example.Now only consider truth values 0 and 1.
Con-sider the noun phrase with object relative clause?men whom Mary loves?
and takeN to be the vec-tor space spanned by the set of all people; then themales form a subspace of this space, where the ba-sis vectors of this subspace, i.e.
men, are denotedby ?
?ml, where l ranges over the set of men whichwe denote byM .
We set ?Mary?
to be the individ-ual?
?f 1, ?men?
to be the common noun?l?M??ml,47???????????????
?men whom Mary loves :=(N ?
?N )???
?f 1 ?
(?(i,j)?Rlove?
?f i ???mj)??l?M??ml?
?=?l?M,(i,j)?RloveN (?
?f 1 ??
?f i)?
?(?
?mj ???ml)=?l?M,(i,j)?Rlove?1i?jl??mj=?(1,j)?Rlove|j?M?
?mjFigure 2: Meaning computation for example ob-ject relative clauseand ?love?
to be as follows:?(i,j)?Rlove?
?f i ??
?mjThe vector corresponding to the meaning of ?menwhom Mary loves?
is computed as in Figure 2.The result is the sum of the men basis vectorswhich are also loved by Mary.The second example involves degrees of truth.Suppose we have two females Mary?
?f 1 and Jane?
?f 2 and four men??m1,??m2,??m3,??m4.
Mary loves?
?m1 with degree 1/4 and?
?m2 with degree 1/2; Janeloves ?
?m3 with degree 1/5; and?
?m4 is not loved.
Inthis situation, we have:Rlove = {(1, 1), (1, 2), (2, 3)}and the verb love is represented by:1/4(?
?f 1???m1)+1/2(?
?f 1???m2)+1/5(?
?f 2??
?m3)The meaning of ?men whom Mary loves?
is com-puted by substituting an ?1,j in the last line of Fig-ure 2, resulting in the men whom Mary loves to-gether with the degrees that she loves them:?(1,j)?Rlove|j?M?1j?
?mj = 1/4?
?m1 + 1/2?
?m2?men whom women love?
is computed as fol-lows, where W is the set of women:?k?W,l?M,(i,j)?Rlove?ijN (?
?f k ??
?f i)?
?(?
?mj ???ml)=?k?W,l?M,(i,j)?Rlove?ij?ki?jl??mj=?(i,j)?Rlove|i?W,j?M?ij?
?mj= 1/4?
?m1 + 1/2?
?m2 + 1/5?
?m3The result is the men loved by Mary or Jane to-gether with the degrees to which they are loved.6.2 A Concrete InstantiationIn the model of Grefenstette and Sadrzadeh(2011a), the meaning of a verb is taken to be ?thedegree to which the verb relates properties of itssubjects to properties of its object?.
Clark (2013)provides some examples showing how this is anintuitive defintion for a transitive verb in the cat-egorical framework.
This degree is computed byforming the sum of the tensor products of the sub-jects and objects of the verb across a corpus, wherew ranges over instances of the verb:verb =?w(??sbj??
?obj)wDenote the vector space of nouns by N ; the aboveis a matrix in N ?
N , depicted by a two-leggedtriangle as follows:N NThe verbs of this model do not have a sentencedimension; hence no information needs to be dis-carded when they are used in our setting, and so no?map appears in the diagram of the relative clause.Inserting the above diagram in the diagrams of thenormal forms results in the following for the sub-ject relative clause (the object case is similar):N N NNSubject Verb ObjectThe abstract vectors corresponding to such dia-grams are similar to the truth-theoretic case, withthe difference that the vectors are populated fromcorpora and the scalar weights for noun vectors48are not necessarily 1 or 0.
For subject and objectnoun context vectors computed from a corpus asfollows:????
?Subject =?kCk?
?n k???
?Object =?lCl?
?n land the verb a linear map:Verb =?ijCij?
?n i ??
?n jcomputed as above, the concrete meaning of anoun phrase modified by a subject relative clauseis as follows:?kijlCkCijCl?N (?
?n k ??
?n i)N (?
?n j ??
?n l)=?kijlCkCijCl?ki?
?n k?jl=?klCkCklCl?
?n kComparing this to the truth-theoretic case, we seethat the previous ?kl are now obtained from a cor-pus and instantiated to CkCklCl.
To see how theabove expression represents the meaning of thenoun phrase, decompose it into the following:?kCk?
?n k?klCklCl?
?n lNote that the second term of the above, which isthe application of the verb to the object, modifiesthe subject via point-wise multiplication.
A simi-lar result arises for the object relative clause case.As an example, suppose that N has two dimen-sions with basis vectors ?
?n 1 and?
?n 2, and considerthe noun phrase ?dog that bites men?.
Define thevectors of ?dog?
and ?men?
as follows:?
?dog = d1?
?n 1+d2?
?n 2??
?men = m1?
?n 1+m2?
?n 2and the matrix of ?bites?
by:b11?
?n 1??
?n 2+b12?
?n 1??
?n 2+b21?
?n 2??
?n 1+b22?
?n 2??
?n 2Then the meaning of the noun phrase becomes:????????????
?dog that bites men :=d1b11m1?
?n 1 + d1b12m2?
?n 1 + d2b21m1?
?n 2+ d2b22m2?
?n 2 = (d1?
?n 1 + d2?
?n 2)((b11m1 + b12m2)?
?n 1 + (b21m1 + b22m2)?
?n 2)Using matrix notation, we can decompose the sec-ond term further, from which the application of theverb to the object becomes apparent:(b11 b12b21 b22)?
(m1m2)Hence for the whole clause we obtain:?
?dog (bites???
?men)Again this result is highly intuitive: assumingthat the basis vectors of the noun space representproperties of nouns, the meaning of ?dog that bitesmen?
is a vector representing the properties ofdogs, which have been modified (via multiplica-tion) by those properties of individuals which bitemen.
Put another way, those properties of dogswhich overlap with properties of biting things getaccentuated.7 Conclusion and Future DirectionsIn this paper, we have extended the compact cate-gorical semantics of Coecke et al(2010) to anal-yse meanings of relative clauses in English froma vector space point of view.
The resulting vec-tor space semantics of the pronouns and clausesis based on the Frobenius algebraic operations onvector spaces: they reveal the internal structure, orwhat we call anatomy, of the relative clauses.The methodology pursued in this paper and theFrobenius operations can be used to provide se-mantics for other relative pronouns and also otherclosed-class words such as prepositions and deter-miners.
In each case, the grammatical type of theword and a detailed analysis of the role of thesewords in the meaning of the phrases in which theyoccur would be needed.
In some cases, it may benecessary to introduce a linear map to representthe meaning of the word, for instance to distin-guish the preposition on from in.The contribution of this paper is best demon-strated via the string diagrammatic representationsof the vector space meanings of these clauses.
Anoun phrase modified by a subject relative clause,which before this paper was depicted as follows:N S N NN N NN SSubject Rel-Pronoun Verb Objectwill now include the internal anatomy of its rela-tive pronoun:49N S N NN N NN SSubject Rel-Pronoun Verb ObjectThis internal structure shows how the informationfrom the noun flows through the relative pronounto the rest of the clause and how it interacts withthe other words.
We have instantiated this vectorspace semantics using truth-theoretic and corpus-based examples.One aspect of our example spaces which meansthat they work particularly well is that the sen-tence dimension in the verb is already discarded,which means that the ?
maps are not required (asdiscussed above).
Another feature is that the sim-ple nature of the models means that the ?map doesnot lose any information, even though it takes thediagonal of a matrix and hence in general throwsinformation away.
The effect of the ?
and ?
mapsin more complex representations of the verb re-mains to be studied in future work.On the practical side, what we offer in this paperis a method for building appropriate vector repre-sentations for relative clauses.
As a result, whenpresented with a relative clause, we are able tobuild a vector for it, only by relying on the vectorrepresentations of the words in the clause and thegrammatical role of the relative pronoun.
We donot need to retrieve information from a corpus tobe able to build a vector or linear map for the rela-tive pronoun, neither will we end up having to dis-card the pronoun and ignore the role that it plays inthe meaning of the clause (which was perhaps thebest option available before this paper).
However,the Frobenius approach and our claim that the re-sulting vectors are ?appropriate?
requires an empir-ical evaluation.
Tasks such as the term definitiontask from Kartsaklis et al(2013) (which also usesFrobenius algebras but for a different purpose) arean obvious place to start.
More generally, the sub-field of compositional distributional semantics isa growing and active one (Mitchell and Lapata,2008; Baroni and Zamparelli, 2010; Zanzotto etal., 2010; Socher et al 2011), for which we arguethat high-level mathematical investigations suchas this paper, and also Clarke (2008), can play acrucial role.AcknowledgementsWe would like to thank Dimitri Kartsaklis andLaura Rimell for helpful comments.
StephenClark was supported by ERC Starting Grant Dis-CoTex (30692).
Bob Coecke and Stephen Clarkare supported by EPSRC Grant EP/I037512/1.Mehrnoosh Sadrzadeh is supported by an EPSRCCAF EP/J002607/1.ReferencesJ.C.
Baez and J. Dolan.
1995.
Higher-dimensional al-gebra and topological quantum field theory.
Journalof Mathematical Physics, 36:6073?6105.M.
Baroni and R. Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Representingadjective-noun constructions in semantic space.
InConference on Empirical Methods in Natural Lan-guage Processing (EMNLP-10), Cambridge, MA.A.
Carboni and R. F. C. Walters.
1987.
Cartesian bicat-egories.
I. J.
Pure and Appied Algebra, 49:11?32.S.
Clark.
2013.
Type-driven syntax and seman-tics for composing meaning vectors.
In Chris He-unen, Mehrnoosh Sadrzadeh, and Edward Grefen-stette, editors, Quantum Physics and Linguistics:A Compositional, Diagrammatic Discourse, pages359?377.
Oxford University Press.D.
Clarke.
2008.
Context-theoretic Semantics for Nat-ural Language: An Algebraic Framework.
Ph.D.thesis, University of Sussex.B.
Coecke and E. Paquette.
2008.
Introducing cat-egories to the practicing physicist.
In B. Coecke,editor, New Structures for Physics, volume 813 ofLecture Notes in Physics, pages 167?271.
Springer.B.
Coecke, D. Pavlovic, and J. Vicary.
2008.
Anew description of orthogonal bases.
MathematicalStructures in Computer Science, 1:269?272.B.
Coecke, M. Sadrzadeh, and S. Clark.
2010.Mathematical foundations for a compositional dis-tributional model of meaning.
Linguistic Analysis,36:345?384.F.
G. Frobenius.
1903.
Theorie der hyperkomplexenGro??en.
Preussische Akademie der WissenschaftenBerlin: Sitzungsberichte der Preu?ischen Akademieder Wissenschaften zu Berlin.
Reichsdr.E.
Grefenstette and M. Sadrzadeh.
2011a.
Experimen-tal support for a categorical compositional distribu-tional model of meaning.
In Proceedings of Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 1394?1404.E.
Grefenstette and M. Sadrzadeh.
2011b.
Experi-menting with transitive verbs in a discocat.
In Pro-ceedings of the Workshop on Geometrical Models ofNatural Language Semantics (GEMS).50A.
Joyal and R. Street.
1991.
The Geometry of TensorCalculus, I.
Advances in Mathematics, 88:55?112.D.
Kartsaklis, M. Sadrzadeh, S. Pulman, and B. Co-ecke.
2013.
Reasoning about meaning in nat-ural language with compact closed categories andfrobenius algebras.
In J. Chubb, A. Eskandar-ian, and V. Harizanov, editors, Logic and AlgebraicStructures in Quantum Computing and Information,Association for Symbolic Logic Lecture Notes inLogic.
Cambridge University Press.G.
M. Kelly and M. L. Laplaza.
1980.
Coherence forcompact closed categories.
Journal of Pure and Ap-plied Algebra, 19:193?213.J.
Kock.
2003.
Frobenius algebras and 2D topologicalquantum field theories, volume 59 of London Mathe-matical Society student texts.
Cambridge UniversityPress.J.
Lambek.
1958.
The Mathematics of Sentence Struc-ture.
American Mathematics Monthly, 65:154?170.J.
Lambek.
1999.
Type Grammar Revisited LogicalAspects of Computational Linguistics.
In LogicalAspects of Computational Linguistics, volume 1582of Lecture Notes in Computer Science, pages 1?27.Springer Berlin / Heidelberg.J.
Mitchell and M. Lapata.
2008.
Vector-based modelsof semantic composition.
In Proceedings of ACL-08, pages 236?244, Columbus, OH.R.
Montague.
1974.
English as a formal language.In R. H. Thomason, editor, Formal philosophy: Se-lected Papers of Richard Montague, pages 189?223.Yale University Press.A.
Preller and J. Lambek.
2007.
Free compact 2-categories.
Mathematical Structures in ComputerScience, 17:309?340.H.
Schu?tze.
1998.
Automatic word sense discrimina-tion.
Computational Linguistics, 24:97?123.R.
Socher, J. Pennington, E. Huang, A. Y. Ng, andC.
D. Manning.
2011.
Semi-supervised recur-sive autoencoders for predicting sentiment distribu-tions.
In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, Edin-burgh, UK.F.
M. Zanzotto, I. Korkontzelos, F. Fallucchi, andS.
Manandhar.
2010.
Estimating linear models forcompositional distributional semantics.
In Proceed-ings of COLING, Beijing, China.51
