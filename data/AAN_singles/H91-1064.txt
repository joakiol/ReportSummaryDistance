DISCOURSE STRUCTURE IN THE TRAINS PROJECTJames F. AllenDepartment of Computer ScienceUniversity of RochesterRochester, NY 14627ABSTRACTIn a natural dialog, a considerable proportion of theutterances actually relate to the maintenance of the dialogitself rather than to furthering the task or goals motivatingthe conversation.
For example, many utterances serve toacknowledge, clarify, correct a previous utterance ratherthan pursue some goal in the domain.
In addition, naturaldialog is full of false starts, ungrammatical sentences andother complexities not found in in written language.
Thispaper describes our recent efforts to define and construct amodel of discourse interaction that handle dialogs that arerich in these natural dialog-related phenomena.INTRODUCTIONThe TRAINS project involves building an intelligentplanning assistant hat is eonversationally-proficit innatural language.
The name of the project comes from thedomain used to test and demonstrate he ideas: the systemacts as an intelligent assistant to a person attempting tosolve transportation problems involving freight trainsand factories in a simulated world.
The system assists informulating plans, and monitors these plans as they areexecuted by the simulated agents in a simulated TRAINSworld, providing updates and support o the human inreplanning as necessary.
The human should be able tocommunicate using unconstrained natural, spokenlanguage.We have started to collect dialogs using a wizard scenarioin the TRAINS domain and have built an initial prototypesystem.
The current system uses keyboard input derivedfrom the transcripts of actual spoken dialogs.
The dialogsexhibit complex behavior as both the human and systemtake initiative at times in the dialog, and there are a largenumber of c lar i f icat ions,  correct ions andacknowledgements.This short paper describes both our empirical work inanalyzing the transcripts, and our theoretical work indefining a computational discourse model.THE DATAWe decided to collect our own data rather than using anexisting source, such as the ATIS corpus, for severalreasons.
First, the dialogs in ATIS are structured toemphasize question-answering rather than interactiveproblem solving.
More importantly, the mixed modalityinteraction of the ATIS scenario inhibits most naturalspoken dialog phenomena.
In particular, the long pausesbefore responses and the table-based system outputprevent natural follow-up, such as" acknowledgements,clarifications and confirmations that are common inspoken dioalog.
Almost 50% of the soeech collected inour more natural setting was of these types.The TRAINS domain was carefully designed so that asignificant part of it is within reach of current (or nearfuture) capabilities of plan reasoning systems.
Because ofthis, we should be able to fully specify and implement thereasoning underlying the "system" in the dialogs.
If ATISwere extended to be a travel-planner rather than a database,the domains would be comparable.We have collected an initial corpus of natural spokenconversations between two people engaged in complexproblem solving in the TRAINS world.
One person (the"system") has most of the information and detail about hedomain, but the other has the problem to solve.
The twoare in different rooms and so have no visual contact, butthey both have the same map from which to work.
Afragment from one of the dialogs shown in Figure 1.
Eachutterance is roughly classified as to its function: whether itis primarily concerns with making progress on solvingthe problem (plain text), or whether it is primarilyconcerned with maintaining the conversation itself (inbold).
The agents are labelled <H> (for human) and <S> (forsystem), even though the system here was simulated by aperson.
Comments on the possible discourse function ofthe utterances concerned with maintaining theconversation are presented in italics.As can be seen, approximately half of the utterances areconcerned with maintaining the communication process.There are utterances that identify the goals of the nextstretch of discourse, and a large number of utterances thatpertain to acknowledging the other agents utterances andin maintaining a smooth flow of control (i.e.
identifyingwhose turn it is to speak).
It has been our claim for sometime that this level of discourse interaction must beexplicitly modelled if we are to build systems that canconverse in natural anguage, and in previous papers wehave described a plan-based model that accounted forclarification subdialogs among other things (Litman &Allen, 1990, Litman & Allen, 1987).
We are nowattempting to develop an extended model that can accountfor all the discourse-level interactions found in the corpus.The project is pursuing two main thrusts.
First, we aredeveloping a database for studying discourse phenomena.To do this, we are developing a taxonomy of discourse-level acts with which different people can independentlyclassify each utterance reliably.
Using this classification,325<H> ok, now uhh, let me, let me check on the uhh<H> where the.. where the engines are and the.. the boxcars are uhhsetting the immediate conversation goals for the following dialog fragment<H> I 'm assuming,indicating that <H> is asking for confirmation<H> let's see, that uhh<H> is holding the turn while he examines the map<H> I have two engines to work with, engine E2 which is at city D<H> and engine E3 which is at city A<S> aah, yes.the "aah" probably indicates that <S> is thinking about he answer (andacknowledging that the question was understood)<H> and uh, I've got two tankers, tanker tl is at city A,<H> and tanker t2 is at city B<S> that's right, hnn, hnn.<H> ok<H> indicates that he has accepted <S>'s reply<S> there're., there're other tankers as well.<H> ok<H> acknowledges <S>~ introduction of new information<S> there're actually four tankers at city E"actually" indicates that <S> believes <H> doesn't know about hese tankers<H> four tankers at city E, ok<H> acknowledges hearing the new information, and then accepts it<H> uhh so, tankers t3, t4, t$, and t6 are all at city E.<H> confirms his understanding of <S> ~ assertions<S> that's right<S> confirms <H>~ confirmation<H> ok. and just uh<H> acknowledges the previous exchange and signals a move to a new topic<H> I have four boxcars, b6 at city H, b5 at city F,<H> b7 at city B, and b8 at city I.we are building a database of dialogs with each utteranceannotated by its discourse function.
In addition, we areanalyzing the tapes and extracting prosodic information(primarily pitch contours, speech rate) and adding thisinformation to the database as well.
We have started somepreliminary studies on prosodic cues to the discourse actsin our taxonomy, but need to analyze additional data beforewe have significant results.
Second, we are developing asystem that implements he discourse model together withfull natural language processing and plan reasoning in thedomain.
In this paper, I will mainly describe the problemswe are facing and the initial taxonomy developed so far.
Atthe end, I will briefly describe the discourse model in thecurrent implementation.THE TAXONOMYRather than analyze the dialogs in terms of abstractdiscourse relations, our taxonomy is based entirely on theintentions of the speaker.
This allows us to integrate wellwith previously developed computational speech actmodels, and provides a slightly different view from theother approaches.
It is important to remember that justbecause a speaker intended an utterance is a certain way, itdoesn't mean that the hearer understands it that way.Establishing agreement between the speaker and hearer asto what was intended is the primary reason foracknowledgements, clarifications and corrections.
Inaddition, even if an utterance is understood correctly, thisdoesn't commit the hearer to accepting the intendedconsequences of the act (e.g.
believing the speaker'sassertion, or performing the requested act).
Acceptanceinvolves yet additional mechanisms to acknowledgment.As we define the set of speech act types, It is important torealize that nearly every speech act can be used at differentlevels of the conversation: they can involve the plan inthe TRAINS world (the domain level), or the problemsolving process that the two agents are engaged in (theproblem solving level), or the understanding andmanaging of the conversation itself (the d i scourselevel).
We will try to give examples of the acts at eachlevel as they are defined.
Because of the focus on thediscourse-level acts in this paper, we will often distinguishthese as separately named acts.The speech acts themselves break into three majorclasses: the unders tand ing  acts, which includeacknowledgements and confirmations, the informationacts, which involve imparting information and includeinforms, elaborations, clarifications, corrections andsummarizations, and the co -ord inat ion  acts, whichinvolve co-ordinating the activities of the two agents andinclude requests, suggestions, acceptances and so on.Throughout we will refer to the agent performing thespeech act as the speaker and the other agent as the otheragent.326There is not the space to precisely define each act, but Iwould like to present he entire taxonomy.
To do this,some of the acts will simply be presented by an example.THE UNDERSTANDING ACTSThe understanding acts specifically relate to indicating thesuccessful hearing of the other agent's utterances.Acknowledgment  (Ack)An acknowledgment indicates that the speaker hasunderstood the other agent's previous utterance, but doesnot necessarily commit the speaker to agreeing with theother agent.
An acknowledgement that is not anacceptance of the other agent's request is shown in italics:<H> unload b8 processing orange juice and loadt2<S> OK, ah but tanker t2 is currently full of beerConf i rmat ion  (Conf)A confirmation act is a special form of acknowledgmentthat involves restating or paraphrasing informationestablished previously in the conversation.
If there is anydoubt implied in the utterance, say by using a questionintonation, then the utterance is a clarification requestrather than a confirmation.<H> Can you have city I fill B8 with orangesplease?<S> OK. We're gonna fill b8 with oranges at cityIComplet ion  (Compl )A completion occurs when the speaker completes the otheragent's utterance rather than waiting for the agent tofinish.<S>.which should leave us plenty of time to uhhh<H> get to city H<S> city H after thatKeepTurnThis is a wide-ranging class and includes any utteranceswhose main purpose is to maintain the speakers turn,although they may also serve as an acknowledgement.<S> where it will then pick up the orange juice<S> and uhhh ...<S> and then take that to city GTHE INFORMATION ACTSInformation acts involve making claims about the state ofthe world.
The prototypical speech act in this class in thespeech act literature in the inform act.We will break downinforms at the discourse level into clarifications,corrections, elaborations and summarizations.Inform (Inf)An inform act in the TRAINS domain is generally either inresponse to a question, or is a situation setting action thatdescribes background information ecessary to understandthe problem.
Inform is the default assignment for acts inthis class if none of the following acts seem appropriate.<H> Where's e3?<S> e3 is just coming in to city A.Clar i f i ca t ions  (C l r )A clarification is an utterance that provides additionalinformation to help the interpretation of the previousutterance.
Utterances that provide information which isnot necessary to understand the previous utterance are notclarifications, but rather elaborations.
Examples are<H> great, have them unload b6<H> have D unload b6and<H> Let's do that<H> Let's move E2 to city EI n tent  C lar i f i cat ion  (Tag)An intent clarification utterance clarifies the intention of aprevious utterance.
The name Tag is assigned as this is therole that is played by tags in sentences such as John iscoming to the party, isn't he?.
The tag indicates that theutterance is a question rather than an assertion.
A tag canbe deleted without affecting the dialog (if the previousutterance is treated appropriately asindicated by the tag)<H> It is 2PM<H> Is that right?Correct ions  (Cor)A correction is a special form of clarification that replacessome earlier information with the new information.Corrections often follow utterances that signal someproblem, such as No, or opps, and so on.
Corrections alsocan appear mid-way through an utterance when the speakerneeds to make a correction of something uttered earlier inthe sentence.<S> e3 is on its way to tl<S> oops with tanker tl<S> full of orange juiceE laborat ion  (E lab)An elaboration is an inform that further develops aprevious topic.
The information is not needed in order tounderstand the previous entence (in which case it would bea clarification).<S> The quickest route would be to go throughcity C<H>OK<S> uhh that should take six hours327Summary  (Sum)A summary act is an inform that restates what has beenasserted or decided upon in the previous utterances, ordraws conclusions from what was previously asserted.<S> uh we can actually have the orange juicemade by uhh twelve pm tonight<S> so there should be plenty., plenty of timeTHE CO-ORDINAT ION ACTSThese acts involve the two agents co-ordinating theiractivities by making requests and suggestions andreaching agreement after negotiation.
As mentionedabove, this co-ordination can occur at the three differentlevels of conversation.
As before, the acts at the discourselevel will be given special treatment as subclasses of thegeneral cases.Request (Req)A request involves one agent attempting to get the otheragent o do something by direct means.
If a request is nottaken up, it must be explicitly denied by the hearer eitherby stating that he won't comply or by suggesting amodification to the requested action.
The requested actionmay be either a domain act, as in:<H> Can you have city I fill B6 with oranges,pleaseor a problem solving act as in<H> Let me know when E3 has B6 loaded.Particular subclasses of requests involving questions aretreated individually as they have their own specificsyntactic markers in language.Wh Quest ion  (WHQ)Wh-questions are true question where the speaker isactually asking for information about a specific entityfrom the hearer.
An example at the domain level is:<H> How much does it cost to dunk it on theground?and at the problem solving level is<H> What should we do?Yes-No Quest ion  (YNQ)These are true yes/no questions, where the speaker wouldbe content with a simple yes or no answer.
If additionalinformation does seem to be required, then the originalquestion was probably an indirect request or WHQ.
Anexample at the domain level is:<H> Is e3 at city I?and at the problem solving level is<H> are you uhh trying to compute the time totake E2 with T3 and T4Requests and questions at the discourse level are typicallyclarification requests, which are marked in their owncategory below.Clarification Request (reqClr)A clarification request is a request for information to helpinterpret some previous utterance(s), i.e.
a request for aclarification.
In the following example, the clarificationrequest is in bold italics, and the ensuring clarification initalics:<S> To city I?<H> yesHere's a clarification request (bold italics) that wasanswered with a correction (italics):<S> I just found city E2<H> city E27<S> uhh .. engine E2Suggest (Sug)A Suggestion in this domain also involves getting theother agent o do something, but is weaker than a request.Suggestions explicitly leave open an option ofnegotiation between the agents, often by using the firstperson plural to include both agents in the suggestedaction.
An example at the domain level is:<<S> Why don't we begin loading oranges inboxcar B6and at the problem solving level:<S> Shall we look at the other engine?and at the discourse level:<H> Well, lets talk about orange juiceCorrection Suggestion (sugCor)Other suggestions at the discourse level may be correctionsuggestions.
In the example, the correction suggestion isin bold italics, and the acceptance (i.e.
a correction) is initalics.<S> second engine E3 is going to uhh city H topick up the bananas<S> back to A, dro ..................<H> ....... H to pick up the oranges<S> sorry, pick up the oranges<S> back to A to drop the oranges offAccept (Ace)Art accept indicates that the hearer has accepted the act inthe previous utteranee, be it a request, suggest, inform ofwhatever.
After an agent has done an accept, they arecommitted to whatever the speech act that was acceptedrequires.
Accepts can also be implicit if the agent328continues on without explicit denial.
Examples oftenoverlap with acknowledgments.
Here is a suggestion at thedomain level that is accepted:<H> and in the mean time, it would be nice if cityH could be filling B6 with oranges<S> OK, it looks like we can do thatDenial  or Re jeetance (Den)A Denial is the opposite of an acceptance.
As with acceptacts, one can deny requests, suggestions or many otheracts.
There are not many denials in the current dialogs asthe conversants are quite co-operative!.
But they do occuroccasionally.
Here's an acknowledgement of a requestfollowed by a denial.<H> have city B prepare for its arrival, it shouldunload b8 processing orange juice and loadt2.<S> OK, ah but tanker t2 is currently full of beer.Eva luat ive  S ta tement  (Eval)An evaluative statement describes the reaction of thespeaker to the current situation.
Such statements serve aconfirmation or denial role, or express more subtle shadesin between.Typical Phrases: great!, terrific!, yuk!, how nice!<S> looks like we can do that<H> TerrificTHE CURRENT SYSTEMEventually, we intend to develop a model that defines eachof the above discourse acts in terms of the changes that theact makes to the shared and individual beliefs and goals ofthe two participants in the dialog.
The current system,however, is quite simple and was constructed mainly todefine the overall architecture of the system.
The currentdiscourse model has the following basic capabilities?
maintaining knowledge of the turn taking (i.e.
whoseresponsibility is it to speak next);?
tracking the status of each fragment of the plan as it issuggested and discussed;?
tracking and responding to simple discourse obligations(e.g.
answering questions)..The discourse module uses the domain plan reasoner, whichuses planning and plan recognition techniques, tomaintain the domain plans.
It calls the domain reasoner toverify hypotheses about the discourse function of theutterances, and to update the state of the plan as needed.Plan fragments in the knowledge base are characterized bysix modalities that are used to indicate the status of parts ofthe plans being discussed.
These are organizedhierarchically with inheritance so that we can examine thefull plan from either human's of the system's perspectiveas shown in Figure 2.The modalities include:?
the plan fragment suggested by the human but not yetacknowledged by the system (Human-Proposed-PIan-Private);?
the plan fragment suggested by the system and not yetacknowledged by the human (System-Proposed-Plan-Private);?
the plan fragment suggested by the human andacknowledged but not yet accepted by the system (Human-Proposed-Plan);?
the plan fragment suggested by the system andacknowledged but not yet accepted by the human (System-Proposed-Plan);?
the plan fragment that is shared between the two (i.e.accepted by both) (Shared-Plan); and?
the plan fragment constructed by the system but not yetsuggested (System-Private-Plan).Each context is associated with a particular form of planreasoning as indicated in the figure.
In particular, the planin the System-Private-Plan context is extended by planconstruction (essentially classical planning), where theplans in all the other contexts are extended by planrecognition relative to the appropriate set of beliefs.Figure 2 also shows how plan fragments may movebetween the various contexts.
A suggestion from thehuman enters a new plan fragment into the Human-Proposed-Plan-Private context and initiates planrecognition with respect o what the system believes aboutthe human's private beliefs.
Once acknowledged, thissuggestion becomes "public" (i.e.
it is in Human-Proposed-Plan).
An acceptance from the system would thenmove that plan fragment into the Shared-Plan context,again invoking plan recognition.Planning by the system results in new actions in theSystem-Private-Plan context.
To make these actions partof the Shared-Plan context, the system must suggest heactions and then depend on the human to acknowledged andaccept them.
This model, while still crude byphilosophical standards, is rich enough to model a widerange of the discourse acts involving clarification,acknowledgment and the suggest/accept speech act cycleever-present in dialogs in this setting.Because of the inheritance through the spaces, when thesystem is planning in the System-Private-Plan context, itsees a plan consisting of all the shared goals and actions,what it has already suggested, and all the new actions it hasintroduced into the plan privately but not yet suggested.329Ishared Plan IPlan recognition Humanbased on shared beliefsPlan recognitionbased on shared knowledgeof the human's beliefsPlan recognitionbased on shared knowledgeof the system's beliefst System AcWConfirms t Human AcWConfirmsHuman Suggests 11 ] Shared BeliefsFigure 2: The different plan modalities from the system's perspectiveConsider an example.
Assume that the Shared-Plan context Acknowledgementscontains a plan to move some oranges to a factory at B,but there is no specification of the engine to be used.
Thesystem might plan to use engine E3.
At this stage, theplan from the System-Private-Plan context involves E3.The plan in the System-Proposed context, however, is stillthe same as the plan in the Shared-Plan context, whichstill does not identify which engine to use.
When thesystem makes the suggestion, the plan fragmentinvolving E3 is added to the system proposed plan(private).
An acknowledgment from the human results inthis plan fragment being added to the system-proposedplan known to both agents.
If the human then accepts this,it then becomes part of the shared plan.
If the humanrejects the suggestion, then E3 does not become part of theshared plan (at least, not without further discussion).This work has been done in conjunction with Shin'yaNakajima and David Traum.
It was supported in part byONRIDARPA conbact number N00014-82-K-0193.ReferencesAllen, J.F.
& Perrault, C.R.
Analyzing intention inutterances, Artificial Intelligence 15, 1980Litman, D.J.
& Allen, J.F.
A plan recognition model forsubdialogues in conversation, Cognitive Science I I ,1987Litman, D.J.
& Allen, J.F.
Discourse processing andcommonsense plans, in In tent ions  inCommunication, P .
Cohen, J. Morgan and M. Pollack(eds), MIT Press, 1990.The prototype system can handle simple examples alongthese lines where the two agents are free to accept or rejectsuggestions as they are made in the dialog.
The systemunder development will extend the current one to supportsome forms of negotiation between the agents in order toarrive at a mutually agreeable plan.
