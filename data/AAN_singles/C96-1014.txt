I n tegrat ing  Syntact i c  and Prosod ic  In fo rmat ion  for theEf f ic ient  Detect ion  of  Empty  Categor iesAnton Batliner l, Anke Feldhaus ~, Stefan GeiBler t,Andreas KieBling*, Tibor Kiss ~, Ralf Kompe*, Ehnar N~ith*I,MU Miinch(.n t IBM l)eutschl~nd lnforma.tionssysteme ~ FAll ti',rla.ngen-Niirnl)erg *lnstitut f. I)eutsche Philologie Inst.
f. Logik und l,inguistik 1,ehrstuhl f. Mustererk?.tmungSehellingstr.
3 V~tngerowstr.
18 Martensstr.
3D-80799 Miinchen 11)-69115 IIeidelberg 1)-91058 \]';rlangenAbstractWe describe a number of experimentsthat demonstrate the usefulness ofprosodic information for a processingmodule which parses spoken utteranceswith a feature-based grammar employingempty categories.
We show that by re-quiring certain prosodic properties fromthose positions in the input, where thepresence of an empty category has to behypothesized, a derivation can be accom-plished more efficiently.
The approachhas been implemented in the machinetranslation project VEItBMOBII, and re-sults in a significant reduction of thework-load for the parser t.1 IntroductionIn this paper we describe how syntactic andprosodic information interact in a translationmodule for spoken utterances which tries to meetthe two - often conflicting - main objectives, theimplementation of theoretically sound solutionsand efficient processing of tile solutions.As an analysis which meets the first criterionbut seemingly fails to meet the second one, we takean analysis of the German clause which relies ontraces in verbal head positions in the framework ofHead-driven Phrase Structure Grammar (llt'sG,cf.
(Pollard&Sag, 1994)).The methods described in this paper havebeen implemented as part of the IBM-SynSem..Module and the FAU-Erlangen/LMU-Munich-Prosody-Module in the MT project Vl,;ltHMOmI,(of.
(Wahlster, 1993)) where spontaneously spo-ken utterances in a negotiation dialogue are trans-lated.
In this system, an lh's(~ is processed by abottom-up chart parser that takes word lattices astThis work was partiMly funded by the Gc,-Imtn Vedcral Ministry for Research and Technology(BMIW) in the framework of the Verbmobil Projectunder (~r~nt ~(11 IV 101 V (Verbmobil).
Tim rt:spon-slbility for the contents of this study lies with the aa,-thors.its input.
The output of the parser is the seman-tic representation for the best string hypothesis inthe lattice.It is our main result that prosodic informa-tion can be employed in such a system to de-termine possible locations for empty elements intile input.
Rather than treating prosodic informa-tion as virtual input items which have to matchan appropriate category in tile grammar rules(Bear&Price, 1990), or which by virtue of being'unknown' in the grammar force the parser to closeoff the current phrase (Marcus&Hindle, 1990), ourparser employs prosodic information as affectingthe postulation of empty elements.2 An HI'sG Analysis of GermanClause St ructure\[\[PSG makes crucial use of "head traces" to ana-lyze the verb-second (V2) phenomenon pertinentin German, i.e.
the fact that finite verbs appear insecond position in main clauses but in final posi-tion in subordinate clauses, as exemplified in (la)and (lb).1.
(a) Gestern reparierte r den Wagen.
(Yesterday fixed he the car)'Yesterday, he fixed the car.
'(b) Ich dachte, dab er gestern den Wagenreparierte.
(I thought that he yesterday the carfixed)'I thought that he fixed tile car yester-day'.Following (Kiss&Wesche, 1991) we assume thatthe structural relationship between tile verb andits arguments and modifiers is not affected by theposition of the verb.
The overt relationship be-tween the verb 'reparierlc' and its object 'den Wa..qe~,'in (1t)) is preserved in (la), although the verbshows up in a different position.
The apparentcontradiction is resolved by assuming an emptyclement which serves as a substitute for tile verbill second position.
The empty element fills tile po--sition occupied by the finite verb in subordinate'/\]jclauses, leading to the structure of main clausesexemplified in (2).GesternC I;d~n "~agen X0-i(2): Syntax tree for 'Gestern reparierteer den Wagen.
'The empty verbal head in (2) carries syntac-tic and semantic information.
Particularly, theempty head licenses the realization of the syntac-tic arguments of the verb according to the ruleschemata of German and Ih'sG's Subcategoriza-tion Principle.The structure of the main clause presented in(2) can be justi fed on several grounds.
In partic-ular, the parallelism in verbal scope between verbfinal and V2 clauses - exemplified in (3a) and (3b)- can be modeled best by assuming that the scopeof a verb is always determined w.r.t, the final po-sition.3.
(a) Ich glaube, du sollst nicht tgten.
(I believe you shall not kill)'I believe you should not kill.
'(b) Ich glaube, dab du nicht tgten sollst.
(I believe that you not kill shall)'I believe that you should not kill.
'In a V2 clause, the scope of the verb is deter-mined with respect o the empty verbal head only.Since the structural position of an empty verbalhead is identical to the structural position of anovert finite verb in a verb final clause, the invari-ance does not come as a surprise.Rather than exploring alternative approacheshere, we will briefly touch upon the representa-tion of the dependency in terms of lIPs(~'s featu~ral architecture.
Information pertaining to emptyheads are projected along the DOUBLI,; SI,ASH(DsL) feature instead of the SLASh feature (cf.
(Borsley, 1989)).
The empty head is described in(4) where the LOCAL value is coindexed with thel)sl, value.SYNSEM LOCNONLOC I I)SL }(4): Feature description of a head traceThe DsL of a head is identical to the I)sL of themother, i.e.
l)sb does not behave like a NONLO-CAt, but like a IlEal) feature.A DSL dependency is bound if the verbal pro-jection is selected by a verb in second position.A lexical rule guarantees that the selector sharesall relevant information with the Dsb value of theselected verbal projection.
The relationship be-tween a verb in final position, a verb in secondposition and the empty head can be summarizedas follows: For each final finite verb form, there isa corresponding finite verb form in second positionwhich licenses a verbal projection whose emptyhead shares its LOCAL information with the cor-responding final verb form.
It is thus guaranteedthat the syntactic arguments of the empty headare identical to the syntactic arguments requiredby the selecting verb.3 P rocess ing  Empty  E lementsDirect parsing of empty elements can become atedious task, decreasing the efficiency of a systemconsiderably.Note first, that a reduction of empty elementsin a grammar in favor of disjunctive lexical rep-resentations, as suggested in (Pollard&Sag, 1994,ch.9), cannot be pursued.
(Pollard&Sag, 1994) assume that an argumentmay occur on the SUBCAT or on the SLAS\]I list.A lexical operation removes the argument fromSur~cA'r and puts it onto SI,AStt.
Hence, no fur-ther need for a syntactic representation of emptyelements emerges.
This strategy, however, will notwork for head traces because they do not occur asdependents on a SUBCAT list.If empty elements have to be represented syn-tactically, a top-down parsing strategy seems bet-ter suited than a bottom-up strategy.
Particu-larly, a parser driven by a bottom-up strategy hasto hypothesize the presence of empty elements atevery point in the input.In lh's(~, however, only very few constraints areavailable for a top-down regime since most infor-mation is contained in lexical items.
The parserwill not restrict the stipulation of empty elementsuntil a lexical element containing restrictive infor-mation has been processed.
The apparent advan-tage of top-down parsing is thus lost when llpsGsare to be parsed.
The same criticism applies toother parsing strategies with a strong top-downorientation, such as left corner parsing or headcorner parsing.We have thus chosen a bottom-up arsing strat-egy where the introduction of empty verbal headsis constrained by syntactic and prosodic informa-tion.
The syntactic onstraints build on the factsthat a) a verb trace will occur always to the rightof its licenser and b) always 'lower' in the syntaxtree.
Furthermore c) since the l)sh percolationmechanism ensures tructure sharing between theverb and its trace, a verb trace always comes witha corresponding overt verb.As a consequence of c) the parser has a fully72specified verb form - although with empty phonol-ogy - at hand, rather than having to cope with theunderspecified structure in (4).
This form can bedetermined at compile time and stored in the lexi-con together with the corresponding verb form.
Itis pushed onto the trace stack whenever this verbis accessed.Although a large number of bottom-up hy-potheses regarding the position of an empty el-ement can be eliminated by providing the parserwith the aforementioned information, the numberof wrong hypotheses i still significant.In a verb-2nd clause most of the input followsa finite verb form so that condition a) indeed isnot very restrictive.
Condition b) rules out a largenumber of structures but often cannot prevent hestipulation of traces in illicit positions.
Conditionc) has the most restrictive ffect in that the syn-tactic potential of the trace is determined by thatof the corresponding verb.If the number of possible trace locations couldbe reduced significantly, the parser could avoid alarge number of subanalyses that conditions a)-c)would rule out only at later stages of the deriva-tion.
The strategy that will be advocated in theremainder of this paper employs prosodic infor-mation to accomplish this reduction.Empty verbal heads can only occur in the rightperiphery of a phrase, i.e.
at a phrase bound-ary.
The introduction of empty arcs is then notonly conditioned by the syntactic onstraints men-tioned before, but additionally, by certain require-ments on the prosodic structure of the input.It turns out, then, that a fine-grained prosodicclassification of utterance turns, based on corre-lations between syntactic and prosodic structureis not only of use to determine the segmentationof a turn, but also, to predict which positions areeligible for trace stipulation.
The following sec-tion focuses on the prosodic classification schema,section 5 features the results of the current exper-iments.4 C lass i fy ing  Prosod ic  In fo rmat ionThe standard unit of spoken language in a dia-logue is the turn.
A turn like (5) can be composedout of several sentences and subsentential phrases-- free elements like the phrase 'ira April' whichdo not stand in an obvious syntactic relationshipwith the surrounding material and which occurmuch more often in spontaneous speech than inother environments.
One of the major tasks of aprosodic component of a processing system is thedetermination of phrase boundaries between thesesentences and free phrases.5.
Im April.
Anfang April bin ich in Urlaub.Ende April habe ich noch Zeit.
(In April beginning April am I on vacationend April have I still time)'In April.
I am on vacation at the beginningof April.
I still have time at the end of April.
'In written language, phrase boundaries areoften determined by punctuation, which is, ofcourse, not available in spoken discourse.
For therecognition of these phrase boundaries, we use astatistical approach, where acoustic-prosodic fea-tures are classified, which are computed from thespeech signal.The classification experiments for this pa-per were conducted on a set of 21 human-human dialogs, which are prosodically labelled (cf.
(Reyelt, 1995)).
We chose 18 dialogs (492 turns,36 different speakers, 6996 words) for training,and 3 dialogs for testing (80 turns, 4 differentspeakers, 1049 words).The computation of the acoustic-prosodic fea-tures is based oi1 a time alignment of the phonemesequence corresponding to the spoken or recog-nized words.
To exclude word recognition errors,for this paper we only used the spoken word se-quence thus simulating 100% word recognition.The time alignment is done by a standard hid-den Markov model word recognizer.
For each syl-lable to be classified the following prosodic fea-tures were computed fully automatically from thespeech signal for the syllable under considerationand for the six syllables in the left and the rightcontext:?
the normalized uration of the syllable nu-cleus?
the minimum, maximum, onset, and offset offundamental frequency (FO) and the maxi-mum energy and their positions on the timeaxis relative to the position of the actual syl-lable?
the mean energy, and the mean FO?
flags indicating whether the syllable carriesthe lexical word accent or whether it is in aword final positionThe following features were computed only forthe syllable under consideration:?
the length of the pause (if any) preceding orsucceeding the word containing the syllable?
the linear regression coefficients of the F0-contour and the energy contour computedover 15 different windows to the left and tothe right of the syllableThis amounts to a set of 242 features, which sofar achieved best results on a large database ofread speech; for a more detailed account of thefeature evaluation, (cf.
(Kief~ling, 1996)).The full set of features could not be used dueto the lack of sufficient training data.
Best re-sults were achieved with a subset of features, con-taining mostly durational features and F0 regres-sion coefficients.
A first set of reference labels73was based on perceptive evaluation of prosod-ically marked boundaries by non-naive listen-ers (cf.
(Reyelt, 1995)).
Here, we will onlydeal with major prosodic phrase boundaries (B3)that correspond closely to the intonational phraseboundaries in the ToBI approach, (cf.
(Beck-man~Ayers, 1994)), vs. all other boundaries (noboundary, minor prosodic boundary, irregularboundary).
Still, a purely perceptual labelling ofthe phrase boundaries under consideration seemsproblematic.
In particular, we find phrase bound-aries which are classified according to the per-ceptual labelling although they did not corre-spond to a syntactic phrase boundary.
Illustra-tions are given below, where perceptually abelledbut syntactically unmotivated boundaries are de-noted with a vertical bar.6.
(a) Sollen wir uns dann im Monat M?r~.
\[einmal treffen?
(Shall we us then in month March meet)'Should we meet then in March.
'(b) Wir treffen uns am Dienstag \[ dendreizehnten April.
(We meet us on tuesday the thirteenthApril.
)'We meet on tuesday the thirteenth ofApril.
'Guided by the assumption that only the bound-ary of the final intonational phrase is relevant forthe present purposes, we argue for a categoriallabelling (cf.
(Feldhaus&Kiss, 1995)), i.e.
a la-belling which is solely based on linguistic defini-tions of possible phrase boundaries in German.Thus instead of labelling a variety of prosodicphenomena which may be interpreted as bound-aries, the labelling follows systematically the syn-tactic phrasing, assuming that the prosodic real-ization of syntactic boundaries exhibits propertiesthat can be learned by a prosodic lassification al-gorithm.The 21 dialogues described above were labelledaccording to this scheme.
For the classificationreported in the following, we employ three mainlabels, $3+ (syntactic boundary obligatory), S3-(syntactic boundary impossible), and $3?
(syn-tactic boundary optional).
Table 1 shows the cor-respondence between the $3 and B3 labels (nottaking turn-final labels into account).cases \ ] ~  not-B3 \]$3+ 844~ 18\]$3- 5907 97$3?
570 68Table 1: Correspondence b tween $3 and B3labels in %.Multi-layer perceptrons (MLP) were trained torecognize $3+ labels based on the features anddata as described above.
The MLP has one out-put node for $3+ and one for $3-.
During trainingthe desired output for each of the feature vectorsis set to one for the node corresponding to thereference label; the other one is set to zero.
Withthis method in theory the MLP estimates poste-riori probabilities for the classes under considera-tion.
However, in order to balance for the a prioriprobabilities of the different classes, during train-ing the MLP was presented with an equal numberof feature vectors from each class.
For the experi-ments, MLPs with 40/20 nodes in the first/secondhidden layer showed best results.For both $3 and B3 labels we obtained overallrecognition rates of over 80% (cf.
table 2).Note, that due to limited training data, errorsin F0 computation and variabilities in the acous-tic marking of prosodic events across speakers, di-alects, and so on, one cannot expect an error freedetection of these boundaries.Table 2 shows the recognition results in percentfor the $3+/$3- classifier and for the B3/not-B3classifier using the S3-positions as reference (firstcolumn) again not counting turn final boundaries.For example, in the first row the number 24means that 24% of the $3+ labels were classifiedas $3-, the number 75 means that 75% of the $3+labels were classified as B3.\[ cases 11 $3+ I S3 -~-g - \ [  n?t-B3 \]s3+ 11o 76 75 25s3 -  766 14 s6 14 s6$3?
93 43 57 46 54Table 2: Recognition rates for $3 labels in % for$3 and B3 classifiers.What table 2 shows, then, is that syntactic $3boundaries can be classified using only prosodicinformation, yielding recognition rates compara-ble to those for the recognition of perceptuallyidentified B3 boundaries.
This means for our pur-poses, that we do not need to label boundariesperceptually, but can instead employ an approachas the one advocated in (Feldhaus&Kiss, 1995),using only the transliterated data.
While this sys-tem turned out to be very time-consuming whenapplied to larger quantities of data, (Batliner etal., 1996) report on promising results applying asimilar but less labor-intensive system.It has further to be considered that the recogni-tion rate for perceptual labelling contained thosecases where phrase boundaries have been recog-nized in positions which are impossible on syntac-tic grounds-el, the number of cases in table (1)where a $3- position was classified as B3 and viceversa .It is important to note, that this approach doesnot take syntactic boundaries and phonologicalboundaries to be one and the same thing.
It is awell-known fact that these two phenomena oftenare orthogonal to each other.
However, the ques-tion to be answered was, can we devise an auto-matic procedure to identify the syntactic bound-74aries with (at least) about the same reliability asthe prosodic ones?
As the fgures in table (2)demonstrate the answer to this question is yes.Our overall recognition rate of 84.5% forthe S3-classifier (cf.
table (2)) cannot ex-ac t ly  be compared with results reported inother studies because these studies were ei-ther based on read and carefully designed ma-terial, (cf., e.g., (Bear&Price, 1990), (Osten-hof&Veilleux, 1994)), or they used not auto-matically computed acoustic-prosodic featuresbait textual and perceptual information, (cf.
(Wang&Hirschberg, 1992)).5 Resu l tsIn order to approximate the usefulness of prosodicinformation to reduce the number of verb tracehypotheses for the parser we examined a corpusof 104 utterances with prosodic amlotations de-noting the probability of a syntactic boundary af-ter every given word.
For every node whose $3boundary probability exceeds a certain thresholdwdue, we considered the hypothesis that this nodeis followed by a verb trace.
These hypotheses werethen rated valid or invalid by the grammar writer.Note that such a setting where a position in theinput is annotated with scores representing the re-spective boundary probabilities is much more ro-bust w.r.t unclear classification results than a purebinary 'boundary-vs.-nonboundary' distinction.The observations were rated according to theff~llowing scheme~:X0 position X0 position L .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I no~ X0 prop.
Miss : 6 X : 703Table 3: Classification results for verb tracepositionsEvaluation of these figures for our test corpusand a threshold value of 0,01 yielded the followingresult:Recall = 95,8 ~Precision = 33,5Error = 25,0Table 4: P~ecall, Precision and Error for theidentification of possible verb trace positions.where:Recall -- Co,.,.~t- -  ~-Cor rec t+Miss jPrecision = Co,.,,ect( Cor rec t  + Fa lse~__ (M iss+Fa lse)Error - C'(C-~reet+False+Miss+X)In practice this means that the number of loca-tions where the parser has to assume the presence2XO position means that the relewLnt position isoccupied by a XO gap, XO prop.
means that theclassifier l)roposes an X0 ~tt this position.of a verb trace could be reduced from 1121 to 412while only 6 necessary trace positions remMnedunmarked.
These results were obtained from acorpus of spoken utterances many of which con-tained several independent phrases and sentences.These segments, however, are also often separatedby an S3-boundary, so that the error rate is likelyto drop considerably if a segmentation of utter-ances into syntacticMly well-formed phrases is per-formed prior to the trace detection.
Since caseswhere the verb trace is not located at the end ofa sentence (i.e.
where extraposition takes place)involve a highly characteristic categorial context,we expect a further improvement if the trace/no-trace classification based on prosodic informationis combined with a language model.The problem with the approach described aboveis that a careful estimation of the threshold valueis necessary and tiffs threshold may vary fromspeaker to speaker or between certain discoursesituations.
Furthermore the analysis fails in thosecases where tile correct position is rated lowertitan this value, i,e.
where the parser does notconsider the correct race position at all.
Thus, ina second experiment we examined how the syntac-tically correct verb trace position is ranked amongthe positions proposed by the prosody modulew.r.t, its S3-boundary probability.
If the cor-rect position turns out to be consistently rankedamong the positions with the highest $3 probabil-ity within a sentence then it might be preferablefor the parsing module to consider the $3 posi-tions in descending order rather than to introducetraces for all positions ranked above a threshold.For the second experiment we considered onlythose segments in the input that represent V2clauses, i.e.
we assumed that the input has beensegmented correctly.
Within these sentences weranked all the spaces between words according tothe associated $3 probability and determined therank of tile correct verb trace position.
When per-forming this test on 134 sentences the followingpicture emerged:Rank 6\ [#ofocc .~T~\ [T I4 \ [3 .
\ [01  71\[ >i- \ ]7Table 5: Ranking of the syntactically correctverb trace position within a sentence accordingto the $3 probability.Table 5 shows that in the majority of cases theposition with the highest $3 probability turns outto be the correct one.
It has to be added though,that in many cases the correct verb trace positionis at the end of the sentence which is often veryreliably marked with a prosodic phrase boundary,even if this sentence is uttered in a sequence to-gether with other phrases or sentences.
This end-of-sentence marker will be assigned a higher $3probability in most cases, even if the correct verbtrace position is located elsewhere.75In a third experiment finally we were interestedin the overall speedup of the processing modulethat resulted form our approach.
In order to es-timate this, we parsed a corpus of 109 turns intwo different settings: While in the first roundthe threshold value was set as described above,we selected a value of 0 for the second pass.
Theparser thus had to consider every postion in theinput as a potential head trace location just as ifno prosodic information about syntactic bound-aries were available at all.
It turns out then (cf.table (6)) that employing prosodic information re-duces the parser untime for the corpus by about46%!I \[ With Prosody I Without Prosody I1 Average 6.5 11.9~I Speedup \[ 45.96% \[ ./.-\]Table 6: Comparison of runtimes (in secs) forparsing batch-jobs with and without he use ofprosodic information, resp.6 Conc lus ionIt has been shown that prosodic information canbe employed in a speech processing system to de-termine possible locations of empty elements.
Al-though the primary goal of the categorial labellingof prosodic phrase boundaries was to adjust tiledivision of turns into sentences to the intuitionsbehind the grammar used, it turned out that thesame classification can be used to minimize thenumber of wrong hypothesis pertaining to emptyproductions in the grammar,We found a very useful correspondence b tweenan observable physical phenomenon-the prosodicinformation associated with an utterance-and atheoretical construct of formal inguistics-the lo-cation of empty elements in the respective deriva-tion.
The method has been successfully imple-mented and is currently being refined by train-ing the classifier on a much larger set of examplesand by integrating categorial information aboutthe relevant positions into the probability scorefor the various kind of boundaries.Contact:The authors can be contacted under the followingemail addresses:anton.batliner~phonetik.uni-muenchen.d400.defeldhaus@heidelbg.ibm.comstefan.geissler@heidelbg.ibm.comkiessling@informatik.uni-erlangen.detibor@heidelbg.ibm.comkompe@informatik.uni-erlangen.denoeth@informatik.uni-erlangen.deReferencesBatliner, Anton, Andreas Kieflling, Ralf Kompe,Heinrich Niemann, Elmar N6th: Syntactic-prosodic Labelling of Large Spontaneous SpeechData-bases.
In Int.
Conf.
on Spoken LanguageProcessing, Philadelphia.
1996.
(to appear).Bear, John.
and Patti Price: Prosody, Syntax, andParsing.
In Proceedings of the 28th Conferenceof the Association for Computational Lingus-tics.
1990. pp.
17-22.Beckman, Mary E. and Ayers, Gayle M.: Guide-lines for ToBI transcription, version 2.
De-partment of Linguistics, Ohio State University.1994.Borsley, Robert.
: Phrase Structure Grammar andthe Barrier Conception of Clause Structure.
In:Linguistics, 27.
1989. pp.
843-863.Feldhaus, Anke and Tibor Kiss: KategorialeEtikettierung der Karlsruher Dialoge, Vl.
;ItB-MOBIL-Memo Nr 94, IBM Deutschland Infor-mationssysteme, H idelberg.
1995.Kieflling, Andreas: Extraktion und Klassifika-tion prosodischer Merkmale in der automatis-chen Sprachverarbeitung, PhD thesis.
Univer-sit,it Erlangen-N/irnberg.
1996.
(to appear).Kiss, Tibor and Birgit Wesche: Verb order andHead-Movement i  German.
In: Herzog, O./C.-R. Rollinger (eds.
): Text Understanding inLILOG.
Integrating Artificial Intelligence andComputational Linguistics.
Springer, pp.
216-240, Berlin.
1991.Marcus, Mitchell and Donald Hindle: DescriptionTheory and Intonation Boundaries.
In: Alt-mann, Gerry (ed.
): Cognitive Models of SpeechProcessing.
The MIT Press, Cambridge.
1990.pp.
483-512.Ostendorf, Mari and N.M. Veilleux: A Hierarchi-cal Stochastic Model for Automatic Predictionof Prosodic Boundary Location.
In: Computa-tional Linguistics, Vol.
20.
1994. pp.
27-53.Pollard, Carl and Ivan A.
Sag: Head-drivenPhrase Structure Grammar, Univ.
of ChicagoPress, Chicago.
1994.Reyelt, Matthias : Consistency of Prosodic Tran-scriptions Labelling Experiments with Trainedand Untrained Transcribers, Proc.
XIIIth Int.Cong.
of Phonetic Sciences, Stockholm, Vol.
4.1995. pp.
212-215.Wahlster, Wolfgang: Verbmobih Ubersetzung yonVerhandlungsdialogen.
V1~IU~MOBlI,-Report 1.DFKI Saarbrficken.
1993.Wang, Michelle Q. and Julia Hirschberg: Au-tomatic Classification of Intonational PhraseBoundaries.
In: Computer Speech & Language,Vol.
6.
1992. pp.
175-190.76
