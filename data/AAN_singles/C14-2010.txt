Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,pages 44?47, Dublin, Ireland, August 23-29 2014.MultiDPS ?
A multilingual Discourse Processing SystemDaniel Alexandru Anechitei?Al.
I. Cuza?
University of IasiFaculty of Computer Science16, General Berthelot St., 700483, Iasi, Romaniadaniel.anechitei@info.uaic.roAbstract1This paper presents an adaptable online Multilingual Discourse Processing System (Mul-tiDPS), composed of four natural language processing tools: named entity recognizer, anapho-ra resolver, clause splitter and a discourse parser.
This NLP Meta System allows any user torun it on the web or via web services and, if necessary, to build its own processing chain, byincorporating knowledge or resources for each tool for the desired language.
In this paper ispresented a brief description for each independent module, and a case study in which the sys-tem is adapted to five different languages for creating a multilingual summarization system.1 IntroductionThis paper describes a multilingual discourse processing system (MultiDPS) consisting in four dif-ferent modules: Named Entity Recognizer (NER), Anaphora Resolver (AR), Clause Splitter (CS),Discourse Parser (DP), and for the summarization scope, the proper summarizer (SUM).
This systemcan run online via web services such that it can be accessed from any programming environment andthe architecture allows each tool to be individually trained.
Each task, except for discourse parsing,MultiDPS?s component tools combines machine learning techniques with heuristics to learn from amanually created corpus (a gold corpus of discourse trees is very difficult to obtain due to the com-plexity of the task).
The complexity of the processing tasks (reaching to discourse analysis) and themultilingual capabilities, make MultiDPS an important system in the field of natural language pro-cessing.2 System DesignThe MultiDPS architecture includes two main parts as it can be seen in Figure 1.Figure 1: The MultiDPS?s component modules and supported workflowsThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/44The Prerequisite part includes usually known basic NLP tools and it is a primary step for obtainingthe input for MultiDPS.
The system consists of four different modules which will be discussed in de-tail in the next sections.
All modules implement a language independent vision in which the algorithmis separated from linguistic details.
Each phase and the output of each module is an input for a nextphase, not necessarily the immediately next one, as it is depicted in Figure 1 (dotted arrows suggestdifferent paths that the system supports).
Depending on individual needs or on the existence of specificresources (manual annotated corpora for a specific language), different language processing chains canbe created.
The entire system is designed in such a way that each individual module brings an extraannotation to the text therefore, when building a processing chain, some modules can be skipped.2.1 Named Entity RecognizerNamed Entity Recognition (NER) is a computational linguistic task that seeks to classify sequences ofwords in predefined categories.
In this approach the categories are organized under four top level clas-ses (PERSON, LOCATION, ORGANIZATION and MISC) and a total of nine subclasses.In order to identify the type of entities a voting system is implemented, being meant to decide be-tween different heuristics, which use automatically calibrated weights for different features, wherehigh scores are given for the entities within gazetteers.
Examples of features are: context bi/tri gramsfor different classes; appearance of a definite article; partial matches with gazetteers or within thesame text.2.2 Anaphora ResolutionThe AR module used in MultiDPS is based on the work done in Anechitei et al (2013), and improvedby adding a classifier, to predict whether there is a relation between each pair of noun phrases, result-ing in a hybrid approach.
Examples of features used to decide if there is a co-referential chain betweentwo noun phrases are: number agreement, gender agreement, and morphological description, imple-menting on the head noun; similarity between the two noun phrases, both at lemma level and text levelimplemented on the head noun and also on the entire noun phrase; condition if the two noun phrasesbelong to the same phrase or not.If the matching score given by the two methods is greater than an automatically computed thresh-old, then the actual noun phrase is added to already existing chain of referential expressions attachedto the noun phrase, and all the features are copied onto the list of features of the new referential ex-pression.
If there is no previous noun phrase, for which the matching score to be greater than thethreshold, then a new co-referential chain is created containing only the actual noun phrase along withits features.2.3 Clause SplitterA clause is a grammatical unit comprising a predicate and an explicit or implied subject, and expressesa proposition.
For the present work, the delimitation of clauses follows the work done in Anechitei etal (2013) and starts from the identification of verbs and verb compounds.
Verb compounds are se-quences of more than one verb in which one is the main verb and the others are auxiliaries (?is writ-ing?, ?like to read?).
Examples of features used to build the model of compound verbs are: distancebetween the verbs; the existence of punctuation or markers between them; the lemma and the morpho-logical description of the verbs, etc.The semantics of the compound verbs makes it necessary to take the whole construction togethernot putting boundary in the interior, so that the clause does not lose its meaning.
Clause boundaries arelooked between verbs and compound verbs which are considered the pivots of clauses.
The exact loca-tion of a boundary is, in many cases, best indicated by discourse markers.
A discourse marker is aword, or a group of words, that also have the function to indicate a rhetorical relation between twoclauses.
The features used to build the marker?s model are: the lemma and the context of the markerexpressed as configurable length sequences of POS tags and the distance from the verb in front of it.When markers are missing, boundaries can still be indicated by statistical methods, trained on ex-plicit annotations.
The weights of the features are tuned like in previous examples, by running the cal-ibration system on the manual annotated corpora and creating the models using MaxEnt1 library.1 The Maximum Entropy Framework: http://maxent.sourceforge.net/about.html452.4 Discourse ParserThe approach to discourse parsing implemented in MultiDPS follows the one described in Anechitei etal (2013) and is a symbolic approach rooted on (Marcu, 1999).
The generated discourse trees put inevidence only the nuclearity of the nodes, while the name of relations is ignored.
The discourse parseradopts an incremental policy in developing the trees and it is constrained by two general principles,well known in discourse parsing: sequentiality of the terminal nodes (Marcu, 2000) and attachmentrestricted to the right frontier (Cristea, 2005).
The algorithm involves a generate-rank-evaluate meth-od by generating a forest of developing trees at each step, followed by heuristics for ranking and eval-uating the trees.
The heuristics are suggested by both Veins Theory (Cristea et al, 1998) and CenteringTheory (Grosz et al, 1995).
The aim of these heuristics is to assign scores to the developing trees andalso to master the exponential explosion of the developing structure.2.5 The SummarizerFor the summarization purpose, the discourse structure gives more information than properly needed.The summary is achieved by trimming unimportant clauses/sentences on the basis of the relative sali-ency, cohesion and coherence properties.
For each discourse unit, a score is attached and reflects theproperties mentioned above.
Each component of MultiDPS contributes to the calculation of this score.3 Implementation of the modulesThe main idea behind the system architecture is that, if a module is fuelled with appropriate languageresources, it can be put to work on any language.
For the Romanian language, the input for MultiDPSis obtained using a deep noun phrase chunker (Simionescu, 2011) and for the English language usingthe Stanford Parser (Socher et al, 2013).
All the resources (manually annotated corpora for Englishand Romanian) are available for download.The clear benefit of this system architecture using web services is that if an improvement is made ina certain module, the results will be propagated through the others, without the need of human inter-vention.
Figure 2 illustrates the web interface for the discourse parser, where the XML annotations aremapped in a visual mode.Figure 2: View of the Discourse Parser web application that illustrates all annotations.In addition to the web applications and the core of the system (each module can be used as a library),what is made available is a wide range of free additional tools like online annotation services and cali-bration systems for each individual module.
MultiDPS was easily adapted for other languages wherethere was input provided for the system entry and training corpus for each module.4 Experiments and resultsIn this paper I present the results obtained after combining all the modules to create a multilingualsummarization system.
The results were obtained after attending an international workshop on sum-marization (Kubina et al., 2013), where the objective of each participant was to compute a maximum46250 words summary for each document for at least two of the dataset languages (30 documents perlanguage).
The submitted summaries were evaluated using ROUGE metric (Lin, 2004) and presentedin the next table, where the oracle in the table represents the ?perfect summary?
:Language Systembaseline s1 s2 s3 s4 s5 s6 oraclebg 0.28540.31900.29550.29690.29740.3966de 0.25290.34140.31980.33410.32030.3675el 0.28990.32290.27770.27470.26980.3775en 0.41130.32730.27810.27990.27650.36380.34110.5554ro 0.31250.33370.290480.30060.29850.4361Table 1: ROUGE-1 average for all five languages(Bulgarian, German, Greek, English and Romanian)Nevertheless, the results are encouraging for this complex system (s1 is the id of the system pre-sented in this paper).5 ConclusionsMultiDPS?s strength is manifested through its online availability and the existence of the online ser-vices for creating corpora for each module.
Moreover, considering that the results obtained by puttingtogether all the modules are similar for different languages, the system can be regarded as having lan-guage-wide validity.ReferenceBarbara J. Grosz, Aravind K. Joshi and Scott Weinstein.
1995.
Centering: A framework for modeling the localcoherence of discourse.
Computational Linguistics, 21(2), pages 203?226.Chin-Yew Lin.
2004.
Rouge: A package for automatic evaluation of summaries.
In Proceedings of the ACLWorkshop on Text Summarization Branches Out, Barcelona, Spain.Dan Cristea, Nancy Ide, Laurent Romary.
1998.
Veins theory: A model of global discourse cohesion and coher-ence.
In Proceedings of the 17th   international conference on Computational linguistics, pages 281-285, Mon-treal.Dan Cristea.
2005.
The Right Frontier Constraint Holds Unconditionally.
In Proceedings of the Multidiscipli-nary Approaches to Discourse (MAD'05), Chorin/Berlin, Germany.Daniel A. Anechitei, Dan Cristea, Ioannidis Dimosthenis, Eugen Ignat, Diman Karagiozov, Svetla Koeva, Ma-teusz Kope?, Cristina Vertan.
2013.
Summarizing Short Texts Through a Discourse-Centered Approach in aMultilingual Context.
In Neustein, A., Markowitz, J.A.
(eds.
), Where Humans Meet Machines: Innovative So-lutions to Knotty natural Language Problems.
Springer Verlag, Heidelber/New York.Daniel Marcu.
1999.
Discourse trees are good indicators of importance in text.
In I. Mani and M.
Maybury(eds.
), Advances in Automatic Text Summarization, pages 123-136, The MIT Press.Daniel Marcu.
2000.
The Theory and Practice of Discourse Parsing and Summarization.
The MIT Press.
Cam-bridge, Massachusetts.Jeff Kubina, John M. Conroy, Judith D. Schleisinger.
2013.
ACL 2013 MultiLing Pilot Overview.
In Proceedingsof MultiLing 2013 Workshop on Multilingual Multi-document Summarization, Sofia, Bulgaria, pages 29-38,workshop in conjunction with the 51th Annual Meeting of the Association for Computational Linguistics(ACL 2013).Radu Simionescu.
2011.
Romanian Deep Noun Phrase Chunking Using Graphical Grammar Studio.
In Pro-ceedings of The International Conference on Resources and tools for Romanian Language.Richard Socher, John Bauer, Christopher D. Manning, Andrew Y. Ng.
2013.
Parsing with Compositional VectorGrammars.
In Proceedings of ACL.47
