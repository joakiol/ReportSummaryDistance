Automatic Acquisition of Hyponyms~om Large Text CorporaMart i  A. HearstComputer  Science Division, 571 Evans HallUn ivers i ty  of Cal i fornia,  BerkeleyBerkeley,  CA 94720andXerox Palo A l to  Research Centermart i~cs ,  berkeley, eduAbst rac tWe describe a method for the automatic acquisitionof the hyponymy lexical relation from unrestrictedtext.
Two goals motivate the approach: (i) avoid-ance of the need for pre-encoded knowledge and (ii)applicability across a wide range of text.
We identifya set of lexico-syntactic patterns that are easily rec-ognizable, that occur iYequently and across text genreboundaries, and that indisputably indicate the lexicalrelation of interest.
We describe a method for discov-ering these patterns and suggest hat other lexicalrelations will also be acquirable in this way.
A subsetof the acquisition algorithm is implemented and theresults are used to attgment and critique the struc-ture of a large hand-built hesaurus.
Extensions andapplications to areas uch as information retrieval aresuggested.1 In t roduct ionCurrently there is much interest in the automatic ac-quisition of lexiea\[ syntax and semantics, with thegoal of building up large lexicons for natural lainguage processing.
Projects that center around ex-tracting lexical information from Machine ReadableDictionaries (MRDs) have shown much success butare inherently limited, since the set of entries withina dictionary is fixed.
In order to find terms and ex-pressions that are not defined in MRDs we must turnto other textual resources.
For this purpose, we viewa text corpus not only as a source of information, butalso as a source of information about the language itis written in.When interpreting unrestricted, omain-independenttext, it is difficult to determine in advance what kindof infbrmation will be encountered and how it will beexpressed.
Instead of interpreting everything in thetext in great detail, we can searcil for specific lexicalrelations that are expressed in well-known ways.
Sur-prisingly useful information can be found with onlya very simple understanding of a text.
Consider thefollowing sentence: 1.
(SI) The  bow lu te ,  such as the  Bambara ndang,is plucked and has an ind iv idualcurved neck :for each string.Most fluent readers of English who }lave never be-fore encountered the term 'q3amhara ndang" will nev-ertheless from this sentence infer that a "Bambaraudang" is a kind of "bow Iute".
This is true even iftile reader has only a fuzzy conception of what a howlute is.
Note that the attthor of the sentence is not de-liberately defining the term, as would a dictionary ora children's book containing a didactic sentence likeA Bambara ndang is a kind of bow lute.
However,the semantics of the lexico-syntactic construction i -dicated by the pattern:(la) NPo ..... h as {NP1, NP2 .
.
.
.
(and Ior)} NP,,are such that they imply(lb) for all NP , ,  1 < i< n, hyponym(NPi,  NPo)Thus from sentence (SI) we concludehyponym ( "Barn bare n dang", "how lu re").We use the term hyponym similarly to the sense usedin (Miller et el.
1990): a concept represented by alexicaI item L0 is said to be a hyponym of the conceptrepresented by a lexical item LI if native speakers ofEnglish accept sentences constructed from the frameAn Lo is a (kind of) L1.
Here Lt is the hypernymof Lo and the relationship is reflexive and transitive,but not symmetric.This example shows a way to discover a hyponymiclexical relationship between two or more noun phrasesin a naturally-occurring text.
This approach is siml-lar in spirit to the pattern-based interpretation tech-niques being used in MRD processing.
For example,t All examples in this paper are real text, taken fromGrolter's Amerwan Acaderntc Encyclopedia(Groher tg00)AcrF.s DE COLING-92, NANTI~S, 23-28 Aol}r 1992 5 3 9 PROC.
OV COLING-92, NhNTIIS, AUG. 23-28, 1992(Alshawi 1987), in interpreting LDOCE definitions,uses a hierarchy of patterns which consist mainlyof part-of-speech indicators and wildcard characters.
(Markowitz e~ al.
1986), (Jensen & Binot 1987), and(Nakamura & Nagao 1988) also use pattern recogni-tion to extract semantic relations uch as taxonomyfrom various dictionaries.
(Ahlswede & Evens I988)compares an approach based on parsing Webster's7th definitions with one based on pattern recognition,and finds that for finding simple semantic relations,pattern recognition \[s far more accurate and efficientthan parsing.
The general feeling is that the struc-ture and function of MRDs makes their interpretationamenable to pattern-recognition techniques.Thus one could say by interpreting sentence (S1) ac-cording to (In-b) we are applying pattern-based rela-tion recognition to general texts.
Since one of thegoals of building a lexical hierarchy automaticallyis to aid in the construction of a natural anguageprocessing program, this approach to acquisition ispreferable to one that needs a complex parser ~ndknowledge base.
The tradeoff is that the the refor-mation acquired is coarse-grained.There are many ways that the structure of a lan-guage can indicate the meanings of lexical items, butthe difficulty lies in finding constructions that fre-quently and reliably indicate the relation of interest.It might seem tbat because free text is so varied inform and content (as compared with the somewhatregular structure of the dictionary) that it may notbe possible to find such constructions.
However, wehave identified a set of lexico-syntactic patterns, in-cluding the one shown in (In) above, that indicatethe hyponymy relation and that satisfy the followingdesiderata:(i) They occur frequently and in many text genres.
(ii) They (almost) always indicate the relation of in-terest.
(iii) They can be recognized with little or no pre-encoded knowledge.Item (i) indicates that the pattern will result in thediscovery of many instances of the relation, item (ii)that the information extracted will not be erroneous,and item (iii) that making use of the pattern does notrequire the tools that it is intended to help build.Finding instances of the hyponymy relation is usefulfor several purposes:Lexicon Augmentat ion .
Hyponymy relations canbe used to augment and verify existing lexicons, in-cluding ones built from MRDs.
Section 3 of thispaper describes an example, comparing results ex-tracted from a text corpus with information stored inthe noun hierarchy of WordNet ((Miller et al 1990)),a hand-built lexical thesaurus.Noun Phrase  Semantics.
Another purpose towhich these relations can be applied is the identifi-cation of the general meaning of an unfamiliar nounphrases.
For example, discovering the predicatehyponym( "broken bone", "injury")indicates that tbe term "broken bone" can be under-stood at some level as an "injury" without having todetermine the correct senses of the component wordsand how they combine.
Note also that a term like"broken bone" is not likely to appear in a dictionaryor lexicon, although it is a common locution.Semant ic  Relatedness In fo rmat ion .
There basrecently been work in the detection of semantically re-lated nouns via, for example, shared argument struc-tures (Hindle 1990), and shared dictionary definitioncontext (Wilks e?
al.
1990).
These approaches at-tempt to infer relationships among \[exical terms bylooking at very large text samples and determiningwhich ones are related in a statistically significantway.
The technique introduced in this paper can beseen as having a similar goal but an entirely differentapproach, since only one sample need be found in or-der to determine a salient relationship (and that sam-ple may be infrequently occurring or nonexistent).Thinking of the relations discovered as closely relatedsemantically instead of as hyponymic is most felic-itous when the noun phrases involved are modifiedand atypical.
Consider, for example, the predicatehyponym( "detonating explosive", "blasting agent")This relation may not be a canonical ISA relation butthe fact that it was found in a text implies that theterms' meanings are close.
Connecting terms whoseexpressions are quite disparate but whose meaningsare similar should be useful for improved synonym ex-pansion in information retrieval and for finding chainsof semantically related phrases, as used in the ap-proach to recognition of topic boundaries of (MorrisHirst 1991).
We observe that terms that occur in alist are often related semantically, whether they occurin a hyponymy relation or not.In the next section we outline a way to discover theselexico-syntactic patterns as well as illustrate those wehave found.
Section 3 shows the results of searchingtexts for a restricted version of one of the patterns andcompares the results against a hand-built hesaurus.Section 4 is a discussion of the merits of this workand describes future directions.2 Lexico-Syntactic Patternsfor HyponymySince only a subset of the possible instances of thehyponymy relation will appear in a particular form,we need to make use of as many patterns as possi-ble.
Below is a list of lexico-syntactie patterns thatindicate the hyponymy relation, followed by illustra-tive sentence fragments and the predicates that canACTI~S DE COLING-92, NANTES, 23-28 AOt~r 1992 5 4 0 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992be derived from them (detail about the environmentsurrounding tile patterns is omitted for simplicity):(2) .... h NP us {NP ,}* {(or \[ and)} NP... works  by such authors  as Her r i ck ,Go ldsmi th ,  and Shakespeare .
: ~.
hyf)onym I'~author", "Ilerrick'),llyponym( "author", "(;oldsmith "),hyponynl( "author", "Shakespeare")(3) NP {, NP} * {,} o,' other NPBru ises ,  wounds ,  broken bones or o therin ju r ies  .
.
.~... hyponym( "bruise".
"injury"),hyponym ( "wo und", "mj ury" ),hyponym( "broken bone", "injury")(4) NP {, NP}* {,} and other NP... temples ,  t reasur ies ,a l td  o therimpor tant  c iv ic  buildings.
:~- hyponym("tenlple", "civic' building"),hyponym( "treasury ", "civic building")(5) m, {,} .~clsa,,~y {NP 5* {o,. '
.
.a} NPAl l  common- law count r ies ,  includingCanada and England ...-~, hyponym( "Canada", "collllnou--law coontry"), f lyponym ( "Eng\]and", "common-law co lm -try")(6) NP {,} especially {NP ,}* {or\] and} NP.
.
.
most: European count r ies ,  espec ia l l yFrance, England, and Spain.~ hyponym( "France", "European country"),hyponym( "England", "European country"),hypouym( "Spain", "European country")When a relation hyponym(NPo, NI ' I )  is discov-ered, aside from some temmatiz ing and removal ofunwanted modifiers, tile uonn phrase is left as allatomic unit, not broken clown and analyzed.
I ra  moredetailed interpretation is desired, the results can bepassed on to a more intelligent or specialized languageanalysis component.
And, as mentioned above, thiskind of discovery procedure can be a partial solutionfor a problenr like noun phrase interpretation becauseat least part of the meaning of the phrase is indicatedby tile hyponymy relation.and we usually want them to be singular.
Adjecti-val quantiflers uch as "other" and "some" are usu-ally undesirable and can be eliminated in most caseswithout making the statement of tile hypouym rela-tion erroneous.
( 'omparat ives SUCh as "inlportaat"and "smaller" are usually best removed, since theirmeaning \[s relative and dependent on tile context inwhich they appear.I low much modification is desirable depends on theapplication to which the lexical relations will be put.For budding up a basic, general-domain thesaurus,single-word uouns and very cOnllnon colnpouuds aremost appropriate.
For a inore specialized domain,umre modified terms have their place.
Per example,noun phrases in ~he me(licai ?lontain otteu have sev-eral layers of modification which should be preservedin a taxonomy of medical terms.Other difficulties and concerns are discussed ill Sec-tion a.2.2  Discovery  o f  New Pat ternsHow can these patterns be found?
Initially we dis-covered patterns (1 ) -  (3) 5y observation, looldugthrough text and noticing die patterns and tile rela-tionships they indicate, lu order to find new patternsautomatical ly, we sketch the following procedure:1. l)ecide on a lexical relation, R, that is of interest,e.g., "gro up/member"(iu our formulation this isa subset of the hypouylny relation).2.
Gather a list of terms for which this rela-tion is known to hold, e.g., "England-country'.This list can be found autonmtically using themethod described here, bootstrapping from pat-terns found by hand, or by bootstrapping froman existing lexicon or knowledge base.3.
Find places in tile corpus where these expressionsoccur syntactically near one another and recordthe environment.4.
t,'ind the commonaflties among these environ-i~leuts and hypothesize that corn.men ones yieldpatterns that indicate the relation of interest.5.
Once a new pattern has been positively identi-fied, use it to gather more instances of the targetrelation and go to Step 2.2.1  Some Cons iderat ionsIn example (4) above, the full noun phrase corre-sponding to the hypernym is "other important civicbuildings".
This illustrates a difficulty that arisesfrom using free text as the data source, as opposedto a dictionary - often the form that a noun phraseoccurs in is not what we would like to record.
Forexample, nouns frequently occur in their plural formWe tried this procedure by hand using just one pairof terms at a time.
In the first case we tried the"Fngland-country" example, and with just this pairwe tound uew patterns (4) and (5), as well as (1)(3) which were already known.
Next we tried "tank-vehicle" and discovered a very productive pattern,pattern (6).
(Note that for this pattern, even thoughit has an emphatic element, this does not affect thefact that the relation indicated is hypouymic.
)AcrEs DE COLING-92, N^mEs, 23-28 hotrr 1992 5 4 1 l)Roc, ov COLING-92, NAbrrEs, AUG. 23-28, 1992We have tried applying this technique to meronymy(i.e., the part/whole relation), but without great suc-cess.
The patterns fotu~.d for this relation do not tendto uniquely identify it, but can be used to expressother relations as well.
It may be the case that inEnglish the hyponymy relation is especially amenableto this kind of analysis, perhaps due to its "naming"nature.
However, we have bad some success at iden-tification of more specific relations, such as patternsthat indicate certain types of proper nouns.We have not implemented an automatic version ofthis algorithm, primarily because Step 4 is underde-termined.2.3 Related WorkThis section discusses work in acquisition of lexical in-formation from text corpora, although as mentionedearlier, significant work has been done in acquiringlexical information from MRDs.
(Coates-Stephens 1991) acquires semantic descrip-tions of proper nouns in a system called FUNES.
FU-NES attempts to fill in frame roles, (e.g., name, age~origin, position, and works-for, for a person frame)by processing newswire text.
This system is simi-lar to the work described here in that it recognizessome features of the context in which the proper nounoccurs in order to identify some relevant semanticattributes.
For instance.
Coates-Stephens mentionsthat "known as" can explicitly introduce meaningsfor terms, as can appositives.
We also have consid-ered these markers, hut the tbrmer often does notcleanly indicate "another name for" and the latter isdifficult to recognize accurately.
FUNES differs quitestrongly from our approach in that, because it is ableto fill in many kinds of frame roles, it requires a parserthat produces a detailed structure, and it requires adomain-dependent k owlege base/lexicon.
(Velardi & Pazienza 1989) makes use of hand-codedselection restriction and conceptual relation rules inorder to assign case roles to lexical items, and (Ja-cobs & Zernik 1988) uses extensive domain knowledgeto fill in missing category information for unknownwords.Work on acquisition of syntactic information fromtext corpora includes Brent's (Brent 1991) verbsubcategorization frame recognition technique andSmadja's (Smadja & McKeown 1990) collocation ac-quisition algorithm.
(Calzolari & Bindi 1990) usecorpus-based statistical association ratios to deter-mine lexical information such as prepositional com-plementation relations, modification relations, andsignificant compounds.Our methodology is similar to Brent's in its effortto distinguish clear pieces of evidence from ambigu-ous ones.
The assumption is that that given a largeenough corpus, the algorithm can afford wait untilit encounters clear examples.
Brent's algorithm re-lies on a clever trick: in the configuration of interest(in this case, verb valence descriptions), where nounphrases are the source of ambiguity, it uses only sen-tences which have pronouns in the crucial position,since pronouns do not allow this ambiguity.
Thisapproach is qnite effective, but the disadvantage isthat it isn't clear that it is applicable to any othertasks.
The approach presented in this paper, usingthe algorithm sketched in the previous ubsection, ispotentially extensible.3 Incorporating Results i n toWordNetTo validate this acquisition method, we compared theresults of a restricted version of the algorithm withinformation found in WordNet.
2 WordNet (Milleret al 1990) is a hand-built online thesaurus whoseorganization is modeled after the results of psycbolin-guistic research.
To use tile authors' words, Wordnet"... is an attempt o organize lexical information interms of word meanings, rather than word forms.
Inthat respect, WordNet resembles a thesaurus morethan a dictionary ..." To this end, word forms withsynonymous meanings are grouped into sets, calledsynsets.
This allows a distinction to be made be-tween senses of homographs.
For example, the noun"board" appears in the synsets {board, plank} and{board, committee}, and this grouping serves for themost part as the word's definition.
In version 1.1,WordNet contains about 34,000 noun word forms,including some compounds and proper nouns, orga-nized into about 26,000 synsets.
Noun synsets areorganized hierarchically according to the hyponymyrelation with implied inheritance and are further dis-tinguished by values of features uch as meronymy.WordNet's coverage and structure are impressive andprovide a good basis for an automatic acquisition al-gorithm to build on.When comparing a result hyponym(No,Nt) to thecontents of WordNet's noun hierarchy, three kinds ofoutcomes are possible:Verify.
If both No and Nt are in WordNet, and if therelation byponym(No,N1) is in the hierarchy (possi-bly througi~ transitive closure) then the thesaurus iverified.Cr i t ique.
If both No and N1 are in WordNet, and ifthe relation hyponym(No, N1) is not in the hierarchy(even through transitive closure) then the thesaurusis critiqued, i.e., a new set of hyponym connections isuggested.Augment .
If one or both of No and NI are notpresent then these noun phrases and their relationare suggested as entries.As an example of critiquing, consider the following2The author thanks Miller, et al, for the distribution ofWordNet.AcrEs DE COL1NG-92, NANTES, 23-28 AoU'r 1992 5 4 2 PRec.
OF COLING-92, NANTES, AUG. 23-28, 1992sentence and derived relation:(S2) Other  input -output  dev?ces ,  such aspr in ters ,  co lo r  p lo tzers ,  .
.
.~ hyponym('~rinter','~npnt-mltput device")The text indicates that a printer is a kind of input-output device.
Figure 1 indicates tile portion of tilehyponymy relation in WordNet's noun hierarchy thathas to do with printers and devices.
Note ;althoughthe terms device and printer are present, they are notlinked in such as way as to allow the easy insertionUO device under the more general dewce and over themore specific printer.
Although it is not obvious whatto suggest to fix this portion of the hierarchy fromthis one relation ~done, it is clear that its discoveryhighlights a trouble spot ill tile structure.,__/_"-._._,Figure t: A Fragment of the WordNet Noun Hier-archy.
Syasets are enclosed in braces; most synsetshave more connections than those shown.aereal~: ricu* ~heat*countries: Cuba Vietnam France*hydrocarbon: ethylene~ubstances: bromine* hydrogen*protozoa: parameclumliqueurs: anisette* absinthe*rocks: gralt lte*substances: phosphorus* nitrogen*species: stuatornis oilbirdsbivalves: scallop*fungi: smuts* rusts*fabrics: acrylics* nylon* silk*antibiotlcS: amplcillin erythromycln*institutions: temples kingseabirds: penguins albatross*flatworms: tapeworms pla~ariaamphibians: frogs*~aterfowl: duckslegumes: lentils* beans* nutsorg~lisms: horsetails ferns mossesrivers: Sevier Ca\[rson Humboldtfruit: olives* grapes*hydrocarbons: benzene gasol?neideologies: liberalism conservatismindustries: steel iron shoesmin.rals: pyrite* galenaphenomena: lightning*infection; menlngltisdyes: quercitronFigure 2: Relations found in Grolier's.
The formatis hypernym: hyponyrn list.
Entries with * indicaterelations found in WordNet.Most of the terms in WordNet's noun hierarchy areunmodified nouns or nouns with a single modifier.For this reason, ill this experiment we only extractedrelations consisting of mmmdif ied nouns in both thehypernym and hypouym roles (although determinersare allowed and a very small set of quantifier ad-jectives: "some", "many", "certain", and "other").Making this restriction is also usethl because of thedifficulties with determining which modifiers are sig-nificant, as touched on above, and because it seemseasier to make a judgement call about the correctnessof the classification of unmodified nouns for evalua-tion purposes.Since we are trying to acquire lexical information ourparsing mechanism should not be one that requiresextensive lexicat information.
In order to detect thelexico-syntactic patterns, we use a unification-basedconstituent analyzer (taken from (Batali 1991)),which builds on the output of a part-or=speech tag-ger (Cutt ing el al.
1991).
(All code described in thisreport is written m Common Lisp and run on SunSparcStations.
)We wrote grammar  ules for the constituent analyzerto recognize the pattern in ( la) .
As mentioned above,in this experiment we are detecting only unmodifiednouns.
Therefore, when a noun is found in the hyper-nym position, that is, before the lexemes "such as",we check for the noun's inclusion in a relative clause,or as part of a larger noun phrase that includes anappositive or a parenthetical.
Using tile constituentanalyzer, it is not necessary to parse the entire sell-tence; instead we look at just enough local contextaround the iexical items in the pattern to ensure thattile nouns in tile pattern are isolated.After the hypernym is detected the hyponyms areidentified.
Often they occur ill a llst and each ele-ment ill the list holds a hyponym relation with thehypernym.
The main difficulty here lies m determin-ing the extent of the last term in the list.3.1 Results and EvaluationFigure 2 illustrates some of the results of a run ofthe acquisition algorithm on Grolier's American Aca-demic Encyelopedia(Grolier 1990), where a restrictedversion of pattern ( la)  is the target (space constraintsdo not allow a full listing of the results).
After the re-lations are found they are looked up in WordNet.
Weplaced the WordNet noun hierarchy into a b-tree datastructure for efficient retrieval and update and used abreadth-first-search to search through the transit iveclosure.Ont of 8.6M words of encyclopedia text, there areAcrEs DE COL1NG-92, NANt .
'F.S, 23-28 ho,,~'r 1992 5 4 3 Paoc.
ov COLING-92, NANTES, AUO.
23-28, 19927067 sentences that contain tile lexemes "such as"contiguously.
Out of these, 152 relations fit tile re-strictions of the experiment, namely that both thehyponyms and the hypernyms are unmodified (withthe exceptions mentioned above).
When the restric-tions were eased slightly, so that NPs consisting oftwo nouns or a present/past participle plus a nounwere allowed, 330 relations were found.
Wheu the lat-ter experiment was run o21 about 20M words of NewYork Times text, 3178 sentences contained "such as"contiguously, and 46 relations were found using thestrict no-modifiers criterion.Wilen the set of t52 Grolier's relations was looked upin WordNet, 180 out of the 226 mlique words involvedin the relations actually existed in the hierarchy, and61 out of the 106 feasible relations (i.e., relations inwhich both terms were already registered in Word-Net) were found.The quality of the relations found seems high over-all, although there are difficulties.
As to be expected,metonymy occurs, as seen in hyponym("king", "in-stitution").
A more common problem is under-specification.
For example, one relation is hy-ponym( "steatornis', "species"), which is problematicbecause what kind of species needs to be known andmost likely this reformation was mentioned in the pre-vious sentence.
Similarly, relations were found be-tween "device" and "plot", "metaphor", and "char-acter", underspecifying the fact that literary devicesof some sort are under discussion.Sometimes the relationship expressed is slightlyaskance of the norm.
For example, the algorithmfinds hyponym( "Washington", nationalist")and hy-ponym( "aircraft", "target") which are somewhat con-text and point-of-view dependent.
This is not neces-sarily a problem; as mentioned above, finding alter-native ways of stating similar notions is one of ourgoals.
However, it is important to try to distinguishthe more canonical and context-independent relationsfor entry in a thesaurus.There are a few relations whose hypernyms are veryhigh-level terms, e.g., "substance" aud "form".
Theseare not incorrect; they just may not be as useful asmore specific relations.Overall, the results are encouraging.
Although thenumber of relations found is small compared to thesize of the text used, this situation can he greatly im-proved in several ways.
Less stringent restrictions willincrease the numbers, as the slight loosening shownin the Grolier's experiment indicates.
A more savvygrammar for the constituent analyzer should also in-crease the results.3.2 Automatic UpdatingThe question arises as to how to automatically in-sert relations between terms into the hierarchy.
Thisinvolves two main difficulties.
First, if both lexicalexpressions are present in the noun hierarchy but oneor both }lave more than one sense, the algorithm ustdecide which senses to link together.
We have prelim-inary ideas as to how to work around this problem.Say the hyponym in question has only one sense, butthe hypernym has several.
Then the task is simplifiedto determining which sense of the hypernym to linkthe hypouym to.
We can then make use of a lexicaldisambiguation algorithm, e.g., (Hearst 1991), to de-termine which sense of the hypernym is being used iuthe sample sentence.Furthermore, since we've assumed the hyponym hasonly one main sense we could do tile following: Lookthrough a corpus for occurrences of the hyponym andsee if its environment tends to be similar to one of thesenses of its hypernym.
For example, if the hypernymis "bank" and the hyponym is "First National", ev-ery time, within a sample of text, the term "FirstNational" occurs, replace it with "bank", and thenrun the disambiguation algorithm as usual.
If thisterm can be positively classified as having one sense ofbank over the others, then this would provide strongevidence as to which sense of the hypernym to linkthe hypouym to.
This idea is purely speculative; wehave not yet tested it.The second main problem with inserting new rela-tions arises when one or both terms do not occur inthe hierarchy at all.
In this case, we have to deter-mine which, if any, existing synset the term belongsin and then do the sense determination mentionedabove.4 Conc lus ionsWe have described a low-cost approach for automaticacquisition of semantic lexical relations from uure-stricted text.
This method is meant to provide anincremental step toward the larger goals of naturallanguage processing.
Our approach is complementaryto statistically based approaches that find semanticrelations between terms, iu that ours requires a sin-gle specially expressed instance of a relation whilethe others require a statistically significant numberof generally expressed relations.
We've shown thatour approach is also useful as a critiquing componentfor existing knowledge bases and lexicons.We plan to test the pattern discovery algorithm onmore relations and on languages other than English(depending on the corpora available).
We would alsolike to do some analysis of the noun phrases that areacquired, and to explore the effects of various kinds ofmodifiers on the appropriateness of the noun phrase.We plan to do this in the context of analyzing envi-ronmental impact reports.Acknowledgements .
This work was supported inpart by an internship at tile Xerox Palo Alto ResearchCenter and in part by the University of California ndDigital Equipment Corporation under Digital's flag-AcrEs DE COLING-92, NANTES, 23-28 ^o~-r 1992 5 4 4 PRoc.
OF COLING-92.
NANTES, Auo.
23-28, 1992ship research project Sequoia 2000: Large CapacityObject Servers to Support Global Change Research.ReferencesAhlswede, T. & M. Evens (1988).
Parsing vs. textprocessing in the analysis of dictionary defini-tions.
Proceedings of the 26th Annual Meeting ofthe Association for Computational Linguistics,pages 217-224.Alshawi, H. (1987).
Processing dictionary definitionswith phrasal pattern hierarchies.
American Jour-nal of Computational Linguistics, 13(3):195 202.Batali, J.
(1991).
Automatic Acquisition and Use ofSome of the Knowledge in Physics Tezts.
PhDthesis, Massachusetts Institute of Technology,Artificial Intelligence Laboratory.Brent, M. R. (1991).
Automatic acquisition ofsubcat-egorization frames from untagged, free-text cor-pora.
In Proceedings of the 29th Annual Meet-ing of the Association fo'e Computational Lin-guistics.Calzolari, N. & R. Bindi (1990).
Acquisition of lexi-cal information from a large textual italian cor-pus.
In Proceedings of the Thirteenth Interna-tional Conference on Computational Linguistics,Helsinki.Coates-Stephens, S. (1991).
Coping with lexical in-adequacy - the automatic acquisition of propernouns from news text.
In The Proceedings of the7th Annual Conference of the UW Centre for theNew OED and Tezt Research: Using Corpora,pages 154-169, Oxford.Cutting, D., J. Kupiec, J. Pedersen, & P. Sibun(1991).
A practical part-of-speech tagger.
Sub-mitted to The 3rd Conference on Applied NaturalLanguage Process*ng.Grolier (1990).
Academic American Encyclopedia.Grolier Electronic Publishing, Danbury, Con-neeticut.Jensen, K. & J.-L. Binot (1987).
Disambiguatingprepositional phrase attachments by using on-line dictionary definitions.
American Journal ofComputational Linguistics, 13(3):251-260.Markowitz, J., T. Ahlswede, & M. Evens (1986).
Se-mantically significant patterns in dictionary def-initions.
Proceedings of the 24th Annual Meet-ing of the Assoczation for Computational Lin-guistics, pages 112-119.Miller, G. A., R. Beckwith, C. Fellbaum, D. Gross, &K. J. Miller (1990).
Introduction to wordnet: Anon-line lexieal database.
Journal of Le~xieography,3(4):235-244.Morris, J.
& G. Hirst (1991).
Lexical cohesion com-puted by tbesaural relations as an indicator ofthe structure of text.
Computational Lzngmstics,17(1):21-48.Nakamura, J.
& M. Nagao (1988).
Extraction of se-mantic inlbrmation t?om an ordinary english dic-tionary and its evaluation.
In Proceedings of theTwelfth International Conference on Computa-tional Linguistics, pages 459-464, Budapest.Smadja, F. A.
& K. R. McKeown (1990).
Automati-cally extracting and representing collocations forlanguage generation.
Proceedings ofthe 28th An-nual Meeting of the Association for Computa-tional Linguistics, pages 252-259.Velardi, P. & M. T. Pazienza (1989).
Computer aidedinterpretation of lexical cooccurrences.
Proceed-ings of the 27th Annual Meeting of the Associ-ation for Computational Linguistics, pages 185-192.Wilks, Y.
A., D. C. Fass, C. ruing Guo, J. E. McDon-ald, T. Plate, & B. M. Slator (1990).
Providingmachine tractable dictionary tools.
Journal ofMachzne Translation, 2.Hearst, M. A.
(1991).
Noun homograph disambigua-tion using local context in large text corpora.
InThe Proceedings of the 7th Annual Conferenceof the UW Centre for the New OED and TeztResearch: Using Corpora, Oxford.Hindle, D. (1990).
Noun classification from predicate-argument structures.
Proceedings ofthe 28th An-nual Meeting of the Association for Computa-tional Linguistics, pages 268-275.Jacobs, P. & U. Zernik (1988).
Acquiring lexicalknowledge from text: A case study.
In Proceed-ings of AAAI88, pages 739-744.ACrF~ DE COLING-92, NANTES, 23-28 AOt~T 1992 5 4 5 PRoc.
OF COLING-92, NANTnS.
AUO.
23-28, 1992
