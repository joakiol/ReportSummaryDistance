Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 224?231,New York, June 2006. c?2006 Association for Computational LinguisticsUnsupervised and Semi-supervised Learning of Tone and Pitch AccentGina-Anne LevowUniversity of Chicago1100 E. 58th St.Chicago, IL 60637 USAlevow@cs.uchicago.eduAbstractRecognition of tone and intonation is es-sential for speech recognition and lan-guage understanding.
However, most ap-proaches to this recognition task have re-lied upon extensive collections of man-ually tagged data obtained at substantialtime and financial cost.
In this paper,we explore two approaches to tone learn-ing with substantially reductions in train-ing data.
We employ both unsupervisedclustering and semi-supervised learningto recognize pitch accent in English andtones in Mandarin Chinese.
In unsu-pervised Mandarin tone clustering exper-iments, we achieve 57-87% accuracy onmaterials ranging from broadcast news toclean lab speech.
For English pitch accentin broadcast news materials, results reach78%.
In the semi-supervised framework,we achieve Mandarin tone recognition ac-curacies ranging from 70% for broadcastnews speech to 94% for read speech, out-performing both Support Vector Machines(SVMs) trained on only the labeled dataand the 25% most common class assign-ment level.
These results indicate that theintrinsic structure of tone and pitch accentacoustics can be exploited to reduce theneed for costly labeled training data fortone learning and recognition.1 IntroductionTone and intonation play a crucial role across manylanguages.
However, the use and structure of tonevaries widely, ranging from lexical tone which de-termines word identity to pitch accent signalling in-formation status.
Here we consider the recognitionof lexical tones in Mandarin Chinese syllables andpitch accent in English.Although intonation is an integral part of lan-guage and is requisite for understanding, recogni-tion of tone and pitch accent remains a challeng-ing problem.
The majority of current approaches totone recognition in Mandarin and other East Asiantone languages integrate tone identification with thegeneral task of speech recognition within a Hid-den Markov Model framework.
In some cases tonerecognition is done only implicitly when a wordor syllable is constrained jointly by the segmentalacoustics and a higher level language model and theword identity determines tone identity.
Other strate-gies build explicit and distinct models for the syl-lable final region, the vowel and optionally a finalnasal, for each tone.Recent research has demonstrated the importanceof contextual and coarticulatory influences on thesurface realization of tones.
(Xu, 1997; Shen, 1990)The overall shape of the tone or accent can be sub-stantially modified by the local effects of adjacenttone and intonational elements.
Furthermore, broadscale phenomena such as topic and phrase struc-ture can affect pitch height, and pitch shape may bevariably affected by the presence of boundary tones.These findings have led to explicit modeling of tonal224context within the HMM framework.
In additionto earlier approaches that employed phrase structure(Fujisaki, 1983), several recent approaches to tonerecognition in East Asian languages (Wang and Sen-eff, 2000; Zhou et al, 2004) have incorporated ele-ments of local and broad range contextual influenceon tone.
Many of these techniques create explicitcontext-dependent models of the phone, tone, or ac-cent for each context in which they appear, eitherusing the tone sequence for left or right context orusing a simplified high-low contrast, as is naturalfor integration in a Hidden Markov Model speechrecognition framework.
In pitch accent recognition,recent work by (Hasegawa-Johnson et al, 2004) hasintegrated pitch accent and boundary tone recogni-tion with speech recognition using prosodically con-ditioned models within an HMM framework, im-proving both speech and prosodic recognition.Since these approaches are integrated with HMMspeech recognition models, standard HMM trainingprocedures which rely upon large labeled trainingsets are used for tone recognition as well.
Othertone and pitch accent recognition approaches us-ing other classification frameworks such as supportvector machines (Thubthong and Kijsirikul, 2001)and decision trees with boosting and bagging (Sun,2002) have relied upon large labeled training sets -thousands of instances - for classifier learning.
Thislabelled training data is costly to construct, both interms of time and money, with estimates for some in-tonation annotation tasks reaching tens of times real-time.
This annotation bottleneck as well as a theo-retical interest in the learning of tone motivates theuse of unsupervised or semi-supervised approachesto tone recognition whereby the reliance on this of-ten scarce resource can be reduced.Little research has been done in the applicationof unsupervised and semi-supervised techniques fortone and pitch accent recognition.
Some prelimi-nary work by (Gauthier et al, 2005) employs self-organizing maps and measures of f0 velocity fortone learning.
In this paper we explore the useof spectral and standard k-means clustering for un-supervised acquisition of tone, and the frameworkof manifold regularization for semi-supervised tonelearning.
We find that in clean read speech, un-supervised techniques can identify the underlyingMandarin tone categories with high accuracy, whileeven on noisier broadcast news speech, Mandarintones can be recognized well above chance levels,with English pitch accent recognition at near thelevels achieved with fully supervised Support Vec-tor Machine (SVM) classifiers.
Likewise in thesemi-supervised framework, tone classification out-performs both most common class assignment anda comparable SVM trained on only the same smallset of labeled instances, without recourse to the un-labeled instances.The remainder of paper is organized as fol-lows.
Section 2 describes the data sets on whichEnglish pitch accent and Mandarin tone learningare performed and the feature extraction process.Section 3 describes the unsupervised and semi-supervised techniques employed.
Sections 4 and5 describe the experiments and results in unsuper-vised and semi-supervised frameworks respectively.Section 6 presents conclusions and future work.2 Data SetsWe consider two corpora: one in English for pitchaccent recognition and two in Mandarin for tonerecognition.
We introduce each briefly below.2.1 English CorpusWe employ a subset of the Boston Radio News Cor-pus (Ostendorf et al, 1995), read by female speakerF2B, comprising 40 minutes of news material.
Thecorpus includes pitch accent, phrase and boundarytone annotation in the ToBI framework (Silvermanet al, 1992) aligned with manual transcription andsyllabification of the materials.
Following earlier re-search (Ostendorf and Ross, 1997; Sun, 2002), wecollapse the ToBI pitch accent labels to four classes:unaccented, high, low, and downstepped high for ex-perimentation.2.2 Mandarin Chinese Tone DataMandarin Chinese is a language with lexical tonein which each syllable carries a tone and the mean-ing of the syllable is jointly determined by the toneand segmental information.
Mandarin Chinese hasfour canonical lexical tones, typically described asfollows: 1) high level, 2) mid-rising, 3) low falling-rising, and 4) high falling.1 The canonical pitch con-1For the experiments in this paper, we exclude the neutraltone, which appears on unstressed syllables, because the clear225Figure 1: Contours for canonical Mandarin tonestours for these tones appear in Figure 1.We employ data from two distinct sources in theexperiments reported here.2.2.1 Read SpeechThe first data set is very clean speech data drawnfrom a collection of read speech collected under lab-oratory conditions by (Xu, 1999).
In these mate-rials, speakers read a set of short sentences wheresyllable tone and position of focus were varied toassess the effects of focus position on tone realiza-tion.
Focus here corresponds to narrow focus, wherespeakers were asked to emphasize a particular wordor syllable.
Tones on focussed syllables were foundto conform closely to the canonical shapes describedabove, and in previous supervised experiments usinga linear support vector machine classifier trained onfocused syllables, accuracy approached 99%.
Forthese materials, pitch tracks were manually alignedto the syllable and automatically smoothed and time-normalized by the original researcher, resulting in 20pitch values for each syllable.2.2.2 Broadcast News SpeechThe second data set is drawn from the Voice ofAmerica Mandarin broadcast news, distributed bythe Linguistic Data Consortium2, as part of the TopicDetection and Tracking (TDT-2) evaluation.
Us-ing the corresponding anchor scripts, automaticallyword-segmented, as gold standard transcription, au-dio from the news stories was force-aligned to thetext transcripts.
The forced alignment employed thelanguage porting functionality of the University ofspeech data described below contains no such instances.2http://www.ldc.upenn.eduColorado Sonic speech recognizer (Pellom et al,2001).
A mapping from the transcriptions to Englishphone sequences supported by Sonic was createdusing a Chinese character-pinyin pronunciation dic-tionary and a manually constructed mapping frompinyin sequences to the closest corresponding En-glish phone sequences.32.3 Acoustic FeaturesUsing Praat?s (Boersma, 2001) ?To pitch?
and ?Tointensity?
functions and the alignments generatedabove, we extract acoustic features for the prosodicregion of interest.
This region corresponds to the?final?
region of each syllable in Chinese, includingthe vowel and any following nasal, and to the sylla-ble nucleus in English.4 For all pitch and intensityfeatures in both datasets, we compute per-speaker z-score normalized log-scaled values.
We extract pitchvalues from points across valid pitch tracked regionsin the syllable.
We also compute mean pitch acrossthe syllable.
Recent phonetic research (Xu, 1997;Shih and Kochanski, 2000) has identified signifi-cant effects of carryover coarticulation from preced-ing adjacent syllable tones.
To minimize these ef-fects consistent with the pitch target approximationmodel (Xu et al, 1999), we compute slope featuresbased on the second half of this final region, wherethis model predicts that the underlying pitch heightand slope targets of the syllable will be most accu-rately approached.
We further log-scale and normal-ize slope values to compensate for greater speeds ofpitch fall than pitch rise(Xu and Sun, 2002).We consider two types of contextualized featuresas well, to model and compensate for coarticula-tory effects from neighboring syllables.
The first setof features, referred to as ?extended features?, in-cludes the maximum and mean pitch from adjacentsyllables as well as the nearest pitch point or pointsfrom the preceding and following syllables.
Thesefeatures extend the modeled tone beyond the strictbounds of the syllable segmentation.
A second setof contextual features, termed ?difference features?,captures the change in pitch maximum, mean, mid-point, and slope as well as intensity maximum be-3All tone transformations due to third tone sandhi are ap-plied to create the label set.4We restrict our experiments to syllables with at least 50 msof tracked pitch in this final region.226tween the current syllable and the previous or fol-lowing syllable.In prior supervised experiments using supportvector machines(Levow, 2005), variants of this rep-resentation achieved competitive recognition levelsfor both tone and pitch accent recognition.
Sincemany of the experiments for Mandarin Chinese tonerecognition deal with clean, careful lab speech, weanticipate little coarticulatory influence, and usea simple pitch-only context-free representation forour primary Mandarin tone recognition experiments.For primary experiments in pitch accent recognition,we employ a high-performing contextualized repre-sentation in (Levow, 2005), using both ?extended?and ?difference?
features computed only on the pre-ceding syllable.
We will also report some contrastiveexperimental results varying the amount of contex-tual information.3 Unsupervised and Semi-supervisedLearningThe bottleneck of time and monetary cost asso-ciated with manual annotation has generated sig-nificant interest in the development of techniquesfor machine learning and classification that reducethe amount of annotated data required for train-ing.
Likewise, learning from unlabeled data alignswith the perspective of language acquisition, aschild learners must identify these linguistic cate-gories without explicit instruction by observation ofnatural language interaction.
Of particular interestare techniques in unsupervised and semi-supervisedlearning where the structure of unlabeled examplesmay be exploited.
Here we consider both unsuper-vised techniques with no labeled training data andsemi-supervised approaches where unlabeled train-ing data is used in conjunction with small amountsof labeled data.A wide variety of unsupervised clustering tech-niques have been proposed.
In addition to classicclustering techniques such as k-means, recent workhas shown good results for many forms of spec-tral clustering including those by (Shi and Ma-lik, 2000; Belkin and Niyogi, 2002; Fischer andPoland, 2004).
In the unsupervised experiments re-ported here, we employ asymmetric k-lines clus-tering by (Fischer and Poland, 2004) using codeavailable at the authors?
site, as our primary unsu-pervised learning approach.
Asymmetric clusteringis distinguished from other techniques by the con-struction and use of context-dependent kernel radii.Rather than assuming that all clusters are uniformand spherical, this approach enhances clustering ef-fectiveness when clusters may not be spherical andmay vary in size and shape.
We will see that thisflexibility yields a good match to the structure ofMandarin tone data where both shape and size ofclusters vary across tones.
In additional contrastiveexperiments reported below, we also compare k-means clustering, symmetric k-lines clustering (Fis-cher and Poland, 2004), and Laplacian Eigenmaps(Belkin and Niyogi, 2002) with k-lines clustering.The spectral techniques all perform spectral decom-position on some representation of the affinity or ad-jacency graph.For semi-supervised learning, we employ learn-ers in the Manifold Regularization framework de-veloped by (Belkin et al, 2004).
This work postu-lates an underlying intrinsic distribution on a low di-mensional manifold for data with an observed, am-bient distribution that may be in a higher dimen-sional space.
It further aims to preserve locality inthat elements that are neighbors in the ambient spaceshould remain ?close?
in the intrinsic space.
A semi-supervised classification algorithm, termed ?Lapla-cian Support Vector Machines?, allows training andclassification based on both labeled and unlabeledtraining examples.We contrast results under both unsupervised andsemi-supervised learning with most common classassignment and previous results employing fully su-pervised approaches, such as SVMs.4 Unsupervised Clustering ExperimentsWe executed four sets of experiments in unsu-pervised clustering using the (Fischer and Poland,2004) asymmetric clustering algorithm.4.1 Experiment ConfigurationIn these experiments, we chose increasingly diffi-cult and natural test materials.
In the first experi-ment with the cleanest data, we used only focusedsyllables from the read Mandarin speech dataset.In the second, we included both in-focus (focused)227and pre-focus syllables from the read Mandarinspeech dataset.5 In the third and fourth experiments,we chose subsets of broadcast news report data,from the Voice of America (VOA) in Mandarin andBoston University Radio News corpus in English.In all experiments on Mandarin data, we per-formed clustering on a balanced sampling set oftones, with 100 instances from each class6, yield-ing a baseline for assignment of a single class to allinstances of 25%.
We then employed a two-stage re-peated clustering process, creating 2 or 3 clusters ateach stage.For experiments on English data, we extracted aset of 1000 instances, sampling pitch accent typesaccording to their frequency in the collection.
Weperformed a single clustering phase with 2 to 16clusters, reporting results at different numbers ofclusters.For evaluation, we report accuracy based on as-signing the most frequent class label in each clusterto all members of the cluster.4.2 Experimental ResultsWe find that in all cases, accuracy based on theasymmetric clustering is significantly better thanmost common class assignment and in some casesapproaches labelled classification accuracy.
Unsur-prisingly, the best results, in absolute terms, areachieved on the clean focused syllables, reaching87% accuracy.
For combined in-focus and pre-focussyllables, this rate drops to 77%.
These rates con-trast with 99-93% accuracies in supervised classi-fication using linear SVM classifiers with severalthousand labelled training examples(Surendran etal., 2005).On broadcast news audio, accuracy for Mandarinreaches 57%, still much better than the 25% level,though below a 72% accuracy achieved using super-vised linear SVMs with 600 labeled training exam-ples.
Interestingly, for English pitch accent recogni-tion, accuracy reaches 78.4%, aproaching the 80.1%5Post-focus syllables typically have decreased pitch heightand range, resulting in particularly poor recognition accuracy.We chose not to concentrate on this specific tone modelingproblem here.6Sample sizes were bounded to support rapid repeated ex-perimentation and for consistency with the relatively smallVOA data set.Figure 2: Differences for alternative unsupervisedlearners across numbers of clusters.accuracy achieved with SVMs on a comparable datarepresentation.4.3 Contrastive ExperimentsWe further contrast the use of different unsupervisedlearners, comparing the three spectral techniquesand k-means with Euclidean distance.
All contrastsare presented for English pitch accent classification,ranging over different numbers of clusters, with thebest parameter setting of neighborhood size.
The re-sults are illustrated in Figure 2.
K-means and theasymmetric clustering technique are presented forthe clean focal Mandarin speech under the standardtwo stage clustering, in Table 1.The asymmetric k-lines clustering approach con-sistently outperforms the corresponding symmetricclustering learner, as well as Laplacian Eigenmapswith binary weights for pitch accent classification.Somewhat surprisingly, k-means clustering outper-forms all of the other approaches when producing 3-14 clusters.
Accuracy for the optimal choice of clus-ters and parameters is comparable for asymmetrick-lines clustering and k-means, and somewhat bet-ter than all other techniques considered.
The care-ful feature selection process for tone and pitch ac-cent modeling may reduce the difference betweenthe spectral and k-means approaches.
In contrast,for the four tone classification task in Mandarin us-ing two stage clustering with 2 or 3 initial clusters,the best clustering using asymmetric k-lines stronglyoutperforms k-means.We also performed a contrastive experiment inpitch accent recognition in which we excluded con-textual information from both types of contextualfeatures.
We find little difference for the majority of228Asymm.
K-meansClear speech 87% 74.75%Table 1: Clustering effectiveness for asymmetric k-lines and k-means on clear focused speech.Figure 3: Scatterplot of pitch height vs pitch slope.Open Diamond: High tone (1), Filled black traingle:Rising tone (2), Filled grey square: Low tone (3), X:Falling tone (4)the unsupervised clustering algorithms, with resultsfrom symmetric, asymmetric and k-means cluster-ing differing by less than 1% in absolute accuracy.It is, however, worth noting that exclusion of thesefeatures from experiments using supervised learningled to a 4% absolute reduction in accuracy.4.4 DiscussionAn examination of both the clusters formed and thestructure of the data provides insight into the effec-tiveness of this process.
Figure 3 displays 2 dimen-sions of the Mandarin four-tone data from the fo-cused read speech, where normalized pitch mean ison the x-axis and slope is on the y-axis.
The sepa-ration of classes and their structure is clear.
One ob-serves that rising tone (tone 2) lies above the x-axis,while high-level (tone 1) lies along the x-axis.
Low(tone 3) and falling (tone 4) tones lie mostly belowthe x-axis as they generally have falling slope.
Lowtone (3) appears to the left of falling tone (4) in thefigure, corresponding to differences in mean pitch.In clustering experiments, an initial 2- or 3-waysplit separates falling from rising or level tonesbased on pitch slope.
The second stage of cluster-ing splits either by slope (tones 1,2, some 3) or bypitch height (tones 3,4).
These clusters capture thenatural structure of the data where tones are charac-terized by pitch height and slope targets.5 Semi-supervised LearningBy exploiting a semi-supervised approach, we hopeto enhance classification accuracy over that achiev-able by unsupervised methods alone by incorporat-ing small amounts of labeled data while exploitingthe structure of the unlabeled examples.5.1 Experiment ConfigurationWe again conduct contrastive experiments usingboth the clean focused read speech and the morechallenging broadcast news data.
In each Mandarincase, for each class, we use only a small set (40) oflabeled training instances in conjunction with an ad-ditional sixty unlabeled instances, testing on 40 in-stances.
For English pitch accent, we restricted thetask to the binary classification of syllables as ac-cented or unaccented.
For the one thousand sampleswe proportionally labeled 200 unaccented examplesand 100 accented examples.
7We configure the Laplacian SVM classificationwith binary neighborhood weights, radial basis func-tion kernel, and cosine distance measure typicallywith 6 nearest neighbors.
Following (C-C.Chengand Lin, 2001), for   -class classification we train	binary classifiers.
We then classify eachtest instance using all of the classifiers and assignthe most frequent prediction, with ties broken ran-domly.
We contrast these results both with conven-tional SVM classification with a radial basis func-tion kernel excluding the unlabeled training exam-ples and with most common class assignment, whichgives a 25% baseline.5.2 Experimental ResultsFor the Mandarin focused read syllables, we achieve94% accuracy on the four-way classification task.7The framework is transductive; the test samples are a subsetof the unlabeled training examples.229For the noisier broadcast news data, the accuracy is70% for the comparable task.
These results all sub-stantially outperform the 25% most common classassignment level.
The semi-supervised classifieralso reliably outperforms an SVM classifier with anRBF kernel trained on the same labeled training in-stances.
This baseline SVM classifier with a verysmall training set achieves 81% accuracy on cleanread speech, but only   35% on the broadcast newsspeech.
Finally, for English pitch accent recogni-tion in broadcast news data, the classifier achieves81.5%, relative to 84% accuracy in the fully super-vised case.6 Conclusion & Future WorkWe have demonstrated the effectiveness of bothunsupervised and semi-supervised techniques forrecognition of Mandarin Chinese syllable tones andEnglish pitch accents using acoustic features aloneto capture pitch target height and slope.
Althoughoutperformed by fully supervised classification tech-niques using much larger samples of labelled train-ing data, these unsupervised and semi-supervisedtechniques perform well above most common classassignment, in the best cases approaching 90%of supervised levels, and, where comparable, wellabove a good discriminative classifier trained on acomparably small set of labelled data.
Unsuper-vised techniques achieve accuracies of 87% on thecleanest read speech, reaching 57% on data from astandard Mandarin broadcast news corpus, and over78% on pitch accent classification for English broad-cast news.
Semi-supervised classification in theMandarin four-class classification task reaches 94%accuracy on read speech, 70% on broadcast newsdata, improving dramatically over both the simplebaseline of 25% and a standard SVM with an RBFkernel trained only on the labeled examples.Future work will consider a broader range of toneand intonation classification, including the richertone set of Cantonese as well as Bantu family tonelanguages, where annotated data truly is very rare.We also hope to integrate a richer contextual rep-resentation of tone and intonation consistent withphonetic theory within this unsupervised and semi-supervised learning framework.
We will further ex-plore improvements in classification accuracy basedon increases in labeled and unlabeled training exam-ples.AcknowledgementsWe would like to thank Yi Xu for granting accessto the read speech data, Vikas Sindhwani, MikhailBelkin, and Partha Niyogi for their implementationof Laplacian SVM, and Igor Fischer and J. Polandfor their implementation of asymmetric clustering.ReferencesMikhail Belkin and Partha Niyogi.
2002.
Laplacianeigenmaps and spectral techniques for embedding andclustering.
In Proceeding of NIPS?02.M.
Belkin, P. Niyogi, and V. Sindhwani.
2004.
Mani-fold regularization: a geometric framework for learn-ing from examples.
Technical Report TR-2004-06,University of Chicago Computer Science.P.
Boersma.
2001.
Praat, a system for doing phoneticsby computer.
Glot International, 5(9?10):341?345.C-C.Cheng and C-J.
Lin.
2001.
LIBSVM:a libraryfor support vector machines.
Software available at:http://www.csie.ntu.edu.tw/ cjlin/libsvm.I.
Fischer and J. Poland.
2004.
New methods for spectralclustering.
Technical Report ISDIA-12-04, IDSIA.H.
Fujisaki.
1983.
Dynamic characteristics of voice fun-damental frequency in speech and singing.
In The Pro-duction of Speech, pages 39?55.
Springer-Verlag.Bruno Gauthier, Rushen Shi, Yi Xu, and Robert Proulx.2005.
Neural-network simulation of tonal categoriza-tion based on f0 velocity profiles.
Journal of theAcoustical Society of America, 117, Pt.
2:2430.M.
Hasegawa-Johnson, Jennifer Cole, Chilin Shih abdKen Chen, Aaron Cohen, Sandra Chavarria, HeejinKim, Taejin Yoon, Sarah Borys, and Jeung-Yoon Choi.2004.
Speech recognition models of the interdepen-dence among syntax, prosody, and segmental acous-tics.
In HLT/NAACL-2004.Gina-Anne Levow.
2005.
Context in multi-lingual toneand pitch accent prediction.
In Proc.
of Interspeech2005 (to appear).M.
Ostendorf and K. Ross.
1997.
A multi-level modelfor recognition of intonation labels.
In Y. Sagisaka,N.
Campbell, and N. Higuchi, editors, ComputingProsody, pages 291?308.M.
Ostendorf, P. J.
Price, and S. Shattuck-Hufnagel.1995.
The Boston University radio news corpus.Technical Report ECS-95-001, Boston University.230B.
Pellom, W. Ward, J. Hansen, K. Hacioglu, J. Zhang,X.
Yu, and S. Pradhan.
2001.
University of Coloradodialog systems for travel and navigation.Xiao-Nan Shen.
1990.
Tonal co-articulation in Man-darin.
Journal of Phonetics, 18:281?295.Jianbo Shi and Jitendra Malik.
2000.
Normalized cutsand image segmentation.
IEEE Transactions on Pat-tern Analysis and Machine Intelligence, 22(8).C.
Shih and G. P. Kochanski.
2000.
Chinese tone model-ing with stem-ml.
In Proceedings of the InternationalConference on Spoken Language Processing, Volume2, pages 67?70.K.
Silverman, M. Beckman, J. Pitrelli, M. Osten-dorf, C. Wightman, P. Price, J. Pierrehumbert, andJ.
Hirschberg.
1992.
ToBI: A standard for labellingEnglish prosody.
In Proceedings of ICSLP, pages867?870.Xuejing Sun.
2002.
Pitch accent prediction using ensem-ble machine learning.
In Proceedings of ICSLP-2002.D.
Surendran, Gina-Anne Levow, and Yi Xu.
2005.
Tonerecognition in Mandarin using focus.
In Proc.
of Inter-speech 2005 (to appear).Nuttakorn Thubthong and Boonserm Kijsirikul.
2001.Support vector machines for Thai phoneme recogni-tion.
International Journal of Uncertainty, Fuzzinessand Knowledge-Based Systems, 9(6):803?813.C.
Wang and S. Seneff.
2000.
Improved tone recogni-tion by normalizing for coarticulation and intonationeffects.
In Proceedings of 6th International Confer-ence on Spoken Language Processing.Yi Xu and X.
Sun.
2002.
Maximum speed of pitchchange and how it may relate to speech.
Journal ofthe Acoustical Society of America, 111.C.X.
Xu, Y. Xu, and L.-S. Luo.
1999.
A pitch tar-get approximation model for f0 contours in Mandarin.In Proceedings of the 14th International Congress ofPhonetic Sciences, pages 2359?2362.Yi Xu.
1997.
Contextual tonal variations in Mandarin.Journal of Phonetics, 25:62?83.Y.
Xu.
1999.
Effects of tone and focus on the formationand alignment of f0 contours - evidence from Man-darin.
Journal of Phonetics, 27.J.
L. Zhou, Ye Tian, Yu Shi, Chao Huang, and EricChang.
2004.
Tone articulation modeling for Man-darin spontaneous speech recognition.
In Proceedingsof ICASSP 2004.231
