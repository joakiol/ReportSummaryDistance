Machine Translation Divergences:A Formal Description and ProposedSolutionBonnie J. Dorr*University of MarylandThere are many cases in which the natural translation of one language into another esults in avery different form than that of the original.
The existence of translation divergences (i.e., cross-linguistic distinctions) makes the straightforward transfer from source structures into targetstructures impractical.
Many existing translation systems have mechanisms for handling diver-gent structures but do not provide a general procedure that takes advantage of the systematicrelation between lexical-semantic structure and syntactic structure.
This paper demonstratesthat a systematic solution to the divergence problem can be derived from the formalization oftwo types of information: (1) the linguistically grounded classes upon which lexical-semanticdivergences are based; and (2) the techniques by which lexical-semantic divergences are resolved.This formalization is advantageous in that it facilitates the design and implementation f thesystem, allows one to make an evaluation of the status of the system, and provides a basis forproving certain important properties about he system.1.
IntroductionThere are many cases in which the natural translation of one language into anotherresults in a very different form than that of the original.
The existence of translationdivergences (i.e., cross-linguistic distinctions) makes the straightforward transfer fromsource structures into target structures impractical.
This paper demonstrates that a sys-tematic solution to the divergence problem can be derived from the formalization oftwo types of information: (1) the linguistically grounded classes upon which lexical-semantic divergences are based; and (2) the techniques by which lexical-semanticdivergences are resolved.
An important result of this formalization is the provision ofa framework for proving that the lexical-semantic divergence classification proposedin the current approach covers all source-language/target-language distinctions basedon lexical-semantic properties.
Other types of divergences and mismatches are outsideof the scope of this paper; these include distinctions based on purely syntactic informa-tion, idiomatic usage, aspectual knowledge, discourse knowledge, domain knowledge,or world knowledge/Although other translation approaches have attempted to account for divergences,the main innovation of the current approach is that it provides a formalization of thesedivergences and the techniques by which they are resolved.
This is advantageous froma computational point of view in that it facilitates the design and implementation of?
Department ofComputer Science, University of Maryland, A. V. Williams Building, College Park, MD20742, USA.1 The reader is referred to Dorr (1993a) for a discussion of how syntactic divergences are handled.Aspectual divergences are treated by Dorr (1992a).
The relatio.n of the current framework to other typesof knowledge outside of lexical semantics i  discussed by Dorr and Voss (1993b).?
1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 4(1) Thematic divergence:E: I like Mary ~ S: Maria me gusta a mi'Mary pleases me'(2) Promotional divergence:E: John usually goes home 4=~ S: Juan suele i ra casa'John tends to go home'(3) Demotional divergence:E: I like eating ~ G: Ich esse gem'I eat likingly'(4) Structural divergence:E: John entered the house 4=~ S: Juan entr6 en la casa'John entered in the house'(5) Conflational divergence:E: I stabbed John ~ S: Yo le di pu~aladas a Juan'I gave knife-wounds to John'(6) Categorial divergence:E: I am hungry ~ G: Ich habe Hunger'I have hunger'(7) Lexical divergence:E: John broke into the room ~ S: Juan forz6 la entrada l cuartoFigure 1 'John forced (the) entry to the room'Examples of translation divergences with respect o English, Spanish, and German.the system: the problem is clearly defined in terms of a small number  of divergencecategories, and the solution is systematically stated in terms of a uniform translationmapping  and a handful of simple lexical-semantic parameters.
In addition, the for-malization allows one to make an evaluation of the status of the system.
For example,given the formal description of the interlingua nd target-language root words, one isable to judge whether a particular target-language s ntence fully covers the conceptthat underlies the corresponding source-language s ntence.
Finally, the formalizationof the divergence types and the associated solution allows one to prove certain proper-ties about the system.
For example, one might want to determine whether the systemis able to handle two or more simultaneous divergences that interact in some way.With the mechanism of the current approach, one is able to prove formally that suchcases are handled in a uniform fashion.This paper will focus on the problem of lexical-semantic divergences and willprovide support for the view that it is possible to construct a finite cross-linguisticclassification of divergences and to implement a systematic mapping between theinterlingual representation and the surface syntactic structure that accommodates allof the divergences in this classification.
The types of divergences under considerationare those shown in Figure 1.
The first divergence type is thematic: in (1), the themeis realized as the verbal object (Mary) in English but as the subject (Maria) of themain verb in Spanish.
The second divergence type, promotional, is one of two headswitching divergence types: in (2), the modifier (usually) is realized as an adverbialphrase in English but as the main verb soler in Spanish.
The third divergence type,demotional, is another type of head switching divergence: in (3), the word like is realizedas a main verb in English but as an adverbial modifier (gern) in German.
2The fourth2 The distinction between promotional nd demotional divergences is not intuitively obvious at firstglance.
In both (2) and (3), the translation mapping associates a main verb with an adverbial satellite,or vice versa (i.e., in (2), the main verb soler is associated with the adverbial satellite usually, and in (3)the main verb like is associated with the adverbial satellite gern).
The distinction between these two598Bonnie J. Dorr Machine Translation Divergencesdivergence type is structural: in (4), the verbal object is realized as a noun phrase(the house) in English and as a prepositional phrase (en la casa) in Spanish.
The fifthdivergence type is conflational.
Conflation is the incorporation ofnecessary participants(or arguments) of a given action.
In (5), English uses the single word stab for the twoSpanish words dar (give) and pu~aladas (knife-wounds); this is because the effect of theaction (i.e., the knife-wounds portion of the lexical token) is conflated into the main verbin English.
The sixth divergence type is categoriah in (6), the predicate is adjectival(hungry) in English but nominal (Hunger) in German.
Finally, the seventh divergencetype is a lexical divergence: in (7), the event is lexically realized as the main verb breakin English but as a different verb forzar (literally force) in Spanish.The next section discusses the divergence classification given above, comparingthe current divergence categories with those of other researchers.
Section 3 formallydefines the terms used to classify divergences.
Section 4 uses this terminology toformalize the divergence classification and to define the solution to the divergenceproblem in the context of detailed examples.
Finally, Section 5 discusses certain issuesof relevance to the divergence problem including the resolution of several (recursively)interacting divergence types.2.
Classification of Machine Translation DivergencesThe divergence problem in machine translation has received increasingly greater at-tention in recent literature (see, for example, Barnett et al 1991a, 1991b; Beaven 1992a,1992b; Dorr 1990a, 1990b; Kameyama et al 1991; Kinoshita, Phillips, and Tsujii 1992;Lindop and Tsujii 1991; Tsujii and Fujita 1991; Whitelock 1992; related discussion canalso be found in work by Melby \[1986\] and Nirenburg and Nirenburg \[1988\]).
In par-ticular, Barnett et al (1991a) divide distinctions between the source language and thetarget language into two categories: translation divergences, in which the same infor-mation is conveyed in the source and target exts, but the structures of the sentencesare different (as in previous work by Dorr \[1990a, 1990b\]); and translation mismatches,in which the information that is conveyed is different in the source and target lan-guages (as described by Kameyama et al \[1991\]).
3 Although translation mismatchesare a major problem for translation systems that must be addressed, they are outsidethe scope of the model presented here.
(See Barnett et al 1991a, 1991b; Carbonell andTomita 1987; Meyer, Onyshkevych, and Carlson 1990; Nirenburg, Raskin, and Tucker1987; Nirenburg and Goodman 1990; Nirenburg and Levin 1989; Wilks 1973; amongothers, for descriptions of interlingual machine translation approaches that take intoaccount knowledge outside of the domain of lexical semantics.
)Although researchers have only recently begun to classify divergence types sys-tematically, the notion of translation divergences i not a new one in the machinetranslation community.
For example, a number of researchers working on the Euro-tra project have sought o solve divergent source-to-target translations, although thedivergences were named differently and were resolved by construction-specific trans-fer rules.
(For cogent descriptions of the Eurotra project, see, for example, Arnoldand des Tombe 1987; Copeland et al 1991; and Johnson, King, and des Tombe 1985).head switching cases will be made clearer in Section 4.3.3 An example of the latter situation is the translation of the English word fish into Spanish: thetranslation is pez if the fish is still in its natural state, but it is pescado if the fish has been caught and issuitable for food.
It is now widely accepted that, in such a situation, the machine translation systemmust  be able to derive the required information from discourse context and a model  of the domain thatis being discussed.599Computational Linguistics Volume 20, Number 4Figure 2Formal definition of lexical conceptual structure.A comprehensive survey of divergence xamples is presented by Lindop and Tsujii(1991).
The term used in this work is "complex transfer," but it describes a class ofproblems inherent in machine translation itself, not just in the transfer (or interlingual)approaches.One of the claims made by Lindop and Tsujii (1991) is that the non-Eurotra liter-ature rarely goes into great detail when discussing how divergences are handled.
Anadditional claim is that combinations of divergences and interaction effects betweendivergent and nondivergent translations are not described in the literature.
This paperseeks to change this perceived state of affairs by providing a detailed description of asolution to all of the (potentially interacting) divergences shown in Figure 1, not justa subset of them as would typically be found in the description of most translationsystems.
The framework assumed for the current approach makes use of a linguis-tically grounded classification of divergence types that can be formally defined andsystematically resolved.We now turn to a formal description of the terminology used to define the diver-gence problem.3.
DefinitionsThis section formally defines the lexical-semantic representation that serves as theinterlingua of the system (Definitions 1-3).
This representation, which is influencedprimarily by Jackendoff (1983, 1990), has been described in detail elsewhere (see, forexample, Dorr 1992b, 1993a) and thus will not be the focus of this paper.
In additionto a formal description of the lexical-semantic representation, definitions are providedfor syntactic phrases (Definition 4) and two translation mappings (Definitions 5 and 6).Definition 1A lexical conceptual structure (LCS) is a modified version of the representation proposedby Jackendoff (1983, 1990) that conforms to the following structural form:\[T(X') X' (\[T(W') Wt\], \[T(Zq) Ztl\] "'" \[T(Z',,) Ztn\] \[T(Q',) Q'I\] - "  \[T(Q',,,) Q'm\])\]This corresponds to the tree-like representation shown in Figure 2, in which (1) X' isthe logical head; (2) W' is the logical subject; (3) Z~... Z~ are the logical arguments; and(4) Q~ ... Q~m are the logical modifiers.
These four positions are relevant o the mapping600Bonnie J. Dorr Machine Translation Divergences( oo .
1I JOHN TOLo c HAPPILY?
Thing path Manner!I 1Thing LocationFigure 3CLCS representation for John went happily to school.between the interlingual representation and the surface syntactic representation.
Inaddition, T(~) is the logical type (Event, State, Path, Position, etc.)
corresponding tothe primitive ~ (CAUSE, LET, GO, STAY, BE, etc.
); Primitives are further categorizedinto fields (e.g., Possessional, Identificational, Temporal, Locational, etc.).
4Example 1The LCS representation f John went happily to school is\[Event GOLoc(\[Thing JOHN\],\[Path TOLoc (\[Position ATLoc (\[Thing JOHN\], \[Location SCHOOL\])\])\]\[M .
.
.
.
.
HAPPILY\])\]This corresponds to the tree-like representation shown in Figure 3, in which (1) thelogical head is GOLoc (of type Event); (2) the logical subject is JOHN (of type Thing);(3) the logical argument is TOcoc (of type Path); and (4) the logical modifier is HAPPILY(of type Manner).
Note that the logical argument is itself a LCS that contains a logicalargument, SCHOOL (of type Location), i.e., LCSs are recursively defined.The LCS representation is used both in the lexicon and in the interlingual repre-sentation.
The former is identified as a root LCS (RLCS) and the latter is identified asa composed LCS (CLCS):Definition 2A RLCS (i.e., a root LCS) is an uninstantiated LCS that is associated with a worddefinition in the lexicon (i.e., a LCS with unfilled variable positions).Example 2The RLCS associated with the word go (from Example 1) is\[Event GOLoc (\[Thing X\], \[Path TOLoc (\[Position ATLoc (\[Thing X\], \[Location Z\])\])\])\]4 The validity of the primitives and their compositional properties i not discussed here.
The LCS hasbeen studied as the basis of a representation for multiple languages (see, for example, Hale and Keyser1986a, 1986b, 1989; Hale and Laughren 1983; Levin and Rappaport 1986; Zubizarreta 1982, 1987) and isdiscussed in the context of machine translation by Dorr (1992b).601Computational Linguistics Volume 20, Number 4({ )x / \ ..., lPosition )I ( '  \[ x 7.
Thing LocationFigure 4RLCS representation forgo.which corresponds to the tree-like representation shown in Figure 4.Definition 3A CLCS (i.e., a composed LCS) is an instantiated LCS that is the result of combining twoor more RLCSs by means of unification (roughly).
This is the interlingua, or language-independent, form that serves as the pivot between the source and target languages.Example 3If we compose the RLCS for go (in Figure 4) with the RLCSs for John (\[ThingJOHN\]),school (\[Location SCHOOL\]), and happily (\[Manner HAPPILY\]), we get the CLCS corre-sponding to John went happily to school (shown in Figure 3).Each (content) word in the lexicon is associated with a RLCS, whose variablepositions may have certain restrictions.
The CLCS is a structure that results from com-bining the lexical items of a source-language sentence into a single underlying pivotform by means of LCS composition.
5 The notion of unification (as used in Definition 3)differs from that of the standard unification frameworks (see, for example, Shieberet al 1989, 1990; Kaplan and Bresnan 1982; Kaplan et al 1989; Kay 1984; etc.)
in thatit is not directly invertible.
That is, the generation process operates on the CLCS in aunification-like fashion that roughly mirrors the LCS composition process, but it is nota direct inverse of this process.
The notion of unification used here also differs fromothers in that it is a more "relaxed" notion: those words that are mapped in a relaxedway are associated with special exical information (i.e., the :INT, :EXT, :PROMOTE,:DEMOTE, ,, :CAT, and :CONFLATED parameters, each of which will be formalizedshortly).A fundamental component of the mapping between the interlingual representationand the surface syntactic representation is the syntactic phrase.Definition 4A syntactic phrase is a maximal projection that conforms to the following structuralform:5 This process is described in detail in Dorr (1992b).602Bonnie J. Dorr Machine Translation DivergencesY-MAXQ-MAXj+I  ... Q -MAXk Y -MAX Q-MAXk+ I ... Q .MAX mW-MAX X-MAXX Z-MAX1 ... Z-MAX aQ-MAX 1 ... Q-MAXi X Q-MAXi+ 1 ... Q-MAXjF igure  5Formal definition of syntactic phrase.\[Y-MAXQ-MAXj+~ ... Q-MAXk\[Y-MAXW-MAX\[X-MAX \[X Q-MAX1 .. .
Q-MAXi X Q-MAXi+I ... Q-MAX i\]Z-MAX1 .. .
Z-MAXn\]\]Q-MAXk+1 .. .
Q-MAXm\] 6This corresponds to the tree-like representation shown in Figure 5, in which (1) X isthe syntactic head (of category V, N, A, P, I, or C); (2) W-MAX is the external argument;(3) Z-MAX1, ... ,  Z-MAXn are the internal arguments; and (4) Q-MAX1 .
.
.
.
.
Q-MAXmare the syntactic adjuncts.Example  4The syntactic phrase corresponding to John went happily to school is\[C-MAX \[I-MAX \[N-MAX John\]\[V-MAX \[v went\] \[ADV happily\] \[P-MAX to \[N-MAX school\]\]\]\]\]This corresponds to the tree-like representation shown in Figure 6, in which (1) thesyntactic head is \[v went\]; (2) the external argument is \[N-MAX John\]; (3) the internalargument is \[P-MAX a ...\]; and (4) the syntactic adjunct is \[ADV happily\].
Note thatthe internal argument constituent is itself a syntactic phrase that contains an internalargument, \[N-MAX school\], i.e., syntactic phrases are recursively defined.In addition to the representations involved in the translation mapping,  it is alsopossible to formalize the mapping itself.
The current approach is to map between6 These syntactic structures are based on the X framework of government-binding theory (see Chomsky1981, 1982, 1986a, 1986b).
For ease of illustration, the word order used in all formal definitions ihead-initial/spec-initial ( .e., the setting for English).
The syntactic operations that determine wordorder are completely independent from the lexical-semantic operations that use these definitions.
Thus,the formal definitions can be stated in terms of an arbitrary ordering of constituents, without loss ofgenerality, as long as it is understood that the constituent order is independently determined.603Computational Linguistics Volume 20, Number 4/N-MAXAJohnC-MAXII -MAX\V-MAXV ADV P-MAXI I / \went happily to N-MAXschoolFigure 6Syntactic phrase representation forJohn went happily to school.the LCS representation a d the surface syntactic form by means of two routines thatare grounded in linguistic theory: a generalized linking routine (G?T4) and a canonicalsyntactic realization (CST4).
These routines are defined formally here:Definition 5The ~?T4 systematically relates syntactic positions from Definition 1 and lexical-semantic positions from Definition 4 as follows:1.
X I 4=~X2.
W'~W3.
Z I\] ?
?
?
K in  ~ Z l  ?
.
.
Zn4.
Q' I - - .
Q'm 4=~ Q1,.
.
QmExample 5The correspondence b tween the LCS of Example 1 and the syntactic structure ofExample 4 (i.e., for the sentence John went happily to school) is (1) X ~ = GOLoc 4=~ X = Ivwent\]; (2) W' = JOHN 4=~ W = \[N-MAX John\]; (3) Z' = TOcoc 4~ Z = \[pp to .
,  .\]; and (4)Q' = HAPPILY ~ Q ~--~\[ADV happily\].Definition 6The CST4 systematically relates a lexical-semantic type T(~') to a syntactic ategoryCAT(h), where ~t is a CLCS constituent related to the syntactic onstituent ?> by the~?~.Example 6The LCS type Thing corresponds to the syntactic ategory N, which is ultimatelyprojected up to a maximal level (i.e., N-MAX).
The full range of realization possibilitiesis given in Figure 7.604Bonnie J. Dorr  Machine Translat ion DivergencesLCS TypeEVENTSTATETHINGPROPERTYPATHPOSITIONLOCATIONTIMEMANNERINTENSIFIERPURPOSESyntactic CategoryVVNAPPADVADVADVADV~ DILl,Figure 7CST4 mapp ing  between LCS types and  syntactic ategories.Now that  we  have  fo rmal ly  de f ined  the  representat ions  and  mapp ings  used  dur -ing  t rans la t ion ,  we  wi l l  tu rn  to a c lass i f i ca t ion  of  d ivergences  that  is based  on  thesede f in i t ions .4.
The Divergence Problem: Formal Classification and SolutionIn  genera l ,  t rans la t ion  d ivergences  occur  when there  is an  except ion  e i ther  to the~?T4 or  to the  CST4 (or  to both)  in  one  language,  but  not  in  the  other .
7 Th is  p remisea l lows  one  to de f ine  fo rmal ly  a c lass i f i ca t ion  of  al l  l ex ica l - semant ic  d ivergences  thatar i se  dur ing  t rans la t ion  (i.e., d ivergences  based  on  proper t ies  assoc ia ted  w i th  lex ica l7 Most of the examples in this paper seem to suggest hat a divergence is defined in terms of alanguage-to-language phenomenon: a divergence occurs when a sentence in language L1 translates into asentence in L2 in a very different form (i.e., differently shaped parse trees or similarly shaped trees withdifferent basic categories).
This definition implies that a divergence may arise between two languagesL1 and L2, independent of the way the translation is done (i.e., direct, transfer, or interlingual).However, it is also possible to define a divergence from an interlingual point of view, i.e., with respectto an underlying representation (lexical conceptual structure) that has been chosen to describe thesource and target language sentences.
From this point of view, a divergent mapping may apply even incases in which the source- and target-language pairs do not exhibit any distinctions on the surface (e.g.,the translation of the German sentence Hans kuflt Marie gern as the equivalent Dutch sentence Hans kustMarie graag, both of which literally translate to Hans kisses Mary likingly).
In such cases, there aregenerally two occurrences of a language-to-interlingua divergence: one from the surface structure and oneto the surface structure.
(The terms language-to-language nd language-to-interlingua are taken from Dorrand Voss 1993a.)
At first glance, it might seem odd to introduce the notion of a language-to-interlinguadivergence for cases that do not exhibit a language-to-language divergence.
However, it is clearly thecase that language-to-language divergences--a special case of language-to-interlingua divergences--doexist regardless of the translation approach adopted.
Thus, we can view divergences more generally asa consequence of the internal mapping between the surface structure and the interlingualrepresentation rather than as an external distinction that shows up on the surface.
The result is that theinterlingua ppears to have been simplified to the extent hat it accommodates constructions in onelanguage (without any special information) more readily than it accommodates the correspondingconstruction i another language.
However, as one reviewer points out, this is not an undesirableconsequence, since the development of a suitable representation is where the interlingua builder has achoice and should choose the simplest representation format.
The appropriate question to ask iswhether an approach that addresses the divergence problem from a language-to-interlingua perspectiveis an improvement over an approach that addresses the problem strictly from a language-to-languagepoint of view.
This paper argues that the language-to-interlingua approach is the correct one given thatthe alternative would be to handle language-to-language divergences by constructing detailedsource-to-target transfer ules for each lexical entry in the source and target language.
Introducing thenotion of language-to-interlingua divergence allows the translation mapping to be defined in terms of arepresentation that is general enough to carry over to several different language pairs.605Computational Linguistics Volume 20, Number 4CLCS: Syntax:Y-MAXY-~x QWX-MAXINX ZFigure 8G?T?
mapping between the CLCS and the syntactic structure.entries that are not based on purely syntactic information, idiomatic usage, aspectualknowledge, discourse knowledge, domain knowledge, or world knowledge).Before we define and resolve each divergence type, we will first make some revi-sions to the representations used in Definitions 1 and 4 to simplify the presentation.The representation given in Definition 1 is revised so that Z' is used to denote a logicalargument from the set {Z~l ... Z~n} and Q' is used to denote a logical modifier fromthe set {Q'I ... Q'm}.
The resulting representation is considerably simplified:(8) \[T(X') X' (\[T(W') Wt\],  \[T(Z') Z' \ ] ,  \[T(Q') Q'\])\]Similarly, the representation given in Definition 4 is revised so that W is used to denotethe external argument, Z is used to denote an internal argument from the set {Z-MAX1... Z-MAXn}, and Q is used to denote a syntactic adjunct from the set {Q-MAXI ...Q-MAXm}.
The resulting representation has the following simplified form:(9) \[Y-MAX \[Y-MAX W IX-MAX X Z\]\] Q\]8With these simplifications, the G?T4 can be conceptualized asthe following set ofrelations:(10) Simplified G?T4:1.
X' ~X2.
W~ ~W3.
Z' ~Z4.
Q '~QFigure 8 shows the simplified ~?T4 in terms of tree-like representations.
9We are now prepared to define and resolve the translation divergences of Fig-ure 1 on the basis of the simplified formalization presented in (8)-(10) above.
The8 For the purposes of this discussion, we will retain the convention that syntactic adjuncts occur on theright at the maximal level.
Note that this is not always the case: the setting of an adjunction parameter(described by Dorr \[1993b\]) determines the side and level at which a particular adjunct will occur.9 For ease of illustration, this diagram omits the type specification.
(There is no loss of generality, sincethe G?
'R mapping does not make use of this specification.)
We will retain this convention throughoutthe rest of this paper.606Bonnie J. Dorr Machine Translation Divergences(a) Thematic DivergenceCLCS: Syntax:Y-MAXI \Y-MAX Q/ IX-MAXI \X W(b) Promotional DivergenceCLCS: Syntax:Y-MAX/ iX-MAX!
\Q X(c) Demofional DivergenceCLCS: Syntax:I \Y-MAX XX-MAXIZ(d) Structural DivergenceCLCS:~ Y-M~0CY-MAX OX-MAXINX RIZ(e) Conflational DivergenceCLCS: Syntax:/ IX-MAXIxQFigure 9Translation mappings for cases in which G?~ default positions are overridden.solution to the divergence problem relies solely on three types of information: theG?T4; the CST4; and a small set of parametric mechanisms.
The G?T4 and C$T4 areintended to be language independent, whereas the parameters are intended to encodelanguage-specific information about lexical items.
Because the interlingual representa-tion preserves relevant lexical-semantic relations, these three types of information areall that are required for providing a systematic solution to the divergence types shownin Figure 1.
In particular, the solution given here eliminates the need for transfer rulesand relies instead on parameterized mappings that are defined and applied uniformlyacross all languages.
Seven parameters are used to invoke exceptions to the ~?T4 andC$T4 functions in the context of translation divergences: :INT, :EXT, :PROMOTE, :DE-MOTE, ,, :CAT, and :CONFLATED.
We will now present a formal description of eachdivergence type and its associated parameter.4.1 Thematic DivergenceThe first divergence type to be formalized is the one for thematic divergence, i.e., therepositioning ofarguments with respect to a given head.
This type of divergence arises607Computational Linguistics Volume 20, Number 4in cases in which the ~?T4 invokes the following sets of relations in place of steps 2and 3 of (10):(11) 2.'
W' ~ Z3/Z  l ~ WFigure 9a shows the revised mapping.Thematic divergence arises only in cases in which there is a logical subject.
Anexample of thematic divergence is the reversal of the subject with an object, as inthe thematic divergence xample given earlier in (1).
The syntactic structures andcorresponding CLCS are shown here:(12) \[C-MAX \[I--MAX IN-MAX I\] \[V-MAX \[V like\] \[N-MAX Mary\]\]\]\]\[State BEIdent (\[Thing II,\[Position aTIdent (\[Thing I\], \[Thing MARY\])\],\[Manner LIKINGLY\])\]\[C-MAX \[I-MAX IN-MAX Maria\] \[V-MAX IV me gusta\]l\]\] 1?Here the object Mary has reversed places with the subject I in the Spanish translation.The result is that the object Mary turns into the subject Maria, and the subject I turnsinto the object me.This argument reversal is resolved by means of the :INT and :EXT parameters,which force the ~?T4 mapping to be overridden with respect o the positioning of thelogical subject and logical argument in Spanish.
The lexical entries for like and gustarillustrate the difference in the use of these parameters:(13) (i)(ii)Lexical entry for like:\[State BEIdent (\[Thing W\],\[Position aTIdent (\[Thing Wl, \[Thing Z\])\],\[Manner LIKINGLYI)\]Lexical entry for gustar:\[State BEldent (\[Thing :INT W\],\[Position aTIdent (\[Thing W\], \[Thing :EXT Z\])\],\[Manner LIKINGLY\])\]Because the English entry does not include these parameters, the translation relies onthe default argument positionings imposed by the ~?T4.
By contrast, the :INT/:EXTmarkers specified in the Spanish entry force the internal and external arguments toswap places in the syntactic structure.10 For the purposes of this discussion, the Spanish sentence is given in its uninverted form.
There areother ways of realizing this sentence.
In particular, anative speaker of Spanish will frequently invertthe subject o post-verbal position:\[C-MAX \[I--MAX ei \[V-MAX IV--MAX \[V me gusta\]\] IN--MAX Mafia\]i\]\]\].However, this does not affect he internal/external reversal scheme described here, since inversion is asyntactic operation that takes place independently of the process that handles thematic divergences.608Bonnie J. Dorr Machine Translation DivergencesThe general solution to thematic divergence is diagrammed as follows:(14) RLCS 1: \[T(X,) X' (\[T(W') W'\], \[r(z,) Z'\] \[T(Q') Q'\])\]RLCS 2: \[r(x,) X' (\[r(w') :INT W'\], \[T(Z') :EXT Z'\] \[T(Q') Q'I)\]Trans la t ion :  \[Y-MAX \[Y-MAX W \[X-MAX X Z\]\]  Q\]\[T(X') X'  (\[T(W') W' \ ] ,  \[T(Z') Z ' \ ]  \[T(Q') Q'\])\]\[Y-MAX \[Y-MAX Z \[X-MAX X Wll QIThis assumes that there is only one external argument and zero or more internalarguments.
If the situation arises in which more than one variable is associated withthe :EXT markers, it is assumed that there is an error in the word definition.
N Notethat the :INT and :EXT markers how up only in the RLCS.
The CLCS does not includeany such markers, since it is intended to be a language-independent r presentationfor the source- and target-language sentences.Thematic divergence is one of three types of possible positioning variations thatforce the G?T4 to be overridden.
Two additional positioning variations are promo-tional and demotional divergences, which will be defined in the next two sections.Whereas thematic divergence involves a repositioning of two satellites relative to ahead, promotional and demotional divergences involve a repositioning of the headitself\] 2 We will see in Section 5.1 that these three divergences account for the entirerange of repositioning possibilities.4.2 Promotional DivergencePromotional divergence is characterized by the promotion (placement "higher up") ofa logical modifier into a main verb position (or vice versa), as shown in Figure 9b.In such a situation, the logical modifier is associated with the syntactic head position,and the logical head is then associated with an internal argument position.
Thus,promotional divergence overrides the G?T4, invoking the following sets of relations inplace of steps 1 and 4 of (10):(15) 1.'
X !
~ Z 134.
'Q' ?~XFigure 9b shows the revised mapping.11 The parameters associated with the RLCS are assumed to be correctly specified for the purposes of thisformal description.
However, in practice, there might be errors in the lexical entries, since they areconstructed by hand in the current implementation.
Eventually, the intent is to automate the process oflexical entry construction so that these errors can be avoided.12 The notions of demotion and promotion are not the same as the notions of demotion and advancementin the theory of relational grammar (see Perlmutter 1983).
Dorr (1993b, pp.
269-274) argues that,although the relational representation might be a convenient tool for illustrating the promotion anddemotion operations as used in the current approach, this representation is not an appropriate vehiclefor interlingual translation for a number of reasons.13 This relation does not mean that X replaces Z (if there is a Z), but that X retains the same structuralrelation with Z (i.e., Z remains an internal argument of X).
To simplify the current description, Z is notshown in the syntactic structure of Figure 9b.609Computational Linguistics Volume 20, Number 4An example of promotional divergence is the case given earlier in (2).
The syntacticstructures and corresponding CLCS are shown here:(16) \[C-MAX \[I-MAX \[N--MAX John\]\[V-MAX IV usually Iv goes\]\] IN-MAX home\]\]\]l\[Event OLoc (\[Thing JOHN\],\[Path TOcoc (\[Position ATcoc (\[Thing JOHN\], \[Location HOUSE\])\])\],\[Manner HABITUALLY\])\]\[C-MAX \[I--MAX IN-MAX Juan\]\[V-MAX Iv suele\] \[V-MAX \[V ir\] \[P-MAX a casa\]\]\]\]\]Here the main verb go is modified by an adverbial adjunct usually, but in Spanish,usually has been placed into a higher position as the main verb soler, and the "goinghome" event has been realized as the internal argument of this verb.Promotional divergence is resolved by the :PROMOTE parameter, which forcesthe ~?T4 mapping to be overridden with respect to the positioning of the logical headand the logical modifier.
The lexical entries for usually and soler illustrate the differencein the use of this parameter:(17) (i)(ii)Lexical entry for usually:\[Manner HABITUALLY\]Lexical entry for soler:\[Manner :PROMOTE HABITUALLY\]Because the English entry does not use this parameter, the translation relies on the de-fault argument positionings imposed by the G?T4.
By contrast, he :PROMOTE markerspecified in the Spanish entry forces the head and adjunct o swap places in the syn-tactic structure.The general solution to promotional divergence is diagrammed as follows:(18) RLCS 1: \[T(Q') Q'\]RLCS 2: \[T(Q') :PROMOTE Q'\]Translation: \[Y-MAX \[Y-MAX W \[X--MAX X Z\]\] Q\]\[T(X') X' (\[T(W') W'\], \[T(Z') Z'\] \[T(Q') Q'\])\]\[Y-MAX \[Y-MAX W \[X-MAX Q \[ ... X Z\]\]\]\]4.3 Demotional DivergenceDemotional divergence is characterized by the demotion (placement "lower down") ofa logical head into an internal argument position (or vice versa), as shown in Figure 9c.In such a situation, the logical head is associated with the syntactic adjunct position,and the logical argument is then associated with a syntactic head position.
Thus,610Bonnie J. Dorr Machine Translation Divergencesdemotional divergence overrides the g?T4, invoking the following sets of relations inplace of steps 1 and 3 of (10):(19) 1.'
X' 4:~ Q143.'
Z' 4:> XFigure 9(c) shows the revised mapping.An example of demotional divergence is the case given earlier in (3).
The syntacticstructures and corresponding CLCS are shown here: is(20) \[C-MAX \[I-MAX IN-MAX I\]i IV-MAX IV l ike\] \[C-MAX PROi  to eat\]\]\]\]\[State BEcirc (\[Thing I\],\[Position ATcirc (\[Thing I\], \[Event EAT (\[Thing I\], \[Thing FOOD\]) \ ] ) \ ]\[Manner LIKINGLY\])\]\[C-MAX \[I-MAX IN-MAX Ich\] IV-MAX IV \[ADV gern\] Iv esse\]\]\]\]\] 16Here the main verb like takes the "to eat" event as an internal argument; but in German,like has been placed into a lower position as the adjunct gern, and the "eat" event hasbeen realized as the main verb.The distinction between promotional and demotional divergences may not be in-tuitively obvious at first glance.
In both cases, the translation mapping appears toassociate a main verb with an adverbial satellite, or vice versa.
However, the dis-tinction between these two head switching cases becomes more apparent when weconsider the status of the participating lexical tokens more carefully.
In the case ofsoler-usually, the main verb soler is, in some sense, the token that "triggers" the headswitching operation: its presence forces the adverbial satellite usually to appear in En-glish, even if we were to substitute some other event for ir in Spanish (e.g., correr a latienda, leer un libro, etc.).
By contrast, in the case of like-gern, the triggering element isnot the main verb like, since we are able to use like in other contexts that do not requiregern (e.g., I like the car ~ Mir gefdllt der Wagen); instead, the triggering element is theadverbial satellite gern: its presence forces the verb like to appear in English even ifwe were to substitute some other event in place of essen in German (e.g., zum Geschdftlaufen, das Buch lesen, etc.).
We will return to this point in Section 5.2.Demotional divergence is resolved by the :DEMOTE parameter, which forces the~?T4 mapping to be overridden with respect o the positioning of the logical headand the logical argument.
The lexical entries for like and gern illustrate the differencein the use of this parameter: 1714 This relation does not mean that X replaces Q (if there is a Q), but that X retains the same structuralrelation with Q (i.e., Q remains a syntactic adjunct of X).
To simplify the current description, Q is notshown in the syntactic structure of Figure 9c.15 The default object being eaten is FOOD, although this argument does not appear on the surface for thecurrent example.16 The German syntactic structure is shown here in the uninverted base form.
In the German surfacestructure, the verb is moved up into verb-second position and the subject is topicalized:\[C--MAX IN--MAX IchJ/ Iv esse\]j \[I--MAX IN--MAX t\]l IV--MAX Iv \[ADV gem\] Iv t\]/\]\]/\].17 Both definitions of like in (21) use the circumstantial field, which means that the Y argument must bean Event (e.g., like ta eat) rather than a Thing (e.g., like Mary).
Thus, the definitions for like and gern areslightly different from the definitions of like given earlier in (13) (i.e., these are additional lexical entriesfor like).611Computational Linguistics Volume 20, Number 4(21) (i)(ii)Lexical entry for like:\[State BEcirc (\[Thing W\],\[position ATcirc (\[Thing W\], \[Event Z\])\],\[Manner LIKINGLY\])\]Lexical entry for gem:\[State BECirc (\[Thing W\],\[Position ATCirc (\[Thing W\], \[Event :DEMOTE Z\])\],\[Manner LIKINGLY\])\]Because the English entry does not use this parameter, the translation relies on thedefault argument positionings imposed by the ~?T4.
By contrast, he :DEMOTE markerspecified in the German entry forces the head and internal argument to swap placesin the syntactic structure.The general solution to demotional divergence is diagrammed as follows:(22) RLCS 1: \[v(x') X' (\[T(W') W'\], \[T(Z') Z'\] \[T(Q') Q'\])\]RLCS 2: \[T(X') X' (\[T(W') W'\], \[T(Z') :DEMOTE Z'\] \[T(Q') Q'\])\]Translation: \[Y-MAX \[Y-MAX W IX-MAX X Z\]\] Q\]\[v(x') X' (\[T(W'/ W'\], \[T(Z') Z'\] \[T(Q'/ Q'\])l\[Y--MAX \[Y-MAX W IX-MAX Z\] \[ ... X QI\]\]4.4 Structural DivergenceStructural divergence differs from the last three divergence types in that it does notalter the positions used in the ~?T4 mapping, but it changes the nature of the relationbetween the different positions (i.e., the "4=~" correspondence).
Figure 9d characterizesthe alteration that takes place.
Note that the mapping of Z' to the correspondinginternal argument position is altered so that it is positioned under the constituent thatcorresponds to W.An example of structural divergence is the case given earlier in (4).
The syntacticstructures and corresponding CLCS are shown here:(23) \[C-MAX \[I-MAX IN-MAX John\]IV-MAX IV entered\] [N-MAX the house\]\]\]\]\[Event GOLoc (\[Thing JOHN\],\[Path TOcoc (\[Position INcoc (\[Thing JOHN\], \[Location HOUSE\])\])\])\]\[C-MAX \[I-MAX IN-MAX Juan\]\[V-MAX IV entr6\] \[P-MAX en \[N-MAX la casa\]\]\]\]\]Here the verbal object is realized as a noun phrase (the house) in English and as aprepositional phrase (en la casa) in Spanish.Structural divergence is resolved by means of the * marker, which forces logicalconstituents obe realized compositionally atdifferent levels.
In particular, the * servesas a pointer to a RLCS position that must be combined with another RLCS in orderto arrive at a (portion of a) CLCS.
The lexical entries for enter and entrar illustrate thedifference in the use of this parameter:612Bonnie J. Dorr Machine Translation Divergences(24) (i)(ii)Lexical entry for enter:\[Event GOLoc (\[Thing W\],\[Path TOLoc (\[Position INLoc (\[Thing W\], \[Location * Z\])\])\])\]Lexical entry for entrar:\[Event GOLoc (\[Thing W\],\[Path * TOLoc (\[Position INcoc (\[Thing W\], \[Location Z\])\])\])\]Because the English entry contains a * marker in the \[Location Z\[ position, this constituentis realized on the surface as the object (i.e., the house) of the main verb.
By contrast, the?
marker is associated with a "higher" position \[Path TOcoc ...\] in the Spanish entry,thus forcing this constituent to have a more complex realization (i.e., en la casa) in thesyntactic structure.The general solution to structural divergence is diagrammed as follows:(25) RLCS 1: \[T(X,) X' (\[T(W') W'\], \[T(R') R' (\[T(Z') * Z'\])\] \[r(Q,) Q'\])\]RLCS 2: \[r(x,) X' (\[r(w,) W'\], \[r(R') * R' (\[r(z') Z'\])\] \[T(Q') Q'\])\]Translation: \[Y-MAX \[Y-MAX\[r(x,) X' (\[T(W')\[Y-MAX \[Y-MAXW \[X-MAX X Z\]\] Q\]W'\], \[T(Z') Z'\] \[T(Q') Q'\])\]W \[X-MAX X \[ ... R Z\]\]\] Q\]Note that the logical argument R' is associated with a * marker in the RLCS of thetarget language, but not in the RLCS of the source language.
This forces the targetlanguage syntactic structure to realize a phrase R that dominates Z; in contrast, nosuch dominating phrase occurs in the source-language structure.4.5 Conflational DivergenceConflational divergence is another case in which the "~"  correspondence is changed.In particular, conflational divergence is characterized by the suppression of a CLCSconstituent (or the inverse of this process).
The constituent generally occurs in logicalargument or logical modifier position; thus, the "4=>" correspondence of either step 3or step 4 of the ~?T4 is changed, depending on which position is conflated.
Figure 9echaracterizes the alteration that takes place.
Note that the Z' position in the CLCS doesnot have a corresponding realization in the syntax.An example of conflational divergence is the case given earlier in (5).
The syntacticstructures and corresponding LCS are shown here:(26) \[C-MAX \[I-MAX IN-MAX I\]\[V-MAX \[V stabbed\[ [N-MAX John\]\]\[\[\[Event CAUSE(\[Thing I\],\[Event GOposs(\[Thing KNIFE-WOUND\],\[Path TOWARDposs(\[Position ATposs (/Thing KNIFE-WOUND\], \[Thing JOHN\])\])\[)\])\]\[C-MAX \[I-MAX IN-MAX Yo\]\[V-MAX \[v le di\] \[N-MAX pufialadas\] \[P-MAX a Juan\]\[\]\]613Computational Linguistics Volume 20, Number 4Here, English uses the single word stab for the two Spanish words dar (give) andpu~aladas (knife-wounds); this is because the effect of the action (i.e., the knife-woundportion of the lexical token) is incorporated into the main verb in English.Conflational divergence is resolved by means of the :CONFLATED marker, whichsuppresses the realization of the filler of a particular position.
The lexical entries forstab and dar illustrate the difference in the use of this parameter: is(27) (i)(ii)Lexical entry for stab:\[Event CAUSE(\[Thing W\] ,\[Event GOposs(\[Thing :CONFLATED KNIFE-WOUND\],\[Path TOWARDposs(\[Position ATposs (\[Thing KNIFE-WOUND\], \[Thing Z\])\])\])\])lLexical entry for dar:\[Event CAUSE(\[Thing W\],\[Event GOposs(\[Thing ~ Y\],\[Path TOWARDposs(\[Position ATposs (\[Thing Y\], \[Thing ZI)\])\])\])\]Because the English entry contains a :CONFLATED marker in the logical position cor-responding to KNIFE-WOUND, this constituent is suppressed in the syntactic struc-ture.
By contrast, this marker does not appear in the corresponding position in Span-ish, thus forcing this constituent to be overtly realized (i.e., puflaladas) in the svntacticstructure.The general solution to conflational divergence is diagrammed as follows:(28) RLCS 1: \[~(x,) X' (\[T(W') W'\], \[T(Z') * Z'\] \[T(Q') Q'\])\]RLCS 2: \[T(X') X' (\[z(w') W'\], \[T(Z') :CONFLATED Z'\] \[T(Q') Q'\])\]Trans lat ion:  \[Y-MAX \[Y-MAX W \[X-MAX X Z\]\] Q\]\[T(X'~ X' (\[T(W'/ W'\], \[T(Z'} Z'\] \[r;Qq Q'\])\]\[Y-MAX \[Y-MAX W \[X-MAX XI\[ QINote that the logical argument Z' is associated with a :CONFLATED marker in theRLCS of the target language, but not in the RLCS of the source language.
This forcesthe target language syntactic structure to suppress the realization of this constituent.18 Note that the :CONFLATED marker appears to be in complementary distribution with the ?
marker.
Infact, one might consider the use of the :CONFLATED marker to be unnecessary, since its presencecould be implied by the absence of the * marker.
However, the :CONFLATED marker plays animportant role in the lexical-semantic representation: it specifies that the "constant" term (e.g., theKNIFE-WOUND of the stab RLCS) must obligatorily fill the position and, moreover, that this constantmust be a legal LCS primitive of the system.
In addition, there is an inherent asymmetry between the:CONFLATED marker and the * marker: whereas the former always occurs in a leaf node position, thelatter may occur in any position in the RLCS.
Because the notion of conflation is not meaningful innon-leaf node positions, it would be unreasonable to make the assumption that every non-leaf positionwithout the * marker is conflated.
The :CONFLATED marker is used to identify truly conflatedpositions, not just those positions without the * marker.614Bonnie J. Dorr Machine Translation Divergences4.6 Categorial DivergenceUnlike the previous five divergence types, categorial divergence affects the operationof the C$/~, not the ~?T4.
It is characterized by a situation in which CAT(0) is forcedto have a different value than would normally be assigned to T(~ ~) by means ofthe mapping specified in Figure 7.
Thus, categorial divergence is formally describedas follows: a lexical-semantic type T(~') is related to a syntactic category CAT(~),where CAT(~) ~ CST4(T(~')).
In such a case, CAT(~) must be specified through lexicalparameterization.An example of categorial divergence is the case given earlier in (6).
The syntacticstructures and corresponding CLCS are shown here:(29) \[C-MAX \[I-MAX \[N-MAX I\] \[V-MAX \[V am\]  \[A--MAX hungry\]\]\]\]\[State BEIdent (\[Thing I\],\[Position aTIdent (\[Thing I\], \[Property HUNGRY\])\])\]\[C-MAX \[I-MAX \[N-MAX Ich\] \[V-MAX IN-MAX Hunger\] \[v habe\]\]\]\] 19Here, the predicate is adjectival (hungry) in English but nominal (Hunger) in German.Categorial divergence is resolved by means of the :CAT parameter.
The lexicalentries for be and haben illustrate the difference in the use of this parameter: 2?
(30) (i)(ii)Lexical entry for be:\[State BEIdent (\[Thing W\],\[Position aTIdent (\[Thing W\], \[Property Y\])\])\]Lexical entry for haben:\[State BEIdent (\[Thing W\],\[Position aTIdent (\[Thing W\], \[Property :CAT(N) Y\])\])\]Because the English entry does not contain a :CAT marker in the position correspond-ing to \[Property Y\], this constituent is realized in the syntactic structure as C$/~(Property)Adjective (i.e., hungry).
By contrast, the :CAT(N) marker specified in the Germanentry forces the default C$T4 category to be overridden and the Property argument isrealized as a noun form (i.e., Hunger).19 The German structure shown here is the base form of the following surface syntactic tree:\[C-MAX IN-MAX Ich\]i\[C Iv babe\]j\]\[I--MAX \[N--MAX tli \[V-MAX \[N-MAX Hunger\] \[v t\]jI \[I e\]\]\]This form is derived by the syntactic processor after lexical-semantic processing is complete (see Dorr1993a, for details).20 As might be expected, there are two lexical entries for the verb haben, only one of which is listed here.The one not shown here corresponds to the possessional sense of haben, i.e., the meaningcorresponding to the word have in English.
This entry does not contain a :CAT marker.615Computational Linguistics Volume 20, Number 4The general solution to categorial divergence is diagrammed as follows:(31) RLCS 1: \[T(X,) X' (\[T(W') W'\], IT(Z,) :Z'\] \[T(Q') Q'\])\]RLCS 2: It(x,) X' (\[7(w') W'\], IT(Z,) (:CAT 6) Z'\] \[~(Q,) Q'\])\]Translation: \[Y-MAX \[Y-MAX W IX-MAX X Z\]\] Q\]\[T(X') X' (\[T(W') W'\], \[T(Z') Z'\] \[T(Q') Q'\])I\[Y-MAX \[Y-MAX W \[X-MAX X a\]\] QIwhere CAT(Z) = &MAX.4.7 Lexical DivergenceLexical divergence arises only in the context of other divergence types.
21 This is be-cause the choice of lexical items in any language relies crucially on the realization andcomposition properties of those lexical items.
Because the six preceding divergencespotentially alter these properties, lexical divergence is viewed as a side effect of otherdivergences.
Thus, the formalization thereof is considered to be some combination ofthose given above.Unlike the first six divergence types, lexical divergence is solved during the pro-cess of lexical selection.
22Thus, there is no specific override marker that is used forthis type of divergence.
For example, in the lexical divergence (7), a conflational di-vergence forces the occurrence of a lexical divergence.
The syntactic structures andcorresponding CLCS for this example are shown here:(32) \[C-MAX \[I-MAX \[N-MAX John\]IV--MAX IV broke\] \[P-MAX into IN--MAX the room\]\]\]\]\]\[Event CAUSE(\[Thing JOHN\],\[Event GOLoc(\[Thing JOHN\],\[Path TOLoc(\[Position INcoc (\[Thing JOHN\], \[Location ROOMI)\])I)\]\[Manner FORCEFULLY\])\]\[C-MAX \[I-MAX \[N-MAX Juan\]IV-MAX IV forz6\] IN-MAX la entrada\] [P-MAX al cuarto\]\]\]\]Because the word-particle pair break into subsumes two concepts (forceful spatial mo-tion and entry to a location), it is crucial that the word forzar (literally, force) be selectedin conjunction with entrada (literally, entry) for the underlying break-into concept.21 As noted by a reviewer, this is not strictly true, since there are many cases in which a source-languageword maps to more than one target-language word without he simultaneous occurrence of anotherdivergence type.
An example of such a case is the English word eat, which maps to essen (for humans)or fressen (for animals).
Such cases are considered to be outside of the classes of lexical-semanticdivergences considered here (see Footnote 3).
However, a simple approach to resolving such caseswould be to use featural restrictions during syntactic processing.22 The solution to lexical divergence is trivial for transfer machine translation systems, ince transferentries map source-language words directly to their target-language equivalents.
In general, exicalselection is not seen as a problem in these systems.616Bonnie J. Dorr Machine Translation DivergencesThere is also a structural divergence in this example, since the prepositional phraseinto the room must be translated into a noun phrase entrada al cuarto.
This divergencecompounds the lexical divergence problem, since it is necessary to choose the target-language word a in the absence of a source-language counterpart.Lexical divergence also shows up in three previously presented examples, (12),(29), and (26), owing to the presence of thematic, categorial, and conflational diver-gences, respectively: in (12) the word like is chosen for the word gustar (literally, toplease); in (29) the word haben (literally, to have) is chosen for the word be; and in (26)the word dar (literally, to give) is chosen for the word stab.5.
DiscussionThis section discusses certain issues of relevance to the formal classification and reso-lution of translation divergences.
In particular, we will discuss (1) the limits imposedon the range of repositioning possibilities; (2) the justification for distinguishing be-tween promotional nd demotional divergences; (3) the notion of full coverage in thecontext of lexical selection; and (4) the resolution of interacting divergence types.5.1 Limits on Repositioning DivergencesIn Section 4.1 we made the claim that the thematic, promotional, and demotionaldivergences account for the entire range of repositioning possibilities.
We will nowexplore the validity of this claim.There are two potential types of syntactic relations that exist between a head anda satellite: the first is complementation (i.e., involving the internal argument), andthe second is adjunction.
23 Given these two types of relations, there are only a smallnumber of ways syntactic entities may be repositioned.
The three CLCS positions thatare involved in these relations are X', Z ~, and Q'.
If we compute the repositioningscombinatorically, there are 33 = 27 configurations (i.e., X ~, Z', and Q~ would map intoany of three positions).
However, we can eliminate 15 of these (since a CLCS mustcontain exactly one head), thus leaving only 12 possible configurations.
One of thesecorresponds to the default G?~ mapping (i.e., the logical head, logical argument, andlogical modifier map into canonical positions).
The remaining 11 configurations canbe factored into three cases as follows:1.
X' 4=> X1.1 Q' ~ Z; Z 1 4=~ Z.1.2 Z' ~ Q; Q' 4=~ Q.1.3 Q' <~ Z; Z' ~ Q.2.
Q' 4=?
X2.1 X ~ 4=~ Z; Z' ??
Z.2.2 X ~Z;Z  ~<=~Q.23 We have left out the possibility of an external argument as a participant in the head-satellite r lation.Of course, the external argument is a satellite with respect to the head, but it turns out that the externalargument, which corresponds to the logical subject in the CLCS, has a special status and does not havethe same repositioning potential that internal arguments and syntactic adjuncts have.
In particular, theexternal argument has the unique property that it never participates as the incorporated argument of aconflational verb.
Hale and Keyser (1989) provide evidence that this property holds across alllanguages.
Thus, we take the external argument to have a special status (universally) that exempts itfrom participating in divergences other than thematic divergence.617Computational Linguistics Volume 20, Number 4(a) Case 1.1CLCS:X ~  Y-MAX\]Y-MAX71X-MAXINx Q(b) Case 1.2CLCS: Syntax:Y-MAXI \  Y-MAX Z/ IX-MAXIx(e) Case 2.3CLCS: Syntax:INY-MAX X/ IZ~, X-MAXt \?
Q z(d) Case 3.2CLCS: Syntax:Y-MAXX-MAXINZ XQFigure 10Illegal translation mappings for natural language..2.3 X' ~ Q; Z' 4~ Z.2.4 X '~Q;Z '~Q.Z '~X3.1 X '~Z;Q '~Z.3.2 x' <=~ Z; Q' ~=~ Q.3.3 X' ~ Q; Q' <=~ Z.3.4 X' <=~ Q; Q' <=~ Q.We will discuss in detail how four of these cases, i.e., the ones characterized in Fig-ure 10, are ruled out.
Of the remaining, 2.1 and 3.4 correspond to the definitions ofpromotional and demotional divergences illustrated in Figures 9b and 9c, respectively;cases 1.3, 2.2, 2.4, 3.1, and 3.3 are ruled out for the same reasons that cases 1.1 and 1.2are ruled out (as we will see shortly), namely, that an internal argument Z can neverbe associated with a logical modifier Q' and that a syntactic adjunct (Q) can never beassociated with a logical argument Z'.It cannot be the case that a logical modifier maps to an internal argument position(case 1.1) because a logical modifier is an optional participant of a particular action,i.e., it need not be "governed" by the lexical item that it modifies.
Internal argumentpositions are reserved for cases in which a government relation must hold; thus, logicalmodifiers must necessarily be mapped into syntactic adjunct positions.Similarly, it also cannot be the case that a logical argument maps to a syntacticadjunct position (case 1.2).
A logical argument is a necessary participant of a particularaction, and as such, it must be "governed" by the lexical item that selects it.
By contrast,adjunct positions are reserved for optional modifying participants that do not need tobe governed by the lexical item that they are modifying; thus, logical arguments mustnecessarily be mapped into internal argument positions.618Bonnie J. Dorr Machine Translation DivergencesAnother case that is eliminated is the renaming of a logical head as a syntacticadjunct whose head corresponds to a logical modifier (case 2.3).
The idea is simplythat modification is a one-way relation.
If a logical head has a modifier, the headcannot become an adjunct of that modifier because the modifying relation would bereversed (i.e., the logical head would modify the syntactic head rather than the otherway around).
In contrast, a logical head of a CLCS can be mapped to an internalargument position in cases in which a logical modifier is mapped to a syntactic head(i.e., the case of promotional divergence presented earlier), since there is no violationof the one-way relation.A similar argument is used to eliminate the case in which a logical head is mappedto an internal argument whose head corresponds toa logical argument (case 3.2).
Theidea is that heads and arguments participate in a one-way relation.
If a logical headhas an argument, he head cannot become an internal argument of that argumentbecause the head-argument relation would be reversed (i.e., the logical head would bean argument of the syntactic head rather than the other way around).
In contrast, helogical head of a CLCS can be mapped to an adjunct (i.e., modifier) position in casesin which a logical argument is mapped to a syntactic head (i.e., the case of demotionaldivergence presented earlier), since these is no violation of the one-way relation.The argument for the elimination of the last two cases could be viewed as an appealto a constraint that is analogous to the 0-criterion in syntax.
Essentially, this constraintstates that all arguments and modifiers must be licensed (see Chomsky 1986a; Abney1989) in order to appear either in the syntactic structure or in the conceptual structure.In the context of conceptual structure, a logical modifier may license the realization ofa logical head in an internal argument position, but not in an adjunct position, sincethe modifier elation is already satisfied by virtue of the relation between the headand the modifier.
Similarly, a logical argument may license the realization of a logicalhead in a syntactic adjunct position, but not in an internal argument position, sincethe head-argument relation is already satisfied by virtue of the relation between thehead and the argument.
Having eliminated the meaningless possibilities, we are leftwith the promotional nd demotional cases presented above.5.2 Promotional versus Demotional DivergencesWe will now provide justification for the earlier claim that promotional and demo-tional divergence should be classified ifferently, even though they exhibit some ofthe same properties.
It might be argued that these divergences are essentially the same,since both cases involve an association of a main verb with an adverbial satellite orvice versa.
In the examples given earlier, the promotional divergence r ferred to a map-ping between the adverbial usually and the main verb soler and demotional divergencereferred to a mapping between the adverbial gern and the main verb like.
However,as mentioned in Section 4.3, these are taken to be in distinct classes: the differencebetween these two cases is determined by the "triggering" element (i.e., promotion istriggered by a main verb such as soler, whereas demotion is triggered by an adverbsuch as gern).Another factor that distinguishes between promotional and demotional diver-gences is the fact that verbs such as like and verbs such as soler do not have parallelsyntactic distributions, nor do they have analogous logical interpretations.
The verblike may take a sentential complement that has its own event structure (as in I like toeat), or it may take a nominal complement without an event structure (as in I like thecar).
In either case, the verb like generally means the same thing (i.e., it describes astate in which an event or a thing is somehow desirable to that person).
By contrast,the verb soler is a modal verb that contributes an aspectual component of meaning619Computational Linguistics Volume 20, Number 4that crucially relies on a verbal complement with an event structure; in a sense, soleris analogous to the modal must in English in that it cannot be used in isolation, butrequires the presence of a verbal complement in order for it to be interpretable.
In sucha configuration, the modal soler allows the event to be interpreted as being habitualin nature.Given these distinctions, it would not be appropriate to consider the head switch-ing mapping to be the same for the soler-usually and like-gern cases.
Not only do theyhave different triggering elements (i.e., the main verb in the former and the adverb inthe latter), but they do not have identical syntactic distributions and their logical in-terpretations are not analogous.
Thus, they are taken to be two independent mappingswith entirely different syntactic and lexical-semantic ramifications.The handling of promotional and demotional divergences i  a topic that has re-ceived recent attention, although it has been labeled differently, depending on how itis manifested.
An example of such a case is the way construction.
This phenomenonhas been studied by Jackendoff (1990) in his extended version of the original LCSframework:(33) Bill belched his way out of the restaurantIn such cases, Jackendoff claims that belching is subordinated toa higher predicate likeGO, "in effect demoting the meaning of the lexical verb to a subordinate accompani-ment or means 'modifier" (Jackendoff 1990, p. 214).
This characterization is essentiallyequivalent to that of the soler-usually example (i.e., promotional divergence) givenearlier.
245.3 Lexical Selection: Full Coverage ConstraintBecause of the compositional nature of the LCS representation, the current frameworkautomatically imposes a full coverage constraint during the lexical selection process.Formally, this constraint is defined as follows:(34) Full coverage constraint:A RLCS R matches a CLCS C if and only if R fully covers C.where R fully covers C under the following conditions:(35) A RLCS R fully covers a CLCS C if and only if:(a) there is no portion of R that does not match C;24 Jackendoff's approach to handling the way construction has been criticized by Marantz (1992) for itsuse of arbitrary exceptions to the "usual mappings."
Marantz takes issue with the characterization fsuch cases as an idiosyncratic relation between syntax and semantics and proposes, instead, that theconceptual structure looks different from what Jackendoff envisions.
Whichever of these proposals icorrect, neither Jackendoff nor Marantz considers their proposals in the context of interlingual machinetranslation.
If the exceptional mappings are indeed arbitrary, then one needs to explain how this affectsthe handling of different languages.
Moreover, neither Jackendoff nor Marantz mentions the possibilitythat the number of exceptional mappings might not be arbitrarily large, but that there might be a fixednumber of exceptions, delineated in such a way that only a handful need to be considered at any timefor any given language.
This is why the formalization described in this paper is a valuable resource: itprovides a means for proving that only certain types of exceptions are allowed and that the number ofsuch exceptions i  actually quite small.
Finally, neither Jackendoff nor Marantz considers keepingJackendoff's version of the LCS intact and using a single parameterized mapping along the linesproposed in the current framework.620Bonnie J. Dorr Machine Translation Divergences(b) either R completely matches C (i.e., there is no portion of C thatdoes not match R) or R matches all of C except some portion C'(i.e., a subcomponent of C) that is fully covered by some otherRLCS R/.In cases in which more than one lexical entry matches a current concept, his constraintis used to determine which possibilities hould be ruled out (if any).One of the main advantages to the formalization defined in this paper is that itallows one to judge whether a target-language concept fully covers the concept underly-ing the source-language sentence and, thus, to make an evaluation of the status of thesystem.
As an illustration of this point, consider the stab-dar example of Section 4.5.The notion of full coverage is manifested through the lexical-selection process.
The basicidea is that RLCSs are chosen such that they entirely cover the underlying concept.In terms of the mapping from the source-language sentence to the CLCS, this impliesthat the RLCSs must compose in such a way as to provide a full cover (i.e., there mustbe a path from the root to the leaf nodes that includes all the \[content\] words of thesentence).
In terms of the mapping from the CLCS to the target-language sentence,this implies that the CLCS must be decomposed into (potentially overlapping) RLCSswhose "union" covers the entire CLCS.From the English sentence in (26), the RLCSs must be chosen for each word in thesentence such that they provide a coherent CLCS.
The RLCS for stab is 25(36) \[Event CAUSE(\[Thing * W\] ,\[Event GOposs(\[Thing Y KNIFE-WOUND :CONFLATED\],\[Path TOWARDposs(\[Position ATposs (\[Thing Y KNIFE-WOUND\[, \[Thing * Z\])\])\])\])\[Because Y does not have a * specification, only W and Z need to be filled in.
Oncethese positions are filled in, the resulting CLCS fulfills the full coverage requirement,since there is a path from the root to the leaves that covers all of the words of thesource-language sentence.
The resulting CLCS is(37) \[Event CAUSE(\[Thing I\],\[Event GOposs(\[Thing KNIFE-WOUND\[,\[Path TOWARDposs(\[Position ATposs (\[Thing KNIFE-WOUND\[, \[Thing JOHN\])\])\])\])\]To complete the translation, this CLCS must be decomposed into RLCSs that satisfythe full coverage requirement.
The RLCS that is selected as a match for this top-levelCLCS is that of the word dar:25 In (27) we abbreviated the lexical entries for stab and dar, showing the * marker only in the positionthat was relevant o example (26).
In 36 and 38, we show the complete form of the lexical entries toillustrate the notion of full coverage,621Computational Linguistics Volume 20, Number 4(38) \[Event CAUSE(\[Thing * W\],\[Event GOposs(\[Thing * YI,\[Path * TOWARDposs(\[Position ATposs (\[Thing Y\], \[Thing ZI)\])I)\])IUnlike the RLCS for stab, the Y position is associated with a ?
marker; thus, it isnecessary to find RLCSs for all three positions W, Y, and Z.
Positions W and Y arefilled at the leaf level and Z is filled at the TOWARDposs level.
Once these positionsare filled, the combination of the RLCSs for yo, dar, pu~aladas, a and Juan covers theentire concept.
Thus, the full coverage requirement is satisfied.It should be noted that a number of other systems have attempted to tackle diver-gences imilar to those discussed in this paper without appealing to the notion of fullcoverage.
Three examples of such systems are (1) GETA/ARIANE (Vauquois and Boitet1985; Boitet 1987); (2) LMT (McCord 1989); and (3) METAL (Alonso 1990; Thurmair1990).
In particular, these approaches address the problem of thematic divergence bymeans of transfer ules of the following form, respectively:(39)(40)(41)like(SUBJ(ARG2:GN),OBJI(ARGI:GN))plaire(SUBJ(ARGI:GN),OBJI(ARG2:PREP, GN)) 4~gverb (like (dat : ,, nom: X), ge+f  all, ?
: X)like V ~ gustar VNP (\[ROLE SUBJD ~ NP (\[ROLE IOBJ\])NP (\[ROLE DOBJ\]) ~ NP (\[ROLE SUBJ\])One problem with these approaches i that surface syntactic decisions are, in a sense,performed off-line by means of lexical entries and transfer ules that specifically en-code language-specific syntactic information.
Such a scheme is limited in that it hasno potential for relating thematic divergence to the rest of the space of divergencepossibilities.
Moreover, although transfer ules might be deemed suitable for local di-vergences such as simple subject-object reversal, it is well known that simple transferrules of this type do not readily accommodate more complicated ivergences.Consider a more complicated case such as the following promotional divergence: R6(42) Promotional divergence:E: The baby just fell ~ F: Le b6b6 vient de tomber'The baby just (verb-past) of fall'Here, the English adverbial just is translated as the French main verb venir, whichtakes the falling event as its complement de tomber.At first glance, it might seem difficult to construct transfer ules that handle suchcases.
However, the LFG-MT system by .Kaplan et al (1989) does, in fact, handlesuch cases by means of mappings between source and target functional structures (f-structures).
The f-structures that correspond, respectively, to the English and Frenchsentences in this example are the following:26 This example was taken from Kaplan et al (1989).622Bonnie J. Dorr Machine Translation Divergences(43) (i)(ii)PREDARG'JUST((T ARG))'PRED 'FALL((T SUBJ))'TENSE PASTPRED 'BABY'NUM SG SUBJ DEFSPEC PRED+'THE' \]PREDSUBJXCOMP'VENIR((TPREDGENDERNUMBSPECPREDCOMPLTENSESUBJSUBJ)(T XCOMP)}''Bt~Bt~'MASCSGPRED 'LE''TOMBER((T SUBJ)}'DEINFThe translation mapping is performed by a transfer equation that relates thesource- and target-language f-structures:(44) (T T PRED 'JUST((T ARG))') = VENIR (T T XCOMP) = T (T ARG)This equation identifies venir as the corresponding French predicate, and it maps theargument of just to a complement that is headed by the prepositional complementizerde.Although such a case is handled in the LFG-MT system, there are a number ofproblems with this approach.
A serious flaw concerns the handling of divergences inthe context of embedded clauses.
(For additional discussion, see Sadler and Thompson1991.)
In particular, if the English sentence in (42) were realized as an embeddedcomplement such as I think that the baby just fell, it would not be possible to generatethe French output.
The reason for this is that the LFG-MT system is not designedto handle an interaction between a (divergent) matrix clause and a (nondivergent)embedded clause.
This sentence is broken down into predicate-argument relationsthat conform (roughly) to the following logical specification:(45) think(I,fall(baby))just(fall(baby))Because the logical constituent fall(baby) is viewed as an argument of two logicalheads, "think" and "just," the LFG-MT generator cannot determine how to composethese concepts and produce an output string.The divergence solution proposed in the LCS framework overcomes this difficultyby imposing the full coverage constraint.
In particular, specific relations are set up623Computational Linguistics Volume 20, Number 4between logical heads and their associated arguments and modifiers so that therecould never be any question of how two concepts are composed, even for embeddedcases.
For the current example, the LCS approach would reduce the logical relationsto a single specification for both French and English:(46) think(I, fall(baby, just))That is, the "just" component of meaning is a modifier of the "falling" action, regard-less of how this constituent is realized on the surface.The full benefit of this approach is further demonstrated when one considers theextent o which the full coverage constraint carries over to other divergence categories.Consider the following (frequently cited) conflational divergence:(47) Conflational divergence:E: John swam across the riverF: John a travers6 la rivi~re ~ la nage'John crossed the river by swimming'In this example, the English path component (across) is translated as the French mainverb (traverser), and the English main verb (swim) is translated as the French mannercomponent (a la nage).
In a system like TAUM (Isabelle 1987), transfer ules imposelexical transformations in order to establish correspondences between source and targetstructures, i.e., rules of the following form:(48) (X swim (across Y)) 4~ (X traverser Y (a la nage))This rule maps the path component (across) to the French main verb (traverser), andthe English main verb (swim) to the French adverbial (a la nage).
27The disadvantage to this approach is that it requires a new transfer ule for everyadverbial that might potentially participate in the traverser construction (e.g., ~ pied, encourant, en marchant, etc.).
The LCS approach, on the other hand, resolves this type ofdivergence compositionally by relying on the full coverage constraint and the :CON-FLATED marker, analogous to the handling of example (26).
The underlying LCS forthe two sentences in (47) is the following:(49) \[Event GOLoc(\[Thing JOHN\],\[Path ACROSSLoc (\[Position ATLoc (\[Thing JOHN\], \[Location RIVER\])\[)\],\[Manner SWIMMINGLY\])\]The solution to this example relies on the assumption that the distinction betweenthe English and French exists by virtue of the fact that the word swim includes themanner component swimmingly, whereas the word traverser does not.
Because of thisconflational distinction, the manner component is suppressed in English, but is overtlyrealized (as ~ la nage) in French.
2s The important point is that this entire concept is fully27 A related, but more general, strategy would be to handle such cases in bilingual exical entries (see, forexample, Beaven 1992a, 1992b; Whitelock 1992; Trujillo 1992).28 The use of the word traverser (i.e., cross) instead of nager (i.e., swim) is independently determined by thefact that the path component ACROSS is present in the conceptual representation (i.e., there would beno way to realize the path component in conjunction with the word nager).624Bonnie J. Dorr Machine Translation Divergencescovered (in the sense of \[34\]) by both the source- and target-language s ntences, eventhough these two sentences do not have the same structural representation.
That is,as long as all conceptual components of (49) are somehow retrievable, the suppres-sion/realization of the individual components in the surface structure may be forcedby the presence/absence of the :CONFLATED marker in the relevant lexical entries.5.4 Interacting Divergence TypesWe now turn to another important issue that has only recently received the attentionit deserves, namely, that of handling interacting divergence types.
In particular, therehave been criticisms (see, for example, Lindop and Tsujii 1991) of systems that performtransfer on relatively shallow analyses (e.g., early METAL \[Alonso 1990, Thurmair1990\] and LTAG \[AbeillG Schabes, and Joshi 1990\]) owing to the fact that such systemsare not likely to be able to handle divergence interactions (although they may be able tohandle each divergence type in isolation).
The solution adopted in the current approachdoes not appeal to a shallow analysis (i.e., it does not use a set of already-coded canned"frames" with predetermined argument structure).
Rather, the syntactic structures arederived compositionally on the basis of two pieces of information: the structure ofthe CLCS (i.e., the language-independent predicate-argument i formation) and thelexical entries (i.e., the RLCSs and their associated language-dependent information).It would not be possible to handle interacting divergence types in an approach thatmaps directly from a set of hard-wired source-language frames to a set of hard-wiredtarget-language frames.
This is because an argument that occurs in a divergent phrasalconstruction might itself be a divergent phrasal construction.Consider the following example:(5O) Promotional and thematic divergence:S: Leer libros le suele gustar a Juan'Reading books (him) tends to please (to) John'E: John usually likes reading booksThis example xhibits a simultaneous occurrence of two types of divergences: the verbsoler exhibits a promotional divergence with respect o its internal argument gustar aJuan, which itself exhibits a thematic divergence.
The recursive nature of the GGT4 iscrucial for handling such cases.The CLCS for (50) is the following:(51) \[State BEcirc(\[Thing JOHN\],\[Position ATcirc(\[Thing JOHN\], \[Event READ (\[Thing JOHN\], \[Thing BOOK\])\])\],\[Manner LIKINGLY\],\[Manner HABITUALLY\])\]Note that there are two modifiers, LIKINGLY and HABITUALLY.
It is the job of the~?T4 function to determine the appropriate decomposition of the event on the basisof the language-specific requirements of the RLCSs involved in the mapping.
In thecurrent example, the LIKINGLY component is, in a sense, an "inherent" modifier, sinceit appears in the RLCS of both like and gustar.
In contrast, the HABITUALLY modifieris an independent constituent that corresponds to independent RLCSs for usually andsoler.625Computational Linguistics Volume 20, Number 4We will now formally analyze how this example is handled.
The two relevantoverride mappings are specified in (15) and (11), repeated here for convenience:(52) Promot ional  override:1.'
X' ~=~ Z4.'
Q' ~ X(53) Thematic override:1.'
W' ~Z4 /Z '  ??
WIn terms of the logical constituents that participate in the divergence mapping, X'corresponds to \[State BEcirc -..\], W' corresponds to \[Thing JOHN\[, Z' corresponds to\[Event READ ...\], and Q' corresponds to \[Manner HABITUALLY\].Formally, the structure of the English sentence in (50) has the default syntacticrepresentation(54) \[Y-MAX \[Y-MAX W \[X-MAX X Z\] l  Q\]In contrast, the equivalent Spanish sentence has an entirely different syntactic repre-sentation:(55) \[Y-MAX \[Y-MAX Z \[X-MAX Q \[ .
.
-  X W\]\]\]\]Note that this structure differs from the default representation i  that the externalargument is Z, not W, and that the syntactic head is Q, not X.
Also, because thepromotional mapping forces X into an internal argument position, additional structureis created so that X retains its status as a head.
This head selects an internal argumentthat, in this case, is W rather than Z because of the interaction with the thematicdivergence.Suppose we were to generate the Spanish sentence for this example.
The RLCSsfor the Spanish case conform to the following formal specifications:(56) gustar: \[T(X') X' (\[T(W') :INT W'\], \[T(Z') :EXT Z'\])\]soler: IT(Q,) :PROMOTE Q'\]When the ~?T4 is applied to the CLCS of (51), the promotional override (52) is im-mediately triggered by the :PROMOTE marker in the RLCS for soler; this invocationcrucially precedes the invocation of the thematic override (53).
29 The promotional over-ride forces Q' (i.e., \[Manner HABITUALLY\[) to be realized as the syntactic head soler.This head takes an internal argument corresponding to X' (\[State BEcirc ...\]) that is29 This seems to indicate that there is some notion of prioritization during the resolution of interactingdivergence types.
In particular, the head swapping (promotional nd demotional) divergences appear totake priority over the "argument swapping" cases (thematic).
The decision to impose this prioritizationis not entirely unprincipled.
It would not be possible to apply these two overrides in the oppositeorder, since a head must  be properly positioned (potentially via a promotional override) in order toidentify the relative positions for its satellites (potentially via a thematic override).
Although the formalramifications of this ordering have not yet been established, it should be noted that the prioritizationfits in naturally in the current framework, given that the syntactic realization process tarts by realizing"outer" phrases, but then recursively realizes "inner" phrases before any attachments are made.626Bonnie J. Dorr Machine Translation Divergencesrealized as the verb gustar.
Recall that the structural relation between the subordi-nated verb and its internal argument is not changed by the promotional mapping (seeFootnote 13).
However, the promotional operation does change the relation betweenthe subordinated verb and its external argument by realizing the argument in an ex-ternal position relative to the main verb.
Normally, this would mean that the CLCSconstituent \[Thing JOHN\] would become an external argument of soler such as in thenoninteracting case, John suele leer libros.
In the current example, however, the attach-ment of the external argument is delayed until the recursive application of the ~?T4on \[State BEcirc ...\].At this point, the :INT and :EXT markers trigger the thematic interchange, andthe logical subject \[Thing JOHN\] is realized as the internal argument aJuan.
The \[EventREAD ...\] constituent is then taken to be the external argument of gustar, exceptthat this constituent cannot be attached inside of the subordinate phrase owing tothe promotional divergence.
Instead, the current phrase is completed and the externalargument is "passed up" to the higher phrase, which then attaches it in an externalposition relative to the verb soler.
The final structure is then generated:(57) \[C-MAX\[I-MAX\[C-MAX leer libros\]\[V-MAX \ [V le  suele\]IV-MAX \[V gustar\] \[P-MAX a Juan\]\]\]\]\]Thus, we have shown how the current framework provides a formal means for demon-strating how interacting divergence types are handled.6.
Limitations and ConclusionsThe current approach as been implemented in a system called UNITRAN (Dorr 1990a,1990b, 1993b).
3?
Many of the problems associated with the direct replacement andtransfer approaches of previous ystems have been eliminated in this new design.
Inparticular, UNITRAN does not make use of analysis/synthesis rules that are meticu-lously tailored to each of the source and target languages, nor does it require detailedsource-to-target transfer ules.
On the other hand, because the system is designed (de-liberately) to operate on one sentence at a time, it has a number of inherent limitations.In particular, the lack of a theory of multisententiality makes high quality transla-tion difficult, since it is often the case that a single sentence in one language shouldbe translated as two or more sentences in the other language; currently, UNITRANdoes not allow for a mismatch between the number of source- and target-languagesentences.
31 Since generation has not been the primary focus of the current research,this and other generation problems have not yet been addressed in this framework.Such problems include cohesion (Granville 1983), selecting propositional nd rhetoricalgoals (McKeown 1985), selecting open-class items from "deep knowledge" (Goldman30 The name UNITRAN stands for UNiversal TRANslator, that is, the system serves as the basis fortranslation across a variety of languages, not just two languages or a family of languages.31 In general, systems hould be designed so that sentences are realized differently in different languages,depending on the speaker's intended effect.
In the words of a reviewer, "What's a long-winded andboring sentence to an American may be precisely a very fine formal sentence to a German."
Even forlanguages as close as French and English, sentence boundaries differ about 10% of the time (see Brownet al 1991).627Computational Linguistics Volume 20, Number 41975; Jacobs 1985; Kittredge, Iordanskaja, nd Polgu6re 1988; Nirenburg and Niren-burg 1988; Nirenburg et al 1992; among others), ordering propositions for producingcoherent text (Hovy 1988), resolving anaphora (Derr and McKeown 1984; Sondheimer,Cumming, and Albano 1990; Werner and Nirenburg 1988), and many others.
In fact,not all of these issues (e.g., selecting propositional nd rhetorical goals) are directlyrelevant to the task of machine translation, which already has the advantage (at leastfrom the generation point of view) that the source-language sentence and, in the cur-rent model, the conceptual nalysis underlying this sentence are available at the onsetof the generation process.Instead, the current research focuses on demonstrating the utility of the LCS-based interlingua nd the associated parameters for resolving translation divergenceswhile maintaining the systematic relation between the interlingua nd the syntax.
Thetasks involved in achieving this objective have been reduced to what might be con-sidered the standard "what" and "how" questions of generation: (1) lexical selection,i.e., the task of deciding what target-language words accurately reflect the meaningof the corresponding source-language words; and (2) syntactic realization, i.e., the taskof determining how target-language words are mapped to their appropriate syntacticstructures.
In the context of the current model, the first task consists of matching theLCS-based interlingua (the CLCS) against he LCS-based entries (the RLCS) in thedictionary in order to select he appropriate word, and the second task consists of re-alizing the positions marked by * (and other parametric markers) into the appropriatesyntactic structure.The question of lexical choice is one that deserves further discussion.
The detailsof the matching process that achieves lexical selection of the target-language RLCSs(e.g., the selection of the RLCSs for like \[or gustar\] from the underlying CLCS shownin Definition 1) have not been presented here, but see Dorr (1993a) for a discussionwith examples.
Roughly, lexical selection in UNITRAN is a "reverse" unification-likeprocess that matches the CLCS to the RLCS templates in the lexicon and choosesthe associated lexical words accordingly.
One of the important problems that mustbe considered with respect o lexical selection is that of overgeneration.
32 In particu-lar, one might ask how the matcher knows whether it should try to choose phrasesthat restate the source language more succinctly in the target language, or whether itshould be allowed to restate the source-language phrases more verbosely in the targetlanguage.
This comes up in cases such as the stab example given earlier.
It turns outthat the word stab can be translated into Spanish as the succinct form apu~alar, or asthe more verbose form dar pu~aladas.
Similarly, in the reverse direction, the transla-tion of dar pu~aladas is the more succinct form stab; however, one could conceive ofa more verbose translation (e.g., inflict knife wounds or even give knife wounds).
Cur-rently, there is no preference assignment during lexical selection (as in Nirenburg andNirenburg 1988; Wilks 1973); instead, the system requires an exact match of the CLCSto the target-language RLCS (or some combination of RLCSs).
If there is more thanone way of matching the CLCS, multiple forms will be generated (although we havediscussed only one target-language form, dar pu~aladas, for the stab example).
A first-pass approach to resolving such cases of overgeneration (based on aspectual features)is discussed in Dorr (1992a) and in more detail in Dorr (1993b).
In addition, a model32 The complexity of the lexical selection process i a well-studied problem.
See, for example, the work byReiter (1990), which shows that he selection ofthe optimal set of adjectives for a noun phrase undersome very strong conditions is NP-complete.
Presumably, the general lexical selection problem isconsiderably harder.628Bonnie J. Dorr Machine Translation Divergencesof generation based on theories of tense by Allen (1983, 1984), Hornstein (1990), andReichenbach (1947) is discussed in Dorr and Gaasterland (1992) and Dorr (1993b).The difficulty of the lexical choice problem will become more important as thesystem grows beyond its current prototypical state.
Research is currently underwayto extend the system by developing automatic lexical acquisition procedures thatmake use of a small set of conceptual structures, as a starting point, and then ac-quire syntactic and semantic information on the basis of these initial representationsplus machine-readable definitions from the Longman's Dictionary of Contemporary English(Proctor 1978).
(LDOCE is useful because it includes collocations and sense frequency,thus making it possible to determine the argument structures for different words.
)This investigation will benefit from the work of several researchers in the field of au-tomatic lexicon construction, most notably, Brent (1993), Boguraev and Briscoe (1989),Boguraev and Pustejovsky (1990), Briscoe and Copestake (1990), Byrd et al (1987), Far-well, Guthrie, and Wilks.
(1992), Montemagni and Vanderwende (1992), Pustejovsky(1987), Pustejovsky and Bergler (1987), and Pustejovsky, Bergier, and Anick (1993),among others.
In particular, it has been argued convincingly by Farwell, Guthrie, andWilks (1992) that resources such as the LDOCE are useful for constructing dictionaryrepresentations for languages other than English, thus paving the way for scaling upinterlingual machine translations so that they have broader coverage.
Once this ex-tension is complete, we intend to scale up the UNITRAN system and test the LCSapproach to lexical choice on a broader set of phenomena using a larger lexicon.The current framework provides a systematic classification of machine transla-tion divergences.
We have shown how this classification can be formally defined andsystematically resolved through the use of general mapping relations and a small setof cross-linguistic parameters.
Because the parameters are used to factor out "trans-fer" information, the current approach obviates the need for transfer ules.
We haveprovided evidence that supports the view that the lexical-semantic divergence classifi-cation proposed in the current framework covers all lexical-semantic divergences thatarise during translation (i.e., divergences based on properties associated with lexicalentries that are not based on purely syntactic information, idiomatic usage, aspectualknowledge, discourse knowledge, domain knowledge, or world knowledge).
Since thecharacterization f the range of potential divergences is manageably small, the task ofaccommodating divergences i  immensely simplified.
We have also demonstrated theusefulness of a full coverage requirement as a tool that allows one to judge whether aparticular target-language sentence fully covers the concept hat underlies the corre-sponding source-language sentence.
Finally, we have shown, formally, that the currentmodel accommodates interacting divergence types.AcknowledgmentsThis paper describes research done at theUniversity of Maryland Institute forAdvanced Computer Studies.
Support forthis research as been provided in part bythe National Science Foundation under aYoung Investigator Award IRI-9357731 andgrant IRI-9120788, by the DARPA BasicResearch Program under grantN00014-92-J-1929, bythe Army ResearchOffice under contract DAAL03-91-C-0034through Batelle Corporation, and by theArmy Research Institute under contractMDA-903-92-R-0035 throughMicroelectronics and Design, Inc. Usefulguidance and commentary during theresearch and preparation of this documentwere provided by Bob Berwick, BruceDawson, Ken Hale, Clare Voss, and AmyWeinberg.
The author would also like tothank three anonymous reviewers for theirhelpful comments during the preparation ofthis document.ReferencesAbeillG Anne; Schabes, Yves; and Joshi,Aravind K. (1990).
"Using lexicalized tagsfor machine translation."
In Proceedings,13th International Conference on629Computational Linguistics Volume 20, Number 4Computational Linguistics, Helsinki,Finland, 1-6.Abney, S. (1989).
"A computational modelof human parsing."
Journal ofPsychol in guistic Research 18:129-144.Allen, James E (1983).
"Maintainingknowledge about temporal intervals.
"Communications of the ACM 26(11):832-843.Allen, James E (1984).
"Towards a generaltheory of action and time."
ArtificialIntelligence 23(2):123-160.Alonso, Juan Alberto.
(1990).
"Transferinterstructure: designing an 'interlingua'for transfer-based MT systems."
InProceedings, Third International Conferenceon Theoretical nd Methodological Issues inMachine Translation of Natural Languages,Linguistics Research Center, TheUniversity of Texas, Austin, Texas,189-201.Arnold, Doug, and des Tombe, Louis.(1987).
"Basic theory and methodology inEurotra."
In Machine Translation: Theoreticaland Methodological Issues, edited by SergeiNirenburg, 114-135.
Cambridge:Cambridge University Press.Barnett, Jim; Mani, Inderjeet; Martin, Paul;and Rich, Elaine (1991a).
"Reversiblemachine translation: What to do when thelanguages don't line up."
In Proceedings,Workshop on Reversible Grammars in NaturalLanguage Processing, ACL-91, University ofCalifornia, Berkeley, California, 61-70.Barnett, Jim; Mani, Inderjeet; Rich, Elaine;Aone, Chinatsu; Knight, Kevin; andMartinez, Juan C. (1991b).
"Capturinglanguage-specific semantic distinctions ininterlingua-based MT."
In Proceedings,Machine Translation Summit, Washington,DC, 25-32.Beaven, John (1992a).
"Lexicalistunification-based machine translation.
"Doctoral dissertation, University ofEdinburgh, Edinburgh, UK.Beaven, John (1992b).
"Shake and bakemachine translation."
In Proceedings, 14thInternational Conference on ComputationalLinguistics, Nantes, France, 603-609.Boguraev, Branimir, and Briscoe, Ted (1989).Computational Lexicography for NaturalLanguage Processing.
London: Longman.Boguraev, Branimir, and Pustejovsky, James(1990).
"Lexical ambiguity and the role ofknowledge representation in lexicaldesign."
In Proceedings, 13th InternationalConference on Computational Linguistics,Helsinki, Finland, 36-41.Boitet, Christian (1987).
"Research anddevelopment on MT and relatedtechniques at Grenoble University(GETA)."
In Machine Translation: The Stateof the Art, edited by Margaret King,133-153.
Edinburgh University Press,Edinburgh.Brent, Michael (1993).
"From grammar tolexicon: Unsupervised learning of lexicalsyntax."
Computational Linguistics19(2):243-262.Briscoe, E. J., and Copestake, A.
A.
(1990).
"Enjoy the paper: Lexical semantics vialexicology."
In Proceedings, 13thInternational Conference on ComputationalLinguistics, Helsinki, Finland, 42-47.Byrd, Roy J., Calzolari, Nicoletta;Chodorow, Martin S.; Klavans, Judith L.;Neff, Mary S.; and Rizk, Omneya A.(1987).
"Tools and methods forcomputational linguistics."
ComputationalLinguistics 13(3-4):219-240.Carbonell, Jaime G., and Tomita, Masaru(1987).
"Knowledge-based machinetranslation, the CMU approach."
InMachine Translation: Theoretical ndMethodological Issues, edited by SergeiNirenburg, 68-89.
Cambridge: CambridgeUniversity Press.Chomsky, Noam A.
(1981).
Lectures onGovernment and Binding.
Dordrecht,Holland: Foris Publications.Chomsky, Noam A.
(1982).
Some Conceptsand Consequences of the Theory of Governmentand Binding.
Cambridge: MIT Press.Chomsky, Noam A.
(1986a).
Barriers.Cambridge: MIT Press.Chomsky, Noam A.
(1986b).
Knowledge ofLanguage: Its Nature, Origin and Use.Cambridge: MIT Press.Copeland, C.; Durand, J.; Krauwer, S.; andMaegaard, B.
(1991).
"The Eurotralinguistic specifications."
In Studies inMachine Translation and Natural LanguageProcessing, Volume 1, edited by ErwinValentini.
Brussels: Commission of theEuropean Communities.Derr, M., and McKeown, K. (1984).
"Usingfocus to generate complex and simplesentences."
In Proceedings, TenthInternational Conference on ComputationalLinguistics, Stanford, California, 319-326.Dorr, Bonnie J.
(1990a).
"A cross-linguisticapproach to machine translation."
InProceedings, Third International Conferenceon Theoretical nd Methodological Issues inMachine Translation of Natural Languages,Linguistics Research Center, TheUniversity of Texas, Austin, Texas, 13-32.Dorr, Bonnie J.
(1990b).
"Solving thematicdivergences in machine translation."
InProceedings, 28th Annual Conference of theAssociation for Computational Linguistics,University of Pittsburgh, Pittsburgh,Pennsylvania, 127-134.630Bonnie J. Dorr Machine Translation DivergencesDorr, Bonnie J.
(1992a).
"Lexical semanticsfor interlingual machine translation.
"Machine Translation 7(3).Dorr, Bonnie J.
(1992b).
"A parameterizedapproach to integrating aspect withlexical-semantics formachine translation.
"In Proceedings, 30th Annual Conference oftheAssociation of Computational Linguistics,University of Delaware, NewarkDelaware, 257-264.Dorr, Bonnie J.
(1993a).
"lnterlingualmachine translation: A parameterizedapproach."
Artificial Intelligence 63(1,2).Dorr, Bonnie J.
(1993b).
Machine Translation:A View from the Lexicon.
Cambridge: MITPress.Dorr, Bonnie J., and Gaasterland, Terry(1992).
"Reflecting time in generated text:Tense, aspect and temporal connectingwords."
Technical report UMIACS TR92-92, CS TR 2950, Department ofComputer Science, University ofMaryland, College Park, Maryland.Dorr, Bonnie J., and Voss, Clare R.
(1993a).
"Constraints on the space of MTdivergences."
In Building Lexicons forMachine Translation, Papers from the 1993Spring Symposium, Technical reportSS-93-02, Stanford University, Stanford,California.Dorr, Bonnie J., and Voss, Clare R. (1993b).Machine translation of spatialexpressions: Defining the relationbetween an interlingua nd a knowledgerepresentation system."
In Proceedings,Twelfth Conference ofthe AmericanAssociation for Artificial Intelligence,Washington, DC.Farwell, David; Guthrie, Louise; and Wilks,Yorick (1992).
"The automatic reation oflexical entries for a multilingual MTsystem."
In Proceedings, 14th InternationalConference on Computational Linguistics,Nantes, France, 532-538.Goldman, Neil M. (1975).
"Conceptualmemory and inference."
In ConceptualInformation P~ocessing, edited by Roger C.Schank, 289-371.
Amsterdam, Holland:Elsevier Science Publishers.Granville, Robert (1983).
"Cohesion incomputer text generation: Lexicalsubstitution."
Technical Report, LCSTechnical Report 310, MassachusettsInstitute of Technology, Cambridge,Massachusetts.Hale, Kenneth, and Keyser, S. Jay (1986a).
"Some transitivity alternations inEnglish."
Technical report, Lexicon ProjectWorking Paper 7, Center for CognitiveScience, Massachusetts Institute ofTechnology, Cambridge, Massachusetts.Hale, Kenneth, and Keyser, S. Jay (1986b).
"A view from the middle."
Technicalreport, Lexicon Project Working Paper 10,Center for Cognitive Science,Massachusetts Institute of Technology,Cambridge, Massachusetts.Hale, Kenneth, and Keyser, S. Jay (1989).
"On some syntactic rules in the lexicon.
"Technical Report, Center for CognitiveScience, Massachusetts Institute ofTechnology, Cambridge, Massachusetts.Hale, Kenneth, and Laughren, Mary (1983).
"Warlpiri lexicon project: Warlpiridictionary entries."
Technical report,Warlpiri Lexicon Project, MassachusettsInstitute of Technology, Cambridge,Massachusetts.Hornstein, Norbert (1990).
As Time Goes By.Cambridge: MIT Press.Hovy, Eduard (1988).
Generating NaturalLanguage Under Pragmatic Constraints.
NewJersey: Lawrence Erlbaum Associates.Isabelle, Pierre (1987).
"Machine translationat the TAUM group."
In MachineTranslation: The State of the Art, edited byMargaret King, 247-277.
Edinburgh:Edinburgh University Press.Jackendoff, Ray S. (1983).
Semantics andCognition.
Cambridge: MIT Press.Jackendoff, Ray S. (1990).
SemanticStructures.
Cambridge: MIT Press.Jacobs, Paul S. (1985).
"PHRED: A generatorfor natural language interfaces.
"Computational Linguistics 11(4):219-242.Johnson, Rod; King, Maghi; and des Tombe,Louis (1985).
"Eurotra: A multilingualsystem under development.
"Computational Linguistics 11(2,3):155-169.Kameyama, Megumi; Ochitani, Ryo; Peters,Stanley; and Sirai, Hidetoshi (1991).
"Resolving translation mismatches withinformation flow."
In Proceedings, 29thAnnual Meeting of the Association forComputational Linguistics, University ofCalifornia, Berkeley, California, 193-200.Kaplan, Ronald M., and Bresnan, Joan(1982).
"Lexical-functional grammar: Aformal system for grammaticalrepresentation."
In The MentalRepresentation f Grammatical Relations,edited by Joan Bresnan, 173-28l.Cambridge: MIT Press.Kaplan, Ronald M.; Netter, Klaus;Wedekind, Jurgen; and Zaenen, Annie(1989).
"Translation by structuralcorrespondences."
In Proceedings, FourthConference ofthe European Chapter of theAssociation for Computational Linguistics,Manchester, UK, 272-281.Kay, Martin (1984).
"Functional unificationgrammar: A formalism for machine631Computational Linguistics Volume 20, Number 4translation."
In Proceedings, lOthInternational Conference on ComputationalLinguistics, Stanford University, Stanford,California, 75-78.Kinoshita, Satoshi; Phillips, John; and Tsujii,Jun-ichi (1992).
Interaction betweenstructural changes in machinetranslation."
In Proceedings, 14thInternational Conference on ComputationalLinguistics, Nantes, France, 679-685.Kittredge, Richard I.; Iordanskaja, Lidija;and Polgu6re, Alain (1988).
"Multi-lingualtext generation and the meaning-texttheory."
In Proceedings, Conference onTheoretical nd Methodological Issues inMachine Translation of Natural Languages,Carnegie Mellon University, Pittsburgh,Pennsylvania.Levin, Beth, and Rappaport, Malka (1986).
"The formation of adjectival passives.
"Linguistic Inquiry 17:623-662.Lindop, Jeremy, and Tsujii, Jun-ichi (1991).
"Complex transfer in MT: A survey ofexamples."
Technical report, CCL/UMISTReport 91/5, Center for ComputationalLinguistics, UMIST, Manchester, UK.Marantz, Alec (1992).
"Theway-constructions and the semantics ofdirect arguments in English: A reply toJackendoff."
Technical report, Departmentof Linguistics and Philosophy,Massachusetts Institute of Technology,Cambridge, Massachusetts.McCord, Michael C. (1989).
"Design ofLMT: A prolog-based machine translationsystem."
Computational Linguistics15(1):33-52.McKeown, Kathleen (1985).
Text generation:Using discourse strategies and focusconstraints to generate natural anguage text.Cambridge: Cambridge University Press.Melby, A. K. (1986).
"Lexical transfer:Missing element in linguistic theories."
InProceedings, 11th International Conference onComputational Linguistics, Bonn, Germany.Meyer, Ingrid; Onyshkevych, Boyan; andCarlson, Lynn (1990).
"Lexicographicprinciples and design forknowledge-based machine translation.
"Technical report, CMU CMT TechnicalReport 90-118, Carnegie MellonUniversity, Pittsburgh, Pennsylvania.Montemagni, Simonetta; nd Vanderwende,Lucy (1992).
"Structural patterns vs.string patterns for extracting semanticinformation from dictionaries."
InProceedings, 14th International Conference onComputational Linguistics, Nantes, France,546-552.Nirenburg, Sergei; Carbonell, Jaime; Tomita,Masaru; and Goodman, Kenneth (1992).Machine Translation: A Knowledge-BasedApproach.
San Mateo, California: MorganKaufmann.Nirenburg, Sergei, and Goodman, Kenneth(1990).
"Treatment of meaning in MTsystems."
In Proceedings, Third InternationalConference on Theoretical nd MethodologicalIssues in Machine Translation of NaturalLanguages, Linguistics Research Center,The University of Texas, Austin, Texas,171-187.Nirenburg, Sergei, and Levin, Lori (1989).
"Knowledge representation support.
"Machine Translation 4(1):25-52.Nirenburg, Sergei, and Nirenburg, Irene(1988).
"A framework for lexical selectionin natural language generation."
InProceedings, 12th International Conference onComputational Linguistics, Budapest,Hungary, 471-475.Nirenburg, Sergei; Raskin, Victor; andTucker, Allen B.
(1987).
"The structure ofinterlingua in translator."
In MachineTranslation: Theoretical nd MethodologicalIssues, edited by Sergei Nirenburg, 90-113.Cambridge: Cambridge University Press.Perlmutter, David M. (1983).
Studies inRelational Grammar 1.
Chicago: TheUniversity of Chicago Press.Proctor, P. (1978).
Longman Dictionary ofContemporary English.
London: Longman.Pustejovsky, James (1987).
"On theacquisition of lexical entries: Theperceptual origin of thematic relations.
"In Proceedings, 25th Annual Conference oftheAssociation for Computational Linguistics,Stanford University, Stanford, California,172-178.Pustejovsky, James, and Bergler, Sabine(1987).
"The acquisition of conceptualstructure for the lexicon."
In Proceedings,Sixth Conference ofthe American Associationof Artificial Intelligence, Seattle,Washington, 566-570.Pustejovsky, James; Bergler, Sabine; andAnick, Peter (1993).
"Lexical semantictechniques for corpus analysis.
"Computational Linguistics 19(2):331-358.Reichenbach, H. (1947).
Elements of SymbolicLogic.
London: Macmillan.Reiter, Ehud (1990).
"Generatingappropriate natural language objectdescriptions."
Doctoral dissertation,Harvard University, Cambridge, MA.Sadler, Louisa, and Thompson, Henry S.(1991).
"Structural non-correspondence intranslation."
In Proceedings, Fifth Conferenceof the European Chapter of the Association forComputational Linguistics, Berlin, Germany,293-298.Shieber, Stuart M.; van Noord, Gertjan;632Bonnie J. Dorr Machine Translation DivergencesMoore, Robert C.; and Pereira, FernandoC.
N. (1989).
"A semantic-head-drivengeneration algorithm for unification-basedformalisms."
In Proceedings, 27th AnnualConference ofthe Association forComputational Linguistics, University ofBritish Columbia, Vancouver, BritishColumbia, Canada, 7-17.Shieber, Stuart M.; van Noord, Gertjan;Moore, Robert C.; and Pereira, FernandoC.
N. (1990).
"Semantic-head-drivengeneration."
Computational Linguistics16(1).Sondheimer, N.; Cumming, S.; and Albano,R.
(1990).
"How to realize a concept:Lexical selection and the conceptualnetwork in text generation."
MachineTranslation 5(1):57-78.Thurmair, Gregor (1990).
"Complex lexicaltransfer in metal."
In Proceedings, ThirdInternational Conference on Theoretical ndMethodological Issues in Machine Translationof Natural Languages, Linguistics ResearchCenter, The University of Texas, Austin,Texas, 91-107.Trujillo, Arturo (1992).
"Locations in themachine translation of prepositionalphrases."
In Proceedings, FourthInternational Conference on Theoretical ndMethodological Issues in Machine Translationof Natural Languages, Montreal, Canada,13-20.Tsujii, Jun-ichi, and Fujita, Kimikazu (1991).
"Lexical transfer based on bilingual signs:Towards interaction during transfer."
InProceedings, European Chapter of theAssociation for Computational Linguistics,Berlin, Germany, 275-280.Vauquois, Bernard, and Boitet, Christian(1985).
"Automated translation atGrenoble University."
ComputationalLinguistics 11(1):28-36.Werner, P., and Nirenburg, S. (1988).
"Aspecification language that supports therealization of intersentential anaphora.
"In Proceedings, AAAI Workshop on NaturalLanguage Generation, Saint Paul,Minnesota.Whitelock, Pete (1992).
"Shake-and-baketranslation."
In Proceedings, 14thInternational Conference on ComputationalLinguistics, Nantes, France, 784-791.Wilks, Yorick (1973).
"An artificialintelligence approach to machinetranslation."
In Computer Models of Thoughtand Language, dited by Roger C. Schankand K. M. Colby, 114-151.
San Francisco:Freeman.Zubizarreta, Maria Luisa (1982).
"On therelationship of the lexicon to syntax.
"Doctoral dissertation, Department ofLinguistics and Philosophy,Massachusetts Institute of Technology,Cambridge, Massachusetts.Zubizarreta, Maria Luisa (1987).
Levels ofRepresentation n the Lexicon and in theSyntax.
Dordrecht, Holland: ForisPublications.633
