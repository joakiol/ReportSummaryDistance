Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 141?146,Sydney, July 2006. c?2006 Association for Computational LinguisticsParsing TAG with Abstract Categorial GrammarSylvain SalvatiNational Institute of Informatics2-1-2 Hitotsubashi, Chiyoda-ku,Tokyo 101-8430, JAPANsalvati@nii.ac.jpAbstractThis paper presents informally an Earleyalgorithm for TAG which behaves as thealgorithm given by (Schabes and Joshi,1988).
This algorithm is a specializationto TAG of a more general algorithm ded-icated to second order ACGs.
As secondorder ACGs allows to encode Linear Con-text Free Rewriting Systems (LCFRS) (deGroote and Pogodalla, 2004), the presen-tation of this algorithm gives a rough pre-sentation of the formal tools which canbe used to design efficient algorithms forLCFRS.
Furthermore, as these tools allowto parse linear ?-terms, they can be usedas a basis for developping algorithms forgeneration.1 IntroductionThe algorithm we present is a specialization toTAGs of a more general one dedicated to secondorder Abstract Categorial Grammars (ACGs) (deGroote, 2001).
Our aim is to give here an informalpresentation of tools that can be used to design ef-ficient parsing algorithms for formalisms more ex-pressive than TAG.
Therefore, we only give a rep-resentation of TAGs with linear ?-terms togetherwith simple derivation rules; we do not give incomplete details the technical relation with ACGs.For some more information about ACGs and theirrelation to TAGs, one may read (de Groote, 2001)and (de Groote, 2002).The advantage of using ACG is that they aredefined with very few primitives, but can encodemany formalisms.
Thus they are well suited tostudy from a general perspective a full class of for-malisms.
In particular, a special class of ACGs(second order ACGs) embeds LCFRS (de Grooteand Pogodalla, 2004), i.e.
mildly context sensi-tive languages.
Therefore, the study of secondorder ACGs leads to insights on mildly contextsensitive languages.
Having a general frameworkto describe parsing algorithms for mildly contextsensitive languages may give some help to trans-fer some interesting parsing technique from oneformalism to another.
It can be, for example, agood mean to obtain prefix-valid algorithms, LCalgorithms, LR algorithms.
.
.
for the full class ofmildly context sensitive languages.The class of languages described by second or-der ACGs is wider than mildly context sensitivelanguages.
They can encode tree languages, andmore generally languages of linear ?-terms.
AsMontague style semantics (Montague, 1974) isbased on ?-calculus, being able to parse linear ?-term is a first step towards generation algorithmsseen as parsing algorithm.
Furthermore, since thisparsing algorithm is a generalization of algorithmsa` la Earley for CFGs and TAGs, the more generalalgorithm that can be used for generation (whensemantic formulae are linear) can be consideredas efficient.The paper is organized as follows: section twogives basic defintions and tools concerning the lin-ear ?-calculus.
Section three explains how the in-dices usually used by parsers are represented forthe linear ?-calculus.
Section four gives a roughexplaination of the encoding of TAGs within acompiled representation of second order ACGs.Section five explains the parsing algorithm and weconclude with section six.2 The linear ?-calculusWe begin by giving a brief definition of lineartypes and linear ?-terms together with some stan-141dard notations.
We assume that the reader is famil-iar with the usual notions related to ?-calculus (?-conversion, free variables, capture-avoiding sub-stitutions.
.
.
); for more details about ?-calculus,one may consult (Barendregt, 1984).Definition 1 The set of linear types, T , is thesmallest set containing {?}
and such that if ?, ?
?T then (?
( ?)
?
T .Given a type (?1 ( (?
?
?
(?n ( ?)
?
?
?
)), wewrite it (?1, .
.
.
, ?n)( ?.Definition 2 Given a infinite enumerable set ofvariables, X , and an alphabet ?, we define theset of linear ?-terms of type ?
?
T , ?
?, as thesmallest set satisfying the following properties:1. x ?
X ?
x?
?
??2.
t ?
??
?
x?
?
FV (t) ?
?x?.t ?
??(?3.
a ?
?
?
a ?
??(?4.
t1 ?
??(?
?t2 ?
??
?FV (t1)?FV (t2) ?
(t1t2) ?
?
?In general, we write ?x1 .
.
.
xn.t for?x1.
.
.
.
?xn.t and we write t0t1 .
.
.
tn for(.
.
.
(t0t1) .
.
.
tn).
Strings are represented byclosed linear ?-terms of type str = ?
( ?.Given a string abcde, it is represented by thefollowing linear ?-term: ?y?.a(b(c(d(e y?
))));/w/ represents the set of terms which are?-convertible to the ?-term representing thestring w. Concatenation is represented by+ = ?xstr1 xstr2 y?.xstr1 (xstr2 y?
), and (+w1)w2will be written w1 + w2.
The concatenationis moreover associative, we may thus writew1 + ?
?
?
+ wn.For the description of our algorithm, we rely oncontexts:Definition 3 A context is a ?-term with a hole.Contexts are defined by the following grammar:C = [] | ?C | C?
| ?V.CThe insertion of a term within a context is donethe obvious way.
One has nevertheless to remarkthat when a term t is inserted in a context C[], thecontext C[] can bind variables free in t. For exam-ple, if C[] = ?x.
[] and t = x then C[t] = ?x.xand x which was free in t is not free anymore inC[t].3 Indices as syntactic descriptionsUsually the items of Earley algorithms use indicesto represent positions in the input string.
The algo-rithm we describe is a particular instance of a moregeneral one which parses linear ?-terms ratherthan strings.
In that case, one cannot describe in asimple way positions by means of indices.
Insteadof indices, positions in a term t will be representedwith zippers ((Huet, 1997)), i.e.
a pair (C[], v) ofa context and a term such that C[v] = t. Figure 1explicits the correspondence between indices andzippers via an example.The items of Earley algorithms for TAGs usepairs of indices to describe portions of the inputstring.
In our algorithm, this role is played by lin-ear types built upon zippers; the parsing processcan be seen as a type-checking process in a par-ticular type system.
We will not present this sys-tem here, but we will give a flavor of the mean-ing of those types called syntactic descriptions(Salvati, 2006).
In order to represent the portionof a string between the indices i and j, we usethe zippers (Ci[], vi) and (Cj [], vj) which respec-tively represent the position i and j in the string.The portion of string is represented by the syntac-tic description (Cj [], vj) ( (Ci[], vi); this syn-tactic description can be used to type functionswhich take vj as argument and return vi as a re-sult.
For example, given the syntactic description:(?x.a(b(c[])), d(e x)) ( (?x.a[], b(c(d(e x)))),it represents the set of functions that result interms that are ?-convertible to b(c(d(e x))) whenthey take d(e x) as an argument; this set isexactly /bc/.
Our algorithm uses representa-tions of string contexts with syntactic descrip-tions such as d = ((C1[], v1) ( (C2[], v2)) ((C3[], v3)( (C4[], v4) (in the following we write((C1[], v1)( (C2[], v2), (C3[], v3))( (C4[], v4)for such syntactic descriptions).
Assume that(C1[], v1) ( (C2[], v2) represents /bc/ and that(C3[], v3) ( (C4[], v4) represents /abcde/, thend describes the terms which give a result in/abcde/ when they are applied to an elementof /bc/.
Thus, d describes the set of terms ?-convertible to ?fy.a(f(d(e y))), the set of termsrepresenting the string context a[ ]de.Some of the syntactic descriptions we use maycontain variables denoting non-specified syntacticdescriptions that may be instanciated during pars-ing.
In particular, the syntactic description vari-able F will always be used as a non-specified syn-1420 (?x.
[], a(b(c(d(e x))))) 1 (?x.a[], b(c(d(e x))))2 (?x.a(b[]), c(d(e x))) 3 (?x.a(b(c[])), d(e x))4 (?x.a(b(c(d[]), e x) 5 (?x.a(b(c(d(e[])))), x)?a?b?c?d?e?Figure 1: Correspondence indices/zippers for the string abcdetactic description representing strings (i.e.
F mayonly be substituted by a syntactic description ofthe form (C1[], v1) ( (C2[], v2)), such syntac-tic descriptions will represent the foot of an auxil-iary tree.
We will also use Y to represent a non-specifed point in the input sentence (i.e.
Y mayonly be substituted by syntactic descriptions ofthe form (C[], v)), such syntactic descriptions willrepresent the end of an elementary tree.As syntactic desccriptions are types for the lin-ear ?-calculus, we introduce the notion of typingcontext for syntactic descriptions.Definition 4 A typing context ?
(context forshort), is a set of pairs of the form x : d where xis a variable and d is a syntactic description suchthat x : d ?
?
and x : e ?
?
iff d = e.If x : d ?
?, then we say that x is declared withtype d in ?.Typing contexts ?
must not be confused withcontexts C[].
If a typing context ?
is the set{x1 : d1; .
.
.
;xn : dn} then we will write if byx1 : d1, .
.
.
, xn : dn.
In the present paper, typingcontexts may declare at most two variables.4 Representing TAG with second orderACGsWe cannot give here a detailed definition of secondorder ACGs here.
We therefore directly explainhow to transform TAGs into lexical entries repre-senting a second order ACG that can be directlyused by the algorithm.We represent a TAG G by a set of lexical en-tries LG.
Lexical entries are triples (?, t, ?)
where?
is a typing context, t is a linear ?-term and ?is either Na, Ns or Na.1 if N is a non-terminalof the considered TAG.
Without loss of general-ity, we consider that the adjunction at an interiornode of an elementary tree is either mandatoryor forbidden1 .
We adopt the convention of rep-1We do not treat here the case of optional adjunction, butour method can be straightforwardly extended to cope withit, following ideas from (de Groote, 2002).
It only modifiesthe way we encode a TAG with a set of lexical entries, thealgorithm remains unchanged.resenting adjunction nodes labeled with N by thevariable xstr(strNa , the substitution nodes labeledwith N ?
by the variable xstrNs , the foot node ofan auxiliary tree labeled with N?
by the variablef strNa.1 and the variable y?
will represent the endof strings.
When necessary, in order to respectthe linearity constraints of the ?-terms, indices areused to distinguish those variables.
This conven-tion being settled, the type annotation on variablesis not necessary anymore, thus we will write xNa ,xNs , fNa.1 and y.
To translate the TAG, we usethe function ?
defined by figure 2.
Given an initialtree T whose root is labeled by N and t the normalform of ?
(T ), ( , t,Ns)2 is the lexical entry asso-ciated to T ; if T is an auxiliary tree whose rootis labeled by N and t is the normal form of ?
(T )then ( , ?fNa.1.t,Na)2 is the lexical entry associ-ated to T .
A TAG G is represented by LG thesmallest set verifying:1. if T is an elementary tree of G then the lexi-cal entry associated to T is in LG.2.
if ( , t, ?)
?
LG, with ?
equals to Na or Ns,and t = C[xNat1t2] then (?, t1, Na.1) ?
LGwhere ?
= fMa.1 : F if fMa.1 ?
FV (t1)otherwise ?
is the empty typing context.Given a term t such that x?
?
FV (t), and(?, t?, ?)
?
LG, then we say that t is rewrittenas t[x?
:= t?
], t ?
t[x?
:= t?].
Furthermore if x?is the leftmost variable we write t ?l t[x?
:= t?
].It is easy to check that if t ??
t?
with FV (t?)
= ?,then t ?
?l t?.
A string w is generated by a LGwhenever xSs??
t and t ?
/w/ (S being the startsymbol of G).
Straightforwardly, the set of stringsgenerated by LG is exactly the language of G.5 The algorithmAs we want to emphasize the fact that the algo-rithm we propose borrows much to type checking,we use sequents in the items the algorithm manip-ulates.
Sequents are objects of the form ?
` t : d2In that case the typing context is empty.143????
?NT1 Tn.
.
.??????
?y.xNa(?
(T1) + ?
?
?
+ ?
(Tn))y xNa and y are fresh????
?NNAT1 Tn.
.
.??????
?
(T1) + ?
?
?
+ ?(Tn)?(N?)
??
?y.xNa(?y.fN.1y)y?
(N?NA) ??
?y.fN.1y?
(N ?)
??
?y.xNsy?
(a) ??
?y.ay?
() ??
?y.yFigure 2: Translating TAG into ACG: definition of ?where ?
is a typing context, t is a linear ?-term,and d is a syntactic description.The algorithm uses two kinds of items; eitheritems of the form (?
; ?
` t : d;L) (where L isa list of sequents, the subgoals, here L containseither zero or one element) or items of the form[Na.1; ?
; t; (C1[], v1) ( (C2[], v2)].
All the pos-sible instances of the items are given by figure 3.The algorithm is a recognizer but can easily be ex-tended into a parser3.
It fills iteratively a chart untila fixed-point is reached.
Elements are added to thechart by means of inference rules given by figure4, in a deductive parsing fashion (Shieber et al,1995).
Inference rules contain two parts: the firstpart is a set of premises which state conditions onelements that are already in the chart.
The secondpart gives the new element to add to the chart ifit is not already present.
For the more general al-gorithm, the rules are not much more numerous asthey can be abstracted into more general schemes.An item of the form (?
; ?1 ` t1 : d; ?2 ` t2 :(C1[], v1)) verifies:1.
(?
?1, t1, ?)
?
LG where ?
?1 = fNa.1 : F if?1 = fNa.1 : e or ?
?1 = ?1 otherwise.2.
there is a context C[] such that t1 = C[t2] andif d is of the form (d1, .
.
.
,dn)( (C2[], v2)(n must be 1, or 2) then C[y] ?
?l t?
so that t?is described by (C1[], v1)( (C2[], v2).3. if ?1 = fNa.1 : (C3[], v3) ( (C4[], v4)or if d = ((C3[], v3) ( (C4[], v4), Y ) (3Actually, if it is extended into a parser, it will ouput theshared forest of the derivation trees; (de Groote, 2002) ex-plains how to obtain the derived trees from the derivationtrees in the framework of ACGs(C2[], v2) and t1 = ?fNa.1y.v then fNa.1 ?lt??
and t??
is described by (C3[], v3) ((C4[], v4)An item of the form (?
; ?
` t : d; ) verifies:1.
(?
?, t, ?)
?
LG where ??
= fNa.1 : F if?
= fNa.1 : e or ??
= ?
otherwise2.
d does not contain non-specified syntacticdescriptions4 .3. t ?
?l t?
and t?
is described by d (d may eitherrepresent a string context or a string).4. if ?
= fNa.1 : (C3[], v3) ( (C4[], v4) or ifd = ((C3[], v3) ( (C4[], v4), (C1[], v1)) ((C2[], v2) and t1 = ?fNa.1y.t?
then fMa.1??lt??
and t??
is described by (C3[], v3) ((C4[], v4)Finally an item of the form[Na.1; ?
; t; (C1[], v1) ( (C2[], v2)] im-plies the existence of t?, (C3[], v3) and(C4[], v4) such that (Na;` t?
: ((C3[], v3) ((C4[], v4), (C1[], v1)) ( (C2[], v2); ) and(Na.1; ?
` t : (C3[], v3) ( (C4[], v4)); ) are inthe chart.An input ?y.C[y] is recognized iff when thefixed-point is reached, the chart contains an itemof the form (Ss; ` t : (?y.C[], y) ((?y.
[], C[y]); ) (where S is the start symbol of theTAG G.4There is no occurence of F or Y in d.144General items(Na ; ` ?fNa.1y.t1 : (F, Y )( (C1[], v1) ; fNa.1 : F, y : Y ` t2 : (C2[], v2))(Na ; ` ?fNa.1y.t : ((C1[], v1)( (C2[], v2), Y )( (C3[], v3) ; y : Y ` t2 : (C4[], v4))(Na ; ` ?fNa.1y.t : ((C1[], v1)( (C2[], v2), (C3[], v3))( (C4[], v4) ; )(?
; ` ?y.t1 : Y ( (C1[], v1) ; y : Y ` t2 : (C2[], v2))(?
; ` ?y.t : (C1[], v1)( (C2[], v2) ; )(Na.1 ; fMa.1 : F ` ?y.t : Y ( (C[], v) ; fMa.1 : F, y : Y ` t2 : (C2[], v2)(Na.1 ; fMa.1 : (C1[], v1)( (C2[], v2) ` ?y.t : Y ( (C3[], v3) ; y : Y ` t2 : (C4[], v4))(Na.1 ; fMa.1 : (C1[], v1)( (C2[], v2) ` ?y.t : (C3[], v3)( (C4[], v4) ; )Wrapped subtrees[Na.1 ; ; t ; (C1[], v1)( (C2[], v2)][Na.1 ; fMa.1 : (C1[], v1)( (C2[], v2) ; t ; (C3[], v3)( (C4[], v4)]Figure 3: Possible items6 Conclusion and perspectiveIn this paper, we have illustrated the use for TAGsof general and abstract tools, syntactic descrip-tions, which can be used to parse linear ?-terms.Even though ACGs are very general in their def-inition, the algorithm we describe shows that thisgenerality is not a source of unefficiency.
Indeed,this algorithm, a special instance of a general onewhich can parse any second order ACG and it be-haves exactly the same way as the algorithm givenby (Schabes and Joshi, 1988) so that it parses asecond order ACG encoding a TAG in O(n6).The technique used enables to see generation asparsing.
In the framework of second order ACG,the logical formulae on which generation is per-formed are bound to be obtained from semantic re-cipies coded with linear ?-terms and are thereforenot really adapted to Montague semantics.
Nev-ertheless, syntactic descriptions can be extendedwith intersection types (Dezani-Ciancaglini et al,2005) in order to cope with simply typed ?-calculus.
With this extension, it seems possibleto extend the algorithm for second order ACGsso that it can deal with simply typed ?-terms andwithout loosing its efficiency in the linear case.ReferencesHenk P. Barendregt.
1984.
The Lambda Calculus: ItsSyntax and Semantics, volume 103.
Studies in Logicand the Foundations of Mathematics, North-HollandAmsterdam.
revised edition.Philippe de Groote and Sylvain Pogodalla.
2004.
Onthe expressive power of abstract categorial gram-mars: Representing context-free formalisms.
Jour-nal of Logic, Language and Information, 13(4):421?438.Philippe de Groote.
2001.
Towards abstract categorialgrammars.
In Association for Computational Lin-guistic, editor, Proceedings 39th Annual Meetingand 10th Conference of the European Chapter,pages 148?155.
Morgan Kaufmann Publishers.Philippe de Groote.
2002.
Tree-adjoining grammarsas abstract categorial grammars.
TAG+6, Proceed-ings of the sixth International Workshop on Tree Ad-joining Grammars and Related Frameworks, pages145?150.Mariangiola Dezani-Ciancaglini, Furio Honsell, andYoko Motohama.
2005.
Compositional Characteri-zation of ?-terms using Intersection Types.
Theoret.Comput.
Sci., 340(3):459?495.Ge?rard Huet.
1997.
The zipper.
Journal of FunctionalProgramming, 7(5):549?554.Richard Montague.
1974.
Formal Philosophy: Se-lected Papers of Richard Montague.
Yale UniversityPress, New Haven, CT.Sylvain Salvati.
2006.
Syntactic descriptions: a typesystem for solving matching equations in the linear?-calculus.
In to be published in the proceedingsof the 17th International Conference on RewritingTechniques and Applications.Yves Schabes and Aravind K. Joshi.
1988.
An earley-type parsing algorithm for tree adjoining grammars.In Proceedings of the 26th annual meeting on Asso-ciation for Computational Linguistics, pages 258?269, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Stuart M. Shieber, Yves Schabes, and Fernando C. N.Pereira.
1995.
Principles and implementation ofdeductive parsing.
Journal of Logic Programming,24(1?2):3?36, July?August.
Also available as cmp-lg/9404008.145The initializer(?y.t, Ss) ?
LG(Ss; ` ?y.t : Y ( (?y.
[], u); y : Y ` t : (?y.
[], u))The scanner(?
; ?1 ` t1 : d; ?2 ` at2 : (C[], av))(?
; ?1 ` t1 : d; ?2 ` t2 : (C[a[]], v))(?
; ?
` t : d; y : Y ` y : (C[], v)) ?
= [Y := (C[], v)](?
; ?
` t : d.?
; )The predictor(?
; ?1 ` t1 : d; ?2 ` xNat2t3 : (C[], v)) ( , ?fNa.1y.t,Na) ?
LG(Na; ` ?fNa.1y.t : (F, Y )( (C[], v); fNa.1 : F, y : Y ` t : (C[], v))(?
; ?1 ` t1 : d; ?2 ` xNst2 : (C[], v)) ( , ?y.t,Ns) ?
LG(Ns; ` ?y.t : Y ( (C[], v); y : Y ` t : (C[], v))(?
; ?1 ` t1 : d; ?2 ` fNa.1t2 : (C2[], v2))(?3, ?y.t3, Na.1) ?
LG(Na.1; ?3 ` ?y.t3 : Y ( (C2[], v2); ?3, y : Y ` t3 : (C2[], v2))The completer(Na; ` t1 : ((C1[], v1)( (C2[], v2), (C3[], v3))( (C4[], v4); )(Na.1; ?2; t2 : (C1[], v1)( (C2[], v2); )[Na.1; ?2; t2; (C3[], v3)( (C4[], v4)](?
; ?1 ` t1 : d; y : Y,?
?2 ` xNat2t3 : (C1[], v1))[Na.1; ?2; t2; (C2[], v2)( (C1[], v1)]if ?2 = fMa.1 : f then ?
= [F := f ] else ?
= Id(?
; ?1.?
` t1 : d.?
; ?2 ` t3 : (C2[], v2))(?
; ?1 ` t1 : d; fNa.1 : F, y : Y ` fNa.1t2 : (C1[], v1))(Na.1; ?2 ` t2 : (C2[], v2)( (C1[], v1); )?
= [F := (C2[], v2)( (C1[], v1)](?
; ?1.?
` t1 : d.?
; y : Y ` t2 : (C2[], v2))(?
; ?1 ` t1 : d; ?2 ` xNst2 : (C1[], v1))(Ns; ` t2 : (C2[], v2)( (C1[], v1); )(?
; ?1 ` t1 : d; ?2 ` t2 : (C2[], v2))Figure 4: The rules of the algorithm146
