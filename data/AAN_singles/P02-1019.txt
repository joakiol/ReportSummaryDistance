Pronunciation Modeling for Improved Spelling CorrectionKristina ToutanovaComputer Science DepartmentStanford UniversityStanford, CA 94305 USARobert C. MooreMicrosoft ResearchOne Microsoft WayRedmond, WA 98052 USAAbstractThis paper presents a method for incor-porating word pronunciation informationin a noisy channel model for spelling cor-rection.
The proposed method builds anexplicit error model for word pronuncia-tions.
By modeling pronunciation simi-larities between words we achieve a sub-stantial performance improvement overthe previous best performing models forspelling correction.1 IntroductionSpelling errors are generally grouped into twoclasses (Kuckich, 1992) ?
typographic and cogni-tive.
Cognitive errors occur when the writer doesnot know how to spell a word.
In these cases themisspelling often has the same pronunciation as thecorrect word ( for example writing latex as latecks).Typographic errors are mostly errors related to thekeyboard; e.g., substitution or transposition of twoletters because their keys are close on the keyboard.Damerau (1964) found that 80% of misspelledwords that are non-word errors are the result of a sin-gle insertion, deletion, substitution or transpositionof letters.
Many of the early algorithms for spellingcorrection are based on the assumption that the cor-rect word differs from the misspelling by exactlyone of these operations (M. D. Kernigan and Gale,1990; Church and Gale, 1991; Mayes and F. Dam-erau, 1991).By estimating probabilities or weights for thedifferent edit operations and conditioning on theleft and right context for insertions and deletionsand allowing multiple edit operations, high spellingcorrection accuracy has been achieved.
At ACL2000, Brill and Moore (2000) introduced a new errormodel, allowing generic string-to-string edits.
Thismodel reduced the error rate of the best previousmodel by nearly 50%.
It proved advantageous tomodel substitutions of up to 5-letter sequences (e.gent being mistyped as ant, ph as f, al as le, etc.)
Thismodel deals with phonetic errors significantly betterthan previous models since it allows a much largercontext size.However this model makes residual errors, manyof which have to do with word pronunciation.
Forexample, the following are triples of misspelling,correct word and (incorrect) guess that the Brill andMoore model made:edelvise edelweiss advisebouncie bouncy bouncelatecks latex lacksIn this work we take the approach of modelingphonetic errors explicitly by building a separate er-ror model for phonetic errors.
More specifically,we build two different error models using the Brilland Moore learning algorithm.
One of them is aletter-based model which is exactly the Brill andMoore model trained on a similar dataset.
The otheris a phone-sequence-to-phone-sequence error modeltrained on the same data as the first model, but usingthe pronunciations of the correct words and the es-timated pronunciations of the misspellings to learnphone-sequence-to-phone-sequence edits and esti-mate their probabilities.
At classification time, N -best list predictions of the two models are combinedusing a log linear model.A requirement for our model is the availability ofComputational Linguistics (ACL), Philadelphia, July 2002, pp.
144-151.Proceedings of the 40th Annual Meeting of the Association fora letter-to-phone model that can generate pronunci-ations for misspellings.
We build a letter-to-phonemodel automatically from a dictionary.The rest of the paper is structured as follows:Section 2 describes the Brill and Moore model andbriefly describes how we use it to build our er-ror models.
Section 3 presents our letter-to-phonemodel, which is the result of a series of improve-ments on a previously proposed N-gram letter-to-phone model (Fisher, 1999).
Section 4 describes thetraining and test phases of our algorithm in more de-tail and reports on experiments comparing the newmodel to the Brill and Moore model.
Section 6 con-tains conclusions and ideas for future work.2 Brill and Moore Noisy Channel SpellingCorrection ModelMany statistical spelling correction methods can beviewed as instances of the noisy channel model.
Themisspelling of a word is viewed as the result of cor-ruption of the intended word as it passes through anoisy communications channel.The task of spelling correction is a task of finding,for a misspelling w, a correct word r 2 D, whereD is a given dictionary and r is the most probableword to have been garbled into w. Equivalently, theproblem is to find a word r for whichP (rjw) =P (r)P (wjr)P (w)is maximized.
Since the denominator is constant,this is the same as maximizing P (r)P (wjr).
In theterminology of noisy channel modeling, the distribu-tion P (r) is referred to as the source model, and thedistribution P (wjr) is the error or channel model.Typically, spelling correction models are not usedfor identifying misspelled words, only for propos-ing corrections for words that are not found in adictionary.
Notice, however, that the noisy chan-nel model offers the possibility of correcting mis-spellings without a dictionary, as long as sufficientdata is available to estimate the source model fac-tors.
For example, if r = Osama bin Laden andw = Ossama bin Laden, the model will predict thatthe correct spelling r is more likely than the incor-rect spelling w, provided thatP (w)P (r)<P (wjr)P (wjw)where P (wjr)=P (wjw) would be approximately theodds of doubling the s in Osama.
We do not pursuethis, here, however.Brill and Moore (2000) present an improved er-ror model for noisy channel spelling correction thatgoes beyond single insertions, deletions, substitu-tions, and transpositions.
The model has a set of pa-rameters P ( ! )
for letter sequences of lengthsup to 5.
An extension they presented has refined pa-rameters P ( !
jPSN) which also depend onthe position of the substitution in the source word.According to this model, the misspelling is gener-ated by the correct word as follows: First, a personpicks a partition of the correct word and then typeseach partition independently, possibly making someerrors.
The probability for the generation of the mis-spelling will then be the product of the substitutionprobabilities for each of the parts in the partition.For example, if a person chooses to type the wordbouncy and picks the partition boun cy, the proba-bility that she mistypes this word as boun cie willbe P (boun !
boun)P (cie !
cy).
The probabilityP (wjr) is estimated as the maximum over all parti-tions of r of the probability that w is generated fromr given that partition.We use this method to build an error model forletter strings and a separate error model for phonesequences.
Two models are learned; one model LTR(standing for ?letter?)
has a set of substitution prob-abilities P ( ! )
where  and  are characterstrings, and another model PH (for ?phone?)
has aset of substitution probabilities P ( ! )
whereand  are phone sequences.We learn these two models on the same data setof misspellings and correct words.
For LTR, we usethe training data as is and run the Brill and Mooretraining algorithm over it to learn the parameters ofLTR.
For PH, we convert the misspelling/correct-word pairs into pairs of pronunciations of the mis-spelling and the correct word, and run the Brill andMoore training algorithm over that.For PH, we need word pronunciations for the cor-rect words and the misspellings.
As the misspellingsare certainly not in the dictionary we need a letter-to-phone converter that generates possible pronun-ciations for them.
The next section describes ourletter-to-phone model.NETtalk MS SpeechSet Words Set WordsTraining 14,876 Training 106,650Test 4,964 Test 30,003Table 1: Text-to-phone conversion data3 Letter-to-Phone ModelThere has been a lot of research on machine learn-ing methods for letter-to-phone conversion.
Highaccuracy is achieved, for example, by using neuralnetworks (Sejnowski and Rosenberg, 1987), deci-sion trees (Jiang et al, 1997), and N -grams (Fisher,1999).
We use a modified version of the method pro-posed by Fisher, incorporating several extensions re-sulting in substantial gains in performance.
In thissection we first describe how we do alignment atthe phone level, then describe Fisher?s model, and fi-nally present our extensions and the resulting letter-to-phone conversion accuracy.The machine learning algorithms for convertingtext to phones usually start off with training datain the form of a set of examples, consisting of let-ters in context and their corresponding phones (clas-sifications).
Pronunciation dictionaries are the ma-jor source of training data for these algorithms, butthey do not contain information for correspondencesbetween letters and phones directly; they have cor-respondences between sequences of letters and se-quences of phones.A first step before running a machine learningalgorithm on a dictionary is, therefore, alignmentbetween individual letters and phones.
The align-ment algorithm is dependent on the phone set used.We experimented with two dictionaries, the NETtalkdataset and the Microsoft Speech dictionary.
Statis-tics about them and how we split them into trainingand test sets are shown in Table 1.
The NETtalkdataset contains information for phone level align-ment and we used it to test our algorithm for auto-matic alignment.
The Microsoft Speech dictionaryis not aligned at the phone level but it is much big-ger and is the dictionary we used for learning ourfinal letter-to-phone model.The NETtalk dictionary has been designed so thateach letter correspond to at most one phone, so aword is always longer, or of the same length as, itspronunciation.
The alignment algorithm has to de-cide which of the letters correspond to phones andwhich ones correspond to nothing (i.e., are silent).For example, the entry in NETtalk (when we removethe empties, which contain information for phonelevel alignment) for the word able is ABLE e b L.The correct alignment is A/e B/b L/L E/?, where ?
de-notes the empty phone.
In the Microsoft Speech dic-tionary, on the other hand, each letter can naturallycorrespond to 0, 1, or 2 phones.
For example, the en-try in that dictionary for able is ABLE ey b ax l. Thecorrect alignment is A/ey B/b L/ax&l E/?.
If we alsoallowed two letters as a group to correspond to twophones as a group, the correct alignment might beA/ey B/b LE/ax&l, but that would make it harder forthe machine learning algorithm.Our alignment algorithm is an implementa-tion of hard EM (Viterbi training) that starts offwith heuristically estimated initial parameters forP (phonesjletter) and, at each iteration, finds themost likely alignment for each word given the pa-rameters and then re-estimates the parameters col-lecting counts from the obtained alignments.
Herephones ranges over sequences of 0 (empty), 1,and 2 phones for the Microsoft Speech dictionaryand 0 or 1 phones for NETtalk.
The parametersP (phonesjletter) were initialized by a method sim-ilar to the one proposed in (Daelemans and van denBosch, 1996).
Word frequencies were not taken intoconsideration here as the dictionary contains no fre-quency information.3.1 Initial Letter-to-Phone ModelThe method we started with was the N-gram modelof Fisher (1999).
From training data, it learns rulesthat predict the pronunciation of a letter based on mletters of left and n letters of right context.
The rulesare of the following form:[Lm:T:Rn !
ph1p1ph2p2: : :]Here Lm stands for a sequence of m letters to theleft of T and Rn is a sequence of n letters to theright.
The number of letters in the context to the leftand right varies.
We used from 0 to 4 letters on eachside.
For example, two rules learned for the letter Bwere: [AB:B:OT !
  1:0] and [B !
b :96   :04],meaning that in the first context the letter B is silentwith probability 1:0, and in the second it is pro-nounced as b with probability :96 and is silent withprobability :04.Training this model consists of collecting countsfor the contexts that appear in the data with the se-lected window size to the left and right.
We col-lected counts for all configurations Lm:T:Rn form 2 f0; 1; 2; 3; 4g, n 2 f0; 1; 2; 3; 4g that occurredin the data.
The model is applied by choosing foreach letter T the most probable translation as pre-dicted by the most specific rule for the context ofoccurrence of the letter.
For example, if we wantto find how to pronounce the second b in abbot wewould chose the empty phone because the first rulementioned above is more specific than the second.3.2 ExtensionsWe implemented five extensions to the initial modelwhich together decreased the error rate of the letter-to-phone model by around 20%.
These are : Combination of the predictions of several ap-plicable rules by linear interpolation Rescoring of N -best proposed pronunciationsfor a word using a trigram phone sequence lan-guage model Explicit distinction between middle of wordversus start or end Rescoring of N -best proposed pronunciationsfor a word using a fourgram vowel sequencelanguage modelThe performance figures reported by Fisher(1999) are significantly higher than our figures us-ing the basic model, which is probably due to thecleaner data used in their experiments and the dif-ferences in phoneset size.The extensions we implemented are inspiredlargely by the work on letter-to-phone conversionusing decision trees (Jiang et al, 1997).
The lastextension, rescoring based on vowel fourgams, hasnot been proposed previously.
We tested the algo-rithms on the NETtalk and Microsoft Speech dic-tionaries, by splitting them into training and testsets in proportion 80%/20% training-set to test-setsize.
We trained the letter-to-phone models usingthe training splits and tested on the test splits.
WeModel Phone Acc Word AccInitial 88.83% 53.28%Interpolationof contexts 90.55% 59.04%Distinctionof middle 91.09% 60.81%Phonetictrigram 91.38% 62.95%Vowelfourgram 91.46% 63.63%Table 2: Letter-to-phone accuraciesare reporting accuracy figures only on the NETtalkdataset since this dataset has been used extensivelyin building letter-to-phone models, and becausephone accuracy is hard to determine for the non-phonetically-aligned Microsoft Speech dictionary.For our spelling correction algorithm we use a letter-to-phone model learned from the Microsoft Speechdictionary, however.The results for phone accuracy and word accuracyof the initial model and extensions are shown in Ta-ble 2.
The phone accuracy is the percentage cor-rect of all phones proposed (excluding the empties)and the word accuracy is the percentage of wordsfor which pronunciations were guessed without anyerror.For our data we noticed that the most specificrule that matches is often not a sufficiently goodpredictor.
By linearly interpolating the probabili-ties given by the five most specific matching ruleswe decreased the word error rate by 14.3%.
Theweights for the individual rules in the top five wereset to be equal.
It seems reasonable to combine thepredictions from several rules especially because thechoice of which rule is more specific of two is arbi-trary when neither is a substring of the other.
Forexample, of the two rules with contexts A:B: and:B:B, where the first has 0 right context and thesecond has 0 left letter context, one heuristic is tochoose the latter as more specific since right contextseems more valuable than left (Fisher, 1999).
How-ever this choice may not always be the best and itproves useful to combine predictions from severalrules.
In Table 2 the row labeled ?Interpolation ofcontexts?
refers to this extension of the basic model.Adding a symbol for interior of word produced again in accuracy.
Prior to adding this feature, wehad features for beginning and end of word.
Explic-itly modeling interior proved helpful and further de-creased our error rate by 4.3%.
The results after thisimprovement are shown in the third row of Table 2.After linearly combining the predictions from thetop matching rules we have a probability distribu-tion over phones for each letter.
It has been shownthat modeling the probability of sequences of phonescan greatly reduce the error (Jiang et al, 1997).
Welearned a trigram phone sequence model and usedit to re-score the N -best predictions from the basicmodel.
We computed the score for a sequence ofphones given a sequence of letters, as follows:Score(p1; p2; : : : ; pnjl1; l2: : : ln) =logYi=1:::nP (pijl1; l2: : : ln) +logYi=1:::nP (pijpi 1; pi 2) (1)Here the probabilities P (pijl1; l2: : : ln) are thedistributions over phones that we obtain for each let-ter from combination of the matching rules.
Theweight  for the phone sequence model was esti-mated from a held-out set by a linear search.
Thismodel further improved our performance and the re-sults it achieves are in the fourth row of Table 2.The final improvement is adding a term from avowel fourgram language model to equation 1 witha weight .
The term is the log probability of thesequence of vowels in the word according to a four-gram model over vowel sequences learned from thedata.
The final accuracy we achieve is shown inthe fifth row of the same table.
As a comparison,the best accuracy achieved by Jiang et al (1997)on NETalk using a similar proportion of trainingand test set sizes was 65:8%.
Their system usesmore sources of information, such as phones in theleft context as features in the decision tree.
Theyalso achieve a large performance gain by combiningmultiple decision trees trained on separate portionsof the training data.
The accuracy of our letter-to-phone model is comparable to state of the art sys-tems.
Further improvements in this component maylead to higher spelling correction accuracy.4 Combining Pronunciation andLetter-Based ModelsOur combined error model gives the probabilityPCMB(wjr) where w is the misspelling and r is aword in the dictionary.
The spelling correction algo-rithm selects for a misspelling w the word r in thedictionary for which the product P (r)PCMB(wjr)is maximized.
In our experiments we used a uniformsource language model over the words in the dictio-nary.
Therefore our spelling correction algorithm se-lects the word r that maximizes PCMB(wjr).
Brilland Moore (2000) showed that adding a source lan-guage model increases the accuracy significantly.They also showed that the addition of a languagemodel does not obviate the need for a good errormodel and that improvements in the error model leadto significant improvements in the full noisy channelmodel.We build two separate error models, LTR andPH (standing for ?letter?
model and ?phone?model).
The letter-based model estimates a prob-ability distribution PLTR(wjr) over words, andthe phone-based model estimates a distributionPPH(pron wjpron r) over pronunciations.
Usingthe PH model and the letter-to-phone model, we de-rive a distribution PPHL(wjr) in a way to be madeprecise shortly.
We combine the two models to esti-mate scores as follows:SCMB(wjr) =logPLTR(wjr) + logPPHL(wjr)The r that maximizes this score will also maxi-mize the probability PCMB(wjr).
The probabilitiesPPHL(wjr) are computed as follows:PPHL(wjr)=Xpron rP (pron r;wjr)=Xpron rP (pron rjr) P (wjpron r; r)This equation is approximated by the expressionfor PPHLshown in Figure 1 after several simplify-ing assumptions.
The probabilities P (pron rjr) arePPHL(wjr) Xpron r1num pron rmaxpron w(PPH(pron wjpron r) P (pron wjw))Figure 1: Equation for approximation of PPHLtaken to be equal for all possible pronunciations of rin the dictionary.
Next we assume independence ofthe misspelling from the right word given the pro-nunciation of the right word i.e.
P (wjr; pron r) =P (wjpron r).
By inversion of the conditional prob-ability this is equal to P (pron rjw) multiplied byP (w)=P (pron r).
Since we do not model thesemarginal probabilities, we drop the latter factor.Next the probability P (pron rjw) is expressed asXpron wP (pron w; pron rjw)which is approximated by the maximum term in thesum.
After the following decomposition:P (pron w; pron rjw)= P (pron wjw)P (pron rjw; pron w) P (pron wjw)P (pron rjpron w)where the second part represents a final indepen-dence assumption, we get the expression in Figure 1.The probabilities P (pron wjw) are given by theletter-to-phone model.
In the following subsections,we first describe how we train and apply the individ-ual error models, and then we show performance re-sults for the combined model compared to the letter-based error model.4.1 Training Individual Error ModelsThe error model LTR was trained exactly as de-scribed originally by Brill and Moore (2000).
Givena training set of pairs fwi; rig the algorithm es-timates a set of rewrite probabilities p( !
)which are the basis for computing probabilitiesPLTR(wjr).The parameters of the PH modelPPH(pron wjpron r) are obtained by traininga phone-sequence-to-phone-sequence error modelstarting from the same training set of pairs fwi; rigof misspelling and correct word as for the LTRmodel.
We convert this set to a set of pronunciationsof misspellings and pronunciations of correctwords in the following way: For each trainingsample fwi; rig we generate m training samplesof corresponding pronunciations where m is thenumber of pronunciations of the correct word riin our dictionary.
Each of those m samples is themost probable pronunciation of wiaccording toour letter-to-phone model paired with one of thepossible pronunciations of ri.
Using this trainingset, we run the algorithm of Brill and Moore to es-timate a set of substitution probabilities  !
forsequences of phones to sequences of phones.
Theprobability PPH(pron wjpron r) is then computedas a product of the substitution probabilities in themost probable alignment, as Brill and Moore did.4.2 ResultsWe tested our system and compared it to the Brilland Moore model on a dataset of around 10; 000pairs of misspellings and corresponding correctwords, split into training and test sets.
The ex-act data sizes are 7; 385 word pairs in the trainingset and 1; 812 word pairs in the test set.
This setis slightly different from the dataset used in Brilland Moore?s experiments because we removed fromthe original dataset the pairs for which we did nothave the correct word in the pronunciation dictio-nary.
Both models LTR and PH were trained on thesame training set.
The interpolation weight that thecombined model CMB uses is also set on the train-ing set to maximize the classification accuracy.At test time we do not search through all possiblewords r in the dictionary to find the one maximizingScoreCMB(wjr).
Rather, we compute the combi-nation score only for candidate words r that are inthe top N according to the PLTR(wjr) or are in thetop N according to PPH(pron wjpron r) for anyof the pronunciations of r from the dictionary andany of the pronunciations for w that were proposedby the letter-to-phone model.
The letter-to-phoneModel 1-Best 2-Best 3-Best 4-BestLTR 94.21% 98.18% 98.90 % 99.06%PH 86.36% 93.65% 95.69 % 96.63%CMB 95.58% 98.90% 99.34% 99.50%ErrorReduction 23.8% 39.6% 40% 46.8%Table 3: Spelling Correction Accuracy Resultsmodel returned for each w the 3 most probable pro-nunciations only.
Our performance was better whenwe considered the top 3 pronunciations of w ratherthan a single most likely hypothesis.
That is prob-ably due to the fact that the 3-best accuracy of theletter-to-phone model is significantly higher than its1-best accuracy.Table 3 shows the spelling correction accuracywhen using the model LTR, PH, or both in com-bination.
The table shows N -best accuracy results.The N -best accuracy figures represent the percenttest cases for which the correct word was in the topN words proposed by the model.
We chose the con-text size of 3 for the LTR model as this context sizemaximized test set accuracy.
Larger context sizesneither helped nor hurt accuracy.As we can see from the table, the phone-basedmodel alone produces respectable accuracy resultsconsidering that it is only dealing with word pronun-ciations.
The error reduction of the combined modelcompared to the letters-only model is substantial:for 1-Best, the error reduction is over 23%; for 2-Best, 3-Best, and 4-Best it is even higher, reachingover 46% for 4-Best.As an example of the influence of pronuncia-tion modeling, in Table 4 we list some misspelling-correct word pairs where the LTR model madean incorrect guess and the combined model CMBguessed accurately.5 Conclusions and Future WorkWe have presented a method for using word pro-nunciation information to improve spelling correc-tion accuracy.
The proposed method substantiallyreduces the error rate of the previous best spellingcorrection model.A subject of future research is looking for a bet-ter way to combine the two error models or buildingMisspelling Correct LTR Guessbouncie bouncy bounceedelvise edelweiss advisegrissel gristle grizzlelatecks latex lacksneut newt nutrench wrench ranchsaing saying sangstail stale stallTable 4: Examples of Corrected Errorsa single model that can recognize whether there isa phonetic or typographic error.
Another interest-ing task is exploring the potential of our model indifferent settings such as the Web, e-mail, or as aspecialized model for non-native English speakersof particular origin.ReferencesE.
Brill and R. C. Moore.
2000.
An improved errormodel for noisy channel spelling correction.
In Proc.of the 38th Annual Meeting of the ACL, pages 286?293.K.
Church and W. Gale.
1991.
Probability scoring forspelling correction.
In Statistics and Computing, vol-ume 1, pages 93?103.W.
Daelemans and A. van den Bosch.
1996.
Language-independent data-oriented grapheme-to-phoneme con-version.
In Progress in Speech Synthesis, pages 77?90.F.
J. Damerau.
1964.
A technique for computer detectionand correction of spelling errors.
In Communicationsof the ACM, volume 7(3), pages 171?176.W.
M. Fisher.
1999.
A statistical text-to-phone functionusing ngrams and rules.
In Proc.
of the IEEE Inter-national Conference on Acoustics, Speech and SignalProcessing, pages 649?652.L.
Jiang, H.W.
Hon, and X. Huang.
1997.
Improvementson a trainable letter-to-sound converter.
In Proceed-ings of the 5th European Conference on Speech Com-munication and Technology.K.
Kuckich.
1992.
Techniques for automatically correct-ing words in text.
In ACM Computing Surveys, volume24(4), pages 377?439.W.
Church M. D. Kernigan and W. A. Gale.
1990.
Aspelling correction program based on a noisy channelmodel.
In Proc.
of COLING-90, volume II, pages 205?211.F.
Mayes and et al F. Damerau.
1991.
Conext basedspelling correction.
In Information Processing andManagement, volume 27(5), pages 517?522.T.
J. Sejnowski and C. R. Rosenberg.
1987.
Parallel net-works that learn to pronounce english text.
In ComplexSystems, pages 145?168.
