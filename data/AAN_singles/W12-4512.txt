Proceedings of the Joint Conference on EMNLP and CoNLL: Shared Task, pages 107?112,Jeju Island, Korea, July 13, 2012. c?2012 Association for Computational LinguisticsIncorporating Rule-based and Statistic-based Techniques forCoreference ResolutionRuifeng Xu, Jun Xu, Jie Liu, Chengxiang Liu, Chengtian Zou, Lin Gui, YanzhenZheng, Peng QuHuman Language Technology Group, Key Laboratory of Network Oriented IntelligentComputation, Shenzhen Graduate School, Harbin Institute of Technology, China{xuruifeng.hitsz;hit.xujun;lyjxcz;matitalk;chsky.zou;monta3pt;zhyz.zheng;viphitqp@gmail.com}AbstractThis paper describes a coreference resolutionsystem for CONLL 2012 shared taskdeveloped by HLT_HITSZ group, whichincorporates rule-based and statistic-basedtechniques.
The system performs coreferenceresolution through the mention pairclassification and linking.
For each detectedmention pairs in the text, a Decision Tree (DT)based binary classifier is applied to determinewhether they form a coreference.
Thisclassifier incorporates 51 and 61 selectedfeatures for English and Chinese, respectively.Meanwhile, a rule-based classifier is applied torecognize some specific types of coreference,especially the ones with long distances.
Theoutputs of these two classifiers are merged.Next, the recognized coreferences are linked togenerate the final coreference chain.
Thissystem is evaluated on English and Chinesesides (Closed Track), respectively.
It achieves0.5861 and 0.6003 F1 score on thedevelopment data of English and Chinese,respectively.
As for the test dataset, theachieved F1 scores are 0.5749 and 0.6508,respectively.
This encouraging performanceshows the effectiveness of our proposedcoreference resolution system.1 IntroductionCoreference resolution aims to find out thedifferent mentions in a document which refer to thesame entity in reality (Sundheim and Beth, 1995;Lang et al 1997; Chinchor and Nancy, 1998;).
It isa core component in natural language processingand information extraction.
Both rule-basedapproach (Lee et al 2011) and statistic-basedapproach (Soon et al, 2001; Ng and Cardie, 2002;Bengtson and Roth, 2008; Stoyanov et al, 2009;Chen et al 2011) are proposed in coreferenceresolution study.
Besides the frequently usedsyntactic and semantic features, the more linguisticfeatures are exploited in recent works (Versley,2007; Kong et al 2010).CoNLL-2012 proposes a shared task, ?Modelingmultilingual unrestricted coreference in theOntoNotes?
(Pradhan et al 2012).
This is anextension of the CoNLL-2011 shared task.
Thetask involves automatic anaphoric mentiondetection and coreference resolution across threelanguages including English, Chinese and Arabic.HLT_HITSZ group participated in the ClosedTrack evaluation on English and Chinese side.
Thispaper presents the framework and techniques ofHLT_HITSZ system which incorporates both rule-based and statistic-based techniques.
In this system,the mentions are firstly identified based on theprovided syntactic information.
The mention pairsin the document are fed to a Decision Tree basedclassifier to determine whether they form acoreference or not.
The rule-based classifiers arethen applied to recognize some specific types ofcoreference, in particular, the long distance ones.Finally, the recognized coreference are linked toobtain the final coreference resolution results.
Thissystem incorporates lexical, syntactical andsemantic features.
Especially for English, WordNetis used to provide semantic information of thementions, such as semantic distance and the107category of the mentions and so on.
Other than theofficially provided number and gender data, wegenerated some lexicons from the training datasetto obtain the values of some features.
This systemachieves 0.5861 and 0.6003 F1 scores on Englishand Chinese development data, respectively, and0.5749 and 0.6508 F1 scores on English andChinese testing data, respectively.
The achievedencouraging performances show that the proposedincorporation of rule-based and statistic-basedtechniques is effective.The rest of this report is organized as below.Section 2 presents the mention detection.
Section 3presents the coreference determination and Section4 presents the coreference linking.
Theexperimental results are given in Section 5 in detail.Finally, Section 6 concludes this report.2 Mention DetectionIn this stage, the system detects the mentions fromthe text.
The pairs of these mentions in onedocument are regarded as the coreferencecandidates.
Thus, the high recall is a moreimportant target than higher precision for this stage.Corresponding to English and Chinese, we adopteddifferent detection methods, respectively.2.1 Mention Detection - EnglishHLT_HITSZ system chooses the marked nounphrase (NP), pronouns (PRP) and PRP$ in Englishdata as the mentions.
The system selects mostnamed entities (NE) as the mentions but filter outsome specific types.
Firstly, the NEs which cannotbe labeled either as NP or NML are filter outbecause there are too cases that the pairs of theseNEs does not corefer even they are in the sameform as shown in the training dataset.
Second, theNEs of ORDINAL, PERCENT and MONEY typesare filtered because they have very low coreferenceratio (less than 2%).
Furthermore, for the cases thatNPs overlapping a shorter NP, normally, only thelonger one are choose.
An exception is that if theshorter NPs are in parallel structures with the samelevel to construct a longer NP.
For example, for aNP ?A and B?, ?A?, ?B?
and ?A and B?
asregarded ed as three different mentions.2.2 Mention Detection ?
ChineseHLT_HITSZ system extracts all NPs and PNs asthe mention candidates.
For the NPs have theoverlaps, we handle them in three ways: 1.
For thecases that two NPs share the same tail, the longerNP is kept and the rest discarded; 2.
For cases thatthe longer NP has a NR as its tail, the NPs whichshare the same tail are discarded; 3.
In MZ andNW folders, they are many mentions nestedmarked as the nested co-referent mentions.
Thesystem selects the longest NP as mention in thisstage while the other mention candidates in thelongest NP will be recalled in the post processingstage.3 Coreference DeterminationAny pair of two detected mentions in onedocument becomes one coreference candidate.
Inthis stage, the classifiers are developed todetermine whether this pair be a coreference or not.During the generation of mention pairs, it isobserved that linking any two mentions in onedocument as candidates leads to much noises.
Thestatistical observation on the Chinese trainingdataset show that 90% corefered mention pairs arein the distance of 10 sentences.
Similar results arefound in the English training dataset while thecontext window is set to 5 sentences.
Therefore, inthis stage, the context windows for generatingmention pairs as coreference candidates forEnglish and Chinese are limited to 5 and 10sentences, respectively.3.1 The Statistic-based CoreferenceDeterminationThe same framework is adopted in the statistical-based coreference determination for English andChinese, respectively, which is based on a machinelearning-based statistical classifier and selectedlanguage-dependent features.
Through transfer theexamples in the training test into feature-valuedspace, the classifier is trained.
This binaryclassifier will be applied to determine whether theinput mention pair be a coreference or not.
Here,we evaluated three machine learning basedclassifiers including Decision Tree, Support VectorMachines and Maximum Entropy on the trainingdata while Decision Tree perform the best.
Thus,DT classifier is selected.
Since the annotations onthe training data from different directory showsome inconsistence, multiple classifierscorresponding to each directory are trainedindividually.1083.1.1 Features - English51 features are selected for English coreferencedetermination.
The features are camped to sixcategories.
Some typical features are listed below:1.
Basic features:(1) Syntactic type of the two mentions,includes NP, NE, PRP, PRP$.
Here, onlythe NPs which do not contain any namedentities or its head word isn?t a namedentity are considered as an NP while theothers are discarded.
(2) If one mention is a PRP or PRP$, use anID to specify which one it is.
(3) The sentence distance between twomentions.
(4) Whether one mention is contained byanother one.2.
Parsing features:(1) Whether two mentions belong to one NP.
(2) The phrase distance between the twomentions.
(3) The predicted arguments which the twomentions belong to.3.
Named entity related features:(1) If both of the two mentions may beconsidered as named entities, whetherthey have the same type.
(2) If one mention is a common NP or PRPand another one can be considered asnamed entity, whether the words of thecommon NP or PRP can be used to referthis type of named entity.
This knowledgeis extracted from the training dataset.
(3) Whether the core words of the two namedentity type NP match each other.4.
Features for PRP:(1) If both mentions are PRP or PRP$, use anID to show what they are.
The PRP$ withthe same type will be assigned the sameID, for example, he, him and his.
(2) Whether the two mentions has the samePRP ID.5.
Semantic Features:(1) Whether the two mentions have the sameheadword.
(2) Whether the two mentions belong to thesame type.
Here, we use WordNet to getthree most common sense of each NP andcompare the type they belong to.
(3) The semantic distance between twomentions.
WordNet is used here.
(4) The natures of the two mentions, includingnumber, gender, is human or not, andmatch each other or not.
We use WordNetand a lexicon extracted from the genderand number file here.6.
Document features:(1) How many speakers in this document.
(2) Whether the mention is the first or the lastsentence of the document.
(3) Whether the two mentions are from thesame speaker.3.1.2 Features - ChineseThere are 61 features adopted in Chinese side.Because of the restriction of closed crack, most offeatures use the position and POS information.
It ismentionable that the ways for calculating thefeatures values.
For instance, the sentence distanceis not the real sentence distance in the document.For instead, the value is the number of sentences inwhich there are at least one mention between themention pair.
This ignores the sentences of onlymodal particles.The 61 features are camped into five groups.Some example features are listed below.1.
Basic information:(1) The matching degree of two mentions(2) The word distance of two mentions(3) The sentence distance of two mentions2.
Parsing information:(1) Predicted arguments which the twomentions belong to and correspondinglayers.3.
POS features(1) Whether the mention is NR(2) Whether the two mentions are both NRand are matched4.
Semantic features:(1) Whether the two mention is related(2) Whether the two mentions corefer in thehistory.
Since the restriction of closedtrack, we did not use any additionalsemantic resources.
Here, we extract theco-reference history from the training setto obtain some semantic information, suchas ?NN ???
and ?NN ???
corefered inthe training data, and they are regarded ascoreference in the testing data.5.
Document Features:109(1) Whether the two mentions have the samespeaker.
(2) Whether the mention is a human.
(3) Whether the mention is the first mention inthe sentence.
(4) Whether the sentence to which the mentionbelongs to is the first sentence.
(5) Whether the sentence to which the mentionbelongs to is the second sentence(6) Whether the sentence to which the mentionbelongs to is the last sentence(7) The number of the speakers in thedocument.3.2 The Rule-based CoreferenceDeterminationThe rule-based classifier is developed to recognize somespecific types of coreference and especially, the longdistance ones.3.2.1 Rule-based Classifier - EnglishTo achieve a high precision, only the mention pairsof NE-NE (include NPs those can be considered asNE) or NP-NP types with the same string areclassified here.For the NE-NE pair, the classifier identifies theirNE part from the whole NP, if their strings are thesame, they are considered as coreference.For the NP-NP pair, the pairs satisfy thefollowing rules are regarded as coreference.
(1) The POS of the first word isn?t ?JJR?
or ?JJ?.
(2) If NP has only one word, its POS isn?t ?NNS?or ?NNPS?.
(3) The NP have no word like ?every?, ?every-?,?none?, ?no?,  ?any?,  ?some?,  ?each?.
(4) If the two NP has article, they can?t be both?a?
or ?an?.Additionally, for the PRP mention pairs, only?I?, ?me?, ?my?
with the same speaker can beregarded as coreference.3.2.2 Rule-based Classifier - ChineseA rule-based classifier is developed to determinewhether the mention pairs between PNs andmentions not PN corefer or not.
For instance, themention pairs between the PN ???
which is after acomma and the mention which is marked as ARG0in the same sentence.
In the sentence ????????
?
?
??
??
??
??
?
??
?,because the mention pair between ??????
?and the first ???
match the mentioned above rule,it  is classified as a positive one.
The result on thedevelopment set shows that the rule-basedclassifier brings good improvement.4 Coreference Chain Construction4.1 Coreference Chain Construction-EnglishThe evaluation on development data shows that theachieved precision of our system is better thanrecall.
Thus, in this stage, we simply link everypair of mentions together if there is any links canlink them together to generate the initialcoreference chain.
After that, the mentions havethe distance longer than 5 sentences are observed.The NE-NE or NP-NP mention pairs between oneknown coreference and an observing mention withlong distance are classified to determine they arecorefered or not by using a set of rules.
The newdetected conference will be linked to the initialcoreference chain.4.2 Coreference Chain Construction-ChineseThe coreference chain construction for Chinese issimilar to English.
Furthermore, as mentionedabove, in MZ and NW folders, there are manymentions nested marked as the nested co-referenced mentions.
In this stage, HLT_HITSZsystem generates the nested co-reference mentionsfor improving the analysis for these two folders.Additionally, the system uses some rules toimprove the coreference chain construction.
Wefind that the trained classifier performs poor in co-reference resolution related to Pronoun.
So, mostrules adopted here are related to these Pronouns:???
?, ??
?, ??
?, ??
?, ??
?, ???
?, ????,???.
We use these rules to bridge the chain ofpronouns and the chain of other type.Although high precision for NT co-referencecases are achieved through string matching, therecall is not satisfactory.
It partially attributes tothe fact that the flexible use of Chinese.
Forexample, to express the year of 1980, we found??????
?, ?????
?, ?
????
?, ????
?, ?1980 ?
?.
Similar situation happens formonth (?, ??)
and day (?,?
), we concludemost situations to several templates to improve therule-based conference resolution.1105 Evaluation Results5.1 DatasetThe status of training dataset, development datasetand testing dataset in CoNLL 2012 for English andChinese are given in Table 1 and Table 2,respectively.Files Sentence Cluster CoreferenceTrain 1,940 74,852 35,101 155,292Development 222 9,603 4,546 19,156Test 222 9,479 n/a n/aTable 1.
Status of CoNLL 2012 dataset - EnglishFiles Sentence Cluster CoreferenceTrain 1,391 36,487 28,257 102,854Develop 172 6,083 3,875 14,383Test 166 4,472 n/a n/aTable 2.
Status of CoNLL 2012 dataset - Chinese5.2 Evaluation on Mention DetectionFirstly, the mention detection performance is evaluated.The performance achieved on the development dataset(Gold/Auto) and test data on English and Chinese aregiven in Table 3 and Table 4, respectively.
In which,Gold means the development dataset with goldmanually annotation and Auto means the automaticallygenerated annotations.Precision Recall F1Develop-Gold 0.8499 0.6716 0.7503Develop-Auto 0.8456 0.6256 0.7192Test 0.8455 0.6264 0.7196Table 3.
Performance on Mention Detection - EnglishPrecision Recall F1Develop-Gold 0.7402 0.7360 0.7381Develop-Auto 0.6987 0.6429 0.6697Test 0.7307 0.7502 0.7403Table 4.
Performance on Mention Detection - ChineseGenerally speaking, our system achieves acceptablemention detection performance, but furtherimprovements are desired.5.3 Evaluation on Coreference ResolutionThe performance on coreference resolution is nextevaluated.
The achieved performances on thedevelopment data (Gold/Auto) and test dataset onEnglish and Chinese are given in Table 5 and Table 6,respectively.
It is shown that the OF performance drops0.0309(Gold) and 0.0112(Auto) from developmentdataset to test dataset on English, respectively.
On thecontrary, the OF performance increases 0.0096(Gold)and 0.0505(Auto) from development dataset to testdataset on Chinese, respectively.
Compared with theperformance reported in CoNLL2012 shared task, oursystem achieves a good result, ranked 3rd, on Chinese.The results show the effectiveness of our proposedsystem.Precision Recall F1MUC 0.7632 0.6455 0.6994BCUB 0.7272 0.6797 0.7027CEAFE 0.3637 0.4840 0.4154OF-Develop-Gold   0.6058MUC 0.7571 0.5993 0.6691BCUB 0.7483 0.6441 0.6923CEAFE 0.3350 0.4865 0.3968OF-Develop-Auto   0.5861MUC 0.7518 0.5911 0.6618BCUB 0.7329 0.6228 0.6734CEAFE 0.3264 0.4829 0.3895OF-Test   0.5749Table 5.
Performance on Coreference Resolution ?EnglishPrecision Recall F1MUC 0.6892 0.6655 0.6771BCUB 0.7547 0.7410 0.7478CEAFE 0.4876 0.5105 0.4988OF-Develop-Gold   0.6412MUC 0.6535 0.5643 0.6056BCUB 0.7812 0.6809 0.7276CEAFE 0.4322 0.5101 0.4679OF-Develop-Auto   0.6003MUC 0.6928 0.6595 0.6758BCUB 0.7765 0.7328 0.7540CEAFE 0.5072 0.5390 0.6253OF-Test(Gold parses)   0.6508MUCBCUBCEAFEOF-Test-Predicted-mentions(Auto parses)0.55020.68390.50400.61470.76380.44810.58070.72160.47440.5922MUCBCUBCEAFEOF-Test-Gold-mention-boundaries(Auto parses)0.63540.71360.53900.68730.78700.49070.66030.74850.51370.6408MUCBCUBCEAFEOF-Test-Gold-mentions(Auto parses)0.65630.65050.78130.94070.91230.43770.77320.75950.56110.6979Table 6.
Performance on Coreference Resolution ?Chinese1116 ConclusionsThis paper presents the HLT_HITSZ system forCoNLL2012 shared task.
Generally speaking, thissystem uses a statistic-based classifier to handleshort distance coreference resolution and uses arule-based classifier to handle long distance cases.The incorporation of rule-based and statistic-basedtechniques is shown effective to improve theperformance of coreference resolution.
In ourfuture work, more semantic and knowledge baseswill be incorporated to improve coreferenceresolution in open track.AcknowledgementThis research is supported by HIT.NSFIR.201012from Harbin Institute of Technology, China andChina Postdoctoral Science Foundation No.2011M500670.ReferencesB.
Baldwin.
1997.
CogNIAC: High PrecisionCoreference with Limited Knowledge and LinguisticResources.
Proceedings of Workshop on OperationalFactors in Practical, Robust Anaphora Resolution forUnrestricted Texts.E.
Bengtson, D. Roth.
2008.
Understanding the Value ofFeatures for Coreference Resolution.
Proceedings ofEMNLP 2008, 294-303.M.
S. Beth M. 1995.
Overview of Results of the MUC-6Evaluation.
Proceedings of the Sixth MessageUnderstanding Conference (MUC-6)W. P. Chen, M. Y. Zhang, B. Qin,  2011.
CoreferenceResolution System using Maximum EntropyClassifier.
Proceedings of CoNLL-2011.N.
A. Chinchor.
1998.
Overview of MUC-7/MET-2.Proceedings of the Seventh Message UnderstandingConference (MUC-7).F.
Kong, G. D. Zhou, L. H. Qian, Q. M. Zhu.
2010.Dependency-driven Anaphoricity Determination forCoreference Resolution.
Proceedings of COLING2010, 599-607J.
Lang, B. Qin, T. Liu.
2007.
Intra-documentCoreference Resolution: The State of the Art.
Journalof Chinese Language and Computing , 2007, 17( 4) :227-253.H.
Lee, Y. Peirsman, A. Chang, N. Chambers, M.Surdeanu, D. Jurafsky.
2011.
Stanford?s Multi-PassSieve Coreference Resolution System at the CoNLL-2011 Shared Task.
Proceedings of CoNLL-2011.V.
Ng and C. Cardie.
2002.
Improving MachineLearning Approaches to Coreference Resolution.Proceedings of ACL 2002.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
AMachine Learning Approach to CoreferenceResolution of Noun Phrases.
ComputationalLinguistics, 27(4):521-544S.
Pradhan and A. Moschitti et al 2012.
CoNLL-2012Shared Task: Modeling Multilingual UnrestrictedCoreference in OntoNotes.
Proceedings of CoNLL2012V.
Stoyanov, N. Gilbert, C. Cardie, E. Riloff.
2009.Conundrums in Noun Phrase Coreference Resolution:Making Sense of the State-of-the-Art.
ProceedingACL 2009Y.
Versley.
2007.
Antecedent Selection Techniques forHigh-recall Coreference Resolution.
Proceedings ofEMNLP/CoNLL 2007.Y.
Yang, N. W. Xue, P. Anick.
2011.
A MachineLearning-Based Coreference Detection System ForOntoNotes.
Proceedings of CoNLL-2011.112
