Proceedings of the 2009 Workshop on Applied Textual Inference, ACL-IJCNLP 2009, pages 44?47,Suntec, Singapore, 6 August 2009.c?2009 ACL and AFNLPRanking Paraphrases in ContextStefan ThaterUniversit?t des Saarlandesstth@coli.uni-sb.deGeorgiana DinuUniversit?t des Saarlandesdinu@coli.uni-sb.deManfred PinkalUniversit?t des Saarlandespinkal@coli.uni-sb.deAbstractWe present a vector space model that sup-ports the computation of appropriate vec-tor representations for words in context,and apply it to a paraphrase ranking task.An evaluation on the SemEval 2007 lexicalsubstitution task data shows promising re-sults: the model significantly outperformsa current state of the art model, and ourtreatment of context is effective.1 IntroductionKnowledge about paraphrases is of central impor-tance to textual inference modeling.
Systems whichsupport automatic extraction of large repositoriesof paraphrase or inference rules like Lin and Pantel(2001) or Szpektor et al (2004) thus form first-classcandidate resources to be leveraged for NLP taskslike question answering, information extraction, orsummarization, and the meta-task of recognizingtextual entailment.Existing knowledge bases still suffer a numberof limitations, making their use in applicationschallenging.
One of the most serious problemsis insensitivity to context.
Natural-language infer-ence is highly context-sensitive, the applicabilityof inference rules depending on word sense andeven finer grained contextual distinctions in us-age (Szpektor et al, 2007).
Application of a rulelike ?X shed Y ?
X throw Y?
is appropriate in asentence like ?a mouse study sheds light on themixed results,?
but not in sentences like ?the econ-omy seems to be shedding fewer jobs?
or ?catsdo not shed the virus to other cats.?
Systems likethe above-mentioned ones base the extraction ofinference rules on distributional similarity of wordsrather than word senses, and apply unconditionallywhenever one side of the rule matches on the wordlevel, which may lead to considerable precisionproblems (Geffet and Dagan, 2005) .Some approaches address the problem of con-text sensitivity by deriving inference rules whoseargument slots bear selectional preference infor-mation (Pantel et al, 2007; Basili et al, 2007).
Adifferent line of accounting for contextual variationhas been taken by Mitchell and Lapata (2008), whopropose a compositional approach, ?contextualiz-ing?
the vector-space meaning representation ofpredicates by combining the distributional proper-ties of the predicate with those of its arguments.A related approach has been proposed by Erk andPad?
(2008), who integrate selectional preferencesinto the compositional picture.
In this paper, wepropose a context-sensitive vector-space approachwhich draws some important ideas from Erk andPado?s paper (?E&P?
in the following), but imple-ments them in a different, more effective way: Anevaluation on the SemEval 2007 lexical substitu-tion task data shows that our model significantlyoutperforms E&P in terms of average precision.Plan of the paper.
Section 2 presents our modeland briefly relates it to previous work.
Section 3describes the evaluation of our model on the lexicalsubstitution task data.
Section 4 concludes.2 A model for meaning in contextWe propose a dependency-based model whose di-mensions reflect dependency relations, and distin-guish two kinds or layers of lexical meaning: ar-gument meaning and predicate meaning.
The argu-ment meaning of a word w is a vector representingfrequencies of all pairs (w?,r?)
of predicate expres-sions w?and dependency relations r?such that w?stands in relation r?to w. Intuitively, argumentmeaning is similar to E&P?s ?inverse selectionalpreferences.?
Argument meanings are used for twopurposes in our model: (i) to construct predicatemeanings, and (ii) to contextually constrain them.For technical convenience, we will use a defini-tional variant of argument meaning, by indexingit with an ?incoming?
relation, which allows pred-icate and argument meaning to be treated techni-cally as vectors of the same type.
Assuming a set44R of role labels and a set W of words, we representboth predicate and argument meaning as vectorsin a vector space V with a basis {ei}i?R?R?W, i.e.,a vector space whose dimensions correspond totriples of two role labels and a word.
The argumentmeaning vr(w) of a word w is defined as follows:vr(w) =?w??W,r?
?Rf (w?,r?,w) ?
e(r,r?,w?
), (1)where r is the ?incoming?
relation, and f (w?,r?,w)denotes the frequency of w occurring in relation r?to w?in a collection of dependency trees.
To obtainpredicate meaning vP(w), we count the occurrencesof argument words w?standing in relation r to w,and compute the predicate meaning as the sum ofthe argument meanings vr(w?
), weighted by theseco-occurrence frequencies:vP(w) =?r?R,w?
?Wf (w,r,w?)
?
vr(w?)
(2)That is, the meaning of a predicate is modelled by avector representing ?second order?
co-coccurrencefrequencies with other predicates.In general, words have both a ?downward look-ing?
predicate meaning and an ?upward looking?argument meaning.
In our study, only one of themwill be relevant, since we will restrict ourselvesto local predicate-argument structures with verbalheads and nominal arguments.Computing meaning in context.
Vectors repre-senting predicate meaning are derived by collectingco-occurrence frequencies for all uses of the pred-icate, possibly resulting in vector representationsin which different meanings of the predicate arecombined.
Given an instance of a predicate w thathas arguments w1, .
.
.
,wk, we can now contextuallyconstrain the predicate meaning of w by the argu-ment meanings of its arguments.
Here, we proposeto simple ?restrict?
the predicate meaning to thosedimensions that have a non-zero value in at leastone of its argument meanings.
More formally, wewrite v|v?to denote a vector that is identical to vfor all components that have a non-zero value in v?,zero otherwise.
We compute predicate meaning incontext as follows:vP(w)|?1?i?kvri(wi), (3)where riis the argument position filled by wi.Parameters.
To reduce the effect of noise andprovide a more fine-grained control over the ef-fect of context, we can choose different thresholdstarget subject object paraphrasesshed study light throw 3, reveal 2, shine 1shed cat virus spread 2, pass 2, emit 1, transmit 2shed you blood lose 3, spill 1, give 1Table 1: Lexical substitution task data setfor function f in the computation of predicate andargument meaning.
In Section 3, we obtain bestresults if we consider only dependency relationsthat occur at least 6 times in the British NationalCorpus (BNC) for the computation of predicatemeaning, and relations occurring at least 15 timesfor the computation of argument meanings whenpredicate meaning is contextually constrained.Related work.
Our model is similar to the struc-tured vector space model proposed by Erk and Pad?
(2008) in that the representation of predicate mean-ing is based on dependency relations, and that ?in-verse selectional preferences?
play an importantrole.
However, inverse selectional preferences areused in E&P?s model mainly to compute mean-ing in context, while they are directly ?built into?the vectors representing predicate meaning in ourmodel.3 EvaluationWe evaluate our model on a paraphrase rankingtask on a subset of the SemEval 2007 lexical substi-tution task (McCarthy and Navigli, 2007) data, andcompare it to a random baseline and E&P?s stateof the art model.Dataset.
The lexical substitution task dataset con-tains 10 instances for 44 target verbs in differentsentential contexts.
Systems that participated inthe task had to generate paraphrases for each ofthese instances, which are evaluated against a goldstandard containing up to 9 possible paraphrasesfor individual instances.
Following Erk and Pad?
(2008), we use the data in a different fashion: wepool paraphrases for all instances of a verb in allcontexts, and use the models to rank these para-phrase candidates in specific contexts.Table 1 shows three instances of the target verbshed together with its paraphrases in the gold stan-dard as an expample.
The paraphrases are attachedwith weights, which correspond to the number oftimes they have been given by different annotators.To allow for a comparision with E&P?s model,we follow Erk and Pad?
(2008) and extract onlysentences from the dataset containing target verbs45with overtly realized subject and object, and re-move instances from the dataset for which the tar-get verb or one of its arguments is not in the BNC.We obtain a set of 162 instances for 34 differentverbs.
We also remove paraphrases that are notin the BNC.
On average, target verbs have 20.5paraphrase candidates, 3.9 of which are correct inspecific contexts.Experimental setup.
We parse the BNC usingMiniPar (Lin, 1993) and extract co-occurrence fre-quencies, considering only dependency relationsfor the most frequent 2000 verbs.
We don?t use rawfrequency counts directly but reweight the vectorsby pointwise mutual information.To rank paraphrases in context, we compute con-textually constrained vectors for the verb in theinput sentence and all its paraphrase candidatesby taking the corresponding predicate vectors andrestricting them to the argument meanings of theargument head nouns in the input sentence.
Therestricted vectors for the paraphrase candidates arethen ranked by comparing them to the restrictedvector of the input verb using cosine similarity.In order to compare our model with state of theart, we reimplement E&P?s structured vector spacemodel.
We filter stop words, and compute lexicalvectors in a ?syntactic?
space using the most fre-quent 2000 words from the BNC as basis.
We alsoconsider a variant in which the basis correspondsto words indexed by their grammatical roles.
Wechoose parameters that Erk and Pad?
(2009) reportto perform best, and use the method described inErk and Pad?
(2009) to compute vectors in context.Evaluation metrics.
As scoring methods, weuse both ?precision out of ten?
(Poot), which wasoriginally used in the lexical substitution task andalso used by E&P, and generalized average preci-sion (Kishida, 2005), a variant of average precisionwhich is frequently used in information extractiontasks and has also been used in the PASCAL RTEchallenges (Dagan et al, 2006).Pootcan be defined as follows:Poot=?s?M?Gf (s)?s?Gf (s),where M is the list of 10 paraphrase candidatestop-ranked by the model, G is the correspondingannotated gold data, and f (s) is the weight of theindividual paraphrases.
Here, Pootis computed foreach target instance separately; below, we reportthe average over all instances.Model PootGAPRandom baseline 54.25 26.03E&P (target only) 64.61 (63.31) 29.95 (32.02)E&P (add, object only) 66.20 (62.90) 29.93 (31.54)E&P (min, both) 64.86 (59.62) 32.22 (31.28)TDP 63.32 36.54TDP (target only) 62.60 33.04Table 2: ResultsGeneralized average precision (GAP) is a moreprecise measure than Poot: Applied to a rankingtask with about 20 candidates, Pootjust gives thepercentage of good candidates found in the upperhalf of the proposed ranking.
Average precisionis sensitive to the relative position of correct andincorrect candidates in the ranking, GAP moreoverrewards the correct order of positive cases w.r.t.their gold standard weight.We define average precision first:AP =?ni=1xipiRpi=?ik=1xkiwhere xiis a binary variable indicating whetherthe ith item as ranked by the model is in the goldstandard or not, R is the size of the gold standard,and n the number of paraphrase candidates to beranked.
If we take xito be the gold standard weightof the ith item or zero if it is not in the gold standard,we can define generalized average precision asfollows:GAP =?ni=1I(xi) piR?R?= ?Ri=1I(yi)yiwhere I(xi) = 1 if xiis larger than zero, zero oth-erwise, and yiis the average weight of the idealranked list y1, .
.
.
,yiof paraphrases in the gold stan-dard.Results and discussion.
Table 2 shows the re-sults of our experiments for two variants of ourmodel (?TDP?
), and compares them to a randombaseline and three instantiations (in two variants) ofE&P?s model.
The ?target only?
models don?t usecontext information, i.e., paraphrases are ranked bycosine similarity of predicate meaning only.
Theother models take context into account.
The ?min?E&P model takes the component-wise minimum tocombine a lexical vector with context vectors andconsiders both subject and object as context; it isthe best performing model in Erk and Pad?
(2009).The ?add?
model uses vector addition and consid-ers only objects as context; it is the best-performing460204060801001 2 3 4 5 6 7 8 9 10presisionoutofnE&P (add, object only)present paperbaselineupper boundFigure 1: ?Precision out of n?
for 1?
n?
10.model (in terms of Poot) for our dataset.
The num-bers in brackets refer to variants of the E&P modelsin which the basis corresponds to words indexedby their syntactic roles.
Note that the results for theE&P models are better than the results publishedin Erk and Pad?
(2009), which might be due toslightly different datasets or lists of stop-words.As can be seen, our model performs > 10% bet-ter than the random baseline.
It performs > 4%better than the ?min?
E&P model and > 6% betterthen the ?add?
model in terms of GAP if we use avectors space with words as basis.
For the variantsof the E&P models in which the basis correspondsto words indexed by their syntactic role, we ob-tain different results, but our model is still > 4%better than these variants.
We can also see thatour treatment of context is effective, leading to a> 3% increase of GAP.
A stratified shuffling-basedrandomization test (Yeh, 2000) shows that the dif-ferences are statistically significant (p < 0.05).In terms of Poot, the ?add?
E&P model performsbetter than our model, which might look surprising,given its low GAP score.
Fig.
1 gives a more fine-grained comparison between the two models.
Itdisplays the ?precision out of n?
of the two modelsfor varying n. As can be seen, our model performsbetter for all n< 10, and much better than the base-line and E&P for n?
4.4 ConclusionIn this paper, we have proposed a dependency-based context-sensitive vector-space approach thatsupports the computation of adequate vector-basedrepresentations of predicate meaning in context.An evaluation on a paraphrase ranking task usinga subset of the SemEval 2007 lexical substitutiontask data shows promising results: our model per-forms significantly better than a current state of theart system (Erk and Pad?, 2008), and our treatmentof context is effective.Since the dataset we used for the evaluation isrelatively small, there is a potential danger for over-fitting, and it remains to be seen whether the resultscarry over to larger datasets.
First experimentsindicate that this is actually the case.We expect that our approach can be generalizedto arrive at a general compositional model, whichwould allow to compute contextually appropriatemeaning representations for complex relational ex-pressions rather than single lexical predicates.Acknowledgements.
We thank Katrin Erk andSebastian Pad?
for help and critical comments.ReferencesR.
Basili, D. De Cao, P. Marocco, and M. Pennacchiotti.
2007.Learning selectional preferences for entailment or para-phrasing rules.
In Proc.
of RANLP 2007.I.
Dagan, O. Glickman, and B. Magnini.
2006.
The PASCALRecognising Textual Entailment Challenge.
In MachineLearning Challenges, volume 3944.
Springer.K.
Erk and S. Pad?.
2008.
A structured vector space modelfor word meaning in context.
In Proc.
of EMNLP.K.
Erk and S. Pad?.
2009.
Paraphrase assessment in struc-tured vector space: Exploring parameters and datasets.
InProc.
of the Workshop on Geometrical Models of NaturalLanguage Semantics, Athens.M.
Geffet and I. Dagan.
2005.
The distributional inclusionhypotheses and lexical entailment.
In Proc.
of the ACL.K.
Kishida.
2005.
Property of average precision and itsgeneralization: An examination of evaluation indicator forinformation retrieval experiments.
NII Technical Report.D.
Lin and P. Pantel.
2001.
DIRT ?
Discovery of InferenceRules from Text.
In Proc.
of the ACM Conference onKnowledge Discovery and Data Mining, San Francisco.D.
Lin.
1993.
Principle-based parsing without overgeneration.In Proc.
of ACL, Columbus.D.
McCarthy and R. Navigli.
2007.
SemEval-2007 Task 10:English Lexical Substitution Task.
In Proc.
of SemEval,Prague.J.
Mitchell and M. Lapata.
2008.
Vector-based models of se-mantic composition.
In Proc.
of ACL-08: HLT, Columbus.P.
Pantel, R. Bhagat, B. Coppola, T. Chklovski, and E. Hovy.2007.
ISP: Learning inferential selectional preferences.
InHuman Language Technologies 2007, Rochester.I.
Szpektor, H. Tanev, I. Dagan, and B. Coppola.
2004.
Scal-ing web-based acquisition of entailment relations.
In Proc.of EMNLP, Barcellona.I.
Szpektor, E. Shnarch, and I. Dagan.
2007.
Instance-basedevaluation of entailment rule acquisition.
In Proc.
of ACL.A.
Yeh.
2000.
More accurate tests for the statistical signifi-cance of result differences.
In Proc.
of COLING.47
