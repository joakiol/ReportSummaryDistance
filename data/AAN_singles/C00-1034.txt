Theory Refinement and Natural Language LearningHervd Ddjean*Seminar fiir S1)rachwissenschaftUniversitSt Tiibingendej ean~sf s. nphil, uni-l;uebingen, deAbstractThis 1)aI)er l)resents a learning system for identify-ing synta(:tie structures.
This system relies on theuse of backgromld knowledge an(1 default wflues inorder to buihl utl an initial grammar and the use oftheory retiimlnent in order to iml)rove this granunar.This contbilmtion provides a good machine learningfl:amework for Natural Lmlguage Learning.
We il-lustrate this 1)oint with the 1)resentation of ALLiS,a learlfiug system which generates a regular ext)res-sion grmnmar of non-recursive phrases fi'om brack-eted corpora.1 In t roduct ionApl)lying Machine lx~'arning t('.chniques to NaturalLanguage Processing is a booming domain of ru-s(:~ar('h.
One of the reasons is the.
(levelopment ofcor-1)ora with morl)ho-synta(:ti(: and syntacti(: mmota-tion (Marcus et al, 1993), (Sampson, 1995).
One re-cent l)opular sul)task is the learning of non-re(:ursiveNouns Phrases (NP) (\]{amshaw and Mart:us, 1995),(~\['jong Kim Sang an(1 Vcenstra, 1999), (Mufioz etal., 1999), (Group, 1998), (Cardie and Pierce, 1999),(Buchholz el; al., 1999).When other  learn ing  tcchui ( lues  (symbol i( :  or s ta-t is t ica l )  are widely used in Natural Language Bern'h-int, theory retlnelnent (Aliecker and Schmid, 199G),(Mooney, 1993) seems to be ignored (excel)t (Brunkand Pazzmfi, 1995)).
Theory refinement consists ofiml)roving an existing knowledge base so that it; bet-ter at:cords with data.
No work using theory re-finement apI)lied to tile grammar learning paradigmseems to have been develol)ed.
We would like topoint out in this article the adequacy between the-ory refinement and Natural Language Learning.To illustrate this claim, we present ALLiS (Archi-tecture for Learning Linguistic Structures), a learn-ing system which uses theory refinement in order tolearn non-reeursive noun phrases (also called basenorm t)hrases) and non-recursive verbal 1)hrases.
Wewill show that this technique comliine(1 with the* This research is flmded be the TMll.
network L('m'ningComl)Ut;~tional ( lrmnmars www.
leg- www.
u ia .
ac .
be/ lcg /use of default vahms provides a good architectureto learn natural anguage structures.This article is organised as follows: Section 2 givesall overview of theory refinement.
Section 3 CXl)Iainsthe advantage of combining default vahles and the-ory refinement to build a learning system.
Section ddes(:ril)es th('.
genc'ra l  characteristics (if ALLiS, andSc(:tion 5 explains the learning algorithm.
The eval-uation of ALLiS is described Section 6.
The exam-ples which illustrate this arti(:le corresl)ond to En-glish NPs.2 Theory  Ref inementWe 1)resent here  a l)rief i l l t ro (h lc t ion  to theory  re-f inement .
For a more (tetailed presentation, we referthe reader to (Abecker and Schmid, 1996), (Brunk,1996) or (Ourston and Mooney, 1990).
(Mooney,1993) detines it; as:Theory retinement systems develot)ed inMachine Learning automatically modify aKnowle(lge Base to render it; consiste.ntwith a set of (:lassifie(1 training examples.This technique thus (:onsists of trot)roving a givenKnowledge Base (here a grammar) on tile l/asisof examtIles (here a treebank).
Some iml)OSe tomodif'y the initial knowledge 1)ase as little as pos-sible.
Applied in conjmmtion with existing learningtechniques (Explanation-Based Learning, InductiveLogic l)rogramming), TR seems to achieve' betterresults than these techniques used alone (Mooney,1997).
Theory retinement is mainly used (and has itsorigin) in Knowledge Based Systems (KBS) (Crawand Sleeman, 1990).
It consists of two main steps:1..
Build a more or less correct grammar on thebasis of background knowled.qe.2.
Refine this grmnmar using training examt)les:(a) Identify the revision 1)oints(b) Correct themThe first; step consists of acquiring an initial gram-nmr (or more generally a knowledge base).
In thiswork, the initial grainmar is automatically induce(1229from a tagged and bracketed corpus.
The secondstep (the refinement) compares the prediction of theinitial gralnmar with the training corpus in order tofirstly identify the revision point.s, i.e.
points thatare not correctly described by the grammar, andsecondly, to correct these revision points.
The er-ror identification and refinement operations are ex-plained Section 5.3.The main difference between a TR, system andother symbolic learning systems is that a TR systemmust be able to revise existing rules given to tilesystem as background knowledge.
(A system suchas TBL (Brill, 1993) can not be considered us TRsince it only acquires new rules).
In the case of othertechniques, new rules are learned in order to improvethe general efficiency of the system (selection of the"best rule" according to a preference function) andnot in order to correct a specific rule.3 Theory  Ref inement ,  Defau l t  valuesand Natura l  Language L~arn ingThis section explains how default values combinedwith theory refinement can provide a good inachinelearning framework for NLP.3.1 The Use of Default ValuesThe use of default values is not new in NLP (Brill,1993), (Vergne and Giguet, 1998).
We can observethat often (but not necessarily) in a language, anelement belongs to a predominant class (Vergne andGiguet, 1998).
Some systems such as stochasticmodels use this property implicitly.
Some others useit explicitly.
For instance, the general principle ofthe Transformation-Based Learning (Brill, 1993) isto assign to each element its most f requent  category,and then to learn transformation rules which cor-rect its initial categorisation.
A second example is:the parser described ill (Vergne and Giguet, 1998).They first assign to each granunatical word a de-fault category (default ag), and then might modifyit thanks to local contexts and grammatical relationassignment (in order to deal with constraints due tolong distance relations which can not be expressedby local contexts).The main work is done by the lexicon and by de-fault values (even if further operations are ol)viouslynecessary)These approaches are thus different for the disam-biguation often used in tagging.
The default rulesare not numerous (one per tag), easy to automati-cally generate but they nevertheless produce a sat-isfactory starting level.3.2 The Combination of Default Valueswith TRThe idea on which ALLiS relies is tile following: afirst; "naive gramnmr" is lmilt up using default val-ues, and then TR is used in order to provide a "morerealistic gralnmar".
Tiffs initial grammar assigns toeach element its default category (the algorithm isexplained ill Section 5.2).
Tile rules learned are cat-egorisation rules: assign a category to an clement (atag or a word).
Since an element is automaticallyassigned to its default category, the system has notto learn the categorisation rules for its category, andjust learns categorisation rules which correspond tocases in which the element does not belong to its de-fault category.
This minimised the number of rulesthat have to be learned.
Suppose the element c canbelong to several categories (a frequent case).
Tilefrst  rule learned is tile "default" rule: assign(e, dc),where dc is the defimlt category of c. Then ALLiSjust learns rules for cases where c does no 1)elong toits default category.
The numerous rules concern-ing the default category are replaced by the simpledefault rule.4 ALL iSThe goal of ALLiS x is to automatically build a regu-lar expression grammar from a bracketed and taggedcorpus 9.
In this training data, only the structureswe want to learn are marked at their boundaries bysquare brackets a.
The following sentence shows anexample of tile training corpus for the NP structure(only base-NPs occur inside brackets).In/IN \[ early/ J J  trading/NN \] in/IN \[Itong/NNP Kong/NNP \] \[ Monday/NNP\] ,/, \[ gold/NN \] was/VBD quoted/VBNat/ IN \[ $/$ 366.50/CD \] \[ an/DTounce/NN \] ./.ALl, iS uses an internal formalism in order to rep-resent he grmmnar ules.
In order to parse a text,a module converts its formalism into a regular ex-pression grammar which can be used by a parser us-ing such representation (two modules exist: one forthe CASS parser (Almey, 1996) and one for XFST(Karttunen et al, 1997)).Following the principle of theory refinement, helearning task is composed of two steps.
The first stepis the generation of the initial grammar.
This gram-mar is generated ti'om examples and baekgromxdknowledge (Section 5).
This initial grammar pro-vides an incomplete and/or incorrect analysis of thedata.
The second step is the refinement of this gram-mar (Section 5.3).
During this step, the validity ofthe grammar ules is checked and the rules are im-proved (refined) if necessary.
This improvement cor-responds to find contexts in which elements whichi http ://www.
sfb441, uni- tuebingen, de/'dej ean/chunker, html.2'\]'he WSJ corpus (Marcus et al, 1993).a(Mufioz et al, 1999) showed that this representationtends to provide better results than the representation usedin (Ramshaw and Marcus, 1995) where each word is taggedwith a tag I(inside), O(outskte), or B(breaker).230are considered to be meinbers (}f the structure dohoe 1}elong to this stru{:ture (and re(:it}r{)c~dly ).We give here a simple exami)le to il lustrate tit(.
*learning process.
The first step (initial g rammargeneration) categorises the tag JJ (adje{:tive) as be-longing by default to the NP strl leture if it; oec:irsbefore a noun.
Tit{; second ste t) (refinemellt) tindsouI; that  some adjectives do not ol}ey to these rules 4.Tim refiimment is triggered in order t{} modify thedefault rule so that these ex{'el)tions can t}e {:(}rre(:tlyprocessed.Thus, the learning algorithm siml}ly consists ofeategorising the elements of the eorlms (tags andwords) into st}celtic categories, and this eategorisa-lion allows the extract ion of the stru{:i;ures we wantto learn.
These (:ategories are exi)lained in the nextsection.5 The  Learn ing  System5.1 The Background Knowledge .\]n order to ease the learning, the system uses 1)aek-ground knowledge.
This knowledge, 1}rovide, s a for-real and general (les('ription of the S\[;lll{:tllr{)s thatALLiS can learn.
We SUl)l)ose that the stru{:tures are(:Oml}(}se(l of a mmleus with (}t)ti{mal left; an(1 rightad.\]un{:ts.
We here give int'{}rmal ( etiniti{}ns, |h(', for-inal/disl;rilmti{mal ones are given in Section 5.2.Tit(; nuc leus  is the head of the structure.. Weauthorise the presence of several nuclei in the.
stonestrll{;l;ure.All the other e.lements in the st;ruet;nre (exceptthe linker) me (:onsidered as ad juncts .
They arein dependence relation with the, head of tit{!
st:rue-tm'e.
Tit(; adjuncts are (',hara(:l;eris(;{I 1}y l;heir \])osi-tion (left/right) re, lative to the nu(:leus.A l inker  is a Sl)e{:ial elenle, nt; which 1}uihls an en-{lo{:entri{: st;ruetlne with t;w(} elentenl;s. It usually{;{)rrest}on(ts t;o c(}or(lilla{;i{)n 5.An ehBment (micleus or adjunct) might possess thebreak  1)r{}I)erty.
This llotiolt is iu|;rodtlce(| (;IS ill(l{axnshaw and Marcus, 19\[)5), (Mufioz et al, 1999))in order to deal with sequences where adjacent m~eleicompose several structures (Section 5.2.4).This 1}attern can 1)e seen as a variant of the X-l)ar template (Ilead, Spec and COral)), whieh wasalready used in a learning sysl;ent (Berwiek, 1.985)(alth(mgh Coral) is not useflfl for the n{m-reeursivestructures).The possible ditferent categories of air element aresummm'ised in Figure 5.1.The tbllowing sentence shows an exmnl}le of cat-egorisation (elements which do not al}l)ear in thestructure (NP) are tagged O):4For examl}le: \[ the/l)T 7/el)  %/NN |}(mchmarl:/NN is-sue/NN \] due/aa  \[ October/NNP l.q,qg/Cl) \].5Only linkers occurring between the two coordinated eh!-I l l{ !
l l \ [ ,S  a l '{ ,  ~ i ) l ' oc ( !
,qs{~( \ ] ,CAT /%OUT INA l/r NU+/- B +/- BFigure 1: The different categories.Ill 0 earlYAB+ tradingNU in 0 I{ongN U KOngNUMondayNuB+ ,0 goldNu was 0 quoted 0 at 0 $A366.50NU allAB+OlllleeNu -0The stru(:ture is fornmlly defined as:S+A * \ [A  *NUb_A * \ ]+ * l,b+ 1,1> r,b- At,b+\ ]A  *k  * A * *" l,bq 1,1}- NUb+ r,b- Ar,b+2File syml}ol , {:orresl)onds to the Kleene star.
Forthe sake of legit}ility, we do not introduce linkers inthis expression.
But each symbol X (NU, A) cml1)e de, tined 1}y the rule {; X - -~-  X I X 1 X where l isthe list; of linkers.
The symbols B+ and \]Y- indicatewhether the element has the.
breaker i)rot)erty or n(}t.Since lit(; {:orpus does not contain informationabout  these distri lmtional categories, ALLiS has tofigure them {}ut.
This {:ategorisation relies on thedistritmtional behaviour of the ele.nlents, and ean beautomati{:ally achieved.5.2 The In i t ia l  Categor i sa t ionThe general idea t{} {:ateg(}rise elements is t(} use sl}e-{:iti{: (:ont{:xts which 1)oint {}ut s(}nie of the distrilm-l;iona\] t)r(}perti{:s of lhe (;ategory.
~\]Plle {;al;eg()risaf, iollis a sequential 1)ro{;ess.
First; the mmM have to befound out.
14)r each tag (}f the {:(}rl)uS , we ai)l}lythe fim{'ti{m J'm~ (described bek}w).
This flmctionse\]e('ts a fist of elements w\]fich are eateg(}rised asmmIei.
The fun{:tion ft) is al}p\]ied to this list in 0>der to tigure out mmlei which a,'e breakers.
Thenthe a(ljmtcts are, found out, and the function fb  isalso apl}\]ied l;(} them to figure out breakers.5.2.1 Categor isat ion of  Nuc le iThe (;Olltext used to find out the nuclei relies ott thissiml}le following ol)servation: A structure requiresat least; {me nucleus r. Thus, the elements tha.t; oc-cur alone in a structure are assimilated to nucleus,since a structure requires a nucleus.
For example,the tags PRP  (pronouns) and NNP (proi)er nora:s)may eomp{}se a.lone a structure, (respectively 99%6The regular exl)ression lbrmalism does not allow suchrule, and then, this recursion is simulated.7The partial structures (structures without mtcleus) tel>re-sent 2% of all the structures it: the, training corl)us , and I,h(mintroduce little noise.231and 48% of these tags appear alone in NP) but thetag J J  appears alone only 0.009%.
We deduce thatPRP and NNP belong to the nuclei and not JJ.
Butthis criterion does not allow tile identification of allthe nuclei.
Some often appear with adjuncts (an En-glish noun (NN) often s occurs with a deternfiner oran adjective and thus appears alone only 13%).
Thesingle use of this characteristic provides a continuumof values where the automatic set up of a thresholdbetween adjuncts and nuclei is probleinatic and de-pends on the structure.
To solve this problem, theidea is to decompose the categorisation of nuclei intwo steps.
First we identify characteristic adjuncts.The adjuncts can not appear alone since they de-pend on a nucleus.
The function fchar is built sothat it provides a very small value for adjuncts.
Ifthe value of an element is lower than a given thresh-old (0char = 0.05), then it is categorised as a char-acteristic adjunct.=~c x~c  P corresi)onds to the number of occurrences ofthe pattern P in the corpus C. For exmnple thenumber of occurrences in the training corpus of thepattern \[JJ\] is 99: and the number of occurrences ofthe pattern J J  (including the pattern \[ J J  \]) is 11097.So lobar(J J) = 0.009, value being low enough toconsider J J  as a characteristic adjunct.
The list pro-vi(le(1 by fchar for English NP is:Achar = {DT, P1H~$, POS, .l.l, .I.IR, JJS," "," "}These elements can correspond to left; or right ad-juncts.
All the adjuncts are not identified, but tiffslist allows the identification of the nuclei as ex-plained in the next paragraplLThe second step consists of introducing these ele-ments into a new pattern used by the funetioll fro,.This pattern matches elements urrounded by thesecharacteristic adjuncts.
It; thus matches nuclei whichoften appear with adjuncts.
Since a sequence of ad-juncts (as an adjunct alone) can not alone compose acomplete structure, X only matches elements whichcorrespond to a nucleus.= Ec  { Ache,.
* x A lThe flmction fnu is a good discrimination functionbetween nuclei and adjuncts and provides very lowvalues for adjuncts and very high values for nuclei(table 1).5.2 .2  Categor i sa t ion  o f  Ad junctsOnce the nuclei are identified, we can easily find outtlm adjuncts.
They correspond to all the other ele-inents which appear in the context: There are twoSAt least, in the training corpus.x Freq(x) fml(X) intcleusPOS 1759 0.00 noPRP$ 1876 0.01 noJJ 11097 0.02 noDT 18097 0.03 noRB 919 0.06 noNNP 11046 0.74 yesNN 21240 0.87 yesNNPS 164 0.93 yesNNS 7774 0.95 yesWP 527 0.97 yesPRP 3800 0.99 yesTable 1: Detection of some nuclei of the English NP(nouns and pronouns).kinds of adjuncts: the left and the right adjuncts.The contexts used are:\[ _ NU \] fbr tile left, adjuncts\[ AI* NU _ \] for the right adjunctsIf an element appears at tile position of the under-score, it is categorised as adjunct.
Once tile leftadjuncts are found out, they can be used for the cat-egorisation of the right adjuncts.
They thus appearin the context as optional dements (this is helpfiflto capture circumpositions).Since tilt; Adjective Phrase occurring inside an NPis not marked in the Upenn treebank, we introducethe class of all'inner of adjunct.
The contexts usedto find out the acljuncts of the left adjunct are:\[ _ A 1 NU \] for the left adjuncts of A 1\[ al* A 1 _ NU \] for the right adjuncts of A 1The contexts are similar for adjuncts of right a(1-juncts.5.2.3  The  L inkersBy definition, a linker commcts two elements, andappears between them.
The contexts used to findlinkers are:\[ NU _ NU \] linker of nuclei\[ A _ A NU \] linker of left adjuncts\[ NU A _ A \] linker of right adjunctsElements which occur in these contexts trot whichhave already been categorised as nucleus or adjunctsare deleted from the list.5.2 .4  The  Break  Proper tyA sequence of several nuclei (and the adjuncts whichdepend on them) can 1)elong to a mfique structureor compose several ad.iacent structures.
An elementis a breaker if its presence introduces a break into asequence of adjacent nuclei.
For example, the pres-once of the tag DT in the sequence NN DT J J  NNintroduces a break before the tag DT, although the232sequence NN aJ NN (without \])T) can compose asingle structure in the training corlms.. .
.
\ [ the/DT coming/VB?
week/NN\]\ [ the/ l )T foreign/ J J  exchange/NN mar-ket/NN\] .
.
.The tag DT introduces a 1)reak on its lefl;, but sometags can introduce a break on thoir right or on theirleft, and right.
For instance, the tag WDT (NU bydefmflt) introduces a bre, ak on its M't and on itsright.
In other words, this tag can not belong tothe same structure as the preceding adjacent nucleusand to the same structure as the following adjacentIlucleus.. .
.
\[ raih'oads/NNS and/CC trucking/NNcompanies/NNS \] \[ that /WDT \] tw,-ga,UW~D iu/llN \[ 19S0/CD \] ...... i,l/l:N \[ wh ich /WDT \] \[ peop>/~,'NS \]general ly/ I / \] l  arc/V'lTP .
.
.lit order to detect wlfich tag has the t)re, ak 1)rot)erl;y,we build up two fimctions 'fb h;fl; and fb  right".l't, i,;n(x) = ~.
Nu x" W\ ]  )?
fb  ,.i~O,t (x )  - ~'  x \] \[ N ,  )~-,c' X U NU : {'nuch'.i}?
wb(;wb: corpus wiLhout l)ra(:kcl,sThese funcl;ions are used to coniput(; l;he, break 1)rop-erl;y for nuclei, but; also for adjullcts (\]\]i .hi.q case,the pattern X is conll)leted })y a(hling the, elemeutNU to the left; or 1;o the right of X (tim 1)ot(mtialadjunct) according 1;o the kind of adjull(:t (left orright adjunct)).
The table 2 shows some vahles forsome tags.
An olon)eIll; Call \])e a left brcakem (DT), aright breaker (no example fi)r English NI?
at the taglevel), or both (PRP).
The break property is gener-ally well-markc'd and the thre~shold is easy to set up(0.66 in practice).TAG fb h;\[I; fb right_1)31 0.97 (yes) O.O0(no)pR> 0.97 (yes) O.OS(yes)POS 0.95 (yes) 0.O0(no)l'lU'$ 0.94 (yes) 0.00(no)J,l 0.44 (no) O.O0(no)NN 0.04 (no) O.\].l.
(no)NNS 0 .03  (,,o) 0.14(no)Table 2: Breaker determina.tion.
Values of the flmc-tions ot' b left and fb- right for soille elements.In the refinement step (Se(:tion 5.3), the breakerproperty can be extended to words.
Thus, the wordyesterday is considered as a right breaker, althoughits tag (NN) is not.5.3 The  Ref inement  Step5.3.1 The not ion  o f  re l iab i l i tyTile preceding functions ident, i(y the category of D, IIelenmnt when it occurs in the str'ltctltT'e.
\]lilt, fill ele-lnent can occur in the structure as well as out; of thestructure.
For example, the tag VBG is only consid-ered as adjunct when it occurs in the structure.
Nev-ertheless, it mainly occurs out of the structure (84%of its occurrences).
If an element mainly 9 occurs outof the st, ructure, it is considered as non-reliable andits default category is OUT.
For each dement  occur-ring inside the structure, its rdiable is tested.
Theinitial grammar corresponds to the grammar whichonly contains the reliable elements.
Its precision andits recall are aromM 86%.Itow is determined the reliability of an element?This notion of reliabh; element is contextual and de-pends on th(!
category of the element.For the uuclei, the context is eml)ty.
W'e just com-tmte l;he ratio })el;ween l;hc number of occurrences inthe strll(;tur(} over th(} lllllllber of occtlrrelices occur-ring outside of the sl, ructure.For the adjmicts, the context in(-ludes an adja-cent nuc:leus (on the right for left adjun(tts or on theh~ft for right a(ljun(-l;s).
For instance, the tag .lJ iscategorise(l as left a@mct  for the English NP.
It ap-1)ears 9617 times 1)efore a lm(:leus and 9,189 timesin the stru(-ture.
It is thus (:onsi(lered as relial)le,and its default category is left adjmmt.
In the casewhere the tag .\]J occurs without mmleus on its righl;(a pr(,dicative us(,,), it is not considered as adjunctmM this kind of occnrr(mces ix not used to deter-niine the rclialfility of the element.
On l;he coutrary,the tag VIIG appears 468 times before a mmleus,but, in this context, it occurs only 138 times in thestructure.
This is not enough (29%) to consider t.heelement as a relial)le left; adjunct, and thus il;s de-5mlt ca(;egoi'y is OUT.
For the adjunct of adjunct,the conl;ext includes a(tjm/ct and imcleus.5.a.2 Detect ion  of  er rorsOnce the inil;iM g lmnmar ix built ufh its errors haveI;o 1)e corrected.
The detection of the errors corre-sponds to a lniscategorisation f a tag.
An aut;omaticerror done by the initial grammar is to wrongly anal-yse the structures coml)osed with non-reliable ele-ments (false negative examples).
Each time that anon-reliable elenmnt occurs in the structure corm-spends to an error.
For instance, the initial grammarcmi not correctly recognise the following sequence asan NP, the default category of the tag VBG beingOUT (outside the structure):.
.
.
\[the/1)T eoming/VBG week/NN\] .
.
.~')'l'he threshold used is of 50%.233The second kind of errors corresponds to se-quences wrongly recognised as structures (false pos-itive exmnples).
This kind of error is generated byreliable elements which exceptionally do not occur illthe structure.
In the following example, orde~NNoccurs outside of the structure, although the defaultcategory of the tag NN is NU (nucleus), and thusthe initial grammar ecognises an NP... .
in/IN order/NN to/TO 1,ay/VB ...5.3.3 CorrectionIn both kinds of errors, the stone technique is usedto correct them.
I~r this purpose, ALLiS disposesof two operators, the eontextualisation a d the lex-icalisation.The contcxtualisation consists of finding out con-texts in order to fix the errors.
The idea is to addconstraints for recategorising non-reliable lementsas reliable m. The t)resence of some specific elementscan completely change the behaviour of a tag.
Thetable 3 shows the list of contexts where the tag VBNis not categorised as OUT but as left Adjmmt.PRP$ VBG NUIN\[ VBG NUDT VBG NUaJ VBG NUPOS VBG NUVBG \[ VBG NUTable 3: Some contexts where the non-reliable le-ment VBN becomes reliable.For each tag occurring in the, structure, all tilepossible contexts 11 are generated.
For the non-reliable tags (first kind of error), we evaluate thereliability of them contextually, and we delete thecontexts in which the tag is still non-reliable (tilelist of contexts can be empty, and in this case theerror can not be fixed).
For the reliable tags (secondkind of error), we keel) the contexts in which the tagis categorised OUT.The lcxicalisation consists of introducing lexicalinformation: the word level.
Some words can havea specific behaviour which does not appear at thePart-Of-Speech (POS) level.
For instance, the wordyesterday is a left breaker, behaviour which can notbe figured out at the POS level (Table 4).
The in-troduction of the lexicalisation improves the resultby 2% (Section 6).The lexicalisation and the contextualisation canbe combined when both separately a.re not powerflflenough to fix the error.
For example, the word abouttagged RB (default category of RB: OUT) followedl?q'he same techifique is used in (Sima'an, 1997).HThe  contexts depend on the category of the tag, but arejust  composed of one element.word(context) default cat.
new cat.about/RB ( _ Cl)) OUT A1,B+order (IN _ TO) NU OUTyesterday/NN NUB- NUB +operating/VBG OUT A1,B_last/.JJ A1,B- A1, B+Table 4: Some specific lexical behaviours.by the tag CD is recategorised as left: adjunct andleft breaker (Table 4).6 Evaluat ionWe now show some results and give some compar-isons with other works (Table 5).
The results are,quite sinfilar to other approaches.
Two rates aremeasured: precision an recall.~, ~ Nu~nbcr of correct proposed pattc'rnsNumber  of correct patternsp z Number  o.f correct proposed patternsNu'mber of  proposed pattcrnsTile training data.
are comt)osed of the sections15-18 of tile Wall Street Journal Corpus (Marcus el;al., 1993), and we use the section 20 for the testcorpus 12.
The data is tagged with the Brill tag-ger.
The works generating syinbolic rules like ALLiSare (Rainshaw and Marcus, 1.995) (Transformation-Based learning) and (Cardie and Pierce, 1.998)(error-driven pruning of treebank grammars).
AL-LiS provides better results than them.
(Argamonet al, 1.998) use a Memory-Based Shallow Learningsystem, (Tjong Kim Sang and Veenstra, 1999) theMemory-Based Learning nmtho(l and (Mufioz el; at.,1999) uses a network of linear functions.
The latterwork seems to integrate better lexical intbrmationsince ALLiS gets better results with POS only.POS only with wordsNP MPRZ99 90.3/90.9 92.40/93.10ALLiS 9t.0/91.2 92.56/92.36TV99 92.50/92.25ADK98 91.6/91.6RM95 90.7/90.5 92.3/91.8CP98 91.1/90.7VP ALLiS 91.39/90.52 92.15/91.95Table 5: Results for NP and VP structures (preci-sion/recall).The main errors done by ALLiS are due to er-rors of tagging (the corpus is tagged with the Brilltagger) or errors in the bracketing of the trainingcortms.
Then, the second type of errors concerns12This data  set; is avMlable via ftp://ftp, c i s .
upenn, edu/pub/chunker/.234tim (:o()rdin;dx:(1 sl,ru(:tures.
'l'h(;s(~ two tyl)(;s (}l'l'Ol'Scorrespond to 51% of the, overall errors.
We (:an tin(l1;11(: sam(; l;yl)olop;y in other works (\]{anlshaw :rodMarcus, 1995), (Ca rdi(: and Pierc(:, 1998).
\Ve didsome tries in order to manually imt)r()v(', th(; final,grammar: I)ut l;lm only tyt/(; ()f errors whi(:h can 1)emmnmlly iml)r()v(;(1 (:(m(:(wns tim t)r()t)h;m of the (tuo-laI;ion tamks (th(~ inll)rov(mw.nl is al)()ul ()l' 0.2% i~ll)re(:ision mid recall).Error types ~j/- %tagging/bracket ing errors 57 28.5%coordination d5 22.5%germM 15 7.5%a dv(wl) 13 6.5%ai)l)ositiv(:s 13 6.5%(lUOi;al;ion l;lrks~ 1)ml(:tualion \] 0 5 %past; 1)artMl)le 9 :1.5%that (IN) fi 3%Tal)h'.
6: Typology of the 200 tirst errors.Re/>xencesAn(h'eas Ab(;ck(;r and Klaus Schmid.
:1996.
Fromtlmory l'(:filmm(mt 1o kl) l I l}li I l((~ll}ll lC(~: ;/ I)()sition:-d;a,l;(:ln(;lll;.
\]11 U6'Al'96, Budat)(>l;, \]hmgary.Steven Almey.
1996.
\])artial tmrsing via tinil;(>stal:e(:as(:ades.
In l)roccedings of the E?
'SLLI '95 ll, obustl)arsing Workshop.Shlom() Argmnon, Mo \])agan, and Yuval Kry-molowski.
1998.
A m(:mory-1)as(~(1 at)l)r()a(:h 1()learning s\]mllow natural \[an~t~uag(!
i)al.l(!rns.
\]1lCOL1NG'98, Montrdal.Robert C. 13erwick.
1985.
Th, c acquisition of syntac-tic k'nowlcdg('.. M\[T press, Cmnbri(lg('..Eric Brill.
1993.
A Corpv, s-Bascd Ap\]nvach 1,oLanguage Learning.
Ph.l).
thesis, 1)el)artnmnl; ofComputer and hfformation Science, University of\]'ennsylvania.Clifl'ord Alan Brunk and Michael Pazzmii.
1995.A lexically based semantics bias for theory rex'i-:don.
In Morgan l(aufl'man, e(litor, 7'welflh lnl, cr-national Co't@rc'nc(: on Mach.ine Learning, pages81-89.Cliflbrd Alto1 Brtmk.
1996.
An invest, igationof Knowlc@c h~,tensivc Appwach, cs to ConceptLearning and Theory Refinement.
Ph.\]).
thesis,University of Caliibrnia, irvine.Sabine B,u:hholz, \]orn Veenstxa, and \\qdter 1)aele-marts.
1999.
Cascaded grammatical relal;ion as-tdgmnenl;.
In l'Tvcccdings of l~MNL1)/VLC-99,pages I)P- 239 2.
"16, University of Maryland, USA.Claire, Car(lie mtd 1)avid Pierce.
1998.
Error-drivenpruning ()f tr(;ellank gl'mlmlars for base n(nlnphras(; identiti(;ation.
In l'Tvccedings of th, e. I Tth,International Co'l@rc, ncc on Comp',,tational Lin-g'aistics (COLING-A CL '98).Claire, Ca rdie and David Pierce.
1999.
The.
rol(~ oflexicalization an(| pruning for base noun 1)}n'asegrammars.
\]n l)~vccc:dings of I, he Sizl, c.cnth, Na-l, ional Confl:renc(: on Artificial Intelligence.Susan Craw and I).
Sleenmn.
1990.
Automating ther(~lineln(!nl; of l~nowledge-based syst;cnls.
\]n Pro-cecdings of the ?
'(MI'90 Cm@~v',,cc: pages 167172.The XTAC l{.esear(:h Group.
1998.
A lexicalizedtree adjoining grammar fbr english.
Technical Re-port i\]{CS 98-18, University of Pemlsylvania.Lauri Karl;I;un(~ll, ~l'am~is Gal, and Andrd K(!Illp(~,.1997.
Xerox tinite-state tool.
Technical report,Xerox \]{.es(!arch Centr(~ Eurol)e, Grenobl(,,.Mitchell Marcus, Bdatric(' Sanl;orilfi, and Marc AmiMarcinkie, wicz.
1993.
\]hill(ling a large annotatedcorpus of english: the I)e1111 treel)ank.
Comp'nta-tional Linguistics, 19(2):313 330.Raymond J. Mooney.
1(.)93.
In(hlction over the l111-exl)lained: Using overly-general domain theories(o aid (:on(:(;p( learning.
Mach, i',,r~ Lc:arni',,g, 10:79.llas, mond .\].
Mooney.
1997.
Induc(;ive logic pro-gramming for md;ural languag(; processing.
InSizl, h lntcvnal, ional lnd'u, ct, ive Logic: ProgrammingWovl,:shop, pages 205 22d, Sl;o(:ldlohn,Swedcn.Mar(:i;t Mufioz, Vasill l'unyal(anol% 1)2'111 i/()th, andl)av Zimak.
1999.
A learning approach to shallowlmrsing, lilt t'~vceedings of EMNLI )- WVLC'99.l)irk ()m'st(m and \]{aymond Mooney.
1990.
Chang-ing the rules: A (:(mq)rt~hensiv(,, al)prtmcli to th('.oryl'(tfillOlll(tlll.. \]ll l'roccc:dings of t/w ls'igM, NationalCo'l@re'm:r, o'n Arl,~ific:ial \[nl, elligr:nce, 1)ag(!s 815820.l~ance A. llmnshaw and Mitchell P. Marcus.
1995.Text; chunking using trmlstbrmation-based l arn-in g. In A 67, Third Worksh, op on Very Lmyle Car-pora, pages 82 94.Geotti'ey Sampson.
1995.
English, for the Comp'utcr.The SUSANNE Uorpus and Analytic ,5'ch, cme.Oxford: Clarendon Press.Khalil Sima'an.
19{)7.
Exl)lanal;ion-based learningof (lal;a oriented parsing.
Ill T. Mark Ellison, ed-itor, Uompul, ational Nal, ural Lwng'ungc Learning(CoNLL), A CL/EA CL-9~, Madrid.Erik Tjong Kim Sang and .Jonl Veenstra.
1999.Rel)resenting text chunks.
In Proceedings ofEACL'99, Association for Computational Lin-guistics, Bergen.Jacques Vergn(~ mid Enunan:le, l Giguet.
1998.
Re-gards thdoriqu(',s ur le "tagging".
In proceed-ings of 7}'aitemc'nt Automcztiquc des Langucs Na-tu~vlh'.s (TALN I998), 1)aris.235
