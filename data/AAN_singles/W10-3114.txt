Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 86?94,Uppsala, July 2010.Contradiction-Focused Qualitative Evaluation of Textual EntailmentBernardo MagniniFBK-IrstTrento, Italymagnini@fbk.euElena CabrioFBK-Irst, University of TrentoTrento, Italycabrio@fbk.euAbstractIn this paper we investigate the rela-tion between positive and negative pairsin Textual Entailment (TE), in order tohighlight the role of contradiction in TEdatasets.
We base our analysis on the de-composition of Text-Hypothesis pairs intomonothematic pairs, i.e.
pairs where onlyone linguistic phenomenon at a time is re-sponsible for entailment judgment and weargue that such a deeper inspection of thelinguistic phenomena behind textual en-tailment is necessary in order to highlightthe role of contradiction.
We support ouranalysis with a number of empirical ex-periments, which use current available TEsystems.1 IntroductionTextual Entailment (TE) (Dagan et al, 2009) pro-vides a powerful and general framework for ap-plied semantics.
TE has been exploited in a seriesof evaluation campaigns (RTE - Recognizing Tex-tual Entailment) (Bentivogli et al, 2009), wheresystems are asked to automatically judge whetherthe meaning of a portion of text, referred as Text(T), entails the meaning of another text, referredas Hypothesis (H).RTE datasets have been mainly built with thepurpose of showing the applicability of the TEframework to different semantic applications inComputational Linguistics.
Starting from 2005,[T,H] pairs were created including samples fromsummarization, question answering, informationextraction, and other applications.
This evaluationprovides useful cues for researchers and develop-ers aiming at the integration of TE components inlarger applications (see, for instance, the use of aTE engine for question answering in the QALL-ME project system1, the use in relation extraction(Romano et al, 2006), and in reading comprehen-sion systems (Nielsen et al, 2009)).Although the RTE evaluations showed pro-gresses in TE technologies, we think that there isstill large room for improving qualitative analysisof both the RTE datasets and the system results.
Inparticular, we intend to focus this paper on contra-diction judgments and on a deep inspection of thelinguistic phenomena that determine such judg-ments.
More specifically, we address two distin-guishing aspects of TE: (i) the variety of linguis-tic phenomena that are relevant for contradictionand how their distribution is represented in RTEdatasets; (ii) the fact that in TE it is not enough todetect the polarity of a sentence, as in traditionalsemantic analysis, but rather it is necessary to ana-lyze the dependencies between two sentences (i.e.the [T,H] pair) in order to establish whether a con-tradiction holds between the pair.
Under this re-spect we are interested to investigate both howpolarity among Text and Hypothesis affects theentailment/contradiction judgments and how dif-ferent linguistic phenomena interact with polarity(e.g.
whether specific combinations of phenomenaare more frequent than others).As an example, let us consider the pair:T: Mexico?s new president, Felipe Calderon, seems to bedoing all the right things in cracking down on Mexico?s drugtraffickers.[...
]H: Felipe Calderon is the outgoing President of Mexico.In order to detect the correct contradiction judg-ment between T and H it is necessary to solve thesemantic inference that being the new President ofa country is not compatible with being the outgo-ing President of the same country.
This kind ofinference requires that (i) the semantic oppositionis detected, and that (ii) such opposition is consid-1http://qallme.fbk.eu/86Text snippet (pair 125) Phenomena Judg.T Mexico?s new president, Felipe Calderon, seems to be doingall the right things in cracking down on Mexico?s drug traffickers.
[...]lexical:semantic-opposition CH Felipe Calderon is the outgoing President of Mexico.
syntactic:argument-realizationsyntactic:appositionH1 Mexico?s outgoing president, Felipe Calderon, seems to be lexical:semantic-opposition Cdoing all the right things in cracking down on Mexico?s drugtraffickers.
[...]H2 The new president of Mexico, Felipe Calderon, seems to be syntactic:argument-realization Edoing all the right things in cracking down on Mexico?s drugtraffickers.
[...]H3 Felipe Calderon is Mexico?s new president.
syntactic:apposition ETable 1: Application of the decomposition methodology to an original RTE pairered relevant for the contradiction judgment in thespecific context of the pair.In order to address the issues above, we pro-pose a methodology based on the decompositionof [T,H] pairs into monothematic pairs, each rep-resenting one single linguistic phenomenon rele-vant for entailment judgment.
Then, the analy-sis is carried out both on the original [T,H] pairand on the monothematic pairs originated fromit.
In particular, we investigate the correlations onpositive and on negative pairs separately, and weshow that the strategies adopted by the TE sys-tems to deal with phenomena contributing to theentailment or to the contradiction judgment cometo light when analyzed using qualitative criteria.We have experimented the decomposition method-ology over a dataset of pairs, which either aremarked with a contradiction judgment, or show apolarity phenomenon (either in T or H) which, al-though present, is not relevant for cotradiction.The final goal underlying our analysis of con-tradiction in current RTE datasets is to discovergood strategies for systems to manage contradic-tion and, more generally, entailment judgments.To this aim, in Section 5 we propose a comparisonbetween two systems participating at the last RTE-5 campaign and try to analyze their behaviour ac-cording to the decomposition into monothematicpairs.The paper is structured as follows.
Section 2presents the main aspects related to contradictionwithin the RTE context.
Section 3 explains theprocedure for the creation of monothematic pairsstarting from RTE pairs.
Section 4 describes theexperimental setup of our pilot study, as well asthe results of the qualitative analysis.
Section 5outlines the preliminary achievements in terms ofcomparison of systems?
strategies in order to man-age contradiction.
Finally, Section 6 reports onprevious work on contradiction and textual entail-ment.2 Contradiction and Textual EntailmentIn RTE, two kinds of judgment are allowed: twoways (yes or no entailment) or three way judg-ment.
In the latter, systems are required to decidewhether the hypothesis is entailed by the text (en-tailment), contradicts the text (contradiction), oris neither entailed by nor contradicts the text (un-known).
The RTE-4 and RTE-5 datasets are anno-tated for a 3-way decision: entailment (50% of thepairs), unknown (35%), contradiction (15%).
Thisdistribution among the three entailment judgmentsaims at reflecting the natural distribution of en-tailment in a corpus, where the percentage of textsnippets neither entailing nor contradicting eachother is higher than the contradicting ones.
Even ifthis balance seems artificial since in a natural set-ting the presence of unknown pairs is much higherthan the other two judgments (as demonstrated inthe Pilot Task proposed in RTE-5 (Bentivogli etal., 2009)), the reason behind the choice of RTEorganizers is to maintain a trade-off between thenatural distribution of the data in real documents,and the creation of a dataset balanced beween pos-itive and negative examples (as in two way task).As already pointed out in (Wang, 2009), thesimilarity between T?s and H?s in pairs marked asentailment and contradiction is much higher withrespect to the similarity between T?s and H?s inpairs marked as unknown.
To support this in-tuition, (Bentivogli et al, 2009) provides somedata on the lexical overlap between T?s and H?sin the last RTE Challenges.
For instance, in RTE-4 the lexical overlap is 68.95% in entailment pairs,67.97% in contradiction pairs and only 57.36% in87the unknown pairs.
Similarly, in RTE-5 the lexicaloverlap between T?s and H?s is 77.14% in entail-ment pairs, 78.93% in contradiction pairs and only62.28% in the unknown pairs.For this reason, for contradiction detection it isnot sufficient to highlight mismatching informa-tion between sentences, but deeper comprehensionis required.
For applications in information anal-ysis, it can be very important to detect incompat-ibility and discrepancies in the description of thesame event, and the contradiction judgment in theTE task aims at covering this aspect.
More specif-ically, in the RTE task the contradiction judgmentis assigned to a T,H pair when the two text frag-ments are extremely unlikely to be true simultane-ously.According to Marneffe et al (2008), contra-dictions may arise from a number of differentconstructions, defined in two primary categories:i) those occurring via antonymy, negation, andnumeric mismatch, and ii) contradictions arisingfrom the use of factive or modal words, structuraland subtle lexical contrasts, and world knowledge.Comparing the distribution of contradiction typesfor RTE-3 and the real contradiction corpus theycreated collecting contradiction ?in the wild?
(e.g.from newswire, Wikipedia), they noticed that inthe latter there is a much higher rate of negations,numeric and lexical contradictions with respectto RTE dataset, where contradictions of category(ii) occur more frequently.
Analyzing RTE dataof the previous challenges, we noticed that thetendency towards longer and more complexsentences in the datasets in order to reproducemore realistic scenarios, is also reflected in morecomplex structures determining contradictions.For instance, contradictions arising from overtnegation as in (pair 1663, RTE-1 test set):T: All residential areas in South Africa are segregated byrace and no black neighborhoods have been established inPort Nolloth.H: Black neighborhoods are located in Port Nolloth.are infrequent in the datasets of more recent RTEchallenges.
For instance, in RTE-5 test set, only in4 out of 90 contradiction pairs an overt negationis responsible for the contradiction judgment.In agreement with (Marneffe et al, 2008), wealso remarked that most of the contradictioninvolve numeric mismatch, wrong appositions,entity mismatch and, above all, deeper inferencesdepending on background and world knowledge,as in (pair 567, RTE-5 test set):T: ?[...]
we?ve done a series of tests on Senator Kennedyto determine the cause of his seizure.
He has had no furtherseizures, remains in good overall condition, and is up andwalking around the hospital?.H: Ted Kennedy is dead.These considerations do not mean that overtnegations do not appear in the RTE pairs.
On thecontrary, they are often present in T,H pairs, butmost of the times their presence is irrelevant in theassignment of the correct entailment judgment tothe pair.
For instance, the scope of the negationcan be a phrase or a sentence with additional infor-mation with respect to the relevant parts of T andH that allow to correctly judge the pair.
This factcould be misleading for systems that do not cor-recly exploit syntactic information, as the experi-ments using Linear Distance described in (Cabrioet al, 2008).3 Decomposing RTE pairsThe qualitative evaluation we propose takesadvantage of previous work on monothematicdatasets.
A monothematic pair (Magnini andCabrio, 2009) is defined as a [T,H] pair in which acertain phenomenon relevant to the entailment re-lation is highlighted and isolated.
The main idea isto create such monothematic pairs on the basis ofthe phenomena which are actually present in theoriginal RTE pairs, so that the actual distributionof the linguistic phenomena involved in the entail-ment relation emerges.For the decomposition procedure, we refer tothe methodology described in (Bentivogli et al,2010), consisting of a number of steps carriedout manually.
The starting point is a [T,H] pairtaken from one of the RTE datasets, that should bedecomposed in a number of monothematic pairs[T,Hi]mono, where T is the original Text and Hiare the Hypotheses created for each linguistic phe-nomenon relevant for judging the entailment rela-tion in [T,H].In detail, the procedure for the creation ofmonothematic pairs is composed of the followingsteps:1.
Individuate the linguistic phenomena whichcontribute to the entailment in [T,H].2.
For each phenomenon i:88(a) Individuate a general entailment rule rifor the phenomenon i, and instantiatethe rule using the portion of T which ex-presses i as the left hand side (LHS) ofthe rule, and information from H on i asthe right hand side (RHS) of the rule.
(b) Substitute the portion of T that matchesthe LHS of riwith the RHS of ri.
(c) Consider the result of the previous stepas Hi, and compose the monothematicpair [T,Hi]mono.
Mark the pair withphenomenon i.3.
Assign an entailment judgment to eachmonothematic pair.Relevant linguistic phenomena are grouped us-ing both fine-grained categories and broader cate-gories.
Macro categories are defined referring towidely accepted linguistic categories in the liter-ature (e.g.
(Garoufi, 2007)) and to the inferencetypes typically addressed in RTE systems: lexical,syntactic, lexical-syntactic, discourse and reason-ing.
Each macro category includes fine-grainedphenomena (Table 2 reports a list of some of thephenomena detected in RTE-5 dataset).Table 1 shows an example of the decomposi-tion of a RTE pair (marked as contradiction) intomonothematic pairs.
At step 1 of the methodologyboth the phenomena that preserve the entailmentand the phenomena that break the entailment rulescausing a contradiction in the pair are detected,i.e.
argument realization, apposition and seman-tic opposition (column phenomena in the table).While the monothematic pairs created basing onthe first two phenomena preserve the entailment,the semantic opposition generates a contradiction(column judgment).As an example, let?s apply step by step theprocedure to the phenomenon of semantic oppo-sition.
At step 2a of the methodology the generalrule:Pattern: x ?
/ ?
yConstraint: semantic opposition(y,x)is instantiated (new?
/ ?outgoing), and at step2b the substitution in T is carried out (Mexico?soutgoing president, Felipe Calderon [...]).
Atstep 2c a negative monothematic pair T,H1iscomposed (column text snippet in the table) andmarked as semantic opposition (macro-categorylexical), and the pair is judged as contradiction.In (Bentivogli et al, 2010), critical issues con-cerning the application of such procedure are dis-cussed in detail, and more examples are provided.Furthermore, a pilot resource is created, composedof a first dataset with 60 pairs from RTE-5 testset (30 positive, and 30 negative randomly ex-tracted examples), and a dataset composed of allthe monothematic pairs derived by the first onefollowing the procedure described before.
Thesecond dataset is composed of 167 pairs (134 en-tailment, 33 contradiction examples, considering35 different linguistic phenomena).24 Analysis and discussionOur analysis has been carried out taking advan-tage of the pilot resource created by Bentivogliet al (2010).
From their first dataset we ex-tracted a sample of 48 pairs ([T,H]sample?contr)composed of 30 contradiction pairs and 18 entail-ment pairs, the latter containing either in T or inH a directly or an indirectly licensed negation.3Furthermore, a dataset of 129 monothematic pairs(96 entailment and 33 contradiction examples),i.e.
[T,H]mono?contr, was derived by the pairsin [T,H]sample?contrapplying the procedure de-scribed in Section 3.
The linguistic phenomenaisolated in the monothematic pairs (i.e.
consideredrelevant to correctly assign the entailment judg-ment to our sample) are listed in Table 2.In RTE datasets only a subpart of the potentiallyproblematic phenomena concerning negation andnegative polarity items is represented.
At the sametime, the specificity of the task lies in the fact thatit is not enough to find the correct representationof the linguistic phenomena underlying a sentencemeaning, but correct inferences should be derivedfrom the relations that these phenomena contributeto establish between two text fragments.
Themere presence of a negation in T is not relevantfor the TE task, unless the scope of the negation (atoken or a phrase) is present as non-negated in H2Both datasets are freely available athttp://hlt.fbk.eu/en/Technology/TE Specialized Data3Following (Harabagiu et al, 2006) overt (directly li-censed) negations include i) overt negative markers such asnot, n?t; ii) negative quantifiers as no, and expressions suchas no one and nothing; iii) strong negative adverbs like never.Indirectly licensed negations include: i) verbs or phrasalverbs (e.g.
deny, fail, refuse, keep from); ii) prepositions (e.g.without, except); weak quantifiers (e.g.
few, any, some), andiv) traditional negative polarity items (e.g.
a red cent or any-more).89phenomena # pairs [T,H]RTE5?mono?contrentailment contradiction# mono probab.
# mono probab.lex:identity 1 0.25 3 0.75lex:format 2 1 - -lex:acronymy 1 1 - -lex:demonymy 1 1 - -lex:synonymy 6 1 - -lex:semantic-opp.
- - 3 1lex:hypernymy 2 1 - -TOT lexical 13 0.68 6 0.32lexsynt:transp-head 2 1 - -lexsynt:verb-nom.
6 1 - -lexsynt:causative 1 1 - -lexsynt:paraphrase 2 1 - -TOT lexical-syntactic 11 1 - -synt:negation - - 1 1synt:modifier 3 0.75 1 0.25synt:arg-realization 4 1 - -synt:apposition 9 0.6 6 0.4synt:list 1 1 - -synt:coordination 2 1 - -synt:actpass-altern.
4 0.67 2 0.33TOT syntactic 23 0.7 10 0.3disc:coreference 16 1 - -disc:apposition 2 1 - -disc:anaphora-zero 3 1 - -disc:ellipsis 3 1 - -disc:statements 1 1 - -TOT discourse 25 1 - -reas:apposition 1 0.5 1 0.5reas:modifier 2 1 - -reas:genitive 1 1 - -reas:meronymy 1 0.5 1 0.5reas:quantity - - 5 1reas:spatial 1 1 - -reas:gen-inference 18 0.64 10 0.36TOT reasoning 24 0.59 17 0.41TOT (all phenomena) 96 0.74 33 0.26Table 2: Occurrences of linguistic phenomena inTE contradiction pairs(or viceversa), hence a contradiction is generated.For this reason, 18 pairs of [T,H]sample?contrare judged as entailment even if a negation ispresent, but it is not relevant to correctly assignthe entailment judgment to the pair as in (pair205, RTE-5 test set):T: A team of European and American astronomers saythat a recently discovered extrasolar planet, located not farfrom Earth, contains oceans and rivers of hot solid water.
Theteam discovered the planet, Gliese 436 b [...].H: Gliese 436 b was found by scientists from America andEurope.As showed in Table 2, only in one pair ofour sample the presence of a negation is relevantto assign the contradiction judgment to the pair.In the pairs we analyzed, contradiction mainlyarise from quantity mismatching, semantic oppo-sition (antonymy), mismatching appositions (e.g.the Swiss Foreign Minister x contradicts y is theSwiss Foreign Minister), and from general infer-ence (e.g.
x became a naturalized citizen of theU.S.
contradicts x is born in the U.S.).
Due to thesmall sample we analyzed, some phenomena ap-pear rarely, and their distribution can not be con-sidered as representative of the same phenomenonin a natural setting.
In 27 out of 30 contradictionpairs, only one monothematic pair among the onesderived from each example was marked as con-tradiction, meaning that on average only one lin-guistic phenomenon is responsible for the contra-diction judgment in a TE original pair.
Hence theimportance of detecting it.Given the list of the phenomena isolated in[T,H]mono?contrwith their frequency both inmonothematic positive pairs and monothematicnegative pairs, we derived the probability of lin-guistic phenomena to contribute more to the as-signment of a certain judgment than to another(column probab.
in Table 2).
Such probability Pof a phenomenon i to appear in a positive (or in anegative) pair is calculated as follows:P (i|[T,H]positive) =#(i|[T,H]RTE5?positive?mono)#(i|[T,H]RTE5?mono)(1)For instance, if the phenomenon semantic op-position appears in 3 pairs of our sample and allthese pairs are marked as contradiction, we as-sign a probability of 1 to a pair containing a se-mantic opposition to be marked as contradiction.If the phenomenon apposition (syntax) appears in9 monothematic positive pairs and in 6 negativepairs, that phenomenon has a probability of 0.6 toappear in positive examples and 0.4 to appear innegative examples.
Due to their nature, some phe-nomena are strongly related to a certain judgment(e.g.
semantic opposition), while other can appearboth in positive and in negative pairs.
Learningsuch correlations on larger datasets could be an in-teresting feature to be exploited by TE systems inthe assignment of a certain judgment if the phe-nomenon i is detected in the pair.Table 3 reports the cooccurrences of the linguis-tic phenomena relevant to inference in the pairsmarked as contradiction.
On the first horizontalrow all the phenomena that at least in one pairdetermine contradiction are listed, while in thefirst column there are all the phenomena cooc-curring with them in the pairs.
The idea un-delying this table is to understand if it is possi-ble to identify recurrent patterns of cooccurrencesbetween phenomena in contradiction pairs.
Ascan be noticed, almost all phenomena occur to-gether with expressions requiring deeper inference90lex:identitylex:semoppositionsynt:negationsynt:modifiersynt:appositionsynt:actpassalternreas:meronymyreas:quantityreas:geninferencelex:identity 1 1lex:format 1lex:acronymy 1lex:synonymy 1 1 1 1lex:hypernymy 1lexsynt:vrb-nom 1 1 1lexsynt:caus.
1synt:modifier 1synt:arg-realiz.
1 1synt:apposition 2 3synt:coord.
1synt:actpass 1 1disc:coref.
3 1 4disc:appositiondisc:anaph-0 1 1disc:ellipsis 1 1 2disc:statements 1reas:genitive 1reas:meronymy 1reas:gen-infer.
1 1 3 1 2 1Table 3: Cooccurrencies of phenomena in contra-diction pairs(reas:general inference), but this is due to the factthat this category is the most frequent one.
Besidethis, it seems that no specific patterns can be high-lighted, but it could be worth to extend this analy-sis increasing the number of pairs of the sample.5 Comparing RTE systems?
behaviouron contradiction pairsAs introduced before, from a contradiction pair itis possible to extract on average 3 monothematicpairs (Bentivogli et al, 2009), and only one ofthese monothematic pairs is marked as contradic-tion.
This means that on average only one lin-guistic phenomenon is responsible for the contra-diction judgment in a RTE pair, while the othersmaintain the entailment relation (i.e.
it is possibleto correcly apply an entailment rule as exemplifiedin Section 3).
On the contrary, in a pair judgedas entailment, all the monothematic pairs derivedfrom it are marked as entailment.These observations point out the fact that if aTE system is able to correctly isolate and judgethe phenomenon that generates the contradiction,the system should be able to assign the correctjudgment to the original contradiction pair, despitepossible mistakes in handling the other phenom-ena present in that pair.In order to understand how it is possible totake advantage of the data analyzed so far toimprove a TE system, we run two systems thattook part into the last RTE challenge (RTE-5) on[T,H]mono?contr.The first system we used is the EDITS system(Edit Distance Textual Entailment Suite) (Negri etal., 2009)4, that assumes that the distance betweenT and H is a characteristics that separates the pos-itive pairs, for which entailment holds, from thenegative pairs, for which entailment does not hold(it is developed according to the two way task).
Itis based on edit distance algorithms, and computesthe [T,H] distance as the overall cost of the edit op-erations (i.e.
insertion, deletion and substitution)that are required to transform T into H. In partic-ular, we applied the model that produced EDITSbest run at RTE-5 (acc.
on RTE-5 test set: 60.2%).The main features of this run are: Tree Edit Dis-tance algorithm on the parsed trees of T and H,Wikipedia lexical entailment rules, and PSO opti-mized operation costs, as described in (Mehdad etal., 2009).The other system used in our experimentsis VENSES5(Delmonte et al, 2009), that ob-tained performances similar to EDITS at RTE-5(acc.
on test set: 61.5%).
VENSES applies alinguistically-based approach for semantic infer-ence, composed of two main components: i) agrammatically-driven subsystem that validates thewell-formedness of the predicate-argument struc-ture and works on the output of a deep parserproducing augmented (i.e.
fully indexed) head-dependency structures; and ii) a subsystem thatdetects allowed logical and lexical inferences bas-ing on different kind of structural transformationsintended to produce a semantically valid mean-ing correspondence.
The system has a pronomi-nal binding module that works at text/hypothesislevel separately for lexical personal, possessiveand reflexive pronouns, which are substituted bythe heads of their antecedents.
Also in this case,we applied the same configuration of the systemused in RTE evaluation.Table 4 reports EDITS and VENSES accuracieson the monothematic pairs of [T,H]mono?contr.As said before, the accuracy reported for somevery rare phenomena cannot be considered com-pletely reliable.
Nevertheless, from these data themain features of the systems can be identified.
Forinstance, EDITS obtains the highest accuracies onthe positive monothematic pairs, while it seems ithas no peculiar strategies to deal with phenomena4http://edits.fbk.eu/5http://project.cgm.unive.it/venses en.html91phenomena EDITS VENSES% acc.
% acc.pos.
neg.
pos.
neg.lex:identity 100 0 100 33.3lex:format 100 - 100 -lex:acronymy 100 - 0 -lex:demonymy 100 - 100 -lex:synonymy 80.3 - 80.3 -lex:semantic-opp.
- 0 - 100lex:hypernymy 100 - 100 -TOT lexical 96.7 0 80 66.6lexsynt:transp-head 100 - 50 -lexsynt:verb-nom.
83.3 - 16 -lexsynt:causative 100 - 100 -lexsynt:paraphrase 100 - 100 -TOT lexical-syntactic 95.8 - 66.5 -synt:negation - 0 - 0synt:modifier 100 0 33.3 100synt:arg-realization 100 - 50 -synt:apposition 100 33.3 55.5 83.3synt:list 100 - 100 -synt:coordination 100 - 50 -synt:actpass-altern.
100 0 25 50TOT syntactic 100 22.2 52.3 77.7disc:coreference 95 - 50 -disc:apposition 100 - 0 -disc:anaphora-zero 100 - 33.3 -disc:ellipsis 100 - 33.3 -disc:statements 100 - 0 -TOT discourse 99 - 23.3 -reas:apposition 100 0 100 100reas:modifier 50 - 100 -reas:genitive 100 - 100 -reas:meronymy 100 0 100 0reas:quantity - 0 - 80reas:spatial 100 - 0 -reas:gen-inference 87.5 50 37.5 90TOT reasoning 89.5 35.2 72.9 82.3TOT (all phenomena) 96.2 25 59 81.2Table 4: RTE systems?
accuracy on phenomenathat generally cause contradiction (e.g.
seman-tic opposition, negation, and quantity mismatch-ing).
On the contrary, VENSES shows an oppo-site behaviour, obtaining the best results on thenegative cases.
Analysing such data it is possibleto hypothesize systems?
behaviours: for example,on the monothematic dataset EDITS produces apretty high number of false positives, meaning thatfor this system if there are no evidences of con-tradiction, a pair should be marked as entailment(in order to improve such system, strategies to de-tect contradiction pairs should be thought).
On thecontrary, VENSES produces a pretty high numberof false negatives, meaning that if the system is notable to find evidences of entailment, it assigns thecontradiction value to the pairs (for this system,being able to correctly detect all the phenomenacontributing to entailment in a pair is fundamen-tal, otherwise it will be marked as contradiction).6 Related WorkCondoravdi et al (2003) first proposed contra-diction detection as an important NLP task, then(Harabagiu et al, 2006) provided the first em-pirical results for it, focusing on contradictioncaused by negation, antonymy, and paraphrases.Voorhees (2008) carries out an analysis of RTE-3 extended task, examining systems?
abilities todetect contradiction and providing explanationsof their reasoning when making entailment deci-sions.Beside defining the categories of constructionfrom which contradiction may arise, Marneffe etal.
(2008) provide the annotation of the RTEdatasets (RTE-1 and RTE-2) for contradiction.Furthermore, they also collect contradiction ?inthe wild?
(e.g.
from newswire, Wikipedia) to sam-ple naturally occurring ones.6Ritter et al (2008) extend (Marneffe et al,2008)?s analysis to a class of contradiction that canonly be detected using backgroud knowledge, anddescribe a case study of contradiction detectionbased on functional relations.
They also automat-ically generate a corpus of seeming contradictionfrom the Web text.7Furthermore, some of the systems presented inthe previous editions of the RTE challenges at-tempted specic strategies to focus on the phe-nomenon of negation.
For instance, (Snow et al,2006) presents a framework for recognizing tex-tual entailment that focuses on the use of syntacticheuristics to recognize false entailment.
Amongthe others, heuristics concerning negation mis-match and antonym match are defined.
In (Tatuet al, 2007) the logic representation of sentenceswith negated concepts was altered to mark asnegated the entire scope of the negation.
(Ferran-dez et al, 2009) propose a system facing the en-tailment recognition by computing shallow lexicaldeductions and richer inferences based on seman-tics, and features relating to negation are extracted.In (Iftene et al, 2009) several rules are extractedand applied to detect contradiction cases.7 ConclusionWe have proposed a methodology for the qualita-tive analysis of TE systems focusing on contradic-tion judgments and on the linguistic phenomenathat determine such judgments.
The methodologyis based on the decomposition of [T,H] pairs intomonothematic pairs, each representing one sin-gle linguistic phenomenon relevant for entailment6Their corpora are available at http://www-nlp.stanford.edu/projects/contradiction.7Available at http://www.cs.washington.edu/research/ au-contraire/92judgment.In particular, the phenomena from which con-tradiction may arise and their distribution in RTEdatasets have been highlighted, and a pilot studycomparing the performancies of two RTE systemsboth on monothematic pairs and on the corre-sponding original ones has been carried out.
Wediscovered that, although the two systems havesimilar performances in terms of accuracy on theRTE-5 datasets, they show significant differencesin their respective abilities to correctly manage dif-ferent linguistic phenomena that generally causecontradiction.
We hope that the analysis of con-tradiction in current RTE datasets may bring inter-esting elements to TE system developers to definegood strategies to manage contradiction and, moregenerally, entailment judgments.8 AcknowledgementsThis work has been partially supported by theLiveMemories project (Active Digital Memo-ries of Collective Life) funded by the Au-tonomous Province of Trento under the call ?Ma-jor Projects?.
We would like to thank ProfessorRodolfo Delmonte and Sara Tonelli for runningthe VENSES system on our datasets.ReferencesBentivogli, Luisa, Bernardo Magnini, Ido Dagan,Hoa Trang Dang, and Danilo Giampiccolo.
2009.The Fifth PASCAL RTE Challenge.
Proceedings ofthe TAC 2009 Workshop on Textual Entailment.
Toappear.
Gaithersburg, Maryland.
17 November.Bentivogli, Luisa, Elena Cabrio, Ido Dagan,Danilo Giampiccolo, Medea Lo Leggio, andBernardo Magnini.
2010.
Building Textual En-tailment Specialized Data Sets: a Methodologyfor Isolating Linguistic Phenomena Relevant toInference.
Proceedings of the 7th LREC conference.Valletta, Malta.
19-21 May.Cabrio, Elena, Milen Ognianov Kouylekov andBernardo Magnini, 2008.
Combining SpecializedEntailment Engines for RTE-4, Proceedings of theText Analysis Conference (TAC 2008).
Gaithersburg,Maryland, USA, 17-18 November.Condoravdi, Cleo, Dick Crouch, Valeria de Paiva,Reinhard Stolle, and Daniel Bobrow.
2003.
Entail-ment, Intentionality and Text Understanding Pro-ceedings of the HLT-NAACL 2003 Workshop on TextMeaning.
Edmonton, Alberta, Canada.
31 May.Dagan, Ido, Bill Dolan, Bernardo Magnini, andDan Roth.
2009.
Recognizing textual entailment:Rational, evaluation and approaches.
Natural Lan-guage Engineering (JNLE), Volume 15, Special Is-sue 04, October 2009, pp i-xvii.
Cambridge Univer-sity Press.De Marneffe, Marie-Catherine, Anna N. Rafferty andChristopher D. Manning.
2008.
Finding Contradic-tions in Text.
Proceedings of ACL-08: HLT, pages10391047.
Columbus, Ohio, USA, June.Delmonte, Rodolfo, Sara Tonelli, Rocco Tripodi.2009.
Semantic Processing for Text Entailment withVENSES.
Proceedings of the TAC 2009 Workshopon TE.
Gaithersburg, Maryland.
17 November.Garoufi, Konstantina.
2007.
Towards a Better Un-derstanding of Applied Textual Entailment.
MasterThesis.
Saarland University.
Saarbr?ucken, Germany.Ferr?andez,?Oscar, Rafael Mu?noz, and Manuel Palomar.2009.
Alicante University at TAC 2009: Experi-ments in RTE.
Proceedings of the TAC 2009 Work-shop on Textual Entailment.
Gaithersburg, Mary-land.
17 November.Harabagiu, Sanda, Andrew Hickl, and Finley Lacatusu.2006.
Negation, Contrast and Contradiction in TextProcessing.
In Proceedings of AAAI-06.
Boston,Massachusetts.
July 16-20.Iftene, Adrian, Mihai-Alex Moruz 2009.
UAICParticipation at RTE-5.
Proceedings of the TAC2009 Workshop on Textual Entailment.
To appear.Gaithersburg, Maryland.
17 November.Magnini, Bernardo, and Elena Cabrio.
2009.
Com-bining Specialized Entailment Engines.
Proceed-ings of the LTC ?09 conference.
Poznan, Poland.6-8 November.Mehdad, Yashar, Matteo Negri, Elena Cabrio,Milen Kouylekov, and Bernardo Magnini.
2009.Using Lexical Resources in a Distance-Based Ap-proach to RTE.
Proceedings of the TAC 2009 Work-shop on TE.
Gaithersburg, Maryland.
17 November2009.Negri, Matteo, Milen Kouylekov, Bernardo Magnini,Yashar Mehdad, and Elena Cabrio.
2009.
TowardsExtensible Textual Entailment Engines: the EDITSPackage.
AI*IA 2009: Emergent Perspectives in Ar-tificial Intelligence.
Lecture Notes in Computer Sci-ence, Springer-Verlag, pp.
314-323.
2009.Nielsen, Rodney D., Wayne Ward, and James H. Mar-tin.
2009.
Recognizing entailment in intelligent tu-toring systems.
In Ido Dagan, Bill Dolan, BernardoMagnini and Dan Roth (Eds.)
The Journal of Natu-ral Language Engineering, (JNLE).
15, pp 479-501.Copyright Cambridge University Press, Cambridge,United Kingdom.Ritter, Alan, Doug Downey, Stephen Soderland, andOren Etzioni.
2008.
It?s a Contradiction - No, it?snot: A Case Study using Functional Relations.
Pro-ceedings of 2008 Conference on Empirical Methods93in Natural Language Processing.
Honolulu, Hawaii.25-27 October.Romano, Lorenza, Milen Ognianov Kouylekov,Idan Szpektor, Ido Kalman Dagan, and Al-berto Lavelli.
2006.
Investigating a GenericParaphrase-Based Approach for Relation Extrac-tion.
Proceedings of EACL 2006.
Trento, Italy.
3-7April.Snow, Rion, Lucy Vanderwende, and Arul Menezes.2006.
Effectively using syntax for recognizing falseentailment.
Proceedings of the main conferenceon Human Language Technology Conference of theNorth American Chapter of the Association of Com-putational Linguistics.
New York, 4-9 June.Tatu, Marta, Dan I. Moldovan.
2007.
COGEX atRTE 3.
Proceedings of the ACL-PASCAL Workshopon Textual Entailment and Paraphrasing.
Prague,Czech Republic, 28-29 June.Voorhees, Ellen M. 2008.
Contradictions and Justifi-cations: Extentions to the Textual Entailment Task.Proceedings of ACL-08: HLT.
Columbus, Ohio,USA.
15-20 June.Wang, Rui, and Yi Zhang.
2009.
Recognizing Tex-tual Relatedness with Predicate-Argument Struc-tures.
Proceedings of the 2009 Conference on Em-pirical Methods in Natural Language Processing.Singapore, 6-7 August.94
