Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 349?358,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsLearning to ?Read Between the Lines?
using Bayesian Logic ProgramsSindhu Raghavan Raymond J. Mooney Hyeonseo KuDepartment of Computer ScienceThe University of Texas at Austin1616 Guadalupe, Suite 2.408Austin, TX 78701, USA{sindhu,mooney,yorq}@cs.utexas.eduAbstractMost information extraction (IE) systemsidentify facts that are explicitly stated in text.However, in natural language, some facts areimplicit, and identifying them requires ?read-ing between the lines?.
Human readers nat-urally use common sense knowledge to in-fer such implicit information from the explic-itly stated facts.
We propose an approachthat uses Bayesian Logic Programs (BLPs),a statistical relational model combining first-order logic and Bayesian networks, to inferadditional implicit information from extractedfacts.
It involves learning uncertain common-sense knowledge (in the form of probabilis-tic first-order rules) from natural language textby mining a large corpus of automatically ex-tracted facts.
These rules are then used to de-rive additional facts from extracted informa-tion using BLP inference.
Experimental eval-uation on a benchmark data set for machinereading demonstrates the efficacy of our ap-proach.1 IntroductionThe task of information extraction (IE) involves au-tomatic extraction of typed entities and relationsfrom unstructured text.
IE systems (Cowie andLehnert, 1996; Sarawagi, 2008) are trained to extractfacts that are stated explicitly in text.
However, somefacts are implicit, and human readers naturally ?readbetween the lines?
and infer them from the statedfacts using commonsense knowledge.
Answeringmany queries can require inferring such implicitlystated facts.
Consider the text ?Barack Obama is thepresident of the United States of America.?
Giventhe query ?Barack Obama is a citizen of what coun-try?
?, standard IE systems cannot identify the an-swer since citizenship is not explicitly stated in thetext.
However, a human reader possesses the com-monsense knowledge that the president of a countryis almost always a citizen of that country, and easilyinfers the correct answer.The standard approach to inferring implicit infor-mation involves using commonsense knowledge inthe form of logical rules to deduce additional in-formation from the extracted facts.
Since manuallydeveloping such a knowledge base is difficult andarduous, an effective alternative is to automaticallylearn such rules by mining a substantial database offacts that an IE system has already automaticallyextracted from a large corpus of text (Nahm andMooney, 2000).
Most existing rule learners assumethat the training data is largely accurate and com-plete.
However, the facts extracted by an IE sys-tem are always quite noisy and incomplete.
Conse-quently, a purely logical approach to learning and in-ference is unlikely to be effective.
Consequently, wepropose using statistical relational learning (SRL)(Getoor and Taskar, 2007), specifically, BayesianLogic Programs (BLPs) (Kersting and De Raedt,2007), to learn probabilistic rules in first-order logicfrom a large corpus of extracted facts and then usethe resulting BLP to make effective probabilistic in-ferences when interpreting new documents.We have implemented this approach by using anoff-the-shelf IE system and developing novel adap-tations of existing learning methods to efficientlyconstruct fast and effective BLPs for ?reading be-349tween the lines.?
We present an experimental evalu-ation of our resulting system on a realistic test cor-pus from DARPA?s Machine Reading project, anddemonstrate improved performance compared to apurely logical approach based on Inductive LogicProgramming (ILP) (Lavrac?
and Dz?eroski, 1994),and an alternative SRL approach based on MarkovLogic Networks (MLNs) (Domingos and Lowd,2009).To the best of our knowledge, this is the first paperthat employs BLPs for inferring implicit informationfrom natural language text.
We demonstrate that itis possible to learn the structure and the parametersof BLPs automatically using only noisy extractionsfrom natural language text, which we then use to in-fer additional facts from text.The rest of the paper is organized as follows.
Sec-tion 2 discusses related work and highlights key dif-ferences between our approach and existing work.Section 3 provides a brief background on BLPs.Section 4 describes our BLP-based approach tolearning to infer implicit facts.
Section 5 describesour experimental methodology and discusses the re-sults of our evaluation.
Finally, Section 6 discussespotential future work and Section 7 presents our fi-nal conclusions.2 Related WorkSeveral previous projects (Nahm and Mooney, 2000;Carlson et al, 2010; Schoenmackers et al, 2010;Doppa et al, 2010; Sorower et al, 2011) have minedinference rules from data automatically extractedfrom text by an IE system.
Similar to our approach,these systems use the learned rules to infer addi-tional information from facts directly extracted froma document.
Nahm and Mooney (2000) learn propo-sitional rules using C4.5 (Quinlan, 1993) from dataextracted from computer-related job-postings, andtherefore cannot learn multi-relational rules withquantified variables.
Other systems (Carlson et al,2010; Schoenmackers et al, 2010; Doppa et al,2010; Sorower et al, 2011) learn first-order rules(i.e.
Horn clauses in first-order logic).Carlson et al (2010) modify an ILP system simi-lar to FOIL (Quinlan, 1990) to learn rules with prob-abilistic conclusions.
They use purely logical de-duction (forward-chaining) to infer additional facts.Unlike BLPs, this approach does not use a well-founded probabilistic graphical model to computecoherent probabilities for inferred facts.
Further,Carlson et al (2010) used a human judge to man-ually evaluate the quality of the learned rules beforeusing them to infer additional facts.
Our approach,on the other hand, is completely automated andlearns fully parameterized rules in a well-definedprobabilistic logic.Schoenmackers et al (2010) develop a systemcalled SHERLOCK that uses statistical relevance tolearn first-order rules.
Unlike our system and others(Carlson et al, 2010; Doppa et al, 2010; Sorower etal., 2011) that use a pre-defined ontology, they auto-matically identify a set of entity types and relationsusing ?open IE.?
They use HOLMES (Schoenmack-ers et al, 2008), an inference engine based on MLNs(Domingos and Lowd, 2009) (an SRL approach thatcombines first-order logic and Markov networks)to infer additional facts.
However, MLNs includeall possible type-consistent groundings of the rulesin the corresponding Markov net, which, for largerdatasets, can result in an intractably large graphicalmodel.
To overcome this problem, HOLMES usesa specialized model construction process to controlthe grounding process.
Unlike MLNs, BLPs natu-rally employ a more ?focused?
approach to ground-ing by including only those literals that are directlyrelevant to the query.Doppa et al (2010) use FARMER (Nijssen andKok, 2003), an existing ILP system, to learn first-order rules.
They propose several approaches toscore the rules, which are used to infer additionalfacts using purely logical deduction.
Sorower et al(2011) propose a probabilistic approach to modelingimplicit information as missing facts and use MLNsto infer these missing facts.
They learn first-orderrules for the MLN by performing exhaustive search.As mentioned earlier, inference using both these ap-proaches, logical deduction and MLNs, have certainlimitations, which BLPs help overcome.DIRT (Lin and Pantel, 2001) and RESOLVER(Yates and Etzioni, 2007) learn inference rules, alsocalled entailment rules that capture synonymous re-lations and entities from text.
Berant et al (Berantet al, 2011) propose an approach that uses transitiv-ity constraints for learning entailment rules for typedpredicates.
Unlike the systems described above,350these systems do not learn complex first-order rulesthat capture common sense knowledge.
Further,most of these systems do not use extractions froman IE system to learn entailment rules, thereby mak-ing them less related to our approach.3 Bayesian Logic ProgramsBayesian logic programs (BLPs) (Kersting and DeRaedt, 2007; Kersting and Raedt, 2008) can be con-sidered as templates for constructing directed graph-ical models (Bayes nets).
Formally, a BLP con-sists of a set of Bayesian clauses, definite clausesof the form a|a1, a2, a3, .....an, where n ?
0 anda, a1, a2, a3,......,an are Bayesian predicates (de-fined below), and where a is called the head ofthe clause (head(c)) and (a1, a2, a3,....,an) is thebody (body(c)).
When n = 0, a Bayesian clauseis a fact.
Each Bayesian clause c is assumed tobe universally quantified and range restricted, i.evariables{head} ?
variables{body}, and has anassociated conditional probability table CPT(c) =P(head(c)|body(c)).
A Bayesian predicate is a pred-icate with a finite domain, and each ground atom fora Bayesian predicate represents a random variable.Associated with each Bayesian predicate is a com-bining rule such as noisy-or or noisy-and that mapsa finite set of CPTs into a single CPT.Given a knowledge base as a BLP, standard logi-cal inference (SLD resolution) is used to automat-ically construct a Bayes net for a given problem.More specifically, given a set of facts and a query,all possible Horn-clause proofs of the query are con-structed and used to build a Bayes net for answeringthe query.
The probability of a joint assignment oftruth values to the final set of ground propositions isdefined as follows:P(X) =?i P (Xi|Pa(Xi)),where X = X1, X2, ..., Xn represents the set ofrandom variables in the network and Pa(Xi) rep-resents the parents of Xi.
Once a ground network isconstructed, standard probabilistic inference meth-ods can be used to answer various types of queriesas reviewed by Koller and Friedman (2009).
Theparameters in the BLP model can be learned usingthe methods described by Kersting and De Raedt(2008).4 Learning BLPs to Infer Implicit Facts4.1 Learning Rules from Extracted DataThe first step involves learning commonsenseknowledge in the form of first-order Horn rules fromtext.
We first extract facts that are explicitly statedin the text using SIRE (Florian et al, 2004), an IEsystem developed by IBM.
We then learn first-orderrules from these extracted facts using LIME (Mc-creath and Sharma, 1998), an ILP system designedfor noisy training data.We first identify a set of target relations we wantto infer.
Typically, an ILP system takes a set ofpositive and negative instances for a target relation,along with a background knowledge base (in ourcase, other facts extracted from the same document)from which the positive instances are potentially in-ferable.
In our task, we only have direct access topositive instances of target relations, i.e the relevantfacts extracted from the text.
So we artificially gen-erate negative instances using the closed world as-sumption, which states that any instance of a rela-tion that is not extracted can be considered a nega-tive instance.
While there are exceptions to this as-sumption, it typically generates a useful (if noisy)set of negative instances.
For each relation, we gen-erate all possible type-consistent instances using allconstants in the domain.
All instances that are notextracted facts (i.e.
positive instances) are labeledas negative.
The total number of such closed-worldnegatives can be intractably large, so we randomlysample a fixed-size subset.
The ratio of 1:20 forpositive to negative instances worked well in our ap-proach.Since LIME can learn rules using only positive in-stances, or both positive and negative instances, welearn rules using both settings.
We include all uniquerules learned from both settings in the final set, sincethe goal of this step is to learn a large set of po-tentially useful rules whose relative strengths willbe determined in the next step of parameter learn-ing.
Other approaches could also be used to learncandidate rules.
We initially tried using the popularALEPH ILP system (Srinivasan, 2001), but it did notproduce useful rules, probably due to the high levelof noise in our training data.3514.2 Learning BLP ParametersThe parameters of a BLP include the CPT entries as-sociated with the Bayesian clauses and the parame-ters of combining rules associated with the Bayesianpredicates.
For simplicity, we use a deterministiclogical-and model to encode the CPT entries associ-ated with Bayesian clauses, and use noisy-or to com-bine evidence coming from multiple ground rulesthat have the same head (Pearl, 1988).
The noisy-or model requires just a single parameter for eachrule, which can be learned from training data.We learn the noisy-or parameters using the EMalgorithm adapted for BLPs by Kersting and DeRaedt (2008).
In our task, the supervised trainingdata consists of facts that are extracted from thenatural language text.
However, we usually do nothave evidence for inferred facts as well as noisy-ornodes.
As a result, there are a number of variables inthe ground networks which are always hidden, andhence EM is appropriate for learning the requisiteparameters from the partially observed training data.4.3 Inference of Additional Facts using BLPsInference in the BLP framework involves backwardchaining (Russell and Norvig, 2003) from a spec-ified query (SLD resolution) to obtain all possi-ble deductive proofs for the query.
In our context,each target relation becomes a query on which webackchain.
We then construct a ground Bayesiannetwork using the resulting deductive proofs forall target relations and learned parameters usingthe standard approach described in Section 3.
Fi-nally, we perform standard probabilistic inferenceto estimate the marginal probability of each inferredfact.
Our system uses Sample Search (Gogate andDechter, 2007), an approximate sampling algorithmdeveloped for Bayesian networks with determinis-tic constraints (0 values in CPTs).
We tried severalexact and approximate inference algorithms on ourdata, and this was the method that was both tractableand produced the best results.5 Experimental Evaluation5.1 DataFor evaluation, we used DARPA?s machine-readingintelligence-community (IC) data set, which con-sists of news articles on terrorist events around theworld.
There are 10, 000 documents each contain-ing an average of 89.5 facts extracted by SIRE (Flo-rian et al, 2004).
SIRE assigns each extracted facta confidence score and we used only those with ascore of 0.5 or higher for learning and inference.
Anaverage of 86.8 extractions per document meet thisthreshold.DARPA also provides an ontology describing theentities and relations in the IC domain.
It con-sists of 57 entity types and 79 relations.
Theentity types include Agent, PhysicalThing, Event,TimeLocation, Gender, and Group, each with sev-eral subtypes.
The type hierarchy is a DAG ratherthan a tree, and several types have multiple super-classes.
For instance, a GeopoliticalEntity can bea HumanAgent as well as a Location.
This cancause some problems for systems that rely on astrict typing system, such as MLNs which rely ontypes to limit the space of ground literals that areconsidered.
Some sample relations are attended-School, approximateNumberOfMembers, mediatin-gAgent, employs, hasMember, hasMemberHuman-Agent, and hasBirthPlace.5.2 MethodologyWe evaluated our approach using 10-fold cross vali-dation.
We learned first-order rules for the 13 tar-get relations shown in Table 3 from the facts ex-tracted from the training documents (Section 4.1).These relations were selected because the extrac-tor?s recall for them was low.
Since LIME does notscale well to large data sets, we could train it onat most about 2, 500 documents.
Consequently, wesplit the 9, 000 training documents into four disjointsubsets and learned first-order rules from each sub-set.
The final knowledge base included all uniquerules learned from any subset.
LIME learned sev-eral rules that had only entity types in their bodies.Such rules make many incorrect inferences; hencewe eliminated them.
We also eliminated rules vio-lating type constraints.
We learned an average of 48rules per fold.
Table 1 shows some sample learnedrules.We then learned parameters as described in Sec-tion 4.2.
We initially set al noisy-or parameters to0.9 based on the intuition that if exactly one rule fora consequent was satisfied, it could be inferred witha probability of 0.9.352governmentOrganization(A) ?
employs(A,B)?
hasMember(A,B)If a government organization A employs person B, then B is a member of AeventLocation(A,B) ?
bombing(A)?
thingPhysicallyDamaged(A,B)If a bombing event A took place in location B, then B is physically damagedisLedBy(A,B)?
hasMemberPerson(A,B)If a group A is led by person B, then B is a member of AnationState(B) ?
eventLocationGPE(A,B)?
eventLocation(A,B)If an event A occurs in a geopolitical entity B, then the event location for that event is BmediatingAgent(A,B) ?
humanAgentKillingAPerson(A)?
killingHumanAgent(A,B)If A is an event in which a human agent is killing a person and the mediating agent of A is an agent B, then B isthe human agent that is killing in event ATable 1: A sample set of rules learned using LIMEFor each test document, we performed BLP in-ference as described in Section 4.3.
We ranked allinferences by their marginal probability, and evalu-ated the results by either choosing the top n infer-ences or accepting inferences whose marginal prob-ability was equal to or exceeded a specified thresh-old.
We evaluated two BLPs with different param-eter settings: BLP-Learned-Weights used noisy-orparameters learned using EM, BLP-Manual-Weightsused fixed noisy-or weights of 0.9.5.3 Evaluation MetricsThe lack of ground truth annotation for inferred factsprevents an automated evaluation, so we resortedto a manual evaluation.
We randomly sampled 40documents (4 from each test fold), judged the ac-curacy of the inferences for those documents, andcomputed precision, the fraction of inferences thatwere deemed correct.
For probabilistic methods likeBLPs and MLNs that provide certainties for theirinferences, we also computed precision at top n,which measures the precision of the n inferenceswith the highest marginal probability across the 40test documents.
Measuring recall for making infer-ences is very difficult since it would require labelinga reasonable-sized corpus of documents with all ofthe correct inferences for a given set of target rela-tions, which would be extremely time consuming.Our evaluation is similar to that used in previous re-lated work (Carlson et al, 2010; Schoenmackers etal., 2010).SIRE frequently makes incorrect extractions, andtherefore inferences made from these extractions arealso inaccurate.
To account for the mistakes madeby the extractor, we report two different precisionscores.
The ?unadjusted?
(UA) score, does not cor-rect for errors made by the extractor.
The ?adjusted?
(AD) score does not count mistakes due to extractionerrors.
That is, if an inference is incorrect becauseit was based on incorrect extracted facts, we removeit from the set of inferences and calculate precisionfor the remaining inferences.5.4 BaselinesSince none of the existing approaches have beenevaluated on the IC data, we cannot directly compareour performance to theirs.
Therefore, we comparedto the following methods:?
Logical Deduction: This method forwardchains on the extracted facts using the first-order rules learned by LIME to infer additionalfacts.
This approach is unable to provide anyconfidence or probability for its conclusions.?
Markov Logic Networks (MLNs): We use therules learned by LIME to define the structureof an MLN.
In the first setting, which we callMLN-Learned-Weights, we learn the MLN?sparameters using the generative weight learn-ing algorithm (Domingos and Lowd, 2009),which we modified to process training exam-ples in an online manner.
In online generativelearning, gradients are calculated and weightsare estimated after processing each exampleand the learned weights are used as the start-ing weights for the next example.
The pseudo-likelihood of one round is obtained by multi-plying the pseudo-likelihood of all examples.353UA ADPrecision 29.73 (443/1490) 35.24 (443/1257)Table 2: Precision for logical deduction.
?UA?
and ?AD?refer to the unadjusted and adjusted scores respectivelyIn our approach, the initial weights of clausesare set to 10.
The average number of itera-tions needed to acquire the optimal weights is131.
In the second setting, which we call MLN-Manual-Weights, we assign a weight of 10 toall rules and maximum likelihood prior to allpredicates.
MLN-Manual-Weights is similar toBLP-Manual-Weights in that all rules are giventhe same weight.
We then use the learned rulesand parameters to probabilistically infer addi-tional facts using the MC-SAT algorithm im-plemented in Alchemy,1 an open-source MLNpackage.6 Results and Discussion6.1 Comparison to BaselinesTable 2 gives the unadjusted (UA) and adjusted(AD) precision for logical deduction.
Out of 1, 490inferences for the 40 evaluation documents, 443were judged correct, giving an unadjusted preci-sion of 29.73%.
Out of these 1, 490 inferences, 233were determined to be incorrect due to extraction er-rors, improving the adjusted precision to a modest35.24%.MLNs made about 127, 000 inferences for the 40evaluation documents.
Since it is not feasible tomanually evaluate all the inferences made by theMLN, we calculated precision using only the top1000 inferences.
Figure 1 shows both unadjustedand adjusted precision at top-n for various valuesof n for different BLP and MLN models.
For bothBLPs and MLNs, simple manual weights result insuperior performance than the learned weights.
De-spite the fairly large size of the overall training sets(9,000 documents), the amount of data for eachtarget relation is apparently still not sufficient tolearn particularly accurate weights for both BLPsand MLNs.
However, for BLPs, learned weightsdo show a substantial improvement initially (i.e.1http://alchemy.cs.washington.edu/top 25?50 inferences), with an average of 1 infer-ence per document at 91% adjusted precision asopposed to an average of 5 inferences per docu-ment at 85% adjusted precision for BLP-Manual-Weights.
For MLNs, learned weights show a smallimprovement initially only with respect to adjustedprecision.
Between BLPs and MLNs, BLPs per-form substantially better than MLNs at most pointsin the curve.
However, MLN-Manual-Weights im-prove marginally over BLP-Learned-Weights at laterpoints (top 600 and above) on the curve, where theprecision is generally very low.
Here, the superiorperformance of BLPs over MLNs could be possiblydue to the focused grounding used in the BLP frame-work.For BLPs, as n increases towards including all ofthe logically sanctioned inferences, as expected, theprecision converges to the results for logical deduc-tion.
However, as n decreases, both adjusted andunadjusted precision increase fairly steadily.
Thisdemonstrates that probabilistic BLP inference pro-vides a clear improvement over logical deduction,allowing the system to accurately select the best in-ferences that are most likely to be correct.
Unlike thetwo BLP models, MLN-Manual-Weights has moreor less the same performance at most points on thecurve, and it is slightly better than that of purely-logical deduction.
MLN-Learned-Weights is worsethan purely-logical deduction at most points on thecurve.6.2 Results for Individual Target RelationsTable 3 shows the adjusted precision for eachrelation for instances inferred using logical de-duction, BLP-Manual-Weights and BLP-Learned-Weights with a confidence threshold of 0.95.
Theprobabilities estimated for inferences by MLNs arenot directly comparable to those estimated by BLPs.As a result, we do not include results for MLNshere.
For this evaluation, using a confidence thresh-old based cutoff is more appropriate than using top-n inferences made by the BLP models since the esti-mated probabilities can be directly compared acrosstarget relations.For logical deduction, precision is high for a fewrelations like employs, hasMember, and hasMem-berHumanAgent, indicating that the rules learnedfor these relations are more accurate than the ones3540 100 200 300 400 500 600 700 800 900 100000.10.20.30.40.50.60.70.80.91Top?n inferencesUnadjusted PrecisionBLP?Learned?WeightsBLP?Manual?WeightsMLN?Learned?WeightsMLN?Manual?Weights0 100 200 300 400 500 600 700 800 900 100000.10.20.30.40.50.60.70.80.91Top?n inferencesAdjusted PrecisionBLP?Learned?WeightsBLP?Manual?WeightsMLN?Learned?WeightsMLN?Manual?WeightsFigure 1: Unadjusted and adjusted precision at top-n for different BLP and MLN models for various values of nlearned for the remaining relations.
Unlike rela-tions like hasMember that are easily inferred fromrelations like employs and isLedBy, certain relationslike hasBirthPlace are not easily inferable using theinformation in the ontology.
As a result, it mightnot be possible to learn accurate rules for such tar-get relations.
Other reasons include the lack of asufficiently large number of target-relation instancesduring training and lack of strictly defined types inthe IC ontology.Both BLP-Manual-Weights and BLP-Learned-Weights also have high precision for several re-lations (eventLocation, hasMemberHumanAgent,thingPhysicallyDamaged).
However, the actualnumber of inferences can be fairly low.
For in-stance, 103 instances of hasMemberHumanAgentare inferred by logical deduction (i.e.
0 confidencethreshold), but only 2 of them are inferred by BLP-Learned-Weights at 0.95 confidence threshold, in-dicating that the parameters learned for the corre-sponding rules are not very high.
For several rela-tions like hasMember, hasMemberPerson, and em-ploys, no instances were inferred by BLP-Learned-Weights at 0.95 confidence threshold.
Lack of suffi-cient training instances (extracted facts) is possiblythe reason for learning low weights for such rules.On the other hand, BLP-Manual-Weights has in-ferred 26 instances of hasMemberHumanAgent, outwhich all are correct.
These results therefore demon-strate the need for sufficient training examples tolearn accurate parameters.6.3 DiscussionWe now discuss the potential reasons for BLP?s su-perior performance compared to other approaches.Probabilistic reasoning used in BLPs allows for aprincipled way of determining the most confidentinferences, thereby allowing for improved precisionover purely logical deduction.
The primary dif-ference between BLPs and MLNs lies in the ap-proaches used to construct the ground network.
InBLPs, only propositions that can be logically de-duced from the extracted evidence are included inthe ground network.
On the other hand, MLNs in-clude all possible type-consistent groundings of allrules in the network, introducing many ground liter-als which cannot be logically deduced from the ev-idence.
This generally results in several incorrectinferences, thereby yielding poor performance.Even though learned weights in BLPs do not re-sult in a superior performance, learned weights inMLNs are substantially worse.
Lack of sufficienttraining data is one of the reasons for learning lessaccurate weights by the MLN weight learner.
How-ever, a more important issue is due to the use of theclosed world assumption during learning, which webelieve is adversely impacting the weights learned.As mentioned earlier, for the task considered in thepaper, if a fact is not explicitly stated in text, andhence not extracted by the extractor, it does not nec-essarily imply that it is not true.
Since existingweight learning approaches for MLNs do not dealwith missing data and open world assumption, de-veloping such approaches is a topic for future work.Apart from developing novel approaches for355Relation Logical Deduction BLP-Manual-Weights-.95 BLP-Learned-Weights-.95 No.
training instancesemploys 69.44 (25/36) 92.85 (13/14) nil (0/0) 18440eventLocation 18.75 (18/96) 100.00 (1/1) 100 (1/1) 6902hasMember 95.95 (95/99) 97.26 (71/73) nil (0/0) 1462hasMemberPerson 43.75 (42/96) 100.00 (14/14) nil (0/0) 705isLedBy 12.30 (8/65) nil (0/0) nil (0/0) 8402mediatingAgent 19.73 (15/76) nil (0/0) nil (0/0) 92998thingPhysicallyDamaged 25.72 (62/241) 90.32 (28/31) 90.32 (28/31) 24662hasMemberHumanAgent 95.14 (98/103) 100.00 (26/26) 100.00 (2/2) 3619killingHumanAgent 15.35 (43/280) 33.33 (2/6) 66.67 (2/3) 3341hasBirthPlace 0 (0/88) nil (0/0) nil (0/0) 89thingPhysicallyDestroyed nil (0/0) nil (0/0) nil (0/0) 800hasCitizenship 48.05 (37/77) 58.33 (35/60) nil (0/0) 222attendedSchool nil (0/0) nil (0/0) nil (0/0) 2Table 3: Adjusted precision for individual relations (highest values are in bold)weight learning, additional engineering could poten-tially improve the performance of MLNs on the ICdata set.
Due to MLN?s grounding process, sev-eral spurious facts like employs(a,a) were inferred.These inferences can be prevented by including ad-ditional clauses in the MLN that impose integrityconstraints that prevent such nonsensical proposi-tions.
Further, techniques proposed by Sorower etal.
(2011) can be incorporated to explicitly han-dle missing information in text.
Lack of strict typ-ing on the arguments of relations in the IC ontol-ogy has also resulted in inferior performance of theMLNs.
To overcome this, relations that do not havestrictly defined types could be specialized.
Finally,we could use the deductive proofs constructed byBLPs to constrain the ground Markov network, sim-ilar to the model-construction approach adopted bySingla and Mooney (2011).However, in contrast to MLNs, BLPs that usefirst-order rules that are learned by an off-the-shelfILP system and given simple intuitive hand-codedweights, are able to provide fairly high-precision in-ferences that augment the output of an IE system andallow it to effectively ?read between the lines.
?7 Future WorkA primary goal for future research is developing anon-line structure learner for BLPs that can directlylearn probabilistic first-order rules from uncertaintraining data.
This will address important limita-tions of LIME, which cannot accept uncertainty inthe extractions used for training, is not specificallyoptimized for learning rules for BLPs, and does notscale well to large datasets.
Given the relatively poorperformance of BLP parameters learned using EM,tests on larger training corpora of extracted facts andthe development of improved parameter-learning al-gorithms are clearly indicated.
We also plan to per-form a larger-scale evaluation by employing crowd-sourcing to evaluate inferred facts for a bigger cor-pus of test documents.
As described above, a num-ber of methods could be used to improve the per-formance of MLNs on this task.
Finally, it wouldbe useful to evaluate our methods on several otherdiverse domains.8 ConclusionsWe have introduced a novel approach usingBayesian Logic Programs to learn to infer implicitinformation from facts extracted from natural lan-guage text.
We have demonstrated that it can learneffective rules from a large database of noisy extrac-tions.
Our experimental evaluation on the IC dataset demonstrates the advantage of BLPs over logicaldeduction and an approach based on MLNs.AcknowledgementsWe thank the SIRE team from IBM for providing SIREextractions on the IC data set.
This research was fundedby MURI ARO grant W911NF-08-1-0242 and Air ForceContract FA8750-09-C-0172 under the DARPA Ma-chine Reading Program.
Experiments were run on theMastodon Cluster, provided by NSF grant EIA-0303609.356ReferencesJonathan Berant, Ido Dagan, and Jacob Goldberger.2011.
Global learning of typed entailment rules.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies (ACl-HLT 2011), pages 610?619.A.
Carlson, J. Betteridge, B. Kisiel, B.
Settles, E.R.
Hr-uschka Jr., and T.M.
Mitchell.
2010.
Toward an ar-chitecture for never-ending language learning.
In Pro-ceedings of the Conference on Artificial Intelligence(AAAI), pages 1306?1313.
AAAI Press.Jim Cowie and Wendy Lehnert.
1996.
Information ex-traction.
CACM, 39(1):80?91.P.
Domingos and D. Lowd.
2009.
Markov Logic: AnInterface Layer for Artificial Intelligence.
Morgan &Claypool, San Rafael, CA.Janardhan Rao Doppa, Mohammad NasrEsfahani, Mo-hammad S. Sorower, Thomas G. Dietterich, XiaoliFern, and Prasad Tadepalli.
2010.
Towards learn-ing rules from natural texts.
In Proceedings of theNAACL HLT 2010 First International Workshop onFormalisms and Methodology for Learning by Read-ing (FAM-LbR 2010), pages 70?77, Stroudsburg, PA,USA.
Association for Computational Linguistics.Radu Florian, Hany Hassan, Abraham Ittycheriah,Hongyan Jing, Nanda Kambhatla, Xiaoqiang Luo,Nicolas Nicolov, and Salim Roukos.
2004.
A statisti-cal model for multilingual entity detection and track-ing.
In Proceedings of Human Language Technolo-gies: The Annual Conference of the North AmericanChapter of the Association for Computational Linguis-tics (NAACL-HLT 2004), pages 1?8.L.
Getoor and B. Taskar, editors.
2007.
Introductionto Statistical Relational Learning.
MIT Press, Cam-bridge, MA.Vibhav Gogate and Rina Dechter.
2007.
Samplesearch:A scheme that searches for consistent samples.
In Pro-ceedings of Eleventh International Conference on Ar-tificial Intelligence and Statistics (AISTATS-07).K.
Kersting and L. De Raedt.
2007.
Bayesian LogicProgramming: Theory and tool.
In L. Getoor andB.
Taskar, editors, Introduction to Statistical Rela-tional Learning.
MIT Press, Cambridge, MA.Kristian Kersting and Luc De Raedt.
2008.
Basic princi-ples of learning Bayesian Logic Programs.
Springer-Verlag, Berlin, Heidelberg.D.
Koller and N. Friedman.
2009.
Probabilistic Graphi-cal Models: Principles and Techniques.
MIT Press.Nada Lavrac?
and Saso Dz?eroski.
1994.
Inductive LogicProgramming: Techniques and Applications.
EllisHorwood.Deaking Lin and Patrick Pantel.
2001.
Discovery ofinference rules for question answering.
Natural Lan-guage Engineering, 7(4):343?360.Eric Mccreath and Arun Sharma.
1998.
Lime: A systemfor learning relations.
In Ninth International Work-shop on Algorithmic Learning Theory, pages 336?374.Springer-Verlag.Un Yong Nahm and Raymond J. Mooney.
2000.
A mu-tually beneficial integration of data mining and infor-mation extraction.
In Proceedings of the SeventeenthNational Conference on Artificial Intelligence (AAAI2000), pages 627?632, Austin, TX, July.Siegfried Nijssen and Joost N. Kok.
2003.
Efficient fre-quent query discovery in FARMER.
In Proceedingsof the Seventh Conference in Principles and Practicesof Knowledge Discovery in Database (PKDD 2003),pages 350?362.
Springer.Judea Pearl.
1988.
Probabilistic Reasoning in Intelli-gent Systems: Networks of Plausible Inference.
Mor-gan Kaufmann, San Mateo,CA.J.
Ross Quinlan.
1990.
Learning logical definitions fromrelations.
Machine Learning, 5(3):239?266.J.
R. Quinlan.
1993.
C4.5: Programs for MachineLearning.
Morgan Kaufmann, San Mateo,CA.Stuart Russell and Peter Norvig.
2003.
Artificial Intel-ligence: A Modern Approach.
Prentice Hall, UpperSaddle River, NJ, 2 edition.S.
Sarawagi.
2008.
Information extraction.
Foundationsand Trends in Databases, 1(3):261?377.Stefan Schoenmackers, Oren Etzioni, and Daniel S.Weld.
2008.
Scaling textual inference to the web.In Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing (EMNLP 2008),pages 79?88, Stroudsburg, PA, USA.
Association forComputational Linguistics.Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld,and Jesse Davis.
2010.
Learning first-order Hornclauses from web text.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP 2010), pages 1088?1098, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Parag Singla and Raymond Mooney.
2011.
AbductiveMarkov Logic for plan recognition.
In Twenty-fifthNational Conference on Artificial Intelligence.Mohammad S. Sorower, Thomas G. Dietterich, Janard-han Rao Doppa, Orr Walker, Prasad Tadepalli, and Xi-aoli Fern.
2011.
Inverting Grice?s maxims to learnrules from natural language extractions.
In Proceed-ings of Advances in Neural Information ProcessingSystems 24.A.
Srinivasan, 2001.
The Aleph manual.http://web.comlab.ox.ac.uk/oucl/research/areas/machlearn/Aleph/.Alexander Yates and Oren Etzioni.
2007.
Unsupervisedresolution of objects and relations on the web.
In Pro-357ceedings of Human Language Technologies: The An-nual Conference of the North American Chapter of theAssociation for Computational Linguistics (NAACL-HLT 2007).358
