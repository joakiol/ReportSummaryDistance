Proceedings of NAACL-HLT 2013, pages 158?167,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsRepresenting Topics Using ImagesNikolaos Aletras and Mark StevensonDepartment of Computer ScienceUniversity of SheffieldRegent Court, 211 PortobelloSheffield, S1 4DP, UK{n.aletras, m.stevenson}@dcs.shef.ac.ukAbstractTopics generated automatically, e.g.
usingLDA, are now widely used in ComputationalLinguistics.
Topics are normally representedas a set of keywords, often the n terms in atopic with the highest marginal probabilities.We introduce an alternative approach in whichtopics are represented using images.
Candi-date images for each topic are retrieved fromthe web by querying a search engine using thetop n terms.
The most suitable image is se-lected from this set using a graph-based al-gorithm which makes use of textual informa-tion from the metadata associated with eachimage and features extracted from the imagesthemselves.
We show that the proposed ap-proach significantly outperforms several base-lines and can provide images that are useful torepresent a topic.1 IntroductionTopic models are statistical methods for summaris-ing the content of a document collection using latentvariables known as topics (Hofmann, 1999; Blei etal., 2003).
Within a model, each topic is a multino-mial distribution over words in the collection whiledocuments are represented as distributions over top-ics.
Topic modelling is now widely used in NaturalLanguage Processing (NLP) and has been applied toa range of tasks including word sense disambigua-tion (Boyd-Graber et al 2007), multi-documentsummarisation (Haghighi and Vanderwende, 2009),information retrieval (Wei and Croft, 2006), imagelabelling (Feng and Lapata, 2010a) and visualisationof document collections (Chaney and Blei, 2012).Topics are often represented by using the n termswith the highest marginal probabilities in the topic togenerate a set of keywords.
For example, wine, bot-tle, grape, flavour, dry.
Interpreting such lists maynot be straightforward, particularly since there maybe no access to the source collection used to train themodel.
Therefore, researchers have recently begundeveloping automatic methods to generate meaning-ful and representative labels for topics.
These tech-niques have focussed on the creation of textual la-bels (Mei et al 2007; Lau et al 2010; Lau et al2011).An alternative approach is to represent a topic us-ing an illustrative image (or set of images).
Im-ages have the advantage that they can be under-stood quickly and are language independent.
This isparticularly important for applications in which thetopics are used to provide an overview of a collec-tion with many topics being shown simultaneously(Chaney and Blei, 2012; Gretarsson et al 2012;Hinneburg et al 2012).This paper explores the problem of selecting im-ages to illustrate automatically generated topics.Our approach generates a set of candidate images foreach topic by querying an image search engine withthe top n topic terms.
The most suitable image isselected using a graph-based method that makes useof both textual and visual information.
Textual in-formation is obtained from the metadata associatedwith each image while visual features are extractedfrom the images themselves.
Our approach is evalu-ated using a data set created for this study that wasannotated by crowdsourcing.
Results of the evalu-ation show that the proposed method significantly158outperforms three baselines.The contributions of this paper are as follows: (1)introduces the problem of labelling topics using im-ages; (2) describes an approach to this problem thatmakes use of multimodal information to select im-ages from a set of candidates; (3) introduces a dataset to evaluate image labelling; and (4) evaluates theproposed approach using this data set.2 Related workIn early research on topic modelling, labels weremanually assigned to topics for convenient presen-tation of research results (Mei and Zhai, 2005; Tehet al 2006).The first attempt at automatically assigning la-bels to topics is described by Mei et al(2007).In their approach, a set of candidate labels are ex-tracted from a reference collection using chunkingand statistically important bigrams.
Then, a rele-vance scoring function is defined which minimisesthe Kullback-Leibler divergence between word dis-tribution in a topic and word distribution in candi-date labels.
Candidate labels are ranked accordingto their relevance and the top ranked label chosen torepresent the topic.Magatti et al(2009) introduced an approachfor labelling topics that relied on two hierarchi-cal knowledge resources labelled by humans, theGoogle Directory and the OpenOffice English The-saurus.
A topics tree is a pre-existing hierarchi-cal structure of labelled topics.
The Automatic La-belling Of Topics algorithm computes the similaritybetween LDA inferred topics and topics in a topicstree by computing scores using six standard similar-ity measures.
The label for the most similar topic inthe topic tree is assigned to the LDA topic.Lau et al(2010) proposed selecting the most rep-resentative word from a topic as its label.
A la-bel is selected by computing the similarity betweeneach word and all the others in the topic.
Sev-eral sources of information are used to identify thebest label including Pointwise Mutual Informationscores, WordNet hypernymy relations and distribu-tional similarity.
These features are combined in areranking model to achieve results above a baseline(the most probable word in the topic).In more recent work, Lau et al(2011) proposeda method for automatically labelling topics by mak-ing use of Wikipedia article titles as candidate la-bels.
The candidate labels are ranked using infor-mation from word association measures, lexical fea-tures and an Information Retrieval technique.
Re-sults showed that this ranking method achieves bet-ter performance than a previous approach (Mei et al2007).Mao et al(2012) introduced a method for la-belling hierarchical topics which makes use of sib-ling and parent-child relations of topics.
Candidatelabels are generated using a similar approach to theone used by Mei et al(2007).
Each candidate la-bel is then assigned a score by creating a distribu-tion based on the words it contains and measuringthe Jensen-Shannon divergence between this and areference corpus.Hulpus et al(2013) make use of the structureddata in DBpedia1 to label topics.
Their approachmaps topic words to DBpedia concepts.
The bestconcepts are identified by applying graph central-ity measures which assume that words that co-occurring in text are likely to refer to concepts thatare close in the DBpedia graph.Our own work differs from the approaches de-scribed above since, to our knowledge, it is the firstto propose labelling topics with images rather thantext.Recent advances in computer vision has lead tothe development of reliable techniques for exploit-ing information available in images (Datta et al2008; Szeliski, 2010) and these have been combinedwith NLP (Feng and Lapata, 2010a; Feng and Lap-ata, 2010b; Agrawal et al 2011; Bruni et al 2011).The closest work to our own is the text illustrationtechniques which have been proposed for story pic-turing (Joshi et al 2006) and news articles illustra-tion (Feng and Lapata, 2010b).
The input to text il-lustration models is a textual document and a set ofimage candidates.
The goal of the models is to as-sociate the document with the correct image.
More-over, the problem of ranking images returned froma text query is related to, but different from, theone explored in our paper.
Those approaches usedqueries that were much smaller (e.g.
between oneand three words) and more focussed than the ones1http://dbpedia.org159we use (Jing and Baluja, 2008).
In our work, the in-put is a topic and the aim is to associate it with animage, or images, denoting the main thematic sub-ject.3 Labelling TopicsIn this section we propose an approach to identify-ing images to illustrate automatically generated top-ics.
It is assumed that there are no candidate imagesavailable so the first step (Section 3.1) is to generatea set of candidate images.
However, when a candi-date set is available the first step can be skipped.3.1 Selecting Candidate ImagesFor the experiments presented here we restrict our-selves to using images from Wikipedia available un-der the Creative Commons licence, since this allowsus to make the data available.
The top-5 terms froma topic are used to query Google using its CustomSearch API2.
The search is restricted to the EnglishWikipedia3 with image search enabled.
The top-20images retrieved for each search are used as candi-dates for the topic.3.2 Feature ExtractionCandidate images are represented by two modalities(textual and visual) and features extracted for each.3.2.1 Textual InformationEach image?s textual information consists of themetadata retrieved by the search.
The assumptionhere is that image?s metadata is indicative of the im-age?s content and (at least to some extent) related tothe topic.
The textual information is formed by con-catenating the title and the link fields of the searchresult.
These represent, respectively, the web pagetitle containing the image and the image file name.The textual information is preprocessed by tokeniz-ing and removing stop words.3.2.2 Visual InformationVisual information is extracted using low-levelimage keypoint descriptors, i.e.
SIFT features2https://developers.google.com/apis-explorer/#s/customsearch/v13http://en.wikipedia.org(Lowe, 1999; Lowe, 2004) sensitive to colour in-formation.
SIFT features denote ?interesting?
ar-eas in an image.
Image features are extracted us-ing dense sampling and described using Opponentcolour SIFT descriptors provided by the colorde-scriptor4 software.
Opponent colour SIFT descrip-tors have been found to give the best performancein object scene and face recognition (Sande et al2008).
The SIFT features are clustered to form a vi-sual codebook of 1,000 visual words using K-Meanssuch that each feature is mapped to a visual word.Each image is represented as a bag-of-visual words(BOVW).3.3 Ranking Candidate ImagesWe rank images in the candidates set using graph-based algorithms.
The graph is created by treatingimages as nodes and using similarity scores (textualor visual) between images to weight the edges.3.3.1 PageRankPageRank (Page et al 1999) is a graph-based al-gorithm for identifying important nodes in a graphthat was originally developed for assigning impor-tance to web pages.
It has been used for a rangeof NLP tasks including word sense disambiguation(Agirre and Soroa, 2009) and keyword extraction(Mihalcea and Tarau, 2004).Let G = (V,E) be a graph with a set of ver-tices, V , denoting image candidates and a set ofedges, E, denoting similarity scores between twoimages.
For example, sim(Vi, Vj) indicates the sim-ilarity between images Vi and Vj .
The PageRankscore (Pr) over G for an image (Vi) can be com-puted by the following equation:Pr(Vi) = d ?
?Vj?C(Vi)sim(Vi, Vj)?Vk?C(Vj)sim(Vj , Vk)Pr(Vj) + (1 ?
d)v(1)where C(Vi) denotes the set of vertices which areconnected to the vertex Vi.
d is the damping factorwhich is set to the default value of d = 0.85 (Page etal., 1999).
In standard PageRank all elements of thevector v are the same, 1N where N is the number ofnodes in the graph.4http://koen.me/research/colordescriptors1603.3.2 Personalised PageRankPersonalised PageRank (PPR) (Haveliwala et al2003) is a variant of the PageRank algorithm inwhich extra importance is assigned to certain ver-tices in the graph.
This is achieved by adjusting thevalues of the vector v in equation 1 to prefer certainnodes.
Nodes that are assigned high values in v aremore likely to also be assigned a high PPR score.We make use of PPR to prefer images with textualinformation that is similar to the terms in the topic.3.3.3 Weighting Graph EdgesThree approaches were compared for computingthe values of sim(Vi, Vj) in equation 1 used toweight the edges of the graph.
Two of these makeuse of the textual information associated with eachimage while the final one relies on visual features.The first approach is Pointwise Mutual Infor-mation (PMI).
The similarity between a pair ofimages (vertices in the graph) is computed as theaverage PMI between the terms in their metadata.PMI is computed using word co-occurrence countsover Wikipedia identified using a sliding window oflength 20.
We also experimented with other wordassociation measures but these did not perform aswell.
The PageRank over the graph weighted usingPMI is denoted as PRPMI.The second approach, Explicit Semantic Anal-ysis (ESA) (Gabrilovich and Markovitch, 2007), isa knowledge-based similarity measure.
ESA trans-forms the text from the image metadata into vectorsthat consist of Wikipedia article titles weighted bytheir relevance.
The similarity score between thesevectors is computed as the cosine of the angle be-tween them.
This similarity measure is used to cre-ate the graph and its PageRank is denoted as PRESA.The final approach uses the visual features ex-tracted from the images themselves.
The visualwords extracted from the images are used to formfeature vectors and the similarity between a pair ofimages computed as the cosine of the angle betweenthem.
The PageRank of the graph created using thisapproach is PRvis and it is similar to the approachproposed by Jing and Baluja (2008) for associatingimages to text queries.3.3.4 Initialising the Personalisation VectorThe personalisation vector (see above) isweighted using the similarity scores computed be-tween the topic and its image candidates.
Similarityis computed using PMI and ESA (see above).
WhenPMI and ESA are used to weight the personalisationvector they compute the similarity between thetop 10 terms for a topic and the textual metadataassociated with each image in the set of candidates.We refer to the personalisation vectors createdusing PMI and ESA as Per(PMI) and Per(ESA)respectively.Using PPR allows information about the simi-larity between the images?
metadata and the topicsthemselves to be considered when identifying a suit-able image label.
The situation is different whenPageRank is used since this only considers the sim-ilarity between the images in the candidate set.The personalisation vector used by PPR is em-ployed in combination with a graph created us-ing one of the approaches described above.
Forexample, the graph may be weighted using vi-sual features and the personalisation vector createdusing PMI scores.
This approach is denoted asPRvis+Per(PMI).4 EvaluationThis section discusses the experimental design forevaluating the proposed approaches to labelling top-ics with images.
To our knowledge no data set forevaluating these approaches is currently availableand consequently we developed one for this study5.Human judgements about the suitability of imagesare obtained through crowdsourcing.4.1 DataWe created a data set of topics from two collectionswhich cover a broad thematic range:?
NYT 47,229 New York Times news articles(included in the GigaWord corpus) that werepublished between May and December 2010.?
WIKI A set of Wikipedia categories randomlyselected by browsing its hierarchy in a breadth-first-search manner starting from a few seed5Data set can be downloaded from http://staffwww.dcs.shef.ac.uk/people/N.Aletras/resources.html.161police, officer, crime, street, man, city, gang, suspect, arrested, violencegame, season, team, patriot, bowl, nfl, quarterback, week, play, jetmilitary, afghanistan, force, official, afghan, defense, pentagon, american, war, gatesFigure 1: A sample of topics and their top-3 image candidates (i.e.
with the highest average human annota-tions).categories (e.g.
SPORTS, POLITICS, COMPUT-ING).
Categories that have more that 80 articlesassociated with them are considered.
Thesearticles are collected to produce a corpus ofapproximately 60,000 articles generated from1,461 categories.Documents in the two collections are tokenisedand stop words removed.
LDA was applied to learn200 topics from NYT and 400 topics from WIKI.The gensim package6 was used to implement andcompute LDA.
The hyperparameters (?, ?)
were setto 1num of topics .
Incoherent topics are filtered outby applying the method proposed by Aletras andStevenson (2013).We randomly selected 100 topics from NYT and200 topics from WIKI resulting in a data set of 300topics.
Candidate images for these topics were gen-erated using the approach described in Section 3.1,producing a total of 6,000 candidate images (20 for6http://pypi.python.org/pypi/gensimeach topic).4.2 Human Judgements of Image RelevanceHuman judgements of the suitability of each im-age were obtained using an online crowdsourcingplatform, Crowdflower7.
Annotators were providedwith a topic (represented as a set of 10 keywords)and a candidate image.
They were asked to judgehow appropriate the image was as a representationof the main subject of the topic and provide a ratingon a scale of 0 (completely unsuitable) to 3 (verysuitable).Quality control is important in crowdscourcingexperiments to ensure reliability (Kazai, 2011).
Toavoid random answers, control questions with obvi-ous answer were included in the survey.
Annotationsby participants that failed to answer these questionscorrectly or participants that gave the same rating forall pairs were removed.7http://crowdflower.com162The total number of filtered responses obtainedwas 62, 221 from 273 participants.
Each topic-image pair was rated at least by 10 subjects.
Theaverage response for each pair was calculated in or-der to create the final similarity judgement for use asa gold-standard.
The average variance across judges(excluding control questions) is 0.88.Inter-Annotator agreement (IAA) is computed asthe average Spearman?s ?
between the ratings givenby an annotator and the average ratings given by allother annotators.
The average IAA across all topicswas 0.50 which indicates the difficulty of the task,even for humans.Figure 1 shows three example topics from the dataset together with the images that received the highestaverage score from the annotators.4.3 Evaluation MetricsEvaluation of the topic labelling methods is carriedout using a similar approach to the framework pro-posed by Lau et al(2011) for labelling topics usingtextual labels.Top-1 average rating is the average human ratingassigned to the top-ranked label proposed by the sys-tem.
This provides an indication of the overall qual-ity of the image the system judges as the best one.The highest possible score averaged across all top-ics is 2.68, since for many topics the average scoreobtained from the human judgements is lower than3.The second evaluation measure is the normalizeddiscounted cumulative gain (nDCG) (Ja?rvelin andKeka?la?inen, 2002; Croft et al 2009) which com-pares the label ranking proposed by the system tothe optimal ranking provided by humans.
The dis-counted cumulative gain at position p (DCGp) iscomputed using the following equation:DCGp = rel1 +p?i=2relilog2(i)(2)where reli is the relevance of the label to the topicin position i.
Then nDCG is computed as:nDCGp =DCGpIDCGp(3)where IDCGp is the optimal ranking of the imagelabels, in our experiments this is the ranking pro-vided by the scores in the human annotated data set.We follow Lau et al(2011) in computing nDCG-1,nDCG-3 and nDCG-5 for the top 1, 3 and 5 rankedsystem image labels respectively.4.4 BaselinesSince there are no previous methods for labellingtopics using images, we compare our proposed mod-els against three baselines.The Random baseline randomly selects a labelfor the topic from the 20 image candidates.
The pro-cess is repeated 10,000 times and the average scoreof the selected labels is computed for each topic.The more informed Word Overlap baseline se-lects the image that is most similar to the topic termsby applying a Lesk-style algorithm (Lesk, 1986) tocompare metadata for each image against the topicterms.
It is defined as the number of common termsbetween a topic and image candidate normalised bythe total number of terms in the topic and image?smetadata.We also compared our approach with the rankingreturned by the Google Image Search for the top-20images for a specific topic.4.5 User StudyA user study was conducted to estimate human per-formance on the image selection task.
Three annota-tors were recruited and asked to select the best imagefor each of the 300 topics in the data set.
The anno-tators were provided with the topic (in the form of aset of keywords) and shown all candidate images forthat topic before being asked to select exactly one.The Average Top-1 Rating was computed for eachannotator and the mean of these values was 2.24.5 ResultsTable 1 presents the results obtained for each of themethods on the collection of 300 topics.
Results areshown for both Top-1 Average rating and nDCG.We begin by discussing the results obtained us-ing the standard PageRank algorithm applied tographs weighted using PMI, ESA and visual features(PRPMI, PRESA and PRvis respectively).
Results us-ing PMI consistently outperform all baselines andthose obtained using ESA.
This suggests that distri-butional word association measures are more suit-able for identifying useful images than knowledge-based similarity measures.
The best results using163Model Top-1 Av.
Rating nDCG-1 nDCG-3 nDCG-5BaselinesRandom 1.79 - - -Word Overlap 1.85 0.69 0.72 0.74Google Image Search 1.89 0.73 0.75 0.77PageRankPRPMI 1.87 0.70 0.73 0.75PRESA 1.81 0.67 0.68 0.70PRvis 1.96 0.73 0.75 0.76Personalised PageRankPRPMI+Per(PMI) 1.98 0.74 0.76 0.77PRPMI+Per(ESA) 1.92 0.70 0.72 0.74PRESA+Per(PMI) 1.91 0.70 0.72 0.73PRESA+Per(ESA) 1.88 0.69 0.72 0.74PRvis+Per(PMI) 2.00 0.74 0.75 0.76PRvis+Per(ESA) 1.94 0.72 0.75 0.76User Study 2.24 ?
?
?Table 1: Results for various approaches to topic labelling.standard PageRank are obtained when the visualsimilarity measures are used to weight the graph,with performance that significantly outperforms theword overlap baseline (paired t-test, p < 0.05).
Thisdemonstrates that visual features are a useful sourceof information for deciding which images are suit-able topic labels.The Personalised version of PageRank producesconsistently higher results compared to standardPageRank, demonstrating that the additional infor-mation provided by comparing the image metadatawith the topics is useful for this task.
The bestresults are obtained when the personalisation vec-tor is weighted using PMI (i.e.
Per(PMI)).
Thebest overall result for the top-1 average rating (2.00)is obtained when the graph is weighted using vi-sual features and the personalisation vector using thePMI scores (PRvis+Per(PMI)) while the best resultsfor the various DCG metrics are produced whenboth the graph and the personalisation vector areweighted using PMI scores (PRPMI+Per(PMI)).
Inaddition, these two methods, PRvis+Per(PMI) andPRPMI+Per(PMI), perform significantly better thanthe word overlap and the Google Image Search base-lines (p < 0.01 and p < 0.05 respectively).
Weight-ing the personalisation vector using ESA consis-tently produces lower performance compared toPMI.
These results indicate that graph-based meth-ods for ranking images are useful for illustrating top-ics.6 DiscussionFigure 2 shows a sample of three topics togetherwith the top-3 candidates (left-to-right) selected byapplying the PRvis+Per(PMI) approach.
Reasonablelabels have been selected for the first two topics.
Onthe other hand, the images selected for the third topicdo not seem to be as appropriate.We observed that inappropriate labels can be gen-erated for two reasons.
Firstly, the topic may be ab-stract and difficult to illustrate.
For example, one ofthe topics in our data set refers to the subject AL-GEBRAIC NUMBER THEORY and contains the termsnumber, ideal, group, field, theory, algebraic, class,ring, prime, theorem.
It is difficult to find a represen-tative image for topics such as this one.
Secondly,there are topics for which none of the candidate im-ages returned by the search engine is relevant.
Anexample of a topic like this in our data set is onethat refers to PLANTS and contains the terms family,sources, plants, familia, order, plant, species, taxon-omy, classification, genera.
The images returned bythe search engine include pictures of the Sagrada Fa-milia cathedral in Barcelona, a car called ?Familia?164dance, ballet, dancer, swan, company, dancing, nutcracker, balanchine, ballerina, choreographer2.3 2.7 2.5 2.8 2.8 2.73wine, bottle, grape, flavor, dry, vineyard, curtis, winery, sweet, champagne2.1 2.6 2.7 2.83 2.8 2.8haiti, haitian, earthquake, paterson, jean, prince, governor, au, cholera, country1.0 1.2 0.2 1.91 1.7 1.6Figure 2: A sample of topics and their top-3 images selected by applying the the PRvis+Per(PMI) approach(left side) and the ones with the highest average human annotations (right side).
The number under eachimage represents its average human annotations score.and pictures of families but no pictures of plants.7 ConclusionsThis paper explores the use of images to representautomatically generated topics.
An approach to se-lecting appropriate images was described.
This be-gins by identifying a set of candidate images us-ing a search engine and then attempts to select themost suitable.
Images are ranked using a graph-based method that makes use of both textual andvisual information.
Evaluation is carried out on adata set created for this study.
The results show thatthe visual features are a useful source of informationfor this task while the proposed graph-based methodsignificantly outperforms several baselines.This paper demonstrates that it is possible to iden-tify images to illustrate topics.
A possible applica-tion for this technique is to represent the contentsof large document collections in a way that supportsrapid interpretation and can be used to enable nav-igation (Chaney and Blei, 2012; Gretarsson et al2012; Hinneburg et al 2012).
We plan to explorethis possibility in future work.
Other possible exten-sions to this work include exploring alternative ap-proaches to generating candidate images and devel-oping techniques to automatically identify abstracttopics for which suitable images are unlikely to befound, thereby avoiding the problem cases describedin Section 6.AcknowledgmentsThe research leading to these results wascarried out as part of the PATHS project(http://paths-project.eu) funded bythe European Community?s Seventh FrameworkProgramme (FP7/2007-2013) under grant agree-ment no.
270082.165ReferencesEneko Agirre and Aitor Soroa.
2009.
PersonalizingPageRank for word sense disambiguation.
In Proceed-ings of the 12th Conference of the European Chap-ter of the Association for Computational Linguistics(EACL ?09), pages 33?41, Athens, Greece.Rakesh Agrawal, Sreenivas Gollapudi, Anitha Kannan,and Krishnaram Kenthapadi.
2011.
Enriching text-books with images.
In Proceedings of the 20th ACMInternational Conference on Information and Knowl-edge Management (CIKM ?11), pages 1847?1856,Glasgow, Scotland, UK.Nikolaos Aletras and Mark Stevenson.
2013.
Evaluat-ing topic coherence using distributional semantics.
InProceedings of the 10th International Conference onComputational Semantics (IWCS ?13) ?
Long Papers,pages 13?22, Potsdam, Germany.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet Allocation.
Journal of Ma-chine Learning Research, 3:993?1022.Jordan Boyd-Graber, David Blei, and Xiaojin Zhu.
2007.A topic model for word sense disambiguation.
In Pro-ceedings of the 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Compu-tational Natural Language Learning (EMNLP-CoNLL?07), pages 1024?1033, Prague, Czech Republic.Elia Bruni, Giang Binh Tran, and Marco Baroni.
2011.Distributional semantics from text and images.
In Pro-ceedings of the Workshop on GEometrical Models ofNatural Language Semantics (GEMS ?11), pages 22?32, Edinburgh, UK.Allison June-Barlow Chaney and David M. Blei.
2012.Visualizing topic models.
In Proceedings of the SixthInternational AAAI Conference on Weblogs and SocialMedia, Dublin, Ireland.Bruce W. Croft, Donald Metzler, and Trevor Strohman.2009.
Search engines: Information retrieval in prac-tice.
Addison-Wesley.Ritendra Datta, Dhiraj Joshi, Jia Li, and James Z. Wang.2008.
Image Retrieval: Ideas, Influences, and Trendsof the New Age.
ACM Computing Surveys, 40(2):1?60.Yansong Feng and Mirella Lapata.
2010a.
How manywords is a picture worth?
Automatic caption gener-ation for news images.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, pages 1239?1249, Uppsala, Sweden.Yansong Feng and Mirella Lapata.
2010b.
Topic Modelsfor Image Annotation and Text Illustration.
In Pro-ceedings of Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages831?839, Los Angeles, California.Evgeniy Gabrilovich and Shaul Markovitch.
2007.
Com-puting semantic relatedness using Wikipedia-basedexplicit semantic analysis.
In Proceedings of the In-ternational Joint Conference on Artificial Intelligence(IJCAI ?07), pages 1606?1611, Hyberabad, India.Brynjar Gretarsson, John O?Donovan, Svetlin Bostand-jiev, Tobias Ho?llerer, Arthur Asuncion, David New-man, and Padhraic Smyth.
2012.
TopicNets: Vi-sual analysis of large text corpora with topic modeling.ACM Trans.
Intell.
Syst.
Technol., 3(2):23:1?23:26.Aria Haghighi and Lucy Vanderwende.
2009.
Exploringcontent models for multi-document summarization.
InProceedings of Human Language Technologies: The2009 Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,pages 362?370, Boulder, Colorado.Taher Haveliwala, Sepandar Kamvar, and Glen Jeh.2003.
An analytical comparison of approaches topersonalizing PageRank.
Technical Report 2003-35,Stanford InfoLab.Alexander Hinneburg, Rico Preiss, and Rene?
Schro?der.2012.
TopicExplorer: Exploring document collec-tions with topic models.
In Peter A. Flach, Tijl Bie,and Nello Cristianini, editors, Machine Learning andKnowledge Discovery in Databases, volume 7524 ofLecture Notes in Computer Science, pages 838?841.Springer Berlin Heidelberg.Thomas Hofmann.
1999.
Probabilistic latent semanticindexing.
In Proceedings of the 22nd Annual Interna-tional ACM SIGIR Conference on Research and De-velopment in Information Retrieval (SIGIR ?99), pages50?57, Berkeley, California, United States.Ioana Hulpus, Conor Hayes, Marcel Karnstedt, andDerek Greene.
2013.
Unsupervised graph-based topiclabelling using DBpedia.
In Proceedings of the 6thACM International Conference on Web Search andData Mining (WSDM ?13), pages 465?474, Rome,Italy.Kalervo Ja?rvelin and Jaana Keka?la?inen.
2002.
Cumu-lated gain-based evaluation of IR techniques.
ACMTrans.
Inf.
Syst., 20(4):422?446.Yushi Jing and Shumeet Baluja.
2008.
PageRank forproduct image search.
In Proceedings of the 17th In-ternational Conference on World Wide Web (WWW?08), pages 307?316, Beijing, China.Dhiraj Joshi, James Z. Wang, and Jia Li.
2006.
The StoryPicturing Engine?A system for automatic text illus-tration.
ACM Trans.
Multimedia Comput.
Commun.Appl., 2(1):68?89.Gabriella Kazai.
2011.
In search of quality in crowd-sourcing for search engine evaluation.
Advances in In-formation Retrieval, pages 165?176.Jey Han Lau, David Newman, Sarvnaz Karimi, and Tim-othy Baldwin.
2010.
Best topic word selection for166topic labelling.
In The 23rd International Conferenceon Computational Linguistics (COLING ?10), pages605?613, Beijing, China.Jey Han Lau, Karl Grieser, David Newman, and TimothyBaldwin.
2011.
Automatic labelling of topic models.In Proceedings of the 49th Annual Meeting of the As-sociation for Computational Linguistics: Human Lan-guage Technologies, pages 1536?1545, Portland, Ore-gon, USA.Michael Lesk.
1986.
Automatic sense disambiguationusing machine readable dictionaries: How to tell a pinecone from an ice cream cone.
In Proceedings of the5th Annual International Conference on Systems Doc-umentation (SIGDOC ?86), pages 24?26, Toronto, On-tario, Canada.David G. Lowe.
1999.
Object Recognition from LocalScale-invariant Features.
In Proceedings of the Sev-enth IEEE International Conference on Computer Vi-sion, pages 1150?1157, Kerkyra, Greece.David G. Lowe.
2004.
Distinctive Image Features fromScale-Invariant Keypoints.
International Journal ofComputer Vision, 60(2):91?110.Davide Magatti, Silvia Calegari, Davide Ciucci, andFabio Stella.
2009.
Automatic Labeling of Topics.In Proceedings of the 9th International Conference onIntelligent Systems Design and Applications (ICSDA?09), pages 1227?1232, Pisa, Italy.Xian-Li Mao, Zhao-Yan Ming, Zheng-Jun Zha, Tat-SengChua, Hongfei Yan, and Xiaoming Li.
2012.
Auto-matic labeling hierarchical topics.
In Proceedings ofthe 21st ACM International Conference on Informa-tion and Knowledge Management (CIKM ?12), Shera-ton, Maui Hawai.Qiaozhu Mei and ChengXiang Zhai.
2005.
Discoveringevolutionary theme patterns from text: an explorationof temporal text mining.
In Proceedings of the 11thACM International Conference on Knowledge Discov-ery in Data Mining (SIGKDD ?05), pages 198?207,Chicago, Illinois, USA.Qiaozhu Mei, Xuehua Shen, and Cheng Xiang Zhai.2007.
Automatic Labeling of Multinomial Topic Mod-els.
In Proceedings of the 13th ACM InternationalConference on Knowledge Discovery and Data Mining(SIGKDD ?07), pages 490?499, San Jose, California.Rada Mihalcea and Paul Tarau.
2004.
TextRank:Bringing order into texts.
In Proceedings of Interna-tional Conference on Empirical Methods in NaturalLanguage Processing (EMNLP ?04), pages 404?411,Barcelona, Spain.Lawrence Page, Sergey Brin, Rajeev Motwani, and TerryWinograd.
1999.
The PageRank citation ranking:Bringing order to the web.
Technical Report 1999-66,Stanford InfoLab.Koen E.A.
Sande, Theo Gevers, and Cees G. M. Snoek.2008.
Evaluation of Color Descriptors for Object andScene Recognition.
In Proceedings of the IEEE Com-puter Society Conference on Computer Vision and Pat-tern Recognition (CVPR ?08), pages 1?8, Anchorage,Alaska, USA.Richard Szeliski.
2010.
Computer Vision: Algorithmsand Applications.
Springer-Verlag Inc.Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, andDavid M. Blei.
2006.
Hierarchical dirichlet pro-cesses.
Journal of the American Statistical Associa-tion, 101(476):1566?1581.Xing Wei and W. Bruce Croft.
2006.
LDA-based Doc-ument Models for Ad-hoc Retrieval.
In Proceedingsof the 29th annual international ACM SIGIR confer-ence on Research and Development in Information Re-trieval (SIGIR ?06), pages 178?185, Seattle, Washing-ton, USA.167
