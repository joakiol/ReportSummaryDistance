Maintaining Consistency and Plausibility in Integra,ted Natm-alLangu~ge Understanding' "  "" : ( 'amad~_,  Toyoaki Nishida, Xuemin Liu, c>hup Doshita,, and Atsuahi ~ :aDepartment ofhdbrmation ScienceKyoto UniversitySa,kyo-ku,  Kyoto  606, Japan.phone: 81.~.75,.751-2111 ext.
5396email: nishid~%doshit~Lkuis.kyoto-u.j,met %j apan@relay.cs.netAbst rac tIn this paper, we present an inference mecha-nism called the integrated parsing engine whichprovides a uniform abductive inference mech--anism for natu~al language understmlding.
Itcan (1) make phmsibh, assmnptiox~s, (2) rea~.son with mlfltiple alternatives, (3) switch thesearch process to the maximally plausible alter..,native, (4) detect contradiction attd tame COlt -~clutions which depend on inconsistent a,'~sump-tions, and (5) update plausibility factor of eachbefief based on new obsexvations.
We demon-strafe that a .natural anguage understandingsystem using the integrated parsing engine as asubsystem can pursue a guided search for mostt)lausible interpretation by making use of syn-tax, semantics, and contextual information.1 In t roduct ionNatural language understanding involves lots ofhard issues such as various types of ambiguities,indeterrtfinacies caused by ellipses or fragmentalutterances, or ill-formedness.
Being confrontedwith these difl\]culties, it does not seen, reason--able toseek for a method of logically deducingthe spe~ker's intexMed meaning or p\]an fromutterances.
Insteaxt, it is much more natural tocharacterize natural anguage understandhlg a~qan abductive process of exploring most plausbble interpretation which can ext)lain given ut-t el'a/Ices.In this paper, we present an abductive in-.ference mechanism, called the integrMcd pars-ing engine, for natural mlguage lmdcrst;mding.The integrated pea'sing engine is ~ble to:make plausible assunrptions at z,:pproprlatetimereason with multiple alternatives based o~ditferent sets of a~ss~m~ptionsswitch the sem'ch process to the maximallyplausible alternative, detect contradiction resulting from inco~vsistent ~sumpf ions and eliminate ~fil con-clutions which depends ,',m these assump~tions* update plausibility factor of each beliefbased on new observations.Thus, the integrated parsing engine is generMenough to carry out hngulstic and nonlingulso.tic inferences in a uniform manner, by drawinginformation from various sources: syntax, seomantle, discourse, pragmatics, or real world.In the remainder of this paper, we first de-~scribe mechanisms for maintaining consistencyand plausibility.
We then show how these twomechauisms interact o guide the inference pro..tess.
Finally, we use an implemented exam=ple to demonstrate how the integrated parsingengine is used to interpret sentences by takingcontextual factors into account.2 Ma inta in ing  Cons~si, e:c~cyThe CME (Consistency Maintenm~ce Engixtc)is a component of the httegrated pa:rsmg (mghte4B2re~;ponsib\]e fl)r maintaining consistency amongbeliefs.
Basic design principles of the CMEis b~L, md on de Kleer's ATMS (Assumption-bz~sed '\]!i'uth Maintenance Engine) \[de 86\].The CME maintains a set of alternative be-tlet~ eae~ of which consists of a set of as-~mp~ion~ m~d their conclusions, as follows:alter'na~,ive I {./ i l j~o?,,A!,rt~} Bl l~ .... ,B lm~alternative re (A,,i~.
?
.
,Aura,, } Bul~ ...~ Bunt,,en vlr o~tme~t couclu siousAn extc:c~fl problem solver is assumed to existwhich makeu a~sumpfion, adds conclusion, anddctcd;s contx~a~li(:tion?~\['he mv~n ~ask of CME is to maintain alterna-tive bc~i('2~ by removing all alternatives whose:;ct of a:~'~mmptions has turned out contradic-tory?
Lik(, ATMS, the CME takes advantage ofthe followi~,g monotonic property:if ~ contr~dictlo** is derived from a setof assumptions A, then contradictionis Mso derived from any set of assump-tions B such that B D A.E~={A,} E2={Au} E. ={A=}Ell El., E~I E~m.={AI,Au} ={A1, A,.,} ={A.,A.1) ={A~,A .... }Figure 1: The E-treeE1 :: {AI} E2 = {A2} E. = {A.
}P 11///// ~ / )  1 n I Pn~ ~Pu m .En El,,~ E.I E.,..= {AbAn} ={A1,A,.,} ={A.,A.I} = {A.,A.,..
}Figure 2: The E-tree with Conditional Proba-bilitiesThus, if contradiction is derived from a setof as.,mm~)tions { t~-~, D ), alternative in terpreta-tiol~s depending on sets of assumptions such as{B,C,D},  {A,B ,D},  \ [A ,B ,C ,D},  ... are re-moved.
\[n addition~ t, he GME keeps recordsof contradictory sets of assumptions to preventany interpretation depending on them from be-ing considered in future.Unlike ATMS whose control regime is bread-first, our CME uses a tree called the envh'on-ment tree, or the E-tree for short, to guide thesearch process.
Each node of the E-tree rep-resents an environment, a set of assumptions.\]i;alch arc of the E4ree represents that a lowernode is derived from the upper node by mak-ing one :more assumption.
Thus in figure 1, E0is the root node, and it represents an environ-mnet without any assumption.
Nodes below-5;0 :represent environments with one or moreassumption added to its parent node's envi-:r,~x~meaL Thus, El :: E0 U {A1} = {A,},~:_~1 := J\[!
;:, U (AH} =: (A I ,AH},  and so on.We assume that a set of assumptions made at~he same parent node axe mutually exclusive.Although this is a rather strong assumption,it, makes sense in ~tatural language tmderstand-ing :~ince many assmuptions being made dur-i~g the natural anguage mlderstanding processare mutuMly exclusive.
Even if this is not thec~se, any set of assumptions can be transformedinto a set of mutually exclusive assumptions byadding appropriate conditions.
Although this isa cumbersome solution, it does not often takeplace in natural language understanding andmost importantly it saves tile amottnt of com-putation.Note that the CME alone cannot determinewhich way to go when there is more than onepossibility of extending the set of beliefs.
Thisinformation is provided by the PME, as de-scribed in the next section.3 Maintaining PlausibilityThe PME (Plausibility Maintenance Engine)inaintains estimations of how plausible ach en-vironment is.
This information is given as con-ditional probabilities and it is kept as annota-tions to each arc of the F,-tree.
Thus, in figure 2,which is a slightly more precise version of fig-ure 1, Pl stands for P(EI), pq for P(EjIAi),pi./~ for P(Ek, IAi, Aj), etc.It follows from the property of conditionalprobability that= O,if i ~ j and El and Ej are immediate children4133(a) initial E-tree.
(b) The F~tree after -,E~ isobserved.~'0 E0Ex I);= E1 I-';2t> I i o "-...Ea E4 Es Ea 1/)4 EsFigure 3: A Sample E-tree with Annotationof the same parent.
Furthermore,if Ej is a parent node of Ei.Initial value of pi's are to be given from theexternal problem solver.
The PME's role is tomaintain estimation of prausibility by takinginto account given observations.
Currently weonly take -~E, the event of environment E run-ning into contradiction, as an observation.
Weuse a Bayes' law to modify P(A) into P(AI-E).Thus,P (~E i lE~ ) ?
P(E~)(1 -  P(EjlP~)).
P(E,).
(1 )1 -  P(Ej)if El and Ej are brothers, (1) is further simpli-fied to:P(E,)1-  P(Ej)" (2)For example, suppose it has turned out thatenvironment E4 is in contradiction and hence-E4 is observed (figure 3(a)).
The annotationsto the E-tree are updated as in figure 3(b).Notice that the update of conditional proba-bility can be done based on local information.Linl uistic and Nonlingaistic Pwblem Solve~I Working MemoryKnowledge BaseAssociative NetworksProblem Solving Engine Previmm Topic(PSi)The Integrated Parsing Engine \[ E-tn:e(CME) .~  E0,.~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
E 1Plauaibi|ity M~intenance Engine ~'~ E~Figure 4: The Structure of a, Natural Lan..guage Understanding System with the Inte-grated Parsing Engine as a subsystem4 Natural Language Un-derstanding System Usoing the Integrated Parslag Engine as a Subsyste rnThe integrated parsing engine consists of theCME and the PME.
The architecture of a natu-ral language understanding system with the in-tegrated parsing engine as a subsystem is shownin figure 4.The knowledge base contains various typesof information for language comprehension, i -cluding lexicon, morphology, syntax, semantics,discourse, pragmatics, commonsenses, and soon.
The whole system is controled by the prob-lem solving engine (PSE).
The PSE can accessto the knowledge base and use the integratedparsing engine as an aid to seek for most plau-sible interpretation.
Input texts are analyzed ina sentence-by-sentence manner.
The discoursestructure is maintained as a previous topic inthe working memory?When it scans a new sentence, the PSE tirs~initialize the F~tree with only the root node?Then the PSE repeats the following cycle:(step 1) choose a leaf node with the high-est probability as a working envirboment(step 2) repeatedly derive conclusions h'om4~34the  | ib rary  the  xerox  the  i rmet ingroo ln  rool~l l 'ool l l-.
I t //" \  I !keyI key2 hey3l~4x.
.
.
.
.
.
.
(* .
.
.
.
.
.
~ '  .
.....,.
o ?KA ?3I WO I(A S\]I I '1'i,~ KU DA SA \ ] '~k~ ' "  ../the) key <object> lend .
.
.
.
Id y .
.
.
.
.
": .
)the 1.
'ojessor: ~gure 5: o,mq~le Dialog Environmentbelieved p~'opositions unti l  either (a)the goal is achieved, (b) contra,diction is derived~ or (c) no moreconchlsion is derived ~mless makingmore assumption.In case (a), the process hMts.In case (b), the process is passed tothe PME~ which modifies current es-t imation of plausibility so that thisf,~:t is reflected, then nat alternativeof mex imum plausibil ity is dmsen~( l  is suggested to the CME.In case (c)~ the process also is passedto the PME,  which assigns plausibibity to new nodes, and working cnvi-ronment is chosen agMn.The integrated parsing engine has been writ-ten in Lisp.
It is running with a small exmerl-mental  grammar for Japanese.
The next sectionshows how it works.5 .A.n ExampleSuppose a dialog envh'omne~tt in which a pro..fesso~" speaks to a clerk to borrow a key ofsome rooms (figure 5) and utters the followingJ a \ ]pa~e~e ~extteltce:(3) KA GI WO KA SH ITE  KU DA SA I(~/the) key <object> lend could you .
.
.
?
"co,ad you le,,d (me) (a/,h,:) key.
"L/a .../"-,., ~./a{~word-1} {~.,~o~d-~, }Figure 6: I);~rec after assumptions @word-1and @word-2 are made'i'he referential meaning of this sentence isambiguous if there is more than one key in agiven situation.
Suppose three keys are there:key1 for a hbrary room, key2 for a xerox room,and key3 for a meeting room.Although sentence (3) is ambiguous in nor-real contexts, it becomes much lcss so if it fol-lows sentences like:(4) HO N WO KO PI I SHI TA I NO DE SU GA"I 'd like to xerox some books.
"Even if no previous sentence is spoken, sen-.fence (3) is acceptable in a situation where thespeaker and the hearer rmltually believe thatthe xerox room is accessed so often that "thekey" is usually uscd to refer to key& the onefor the xerox room.Note that the omission of the patient casedoes not matter  in usual situations, since thereis a strong defa~flt hat  the filler of this case isthe speaker.Now let us show how sentence (3) is ana-lyzed in a context where sentence (4) was pre-viously uttered.
The task of analyzing inputstarts from recognizing words.
Lots of ambi-guities arise in this phase.
For sentence (3),'KA' might be a single word 'KA' (postposi-tion marking interrogative) or a part of a longerword 'KAGI'  (key).
Since longer match is con-sidered to be more plausible in generM case inJapanese analysis, we assign larger number ofprobabil ity to the latter possibility.
Followingthis anMysis, the PSE makes the assumptionsto the integrated parsing engine:@toord-1 (t~ke the sequence ~KA t as a word):~-~ probability 1/3.
@word-2 (ta&e the sequence 'KAGI'  as a word):probability 2/3.Accordingly, 'the CME extends the initial E-treeas in figure 6.
Since, the enviromnent E1 hasthe highest plausibility, the CME chooses it forthe next environment and control is returned tothe PSE.4~3 5k , the libra W cy t ............ room ,,,,., .bookke~2 ........ I,ohg,le:y_~__ ~.
?eroxinghey3 .
.
.
.
.
.
.
the meet ing- -meet ing1"0 0I~1Figure 7: A.n Associative Network betweenConceptsNow the PSE tries to derive further conclu-sion in the chosen environment.
After havingi'ccognized that the pm't of speech of the word'KA(~I' i~ noun, the PSE tries to find out thereferent of the noun and reahzes that thi'ee am-bigtAties arise lit this situation.
Again, the PSEcalls the CME to make assumptions.
At thesame time, the PSE is called for to assign esti-mated conditional probabihties to each assump-tion?Currently, the system uses an associative net-work as shown in figure 7 to determine plausLbility.
Nodes of this network represent either aconcept or art instzatce, and arcs mean that thetwo concepts or instants at its both ends have acertain relation.
Those items which have denseconuections to previous ubjects are consideredto be plausible as a referent.
In our example,since the node xerox is marked as the previoussubject key2 is considered most plausible, whilekey1 is less plausible and key3 much less.
Thus,the following assumptions are made: 1@re fereni-1 (consider 'KAGI'  to refer to keyl):=~ probabiliy 1/3.
@referent-2 (consider 'KAGI '  to refer to key$):--~ probabiliy 1/2.
@re\[erenl-3 (consider 'KAGI'  to refer to key3):=ez probabiliy 1/6.In case no previous utterance is given, thePSE will consult information given as a priorimeasurements.The E-4ree now becomes as in figure 8, a~td{@word-2, @referent-2}, which is the most1 Currently we use a very simple a lgor i thm for assign-ing those value: when there are three alternatives, thedensest connection receives the vMue (1/3), the second(1/2),  and the third (1\]6), regardless of how closely theyare related to each other.
We plan to develop a muchmore precise method in a near future.E~1/3 ~ ~.~.
2/3{Qwo,.d-1} {~wor<l-2}{@word-2, {@word-2, {@word-?,,@referent- 1} @referenb2} @referenb3}Figure 8: E-.tree after assumptions about {,}L~:referent of 'KAGI' (key) are mademeaning-2 meaniag-3 meanings4,o,o,oot-,4 ,o,o,o,.-,AtO--=o--nt-=Xl*o=o==-;J .!
/ Inoun 1 .
t -  post-I verl> l" l 1 .
.
.
.
.d-4 1{-,o .
.
.
.
,_, A ooo,.=-=l \-o.o,=.=/Ich-I ch-2 ch-3 ch-4 ch-5 ?
'~ ch-lOI I I I I tKA GI WO KA Stl I  T\]~ I(U DA SAINotice that ~1l part of this netwm'k is not explored inactual processing.Figure 9: Dependency of Befiei~plausible nviromnent at tiffs point, is chosen asthe next environment.
The analysis is contin-ued this way until the semantic representationis obtained for the whole sentence.
The inter-pretation obtained tlds case is:event = asking-for \]actor = <the speaker>object = key2Figure 9 shows the dependency structtu'e of be-fiefs related to this analysis.Notice that the efficiency of the analysis issignificantly improved when strong expectationexists.
For example, although character 'sin' h~sentence (3) has many possible interpretationsin Japanese, the system is not annoyed by thoseambiguities, ince this part of the sentence justgoes as expected.
The system may come to sus-pect it only when most of its expectation faik.G{@word..,l\] {@word-2}{@word-2, {@word-2, {@word-2,Co)referent~ 1} (c~referent- 2 } @referent-3}addition~ the integrated paxsign engine providesa concise and high level mechatdsm for abduc~tire reasoning.
We have carefully chosen a setof reasonably high-level functions necessary forabductive reasoning.
This serves to much sim-plifying natur~ langu.age mtdersta~tding systemthan otherwise.li'ig,~re 10: Gtree after assumptions about theproposed interpretation based on {@word-2,@referent-.2} is rejectedNow suppose the above interpretation is re-jected for some ~'eason, say by expficitly negatedby the speaker.
Th.e~ the system will eventu-ally produce an alte~atative interpretation tak-ing key1 as a referent, by changing ammtationsto the E4ree as lit figm'e 10.6 Re la ted  WorkThis paper was inspired by a number of works.A massively par-Mlel parsing by Waltz andPol l~k \[WP85\] has demonstrated the etfectof integration through a uniform computa-tion me(hanism (marker passing) in context-dependent comprehension of discourse.
Theyhave pointed out the importance of non-logical,associative relation between concepts.
Char-niak has pointed out the abductive nature oflanguage comprehension.
Chat'niak's Wimp\[Cha86\] uses a marker passing mechanism asa basis of abductive inference engine for lan-guage comprehension.
But it is not used alone;it is augmented by a logical process called pathproof.
\ [na  parser used in Lytinen's MOP-.TITANS \[Lyt86\], a mechanism is provided toallow close interaction between syntax and se-mantics, while keeping the modularity of thesystem.
Another thing to note is that Lytinen'sintegrated parser makes use of strong semanticexpectation to constrain the search.The integrated parsing engine presented inthis paper takes advantages of these preced-ing works.
Unlike Waltz and Pollack, and likeCharniak and Lytinen, our integrated parsingengine has a hybrid architecture for logical atldnon-logical inferences.
What is novel with ore"integrated pat'sing engine is the method of inte-grating and maintaining logical and non-logical~nformafion Obtained from various sottrce.
In7 Conc lud ing  RemarksWe have presented an inference ngine for inte-grated natural language understanding, basedon a characterization of natural language un~dcrstanding as an abductive process.
Theessence of our approach is connecting con-sistency maintenance ngine and plausibilitymaintenance ngine closely enough to allowtheir dense interaction.
Although we haveshown rather "low level" issues, we believe thesame idea is applicable to "higher level" prob-lems such as inferring speaker's intention andplan.References\[Oha86\]\[de 86\]\[Lyt86\]\[WP85\]Eugine Charniak.
A neat theory ofmarker passing.
In Proceedings AAAL86, pages 584-588~ 1986.Johan de Kleer.
An assumption-basedtins.
Artificial Intelligence, 28:127--162, 1986.Steven Lytinen.
Dynamically combin-ing syntax and semantics in nabn'Mlanguage processing.
In ProceedingsAAAI-86, pages 574-578~ 1986.D.
Waltz and J.
B. Pollack.
Massivelyparallel parsing: a strongly interactivemodel of natural angqlage interpreta-tion.
Cognitive Science, 9:51-74, 1985.l~lV/
