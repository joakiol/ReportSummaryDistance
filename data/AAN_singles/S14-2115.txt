Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 647?651,Dublin, Ireland, August 23-24, 2014.Think Positive: Towards Twitter Sentiment Analysis from ScratchC?
?cero Nogueira dos SantosBrazilian Research LabIBM Researchcicerons@br.ibm.comAbstractIn this paper we describe a Deep Convo-lutional Neural Network (DNN) approachto perform two sentiment detection tasks:message polarity classification and con-textual polarity disambiguation.
We applythe proposed approach for the SemEval-2014 Task 9: Sentiment Analysis in Twit-ter.
Despite not using any handcraftedfeature or sentiment lexicons, our systemachieves very competitive results for Twit-ter data.1 IntroductionIn this work we apply a recently proposed deepconvolutional neural network (dos Santos andGatti, 2014) that exploits from character- tosentence-level information to perform sentimentanalysis of Twitter messages (tweets).
The net-work proposed by dos Santos and Gatti (2014),named Character to Sentence Convolutional Neu-ral Network (CharSCNN), uses two convolutionallayers to extract relevant features from words andmessages of any size.We evaluate CharSCNN in the unconstrainedtrack of the SemEval-2014 Task 9: SentimentAnalysis in Twitter (Rosenthal et al., 2014).
Twosubtasks are proposed in the SemEval-2014 Task9: the contextual polarity disambiguation (Sub-taskA), which consists in determining the polar-ity (positive, negative, or neutral) of a markedword or phrase in a given message; and themessage polarity classification (SubtaskB), whichconsists in classifying the polarity of the wholemessage.
We use the same neural network to per-form both tasks.
The only difference is that inThis work is licenced under a Creative Commons Attribution4.0 International License.
Page numbers and proceedingsfooter are added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/SubtaskA, CharSCNN is fed with a text segmentcomposed by the words in a context window cen-tered at the target word/phrase.
While in Sub-taskB, CharSCNN is fed with the whole message.The use of deep neural networks for sentimentanalysis has been the focus of recent research.However, instead of convolutional neural network,most investigation has been done in the use ofrecursive neural networks (Socher et al., 2011;Socher et al., 2012; Socher et al., 2013).2 Neural Network ArchitectureGiven a segment of text (e.g.
a tweet), CharSCNNcomputes a score for each sentiment label ?
?T = {positive, negative, neutral}.
In order toscore a text segment, the network takes as inputthe sequence of words in the segment, and passesit through a sequence of layers where features withincreasing levels of complexity are extracted.
Thenetwork extracts features from the character-levelup to the sentence-level.2.1 Initial Representation LevelsThe first layer of the network transforms wordsinto real-valued feature vectors (embeddings) thatcapture morphological, syntactic and semantic in-formation about the words.
We use a fixed-sized word vocabulary Vwrd, and we consider thatwords are composed of characters from a fixed-sized character vocabulary Vchr.
Given a sen-tence consisting ofN words {w1, w2, ..., wN}, ev-ery word wnis converted into a vector un=[rwrd; rwch], which is composed of two sub-vectors: the word-level embedding rwrd?
Rdwrdand the character-level embedding rwch?
Rcl0uof wn.
While word-level embeddings are meantto capture syntactic and semantic information,character-level embeddings capture morphologi-cal and shape information.6472.1.1 Word-Level EmbeddingsWord-level embeddings are encoded by col-umn vectors in an embedding matrix Wwrd?Rdwrd?|Vwrd|.
Each column Wwrdi?
Rdwrdcor-responds to the word-level embedding of the i-thword in the vocabulary.
We transform a word winto its word-level embedding rwrdby using thematrix-vector product:rwrd= Wwrdvw(1)where vwis a vector of size??Vwrd?
?which hasvalue 1 at index w and zero in all other positions.The matrix Wwrdis a parameter to be learned,and the size of the word-level embedding dwrdisa hyper-parameter to be chosen by the user.2.1.2 Character-Level EmbeddingsIn the task of sentiment analysis of Twitter data,important information can appear in different partsof a hash tag (e.g., ?#SoSad?, ?#ILikeIt?)
andmany informative adverbs end with the suffix?ly?
(e.g.
?beautifully?, ?perfectly?
and ?badly?
).Therefore, robust methods to extract morphologi-cal and shape information from this type of tokensmust take into consideration all characters of thetoken and select which features are more impor-tant for sentiment analysis.
Like in (dos Santosand Zadrozny, 2014), we tackle this problem us-ing a convolutional approach (Waibel et al., 1989),which works by producing local features aroundeach character of the word and then combiningthem using a max operation to create a fixed-sizedcharacter-level embedding of the word.Given a word w composed of M characters{c1, c2, ..., cM}, we first transform each charac-ter cminto a character embedding rchrm.
Characterembeddings are encoded by column vectors in theembedding matrix Wchr?
Rdchr?|Vchr|.
Given acharacter c, its embedding rchris obtained by thematrix-vector product:rchr= Wchrvc(2)where vcis a vector of size??Vchr?
?which has value1 at index c and zero in all other positions.
Theinput for the convolutional layer is the sequenceof character embeddings {rchr1, rchr2, ..., rchrM}.The convolutional layer applies a matrix-vector operation to each window of sizekchrof successive windows in the sequence{rchr1, rchr2, ..., rchrM}.
Let us define the vectorzm?
Rdchrkchras the concatenation of thecharacter embedding m, its (kchr?
1)/2 leftneighbors, and its (kchr?
1)/2 right neighbors:zm=(rchrm?
(kchr?1)/2, ..., rchrm+(kchr?1)/2)TThe convolutional layer computes the j-th elementof the vector rwch, which is the character-level em-bedding of w, as follows:[rwch]j= max1<m<M[W0zm+ b0]j(3)where W0?
Rcl0u?dchrkchris the weight matrixof the convolutional layer.
The same matrix isused to extract local features around each charac-ter window of the given word.
Using the max overall character windows of the word, we extract a?global?
fixed-sized feature vector for the word.Matrices Wchrand W0, and vector b0are pa-rameters to be learned.
The size of the char-acter vector dchr, the number of convolutionalunits cl0u(which corresponds to the size of thecharacter-level embedding of a word), and the sizeof the character context window kchrare hyper-parameters.2.2 Sentence-Level Representation andScoringGiven a text segment x with N words{w1, w2, ..., wN}, which have been converted tojoint word-level and character-level embedding{u1, u2, ..., uN}, the next step in CharSCNNconsists in extracting a segment-level represen-tation rsegx.
Methods to extract a segment-widefeature set most deal with two main problems:text segments have different sizes; and importantinformation can appear at any position in thesegment.
A convolutional approach is a goodoption to tackle this problems, and thereforewe use a convolutional layer to compute thesegment-wide feature vector rseg.
This secondconvolutional layer works in a very similar way tothe one used to extract character-level features forwords.
This layer produces local features aroundeach word in the text segment and then combinesthem using a max operation to create a fixed-sizedfeature vector for the segment.The second convolutional layer applies amatrix-vector operation to each window of sizekwrdof successive windows in the sequence{u1, u2, ..., uN}.
Let us define the vector zn?R(dwrd+cl0u)kwrdas the concatenation of a se-648quence of kwrdembeddings, centralized in the n-th word1:zn=(un?
(kwrd?1)/2, ..., un+(kwrd?1)/2)TThe convolutional layer computes the j-th elementof the vector rsegas follows:[rseg]j= max1<n<N[W1zn+ b1]j(4)where W1?
Rcl1u?
(dwrd+cl0u)kwrdis the weightmatrix of the convolutional layer.
The same ma-trix is used to extract local features around eachword window of the given segment.
Using the maxover all word windows of the segment, we extracta ?global?
fixed-sized feature vector for the seg-ment.
Matrix W1and vector b1are parametersto be learned.
The number of convolutional unitscl1u(which corresponds to the size of the segment-level feature vector), and the size of the word con-text window kwrdare hyper-parameters to be cho-sen by the user.Finally, the vector rsegx, the ?global?
feature vec-tor of text segment x, is processed by two usualneural network layers, which extract one morelevel of representation and compute a score foreach sentiment label ?
?
T :s(x) = W3h(W2rsegx+ b2) + b3(5)where matrices W2?
Rhlu?cl1uand W3?R|T |?hlu, and vectors b2?
Rhluand b3?
R|T |are parameters to be learned.
The transfer func-tion h(.)
is the hyperbolic tangent.
The size of thenumber of hidden units hluis a hyper-parameterto be chosen by the user.2.3 Network TrainingOur network is trained by minimizing a nega-tive likelihood over the training set D. Given atext segment x, the network with parameter set ?computes a score s?
(x)?for each sentiment label?
?
T .
In order to transform this score into a con-ditional probability p (?
|x, ?)
of the label given thesegment and the set of network parameters ?, weapply a softmax operation over all tags:p (?
|x, ?)
=es?(x)??ies?
(x)i(6)1We use a special padding token for the words with in-dices outside of the text segment boundaries.Taking the log, we arrive at the following con-ditional log-probability:log p (?
|x, ?)
= s?(x)??log(??i?Tes?
(x)i)(7)We use stochastic gradient descent (SGD) tominimize the negative log-likelihood with respectto ?:?
7??
(x,y)?D?log p(y|x, ?)
(8)where (x, y) corresponds to a text segment (e.g.
atweet) in the training corpus D and y represents itsrespective sentiment class label.We use the backpropagation algorithm to com-pute the gradients of the network (Lecun et al.,1998; Collobert, 2011).
We implement theCharSCNN architecture using the automatic dif-ferentiation capabilities of the Theano library(Bergstra et al., 2010).3 Experimental Setup and Results3.1 Unsupervised Learning of Word-LevelEmbeddingsUnsupervised pre-training of word embeddingshas shown to be an effective approach to improvemodel accuracy (Collobert et al., 2011; Luong etal., 2013; Zheng et al., 2013).
In our experiments,we perform unsupervised learning of word-levelembeddings using the word2vec tool2.We use two Twitter datasets as sources of un-labeled data: the Stanford Twitter Sentiment cor-pus (Go et al., 2009), which contains 1.6 mil-lion tweets; and a dataset containing 10.4 mil-lion tweets that were collected in October 2012for a previous work by the author (Gatti et al.,2013).
We tokenize these corpora using Gimpel etal.
?s (2011) tokenizer, and removed messages thatare less than 5 characters long (including whitespaces) or have less than 3 tokens.
Like in (Col-lobert et al., 2011) and (Luong et al., 2013), welowercase all words and substitute each numericaldigit by a 0 (e.g., 1967 becomes 0000).
The re-sulting corpus contains about 12 million tweets.We do not perform unsupervised learning ofcharacter-level embeddings, which are initial-ized by randomly sampling each value from anuniform distribution: U (?r, r), where r =?6|Vchr| + dchr.
The character vocabulary is2https://code.google.com/p/word2vec/649constructed by the (not lowercased) words in thetraining set, which allows the neural network tocapture relevant information about capitalization.3.2 Sentiment Corpora and Model SetupSemEval-2014 Task 9 is a rerun of the SemEval-2013 Task 2 (Nakov et al., 2013), hence the train-ing set used in 2014 is the same of the 2013 task.However, as we downloaded the Twitter trainingand development sets in 2014 only, we were notable to download the complete dataset since sometweets have been deleted by their respective cre-ators.
In Table 1, we show the number of messagesin our SemEval-2013 Task 2 datasets.Dataset SubtaskA SubtaskBTrain 7390 8213Dev.
904 1415Twitter2013 (test) 3491 3265SMS2013 (test) 2,334 2,093Table 1: Number of tweets in our version ofSemEval-2013 Task2 datasets.In SemEval-2014 Task 9, three different testsets are used: Twitter2014, Twitter2014Sarcarmand LiveJournal2014.
While the two first containTwitter messages, the last one contains sentencesfrom LiveJournal blogs.
In Table 2, we show thenumber of messages in the SemEval-2014 Task 9test datasets.Test Dataset SubtaskA SubtaskBTwitter2014 2597 1939Twitter2014Sarcasm 124 86LiveJournal2014 1315 1142Table 2: Number of tweets in the SemEval-2014Task9 test datasets.We use the copora Twitter2013 (test) andSMS2013 to tune CharSCNN?s hyper-parametervalues.
In Table 3, we show the selected hyper-parameter values, which are the same for bothSubtaskA and SubtaskB.
We concatenate theSemEval-2013 Task 2 training and developmentsets to train the submitted model.3.3 Sentiment Prediction ResultsIn Table 4, we present the official results of oursubmission to the SemEval-2014 Task9.
In Sub-taskB, CharSCNN?s result for the Twitter2014 testcorpus is the top 11 out of 50 submissions, and isParameter Parameter Name ValuedwrdWord-Level Emb.
dim.
100kwrdWord Context window 3dchrChar.
Emb.
dim.
5kchrChar.
Context window 5cl0uChar.
Convol.
Units 30cl1uWord Convol.
Units 100hluHidden Units 300?
Learning Rate 0.02Table 3: Neural Network Hyper-Parameters.3.9 F-measure points from the top performing sys-tem.
In the SubtaskA, CharSCNN?s result for theTwitter2014 test corpus is the top 6 out of 27 sub-missions.
These are very promising results, sinceour approach do not use any handcrafted featuresor lexicons, all features (representations) are auto-matically learned from unlabeled and labeled data.Nevertheless, our system result for the Live-Journal2014 corpus in SubtaskB is regular.
Forthis dataset CharSCNN achieves only the top 25out of 50 submissions, and is 7.9 F-measure pointsbehind the top performing system.
We believe themain reason for this poor result is the exclusive useof Twitter data in the unsupervised pre-training.Test Subset SubtaskA SubtaskBTwitter2014 82.05 67.04Twitter2014Sarcasm 76.74 47.85LiveJournal2014 80.90 66.96Twitter2013 88.06 68.15SMS2013 87.65 63.20Table 4: Average F-measure of CharSCNN for dif-ferent test sets.4 ConclusionsIn this work we describe a sentiment analysissystem based on a deep neural network architec-ture that analyses text at multiple levels, fromcharacter-level to sentence-level.
We apply theproposed system to the SemEval-2014 Task 9 andachieve very competitive results for Twitter data inboth contextual polarity disambiguation and mes-sage polarity classification subtasks.
As a futurework, we would like to investigate the impact ofthe system performance for the LiveJournal2014corpus when the unsupervised pre-training is per-formed using in-domain texts.650ReferencesJames Bergstra, Olivier Breuleux, Fr?ed?eric Bastien,Pascal Lamblin, Razvan Pascanu, Guillaume Des-jardins, Joseph Turian, David Warde-Farley, andYoshua Bengio.
2010.
Theano: a CPU andGPU math expression compiler.
In Proceedingsof the Python for Scientific Computing Conference(SciPy).Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) fromscratch.
Journal of Machine Learning Research,12:2493?2537.Ronan Collobert.
2011.
Deep learning for efficientdiscriminative parsing.
In Proceedings of the Four-teenth International Conference on Artificial Intelli-gence and Statistics (AISTATS), pages 224?232.C?
?cero Nogueira dos Santos and Ma?
?ra Gatti.
2014.Deep convolutional neural networks for sentimentanalysis of short texts.
In Proceedings of the 25th In-ternational Conference on Computational Linguis-tics (COLING), Dublin, Ireland.C?
?cero Nogueira dos Santos and Bianca Zadrozny.2014.
Learning character-level representations forpart-of-speech tagging.
In Proceedings of the31st International Conference on Machine Learning(ICML), JMLR: W&CP volume 32, Beijing, China.Ma?
?ra Gatti, Ana Paula Appel, C?
?cero Nogueira dosSantos, Claudio Santos Pinhanez, Paulo RodrigoCavalin, and Samuel Martins Barbosa Neto.
2013.A simulation-based approach to analyze the infor-mation diffusion in microblogging online social net-work.
In Winter Simulation Conference, pages1685?1696.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: Annotation, features, and experiments.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies: Short Papers - Volume 2,pages 42?47.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.Technical report, Stanford University.Yann Lecun, Lon Bottou, Yoshua Bengio, and PatrickHaffner.
1998.
Gradient-based learning applied todocument recognition.
In Proceedings of the IEEE,pages 2278?2324.Minh-Thang Luong, Richard Socher, and Christo-pher D. Manning.
2013.
Better word representa-tions with recursive neural networks for morphol-ogy.
In Proceedings of the Conference on Computa-tional Natural Language Learning, Sofia, Bulgaria.Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,Veselin Stoyanov, Alan Ritter, and Theresa Wilson.2013.
Semeval-2013 task 2: Sentiment analysis intwitter.
In Second Joint Conference on Lexical andComputational Semantics (*SEM), Volume 2: Pro-ceedings of the Seventh International Workshop onSemantic Evaluation (SemEval 2013), pages 312?320, Atlanta, Georgia, USA, June.
Association forComputational Linguistics.Sara Rosenthal, Preslav Nakov, Alan Ritter, andVeselin Stoyanov.
2014.
SemEval-2014 Task 9:Sentiment Analysis in Twitter.
In Preslav Nakov andTorsten Zesch, editors, Proceedings of the 8th In-ternational Workshop on Semantic Evaluation, Se-mEval?14, Dublin, Ireland.Richard Socher, Jeffrey Pennington, Eric H. Huang,Andrew Y. Ng, and Christopher D. Manning.
2011.Semi-supervised recursive autoencoders for predict-ing sentiment distributions.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 151?161.Richard Socher, Brody Huval, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Semantic composi-tionality through recursive matrix-vector spaces.
InProceedings of theConference on Empirical Meth-ods in Natural Language Processing, pages 1201?1211.Richard Socher, Alex Perelygin, Jean Wu, JasonChuang, Christopher D. Manning, Andrew Y. Ng,and Christopher Potts.
2013.
Recursive deep mod-els for semantic compositionality over a sentimenttreebank.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,pages 1631?1642.Alexander Waibel, Toshiyuki Hanazawa, GeoffreyHinton, Kiyohiro Shikano, and Kevin J. Lang.
1989.Phoneme recognition using time-delay neural net-works.
IEEE Transactions on Acoustics, Speech andSignal Processing, 37(3):328?339.Xiaoqing Zheng, Hanyang Chen, and Tianyu Xu.2013.
Deep learning for chinese word segmentationand pos tagging.
In Proceedings of the Conferenceon Empirical Methods in NLP, pages 647?657.651
