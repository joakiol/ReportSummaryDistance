Proceedings of the NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing, pages 10?17,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsActive Semi-Supervised Learning for Improving Word AlignmentVamshi Ambati, Stephan Vogel and Jaime Carbonell{vamshi,vogel,jgc}@cs.cmu.eduLanguage Technologies Institute, Carnegie Mellon University5000 Forbes Avenue, Pittsburgh, PA 15213, USAAbstractWord alignment models form an importantpart of building statistical machine transla-tion systems.
Semi-supervised word align-ment aims to improve the accuracy of auto-matic word alignment by incorporating fullor partial alignments acquired from humans.Such dedicated elicitation effort is often ex-pensive and depends on availability of bilin-gual speakers for the language-pair.
In thispaper we study active learning query strate-gies to carefully identify highly uncertain ormost informative alignment links that are pro-posed under an unsupervised word alignmentmodel.
Manual correction of such informativelinks can then be applied to create a labeleddataset used by a semi-supervised word align-ment model.
Our experiments show that usingactive learning leads to maximal reduction ofalignment error rates with reduced human ef-fort.1 IntroductionThe success of statistical approaches to MachineTranslation (MT) can be attributed to the IBM mod-els (Brown et al, 1993) that characterize word-level alignments in parallel corpora.
Parameters ofthese alignment models are learnt in an unsupervisedmanner using the EM algorithm over sentence-levelaligned parallel corpora.
While the ease of auto-matically aligning sentences at the word-level withtools like GIZA++ (Och and Ney, 2003) has enabledfast development of statistical machine translation(SMT) systems for various language pairs, the qual-ity of alignment is typically quite low for languagepairs that diverge from the independence assump-tions made by the generative models.
Also, an im-mense amount of parallel data enables better estima-tion of the model parameters, but a large number oflanguage pairs still lack parallel data.Two directions of research have been pursued forimproving generative word alignment.
The first is torelax or update the independence assumptions basedon more information, usually syntactic, from thelanguage pairs (Cherry and Lin, 2006).
The sec-ond is to use extra annotation, typically word-levelhuman alignment for some sentence pairs, in con-junction with the parallel data to learn alignment ina semi-supervised manner.
Our research is in thedirection of the latter, and aims to reduce the effortinvolved in hand-generation of word alignments byusing active learning strategies for careful selectionof word pairs to seek alignment.Active learning for MT has not yet been exploredto its full potential.
Much of the literature has ex-plored one task ?
selecting sentences to translateand add to the training corpus (Haffari et al, 2009).In this paper we explore active learning for wordalignment, where the input to the active learner isa sentence pair (sJ1 , tI1), present in two different lan-guages S = {s?}
and T = {t?
}, and the annotationelicited from human is a set of links {(j, i) : j =0 ?
?
?
J ; i = 0 ?
?
?
I}.
Unlike previous approaches,our work does not require elicitation of full align-ment for the sentence pair, which could be effort-intensive.
We use standard active learning querystrategies to selectively elicit partial alignment infor-mation.
This partial alignment information is thenfed into a semi-supervised word aligner which per-10forms an improved word alignment over the entireparallel corpus.Rest of the paper is organized as follows.
Wepresent related work in Section 2.
Section 3 givesan overview of unsupervised word alignment mod-els and its semi-supervised improvisation.
Section 4details our active learning framework with discus-sion of the link selection strategies in Section 5.
Ex-periments in Section 6 have shown that our selectionstrategies reduce alignment error rates significantlyover baseline.
We conclude with discussion on fu-ture work.2 Related WorkSemi-supervised learning is a broader area of Ma-chine Learning, focusing on improving the learn-ing process by usage of unlabeled data in conjunc-tion with labeled data (Chapelle et al, 2006).
Manysemi-supervised learning algorithms use co-trainingframework, which assumes that the dataset has mul-tiple views, and training different classifiers on anon-overlapping subset of these features providesadditional labeled data (Zhu, 2005).
Active queryselection for training a semi-supervised learning al-gorithm is an interesting method that has been ap-plied to clustering problems.
Tomanek and Hahn(2009) applied active semi supervised learning tothe sequence-labeling problem.
Tur et al (2005) de-scribe active and semi-supervised learning methodsfor reducing labeling effort for spoken language un-derstanding.
They train supervised classification al-gorithms for the task of call classification and applyit to a large unlabeled dataset to select the least con-fident instances for human labeling.Researchers have begun to explore semi-supervised word alignment models that use bothlabeled and unlabeled data.
Fraser and Marcu(2006) pose the problem of alignment as a searchproblem in log-linear space with features comingfrom the IBM alignment models.
The log-linearmodel is trained on the available labeled datato improve performance.
They propose a semi-supervised training algorithm which alternatesbetween discriminative error training on the la-beled data to learn the weighting parameters andmaximum-likelihood EM training on unlabeleddata to estimate the parameters.
Callison-Burch etal.
(2004) also improve alignment by interpolatinghuman alignments with automatic alignments.
Theyobserve that while working with such datasets,alignments of higher quality should be given a muchhigher weight than the lower-quality alignments.Wu et al (2006) learn separate models from labeledand unlabeled data using the standard EM algo-rithm.
The two models are then interpolated as alearner in the semi-supervised AdaBoost algorithmto improve word alignment.Active learning has been applied to various fieldsof Natural Language Processing like statistical pars-ing, entity recognition among others (Hwa, 2004;Tang et al, 2001; Shen et al, 2004).
In case ofMT, the potential of active learning has remainedlargely unexplored.
For Statistical Machine Transla-tion, application of active learning has been focusedon the task of selecting the most informative sen-tences to train the model, in order to reduce costof data acquisition.
Recent work in this area dis-cussed multiple query selection strategies for a Sta-tistical Phrase Based Translation system (Haffari etal., 2009).
Their framework requires source text tobe translated by the system and the translated datais used in a self-training setting to train MT models.To our knowledge, we are not aware of any workthat has looked at reducing human effort by selec-tive elicitation of alignment information using activelearning techniques.3 Word Alignment3.1 IBM modelsIBM models provide a generative framework forperforming word alignment of parallel corpus.Given two strings from source and target languagessJ1 = s1, ?
?
?
, sj , ?
?
?
sJ and tI1 = t1, ?
?
?
, ti, ?
?
?
tI ,an alignment A is defined as a subset of the Carte-sian product of the word indices as shown in Eq 1.In IBM models, since alignment is treated as a func-tion, all the source positions must be covered exactlyonce (Brown et al, 1993).A ?
{(j, i) : j = 0 ?
?
?
J ; i = 0 ?
?
?
I} (1)For the task of translation, we would ideally wantto model P (sI1|tJ1 ), which is the probability of ob-serving source sentence sI1 given target sentence tJ1 .This requires a lot of parallel corpus for estimation11and so it is then factored over the word alignmentA for the sentence pair, which is a hidden variable.Word alignment is therefore a by-product in the pro-cess of modeling translation.
We can also representthe same under some parameterization of ?, whichis the model we are interested to estimate.P (sJ1 |tI1) =?aJ1Pr(sJ1 , A|tJ1 ) (2)=?Ap?
(sJ1 , A|tI1) (3)Given a parallel corpus U of sentence pairs{(sk, tk) : k = 1, ?
?
?
,K} the parameters can beestimated by maximizing the conditional likelihoodover the data.
IBM models (Brown et al, 1993) from1 to 5 are different ways of factoring the probabilitymodel to estimate the parameter set ?.
For examplein the simplest of the models, IBM model 1, only thelexical translation probability is considered treatingeach word being translated independent of the otherwords.??
= argmax?K?k=1?Ap?
(sk, A|tk) (4)The parameters of the model above are estimatedas ?
?, using the EM algorithm.
We can also extractthe Viterbi alignment ,A?, for all the sentence pairs,which is the alignment with the highest probabilityunder the current model parameters ?:A?
= argmaxAp??
(sJ1 , A|tI1) (5)The alignment models are asymmetric and dif-fer with the choice of translation direction.
We cantherefore perform the above after switching the di-rection of the language pair and obtain models andViterbi alignments for the corpus as represented be-low:??
= argmax?K?k=1?ap?
(tk, a|sk) (6)A?
= argmaxAp??
(tI1, A|sJ1 ) (7)Given the Viterbi alignment for each sentencepair in the parallel corpus, we can also compute theword-level alignment probabilities using simple rel-ative likelihood estimation for both the directions.As we will discuss in Section 5, the alignments andthe computed lexicons form an important part of ourlink selection strategies.P (sj/ti) =?s count(ti, sj ; A?
)?s count(ti)(8)P (ti/sj) =?s count(ti, sj ; A?
)?s count(sj)(9)We perform all our experiments on a symmetrizedalignment that combines the bidirectional align-ments using heuristics as discussed in (Koehn et al,2007).
We represent this alignment as A = {aij :i = 0 ?
?
?
J ?
sJ1 ; j = 0 ?
?
?
I ?
tI1}.3.2 Semi-Supervised Word AlignmentWe use an extended version of MGIZA++ (Gaoand Vogel, 2008) to perform the constrained semi-supervised word alignment.
To get full benefitfrom the manual alignments, MGIZA++ modifies allalignment models used in the standard training pro-cedure, i.e.
the IBM1, HMM, IBM3 and IBM4 mod-els.
Manual alignments are incorporated in the EMtraining phase of these models as constraints thatrestrict the summation over all possible alignmentpaths.
Typically in the EM procedure for IBM mod-els, the training procedure requires for each sourcesentence position, the summation over all positionsin the target sentence.
The manual alignments al-low for one-to-many alignments and many-to-manyalignments in both directions.
For each position iin the source sentence, there can be more than onemanually aligned target word.
The restricted train-ing will allow only those paths, which are consistentwith the manual alignments.
Therefore, the restric-tion of the alignment paths reduces to restricting thesummation in EM.4 Active Learning for Word AlignmentActive learning attempts to optimize performanceby selecting the most informative instances to la-bel, where ?informativeness?
is defined as maximalexpected improvement in accuracy.
The objectiveis to select optimal instance for an external expertto label and then run the learning method on thenewly-labeled and previously-labeled instances tominimize prediction or translation error, repeatinguntil either the maximal number of external queries12is reached or a desired accuracy level is achieved.Several studies (Tong and Koller, 2002; Nguyenand Smeulders, 2004; Donmez and Carbonell, 2008)show that active learning greatly helps to reduce thelabeling effort in various classification tasks.We discuss our active learning setup for wordalignment in Algorithm 1.
We start with an un-labeled dataset U = {(Sk, Tk)}, indexed by k,and a seed pool of partial alignment links A0 ={akij , ?si ?
Sk, tj ?
Tk}.
Each akij represents analignment link from a sentence pair k that connectssource word si with tj .This is usually an empty set at iteration t = 0.
Weiterate for T iterations.
We take a pool-based activelearning strategy, where we have access to all the au-tomatically aligned links and we can score the linksbased on our active learning query strategy.
Thequery strategy uses the automatically trained align-ment model ?t from the current iteration t, for scor-ing the links.
Re-training and re-tuning an SMT sys-tem for each link at a time is computationally infea-sible.
We therefore perform batch learning by se-lecting a set of N links scored high by our querystrategy.
We seek manual corrections for the se-lected links and add the alignment data to the cur-rent labeled dataset.
The word-level aligned labeleddataset is then provided to our semi-supervised wordalignment algorithm, which uses it to produces thealignment model ?t+1 for U .Algorithm 1 AL FOR WORD ALIGNMENT1: Unlabeled Data Set: U = {(sk, tk)}2: Manual Alignment Set : A0 = {akij ,?si ?Sk, tj ?
Tk}3: Train Semi-supervised Word Alignment using(U , A0)?
?04: N : batch size5: for t = 0 to T do6: Lt = LinkSelection(U ,At,?t,N )7: Request Human Alignment for Lt8: At+1 = At + Lt9: Re-train Semi-Supervised Word Align-ment on (U,At+1)?
?t+110: end forWe can iteratively perform the algorithm for a de-fined number of iterations T or until a certain desiredperformance is reached, which is measured by align-ment error rate (AER) (Fraser and Marcu, 2007) inthe case of word alignment.
In a more typical sce-nario, since reducing human effort or cost of elici-tation is the objective, we iterate until the availablebudget is exhausted.5 Query Strategies for Link SelectionWe propose multiple query selection strategies forour active learning setup.
The scoring criteria isdesigned to select alignment links across sentencepairs that are highly uncertain under current au-tomatic translation models.
These links are diffi-cult to align correctly by automatic alignment andwill cause incorrect phrase pairs to be extracted inthe translation model, in turn hurting the transla-tion quality of the SMT system.
Manual correctionof such links produces the maximal benefit to themodel.
We would ideally like to elicit the least num-ber of manual corrections possible in order to reducethe cost of data acquisition.
In this section we dis-cuss our link selection strategies based on the stan-dard active learning paradigm of ?uncertainty sam-pling?
(Lewis and Catlett, 1994).
We use the au-tomatically trained translation model ?t for scoringeach link for uncertainty.
In particular ?t consists ofbidirectional lexicon tables computed from the bidi-rectional alignments as discussed in Section 3.5.1 Uncertainty based: BidirectionalAlignment ScoresThe automatic Viterbi alignment produced by thealignment models is used to obtain translation lexi-cons, as discussed in Section 3.
These lexicons cap-ture the conditional distributions of source-given-target P (s/t) and target-given-source P (t/s) prob-abilities at the word level where si ?
S and tj ?
T .We define certainty of a link as the harmonic meanof the bidirectional probabilities.
The selection strat-egy selects the least scoring links according to theformula below which corresponds to links with max-imum uncertainty:Score(aij/sI1, tJ1 ) =2 ?
P (tj/si) ?
P (si/tj)P (tj/si) + P (si/tj)(10)5.2 Confidence Based: Posterior AlignmentprobabilitiesConfidence estimation for MT output is an interest-ing area with meaningful initial exploration (Blatz13et al, 2004; Ueffing and Ney, 2007).
Given a sen-tence pair (sI1, tJ1 ) and its word alignment, we com-pute two confidence metrics at alignment link level ?based on the posterior link probability and a simpleIBM Model 1 as seen in Equation 13.
We select thealignment links that the initial word aligner is leastconfident according to our metric and seek manualcorrection of the links.
We use t2s to denote com-putation using higher order (IBM4) target-given-source models and s2t to denote source-given-targetmodels.
Targeting some of the uncertain parts ofword alignment has already been shown to improvetranslation quality in SMT (Huang, 2009).
In ourcurrent work, we use confidence metrics as an ac-tive learning sampling strategy to obtain most infor-mative links.
We also experiment with other con-fidence metrics as discussed in (Ueffing and Ney,2007), especially the IBM 1 model score metricwhich showed some improvement as well.Pt2s(aij , tJ1 /sI1) =pt2s(tj/si, aij ?
A)?Mi pt2s(tj/si)(11)Ps2t(aij , sI1/tJ1 ) =ps2t(si/tj , aij ?
A)?Ni pt2s(tj/si)(12)Conf(aij/S, T ) =2 ?
Pt2s ?
Ps2tPt2s + Ps2t(13)5.3 Agreement Based: Query by CommitteeThe generative alignments produced differ based onthe choice of direction of the language pair.
We useAs2t to denote alignment in the source to target di-rection and At2s to denote the target to source direc-tion.
We consider these alignments to be two expertsthat have two different views of the alignment pro-cess.
We formulate our query strategy to select links,where the agreement differs across these two align-ments.
In general query by committee is a standardsampling strategy in active learning(Freund et al,1997), where the committee consists of any numberof experts with varying opinions, in this case align-ments in different directions.
We formulate a queryby committee sampling strategy for word alignmentas shown in Equation 14.
In order to break ties, weextend this approach to select the link with higheraverage frequency of occurrence of words involvedin the link.Language Sentences WordsSrc TgtCh-En 21,863 424,683 524,882Ar-En 29,876 630,101 821,938Table 1: Corpus Statistics of Human DataAlignment Automatic Links Manual LinksCh-En 491,887 588,075Ar-En 786,223 712,583Table 2: Alignment Statistics of Human DataScore(aij) = ?
where (14)?
=??
?2 aij ?
At2s ?At2s1 aij ?
At2s ?At2s0 otherwise6 Experiments6.1 Data AnalysisTo run our active learning and semi-supervised wordalignment experiments iteratively, we simulate thesetup by using a parallel corpus for which thegold standard human alignment is already available.We experiment with two language pairs - Chinese-English and Arabic-English.
Corpus-level statisticsfor both language pairs can be seen in Table 1 andtheir alignment link level statistics can be seen inTable 2.
Both datasets were released by LDC as partof the GALE project.Chinese-English dataset consists of 21,863 sen-tence pairs with complete manual alignment.
Thehuman alignment for this dataset is much denserthan the automatic word alignment.
On an aver-age each source word is linked to more than onetarget word.
Similarly, the Arabic-English datasetconsisting of 29,876 sentence pairs also has a densermanual alignment.
Automatic word alignment inboth cases was computed as a symmetrized versionof the bidirectional alignments obtained from usingGIZA++ (Och and Ney, 2003) in each direction sep-arately.6.2 Word Alignment ResultsWe first perform an unsupervised word alignment ofthe parallel corpus.
We then use the learned model14Figure 1: Chinese-English: Link Selection Resultsin running our link selection algorithm over the en-tire alignments to determine the most uncertain linksaccording to each active learning strategy.
The linksare then looked up in the gold standard human align-ment database and corrected.
In scenarios wherean alignment link is not present in the gold stan-dard data for the source word, we introduce a NULLalignment constraint, else we select all the links asgiven in the gold standard.
The aim of our work is toshow that active learning can help in selecting infor-mative alignment links, which if manually labeledcan reduce the overall alignment error rate of thegiven corpus.
We, therefore measure the reductionof alignment error rate (AER) of a semi-supervisedword aligner that uses this extra information to alignthe corpus.
We plot performance curves for bothChinese-English, Figure 1 and Arabic-English, Fig-ure 2, with number of manual links elicited on x-axisand AER on y-axis.
In each iteration of the experi-ment, we gradually increase the number of links se-lected from gold standard and make them availableto the semi-supervised word aligner and measure theoverall reduction of AER on the corpus.
We com-pare our link selection strategies to a baseline ap-proach, where links are selected at random for man-ual correction.All our approaches perform equally or better thanthe baseline for both language pairs.
Query bycommittee (qbc) performs similar to the baseline inChinese-English and only slightly better for Arabic-Figure 2: Arabic-English: Link Selection ResultsEnglish.
This could be due to our committee con-sisting of two alignments that differ only in direc-tion and so are not sufficient in deciding for uncer-tainty.
We will be exploring alternative formulationsto this strategy.
Confidence based and uncertaintybased metrics perform significantly better than thebaseline in both language pairs.
We can interpret theimprovements in two ways.
For the same numberof manual alignments elicited, our selection strate-gies select links that provide higher reduction of er-ror when compared to the baseline.
An alternativeinterpretation is that assuming a uniform cost perlink, our best selection strategy achieves similar per-formance to the baseline, at a much lower cost ofelicitation.6.3 Translation ResultsWe also perform end-to-end machine translation ex-periments to show that our improvement of align-ment quality leads to an improvement of translationscores.
For Chinese-English, we train a standardphrase-based SMT system (Koehn et al, 2007) overthe available 21,863 sentences.
We tune on the MT-Eval 2004 dataset and test on a subset of MT-Eval2005 dataset consisting of 631 sentences.
The lan-guage model we use is built using only the Englishside of the parallel corpus.
We understand that thislanguage model is not the optimal choice, but weare interested in testing the word alignment accu-racy, which primarily affects the translation model.15Cn-En BLEU METEORBaseline 18.82 42.70Human Alignment 19.96 44.22Active Selection 20% 19.34 43.25Table 3: Effect of Alignment on Translation QualityWe first obtain the baseline score by training in anunsupervised manner, where no manual alignmentis used.
We also train a configuration, where wesubstitute the final word alignment with gold stan-dard manual alignment for the entire parallel corpus.This is an upper bound on the translation accuracythat can be achieved by any alignment link selec-tion algorithm for this dataset.
We now take ourbest link selection criteria, which is the confidencebased method and re-train the MT system after elic-iting manual information for only 20% of the align-ment links.
We observe that at this point we havereduced the AER from 37.09 to 26.57.
The trans-lation accuracy reported in Table 3, as measured byBLEU (Papineni et al, 2002) and METEOR (Lavieand Agarwal, 2007), also shows significant improve-ment and approaches the quality achieved using goldstandard data.
We did not perform MT experimentswith Arabic-English dataset due to the incompatibil-ity of tokenization schemes between the manuallyaligned parallel corpora and publicly available eval-uation sets.7 ConclusionWord-Alignment is a particularly challenging prob-lem and has been addressed in a completely unsuper-vised manner thus far (Brown et al, 1993).
Whilegenerative alignment models have been successful,lack of sufficient data, model assumptions and lo-cal optimum during training are well known prob-lems.
Semi-supervised techniques use partial man-ual alignment data to address some of these issues.We have shown that active learning strategies canreduce the effort involved in eliciting human align-ment data.
The reduction in effort is due to care-ful selection of maximally uncertain links that pro-vide the most benefit to the alignment model whenused in a semi-supervised training fashion.
Experi-ments on Chinese-English have shown considerableimprovements.8 Future WorkIn future, we wish to work with word alignments forother language pairs as well as study the effect ofmanual alignments by varying the size of availableparallel data.
We also plan to obtain alignments fromnon-experts over online marketplaces like AmazonMechanical Turk to further reduce the cost of an-notation.
We will be experimenting with obtain-ing full-alignment vs. partial alignment from non-experts.
Our hypothesis is that, humans are goodat performing tasks of smaller size and so we canextract high quality alignments in the partial align-ment case.
Cost of link annotation in our currentwork is assumed to be uniform, but this needs tobe revisited.
We will also experiment with activelearning techniques for identifying sentence pairswith very low alignment confidence, where obtain-ing full-alignment is equivalent to obtaining multi-ple partial alignments.AcknowledgmentsThis research was partially supported by DARPAunder grant NBCHC080097.
Any opinions, find-ings, and conclusions expressed in this paper arethose of the authors and do not necessarily reflect theviews of the DARPA.
The first author would like tothank Qin Gao for the semi-supervised word align-ment software and help with running experiments.ReferencesJohn Blatz, Erin Fitzgerald, George Foster, Simona Gan-drabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis,and Nicola Ueffing.
2004.
Confidence estimation formachine translation.
In Proceedings of Coling 2004,pages 315?321, Geneva, Switzerland, Aug 23?Aug27.
COLING.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Computational Linguistics, 19(2):263?311.Chris Callison-Burch, David Talbot, and Miles Osborne.2004.
Statistical machine translation with word- andsentence-aligned parallel corpora.
In ACL 2004, page175, Morristown, NJ, USA.
Association for Computa-tional Linguistics.O.
Chapelle, B. Scho?lkopf, and A. Zien, editors.
2006.Semi-Supervised Learning.
MIT Press, Cambridge,MA.16Colin Cherry and Dekang Lin.
2006.
Soft syntacticconstraints for word alignment through discriminativetraining.
In Proceedings of the COLING/ACL on Mainconference poster sessions, pages 105?112, Morris-town, NJ, USA.Pinar Donmez and Jaime G. Carbonell.
2008.
Opti-mizing estimated loss reduction for active sampling inrank learning.
In ICML ?08: Proceedings of the 25thinternational conference on Machine learning, pages248?255, New York, NY, USA.
ACM.Alexander Fraser and Daniel Marcu.
2006.
Semi-supervised training for statistical word alignment.
InACL-44: Proceedings of the 21st International Con-ference on Computational Linguistics and the 44thannual meeting of the Association for ComputationalLinguistics, pages 769?776, Morristown, NJ, USA.Association for Computational Linguistics.Alexander Fraser and Daniel Marcu.
2007.
Measuringword alignment quality for statistical machine transla-tion.
Comput.
Linguist., 33(3):293?303.Yoav Freund, Sebastian H. Seung, Eli Shamir, and Naf-tali Tishby.
1997.
Selective sampling using the queryby committee algorithm.
Machine.
Learning., 28(2-3):133?168.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, pages 49?57, Columbus, Ohio,June.
Association for Computational Linguistics.Gholamreza Haffari, Maxim Roy, and Anoop Sarkar.2009.
Active learning for statistical phrase-based ma-chine translation.
In Proceedings of HLT NAACL2009, pages 415?423, Boulder, Colorado, June.
As-sociation for Computational Linguistics.Fei Huang.
2009.
Confidence measure for word align-ment.
In Proceedings of the Joint ACL and IJCNLP,pages 932?940, Suntec, Singapore, August.
Associa-tion for Computational Linguistics.Rebecca Hwa.
2004.
Sample selection for statisticalparsing.
Comput.
Linguist., 30(3):253?276.Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,Christopher Callison-Burch, Marcello Federico,Nicola Bertoldi, Brooke Cowan, Wade Shen, Chris-tine Moran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open source toolkit for statistical machinetranslation.
In ACL Demonstration Session.Alon Lavie and Abhaya Agarwal.
2007.
Meteor: an au-tomatic metric for mt evaluation with high levels ofcorrelation with human judgments.
In WMT 2007,pages 228?231, Morristown, NJ, USA.David D. Lewis and Jason Catlett.
1994.
Heterogeneousuncertainty sampling for supervised learning.
In InProceedings of the Eleventh International Conferenceon Machine Learning, pages 148?156.
Morgan Kauf-mann.Hieu T. Nguyen and Arnold Smeulders.
2004.
Activelearning using pre-clustering.
In ICML.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, pages 19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic evalua-tion of machine translation.
In ACL 2002, pages 311?318, Morristown, NJ, USA.Dan Shen, Jie Zhang, Jian Su, Guodong Zhou, and Chew-Lim Tan.
2004.
Multi-criteria-based active learningfor named entity recognition.
In ACL ?04: Proceed-ings of the 42nd Annual Meeting on Association forComputational Linguistics, page 589, Morristown, NJ,USA.
Association for Computational Linguistics.Min Tang, Xiaoqiang Luo, and Salim Roukos.
2001.
Ac-tive learning for statistical natural language parsing.
InACL ?02, pages 120?127, Morristown, NJ, USA.Katrin Tomanek and Udo Hahn.
2009.
Semi-supervisedactive learning for sequence labeling.
In Proceedingsof the Joint Conference of the 47th Annual Meetingof the ACL and the 4th International Joint Conferenceon Natural Language Processing of the AFNLP, pages1039?1047, Suntec, Singapore, August.
Associationfor Computational Linguistics.Simon Tong and Daphne Koller.
2002.
Support vectormachine active learning with applications to text clas-sification.
Journal of Machine Learning, pages 45?66.Gokhan Tur, Dilek Hakkani-Tr, and Robert E. Schapire.2005.
Combining active and semi-supervised learningfor spoken language understanding.
Speech Commu-nication, 45(2):171 ?
186.Nicola Ueffing and Hermann Ney.
2007.
Word-levelconfidence estimation for machine translation.
Com-put.
Linguist., 33(1):9?40.Hua Wu, Haifeng Wang, and Zhanyi Liu.
2006.
Boostingstatistical word alignment using labeled and unlabeleddata.
In Proceedings of the COLING/ACL on Mainconference poster sessions, pages 913?920, Morris-town, NJ, USA.
Association for Computational Lin-guistics.X.
Zhu.
2005.
Semi-Supervised Learning Lit-erature Survey.
Technical Report 1530, Com-puter Sciences, University of Wisconsin-Madison.http://www.cs.wisc.edu/?jerryzhu/pub/ssl survey.pdf.17
