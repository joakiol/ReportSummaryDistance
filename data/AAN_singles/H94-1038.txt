RECENT DEVELOPMENTS INTHE EXPERIMENTAL "WAXHOLM" DIALOG SYSTEMRoll CarlsonDepartment of Speech Communication and Music Acoustics,KTI-I, Stockholm, SwedenABSTRACTRecently we have begun to build the basic tools for a geneticspeech-dialog system.
The main modules, their function andinternal ccommunication have been specified.
The differentcomponents ~e connected through a computer network.
Apreliminary version of the system has been tested, usingsimplified versions of the modules.
The dialog component of thesystem is described by a dialog grammar with the help ofsemantic features.
Probabilities are also used in this process.
Wewill give a general overview of the system and describe some ofthe components in more detail.
Application-specific data arecollected with the help of Wizard-of-Oz techniques.
Currentlythe system is used during the data collection and the bionicwizard replaces only the speech-recognition module.1.
INTRODUCTIONOur research group at KTH* is currently building a geneticsystem in which speech synthesis and speech recognition can bestudied in a man-machine dialog framework.
In addition, thesystem should facilitate the collection of speech and text datathat are required for development.
The system was firstpresented at the Eurospeech '93 conference \[1\].
The currentpaper is an expanded version of that paper.
We will give ageneral overview of the system and describe some of thecomponents in more detail.
The dialog management componenthas recently been reformulated in a more general framework andis presented in the latter part of the paper.2.
THE DEMONSTRATOR APPLICATIONThe demonstrator application, which we call WAXHOLM, givesinformation on boat traffic in the Stockholm archipelago (seeFigure 1).
I references time tables for a fleet of some twenty* The Waxholm group consists of staff and students at theDepartment of Speech Communication and Music Acoustics,KTH.
Most of the efforts are done part time.
The members ofthe group in alphabetic order are: Mats Blomberg, Rolf Carlson,Kjell Elenius, Bj6rn Granstr6m, Joakim Gustafson, SheriHunnicutt, Jesper H6gberg, Roger Lindell, Lennart Neovius,Lennart Nord, Antonio de Serpa-Leitao and Nikko Str6mboats from the Waxholm company which connects about twohundred ports.
Different days of the week have different ime-tables.Besides the speech recognition and synthesis components, thesystem contains modules that handle graphic information such aspictures, maps, charts, and time-tables.
This information can bepresented to the user at his/her request The application hasgreat similarities to the ATIS domain within the ARPAcommunity and other similar tasks in Europe, for exampleSUNDIAL.
The possibility of expanding the task in manydirections is an advantage for our future research on interactivedialog systems.
An initial version of the system based on textinput has been running since September 1992.2.1.
The databaseIn addition to boat time-tables the database also contains, andalso information about port locations, hotels, camping places,and restaurants in the Stockholm archipelago.
This informationis accessed by the standardized query language (SQL, Oracle).The time-table, which is the primary part of the database, bringssome inherent difficulties to our application.
One is that a boatcan go in "loops," i.e.
it uses the same port more than once fordeparture or arrival.
This has been solved by giving unique touridentification numbers to different "loops."
Another problem isthat the port Waxho im may be used as a "transit port" for manydestinations, and to avoid redundancy transit tours are notincluded in the database.
Transits are instead handled bysearching for tours from the departure port to Waxholm, and(backwards) from the destination port to Waxholm that requireless than 20 minutes at the transit point \[2\].2.2.
ImplementationThe dialog system is implemented as a number of independentand specialized modules that run as servers on our HP computersystem.
A notation has been defined to control the informationflow between them.
The structure makes it possible to run thesystem in parallel on different machines and facilitates theimplementation a d testing of alternate models within the sameframework.
The communication software is based on UNIX defacto standards, which will facilitate the reuse and portability ofthe components.207WordsParts of speechSemantic informationPronunciationRECOGNITIONLE~CONINPUTSpeechRECORDGRAMMAR &SEMAN~CSHuman interactionContext sensitive rulestransition networksDATA BASE DATABASE SEARCH DIALOG MANAGER Application specific modulesShip schedulesPort locationsLodgingEatingGRAPHICS B I SYNTHESIS R I SoundCharts Maps Tables Speech RecordingsOUTPUTFigure 1.
Block diagram of the demonstrator application Waxholm.3.
SPEECH RECOGNITIONThe speech recognition component, which so far has not beenintegrated in the system during data collection, will handlecontinuous peech with a vocabulary of about 1000 words.
Thework on recognition has been carried out along two main lines:artificial neural networks and a speech production orientedapproach.
Since neural nets are general classification tools, it isquite feasible to combine the two approaches.3.2.
Artificial neural networksWe have tested different ypes of artificial neural networks forperforming acoustic-pbonetic mapping for speech signais, see\[4\], \[5\], and \[6\].
The tested strategies include serf-organizingnets and nets using the error-back propagation (BP) technique.The use of simple recurrent BP-networks has been shown tosubstantially improve performance.
The serf-organizing netslearn faster than the BP-networks, but they are not as easilytransformed torecurrent structures.3.1.
Speech production approachOur system uses a speech synthesis technique to generatespectral prototypes of words in a given vocabulary, sec \[3\].
Aspeaker-independent r cognition system has been built accordingto the speech production approach, using a formant-based speechproduction module including a voice source model.
Whole wordmodels are used to describe intra-word phonemes, whiletriphones (three-phoneme clusters) are used to model thephonemes at word boundaries.
An important part of the systemis a method of dynamic voice-source adaptation.
The recognitionerrors have been significantly reduced by this method.3.3.
Lexical searchThe frame based outputs from the neural network form the inputto the lexical search.
There is one output for each of the40 Swedish phonemes used in our lexicon.
Each word in thelexicon is described on the phonetic level.
The lexicon mayinclude alternate pronunciations of each word.
The outputs areseen as the aposteriori probabilities of the respective phonemesin each frame.
We have implemented an A* N-best search usinga simple bigram language model.
In a second stage the speechproduction approach mentioned above will be used to reorder theN-best list according to speaker specific criteria.
A tightcoupling between the parser and the recognizer is a long-termgoal in the project.
This will naturally influence the searchalgorithms.2084.
SPEECH SYNTHESISFor the speech-output component we have chosen the multi-lingual text-to-speech system developed in an earlier project \[7\].The system is modified for this application.
The applicationvocabulary must be checked for correctness, especiallyconsidering the general problem of name pronunciation.Speaker-specific aspects are important for the acceptability ofthe synthetic speech.
The WAXHOLM dialog system will focusour efforts on modelling the speaking style and speakercharacteristics of one reference speaker.
Since the recognitionand synthesis modules have the same need of semantic, syntacticand pragmatic information, the lexieal information will, to agreat extent, be shared.
The linguistic module, STINA, will alsobe used for improved phrase parsing, compared to the simplefunction-word based methods that have been used so far in thesynthesis project.
However, in dialog applications such as theproposed WAXHOLM demonstrator, information on phrasingand prosodic structure can be supplied by the application controlsoftware itself, rather than by a general module meant for text-to-speech.
In a man-machine dialog situation we have a muchbetter base for prosodic modelling compared to ordinary text-to-speech, since we, in such an environment, will have access tomuch more information than if we used an unknown text asinput o the speech synthesizer.5.
NATURAL LANGUAGE COMPONENTOur initial work on a natural language component is focused ona sublanguage grammar, a grammar limited to a particularsubject domain: that of requesting information from atransportation database.The fundamental concepts are inspired by TINA, a parserdeveloped at MIT \[8\].
Our parser, STINA, i.e., Swedish TINA,is knowledge-based and is designed as a probabilistic languagemodel \[9\].
It contains a context-free grammar which is compiledinto an augmented transition etwork (ATN).
Probabilities areassigned to each arc after training.
Features of STINA are astack-decoding search strategy and a feature-passing mechanismto implement unification.In the implementation f the parser and the dialog management,we have stressed an interactive development environment.
Thismakes it easier to have control over the system's progress asmore components are added.
It is possible to study the parsingand the dialog flow step by step when a tree is built.
It is evenpossible to use the collected log files as scripts to repeat acollected dialog including all graphic displays and acousticoutputs.5.1.
LexiconThe lexicon entries are generated by processing each word in theTwo-Level Morphology (TWOL) lexical analyzer (\[10\] and\[11\]).
Each entry is then corrected by removing all unknownhomographs.
New grammatical nd semantic features, which areused by our algorithm and special application, are then added.5.2.
FeaturesThe basic grammatical features can be positive, negative orunspecified.
Unspecified features match both positive andnegative f atures.Figure 2.
Example of a semantic tree feature structure.Semantic features can be divided into two different classes.
Thebasic features like BOAT and PORT give a simple description of'the semantic property of a word.
These features arehierarchically structured.
Figure 2 gives an example of asemantic feature tree.
During the unification process in STINA,all features which belong to the same branch are considered.Thus, a unification of the feature PLACE engage all semantic"non-shaded" features in Figure 2.Another type of semantic feature controls which nodes can beused in the syntactic analysis.
For example, the nodeDEPARTURE TIME cannot be used in connection with verbsthat imply an arrival time.
This is also a powerful method tocontrol the analysis of responses to questions from the dialogmodule.
The question "Where do you want to go?"
conditions theparser to accept a simple port name as a possible response fromthe user.6.
DIALOG MANAGEMENT6.1.
Dialog rulesDialog management based on grammar ules and lexicalsemantic features has recently been implemented in STINA.
Thenotation to describe the syntactic rules has been expanded tocover some of our special needs to model the dialog.
The STINAparser is running with two different ime scales during datacollection corresponding both to the words in each utterance andto the turns in the dialog.
Syntactic nodes and dialog states areprocessed according to transition etworks with probabilities oneach arc.209Dialog Node SpecificationsNode typesbranching or preterminalConstant evaluation ondialog flow featuressemantic frame slots and featuresIf more information eededsynthesize question to usercontrol parser to accept incomplete sentencesNode functions:record utterancesynthesize messagetest constraintsdata base search using SQLgraphic display tablegraphic display mapgraphic display pictureFigure 3.
Dialog node specification.Each dialog topic is explored according to the rules.
These rulesdefine which constraints have to be fulfilled and what action thatshould be taken depending on the dialog history.
Each dialognode is specified according to Figure 3.The constraint evaluation i s described in terms of features andthe content in the semantic frame.
If the frame needs to beexpanded with additional information, a system question, issynthesized.
During recognition of a response to such a questionthe grammar is controlled with semantic features in order toallow incomplete sentences.
If the response from the subjectdoes not clarify the question, the robust parsing is temporarilydisconnected so that specific information can be given to theuser about syntactic or unknown word problems.
At the sametime a complete sentence is requested giving the dialog managerthe possibility of evaluating whether the chosen topic is a badchoice.A positive response from the constraint evaluation clears theway for the selected action to take place.
The node function listin the figure gives examples of such actions.6.2.
Topic selectionIn Figure 4 some of the major topics are listed.
The decisionabout which path to follow in the dialog is based on severalfactors uch as the dialog history and the content of the specificutterance.
The utterance is coded in the form of a "semanticframe" with slots corresponding toboth the grammatical nalysisand the specific application.
The structure of the semantic frameis automatically created based on the rule system.TIME_TABLEGoal: to get a time-table presented with departure and arrivaltimes specified between two specific locations.Example: N~ g~r b~ten?
(When does the boat leave?
)GETPOSIT IONGoal: to get a chart or a map displayed with the place of interestshown.Example: Var ligger Vaxholm?
(Where is Vaxholm?
)EXISTGoal: to display the availability of lodging and diningpossibilities.Example: Var finns det vandrarhem?
(Where are there hostels?
)OUT_OFDOMAINGoal: Inform the user that the subject is out of the domain for thesystem.Example: Kan jag boka rum.
(Can I book a room?
)Figure 4.
Some of the main topics used in the dialog.Each semantic feature found in the syntactic and semanticanalysis is considered in the form of a conditional probability todecide on the topic.
The probability for each topic is expressedas: p(topiclF), where F is a feature vector including all semanticfeatures used in the utterance.
Thus, the BOAT feature can be astrong indication for the TIME-TABLE topic but this can becontradicted by a HOTEL feature.6.3.
Introduction of a new topicThe rule-based and to some extent probabilistic approach we areexploring makes the addition of new topics relatively easy.However, we do not know at this stage where the limits are forthis approach.
In this section we will give a simple example ofhow a new topic can be introduced.Suppose we want to create a topic called "out of domain."
Figure5 illustrates the steps that need to be taken.
First a topic node isintroduced in the rule system.
Some words will need to beincluded in the lexicon and labelled with a semantic featureshowing that the system does not know how to deal with thesubjects these words relate to.
Then a synthesis node might beadded with a text informing the user about the situation.Example sentences must be created that illustrate the problem.
'nae dialog parser must be trained with these sentences labelledwith the "out of domain" topic.Since the topic selection is done by a probabilistic approach thatneeds application-specific training, data collection is of greatimportance for the progress of the project.210How to introduce a new topicIntroduce anew dialog grammar parent nodeExpand the semantic feature set if neededSpecify dialog children odes and their function and add tolexiconConstruct and label training sentencesTrain topic probabilitiesFigure 5.
Introduction of a new topic.The dialog will be naturally restricted by application-specificcapabilities and the limited grammar.
So far we also assume thatthe human subjects will be co-operative in pursuing the task.Recovery in case of human-machine "misunderstandings" will beaided by informative error messages generated upon theoccurrence of lexical, parsing or retrieval errors.
This techniquehas been shown to be useful in helping subjectsto recover froman error through rephrasing of their last input \[12\].7.
DATA COLLECTIONWe are currently collecting speech and text data using theWAXHOLM system.
Initially, a "Wizard of Oz" (a humansimulating part of a system) is replacing the speech recognitionmodule, (See Figure 6).
The user is placed in a sound-treatedroom in front of a terminal screen.
The wizard sitting outside theroom can observe the subject's screen on a separate display.The user is initially requested to pronounce a number ofsentences and digit sequences to practice talking to a computer.This material will be used for speaker adaptation experiments.After this the subject is presented with a task to be carried out.The scenario is presented both as text and as synthetic speech.An advantage of this procedure is that the subject becomesfamiliar with the synthetic speech.
During the data collection,utterance-size speech files are stored together with thetranscribed text entered by the wizard.The stored speech files and their associated label files areprocessed by our text-to-speech system to generate a possiblephonetic transciption.
This transcription is then aligned andmanually corrected.
(For a description of this process ee \[13\].
)The collected corpus is being used for grammar development, fortraining of probabilities in the language model in STINA, andalso for generation of an application-dependent bigram model tobe used by the recognizer.
It is also being used to train wordcollocation probabilities.
Our plan is to replace explicitformulations of semantic oupling by a collocation probabilitymall~X.I|11Wizard UserFigure 6.
Hardware setup for data collection, with the help of a wizard.2118.
FINAL REMARKSIn our we have presentation described the Waxhom project withspecial emphasis on the natural anguage components of thesystem.
No module is yet considered complete.
However, themost important work besides data collection is the integration ofthe spo~ch recognizer into the system.
The interaction betweenthe parser and the recognizer still has to be improved.The STINA parser has been expanded to better handle robustparsing and unknown word problems.
In addition we arecurrently testing a simple application-independent grammar onunlimited text.
This system will also be used as part of ourgeneral text-to-speech system, which is outside the scope of thispresentation.The dialog management module still needs to be tested in amore hostile environment.
And the limits for our rule-based andprobabi~istic approach need to be explored.ACKNOWLEDGEMENTWe thank Mike Phillips, SLS, MIT for valuable help inimplementing the A*-search algorithm.
This work has beensupported by grants from The Swedish National LanguageTechnology Program.REFERENCES4Blomberg, M., Carlson, R., Elenius, K., Granstr6m, B.,Gustafson, J., Hunnicutt, S., Lindell, R., and Neovius, L.(1993): "An experimental dialog system: WAXttOLM,"Proceedings of Eurospeech '93.
pp 1867-1870.Gustafson, J.
(1992): "Databashantering som del av etttalftrstfielsesystem," Thesis work, Dept.
of SpeechComm., KTH (only available in Swedish).Blomberg, M. (1991): "Adaptation to a speaker's voice ina speech recognition system based on synthetic phonemereferences," Speech Communication, Vol.
10. pp 453-462.Elenius K. and Takfics, G. (1990): "Acoustic-phoneticrecognition of continuous speech by artificial neuralnetworks," S'IL-QPSR 2-3, Technical Report, Dept.
ofSpeech Comm., KTH, 1990. pp 1-44.Elenius, K. & Blomberg M., (1992): "Experiments withartificial neural networks for phoneme and wordrecognition," Proceedings of ICSLP 92, Banff, Vol.
2,pp.
1279-1282.Elenius K. & Trfivtn H. (1993): "Multi-layer perceptronsand probabilistic neural networks for phonemerecognition," Proceedings of Eurospeech '93.
pp 1237-1240.910111213Carlson, R., Granstrtm, B., & Hunnicutt, S. (1991),"Multilingual text-to-speech development andapplications," (ed.
A. W. Ainsworth), Advances inspeech, hearing and language processing, JAI Press,London, UK.Seneff, S. (1989): "TINA: A Probabilistic SyntacticParser for Speech Understanding Systems," ProceedingsICASSP-89, pp.
711-714.Carlson, R., & Hunnicutt, S. (1992): "STINA: Aprobabifistic parser for speech recognition,"FONETIK'92, Sixth Swedish Phonetics Conference, May20-22, 1992, Technical Report No.
10, Dept.
ofInformation Theory, Chalmers University of Technology,Gtteborg.
pp 23-26.Koskenniemi, K. (1983): "Two-Level Morphology: AGeneral Computational Model for Word-FormRecognition and Production," University of Helsinki,Department ofGeneral Linguistics, Publications No.
11.Karlsson, F. (1990): "A Comprehensive MorphologicalAnalyzer for Swedish," manuscript, University ofHelsinki, Department ofGeneral Linguistics.Hunnicutt, S., Hirschman, L., Polifroni, J., & Seneff, S.(1992): "Analysis of the effectiveness of system errormessages in a human-machine travel planning task,"ICSLP 92 Proceedings, Vol.
1, University of Alberta,Canada.
pp 197-200.Blomberg, M., & Carlson, R. (1993): "Labelling ofspeech given its text representation," Proceedings ofEurospeech '93.
pp 1775-1778.212
