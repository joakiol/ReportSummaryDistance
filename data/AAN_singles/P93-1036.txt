A Competition-Ba sed Explanation of Syntactic AttachmentPreferences and Garden Path PhenomenaSuzanne StevensonDepar tment  of  Computer  Sc ienceUn ivers i ty  of  TorontoToronto ,  Ontar io  MSS 1A4 Canadasuzanne@cs .
to ronto .eduAbst ractThis paper presents a massively parallel parser that pre-dicts critical attachment behaviors of the human sentenceprocessor, without he use of explicit preference heuristicsor revision strategies.
The processing of a syntactic am-biguity is modeled as an active, distributed competitionamong the potential attachments for a phrase.
Computa-tionally motivated constraints on the competitive mecha-nism provide a principled and uniform account of a rangeof human attachment preferences and garden path phe-no lnena .1 A Compet i t ion -Based  ParserA model of the human parser must explain, amongother factors, the following two aspects of the pro-cessing of a syntactic ambiguity: the initial attach-ment preferences that people exhibit, and their abil-ity or inability to later revise an incorrect attachment.This paper presents a competition-based parser, CA-PERS, that predicts critical attachment behaviors ofthe human sentence processor, without the use of ex-plicit preference heuristics or revision strategies.
CA-PERS is a massively parallel network of processingnodes that represent syntactic phrases and their at-tachments within a parse tree.
A syntactic ambi-guity leads to a network of alternative attachmentsthat compete in parallel for numeric activation; an at-tachment wins over its competitors when it amassesactivation above a certain threshold.
The competi-tion among attachments i achieved solely througha technique called competition-based spreading ac-tivation (CBSA) (Reggia 87).
The effective use ofCBSA requires restrictions on the syntactic attach-ments that are allowed to compete simultaneously.Ensuring these network restrictions necessitates thefurther constraint hat a stable state of the networkcan only represent a single valid parse state.
The re-sulting network structure defines a limited set of corn-peting attachments hat simultaneously define the ini-tial attachments for the current input phrase, alongwith the reanalysis possibilities for phrases previouslystructured within the parse tree.The competitive mechanism and its ensuing restric-tions have profound consequences for the modeling ofthe human sentence processor.
Whereas other mod-els must impose explicit conditions on the parser'sattachment behavior (Abney 89; Gibson 91; McRoy& Hirst 90; Pritchett 88), in CAPERS both initialattachment preferences and reanalyzability are a sideeffect of independently motivated computational s-sumptions.
Furthermore, parsing models generallyemploy two different computational mechanisms indetermining syntactic attachments: a general parserto establish the attachment possibilities, and addi-tional strategies for choosing among them (Abney 89;Frazier 78; Gibson 91; McRoy & Hirst 90; Shieber83).
By contrast, CAPERS provides a more restric-tive account, in which a single competitive mechanismimposes constraints on the parser that determine thepotential attachments, as well as choosing the pre-ferred attachment from among those.The competitive mechanism of CAPERS also leadsto an advantageous integration of serialism and paral-lelism.
In order to conform to human memory limita-tions, other parallel models must be augmented witha scheme for reducing the number of structures thatare maintained (Gibson 91; Gorrell 87).
Such pruningschemes are unnecessary in CAPERS, since inherentproperties of the competitive mechanism lead to a re-striction to maintain a single parse state.
However,in spite of this serial aspect, CAPERS is not a sim-ple serial model.
The network incorporates each in-put phrase through a parallel atomic operation thatdetermines both the initial attachment for the cur-rent phrase and any revision of earlier attachments.Thus, CAPERS avoids the problems of purely serialor race-based models that rely on backtracking, whichis cognitively implausible, or explicit revision strate-266gies, which can be unrestrictive (Abney 89; Frazier78; Inoue & Fodor 92; McRoy & Hirst 90; Pritchett88).Other work (Stevenson 93b, 90) describes the de-tailed motivation for the CAPERS model, its expla-nation of serial and parallel effects in human parsing,and its predictions of a broad range of human attach-ment preferences.
This paper focuses on the competi-tive mechanism described above.
Section 2 briefly de-scribes the implementation f the parser) Section 3discusses the constraints on the network structure,and Section 4 demonstrates the consequences oftheseconstraints for the processing of attachment ambigui-ties.
Section 5 summarizes how the competitive mech-anism provides a principled and uniform account ofthe example human attachment preferences and gar-den path phenomena.2 The  Pars ing  NetworkCAPERS dynamically creates the parsing network byallocating processing nodes in response to the input.Control of the parse is distributed among these nodes,which make attachment decisions olely on the basisof the local communication f simple symbolic fea-tures and numeric activation.
The symbolic informa-tion determines the grammaticality of potential at-tachments, while numeric activation weighs the rela-tive strengths of the valid alternatives.
The spread-ing activation process allows the network to graduallysettle on a set of winning attachments hat form aglobally consistent parse tree.Building the NetworkWhen an input token is read, the parser activates a setof phrasal nodes, or p-nodes, from a pool of X tem-plates; their symbolic features are initialized basedon the input token's lexical entry.
Figure 1 shows asample X template and its instantiation.
Syntacticphrases are only allocated in response to explicit evi-dence in the input; top-down hypothesizing of phrasesis disallowed because it greatly increases the complex-ity of the network.
Next, the parser allocates process-ing nodes to represent the potential attachments be-tween the current input phrase and the existing parsetree.
Attachment nodes, or a-nodes, are establishedbetween potential sisters in the parse tree; each a-node connects to exactly two p-nodes, as shown inFigure 2.
(In all figures, a-nodes are shown as squares,which are black when the a-node is fully activated.
)Once the current phrase is connected to the existingnetwork, each processing node iteratively updates itsl CAPERS is implemented in Conunoa Lisp, serially simu-lating the parallel processing of the network.~ has Case:has_category :selects_categ ory:assignsCase:ass igns jheta :selects category:~ has Oase:"none" has_category: V setects_category: "none" assigns_Case; Accassigns_theta: themeselects_category: (N I C)expectFigure 1: An X template and sample instantiation.Figure 2: (a) The basic configuration of a phrase inX theory.
(b) Representation f these attachments asister relations in CAPERS.symbolic features and numeric activation, and out-puts them to its neighbors.
This network processingloop continues until the activation level of each a-nodeis either above a certain threshold O, or is zero.
2 Theset of active a-nodes in this stable state represents hecurrent parse tree structure.
At this point, the nextinput token is read and the proeess is repeated.Grammaticality of AttachmentsUnlike other connectionist parsers (Cottrell 89; Fanty85; Selman & Hirst 85), CAPERS is a hybrid modelwhose limited symbolic processing abilities supportthe direct representation f the grammar of a cur-rent linguistic theory.
In Government-Binding theory(GB) (Chomsky 81, 86; Rizzi 90), the validity of syn-tactic structures i achieved by locally satisfying thegrammatical constraints among neighboring syntac-tic phrases.
CAPERS directly encodes this formula-tion of linguistic knowledge as a set of simultaneouslocal constraints.
Symbolic features are simple at-tribute/value pairs, with the attributes correspondingto grammatical entities uch as Case and theta roles.The values that these attributes can assume are takenfrom a pre-defined list of atoms.
GB constraints areimplemented as equality tests on the values of cer-tain attributes.
For example, the Case Filter in (;Bstates that every NP argument must receive Case.
InCAPERS, this is stated as a condition that the at-tribute Case must receive a value when the attributeCategory equals Noun and the attribute IsArgumentequals True.An a-node receives symbolic features from its p-2The network always stabifizes in less than 100 iterations.267expect toSaraFigure 3: The NP can attach as a sister to the V or theI'.
The attachment to the V has a higher grammaticalstate value, and thus a higher initial activation level.nodes, which are used to determine the grammatical-ity of the attachment.
If  an a-node receives incom-patible features from its two p-nodes, then it is an in-valid attachment and it becomes inactive.
Otherwise,it tests the equality conditions that were developedto encode the following subset of GB constraints: theTheta Criterion, the Case Filter, categorial selection,and the binding of traces.
The algorithm outputs anumeric representation of the degree to which thesegrammatical constraints are satisfied; this state valueis used in determining the a-node's activation level.Choos ing  Pre fer red  At tachmentsMultiple grammatical attachments may exist for aphrase, as in Figure 3.
The network's task is to focusactivation onto a subset of the grammatical attach-ments that form a consistent parse tree for the inputprocessed thus far.
Attachment alternatives must bemade to effectively compete with each other for nu-meric activation, in order to ensure that some a-nodesbecome highly activated and others have their activa-tion suppressed.
There are two techniques for pro-ducing competitive behavior in a connectionist net-work.
The traditional method is to insert inhibitorylinks between pairs of competing nodes.
Competition-based spreading activation (CBSA) is a newer tech-nique that achieves competitive behavior indirectly:competing nodes vie for output from a common neigh-bor, which allocates its activation between the com-petitors.
In a CBSA function, the output of a node isbased on the activation levels of its neighbors, as inequation 1.aj?
(1 )  Oji =akkwhere:oji is the output from node ni to node nj;ai is the activation of node hi;k ranges over all nodes connected to node hi.For reasons of space ei-liciency, flexibility, and cogni-tive plausibility (Reggia et al 88), CBSA was adoptedas the means for producing competitive behavioramong the a-nodes in CAPERS.
Each p-node uses aCBSA function to allocate output activation amongits a-nodes, proportional to their current activationlevel.
For example, the NP node in Figure 3 will sendmore of its output to the attachment to the V nodethan to the I' node.
The CBSA function is designedso that in a stable state of the network, each p-nodeactivates a number of a-nodes in accordance with itsgrammatical properties.
Since every XP must have aparent in the parse tree, all XP nodes must activateexactly one a-node.
An X or X ~ node must activatea number of a-nodes equal to the number of comple-ments or specifiers, respectively, that it licenses.
Thea-nodes enforce consistency among the p-nodes' indi-vidual attachment decisions: each a-node numericallyANDs together the input from its two p-nodes to en-sure that they agree to activate the attachment.A p-node that has obligatory attachments must atall times activate the appropriate number of a-nodesin order for the network to stabilize.
However, sincethe phrase(s) that the p-node will attach to may oc-cur later in the input, the parser needs a way to rep-resent a "null" attachment to act as a placeholderfor the p-node's eventual sister(s).
For this purpose,the model uses processing nodes called phi-nodes torepresent a "dummy" phrase in the tree.
3 Every Xand X' node has an a-node that connects to a phi-node, allowing the possibility of a null attachment.
Aphi-node communicates default symbolic informationto its a-node, with two side effects.
The a-node isalways grammatical ly valid, and therefore representsa default attachment for the p-node it connects to.But, the default information does not fully satisfy thegrammatical constraints of the a-node, thereby lower-ing its activation level and making it a less preferredattachment alternative.3 Rest r i c t ions  on  the  NetworkThe competitive mechanism presented thus far is in-complete.
If all possible attachments are establishedbetween the current phrase and the existing network,CBSA cannot ensure that the set of active a-nodesforms a consistent parse tree.
CBSA can weed outlocally incompatible a-nodes by requiring that eachp-node activate the grammatical ly appropriate num-ber of a-nodes, but it cannot rule out the simulta-neous activation of certain incompatible attachmentsthat are farther apart in the tree.
Figure 4 shows thetypes of structures in which CBSA is an insufficient3 Ph i -nodes also represent the traces of displaced phrases illthe parse tree; see (Stevenson 93a, 93b).268Figure 4: Example pairs of incompatible attachmentsthat CBSA alone cannot prevent from being activesimultaneously.competitive mechanism.
Both cases involve violationsof the proper nesting structure of a parse tree.
SinceCBSA cannot rule out these invalid structures, theparsing network must be restricted to prevent heseattachment configurations.
The parser could insertinhibitory links between all pairs of incompatible a-nodes, but this increases the complexity of the net-work dramatically.
The decision was made to insteadreduce the size and connectedness of the network, si-multaneously solving the tree structuring problems,by only allowing attachments between the currentphrase and the right edge of the existing parse tree.Limiting the attachment of the current phrase tothe right edge of the parse tree rules out all of theproblematic ases represented by Figure 4(a).
In-terestingly, the restriction leads to a solution for thecases of Figure 4(b) as well.
Since there is no globalcontroller, each syntactic phrase that is activatedmust be connected to the existing network so thatit can participate in the parse.
However, sometimesa phrase cannot attach to the existing parse tree; forexample, a subject in English attaches to an inflec-tion phrase (IP) that follows it.
The network con-nections between these unattached phrases must bemaintained as a stack; this ensures that the currentphrase can only establish attachments to the rightedge of an immediately preceding subtree.
The stackmechanism in CAPERS is implemented as shown inFigure 5: a phrase pushes itself onto the stack whenits XP node activates an a-node between it and a spe-cially designated stack node.
Because the stack can-not satisfy grammatical constraints, stack node at-tachments are only activated if no other attachmentis available for the XP.
The flexibility of CBSA al-lows the stack to activate more than one a-node, sothat multiple phrases can be pushed onto it.
The sur-prising result is that, by having the stack establish a-nodes that compete for activation like normal attach-ments, the indirect competitive relationships withinthe network effectively suppress all inconsistent at-tachment possibilities, including those of Figure 4(b).This result relies on the fact that any incompatiblea-nodes that are created either directly or indirectlystackofpartialparse trees.... ::ty ~treeon(x3 top of stackFigure 5: The stack is implemented as a degeneratep-node that can activate attachments o XP nodes.currenta 1 phaseofFigure 6: Attachments al-a4 were previously acti-vated.
To attach the current phrase to the tree onthe stack, the following must occur: exactly one of theprior attachments, al, must become inactive, and thecorresponding pair of attachments, pi, must becomeactive.
This relationship holds for a tree of arbitrarydepth on the stack.compete with each other through CBSA.
To guaran-tee this condition, all inactive a-nodes must be deletedafter the network settles on the attachments for eachphrase.
Otherwise, losing a-nodes could become acti-vated later in the parse, when the network is no longerin a configuration in which they compete with theirincompatible alternatives.
Since losing a-nodes aredeleted, CAPERS maintains only a single valid parsestate at any time.The use of CBSA, and the adoption of a stack mech-anism to support this, strongly restrict the attach-ments that can be considered by the parser.
The onlya-nodes that can compete simultaneously are thosein the set of attachments between the current phraseand the tree on top of the stack.
The competitive269currents t a c k ~(~ past (~/  al V SaraexpectFigure 7: The network after attaching the NP Sara.currenttop/ expect (( )SaraFigure 8: A-nodes a2 and a 3 define the necessary at-tachments for the current phrase.relationships among the allowed a-nodes completelydefine the sets of a-nodes that can be simultaneouslyactive in a stable state of the network.
These logi-cal attachment possibilities, shown in Figure 6, fol-low directly from the propagation of local competi-tions among the a-nodes due to CBSA.
In over 98%of the approximately 1400 simulations of attachmentdecisions in CAPERS, the network stabilized on oneof these attachment sets (Stevenson 93b).
The com-petitive mechanism of CAPERS thus determines acircumscribed set of attachment possibilities for bothinitial and revised attachments in the parser.4 Pars ing  At tachment  Ambigu i t iesThis section demonstrates the processing of CAPERSon example attachment ambiguities from the sentenceprocessing literature.
4 In sentence (1), the parser is4 A more complete presentation of CAPERS' explanation ofexpect,op/2;SaraFigure 9: The misattachment of the NP to the V hasbeen revised.faced with a noun phrase/sentential complement am-biguity at the post-verbal NP Sara:(1) Mary expected Sara to leave.People show a Minimal Attachment preference to at-tach the NP as the complement of the verb, but haveno conscious difficulty in processing the continuationof the sentence (Frazier & Rayner 82; Gorrell 87).The CAPERS network after attaching Sara is shownin Figure 7.
5 The NP has valid attachments to thestack (a0) and to the V (al).
Since the default stackattachment is less competitive, a-node al is highlyactivated.
This initial attachment accounts for theobserved Minimal Attachment preferences.
Next, theword to projects an IP; its initial connections to thenetwork are shown in Figure 8.
6 The same set of a-nodes that define the initial attachment possibilitiesfor the current IP phrase, a2 and a3, simultaneouslydefine the revised attachment necessary for the NPSara.
A-node al competes with a2 and a3 for the ac-tivation from the V and NP nodes, respectively; thiscompetition draws activation away from al.
Whenthe network stabilizes, a2 and a3 are highly activeand al has become inactive, resulting in the tree ofFigure 9.
In a single atomic operation, the networkthese and related psycholinguistic data can be found in (Steven-son 93b).5Note that a tensed verb such as expected projects a fullsentential s t ructure- - that  is, CP/\[P/VP--as in (Abney 86),although the figures here are simplified by onfitting display ofthe CP of root clauses.6In tlfis and the remaining figures, grannnatically invalida-nodes and irrelevant phi-nodes are not shown.270t:!~c k~ ~ ph:r=n:KivaeatFigure 10: The NP food has a single valid attachmentto the parse tree.has revised its earlier attachment hypothesis for theNP and incorporated the new IP phrase into the parsetree.Sentence (2), an example of Late Closure effects, isinitially processed in a similar fashion:(2) When Kiva eats food gets thrown.After attaching food, the network has the configura-tion shown in Figure 10.
As in sentence (1), the post-verbal NP makes the best attachment available to it,as the complement of the verb.
This behavior is againconsistent with the initial preferences of the humansentence processor (Frazier ~ Rayner 82).
Since theinitial attachment in these cases of Late Closure is de-termined in exactly the same manner as the MinimalAttachment cases illustrated by sentence (1), thesetwo classic preferences receive a uniform account inthe CAPERS model.Additional processing of the input distinguishes thesentence types.
At gets, a sentential phrase is pro-jected, and the network settles on the attachmentsshown in Figure 11.
As in Figure 8, the revision nec-essary for a valid parse involves the current phraseand the right edge of the tree.
However, in this case,the misattached NP cannot break its attachment tothe verb and reattach as the specifier of the IP.
Thedifference from the prior example is that here the Vnode has no other a-node to redirect its output to, andso it continues to activate the NP attachment.
Theattachment of the NP to the I ~ is not strong enoughby itself to draw activation away from the attachmentof the NP to the V. The current I' thus activates thedefault phi-node attachment, leading to a clause withcurrentphrase ?WhenpresentpresentKivaeat,:0/stackfoodFigure 11: The attachment of the NP food to the Vis not strong enough to break the attachment of theNP to the V.an empty (and unbound) subject.
Since the networksettles on an irrecoverably ungrammatical nalysis,CAPERS correctly predicts a garden path.The next two examples, adapted from (Pritchett88), involve double object verbs; both types of sen-tences clearly garden path the human sentence pro-cessor.
In each case, the second post-verbal NP isthe focus of attention.
In sentence (3), this NP is thesubject of a relative clause modifying the first NP,but the parser misinterprets it as the verb's secondcomplement:(3) Jamie gave the child the dog bit a bandaid.The initial Connections of the NP the dog to the net-work are shown in Figure 12.
The NP can either pushitself onto the stack, or replace the null attachmentof the verb to the phi-node.
Since both stack attach-ments and phi-node attachments are relatively weak,the NP attachment to the V wins the a-node competi-tion, and the network settles on the tree in Figure 13.In accordance with human preferences, the NP is at-tached as the second object of the verb.
When bitis processed, the network settles on the configurationin Figure 14.
As in the earlier examples, the misat-tached NP needs to attach as the subject of the cur-rent clause; however, this would leave the V node withonly one a-node to activate instead of its required twoattachments.
CAPERS again settles on an ungram-matical analysis in which the current clause has an271;cUrra~:tJ I / /  th~ Jamie ~ = ~/ 0,w=top / .
.
.<~== .j..the childFigure 12: The initial connections of the NP the dogto the network.the child theFigure 13: The NP the dog attaches as the verb'ssecond complement.empty (unbound) subject, consistent with the gardenpath effect of this sentence.The second example with a double object verb in-volves the opposite problem.
In sentence (4), the sec-ond post-verbal NP is mistakenly interpreted as partof the first object; in a complete parse, it is part ofthe second object:(4) I convinced her children are noisy.Initially, the parser attaches her as the NP objectof convinced.
The structure of the network after at-tachment of children is shown in Figure 15.
The NPchildren cannot replace the phi-node attachment tothe verb, since the second object of convince must be~ ~ current?
.,/toy /  .
.
.
.~ /  m ft... ,,oz.,, Tof - ~e~ (N) ~ dogs,ack "V" "V  Tthe child theFigure 14: If the NP the dog activates the attachmentto the V, the V node would be left with only one activeattachment.sentential.
In order to maximally satisfy the attach-ment preferences, her is reanalyzed as the specifier ofchildren, with her children replacing her as the firstobject of convinced.
This reanalysis is structurallythe same as that required in Figure 8; the relevant a-nodes have been numbered the same in each figure tohighlight he similarity.
Problems arise when the net-work attaches the next input word, are; see Figure 16.Once again, the misattached NP needs to attach asthe specifier of the following sentential phrase, buta V node would be left with only one active a-nodewhen it requires two.
A garden path once more re-sults from the network settling on an ungrammaticalanalysis.This example highlights another aspect of the com-petitive mechanism of CAPERS in driving the attach-ment behavior of the parser: the only way a pre-vious attachment can be broken is if it participatesin a competition with an attachment to the currentphrase.
A correct parse requires her to break its at-tachment o children and re-attach directly to theverb.
Because the a-node attaching her to childrenhas no competitor, there is no mechanism for chang-ing the problematic attachment.5 SummaryIn each of the examples of Section 4, the initial attach-ment of a phrase was incompatible with the remain-der of the sentence.
CAPERS can recover from anattachment error of this type exactly when the mis-attached phrase can reattach to the current phrase,with the current phrase "replacing" the misattached272cu rr::t@ ' , i    ,,Orentop /  convirtce ~)?,stackherFigure 15: Attaching the NP children requires reanal-ysis of the NP her.currentchildrenherFigure 16: If the NP headed by children activatesthe attachment to the I', the V node would be leftwithout an NP complement.phrase in its original attachment site.
If the p-node towhich the misattached phrase was originally attacheddoes not have an alternative a-node to activate, re-analysis cannot take place and a garden path results.The allowable attachment configurations are a directconsequence of the restrictions imposed by the com-petitive mechanism of CAPERS.
The resulting initialattachment preferences, and the parser's ability or in-ability to revise the incorrect structure, account forthe preferred readings of these temporarily ambigu-ous sentences, as well as the garden path results.ReferencesAbney, S. (1986).
"Functional elements and licensing."
GLOWConference, (-;erona, Spain.Abney, S. (1989).
"A computational model of human parsing.
"Journal of Psycholinguistic Research 18:1, 129-144.Chomsky, N. (1981).
Lectures on Government and Binding: ThePiss Lectures.
Dordrecht: Foris Publications.Chomsky, N. (1986).
Barriers.
Cambridge: MIT PressCottrell, G.W.(1989).
A Connectionist Approach to Word SenseD=sambiguation.
Los Altos, CA: Morgan Kaufmann.Fanty, M. (1985).
"Context-free parsing in connectionist net-works."
Technical Report TR174, University of Rochester.Frazier, L. (1978).
On Comprehending Sentences: SyntacticParsing Strategies.
Doctoral dissertation, University of Connecti-cut.
Bloomington, IN: Indiana University Linguistics Club.Frazier, L., and K. Rayner (1982).
"Making and correcting errorsduring sentence comprehension: Eye movements in the analysis ofstructurally ambiguous sentences."
Cognitive Psychology 14, 178-210.Gibson, E. (1991).
"A Computational Theory of Human Linguis-tic Processing: Memory Limitations and Processing Breakdown.
"Doctoral dissertation, Carnegie-Mellon University.Gorrell, P. (1987).
"Studies of Human Syntactic Processing:Ranked-Parallel versus Serial Models."
Unpublished octoral dis-sertation, University of Connecticut, Storrs, CT.Inoue, A. and J. Fodor (1992).
"Information-paced parsing ofJapanese."
Presented at the Fifth Annual CUNY Conference onHuman Sentence Processing, New York.McRoy, S. and G. Hirst (1990).
"Race-Based Parsing and SyntacticDisambiguation."
Cognitive Science 14, 313-353.Pritchett, B.
(1988).
"Garden Path Phenomena and the Grammat-ical Basis of Language Processing."
Language 64:3, 539-576.Rizzi, L. (1990).
Relativized Minimality.
Cambridge: MIT Press.Reggia, J.
(1987).
"Properties of a Competition-Based ActivationMechanism in Neuromimetic Network Models."
Proceedings of theFirst International Conference on Neural Networks, San Diego,II-131-11-138.Reggia, J., P. Marsland, and R. Berndt (1988).
"Competitive Dy-namics in a Dual-Route Connectionist Model of Print-to-SoundTransformation."
Complex Systems.Selman, G., and G. Hirst (1985).
"A Rule-Based ConnectionistParsing Scheme."
Proceedings of the Seventh Annual Conferenceof the Cognitive Science Society, 212-219.Shieber, S. (1983).
"Sentence Disambiguation by a Shift-ReduceParsing Technique."
Proceedings of the 21st Annual Meeting ofthe Association for Computational Linguistics, 113-118.Stevenson, S. (1993a).
"Establishing Long-Distance Dependenciesin a Hybrid Network Model of Human Parsing."
Proceedings ofthe 15th Annual Conference of the Cognitive Science Society.Stevenson, S. (1993b).
"A Constrained Active Attachment Modelfor Resolving Syntactic Ambiguities in Natural Language Parsing.
"Doctoral dissertation, Computer Science Department, University ofMaryland, College Park.Stevenson, S. (1990).
"A Parallel Constraint Satisfaction andSpreading Activation Model for Resolving Syntactic Ambiguity.
"Proceedings of the Twelfth Annual Conference of the CognitiveScience Society, 396-403.273
