Development of the HRL Route Navigation Dialogue SystemRobert BelvinHRL Laboatories, LLC3011 Malibu Canyon RoadMalibu, CA 90265310-317-5799rsBelvin@hrl.comRon BurnsHRL Laboatories, LLC3011 Malibu Canyon RoadMalibu, CA 90265310-317-5445rBurns@hrl.comCheryl HeinHRL Laboatories, LLC3011 Malibu Canyon RoadMalibu, CA 90265310-317-5489cheryl@hrl.comABSTRACTIn this paper we report on our work on a prototype routenavigation dialogue system for use in a vehicle.
The systemdelivers spoken turn-by-turn directions, and has been developedto accept naturally phrased navigation queries, as part of ouroverall effort to create an in-vehicle information system whichdelivers information as requested while placing minimal cognitiveload on the driver.KeywordsDialogue Systems, Discourse, Navigation, NLP, Pragmatics,Dialogue Manager1.
INTRODUCTIONIn this paper we report on our work on a spoken languagenavigation system which runs in real-time on a high-end laptop orPC, for use in a vehicle.
We focus on issues in developing asystem which can understand natural conversational queries andrespond in such a way as to maximize ease of use for the driver.Because today?s technology has the potential to deliver massiveamounts of information to automobiles, it is crucial to deliver thisinformation in such way that the driver?s attention is not divertedfrom the primary task of safe driving.
Our assumption has beenthat a dialogue system with a near-human conversational abilitywould place less of a cognitive load on the driver than one whichbehaves very differently than a human.We have implemented a testbed on which to develop and evaluatedriver interfaces to navigation systems.
Our approach is multi-modal and the interface will include a head-up display, steeringhub controls, and spoken language, though it is only the lattermodality that we report on here.
We first discuss ourdevelopment phases, and after this we provide an overview of ourimplementation, emphasizing the natural language processingaspects and application interface to the map databases.
Next weprovide results of our initial evaluation of the system, and finallywe draw conclusions and summarize plans for future work.2.
DEVELOPMENT PHASESOne can identify four distinct subproblems which must be solvedfor a navigation system: 1) the natural language navigationinterface, 2) street name recognition, 3) the natural languagedestination entry interface given street name recognition, and 4)the map database interface.
We have partitioned the problem andhave phased our development to progressively implementsolutions with increasing complexity.Navigation system implementation is complicated by the potentialof having a very large street name vocabulary with many unusualand uncommon pronunciations with significant variations acrossspeakers.
The appropriate name space is dynamic since it dependson the location of the vehicle.Our initial system does not accept queries with proper streetnames.
In addition, we assume separate destination entry androute planning systems, and that one or more routes have beenloaded into the navigation system.
The system relies on opendialogue to resolve the directions at any stage of the journey andmay or may not use the Global Positioning System (GPS) todetermine the progress along the route.
By implementing thissystem first we could concentrate on the dialogue aspects of thenavigation problem and also establish a baseline with which tocompare our other implementations.In the second phase we include a limited set of street names aspart of the language model and lexicons.
Initially we are using apredefined set of names with hand tuning of the pronunciations.Additional research is required to solve the street namerecognition problem generally and automatically.
We assume in-vehicle GPS and use a map matching system to determine thevehicle?s position and if it is on-route.
This phase includesdevelopment of the natural language components for destinationentry and also broadens the scope of the navigation queries toinclude questions with and about street names.
More distant plansinclude on-road route replanning, providing information torequests for specific street names or points of interest along theroute, and traffic information and workarounds.3.
IMPLEMENTATIONOur implementation is based on the Galaxy-II system [6] from theMassachusetts Institute of Technology (MIT), which is thebaseline for the Communicator program of the Defense AdvanceResearch Projects Agency (DARPA).
The architecture consists ofa hub client that communicates, using a standard protocol, with anumber of servers as shown in Figure 1.
Each server generallyimplements a key system function including Speech Recognition,Frame Construction (language parsing), Context Tracking,Dialogue Management, Application Interface, LanguageGeneration, and Text-to-speech.
?2001 HRL Laboratories, LLC, All rights reservedSpeechRecognitionLanguageGenerationDialogueManagementApplicationBack-endContextTrackingFrameConstructionAudioServerText-to-speechConversionHubFigure 1.
The client-server architecture of the MIT Galaxy-IIis used to implement our navigation system testbed.3.1 Speech RecognitionWe use the latest MIT SUMMIT recognizer [8] using weightedfinite-state transducers for the lexical access search.
We have also"plugged in" alternate recognizers such as the Microsoft SpeechSDK recognizer and the Sphinx [3] speech recognizer available asopen source code from Carnegie Mellon University.We are in the process of developing a large database of in-vehicleutterances collected in various car models under a wide range ofroad and other background noise conditions.
This data collectionwill be carried out in two phases, the first of which is completed;phase two is underway.
Limited speech data will result from thefirst phase and subtantial speech data (appropriate for trainingacoustic models to represent in-vehicle noise conditions andtesting of recognition engines) will come out of the second phase,and will become available through our partners in this collectioneffort, CSLR at University of Colorado, Boulder [4].
In themeantime we are using the MIT JUPITER acoustic models.
Theperformance is acceptable for our language and dialogue modeldevelopment, but we refrain from presenting any detailedrecognizer results here since they would not reflect fairly onoptimized recognizer performance.Our vocabulary consists of about 400 words without street names.We have an additional 600 street names gleaned from the LosAngeles area where we do much of our system evaluation.Baseforms for the vocabulary are derived from the PRONLEXdictionary from the Linguistic Data Consortium at the Universityof Pennsylvania.
Extensive hand editing is needed especially forthe street names.
The MIT rule set is used for production of wordgraphs for the alternate pronunciation forms.
We have derived alanguage model from a set of utterances that were initiallygenerated based our best guess of the query space.
As evaluationevolves, we modify the utterance list and retrain the languagemodel.
The language model uses classes and includes both bigramand trigram models.3.2 Application InterfaceWe are building the application interface in several phases.Initially we are only answering queries about turns and distancesduring navigation.
We obtain the database in two steps.
First, weaccess a commercial map database using standard text I/O fordestination entry and route planning.
This produces a detailed setof instruction that includes many short segments such as on- andoff-ramps.
We filter this and rewrite the data to provide a set ofnatural driving instructions suitable for verbal communication.The result is a flat database, such as the one shown in Figure 2.This is loaded into to the system and used to formulate answers tothe route queries.
In the example in Figure 2 the estimated drivingtime is 45 minutes.
Each row is a segment of the trip.
The first andsecond columns code right, left, straight, and compass directioninformation.
The third column is the segment length in miles andthe last is the segment name.HRL Airport 450 0  1.0 Malibu Canyon Road0 2 13.3 PCH1 1  3.4 East I-10 freeway0 1  4.5 South I-405 freeway3 0  0.3 Howard Hughes Parkway0 1  1.7 Sepulveda Boulevard0 4  0.4 Los Angeles International AirportFigure 2: Example database used as source data to generateguidance instructions for the route between HRL Laboratoriesand the Los Angeles airportA sample dialogue is shown in Figure 3 which illustrates the kindof responses the system can generate from a database such as thatshown above, given navigation queries of the sort shown; thissample was drawn from our phase I user-system data logs:S Welcome to NavigatorU What routes are loaded?S I have one set of directions loaded.
It isfor the route to the airport from HRLU What?s my first turn?S From Malibu Canyon Road turn left ontoPacific Coast HighwayU And after that?S From Pacific Coast Highway go straightonto East I-10 freewayU How far is that turn?S The distance is 14.3 milesU My odometer reads fifteen point one miles.S Your odometer reading is fifteen point oneU What is my next turn?S From East I-10 freeway turn right ontoSouth I-405 freewayU How far is it from here?S The distance is 2.6 milesU How far is the airport from there?S The distance is 6.7 milesU Bye Bye.S Goodbye.
Have a nice day.Figure 3.
A navigation system dialog illustrating some samplequeries and showing the responses derived by the dialoguemanager based on the database of Figure 2.Off-line construction of the global navigation database is notunrealistic since it could be done, at least in the near term, by aservice organization such as OnStar from General Motors (GM).However as navigation systems become widely deployed, userswill expect destination entry including real time route re-planningto be an integral part of system.
We are developing a direct voiceinterface to the commercial map database that includes destinationentry, route planning, and map matching using GPS data todetermine if the vehicle is on-route or not.During the destination entry phase street names need to berobustly recognized.
We are currently working with a subset ofstreet names in the Los Angeles area preloaded in the recognizerand language models.
It is untenable to keep all of the streetnames in Los Angeles loaded in the recognizer simultaneously(there are around 16,000, including 8,000 base names), thus weare developing a method for dynamic loading of map names localto the vehicle position which we will report on in the near future.We have experimented with using a subset of street names as afilter list, and as a lookup list based on spelling the first fewletters, to try to resolve the destination requested.
If this fails, orif the trip is outside of the area from which names are loaded, werely on more complete spelling to determine the destination.
Theorigin for the route plan is generally implied since it is determinedby the GPS position of the vehicle most of the time.
Once thedestination is determined it is straightforward to continuously re-plan the route based on the current vehicle position and therebybe able to provide remedial instruction if the driver departs fromthe route plan.3.3 NL Analysis and GenerationThe core NLP components in our system are a TINA [5] grammar,context tracking mechanisms, and the GENESIS languagegeneration module.
The TINA grammar includes both syntacticand semantic elements and we try to extract as much informationas possible from the parse.
The information is coded in ahierarchical frame (Figure 4a) as well as a flat key-value pair(Figure 4b).
In addition to handcrafting this grammar, a set ofrules was also developed for the TINA inheritance mechanism.These rules are applied during context tracking, after the parse, toincorporate information from the dialog history into phrases suchas "and after that" and "how about my second turn," and are alsoused to incorporate modifications that are a result of dialoguemanagement.a) Parse frame{c locate:domain "Nav":pred {p locate_object:topic {q turn:quantifier "poss_pro":pred {p ord:topic 2 }}}}b) Key-values Pairs:clause "locate" :locate_object "turn" :ORD 2c) Reply Frame{c speak_turn:topic {q turn:turn_direction "straight":current_roadway "PCH":new_roadway "East I-10 freeway":domain :Nav" }Figure 4.
Example frames produced for the simple query"What?s my second turn?
"As noted, we use the MIT GENESIS server for languagegeneration.
Again this module is rule driven and we developed thelexicon, templates and rewrite rules needed for the three ways weuse GENESIS.
We extract the key-value pairs (e.g.
Figure 4b)from the TINA parse frame.
The key values are used to helpcontrol the dialogue management as well as provide easy access tothe variable values.
We use GENESIS to produce the Englishreply string that is spoken by the synthesizer.
The example framein Figure 4c in conjunction with our rules generates the sentence"From Pacific Coast Highway turn straight onto East I-10freeway" Lastly GENESIS is used to produce an SQL querystring for database access.
Templates and rewrite rules determinewhich form the output from GENESIS will take.
Technically thesethree uses (key-value, reply string, and SQL) are just generationof different languages.3.4 Dialogue ManagementWe have developed servers for dialog management and to controlthe application interface for database query.
The hub architecturesupports use of a control table to direct which server function iscalled.
This is especially useful for dialogue management.
Thecontrol table is specified by a set of rules using logic andarithmetic operations on the key-value pairs.
A well-designed setof rules makes it far easier to visualize the flow and debug thedialogue logic.
For example, when a control rule such as:Clause "locate" !
:from --> turn_from_herefires on the key-value pairs (Figure 4b), the hub calls the turnmanager function "turn_from_here".
In this simplified case, weare assuming if there is no ":from" key, the request is to locate anobject (i.e.
"turn") relative to the vehicle?s current position.
In thiscase the function needs only to extract the value of the key":ORD" and look up the data for the second turn in the databaseof Figure 2.
This data is then written into the response frame, herecalled "speak_turn" and shown in Figure 4c.
GENESIS uses thisframe to generate the English language reply that is spoken by thesynthesizer as described above.In the examples shown here we communicate with the databasefrom the dialogue manager by downloading a flat database such asthat of Figure 2, perhaps via a data link to an off-board serviceorganization such as OnStar.
In cases where we access databasesdirectly, we use a separate server for this function.
Generally,communications between the dialogue manager and databaseservers are routed via the Hub.Our dialogue manager has been designed to use GPS data whenavailable (in which case GPS coordinates would also be a part ofthe database) or to use location information based on currentodometer readings provided as input by drivers when GPS is notavailable.
We use this latter method for demonstrating the systemin a desktop setting, though we have also recently completed autility for employing maps generated by our commercialnavigation database, graphically displaying a driver?s progressalong an imaginary route.
We are now employing this tool as partof our current iteration of system testing and revision.3.4.1 Referential amiguities in driver queriesThe driver can query to determine turn or distance informationrelative to current vehicle position, relative to another turn orreference point in the database, or as an absolute reference intothe route plan stored in the database.
We have devotedconsiderable effort to dealing with ambiguities which may arise asa result of different ways users may be conceptualizing the route(that is, in absolute or relative terms), as well as the driver beingat different points in the route, and at different points in theprogression of a discourse segment.
Queries such as ?what?snext??
can be ambiguous.
Determining the correct interpretationrequires consideration of the discourse history and the user?scircumstances.
For example, in the following dialog sequence(drawn from our data), there are at least two possibleinterpretations for ?what is next??
in the third turn (U:user,S:system):1---------------U:  what?s my next turnS:  From Malibu Canyon Road turn leftonto Pacific Coast Highway.---------------U:  and after thatS:  From Pacific Coast Highway gostraight onto East I-10 freeway---------------?
U:  what?s nextFigure 5.
Sample dialog containing ambiguous ?What is next?.Notice that this query could be requesting information about thenext turn from the driver?s current position (i.e.
the immediatelyapproaching turn), or it could be requesting information about thethird turn from the driver?s current position, that is, the next turnfrom the most recently referred to turn.
We will henceforth referto these two interpretations as next-from-here and next-after-that,respectively.The factor which appears to have the most influence on whichinterpretation is given to this utterance originates neither in theutterance itself nor in the preceding dialog, but is purelycircumstantial, namely, how much time has passed since the lastutterance.
Our assumption has been that there is a kind of time-dependency factor in coherent discourses: while ?what is next?
isstill within the scope of the preceding discourse context, it may(most likely will) be given the next-after-that interpretation.
Butafter a certain length of time has elapsed, ?what is next?
cannot beinterpreted as referring to some previously uttered instruction, butonly as referring to the driver?s current position.
If we think ofthis in terms of the user?s frame of reference for talking abouttheir real or imagined location (we?ll refer to this as the FROMvalue), then we could characterize this phenomenon as the valueof FROM being reset to HERE in the absence of immediatediscourse context.Interpretations of numbered turn references (e.g.
"what's mysecond turn") can also vary depending on another purelycircumstantial factor, namely whether the driver is querying thesystem while preparing to begin the trip, or after she has begundriving.
Some drivers will want to preview trip informationbefore beginning to drive, and in this situation, interpretation ofcertain query types may differ from interpretation done during thetrip.
When the driver is querying the system before beginning todrive, she is more likely to conceive of and speak of the route inan absolute sense (cf.
[7]).
That is, the driver may conceive of theroute as a fixed plan, wherein each turn and segment have aunique and constant order in a sequence.
When conceiving of the1There is at least one further possible interpretation to ?what isnext??
here, at least if the proper prosodic features are present.If heavy emphasis is placed on ?what,?
the query has a quasiecho-question interpretation, indicating either that the user didnot hear, or else is surprised at the prior instruction and isasking for clarification or repetition.route in this way, one may refer to turns by number in the route,rather than by number relative to current position.
Although wehave yet to gather real user data bearing on this question, ourintuition is that once the trip is underway, especially once anysignificant distance has been traveled, if users do use numberedturn references at all, they will be much more likely to use themrelative to their current position.Queries of this type are, for practical purposes, only ambiguousonce the user has begun the trip, but prior to the absolutenumbered turn.
Drivers are very unlikely to be asking about thesecond turn in the route once they have passed the second turn.Moreover, since people will generally only keep track of turnnumbers in the range of 1-3, (give or take 1), numbered turnreferences will only be ambiguous prior to the third or fourth turnin the route (nobody is likely to be asking ?what is the eighth turnin the route?).
What is more, if the user asks a numbered turnquery before beginning the trip, the system response will be thesame, since the relative and absolute turn numbers will at thatpoint coincide.
Thus, the only time a true ambiguity must behandled by the system is the time after the trip is underway, andbefore the fourth turn.
It is perhaps worth noting that if one looksat the overall query interpretation problem as entailing adetermination of whether the user is asking a question relative totheir current position, or some other position, then theabsolute/relative distinction is just a special case that.We have gone on the assumption that there are a substantialnumber of these ambiguous queries, not only for those of the"what's next" type, but also for some numbered turn requests, andfor a class of distance query [1].
However, we have now carriedout an experiment in which subjects interpreted such queries in acontrolled setting, and the results indicate there is far lessambiguity in truly felicitous driver utterances than we originallyhypothesized [2].
There probably will be some genuinelyambiguous queries, especially for a system which is not capable ofdetecting prosodic cues, however, we now are of the opinion thatthey will not comprise a significant percentage of driver queries.For the system which we describe herein, however, the controllogic for queries of the type under discussion includesconsideration of the temporal "reset" threshold discussed above,as indicated in the following table:Table 1.
Decision matrix showing some determining factors forinterpreting ?next?
and numbered turn queries.n-route -- -- ?
-- -- -- --eset thresholdeached-- -- -- -- -- ?ext turn ?
?
?
?umbered turn n n nFrom here?
?
?After that?
?
?QL Turn number c+n c+1 n r+n  r+1 r+1 c+1?
= set c = current positionblank = not set r = most recently mentioned turnn = number value  -- = irrelevantThe table is to be read column-by-column.
Thus, the first columntells us that if we have a query with a numbered turn reference anda phrase which is semantically equivalent to ?from here?
(which isalso the default), then the instruction number which will berequested (via SQL query) from the database is current+number.4.
EVALUATIONWe are have implemented an initial system and are conductingongoing evaluations and iterative enhancements as part of asecond phase of effort.
We are in advanced development on thesecond phase.
We report here on some results of the first phase ofour project.Evaluation of a route guidance system is difficult because themajority of time is spent driving with only a periodic need forinstructions.
Therefore, for the purposes of developing thelanguage and dialogue models we tried to expedite data collectionby having dialogues in which the user simulated a trip by meansof a more or less continuous conversation with the system.
Theposition of the vehicle along the route was determined by the userproviding odometer readings relative to the start of the trip.
Ateach point the user would query the system and input a newodometer location along the route and continue the dialogue.While certainly not as meaningful as queries under normal drivingcondition, we did obtain good data for our recognizer languagemodel and grammar coverage.
In addition we could debug andtune our turn manager functions to make sure we were properlyaccessing the database and providing correct responses.Each query essentially represents a single task and the mostmeaningful metric for this type of system seems to be the numberof dialogue turns per correct response.
By correct response wemean that the system provides the final answer versus providing arequest to repeat or disambiguate the user query.
We haveaccumulated several thousand utterances during dialogues that runaround fifteen to twenty turns per session for a simple route likethe one in Figure 2.
About a third of the utterances are used to setthe vehicle position via inputting odometer data.We can also divide the dialogues into task oriented dialogues,where the user is trying to get helpful answers, and dialogueswhere the user is exploring the limits of the system.
We find withthe task oriented dialogues that the number of dialogue turns areabout 15-20% greater that the number of correct responses andthat the inital implementations even without street namerecognition is a useful system.5.
SUMMARY AND FUTURE PLANSWe have reported on our initial implementation and results for anin-vehicle navigation system through the first phase of our systemdevelopment effort and into the second phase.
Full exploitation ofthe natural language interface is not fully completed in the firstphase because we are still developing an operational in-vehiclenavigation system to integrate with our dialogue system.
The fullinterface, including destination entry, route planning, positiontracking, and map matching will be available later this year.
Wehave, however, developed most of the NL components needed foraccessing the database functionality as it comes on-line.
We planto add other important functionality such as points-of-interest andtraffic conditions as the project progresses.Two other major elements need to be further explored to gain fullsystem functionality.
The first is recognizer robustness in thepresence of in-vehicle noise during normal everyday use; thesecond is the street name recognition and pronunciation synthesisproblem.
Recognizer performance is being addressed by means ofa full-scale data collection and corpora development project, incollaboration with GM and the Center for Spoken LanguageResearch at the University of Colorado at Boulder.
This work willprovide the in-vehicle acoustic data needed to re-train therecognizer models as well as provide a database for developingnoise-mitigation and speaker adaptation algorithms for improvingrecognizer performance.
We are developing a method for dynamicloading of street names which we will report on in the near future.Acknowledgments.
This work was supported in part by aresearch contract from General Motors.6.
REFERENCES[1] R. Belvin, R. Burns and C Hein "What?s next: A Case Studyin the Multidimensionality of a Dialogue System,"Proceedings of ICSLP 2000, Beijing, China, October 2000.
[2] A. Kessell and R. Belvin "Unambiguous AmiguousQuestions: Pronominal Resolution in Human-to-HumanNavigation," unpublished ms., HRL Laboratories, 2001.
[3] K-F. Lee, Automatic Speech Recognition: The Developmentof the Sphinx System, Kluwer, Boston, 1989.
[4] B. Pellom, W. Ward, J. Hansen, K. Hacioglu, J. Zhang, X.Yu, and S. Pradhan, "University of Colorado DialogSystems for Travel and Navigation," these proceedings,2001.
[5] S. Seneff.
"TINA: A Natural Language System for SpokenLanguage Applications," Computational Linguistics, Vol.18, No.
1, pp.
61-86, 1992.
[6] S. Seneff, E. Hurley, R. Lau, C. Pao, P. Schmidt and V.Zue, "Galaxy-II: A Reference Architecture ForConversational System Development," Proc.
ICSLP '98, pp.931-934, Sydney, Australia, November 1998.
[7] L. Suchman.
Plans and situated actions.
CambridgeUniversity Press, Cambridge, 1987.
[8] V. Zue, S. Seneff, J.
Glass, J. Polifroni, C. Pao, T. Hazen &L. Heatherington, ?Jupiter: A Telephone-BasedConversational Interface for Weather Information,?IEEE:Transactions on Speech and Audio Processing, Vol.8, No.
1, pp.
85-96, 2000.
