Proceedings of the Workshop on Language in Social Media (LASM 2013), pages 11?19,Atlanta, Georgia, June 13 2013. c?2013 Association for Computational LinguisticsPhonological Factors in Social Media WritingJacob Eisensteinjacobe@gatech.eduSchool of Interactive ComputingGeorgia Institute of TechnologyAbstractDoes phonological variation get transcribedinto social media text?
This paper investigatesexamples of the phonological variable of con-sonant cluster reduction in Twitter.
Not onlydoes this variable appear frequently, but it dis-plays the same sensitivity to linguistic contextas in spoken language.
This suggests that whensocial media writing transcribes phonologicalproperties of speech, it is not merely a case ofinventing orthographic transcriptions.
Rather,social media displays influence from structuralproperties of the phonological system.1 IntroductionThe differences between social media text and otherforms of written language are a subject of increas-ing interest for both language technology (Gimpelet al 2011; Ritter et al 2011; Foster et al 2011)and linguistics (Androutsopoulos, 2011; Dresner andHerring, 2010; Paolillo, 1996).
Many words thatare endogenous to social media have been linkedwith specific geographical regions (Eisenstein et al2010; Wing and Baldridge, 2011) and demographicgroups (Argamon et al 2007; Rao et al 2010; Eisen-stein et al 2011), raising the question of whetherthis variation is related to spoken language dialects.Dialect variation encompasses differences at multi-ple linguistic levels, including the lexicon, morphol-ogy, syntax, and phonology.
While previous workon group differences in social media language hasgenerally focused on lexical differences, this paperconsiders the most purely ?spoken?
aspect of dialect:phonology.Specifically, this paper presents evidence againstthe following two null hypotheses:?
H0: Phonological variation does not impact so-cial media text.?
H1: Phonological variation may introduce newlexical items into social media text, but not theunderlying structural rules.These hypotheses are examined in the context ofthe phonological variable of consonant cluster reduc-tion (also known as consonant cluster simplification,or more specifically, -/t,d/ deletion).
When a wordends in cluster of consonant sounds ?
for exam-ple, mist or missed ?
the cluster may be simplified,for example, to miss.
This well-studied variable hasbeen demonstrated in a number of different Englishdialects, including African American English (Labovet al 1968; Green, 2002), Tejano and Chicano En-glish (Bayley, 1994; Santa Ana, 1991), and BritishEnglish (Tagliamonte and Temple, 2005); it has alsobeen identified in other languages, such as Quebe-cois French (Co?te?, 2004).
While some previous workhas cast doubt on the influence of spoken dialects onwritten language (Whiteman, 1982; Thompson et al2004), this paper presents large-scale evidence forconsonant cluster reduction in social media text fromTwitter ?
in contradiction of the null hypothesis H0.But even if social media authors introduce neworthographic transcriptions to capture the sound oflanguage in the dialect that they speak, such innova-tions may be purely lexical.
Phonological variationis governed by a network of interacting preferencesthat include the surrounding linguistic context.
Do11these structural aspects of phonological variation alsoappear in written social media?Consonant cluster reduction is a classic exampleof the complex workings of phonological variation:its frequency depends on the morphology of the wordin which it appears, as well as the phonology of thepreceding and subsequent segments.
The variableis therefore a standard test case for models of theinteraction between phonological preferences (Guy,1991).
For our purposes, the key point is that con-sonant cluster reduction is strongly inhibited whenthe subsequent phonological segment begins with avowel.
The final t in left is more likely to be deletedin I left the house than in I left a tip.
Guy (1991)writes, ?prior studies are unanimous that a followingconsonant promotes deletion more readily than a fol-lowing vowel,?
and more recent work continues touphold this finding (Tagliamonte and Temple, 2005).Consonant cluster reduction thus provides an op-portunity to test the null hypothesis H1.
If the intro-duction of phonological variation into social mediawriting occurs only on the level of new lexical items,that would predict that reduced consonant clusterswould be followed by consonant-initial and vowel-initial segments at roughly equal rates.
But if conso-nant cluster reduction is inhibited by adjacent vowel-initial segments in social media text, that would argueagainst H1.
The experiments in this paper provide ev-idence of such context-sensitivity, suggesting that theinfluence of phonological variation on social mediatext must be deeper than the transcription of inviduallexical items.2 Word pairsThe following word pairs were considered:?
left / lef?
just / jus?
with / wit?
going / goin?
doing / doin?
know / knoThe first two pairs display consonant cluster re-duction, specifically t-deletion.
As mentioned above,consonant cluster reduction is a property of AfricanAmerican English (AAE) and several other Englishdialects.
The pair with/wit represents a stoppingof the interdental fricative, a characteristic of NewYork English (Gordon, 2004), rural Southern En-glish (Thomas, 2004), as well as AAE (Green, 2002).The next two pairs represent ?g-dropping?, the re-placement of the velar nasal with the coronal nasal,which has been associated with informal speech inmany parts of the English-speaking world.1 The finalword pair know/kno does not differ in pronunciation,and is included as a control.These pairs were selected because they are allfrequently-used words, and because they cover arange of typical ?shortenings?
in social media andother computer mediated communication (Gouws etal., 2011).
Another criterion is that each shortenedform can be recognized relatively unambiguously.Although wit and wan are standard English words,close examination of the data did not reveal any ex-amples in which the surface forms could be construedto indicate these words.
Other words were rejectedfor this reason: for example, best may be reducedto bes, but this surface form is frequently used as anacronym for Blackberry Enterprise Server.Consonant cluster reduction may be combinedwith morphosyntactic variation, particularly inAfrican American English.
Thompson et al(2004)describe several such cases: zero past tense (motherkiss(ed) them all goodbye), zero plural (the childrenmade their bed(s)), and subject-verb agreement (thenshe jump(s) on the roof ).
In each of these cases, it isunclear whether it is the morphosyntactic or phono-logical process that is responsible for the absence ofthe final consonant.
Words that feature such ambigu-ity, such as past, were avoided.Table 1 shows five randomly sampled examplesof each shortened form.
Only the relevant portionof each message is shown.
From consideration ofmany examples such as these, it is clear that theshortened forms lef, jus, wit, goin, doin, kno refer tothe standard forms left, just, with, going, doing, knowin the overwhelming majority of cases.1Language Log offers an engaging discussion of thelinguistic and cultural history of ?g-dropping.?
http://itre.cis.upenn.edu/?myl/languagelog/archives/000878.html121.
ok lef the y had a good workout(ok, left the YMCA, had a good workout)2.
@USER lef the house3.
eat off d wol a d rice and lef d meat(... left the meat)4. she nah lef me(she has not left me)5. i lef my changer6.
jus livin this thing called life7.
all the money he jus took out the bank8.
boutta jus strt tweatin random shxt(about to just start tweeting ...)9. i jus look at shit way different10.
u jus fuckn lamee11.
fall in love wit her12.
i mess wit pockets13.
da hell wit u(the hell with you)14. drinks wit my bro15.
don?t fuck wit him16.
a team that?s goin to continue17.
what?s goin on tonight18.
is reign stil goin down19.
when is she goin bck 2 work?20.
ur not goin now where(you?re not going nowhere)21. u were doin the same thing22.
he doin big things23.
i?m not doin shit this weekend24.
oh u doin it for haiti huh25.
i damn sure aint doin it in the am26.
u kno u gotta put up pics27.
i kno some people bout to be sick28.
u already kno29.
you kno im not ugly pendeja30.
now i kno why i?m always on netflixTable 1: examples of each shortened form3 DataOur research is supported by a dataset of microblogposts from the social media service Twitter.
This ser-vice allows its users to post 140-character messages.Each author?s messages appear in the newsfeeds ofindividuals who have chosen to ?follow?
the author,though by default the messages are publicly availableto anyone on the Internet.
Twitter has relatively broadpenetration across different ethnicities, genders, andincome levels.
The Pew Research Center has repeat-edly polled the demographics of Twitter (Smith andBrewer, 2012), finding: nearly identical usage amongwomen (15% of female internet users are on Twit-ter) and men (14%); high usage among non-HispanicBlacks (28%); an even distribution across income andeducation levels; higher usage among young adults(26% for ages 18-29, 4% for ages 65+).Twitter?s streaming API delivers an ongoing ran-dom sample of messages from the complete set ofpublic messages on the service.
The data in thisstudy was gathered from the public ?Gardenhose?feed, which is claimed to be approximately 10% ofall public posts; however, recent research suggeststhat the sampling rate for geolocated posts is muchhigher (Morstatter et al 2013).
This data was gath-ered over a period from August 2009 through theend of September 2012, resulting in a total of 114million messages from 2.77 million different useraccounts (Eisenstein et al 2012).Several filters were applied to ensure that thedataset is appropriate for the research goals of this pa-per.
The dataset includes only messages that containgeolocation metadata, which is optionally providedby smartphone clients.
Each message must have alatitude and longitude within a United States censusblock, which enables the demographic analysis inSection 6.
Retweets are excluded (both as identifiedin the official Twitter API, as well as messages whosetext includes the token ?RT?
), as are messages thatcontain a URL.
Grouping tweets by author, we retainonly authors who have fewer than 1000 ?followers?
(people who have chosen to view the author?s mes-sages in their newsfeed) and who follow fewer than1000 individuals.Specific instances of the word pairs are acquired byusing grep to identify messages in which the short-ened form is followed by another sequence of purely13alphabetic characters.
Reservoir sampling (Vitter,1985) was used to obtain a randomized set of at most10,000 messages for each word.
There were only 753examples of the shortening lef ; for all other words weobtain the full 10,000 messages.
For each shortenedword, an equal number of samples for the standardform were obtained through the same method: greppiped through a reservoir sampler.
Each instanceof the standard form must also be followed by apurely alphabetic string.
Note that the total numberof instances is slightly higher than the number ofmessages, because a word may appear multiple timeswithin the same message.
The counts are shown inTable 2.4 Analysis 1: Frequency of vowels afterword shorteningThe first experiment tests the hypothesis that con-sonant clusters are less likely to be reduced whenfollowed by a word that begins with a vowel letter.Table 2 presents the counts for each term, along withthe probability that the next segment begins with thevowel.
The probabilities are accompanied by 95%confidence intervals, which are computed from thestandard deviation of the binomial distribution.Alldifferences are statistically significant at p < .05.The simplified form lef is followed by a vowelonly 19% of the time, while the complete form left isfollowed by a vowel 35% of the time.
The absolutedifference for jus and just is much smaller, but withsuch large counts, even this 2% absolute differenceis unlikely to be a chance fluctuation.The remaining results are more mixed.
The short-ened form wit is significantly more likely to be fol-lowed by a vowel than its standard form with.
Thetwo ?g dropping?
examples are inconsistent, and trou-blingly, there is a significant effect in the controlcondition.
For these reasons, a more fine-grainedanalysis is pursued in the next section.A potential complication to these results is thatcluster reduction may be especially likely in specificphrases.
For example, most can be reduced to mos,but in a sample of 1000 instances of this reduction,72% occurred within a single expression: mos def.This phrase can be either an expression of certainty(most definitely), or a reference to the performingartist of the same name.
If mos were observed toword N N(vowel) P(vowel)lef 753 145 0.193 ?
0.028left 757 265 0.350 ?
0.034jus 10336 939 0.091 ?
0.006just 10411 1158 0.111 ?
0.006wit 10405 2513 0.242 ?
0.008with 10510 2328 0.222 ?
0.008doin 10203 2594 0.254 ?
0.008doing 10198 2793 0.274 ?
0.009goin 10197 3194 0.313 ?
0.009going 10275 1821 0.177 ?
0.007kno 10387 3542 0.341 ?
0.009know 10402 3070 0.295 ?
0.009Table 2: Term counts and probability with which the fol-lowing segment begins with a vowel.
All differences aresignificant at p < .05.be more likely to be followed by a consonant-initialword than most, this might be attributable to this oneexpression.An inverse effect could explain the high likelihoodthat goin is followed by a vowel.
Given that theauthor has chosen an informal register, the phrasegoin to is likely to be replaced by gonna.
One mighthypothesize the following decision tree:?
If formal register, use going?
If informal register,?
If next word is to, use gonna?
else, use goinCounts for each possibility are shown in Table 3;these counts are drawn from a subset of the 100,000messages and thus cannot be compared directly withTable 2.
Nonetheless, since to is by far the mostfrequent successor to going, a great deal of going?spreference for consonant successors can be explainedby the word to.5 Analysis 2: Logistic regression to controlfor lexical confoundsWhile it is tempting to simply remove going to andgoin to from the dataset, this would put us on a slip-pery slope: where do we draw the line between lexi-cal confounds and phonological effects?
Rather than14total ... to percentagegoing 1471 784 53.3%goin 470 107 22.8%gonna 1046 n/a n/aTable 3: Counts for going to and related phrases in the first100,000 messages in the dataset.
The shortened form goinis far less likely to be followed by to, possibly because ofthe frequently-chosen gonna alternative.word ??
??
z plef/left -0.45 0.10 -4.47 3.9?
10?6jus/just -0.43 0.11 -3.98 3.4?
10?5wit/with -0.16 0.03 -4.96 3.6?
10?7doin/doing 0.08 0.04 2.29 0.011goin/going -0.07 0.05 -1.62 0.053kno/know -0.07 0.05 -1.23 0.11Table 4: Logistic regression coefficients for the VOWELfeature, predicting the choice of the shortened form.
Nega-tive values indicate that the shortened form is less likely iffollowed by a vowel, when controlling for lexical features.excluding such examples from the dataset, it wouldbe preferable to apply analytic techniques capable ofsorting out lexical and systematic effects.
One suchtechnique is logistic regression, which forces lexicaland phonological factors to compete for the right toexplain the observed orthographic variations.2The dependent variable indicates whether theword-final consonant cluster was reduced.
The inde-pendent variables include a single feature indicatingwhether the successor word begins with a vowel, andadditional lexical features for all possible successorwords.
If the orthographic variation is best explainedby a small number of successor words, the phono-logical VOWEL feature will not acquire significantweight.Table 4 presents the mean and standard deviationof the logistic regression coefficient for the VOWELfeature, computed over 1000 bootstrapping itera-tions (Wasserman, 2005).3 The coefficient has the2(Stepwise) logistic regression has a long history in varia-tionist sociolinguistics, particularly through the ubiquitous VAR-BRUL software (Tagliamonte, 2006).3An L2 regularization parameter was selected by randomlysampling 50 training/test splits.
Average accuracy was between58% and 66% on the development data, for the optimal regular-ization coefficient.largest magnitude in cases of consonant cluster re-duction, and the associated p-values indicate strongstatistical significance.
The VOWEL coefficient isalso strongly significant for wit/with.
It reaches thep < .05 threshold for doin/doing, although in thiscase, the presence of a vowel indicates a preferencefor the shortened form doin ?
contra the raw fre-quencies in Table 2.
The coefficient for the VOWELfeature is not significantly different from zero forgoin/going and for the control kno/know.
Note thatsince we had no prior expectation of the coefficientsign in these cases, a two-tailed test would be mostappropriate, with critical value ?
= 0.025 to estab-lish 95% confidence.6 Analysis 3: Social variablesThe final analysis concerns the relationship betweenphonological variation and social variables.
In spo-ken language, the word pairs chosen in this studyhave connections with both ethnic and regional di-alects: consonant cluster reduction is a feature ofAfrican-American English (Green, 2002) and Te-jano and Chicano English (Bayley, 1994; Santa Ana,1991); th-stopping (as in wit/with) is a feature ofAfrican-American English (Green, 2002) as well asseveral regional dialects (Gordon, 2004; Thomas,2004); the velar nasal in doin and goin is a propertyof informal speech.
The control pair kno/know doesnot correspond to any sound difference, and thusthere is no prior evidence about its relationship tosocial variables.The dataset includes the average latitude and lon-gitude for each user account in the corpus.
It is possi-ble to identify the county associated with the latitudeand longitude, and then to obtain county-level de-mographic statistics from the United States census.An approximate average demographic profile foreach word in the study can be constructed by ag-gregating the demographic statistics for the countiesof residence of each author who has used the word.Twitter users do not comprise an unbiased samplefrom each county, so this profile can only describe thedemographic environment of the authors, and not thedemographic properties of the authors themselves.Results are shown in Figure 1.
The confidenceintervals reflect the Bonferroni correction for mul-tiple comparison, setting ?
= 0.05/48.
The con-15lef left jus just wit with goin going doin doing kno know1618202224262830%blacklef left jus just wit with goin going doin doing kno know6062646668707274%whitelef left jus just wit with goin going doin doing kno know141618202224%hispaniclef left jus just wit with goin going doin doing kno know200040006000800010000120001400016000pop.densityFigure 1: Average demographics of the counties in which users of each term live, with 95% confidence intervals16sonant cluster reduction examples are indeed pre-ferred by authors from densely-populated (urban)counties with more African Americans, althoughthese counties tend to prefer all of the non-standardvariants, including the control pair kno/know.
Con-versely, the non-standard variants have aggregatedemographic profiles that include fewer EuropeanAmericans.
None of the differences regarding thepercentage of Hispanics/Latinos are statistically sig-nificant.
Overall, these results show an associa-tion between non-standard orthography and densely-populated counties with high proportions of AfricanAmericans, but we find no special affinity for conso-nant cluster reduction.7 Related workPrevious studies of the impact of dialect on writ-ing have found relatively little evidence of purelyphonological variation in written language.
White-man (1982) gathered an oral/written dataset of inter-view transcripts and classroom compositions.
In thewritten data, there are many examples of final con-sonant deletion: verbal -s (he go- to the pool), plural-s (in their hand-), possessive -s (it is Sally- radio),and past tense -ed.
However, each of these deletionsis morphosyntactic rather than purely phonological.They are seen by Whiteman as an omission of theinflectional suffix, rather than as a transcription ofphonological variation, which she finds to be veryrare in cases where morphosyntactic factors are not inplay.
She writes, ?nonstandard phonological featuresrarely occur in writing, even when these features areextremely frequent in the oral dialect of the writer.
?Similar evidence is presented by Thompson et al(2004), who compare the spoken and written lan-guage of 50 third-grade students who were identi-fied as speakers of African American English (AAE).While each of these students produced a substantialamount of AAE in spoken language, they producedonly one third as many AAE features in the writtensample.
Thompson et alfind almost no instancesof purely phonological features in writing, includingconsonant cluster reduction ?
except in combina-tion with morphosyntactic features, such as zero pasttense (e.g.
mother kiss(ed) them all goodbye).
Theypropose the following explanation:African American students have modelsfor spoken AAE; however, children do nothave models for written AAE... studentslikely have minimal opportunities to ex-perience AAE in print (emphasis in theoriginal).This was written in 2004; in the intervening years,social media and text messages now provide manyexamples of written AAE.
Unlike classroom settings,social media is informal and outside the scope ofschool control.
Whether the increasing prevalence ofwritten AAE will ultimately lead to widely-acceptedwriting systems for this and other dialects is an in-triguing open question.8 Conclusions and future workThe experiments in this paper demonstrate thatphonology impacts social media orthography at theword level and beyond.
I have discussed examples ofthree such phenomena: consonant cluster reduction,th-stopping, and the replacement of the velar nasalwith the coronal (?g-dropping?).
Both consonantcluster reduction and th-stopping are significantly in-fluenced by the phonological context: their frequencydepends on whether the subsequent segment beginswith a vowel.
This indicates that when social mediaauthors transcribe spoken language variation, theyare not simply replacing standard spellings of indi-vidual words.
The more difficult question ?
howphonological context enters into writing ?
must beleft for future work.There are several other avenues along which to con-tinue this research.
The sociolinguistic literature de-scribes a number of other systematic factors that im-pact consonant cluster reduction (Guy, 1991; Taglia-monte and Temple, 2005), and a complete model thatincluded all such factors might shed additional lighton this phenomenon.
In such work it is typical to dis-tinguish between different types of consonants; forexample, Tagliamonte and Temple (2005) distinguishobstruents, glides, pauses, and the liquids /r/ and /l/.In addition, while this paper has equated consonantletters with consonant sounds, a more careful analy-sis might attempt to induce (or annotate) the pronun-ciation of the relevant words.
The speech synthesisliterature offers numerous such methods (Bisani andNey, 2008), though social media text may pose new17challenges, particularly for approaches that are basedon generalizing from standard pronunciation dictio-naries.One might also ask whether the phonological sys-tem impacts all authors to the same extent.
Labov(2007) distinguishes two forms of language change:transmission, where successive generations of chil-dren advance a sound change, and diffusion, wherelanguage contact leads adults to ?borrow?
aspectsof other languages or dialects.
Labov marshalls ev-idence from regional sound changes to show thattransmission is generally more structural and reg-ular, while diffusion is more superficial and irreg-ular; this may be attributed to the ability of childlanguage learners to recognize structural linguisticpatterns.
Does phonological context impact transcrip-tion equally among all authors in our data, or can weidentify authors whose use of phonological transcrip-tion is particularly sensitive to context?AcknowledgmentsThanks to Brendan O?Connor for building the Twitterdataset that made this research possible.
Thanks tothe reviewers for their helpful comments.ReferencesJannis Androutsopoulos.
2011.
Language change anddigital media: a review of conceptions and evidence.
InNikolas Coupland and Tore Kristiansen, editors, Stan-dard Languages and Language Standards in a Chang-ing Europe.
Novus, Oslo.S.
Argamon, M. Koppel, J. Pennebaker, and J. Schler.2007.
Mining the blogosphere: age, gender, and thevarieties of self-expression.
First Monday, 12(9).Robert Bayley.
1994.
Consonant cluster reductionin tejano english.
Language Variation and Change,6(03):303?326.Maximilian Bisani and Hermann Ney.
2008.
Joint-sequence models for grapheme-to-phoneme conversion.Speech Commun., 50(5):434?451, May.Marie-He?le`ne Co?te?.
2004.
Consonant cluster simplifica-tion in Que?bec French.
Probus: International journalof Latin and Romance linguistics, 16:151?201.E.
Dresner and S.C.
Herring.
2010.
Functions of thenonverbal in cmc: Emoticons and illocutionary force.Communication Theory, 20(3):249?268.Jacob Eisenstein, Brendan O?Connor, Noah A. Smith, andEric P. Xing.
2010.
A latent variable model for geo-graphic lexical variation.
In Proceedings of EMNLP.Jacob Eisenstein, Noah A. Smith, and Eric P. Xing.
2011.Discovering sociolinguistic associations with structuredsparsity.
In Proceedings of ACL.Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,and Eric P. Xing.
2012.
Mapping the geographicaldiffusion of new words, October.Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,Joseph Le Roux, Joakim Nivre, Deirdre Hogan, andJosef van Genabith.
2011.
From news to comment:Resources and benchmarks for parsing the language ofweb 2.0.
In Proceedings of IJCNLP.Kevin Gimpel, Nathan Schneider, Brendan O?Connor, Di-panjan Das, Daniel Mills, Jacob Eisenstein, MichaelHeilman, Dani Yogatama, Jeffrey Flanigan, andNoah A. Smith.
2011.
Part-of-speech tagging for twit-ter: annotation, features, and experiments.
In Proceed-ings of ACL.Matthew J. Gordon, 2004.
A Handbook of Varieties ofEnglish, chapter New York, Philadelphia, and othernorthern cities, pages 282?299.
Volume 1 of Kortmannet al(Kortmann et al 2004).Stephan Gouws, Dirk Hovy, and Donald Metzler.
2011.Unsupervised mining of lexical variants from noisy text.In Proceedings of the First workshop on UnsupervisedLearning in NLP, pages 82?90, Edinburgh, Scotland,July.
Association for Computational Linguistics.Lisa J.
Green.
2002.
African American English: ALinguistic Introduction.
Cambridge University Press,September.Gregory R. Guy.
1991.
Contextual conditioning invariable lexical phonology.
Language Variation andChange, 3:223?239, June.Bernd Kortmann, Edgar W. Schneider, and Kate Burridgeet al editors.
2004.
A Handbook of Varieties of En-glish, volume 1.
Mouton de Gruyter, Berlin, Boston.William Labov, Paul Cohen, Clarence Robins, and JohnLewis.
1968.
A study of the Non-Standard englishof negro and puerto rican speakers in new york city.Technical report, United States Office of Education,Washington, DC.William Labov.
2007.
Transmission and diffusion.
Lan-guage, 83(2):344?387.Fred Morstatter, Jurgen Pfeffer, Huan Liu, and Kathleen M.Carley.
2013.
Is the sample good enough?
comparingdata from twitter?s streaming api with twitter?s firehose.In Proceedings of ICWSM.John C. Paolillo.
1996.
Language choice onsoc.culture.punjab.
Electronic Journal of Communi-cation/La Revue Electronique de Communication, 6(3).Delip Rao, David Yarowsky, Abhishek Shreevats, andManaswi Gupta.
2010.
Classifying latent user at-tributes in twitter.
In Proceedings of Workshop onSearch and mining user-generated contents.18Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.
2011.Named entity recognition in tweets: an experimentalstudy.
In Proceedings of EMNLP.Otto Santa Ana.
1991.
Phonetic simplification processesin the English of the barrio: A cross-generational soci-olinguistic study of the Chicanos of Los Angeles.
Ph.D.thesis, University of Pennsylvania.Aaron Smith and Joanna Brewer.
2012.
Twitter use 2012.Technical report, Pew Research Center, May.Sali Tagliamonte and Rosalind Temple.
2005.
New per-spectives on an ol?
variable: (t,d) in british english.Language Variation and Change, 17:281?302, Septem-ber.Sali A. Tagliamonte.
2006.
Analysing SociolinguisticVariation.
Cambridge University Press.Erik R Thomas, 2004.
A Handbook of Varieties of English,chapter Rural Southern white accents, pages 87?114.Volume 1 of Kortmann et al(Kortmann et al 2004).Connie A. Thompson, Holly K. Craig, and Julie A. Wash-ington.
2004.
Variable production of african americanenglish across oracy and literacy contexts.
Language,speech, and hearing services in schools, 35(3):269?282,July.Jeffrey S. Vitter.
1985.
Random sampling with a reservoir.ACM Trans.
Math.
Softw., 11(1):37?57, March.Larry Wasserman.
2005.
All of Nonparametric Statistics(Springer Texts in Statistics).
Springer, October.Marcia F. Whiteman.
1982.
Dialect influence in writing.In Marcia Farr Whiteman and Carl, editors, Writing:The Nature, Development, and Teaching of WrittenCommunication, volume 1: Variation in writing.
Rout-ledge, October.Benjamin Wing and Jason Baldridge.
2011.
Simple su-pervised document geolocation with geodesic grids.
InProceedings of ACL.19
