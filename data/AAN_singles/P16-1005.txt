Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 44?53,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsUnsupervised Person Slot Filling based on Graph MiningDian Yu Heng JiComputer Science DepartmentRensselaer Polytechnic InstituteTroy, NY 12180, USA{yud2,jih}@rpi.eduAbstractSlot filling aims to extract the values (slotfillers) of specific attributes (slots types)for a given entity (query) from a large-scale corpus.
Slot filling remains verychallenging over the past seven years.
Wepropose a simple yet effective unsuper-vised approach to extract slot fillers basedon the following two observations: (1) atrigger is usually a salient node relative tothe query and filler nodes in the depen-dency graph of a context sentence; (2) arelation is likely to exist if the query andcandidate filler nodes are strongly con-nected by a relation-specific trigger.
Thuswe design a graph-based algorithm to au-tomatically identify triggers based on per-sonalized PageRank and Affinity Prop-agation for a given (query, filler) pairand then label the slot type based on theidentified triggers.
Our approach achieves11.6%-25% higher F-score over state-of-the-art English slot filling methods.
Ourexperiments also demonstrate that as longas a few trigger seeds, name tagging anddependency parsing capabilities exist, thisapproach can be quickly adapted to anylanguage and new slot types.
Our promis-ing results on Chinese slot filling can serveas a new benchmark.1 IntroductionThe goal of the Text Analysis Conference Knowl-edge Base Population (TAC-KBP) Slot Filling(SF) task (McNamee and Dang, 2009; Ji et al,2010; Ji et al, 2011; Surdeanu and Ji, 2014) isto extract the values (fillers) of specific attributes(slot types) for a given entity (query) from a large-scale corpus and provide justification sentencesto support these slot fillers.
KBP defines 25 slottypes for persons (e.g., spouse) and 16 slots fororganizations (e.g., founder).
For example, givena person query ?Dominich Dunne?
and slot typespouse, a SF system may extract a slot filler ?EllenGriffin?
and its justification sentence E1 as shownin Figure 1.E1:   Ellen Griffin Dunne, from whom he was divorced in 1965, died in 1997.Ellen Griffin Dunnewhominhe was 1965Dominick Dunne in1997fromcasenmod nsubjpass auxpass nmodcase coreference casePersonPerson | QueryYearYeardieddivorcedFigure 1: Extended dependency tree for E1.Slot filling remains a very challenging task.
Thetwo most successful state-of-the-art techniques areas follows.
(1) Supervised classification.
Consideringany pair of query and candidate slot filler asan instance, these approaches train a classifierfrom manually labeled data through activelearning (Angeli et al, 2014b) or noisy labeleddata through distant supervision (Angeli et al,2014a; Surdeanu et al, 2010) to predict theexistence of a specific relation between them.
(2) Pattern matching.
These approaches extractand generalize lexical and syntactic patterns auto-matically or semi-automatically (Sun et al, 2011;Li et al, 2012; Yu et al, 2013; Hong et al, 2014).They usually suffer from low recall due to nu-merous different ways to express a certain relationtype (Surdeanu and Ji, 2014).
For example, noneof the top-ranked patterns (Li et al, 2012) basedon dependency paths in Table 1 can capture thespouse slot in E1.44Query poss?1Slot FillerQuery poss?1[wife-widow-husband] appos Slot FillerQuery nsubj?1married dobj Slot FillerQuery appos wife prep of Slot FillerQuery nsubjpass?1survived agent Slot FillerTable 1: Dependency patterns for slot spouse.Both of the previous methods have poor porta-bility to a new language or a new slot type.Furthermore, both methods focus on the flat re-lation representation between the query and thecandidate slot filler, while ignoring the globalgraph structure among them and other facts in thecontext.When multiple facts about a person entity arepresented in a sentence, the author (e.g., a newsreporter or a discussion forum poster) often usesexplicit trigger words or phrases to indicate theirrelations with the entity.
As a result, these inter-dependent facts and query entities are stronglyconnected via syntactic or semantic relations.Many slot types, especially when the queriesare person entities, are indicated by such triggers.We call these slots trigger-driven slots.
In thispaper, we define a trigger as the smallest extent ofa text which most clearly indicates a slot type.
Forexample, in E1, ?divorced?
is a trigger for spousewhile ?died?
is a trigger for death-related slots.Considering the limitations of previous flat rep-resentations for the relations between a query (Q)and a candidate slot filler (F ), we focus on analyz-ing the whole dependency tree structure that con-nects Q, F and other semantically related wordsor phrases in each context sentence.
Our mainobservation is that there often exists a trigger word(T ) which plays an important role in connectingQ and F in the dependency tree for trigger-drivenslots.
From the extended dependency tree shownin Figure 1, we can clearly see that ?divorced?is most strongly connected to the query mention(?he?)
and the slot filler (?Ellen Griffin Dunne?
).Therefore we can consider it as a trigger wordwhich explicitly indicates a particular slot type.Based on these observations, we propose anovel and effective unsupervised graph miningapproach for person slot filling by deeply explor-ing the structures of dependency trees.
It consistsof the following three steps:?
Step 1 - Candidate Relation Identification:Construct an extended dependency tree for eachsentence including any mention referring to thequery entity.
Identify candidate slot fillers basedon slot type constraints (e.g., the spouse fillersare limited to person entities) (Section 2).?
Step 2 - Trigger Identification: Measure theimportance of each node in the extended depen-dency tree relative to Q and F , rank them andselect the most important ones as the trigger set(Section 3).?
Step 3 - Slot Typing: For any given new slottype, automatically expand a few trigger seedsusing the Paraphrase Database (Ganitkevitch etal., 2013).
Then we use the expanded triggerset to label the slot types of identified triggers(Section 4).This framework only requires name tagging anddependency parsing as pre-processing, and a fewtrigger seeds as input, and thus it can be easilyadapted to a new language or a new slot type.Experiments on English and Chinese demonstratethat our approach dramatically advances state-of-the-art results for both pre-defined KBP slot typesand new slot types.2 Candidate Relation IdentificationWe first present how to build an extended de-pendency graph for each evidence sentence (Sec-tion 2.1) and generate query and filler candidatementions (Section 2.2).2.1 Extended Dependency Tree ConstructionGiven a sentence containing N words, we con-struct an undirected graph G = (V,E), whereV = {v1, .
.
.
, vN} represents the words in asentence, E is an edge set, associated with eachedge eijrepresenting a dependency relation be-tween viand vj.
We first apply a dependencyparser to generate basic uncollapsed dependenciesby ignoring the direction of edges.
Figure 1shows the dependency tree built from the examplesentence.
In addition, we annotate an entity, timeor value mention node with its type.
For example,in Figure 1, ?Ellen Griffin Dunne?
is annotatedas a person, and ?1997?
is annotated as a year.Finally we perform co-reference resolution, whichintroduces implicit links between nodes that referto the same entity.
We replace any nominal orpronominal entity mention with its coreferentialname mention.
For example, ?he?
is replacedby ?Dominick Dunne?
in Figure 1.
Formally, anextended dependency tree is an annotated tree ofentity mentions, phrases and their links.452.2 Query Mention and Filler CandidateIdentificationGiven a query q and a set of relevant documents,we construct a dependency tree for each sentence.We identify a person entity e as a query mentionif e matches the last name of q or e shares two ormore tokens with q.
For example, ?he/DominickDunne?
in Figure 1 is identified as a mentionreferring to the query Dominick Dunne.
For eachsentence which contains at least one query men-tion, we regard all other entities, values and timeexpressions as candidate fillers and generate a setof entity pairs (q, f), where q is a query mention,and f is a candidate filler.
In Example E1, we canextract three entity pairs (i.e., {Dominick Dunne}?
{Ellen Griffin Dunne, 1997, 1965}).
For eachentity pair, we represent the query mention andthe filler candidate as two sets of nodes Q and Frespectively, where Q,F ?
V .3 Trigger IdentificationIn this section, we proceed to introduce an unsu-pervised graph-based method to identify triggersfor each query and candidate filler pair.
We rankall trigger candidates (Section 3.1) and then keepthe top ones as the trigger set (Section 3.2).3.1 Trigger Candidate RankingAs we have discussed in Section 1, we can con-sider trigger identification problem as finding theimportant nodes relative to Q and F in G. Al-gorithms such as Pagerank (Page et al, 1999)are designed to compute the global importanceof each node relative to all other nodes in agraph.
By redefining the importance according toour preference toward F and Q, we can extendPageRank to generate relative importance scores.We use the random surfer model (Page et al,1999) to explain our motivation.
Suppose a ran-dom surfer keeps visiting adjacent nodes in Gat random.
The expected percentage of surfersvisiting each node converges to the PageRank s-core.
We extend PageRank by introducing a ?backprobability?
?
to determine how often surfersjump back to the preferred nodes (i.e., Q or F ) sothat the converged score can be used to estimatethe relative probability of visiting these preferrednodes.Given G and a set of preferred nodes R whereR ?
V , we denote the relative importance for allv ?
V with respect to R as I(v |R), following thework of White and Smyth (2003).For a node vk, we denote N(k) as the set ofneighbors of vk.
We use pi(k), the k-th com-ponent of the vector pi, to denote the stationarydistribution of vkwhere 1 ?
k ?
|V |.
Wedefine a preference vector pR = {p1, ..., p|V |}such that the probabilities sum to 1, and pkdenotesthe relative importance attached to vk.
pkis setto 1/|R| for vk?
R, otherwise 0.
Let A bethe matrix corresponding to the graph G whereAjk= 1/|N(k)| and Ajk= 0 otherwise.For a given pR, we can obtain the personalizedPageRank equation (Jeh and Widom, 2003):pi = (1?
?
)Api + ?pR (1)where ?
?
[0, 1] determines how often surfersjump back to the nodes in R. We set ?
= 0.3in our experiment.
The solution pi to Equation 1is a steady-state importance distribution inducedby pR.
Based on a theorem of Markov Theory, asolution pi with?|V |k=1pi(k) = 1 always exists andis unique (Motwani and Raghavan, 1996).We define relative importance scores basedon the personalized ranks described above, i.e.,I(v |R) = pi(v) after convergence, and wecompute the importance scores for all the nodesin V relative to Q and F respectively.A query mention in a sentence is more likelyto be involved in multiple relations while a filleris usually associated with only one slot type.Therefore we combine two relative importancescores by assigning a higher priority to I(v |F )as follows.I(v | {Q,F}) = I(v |F ) + I(v |F ) ?
I(v |Q) (2)We discard a trigger candidate if it is (or partof) an entity which can only act as a query or aslot filler.
We assume a trigger can only be a noun,verb, adjective, adverb or preposition.
In addition,verbs, nouns and adjectives are more informativeto be triggers.
Thus, we remove any trigger candi-date v if it has a higher I(v | {Q,F}) than the firsttop-ranked verb/noun/adjective trigger candidate.For example, we rank the candidate triggersbased on the query and slot filler pair (?DominickDunne?, ?Ellen Griffin Dunne?)
as shown in Fig-ure 2.46E1:   Ellen Griffin Dunne, from whom he was divorced in 1965, died in 1997.Ellen Griffin Dunnewhominhe was 1965Dominick Dunne in1997fromacl:relcl casenmod nsubjpass auxpass nmodcase coreference casePerson | FillerPerson | QueryDateDate0.1280.0780.0130.006 0.006dieddivorcedFigure 2: Importance scores of trigger candidatesrelative to query and filler in E1.3.2 Trigger Candidate SelectionGiven Q and F , we can obtain a relative im-portance score I(v | {Q,F}) for each candidatetrigger node v in V as shown in Section 3.1.We denote the set of trigger candidates as T ={t1, ?
?
?
, tn} where n ?
|V |.Since a relation can be indicated by a singletrigger word, a trigger phrase or even multiplenon-adjacent trigger words, it is difficult to set asingle threshold even for one slot type.
Instead,we aim to automatically classify top ranked candi-dates into one group (i.e., a trigger set) so that theyall have similar higher scores compared to othercandidates.Therefore, we define this problem as a clus-tering task.
We mainly consider clustering algo-rithms which do not require pre-specified numberof clusters.We apply the affinity propagation approach totake as input a collection of real-valued similarityscores between pairs of candidate triggers.
Real-valued messages are exchanged between candi-date triggers until a high-quality set of exemplars(centers of clusters), and corresponding clustersgradually emerges (Frey and Dueck, 2007).There are two kinds of messages exchangedbetween candidate triggers: one is called responsi-bility ?
(i, j), sent from tito a candidate exemplartj; the other is availability ?
(i, j), sent from thecandidate exemplar tjto ti.The calculation of each procedure iterates untilconvergence.
To begin with, the availabilitiesare initialized to zero: ?
(i, j) = 0.
Then theresponsibilities are computed using the followingrule:?
(i, j)?
s(i, j)?
maxj?s.t.j?6=j{?
(i, j?)
+ s(i, j?)}
(3)where the similarity score s(i, j) indicates howwell tjis suited to be the exemplar for ti.
Whereasthe above responsibility update lets all candidateexemplars compete for the ownership of a trig-ger candidate ti, the following availability updategathers evidence from trigger candidates as towhether each candidate exemplar would make agood exemplar:?
(i, j)?
min{0, ?
(j, j) +?i?s.t.i?/?
{i,j}max{0, ?
(i?, j)}}(4)Given T , we can generate an n ?
n affinitymatrixM which serves as the input of the affinitypropagation.
Mijrepresents the negative squareddifference in relative importance score between tiand tj(Equation 5).Mij= ?
(I(i | {Q,F})?
I(j | {Q,F}))2(5)We compute the average importance score forall the clusters after convergence and keep theone with the highest average score as the triggerset.
For example, given the query and slot fillerpair in Figure 3, we obtain trigger candidatesT = {died, divorced, from, in, in} and theircorresponding relative importance scores.
Afterthe above clustering, we obtain three clusters andchoose the cluster {divorced} with the highestaverage relative importance score (0.128) as thetrigger set.0.0060.0780.1280.013 0.006E1:   Ellen Griffin Dunne, from whom he was divorced in 1965, died in 1997.Ellen Griffin DunneinDominick Dunnein fromPerson | Filler Person | QuerydieddivorcedAverage = 0.006 + 0.013 + 0.006 /3 ?
0.008Cluster 1Cluster 3Cluster 2Figure 3: Trigger candidate filtering for E1.4 Slot Type LabelingIn this section, we will introduce how to label theslot type for an identified relation tuple (Q,T, F ).The simplest solution is to match T against exist-ing trigger gazetteers for certain types of slots.
For47E1:   Ellen Griffin Dunne, from whom he was divorced in 1965, died in 1997.Ellen Griffin Dunne Dominick Dunne Person | Filler Person | Query divorced wife husband divorce    marry ?Trigger Gazetteer for slot spouse{ Dominick Dunne|Query,  spouse,  Ellen Griffin Dunne|Filler }Figure 4: Example of slot type labeling.example, Figure 4 shows how we label the relationas a spouse slot type.In fact, some trigger gazetteers have alreadybeen constructed by previous work such as (Yu etal., 2015).
However, manual construction of thesetriggers heavily rely upon labeled training data andhigh-quality patterns, which would be unavailablefor a new language or a new slot type.Inspired by the trigger-based event extractionwork (Bronstein et al, 2015), we propose to ex-tract trigger seeds from the slot filling annotationguideline1and then expand them by paraphrasingtechniques.
For each slot type we manually selecttwo trigger seeds from the guideline and then usethe Paraphrase Database (PPDB) (Ganitkevitchet al, 2013; Pavlick et al, 2015) to expandthese seeds.
Specifically, we select top-20 lexicalparaphrases based on similarity scores as our newtriggers for each slot type.
Some examples areshown in Table 2.Seeds Slot Types Expanded Triggersassassinate death kill, die, slay, murdergraduate schools PhD, supervisor, diplomasister siblings twin, half-brother, siblingmarriage spouse married, spouse, matrimonyTable 2: PPDB-based trigger expansion examples.5 Filler ValidationAfter we label each relation tuple, we performthe following validation steps to filter noise andremove redundancy.
For many slot types, there aresome specific constraints on entity types of slotfillers defined in the task specification.
For ex-ample, employee or member of fillers should beeither organizations or geopolitical entities, whilefamily slots (e.g., spouse and children) expectperson entities.
We apply these constraints tofurther validate all relation tuples.1http://www.nist.gov/tac/2015/KBP/ColdStart/guidelines/TAC KBP 2015 Slot Descriptions V1.0.pdfMoreover, single-value slots can only havea single filler (e.g., date of birth), while list-value slots can take multiple fillers (e.g.,cities of residence).
However, we might extractconflicting relation tuples from multiple sentencesand sources.
For each relation tuple, it can alsobe extracted from multiple sentences, and thus itmay receive multiple relative importance scores.We aim to keep the most reliable relation tuple fora single-value slot.For a single-value slot, suppose we have acollection of relation tuples R which share thesame query.
Given r ?
R with a set of relativeimportance scores I = {i1, i2, ?
?
?
, in}, we canregard the average score of I as the credibilityscore of r. The reason is that the higher the relativeimportance score, the more likely the tuple is to becorrect.
In our experiments, we use the weightedarithmetic mean as follows so that higher scorescan contribute more to the final average:?i =?nk=1wk?
ik?nk=1wk(6)where wkdenotes the non-negative weight of ik.When we regard the weight wkequal to the scoreik, Equation 6 can be simplified as:?i =?nk=1w2k?nk=1wk(7)We calculate the weighted mean?i for each r ?R and keep the relation tuple with the highest?i.6 Experiments6.1 Data and Scoring MetricIn order to evaluate the quality of our proposedframework and its portability to a new language,we use TAC-KBP2013 English Slot Filling (ESF),TAC-KBP 2015 English Cold Start Slot Filling(CSSF) and TAC-KBP2015 Chinese Slot Filling(CSF) data sets for which we can compare with theground truth and state-of-the-art results reportedin previous work.
The source collection includesnews documents, web blogs and discussion forumposts.
In ESF there are 50 person queries and onaverage 20 relevant documents per query; while inCSF there are 51 person queries, and on average 5relevant documents per query.48Slot Type Our Approach Roth?13 Angeli?14siblings 62.9 48.0 40other family 42.4 11.8 0spouse 58.7 40.0 66children 66.7 27.3 27parents 43.1 47.8 39schools attended 81.4 30.2 60date of birth 87.0 60.0 92date of death 73.2 3.2 48state of birth 55.6 30.8 17state of death 88.2 53.3 0city of birth 70.0 64.0 25city of death 72.7 73.7 30country of birth 75.0 0.0 0country of death 70.0 46.2 18states of residence 57.1 25.6 12cities of res.
61.4 38.8 38countries of res.
45.7 20.0 41employee of 43.8 18.5 38Overall 57.4 32.3 ?Table 3: English Slot Filling F1(%) (KBP2013 SFdata set).We only test our method on 18 trigger-drivenperson slot types shown in Table 3.
Some otherslot types (e.g., age, origin, religion and title)do not rely on lexical triggers in most cases;instead the query mention and the filler are usuallyadjacent or seperated by a comma.
In addition,we do not deal with the two remaining trigger-driven person slot types (i.e., cause of death andcharges) since these slots often expect other typesof concepts (e.g., a disease or a crime phrase).We use the official TAC-KBP slot filling eval-uation scoring metrics: Precision (P ), Recall (R)and F-score (F1) (Ji et al, 2010) to evaluate ourresults.6.2 English Slot FillingWe apply Stanford CoreNLP (Manning et al,2014) for English part-of-speech (POS) tagging,name tagging, time expression extraction, depen-dency parsing and coreference resolution.
InTable 3 we compare our approach with two state-of-the-art English slot filling methods: a distantsupervision method (Roth et al, 2013) and a hy-brid method that combines distant and partial su-pervision (Angeli et al, 2014b).
Our method out-performs both methods dramatically.
KBP2015English cold start slot filling is a task whichcombines entity mention extraction and slot fil-ing (Surdeanu and Ji, 2014).
Based on the releasedevaluation queries from KBP2015 Cold Start SlotFilling, our approach achieves 39.2% overall F-score on 18 person trigger-driven slot types, whichSlot Type Our Approach Angeli?15siblings 48.0 26.1other family 0.0 33.3spouse 14.3 15.4children 72.8 0.0parents 25.0 14.3schools attended 63.6 42.1date of birth 0.0 80.0date of death 44.0 0.0state of birth 0.0 33.3state of death 0.0 15.4city of birth 0.0 85.7city of death 0.0 0.0country of birth 0.0 66.7country of death 100.0 0.0states of residence 0.0 0.0cities of res.
0.0 50.0countries of res.
0.0 0.0employee of 60.0 26.7Overall 39.2 27.6Table 4: English Cold Start Slot Filling F1(%)(KBP2015 CSSF data set).is significantly better than state-of-the-art (Angeliet al, 2015) on the same set of news documents(Table 4).Compared to the previous work, our methoddiscards a trigger-driven relation tuple if it is notsupported by triggers.
For example, ?Poland?
ismistakenly extracted as the country of residenceof ?Mandelbrot?
by distant supervision (Roth etal., 2013) from the following sentence:A professor emeritus at Yale University, Man-delbrot was born in Poland but as a child movedwith his family to France where he was educated.maybe because the relation tuple (Mandelbrot,live in, Poland) indeed exists in external knowl-edge bases.
Given the same entity pair, our methodidentifies ?born?
as the trigger word and labels theslot type as country of birth.When there are several triggers indicating d-ifferent slot types in a sentence, our approachperforms better in associating each trigger withthe filler it dominates by analyzing the wholedependency tree.
For example, given a sentence:Haig is survived by his wife of 60 years, Patri-cia; his children Alexander, Brian and Barbara;eight grandchildren; and his brother, the Rev.Francis R.
Haig.
(Haig, sibling, Barbara) is the only relationtuple extracted from the above sentence by theprevious method.
Given the entity pair (Haig, Bar-bara), the relative importance score of ?children?
(0.1) is higher than the score of ?brother?
(0.003),49and ?children?
is kept as the only trigger candidateafter clustering.
Therefore, we extract the tuple(Haig, children, Barbara) instead.
In addition, wesuccessfully identify the missing fillers for otherslot types: spouse (Patricia), children (Alexander,Brian and Barbara) and siblings (Francis R. Haig)by identifying their corresponding triggers.In addition, flat relation representations fail toextract the correct relation (i.e., alternate names)between ?Dandy Don?
and ?Meredith?
since?brother?
is close to both of them in the followingsentence:In high school and at Southern Methodist U-niversity, where, already known as Dandy Don(a nickname bestowed on him by his brother) ,Meredith became an all-American.6.3 Adapting to New Slot TypesOur framework can also be easily adapted tonew slot types.
We evaluate it on three newperson list-value slot types: friends, colleaguesand collaborators.We use ?friend?
as the slot-specific trigger forthe slot friends and ?colleague?
for the slot col-leagues.
?collaborate?, ?cooperate?
and ?part-ner?
are used to type the slot collaborators.We manually annotate ground truth for evalua-tion.
It is difficult to find all the correct fillers for agiven query from millions of documents.
There-fore, we only calculate precision.
Experimentsshow we can achieve 56.3% for friends, 100% forcolleagues and 60% for collaborators (examplesshown in Table 5).6.4 Impact of Trigger MiningIn Section 3.2, we keep top-ranked trigger can-didates based on clustering rather than thresholdtuning.
We explore a range of thresholds forcomparison, as shown in Figure 5.
Our approachachieves 57.4% F-score, which is comparable tothe highest F-score 58.1% obtained by thresholdtuning.We also measure the impact of the size of thetrigger gazetteer.
We already outperform state-of-the-art by using PPDB to expand triggers minedfrom guidelines as shown in Table 6.
As thesize of the trigger gazetteer increases, our method(marked with a ?)
achieves better performance.6.5 Chinese Slot FillingAs long as we have the following resources: (1)a POS tagger, (2) a name tagger, (3) a dependen-11 2 3 4 5 640424446485052545658F-score(%)Top N candidates as triggersThreshold Tuning Affinity PropagationFigure 5: The effect of the number of triggercandidates on ESF.Method Size F1(%)State-of-the-art (Roth et al, 2013) ?
32.3Guideline seeds?20 27.3Guideline seeds + PPDB expansion?220 38.9Manually Constructed Trigger Gazetteers?7,463 57.4Table 6: The effect of trigger gazetteers on ESF(size: the number of triggers).cy parser and (4) slot-specific trigger gazetteers,we can apply the framework to a new language.Coreference resolution is optional.We demonstrate the portability of our frame-work to Chinese since all the resources men-tioned above are available.
We apply StanfordCoreNLP (Manning et al, 2014) for Chinese POStagging, name tagging (Wang et al, 2013) anddependency parsing (Levy and Manning, 2003).To explore the impact of the quality of annotationresources, we also use a Chinese language analysistool: Language Technology Platform (LTP) (Cheet al, 2010).
We use the full set of Chinesetrigger gazetteers published by Yu et al (2015).Experimental results (Table 7) demonstrate thatour approach can serve as a new and promisingbenchmark.
As far as we know, there are no resultsavailable for comparison.However, the performance of Chinese SF isheavily influenced by the relatively low perfor-mance of name tagging since our method return-s an empty result if it fails to find any querymetnion.
About 20% and 16% queries cannotbe recognized by CoreNLP and LTP respectively.One reason is that many Chinese names are alsocommon words.
For example, a buddhist monk?sname ????
(wake) is identified as a verb ratherthan a person entity.50Evidence Sentence Slot Type Query Extracted FillersMany of his subjects were friends from his previous life , such asElizabeth Taylor and Gloria Vanderbilt .friends Dominick Dunne Gloria Vanderbilt;Elizabeth TaylorToby Keith hit an emotional note with a performance of ?Cryin?For Me (Wayman?s Song),?
dedicated to his late friend, jazz artistand former basketball star Wayman Tisdale, who died last May.friends Wayman Tisdale Toby Keith?I think all of her writing came from her heart,?
Michael Glaser,a longtime colleague at St. Mary?s and former Maryland poetlaureate, said last week.colleagues Lucille Clifton Michael GlaserCunningham has collaborated on two books: ?Changes: Noteson Choreography,?
with Frances Starr, and ?The Dancer and theDance,?
with Jacqueline Lesschaeve.collaborators Merce Cunningham JacquelineLesschaeveTable 5: Examples for new slot types.A dependency parser is indispensable to pro-duce reliable rankings of trigger candidates.
Un-fortunately, a high-quality parser for a new lan-guage is often not available because of language-specific features.
For example, in Chinese asingle sentence about a person?s biography oftencontains more than five co-ordinated clauses, eachof which includes a trigger.
Therefore a dependen-cy parser adapted from English often mistakenlyidentifies one of the triggers as a main predicate ofthe sentence.In addition, Chinese is a very concise language.For example, a ?
[Person Name][Organization Suf-fix]?structure can indicate various different typesof relations between the person name and theorganization: ????????
(Yang Ming Clin-ic) indicates ownership, ????????
(ShaoYifu Library) indicates sponsorship, ?????????
(Feng Zikai Research Center) indicatesSlot Type CoreNLP-based LTP-basedsiblings 40.0 57.1other family 40.0 0.0spouse 40.0 48.0children 19.0 21.4parents 0.0 25.0schools attended 11.1 17.1date of birth 42.4 0.0date of death 48.5 0.0state of birth 38.1 52.2state of death 55.6 70.0city of birth 28.6 26.7city of death 33.3 42.9country of birth 11.8 11.8country of death 0.0 0.0states of residence 30.8 29.6cities of residence 27.3 34.8country of residence 6.5 0.0employee of 31.0 31.2Overall 29.6 28.3Table 7: Chinese Slot Filling F1(%) (KBP2015CSF data set).research theme, and ?????????
(LuojingCommemoration Committee) indicates commem-oration.
None of them includes an explicit triggernor indicates employment relation.
It requiresmore fine-grained dependency relation types todistinguish them.Finally, compared to English, Chinese tends tohave more variants for some types of triggers (e.g.,there are at least 31 different titles for ?wife?inChinese).
Some of them are implicit and requireshallow inference.
For example, ????
(to seekshelter or asylum) indicates a residence relation inmost cases.7 Related WorkBesides the methods based on distant supervision(e.g., (Surdeanu et al, 2010; Roth et al, 2013;Angeli et al, 2014b)) discussed in Section 6.2,pattern-based methods have also been proven to beeffective in SF in the past years (Sun et al, 2011;Li et al, 2012; Yu et al, 2013).
Dependency-basedpatterns achieve better performance since they cancapture long-distance relations.
Most of theseapproaches assume that a relation exists betweenQ and F if there is a dependency path connectingQ and F and all the words on the path are equallyregarded as trigger candidates.
We explore thecomplete graph structure of a sentence rather thanchains/subgraphs as in previous work.
Our pre-vious research focused on identifying the relationbetween F and T by extracting filler candidatesfrom the identified scope of a trigger (e.g., (Yuet al, 2015)).
We found that each slot-specifictrigger has its own scope, and corresponding fillersseldom appear outside its scope.
We did notcompare with results from this previous approachwhich did not consider redundancy removal re-quired in the official evaluations.51Soderland et al (2013) built their SF systembased on Open Information Extraction (IE) tech-nology.
Our method achieves much higher recallsince dependency trees can capture the relationsamong query, slot filler and trigger in more com-plicated long sentences.
In addition, our triggersare automatically labeled so that we do not needto design manual rules to classify relation phrasesas in Open IE.8 Conclusions and Future WorkIn this paper, we demonstrate the importance ofdeep mining of dependency structures for slotfilling.
Our approach outperforms state-of-the-artand can be rapidly portable to a new language or anew slot type, as long as there exists capabilities ofname tagging, POS tagging, dependency parsingand trigger gazetteers.In the future we aim to label slot types basedon contextual information as well as sentencestructures instead of trigger gazetteers only.
Thereare two primary reasons.
First, a trigger can servefor multiple slot types.
For example, slot childrenand its inverse slot parents share a subset oftriggers.
Second, a trigger word can have multipledifferent meanings.
For example, a sibling triggerword ?sister?
can also represent a female memberof a religious community.
We attempt to combinemulti-prototype approaches (e.g., (Reisinger andMooney, 2010)) to better disambiguate senses oftrigger words.Besides considering the cross-sentence conflict-s, we also want to investigate the within-sentenceconflicts caused by the competition of triggers.A trigger identified by our approach is the mostimportant node in the dependency tree relative tothe given entity pair.
However, this trigger mightbe more important to another entity pair, whichshares the same filler, in the same sentence.
Apromising solution is to rank all the entities in thesentence based on their importance relative to theidentified trigger and the filler candidate.AcknowledgementWe would like to thank Chris Callison-Burchfor providing English and Chinese paraphraseresources.
This work was supported by theDARPA LORELEI Program No.
HR0011-15-C-0115, DARPA DEFT Program No.
FA8750-13-2-0041, ARL NS-CTA No.
W911NF-09-2-0053,NSF CAREER Award IIS-1523198.
The viewsand conclusions contained in this document arethose of the authors and should not be interpretedas representing the official policies, eitherexpressed or implied, of the U.S. Government.The U.S. Government is authorized to reproduceand distribute reprints for Government purposesnotwithstanding any copyright notation here on.ReferencesG.
Angeli, S. Gupta, M. Jose, C. Manning, C. R?e,J.
Tibshirani, J. Wu, S. Wu, and C. Zhang.
2014a.Stanford?s 2014 slot filling systems.
In Proc.
TextAnalysis Conference (TAC 2014).G.
Angeli, J. Tibshirani, J. Wu, and C. Manning.2014b.
Combining distant and partial supervisionfor relation extraction.
In Proc.
Empirical Methodson Natural Language Processing (EMNLP 2014).G.
Angeli, V. Zhong, D. Chen, J. Bauer, A. Chang,V.
Spitkovsky, and C. Manning.
2015.
Bootstrappedself training for knowledge base population.
InProc.
Text Analysis Conference (TAC 2015).O.
Bronstein, I. Dagan, Q. Li, H. Ji, and A. Frank.2015.
Seed-based event trigger labeling: How farcan event descriptions get us?
In Proc.
Associationfor Computational Linguistics (ACL 2015).W.
Che, Z. Li, and T. Liu.
2010.
Ltp: Achinese language technology platform.
In Proc.Computational Linguistics (COLING 2010).B.
Frey and D. Dueck.
2007.
Clustering by passingmessages between data points.
science.J.
Ganitkevitch, B.
Van Durme, and C. Callison-Burch.
2013.
PPDB: The paraphrase database.
InProc.
North American Chapter of the Associationfor Computational Linguistics - Human LanguageTechnologies (NAACL-HLT 2013).Y.
Hong, X. Wang, Y. Chen, J. Wang, T. Zhang,J.
Zheng, D. Yu, and Q. Li.
2014.
Rpi blendertac-kbp2014 knowledge base population system.
InProc.
Text Analysis Conference (TAC 2014).G.
Jeh and J. Widom.
2003.
Scaling personalized websearch.
In Proc.
World Wide Web (WWW 2003).H.
Ji, R. Grishman, H. Dang, K. Griffitt, and Joe Ellis.2010.
An overview of the tac2010 knowledge basepopulation track.
In Proc.
Text Analysis Conference(TAC 2010).H.
Ji, R. Grishman, and H. Dang.
2011.
An overviewof the tac2011 knowledge base population track.
InProc.
Text Analysis Conference (TAC 2011).R.
Levy and C. Manning.
2003.
Is it harder toparse chinese, or the chinese treebank?
In Proc.Association for Computational Linguistics (ACL2003).52Y.
Li, S. Chen, Z. Zhou, J. Yin, H. Luo, L. Hong,W.
Xu, G. Chen, and J. Guo.
2012.
Pris at tac2012kbp track.
In Proc.
Text Analysis Conference (TAC2012).C.
Manning, M. Surdeanu, J. Bauer, J. Finkel,S.
Bethard, and D. McClosky.
2014.
The StanfordCoreNLP natural language processing toolkit.
InProc.
Association for Computational Linguistics(ACL 2014).P.
McNamee and H. Dang.
2009.
Overview of the tac2009 knowledge base population track.
In Proc.
TextAnalysis Conference (TAC 2009).R.
Motwani and P. Raghavan.
1996.
Randomizedalgorithms.
ACM Computing Surveys (CSUR).L.
Page, S. Brin, R. Motwani, and T. Winograd.
1999.The pagerank citation ranking: Bringing order to theweb.
Technical report, Stanford InfoLab.E.
Pavlick, P. Rastogi, J. Ganitkevitch, andC.
Van Durme, B.and Callison-Burch.
2015.Ppdb 2.0: Better paraphrase ranking, fine-grainedentailment relations, word embeddings, andstyle classification.
In Proc.
Association forComputational Linguistics (ACL 2015).J.
Reisinger and R. Mooney.
2010.
Multi-prototype vector-space models of word meaning.
InProc.
North American Chapter of the Associationfor Computational Linguistics - Human LanguageTechnologies (NAACL-HLT 2010).B.
Roth, T. Barth, M. Wiegand, M. Singh, andD.
Klakow.
2013.
Effective slot filling based onshallow distant supervision methods.
In Proc.
TextAnalysis Conference (TAC 2013).S.
Soderland, J. Gilmer, R. Bart, O. Etzioni, andD.
Weld.
2013.
Open ie to kbp relations in 3 hours.In Proc.
Text Analysis Conference (TAC 2013).A.
Sun, R. Grishman, B. Min, and W. Xu.
2011.Nyu 2011 system for kbp slot filling.
In Proc.
TextAnalysis Conference (TAC 2011).M.
Surdeanu and H. Ji.
2014.
Overview of theenglish slot filling track at the tac2014 knowledgebase population evaluation.
In Proc.
Text AnalysisConference (TAC 2014).M.
Surdeanu, D. McClosky, J. Tibshirani, J. Bauer,A.
Chang, V. Spitkovsky, and C. Manning.
2010.
Asimple distant supervision approach for the tac-kbpslot filling task.
In Proc.
Text Analysis Conference(TAC 2010).M.
Wang, W. Che, and C. Manning.
2013.
Joint wordalignment and bilingual named entity recognitionusing dual decomposition.
In Proc.
Association forComputational Linguistics (ACL 2013).S.
White and P. Smyth.
2003.
Algorithms forestimating relative importance in networks.
In Proc.Knowledge discovery and data mining (KDD 2003).D.
Yu, H. Li, T. Cassidy, Q. Li, H. Huang, Z. Chen,H.
Ji, Y. Zhang, and D. Roth.
2013.
Rpi-blendertac-kbp2013 knowledge base population system.
InProc.
Text Analysis Conference (TAC 2013).D.
Yu, H. Ji, S. Li, and C. Lin.
2015.
Why read ifyou can scan: Scoping strategy for biographical factextraction.
In Proc.
North American Chapter of theAssociation for Computational Linguistics - HumanLanguage Technologies (NAACL-HLT 2015).53
