Abst ractUn i f i ca t ion -Based  Semant ic  In terpretat ionRobert C. MooreArtificial Intelligence CenterSRI InternationalMenlo Park, CA 94025We show how unification can be used to spec-ify the semantic interpretation fnatural-languageexpressions, including problematical constructionsinvolving long-distance dependencies.
We alsosketch a theoretical foundation for unification-based semantic interpretation, and compare theunification-based approach with more conven-tional techniques based on the lambda calculus.1 In t roduct ionOver the past several years, unification-based for-malisms (Shieber, 1986) have come to be widelyused for specifying the syntax of natural lan-guages, particularly among computational lin-guists.
It is less widely realized by computa-tional linguists that unification can also be a pow-erful tool for specifying the semantic interpreta-tion of natural languages.
While many of thetechniques described in this paper are fairly wellknown among natural-language researchers work-ing with logic grammars, they have not been ex-tensively discussed in the literature, perhaps theonly systematic presentation being that of Pereiraand Shieber (1987).
This paper goes into many is-sues in greater detail than do Pereira and Shieber,however, and sketches what may be the first the-oretical analysis of unification-based semantic in-terpretation.We begin by reviewing the basic ideas behindunification-based grammar formalisms, which willalso serve to introduce the style of notation to beused throughout the paper.
The notation is thatused in the Core Language Engine (CLE) devel-oped by SKI's Cambridge Computer Science Re-search Center in Cambridge, England, a systemwhose semantic-interpretation c mponent makesuse of many of the ideas presented here.Fundamentally, unification grammar is a gener-alization of context-free phrase structure grammarin which grammatical:category expressions are notsimply atomic symbols, but have sets of featureswith constraints on their values.
Such constraintsare commonly specified using sets of equations.Our notation uses equations of a very simpleformat--just ~eal;ure=value--and permits onlyone equation per feature per constituent, but wecan indicate constraints that would be expressedin other formalisms using more complex equationsby letting the value of a feature contain a variablethat appears in more than one equation.
The CLEis written in Prolog, to take advantage of the effi-ciency of Prolog unification in implementing cate-gory unification, so our grammar ules are writtenas Prolog assertions, and we follow Prolog con-ventions in that constants, such as category andfeature names, start with lowercase letters, andvariables tart with uppercase letters.
As an ex-ample, a simplified version of the rule for the basicsubject-predicate sentence form might be writtenin our notation as(1) syn(s_np_vp,\[s: \[type=tensed\],np: \[person=P, hUm=N\] ,vp: \[~ype=~ens ed,person=P, hum=N\] \]).The predicate syn indicates that this is a syntaxrule, and the first argument s_npovp is a rule iden-tifier that lets us key the semantic-interpretationrules to the syntax rules.
The second argu-ment of syn is a list of category expressions thatmake up the content of the rule, the first speci-fying the category of the mother constituent andthe rest specifying the categories of the daugh-ter constituents.
This rule, then, says that atensed sentence (s: \ [type=~ensed\])  can consistof a noun phrase (rip) followed by a verb phrase(vp), with the restrictions that the verb phrasemust be tensed (type=tensed), and that the nounphrase and verb phrase must agree in person andnumber--that is, the person and num features ofthe noun phrase must have the same respectivevalues as the person and mm features of the verbphrase.These constraints are checked in the process ofparsing a sentence by unifying the values of fea-tures specified in the rule with the values of fea-tures in the constituents found in the input.
Sup-pose, for instance, that we are parsing the sentence33Mary runs using a left-corner parser.
If Mary isparsed as a constituent of categorynp:\[person=3rd,num=sing\],then unifying this category expression withnp : \[person=P ,num=N\]in applying the sentence rule above will force thevariables P and N to take on the values 3rd ands~_ug, respectively.
Thus when we try to parsethe verb phrase, we know that it must be of thecategoryvp : \[type=tensed, person=3rd,num=sing\].Our notation for semantic-interpretation rulesis a slight generalization of the notation for syn-tax rules.
The only change is that in each positionwhere a syntax rule would have a category expres-sion, a semantic rule has a pair consisting of a"logical-form" expression and a category expres-sion, where the logical-form expression specifiesthe semantic interpretation of the correspondingconstituent.
A semantic-interpretation rule cor-responding to syntax rule (1) might look hke thefollowing:(2) sem(s_np_vp,\[(apply(Vp,Np),  s : \[\] ) ,(~p,np: \[\] ) ,(Vp ,vp :  \[3 )\] ) .The predicate sere means that this is a semantic-interpretation rule, and the rule identifier s..up_vpindicates that this rule applies to structures builtby the syntax rule with the same identifier.
Thelist of pairs of logical-form expressions and cate-gory expressions specifies the logical form of themother constituent in terms of the logical formsand feature values of the daughter constituents.In this case the rule says that the logical form ofa sentence generated by the s_np_vp rule is an ap-plicative expression with the logical form of theverb phrase as the functor and the logical form ofthe noun phrase as the argument.
(The dummyfunctor apply is introduced because Prolog syntaxdoes not allow variables in functor position.)
Notethat there are no feature restrictions on any of thecategory expressions occurring in the rule.
Theyare unnecessary in this case because the semanticrule applies only to structures built by the s_np_vpsyntax rule, and thus inherits all the restrictionsapplied by that rule.342 Funct iona l  App l i ca t ion  vs.Un i f i ca t ionExample (2) is typical of the kind of semantic rulesused in the standard approach to semantic inter-pretation in the tradition established by PdchardMontague (1974) (Dowty, Wall, and Peters, 1981).In this approach, the interpretation of a complexconstituent is the result of the functional applica-tion of the interpretation of one of the daughterconstituents o the interpretation of the others.A problem with this approach is that if, in arule like (2), the verb phrase itself is semanti-cally complex, as it usually is, a lambda expres-sion has to be used to express the verb-phrase in-terpretation, and then a lambda reduction mustbe applied to express the sentence interpretationin its simplest form (Dowry, Wall, and Peters,1981, pp.
98-111).
To use (2) to specify the in-terpretation of the sentence John likes Mary, thelogical form for John could simply be john, butthe logical form for likes Mary would have to besomething like X\like(X,mary).
\[The notationVar\Bocly for lambda expressions i  borrowed fromLambda Prolog (Miller and Nadathur, 1988).\] Thelogical form for the whole sentence would thenbe apply(Xklike(X,mary),john), which mustbe reduced to yield the simplified logical formlike(jobn,m~y).Moreover, lambda expressions and the ensuingreductions would have to be introduced at manyintermediate stages if we wanted to produce sim-plified logical forms for the interpretations of com-plex constituents such as verb phrases.
If we wantto accommodate modal auxiliaries, as in Johnmight like Mary, we have to make sure that theverb phrase might like Mary receives the sametype of interpretation as like(s) Mary in order tocombine properly with the interpretation of thesubject.
If we try to maintain functional applica-tion as the only method of semantic omposition,then it seems that the simplest logical form we cancome up with for might like Mary is produced bythe following rule:(3) sem(vp_aux_vp.\[(Xkapply (Aux, apply (Vp, X) ),vp: \[\] ) ,(Aux,  aux : \[\] ) ,(Vp,vp : \[\] )\] ) .Applying this rule to the simplest plausible logicalforms for migM and like Mary would produce thefollowing logical form for might like Mary:X\apply(might,(apply(Y\like(Y,mary),X)))which must be reduced to obtain the simpler ex-pression X\might ( l i ke  (X ,mary) .
When this ex-pression is used in the sentence-level rule, anotherreduction is required to eliminate the remaininglambda expression.
The part of the reduction stepthat gets rid of the apply functors is to some ex-tent an artifact of the way we have chosen to en-code these expressions as Prolog terms, but thelambda reductions are not.
They are inherent inthe approach, and normally each rule will intro-duce at least one lambda expression that needs tobe reduced away.It is, of course, possible to add a lambda-reduction step to the interpreter for the semanticrules, but it is both simpler and more efficient touse the feature system and unification to do ex-plicitly what lambda expressions and lambda re-duction do implicitly--assign a value to a variableembedded in a logical-form expression.
Accordingto this approach, instead of the logical form fora verb phrase being a logical predicate, it is thesame as the logical form of an entire sentence, butwith a variable as the subject argument of the verband a feature on the verb phrase having that samevariable as its value.
The sentence interpretationrule can thus be expressed as(4) sem(s_np_vp,\[(Vp,,: \[\] ),(Np,np: \[\]),(Vp,vp:\[subjval=Np\])\]),which says that the logical form of the sentence isjust the logical form of the verb phrase with thesubject argument of the verb phrase unified withthe logical form of the subject noun phrase.
Ifthe verb phrase likes Mary is assigned the logical-form/category-expression pair(like(X,mary),vp:\[subjval=X\]),then the application of this rule will unify the log-ical form of the subject noun phrase, say john,directly with the variable X in l ike(X,mary)  toimmediately produce a sentence constituent withthe logical form l i ke ( jo tm,mary) .Modal auxiliaries can be handled equally easilyby a rule such as(5) sem(vp_aux_vp,\[ (Aux, vp: \[subj val=S\] ),(Aux, aux : \[argval=Vp\] ),(Vp, vp : \[subj val=S\] ) \] ).If might is assigned the logical-form/category-expression pair(might (A), aux : \[argval=A\] ),then applying this rule to interpret he verb phrasemight like Mary will unify A in mighl;(A) withl ike(X,mary)  to produce a constituent with thelogical-form/category-expression pair(migh~ (like, X, mary), vp : \[subj val=X\] ).which functions in the sentence-interpretationrule in exactly the same way as the logical-form/category-expression pairfor like Mary.3 Are Lambda ExpressionsEver Necessary?The approach presented above for eliminating tileexplicit use of lambda expressions and lambda re-ductions is quite general, but it does not replaceall possible uses of lambda expressions in seman-tic interpretation.
Consider the sentence John andBill like Mary.
The simplest logical form for thedistributive reading of this sentence would beand(like(john,mary) ,like(bill ,mary) ).If the verb phrase is assigned the logical-form/category-expression pair(like (X, mary), vp : \[subj val=X\] ),as we have suggested, then we have a problem:Only one of john or b i l l  can be directly unifiedwith X, but to produce the desired logical form,we seem to need two instances of l ike(X,mary) ,with two different instantiations of X.Another problem arises when a constituent thatnormally functions as a predicate is used as anargument instead.
Common nouns, for example,are normally used to make direct predications, oa noun like senator might be assigned the logical-form/category-expression pair(S enamor (X), nbar: \[argval=X\] )according to the pattern we have been following.
(Note that we do not have "noun" as a syntacticcategory; rather, a common oun is simply treatedas a lexical "n-bar.")
It is widely recognized, how-ever, that there are "intensional" adjectives andadjective phrases, such as former, that need to betreated as higher-level predicates or operators onpredicates, so that in an expression like former35senator, the noun senator is not involved in di-rectly making a predication, but instead functionsas an argument o former.
We can see that thismust be the case, from the observation that a for-mer senator is no longer a senator.
The logicalform we have assigned to senator, however, is notliterally that of a predicate, however, but rather ofa complete formula with a free variable.
We there-fore need some means to transform this formulawith its free variable into an explicit predicate tobe an argument of former.
The introduction oflambda expressions provides the solution to thisproblem, because the transformation we require isexactly what is accomplished by lambda abstrac-tion.
The following rule shows how this can becarried out in practice:(6) sem(nba~_adj_nba~,\ [ (Adjp,nbar:  \[argval=A\] ),(Adjp, adjp: \[type=in~ensional,argva l  =X\Nbar,argva12=A\] ) ,(Nbar, nbar: \[argval=X\] ) \] ).This rule requires the logical-form/category-expression pair assigned to an intensional adjec-tive phrase to be something like( formerCP,?)
,adjp: \[~ype=intensional,argvall--P, argvalg=Y\] ),where former(P,Y) means that Y is a former P.The daughter nbar is required to be as previouslysupposed.
The rule creates a lambda expression,by unifying the bound variable with the argumentof the daughter nbar and making the logical formof the daughter nbar the body of the lambda ex-pression, and unifies the lambda expression withthe first argument of the adjp.
The second ar-gument of the adjp becomes-the argument of themother nbar.
Applying this rule to former senatorwill thus produce a constituent with the logical-form/category-expression pair(former(Xksenator (X) .Y) .nbar: \[argval=Y\] ).This solution to the second problem also solvesthe first problem.
Even in the standard lambda-calculus-based approach, the only way in whichmultiple instances of a predicate expression ap-plied to different arguments can arise from a sin-gle source is for the predicate expression to ap-pear as an argument o some other expressionthat contains multiple instances of that argument.Since our approach requires turning a predicateinto an explicit lambda expression if it is usedas an argument, by the time we need multipleinstances of the predicate, it is a lready in theform of a lambda expression.
We can show howthis works by encoding a Montagovian (Dowty,Wall, Peters, 1981) treatment of conjoined sub-ject noun phrases within our approach.
The ma-jor feature of this treatment is that noun phrasesact as higher-order predicates of verb phrases,rather than the other way around as in the sim-pler rules presented in Sections 1 and 2.
Inthe Montagovian treatment, a proper noun suchas JoAn is given an interpretation equivalent oP\P( jotm),  so that when we apply it to a pred-icate like ran in interpreting John runs we getsomething like app ly (P \P ( john) , run)  which re-duces to run( john) .
With this in mind, considerthe following two rules for the interpretation ofsentences with conjoined subjects:(7) sem(np_np_conj_np\[(Conj .rip: \ [argval=P\]  ) .
(Np1 ,np: \[axgval=P\] ) ,( toni ,  conj : \ [argva l l=Npl ,argval2=Np2\] ),(Np2,np: \[argval=P\] )\] ).
(8) semCs_np_vp,\[CNp.s: Q).CNp.np: \[argval=X\Vp\] ) ,(Vp,vp: \[subj val=X\] )\] ) .The first of these rules gives a Montagoviantreatment of conjoined noun phrases, and thesecond gives a Montagovian treatment of simpledeclarative sentences.
Both of these rules assumethat a proper noun such as John would have alogicai-form/category-expression pair like(apply(P, john) .np: \[argval=P\] ).In (7) it is assumed that the conjunction andwould have a logicai-form/category-expressionpair like(~dCP1,P2),conj : \[argvall=Pl, argval2=P2\] ).In (7) the logical forms of the two conjoined augh-ter nps are unified with the two arguments of theconjunction, and the arguments of the daughternps are unified with each other and with the sin-gle argument of the mother np.
Thus applying(7) to interpret John and Bill yields a constituentwith the logical-form/category-expression pair35(and(apply(P, j ohm), apply (P, bill) ),np: \[argval=P\] ).In (8) an explicit lambda expression is constructedout of the logical form of the vp daughter in thesame way a lambda expression was constructed in(6), and this lambda expression is unified with theargument of the subject np.
For the sentence Johnand Bill like Mary, this would produce the logicalformand (apply (X\like (X,mary), j ohm),apply(X\like (X,mary) ,bill)),which can be reduced toand(like (john,mary) ,like(bill,mary)).4 Theoret i ca l  Foundat ions  ofUn i f i ca t ion -Based  Seman-t icsThe examples presented above ought to be con-vincing that a unification-based formalism can bea powerful tool for specifying the interpretation ofnatural-language expressions.
What may not beclear is whether there is any reasonable theoreticalfoundation for this approach, or whether it is justso much unprincipled "feature hacking."
The in-formal explanations we have provided of how par-ticular rules work, stated in terms of unifying thelogical form for constituent X with the appropriatevariable in the logical form for constituent Y, maysuggest that the latter is the case.
If no constraintsare placed on how such a formalism is used, it iscertainly possible to apply it in ways that have nobasis in any well-founded semantic theory.
Never-theless, it is possible to place restrictions on theformalism to ensure that the rules we write have asound theoretical basis, while still permitting thesorts of rules that seem to be needed to specify thesemantic interpretation of natural languages.The main question that arises in this regard iswhether the semantic rules specify the interpreta-tion of a natural-language expression in a compo-sitional fashion.
That is, does every rule assignto a mother constituent a well-defined interpreta-tion that depends solely on the interpretations ofthe daughter constituents?
If the interpretationof a constituent is taken to be just the interpre-tation of its logical-form expression, the answer isclearly "no."
In our formalism the logical-formexpression assigned to a mother constituent de-pends on both the logical-form expressions andthe category expressions assigned to its daughters.As long as both category expressions and logical-form expressions have a theoretically sound basis,however, there is no reason that both should notbe taken into account in a semantic theory; so,we will define the interpretation of a constituentbased on both its category and its logical form.Taking the notion of interpretation i  this way,we will explain how our approach can be madeto preserve compositionality.
First, we will showhow to give a well-defined interpretation to everyconstituent; then, we will sketch the sort of re-strictions on the formalism one needs to guaranteethat any interpretation-preserving substitution fora daughter constituent also preserves the interpre-tation of the mother constituent.The main problem in giving a well-defined inter-pretation to every constituent is how to interpret aconstituent whose logical-form expression containsfree variables that also appear in feature values inthe constituent's category expression.
Recall therule we gave for combining auxiliaries with verbphrases:(5) sem(vp_aux_vp,\[ (Aux, vp : \[subj val--S\] ),(Aux, aux: \[argval=Vp\] ),(Vp,vp: \[subj val=S\] )\] ).This rule accepts daughter constituents havinglogical-form/category-expression pairs such as(migh~ (A), attz : \[argval=A\] )and(like (X, mary), vp: \[subj val=X\] )to produce a mother constituent having thelogical-form~category-expression pair(migh~ (like, X, mary), vp: \[subj val=X\].Each of these pairs has a logical-form expressioncontaining a free variable that also occurs as a fea-ture value in its category expression.
The simplestway to deal with logical-form/category-expressionpairs such as these is to regard them in the waythat syntactic-category expressions in unificationgrammar can be regarded--as abbreviations forthe set of all their well-formed fully instantiatedsubstitution instances.To establish some terminology, we will say thata logical-form/category-expression pair containingno free-variable occurrences has a "basic interpre-tation," which is simply the ordered pair consist-ing of the interpretation of the logical-form ex-pression and the interpretation of the category37expression.
Since there are no free variables in-volved, basic interpretations should be unprob-lematic.
The logical-form expression will simplybe a closed well-formed expression of some ordi-nary logical language, and its interpretation willbe whatever the usual interpretation of that ex-pression is in the relevant logic.
The category ex-pression can be taken to denote a fully instantiatedgrammatical category of the sort typically foundin unification grammars.
The only unusual prop-erty of this category is that some of its featuresmay have logical-form interpretations as values,but, as these will always be interpretations of ex-pressions containing no free-variable occurrences,they will always be well defined.Next, we define the interpretation of an arbi-trary logical-form/category-expression pair to bethe set of basic interpretations of all its well-formed substitution instances that contain nofree-variable occurrences.
For example, the in-terpretation of a constituent with the logical-form/category-expression pair(might (like, X, mary), vp: \[subj val=X\] )would consist of a set containing the basic inter-pretations of such pairs as(might (like, john, mary).vp : \[subj val=j ohn\] ).
(might (like, bill, mary),vp : \[subj val=bill\] ).and so forth.This provides well-defined interpretation for ev-ery constituent, so we can now consider what re-strictions we can place on the formalism to guaran-tee that any interpretation-preserving substitutionfor a daughter constituent also preserves the inter-pretation of its mother constituent.
The first re-striction we need rules out constituents hat wouldhave degenerate interpretations: No semantic ruleor semantic lexical specification may contain bothfree and bound occurrences of the same variablein a logicai-form/category-expression pair.To see why this restriction is needed, considerthe logical-form/category-expression pair(every (X ,man(X), die(X) ) ,np: \[boundvar=X, bodyval=die (X) \] ).which might be the substitution instance of adaughter constituent hat would be selected ina rule that combines noun phrases with verbphrases.
The problem with such a pair is38that it does not have any well-formed substi-tution instances that contain no free-variableoccurrences.
The variable X must be leftuninstantiated in order for the logical-form ex-pression every(X,man(X) ,d ie(X))  to be wellformed, but this requires a free occurrence of Xin np: \[boundvar=X, bodyval=die (X) \].
Thus thispair will be assigned the empty set as its in-terpretation.
Since any logical-form/category-expression pair that contains both free and boundoccurrences of the same variable will receive thisdegenerate interpretation, any other such paircould be substituted for this one without alter-ing the interpretations of the daughter constituentsubstitution instances that determine the inter-pretation of the mother constituent.
It is clearthat this would normally lead to gross violations ofcompositionality, since the daughter substitutioninstances elected for the noun phrases every man,no woman,  and some dog would all receive thesame degenerate interpretation under this scheme.This restriction may appear to be so constrain-ing as to rule out certain potentially useful waysof writing semantic rules, but in fact it is gener-ally possible to rewrite such rules in ways that donot violate the restiction.
For example, in place ofthe sort of logical-form/category-expression pairwe have just ruled out, we can fairly easily rewritethe relevant rules to select daughter substitutioninstances uch as(every (X ,man(X), die (X)),np: \[bodypred=X\die (X) \ ] ) ,which does not violate the constraint and has acompletely straightforward interpretation.Having ruled out constituents with degenerateinterpretations, the principal remaining problemis how to exclude rules that depend on propertiesof logical-form expressions over and above their in-terpretations.
For example, suppose that the or-der of conjuncts does not affect the interpretationof a logical conjunction, according to the inter-pretation of the logical-form language.
That is,and(p,c 1) would have the same interpretation asand(q,p) .
The potential problem that this raisesis that we might write a semantic rule that con-tains both a logicai-form expression like and(P, Q)in the specification of a daughter constituent andthe variable P in the logical form of the motherconstituent.
This would be a violation of composi-tionality, because the interpretation of the motherwould depend on the interpretation of the left con-junct of a conjunction, even though, accordingto the semantics of the logical-form language, itmakes no sense to distinguish the left and rightconjuncts.
If order of conjunction does not af-fect meaning, we ought to be able to substitutea daughter with the logical form and(q,p) forone with the logical form and(p,q) without af-fecting the interpretation assigned to the mother,but clearly, in this case, the interpretation of themother would be affected.It is not clear that there is any uniquely optimalset of restrictions that guarantees that such viola-tions of compositionality cannot occur.
Indeed,since unification formalisms in general have Tur-ing machine power, it is quite likely that there isno computable characterization of all and only thesets of semantic rules that are compositional.
Nev-ertheless, one can describe sets of restrictions thatdo guarantee compositionality, and which seemto provide enough power to express the sorts ofsemantic rules we need to use to specify the se-mantics of natural languages.
One fairly natu-ral way of restricting the formalism to guaranteecompositionality is to set things up so that unifi-cations involving logical-form expressions are gen-erally made against variables, so that it is possibleneither to extract subparts of logical-form expres-sions nor to filter on the syntactic form of logical-form expressions.
The only exception to this re-striction that seems to be required in practice isto allow for rules that assemble and disassemblelambda expressions with respect to their bodiesand bound variables.
So long as no extractionfrom inside the body of a lambda expression isallowed, however, compositionality is preserved.It is possible to define a set of restrictions onthe form of semantic rules that guarantee thatno rule extracts subparts (other than the bodyor bound variable of a lambda expression) of alogical-form expression or filters on the syntacticform of a logical-form expression.
The statementof these restrictions is straightforward, but ratherlong and tedious, so we omit the details here.
Wewill simply note that none of the sample rules pre-sented in this paper involve any such extraction orfiltering.5 The Semantics of Long-Distance DependenciesThe main difficulty that arises in formulatingsemantic-interpretation rules is that constituentsfrequently appear syntactically in places that donot directly reflect their semantic role.
Semanti-cally, the subject of a sentence is one of the argu-ments of the verb, so it would be much easier toproduce logical forms for sentences if the subjectwere part of the verb phrase.
The use of featuressuch as sub jva l ,  in effect, provides a mechanismfor taking the interpretation of the subject fromthe place where it occurs and inserting it into theverb phrase interpretation where it "logically" be-longs.The way features can be manipulated to accom-plish this is particularly striking in the case of thelong-distance dependencies, such as those in WH-questions.
For the sentence Which girl might Johnlike.C, the simplest plausible logical form would besomething likewhich(X, girl (X), migh~ (like (john, X) ),where the question-forming operator which istreated as a generalized quantifier whose "argu-ments" consist of a bound variable, a restriction,and a body.The problem is how to get the variable X tolink the part of the logical form that comes fromthe fronted interrogative noun phrase with theargument of l i ke  that corresponds to the nounphrase gap at the end of the verb phrase.
To solvethis problem, we can use a technique called "gap-threading."
This technique was introduced in uni-fication grammar to describe the syntax of con-structions with long-distance dependencies (Kart-tunnen, 1986) (Pereira and Sheiber, 1987, pp.
125-129), but it works equally well for specifying theirsemantics.
The basic idea is to use a pair of fea-tures, gapva ls in  and gapvalsou% to encode a listof semantic "gap fillers" to be used as the seman-tic interpretations of syntactic gaps, and to threadthat list along to the points where the gaps occur.These gap fillers are often just the bound variablesintroduced by the constructions that permit gapsto occur.The following semantic rules illustrate how thismechanism works:(9) s em(whq_ynq_np_gap,\[(Np,s : \[gapvalsin= \[\],gapvalsout  = \[7 \] ) ,(Np,np : \[type=int errog,bodypred=A\Ynq\] ) ,(Ynq, s : \[gapvalsin= \[A\] ,gapvalsout = \[\] \] )\] ).This is the semantic-interpretation rulefor a WH-question with a long-distance dependency.
Thesyntactic form of such a sentence is an interrog-ative noun phrase followed by a yes/no questionwith a noun phrase gap.
This rule expects the39interrogative noun phrase which girl to have alogical-form/category-expression pair such as(which(X, girl (X), Bodyval),np: \[type=int errog,bodypred=X\Bodyval\] ).The feature bodypred holds a lambda expressionwhose body and bound variable are unified respec-tively with the body and the bound variable of thewhich expression.
In (9) the body of this lambdaexpression is unified with the logical form of theembedded yes/no question, and the gapvals infeature is set to be a list containing the bound vari-able of the lambda expression.
This list is actuallyused as a stack, to accomodate multiply nestedfiller-gap dependencies.
Since this form of ques-tion cannot be embedded in other constructions,however, we know that in this case there will beno other gap-fillers already on the list.This is the rule that provides the logical formfor empty noun phrases:(I0) sem(empl:y_np,\[ (Val, np: \[gapvalsin= \[Val\[ ValRest\],gapvalsout=ValRes~\] )\] ).Notice that it has a mother category, but nodaughter categories.
The rule simply says thatthe logical form of an empty np is the first ele-ment on its list of semantic gap-fillers, and thatthis element is "popped" from the gap-filler list.That is, the gapvalsoul: feature takes as its valuethe tail of the value of the gapvalsin feature.We now show two rules that illustrate how a listof gap-fillers is passed along to the points wherethe gaps they fill occur.
(II) sem(vp_aux_vp,\[ (Aux, vp: \[subj val=S, gapvals in= In,gapvalsouz=Out\] ) ,(Aux, aux: \[argvalfVp\] ),(Vp, vp: \[subj val=S, gapvalsin= In,gapvalsou~=Out\] ) \] ).This semantic rule for verb phrases formed by anauxilliary followed by a verb phrase illustrates thetypical use of the gap features to "thread" the listof gap fillers through the syntactic structure of thesentence to the points where they are needed.
Anauxiliary verb cannot be or contain a WH-typegap, so there are no gap features on the categoryaux.
Thus the gap features on the mother vp aresimply unified with the corresponding features onthe daughter vp.A more complex case is illustrated by the fol-lowing rule:(12) sem(vp_vp_pp,\[ (Pp, vp: \[subj va1=S, gapvals in=In,gapvalsou~=Ou~\] ).
(Vp, vp : \[subj val=S, gapvalsin=In,gapvalsout =Thru\] ),(Pp ,pp : \[argval=Vp, gapvalsin=Thru,gapvalsouZ=Out\] ) \] ).This is a semantic rule for verb phrases that con-sist of a verb phrase and a prepositional phrase.Since WH-gaps can occur in either verb phrasesor prepositional phrases, the rule threads the listcarried by the gapvals in  feature of the mother vpfirst through the daughter vp and then through thedaughter pp.
This is done by unifying the mothervp's gapvals in  feature with the daughter vp'sgapvals in  feature, the daughter vp's gapvalsoutfeature with the daughter pp's gapvals in  feature,and finally the daughter pp's gapvalsouz featurewith the mother vp's gapvalsout  feature.
Sincea gap-filler is removed from the list once it hasbeen "consumed" by a gap, this way of threadingensures that fillers and gaps will be matched ina last-in-first-out fashion, which seems to be thegeneral pattern for English sentences with multi-ple filler-gap dependencies.
(This does not handle"parasitic gap" constructions, but these are veryrare and at present here seems to be no reallyconvincing linguistic account of when such con-structions can be used.
)Taken altogether, these rules push the quan-tified variable of the interrogative noun phraseonto the list of gap values encoded in the fea-ture gapvals in  on the embedded yes/no question.The list of gap values gets passed along by thegap-threading mechanism, until the empty-noun-phrase rule pops the variable off the gap values listand uses it as the logical form of the noun phrasegap.
Then the entire logical form for the embed-ded yes/no question is unified with the body ofthe logical form for the interrogative noun phrase,producing the desired logical form for the wholesentence.This treatment of the semantics of long-distancedependencies provides us with an answer to thequestion of the relative expressive power of ourapproach compared with the conventional lambda-calculus-based approach.
We know that theunification-based approach is at least as power-ful as the conventional approach, because thethe conventional approach can be embedded i-rectly in it, as illustrated by the examples inSection 3.
What about the other way around?Many unification-based rules have direct lambda-calculus-based counterparts; for example (2) is40a counterpart of (4), and (3) is the counterpartof (5).
Once we introduce gap-threading, how-ever, the correspondence breaks down.
In theconventional pproach, each rule applies only toconstituents whose semantic interpretation is ofsome particular single semantic type, say, func-tions from individuals to propositions.
If everyfree variable in our approach istreated as a lambdavariable in the conventional pproach, then noone rule can cover two expressions whose inter-pretation essentially involves different numbers ofvariables, since these would be of different seman-tic types.
Hence, rules like (11) and (12), whichcover constituents containing any number of gaps,would have to be replaced in the conventional p-proach by a separate rule for each possible numberof gaps.
Thus, our formalism enables us to writemore general rules than is possible taking the con-ventional approach.6 ConclusionsIn this paper we have tried to show that aunification-based approach can provide powerfultools for specifying the semantic interpretationof natural-language expressions, while being justas well founded theoretically as the conventionallambda-calculus-based approach.
Although theunification-based approach does not provide a sub-stitute for all uses of lambda expressions in se-mantic interpretation, wehave shown that lambdaexpressions can be introduced very easily wherethey are needed.
Finally, the unification-based ap-proach provides for a simpler statement of manysemantic-interpretation rules, it eliminates manyof the lambda reductions needed to express eman-tic interpretations in their simplest form, and insome cases it allows more general rules than canbe stated taking the conventional pproach.in part by a gift from the Systems DevelopmentFoundation and in part by a contract with theNippon Telegraph and Telephone Corporation.ReferencesDowty, David R., Robert Wall, and Stanley Pe-ters (1981) Introduction to Montague Semantics(D. Reidel, Dordrecht, Holland).Karttunnen, Lauri (1986) "D-PATR: A De-velopment Environment for Unification-BasedGrammars," Proceedings of the l l th Interna-tional Conference on Computational Linguis-tics, Bonn, West Germany, pp.
74-80.Miller, Dale A., and Gopalan Nadathur (1986)"Higher-Order Logic Programming," in E.Shapiro (ed.
), Third International Conferenceon ?ogic Programming, pp.
448-462 (Springer-Verlag, Berlin, West Germany).Montague, Richard (1974) Formal Philosophy(Yale University Press, New Haven, Connecti-cut).Pereira, Fernando C.N., and Stuart M. Shieber(1987) Prolog and Natural-Language Analysis,CSLI Lecture Notes Number 10, Center for theStudy of Language and Information, StanfordUniversity, Stanford, California.Shieber, Stuart M. (1986) An Introduction toUnification-Based Approaches to Grammar,CSLI Lecture Notes Number 4, Center for theStudy of Language and Information, StanfordUniversity, Stanford, California.AcknowledgmentsThe research reported in this paper was begunat SRI International's Cambridge Computer Sci-ence Research Centre in Cambridge, England, sup-ported by a grant from the Alvey Directorateof the U.K. Department of Trade and Indus-try and by the members of the NATTIE consor-tium (British Aerospace, British Telecom, HewlettPackard, ICL, Olivetti, Philips, Shell Research,and SRI).
The work was continued at the SRI Ar-tificial Intelligence Center and the Center for theStudy of Language and Information, supported41
