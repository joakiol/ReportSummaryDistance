Proceedings of NAACL-HLT 2013, pages 348?358,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsDialectal Arabic to English Machine Translation:Pivoting through Modern Standard ArabicWael Salloum and Nizar HabashCenter for Computational Learning SystemsColumbia University{wael,habash}@ccls.columbia.eduAbstractModern Standard Arabic (MSA) has a wealthof natural language processing (NLP) toolsand resources.
In comparison, resources fordialectal Arabic (DA), the unstandardized spo-ken varieties of Arabic, are still lacking.
Wepresent ELISSA, a machine translation (MT)system for DA to MSA.
ELISSA employs arule-based approach that relies on morpho-logical analysis, transfer rules and dictionar-ies in addition to language models to produceMSA paraphrases of DA sentences.
ELISSAcan be employed as a general preprocessor forDA when using MSA NLP tools.
A man-ual error analysis of ELISSA?s output showsthat it produces correct MSA translations over93% of the time.
Using ELISSA to produceMSA versions of DA sentences as part ofan MSA-pivoting DA-to-English MT solution,improves BLEU scores on multiple blind testsets between 0.6% and 1.4%.1 IntroductionMuch work has been done on Modern Standard Ara-bic (MSA) natural language processing (NLP) andmachine translation (MT), especially Statistical MT(SMT).
MSA has a wealth of resources in terms ofmorphological analyzers, disambiguation systems,and parallel corpora.
In comparison, research on di-alectal Arabic (DA), the unstandardized spoken vari-eties of Arabic, is still lacking in NLP in general andMT in particular.
In this paper we present ELISSA,our DA-to-MSA MT system, and show how it canhelp improve the translation of highly dialectal Ara-bic text into English by pivoting on MSA.The ELISSA approach can be summarized as fol-lows.
First, ELISSA uses different techniques toidentify dialectal words and multi-word construc-tions (phrases) in a source sentence.
Then, ELISSAproduces MSA paraphrases for the selected wordsand phrase using a rule-based component that de-pends on the existence of a dialectal morphologi-cal analyzer, a list of morphosyntactic transfer rules,and DA-MSA dictionaries.
The resulting MSA is ina lattice form that we pass to a language model for n-best decoding.
The output of ELISSA, whether a top-1 choice sentence or n-best sentences, is passed to anMSA-English SMT system to produce the Englishtranslation sentence.
ELISSA-based MSA-pivotingfor DA-to-English SMT improves BLEU scores (Pa-pineni et al 2002) on three blind test sets between0.6% and 1.4%.
A manual error analysis of trans-lated words shows that ELISSA produces correctMSA translations over 93% of the time.The rest of this paper is structured as follows:Section 2 motivates the use of ELISSA to improveDA-English SMT with an example.
Section 3 dis-cusses some of the challenges associated with pro-cessing Arabic and its dialects.
Section 4 presentsrelated work.
Section 5 details ELISSA and itsapproach and Section 6 presents results evaluatingELISSA under a variety of conditions.2 Motivating ExampleTable 1 shows a motivating example of how pivot-ing on MSA can dramatically improve the transla-tion quality of a statistical MT system that is trainedon mostly MSA-to-English parallel corpora.
In thisexample, we use Google Translate?s online Arabic-English SMT system.1 The table is divided into twoparts.
The top part shows a dialectal (Levantine)sentence, its reference translation to English, andits Google Translate translation.
The Google Trans-late translation clearly struggles with most of the DAwords, which were probably unseen in the trainingdata (i.e., out-of-vocabulary ?
OOV) and were con-1The system was used on February 21, 2013.348DA source hP AJ??
@ 	??
?Q.gA?
?KB HAJJ?????J?J.
K?AK?YK.
B?
?
?J.K?J?j ??
@ ?j???
@ ?Jj?
??
?J.J?Jk A?
?A???Am?'A?E..
Y?J.
?
A?
h?QKbhAlHAlh?
hAy mA Hyktbwlw ?HyT AlSfHh Al?xSyh?
tb?w wlA bdn yAh yb?tln kwmyntAt l?nw mAxbrhwn AymtArH yrwH ?Albld.HumanReferenceIn this case, they will not write on his profile wall and they do not want him to send them comments because hedid not tell them when he will go to the country.GoogleTranslateBhalhalh Hi Hictpoulo Ahat Profile Tbau not hull Weah Abatln Comintat Anu Mabarhun Oamta welcomed callsthem Aalbuld.Human ?
??
?
?Q.m'??
?KB HA?J?
?K ???
??QK?
@ ?K?YKQKB??J?j ??
@ ?Jj??
?Ag ???
??
@?J.J?K????Am?
'@ ?Y?
?
?DA-to-MSA .
Y?J.
?
@ ??@I.
?YJ?fy h?h AlHAlh?
ln yktbwA lh ?l?
HAy?T SfHth Al?xSyh?
wlA yrydwnh ?n yrsl lhm t?lyqAt l?nh lm yxbrhm mt?
sy?hbA?l?
Albld.GoogleTranslateIn this case it would not write to him on the wall of his own and do not want to send their comments because hedid not tell them when going to the country.Table 1: A motivating example for DA-to-English MT by pivoting (bridging) on MSA.
The top half of the tabledisplays a DA sentence, its human reference translation and the output of Google Translate.
The bottom half of thetable shows the result of human translation into MSA of the DA sentence before sending it to Google Translate.sidered proper nouns (transliterated and capitalized).The lack of DA-English parallel corpora suggestspivoting on MSA can improve the translation qual-ity.
In the bottom part of the table, we show a hu-man MSA translation of the DA sentence above andits Google translation.
We see that the results arequite promising.
The goal of ELISSA is to model thisDA-MSA translation automatically.
In Section 5.4,we revisit this example to discuss ELISSA?s perfor-mance on it.
We show its output and its correspond-ing Google translation in Table 3.3 Challenges for Processing Arabic and itsDialectsContemporary Arabic is in fact a collection of vari-eties: MSA, the official language of the Arab World,which has a standard orthography and is used informal settings; and DAs, the commonly used in-formal native varieties, which have no standard or-thographies but have an increasing presence on theweb.
Arabic, in general, is a morphologically com-plex language which has rich inflectional morphol-ogy, expressed both templatically and affixationally,and several classes of attachable clitics.
For exam-ple, the Arabic word A?
E?J.J?J??
w+s+y-ktb-wn+hA2?and they will write it?
has two proclitics (+?
w+?and?
and +?
s+ ?will?
), one prefix -?y- ?3rd2Arabic transliteration throughout the paper is presented inthe Habash-Soudi-Buckwalter scheme (Habash et al 2007): (inalphabetical order) Abt?jHxd?rzs?SDTD??
?fqklmnhwy and theadditional symbols: ?
Z, ?
@, A?
@, A?@, w??
', y?
Z?
', h??, ?
?.person?, one suffix 	?
?- -wn ?masculine plural?
andone pronominal enclitic A?+ +hA ?it/her?.
DAs dif-fer from MSA phonologically, morphologically andto a lesser degree syntactically.
The morpholog-ical differences are most noticeably expressed inthe use of clitics and affixes that do not exist inMSA.
For instance, the Levantine Arabic equivalentof the MSA example above is A??J.J?Jk?
w+H+y-ktb-w+hA ?and they will write it?.
The optionalityof vocalic diacritics helps hide some of the differ-ences resulting from vowel changes; compare thediacritized forms: Levantine wHayikitbuwhA andMSA wasayaktubuwnahA.All of the NLP challenges of MSA (e.g., optionaldiacritics and spelling inconsistency) are shared byDA.
However, the lack of standard orthographies forthe dialects and their numerous varieties pose newchallenges.
Additionally, DAs are rather impover-ished in terms of available tools and resources com-pared to MSA, e.g., there is very little parallel DA-English corpora and almost no MSA-DA parallelcorpora.
The number and sophistication of morpho-logical analysis and disambiguation tools in DA isvery limited in comparison to MSA (Duh and Kirch-hoff, 2005; Habash and Rambow, 2006; Abo Bakr etal., 2008; Habash, 2010; Salloum and Habash, 2011;Habash et al 2012; Habash et al 2013).
MSAtools cannot be effectively used to handle DA, e.g.,Habash and Rambow (2006) report that over one-third of Levantine verbs cannot be analyzed usingan MSA morphological analyzer.3494 Related WorkDialectal Arabic NLP.
Several researchers haveexplored the idea of exploiting existing MSA richresources to build tools for DA NLP (Chiang et al2006).
Such approaches typically expect the pres-ence of tools/resources to relate DA words to theirMSA variants or translations.
Given that DA andMSA do not have much in terms of parallel cor-pora, rule-based methods to translate DA-to-MSAor other methods to collect word-pair lists have beenexplored.
For example, Abo Bakr et al(2008) intro-duced a hybrid approach to transfer a sentence fromEgyptian Arabic into MSA.
This hybrid system con-sisted of a statistical system for tokenizing and tag-ging, and a rule-based system for constructing dia-critized MSA sentences.
Moreover, Al-Sabbagh andGirju (2010) described an approach of mining theweb to build a DA-to-MSA lexicon.
In the contextof DA-to-English SMT, Riesa and Yarowsky (2006)presented a supervised algorithm for online mor-pheme segmentation on DA that cut the OOV wordsby half.Machine Translation for Closely Related Lan-guages.
Using closely related languages has beenshown to improve MT quality when resources arelimited.
Hajic?
et al(2000) argued that for veryclose languages, e.g., Czech and Slovak, it is pos-sible to obtain a better translation quality by usingsimple methods such as morphological disambigua-tion, transfer-based MT and word-for-word MT.Zhang (1998) introduced a Cantonese-Mandarin MTthat uses transformational grammar rules.
In thecontext of Arabic dialect translation, Sawaf (2010)built a hybrid MT system that uses both statisticaland rule-based approaches for DA-to-English MT.In his approach, DA is normalized into MSA us-ing a dialectal morphological analyzer.
In previ-ous work, we presented a rule-based DA-MSA sys-tem to improve DA-to-English MT (Salloum andHabash, 2011; Salloum and Habash, 2012).
Our ap-proach used a DA morphological analyzer (ADAM)and a list of hand-written morphosyntactic transferrules.
This use of ?resource-rich?
related languagesis a specific variant of the more general approachof using pivot/bridge languages (Utiyama and Isa-hara, 2007; Kumar et al 2007).
In the case ofMSA and DA variants, it is plausible to considerthe MSA variants of a DA phrase as monolingualparaphrases (Callison-Burch et al 2006; Du et al2010).
Also related is the work by Nakov and Ng(2011), who use morphological knowledge to gener-ate paraphrases for a morphologically rich language,Malay, to extend the phrase table in a Malay-to-English SMT system.Pivoting on MSA or acquiring more DA-Englishdata?
Zbib et al(2012) demonstrated an approachto cheaply obtaining DA-English data.
They usedAmazon?s Mechanical Turk (MTurk) to create a DA-English parallel corpus of 1.5M words and added itto a 150M MSA-English parallel corpus to create thetraining corpus of their SMT system.
They also usedMTurk to translate their dialectal test set to MSAin order to compare the MSA-pivoting approach tothe direct translation from DA to English approach.They showed that even though pivoting on MSA(produced by Human translators in an oracle experi-ment) can reduce OOV rate to 0.98% from 2.27% fordirect translation (without pivoting), it improves by4.91% BLEU while direct translation improves by6.81% BLEU over their 12.29% BLEU baseline (di-rect translation using the 150M MSA system).
Theyconcluded that simple vocabulary coverage is notsufficient and the domain mismatch is a more im-portant problem.
The approach we take in this paperis orthogonal to such efforts to build parallel data.We plan to study interactions between the two typesof solutions in the future.Our work is most similar to Sawaf (2010)?s MSA-pivoting approach.
In his approach, DA is normal-ized into MSA using character-based DA normal-ization rules, a DA morphological analyzer, a DAnormalization decoder that relies on language mod-els, and a lexicon.
Similarly, we use some char-acter normalization rules, a DA morphological an-alyzer, and DA-MSA dictionaries.
In contrast, weuse hand-written morphosyntactic transfer rules thatfocus on translating DA morphemes and lemmas totheir MSA equivalents.In our previous work (Salloum and Habash, 2011;Salloum and Habash, 2012), we applied our ap-proach to tokenized Arabic and our DA-MSA trans-fer component used feature transfer rules only.
Wedid not use a language model to pick the best path;instead we kept the ambiguity in the lattice andpassed it to our SMT system.
In contrast, in this pa-per, we run ELISSA on untokenized Arabic, we use350feature, lemma, and surface form transfer rules, andwe pick the best path of the generated MSA latticethrough a language model.Certain aspects of our approach are similar toRiesa and Yarowsky (2006)?s, in that we use mor-phological analysis for DA to help DA-English MT;but unlike them, we use a rule-based approach tomodel DA morphology.5 ELISSAELISSA is a DA-to-MSA MT System.
ELISSA usesa rule-based approach (with some statistical compo-nents) that relies on the existence of a DA morpho-logical analyzer, a list of hand-written transfer rules,and DA-MSA dictionaries to create a mapping ofDA to MSA words and construct a lattice of pos-sible sentences.
ELISSA uses a language model torank and select the generated sentences.ELISSA supports untokenized (raw) input only.ELISSA supports three types of output: top-1 choice,an n-best list or a map file that maps sourcewords/phrases to target phrases.
The top-1 and n-best lists are determined using an untokenized MSAlanguage model to rank the paths in the MSA trans-lation output lattice.
This variety of output typesmakes it easy to plug ELISSA with other systems andto use it as a DA preprocessing tool for other MSAsystems, e.g., MADA (Habash and Rambow, 2005)or AMIRA (Diab et al 2007).ELISSA?s approach consists of three major stepspreceded by a preprocessing and normalization step,that prepares the input text to be handled (e.g., UTF-8 cleaning, Alif/Ya normalization, word-lengtheningnormalization), and followed by a post-processingstep, that produces the output in the desired form(e.g., encoding choice).
The three major steps areSelection, Translation, and Language Modeling.5.1 SelectionIn the first step, ELISSA identifies which words orphrases to paraphrase and which words or phrasesto leave as is.
ELISSA provides different methods(techniques) for selection, and can be configured touse different subsets of them.
In Section 6 we use theterm "selection mode" to denote a subset of selec-tion methods.
Selection methods are classified intoWord-based selection and Phrase-based selection.Word-based selection.
Methods of this type fallin the following categories:a.
User token-based selection: The user can markspecific words for selection using the tag ?/DIA?
(stands for ?dialect?)
after each word to select.b.
User type-based selection: The user can specifya list of words to select from, e.g., OOVs.
Alsothe user can provide a list of words and theirfrequencies and specify a cut-off threshold toprevent selecting a frequent word.c.
Morphology-based word selection: ELISSAuses ADAM (Salloum and Habash, 2011)to select words that have DA analyses only(DIAONLY) or DA/MSA analyses (DIAMSA).d.
Dictionary-based selection: ELISSA selectswords based on their existence in the DA sideof our DA-MSA dictionaries.e.
All: ELISSA selects every word in an input sen-tence.Phrase-based selection.
This selection type useshand-written rules to identify dialectal multi-wordconstructions that are mappable to single or multi-word MSA constructions.
The current count of theserules is 25.
Table 2 presents some rule categoriesand related examples.In the current version of ELISSA, words canbe selected using either the phrase-based selectionmethod or a word-based selection method, but notboth.
Phrase-based selection has precedence.
Weevaluate different settings for selection step in Sec-tion 6.5.2 TranslationIn this step, ELISSA translates the selected wordsand phrases to their MSA equivalent paraphrases.The specific type of selection determines the type ofthe translation, e.g., phrase-based selected words aretranslated using phrase-based translation rules.
TheMSA paraphrases are then used to form an MSA lat-tice.Word-based translation.
This category has twotypes of translation techniques: surface transla-tion that uses DA-to-MSA surface-to-surface (S2S)transfer rules (TRs) and deep (morphological) trans-lation that uses the classic rule-based machine trans-lation flow: analysis, transfer and generation.
The351Rule Category Selection Examples Translation ExamplesDialectal Idafa A 	J?AJK.
?????
@ ?m.?
'@ Aljy?
AlwTny btA?nA ?????
@ AJ ?k.
jy?nA AlwTny?the-army the-national ours?
?our-army the-national?Verb + 	??AKA??Q?
?k HDrlhA yAhn A??
??Q?
?k HDrhm lhAflipped direct and indirect objects ?he-prepared-for-her them?
?he-prepared-them for-her?Special dialectal expressions A?AK@ ?YK.
bdw AyAhA A?YKQKyrydhA?his-desire her?
?he-desires-her?Negation + verb ??
?J.J?Jk A??
wmA Hyktbwlw ??
@?J.J?K???
wln yktbwA lh?and-not they-will-write-to-him?
?and-will-not they-write to-him?Negation + agent noun?J?B ???
fm?
lAqyh?
Ym.' C?
flA tjd?so-not finding?
?so-not she-finds?Negation + closed-class words ??Y?
A?
mA ?dkm ??KY?
??
lys ldykm?not with-you?
?not with-you?Table 2: Examples of some types of phrase-based selection and translation rules.DA Phrase B?k@P A??
wmA rAHwlA ?And they did not go to her?Analysis Word 1 Word 2Proclitics [Lemma & Features] [Lemma & Features] [Lemma & Features] Encliticw+ mA rAHw +l +Aconj+ [neg] [rAH PV subj:3MP] +prep +pron3FSand+ not they go +to +herTransfer Word 1 Word 2 Word 3Proclitics [Lemma & Features] [Lemma & Features] [Lemma & Features] Encliticconj+ [ lam ] [?ahab IV subj:3MP] [ A?l? ]
+pron3FSand+ did not they go to +herGeneration w+ lm y?hbwA A?ly +hAMSA Phrase A?D?
@@?J.?YK???
wlm y?hbwA A?lyhA ?And they did not go to her?Figure 1: An example illustrating the analysis-transfer-generation steps to translate a dialectal multi-word expressioninto its MSA equivalent phrase.dialectal morphological analysis step uses ADAM(Salloum and Habash, 2011) to get a list of di-alectal analyses.
The morphosyntactic transferstep uses lemma-to-lemma (L2L) and features-to-features (F2F) transfer rules to change lemmas, cl-itics or features, and even split up the dialectal wordinto multiple MSA word analyses (such as splittingnegation words and indirect objects).
The MSAmorphological generation step uses the general to-kenizer/generator TOKAN (Habash, 2007) to gen-erate untokenized surface form words.
For more de-tails, see Salloum and Habash (2011).Phrase-based translation.
Unlike the word-based translation techniques which map single DAwords to single or multi-word MSA sequences, thistechnique uses hand-written multi-word transferrules that map multi-word DA constructions tosingle or multi-word MSA constructions.
In thecurrent system, there are 47 phrase-based transferrules.
Many of the word-based morphosyntactictransfer rules are re-used for phrase-based transla-tion.
Figure 1 shows an example of a phrase-basedmorphological translation of the two-word DAsequence B?k@P A??
wmA rAHwlA ?And they didnot go to her?.
If these two words were spelled as asingle word, B?k@PA??
wmArAHwlA, we would stillget the same result using the word-based translationtechnique only.
Table 2 shows some rule categoriesalong with selection and translation examples.5.3 Language ModelingThe language model (LM) component uses theSRILM lattice-tool for weight assignment and n-best decoding (Stolcke, 2002).
ELISSA comes witha default 5-gram LM file trained on ?200M unto-352DA source 7 HAJ 	J??
?6 	??J?J.
K5( ?AK?YK.)
B?4(?
?J.K?J?j ??
@ ?j???@)3?Jj?2(??
?J.J?Jk A?)1(?A???Am?'A?E.
).12 Y?J.
?
A?11(h?QKhP)10AJ??@9??
?Q.gA?8?KB(bhAlHAlh?
hAy)1 (mA Hyktbwlw)2 ?HyT3 (AlSfHh Al?xSyh?
tb?w)4 wlA (bdn yAh)5 yb?tln6 kwmyntAt7 l?nw8mAxbrhwn9 AymtA10 (rH yrwH)11 ?Albld12.Human Ref-erenceIn this case, they will not write on his profile wall and they do not want him to send them comments because he didnot tell them when he will go to the country.GoogleTranslateBhalhalh Hi Hictpoulo Ahat Profile Tbau not hull Weah Abatln Comintat Anu Mabarhun Oamta welcomed callsthem Aalbuld.ELISSA 6 (??D?
@ ??QK)5(?
@ ?K?YKQK) B?4(?J?j ??
@ ?Jj??
)3(?Ag ???
)2( ??
@?J.J?K??)1(??Am?
'@ ?Y?
??
)DA-to-MSA .
12 (Y?J.
?
@ ??@)11I.
?YJ?10???9(?
?Q.m'??
)8?KB7 HA?J?
?K(fy h?h AlHAlh?
)1 (ln yktbwA lh)2 (?ly HAy?T)3 (SfHth Al?xSyh?
)4 wlA (yrydwnh An)5 (yrsl Alyhm)6 t?lyqAt7 lAnh8(lm yxbrhm)9 mty10 sy?hb11 (Aly Albld)12.GoogleTranslateIn this case it would not write to him on the wall of his own and do not want to send them comments that he did nottell them when going to the country.Table 3: Revisiting our motivating example, but with ELISSA-based DA-to-MSA middle step.
ELISSA?s output isAlif/Ya normalized.
Parentheses are added for illustrative reasons to highlight how multi-word DA constructions areselected and translated.
Superscript indices link the selected words and phrases with their MSA translations.kenized Arabic words of Arabic Gigaword (Parkeret al 2009).
Users can specify their own LM fileand/or interpolate it with our default LM.
This isuseful for adapting ELISSA?s output to the Arabicside of the training data.5.4 Revisiting our Motivating ExampleWe revisit our motivating example in Section 2 andshow automatic MSA-pivoting through ELISSA.
Ta-ble 3 is divided into two parts.
The first part iscopied from Table 1 for convenience.
The secondpart shows ELISSA?s output on the dialectal sentenceand its Google Translate translation.
The producedMSA is not perfect, but is clearly an improvementover doing nothing as far as usability for MT intoEnglish.6 EvaluationIn this section, we present two evaluations ofELISSA.
The first is an extrinsic evaluation ofELISSA as part of MSA-pivoting for DA-to-EnglishSMT.
And the second is an intrinsic evaluation ofthe quality of ELISSA?s MSA output.6.1 DA-English MT Evaluation6.1.1 Experimental SetupWe use the open-source Moses toolkit (Koehnet al 2007) to build a phrase-based SMT systemtrained on mostly MSA data (64M words on theArabic side) obtained from several LDC corpora in-cluding some limited DA data.
Our system usesa standard phrase-based architecture.
The paral-lel corpus is word-aligned using GIZA++ (Och andNey, 2003).
Phrase translations of up to 10 wordsare extracted in the Moses phrase table.
The lan-guage model for our system is trained on the En-glish side of the bitext augmented with English Gi-gaword (Graff and Cieri, 2003).
We use a 5-gramlanguage model with modified Kneser-Ney smooth-ing.
Feature weights are tuned to maximize BLEUon the NIST MTEval 2006 test set using MinimumError Rate Training (Och, 2003).
This is only doneon the baseline systems.
The English data is tok-enized using simple punctuation-based rules.
TheArabic side is segmented according to the ArabicTreebank (ATB) tokenization scheme (Maamouri etal., 2004) using the MADA+TOKAN morphologi-cal analyzer and tokenizer v3.1 (Habash and Ram-bow, 2005; Roth et al 2008).
The Arabic text isalso Alif/Ya normalized.
MADA-produced Arabiclemmas are used for word alignment.We use the same development (dev) and test setsused by Salloum and Habash (2011) (we will callthem speech-dev and speech-test, respectively) andwe compare to them in the next sections.
We alsoevaluate on two web-crawled blind test sets: theLevantine test set presented in Zbib et al(2012) (wewill call it web-lev-test) and the Egyptian Dev-MT-v2 development data of the DARPA BOLT program(we will call it web-egy-test).
The speech-dev sethas 1,496 sentences with 32,047 untokenized Arabicwords.
The speech-test set has 1,568 sentences with35332,492 untokenized Arabic words.
The web-lev-test set has 2,728 sentences with 21,179 untokenizedArabic words.
The web-egy-test set has 1,553 sen-tences with 21,495 untokenized Arabic words.
Thetwo speech test sets contain multi-dialect (e.g., Iraqi,Levantine, Gulf, and Egyptian) broadcast conver-sational (BC) segments (with three reference trans-lations), and broadcast news (BN) segments (withonly one reference, replicated three times).
Theweb-egy-test has two references while the web-lev-test has only one reference.
Results are presented interms of BLEU (Papineni et al 2002).
All evalua-tion results are case insensitive.6.1.2 Results on the Development SetWe experimented with different method combi-nations in the selection and translation componentsin ELISSA.
We use the term selection mode andtranslation mode to denote a certain combinationof methods in selection or translation, respectively.Due to limited space, we only present the best se-lection mode variation experiments.
Other selectionmodes were tried but they proved to be consistentlylower than the rest.
The ?F2F+L2L; S2S?
word-based translation mode (using morphological trans-fer of features and lemmas along with surface formtransfer) showed to be consistently better than othermethod combinations across all selection modes.
Inthis paper we only use ?F2F+L2L; S2S?
word-basedtranslation mode.
Phrase-based translation mode isused when phrase-based selection mode is used.To rank paraphrases in the generated MSA lattice,we combine two 5-gram untokenized Arabic lan-guage models: one is trained on Arabic Gigaworddata and the other is trained the Arabic side of ourSMT training data.
The use of the latter LM gavefrequent dialectal phrases a higher chance to appearin ELISSA?s output; thus, making the output "moredialectal" but adapting it to our SMT input.
Exper-iments showed that using both LMs is better thanusing each one alone.In all the experiments, we run the DA sentencethrough ELISSA to generate a top-1 MSA transla-tion, which we then tokenize through MADA be-fore sending to the MSA-English SMT system.
Ourbaseline is to not run ELISSA at all; instead, we sendthe DA sentence through MADA before applyingthe MSA-English MT system.Table 4 summarizes the experiments and resultson the dev set.
The rows of the table are the dif-ferent systems (baseline and ELISSA?s experiments).All differences in BLEU scores from the baselineare statistically significant above the 95% level.
Sta-tistical significance is computed using paired boot-strap re-sampling (Koehn, 2004).
The name of thesystem in ELISSA?s experiments denotes the com-bination of selection method.
ELISSA?s experi-ments are grouped into three groups: simple selec-tion, frequency-based selection, and phrase-basedselection.
Simple selection group consists of fivesystems: OOV, ADAM, OOV U ADAM, DICT,and OOV U ADAM U DICT.
The OOV selectionmode identifies the untokenized OOV words.
Inthe ADAM selection mode, or the morphologicalselection mode, we use ADAM to identify dialec-tal words.
Experiments showed that ADAM?s DI-AMSA mode (selecting words that have at least onedialectal analysis) is slightly better than ADAM?sDIAONLY mode (selecting words that have only di-alectal analyses and no MSA ones).
The OOV UADAM selection mode is the union of the OOVsand ADAM selection modes.
In DICT selectionmode, we select dialectal words that exist in our DA-MSA dictionaries.
The OOV U ADAM U DICTselection mode is the union of the OOVs, ADAM,and DICT selection modes.
The results show thatcombining the output of OOV selection method andADAM selection method is the best.
DICT selec-tion method hurts the performance of the systemwhen used because dictionaries usually have fre-quent dialectal words that the SMT system alreadyknows how to handle.In the frequency-based selection group, we ex-clude from word selection all words with number ofoccurrences in the training data that is above a cer-tain threshold.
This threshold was determined em-pirically to be 50.
The string ?- (Freq >= 50)?
meansthat all words with frequencies of 50 or more shouldnot be selected.
The results show that excluding fre-quent dialectal words improves the best simple se-lection system.
It also shows that using DICT selec-tion improves the best system if frequent words areexcluded.In the last system group, phrase+word-based se-lection, phrase-based selection is used to selectphrases and add them on top of the best perform-ers of the previous two groups.
Phrase-based trans-354Test Set speech-devBLEU Diff.Baseline 37.20 0.00Select: OOV 37.75 0.55Select: ADAM 37.88 0.68Select: OOV U ADAM 37.89 0.69Select: DICT 37.06 -0.14Select: OOV U ADAM U DICT 37.53 0.33Select: (OOV U ADAM) - (Freq >= 50) 37.96 0.76Select: (OOV U ADAM U DICT) - (Freq >= 50) 38.00 0.80Select: Phrase; (OOV U ADAM) 37.99 0.79Select: Phrase; ((OOV U ADAM) - (Freq >= 50)) 38.05 0.85Select: Phrase; ((OOV U ADAM U DICT) - (Freq >= 50)) 38.10 0.90Table 4: Results for the speech-dev set in terms of BLEU.
The ?Diff.?
column shows result differences from thebaseline.
The rows of the table are the different systems (baseline and ELISSA?s experiments).
The name of thesystem in ELISSA?s experiments denotes the combination of selection method.
In all ELISSA?s experiments, all word-based translation methods are tried.
Phrase-based translation methods are used when phrase-based selection is used(i.e., the last three rows).
The best system is in bold.lation is also added to word-based translation.
Re-sults show that selecting and translating phrases im-prove the three best performers of word-based se-lection.
The best performer, shown in the last raw,suggests using phrase-based selection and restrictedword-based selection.
The restriction is to includeOOV words and selected low frequency words thathave at least one dialectal analysis or appear in ourdialectal dictionaries.
Comparing the best performerto the OOV selection mode system shows that trans-lating low frequency in-vocabulary dialectal wordsand phrases to their MSA paraphrases can improvethe English translation.
This is a similar conclusionto our previous work in Salloum and Habash (2011).6.1.3 Results on the Blind Test SetsWe run the system settings that performed best onthe dev set alg with the OOV selection mode sys-tem on the three blind test set.
Results and their dif-ferences from the baseline are reported in Table 5.We see that OOV selection mode system always im-proves over the baseline for all test sets.
Also, thebest performer on the dev is the best performer forall test sets.
The improvements of the best per-former over the OOV selection mode system on alltest sets confirm that translating low frequency in-vocabulary dialectal words and phrases to their MSAparaphrases can improve the English translation.
Itsimprovements over the baseline for the three test setsare: 0.95% absolute BLEU (or 2.5% relative) for thespeech-test, 1.41% absolute BLEU (or 15.4% rela-tive) for the web-lev-test, and 0.61% absolute BLEU(or 3.2% relative) for the web-egy-test.6.1.4 A Case StudyWe next examine an example in some detail.Table 6 shows a dialectal sentence along with itsELISSA?s translation, English references, the outputof the baseline system and the output of our bestsystem.
The example shows a dialectal word 	??J.
??
A?hAlmbl?
?this-amount/sum?, which is not translatedby the baseline (although it appears in the trainingdata, but quite infrequently such that all of its phrasetable occurrences have restricted contexts, mak-ing it effectively an OOV).
The dialectal proclitic+?A?
hAl+ ?this-?
comes sometimes in the dialec-tal construction: ?hAl+NOUN DEM?
(as in this ex-ample: @Y?
??J.
??
A?
hAlmbl?
h?A ?this-amount/sumthis?).
ELISSA?s selection component captures thismulti-word expression and its translation componentproduces the following paraphrases: 	??J.
??
@ @Y?
h?AAlmbl?
?this amount/sum?
(h?A is used with mas-culine singular nouns), 	??J.
??
@ ?Y?
h?h Almbl?
?thisamount/sum?
(h?h is used with feminine singularor irrational plural nouns), and 	??J.
??
@ ZB??
hw?lA?Almbl?
?these amount/sum?
(hw?lA?
is used withrational plural nouns).
ELISSA?s language mod-eling component picks the first MSA paraphrase,which perfectly fits the context and satisfies thegender/number/rationality agreement (note that theword Almbl?
is an irrational masculine singular355Test Set speech-test web-lev-test web-egy-testBLEU Diff.
BLEU Diff.
BLEU Diff.Baseline 38.18 0.00 9.13 0.00 18.98 0.00Select: OOV 38.76 0.58 9.65 0.62 19.19 0.21Select: Phrase; ((OOV U ADAM U DICT) - (Freq >= 50)) 39.13 0.95 10.54 1.41 19.59 0.61Table 5: Results for the three blind test sets (table columns) in terms of BLEU.
The ?Diff.?
columns show resultdifferences from the baselines.
The rows of the table are the different systems (baselines and ELISSA?s experiments).The best systems are in bold.noun).
For more on Arabic morpho-syntactic agree-ment patterns, see Alkuhlani and Habash (2011).Finally, the best system translation for the selectedphrase is ?this sum?.
We can see how both the accu-racy and fluency of the sentence have improved.DA sentence fmA mA AtSwr hAlmbl?
h?A y?ny.ELISSA?s output fmA mA AtSwr h?A Almbl?
y?ny.References I don?t think this amount is I mean.So I do not I do not think this cost I mean.So I do not imagine this sum I meanBaseline So i don?t think hAlmblg this means.Best system So i don?t think this sum i mean.Table 6: An example of handling dialectal words/phrasesusing ELISSA and its effect on the accuracy and fluencyof the English translation.
Words of interest are bolded.6.2 DA-to-MSA Translation QualityWe conducted a manual error analysis comparingELISSA?s input (the original dev set) to its outputusing our best system settings from the experimentsabove.
Out of 708 affected sentences, we randomlyselected 300 sentences (42%).
Out of the 482 han-dled tokens, 449 (93.15%) tokens have good MSAtranslations, and 33 (6.85%) tokens have wrongMSA translations.
Most of the wrong translationsare due to spelling errors, proper nouns, and weakinput sentence fluency (especially due to speech ef-fect).
This analysis clearly validates ELISSA?s MSAoutput.
Of course, a correct MSA output can still bemistranslated by the MT system we used above if itis not in the vocabulary of the MT system.7 Conclusion and Future WorkWe presented ELISSA, a tool for DA-MSA transla-tion.
ELISSA employs a rule-based MT approachthat relies on morphological analysis, transfer rulesand dictionaries in addition to language models toproduce MSA paraphrases of dialectal sentences.Using ELISSA to produce MSA versions of dialec-tal sentences as part of an MSA-pivoting DA-to-English MT solution, improves BLEU scores onthree blind test sets by: 0.95% absolute BLEU(or 2.5% relative) for a speech multi-dialect (Iraqi,Levantine, Gulf, Egyptian) test set, 1.41% absoluteBLEU (or 15.4% relative) for a web-crawled Levan-tine test set, and 0.61% absolute BLEU (or 3.2% rel-ative) for a web-crawled Egyptian test set.
A man-ual error analysis of translated selected words showsthat our system produces correct MSA translationsover 93% of the time.In the future, we plan to extend ELISSA?s cover-age of phenomena in the handled dialects and to newdialects.
We also plan to automatically learn addi-tional rules from limited available data (DA-MSAor DA-English).
We also would like to do additionalMT experiments where we use ELISSA to prepro-cess the training data, comparable to experimentsdone by Sawaf (2010).
We are interested in studyinghow our approach can be combined with solutionsthat simply add more dialectal training data sincethe two directions are complementary in that theyaddress linguistic normalization and domain cov-erage.
Finally, we look forward to experimentingwith ELISSA as a preprocessing system for a varietyof dialect NLP applications similar to Chiang et al(2006)?s work on dialect parsing, for example.ELISSA will be publicly available.
Please contactthe authors for more information.AcknowledgmentThis paper is based upon work supported bythe Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-12-C-0014.Any opinions, findings and conclusions or recom-mendations expressed in this paper are those of theauthors and do not necessarily reflect the views ofDARPA.356ReferencesHitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan.2008.
A Hybrid Approach for Converting WrittenEgyptian Colloquial Dialect into Diacritized Arabic.In The 6th International Conference on Informaticsand Systems, INFOS2008.
Cairo University.Rania Al-Sabbagh and Roxana Girju.
2010.
Mining theWeb for the Induction of a Dialectical Arabic Lexicon.In Nicoletta Calzolari, Khalid Choukri, Bente Mae-gaard, Joseph Mariani, Jan Odijk, Stelios Piperidis,Mike Rosner, and Daniel Tapias, editors, LREC.
Eu-ropean Language Resources Association.Sarah Alkuhlani and Nizar Habash.
2011.
A Corpusfor Modeling Morpho-Syntactic Agreement in Ara-bic: Gender, Number and Rationality.
In Proceed-ings of the 49th Annual Meeting of the Association forComputational Linguistics (ACL?11), Portland, Ore-gon, USA.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine transla-tion using paraphrases.
In Proceedings of the HumanLanguage Technology Conference of the NAACL, MainConference, pages 17?24.David Chiang, Mona Diab, Nizar Habash, Owen Ram-bow, and Safiullah Shareef.
2006.
Parsing ArabicDialects.
In Proceedings of the European Chapter ofACL (EACL).Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2007.Automated Methods for Processing Arabic Text: FromTokenization to Base Phrase Chunking.
In Antalvan den Bosch and Abdelhadi Soudi, editors, ArabicComputational Morphology: Knowledge-based andEmpirical Methods.
Kluwer/Springer.Jinhua Du, Jie Jiang, and Andy Way.
2010.
Facil-itating translation using source language paraphraselattices.
In Proceedings of the 2010 Conferenceon Empirical Methods in Natural Language Process-ing, EMNLP?10, pages 420?429, Cambridge, Mas-sachusetts.Kevin Duh and Katrin Kirchhoff.
2005.
POS tagging ofdialectal Arabic: a minimally supervised approach.
InProceedings of the ACL Workshop on ComputationalApproaches to Semitic Languages, Semitic ?05, pages55?62, Ann Arbor, Michigan.David Graff and Christopher Cieri.
2003.
English Gi-gaword, LDC Catalog No.
: LDC2003T05.
LinguisticData Consortium, University of Pennsylvania.Nizar Habash and Owen Rambow.
2005.
Arabic Tok-enization, Part-of-Speech Tagging and MorphologicalDisambiguation in One Fell Swoop.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics (ACL?05), pages 573?580, AnnArbor, Michigan.Nizar Habash and Owen Rambow.
2006.
MAGEAD:A Morphological Analyzer and Generator for the Ara-bic Dialects.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for ComputationalLinguistics, pages 681?688, Sydney, Australia.Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.2007.
On Arabic Transliteration.
In A. van den Boschand A. Soudi, editors, Arabic Computational Mor-phology: Knowledge-based and Empirical Methods.Springer.Nizar Habash, Ramy Eskander, and Abdelati Hawwari.2012.
A Morphological Analyzer for Egyptian Ara-bic.
In Proceedings of the Twelfth Meeting of the Spe-cial Interest Group on Computational Morphology andPhonology, pages 1?9, Montr?al, Canada.Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskan-der, and Nadi Tomeh.
2013.
Morphological Analysisand Disambiguation for Dialectal Arabic.
In Proceed-ings of the 2013 Conference of the North AmericanChapter of the Association for Computational Linguis-tics: Human Language Technologies (NAACL-HLT),Atlanta, GA.Nizar Habash.
2007.
Arabic Morphological Representa-tions for Machine Translation.
In A. van den Boschand A. Soudi, editors, Arabic Computational Mor-phology: Knowledge-based and Empirical Methods.Springer.Nizar Habash.
2010.
Introduction to Arabic NaturalLanguage Processing.
Morgan & Claypool Publish-ers.Jan Hajic?, Jan Hric, and Vladislav Kubon.
2000.
Ma-chine Translation of Very Close Languages.
In Pro-ceedings of the 6th Applied Natural Language Pro-cessing Conference (ANLP?2000), pages 7?12, Seat-tle.Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-pher Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Christopher Dyer, Ondrej Bo-jar, Alexandra Constantin, and Evan Herbst.
2007.Moses: open source toolkit for statistical machinetranslation.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational LinguisticsCompanion Volume Proceedings of the Demo andPoster Sessions, pages 177?180, Prague, Czech Re-public.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofEMNLP 2004, pages 388?395, Barcelona, Spain, July.Association for Computational Linguistics.Shankar Kumar, Franz J. Och, and Wolfgang Macherey.2007.
Improving word alignment with bridge lan-guages.
In Proceedings of the 2007 Joint Conference357on Empirical Methods in Natural Language Process-ing and Computational Natural Language Learning(EMNLP-CoNLL), pages 42?50, Prague, Czech Re-public.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank:Building a Large-Scale Annotated Arabic Corpus.
InNEMLAR Conference on Arabic Language Resourcesand Tools, pages 102?109, Cairo, Egypt.Preslav Nakov and Hwee Tou Ng.
2011.
Translat-ing from Morphologically Complex Languages: AParaphrase-Based Approach.
In Proceedings of theMeeting of the Association for Computational Linguis-tics (ACL?2011), Portland, Oregon, USA.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum Error Rate Trainingfor Statistical Machine Translation.
In Proceedingsof the 41st Annual Conference of the Association forComputational Linguistics, pages 160?167, Sapporo,Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for Automatic Eval-uation of Machine Translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia, PA.Robert Parker, David Graff, Ke Chen, Junbo Kong, andKazuaki Maeda.
2009.
Arabic Gigaword Fourth Edi-tion.
LDC catalog number No.
LDC2009T30, ISBN1-58563-532-4.Jason Riesa and David Yarowsky.
2006.
Minimally Su-pervised Morphological Segmentation with Applica-tions to Machine Translation.
In Proceedings of the7th Conference of the Association for Machine Trans-lation in the Americas (AMTA06), pages 185?192,Cambridge,MA.Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,and Cynthia Rudin.
2008.
Arabic Morphological Tag-ging, Diacritization, and Lemmatization Using Lex-eme Models and Feature Ranking.
In Proceedings ofACL-08: HLT, Short Papers, pages 117?120, Colum-bus, Ohio.Wael Salloum and Nizar Habash.
2011.
Dialectalto Standard Arabic Paraphrasing to Improve Arabic-English Statistical Machine Translation.
In Proceed-ings of the First Workshop on Algorithms and Re-sources for Modelling of Dialects and Language Va-rieties, pages 10?21, Edinburgh, Scotland.Wael Salloum and Nizar Habash.
2012.
Elissa: A Di-alectal to Standard Arabic Machine Translation Sys-tem.
In Proceedings of the 24th International Confer-ence on Computational Linguistics (COLING 2012):Demonstration Papers, pages 385?392, Mumbai, In-dia.Hassan Sawaf.
2010.
Arabic dialect handling in hybridmachine translation.
In Proceedings of the Confer-ence of the Association for Machine Translation in theAmericas (AMTA), Denver, Colorado.Andreas Stolcke.
2002.
SRILM an Extensible LanguageModeling Toolkit.
In Proceedings of the InternationalConference on Spoken Language Processing.Masao Utiyama and Hitoshi Isahara.
2007.
A compar-ison of pivot methods for phrase-based statistical ma-chine translation.
In HLT-NAACL, pages 484?491.Rabih Zbib, Erika Malchiodi, Jacob Devlin, DavidStallard, Spyros Matsoukas, Richard Schwartz, JohnMakhoul, Omar F. Zaidan, and Chris Callison-Burch.2012.
Machine Translation of Arabic Dialects.
In Pro-ceedings of the 2012 Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics: Human Language Technologies, pages 49?59, Montr?al, Canada, June.
Association for Compu-tational Linguistics.Xiaoheng Zhang.
1998.
Dialect MT: a case study be-tween Cantonese and Mandarin.
In Proceedings of the36th Annual Meeting of the Association for Computa-tional Linguistics and 17th International Conferenceon Computational Linguistics, ACL ?98, pages 1460?1464, Montreal, Canada.358
