Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 189?192,New York, June 2006. c?2006 Association for Computational LinguisticsBioEx: A Novel User-Interface that Accesses Images from Abstract SentencesHong Yu Minsuk LeeDepartment of Biomedical Informatics Department of Biomedical InformaticsColumbia University Columbia UniversityNew York, NY 10032 New York, NY 10032Hy52@columbia.edu minsuk.lee@gmail.comAbstractImages (i.e., figures or tables) are important ex-perimental results that are typically reported inbioscience full-text articles.
Biologists need toaccess the images to validate research facts andto formulate or to test novel research hypothe-ses.
We designed, evaluated, and implemented anovel user-interface, BioEx, that allows biolo-gists to access images that appear in a full-textarticle directly from the abstract of the article.1 IntroductionThe rapid growth of full-text electronic publica-tions in bioscience has made it necessary to cre-ate information systems that allow biologists tonavigate and search efficiently among them.
Im-ages are usually important experimental resultsthat are typically reported in full-text biosciencearticles.
An image is worth a thousand words.Biologists need to access image data to validateresearch facts and to formulate or to test novelresearch hypotheses.
Additionally, full-text arti-cles are frequently long and typically incorpo-rate multiple images.
For example, we havefound an average of 5.2 images per biologicalarticle in the journal Proceedings of the NationalAcademy of Sciences (PNAS).
Biologists need tospend significant amount of time to read the full-text articles in order to access specific images.Figure 1.
BioEx user-interface (as shown in A) is built upon the PubMed user-interface.
Imagesare shown as thumbnails at the bottom of a PubMed abstract.
Images include both Figure and Ta-ble.
When a mouse (as shown as a hand in A) moves to ?Fig x?, it shows the associated abstractsentence(s) that link to the original figure that appears in the full-text articles.
For example, ?Fig1?
links to image B.
?Related Text?
provides links to other associated texts that correspond to theimage besides its image caption.189In order to facilitate biologists?
access to images,we designed, evaluated, and implemented anovel user-interface, BioEx, that allows biolo-gists to access images that appear in a full-textarticle directly from the abstract of the article.
Inthe following, we will describe the BioEx user-interface, evaluation, and the implementation.2.
Data CollectionWe hypothesize that images reported in a full-text article can be summarized by sentences inthe abstract.
To test this hypothesis, we ran-domly selected a total of 329 biological articlesthat are recently published in leading journalsCell (104), EMBO (72), Journal of BiologicalChemistry (92), and Proceedings of the NationalAcademy of Sciences (PNAS) (61).
For each arti-cle, we e-mailed the corresponding author andinvited him or her to identify abstract sentencesthat summarize image content in that article.
Inorder to eliminate the errors that may be intro-duced by sentence boundary ambiguity, wemanually segmented the abstracts into sentencesand sent the sentences as the email attachments.A total of 119 biologists from 19 countries par-ticipated voluntarily the annotation to identifyabstract sentences that summarize figures or ta-bles from 114 articles (39 Cells, 29 EMBO, 30Journal of Biological Chemistry, and 16 PNAS),a collection that is 34.7% of the total articles werequested.
The responding biologists includedthe corresponding authors to whom we had sentemails, as well as the first authors of the articlesto whom the corresponding authors had for-warded our emails.
None of the biologists orauthors were compensated.This collection of 114 full-text articles incorpo-rates 742 images and 826 abstract sentences.The average number of images per document is6.5?1.5 and the average number of sentences perabstract is 7.2?1.9.
Our data show that 87.9%images correspond to abstract sentences and66.5% of the abstract sentences correspond toimages.
The data empirically validate our hy-pothesis that image content can be summarizedby abstract sentences.
Since an abstract is a sum-mary of a full-text article, our results also em-pirically validate that images are importantelements in full-text articles.
This collection of114 annotated articles was then used as the cor-pus to evaluate automatic mapping of abstractsentences to images using the natural languageprocessing approaches described in Section 4.3.
BioEx User-Interface EvaluationIn order to evaluate whether biologists wouldprefer to accessing images from abstract sen-tence links, we designed BioEx (Figure 1) andtwo other baseline user-interfaces.
BioEx is builtupon the PubMed user-interface except that im-ages can be accessed by the abstract sentences.We chose the PubMed user-interface because ithas more than 70 million hits a month and repre-sents the most familiar user-interface to biolo-gists.
Other information systems have alsoadapted the PubMed user-interface for similarreasons (Smalheiser and Swanson 1998; Hearst2003).
The two other baseline user-interfaceswere the original PubMed user-interface and amodified version of the SummaryPlus user-interface, in which the images are listed as dis-jointed thumbnails rather than related by abstractsentences.We asked the 119 biologists who linked sen-tences to images in their publications to assign alabel to each of the three user-interfaces to be?My favorite?, ?My second favorite?, or ?Myleast favorite?.
We designed the evaluation sothat a user-interface?s label is independent of thechoices of the other two user-interfaces.A total of 41 or 34.5% of the biologists com-pleted the evaluation in which 36 or 87.8% ofthe total 41 biologists judged BioEx as ?My fa-vorite?.
One biologist judged all three user-interfaces to be ?My favorite?.
Five other biolo-gists considered SummaryPlus as ?My favorite?,two of whom (or 4.9% of the total 41 biologists)judged BioEx to be ?My least favorite?.4.
Linking Abstract Sentences to ImagesWe have explored hierarchical clustering algo-rithms to cluster abstract sentences and imagecaptions based on lexical similarities.Hierarchical clustering algorithms are well-established algorithms that are widely used in190many other research areas including biologicalsequence alignment (Corpet 1988), gene expres-sion analyses (Herrero et al 2001), and topicdetection (Lee et al 2006).
The algorithm startswith a set of text (i.e., abstract sentences or im-age captions).
Each sentence or image captionrepresents a document that needs to be clustered.The algorithm identifies pair-wise documentsimilarity based on the TF*IDF weighted cosinesimilarity.
It then merges the two documentswith the highest similarity into one cluster.
Itthen re-evaluates pairs of documents/clusters;two clusters can be merged if the average simi-larity across all pairs of documents within thetwo clusters exceeds a predefined threshold.
Inpresence of multiple clusters that can be mergedat any time, the pair of clusters with the highestsimilarity is always preferred.In our application, if abstract sentences belongto the same cluster that includes images cap-tions, the abstract sentences summarize the im-age content of the corresponded images.
Theclustering model is advantageous over othermodels in that the flexibility of clustering meth-ods allows ?many-to-many?
mappings.
That is asentence in the abstract can be mapped to zero,one or more than one images and an image canbe mapped to zero, one or more than one ab-stract sentences.We explored different learning features, weightsand clustering algorithms to link abstract sen-tences to images.
We applied the TF*IDFweighted cosine similarity for document cluster-ing.
We treat each sentence or image caption asa ?document?
and the features are bag-of-words.We tested three different methods to obtain theIDF value for each word feature: 1)IDF(abstract+caption): the IDF values werecalculated from the pool of abstract sentencesand image captions; 2) IDF(full-text): the IDFvalues were calculated from all sentences in thefull-text article; and 3)IDF(abstract)::IDF(caption): two sets of IDFvalues were obtained.
For word features thatappear in abstracts, the IDF values were calcu-lated from the abstract sentences.
For words thatappear in image captions, the IDF values werecalculated from the image captions.The positions of abstract sentences or images areimportant.
The chance that two abstract sen-tences link to an image decreases when the dis-tance between two abstract sentences increases.For example, two consecutive abstract sentenceshave a higher probability to link to one imagethan two abstract sentences that are far apart.Two consecutive images have a higher chance tolink to the same abstract sentence than two im-ages that are separated by many other images.Additionally, sentence positions in an abstractseem to correspond to image positions.
For ex-ample, the first sentences in an abstract havehigher probabilities than the last sentences tolink to the first image.To integrate such ?neighboring effect?
into ourexisting hierarchical clustering algorithms, wemodified the TF*IDF weighted cosine similar-ity.
The TF*IDF weighted cosine similarity for apair of documents i and j is Sim(i,j), and the finalsimilarity metric W(i,j) is:( ) ))//(1(*),(, jjii TPTPabsjiSimjiW ??=1.
If i and j are both abstract sentences,Ti=Tj=total number of abstract sentences; andPi and Pj represents the positions of sentences iand j in the abstract.2.
If i and j are both image captions,Ti=Tj=total number of images that appear in afull-text article; and Pi and Pj represents thepositions of images i and j in the full-text arti-cle.3.
If i and j are an abstract sentence and animage caption, respectively, Ti=total numberof abstract sentences and Tj=total number ofimages that appear in a full-text article; and Piand Pj represent the positions of abstract sen-tence i and image j.Finally, we explored three clustering strategies;namely, per-image, per-abstract sentence, andmix.The Per-image strategy clusters each imagecaption with all abstract sentences.
The image is191assigned to (an) abstract sentence(s) if it belongsto the same cluster.
This method values featuresin abstract sentences more than image captionsbecause the decision that an image belongs to (a)sentence(s) depends upon the features from allabstract sentences and the examined image cap-tion.
The features from other image captions donot play a role in the clustering methodology.The Per-abstract-sentence strategy takes eachabstract sentence and clusters it with all imagecaptions that appear in a full-text article.
Imagesare assigned to the sentence if they belong to thesame cluster.
This method values features in im-age captions higher than the features in abstractsentences because the decision that an abstractsentence belongs to image(s) depends upon thefeatures from the image captions and the exam-ined abstract sentence.
Similar to per-imageclustering, the features from other abstract sen-tences do not play a role in the clustering meth-odology.The Mix strategy clusters all image captionswith all abstract sentences.
This method treatsfeatures in abstract sentences and image captionsequally.5.
Results and ConclusionsFigures 2 - 4 show the results from three differ-ent combinations of features and algorithms withvaried TF*IDF thresholds.
The default parame-ters for all these experiments were ?per image?,?bag-of-words?, and ?without neighboringweight?.Figure 2 shows that the ?global?
IDFs, or theIDFs obtained from the full-text article, have amuch lower performance than ?local?
IDFs, orIDFs calculated from the abstract sentences andimage captions.
Figure 3 shows that Per-imageout-performs the other two strategies.
The re-sults suggest that features in abstract sentencesare more useful than features that reside withincaptions for the task of clustering.
Figure 4shows that the ?neighboring weighted?
approachoffers significant enhancement over the TF*IDFweighted approach.
When the recall is 33%, theprecision of ?neighboring weighted?
approachincreases to 72% from the original 38%, whichcorresponds to a 34% increase.
The resultsstrongly indicate the importance of the?neighboring effect?
or positions of additionalfeatures.
When the precision is 100%, the recallis 4.6%.
We believe BioEx system is applicablefor real use because a high level of precision isthe key to BioEx success.Acknowledgement: The authors thank Dr. WeiqingWang for her contribution to this work.
The authorsalso thank Michael Bales, Li Zhou and Eric Silfen,and three anonymous reviewers for valuable com-ments.
The authors acknowledge the support of Juve-nile Diabetes Foundation International (JDRF 6-2005-835).References:Corpet F (1988) Multiple sequence alignment with hierar-chical clustering.
Nucleic Acids Res 16:10881-10890Hearst M (2003) The BioText project.
A powerpoint pres-entation.Herrero J, Valencia A, Dopazo J (2001) A hierarchicalunsupervised growing neural network for clustering geneexpression patterns.
Bioinformatics 17:126-136Lee M, Wang W, Yu H (2006) Exploring supervised andunsupervised methods to detect topics in Biomedical text.BMC Bioinformatics 7:140Smalheiser NR, Swanson DR (1998) UsingARROWSMITH: a computer-assisted approach to formu-lating and assessing scientific hypotheses.
Comput Meth-ods Programs Biomed 57:149-153192
