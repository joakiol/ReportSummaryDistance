Explana~..: 3tructures in XSELKaren KukichComputer Science DepartmentCarnegie-Mellon UniversityPittsburgh, PA 15213412-578.2621Kukich@CMU-CS-A1.
IntroductionExpert systems provide a rich testbed from which to developand test techniques for natural language processing.
Thesesystems capture the knowledge needed to solve real-worldproblems in their respective domains, and that knowledge canand should be exploited for testing computational procedures fornatural language processing.
Parsing.
semantic ,nterpretation,dialog monitoring, discourse organization, and text gef,erationare just a few of the language processinq problems that mighttakeadvantage of the pre.structured semantic knowledge of anexpert system.
In particular, the need for explanation generationfacilities for expert systems provides an opportunity to explorethe relationships between the underlying knowleqge structuresneeded for automated reasoning and those needed for naturallanguage processing.
One such exploration was thedevelopment of an explanation generator for XSEL, which is anexpert system that hellos a salesperson in producing a purchaseorder for a computer system\[10\].
This pager describes atechnique called "link-dependent message generation" thatforms the basis for explanation generation in XSEL.1.1.
Overview of XSELBriefly, the function of the XSEL system is to assist asalesperson in configuring a custom-tailored purchase order fora Digital Equipment Corporation VAX computer system.
XSELworks with the salesperson tO elicit the functional computingrequirements of the individual customer, and then goes on toselect the components that best fit those requirements.
Theoutput of an XSEL session is a purchase order consisting of a listof line-items that specify hardware and software components.There ~re two main phases to XSEL's processincj, a factgathering phase and a component select=on phase.
During thefact gathering phase XSEL carries on an interactive dialog withthe salesperson to elicit values for facts that determine thecustomer's functional computing requirements.
These mightinclude requirements for total disk space, percent of removabledisk storage, number of terminals, lines-per.minute of printing,etc.
Natural language processing during the fact gatheringdialog is minimal: XSEL displays menues and pre-formutatedqueries and accepts one- or two-word answers from the user.Once enough facts have been collected XSEL begins a silentphase of processing.
During this phase a set of candidatecomponents that satisfy the customer's basic requirements isretrieved from the DEC parts database.
Within each class ofcomponent, i.e., processor, disk, terminal, etc., candidates areranked according to their score on a~q evaluation function thatmeasures the degree to which a candidate satisfies thecustomer's weighted functional requirements.
The candidatewith the highest score is selected and placed on the purchaseorder.The most important knowledge structure used by XSEL duringthe fact gathering I~ase is a fact.
A fact is simply a list ofattribute-value pairs that represent knowledge about one of thecustomer's functional computing requirements.
Figure 1-1depicts a sample facL(FACT ?ATTRIBUTE TOTAL.DISK-SPACE?STATUS INFERENCE TCLASS DISK?UNITS MEGAB~'TE3 ?MEAN 3600YTOKEN G'.29)Figure 1.1: Sample XSEL Fact228The fact collection process is driven by backward-chainingrules.
A top-level rule deposits a few "core" facts for which XSELmust obtain values, such as "total.disk-space", "total-number.of-terminals", etc.
One at a time, XSEL solicits a value for thesecore facts from the salesperson.
If the salesperson answers"unknown" to a solicitation, another rule fires to deposit someadditional facts that would enable XSEL to infer a value for theunknown fact.
The cycle is then repeated as XSEL solicits valuesfor each of the newly deposited facts.
Any time a newlyinstantiated fact completes the set of facts required to infer avalue for some other fact.
the appropriate inference rule isautomatically triggered and the value for another fact is inferred.This backward-chaining process continues until XSEL obtainsvalues for all of the core facts, or until no more data can becollected and no more inferences can be made, in which casesome default value rules fire to instantiate values for anyremaining unknown facts.The most important knowledge structure used by XSEL duringthe component selection phase is a rank element.
Like a fact, arank element is simply a list of atthbute.value palm.
In this casethe attribute-value pairs represent knowledge about a candidate'sscore for one term in the evaluation function.
A differentevaluation function is associated with each class of component.and each evaluation function is a sum of some weighted terms.The terms of the evaluation function for the class disk, forexample, include price, disk-pack-type, storage-capacity,average-access-time, peak-transfer-rate, and handednesa.
Forevery candidate, XSEL computes a rank value for each term inthe evaluation function.
The rank value for a term is the productof the candidate's normalized SCore for the term and a weightwhich represents an importance factor.
The essential informationneeded to compute a rank value for a term for a candidate isstored in a rank element, an example of which is shown in Figure1-2.
(RANK tRANK-NAME AVERAGE.ACCESS-TIMEtNAME RA60-AA" tCLASS DISKfRANK-VALUE -3 tCOEFFICIENT ttVALUE 50 tlMPORTANCE ItTOKEN G:9)Figure 1-2: Sample XSEL RankAfter aJl the rank values have been computed for a candidate theyare summed to obtain a total score for the candidate.
Thecandidate with the highest total score is selected and placed onthe purchase order.The component selection phase is driven by forward.chainingrules.
These rules perform the subtasks of first, retrievingcandidates from the database, next, determining a quantity andcost for each of the candidates, next, computing a total rankscore for each candidate, and finally, selecting the candidate withthe highest rank score.At present, the entire XSEL system consists of over threethousand OPS5 \[2\] rules.
The explanation generator, which willbe described shortly, comprises an additional five hundred rules.Anywhere from approximately five hundred to five thousand rulesmay fire during the fact gathering phase to create from fifty to fivehundred facts, and roughly three thousand rules will fire duringthe component selection phase to create around one thousandrank elements.
The whole process can take anywhere from ten tothirty minutes of real time, depending on how XSEL's queries areanswered.t .2.
Sample Explanat ionsThree of the most obvious types of queries a user m~ght askwere targeted for initial explanation development.
Sampleexplanations from each of those types are given in this section.The following sections describe the knowledge structures andprocesses within both XSEL and the explanation generator thatproduced those explanations, as well as the goals and rationalebehind them.One type of query that is likely to be asked is why a particularcomponent appears on a purchase order.
We refer to queries ofthis type as "why-choice" queries.
To answer a why-choicequery the explanation generator must compare the rank elementsfor each candidate on each term of the evaluation function inorder to determine which attributes were responsible for thehigher SCore of the component that was actually selected.
Thefollowing are sample explanations from the why-choice class ofqueries.229?
why ra81THE RA81 IS CHEAPER THAN ANYALTERNATIVE RXED PACK DISK,POSSIBLY BECAUSE IT HAS A SMALLERTOTAL STORAGE CAPACITY AND ASLOWER AVERAGE-ACCESS-TIME.
?why rm05ALTHOUGH THERE ARE LESS EXPENSIVEDISK S, THE RM05 HAS A LARGERDISK PACK THAN ANY ALTERNATIVEREMOVABLE PACK DISK.Figure 1-3: Sample Why-Choice ExplanationsA second obvious type of query asks why a certain fact haswhatever value it has.
e.g., why total-disk.space is 3600megabytes.
We refer to queries in this class as "why-lact"queries.
In the case of why-fact queries, the explanationgenerator must examine the facts that were created during thefact gathering phase, and it must determine how those facts arerelated through the backward-chaining process.
An example ofan explanation that was generated in response to a why.factquery follows:?
why q total-disk-spaceXSEL INFERRED A VALUE QF 3600 MEGABYTESFOR TOTAL-DISK.SPACE.
3574 MEGABYTESARE REQUIRED FOR TOTAL.USER-DISK-SPACE.THE REMAINDER IS ACCOUNTED FOR BY OTHERFACTORS, SUCH AS SUM-OF-SYSTEM-DISK-SPACE.3574 MEGABYTES WAS INFERRED FORTOTAL-USER-DISK-SPACE BECAUSE 2859MEGABYTES ARE REQUIRED FOR USER-DISK-SPACE AND THAT VALUE IS MULTIPLIEDBY 125 FOR PERCENT-FOR-EXPANSION .XSEL INFERRED A VALUE OF 25 MEGABYTESFOR SUM.OF.SYSTEM.DISK-SPACE FROM 1SYSTEM-DISK-SPACE REQUIREMENT OF 25MEGABYTES FOR THE VMS OPERATING-SYSTEM.Figure 1,4: Sample Why-Fact ExplanationThis explanation would have ended immediately following thefirst paragraph had not the user previously asked for longerexplanations.
But because the user had earlier typed "explainmore", the explanation generator went on to explain the terms"total-user-disk-space" and "sum.of.system.disk-space", whichwere introduced in the first paragraph.
If the user were to type"explain more" a second time.
and then ask the same question"why quantity total-disk-space", the explanation generator wouldnot stop where it did.
Instead, it would go on to explain the termsuser-disk.space, percent.for-expansion, and system.disk-space,which were introduced in the second and third paragraphs,There is no upper bound on the number of levels of explanationthe user may request.
If the number of levels to explain is high.XSEL will keep explaining until it reaches those facts whosevalues were set either by user input or by default, in which casethere is nothing further to explain.
The user can ~lso type"explain less" at any time, thus decreasing the number of levelsto explain.
The lower bound on the number of levels to explain isone.The mechanism for determining which term to explain next is aqueue.
As new terms are introduced they are placed in thequeue.
The queue was originally implemented as a stack, but asexplanations got longer they began to sound less coherent usingthe stack mechanism.
So the queue was implemented, but thestack was retained.
Now one can toggle between them by typing"explain queue" or "explain stack", thus producing alternativelystructured explanations for the sake of comparison.The third ol~vious class of queries asks why a certain quantity isneeded for any line-item.
We refer to these as "why-line.item"queries, Why-line-item queries require the most complicatedprocessing because the explanation generator must understandhow the line-item that was selected relates back to the facts thatdetermine the quantity needed, and there is usually a longsequence of forward-chaining rules as well as the wholeevaluation function mechananism between the creation of thefacts and the creation of the line-items.
Figure 1-5 shows asample explanation from the why-line-item class.
In this example.the number of levels to explain was set at two.
The first twoparagrapl'~ comprise the first level, so tire explanation could have23Ostopped there; the remaining two paragraphs were generated inresponse to terms introduced in the first two paragraphs.?
why q ra604 RA60-AA" 'S WERE SELECTED IN ORDER TOSATISFY A REMOVABLE-DISK-SPACEREQUIREMENT OF 900 MEGABYTES.EACH RA60-AA" PROVIDES A CAPACITY OF 205MEGABYTES.
THEREFORE, 4 RA60-AA" 'S AREREQUIRED TO YIELD AT LEAST 90 PERCENT OFTHE REMOVABLE-DISK-SPACE CAPACITY OF 900MEGABYTES.900 MEGABYTES OF THE TOTAL-DISK.SPACEREQUIREMENT OF 3600 MEGABYTES WEREALLOCATED TO REMOVABLE.DISK-SPACE .XSEL INFERRED A VALUE OF 900 MEGABYTESFOR REMOVABLE-DISK-SPACE BECAUSE 3600MEGABYTES ARE REQUIRED FOR TOTAL-DISK.SPACE AND 2700 RXED-DISK ARESUBTRACTED FROM IT TO GET THE DIFFERENCE .THE VALUE OF 205 MEGABYTES FOR REMOVABLE-DISI(-UNIT.CAPABILITY WAS RETRIEVED FROMTHE DATABASE.Figure 1-5: Sample Why-Line.Item Explanation2.
XSEL Explanation Design Goals2.1.
Related Explanation WorkThe desi(jn of the XSEL explanation generator was motivatedby three goals: first, that explanations should be accurate.second, that explanations hould be direct, and third, that somedegree of generality should be attempted.Most early attempts at explanation generation adopted either acanned text or an execution trace approach.
The canned textapproach led to accuracy problems and the execution traceapproach led to directness problems.
These problems aredescribed in detail by Swartout\[12\].
In brief, cannedexplanations can suffer from a lack of accuracy in the event thatany modifications or additions are made to the Performanceprogram without the corresl0onding modifications or additionsbeing made to the canned text.
Execution trace.explanationstend to suffer from a lack of directness because every step duringprogram execution gets reported, including what Swartout hasreferred to as "computer artifacts", as in "Variable X wasinitialized to 0".Another common early approach to explanation generationwas the goal tree approach, which is very.similar to the executiontrace approach.
The original explanations produced by theMYCIN system were goal tree explanations \[1\].
This approachallowed the user to question any request for information made bythe system, and the system would simply locate the goalimmediately above the current one in the goal tree and report thatit needed the information to resolve that higher goal.
Goal treeexplanations tend to suffer from the same lack of directnessproblems that execution trace explanations uffer from.Swartout's work on an explanation generator for the DigitalisTherapy Advisor attacked the accuracy and directness problemssuccessfully.
His approach was to redesign the DTA, separatingdescriptive facts from domain principles and from the abstractgoals of the system.
This allowed the performance program to begenerated by an automatic programmer, which also created agoal refinement structure in the process.
The goal refinementstructure captures the knowledge that goes into writing theperformance program, and makes it accessible to the explanationgenerator, where it can be used to produce explanations that areboth accurate and direct.
Furthermore, as Swartout points out,such explanations can be viewed as "justifications" for thesystem's behavior.One of the major contributions of the DTA work was todemonstrate that a singte explicit representation of knowledgecan and should drive both the automatic program generationprocess and the explanation generation process.
Furtherresearch supporting the "shared explicit knowledge" approachto automatic knowledge acquisition, rule generation, andexplanation generation is underway for at least three otherprojects \[8\] [4\] [5\] [6\].2.2.
The XSEL Explanation ApproachXSEL's approach to explanation generation differs from all of231the approaches discussed above.
The sheer size of XSEL wouldmake implementing canned responses tedious.
Similarly, thenumber of rule firings on any run would make reading executiontrace explanations labonous even.
or perhaps especially, if theywere translated into natural lanaguage.
The approach taken bySwartout of extracting the regularities and representing themseparately as domain principles would work for the backward-chaining rules used during XSEL's fact gathering phase, but theforward-chaining rules used during the component selectionphase are so irregular that attempting to extract regularitieswould result in the duplication of nearly the entire set of rules.Some other common denominator needed to be found in order toachieve some computational power for explanation generation.For about two thirds of XSEL's explanation facilities, thatcomputational power was bought by the creation of links, whichare simple knowledge structures that establish relations betweenelements in XSEL's working memory.
The role of links will be thefocus of the remainder of this paper.
But first a brief generaloverview of all the explanation facilities is given.There is a simple variant of a goal tree explanation facility builtinto XSEL.
so that the system can always state why it wants avalue for any fact it reduests during the fact gathering dialog.
Butthe explanation samples shown in the previous section weregenerated by an entirely different mechanism, a message-basedexplanation generator.
A message-based explanation generatoris a two-phase processor that first generates and organizesmessages based on the contents of working memory, and thenmaps those messages into surface strings.
Two different ypes ofmessage generator have been implemented for XSEL.
Themessage generator used to answer why-choice queries may becalled a comparative message generator; it examines andcompares the rank elements produced by the evaluationfunctions to determine what roles they play in the selection of thechosen component, and then it creates a,opropriate messages,The message generators used to answer the why-fsct and why.line.item clueries may be called link-dependent messagegenerators: they examine the facts and the links between facts todetermine what relations hold among them, and then they createappropriate messages.Explanations produced by both the comparative messagegenerator and the link-dependent message generators arecertain to be accurate because they always originate from thecontenfs of working memory.
Special steps had to be taken toensure the directness of the link-dependent message generators.however.
Those steps will be discussed in the following sections.which describe the workings of the lipk-dependent messagegenerators in some detail.
Discussion of the comparativemessage generator and the surface generator will be reserved forother occasions.3.
Link-dependent Message Generation3.1.
Generic vs. Relational ExplanationsBoth of the link-dependent message generators are capable ofoperating in two modes, generic mode and relational mode.
(Theuser can toggle between modes by typing "explain generic" or"explain relational".)
The explanations hown above in Figures1-4 and 1-5 are relational explanations: they explicate therelations that hold between facts.
Some of those relations arearithmetic relations, such as sum and product, and some areabstract relations, such as satisfaction and allocation relations.Contrast the relational explanation for the query "why q total-disk-space" shown in Figure 3-1 with the generic explanation forthe same query shown in Figure 1-4.
Generic explanations do notexplicate the relations that hold between facts; they simply statethat some generic dependencies exist.
The same messagegenerator is used to generate both generic and relationalexplanations.
(Notice that the same queuing mechanism is usedto explain subsequent terms in both generic and relationalexplanations.)
The difference between generic and relationalexplanations results from the fact that there are two differenttyoes of links in XSEL's memory, qeneric links and relationallinks.
Both types of links establish -~ connectton between two ormore facts.
The difference is that generic links are ~lwaysunnamed, binary links, whereas relational links are alwaysnamed, n.ary links, where the name may be an arithmetic relationsuch as sum or product, or an abstract relation, such assatisfaction or allocation.
Both types of links au'e deposited into232?
why q total-disk-spaceTHE VALUE OF 3600 MEGABYTES FOR TOTAL-DISKIS DEPENDENTON 1424 KILOBYTES FOR TOTAL-APPLICATION-DIS110592 KILOBYTES FOR PROGRAMMER-DISK.SPAC2816000 KILOBYTES FOR TOTAL-DATA-FILE.DISK-S600 KILOBYTES FOR PAGE-AND-SWAP-SPACEAND 25600 KILOBYTES FOR SYSTEM-DISK-SPACE.THE VALUE OF 25600 KILOBYTES FOR SYSTEM.DISIS DEPENDENTON VMS FOR OPERATING-SYSTEM .THE VALUE OF 600 KILOBYTES FOR PAGE-AND-SWIS DEPENDENTON 200 KILOBYTES FOR CODE-SIZE.THE VALUE OF 2816000 KILOBYTES FOR TOTAL-DAIS DEPENDENTON 2816000 KILOBYTES FOR DATA-FILE.DISK.SPACTHE VALUE OF 110592 KILOBYTES FOR PROGRAMIS DEPENDENTON 2048 KILOBYTES FOR EDITOR-DISK-SIZE,2816000 KILOBYTES FOR LARGEST-DATA.FILE,4 PROGRAMMERS FOR NUMBER-OF.PROGRAMMEAND 102400 KILOBYTES FOR LANGUAGE.USE.DISKTHE VALUE OF 1424 KILOBYTES FOR TOTAL.APPLIIS DEPENDENTON 1024 KILOBYTES FOR SOFTWARE-DEDICATED.AND 150 KILOBYTES FOR APPLICATION.DISK-SPACRgu re 3-1: Sample Generic ExplanationXSEL's working memory by the re;lsoning rules that fire duringprogram execution.
As links are de;)osited during XSEL'sexecution, two dynamically growing networks are built up; thegeneric network is a sim0le dependency network, and therelational network is an augmented semantic network.
Thesenetworks are the mare source of knowledge for the link-dependent message generators.A generic link is a very sJmple memory element consisting ofonly two attributes, a source attribute and a sink attribute.
Thevalue of the source attribute is the token (i.e., unique identifier) ofsome fact that entered into the inference of the resultant fact; thevalue of the sink attribute is the token of the resultant fact.
Forexample, the rules that fire to infer a value for the fact total-disk-233space will deposit into working memory at lea.st five generic links,each having the token of the fact total-disk-space in its sinkattribute and each having the token of a fact that entered into thecalculation of the value for total-disk-space, such aS total-application-disk-space, programmer-disk-space, etc., in itssource attribute.
An example of a generic link is shown in Figure3-2.
A relational ink is a sJightly richer memory element whichnot only names the relation that holds between two or more facts,but also categorizes it.
Figure 3-3 displays one arithmeticrelational link and one abstract relation link.
(generic.linktsource <total-application-disk-space-token>tsink <total-disk.space-token>)Figure 3-2: Sample Generic Link(relational- inktrelation sumtcategory arithmetictsmk <total-disk-space-token>tsourcet <total-user-disk-space-token>tsource2 <sum-of- System-disk-space- token>tSOurce3 <sum-of-page-and-swap-space-token>)(relational-link~retation satisfaction?category reasontsink <quantity-of-disks-token>tsource <total-disk-space- token>)F igure  3 -3 :  Sample Arithmetic and Abstract Relational LinksThe network formed by relational inks is in some ;)laces moredense and in other ;)laces less dense than the network formed bygenenc links; arithmetic relational inks create more levels thusmaking the relaUonal network denser, while abstract links tend tobridge long chains of facts, thus making the network sparser.
Tosee this distinction, consider the arithmetic formula used by XSELto calculate the total-disk-space requirement:total-disk.space =( (total.
application -disk.
space+ programmer-disk-space?
total-data- file-disk- space)* 125%)+ sum of system.disk.space+ sum of page-and.swap-spaceThe rules that execute this formula create at least five genericlinks linking total-disk.space to total-application-disk-space,programmer-disk-space, total-data-file-disk-space, one or moresystem-disk-sp,3ce facts, and one or more page-and-swap-spacefacts.
At the same time they create one relational link linkingtotal-disk-space to three new intermediate level facts, total-user-disk-space, sum.of-system-disk-space, and sum-of-page-and-swap.space, and they create additional relational links linkingeach of the intermediate facts to their subfacts.
Total.user-disk-space is a newly created intermediate fact, and a relational link,with rrelation percent, is created linking it to two more newintermediate facts, user-disk-space and percent.for-expansion.Another relational ink is in turn created linking user-disk-space tothe three facts total-application-disk-space, programmer-disk-space, and total-data-file-disk-space.On the other hand, the rules that determine how many RA60disk drives are needed, for example, create a dense genericnetwork linking all the facts that enter into the calculation of total-disk-space to the facts that allocate some portion of that amountto fixed-disk-space.
From there the network would get evendenser as fixed-disk-space is linked tO the fixed.disk.unit.capabihty and quantity-of-fixed-disks facts for each candidate.
Infact, these generic links are not currently created due tolimitations of working memory space.
In contrast to thepotentially dense generic network, the relational networkcontains only a few abstract relation links, such as satisfactionand allocation links, that bridge many of the generic links, thusresulting in a sparser network (and in more direct explanations).There are good reasons for the existence of two completenetworks.
Essentially, the tradeoff is that while generic links aretrivial tO create, they do not facilitate satisfying explanations.
Onthe other hand, the creation of relatil)nal links often requiresmanual intervention, lout relational links facilitate directexplanations.
Compare again the generic explanation in Figure3- I to its corresponding relational explanation in Figure 1.4.Generic links require little effort to create because they simplyincorporate the tokens of the facts that are used in an inference234rule.
In fact, an automatic rule generator was developed forautomatically creating most of XSEL's backward.chaining fact-gathering rules from simple arithmetic formulas such as theformula for total-disk-spsce discussed above.l it  was a trivial taskto have the automatic rule generator include the actions requiredto have the inference rules create the generic links.The task of augmenting the fact-gathering rules to createarithmetic relational inks was also automatable, for the most part.An automatic link-creator was written to parse the arithmeticformulas that were input to the rule generator and create theappropriate links.
This parser identified the main arithmeticoperations, created names for intermediate facts, and modifiedXSEL's rules to have them create the arithmetic relational links.The output of the automatic link-creator required only minormanual retouching in those cases where its heuristics forcreating names for intermediate facts fell short.
2 But the task ofaugmenting the component selection rules to create the abstractrelational links between facts has so far resisted an automaticsolution.
These links are now being added manually.
Theyrequire the effort of someone who understands the workings ofXSEL and recognizes what explanations might be called for and.consequently, which rules should be modified to create relationallinks.3.2.
Overv iew of Process ingThe processing of a query by a link-dependent messagegenerator goes as follows.
When the initial query is input, aquery-interpretation context is entered.
In this context somerules fire tO identify and locate the fact in question, to create aquery-term with the same token as the fact.
and to place thatquery-term in the query-queue.
Following query-interpretation, amessage generation cycle consisting roughly of the following fivesteps reiterates: 1) focus on the next query-term in the queue, 2)locate the links related to that query-term, 3) select anexplanation schema 3 based on the links found, 4) create1XSEL's automatic ride gammer was v~ten by Samly Marcus.2XSEL's auSommic link-creatm ~S vmtmen by kTr.ttaet ~w~additional query-terms and messages suggested by the selectedschema, and 5) turn control over to the surface generator.
Eachtime a new query-term is created, queue-control rules decidewhether to place it in the query-queue, depending on suchfactors as whether the term has already been explained and howmany levels of explanation the user has requested.
As long asthe query-queue is not empty, the message generation cycle isreiterated.When the message generator is in generic mode, it bconstrained to locating generic links during step 2 of the cycle,and it is constrained to selecting the generic schema during step3 of the cycle.
A simplified version of the generic schema isdepicted in Figure 3.4.
The first directive of the generic schema(Schema-directives::Generic-schema(make goal tgoal-name create.extra.query.termststatus reiterate)(make goal Tgoal-name create-messagetgredicate IS-DEPENDENT~erml <current-focus>)(make goal rgoal-narne create-message?predicate ON~terml <link.focus>tstatus reiterate))Figure 3-4: The Generic Schemadirects the message generator to create additional query.termsfor all the facts that are linked to the current query-term.
Thesecond directive directs the message generator to create onemessage with the predicate "IS-DEPENDENT" and with thefocus-token of term1, which is the current query.term.
Thesurface realization of this message will be the clause "THEVALUE OF 3600 MEGABYTES FOR TOTAL-DISK-SPACE ISDEPENDENT ".
The third directive of the generic schema directsthe message generator to create one additional message with thepredicate "ON" and the focus.token of terror for each of the linkterms found.
These messages will emerge as prepositionalphrases in their surface form, such as " ON 1424 KILOBYTESFOR TOTAL-APPLICATION.DISK.SPACE, 110592 KILOBYTES3'The term so/letup wls adOl~ed fRmt ~e ~ of McKeown(11), ~simdet smBclu=~s f~ discou~e o?~=anizatlo~.FOR PROGRAMMER.DISK.SPACE , 2816000 KILOBYTES FORTOTAL-DATA.FILE.DISK.SPACE , 600 KILOBYTES FOR PAGE.AND-SWAP-SPACE AND 25600 KILOBYTES FOR SYSTEM-DISK-SPACE .
"When the message generator is in relational mode, it isconstrained to locating relational links and using relationalschemas.
There are a variety of each.
Currently, relational inksare categorized as being either reasons, elaborations, orarithmetic links.
During step 2 of the message-generation cycle,the message generator searches first for reason links, next forelaboration links, and finally for arithmetic links.
In some cases,the search for arithmetic links may be suppressed.
For example,some links whose relation is allocation are subcategorized asbeing arithmetic operations, as in "75 percent of the total.disk.space requirement was allocated to removable-pack disks".
Inthese cases, expressing the arithmetic relation also would beredundant.When a relational ink is located, a corresponding schema isselected.
In contrast to the single generic schema, there are avariety of arithmetic and abstract relational ~chemas.
Figure 3-5illustrates the arithmetic "plus" schema that was used togenerate the messages for the first paragraph of the "whyquantity totaJ-disk-space" relational explanation shown in Figure1-4.
It contains five directives, one to create the new query-termsfound in the arithmetic reasoning trace and four to createmessages.
The second message creation directive will create asmany messages as are needed to account for at least 80 percentof the total value of the fact being explained.
(The 80 percentfactor was implemented in order to filter out insignificant facts,thus making the explanation more concise.
Another process thatcontributes to more readable explanations is the conversion of allunits in different clauses of the explanation to the same highestcommon denominator, eg.
megabytes.)
Following that, twoadditional messages will be created, one to mention that theremainder of the total is accounted for by other terms, andanother to give an example.Figure 3-6 illustrates the "setisfactJon" schema that was u~=d235(Schema-directives:plus-schema(make goal tgoal-name create-extra-query.terms~status reiterate)(make goal tgoal-name create- messagetfocus-token <token I >tpredicate CAPACITY.REQUIREMENTtsubname RECOMMENDED)(make goal tgoal.name create-messegetfocus-token ew?predicate CAPACITY-REQUIREMENT~ubname GENERALtamount 80)(make goal tgoal-name create-messagetpredicate REMAINDER)(make goal tgoal.name Create-message tfocus.token ewtpredicate EXAMPLE))F igure 3-5: Sample Arithmetic Schemato create the massages for the first sentence of the "why quantityRA60" explanation shown in Figure 1-5.
It contains one directiveto create an extra query-term matching the token of the new termidentified in the "satisfaction" link, and three actions making thethree messages which surface as three clauses of text in theexplanation.4.
RationaleThe knowledge structures just described, including mas=mge~query.terms, the query-queue, schemas and links, serve asintermediate structures between the reasoning knowledge of theexpert system and the linguistic knowledge needed for languagegeneration .4 Some of the terminology used to describe thesestructures, e.g., "reason" and "elaboration" relations, is derivedfrom the work of Mann \[7\] and Hobbs\[3\] on discourseorganization.
Mann and Hobbs independently postulate thatdiscourse relations, such as reason and elaboration relationsamong others, are rasDonsible for coherence in well-organized(Schema.directives:satisfy-schema(make goal tgoal-name create-extra.query-termHocus-token <term2>)(make goal tgoal.narne create-message?predicate QUANTITY.SELECTEDtterml <term1>)"(make goal ?goal.name create-messagetpredicate INORDER1"retype relational-prop)(make goal tgoal-narne create-message?predicate CAPACITY.REQUIREMENTtsubncme SATISFYtterm2 <term?.>)Figure 3-6: Sample Satisfaction Schemanatural language text.
One of the premises of this work onexplanation generation is that the relations, or links, that areembodied in the inference rules of a successful reasoning systemare the same ones that give coherence to natural languageexplanations.
An immediate goal of this research is to identitythose relations.
At the present time only twenty.six differentreasoning relations, have been identified in XSEL.
As more typesof reasoning relations are identified and corresponding links areadded to XSEL's rules, more of XSEL's reasoning will beexplainable.
A long term goal of this work is to continue toidentify and add reasoning links and schemas until we see somegeneralities begin to emerge.
Perhaps some domain-independent set of reasoning relations and schemas might befound.
Furthermore.
such relations and schemas might facilitatethe design of a knowledge acquisition system that would elicitknowledge from an expert, represent it as relations, and generateinference rules from relations.
We realize that this could be avery long term goal, but it aJse has the short term benefit ofproviding useful explanations.4~ ~ld~ \[91 for another ~ ot intermediate236AcknowledgementsMany people at CMU and DEC have contributed to thedevelopment of XSEL.
Some of these include John McDermott,Tianran Wang, and Kim Smith who developed XSEL's sizing andselection knowledge; Robert Schnelbach and Michael Brownewho worked on explanation facilities; Sandy Marcus, who wroteXSEL's rule generator;, George Wood, Jim Park, and MikeHarmon who provided technical support; and Dan Offutt who isextending XSEL's sizing knowledge with a view towardsdeveloping knowledge acquisition facilities.10.
John McDermott.
Building Expert Systems.
Proceedings ofthe 1983 NYU Symposium on Artificial Intelligence Applicationsfor Business, New York Univer~ty, New York City, April 198,3.11.
Kathleen Rose McKeown.
Generating Natural LanguageText in Response to Questions about Database Structure.
Ph.D.Th., University of Pennsylvania Computer and InformationScience Department, 1982.12.
William R. Swartout.
"XPLAIN: a System for Creating andExplaining Expert Consulting Programs".
Artificial Intelligence27 (198,3), 285-325.References1.
R. Davis.
Applications of meta level knowledge to theconstruction, maintenance, and use of large knowledge bases.Ph.D.
Th., Stanford University, 1976.
Stanford ArtificialIntelligence L~oratory Memo 283, Stanford, CA.2.
C. L Forgy.
OPS.5 User's Manual.
CMU.CS-81-135, Dept ofComputer Science, Carnegie-Mellon University, Pittsburgh, PA15213, July 1981.3.
Jerry R. Hobbs.
Towards an Understanding of Coherence inDiscourse.
In W. G. Lehnert and M. H. Ringle, Ed., Strategies forNatural Language Processing, Lawrence Erlbaum Associates,New Jersey, 1982, pp.
223-24,3.4.
Gary Kahn, Steve Now/an, and John McDermott.
AFoundation for Knowledge Acquisition.
Proceedings of the IEEEWorkshop on Principles of Knowledge.Based Systems, IEEE,Denver, CO, 1984, pp..5.
Gary Kahn and David Gelier.
MEX: An OPS-based approachto explanation.
1984.6.
Karan Kukich, John McDermott and Tianran Wang.
XSEL asKnowledge Acquirer and Explainer.
1985.7.
William C. Mann and Sandra A. Thompson.
RelationalPropositions in Discourse.
198,3.8.
Sandra L. Marcus, John McDermott and Tianran Wang.
AKnowledge Acquisition System for VT.
Proceedings of the AAAI,AAAI, Los Angeles, CA, 1985, pp..9.
Michael Mauldin.
Semantic Rule Based Text Generation.Proceedings of the lOth International Conference onCompu=ational Linguistic~ ACL, Stanford University, Stanford,CA, 2-6 July 1984, pp.
376-380.237
