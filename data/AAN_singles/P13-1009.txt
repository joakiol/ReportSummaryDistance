Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 83?92,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsLanguage-Independent Discriminative Parsing of Temporal ExpressionsGabor AngeliStanford UniversityStanford, CA 94305angeli@stanford.eduJakob UszkoreitGoogle, Inc.1600 Amphitheatre ParkwayMountain View, CA 94303uszkoreit@google.comAbstractTemporal resolution systems are tradition-ally tuned to a particular language, re-quiring significant human effort to trans-late them to new languages.
We presenta language independent semantic parserfor learning the interpretation of tempo-ral phrases given only a corpus of utter-ances and the times they reference.
Wemake use of a latent parse that encodesa language-flexible representation of time,and extract rich features over both theparse and associated temporal semantics.The parameters of the model are learnedusing a weakly supervised bootstrappingapproach, without the need for manuallytuned parameters or any other languageexpertise.
We achieve state-of-the-art ac-curacy on all languages in the TempEval-2 temporal normalization task, reportinga 4% improvement in both English andSpanish accuracy, and to our knowledgethe first results for four other languages.1 IntroductionTemporal resolution is the task of mapping froma textual phrase describing a potentially complextime, date, or duration to a normalized (grounded)temporal representation.
For example, possiblycomplex phrases such as the week before last1 areoften more useful in their grounded form ?
e.g.,August 4 - August 11.Many approaches to this problem makeuse of rule-based methods, combining regular-expression matching and hand-written interpreta-tion functions.
In contrast, we would like to learnthe interpretation of a temporal expression proba-bilistically.
This allows propagation of uncertaintyto higher-level components, and the potential to1Spoken on, for instance, August 20.dynamically back off to a rule-based system in thecase of low confidence parses.
In addition, wewould like to use a representation of time which isbroadly applicable to multiple languages, withoutthe need for language-specific rules or manuallytuned parameters.Our system requires annotated data consist-ing only of an input phrase and an associ-ated grounded time, relative to some referencetime; the language-flexible parse is entirely latent.Training data of this weakly-supervised form isgenerally easier to collect than the alternative ofmanually creating and tuning potentially complexinterpretation rules.A large number of languages conceptualize timeas lying on a one dimensional line.
Althoughthe surface forms of temporal expressions differ,the basic operations many languages use can bemapped to operations on this time line (see Sec-tion 3).
Furthermore, many common languagesshare temporal units (hours, weekdays, etc.).
Bystructuring a latent parse to reflect these seman-tics, we can define a single model which performswell on multiple languages.A discriminative parsing model allows us to de-fine sparse features over not only lexical cues butalso the temporal value of our prediction.
For ex-ample, it allows us to learn that we are much morelikely to express March 14th than 2pm in March ?despite the fact that both interpretations are com-posed of similar types of components.
Further-more, it allows us to define both sparse n-gram anddenser but less informative bag-of-words featuresover multi-word phrases, and allows us to handlenumbers in a flexible way.We briefly describe our temporal representationand grammar, followed by a description of thelearning algorithm; we conclude with experimen-tal results on the six languages of the TempEval-2A task.832 Related WorkOur approach follows the work of Angeli et al(2012), both in the bootstrapping training method-ology and the temporal grammar.
Our foremostcontributions over this prior work are: (i) the uti-lization of a discriminative parser trained with richfeatures; (ii) simplifications to the temporal gram-mar which nonetheless maintain high accuracy;and (iii) experimental results on 6 different lan-guages, with state-of-the-art performance on bothdatasets on which we know of prior work.As in this previous work, our approach drawsinspiration from work on semantic parsing.
Thelatent parse parallels the formal semantics in pre-vious work.
Supervised approaches to semanticparsing prominently include Zelle and Mooney(1996), Zettlemoyer and Collins (2005), Kate etal.
(2005), Zettlemoyer and Collins (2007), interalia.
For example, Zettlemoyer and Collins (2007)learn a mapping from textual queries to a logicalform.
Importantly, the logical form of these parsescontain all of the predicates and entities used inthe parse ?
unlike the label provided in our case,where a grounded time can correspond to any ofa number of latent parses.
Along this line, re-cent work by Clarke et al (2010) and Liang et al(2011) relax supervision to require only annotatedanswers rather than full logical forms.Related work on interpreting temporal expres-sions has focused on constructing hand-crafted in-terpretation rules (Mani and Wilson, 2000; Sa-quete et al, 2003; Puscasu, 2004; Grover et al,2010).
Of these, HeidelTime (Stro?tgen and Gertz,2010) and SUTime (Chang and Manning, 2012)provide a strong comparison in English.Recent probabilistic approaches to temporalresolution include UzZaman and Allen (2010),who employ a parser to produce deep logicalforms, in conjunction with a CRF classifier.
In asimilar vein, Kolomiyets and Moens (2010) em-ploy a maximum entropy classifier to detect thelocation and temporal type of expressions; thegrounding is then done via deterministic rules.In addition, there has been work on pars-ing Spanish expressions; UC3M (Vicente-D?
?ez etal., 2010) produce the strongest results on theTempEval-2 corpus.
Of the systems entered in theoriginal task, TIPSem (Llorens et al, 2010) wasthe only system to perform bilingual interpreta-tion for English and Spanish.
Both of the abovesystems rely primarily on hand-built rules.3 Temporal RepresentationWe define a compositional representation of time,similar to Angeli et al (2012), but with a greaterfocus on efficiency and simplicity.
The represen-tation makes use of a notion of temporal typesand their associated semantic values; a grammaris constructed over these types, and is groundedby appealing to the associated values.A summary of the temporal type system is pro-vided in Section 3.1; the grammar is described inSection 3.2; key modifications from previous workare highlighted in Section 3.3.3.1 Temporal TypesTemporal expressions are represented either as aRange, Sequence, or Duration.
The root of a parsetree should be one of these types.
In addition,phrases can be tagged as a Function; or, as a spe-cial Nil type corresponding to segments without adirect temporal interpretation.
Lastly, a type is al-located for numbers.
We describe each of thesebriefly below.Range [and Instant] A period between twodates (or times), as per an interval-based theoryof time (Allen, 1981).
This includes entities suchas Today, 1987, or Now.Sequence A sequence of Ranges, occurring atregular but not necessarily constant intervals.
Thisincludes entities such as Friday, November27th, or last Friday.
A Sequence is de-fined in terms of a partial completion of calendarfields.
For example, November 27th would de-fine a Sequence whose year is unspecified, monthis November, and day is the 27th; spanning the en-tire range of the lower order fields (in this case, aday).
This example is illustrated in Figure 1.
Notethat a Sequence implicitly selects a possibly infi-nite number of possible Ranges.To select a particular grounded time for a Se-quence, we appeal to a notion of a reference time(Reichenbach, 1947).
For the TempEval-2 corpus,we approximate this as the publication time of thearticle.
While this is conflating Reichenbach?s ref-erence time with speech time, and comes at theexpense of certain mistakes (see Section 5.3), it isnonetheless useful in practice.To a first approximation, grounding a sequencegiven a reference time corresponds to filling in theunspecified fields of the sequence with the fully-specified fields of the reference time.
This pro-84Sequence: year?monNov day27th ?
28thweek?
weekday?hour00 min00 sec00Reference Time: year2013monAug day06thweek32 weekdayTuehour03 min25 sec00year2013monNov day27th ?
28thweek?
weekday?hour00 min00 sec00Figure 1: An illustration of grounding a Sequence.
When grounding the Sequence November 27thwith a reference time 2013-08-06 03:25:00, we complete the missing fields in the Sequence (theyear) with the corresponding field in the reference time (2013).cess has a number of special cases not enumeratedhere,2 but the complexity remains constant time.Duration A period of time.
This includes enti-ties like Week, Month, and 7 days.
A specialcase of the Duration type is defined to represent ap-proximate durations, such as a few years or somedays.Function A function of arity less than or equalto two representing some general modification toone of the above types.
This captures semanticentities such as those implied in last x, the third x[of y], or x days ago.
The particular functions areenumerated in Table 2.Nil A special Nil type denotes terms which arenot directly contributing to the semantic meaningof the expression.
This is intended for words suchas a or the, which serve as cues without bearingtemporal content themselves.Number Lastly, a special Number type is definedfor tagging numeric expressions.3.2 Temporal GrammarOur approach assumes that natural language de-scriptions of time are compositional in nature; thatis, each word attached to a temporal phrase is com-positionally modifying the meaning of the phrase.We define a grammar jointly over temporal typesand values.
The types serve to constrain the parseand allow for coarse features; the values encodespecific semantics, and allow for finer features.At the root of a parse tree, we recursively apply2Some of these special cases are caused by variable daysof the month, daylight savings time, etc.
Another class arisesfrom pragmatically peculiar utterances; e.g., the next Mondayin August uttered in the last week of August should ground toAugust of next year (rather than the reference time?s year).the functions in the tree to obtain a final temporalvalue.This approach can be presented as a rule-to-ruletranslation (Bach, 1976; Allen, 1995, p. 263), ora constrained Synchronous PCFG (Yamada andKnight, 2001).Formally, we define our grammar asG = (?, S,V, T,R).
The alphabet ?
and startsymbol S retain their usual interpretations.
Wedefine a set V to be the set of types, as described inSection 3.1.
For each v ?
V we define an (infinite)set Tv corresponding to the possible instances oftype v. Each node in the tree defines a pair (v, ?
)such that ?
?
Tv.
A rule R ?
R is defined asa pair R = (vi ?
vjvk, f : (Tvj , Tvk)?
Tvi).This definition is trivially adapted for the case ofunary rules.The form of our rules reveals the synchronousaspect of our grammar.
The structure of the tree isbound by the first part over types v ?
these typesare used to populate the chart, and allow for effi-cient inference.
The second part is used to eval-uate the semantics of the parse, ?
?
Tvi , and al-lows partial derivations to be discriminated basedon richer information than the coarse types.We adopt the preterminals of Angeli et al(2012).
Each preterminal consists of a typeand a value; neither which are lexically in-formed.
That is, the word week and preterminal(Week,Duration) are not tied in any way.
A totalof 62 preterminals are defined corresponding to in-stances of Ranges, Sequences, and Durations; theseare summarized in Table 1.In addition, 10 functions are defined for manip-ulating temporal expressions (see Table 2).
Themajority of these mirror generic operations on in-tervals on a timeline, or manipulations of a se-quence.
Notably, like intervals, times can be85Type Example InstancesRange Past, Future, Yesterday,Tomorrow, Today, Reference,Year(n), Century(n)Sequence Friday, January, .
.
.DayOfMonth, DayOfWeek, .
.
.EveryDay, EveryWeek, .
.
.Duration Second, Minute, Hour,Day, Week, Month, Quarter,Year, Decade, CenturyTable 1: The content-bearing preterminals of thegrammar, arranged by their types.
Note that theSequence type contains more elements than enu-merated here; however, only a few of each charac-teristic type are shown here for brevity.Function DescriptionshiftLeft Shift a Range left by a DurationshiftRight Shift a Range right by a DurationshrinkBegin Take the first Duration of a RangeshrinkEnd Take the last Duration of a RangecatLeft Take the Duration after a RangecatRight Take the Duration before a RangemoveLeft1 Shift a Sequence left by 1moveRight1 Shift a Sequence right by 1nth x of y Take the nth element in yapproximate Make a Duration approximateTable 2: The functional preterminals of the gram-mar.
The name and a brief description of the func-tion are given; the functions are most easily in-terpreted as operations on either an interval or se-quence.
All operations on Ranges can equivalentlybe applied to Sequences.moved (3 weeks ago) or their size changed (thefirst two days of the month), or a new interval canbe started from one of the endpoints (the last 2days).
Additionally, a sequence can be modifiedby shifting its origin (last Friday), or taking thenth element of the sequence within some bound(fourth Sunday in November).Combination rules in the grammar mirror type-checked curried function application.
For in-stance, the function moveLeft1 applied to week(as in last week) yields a grammar rule:( EveryWeek -1 , Seq.
)( moveLeft1 , Seq.?Seq. )
( EveryWeek , Seq.
)In more generality, we create grammar rules forapplying a function on either the left or the right,for all possible type signatures of f : f(x, y)  xor x f(x, y).Additionally, a grammar rule is created for in-tersecting two Ranges or Sequences, for multiply-ing a duration by a number, and for absorbing a Nilspan.
Each of these can be though of as an implicitfunction application (in the last case, the identityfunction).3.3 Differences From Previous WorkWhile the grammar formalism is strongly inspiredby Angeli et al (2012), a number of key differ-ences are implemented to both simplify the frame-work, and make inference more efficient.Sequence Grounding The most time-consuming and conceptually nuanced aspectof temporal inference in Angeli et al (2012)is intersecting Sequences.
In particular, thereare two modes of expressing dates which resistintersection: a day-of-month-based mode and aweek-based mode.
Properly grounding a sequencewhich defines both a day of the month and a dayof the week (or week of the year) requires backingoff to an expensive search problem.To illustrate, consider the example: Friday the13th.
Although both a Friday and a 13th of themonth are easily found, the intersection of the tworequires iterating through elements of one until itoverlaps with an element of the other.
At train-ing time, a number of candidate parses are gen-erated for each phrase.
When considering thatthese parses can become both complex and prag-matically unreasonable, this can result in a notice-able efficiency hit; e.g., during training a sentencecould have a [likely incorrect] candidate interpre-tation of: nineteen ninety-six Friday the 13ths fromnow.In our Sequence representation, such intersec-tions are disallowed, in the same fashion as Febru-ary 30th would be.Sequence Pragmatics For the sake of simplicitythe pragmatic distribution over possible ground-ings of a sequence is replaced with the single mostlikely offset, as learned empirically from the En-glish TempEval-2 corpus by Angeli et al (2012).No Tag Splitting The Number and Nil typesare no longer split according to their ordinal-ity/magnitude and subsumed phrase, respectively.86More precisely, there is a single nonterminal (Nil),rather than a nonterminal symbol characterizingthe phrase it is subsuming (Nil-the, Nil-a, etc.).
Thisinformation is encoded more elegantly as features.4 LearningThe system is trained using a discriminative k-best parser, which is able to incorporate arbi-trary features over partial derivations.
We describethe parser below, followed by the features imple-mented.4.1 ParserInference A discriminative k-best parser wasused to allow for arbitrary features in the parsetree.
In the first stage, spans of the input sentenceare tagged as either text or numbers.
A rule-basednumber recognizer was used for each languageto recognize and ground numeric expressions, in-cluding information on whether the number wasan ordinal (e.g., two versus second).
Note that un-like conventional parsing, a tag can span multiplewords.
Numeric expressions are treated as if thenumeric value replaced the expression.Each rule of the parse derivation was assigneda score according to a log-linear factor.
Specifi-cally, each rule R = (vi ?
vjvk, f) with featuresover the rule and derivation so far ?
(R), subject toparameters ?, is given a probability:P (vi | vj , vk, f ; ?)
?
e?T?
(R) (1)Na?
?vely, this parsing algorithm gives us a com-plexity of O(n3k2), where n is the length of thesentence, and k is the size of the beam.
However,we can approximate the algorithm inO(n3k log k)time with cube pruning (Chiang, 2007).
Withfeatures which are not context-free, we are notguaranteed an optimal beam with this approach;however, empirically the approximation yields asignificant efficiency improvement without notice-able loss in performance.Training We adopt an EM-style bootstrappingapproach similar to Angeli et al (2012), in order tohandle the task of parsing the temporal expressionwithout annotations for the latent parses.
Eachtraining instance is a tuple consisting of the wordsin the temporal phrase, the annotated groundedtime ?
?, and the reference time.Given an input sentence, our parser will out-put k possible parses; when grounded to thereference time these correspond to k candidatetimes: ?1 .
.
.
?k, each with a normalized probabil-ity P (?i).
This corresponds to an approximate Estep in the EM algorithm, where the distributionover latent parses is approximated by a beam ofsize k. Although for long sentences the numberof parses is far greater than the beam size, as theparameters improve, increasingly longer sentenceswill have correct derivations in the beam.
In thisway, a progressively larger percentage of the datais available to be learned from at each iteration.To approximate the M step, we define a multi-class hinge loss l(?)
over the beam, and optimizeusing Stochastic Gradient Descent with AdaGrad(Duchi et al, 2010):l(?)
= max0?i<k1[?i 6= ??]
+ P?(?i)?
P?(??)
(2)We proceed to describe our features.4.2 FeaturesOur framework allows us to define arbitrary fea-tures over partial derivations.
Importantly, this al-lows us to condition not only on the PCFG proba-bilities over types but also the partial semantics ofthe derivation.
We describe the features used be-low; a summary of these features for a short phraseis illustrated in Figure 2.Bracketing Features A feature is defined overevery nonterminal combination, consisting ofthe pair of children being combined in thatrule.
In particular, let us consider a ruleR = (vi ?
vjvk, f) corresponding to a CFG rulevi ?
vjvk over types, and a function f over thesemantic values corresponding to vj and vk: ?jand ?k.
Two classes of bracketing features areextracted: features are extracted over the typesof nonterminals being combined (vj and vk), andover the top-level semantic derivation of the non-terminals (f , ?j , and ?k).Unlike syntactic parsing, child types of a parsetree uniquely define the parent type of the rule; thisis a direct consequence of our combination rulesbeing functions with domains defined in termsof the temporal types, and therefore necessarilyprojecting their inputs into a single output type.Therefore, the first class of bracketing features ?over types ?
reduce to have the exact same expres-sive power as the nonterminal CFG rules of Angeliet al (2012).
Examples of features in this class arefeatures 13 and 15 in Figure 2 (b).87Input (w,t) ( Friday of this week , August 6 2013 )LatentparseFRI ?
EveryWeekFRIFridayEveryWeekNilof thisEveryWeekweekOutput ??
August 9 2013FRIFriday1.
< FRI , Friday >Nilof this2.
< Nil , of >3.
< Nil , this >4.
< Nil , of this >5.
< nil bias >EveryWeekweek6.
< EveryWeek , week >EveryWeekNil EveryWeek7.
< Nil of , EveryWeek >8.
< Nil this , EveryWeek >9.
< Nil of this , EveryWeek >10.
< Nil of , Sequence >11.
< Nil this , Sequence >12.
< Nil of this , Sequence >13.
< Nil , Sequence >14.
< Nil , EveryWeek >FRI ?
EveryWeekFRI EveryWeek15.
< Sequence , Sequence >16.
< Intersect , FRI , EveryWeek >17.
< root valid >(a) (b)Figure 2: An example parse of Friday of this week, along with the features extracted from the parse.A summary of the input, latent parse, and output for a particular example is given in (a).
The featuresextracted for each fragment of the parse are given in (b), and described in detail in Section 4.2.We now also have the flexibility to extract a sec-ond class of features from the semantics of thederivation.
We define a feature bracketing themost recent semantic function applied to each ofthe two child derivations; along with the functionbeing applied in the rule application.
If the childis a preterminal, the semantics of the pretermi-nal are used; otherwise, the outermost (most re-cent) function to be applied to the derivation isused.
To illustrate, a tree fragment combiningAugust and 2013 into August 2013 wouldyield the feature<INTERSECT, AUGUST, 2013>.This can be read as a feature for the rule apply-ing the intersect function to August and 2013.Furthermore, intersecting August 2013 withthe 12th of the month would yield a feature<INTERSECT, INTERSECT, 12th>.
This can beread as applying the intersect function to a subtreewhich is the intersection of two terms, and to the12th of the month.
Features 14 and 16 in Figure 2(b) are examples of such features.Lexical Features The second large class of fea-tures extracted are lexicalized features.
These areprimarily used for tagging phrases with pretermi-nals; however, they are also relevant in incorporat-ing cues from the yield of Nil spans.
To illustrate, aweek and the week have very different meanings,despite differing by only their Nil tagged tokens.In the first case, a feature is extracted over thevalue of the preterminal being extracted, and thephrase it is subsuming (e.g., features 1?4 and 6 inFigure 2 (b)).
As the type of the preterminal isdeterministic from the value, encoding a featureon the type of the preterminal would be a coarserencoding of the same information, and is empir-ically not useful in this case.
Since a multi-wordexpression can parse to a single nonterminal, a fea-ture is extracted for the entire n-gram in additionto features for each of the individual words.
Forexample, the phrase of this ?
of type Nil ?
wouldhave features extracted: <NIL, of>, <NIL, this>,and <NIL, of this>.In the second case ?
absorbing Nil-tagged spans?
we extract features over the words under the Nilspan joined with the type and value of the otherderivation (e.g., features 7?12 in Figure 2 (b)).As above, features are extracted for both n-gramsand for each word in the phrase.
For example,combining of this and week would yield features88Train TestSystem Type Value Type ValueGUTime 0.72 0.46 0.80 0.42SUTime 0.85 0.69 0.94 0.71HeidelTime 0.80 0.67 0.85 0.71ParsingTime 0.90 0.72 0.88 0.72OurSystem 0.94 0.81 0.91 0.76Table 3: English results for TempEval-2 attributescores for our system and four previous systems.The scores are calculated using gold extents, forc-ing an interpretation for each parse.Train TestSystem Type Value Type ValueUC3M ?
?
0.79 0.72OurSystem 0.90 0.84 0.92 0.76Table 4: Spanish results for TempEval-2 attributescores for our system and the best known previ-ous system.
The scores are calculated using goldextents, forcing an interpretation for each parse.<of, EVERYWEEK>, <this, EVERYWEEK>,and <of this, EVERYWEEK>.In both cases, numbers are featurized accordingto their order of magnitude, and whether they areordinal.
Thus, the number tagged from thirty-firstwould be featurized as an ordinal number of mag-nitude 2.Semantic Validity Although some constraintscan be imposed to help ensure that a top-levelparse will be valid, absolute guarantees are diffi-cult.
For instance, February 30 is never a validdate; but, it would be difficult to disallow any localrule in its derivation.
To mediate this, an indicatorfeature is extracted denoting whether the groundedsemantics of the derivation is valid.
This is illus-trated in Figure 2 (b) by feature 17.Nil Bias Lastly, an indicator feature is extractedfor each Nil span tagged (feature 5 in Figure 2(b)).
In part, this discourages over-generation ofthe type; in another part, it encourages Nil spans toabsorb as many adjacent words as possible.We proceed to describe our experimental setupand results.5 EvaluationWe evaluate our model on all six languages inthe TempEval-2 Task A dataset (Verhagen et al,2010), comparing against state-of-the-art systemsfor English and Spanish.
New results are reportedon smaller datasets from the four other languages.To our knowledge, there has not been any priorwork on these corpora.We describe the TempEval-2 datasets in Sec-tion 5.1, present experimental results in Sec-tion 5.2, and discuss system errors in Section 5.3.5.1 TempEval-2 DatasetsTempEval-2, from SemEval 2010, focused on re-trieving and reasoning about temporal informationfrom newswire.
Our system evaluates against TaskA ?
detecting and resolving temporal expressions.Since we perform only the second of these, weevaluate our system assuming gold detection.The dataset annotates six languages: English,Spanish, Italian, French, Chinese, and Korean; ofthese, English and Spanish are the most mature.We describe each of these languages, along withrelevant quirks, below:English The English dataset consists of 1052training examples, and 156 test examples.
Evalu-ation was done using the official evaluation script,which checks for exact match between TIMEX3tags.
Note that this is stricter than our training ob-jective; for instance, 24 hours and a day have thesame interpretation, but have different TIMEX3strings.
System output was heuristically convertedto the TIMEX3 format; where ambiguities arose,the convention which maximized training accu-racy was chosen.Spanish The Spanish dataset consists of 1092training examples, and 198 test examples.
Evalua-tion was identical to the English, with the heuristicTIMEX3 conversion adapted somewhat.Italian The Italian dataset consists of 523 train-ing examples, and 126 test examples.
Evaluationwas identical to English and Spanish.Chinese The Chinese dataset consists of 744training examples, and 190 test examples.
Ofthese, only 659 training and 143 test examples hada temporal value marked; the remaining exampleshad a type but no value, and are therefore impossi-ble to predict.
Results are also reported on a cleancorpus with these impossible examples omitted.The Chinese, Korean, and French corpora hadnoticeable inconsistencies in the TIMEX3 anno-tation.
Thus, evaluations are reported according89Train TestLanguage # examples Type Value # examples Type ValueEnglish 1052 0.94 0.81 156 0.91 0.76Spanish 1092 0.90 0.84 198 0.92 0.76Italian 523 0.89 0.85 126 0.84 0.38Chinese?
744 0.95 0.65 190 0.87 0.48Chinese (clean)?
659 0.97 0.73 143 0.97 0.60Korean?
247 0.83 0.67 91 0.82 0.42French?
206 0.78 0.76 83 0.78 0.35Table 5: Our system?s accuracy on all 6 languages of the TempEval-2 corpus.
Chinese is divided into tworesults: one for the entire corpus, and one which considers only examples for which a temporal valueis annotated.
Languages with a dagger (?)
were evaluated based on semantic rather than string-matchcorrectness.to the training objective: if two TIMEX3 valuesground to the same grounded time, they are con-sidered equal.
For example, in the example above,24 hours and a day would be marked identical de-spite having different TIMEX3 strings.Most TIMEX3 values convert naturally toa grounded representation; values with wild-cards representing Sequences (e.g., 1998-QX or1998-XX-12) ground to the same value as theSequence encoding that value would.
For instance,1998-QX is parsed as every quarter in 1998.Korean The Korean dataset consists of 287training examples, and 91 test examples.
40 ofthe training examples encoded dates as a long in-teger For example: 003000000200001131951006grounds to January 13, 2000 at the time 19:51.These were removed from the training set, yield-ing 247 examples; however, all three such exam-ples were left in the test set.
Evaluation was doneidentically to the Chinese data.French Lastly, a dataset for French temporalexpressions was compiled from the TempEval-2data.
Unlike the other 5 languages, the Frenchdata included only the raw TIMEX3 annotatednewswire documents, encoded as XML.
Thesedocuments were scraped to recover 206 trainingexamples and 83 test examples.
Evaluation wasdone identically to the Chinese and Korean data.We proceed to describe our experimental resultson these datasets.5.2 ResultsWe compare our system with state-of-the-art sys-tems for both English and Spanish.
To the best ofour knowledge, no prior work exists for the otherfour languages.We evaluate in the same framework as Angeli etal.
(2012).
We compare to previous system scoreswhen constrained to make a prediction on everyexample; if no guess is made, the output is consid-ered incorrect.
This in general yields lower resultsfor those systems, as the system is not allowed toabstain on expressions it does not recognize.The systems compared against are:?
GUTime (Mani and Wilson, 2000), a widelyused, older rule-based system.?
HeidelTime (Stro?tgen and Gertz, 2010), thetop system at the TempEval-2 task for En-glish.?
SUTime (Chang and Manning, 2012), a morerecent rule-based system for English.?
ParsingTime (Angeli et al, 2012), a seman-tic parser for temporal expressions, similar tothis system (see Section 2).?
UC3M (Vicente-D?
?ez et al, 2010), a rule-based system for Spanish.Results for the English corpus are shown in Ta-ble 3.
Results for Spanish are shown in Table 4.Lastly, a summary of results in all six languages isshown in Table 5.A salient trend emerges from the results ?
whiletraining accuracy is consistently high, test accu-racy drops sharply for the data-impoverished lan-guages.
This is consistent with what would beexpected from a discriminatively trained modelin data-impoverished settings; however, the con-sistent training accuracy suggests that the modelnonetheless captures the phenomena it sees in90Error Class English SpanishPragmatics 29% 23%Type error 16% 5%Incorrect number 10% 5%Relative Range 7% 2%Incorrect parse 19% 36%Missing context 16% 23%Bad reference time 3% 6%Table 6: A summary of errors of our system,by percentage of incorrect examples for the En-glish and Spanish datasets.
The top section de-scribes errors which could be handled in ourframework, while the bottom section describes ex-amples which are either ambiguous (missing con-text), or are annotated inconsistently relative thereference time.training.
This suggests the possibility for improv-ing accuracy further by making use of more dataduring training.5.3 DiscussionWe characterize the examples our system parsesincorrectly on the English and Spanish datasets inTable 6, expanding on each class of error below.Pragmatics This class of errors is a result ofpragmatic ambiguity over possible groundings ofa sequence ?
for instance, it is often ambiguouswhether next weekend refers to the coming or sub-sequent weekend.
These errors manifest in eitherdropping a function (next, last), or imagining onethat is not supported by the text (e.g., this weekparsed as next week).Type error Another large class of errors ?
par-ticularly in the English dataset ?
arise from notmatching the annotation?s type, but otherwise pro-ducing a reasonable response.
For instance, thesystem may mistake a day on the calendar (aRange), with a day, the period of time.Incorrect number A class of mistakes arisesfrom either omitting numbers from the parse, orincorrectly parsing numbers ?
the second case isparticularly prevalent for written years, such asseventeen seventy-six.Relative Range These errors arise from attempt-ing to parse a grounded Range by applying func-tions to the reference time.
For example, froma reference time of August 8th, it is possible to?correctly?
parse the phrase August 1 as a weekago; but, naturally, this parse does not general-ize well.
This class of errors, although relativelysmall, merits special designation as it suggests aclass of correct responses which are correct for thewrong reasons.
Future work could explore miti-gating these errors for domains where the text isfurther removed from the events it is describingthan most news stories are.Incorrect parse Errors in this class are a resultof failing to find the correct parse, for a number ofreasons not individually identified.
A small sub-set of these errors (notably, 6% on the Spanishdataset) are a result of the grammar being insuf-ficiently expressive with the preterminals we de-fined.
For instance, we cannot capture fractionalunits, such as in half an hour.Missing context A fairly large percentage of ourerrors arise from failing to classify inputs whichexpress ambiguous or poorly defined times.
Forexample, from time to time (annotated as the fu-ture), or that time (annotated as 5 years).
Manyof these require either some sort of inference or abroader understanding of the context in which thetemporal phrase is uttered, which our system doesnot attempt to capture.Bad reference time The last class of errorscover cases where the temporal phrase is clear,but annotation differs from our judgment of whatwould be reasonable.
These are a result of assum-ing that the reference time of an utterance is thepublication time of the article.6 ConclusionWe have presented a discriminative, multilingualapproach to resolving temporal expressions, usinga language-flexible latent parse and rich featureson both the types and values of partial derivationsin the parse.
We showed state-of-the-art resultson both languages in TempEval-2 with prior work,and presented results on four additional languages.Acknowledgments Work was done in the sum-mer of 2012 while the first author was an intern atGoogle.
We would like to thank Chris Manning,and our co-workers at Google for their insight andhelp.91ReferencesJames F. Allen.
1981.
An interval-based representa-tion of temporal knowledge.
In Proceedings of the7th international joint conference on Artificial intel-ligence, pages 221?226, San Francisco, CA, USA.Morgan Kaufmann Publishers Inc.James Allen.
1995.
Natural Language Understanding.Benjamin/Cummings, Redwood City, CA.Gabor Angeli, Christopher D. Manning, and Daniel Ju-rafsky.
2012.
Parsing time: Learning to interprettime expressions.
In NAACL-HLT.E.
Bach.
1976.
An extension of classical transforma-tional grammar.
In Problems of Linguistic Metathe-ory (Proceedings of the 1976 Conference), MichiganState University.Angel Chang and Chris Manning.
2012.
SUTIME: alibrary for recognizing and normalizing time expres-sions.
In Language Resources and Evaluation.David Chiang.
2007.
Hierarchical phrase-based trans-lation.
computational linguistics, 33(2):201?228.James Clarke, Dan Goldwasser, Ming-Wei Chang, andDan Roth.
2010.
Driving semantic parsing from theworld?s response.
In CoNLL, pages 18?27, Uppsala,Sweden.John Duchi, Elad Hazan, and Yoram Singer.
2010.Adaptive subgradient methods for online learningand stochastic optimization.
Journal of MachineLearning Research, 12:2121?2159.Claire Grover, Richard Tobin, Beatrice Alex, and KateByrne.
2010.
Edinburgh-LTG: TempEval-2 systemdescription.
In Proceedings of the 5th InternationalWorkshop on Semantic Evaluation, Sem-Eval, pages333?336.Rohit J. Kate, Yuk Wah Wong, and Raymond J.Mooney.
2005.
Learning to transform natural toformal languages.
In AAAI, pages 1062?1068, Pitts-burgh, PA.Oleksandr Kolomiyets and Marie-Francine Moens.2010.
KUL: recognition and normalization of tem-poral expressions.
In Proceedings of the 5th Interna-tional Workshop on Semantic Evaluation, Sem-Eval?10, pages 325?328.P.
Liang, M. I. Jordan, and D. Klein.
2011.
Learn-ing dependency-based compositional semantics.
InACL.Hector Llorens, Estela Saquete, and Borja Navarro.2010.
Tipsem (english and spanish): Evaluating crfsand semantic roles in tempeval-2.
In Proceedings ofthe 5th International Workshop on Semantic Evalu-ation, pages 284?291.Inderjeet Mani and George Wilson.
2000.
Robust tem-poral processing of news.
In ACL, pages 69?76,Hong Kong.G.
Puscasu.
2004.
A framework for temporal resolu-tion.
In LREC, pages 1901?1904.Hans Reichenbach.
1947.
Elements of Symbolic Logic.Macmillan, New York.E.
Saquete, R. Muoz, and P. Martnez-Barco.
2003.Terseo: Temporal expression resolution system ap-plied to event ordering.
In Text, Speech and Dia-logue, pages 220?228.Jannik Stro?tgen and Michael Gertz.
2010.
Heideltime:High quality rule-based extraction and normaliza-tion of temporal expressions.
In Proceedings of the5th International Workshop on Semantic Evaluation,Sem-Eval, pages 321?324.Naushad UzZaman and James F. Allen.
2010.
TRIPSand TRIOS system for TempEval-2: Extracting tem-poral information from text.
In Proceedings of the5th International Workshop on Semantic Evaluation,Sem-Eval, pages 276?283.Marc Verhagen, Roser Sauri, Tommaso Caselli, andJames Pustejovsky.
2010.
Semeval-2010 task 13:TempEval-2.
In Proceedings of the 5th Interna-tional Workshop on Semantic Evaluation, pages 57?62, Uppsala, Sweden.Mar?
?a Teresa Vicente-D?
?ez, Julia?n Moreno Schneider,and Paloma Mart??nez.
2010.
Uc3m system: De-termining the extent, type and value of time expres-sions in tempeval-2.
In proceedings of the SemanticEvaluation?2 (Semeval 2010), ACL Conference, Up-psala (Sweden).Kenji Yamada and Kevin Knight.
2001.
A syntax-based statistical translation model.
In ACL, pages523?530.John M. Zelle and Raymond J. Mooney.
1996.
Learn-ing to parse database queries using inductive logicprogramming.
In AAAI/IAAI, pages 1050?1055,Portland, OR.Luke S. Zettlemoyer and Michael Collins.
2005.Learning to map sentences to logical form: Struc-tured classification with probabilistic categorialgrammars.
In UAI, pages 658?666.
AUAI Press.Luke S. Zettlemoyer and Michael Collins.
2007.
On-line learning of relaxed CCG grammars for parsingto logical form.
In EMNLP-CoNLL, pages 678?687.92
