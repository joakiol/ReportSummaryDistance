A New Approach to Automatic Document SummarizationXiaofeng WuNational Laboratory of Pattern Recognition,Institute of Automation,Chinese Academy of SciencesBeijing, Chinaxfwu@nlpr.ia.ac.cnChengqing ZongNational Laboratory of Pattern Recognition,Institute of Automation,Chinese Academy of SciencesBeijing, Chinacqzong@nlpr.ia.ac.cnAbstractIn this paper we propose a new approachbased on Sequence Segmentation Models(SSM) to the extractive document summa-rization, in which summarizing is regardedas a segment labeling problem.
Comparingwith the previous work, the difference ofour approach is that the employed featuresare obtained not only from the sentencelevel, but also from the segment level.
Inour approach, the semi-Markov CRF modelis employed for segment labeling.
The pre-liminary experiments have shown that theapproach does outperform all other tradi-tional supervised and unsupervised ap-proaches to document summarization.1 IntroductionDocument summarization has been a rapidlyevolving subfield of Information Retrieval (IR)since (Luhn, 1958).
A summary can be looselydefined as a text that is produced from one or moretexts and conveys important information of theoriginal text(s).
Usually it is no longer than half ofthe original text(s) or, significantly less (Radev etal., 2002).
Recently, many evaluation competitions(like the Document Understanding ConferenceDUC ?http://duc.nist.gov?, in the style of NIST?sTREC), provided some sets of training corpus.
It isobvious that, in the age of information explosion,document summarization will be greatly helpful tothe internet users; besides, the techniques it usescan also find their applications in speech tech-niques and multimedia document retrieval, etc.The approach to summarizing can be catego-rized in many ways.
Some of them are: 1) indica-tive, informative and evaluative, according to func-tionality; 2) single-document and multi-document,according to the amount of input documents; 3)generic and query-oriented, according to applica-tions.
Yet the taxonomy currently widely em-ployed is to categorize summarization into abstrac-tive and extractive.According to (Radev et al, 2002), all methodsthat are not explicitly extractive are categorized asabstractive.
These approaches include ontologicalinformation, information fusion, and compression.Abstract-based summarization never goes beyondconceptual stage, though ever since the dawn ofsummarization it has been argued as an alternativefor its extract-based counterpart.
On the other hand,extractive summarization is still attracting a lot ofresearchers (Yeh et al, 2005) (Daum?e III andMarcu, 2006) and many practical systems, say,MEAD ?http://www.summarization.com/mead/?,have been produced.
Using supervised or unsuper-vised machine learning algorithms to extract sen-tences is currently the mainstream of the extractivesummarization.
However, all pervious methodsfocus on obtaining features from the sentence gra-nularity.In this paper we focus on generating summariza-tion by using a supervised extractive approach inwhich the features are obtained from a larger gra-nularity, namely segment.
The remainder of thepaper is organized as follows: Section 2 introducesthe related work concerning the extract-basedsummarization.
Section 3 describes our motiva-tions.
Our experiments and results are given inSection 4, and Section 5 draws the conclusion andmentions the future work.1262 Related WorkEarly researchers approached the summarizationproblem by scoring each sentence with a combina-tion of the features like word frequency and distri-bution, some proper names (Luhn, 1958), sentencepositions in a paragraph (Baxendale, 1958), andsentence similarity (Gong, 2001) etc.
The resultswere comparatively good.
Most supervised extrac-tive methods nowadays focus on finding powerfulmachine learning algorithms that can properlycombine these features.Bayesian classifier was first applied to summari-zation by (Pedersen and Chen, 1995), the authorsclaimed that the corpus-trained feature weightswere in agreement with (Edmundson, 1969), whichemployed a subjective combination of weightedfeatures.
Another usage of the na?ve Bayesianmodel in summarization can be found in (Aone etal., 1997).
Bayesian model treats each sentenceindividually, and misses the intrinsic connectionbetween the sentences.
(Yeh et al, 2005) employedgenetic algorithm to calculate the belief or score ofeach sentence belonging to the summary, but italso bears this shortcoming.To overcome this independence defect, (Conroyand O?leary, 2001) pioneered in deeming this prob-lem as a sequence labeling problem.
The authorsused HMM, which has fewer independent assump-tions.
However, HMM can not handle the rich lin-guistic features among the sentences either.
Re-cently, as CRF (Lafferty and McCallum, 2001) hasbeen proved to be successful in part-of-speech tag-ging and other sequence labeling problems, (Shenet al, 2007) attempted to employ this model indocument summarization.
CRF can leverage allthose features despite their dependencies, and ab-sorb other summary system?s outcome.
By intro-ducing proper features and making a comparisonwith SVM, HMM, etc., (Shen et al, 2007) claimedthat CRF could achieve the best performance.All these approaches above share the sameviewpoint that features should be obtained at sen-tence level.
Nevertheless, it can be easily seen thatthe non-summary or summary sentences tend toappear in a consecutive manner, namely, in seg-ments.
These rich features of segments can surelynot be managed by those traditional methods.Recently, Sequence Segmentation Model (SSM)has attracted more and more attention in sometraditional sequence learning tasks.
SSM builds adirect path to encapsulate the rich segmentalfeatures (e.g., entity length and the similarity withother entities, etc., in entity recognition).
Semi-CRF (Sarawagi and Cohen, 2004) is one of theSSMs, and generally outperforms CRF.3 MotivationsAccording to the analysis in Section 2, our basicidea is clear that we regard the supervised summa-rizing as a problem of sequence segmentation.However, in our approach, the features are not onlyobtained on the sentence level but also on the seg-ment level.Here a segment means one or more sentencessharing the same label (namely, non-summary orsummary), and a text is regarded as a sequence ofsegments.
Semi-CRF is a qualified model to ac-complish the task of segment labeling, besides itshares all the virtues of CRF.
Using semi-CRF, wecan easily leverage the features both in traditionalsentence level and in the segment level.
Some fea-tures, like Log Likelihood or Similarity, if obtainedfrom each sentence, are inclined to give unex-pected results due to the small granularity.
Fur-thermore, semi-CRF is a generalized version ofCRF.
The features designed for CRF can be usedin semi-CRF directly, and it has been proved thatsemi-CRF outperforms CRF in some Natural Lan-guage Processing (NLP) problems (Sarawagi andCohen, 2004).In the subsections below, we first introducesemi-CRF then describe the features we used inour approach.3.1 Semi-CRFCRF was first introduced in (Lafferty andMcCallum, 2001).
It is a conditional model P(Y|X),and here both X and Y may have complex structure.The most prominent merits of CRF are that itoffers relaxation of the strong independenceassumptions made in HMM or Maximum EntropyMarkov Models (MEMM) (McCallum, 2000) andit is no victim of the label bias problem.
Semi-CRFis a generalization version of sequential CRF.
Itextends CRF by allowing each state to persist for anon-unit length of time.
After this time has elapsed,the system might transmit to a new state, whichonly depends on its previous one.
When the systemis in the ?segment of time?, it is allowed to behavenon-Markovianly.1273.1.1 CRF vs. Semi-CRFGiven an observed sentence sequenceX=(x1,x2,?,xM).
The corresponding output labelsare Y=(y1,y2,?,yM), where yi gets its value from afixed set ?.
For document summarization,?={0,1}.
Here 1 for summary and 0 for non-summary.
The goal of CRF is to find a sequence ofY, that maximize the probability:1( | , ) exp( ( , ))( )P Y X W W F X YZ X= ?
(1)Here?
is a vertical vector ofsize T. The vertical vector1( , ) f ( , , )MiF X Y i X Y==?1 2'f ( , , ..., )Tf f f= meansthere are T feature functions, and each of them canbe written as ft(i,X,Y)?R,t?(1,?,T),i?
(1,?,M).For example, in our experiment the 10th featurefunction is expressed as: [if the length of currentsentence is bigger than the predefined thresholdvalue]&[if the current sentence is a summary].When this feature function is acting upon the thirdsentence in text_1 with label_sequence_1, the fol-lowing feature equation f10(3,text_1, la-bel_sequence_1) means: in text_1 with la-bel_sequence_1, [if the length of the third sentenceis bigger than the predefined threshold value]&[ifthe third sentence is a summary].
W is a horizontalvector of size T that represents the weights of thesefeatures respectively.
Equation (2) gives the defini-tion of Z(X), which is a normalization constant thatmakes the probabilities of all state sequences sumto 1.
'( ) exp( ( , '))YZ X W F X= ??
Y|(2)If we change the sequence vector X toS=<s1,s2,?,sN>, which means one way to split Xinto N segments, we have the semi-CRF.
Eachelement in S is a triple: Sj=<tj,uj,yj>, which de-notes the jth segment in this way of segmentation.In the triple, tj denotes the start point of the jth seg-ment, uj denotes its end position, and yj is the out-put label of the segment (recall the example at thebeginning of this subsection that there is only oneoutput for a segment).
Under this definition, seg-ments should have no overlapping, and satisfy thefollowing conditions:1| | |Njjs X==?
(3)(4) 1 11, | |,1 | |, 1N j j jt u X t u X t u+= = ?
?
?
= +Here, |?| denotes the length of?.Figure 1  A 10-sentences text with label sequenceFor example, one way to segment a text of 10 sen-tences in Figure 1 is S=<(1,1,1),(2,4,0),(5,5,1),(6,9,0),(10,10,1)> .
The circles in the second rowrepresent sentences, and actually are only someproperties of the corresponding sentences.Consequently, the feature function f in CRFconverts to the segmental feature functiong=(g1,g2,?,g T?).
Like f, gt(i,x,s) ?R also maps atriple (i,x,s) to a real number.
Similarly, we maydefine .
Now we give thefinal equation used to estimate the probability of S.Given a sequence X and feature weight W, we have1( , ) g( , , )NiG X S i X S== ?1( | , ) exp( ( , ))( )P S X W W G X SZ X= ?
(5)Here,'( ) exp( ( , '))SZ X W G X?
?= ?
S?
(6)Where, { }all segmentations allowed?
= ?
?
.3.1.2 InferenceThe inference or the testing problem of semi-CRFis to find the best S that maximizes Equation (5).We use the following Viterbi-like algorithm to cal-culate the optimum path.Suppose the longest segment in corpus is K, letS1:i,y represent all possible segmentations startingfrom 1 to i , and the output of the last segment is y.V(i,y) denotes the biggest value of P(S?|X,W).
Notethat it?s also the largest value of W?G(X,S?),S?
?S1:i,y.Compared with the traditional Viterbi algorithmused in CRF, the inference for semi-CRF is moretime-consuming.
But by studying Algorithm 1, wecan easily find out that the cost is only linear in K.j1283.1.3 Parameter EstimationDefine the following functionlog ( | , )( ( , ) log (lW l ll l l lL P S X WW G X S Z X= ?= ?
?? ))
(8)In this approach, the problem of parameter estima-tion is to find the best weight W that maximizes LW.According to (Bishop, 2006), the Equation (8) isconvex.
So it can be optimized by gradient ascent.Various methods can be used to do this work (Pie-tra et al 1997).
In our system, we use L-BFGS, aquasi-Newton algorithm (Liu and Nocedal.
1989),because it has the fast converging speed and effi-cient memory usage.
APIs we used for estimationand inference can be found in website?http:\\crf.sourcefourge.net?.3.2 Features(Shen et al 2007) has made a thorough investiga-tion of the performances of CRF, HMM, and SVM.So, in order to simplify our work and make it com-parable to the previous work, we shape our desig-nation of features mainly under their framework.The mid column in Table 1 lists all of the fea-tures we used in our semi-CRF approach.
For theconvenience of comparison, we also list the nameof the features used in (Shen et al 2007) in theright column, and name them Regular Features.The features in bold-face in the mid column are thecorresponding features tuned to fit for the usage ofsemi-CRF.
We name them Extended Features.There are some features that are not in bold-face inthe mid column.
These features are the same as theRegular Features in the right column.
We alsoused them in our approach.
The mark star denotesthat there is no counterpart.
We number these fea-tures in the left column.
Algorithm 1:Step1.
Initialization:Let V i  ( , ) 0,  0No.
semi-CRF CRF1 Ex_Position        Position2 Ex_Length         Length3 Ex_Log_Likelihood  Log Likeli-hood4Ex_Similarity_to_Neighboring_SegmentsSimilarity toNeighboringSentences5 Ex_Segment_Length     *6 Thematic           Thematic7 Indicator           Indicator8 Upper Case         Upper Casey for i= =Step2.
Induction:0for i >', 1,...,( , ) max ( , ')g( , ', , 1, )y k KV i y V i k yW y y x i d i== ?+ ?
?
+         (7)Step3.
Termination and path readout:max (| |, )ybestSegment V X y=Table 1.
Features ListThe details of the features we used in semi-CRF are explained as follow.Extended Features:Ex_Position: is an extended version of the Po-sition feature.
It gives the description of the po-sition of a segment in the current segmentation.If the sentences in the current segment containthe beginning sentence of a paragraph, the valueof this feature will be 1, 2 if it contains the endof a paragraph; and 3 otherwise;Ex_Length: the number of words in the cur-rent segment after removing some stop-words.Ex_Log_Likelihood: the log likelihood of thecurrent segment being generated by the docu-ment.
We use Equation (9) below to calculatethis feature.
N(wj,si) denotes the number of oc-currences of the word wj in the segment si, andwe use ( , ) / ( , )kj w kN w D N w D?
to estimate theprobability of a word being generated by a doc-ument.log ( | ) ( , ) log ( | )ji j iw jP s D N w s p w D=?
(9)Ex_Similarity_to_Neighboring_Segments:we define the cosine similarity based on theTF*IDF (Frakes &Baeza-Yates, 1992) betweena segment and its neighbors.
But unlike (Shen etal.
2007), in our work only the adjacent neighborsof the segment in our work are considered.EX_Segment_Length: this feature describesthe number of sentences contained in a segment.129All these features above are actually an ex-tended version used in the regular CRF (or inother supervised model).
It is easy to see that, ifthe segment length is equal to 1, then the fea-tures will degrade to their normal forms.There are some features that are also used insemi-CRF but we don?t extend them like thosefeatures above.
Because the extended version ofthese features leads to no improvement of ourresult.
These features are:Regular features we used:Thematic: with removing of stop words, wedefine the words with the highest frequency inthe document to be the thematic words.
And thisfeature gives the count of these words in eachsentence.Indicator: indicative words such as ?conclu-sion?
and ?briefly speaking?
are very likely to beincluded in summary sentences, so we definethis feature to signal if there are such words in asentence.Upper Case: some words with upper case areof high probability to be a name, and sentenceswith such words together with other wordswhich the author might want to emphasize arelikely to be appeared in a summary sentence.
Sowe use this feature to indicate whether there aresuch words in a sentence.It should be noted that theoretically the num-ber of extended features obtained from the cor-pus goes linearly with K in Equation (7).4 Experiments4.1 Corpus & Evaluation CriteriaTo evaluate our approach, we applied the widelyused test corpus of (DUC2001), which is spon-sored by ARDA and run by NIST?http://www.nist.gov?.
The basic aim of DUC2001 is to further progress of summarization andenable researchers to participate into large-scaleexperiments.
The corpus DUC2001 we used con-tains 147 news texts, each of which has been la-beled manually whether a sentence belongs to asummary or not.
Because in (Shen et al 2007) allthe experiments were conducted upon DUC2001,we may make a comparison between the sequencelabeling models and the sequence segmentationmodes we used.
The only preprocessing we did isto remove some stop words according to a stopword list.We use F1 score as the evaluation criteria which isdefined as:2*Precesion*Recall1Precesion+RecallF =                 (10)We used 10-fold cross validation in order to reducethe uncertainty of the model we trained.
The finalF1 score reported is the average of all these 10 ex-periments.All those steps above are strictly identical to thework in (Shen et al 2007), and its result is taken asour baseline.4.2 Results & AnalysisAs we mentioned in Sub-Section 3.2, those ex-tended version of features only work when seg-ment length is bigger than one.
So, each of theseextended version of features or their combinationcan be used together with all the other regular fea-tures listed in the right column in Table 1.
In orderto give a complete test of the capacity of all theseextended features and their combinations, we dothe experiments according to the power set of {1, 2,3, 4, 5} (the numbers are the IDs of these extendedfeatures as listed in Table 1), that is we need to dothe test 25-1 times with different combinations ofthe extended features.
The results are given in Ta-ble 2.
The rows with italic fonts (1, 3, 5, 7, 9, 11,13), in Table 2 denote the extended features used.For example, ?1+2?
means that the featuresEx_Positon and the Ex_Length are together usedwith all other regular features are used.Table 2.
Experiment results.1 2 3 4 5F1 0.395 0.391 0.398 0.394 0.3921+2 1+3 1+4 1+5 2+3F1 0.395 0.396 0.396 0.395 0.3822+4 2+5 3+4 3+5 4+5F1 0.389 0.384 0.398 0.399 0.3801+2+3 1+2+4 1+2+5 1+3+4 1+3+5F1 0.398 0.397 0.393 0.403 0.4021+4+5 2+3+4 2+3+5 2+4+5 3+4+5F1 0.402 0.403 0.401 0.403 0.4041+2 +3+41+2+3+51+2+4+51+3+4+52+3+4+5F1 0.407 0.404 0.406 0.402 0.404All CRFF1 0.406 0.389130Other rows (2, 4, 6, 8, 10, 12, 14) give F1 scorescorresponding to the features used.In Table 3 we compare our approach with someof the most popular unsupervised methods, includ-ing LSA (Frakes & Baeza-Yates, 1992) and HITS(Mihalcea 2005).
The experiments were conductedby (Shen et al 2007).Table 3 Comparison with unsupervised methodsFrom the results in Table 2 we can see that indi-vidually applying these extended features can im-prove the performance somewhat.
The best one ofthese extended features is feature 3, as listed in the2nd row, the 5th column.
The highest improvement,1.8%, is obtained by combining the features 1, 2, 3and 4.
Although a few of the combinations hurt theperformance, most of them are helpful.
This veri-fies our hypothesis that the extended features underSSM have greater power than the regular features.The results in Table 3 demonstrate that our ap-proach significantly outperforms the traditionalunsupervised methods.
8.3% and 4.9% improve-ments are respectively gained comparing to LSAand HITS modelsCurrently, the main problem of our method isthat the searching space goes large by using theextended features and semi-CRF, so the trainingprocedure is time-consuming.
However, it is not sounbearable, as it has been proved in (Sarawagi andCohen, 2004).5 Conclusion and Future WorkIn this paper, we exploit the capacity of semi-CRF ,we also make a test of most of the common fea-tures and their extended version designed for doc-ument summarization.
We have compared our ap-proach with that of the regular CRF and some ofthe traditional unsupervised methods.
The com-parison proves that, because summary sentencesand non-summary sentences are very likely toshow in a consecutive manner, it is more nature toobtain features from a lager granularity than sen-tence.In our future work, we will test this approach onsome other well known corpus, try the complexfeatures used in (Shen et al 2007), and reduce thetime for training.AcknowledgementsThe research work described in this paper has beenfunded by the Natural Science Foundation of Chi-na under Grant No.
60375018 and 60121302.ReferencesC.Aone, N. Charocopos, J. Gorlinsky.
1997.
AnIntelligent Multilingual Information Browsing andRetrieval System Using Information Extraction.
InANLP, 332-339.P.B.
Baxendale.
1958.
Man-made Index for Tech-nical Literature -An Experiment.
IBM Journal ofResearch and Development, 2(4):354-361.C.M.
Bishop.
2006.
Linear Models for Classifica-tion, Pattern Recognition and Machine Learning,chapter 4, Springer.J.
M. Conroy and D. P. O?leary.
2001.
Text Sum-marization via Hidden Markov Models.
In SIGIR,406-407.Hal Daum?e III, and D. Marcu.
2006.
BayesianQuery- Focused Summarization, In ACLH.
P. Edmundson.
1969.
New Methods in Auto-matic Extracting.
Journal of the Association forComputing Machinery, 16(2):264-285.W.
B. Frakes, R. Baeza-Yates, 1992, InformationRetrieval Data Structures & Algorithms.
PrenticeHall PTR, New JerseyY.
H. Gong and X. Liu.
2001.
Generic text summa-rization using relevance measure and latent seman-tic analysis.
In SIGIR, 19-25J.
Kupiec, J. Pedersen, and F. Chen.
1995.
ATrainable Document Summarizer.
Research andDevelopment in Information Retrieval, 68-73J.
D. Lafferty, A. McCallum and F. C. N. Pereira.2001.
Conditional random fields: probabilisticmodels for segmenting and labeling sequence data.ICML, 282-289.D.
C. Liu and J. Nocedal.
1989.
On the limitedmemory BFGS method for large-scale optimiza-tion.
Mathematic Programming, 45:503-528.H.
P. Luhn.
1958.
The Automatic Creation of Lit-erature Abstracts.
IBM Journal of Research andDevelopment, 2(2): 159 -165.LSA HITS Seim-CRFF1 0.324 0.368 0.407131A.
McCallum, D. Freitag, and F. Pereira.
2000.Maximum entropy Markov models for informationextraction and segmentation.
In ICML, 591-598Mihalcea R. Mihalcea.
2005.
Language independ-ent extractive summarization.
In AAAI, 1688-1689S.
D. Pietra, V. D. Pietra, and J. D. Lafferty.
1997.Inducing features of random fields.
IEEE Tran.
onPattern Analysis and Machine Intelligence,19(:)380?393.D.
R. Radev, E. Hovy and K. McKeown.
2002.Introduction to the Special Issue on Summarization.Computational Linguistics, 28(4): 399-408.S.
Sarawagi and W.W. Cohen.
2004.
Semi-markovconditional random fields for information extrac-tion.In NIPSD.
Shen, J. T. Sun, H. Li, Q. Yang, Z. Chen.
2007.Document Summarization using Conditional Ran-dom Fields?
In IJCAI, 1805-1813J.
Y. Yeh, H. R. Ke, W. P. Yang and I. H. Meng.2005.
Text summarization using trainable summar-izer and latent semantic analysis.
IPM, 41(1): 75?95132
