Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 43?47,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsTight Integration of Speech Disfluency Removal into SMTEunah Cho Jan NiehuesInteractive Systems LabInstitute of AnthropomaticsKarlsruhe Institute of Technology, Germany{eunah.cho,jan.niehues,alex.waibel}@kit.eduAlex WaibelAbstractSpeech disfluencies are one of the mainchallenges of spoken language processing.Conventional disfluency detection systemsdeploy a hard decision, which can havea negative influence on subsequent appli-cations such as machine translation.
Inthis paper we suggest a novel approachin which disfluency detection is integratedinto the translation process.We train a CRF model to obtain a disflu-ency probability for each word.
The SMTdecoder will then skip the potentially dis-fluent word based on its disfluency prob-ability.
Using the suggested scheme, thetranslation score of both the manual tran-script and ASR output is improved byaround 0.35 BLEU points compared to theCRF hard decision system.1 IntroductionDisfluencies arise due to the spontaneous natureof speech.
There has been a great deal of effort todetect disfluent words, remove them (Johnson andCharniak, 2004; Fitzgerald et al., 2009) and usethe cleaned text for subsequent applications suchas machine translation (MT) (Wang et al., 2010;Cho et al., 2013).One potential drawback of conventional ap-proaches is that the decision whether a token isa disfluency or not is a hard decision.
For anMT system, this can pose a severe problem if theremoved token was not in fact a disfluency andshould have been kept for the correct translation.Therefore, we pass the decision whether a word ispart of a disfluency or not on to the translation sys-tem, so that we can use the additional knowledgeavailable in the translation system to make a morereliable decision.
In order to limit the complexity,the search space is pruned prior to decoding andrepresented in a word lattice.2 Related WorkDisfluencies in spontaneous speech have beenstudied from various points of view.
In the noisychannel model (Honal and Schultz, 2003), it isassumed that clean text without any disfluencieshas passed through a noisy channel.
The cleanstring is retrieved based on language model (LM)scores and five additional models.
Another noisychannel approach involves a phrase-level statisti-cal MT system, where noisy tokens are translatedinto clean tokens (Maskey et al., 2006).
A tree ad-joining grammar is combined with this noisy chan-nel model in (Johnson and Charniak, 2004), usinga syntactic parser to build an LM.Fitzgerald et al.
(2009) present a method to de-tect speech disfluencies using a conditional ran-dom field (CRF) with lexical, LM, and parserinformation features.
While previous work hasbeen limited to the postprocessing step of the au-tomatic speech recogition (ASR) system, furtherapproaches (Wang et al., 2010; Cho et al., 2013)use extended CRF features or additional modelsto clean manual speech transcripts and use themas input for an MT system.While ASR systems use lattices to encode hy-potheses, lattices have been used for MT systemswith various purposes.
Herrmann et al.
(2013)use lattices to encode different reordering variants.Lattices have also been used as a segmentation tac-tic for compound words (Dyer, 2009), where thesegmentation is encoded as input in the lattice.One of the differences between our work andprevious work is that we integrate the disfluencyremoval into an MT system.
Our work is not lim-ited to the preprocessing step of MT, instead weuse the translation model to detect and remove dis-fluencies.
Contrary to other systems where detec-tion is limited on manual transcripts only, our sys-43tem shows translation performance improvementson the ASR output as well.3 Tight Integration using LatticesIn this chapter, we explain how the disfluency re-moval is integrated into the MT process.3.1 ModelThe conventional translation of texts from sponta-neous speech can be formulated ase?
= argmaxep(e| argmaxfcp(fc|f)) (1)withp(fc|f) =I?i=1p(ci|fi) (2)where fcdenotes the clean stringfc= {f1, .
.
.
, fI| ci= clean} (3)for the disfluency decision class c of each token.c ?
{cleandisfluent(4)Thus, using the conventional models, disfluencyremoval is applied to the original, potentially noisystring in order to obtain the cleaned string first.This clean string is then translated.The potential drawback of a conventionalspeech translation system is caused by the roughestimation in Equation 1, as disfluency removaldoes not depend on maximizing the translationquality itself.
For example, we can consider thesentence Use what you build, build what you use.Due to its repetitive pattern in words and structure,the first clause is often detected as a disfluency us-ing automatic means.
To avoid this, we can changethe scheme how the clean string is chosen as fol-lows:e?
= argmaxe,fc(p(e|fc) ?
p(fc|f)) (5)This way a clean string which maximizes thetranslation quality is chosen.
Thus, no instant de-cision is made whether a token is a disfluency ornot.
Instead, the disfluency probability of the to-ken will be passed on to the MT process, usingthe log linear combination of the probabilities asshown in Equation 5.In this work, we use a CRF (Lafferty et al.,2001) model to obtain the disfluency probabilityof each token.Since there are two possible classes for each to-ken, the number of possible clean sentences is ex-ponential with regard to the sentence length.
Thus,we restrict the search space by representing onlythe most probable clean source sentences in a wordlattice.3.2 CRF Model TrainingIn order to build the CRF model, we used theopen source toolkit CRF++ (Kudoh, 2007).
Asunigram features, we use lexical and LM featuresadopted from Fitzgerald et al.
(2009), and addi-tional semantics-based features discussed in (Choet al., 2013).
In addition to the unigram features,we also use a bigram feature to model first-orderdependencies between labels.We train the CRF with four classes; FL for fillerwords, RC for (rough) copy, NC for non-copy and0 for clean tokens.
The class FL includes obviousfiller words (e.g.
uh, uhm) as well as other dis-course markers (e.g.
you know, well in English).The RC class covers identical or roughly simi-lar repetitions as well as lexically different wordswith the same meaning.
The NC class representsthe case where the speaker changes what to speakabout or reformulates the sentence and restarts thespeech fragments.
The disfluency probability Pdof each token is calculated as the sum of probabil-ities of each class.3.3 Lattice ImplementationWe construct a word lattice which encodes long-range reordering variants (Rottmann and Vogel,2007; Niehues and Kolss, 2009).
For translationwe extend this so that potentially disfluent wordscan be skipped.
A reordering lattice of the ex-ample sentence Das sind die Vorteile, die sie uhdie sie haben.
(En.gls: These are the advantages,that you uh that you have.)
is shown in Figure 1,where words representing a disfluency are markedin bold letters.
In this sentence, the part die sieuh was manually annotated as a disfluency, due torepetition and usage of a filler word.Table 1 shows the Pdobtained from the CRFmodel for each token.
As expected, the words diesie uh obtain a high Pdfrom the CRF model.In order to provide an option to avoid translatinga disfluent word, a new edge which skips the wordis introduced into the lattice when the word has ahigher Pdthan a threshold ?.
During decoding theimportance of this newly introduced edge is opti-mized by weights based on the disfluency proba-440 1 das 2 sie 3 sie 4 sind 5 das 6 das 7 die 8 sind 9 sind 10 Vorteile 11 die 12 die 13 , 14 Vorteile 15 Vorteile 16 die 17 , 18 , 19 sie 20haben  die 21 die 22 uh 23sie24 sie 25 die 26uh27 uh 28 sie 29 haben 30die  die 31 haben  sie  sie 32 .Figure 1: Reordering lattice before adding alternative clean paths for an exemplary sentence0 1 das 2 sie 3 sie 5 das 4sind  das 6 das 7die8 sind 9 sind10 Vorteile11 die 12 die13 ,14 Vorteile 15 Vorteile16 die 19 haben 26 die 17 , 18 ,haben 20 sie  die  die  die 21 die 30 die22 sie 28 die 23 uh  die24 sie  die25 uh  die  die27 uh  diedie29 haben  sie  die31sie  sie  haben 32 .Figure 2: Extended lattice with alternative clean paths for an exemplary sentencedas 0.000732 sie 0.953126sind 0.004445 uh 0.999579die 0.013451 die 0.029010Vorteile 0.008183 sie 0.001426, 0.035408 haben 0.000108die 0.651642 .
0.000033Table 1: Disfluency probability of each wordbility and transition probability.
The extended lat-tice for the given sentence with ?
= 0.5 is shownin Figure 2, with alternative paths marked by adotted line.
The optimal value of ?
was manuallytuned on the development set.4 System DescriptionThe training data for our MT system consists of1.76 million sentences of German-English paral-lel data.
Parallel TED talks1are used as in-domaindata and our translation models are adapted to thedomain.
Before training, we apply preprocess-ing such as text normalization, tokenization, andsmartcasing.
Additionally, German compoundwords are split.To build the phrase table we use the Mosespackage (Koehn et al., 2007).
An LM is trainedon 462 million words in English using the SRILMToolkit (Stolcke, 2002).
In order to extend sourceword context, we use a bilingual LM (Niehues etal., 2011).
We use an in-house decoder (Vogel,2003) with minimum error rate training (Venu-gopal et al., 2005) for optimization.For training and testing the CRF model, we use61k annotated words of manual transcripts of uni-1http://www.ted.comversity lectures in German.
For tuning and testingthe MT system, the same data is used along withits English reference translation.
In order to makethe best use of the data, we split it into three partsand perform three-fold cross validation.
There-fore, the train/development data consists of around40k words, or 2k sentences, while the test dataconsists of around 20k words, or 1k sentences.5 ExperimentsIn order to compare the effect of the tight inte-gration with other disfluency removal strategies,we conduct different experiments on manual tran-scripts as well as on the ASR output.5.1 Manual TranscriptsAs a baseline for manual transcripts, we usethe whole uncleaned data for development andtest.
For ?No uh?, we remove the obvious fillerwords uh and uhm manually.
In the CRF-hardexperiment, the token is removed if the labeloutput of the CRF model is a disfluency class.The fourth experiment uses the tight integrationscheme, where new source paths which jump overthe potentially noisy words are inserted based onthe disfluency probabilities assigned by the CRFmodel.
In the next experiments, this method iscombined with other aforementioned approaches.First, we apply the tight integration scheme afterwe remove all obvious filler words.
In the nextexperiment, we first remove all words whose Pdis higher than 0.9 as early pruning and then applythe tight integration scheme.
In a final experiment,we conduct an oracle experiment, where all wordsannotated as a disfluency are removed.455.2 ASR OutputThe same experiments are applied to the ASR out-put.
Since the ASR output does not contain re-liable punctuation marks, there is a mismatch be-tween the training data of the CRF model, which ismanual transcripts with all punctuation marks, andthe test data.
Thus, we insert punctuation marksand augment sentence boundaries in the ASR out-put using the monolingual translation system (Choet al., 2012).
As the sentence boundaries differfrom the reference translation, we use the Leven-shtein minimum edit distance algorithm (Matusovet al., 2005) to align hypothesis for evaluation.No optimization is conducted, but the scaling fac-tors obtained when using the correponding setupof manual transcripts are used for testing.5.3 ResultsTable 2 shows the results of our experiments.
Thescores are reported in case-sensitive BLEU (Pap-ineni et al., 2002).System Dev Text ASRBaseline 23.45 22.70 14.50No uh 25.09 24.04 15.10CRF-hard 25.32 24.50 15.15Tight int.
25.30 24.59 15.19No uh + Tight int.
25.41 24.68 15.33Pruning + Tight int.
25.38 24.84 15.51Oracle 25.57 24.87 -Table 2: Translation results for the investigateddisfluency removal strategiesCompared to the baseline where all disfluen-cies are kept, the translation quality is improvedby 1.34 BLEU points for manual transcripts bysimply removing all obvious filler words.
Whenwe take the output of the CRF as a hard deci-sion, the performance is further improved by 0.46BLEU points.
When using the tight integrationscheme, we improve the translation quality around0.1 BLEU points compared to the CRF-hard deci-sion.
The performance is further improved by re-moving uh and uhm before applying the tight inte-gration scheme.
Finally the best score is achievedby using the early pruning coupled with the tightintegration scheme.
The translation score is 0.34BLEU points higher than the CRF-hard decision.This score is only 0.03 BLEU points less than theoracle case, without all disfluencies.Experiments on the ASR output also showed aconsiderable improvement despite word errors andconsequently decreased accuracy of the CRF de-tection.
Compared to using only the CRF-hard de-cision, using the coupled approach improved theperformance by 0.36 BLEU points, which is 1.0BLEU point higher than the baseline.System Precision RecallCRF-hard 0.898 0.544Pruning + Tight int.
0.937 0.521Table 3: Detection performance comparisonTable 3 shows a comparison of the disfluencydetection performance on word tokens.
While re-call is slightly worse for the coupled approach,precision is improved by 4% over the hard deci-sion, indicating that the tight integration schemedecides more accurately.
Since deletions made bya hard decision can not be recovered and losing ameaningful word on the source side can be verycritical, we believe that precision is more impor-tant for this task.
Consequently we retain morewords on the source side with the tight integrationscheme, but the numbers of word tokens on thetranslated target side are similar.
The translationmodel is able to leave out unnecessary words dur-ing translation.6 ConclusionWe presented a novel scheme to integrate disflu-ency removal into the MT process.
Using thisscheme, it is possible to consider disfluency prob-abilities during decoding and therefore to choosewords which can lead to better translation perfor-mance.
The disfluency probability of each tokenis obtained from a CRF model, and is encoded inthe word lattice.
Additional edges are added in theword lattice, to bypass the words potentially rep-resenting speech disfluencies.We achieve the best performance using the tightintegration method coupled with early pruning.This method yields an improvement of 2.1 BLEUpoints for manual transcripts and 1.0 BLEU pointimprovement over the baseline for ASR output.Although the translation of ASR output is im-proved using the suggested scheme, there is stillroom to improve.
In future work, we would like toimprove performance of disfluency detection forASR output by including acoustic features in themodel.46AcknowledgementsThe research leading to these results has receivedfunding from the European Union Seventh Frame-work Programme (FP7/2007-2013) under grantagreement n?287658.ReferencesEunah Cho, Jan Niehues, and Alex Waibel.
2012.Segmentation and Punctuation Prediction in SpeechLanguage Translation using a Monolingual Trans-lation System.
In Proceedings of the Interna-tional Workshop for Spoken Language Translation(IWSLT), Hong Kong, China.Eunah Cho, Thanh-Le Ha, and Alex Waibel.
2013.CRF-based Disfluency Detection using Seman-tic Features for German to English Spoken Lan-guage Translation.
In Proceedings of the Interna-tional Workshop for Spoken Language Translation(IWSLT), Heidelberg, Germany.Chris Dyer.
2009.
Using a Maximum Entropy Modelto Build Segmentation Lattices for MT.
In Proceed-ings of Human Language Technologies: The 2009Annual Conference of the North American Chap-ter of the Association for Computational Linguis-tics, Boulder, Colorado, USA, June.
Association forComputational Linguistics.Erin Fitzgerald, Kieth Hall, and Frederick Jelinek.2009.
Reconstructing False Start Errors in Sponta-neous Speech Text.
In Proceedings of the EuropeanAssociation for Computational Linguistics (EACL),Athens, Greece.Teresa Herrmann, Jan Niehues, and Alex Waibel.2013.
Combining Word Reordering Methods ondifferent Linguistic Abstraction Levels for Statisti-cal Machine Translation.
In Proceedings of the Sev-enth Workshop on Syntax, Semantics and Structurein Statistical Translation, Altanta, Georgia, USA,June.
Association for Computational Linguistics.Matthias Honal and Tanja Schultz.
2003.
Correction ofDisfluencies in Spontaneous Speech using a Noisy-Channel Approach.
In Eurospeech, Geneva.Mark Johnson and Eugene Charniak.
2004.
A TAG-based Noisy Channel Model of Speech Repairs.
InProceedings of the Association for ComputationalLinguistics (ACL).Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In Proceedings of the Association for ComputationalLinguistics (ACL), Demonstration Session, Prague,Czech Republic, June.Taku Kudoh.
2007.
CRF++: Yet Another CRFToolkit.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional Random Fields: Prob-abilitic Models for Segmenting and Labeling Se-quence Data.
In ICML, Massachusetts, USA.Sameer Maskey, Bowen Zhou, and Yuqing Gao.
2006.A Phrase-Level Machine Translation Approach forDisfluency Detection using Weighted Finite StateTranducers.
In Interspeech, Pittsburgh, PA.Evgeny Matusov, Gregor Leusch, Oliver Bender, andHerrmann Ney.
2005.
Evaluating Machine Trans-lation Output with Automatic Sentence Segmenta-tion.
In Proceedings of the International Workshopon Spoken Language Translation (IWSLT), Boulder,Colorado, USA, October.Jan Niehues and Muntsin Kolss.
2009.
A POS-BasedModel for Long-Range Reorderings in SMT.
InProceedings of the 4th Workshop on Statistical Ma-chine Translation, Athens, Greece.Jan Niehues, Teresa Herrmann, Stephan Vogel, andAlex Waibel.
2011.
Wider Context by Using Bilin-gual Language Models in Machine Translation.
InProceedings of the 6th Workshop on Statistical Ma-chine Translation, Edinburgh, UK.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a Method for AutomaticEvaluation of Machine Translation.
Technical Re-port RC22176 (W0109-022), IBM Research Divi-sion, T. J. Watson Research Center.Kay Rottmann and Stephan Vogel.
2007.
Word Re-ordering in Statistical Machine Translation with aPOS-Based Distortion Model.
In TMI, Sk?ovde,Sweden.Andreas Stolcke.
2002.
SRILM ?
An Extensible Lan-guage Modeling Toolkit.
Denver, Colorado, USA.Ashish Venugopal, Andreas Zollman, and Alex Waibel.2005.
Training and Evaluation Error MinimizationRules for Statistical Machine Translation.
In WPT-05, Ann Arbor, MI.Stephan Vogel.
2003.
SMT Decoder Dissected: WordReordering.
In Int.
Conf.
on Natural LanguageProcessing and Knowledge Engineering, Beijing,China.Wen Wang, Gokhan Tur, Jing Zheng, and Necip FazilAyan.
2010.
Automatic Disfluency Removal for Im-proving Spoken Language Translation.
In Interna-tional Conference on Acoustics, Speech, and SignalProcessing (ICASSP).47
