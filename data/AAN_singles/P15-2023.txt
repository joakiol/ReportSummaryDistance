Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 139?144,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsDiscriminative Preordering Meets Kendall?s ?
MaximizationSho Hoshino Yusuke MiyaoNational Institute of Informatics / The Graduate University for Advanced Studies, Japan{hoshino,yusuke}@nii.ac.jpKatsuhito Sudoh Katsuhiko Hayashi Masaaki NagataNTT Communication Science Laboratories, NTT Corporation{sudoh.katsuhito,hayashi.katsuhiko,nagata.masaaki}@lab.ntt.co.jpAbstractThis paper explores a simple discrimina-tive preordering model for statistical ma-chine translation.
Our model traversesbinary constituent trees, and classifieswhether children of each node should bereordered.
The model itself is not ex-tremely novel, but herein we introduce anew procedure to determine oracle labelsso as to maximize Kendall?s ?
.
Exper-iments in Japanese-to-English translationrevealed that our simple method is compa-rable with, or superior to, state-of-the-artmethods in translation accuracy.1 IntroductionCurrent statistical machine translation systemssuffer from major accuracy degradation in distantlanguages, primarily because they utilize excep-tionally dissimilar word orders.
One promisingsolution to this problem is preordering, in whichsource sentences are reordered to resemble thetarget language word orders, after which statis-tical machine translation is applied to reorderedsentences (Xia and McCord, 2004; Collins et al,2005).
This is particularly effective for distant lan-guage pairs such as English and Japanese (Isozakiet al, 2010b).Among such preordering, one of the simplestand straightforward model is a discriminative pre-ordering model (Li et al, 2007), which classifieswhether children of each constituent node shouldbe reordered, given binary trees.1This simplemodel has, however, difficulty to find oracle la-bels.
Yang et al (2012) proposed a method to ap-proximate oracle labels along dependency trees.The present paper proposes a new procedure tofind oracle labels.
The main idea is simple: we1It is also possible to use n-ary trees (Li et al, 2007; Yanget al, 2012), but we keep this binary model for simplicity.S=MVP=WNP=MNNclassification4JJbinary3VBZis2NPNNReordering1Figure 1: Discriminative preordering model.determine reordering decisions in a way that max-imizes Kendall?s ?
of word alignments.
We provethat our procedure guarantees the optimal solutionfor word alignments given as an integer list; in away that local decisions on each node reach globalmaximization of Kendall?s ?
in total.
Any reorder-ing methods that utilize word alignments alongconstituency benefit from this proof.Empirical study in Japanese-to-English trans-lation demonstrate that our simple method out-performs a rule-based preordering method, and iscomparable with, or superior to, state-of-the-artmethods that rely on language-specific heuristics.Our contributions are summarized as follows:?
We define a method for obtaining oracle la-bels in discriminative preordering as the max-imization of Kendall?s ?
.?
We give a theoretical background toKendall?s ?
based reordering for binaryconstituent trees.?
We achieve state-of-the-art accuracy inJapanese-to-English translation with a simplemethod without language-specific heuristics.1392 Preordering Method2.1 Discriminative Preordering ModelThe discriminative preordering model (Li et al,2007) is a reordering model that determineswhether children of each node should be re-ordered, given a binary constituent tree.
For a sen-tence with n words, a node in a binary constituenttree is expressed as v(i, p, j), where 1 ?
i ?
p <p + 1 ?
j ?
n. This indicates that the nodetakes the left span from i-th to p-th words and theright span from (p + 1)-th to j-th words.
Thenwe define whether a node should be reordered asP (x | ?
(v(i, p, j))), where x ?
{W,M}.
W rep-resents a reverse action (reorder the child nodes),M represents a monotonic action (do not reorderthe child nodes), and ?
is a feature function that isdescribed at Section 2.4.For instance, Figure 1 shows a sentence (n = 4)that has three binary nodes S, VP, and NP, whichare our reordering candidates.
We examine the NPnode v(3, 3, 4) that has a left (binary3) and a right(classification4) spans, of which reordering isdetermined by P (x | ?
(v(3, 3, 4))), and is clas-sified x = M in this example.
The actions for theVP node v(2, 2, 4) and the S root node v(1, 1, 4)are determined in a similar fashion.Once all classifications are finished, the chil-dren of the nodes with W are reversed.
From theconstituent tree in Figure 1, this reordering pro-duces a new tree in Figure 2 that represents a re-ordered sentence Reordering binary classificationis, which is used in statistical machine translation.2.2 Oracle Labels Maximizing Kendall?s ?In order to train such a classifier, we need an ora-cle label, W or M , for each node.
Since we can-not rely on manual label annotation, we define aprocedure to obtain oracle labels from word align-ments.
The principal idea is that we determine anoracle label of each node v(i, p, j) so that it max-imizes Kendall?s ?
under v(i, p, j).
This is intu-itively a straightforward idea, because our objec-tive is to find a monotonic order, which indicatesmaximization of Kendall?s ?
.In the context of statistical machine translation,Kendall?s ?
is used as an evaluation metric formonotonicity of word orderings (Birch and Os-borne, 2010; Isozaki et al, 2010a; Talbot et al,2011).
Given an integer list x = x1, .
.
.
, xn, ?
(x)S=MVP=WVBZis2NP=MNNclassification4JJbinary3NPNNReordering1Figure 2: Output of discriminative preordering.measures a similarity between x and sorted x as:?
(x) =4c(x)n(n ?
1)?
1,where c(x) is the number of concordant pairs be-tween x and sorted x, which is defined as:c(x) =?i,j?[1,n],i<j?
(xi< xj),where ?
(xi< xj) = 1 if xi< xj, and 0 oth-erwise.
The ?
function expresses that x is com-pletely monotonic when ?
(x) = 1, and in contrast,x is completely reversed when ?
(x) = ?1.
Since?
(x) is proportional to c(x), only c(x) is consid-ered in the course of our maximization.Suppose that word alignments are given in theform a = a1, .
.
.
, an, where ax= y indicates thatthe x-th word in a source sentence corresponds tothe y-th word in a target sentence.2We also as-sume that a binary constituent tree is given, andalignment for the span (i, j) is denoted as a(i, j).For each node v(i, p, j), we define the score as:s(v(i, p, j)) = c(a(i, p) ?
a(p + 1, j))?c(a(p + 1, j) ?
a(i, p)),where ?
indicates a concatenation of vectors.
Then,a node that has s(v(i, p, j)) < 0 is assigned W ,and a node that has s(v(i, p, j)) > 0 is assignedM .
All the nodes scored as s = 0 are excludedfrom the training data, because they are noisy andambiguous in terms of binary classification.2.3 Proof of Independency over ConstituencyThe question then arises: Can oracle labelsachieve the best reordering in total?
We see this2We used median values to approximate this y-th word inthe target sentence for simplicity.140ti:p, tp+1:j, wi:p, wp+1:j, ?
(v(i, p, j)),ti:p?
tp+1:j, wi:p?
wp+1:j, ?r(v(i, p, j)),ti:p?
tp+1:j?
wi:p?
wp+1:j, ?t(v(i, p, j)),tl:p, tp+1:r, wl:p, wp+1:r, ?w(v(i, p, j))tl:p?
tp+1:r, wl:p?
wp+1:r,tl:p?
tp+1:r?
wl:p?
wp+1:rTable 1: Templates for the node v(i, p, j): whereintegers l and r satisfy i ?
l ?
p < p+1 ?
r ?
j.Template Instance Template Instancet2:2VBZ w2:2ist3:4JJ NN w3:4binary classificationt3:3JJ w3:3binaryTemplate Instance?
(v(2, 2, 4)) (VP(VBZis)(NP(JJbinary)(NNclassification)))?r(v(2, 2, 4)) VP VBZ NP JJ NN VP VBZ VP NP NP JJ NP NN?t(v(2, 2, 4)) (VP(VBZ)(NP(JJ)(NN)))?w(v(2, 2, 4)) ((is)((binary)(classification)))Table 2: Examples in v(2, 2, 4) from Figure 1.Proposed Accuracy Previous AccuracyFull 90.91 Li et al (2007) 84.43w/o the first set 87.50w/o ?
(v(i, p, j)) 90.76w/o ?r(v(i, p, j)) 90.85w/o ?t(v(i, p, j)) 90.90w/o ?w(v(i, p, j)) 90.88Table 3: Ablation tests on binary classification ac-curacy (%).is true, because c(a(i, j)) can be computed in a re-cursive manner.
See c(a(i, j)) is decomposed as:c(a(i, j)) = c(a(i, p)) + c(a(p + 1, j))+?k?[i,p],l?[p+1,j]?
(ak< al).The three terms in this formula are mutually inde-pendent.
That is, any reordering of a(i, p) changesonly the first term and the others are unchanged.We maximize c(a(i, j)) by maximizing each term.Since the first and the second terms are maxi-mized recursively, our method directly maximizesthe third term, which corresponds to our oracle la-bels, hence c(a) and ?
(a) of entire sentence.3Essentially, our decisions on each node areequivalent to sorting a list consists of left and rightpoints, while the order of the points inside of leftand right lists are left untouched.
We determine or-acle labels for a given constituent tree by comput-ing s(v(i, p, j)) for every v(i, p, j) independently.3Oracle labels guarantee ?
(a) ?
0, but not ?
(a) = 1,because parsed trees will not correspond to word alignments.test9 test10Settings DL RIBES BLEU RIBES BLEUBaseline w/o preorderingMoses 0 66.95 26.36 67.50 27.17Moses 10 68.95 29.41 69.64 30.20Moses 20 69.88 30.12 70.22 30.51Proposed preorderingGiza 0 77.49 33.08 77.49 33.65Giza 10 77.44 33.28 77.42 33.77Nile 0 77.74 32.97 77.89 33.91Nile 10 77.97 33.55 78.07 34.13Table 4: Results in Japanese-to-English transla-tion.
Boldfaces denote the highest scores and theinsignificant difference (p < 0.01) from the high-est scores in bootstrap resampling (Koehn, 2004).2.4 FeaturesTable 1 shows the templates for the node v(i, p, j)of the feature function ?
in Section 2.1.
To tell thedifferences between the left span a(i, p) and theright span a(p + 1, j), such as whether the headword of the node is in left or right, the first setof templates considers individual indices x:y thatdenote the span from x-th to y-th words: wheretxrepresents a part-of-speech feature; wxrepre-sents a lexical feature; and ?
represents featurecombination.
The second set of templates consid-ers constituent structures of the node by supply-ing three S-expressions and parent-child relations:where ?
(v(i, p, j)) represents a constituent struc-ture under the node v(i, p, j); ?r(v(i, p, j)) rep-resents part-of-speech tags of the node and theirparent-child relations; ?t(v(i, p, j)) represents theconstituent structure including only part-of-speechtags; and ?w(v(i, p, j)) represents the constituentstructure including only surface words.Table 2 shows instances of features for the VPnode v(2, 2, 4) in Figure 1, which has the left (is2)and the right (binary3classification4) spans.Table 3 shows ablation test results on binaryclassification, which indicate that our templatesperformed better than that of Li et al (2007).3 Experiment3.1 Experimental SettingsWe perform experiments over the NTCIR patentcorpus (Goto et al, 2011) that consists of morethan 3 million sentences in English and Japanese.Following conventional literature settings (Goto etal., 2012; Hayashi et al, 2013), we used all 3million sentences from the NTCIR-7 and NTCIR-141test9 test10Reordering Methods DL RIBES ?
BLEU ?
RIBES ?
BLEU ?Moses 20 69.88 30.12 70.22 30.51Proposed preordering 10 77.97 +8.09 33.55 +3.43 78.07 +7.85 34.13 +3.62Moses (Hoshino et al, 2013) 20 68.08 27.57Preordering (Hoshino et al, 2013) 10 72.37 +4.29 30.56 +2.99Moses (Goto et al, 2012) 20 68.28 30.20Moses-chart (Goto et al, 2012) 70.64 +2.36 30.69 +0.49Postordering (Goto et al, 2012) 75.48 +7.20 33.04 +2.84Moses (Hayashi et al, 2013) 20 69.31 29.43 68.90 29.99Postordering (Hayashi et al, 2013) 0 76.46 +7.15 32.59 +3.16 76.76 +7.86 33.14 +3.15Table 5: Comparison with previous systems in Japanese-to-English translation, of which scores areretrieved from their papers.
Boldfaces indicate the highest scores and differences.8 training sets, used the first 1000 sentences inNTCIR-8 development set, and then fetched boththe NTCIR-9 and NTCIR-10 testing sets.
The ma-chine translation experiments pipelined Moses 3(Koehn et al, 2007) with lexicalized reordering,SRILM 1.7.0 (Stolcke et al, 2011) in 6-gram or-der, MGIZA (Gao and Vogel, 2008), and RIBES(Isozaki et al, 2010a) and BLEU (Papineni et al,2002) for evaluation.
Binary constituent parsingin Japanese used Haruniwa (Fang et al, 2014),Berkeley parser 1.7 (Petrov and Klein, 2007), Co-mainu 0.7.0 (Kozawa et al, 2014), MeCab 0.996(Kudo et al, 2004), and Unidic 2.1.2.We explore two types of word alignment datafor training our preordering model.
The firstdata (Giza) is created by running an unsuper-vised aligner Giza (Och and Ney, 2003) on thetraining data (3 million sentences).
The seconddata (Nile) is developed by training a supervisedaligner Nile (Riesa et al, 2011) with manually an-notated 8,000 sentences, then applied the trainedalignment model to remaining training data.
Inthe evaluation on manually annotated 1,000 sen-tences4, Giza achieved F1 50.1 score, while Nileachieved F1 86.9 score, for word alignment task.3.2 ResultTable 4 shows the performance of our method,which indicates that our preordering significantlyimproved translation accuracy in both RIBES andBLEU scores, from the baseline result attainedby Moses without preordering.
In particular, thepreordering model trained with the Giza data re-vealed a substantial improvement, while the useof the Nile data further improves accuracy.
Thissuggests that our method is particularly effectivewhen high-accuracy word alignments are given.
In4This testing data is excluded from latter experiments.addition, we achieved modest improvements evenwith DL=0 (no distortion allowed), which indi-cates the monotonicity of our reordered sentences.Table 5 shows a comparison of the proposedmethod with a rule-based preordering method(Hoshino et al, 2013) and two postordering meth-ods (Goto et al, 2012; Hayashi et al, 2013).5Onecomplication is that each work reports differentbaseline accuracy, although Moses is shared as abaseline, because these systems differ in varioussettings in data preprocessing, tokenization crite-ria, etc.
Since this makes a fair comparison diffi-cult, we additionally put a score difference (?)
ofeach system from its own baseline.Our proposed method showed translation ac-curacy comparable with, or superior to, state-of-the-art methods.
This highlights the importanceof Kendall?s ?
maximization in the simple dis-criminative preordering model.
In contrast to asubstantial gain in RIBES, we attained a rathercomparable gain in BLEU.
The investigation ofour translation suggests that insufficient genera-tion of English articles caused a significant degra-dation in the BLEU score.
Previous systems listedin Table 5 incorporated article generation anddemonstrated its positive effect (Goto et al, 2012;Hayashi et al, 2013).
While we achieved state-of-the-art accuracy without language-specific tech-niques, it is also a promising direction to integrateour preordering method with language-specifictechniques such as article generation and subjectgeneration (Kudo et al, 2014).5We could not find a comparable report using tree-basedmachine translation systems apart from Moses-chart; never-theless, Neubig and Duh (2014) reported that their forest-to-string system on the same corpus, which is unfortunatelyevaluated on the different testing data (test7), showed RIBES+6.19 (75.94) and BLEU +2.93 (33.70) improvements.
Al-though not directly comparable, our method achieves a com-parable or superior improvement.1424 Related WorkLi et al (2007) proposed a simple discriminativepreordering model as described in Section 2.1.They employed heuristics that utilize Giza to aligntheir training sentences, then sort source words toresemble target word indices.
After that, sortedsource sentences without overlaps are used to trainthe model.
They gained BLEU +1.54 improve-ment in Chinese-to-English evaluation.
Our pro-posal follows their model, while we do not rely ontheir heuristics for preparing training data.Lerner and Petrov (2013) proposed anotherdiscriminative preordering model along depen-dency trees, which classifies whether the parentof each node should be the head in target lan-guage.
They reported BLEU +3.7 improvementin English-to-Japanese translation.
Hoshino et al(2013) proposed a similar but rule-based methodfor Japanese-to-English dependency preordering.Yang et al (2012) proposed a method to pro-duce oracle reordering in the discriminative pre-ordering model along dependency trees.
Theiridea behind is to minimize word alignment cross-ing recursively, which is essentially the same re-ordering objective as our Kendall?s ?
maximiza-tion.
Since they targeted complex n-ary depen-dency instead of simple binary trees, their methodonly calculates approximated oracle reordering inpractice by ranking principle.
We did not taken-ary trees into consideration to follow the sim-ple discriminative preordering model along con-stituency, while the use of binary trees enabled usto produce strict oracle reordering as a side effect.Another research direction called postordering(Sudoh et al, 2011; Goto et al, 2012; Hayashiet al, 2013) has been explored in Japanese-to-English translation.
They first translate Japaneseinput into head final English texts obtained by themethod of Isozaki et al (2010b), then reorder headfinal English texts into English word orders.5 ConclusionWe proposed a simple procedure to train a discrim-inative preordering model.
The main idea is toobtain oracle labels for each node by maximizingKendall?s ?
of word alignments.
Experiments inJapanese-to-English translation demonstrated thatour procedure, without language-specific heuris-tics, achieved state-of-the-art translation accuracy.AcknowledgmentsWe would like to thank Kevin Duh, Atsushi Fujita,Taku Kudo, Shinsuke Mori, Toshiaki Nakazawa,Graham Neubig, Hiroshi Noji, and anonymous re-viewers for their insightful comments.ReferencesAlexandra Birch and Miles Osborne.
2010.
LRscorefor evaluating lexical and reordering quality in MT.In Proceedings of the Joint Fifth Workshop on Statis-tical Machine Translation and MetricsMATR, pages327?332.Michael Collins, Philipp Koehn, and Ivona Kucerova.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd AnnualMeeting of the Association for Computational Lin-guistics, pages 531?540.Tsaiwei Fang, Alastair Butler, and Kei Yoshimoto.2014.
Parsing Japanese with a PCFG treebankgrammar.
In Proceedings of the Twentieth Meetingof the Association for Natural Language Processing,pages 432?435.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, pages 49?57.Isao Goto, Bin Lu, Ka Po Chow, Eiichiro Sumita, andBenjamin K. Tsou.
2011.
Overview of the patentmachine translation task at the NTCIR-9 workshop.In Proceedings of the NTCIR-9 Workshop Meeting,pages 559?578.Isao Goto, Masao Utiyama, and Eiichiro Sumita.
2012.Post-ordering by parsing for Japanese-English sta-tistical machine translation.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics, pages 311?316.Katsuhiko Hayashi, Katsuhito Sudoh, Hajime Tsukada,Jun Suzuki, and Masaaki Nagata.
2013.
Shift-reduce word reordering for machine translation.
InProceedings of the 2013 Conference on EmpiricalMethods in Natural Language Processing, pages1382?1386.Sho Hoshino, Yusuke Miyao, Katsuhito Sudoh, andMasaaki Nagata.
2013.
Two-stage pre-orderingfor Japanese-to-English statistical machine transla-tion.
In Proceedings of the Sixth International JointConference on Natural Language Processing, pages1062?1066.Hideki Isozaki, Tsutomu Hirao, Kevin Duh, KatsuhitoSudoh, and Hajime Tsukada.
2010a.
Automaticevaluation of translation quality for distant languagepairs.
In Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Process-ing, pages 944?952.143Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, andKevin Duh.
2010b.
Head finalization: A simplereordering rule for SOV languages.
In Proceedingsof the Joint Fifth Workshop on Statistical MachineTranslation and MetricsMATR, pages 244?251.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics, pages 177?180.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Proceedings ofthe 2004 Conference on Empirical Methods in Nat-ural Language Processing, pages 388?395.Shunsuke Kozawa, Kiyotaka Uchimoto, and YasuharuDen.
2014.
Adaptation of long-unit-word anal-ysis system to different part-of-speech tagset (inJapanese).
Journal of Natural Language Process-ing, 21(2):379?401.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying conditional random fields tojapanese morphological analysis.
In Proceedings ofthe 2004 Conference on Empirical Methods in Nat-ural Language Processing, pages 230?237.Taku Kudo, Hiroshi Ichikawa, and Hideto Kazawa.2014.
A joint inference of deep case analysis andzero subject generation for Japanese-to-English sta-tistical machine translation.
In Proceedings of the52nd Annual Meeting of the Association for Compu-tational Linguistics, pages 557?562.Uri Lerner and Slav Petrov.
2013.
Source-side classi-fier preordering for machine translation.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing, pages 513?523.Chi-Ho Li, Minghui Li, Dongdong Zhang, Mu Li,Ming Zhou, and Yi Guan.
2007.
A probabilisticapproach to syntax-based reordering for statisticalmachine translation.
In Proceedings of the 45th An-nual Meeting of the Association of ComputationalLinguistics, pages 720?727.Graham Neubig and Kevin Duh.
2014.
On the ele-ments of an accurate tree-to-string machine trans-lation system.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Lin-guistics, pages 143?149.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof 40th Annual Meeting of the Association for Com-putational Linguistics, pages 311?318.Slav Petrov and Dan Klein.
2007.
Improved infer-ence for unlexicalized parsing.
In Human LanguageTechnologies 2007: The Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics; Proceedings of the Main Confer-ence, pages 404?411.Jason Riesa, Ann Irvine, and Daniel Marcu.
2011.Feature-rich language-independent syntax-basedalignment for statistical machine translation.
InProceedings of the 2011 Conference on EmpiricalMethods in Natural Language Processing, pages497?507.Andreas Stolcke, Jing Zheng, Wen Wang, and VictorAbrash.
2011.
SRILM at sixteen: Update and out-look.
In Proceedings of the IEEE Automatic SpeechRecognition and Understanding Workshop.Katsuhito Sudoh, Xianchao Wu, Kevin Duh, HajimeTsukada, and Masaaki Nagata.
2011.
Post-orderingin statistical machine translation.
In Proceedings ofthe Machine Translation Summit XIII, pages 316?323.David Talbot, Hideto Kazawa, Hiroshi Ichikawa, Ja-son Katz-Brown, Masakazu Seno, and Franz Och.2011.
A lightweight evaluation framework for ma-chine translation reordering.
In Proceedings of theSixth Workshop on Statistical Machine Translation,pages 12?21.Fei Xia and Michael McCord.
2004.
Improvinga statistical MT system with automatically learnedrewrite patterns.
In Proceedings of the 20th Inter-national Conference on Computational Linguistics,pages 508?514.Nan Yang, Mu Li, Dongdong Zhang, and Nenghai Yu.2012.
A ranking-based approach to word reorderingfor statistical machine translation.
In Proceedingsof the 50th Annual Meeting of the Association forComputational Linguistics, pages 912?920.144
