Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 197?205,Beijing, August 2010Unsupervised Synthesis of Multilingual Wikipedia ArticlesChen YuncongThe Human Language Technology CenterThe Hong Kong University of Science andTechnologyee_cyxab@stu.ust.hkPascale FungThe Human Language Technology CenterThe Hong Kong University of Science andTechnologypascale@ee.ust.hkAbstractIn this paper, we propose anunsupervised approach to automaticallysynthesize Wikipedia articles inmultiple languages.
Taking an existinghigh-quality version of any entry ascontent guideline, we extract keywordsfrom it and use the translated keywordsto query the monolingual web of thetarget language.
Candidate excerpts orsentences are selected based on aniterative ranking function andeventually synthesized into a completearticle that resembles the referenceversion closely.
16 English and Chinesearticles across 5 domains are evaluatedto show that our algorithm is domain-independent.
Both subjectiveevaluations by native Chinese readersand ROUGE-L scores computed withrespect to standard reference articlesdemonstrate that synthesized articlesoutperform existing Chinese versions orMT texts in both content richness andreadability.
In practice our method cangenerate prototype texts for Wikipediathat facilitate later human authoring.1 IntroductionWikipedia has over 260 versions in differentlanguages, but the great disparity in their scopeand quality is hindering the effective spread ofknowledge.
The English version is currently thedominant one with over 3 million articles whilethe Chinese version, for example, has only onetenth the amount.
Most Chinese articles sufferfrom content incoherence and lack of detailscompared to their English counterparts.
Someof these articles are human-authored translationof the English version with varying degrees ofaccuracy and completeness, and others are ill-arranged combinations of excerpts directlyadapted from external sources.
The formertakes considerable human effort and the lattertends to produce fragmented and incompletetexts.
The intuitive solution of machinetranslation is also not feasible because it hardlyprovides satisfactory readability.These problems call for a synthesis approach.In order to present the information conveyed byan English article in Chinese, instead ofliterally translate it, we build a topic-templateexpressed by the keywords extracted from theEnglish article.
Machine-translation of thesekeywords helps to yield the topic-template inChinese.
Using the topic-template in Chinese,we form a pool of candidate excerpts byretrieving Chinese documents from the Internet.These online documents are usually human-authored and have optimal readability andcoherence.
Candidate excerpts are further splitinto segments as synthesis unit.
For segmentselection, we propose an iterative rankingfunction that aims to maximize textualsimilarity, keywords coverage, and contentcoherence, while penalizes informationredundancy.A feature of our approach is the use of bi-lingual resources throughout the synthesisprocess.
We calculate similarity scores of twotexts based on both English and Chineseversions of them, which forms a more precisemeasure than using either version alone.For the sake of clarity, we will use English andChinese as examples of source and targetlanguage respectively when describing themethodology.
Nonetheless, our approach is notconstrained to any specific language pair andsupports both direction of synthesis.1972 Related WorkMuch work has been done to explore themultilingualism of Wikipedia.
(Adafre et al2006) investigated two approaches to identifysimilarity between articles in differentlanguages for automatic generation of parallelcorpus, including a machine-translation basedapproach and one using a bilingual lexiconderived from the hyperlink structure underlyingWikipedia articles.
Both methods rely on pair-wise comparisons made at the sentential level,which hardly account for similarity orcoherence in the paragraph scope.
Besides it isnot a generative algorithm and thusinapplicable to our problem where comparablesentences in Chinese are simply not available.A generative approach was proposed by(Sauper and Barzilay, 2009) to create highly-structured Wikipedia articles (e.g.
descriptionsof diseases) composed of information drawnfrom the Internet.
It uses an automatically-induced domain-specific template, and theperceptron algorithm augmented with a globalinteger linear programming (ILP) formulationto optimize both local fit of information intoeach section and global coherence across theentire article.
This method works only forspecific domains where articles have obviouslyseparable sections (e.g.
Causes and Symptoms)and it requires a training corpus for eachdomain to induce the template.
Moreover, thesynthesis units they use are complete excerptsrather than individual sentences as in ourapproach.
Their choice is based on theassumption that texts on the Internet appear incomplete paragraphs, with structure strictlyadhere to the fixed training templates, whichmay be true for specific domains they test on,but fails to hold for domain-independentapplication.
Instead, our algorithm aims tosynthesize the article in the sentential level.
Weselect sentences to fit the source content at runtime, regardless to whether a pre-determinedstructural template exists or not.
Therefore therequirement on the structures of source articlesbecomes very flexible, enabling our system towork for arbitrary domain.
In a sense, ratherthan being a structure-aware approach, ouralgorithm performs in a content-aware manner.This also makes maintaining coherencethroughout article a lot more challenging.Works on monolingual extractive textsummarization also lend insights into ourproblem.
(Goldstein et al, 2000) usedsequential sentence selection based on MaximalMarginal Relevance Multi-Document (MMR-MD) score to form summarizations for multipledocuments, with the constraint of sentencecount.
Since our problem does not have thisconstraint, we employ a variant of MMR-MDand introduced new terms specific to this task.
(Takamura and Okumura, 2009) formulated atext summarization task as a maximumcoverage problem with knapsack constraint andproposed a variety of combinatorialmathematics-based algorithms for solving theoptimization problem.For multi-lingual summarization, (Evans, 2005)applied the concept of multi-lingual textsimilarity to summarization and improvedreadability of English summaries of Arabic textby replacing machine translated Arabicsentences with highly similar English sentenceswhenever possible.3 MethodologyFigure 1 describes the high-level algorithm ofour approach.
The system takes as input theEnglish Wikipedia page and outputs an articlein Chinese.First, the structured English article is extractedfrom the Wikipedia page.
Due to the relativeindependence of contents in different sectionsin typical Wikipedia articles (e.g.
childhood,early writings), a separate synthesis task isperformed on each section and all synthesizedsections are eventually combined in the originalorder to form the Chinese article.For each section, keywords are extracted fromthe English text using both tf-idf and the graph-based TextRank algorithm.
Named entities,time indicators, and terms with Wikipediahyperlinks are also included.
These keywordsexpress the topics of the current section and areregarded as the content guideline.
We then useGoogle Translate and Google Dictionary to198obtain the Chinese translations of thesekeywords and thereby convert the contentguideline into Chinese.
The Chinese keywordsare then combined with the translated subjectterm and section title to form queries that areused to retrieve online Chinese documents byGoogle search.
The returned Chinesedocuments are clustered and filtered based onboth their format and content.
The remainingcandidate excerpts are further split using theTextTiling algorithm (Hearst, 1997) intosegments that constitutes the text units forsynthesis.
This unit size ensures both semanticcompleteness within each unit and flexibility ofcombining multiple units into coherentparagraphs.
Segments are chosen according toscores computed iteratively by a variant of theMMR-MD scoring function that considers notonly the relevance of an individual segment tothe source section but also its impact on theprovisional synthesized section as a whole.3.1 Wikipedia Page PreprocessingThe source Wikipedia page is parsed to removenon-textual page elements (e.g.
images, info-boxes and side-bars).
Only texts and headingsare extracted and their structures are maintainedas templates for final integration of synthesizedsections.3.2 Keyword ExtractionThe keyword set K for a section is the union of6 categories of content-bearing terms.?
: set of terms with high tf-idf score (top 5%): set of terms with high TextRank score (top5%): set of named entities: set of temporal indicators (e.g.
June, 1860): set of terms with Wikipedia links: section titleFor   , tf-idf scores are computed by:?
()where     is the term frequency of term i in thesection and     is the document frequency ofterm i in a corpus consists of 2725 high-qualityEnglish Wikipedia articles 1 , which wellrepresent the language style of Wikipedia.For   , we compute TextRank scoresaccording to (Mihalcea and Tarau, 2004).
It is agraph-based model where words as verticesrecursively vote for the weights of their linkedneighbors (e.g.
words appear in the samesentence as them) using the formula:(  )(   )    ??
(  )(  )   (  )1http://evanjones.ca/software/wikipedia2text.htmlInput:English version of an entryOutput:Synthesized Chinese versionAlgorithm:1: Parse the English Wikipedia page to extract the structured texts.2: For each section:2.1: Extract keywords.2.2: Use Chinese translation of keywords to search online Chinese texts.2.3: Filter retrieved Chinese texts and split them into segments.2.4: Synthesize the current section using candidate segments.3: Generate the Chinese Wikipedia page by combining synthesized sections accordingto the original structure of English version.Figure 1.
High-level algorithm of the synthesis approach199Where   (  ) is the set of vertices with forwardlinks to i,    (  )  is the set of verticesreceiving links from i,     is the weight of edgebetween    and   .
In the case of a word graph,we simplify this formula by assuming the graphto be undirected and unweighted.
Each pair ofwords occurring in the same sentence share anedge between them and all word vertices haveinitial weights of 1.Unlike tf-idf which considers only word-specific values and tends to give higher weightsfor rare words, TextRank uses globalinformation about how a word is used in itscontext to induce its importance and has theadvantage of highlighting keywords that arerelatively common but highly relevant.
In thissense, these two measures complement eachother.
Named entities are recognized using thenamed entity chunker provided by the NLTK(Natural Language ToolKit) package2.3.3 Keyword TranslationKeywords are then translated using GoogleDictionary to form Chinese queries.
Usuallyone English keyword has several translationsand they will be used jointly when forming thesearch query.Google Dictionary often fails to generatecorrect transliteration for rare names, so weaugment it with a function of parenthesizedphrase translation.
We basically seeks named-entity strings from online documents that are inthe format of ?CHINESE (ENGLISH)?
andextracts the Chinese transliteration from thepattern using regular expression combined witha Pinyin (Chinese Romanization) 3 /Englishpronunciation lookup table.
Since Chinesewords are not spaced in documents, thePinyin/English lookup is helpful to determinethe boundary of the Chinese transliterationbased on the fact that most Chinesetransliterations start with characters pronouncedsimilar to the initial syllables in correspondingEnglish names.
This function is relativelysimple but works surprisingly well as many2 The package is available at http://www.nltk.org3 Pinyin information is obtained from Unicode HanDatabase at http://www.unicode.org/reports/tr38/rare named entities are available in this patternon the Web.3.4 Web SearchKeywords in Chinese alternatively form querypairs with the Wikipedia subject term.
Eachpair is used to retrieve a set of (16 in ourexperiments) Chinese documents containingboth words with Google Search.
If a keywordhas multiple translations, they are joined by thestring ?OR?
in the query which is the way tospecify alternatives in Google logic.
If akeyword is a named entity, its English versionis also used as an alternative in order to acquiredocuments in which the subject is referred to byits English name instead of transliterations.
Forthe subject ?Chekhov/???
?, a keyword withtwo transliterations ?Taganrog/????/???
?
?
and another keyword with twotransliterations ?father/??/???
will resultin two query pairs: ?Chekhov OR ??
?Taganrog OR ????
OR ?????
and?Chekhov OR ???
??
OR ??
?.3.5 Candidate FilteringThe retrieved excerpts are filtered first bycriteria on format include text length and thepercentage of white-space and non-Chinesecharacters.
Pair-wise similarity is thencomputed among all the remaining excerpts andthose above a certain threshold are clustered.Within a cluster only the centroid excerpt withmaximum similarity with the source sectionwill be selected.
This stage typically eliminates?
of the documents that are either notsufficiently relevant or redundant.
Thesimilarity measure we use is a combination ofboth English and Chinese versions of cosinesimilarity and Jaccard index.
(   )           (   )           (   )(   )           (   )For Chinese excerpts, English similarity iscomputed by first translating them into Englishby Google Translate and taking tf-idf as tokenweights.
Similar procedure works forcomputing Chinese similarity for Englishexcerpts, except that Chinese texts need to be200segmented4  first and weights are based on tfonly.
These machine translations do not requiregrammatical correctness since they areessentially used as bags of words in both cosinesimilarity and Jaccard index.
During this stage,every excerpt acquires bi-lingual versions,which is important for the extended similaritymeasure in the iterative ranking function.Filtered excerpts are further split into segmentsusing the TextTiling algorithm.
After clusteringthe remaining segments form the candidateunits for synthesis of the current section.3.6 Iterative Scoring FunctionBased on the idea that the ?goodness?
of asegment should be evaluated both on itsindividual relevance to the source and theoverall impact on the synthesized section, wesummarize four factors for scoring a segment:(1) Intuitively a segment scores higher if it hashigher similarity to the source section; (2) Asegment makes positive contribution tosynthesized section if it introduces somekeywords mentioned in the source; (3) Asegment tends to improve the coherence ofsynthesized section if it comes from the sameexcerpts as the other segments in synthesizedsection; (4) A sentence should be penalized ifits content is redundant with the synthesizedsection.Integrating the four factors above, we proposethat for source text r, the score of the ithcandidate segment si in the nth iteration isformulated as:(  )       (  )        (  )(  )       (  )This formula is composed of 4 termscorresponding to the ?goodness?
factors:   (  )for similarity,    (  )  for keyword coverage,(  )  for coherence, and    (  )  forredundancy.
The corresponding weights aretuned in a large number of experiments as to4 The segmentation tool using forward maximummatching is obtained athttp://technology.chtsai.org/mmsegachieve optimal performance.
This function is avariant of the original MMR-MD score tailoredfor our application.
(  ) is a comprehensive similarity measure ofsegment si to the reference text r.(  )        (    )        (    )(    )        (    )where p is the parent section of r and    is theparent excerpt of   .
Similarities between parentexcerpts are also examined because sometimestwo segments, especially short segments,despite their textual similarity actually comefrom very different contexts and exhibitdifferent focuses.
In this case, the latter threeterms will suppress the score between these twosegments which would otherwise beerroneously high and therefore produce a moreprecise measure of similarity.
(  )  measures the contribution of    interms of uncovered keywords.
(  )  ?
( )?where    is the winner set in the nth iteration.is the set of keywords in the reference textand    is the set of keywords in the selectedsegment   .
represents the set of keywordsin the reference that are not yet been coveredby the provisional synthesized text in the nthiteration.
(  )  quantifies the keywordcontribution as the sum of idf values ofuncovered keywords.
The subject term isexcluded because it as a keyword does notreflect any topic bias and is therefore not agood indicator for coverage.
(  ) is a term that reflects the coherence andreadability in the synthesized text.
(  )  |{  |           }|201Input:Sn: candidate set in iteration nr: the reference textDefine:n: iteration indexDn: winner set in iteration nCsel-segment:            (    )Csel-sentence:            (    )(    )(    )Cbreak:                (    )Algorithm:,while     :(  )if Cbreak:returnelse if Csel-segment:else if Csel-sentence:Output:Synthesized text for the reference rwhere    is the parent excerpt of    and    is theparent excerpt of   .
Segments from the sameexcerpts tend to be less redundant and morecoherent.
Therefore candidates that share thesame parent excerpts as segments in winner setare more favorable and rewarded by this term.This is a major difference from the originalMMR-MD function in which sentences fromdifferent documents are favored.
This isbecause their formula is targeted for automaticsummarization where more emphasis is put ondiversity rather than coherence.
(  )  measures the redundancy of thesynthesized text if    is included.
It is quantifiedas the maximum similarity of    with allselected segments.
(  )(     )3.7 Segment Selection AlgorithmFigure 2 describes the segment selectionalgorithm.
Starting with a candidate set and anempty winner set, we iteratively rank thecandidates by Q and in each iteration the top-ranked segment is examined.
There are twocircumstances a segment would be selected forthe winner set:(1) if the segment scores sufficiently high(2) the segment does not score high enough foran unconditional selection, but as long as itintroduces uncovered keywords,  itscontribution to the overall content qualitymay still overweigh the compromisedsimilarityIn the second circumstance however, since weare only interested in the uncovered keywords,it may not be necessary for the entire segmentto be included in the synthesized text.
Instead,we only include the sentences in this segmentthat contain those keywords.
Therefore wepropose two conditions:?
Csel-segment: condition for selecting a segment(    )?
Csel-sentence: condition for selecting sentences(     )                   (     )(    )Thresholds in both conditions are not static butdependent on the highest score of all candidatesin order to accommodate diversity in scorerange for different texts.
Finally if no morecandidates are able to meet the lowered scorethreshold, even if they might carry newkeywords, we assume they are not suitable forsynthesis and return the current winner set.
Thisbreak condition is formulated as Cbreak:?
Cbreak: condition to finish selection(    )4 Evaluation4.1 Experiment SetupWe evaluate our system on 16 Wikipediasubjects across 5 different domains as listed inTable 1.Figure 2.
Segment selection algorithm202The subjects are selected from ?the List ofArticles Every Wikipedia Should Have?
5published by Wikimedia.
These subjects areespecially appropriate for our evaluationbecause we can (1) use a subset of such articlesthat have high quality in both English andChinese as standard reference for evaluation; (2)safely assume Chinese information about thesesubjects is widely available on the Internet; (3)take subjects currently without satisfactoryversions in Chinese as our challenge.Human EvaluationWe presented the synthesized articles of thesesubjects to 5 native Chinese readers whocompare synthesized articles with MT resultsand existing Chinese versions on Wikipediawhich range from translated stubs to human-authored segments.
We asked the reviewers toscore them on a 5-point scale in terms of fourquality indicators: structural similarity to theEnglish version, keyword coverage, fluency,and conciseness.Automatic EvaluationIn addition to human evaluation, we alsocompare synthesized articles to several high-quality Chinese Wikipedia articles usingROUGE-L (C.Y.
Lin, 2004).
We assume these5http://meta.wikimedia.org/wiki/List_of_articles_every_Wikipedia_should_have/Version_1.2Chinese versions are the goals for our synthesissystem and greater resemblance with thesestandard references indicates better synthesis.ROUGE-L measures the longest commonsubsequence (LCS) similarity between twodocuments, rather than simply word overlap soit to some degree reflects fluency.4.2 Result AnalysisHuman EvaluationHuman evaluator feedbacks for articles indifferent categories are shown in Table 2.Machine-translated versions are judged to havethe highest score for structural similarity, buterroneous grammar and word choices maketheir readability so poor even within sentencesand therefore of no practical use.Generally, articles synthesized by our systemoutperform most existing Chinese versions interms of both structural and content similarity.Many existing Chinese versions completelyignore important sections that appear in Englishversions, while our system tries to offerinformation with as much fidelity to theEnglish version as possible and is usually ableto produce information for every section.Synthesized articles however, tend to be lessfluent and more redundant than human-authored versions.Performance varies in different domains.Synthesis works better for subjects in Personcategory, because the biographical structureprovides a specific and fairly unrelated contentin each section, making the synthesis lessredundancy-prone.
On the other hand, there isarbitrariness when organizing articles in Eventand Culture category.
This makes it difficult tofind online text organized in the same way asthe English Wikipedia version, thereforeintroducing a greater challenge in sentenceselection for each section.
Articles in theScience category usually include rareterminologies, and formatted texts likediagrams and formula, which impede correcttranslation and successful extraction ofkeywords.Category SubjectsPerson Anton ChekhovAbu NuwasJoseph HaydnLi BaiOrganization HKUSTIMFWTOEvents Woodstock FestivalInvasion of NormandyDecembrist RevoltScience El NinoGamma RayStingrayCulture Ceramic ArtSpidermanTerrorismTable 1.
Subjects used for evaluation203Automatic EvaluationUsing ROUGE-L to measure the quality ofboth synthesized and MT articles againsthuman-authored standard references, we findsynthesized articles generally score higher thanMT versions.
The results are shown in Table 3.The synthesized articles, extracted from highquality human-authored monolingual texts, aregenerally better in precision than the MTarticles because there is less erroneous wordchoice or grammatical mistakes.
Mostsynthesized articles also have higher recall thanMT versions because usually a substantialportion of the high-quality Chinese excerpts,after being retrieved by search engine, will bejudged by our system as good candidate textsand included into the synthesized article.
Thisnaturally increases the resemblance ofsynthesized articles to standard references, andthus the F-scores.
Note that since our method isunsupervised, the inclusion of the standardChinese articles underscores the precision andrecall of our method.5 ConclusionIn this paper, we proposed an unsupervisedapproach of synthesizing Wikipedia articles inmultiple languages based on an existing high-quality version of any entry.
By extractingkeywords from the source article and retrievingrelevant texts from the monolingual Web in atarget language, we generate new articles usingan iterative scoring function.Synthesis results for several subjects acrossvarious domains confirmed that our method isable to produce satisfactory articles with highresemblance to the source English article.
Formany of the testing subjects that are in ?stub?status, our synthesized articles can act as eitherreplacement or supplement to existing Chineseversions.
For other relatively well-written ones,our system can help provide content prototypesfor missing sections and missing topics,bootstrapping later human editing.A weakness of our system is the insufficientcontrol over coherence and fluency inparagraph synthesis within each section, newmethods are being developed to determine theproper order of chosen segments and optimizethe readability.We are working to extend our work to a systemthat supports conversion between majorlanguages such as German, French and Spanish.The employment of mostly statistical methodsin our approach facilitates the extension.
Wehave also released a downloadable desktopapplication and a web application based on thissystem to assist Wikipedia users.Cat.
Structural Similarity Coverage Fluency ConcisenessSynt.
Orig.
MT Synt.
Orig.
MT Synt.
Orig.
MT Synt.
Orig.
MTPsn.
2.85 1.49 5 2.94 1.84 4.51 2.71 4.58 0.83 1.74 4.47 n/aOrg.
1.96 1.22 5 2.51 2.10 4.46 2.10 4.42 1.06 0.99 4.53 n/aEvt.
1.37 1.13 5 2.56 1.94 4.40 2.45 4.46 0.81 0.80 4.40 n/aSci.
2.43 1.30 5 2.68 2.14 4.42 2.53 4.51 1.02 1.05 4.50 n/aCul.
1.39 1.35 5 2.2 2.21 4.54 2.32 4.54 0.94 1.34 4.59 n/aAvg.
2.02 1.30 5 2.58 2.05 4.47 2.42 4.50 0.93 1.22 4.50 n/aTable 2.
Result of human evaluation against English source articles (out of 5 points; Synt:synthesized articles; Orig: the existing human-authored Chinese Wikipedia versions; MT: Chineseversions generated by Google Translate)Category Recall Precision F-scoreSynt.
MT Synt.
MT Synt.
MTPsn.
0.48 0.30 0.20 0.16 0.28 0.22Org.
0.40 0.29 0.16 0.13 0.23 0.18Evt.
0.36 0.26 0.13 0.15 0.19 0.19Sci.
0.31 0.22 0.14 0.11 0.19 0.15Cul.
0.37 0.27 0.13 0.12 0.24 0.17Avg.
0.38 0.27 0.15 0.13 0.23 0.18Table 3.
Results of automatic evaluationagainst gold Chinese reference articles (Synt:synthesized articles; MT: Chinese versionsgenerated by Google Translate)204ReferenceAdafre, Sisay F. and Maarten de Rijke, ?FindingSimilar Sentences across Multiple Languages inWikipedia?, Proceedings of the EACL Workshop onNew Text, Trento, Italy, 2006Bird, Steven, E. Klein, and E. Loper, NaturalLanguage Processing with Python --- AnalyzingText with the Natural Language Toolkit, O'ReillyMedia, 2009Evans, David K., ?Identifying Similarity in Text:Multi-Lingual Analysis for Summarization?, PhDthesis, Columbia University, 2005.Goldstein, Jade, Vibhu Mittal, Jaime Carbonell andMark Kantrowitz, ?Multi-document summarizationby sentence extraction?, NAACL-ANLP 2000Workshop on Automatic summarization, pages 40-48, 2000Hearst, Marti A., ?TextTiling: Segmenting Text intoMulti-paragraph Subtopic Passages?, ComputationalLinguistics, Volume 23, Issue 1, pp.
33-64, 1997Lin, Chin-Yew, ?ROUGE: A Package forAutomatic Evaluation of Summaries?, Proceedingsof Workshop on Text Summarization Branches Out,Post-Conference Workshop of ACL 2004, Barcelona,Spain.Mihalcea, Rada and Paul Tarau, ?TextRank:Bringing order into texts?, Proceedings of EMNLP,pages 404?411 Barcelona, Spain, 2004Sauper, Christina and Regina Barzilay,?Automatically Generating Wikipedia Articles: aStructure-Aware Approach?, Proceedings of the47th Annual Meeting of the ACL and the 4thIJCNLP of the AFNLP, pages 208?216, Suntec,Singapore, 2-7 August 2009.Takamura, Hiroya and Manabu Okumura, ?TextSummarization Model based on MaximumCoverage Problem and its Variant?, Proceedings ofthe 12th Conference of the European Chapter of theAssociation for Computational Linguistics, pages781-789, 2009205
