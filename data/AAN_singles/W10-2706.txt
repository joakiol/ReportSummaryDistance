Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 31?36,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsAn Embodied Dialogue System with Personality and EmotionsStasinos KonstantopoulosNCSR ?Demokritos?, Athens, Greecekonstant@iit.demokritos.grAbstractAn enduring challenge in human-computer interaction (HCI) research is thecreation of natural and intuitive interfaces.Besides the obvious requirement that suchinterfaces communicate over modalitiessuch as natural language (especially spo-ken) and gesturing that are more naturalfor humans, exhibiting affect and adaptiv-ity have also been identified as importantfactors to the interface?s acceptance by theuser.
In the work presented here, we pro-pose a novel architecture for affective andmultimodal dialogue systems that allowsexplicit control over the personality traitsthat we want the system to exhibit.
Morespecifically, we approach personality asa means of synthesising different, andpossibly conflicting, adaptivity modelsinto an overall model to be used to drivethe interaction components of the system.Furthermore, this synthesis is performedin the presence of domain knowledge,so that domain structure and relationsinfluence the results of the calculation.1 IntroductionAn enduring challenge in human-computer inter-action (HCI) research is the creation of naturaland intuitive interfaces.
Besides the obvious re-quirement that such interfaces communicate overmodalities such as natural language (especiallyspoken) and gesturing that are more natural forhumans, exhibiting affect and adaptivity have alsobeen identified as important factors to the inter-face?s acceptance by the user.We perceive HCI systems as ensembles of inter-action modules, each controlling a different inter-action modality, and able to modulate their opera-tion depending on external (to the modules them-selves) parameters.
A central cognitive moduledeliberates about dialogue acts and orchestratesthe interaction modules in order to ensure thatsuch dialogue acts are carried out in a coherentway, keeping uttered content and affect consistentwithin and across interaction modules.In this paper we describe work towards this end,carried out in the context of the INDIGO project,and implemented in the form of a personality mod-ule that complements INDIGO?s dialogue man-ager by calculating parameters related to adap-tivity and emotion to be used by the interactionmodules in the process of concretely realizing theabstract dialogue-action directives issued by thedialogue manager.
This calculation involves theplanned act, the user adaptivity model, the sys-tem?s own goals, but also a machine representa-tion of the personality that we want the system toexhibit, so that systems with different personalitywill react differently even when in the same dia-logue state and with the same user or user type.This is motivated by the fact that, althoughpersonality is a characteristically human quality,it has been demonstrated that human users at-tribute a personality to the computer interfacesthey use, regardless of whether one has been ex-plicitly encoded in the system?s design (Nass et al,1995).
Furthermore, personality complementarityand similarity are important factors for the accep-tance of an interface by a user (Moon and Nass,1996; Nass and Lee, 2000), so that there is no ?op-timal?
or ?perfect?
system personality, but ratherthe need to tune system personality to best fit itsusers.In the rest of this paper, we will briefly discussliterature on both adaptivity and personality mod-elling (Section 2), proceed to present the interac-tion between multimodal dialogue strategies andour personality model (Section 3), and finally con-clude (Section 4).312 BackgroundINDIGO in general and our work in particularis, to a large extend, based on work on adaptivenatural-language interfaces to databases.
The do-mains of application of these systems have var-ied from generating personalized encyclopedia en-tries and museum exhibit descriptions, to support-ing the authoring of technical manuals and on-linestore catalogues.2.1 Adaptive HCIThe ILEX system was a major milestone in adap-tive natural language generation (NLG), empha-sising the separation between domain and linguis-tic resources permitting the portability of linguis-tic resources between domains.
ILEX also intro-duced the notion of a system agenda that rep-resents the system?s own communicative goals,a significant step in the direction of represent-ing system personality.
These system preferenceswere combined with user preferences and a dy-namic assimilation score (calculated from interac-tion history) to estimate a single preference factorfor the various facts in the database for the pur-poses of selecting the content that is to be includedin the description of each object (O?
Donnell et al,2001).ILEX, however, offered no theory about whereinterest and importance come from or how to com-bine them; arbitrary values had to be providedfor all objects in the database and the combinedpreference was derived by multiplying the threefactors (importance, interest, and assimilation) re-gardless of how each object is related to other in-teresting or important objects in the collection orwhat other relevant and semantically similar ob-jects have been assimilated.Building upon ILEX, the M-PIRO system ex-tended user model preferences to influence surfacerealization besides content selection, so that dif-ferent surface forms would be generated to realizethe same abstract piece of information for differ-ent users (Isard et al, 2003).
This was achievedby explicitly representing the grammar fragmentsthat could be used to realize different types of facts(properties of the object being described) and thenextending the user interests mechanism to also se-lect which grammar fragment is more ?interesting?
(or, rather, appropriate) to realize a particular pieceof information for a particular user model.By comparison to ILEX, M-PIRO offered greaterflexibility and linguistic variation, as well as lan-guage portability by allowing the combination ofdifferent grammars with the same domain or usermodels.
On the other hand, the, even rudimen-tary, ability to combine user and system prefer-ences was dropped and user model authoring be-came practically unmanageable due the size andcomplexity of user models.With the emergence of the Semantic Web, itbecame obvious that representation technologiessuch as RDF and OWL offered an opportunityto reduce the authoring effort by operating uponpre-existing OWL ontologies.
This motivated thedevelopment of the NATURALOWL/ELEON sys-tem.
NATURALOWL is a template-based NLGengine, explicitly designed for generating natu-ral language descriptions of ontological entities,based on such entities?
abstract properties (Gala-nis and Androutsopoulos, 2007).
The ELEON au-thoring tool (Konstantopoulos et al, 2009) can beused to annotate OWL ontologies with linguisticand content-selection resources and inter-operateswith NATURALOWL which can use such anno-tations to generate descriptions of ontological ob-jects.2.2 Emotions and personalityAnother relevant line of research is centred aroundaffective interaction and intelligent virtual agents.The main focus here is the modelling and mim-icking of the various affective markers that peopleuse when they communicate, aiming at more nat-ural and seamless human-computer interaction.Such affective systems are modulated by per-sonality representations varying from fully-blowncognitive architectures (Vankov et al, 2008) to rel-atively simpler personality models.
The OCEANor Big Five model, in particular, a standard frame-work in psychology (Norman, 1963; Costa andMcCrae, 1992), is used to represent personality ina variety of virtual agents and avatars capable formulti-modal communication acts such as speechand facial expressions (Strauss and Kipp, 2008;Kasap et al, 2009).
Such systems are typicallyrich in visual expression, but lack sophisticationin natural language generation, knowledge repre-sentation and dialogue structure.The PERSONAGE and INDIGO systems, on theother hand, move in the area between these sys-tems and the database-access systems discussedabove: PERSONAGE develops a comprehensive32??????????????????????????????????????????????????????????????????????
?????????????????????????????????????????????
?
?
?
?
???
?????????
?
?????
??????
?
??
?
?????
?
??
?
??????
????
?
??
?
???
???????
?
?????
?
????
?
??
????
???
?
??
?
???
?
????
?
???
?
??
?
?????
??????????
?
??????
?
??
??????????
????????????????
????
?
??????
????
?
??????????
??????
?????
??????????
???????????????????????????????????????????????
????????????????????????
???????
??????
?
???
??
?
????
?
?????
?
??
?
?????????
?????????
??
?
????
???
??
????
??????????????????????????????????????????????????????????????????????????
????
????
???????
?????????????????????????????????
?
???
????
????????
???
?????????
??
??????????
???????????????????????????????
????????????????????????????????
???
????????
????????
?
?????????
???
???????
?
?
????????
?????
?
?????
????
?????
???
???????????????????????
???????????????????
????????
??????????????????????
????????????????????????????????????????????????????????????????
????????????????????????????????????????????
??????????????????????
?
?
???
?????????
????
?
??????
???
????????
?
?
???
???????
????????????
?
?????
?????????????????????????????????????????????????????????????????????
??
?????
?
????
?
?????
?
???
?
??????
?
???
?
???
?
??
?
????
?
??
?
???
?
????
?
???????
?????????
??????
?
??????
?
????????
????????????
??
?????
????
???????
???????
???????
????
????????????
?????????????
???????????????????????
??????????
?
????
?
?????
?
????
????
?
??
?
????????
?
?????????
?
?
?
???
?
???????
?????
?
????
?
??
??????????????????????????????????????????????????????????????????????
?????????????
??????????????
?Figure 1: An INDIGO robot interacting with Hel-lenic Cosmos personnel during preliminary trials,September 2009.theory of using OCEAN parameters to controlnatural language interaction from lexical choiceto syntax, pragmatics, and planning, but is re-stricted to text generation and no other com-munication modalities are covered (Mairesse andWalker, 2007).
The INDIGO dialogue system em-phasises multi-modality as it is embodied in arobot capable of multi-modal interaction.
INDIGOuses OCEAN to combine a separate user modeland system profile into a single parameter set usedto parametrize a number of interaction compo-nents, such as a virtual avatar capable of display-ing emotions, the NLG engine, the text-to-speechengine, the dialogue manager, etc.3 A dialogue system with personalityThe INDIGO system has been fielded at the Hel-lenic Cosmos cultural centre,1 where it providespersonalized tours with historical, architectural,and cultural information about the buildings of theAncient Agora of Athens (Figure 1).The dialogue manager (DM, Matheson et al,2009), implemented using TrindiKit,2 assumes theinformation-state and update approach to dialoguemanagement (Traum and Larsson, 2003).
Theinformation state stores information such as dia-logue history and current robot position.
Inputfrom the sensors (ASR, vision, laser tracker, andtouchscreen) is processed by update rules whichheuristically fuse multimodal (and possibly con-tradicting) sensory input and implement generic(i.e., domain and personality-independent) dia-logue strategies.
These strategies deliberate aboutthe next action that the robot will take, such as1See also http://www.hellenic-cosmos.gr2See http://sourceforge.net/projects/trindikit/moving to a different section of the exhibition, of-fering a menu of choices, or describing an item.One notable strategy implemented in the DM isthe Move On Related strategy (Bohus and Rud-nicky, 2008), the system?s fallback when user in-put cannot be confidently recognized even afterfusing all input modalities.
In such situations, DMuses the combined preference factors to choose themost preferred exhibit within the ontological classthat is the current focus of the discourse.
If thereis an instance in this class with a clear preference,DM assumes this as the user response; if, on theother hand, there is no instance with significantlyhigher preference than the rest, DM prompts theuser to repeat their answer or use the touchscreen.The other notable, and widely used, strategy isthe one that drives the two loops shown in Fig-ure 2, in response to a user request for content:one pertaining to dynamically realizing a person-alized description of an object of the domain on-tology and one pertaining to updating the system?semotion and mood.3.1 Content selection and realization loopOnce the DM has resolved that the next robot ac-tion will be the description of a domain ontologyobject, the personality-driven preferences are usedto select which properties of this object will be in-cluded in the description.
These preferences arecalculated taking into account a combined user-system preference (Konstantopoulos et al, 2008)as well as a dynamic assimilation score, calcu-lated from interaction history, which balances be-tween the gratuitous and tiring repetition of high-preference material and simply rotating throughthe list of properties of an object.The chosen content is then used by the NAT-URALOWL NLG engine (Galanis and Androut-sopoulos, 2007) to plan and realize a personalizedtextual description of the object.
Besides selectingwhat to include in a description, preference is usedby NATURALOWL to annotate the generated textwith directives, such as emphasis, for the text-to-speech effector that drives the robot?s speakers.The combined user-system preference stemsfrom associating domain objects with content-selection parameters, using an representation de-veloped for NATURALOWL and extended in IN-DIGO to provide for representing not only usermodels but also system profiles that establish thesystem?s own goals and preferences (Konstan-33AppraisalModuleEffectorsNavigationText?to?SpeechDisplayRobot headNLGOntologyDomainModelUserRobotModelPersonalityModuleDialogueManagerEmotionEngineMoodASRVisionTouchscreenLaser TrackerSensorsUserfacialgestureUserinputContentAppraisal ContentChosenitemRealizedDescriptionFigure 2: Overall architecture of the dialogue system.topoulos et al, 2009).Emotional and, in general, behavioural varia-tion among different instantiations of the system isachieved through synthetic personality models thatassert different points of balance between the (po-tentially) conflicting user and system preferences.What is of particular importance is that the thecombined user-system preference is not estimatedin isolation for each and every ontological objectas was the case in ILEX, but by axiomatizing howpreference is ?transferred?
between domain objectsbased on their semantic relations.
This is achievedby defining personality in terms of logic clausesthat link the preferences of an object not only toits user and system preferences, but also to thoseof objects it semantically relates with.3.2 Emotional appraisal and update loopThe system emotionally appraises user actions aswell as its own actions.
With respect to its ownactions, the preference factors for the propertiesselected to describe an object reflect the robot?sbeing excited or bored to discuss the current sub-ject.Appraisal of user actions stems from vision andspeech analysis to reflect the impact of the mannerof what the user said.
More specifically, facial ges-ture recognition is used to detect emotional signs(such as smiling) besides detecting affirmative andnegative nods and similar signs that are fused withthe results of speech recognition.As user utterances are mostly short and incom-plete answers to questions such as ?Would you liketo hear more about this monument??
or ?Whichmonument would you like me to talk about??
wecannot detect emotion based on linguistic mean-ing or syntactic structure, but rather concentrate onextracting useful prosodic and linguistic featuressuch the length of the last syllable in an utteranceor whether the first word of the utterance is an wh-word.3 Although these features are not by them-selves indicative of emotion, they are indicativeof prosody and their combination with segmentalfeatures (referring to the acoustic form) extracteddirectly from the speech signal was shown to im-prove emotion estimation.Emotional appraisal is used by an emotion sim-ulator (Kasap et al, 2009) that uses the system?spersonality traits (OCEAN vector) to model howdialogue acts affect the system?s emotional state.This emotion simulator updates the system?s in-ternal short-term emotional state and long-termmood by applying an update function on the cur-rent state and the emotional appraisal of each dia-logue act.
The OCEAN parameters act as param-eters of the update function, so that, for example,3Where, what, who, etc.34neuroticism (i.e., ?tendency to distress?)
makes theupdate function tend towards negative emotions,whereas agreeableness (i.e., ?sympathetic?)
makesit more directly reflect the user?s emotions.The speech synthesiser and the robot?s anima-tronic head reflect emotional state as voice mod-ulations and facial expressions, whereas mood istaken into account by the DM when deliberatingabout the robot?s next dialogue action.4 ConclusionsIn this paper we have approached personality as ameans of synthesising different, and possibly con-flicting, adaptivity models into an overall model tobe used to drive the interaction components of thesystem.
Furthermore, this synthesis is performedin the presence of domain knowledge, so that do-main structure and relations influence the resultsof the calculation.We thusly explore the self vs. other aspect ofpersonality modelling, theoretically interesting butalso practically important as we cleanly separateadaptivity and profiling data that refers the systemfrom that which refers to the user.
This follows upon the tradition of the line of systems stemmingfrom ILEX, where increasingly separable models(domain vs. NLG resources, the latter later brokendown between linguistic and adaptivity resources)have allowed for such hard-to-create resources tobe re-used.AcknowledgementsThe work described in this paper was funded bythe FP6-IST project INDIGO, that developed andadvanced human-robot interaction technology, en-abling robots to perceive natural human behaviourand act in ways that are more familiar to humans.To achieve its goals, INDIGO advanced varioustechnologies, which it integrated in a robotic plat-form.More details are availble from the project web-site, http://www.ics.forth.gr/indigoReferencesDan Bohus and Alex Rudnicky.
2008.
Sorry, Ididn?t catch that.
In Laila Dybkj?r and Wolf-gang Minker, editors, Recent Trends in Dis-course and Dialogue, volume 39 of Text, Speechand Language Technology, chapter 6, pages123?154.
Springer Netherlands.P.
T. Costa and R. R. McCrae.
1992.
Normalpersonality assessment in clinical practice: TheNEO personality inventory.
Psychological As-sessment, 4(5?13).Dimitris Galanis and Ion Androutsopoulos.
2007.Generating multilingual descriptions from lin-guistically annotated OWL ontologies: the Nat-uralOWL system.
In Proceedings of the 11thEuropean Workshop on Natural Language Gen-eration (ENLG 2007), Schloss Dagstuhl, Ger-many, pages 143?146.Amy Isard, Jon Oberlander, Ion Androutsopoulos,and Colin Matheson.
2003.
Speaking the users?languages.
IEEE Intelligent Systems, 18(1):40?45.Zerrin Kasap, Maher Ben Moussa, Parag Chaud-huri, and Nadia Magnenat-Thalmann.
2009.Making them remember: Emotional virtualcharacters with memory.
In Tiffany Barnes,L.
Miguel Encarnc?a?o, and Chris Shaw, editors,Serious Games, Special Issue of IEEE Com-puter Graphics and Applications.
IEEE.Stasinos Konstantopoulos, Vangelis Karkaletsis,and Dimitris Bilidas.
2009.
An intelligent au-thoring environment for abstract semantic rep-resentations of cultural object descriptions.
InLars Borin and Piroska Lendvai, editors, Pro-ceedings of EACL-09 Workshop on LanguageTechnology and Resources for Cultural Her-itage, Social Sciences, Humanities, and Edu-cation (LaTeCH-SHELT&R 2009), Athens, 30Mar 2009, pages 10?17.Stasinos Konstantopoulos, Vangelis Karkaletsis,and Colin Matheson.
2008.
Robot personal-ity: Representation and externalization.
In Pro-ceedings of ECAI-08 Workshop on Computa-tional Aspects of Affective and Emotional In-teraction (CAFFEi 2008), Patras, Greece, July21st, 2008, pages 5?13.Franc?ois Mairesse and Marilyn Walker.
2007.PERSONAGE: Personality generation for dia-logue.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational Lin-guistics (ACL).
Prague.Colin Matheson, Amy Isard, Jon Oberlan-der, Stasinos Konstantopoulos, and VangelisKarkaletsis.
2009.
Multimodal human-robot di-alogue management.
INDIGO Deliverable 4.1(public).35Youngme Moon and Clifford Nass.
1996.
Adap-tive agents and personality change: comple-mentarity versus similarity as forms of adap-tation.
In Proceedings SIGCHI Conference onHuman Factors in Computing Systems, Vancou-ver, BC, Canada, 1996.
SIG on Computer-Human Interaction, ACM, New York, U.S.A.Clifford Nass and Kwan Min Lee.
2000.
Doescomputer-generated speech manifest person-ality?
an experimental test of similarity-attraction.
In Proceedings SIGCHI Conferenceon Human factors in Computing Systems, TheHague, 2000.
SIG on Computer-Human Inter-action, ACM, New York, U.S.A.Clifford Nass, Youngme Moon, B. Fogg, andB.
Reeves.
1995.
Can computer personalitiesbe human personalities?
International Journalof Human-Computer Studies, 43:223?239.W.
T. Norman.
1963.
Toward an adequate taxon-omy of personality attributes: Replicated fac-tor structure in peer nomination personality rat-ing.
Journal of Abnormal and Social Psychol-ogy, 66:574?583.Michael O?
Donnell, Chris Mellish, Jon Oberlan-der, and A. Knott.
2001.
ILEX: an architec-ture for a dynamic hypertext generation system.Natural Language Engineering, 7(3):225?250.Martin Strauss and Michael Kipp.
2008.
ERIC:a generic rule-based framework for an affectiveembodied commentary agent.
In Proceedingsof the 7th international joint conference on Au-tonomous agents and multiagent systems (AA-MAS 08), Estoril, Portugal, 2008, pages 97?104.David Traum and Steffan Larsson.
2003.
The in-formation state approach to dialogue manage-ment.
In Jan van Kuppevelt and Ronnie Smith,editors, Current and New Directions in Dis-course and Dialogue.
Kluwer Academic Pub-lishers, Dordrecht, the Netherlands.Ivan Vankov, Kiril Kiryazov, and Maurice Grin-berg.
2008.
Introducing emotions in an analogy-making model.
In Proceedings of 30th An-nual Meeting of the Cognitive Science Society(CogSci 2008), Washington D.C.36
