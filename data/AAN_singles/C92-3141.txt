HIGH-PROBABILITY SYNTACTIC LINKSLeonid MitjushinInstitute for Problems of Information TransmissionRussian Academy of Sciences19 Ermolovoy Street, 101447 GSP-4, Moscow, Russia1 IntroductionIn this paper we consider syntactic relations betweenwords of a sentence that can be strongly predicted bylocal mechanisms.
For instance, if a sentence con-tains a pair of words... red  b lock  ....then the reader immediately makes a conjecture thatred is an adjective modifier for the noun block.
Thesame is true for semantically abnormal pairs such as... g reen ideas  .
.
.
.Other examples of strong prediction are providedby pairs... authors  descr ibe  .
.
.
.... p rob lem i s .
.
.
,for which a "subject - verb" relation takes place withhigh probability.In most cases, such simple hypotheses prove to becorrect.
However, sometimes they lead to errors, asfor the pair prob lem is in the sentence( I )  The  so lut ion  o f  this p rob lem is very s imp le .In this example, however, by the moment the word ishas been read, the word prob lem is already engagedin other strongly predicted constructions, namely theprepositional phrase of" this p rob lem and even thewhole noun phrase the so lut ion  o f  this p rob lem.
Aconflict arises, and plausibility of the new hypothesisbecomes much lower.Such syntactic relations may concern not only ad-jacent words.
For instance, in (1) it is for the pairso lut ion  ... is that the "subject - verb" relation will beconjectured.In this paper, slrong prediction of syntactic rela-tions is modeled within the framework of dependencysyntax (see Mel'~uk 1974, 1988).
According to thistheory, (surface) syntactic structure of a sentence isan oriented tree whose nodes are the words of thesentence (more precisely, their lexico-morphologicalinterpretations).
The arcs of the tree represent syn-tactic links between words and are labeled by namesof syntactic relations.
The result of strong predictionis a partial parse of the sentence, in which high-prob-ability syntactic links are established.In our opinion, dependency structures are betteradapted to partial parsing than constituent struc-tures.
The reason is that the dependency structure ofa segment is the same both when the segment is con-sidered as isolated and when it is considered as a partof some sentence (by "segment" we understand anysequence of words).
Generally, this is not true forconstituent structures.
For instance, the segment lsaw a man has the dependency structure *(2) l-complpred \[ det 1I ~ SOW O ~ manboth as a complete sentence and as a part of thesentence I saw a man with a te lescope.
The fact thatthe latter sentence is ambiguous does not hamperanything, as both its structures contain subtree (2)(and differ only in arcs that go into the word with):(3) l-comp\[ preppred \[ de l \ ]  attr l, det lI ~ saw a ~man ~wi~n a ~ telescope.
(4) novpredI ~sawl-compl \[~_ prepd?t \] dnt \[a ~man with a ~ telescope.On the other hand, the constituent structure of thesegment I saw a man is not fully inherited in theconstituent structures of the longer sentence.
In ouropinion, this comparison demonstrates that, in a cer-tain sense, dependency structures reflect the in-cremental nature of sentence comprehension fromleft to right better than constituent s ructures do.In this paper we describe a bottom-up, left-to-rightalgorithm of partial parsing that establishes high-probability syntactic links.
It is implemented on aVAX 11/750  computer as a subsystem of a multipur-pose linguistic processor developed in the Laboratoryof Computational  Linguistics of the Inst i tute forProblems of Information Transmission, the RussianAcademy of Sciences (Apresjan et al 1992).
The par-tial parser is employed as a preprocessing unit beforethe operation of the main filter-type parser.
It can alsobe used for automatic ndexing and lemmatization.The algorithm is language-independent: all lan-guage-specific nformation is recorded in the dic-t ionar ies  and  the ru les  that  es tab l i sh  l inks .
* Full names of English syntactic relationS that appear in example=are: predicative, determinative, lsl completive, prepositional, t-tributive, adverbial.
The number of relations used In completemodels of English and Ru~tan syntax varies from 40 to 55 (Mel'~uk1974; Mel'~.uk and Pertsov 1987; Apresjan et al 1989, 1992).AcrEs DE COLING-92, NANT~, 23-28 AOtJT 1992 9 3 0 PROC.
OF COLING-92.
NANTES, AUG. 23-28.
1992Exper iments with Russian sentences have givenpromising results: on average, the algorithm estab-l ishes 70 - 80 ~o of syntactic l inks of a sentence;p rocess ing  speed (exc lus ive of morpho log ica lanalysis) is about 10 words per CPU second.
Theerror rate is less than 1% (stable stimates have notbeen obtained yet).2 Bot tom-up  Pars ingThe processing ofa sentence begins with morphologi-cal analysis.
As a result, each word is given a set of itspossible lexico-morphological interpretations, hence-forth called "homonyms".
A homonym is a list thatincludes a lexeme ident i f ier ,  a part-of-speechmarker, and morphological features of the wordform.For instance, the morphological module of theETAP-2 system (Apresjan et al 1989) will give forthe word sawtbe following three homonyms: SEE, V,pt ( -past tense); SAWl, V, mf ( -main form); SAW2,N, sg.All morphological data are concentrated in a spe-cial morphological dictionary.
The key role in parsingproper is played by a combinatorial (syntactic) dic-tionary that contains versatile information on syntac-tic propert ies of lexemcs, i.e.
on their  abi l i ty toparticipate in various syntactic onstructions (fordetails ee Mel'~uk 19"/4, 1988; Apresjan et al 1989,1992).The general scheme of parsing is as follows.
Afterthe morphological nalysis, for each word there ap-pears one or more homonyms.
By "fragment" we shallunderstand a set of homonyms occupying one ormore successive posit ions in the sentence (onehomonym in each position) plus a tree of syntacticlinks defined on these homonyms as nodes.
For in-stance, an isolated homonym is a trivial fragment; hewhole dependency tree of a sentence is also a frag-ment.
It should be noted that in trees (2) - (4) eachword is represented by a certain homonym (for ex-ample, saw is represented by SEE, V, pt).Lejkina and Tsejtin (1975) described a bottom-upprocess for constructing dependency trees.
It is basedon the operation of adjunction.
This operation is ap-plied to two adjacent fragments and consists in estab-lishing a link, marked by a certain syntactic relation,from a certain node of one fragment to the root of theother.
The result of adjunction is a new fragment onthe union of segments occupied by the initial frag-ments.This action is similar to generation of a new con-stituent from two adjacent constituents.
However,unlike constituents, fragments at the moment of ad-junction may be "incomplete", i.e.
they need not con-tain all  the nodes that will be direct or indirectdependents of their roots in the structure of the sen-tence.
These nodes may be added to them later (alsoby the operation of adjunction).Mitjushin (1985) described the class of trees thatcan be constructed from isolated homonyms byrepeated adjunction, i.e.
that can be built by the bot-tom-up process.
Consider a tree with an ordered setof nodes.
Let a "tangle" be a quadruple of nodes (a, b,c, d) with the following properties:1) a<b<c<d;2) a and c are linked by an arc (in any direction);3) b and d are linked by an arc (in any direction);4) the path between a and d contains neither b norc (here, orientation of arcs is ignored, so thepath always exists).The following criterion is true: a tree can be con-structed from its nodes by repeated adjunction if andonly if it contains no tangles.The simplest tangle looks as follows:a b c d(direction of the arcs does not matter; there can beother nodes between a, b, c, and d).
According to thecriterion, a tree that contains uch a subtree cannotbe built by the bottom-up rocess.The class of trees obtainable by adjunction is muchwider than the class of so-called projective trees (onprojectivity see, for example, Gladkij 1985; Mel't~uk1988).
For the model of Russian syntax presented byMel'~uk (1974) and Apresjan et al (1992), this classincludes all syntactic structures permissible in scien-tific, technical, and business texts (however, it is notso for spoken language and poetry).
We suppose allthe structures considered below to belong to thisclass.3 Ru lesIn our system, in contrast o those based on forulalgrammars, the rules are not a tool for the exhaustivedescription of the set of correct syntactic structures.We suppose that the correspondence b tween senten-ces and their syntactic structures i  defined by someother means.
The task of the parsing algorithm andthe rules it employs is to build, for a given sentence,some set of its syntactic structures or their fragments,without losing the semantically correct ones.The concrete function of the rules is to checkwhether the given case of adjunction is feasible and,if so, to perform the operation of adjunctioa.
Someaddit ional operations can also be performed.
Therules have access to any information about the struc-ture of fragments to be adjoined and the homonymsthey contain (their lexeme names, morphological fea-tures, and syntactic properties tated in the com-binatorial dictionary).
The rules may also use dataon punctuation and limited data on homonyms notbelonging to the given two fragments; they have noaccess to information about fragments built by the al-gorithm earlier.While formally the rules could be strongly context-sensitive within the limits of two given fragments, inmost cases they only use information on nodes X andY (those to be linked) and their nearest syntacticContext.
In fact, the rules currently emloyed do notACTES DE COLING-92, NANTES.
23-28 Am~'r 1992 9 3 1 PROC.
OF COLING-92, NANTES, AUG. 23-28.
1992consider nodes for which distance from X or Y ex-ceeds 3 (where distance is the number of links in thepath connecting two nodes in the dependency tree ofa fragment).A rule is a program written in the form of a transi-lion graph, with an elementary predicate or operationassociated with each arc.
The rule interpreter per-forms ordered search to find a path along "true" arcsthat starts at a fixed entry node and ends at one offixed exit nodes.
No backtracking is used: if forwardmotion from some node proves to be impossible, in-terpretation is terminated.
The fact that backtrackingis not necessary has been discovered empirically; it isconnected with the nature of syntactic events con-s idered  by the rules.
On the other  hand,  whendesirable, an explicit return may be made to a pointpassed earlier, with simple measures taken againstinfinite cycling.Each  ru le  conta ins  at  leas t  one  operat ionL INK(X ,  Y ,R)  that establ ishes a link marked by acertain syntactic relation R between the given node Xof one fragment and the root Y of the other (that is,performs the adjunction).
The corpus of rules coversonly those situations for which the probability thatthe established links are correct is estimated as closeto 1.
For instance, the rules do not establish links likealter and ad~v in structures (3) and (4) because altach-ment of prepositional postmodifiers i known as a"classical" case of structural ambiguity.It should be noted that the probability close to 1characterizes here not individual inks (it would betoo strong a demand) but all complex of links estab-lished for the given words.
This can be illustrated bythe segment 1 saw, for which two fragments will bebuilt with different homonyms for the word saw:pred predI~- -  SEE V.pt, I ~  SAWI V,mf.Both these alternatives are syntactically correct.
Atthe same time, they are mutually exclusive, and it isonly their disjunction that has probability close to 1.This ambiguity is also inherited by larger fragments.
(As a result, the sentence 1 saw a man with a telescopehas four different parses, two of which are semanti-cally abnormal.)
Thus, high probability is a "roller-five" and not an " individual" property of links.Rigorous definitions can be found in the paper byMiljushin (1988).4 The  Pars ing  A lgor i thmThe simplest method of bottom-up arsing is to con-sider all opportunities for adjunction, starting fromadjacent one-element fragments.
We employ a fasteralgorithm, in which certain heuristics are used toreduce search (Mitjushin 1988).The algorithm builds a growing sequence A of frag-ments .
At any  moment  of t ime A conta ins  somehomonyms of the sentence and certain f ragmentsconst ructed  of these homonyms.
The a lgor i thmmoves from the beginning of the sequence A to its endand tries to perform adjunction between the currentfragment F E A and the fragments that appear in Aearlier than F. New fragments are added to the end ofthe sequence.The fragment cmtsidered at the given moment iscalled active.
All fragments of A (including isolatedhomonyms)  become active successively,  withoutleaps or returns.While the algorithm moves along the sequence A,tile sequence grows longer because of the addition ofnewly built fragments.
Nevertheless, a moment willnecessarily come when the active fragment is the lastin A and further motion is impossible.
In this case,the next homonym of the sentence is added to the se-quence; it becomes active and the work is continued.When a new deadlock arises, another homonym isadded, and so on.
If in such a situation it turns outthat all homonyms of the sentence are exhausted,then the work is finished.Homonyms are added to the sequence in the orderthey are arranged in the sentence from left to right(which is essential), and those occupying the sameposition are added in an arbitrary order (in this case,the order has no influence m~ the results).
At the ini-tial moment A contains a single element, namely oneof the homonyms occupying the leftmost position ofthe sentence, and it is declared active.For each active fragment F lhe  algorithm selects inA its left neighbors, i.e.
fragments thai are adjacentto F on its left.
A preference relation is defined be-tween tile neighbors of F: fragments of greatter lengthare preferred,  and  lhose of equal length are con-sidered equivalent.For the given F, the algorithm considers its leftneighbors E in order of their preference, and for eachE tries to adjoin it to F. If for some E adjunclion issuccessful, subsequent search is limited to the neigh-bors of F equivalent to E; less preferred fragments arenot considered.An attempt o adjoin E to F is made as follows.I Jnks are considered that connect a certain node X offragment E with the rightmost node Y of fragment F.A preference relation is defined between the links:those of greater length are less prefen'ed, and thoseof equal length are equivalent.
In other words, morepreferred are links X -- -Y and X ~ Y with nodes Xthat are nearer to the Jight end of E; links with thesame X are equivalent.For the given E and F, nodes X ~E are consideredfrom right to left (i.e.
in order of the preference oflinks between X and Y), and for each X the rules ap-plicable to these X and Y are activated.
The list ofsuch rules is determined by parts of speech of X andY, and by possible direction of fhe link.
If during in-terpretation of a rule an operation L INK(X ,  Y, .)
orL INK(Y ,X ,  .)
is performed then a new fragment isbuilt which is the ~'esult of joining X and Y with thegiven link.
It is placed at the end of tile sequence A.After flint, for these E and F the search is limited tothe l inks equivalent o the estab l i shed one; lesspreferred links are not considered.When the sequence A is built, its subset C of maxi-mal fragments i  formed.
A fragment is called maxi-mal if its segment is not a proper part of the segmentof any other fragment belonging to A.
The set C is thefinal result of partial parsing.
Below, when speakingACTES DE COLING-92, NANTES, 23-28 AO(ZI' 1992 9 3 2 PROC.
OI' COLING 92, NANI KS.
AUG. 23-28.
1992about fragments built by the algoritlnn, we shall al.-ways mean exactly tim set C.The first experiments with this algorithm haveshown titbit, tit sonte c;.tses, the preferences attdrestrictions adopted arc too strong and pvtme awaysemantically correct parses.
To intprove tire situa-tion, special operations were defined that made itpossible to cancel (from inside lhc rule) priority oflonger neighbors or shorter links, and also to makethe algm'ithm cmrsider not only the rightmost node oftire right fragment.
()wing to them, the search can bemade exhaustive in all cases when the rule "considersit desirable".
In tile real process of pursing, theseoperations are fired not too often, so tile main part ofsearch remains limited.5 Exper imcn|sAt present, after preliminary debugging and tuning oftile rules, we have begun to carry out regahn' experi~merits with it homogeneous flow of Russian texts.
Theexperiments make use of a Coluputer-olicnted conl-binatorial dictionary of Russian compiled by a groupof linguists under ttle guidance of Ju.D.Apresjan (seeApresjan et al 1992).
It contains over' 10,000 entries,mainly general scicnlific vcxzabulary and terms horncomputer science and e\]tx:trical engineering.The number of rules in lhc system is now about100.
Total number of arcs in their transition graphs isabout 2,000.As a source of texts, we have taken several issues ofthe journal Computer Science Abstracts (Referativnyjzhurnal Vyehislitel'nyje Nauki, in Russian).
Senten-ces are chosen at raodom.
Sentences with formulas,occasional abbreviations, and non-Cyrillic words areexcluded.
Words absent in the dictionaries (aboul8% of all word occureuces in these texts) arereplaced by "dummy" words that have syntacticproperties most probable for the given category.
Atpresent, about 300 sentences have been processed.On the average, fraginr:nts produced by partialparsing include 3 - 4 words.
It is not infrequent thatthey have 8 - 10 or store words, or present completestructures of sentences.
On the other hand, a sub-stantial parl of fragments are isolated homonyms.For instance, subordinate conjunctions remain iso-lated in most eases because, as a rule, their links wilhother words are not considered having high prob-ability.Frequently enough morphoh~gieal, lexical, andstructural ambiguity results ill building 2 - 4 differentfragments on tile same segnlellt, Sometimes theirnumber is 8 - 12 and more, but such cases are rela-tively rare.
The record is now equal to 72 fragmentson a segment of 9 words.
For such cases, packingtechn iques  can be deve loped s imi la r  to thosedescr ibed by Tomita (1987).
Another  possiblemethod is to employ ntnnelical estimates of syntacticpreference (set, for example, Tsejtin 1975; Kulagiua1987, 1990; Tsujii et al 1988).On the avecage, the nmubcr of established links is70 - 80 % of the total nunlber of syntactic links in tilesentence.
These figm'es include links present both inthe fragmenls built ;trl0 ill tile semantically COl r?ctstructm'e of the sentence; "extra" links that arise dueto ambiguity of fragments are not included.Sometimes the fragments overlap, that is, theirsegments intersect.
It happens approximately in onetenth of sentences.
As a rule, in such cases the correctresnlt is a combination of one of the overlapping frag-ments with its "truncated" competitor.A fragment is called correct for a given sentence ifit is a subtree of the semantically correct dependencytrek of this sentence (or of one of such trees, in therare cases of real semantic ambiguity like (3) - (4)).A h'agment is called feasible if it is a subtree of somedependency tree of some sentence of the given lan-guage.
The algmSthm akes an error in the followinglwo cases: (a) if a non-feasible fragment is built; (b)if all fragments built on some segment are feasiblebut none is correct.
(Here we do not take into accountsemantically abnormal sentences or the possibility ofoverlapping; these situations would require more ac-curate definitions.
)hi roost cases, all error means that some link of afragment is established erroneously, while all theothers arc correct.
Ttre experiments have shown thattile frequency of errors for the algorithm described isfairly snmll.
For tile lasl 100 sentences, 12 errorswere nmde (9 of the first type and 3 of the second),which is less than 1% of the total number of linkseslablished in correct fragments.
A stable estimate isnot yet obtained because at this stage of experimentstuning of tire rules is emllinued, and the error fre-queocy decreases steadily.Error s of tire first type are caused by inaccuracy ofthe lexicographic descriplious and imperfection ofthe rules.
In the presence of adequate lexicographieinformation, these errors in principle are avoidable,as the rules may fully control internal properties ofthe fragments being created.The second type of error is intrinsic to our ap-proach.
The rules employed are local in two respects:they take no (or almost no) account of the contextoutside the fragments being adjoined, and they takeno account of a very large part of syntax that concernsless probable links.
The first restrictiou means thatf ragments may appear which are grammatical lyfeasible but do not agree with the context.
Thesecond one implies that wc do not intend to obtaincomplete structures of sentences, and therefore shallno\[ be able to reject a fragment for the reason that itis not engaged in any complete structure.In general, it is not at all snrprising that a certainpart of syntactic links can be reliably revealed bylocal mcchanisrns.
Any flow of texts in any languagemust contain chains of words the parse of whichweakly depends on the context ("weakly" can be un-derstood here in the statistical sense: the share ofthose occurences for which tile parse differs from themost probable one is small).
The possibility of ex-amining fragments in any detail permits to avoidsituations iu which the risk of creating a non-feasiblefragment is too large.A more surprising fact is that the number of reliab-ly established links is rather high ~ about 75 %.
Forthe most part, these are links typical of the basic,most frequent syntactic onstructions such as "adjec-ACIES DI,;COLlN(l-92, NANIV;S, 23-28 AOt-ll 1992 93 3 l'aoC.
OV COLING-92, NAhqES, AUG, 23-28, 1992tire + noun", "preposition + noun", "numeral +noun","adverb + verb", and also a large group of links con-necting predicate words with their arguments.
Asregards the last type, preference for the predicate-ar-gument interpretation f word combinations wasorlon noted in the literature (this preference is a par-ticular case of the Most Restrictive Context Principleproposed by Hobhs and Bear (1990)).Observations show that the number of establishedhigh-probability links noticeably depends on the typeof text.
The general trend is as follows: the more "for-mal" the text is, the more links are established.
Fromthis point of view, the language of scientific abstractssuits the given approach quite well.As regards comparative frequency of high-prob-ability links in different languages, it would benatural to expect these links to be more typical of lan-guages with rich morphology than of analytical ones(such as English).
Nevertheless, preliminary experi-ments have shown no substantial difference in thisrespect between English and Russian scientific texts.We suppose that in case of high-probability links,the efficiency of local approach is additionally aug-mented ue to factors "of the second order" concern-ing general mechanisms of text comprehension a dgeneration.
This opinion is based on the following as-sumptions.
If someone reading a text sees that ahigh-probability link is possible between certainwords and this link is compatible with the previouspart of the text, then he makes aconjecture that thislink is correct; such conjecture isabandoned only ifsome counter-evidence is obtained.
When peoplegenerate xts, they take into account this property ofthe comprehension mechanism and tend not to disap-point expectations of the readers.
In other words,they are careful not to create high-probability linksthat would prove to be incorrect.
This can be re-garded as an instance of cooperation i language per-formance (cf.
the Cooperative Principle in pragmaticsformulated by Grice (1975)).ReferencesApresjan, Ju.D., I.M.Boguslavskij, L.L.Iomdin,A.V.Lazurskij, N.V.Pertsov, V.Z.Sannikov, andL.L.Tsinman.
1989.
Lingvisticheskoje Obespe-chenije Sistemy ETAP-2.
Nauka, Moscow.
('Thelinguistics of the ETAP-2 system', in Russian)Apresjan, Ju.D., I.M.Boguslavskij, L.L.Iomdin,A.V.Lazurskij, LG.Mitjushin, V.Z.Sannikov, andL.LTsinman.
1992 (forthcoming).
LingvisticheskijProtsessor dlja Slozhnykh Informatsionnykh Sis-tern.
Nauka, Moscow.
('A linguistic processor forcomplex information systems', inRussian)Gladki j ,  A.V.
1985.
Sintaksicheskije StrukturyEstestvennogo Yazyka v Avtomatizirovannykh Sis-temakh Obshchenija.
Nauka, Moscow.
('Syntacticstructures of natural language in automaticdialogue systems', in Russian)Grice, H.P.
1975.
Logic and Conversation.
In P.Cole,J.L.Morgan, editors.
Syntax and Semantics, Vol.3, Academic Press, New York, pp.
41 - 58.Hobbs, .LR.
and J.Bear.
1990.
Two Principles ofParse Preference.
In Proceedings of COLING-90,Vol.
3, Helsinki, pp.
162 - 167.Kulagina, O.S.
1987.
Ob Avtomaticheskom sintak-sicheskom Analize Russkikh Tekstov.
Preprint No.205, Institute for Applied Mathematics, Moscow.
('On automatic parsing of Russian texts', in Rus-sian)Kulagina, O.S.
1990.
O Sintaksicheskom Analize naOsnove Predpochtenij.
Preprint No.
3, Institute forApplied Mathematics, Moscow.
('On preference-based parsing', in Russian)Lejkina, B.M.
and G.S.Tsejtin.
1975.
Sintaksiches-kaja Model' s Dopushchenijem OgranichennojNeprojectivnosti.
In Meztulunarodnyj Seminar poMashinnomu Perevodu, Moscow, pp.
72 - 74.
('Asyntactic model allowing limited non-projectivity',in Russian)Mel'~uk, I.A.
1974.
Opyt Teorii LingvisticheskikhModelej "Smysl ,,* Tekst".
Nauka, Moscow.
('Toward a theory of Meaning ~--, Text linguisticmodels', in Russian)Mel'tfuk, I.A.
1988.
Dependency Syntax: Theory andPractice.
State University of New York Press, Al-bany.Mel'~uk, I.A.
and N.V.Pertsov.
1987.
Surface Syntaxof English."
A Formal Model within the Meaning--- Text Framework.
John Benjamins, Amster-dam.Mitjushin, L.G.
1985.
Dlina Sintaksicheskikh Svjazeji Induklivnyje Struktury.
In Semiotika i Infor-matika, No.
26, Moscow, pp.
34 - 51.
('Length ofsyntact ic l inks and the class of inductivestructures', inRussian)Mitjushin, LG.
1988.
O Vysokoverojatnykh Sintak-sicheskikh Svjazjakh.
In Problemy RazrabotkiFormal'noj Modeli Jazyka (series "VoprosyKibernetiki", No.
137), Moscow, pp.
145 - 174.
('On high-probability s ntactic links', in Russian)Tomita, M. 1987.
An Efficient Augmented-Context-Free Parsing Algorithm.
Computational Linguis-tics, Vol.
13, No.
1 - 2, pp.
31 - 46.Tsejtin, G.S.
1975.
Metody SintaksicheskogoAnaliza, Ispol 'zu jushchi je  Predpochteni jeJazykovykh Konstruktsij: Modeli i Eksperimenty.In Mezhdunarodnyj Seminar po MashinnomuPerevodu, Moscow, pp.
131 - 133.
( 'Parsingmethods based on preference of the language con-structions: models and experiments', in Russian)Tsujii, J., Y.Muto, Y.Ikeda, and M.Nagao.
1988.How to Get Preferred Readings in Natural Lan-guage Analysis.
In Proceedings of COLING-88,Vol.
2, Budapest, pp.
683 - 687.ACRES DE COLING-92, NANTES, 23-28 ^OI~T 1992 9 3 4 PROC.
OF COLING-92, NANTES, AUO.
23-28, 1992
