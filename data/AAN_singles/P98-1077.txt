Eff ic ient L inear  Logic  Mean ing  AssemblyVineet  GuptaCae lum Research  Corporat ionNASA Ames  Research  CenterMof fe t t  F ie ld  CA 94035vgupt a@pt olemy, arc.
nasa.
govJ ohn  LampingXerox  PARC3333 Coyote  Hi l l  RoadPa lo  A l to  CA 94304 USAi amping?parc, xerox, tom1 In t roduct ionThe "glue" approach to semantic ompositionin Lexical-Functional Grammar uses linear logicto assemble meanings from syntactic analyses(Dalrymple et al, 1993).
It has been compu-rationally feasible in practice (Dalrymple t al.,1997b).
Yet deduction in linear logic is knownto be intractable.
Even the propositional ten-sor fragment is NP complete(Kanovich, 1992).In this paper, we investigate what has madethe glue approach computationally feasible andshow how to exploit that to efficiently deduceunderspecified representations.In the next section, we identify a restrictedpattern of use of linear logic in the glue analyseswe are aware of, including those in (Crouch andGenabith, 1997; Dalrymple et al, 1996; Dal-rymple et al, 1995).
And we show why thatfragment is computationally feasible.
In otherwords, while the glue approach could be usedto express computationally intractable analyses,actual analyses have adhered to a pattern of useof linear logic that is tractable.The rest of the paper shows how this pat-tern of use can be exploited to efficiently cap-ture all possible deductions.
We present a con-servative xtension of linear logic that allows areformulation of the semantic ontributions tobetter exploit this pattern, almost urning theminto Horn clauses.
We present a deduction algo-rithm for this formulation that yields a compactdescription of the possible deductions.
And fi-nally, we show how that description of deduc-tions can be turned into a compact underspeci-fled description of the possible meanings.Throughout he paper we will use the illus-trative sentence "every gray cat left".
It hasflHlctional structure(1) \[PRED 'LEAVE' 1PRED 'CAT'f: SUBJ g: \[SPEC 'EVERY'\[MODS {\[ PRED 'GRAY'\]}and semantic ontributionsleave :Vx.
ga',-*x --.o fo',-*leave(x)cat :w. (ga VAR)--** ~ (ga RESTR)-,~ Cat(*)gray NP.
\[Vx.
(ga VAtt)---* x --o (g~ RESTR)-,-* P(x)\]-o \[w. (g~ VAR)~,every :VH, R, S.\[w. (g~ VAR)--~, --o (g~ RESTR)--~R(z)\]?\[Vx.
g,,'...*x ~ g-,-*S(x)\]--~ H',-* every(R, S)For our purposes, it is more convenient to fol-low (Dalrymple t al., 1997a) and separate thetwo parts of the semantic ontributions: use alambda term to capture the meaning formulas,and a type to capture the connections to thef-structure.
In this form, the contributions areleave :cat  :gray :every :Ax.leave(x) : g,, --o fa.,~x.cat(x) : (ga VAR) --o (ga RESTR)AP.Ax.gray(P)(x)  :((g~ vAR) --o (ga RESTR))--o (g~ VAn) ~ (ga RESTR)AR.AS.every(R,  S) :VH.
(((g~ 'CAR) --o (ga RESTR))?(g.
~ H))--oHWith this separation, the possible derivationsare determined solely by the "types", the con-nections to the f-structure.
The meaning is as-sembled by applying the lambda terms in ac-cordance with a proof of a type for the sen-tence.
We give the formal system behind thisapproach, C in Figure 1 - -  this is a differentpresentation of the system given in (Dalrymple464et al, 1997a), adding the two standard rulesfor tensor, using pairing for meanings.
For thetypes, the system merely consists of the Inearlogic rules for the glue fragment.We give the proof for our example in Figure 2,where we have written the types only, and haveomitted the trivial proofs at the top of the tree.The meaning every(gray(cat),left) may be as-sembled by putting the meanings back in ac-cording to the rules of C and r/-reduction.M : A ~-c M / : Awhere M --a,n M ~F,P,Q,A~-c RF,Q,P,  AF-c Rr, : A\[B/X\] -o RF ,M :VX.AF-c Rr M: A\[Y/X\] (r new)F t-c M : VX.AF ~-c N : A A ,M\ [N/x \ ]  : B F-c RF,A, Ax.M : A --o B ~-c Rr ,y  : A be M\[y/x\] : Br F-c Ax.M : A .-.o B (y new)F,M :A ,N : B I-- Rr, (M, N) :A?
B ~- RFF-M:A  A~-N:BF ,A~- (M,N) :A?BFigure 1: The system C. M,N  are meanings,and x, y are meaning variables.
A, B are types,and X, Y are type variables.
P, Q, R are formu-las of the kind M : A. F ,A are multisets offormulas.2 Ske leton  re ferences  and  modi f ie r  ref-e rencesThe terms that describe atomic types, terms Ikega and (g~ vA1Q, are semantic structure refer-ences, the type atoms that connect he semanticassembly to the syntax.
There is a pattern tohow they occur in glue analyses, which reflectstheir function in the semantics.Consider a particular type atom in the ex-ample, such as g~.
It occurs once positively inthe contribution of "every" and once negativelyin the contribution of "leave".
A sightly morecompIcated example, the type (ga l~nSTR) oc-curs once positively in the contribution of "cat",once negatively in the contribution of "every",and once each positively and negatively in thecontribution of "gray".The pattern is that every type atom occursonce positively in one contribution, once nega-tively in one contribution, and once each posi-tively and negatively in zero or more other con-tributions.
(To make this generaIzation hold,we add a negative occurrence or "consumer" offa, the final meaning of the sentence.)
This pat-tern holds in all the glue analyses we know of,with one exception that we will treat shortly.We call the independent occurrences the skele-ton occurrences, and the occurrences that occurpaired in a contribution modifier occurrences.The pattern reflects the functions of the lex-ical entries in LFG.
For the type that corre-sponds to a particular f-structure, the idea isthat, the entry corresponding to the head makesa positive skeleton contribution, the entry thatsubcategorizes for the f-structure makes a neg-ative skeleton contribution, and modifiers onthe f-structure make both positive and negativemodifier contributions.Here are the contributions for the examplesentence again, with the occurrences classified.Each occurrence is marked positive or negative,and the skeleton occurrences are underlined.leave : g_Ka- -o fa+cat : (ga VAtt)- --o (ga ttESWtt) +gray : ((ga VAn) + --o (ga aESTR)-)---o (ga VAn)- --o (ga RESTR) +every : VH.
(((ga VAR) + --o (ga RESTR.)-)?
(g_z.~ ~ --~ g - ) )---o H +This pattern explains the empirical tractabil-ity of glue inference.
In the general case ofmultiplicative Inear logic, there can be complexcombinatorics in matching up positive and neg-ative occurrences of literals, which leads to NP-completeness (Kanovich, 1992).
But in the gluefragment, on the other hand, the only combina-torial question is the relative ordering of modi-tiers.
In the common case, each of those order-ings is legal and gives rise to a different mean-ing.
So the combinatorics of inference tends tobe proportional to the degree of semantic am-biguity.
The complexity per possible reading isthus roughly tnear  in the size of the utterance.But, this simple combinatoric structure sug-gests a better way to exploit the pattern.Rather than have inference xplore all the com-binatorics of different modifier orders, we canget a single underspecitied representation thatcaptures all possible orders, without having to465cat F- (ga VAR) --o (go RESTR) (go VAR) --O (go RESTR) ~ (go" VAR) ---O (ga RESTR)cat, ((ga VAR) ---o (ga RESTR)) --o (ga VAR) ---o (ga RESTR) ~ (ga VAR) ---o (ga RESTR)gray, cat ~- (ga VAR) --~ (ga RESTR) leave F- ga --o fogray, cat, leave F ((go VAR) --~ (go RESTR)) ~(ga .--o fa) fo ~- fagray, cat,leave, (((ga VAR) --o (ga RESTR)) ?
(go.
---o fo)) --o fo ~- foevery, gray, cat, leave F- faFigure 2: Proof of "Every gray cat left", omitting the lambda termsexplore them.The idea is to do a preliminary deduction in-volving just the skeleton, ignoring the modifieroccurrences.
This will be completely determin-istic and linear in the total length of the for-mulas.
Once we have this skeletal deduction,we know that the sentence is well-formed andhas a meaning, since modifier occurrences es-sentially occur as instances of the identity ax-iom and do not contribute to the type of thesentence.
Then the system can determine themeaning terms, and describe how the modifierscan be attached to get the final meaning term.That is the goal of the rest of the paper.3 Convers ion  toward  horn  c lausesThe first hurdle is that the distinction betweenskeleton and modifier applies to atomic types,not to entire contributions.
The contribution of"every", for example, has skeleton contributionsfor go, (go VAR), and (ga RESTR), but modifiercontributions for H. Furthermore, the nestedimplication structure allows no nice way to dis-entangle the two kinds of occurrences.
When adeduction interacts with the skeletal go in thehypothetical it also brings in the modifier H.If the problematic hypothetical could be con-verted to Horn clauses, then we could get a bet-ter separation of the two types of occurrences.We can approximate this by going to an in-dexed linear logic, a conservative xtension ofthe system of Figure 1, similar to Hepple's sys-tem(Hepple, 1996).To handle nested implications, we introducethe type constructor A{B},  which indicates anA whose derivation made use of B.
This is sim-ilar to Hepple's use of indices, except that weindicate dependence on types, rather than on in-dices.
This is sufficient in our application, sinceeach such type has a unique positive skeletaloccurrence.We can eliminate problematic nested impli-cations by translating them into this construct,in accordance with the following rule:For a nested hypothetical t top level that hasa mix of skeleton and modifier types:M : ( A -o B ) -o Creplace it withx :A ,  M: (B{A}- - -oC)where x is a new variable, and reduce complexdependency formulas as follows:1.
Replace A{B ---o C} with A{C{B}}.2.
Replace (A --o B){C} with A --o B{C}.The semantics of the new type constructorsis captured by the additional proof rule:F ,x :AF -M:BF,x : A ~- Ax.M : B{A}The translation is sound with respect o thisrule:Theorem 1 If F is a set of sentences in theunextended system of Figure 1, A is a sentencein that system, and F ~ results from F by applyingthe above conversion rules, then F F- A in thesystem of Figure 1 iff F' F- A in the extendedsystem.The analysis of pronouns present a differentproblem, which we discuss in section 5.
For allother glue analyses we know of, these conver-sions are sufficient to separate items that mixinteraction and modification into statements of466the form S, Jr4, or S -o .h4, where S is pureskeleton and M is pure modifier.
Furthermore,.h4 will be of the form A -o A, where A may bea formula, not just an atom.
In other words, thetype of the modifier will be an identity axiom.The modifier will consume some meaning andproduce a modified meaning of the same type.In our example, the contribution of "every",can be transformed by two applications of thenested hypothetical rule toevery :AR.AS.every(R, S) :VH.
(ga RESTR){(ga VAR)}--o H{gq} -o Hx :(go VAR)Y :gaHere, the last two sentences are pure skele-ton, producing (g~ VAR) and ga, respectively.The first is of the form S -o M,  consuming(ga RESTR), to produce a pure modifier.While the rule for nested hypotheticals couldbe generalized to eliminate all nested implica-tions, as Hepple does, that is not our goal, be-cause that does remove the combinatorial com-bination of different modifier orders.
We use therule only to segregate skeleton atoms from mod-ifier atoms.
Since we want modifiers to end uplooking like the identity axiom, we leave themin the A -o A form, even if A contains furtherimplications.
For example, we would not applythe nested hypothetical rule to simplify the en-try for g ray  any further, since it is already inthe form A ---o A.Handling intensional verbs requires a moreprecise definition of skeleton and modifier.
Thetype part of an intensional verb contributionlooks like (VF.
(ha -o F)  --o F) -o ga -o fa(Dalrymple t al., 1996).First, we have to deal with the smalltechnical problem that the VF gets in theway of the nested hypothetical translationrule.
This is easily resolved by introducinga skolem constant, 5', turning the type into((h~ -o 5') --o 5') --o g~ --o f~.
Now, thenested hypothetical rule can be applied to yield(ho -o S) and S{5"{h~}} ---o ga --o fa.But now we have the interesting question ofwhether the occurrences of the skolem constant,S, are skeleton or modifier.
If we observe how 5'resources get produced and consumed in a de-duction involving the intensional verb, we findthat (ha --o 5') produces an 5', which may bemodified by quantifiers, and then gets consumedby S { S { ha } } ---o ga -o f~.
So unlike a modifier,which takes an existing resource from the envi-ronment and puts it back, the intentional verbplaces the initial resource into the environment,allows modifiers to act on it, and then takes itout.
In other words, the intensional verb is act-ing like a combination of a skeleton producerand a skeleton consumer.So just because an atom occurs twice in acontribution doesn't make the contribution amodifier.
It is a modifier if its atoms must in-teract with the outside, rather than with eachother.
Roughly, paired modifier atoms functionas f -o f ,  rather than as f ?
f?,  as do the Satoms of intensional verbs.Stated precisely:Def in i t ion 2 Assume two occurrences of thesame type atom occur in a single contribution.Convert the formula to a normal form consist-ing of just ?, ~ , and J_ on atoms by convertingsubformulas A -o B to the equivalent A ?
:~ B,and then using DeMorgan's laws to push all J_ 'sdown to atoms.
Now, if the occurrences of thesame type atom occur with opposite polarity andthe connective between the two subexpressions inwhich they occur is ~ , then the occurrences aremodifiers.
All other occurrences are skeleton.For the glue analyses we are aware of, this def-inition identifies exactly one positive and onenegative skeleton occurrence of each type amongall the contributions for a sentence.4 Eff ic ient deduct ion  of  underspec i f iedrepresentat ionIn the converted form, the skeleton deductionscan be done independently of the modifier de-ductions.
Furthermore, the skeleton deductionsare completely trivial, they require just a lin-ear time algorithm: since each type occurs oncepositively and once negatively, the algorithmjust resolves the matching positive and nega-tive skeleton occurrences.
The result is severaldeductions starting from the contributions, thatcollectively use all of the contributions.
One ofthe deductions produces a meaning for fa, forthe whole f-structure.
The others produce puremodifiers - -  these are of the form A --o A. For467Lexical contributions in indexed logic:leave :cat :g ray  :everyx :every2 :everya  :Ax.leave(x) : ga --o fc,ax.eat(x): VAR) R .STR): VAR) --o R STR)) VAR) --o RESTR)AR.AS.every(R, S) : vg .
(g~ RnSTR){(g~ 'CAR)} --o g{ga} ---o Hz VAR)Y :g~The following can now be proved using the extended system:gray  ~- AP.Ax.gray(P)(x) : ((ga VAR) --o (g~ RESTR)) ----O (g~ VAR) --o (ga RESTR)every2,  cat,  every1 ~- AS.every(Ax.eat(x), S :  VH.
H{ga} --o Heverya,  leave F- leave(y) : faFigure 3: Skeleton deductions for "Every gray cat left".the example sentence, the results are shown inFigure 3.These skeleton deductions provide a compactrepresentation of all possible complete proofs.Complete proofs can be read off from the skele-ton proofs by interpolating the deduced modi-tiers into the skeleton deduction.
One way tothink about interpolating the modifiers is interms of proof nets.
A modifier is interpolatedby disconnecting the arcs of the proof net thatconnect he type or types it modifies, and recon-necting them through the modifier.
Quantifiers,which turn into modifiers of type VF.F ---o F,can choose which type they modify.Not all interpolations of modifiers are le-gal.
however.
For example, a quantifier mustoutscope its noun phrase.
The indices of themodifier record these limitations.
In the caseof the modifier resulting from "every cat",VH.H{ga} ---o H, it records that it mustoutscope "every cat" in the {ga}.
The in-dices determine a partial order of what modi-fiers must outscope other modifiers or skeletonterms.In this particular example, there is no choiceabout where modifiers will act or what their rel-ative order is.
In general, however, there will bechoices, as in the sentence "someone likes everycat", analyzed in Figure 4.To summarize so far, the skeleton proofs pro-vide a compact representation f all possible de-ductions.
Particular deductions are read off byinterpolating modifiers into the proofs, subjectto the constraints.
But we are usually more in-terested in all possible meanings than in all pos-sible deductions.
Fortunately, we can extract acompact representation f all possible meaningsfrom the skeleton proofs.We do this by treating the meanings of theskeleton deductions as trees, with their arcs an-notated with the types that correspond to thetypes of values that flow along the arcs.
Just asmodifiers were interpolated into the proof netlinks, now modifiers are interpolated into thelinks of the meaning trees.
Constraints on whatmodifiers must outscope become constraints onwhat tree nodes a modifier must dominate.Returning to our original example, the skele-ton deductions yield the following three trees:!gRESTR) / ~/-/Iga~tga VAR) ---o ?
,~Z.
\] ga RESTR)leave (go RESTR)I graycat lga VAR) --oI g~ (go VAR) ~ I tgo' RESTR) yleave(y) aS.every(;~x.cat(x),S) aP.ax.gray(P)(x)Notice that higher order argumentsare reflected as structured types, like(g~ VAR) ----o (g~ RESTR).
These trees area compact description of the possible meanings,in this case the one possible meaning.
Webelieve it will be possible to translate this rep-resentation i to a UDRS representation(Reyle,1993), or other similar representations forambiguous entences.We can also use the trees directly as an un-derspecified representation.
To read out a par-ticular meaning, we just interpolate modifiersinto the arcs they modify.
Dependencies on a468The functional structure of "Someone likes every cat".PREDSUBJ/:OBJThe lexical entries after'LIKE'h:\[ pRro 'soMroNE'\]PRED 'eAT' \]g: SPEC ~EVERY'conversion to indexed form:like :cat :someone l  :someone2 :every l  :every2 :everya  :Ax.Ay.tike(x, y): (ho ?
go) -o/oAx.cat(x): (go VAR) -o (ga RESTR)z :hvAS.some(person, S) : VH.
H{ho) --o HAR.AS.every(R, S) : vg .
(go RESTR){(go VA1Q) --o H{go) --o Hx : (go VAR)Y:goFrom these we can prove:someone1,  everya,  like ~- like(z, y) : fosomeone2 F- AS.some(person, S) : VH.
H{ho} --o Hevery2,  cat,  every1 b AS.every(cat, S) : VH.
H{go} -o HFigure 4: Skeleton deductions for "Someone likes every cat"modifier's type indicate that a lambda abstrac-tion is also needed.
So, when "every cat" mod-ifies the sentence meaning, its antecedent, in-stantiated to fo{go) indicates that it lambdaabstracts over the variable annotated with goand replaces the term annotated fo.
So the re-sult is:Ifo, everyRESTR.)
A Ax.
Y.
(go RESTR)\] \]focat leave(go VAR)!
: /oSimilarly "gray" can modify this by splicingit into the line labeled (go VAR) --o (go RESTR)to yield (after y-reduction, and removing labelson the arcs).Ifo /vergray leaveIcatThis gets us the expected meaningevery(gray(cat), leave).In some cases, the link called for by a higherorder modifier is not directly present in the tree,and we need to do A-abstraction to supportit.
Consider the sentence "John read Hamletquickly".
We get the following two trees fromthe skeleton deductions:re!fd g/ \hoJohn Hamletread(John, Hamlet)I go --o foquicklyIgo-o foAP.Ax.quickly( P )( x )There is no link labeled ga --o fa to be modi-fied.
The left tree however may be converted byA-abstraction to the following tree, which has arequired link.
The @ symbol represents A ap-plication of the right subtree to the left.I/oAx.
JohnI/oread gj  \hox HamletNow quickly can be interpolated into thelink labeled go --o fo to get the desiredmeaning quickly(read(Hamlet), John), after r/-reduction.
The cases where A-abstraction is re-quired can be detected by scanning the modi-fiers and noting whether the links to be mod-ified are present in the skeleton trees.
If not,A-abstraction can introduce them into the un-469derspecified representation.
Furthermore, theintroduction is unavoidable, as the link will bepresent in any final meaning.5 AnaphoraAs mentioned earlier, anaphoric pronounspresent a different challenge to separating skele-ton and modifier.
Their analysis yields typeslike f~ --o (f~ ?
g~) where g~ is skeleton and f~is modifier.
We sketch how to separate them.We introduce another type constructor (B)A,informally indicating that A has not been fullyused, but is also used to get B.This lets us break apart an implication whoseright hand side is a product in accordance withthe following rule:For an implication that occurs at top level,and has a product on the right hand side thatmixes skeleton and modifier types:Ax.
(M, N) : A ---o (B ?
C)replace it withAx.M : (C)A -o B, N : CThe semantics of this constructor is capturedby the two rules:M1 : AI~...,M,~ : An ~- M : AM1 : (B)A1, .
.
.
,Mn: (B)A,~ t- M:  (B)AF, M1 : (B)A, M2 :B~-N :CF t, M~:A, M~:B~-N ' :Cwhere the primed terms are obtained byreplacing free x's with what was applied tothe Ax.
in the deduction of (B)AWith these rules, we get the analogue of The-orem 1 for the conversion rule.
In doing theskeleton deduction we don't worry about the(B)A constructor, but we introduce constraintson modifier positioning that require that a hy-pothetical dependency can't be satisfied by adeduction that uses only part of the resource itrequires.6 AcknowledgementsWe would like to thank Mary Dalrymple, JohnFry, Stephan Kauffmann, and Hadar Shemtovfor discussions of these ideas and for commentson this paper.ReferencesRichard Crouch and Josef van Genabith.
1997.How to glue a donkey to an f-structure, orporting a dynamic meaning representationinto LFG's linear logic based glue-languagesemantics.
Paper to be presented at the Sec-ond International Workshop on Computa-tional Semantics, Tilburg, The Netherlands,January 1997.Mary Dalrymple, John Lamping, and VijaySaraswat.
1993.
LFG semantics via con-straints.
In Proceedings of the Sixth Meetingof the European ACL, pages 97-105, Univer-sity of Utrecht.
European Chapter of the As-sociation for Computational Linguistics.Mary Dalrymple, John Lamping, FernandoC.
N. Pereira, and Vijay Saraswat.
1995.
Lin-ear logic for meaning assembly.
In Proceed-ings of CLNLP, Edinburgh.Mary Dalrymple, John Lamping, FernandoC.
N. Pereira, and Vijay Saraswat.
1996.
In-tensional verbs without ype-raising or lexicalambiguity.
In Jerry Seligman and Dag West-erst?hl, editors, Logic, Language and Com-putation, pages 167-182.
CSLI Publications,Stanford University.Mary Dalrymple, Vineet Gupta, John Lamp-ing, and Vijay Saraswat.
1997a.
Relatingresource-based semantics to categorial seman-tics.
In Proceedings of the Fifth Meeting onMathematics of Language (MOL5), SchlossDagstuhl, Saarbriicken, Germany.Mary Dalrymple, John Lamping, FernandoC.
N. Pereira, and Vijay Saraswat.
1997b.Quantifiers, anaphora, and intensionality.Journal of Logic, Language, and Information,6(3):219-273.Mark Hepple.
1996.
A compilation-chartmethod for linear categorical deduction.
InProceedings of COLING-96, Copenhagen.Max I. Kanovich.
1992.
Horn programming inlinear logic is NP-complete.
In Seventh An-nual IEEE Symposium on Logic in ComputerScience, pages 200-210, Los Alamitos, Cali-fornia.
IEEE Computer Society Press.Uwe Reyle.
1993.
Dealing with ambiguities byunderspecification: Construction, representa-tion, and deduction.
Journal of Semantics,10:123-179.470
