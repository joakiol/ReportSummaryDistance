Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 361?365,Dublin, Ireland, August 23-24, 2014.IxaMed: Applying Freeling and a Perceptron Sequential Tagger at theShared Task on Analyzing Clinical TextsKoldo Gojenola, Maite Oronoz, Alicia P?erez, Arantza CasillasIXA Taldea (UPV-EHU)maite.oronoz@ehu.eshttp://ixa.si.ehu.esAbstractThis paper presents the results of the Ix-aMed team at the SemEval-2014 SharedTask 7 on Analyzing Clinical Texts.We have developed three different sys-tems based on: a) exact match, b) ageneral-purpose morphosyntactic analyzerenriched with the SNOMED CT termi-nology content, and c) a perceptron se-quential tagger based on a Global LinearModel.
The three individual systems re-sult in similar f-score while they vary intheir precision and recall.
We have alsotried direct combinations of the individualsystems, obtaining considerable improve-ments in performance.1 IntroductionThis paper presents the results of the IxaMed team.The task is focused on the identification (Task A)and normalization (Task B) of diseases and disor-ders in clinical reports.We have developed three different systemsbased on: a) exact match, b) a general-purpose morphosyntactic analyzer enriched withthe SNOMED CT terminology content, and c) aperceptron sequential tagger based on a GlobalLinear Model.
The first system can be seen asa baseline that can be compared with other ap-proaches, while the other two represent two alter-native approaches based on knowledge organizedin dictionaries/ontologies and machine learning,respectively.
We also tried direct combinations ofthe individual systems, obtaining considerable im-provements in performance.These approaches are representative of differentsolutions that have been proposed in the literatureThis work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organizers.
License details:http://creativecommons.org/licenses/by/4.0/(Pradhan et al., 2013), which can be broadly clas-sified in the following types:?
Knowledge-based.
This approach makes useof large-scale dictionaries and ontologies,that are sometimes integrated in general toolsadapted to the clinical domain, as MetaMap(Aronson and Lang, 2010) and cTAKES (Xiaet al., 2013).?
Rule-based.
For example, in (Wang andAkella, 2013) the authors show the useof a rule-based approach on the output ofMetaMap.?
Statistical techniques.
These systems take atraining set as input and apply different vari-ants of machine learning, such as sequen-tial taggers based on hidden Markov mod-els (HMMs) or conditional random fields(CRFs) (Zuccon et al., 2013; Bodnari et al.,2013; Gung, 2013; Hervas et al., 2013; Lea-man et al., 2013).?
Combinations.
These approaches try to takethe advantages of different system types, us-ing methods such as voting or metaclassi-fiers (Liu et al., 2013).In the rest of the paper, we will first introducethe different systems that we have developed insection 2, presenting the main results in section 3,and ending with the main conclusions.2 System DescriptionThe task of detecting diseases and their corre-sponding concept unique identifiers (CUI) hasbeen faced using three methods that are describedin the following subsections.2.1 Exact MatchThe system based on Exact Match (EM) simplyobtained a list of terms and their corresponding361CUI identifier from the training set and markedany appearance of those terms in the evaluationset.
This simple method was improved with someadditional extensions:?
Improving precision.
In order to reduce thenumber of false positives (FP), we appliedfirst the EM system to the training set it-self.
This process helped to measure FPs,for example, blood gave 184 FPs and 2 truepositives (TPs).
For the sake of not hurtingthe recall, we allowed the system to detectonly those terms where TP > FP , that is,?blood?
would not be classified as disorder.?
Treatment of discontinuous terms.
Forthese terms, our system performed a soft-matching comparison allowing a limited vari-ation for the text comprised between theterm elements (for example ?right atrium ismildly/moderately dilated?).
These patternswere tuned manually.2.2 Adapting Freeling to the Medical DomainFreeling is an open-source multilingual languageprocessing library providing a wide range of ana-lyzers for several languages (Padr?o et al., 2010),Spanish and English among others.
We had al-ready adapted Freeling to the medical domain inSpanish (Oronoz et al., 2013), so we used our pre-vious experience to adapt the English version tothe same domain.
For the sake of clarity, we willrefer to this system as FreeMed henceforth.The linguistic resources (lexica, grammars,.
.
.
)in Freeling can be modified, so we took advantageof this flexibility extending two standard Freel-ing dictionaries: a basic dictionary of terms con-sisting of a unique word, and a multiword-termdictionary.
Both of them were enriched with adictionary of medical abbreviations1and with theSystematized Nomenclature of Medicine ClinicalTerms (SNOMED CT) version dated 31st of Julyof 2013.
In addition to the changes in the lexica,we added regular expressions in the tokenizer torecognize medical terms as ?Alzheimer?s disease?as a unique term.In our approach, the system distinguishes be-tween morphology and syntax on one side andsemantics on the other side.
First, on the mor-phosyntactic processing, our system only catego-rizes word-forms using their basic part-of-speech1http://www.jdmd.com/abbreviations-glossary.asp(POS) categories.
Next, the semantic distinctionsare applied (the identification of the term as sub-stance, disorder, procedure,.
.
.
).
Following thisapproach, whenever the specific term on the newdomain (biomedicine in this case) was already inFreeling?s standard dictionaries, the specific en-tries will not be added to the lexicon.
Instead,medical meanings are added in a later semantictagging stage.
For example: the widely used term?fever?, as common noun, was not added to thelexicon but its semantic class is given in a sec-ond stage.
Only very specific terms not appear-ing in the lexica as, for instance, ?diskospondyli-tis?
were inserted.
This solution helps to avoidan explosion of ambiguity in the morphosyntacticanalysis and, besides, it enables a clear separationbetween morphosyntax and semantics.In figure 1 the results of both levels of anal-ysis, morphosyntactic and semantic, are shown.The linguistic and medical information of medicaltexts is stored in the Kyoto Annotation Format orKAF (Bosma et al., 2009) that is based in the eX-tended Markup Language (XML).
In this examplethe term aneurysm is analyzed as NN (meaningnoun) and it is semantically categorized as mor-phological abnormality and disorder.SNOMED CT is part of the Metathesaurus,one of the elements of the Unified Medical Lan-guage System (UMLS).
We used the Metathe-saurus vocabulary database to extract the map-ping between SNOMED CT?s concept identifiersand their corresponding UMLS?s concept uniqueidentifier (CUI).
All the medical terms appearingin SNOMED CT and analyzed with FreeMed aretagged with both identifiers.
For instance, the termaneurysm in figure 1 has the 85659009 SNOMEDCT identifier when the term is classified in themorphological abnormality content hierarchy andthe 432119003 identifier as disorder.
Both arelinked to the same concept identifier, C0002940,in UMLS.
This mapping has been used for TaskB, whenever the CUI is the same in all the analy-sis of the same term.All the terms from all the 19 content hierarchiesof SNOMED CT were tagged with semantic infor-mation in the provided texts.The training corpus was linguistically analyzedand its format was changed from XML to the for-mat specified at the shared task.
After a manualinspection of the results and the Gold Standard,some selection of terms was performed:362<term tid=?t241?
lemma=?aneurysm?
pos=?NN?><extRefs><extRef resource=?SCT 20130731?
reference=?85659009?reftype=?morphologic abnormality?
><extRef resource=?UMLS-2010AB?
reference=?C0002940?/ ></extRef><extRef resource=?SCT 20130731?
reference=?432119003?reftype=?disorder?
><extRef resource=?UMLS-2010AB?
reference=?C0002940?/></extRef></extRefs></term>Figure 1: Analysis with augmented information.?
Selection and combination of semanticclasses.
All the terms from the disor-der semantic class (for example ?Hypothy-roidism?)
and from the finding class (for in-stance ?headache?)
are chosen, as well assome tag combinations (see figure 1).
Afteranalyzing the train corpus we decided to joininto a unique term a body structure immedi-ately followed by a disorder/finding.
In thisway, we identify terms as ?MCA aneurysm?that are composed of the MCA abbreviation(meaning ?middle cerebral artery?)
and theinmediately following ?aneurysm?
disorder.?
Filtering.
Not all the terms from the men-tioned SNOMED CT hierarchies are identi-fied as disorders in the Gold Standard.
Someterms are discarded following these criteria:i) findings describing personal situations (e.g.?alcoholic?
), ii) findings describing currentsituations (e.g.
?awake?
), iii) findings withwords indicating a negation or normal situ-ation (e.g.
?stable blood pressure?)
and iv)too general terms (e.g.
?problems?
).The medical terms indicating disorders that arelinked to more than one CUI identifier, weretagged as CUI-less.
That is, we did not performany CUI disambiguation.In subsequent iterations and after analyzing ourmisses, new terms and term variations (Hina etal., 2013) are added to the lexica in Freeling withthe restriction that, at least, one synonym shouldappear in SNOMED CT.
Thus, equivalent formswere created for all the terms indicating a cancer,a tumor, a syndrome, or a specific disease.
For in-stance, variants for the term ?cancer of colon?
andwith the same SNOMED CT concept identifier(number 363406005) are created with the forms?colon cancer?, ?cancer of the colon?
and ?can-cer in colon?.
Some abbreviation variations foundin the Gold Standard are added in the lexica too,following the same criteria.2.3 Perceptron Sequential TaggerThis system uses a Global Linear Model (GLM),a sequential tagger using the perceptron algorithm(Collins, 2002), that relies on Viterbi decoding oftraining examples combined with simple additiveupdates.
The algorithm is competitive to other op-tions such as maximum-entropy taggers or CRFs.The original textual files are firstly processed byFreeMed, and then the tagger uses all the availableinformation to assign tags to the text.
Each tokencontains information about the word form, lemma,part of speech, and SNOMED CT category.Our GLM system only deals with Task A, andit will not tackle the problem of concept normal-ization, due to time constraints.
In this respect, forTask B the GLM system will simply return the firstSNOMED CT category given by FreeMed.
Thisdoes not mean that GLM and FreeMed will givethe same result for Task B, as the GLM systemfirst categorizes each element as a disease, and itgives a CUI only when that element is identified.2.4 CombinationsThe previous subsections presented three differ-ent approaches to the problem that obtain com-parable scores (see table 1).
In the area of auto-matic tagging, there are several works that com-bine disparate systems, usually getting good re-sults.
For this reason, we tried the simplest ap-proach of merging the outputs of the three individ-ual systems into a single file.3 ResultsTable 1 presents the results of the individual andcombined systems on the development set.
Look-ing at the individual systems on Task A, we can seethat all of them obtain a similar f-score, althoughthere are important differences in terms of preci-sion and recall.
Contrary to our initial intuition,the FreeMed system, based on dictionaries and on-tologies, gives the best precision and the lowest re-call.
In principle, having SNOMED CT as a base,we could expect that the coverage would be morecomplete (attaining the highest recall).
However,the results show that there is a gap between thewriting of the standard SNOMED CT terms andthe terms written by doctors in their notes.
On theother hand, the sequential tagger gives the best re-363Task A Task BStrict Relaxed Strict RelaxedSystem Precision Recall F-Score Precision Recall F-Score AccuracyINDIVIDUAL SYSTEMSExact Match (EM) 0.804 0.505 0.620 0.958 0.604 0.740 0.479 0.948FreeMed 0.822 0.501 0.622 0.947 0.578 0.718 0.240 0.479GLM 0.715 0.570 0.634 0.908 0.735 0.813 0.298 0.522COMBINATIONSFreeMed + EM 0.766 0.652 0.704 0.936 0.754 0.835 0.556 0.855FreeMed + GLM 0.689 0.668 0.678 0.903 0.790 0.843 0.345 0.518EM + GLM 0.680 0.679 0.679 0.907 0.819 0.861 0.398 0.598FreeMed + EM + GLM 0.659 0.724 0.690 0.899 0.845 0.871 0.421 0.584Table 1: Results of the different systems on the development set.Task A Task BStrict Relaxed Strict RelaxedSystem Precision Recall F-Score Precision Recall F-Score AccuracyFreeMed + EM 0.729 0.701 0.715 0.885 0.808 0.845 0.604 0.862FreeMed + EM + GLM 0.681 0.786 0.730 0.872 0.890 0.881 0.439 0.558Best system 0.843 0.786 0.813 0.936 0.866 0.900 0.741 0.873Table 2: Results on the test set.call.
Since the tagger uses both contextual wordsand prefixes and suffixes as features for learning,this method has proven helpful for the recognitionof terms that do not appear in the training data (seethe difference with the EM approach).Looking at the different combinations in table 1,we see that two approaches work best, either com-bining FreeMed and EM, or combining the threeindividual systems.
The inclusion of GLM resultsin the best coverage, but at the expense of preci-sion.
On the other hand, combining FreeMed andEM gives a better precision but lower coverage.As pointed out by Collins (2002), the results ofthe perceptron tagger are competitive with respectto other statistical approaches such as CRFs (Zuc-con et al., 2013; Bodnari et al., 2013; Gung, 2013;Hervas et al., 2013; Leaman et al., 2013).Regarding Task B, we can see that the EM sys-tem is by far the most accurate, while FreeMedis well below its a priori potential.
The reason ofthis low result is mainly due to the high ambiguityfound on the output of the SNOMED CT tagger, asmany terms are associated with more than one CUIand, consequently, are left untagged.
This problemdeserves future work on automatic semantic dis-ambiguation.
On the combinations, FreeMed andEM together give the best result.
However, as wetold before, the GLM system was only trained forTask A, so it is not surprising to see that its resultsdeteriorate the accuracy in Task B.We chose these best two combinations for theevaluation on the test set (using training and de-velopment for experimentation or training), whichare presented in table 2.
Here we can see that re-sults on the development also hold on the test set.Given the unsophisticated approach to combinethe systems, we can figure out more elaborated so-lutions, such as majority or weighted voting, oreven more, the definition of a machine learningclassifier to select the best system for every pro-posed term.
These ideas are left for future work.4 ConclusionsWe have presented the IxaMed approach, com-posed of three systems that are based on exactmatch, linguistic and knowledge repositories, anda statistical tagger, respectively.
The results of in-dividual systems are comparable, with differencesin precision and recall.
We also tested a sim-ple combination of the systems, which proved togive significant improvements over each individ-ual system.
The results are competitive, althoughstill far from the winning system.For future work, we plan to further improve theindividual systems.
Besides, we hope that the ex-perimentation with new combination approacheswill offer room for improvement.AcknowledgementsThis work was partially supported by the Euro-pean Commission (325099 and SEP-210087649),the Spanish Ministry of Science and Innovation(TIN2012-38584-C06-02) and the Industry of theBasque Government (IT344-10).364ReferencesAlan R Aronson and Francois-Michel Lang.
2010.
Anoverview of MetaMap: historical perspective and re-cent advances.
Journal of the American Medical In-formatics Association (JAMIA), 17:229?236.Andreea Bodnari, Louise Deleger, Thomas Lavergne,Aurelie Neveol, and Pierre Zweigenbaum.
2013.A Supervised Named-Entity Extraction System forMedical Text.
In Online Working Notes of the CLEF2013 Evaluation Labs and Workshop, September.Wauter Bosma, Piek Vossen, Aitor Soroa, GermanRigau, Maurizio Tesconi, Andrea Marchetti, Mon-ica Monachini, and Carlo Aliprandi.
2009.
KAF: aGeneric Semantic Annotation Format.
In Proceed-ings of the 5th International Conference on Gener-ative Approaches to the Lexicon GL, pages 17?19,Septembre.Michael Collins.
2002.
Discriminative Training Meth-ods for Hidden Markov Models: Theory and Ex-periments with Perceptron Algorithms.
In Proceed-ings of the 2002 Conference on Empirical Methodsin Natural Language Processing, pages 1?8.
Asso-ciation for Computational Linguistics, July.James Gung.
2013.
Using Relations for Identificationand Normalization of Disorders: Team CLEAR inthe ShARe/CLEF 2013 eHealth Evaluation Lab.
InOnline Working Notes of the CLEF 2013 EvaluationLabs and Workshop, September.Lucia Hervas, Victor Martinez, Irene Sanchez, and Al-berto Diaz.
2013.
UCM at CLEF eHealth 2013Shared Task1.
In Online Working Notes of the CLEF2013 Evaluation Labs and Workshop, September.Saman Hina, Eric Atwell, and Owen Johnson.
2013.SnoMedTagger: A semantic tagger for medical nar-ratives.
In Conference on Intelligent Text Processingand Computational Linguistics (CICLING).Robert Leaman, Ritu Khare, and Zhiyong Lu.
2013.NCBI at 2013 ShARe/CLEF eHealth Shared Task:Disorder Normalization in Clinical Notes withDnorm.
In Online Working Notes of the CLEF 2013Evaluation Labs and Workshop, September.Hongfang Liu, Kavishwar Wagholikar, Siddhartha Jon-nalagadda, and Sunghwan Sohn.
2013.
IntegratedcTAKES for Concept Mention Detection and Nor-malization.
In Online Working Notes of the CLEF2013 Evaluation Labs and Workshop, September.Maite Oronoz, Arantza Casillas, Koldo Gojenola, andAlicia Perez.
2013.
Automatic Annotation ofMedical Records in Spanish with Disease, Drugand Substance Names.
In Lecture Notes in Com-puter Science, 8259.
Progress in Pattern Recogni-tion, ImageAnalysis, ComputerVision, and Applica-tions 18th Iberoamerican Congress, CIARP 2013,Havana, Cuba, November 20-23.Lluis Padr?o, Samuel Reese, Eneko Agirre, and AitorSoroa.
2010.
Semantic Services in Freeling 2.1:WordNet and UKB.
In Global Wordnet Conference,Mumbai, India.Sameer Pradhan, Noemie Elhadad, Brett R. South,David Martinez, Lee Christensen, Amy Vogel,Hanna Suominen, Wendy W. Chapman, and Guer-gana Savova.
2013.
Task 1: ShARe/CLEF eHealthEvaluation Lab 2013.
In Online Working Notesof the CLEF 2013 Evaluation Labs and Workshop,September.Chunye Wang and Ramakrishna Akella.
2013.
UCSCsSystem for CLEF eHealth 2013 Task 1.
In OnlineWorking Notes of the CLEF 2013 Evaluation Labsand Workshop, September.Yunqing Xia, Xiaoshi Zhong, Peng Liu, Cheng Tan,Sen Na, Qinan Hu, and Yaohai Huang.
2013.
Com-bining MetaMap and cTAKES in Disorder Recogni-tion: THCIB at CLEF eHealth Lab 2013 Task 1.
InOnline Working Notes of the CLEF 2013 EvaluationLabs and Workshop, September.Guido Zuccon, Alexander Holloway, Bevan Koop-man, and Anthony Nguyen.
2013.
Identify Disor-ders in Health Records using Conditional RandomFields and Metamap AEHRC at ShARe/CLEF 2013eHealth Evaluation Lab Task 1.
In Online WorkingNotes of the CLEF 2013 Evaluation Labs and Work-shop, September.365
