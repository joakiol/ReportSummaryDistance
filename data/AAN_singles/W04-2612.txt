Comparing, Integrating Lexical Definitional KnowledgeFrom Multiple SourcesLucja M. IwanskaSchool of Computer & Information ScienceGeorgia Southwestern State University800 Wheatley Street, Americus, Georgia 31709liwanska@gsw.eduAbstractWe discuss a computational mechanism for comparingand integrating lexical definitional knowledge,meanings and concept definitions of English words andphrases available from different sources such asdictionaries, encyclopedias, corpora of texts, andpersonal beliefs.
Such a mechanism is needed in orderto automate comparison and reconciliation of thedefinitional differences because completeness andcorrectness of definitional knowledge seriously affectthe results of text processing, particularlyclassification, question answering, and summarization.1 Problem Statement, Motivation1.1 Same Word, Many Different DefinitionsWhat is the meaning of words and phrases?
Whatconcepts do they denote?
Different sources ofdefinitional knowledge, including dictionaries,encyclopedias, various texts, and people sharing theirpersonal beliefs, define common words such as"document" and less common such as "virus" quitedifferently.
Their definitions differ significantly interms of length, properties (dimensions ofinformation), their significance, levels of specificity,the number of different senses; see Tables 1-5.Table 1.
DOCUMENT   according to different sourcesSourceD1 1. a piece of paper, booklet, etc., providing information,esp.
of an official or legal nature.2.
qual Archaic.
evidence; proof.SourceD2 1. anything printed, written, etc., relied upon to record orprove something2.
anything serving as proofSourceD7 1. writing that provides information (especiallyinformation of an official nature)2. anything serving as a representation of a person'sthinking by means of symbolic marks3.
a written account of ownership or obligation4.
(computer science) a computer file that contains text(and possibly formatting instructions) using 7-bit ASCIIcharactersSourceP1  1. something validating a claim or establishing a factSourceP2  1. an official-looking paper with writing and maybe a sealTable 2.
MURDER   according to different sourcesSourceD2 1.
The unlawful and malicious or premeditated killing ofone human being by another.
Also, any killing donewhile committing some other felony, as rape or robbery.2.
Collloq.
Something very hard, unsafe or disagreeableto do or to deal with.SourceD3 1. the crime of intentionally killing a personSourceD4 1. the crime of unlawfully killing a person especially withmalice aforethought   a something very difficult ordangerous   b something outrageous or blameworthySourceD5 1.
The unlawful killing of one human by another,especially with premeditated malice.2.
Slang Something that is very uncomfortable, difficult,or hazardous:3.
A flock of crows.SourceD6 1.
The offense of killing a human being with maliceprepense or aforethought, express or implied; intentionaland unlawful homicide.SourceD7 1. unlawful premeditated killing of a human being by ahuman beingSourceP3 1.
Killing someone without justifications defined bysociety.SourceP4 1.
The act of killing a living being is called murder.
Thisis a crime and is against the ethics of human life.SourceP5 1.
Killing a human.SourceA1 1.
The willful (nonnegligent) killing of one human beingby another.With any information and knowledge, the reasons fordifferences include incompleteness and lack ofknowledge, errors, lies, and misinformation,subjectivity, specific processing needs that deemcertain characteristics and details as relevant andimportant.Additionally, such big differences exist because itappears that natural languages are inherentlyambiguous and context-dependent.
Roughly, differentsources give different definitions because theyconsider different contexts.
Further complication isthat words and phrases of natural language changetheir meanings with time.
There are also regionaldifferences.Table 3.
STUDENT   according to different sourcesSourceD1 1. a person following a course of study, as in a school,college, university, etc.2.
a person who makes a thorough study of a subject3.
a person who likes to studySourceD2 1. a person who studies or investigates2.
a person who is enrolled for study at a school, college,etc.SourceD5 1.
One who is enrolled or attends classes at a school,college, or university.2.
a.
One who studies something.
b.
An attentiveobserver.SourceD7 1. a learner who is enrolled in an educational institution2.
a learned person (especially in the humanities);someone who by long study has gained mastery in one ormore disciplines1.2 Important to Know Right DefinitionsThis situation creates a major difficulty for designersof general-purpose natural language processing (NLP)systems.
An in-depth interpretation of naturallanguage requires a component providing lexicalknowledge, a dictionary or knowledge base kind ofresource.
Text processing applications involvingclassification, summarization, or question answeringmay produce very different results depending onwhich definition will be used.Table 4.
VIRUS   according to different sourcesSourceD1 1. any of a group of submicroscopic entities consisting ofa single nucleic acid surrounded by a protein coat andcapable of replication only within the cells of animals andplants; many are pathogenic.2.
a disease caused by a virus.3.
any corrupting or infecting influenceSourceD2 1.
orig., venom, as of a snake2.
a. same as FILTERABLE VIRUS; specif., any of agroup of ultramicroscopic or submicroscopic infectiveagents that cause various diseases in animals, as measles,mumps, etc., or in plants, as mosaic diseases; viruses arecapable of multiplying only in connection with livingcells and are regarded both as living organisms and ascomplex proteins sometimes involving nucleic acid,enzymes, etc.
b. a disease caused by a virus3.
anything that corrupts or poisons the mind or character;evil or harmful influence4.
something that poisons the mind or soul5.
a computer program usually hidden within anotherseemingly innocuous program that produces copies ofitself and inserts them into other programs and thatusually performs a malicious action (as destroying data)SourceD3 1. a very small organism, smaller than a bacterium, whichcauses disease in humans, animals and plants2.
Virus also means a disease caused by a virus.3.
a hidden instruction in a computer program which isintended to introduce faults into a computer system andin so doing destroy information stored in itSourceC2 1.
Viruses are extremely small infectious substances(much smaller than bacteria).For example, the property of ?liking to study?
and theproperty of ?being enrolled at school?
have a potentialto classify individuals as "students" completelydifferently; see definitions of "student" according toSourceD1 and SourceD5 in Table 3.A person who understands "murder" as ?killing ahuman?, see SourceP5 in Table 2, may develop a falsesense of security when reading FBI statistics compiledwith a different, more restrictive definition of"murder" which excludes certain types of killing ahuman from being classified as "murder"; FBI isSourceA1 in Table 2.1.3 Many Competing SourcesThe question arises as to which of these manydefinitions is the right one, the most correct andcomplete, and which of the many available sourcesshould be used for building a lexical knowledgecomponent of a NLP system, be it a dictionary or aknowledge base.Many NLP researchers and practitioners have builtand continue to build their owndictionaries/knowledge bases, which tends to be avery long and costly effort requiring serious resources.Another problem is that self-developed resources arevirtually always geared toward specific applicationsand type of textual data processed, which contributesto the nonscalability of NLP systems.Table 5.
Sources of Information and KnowledgeSourceD1 Collins English Language Dictionary, 1979SourceD2 Webster's NewWorld Dictionary,   2nd College Edition, 1982SourceD3 Cambridge International Dictionary of EnglishSourceD4 Merriam Webster's Collegiate Dictionary, 10th EditionSourceD5 American Heritage Dictionary of the English Language, 4th Edition, 2000SourceD6Online Plain Text English Dictionary   Kyoto NotreDame University, Project Gutenberg Etext of Webster'sUnabridged DictionarySourceD7 WordNet 1.7   Princeton University, Cognitive ScienceSourceE1 Encyclopedia.com   updated Columbia Encyclopedia, 6th EditionSourceP  Personal beliefs, knowledge of different individualsSourceC1 Knowledge automatically acquired by our NLP system from a corpora of textsSourceA1 FBI   Uniform Crime Reporting: Data Collection GuidelinesMany researchers utilize existing sources.
WordNet(Fellbaum, 1998) is a wonderful and free-of-chargeresource designed specifically for the needs ofcomputational linguistics (CL) community and thedictionary of choice for many NLP systems (Voorheesand Buckland, 2002).
It is not, however, the only, thebest, or the most comprehensive source.
There arehundreds of other sources of lexical definitionalknowledge available at, among others,  OneLook.comand  YourDictionary.com Dictionary Search websites.A promising recent approach pursued by a number ofNLP and CL researchers is developing knowledgeacquisition and learning methods to automaticallycreate dictionaries and knowledge bases or augmentthe existing ones with system-acquired knowledgefrom corpora of texts  (Iwanska et al, 1999, 2000a),(Harabagiu and Moldovan, 2000), (Rapaport andKibby, 2002), (Reiter and Robertson,2003),(Thompson and Mooney, 2003).1.4 Need for Comparison, IntegrationGiven the variety of sources and definitions forvirtually all words and phrases, a comparisonmechanism is needed in order to address the questionas to which of the sources is the best, the mostcomplete and correct, which definition(s) to use, and,if multiple definitions are valid, in order to identifytheir similarities and differences.We developed a computational mechanism toautomatically compare and, in some cases, integrateknowledge from multiple sources.
Given twodefinitions of a word or phrase, our system computesquantitative measure of distance between them basedon qualitative relations between these definitions:PARTIAL-OVERLAP,    MORE-SPECIFIC /  MORE-GENERAL,DISJOINT.
It highlights similarities and differences.Computed comparison is used to reach the integrate-or-not decision.
If integration is deemed appropriate,the system computes integrated definitions.In our NLP system, we address incompleteness andchanges in meaning through integration of our hand-crafted, modest size dictionary with definitions fromreliable sources.
Our primary sources include existing"respectable" dictionaries, see Table 5, and knowledgeacquired automatically by our system from corpora of"respectable" texts.Automatic knowledge acquisition methods areparticularly useful for acquiring and updating phrasaldefinitional knowledge.
For example, none of theabove mentioned hundreds dictionaries define phrasessuch as "safe environment" or "very fast actions", bothof which were learned by our system  (Iwanska et al,1999, 2000a).Additionally, knowledge acquired from recent textsallows our system to update definitions that changedwith time.
For example, the fourth definition of"document" given by SourceD7 (WordNet), probablyabout ten years ago, is now too restrictive.
Currently,any character, not just 7-bit ASCII character, can beused in a document.
Knowledge acquired by oursystem allowed us to correctly generalize thisdefinition to account for this change.The capability of comparing and integrating lexicalknowledge results in improved performance of ourNLP system.
For example.
In question answering, newquestions can be answered, correctness of someanswers is improved, and some questions can beanswered more completely.
In tasks involvingclassification, groupings arrived via differentdefinitions may be compared and predicted.The rest of the paper is organized as follows: Sect.
2provides a high-level discussion of our meaning andknowledge-level representation of text; Sect.
3 givesalgorithmic details of our comparison and integrationapproach; it also provides a number of examples; Sect.4 and 5 discuss reliable and unreliable sources andmore details about our integration mechanism.2  NL-Motivated  Representation of TextWe discuss briefly our natural language-motivatedrepresentation of text.
Further details, includingquestion answering, representation and reasoning withtext conveying spatio-temporal and probabilisticinformation and knowledge can be found in (Iwanska,1993), (Iwanska, 1996), (Iwanska, 2000b).2.1 Text as Sets of Type EquationsWe represent text by natural language-motivated typeequations with Boolean, set and interval-theoreticsemantics of the following formP   ==   P1,   P2,   ...,   PN .where P's are properties corresponding to textfragments such as noun phrases and verb phrases.Each property is a term, a record-like, graph-like,underspecified structure that consist of two elements1.
head, a type symbol, and2.
body, a possibly empty list of attribute-valuepairsattribute => value  where attributes are symbolsand values are single terms or sets of terms.For example, the sentence "Viruses are extremelysmall infectious substances" is represented by theequationvirus ==substance(size   => small(degree => extremely),infect => infectious) .whose right handside contains one property, a termwith "substance" as its head and two attributes:1. the attribute "size" with the valuesmall(degree => extremely)   which itself is a termwith the type "small" as its head, and oneattribute "degree" with the value "extremely".2. the attribute "infect" with the value"infectious" which is a basic type.2.2 Boolean, Set and Interval-TheoreticSemantics Motivated by Natural LanguageSemantically, terms are subtypes of their head types.For example, the above term represents this subset ofthings of the type "substance" for which the attribute"size" has the value "extremely small" and for whichthe function "infect" yields the value "infectious".The Boolean operations of MEET, JOIN, andCOMPLEMENT simulate conjunction, disjunction andnegation in natural language.
They take terms asarguments and compute conjunctive, disjunctive, andcomplementary terms with the set-intersection, set-union, and set-complement semantics.Efficient computation of arbitrary Booleanexpressions allows the system to compute a number ofsemantics relations among terms, including EQUALreflecting set identity, ENTAILMENT (andSUBSUMPTION, its dual) reflecting set-inclusion,PARTIAL-OVERLAP, reflecting non-empty set-intersection, DISJOINT reflecting empty set-intersection.
These relations allow the system tocompute consequences of knowledge expressed bytext, and therefore compute answers to questions ofthe knowledge base created as the result of processinginput texts, and to update system's knowledge base.Knowledge bases with such type equations are usedbi-directionally: for answering questions about theproperties of entities and concepts in the lefthandsides, and  for matching particular propertiesagainst the right handside properties of entities andconcepts that the system knows about.
We use thesecapabilities to compute comparison as well asintegration of properties in different conceptdefinitions.3 Algorithmic Details3.1 Input1.
Concept C, a word or phrase.
For example, we maybe concerned with the meaning (concept definition) ofthe word "virus" or the phrase "very fast actions".2.
Two knowledge sources Source1 and Source2.
Oursources of definitional knowledge include dictionaries,encyclopedias, personal beliefs obtained viaknowledge engineering methods, and knowledgeautomatically acquired by our NLP system fromcorpora of texts; see Table 5.3.
Concept definitions according to both sourcesSource1: {T1,1, T1,2, ..., T1,N}Source2:        {T2,1,         T2,2,        ...,        T2,M}where each definition Ti,j is text, some number ofsentences or phrases such as noun phrases or verbphrases.
For example, if the word is "virus" and weconsider SourceD1 as Source1, and SourceD2 asSource2, then N=3 and M=6, i.e., we have threedefinitions of "virus" from Source1   { T1,1, T1,2, T1,3}and competing six definitions of "virus" from Source2{ T2,1, T2,2, T2,3, T2,4, T2,5, T2,6 }.
These definitionscorrespond to different senses; note that SourceD2distinguishes two senses 2a., 2b.
; see Tables 4 and 5.3.2 StepsStep 1   Compute representations of word or phrase Cand of each of its textual definitions Ti,j.Step 2   For each pair (T1,k , T2,n) of definitions fromboth sources, compute qualitative relation R betweeneach pair of properties   ( Pi1,k,   Pj2,n )   in the righthandside of the definitions;R can be one and only one of the following:   EQUAL,SMALLER (MORE-SPECIFIC), LARGER (MORE GENERAL),PARTIAL-OVERLAP, or DISJOINT.Step 3   For each pair (T1,k , T2,n) of definitions fromboth sources, compute numeric measure of closenessD between two definitions.This measure whose motivation is similar to (Resnik1999) is a number between 0 and 1 computed basedon qualitative relations R among the properties in bothdefinitions and on proportion of relations indicatingcloseness; EQUAL corresponds to 1, the smallestdistance, SMALLER and LARGER to 0.8, PARTIAL-OVERLAP to 0.6, and DISJOINT to 0, the largestdistance.Step 4   Compute alignment of definitions based onmetric D computed for each pair.
This alignmentshows which definitions from both sources resembleeach other most closely.
For the definitions of "virus"according to SourceD1 and SourceD2, see Table 4,this alignment is((1, 2a),   (2, 2b),   (3, 3),   (-, 1),   (-, 4),   (-, 5)).Step 5   For each pair of aligned definitions, decide ifintegrate and choose integration mode based on thereliability of sources and on the value of D.Step 5a   Compute integrated definition.
Thisintegration, illustrated by examples in Sections 4 and5, involves computing the Boolean operations of meet(conjunction), join (disjunction), and complement(negation) on the properties in the right handside ofthe definitions.Step 5b   Generate English text for theintegrateddefinition.Step 5c   Update system dictionary/knowledgebasewith the integrated definition.3.3 Output1.
Updated system dictionary/knowledgebaseincorporating knowledge from both sources.2.
Alignment of definitions3.
Highlights of similarities and differences betweenpairs of definitions.4 Reliable and Unreliable SourcesDepending whether sources are reliable or not (ingeneral or in terms of specific piece of information orknowledge), we use different integration operations.
Ifboth are reliable, we integrate most aggressively andthe resulting integrated piece reflects fully all that bothsources provided.
If one source may not be reliable, aconservative integration is performed.
Finally, if asource is known or suspected to be unreliable, we firstnegate its information and then fully combine it withall provided by the reliable source.Consider temporal information about the occurence ofan event provided by two sources, different peoplerecalling the same event.Source1:   "It took place in 1992, April or May"Source2:   "It did not happen in early May"Depending whether these sources are consideredreliable or not, we combine their informationdifferently, which results in three possible integratedinformation about the time when the event took place.Information provided by the sources is translated intothe following termsD  = date(month => [ April, May ], 1year  => 1992)D  = date(month => not May(part => early) ) = 2date(month => [ not May,  May(part => not early) ])4.1 Both Sources ReliableIf both sources are considered reliable, we use themeet operation to compute integrated piece ofinformation or knowledge.
This operation, aconjunction with inheritance, incorporates fully allinformation provided by both sources.
For the abovedates, an integrated term is computedD1 MEET D2 = D1 =date(month => [ April, May(part => not early) ],year  => 1992)which gets automatically translated into an Englishphrase   "April or May, but not early May, 1992".4.2 One Source Possibly UnreliableIf one source may not be reliable, but it is not knownwhich one, we use the join operation to integrate.
Thisoperation, a disjunction, incorporates conservativelyinformation provided by both sources.
For the abovedates, the integrated term cannot be simplified, its twoelements are partially overlapping because bothsources provide different aspects of the temporalinformation.D1 JOIN D2 = D2 =[ date(month => [ April, May ],year  => 1992),date(month => not May(part => early)) ]which  gets automatically translated into a disjunctiveEnglish phrase   "April or May, 1992, or not earlyMay".4.3 One Source Reliable, One UnreliableIf one source is considered unreliable, eg.
it is knownor suspected to have lied or to be ignorant, we use thecomplement operation to negate its information.
Therationale is that if information or piece of knowledgeis incorrect, then the actual correct information andknowledge, whatever it may be, is consistent with thenegation of what the source provided.
Thecomplement operation allows us to capture this.
Wethen integrate both terms via the meet operation.
Forthe above dates, the system computes an integratedtermD2neg = not D2 = [ not date,  date(month => May(part => early)) ]D  MEET  D1 2date(month => May(part => early),neg = D3 =year  => 1992)5 Reliable Sources5.1 Partially Overlapping ConceptsDefinitions from different sources frequently denotepartially overlapping concepts.
Overlap exists becauseproperties are described at different levels ofspecificity and because some properties are stated onlyby one source.
If both sources are reliable, we mostlyuse the most aggressive mode of integration, whichcombines all knowledge provided by both sources.
Inthe integrated definition, some properties becomemore specialized (more informative) and some othernew properties are added.An example is a dictionary definition which we updatewith knowledge acquired from texts.
As shown inTable 4, SourceD3 defines "virus" as "a very smallorganism, smaller than a bacterium, which causesdisease in humans, animals and plants", and SourceC1as "extremely small infectious substances (muchsmaller than bacteria)".The integration of the first definition with the secondproduces an integrated definition "an extremely small,infectious organism (substance), much smaller than abacterium, which causes disease in humans, animalsand plants".
Two size-related properties get morespecialized: "very small" becomes "extremely small",and "smaller" becomes "much smaller".
Theseintegrated properties contain strictly more informationthan (entail) the corresponding properties in the olddefinition.
The new property added is "infectious".This is accomplished as follows.First, the representation of definitions is computedvirus( 1 2virusSourceD1) == P1,1,   P 1,1,    P31,1 .
(SourceC1) == P12,1,   P22,1 .P11,1 = organism(size => small(degree => very))P21,1 = smaller(arg2 => bacterium)P31,1 = causes(np => disease(pp => in(np => [ humans, animals, plants ])))P1infect => infectious)2,1 = substance(size  => small(degree => extremely),P2arg2     => bacterium) .2,1 = smaller(quantity => much,Then, relations R for each pair of properties in theright handside of the equations are computed via themeet operation.R(P1 1 1organism(size   => small(degree => extremely),1,1,   P 2,1) = PARTIAL-OVERLAP because P  = P11,1  MEET P12,1 =infect => infectious)P1 LESS-THAN P11,1  and   P1 LESS-THAN P12,1R(P21,1,   P22,1) = MORE-GENERAL (LARGER) because P2 = P21,1  MEET P22,1=smaller(quantity => much,arg2     => bacterium)P2 LESS-THAN P21,1,  P2 = P22,1The relations R for the other pairs of properties areDISJOINT because the meet operation yields termscorresponding to empty set.
D = 2/3 and in theCOMBINE-ALL integration mode, the integrated typeequation has three properties: the integrated propertiesP1 and P2, and the unchanged property P31,1.
Theintegrated  equation isvirus ==organism(size   => small(degree => extremely),infect => infectious) ,smaller(quantity => much,arg2     => bacterium) ,causes(np => disease(pp => in(np => [ humans, animals, plants ]))) .This equation then gets translated into English phrase"an extremely small, infectious organism (substance),much smaller than a bacterium, which causes diseasein humans, animals and plants", in which the order ofproperties mentioned follows the order in the originaldefinition.5.2 Concepts in  MORE-GENERAL  RelationDefinitions from different sources may denoteconcepts in MORE-GENERAL (LARGER) relation.
Forexample, as the following equations reveal, SourceP3definition is strictly more general, i.e., denotes largerset, than definitions from SourceD3 and SourceA1.murderSourceD3 ==  killing(intent => intentionally,object => person) .murderSourceP3 ==  killing(object => human) .murder  ==  killing(intent => wilful, SourceA1agent  => human,object => human) .Such a relation may indicate that one source has adefinition that is too general due to, for example,ignorance.
It can also indicate that a source has adefinition that is overly specific, i.e., not generalizedenough.
We do not have means to automaticallydecide which is the case.
In certain cases, we makesomewhat arbitrary assumptions.For example, if two dictionary definitions are inMORE-GENERAL relation, we integrate by keeping themost specific.
Then, if context requires certainproperties at given level of specificity, we generateshorter, more general definitions via oursummarization/generalization mechanism.
In case ofpersonal beliefs, unless a person is known to be anexpert, we assume that sources such as dictionariesand texts are more correct and integrate accordingly.5.3 Clashes Signal Need to Generalize, CorrectClashes between information and knowledge fromdifferent sources indicate inconsistencies that need tobe resolved.
In our representation, inconsistencies areautomatically detected when the meet operationgenerates a term corresponding to empty set.Some clashes indicate the need to generalize, othersreflect errors or deliberate misrepresentations thatneed to be corrected.
We have a mechansim to identifyclashes, but we do not have automatic way to decidewhat to do about them.
Each time the system generatesa clash, a human has to make the decision what to doabout the clash.This situation is reminiscent of expert systems andknowledge-based systems in that the decision whichpiece of knowledge or which expert is correct does notappear to have a general solution and involves ratherarbitrary assumptions and trust.5.4 Integrating Two Word Senses Into OneThe same source, eg.
dictionary, can be used as if twosources, which allows us to investigate similarities anddifferences between different senses of the same wordor phrase.
In some cases, similarities lead tointegrating two senses into one, thus reducing thenumber of word senses.For example, similarity between partially overlappingsenses of ?virus?
, see Table 4 for definitions 3 and 4from SourceD2, led to one combined sense.
Theoriginal two senses  ?anything that corrupts or poisonsthe mind or character?
and ?something that poisonsthe mind or soul?
are represented as followsvirus ==   [ corrupt, poison ](object   => [ mind, character ]) .virus ==   poison ](object   => [ mind, soul ]) .The conservative, join operation integration combinedwith a machine learning-style inductive leap (add orskip some aspect in order to simplify and/or shortenthe utterance) results in one combined word sensewhich corresponds to the first original sense.6 Discussion, Ongoing and Future Efforts6.1 Short versus LongTextsOur integration mechanism appears to work well whentextual definitions are short texts with not very longsentences and phrases.
This is the case with standarddictionaries and our system acquired knowledgewhich, by design, acquires knowledge in smallportions, short, few sentence-long texts.
We canaccomplish this because for short texts, parsing andcomputing meaning-level representation is possibleand can be done with high levels of precision.Full integration of larger texts such as many pageencyclopedic entries or complete newspaper articles iscurrently not really possible because parsing longsentences and computing meaning-level representationof large texts with high levels of precision remains anopen research problem.6.2 Integrate or NotA really hard part is the integrate-or-not decision.
Ingeneral, it is hard both for humans and systems todecide who is right and which piece of knowledge iscorrect.
So despite having a system capable of fullyautomatic integration, we involve a human in the loop.We look at the system's recommendation, thealignment of different definitions, similarity metricsetc.
and then make this decision by hand.The only alternative appears to make an arbitraryassumption that particular sources are (always) rightor more right than some others.We have a mechanism that, in principle, allows us tointegrate definitions from all existing sources.
Inpractise, we consider a safer road of choosing twoexisting sources and updating them only withknowledeg acquired automatically by our system fromcorpora of  ?respectable?
texts.6.3 Dictionary Entries as Summaries,GeneralizationsOur investigation leads us to believe that dictionaryentries may be summaries and generalizations ofwords' uses over certain contexts.
As such, they wouldconstitute derived, and not primary, resource in peopleand machines.
We plan to continue developingknowledge acquisition and learning methods toautomatically create dictionaries/knowledge basesfrom corpora of texts.
Our approach is to let thesystem acquire as much as possible and as specific aspossible pieces of information and knowledge.
Wethen generate dictionary-like, short, context-relevantdefinitions via our summarization/generalizationmechanism.6.4 Text GenerationEven with shorter text, we encounter many problemswith generating naturally-sounding English text fromour representation.
One problem is that integrationresults in increasingly heavier phrases.
Breaking longphrases into separate sentences with shorter phrasessometimes produces akward texts.Another problem is naturalness, which may meandifferent things in different contexts.
In case ofsynonymous relations, we use two criteria.
The first isfrequency, commonality-based  with preference givento the more commonly used, relative to a corpus,subject matter, or overall.
For example, the word?infectious?
will be preferred to ?pathogenic?, and thephrase ?extremely small?
to ?submicroscopic?.
Thesecond criterion is based on simplicity and size ofutterance.
For example, the word ?submicroscopic?will be preferred to ?extremely small?.It is clear that with progress on processing larger texts,the text generation problems will intensify.ReferencesFellbaum, C., ed 1998.
WordNet An electronic lexicaldatabase , The MIT Press.Harabagiu, S. and Moldovan, D. 2000.
Enriching theWordNet Taxonomy with Contextual Knowledge Acquiredfrom Text.
in Iwanska, L.M., and Shapiro, S.C. eds 2000.Natural Language Processing and KnowledgeRepresentation: Language for Knowledge and Knowledgefor Language The MIT Press.
301-334.Iwanska, L. 1993.
Logical Reasoning in Natural Language:It Is All About Knowledge.
International Journal of Mindsand Machines, 3(4): 475-510.Iwanska, L. 1996.
Natural (Language) Temporal Logic:Reasoning about Absolute and Relative Time".
InternationalJournal of Expert Systems, 9(1): 113-149.Iwanska, L., Mata, N. and Kruger, K. 1999, 2000a.
FullyAutomatic Acquisition of Taxonomic Knowledge fromLarge Corpora of Texts: Limited-Syntax KnowledgeRepresentation System based on Natural Language.Proceedings of the Eleventh International Symposium onMethodologies for Intelligent Information Systems(ISMIS99), Springer-Verlag, pp.
691-697, Warsaw, Poland,1999.
Reprinted in Iwanska, L.M., and Shapiro, S.C. eds2000.
Natural Language Processing and KnowledgeRepresentation: Language for Knowledge and Knowledgefor Language The MIT Press.
335-346.Iwanska, L. 2000b.
Natural Language is a PowerfulKnowledge Representation System: The UNO Model.
InIwanska, L.M., and Shapiro, S.C. eds 2000.
NaturalLanguage Processing and Knowledge Representation:Language for Knowledge and Knowledge for Language TheMIT Press, 7-64.Liu, H. 2003.
Unpacking Meaning from Words: A Context-Centered Approach to Computational Lexicon Design inBlackburn, P. et al eds 2003 Modeling and Using Context ,Proceedings of the 4th International and InterdisciplinaryConference, Lecture Notes in Artificial Intelligence 2680,Berlin, Springer, 218-232.Muresan and Klavans, 2002.
Muresan, S. and Klavans, J. Amethod for automatically building and evaluating dictionaryresources.
Proceedings of the Language Resources andEvaluation Conference (LREC 2002).OneLook.com   Dictionary SearchRapaport, W.J.
and Kibby, M.W.
2002.
ContextualVocabulary Acquisition: A Computational Theory andEducational Curriculum.
in Proceedings of the 6th WorldMulticonference on Systemics, Cybernetics and Informatics(SCI 2002), Orlando, FL, 2002.Reiter, E. and Robertson.
R. 2003 Acquiring CorrectKnowledge for Natural Language Generation Journal ofArtificial Intelligence Research 18:491-516.Resnik, P. 1999.
Semantic Similarity in a Taxonomy: AnInformation-Based Measure and its Application to Problemsof Ambiguity in Natural Language.
Journal of ArtificialIntelligence Research 11:95-130.Thompson, C.A.
and Mooney, R.J. 2003.
Acquiring Word-Meaning Mappings for Natural Language Interfaces Journalof Artificial Intelligence Research 18:1-44.Voorhees, E.M. and Buckland, L.P. eds 2002.
Proceedingsof the Eleventh Text REtrieval Conference (TREC 2002).Department of Commerce, National Institute of Standardsand Technology.YourDictionary.com   Dictionary Search
