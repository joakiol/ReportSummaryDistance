Proceedings of the ACL 2010 Student Research Workshop, pages 55?60,Uppsala, Sweden, 13 July 2010.c?2010 Association for Computational LinguisticsTransition-based parsing with Confidence-Weighted ClassificationMartin HaulrichDept.
of International Language Studies and Computational LinguisticsCopenhagen Business Schoolmwh.isv@cbs.dkAbstractWe show that using confidence-weightedclassification in transition-based parsinggives results comparable to using SVMswith faster training and parsing time.
Wealso compare with other online learningalgorithms and investigate the effect ofpruning features when using confidence-weighted classification.1 IntroductionThere has been a lot of work on data-driven depen-dency parsing.
The two dominating approacheshave been graph-based parsing, e.g.
MST-parsing(McDonald et al, 2005b) and transition-basedparsing, e.g.
the MaltParser (Nivre et al, 2006a).These two approaches differ radically but havein common that the best results have been ob-tained using margin-based machine learning ap-proaches.
For the MST-parsing MIRA (McDonaldet al, 2005a; McDonald and Pereira, 2006) and fortransition-based parsing Support-Vector Machines(Hall et al, 2006; Nivre et al, 2006b).Dredze et al (2008) introduce a new approachto margin-based online learning called confidence-weighted classification (CW) and show that theperformance of this approach is comparable tothat of Support-Vector Machines.
In this workwe use confidence-weighted classification withtransition-based parsing and show that this leadsto results comparable to the state-of-the-art resultsobtained using SVMs.We also compare training time and the effectof pruning when using confidence-weighted learn-ing.2 Transition-based parsingTransition-based parsing builds on the idea thatparsing can be viewed as a sequence of transitionsbetween states.
A transition-based parser (deter-ministic classifier-based parser) consists of threeessential components (Nivre, 2008):1.
A parsing algorithm2.
A feature model3.
A classifierThe focus here is on the classifier but we willbriefly describe the parsing algorithm in order tounderstand the classification task better.The parsing algorithm consists of two com-ponents, a transition system and an oracle.Nivre (2008) defines a transition system S =(C, T, cs, Ct) in the following way:1.
C is a set of configurations, each of whichcontains a buffer ?
of (remaining) nodes anda set A of dependency arcs,2.
T is a set of transitions, each of which is apartial function t : C ?
C,3.
csis a initialization function mapping a sen-tence x = (w0, w1, .
.
.
, wn) to a configura-tion with ?
= [1, .
.
.
, n],4.
Ctis a set of terminal configurations.A transition sequence for a sentence x in S is a se-quence C0,m= (c0, c1.
.
.
, cm) of configurations,such that1.
c0= cs(x),2. cm?
Ct,3.
for every i (1 ?
i ?
m)ci= t(ci?1) for somet ?
TThe oracle is used during training to determine atransition sequence that leads to the correct parse.The job of the classifier is to ?imitate?
the ora-cle, i.e.
to try to always pick the transitions that55lead to the correct parse.
The information given tothe classifier is the current configuration.
There-fore the training data for the classifier consists ofa number of configurations and the transitions theoracle chose with these configurations.Here we focus on stack-based parsing algo-rithms.
A stack-based configuration for a sentencex = (w0, w1, .
.
.
, wn) is a triple c = (?, ?,A),where1.
?
is a stack of tokens i ?
k (for some k ?
n),2. ?
is a buffer of tokens j > k ,3.
A is a set of dependency arcs such that G =(0, 1, .
.
.
, n, A) is a dependency graph for x.
(Nivre, 2008)In the work presented here we use the NivreEageralgorithm which has four transitions:Shift Push the token at the head of the bufferonto the stack.Reduce Pop the token on the top of the stack.Left-ArclAdd to the analysis an arc with label lfrom the token at the head of the buffer to the tokenon the top of the stack, and push the buffer-tokenonto the stack.Right-ArclAdd to the analysis an arc with labell from the token on the top of the stack to the tokenat the head of the buffer, and pop the stack.2.1 ClassificationTransition-based dependency parsing reducesparsing to consecutive multiclass classification.From each configuration one amongst some prede-fined number of transitions has to be chosen.
Thismeans that any classifier can be plugged into thesystem.
The training instances are created by theoracle so the training is offline.
So even thoughwe use online learners in the experiments these areused in a batch setting.The best results have been achieved usingSupport-Vector Machines placing the MaltParservery high in both the CoNNL shared tasks on de-pendency parsing in 2006 and 2007 (Buchholzand Marsi, 2006; Nivre et al, 2007) and it hasbeen shown that SVMs are better for the task thanMemory-based learning (Hall et al, 2006).
Thestandard setting in the MaltParser is to use a 2nd-degree polynomial kernel with the SVM.3 Confidence-weighted classificationDredze et al (2008) introduce confidence-weighted linear classifiers which are online-classifiers that maintain a confidence parameterfor each weight and uses this to control how tochange the weights in each update.
A problemwith online algorithms is that because they haveno memory of previously seen examples they donot know if a given weight has been updated manytimes or few times.
If a weight has been updatedmany times the current estimation of the weight isprobably relatively good and therefore should notbe changed too much.
On the other hand if it hasnever been updated before the estimation is prob-ably very bad.
CW classification deals with thisby having a confidence-parameter for each weight,modeled by a Gaussian distribution, and this pa-rameter is used to make more aggressive updateson weights with lower confidence (Dredze et al,2008).
The classifiers also use Passive-Aggressiveupdates (Crammer et al, 2006) to try to maximizethe margin between positive and negative traininginstances.CW classifiers are online-algorithms and aretherefore fast to train, and it is not necessary tokeep all training examples in memory.
Despite thisthey perform as well or better than SVMs (Dredzeet al, 2008).
Crammer et al (2009) extend the ap-proach to multiclass classification and show thatalso in this setting the classifiers often outperformSVMs.
They show that updating only the weightsof the best of the wrongly classified classes yieldsthe best results.
We also use this approach, calledtop-1, here.Crammer et al (2008) present different update-rules for CW classification and show that the onesbased on standard deviation rather than varianceyield the best results.
Our experiments have con-firmed this, so in all experiments the update-rulefrom equation 10 (Crammer et al, 2008) is used.4 Experiments4.1 SoftwareWe use the open-source parser MaltParser1forall experiments.
We have integrated confidence-weighted, perceptron and MIRA classifiers intothe code.
The code for the online classifiers has1We have used version 1.3.1, available at maltparser.org56been made available by the authors of the CW-papers.4.2 DataWe have used the 10 smallest data sets fromCoNNL-X (Buchholz and Marsi, 2006) in our ex-periments.
Evaluation has been done with the offi-cial evaluation script and evaluation data from thistask.4.3 FeaturesThe standard setting for the MaltParser is to useSVMs with polynomial kernels, and because ofthis it uses a relatively small number of features.In most of our experiments the default feature setof MaltParser consisting of 14 features has beenused.When using a linear-classifier without a ker-nel we need to extend the feature set in order toachieve good results.
We have done this very un-critically by adding all pair wise combinations ofall features.
This leads to 91 additional featureswhen using the standard 14 features.5 Results and discussionWe will now discuss various results of our ex-periments with using CW-classifiers in transition-based parsing.5.1 Online classifiersWe compare CW-classifiers with other online al-gorithms for linear classification.
We comparewith perceptron (Rosenblatt, 1958) and MIRA(Crammer et al, 2006).
With both these classi-fiers we use the same top-1 approach as with theCW-classifers and also averaging which has beenshown to alleviate overfitting (Collins, 2002).
Ta-ble 2 shows Labeled Attachment Score obtainedwith the three online classifiers.
All classifierswere trained with 10 iterations.These results confirm those by Crammer et al(2009) and show that confidence-weighted classi-fiers are better than both perceptron and MIRA.5.2 Training and parsing timeThe training time of the CW-classifiers depends onthe number of iterations used, and this of courseaffects the accuracy of the parser.
Figure 1 showsLabeled Attachment Score as a function of thenumber of iterations used in training.
The hori-zontal line shows the LAS obtained with SVM.2 4 6 8 1079.079.580.080.581.0IterationsLASFigure 1: LAS as a function of number of trainingiterations on Danish data.
The dotted horizontalline shows the performance of the parser trainedwith SVM.We see that after 4 iterations the CW-classifierhas the best performance for the data set (Danish)used in this experiment.
In most experiments wehave used 10 iterations.
Table 1 compares trainingtime (10 iterations) and parsing time of a parserusing a CW-classifiers and a parser using SVM onthe same data set.
We see that training of the CW-classifier is faster, which is to be expected giventheir online-nature.
We also see that parsing ismuch faster.SVM CWTraining 75 min 8 minParsing 29 min 1.5 minTable 1: Training and parsing time on Danish data.5.3 Pruning featuresBecause we explicitly represent pair wise combi-nations of all of the original features we get an ex-tremely high number of binary features.
For someof the larger data sets, the number of features isso big that we cannot hold the weight-vector inmemory.
For instance the Czech data-set has 16million binary features, and almost 800 classes -which means that in practice there are 12 billionbinary features2.2Which is also why we only have used the 10 smallestdata sets from CoNNL-X.57Perceptron MIRA CW, manual fs CW SVMArabic 58.03 59.19 60.55 ?60.57 59.93Bulgarian 80.46 81.09 82.57 ?82.76 82.12Danish 79.42 79.90 81.06 ?81.13 80.18Dutch 75.75 77.47 77.65 ?78.65 77.76Japanese 87.74 88.06 88.14 88.19 ?89.47Portuguese 85.69 85.95 86.11 86.20 86.25Slovene 64.35 65.38 66.09 ?66.28 65.45Spanish 74.06 74.86 75.58 75.90 75.46Swedish 79.79 80.31 81.03 ?81.24 80.56Turkish 46.48 47.13 46.98 47.09 47.49All 78.26 79.00 79.68 ?79.86 79.59Table 2: LAS on development data for three online classifers, CW-classifiers with manual feature se-lection and SVM.
Statistical significance is measuered between CW-classifiers without feature selectionand SVMs.To solve this problem we have tried to use prun-ing to remove the features occurring fewest timesin the training data.
If a feature occurs fewer timesthan a given cutoff limit the feature is not included.This goes against the idea of CW classifiers whichare exactly developed so that rare features can beused.
Experiments also show that this pruninghurts accuracy.
Figure 2 shows the labeled attach-ment score as a function of the cutoff limit on theDanish data.Cutoff limitLAS0 2 4 6 8 1079.580.080.581.050000010000001500000Figure 2: LAS as a function of the cutoff limitwhen pruning rare features.
The dotted line showsthe number of features left after pruning.5.4 Manual feature selectionInstead of pruning the features we tried manuallyremoving some of the pair wise feature combina-tions.
We removed some of the combinations thatlead to the most extra features, which is especiallythe case with combinations of lexical features.
Inthe extended default feature set for instance we re-moved all combinations of lexical features exceptthe combination of the word form of the token atthe top of the stack and of the word form of thetoken at the head of the buffer.Table 2 shows that this consistently leads to asmall decreases in LAS.5.5 Results without optimizationTable 2 shows the results for the 10 CoNNL-Xdata sets used.
For comparison we have includedthe results from using the standard classifier in theMaltParser, i.e.
SVM with a polynomial kernel.The hyper-parameters for the SVM have not beenoptimized, and neither has the number of iterationsfor the CW-classifiers, which is always 10.
We seethat in many cases the CW-classifier does signifi-cantly3better than the SVM, but that the oppositeis also the case.5.6 Results with optimizationThe results presented above are suboptimal for theSVMs because default parameters have been usedfor these, and optimizing these can improve ac-3In all tables statistical significance is marked with ?.
Sig-nificance is calculated using McNemar?s test (p = 0.05).These tests were made with MaltEval (Nilsson and Nivre,2008)58SVM CWLAS UAS LA LAS UAS LAArabic 66.71 77.52 80.34 67.03 77.52 ?81.20Bulgarian* 87.41 91.72 90.44 87.25 91.56 89.77Danish ?84.77 ?89.80 89.16 84.15 88.98 88.74Dutch* ?78.59 ?81.35 ?83.69 77.21 80.21 82.63Japanese ?91.65 ?93.10 ?94.34 90.41 91.96 93.34Portuguese* ?87.60 ?91.22 ?91.54 86.66 90.58 90.34Slovene 70.30 78.72 80.54 69.84 ?79.62 79.42Spanish 81.29 84.67 90.06 82.09 ?85.55 90.52Swedish* ?84.58 89.50 87.39 83.69 89.11 87.01Turkish ?65.68 ?75.82 ?78.49 62.00 73.15 76.12All ?79.86 ?85.35 ?86.60 79.04 84.83 85.91Table 3: Results on the CoNNL-X evaluation data.
Manuel feature selection has been used for languagesmarked with an *.curacy a lot.
In this section we will compare re-sults obtained with CW-classifiers with the resultsfor the MaltParser from CoNNL-X.
In CoNNL-Xboth the hyper parameters for the SVMs and thefeatures have been optimized.
Here we do not dofeature selection but use the features used by theMaltParser in CoNNL-X4.The only hyper parameter for CW classificationis the number of iterations.
We optimize this bydoing 5-fold cross-validation on the training data.Although the manual feature selection has beenshown to decrease accuracy this has been used forsome languages to reduce the size of the model.The results are presented in table 3.We see that even though the feature set usedare optimized for the SVMs there are not big dif-ferences between the parses that use SVMs andthe parsers that use CW classification.
In generalthough the parsers with SVMs does better thanthe parsers with CW classifiers and the differenceseems to be biggest on the languages where we didmanual feature selection.6 ConclusionWe have shown that using confidence-weightedclassifiers with transition-based dependency pars-ing yields results comparable with the state-of-the-art results achieved with Support Vector Machines- with faster training and parsing times.
Currentlywe need a very high number of features to achievethese results, and we have shown that pruning thisbig feature set uncritically hurts performance of4Available at http://maltparser.org/conll/conllx/the confidence-weighted classifiers.7 Future workCurrently the biggest challenge in the approachoutlined here is the very high number of featuresneeded to achieve good results.
A possible so-lution is to use kernels with confidence-weightedclassification in the same way they are used withthe SVMs.Another possibility is to extend the feature setin a more critical way than what is done now.
Forinstance the combination of a POS-tag and CPOS-tag for a given word is now included.
This featuredoes not convey any information that the POS-tag-feature itself does not.
The same is the case forsome word-form and word-lemma features.
All inall a lot of non-informative features are added asthings are now.
We have not yet tried to use auto-matic features selection to select only the combi-nations that increase accuracy.We will also try to do feature selection on amore general level as this can boost accuracy a lot.The results in table 3 are obtained with the featuresoptimized for the SVMs.
These are not necessarilythe optimal features for the CW-classifiers.Another comparison we would like to do is withlinear SVMs.
Unlike the polynomial kernel SVMsused as default in the MaltParser linear SVMs canbe trained in linear time (Joachims, 2006).
Tryingto use the same extended feature set we use withthe CW-classifiers with a linear SVM would pro-vide an interesting comparison.598 AcknowledgementsThe author thanks three anonymous reviewers andAnders S?gaard for their helpful comments andthe authors of the CW-papers for making theircode available.ReferencesSabine Buchholz and Erwin Marsi.
2006.
Conll-x shared task on multilingual dependency parsing.In Proceedings of the Tenth Conference on Com-putational Natural Language Learning (CoNLL-X),pages 149?164, New York City, June.
Associationfor Computational Linguistics.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: theory and experi-ments with perceptron algorithms.
In EMNLP ?02:Proceedings of the ACL-02 conference on Empiri-cal methods in natural language processing, pages1?8, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Koby Crammer, Ofer Dekel, Joseph Keshet, ShaiShalev-Shwartz, and Yoram Singer.
2006.
On-line passive-aggressive algorithms.
J. Mach.
Learn.Res., 7:551?585.Koby Crammer, Mark Dredze, and Fernando Pereira.2008.
Exact convex confidence-weighted learning.In Daphne Koller, Dale Schuurmans, Yoshua Ben-gio, and L?eon Bottou, editors, NIPS, pages 345?352.MIT Press.Koby Crammer, Mark Dredze, and Alex Kulesza.2009.
Multi-class confidence weighted algorithms.In Proceedings of the 2009 Conference on Empiri-cal Methods in Natural Language Processing, pages496?504, Singapore, August.
Association for Com-putational Linguistics.Mark Dredze, Koby Crammer, and Fernando Pereira.2008.
Confidence-weighted linear classification.
InICML ?08: Proceedings of the 25th internationalconference on Machine learning, pages 264?271,New York, NY, USA.
ACM.Johan Hall, Joakim Nivre, and Jens Nilsson.
2006.Discriminative classifiers for deterministic depen-dency parsing.
In Proceedings of the COLING/ACL2006 Main Conference Poster Sessions, pages 316?323, Sydney, Australia, July.
Association for Com-putational Linguistics.Thorsten Joachims.
2006.
Training linear svms inlinear time.
In KDD ?06: Proceedings of the 12thACM SIGKDD international conference on Knowl-edge discovery and data mining, pages 217?226,New York, NY, USA.
ACM.Ryan T. McDonald and Fernando C. N. Pereira.
2006.Online learning of approximate dependency parsingalgorithms.
In EACL.
The Association for ComputerLinguistics.Ryan T. McDonald, Koby Crammer, and FernandoC.
N. Pereira.
2005a.
Online large-margin train-ing of dependency parsers.
In ACL.
The Associationfor Computer Linguistics.Ryan T. McDonald, Fernando Pereira, Kiril Ribarov,and Jan Hajic.
2005b.
Non-projective depen-dency parsing using spanning tree algorithms.
InHLT/EMNLP.
The Association for ComputationalLinguistics.Jens Nilsson and Joakim Nivre.
2008.
Malteval:An evaluation and visualization tool for dependencyparsing.
In Proceedings of the Sixth InternationalLanguage Resources and Evaluation, Marrakech,Morocco, May.
LREC.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006a.Maltparser: A data-driven parser-generator for de-pendency parsing.
In Proceedings of the fifth in-ternational conference on Language Resources andEvaluation (LREC2006), pages 2216?2219, May.Joakim Nivre, Johan Hall, Jens Nilsson, G?uls?enEryi?git, and Svetoslav Marinov.
2006b.
Labeledpseudo-projective dependency parsing with supportvector machines.
In Proceedings of the Tenth Con-ference on Computational Natural Language Learn-ing (CoNLL-X), pages 221?225, New York City,June.
Association for Computational Linguistics.Joakim Nivre, Johan Hall, Sandra K?ubler, Ryan Mc-Donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007.
The CoNLL 2007 shared task on de-pendency parsing.
In Proceedings of the CoNLLShared Task Session of EMNLP-CoNLL 2007, pages915?932.Joakim Nivre.
2008.
Algorithms for deterministic in-cremental dependency parsing.
Computational Lin-guistics, 34(4):513?553.Frank Rosenblatt.
1958.
The perceptron: A probabilis-tic model for information storage and organization inthe brain.
Psychological Review, 65(6):386?408.60
