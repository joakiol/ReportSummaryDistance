Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 378?382,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsTokenization: Returning to a Long Solved ProblemA Survey, Contrastive Experiment, Recommendations, and ToolkitRebecca Dridan & Stephan OepenInstitutt for Informatikk, Universitetet i Oslo{rdridan |oe}@ifi.uio.noAbstractWe examine some of the frequently disre-garded subtleties of tokenization in Penn Tree-bank style, and present a new rule-based pre-processing toolkit that not only reproduces theTreebank tokenization with unmatched accu-racy, but also maintains exact stand-off point-ers to the original text and allows flexible con-figuration to diverse use cases (e.g.
to genre-or domain-specific idiosyncrasies).1 Introduction?MotivationThe task of tokenization is hardly counted among thegrand challenges of NLP and is conventionally in-terpreted as breaking up ?natural language text [...]into distinct meaningful units (or tokens)?
(Kaplan,2005).
Practically speaking, however, tokeniza-tion is often combined with other string-level pre-processing?for example normalization of punctua-tion (of different conventions for dashes, say), dis-ambiguation of quotation marks (into opening vs.closing quotes), or removal of unwanted mark-up?where the specifics of such pre-processing dependboth on properties of the input text as well as on as-sumptions made in downstream processing.Applying some string-level normalization prior tothe identification of token boundaries can improve(or simplify) tokenization, and a sub-task like thedisambiguation of quote marks would in fact be hardto perform after tokenization, seeing that it dependson adjacency to whitespace.
In the following, wethus assume a generalized notion of tokenization,comprising all string-level processing up to and in-cluding the conversion of a sequence of characters(a string) to a sequence of token objects.11Obviously, some of the normalization we include in the to-kenization task (in this generalized interpretation) could be leftto downstream analysis, where a tagger or parser, for example,could be expected to accept non-disambiguated quote marks(so-called straight or typewriter quotes) and disambiguate asArguably, even in an overtly ?separating?
lan-guage like English, there can be token-level ambi-guities that ultimately can only be resolved throughparsing (see ?
3 for candidate examples), and indeedWaldron et al (2006) entertain the idea of down-stream processing on a token lattice.
In this article,however, we accept the tokenization conventionsand sequential nature of the Penn Treebank (PTB;Marcus et al, 1993) as a useful point of reference?primarily for interoperability of different NLP tools.Still, we argue, there is remaining work to be doneon PTB-compliant tokenization (reviewed in?
2),both methodologically, practically, and technologi-cally.
In ?
3 we observe that state-of-the-art toolsperform poorly on re-creating PTB tokenization, andmove on in ?
4 to develop a modular, parameteri-zable, and transparent framework for tokenization.Besides improvements in tokenization accuracy andadaptability to diverse use cases, in ?
5 we furtherargue that each token object should unambiguouslylink back to an underlying element of the originalinput, which in the case of tokenization of text werealize through a notion of characterization.2 Common ConventionsDue to the popularity of the PTB, its tokenizationhas been a de-facto standard for two decades.
Ap-proximately, this means splitting off punctuationinto separate tokens, disambiguating straight quotes,and separating contractions such as can?t into caand n?t.
There are, however, many special cases?part of syntactic analysis.
However, on the (predominant) pointof view that punctuation marks form tokens in their own right,the tokenizer would then have to adorn quote marks in someway, as to whether they were split off the left or right periph-ery of a larger token, to avoid unwanted syntactic ambiguity.Further, increasing use of Unicode makes texts containing ?na-tively?
disambiguated quotes more common, where it wouldseem unfortunate to discard linguistically pertinent informationby normalizing towards the poverty of pure ASCII punctuation.378documented and undocumented.
In much taggingand parsing work, PTB data has been used withgold-standard tokens, to a point where many re-searchers are unaware of the existence of the orig-inal ?raw?
(untokenized) text.
Accordingly, the for-mal definition of PTB tokenization2 has received lit-tle attention, but reproducing PTB tokenization au-tomatically actually is not a trivial task (see ?
3).As the NLP community has moved to process dataother than the PTB, some of the limitations of thePTB tokenization have been recognized, and manyrecently released data sets are accompanied by anote on tokenization along the lines of: Tokenizationis similar to that used in PTB, except .
.
.
Most ex-ceptions are to do with hyphenation, or special formsof named entities such as chemical names or URLs.None of the documentation with extant data sets issufficient to fully reproduce the tokenization.3The CoNLL 2008 Shared Task data actually pro-vided two forms of tokenization: that from the PTB(which many pre-processing tools would have beentrained on), and another form that splits (most) hy-phenated terms.
This latter convention recentlyseems to be gaining ground in data sets like theGoogle 1T n-gram corpus (LDC #2006T13) andOntoNotes (Hovy et al, 2006).
Clearly, as onemoves towards a more application- and domain-driven idea of ?correct?
tokenization, a more trans-parent, flexible, and adaptable approach to string-level pre-processing is called for.3 A Contrastive ExperimentTo get an overview of current tokenization methods,we recovered and tokenized the raw text which wasthe source of the (Wall Street Journal portion of the)PTB, and compared it to the gold tokenization in thesyntactic annotation in the treebank.4 We used threecommon methods of tokenization: (a) the original2See http://www.cis.upenn.edu/~treebank/tokenization.html for available ?documentation?
and ased script for PTB-style tokenization.3?vrelid et al (2010) observe that tokenizing with the GE-NIA tagger yields mismatches in one of five sentences of theGENIA Treebank, although the GENIA guidelines refer toscripts that may be available on request (Tateisi & Tsujii, 2006).4The original WSJ text was last included with the 1995 re-lease of the PTB (LDC #95T07) and required alignment withthe treebank, with some manual correction so that the same textis represented in both raw and parsed formats.Tokenization Differing LevenshteinMethod Sentences Distancetokenizer.sed 3264 11168CoreNLP 1781 3717C&J parser 2597 4516Table 1: Quantitative view on tokenization differences.PTB tokenizer.sed script; (b) the tokenizer from theStanford CoreNLP tools5; and (c) tokenization fromthe parser of Charniak & Johnson (2005).
Table 1shows quantitative differences between each of thethree methods and the PTB, both in terms of thenumber of sentences where the tokenization differs,and also in the total Levenshtein distance (Leven-shtein, 1966) over tokens (for a total of 49,208 sen-tences and 1,173,750 gold-standard tokens).Looking at the differences qualitatively, the mostconsistent issue across all tokenization methods wasambiguity of sentence-final periods.
In the treebank,final periods are always (with about 10 exceptions)a separate token.
If the sentence ends in U.S. (butnot other abbreviations, oddly), an extra period ishallucinated, so the abbreviation also has one.
Incontrast, C&J add a period to all final abbreviations,CoreNLP groups the final period with a final abbre-viation and hence lacks a sentence-final period to-ken, and the sed script strips the period off U.S.
The?correct?
choice in this case is not obvious and willdepend on how the tokens are to be used.The majority of the discrepancies in the sed scripttokenization come from an under-restricted punctu-ation rule that incorrectly splits on commas withinnumbers or ampersands within names.
Other thanthat, the problematic cases are mostly shared acrosstokenization methods, and include issues with cur-rencies, Irish names, hyphenization, and quote dis-ambiguation.
In addition, C&J make some addi-tional modifications to the text, lemmatising expres-sions such as won?t as will and n?t.4 REPP: A Generalized FrameworkFor tokenization to be studied as a first-class prob-lem, and to enable customization and flexibility todiverse use cases, we suggest a non-procedural,rule-based framework dubbed REPP (Regular5See http://nlp.stanford.edu/software/corenlp.shtml, run in ?strictTreebank3?
mode.379>wiki#1!([?
])([])}?!,;:??])
([?
]|$) \1 \2 \3!(?|[? ])
([[({??])([? ])
\1 \2 \3#>1:[[:space:]]+Figure 1: Simplified examples of tokenization rules.Expression-Based Pre-Processing)?essentially acascade of ordered finite-state string rewriting rules,though transcending the formal complexity of regu-lar languages by inclusion of (a) full perl-compatibleregular expressions and (b) fixpoint iteration overgroups of rules.
In this approach, a first phase ofstring-level substitutions inserts whitespace around,for example, punctuation marks; upon completion ofstring rewriting, token boundaries are stipulated be-tween all whitespace-separated substrings (and onlythese).For a good balance of human and machine read-ability, REPP tokenization rules are specified in asimple, line-oriented textual form.
Figure 1 showsa (simplified) excerpt from our PTB-style tokenizer,where the first character on each line is one of fourREPP operators, as follows: (a) ?#?
for group forma-tion; (b) ?>?
for group invocation, (c) ?!?
for substi-tution (allowing capture groups), and (d) ?:?
for to-ken boundary detection.6 In Figure 1, the two rulesstripping off prefix and suffix punctuation marks ad-jacent to whitespace (i.e.
matching the tab-separatedleft-hand side of the rule, to replace the match withits right-hand side) form a numbered group (?#1?
),which will be iterated when called (?>1?)
until noneof the rules in the group fires (a fixpoint).
In this ex-ample, conditioning on whitespace adjacency avoidsthe issues observed with the PTB sed script (e.g.
to-ken boundaries within comma-separated numbers)and also protects against infinite loops in the group.7REPP rule sets can be organized as modules, typ-6Strictly speaking, there are another two operators, for line-oriented comments and automated versioning of rule files.7For this example, the same effects seemingly could be ob-tained without iteration (using greatly more complex rules); ouractual, non-simplified rules, however, further deal with punctu-ation marks that can function as prefixes or suffixes, as well aswith corner cases like factor(s) or Ca[2+].
Also in mark-up re-moval and normalization, we have found it necessary to ?parse?nested structures by means of iterative groups.ically each in a file of its own, and invoked selec-tively by name (e.g.
?>wiki?
in Figure 1); to date,there exist modules for quote disambiguation, (rele-vant subsets of) various mark-up languages (HTML,LATEX, wiki, and XML), and a handful of robust-ness rules (e.g.
seeking to identify and repair ?sand-wiched?
inter-token punctuation).
Individual tok-enizers are configured at run-time, by selectively ac-tivating a set of modules (through command-line op-tions).
An open-source reference implementation ofthe REPP framework (in C++) is available, togetherwith a library of modules for English.5 Characterization for TraceabilityTokenization, and specifically our notion of gener-alized tokenization which allows text normalization,involves changes to the original text being analyzed,rather than just additional annotation.
As such, fulltraceability from the token objects to the originaltext is required, which we formalize as ?character-ization?, in terms of character position links back tothe source.8 This has the practical benefit of allow-ing downstream analysis as direct (stand-off) anno-tation on the source text, as seen for example in theACL Anthology Searchbench (Sch?fer et al, 2011).With our general regular expression replacementrules in REPP, making precise what it means for atoken to link back to its ?underlying?
substring re-quires some care in the design and implementation.Definite characterization links between the stringbefore (I) and after (O) the application of a sin-gle rule can only be established in certain positions,viz.
(a) spans not matched by the rule: unchangedtext in O outside the span matched by the left-handside regex of the rule can always be linked back toI; and (b) spans caught by a regex capture group:capture groups represent the same text in the left-and right-hand sides of a substitution, and so can belinked back to O.9 Outside these text spans, we canonly make definite statements about characterizationlinks at boundary points, which include the start andend of the full string, the start and end of the string8If the tokenization process was only concerned with theidentification of token boundaries, characterization would benear-trivial.9If capture group references are used out-of-order, however,the per-group linkage is no longer well-defined, and we resortto the maximum-span ?union?
of boundary points (see below).380matched by the rule, and the start and end of anycapture groups in the rule.Each character in the string being processed hasa start and end position, marking the point beforeand after the character in the original string.
Beforeprocessing, the end position would always be onegreater than the start position.
However, if a rulemapped a string-initial, PTB-style opening doublequote (``) to one-character Unicode ?, the new firstcharacter of the string would have start position 0,but end position 2.
In contrast, if there were a rule!wo(n?t) will \1 (1)applied to the string I won?t go!, all characters in thesecond token of the resulting string (I will n?t go!
)will have start position 2 and end position 4.
Thisdemonstrates one of the formal consequences of ourdesign: we have no reason to assign the characters illany start position other than 2.10 Since explicit char-acter links between each I and O will only be estab-lished at match or capture group boundaries, any textfrom the left-hand side of a rule that should appear inO must be explicitly linked through a capture groupreference (rather than merely written out in the right-hand side of the rule).
In other words, rule (1) aboveshould be preferred to the following variant (whichwould result in character start and end offsets of 0and 5 for both output tokens):!won?t will n?t (2)During rule application, we keep track of charac-ter start and end positions as offsets between a stringbefore and after each rule application (i.e.
all pairs?I,O?
), and these offsets are eventually traced backto the original string at the time of final tokenization.6 Quantitative and Qualitative EvaluationIn our own work on preparing various (non-PTB)genres for parsing, we devised a set of REPP ruleswith the goal of following the PTB conventions.When repeating the experiment of ?
3 above us-ing REPP tokenization, we obtained an initial dif-ference in 1505 sentences, with a Levenshtein dis-10This subtlety will actually be invisible in the final tokenobjects if will remains a single token, but if subsequent ruleswere to split this token further, all its output tokens would have astart position of 2 and an end position of 4.
While this examplemay seem unlikely, we have come across similar scenarios infine-tuning actual REPP rules.tance of 3543 (broadly comparable to CoreNLP, ifmarginally more accurate).Examining these discrepancies, we revealed somedeficiencies in our rules, as well as some peculiari-ties of the ?raw?
Wall Street Journal text from thePTB distribution.
A little more than 200 mismatcheswere owed to improper treatment of currency sym-bols (AU$) and decade abbreviations (?60s), whichled to the refinement of two existing rules.
NotablePTB idiosyncrasies (in the sense of deviations fromcommon typography) include ellipses with spacesseparating the periods and a fairly large number ofpossessives (?s) being separated from their preced-ing token.
Other aspects of gold-standard PTB tok-enization we consider unwarranted ?damage?
to theinput text, such as hallucinating an extra period af-ter U.S. and splitting cannot (which adds spuri-ous ambiguity).
For use cases where the goal werestrict compliance, for instance in pre-processing in-puts for a PTB-derived parser, we added an optionalREPP module (of currently half a dozen rules) tocater to these corner cases?in a spirit similar to theCoreNLP mode we used in ?
3.
With these extrarules, remaining tokenization discrepancies are con-tained in 603 sentences (just over 1%), which givesa Levenshtein distance of 1389.7 Discussion?ConclusionCompared to the best-performing off-the-shelf sys-tem in our earlier experiment (where it is reason-able to assume that PTB data has played at leastsome role in development), our results eliminate twothirds of the remaining tokenization errors?a moresubstantial reduction than recent improvements inparsing accuracy against the PTB, for example.Of the remaining differences, over 350 are con-cerned with mid-sentence period ambiguity, whereat least half of those are instances where a pe-riod was separated from an abbreviation in thetreebank?a pattern we do not wish to emulate.Some differences in quote disambiguation also re-main, often triggered by whitespace on both sides ofquote marks in the raw text.
The final 200 or so dif-ferences stem from manual corrections made duringtreebanking, and we consider that these cases couldnot be replicated automatically in any generalizablefashion.381ReferencesCharniak, E., & Johnson, M. (2005).
Coarse-to-finen-best parsing and maxent discriminative rerank-ing.
In Proceedings of the 43rd Annual Meetingof the Association for Computational Linguistics(pp.
173?180).
Ann Arbor, USA.Hovy, E., Marcus, M., Palmer, M., Ramshaw, L.,& Weischedel, R. (2006).
Ontonotes.
The 90%solution.
In Proceedings of the Human Lan-guage Technology Conference of the North Amer-ican Chapter of the Association for Computa-tional Linguistics (pp.
57?60).
New York City,USA.Kaplan, R. M. (2005).
A method for tokenizingtext.
Festschrift for Kimmo Koskenniemi on his60th birthday.
In A. Arppe, L. Carlson, K. Lind?n,J.
Piitulainen, M. Suominen, M. Vainio, H. West-erlund, & A. Yli-Jyr?
(Eds.
), Inquiries into words,constraints and contexts (pp.
55 ?
64).
Stanford,CA: CSLI Publications.Levenshtein, V. (1966).
Binary codes capable of cor-recting deletions, insertions and reversals.
SovietPhysice ?
Doklady, 10, 707?710.Marcus, M. P., Santorini, B., & Marcinkiewicz,M.
A.
(1993).
Building a large annotated corpusof English.
The Penn Treebank.
ComputationalLinguistics, 19, 313 ?
330.?vrelid, L., Velldal, E., & Oepen, S. (2010).
Syn-tactic scope resolution in uncertainty analysis.
InProceedings of the 23rd international conferenceon computational linguistics (pp.
1379 ?
1387).Beijing, China.Sch?fer, U., Kiefer, B., Spurk, C., Steffen, J., &Wang, R. (2011).
The ACL Anthology Search-bench.
In Proceedings of the ACL-HLT 2011 sys-tem demonstrations (pp.
7?13).
Portland, Oregon,USA.Tateisi, Y., & Tsujii, J.
(2006).
GENIA anno-tation guidelines for tokenization and POS tag-ging (Technical Report # TR-NLP-UT-2006-4).Tokyo, Japan: Tsujii Lab, University of Tokyo.Waldron, B., Copestake, A., Sch?fer, U., & Kiefer,B.
(2006).
Preprocessing and tokenisation stan-dards in DELPH-IN tools.
In Proceedings of the5th International Conference on Language Re-sources and Evaluation (pp.
2263 ?
2268).
Genoa,Italy.382
