Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 124?132,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsFrame Semantics for Stance ClassificationKazi Saidul Hasan and Vincent NgHuman Language Technology Research InstituteUniversity of Texas at DallasRichardson, TX 75083-0688{saidul,vince}@hlt.utdallas.eduAbstractDetermining the stance expressed by anauthor from a post written for a two-sideddebate in an online debate forum is arelatively new problem in opinion min-ing.
We extend a state-of-the-art learning-based approach to debate stance classifica-tion by (1) inducing lexico-syntactic pat-terns based on syntactic dependencies andsemantic frames that aim to capture themeaning of a sentence and provide a gen-eralized representation of it; and (2) im-proving the classification of a test post viaa novel way of exploiting the informationin other test posts with the same stance.Empirical results on four datasets demon-strate the effectiveness of our extensions.1 IntroductionGiven a post written for a two-sided topic in anonline debate forum (e.g., ?Should abortion be al-lowed??
), the task of debate stance classificationinvolves determining which of the two sides (i.e.,for or against) its author is taking.
For example, astance classification system should determine thatthe author of the following post is anti-abortion.Post 1: Abortion has been legal for decades and noone seems to have a problem with it.
That?s ridicu-lous!
There are millions of people in the worldwho would love to have children but can?t.Previous approaches to debate stance classifica-tion have focused on three debate settings, namelycongressional floor debates (Thomas et al 2006;Bansal et al 2008; Balahur et al 2009; Yesse-nalina et al 2010; Burfoot et al 2011), company-internal discussions (Murakami and Raymond,2010), and online social, political, and ideologi-cal debates in public forums (Agrawal et al 2003;Somasundaran and Wiebe, 2010; Wang and Rose?,2010; Biran and Rambow, 2011; Hasan and Ng,2012).
As Walker et al(2012) point out, debatesin public forums differ from congressional debatesand company-internal discussions in terms of lan-guage use.
Specifically, online debaters use color-ful and emotional language to express their points,which may involve sarcasm, insults, and question-ing another debater?s assumptions and evidence.These properties can potentially make stance clas-sification of online debates more challenging thanthat of the other two types of debates.Our goal in this paper is to improve the stateof the art in stance classification of online de-bates, focusing in particular on ideological de-bates.
Specifically, we present two extensions,one linguistic and the other extra-linguistic, tothe state-of-the-art supervised learning approachto this task proposed by Anand et al(2011).
In ourlinguistic extension, we induce patterns from eachsentence in the training set using syntactic depen-dencies and semantic frames that aim to capturethe meaning of a sentence and provide a general-ized representation of it.
Note that while Anand etal.
?s lexico-syntactic approach aims to generalizefrom a sentence using syntactic dependencies, weaim to generalize using semantic frames.
As wewill see in Section 4, not only is there no guaran-tee that syntactic dependencies can retain or suf-ficiently capture the meaning of a sentence duringthe generalization process, it is in fact harder togeneralize from syntactic dependencies than fromsemantic frames.
In our extra-linguistic extension,we improve the classification of a test post via anovel way of exploiting the information in othertest posts with the same stance.We evaluate our approach to stance classifica-tion of ideological debates on datasets collectedfor four domains from online debate forums.
Ex-perimental results demonstrate the effectiveness ofour approach: it outperforms an improved versionof Anand et als approach by 2.6?7.0 accuracypoints on the four domains.124Number of % of ?for?Domain posts postsABO 1741 54.9GAY 1376 63.4OBA 985 53.9MAR 626 69.5Table 1: Statistics of the four datasets.The rest of the paper is organized as follows.We first present our datasets in Section 2.
Sec-tion 3 describes our two learning-based baselinesystems for stance classification.
Sections 4 and 5discuss our two extensions.
Finally, we show eval-uation results in Section 6 and present conclusionsin Section 7.2 DatasetsFor our experiments, we collect debate postsfrom four popular domains, Abortion (ABO),Gay Rights (GAY), Obama (OBA), and Marijuana(MAR).
Each post should receive one of two do-main labels, for or against, depending on whetherthe author of the post supports or opposes abor-tion, gay rights, Obama, or the legalization of mar-ijuana.
To see how we obtain these domain labels,let us first describe the data collection process inmore detail.We collect our debate posts for the four domainsfrom an online debate forum1.
In each domain,there are several two-sided debates.
Each debatehas a subject (e.g., ?Abortion should be banned?
)for which a number of posts were written by dif-ferent authors.
Each post is manually tagged withits author?s stance (i.e., yes or no) on the debatesubject.
Since the label of each post represents thesubject stance but not the domain stance, we needto automatically convert the former to the latter.For example, for the subject ?Abortion should bebanned?, the subject stance yes implies that the au-thor opposes abortion, and hence the domain labelfor the corresponding label should be against.We construct one dataset for each domain.Statistics of these datasets are shown in Table 1.3 Baseline SystemsWe employ as baselines two stance classificationsystems, Anand et als (2011) approach and an en-hanced version of it, as described below.Our first baseline, Anand et als approach, isa supervised method that trains a stance classifier1http://www.createdebate.com/for determining whether the stance expressed ina debate post is for or against.
Hence, we cre-ate one training instance from each post in thetraining set, using the stance it expresses as itsclass label.
Following Anand et al we repre-sent a training instance using five types of fea-tures: n-grams, document statistics, punctuations,syntactic dependencies, and, if applicable, the setof features computed for the immediately preced-ing post in its thread.
Their n-gram features in-clude both the unigrams and bigrams in a post,as well as its first unigram, first bigram, and firsttrigram.
The features based on document statis-tics include the post length, the number of wordsper sentence, the percentage of words with morethan six letters, and the percentage of words aspronouns and sentiment words.
The punctuationfeatures are composed of the repeated punctuationsymbols in a post.
The dependency-based featureshave three variants.
In the first variant, the pairof arguments involved in each dependency rela-tion extracted by a dependency parser is used as afeature.
The second variant is the same as the firstexcept that the head (i.e., the first argument in a re-lation) is replaced by its part-of-speech (POS) tag.The features in the third variant, the topic-opinionfeatures, are created by replacing each featurefrom the first two types that contains a sentimentword with the corresponding polarity label (i.e.,+ or ?).
For instance, given the sentence ?Johnhates guns?, the topic-opinion features John?
andguns?
are generated, since ?hate?
has a negativepolarity and it is connected to ?John?
and ?guns?via the nsubj and dobj relations, respectively.
Inour implementation, we train the stance classifierusing SVMlight (Joachims, 1999).
After training,we can apply the stance classifier to classify thetest instances, which are generated in the sameway as the training instances.Related work on stance classification of con-gressional debates has found that enforcing authorconstraints (ACs) can improve classification per-formance (e.g., Thomas et al(2006), Burfoot et al(2011), Lu et al(2012)).
ACs are a type of inter-post constraints that specify that two posts writtenby the same author for the same debate domainshould have the same stance.
We hypothesize thatACs could similarly be used to improve stanceclassification of ideological debates, and thereforepropose a second baseline where we enhance thefirst baseline with ACs.
Enforcing ACs is simple.125We first use the learned stance classifier to classifythe test posts as in the first baseline, and then post-process the labels of the test posts.
Specifically,we sum up the confidence values2 assigned to theset of test posts written by the same author for thesame debate domain.
If the sum is positive, thenwe label all the posts in this set as for; otherwisewe label them as against.4 Semantic GeneralizationOur first extension to Anand et als (2011) ap-proach involves semantic generalization.To motivate this extension, let us take a closerlook at Anand et als attempt to generalize usingsyntactic dependencies.
Note that any approachthat aims to generalize using syntactic dependen-cies suffers from several weaknesses.
First, thesemantic relationship between the pair of lexicalitems involved in each of these features is not en-coded.
This means that the resulting features donot adequately capture the meaning of the under-lying sentence.
Second, replacing a word withits POS tag is a syntactic, not semantic, gener-alization, and doing so further abstracts the re-sulting feature from the meaning of the under-lying sentence.
Above all, while the resultingfeatures are intended to improve generalizations,they can provide very limited generalizations.
Tosee why, consider two semantically similar sen-tences ?I hate arrogant people?
and ?I dislike ar-rogant people?.
Ideally, any features that intend toprovide a generalized representation of these sen-tences should be able to encode the fact that theyare semantically similar.
However, Anand et alsfeatures would fail to do so because they cannotcapture the fact that ?hate?
and ?dislike?
are se-mantically similar.In the rest of this section we describe how wegenerate a semantic generalization of a sentenceto capture its meaning.
Our approach to seman-tic generalization involves (1) inducing from thetraining data a set of patterns that aim to providea semantic generalization of the sentences in thetraining posts and (2) using them in combinationwith the baseline systems to classify a test post.Below we describe these two steps in detail.4.1 Step 1: Pattern InductionThis step is composed of two sub-steps.2We use as the confidence value the signed distance of theassociated test point from the SVM hyperplane.4.1.1 Sub-step 1: Topic ExtractionFor each domain, we extract a list of topics.
Wedefine a topic as a word sequence that (1) startswith zero or more adjectives and ends with one ormore nouns and (2) appears in at least five postsfrom the domain.
Using this method, for example,we can extract ?abortion?, ?partial-birth abortion?,?birth control?, etc., as the topics for Abortion.4.1.2 Sub-step 2: Pattern CreationGiven a sentence, we create patterns to capture itsinformation using syntactic dependencies and se-mantic frames.3 These patterns can be divided intothree types, as described below.
For ease of expo-sition, we will use the two (semantically equiva-lent) sentences below as our running examples andsee what patterns are created from them.
(1) Some people hate guns.
(2) Some people do not like guns.Subject-Frame-Object (SFO) patterns.
Wecreate a set of SFO patterns for a transitive verbif (1) it is a frame target4; (2) its subject (respec-tively object) is a topic; and (3) its object (respec-tively subject) is a frame target.
In sentence (1),hate is the target of the frame Experiencer focus(henceforth EF), its subject, people, is a topic, andits object, guns is the target of the frame Weapon.As a result, we create a set of SFO patterns, eachof which is represented as a 6-tuple.
More specifi-cally, we create the 8 SFO patterns shown in thefirst column of Table 2.
Pattern 1 says that (1)this is an SFO pattern; (2) the subject is the wordpeople; (3) the frame name of the verb is EF; (4)the frame name of the object is Weapon; (5) theverb is not negated (POS); and (6) we don?t care(DC) whether the verb is sentiment-bearing.
If theverb is sentiment-bearing (in this case, hate has anegative sentiment), we create another pattern thatis the same as the first one, except that DC is re-placed with its sentiment value (see Pattern 2).Next, note that since the subject of hate is thetarget of the frame People and its object is a topic,we need to create patterns in a similar manner,resulting in Patterns 3 and 4.
Note that Peoplein these two patterns (with ?P?
capitalized) is the3We use the Stanford parser (de Marneffe and Manning,2008) and SEMAFOR (Das et al 2010) to obtain depen-dency relations and semantic frames, respectively.4A word w is the target of a frame f if f is assigned tow to generalize its meaning.
For example, assassination, kill,and terminate are the targets of the frame Killing.1261 <SFO:people:EF:Weapon:POS:DC> 9 <SFO:people:EF:Weapon:NEG:DC> 17 <DF:dobj:EF:Weapon:POS:DC>2 <SFO:people:EF:Weapon:POS:?> 10 <SFO:people:EF:Weapon:POS:?> 18 <DF:dobj:EF:Weapon:POS:?>3 <SFO:People:EF:guns:POS:DC> 11 <SFO:People:EF:guns:NEG:DC> 19 <DF:dobj:EF:guns:POS:DC>4 <SFO:People:EF:guns:POS:?> 12 <SFO:People:EF:guns:POS:?> 20 <DF:dobj:EF:guns:POS:?>5 <SFO:people:EF:DC:POS:DC> 13 <SFO:people:EF:DC:NEG:DC> 21 <FET:people:Experiencer:EF:POS:DC>6 <SFO:people:EF:DC:POS:?> 14 <SFO:people:EF:DC:POS:?> 22 <FET:people:Experiencer:EF:POS:?>7 <SFO:DC:EF:guns:POS:DC> 15 <SFO:DC:EF:guns:NEG:DC> 23 <FET:guns:Content:EF:POS:DC>8 <SFO:DC:EF:guns:POS:?> 16 <SFO:DC:EF:guns:POS:?> 24 <FET:guns:Content:EF:POS:?>Table 2: Sample patterns created for sentences (1) and (2).name of the frame People, not the word people ap-pearing in the sentence.To provide better generalization, we create asimplified version of each SFO pattern by replac-ing the frame name representing subject/objectwith the value DC.
This results in Patterns 5?8.For sentence (2), we can generate patterns in asimilar manner, resulting in Patterns 9?16.
For ex-ample, Pattern 9 contains the element NEG, whichencodes the fact that the verb like is negated.
Pat-tern 10 deserves discussion.
Since the positivesentiment-bearing verb like is negated, the senti-ment value of Pattern 10 is ?, which encodes thefact that not like has a negative sentiment.
Thenegation value of Pattern 10 is POS rather thanNEG, reflecting the fact that not like does not ap-pear in a negative context.
In other words, thesentiment value needs to be flipped if the verbis negated, and so may the negation value.
It isworth noting that Patterns 2 and 10 are identical,which provides suggestive evidence that sentences(1) and (2) are semantically equivalent.Dependency-Frame (DF) patterns.
We createa set of DF patterns for a dependency relation dif (1) both arguments of d are frame targets or (2)the head is a frame target and the dependent is atopic.
For example, in the dependency relationdobj(hate,guns), both hate and guns are frame tar-gets, as discussed above, and guns is a topic, so aset of DF patterns (Patterns 17?20 in Table 2) willbe created from it.
A DF pattern is represented asa 6-tuple.
For example, Pattern 17 says that (1)this is a DF pattern; (2) the relation type is dobj;(3) the frame name of the head is EF; (4) the framename of the dependent is Weapon; (5) the head isnot negated; and (6) we don?t care about the sen-timent of the head.
Pattern 18 is the same as Pat-tern 17, except that it takes into account the senti-ment value of the verb.
Patterns 19 and 20 replacesthe frame name of the dependent with the topicname, which is guns.
The negation and sentimentvalues are computed in the same way as those inthe SFO patterns.Frame-Element-Topic (FET) patterns.
Wecreate one FET pattern for every (v,fe) pair ina sentence where v is a verb and a frame target,and fe is a topic and a frame element of v?sframe.5 In sentence (1), people is a topic andit is assigned the role Experiencer, so two FETpatterns (Patterns 21 and 22) are created.
Also,since guns is a topic and it is assigned the roleContent, two additional FET patterns (Patterns 23and 24) are created.
The negation and sentimentvalues are computed in the same way as those inthe SFO patterns.4.2 Step 2: ClassificationIn this step, we will use the patterns learned inStep 1 in combination with the baseline systems toclassify a test post.
A simple way to combine thelearned patterns with the baseline systems wouldbe to augment the feature set they employ with thelearned patterns.
One potential weakness of thismethod is that the impact of these patterns couldbe undermined by the fact that they are signifi-cantly outnumbered by the baseline features, par-ticularly the n-gram features.For this reason, we decided to train anotherstance classifier, which we will refer to as thesemantics-based classifier, cs.
Like the base-line stance classifier cb, (1) cs is trained usingSVMlight, (2) each training instance for cs corre-sponds to a training post, and (3) its class label isthe stance the post expresses.
Unlike cb, however,the features employed by cs are created from thelearned patterns.
Specifically, from each patternwe create one binary feature whose value is 1 ifand only if the corresponding pattern is applicableto the training post under consideration.A natural question, then, is: how can we com-bine the decisions made by cb and cs?
To answerthis question, we applied both classifiers to the de-5Note that since fe is a frame element of v?s frame, it isassigned a semantic role.127System ABO GAY OBA MARcb 60.3 63.2 59.5 67.1cs 56.1 58.7 56.0 65.2Table 3: Development set accuracies.System ABO GAY OBA MARcb 22.9 18.5 24.1 9.6cs 17.6 14.3 19.4 7.2Table 4: Percentage of posts predicted correctlyby one but not both classifiers on the developmentset.velopment set for each domain and obtained theresults in Table 3.
As we can see, cs performs sig-nificantly worse than cb for all domains.6At first glance, we should just abandon csbecause of its consistently poorer performance.However, since the two classifiers are trained ondisjoint feature sets (one is lexico-syntactic andthe other semantic), we hypothesize that the mis-takes they made on the development set could becomplementary.
To confirm this hypothesis, wecompute the percentage of posts in the develop-ment set that are correctly classified by one but notthe other.
Results of this experiment are shown inTable 4.
As we can see, these results are largelyconsistent with our hypothesis.
For instance, forABO, 22.9% of the posts are classified correctlyonly by cb but not cs, whereas 17.6% of them areclassified correctly only by cs but not cb.Given these results, we hypothesize that perfor-mance could be improved by combining the pre-dictions made by cb and cs.
Since cb consistentlyoutperforms cs on all datasets, we use cs to make aprediction if and only if (1) cb cannot predict con-fidently and (2) cs can predict confidently.
Thispreference for cb is encoded in the following rule-based strategy for classifying a test post p, wherethe rules are applied in the order in which they arelisted.Rule 1: if cb can classify p confidently, then usecb?s prediction.Rule 2: if cs can classify p confidently, use cs?sprediction.Rule 3: use cb?s prediction.The next question is: how do we define con-fidence?
Since cb and cs are SVM-based clas-sifiers, the data points that are closer to the hy-perplane are those whose labels the SVM is less6All significance tests are paired t-tests, with p < 0.05.confident about.
Hence, we define confidence forclassifier ci by the interval [conf il , conf iu], whereconf il < 0 and conf iu > 0 are signed distancesfrom the hyperplane defining ci.
Specifically, wesay that a point p is confidently classified by ci ifand only if p lies outside the interval defined byconf il and conf iu.
Since we have two classifiers,cb and cs, we need to define two intervals (i.e., fournumbers).
Rather than defining these four num-bers by hand, we tune them jointly so that the ac-curacy of our combination strategy on the devel-opment set is maximized.7There is a caveat, however.
Recall that whenapplying this extension, we need to compute thesigned distances of every post p from cb and csto determine which classifier will be used to clas-sify p. The question, then, is: when applying thisextension to the second baseline (the Anand et albaseline extended with ACs) where all the postswritten by the same author for the same domainshould have the same stance, how should theirsigned distances be computed?
We adopt a sim-ple solution: we take the average of the signeddistances of all such posts from the correspond-ing hyperplane and set the signed distance of eachsuch post to the average value.5 Exploiting Same-Stance PostsTo classify a debate post p in the test set, we haveso far exploited only the information extractedfrom p itself.
However, it is conceivable that wecan improve the classification of p by exploitingthe information extracted from other test posts thathave the same stance as p. This is the goal of oursecond extension.To see why doing so can improve the classifi-cation of p, we make a simple observation: someposts are easier to classify than the others.
Typi-cally, posts containing expressions that are strongindicators of the stance label are easier to classifythan those that do not.
As an example, considerthe following posts:Post 2: I don?t think abortion should be illegal.Post 3: What will you do if a woman?s life is indanger while she?s pregnant?
Do you still want tosacrifice her life simply because the fetus is alive?It should be fairly easy for a human to see thatthe authors of both posts support abortion.
How-ever, Post 2 is arguably easier to classify than7For parameter tuning, for each of the four numbers wetried the values from ?0.5 to +0.5 with a step value of 0.001.128Post 3: Post 2 has an easy-to-determine stance,whereas Post 3 has a couple of rhetorical questionsthat may be difficult for a machine to understand.Hence, we might be able to improve the classifica-tion of Post 3 by exploiting information from otherposts that have the same stance as itself (which inthis case would be Post 2).In practice, however, we are not given the infor-mation of which posts have the same stance.
Inthe two subsections below, we discuss two sim-ple methods of determining whether two posts arelikely to have the same stance.5.1 Using Same-Author InformationThe first method, which we will refer to as M1, isfairly straightforward: we posit that two posts arelikely to have the same stance if they are writtenby the same author.
Given a test post p to be clas-sified, we can use this method to identify a sub-set of p?s same-stance posts.
For convenience, wedenote this set as SameStancePosts(p).
The ques-tion, then, is: how can we exploit information inSameStancePosts(p) to improve the classificationof p?
One way would be to combine the con-tent of the posts in SameStancePosts(p) with thatof p (i.e., by taking the union of all the binary-valued feature vectors), and use the class value ofthe combined post as the class value of p. How-ever, rather than simply combining all the poststo form one big post, we generalize this idea by(1) generating all possible combinations of postsin SameStancePosts(p); (2) for each such combi-nation, combine it with p; (3) classify each combi-nation obtained in (2) using the SVM classifier; (4)sum the confidence values of all the combinations;and (5) use the signed value as the class value of p.Note that if SameStancePosts(p) contains n posts,the number of possible combinations is?ni=0(ni).For efficiency reasons, we allow each combinationto contain at most 10 posts.At first glance, it seems that the combinationmethod described in the previous paragraph is analternative implementation of ACs.
(Recall thatACs are inter-post constraints that ensure that twoposts written by the same author for the same do-main should receive the same label.)
Neverthe-less, there are two major differences between ourcombination method and ACs.
First, in ACs, thesame-author posts can only interact via the confi-dence values assigned to them.
On the other hand,in our proposal, the same-author posts interact viaFeature DefinitionSameDebate whether authors posted in same debateSameThread whether authors posted in same threadReplied whether one author replied to the otherTable 5: Interaction features for the author-agreement classifier.feature sharing.
In other words, in ACs, the same-author posts interact after they are classified bythe stance classifier, whereas in our proposal, theinteraction occurs before the posts are classified.Second, in ACs, all the same-author posts receivethe same stance label.
On the other hand, this isnot necessarily the case in our proposal, becausetwo same-author posts can be classified using dif-ferent combinations.
In other words, ACs and ourcombination method are not the same.
In fact, theycan be used in conjunction with each other.5.2 Finding Similar-Minded AuthorsUsing M1 to identify same-stance posts has a po-tential weakness.
If an author has composed asmall number of posts, then the number of com-binations that can be generated will be small.
Inthe extreme case, if an author has composed justone post p, then no combinations will be gener-ated using M1.To enable p to benefit from our idea of ex-ploiting same-stance posts, we propose anothermethod to identify same-stance posts, M2, whichis a generalization of M1.
In M2, we positthat two posts are likely to have the same stanceif they are written by the same author or bysimilar-minded authors.
Given test post p, wecan compute SameStancePosts(p) using the defi-nition of M2, and apply the same 5-step combina-tion method described in the previous subsectionto SameStancePosts(p) to classify p.The remaining question is: given an author,a, in the test set, how do we compute his set ofsimilar-minded authors, Asimilar?
To do this, wetrain a binary author-agreement classifier on thetraining set to generate Asimilar for a. Specifi-cally, each training instance corresponds to a pairof authors in the training set having one of twoclass labels, agree (i.e., authors have the samestance) and disagree (i.e., authors have opposingstances).
We represent each instance with twotypes of features.
Features of the first type are ob-tained by taking the difference of the feature vec-tors corresponding to the two authors under con-sideration, where the feature vector of an author is129obtained by taking the union of the feature vectorscorresponding to all of the posts written by her.Taking the difference would allow the learner tofocus on those features whose values differ in thefeature vectors.
For the second type of features,we use author interaction information encoded asthree binary features (see Table 5 for their defi-nitions), which capture how authors interact witheach other in a debate thread.
After training theclassifier, we apply it to classify the author-pairsin the test set.
Then, for each author a, we com-pute her k-nearest authors based on the magnitudeof their agreement, where k is tuned to maximizeaccuracy on the development data.8 Finally, wetake Asimilar to be the set of k-nearest authors.6 Evaluation6.1 Experimental SetupResults are expressed in terms of accuracy ob-tained via 5-fold cross validation, where accuracyis the percentage of test instances correctly classi-fied.
Since all experiments require the use of de-velopment data for parameter tuning, we use threefolds for model training, one fold for development,and one fold for testing in each fold experiment.6.2 ResultsResults are shown in Table 6.
Row 1 shows theresults of the Anand et al(2011) baseline on thefour datasets, obtained by training a stance classi-fier using the SVMlight package.9 Row 2 showsthe results of the second baseline, Anand et alssystem enhanced with ACs.
As we can see, incor-porating ACs into Anand et als system improvesits performance significantly on all datasets andyields a system that achieves an average improve-ment of 4.6 accuracy points.Next, we incorporate our first extension, patterninduction, into the better of the two baselines (i.e.,the second baseline).
Results of combining cb andcs to classify the test posts (together with the ACs)are shown in row 3 of Table 6.
As we can see, in-corporating pattern induction into the second base-line significantly improves its performance on allfour datasets and yields a system that achieves anaverage improvement of 2.48 accuracy points.Before incorporating our second extension, let8We tested values of k from 1 to 7.9For all SVM experiments, the regularization parameter Cis tuned using development data, but the remaining learningparameters are set to their default values.System ABO GAY OBA MARcb 61.4 62.6 58.1 66.9cb+AC 72.0 64.9 62.7 67.8cb+cs+AC 73.2 68.0 64.2 71.9cbs+AC 71.8 65.0 60.2 67.9cb+cs+M1+AC 74.8 69.1 69.7 73.2cb+cs+M2+AC 75.9 70.6 71.2 75.3Table 6: 5-fold cross-validation accuracies.us recall our earlier hypothesis that combining cband cs using our method would be better thantraining just one classifier that combines the fea-tures used by cb and cs.
The reason behind ourhypothesis was that simply combining the featuresets would undermine the impact of pattern-basedfeatures because they would be significantly out-numbered by the features in cb.
To confirm thishypothesis, we showed in row 4 of Table 6 theresults of this experiment, where we trained oneclassifier on all the features used by cb and cs.As we can see, this classifier (referred to as cbs inthe table) together with the ACs performs signif-icantly worse than the cb+cs+AC system (row 3)on all datasets.
In fact, the cb+AC system (row 2)outperforms the cbs+AC system on OBA, but theyare statistically indistinguishable on the remainingdatasets.
These results suggest that combining thepattern-based features with the baseline featuresinto one feature set renders the former ineffective.Finally, we incorporate our second extension,the one that involves generating combinations oftest posts written by the same author (M1) and byboth the same author and similar-minded authors(M2).
Results of these experiments are shown inrows 5?6 of Table 6.
The M1-based system sig-nificantly outperforms cb+cs+AC on all four do-mains, yielding an average improvement of 2.4 ac-curacy points.
The M2-based system further beatsthe M1-based system by 1.5 accuracy points onaverage, and their performance difference is sig-nificant on all but the ABO domain.Overall, our two extensions yield a stance clas-sification system that significantly outperforms thebetter baseline on all four datasets, with an averageimprovement of 6.4 accuracy points.Given the better performance of thecombination-based systems, a natural ques-tion is: can we further improve performanceby applying our combination methods to gen-erate artificial posts and use them as additionaltraining instances?
To answer this question, weapply both M1 and M2 to generate additional130training instances, using a random selection ofsame-stance authors in place of M2?s k-nearestneighbor method.
However, neither method yieldsan improvement in performance over the methodon which it is based.
We speculate that since allthe posts in the training combinations are alreadypresent in the training set as individual posts,they are more likely to be farther away from thehyperplane than the individual posts, meaningthat they are less likely to be support vectors.
Thisin turn implies that they are less likely to affectclassification performance.6.3 Error AnalysisTo gain additional insights into our approach, weperformed a qualitative analysis of the errors pro-duced by our best-performing system below.Failure to accumulate decisions from severalclues.
Authors often express their stance using agroup of sentences where the latter sentence(s) in-dicate the actual stance and the initial sentence(s)may give a false impression about the author?sstance.
Consider Post 1 (see Section 1) and Post 4.Post 4: I agree abortion creates stress and pain.
Iagree it kills a potential life.
That does not meanit is right to ban abortion.In Post 1, the author is anti-abortion, whereasin Post 4, the author is pro-abortion.
However,the first sentence in Post 1 gives a misleading clueabout the author?s stance, and so do the first twosentences in Post 4.
Since all the systems dis-cussed in the paper operate on one sentence at atime, they are all prone to such errors.
One wayto address this problem could be to determine howadjacent sentences are related to each other via theuse of discourse relations.Presence of materials irrelevant to stance.
Be-cause of the informal style of writing, we oftenfind long posts with one or two sentences indicat-ing the actual stance of the author.
The rest of suchposts often include descriptions of an author?s per-sonal experience, comments or questions directedto other authors etc.
Such long posts are frequentlymisclassified for all four domains.
Consider thefollowing example.Post 5: Marijuana should at least be decriminal-ized.
Driving stoned, however, is something totallydifferent and should definitely be a crime.
Also,weed can?t kill you, unlike cigarettes and alcohol.In my opinion cigarettes should definitely be ille-gal, but they?re so ingrained into our culture that Idoubt that is going to happen any time soon.In this post, the author supports the legalizationof marijuana.
However, the only useful hints abouther stance are ?marijuana should at least be de-criminalized?
and ?weed can?t kill you?.
The restof the post is not helpful for stance classification.Convoluted posts appearing later in long postsequences.
As a post sequence gets longer, au-thors tend to focus on specific aspects of a de-bate and consequently, it becomes more difficult toclassify their stances, even with the context-basedfeatures (features taken from the immediately pre-ceding post) proposed by Anand et alConsiderthe following post sequence, where only the firstpost (P1) and the nth post (Pn) are shown due tospace limitations.
[P1: Anti-Obama] Obama is a pro-abortionist.
Killing ba-bies is wrong so stop doing it.
The new health reform billis not good.
There are some good things but more worsethan good.
You could have just passed some laws instead ofmaking a whole bill.?
?
?
[Pn: Pro-Obama] Killing fetuses isn?t wrong.
Be-sides, we could use those fetuses for stem cell re-search.As we can see, the author of P1 does not sup-port Obama because of his pro-abortion views.
InPn, a pro-Obama author explains why she thinksabortion is not wrong.
However, without the con-text from P1 that Obama is pro-abortion, it is noteasy for a machine to classify Pn correctly.
Thisproblem is more serious in ABO and GAY than inthe other domains as the average length of a postsequence in these two domains is larger.7 ConclusionsWe examined the under-studied task of stanceclassification of ideological debates.
Employingour two extensions yields a system that outper-forms an improved version of Anand et als ap-proach by 2.6?7.0 accuracy points.
In particular,while existing approaches to debate stance classi-fication have primarily employed lexico-syntacticfeatures, to our knowledge this is the first attemptto employ FrameNet for this task to induce fea-tures that aim to capture the meaning and pro-vide semantic generalizations of a sentence.
Inaddition, our method for identifying and exploit-ing same-stance posts during the inference proce-dure provides further gains when used on top ofour FrameNet extension.131ReferencesRakesh Agrawal, Sridhar Rajagopalan, RamakrishnanSrikant, and Yirong Xu.
2003.
Mining newsgroupsusing networks arising from social behavior.
InProceedings of the 12th international conference onWorld Wide Web, WWW ?03, pages 529?535.Pranav Anand, Marilyn Walker, Rob Abbott, Jean E.Fox Tree, Robeson Bowmani, and Michael Minor.2011.
Cats rule and dogs drool!
: Classifying stancein online debate.
In Proceedings of the 2nd Work-shop on Computational Approaches to Subjectivityand Sentiment Analysis (WASSA 2011), pages 1?9.Alexandra Balahur, Zornitsa Kozareva, and Andre?sMontoyo.
2009.
Determining the polarity andsource of opinions expressed in political debates.
InProceedings of the 10th International Conference onComputational Linguistics and Intelligent Text Pro-cessing, CICLing ?09, pages 468?480.Mohit Bansal, Claire Cardie, and Lillian Lee.
2008.The power of negative thinking: Exploiting labeldisagreement in the min-cut classification frame-work.
In Proceedings of the 22nd InternationalConference on Computational Linguistics: Com-panion volume: Posters, pages 15?18.Or Biran and Owen Rambow.
2011.
Identifying justi-fications in written dialogs.
In Proceedings of the2011 IEEE Fifth International Conference on Se-mantic Computing, ICSC ?11, pages 162?168.Clinton Burfoot, Steven Bird, and Timothy Baldwin.2011.
Collective classification of congressionalfloor-debate transcripts.
In Proceedings of the 49thAnnual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies,pages 1506?1515.Dipanjan Das, Nathan Schneider, Desai Chen, andNoah A. Smith.
2010.
Probabilistic frame-semanticparsing.
In Human Language Technologies: The2010 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics, pages 948?956.Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
The Stanford typed dependenciesrepresentation.
In Proceedings of the COLINGWorkshop on Cross-Framework and Cross-DomainParser Evaluation, CrossParser ?08, pages 1?8.Kazi Saidul Hasan and Vincent Ng.
2012.
Predict-ing stance in ideological debate with rich linguisticknowledge.
In Proceedings of the 24th InternationalConference on Computational Linguistics: Posters,pages 451?460.Thorsten Joachims.
1999.
Making large-scale SVMlearning practical.
In Bernhard Scholkopf andAlexander Smola, editors, Advances in Kernel Meth-ods - Support Vector Learning, pages 44?56.
MITPress.Yue Lu, Hongning Wang, ChengXiang Zhai, and DanRoth.
2012.
Unsupervised discovery of opposingopinion networks from forum discussions.
In Pro-ceedings of the 21st ACM International Conferenceon Information and Knowledge Management, CIKM?12, pages 1642?1646.Akiko Murakami and Rudy Raymond.
2010.
Supportor oppose?
Classifying positions in online debatesfrom reply activities and opinion expressions.
InProceedings of the 23rd International Conference onComputational Linguistics: Posters, pages 869?875.Swapna Somasundaran and Janyce Wiebe.
2010.
Rec-ognizing stances in ideological on-line debates.
InProceedings of the NAACL HLT 2010 Workshop onComputational Approaches to Analysis and Gener-ation of Emotion in Text, CAAGET ?10, pages 116?124.Matt Thomas, Bo Pang, and Lillian Lee.
2006.
Get outthe vote: Determining support or opposition fromCongressional floor-debate transcripts.
In Proceed-ings of the 2006 Conference on Empirical Methodsin Natural Language Processing, pages 327?335.Marilyn Walker, Pranav Anand, Rob Abbott, and RickyGrant.
2012.
Stance classification using dialogicproperties of persuasion.
In Proceedings of the 2012Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 592?596.Yi-Chia Wang and Carolyn P. Rose?.
2010.
Makingconversational structure explicit: Identification ofinitiation-response pairs within online discussions.In Human Language Technologies: The 2010 An-nual Conference of the North American Chapterof the Association for Computational Linguistics,pages 673?676.Ainur Yessenalina, Yisong Yue, and Claire Cardie.2010.
Multi-level structured models for document-level sentiment classification.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, pages 1046?1056.132
