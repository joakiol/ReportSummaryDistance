A SEMANTIC CONCORDANCEGeorge A. Miller, Claudia Leacock, Randee Tengi, Ross T. BunkerCogn i t ive  Sc ience LaboratoryPr inceton Un ivers i tyPr inceton,  NJ  08542ABSTRACTA semantic oncordance is a textual corpus and a lexicon So com-bined that every substantive word in the text is linked to itsappropriate ~nse in the lexicon.
Thus it can be viewed either as acorpus in which words have been tagged syntactically and semanti-cally, or as a lexicon in which example sentences can be found formany definitions.
A semantic oncordance is being constructed touse  in studies of sense resolution in context (semantic disambigua-tion).
The Brown Corpus is the text and WordNet is the lexicon.Semantic tags (pointers to WordNet synsets) are inserted in the textmanually using an interface, ConText, that was designed to facili-tate the task.
Another interface supports earches of the taggedtext.
Some practical uses for semantic oncordances are proposed.1.
INTRODUCTIONWe wish to propose a new version of an old idea.
Lexi-cographers have traditionally based their work on a corpusof examples taken from approved usage, but considerationsof cost usually limit published ictionaries to lexical entrieshaving only a scattering of phrases to illustrate the usagesfrom which definitions were derived.
As a consequence ofthis economic pressure, most dictionaries are relatively weakin providing contextual information: someone learningEnglish as a second language will find in an English diction-ary many alternative meanings for a common word, but littleor no help in determining the linguistic ontexts in which theword can be used to express those different meanings.Today, however, large computer memories are affordableenough that this limitation can be removed; it would now befeasible to publish a dictionary electronically along with allof the citation sentences on which it was based.
The result-ing combination would be more than a lexicon and morethan a corpus; we propose to call it a semantic concordance.If the corpus is some specific text, it is a specific semanticconcordance; ff the corpus includes many different exts, itis a universal semantic concordance.We have begun constructing a universal semantic oncor-dance in conjunction with our work on a lexical database.The result can be viewed either as a collection of passages inwhich words have been tagged syntactically and semanti-eally, or as a lexicon in which illustrative sentences can befound for many definitions.
At the present time, the correla-tion of a lexical meaning with examples in which a word isused to express that meaning must be done by hand.
Manualsemantic tagging is tedious; it should be done automaticallyas soon as it is possible to resolve word senses in contextautomatically.
It is hoped that the manual creation of asemantic oncordance will provide an appropriate environ-ment for developing and testing those automatic procedures.2.
WORDNET:  A LEX ICAL  DATABASEThe lexical component of the universal semantic oncor-dance that we are constructing is WordNet, an on-line lexi-cal resource inspired by current psycholinguistic theories ofhaman lexical memory \[1, 2\].
A standard, handheld iction-ary is organized alphabetically; it puts together words thatare spelled alike and scatters words with related meanings.Although on-line versions of such standard ictionaries canrelieve a user of alphabetical searches, it is clearly inefficientto use a computer merely as a rapid page-turner.
WordNetis an example of a more efficient combination of traditionallexicography and modern computer science.The most ambitious feature of WordNet is the attempt oorganize lexical information in terms of word meanings,rather than word forms.
WordNet is organized by semanticrelations (rather than by semantic omponents) within theopen-class categories of noun, verb, adjective, and adverb;closed-class categories of words (pronouns, prepositions,conjunctions, etc.)
are not included in WordNet.
Thesemantic relations among open-class words include:synonymy and antonymy (which are semantic relationsbetween words and which are found in all four syntacticcategories); hyponymy and hypernymy (which are semanticrelations between concepts and which organize nouns into acategorical hierarchy); meronymy and holonymy (whichrepresent part-whole relations among noun concepts); andtroponymy (manner relations) and entailment relationsbetween verb concepts.
These semantic relations werechosen to be intuitively obvious to nonlinguists and to havebroad applicability throughout the lexicon.The basic elements of WordNet are sets of synonyms (orsynsets), which are taken to represent lexicalized concepts.A synset is a group of words that are synonymous, in thesense that there are contexts in which they can be inter-changed without changing the meaning of the statement.For example, WordNet distinguishes between the synsets:303{board, plank, (a stout length of sawn timber)}{board, committee, (agroup with supervisory powers)}In the context, "He nailed a board across the entrance," theword "plank" can be substituted for "board."
In the con-text, "The board announced last quarter's dividend," theword "committee" can be substituted for "board.
"WordNet alo provides sentence frames for each sense ofevery verb, indicating the kinds of simple constructions intowhich the verb can enter.WordNet contains only uninflected (or base) forms of words,so the interface to WordNet includes raorphy, a morpho-logical analyzer that is applied to input strings to generatethe base forms.
For example, given "went" as the inputstring, rnorphy returns "go";  given "children," it returns"child," etc.
raorphy first checks an exception list; if theinput string is not found, it then uses standard rules ofdetachment.Words (like "fountain pen") that are composed of two ormore simpler words with spaces between them are calledcollocations.
Since collocations are less polysemous thanare individual words, their inclusion in WordNet promises tosimplify the task of sense resolution.
However, the mor-phology of collocations poses certain problems.
Specialalgorithms are required for inflected forms of some colloca-tions: for example, "standing astride of" will return thephrasal verb, "stand astride of.
"As of the time this is written, WordNet contains more than83,800 entries (unique character strings, words and colloca-tions) and more than 63,300 lexicalized concepts (synsets,plus defining glosses); altogether there are more than118,600 entry-concept airs.
The semantic relations arerepresented by more than 87,600 pointers between concepts.Approximately 43% of the entries are collocations.
Approx-imately 63% of the synsets include definitional glosses.
Andapproximately 14% of the nouns and 25% of the verbs arepolysemous.WordNet continues to grow at a rate of almost 1,000 con-cepts a month.
The task of semantic tagging has provided auseful stimulus to improve both coverage and precision.3.
THE BROWN CORPUSThe textual component of our universal semantic oncor-dance is taken from the Brown Corpus \[3, 4\].
The corpuswas assembled at Brown University in 1963-64 under thedirection of W. Nelson Francis with the intent of making itbroadly representative of American English writing.
It con-tains 500 samples, each approximately 2,000 words long, fora total of approximately 1,014,000 running words of text,where a "word" is defined graphically as a string of con-tiguous alphanumeric characters with a space at either end.The genres of writing range from newspaper reporting totechnical writing, and from fiction to philosophical essays.The computer-readable form of the Brown Corpus has beenused in a wide variety of research studies, and many labora-tories have obtained permission to use it.
It was initiallyused for studies of word frequencies, and subsequently wasmade available with syntactic tags for each word.
Since it iswell known in a variety of contexts, and widely available,the Brown Corpus seemed agood place to begin.4.
SEMANTIC  TAGGINGTwo contrasting strategies for connecting a lexicon and acorpus emerge depending on where the process tarts.
Thetargeted approach starts with the lexicon: target apolysemous word, extract all sentences from the corpus inwhich that word occurs, categorize the instances and writedefinitions for each sense, and create a pointer between eachinstance of the word and its appropriate sense in the lexicon;then target another word and repeat he process.
The tar-geted approach as the advantage that concentrating on asingle word should produce better definitions---it is, after all,the procedure that lexicographers egard as ideal.
And italso makes immediately available a classification of sen-tences that can be used to test alternative methods ofautomatic sense resolution.The alternative strategy starts with the corpus and proceedsthrough it word by word: the sequential pproach.
This pro-cedure has the advantage of immediately revealingdeficiencies in the lexicon: not only missing words (whichcould be found more directly), but also missing senses andindistinguishable definitions--deficiencies that would notsurface so quickly with the targeted approach.
Since thepromise of improvements in WordNet was a major motivefor pursuing this research, we initially adopted the sequentialapproach for the bulk of our semantic tagging.A second advantage of the sequential pproach emerged asthe work proceeded.
One objective test of the adequacy of alexicon is to use it to tag a sample of text, and to record thenumber of times it fails to have a word, or fails to have theappropriate sense for a word.
We have found that suchrecords for WordNet show considerable variability depend-ing on the particular passage that is tagged, but over severalmonths the averaged estimates of its coverage have beenslowly improving: coverage it is currently averaging a littlebetter than 96%.5.
CONTEXT: A TAGGING INTERFACEThe task of semantically tagging a text by hand is notori-ously tedious, but the tedium can be reduced with anappropriate user interface.
ConText is an X-windows inter-face designed specifically for annotating written texts withWordNet sense tags \[5\].
Since WordNet contains onlyopen-class words, ConText is used to tag only nouns, verbs,adjectives, and adverbs; that is to say, only about 50% of therunning words in the Brown Corpus are semantically tagged.304Manual tagging with ConText requires a user to examineeach word of the text in its context of use and to decidewhich WordNet sense was intended.
In order to facilitatethis task, ConText displays the word to be tagged in its con.text, along with the WordNet synsets for all of the senses ofthat word (in the appropriate part of speech).
For example,when the person doing the tagging reaches "horse" in thesentence:The horse and men were saved, but the oxen drowned.ConText displays WordNet synsets for five meanings ofnoun ' ' horse' ':1. sawhorse, horse, sawbuck, buck (a framework used bycarpenters)2. knight, horse (a chess piece)3. horse (a gymnastic apparatus)4. heroin, diacetyl morphine, H, horse, junk, scag, smack(a morphine derivative)5. horse, Equus caballus (herbivorous quadruped)The tagger uses the cursor to indicate the appropriate sense(5, in this example), at which point ConText attaches a label,or semantic tag, to that word in the text.
ConText thenmoves on to "men," the next content word, and the processrepeats.
If the word is missing, or ff the appropriate sense ismissing, the tagger can insert comments calling for thenecessary evisions of WordNet.5.1.
Input to ConTextIn the current version of ConText, text to be tagged semanti-cally must be preprocessed to indicate collocations andproper nouns (by concatenating them with underscores) andto provide syntactic tags.
Since different corpora come indifferent formats and so requke slighdy different prepro-cessing, we have not tried to incorporate the preprocessorinto ConText itself.A tokenizer searches the input text for collocations thatWordNet knows about and when one is found it is made intoa unit by connecting its parts with underscores.
For exam-ple, if a text contains the collocation "took place," the tok-enizer will convert it to "took_place."
ConText can thendisplay the synset for "take place" rather than successivesynsets for "take" and "place.
"Syntactic tags indicate the part of speech of each word in theinput text.
We have used an automatic syntactic taggerdeveloped by Eric Brill \[6\] which he generously adapted toour needs.
For example, "store" can be a noun or a verb;when the syntactic tagger encounters an instance of "store"it tries to decide from the context whether it is being used asa noun or a verb.
ConText then uses this syntactic tag todetermine which part of speech to display to the user.
Con-Text also uses syntactic tags in order to skip over closed-class words.
Since the automatic syntactic tagger sometimesmakes mistakes, ConText allows the user to change the partof speech that is being displayed, or to tag words that shouldnot have been skipped.After the text has been syntactically tagged, all contiguousstrings of proper nouns are joined with an underscore.
Forexample, the string "Mr. Charles C. Carpenter" is output as"Mr._Charles_C._Carpenter."
Here, too, the user canmanually correct any mistaken concatenations.An example may clarify what is involved in preprocessing.The 109th sentence inpassage k13 of the Brown Corpus is:He went down the hall to Eugene's bathroom, to turn onthe hot-water heater, and on the side of the tub he saw apair of blue wool swimming trunks.After preprocessing, this sentence is passed to ConText inthe following form:br-kl3:109: He/PP went_down/VB the/DT hall/NN to/TOEugene/NP '/POS s/NN bathroom/NN J, to/TOturn_on/VB the/DT hot-water/NN heater/NN ,/, and/CCon/IN the/DT side/NN of/IN the/DT tub/NN he/PPsaw/VBD a/DT pair/NN of/IN blue/JJ wool/NNswimming_trunks/NN ./.The version displayed to the tagger, however, looks like theBrown Corpus, except that collocations are indicated byunderscores.
Note, incidentally, that the processor has madea mistake in this example: "went_down" (as in "the shipwent down") is not the sense intendeed here.5.2.
Output of ConTextThe output of ConText is a file containing the original textannotated with WordNet semantic tags; semantic tags aregiven in square brackets, and denote the particular WordNetsynset that is appropriate.
For example, when "hall" istagged with \[noun.artifact.l\] it means that the word is beingused to express the concept defined by the synset containing"hal l l "  in the noun.artifact file.
(Since WordNet is con-stantly growing and changing, references to the lexicogra-phers' files have been retained; if the lexical componentwere frozen, some more general identifier could be usedinstead.)
In cases where the appropriate sense of a word isnot in WordNet, the user annotates that word with a com-ment that is later sent to the appropriate lexicographer.After the lexicographer has edited WordNet, the text mustbe retagged.
In the retag mode, ConText skips from onecommented word to the next.In addition to the syntactic and semantic tags, ConText addsSGML markers and reformats the text one word to a line.The SGML markers delimit sentences <s>, sentencenumbers <stn>, words in the text <wd>, base forms of textwords <mwd>, comments <cmt>, proper nouns <pn>, part-of-speech tags <tag> and semantic tags <sn> or <msn>.
Thesentence preprocessed above might come out of ConTextlooking like this:<stn>109</stn>305<wd>He</wd><tag>PP</tag><wd>went</wd><mwd>go</mwd><msn> \[verb.motion.6\]</msnxtag>VB</tag><wd>down</wd><wd>the</w d><tag>DT</tag><wd>hall</wd><sn> \[noun.artifact.
1\]</sn><tag>NN</tag><wd>to</wd><tag>TO</tag><wd>Eugene</wd><pn>person</pn><sn> \[noun .Tops.0\]</sn><tag>NP</tag><wd>'</wd><tag>POS</tag><wd>s</wd><tag>NN</tag><wd>bathroom</wd><sn> \[noun.artifact.0\]</sn><tag>NN</tag><wd>,</wd><tag>,</tag><wd>to</wd><tag>TO</tag><wd>turn_on</wd><sn> \[verb.contact.0\]</sn><tag>VB</tag><wd>the</wd><tag>DT</tag><wd>hot-water-heater</wd><cm t WORD_MIS ING</cmt><tag>NN</tag><wd>,</wd><tag>,</tag><wd>and</wd><tag>CC</tag><wd>on</wd><tag>IN</tag><wd>the</w d><tag>DT</tag><wd>side</wd><sn> \[noun.location.0\] </sn><tag>NN</tag><wd>of</wd><tag>IN</tag><wd>the</wd><tag>DT<\[tag><wd>tub</wd><sn> \[noun.artifact.
1 \] </sn><tag>NN</tag><wd>he</wd><tag>PP</tag><wd>saw</wd><mwd>sce</mwd><msn> \[verb.perception.0\]</msnxtag>VBD</tag><wd>a</wd><tag>DT</tag><wd>pair</wd><sn> \[noun .quantity .0\] </sn> <tag>NN</tag><wd>of</wd><tag>IN</tag><wd>blue</wd><sn> \[adj .all.0.col.3\] </sn><tag>JJ</tag><wd>wool</wd><sn> \[noun.artifact.0\]</sn><tag>NN</tag><wd>swimming_.trunks</wd><sn> \[noun.artifact.0\]</sn><tag>NN</tag><wd>.</wd><tag>.</tag></s>Note that the tokenizcr's mistaken linking of "went_down"has now been corrected by the tagger.
Also note"<cmt>WORD_MISSING</cmt>" on line 16 of the output:that comment indicates that the tagger has connected "hot-water" and "heater" to form the collocation "hot-water heater," which was not in WordNet.
This illustratesthe kind of comments that are passed on to the lexicogra-phers, who use them to edit or add to WordNet.The WordNet database is constantly growing and changing.Consequently, previously tagged texts must be updatedperiodically.
In the update mode, ConText searches thetagged files for pointers to WordNet senses that have subse-quently been revised.
A new semantic tag must then beinserted by the tagger.5.3 TrackingAs the number of semantically tagged files increased, thedifficulty of keeping track of which files had beeen prepro-cessed, which had been tagged, which were ready to beretagged, which had been retagged, and which were com-plete and cleared for use made it necessary to create a mas-ter traacking system that would handle the record keepingautomatically.
Scripts were written that allowed an adminis-trator to preprocess files and add them to the tracking sys-tem.
Once files are in the tracking system, other scripts keepa log of all the tagging activities pertaining to each file, andinsure that taggers will not try to perform operations that areinvalid for files with a given status.
The administrator caneasily generate simple reports on the status of all files in thetracking system.6.
QUERYING THE TAGGED TEXTA program to query the semantically tagged database hasalso been written: p rsent  (print sentences) allows a userto retrieve sentences by entering the base form of a wordand its semantic tag.
It was developed as a simple interfaceto the semantic oncordance, and puts the burden of know-ing the word's semantic tag on the user.
This program isuseful to the lexicographers, who are intimately familiarwith WordNet semantic tags and who use it to find samplesentences.
A more robust interface is needed, however.Presently under development is a comprehensive queryingtool that will allow a user the flexibility of specifying vari-ous retrieval criteria and display options.
Envisioned is anX-Windows application with two main windows: one areafor entering searching information and another for display-ing the retrieved sentences.
A primary search key is theonly required component.
Additional search keys can bespecified to find words that co-occur in sentences.
Thisalone is a powerful improvement over p rsent .
Otheroptions will restrict or expand the retrieval, as listed here:1.
Search only given part(s) of speech.2.
Search only for a specific sense.3.
Expand search to include sentences for synonyms ofsearch key.4.
Expand search to include sentences for hyponyms ofsearch key.5.
Use primary key and all secondary keys, or primarykey and any secondary key.6.
Search for a secondary key that is within n words ofthe primary key.As important as specifying searching criteria is how theretrieved information is displayed.
An option will be pro-vided to display retrieved sentences in a concordance format(all the target words vertically aligned and surrounded bycontext o the window's borders) or left justified.
Searchkeys will be highlighted in the retrieved sentences.306Implementation f this program requires the creation of a"master list" of semantically tagged words.
Each line inthe alphabetized list contains the target word, its semantictag, and for each sentence containing the word, a list of allthe co-occurring nouns, verbs, adjectives, and adverbs withnumbers indicating their position in the sentence.
For exam-ple, the sentence already dissected provides a context for"hall" that might look like this:hall/5 \[noun.artifact.l\]:{bathroom/10 \[noun.artifact.0\]; hot-water heater/15\[noun.artifact.0\]; side/19 \[noun.location.0\]; tub/22\[noun.artifact.l\]; pair/25 \[noun.quantity.0\]; wool/28\[noun.artifact.0\]; swimming_trunks/29 \[noun.artifact.0\]}{go/2 \[verb.motion.6\]; turn_on/13 \[verb.contact.0\]; see/23\[verb.perception.0\] }{blue/27 \[adj.all.col.3\] }\[\]Collecting entries for this sense of "hall" provides valuableinformation about he contexts in which it can occur.7.
APPL ICAT IONSOur reasons for building this universal semantic oncor-dance were to test and improve the coverage of WordNetand to develop resources for developing and testing pro-cedures for the automatic sense resolution in context.
Itshould be pointed out, however, that semantic oncordancescan have other uses.7.1.
InstructionDictionaries are said to have evolved from the interlinearnotations that medieval scholars added for difficult Latinwords \[7\].
Such notations were found to be useful in teach-ing students; as the number of such notations grew, collec-tions of them were extracted and arranged in lists.
When thelists took on a life of their own their educational originswere largely forgotten.
A semantic oncordance brings thisstory back to its origins: lexical "footnotes" indicating themeaning that is appropriate to the context are immediatelyavailable lectronically.One obvious educational use of a semantic oncordancewould be for people trying to learn English as a secondlanguage.
By providing them with the appropriate sense ofan unfamiliar word, they are spared the task of selecting asense from the several alternatives listed in a standard ic-tionary.
Moreover, they can retrieve other sentences thatillustrate the same usage of the word, and from such sen-tences they can acquire both local and topical informationabout the use of a word: (1) local information about thegrammatical constructions in which that word can expressthe given concept, and (2) topical information about otherwords that are likely to be used when that concept is dis-cussed.A use for specific semantic oncordances would be in sci-ence education!
much of the new learning demanded ofbeginning students in any field of science is terminological.7.2.
Sense FrequenciesMuch attention has been paid to word frequencies, but rela-tively little to the frequencies of occurrence of differentmeanings.
Some lexicographers have atempted to order thesenses of polysemous words from the most to the least fre-quent, but the more general question has not been askedbecause the data for answering it have not been available.We have enough tagged text now, however, to get an ideawhat such data would look like.
For example, here are prel-irninary data for the 10 most frequent concepts expressed bynouns, based on some 80 selections from the Brown Corpus:172 {year, (timeperiod)}144 {person, individual, someone, man, mortal, human,soul, (a human being)\]139 \[man, adult_male, (a grown man)}105 {consequence, effect, outcome, result, upshot, (aphenomenon that follows and is caused by someprevious phenomenon)}104 {night, night_time, dark, (time after sunset andbefore sunrise while it is dark outside)}102 {kind, sort, type, form, ("sculpture isa form of art"or "what kind of man is this?
")}94 {eye, eyeball, oculus, optic, peeper, (organ of sight)}89 {day, daytime, daylight, (time after sunrise and beforesunset while it is light outside)}88 {set, class, category, type, family, (a collection ofthings haring acommon attribute)}87 {number, count, complement, (adefinite quantity)}Our limited experience suggests, however, that such statis-tics depend critically on the subject matter of the corpus thatis used.7.4.
Sense Co-occurrencesOne shortcoming of WordNet that several users havepointed out to us is its lack of topical organization.
PeterMark Roget's original conception of his thesaurus reliedheavily on his list of topics, which enabled him to pulltogether in one place all of the words used to talk about agiven topic.
This tradition of topical organization has sur-vived in many modern thesauri, even though it requires adouble look-up by the reader.
For example, under "base-ball" a topically organized thesaurus would pull togetherwords like "batter," "team," "lineup," "diamond,""homer," hit," and so on.
Topical organization obviouslyfacilitates sense resolution: if the topic is baseball, the mean-ing of "ball" will differ from its meaning when the topic is,say, dancing.
In WordNet, those same words are scatteredabout: a baseball is an artifact, batters are people, a team is agroup, a lineup is a list, a diamond is a location, a homer is307an act, to hit is a verb, and so on.
By itself, WordNet doesnot provide topical groupings of words that can be used forsense resolution.One solution would be to draw up a list of topics and indexall of the WordNet synsets to the topics in which they arelikely to occur.
Chapman \[8\], for example, uses 1,073 suchclasses and categories.
But such lists are necessarily arbi-gary.
A universal semantic oncordance should be able toaccomplish the same result in a more natural way.
That is tosay, a passage discussing baseball would use words togetherin their baseball senses; a passage discussing the drug tradewould use words together with senses appropriate to thattopic, and so on.
Instead of a long list of topics, the corpusshould include a large variety of passages.In order to take advantage of this aspect of universal seman-tic concordances, it is necessary to be able to query the tex-tual component for associated concepts.
Data on sense co-occurrences build up slowly, of course, but they will be avaluable by-product of this line of work.7.4.
TestingWe are developing a version of the ConText interface thatcan be used for psychometric testing.
The tagger's task inusing ConText resembles an extended multiple-choiceexamination, and we believe that that feature can be adaptedto test reading comprehension.
Given a text that has alreadybeen tagged, readers' comprehension can be tested by seeingwhether they are able to choose correct senses on the basisof the contexts of use.No doubt here are other, even better uses for semantic on-cordances.
As the variety of potential applications grows,however, the need to automate the process of semantic tag-ging will become ever more pressing.
But we must beginwith what we have.
We are now finishing a first installmentof semantically tagged text consisting of 100 passages fromthe Brown Corpus; as soon as that much has been completedand satisfactorily cleaned up, we plan to make it, and thecorresponding WordNet database, available to other labora-tories that also have permission to use the Brown Corpus.We expect hat such distribution will stimulate further usesfor semantic oncordances, uses that we have not yet ima-gined.8.
CONCLUSIONThe fact that we have control of the lexical component ofour semantic oncordance enables us to shape the lexicon tofit the corpus.
It would be possible, of course, to create aspecific semantic oncordance with a lexicon limited strictlyto the words occurring in the accompanying corpus.
Thatconstraint would have certain size advantages, but wouldmiss the opportunity to build a single general exicon ontowhich a wide variety of corpora could be mapped.The universal semantic concordance described here hasenabled us to improve WordNet and has given us a tool forour studies of sense resolution in context.
In the course ofthis exercise, however, it has become apparent to us thatcross-referencing a lexicon and a textual corpus produces ahybrid resource that will be useful in a variety of practicaland scientific applications.
It has occurred to us that seman-tic concordances might be even more useful if a richer syn-tactic component could be incorporated, but how best toaccomplish that is presently a question for the future.ACKNOWLEDGMENTSThis work has been supported in part by Grant No.N00014-91-J-1634 from the Defense Advanced ResearchProjects Agency, Information and Technology Office, andthe Office of Naval Research, and in part by grants from theJames S. McDonnell Foundation and from the Pew Charit-able Trusts.
We are indebted to Henry Ku~era nd W. Nel-son Francis for permission to use the Brown Corpus in ourresearch.
And we are indebted for assistance and advice toAnthony Adler, Christiane Fellbaum, Kathy Garuba, DawnGolding, Brian Gustafson, Benjamin Johnson-Laird, PhilipN.
Johnson-Laird, Shari Landes, Elyse Michaels, KatherineMiller, Jeff Tokazewski, and Pamela Wakefield.
The desig-nation, "semantic oncordance," was suggested to us bySusan Chipman.REFERENCES1.
Miller, G. A.
(ed.
), WordNet: An on-line lexical data-base.
International Journal of Lexicography (specialissue), 3(4):235-312, 1990.2.
Miller, G. A. and Fellbaum, C. Semantic networks ofEnglish.
Cognition (special issue), 41(1-3):197-229,1991.3.
Ku~era, H. and Francis, W. N. Computational nalysisof present-day American English.
Providence, RI:Brown University Press, 1967.4.
Francis, W. N. and Ku~era, H. Frequency analysis ofEnglish Usage: Lexicon and Grammar.
Boston, MA:Houghton Mifflin, 1982.5.
Leacock, C. ConText: A toot for semantic tagging oftext: User's guide.
Cognitive Science Laboratory,Princeton University: CSL Report No.
54, February1993.6.
Brill, E. A simple rule-based part of speech tagger.
InProceedings of Speech and Natural LanguageWorkshop, 112-116, February 1992.
San Mateo, CA:Morgan Kaufman.7.
Landauer, S. I. Dictionaries: The art and craft of lexi-cography.
New York: Scribner's, 1984.8.
Chapman, R. L.
(ed.)
Roget's International Thesaurus,(5th edition).
New York: HarpcrCollins, 1992.308
