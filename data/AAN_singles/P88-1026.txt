Lex icon  and  grammar  in  probab i l i s t i c  tagg ingo f  wr i t ten  Eng l i sh .Andrew David Be, aleUnit for Compum" ~ on the English LanguaseUnivenity of ~ rBailngg, LancasterEngland LAI 4Yrmb0250~..az.~c~vaxlAbst rac tThe paper describes the development of software forautomatic grammatical ana\]ysi$ of un l~ 'U i~,  uneditedEnglish text at the Unit for Compm= Research on the Ev~li~hLanguage (UCREL) at the Un ivet~ of Lancaster.
The workis ~n'nmtly funded by IBM and carried out in collaborationwith colleagues at IBM UK (W'~)  and IBM YorktownHeights.
The paper will focus on the lexicon component of theword raging system, the UCREL grammar, the datal~zlks ofparsed sentences, and the tools that have been written tosupport developmem of these comlm~ems.
~ wozk hasapplications to speech technology, sl~lfing conectim, endother areas of natural lmlguage pngessil~ ~ y ,  our goalis to provide a language model using transin'ca statistics todi.~.nbigu~ al.
:mative 1~ for a speech .
:a~nicim device.1.
Text  CorporaHistorically, the use of text corpora to provide mnp/ncaldata for tes~g gramm.~e.al theories has been regarded asimportant to varying degn~es by philologists and linguists ofdiffering pe~msions.
The use of co~us citations in ~-~,~ma~and dictionaries pre~t~ electronic da~a processing (Brown.1984: 34).
While most of the generative 8r~-,-a,iam of the60S and 70S ignored corpus ant,,: the inc~tsed power Of thenew t~mlogy  ,wenlw.
l~ points the way to newapplications of computerized text cmlxEa in dictiona~ makln~_:style checking and speech w, cognition.
Compmer corporapresent the computational linguist with the diversity andcomplexity of real language which is more challenging fortesting language models than intuitively derived examples.Ultimately grammatl must be judged by their ability tocontend with the teal facts of language and not just basicconstructs extrapolated by grammm/ans.2.
Word  Tagg ingThe system devised for automatic word tagging or part ofspeech selection for processing nmn/ng Enfli~ text, known asthe Constituent-Likelihood Automatic Word-tagging System(CLAWS) (Garside et aL, 1987) serves as the basis for thecurrent work.
The word tagging system is an automatedc~mponent of the probabilist/c parsing system we are curnmtlywoddng on.
In won/tagging, each of the rurmi.$ words in thecoqms text to be processed is associated with a pre-termina/symbol, denoting word class.
In e.~enc~ the CLAWS suite canbe conceplually divided imo two phases: tag assignment andtag selection.constable NNSI NNSI: NPI:constant JJ NNIconstituent NNIconstitut ional J J  NNI@construction NNIconsultant NNIcons~"w~-~e J J  W0contact NNI VV0contained VVD VVN jJ@containing WG NNI%contemporary JJ NNI@content NNI J J  VV0@contessa NNSI NNSI :contest NNI VV0@contestant NNIcontinue VV0continued VVD VVN JB@contraband NNI J Jcontract NNI W0@contradictory j jcontrary JJ NNIcontrast NNI VV0@Figure 1: Section of the CLAWS I.~iconJB = attributive adjective; JJ = general adjective: NNI =singular~co~mon noun; I~S1 = noun of style or title; NP1 =singular proper noun; W0 : base form of lexical verb, VVD-- past tense of lex/cal verb; WG = qng form of lexical verb;VVN = past participle of lexical verb; %, @ = probabilitymarkers; :- = word initial capital marker.211Tag assignmeat involves, for each input nmning word orpunctuation mask.
lexicon look-up, which provides one ormore potential word tags for each input word or punctuationmark.
The lexicon is a list of about 8,000 records containingfields for(1) the word form(2) the set of one or more ~u-~41da~ tabs denoting the wont'sword class(es) with probability markers attachedindicating three ~ levels of plrl0~tl~lity.Words not in the CLAWS lcxicoa me assigned potemialtabs either by suffixlist look-up, which attempts to match endcharacters of the input wo~ with a suffix in the ~ or,if the input word does not have a word.ending to match one ofthese enuies, default ags are assigned.
The procedures emurethat ~ words and neologL~as not: in the lezi~n .amgiven an analysis.de NNIade NNI VV0 NPI:made J Jede VV0 NPI :ide NNI W0side NNIwide J Joxide NNIode NNI VV0ude VV0rude NNIee NNIf ree J Jfe NNI NPI :ge NNI W0 NPI-dge NN1 WOridge NNI NPI:Figure 2: Section of the SuffixlistTag selection disambiguates the aRemative tags that areassigned to some of the running words.
Disambiguafion isachieved by invoking one-step probabilities of tag pairE_~kelihoods exmtaed from a previously tagged training corpusand upgrading or downgrading likelihoods according to theprobability markets against word tags in the lexicon orsuffixlist.
In the majority of cases, this first order Ma:kovmodel is sufficient o con~tly select he most likelyof tags associated with the input nau~g text.
(Over 90 perant  of running words am correctly disambiguatcd in this way.
)Exceptions me dealt with by invoking a look up procedme thatsearches through a limited list of groups of two or morewords, or by automatically adjus~ng the probabilities ofsequences of three tags in cases where the intermediate ag ismisleading.The curreat vemm of the CLAWS system requires no pro-editing and auribums the correct won1 tag to over 96 per centof the input running words, leaving 3 to 4 per cast to beconectat by lmaum post.editom.3.
Error AnalysisEn'm" analysis of CLAWS output has resulted, andccminms to result, in diveaue imlaovemems to the system,from the simple adjustm~ of probability weightings againsttags in the lexicon tO the inclusioa of additional procedures,for insum~ m deal wire fl~ dis~cflon l~m pn~r  namesPare of the system can also be used to develop new parts,to extend ~ pans, or to interfaz with other systems.
Forinstam~ in onler to lzaXlace a lexicon sufficiently large anddenia l  mou~ for pm~t ,  we _~___d m ~ ~ or i~Ust of almut &000 enuies to o r= 20,000 (the new CLAWSlexiccm ?oma~s almut 26,500 enn~es)..In onfer to do this, alist of 15,000 wools not alnmdy in the CLAWS lexicon wastagged msn~ the CLAWS tag as~gmnem program.
(Since theywee not already in the lexicon, the candidate tags for eachnew amy were assigned by sut~axlim toolcup or default tagasaignmem.)
The new list was rhea post-edited by interaJ~ivescum ed i~ md m ~  with the old l~icon.Anot/a~ example of 'self impmvemem' is in the pnxluaionof a better set of case-step tmmiticea probabilities.
The firstCLAWS system used a mat~ of tag trmsttion probabilitiesderived fnxn the tagged Brown corpus (F-nmcis and gu~em.1982).
Some cells of this matrix were inaccurate because ofincompmilz'lity of the Brown tagset and the CS...AWS tagset.
Toremedy this, a new manix was created by a statistics-gathedngprogram that processed the post-edited version of a corpus ofone million WOldS tagged by the ofigiglal CLAWS suite ofprograms.4.
SubcategorizationApart ~ ~ g  tim vocaiml~ coverage of theCLAWS lexicon, we are also subcamgorizing words belongingto the major won1 classes in order to reduce thc over-generation of alternative parses of semences of gx~tter thantrivial lmgtlL The task of subcalegorizafion involves:(1) a linguist's specification of a schema or typology oflexical sulr.ategorics based ca distributional am1212functional cri~efi~(2) a lexicographer's judgement in assigning one or more ofthe mbcategory codes in the linguist's schenm to themajor lexical word forms (verbs, nouns, adjectives).The amount of detail demarcated by the sub~ttegodzationtypology is dependent, in part, on the practical n~quinnne~s ofthe system.
~ subcategorization systems, uch as the oneprovided in the Longman Dic~onary of Contempora~ English(1978) or Sager's (1981) sutr.atogories, need tO be taken intoaccount.
But these are assessed critically rather thaa adop~wholesale (see for instanoe Akkenmm et al, 1985 andBoguraev et al, 1987, for a discussion of the strengths andwea~____~_ of the LDOCE grammar codes).\[I\] intran~tlve verb : ache, age, allow, care.
conflict, escape.occur, mp~y, snow.
stay, sun-bad~, swoon, talk, vanish.\[2\] transitive verb : abandon, abhor, a11ow, hoild, complete,contain, demand, exchange, get.
give, house, keep, mail,master, oppose, pardo~ spend, sumSe~e~ warn.\[3\] copular verb : appear, become, feel, ~ grow, rfmain:seem.\[4\] prepositional verb : absWd~ aim, ask.
belong, cater,consist, prey, pry, search, vote.\[5\] phrasal verb : blow, build, cry, dn~as, ease.
farm, fill,hand, jazz, look, open, pop, sham, work.\[6\] vevb followed by that-danas : accept, believe, demlnd;doubt, feel, guess, know, ~ reckon, mqu~ think.\[7\] verb followed by to-infinitive : ask.
come, dare, demand,fail, hope, intend, need, prefer, pmpese, refuse, seem, try,wish.\[8\] verb followed by -ing construction : abhor, begin.continue, deny, dislike, enjoy, keep, recall, l~'maember, risk,suggest.\[9\] ambltrans/tive rb : accept, answer, close, omnpile, cook,develop, feed, fly, move, obey, p rm~ quit.
sing, stop, teach.try.\[A\] verb habitually followed by an adverbial : appear, come,go, keep, lie, live, move, put.
sit, stand, swim, veer.\[W\] verb followed by a wh-dause : ask, choose, doubt,imagine, know, matter, mind, wonder.Figure 3: The initial schema of eleven verb subcategoriesWe began subca~gorization f the CLAWS lexicon byword-tagging the 3,000 most frequem words in the Browncorpus (Ku~ra and Francis, 1967).
An initial system of eleve~verb subcategories was proposed, and judgame~s about whichsubcategory(ies) ach verb belonged to wen: empirically testedby looking up ena'ies in the microfiche concordenoe of thetagged Lancaster/Oslo-Bergen corpus CHofland and Johansson,1982; Johansson et aL, 1986) which shows every occur~nce ofa tagged word in the corpus together with its contexLAhout 2.500 verbs have been coded in this way, and we arenow wo~ng on a more derailed system of about 80 diffem~verb subcm~q~des using the Lexicon DevelopmentEm, imnmem of Bogumev et al (1987).5.
Constituent AnalysisThe task of implemem~ a p~ohabili~c ~ algorifl~nto provide a dismnbiguatod conmimant analysis of uormmcxodEnrich is mine demanding than implementing the wordtagging suite, not least because, in order to operate in amaonm" similar tO ~ wofd-tag~\[lg model, the system mcluims(1) specification of an appropriate grammar of rules andsymbols and(2) the consuucfion of a sufficiently large d::.bank of parsedsmm~es conforming tO the (op~msD grammar specifiedin (1) tO provide suuistics of the relative likelihoods ofcons~uem tag mmsitions for consfiutcot tagdisambigumion.In order m meet hese prior n~ptin~ms, researche~ havebeen employed on a full-time basis to assemble a corpus ofparasd ~6.
Grammar  Deve lopment  and  ParsedSubcorporaThe databank of approximately 45,000" words of manuallyparsed semences of the Lancaster/Oslo-Bergen corpus(Sampson, 1987: 83ff) was processed to .show the disl/ncttypes of pmduodon das and ~ i r  fn~iue~ of occorrenco ingv,mmAr associated with the Sampson m:chank.of the UCR\]~ pmbabilistic syslz~ (Gandde and Leech, 1987:66ff) and mgges~ons from other researchers prompdng newrules resulted in a new context-f~e grammar of about 6,000pmductians cresting mine steeply nested slmcun~ than thoseof the Sampson g~anm~.
(It was antici~m_!~ that steepernesting would mduco the size of the m~ebank requin:d toobtain adequate f'n~luency stal~cs.)
The new ~w-~rnar isdefined descriptively in a Parser's Manual (Leech, 1987) andformaiLu~ as a set of context-free phrase-su~cmn: productions.Developmem of the grammar then proceeded in ~ lemwith the construc~n ofa second ,~tnhank of parsed sentences,fitting, as closely as pos,~ole" the ralas expressed by thegrammar.
The new databank comprises extracts fromnewspaper r,~pons dining from 1979-80 in the Associated Press(A.P) corpus.
Any difficolflas the grammarians had in parsingwere resolved, whine appropriate, by amending or adding rulestO the grammar.
This methodology resulted in the grammar213being modified and extended to nearly 10,000 context-freeproductions by December 1987.V' ->  VOd (I) (v)Oh (I) (Vn)Ob {I) {(Vg)/(Vn)}Figure 4: F ragm~ of the Grammar from the l~u-ser's MammlOb = operator ~ of, or ending with, a form of /~,  Odffi operator consisting of, or ending with, a form of ~ Oh -operator ~ of, or ending with, a form of the verbhart, V ffi main verb with complemmumiom V' ffi predicate;Vg = an -/rig veto p~m?
; Vn = a past participle plume; 0 =op~oml con~umm; {/} = altcmmive comuiumm.7.
Const ruct ing  the  ParsedDambankFor c~wenieme of ~ editing and compuu= pmcess~,,the constituent stmctmm are re lamen~ in a linear form, assu-inss of ~-,~nafical words with labelled bracketing.
Thegrammariam are givan prim-oum of post-?diu~l output fromthe CLAWS suite.
They then construct a consfime~ analysisfor each sentence on the p~im-om, either in derail or in outline,according to the rules described in the Pamer's Mamufl, andkey in tbeir sm~mms using an input program that checks forwell-fonnedne~ The wen-fonmsdv~ ~, t~ impo~,~l bythe pmgr~ a~:(I) mat labe2s m legal non-umnin~ symhols(2) t l~  labelled brackm tmmce(3) that the productions obufined by the ~ analysis amcontained in the existing rammar.One se~ance is p~?seraed at a time.
Any mmrs found bythe program a~ reported back to the sc~ean, once thegrammarian has sent what s/he conside~ to be the completedprose.
Sentences which are not well formed can be ~.edited orabandoned.
A validity nuuker is appended to the w.f=enco foreach sentence indicating ~ the semele has beanabandoned with errors contain~ in it.^ Shortages NN2 of_IO gasoline_NNl and..CCrapidly_RR risin~_VVG prlces_NN2 for_IFthe__AT fuel_NN1 are_VBR given_VVN as_IIthe_AT reasons_NN2 for_IF a_ATI 6.7_MCpercent_NNU reduc~ion_NNl in_II ~raffic_NNldea~hs_NN2 on_II New_NPI York_NPl s~ane NNI?
s_$ roads_NNL2 las~_MD year_NNTl .
.Figure 5: A word.tagged senu:m~ from the AP coqmsAT = article; AT1 = singular article; CC : coordinatingconjunction: IF = for as preposifiow, II = l~-posifion; IO = ofas preposition; MC ffi cardinal number;, MD ffi ordinal number,NN2 ffi plural common noun; NNL2 ffi plural locative noun;NNTI = u~mporal noun; NNU = unit of measuremen~ RR =general adverb; VBR ffi are; $ ffi germanic genitive marker.8.
Assess ing  the  Parsed  Databank  and  theGrammarWe have written ancillary prosrmn~ to help in thedevelopment of the tpmumar and to check the validity of theparses in the ~*.henk One program searches thnmgh theparsed mtqmk for every occumm~ of a consfimant matchinga specilied comfimem rag.
Output is a list of all occurrances ofthe spec i l~ ~ together with fnx lucoc~ This facilityallows selective searching through the 4-t-h~k, which is a~0OI for revising p~rts of I11 grnmmar.9.
Ske le ton  Pars ingWe are aiming to produce a millinn word corpus of parsedsentences by December 1988 so that we can implement avariant of the CYK algorithm (Hopemfl and Ullman, 1979:140) m obtain a set of pames for each sentence.
VRerbilabelling (Bahl et aL, 1983; Fomey, 1973) could be used toselect he most pmbeble prose from ~e output paine set.
Butpmblmm associated with assembling a fully parsed datnhank(t) ~ of pmmmicm ml(2) .
, ,H~ the parsed malm~ m am evolving grammar.In order to cimmmvem these problems, a su~-gy ofskeleum parsing hm been muoduced.
In skeleton pms-ing,.gFmmn~mm cream" mininml labelled bracketing by insertingonly those labelled bmckem that are unconuvversial nd, insome cases, by insm~g brackets with no labels.
The grammarvalidation routine is de-coupled from the input program sochanges to the smmmar cam be made without disrupting theinput parsing.
The strategy also ?
prevems extrusivere~o~e editing whenever the grammar is modified.Grammar development and parsed a~t~nk ccmtmction arenot mtiw.ly indeI~nd_ ~ however.
A sulmet (I0 per cant) of theskeleton pames a~ ~ for comparison with the currentgrammar, wiule another subset (I per cent) is checked byi l ~  grnmmariai~.Skeleum parting win give us a partially parsed databankwhich should limit the alternative parses compatible with thefinal grammar.
We can either assume each parse is equallylikely and use the fiequency weighted productions generatedby the paniaUy parsee d:tntmxk to upgrade or downgradealternative parses or we can use a 'restrained' outsidefmsidealgerifl~m (Baker.
1979) to find the optimal parse.214/.-: ._-> ) .
.
.
.
.
~ ~,~..,.A010 1 vIS' \[Sd\[N' IN'& \[N Shortages_NN2 \[Po of_IO \[N' \[N gasoline_NNl N\]N' \]Po\]N\]N'&\] and_CC \[N'+\[Jm rapidly_RR rising_VVG Jm\] IN prices_NN2 \[P for_IFIN" \[Da the_AT Da\] \[N fuel_NNl N\]N" \]P\]N\]N'+\]N'\] IV' lOb are_VBR Oh\] \[Vngiven_VVN \[P as II \[N' IDa the_AT Da\] IN reasons_NN2 N\]N" \]P\] \[P for_IF\[N' \[D a_ATI \[M 6.7_MC MID\] \[N percent_NNU reduction_NNl \[P in_II \[N' \[Ntraffic_NNl deaths_NN2 \[P on_II IN' \[D\[G\[N New_NPI York_NPI state_NNlN\] 's_$ G\]D\] \[N roads_NNL2 N\] \[Q\[Nr" \[D\[M last_MD M\]D\] year_NNTl Nr'\]Q\]N'\]P\]N\]N'\]P\]N\]N'\]P\]Vn\]V'\]Sd\] ._.
S'\]Figure 6: A Fully Parsed Veqi~ of the Semmce in figure 5.D = general de~ermlnafive element; Da = detetminadve element containing an article asthe last or only word; G = genitive consmu:tion; Jm = adjective phrase; M = numeral' phrase; N ffi nominal; N' ffi noun phrase; N'& =-fltlt conjunct of co-ordinated nounphrase; N'+ ffi non-initial conjunct following a conjunction; Nr' = temporal noun phrase; P= prepo~on~ phrase; Po ffi p~.pesiaon~ phrase; Q ffi quadfiec S' = sen~ Sd =declarative sentenc~A062 96 v" "  \[S Now RT ,  , " " \[Si\[N he PPHSI N\] \[V said VVD V\]Si\] , , "_" \[S&\[N we PPIS2 HI \[~ arLVBR negotiating VVG \[P under II IN duress NNI N\]P\]V\]S~\] ,_, and CC \[S+\[N they_PPHS2 HI IV can_VM p~ay_VV0 \[P w~th_IW\[N us_PPI02 N\]PT\[P like_ICS \[N a ATI cat_NNl \[P with_IW IN a_ATImouse_NNl N\]P\]N\]P\]V\]S+\]S\] ._.
_Figure 7: A Skeleton Premed Se~a~ce.word rags: ICS = im~0os/tion.conjuncli~; IW = w/~, w/thou: as prepositions;PPHSI = he, she;, PPI-IS2 = they; PPI02 = m~.
PPIS2 = we;, RT = nominal adverb oftime; VM = modal auxiliary verb; ~,pert~r.
S = incl~d~ sentence; S& = firstcoordi-,,,'d main cJause; S+ = non-inital coordinated main clmu~ following aconjun~iom Si = inte~olated or appended sentence.10.
Feamr isat ionThe development of the CLAWS tagset md UCRELgrammar owes much to the work of Quirk et al (1985) whilethe tags themselves have evolved from the Brown tagsetG :~ and Ku~ra, 1982).
However, the rules and symbolschosen have been wa~l,-~_ into a notation compatible withother theories of grammar.
For instate, tags from theextended ve~ion of the CLAWS lexicon have been translatedinto a formalism compatible with the Winchester pa~er(Sharman, 1988).
A program has also been written to map allof the ten thousand productions of the c~urent UCRELgrammar into the notation used by the Gr~-mm~tr Deve/opmentEnvironment ((\]DE) (Briscoe et at., 1987; Grover et aL, 1988;Carroll et aL.
1988).
This is a l~.liminary step in the task ofrecasting the grammar into a feanne-hased unificationformalism which will allow us to radically reduce the size ofthe rule set while preventing file grammar from overgeneradng.V 1\[ W0*  \] 50 85\[ VV0* N" \] 800 86\[ W0*  J \] 80 87\[ VV0* P \] 400 88\[ VV0* R \] 80 89\[ W0*  Fn \] 100 90Figure 8: A Fragment of tl~ UCREL grammar215!PSRULE V85 : V1  --3, V.PSRULE V86 : V1  --~ V NP.PSRULE V87 : VX --~ V AP.PSRULE V88 : V1  --~ V PP.PSRULE V89 : V1  --~ V ADVP.PSRULE vg0  : V1  -~ V V2 \[FIN\] .Figure 9: Tramlmion of the Rules in Figure 8into ODE ~msematio~1 I. SummaryIn ,~m~/ ,  we have a wor~ tagging system f l~minimal post-editing, a _~ j ly  accumulating ?oqms of parsedand a ?OIIge~-fl~: ~'.~rnmar of about ten thousandproducdons which is currently being recast into aunification forma, m Additionally, w~ have p~grams forextruding statistical and conocatinnal data from both wordtagged and pined text cotl~Om.12.
AcknowledgementsThe author is a member of a gnmp of tesearchem woddngat the Unit for Computer Research on the English Language atLancaster Univemity.
The ~ members of UCREL meGeoffrey Leech, Roger Gannde (UCRI~ directmu),Beale, Louise Denmark, Steve ~liou., Jean Forum., FannyLeech and IAta Taylor.
The work is ~nently funded by IBMUK (research grant: 8231053 and ~ out in collaborationwith Oaire Graver, Richard Sharma~ Peter Aldemo~ EzraBlack and Frederick Jelinck of IBM.13.
ReferencesErik Akkerman, Pieter Masereeuw and V/ilium Meijs (1985).
'Designing a C o m ~  Lexi~n for Linguistic Proposes'.ASCOT Report No.
I, CIP-Gegevens KoninHij~e Bib~otheeg.Den Haaf, Netherlm~.Lalit R. Bahl, Frederick Jelinck and Rol~rt L Mercer (1983).
"A Maximum I.ik~lillood A ~  tO ~ SpeechRecognition', IEEE Transactions on Pattern Analysis andMachine In:eUigence, VoL PAMI-5, No.
2, March 1983.J.
IL Baker (1979).
'Trainable Grammms for SpeechRecognition,' Proceedings of the Spring Conference of theAcoustical Society of America.Bran Boguraev, Ted Brlscoe, John ~ l l ,  David ~ andClaire Graver (19873.
'The Derivation of a GrammaticallyIndexed Lexicon from the Longman Di~onary ofContemporary Engfish', Proceedings of ACL-87, Ste~forrLCalifornia.Ted Brise~, Claire Grover, Bran Boguraev, Jolm Carroll(19873.
'A Formalism and Environment for the Develol~nentof a Large Grammar of English', proceedings ofIJCAI, Milan.Keith Brown (1984)./~nguugi?$ Today, Fomana, U.K.John Carroll, Brml Bo~,  Claire Grover, Ted Briscoe(1988).
'The Grammar Development Environment UserM~ual', Cambridge Computer Laboratory Technical Report127, Cambridge, England.Roger Gmside, Geoffrey Leech aad Geoff~y Sampson (19873.The Comp,m~gnal Analysis of English: A Corpus-BasedApproach, Longman, London and New York.Claire Graver, Ted Bt~.oe, John Can~ll, Bran Boguraev(1988).
'The Alvey Natural L,mguage Tools Proje:t Grammar:.A Wide-Coverage Compalafiooai Grammar of F~Sllxh',Lancaster Papers In ~ 47.
~ of Linguistics.Univorsity of Lma:uler: Mawdt 1988.G.
Fomey, Jr. (1973).
'1"he Viu~oi Algorithm', Proc.
IEEE,Vol 61: March 1973, pp.
268-278.W.
Nelson Franc~ mad Henry ~ (1982).
Frequency?
Analysis of English Usage: Lexicon and Granmu~, HoughtooBoston.Knut Hofland and Stig Johansson (1982).
Word Frequencies inBriOJh and Ismerican EnglisS.
Norwegian Computing Cenuefor the Humanities.
Bergen: Longmmx.
Lo~on.John E. Ho~ a~!
Jeff~'y D. Ullmm (1979).
l ~ nw Automata Theory, Languages, and Compum~on, AddlsowWesley, Reading, MesLStig J ~  F.~ Atwe~ Roger Gmeide and GeoffreyLeech (1986).
Whe Tagged LOB Corpus Users' Mmmal,'Norwegian Computing ~ for the Humanities, Bergen.Henry ~ and W. Nelson Francis (19673.
Compum:ionalAnalysis of Present-day Ame~an English, Brown Unive:sityPress, Pmvidmu:e, Rlmde lsla~Geoffrey L~ (198"/).
'Parsers' Manual', Depamnmu of!J-m~is~cs, UnivemSy of Lmmu~er.Longman Dicdonary of Conu~pomry Eng/~ (1978), secondedition (19873, Lonmman Group I.imig~ I-Iar~w andl~JnelmldRandolph Quirk, Sidney G~mn:  Geoffrey Leech and JanSvartv~ (19853.
A Compre.hens~ Grammar of the EnglishLanguage, Longm~ Inc., New Yor~Naomi Sager (1981).
Namra/ Language InformationPraces~g, Addi-?on-Wesley, Reading, Mass.Geo~ Sampson (1987).
"The grammatical database andpanm 8 scheme' in Gar~de, Leech and Smnpson, pp 82-96.Richard A. Slmmmn (1988).
"The Winchesl~r UnificationParsing System', IBM UICSC Report 999: April 1988.216
