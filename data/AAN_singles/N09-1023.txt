Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 200?208,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsContext-based Message Expansion for Disentanglementof Interleaved Text ConversationsLidan WangComputer Science Dept./UMIACSUniversity of Maryland, College ParkCollege Park, MD 20742lidan@cs.umd.eduDouglas W. OardCollege of Information Studies/UMIACSand HLT Center of ExcellenceUniversity of Maryland, College ParkCollege Park, MD 20742oard@umd.eduAbstractComputational processing of text exchangedin interactive venues in which participants en-gage in simultaneous conversations can bene-fit from techniques for automatically groupingoverlapping sequences of messages into sepa-rate conversations, a problem known as ?dis-entanglement.?
While previous methods ex-ploit both lexical and non-lexical informationthat exists in conversations for this task, theinter-dependency between the meaning of amessage and its temporal and social contextsis largely ignored.
Our approach exploits con-textual properties (both explicit and hidden)to probabilistically expand each message toprovide a more accurate message representa-tion.
Extensive experimental evaluations showour approach outperforms the best previouslyknown technique.1 IntroductionConversational media such as the text messagesfound in Internet Relay Chat presents both new op-portunities and new challenges.
Among the chal-lenges are that individual messages are often quiteshort, for the reason that conversational participantsare able to assemble the required context over thecourse of a conversation.
A natural consequence ofthis is that many tasks that we would like to performon conversational media (e.g., search, summariza-tion, or automated response) would benefit from re-assembly of individual messages into complete con-versations.
This task has been studied extensively inthe context of email (where it is often referred to as?threading?)
(Yeh et al, 2006).
The extensive meta-data associated with email and the relatively richcontent of some email messages makes email some-what of a special case in the broad set of conversa-tion recovery tasks, however.
At the opposite ex-treme, conversation ?threading?
in multi-party spo-ken interactions (e.g., meetings) would be a com-pelling application, but the word error rate of currentautomated transcription techniques somewhat limitsaccess to the lexical evidence that we know is use-ful for this task.
The recent interest in identifyingindividual conversations from online-discussions, atask that some refer to as ?disentanglement,?
there-fore seems to be something of a middle ground inthe research space: computationally tractable, repre-sentative to some degree of a broader class of prob-lems, and directly useful as a pre-processing step fora range of important applications.One way to think of this task is as a clusteringproblem?we seek to partition the messages into aset of disjoint clusters, where each cluster representsa conversation among a set of participants on a topic.This formulation raises the natural question of howwe should design a similarity measure.
Since themessages are often too short to be meaningful bythemselves, techniques based solely on lexical over-lap (e.g., inner products of term vectors weightedby some function of term frequency, document fre-quency and message length) are unlikely to be suc-cessful.
For instance, consider the multi-party ex-change in Figure 1, in which a single message maynot convey much about the topic without consider-ing what has been said before, and who said it.Fortunately for us, additional sources of evidence200(18323 Ricardo) is there a way to emulate input for aprogram listening on a COM port?
(18911 Azzie) Ricardo: Hello there, how is it going?
(18939 Ricardo) pretty good, just at the office, about toleave.
How are you?
(18970 Azzie) well, end of semester work, what couldbe better?
(18980 Josephina) if it's just reading from /dev/ttyS0 orsomething you could somehow get it to just read from anamed pipe instead(19034 Ricardo) Josephina: I might just have to end upmodifying the entire program...(19045 Ricardo) so it can read from a different inputstreamFigure 1: An example of the text message stream.
Thenumber before each author?s name denotes the time-stamp of the message.are available.
As we describe below, messagesare strongly correlated both temporally (i.e., acrosstime) and socially (i.e,, across participants).
Forexample, in our running example in Figure 1, Ri-cardo?s message (19045 Ricardo) ?so it can readfrom a different input stream?
elaborates on hisprevious message (19034 Ricardo) to Josephina.Messages that are close in time and from thesame speaker can share related meanings.
Simi-larly, we see that Ricardo?s messages to Josephina(19034 Ricardo and 19045 Ricardo) are responsesto earlier comments made by Josephina (18980Josephina), and that fact is signaled by Ricardo in-voking Josephena?s name.
This is an example ofsocial correlation: lexicalized references to identitycan also provide useful evidence.
If we take so-cial and temporal context into account, we should beable to do better at recognizing conversations thanwe could using lexical overlap alone.In recent years, several approaches have been de-veloped for detecting conversational threads in dy-namic text streams (Elsner et al, 2008; Shen etal., 2006; Wang et al, 2008).
Although they useboth lexical and non-lexical information (e.g., time,name mentions in message) for this task, they haveignored the temporal and social contexts a messageappears in, which provide valuable cues for inter-preting the message.
Correlation clustering used ina two-step approach (Elsner et al, 2008) exploitsmessage contexts to some degree, but its perfor-mance is largely limited by the classifier used in thefirst-step which computes message similarity with-out considering the temporal and social contexts ofeach message.Our approach exploits contextual properties (bothexplicit and hidden) to probabilistically expand eachmessage to provide a more accurate message rep-resentation.
The new representation leads to a muchimproved performance for conversation disentangle-ment.
We note that this is a general approach and canbe applied to the representation of non-chat data thatexhibits temporal and social correlations as well.The results that we obtain with this technique areclose to the limit of what we can measure usingpresent test collections and evaluation measures.
Tothe best of our knowledge, our work is the first toapply document expansion to the conversation dis-entanglement problem.2 Related WorkPrevious work in conversation disentanglement(i.e.
thread detection) has shown the conven-tional lexical-based clustering is not suitable for textstreams because messages are often too short andincomplete.
They focus on using discourse/chat-specific features to bias the lexical-based messagesimilarity (Elsner et al, 2008; Shen et al, 2006;Wang et al, 2008).
These features provide themeans to link messages that may not have sufficientlexical overlap but are nevertheless likely to be top-ically related.
However, our work is different fromthem in several aspects:(1) They treat individual messages as the basic ele-ments for clustering, and ignore the social and tem-poral contexts of the messages.
In our work, eachmessage is probabilistically expanded using reliableinformation from its contexts and the expanded mes-sages are the basic elements for clustering.
(2) Messages have different amount of explicit infor-mation.
For example, messages that initiate conver-sations may have more name mentions than subse-quent messages (i.e.
for establishing conversations).Previous work only uses what are explicitly presentin each message, and clusters may be erroneouslyassigned for messages that lack enough explicit in-201formation.
Our work exploits both explicit and im-plicit context for each message due to how we definecontexts (Section 3.2.1).
(3) Most work imposes a fixed window size for clus-tering and it may break up long conversations or maynot be fine-grained enough for short conversations.Given each message, we use an exponential decaymodel to naturally encode time effect and assign dif-ferential weights to messages in its contexts.Another thread of related work is document ex-pansion.
It was previously studied in (Singhal et al,1999) in the context of the speech retrieval, helpingto overcome limitations in the transcription accuracyby selecting additional terms from lexically simi-lar (text) documents.
Document expansion has alsobeen applied to cross-language retrieval in (Levowet al, 2005), in that case to overcome limitationsin translation resources.
The technique has recentlybeen re-visited (Tao et al, 2006; Kurland et al,2004; Liu et al, 2004) in the language modelingframework, where lexically related documents areused to enlarge the sample space for a documentto improve the accuracy of the estimated documentlanguage model.
However, these lexical-based ap-proaches are less well suited to conversational in-teraction, because conversational messages are oftenshort, they therefore may not overlap sufficiently inwords with other messages to provide a useful basisfor expansion.
Our technique can be viewed as anextension of these previous methods to text streams.Our work is also related to text segmentation (Jiet al, 2003) and meeting segmentation (Malioutovet al, 2006; Malioutov et al, 2007; Galley et al,2003; Eisenstein et al, 2008).
Text segmentationidentifies boundaries of topic changes in long textdocuments, but we form threads of messages fromstreams consisting of short messages.
Meeting con-versations are not as highly interleaving as chat con-versations, where participants can create a new con-versation at any time.3 MethodThis section describes our technique for clusteringmessages into threads based on the lexical similar-ity of documents that have been expanded based onsocial and temporal evidence.3.1 Context-Free Message ModelTo represent the semantic information of messagesand threads (clusters of messages), most of the priorapproaches build a document representation on eachmessage alone (using word features and time-stampand/or discourse features found in the message).
Wecall such a model a context-free message model.Most commonly, a message is represented as a vec-tor (Salton, 1989).
Each dimension corresponds toa separate term.
If a term occurs in the message,its value in the vector is non-zero.
Several dif-ferent ways of computing these values, known asterm weights, have been developed.
One of the bestknown schemes is tf-idf weighting.However, in conversational text, a context-freemodel cannot fully capture the semantics of mes-sages.
The meaning of a message is highly depen-dent on other messages in its context.
For example,in our running example in Figure 1, to fully interpretthe message 19045 Ricardo, we need to first readhis previous message (19034 Ricardo) to Josephina.Further, messages on the same topic may have lit-tle or no overlap in words (Figure 1), and the mes-sages between participants are highly interactive andare often too short and incomplete to fully capture atopic on their own.3.2 Context-Sensitive Message ModelOur main idea is to exploit the temporal and so-cial aspects of the conversations to build a context-sensitive document model for each message.
Wedo this by first identifying the temporal and socialcontexts for each message, then probabilistically ex-panding the content of each message with selectedmessages in each context.
As we have seen, a mes-sage?s contexts provide valuable cues for interpret-ing the message.
Finally, we cluster the messagesinto distinct conversations based on their new repre-sentation models.We present the formal definitions of each contextand discuss how to model them in Section 3.2.1.
InSection 3.2.2, we show how to efficiently identifythe related messages in each context, and how to usethem to expand our representation of the message.3.2.1 Social and Temporal ContextsSocial contexts: we define two kinds of social con-texts: author context and conversational context.
We202?400 ?200 0 200 40000.20.40.60.81Time diff.
between messages from same authorProbability in same thread?400 ?200 0 200 40000.20.40.60.81Time difference between name mentionProbability in same thread?400 ?200 0 200 40000.20.40.60.81Time difference between message pairsProbability in same thread(i) (ii) (iii)Figure 2: (i) Relationship between messages from the same author (ii) Relationship between messages that mentioneach other?s authors, and (iii) All pairs of messages as a function of time.
Estimation is based on training data used inexperiments.explain them in detail below.Author context: the author context of a messagem, denoted by CA(m), is the set of other messageswritten by m?s author am:CA(m) = {mi|ami = am,m 6= mi}Further, because of the nature of human conversa-tions, we would be less surprised to find messagesfrom the same person belonging to the same conver-sation if they are close in time rather than far apart.This is illustrated in Figure 2(i) 1, which shows theprobability that a pair of messages written by thesame person belong to the same conversation as afunction of the time difference between them.
Notsurprisingly, messages in m?s author context haveprobabilities which are influenced by their temporalproximity to m.We use a normal distribution (Figure 2(i)) to en-code the notion of author context.
Given two mes-sages mi and mj written by the same author, eachwith time-stamp ti and tj , respectively, the proba-bility that mj is topically related to mi given theirtime difference d = tj ?
ti is:Pa(d) = N(?a, ?2a) = 1?a?2pie?
(d?
?a)22?2aThe exponential decay helps to limit the influencefrom temporally remote messages.
For message mi,this distribution models the uncertainty that mes-sages in its author context (i.e.
other messages mjfrom the same author) belong to the same conver-sation by assigning assigning a high value to mj if1Gaussian kernels shown for illustration purpose in Figure 2are un-normalized.tj ?
ti is small.
The mean ?a is chosen to be zero sothat the curve is centered at each message.
The vari-ance can be readily estimated from training data.Conversational context: the second kind of so-cial context is the conversational context, which isconstructed from name mentions.
As pointed out byprevious linguistic studies of discourse, especiallyanalysis of multi-party conversation (ONeill et al,2003), one key difference between multi-party con-versation and typical two-party conversation is thefrequency with which participants mention each oth-ers?
names.
Name mentioning is hypothesized as astrategy for participants to compensate for the lackof cues normally present in face-to-face dialogue(ONeill et al, 2003; Elsner et al, 2008).
Althoughinfrequent, name mentions (such as Azzie?s com-ments to Ricardo in Figure 1) provide a means forlinking two speakers and their messages.The conversational context of m, CC(m), is de-fined to be the set of all messages written by peo-ple whose names are mentioned in any of am?s mes-sages (where am is the author of m), or who mentionam in their messages.
Let Ma denote all messageswritten by author a.
The conversational context ofm is:CC(m) = {?a Ma|mention(am, a)}?
{?a Ma|mention(a, am)}where mention(am, a) = true if author am men-tions a in any of am?s messages.
Mention(a, am)is similarly defined.Discussion: From the definition, mj is included inmi?s conversational context if the author of mi men-203tions the author of mj in any of mi?s messages, orvice versa.
For instance, the conversational con-text for Ricardo?s message (19034 Ricardo) in Fig-ure 1 includes the messages from Josephina (18980Josephina) due to the mentioning of Josephina inhis message.
However, it may well be the case thatmi does not contain any name mentions, e.g.
Ri-cardo?s message to Azzie (18939 Ricardo).
In thiscase, if Ricardo is being mentioned by another au-thor (here Azzie asks Ricardo a question by start-ing with his name in 18939 Azzie), message (18939Ricardo)?s conversational context will contain all ofAzzie?s messages (18911 and 18970 Azzie) accord-ing to the above definition.
This intuitively capturesthe implicit question-answer patterns in conversa-tional speech: Ricardo?s subsequent answer is a re-sponse to Azzie?s comments, hence they are in eachother?s conversational context.Our definition also accounts for another source ofimplicit context.
In interactive conversations namemention is a tool for getting people?s attention andstarting a conversation.
Once a participant ai estab-lishes a conversation with aj (such that ai may men-tion aj?s name in an initial message mp to aj), aimay stop mentioning aj?s name in subsequent mes-sages (mq) to aj .
This is illustrated in Ricardo?s lastmessage to Josephina in Figure 1.
Our definitionaccounts for the conversation continuity between ajand ai by including messages from aj in the conver-sational context of subsequent messages mq from ai(note mq may or may not mention aj).
For instance,message 19045 Ricardo continues the conversationwith Josephina from 19034 Ricardo, message 19045Ricardo thus has Josephina?s messages as part of itsconversational context.In general, a person can participate in multipleconversations over time, but as time goes on thetopic of interest may shift and the person may starttalking to other people.
So the messages in the con-versational context of mi due to earlier discussionswith other people should be assigned a lower con-fidence value for mi.
For example, five hours laterRicardo may still be active, but it is unlikely he stillchats with Josephina on the same topic, so the ear-lier messages by Josephina should receive a smallconfidence value in the conversational context of Ri-cardo?s later messages.
We illustrate this idea in Fig-ure 2(ii).
It shows the probability that message mj ,where mj ?
CC(mi), belongs to the same threadas mi, given their time difference tj ?
ti.
Thisis encoded with a normal probability distribution,N(?c, ?c) where ?c = 0 and variance is estimatedfrom training data.
Let d = tj ?
ti, the probabilitythey are topically related given mj ?
CC(mi) is:Pc(d) = 1?c?2pie?
d22?2cTemporal context: temporal context for messagem, CT (m), refers to all other messages:CT (m) = M \mwhere M denotes the entire set of messages.
Theintuition is that nearby messages to m can providefurther evidence to the semantics of m. This is illus-trated in Figure 2(iii).
From the viewpoint of doc-ument smoothing, this can also be regarded as us-ing temporally nearby messages to smooth the rep-resentation of m. So given mi, we again model itstemporal context by fitting a normal probability dis-tribution N(?t, ?t), so that if mj ?
CT (mi) andd = tj ?
ti, the probability that mj is topically re-lated to mi is:Pt(d) = 1?t?2pie?
d22?2t3.2.2 Constructing Expanded MessagesWe have shown how to use the social and tem-poral aspects of conversational text to identify andmodel the contexts of each message, and how toassign confidence values to messages in its con-texts.
We now show how to use a message?s con-texts and their associated messages to probabilisti-cally expand the given message.
We hypothesizethat the expanded message provides a more accuratemessage representation and that this improved repre-sentation can lead to improved accuracy for conver-sation disentanglement.
We will test this hypothesisin the experiment section.Each message m is represented as a vector of es-timated term counts.
We expand m using the nor-malized messages in its contexts.
For the expandedmessage m?
of m we estimate the term counts as alinear mixture of term counts from each message in204each context:c(w,m?)
= ?c(w,m) + (1?
?){?C?mj?CC(m)Pc(dji)?
c(w,mj)+ ?A?mj?CA(m)Pa(dji)?
c(w,mj)+ ?T?mj?CT (m)Pt(dji)?
c(w,mj)}These parameter values are tuned on training data:?
controls how much relative weight we give to lex-ical content of m (0.45 in our experiments), and?C , ?A and ?T are the relative weights assignedto the conversational, author and temporal contexts(0.6, 0.3, and 0.1 in our experiments, respectively).A context with large variance in its normal densitygraph should receive a small ?
value.
This is be-cause a large variance in context k implies more un-certainty on a message mj being topically related tom while mj is in the context k of m. In Figure 2,the conversational context (Figure 2(ii)) has the min-imum variance among all contexts, hence, it is moreaccurate for linking messages related in topic and itis assigned a higher ?
value (0.6), while the tempo-ral context has the lowest ?
value (0.1).
Finally, fora message mj in context k of mi, Pk(dji) indicateshow strongly we believe mj is topically related tomi, given their time difference dji.Because of the exponential decays of the normaldensities that model contexts k, messages in a con-text will contribute differentially to mi.
Temporallydistant messages will have a very low density.3.3 Single-Pass ClusteringThe expanded messages are the basic elements forclustering.
The cosine is used to measure similarity:sim(mi,mj) =?wc(w,mi)c(w,mj)?mi?
?mj?Single-pass clustering is then performed: treat thefirst message as a single-message cluster T ; for eachremaining message m compute ?T :sim(m,T ) = maxmi?T sim(mi,m)For the thread T that maximizes sim(m,T ), ifsim(m,T ) > tsim, where tsim is a threshold (0.7 inMin Mean MaxNumber of Conversations 50.00 81.33 128.00Avg.
Conv.
Length 6.20 10.60 16.00Avg.
Conv.
Density 2.53 2.75 2.92Table 1: Statistics on the IRC chat transcript data (Elsneret al, 2008).
The reported values are based on annota-tions from six different annotations for the 800 lines ofchat transcript.our experiments) empirically estimated from train-ing data, add m to T ; else, start a new cluster con-taining only m. The time complexity of this algo-rithm is O(n2), which is tractable for problems ofmoderate size.4 ExperimentsThe collection used in the experiments consists ofreal text streams produced in Internet Relay Chat,created by (Elsner et al, 2008) and annotated inde-pendently by six annotators.
As an upper (human)baseline for each of the three measures reported be-low, we report the average agreement between allpairs of annotators (i.e., treating one annotator astruth and another as a ?system?).
For our experi-ment results, we report the average across all anno-tators of the agreement between our system and eachannotator.The test collection also contains both a develop-ment set and an evaluation set.
We used the devel-opment set to approximate the normal densities usedin our context models and the evaluation set to ob-tain the results reported below.
Some statistics forthe 800 annotated messages in the chat transcript ofthe evaluation collection are shown in Table 1.
Asthat table shows, the average number of active con-versation at a given time is 2.75, which makes threaddetection a non-trivial task.4.1 Evaluation MeasuresWe conduct comparisons using three commonlyused evaluation measures for the thread detectiontask.
As a measure of the systems ability to grouprelated messages we report the F -measure (Shen etal., 2006):F =?inin maxj(F (i, j))205where i is a ground-truth conversation with lengthni, and n is the length of entire transcript.
F (i, j)is the harmonic mean of recall (fraction of the mes-sages in the i also present in j) and precision (frac-tion of messages in j also present in i), and F isa weighted sum over all ground-truth conversations(i.e., F is microaveraged).Two other evaluation measures are ?one-to-oneaccuracy?
and ?local agreement?
(Elsner et al,2008).
?One-to-one accuracy?
measures how wellwe extract whole conversations intact (e.g., as mightbe required for summarization).
It is computed byfinding the max-weight bipartite matching betweenthe set of detected threads and the set of real threads,where weight is defined in terms of percentage over-laps for each ground truth and detected thread pair.Some applications (e.g., real-time monitoring)may not require that we look at entire conversationsar once; in this case a ?local agreement?
measuremight make more sense.
?loc3?
between system andhuman annotations as the average (over all possiblesets of three consecutive messages) of whether those3 consecutive messages are assigned consistently bythe ground truth and the system.
For example, ifboth the ground truth and the system cluster the firstand third messages together and place the secondmessage in a different cluster, then agreement wouldbe recorded.4.2 Methods Used in ComparisonWe compare with the following methods:Elsner et al 2008 (best previously known tech-nique): Message similarity is computed with lexicaland discourse features, but without documentexpansion.Blocks of k: Every consecutive group of k messagesis a conversation.Pause of k: Every pause of k seconds or moreseparate two conversations.Speaker: Each speaker?s messages are treated as asingle conversation.All different: Each utterance is a separate thread.All same: The entire transcript is one conversation.4.3 ResultsFigure 3 compares the effectiveness of differentschemes in terms of the F measure.
We show resultsFigure 3: F measure.
The dotted line represents inter-annotator agreement.from the best baseline, Elsner and our technique(which we call the Context model).
The average Fbetween human annotators is shown with the dottedline at 0.55; we would expect this to be an upperbound for any model.
Our method substantially out-performs the other methods, with a 24% improve-ment over Elsner and 48% improvement over thebest baseline (speaker).
Viewed another way, oursystem achieves 98% of human performance, whileElsner and the best baseline achieve 79% and 66% ofthat bound, respectively.
From this, we can concludethat our Context model is quite effective at cluster-ing messages from same conversation together.To illustrate the impact of conversation length,we binned the lengths of ground-truth conversationsfrom a single assessor into bins of size 5 (i.e., 3?7messages, 8?12 messages, .
.
.
; there were no groundtruth bins of size 1 or 2).
Figure 4 plots the approx-imated microaveraged F at the center value of eachbin (i.e., the F for each ground truth cluster, scaledby the number of messages in the cluster).
Thesefine-grained values provide insight into the contri-bution of conversations of different sizes to the over-all microaveraged F .
The Context model performswell for every conversation length, but particularlyso for conversations containing 35 or more messagesas shown by the widened gap in that region.
Longconversations usually have richer social and tempo-ral contexts for each message.
The context modelcan benefit more from drawing evidences from thesesources and using them to expand the message, thusmakes it possible to group messages of the same206Figure 4: Dependence of F on ground-truth conversationsize, in number of messages.Figure 5: One-to-one measure.
The dotted line representsinter-annotator agreement.conversation together.
The other two methods thatignore contextual properties do not do well in com-parison.To measure how well we extract whole conversa-tions intact, Figure 5 shows the results in terms ofthe one-to-one measure, where each real conversa-tion is matched up with a distinct detected conversa-tion thread.
It is computed by max-weight bipartitematching such that the total message overlap is max-imized between the sets of detected threads and realthreads.
The average by this measure between hu-man annotators is 0.53.
In this case, the proposedcontext model achieves an 14% increase over El-sner and 32% increase over the best baseline, andit is within 88% of human performance.
This fairlyclearly indicates that our Context model can disen-tangle interleaved conversations relatively well.Finally, Figure 6 presents the results for ?local-3?to evaluate the system?s ability to do local annota-Figure 6: Local-3 measure.
The dotted line representsinter-annotator agreement.tions.
The difference between the best baseline andmaximum upper bound is small, implying limitedroom for potential improvement by any non-baselinetechniques.
Our result again compares favorablywith the previously reported result and the best base-line, although with a smaller margin of 20% over thebest baseline and 3% over Elsner as a result of therelatively high baseline for this measure.5 Conclusion and Future WorkWe have presented an approach that exploits contex-tual properties to probabilistically expand each mes-sage to provide a more accurate message represen-tation for dynamic conversations.
It is a general ap-proach and can be applied to the representation ofnon-chat data that exhibits temporal and social cor-relations as well.
For conversation disentanglement,it outperforms the best previously known technique.Our work raises three important questions: (1) towhat extent is the single test collection that we haveused representative of the broad range of ?text chat?applications?, (2) to what extent do the measures wehave reported correlate to effective performance ofdownstream tasks such as summarization or auto-mated response?, and (3) can we re-conceptualizethe formalized problem in a way that would resultin greater inter-annotator agreement, and hence pro-vide scope for further refinements in our technique.These problems will be the focus of our future work.207ReferencesMicha Elsner and Eugene Charniak.
2008.
You talk-ing to me?
A Corpus and Algorithm for Conversa-tion Disentanglement.
In ACL 2008: Proceedings ofthe 46th Annual Meeting on Association for Compu-tational Linguistics, pages 834-842, Columbus, OH,USA.
Association for Computational Linguistics.Dou Shen, Qiang Yang, Jian-Tao Sun, and Zheng Chen.2006.
Thread Detection in Dynamic Text Mes-sage Streams.
In SIGIR 2006: Proceedings of the29th annual international ACM SIGIR conference onResearch and development in information retrieval,pages 35-42, Seattle, WA, USA.
Association for Com-puting Machinery.Yi-Chia Wang, Mahesh Joshi, William Cohen, and Car-olyn Rose.
2008.
Recovering Implicit Thread Struc-ture in Newsgroup Style Conversations.
In ICWSM2008: Proceedings of the 2nd International Confer-ence on Weblogs and Social Media, pages 152-160,Seattle, WA, USA.
Association for the Advancementof Artificial Intelligence.Tao Tao, Xuanhui Wang, Qiaozhu Mei, and ChengXi-ang Zhai.
2006.
Language Model Information Re-trieval with Document Expansion.
In HLT-NAACL2006: Proceedings of the Human Language Technol-ogy Conference of the North American Chapter of theACL, pages 407-414, New York, NY, USA.
Associa-tion for Computational Linguistics.Oren Kurland and Lillian Lee.
2004.
Corpus Structure,Language Models, and AdHoc Information Retrieval.In SIGIR 2004: Proceedings of the 27th annual in-ternational ACM SIGIR conference on Research anddevelopment in information retrieval, pages 194-201,Sheffield, UK.
Association for Computing Machinery.Xiaoyong Liu and W Croft.
2004.
Cluster-based Re-trieval Using Language Models.
In SIGIR 2004: Pro-ceedings of the 27th annual international ACM SIGIRconference on Research and development in informa-tion retrieval, pages 186-193, Sheffield, UK.
Associa-tion for Computing Machinery.Amit Singhal and Fernando Pereira.
1999.
DocumentExpansion for Speech Retrieval.
In SIGIR 1999: Pro-ceedings of the 22nd annual international ACM SIGIRconference on Research and development in informa-tion retrieval, pages 34-41, Berkeley, CA, USA.
Asso-ciation for Computing Machinery.Xiang Ji and Hongyuan Zha 2003.
Domain-IndependentText Segmentation using Anisotropic Diffusion andDynamic Programming.
In SIGIR 2003: Proceedingsof the 26th annual international ACM SIGIR confer-ence on Research and development in information re-trieval, pages 322-329, Toronto, Canada.
Associationfor Computing Machinery.Michel Galley, Kathleen McKeown, Eric Lussier, andHongyan Jing.
2003.
Discourse Segmentation ofMulti-Party Conversation.
In ACL 2003: Proceed-ings of the 41st Annual Meeting of the Association forComputational Linguistics, pages 562-569, Sapporo,Japan.
Association for Computational Linguistics.Jacob Eisenstein and Regina Barzilay.
2008.
BayesianUnsupervised Topic Segmentation.
In EMNLP 2008:Proceedings of the 2008 Conference on EmpiricalMethods in Natural Language Processing, pages 334-343, Honolulu, Hawaii, USA.
Association for Compu-tational Linguistics.Igor Malioutov and Regina Barzilay 2006.
Minimum-Cut Model for Spoken Lecture Segmentation.
In ACL2006: Proceedings of the 44rd Annual Meeting of theAssociation for Computational Linguistics, pages 25-32, Sydney, Australia.
Association for ComputationalLinguistics.Igor Malioutov, Alex Park, Regina Barzilay, and JamesGlass.
2007.
Making Sense of Sound: Unsuper-vised Topic Segmentation over Acoustic Input.
In ACL2007: Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics, pages 504-511, Prague, Czech Republic.
Association for Compu-tational Linguistics.Jen-Yuan Yeh and Aaron Harnly.
2006.
Email ThreadReassembly Using Similarity Matching.
In CEAS2006: The 3rd Conference on Email and Anti-Spam,pages 64-71, Mountain View, CA, USA.Jacki ONeill and David Martin.
2003.
Text Chat in Ac-tion.
In ACM SIGGROUP 2003: Proceedings of the2003 International ACM SIGGROUP Conference onSupporting Group Work, pages 40-49, New York, NY,USA.
ACM Press.Gerard Salton.
1989.
Automatic Text Processing: theTransformation, Analysis and Retrieval of Informationby Computer.
Addison-Wesley Longman PublishingCo., Inc., Boston, MA, USA, 1989.Gina-Anne Levow, Douglas Oard, and Philip Resnik.2005.
Dictionary-based techniques for cross-languageinformation retrieval.
In Information Processing andManagement Special Issue: Cross-Language Informa-tion Retrieval, 41(3): 523-547.208
