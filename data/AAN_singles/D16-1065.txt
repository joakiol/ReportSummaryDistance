Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 680?689,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsAMR Parsing with an Incremental Joint ModelJunsheng Zhou?, Feiyu Xu?, Hans Uszkoreit?, Weiguang Qu?, Ran Li?
and Yanhui Gu??
Language Information Processing and Social Computing LabSchool of Computer Science and Technology, Nanjing Normal University, China{zhoujs, wgqu, gu}@njnu.edu.cn, liran3277@sina.com?
Language Technology Lab, DFKI, Germany{feiyu, uszkoreit}@dfki.deAbstractTo alleviate the error propagation in the tra-ditional pipelined models for Abstract Mean-ing Representation (AMR) parsing, we for-mulate AMR parsing as a joint task that per-forms the two subtasks: concept identificationand relation identification simultaneously.
Tothis end, we first develop a novel component-wise beam search algorithm for relation iden-tification in an incremental fashion, and thenincorporate the decoder into a unified frame-work based on multiple-beam search, whichallows for the bi-directional information flowbetween the two subtasks in a single incre-mental model.
Experiments on the publicdatasets demonstrate that our joint model sig-nificantly outperforms the previous pipelinedcounterparts, and also achieves better or com-parable performance than other approaches toAMR parsing, without utilizing external se-mantic resources.1 IntroductionProducing semantic representations of text is moti-vated not only by theoretical considerations but alsoby the hypothesis that semantics can be used to im-prove many natural language tasks such as questionanswering, textual entailment and machine transla-tion.
Banarescu et al (2013) described a semanticsbank of English sentences paired with their logicalmeanings, written in Abstract Meaning Representa-tion (AMR), which is rapidly emerging as an impor-tant practical form of structured sentence semantics.Recently, some literatures reported some promisingapplications of AMR.
Pan et al (2015) presentedan unsupervised entity linking system with AMR,achieving the performance comparable to the super-vised state-of-the-art.
Liu et al (2015) demonstrateda novel abstractive summarization framework drivenby the AMR graph that shows promising results.Garg et al (2016) showed that AMR can signifi-cantly improve the accuracy of a biomolecular in-teraction extraction system compared to only usingsurface- and syntax-based features.
Mitra and Baral(2016) presented a question-answering system byexploiting the AMR representation, obtaining goodperformance.Automatic AMR parsing is still in a nascentstage.
Flanigan et al (2014) built the first AMRparser, JAMR, based on a pipelined approach, whichbreaks down the whole task into two separate sub-tasks: concept identification and relation identifica-tion.
Considering that node generation is an impor-tant limiting factor in AMR parsing, Werling et al(2015) proposed an improved approach to the con-cept identification subtask by using a simple clas-sifier over actions which generate these subgraphs.However, the overall architecture is still based on thepipelined model.As a common drawback of the staged architec-ture, errors in upstream component are often com-pounded and propagated to the downstream predic-tion.
The downstream components, however, can-not impact earlier decision.
For example, for theverb ?affect?
in the example shown in Figure 1,there exist two possible concepts: ?affect-01?
and?affect-02?.
Comparatively, the first concept hasmore common use cases than the second one.
But,when the verb ?affect?
is followed by the noun ?ac-680cent?, it should evoke the concept ?affect-02?.
Ob-viously, the correct concept choice for the verb ?af-fect?
should exploit a larger context, and even thewhole semantic structure of the sentence, which ismore probable to be unfolded at the downstream re-lation identification stage.
This example indicatesthat it is necessary to allow for the interaction of in-formation between the two stages.try-01Heaffect-02accent:ARG0:ARG1:ARG1:ARG0countrynameBritish:op1:name:modFigure 1: The AMR graph for the sentence ?He tries to affect aBritish accent.
?To address this problem, in this paper we refor-mulate this task as a joint parsing problem by ex-ploiting an incremental parsing model.
The under-lying learning algorithm has shown the effectivenesson some other Natural Language Processing (NLP)tasks, such as dependency parsing and extraction ofentity mentions and relations (Collins and Roark,2004; Hatori et al, 2012; Li and Ji, 2014).
However,compared to these NLP tasks, the AMR parsing ismore challenging in that the AMR graph is morecomplicated.
In addition, the nodes in the graph arelatent.One main challenge to search for concept frag-ments and relations incrementally is how to com-bine the two subtasks in a unified framework.
Tothis end, we first develop a novel Component-WiseBeam Search (CWBS) algorithm for incremental re-lation identification to examine the accuracy loss ina fully incremental fashion compared to the globalfashion in which a sequence of concept fragmentsderived from the whole sentence are required as in-put, as the MSCG algorithm in JAMR.
Secondly,we adopt a segment-based decoder similar to themultiple-beam algorithm (Zhang and Clark, 2008b)for concept identification, and then incorporate theCWBS algorithm for relation identification into thisframework, combining the two subtasks in a sin-gle incremental model.
For parameter estimation,?violation-fixing?
perceptron is adopted since it isdesigned specifically for inexact search in structuredlearning (Huang et al, 2012).Experimental results show that the proposed jointframework significantly outperforms the pipelinedcounterparts, and also achieves better or comparableperformance than other AMR parsers, even withoutemploying external semantic resources.2 Background2.1 AMR Parsing TaskNodes of an AMR graph are labeled with con-cepts, and edges are labeled with relations.
Con-cepts can be English words (?He?
), PropBank eventpredicates (?try-01?, ?affect-02?
), or special key-words (?British?).
For example, ?affect-02?
rep-resents a PropBank roleset that corresponds to thefirst sense of ?affect?.
According to (Banarescu etal., 2013), AMR uses approximately 100 relations.The rolesets and core semantic relations (e.g., ARG0to ARG5) are adopted from the PropBank annota-tions in OntoNotes.
Other semantic relations include?mode?, ?name?, ?time?, ?topic?
and so on.
TheAMR guidelines provide more detailed descriptions.2.2 The Pipelined Models for AMR ParsingThe AMR parser JAMR is a two-stage algorithm thatfirst identifies concepts and then identifies the rela-tions that obtain between these.The concept identification stage maps spans ofwords in the input sentence to a sequence of con-cept graph fragments.
Note that these graph frag-ments, in some cases, are subgraphs with multi-ple nodes and edges, not just one labeled conceptnode.
The relation identification stage adds edgesamong the concept subgraph fragments identified inthe first stage.
JAMR requires the output subgraphG =< VG, EG > should respect the following con-straints:(1) Simple: For any two vertices u and v ?
VG, EGincludes at most one edge between u and v.(2) Connected: G must be weakly connected (everyvertex reachable from every other vertex, ignor-ing the direction of edges).
(3) Deterministic: For each node u ?
VG, and foreach label l ?
{ARG0, .
.
.
,ARG5} , there is at681most one outgoing edge inEG from uwith labell.To find a maximum spanning AMR graph, JAMRproposed a two-step approach1 .
First, a graph thatignores constraint (3) but respects the others wascreated, by searching for the maximum spanningconnected subgraph from an edge-labeled, directedgraph representing all possible relations between theidentified concepts; Second, a Lagrangian relaxationwas adopted to iteratively adjust the edge scores soas to enforce constraint (3).In order to train the parser, JAMR built an auto-matic aligner that uses a set of rules to greedily alignconcepts to spans of words in the training data togenerate an alignment table.3 AlgorithmsBased on the hypothesis that concept identificationand relation identification are interrelated, we pro-pose to jointly perform the two subtasks in a sin-gle model.
To this end, we present an incrementalmodel for AMR parsing.
Evidence from psycholin-guistic research also suggests that human languagecomprehension is incremental.
Comprehenders donot wait until the end of the sentence before theybuild a syntactic or semantic representation for thesentence.However, the challenges of successfully applyingthe incremental joint model to this problem formu-lation are: 1) how can we design an effective decod-ing algorithm for identifying the relations betweenthe nodes in an incremental fashion, given a partialsequence of spans, i.e., a partial sequence of gold-standard concept fragments; 2) further, if given asentence, how can we design an incremental frame-work to perform concept identification and relationidentification simultaneously.
In the following sub-sections we introduce our solutions to these chal-lenges in detail.3.1 An Incremental Decoding Algorithm forRelation IdentificationWe define the relation identification problem as find-ing the highest scoring graph y from all possible out-1In this paper, we refer to this two-step approach for relationidentification as MSCG algorithm.puts given a sequence of concept fragments c:F (c) = argmaxGen(c)Score(y) (1)where Gen(c) denotes the set of possible AMRgraph for the input c. The score of an output parsey is defined to be decomposed by edges, and with alinear model:Score(y) =?e?EywT ?
?
(e) (2)where ?
(e) is the feature vector over the edge e, andw is weight vector of the model.The AMR graph is a directed graph that respectsthree constraints (see section 2.2) and has a nodemarked as the focus node.
Obviously, finding such amaximum spanning graph in AMR parsing in factcarries more complexities than that of maximumspanning tree (MST) decoding for syntactic parsing.Especially, performing the task incrementally is sub-stantially harder than doing it non-incrementally.
Inboth cases, parsing is in general intractable and weprovide an approximate inference algorithm to makethese cases tractable.Inspired by the graph-based dependency parserunder the framework of beam-search, which yieldsa competitive performance compared to the exact-search-based counterpart (Zhang and Clark, 2008a),we develop a CWBS algorithm for the relation iden-tification task.Basically, the decoder works incrementally, build-ing a state item (i.e.
a partial AMR graph) fragmentby fragment.
When each concept fragment is pro-cessed, edges are added between the current con-cept fragment and its predecessors.
However, howto treat its predecessors is a difficult problem.
Inour experiments, we found that if we consider everypreceding concept fragment to the left of the cur-rent fragment in a right-to-left order in the searchprocess, the decoder suffers from low efficiencyand poor performance.
Unlike the beam-search fordependency parsing, which can greatly reduce thesearch space by exploiting the projectivity propertyof the dependency tree (Covington, 2001; Zhang andClark, 2008a), this naive search process in this con-text inevitably leads to huge search space, and fur-thermore is difficult to guarantee the connectivity of682output graph.
Instead, we propose a component-wise beam search scheme, which can not only al-leviate much noisy partial candidate, but also ensurethat the final output graph is connected.Algorithm 1 shows the pseudocode for the com-plete procedure of the decoder.
In a nutshell, thealgorithm builds the AMR graph in one left-to-rightpass over the sequence of concept fragments.
Beamsearch is applied by keeping the B-best2 items inthe agenda at each processing stage, according to thescores of partial graph up to the current concept frag-ment.
Lets take an illustrative diagram to demon-strate the procedure (see Figure 2).
When appendingthe current concept fragment to the left partial graphto extend it, we just need to consider the relations be-tween current concept and each preceding connectedcomponent.
However, even at this single step, pick-ing B-best extended partial graphs is still a difficulttask due to the large combination space.
Here, weadopt an effective nested beam search strategy atthis step.
In other words, edges are added betweenthe current concept fragment and its preceding con-nected components by iterating through these com-ponents in a right-to-left order3 using an inner beam-search.
When examining the edges between the cur-rent concept fragment and some preceding compo-nent, four elementary actions are used:(1) SHIFT (lines 12-14): Add only current conceptto the partial graph.
(2) LEFT-ARC (lines 16-19): Add current conceptand a highest-scoring edge from a node in thecurrent concept to a node in some precedingconnected component to the partial graph.
(3) RIGHT-ARC (lines 21-24): Add current con-cept and a highest-scoring edge from a node insome preceding connected component to a nodein current concept to the partial graph.
(4) LEFT & RIGHT-ARCS (lines 26-27): Addcurrent concept and highest-scoring left arc andright arc to the partial graph.The first three actions are similar in form to thosein the Arc-Standard algorithm for transition-based2The constant B denotes the beam size.3The right-to-left order reflects the principle of local priority.Figure 2: An illustrative diagram for CWBS algorithm.
Eachdotted box corresponds to a connected component in the par-tial graph, each of which consists one or multiple concept frag-ments.
The rightmost subgraph corresponds to the current con-cept fragment.dependency parsing (Nivre, 2008; Zhang and Clark,2008a).
The last one is defined to cope with thecases where there may be multiple parents for somenodes in an AMR graph.
Note that the ?SHIFT?action does not add any edges.
This operation isparticularly necessary because the partial graphs arenot always connected during the search process.
Inour experiments, we also found that the number ofconnected components during search process is rel-atively small, which is generally less than 6.
It is im-portant to note that, in order to guarantee the outputgraph connected, when the last concept fragment isencountered, the ?SHIFT?
action is skipped (see line10 in Algorithm 1), and the other three ?arc?
actionswill add edges to connect the last concept fragmentwith all preceding connected components to yield aconnected graph.For purpose of brevity, we introduce somefunctional symbols in Algorithm 1.
FunctionCalEdgeScores(state, ci) calculates the scores ofall candidate edges between the nodes in currentconcept fragment ci and the nodes in the partialgraph in state covering (c1, c2, .
.
.
, ci?1).
For com-puting the scores of edges, we use the same fea-tures as JAMR (refer to Flanigan et al (2014) formore details).
Function FindComponents(state)returns all connected components (p1, p2, .
.
.
, pm)in the partial graph in state, sorted by the max-imum end position of spans including in everycomponent.
The AddItem function adds the cur-rent concept fragment and left/right arc to thepartial graph.
Function AppendItem(buf, item)inserts the partial graph item into buf by itsscore.
Functions GetMaxLeftEdge(ci, pj) and683Algorithm 1 The incremental decoding algorithm forrelation identification.Input: A sequence of concept fragments (c1, c2, .
.
.
, cn)Output: Best AMR graph including (c1, c2, .
.
.
, cn)1: agenda?
{Empty-graph}2: for i?
1 .
.
.
n do3: for state in agenda do4: CalEdgeScores(state, ci)5: (p1, p2, .
.
.
, pm)?
FindComponents(state)6: innerAgenda?
state7: for j ?
m. .
.
1 do8: buf ?
NULL9: for item in innerAgenda do10: if i < n then11: //Add only ci to the item12: newitem?
item13: AddItem(newitem, ci)14: AppendAgenda(buf, newitem, i, n)15: // Add a left arc from ci to pj to the item16: newitem?
item17: le?
GetMaxLeftEdge(ci, pj)18: AddItem(newitem, ci, le)19: AppendAgenda(buf, newitem, i, n)20: //Add a right arc from pj to ci the item21: newitem?
item22: re?
GetMaxRightEdge(pj , ci)23: AddItem(newitem, ci, le)24: AppendAgenda(buf, newitem, i, n)25: //Add both left and right arc to the item26: AddItem(item, ci, le, re)27: AppendAgenda(buf, item, i, n)28: innerAgenda?
B-best(buf)29: agenda?
innerAgenda30: return agenda[0]31: function AppendAgenda(buf, item, i, n)32: //parameter n represents the terminal position33: if i = n then34: CalRootFeatures(item)35: AppendItem(buf, item)GetMaxRightEdge(pj , ci) pick the highest-scoringleft-arc and right-arc linking current fragment ci andthe connected component pj by the scores returnedfrom the CalEdgeScores function, respectively.Finally, the function CalRootFeatures(g) firstcomputes the scores for all nodes in the output graphg by treating them as the candidate root respectively,and then pick the node with the highest score asthe focus node of the graph.
When computing thescore for each candidate node, similar to JAMR, twotypes of features were used: the concept of the node,and the shortest dependency path from a word in thespan to the root of the dependency tree.The time complexity of the above algorithm isO(MB2n), where M is the maximum number ofconnected components during search, B is beamsize and n is the number of concept fragments.
Itis linear in the length of sequence of concept frag-ments.
However, the constant in the O is relativelylarge.
In practice, the search space contains a largenumber of invalid partial candidates.
Therefore,we introduce three partial output pruning schemeswhich are helpful in reducing search space as wellas making the input for parameter update less noisy.Firstly, we limit the number of children and par-ents of every node.
By observing the training data,we set the maximum numbers of children and par-ents of every node as 7 and 4, respectively.
Sec-ondly, due to the fact that all frame argumentsARG0-ARG5 are derived from the verb framesets,the edges with label l ?
{ARG0, .
.
.
, ARG5} thatdo not outgo from a verb node will be skipped.Finally, consider the determinism constraint (as il-lustrated in section 2.2) that should be satisfied by anAMR representation.
When one edge has the samelabel l ?
{ARG0, .
.
.
, ARG5} as one of edges out-going from the same parent node, this edge will alsobe skipped.
Obviously, this type of pruning can en-force the determinism constraint for every decodingoutput.3.2 Joint Decoding for Concept Identifica-tionand Relation IdentificationIn this section, we further consider the joint decod-ing problem for a given sentence x, which maps thesentence x to an output AMR graph y.
The objectivefunction for the joint decoding is as follows:y?
= argmaxy?
?Gen(x)(wT ?
?
(x, y?)
+ wT ?
f(y?))
(3)where the first term is to calculate the score overall concept fragments derived from the words in thesentence x, and the second one is to calculate thescore over all edges linking the concept fragments.Maximizing Equation (3) amounts to concurrentlymaximizing the score over the concept fragmentsand the score over the edges.
Admittedly, the jointdecoding problem is more intricate and in general684intractable.
Therefore, we use a beam-search-basedincremental decoder for approximate joint inferenceduring training and testing.In order to combine the two subtasks in a uni-fied framework, we first relax the exact-search forconcept identification in JAMR by beam search,resulting in a segment-based decoder similar tothe multiple-beam algorithm in (Zhang and Clark,2008b; Li and Ji, 2014), and then incorporate theCWBS algorithm for relation identification (as de-picted in section 3.1) into this framework, whichprovides a natural formulation for combining thetwo subtasks in a single incremental model.Algorithm 2 shows the joint decoding algorithm.In short, during performing joint decoding incre-mentally for the input sentence, for each word indexi in the input sentence, it maintains a beam for thepartial graphs whose last segments end at the i-thword, which is denoted as agendas[i] in the algo-rithm.
When the i-th word is processed, it either trig-gers concepts starting from this word by looking upthe alignment table generated from the training data,or evokes no concept (we refer to this type of wordsas function words).
If the current word triggers mul-tiple concepts, we first append each candidate con-cept to the partial graphs in the beam agendas[i?1],by using a component-wise beam search way (seesection 3.1), and then pick B-best extended partialgraphs by exploiting the features from both the con-cept level and relation level to compute the overallscores.In particular, judging whether a word is a func-tion word is an important and difficult task.
Forexample, the word ?make?
corresponds to multiplecandidate concepts in the alignment table, such as?make-01?
and ?make-02?.
However, it can alsoact as a functional word in some cases.
To re-solve the judgement problem, we view each wordas a function word and a non-function word at thesame time to allow them to compete against eachother by their scores.
For instance, for the i-thword, this is done by combining all partial graphsin the beam agendas[i ?
1] with those in the beamagendas[i] to select B-best items and then recordthem in agendas[i], which is represented as theUnion function in Algorithm 2.After all words are processed, the highest-scoringgraph in the beam corresponding to the terminal po-Algorithm 2 The joint decoding algorithm.Input: Input sentence x = (w1, w2, .
.
.
, wn)Output: Best AMR graph derived from x1: agendas[0]?
?2: last?
Scan(x)3: for i?
1 .
.
.
n do4: list?
Lookup(x, i)5: if list.size > 0 then6: preAgenda?
agendas[i?
1]7: for cf ?
list do8: end?
i+ cf .size?
19: if preAgenda.size = 0 then10: g ?
Graph.empty11: CalConceptFeatures(g, cf )12: AppConcept(agendas, end, g, cf, last)13: else14: for item ?
preAgenda do15: g ?
item16: CalConceptFeatures(g, cf )17: AppConcept(agendas, end, g, cf, last)18: Union(agendas, i, i?
1)19: else20: agendas[i]?
agendas[i?
1]21: bestGraph?
agendas[last][0]22: return bestGraphsition of the sentence is selected as the output.In algorithm 2, function Scan(x) is used to searchthe terminal position corresponding to the last con-cept fragment in the sentence x, which will bepassed as a parameter to the function AppConcept.The Scan function can be efficiently implemented bycalling the function Lookup in a right-to-left order.Function Lookup(x, i) maps a sequence of wordsstarting from the index i in sentence x to a set of can-didate concept fragments, by looking up the align-ment table that was generated from the training data.The alignments are accomplished using an alignerfrom JAMR.
Motivated by Werling et al (2015), wealso adopt two additional actions to generate the can-didate concept fragments: LEMMA and VERB.
Theaction LEMMA is executed by using the lemma ofthe source token as the generated node title, and theaction VERB is to find the most similar verb in Prop-Bank based on Jaro-Winkler distance, and adopt itsmost frequent sense.Function CalConceptFeatures(g, cf ) calculatesthe feature vector for the candidate concept frag-ment cf and the partial graph g, using the features685defined in Table 1.
Among them, features 1-4are from JAMR.
Additional features 5-16 aim tocapture the association between the current conceptand the context in which it appears.
FunctionAppConcept(agendas, end, g, cf, last) appendsthe current concept cf to the partial graph g,and then inserts the extended partial graph intoagendas[end].
Note that when the parameter endequals to the parameter last, this function will callthe function CalRootFeatures to select the focusnode, as illustrated in Algorithm 1.Name Description1 Fragment givenwordsRelative frequency estimates ofthe probability of a conceptfragment given the span ofwords.2 Span length The length of the span.3 NER 1 if the span corresponds to anamed entity, 0 otherwise.4 Bias 1 for any concept fragmentfrom the alignment table, 0 oth-erwise.5 cc represents the current con-cept label, w represents the cur-rent words, lem represents thecurrent lemmas, pos representsthe current POS tags.
w?1 de-notes the first word to the left ofcurrent word, w+1 denotes thefirst word to the right of currentword, and so on.6 c+ w7 c+ lem8 c+ pos9 c+ w?110 c+ w+111 c+ pos?112 c+ pos+113 c+ w?214 c+ w+215 c+ pos?216 c+ pos+2Table 1: Features associated with the concept fragments.3.3 Violation-Fixing Perceptron for TrainingOnline learning is an attractive method for the struc-tured learning since it quickly converges within afew iterations (Collins, 2002).
Particularly, Huanget al (2012) establish a theoretical framework called?violation-fixing perceptron?
which is tailored forstructured learning with inexact search and has prov-able convergence properties.
Since our incremen-tal decoding for AMR parsing is an approximate in-ference, it is very natural to employ violation-fixingperceptron here for AMR parsing training.Specifically, we use an improved update method?max-violation?
which updates at the worst mistake,and converges much faster than early update withsimilar or better accuracy.
We adopt this idea hereas follows: decode the whole sentence, and findthe word index i?
where the difference between thecandidate partial graph and gold-standard one is thebiggest.
Only part of the graph ending at the wordindex i?
is used to calculate the weight update, inorder to account for search errors.To reduce overfitting, we used averaged parame-ters after training to decode test instances in our ex-periments.
The resulting model is called averagedperceptron (Collins, 2002).Additionally, in our training algorithms, the im-plementation of the oracle function is rela-tivelystraightforward.
Specifically, when the i-th span isprocessed in the incremental parsing process, thepartial gold-standard AMR graph up to the i-th spanconsists of the edges and nodes that appear beforethe end position of the i-th span, over which thegold-standard feature vectors are calculated.4 Experiments4.1 Dataset and Evaluation MetricFollowing previous studies on AMR parsing, our ex-periments were performed on the newswire sectionsof LDC2013E117 and LDC2014T12, and we alsofollow the official split for training, development andevaluation.
Finally, we also show our parsers perfor-mance on the full LDC2014T12 dataset.
We evalu-ate the performance of our parser using Smatch v2.0(Cai and Knight, 2013), which counts the precision,recall and F1 of the concepts and relations together.4.2 Development ResultsGenerally, larger beam size will increase the com-putational cost while smaller beam size may reducethe performance.
As a tradeoff, we set the beam sizeas 4 throughout our experiments.
Figure 3 shows thetraining curves of the averaged violation-fixing per-ceptron with respect to the performance on the bothdevelopment sets.
As we can see the curves con-verge very quickly, at around iteration 3.6860.660.670.680.690.70.710.720 1 2 3 4 5 6 7 8 9 10F-measureNumber of training iterationsLDC2014T112LDC2103E117Figure 3: Learning curves on development sets.Dataset System P R F1LDC2013E117 MSCG .85 .77 .81CWBS .85 .78 .81LDC2014T12 MSCG .84 .77 .80CWBS .84 .77 .80Table 2: Results of two different relation identification algo-rithms.4.3 Incremental Relation IdentificationPerformanceBefore performing joint decoding, we should firstverify the effectiveness of our incremental algorithmCWBS.
The first question about CWBS is whetherthe component-wise search is a valid scheme for de-riving the gold-standard AMR graph given the se-quence of gold-standard concepts.
Therefore, wefirst implement an oracle function by performing theincremental component-wise search for each frag-ment sequence c to get a ?pseudo-gold?
graph G?c;Then we compare with gold-standard AMR graphGc .
On the training data of LDC2013E117 andLDC2014T12, we respectively got an overall 99.6%and 99.7% F-scores for all < G?c, Gc > pairs, whichindicates that our component-wise search is an ef-fective incremental search scheme.Further, we train a perceptron model using themax-violation update to approximate the oraclesearch procedure.
As shown in Table 2, our in-cremental algorithm CWBS achieves almost thesame performance as the non-incremental algorithmMSCG in JAMR, using the same features as MSCG.The results indicate that CWBS is a competitive al-ternative to MSCG.4.4 Joint Model vs. Pipelined ModelIn this section, we compare the overall performanceof our joint model to the pipelined model, JAMR4.To give a fair comparison, we first implemented sys-tem 1 only using the same features (i.e., features 1-4 in Table 1) as JAMR for concept fragments.
Ta-ble 3 gives the results on the two datasets.
In termsof F-measure, we gain a 6% absolute improvement,and a 5% absolute improvement over the results ofJAMR on the two different experimental setups re-spectively.Next, we implemented system 2 by using morelexical features to capture the association betweenconcept and the context (i.e., features 5-16 in Table1).
Intuitively, these lexical contextual featuresshould be helpful in identifying concepts in parsingprocess.
As expected, the results in Table 3 showthat we gain 3% improvement over the two differentdatasets respectively, by adding only some addi-tional lexical features.Dataset System P R F1LDC2013E117JAMR(fixed) .67 .58 .62System 1 .72 .65 .68System 2 .73 .69 .71LDC2014T12JAMR(fixed) .68 .59 .63System 1 .74 .63 .68System 2 .73 .68 .71Table 3: Comparison between our joint approaches and thepipelined counterparts.Dataset System P R F1LDC2013E117CAMR* .69 .67 .68CAMR .71 .69 .70Our approach .73 .69 .71LDC2014T12CAMR* .70 .66 .68CAMR .72 .67 .70CCG-based .67 .66 .66Our approach .73 .68 .71Table 4: Final results of various methods.4.5 Comparison with State-of-the-artWe give a comparison between our approach andother state-of-the-art AMR parsers, including CCG-based parser (Artzi et al, 2015) and dependency-based parser (Wang et al, 2015b).
For comparison4We use the latest, fixed version of JAMR, available athttps://tiny.cc/jamr.687purposes, we give two results from two different ver-sions of dependency-based AMR parser5: CAMR*and CAMR.
Compared to the latter, the former de-notes the system that does not use the extended fea-tures generated from the semantic role labeling sys-tem, word sense disambiguation system and so on,which is directly comparable to our system.From Table 4 we can see that our parser achievesbetter performance than other approaches, evenwithout utilizing any external semantic resources.We also evaluate our parser on the fullLDC2014T12 dataset.
We use the train-ing/development/test split recommended in therelease: 10,312 sentences for training, 1,368 sen-tences for development and 1,371 sentences fortesting.
For comparison, we include the results ofJAMR, CAMR*, CAMR and SMBT-based parser(Pust et al, 2015), which are also trained on thesame dataset.
The results in Table 5 show thatour approach outperforms CAMR*, and obtainscomparable performance with CAMR.
However,our approach achieves slightly lower performance,compared to the SMBT-based parser, which addsdata and features drawn from various externalsemantic resources.Dataset System P R F1LDC2014T12JAMR(fixed) .64 .53 .58CAMR* .68 .60 .64CAMR .70 .62 .66SMBT-based - - .67Our approach .70 .62 .66Table 5: Final results on the full LDC2014T12 dataset.5 Related WorkOur work is motivated by JAMR (Flanigan et al,2014), which is based on a pipelined model, re-sulting in a large drop in overall performance whenmoving from gold concepts to system concepts.Wang et al (2015a) uses a two-stage approach;dependency parses are modified by executing a se-quence of actions to resolve dis-crepancies betweendependency tree and AMR structure.
Goodmanet al (2016) improves the transition-based parserwith the imitation learning algorithms, achieving al-most the same performance as that of Wang et al5The code is available at https://github.com/Juicechuan/AMRParsing(2015b), which exploits the extended features fromadditional trained analysers, including co-referenceand semantic role labelers.
Artzi et al (2015) in-troduces a new CCG grammar induction algorithmfor AMR parsing, combined with a factor graphto model non-compositional phenomena.
Pust etal.
(2015) adapts the SBMT parsing framework toAMR parsing by designing an AMR transformation,and adding external semantic resources.
More re-cently, Damonte et al (2016) also presents an incre-mental AMR parser based on a simple transition sys-tem for dependency parsing.
However, compared toour parser, their parser cannot parse non-projectivegraphs, resulting in a limited coverage.Our work is also inspired by a new computa-tional task of incremental semantic role labeling, inwhich semantic roles are assigned to incomplete in-put (Konstas et al, 2014).6 Conclusions and Future WorkIn this paper, we present a new approach to AMRparsing by using an incremental model for perform-ing the concept identification and relation identifica-tion jointly, which alleviates the error propagation inthe pipelined model.In future work, we plan to improve the parsingperformance by exploring more features from thecoreference resolution, word sense disambiguationsystem and other external semantic resources.
Inaddition, we are interested in further incorporatingthe incremental semantic role labeling into our in-cremental framework to allow bi-directional infor-mation flow between the two closely related tasks.AcknowledgmentsThis research is supported by projects 61472191,61272221 under the National Natural ScienceFoundation of China, projects 14KJB520022,15KJA420001 under the Natural Science Researchof Jiangsu Higher Education Institutions of China,and partially supported by the German Federal Min-istry of Education and Research (BMBF) throughthe project ALL SIDES (01IW14002) and BBDC(contract 01IS14013E).
We would also like to thankthe insightful comments from the three anonymousreviewers.688ReferencesYoav Artzi, Kenton Lee, and Luke Zettlemoyer.
2015.Broad-coverage CCG Semantic Parsing with AMR.
InProc.
of EMNLP, pages 1699?1710.Laura Banarescu, Claire Bonial, Shu Cai, MadalinaGeorgescu, Kira Griffitt, Ulf Hermjakob, KevinKnight, Philipp Koehn, Martha Palmer, , and NathanSchneider.
2013.
Abstract Meaning Representationfor Sembanking.
In Proc.
of the Linguistic AnnotationWorkshop and Interoperability with Discourse.Shu Cai and Kevin Knight.
2013.
Smatch: an EvaluationMetric for Semantic Feature Structures.
In Proc.
ofACL, pages 748?752.Michael Collins and Brian Roark.
2004.
IncrementalParsing with the Perceptron Algorithm.
In Proc.
ofACL, pages 111?118.Michael Collins.
2002.
Discriminative Training Meth-ods for Hidden Markov Models: Theory and Ex-periments with Perceptron algorithms.
In Proc.
ofEMNLP, pages 1?8.Michael A. Covington.
2001.
A Fundamental Algorithmfor Dependency Parsing.
In Proc.
of ACM SoutheastConference.Marco Damonte, Shay B. Cohen, and Giorgio Satta.2016.
An Incremental Parser for Abstract MeaningRepresentation.
arXiv preprint at arXiv:1608.06111.Jeffrey Flanigan, Sam Thomson, Jaime Carbonell, ChrisDyer, and Noah A. Smith.
2014.
A DiscriminativeGraph-Based Parser for the Abstract Meaning Repre-sentation.
In Proc.
of ACL, pages 1426?1436.Sahil Garg, Aram Galstyan, Ulf Hermjakob, and DanielMarcu.
2016.
Extracting Biomolecular InteractionsUsing Semantic Parsing of Biomedical Text.
In Proc.of AAAI.James Goodman, Andreas Vlachos, and Jason Na-radowsky.
2016.
Noise Reduction and Targeted Ex-ploration in Imitation Learning for Abstract MeaningRepresentation Parsing.
In Proc.
of ACL, pages 1?11.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Ju-nichi Tsujii.
2012.
Incremental Joint Approach toWord Segmentation, POS Tagging, and DependencyParsing in Chinese.
In Proc.
of ACL, pages 1045?1053.Liang Huang, Suphan Fayong, and Yang Guo.
2012.Structured Perceptron with Inexact Search.
In Proc.of HLT-NAACL, pages 142?151.Ioannis Konstas, Frank Keller, Vera Demberg, andMirella Lapata.
2014.
Incremental Semantic RoleLabeling with Tree Adjoining Grammar.
In Proc.
ofEMNLP, pages 301?312.Qi Li and Heng Ji.
2014.
Incremental Joint Extraction ofEntity Mentions and Relations.
In Proc.
of ACL, pages402?412.Fei Liu, Jeffrey Flanigan, Sam Thomson, Norman Sadeh,and Noah A. Smith.
2015.
Toward Abstractive Sum-marization Using Semantic Representations.
In Proc.of NAACL, pages 1086?1077.Arindam Mitra and Chitta Baral.
2016.
Addressing aQuestion Answering Challenge by Combining Statis-tical Methods with Inductive Rule Learning and Rea-soning.
In Proc.
of AAAI.Joakim Nivre.
2008.
Algorithms for Deterministic Incre-mental Dependency Parsing.
Computational Linguis-tics, 34(4):513?553.Xiaoman Pan, Taylor Cassidy, Ulf Hermjakob, Heng Ji,and Kevin Knight.
2015.
Unsupervised Entity Link-ing with Abstract Meaning Representation.
In Proc.
ofNAACL, pages 1130?1139.Michael Pust, Ulf Hermjakob, Kevin Knight, DanielMarcu, and Jonathan May.
2015.
Parsing Englishinto Abstract Meaning Representation Using Syntax-Based Machine Translation.
In Proc.
of EMNLP,pages 1143?1154.Chuan Wang, Nianwen Xue, and Sameer Pradhan.2015a.
A Transition-based Algorithm for AMR Pars-ing.
In Proc.
of NAACL, pages 366?375.Chuan Wang, Nianwen Xue, and Sameer Pradhan.2015b.
Boosting Transition-based AMR Parsing withRe-fined Actions and Auxiliary Analyzers.
In Proc.
ofACL, pages 857?862.Keenon Werling, Gabor Angeli, and Christopher D. Man-ning.
2015.
Robust Subgraph Generation ImprovesAbstract Meaning Representation Parsing.
In Proc.
ofACL, pages 982?991.Yue Zhang and Stephen Clark.
2008a.
A Tale ofTwo Parsers: Investigating and Combining Graph-Based And transition-Based Dependency Parsing Us-ing Beam-search.
In Proc.
of EMNLP, pages 562?571.Yue Zhang and Stephen Clark.
2008b.
Joint Word Seg-mentation and POS Tagging Using a Single Percep-tron.
In Proc.
of ACL, pages 888?896.689
