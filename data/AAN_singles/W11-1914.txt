Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 93?96,Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational LinguisticsHybrid Approach for Coreference ResolutionFirst Author: Sobha, Lalitha Devi., Pattabhi, RK Rao., Vijay Sundar Ram, R.Second Author: Malarkodi, CS., Akilandeswari, A.AU-KBC Research Centre,MIT Campus of Anna University,Chrompet, Chennai, India.sobha@au-kbc.orgAbstractThis paper describes our participation inthe CoNLL-2011 shared task for closedtask.
The approach used combines refinedsalience measure based pronominalresolution and CRFs for non-pronominalresolution.
In this work we also usemachine learning based approach foridentifying non-anaphoric pronouns.1 IntroductionIn this paper we describe our system, used in theCoNLL-2011 shared task ?Modeling UnrestrictedCoreference in OntoNotes?.
The goal of this task isto identify coreference chains in a document.
Thecoreference chains can include names, nominalmentions, pronouns, verbs that are coreferencedwith a noun phrases.The coreferents are classified into two types,pronominal and non-pronominal referents.
We usetwo different approaches using machine learningand salience factor in the resolution of the abovetwo types.
Pronominal resolution is done usingsalience factors and Non-Pronominals usingmachine learning approach.
Pronominal resolutionrefers to identification of a Noun phrase (NP) thatis referred by a pronominal and Non-Pronominalsare NP referring to another NP.
In the next sectionwe describe the system in detail.2 System DescriptionIn this section we give a detailed description of oursystem.
The task is divided into two sub-tasks.They arei) Pronominal resolutionii) Non-pronominal resolution2.1 Pronominal ResolutionHere we have identified salience factors andassigned weights for each factor.
Before resolvingthe pronouns we identify whether a given pronounis anaphoric or not.
In example, (1) below, thepronoun ?It?, does not refer to any entity, and it isa pleonastic ?it?.
(1) ?It will rain today?In identifying the non-anaphoric pronouns suchas ?it?
we use a CRFs engine, a machine learningapproach.
We build a language model using theabove ML method to identify the non-anaphoricpronouns and the features used in training are wordand it?s POS in a window of five (two precedingand two following words to the pronoun).
After thenon-anaphoric pronoun identification, we resolvethe anaphoric pronouns using a pronominalresolution system.
Though we use salience factorsbased on the Lappin and Leass (1994), we havesubstantially deviated from the basic algorithm andhave also used factors from Sobha (2008), wherenamed entity and ontology are considered forresolution.For identifying an antecedent for a pronoun weconsider all the noun phrases before the pronoun in93the current sentence and in the four sentencespreceding the current sentence.
Those nounphrases which agree in PNG with the pronoun areconsidered as the possible candidates.
The PNG isobtained using the gender data work of ShaneBergsma and Dekang Lin (2006).
The possiblecandidates are scored based on the salience factorsand ranked.
The salience factors considered hereare presented in the table 1.Salience Factors WeightsCurrent Sentence(sentence in whichpronoun occurs)100For the precedingsentences up to foursentences from thecurrent sentenceReduce sentence scoreby 10Current Clause(clause in whichpronoun occurs)100 ?
for possessivepronoun50 ?
for non-possessivepronounsImmediate Clause(clause preceding orfollowing the currentclause)50 ?
for possessivepronoun100 ?
for non-possessive pronounsNon-immediateClause (neither thecurrent or immediateclause)50Possessive NP 65Existential NP 70Subject 80Direct Object 50Indirect Object 40Compliment of PP 30Table 1: Salience Factors and weightsImproving pronominal resolution Using NameEntity (NE) and WordNet: Pronouns such as?He?, ?She?, ?I?
and ?You?
can take antecedentswhich are animate and particularly having the NEtag PERSON.
Similarly the pronoun ?It?
can nevertake an animate as the antecedent.
From theWordNet we obtain the information of nouncategory such as ?person?, ?object?, ?artifact?,?location?
etc.
Using the NE information providedin the document and the category information inWordNet, the irrelevant candidates are filtered outfrom the possible candidates.
Thus the antecedentand pronoun category agrees.The highest ranked candidate is considered asthe antecedent for the particular pronoun.In TC and BC genres, the pronouns ?I?
and?you?
refer to the speakers involved in theconversation.
For these pronouns we identify theantecedent using heuristic rules making use of thespeaker information provided.2.2 Non-pronominal Coreference resolutionIn identifying the Non-pronominal as said earlier,we have used a CRFs based machine learningapproach.
CRFs are well known for labelsequencing tasks such as Chunking, Named Entitytagging (Lafferty et al 2001; Taku Kudo 2005).Here we have CRFs for classification task, byusing only the current state features and not thefeatures related to state transition.
The featuresused for training are based on Soon et al(2001).We have changed the method of deriving, valuesof the features such as String match, alias, from theSoon el al method and found that our method isgiving more result.
The features used in our workare as follows.a) Distance feature ?
same as in Soon et alb) Definite NP - same as in Soon et alc) Demonstrative NP ?
same as in Soon et ald) String match ?
(Not as Soon et althe possiblevalues are between 0 and 1.
This is calculated asratio of the number of words matched between theNPs and the total number of words of the anaphorNP.
Here we consider the NP on the left side asantecedent NP and NP on the right side as anaphorNP.e) Number Agreement ?
We use the gender datafile (Bergsma and Lin, 2006) and also the POSinformationf) Gender agreement ?
We use the gender datafile (Bergsma and Lin, 2006)g) Alias feature ?
(Not as in Soon et al the aliasfeature takes the value 0 or 1.
This is obtainedusing three methods,i) Comparing the head of the NPs, if both aresame then scored as 1ii) If both the NPs start with NNP or NNPSPOS tags, and if they are same then scored as 1iii) Looks for Acronym match, if one is anacronym of other it is scored as 1h) Both proper NPs ?
same as Soon et ali )  NE tag information.94The semantic class information (noun category)obtained from the WordNet is used for the filteringpurpose.
The pairs which do not have semanticfeature match are filtered out.
We have not usedthe appositive feature described in Soon et al(2001), since we are not considering appositivesfor the coreference chains.The feature template for CRF is defined in sucha way that more importance is given to the featuressuch as the string match, gender agreement andalias feature.
The data for training is prepared bytaking all NPs between an anaphor and antecedentas negative NPs and the antecedent and anaphor aspositive NP.The core CRFs engine for Non-pronominalresolution system identifies the coreferring pairs ofNPs.
The Coreferring pairs obtained frompronominal resolution system and Non-pronominalsystem are merged to generate the completecoreference chains.
The merging is done asfollows: A member of a coreference pair iscompared with all the members of the coreferencepairs identified and if it occurs in anyone of thepair, then the two pairs are grouped.
This processis done for all the members of the identified pairsand the members in each group are aligned basedon their position in the document to form the chain.3 EvaluationIn this section we present the evaluation of thecomplete system, which was developed under theclosed task, along with the independent evaluationof the two sub-modules.a) Non-anaphoric detection modulesb) Pronominal resolution moduleThe data used for training as well as testing wasprovided CoNLL-2001 shared task (Pradhan et al,2011), (Pradhan et al, 2007) organizers.
Theresults shown in this paper were obtained for thedevelopment data.The non-anaphoric pronoun detection module istrained using the training data.
This module wasevaluated using the 91files development data.
Thetraining data contained 1326 non-anaphoricpronouns.
The development data used forevaluation had 160 non-anaphoric pronouns.
Thetable 2 shows the evaluation, of the non-anaphoricpronoun detection module.The Pronominal resolution module was alsoevaluated on the development data.
The filtering ofnon-anaphoric pronouns helped in the increase inprecision of the pronoun resolution module.
Thetable 3 shows the evaluation of pronoun resolutionmodule on the development data.
Here we showthe results without the non-anaphor detection andwith non-anaphor detection.Type ofpronounActual(goldstandard)SystemidentifiedCorrectlyAccuracy(%)AnaphoricPronouns939 908 96.6Non-anaphoricpronouns160 81 50.6Total 1099 989 89.9Table 2: Evaluation of Non-anaphoric pronounSystemtypeTotalAnaphoricPronounsSystemidentifiedpronounsSystemcorrectlyResolvedPronounsPrecision(%)Withoutnon-anaphoricpronoundetection939 1099 693 63.1With non-anaphoricpronoundetection939 987 693 70.2Table 3: Evaluation of Pronominal resolutionmoduleThe output of the Non-pronominal resolutionmodule, merged with the output of the pronominalresolution module and it was evaluated usingscorer program of the CoNLL-2011.
Theevaluation was done on the development data,shown in the table 4.On analysis of the output we found mainly threetypes of errors.
They area) Newly invented chains ?
The system identifiesnew chains that are not found in the gold standardannotation.
This reduces the precision of the95system.
This is because of the string match as oneof the features.MetricMentionDetectionCoreferenceResolutionRec  Prec F1 Rec Prec F1MUC 68.1 61.5 64.6 52.1 49.9 50.9BCUBED68.1 61.5 64.6 66.6 67.6 67.1CEAFE68.1 61.5 64.6 42.8 44.9 43.8Avg 68.1 61.5 64.6 53.8 54.1 53.9Table 4: Evaluation of the Complete Systemb) Only head nouns in the chain ?
We observedthat system while selecting pair for identifyingcoreference, the pair has only the head nouninstead of the full phrase.
In the phrase ?the letterssent in recent days?, the system identifies ?theletters?
instead of the whole phrase.
This affectsboth the precision and recall of the system.c) Incorrect merging of chains ?
The outputchains obtained from the pronominal resolutionsystem and the non-pronominal resolution systemare merged to form a complete chain.
When theantecedents in the pronominal chain are mergedwith the non-pronominal chains, certain chains arewrongly merged into single chain.
For example?the chairman of the committee?
is identified ascoreferring with another similar phrase ?thechairman of executive board?
by the non-pronominal resolution task.
Both of these areactually not referring to the same person.
Thishappens because of string similarity feature of thenon-pronominal resolution.
This merging leads tobuilding a wrong chain.
Hence this affects theprecision and recall of the system.4 ConclusionWe have presented a coreference resolution systemwhich combines the pronominal resolution usingrefined salience based approach with non-pronominal resolution using CRFs, machinelearning approach.
In the pronominal resolution,initially we identify the non-anaphoric pronounsusing CRFs based technique.
This helps inimproving the precision.
In non-pronominalresolution algorithm, the string match feature is aneffective feature in identifying coreference.
But,this feature is found to introduce errors.
We needto add additional contextual and semantic featureto reduce above said errors.
The results on thedevelopment set are encouraging.ReferencesShane Bergsma, and Dekang Lin.
2006.
BootstrappingPath-Based Pronoun Resolution.
In Proceedings ofthe Conference on Computational Lingustics /Association for Computational Linguistics(COLING/ACL-06), Sydney, Australia, July 17-21,2006.John Lafferty, Andrew McCallum, Fernando Pereira.2001.
Conditional Random Fields: ProbabilisticModels for Segmenting and Labeling Sequence Data.In Proceedings of the Eighteenth InternationalConference on Machine Learning (ICML-2001).282-289.S.
Lappin and H. Leass.
1994.
An Algorithm forPronominal Anaphora Resolution.
ComputationalLinguistics, 20(4):535?562, 1994.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, Nianwen Xue.2011.
CoNLL-2011 Shared Task: ModelingUnrestricted Coreference in OntoNotes.
InProceedings of the Fifteenth Conference onComputational Natural Language Learning (CoNLL2011).Sameer Pradhan and Lance Ramshaw and RalphWeischedel and Jessica MacBride and LinneaMicciulla.
2007.
Unrestricted Coreference:Identifying Entities and Events in OntoNotes.
InProceedings of the IEEE International Conference onSemantic Computing (ICSC)".
Irvine, CA,September 17-19, 2007.Sobha, L. 2008.
Anaphora Resolution Using NamedEntity and Ontology.
In Proceedings of the SecondWorkshop on Anaphora Resolution (WAR II), EdChrister Johansson, NEALT Proceedings Series, Vol.2 (2008) Estonia.
91-96.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
AMachine Learning Approach to CoreferenceResolution of Noun Phrases.
ComputationalLinguistics, 27(4):521?544.Taku Kudo.
2005.
CRF++, an open source toolkit forCRF, http://crfpp.sourceforge.net .96
