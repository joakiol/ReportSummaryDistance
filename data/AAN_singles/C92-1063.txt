The Typology of Unknown Words:An Experimental Study of Two CorporaXiaobo Ren and Francois Perraultxren@ccrit.doc.ca, perra ult@ ccrit.doc.caCCRIT, Communications Canada, 1575 Chomedey Bid, Laval, Qu6bec, Canada, H7V 2X2Table of contentsIntroductionRelated workCorpusHansardJobsExtracting unknown wordsTypologyG 1: Correct wordsG2: Erroneous wordsFrequency of unknown wordsRecognizing unknown wordsG2: Erroneous wordsGI: Correct wordsAcknowledgmentsReferences1.0 IntroductionMost current state-of-the-art natural language processing(NLP) systems, when presented with real-life texts, haveproblems recognizing each and every word present in theinput.
Depending on the application, the consequencescan be severe.
For example, in a machine translation sys-tem the quality of the processing may suffer and some-times further processing may even be impossible.Thereare two main reasons why a word might not be recog-razed and thus be considered unknown by the system:?
The linguistic knowledge of the system is not complete,i.e.
the word is correct but is not present in the system'sd=ctionary;?
The word is erroneous.A lot of effort has been directed towards dealing with thelatter, i.e.
finding ways of detecting and correcting erro-neous words.
Most of the developments in this area of re-search are based on a paper by Damerau \[Damerau 64\]where the author offers a classification of erroneouswords.The aim of this paper is to present further esults aboutthe frequency and types of unknown words found in real-life corpora.
We hope that the results of our study will beof some use in the development of NLP systems capableof dealing with realistic input.Our findings confirm Damerau's results in that the greatmajority of erroneous words contain a single typographi-cal error and belong to one of the four following catego-fie, s: insertion, deletion, substitution, transposition.But we have also found that a large proportion of the un-known words is made up of correct words which are notpresent in the dictionary.
For example, derived wordsalone represent 30% of all unknown words in our sam-pies.These results indicate the need for further work before anacceptable vel of robustness can be attained.
Althoughtraditional typographical error detection and correctiontechniques can be used to handle the majority of errone-ous words, much remains to be done before such prob-lematic areas as derived words can be dealt witheffectively.2.0 Related workIn his pioneering article \[Damerau 64\], the author givesvaluable information about the frequency of typogruphi-cal errors.
In his paper Damerau indicates that typically,80% of all ill-formed words in a document are file resultof one of four typographical errors:?
Transposition of two letters, e+g.
&bali instead of 61abli;?
Insertion of one extra letter, e.g.
6conomioque instead of6conomique;?
Deletion of one letter, e.g.
additionelle instead of addi-tionnelle;?
Substitution of a valid letter by one that is wrong, e.g.oglig6 instead of oblig6.More recent results \[Pollock and Zamora 83\] also indi-cate that in most cases, there is only one error per word.The classification of possible errors has been extendedover the years to include other types of errors \[Srihari 85,Szanzer 69, Veronis 88\].
Based on this body of work, weACTES DE COLlNG-92, NANTES, 23-28 ^ o~r 1992 4 0 8 Pgoc.
OF COLING-92, NANTES, AUG. 23-28, 1992can propose the following incomplete list of the possiblenature of errors:?
Typographical errors, which are errors of execution incarrying out the task of typing text on a keyboard;?
Orthographic errors, which are errors of intention attrib-utable to distraction or lack of knowledge on the part offile author;?
Syntactic and semantic errors;?
Errors committed during rite input procedure, ither byan optical character recognition device or by a speechrecognition system;?
Storage and transmission errors due to noisy electronicsor communication channels.3.0 CorpusOur typology of unknown words is based on the study oftwo corpora.3.1 HansardThe first one, a French corpus called the Hansard, is atranscript of all file proceedings that took place in tile Ca-nadian House of Commons in 1986.Since Canada is offmially a bilingual country, wheneverMembers of Parliament gather together to debate laws,the transcripts of the session have to be made available inboth English and French.
On the day a session is held,transcripts are translated and printed rapidly in order forthe Members of Parliament to have a bilingual copy ofthe previous days' session on their desk the next morn-ing.The main characteristics of this corpus are:?
Spoken language style;?
Manually typed on a conrputer;?
Made up of both translations from English to Frenchand source French statements;?
Translated by qualified professional translators;?
Translated rapidly;?
Even the source text is sometimes touched up by profes-sional writers.3.2 JobsThe second corpus, called Jobs, was obtained from Em-ployment and Immigration Canada and consists of En-glish job offers.
Employment centres across Canadareceive calls from employers offering job opportunities.Clerks are responsible for answering the telephone andwriting up the job postings.The nmin characteristics of this corpus arc:?
Telegraphic style;?
Manually typed into a computer program flint has a rig-idly formatted interface;?
Made up solely of text originally written in English;?
Written rapidly by a clerk.3.3 Extracting unknown wordsThe two cmpora differ in nature and in the way respec-tive lists of unknown words were extracted.For the Hansard corpus we tokenized the text and we au-tomatically tagged each token with a part of speech \[Fos-ter 91\].
From this list we then removed all punctuation,numbers and words beginning with a capital etter (prop-er nouns and abbreviations merit separate study).
We thensingled out all the words that could not be found in anelectronic dictionary.
For this operation we used tileDMF \[Bourbeau, Pinard 86\] which contains the equiva-lent of 59 000 entries.As for the English corpus most of the work was done byhand.
We tokenized the text as previously described butthe sifting of punctuation, numbers, words beginningwith a capital etter and known words, was done manual-ly, leaving a list of unknown words.4.0 TypologyWe trove divided the list of unknown words into two maingroups.
GI contains words that could not be recognizedbut were correct, while G2 contains erroneous words.
Wehave further subdivided these two groups into differenttypes of unknown word.Our goal has been to identi|y tendencies in this group wccall "anknown words".
In doing so, we iucrcased thenumber of types and inevitably some of these types inter-sect.
We have relied on our intuition and experience toas-sign the most plausible type to the unknown words.In this section descriptions will be given of each of thesetypes along with numerous examples.
In addition, in thecase of G2 types, we speculate on tile possible causes oferror.4.1 G1 : Correct words4.1.1 Proper nounsIn principle, proper nouus shoukl nnt be part of the list ofunknown words since we removed all words beginningwith a capital letter.
But a few occurrences of propernouns appeared with tile wrong eapitalizmion and in oth-er cases a lower case component of a proper noun (isolat-ed by the tokenization process) was found.E.g.
ottawa (Ottawa) 1,nat (B'nai Brith)ACRES DE COLlNG-92, NANIES, 23-28 Ao~r 1992 4 0 9 Prec.
OF COLING-92, NANTES, AUG. 23-28, 19924,1.2 AbbreviationsUpper case abbreviations (acronyms, initials, etc.)
are notconsidered to be unknown words, but a few (common)abbreviations are written in lower case and thus end up inthe unknown word list.E.g.
km 0dlom/~tre), pub (publieil~)4.1.3 OrdinalsAlthough numbers and punctuation have not been consid-ered valid unknown word candidates, ince letters aresometimes used as roman numbers, a few ordinal num-bers were found.E.g.
i (1), iv (4)4.1.4 Regional wordsThose are words or expressions that cannot be found intraditional dictionaries.
Some of them can found in spe-cialized dictionaries \[Shiaty 88\] and some of them can beidentified by native speakers.E.g.
abrier (couvrir), b6eosses (toilettes), cenne(sou)4.1.5 Scholarly wordsScholarly words include technical or rare words.
Theycan be found in large reference tools like Termium 2.E.g.
6cosph~re, amoxicillin, anadrome,ayatollah4.1.6 Parts of expressionsCertain expressions (French and Latin mostly) are madeup of several elements separated by spaces.
Isolated fromthe rest of the expression, some of these elements cannotbe recognized.E.g.
facto (de facto), wa (oskee wa wa),feminem (ad feminem)4.1.7 Foreign wordsin the Hansard this category corresponds toanglicisms orEnglish words appearing in a quote.E.g.
abortionniste, affluente, runn~sHowever, we also found foreign words in the Englishcorpus.E.g.
chad chow, noel, solicite4.1.8 Derived wordsDerived words are very productive.
The number of oc-carrences of this type of unknown word in the Hansardrepresents almost 30% of all unknown words.
In Frenchwe found 96 affixes that were used to form new words,I.
In the context of an example, parentheses indicate thecorrect or intended word.2.
The terminological data bank of the Translation Bu-reau of the Department of the Secretary of State of Cana-da.Certain words have both a prefix and a suffix at the sametime.E.g.
r66chelonnement, prOcommercialisationCertain affixes are more productive than others:anti-, d&, d~s-, extra-, sur-, in-, inter- rO-, super--age, -ation, -ien, -cur, -iser, -ment4.1.9 CompoundsWe excluded from the unknown word list compounds be-ginning with a capital etter and compounds that cannotbe recognized when considered as a whole nor when theelements are considered individually.
The unknownwords classified as compounds are: ones that should startwith a capital etter but do not; those in which the neces-sary spaces or hyphens have been deleted, i.e.
the ele-ments have been concatenated; and compounds made upof an element that cannot be recognized (often because ofthe 'o' infix).E.g.
c~tblodistributeurs, chimio-d6pendance,radioastronomique4.1,10 Garbled wordsWe include in this category words that are divided by ablank space, words that are joined together but are notcompounds and words which are, in general, affected byelectronic noise.
Although in some ways this could beconsidered an error, we did not want to put this categoryin G2 because contrary to other types in G2, in this casethe writer cannot be held responsible for the error.E.g.
employEs, sAvez-vous, afinque, erreur.Ce4.2 G2: Erroneous words4.2.1 AccentsThese errors are unique to the French corpus and can besubdivided into four types:?
Accent insertion.E.g.
61~vant (6levant), ~ssai (essai), 6tages(otages)?
Accent deletion.E.g.
achetera ( ch~tera), aerospatiale(a6rospatiale), ag6es (ag6es)?
Substitution of one accent for another.E.g.
hg6es (~g6es), 6v/mement (6v6nemen0,all,gem (all6gera)?
Repositioning of the accent.E.g.
chomfige (ch6mage), compose6(compos6e), d6g6utant (d6gofitant)4.2.2 PunctuationThis type of error is unique to the English corpus and cor-responds to problems with hyphens and apostrophes.There are three cases:?
Deletion of a necessary hyphen.Acrv.s D13 COLING-92, NANTES, 23-28 not.~-r 1992 4 1 0 PRoc.
OF COLING-92, NAN'rES, AUG. 23-28, 1992E.g.
cardio respiratory (cardio-respiratory),cle,anup (clean-up)?
Insertion of a hyphen.
This usually occurs when hy-phens are used to parenthesize t xt.E.g.
class-secondary, cleaners-including?
Deletion of an apostrophe denoting possession.E.g.
compauys (company's)4.2.3 InsertionsKnowing the configuration of a standard keyboard andthe way people type suggests everal plausible reasonsfor the inserfiou of superfluous characters.?
A key is held down too long, generating sequences ofidentical letters.E.g.
6tonnne, access, beaauconp, aartnership?
The finger strikes two contiguous keys at the same time.E.g.
6conomioque, 6galememnt, profcessional,tltgen?
'Influence' of other letters in the same word.E.g.
6vidememenl,, a6oroport, accueuillir,taboubli, electrolologistOther instances of insertion seem to be simply attribut-able to a lack of knowledge of the language.E.g.
6perduemeot, absoluement, orthopaedic,paediatric.For another group of insertion-type errors, no obvious ex-planation could be found.E.g.
constinu6, lotusi, manchine, xperiencep4.2.4 DeletionsThe omission of a character is the most common typo-graphical error.
This is probably related to a situationwhere rapid typing is required and where the mind mightwork faster than the hand.
tfere is a list of the ten mostfrequently omitted letters (the percentages are based onthe total number of words in this chLss):Letter r s i n t e p c 1 a-!% 9.4 9.2 6.3 5.85.8 5.4 3.2 3.1 2.5 2.2qhble 1: Most common deletions in the Han~rdLetter e i r a n s u c t h% 9.2 6.4 5.6 4.514.1 3.8 3.0 2.6 2.6 1.9Table 2: Most common deletions in Jobs4.2.5 Subst i tut ionsThis is a fairly complex category.
Substitution of one let-ter for another can be typographical or orthographic nnature.
Some tentative explanations include:?
The letter is replaced by an adjacent letter.E.g.
'indident (incident), esperience(experience), satisfaisamte (satisfaisante)?
The wrong hand is used.E.g.
quesque (quelque), gouvervement(gouveroement)?
The letter is 'influenced' by another letter in the sameword.E.g.
bubget (budget), songages ( ondages), stell(steel)?
The error is orthographic in nature.E.g.
maintenence (maintenance),engouragement (encouragement), auvrage(naufrage)- Other substitutions e cape simple explanations.E.g.
da (de), ja (je), saire (fake)4.2.6 TranspositionsThere are three types of transpositions:?
Inversion of adjacent letters.E.g.
appearnace, appmpraite, commerical?
Inversion of non-adjacent letters.E.g.
6nocomique, anamulie, condiser, ditues?
Although not strictly speaking a transposition, we alsoinclude here the displacement of a single letter.E.g.
avatanges, comagpnies, avalaible,expierence4.2.7 GrammarThere are not many errors under this heading, since nosyntactic analysis has been done in order to extract helist of unknown words.
What we have here are errors ofmorphology and conjugation.E.g.
6tEe (6t6), pines (pin), cloths (clothes)4.2.8 OtherThere are a Iew remaining words which we could not litin the other categories; ome of them are incorrect whileothers can be considered spelling variations flint are notfully standard.E.g.
tee shirt (T-shirt), thru (through)5.0 Frequency of unknown wordsThe Hansacd corpus contains 4 173 506 tokens.
Amongthese tokens we found 2 982 distinct unknown words oc-curring 9 301 times.
This represents 0.2% of all tokens.The Jobs corpus contains 140 482 tokens.
Of those, 1 016were distinct unknown words occurring 2 109 times.
Thisrepresents 1.5% of all tokens.We now present in tabular form the frequency distribu-tion of unknown words in built corpora.
For each type ofunknown word we indicate the number of distinct words(cases) and the total number of occurrences (occ.)
found.ACRES DE COLING-92, NA~Cn~S, 23-28 Ao~r 1992 4 1 l Puoc.
oF COLING-92, NArer~s, Auo.
23-28, 1992For each of these numbers, we also give the associatedpercentages over the total number of unknown words inboth G1 and G2.
Therefore the total percentages of G1and G2 add up to 100 percent.TypeDerived wordsForeign wordsScholarly words!Parts of expres-sionsGarbled wordsCompoundsOrdinalsAbbreviationsRegional wordsProper nounsTotal# ofcases % # ofocc.
%526 17.22 ' 2814 29.93392 12,83 2014 21.4273 2.39 658 7.0073 2.39 579 6.1694 3.08 296 3.1548 1.57 160 1.708 0.26 153 1.6310 0.33 43 0A618 0.59 26 0.288 0.26 21 0.221250 40.92 6764 71.93in the Hansard Table 3:G1 frequenciesType # of cases % # of occ.
%Deletions 645 21.11 976 10,38Insertions 406 13.29 503 5.35Accents 248 8.12 414 4.40Substitutions 230 7.53 319 3.39Grammar 141 4.62 258 2.74Transpositions 135 4.42 169 1.80Total 1805 59.08 2639 28.07Table 4:G2 frequencies in the HansardType # of cases % # of occ.
%Garbled words 143 13.64 322 15.27Foreign words 10 0.95 36 1.71Total 153 14.78 358 16.97Table 5:G1 frequencies in JobsTYPePunctuationsDeletionsSubstitutionsInsertionsTranspositionsOthersGrammarTotal# of cases % # of occ.
%224 21.35 514 24.37287 27.36 467 22.14158 15.06 363 17.21140 13.35 227 10.7658 5.53 87 4.1313 1.24 49 2.3216 1.53 44 2.09894 85.22 1751 83.03Table 6:G2 frequencies in JobsThe following points should be noted:?
A word containing two errors is accounted for in twocategories.
This explains why the total is a slightly high-er than the total number of unknown words given previ-ously??
In the Hansard there are 16 words (0.17%) that containmore than one error per word and 94 words (1.01%) thatbelong to both GI and G2 (e.g.
a word can be incorrectand be derived at the same dine).
On the other hand.with Jobs there are 42 words (1.99%) that contain morethan one error per word.
These results are comparable toDamerau's findings about the preponderance of singleerror words.?
Of course, different extraction procedures give differentresults.
The Hansard contains a great many correctwords not in the DMF; on the other hand the Jobs list ofunknown words contains very few of those correctwords.
When faced with a word they do not recognizeimmediately, humans have the option of consulting adictionary (general or specialized) and even if the wordis not in any of those, the person can still rely on his orher intuition about word composition and derivation inorder to accept a word.?
In the case of the Hansard the total number of occur-rences in G1 (71.93%) is much higher than the totalnumber of occurrences in G2 (28.07%).
This significantrestflt shows that instead of putting all of our efforts intotrying to develop a better error correcter, we would gaina lot from looking into ways of dealing with the defi-ciencies of our lexical databases.?
Since English does not have accents, this category is notrepresented in G2 of Jobs.?
On the other hand, errors involving hyphens and apos-trophes are very common in the Jobs corpus.
We classi-fied these as punctuation errors.?
We believe that the punctuation category of G2 Jobs isnot representative of English in general.
The high fre-quency of this type of error is due to a peculiarity of theAcrEs DE COLING-92, NANTES.
23-28 AO~r 1992 4 1 2 PROC, Ol: COLING-92, NANTES, AUG. 23-28, 1992program responsible for the input of job descriptionswhich encourages the use of hyphens to parenthesizetext.6.0 Recognizing unknown wordsIn this section we examine possible avenues of investiga-tion designed to deal with the different unknown wordtypes.6.1 G2: Erroneous wordsWheu confronted with an unknown word, the ideal NLPsystem would be able to understand the text and to dealwith what was intended by the writer, and not just whathe wrote.
But of course this is not within the scope of cur-rent technology.A more realistic goal is to try to deal with typographicalerrors and a lot of attention over the years has been givento the detection and correction of such errors.
Differentmethods have been proposed, some completely automat-ic, others meant o assist humans in proof reading, somepractical and usable, others of theoretical interest only.For a good overview of this field of research we suggest\[Peterson 80\], while \[Pollock 82\] contains an extensivebibliography.Despite years of research, the detection and correction oftypographical errors remains a problem not entirely re-solved.
Commercial software as well as state-of-the-arttechniques described in the literature can only proposeapproximate solutions.
No program is capable of detect-ing every error and capable of always uggesting the rightcorrection.Despite their limitations, ome existing methods can stillbe useful and sometimes even better than most humancorrectors.
This fact is well illustrated by the success ofcommercial detector/corroctors available on the market,despite an overall performance that can at best be de-scribed as acceptable \[Dinnematin a d Sanz 90\].in order to detect errors most techniques rely on a list ofcorrect words known to the system (a dictionary), possi-bly augmented by a set of morphological roles.Amongst he possible approaches to typographical errorcorrection, two methods eem to be more successful thanthe others.We can either compare the unknown wordagainst each of the dictionary words and if one of thosecomes close enough to the original word according tosome measure of similarity, itcan be used in its place (foran example see \]Wagner and Fischer 74\]).
Or we can takean erroneous word, undo all possible errors we want todetect and then search the dictionary to see if any of thosepotential corrections produces a valid word.
We call thismethod the hypothesis generation method.
For example atransposition error can be detected by transposing eachpair of characters in the unknown word and then consult-lug the dictionary with the resulting words.
This essen-tially is the technique used in such programs as the DEC-10 Spell software.The method based on a measure of similarity is too ineffi-cient to be practical and is mostly of theoretical interest.The latter is more efficient but also more approximate inthat it is not guaranteed tim\[ we will find a correction ifwe did not expect he offending error.\[n both cases the contents of the dictionary must be care-fully selected.
It must be large enough to offer reasonablecoverage, but on the other hand there is a real danger ofusing a list of words that is too big, in that a very exten-sive list will usually contain rare and archaic words thatcould correspond to errors on more frequent words.An error corrector integrated inan NLP system should al-low us to reduce the dictionary search space by compar-ing the erroneous word only with dictionary wordscomplying with die syntactic and semantic requirementsvalid at that time in the processing.
This should make thesearch significantly more efficient.
For example, if atsome point we are expecting a verb and we encounter anunknown word, in order to suggest corrections we couldlimit ourselves and cousitler only the verbs in the dictio-nary.due interesting aspect of typographical error correctionmethods uch as the hypothesis generation method is thatthey can also be used to correct some of the other types oferrors.
So with these methods, not only do we have a(somewhat approximate) solution to insertion, deletion,transposition and substitution errors, but in some casesthey will also solve punctuation, accent and grammar er-rors.
For example in the case of accents, we can extendthe French alphabet with the possible accented letters andsimply use this alphabet to generate more candidate cor-rections.Again if the hypothesis generation method is chosen,then further use can be made of the knowledge gainedabout he type of errors usually comufitted.
For examplein order to minimize the number of hypotheses generatedand to maximize the probability of tinding the right cor-rection, when testing the deletion of a character, onecould attentpt to "re-introduce" the character only in thecase of the 10 most frequent deletions.
More anecdotalknowledge gained through the sifting of the list of uu-knowu words could also be of .some use.
For example,duplication of consonants was a frequent type of insertionerror and thus.
if only a few hypotheses are to be tried,unknown words with duplicate consonants could be con-sidered prime candidates for insertion errors.6.2 G1 : Correct wordsThe results collected in the course of our study should atthe very least, influence the amount of effort put intodealing with each of the diflerent ypes of errors.
The re-ACIT.S DE COLING-92.
NANTES, 23-28 AO~T 1992 4 I 3 l'Roc.
OF COLING-92, NANTES, AUO.
23-28, 1992alization that a large percentage of unknown words arepart of the G1 group warrants renewed effort in treatingthis type of problem.There will always be w~ds that a system cannot recog-nize, if only because some of them belong to so-calledopen classes.
But we can still reduce the number of such.words.One obvious olution is to enrich the dictionary, for ex-ample with common abbreviations and expressions.
An-other similar, but more modular solution consists insupplementing the basic dictionary with auxiliary dictio-naries.
One could envision separate dictionaries for re-gional and scholarly words for example.The ordinals found in our corpora could easily be recog-nized by a grammar describing the formation of romannumerals.Foreign words represent a difficult problem.
They are ex-ceptions to the usual assumption that the whole text to beprocessed is expressed in the same language throughout.Although it does not completely solve the problem, thedetection of such signs as double quotes, setting thewords apart from the text, could be used to suggest thatthe following unknown words might be foreign.It might be possible to recognize garbled words and com-pounds by using methods similar to the ones used to treatG2 words.
For example the deletion of a necessary hy-phen could be detected and possibly corrected as is donefor the deletion of an ordinary character.As we have seen, derived words represent an impressivepercentage of the total number of unknown words.
Evenif we were to enlarge the dictionary we would never beable to include very derived word, for they are much tooproductive.
Therefore the solution seems to lie in a rule-based description of derivation similar to the descriptionof inflectional morphology.
This will require integratingdetailed studies of affixation and of the structure and se-mantic ompositionality of derived words.Finally, GI words are perhaps more difficult to processthan G2 words.
As \[Hayes and Mouradian 81\] put it:"Since novel words are by definition ot in theknown vocabulary, how can we distinguishthem from misspelling?
"Most of the time (but not always) they will not be closeenocagh to words in the dictionary for the system to makesuggestions.
The best one can hope for in this situation isto deduce from the context he maximum amount of in-formation about he word, such as its role in the sentence.As for the ability to learn new vocabulary, this is beyondthe capabilities ofcurrent artificial intelligence.7.0 AcknowledgmentsThis work was conducted by the Computer-AssistedTranslation group at the CCRIT.
For their participation ithe data collection we are greatly indebted to Pierre Isa~belle, Elliott Mackloviteh and Marie-Louise Hannan.
Wealso wish to thank Marc Dymetman, Marie-Louise Han-nah and Elliott Macklovitch for their helpful comments.8.0 References\[Bourbeau, Pinard 86\] Bourbeau, L. and Pinard, F., Dic-tionnaire micro-informatis~6 du Fmn~ais (DMF),1987, Progiciels Bourbeau-Pinard Inc., Montr6al.\[Damerau 64\] Damerau, F.J., A technique for computerdetection and correction of spelling errors, Comm.ACM, 1964,7, 3, pp.
171-176.\[Dinnematin a d Sanz 90\] Dinnematin, S., and Sanz, D.,Sept correcteurs pour l'orthogmphe etla gram-maire, Science t Vie Micro, 1990, pp.
118-130.\[Foster 91\] Foster, G.E, Statistical lexieal disambigua-fion, 1991, Master's thesis, McGill University,Montreal.\[Hayes and Mouradian 81\] Hayes, P.J.
and Mouradian,G.V., Flexible parsing, American Journal of Com-putational Linguistics, 81, 7, 4, pp.
232-242.\[Peterson 80\] Peterson, J. L., Computer programs for de-tecting and correcting spelling errors, Comm.ACM, 1980, 23, pp.
676-687.\[Pollock 82\] Pollock, J.J., Spelling error detection andcorrection by computer: some notes and a bibliog-raphy, Journal of Documentation, 1982, 38, 4, pp.282-291.\[Pollock and Zamora 83\] Pollock J.J. and Zamora, A.,Collection and characterization of spelling errors inscientific and scholarly texts, J.
Am.
Soc.
Inf.
Sc.,1983, 34, 1, pp.
51-58.\[Shiaty 88\] Shiaty, A.E.
ed., Dictionnaire du franc, aisplus, 1988, CEC, Montr6al.\[Srihari 85\] Srihari, S.N., Computer text recognition anderror correction, 1985, IEEE Computer SocietyPress, Silver Spring.\[Szanzer 69\] Szanzer.
A.J., Error-correcting methods innatural language processing, Information Process-ing, 1969, 68, 2.\[Veronis 88\] Veronis, J., Correction of phonographic er-rors in natural language interfaces, Comm.
ACM,1988, pp.
101-115.\[Wagner and Fischer 74\] Wagner, R.A. and Fischer, M.J., The string-to-string correction problem, JACM,1974, 21, I, pp.
168-178.AcrEs DE COL.ING-92, NANTES.
23-28 ^ ot~r 1992 4 1 4 PRoc.
OF COL1NG-92.
NANTES, AUG. 23-28, 1992
