A compact Representation of prosodically relevant Knowledge ina Speech Dialogue SystemPeter PollerGerman lZesearch Center forArtifical Intelligence (DFKI GmbH)Stuhlsatzenhausweg 366123 Saarbriicken, Germanypo ller@dfki, uni-sb, deAbstractThe acceptance of speech dialogue sys-tems by the user is critically dependenton the degree of "naturalness" realized.The speech generation and synthesis mod-ules have to be able to run in real timeand to produce high-quality speech output.To produce naturally sounding speech, thesynthesizer has to have not only the knowl-edge of the words to utter and the or-der in which they appear but also infor-mation about their structural relationship.The latter is expressed acoustically in theform of prosody, i.e.
how the voice raisesand falls during an utterance, the rhythm,where pauses are set, etc.
Prosody isalso influenced by the properties associatedwith given words in the context of an ut-terance, e.g.
the focus of a sentence or cer-tain emphatic elements.
This article de-scribes a compact representation for con-veying this type of information from thegenerator to the synthesizer in a modularsystem and describes how (parts of) this in-formation is (are) derived in the EFFENDIsystem, the generation module for a speechdialogue system for train inquiries.1 IntroductionThe speech generation and synthesis modules of aspeech dialogue system are very important, sincethey form the output "visible" to the user.
Natural-language generation for a speech dialogue systemmust therefore operate in real time.
In a systemwhich outputs speech, real time is essentially thetime the system takes before it starts to utter whatit has to say.
The reaction time to the previous userinput should be minimal.
One way of increasingPaul HeisterkampDaimler-Benz AGForschungszentrum UlmWilhelm-Runge Str.
1189081 Ulm, Germanyheist  erkamp@dbag, ulm.
daimlerbenz, cornthroughput, and thus coming closer to real-time op-eration, is to divide the input into small autonomouspackets which can be processed independent ofeachother and thus simultaneously.
Then, once the firstpart of an utterance has been generated, it can bepassed on to the synthesis module, and while thelatter is producing speech for this segment, he gen-erator can proceed to process the next segment.
Thistype of processing is known as incremental process-ing.The acoustic speech signal is by its nature volatile;it can only be heard once.
This makes it impera-tive that the generator provides the synthesizer withall information ecessary to produce high-qualityspeech.
In human speech, information is conveyednot only in the individual words, but also in theprosody which provides the listener in many subtleways how these words are related to each other.
Itoften conveys information ot explicitly contained inthe spoken words, such as the focal point of a sen-tence or the contrast of certain words (ideas) withother spoken or unspoken words.
A prerequisitefor high-grade synthetic speech is therefore that allphonologically and prosodically relevant informationcontained in the concepts forwarded to the generatorand the syntactic structure produced by it be passedon in a suitable form to the synthesis module.
Onlythe consideration of structural information can as-sure the production of high-quality prosody by thesynthesis module.
The details of these "phonolog-ical" structures are of course language dependent,but there are certain properties common to all lan-guages.
As the overall system described here isstrictly modular and (in principle) multilingual, thephonologically relevant information of an utterancehas to be coded in a high-level interface protocol,that can both be output by a variety of generatorsas well as used as input for a wriety of synthesismodules.Since the design of such an interface protocol de-17pends on the structure of the semantic input con-cepts and the syntactic structures generated fromthem, section 2 gives a short overview of the dialoguemanagement module and our generation system thathas been developed in the EFFENDI project 1.
Sec-tion 3 then describes the compact representation forprosodically relevant knowledge and briefly indicateshow the information for this representation is ob-tained from the input concepts of the generator andthe syntactic structures generated from them.
Asincremental generation often requires the repair ofsome previously generated parts, section 4 considersthe effects of incremental generation that concernthe synthesis module and how we try to avoid un-necessary repetitions of words as far as possible.
Thefinal section describes the goals of the on-going workin EFFENDI.2 Overv iew o f  the  D ia logue  SystemThe syntactic generator EFFENDI is integratedinto the speech dialogue system implemented byDaimler-Benz.
The generator itself is particularilyadapted to the specific needs of a real time speechdialogue system (cf.
(Poller and Heisterkamp 1997)).A more detailed escription of the diaogue system asa whole can be found elsewhere (cf.
e.g.
(Brietzmannet al 1994), (Hanrieder and Heisterkamp 1994) oralso (Heisterkamp 1993)).
We will thus restrict ourdescription to those components of the dialogue sys-tem that interact with the generator.
2The planning of a system utterance (also called"strategic generation" or "what-to-say") is the maintask of the dialogue management component.
Thismeans the determination of the appropriate type ofutterance in a given dialogue situation, the itemsthat are to be talked about in which manner or styleand finally to deliver a semantic description of theutterance to the syntactic generator.A module called the Dialogue Manager operateswith a set of goals (cfi e.g.
(Heisterkamp and Mc-Glashan 1996)) that result from the contextual in-terpretation of the user utterance in a Belief Mod-ule ((Heisterkamp et al 1992)), the requirements ofthe application system, and the current confirmationstrategy (cf.
(Heisterkamp 1993)).1EFFENDI stands for "EFfizientes FormulierENvon DIalogbeitr~gen" (Ei-\[icient formulation of dialoguecontributions) and is a joint research project of the DFKISaarbriicken and Daimler-Benz Research Ulm.2Historically, our dialogue system goes back in partto the one developed in the SUNDIAL project.
The ar-chitecture of that system was laid out to accommodate agenerator (cf.
(Youd and McGlashan 1992), but for var-ious reasons the work on this aspect was discontinued.The Dialogue Module selects from the overall setof goals that subset which should constitute the nextsystem utterance.
A Message Planner eceives thissubset consisting of types utterances (e.g.
a requestfor confirmation), the task item of that goal (e.g.
adeparture place) and the status of this item (new,repeated n times).
It requests a semantic descrip-tion of that task item from the Belief Module.
Thesemantic description is then combined with the di-alogue goal types for the phrase type markers (e.g.question) and verbosity markers inferred from thestatus (e.g.
the possibility of ellipting a verb orreducing it to a prepositional phrase) to result ina semantic structure 3.
This semantic structure isthen passed on to the generation module.
A spe-cial interface translates these semantic representa-tions into syntactically oriented input specificationsfor the generator.The most important property of the EFFENDIgenerator is its incrementality.
Incremental genera-tion means that both the consumption of the inputelements as well as the production of the output el-ements work in a piecemeal and interleaved fashion.Input consumption and output production interleavein such a way that first parts of a sentence are ut-tered before the generation process is finished andeven before all input elements are consumed.
Thiskind of flexible syntactic generation is only possibleif the processing can be broken down into a large setof independent tasks which can run in parallel (cf.
(Kempen and Hoenkamp 1982)).
Applying this prin-ciple, generation i EFFENDI is realized by synchro-nizing a set of actively communicating, independentprocesses (so-called objects) each of which is respon-sible for the syntactic realization of an input elementand its integration into the syntactic structure of thewhole utterance (cfi (Kilger 1994)).In addition, incremental generation should be sep-arated into two main computational steps.
The firststep must comprise the construction of the hierarchi-cal (syntactic) structure.
The word order of the sur-face string is computed in a second step (lineariza-tion).
The reason for this separation is the observa-tion that decisions at the hierarchical level are oftenpossible at a time where input information is not yetsufficient o make decisions at the positional evel((gilger 1994)).Incremental syntactic generation can therefore beorganized as follows.
The incremental input in-terface immediately translates each incoming inputspecification into an independent process (object).3The planning process also has access to knowledgeabout recency, semantic focus etc.
This knowledge isincorporated in the planning result.18This process immediately and independently runsthe following computational steps.
At the hierar-chical level, an elementary syntactic structure forthe individual input element is selected.
In order tobuild a virtual syntactic structure for the whole sen-tence, the objects exchange structural and syntacticinformation by explicitely sending messages to re-lated objects.
An object that completes the struc-tural combination with related objects, changes tothe positional evel the task of which is the deter-ruination of the resulting word order of the surfacestring (linearization) and its output.
Linearizationmid output production have to be synchronized withrespect o the word order that globally results fromthe local linearizations.
So, incremental output pro-duction is organized as a global visit of all objects.As soon as an object has finished its linearization, itcan be uttered, i.e.
sent to the synthesizer.
The in-crementality of the output is automatically ensuredbecause the individual objects finish their local lin-earizations at different imes.3 The  In ter face  Protoco lThe goal of the interface protocol is to form a com-pact representation that contains all phonologicallyand prosodically relevant information which the gen-erator can currently derive from its concept input orthe syntactic structures generated from it.
Both arerelevant for phonological realisation, but they nei-ther are nor directly contain the phonological knowl-edge itself, as the strategic generation, linguistic gen-eration and final synthesis task are divided into dif-ferent modules.
The representation concerns cate-gories that the prosodic construction makes use ofrather than instructing it directly.
4A phonologically oriented description suitable forgenerating proper sentence prosody differs in manyaspects from the traditional syntactically orienteddescription ormally produced by a sentence gener-ator such as EFFENDI.
The following section showshow the basic phonological specification can be de-rived from existing semantic and syntactic structuresof an utterance in three main steps.
For reasons ofsimplicity the treatment of incremental processing ispostponed to the next section.4In integrated systems, where conceptual construc-tion, generation and synthesis have full mutual accessto the relevant knowledge, there is no need for such aninterface, and the linguistic grammar can directly in-corporate the phonological features (cf.
e.g.
(Prevostand Steedman 1994)).
However, apart for lack of flexi-blility, integrated systems mostly must make use of theconcept-to-speech synthesis ((Steedman 1996)), whereasthe interface presented here can also be used with a text-to-speech synthesis.3.1 Phonological CategorizationIn classical grammars every word belongs to a cate-gory which describes how words of this category maybe inflected and how they interact with other wordsin a sentence on both a syntactic and a semanticlevel.
In formal computer grammars for parsers andgenerators, words are also assigned to categories.
Wewill call these categories and all other phenomenaconnected with such grammars "syntactical.
"The structures necessary to describe the prosodicbehavior of a sentence or utterance may differ con-siderably from those necessary for classical gram-mars.
In this paper we refer to all phenomena asso-ciated with prosodic or pronunciational behavior, asopposed to that described above, as being "phono-logical".
In this sense each word to be uttered hasa phonological category associated with it.
Thesecategories tell the synthesizer something about thephonological function of each word in a sentence, inparticular about the relative stress of the words tobe uttered.
These categories will often differ fromthe purely syntactic ategories, which define the se-mantic and syntactic function of each word in a sen-tence.
These categories will vary from language tolanguage.
In addition to the phonological category,one or more special attributes uch as focus or em-phasis (coming from the semantic generator input)may be optionally associated with each word.3.2 Phono log ica l  SegmentationIn every language, spoken sentences are broken upinto so-called "thought groups" or "breath groups"if they are more than a few words long.
Also certain"atomic" groups such as "in the big room" are neverbroken up any further.
The elements that constitutean atomic group are of course language dependent.These phonologically oriented atomic groups may ormay not correspond to syntactic groups (i.e.
sub-trees) produced by the generator, but can be derivedfrom the latter.
Each atomic group also has a groupcategory associated with it, which describes how thegroup interacts prosodically with others.
Some ofthe group categories we initially propose for Ger-man are summarized in the following.
Note that,e.g., "phonological" conjunctional phrases have nophrasal counterpart on the syntactic level:19SP (Subject Phrase)Example :  Der  Zug fiihrt nach Ulm.Def in i t ion:  A noun phrase or a pronoun usedin the nominative casePP  (Prepositionl Phrase)Example :  Der Zug f~hrt nach Ulna.Def in i t ion:  A prepositional phraseAP  (Adverbial Phrase)Examples :  morgen friih; Der Zug f~ihrt je-den  Tag.Def in i t ion:  One or more adverbs or an adver-bially used noun phraseKP  (Conjunctional Phrase)Examples :  fiber Ulm und Mi inchen;  .
.
.
,weil der  Zug nicht f'?hrt.Def in i t ion:  A conjunction together with thefollowing syntactic segmentV (Verb)Example :  Der Zug f~ihrt.Def in i t ion:  An isolated inflected verb in amain clauseVP  (Verb Phrase)Examples :  .
.
.
,  ob man f~hren kann; .
.
.
,  obder Zug f'~ihrtDef in i t ion:  A complete verb phrase if allwords are contiguous or an isolated in-flected verb in a subordinate clause3.3 Assoc ia t ion  of  A tomic  Groups  to EachOtherOnce the atomic groups have been determined, it isnecessary to specify how these groups are logicallyconnected to each other.
In a phrase such astfrom the manl \ [ in  the room\]I wearing the coat\[the second atomic group is logically connected to thefirst because "in the room" refers to man.
Likewisethe third group is also logically connected to the firstgroup rather than its antecedent because "wearingthe coat" also refers to man and not to room.
Thistype of information can be derived from the originalsyntactic tree structure produced by the generatormodule.
How such groups are connected to eachother has a bearing on how the ultimate divisioninto breath groups is determined by the synthesizermodule.3.4 The  Protoco lThis section describes the formal syntax of the in-terface protocol and illustrates it with an example.Each interface protocol describes a dialogue turn,which may consist of one or more sentences.
In ourexample the turn consists of a single sentence.
Theprotocol contains the following information:?
the type of each sentence to be uttered,?
a list of all words to be uttered along with theirassociated categories, special attributes if any,and the order in which they are to be uttered,?
a specification of each atomic group along withits associated group category and?
a description of all logical connections betweenatomic groups.The interface protocol for the sentence "Sie mbchtenwissen, wann der Zug nach Ulm f'~ihrt" (literally:You would like to know, when the train to Ulmleaves.)
looks like this:$AS** Sie (PRON) #SP >+I** mbchten(H) wissen(VU) #VP >-I >+I** wann(KONJ) der(DET-S) Zug(N) #KP >-1 >+2** nach(PRAEP) Ulm(N) #PP >+1** f~ihrt(V) #VP >-2 >-1Each sentence of an interface protocol consists ofa specification of the sentence type, followed by adescription of the atomic groups in the order theyare to be uttered.
The sentence-type descriptor isuniquely identified by the initial "$" and also servesto separate sentences from each other.
Currently,the follwing types of sentences are distinguished:?
$AS - -  Affirmative proposition?
$WF - -  Wh-question?
$ JNF  - -  Yes/No-question?
$BS - -  Imperative clauseEach atomic group is introduced by "**", afterwhich the individual words of the group along withtheir category and any optional attributes are listed.Word categories are enclosed in parentheses.
At-tributes, if present, are enclosed in square brack-ets, such as " \ [ focus \ ] "  to indicate that the wordin question forms the sentence focus.
The lastword/category pair is then followed by the group20category, which is uniquely identified by the preced-ing "#".
Finally a series of one or more pointers pec-ifies other groups that are logically related.
Eachpointer is introduced by a ">" followed by a signednumber which specifies how many groups before (-)or after (+) the present group the connected grouplies.
These pointers are effectively double headed.In the example the first group points to the second(>+1), and the second group points back to the firstone (>-i).
This protocol is designed in such a waythat all spacing between elements, as shown in theexmnple, is optional.Apart from the use in EFFENDI, the protocolis also used as synthesis input specification in theVERBMOBILS-project ((Wahlster 1993)), for thesystem utterances within the german clarification di-alogue.4 The interface to the synthesiscomponent  in EFFENDIThis section considers the question how the interfaceprotocol can be used when the syntactic generatorand the synthesis module interleave incrementallymeaning that some words of the output are handedover to the synthesis module while others are still be-ing generated at the same time.
The problem for thisprocessing mode is that the pieces handed over to thesynthesis module cannot contain all prosodically rel-evant information as far as sentence parts that havenot yet been generated are concerned.
In sequentialprocessing the complete protocol for an utteranceis automatically computed and handed over to thesynthesis module in one single step.
In incrementalprocessing the protocol must be handed over to thesynthesis module in a piecemeal fashion.
The ques-tion is therefore how the information handed overto the synthesis module can be reduced in favor ofan early beginning of the articulation of a systemanswer.Since the protocol consists of a separation intobreath groups, it seems to be reasonable to handthem over to the synthesis module as soon as theyhave been identified 6.
In order to minimize the num-~VERBMOBIL is a translation system that can as-sist a tkce-to-face dialogue between two non-native n-glish speakers.
The dialogue partners have the optionto switch to their repective mother tongue and to ac-tivate VERBMOBIL to translate their utterances intoenglish.
This processing sometimes requires a clarifica-tion dialogue, e.g., if some background noises irritatedthe recognizer.~Note, that the identification of the breath groupsruns in parallel to the ongoing generation, so that theonly missing information may be some pointers to breathgroups that have not yet been generated.ber of missing pointers it is possible to impose a de-lay on one or more breath groups.
This means thata breath group is handed over to the synthesis com-ponent if some of the following breath groups havealready been identified by the generator.The most important problem in incremental gen-eration is the necessity of repairs that have to bedone if, e.g., a previously unknown word cannotbe attached to the word order already articulated.Since already articulated words cannot be retracted,an extensive repetition of the concerned phrase isnecessary to correct the already articulated butwrong formulation.
E.g., if the noun phrase "theman" has been articulated and it is incrementallyextended by an adjective "young", the correctionof the articulation consists of the repetition of thewhole phrase "the young man".In order to avoid such extensive repetitions, wedeveloped a strategy called "afterthought syntax".If words resulting from semantic information thatwas not available when the first words of a sen-tence were uttered can't be syntactically correctlyattached to the words already articulated, then thesyntactic ordering is (partly) disregarded, i.e.
prece-dence is given to completeness of the semantic on-tent and shortness of the utterance over syntacticcorrectness.
In virtually all cases, the resulting ut-terance remains completely understandable.
Tech-nically this behaviour is implemented using ellipticgeneration.
The (now complete) utterance is re-generated, and all parts of the utterance that havealready been uttered are marked as ellipses, i.e.
pro-hibited from being uttered again.
However, rulesare applied to ensure that repair elements receive asyntatic ontext if they need it, thus overriding thatprohibition, if necessary:Sie m6chten wissen, w~n~ der Zug f~ihrt ...(You want-to know, when the train leaves ...)tier n~ichste Zug ?.
?
(the next train ...)nach Ulm.
(to Ulm.
)The first elliptical resumption is caused by thepreviously unknown adjective "n~chste" which leadsto the repetition of the complete noun phrase, whilethe second resumption is caused by the PP "nachUlm" which, according to standard German syntax,would have to be placed before the verb in a subor-dinate clause.5 Future  WorkFor the near future, we plan to implement a full in-teraction between the dialogue manager, the genera-21tor, and the speech synthesis module in incrementalprocessing.
We hope to gain practical experience ininterleaved generation and synthesis.
This is espe-cially vital for finding an answer to the question, howarticulation can be delayed in favor of an acceptableoutput quality in such a way that the overall reac-tion time of the system is only marginally increased.Re ferencesA.
Brietzmann, F. Class, U. Ehrlich, P. Heister-kamp, A. Kaltenmeier, K, Mecklenburg, P. Regel-Brietzmann, G. Hanrieder, W. Hiltl.
1994.
Ro-bust speech understanding.
In Proceedings ofICSLP-1994, Yokohama, 1994.G.
Hanrieder, P. Heisterkamp.
1994.
Robust anal-ysis and interpretation i  speech dialogue.
In:H. Niemann, R. de Mori, G. Hanrieder (eds.
):Progress and prospects of speech research andtechnology, Proceedings of the CRIM/FORWISSworkshop, Munich 1994.P.
Heisterkamp.
1993.
Ambiguity and uncer-tainty in spoken dialogue.
In: Proceedings of EU-ROSPEECH '93, Berlin, 1993.P.
Heisterkamp, S. McGlashan, N. Youd.
1992.Dialogue semantics for an oral dialogue system.In: Proceedings of ICSLP-1992, Banff, Alberta,Canada, 1992.P.
Heisterkamp, S. McGlashan 1996.
Units of dia-logue management.
An example.
In: Proceedingsof ICSLP-1996, Philadelphia, PA, 1996.G.
Kempen, E. Hoenkamp.
1982.
Incremental Sen-tence Generation: Implications for the Structureof a Syntactic Processor.
In: J. Horecky (ed.
), 9thInternational Conference on Computational Lin-guistics, 1982.A.
Kilger.
1994.
Using UTAGs for Incremental andParallel Generation.
In: Computational Intelli-gence, 10 (1994) 4, PP.
591-603, 1994.J.
Peckham.
1993.
A new generation of spoken dia-logue systems: Results and lessons from the Sun-dial project.
In: Proceedings of EUROSPEECH'93, Berlin, 1993.P.
Poller, P. Heisterkamp.
1997.
Hybrid Knowl-edge Sources for Generation in a Speech DialogueSystem.
submitted to ACL/EACL 1997, Madrid,Spain.S.
Prevost, M. Steedman.
1994 Specifying Into-nation from Context for Speech Synthesis.
In:Speech Communication, 15, pp.
139-153, 1994.M.
Steedman.
1996 Representing Discourse Infor-mation for Spoken Dialogue Generation.
In: Pro-ceedings of International Symposium on SpokenDialogue (ISSD '96), pp.
89-92, Philadelphia, PA,1996.W.
Wahlster.
1993.
VERBMOBIL: Translations ofFace-to-Face Dialogs.
In Proceedings of the MTSummit IV, Kobe, Japan, pp.
127-135, 1993.N.
Youd, S. McGlashan.
1992.
Generating Utter-ances in Dialogue Systems.
In: R. Dale, E. Hovy,D.
RSsner, O.
Stock (Eds.)
(1992): Aspects of au-tomated natural language generation.
Proc.
of the6th International workshop on natural languagegeneration, Trento, Italy, April 1992.22
