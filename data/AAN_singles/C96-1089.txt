Learning Bilingual Collocations by Word-Level SortingMasah iko  Haruno  Satoru  Ikehara  Takefumi  Yamazak iNTT ( ' ,ommunicat io l t  Sci('nce l ,al)s.1-2:156 Take Yokosuka-Sh iKa.nagawa.
2:18-03, ,la,l:)a,nharuno@n'c'ckb, nt-I;, j p i kehara@nttkb ,  rt'c-I;, j p yamazak i~nt tkb ,  n t t .
j pAbst rac tThis paper I)roposes ;t new tnethodfor learning bilingual colloca, tions fromsentence-aligned paralM corpora.
Ourmethod COml)ris('s two steps: (1) ex-tracting llseftll word chunks (n-grmns)by word-level sorting and (2) construct-ing bilingua,l ('ollocations t)y combiningthe word-(;hunl(s a(-quired iu stag(' (1).We apply the method to a very ('hal-lenging text l)~tir: a stock market 1)ul-let;in in Japanese and il;s abstract in En--glish.
I)om;tin sl)ecific collocations arewell captured ewm if they were not con-ta.ined in the dictionaric's of economictel?IllS.1 I n t roduct ionIn the field of machitm translation, there is a,growing interest in corl)llS-I)ased al)l)roa.
('hes (Satoand Nagao, 1990; l)a.gan mid (',hutch, 199d; Mat.sulnoto et M., 19.93; Kumano m,d ll imka.wa., 199d ;Smadja et al, 1996).
The main motiw~.tion be-hind this is to well ha.ndle, domain specific ex-pressions.
I~ach apl~licatiotl dom~dn has va.riouskinds of collocations ranging from word-level tosentence-level.
'\]'he correct use of these colloca-tions grea.l.ly inlluellcC's the qua.lity ofoutpttt exts.Ilexa.uso such detaih'd collocations ;~r~'~ <tillicult 1:ohand-conlpile, the automatic extra(:tion of bilin-gual collocations is needed.A number of studies haw> aJ.tetnpte(I to extractbilinguaJ collocations from paralM corpora.
Thesestudies c~m be classified into two directions.
Oneis hased on the full parsing techniques.
(Mat,-sumoto et a l., 1993) I)roposed a. method to find outphrase-lew'l correspondences, while resolving syn-tactic ambiguities a.t the same time.
Their ninth-()(Is determine t)hrase eorresl)ondences I)y usingthe phrase structures of I,he two hmgua,ges and ox-isting bilingual dict.iona.ries.
Unfi)rl.unately tl, 'seal)proaches are protnising only for (,he compara--I, ively short sentences l, hat ca, I>e a,a\]yze(I I>y ;t(',I+,:Y type l>arser.The other direction for extracting bilingual coblocal.ions involw+:s tatistics.
(Fung, 1995) ac-quired bilingual word correspondences withoutsentetlce alignment.
Although these methods;|re rob/Is|  ~HI(I aSSllllle rio illfOl'lll~ttiOll SOltrce~their outputs are just word-word corresl)otMences.
(Kupiec, 1993; Kumano and }lirakawa, 1!194) ex-tracted noun phr~me (NP) correspondences fromaligned parallel corpora.
|n (Kupiec, 1993), Nl'sin English and French t;exts are+ first extractedby a. NP recoguizer.
Their correspotldence prol>abilities arc then gradually relined by using anEM-like iteration algorithm.
(t,~uma.no and Ili-rakawa, 1994) lirst extracted .Japanese N Ps in theS&III(?
way, and comhined statistics with a bilin-gtta.l dictionary tbr MT 1o find out NP (-orrespon-dences.
Although their apl)ro+tches a.t.ta.ined highaccuracy for the+ task considered, the most cru-cial knowledge for MT is tnorc COml~lex corre-spOlldelices Sllch ~-LS NI'-VP corres\[,Oll(teltces atHIsenl.et,'e-hwe\[ orrespotldences.
It seems di\[\[icuttI.o extend these statistical l lethods to ~t I)roa.
(lerrmtge of collocations because they are specializedto N l's o1: sillglc" words.
(Smmlj~t et al, 1996) proposed a generMmethod to extract a I)roader ange of colloca.tions.They first extract English collocations using theXtract systetn (Smadja, 1993), and theu look forFrench coutlterparts.
Their search strategy is anitemtive combina.tion of two elements.
This isha,sed on the intuitive ide~ tim| "if a set of words('onstitutes a collocation, its subset will Mso becorrela.ted".
Although this idea is corre~(:t, he it-era|ire combination strategy generates a. mlmberol + useless expressions.
In fa.ct, Xtract.
employs a.rol)ust l",nglish pa.rser to lilter out the wrong collo-ca.tions which form more thaal ha.If lhe candidates.In other hmgua,ges such as Japanese, pa,rser-lmscdprmfi .g cannot be used.
Another drawback oftheir approa, ch is that only the longesl, n-gramis adopl.ed.
That is, when 'Ja.lmn-US auto tradetalks' is ardol)ted as ;/collocation, ',lapall-IlS' can-not bc recognized as a. collocal,ion though it is i.-dependently used very often.In thi,~ pN)er, we propose an alt,ernative methodbased oil word-lewd sorting.
Our method com-525prises two steps: (1) extracting useful word chunks(n-grams) by word-level sorting and (2) constrnct-ing bilingual collocations by combining the word-chunks acquired at stage (1).
Given sentence-aligned texts in two languages(Haruno and Ya-mazaki, 1996), the first step detects useful wordchunks by sorting and counting all uninterruptedword sequences in sentences.
In this phase, we de-veloped a new technique for extracting only usefulchunks.
The second step of the method evalu-ates the statistical similarity of the word chunksappearing in the corresponding sentences.
Mostof the fixed (uninterrupted) collocations are di-rectly extracted from the word chunks.
More flex-ible (interrupted) collocations are acquired levelby level by iteratively combining the chunks.
Theproposed method, which uses effective word-levelsorting, not only extracts fixed collocations withhigh precision, but also avoids the combinatorialexplosion involved in searching flexible colloca-tions.
In addition, our method is robust and suit-able for real-world applications because it only as-sumes part-of-speech taggers for both languages.Even if the part-of-speech taggers make errors inword segmentation, the errors can be recovered inthe word chunk extraction stage.2 Two Types  o f  Japanese-Eng l i shCo l locat ionsIn this section, we briefly classify the types ofJapanese-English collocations by using the ma-terial in Table 1 as an example.
These textswere derived from a stock market bulletin writtenin Japanese and its abstract written in English,which were distributed electrically via a computernetwork.In Table 1, (~g-~,~'l-~/Tokyo Forex), (H~I~!IYJ~\[~n~\]{~ /auto talks between Japan and the U.S.)and (~k, .
'~/ahead of) are Japanese-English col-locations whose elements constitute uninterruptedword sequences.
We call hereafter this type of col-location f ixed eol loeatlon.
Although fixed col-location seems trivial, more than half of all use-ful collocations belong to this class.
Thus, it isimportant o extract fixed collocations with highprecision.
In contrast, ( b ' ) t - t~ '~ ~ ~1~ ?ki~?,_~ / The U.S. currency was quoted at -~ ) and ( b") t .~ '~ ~ ~l~ ~k_2~ /The dollar stood ..~)1are constructed from interrupted word sequences.We will call this type of collocation f lexible col-locat ion.
From the viewpoint of machine learn-ing, flexible collocations are much more difficultto learn because they involve the combination ofelements.
The points when extracting flexible col-locations is how the number of combination (can-didates) can be reduced.Our learning method is twofold according tothe collocation types.
First, useful uninterrupted1 ~.
represents any sequence of words.word chunks are extracted by the word-level sort-ing method.
To find out fixed collocations, weevaluate stochastic similarity of the chunks.
Next,we iteratively combin the chunks to extract flexi-ble collocations.3 Ext ract ing  Usefu l  Chunks  byWord-Leve l  Sor t ing3.1 Prev ious  ResearchWith the availability of large corpora and mem-ory devices, there is once again growing interest inextracting n-grams with large values of n. (Nagaoand Mori, 1994) introduced an efficient methodfor calculating an arbitrary number of n-gramsfrom large corpora.
When the length of a textis I bytes, it occupies l consecutive bytes in mem-ory as depicted in Figure 1.
First, another tableof size l is prepared, each field of which representsa pointer to a substring.
A substring pointed toby the (i - 1)th entry of the table constitutes astring existing from the ith character to the endof the text string.
Next, to extract common sub-strings, the pointer table is sorted in alphabeticorder.
Two adjacent words in the pointer tableare compared and the lengths of coincident prefixparts are counted(Gonnet  al., 1992).For example, when 'auto talks between Japanand the U.S.' and 'auto talks between Japan andChina' are two adjacent words, the nmnber of co-incidences i 29 as in 'auto talks between Japan and'.
The n-gram frequency table is constructed bycounting the number of pointers which representthe same prefix parts.
Although the method is ef-ficient for large corpora, it involves large volumeof fractional and unnecessary expressions.
Thereason for this is that the method does not con-sider the inter-relationships between the extractedstrings.
That is, the method generates redundantsubstrings which are subsumed by longer strings.text  n t r |hg  ( I  oharaoter~:  I by tes )la, o l .
te r  tab leFigure 1: Nagao's ApproachTo settle this problem, (Ikehara et al, 1996)proposed a method to extract only useful strings.Basically, his methods is based on the longest-match principle.
When the method extracts alongest n-gram as a chunk, strings subsumed bythe chunk are derived only if the shorter string of_tell appears independently to the longest chunk.If 'auto talks between Japan and the U.5'.'
is ex-tracted as a chunk, 'Japan and the U.S.'is also526Tokyo Forex 5 PM: Dollar at 84.21-84.24 yenThe dollar stood 0.26 yen lower at 84.21-84.24 at 5 p.m.Forex market rading was extremely quiet ahead of fnrther auto talks between Japan and the U.S., slatedfor early dawn Tuesday.The U.S. currency was quoted at 1.361-1.3863 German marks at 5:15 p.m.Table 1: Sample of Target Textsextracted because 'Japan and the U.S.' is usedso often independently as in 'Japan and the U.S.agreed ...'.
However, 'Japan and the' is not ex-tracted because it always appears in the contextof 'Japan and the U.S.'.
The method stronglysuppresses fractional and unnecessary expressions.More than 75 % of the strings extracted by Na-gao's method are removed with the new method.3.2 Word-Leve l  Sort ing Methodal Ipl l I@ i I \[dl@~tlh\] \[po ln~r  imbl~?O:~n l  ~ l lm~rFigure 2: Word-Level Sorting ApproachThe research described in the previous sectiondeals with character-based n-grams, which gener-ate excessive numbers of expressions and requireslarge memory for the pointer table.
Thus, froma practical point of view, word-based n-grams arepreferable in order to further suppress fractionalexpressions and pointer table use.
In this paper,we extend Ikehara's method to handle word-basedn-grams.
First, both Japanese and English textsare part-of-speech (POS) tagged 2 and stored inmemory as in Figure 2.
POS tagging is requiredfor two main reasons: (1) There are no explicitword delimiters in Japanese and (2) By using POSinformation, useless expressions can be removed.In Figure 2, '@' and ' \0'  represent the explicitword delimiter and the explicit sentence delimiter,respectively.
Compared to previous research, thisdata structure has the following advantages.2We use in this phase the JUMAN morphologicalanalyzing system (Kurohashi et al, 11994) for taggingJapanese texts and Brill's transformation-based tag-get (Brill, 1994) for tagging English texts.
We wouldlike to thank all people concerned for providing uswith the tools.1.
Only heads of each word are recorded in thepointer table.
As depicted in Figure 2, thisremarkably reduces memory use because thepointer table also contains other string char-acteristics as Figure 3.2.
As depicted in Figure 2, only expressionswithin a sentence are considered by introduc-ing the explicit sentence delimiter ' \0'.3.
Only word-level coincidences are extractedby introducing the explicit word delimiter'@'.
This removes strings arising from apartial match of different words.
For exam-ple, the coincident string between 'Japan andChina' and 'Japan and Costa Rica' is 'Japanand'in our method, while it is 'Japan and C'in previous methods.co lno l  ~?ont adopt  dance~4(151 - /0  2I lC)* I104s t r ingI0I?
)16I 616J~p .
n~-v andc~a ?
"h  m, ,ovJ , .
.
, .
, ,< .o .
.
.
t c .~,c 'o .
, .
~1o.a ap .
n~-q an d?,~ t |~ ,*~ 1 J sJu  pa  t t (~  an , tC ,~ t I ~  U SJ i t  p i t  t~  t tn?U~,  t I~<~ ~ I SJa  p a i ~?U ~n (ICa) II~C~O_ ?
/Figure 3: Sorted Pointer TableNext, the pointer table is sorted in alpha-betic order as shown in Figure 3.
In this table,sentno,  and co inc idence represent which sen-fence the string appeared in and how many char-acters are shared by the two adjacent strings, re-spectively.
That is, eo ine idenee delineates can-didates for usefifl expressions.
Note here that thecoincidence between Japan@and@China... andJapan@and@Costa Rica... is l0 as mentionedabove .Next, in order to remove useless subsumedstrings, the pointer table is sorted according tosentno.
.
In this stage, adopt  is filled with '1'or '0' , each of which represents if or not if astring is subsumed by longer word chnnks, respec-tively.
Sorting by sentno,  makes it much easierto check the subsumption of word chunks.
When527both 'Japan and the U.S.' and 'Japan and the'arise from a sentence, the latter is removed be-cause the former subsumes the latter.Finally, to determine which word-chunks to ex-tract, the pointer table is sorted once again in al-phabetic order.
In this stage, we count how manytimes a string whose adopt  is 1 appears in thecorpus.
By thresholding the frequency, only use-tiff word chunks are extracted.4 Extracting BilingualCollocationsIn this section, we will explain how Japanese-English collocations are constructed from wordchnnks extracted in the previous stage.
First,fixed collocations are induced in the following way.We use the contingency matrix to evaluate thesimilarity of word-chunk occurrences in both lan-guages.
Consider the contingency matrix, shownTable 2, for Japanese word chunk cjp,~ and Englishword chunk c~,g.
The contingency matrix shows:(a) the number of Japanese-English correspondingsentence pairs in which both Cjp n and ce,~g werefound, (b) the number of Japanese-English cor-responding sentence pairs in which just c~, v wasfound, (c) the number of Japanese-English cor-responding sentence pairs in which just ejp,~ wasfonnd, (d) the mnnber of Japanese-English co lresponding sentence pairs in which neither chunkwas found.Ceng a bc dTable 2: Contingency MatrixIf ejpn and Cen.q are good translations of oneanother, a should be large, and b and c shouldbc small.
In contrast, if the two are not goodtranslations of each other, a should be small, midbaud c should be large.
To make this argumentmore precise, we introduce mutual information ~sfollows.
Thresholding the mutual information ex-tracts fixed collocations.
Note that mutual in-formation is reliable in this case because the fre-quency of each word chunk is thresholded at theword chunk extraction stage.p,'ob(q,,,,, c~,,.,) = log "(" + ~ + ~ + d)log v,.ob(,:j,,,)v,.ob(~,~,,~) ( ,  + b)(, + c)Next, we sumnmrize how flexible collocationsare extracted.
The following is a series of proce-dures to extract flexible collocations.1.
For any pair of chunks in a Japanese sen-tence, compute mutual information.
Con>bine the two chunks of highest mutual in-formation.
Iteratively repeat this procedureand construct a tree level by level.2.
For any pair of chunks in an English sen-tence, repeat the operations done in the theJapanese sentence.3.
Perform node matching between trees ofboth langnages by using mutual informationof Japanese and English word chunks.tin ,~l~ore RFigure 4: Constructing Flexible CollocationsThe first two steps construct monolingual simi-larity trees of word chnnks in sentences.
The thirdstep iteratively evalnates the bilingual similarityof word chunk combinations by using the abovetrees.
Consider the example below, in which theunderlined word chunks construct a flexible col-location (~ Yif/~?~.~t~,f~t~_~,:x g ~, I-iti~'~3:~?_k~-L /~: /~ rose ~ on the oil products spotmarket in Singapore).
First, two similarity treesare constructed as shown in Figure 4.
Graphmatching is then iteratively attempted by compnt-ing mutual inforlnation fbr groups of word chunks.In the present implementation, the system com-bines three word chunks at most.
The techniquewe use is similar to the parsing-b~sed methodsfor extracting bilingual collocation(Matsumoto etal., 1993).
Our method replaces the parse treeswith the similarity trees and thus avoids the com-binatorial explosion inherent o the parsing-ba~sedmethods.lia:ample: , ,,Naphtha and gas oil roseon the oil products pot market in Singapore5 Pre l iminary  Eva luat ion  andD iscuss ionWe performed a preliminary ewduation of tileproposed method by using 10-days Japanese stockmarket bulletins and their Fnglish abstracts, eachcontaining 2000 sentences.
The text was first au--tomatically aligned and then hand-checked by ahum~m supervisor.
A sample passage is displayedin TM~Ie 1.In this experiment, we considered only the wordchunks thai; appeared more than 4 times for fixedcollocations and more than 6 times for flexible col-locations.
Table 4 illustrates the fixed collocationsacquired by our method.
Almost all collocat.ionsin Table 4 involw~ domain specilic jargon, which528~tmi l~Tse  Engl ishDI( j \ ] (~I-~ ~ I 1\] ~ Tokyo  Forex  ~ I )o lhu"  ~tt, ~ yenb',i!--'l-1 ~ "~\[+\]\]~ 9 I ~ ~_~k ?c The 1,J.S.
c l i r rency  WitS ( l l loted atwere sold ~ dropped as wellI I~ I~ ~" ?f J~ ' i~( | l  b/ 'e I la,nk of  , lapiin in jectedP~-d~'n Y - -  ~-\ ] !~ ~"  O l l l rO l l  ~ ~ll l l l i l ,  GlllO Forcsl, fy - -Tal)h; 3: Saniples of li'lexible (~ollocationsNo___ Jttl)O lles(:= ~.k 'c,t JAFCO ~ - ~- 7 - - ~s q-:~.k b/%'~ , 6t0 ,j,~,~~ 2" ":; Ta) 5~ ~ ~ t ~  -14151617182o22~3242~L__ 2 62728293O313~aa_~34a s36_ 3 7C B Q s\]z~j~ k A,~ 0 f~ff ktf/19~l Ig}' t11~Eiil411shTokyo Forexahead ofGerman markJapan  Associated lCin~ncein contrastremained aidelined watchingfearTokyo Gold future~ (\]in:slowwait-and-ace moodLoco-London gold~ inat  markConvert ib le bond~dealerst radin~; volumeh~i~h-yielderaNikkei  300 futuren Aft-opg:~-c ln :con|  r~ct endedeconomic ~timulun packa e~a?
- -cloted t~tfuturea cls:bond Int~rketconvert ible bondnnikkei future~ aft-opg:~ \[.
disheartened by-'..0')~1.~7)~ ~ .
.
.
.
pet |a t |on  of%Lo~,9~'1~4~q:e@;ed uphish-tech sharenwMt-and-~e?
moodSurnit omo ForestryU.S.-dapttn ~uto t~lksnpecul~tive buying o f _Tokyo ~ me.8: ~intereat rate~the dapan-U,S.
&uto disputeN -oT .
T .J ii i)l-i 11 thG(~as f~9fll~*~ 'l',t31~)l4 a ~Cl 4 A l ~  - -, ,m- ,4~4o /\]'I I a)9'd I)~--7-- ~Ltc- -~-~- -~5657o~ 0-~: 3 5t687072Eng l i shbond~ and bond futurespublic fundsintt i tut ional  inventorsbenchmarksemiconductor-related ~tocksforei6n inve~tor~hlgh-tech ~tocksturnoversmall-lot ~ellinfz -r~cord highbenchmarklowTokyo Stockn 2nd Secwere weakindividual inveatorapretax profitThe firnt ~ection of TSI~,the Nikkei ~tock averageTokyo CB~ O qp~ ilong-term government bondllwere ~rnded atimpor terlladvancedcoverin~Showa Denkovolume w~hi ta  new year'~ h i ~ r hrul ing co~litlonq:i~JJ~Tif~ _ _tl~\[:~l~R'~r,i,:}~,~..,~ ?
Nikkei World Commodi t ie , :~ir,J I r/Sumltomo Special MetalsNikkei 300 futuren M n ~OSl~year'~ lowl n ~  closeinched npTa, ble 4: Siunples of Fi?cd Collocation,<~cannot, be const.rueted composit, ionally.
For exam-phi, No 9 nieans 'Tokyo (~ohl FuLure, m~rkel; endedt rad ing R)r the (lay', but was never written assuch.
As well as No.
9 , a nuuflml: ofseut;ence-levelcol locations were also extracl, ed.
No.
9, No.
18,No.
23, No.
2< No.
35, No.
56 and No.
67 a.ret ,yp ica , l  heads of  Ll le s tock  marke l ;  repor t .
Theseexi)rcssioiis a.pllear eweryda.y in st.ock markel, re-por ts .IlL i s  inl,  e res l ,  i i l  E I4) not ,  ic(~ lhe  var ie l ,y  o \ [  f i xedcolh)ca.tions.
They dill'~'r in their consl.rucl.ions;noun phrases, verll phrases, I)rel)osit.iolml phrase<;and sentrnce--level.
All, hough co l tvent iona J  nleLll-ot i s  focus  on  hour i  llhrases or  | , ry  t;o en( :on l l /assall kinds of (-olloca.tions at the sanie time, we be-liew" l, ha, t, fixed colloca, tion is au ilnporl,anl, class o\['colh)cation.
It is useful to iltl,ensively sl,udy fixedcol locations because 1,he (:ollocatioll of lilore com--plex structures is ( l i l l ic.
lt  to h ' i , ' ,  regardle'~,~ ofthe mf~l,hod used.
'I'MAe 3 exemplifies the flexible colloca.tions weacquired fronl the saint  cOrllUS.
No.
1 to No.
4 aretypical exprossions in stock nlarkc'l, reports.
Thesecollocation are eXl;l'enlc.ly useful for l,ellll)lal, e--based nlachine /.ra.nsla.tiol~ sysl.enls.
No.
5 is a.nexamph~ o1' a useless ('ol\[ocalriOIt.
BOt\]l Olnrona, nd  ~un i i | ,omo Forcs t ; ry  arc  cotupap,  y names  1,lid, l;co-ocem-  I'requenl, ly i. s l ,ock  u ia , l ' ke l ,  i ' e l )o r t ; s  , bu l ,t.he.qc two conlpanics ha,ve uo direct relal;iou.
Infact, nlore I.han half of a.II lh!xibh~ collocations ac-quired were like No.
5.
To remove useh>ss coJJ()(';t-l ions, co,stra.inl.s <)n l;ll<" <'haracl.er tyl>eS would I)euseful.
Most useful ,lapa/ICSe /lcxiblt' (:ollocai.iOllScoul;;lin al, least one ilira.gamt 3 ch~u-acter.
Thus,3 ,I a i)~nese has (,}n'c(~ t,y pe,~ of ch ara~ctcrs ( II ira.ga.na,I(atak;~na., and t<anjO, each of which has dilt't!rcnta.n.
)uttts of i .
lbrntal io.
.
In ( OllLl,t,qt, Enl-lish ha.s ouly529many useless collocations can be removed by im-posing this constraint on extracted strings.It is also interesting to compare our resultswith a Japanese-English dictionary for economics(Iwatsu, 1990).
About half of Table 4 and all ofTable 3 are not listed in the dictionary.
In partic-ular, no verb-phrase or sentence-level collocationsare not covered.
These collocations are more use-ful for translators than noun phrase collocations,but greatly differ from domain to domain.
Thus, itis difficult in general to hand-compile a dictionarythat contains these kinds of collocations.
Becauseour method automatically extracts these colloca-tions, it will be of significant use in compiling do-main specific dictionaries.Finally, we briefly describe the coverage of theproposed method.
For the corpus examined, 70 %of the fixed collocations and 35 % of the flexiblecollocations output by the method were correct.This level of performance was achieved in the faceof two problems.?
The English text was not a literal transla-tion.
Parts of Japanese sentence were oftenomitted and sometimes appeared in a differ-ent English sentence.?
The data set was too small.We are now constructing a larger volume of cor-pus to address the second problem.6 Conc lus ionWe have described a new method for learningbilingual collocations from parallel corpora.
Ourmethod consists of two steps: (1) extracting use-ful word chunks by the word-level sorting tech-nique and (2) constructing bilingual collocationsby combining these chunks.
This architecture r -flects the fact that fixed collocations play a morecrucial role than accepted in previous research.Our method not only extracts fixed collocationswith high precision but also reduces the combi-natorial explosion that would be otherwise con-sidered inescapable in extracting flexible colloca-tions.
Although our research is in the preliminarystage and tested with a small number of Japanesestock market bulletins and their English, the ex-perimental results have shown a number of inter-esting collocations that are not contained in a dic-tionary of economic terms.ReferencesEric Brill.
1994.
Some advances intransformation-based part of speech tagging.
InProc.
12th AAAI, pages 722-727.Ido Dagan and Ken Church.
1994.
Termight:identifying and translating technical terminol-one type of character.ogy.
In Proc.
Fourth Conference on AppliedNatural Language Processing, pages 34-40.Pascale Fung.
1995.
A pattern matching methodfor finding noun and proper noun translationsfrom noisy parallel corpora.
In Proc.
33rd ACL,pages 236-243.Gaston H. Gonnet, Ricardo A. Baeza-Yates, andTim Snider, 1992.
Information Retrieval, chap-ter 5, pages 66 82.
Prentice-Hall.Masahiko lIaruno and Takefinni Yamazaki.
1996.High-Performance Bilingual Text AlignmentUsing Statistical and Dictionary Information.In Proc.
34th A CL.Satoru Ikehara, Satoshi Shirai, and HajimeUehino.
1996.
A statistical method for extract-ing unitnerrupted and interrupted collocationsfrom very large corpora.
In Proc.
COLING96.Keisuke Iwatsu.
1990.
TREND: Japanese-EnglishDictionary of Current Terms.
Shougakkan.Akira Kumano and Hideki Hirakawa.
1994.Building an MT dictionary from parallel textsbased on linguisitic and statistical information.In Proc.
15th COLING, pages 76-81.Julian Kupiec.
1993.
An algorithm for findingnoun phrase correspondences in bilingual cor-pora.
In the 3lst Annual Meeting of ACL,pages 17-22.Sadao Kurohashi, Toshihisa Nakamura, Yuji Mat-sumoto, and Makoto Nagao.
1994.
Improve-ments of Japanese morphological nalyzer JU-MAN.
In Proc.
International Workshop onSharable Natural Language Resources, pages22-28.Yuji Matsumoto, tIiroyuki Ishimoto, and TakehitoUtsuro.
1993.
Structural matching of paral-lel texts.
In the 31st Annual Meeting of ACL,pages 23-30.Makoto Nagao and Shinsuke Mort.
1994.
A newmethod of n-gram statistics for large number ofn and automatic extraction of words and pha-rases from large text data of japanese,.
In Proc.15th COLING, pages 611 615.Satoshi Sato and Makoto Nagao.
1990.
Towardmemory-based translation.
In Proc.
13th COL-ING, pages 247-252.Frank Smadja, Kathleen McKeown, and Vasileiostlatzivassiloglou.
1996.
Translating colloca-tions for bilingual lexicons: A statistical ap-proach.
Computational Linguistics, 22(1):1- 38,March.\['rank Smadja.
1993.
Retrieving collocationsfrom text: Xtract.
Computational Linguistics,19(1):143 177, March.530
