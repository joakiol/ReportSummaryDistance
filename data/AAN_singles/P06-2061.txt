Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 467?474,Sydney, July 2006. c?2006 Association for Computational LinguisticsIntegration of Speech to Computer-Assisted Translation UsingFinite-State AutomataShahram Khadivi Richard ZensLehrstuhl fu?r Informatik 6 ?
Computer Science DepartmentRWTH Aachen University, D-52056 Aachen, Germany{khadivi,zens,ney}@cs.rwth-aachen.deHermann NeyAbstractState-of-the-art computer-assisted transla-tion engines are based on a statistical pre-diction engine, which interactively pro-vides completions to what a human trans-lator types.
The integration of humanspeech into a computer-assisted system isalso a challenging area and is the aim ofthis paper.
So far, only a few methodsfor integrating statistical machine transla-tion (MT) models with automatic speechrecognition (ASR) models have been stud-ied.
They were mainly based on N -best rescoring approach.
N -best rescor-ing is not an appropriate search methodfor building a real-time prediction engine.In this paper, we study the incorporationof MT models and ASR models usingfinite-state automata.
We also proposesome transducers based on MT models forrescoring the ASR word graphs.1 IntroductionA desired feature of computer-assisted transla-tion (CAT) systems is the integration of the hu-man speech into the system, as skilled humantranslators are faster at dictating than typing thetranslations (Brown et al, 1994).
Additionally,incorporation of a statistical prediction engine, i.e.a statistical interactive machine translation system,to the CAT system is another useful feature.
A sta-tistical prediction engine provides the completionsto what a human translator types (Foster et al,1997; Och et al, 2003).
Then, one possible proce-dure for skilled human translators is to provide theoral translation of a given source text and then topost-edit the recognized text.
In the post-editingstep, a prediction engine helps to decrease theamount of human interaction (Och et al, 2003).In a CAT system with integrated speech, twosources of information are available to recognizethe speech input: the target language speechand the given source language text.
The targetlanguage speech is a human-produced translationof the source language text.
Statistical machinetranslation (MT) models are employed to take intoaccount the source text for increasing the accuracyof automatic speech recognition (ASR) models.Related WorkThe idea of incorporating ASR and MT modelswas independently initiated by two groups:researchers at IBM (Brown et al, 1994),and researchers involved in the TransTalkproject (Dymetman et al, 1994; Brousseauet al, 1995).
In (Brown et al, 1994), theauthors proposed a method to integrate the IBMtranslation model 2 (Brown et al, 1993) withan ASR system.
The main idea was to designa language model (LM) to combine the trigramlanguage model probability with the translationprobability for each target word.
They reported aperplexity reduction, but no recognition results.In the TransTalk project, the authors improvedthe ASR performance by rescoring the ASRN -best lists with a translation model.
They alsointroduced the idea of a dynamic vocabulary fora speech recognition system where translationmodels were generated for each source languagesentence.
The better performing of the two is theN -best rescoring.Recently, (Khadivi et al, 2005) and (Paulik etal., 2005a; Paulik et al, 2005b) have studied theintegration of ASR and MT models.
The firstwork showed a detailed analysis of the effect ofdifferent MT models on rescoring the ASR N -bestlists.
The other two works considered two parallelN -best lists, generated by MT and ASR systems,467respectively.
They showed improvement in theASR N -best rescoring when some proposed fea-tures are extracted from the MT N -best list.
Themain concept among all features was to generatedifferent kinds of language models from the MTN -best list.All of the above methods are based on an N -best rescoring approach.
In this paper, we studydifferent methods for integrating MT models toASR word graphs instead of N -best list.
Weconsider ASR word graphs as finite-state automata(FSA), then the integration of MT models to ASRword graphs can benefit from FSA algorithms.The ASR word graphs are a compact representa-tion of possible recognition hypotheses.
Thus, theintegration of MT models to ASR word graphs canbe considered as an N -best rescoring but with verylarge value for N .
Another advantage of workingwith ASR word graphs is the capability to passon the word graphs for further processing.
Forinstance, the resulting word graph can be used inthe prediction engine of a CAT system (Och et al,2003).The remaining part is structured as follows: inSection 2, a general model for an automatic textdictation system in the computer-assisted transla-tion framework will be described.
In Section 3,the details of the machine translation system andthe speech recognition system along with the lan-guage model will be explained.
In Section 4,different methods for integrating MT models intoASR models will be described, and also the exper-imental results will be shown in the same section.2 Speech-Enabled CAT ModelsIn a speech-enabled computer-assisted translationsystem, we are given a source language sentencefJ1 = f1 .
.
.
fj .
.
.
fJ , which is to be translated intoa target language sentence eI1 = e1 .
.
.
ei .
.
.
eI ,and an acoustic signal xT1 = x1 .
.
.
xt .
.
.
xT ,which is the spoken target language sentence.Among all possible target language sentences, wewill choose the sentence with the highest probabil-ity:e?I?1= argmaxI,eI1{Pr(eI1|fJ1 , xT1 )} (1)?= argmaxI,eI1{Pr(eI1)Pr(fJ1 |eI1)Pr(xT1 |eI1)}(2)Eq.
1 is decomposed into Eq.
2 by assumingconditional independency between xT1 and fJ1 .The decomposition into three knowledge sourcesallows for an independent modeling of the targetlanguage model Pr(eI1), the translation modelPr(fJ1 |eI1) and the acoustic model Pr(xT1 |eI1).Another approach for modeling the posteriorprobability Pr(eI1|fJ1 , xT1 ) is direct modeling us-ing a log-linear model.
The decision rule is givenby:e?I?1 = argmaxI,eI1{ M?m=1?mhm(eI1, fJ1 , xT1 )}(3)Each of the terms hm(eI1, fJ1 , xT1 ) denotes oneof the various models which are involved in therecognition procedure.
Each individual model isweighted by its scaling factor ?m.
As there isno direct dependence between fJ1 and xT1 , thehm(eI1, fJ1 , xT1 ) is in one of these two forms:hm(eI1, xT1 ) and hm(eI1, fJ1 ).
Due to the argmaxoperator which denotes the search, no renormal-ization is considered in Eq.
3.
This approach hasbeen suggested by (Papineni et al, 1997; Papineniet al, 1998) for a natural language understandingtask, by (Beyerlein, 1998) for an ASR task, andby (Och and Ney, 2002) for an MT task.
Thisapproach is a generalization of Eq.
2.
The di-rect modeling has the advantage that additionalmodels can be easily integrated into the overallsystem.
The model scaling factors ?M1 are trainedon a development corpus according to the finalrecognition quality measured by the word errorrate (WER)(Och, 2003).SearchThe search in the MT and the ASR systems isalready very complex, therefore a fully integratedsearch to combine ASR and MT models willconsiderably increase the complexity.
To reducethe complexity of the search, we perform twoindependent searches with the MT and the ASRsystems, the search result of each system will berepresented as a large word graph.
We considerMT and ASR word graphs as FSA.
Then, we areable to use FSA algorithms to integrate MT andASR word graphs.
The FSA implementation ofthe search allows us to use standard optimizedalgorithms, e.g.
available from an open sourcetoolkit (Kanthak and Ney, 2004).The recognition process is performed in twosteps.
First, the baseline ASR system generates aword graph in the FSA format for a given utterancexT1 .
Second, the translation models rescore eachword graph based on the corresponding sourcelanguage sentence.
For each utterance, the deci-sion about the best sentence is made according tothe recognition and the translation models.4683 Baseline ComponentsIn this section, we briefly describe the basic sys-tem components, namely the MT and the ASRsystems.3.1 Machine Translation SystemWe make use of the RWTH phrase-based statis-tical machine translation system for the Englishto German automatic translation.
The system in-cludes the following models: an n-gram languagemodel, a phrase translation model and a word-based lexicon model.
The latter two models areused for both directions: German to English andEnglish to German.
Additionally, a word penaltyand a phrase penalty are included.
The reorderingmodel of the baseline system is distance-based, i.e.it assigns costs based on the distance from the endposition of a phrase to the start position of the nextphrase.
More details about the baseline systemcan be found in (Zens and Ney, 2004; Zens et al,2005).3.2 Automatic Speech Recognition SystemThe acoustic model of the ASR system is trainedon the VerbMobil II corpus (Sixtus et al, 2000).The corpus consists of German large-vocabularyconversational speech: 36k training sentences(61.5h) from 857 speakers.
The test corpus iscreated from the German part of the bilingualEnglish-German XEROX corpus (Khadivi et al,2005): 1562 sentences including 18k runningwords (2.6h) from 10 speakers.
The test cor-pus contains 114 out-of-vocabulary (OOV) words.The remaining part of the XEROX corpus is usedto train a back off trigram language model us-ing the SRI language modeling toolkit (Stolcke,2002).
The LM perplexity of the speech recogni-tion test corpus is about 83.
The acoustic model ofthe ASR system can be characterized as follows:?
recognition vocabulary of 16716 words;?
3-state-HMM topology with skip;?
2500 decision tree based generalized within-word triphone states including noise plus onestate for silence;?
237k gender independent Gaussian densitieswith global pooled diagonal covariance;?
16 MFCC features;?
33 acoustic features after applying LDA;?
LDA is fed with 11 subsequent MFCC vec-tors;?
maximum likelihood training using Viterbiapproximation.Table 1: Statistics of the machine translation cor-pus.English GermanTrain: Sentences 47 619Running Words 528 779 467 633Vocabulary 9 816 16 716Singletons 2 302 6 064Dev: Sentences 700Running Words 8 823 8 050Unknown words 56 108Eval: Sentences 862Running Words 11 019 10 094Unknown words 58 100The test corpus recognition word error rate is20.4%.
Compared to the previous system (Khadiviet al, 2005), which has a WER of 21.2%, weobtain a 3.8% relative improvement in WER.
Thisimprovement is due to a better and complete opti-mization of the overall ASR system.4 Integration ApproachesIn this section, we will introduce several ap-proaches to integrate the MT models with the ASRmodels.
To present the content of this section in amore reader-friendly way, we will first explain thetask and corpus statistics, then we will present theresults of N -best rescoring.
Afterwards, we willdescribe the new methods for integrating the MTmodels with the ASR models.
In each sub-section,we will also present the recognition results.4.1 TaskThe translation models are trained on the part ofthe English-German XEROX corpus which wasnot used in the speech recognition test corpus.
Wedivide the speech recognition test corpus into twoparts, the first 700 utterances as the developmentcorpus and the rest as the evaluation corpus.
Thedevelopment corpus is used to optimize the scal-ing factors of different models (explained in Sec-tion 2).
The statistics of the corpus are depicted inTable 1.
The German part of the training corpus isalso used to train the language model.4.2 N -best RescoringTo rescore the N -best lists, we use the methodof (Khadivi et al, 2005).
But the results shownhere are different from that work due to a betteroptimization of the overall ASR system, using a469Table 2: Recognition WER [%] using N -bestrescoring method.Models Dev EvalMT 47.1 50.5ASR 19.3 21.3ASR+MT IBM-1 17.8 19.0HMM 18.2 19.2IBM-3 17.1 18.4IBM-4 17.1 18.3IBM-5 16.6 18.2Phrase-based 18.8 20.3better MT system, and generating a larger N -bestlist from the ASR word graphs.
We rescore theASR N -best lists with the standard HMM (Vogelet al, 1996) and IBM (Brown et al, 1993) MTmodels.
The development and evaluation sets N -best lists sizes are sufficiently large to achievealmost the best possible results, on average 1738hypotheses per each source sentence are extractedfrom the ASR word graphs.The recognition results are summarized in Ta-ble 2.
In this table, the translation results of theMT system are shown first, which are obtainedusing the phrase-based approach.
Then the recog-nition results of the ASR system are shown.
After-wards, the results of combined speech recognitionand translation models are presented.For each translation model, the N -best listsare rescored based on the translation probabilityp(eI1|fJ1 ) of that model and the probabilities ofspeech recognition and language models.
In thelast row of Table 2, the N -best lists are rescoredbased on the full machine translation system ex-plained in Section 3.1.The best possible hypothesis achievable fromthe N -best list has the WER (oracle WER) of11.2% and 12.4% for development and test sets,respectively.4.3 Direct IntegrationAt the first glance, an obvious method to combinethe ASR and MT systems is the integration at thelevel of word graphs.
This means the ASR systemgenerates a large word graph for the input targetlanguage speech, and the MT system also gener-ates a large word graph for the source languagetext.
Both MT and ASR word graphs are in thetarget language.
These two word graphs can beconsidered as two FSA, then using FSA theory,we can integrate two word graphs by applying thecomposition algorithm.We conducted a set of experiments to integratethe ASR and MT systems using this method.
Weobtain a WER of 19.0% and 20.9% for devel-opment and evaluation sets, respectively.
Theresults are comparable to N -best rescoring resultsfor the phrase-based model which is presented inTable 2.
The achieved improvements over theASR baseline are statistically significant at the99% level (Bisani and Ney, 2004).
However, theresults are not promising compared to the resultsof the rescoring method presented in Table 2 forHMM and IBM translation models.
A detailedanalysis revealed that only 31.8% and 26.7% ofsentences in the development and evaluation setshave identical paths in both FSA, respectively.
Inother words, the search algorithm was not able tofind any identical paths in two given FSA for theremaining sentences.
Thus, the two FSA are verydifferent from each other.
One explanation forthe failure of this method is the large differencebetween the WERs of two systems, as shown inTable 2 the WER for the MT system is more thantwice as high as for the ASR system.4.4 Integrated SearchIn Section 4.3, two separate word graphs aregenerated using the MT and the ASR systems.Another explanation for the failure of the directintegration method is the independent search togenerate the word graphs.
The search in the MTand the ASR systems is already very complex,therefore a full integrated search to combine ASRand MT models will considerably increase thecomplexity.However, it is possible to reduce this problemby integrating the ASR word graphs into the gen-eration process of the MT word graphs.
Thismeans, the ASR word graph is used in addition tothe usual language model.
This kind of integrationforces the MT system to generate identical paths tothose in the ASR word graph.
Using this approach,the number of identical paths in MT and ASRword graphs are increased to 39.7% and 34.4%of the sentences in development and evaluationsets, respectively.
The WER of the integratedsystem are 19.0% and 20.7% for development andevaluation sets.4.5 Lexicon-Based TransducerThe idea of a dynamic vocabulary, restricting andweighting the word lexicon of the ASR was first470introduced in (Brousseau et al, 1995).
The ideawas also seen later in (Paulik et al, 2005b), theyextract the words of the MT N -best list to restrictthe vocabulary of the ASR system.
But they bothreported a negative effect from this method onthe recognition accuracy.
Here, we extend thedynamic vocabulary idea by weighting the ASRvocabulary based on the source language text andthe translation models.
We use the lexicon modelof the HMM and the IBM MT models.
Based onthese lexicon models, we assign to each possibletarget word e the probability Pr(e|fJ1 ).
One wayto compute this probability is inspired by IBMModel 1:Pr(e|fJ1 ) =1J + 1J?j=0p(e|fj)We can design a simple transducer (or more pre-cisely an acceptor) using probability in Eq.
4 toefficiently rescore all paths (hypotheses) in theword graph with IBM Model 1:PIBM-1(eI1|fJ1 ) =1(J + 1)II?i=1J?j=0p(ei|fj)=I?i=11(J + 1) ?
p(ei|fJ1 )The transducer is formed by one node and a num-ber of self loops for each target language word.
Ineach arc of this transducer, the input label is targetword e and the weight is ?
log 1J+1 ?
p(e|fJ1 ).We conducted experiments using the proposedtransducer.
We built different transducers with thelexicons of HMM and IBM translation models.
InTable 3, the recognition results of the rescoredword graphs are shown.
The results are verypromising compared to the N -best list rescoring,especially as the designed transducer is very sim-ple.
Similar to the results for the N -best rescoringapproach, these experiments also show the benefitof using HMM and IBM Models to rescore theASR word graphs.Due to its simplicity, this model can be easilyintegrated into the ASR search.
It is a sentencespecific unigram LM.4.6 Phrase-Based TransducerThe phrase-based translation model is the maincomponent of our translation system.
The pairsof source and corresponding target phrases areextracted from the word-aligned bilingual trainingTable 3: Recognition WER [%] using lexicon-based transducer to rescore ASR word graphs.Models Dev EvalASR 19.3 21.3ASR+MT IBM-1 17.5 19.0HMM 17.8 19.2IBM-3 17.7 18.8IBM-4 17.8 18.8IBM-5 17.6 18.9corpus (Zens and Ney, 2004).
In this section, wedesign a transducer to rescore the ASR word graphusing the phrase-based model of the MT system.For each source language sentence, we extract allpossible phrases from the word-aligned trainingcorpus.
Using the target part of these phraseswe build a transducer similar to the lexicon-basedtransducer.
But instead of a target word on eacharc, we have the target part of a phrase.
The weightof each arc is the negative logarithm of the phrasetranslation probability.This transducer is a good approximation of non-monotone phrase-based-lexicon score.
Using thedesigned transducer it is possible that some partsof the source texts are not covered or covered morethan once.
Then, this model can be comparedto the IBM-3 and IBM-4 models, as they alsohave the same characteristic in covering the sourcewords.
The above assumption is not critical forrescoring the ASR word graphs, as we are con-fident that the word order is correct in the ASRoutput.
In addition, we assume low probability forthe existence of phrase pairs that have the sametarget phrase but different source phrases within aparticular source language sentence.Using the phrase-based transducer to rescorethe ASR word graph results in WER of 18.8%and 20.2% for development and evaluation sets,respectively.
The improvements are statisticallysignificant at the 99% level compared to the ASRsystem.
The results are very similar to the resultsobtained using N -best rescoring method.
Butthe transducer implementation is much simplerbecause it does not consider the word-based lex-icon, the word penalty, the phrase penalty, andthe reordering models, it just makes use of phrasetranslation model.
The designed transducer ismuch faster in rescoring the word graph than theMT system in rescoring the N -best list.
The av-erage speed to rescore the ASR word graphs withthis transducer is 49.4 words/sec (source language471text words), while the average speed to translatethe source language text using the MT system is8.3 words/sec.
The average speed for rescoringthe N -best list is even slower and it depends onthe size of N -best list.A surprising result of the experiments as hasalso been observed in (Khadivi et al, 2005), is thatthe phrase-based model, which performs the bestin MT, has the least contribution in improving therecognition results.
The phrase-based model usesmore context in the source language to generatebetter translations by means of better word selec-tion and better word order.
In a CAT system, theASR system has much better recognition qualitythan MT system, and the word order of the ASRoutput is correct.
On the other hand, the ASRrecognition errors are usually single word errorsand they are independent from the context.
There-fore, the task of the MT models in a CAT system isto enhance the confidence of the recognized wordsbased on the source language text, and it seemsthat the single word based MT models are moresuitable than phrase-based model in this task.4.7 Fertility-Based TransducerIn (Brown et al, 1993), three alignment modelsare described that include fertility models, theseare IBM Models 3, 4, and 5.
The fertility-basedalignment models have a more complicated struc-ture than the simple IBM Model 1.
The fertilitymodel estimates the probability distribution foraligning multiple source words to a single targetword.
The fertility model provides the probabili-ties p(?|e) for aligning a target word e to ?
sourcewords.
In this section, we propose a method forrescoring ASR word graphs based on the lexiconand fertility models.In (Knight and Al-Onaizan, 1998), some trans-ducers are described to build a finite-state basedtranslation system.
We use the same transduc-ers for rescoring ASR word graphs.
Here, wehave three transducers: lexicon, null-emitter, andfertility.
The lexicon transducer is formed byone node and a number of self loops for eachtarget language word, similar to IBM Model 1transducer in Section 4.5.
On each arc of thelexicon transducer, there is a lexicon entry: theinput label is a target word e, the output label isa source word f , and the weight is ?
log p(f |e).The null-emitter transducer, as its name states,emits the null word with a pre-defined probabilityafter each input word.
The fertility transducer isalso a simple transducer to map zero or severalinstances of a source word to one instance of thesource word.The ASR word graphs are composed succes-sively with the lexicon, null-emitter, fertility trans-ducers and finally with the source language sen-tence.
In the resulting transducer, the input labelsof the best path represent the best hypothesis.The mathematical description of the proposedmethod is as follows.
We can decompose Eq.
1using Bayes?
decision rule:e?I?1= argmaxI,eI1{Pr(eI1|fJ1 , xT1 )} (4)?= argmaxI,eI1{Pr(fJ1 )Pr(eI1|fJ1 )Pr(xT1 |eI1)}(5)In Eq.
5, the term Pr(xT1 |eI1) is the acoustic modeland can be represented with the ASR word graph1,the term Pr(eI1|fJ1 ) is the translation model ofthe target language text to the source languagetext.
The translation model can be representedby lexicon, fertility, and null-emitter transducers.Finally, the term Pr(fJ1 ) is a very simple languagemodel, it is the source language sentence.The source language model in Eq.
5 can beformed into the acceptor form in two differentways:1. a linear acceptor, i.e.
a sequence of nodeswith one incoming arc and one outgoing arc,the words of source language text are placedconsecutively in the arcs of the acceptor,2.
an acceptor containing possible permuta-tions.
To limit the permutations, we used anapproach as in (Kanthak et al, 2005).Each of these two acceptors results in differentconstraints for the generation of the hypotheses.The first acceptor restricts the system to generateexactly the same source language sentence, whilethe second acceptor forces the system to generatethe hypotheses that are a reordered variant ofthe source language sentence.
The experimentsconducted do not show any significant differencein the recognition results among the two sourcelanguage acceptors, except that the second accep-tor is much slower than the first acceptor.
There-fore, we use the first model in our experiments.Table 4 shows the results of rescoring the ASRword graphs using the fertility-based transducers.1Actually, the ASR word graph is obtained by usingPr(xT1 |eI1) and Pr(eI1) models.
However, It does not causeany problem in the modeling, especially when we make useof the direct modeling, Eq.
3472Table 4: Recognition WER [%] using fertility-based transducer to rescore ASR word graphs.Models Dev EvalASR 19.3 21.3ASR+MT IBM-3 17.4 18.6IBM-4 17.4 18.5IBM-5 17.6 18.7As Table 4 shows, we get alost the sameor slightly better results when compared to thelexicon-based transducers.Another interesting point about Eq.
5 is its simi-larity to speech translation (translation from targetspoken language to source language text).
Then,we can describe a speech-enabled CAT systemas similar to a speech translation system, exceptthat we aim to get the best ASR output (the bestpath in the ASR word graph) rather than the besttranslation.
This is because the best translation,which is the source language sentence, is alreadygiven.5 ConclusionWe have studied different approaches to integrateMT with ASR models, mainly using finite-stateautomata.
We have proposed three types of trans-ducers to rescore the ASR word graphs: lexicon-based, phrase-based and fertility-based transduc-ers.
All improvements of the combined modelsare statistically significant at the 99% level withrespect to the baseline system, i.e.
ASR only.In general, N -best rescoring is a simplificationof word graph rescoring.
As the size of N -bestlist is increased, the results obtained by N -bestlist rescoring approach the results of the wordgraph rescoring.
But we should consider that thestatement is correct when we use exactly the samemodel and the same implementation to rescore theN -best list and word graph.
Figure 1 shows theeffect of the N -best list size on the recognitionWER of the evaluation set.
As we expected, therecognition results of N -best rescoring improveas N becomes larger, until the point that therecognition result converges to its optimum value.As shown in Figure 1, we should not expect thatword graph rescoring methods outperform the N -best rescoring method, when the size of N -bestlists are large enough.
In Table 2, the recognitionresults are calculated using a large enough size forN -best lists, a maximum of 5,000 per sentence,which results in the average of 1738 hypotheses1818.51919.52020.52121.51  10  100  1000  10000WER[%]Size of N-best list (N), in log scaleIBM-1HMMIBM-3IBM-4IBM-5Figure 1: The N -best rescoring results for differ-ent N -best sizes on the evaluation set.per sentence.
An advantage of the word graphrescoring is the confidence of achieving the bestpossible results based on a given rescoring model.The word graph rescoring methods presented inthis paper improve the baseline ASR system withstatistical significance.
The results are competitivewith the best results of N -best rescoring.
For thesimple models like IBM-1, the transducer-basedintegration generates similar or better results thanN -best rescoring approach.
For the more com-plex translation models, IBM-3 to IBM-5, theN -best rescoring produces better results than thetransducer-based approach, especially for IBM-5.
The main reason is due to exact estimationof IBM-5 model scores on the N -best list, whilethe transducer-based implementation of IBM-3 toIBM-5 is not exact and simplified.
However, weobserve that the fertility-based transducer whichcan be considered as a simplified version of IBM-3 to IBM-5 models can still obtain good results,especially if we compare the results on the evalu-ation set.AcknowledgementThis work has been funded by the EuropeanUnion under the RTD project TransType2 (IST2001 32091) and the integrated project TC-STAR - Technology and Corpora for Speechto Speech Translation -(IST-2002-FP6-506738,http://www.tc-star.org).ReferencesP.
Beyerlein.
1998.
Discriminative model combina-tion.
In Proc.
IEEE Int.
Conf.
on Acoustics, Speech,and Signal Processing (ICASSP), volume 1, pages481 ?
484, Seattle, WA, May.473M.
Bisani and H. Ney.
2004.
Bootstrap estimatesfor confidence intervals in ASR performance evalu-ationx.
In IEEE International Conference on Acous-tics, Speech, and Signal Processing, pages 409?412,Montreal, Canada, May.J.
Brousseau, C. Drouin, G. Foster, P. Isabelle,R.
Kuhn, Y. Normandin, and P. Plamondon.
1995.French speech recognition in an automatic dictationsystem for translators: the transtalk project.
In Pro-ceedings of Eurospeech, pages 193?196, Madrid,Spain.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: Parameter estimation.
Compu-tational Linguistics, 19(2):263?311, June.P.
F. Brown, S. F. Chen, S. A. Della Pietra, V. J. DellaPietra, A. S. Kehler, and R. L. Mercer.
1994.
Au-tomatic speech recognition in machine-aided trans-lation.
Computer Speech and Language, 8(3):177?187, July.M.
Dymetman, J. Brousseau, G. Foster, P. Isabelle,Y.
Normandin, and P. Plamondon.
1994.
Towardsan automatic dictation system for translators: theTransTalk project.
In Proceedings of ICSLP-94,pages 193?196, Yokohama, Japan.G.
Foster, P. Isabelle, and P. Plamondon.
1997.
Target-text mediated interactive machine translation.
Ma-chine Translation, 12(1):175?194.S.
Kanthak and H. Ney.
2004.
FSA: An efficientand flexible C++ toolkit for finite state automatausing on-demand computation.
In Proc.
of the 42ndAnnual Meeting of the Association for Computa-tional Linguistics (ACL), pages 510?517, Barcelona,Spain, July.S.
Kanthak, D. Vilar, E. Matusov, R. Zens, andH.
Ney.
2005.
Novel reordering approaches inphrase-based statistical machine translation.
In 43rdAnnual Meeting of the Assoc.
for ComputationalLinguistics: Proc.
Workshop on Building and UsingParallel Texts: Data-Driven Machine Translationand Beyond, pages 167?174, Ann Arbor, Michigan,June.S.
Khadivi, A. Zolnay, and H. Ney.
2005.
Automatictext dictation in computer-assisted translation.
InInterspeech?2005 - Eurospeech, 9th European Con-ference on Speech Communication and Technology,pages 2265?2268, Portugal, Lisbon.K.
Knight and Y. Al-Onaizan.
1998.
Translationwith finite-state devices.
In D. Farwell, L. Gerber,and E. H. Hovy, editors, AMTA, volume 1529 ofLecture Notes in Computer Science, pages 421?437.Springer Verlag.F.
J. Och and H. Ney.
2002.
Discriminative trainingand maximum entropy models for statistical ma-chine translation.
In Proc.
of the 40th Annual Meet-ing of the Association for Computational Linguistics(ACL), pages 295?302, Philadelphia, PA, July.F.
J. Och, R. Zens, and H. Ney.
2003.
Efficient searchfor interactive statistical machine translation.
InEACL03: 10th Conf.
of the Europ.
Chapter of theAssociation for Computational Linguistics, pages387?393, Budapest, Hungary, April.F.
J. Och.
2003.
Minimum error rate training instatistical machine translation.
In Proc.
of the 41thAnnual Meeting of the Association for Computa-tional Linguistics (ACL), pages 160?167, Sapporo,Japan, July.K.
A. Papineni, S. Roukos, and R. T. Ward.
1997.Feature-based language understanding.
In EU-ROSPEECH, pages 1435?1438, Rhodes, Greece,September.K.
A. Papineni, S. Roukos, and R. T. Ward.
1998.Maximum likelihood and discriminative trainingof direct translation models.
In Proc.
IEEE Int.Conf.
on Acoustics, Speech, and Signal Processing(ICASSP), volume 1, pages 189?192, Seattle, WA,May.M.
Paulik, S. Stu?ker, C. Fu?gen, , T. Schultz, T. Schaaf,and A. Waibel.
2005a.
Speech translation enhancedautomatic speech recognition.
In Automatic SpeechRecognition and Understanding Workshop (ASRU),pages 121?126, Puerto Rico, San Juan.M.
Paulik, C. Fu?gen, S. Stu?ker, T. Schultz, T. Schaaf,and A. Waibel.
2005b.
Document driven machinetranslation enhanced ASR.
In Interspeech?2005 -Eurospeech, 9th European Conference on SpeechCommunication and Technology, pages 2261?2264,Portugal, Lisbon.A.
Sixtus, S. Molau, S.Kanthak, R. Schlu?ter, andH.
Ney.
2000.
Recent improvements of theRWTH large vocabulary speech recognition systemon spontaneous speech.
In Proc.
IEEE Int.
Conf.
onAcoustics, Speech, and Signal Processing (ICASSP),pages 1671 ?
1674, Istanbul, Turkey, June.A.
Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In Proc.
of the Int.
Conf.on Speech and Language Processing (ICSLP), vol-ume 2, pages 901?904, Denver, CO, September.S.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM-based word alignment in statistical translation.
InCOLING ?96: The 16th Int.
Conf.
on ComputationalLinguistics, pages 836?841, Copenhagen, Denmark,August.R.
Zens and H. Ney.
2004.
Improvements in phrase-based statistical machine translation.
In Proc.
of theHuman Language Technology Conf.
(HLT-NAACL),pages 257?264, Boston, MA, May.R.
Zens, O. Bender, S. Hasan, S. Khadivi, E. Matusov,J.
Xu, Y. Zhang, and H. Ney.
2005.
The RWTHphrase-based statistical machine translation system.In Proceedings of the International Workshop onSpoken Language Translation (IWSLT), pages 155?162, Pittsburgh, PA, October.474
