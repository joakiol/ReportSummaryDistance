Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 32?42,Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational LinguisticsTrap Hunting: Finding Personal Data Management Issues in NextGeneration AAC DevicesJoseph ReddingtonRoyal Holloway CollegeEgham, UKj.reddington@rhul.ac.ukLizzie Coles-KempRoyal Holloway CollegeEgham, UKlizzie.coles-kemp@rhul.ac.ukAbstractAdvances in natural language generation andspeech processing techniques, combined withchanges in the commercial landscape, havebrought within reach dramatic improvementsin Augmentative Alternative Communication(AAC).
These improvements, though over-whelmingly positive, amplify a family of per-sonal data use problems.
This paper arguesthat the AAC design and implementation pro-cess needs to identify and address personaldata use problems.
Accordingly, this paperexplores personal data management problemsand proposes responses.
This paper is situatedin the context of AAC technology but the re-sponses could be generalised for other com-munities affected by low digital literacy, lowliteracy levels and cognitive challenges.1 IntroductionElectronic Augmentative and Alternative Commu-nication (AAC) systems enable individuals with se-vere speech impairment to verbally communicatetheir needs, often using Text-to-Speech technology.Such devices are designed to give communicationimpaired people greater independence and improvedopportunities of social integration.
The devices en-able users to construct utterances, many of which de-scribe themselves or aspects of their lives, includingtheir actions with others and, as such, can be con-sidered ?personal data?.
Recent work by Patel andRadhakrishnan (2007), Black et al (2010), Reiteret al (2009), and Reddington and Tintarev (2011)makes explicit use of personal data (about both theuser and other parties) to improve the functionalityof AAC devices.
Depending on context, the use ofthese utterances, in an institutional setting, may becontrolled under data protection legislation, or (e.g.domestically) their use may be influenced more bysocial norms within the context.
A key factor in per-sonal data management is the highly contextual na-ture of privacy related issues; privacy concerns andpractices are situated in their context (Nissenbaum,2009) and influenced by cultural issues (Milberg etal., 2000).The diversity of technology in the AAC sectoris set to increase dramatically.
Apple?s iPad1 hascaused a huge investment in tablet technology.
Mul-tiple, third party applications (e.g.
proloque2go2,myVoice3, and verbally4) already exist that allowthis new range of tablets to function as AAC devices.The effect of this research movement maturingat a time when many new devices and producersare entering the market foreshadows probable ma-jor changes and innovations in coming years.
Thisincludes a risk of the ?panoply of different privacyproblems?
that privacy theorist Solove (2008) fore-saw as a result of diversifying and enhancing tech-nologies.The authors?
position is that it is very timely toexplore personal data management problems in thisnew AAC landscape and in so doing identify trapsthat AAC design might stumble into as this technol-ogy change gathers pace.
This perspective can con-1http://www.apple.com/ipad/, retrieved May 20112http://www.proloquo2go.com, retrieved May 20113http://new.myvoiceaac.com, retrieved May 20114http://verballyapp.com/index.html,retrieved May 201132tribute to the design of technologies and governancestructures that are able to both identify and respondto such traps.As AAC devices are designed to be used in all ar-eas of the AAC user?s life, there are a broad rangeof personal data management problems, which arehighly context sensitive and incorporate legal, so-cial, and technical issues.
This complex problemspace centres on informational privacy issues thatcontribute to a wider family of personal data man-agement problems that can be found in contexts ofAAC use.This paper situates the personal data managementproblems in the use of natural language generationand speech processing techniques in AAC.
It consid-ers all of the following as personal data: utterancesconstructed by the system, communication logs andre-communication of stored utterances.
Followingan overview of state-of-the-art AAC and discussionof how functionality development in next-generationAAC devices maps to the use of personal data, Sec-tion 2 identifies and explores personal data use prob-lems in three AAC-specific examples.
Section 3presents possible responses to problems introducedby the examples and Section 4 considers a gov-ernance framework that enables emergent personaldata management problems with future AAC de-vices to be identified and considers its applicabilityfor other communities.1.1 Personal data generated, and used, by AACdevicesToday, AAC devices may excel at needs-based com-munication (e.g.
?I am hungry?, ?I?m cold?, ?getthe phone?)
but they are limited for real conversa-tion (Soto et al, 2006).
So, in the current genera-tion of AAC devices, the implications for both per-sonal data generation and its use are relatively smallbecause the linguistic capabilities are small.
Typi-cal AAC devices tend towards a hierarchical struc-ture of pages, each of which typically focuses on acontext (e.g.
shopping) or a category (e.g.
clothes,sports), rather than observations or recent personalstories (Beukelman and Mirenda, 2005).
However,Higginbotham et al (2007) report that spontaneousconversation with typical devices is slow and diffi-cult (new utterances are typically constructed at arate of between 8 and 10 words per minute, slightlymore if e.g.
word prediction is used).
Todman etal.
(2008) propose utterance-based devices in whichdevices focus on prepared phrases to facilitate socialcommunication rather than needs-based communi-cation; however, in general, new utterances must beprepared in advance either by the user or a carer,with a large time and energy cost.
It is this im-plementation of functionality designed to speed uputterance production that restricts the production ofpersonal data rather than the underlying technology.A study by Rackensperger et al (2005) shows thatusing pre-programmed phrases can reduce the abil-ity for self-expression; as a result, the range of per-sonal data produced is likely to be limited.
As anexample, there is a particular difficulty in commu-nicating recent or single use events such as talkingabout one?s day or talking about yesterday?s tele-vision: such utterances are expensive to prepare inadvance due to the potential for limited and low-probability use.
Thus, AAC users tend to be pas-sive, responding to questions with single words orshort sentences, and personal stories tend to be toldas a monologue or a sequence of pre-stored utter-ances (Soto et al, 2006).To develop the potential for interaction, and there-fore increase the degree to which AAC devices cansupport increased independence, recent research hasexamined the potential for location-aware devicesto offer different content to the user under differ-ent conditions (Dominowska et al, 2002; Patel andRadhakrishnan, 2007), and for devices that generatenew phrases automatically.
In the later case: Blacket al (2010) use external data to populate a commu-nication device, and Reiter et al (2009) use a NLGengine to generate text from a database of personalfacts.
These innovations could allow users to in-crease social interaction and reduce the device main-tenance, complementing the growing range of AACsystems with internet connectivity.1.1.1 Impact on personal dataAs the capability for interaction increases, the po-tential for increased personal data also increases.For example:?
utterances generated from geo-location enableddevices can potentially include informationabout people (data subjects) other than the33AAC user, as well as increased informationabout the device users themselves;?
utterances generated from input by teachers,care staff and parents can again potentially con-tain information about other data subjects, aswell as increase the range of information aboutdevice users themselves;?
internet access as a medium brings a range ofissues for personal data use in terms of themethods used to broadcast and replay utter-ances and it greatly increases the possibilitiesfor data input (potentially including informa-tion about third parties) into the utterances;?
the general browsing facility of internet accessincreases the ability of users to communicatewith the wider world, carrying with it a setof personal data management and privacy is-sues, much of which is the subject of on-goingresearch (Kani-Zabihi and Coles-Kemp, 2010;Kumaraguru and Cranor, 2005; Spiekermannand Cranor, 2009).Increasing the potential for interaction and givingmore control to the AAC user will increase the rangeof personal data generated and hence the range ofpotential personal data use problems.
Moreover,the increased creation of novel utterances and wideropportunity to relay such utterances potentially in-crease intellectual property issues.AAC devices are designed to increase social inter-action in all settings and therefore the devices, andtheir supporting approaches, must be equally effec-tive in all situations.
This is a challenge for any typeof personal data management that includes aspectsof privacy.
Also, AAC users themselves developtheir uses and desires for communication (Rack-ensperger et al, 2005).
Therefore, any approach topersonal data management has to be highly contextsensitive and capable of responding to changing re-quirements.1.2 Related work in AAC literatureAlthough ethics in the context of complex disabil-ities is well studied, there is little direct researchinto privacy and personal data management issuesin AAC: much of the work is in small accompany-ing sections to other research contributions and fo-cuses directly on personal data dissemination.
Forexample, Smith (2005) notes that externally dis-played lexicons (such as a communications board)violate some aspects of privacy and proposes findingways to ensure that vocabulary can be delivered dis-creetly without affecting access.
Similarly, Black etal.
(2010) address privacy as part of a discussion ofsecurity.
Additionally, there is some meta-work thatlooks at the ethics of research into AAC rather thanAAC itself: Pennington et al (2007) notes that thedata collected by AAC devices makes identificationof the individual trivial, especially when consideringthe relatively small pool of users, a theme that is alsoexamined in work by Lesher et al (2000) on loggingoutput of AAC devices.Privacy has also been raised explicitly in theAAC community by researchers considering de-sign frameworks for next generation devices, e.g.,Rackensperger et al (2005) and DeRuyter et al(2007).
There is also a growing body of AAC re-search that, in discussing next generation AAC tech-nology, raises a wide range of implicit issues re-lated to privacy and ICT mediated communication.These issues include: anonymity; personalisation ofservices; identity management; autonomy; and thechanging of relationship boundaries through media-tion.
These are topics that feature in traditional pri-vacy research, but with added complexity.Therefore, work on the future of AAC and in-ternet connectivity (in particular key features high-lighted in DeRuyter et al (2007)) have great bear-ing on personal data management, although privacyand personal data management are not directly dis-cussed.
DeRuyter et al (2007) discuss simplifiedusability, including ?embeddedness?
functionality:making AAC devices unobtrusive in their environ-ment.
When simplifying usability, there is a ten-sion between requiring user intervention and deci-sion making automation.
For example, where shouldconsent mechanisms related to personal informationdisclosure be placed?Discussions on future AAC functionality also em-phasise adaptive technology that personalises AACuse so that AAC devices are able to recognise a userand adjust functionality accordingly (DeRuyter etal., 2007).
However, adaptation algorithms designed34to anticipate or assess user capabilities will make ad-justments to functionality based on logs of personaldata and usage patterns and thus implicitly processpersonal data.
The ability to adjust such algorithmswould give users and their carers increased controlover the use of this personal data.
In addition, adjust-ing the capabilities of Internet-enabled AAC devicesis likely to also result in changes to the disclosureof a user?s personal data.
This disclosure would bedetermined using a logic internal to the adaptationalgorithms.
Making the logic explicit to users andtheir carers would make both the personal data dis-closure implications of adjustment visible and givegreater control over disclosure.2 ExamplesGiven the situated nature of informational privacy,in order to explore personal data management is-sues meaningfully, it is vital to situate the evalua-tion policy and its related personal data managementissues into a particular context.
We have selectedthree AAC-specific examples through which to ex-plore the issues in particular contexts.This section describes three illustrative scenariosfor potential personal data use problems.
They arebroadly based on the categories of generated con-tent in Reddington and Tintarev (2011) and are con-structed with input from legal experts, youth workpractitioners, and disability officers.
The examplessituate the personal data management problems be-fore analysis in Section 3.2.1 Example 1 - Creating Novel UtterancesThe simplest, and least intrusive level of automati-cally generated content contains inferred utterancesthat can be deduced from logs of previous utter-ances.
Thus, if a device logged the phrase ?HelloMary?
and later ?Thanks Mary?
the phrase ?Today Ispent time with Mary?
could be added to the list ofavailable phrases.
It is trivial to imagine other pos-sible situations where this is applicable - ?My com-munications unit has been away for repair?, ?I wasup very late last night?, and ?I like to talk about foot-ball?, are all deducible from previous utterances.We consider an AAC user Alice, who is solelyreliant on her AAC device for communication andis non-literate.
Alice is able to generate novel ut-terances using utterance segments programmed bycare staff and by taking advantage of inferred utter-ances that her device has been designed to provide.Alice has the right to delete certain utterances butcare staff and family members are able to restore thedeleted utterances.
The digest of Alice?s activitiesare backed up every day and could be placed in acatalogue of utterances that the care provider uses atpromotional events or on the provider?s website.This scenario raises issues related to intellectualproperty rights, ownership, and the management ofpersonal data.
The management issues centre oncontrol of data, and rights to recover deleted items.2.2 Example 2 - Implicit and Explicit PersonalData Exchange RulesThe second and third levels of automatically gen-erated content involve receiving data from networkportals (such as the internet) and local sensors.
Forexample: ?It?s very warm today?, and ?It rainedon Friday!?.
Also included is media data: ?OnYouTube I watched the ?Star Wars Kid?
video ?, or?New series of Doctor Who!
?.A useful context here is the ?How was School To-day...??
(HWST) project (Black et al, 2010; Red-dington and Tintarev, 2011), which generates storiesfor students with complex communication needs ata special needs school.
The project logs interactionswith people, objects and location changes.
This sen-sor data is supplemented with timetable information(to infer classes based on time and location) andvoice recordings, before new content is generated.Consider that Alice is in a class and that her AACdevice reads information from sensors to generatenovel content in a similar way to the HWST sys-tem.
Also in class is Charlie, a typically developingchild.
Charlie?s actions are also recorded by the sen-sors and he takes part in activities with Alice.
Al-ice is able to report Charlie?s behaviour to her par-ents and to other class members.
Unlike when herclassmate Charlie verbally communicates about hisschool day, Alice?s utterances take a permanent formand can be replayed and reused.
Charlie is not reallyaware of this capability and what this means.
Char-lie?s parents are aware that Alice has some kind ofcommunication device and that sensors are used atschool but are not clear on the details.
Alice?s Mumputs some of Alice?s stories, including the one about35Figure 1: An example information flowCharlie and the water fight, up on their family blog.This scenario raises issues of consent to obtaindata from sensor sources and of processing the sen-sor data.
It also raises questions related to the dis-semination of personal data - about the user andother data subjects.
In this scenario, personal data isprocessed in two contexts: school and Alice?s home.This shows the complex array of stakeholders in-volved in managing personal data.
Moreover, thereare questions of how non-AAC users are informedof the implications of AAC use in the school or inany other setting.
Implicitly there is a problem ofensuring that AAC and non-AAC users are treatedequally in terms of the personal data rights, which inturn raises issues of how verbal and AAC generatedutterances are valued in the social context.2.3 Example 3 - Control over Data SharingAn additional level of complexity is the creation ofnarrative flow.
Narratives are groups of messagesthat together relate an experience or tell a story.
Thisadds the problem of creating a narrative structureand consistent style to the data-mining exercise (forNLG work on the importance of narrative informa-tion exchange see e.g.
(Reiter et al, 2008)).
Anexample might be:I had my breakfast quickly because I wasexcited to go to the arcade.
I got on thebus, I went to the arcade, I played in thearcade and won a cuddly bear.Now consider that Alice and Charlie are joinedby Bob, who is also an AAC user on the same sys-tem as Alice.
Alice and Bob?s devices are capable ofsharing data at all levels.
At the device level, Aliceand Bob share raw data to confirm, for example, thattheir system clocks are in sync and that they have thesame records of people who are in the same room.
Itis also possible at the social episode level that Al-ice?s system can import utterances from Bob?s sys-tem so that Alice could say ?Bob liked the swim-ming?.
It is important to note that in this scenario,if Alice deletes an utterance from her machine ?Theteacher gave me a bad mark on my work?, Bob couldstill use the deleted story because Alice is unable todelete the disseminations.
However, data sharing isnot only between device users.
Data sharing couldalso take place between the agencies involved in Al-ice and Bob?s care and support.
Figure 1 shows thisdata sharing taking place on three levels: device, in-dividual AAC user, and institutional.This scenario raises the issues of personal dataflow control and indicates that controls for the flowof personal data have to be set at all three levels.Importantly, when personal data flows are managedat these levels responses will always be sociotech-nical in nature; therefore they include technical re-sponses, governance responses and technology prac-tice responses.
This is a familiar combination of re-36sponses in privacy management (Paine et al, 2007)3 Finding traps and responding to themSection 2 demonstrated a family of personal data useproblems.
These problems address various aspectsof using personal data in the context of AAC de-vices.
Our family of problems partly relate to theoft used definition of privacy from Westin (1967):?the claim of individuals, groups, or institutions todetermine for themselves when, how, and to whatextent information about them is communicated toothers?.
This is not a hierarchy with a root problemand a tree structure of related problems but a fam-ily of problems with complex relations and whichare enmeshed rather than conceptually linear.
An-alytically, the family has four members: IPR; com-pliance responsibility; institutional personal data ac-cess and disclosure rights; and individual personaldata access and disclosure rights.
Each family mem-ber is addressed in this section.
Whitley points outthat Whitley (2009) ?Wittgenstein (1956) tells usthat language is a social activity and hence that spe-cialised terms like privacy are arrived at socially.
?.The social construction of concepts related to per-sonal data mean that personal data issues will be en-meshed in particular contexts and, as a result, thesignificance of these issues will vary from context tocontext.Discussions with legal experts and practitioners(see Acknowledgements) revealed that responses tothese problems occur at the institutional, individ-ual, and technical levels, and an individual inter-pretation of personal data management issues under-pins all responses.
This is true of all personal datamanagement issues; however, in the case of AACusers, the individual level will be a unique combina-tion of AAC user, family, and care workers.
At thenext level is the sociocultural system in place withineach institutional context, which contains the per-sonal data management policies, procedures, prac-tices and institutional values.
This sociocultural sys-tem is supported by technological controls used tocontrol personal data information flow.Unlike spoken conversation, AAC devices createembodiments of conversations that can be perma-nently stored or logged.
Then conversations becomedata that largely focuses on living individuals, ei-ther the users themselves or their family and friends.Under certain conditions processing this data will beregulated by data protection legislation.
In other set-tings the processing will be governed more by so-cial norms.
Furthermore, the permanent nature ofthese embodiments means that they can carry copy-right.
Then there is a natural question of informa-tion flow control, the need for rights managementand traditional information security issues such asconfidentiality and access control.
However, privacyis also an elastic concept (Allen, 1988) and is oftenconsidered wider than the Westin definition, includ-ing aspects of identity and relationship management.As the work of Smith (2005) and Rackenspergeret al (2005) shows, use of AAC devices is relatedto notions of self and relationship to others.
Thenotions of self and relationship to others are a cen-tral aspect of privacy (Kani-Zabihi and Coles-Kemp,2010) (Barnard-Wills and Ashenden, 2010) and thelink between personal data use and privacy and iden-tity issues should not be ignored when consideringthese personal data management problems.3.1 A Family of Personal Data Use ProblemsPractically, any technical, regulatory, or social re-sponse to personal data use issues in AAC must beable to operate in a range of contexts and support auser as they blend and adjust contexts.
For example,an AAC user may use their device at home, in formaleducation, in youth group activities, and in socialsettings.
These different contexts may include manyof the same people, but the personal data controlrequirements and the regulatory and personal datamanagement frameworks are likely to differ fromcontext to context.
A further level of complexity inthe case of AAC users is that capabilities and back-grounds differ widely within the AAC community(DeRuyter et al, 2007) and any personal data man-agement approach has to adjust to these varying ca-pabilities and different perspectives.Technical responses would primarily be formedby meshing the AAC functionality into the underly-ing technical architecture of each device.
Technicalresponses include personal information flow controlover the network; encryption of sensitive utterances,e.g.
health or financial information (such as creditcard numbers), stored on the AAC device; accesscontrol to location databases and so on.373.1.1 Management of IPRAutomatically generated text in AAC devices canbe coupled or merged with input from other sources,increasing the ability of users to develop additionalnovel utterances.
Given the digital nature of the ut-terances, there is potentially a close comparison withmusic copyright, which has three sets of rights: me-chanical, rights related to the creation of the lyricsand performing.
Using music copyright as the paral-lel, consider the situation where an AAC user, Alicesay, imports text from a novel under copyright (me-chanical rights) and adapts it by adding other textand other copyright material in order to create herown monologue (intellectual property rights).
An-other AAC user, Bob say, then downloads Alice?smonologue and performs it through his AAC de-vice at a concert for a school (performing rights).Clearly the majority of instances carry an implicitrights clearance, particularly in the content and per-forming rights elements of this example.
However,if the monologue was posted on YouTube and thenbecame sampled by a recording artist or made into adigital novel, rights clearance may not apply.
Com-municating the rules relating to copyright and ensur-ing understanding can be problematic.Social and institutional responses to IPR prob-lems are largely related to awareness training andthe agreement of ?ground rules?
or social contracts incommunities such as schools and youth clubs wherethe legal issues and social expectations are madeclear.
The traditional methods for negotiating andagreeing ground rules is heavily based on the use ofinformational literature, one-to-one and group dis-cussion (Barnard-Wills and Ashenden, 2010).
Thesemethods do not translate well into an environmentwhere users may have cognitive development issues,or may be non-literate.
It could be envisaged thatguardians and parents would be used to negotiateand agree the ground rules and then left with thetask of communicating the ground rules to their de-pendents.
The difficulty in this is that at the sametime, AAC users can become very skilled in theuse of technology and may well develop practicesthat involve copyright material, in a way that theirguardians have not been able to communicate effec-tively.
In order to respond to this mismatch of ca-pabilities, methods of engagement need to be soughtthat ensure AAC users are as integral as possible tothe establishment of such rules.3.1.2 Management of compliance responsibilityDue to the digital nature of AAC utterances, per-sonal data output by a device is regulated by dataprotection legislation when being processed in thecontext of institutions such as schools, health, or so-cial service.
In the UK, this legislation is the DataProtection Act 1998.
Under the Act there are eightprinciples of personal data management and the re-quirement that there must be a data controller whois responsible for compliance with the legislation.The term ?data subject?
denotes individuals to whomthe personal data relates.
If Alice and Bob wereyoung adults with sufficient cognitive abilities theywould likely be the data controllers.
However, asspeech, language and communication disabilities areregularly a pan-disability, Alice and Bob may alsobe cognitively impaired and a parent or guardian islikely to be regarded as the data controller.Typically, the mechanism for specifying compli-ance requirements is via the creation of a compli-ance schedule.
In the case of AAC use, a complianceschedule for AAC devices is likely to be between theinstitution (school or health services) and the par-ents.
The compliance schedule would establish theresponsibility for data processing and agree the rela-tionship between parents and institutions.
Note thatthe AAC user?s capabilities for technology can po-tentially exceed that of their guardians and parents.The relationship the AAC user has to the technol-ogy is quite possibly very different from that of theparent or guardian.
If effective compliance manage-ment is to be achieved, new engagement methodsneed to be sought to ensure that AAC users are ac-tively engaged in the establishment of complianceschedules.
The connection between the individual,the institution (school) and privacy legislation is il-lustrated in Figure 2.3.1.3 Management of institutional personaldata access and disclosure rightsA set of rights must be agreed as part of the com-pliance schedule when AAC devices are used inschool and healthcare settings.
Many AAC deviceshave their data backed up to a central database.
An38Figure 2: This diagram adapts the characterisation of in-stitutional culture found in (Allaire and Firsirotu, 1984)issue arises as to who has the right to back up or ac-cess the AAC data.
AAC devices that can restoredata that a user has deleted raise particular prob-lems, which relate to who has the right to restore thedata and the subsequent disclosure rights that thisindividual would have.
Problems also occur as towhether other AAC users have the right to down-load content from another AAC device and the sub-sequent disclosure rights that this would afford.AAC users will typically have considerable inter-vention from education and health support workers.Unlike spoken forms of conversations in other caresituations, AAC utterances have a digital embodi-ment.
This allows different teams in the care, ed-ucation and support of the user to easily share ut-terances, and it may be deemed to make care moreeffective to do so.
From an institutional perspective,data sharing policies should be set up to state whichaspects of AAC utterances can be shared, the peoplethat such utterances can be shared with, and a needfor transparency in the logic used to interpret the ut-terances.
In addition, the compliance schedule couldspecify which data transfers are permitted.3.1.4 Management of individual personal dataaccess and disclosure rightsWhilst many institutional issues are related to per-sonal data use, importantly, AAC users are likely touse devices for personal data disclosure outside ofthe institutional context as part of family and sociallife.
In this instance processing is controlled by so-cial norms and practices that could be considered asocial contract (Milne and Gordon, 1993).From a social perspective, developing social con-tracts or norms organically responds to problems re-lated to publishing of data about other data subjects,misuse of the AAC user?s personal data by friendsand family, and unintentional copyright infringe-ments.
In the scenario of AAC use, these social con-tracts and norms are re-enforced with education andawareness briefings (Bogdanovic et al, 2009) thatare typically driven by the education and health in-stitutions.
As part of these ground rules, the degreeof anonymity in any disclosures and the rights ofnon-AAC users to have their personal data removedfrom an AAC device are agreed or follow a sociallyaccepted path.
From a technical perspective, the de-vice interface could be developed to include utter-ances about information disclosure and feelings ofprivacy.
The log files could also include informationdisclosure and processing comments that practition-ers and family members might wish to discuss orconsider.
Role play games could also be consideredas a way of re-enforcing and encouraging groundrules.4 AAC personal data managementframeworkAs illustrated in Figure 2, personal data manage-ment within the AAC context is complex and anyresponse to a personal data management problemhas both technical, governance and cultural aspects.These responses have to be adaptive to differing lev-els of capabilities and different contextual require-ments.
Any technical response has to be scalable toenable users with different privacy and technical re-quirements to have access to their personal data con-trolled accordingly so that, where practical, users areable to have some control over their personal data.This scaleability can, in part, be addressed by the de-sign and implementation of the personal data man-agement framework.394.1 Extending the existing frameworkThe personal data management problems related toAAC use have links with work in the mainstreamprivacy and consent research communities.
Sec-tion 2 illustrates that AAC use adds additional lay-ers of complexity to privacy and consent issues and,as a result, adds additional requirements to any per-sonal data management framework.
Due to spaceconstraints the factors are merely highlighted to notethat each is a large piece of research in its own right.The required extensions fall into three areas:4.1.1 Technical capabilityTechnical capability, in addition to education, is afactor in assessing ability to manage privacy (Coles-Kemp et al, 2010; Kumaraguru and Cranor, 2005;Buchanan et al, 2007) because a relatively sophisti-cated level of technical capability is required to im-plement the privacy controls.
Technical capabilityand education levels are likely to be lower, on aver-age, in AAC users.4.1.2 Family rolesAAC users typically remain ?scaffolded?
by fam-ily and the family will therefore remain involved indecisions about personal data disclosure.
Whilst,family plays an important role at the start of an indi-vidual?s internet journey5, typically this interventionrecedes over time and the design of privacy controlsdoes not traditionally cater for varying levels of userindependence in decision making.
This needs to beaddressed by the management framework.4.1.3 Governance system designResponses to personal data management issuesuse a governance system composed of policy, reg-ulation, and practices to support the use of pri-vacy enhancing technologies.
Engagement withsuch a system is notoriously inconsistent because oflanguage and conceptual complexities (Kani-Zabihiand Coles-Kemp, 2010; Bogdanovic et al, 2009;Bonnici and Coles-Kemp, 2010; McDonald andCranor, 2008; McDonald and Cranor, 2009).
It isreasonable to assume that such a governance sys-tem would require specific modifications for the5UK online Centres (2010) ?Digital engagement un-derstanding customers?, a study (available for download atwww.ukonlinecentres.com/research/research/centres-research)AAC community to make policies more understand-able, to allow for adaptations in privacy and internetsafety education and to enable the role of family indecision support.
However, it should also be keptin mind that similar modifications could be madefor other communities with lower levels of digitalliteracy, literacy and cognitive challenges.
Whilstthe problems themselves are AAC-specific and theproblems are brought about, in part, by the directionof development of AAC technology, the governanceresponses respond to underlying problems found ina range of communities.5 ConclusionsAdvances in text-to-speech technology and mobilecomputing have made a range of AAC devices avail-able to the public.
Advances in natural languagegeneration and speech processing techniques haveco-incided with changes to the commercial land-scape to bring dramatic advances in AAC capabil-ities within reach.
These advances in AAC design,though overwhelmingly positive, do result in a fam-ily of personal data use problems that were not en-countered with previous generations of the devices.This paper argued that AAC devices can only signifi-cantly support users with communication difficultiesto achieve greater independence and social inclusionif their design and implementation both addressesand identifies personal data problems.AcknowledgmentsThe authors wish to thank the staff of the HWSTproject, the Natural Language Generation Groupat Aberdeen and the Sociotechnical Group, withinthe Information Security Group at Royal Holloway.The work was developed with input from legal ex-perts, youth work practitioners, and disability offi-cers: in particular Robert Carolina, Amanda Gerry,and Karen Wood are gratefully acknowledged.
Sim-ilarly, the insights of Nava Tintarev, Sarah Mof-fat, and Margaret Mitchell made this work pos-sible.
This paper was produced in collaborationwith the Visualisation and Other Methods of Ex-pression (VOME) project, which is supported bythe Technology Strategy Board; the Engineering andPhysical Sciences Research Council and the Eco-nomic and Social Research Council [grant numberEP/G00255X/1].40ReferencesY.
Allaire and M.E.
Firsirotu.
1984.
Theories of organi-zational culture.
Organization studies, 5(3):193.A.L.
Allen.
1988.
Uneasy access: Privacy for women ina free society.
Rowman & Littlefield Pub Inc.S.
Balandin, N. Berg, and A. Waller.
2006.
Assessingthe loneliness of older people with cerebral palsy.
Dis-ability & Rehabilitation, 28(8):469?479.D.
Barnard-Wills and D. Ashenden.
2010.
Public sectorengagement with online identity management.
Iden-tity in the Information Society, pages 1?18.DR Beukelman and P. Mirenda.
2005.
Augmentative andalternative communication: Supporting children andadults with complex communication needs3rd ed.
PaulH.
Brookes, Baltimore, MD.R.
Black, J. Reddington, E. Reiter, N. Tintarev, andA.
Waller.
2010.
Using NLG and sensors to supportpersonal narrative for children with complex commu-nication needs.
In Proceedings of the NAACL HLT2010 Workshop on Speech and Language Processingfor Assistive Technologies, pages 1?9, Los Angeles,California, June.
Association for Computational Lin-guistics.D.
Bogdanovic, C. Crawford, and L. Coles-Kemp.
2009.The need for enhanced privacy and consent dialogues.Information Security Technical Report, 14(3):167?172.C.J.
Bonnici and L. Coles-Kemp.
2010.
PrincipledElectronic Consent Management: A Preliminary Re-search Framework.
In 2010 International Conferenceon Emerging Security Technologies, pages 119?123.IEEE.T.
Buchanan, C. Paine, A.N.
Joinson, and U.D.
Reips.2007.
Development of measures of online privacyconcern and protection for use on the internet.
Jour-nal of the American Society for Information Scienceand Technology, 58(2):157?165.L.
Coles-Kemp and E. Kani-Zabihi.
2010.
On-line pri-vacy and consent: a dialogue, not a monologue.
InProceedings of the 2010 workshop on New securityparadigms, pages 95?106.
ACM.L.
Coles-Kemp, Y.L.
Lai, M. Ford, and C. Hyperion.2010.
Privacy on the Internet: Attitudes and Be-haviours.J.
Cornwell, I. Fette, G. Hsieh, M. Prabaker, J. Rao,K.
Tang, K. Vaniea, L. Bauer, L. Cranor, J. Hong,et al 2007.
User-controllable security and privacyfor pervasive computing.
In Mobile Computing Sys-tems and Applications, 2007.
HotMobile 2007.
EighthIEEE Workshop on, pages 14?19.
IEEE.F.
DeRuyter, D. McNaughton, K. Caves, D.N.
Bryen, andM.B.
Williams.
2007.
Enhancing AAC connectionswith the world.
Augmentative and Alternative Com-munication, 23(3):258?270.E.
Dominowska, D. Roy, and R. Patel.
2002.
An adaptivecontext-sensitive communication aid.
In Proceedingsof the 17th Annual International Conference Technol-ogy and Persons with Disabilities.P.
Golle, F. McSherry, and I. Mironov.
2008.
Data collec-tion with self-enforcing privacy.
ACM Transactions onInformation and System Security (TISSEC), 12(2):1?24.D.
J. Higginbotham, H.Shane, S. Russell, and K.Caves.2007.
Access to AAC: Present, past, and fu-ture.
Augmentative and Alternative Communication,23(3):243?257.M.A.
Kamp, P. Slotty, S. Sarikaya-Seiwert, H.J.
Steiger,and D. Hanggi.
Traumatic brain injuries in illustratedliterature: experience from a series of over 700 headinjuries in the asterix comic books.
Acta Neurochirur-gica, pages 1?5.E.
Kani-Zabihi and L. Coles-Kemp.
2010.
Service UsersRequirements for Tools to Support Effective On-linePrivacy and Consent Practices.
In Procedings of the15th Conference on Secure IT Systems, Nordic 2010.C.M.
Karat, C. Brodie, and J. Karat.
2006.
Usable pri-vacy and security for personal information manage-ment.
Communications of the ACM, 49(1):56?57.P.
Kumaraguru and L.F. Cranor.
2005.
Privacy indexes:A survey of westins studies.
Institute for Software Re-search International.G.W.
Lesher, G.J.
Rinkus, B.J.
Moulton, and D.J.
Higgin-botham.
2000.
Logging and analysis of augmentativecommunication.
In Proceedings of the RESNA AnnualConference.
Citeseer.A.M.
McDonald and L.F. Cranor.
2008.
The cost of read-ing privacy policies.
ACM Transactions on Computer-Human Interaction, 4(3):1?22.A.
McDonald and L. Cranor.
2009.
An empirical studyof how people perceive online behavioral advertising.S.J.
Milberg, H.J.
Smith, and S.J.
Burke.
2000.
Infor-mation privacy: Corporate management and nationalregulation.
Organization Science, pages 35?57.G.R.
Milne and M.E.
Gordon.
1993.
Direct mail privacy-efficiency trade-offs within an implied social contractframework.
Journal of Public Policy & Marketing,12(2):206?215.H.
Nissenbaum.
2009.
Privacy in context: Technology,policy, and the integrity of social life.
Stanford LawBooks.C.
Paine, U.D.
Reips, S. Stieger, A. Joinson, andT.
Buchanan.
2007.
Internet users?
perceptions ofprivacy concerns?
and privacy actions?.
InternationalJournal of Human-Computer Studies, 65(6):526?536.41R.
Patel and R. Radhakrishnan.
2007.
Enhancing Accessto Situational Vocabulary by Leveraging GeographicContext.
Assistive Technology Outcomes and Benefits,page 99.L.
Pennington, J. Marshall, and J. Goldbart.
2007.
De-scribing participants in AAC research and their com-municative environments: Guidelines for research andpractice.
Disability & Rehabilitation, 29(7):521?535.T.
Rackensperger, C. Krezman, D. Mcnaughton, M.B.Williams, and K. D?silva.
2005.
When I first got it,I wanted to throw it off a cliff: The challenges andbenefits of learning AAC technologies as described byadults who use AAC.
Augmentative and AlternativeCommunication, 21(3):165?186.J.
Reddington and N. Tintarev.
2011.
Automatically gen-erating stories from sensor data.
In Proceedings of the15th international conference on Intelligent user inter-faces, pages 407?410.
ACM.S.
Reilly, J. Douglas, and J. Oates.
2004.
Evidence-basedpractice in speech pathology.
Whurr, London.E.
Reiter, F. Portet A. Gatt, and M. van der Meulen.
2008.The importance of narrative and other lessons from anevaluation of an NLG system that summarises clinicaldata.
In International Natural Language GenerationConference (INLG), pages 147?156.E.
Reiter, R. Turner, N. Alm, R. Black, M. Dempster,and A. Waller.
2009.
Using NLG to help language-impaired users tell stories and participate in social di-alogues.
In European Workshop on Natural LanguageGeneration (ENLG-09).M.M.
Smith.
2005.
The dual challenges of aided com-munication and adolescence.
Augmentative and Alter-native Communication, 21(1):67?79.D.J.
Solove.
2008.
Understanding privacy.
Harvard uni-versity press.G.
Soto, E. Hartmann, and D. Wilkins.
2006.
Exploringthe elements of narrative that emerge in the interac-tions between an 8-year-old child who uses an AACdevice and her teacher.
Augmentative and AlternativeCommunication, 22(4):231?241.S.
Spiekermann and L.F. Cranor.
2009.
Engineering pri-vacy.
Software Engineering, IEEE Transactions on,35(1):67?82.J.
Todman, N. Alm, J. Higginbotham, and P. File.
2008.Whole utterance approaches in AAC.
Augmentativeand Alternative Communication, 24(3):235?254.A.F.
Westin.
1967.
Privacy and freedom, volume 97.London.E.A.
Whitley.
2009.
Informational privacy, consent andthe.
Information security technical report, 14(3):154?159.L.
Wittgenstein.
1956.
Philosophical investiga-tions.(trans.
GEM Anscombe) Basil Blackwell.42
