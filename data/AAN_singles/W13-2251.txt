Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 405?407,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsRanking Translations using Error Analysis and Quality EstimationMark FishelInstitute of Computational LinguisticsUniversity of Zurich, Switzerlandfishel@cl.uzh.chAbstractWe describe TerrorCat, a submission tothis year?s metrics shared task.
It is a ma-chine learning-based metric that is trainedon manual ranking data from WMT sharedtasks 2008?2012.
Input features aregenerated by applying automatic transla-tion error analysis to the translation hy-potheses and calculating the error cate-gory frequency differences.
We addition-ally experiment with adding quality es-timation features in addition to the er-ror analysis-based ones.
When evaluatedagainst WMT?2012 rankings, the system-level agreement is rather high for severallanguage pairs.1 IntroductionRecently a couple of methods of automatic analy-sis of translation errors have been described (Ze-man et al 2011; Popovic?
and Ney, 2011).
Both ofthese compare a hypothesis translation to a refer-ence and draw detailed conclusions from the dif-ferences between the two.TerrorCat, a metric submitted to the metricsshared task of WMT?2012 (Callison-Burch et al2012) used the output of those two error analysismethods as input features, which yielded mildlypromising results (Fishel et al 2012).
How-ever the submitted version of TerrorCat was lan-guage pair-specific, which means that the classifiermodel used by the metric has to be retrained onnew manual pairwise ranking data for every newlanguage pair.
This in turn complicates its usage.Our main aim in this work is to make Terror-Cat usable out-of-the-box.
We compare modelsspecific to the language pair (baseline), target lan-guage and a universal model for all languages.
Theupdated metric is applied to the WMT?13 metricsshared task.An additional modification to the metric usesinput features from quality estimation.
Using theresources of the quality estimation shared task ofWMT?13 the modified model is applied to theEnglish?Spanish language pair.We start by briefly re-introducing the TerrorCatmetric.2 BaselineThe baseline TerrorCat metric is a machinelearning-based metric: it uses manually rankedtranslation hypothesis pairs to train a classifiermodel.
The trained model is then used to predict aranking for new sentence pairs that have not beenranked yet.To convert the binary comparisons betweentranslation hypothesis pairs into a numeric scoreper translation hypothesis the wins per hypothe-sis are summed together.
Previous year?s workhas shown (Fishel et al 2012) that weightingthe wins with the classifier?s confidence for thesummed score improves agreement with humanjudgements.The input features for learning and classifica-tion are obtained by1.
applying translation error analysis softwareto the compared hypotheses,2.
getting the frequencies of every error type,i.e.
the ratio of words marked with that er-ror type to the hypothesis sentence length,3.
and using each error type?s frequency differ-ences between the two hypotheses as inputfeatures.Relative frequencies are used on both system andsegment level: i.e.
the ratios of words marked witha particular error type to the hypothesis translationlength.
This guarantees that feature values lie inthe [?1, 1] range.405Translation error analysis is done with twotools: Addicter (Zeman et al 2011) and Hjer-son (Popovic?
and Ney, 2011).
Both perform erroranalysis by comparing the hypothesis and refer-ence translations on word level and treating eachdifference as an error of one or the other kind.Translation error taxonomies as well as the wayword differences and their contexts are interpreteddiffer between the two tools.
In order to enableindependent input from both tools the feature vec-tors obtained from them both tools are concate-nated.To increase the level of detail the frequencies ofeach error category are counted separately for eachpart-of-speech separately.
As a result, e.g.
insteadof having the information of order errors having aparticular frequency, the classifier will separatelysee the frequencies of misplaced nouns, adjectives,particles, etc.3 ExperimentsThe usage of part-of-speech tags improves agree-ment with human judgements (Fishel et al 2012);however, it also introduces language dependencyfor the metric.
In the first set of experiments we tryto remove this imposed dependency without losingthe achieved benefit.3.1 Common SettingsWe focused on six language pairs: between En-glish and German, French and Spanish.
Manualranking data for training was taken from WMTshared task evaluations 2008?2011; data fromWMT?2012 was used as a development set to as-sess the performance of metric variations.Final models for the WMT?2013 shared taskwere re-trained on the whole set of manual rank-ings, from WMT 2008?2012.The classifier used by TerrorCat is an SVM witha linear kernel; more powerful kernels, such as ra-dial basis function-based ones scaled poorly to thehigh number of features and thus were not tested.PoS-tagging was done using TreeTagger(Schmid, 1995) with the pre-trained models forEnglish, German, French and Spanish.3.2 Language IndependenceIt is natural to expect error categories to havevarying importance on the quality comparison be-tween two translation candidates.
For instance,one might expect order differences between trans-lations into functional languages (e.g.
English,Chinese) to have a greater importance than in caseof languages with a more flexible word order (e.g.German, Russian); on the other hand inflection er-rors are likely to do more damage to the meaningin morphologically complex languages (e.g.
Rus-sian, Finnish) than in languages with simpler mor-phology (e.g.
English, French).
However, we wantto see whether we can train a classifier that wouldgeneralize over all language pairs.The main obstacle for training a general modelon all language pairs are the different taxonomiesof part-of-speech tags for different target lan-guages: the arity of the input feature vectors is dif-ferent for different target languages, which makesthe data incompatible between them.To overcome the difference we define a map-ping from every used taxonomy to a common gen-eral set of PoS-tags, which is supposed to coverany language.
It consists of general part-of-speechcategories (such as noun, verb, particle, etc., a to-tal of 15), without any morphological information(tense, case, person, etc.
).By using the same set of generalized PoS-tagsfor every language we ensure that the used Terror-Cat classifier model is language-independent; thePoS-tagging step is naturally language-dependentstill.Tables 1 and 2 present system-level andsegment-level correlations of TerrorCat based onthis common PoS-tag set and three models, spe-cific to the language pair, target language onlyand a general model for any language.
Both setsof results show that using a language-independentmodel neither improves nor worsens the perfor-mance.3.3 Quality Estimation for RankingTo further improve the agreement between Terror-Cat and human assessment we experimented withadding input features from quality estimation.The input features were adopted from this year?sshared task on quality estimation.
We selected thesmaller set of black-box features, which includedthe sentence lenghts, their language model proba-bilities, average numbers of translations per word,percentages of uni-, bi- and tri-grams in the dif-ferent frequency quartiles, etc.
All resources weretaken from the shared task, which also meant thatthis modified model was applied only to English?Spanish.406de-en en-de es-en en-es fr-en en-frLanguage pair-specific 0.94 0.56 0.94 0.59 0.85 0.82Target language-specific 0.92 0.56 0.97 0.59 0.84 0.82Language-independent 0.93 0.71 0.94 0.66 0.84 0.88BLEU 0.67 0.22 0.87 0.40 0.81 0.71METEOR 0.89 0.18 0.95 0.45 0.84 0.82TER 0.62 0.41 0.92 0.45 0.82 0.66Table 1: System-level correlation between TerrorCat and human ranking.
Correlations of BLEU, ME-TEOR and TER scores are given for comparison.de-en en-de es-en en-es fr-en en-frLanguage pair-specific 0.31 0.18 0.24 0.21 0.23 0.20Target language-specific 0.31 0.18 0.28 0.21 0.23 0.20Language-independent 0.28 0.20 0.27 0.22 0.24 0.21Table 2: Segment-level correlation between TerrorCat and human ranking.Training the model on quality estimation fea-tures alone yields a system-level score of 0.56.
Al-though this is lower than the TerrorCat baseline,it beats the correlations of BLEU, TER and ME-TEOR (see Table 1).
The segment-level correla-tion is -0.01.Next we combined features from error analysisand quality estimation by concatenating them intoa single input feature vector.
As a result system-level correlation improved to 0.72, which is higherthan all TerrorCat variants so far (best correlation:0.66).
Segment-level correlation remained practi-cally the same (0.22).4 ConclusionWe have applied TerrorCat to the shared metricstask of WMT?2013.
Just like last year, the resultsare mildly promising.We were successful at achieving language inde-pendence, provided that PoS-tagging is done be-fore applying the metric.The trained model as well as the metric imple-mentation with all the necessary scripts is avail-able online1.It remains to be tested, whether quality es-timation features fit well with the language-independent models.
As the extracted feature val-ues are based on completely different, language-specific resources, this does not seem to be a likelyoutcome.1https://github.com/fishel/TerrorCatReferencesChris Callison-Burch, Philipp Koehn, Christof Monz,Matt Post, Radu Soricut, and Lucia Specia.
2012.Findings of the 2012 workshop on statistical ma-chine translation.
In Proceedings of the SeventhWorkshop on Statistical Machine Translation, pages10?51, Montre?al, Canada.Mark Fishel, Rico Sennrich, Maja Popovic?, and Ondr?ejBojar.
2012.
Terrorcat: a translation errorcategorization-based mt quality metric.
In Proceed-ings of the Seventh Workshop on Statistical MachineTranslation, pages 64?70, Montre?al, Canada.Maja Popovic?
and Hermann Ney.
2011.
Towards au-tomatic error analysis of machine translation output.Computational Linguistics, 37(4):657?688.Helmut Schmid.
1995.
Improvements in part-of-speech tagging with an application to german.
InProceedings of the ACL SIGDAT-Workshop, Dublin,Ireland.Daniel Zeman, Mark Fishel, Jan Berka, and Ondr?ej Bo-jar.
2011.
Addicter: What is wrong with my trans-lations?
The Prague Bulletin of Mathematical Lin-guistics, 96:79?88.407
