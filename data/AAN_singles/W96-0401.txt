The Heal thDoc Sentence PlannerLeo WannerDepartment  of Computer  ScienceUniversity of WaterlooWaterlooOntario N2L 3G1Canadatel: +1-519-885-1211 ext.
5344fax: +1-519-885-1208email: lwanner@logos.uwaterloo.caEduard HovyInformation Sciences Inst i tuteUniversity of Southern California4676 Admiralty WayMarina del Rey, CA 90292-6695U.S.A.tel: +1-310-822-1511 ext.
731fax: +1-310-823-6714email: hovy@isi.eduAbstractThis paper describes the Sentence Planner (sP)in the HealthDoc project, which is concernedwith the production of customized patient-education material from a source encoded interms of plans.
The task of the sP is to trans-form selected, not necessarily consecutive, plans(which may vary in detail, from text plans spec-ifying only content and discourse organizationto fine-grained but incohesive, sentence plans)into completely specified specifications for thesurface generator.
The paper identifies the sen-tence planning tasks, which are highly interde-pendent and partially parallel, and argues, inaccordance with \[Nirenburg et al, 1989\], that'a blackboard architecture with several indepen-dent modules is most suitable to deal with them.The architecture is presented, and the interac-tion of the sentence planning modules withinthis architecture is shown.
The first implemen-tation of the sP is discussed; examples illustratethe planning process in action.1 Sentence  P lann ing1.1 In t roduct ionMost current models of text generation in-clude a phase of content selection and orga-nization, usually performed by a text planneror schema application engine, followed by aphase of grammatical surface-form rendering,performed by a sentence generator.In practice, it is usually found that the sen-tence generator requires more detailed linguis-tic information than text planners or schemaappliers can provide \[Meteer, 1991; Rambowand Korelsky, 1992; Hovy, 1992; Panaget, 1994;Wanner, 1994\].
So further planning is required.Following \[Rambow and Korelsky, 1992\], we callthis additional planning task sentence planning(even though some operations may cross sen-tence boundaries).
A sentence planner (sP)must specify one of the various possible alter-native phrasings at roughly the sentence andclause level.
By transforming and augmentingits input, the sentence planner produces repre-sentations detailed enough for the surface gen-erator to operate deterministically.
Consider anexample where the lack of sentence planning re-sults in an awkward text:(o) In some instances, an implantwears out, loosens, or fails.
I fan implant wears out, loosens, orfails, it will have to be removed.More appropriate alternatives can be gen-erated when different sentence planning tech-niques are used:(1) A l te rnat ive  reference:In some instances, an implantwears out, loosens, or fails.
Ifthis happens, it will have to beremoved.
(2) A l te rnat ive  lexical choice:In some instances, an implantwears out, loosens, or fails.I f  replacement is needed, it willhave to be removed.
(3) Remova l  of  redundancy(aggregat ion) :In some instances, an implantwears out, loosens, or fails,and \[\] will have to be removed.In this paper we describe the sentence plan-ner in the HealthDoc project.
HealthDoc \[Di-Marco et al, 1995\] was established in early1995 with the goal of generating customizedpatient-education documents.
It combines ex-isting generation technology--the s ntence gen-erator KPML \[Bateman, 1995\] 1 and its input no-tation sPL \[Kasper, 1989\]--and new systems,such as the sentence planner described here.The sentence planner embodies a design that wehope has some general applicability in bridgingthe gap between text planners and sentence gen-erators.
Its input is a specification of the desiredoutput content (a patient document) written inTezt Source Language (TSL), see Subsection 2.3;its output consists of one or more SPL expres-sions.
Its general operation is to recombine, n-hance, and refine TSL expressions until they areadequately specific SPL expressions.1.1 Sentence P lann ing  TasksAfter analysis of a number of patient-educationdocuments, including those on diabetes, choles-terol, and hormone replacement therapy, wehave identified the following most importantsentence planning tasks:?
F ine-gra ln discourse structuring: Dis-course relations (aST relations, for example)that conjoin clause-size pieces in the TSL arestill open to considerable variation of expres-sion, such as the inclusion of a discourse markeror the lexical or implicit communication f thediscourse relation.
See, for example, \[Scott andde Souza, 1990\] for treatment of ELABORATION,\[Vander Linden and Martin, 1995\] of PURPOSE,and \[Grote t al., 1995\] of CONCESSION.?
Sentence grouping and sentence contentdeterminat ion:  Individual sentences must bedelimited; temporal, spatial, and causal nuancesof predicates must be determined, and so on\[Meteer, 1991; Pustejovsky, 1995; Stede, 1996\].?
C lause- internal  s t ructur ing:  The orderof clause constituents, taxis, and projectivityof propositions within the clause \[Hovy, 1992;DiMarco and Hirst, 1993; Panaget, 1994\] mustbe determined; within each sentence, the the-matized and focused elements must be identi-fied \[Iordanskaja, 1992\]; redundancy must be re-moved \[Dalianis and Hovy, 1996a; Dalianis andHovy, 1996b\].?
Reference planning (endophor ic  lexical1KPML stands for Komet/Pcnman MultiLingual andis a development of the Penman system \[PenmanProject, 1989\].choice): The particular form of coreference (in-cluding anaphora, deixis, and ellipis) and refer-ence must be chosen in order to maintain dis-course cohesion \[McDonald, 1978; Tutin andKittredge, 1992; Dale and Reiter, 1995\].?
Exophoric lexical choice: As argued in\[Nirenburg et al, 1989; Meteer, 1991; Wan-ner, 1994\], lexical choice other than linguisticreference should also be considered a sentenceplanning task, since lexical units predetermihethe syntactic structure of a clause, and sincesalience may be realized by lexical means.2 The  Sentence  P lanner2.1 Constra ints  and Des iderataGiven the nature of the task (namely, the trans-formation and/or augmentation f partial sen-tence specifications into full ones), a set of con-straints emerge for the design of the SentencePlanner.
We believe these constraints to befairly general; that is, that sentence plannersdeveloped for applications other than Health-Doc will have much the same structure.
Theseconstraints are the following:1.
The sP must transform an underspecifiedinput of deep semantics into a suitably specifiedoutput of shallow semantics.2.
The sP must modularize sentence planningtasks as far as possible, to facilitate design clar-ity, development, and maintenance.
Since thesentence planning tasks listed above are notsingle-step operations, since they do not haveto be performed in strict sequence \[De Smedt,1990; Reithinger, 1992\], and since the planner'soperation is non-deterministic (early choicesmay undergo subsequent revision), this suggeststhat each sentence planning task should be im-plemented by a separate module or by severalmodules.3.
The intermediate steps of the sP shouldbe accessible and easily interpretable to peoplebuilding the sP, to enable cross-module inter-connection and debugging.4.
The sP must be extensible, allowing newmodules to be introduced as a need for themis identified.5.
The level of sophistication of the knowledgewithin a module must not be ccnstrained bythe sP architecture, so that the modules mightbe crude initially but then can incrementally berefined without impeding throughput.
To facili-tate this, the rules and knowledge resources em-ployed by the sP modules hould be representedas declaratively as possible.Constraints I and 3 suggest that the inter-mediate form(s) of the data during sP opera-tion be some sort of SPL-in-emergence; that is,a frame continually evolving from the more ab-stract input to the final SPL output(s).
Oneway to achieve this is to see sP modules as tree-transformation engines (viewing SPL and pre-SPL expressions as trees2).
This means thattheir effects must be written as tree-rewritingrules in the following general form (see Sec-tion 2.3):\[pre~sPil ~ pre-sPi2\]Naturally, each module must know whichtree transformation rule to apply to any givenpre-sPI, under any given conditions.
A suit-able mechanism is provided by system networks,used just as in KPML'S grammar \[Matthiessenand Bateman, 1991\].
Each module contains afeature (system) network that discriminates ar-bitrarily finely to a desired state.
At any pointin the network, the selection of a feature with anassociated tree-rewriting rule causes applicationof that rule to the current pre-sP5.
Thus tree-rewriting rules are realization statements in thesP modules (several other realization operatorsare also supported).Constraints 2, 4, and 5 suggest hat the sP?
employ a blackboard architecture.
As has al-ready been argued by \[Nirenburg et hi., 1989\],a blackboard is best suited to accommodate heflexible order in which modules can take action.It also supports the addition of new moduleswithout requiring the revision of the interfacesof existing modules.2.2 Sentence Planner ArchitectureThe architecture of the HealthDoc sentenceplanner is shown in Figure I.
Solid arrows indi-cate data flow; dashed arrows indicate controlflow.
The components are:1.
A set of modules: Discourse Structuring,Content Delimitation, Sentence Structuring,Aggregation, Exophoric Lexical Choice, and2Strictly speaking, SPL expressions and their originsare directed acyclic graphs, not trees; this does not affectthe design in any way.Knowledge SourcesPaficm data Isp~=So~o= k .__Lt__, /I II Exopbonc LC II EndophoncLC IFigure 1: The Architecture of the SentencePlanner in HealthDoc.Endophoric Lexical Choice.
32.
Knowledge sources: the lexicon (essen-tially KPML's lexicon extended by colloca-tional \[Wanner and Bateman, 1990\] and qualia\[Pustejovsky, 1995\] information), the seman-tic and lexicogrammatical resources as dis-cussed in \[Wanner, 1994\], the Penman UpperModel \[Bateman, 1990\], the HealthDoc DomainModel, and the Reader Model of the patient.Not shown in Figure I is the history of choicesmade in the course of processing.3.
The blackboards: the main blackboard,which contains the latest pre-SPL expression(s)and their derivation history, and the controlblackboard, which contains bookkeeping infor-mation such as the flags that signal the status(running/idle/etc.)
of each module.4.
The Administrator: the top-level process thatinvokes modules, updates pre-sPL expressions,manages parallel alternative xpressions, etc.5.
The Tree Transformer: the engine thatmatches the left-hand sides of tree transfor-aWe also foresee an Ordering module.mation rules to pre-SPL expressions and, whenthey match, unifies all variables and replacesthe matched tree fragments with the right-handsides of the rules.6.
The Network Traverser: a process that tra-verses the system network of each module,handles the choice criteria functions (typically,these criteria pertain either to the input pre-SPLor to one of the knowledge resources), and uponreaching tree transformation rules, hands themoff to the Tree Transformer.2.3 The  P lann ing  ProcessThe sentence planning process transforms an in-put TSL expression(s) into one or more SPL ex-pressions.Input and output notation.
TSL is cur-rently under development.
When fully devel-oped, its degree of detail will be variable fromone-to-one quivalent with SPL, to an abstractform that contains only the deep semantic framefor a predication (thereby being a notation inwhich, for example, commit suicide has sui-cide as head, rather than commit).
The flex-ible degree of detail of the TSL will allow ei-ther more semantic or more surface-orientedsentence planning.For illustration, compare the following twoTSLS of varying degrees of abstraction for sen-tences (1) to (3) above:A more  abst ract  TSL express ion:((D1 / disjunction:domain (W / wearout:undergoer (I1 / implant)):range (D2 / disjunction:domain (L / loosen:undergoer I1):range (F / fail:undergoer I1)):circumstance (O / occasional))(C1 / condition:domain (R / remove:patient I1:mode necessity):range D1))Note that coreference information is here en-coded by using the same variables.A more  specif ic TSL express ion:((D1 / disjunction:domain (W / wearout:actor (I1 / implant:number singular):tense present):range (D2 / disjunction:domain (L:range (F /:nonorienting-action (I2 /:theme I2)(C1 / condition:domain (It / remove:actee I1:modality must):range D1))loosen:actor I1:tense present)fail:actor I1:tense present))three-d-location:lex instance:number plural:determiner some)In the more specific TSL expression, the deepsemantic roles have been replaced by surfacesemantic roles (:actor, :actee), and syntac-tic information (tense) and textual information(theme) have been added.
To see the differencebetween the TSL and SPL, consider the $PL ex-pression for the first sentence in (0)-(3):SPL output  express ion:(D1 / disjunction:domain (W / nondirected-action:lex wear-out:tense present:actor (I1 / object:lex implant:number plural)):range (D2 / disjunction:domain (L / nondirected-act.
:lex loosen:tense present:actor I1):range (F / nondirected-act.
:lex fail:tense present:actor I1)):nonorienting-action (I2 / three-d-location:lex instance:number plural:determiner some))Overall planning process.
The planningprocess starts with the Administrator, whichplaces a pre-sPL fragment onto the blackboard4and activates a module.Linguistically, it is not possible to prespecifya fixed sequence in which the modules shouldapply \[De Smedt, 1990; Nirenburg et al, 1989\].In some cases, mutual dependencies exist be-tween different linguistic phenomena (i.e., alsoplanning tasks) that cause race conditions ordeadlock.
We briefly discuss conflict resolutionstrategies in Section 4.
In general, though, wedefine a (partial) default sequence for the mod-ules: the Discourse Structuring and SentenceStructuring modules run first, and in parallel.
4They are followed by the Content Delimitationmodule, and finally by the Exophoric and En-dophoric Choice modules, also in parallel.
Thisis in accordance with the increasing delicacy ofphenomena the modules deal with.
However,we will also experiment with other sequences.A user-specifiable Agenda that determines theordering of module application has been imple-mented.Upon activation, a module removes a pre-SPL from the blackboard, refines and enriches it,and replaces it on the blackboard.
The outputsof parallel modules are unified and the unifiedpre-SPL expression becomes the working copy.The output of non-parallel modules become theworking copy immediately.
After all moduleshave run, the constructed sPL on the blackboardis passed to KPML for realization.In our current implementation, all modulesexcept Discourse Structuring are defined uni-formly using system networks.
5 This allows usto adopt an already developed and well-knownrepresentation, and the machinery that pro-cesses the information encoded in terms of thisrepresentation.
For example, in \[Panaget, 1994;Wanner, 1994\], this machinery has been ap-plied to construct an SPL expression from a 'textplan'.
Unlike this work, which builds up SPL ex-pressions anew using the text plan as a sourceof information to guide processing, our sP trans-forms the text plan itself into the SPL.
We be-lieve that such a transformation is more trans-parent to the sP builders, enabling them to in-spect and manipulate directly the pre-sPL ex-4 "In parallel" here means in arbitrary order.SHowever, each module is an independent black box.This enables eparate and parM.lel developraent of eachmodule using any formalism.pressions formed during the planning process.The types of planning operations required re-main the same in both cases.To implement ransformation rules in theframework of system networks, we define threenew realization operators: REWRITE, ADD, andSUPPLANT.
Each operator has a different ef-fect on the fragment(s) of pre-SPL that matchits left hand side: RBWRIT~ alters its content orstructure, ADD adds new information but altersnothing, and SUPPLANT replaces the matchedportion with something else (see \[Jakeway etal., 1996\]).
The transformation rules invoke theTree Transformer when the features they are as-sociated with are chosen.
The Tree Transformerthen applies the rules to the current pre-SPL ex-pression.Four general types of transformation are gen-erally required during sentence planning (sym-bols preceded by ?
are wildcards and match anyvariable or symbol in the pre-SPL):1.
Augment a pre-SPL expression:(ADD ((?X / CAUSS) -+ (:dmarker causation)))in which any fragment of the current pre-SPLcontaining as head the deep semantic typeCAUSE is augmented by the addition of the role:dmarker with the filler causation (i.e., a cueword signaling causation in the surface form).2.
Modify a pre-sPL expression:(R~WRITB ((?X / RST-RELATm~) ~ (7~ / RST-CAUSE)))in which the head of a pre-SPL fragment ischanged from RST-RELATION to RST-CAUSE.3.
Remove a portion of a pre-SPL expression:(SUPPLANT ((?X / CAUSE:rolel y:function (:rolel agent))(?x / CAUSE:actor y)))in which the intermediate roles :role1 and :func-tion are removed as soon as the process type(and, therefore, also the name of the agent role)are determined, and replaced by appropriate in-formation.4.
Move a portion of a pre-SPL expression:(SUPPLANT ((?X / PROCESS:situation y) -+(?x / y)))in which the intermediate role :situation is re-moved Pnd its filler moved to occupy the head ofthe fragment rooted at '?x'.
(This occurs whenit has been decided that the predicate 'y'e.g., MOVE--is to be expressed as the verb \[to\]move, rather than as the support verb construc-tion make a move; now MOVE must be promotedto be the head of ?x in the emerging SPL).
Notethat 'remove a fragment' always implies 'movea fragment'.2.4 In ter -Modu le  Conf l ict  Reso lu t ionIf a module is activated but is not able to makeall the decisions it needs to, or if it makes deci-sions that are known to be possibly incompati-ble with those made by other modules later on,there are in general three options for how toproceed:1.
The module must suspend operation until allinformation required is available.2.
The module must make decisions omewhatblindly and allow backtracking when a decisionturns out later to be incompatible.3.
The module must not make the decision butproduce all alternatives in parallel, to be win-nowed out by later processing.We do not discuss the first two options sincethey are standard AI search techniques.
Thethird option is inspired by the treatment ofalternatives in statistics-based NLP and theway alternative options are handled in MTM\[Mel'~uk, 1981\].
In this option, we allow a mod-ule to replace an input with multiple alterna-tive outputs instead of only one when it cannotmake a choice.
All such alternative pre-SPLs arespawned and propagated onto the blackboard,so that other modules can work on them all, asparallel alternatives.
Should one of the alter-natives later turn out to be incompatible withsome module's decision, that alternative simply'dies' and is removed from the blackboard.
If,on the other hand, all alternatives remain viableto the end, then the sP has produced more thanone valid locution from the input.
This optionis only feasible if the networks of the modulesare not very detailed, i.e., do not lead to anexcessive number of alternatives.
Although wewill experiment with all three modes, our pri-mary intention is to employ mode 1; currently,for implementational reasons, we use mode 2in its simplest instantiation: when the changesmade by a module turn out to be incompatiblewith those of other modules, the module startsagain.3 The  Modu lesThis section describes the functionality of eachmodule.
As an example, we show the creationof the SPL expressions for the sentences (1) to(3).
Lack of space prevents us from discussingthe criteria and heuristics that are responsiblefor the individual choices.3.1 D iscourse  S t ructur ing  Modu leThe Discourse Structuring module decides uponthe way a discourse relation is communicated.So far, three major distinctions are made:1.
Marker /no -marker :  For example, theCONDITION relation can be marked by if, incase, etc.2.
Exp l i c i t / imp l i c i t :  CONDITION can be com-municated explicitly by discourse means and/orlexical means (such as the verb necessitate), orimplicitly, obtainable via inference.3.
Nuc leus /sate l l i te  sal ience: In the case ofCONDITION, salience can be shifted by change ofthe order of the condition and effect arguments.The pre-SPL expression created by the Dis-course Structuring module reflects the choicesmade regarding sentences 1 to 3 above in thetype and number of roles to introduce, the rolefiller information, etc.
The following fragmentshows the result of the discourse structuringmodule for the sample sentences:(D1(C1 / condition:domain (It / remove:actee I1:modality must):range D1):dmarker condition:range-ordering first))The fragment D1 is not changed.
For fragmentC1, the use of a discourse marker has been de-termined.
Also, due to the salience of the condi-tion part of the utterance, the ':range' role willbe expressed first.3.2 Sentence  St ructur ing  Modu leThe Sentence Structuring module determinesthe structure of the sentences to be encoded inthe SPL.
This includes:1.
Sentence boundaries: If two separate sen-tences are to be produced, the SPL is split intoone per sentence and built up sequentially.2.
Global sentence structure: A sentencecan be a hypotactic clause complex, a parat-actic clause complex, or a simple clause.
To de-termine this, the Sentence Structuring moduleevaluates whether the predications in the pre-SPL are to be communicated as a sequence oras a composite, complex event.
A sequence ofevents can further be emphasized by a marker.In our example, the SPL  under constructionundergoes the following changes:((D1 / disjunction:domain W:range (D2 / disjunction:domain L:range F:dmarker disjunction):dmarker -:nonorienting I2:theme I2)c1)It has been determined that the first sPL willcontain a paratactic clause complex and thatthere will be a disjunction marker between theL and F fragments.
Since a CONDITION thatis represented by the roles :domain and :rangeis expressed in KPML as a hypotactic clausecomplex, fragment C1 remains unchanged (notethat the aggregation module still has not run tomake the changes for (3)).3.3 Content  De l imi ta t ion  Modu leThe Content Delimitation module determinesthe material to be included into each separateSPL expression.
At the present stage, this in-cludes the following:1.
Const i tuents  of  a p red icat ion :  Con-stituents that are to be encoded in the pre-SPL.Depending on the contextual and linguistic con-straints, roles that are listed in the input mightbe suppressed and additional ones might be in-troduced.2.
Causal~ temporal~ aspectual nuances:Nuances of the predication that are to be en-coded in the pre-sPL.The Content Delimitation module primar-ily introduces realization statements into thepre-sPL expression that constrain the exophoricchoice module.In our example, which starts from a relativelyspecific TSL, the content delimitation moduledoes not make visible changes: all roles presentin the pre-SPL are determined to be realized.Starting from the abstract TSL, intermediateroles :situation would have been introduced inthe fragments labeled by the variables W,  L, F,and R. This syntactically neutral role :situationenables the Exophoric Choice module to gener-ate different internal clause structures.3.4 Aggregation Modu leThe Aggregation module eliminates redundancyin the pre-sPL by grouping entities that are ar-guments of the same relation, process, etc., to-gether.
The actions of the Aggregation moduleaffect, as a rule, the resulting syntactic struc-ture.
In our example, redundancy is apparentin pre-SPL fragments W,  L, and F, since theironly internal difference is their type, as well asthe repetition of the whole D1 in fragment CI.The actions of the Aggregation module resultin the following changes within pre-SPL C1 forsentence (3):(C / conjuntion:domain (It / remove:actee I1:lex zeroellipsis:modality must):range D1:range-ordering first)3.5 Exophor ic  Lex ica l  Cho ice  Modu leThe Exophoric Lexical Choice module chooseslexical units for those entities specified in thepre-SPL that are new in the discourse.
Moreprecisely, it makes the pre-SPL more concretealong three lines:1.
Lex ica l i za t ion  of  d i scourse  s t ruc turere lat ions:  Discourse relations (and their cuewords) may be realizable by lexical means.
Inour example, the CONDITION marker in (1), (2)is lexicalized as if; the DISJUNCTION marker asor, and the CONJUNCTION marker as and.2.
In terna l  c lause s t ruc tur ing :  The inter-nal clause structure is predetermined by, amongother means, the valency schema of the lexicalunit that is chosen to serve as a head of a clauseor phrase.
With the choice of a head lexicalunit, the salience of the arguments i also pre-determined (see, e.g., \[Wanner and Bateman,1990\]).
One of the choices the exophoric lexi-cal choice module makes while generating (2),is the replacement of the fragment D1 in theCONDITION part by I f  replacement is needed.This choice can be made because the KB con-tains the process of replacement as a possibleconsequence of an implant being worn out, loos-ened, or having failed.
It is not motivated by thepresence of the coreference link in the TSL.
Thepre-SPL reflects this choice as follows:(D1(C1 / condition:domain (It / remove:actee I1:modality must):range (N / need:actee (ItE / replacement)):dmarker condition:range-ordering first))3.
Lex ica l lzat ion o f  the  ent i t ies:  this istraditionally considered to be the task of thelexical choice process.
We do not discuss thisissue here.3.6 Endophor ic  Lexical  Cho ice  Modu leThe Endophoric Lexical choice module chooseslexical units for entities that have already beenintroduced in the discourse ither verbatim orby related entities.
If an entity has been intro-duced verbatim, its next mention can be real-ized as a personal pronoun, generalized name,definite name, deictic pronoun, or ellipsis.
If arelated entity has been introduced, the new lexi-cal unit depends on the relation between the twoentities; compare \[Tutin and Kittredge, 1992\].In our example, if the Exophoric moduleruns first, the Endophoric module ends up onlypronominalizing implant in the last clause.
Ifinstead the Endophoric module runs first, theSPL produced is (1) rather than (2), i.e., theEndophoric Choice module chooses the phrasethis happens to refer to an implant wears out,loosens, or fails.
If we assume this variant, thepre-SPL expression for the second sentence ischanged to:(C1 / condition:domain (It / remove:actee I1:modality must):range (H / happen:actor (I1 / implant:lex this)):dmarker condition:range-ordering first)4 Re la ted  ResearchRelated work falls into two areas.
The first issentence planning as a task, including the orga-nization of the planning process.
The secondcovers specific subtasks of sentence planning.Since we have already provided extensive refer-ences to work in the second area, and our focusin this paper is not on the detailed presentationof these subtasks, we refrain from discussing itfurther.In the first area, our sP appears, at firstglance, to closely resemble DIOCENES \[Niren-burg et al, 1989\]: both systems contain a black-board with different sentence planning tasksperformed by separate modules.
However, sig-nificant differences exist with respect to pro-cessing strategies, including blackboard man-agement and conflict resolution; the assignmentof different subtasks to modules; the organiza-tion of the modules; and the organization ofknowledge resources.
This issue is discussed in\[Jakeway et al, 1996\].In other related work \[Appelt, 1985; Meteer,1991; Horacek, 1992\], several sentence plan-ning tasks are treated within the process oftext planning.
\[Rambow and Korelsky, 1992;Panaget, 1994\] have a separate sentence plan-ning component, but they do not separate thespecific subtasks of sentence planning into dis-tinct submodules.
Necessarily, some subtasks,such as content delimitation, exophoric, and en-dophoric hoice, then play a less prominent role.5 Conc lus ionIndividual sentence planning tasks have beenthe focus of much previous research.
A fewsentence planners have combined some of thesetasks in a single engine.
With the HealthDocsentence planner, we are attempting to build anarchitecture that supports both the addition ofnew sentence planning tasks, in the form of newmodules, as well as continued growth in sophis-tication and coverage of individual task perfor-mance.
This is an ambitious goal.
We believethat a blackboard architecture with separatemodules, a situation discr:.mination mechanismsuch as feature networks, and a continuouslytransformable internal representation, from TSLinput to SPL output using tree transformationoperators, to be a promising avenue of research,given the complexity of the problems facing textgenerators.AcknowledgmentsWe would like to thank Bruce Jakeway for im-plementations a well as the other members ofthe Sentence Planning Group, Chrysanne Di-Marco, Phil Edmonds, and Daniel Marcu, formany fruitful discussions.
Special thanks toJohn Wilkinson, who was one of the "Key Sen-tence Planners" during the first phase of ourwork.Re ferences\[Appelt, 1985\] D.E.
Appelt.
Planning naturallanguage utterances.
Cambridge UniversityPress, Cambridge, England, 1985.\[Bateman, 1990\] J.A.
Bateman.
Upper Model-ing: Organizing Knowledge for Natural Lan-guage Processing.
In 5th International Work-shop on Natural Language Generation, Pitts-burgh, PA., 1990.\[Bateman, 1995\] J. Bateman.
KPML:KOMET-Penman Multilingual Linguistic Re-source Development Environment.
In Pro-ceedings of the 5th European Workshop onNatural Language Generation, Leiden, 1995.\[Dale and Reiter, 1995\] R. Dale and E. Reiter.Computational Interpretation of the GriceanMaxims in the Generation of Referring Ex-pressions.
Cognitive Science, 19(2):233-263,1995.\[Dalianis and Hovy, 1996a\]H. Dalianis and E.H. Hovy.
Aggregation iNatural Language Generation.
In G. Adorniand M. Zock, editors, Trends in natural lan-guage generation: An Artificial Intelligenceperspective.
Springer Verlag, Berlin & Heidel-berg, 1996.\[Dalianis and Hovy, 1996b\]H. Dalianis and E.H. Hovy.
On Lexical Ag-gregation and Ordering.
In Proceedings of the8th International Workshop on Natural Lan-guage Generation.
Herstmonceux, 1996.\[De Smedt, 1990\] K. De Smedt.
IPF: An Incre-mental Parallel Formulator.
In Robert Dale,Christopher S. Mellish, and M. Zock, editors,Current research in natural language genera-tion.
Academic Press, 1990.\[DiMarco and Hirst, 1993\] C. DiMarco andG.
Hirst.
A Computational Theory of Goal-Directed Style in Syntax.
Computational Lin-guistics, 19(3):451-499, 1993.\[DiMarco et al, 1995\] C. DiMarco, G. Hirst,L.
Wanner, and J. Wilkinson.
Healthdoc:Customizing patient information and healtheducation by medical condition and personalcharacteristics.
In Proceedings of the Work-shop on Patient Education, Glasgow, 1995.\[Grote t al., 1995\] B. Grote, N. Lenke, andM.
Stede.
Ma(r)king Concessions in Englishand German.
In Proceedings of the 5th Euro-pean Workshop on Natural Language Gener-ation, Leiden, 1995.\[Horacek, 1992\] H. Horacek.
An IntegratedView of Text Planning.
In Proceedings ofthe 6th International Workshop on NaturalLanguage Generation, Trento, Italy, 1992.Springer-Verlag.\[Hovy, 1992\] E.H. Hovy.
Sentence Planning Re-quirements for fautomated Explanation gen-eration.
In Proceedings of the Workshopon Explanation Facilities for Model-BasedExpert Systems, DIAMOD-Bericht no.
23,Sankt Augustin, Germany, 1992.\[Iordanskaja, 1992\] L. Iordanskaja.
Commu-nicative Structure and its Use during TextGeneration.
International Forum on In-formation and Documentation, 17(2):15-27,1992.\[Jakeway et al, 1996\] B. Jakeway, E. Hovy,and L. Wanner.
Specification of the Health-Doc sentence planner.
Internal Note, CSDepartment, University of Waterloo andUSC/ISI, Waterloo and Marina del Rey,1996.\[Kasper, 1989\] R. Kasper.
SPL: A sentenceplan language for text generation.
Technicalreport, Information Sciences Institute, Uni-versity of Southern California, 1989.\[Matthiessen a d Bateman, 1991\] C.M.I.M.Matthiessen and J.A.
Bateman.
Text gener-ation and systemic-functional linguistics: ex-periences .from English and Japanese.
FrancesPinter Publishers and St. Martin's Press,London and New York, 1991.\[McDonald, 1978\] D. D. McDonald.
Subse-quent References: Syntactic and RhetoricalConstraints.
In Theoretical Issues in NaturalLanguage Processing--2 (TINLAP).
ACM,New York, 1978.\[Mel'Suk, 1981\] Igor Mel'Suk.
Meaning-textModels: a Recent Trend in Soviet Linguis-tics.
Annual Review of Anthropology, 10:27-62, 1981.\[Meteer, 1991\] M.W.
Meteer.
Bridging theGeneration Gap Between Text Planning andLinguistic Realization.
Computational Intel-ligence, 7(4):296- 304, 1991.\[Nirenburg et al, 1989\]S. Nirenburg, V. Lesser, and E. Nyberg.
Con-trolling a Language Generation Planner.
InProceedings of the Joint Conference on Arti-ficial Intelligence, pages 1524-1530, Detroit,1989.\[Panaget, 1994\] F. Panaget.
Using a TextualRepresentation Level Component in the Con-text of Discourse or Dialogue Generation.
InProceedings of the 7th International Work-shop on Natural Language Generation, Ken-nebunkport, 1994.\[Penman Project, 1989\] Penman Project.
PEN-MAN documentation: the Primer, the UserGuide, the Reference Manual, and the Nigelmanual.
Technical report, USC/InformationSciences Institute, Marina del Rey, Califor-nia, 1989.\[Pustejovsky, 1995\] J. Pustejovsky.
The Gener-ative Lexicon.
MIT Press, Cambridge, 1995.\[Rambow and Korelsky, 1992\] O. Rambow andT.
Korelsky.
Applied Text Generation.
In Ap-plied Conference on Natural Language Pro-cessing, Trento, Italy, 1992.\[Reithinger, 1992\] Norbert Reithinger.Eine parallele Architektur zur inkrementellenGenerierung multimodaler DialogbeitrEge.
In-fix Verlag, St. Augustin, 1992.\[Scott and de Souza, 1990\] D. Scott and C. S.de Souza.
Getting the Message Across in RSW-Based Generation.
In R. Dale, C. Mellish,and M. Zock, editors, Current Research inNatural Language Generation, pages 47-73.Academic Press, London, 1990.\[Stede, 1996\] M. Stede.
A generative perspec-tive on verbs and their readings.
In Pro-ceedings of the 8th International Workshopon Natural Language Generation, Herstmon-ceux, 1996.\[Tutin and Kittredge, 1992\]A. Tutin and R. Kittredge.
Lexical Choicein Context: Generating Procedural Texts.
InProceedings of COLING 92, pages 763-769,1992.\[Vander Linden and Martin, 1995\]K. Vander Linden and J.H.
Martin.
Express-ing rhetorical relations in instructional text:A case study of the purpose relation.
Com-putational Linguistics, 21(1):29-57, 1995.\[Wanner and Bateman, 1990\] L. Wanner andJ.A.
Bateman.
A Collocational Based Ap-proach to Salience-Sensitive L xical Selec-tion.
In 5th Natural Language GenerationWorkshop, Pittsburgh, PA., 1990.\[Wanner, 1994\] L. Wanner.
Building AnotherBridge over the Generation Gap.
In Pro-ceedings of the 7th International Workshopon Natural Language Generation, Kenneb-unkport, 1994.10
