Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 193?200,Prague, June 2007. c?2007 Association for Computational LinguisticsNatural Logic for Textual InferenceBill MacCartneyStanford Universitywcmac@cs.stanford.eduChristopher D. ManningStanford Universitymanning@cs.stanford.eduAbstractThis paper presents the first use of a com-putational model of natural logic?a sys-tem of logical inference which operatesover natural language?for textual infer-ence.
Most current approaches to the PAS-CAL RTE textual inference task achieve ro-bustness by sacrificing semantic precision;while broadly effective, they are easily con-founded by ubiquitous inferences involvingmonotonicity.
At the other extreme, systemswhich rely on first-order logic and theoremproving are precise, but excessively brittle.This work aims at a middle way.
Our systemfinds a low-cost edit sequence which trans-forms the premise into the hypothesis; learnsto classify entailment relations across atomicedits; and composes atomic entailments intoa top-level entailment judgment.
We pro-vide the first reported results for any systemon the FraCaS test suite.
We also evaluateon RTE3 data, and show that hybridizing anexisting RTE system with our natural logicsystem yields significant performance gains.1 IntroductionThe last five years have seen a surge of interest inthe problem of textual inference, that is, automat-ically determining whether a natural-language hy-pothesis can be inferred from a given premise.
Abroad spectrum of approaches have been explored,ranging from shallow-but-robust to deep-but-brittle.Up to now, the most successful approaches haveused fairly impoverished semantic representations,relying on measures of lexical or semantic overlap(Jijkoun and de Rijke, 2005), pattern-based relationextraction (Romano et al, 2006), or approximatematching of predicate-argument structure (Hickl etal., 2006).
Such methods, while robust and broadlyeffective, are imprecise, and are easily confoundedby ubiquituous inferences involving monotonicity,particularly in negative polarity contexts, as in:P: No case of indigenously acquired rabiesinfection has been confirmed in the past 2 years.H: No rabies cases have been confirmed.Because it drops important qualifiers in a negativecontext, the hypothesis does not follow; yet both thelexical content and the predicate-argument structureof the hypothesis closely match the premise.At the other extreme, textual inference can be ap-proached as deduction, building on work in formalcomputational semantics to translate sentences intofirst-order logic (FOL), and then applying a theo-rem prover or a model builder (Akhmatova, 2005;Fowler et al, 2005).
However, such approachestend to founder on the difficulty of accurately trans-lating natural language in FOL?tricky issues in-clude idioms, intensionality and propositional at-titudes, modalities, temporal and causal relations,certain quantifiers, and so on.
FOL-based systemsthat have attained high precision (Bos and Markert,2006) have done so at the cost of very poor recall.In this work, we explore a different point on thespectrum, by developing a computational model ofnatural logic, that is, a logic whose vehicle of in-ference is natural language.1 Natural logic eschewslogical notation and model theory.
Its proofs pro-ceed by incremental edits to expressions of naturallanguage, and its inference rules specify conditionsunder which semantic expansions or contractionspreserve truth.
It thus permits us to do precise rea-soning about monotonicity, while sidestepping thedifficulties of translating sentences into FOL.It should be emphasized that there are many1Natural logic should not be confused with natural deduc-tion, a proof system for first-order logic.193important kinds of inference which are not ad-dressed by a natural logic system, including tem-poral reasoning, causal reasoning (Khan sold nu-clear plans ?
Khan possessed nuclear plans), para-phrase (McEwan flew to Rome ?
McEwan took aflight to Rome), relation extraction (Bill Gates andhis wife, Melinda... ?
Melinda Gates is marriedto Bill Gates), etc.
Moreover, a natural logic sys-tem will struggle with inferences requiring model-building or deep proof search, which are more suit-able for formal deduction systems.
However, the ap-plicability of natural logic is broader than it might atfirst appear, and a natural logic system can be de-signed to integrate with other kinds of reasoners.2 Foundations of natural logicNatural logic aims to explain inferences involvingmonotonicity, in which the concepts or constraintsexpressed are expanded or contracted.
Consider, forexample, the sentence Every meal without wine is aterrible crime.
Some semantic elements can be ex-panded (but not contracted) salva veritate, and aretherefore said to have positive polarity: wine may bebroadened to drink, terrible crime may be relaxed tocrime, or every may be weakened to some.
Other el-ements can only be contracted (not expanded) salvaveritate, and thus have negative polarity: meal canbe narrowed to dinner.
The monotonicity calcu-lus developed in (Sa?nchez Valencia, 1991) explainsthese polarity effects by (1) defining an entailmentrelation over multifarious expressions of natural lan-guage, (2) defining monotonicity properties of se-mantic functions, and finally (3) specifying howmonotonicities combine during Fregean composi-tion of semantic functions.The entailment relation.
Most work in textualinference reflects a simple concept of entailment:one sentence entails another, or does not.
In nat-ural logic, however, entailment is a semantic con-tainment relation (analogous to the set containmentrelation ?)
over expressions of all types, includingwords and phrases as well as sentences.
We definethe entailment relation v recursively over the se-mantic types familiar from Montague semantics.
Ifc and d are of type t (truth values), then c v d iffc ?
d. If c and d are of type e (entities), then c v diff c = d. Finally, if c and d are of functional type?
?, ?
?, then c v d iff for all a ?
?, c(a) v d(a).Otherwise, if c 6v d and d 6v c, we write c # d.Using these formal definitions, we can establishentailment relations between common nouns (pen-guin v bird), common and proper adjectives (tiny vsmall, French v European), transitive and intransi-tive verbs (kick v strike, hover v fly), temporal andlocative modifiers (this morning v today, in Beijingv in China), connectives (and v or), and quanti-fiers (everyone v someone, all v most v some).2Among noun phrases, we have everyone v Einsteinv some physicist.
Finally, observe that dropping amodifier generally yields entailment (eat quickly veat) though this heuristic can be violated, e.g., byoperator adjectives (fake vaccine 6v vaccine).Monotonicity.
Under the Fregean hypothesis, themeaning of a compound expression is the result offunction application.
In semantics as in mathemat-ics, we can describe a function as upward mono-tone if ?larger?
inputs yield larger outputs.
Formally,given a function f of functional type ?
?, ??:?
f is upward-monotone (?)
iff for all x, y ?
?,x v y entails f(x) v f(y).?
f is downward-monotone (?)
iff for all x, y ?
?, x v y entails f(y) v f(x).?
f is non-monotone ( 6??)
iff it is neither upward-nor downward-monotone.Most linguistic expressions may be regarded asupward-monotone semantic functions.
Thus tangoin Paris v dance in France, since tango vdance and in Paris v in France.
However, anumber of important linguistic constructions aredownward-monotone, including negation (not), re-strictive quantifiers (no, few, at most n), restrictiveverbs (lack, fail, prohibit), certain adverbs (without,except), the antecedent of a conditional, and so on.We thus have didn?t dance v didn?t tango, few ath-letes v few sprinters, lack weapons v lack guns,2The entailment relations among quantifiers may be coun-terintuitive to those prone to what Peter Geach called ?quantifi-catious thinking?, who might consider someone ?smaller?
thaneveryone.
But in the theory of generalized quantifiers, the deno-tation of a quantified noun phrase is the set of predicates whichit satisfies, and the predicates satisfied by everyone are a subsetof those satisfied by someone.
Note also that logicians will denythat the universal entails the existential: ?x P (x) 6?
?x P (x).However, most people are happy to infer someone is hungryfrom everyone is hungry.194without clothes v without pants, and If stocks rise,we win v If stocks soar, we win.
Finally, a fewexpressions must be considered non-monotone, in-cluding superlative adjectives and quantifiers suchas most.
Thus prettiest butterfly # prettiest insectand most boats # most vehicles.
Note that certaingeneralized quantifiers must be treated as binaryfunctions having different monotonicities in differ-ent arguments.
Thus every is downward-monotonein its first argument (every fish swims v every sharkswims) but upward-monotone in its second argument(every shark swims v every shark moves).Composition of monotonicity.
Finally, we mustspecify howmonotonicities combine during Fregeancomposition of semantic functions.
In Sa?nchez Va-lencia?s marking algorithm, we represent each inputexpression as a parse in the Lambek categorial gram-mar.
We then (1) mark leaf nodes with appropriatelexical monotonicity values, (2) project monotonic-ities to internal nodes representing function applica-tions, and finally (3) compose monotonicities alongthe path from the root to each leaf in order to deter-mine effective polarities.
The composition of mono-tonicities is straightforward.
Suppose h = f ?
g. Ifeither f or g is non-monotone, then so is h. Other-wise, if the monotonicities of f and g are the same,then h is upward-monotone; if they are different,then h is downward-monotone.
(Thus, wine has pos-itive polarity in no meal without wine because it fallsunder two downward-monotone operators.
)3 The NatLog SystemOur natural logic system, dubbed the NatLog sys-tem, has a three-stage architecture similar to thosein (Marsi and Krahmer, 2005; MacCartney et al,2006), comprising (1) linguistic pre-preprocessing,(2) alignment, and (3) entailment classification.3.1 Linguistic pre-processingRelative to other textual inference systems, the Nat-Log system does comparatively little linguistic pre-processing.
We rely on the Stanford parser (Kleinand Manning, 2003), a Treebank-trained statisticalparser, for tokenization, part-of-speech tagging, andphrase-structure parsing.
By far the most impor-tant analysis performed at this stage is monotonicitymarking, in which we compute the effective mono-unary operator: withoutpattern: IN < /?
[Ww]ithout\$/argument 1: monotonicity ?
on dominating PPpattern: __ > PP=projbinary operator: mostpattern: JJS < /?
[Mm]ost\$/ !> QPargument 1: monotonicity 6??
on dominating NPpattern: __ >+(NP) (NP=proj !> NP)argument 2: monotonicity ?
on dominating Spattern: __ >+(/.
*/) (S=proj !> S)Figure 1: Two examples of monotonicity operatordefinitions.
The patterns employ Tregex syntax.tonicity for each token span in each input sentence.For this, we use an adaptation of the marking algo-rithm of Sa?nchez Valencia (section 2); however, ourchoice of a Treebank-trained parser (driven by thegoal of broad coverage) requires us to modify thealgorithm substantially.
Unlike the categorial gram-mar parses assumed by Sa?nchez Valencia, the nest-ing of constituents in phrase-structure parses doesnot always correspond to the composition of seman-tic functions, which introduces a number of com-plications.
We define a list of downward-monotoneand non-monotone expressions, and for each itemwe specify its arity and a Tregex pattern (Levy andAndrew, 2006) which permits us to identify its oc-currences.
We also specify, for each argument, boththe monotonicity and another Tregex pattern whichhelps us to determine the sentence span over whichthe monotonicity is projected.
(Figure 1 showssome example definitions.)
The marking processcomputes these projections, performs monotonicitycomposition where needed, and marks each tokenspan with its final effective monotonicity.3.2 AlignmentThe second stage of processing establishes an align-ment between the premise and the hypothesis.
Whilethere are many notions of alignment, in this work wehave chosen to represent alignments as sequences ofatomic edits over spans of word tokens.
We definefour types of atomic edits: deletion of a span fromthe premise, insertion of a span into the hypothesis,substitution of a hypothesis span for a premise span,and advance over a span without modification.
Eachatomic edit is parameterized by the token indices atwhich it operates.
As an example, the first problem195in table 3 may be aligned using following edits:An Irishman =?
An Irishman ADVwon =?
won ADVa =?
the SUBNobel prize =?
Nobel prize ADV=?
for literature INS.
=?
.
ADVClearly, this representation imposes certain lim-itations: there is no atomic edit type representingthe movement of a token span from one sentencelocation to another (instead a combination of dele-tion and insertion must be used), and there can be noalignments to non-contiguous sets of tokens.
How-ever, the span edit representation also offers impor-tant benefits.
First, there is always a well-definedsequence of intermediate forms through which thesentence progresses during editing, which is impor-tant for the computation of monotonicity features.Second, given a cost function over edits, it is possi-ble to construct an efficient dynamic program to findthe lowest-cost edit sequence between any pair ofsentences, using a straightforward extension of theLevenshtein string-edit algorithm.For this purpose, we have designed a cost functionwhich prefers edits which operate on longer spans;penalizes edits operating on spans which are notparse-tree constituents; imposes nomimal cost onsubstitutions of words having the same lemma; andimposes little cost on certain ?light?
edits, involvingprepositions, articles, auxiliaries, etc.
When appliedto problems like those in the FraCaS test suite (sec-tion 4), this cost model gives intuitively pleasing re-sults.
However, because our focus in this work is onentailment, we have not devoted much energy to op-timizing our alignment model, and will not discuss itfurther.
(For the RTE experiments described in sec-tion 5, we use alignments derived from an indepen-dent RTE system.
Translating those alignments intothe span edit representation requires relaxing someof its constraints, as we?ll explain.
)3.3 Entailment classificationThe edit sequence obtained during the alignmentstage effectively decomposes the global entailmentproblem into a sequence of atomic entailment prob-lems, one for each atomic edit.
In the final stage, wetrain a model for atomic entailment classification,and predict an entailment relation for each atomicrelation symbol in terms of v FraCaS RTEequivalent p = h p v h, h v p yes yesforward p @ h p v h, h 6v p yes yesreverse p A h h v p, p 6v h unk noindependent p # h p 6v h, h 6v p unk noexclusive p | h p v ?h no noTable 1: The five elementary entailment relations.The last two columns indicate correspondences toFraCaS and RTE answers; see sections 4 and 5.edit.
We then compose our atomic entailment pre-dictions to produce a global entailment prediction.The atomic entailment model uses a classifier topredict one of five elementary entailment relations(table 1) for each atomic edit.
This model uses afeature representation designed to capture character-istics of the edit pertinent to a natural logic analysis:the type of the edit (DEL, INS, or SUB), the effec-tive monotonicity at the affected token span (?, ?, or6??
), and various lexical features of the affected to-kens.
In the case of a SUB edit, the lexical featureshelp to indicate whether the substitution constitutesa semantic expansion, contraction, equivalence, orexclusion, using WordNet-derived measures of syn-onymy, hyponymy, and antonymy, and a measureof lemma similarity based on Levenshtein string-edit distance.
In addition, for edits of all types, wehave found it useful to generate a ?light edit?
fea-ture indicating whether the affected tokens belong tocategories which are usually negligible for inferen-tial purposes, including prepositions, articles, auxil-iaries, and punctuation.The entailment model uses a decision tree clas-sifier, trained on a small data set of 69 problemscustom-designed to exercise diverse regions of thefeature space.3 From these examples, the decisiontree effectively learns such heuristics as deletion inan upward-monotone context yields @, substitutionof a hypernym in a downward-monotone contextyields A, and substitution of an antonym yields |.To produce a top-level entailment judgment, theatomic entailment predictions associated with each3Thus, in using learning, we are not trying to estimate statis-tical properties of some natural distribution of data.
Rather, thelearning framework provides (1) a modular way to add featureswhich may impact the entailment decision, (2) a principled wayto combine evidence from diverse features, such as real-valuedlexical features, and (3) a convenient way to verify the properfunctioning of the system.196atomic edit: SUB(a, the)features:type: SUB, monotonicity: ?, isLightEdit: true,wnSyno: 0.0, wnHypo: 0.0, wnAnto: 0.0, lemmaSim: 0.0predicted entailment relation: =atomic edit: INS(for literature)features:type: INS, monotonicity: ?, isLightEdit: falsepredicted entailment relation: Atop-level inference:composition of entailment relations: = ?
A?
Amapping to FraCaS answer: A?
unkFigure 2: The operation of the entailment model onFraCaS problem 33 (see table 3).edit are composed in a fairly obvious way.
If r is anyentailment relation, then = ?
r ?
r, but # ?
r ?
#.
@ and A are transitive, but @ ?
A ?
#, and so on.Compositions are commutative and associative.Figure 2 shows an example of the operation of theentailment model.4 Experiments with the FraCaS test suiteThe FraCaS test suite (Cooper et al, 1996) was de-veloped as part of a collaborative research effort incomputational semantics.
It contains 346 inferenceproblems reminiscent of a textbook on formal se-mantics.
In the authors?
view, ?inferencing tasks[are] the best way of testing an NLP system?s se-mantic capacity.?
Yet, to our knowledge, this workis the first to present a quantitative system evaluationusing FraCaS.4The problems are divided into nine sections, eachfocused on a category of semantic phenomena, suchas quantifiers or anaphora (see table 2).
Each prob-lem consists of one or more premise sentences, fol-lowed by a one-sentence question.
For this project,the questions were converted into declarative hy-potheses.
Each problem also has an answer, which(usually) takes one of three values: yes (the hypoth-esis can be inferred from the premise(s)), no (thenegation of the hypothesis can be inferred), or unk(neither the hypothesis nor its negation can be in-ferred).
Some examples are shown in table 3.4Indeed, our first step was to put the FraCaS data intomachine-readable form, which we make publicly available athttp://nlp.stanford.edu/?wcmac/downloads/ fracas.xml.?
Category Count % Acc.1 Quantifiers 44 84.092 Plurals 24 41.673 Anaphora 6 50.004 Ellipsis 25 28.005 Adjectives 15 60.006 Comparatives 16 68.757 Temporal 36 61.118 Verbs 8 62.509 Attitudes 9 55.56Applicable sections: 1, 5, 6 75 76.00All sections 183 59.56Table 2: NatLog?s accuracy on the FraCaS test suite,by section.
We exclude degenerate problems andmultiple-premise problems; see text.Not all of the 346 problems were used in thiswork.
First, 12 of the problems were excludedbecause they are degenerate, lacking either a hy-pothesis or a well-defined answer.
Second, anadditional 151 problems (about 45% of the to-tal) were excluded because they involve multiplepremises.
While many of the multiple-premise prob-lems should be feasible for NatLog in the future,such inferences require search, and for now we havechosen to sidestep this complexity.Finally, it should be noted that several sections ofthe test suite involve semantic phenomena, such asellipsis, which the NatLog system makes no attemptto model.
While we report results for these sections,we do not expect performance to be good, and indevelopment we have concentrated on the sectionswhere we expect NatLog to have relevant expertise.In table 2, results for these sections are aggregatedunder the label ?applicable sections?.Results are shown in table 2.
On the ?applica-ble?
sections, performance is good.
(Not supris-ingly, we make little headway with, e.g., ellipsis.
)Of course, this does not constitute a proper evalua-tion on unseen test data?but on the other hand, thesystem was never trained on the FraCaS problems,and has had no opportunity to learn biases implicitin the data.5 Our main goal in testing on FraCaS isto evaluate the representational and inferential ade-quacy of our model of natural logic, and from thatperspective, the strong performance in quantifiers,5This also explains why NatLog?s performance on someFraCaS sections falls below that of a baseline most-common-label classifier.197?
ID Premise(s) Hypothesis Ans1 33 An Irishman won a Nobel prize.
An Irishman won the Nobel prize for literature.
unk1 38 No delegate finished the report.
Some delegate finished the report on time.
no2 99 Clients at the demonstration were all impressed by the sys-tem?s performance.
Smith was a client at the demonstration.Smith was impressed by the system?s perfor-mance.yes9 335 Smith believed that ITEL had won the contract in 1992.
ITEL won the contract in 1992. unkTable 3: Illustrative examples from the FraCaS test suiteguessanswer yes unk no totalyes 62 40 ?
102unk 15 45 ?
60no 6 13 2 21total 90 91 2 183Table 4: Confusions on FraCaS data (all sections)adjectives, and comparatives is satisfying.The confusion matrix shown in table 4 is instruc-tive.
By far the largest category of confusions com-prise problems where we guess unk when the cor-rect answer is yes.
This reflects both the bias to-ward yes in the FraCaS data, and the system?s ten-dency to predict unk (entailment relation #) whenconfused: given the composition rules for entail-ment relations, the system can predict yes only if allatomic-level predictions are either @ or =.
On theother hand, there are a number of problems wherewe predict yes mistakenly.
Several of these errorsarise in a series of problems in ?5 which concernoperator adjectives such as former.
The entailmentmodel wrongly assumes that such modifiers, like anyothers, can safely be deleted in upward-monotonecontexts, but in fact former student 6v student.
Ifthe feature set used by the entailment model wereextended to represent occurrences of operator adjec-tives, and if appropriate examples were included inthe training data, our accuracy in ?5?and the av-erage accuracy for the ?applicable?
sections?couldeasily be boosted over 80%.5 Experiments with RTE dataTextual inference problems from the PASCAL RTEChallenge (Dagan et al, 2005) differ from FraCaSproblems in several important ways.
(See table 5for examples.)
Instead of textbook examples of se-mantic phenomena, RTE problems are more natural-seeming, with premises collected ?in the wild?
fromnewswire text.
The premises are much longer, aver-aging 35 words (vs. 11 words for FraCaS).
Also, theRTE task aims at a binary classification: the RTE noanswer combines the no and unk answers in FraCaS.Due to the character of RTE problems, we do notexpect NatLog to be a good general-purpose solu-tion to solving RTE problems.
First, most RTE prob-lems depend on forms of inference, such as para-phrase, temporal reasoning, or relation extraction,which NatLog is not designed to address.
Second,in most RTE problems, the edit distance betweenpremise and hypothesis is relatively large.
Moreatomic edits means a greater chance that predictionerrors made by the atomic entailment model willpropagate, via entailment composition, to the sys-tem?s final output.
Rather, in applying NatLog toRTE, we hope to make reliable predictions on a sub-set of RTE problems, trading recall for precision.
Ifwe succeed, then we may be able to hybridize with abroad-coverage RTE system to obtain better resultsthan either system individually?the same strategythat was adopted by (Bos and Markert, 2006) fortheir FOL-based system.For this purpose, we have chosen to use the Stan-ford RTE system described in (de Marneffe et al,2006).
In applying NatLog to RTE problems, we usealignments from the Stanford system as input to ourentailment model.
A Stanford alignment is a mapfrom hypothesis words to premise words.
When wetranslate such alignments into the NatLog represen-tation described in section 3, each pair of alignedwords generates a substitution edit (or, if the wordsare identical, an advance edit).
Unaligned premisewords yield deletion edits, while unaligned hypothe-sis words yield insertion edits.
Where possible, con-tiguous sequences of word-level edits are then col-lected into equivalent span edits.
While the resultof this translation method cannot be interpreted as aconventional edit script (there is no well-defined or-198ID Premise(s) Hypothesis Answer518 The French railway company SNCF is cooperating inthe project.The French railway company is called SNCF.
yes601 NUCOR has pioneered a giant mini-mill in which steelis poured into continuous casting machines.Nucor has pioneered the first mini-mill.
noTable 5: Illustrative examples from the RTE3 test suiteRTE3 Development Set (800 problems)System % yes precision recall accuracyStanford 50.25 68.66 66.99 67.25NatLog 18.00 76.39 26.70 58.00Hybrid, bal.
50.00 69.75 67.72 68.25Hybrid, opt.
55.13 69.16 74.03 69.63RTE3 Test Set (800 problems)System % yes precision recall accuracyStanford 50.00 61.75 60.24 60.50NatLog 23.88 68.06 31.71 57.38Hybrid, bal.
50.00 64.50 62.93 63.25Hybrid, opt.
54.13 63.74 67.32 63.62Table 6: Performance on the RTE3 development andtest sets.
% yes indicates the proportion of yes pre-dictions made by the system.
Precision and recallare shown for the yes label.dering of edits, and multiple edits can operate on thesame input spans), we find that this poses no greatimpediment to subsequent processing by the entail-ment model.Table 6 shows the performance of the NatLogsystem on RTE3 data.
Relative to the StanfordRTE system, NatLog achieves high precision on itsyes predictions?about 76% on the development set,and 68% on the test set?suggesting that hybridizingmay be effective.
For comparison, the FOL-basedsystem reported in (Bos and Markert, 2006) attaineda similarly high precision of 76% on RTE2 prob-lems, but was able to make a positive prediction inonly about 4% of cases.
NatLog makes positive pre-dictions far more often?at a rate of 18% on the de-velopment set, and 24% on the test set.The Stanford RTE system makes yes/no predic-tions by thresholding a real-valued inference score.To construct a hybrid system, we adjust the Stan-ford inference scores by +x or ?x, depending onwhether NatLog predicts yes or no/unk.
We choosethe value of x by optimizing development set accu-racy, while adjusting the threshold to generate bal-anced predictions (that is, equal numbers of yes andno predictions).
As an additional experiment, wefix x at this value and then adjust the threshold tooptimize development set accuracy, resulting in anexcess of yes predictions.
(Since this optimizationis based solely on development data, its use on testdata is fully legitimate.)
Results for these two casesare shown in table 6.
The parameters tuned on devel-opment data were found to yield good performanceon test data.
The optimized hybrid system attainedan absolute accuracy gain of 3.12% over the Stan-ford system, corresponding to an extra 25 problemsanswered correctly.
This result is statistically signif-icant (p < 0.01, McNemar?s test, 2-tailed).However, the gain cannot be attributed to Nat-Log?s success in handling the kind of inferencesabout monotonicity which are the staple of naturallogic.
Indeed, such inferences are quite rare in theRTE data.
Rather, NatLog seems to have gainedprimarily by being more precise.
In some cases,this precision works against it: NatLog answers noto problem 518 (table 5) because it cannot accountfor the insertion of called in the hypothesis.
Onthe other hand, it correctly rejects the hypothesis inproblem 601 because it cannot account for the inser-tion of first, whereas the less-precise Stanford sys-tem was happy to allow it.6 Related workWhile the roots of natural logic can be traced backto Aristotle?s syllogisms, the modern conception ofnatural logic began with George Lakoff, who pro-posed ?a logic for natural language?
which could?characterize all the valid inferences that can bemade in natural language?
(Lakoff, 1970).
Thestudy of natural logic was formalized by Johan vanBenthem, who crucially connected it with catego-rial grammar (van Benthem, 1986), and later wasbrought to fruition by Victor Sa?nchez Valencia, whofirst gave a precise definition of a calculus of mono-199tonicity (Sa?nchez Valencia, 1991).
A small currentof theoretical work has continued up to the present,for example (Zamansky et al, 2006).There has been surprisingly little work on build-ing computational models of natural logic.
(Fyo-dorov et al, 2003) describes a Prolog implementa-tion for a small fragment of English, based on a cat-egorial grammar parser.6 In an unpublished draft,(van Eijck, 2005) describes a preliminary implemen-tation in Haskell.Doing inference with representations close to nat-ural language has also been advocated by JerryHobbs, as in (Hobbs, 1985).To our knowledge, the FraCaS results reportedhere represent the first such evaluation.
(Sukkarieh,2003) describes applying a deductive system tosome FraCaS inferences, but does not perform acomplete evaluation or report quantitative results.7 ConclusionOur NatLog implementation of natural logic suc-cessfully handles a broad range of inferences involv-ing monotonicity, as demonstrated on the FraCaStest suite.
While a post-hoc analysis of performanceon the RTE3 Challenge suggests that monotonicity-related inferences have limited applicability in RTEdata, the greater precision of the NatLog system nev-ertheless significantly improved the performance ofa hybrid RTE system.
An area for future work isfurther consideration of what kinds of inference areprevalent and important in prominent computationallinguistic applications.Acknowledgements The authors wish to thankMarie-Catherine de Marneffe and the anonymousreviewers for their helpful comments on an earlierdraft of this paper.
This work was supported in partby ARDA?s Advanced Question Answering for In-telligence (AQUAINT) Program.ReferencesElena Akhmatova.
2005.
Textual entailment resolution viaatomic propositions.
In Proc.
of the PASCAL RTE ChallengeWorkshop.Johan Bos and Katja Markert.
2006.
When logical inferencehelps determining textual entailment (and when it doesn?t).In Proc.
of the 2nd PASCAL RTE Challenge Workshop.6Available at http://yeda.cs.technion.ac.il/?yaroslav/oc/Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Jo-han Van Genabith, Jan Jaspars, Hans Kamp, David Milward,Manfred Pinkal, Massimo Poesio, and Steve Pulman.
1996.Using the framework.
Technical Report LRE 62-051 D-16,The FraCaS Consortium.Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005.
ThePASCAL Recognising Textual Entailment Challenge.
InProc.
of the PASCAL RTE Challenge Workshop.Marie-Catherine de Marneffe, Bill MacCartney, TrondGrenager, Daniel Cer, Anna Rafferty, and Christopher D.Manning.
2006.
Learning to distinguish valid textual entail-ments.
In Proc.
of the 2nd PASCAL RTE Challenge Work-shop.Abraham Fowler, Bob Hauser, Daniel Hodges, Ian Niles,Adrian Novischi, and Jens Stephan.
2005.
Applying CO-GEX to recognize textual entailment.
In Proc.
of the PAS-CAL RTE Challenge Workshop.Yaroslav Fyodorov, Yoad Winter, and Nissim Francez.
2003.Order-based inference in natural logic.
Logic Journal of theIGPL, 11(4):385?416.Andrew Hickl, John Williams, Jeremy Bensley, Kirk Roberts,Bryan Rink, and Ying Shi.
2006.
Recognizing textual en-tailment with LCC?s GROUNDHOG system.
In Proc.
of the2nd PASCAL RTE Challenge Workshop.Jerry R. Hobbs.
1985.
Ontological promiscuity.
In Proc.
ofACL-85, pages 61?69.Valentin Jijkoun and Maarten de Rijke.
2005.
Recognizingtextual entailment using lexical similarity.
In Proc.
of thePASCAL RTE Challenge Workshop.Dan Klein and Christopher D. Manning.
2003.
Accurate unlex-icalized parsing.
In Proc.
of ACL-03.George Lakoff.
1970.
Linguistics and natural logic.
Synthese,22:151?271.Roger Levy and Galen Andrew.
2006.
Tregex and Tsurgeon:tools for querying and manipulating tree data structures.
InProc.
of LREC-06.Bill MacCartney, Trond Grenager, Marie-Catherine de Marn-effe, Daniel Cer, and Christopher D. Manning.
2006.
Learn-ing to recognize features of valid textual entailments.
InProc.
of HLT-NAACL-06.Erwin Marsi and Emiel Krahmer.
2005.
Classification of se-mantic relations by humans and machines.
In Proc.
of theACL 2005 Workshop on Empirical Modeling of SemanticEquivalence and Entailment.Lorenza Romano, Milen Kouylekov, Idan Szpektor, Ido Da-gan, and Alberto Lavelli.
2006.
Investigating a genericparaphrase-based approach for relation extraction.
In Proc.of EACL-06.Victor Sa?nchez Valencia.
1991.
Studies on Natural Logic andCategorial Grammar.
Ph.D. thesis, Univ.
of Amsterdam.Jana Z. Sukkarieh.
2003.
An expressive efficient representation:Bridging a gap between NLP and KR.
In Proc.
of the 7thInt?l Conf.
on Knowledge-Based Intelligent Information andEngineering Systems.Johan van Benthem.
1986.
Essays in logical semantics.
Reidel,Dordrecht.Jan van Eijck.
2005.
Natural logic for natural language.
http://homepages.cwi.nl/?jve/papers/05/nlnl/NLNL.pdf .Anna Zamansky, Nissim Francez, and Yoad Winter.
2006.
A?natural logic?
inference system using the Lambek calculus.Journal of Logic, Language and Information, 15:273?295.200
