Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 387?395,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPA Chinese-English Organization Name Translation System UsingHeuristic Web Mining and Asymmetric AlignmentFan Yang, Jun Zhao, Kang LiuNational Laboratory of Pattern RecognitionInstitute of Automation, Chinese Academy of Sciences, Beijing 100190, China{fyang,jzhao,kliu}@nlpr.ia.ac.cnAbstractIn this paper, we propose a novel system fortranslating organization names from Chineseto English with the assistance of webresources.
Firstly, we adopt a chunking-based segmentation method to improve thesegmentation of Chinese organization nameswhich is plagued by the OOV problem.Then a heuristic query construction methodis employed to construct an efficient querywhich can be used to search the bilingualWeb pages containing translationequivalents.
Finally, we align the Chineseorganization name with English sentencesusing the asymmetric alignment method tofind the best English fragment as thetranslation equivalent.
The experimentalresults show that the proposed methodoutperforms the baseline statistical machinetranslation system by 30.42%.1 IntroductionThe task of Named Entity (NE) translation is totranslate a named entity from the source languageto the target language, which plays an importantrole in machine translation and cross-languageinformation retrieval (CLIR).
The organizationname (ON) translation is the most difficultsubtask in NE translation.
The structure of ON iscomplex and usually nested, including personname, location name and sub-ON etc.
Forexample, the organization name ????????????
(Beijing Nokia CommunicationLtd.)?
contains a company name (??
?/Nokia)and a location name (??/Beijing).
Therefore,the translation of organization names shouldcombine transliteration and translation together.Many previous researchers have tried to solveON translation problem by building a statisticalmodel or with the assistance of web resources.The performance of ON translation using webknowledge is determined by the solution of thefollowing two problems: The efficiency of web page searching: howcan we find the web pages which contain thetranslation equivalent when the amount of thereturned web pages is limited? The reliability of the extraction method: howreliably can we extract the translation equivalentfrom the web pages that we obtained in thesearching phase?For solving these two problems, we propose aChinese-English organization name translationsystem using heuristic web mining andasymmetric alignment, which has threeinnovations.1) Chunking-based segmentation: A ChineseON is a character sequences, we need to segmentit before translation.
But the OOV words alwaysmake the ON segmentation much more difficult.We adopt a new two-phase method here.
First,the Chinese ON is chunked and each chunk isclassified into four types.
Then, different types ofchunks are segmented separately using differentstrategies.
Through chunking the Chinese ONfirst, the OOVs can be partitioned into one chunkwhich will not be segmented in the next phase.
Inthis way, the performance of segmentation isimproved.2) Heuristic Query construction: We need toobtain the bilingual web pages that contain boththe input Chinese ON and its translationequivalent.
But in most cases, if we just send theChinese ON to the search engine, we will alwaysget the Chinese monolingual web pages whichdon?t contain any English word sequences, letalone the English translation equivalent.
So wepropose a heuristic query construction method togenerate an efficient bilingual query.
Somewords in the Chinese ON are selected and theirtranslations are added into the query.
TheseEnglish words will act as clues for searching387bilingual web pages.
The selection of the Chinesewords to be translated will take intoconsideration both the translation confidence ofthe words and the information contents that theycontain for the whole ON.3) Asymmetric alignment: When we extract thetranslation equivalent from the web pages, thetraditional method should recognize the namedentities in the target language sentence first, andthen the extracted NEs will be aligned with thesource ON.
However, the named entityrecognition (NER) will always introduce somemistakes.
In order to avoid NER mistakes, wepropose an asymmetric alignment method whichalign the Chinese ON with an English sentencedirectly and then extract the English fragmentwith the largest alignment score as the equivalent.The asymmetric alignment method can avoid theinfluence of improper results of NER andgenerate an explicit matching between the sourceand the target phrases which can guarantee theprecision of alignment.In order to illustrate the above ideas clearly,we give an example of translating the ChineseON ???????????
(China HuarongAsset Management Corporation)?.Step1: We first chunk the ON, where ?LC?,?NC?, ?MC?
and ?KC?
are the four types ofchunks defined in Section 4.2.??
(China)/LC  ??
(Huarong)/NC  ????
(asset management)/MC  ??
(corporation)/KCStep2: We segment the ON based on thechunking results.??
(china)  ??
(Huarong)  ??(asset)??
(management)  ??
(corporation)If we do not chunk the ON first, the OOVword ???(Huarong)?
may be segmented as ????.
This result will certainly lead to translationerrors.Step 3: Query construction:We select the words ????
and ????
totranslate and a bilingual query is constructed as:?
?
?
?
?
?
?
?
?
?
?
?
+ asset +managementIf we don?t add some English words into thequery, we may not obtain the web pages whichcontain the English phrase ?China Huarong AssetManagement Corporation?.
In that case, we cannot extract the translation equivalent.Step 4: Asymmetric Alignment: We extract asentence ?
?President of China Huarong AssetManagement Corporation??
from the returnedsnippets.
Then the best fragment of the sentence?China Huarong Asset ManagementCorporation?
will be extracted as the translationequivalent.
We don?t need to implement EnglishNER process which may make mistakes.The remainder of the paper is structured asfollows.
Section 2 reviews the related works.
InSection 3, we present the framework of oursystem.
We discuss the details of the ONchunking in Section 4.
In Section 5, we introducethe approach of heuristic query construction.
Insection 6, we will analyze the asymmetricalignment method.
The experiments are reportedin Section 7.
The last section gives theconclusion and future work.2 Related WorkIn the past few years, researchers have proposedmany approaches for organization translation.There are three main types of methods.
The firsttype of methods translates ONs by building astatistical translation model.
The model can bebuilt on the granularity of word [Stalls et al,1998], phrase [Min Zhang et al, 2005] orstructure [Yufeng Chen et al, 2007].
The secondtype of methods finds the translation equivalentbased on the results of alignment from the sourceON to the target ON [Huang et al, 2003; Feng etal., 2004; Lee et al, 2006].
The ONs areextracted from two corpora.
The corpora can beparallel corpora [Moore et al, 2003] or content-aligned corpora [Kumano et al, 2004].
The thirdtype of methods introduces the web resourcesinto ON translation.
[Al-Onaizan et al, 2002]uses the web knowledge to assist NE translationand [Huang et al, 2004; Zhang et al, 2005; Chenet al, 2006] extracts the translation equivalentsfrom web pages directly.The above three types of methods have theiradvantages and shortcomings.
The statisticaltranslation model can give an output for anyinput.
But the performance is not good enough oncomplex ONs.
The method of extractingtranslation equivalents from bilingual corporacan obtain high-quality translation equivalents.But the quantity of the results depends heavily onthe amount and coverage of the corpora.
So thiskind of method is fit for building a reliable ONdictionary.
In the third type of method, with theassistance of web pages, the task of ONtranslation can be viewed as a two-stage process.Firstly, the web pages that may contain the targettranslation are found through a search engine.Then the translation equivalent will be extractedfrom the web pages based on the alignment scorewith the original ON.
This method will not388depend on the quantity and quality of the corporaand can be used for translating complex ONs.3 The Framework of Our SystemThe Framework of our ON translation systemshown in Figure 1 has four modules.Figure 1.
System framework1) Chunking-based ON Segmentation Module:The input of this module is a Chinese ON.
TheChunking model will partition the ON intochunks, and label each chunk using one of fourclasses.
Then, different segmentation strategieswill be executed for different types of chunks.2) Statistical Organization Translation Module:The input of the module is a word set in whichthe words are selected from the Chinese ON.
Themodule will output the translation of these words.3) Web Retrieval Module: When input aChinese ON, this module generates a querywhich contains both the ON and some words?translation output from the translation module.Then we can obtain the snippets that may containthe translation of the ON from the search engine.The English sentences will be extracted fromthese snippets.4) NE Alignment Module: In this module, theasymmetric alignment method is employed toalign the Chinese ON with these Englishsentences obtained in Web retrieval module.
Thebest part of the English sentences will beextracted as the translation equivalent.4 The Chunking-based Segmentationfor Chinese ONsIn this section, we will illustrate a chunking-based Chinese ON segmentation method, whichcan efficiently deal with the ONs containingOOVs.4.1 The Problems in ON SegmentationThe performance of the statistical ON translationmodel is dependent on the precision of theChinese ON segmentation to some extent.
WhenChinese words are aligned with English words,the mistakes made in Chinese segmentation mayresult in wrong alignment results.
We also needcorrect segmentation results when decoding.
ButChinese ONs usually contain some OOVs thatare hard to segment, especially the ONscontaining names of people or brand names.
Tosolve this problem, we try to chunk Chinese ONsfirstly and the OOVs will be partitioned into onechunk.
Then the segmentation will be executedfor every chunk except the chunks containingOOVs.4.2 Four Types of ChunksWe define the following four types of chunks forChinese ONs: Location Chunk (LC): LC contains thelocation information of an ON. Name Chunk (NC): NC contains the nameor brand information of an ON.
In mostcases, Name chunks should betransliterated. Modification Chunk (MC): MC containsthe modification information of an ON. Key word Chunk (KC): KC contains thetype information of an ON.The following is an example of an ONcontaining these four types of chunks.??
(Beijing)/LC ?
?
?
(Peregrine)/NC????
(investment consulting)/MC  ????(co.
)/KCIn the above example, the OOV ????(Peregrine)?
is partitioned into name chunk.
Thenthe name chunk will not be segmented.4.3 The CRFs Model for ChunkingConsidered as a discriminative probabilisticmodel for sequence joint labeling and with theadvantage of flexible feature fusion ability,Conditional Random Fields (CRFs) [J.Lafferty etal., 2001] is believed to be one of the bestprobabilistic models for sequence labeling tasks.So the CRFs model is employed for chunking.We select 6 types of features which are provedto be efficient for chunking through experiments.The templates of features are shown in Table 1,389Description Featurescurrent/previous/successcharacter C0?C-1?C1whether the characters isa wordW(C-2C-1C0)?W(C0C1C2)?W(C-1C0C1)whether the characters isa location nameL(C-2C-1C0)?L(C0C1C2)?L(C-1C0C1)whether the characters isan ON suffixSK(C-2C-1C0)?SK(C0C1C2)?SK(C-1C0C1)whether the characters isa location suffixSL(C-2C-1C0)?SL(C0C1C2)?SL(C-1C0C1)relative position in thesentencePOS(C0)Table 1.
Features used in CRFs modelwhere Ci denotes a Chinese character, i denotesthe position relative to the current character.
Wealso use bigram and unigram features but onlyshow trigram templates in Table 1.5 Heuristic Query ConstructionIn order to use the web information to assistChinese-English ON translation, we must firstlyretrieve the bilingual web pages effectively.
Sowe should develop a method to constructefficient queries which are used to obtain webpages through the search engine.5.1 The Limitation of Monolingual QueryWe expect to find the web pages where theChinese ON and its translation equivalent co-occur.
If we just use a Chinese ON as the query,we will always obtain the monolingual webpages only containing the Chinese ON.
In orderto solve the problem, some words in the ChineseON can be translated into English, and theEnglish words will be added into the query as theclues to search the bilingual web pages.5.2 The Strategy of Query ConstructionWe use the metric of precision here to evaluatethe possibility in which the translation equivalentis contained in the snippets returned by the searchengine.
That means, on the condition that weobtain a fixed number of snippets, the more thesnippets which contain the translation equivalentare obtained, the higher the precision is.
Thereare two factors to be considered.
The first is howefficient the added English words can improvethe precision.
The second is how to avoid addingwrong translations which may bring down theprecision.
The first factor means that we shouldselect the most informative words in the ChineseON.
The second factor means that we shouldconsider the confidence of the SMT model at thesame time.
For example:?
?/LC  ??/NC???
/MC ???
?/KC(Tianjin   Honda     motor           co. ltd.)There are three strategies of constructingqueries as follows:Q1.?????????????
HondaQ2.?????????????
Ltd.Q3.????????????
?
MotorTianjinIn the first strategy, we translate the word ???(Honda)?
which is the most informative wordin the ON.
But its translation confidence is verylow, which means that the statistical model giveswrong results usually.
The mistakes in translationwill mislead the search engine.
In the secondstrategy, we translate the word which has thelargest translation confidence.
Unfortunately theword is so common that it can?t give any help infiltering out useless web pages.
In the thirdstrategy, the words which have sufficienttranslation confidence and information contentare selected.5.3 Heuristically Selecting the Words to beTranslatedThe mutual information is used to evaluate theimportance of the words in a Chinese ON.
Wecalculate the mutual information on thegranularity of words in formula 1 and chunks informula 2.
The integration of the two kinds ofmutual information is in formula 3.y Yp ( x ,y )( , ) = lo gp ( x ) p ( y )M I W x Y ??
(1)Yp ( y , c )( , ) = lo gp ( y ) p ( c )yM I C c Y??
(2)( , )= ( , )+(1- ) ( , )xIC x Y MIW x Y MIC c Y?
?
(3)Here, MIW(x,Y) denotes the mutualinformation of word x with ON Y.
That is thesummation of the mutual information of x withevery word in Y. MIC(c,Y) is similar.
cx denotesthe label of the chunk containing x.We should also consider the risk of obtainingwrong translation results.
We can see that thename chunk usually has the largest mutualinformation.
However, the name chunk alwaysneeds to be transliterated, and transliteration isoften more difficult than translation by lexicon.So we set a threshold Tc for translationconfidence.
We only select the words whosetranslation confidences are higher than Tc, withtheir mutual information from high to low.3906 Asymmetric Alignment Method forEquivalent ExtractionAfter we have obtained the web pages with theassistant of search engine, we extract theequivalent candidates from the bilingual webpages.
So we first extract the pure Englishsentences and then an asymmetric alignmentmethod is executed to find the best fragment ofthe English sentences as the equivalent candidate.6.1 Traditional Alignment MethodTo find the translation candidates, the traditionalmethod has three main steps.1) The NEs in the source and the targetlanguage sentences are extracted separately.
TheNE collections are Sne and Tne.2) For each NE in Sne, calculate the alignmentprobability with every NE in Tne.3) For each NE in Sne, the NE in Tne which hasthe highest alignment probability will be selectedas its translation equivalent.This method has two main shortcomings:1) Traditional alignment method needs theNER process in both sides, but the NER processmay often bring in some mistakes.2) Traditional alignment method evaluates thealignment probability coarsely.
In other words,we don?t know exactly which target word(s)should be aligned to for the source word.
Acoarse alignment method may have negativeeffect on translation equivalent extraction.6.2 The Asymmetric Alignment MethodTo solve the above two problems, we propose anasymmetric alignment method.
The alignmentmethod is so called ?asymmetric?
for that italigns a phrase with a sentence, in other words,the alignment is conducted between two objectswith different granularities.
The NER process isnot necessary for that we align the Chinese ONwith English sentences directly.
[Wai Lam et al, 2007] proposed a methodwhich uses the KM algorithm to find the optimalexplicit matching between a Chinese ON and agiven English ON.
KM algorithm [Kuhn, 1955]is a traditional graphic algorithm for finding themaximum matching in bipartite weighted graph.In this paper, the KM algorithm is extended to bean asymmetric alignment method.
So we canobtain an explicit matching between a ChineseON and a fragment of English sentence.A Chinese NE CO={CW1, CW2, ?, CWn} is asequence of Chinese words CWi and the Englishsentence ES={EW1, EW2, ?, EWm} is a sequenceof English words EWi.
Our goal is to find afragment EWi,i+n={EWi, ?, EWi+n} in ES, whichhas the highest alignment score with CO.Through executing the extended KM algorithm,we can obtain an explicit matching L. For anyCWi, we can get its corresponding English wordEWj, written as L(CWi)=EWj and vice versa.
Wefind the optimal matching L between two phrases,and calculate the alignment score based on L. Anexample of the asymmetric alignment will begiven in Fig2.Fig2.
An example of asymmetric alignmentIn Fig2, the Chinese ON ????????
isaligned to an English sentence ??
theAgriculture Bank of China is the four??.
Thestop words in parentheses are deleted for theyhave no meaning in Chinese.
In step 1, theEnglish fragment contained in the squarebrackets is aligned with the Chinese ON.
We canobtain an explicit matching L1, shown by arrows,and an alignment score.
In step 2, the squarebrackets move right by one word, we can obtain anew matching L2 and its corresponding alignmentscore, and so on.
When we have calculated everyconsequent fragment in English sentence, we canfind the best fragment ?the Agriculture Bank ofChina?
according to the alignment score as thetranslation equivalent.The algorithm is shown in Fig3.
Where, m isthe number of words in an English sentence andn is the number of words in a Chinese ON.
KMalgorithm will generate an equivalent sub-graphby setting a value to each vertex.
The edge whoseweight is equal to the summation of the values ofits two vertexes will be added into the sub-graph.Then the Hungary algorithm will be executed inthe equivalent sub-graph to find the optimalmatching.
We find the optimal matching betweenCW1,n and EW1,n first.
Then we move the windowright and find the optimal matching betweenCW1,n and EW2,n+1.
The process will continueuntil the window arrives at the right most of the?
[(The) Agriculture Bank (of) China] (is) (the) four??
??
??
(The) Agriculture [Bank (of) China] (is) (the) four]???
??
?
?Step 1:Step 2:391English sentence.
When the window moves right,we only need to find a new matching for the newadded English vertex EWend and the Chinesevertex Cdrop which has been matched with EWstartin the last step.
In the Hungary algorithm, thematching is added through finding an augmentingpath.
So we only need to find one augmentingpath each time.
The time complexity of findingan augmenting path is O(n3).
So the wholecomplexity of asymmetric alignment is O(m*n3).Algorithm: Asymmetric Alignment AlgorithmInput: A segmented Chinese ON CO and anEnglish sentence ES.Output: an English fragment EWk,k+n1.
Let start=1, end=n, L0=null2.
Using KM algorithm to find the optimalmatching between two phrases CW1,n andEWstart,end based on the previous matching Lstart-1.
We obtain a matching Lstart and calculate thealignment score Sstart based on Lstart.3.
CWdrop = L(EWstart)  L(CWdrop)=null.4.
If (end==m) go to 7, else start=start+1,end=end+1.5.
Calculate the feasible vertex labeling for thevertexes CWdrop and EWend6.
Go to 2.7.
The fragment EWk,k+n-1 which has the highestalignment score will be returned.Fig3.
The asymmetric alignment algorithm6.3 Obtain the Translation EquivalentFor each English sentence, we can obtain afragment ESi,i+n which has the highest alignmentscore.
We will also take into consideration thefrequency information of the fragment and itsdistance away from the Chinese ON.
We useformula (4) to obtain a final score for eachtranslation candidate ETi and select the largestone as translation result.
( )= + log( +1)+ log(1 / +1)i i i iS ET SA C D?
?
?
(4)Where Ci denotes the frequency of ETi, and Didenotes the nearest distance between ETi and theChinese ON.7 ExperimentsWe carried out experiments to investigate theperformance improvement of ON translationunder the assistance of web knowledge.7.1 Experimental DataOur experiment data are extracted fromLDC2005T34.
There are two corpora,ldc_propernames_org_ce_v1.beta (Indus_corpusfor short) and ldc_propernames_industry_ce_v1.beta (Org_corpus for short).
Somepre-process will be executed to filter out somenoisy translation pairs.
For example, thetranslation pairs involving other languages suchas Japanese and Korean will be filtered out.There are 65,835 translation pairs that we used asthe training corpus and the chunk labels areadded manually.We randomly select 250 translation pairs fromthe Org_corpus and 253 translation pairs fromthe Indus_corpus.
Altogether, there are 503translation pairs as the testing set.7.2 The Effect of Chunking-basedSegmentation upon ON TranslationIn order to evaluate the influence of segmentationresults upon the statistical ON translation system,we compare the results of two translation models.One model uses chunking-based segmentationresults as input, while the other uses traditionalsegmentation results.To train the CRFs-chunking model, werandomly selected 59,200 pairs of equivalenttranslations from Indus_corpus and org_corpus.We tested the performance on the set whichcontains 6,635 Chinese ONs and the results areshown as Table-2.For constructing a statistical ON translationmodel, we use GIZA++1 to align the Chinese NEsand the English NEs in the training set.
Then thephrase-based machine translation systemMOSES2 is adopted to translate the 503 ChineseNEs in testing set into English.Precision Recall F-measureLC 0.8083 0.7973 0.8028NC 0.8962 0.8747 0.8853MC 0.9104 0.9073 0.9088KC 0.9844 0.9821 0.9833All 0.9437 0.9372 0.9404Table 2.
The test results of CRFs-chunking modelWe have two metrics to evaluate thetranslation results.
The first metric L1 is used toevaluate whether the translation result is exactlythe same as the answer.
The second metric L2 isused to evaluate whether the translation resultcontains almost the same words as the answer,1http://www.fjoch.com/GIZA++.html2http://www.statmt.org/moses/392without considering the order of words.
Theresults are shown in Table-3:chunking-basedsegmentationtraditionalsegmentationL1 21.47% 18.29%L2 40.76% 36.78%Table 3.
Comparison of segmentation influenceFrom the above experimental data, we can seethat the chunking-based segmentation improvesL1 precision from 18.29% to 21.47% and L2precision from 36.78% to 40.76% in comparisonwith the traditional segmentation method.Because the segmentation results will be used inalignment, the errors will affect the computationof alignment probability.
The chunking basedsegmentation can generate better segmentationresults; therefore better alignment probabilitiescan be obtained.7.3 The Efficiency of Query ConstructionThe heuristic query construction method aims toimprove the efficiency of Web searching.
Theperformance of searching for translationequivalents mostly depends on how to constructthe query.
To test its validity, we design fourkinds of queries and evaluate their ability usingthe metric of average precision in formula 5 andmacro average precision (MAP) in formula 6,11P rNii iHA vera g e ec is io nN S== ?
(5)where Hi is the count of snippets that contain atleast one equivalent for the ith query.
And Si isthe total number of snippets we got for the ithquery,1= 11( )1 jiHNj jiM A PR iN H== ??
(6)where R(i) is the order of snippet where the ithequivalent occurs.
We construct four kinds ofqueries for the 503 Chinese ONs in testing set asfollows:Q1: only the Chinese ON.Q2: the Chinese ON and the results of thestatistical translation model.Q3: the Chinese ON and some parts?translation selected by the heuristic queryconstruction method.Q4: the Chinese ON and its correct Englishtranslation equivalent.We obtain at most 100 snippets from Googlefor every query.
Sometimes there are not enoughsnippets as we expect.
We set ?
in formula 4 at0.7?and the threshold of translation confidenceat 0.05.
The results are shown as Table 4.AverageprecisionMAPQ1 0.031 0.0527Q2 0.187 0.2061Q3 0.265 0.3129Q4 1.000 1.0000Table 4.
Comparison of four types queryHere we can see that, the result of Q4 is theupper bound of the performance, and the Q1 isthe lower bound of the performance.
Weconcentrate on the comparison between Q2 andQ3.
Q2 contains the translations of every word ina Chinese ON, while Q3 just contains thetranslations of the words we select using theheuristic method.
Q2 may give more informationto search engine about which web pages weexpect to obtain, but it also brings in translationmistakes that may mislead the search engine.
Theresults show that Q3 is better than Q2, whichproves that a careful clue selection is needed.7.4 The Effect of Asymmetric AlignmentAlgorithmThe asymmetric alignment method can avoid themistakes made in the NER process and give anexplicit alignment matching.
We will comparethe asymmetric alignment algorithm with thetraditional alignment method on performance.We adopt two methods to align the Chinese NEwith the English sentences.
The first method hastwo phases, the English ONs are extracted fromEnglish sentences firstly, and then the EnglishONs are aligned with the Chinese ON.
Lastly, theEnglish ON with the highest alignment score willbe selected as the translation equivalent.
We usethe software Lingpipe3 to recognize NEs in theEnglish sentences.
The alignment probability canbe calculated as formula 7:( , ) ( | )i ji jScore C E p e c= ??
(7)The second method is our asymmetricalignment algorithm.
Our method is differentfrom the one in [Wai Lam et al, 2007] whichsegmented a Chinese ON using an English ON assuggestion.
We segment the Chinese ON usingthe chunking-based segmentation method.
TheEnglish sentences extracted from snippets will bepreprocessed.
Some stop words will be deleted,such as ?the?, ?of?, ?on?
etc.
To execute theextended KM algorithm for finding the bestalignment matching, we must assure that thevertex number in each side of the bipartite is the3http://www.alias-i.com/lingpipe/393same.
So we will execute a phrase combinationprocess before alignment, which combines somefrequently occurring consequent English wordsinto single vertex, such as ?limited company?
etc.The combination is based on the phrase pair tablewhich is generated from phrase-based SMTsystem.
The results are shown in Table 5:AsymmetricAlignmentTraditionalmethodStatisticalmodelTop1 48.71% 36.18% 18.29%Top5 53.68% 46.12% --Table 5.
Comparison the precision of alignmentmethodFrom the results (column 1 and column 2) wecan see that, the Asymmetric alignment methodoutperforms the traditional alignment method.Our method can overcome the mistakesintroduced in the NER process.
On the otherhand, in our asymmetric alignment method, thereare two main reasons which may result inmistakes, one is that the correct equivalentdoesn?t occur in the snippet; the other is thatsome English ONs can?t be aligned to theChinese ON word by word.7.5 Comparison between Statistical ONTranslation Model and Our MethodCompared with the statistical ON translationmodel, we can see that the performance isimproved from 18.29% to 48.71% (the bold datashown in column 1 and column 3 of Table 5) byusing our Chinese-English ON translation system.Transforming the translation problem into theproblem of searching for the correct translationequivalent in web pages has three advantages.First, word order determination is difficult instatistical machine translation (SMT), whilesearch engines are insensitive to this problem.Second, SMT often loses some function wordsuch as ?the?, ?a?, ?of?, etc, while our methodcan avoid this problem because such words arestop words in search engines.
Third, SMT oftenmakes mistakes in the selection of synonyms.This problem can be solved by the fuzzymatching of search engines.
In summary, webassistant method makes Chinese ON translationeasier than traditional SMT method.8 ConclusionIn this paper, we present a new approach whichtranslates the Chinese ON into English with theassistance of web resources.
We first adopt thechunking-based segmentation method to improvethe ON segmentation.
Then a heuristic queryconstruction method is employed to construct aquery which can search translation equivalentmore efficiently.
At last, the asymmetricalignment method aligns the Chinese ON withEnglish sentences directly.
The performance ofON translation is improved from 18.29% to48.71%.
It proves that our system can work wellon the Chinese-English ON translation task.
Inthe future, we will try to apply this method inmining the NE translation equivalents frommonolingual web pages.
In addition, theasymmetric alignment algorithm also has somespace to be improved.AcknowledgementThe work is supported by the National HighTechnology Development 863 Program of Chinaunder Grants no.
2006AA01Z144, and theNational Natural Science Foundation of Chinaunder Grants no.
60673042 and 60875041.ReferencesYaser Al-Onaizan and Kevin Knight.
2002.Translating named entities using monolingual andbilingual resources.
In Proc of ACL-2002.Yufeng Chen, Chenqing Zong.
2007.
A Structure-Based Model for Chinese Organization NameTranslation.
In Proc.
of ACM Transactions onAsian Language Information Processing (TALIP)Donghui Feng, Yajuan Lv, Ming Zhou.
2004.
A newapproach for English-Chinese named entityalignment.
In Proc.
of  EMNLP 2004.Fei Huang, Stephan Vogal.
2002.
Improved namedentity translation and bilingual named entityextraction.
In Proc.
of the 4th IEEE InternationalConference on Multimodal Interface.Fei Huang, Stephan Vogal, Alex Waibel.
2003.Automatic extraction of named entity translingualequivalence based on multi-feature costminimization.
In Proc.
of the 2003 AnnualConference of the ACL, Workshop on Multilingualand Mixed-language Named Entity RecognitionMasaaki Nagata, Teruka Saito, and Kenji Suzuki.2001.
Using the Web as a Bilingual Dictionary.
InProc.
of ACL 2001 Workshop on Data-drivenMethods in Machine Translation.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Proc.
ofACL 2005.Conrad Chen, Hsin-His Chen.
2006.
A High-AccurateChinese-English NE Backward Translation SystemCombining Both Lexical Information and WebStatistics.
In Proc.
of ACL 2006.394Wai Lam,  Shing-Kit Chan.
2007.
Named EntityTranslation Matching and Learning: WithApplication for Mining Unseen Translations.
InProc.
of ACM Transactions on InformationSystems.Chun-Jen Lee, Jason S. Chang, Jyh-Shing R. Jang.2006.
Alignment of bilingual named entities inparallel corpora using statistical models andmultiple knowledge sources.
In Proc.
of ACMTransactions on Asian Language InformationProcessing (TALIP).Kuhn, H. 1955.
The Hungarian method for theassignment problem.
Naval Rese.
Logist.
Quart2,83-97.Min Zhang., Haizhou Li, Su Jian, Hendra Setiawan.2005.
A phrase-based context-dependent jointprobability model for named entity translation.
InProc.
of the 2nd International Joint Conference onNatural Language Processing(IJCNLP)Ying Zhang, Fei Huang, Stephan Vogel.
2005.
Miningtranslations of OOV terms from the web throughcross-lingual query expansion.
In Proc.
of the 28thACM SIGIR.Bonnie Glover Stalls and Kevin Knight.
1998.Translating names and technical terms in Arabictext.
In Proc.
of the COLING/ACL Workshop onComputational Approaches to Semitic Language.J.
Lafferty, A. McCallum, and F. Pereira.
2001.Conditional random fields: Probabilistic models forsegmenting and labeling sequence data.
In Proc.ICML-2001.Tadashi Kumano, Hideki Kashioka, Hideki Tanakaand Takahiro Fukusima.
2004.
Acquiring bilingualnamed entity translations from content-alignedcorpora.
In Proc.
IJCNLP-04.Robert C. Moore.
2003.
Learning translation ofnamed-entity phrases from parallel corpora.
In Proc.of 10th conference of the European chapter of ACL.395
