Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 763?774,October 25-29, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsChinese Zero Pronoun Resolution: An Unsupervised ProbabilisticModel Rivaling Supervised ResolversChen Chen and Vincent NgHuman Language Technology Research InstituteUniversity of Texas at DallasRichardson, TX 75083-0688{yzcchen,vince}@hlt.utdallas.eduAbstractState-of-the-art Chinese zero pronoun res-olution systems are supervised, thus re-lying on training data containing manu-ally resolved zero pronouns.
To elimi-nate the reliance on annotated data, wepresent a generative model for unsuper-vised Chinese zero pronoun resolution.At the core of our model is a novel hy-pothesis: a probabilistic pronoun resolvertrained on overt pronouns in an unsuper-vised manner can be used to resolve zeropronouns.
Experiments demonstrate thatour unsupervised model rivals its state-of-the-art supervised counterparts in perfor-mance when resolving the Chinese zeropronouns in the OntoNotes corpus.1 IntroductionA zero pronoun (ZP) is a gap in a sentence thatis found when a phonetically null form is used torefer to a real-world entity.
An anaphoric zeropronoun (AZP) is a ZP that corefers with one ormore preceding noun phrases (NPs) in the asso-ciated text.
Below is an example taken from theChinese TreeBank (CTB), where the ZP (denotedas *pro*) refers to???
(Russia).[???]
???????????????*pro*?????????????
([Russia] is a consistent supporter of Milo?evi?,*pro* has proposed to mediate the political crisis.
)As we can see, ZPs lack grammatical attributesthat are useful for overt pronoun resolution such asnumber and gender.
This makes ZP resolutionmore challenging than overt pronoun resolution.Automatic ZP resolution is typically composedof two steps.
The first step, AZP identification, in-volves extracting ZPs that are anaphoric.
The sec-ond step, AZP resolution, aims to identify an an-tecedent of an AZP.
State-of-the-art ZP resolvershave tackled both of these steps in a supervisedmanner, training a classifier for AZP identificationand another one for AZP resolution (e.g., Zhao andNg (2007), Chen and Ng (2013)).In this paper, we focus on the second task, AZPresolution, designing a model that assumes as in-put the AZPs in a document and resolves each ofthem.
Note that the task of AZP resolution alone isby no means easy: even when gold-standard AZPsare given, state-of-the-art supervised resolvers canonly achieve an F-score of 47.7% for resolvingChinese AZPs (Chen and Ng, 2013).
For the sakeof completeness, we will evaluate our AZP resolu-tion model using both gold-standard AZPs as wellas AZPs automatically identified by a rule-basedapproach that we propose in this paper.Our contribution lies in the proposal of the firstunsupervised probabilistic model for AZP resolu-tion that rivals its supervised counterparts in per-formance when evaluated on the Chinese portionof the OntoNotes 5.0 corpus.
Its main advan-tage is that it does not require training data withmanually resolved AZPs.
This, together with thefact that its underlying generative process is notlanguage-dependent, enables it to be applied tolanguages where such annotated data is not read-ily available.
At its core is a novel hypothesis:we can apply a probabilistic pronoun resolutionmodel trained on overt pronouns in an unsuper-vised manner to resolve zero pronouns.
Moti-vated by Cherry and Bergsma's (2005) and Char-niak and Elsner's (2009) work on unsupervisedEnglish pronoun resolution, we train our unsu-pervised resolver on Chinese overt pronouns us-ing the Expectation-Maximization (EM) algorithm(Dempster et al., 1977).2 Related WorkChinese ZP resolution.
Early approaches toChinese ZP resolution are rule-based.
Con-verse (2006) applied Hobbs' algorithm (Hobbs,7631978) to resolve the ZPs in the CTB documents.Yeh and Chen (2007) hand-engineered a set ofrules for ZP resolution based on Centering The-ory (Grosz et al., 1995).In contrast, virtually all recent approaches tothis task are based on supervised learning.
Zhaoand Ng (2007) are the first to employ a supervisedlearning approach to Chinese ZP resolution.
Theytrained an AZP resolver by employing syntacticand positional features in combination with a de-cision tree learner.
Unlike Zhao and Ng, Kongand Zhou (2010) employed context-sensitive con-volution tree kernels (Zhou et al., 2008) in theirresolver to model syntactic information.
More re-cently, we extended Zhao and Ng's feature set withnovel features that encode the context surroundinga ZP and its candidate antecedents, and exploitedthe coreference links between ZPs as bridges tofind textually distant antecedents for ZPs (Chenand Ng, 2013).ZP resolution for other languages.
There havebeen rule-based and supervised machine learningapproaches for resolving ZPs in other languages.For example, to resolve ZPs in Spanish texts,Ferr?ndez and Peral (2000) proposed a set of hand-crafted rules that encode preferences for candidateantecedents.
In addition, supervised approacheshave been extensively employed to resolve ZPsin Korean (e.g., Han (2006)), Japanese (e.g., Sekiet al.
(2002), Isozaki and Hirao (2003), Iida etal.
(2006; 2007), Imamura et al.
(2009), Iida andPoesio (2011), Sasano and Kurohashi (2011)), andItalian (e.g., Iida and Poesio (2011)).3 Chinese Overt PronounsSince our approach relies heavily on Chineseovert pronouns, in this section we introduce themby describing their four grammatical attributes,namely Number, Gender, Person and Ani-macy.
Number has two values, singular andplural.
Gender has three values, neuter, mascu-line and feminine.
Person has three values, first,second and third.
Finally, Animacy has two val-ues, animate and inanimate.We exploit ten personal pronouns that havewell-defined grammatical attribute values, namely?
(singular you),?
(I),?
(he),?
(she),?
(it),??
(plural you), ??
(we), ??
(masculinethey),??
(feminine they), and??
(impersonalthey).
As can be seen in Table 1, each of them canbe uniquely identified using these four attributes.Pronouns Number Gender Person Animacy?
(I) singular neuter first animate?
(you) singular neuter second animate?
(he) singular masculine third animate?
(she) singular feminine third animate?
(it) singular neuter third inanimate??
(you) plural neuter second animate??
(we) plural neuter first animate??
(they) plural masculine third animate??
(they) plural feminine third animate??
(they) plural neuter third inanimateTable 1: Attribute values of Chinese overt pronouns.4 The Generative Model4.1 NotationLet p be an overt pronoun in PR, the set of the10 overt pronouns described in Section 3.
C, theset of candidate antecedents of p, contains all andonly those maximal or modifier NPs that precedep in the associated text and are at most two sen-tences away from it.1 k is the context surround-ing p as well as every candidate antecedent c inC; kcis the context surrounding p and candidateantecedent c; and l is a binary variable indicat-ing whether c is the correct antecedent of p. Theset A = {Num,Gen, Per,Ani} has four ele-ments, which correspond to Number, Gender,Person and Animacy respectively.
a is an at-tribute in A.
Finally, paand caare the attributevalues of p and c with respect to a respectively.4.2 TrainingOur model estimates P (p, k, c, l), the probabilityof seeing (1) the overt pronoun p; (2) the contextk surrounding p and its candidate antecedents; (3)a candidate antecedent c of p; and (4) whether c isthe correct antecedent of p. Since we estimate thisprobability from a raw, unannotated corpus, we areeffectively treating p, k, and c as observed data andl as hidden data.Owing to the presence of hidden data, we es-timate the model parameters using the EM algo-rithm.
Specifically, we use EM to iteratively es-timate the model parameters from data in whicheach overt pronoun is labeled with the probabilityit corefers with each of its candidate antecedentsand apply the resultingmodel to re-label each overtpronoun with the probability it corefers with eachof its candidate antecedents.
Below we describe1Only 8% of the overt pronouns in our corpus, the Chi-nese portion of the OntoNotes 5.0 corpus, do not have anyantecedent in the preceding two sentences.764the details of the E-step and the M-step.4.2.1 E-StepThe goal of the E-step is to computeP (l=1|p, k, c), the probability that a candi-date antecedent c is the correct antecedent of pgiven context k. Assuming that exactly one of thep's candidate antecedents is its correct antecedent,we can rewrite P (l=1|p, k, c) as follows:P (l=1|p, k, c) =P (p, k, c, l=1)?c?
?CP (p, k, c?, l=1)(1)Applying Chain Rule, we can rewriteP (p, k, c, l=1) as follows:P (p, k, c, l=1) = P (p|k, c, l=1) ?
P (l=1|k, c)?
P (c|k) ?
P (k)(2)Next, given l = 1 (i.e., c is the antecedent of p),we assume that we can generate p from c withoutlooking at the context.2 Then we represent p usingits grammatical attributes A.
We further assumethat p's value with respect to attribute a ?
A isindependent of the value of each of its remainingattributes given the antecedent's value with respectto a.
So we can rewrite P (p|k, c, l=1) as follows:P (p|k, c, l=1) ?
P (p|c, l=1)?
P (pNum, pGen, pPer, pAni|c, l=1)?
?a?AP (pa|ca, l=1)(3)Moreover, we assume that (1) given p and c'scontext, the probability of c being the antecedentof p is not affected by the context of the other can-didate antecedents; and (2) kcis sufficient for de-termining whether c is the antecedent of p. So,P (l=1|k, c) ?
P (l=1|kc, c) ?
P (l=1|kc) (4)Furthermore, we assume that given context k,each candidate antecedent of p is generated withequal probability.
In other words,P (c|k) ?
P (c?|k) ?
c, c??
C (5)Given Equations (2), (3), (4) and (5), we canrewrite P (l=1|p, k, c) as:P (l=1|p, k, c) =P (p, k, c, l=1)?c?
?CP (p, k, c?, l=1)?
?a?AP (pa|ca, l=1) ?
P (l=1|kc)?c?
?C?a?AP (pa|c?a, l=1) ?
P (l=1|kc?
)(6)2This assumption is reasonable because it is fairly easy todetermine which pronoun can be used to refer to a given NP.As we can see from Equation (6), our model hastwo groups of parameters, namely P (pa|ca, l=1)and P (l=1|kc).
Since we have four grammaticalattributes, P (pa|ca, l=1) contains four sets of pa-rameters, with one set per attribute.
Using Equa-tion (6) and the current parameter estimates, wecan compute P (l=1|p, k, c).Two points deserve mention before we describethe M-step.
First, we estimate P (l=1|p, k, c) fromall and only those overt pronouns p ?
PR thatare surface or deep subjects in their correspond-ing sentences.
This condition is motivated by ourobservation that 99.56% of the ZPs in our evalu-ation corpus (i.e., OntoNotes 5.0) are surface ordeep subjects.
In other words, we impose this con-dition so that we can focus our efforts on learn-ing a model for resolving overt pronouns that aresubjects.
This is by no means a limitation of ourmodel: if we were given a corpus in which manyZPs occur as grammatical objects, we could sim-ilarly train another model on overt objects.
Sec-ond, since in the E-step we attempt to probabilisti-cally label every overt pronoun p that satisfies thecondition above, our model is effectively makingthe simplifying assumption that every overt pro-noun is anaphoric.
This is clearly an overly sim-plistic assumption.
One way to relax this assump-tion, which we leave as future work, is to first iden-tify those pronouns that are anaphoric and then useEM to estimate the joint probability only from theanaphoric pronouns.4.2.2 M-StepGiven P (l=1|p, k, c), the goal of the M-step is to(re)estimate the model parameters, P (pa|ca, l=1)and P (l=1|kc), using maximum likelihood esti-mation.
Specifically, P (pa|ca, l=1) is estimatedas follows:P (pa|ca, l=1) =Count(pa, ca, l=1) + ?Count(ca, l=1) + ?
?
|a|(7)where Count(ca, l=1) is the expected number oftimes c has attribute value cawhen it is the an-tecedent of p; |a| is the number of possible valuesof attribute a; ?
is the Laplace smoothing param-eter, which we set to 1; and Count(pa, ca, l=1)is the expected number of times p has attributevalue pawhen its antecedent c has attribute valueca.
Given attribute values p?aand c?a, we compute765Count(p?a, c?a, l=1) as follows:Count(p?a, c?a, l=1) =?p,c:pa=p?a,ca=c?aP (l=1|p, k, c)(8)Similarly, P (l=1|kc) is estimated as follows:P (l=1|kc) =Count(kc, l=1) + ?Count(kc) + ?
?
2(9)where Count(kc) is the number of times kcap-pears in the training data, and Count(kc, l=1) isthe expected number of times kcis the context sur-rounding a pronoun and its antecedent c. Givencontext k?c, we compute Count(k?c, l=1) as fol-lows:Count(k?c, l=1) =?k:kc=k?cP (l=1|p, k, c) (10)To start the induction process, we initialize allparameters with uniform values.
Specifically,P (pa|ca, l=1) is set to 1|a|, and P (l=1|kc) is setto 0.5.
Then we iteratively run the E-step and theM-step until convergence.There are two important questions we have notaddressed.
First, how can we compute the four at-tribute values of a candidate antecedent (i.e., cafor each attribute a), which we need to estimateP (pa|ca, l=1)?
Second, what features should weuse to represent context kc, which we need to esti-mate P (l=1|kc)?
We defer the discussion of thesequestions to Sections 5 and 6.4.3 InferenceAfter training, we can apply the resulting model toresolve AZPs.
Given an AZP z, we determine itsantecedent as follows:(c?, p?)
= argmaxc?C, p?PRP (l=1|p, k, c) (11)where PR is our set of 10 Chinese overt pronounsand C is the set of candidate antecedents of z. Inother words, we apply Formula (11) to eachAZP z,searching for the candidate antecedent c and overtpronoun p that maximize P (l=1|p, k, c) when p isused to fill the ZP gap left behind by z.
The c thatresults in the maximum probability value over allovert pronouns in PR is chosen as the antecedentof z.
In essence, since the model is trained onovert pronouns but is applied to ZPs, we have toexhaustively fill the ZP's gap under considerationwith each of the 10 overt pronouns in PR duringinference.Although we can now apply our generativemodel to resolve AZPs, the resolution procedurecan be improved further.
The improvement ismotivated by a problem we observed previously(Chen and Ng, 2013): an AZP and its closest an-tecedent can sometimes be far away from eachother, thus making it difficult to correctly resolvethe AZP.
To address this problem, we employ thefollowing resolution procedure in our experiments.Given a test document, we process its AZPs in aleft-to-right manner.
As soon as we resolve anAZP to a preceding NP c, we fill the correspond-ing AZP's gap with c. Hence, when we processan AZP z, all of its preceding AZPs in the associ-ated text have been resolved, with their gaps filledby the NPs they are resolved to.
To resolve z, wecreate test instances between z and its candidateantecedents in the same way as described before.The only difference is that the set of candidate an-tecedents of z may now include those NPs that areused to fill the gaps of the AZPs resolved so far.
Inother words, this incremental resolution proceduremay increase the number of candidate antecedentsof each AZP z.
Some of these additional candidateantecedents are closer to z than the original candi-date antecedents, thereby facilitating the resolutionof z.
If the model resolves z to the additional can-didate antecedent that fills the gap left behind by,say, AZP z?, we postprocess the output by resolv-ing z to the NP that z?
is resolved to.35 Attributes of Candidate AntecedentsIn this section, we describe how we determinethe four grammatical attribute values (Number,Gender, Person and Animacy) of a candidateantecedent c, as they are used to represent c whenestimating P (pa|ca, l=1) for each attribute a.5.1 ANIMACYWe determine the Animacy of a candidate an-tecedent c heuristically.
Specifically, we firstcheck the NP type of c. If c is a pronoun, we lookup its Animacy in Table 1.
If c is a named en-tity, there are two cases to consider: if c is a per-son4, we label it as animate; otherwise, we label itas inanimate.
If c is a common noun, we look upthe Animacy of its head noun in an automatically3This postprocessing step is needed because the additionalcandidate antecedents are only gap fillers.4A detailed description of our named entity recognizer canbe found in Chen and Ng (2014).766constructed word list WL.
If the head noun is notin WL, we set its Animacy to unknown.Our method for constructing WL is motivatedby an observation of measure words in Chinese:some of them only modify inanimate nouns whileothers only modify animate nouns.
For example,the nouns modified by the measure word?
are al-ways inanimate, as in???
(one piece of paper).On the other hand, the nouns modified by the mea-sure word?
are always animate, as in????
(one worker).Given this observation, we first define two lists,ManiandMinani.
Maniis a list of measure wordsthat can only modify animate nouns.
Minaniis alist of measure words that can only modify inan-imate nouns.5 There exists a special measureword in Chinese, ?, which can be used to mod-ify most of the common nouns regardless of theirAnimacy.
As a result, we remove ?
from bothlists.
After constructing Maniand Minani, we (1)parse the Chinese Gigaword corpus (Parker et al.,2009), which contains 4,370,600 documents, usingan efficient dependency parser, ctbparser6 (Qian etal., 2010), and then (2) collect all pairs of words(m,n), where m is a measure word, n is a com-mon noun, and there is a NMOD dependency re-lation between m and n. Finally, we determinethe Animacy of a given common noun n as fol-lows.
First, we retrieve all of the pairs contain-ing n. Then, we sum over all occurrences of min Mani(call the sum Cani), as well as all occur-rences of m in Minani(call the sum Cinani).
IfCani> Cinani, we label this common noun as an-imate; otherwise, we label it as inanimate.Table 2 shows the learned values ofP (pAni|cAni, l=1).
These results are consis-tent with our intuition: an animate (inanimate)pronoun is more likely to be generated froman animate (inanimate) antecedent than from aninanimate (animate) antecedent.
Note that animatepronouns are more likely to be generated thaninanimate pronouns regardless of the antecedent'sAnimacy.
This can be attributed to the fact that94.6% of the pronouns in our corpus are animate.5.2 GENDERWe determine the Gender of a candidate an-tecedent c as follows.
If c is a pronoun, we look upits Gender in Table 1.
Otherwise, we determine5We create these two lists with the help of this page:http://chinesenotes.com/ref_measure_words.htm6http://code.google.com/p/ctbparser/``````````AntecedentPronoun animate inanimateanimate 0.999 0.001inanimate 0.858 0.142unknown 0.945 0.055Table 2: Learned values of P (pAni|cAni, l=1).its Gender based on its Animacy.
Specifically,if c is inanimate, we set its Gender to neuter.Otherwise, we determine its gender by looking upa gender word list constructed by Bergsma andLin's (2006) approach.
If the word is not in thelist, we set its Gender to masculine by default.Next, we describe how the aforementioned gen-der word list is constructed.
Following Bergsmaand Lin (2006), we define a dependency path as thesequence of non-terminal nodes and dependencylabels between two potentially coreferent entitiesin a dependency parse tree.
From the parsed Chi-nese Gigaword corpus, we first collect every de-pendency path that connects two pronouns.
Foreach path P collected, we compute CL(P ), thecoreference likelihood of P , as follows:CL(P ) =NI(P )NI(P ) + ND(P )(12)where NI(P ) is the number of times P connectstwo identical pronouns, andND(P ) is the numberof times it connects two different pronouns.
As-suming that two identical pronouns in a sentenceare coreferent (Bergsma and Lin, 2006), we cansee that the larger a path's CL value is, the morelikely it is that the two NPs it connects are corefer-ent.
To ensure that we have dependency paths thatare strongly indicative of coreference relations, weconsider a dependency path P a coreferent path ifand only if CL(P ) > 0.8.Given these coreferent paths, we can computetheGender of a nounn as follows.
First, we com-pute (1) NM(n), the number of coreferent pathsconnecting n with a masculine pronoun; and (2)NF(n), the number of coreferent paths connect-ing n with a feminine pronoun.
Then, if NF(n) >NM(n), we set n's gender to feminine; otherwise,we set it to masculine.Table 3 shows the learned values ofP (pGen|cGen, l=1).
These results are con-sistent with our intuition: a pronoun is a lot morelikely to be generated from an antecedent with thesame Gender than one with a different Gender.767``````````AntecedentPronoun neuter feminine masculineneuter 0.864 0.018 0.117feminine 0.065 0.930 0.005masculine 0.130 0.041 0.828Table 3: Learned values of P (pGen|cGen, l=1).``````````AntecedentPronoun singular pluralsingular 0.861 0.139plural 0.26 0.74Table 4: Learned values of P (pNum|cNum, l=1).5.3 NUMBERWhen computing the Number of a candidate an-tecedent in English, Charniak and Elsner (2009)rely on part-of-speech information.
For example,NN and NNP denote singular nouns, whereas NNSand NNPS denote plural nouns.
However, Chi-nese part-of-speech tags do not provide such in-formation.
Hence, we need a different method forfinding theNumber of a candidate antecedent c inChinese.
If c is a pronoun, we look up itsNumberin Table 1.
If c is a named entity, its Number issingular.
If c is a common noun, we infer itsNum-ber from its string: if the string ends with?
or ismodified by a quantity word (e.g.,??,??
), cis plural; otherwise, c is singular.Table 4 shows the learned values ofP (pNum|cNum, l=1).
These results are con-sistent with our intuition: a pronoun is more likelyto be generated from an antecedent with the sameNumber than one with a different Number.5.4 PERSONFinally, we compute the Person of a candi-date antecedent c. Similar to Charniak and El-sner (2009), we set ?
(I) and ??
(we) to firstperson, ?
(singular you) and ??
(plural you)to second person, and everything else to thirdperson.
We estimate two sets of probabilitiesP (pPer|cPer, l=1), one where p and c are from thesame speaker, and the other where they are fromdifferent speakers.7 This is based on our observa-tion thatP (pPer|cPer, l=1) could be very differentin these two cases.7We employ a simple heuristic to identify the speaker ofNPs occurring in direct speech: we assume that the speakeris the subject of the speech's reporting verb.
So for example,we identify Jack as the speaker of This book in the sentence"This book is good," Jack said.``````````AntecedentPronoun first second thirdfirst 0.856 0.119 0.025second 0.219 0.766 0.016third 0.289 0.077 0.634Table 5: Learned values of P (pPer|cPer, l=1)(same speaker).``````````AntecedentPronoun first second thirdfirst 0.417 0.525 0.057second 0.75 0.23 0.02third 0.437 0.229 0.334Table 6: Learned values of P (pPer|cPer, l=1)(different speakers).Tables 5 and 6 show the learned values of thesetwo sets of probabilities.
These results are consis-tent with our intuition.
In the same-speaker case, apronoun is a lot more likely to be generated froman antecedent with the same speaker than one witha different speaker.
In the different-speaker case,a first (second) person pronoun is most likely to begenerated from a second (first) person pronoun.6 Context FeaturesTo fully specify our model, we need to describehow to represent kc, which is needed to computeP (l=1|kc).
Recall that kcencodes the context sur-rounding candidate antecedent c and the associatedpronoun p. As described below, we represent kcusing eight features, some of which are motivatedby previous work on supervised AZP resolution(e.g., Zhao and Ng (2007), Chen and Ng (2013)).Note that (1) all but feature 1 are computed basedon syntactic parse trees, and (2) features 2, 3, 6,and 8 are ternary-valued features.1.
the sentence distance between c and p;2. whether the node spanning c has an ancestorNP node; if so, whether this NP node is a de-scendant of c's lowest ancestor IP node;3. whether the node spanning c has an ancestorVP node; if so, whether this VP node is a de-scendant of c's lowest ancestor IP node;4. whether vp has an ancestor NP node, wherevp is the VP node spanning the VP that fol-lows p;5. whether vp has an ancestor VP node;768Training TestDocuments 1,391 172Sentences 36,487 6,083Words 756,063 110,034Overt Subject Pronouns 13,418 ?AZPs ?
1,713Table 7: Statistics on the training and test sets.6.
whether p is the first word of a sentence; ifnot, whether p is the first word of an IP clause;7. whether c is a subject whose governing verbis lexically identical to the verb governing p;8. whether c is the closest candidate antecedentwith subject grammatical role and is seman-tically compatible with p's governing verb; ifnot, whether c is the first semantically com-patible candidate antecedent8.Our approach to determine semantic compatibil-ity (in feature 8) resembles Kehler et al.
's (2004)and Yang et al.
's (2005) methods for computing se-lectional preferences.
Specifically, for each verband each noun that serves as a subject in ChineseGigaword, we compute their mutual information(MI).
Now, given a pronoun p and a candidate an-tecedent c in the training/test corpus, we retrievethe MI value of c and p's governing verb.
We thenconsider them semantically compatible if and onlyif their MI value is greater than zero.7 Evaluation7.1 Experimental SetupDatasets.
We employ the Chinese portion of theOntoNotes 5.0 corpus that was used in the officialCoNLL-2012 shared task (Pradhan et al., 2012).In the CoNLL-2012 data, the training set and de-velopment set contain ZP coreference annotations,but the test set does not.
Therefore, we train ourmodels on the training set and perform evaluationon the development set.
Statistics on the datasetsare shown in Table 7.
The documents in thesedatasets come from six sources, namely BroadcastNews (BN), Newswire (NW), Broadcast Conver-sation (BC), Telephone Conversation (TC), WebBlog (WB) and Magazine (MZ).8 We sort the candidate antecedents of p as follows.
Wefirst consider the subject candidate antecedents in the samesentence as p from right to left, then the other candidate an-tecedents in the same sentence from right to left.
Next, weconsider the candidate antecedents in the previous sentence,also preferring candidates that are subjects, but in left-to-rightorder.
Finally, we consider the candidate antecedents twosentences back, following the subject-first, left-to-right order.Evaluation measures.
We express the results ofZP resolution in terms of recall (R), precision (P)and F-score (F).Evaluation settings.
Following Chen and Ng(2013), we evaluate our model in three settings.In Setting 1, we assume the availability of goldsyntactic parse trees and gold AZPs.
In Setting 2,we employ gold syntactic parse trees and system(i.e., automatically identified) AZPs.
Finally, inSetting 3, we employ system syntactic parse treesand system AZPs.
The gold and system syntacticparse trees, as well as the gold AZPs, are obtainedfrom the CoNLL-2012 shared task dataset, whilethe system AZPs are identified by the rule-basedapproach described in the Appendix.9 Since ourAZP identification approach does not rely on anylabeled data, we are effectively evaluating an end-to-end unsupervised AZP resolver in Setting 3.7.2 ResultsBaseline systems.
We employ seven resolversas baseline systems.
To gauge the difficulty ofthe task, we employ four simple rule-based re-solvers, which resolve an AZP z to (1) the can-didate antecedent closest to z (Baseline 1); (2) thesubject NP closest to z (Baseline 2); (3) the clos-est candidate antecedent that is semantically com-patible with z (Baseline 3); and (4) the first can-didate antecedent that is semantically compatiblewith z, where the candidate antecedents are vis-ited according to the order described in Footnote 8(Baseline 4).
These four baselines allow us tostudy the role of (1) recency, (2) salience, (3) re-cency combined with semantic compatibility, and(4) salience combined with semantic compatibil-ity in AZP resolution respectively.
The remainingthree baselines are state-of-the-art supervised AZPresolvers, which include our own resolver (Chenand Ng, 2013) as well as our re-implementationsof Zhao and Ng's (2007) resolver and Kong andZhou's (2010) resolver.The test set results of these seven baseline re-solvers when evaluated under the three afore-mentioned evaluation settings are shown in Ta-ble 8.
The system AZPs employed by the rule-based resolvers are obtained using our rule-based9One may wonder why we do not train a supervised sys-tem for identifying AZPs and instead experiment with a rule-based AZP identification system.
The reason is that employ-ing labeled data defeats the whole purpose of having an unsu-pervised AZP resolution model: if annotated data is availablefor training an AZP identification system, the same data canbe used to train an AZP resolution system.769Setting 1: Setting 2: Setting 3:Gold Parses, Gold Parses, System Parses,Gold AZPs System AZPs System AZPsBaseline R P F R P F R P FSelecting closest candidate antecedent 25.0 25.2 25.1 18.3 10.8 13.6 10.3 6.7 8.1Selecting closest subject 42.0 43.6 42.8 31.8 19.2 23.9 18.0 11.9 14.4Selecting closest semantically compatible candidate antecedent 28.5 28.8 28.7 20.5 12.2 15.3 11.7 7.6 9.2Selecting first semantically compatible candidate antecedent 45.2 45.7 45.5 33.6 20.0 25.1 18.9 12.3 14.9Zhao and Ng (2007) 41.5 41.5 41.5 22.4 24.4 23.3 12.7 14.2 13.4Kong and Zhou (2010) 44.9 44.9 44.9 33.0 19.3 24.4 18.7 11.9 14.5Chen and Ng (2013) 47.7 47.7 47.7 25.3 27.6 26.4 14.9 16.7 15.7Table 8: AZP resolution results of the baseline systems on the test set.Setting 1: Gold Parses, Gold AZPs Setting 2: Gold Parses, System AZPs Setting 3: System Parses, System AZPsBest Baseline Our Model Best Baseline Our Model Best Baseline Our ModelSource R P F R P F R P F R P F R P F R P FOverall 47.7 47.7 47.7 47.5 47.9 47.7 25.3 27.6 26.4 35.4 21.0 26.4 14.9 16.7 15.7 19.9 12.9 15.7NW 38.1 38.1 38.1 41.7 41.7 41.7 15.5 21.7 18.1 29.8 24.8 27.0 6.0 12.2 8.0 11.9 13.0 12.4MZ 34.6 34.6 34.6 34.0 34.2 34.1 18.5 19.6 19.0 24.1 14.5 18.1 6.2 9.4 7.5 6.2 5.2 5.7WB 46.1 46.1 46.1 47.9 47.9 47.9 21.8 22.0 21.8 37.3 18.7 24.9 8.5 11.4 9.7 19.0 11.3 14.2BN 47.2 47.2 47.2 52.8 52.8 52.8 21.8 33.2 26.3 31.5 28.1 29.7 14.6 26.3 18.8 18.2 19.5 18.8BC 52.7 52.7 52.7 49.8 50.3 50.0 23.3 30.7 26.5 38.0 21.0 27.0 12.7 16.2 14.3 20.6 12.4 15.5TC 51.2 51.2 51.2 45.2 46.7 46.0 43.1 28.2 34.1 42.4 20.3 27.4 33.2 17.1 22.5 32.2 13.3 18.8Table 9: AZP resolution results of the best baseline and our unsupervised model on the test set.AZP identification system.
On the other hand,since our supervised resolvers are meant to be re-implementations of existing resolvers, we followprevious work and let them employ a supervisedAZP identification system.
In particular, we em-ploy the one described in Chen and Ng (2013).Several observations can be made about theseresults.
First, among the rule-based resolvers,Baseline 4 achieves the best performance, outper-forming Baselines 1, 2, and 3 by 12.9%, 1.5%,and 10.8% in F-score respectively when averagedover the three evaluation settings.
From theirrelative performance, which remains the same inthe three settings, we can conclude that as far asAZP resolution is concerned, (1) salience plays agreater role than recency; and (2) semantic com-patibility is useful.
Second, among the super-vised baselines, our supervised resolver (Chen andNg, 2013) achieves the best performance, outper-forming Zhao and Ng's resolver and Kong andZhou's resolver by 3.9% and 2.0% in F-score re-spectively when averaged over the three evalua-tion settings.
Finally, comparing the rule-basedresolvers and the learning-based resolvers, we cansee that the best rule-based baseline (Baseline 4)performs even better than Zhao and Ng's resolverand Kong and Zhou's resolver.In the rest of this subsection, we will compareour unsupervised model against the best baseline,Chen and Ng's (2013) supervised resolver.Our model.
Results of the best baseline and ourmodel on the entire test set and each of the sixsources are shown in Table 9.
As we can see, ourmodel achieves the same overall F-score as the bestbaseline under all three settings, despite the factthat it is unsupervised.
In fact, our model even out-performs the best baseline on NW, WB and BN inSetting 1, NW, WB, BN and BC in Setting 2, andNW, WB and BC in Setting 3.It is worth mentioning that while the two re-solvers achieved the same overall performance,their outputs differ a lot from each other.
Specifi-cally, the twomodels only agree on the antecedentsof 55% of the AZPs in Setting 1.107.3 Ablation ExperimentsImpact of P (pa|ca, l=1) and P (l=1|kc).
Re-call that our model is composed of five probabilityterms,P (pa|ca, l=1) for each of the four grammat-ical attributes and P (l=1|kc), the context proba-bility.
To investigate the contribution of contextand each attribute to overall performance, we con-duct ablation experiments.
Specifically, in eachablation experiment, we remove exactly one prob-ability term from the model and retrain it.10Note that it is difficult to directly compare the outputsproduced under Settings 2 and 3: the AZPs identified by thebest baseline are quite different from those identified by ourrule-based system, as can be inferred from the AZP identifi-cation results in Table 12.770Setting 1 Setting 3System R P F R P FFull model 47.5 47.9 47.7 19.9 12.9 15.7?
Number 47.5 47.9 47.7 19.7 12.8 15.5?
Gender 44.5 45.0 44.7 19.2 12.5 15.1?
Person 45.2 45.6 45.4 19.1 12.4 15.1?
Animacy 45.1 45.5 45.3 19.1 12.4 15.1?
Context Features 32.9 33.1 33.0 15.2 9.8 11.9Table 10: Probability term ablation results.Ablation results under Settings 1 and 3 areshown in Table 10.
As we can see, under Set-ting 1, afterNumber is ablated, performance doesnot drop.
We attribute this to the fact that al-most all candidate antecedents are singular.
On theother hand, when we ablate any of the remainingthree attributes, performance drops significantlyby 2.3?3.0% in overall F-score.11 Similar trendscan be observed with respect to Setting 3: afterNumber is ablated, performance only decreasesby 0.2%, while ablating any of the other three at-tributes results in a drop of 0.6%.Results after ablating context are shown in thelast row of Table 10.
As we can see, the F-scoredrops significantly by 14.7% and 3.8% under Set-tings 1 and 3 respectively.
These results illustratethe importance of context features in our model.Context feature ablation.
Recall that we em-ployed eight context features to encode the rela-tionship between a pronoun and a candidate an-tecedent.
To determine the relative contributionof these eight features to overall performance,we conduct ablation experiments under Settings 1and 3.
In these ablation experiments, all four gram-matical attributes are retained in the model.Ablation results are shown in rows 2?9 of Ta-ble 11.
To facilitate comparison, the F-score of themodel in which all eight context features are usedis shown in row 1.
As we can see, feature 8 (therule-based feature) is the most useful feature: itsremoval causes the F-scores of our resolver to dropsignificantly by 6.4% under Setting 1 and 1.5% un-der Setting 3.7.4 Error AnalysisTo gain additional insights into our full model, weexamine its major sources of error below.
To focuson errors attributable to AZP resolution, we ana-lyze our full model under Setting 1.Specifically, we randomly select 100 AZPs thatour model incorrectly resolves under Setting 1.11All significance tests are paired t-tests, with p < 0.05.Setting 1 Setting 3System R P F R P FFull model 47.5 47.9 47.7 19.9 12.9 15.7?
Feature 1 46.1 46.5 46.3 19.4 12.6 15.3?
Feature 2 46.5 46.9 46.7 19.4 12.6 15.3?
Feature 3 45.3 45.7 45.5 19.1 12.4 15.1?
Feature 4 47.4 47.8 47.6 20.1 13.0 15.8?
Feature 5 47.4 47.8 47.6 19.7 12.8 15.5?
Feature 6 47.1 47.5 47.3 19.6 12.7 15.4?
Feature 7 47.1 47.5 47.3 20.1 13.0 15.8?
Feature 8 41.2 41.6 41.4 18.0 11.8 14.2Table 11: Context feature ablation results.We found that 17 errors are attributable to dis-course disfluency, lack of background knowledgeand subject detection, while the remaining 83 er-rors can be divided into three types:Failure to recognize the topics of a document.Our model incorrectly resolves 32 AZPs that arecoreferent with NPs corresponding to the topics ofthe associated documents.
Consider the followingexample:[???]????????????????????*pro*?????????????
([Bali Town] is located in the Northwest of TaipeiBasin.
Its administrative area is affiliated withTaipei County, *pro* is one of Taipei County's 29towns and cities.
)12The model incorrectly resolves the AZP *pro*to???
(Its administrative area).
The reason isthat the correct antecedent, ???
(Bali Town),is far from *pro*: there are five candidate an-tecedents between *pro* and???
(Bali Town).Note, however, that it is easy for a human to re-solve *pro* to ???
(Bali Town) because thewhole passage is discussing???
(Bali Town).Hence, to correctly handle such cases, one mayconstruct a topic model over the passage and as-sign each candidate antecedent a prior probabilityso that the resulting system favors the selection ofcandidates representing the topics as antecedents.Errors in computing semantic compatibility.This type of error contributes to 28 of the incor-rectly resolved AZPs.
When computing seman-tic compatibility in our model, we only considerthe mutual information between a candidate an-tecedent and the pronoun's governing verb, but insome cases, additional context needs to be takeninto account.
Consider the following example:12The pronoun Its in the phrase Its administrative area isinserted into the English translation for the sake of grammat-icality and correct understanding of the sentence.
The corre-sponding Chinese phrase does not contain any pronoun.771[???????]????
[24??????????]?*pro*??????????
([Marines] killed about [24 unarmed Iraqis], *pro*include women and six children.
)There are two candidate antecedents in this ex-ample,???????
(Marines) and 24??????????
(24 unarmed Iraqis), which wedenote as c1and c2respectively.
The correct an-tecedent of *pro* is c2, while our model wronglyresolves *pro* to c1.
Note that both c1and c2arecompatible with the AZP's governing verb ??(include).
However, if the object of the govern-ing verb, i.e., ???????
(women and sixchildren), were also considered, the model coulddetermine that c1is not compatible with the objectwhile c2is, and then correctly resolve *pro* to c2.Failure to recognize and exploit semanticallysimilar sentences.
This type of error contributesto 23 wrongly resolved AZPs.
Recall that an AZPis omitted for brevity, so the sentence it appears inoften expresses similar meaning to an earlier sen-tence.
However, our model fails to handle suchcases.
Consider the following example:[?????????]?????????.....*pro*???????
([The command and the onrush of troops] lost con-nection with each other.
... *pro* cannot connectwith each other.
)The above example shows two sentences thatare separated by some other sentences.
The AZPunder consideration is in the last sentence, whilethe first sentence contains the correct antecedent?????????
(the command and the on-rush troops), denoted as c1.
Our model fails to re-solve *pro* to c1, because there are many com-peting candidate antecedents between c1and AZP.However, if our model were aware of the similaritybetween the constructions appearing after c1and*pro*, i.e., ????????
(lost connectionwith each other) and??????
(cannot con-nect with each other), then it might be able to cor-rectly resolve the AZP.8 ConclusionWe proposed an unsupervised model for Chinesezero pronoun resolution, investigating the novelhypothesis that an unsupervised probabilistic re-solver trained on overt pronouns can be applied toresolve ZPs.
To our knowledge, this is the first un-supervised probabilistic model for this task.
Ex-periments on the OntoNotes 5.0 corpus showedthat our unsupervised model rivaled its state-of-the-art supervised counterparts in performance.AcknowledgmentsWe thank the three anonymous reviewers for theirdetailed comments.
This work was supported inpart by NSF Grants IIS-1147644 and IIS-1219142.ReferencesShane Bergsma and Dekang Lin.
2006.
Bootstrappingpath-based pronoun resolution.
In Proceedings ofthe 21st International Conference on ComputationalLinguistics and the 44th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 33--40.Eugene Charniak and Micha Elsner.
2009.
EM worksfor pronoun anaphora resolution.
In Proceedingsof the 12th Conference of the European Chapterof the Association for Computational Linguistics,pages 148--156.Chen Chen and Vincent Ng.
2013.
Chinese zero pro-noun resolution: Some recent advances.
In Proceed-ings of the 2013 Conference on Empirical Methodsin Natural Language Processing, pages 1360--1365.Chen Chen and Vincent Ng.
2014.
SinoCorefer-encer: An end-to-end Chinese event coreferenceresolver.
In Proceedings of the 9th InternationalConference on Language Resources and Evaluation,pages 4532--4538.Colin Cherry and Shane Bergsma.
2005.
An expecta-tion maximization approach to pronoun resolution.In Proceedings of the Ninth Conference on NaturalLanguage Learning, pages 88--95.Susan Converse.
2006.
Pronominal Anaphora Resolu-tion in Chinese.
Ph.D. thesis, University of Pennsyl-vania.Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-bin.
1977.
Maximum likelihood from incompletedata via the EM algorithm.
Journal of the Royal Sta-tistical Society.
Series B (Methodological), 39:1--38.Antonio Ferr?ndez and Jes?s Peral.
2000.
A compu-tational approach to zero-pronouns in Spanish.
InProceedings of the 38th Annual Meeting on Associa-tion for Computational Linguistics, pages 166--172.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1995.
Centering: A framework for model-ing the local coherence of discourse.
ComputationalLinguistics, 21(2):203--226.Na-Rae Han.
2006.
Korean Zero Pronouns: Analysisand Resolution.
Ph.D. thesis, University of Pennsyl-vania.Jerry Hobbs.
1978.
Resolving pronoun references.Lingua, 44:311--338.772Ryu Iida and Massimo Poesio.
2011.
A cross-lingualILP solution to zero anaphora resolution.
In Pro-ceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics: Human Lan-guage Technologies, pages 804--813.Ryu Iida, Kentaro Inui, andYujiMatsumoto.
2006.
Ex-ploiting syntactic patterns as clues in zero-anaphoraresolution.
In Proceedings of the 21st InternationalConference on Computational Linguistics and the44th Annual Meeting of the Association for Compu-tational Linguistics, pages 625--632.Ryu Iida, Kentaro Inui, and Yuji Matsumoto.
2007.Zero-anaphora resolution by learning rich syntacticpattern features.
ACM Transactions on Asian Lan-guage Information Processing, 6(4).Kenji Imamura, Kuniko Saito, and Tomoko Izumi.2009.
Discriminative approach to predicate-argument structure analysis with zero-anaphora res-olution.
In Proceedings of the ACL-IJCNLP 2009Conference Short Papers, pages 85--88.Hideki Isozaki and Tsutomu Hirao.
2003.
Japanesezero pronoun resolution based on ranking rules andmachine learning.
In Proceedings of the 2003 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 184--191.Andrew Kehler, Douglas Appelt, Lara Taylor, andAleksandr Simma.
2004.
The (non)utility ofpredicate-argument frequencies for pronoun inter-pretation.
In Proceedings of 2004 Human Lan-guage Technology Conference of the North Ameri-can Chapter of the Association for ComputationalLinguistics, pages 289--296.Fang Kong and GuoDong Zhou.
2010.
A tree kernel-based unified framework for Chinese zero anaphoraresolution.
In Proceedings of the 2010 Conferenceon EmpiricalMethods in Natural Language Process-ing, pages 882--891.Robert Parker, David Graff, Ke Chen, Junbo Kong, andKazuaki Maeda.
2009.
Chinese Gigaword fourthedition.
Linguistic Data Consortium.
Philadelphia,PA.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 shared task: Modeling multilingual unre-stricted coreference in OntoNotes.
In Proceedings of2012 Joint Conference on EmpiricalMethods in Nat-ural Language Processing and Computational Nat-ural Language Learning: Shared Task, pages 1--40.Xian Qian, Qi Zhang, Xuangjing Huang, and Lide Wu.2010.
2d trie for fast parsing.
In Proceedings ofthe 23rd International Conference on ComputationalLinguistics, pages 904--912.Ryohei Sasano and Sadao Kurohashi.
2011.
A dis-criminative approach to Japanese zero anaphora res-olution with large-scale lexicalized case frames.
InProceedings of the 5th International Joint Confer-ence on Natural Language Processing, pages 758--766.Kazuhiro Seki, Atsushi Fujii, and Tetsuya Ishikawa.2002.
A probabilistic method for analyzing Japaneseanaphora integrating zero pronoun detection and res-olution.
In Proceedings of the 19th InternationalConference on Computational Linguistics.Xiaofeng Yang, Jian Su, and Chew Lim Tan.
2005.
Im-proving pronoun resolution using statistics-based se-mantic compatibility information.
In Proceedings ofthe 43rd Annual Meeting of the Association for Com-putational Linguistics, pages 165--172.Ching-Long Yeh and Yi-Chun Chen.
2007.
Zeroanaphora resolution in Chinese with shallow pars-ing.
Journal of Chinese Language and Computing,17(1):41--56.Shanheng Zhao and Hwee Tou Ng.
2007.
Identifica-tion and resolution of Chinese zero pronouns: A ma-chine learning approach.
In Proceedings of the 2007Joint Conference on Empirical Methods on Natu-ral Language Processing and Computational Natu-ral Language Learning, pages 541--550.GuoDong Zhou, Fang Kong, and Qiaoming Zhu.
2008.Context-sensitive convolution tree kernel for pro-noun resolution.
In Proceedings of the 3rd Interna-tional Joint Conference on Natural Language Pro-cessing, pages 25--31.Appendix: Automatic AZP IdentificationOur automatic AZP identification system employsan ordered set of rules.
The first rule is a positiverule that aims to extract as many candidate AZPsas possible.
It is followed by seven negative rulesthat aim to improve precision by filtering out er-roneous candidate AZPs.
Below we first describethe rules and then evaluate this rule-based system.Rule 1.
Add candidate AZP z if it occurs beforethe leftmost word spanned by a VP node vp.Rule 2.
Remove z if its associated vp is in a coor-dinate structure or modified by an adverbial node.Rule 3.
Remove z if the parent of its associatedvp node is not an IP node.Rule 4.
Remove z if its associated vp has a NPor QP node as an ancestor.Rule 5.
Remove z if one of the left sibling nodesof vp is NP, QP, IP or ICP.Rule 6.
Remove z if (1) z does not begin a sen-tence, (2) the highest node whose spanning wordsequence ends with the left non-comma neighborword of z is either NP, QP or IP, and (3) the parentof this node is VP.773Gold Parses System ParsesSystems R P F R P FRule-based 72.4 42.3 53.4 42.3 26.8 32.8Supervised 50.6 55.1 52.8 30.8 34.4 32.5Table 12: AZP identification results on the test set.Rule 7.
Remove z if vp's lowest IP ancestor has(1) a VP node as its parent and (2) a VV node asits left sibling.Rule 8.
Remove z if it begins a document.To gauge the performance of our rule-basedAZP identification system, we compare it with oursupervised AZP identification system (Chen andNg, 2013).
Results of the two systems on our testset are shown in Table 12.
As we can see, the F-scores achieved by the rule-based system is com-parable to those of the supervised system.774
