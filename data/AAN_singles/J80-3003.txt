A Plan-Based Analysis of Indirect Speech Acts 1C.
Raymond Per rau l tDepar tment  of Computer  ScienceUniversity of TorontoToronto,  Canada M5S 1A7James  F. A l lenDepar tment  of Computer  ScienceUniversity of RochesterRochester,  New York 14627We propose an account of indirect forms of speech acts to request and inform basedon the hypothesis that language users can recognize actions being performed by others,infer goals being sought, and cooperate in their achievement.
This cooperative behaviour isindependently motivated and may or may not be intended by speakers.
If the hearerbelieves it is intended, he or she can recognize the speech act as indirect; otherwise it isinterpreted directly.
Heuristics are suggested to decide among the interpretations.1.
IntroductionAustin \[1962\] was one of the first to stress thedistinction between the action(s) which a speaker per-forms by uttering a sentence (such as informing, re-questing, or convincing) and the truth conditions ofpropositions contained in the sentence.
Actions haveeffects on the world, and may have preconditionswhich must obtain for them to be felicitously per-formed.
For actions whose execution involves the useof language (or speech acts), the preconditions mayinclude the speaker holding certain beliefs about theworld, and having certain intentions or wants as tohow it should change.As well as being important o the study of naturallanguage semantics, speech acts are important o thedesigner of conversational natural language under-standing systems.
Such systems should be able torecognize what actions the user is performing.
Con-versely, if such a system is to acquire information orrequest assistance from its user, it should know howand when to ask questions and make requests.
(SeeBruce \[1975\] for an early attempt.
)Cohen and Perrault \[1979\] (hereafter referred to asCP) argue for the distinction between a competencet This research was supported in part by the National Re-search Council of Canada under Operating Grant A9285.
Thanksto Phil Cohen, Michael McCord, Corot Reason, and John Searle fortheir comments.
We assume the usual responsibility for remaininginaccuracies, misunderstandings, anddownright errors.theory of speech acts, which characterizes what utter-ances an ideal speaker can make in performing whatspeech acts, and a performance theory which also ac-counts for how a particular utterance is chosen in giv-en circumstances, or how it is recognized.
We areonly concerned here with a competence theory.In Perrault, Allen, and Cohen \[1978\] we suggestedthat it is useful to consider speech acts in the contextof a planning system.
A planning system consists of aclass of parameterized procedures called operators,whose execution can modify the world.
Each operatoris labelled with formulas stating its preconditions andeffects.
A plan construction algorithm is a procedurewhich, given a description of some initial state of theworld and a goal state to be achieved, constructs aplan, or sequence of operators, to achieve it.It is assumed there, and in all our subsequent work,that language users maintain a model of the world(their beliefs) and a set of goals (their wants).
Oneperson S's beliefs may include beliefs about anotherperson A's beliefs and wants, including A's beliefsabout S, etc.
We do not concern ourselves with obli-gations, feelings, etc., which clearly can also be affect-ed by speech acts.CP discuss criteria for judging the correctness ofthe preconditions and effects of the operators corre-sponding to speech acts, and specifically those of theacts INFORM and REQUEST.
However, the condi-tions on INFORM and REQUEST given in CP are atbest necessary and certainly not sufficient.
In particu-Copyright 1980 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial dvantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires afee and/or specific permission.0362-613X/80/030167-16501.00American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 167C.
Raymond Perrault and James F. Al len A Plan-Based Analysis of Indirect Speech Actslar they say nothing about the form of utterances usedto perform the speech acts.
Several syntactic devicescan be used to indicate the speech act being per-formed: the most obvious are explicit performativeverbs such as "I hereby request you to ...", and mood(indicative for assertions, imperative for requests todo, interrogative for requests to inform).
But themood of an utterance is well known to not completelyspecify its illocutionary force: 1.a-b can be requests toclose the door, 1.c-e can be requests to tell the an-swer, and 1.f can be an assertion.
(1.a) I want you to close the door.
(1.b) Will you close the door?
(1.c) Tell me the answer.
(1.d) I want you to tell me the answer.
(1.e) Do you know what the answer is?
(1.f) Do you know that Jack is in town?Furthermore, all these utterances can also be intendedliterally in some contexts.
For example, a parent leav-ing a child at the train station may ask 1.g expecting ayes /no  answer as a confirmation.
(1.g) Do you know when the train leaves?The object of this paper is to extend the work inCP to account for indirect use of mood, loosely calledindirect speech acts.
The solution proposed here isbased on the following intuitively simple and inde-pendently motivated hypotheses:(1) Language users are rational agents engaged ingoal seeking behaviour.
Among these goalsare the modification of the beliefs and goalsof other agents.
(2) Rational agents are frequently capable ofidentifying actions being performed by othersand goals being sought.
An essential part ofhelpful or cooperative behaviour is the adop-tion by one agent of a goal of another, fol-lowed by an attempt o achieve it.
For exam-ple, for a store clerk to reply "How many doyou want?"
to a customer who has asked"Where are the steaks?
", the clerk must haveinferred that the customer wants steaks, thenhe must have decided to get them himself.This might have occurred even if the customerhad intended to get the steaks him or herself.Cooperative behaviour must be accounted forindependently of speech acts, for it often oc-curs without the use of language.
(3) In order for a speaker to successfully performa speech act, he must intend that the hearerrecognize his intention to achieve the effectsof the speech act, and must believe it is likelythat the hearer will be able to do so.
This isthe foundation for the philosophical accountof speech acts.
(4) Language users know that others are capableof achieving goals, of recognizing actions, andof cooperative behaviour.
Furthermore, theyknow that others know they know, etc.
Aspeaker may intend not only that his actionsbe recognized but also that his goals be infer-red.
(5) Thus a speaker can perform one speech act Aby performing another speech act B if he in-tends that the hearer recognize not only thatB was performed but also that through coop-erative behaviour by the hearer, intended bythe speaker, the effects of A should beachieved.
The speaker must also believe thatit is likely that the hearer can recognize thisintention.The process by which one agent can infer the plansof another is central to our account of speech acts.Schmidt et al\[1978\] and Genesereth \[1978\] presentalgorithms by which one agent can infer the goals ofanother, but assuming no interaction between the two.We describe the process in terms of a set of plausibleplan inference rules directly related to the rules bywhich plans can be constructed.
Let A and S be twoagents and ACT an action.
One example of a simpleplan inference rule is:"If S believes that A wants to do ACT thenit is plausible that S believes that A wants toachieve the effects of ACT.
"From simple rules like this can be derived more com-plex plan inference rules such as:"If S believes that A wants S to recognizeA's intention to do ACT, then it is plausiblethat S believes that A wants S to recognizeA's intention to achieve the effects of ACT.
"Notice that the complex rule is obtained by introduc-ing "S believes A wants" in the antecedent and conse-quent of the simple rule, and by interpreting "S recog-nizes A's intention" as "S comes to believe that Awants".
Throughout the paper we identify "want"and "intend".We show that rules of the second type can accountfor S's recognition of many indirect speech acts by A,i.e.
those in which S recognizes A's intention that Sperform cooperative acts.To distinguish the use of, say, the indicative mood,in an assertion from its use in, say, an indirect request,the speech act operators REQUEST and INFORM ofCP are reformulated and two further acts S.REQUESTand S.INFORM are added.
These surface level actsare realized literally as indicative and imperative utter-ances.
An S.REQUEST to INFORM is realized as aquestion.
The surface level acts can be recognizedimmediately as parts of the higher level (or illocution-ary level) acts, to which the simple plan construction168 American Journal of Computational Linguistics, Volume 6, Number 3?4, Ju ly-December 1980C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech Actsand inference rules can apply.
Alternatively, the com-plex rules can be applied to the effects of the surfaceacts, and the intended performance of one of the illo-cutionary acts inferred later.For example, there are two ways an agent S couldbe led to tell A the secret after hearing A tell him"Can you tell me the secret?".
Both start with S'srecognition that A asked a yes/no question.
In thefirst case, S assumes that A simply wanted to knowwhether S could tell the secret, then infers that A infact wants to know the secret and, helpfully, decidesto tell it.
In the second case S recognizes that Aintends S to infer that A wants to know the secret andthat A intends S to tell A the secret, and thus that Ahas requested S to tell the secret.In general, several of the plan inference rules couldapply at any time, and none of them guarantees a validconsequence.
The application of the rules is con-trolled by a set of heuristics which rate the plausibilityof the outcomes.Following a review of the relevant aspects ofspeech act theory in section 2, section 3 outlines ourassumptions about beliefs, goals, actions, plans, andthe plan inference process.
Section 4 shows how thespeech act definitions and the plan inference processcan be used to relate literal to indirect meanings forREQUESTs and INFORMs.
We show how utterancessuch as 1.h-l, and even 1.m can be used as requests topass the salt, and what the origin of the several inter-pretations of 1.m is.
(1.h) I want you to pass the salt.
(1.i) Do you have the salt?
(1.j) Is the salt near you?
(1.k) I want the salt.
(1.1) Can you pass the salt?
(1.m) John asked me to ask you to pass the salt.Similarly we show how 1.n can be used to informwhile 1.o cannot.
Section 5 relates this work to theliterature, while section 6 suggests further problemsand draws some conclusions.
(1,n) Do you know that the train is late?
(1.o) Do you believe that the train is late?The speech act recognition process described herehas been implemented as a computer program andtested by having it simulate an information clerk at arailway station.
This domain is real, but sufficientlycircumscribed so that interchanges between clerk andpatrons are relatively short and are directed towards alimited set of goals.
The program accepts as inputsimple English sentences, parses them using an ATNparser, and produces as output the speech act(s) itrecognized and their associated propositional contents.It can handle all the examples discussed here.
Detailsof the implementation can be found in Allen \[1979\].2.
Introduction to Speech Acts2.1.
Basic Definit ionsPrior to Austin \[1962\], logicians considered themeaning of a sentence to be determined only by itstruth value.
However,  Austin noted that some sen-tences cannot be classified as true or false; the utter-ance of one of these sentences constitutes the per-formance of an action, and hence he named themperformatives.
To quote Austin: "When I say, beforethe register or altar, etc., 'I do', I am not reporting ona marriage: I am indulging in it".Examples like this, and his inability to rigorouslydistinguish performative sentences from those whichpurportedly have truth value (which he calledconstatives) led Austin to the view that all utterancescould be described as actions, or speech acts.
He clas-sified speech acts into three classes, the locutionary,illocutionary, and perlocutionary acts.A locutionary act is an act of saying something: itis the act of uttering sequences of words drawn fromthe vocabulary of a given language and conforming toits grammar.An illocutionary act is one performed in making anutterance; "promise", "warn",  " inform" and "request"are names of illocutionary acts.
In general, any verbthat can complete the sentence "I hereby <verb> you{that I to} ..." names an illocutionary act.
An utter-ance has illocutionary force F if the speaker intends toperform the illocutionary act F by making that utter-ance.
Verbs that name types of il locutionary acts arecalled performative verbs.
From now on, we takespeech acts to mean the illocutionary acts.Perlocutionary acts are performed by making theutterance.
For example, S may scare A by warning A,or convince A of something by informing A of it.
Thesuccess of a perlocutionary act is typically beyond thecontrol of the speaker.
For example, S cannot con-vince A of something against A's will, S can only pres-ent A with sufficient evidence so that A will decide tobelieve it.
Perlocutionary acts may or may not beintentional.
For  instance, S may or may not intend toscare A by warning A.Searle \[1969\] suggests that illocutionary acts can bedefined by providing, for each act, necessary and suf-ficient conditions for the successful performance ofthe act.
Certain syntactic and semantic devices, suchas mood and explicit performative verbs, are used toindicate iUocutionary force.One of the conditions included in Searle's accountis that the speaker performs an illocutionary act only ifhe intends that the hearer recognize his intention toperform the act, and thereby recognize the illocution-ary force.
This is important for it links Austin's workAmerican Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 169C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech Actson speech acts with the work of Grice on meaning,and is discussed in the next section.2.2.
Communicat ion  and the Recognit ion of In tent ionMany philosophers have noted the relationshipbetween communication (or speaker meaning) and therecognition of intention (Grice \[1957, 1968\], Strawson\[1964\], Searle \[1969\], Schiffer \[1972\].)
Grice presentsinformally his notion of a speaker meaning somethingas follows:" 'S meant something by x' is (roughly)equivalent o 'S intended the utterance of xto produce some effect in an audience bymeans of the recognition of this intention'"In other words, in order for S to communicate Mby uttering x to A, S must get A to recognize that Sintended to communicate M by uttering x.
To use andexample of Grice's, if I throw a coin out the windowexpecting a greedy person in my presence to run outand pick it up, I am not necessarily communicating tohim that I want him to leave.
For me to have success-fully communicated, he must at least have recognizedthat I intended him to leave.
The same argumentshold when discussing illocutionary acts.
For example,the only way S can request A to do ACT is to get Ato recognize S's intention to request A to do ACT.2.3.
The Indirect Speech Act ProblemThe relation between speech acts and the devicesused to indicate them is complicated by the fact thatperformative verbs are seldom present and the samedevice can be used to perform many illocutionary acts.The interrogative mood, for example, can be used torequest: "Can you pass the salt?
"question: "Do you know the time?
"inform: "Do you know that Sam got married?
"warn: "Did you see the bear behind you?
"promise: "Would I miss your party?
"As many authors have pointed out, an utteranceconveys its indirect il locutionary force by virtue of itsliteral one (Searle \[1975\], Morgan \[1977\], Morgan\[1978\]). "
I t 's  cold here" can function as a request o,say, close the window, in part because it's an assertionthat the temperature is low.Most of the literature on the treatment of indirectspeech acts within the theory of grammar stems fromthe work of Gordon and Lakof f  \[1975\] (hereafterGL).
They claim that direct and indirect instances ofthe same speech act have different "meanings",  i.e.different logical forms, and they propose a set of"conversat ional  postulates" by which literal forms"entai l" indirect ones.
The postulates for requestscorrespond to conditions that must obtain for a re-quest to be sincere.
For A to sincerely request B todo ACT, the following sincerity conditions must hold:(1) A wants ACT.
(2) B can do ACT.
(3) B is willing to do ACT.
(4) B will not do ACT in the absenceof the request.They then propose that one can convey a requestby asserting a speaker-based sincerity condition(condition 1), or querying a hearer-based sinceritycondition (conditions 2-4).The postulates for indirect requests given in GL  donot account for the readings of 2.3a and 2.3b as re-quests, and although more rules could be added (andsome should be weakened) we believe this solution tobe misguided.
(2.3a) Is the salt near you?
(2.3b) John asked me to ask you to pass the salt.GL 's  postulates directly relate the literal form ofone speech act to the indirect form of another.
Thusthey do not predict why certain acts allow certain indi-rect forms.
For example, the postulates do not ac-count for why 2.3c-d can be requests while 2.3e-fcannot.
But 2.3e is infelicitous as a (literal) questionsince there is no context where one can acquire infor-mation by querying one's own mental state.
Utterance2.3f is a reasonable question but even if the speakerfound out the answer, it would not get him any closerto acquiring the salt (by having the hearer pass it).
Atheory of indirect speech acts should capture thesefacts; GL 's  does not (although they agree it should).
(2.3c) I want the salt.
(2.3d) Do you want to pass the salt?
(2.3e) Do I want the salt?
(2.3f) Does he want to pass the salt?Similarly, GL 's  postulates fail to explain the rela-tion between indirect forms of different speech acts.For example, 2.3g can be an assertion that P and 2.3hcannot, for the same reasons that 2.3i can be a requestto do A and 2.3j cannot.
(2.3g) I want you to know that P.(2.3h) Do I want you to know that P?
(2.3i) I want you to A.
(2.3j) Do I want you to A?The hearer's knowing that P obtains is an intendedperlocutionary effect of an informing act, just as thehearer's doing an act A is an intended effect of a re-quest.
A speaker can indirectly inform or request byinforming the hearer that the speaker desires the per-locutionary effect of that act, and intending that thehearer recognize the speaker's intention that the perlo-cutionary effect should be achieved.This paper shows that what GL  achieve with theirpostulates can be derived from the five hypothesesgiven in the Introduction.
Our proposal here is a de-170 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech Actsvelopment of Searle \[1975\].
It requires eparating thesurface form conditions completely from the defini-tions of the illocutionary acts and introducing an inter-mediary level, the surface acts.Our theory of indirection will however share withGL some problems brought up by Sadock \[1970\],Green \[1975\], and Brown \[1980\].
These are discussedfurther in section 4.5.3.
Plans, Plan Construction, and Plan Inference.Our analysis of indirect REQUESTs and INFORMsrelies on the inference by the hearer of some of thegoals of the speaker and of some of the actions whichthe speaker is taking to achieve those goals.
Section3.1 outlines the form of the models of the world whichlanguage users are assumed to have, in particular theirbeliefs about the world (and about other agents), andtheir goals.
In section 3.2 we define actions and howthey affect the belief model.
The rules for plan con-struction and inference are considered in sections 3.3and 3.4.
Because of space limitations, this section isvery sketchy.
More detail, motivation, and problems,are available in Allen \[1979\] and Allen and Perrault\[19801.3.1.
Beliefs, Knowledge, and Goals3.1.1.
The Belief ModelWe assume that every agent S has a set of beliefsabout the world, which may include beliefs about oth-er agents' beliefs.
Agents can hold false beliefs.
AsQuine \[1956\] pointed out, belief creates a contextwhere substitution of coreferential expressions neednot preserve truth-value.We add to a first-order language with equality theoperator B, and B(A,P) (usually written BA(P)) is tobe read "A believes that P", for any formula P. TheB operator is assumed to satisfy the following axiomschemas (inspired by Hintikka \[1962\]), where P and Qare schema variables ranging over propositions, and Aranges over agents:(B.0) all theorems of First Order Predicate Calculus(B.1) BA(P ) -~ BA(BA(P))(B.2) BA(P ) ^ BA(Q ) ~.~ BA(P ^ Q)(B.3) BA(P) v BA(Q) ~ BA(P v Q)(B.4) BA(~P) ~ ~BA(P)(B.5) (3x) BA(P(x)) =~ BA((~x)P(x))(B.6) (BA(P =~ Q) A BA(P)) ~-~ BA(Q)The rules of inference are Modus Ponens and:If T is a theorem, then BA(T ) is atheorem, for every agent A.i.e.
every agent believes every valid consequence ofthe logical axioms.The partial deduction system used in the implemen-tation of Allen \[1979\] is based on Cohen \[1978\].
Thefoundations for a more elaborate system can be foundin Moore \[1979\].3.1.2.
KnowingThe word "know" is used in at least three differentsenses in English.
One may know that a proposition Pis true, know whether a proposition P is true or knowwhat the referent of a description is.We define "A knows that P", written KNOW(A,P),as P ^ BA(P).
This is weaker than some definitions of"know" in the philosophical literature, where, amongother things, "A knows that P" entails that A believesP for the "right reasons"; i.e.
knowledge is true andjustified belief (Ayer \[1956\], but see also Gettier\[1963\]).
If S believes that A knows that P, S is com-mitted to believing that P is true.Unfortunately, the meaning of "A does not knowthat P" is not captured by ~(P a BA(P)), but by theweaker (P ^ ~BA(P)), i.e.~KNOW(A,P) -= P A ~BA(P )In other words, if S believes A does not know P, thenS must believe that P is true in addition to believingthat A does not believe P is true.
This problem isanalogous to the wide/narrow scope distinction thatRussell found in his account of definite descriptions(Russell \[1919\]).
One solution to this problem is toconsider KNOW as a "macro" whose expansion issensitive to negation.
Details may be found in Allen\[1979\].A knows whether a proposition P is true if AKNOWs that P or A KNOWs that ~P.KNOWlF(A,P) -= KNOW(A,P) v KNOW(A,~p)Knowing what the referent of a description is re-quires quantification i to belief.
One of its argumentsis a formula with exactly one free variable.KNOWREF(A,P(x))(\]y) ((Vz) P(z) --- y= z)^ BA((Vz ) P(z) ~ y = z)A KNOWREF the departure time of TRAIN1 ifTRA IN1 has a unique departure time y, and if A be-lieves that y is TRAINI 's unique departure time.3.1.3.
Want ingWe let W(A,P) (usually written WA(P)) mean"agent A wants P to be true".
P can be either a stateor the execution of some action.
In the latter case, ifACT is the name of an action, WA(ACT(b)) means"A wants b to do ACT".The logic of want is even more difficult than thatof belief.
It is necessary for us to accept he follow-ing:American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 171C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech Acts(W.1) WA(P ) ~- BA(WA(P)).
(W.2) WA(P ^ Q) ~.~ WA(P ) A WA(Q).The most interesting interactions between the beliefand want operators come from the models that agentshave of each other's abilities to act and to recognizethe actions of others.
This will be further discussed inthe following section.3.2.
Act ions  and PlansActions model ways of changing the world.
Aswith the operators in STRIPS (Fikes and Nilsson\[1971\]), the actions can be grouped into families rep-resented by action schemas, which can be viewed asparameterized procedure definitions.
An action sche-ma consists of a name, a set of parameters with con-straints and a set of labelled formulas in the followingclasses:Effects: Conditions that become true after theexecution of the procedure.Body: a set of partially ordered goal states thatmust be achieved in the course of executing theprocedure.
In the examples given here, there willnever be more than one goal state in a body.Preconditions: Conditions necessary to the suc-cessful execution of the procedure.
We distin-guish for voluntary actions a want precondition:the agent must want to perform the action, i.e.
hemust want the other preconditions to obtain, andthe effects to become true through the achieve-ment of the body.The constraints on the parameters consist of typespecifications, and necessary parameter interdependen-ties.
Each action has at least one parameter, namely,the agent or instigator of the action.
In the blocksworld, for example, the action of putting one block ontop of another could be defined as:PUTON(a,b l ,b2)constraints: AGENT(a)  A BLOCK(b l )  A BLOCK(b2)precondition: CLEAR(b l )  A CLEAR(b2)A Wa(PUTON(a,b l ,b2))effect: ON(b l ,b2)The preconditions, effects and body provide infor-mation to the plan construction and inference process-es so that they can reason about the applicability andeffect of performing the action in a given context.Finally, the body of the action specifies what stepsmust be achieved in the course of the execution of theaction.
Primitive actions have no bodies; their execu-tion is specified by a non-examinable procedure.All agents are assumed to believe that actionsachieve their effects and require their preconditions.We need the following axioms:For all agents a and b, and for all actionsACT, if PRE is the precondition of ACT andEFF its effect then:(ACT.
l )  BA(ACT(b) =~ PRE).
(ACT.2) BA(ACT(b) ~ EFF).Every predicate and modal operator in these axioms,and throughout he paper, should be indexed by astate or time.
The resulting logic would be, according-ly, more complex.
The issue is raised again in sect.
6.3.3.
Plan Const ruct ionA plan to transform a world W\[0\] (represented bya formula) into a world W\[n\] is a sequence of actionsA1 .
.
.
.
.
An such that the preconditions of Ai are truein W\[i-1\], and Ai transforms world W\[i-1\] into W\[i\].An agent can achieve a goal by constructing andthen executing a plan which transforms the currentstate of the world into one in which the goal obtains.This can be done by finding an operator which, ifexecuted in some world, would achieve the goal.
If itspreconditions are satisfied in the initial world, the planis complete.
Otherwise, the planning process attemptsto achieve the preconditions.
This simple view of planconstruction as a "backward chaining" process can berefined by assuming different levels of "detail" in therepresentation of the world and of the operators.
Thisview (as developed in Sacerdoti \[1973, 1975\], forexample) allows plans constructed at one level of de-tail to be expanded to a lower level through the bodiesof their constituent acts.As noted earlier, the agent of an action must be-lieve that its precondition is true to believe that hisexecuting the action will succeed.
For agent A to planthat agent S should perform action ACT, A mustachieve that S should believe that the precondition ofACT holds, and S's beliefs should not be inconsistentwith A's, i.e.
it must be true that BA(KNOW(S,P)),where P is the precondition of ACT.We assume that an agent cannot do an action with-out wanting to do that action.
Thus a precondition ofevery action ACT by an agent A is thatWA(ACT(A)).We are concerned with the model that agents haveof each other's plan construction and inference proc-ess, and consider these two processes as consisting ofchains of plausible inferences operating on goals andobserved actions.
The processes are specified in twoparts: first as schemas of rules which conjecture thatcertain states or actions can be added to a plan beingconstructed.
The plausibility of the plans containingthe result of the inferences is then evaluated by ratingheuristics.
Thus the plan construction and inferencerules are not to be interpreted as valid logical rules ofinference.172 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsThe first three plan construction (PC) rules are: 2(PC.EA) \[Effect-action rule\] For any agent A, ifY is an effect of action X, then if A wants Y tohold, it is plausible that A will want action X tobe done.
(PC.AP) \[Action-precondition rule\] For any agentA, if X is a precondition of action Y, and if Awants Y to be done, then it is plausible that S willwant X to hold.
P$,(PC.AB) \[Action-body rule\] For any agent A, ifA wants an action Y to be done, and if X is apart of the body of Y then it is plausible that Swill want X to be done.If X and Y are systematically replaced by one ofthe pairs in Figure 1, then rules PC.EA, PC.AP, andPC.AB can all be written asWA(Y) =c=> WA(X)with =c=> indicating that the rule is a constructionrule.We also need a rule based on KNOWIF:(PC.KI) \ [KNOWlF rule\] For any agent A, if Awants P to be true, then it is plausible that Ashould want to know whether P is true.WA(P) =c=> WA(KNOWIF(A,P))3.4.
Plan In ferenceFor every plan construction ruleWA(Y) =c=> WA(X),and every agent S, there is a corresponding planinference (PI) rule which is writtenBsWA(X ) =i= > BsWA(Y ).The following rules correspond to the effect-action,action-precondition, and action-body rules of the pre-vious section:(PI.AE) \[Action-effect rule\] For all agents S andA, if Y is an effect of action X and if S believesthat A wants X to be done, then it is plausiblethat S believes that A wants Y to obtain.
(PI.PA) \[Precondition-action rule\] For all agentsS and A, if X is a precondition of action Y and ifS believes A wants X to obtain, then it is plausi-ble that S believes that A wants Y to be done.
(PI.BA) \[Body-action rule\] For all agents S andA, if X is part of the body of Y and if S believesthat A wants X done, then it is plausible that Sbelieves that A wants Y done.There are two inverses to the KNOWIF rule: if Awants to know whether P is true, then A may want Pto be true, or A may want P to be false.2 Throughout the rest of the paper agent A will usually de-note the constructor/executor of plans, and S (or System) therecognizer of plans (usually constructed by A).XACTprecond i t ions  of ACTbody of ACTe f fec ts  of ACTACTACTFigure !.
Arguments for PC/PI rules.
(PI.KP) \[Know positive\] For all agents S and A,BsWA(KNOWIF(A,P))  = i=> BsWA(P)(PI.KN) \[Know negative\] For all agents S and A,BsWA(KNOWIF(A,P))  = i=> BsWA(~P)PI.W is the special case of the precondition-actionrule where the precondition is the want precondition:(PI.W) \[Want rule\] For all agents S, A, and Cand for all actions ACT whose agent is C, it isplausible thatBsWA(Wc(ACT))  = i=> BsWA(ACT )3.4.1.
The  Plan In ference ProcessThe plan inference rules generate formulas whichthe recognizing agent believes are possible.
A sepa-rate mechanism is used to evaluate their plausibility.An agent S attempting to infer the plans of anotheragent A starts with an observed action of A and a(possibly empty) set of goals or expectations which Sbelieves A may be trying to achieve.
S attempts toconstruct a plan involving the action and preferablyalso including some of the expectations.Plan inference is a search through a space of partialplans each consisting of two parts.
One part is con-structed using the plan inference rules from the ob-served action (and called the alternative); the other isconstructed using the plan construction rules from anexpected goal (and called the expectation).The partial plans are manipulated by a set of taskswhich decide what rules are to be applied, what"merges" between alternatives and expectationsshould be attempted, and when the process terminates.The partial plans and their associated tasks are ratedby a set of heuristics, and the most highly rated task isexecuted first.3.4.2.
Rat ing Heur ist icsThe rating of a partial plan reflects how likely it isto be part of the "correct"  plan, i.e.
the plan thespeaker is executing.
If several incompatible inferenc-es can be made from one point in the alternative, thenits rating is divided among them.
The heuristics de-scribed in this section are based on domain independ-ent relations between actions, their bodies, precondi-tions, and effects.
The need for more domain depend-ent measures is discussed later.American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 173C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsThe heuristics are described here only in terms ofincreasing or decreasing ratings of partial plans.Decrease the rating of a partial plan in whichthe preconditions of executing actions arecurrently false.Decrease the rating of a partial plan contain-ing a pending action ACT by an agent A if Ais not able to do ACT.
3Decrease the rating of a partial plan in whichthe effects of a pending act already obtain orare not wanted by the planner.
4Other heuristics depending on how well the utter-ance fits with the expectations are not immediatelyrelevant o understanding indirect speech acts and willnot be discussed here.
One further heuristic is addedin section 4.3.In general several rating heuristics are applicable toan partial plan.
Their effects on the rating of the par-tial plan are cumulative.3.4.3.
Extending the Inference RulesA hearer S identifies the illocutionary force of anutterance by recognizing that the speaker A has cer-tain intentions, namely that S should recognize someintention P of A's.
This can be represented by a for-mula of the form BsWA(BsWA(P)).
To do the recog-nition, the simple plan construction and inference rulesof sections 3.3 and 3.4 must be extended so that theycan operate on these nested formulas.
This can bedone by assuming that every agent is aware that otheragents construct and infer plans in the same way hecan.
In fact, both the simple inference and construc-tion rules are necessary to derive the extended infer-enee rules.The extended rules are specified by "meta-rules"which show how to construct new PC/P I  rules fromold ones.
The first extended construction rule (EC.
1)is: A can achieve that S recognizes that A wants theeffect of ACT by achieving that S recognizes that Awants ACT to be done, assuming that S would inferthat the effects of ACT are also desired.
The samerule applies if we replace "wants the effect of ACT"and "wants ACT to be done" by any pair of Y and X,as given in Figure 1.
We assume all these sul~stitu-3 This definition is the same as Cohen's CANDO relation.Being able to do an action means that the action's preconditions areeither presently true, achieved within the existing plan, or can beachieved by a "relatively simple plan", which we take to be a singleaction whose preconditions are presently true or achieved in theexisting plan.4 We have avoided the problem here of planning to do a taskthat requires one to deny a subgoal temporarily so that some actioncan execute, and then needing to reaehieve that (presently true)goal.tions are possible in rules EC.1 - EC.3 and EI.1 -EI.3.
(EC.1) If  BsWA(X) = i=> BsWA(Y) is a PI rule, thenWA(BsWA(Y)) =c=> WA(BsWA(X)) is a PC rule.Similarly we can generate the corresponding PI rule:(EI.1) If BsWA(X) = i=> BsWA(Y) is a PI rule, thenBsWA(BsWA(X)) = i=> BsWA(BsWA(Y)) is a PIrule.EI.
1 allows prefixing BsW A to plan inference rules.Plan construction rules can also be embedded: if Awants S to want to do ACT,  then A should be able toachieve this by achieving that S wants the effect ofACT,  and by relying on S to plan ACT.
In otherwords:(EC.2) If Ws(Y) =c=> Ws(X)  is a PC rule, thenWA(Ws(X))  =c=> WA(Ws(Y))  is a PC rule.Correspondingly,(EI.2) If Ws(Y) =e=> Ws(X)  is a PC rule, thenBsWA(Ws(Y))  = i=> BsWA(Ws(X))  is a PI rule.Finally, any agent A can plan for S to recognizeA's intention that S plan, and for S to be able to rec-ognize this intention in A.
For example, A can planfor S to recognize A's intention that S want to closethe door by planning for S to recognize A's intentionthat S watlt the door closed.
These rules are obtainedby using EI.2 as the PI rule which is "extended" byEC.
1 and El.
1.
(EC.3) If Ws(Y) =c=> Ws(X) is a PC rule, thenWABs(WAWs(X))  =c=> WABs(WAWs(Y))  is a PCrule.
(EI.3) If Ws(Y) =e=> Ws(X)  is a PC rule, thenBsWA(BsWA(Ws(Y)))  = i=> BsWA(BsWA(Ws(X)))is a PI rule.Our "toolkit" is now sufficiently full to allow us toconsider some speech acts and their recognition.4.
Plan In ference and Indirect  Speech  Acts4.1.
Speech  ActsThe definitions of the speech acts REQUEST andINFORM used in this paper are slightly different fromthe ones in Cohen and Perrault \[1979\] in that theyrely on the existence of speech act bodies to accountfor indirect forms.
Plans including speech acts arenow thought of as having two levels, the illocutionarylevel and the surface level.
Acts at the il locutionarylevel model the intentions motivating an utteranceindependently of the syntactic forms used to indicatethose intentions.
Acts at the surface level are realizedby utterances having specific i l locutionary force indi-cators.174 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech Acts'The first illocutionary level act is one by which aspeaker informs a hearer that some proposition is true.INFORM(speaker, hearer, P)prec: KNOW(speaker,P)  ^W(speaker, INFORM(speaker,hearer,P))effect: KNOW(hearer,P)body: B(hearer,W(speaker,KNOW(hearer,P)))For A to sincerely inform S that P is true, A mustbelieve A knows that P is true and want to inform Sthat P (the preconditions), and must intend to get S toknow that P is true (the effect), which is done by con-structing a plan that will achieve S's recognition of thisintention (i.e.
that Bs(WA(KNOW(S,P))~).
A thenmust depend on S to bring about the effect: S mustdecide to believe what A said.
This is made explicit byintroducing an admittedly simplistic DECIDE TOBELIEVE act:DECIDE TO BELIEVE(agent,  other, P)pree: B(agent,W(other,KNOW(agent,P)))effect: KNOW(agent,P)Thus A can INFORM S of P by achievingBsWA(KNOW(S,P))  followed by DECIDE TOBELIEVE(S,A,P).In many cases, agents reason about INFORM actsto be performed (by others or by themselves) wherethe information for the propositional content is notknown at the time of plan construction.
For example,A may plan for S to inform A whether P is true.
Acannot plan for S to perform INFORM(S,A,P) sincethis assumes the truth of P. We get around this diffi-culty by defining INFORMIF,  another view of theINFORM act.INFORMIF(speaker, hearer, P)prec: KNOWlF(speaker,P) AW(speaker, INFORMIF(speaker,hearer,P))effect: KNOWIF(hearer,P)body: B(hearer,W(speaker,KNOWIF(hearer,P)))Similarly, it must be possible for A to plan for S totell A the referent of a description, without A knowingthe referent.
This is the role of the INFORMREF act.INFORMREF(speaker,  hearer, D(x))pree: KNOWREF(speaker,D(x))  ^W(speaker, INFORMREF(speaker,hearer,D(x)))effect: KNOWREF(hearer,D(x))body: B(hearer,W(speaker,KNOWREF(hearer,D(x))))Request is defined as:REQUEST(speaker,  hearer, action)constraint: hearer is agent of actionprec: W(speaker,action(hearer))effect: W(hearer,aetion(hearer))body: B(hearer,W(speaker,action(hearer)))The intention of a request is to get the hearer towant to do the action, and this is accomplished bygetting the hearer to believe that the speaker wantsthe hearer to do the action and then depending on thehearer to decide to do it.
5 To explicitly represent thisdecision process, a CAUSE TO WANT act definedalong the lines of the DECIDE TO BELIEVE actabove is necessary.CAUSE TO WANT(agent, other, P)prec: B(other,B(agent,W(agent,P)))effect: W(other,P)As examples of the use of speech acts, "Tell mewhether the train is here" and "Is the train here?
",intended literally, are both REQUESTs by A that SINFORMIF the train is here.
"When does the trainarrive?
", intended literally, is a REQUEST by A thatH INFORMREF of the departure time of the train.Finally we define the two surface level acts:S. INFORM produces indicative mood utterances, andS.REQUEST produces imperative utterances, or inter-rogative utterances, if the requested act is an IN-FORM.
These acts have no preconditions, and servesolely to signal the immediate intention of the speaker,the starting point for all the hearer's inferencing.S.INFORM(speaker, hearer, P)effect: B(hearer,W(speaker,KNOW(hearer,P)))S.REQUEST(speaker, hearer, action)effect: B (hearer,W(speaker,action(hearer)))The effects of S. INFORM match the body of the IN-FORM act, reflecting the fact that it is a standard wayof executing an INFORM.
It is important, however,that S. INFORM is only one way of executing an IN-FORM.
The same relationship holds between theS.REQUEST and REQUEST actions.4.2.
Recognizing IIIocutionary ForceGiven the speech act definitions of section 4.1, wesay that A performed an illocutionary act IA by utteringx to S if A intends that S should recognize (and beable to recognize) that(1) x is an instance of a surface act SA, and(2) A intended S to infer (using the PI rules andassociated heuristics) from A having performedSA that A wants to achieve the effects of IA.This definition allows more than one illoeutionaryact to be performed by a single surface act.
In thissection we show how the hearer of an utterance canrecognize the speaker's intention(s) indicated by aspeech act, especially when these intentions are com-municated indirectly.5 See Cohen and Perrault \[1979\] for a discussion of whySearle's preparatory conditions "Speaker believes Hearer can do theaction" need not bc part of the preconditions on REQUEST.American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 175C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsAll inferencing by S of A's plans starts from S'srecognition that A intended to perform one of thesurface acts, and that A in fact wanted to do the act.All inference chains will be shown as starting from aformula of the form BsWA(A do the surface act).
Theobject of the inferencing is to find what illocutionarylevel act(s) A intended to perform.
The action-effectrule applied to the starting formula yields one of theform BsWA(BsWA(P)),  i.e.
S believes that A wants Sto recognize A's intention that P. The inferencingprocess searches for plausible formulas of the formBsWA(IA(A))  where IA is an illocutionary level act.
(1) S.REQUEST(A,S,PASS(S,A,SALT))PI .AE (2) BsWA(PASS(S,A,SALT))PI.BA (3) REQUEST(A,S,PASS(S,A,SALT))Example 1.
"Pass the salt,"Example 1 shows a direct request to pass the salt,where the surface request maps directly into the in-tended request interpretation.
6 The actions relevant tothe examples given here are:PASS(agent, beneficiary, object)prec: HAVE(agent ,  object)effect: HAVE(benef ic iary,  object)REACH(agent ,  object)prec: NEAR(agent,  object)effect: HAVE(agent ,  object)Let us also assume that S presently has the salt, i.e.HAVE(S,SALT)  is true, and mutually believed by Sand A.The rating heuristics for the complex rules El.
1 toEI.3 are the same as for the PI rules but each heuristicmay be applicable several times at different levels.For example, consider the frequently recurring infer-ence chain:(1) BsWA(ACT(S))PI.BA (2) REQUEST(A,S ,ACT(S))PI .AE (3) Ws(ACT(S))PI .PA (4) ACT(S)PI .AE (5) effects of ACT(S)It shows the line of inference from the point where Srecognizes that A requested S to do ACT (at step (2))to the point where the effects of the requested actionare inferred as part of A's plan.
Of interest here is theevaluation of the plausibility of step (3).
Two heuris-tics are applicable.
The proposition "Ws(ACT(S) ) "  is6 To improve readability of inference chains in the examples,we drop the prefix BsW A from all propositions.
The formula online (n) follows from the one on line (n-l) by the rule at the begin-ning of line (n).
Applications of EI.1 will be labelled "rule"/EI.l,where "rule" is a PI rule embedded by EI.1.
Similarly, applicationsof EI.2 and EI.3 will be labelled "rule"/EI.2 and "rule"/EI.3,where "rule" is a PC rule name.evaluated with respect to what S believes A believes.
(Remember that BsW A should appear as a prefix to allpropositions in inference chains.)
If BsBAWs(ACT(S))is true, the request interpretation is considered unlike-ly, by the effect-based heuristic.
In addition, the pre-conditions of ACT(S)  are considered with respect towhat S believes A believes S believes.
This step willonly be reasonable if S can do the action, by aprecondit ion-based heuristic.To make more explicit the distinction between in-ferences in BsW A and inferences in BsWABsWA, letus consider two inference chains that demonstrate twointerpretations of the utterance "Do you know thesecret?".
Lines 1-3 of Example 2 show the chainwhich leads S to believe that A asked a (literal)yes /no  question; lines 1-6 of Example 3 show theinterpretation as a request to S to inform A of thesecret.
Notice that in both interpretations S may beled to believe that A wants to know the secret.
In theliteral case, S infers A's goal from the literal interpre-tation, and may tell the secret simply by being helpful(lines 4-9).
In the indirect case, S recognizes A'sintention that S inform A of the secret (lines 1-6).Telling the secret is then conforming to A's intentions(lines 7-9).There is in fact a third interpretation of this sen-tence.
If A and S both know that A already knowsthe secret, then the utterance could be intended as"I f  you don't  know the secret, I will tell it to you.
"This requires recognizing a conditional action and isbeyond our present abilities.4.3.
The Level of Embedding Heur ist icTwo sets of PI rules are applicable to formulas ofthe form BsWABsWA(P): the simple rules PI.1 to PI.6operating "within" the prefix BsW A, and the rulesgenerated by EI.1 and EI.3 which allow the simplerules to apply within the prefix BsWABsW A.
To re-flect the underlying assumption in our model that in-tention will always be attributed if possible, the infer-ences at the most deeply nested level should be prefer-red.Of course, if the inferences at the nested level leadto unlikely plans, the inferences at the "shallow" lev-els may be applied.
In particular, if there are multiplemutually exclusive inferences at the nested level, thenthe "shallow" inferences will be preferred.
This re-flects the fact that the nested inferences model whatthe speaker intends the hearer to infer.
If there aremany inferences possible at the nested level, thespeaker would not be able to ensure that the hearerwould perform the correct (i.e., the intended) one.176 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsPI.AEPI.BAPI.AEPI.WPI.AEPI.KPPI.PAPI.AE(1) S.REQUEST(A,S,INFORMIF(S,A,KNOWREF(S,SECRET(x))))(2) BsWA(INFORMIF(S,A,KNOWREF(S,SECRET(x))))(3) REQUEST(A,S,INFORMIF(S,A,KNOWREF(S,SECRET(x))))(4) Ws(INFORMIF(S,A,KNOWREF(S,SECRET(x))))(5) INFORMIF(S,A,KNOWREF(S,SECRET(x)))(6) KNOWIF(A,KNOWREF(S,SECRET(x)))(7) KNOWREF(S,SECRET(x))(8) INFORMREF(S,A,SECRET(x))(9) KNOWREF(A,SECRET(x))Example 2.
"Do you know the secret?"
(yes/no question)PI.AEPI.AE/EI.1PI.KP/EI.
1PI.PA/EI.1PI.BAPI.AEPI.WPI.AE(\]) S.REQUEST(A,S,INFORMIF(S,A,KNOWREF(S,SECRET(x))))(2) BsWA(INFORMIF(S,A,KNOWREF(S,SECRET(x))))(3) BsWA(KNOWlF (A,KNOWREF(S,SECRET(x))))(4) BsWA(KNOWREF(S,SECRET(x))(5) BsWA(INFORMREF(S,A,SECRET(x))(6) REQUEST(A,S,INFORMREF(S,A,SECRET(x)))(7) Ws(INFORMREF(S,A,SECRET(x))(8) INFORMREF(S,A,SECRET(x))(9) KNOWREF(A,SECRET(x))Example 3.
"Do you know the secret?"
(indirect request)PI.AEPI.PA/EI.1PI.AE/EI.1PI.W/EI.1PI.BA(1) S.INFORM(A,S,WA(PASS(S,A,SALT))(2) BsWA(Bs(WA(PASS(S,A,SALT))))(3) BsWA(CAUSE TO WANT(A,S,PASS(S,A,SALT)) )(4) BsWA(Ws(PASS(S,A,SALT))(5) BsWA(PASS(S,A,SALT))(6) REQUEST(A,S,PASS (S,A,SALT))Example 4.
"I want you to pass the salt."4.4.
More  Indirect  RequestsExample 4 shows the interpretation of "I want youto pass the salt" as a request.
Taking the utteranceliterally, S infers that A wants him to know that Awants him to pass the salt.
This yields proposition (2)which leads through the next three inferences to theintention that would be recognized from a request act,i.e.
that A wants S to pass the salt (5).
Notice that anapplication of the body-action rule to step (2) yields:INFORM(A, S, WA(PASS(S, A, SALT))),for, in fact, the speaker may be performing bothspeech acts.
The level of inferencing heuristic favoursthe indirect form.The key step in Example 5 is the application of theknow-positive rule from line (3) to line (4).
Since,given the context, S assumes that A knows whether Shas the salt, the literal interpretation (from (2)) wouldnot produce a reasonable goal for A.
This supportsthe nested know-positive inference, and attributesfurther intention to the speaker (4).
Once this isdone, it is easy to infer that A wants S to pass him thesalt (5), hence the request interpretation.
"Can you pass the salt?"
and "Do you want to passthe salt?"
are treated similarly, for they inquire aboutthe preconditions on PASS(S, A, SALT).Example 6 begins like Example 5, leading to theinference that A wants S to be able to reach the salt(4).
7 Since being able to reach the salt is a precondi-tion to reaching the salt (5), which then enables pass-ing the salt (6), S can infer that he is being requestedto pass the salt.
"Is the salt near you?"
can be treatedin the same way, as being near the salt is a precondi-tion on reaching the salt.7 Let CANDO(S,ACT) be true if S believes the preconditionsof ACT are true.American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 177C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsPI.AEPI .AE/EI .
1PI .KP/EI .
1PI .PA/EI .
1PI.BA(1) S.REQUEST(A,S, INFORMIF(S,A,HAVE(S,SALT)))(2) BsWA(INFORMIF(S,A,HAVE(S,SALT)))(3) BsWA(KNOWlF(A,HAVE(S,SALT)))(4) BsWA(HAVE(S,SALT))(5) BsWA(PASS(S,A,SALT))(6) REQUEST(A,S,PASS(S,A,SALT))Example 5.
"Do you have the salt?
"PI.AEPI .AE/EI .
1PI .KP/EI .1PI .PA/EI .
1P I .AE/EI .
1PI .PA/EI .1PI.BA(1) S.REQUEST(A,S, INFORMIF(S,A,CANDO(S,REACH(S,SALT)))(2) BsWA(INFORMIF(S,A,CANDO(S,REACH(S,SALT)))(3) BsWA(KNOWIF(A,CANDO(S,REACH(S,SALT)) ) )(4) BsWA(CANDO(S,REACH(S,SALT)))(5) BsWA(REACH(S,SALT))(6) BsWA(HAVE(S,SALT))(7) BsWA(PASS(S,A,SALT))(8) REQUEST(A,S,PASS(S,A,SALT))Example 6.
"Can you reach the salt?
"PI.AEPI .PA/EI .1P I .AE/EI .
1P I .AE/EI .3PI .W/EI .
1PI.BA(1) S. INFORM(A,S,WA(HAVE(A,SALT))(2) BsWA(Bs(WA(HAVE(A,SALT))))(3) BsWA(CAUSE TO WANT(A,S,HAVE(S,A,SALT)))(4) BsWA(Ws(HAVE(A,SALT)))(5) BsWA(Ws(PASS(S,A,SALT)))(6) BsWA(PASS(S,A,SALT))(7) REQUEST(A,S,PASS (S,A,SALT))Example 7.
"I want the salt."
(= "I want to have the salt.
")Example 7 includes in the step from (3) to (4), anapplication, through EI.3, of the effect-action rule.
Ainforms S of A's goal of having the salt (2) and thendepends on S's planning on that goal to infer thePASS action.
Because the action is the "obvious" wayof achieving the goal, S believes that A intended himto infer it.Since questions are treated as requests to inform,most of them are handled in a similar manner to therequests above.
4.4a-h can all be understood as ques-tions about the departure time of some train.
(4.4a) When does the train leave?
(4.4b) I want you to tell me when ...(4.4c) I want to know when ...(4.4d) Tell me when ...(4.4e) Can you tell me when ...(4.4f) Do you know when ...(4.4g) Do you want to tell me when ...(4.4h) Will you tell me when ...4.5.
An  Example  of an Indirect  INFORMAn interesting example of an indirect INFORM is4.5a for it is very similar to 4.5b-c which both seem toonly be requests.
The interpretation of 4.5a as anindirect INFORM follows from the fact that inferencechains which would make it a REQUEST are all inhib-ited by the heuristics.
(4.5a) Do you know that the RAPIDO is late?
(4.5b) Do you believe that the RAPIDO is late?
(4.5c) Do you know whether the RAPIDO is late?In Example 8, the possible body-act ion inferencefrom (2) toREQUEST(A,S, INFORMIF(S,A,KNOW(S,P)) )is downgraded because the embedded inference to (3)is possible.
The interesting case is the embeddedknow-negative inference which is also possible from(3).
It implies that BsWA(~KNOW(S,P)) ,  or equiva-lently(4.5d) BsWA(P ^ 2,Bs(P)178 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsPI.AEPI .AE/EI .
1PI .KP/EI .1..PI.BA(1) S.REQUEST(A,S, INFORMIF(S,A,KNOW(S,P)))(2) BsWA(INFORMIF(S,A,KNOW(S,P)))(3) BsWA(KNOWIF(A,KNOW(S,P)))(4) BsWA(KNOW(S,P))(5) INFORM(A,S,P)Example 8.
"Do you know that P?
"But such a goal is highly unlikely.
A is attempting toachieve the goal ~Bs(P) by having S recognize that Awants P to be true!
As a result, no speech act inter-pretation is possible from this step.
For instance, thebodies of the acts INFORM(A, S, P) and INFORM(A,S, ~P) are BsWA(P A Bs(P)) , and BsWA(~P ABs(~P)) ,  respectively.
Both of these are contradictedby part of 4.5d.
Thus the know-negative possibilitycan be eliminated.
This allows the know-positive in-ference to be recognized as intended, and hence leadsto the indirect interpretation as an INFORM(A, S, P).4.5b has only a literal interpretation since both theknow-positive and know-negative rules are applicableat the nested level; without a reason to favour either,the literalREQUEST(A,S, INFORMIF(S,A,Bs(P)))is preferred.
The interpretations of 4.5c are similar tothose of Examples 2 and 3.4.6.
Using Knowledge of DeductionAll the examples of indirect speech acts so far havebeen explained in terms of rules PI.1-PI.6, and com-plex inference rules derived from them.
In this sec-tion, we give one more example relying on somewhatmore specific rules.
A full investigation of how manysuch specific rules are necessary to account for com-mon forms of indirect REQUESTs and INFORMsremains to be done.This example shows how a completely non-standardform can be intended indirectly.
Suppose that A tellsS(4.6a) "John asked me to ask you to leave"This has at least three possible interpretations:(4.6b) A is asking S to leave, and giving a reason.
(4.6c) A wants to simply report the fact to Sthat John did the action of asking S to leave.
(4.6d) A wants to inform S that John wantshim to leave.Interpretations c and d can hold even if S decidesthat A actually does want him to leave.
However, inthese cases, he would not say that A intended to com-municate the intent that he leave, i.e.
he would not saythe utterance was a REQUEST.Both interpretations rely on axioms ACT.1 andACT.2 (of section 3.2) which state that if some agentA believes that agent S executed some action ACT,then A may believe that the preconditions of ACTobtained before, and the effects of ACT obtainedafter, the execution of ACT.They also require a new PC/P I  rule: if A wants Sto believe some proposition P, then A may get S tobelieve some proposition Q, as long as A believes thatS believes that Q implies P.(PC.I) WA(Bs(P)) =c=> WA(Bs(Q)) ,if BABs(Q ~ P).
(PI.I) BsWA(Bs(Q)) = i=> BsWA(Bs(P)) ,if BsBABs(Q => P).In Example 9, S recognizes that A asked him toleave.
The interpretat ion depends on S concludingthat John performed his REQUEST successfully(through PI.I and ACT.2), and hence that A wants torequest S to leave.
It is then an easy step to infer thatA wants S to leave, which leads to the request inter-pretation.
Interpretation (c), a simple report of someprevious action, follows from (2) by PI.BA.In Example 10, S recognizes that A intended to tellhim that John wants him to leave.
This depends onthe fact that S concludes that John wanted to performthe REQUEST that A reported.
Most of the neededinferences call for the use of EI.1 to embed simpleinference rules twice.
Note that an INFORM actcould have been inferred at each of the four previoussteps; for example, from (5) the body inference wouldproduceINFORM(A, S, Wj(REQUEST(A,  S, LEAVE(S))) .But the inferences at the "BsWABsWj" level were sodirect that they were continued.5.
Gordon and Lakoff  Revis i tedThe examples of the previous section show how ourplan inference rules account for the indirect interpreta-tions of the requests which GL's postulates were de-signed for, as well as several others.
Our approachdiffers from GL's in that an utterance may carry botha literal and an indirect interpretation, and of course inthat its inference rules are language independent.American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 179C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsPI.AEPI.
I /EI.1(PI .AE/EI .
1)/EI .
1(PI .W/EI .
1)/EI .
1(PI .BA/EI .
1)PI .AE/EI .1PI.W/E1.1PI.BA(1) S. INFORM(A,S,REQUEST( J ,A,REQUEST(A,S,LEAVE(S))) )(2) BsWA(Bs(REQUEST( J ,A,REQUEST(A,S,LEAVE(S))) ) )(3) BsWA(BsWA(REQUEST(A,S,LEAVE(S))))(4) BsWA(BsWA(Ws(LEAVE(S))))(5) BsWA(BsWA(LEAVE(S)))(6) BsWA(REQUEST(LEAVE(S)))(7) BsWA(Ws(LEAVE(S))(8) BsWA(LEAVE(S))(9) REQUEST(A,S,LEAVE(S))Example 9.
"John asked me to ask you to leave."
(Interpretation b)PI.AEPI.
I /EI .1(PI .AE/EI .
1)/EI .
1(PI .W/EI .
1)/EI .
1(PI .AE/EI .
1)/EI .
1(PI .W/EI .
1)/EI .
1(P I .BA/E I .1) /E I .
1(1) S. INFORM(A,S,REQUEST( J ,A,REQUEST(A,S,LEAVE(S))) )(2) BsWA(Bs(REQUEST( J ,A,REQUEST(A,S,LEAVE(S))) ) )(3) BsWA(BsWj(REQUEST( J ,A,REQUEST(A,S,LEAVE(S))) )(4) BsWA(BsWj(WA(REQUEST(A,S,LEAVE(S))))(5) BsWA(BsWj(REQUEST(A,S,LEAVE(S))) )(6) BsWA(BsWj(Ws(LEAVE(S))))(7) BsWA(BsWj(LEAVE(S))(8) INFORM(A,S,Wj(LEAVE(S))Example 10.
"John asked me to ask you to leave."
(Interpretation d)However, in some ways both solutions are too strong.Consider, for example, the following:(5.a) Can you reach the salt?
(5.b) Are you able to reach the salt?
(5.c) I hereby ask you to tell me whetheryou are able to reach the salt.Although 5.a-c are all literally questions about thehearer's ability, only 5.a normally conveys a request.Sadock \[1974\] suggests that forms such as 5.a dif-fer from 5.b in that the former is an idiom which isdirectly a request while 5.b is primarily a yes /no  ques-tion.
However, as Brown \[1980\] points out, this failsto account for responses to 5.a which follow from itsliteral form.
One can answer "Yes" to 5.a and thengo on to pass the salt.Brown proposes what she calls "frozen ISA forms"which directly relate surface form and indirect illocu-tionary force, bypassing the literal force.
Frozenforms differ from normal rules mapping illocutionaryforces to illocutionary forces in that they point to therelevant normal rule which provides the informationnecessary to the generation of responses to the surfaceforms.The speaker of 5.b or 5.c may in fact want thehearer to reach the salt, as does the speaker of 5.a, buthe does not want his intention to be recognized by thehearer.
Thus it appears that from the hearer's point ofview the chain of inferences at the intended levelshould get turned off, soon after the recognition of theliteral act.
It seems that in this case (Example 6 ofsection 4.4) the plausibility of the inferences after step3 should be strongly decreased.
Unfortunately it isnot obvious that this can be done without making ,therating heuristics ensitive to syntax.The indirect interpretation can also be downgradedin the presence of stronger expectations.
If a speakerentered a room full of aspiring candidates for employ-ment and said: "I want to know how many peoplehere can write a sort /merge program" and then turn-ing to each individually asked "Can you write asort /merge?"
the question would not be intended as arequest to write a program, and would not be recog-nized as such by a PI algorithm which rated highly anillocutionary act which fits well in an expectation.In several of the earlier examples of questions in-tended as indirect requests, the literal interpretation isblocked because it leads to acts whose effects weretrue before the utterance.
The literal interpretation of5.d gets blocked because the reminding gets done aspart of the understanding of the literal act.
Thus onlyan indirect interpretation is possible.
(5.d) May I remind you to take out the garbage?180 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsSadock \[1970\] points out that some co-occurrencerules depend on conveyed rather than literal illocution-ary force.
The morpheme please can occur initiallyonly in sentences which convey a request.
(5.e) Please, can you close the window?
(5.f) Please, it's cold in here.
(5.g) *Please, do you know thatJames is in town?But it can occur in final position only in sentenceswhich both convey a request and are literally requests:(5.h) Can you close the window, please?
(5.i) *It's cold in here, please.
(5.j) *Do you know that John is in town, please?These remain problematic for Brown and for us.6.
Conc lus ionWe have given evidence in this paper for an ac-count of indirect speech acts based on rationality (planconstruction), imputing rationality to others (planinference), surface speech act definitions relating formto "literal" intentions, and illocutionary acts allowing avariety of realizing forms for the same intentions.The reader may object that we are suggesting acomplex solution to what appears to be a simple prob-lem.
It is important o distinguish here the generalexplanation of indirect speech acts (which is presentedhere partly through an algorithm) from the implemen-tation of such an algorithm in a practical natural an-guage understanding system.
We claim that the ele-ments necessary for a theoretically satisfying accountof indirect speech acts are independently motivated.
Itis almost certain that a computationally efficient solu-tion to the indirect speech act problem would short-cutmany of the inference chains suggested here, althoughwe doubt that all searching can be eliminated in thecase of the less standard forms such as 4.6a.
Theimplementation i Brachman et al\[1980\] does justthat.
However, the more fundamental ccount is nec-essary to evaluate the correctness of the implementa-tions.Many problems remain.
Other syntactic forms thathave significance with respect to illocutionary forcedetermination should be considered.
For example, tagquestions uch as"John is coming to the party tonight, isn't he?
"have not been analysed here (but see Brown \[1980\]).Furthermore, no "why" or "how" questions have beenexamined.Besides the incorporation of more syntactic infor-mation, another critical area that needs work concernsthe control of inferencing.
To allow the use of spe-cialized inferences, a capability that is obviously re-quired by the general theory, much research needs tobe done outlining methods of selecting and restrictingsuch inferences.This paper has concentrated on recognition.
Allen\[1979\] shows how the construction algorithms wouldhave to be modified to allow the generation of surfaceacts, including indirect forms.
McDonald \[1980\] dis-cusses the planning of low-level syntactic form.According to the definition of INFORM of section4.1, any utterance that causes S to infer that A has aplan to achieve KNOW(S,P) by achievingBsWA(KNOW(S,P)) is considered by S to be an IN-FORM.
Strawson \[1964\] argues that one level ofrecognition of intention is not sufficient for the defini-tion of a speech act.
Schiffer \[1972\] gives a series ofcounterexamples to show that no finite number ofconditions of the form BsWA(BsWA(...(KNOW(S,P)))is sufficient either.
The solution he proposes is thatthe recognition of intention must be mutually believedbetween the speaker and the hearer.
Cohen and Lev-esque \[1980\] and Allen \[forthcoming\] show how thespeech act definitions given here can be extended inthis direction.We have only considered acts to request and in-form because many of their interesting properties canbe based on belief and want.
At least primitive ac-counts of the logics of these propositional ttitudes areavailable.
Clearly there is room for much work here.Extending the analysis to other speech acts, such aspromises, will require a study of other underlying log-ics such as that of obligation.There also remain many problems with the formali-zation of actions.
We believe this work shows that theconcepts of preconditions, effects, and action bodiesare fruitful in discussing plan recognition.
The opera-tor definitions for speech acts used here are intendedto facilitate the statement of the plan construction andinference rules.
However, their expressive power isinsufficient o handle complex actions involving se-quencing, conditionals, disjunctions, iterations, paral-lelism, discontinuity, and afortiori  requests and prom-ises to do such acts.
They are also inadequate, asMoore \[1979\] points out, to express what the agent ofan action knows (and does not know) after the successor failure of an act.
Moore's logic of action includessequencing, conditionals, and iterations, and is beingapplied to speech acts by Appelt \[1980\].
Much re-mains to be done to extend it to parallel and disconti-nuous actions typical of multiple agent situations.These difficulties notwithstanding, we hope that wehave helped show that the interaction of logic, philoso-phy of language, linguistics and artificial intelligence isproductive and that the whole will shed light on eachof the parts.American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980 181C.
Raymond Perrault and James F. Allen A Plan-Based Analysis of Indirect Speech ActsReferencesAllen, J.F.
A Plan-Based Approach to Speech Act Recognition.
Ph.D.Thesis, Dept.
of Computer Science, University of Toronto,1979.Allen, J.F.
Recognizing Intentions from Natural Language Utter-ances, forthcoming.Allen, J.F.
and Perrault, C.R., Analyzing Intention in Utterances,Artificial Intelligence, 15, 3, pp.
143-178, 1980.Appelt, D.E., Problem Solving Applied to Language Generation,Prec.
of 18th Annual Meeting of Assoc.
for Comp.
Ling., pp.59-63, 1980.Austin, J.L.
How To Do Things With Words.
New York: OxfordUniversity Press, 1962.Ayer, A.J.
The Problem of Knowledge.
London: Penguin Books,1956.Brachman, R.J., Bobrow, R.J., Cohen, P.R., Klovstad, J.W., Web-ber, B.L., and Woods, W.A., Research in Natural LanguageUnderstanding, Report 4274, Bolt, Beranek, and Newman,Cambridge, Mass., 1980.Brown, G.P.
Characterizing Indirect Speech Acts :A ComputationalApproach, Am.
J. of Comp.
Ling., this issue, pp.
150-166, 1980.Bruce, B.C.
Belief Systems and Language Understanding, TechnicalReport 2973, Bolt Beranek and Newman, Cambridge Mass,1975.Cohen, P.R.
On Knowing What to Say: Planning Speech Acts, Techni-cal Report no.
118, Dept.
of Computer Science, University ofToronto January, 1978.Cohen, P.R., and Levesque, H.J., Speech Acts and the Recognitionof Shared Plans, in Prec.
of 3rd Con f. of Can.
Soc.
for Comp.Studies of Intelligence, Victoria, B.C., pp.
263-271, 1980.Cohen, P.R.
and Perrault, C.R.
Elements of a Plan Based Theory ofSpeech Acts, Cognitive Science, 3, 3, pp.
177-212, 1979.Cole, P. and Morgan, J.L.
Syntax and Semantics, Vol 3: Speech Acts.New York, Academic Press, 1975.Fikes, R.E.
and Nilsson, N.J.
STRIPS: A New Approach to theApplication of Theorem Proving to Problem Solving.
ArtificialIntelligence 2, pp.
189-205, 1971.Genesereth, M.R.
Automated Consultation for Complex ComputerSystems, Ph.D. Thesis, Harvard University, 1978.Gettier, E.L. Is Justified True Belief Knowledge?.
Analysis 23, pp.121-123, 1963.
Reprinted in M.D.
Roth and L. Galis (eds.
)Knowing, New York: Random House, 1970.Gordon, D. and Lakoff, G. Conversational Postulates.
in Cole andMorgan (eds), 1975.Green, G. M. How to Get People to Do Things with Words: theWhimperative Question, in Cole and Morgan (eds.
), 1975.Grice, H.P.
Meaning.
Phil.
Rev.
66, pp.
377-388, 1957.Grice, H.P., Utterer's Meaning, Speaker Meaning, and Word Mean-ing, Found.
of Language, 4, pp.
225-242, 1968.Hintikka, J.
Knowledge and Belief, Ithaca, New York: Cornell Uni-versity Press, 1962.McDonald, D.D., Natural Language Production as a Process of Deci-sion Making under Constraint, Ph.D. Dissertation, Dept.
of E.E.and Comp.
So., MIT, 1980.Moore, R.C.
Reasoning about Knowledge and Action, Ph.D. Thesis,Massachusetts Institute of Technology, 1979.Morgan, J.L.
Conversational Postulates Revisited, Language 53, 2,1977.Morgan, J.L.
Towards a Rational Model of Discourse Comprehen-sion, in Prec.
of Second Conf.
Theoretical Issues in Natural Lan-guage Processing, Champaign-Urbana, 1978.Morgan, J.L.
Two Types of Convention in Indirect Speech Acts, inP.
Cole (ed.)
Syntax and Semantics (vol.
9): Pragmatics, NewYork: Academic Press, 1978.Perrault, C.R., Allen, J.F.
and Cohen, P.R.
Speech Acts as a Basisfor Understanding Dialogue Coherence, in Prec.
of Second Conf.Theoretical Issues in Natural Language Processing, Champaign-Urbana, 1978.Perrault, C.R.
and Cohen, P.R.
It's for Your Own Good: a Note onInaccurate Reference, to appear in Elements of DiscourseUnderstanding, A.K.
Joshi, I.A.
Sag, and B.L.
Webber (eds.
),New York: Cambridge University Press.Quine, W.V.O.
Quantifiers and Propositional Attitudes.
Journal ofPhilosophy 53, pp177-187, 1956.
Reprinted in L. Linsky (ed.
)Reference and Modality, Oxford: Clarendon Press, 1971.Russell, B.
Introduction to Mathematical Philosophy.
London:George Allen and Unwin, 1919.Sacerdoti, E.D.
Planning in a Hierarchy of Abstraction Spaces.Prec.
of Third Int.
Joint Conf.
on Artificial Intelligence, StanfordCA, 1973.Sacerdoti, E.D.
The Nonlinear Nature of Plans.
Prec.
of Fourth Int.Joint Conf.
on Artificial Intelligence, Tbilisi USSR, 1975.Sadock, J.M.
Whimperatives, in J.M.
Sadock and A. Vanek StudiesPresented to R.B.
Lees by his Students, pp.
223-38, Edmonton,1970.Sadock, J. M. Towards a Linguistic Theory of Speech Acts, New York:Academic Press, 1974.Schiffer, S.R.
Meaning.
London: Oxford University Press, 1972.Schmidt, C.F., Shridharan N.S.
and Goodson J.L., The Plan Recog-nition Problem: An Intersection of Artificial Intelligence andPsychology, Artificial Intelligence 11, pp.
45-83, 1978.Searle, J.R.
Speech Acts, New York: Cambridge University Press,1969.Searle, J.R.
Indirect Speech Acts.
in Cole and Morgan (eds), 1975.Stampe, D.W.
Meaning and Truth in the Theory of Speech Acts.
inCole and Morgan (eds), 1975.Strawson, P.F.
Intention and Convention in Speech Acts.
Phil.Rev., 73,4, pp.
439-460, 1964.C.
Raymond Perrault is Associate Professor in theDepartment o f  Computer  Science at the University o fToronto.
He received the Ph.D. degree in computer andcommunicat ion sciences f rom the University o f  Michiganin 1975.James F. Al len is Assistant Professor in the Depart-ment o f  Computer Science at the University o f  Roches-ter.
He received the Ph.D. degree in computer sciencef rom the University o f  Toronto in 1979.182 American Journal of Computational Linguistics, Volume 6, Number 3-4, July-December 1980
