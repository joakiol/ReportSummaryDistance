Proceedings of the Third ACL-SIGSEM Workshop on Prepositions, pages 81?88,Trento, Italy, April 2006. c?2006 Association for Computational LinguisticsHow bad is the problem of PP-attachment?
A comparison of English,German and SwedishMartin VolkStockholm UniversityDepartment of Linguistics106 91 Stockholm, Swedenvolk@ling.su.seAbstractThe correct attachment of prepositionalphrases (PPs) is a central disambigua-tion problem in parsing natural languages.This paper compares the baseline situationin English, German and Swedish basedon manual PP attachments in various tree-banks for these languages.
We argue thatcross-language comparisons of the disam-biguation results in previous research isimpossible because of the different selec-tion procedures when building the trainingand test sets.
We perform uniform tree-bank queries and show that English has thehighest noun attachment rate followed bySwedish and German.
We also show thatthe high rate in English is dominated bythe preposition of.
From our study we de-rive a list of criteria for profiling data setsfor PP attachment experiments.1 IntroductionAny computer system for natural languageprocessing has to struggle with the problem of am-biguities.
If the system is meant to extract preciseinformation from a text, these ambiguities mustbe resolved.
One of the most frequent ambigu-ities arises from the attachment of prepositionalphrases (PPs).
Simply stated, a PP that followsa noun (in English, German or Swedish) can beattached to the noun or to the verb.In the last decade various methods for the res-olution of PP attachment ambiguities have beenproposed.
The seminal paper by (Hindle andRooth, 1993) started a sequence of studies forEnglish.
We investigated similar methods for Ger-man (Volk, 2001; Volk, 2002).
Recently otherlanguages (such as Dutch (Vandeghinste, 2002) orSwedish (Aasa, 2004)) have followed.In the PP attachment research for other lan-guages there is often a comparison of the dis-ambiguation accuracy with the English results.But are the results really comparable across lan-guages?
Are we starting from the same base-line when working on PP attachment in struc-turally similar languages like English, German andSwedish?
Is the problem of PP attachment equallybad (equally frequent and of equal balance) forthese three languages?
These are the questions wewill discuss in this paper.In order to find answers to these questions wehave taken a closer look at the training and testdata used in various experiments.
And we havequeried the most important treebanks for the threelanguages under investigation.2 Background(Hindle and Rooth, 1993) did not have access to alarge treebank.
Therefore they proposed an unsu-pervised method for resolving PP attachment am-biguities.
And they evaluated their method against880 English triples verb-noun-preposition (V-N-P)which they had extracted from randomly selected,ambiguously located PPs in a corpus.
For exam-ple, the sentence ?Timex had requested duty-freetreatment for many types of watches?
results inthe V-N-P triple (request, treatment, for).
Thesetriples were manually annotated by both authorswith either noun or verb attachment based on thecomplete sentence context.
Interestingly, 586 ofthese triples (67%) were judged as noun attach-ments and only 33% as verb attachments.
And(Hindle and Rooth, 1993) reported on 80% at-tachment accuracy, an improvement of 13% overthe baseline (i.e.
guessing noun attachment in all81cases).A year later (Ratnaparkhi et al, 1994) publisheda supervised approach to the PP attachment prob-lem.
They had extracted quadruples V-N-P-N1(plus the accompanying attachment decision) fromboth an IBM computer manuals treebank (about9000 tuples) and from the Wall Street Journal(WSJ) section of the Penn treebank (about 24,000tuples).
The latter tuple set has been reused bysubsequent research, so let us focus on this one.2(Ratnaparkhi et al, 1994) used 20,801 tuples fortraining and 3097 tuples for evaluation.
They re-ported on 81.6% correct attachments.But have they solved the same problem as (Hin-dle and Rooth, 1993)?
What was the initial biastowards noun attachment in their data?
It turns outthat their training set (the 20,801 tuples) containsonly 52% noun attachments, while their test set(the 3097 tuples) contains 59% noun attachments.The difference in noun attachments between thesetwo sets is striking, but (Ratnaparkhi et al, 1994)do not discuss this (and we also do not have anexplanation for this).
But it makes obvious that(Ratnaparkhi et al, 1994) were tackling a prob-lem different from (Hindle and Rooth, 1993) giventhe fact that their baseline was at 59% guessingnoun attachment (rather than 67% in the Hindleand Rooth experiments).3Of course, the baseline is not a direct indica-tor of the difficulty of the disambiguation task.We may construct (artificial) cases with low base-lines and a simple distribution of PP attachmenttendencies.
For example, we may construct thecase that a language has 100 different prepositions,where 50 prepositions always introduce noun at-tachments, and the other 50 prepositions alwaysrequire verb attachments.
If we also assume thatboth groups occur with the same frequency, wehave a 50% baseline but still a trivial disambigua-tion task.But in reality the baseline puts the disambigua-tion result into perspective.
If, for instance, thebaseline is 60% and the disambiguation result is80% correct attachments, then we will claim thatour disambiguation procedure is useful.
Whereas1The V-N-P-N quadruples also contain the head noun ofthe NP within the PP.2The Ratnaparkhi training and test sets were later distrib-uted together with a development set of 4039 V-N-P-N tuples.3It should be noted that important subsequent research,e.g.
by (Collins and Brooks, 1995; Stetina and Nagao, 1997),used the Ratnaparkhi data sets and thus allowed for goodcomparability.if we have a baseline of 80% and the disambigua-tion result is 75%, then the procedure can be dis-carded.So what are the baselines reported for other lan-guages?
And is it possible to use the same extrac-tion mechanisms for V-N-P-N tuples in order tocome to comparable baselines?We did an in-depth study on German PP at-tachment (Volk, 2001).
We compiled our owntreebank by annotating 3000 sentences from theweekly computer journal ComputerZeitung.
Wehad first annotated a larger number of subsequentsentences with Part-of-Speech tags, and based onthese PoS tags, we selected 3000 sentences thatcontained at least one full verb plus the sequenceof a noun followed by a preposition.
After annotat-ing the 3000 sentences with complete syntax treeswe used a Prolog program to extract V-N-P-N tu-ples with the accompanying attachment decisions.This lead to 4562 tuples out of which 61% weremarked as noun attachments.
We used the sameprocedure to extract tuples from the first 10,000sentences of the NEGRA treebank.
This resultedin 6064 tuples with 56% noun attachment (for adetailed overview see (Volk, 2001) p. 86).
Againwe observe a substantial difference in the baseline.When our student Jo?rgen Aasa worked on repli-cating our German experiments for Swedish, heused a Swedish treebank from the 1980s for theextraction of test data.
He extracted V-N-P-N tu-ples from SynTag, a treebank with 5100 newspa-per sentences built by (Ja?rborg, 1986).
And Aasawas able to extract 2893 tuples out of which 73.8%were marked as noun attachments (Aasa, 2004)(p. 25).
This was a surprisingly high figure, andwe wondered whether this indicated a tendency inSwedish to avoid the PP in the ambiguous posi-tion unless it was to be attached to the noun.
Butagain the extraction process was done with a spe-cial purpose extraction program whose correctnesswas hard to verify.3 Querying Treebanks withTIGER-SearchWe therefore decided to check the attachment ten-dencies of PPs in various treebanks for the threelanguages in question with the same tool and withqueries that are as uniform as possible.For English we used the WSJ section of thePenn Treebank, for German we used our ownComputerZeitung treebank (3000 sentences), the82NEGRA treebank (10,000 sentences) and the re-cently released version of the TIGER treebank(50,000 sentences).
For Swedish we used theSynTag treebank mentioned above and one sec-tion of the Talbanken treebank (6100 sentences).All these treebanks consist of constituent structuretrees, and they are in representation formats whichallow them to be loaded into TIGER-Search.
Thisenables us to query them all in similar mannersand to get a fairer comparison of the attachmenttendencies.TIGER-Search is a powerful treebank querytool developed at the University of Stuttgart(Ko?nig and Lezius, 2002).
Its query languageallows for feature-value descriptions of syntaxgraphs.
It is similar in expressiveness to tgrep (Ro-hde, 2005) but it comes with graphical output andhighlighting of the syntax trees plus some nice sta-tistics functions.Our experiments for determining attachmenttendencies proceed along the following lines.
Foreach treebank we first query for all sequences of anoun immediately followed by a PP (henceforthnoun+PP sequences).
The dot being the prece-dence operator, we use the query:[pos="NN"] .
[cat="PP"]This query will match twice in the tree in fig-ure 1.
It gives us the frequency of all ambiguouslylocated PP.
We disregard the fact that in certainclause positions a PP in such a sequence cannotbe verb-attached and is thus not ambiguous.
Forexample, an English noun+PP sequence in subjectposition is not ambiguous with respect to PP at-tachment since the PP cannot attach to the verb.Similar restrictions apply to German and Swedish.In order to determine how many of these se-quences are annotated as noun attachments, wequery for noun phrases that contain both a nounand an immediately following PP.
This query willlook like:#np_mum:[cat="NP"] >#np_child:[cat="NP"] &#np_mum > #pp:[cat="PP"] &#np_child >* #noun:[pos="NN"] &#noun .
#ppAll strings starting with # are variables and the> symbol is the dominance operator.
So, thisquery says: Search for an NP (and call it np mum)that immediately dominates another NP (np child)AND that immediately dominates a PP, AND thenp child dominates a noun which is immediatelyfollowed by the PP.This query presupposes that a PP which is at-tached to a noun is actually annotated with thestructure (NP (NP (... N)) (PP)) which is true forthe Penn treebank (compare to the tree in figure 1).But the German treebanks represent this type of at-tachment rather as (NP (... N) (PP)) which meansthat the query needs to be adapted accordingly.4Such queries give us the frequency of allnoun+PP sequences and the frequency of all suchsequences with noun attachments.
These frequen-cies allow us to calculate the noun attachment rate(NAR) in our treebanks.NAR = freq(noun+ PP, noun attachm)freq(noun+ PP )We assume that all PPs in noun+PP sequenceswhich are not attached to a noun are attached to averb.
This means we ignore the very few cases ofsuch PPs that might be attached to adjectives (asfor instance the second PP in ?due for revision in1990?
).Different annotation schemes require modifica-tions to these basic queries, and different nounclasses (regular nouns, proper names, deverbalnouns etc.)
allow for a more detailed investiga-tion.
We now present the results for each languagein turn.3.1 Results for EnglishWe used sections 0 to 12 of the WSJ part of thePenn Treebank (Marcus et al, 1993) with a totalof 24,618 sentences for our experiments.
Our startquery reveals that an ambiguously located PP (i.e.a noun+PP sequence) occurs in 13,191 (54%) ofthese sentences, and it occurs a total of 20,858times (a rate of 0.84 occurrences per sentenceswith respect to all sentences in the treebank).Searching for noun attachments with the secondquery described in section 3 we learn that 15,273noun+PP sequences are annotated as noun attach-ments.
And we catch another 547 noun attach-ments if we query for noun phrases that containtwo PPs in sequence.5 In these cases the sec-ond PP is also attached to a noun, although not4There are a few occurrences of this latter structure in thePenn Treebank which should probably count as annotationerrors.5See (Merlo et al, 1997) for a discussion of these casesand an approach in automatically disambiguating them.83Figure 1: Noun phrase tree from the Penn Treebankto the noun immediately preceding it (as for ex-ample in the tree in figure 1).
With some simi-lar queries we located another 110 cases of nounattachments (most of which are probably anno-tation errors if the annotation guidelines are ap-plied strictly).
This means that we found a totalof 15,930 cases of noun attachment which corre-sponds to a noun attachment rate of 76.4% (bycomparison to the 20,858 occurrences).This is a surprisingly high number.
Neither(Hindle and Rooth, 1993) with 67% nor (Ratna-parkhi et al, 1994) with 59% noun attachmentwere anywhere close to this figure.
What have wedone differently?One aspect is that we only queried for singu-lar nouns (NN) in the Penn Treebank where pluralnouns (NNS) and proper names (NNP and NNPS)have separate PoS tags.
Using analogous queriesfor plural nouns we found that they exhibit a NARof 71.7%.
Whereas the queries for proper names(singular and plural names taken together) accountfor a NAR of 54.5%.Another reason for the discrepancy in the NARbetween Ratnaparkhi?s data and our calculationscertainly comes from the fact that we queriedfor all sequences noun+PP as possibly ambiguouswhereas they looked only at such sequences withinverb phrases.
But since we will do the same inboth German and Swedish, this is still worthwhile.3.2 Results for GermanThe three German treebanks which we investigateare all annotated in more or less the same man-ner, i.e.
according to the NEGRA guidelines whichwere slightly refined for the TIGER project.
Thisenabled us to use the same set of queries for allCZ NEGRA TIGERsize 3000 10,000 50,000noun+PP seq 4355 6,938 39,634occur rate 1.4 0.7 0.8noun attachm 2743 4102 23,969NAR 63.0% 59.1% 60.5%Table 1: Results for the German treebanksthree of them.
Since the German guidelines distin-guish between node labels for coordinated phrases(e.g.
CNP and CPP) and non-coordinated phrases(e.g.
NP and PP), these distinctions needed to betaken into account.
Table 1 summarizes the re-sults.Our own ComputerZeitung treebank (CZ) has amuch higher occurrence rate of ambiguously lo-cated PPs because the sentences were preselectedfor this phenomenon.
The general NEGRA andTIGER treebanks have an occurrence rate that issimilar to English (0.8).
The NAR varies between59.1% for the NEGRA treebank and 63.0% for theCZ treebank for regular nouns.The German annotation also distinguishes be-tween regular nouns and proper names.
Theproper names show a much lower noun attach-ment rate than the regular nouns.
The NAR in theCZ treebank is 22%, in the NEGRA treebank it is20%, and in the TIGER treebank it is only 17%.Here we suspect that the difference between theCZ and the other treebanks is based on the differ-ent text types.
The computer journal CZ containsmore person names with affiliation (e.g.
Stan Sug-arman von der Firma Telemedia) and more com-pany names with location (e.g.
Aviso aus Finn-84land) than a regular newspaper (that was used inthe NEGRA and TIGER corpora).As mentioned above, our previous experimentsin (Volk, 2001) were based on sets of extractedtuples from both the CZ and NEGRA treebanks.Our extracted data set from the CZ treebank hada noun attachment rate of 61%, and the one fromthe NEGRA treebank had a noun attachment rateof 56%.So why are our new results based on TIGER-Search queries two to three percents higher?
Themain reason is that our old data sets includedproper names (with their low noun attachmentrate).
But our extraction procedure comprised alsoa number of other idiosyncracies.
In an attemptto harvest as many interesting V-N-P-N tuples aspossible from our treebanks we exploited coordi-nated phrases and pronominal PPs.
Some exam-ples:1.
If the PP was preceded by a coordinatednoun phrase, we created as many tuplesas there were head nouns in the coordina-tion.
For example, the phrase ?den Aus-tausch und die gemeinsame Nutzung vonDaten .
.
.
ermo?glichen?
leads to the tuples(ermo?glichen, Austausch, von, Daten) and(ermo?glichen, Nutzung, von, Daten) bothwith the decision ?noun attachment?.2.
If the PP was introduced by coordinatedprepositions (e.g.
Die Argumente fu?r odergegen den Netzwerkcomputer), we created asmany tuples as there were prepositions.3.
If the verb group consists of coordinatedverbs (e.g.
Infos fu?r Online-Dienste aufbe-reiten und gestalten), we created as many tu-ples as there were verbs.4.
We regarded pronominal adverbs (darin,dazu, hieru?ber, etc.)
and reciprocal pronouns(miteinander, untereinander, voneinander,etc.)
as equivalent to PPs and created tu-ples when such pronominals appeared imme-diately after a noun.
See (Volk, 2003) for amore detailed discussion of these pronouns.3.3 Results for SwedishCurrently there is no large-scale Swedish treebankavailable.
But there are some smaller treebanksfrom the 80s which have recently been convertedto TIGER-XML so that they can also be queriedwith TIGER-Search.SynTag (Ja?rborg, 1986) is a treebank consist-ing of around 5100 sentences.
Its conversion toTIGER-XML is documented in (Hagstro?m, 2004).The treebank focuses on predicate-argument struc-tures and some grammatical functions such as sub-ject, head and adverbials.
It is thus different fromthe constituent structures that we find in the Penntreebank or the German treebanks.
We had toadapt our queries accordingly.
Since prepositionalphrases are not marked as such, we need to queryfor constituents (marked as subject, as adverbialor simply as argument) that start with a preposi-tion.
This results in a noun attachment rate of 73%(which is very close to the rate reported by (Aasa,2004)).
Again this does not include proper nameswhich have a NAR of 44% in SynTag.Let us compare these results to the secondSwedish treebank, Talbanken (first described by(Telemann, 1974)).
Talbanken was a remark-able achievement in the 80s as it comes with twowritten language parts (with a total of more than10,000 sentences from student essays and fromnewspapers) and two spoken language parts (withanother 10,000 trees from interviews and conver-sations).
We concentrated on the 6100 trees fromthe written part taken from newspaper texts.The occurrence rate in Talbanken is 0.76 (4658noun+PP sequences in 6100 sentences), which issimilar to the rates observed for English and Ger-man.
The occurrence rate in SynTag is higher 0.93(4737 noun+PP sequences in 5114 sentences).Talbanken (in its converted form) is annotatedwith constituent structure labels (NP, PP, VP etc.
)and also distinguishes coordinated phrases (CNP,CPP, CVP etc.).
The queries for determining thenoun attachment rate can thus be similar to thequeries over the German treebanks.
In addition,Talbanken comes with a rich set of grammaticalfeatures as edge labels (e.g.
there are different la-bels for logical subject, dummy subject and othersubject).We found that the NAR for regular nouns inTalbanken is 60.5%.
Talbanken distinguishes be-tween regular nouns, deverbal nouns (often withthe derivation suffix -ing: tja?nstgo?ring, utbildning,o?vning) and deadjectival nouns (mostly with thederivation suffix -het: skyldighet, snabbhet, verk-samhet).
Not surprisingly, these special nounshave higher NARs than the regular nouns.
The85deadjectival nouns have a NAR of 69.5%, and thedeverbal nouns even have a NAR of 77%.
Takentogether (i.e.
regarding all regular, deadjectivaland deverbal nouns) this results in a NAR of 64%.Thus, the NARs which we obtain from the twoSwedish treebanks (SynTag 73% and Talbanken64%) differ drastically.
It is unclear what this dif-ference depends on.
The text genre (newspapers)is the same in both cases.
We have noticed thatSynTag contains a number of annotation errors,but we don?t see that these errors favor noun at-tachment of PPs in a systematic way.
One aspectmight be the annotation decision in Talbanken toannotate PPs in light verb constructions.These are disturbing cases where the PP is achild node of the sentence node S (which meansthat it is interpreted as a verb attachment) withthe edge label OA (objektadverbial).
Nivre (2005,personal communication) pointed out that ?OA iswhat some theoreticians would call a ?preposi-tional object?
or a ?PP complement?, i.e.
a com-plement of the verb that semantically is close toan object but which is realized as a prepositionalphrase.?
In our judgement many of those casesshould be noun attachments (and thus be a childof an NP).For example, we looked at fo?rutsa?ttning fo?r (=prerequisite for) which occurs 14 times, out ofwhich 2 are annotated as OO (Other object) + OA,11 are annotated as noun attachments, and 1 is er-roneously annotated.
If we compare that to be-tydelse fo?r (= significance for) which occurs 16times out of which 13 are annotated as OO+OAand 3 are annotated as noun attachments, we won-der.First, it is obvious that there are inconsistenciesin the treebank.
We cannot see any reason whythe 2 cases of fo?rutsa?ttning fo?r are annotated dif-ferently than the other 11 cases.
The verbs do notjustify these discrepancies.
For example, we haveskapa (= to create) with the verb attachments andfo?rsvinna (= to disappear) with the noun attach-ment cases.
And we find ge (= to give) on bothsides.Second, we find it hard to follow the argumentthat the tendency for betydelse fo?r is stronger forthe OO+OA than for fo?rutsa?ttning fo?r.
It might bebased on the fact that betydelse fo?r is often usedwith the verb ha (= to have) and thus may countas a light verb construction with a verb group con-sisting of both ha plus betydelse and the fo?r-PPbeing interpreted as an object of this complex verbgroup.Third, unfortunately not all cases of PPs anno-tated as objektadverbial can be regarded as nounattachments.
But after having looked at some 70occurrences of such PPs immediately following anoun, we estimate that around 30% should be nounattachments.Concluding our observations on Swedish let usmention that the very few cases of proper namesin Talbanken have a NAR of 24%.4 Comparison of the resultsFor English we have computed a NAR of 76.4%based on the Penn Treebank, for German we foundNARs between 59% and 63% based on three tree-banks, and for Swedish we determined a puzzlingdifference between 73% NAR in SynTag and 64%NAR in Talbanken.
So, why is the tendency ofa PP to attach to a preceding noun stronger inEnglish than in Swedish which in turn shows astronger tendency than German?For English the answer is very clear.
The strongNAR is solely based on the dominance of thepreposition of.
In our section of the Penn Tree-bank we found 20,858 noun+PP sequences.
Outof these, 8412 (40% !!)
were PPs with the prepo-sition of.
And 99% of all of-PPs are noun attach-ments.
So, the preposition of dominates the Eng-lish NAR to the point that it should be treated sep-arately.6The Ratnaparkhi data sets (described above insection 2) contain 30% tuples with the prepositionof in the test set and 27% of-tuples in the trainingset.
The higher percentage of of-tuples in the testset may partially explain the higher NAR of 59%(vs. 52% in the training set).The dominance of of-tuples may also explainthe relatively high NAR for proper names in Eng-lish (54.5%) in comparison to 17% - 22% in Ger-man and similar figures for the Swedish Talbankencorpus.
The Penn Treebank represents names thatcontain a PP (e.g.
District of Columbia, AmericanAssociation of Individual Investors) with a regularphrase structure.
It turns out that 861 (35%) of the2449 sequences ?proper name followed by PP?
arebased on of-PPs.
The dominance becomes evenmore obvious if we consider that the following6This is actually what has been done in some research onEnglish PP attachment disambiguation.
(Ratnaparkhi, 1998)first assumes noun attachment for all of-PPs and then applieshis disambiguation methods to all remaining PPs.86prepositions on the frequency ranks are in (withonly 485 occurrences) and for (246 occurrences).The dominance of the preposition of is so strongin English that we will get a totally different pic-ture of attachment preferences if we omit of-PPs.The Ratnaparkhi training set without of-tuples isleft with a NAR of 35% (!)
and the test set has aNAR of 42%.
In other words, English has a cleartendency of attaching PPs to verbs if we ignore thedominating of-PPs.Neither German nor Swedish has such a dom-inating preposition.
There are, of course, prepo-sitions in both languages that exhibit a clear ten-dency towards noun attachment or verb attach-ment.
But they are not as frequent as the prepo-sition of in English.
For example, clear temporalprepositions like German seit (= since) are muchmore likely as verb attachments.Closest to the English of is the Swedish prepo-sition av which has a NAR of 88% in the Tal-banken corpus.
But its overall frequency does notdominate the Swedish ranking.
The most frequentpreposition in ambiguous positions is i (frequency:651 and NAR: 53%) followed by av (frequency:564; NAR: 88%) and fo?r (frequency: 460; NAR:42%).5 ConclusionThe most important conclusion to be drawn fromthe above experiments and observations is the im-portance of profiling the data sets when workingand reporting on PP attachment experiments.
Theprofile should certainly answer the following ques-tions:1.
What types of nouns where used when the tu-ples were extracted?
(regular nouns, propernames, deverbal nouns, etc.)2.
Are there prepositions which dominate in fre-quency and attachment rate (like the Englishpreposition of)?
If so, how does the data setlook like without these dominating preposi-tions?3.
What types of prepositions where regarded?
(regular prepositions, contracted prepositions(e.g.
in German am, im, zur), derived prepo-sitions (e.g.
English prepositions derivedfrom gerund verb forms following, including,pending) etc.)4.
Is the extraction procedure restricted tonoun+PP sequences in the verb phrase, ordoes it consider all such sequences?5.
What is the noun attachment rate in the dataset?In order to find dominating prepositions we sug-gest a data profiling that includes the frequencyand NARs of all prepositions in the data set.
Thiswill also give an overall picture of the number ofprepositions involved.Our experiments have also shown the advan-tages of large treebanks for comparative linguisticstudies.
Such treebanks are even more valuableif they come in the same representation schema(e.g.
TIGER-XML) so that they can be queriedwith the same tools.
TIGER-Search has provento be a suitable treebank query tool for our exper-iments although its statistics function broke downon some frequency counts we tried on large tree-banks.
For example, it was not possible to get alist of all prepositions with occurrence frequenciesfrom a 50,000 sentence treebank.Another item on our TIGER-Search wish list isa batch mode so that we could run a set of queriesand obtain a list of frequencies.
Currently we haveto trigger each query manually and copy the fre-quency results manually to an Excel file.Other than that, TIGER-Search is a wonderfultool which allows for quick sanity checks of thequeries with the help of the highlighted tree struc-ture displays in its GUI.We have compared noun attachment rates inEnglish, German and Swedish over treebanksfrom various sources and with various annotationschemes.
Of course, the results would be evenbetter comparable if the treebanks were built onthe same translated texts, i.e.
on parallel corpora.Currently, there are no large parallel treebanksavailable.
But our group works on such a par-allel treebank for English, German and Swedish.Design decisions and first results were reportedin (Volk and Samuelsson, 2004) and (Samuels-son and Volk, 2005).
We believe that such par-allel treebanks will allow a more focused andmore detailed comparison of phenomena acrosslanguages.6 AcknowledgementsWe would like to thank Jo?rgen Aasa for discus-sions on PP attachment in Swedish, and Joakim87Nivre, Johan Hall, Jens Nilsson at Va?xjo?
Univer-sity for making the Swedish Talbanken treebankavailable.
We also thank the anonymous review-ers for their discerning comments.ReferencesJo?rgen Aasa.
2004.
Unsupervised resolution of PP at-tachment ambiguities in Swedish.
Master?s thesis,Stockholm University.
Combined C/D level thesis.Michael Collins and James Brooks.
1995.
Prepo-sitional phrase attachment through a backed-offmodel.
In Proc.
of the Third Workshop on VeryLarge Corpora.Bo Hagstro?m.
2004.
A TIGER-XML version of Syn-Tag.
Master?s thesis, Stockhom University.D.
Hindle and M. Rooth.
1993.
Structural ambigu-ity and lexical relations.
Computational Linguistics,19(1):103?120.Jerker Ja?rborg.
1986.
SynTag Dokumentation.
Manualfo?r SynTaggning.
Technical report, Department ofSwedish, Go?teborg University.Esther Ko?nig and Wolfgang Lezius.
2002.
The TIGERlanguage - a description language for syntax graphs.Part 1: User?s guidelines.
Technical report.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn treebank.
Computa-tional Linguistics, 19(2):313?330.P.
Merlo, M.W.
Crocker, and C. Berthouzoz.
1997.
At-taching multiple prepositional phrases: generalizedbacked-off estimation.
In Proceedings of the SecondConference on Empirical Methods in Natural Lan-guage Processing.
Brown University, RI.A.
Ratnaparkhi, J. Reynar, and S. Roukos.
1994.
Amaximum entropy model for prepositional phrase at-tachment.
In Proceedings of the ARPA Workshopon Human Language Technology, Plainsboro, NJ,March.Adwait Ratnaparkhi.
1998.
Statistical models for un-supervised prepositional phrase attachment.
In Pro-ceedings of COLING-ACL-98, Montreal.Douglas L. T. Rohde, 2005.
TGrep2 User Man-ual.
MIT.
Available from http://tedlab.mit.edu/?dr/Tgrep2/.Yvonne Samuelsson and Martin Volk.
2005.
Presen-tation and representation of parallel treebanks.
InProc.
of the Treebank-Workshop at Nodalida, Joen-suu, May.J.
Stetina and M. Nagao.
1997.
Corpus-based PP at-tachment ambiguity resolution with a semantic dic-tionary.
In J. Zhou and K. Church, editors, Proc.of the 5th Workshop on Very Large Corpora, pages66?80, Beijing and Hongkong.Ulf Telemann.
1974.
Manual Fo?r GrammatiskBeskrivning Av Talad Och Skriven Svenska.
Inst.
fo?rnordiska spra?k, Lund.Vincent Vandeghinste.
2002.
Resolving PP attachmentambiguities using the WWW (abstract).
In Compu-tational Linguistics in the Netherlands, Groningen.Martin Volk and Yvonne Samuelsson.
2004.
Boot-strapping parallel treebanks.
In Proc.
of Work-shop on Linguistically Interpreted Corpora (LINC)at COLING, Geneva.Martin Volk.
2001.
The automatic resolution of prepo-sitional phrase attachment ambiguities in German.Habilitationsschrift, University of Zurich.Martin Volk.
2002.
Combining unsupervised and su-pervised methods for PP attachment disambiguation.In Proc.
of COLING-2002, Taipeh.Martin Volk.
2003.
German prepositions and their kin.a survey with respect to the resolution of PP attach-ment ambiguities.
In Proc.
of ACL-SIGSEM Work-shop: The Linguistic Dimensions of Prepositionsand their Use in Computational Linguistics For-malisms and Applications, pages 77?88, Toulouse,France, September.
IRIT.88
