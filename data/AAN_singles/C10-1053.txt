Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 465?473,Beijing, August 2010Normal-form parsing for Combinatory Categorial Grammarswith generalized composition and type-raisingJulia Hockenmaier Yonatan BiskUniversity of Illinois at Urbana-Champaign{juliahmr, bisk1}@illinois.eduAbstractWe propose and implement a modifica-tion of the Eisner (1996) normal form toaccount for generalized composition ofbounded degree, and an extension to dealwith grammatical type-raising.1 IntroductionCombinatory Categorial Grammar (Steedman,2000) is a linguistically expressive grammar for-malism that has been used for many NLP appli-cations, including wide-coverage parsing (Clarkand Curran, 2007; Hockenmaier, 2003) and se-mantic interpretation (Curran et al, 2007), se-mantic role-labeling (Gildea and Hockenmaier,2003; Boxwell et al, 2009), semantic parsing(Zettlemoyer and Collins, 2005) and natural lan-guage generation (Espinosa et al, 2008).An essential feature of CCG is its flexibleconstituent structure, licensed by type-raisingand composition rules which can create ?non-standard?
constituents such as ?John saw?, or?Mary talked to?, required in constructions in-volving non-local dependencies, such as wh-extraction (Fig.
1) or right-node raising.
Since?John saw?
can now also be a constituent in?John saw Mary?, this leads to a combinato-rial explosion of spurious ambiguities, i.e.
mul-tiple syntactic derivations of the same seman-tic interpretation (Wittenburg, 1986).
This cancreate problems for applications based on CCG,e.g.
for the induction of stochastic CCGs fromtext annotated with logical forms (Zettlemoyerand Collins, 2007), where spreading probabil-ity mass over equivalent derivations should beavoided.
A number of normal-form (NF) parsingalgorithms that aim to produce only one deriva-tion per interpretation have been proposed (Wit-tenburg, 1986; Niv, 1994; Pareschi and Steed-man, 1987; Hepple and Morrill, 1989; Eis-ner, 1996).
Computationally, such algorithmsare very attractive since they do not requirecostly semantic equivalence checks (Karttunen,1989; Komagata, 2004) during parsing.
Eis-ner?s (1996) normal form is the most devel-oped and well-known of these approaches, butis only defined for a variant of CCG wheretype-raising is a lexical operation and where thedegree of composition is unbounded.
There-fore, it and its equivalent reformulation by Hoytand Baldridge (2008) in a multimodal variant ofCCG are not safe (preserve all interpretations)and complete (remove all spurious ambiguities)for more commonly used variants of CCG.
Inparticular, this NF is not safe when the degreeof composition is bounded,1 and not completewhen type-raising is a grammatical operation.This paper defines a NF for CCG with boundedcomposition and grammatical type-raising.2 Combinatory Categorial GrammarIn CCG, every constituent (?John saw?)
has asyntactic category (S/NP) and a semantic in-terpretation (?x.saw(john?, x)).2 Constituentscombine according to a small set of language-1Although Eisner (1996, section 5) also provides a safeand complete parsing algorithm which can return non-NFderivations when necessary to preseve an interpretation ifcomposition is bounded or the grammar is restricted inother (arbitrary) ways.2More complex representations than simple predicate-argument structures are equally possible.the man that John sawNP (NP\NP)/(S/NP) NP (S\NP)/NP>TS/(S\NP)>B1S/NP>B0NP\NP<B0NPFigure 1: CCG derivations for wh-extraction465Application (>) X/Y : ?x.f(x) Y : a ?
X : f(a)(<) Y : a X\Y : ?x.f(x) ?
X : f(a)Composition (>B1) X/Y : ?x.f(x) Y/Z : ?y.g(y) ?
X/Y : ?z.f(g(z))(<B1) Y\Z : ?y.g(y) X\Y : ?x.f(x) ?
X\Y : ?z.f(g(z))(>B 1?)
X/Y : ?x.f(x) Y\Z : ?y.g(y) ?
X\Y : ?z.f(g(z))(<B 1?)
Y/Z : ?y.g(y) X\Y : ?x.f(x) ?
X/Y : ?z.f(g(z))(>Bn) X/Y : ?x.f(x) Y|Z1|...|Zn : ?zn..z1.g(z1...zn) ?
X|Z1|...|Zn : ?zn...z1.f(g(z1...zn))(<Bn) Y|Z1|...|Zn : ?zn..z1.g(z1...zn) X\Y : ?x.f(x) ?
X|Z1|...|Zn : ?zn...z1.f(g(z1...zn))Typeraising (>T ) For X ?
Carg : X : a ?
T/i(T\iX) : ?f.f(a)(<T ) For X ?
Carg : X : a ?
T\i(T/iX) : ?f.f(a)Figure 2: CCG?s combinatory rules.independent combinatory rules (Fig.
2).
The lex-icon pairs words with categories and interpreta-tions and is language-specific.Syntax We distinguish atomic (S, NP, PP,etc.)
from complex categories ((S\NP)/NP,N/N, etc.).
A complex category of the form X/Y(or X\Y) represents a function which returns aresult of type X when applied to an argumentof type Y, which, in the case of a forward slash(/) has to follow the functor, and in the case ofa backslash (\) has to preceed it.
X and Y canthemselves be complex again.
We will use cat-egories with vertical slashes when the directionof the slash does not matter, and may omit un-necessary parentheses (so X|Y|Z will represent(X\Y)/Z, (X\Y)\Z, ...).
We will also use theshorthand X|Y1..n (or X|?)
to refer to a categorywith (possibly complex) result X and argumentsY1...Yn (or an unspecified, possibly empty, listof arguments ?
= Y0...n, where |?| = n) thatcan each appear with either type of slash.Semantics If the category of a constituent isatomic (NP; S), its interpretation will also beatomic (kim?
; sleeps?(kim?
)), and if the categoryis a functor of arity n (X|Y1..n), the interpretationis a ?-expression ?yn..?y1?
(y1...yn) of arity n.The lexicon Each language defines a finite setof lexical category types Clex (e.g.
(S\NP)/NPis in the English lexicon, but (S\NP)\NP is not)with maximal arity NL.
This defines a set oflexical argument category types Carg , consist-ing of all categories Y that are the argumentof some lexical category (X|Y)|?
?
Clex (with|?| ?
0).
Since Clex is finite, Carg is strictlysmaller than Clex (and usually consists of basiccategories such as NP, S, S\NP).Combinatory Rules In addition to functionapplication (>,<), CCG has three kinds of com-binatory rules (Fig.
2): harmonic function com-position (>B(1), <B(1)), crossing function com-position (>B ?,<B ?)
and type-raising (>T ,<T ).
All rules take one or two input categoriesand yield one output category, and consist of asyntactic and a corresponding semantic opera-tion.
Composition also has generalized variants>Bn, <Bn up to a fixed degree NB .3 Compo-sition of unbounded degree increases the genera-tive capacity of CCG (Weir, 1988), and should bedisallowed.
Application (>,<) can be seen as aspecial case of composition (>B0,<B0).
Whencomposing X|Y with Y|Z to X|Z, we call X|Ythe primary input and Y|Z the secondary in-put.
Harmonic composition allows associativ-ity: the string A/B B/C C now has an alter-native derivation where A/B and B/C composeinto A/C, whereas crossing composition enablesnovel permutations, such as C A/B B\C.Type-raising swaps the functor-argument rela-tion.
Although it is often assumed to take placein the lexicon, we will distinguish lexical cate-gories (e.g.
for quantifiers) that have the syn-tactic type of type-raised categories, but seman-tics that could not be obtained by type-raising asimple category from grammatically type-raisedcategories.
We follow the common definitionof CCG (Steedman, 2000) and allow only cat-egories X ?
Carg to be type-raised.4 Instantia-3In X|Y1..n or X|?=X|Y1...|?|, we do not assume theslash variable | ?
{/, \} to be instantiated the same way forall Yi.
We will therefore only distinguish between forwardand backward generalized composition Bn>1.4We stipulate that it may be further necessary to onlyallow those argument categories to type-raise that are notused to project unbounded dependencies, such as S/NP in466tions of the variable T should also be restrictedto categories of finite arity NT in oder to pre-vent an increase in generative capacity (Hoff-man, 1995; Komagata, 1997).
We refer to thearity of T as the degree of any particular instan-tation of T .
We follow Steedman (2000) andassume NT = NB .Coordination requires a ternary rule (?)
whichcan be binarized (?>, ?<) to simplify parsing:5(?)
X conj X ?
X(?>) X X[conj] ?
X(?<) conj X ?
X[conj]Uses of type-raising and composition In En-glish, type-raising and composition are requiredfor wh-extraction and right node raising of argu-ments as well as so-called argument cluster co-ordination.
In other languages, they are neededfor scrambling and cross-serial dependencies.It is important to note that when type-raising isrequired, it always occurs in tandem with com-position.
Since type-raising an argument Y toX/(X\Y) and applying it to the functor X\Y issemantically equivalent to applying X\Y directlyto Y, type-raising is never required when func-tion application can be used instead.
That is, inall cases, a type-raised argument must be com-posed with another constituent, usually the orig-inal functor (head).
Only in argument-cluster co-ordination will the type-raised element be com-posed with a non-head constituent.
In the lat-ter case, coordination will be required beforethe argument cluster can be combined with thehead.
Composition without type-raising may oc-cur, e.g.
for adjuncts, which have categories X|X,but may modify a constituent with category X|?.Restrictions on type-raising and compositionIn order to prevent overgenerations of the form?John speaks because Chinese, he enjoys Bei-jing.
?, we assume a variant of CCG in whichforward crossing composition >B 1?
(e.g.
of be-cause:(S/S)/S) into the result of backward type-raising <T (e.g.
Chinese:S\(S/NP), and, simi-larly, <Bx into the result of >T , are disallowed.
(NP\NP)/(S/NP) for English object relative pronouns.5Here, X needs to be restricted to a finite set of cate-gories (Weir, 1988).
In multimodal CCG, conjunction havecategories of the form (X?\?X)/?X, i.e.
must apply to theirargumentPunctuation and Type-changing rules CCG-bank (Hockenmaier and Steedman, 2007) usesspecial punctuation rules such as S .
?
S or, NP\NP ?
NP\NP, and a small number of(non-recursive) type-changing rules (with id-iosyncratic semantics) such as N ?
NP (fordeterminer-less NPs) or S[pss]\NP ?
NP\NP(for complex adjuncts, here passive VPs beingused as NP postmodifiers):Punctuation (>P) X:?
[., ; ] ?
X:?
(<P) [., ; ] X:?
?
X:?TypeChanging (TCR) X:?
?
Y:?(?
)CCG parsing CCG can be parsed with abottom-up CKY-like algorithm (Shieber et al,1995; Steedman, 2000), which differs from stan-dard CKY in that it requires one (or two) unarycompletion steps in each cell to deal with type-raising (and type changing).6 Chart items are ofthe form ?X, i, j?, where X is a category, and theindices i and j represent the span of the item.Interpretations need only to be constructed forcomplete derivations when unpacking the chart.3 The Eisner normal formThe Eisner normal form Eisner (1996)presents a normal-form parsing algorithm forCCG without grammatical type raising (wherethe lexicon may still contain categories likeS/(S\NP), but there is no combinatory rulethat changes a complex (derived) NP to e.g.S/(S\NP)).
He proves that his algorithm findsonly one canonical derivation for each semanticinterpretation of an input string consisting of asequence of words and their lexical categories.Since the presence of both pre- and postmodi-fiers (as in ?intentionally knock twice?7) intro-duces a genuine ambiguity, Eisner proves thatthe only kind of spurious ambiguity that canarise in his variant of CCG is due to associativechains of composition such as A/B B/C C/D orA/B B/C C\D, which can be derived as either6Since composition allows the arity of derived (?
non-terminal) CCG categories to grow with the length of theinput string, worst-case complexity of this naive algorithmis exponential.
(Vijay-Shanker and Weir, 1993)?s O(n6)algorithm has a more compact representation of categories.7This can mean ?x.intentionally ?
(twice ?
(knock ?
(x)))or ?x.twice ?
(intentionally ?
(knock ?
(x))).467Eisner NF Not Eisner NF(A|B1..b)/C (C|D1..d)/E (E|F1..f)/G G|H1..h>Bh(E|F1..f)|H1..h>Bf+h((C|D1..d)|F1..f)|H1..h>Bd+f+h(((A|B1..b)|D1..d)|F1..f)|H1..h(A|B1..b)/C (C|D1..d)/E (E|F1..f)/G G|H1..h>Bd+1((A|B1..b)|D1..d)/E>Bf+1(((A|B1..b)|D1..d)|F1..f)|G>Bh(((A|B1..b)|D1..d)|F1..f)|H1..hFigure 3: Eisner NF and generalized composition Bn>1Left branching Right branching>B0(>Bm+1,...)?>Bm?0(...,>B0) A/B (B|D0..m)/C C m ?
0>B1(>Bm?1,...)?>Bm?1(...,>B1) A/B (B|C1...m?1)/D D/E m ?
1>Bn?1(>B1,...) ?>Bn(...,>Bm=n) A/B B/C C/D1..n m = n ?
1?
:>Bn>1(...,>Bm>n) A/(B|D1..k) B/C ((C|D1..k)|E1..n m > n > 1>Bm(>Bk,...) ?>Bn>1(...,>B1<m<n) A/B (B|C1..k?1)/D D|E1..m n > m > 1Figure 4: Associative composition chains: our NF disallows the grayed-out derivations.>B (..., >B ) or >B (>B , ).
This is eliminatedby the following constraint:Eisner NF Constraint 1.
The output X|?
offorward composition >Bn>0 cannot be the pri-mary input to forward application or composi-tion >Bm?0.
The output of <Bn>0 cannot bethe primary input to <Bm?0.This can be implemented by a ternary featureHE ?
{>Bn, <Bn, ?}
and chart items of theform ?X, HE, i, j?
where HE =>Bn (or <Bn)if X was produced by the corresponding compo-sition rule (for any n > 0) and ?
otherwise.4 A new normal form for CCG4.1 Generalized compositionEisner NF and generalized composition Un-boundedly long sequences of generalized com-position are required e.g.
for Dutch verb clus-ters that give rise to cross-serial dependen-cies (N1...NnV1...Vn with Ni the argument ofVi).
These can be obtained through standardbounded-degree compositions, but the Eisner NFproduces a derivation that requires compositionsof unbounded degree (Fig.
3).
Although this isallowed in the variant of CCG Eisner considers,compositions of unbounded degree are usuallydisallowed because they increase the generativecapacity of CCG (Weir, 1988).
We stipulate thatthe NF of any derivation ?
should not requirecomposition rules of higher degree than ?
itself.Note that the output of function application (B0)always has lower arity than its functor; the outputof regular composition (B1) has the same arity asits primary functor, but the output of generalizedcomposition (Bn>1) has an arity that is n ?
1higher than that of the primary functor.
Bn>1therefore requires a different treatment.Our reformulation of the Eisner NF As-sociative composition chains for constituentsA B C can lead to spurious ambiguity if both aleft-branching >Bn(>Bm(A B) C) and a right-branching >Bn?
(A >Bm?
(B C)) are possible andlead to the same interpretation.
Figure 4 il-lustrates all possible cases consisting of threeconstituents.
In most cases, the right-branching(Eisner NF) derivation is to be preferred.
Forgeneralized composition >Bn>1, >Bm>1, left-branching >Bn>1(>Bm>1, ...) is always al-lowed, but right-branching >Bn(..., >Bm) isonly allowed if m ?
n.NF Constraint 1 (B0 and Bn?1).
The output of>Bn?1 (resp.
<Bn?1) cannot be primary func-tor for >Bn?1 (resp.
<Bn?1).NF Constraint 2 (B1 and Bn?1).
The output of>B1 (resp.
<B1) cannot be primary functor for>Bn?1 (resp.
<Bn?1).NF Constraint 3 (Bn>1 and Bm>1).
The out-put of >Bm (resp.
<Bm) cannot be secondaryfunctor for >Bn>m (resp.
<Bn>m).4.2 Grammatical type-raisingEisner NF and type-raising Figure 5 illus-trates a spurious ambiguity arising through type-468which Sue ate happilyNP : (S\NP)/NP : S\S :s?
?y.?x.ate?
(x, y) ?z.happily?
(z)>TS/(S\NP) :?f.f(s?
)>B1S/NP : ?y.ate?
(s?, y)<B1?S/NP : ?y.happily?(ate?
(s?, y))which Sue ate happilyNP : (S\NP)/NP : S\S :s?
?y.?x.ate?
(x, y) ?z.happily?
(z)>TS/(S\NP) :?f.f(s?)<B2?
(S\NP)/NP :?y.?x.happily?(ate?
(x, y))>B1S/NP : ?y.happily?(ate?
(s?, y))Figure 5: The Eisner NF allows spurious ambiguity arising due to type-raisingraising that the Eisner NF does not exclude.8Here two derivations can be obtained becausethe result of combining the adverb with thesubject-verb cluster is no longer the output ofa forward composition, and can therefore ap-ply to the object.
The derivations are semanti-cally equivalent: although type-raising reversesthe syntactic functor-argument relation, a type-raised argument applied to a predicate returnsthe same interpretation as when the predicateis applied directly to the original.
But Eis-ner treats S/(S\NP) as a category with se-mantics ?x.?
(x), in which case the derivationsyield indeed different scope relations.
Eis-ner?s analyis is correct for certain classes ofwords which have lexical categories that ap-pear like type-raised categories, but have a dif-ferent interpretation from that of categories ob-tained by type-raising.
These are usually scope-bearing elements, such as the universal quantiferevery ((S/(S\NP))/N : ?P?Q?xP(x) ?
Q(x)),and there may not be a single derivation whichcaptures all semantic interpretations.
Lexical-ized pseudo-type-raising therefore needs to bedistinguished from grammatical type-raising.Our extension of the (modified) Eisner NFIn Fig.
5, Eisner NF licenses two derivations.Both contain an instance of composition inwhich the type-raised argument is the primarycomponent.
In the analysis in which this is thesecond derivation step, the canceled part of this<B2 composition (boxed) contains a category(\NP) that was part of the argument output ofthe first >B1 composition (bold-faced):8We have chosen a slighly unusual adverb category toillustrate a general problem.which Sue ate happilyS/ (S\NP) (S\NP)/NP S\S<B2?S\NP /NP>B1S/NPOur NF will eliminate derivations of this typeand prefer the other, lower-degree derivation.We stipulate that the spurious ambiguities thatarise through type-raising and composition canbe eliminated through the following rule:NF Constraint 4 (T and Bn>0).
The output of>T cannot be primary input to >Bn>0 if thesecondary input is the output of <Bm>n.
Theoutput of <T cannot be primary input in <Bn>0if the secondary input is the output of >Bm>n.We also stipulate that a type-raised T/(T\X)cannot be used as a functor in application (sinceT\X could always apply directly to X).NF Constraint 5 (T and B0).
The output of for-ward (or backward) type-raising >T (resp.
<T )cannot be the functor in application > (resp.
<).Additional spurious ambiguities arise throughthe interaction of type-raising and coordination:Since any category can be coordinated, we caneither coordinate X and then type-raise the co-ordinated X to T/(T\X), or we can first type-raise each conjunct to T/(T\X) and then con-join.
Since nonsymmetric coordinations of anargument-adjunct cluster and a single argument(as in eats ((pizza for lunch) and pasta)) requiretype-raising before coordination, we formulatethe following rule to eliminate interactions be-tween type-raising and coordination:NF Constraint 6 (T and ?).
The result of coor-dination ?
cannot be type-raised.469NF Derivation A NF Derivation BA B CX/X : (X|?a)|?b : (X|?a)\(X|?a) :?Pa(P ) ?xbxab(xaxb) ?Q?zac(Q(za))<Bb(X|?a)|?b : ?xbxac(b(xaxb))>Ba+b?
(X|?a)|?b : ?xbxaa(c(b(xaxb)))A B CX/X : (X|?a)|?b : (X|?a)\(X|?a) :?Pa(P ) ?xbxab(xaxb) ?Q?zac(Q(za))>Ba+b?
(X|?a)|?b : ?xbxaa(b(xaxb))<Bb?
(X|?a)|?b : ?xbxac(a(b(xaxb)))Figure 6: Constituents with pre- and postmodifiers have two semantically distinct derivationsPunctuation and Type-changing rules Punc-tuation results in spurious ambiguities, eitherwhen a constituent X has both an initial and a fi-nal punctuation mark (e.g.
a comma), or when ithas an initial (final) punctuation mark and a final(initial) modifier.
The first case is easy to fix bydisallowing the output of , X ?
X to be the in-put of X ,?
X.
The latter could be eliminated bydisallowing the output X of right-recursive (left-recursive) punctuation rule to be secondary inputto any left-recursive (right-recursive) applicationor composition rule (e.g.
X X\X ?
X).9Implementation Our normal-form constraintscan be implemented in a bottom-up parser withitems of the form ?X, C, i, j?, withC ?
{>, >B 1, >B 2, ..., >Bn; <, <B 1, <B 2, ..., <Bn;>T , <T , >Pct,<Pct, ?>, ?<, TCR}4.3 Is our normal form safe and complete?Here we sketch the beginnings of a proof thatour algorithm allows one and only one syntac-tic derivation per semantic interpretation for theversion of CCG we consider.
We first examineall cases of two adjacent constituents A, B whichmust combine into a category C:Functor X/Y and argument Y combine to XThe functor must apply to the argument.
The ar-gument could type-raise, but then cannot apply.Functor X/Y|?
and argument Y combine toX|?
The functor cannot apply to the argument.The argument must type-raise to X\(X/Y), andcan then backward-compose into the functor.Functor X/X and X\X can combine to X/X orX\X This is not a spurious ambiguity, since theoutput categories are different.9If punctuation can be used both with X and Y, it alsointeracts with type-changing rules X ?
Y.
Our currentimplementation does not deal with this case.Functor X|Y and Y|Z combine to X|Z Our re-formulation of Eisner?s NF eliminates spuriousambiguities that are due to such associative com-position chains.
This covers not only argumentclusters (which must compose), but also ambigu-ous cases where one constituent (e.g.
Y/Z with?
= ) is the argument of the first (X/Y), and ei-ther takes the third (Z) as its own argument or ismodified by the third Y\Y (there are, of course,other arrangements of such categories which arenot ambiguous, e.g.
X/Y Z Y\Z.We now focus our attention on the ternarycases in which one of the constituents is a head(predicate), and the other two are either its argu-ments or modifiers.
The counterexample to Eis-ner?s normal-form algorithm shows that there isat least one additional kind of spurious ambigu-ity that arises when there are three adjacent con-stituents A, B, C and both A and C can composeinto B.
There are three cases: 1) A and C areboth modifiers of B, 2) one of A or C is a mod-ifier of B, the other is an argument of B, and 3)A and C are both arguments of B.
Only 1) is areal ambiguity, but the other cases are instancesof spurious ambiguity which our NF eliminates.Argument Y, head (X\Y)/Z and argument Zcombine to X In the NF derivation, the headapplies first to the Z, than to Y.
All other deriva-tions are blocked, either because type-raised cat-egories cannot apply, or because the output ofcomposition cannot apply.Modifier X/X, head (X|?)|?
and modifier(X|?)\(X|?)
combine to (X|?)|?
(Fig.
4.2).This is the ?intentionally knock twice?
example.The derivations have different semantics.Argument Y, head ((X|?
)\Y)|?, and modifierX\X combine to (X|?)|?
(Fig.
7).
If there isan ambiguity, B must have a category of the form470Normal form Not normal formA B CY ((X|?a)\Y)|?b : X\Xa ?xbxixab(xaxixb) ?Q?zac(Q(za))>T(X|?a)/((X|?a)\Y) :?P?yaP (aya)>Bb?
(X|?a)|?b : ?xbxab(xaaxb)<Ba+b?
(X|?a)|?b : ?xbxac(b(xaaxb))A B CY ((X|?a)\Y)|?b : X\Xa ?xbxixab(xaxixb) ?Q?zac(Q(za))>T <Ba+b+1?
(X|?a)/((X|?a)\Y) : ((X|?a)\Y)|?b :?P?yaP (aya) ?xbxixac(b(xaxixb))>Bb?
(X|?a)|?b : ?xbxac(b(xaaxb))Figure 7: Argument Y, head ((X|?a)\Y)|?b, and modifier X\X combine to (X|?a)|?bNormal form Not normal formA B CY (((X\Y)|?a)/Z)|?b Za ?xbxjxaxib(xixaxjxb) c>T <TX/(X\Y) ((X\Y)|?a)\(((X\Y)|?a)/Z)?P?yaP (aya) ?Q?zazizaQ(czaziza)<Bb?
((X\Y)|?a)|?b : ?xbxaxib(xixacxb)>Ba+b?
(X|?a)|?b : ?xbxab(axacxb)A B CY (((X\Y)|?a)/Z)|?b : Za ?xbxjxaxib(xixaxjxb) c>T <TX/(X\Y) (X|?a)\((X|?a)/Z)?P?yaP (aya) ?Q?zaQ(cza)>Ba+b+1?
((X|?a)/Z)|?b : ?xbxjxab(axaxjxb)<Bb?
(X|?a)|?b : ?xbxab(axacxb)Figure 8: Argument Y, head (((X\Y)|?)/Z)|?
and argument Z combine to (X|?)|?((X|?)\Yi)|?
(with X possibly complex and ?, ?possibly empty), and C must have a category ofthe form X\X.
We obtain the NF derivation byfirst combining head and argument, followed bythe modifier.
The other derivation violates theNF constraints.Argument Y, head (((X\Y)|?)/Z)|?
and ar-gument Z combine to (X|?)|?
(Fig.
8) Thederivation in which Z composes first is in NF.The derivation in which the Y combines firstwith the head is blocked.Arguments YA, YB, head (((X\Y1)|?
)\Y2)|?combine to (X|?)|?
There are two readings:standard (YA:=Y1, YB:=Y2), and scrambled(YA:=Y2, YB:=Y1).
If ?
and ?
are empty, func-tion application is sufficient for the standardreading, and our NF constraint 1 excludes the?argument cluster?
derivation in which both YAand YB type-raise, compose and then apply to thehead.
Otherwise, at least one of the argumentshas to type-raise and compose into the head.
Ifboth ?
and ?
are non-empty, each interpretationhas only one derivation in which the type-raisedYA composes into the output of the compositionof the type-raised YB with the head.
Since thedegree of the second composition is lower thanthe first, this is allowed by our NF constraint 2.Argument YA and heads (((X\Y1)|?
)/Z and((Z|?)\Y2)|?
combine to (((X|?)|?)\Y2)|?
orto (((X|\Y1?)|?)|?
There are two readings:standard (YA:=Y1) or scrambled (YA:=Y2).
De-pending on the maximal degree n of Bn allowedby the grammar, the standard reading one can ei-ther be obtained by type-raising YA and compos-ing into the first head (allowed by our NF) or byfirst composing the two heads and then compos-ing the type-raised YA into the cluster (allowedby Eisner, but not by us).
The second readingrequires the heads to compose and then YA toapply or compose (depending on the arity of ?
),which is allowed by our NF constraint 2 becausethe degree of this second composition is lowerthan that of the first.Our NF and the bound NT on type-raisingIf X\X in Fig.
7 is replaced with a (non-type-raised) category Z\X (for Z= X), the non-NFderivation requires T|Z|+a, whereas the NF-derivation requires T|X|+a.
If we stipulate a fi-nite bound NT on the degree of type-raising,and if |X| > |Z| and |X| + a > NT , ourNF cannot be derived anymore.
If such Z\X(with X ?
Carg ) can be derived from the lexi-con, our NF requires therefore a potentially un-bounded degree of type-raising.
The T-degree471Sentence length l=15...3015 20 25 30No NF (total #derivs) 4.13E6 5.66E8 3.06E11 1.59E14Eisner B 18.92% 9.05% 3.63% 2.14%Our B 18.38% 8.97% 3.60% 2.02%Our B , T 2.92% 1.22% 0.37% 0.10%Our full NF 2.60% 0.93% 0.33% 0.09%(a) Median % of allowed derivationsSentence length l= 30Min Mean Median MaxNo NF 5.99E9 8.19E15 1.59E14 2.61E17Eisner B 1.60% 2.68% 2.14% 2.76%Our B 1.57% 2.49% 2.02% 2.69%Our B ,T 0.64% 0.07% 0.10% 0.05%Our full NF 0.53% 0.06% 0.09% 0.05%(b) Statistics on the % of allowed derivationsFigure 9: Experimental results: the effect of different normal forms on the number of derivationsof the non-NF derivation in Fig.
8 is also one lessthan that of the NF derivation, but its B-degree isincreased by one, so for NT = NB either bothderivations are possible or neither.What remains to be proven is that we haveconsidered all cases of spurious ambiguity in-volving three constituents, and that all cases ofspurious ambiguity that arise for more than threeconstituents reduce to these cases.5 The effects of normal form parsingWe now illustrate the impact of the different nor-mal form variants on a small, restricted, gram-mar.
We define a set of atomic categories, a set oflexical categories (up to a fixed arity NLex), andcompile out all possible rule instantiations (in-cluding compositions up to a fixed degree N|B)that generate categories up to a fixed arity Ncat10The effect of different normal forms Thisexperiment is intended to examine how nor-mal form parsing might reduce spurious ambi-guity for actual grammars, e.g.
for unsuper-vised estimation of stochastic CCGs.
We cre-ated a small English grammar with atomic cat-egories S,NP,N, conj, ., , ; and 47 lexical cate-gories using NLex = 3, NB = 3, NCat = 15.There are two type-changing rules (N ?
NPand S/NP ?
NP\NP ).
We accept deriva-tions of S, NP and S\NP.
The T|X in T hasto be a lexical category.
Our lexical categoriesare divided into disjoint sets of adjuncts of theform X|X and (X|X)|Y, head (both atomic andcomplex), and punctuation and conjunction cat-egories.
The comma can act as a conjunction orto set off modifiers (requiring punctuation rules10The restriction of categories to a fixed aritymeans that we could generate cross-serial dependenciesN1...NnV1...Vn only up to n = Acat .of the form X|X , ?
X|X and , X|X ?
X|X).We furthermore define coarse-grained parts ofspeech (noun, verb, function word, conj, other)and decide for each part of speech which lexicalcategories it can take.
We compare different NFsettings for sentences of lengths 15?30 from Eu-roparl (Koehn, 2005).
At each length, we com-pare 100 sentences that our grammar can parse.All NFs can parse all sentences the full grammarcan parse.
Results (Fig.
9(a)) show that our NFreduces the number of derivations significantlyover Eisner?s NF, even though our (full) gram-mar only allows a restricted set of type-raisingrules.
Fig.
9(b) illustrates the combinatorial ex-plosion of spurious derivations as the sentencelength increases.6 ConclusionsWe have proposed a modification and extensionof Eisner (1996)?s normal form that is more ap-propriate for commonly used variants of CCGwith grammatical type-raising and generalizedcomposition of bounded degree, as well as somenon-combinatory extensions to CCG.
Our exper-iments indicate that incorporating normal formconstraints to deal with grammatical type-raisingdrastically reduces the number of derivations.We have sketched the outline of a proof that ournormal form is safe and complete for the variantof CCG we consider, althoug we have seen thatunder certain circumstances, type-raising of un-bounded degree may be required.
Future workwill investigate this issue further, and will alsoaim to turn our informal arguments about the ad-equacy of our approach into a full proof, and pro-vide more experiments on a wider range of gram-mars and languages.472ReferencesBoxwell, Stephen, Dennis Mehay, and Chris Brew.2009.
Brutus: A semantic role labeling system in-corporating CCG, CFG, and dependency features.In Proceedings of the 47th ACL/4th IJCNLP, pages37?45.Clark, Stephen and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with CCGand log-linear models.
Computational Linguistics,33(4):493?552.Curran, James, Stephen Clark, and Johan Bos.2007.
Linguistically motivated large-scale NLPwith C&C and boxer.
In Proceedings of the 45thACL Companion Volume (Demo and Poster Ses-sions), pages 33?36, Prague, Czech Republic.Eisner, Jason.
1996.
Efficient normal-form pars-ing for Combinatory Categorial Grammar.
In Pro-ceedings of the 34th ACL, pages 79?86, SantaCruz, CA.Espinosa, Dominic, Michael White, and DennisMehay.
2008.
Hypertagging: Supertagging forsurface realization with CCG.
In Proceedings ofACL-08: HLT, pages 183?191, Columbus, Ohio.Gildea, Daniel and Julia Hockenmaier.
2003.
Iden-tifying semantic roles using Combinatory Catego-rial Grammar.
In Proceedings of EMNLP, Sap-poro, Japan.Hepple, Mark and Glyn Morrill.
1989.
Parsing andderivational equivalence.
In Proceedings of theFourth EACL, pages 10?18, Manchester, UK.Hockenmaier, Julia and Mark Steedman.
2007.CCGbank: A corpus of CCG derivations and de-pendency structures extracted from the penn tree-bank.
Computational Linguistics, 33(3):355?396.Hockenmaier, Julia.
2003.
Data and models forstatistical parsing with Combinatory CategorialGrammar.
Ph.D. thesis, School of Informatics,University of Edinburgh.Hoffman, Beryl.
1995.
Computational Analysis ofthe Syntax and Interpretation of ?Free?
Word-orderin Turkish.
Ph.D. thesis, University of Pennsylva-nia.
IRCS Report 95-17.Hoyt, Frederick and Jason Baldridge.
2008.
A log-ical basis for the D combinator and normal formin CCG.
In Proceedings of ACL-08: HLT, pages326?334, Columbus, Ohio.Karttunen, Lauri.
1989.
Radical lexicalism.
InBaltin, M.R.
and A.S. Kroch, editors, AlternativeConceptions of Phrase Structure.
Chicago Univer-sity Press, Chicago.Koehn, Philipp.
2005.
Europarl: A parallel cor-pus for statistical machine translation.
In 10th MTSummit, pages 79?86, Phuket, Thailand.Komagata, Nobo.
1997.
Generative power ofCCGs with generalized type-raised categories.
InACL35/EACL8 (Student Session), pages 513?515.Komagata, Nobo.
2004.
A solution to the spuriousambiguity problem for practical combinatory cate-gorial grammar parsers.
Computer Speech & Lan-guage, 18(1):91 ?
103.Niv, Michael.
1994.
A psycholinguistically moti-vated parser for CCG.
In Proceedings of The 32ndACL, Las Cruces, NM, pages 125?132.Pareschi, Remo and Mark Steedman.
1987.
A lazyway to chart parse with categorial grammars.
InProceedings of the 25th ACL, pages 81?88, Stan-ford, CA.Shieber, Stuart M., Yves Schabes, and FernandoC.
N. Pereira.
1995.
Principles and implemen-tation of deductive parsing.
Journal of Logic Pro-gramming, 24(1?2):3?36, July?August.Steedman, Mark.
2000.
The Syntactic Process.
MITPress, Cambridge, MA.Vijay-Shanker, K and David J Weir.
1993.
Parsingsome constrained grammar formalisms.
Compu-tational Linguistics, 19(4):591?636.Weir, David.
1988.
Characterising Mildly Context-sensitive Grammar Formalisms.
Ph.D. thesis, Uni-versity of Pennsylvania.
Tech.
Report CIS-88-74.Wittenburg, Kent B.
1986.
Natural Language Pars-ing with Combinatory Categorial Grammar in aGraph-Unification Based Formalism.
Ph.D. the-sis, University of Texas at Austin.Zettlemoyer, Luke S. and Michael Collins.
2005.Learning to map sentences to logical form: Struc-tured classification with probabilistic categorialgrammars.
In Proceedings of the 21st UAI, pages658?666, Edinburgh, UK.Zettlemoyer, Luke and Michael Collins.
2007.
On-line learning of relaxed CCG grammars for pars-ing to logical form.
In Proceedings of EMNLP-CoNLL, pages 678?687, Prague, Czech Republic.AcknowledgementsWe would like to thank Mark Steedman for help-ful discussions, and Jason Eisner for his verygenerous feedback which helped to greatly im-prove this paper.
All remaining errors and omis-sions are our own responsibility.
J.H is supportedby NSF grant IIS 08- 03603 INT2-Medium.473
