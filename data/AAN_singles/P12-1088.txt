Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 835?844,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsAutomatic Event Extraction with Structured Preference ModelingWei Lu and Dan RothUniversity of Illinois at Urbana-Champaign{luwei,danr}@illinois.eduAbstractThis paper presents a novel sequence label-ing model based on the latent-variable semi-Markov conditional random fields for jointlyextracting argument roles of events from texts.The model takes in coarse mention and typeinformation and predicts argument roles for agiven event template.This paper addresses the event extractionproblem in a primarily unsupervised setting,where no labeled training instances are avail-able.
Our key contribution is a novel learningframework called structured preference mod-eling (PM), that allows arbitrary preferenceto be assigned to certain structures during thelearning procedure.
We establish and discussconnections between this framework and otherexisting works.
We show empirically that thestructured preferences are crucial to the suc-cess of our task.
Our model, trained with-out annotated data and with a small numberof structured preferences, yields performancecompetitive to some baseline supervised ap-proaches.1 IntroductionAutomatic template-filling-based event extraction isan important and challenging task.
Consider the fol-lowing text span that describes an ?Attack?
event:.
.
.
North Korea?s military may have fired a laserat a U.S. helicopter in March, a U.S. officialsaid Tuesday, as the communist state ditched itslast legal obligation to keep itself free of nuclearweapons .
.
.A partial event template for the ?Attack?
event isshown on the left of Figure 1.
Each row shows anargument for the event, together with a set of its ac-ceptable mention types, where the type specifies ahigh-level semantic class a mention belongs to.The task is to automatically fill the template en-tries with texts extracted from the text span above.The correct filling of the template for this particularexample is shown on the right of Figure 1.Performing such a task without any knowledgeabout the semantics of the texts is hard.
One typi-cal assumption is that certain coarse mention-levelinformation, such as mention boundaries and theirsemantic class (a.k.a.
types), are available.
E.g.:.
.
.
[North Korea?s military]ORG may have fired[a laser]WEA at [a U.S. helicopter]VEH in[March]TME, a U.S. official said Tuesday, as thecommunist state ditched its last legal obligationto keep itself free of nuclear weapons .
.
.Such mention type information as shown on theleft of Figure 1 can be obtained from various sourcessuch as dictionaries, gazetteers, rule-based systems(Stro?tgen and Gertz, 2010), statistically trained clas-sifiers (Ratinov and Roth, 2009), or some web re-sources such as Wikipedia (Ratinov et al, 2011).However, in practice, outputs from existing men-tion identification and typing systems can be farfrom ideal.
Instead of obtaining the above ideal an-notation, one might observe the following noisy andambiguous annotation for the given event span:.
.
.
[[North Korea?s]GPE|LOC military]ORG may havefired a laser at [a [U.S.]GPE|LOC helicopter]VEHin [March]TME, [a [U.S.]GPE|LOC official]PER said[Tuesday]TME, as [the communist state]ORG|FAC|LOCditched its last legal obligation to keep [itself ]ORGfree of [nuclear weapons]WEA .
.
.Our task is to design a model to effectively selectmentions in an event span and assign them with cor-responding argument information, given such coarse835Argument Possible Types Extracted TextATTACKER GPE, ORG, PER N. Korea?s militaryINSTRUMENT VEH, WEA a laserPLACE FAC, GPE, LOC -TARGETFAC, GPE, LOCa U.S. helicopterORG, PER, VEHTIME-WITHIN TME MarchFigure 1: The partial event template for the Attack event (left),and the correct event template annotation for the example eventspan given in Sec 1 (right).
We primarily follow the ACE stan-dard in defining arguments and types.and often noisy mention type annotations.This work addresses this problem by making thefollowing contributions:?
Naturally, we are interested in identifying theactive mentions (the mentions that serve as ar-guments) and their correct boundaries from thedata.
This motivates us to build a novel latent-variable semi-Markov conditional random fieldsmodel (Sarawagi and Cohen, 2004) for such anevent extraction task.
The learned model takesin coarse information as produced by existingmention identification and typing modules, andjointly outputs selected mentions and their cor-responding argument roles.?
We address the problem in a more realistic sce-nario where annotated training instances are notavailable.
We propose a novel general learningframework called structured preference model-ing (or preference modeling, PM), which en-compasses both the fully supervised and thelatent-variable conditional models as specialcases.
The framework allows arbitrary declar-ative structured preference knowledge to be in-troduced to guide the learning procedure in a pri-marily unsupervised setting.We present our semi-Markov model and discussour preference modeling framework in Section 2 and3 respectively.
We then discuss the model?s relationwith existing constraint-driven learning frameworksin Section 4.
Finally, we demonstrate through ex-periments that structured preference information iscrucial to model and present empirical results on astandard dataset in Section 5.2 The ModelIt is not hard to observe from the example presentedin the previous section that dependencies betweenA1T1C1B2C2A3T3C3B4C4.
.
.. .
.. .
.AnTnCnFigure 2: A simplified graphical illustration for the semi-Markov CRF, under a specific segmentation S ?
C1C2 .
.
.
Cn.In a supervised setting, only correct arguments are observed buttheir associated correct mention types are hidden (shaded).arguments can be important and need to be properlymodeled.
This motivates us to build a joint modelfor extracting the event structures from the text.We show a simplified graphical representation ofour model in Figure 2.
In the graph, C1, C2 .
.
.
Cnrefer to a particular segmentation of the eventspan, where C1, C3 .
.
.
correspond to mentions(e.g., ?North Korea?s military?, ?a laser?)
and C2,C4 .
.
.
correspond to in-between mention word se-quences (we call them gaps) (e.g., ?may havefired?).
The symbols T1, T3 .
.
.
refer to mentiontypes (e.g., GPE, ORG).
The symbols A1, A3 .
.
.
re-fer to event arguments that carry specific roles (e.g.,ATTACKER).
We also introduce symbols B2, B4 .
.
.to refer to inter-argument gaps.
The event span issplit into segments, where each segment is eitherlinked to a mention type (Ti; these segments canbe referred to as ?argument segments?
), or directlylinked to an inter-argument gap (Bj ; they can bereferred to as ?gap segments?).
The two types ofsegments appear in the sequence in a strictly alter-nate manner, where the gaps can be of length zero.In the figure, for example, the segments C1 and C3are identified as two argument segments (which arementions of types T1 and T3 respectively) and aremapped to two ?nodes?, and the segment C2 is iden-tified as a gap segment that connects the two argu-ments A1 and A3.
Note that no overlapping argu-ments are allowed in this model 1.We use s to denote an event span and t to denotea specific realization (filling) of the event template.Templates consist of a set of arguments.
Denote by ha particular mention boundary and type assignmentfor an event span, which gives us a specific segmen-tation of the given span.
Following the conditional1Extending the model to support certain argument overlap-ping is possible ?
we leave it for future work.836random fields model (Lafferty et al, 2001), we pa-rameterize the conditional probability of the (t, h)pair given an event span s as follows:P?
(t, h|s) =ef(s,h,t)??
?t,h ef(s,h,t)??
(1)where f gives the feature functions defined on thetuple (s, h, t), and ?
defines the parameter vector.Our objective function is the logarithm of the jointconditional probability of observing the template re-alization for the observed event span s:L(?)
=?ilogP?
(ti|si)=?ilog?h ef(si,h,ti)??
?t,h ef(si,h,t)??
(2)This function is not convex due to the summationover the hidden variable h. To optimize it, we takeits partial derivative with respect to ?j :?L(?)??j=?iEp?
(h|si,ti)[fj(si, h, ti)]??iEp?
(t,h|si)[fj(si, h, t)] (3)which requires computation of expectations termsunder two different distributions.
Such statisticscan be collected efficiently with a forward-backwardstyle algorithm in polynomial time (Okanohara etal., 2006).
We will discuss the time complexity forour case in the next section.Given its partial derivatives in Equation 3, onecould optimize the objective function of Equation 2with stochastic gradient ascent (LeCun et al, 1998)or L-BFGS (Liu and Nocedal, 1989).
We choose touse L-BFGS for all our experiments in this paper.Inference involves computing the most probabletemplate realization t for a given event span:arg maxtP?
(t|s) = arg maxt?hP?
(t, h|s) (4)where the possible hidden assignments h need to bemarginalized out.
In this task, a particular realiza-tion t already uniquely defines a particular segmen-tation (mention boundaries) of the event span, thusthe h only contributes type information to t. As wewill discuss in Section 2.3, only a collection of localfeatures are defined.
Thus, a Viterbi-style dynamicprogramming algorithm is used to efficiently com-pute the desired solution.2.1 Possible SegmentationsAccording to Equation 3, summing over all possi-ble h is required.
Since one primary assumption isthat we have access to the output of existing mentionidentification and typing systems, the set of all possi-ble mentions defines a lattice representation contain-ing the set of all possible segmentations that com-ply with such mention-level information.
Assumingthere are A possible arguments for the event and Kannotated mentions, the complexity of the forward-backward style algorithm is in O(A3K2) under the?second-order?
setting that we will discuss in Sec-tion 2.2.
Typically, K is smaller than the number ofwords in the span, and the factor A3 can be regardedas a constant.
Thus, the algorithm is very efficient.As we have mentioned earlier, such coarse infor-mation, as produced by existing resources, could behighly ambiguous and noisy.
Also, the output men-tions can highly overlap with each other.
For exam-ple, the phrase ?North Korea?
as in ?North Korea?smilitary?
can be assigned both type GPE and LOC,while ?North Korea?s military?
can be assigned thetype ORG.
Our model will need to disambiguate themention boundaries as well as their types.2.2 The Gap SegmentsWe believe the gap segments2 are important tomodel since they can potentially capture depen-dencies between two or more adjacent arguments.For example, the word sequence ?may have fired?clearly indicates an Attacker-Instrument relation be-tween the two mentions ?North Korea?s military?and ?a laser?.
Since we are only interested inmodeling dependencies between adjacent argumentsegments, we assign hard labels to each gap seg-ment based on its contextual argument informa-tion.
Specifically, the label of each gap segmentis uniquely determined by its surrounding argu-ment segments with a list representation.
For ex-ample, in a ?first-order?
setting, the gap segmentthat appears between its previous argument seg-ment ?ATTACKER?
and its next argument segment?INSTRUMENT?
is annotated as the list consistingof two elements: [ATTACKER, INSTRUMENT].
Tocapture longer-range dependencies, in this work weuse a ?second-order?
setting (as shown in Figure 2),2The length of a gap segment is arbitrary (including zero),unlike the seminal semi-Markov CRF model of Sarawagi andCohen (2004).837which means each gap segment is annotated with alist that consists of its previous two argument seg-ments as well as its subsequent one.2.3 FeaturesFeature functions are factorized as products of twoindicator functions: one defined on the input se-quence (input features) and the other on the outputlabels (output features).
In other words, we couldre-write fj(s, h, t) as f ink (s)?
foutl (h, t).For gap segments, we consider the following in-put feature templates:N-GRAM: Indicator function for n-gram appearedin the segment (n = 1, 2)ANCHOR: Indicator function for its relative positionto the event anchor words (to the left, tothe right, overlaps, contains)and the following output feature templates:1STORDER: Indicator function for the combination ofits immediate left argument and its imme-diate right argument.2NDORDER: Indicator function for the combination ofits immediate two left arguments and itsimmediate right argument.For argument segments, we also define the sameinput feature templates as above, with the followingadditional ones to capture contextual information:CWORDS: Indicator function for the previous andnext k (= 1, 2, 3) words.CPOS: Indicator function for the previous andnext k (= 1, 2, 3) words?
POS tags.and we define the following output feature template:ARGTYPE: Indicator function for the combination ofthe argument and its associated type.Although the semi-Markov CRF model gives usthe flexibility in introducing features that can not beexploited in a standard CRF, such as entity namesimilarity scores and distance measures, in prac-tice we found the above simple and general featureswork well.
This way, the unnormalized score as-signed to each structure is essentially a linear sumof the feature weights, each corresponding to an in-dicator function.3 Learning without Annotated DataThe supervised model presented in the previous sec-tion requires substantial human efforts to annotatethe training instances.
Human annotations can bevery expensive and sometimes impractical.
Even ifannotators are available, getting annotators to agreewith each other is often a difficult task in itself.Worse still, annotations often can not be reused: ex-perimenting on a different domain or dataset typi-cally require annotating new training instances forthat particular domain or dataset.We investigate inexpensive methods to alleviatethis issue in this section.
We introduce a novel gen-eral learning framework called structured preferencemodeling, which allows arbitrary prior knowledgeabout structures to be introduced to the learning pro-cess in a declarative manner.3.1 Structured Preference ModelingDenote by X?
and Y?
the entire input and outputspace, respectively.
For a particular input x ?
X?,the set x ?
Y?
gives us all possible structures thatcontain x.
However, structures are not equally good.Some structures are generally regarded as betterstructures while some are worse.Let?s asume there is a function ?
:{x ?
Y?
?
[0, 1]}that measures the quality of the structures.This function returns the quality of a certain struc-ture (x, y), where the value 1 indicates a perfectstructure, and 0 an impossible structure.Under such an assumption, it is easy to observethat for a good structure (x, y), we have p?
(x, y)??
(x, y) = p?
(x, y), while for a bad structure (x, y),we have p?
(x, y)?
?
(x, y) = 0.This motivates us to optimize the following objec-tive function:Lu(?)
=?ilog?y p?
(xi, y)?
?
(xi, y)?y p?
(xi, y)(5)Intuitively, optimizing such an objective functionis equivalent to pushing the probability mass frombad structures to good structures corresponding tothe same input.When the preference function ?
is defined as theindicator function for the correct structure (xi, yi),the numerator terms of the above formula are simplyof the forms p?
(xi, yi), and the model correspondsto the fully supervised CRF model.The model also contains the latent-variable CRFas a special case.
In a latent-variable CRF, we haveinput-output pairs (xi, yi), but the underlying spe-cific structure h that contains both xi and yi is hid-den.
The objective function is:?ilog?h p?
(xi, h, yi)?h,y?
p?
(xi, h, y?
)(6)838where p?
(xi, h, yi) = 0 unless h contains (xi, yi).We define the following two functions:q?
(xi, h) =?y?p?
(xi, h, y?)
(7)?
(xi, h) ={1 h contains (xi, yi)0 otherwise(8)Note that this definition of ?
models instance-specific preferences since it relies on yi, which canbe thought of as certain external prior knowledge re-lated to xi.
It is easy to verify that p?
(xi, h, yi) =q?
(xi, h)??
(xi, h), with q?
remains a distribution.Thus, we could re-write the objective function as:?i=1log?h q?
(xi, h)?
?
(xi, h)?h q?
(xi, h)(9)This shows that the latent-variable CRF is a spe-cial case of our objective function, with the above-defined ?
function.
Thus, this new objective func-tion of Equation 5 is a generalization of both the su-pervised CRF and the latent-variable CRF.The preference function ?
serves as a source fromwhich certain prior knowledge about the structurecan be injected into our model in a principled way.Note that the function is defined at the completestructure level.
This allows us to incorporate bothlocal and arbitrary global structured information intothe preference function.Under the log-linear parameterization, we have:L?(?)
=?ilog?y ef(xi,y)??
?
?
(xi, y)?y ef(xi,y)??
(10)This is again a non-convex optimization problemin general, and to solve it we take its partial deriva-tive with respect to ?k:?L?(?)??k=?iEp?(y|xi;?
)[fk(xi, y)]??iEp?
(y|xi)[fk(xi, y)] (11)p?(y|xi;?)
?
ef(xi,y)??
?
?
(xi, y)p?
(y|xi) ?
ef(xi,y)?
?3.2 Approximate LearningComputation of the denominator terms of Equation10 (and the second term of Equation 11) can be doneefficiently and exactly with dynamic programming.Our main concern is the computation of its numera-tor terms (and the first term of Equation 11).The preference function ?
is defined at the com-plete structure level.
Unless the function is definedin specific forms that allow tractable dynamic pro-gramming (in the supervised case, which gives aunique term, or in the hidden variable case, whichcan define a packed representations of derivations),the efficient dynamic programming algorithm usedby CRF is no longer generally applicable for arbi-trary ?.
In general, we resort to approximations.In this work, we exploit a specific form of thepreference function ?.
We assume that there existsa projection from another decomposable function to?.
Specifically, we assume a collection of auxiliaryfunctions, each of the form ?p : (x, y) ?
R, thatscores a property p of the complete structure (x, y).Each such function measures certain aspect of thequality of the structure.
These functions assign pos-itive scores to good structural properties and nega-tive scores to bad ones.
We then define ?
(x, y) = 1for all structures that appear at the top-n positionsas ranked by?p ?p(x, y) for all possible y?s, and?
(x, y) = 0 otherwise.
We show some actual ?pfunctions used for a particular event in Section 5.At each iteration of the training process, to gen-erate such a n-best list, we first use our model toproduce top n ?
b candidate outputs as scored bythe current model parameters, and extract the top noutputs as scored by?p ?p(x, y).
In practice we setn = 10 and b = 1000.3.3 Event ExtractionNow we can obtain the objective function for ourevent extraction task.
We replace x by s and y by(h, t) in Equation 10.
This gives us the followingfunction:Lu(?)
=?ilog?t,h ef(si,h,t)??
?
?
(si, h, t)?t,h ef(si,h,t)??
(12)The partial derivatives are as follows:?Lu(?)??k=?iEp?(t,h|si;?
)[fk(si, h, t)]??iEp?
(t,h|si)[fk(si, h, t)] (13)p?
(t, h|si;?)
?
ef(si,h,t)??
?
?
(si, h, t)p?
(t, h|si) ?
ef(si,h,t)?
?839Recall that s is an event span, t is a specfic re-alization of the event template, and h is the hiddenmention information for the event span.4 Discussion: Preferences v.s.
ConstraintsNote that the objective function in Equation 5, ifwritten in the additive form, leads to a cost func-tion reminiscent of the one used in constraint-drivenlearning algorithm (CoDL) (Chang et al, 2007) (andsimilarly, posterior regularization (Ganchev et al,2010), which we will discuss later at Section 6).Specifically, in CoDL, the following cost functionis involved in its EM-like inference procedure:arg maxy?
?
f(x, y)?
?
?cd(y,Yc) (14)where Yc defines the set of y?s that all satisfy a cer-tain constraint c, and d defines a distance functionfrom y to that set.
The parameter ?
controls the de-gree of the penalty when constraints are violated.There are some important distinctions betweenstructured preference modeling (PM) and CoDL.CoDL primarily concerns constraints, which pe-nalizes bad structures without explicitly rewardinggood ones.
On the other hand, PM concerns prefer-ences, which can explicitly reward good structures.Constraints are typically useful when one workson structured prediction problems for data with cer-tain (often rigid) regularities, such as citations, ad-vertisements, or POS tagging for complete sen-tences.
In such tasks, desired structures typicallypresent certain canonical forms.
This allows declar-ative constraints to be specified as either local struc-ture prototypes (e.g., in citation extraction, the wordpp.
always corresponds to the PAGES field, whileproceedings is always associated with BOOKTITLEor JOURNAL), or as certain global regulations aboutcomplete structures (e.g., at least one word shouldbe tagged as verb when performing a sentence-levelPOS tagging).Unfortunately, imposing such (hard or soft) con-straints for certain tasks such as ours, where the datatends to be of arbitrary forms without many rigidregularities, can be difficult and often inappropri-ate.
For example, there is no guarantee that a cer-tain argument will always be present in the eventspan, nor should a particular mention, if appeared,always be selected and assigned to a specific argu-ment.
For example, in the example event span givenin Section 1, both ?March?
and ?Tuesday?
are validcandidate mentions for the TIME-WITHIN argumentgiven their annotated type TME.
One important clueis that March appears after the word in and is lo-cated nearer to other mentions that can be poten-tially useful arguments.
However, encoding suchinformation as a general constraint can be inappro-priate, as potentially better structures can be foundif one considers other alternatives.
On the otherhand, if we believe the structural pattern ?at TAR-GET in TIME-WITHIN?
is in general considered abetter sub-structure than ?said TIME-WITHIN?
forthe ?Attack?
event, we may want to assign structuredpreference to a complete structure that contains theformer, unless there exist other structured evidenceshowing the latter turns out to be better.In this work, our preference function is relatedto another function that can be decomposed into acollection of property functions ?p.
Each of themscores a certain aspect of the complete structure.This formulation gives us a complete flexibility toassign arbitrary structured preferences, where posi-tive scores can be assigned to good properties, andnegative scores to bad ones.
Thus, in this way, thequality of a complete structure is jointly measuredwith multiple different property functions.To summarize, preferences are an effective way to?define?
the event structure to the learner, which isessential in an unsupervised setting, which may notbe easy to do with other forms of constraints.
Prefer-ences are naturally decomposable, which allows usto extend their impact without significantly effectingthe complexity of inference.5 ExperimentsIn this section, we present our experimental resultson the standard ACE053 dataset (newswire portion).We choose to perform our evaluations on 4 events(namely, ?Attack?, ?Meet?, ?Die?
and ?Transport?
),which are the only events in this dataset that havemore than 50 instances.
For each event, we ran-domly split the instances into two portions, where70% are used for learning, and the remaining 30%for evaluation.
We list the corpus statistics in Table2.To present general results while making minimalassumptions, our primary event extraction results3http://www.itl.nist.gov/iad/mig/tests/ace/2005/doc/840EventWithout Annotated Training Data With Annotated Training DataRandom Unsup Rule PM MaxEnt-b MaxEnt-t MaxEnt-p semi-CRFAttack 20.47 30.12 39.25 42.02 54.03 58.82 65.18 63.11Meet 35.48 26.09 44.07 63.55 65.42 70.48 75.47 76.64Die 30.03 13.04 40.58 55.38 51.61 59.65 63.18 67.65Transport 20.40 6.11 44.34 57.29 53.76 57.63 61.02 64.19Table 1: Performance for different events under different experimental settings, with gold mention boundaries and types.
We reportF1-measure percentages.Event #ALearning Set Evaluation Set#P#I #M #I #MAttack 8 188 300/509 78 121/228 7Meet 7 57 134/244 24 52/98 7Die 9 41 89/174 19 33/61 6Transport 13 85 243/426 38 104/159 6Table 2: Corpus statistics (#A: number of possible argumentsfor the event; #I: number of instances; #M: number of ac-tive/total mentions; #P: number of preference patterns usedfor performing our structured preference modeling.
)are independent of mention identification and typingmodules, which are based on the gold mention in-formation as given by the dataset.
Additionally, wepresent results obtained by exploiting our in-houseautomatic mention identification and typing mod-ule, which is a hybrid system that combines statis-tical and rule-based approaches.
The module?s sta-tistical component is trained on the ACE04 dataset(newswire portion) and overall it achieves a micro-averaged F1-measure of 71.25% at our dataset.5.1 With Annotated Training DataWith hand-annotated training data, we are able totrain our model in a fully supervised manner.
Theright part of Table 1 shows the performance forthe fully supervised models.
For comparison, wepresent results from several alternative approachesbased a collection of locally trained maximum en-tropy (MaxEnt) classifiers.
In these approaches, wetreat each argument of the template as one possi-ble output class, plus a special ?NONE?
class fornot selecting it as an argument.
We train and applythe classifiers on argument segments (i.e., mentions)only.
All the models are trained with the same fea-ture set used in the semi-CRF model.In the simplest baseline approach MaxEnt-b, typeinformation for each mention is simply treated asone special feature.
In the approach MaxEnt-t, weinstead use the type information to constrain theclassifier?s predictions based on the acceptable typesassociated with each argument.
This approach givesbetter performance than that of MaxEnt-b.
This in-dicates that such locally trained classifiers are notrobust enough to disambiguate arguments that takedifferent types.
As such, type information serving asadditional constraints at the end does help.To assess the importance of structured preference,we also perform experiments where structured pref-erence information is incorporated at the inferencetime of the MaxEnt classifiers.
Specifically, for eachevent, we first generate n-best lists for output struc-tures.
Next, we re-rank this list based on scoresfrom our structured preference functions (we usedthe same preferences as to be discussed in the nextsection).
The results for these approaches are givenin the column of MaxEnt-p of Table 1.
This simpleapproach gives us significant improvements, clos-ing the gap between locally trained classifiers andthe joint model (in one case the former even out-performs the latter).
Note that no structured pref-erence information is used when training and eval-uating our semi-CRF model.
This set of results isnot surprising.
In fact, similar observations are alsoreported in previous works when comparing jointmodel against local models with constraints incor-porated (Roth and Yih, 2005).
This clearly indicatesthat structured preference information is crucial tomodel.5.2 Without Annotated Training DataNow we turn to experiments for the more realisticscenario where human annotations are not available.We first build our simplest baseline by randomlyassigning arguments to each mention with mentiontype information serving as constraints.
Averagedresults over 1000 runs are reported in the first col-umn of Table 1.Since our model formulation leaves us with com-plete freedom in designing the preference function,841Type Preference pattern (p)General{at|in|on} followed by PLACE{during|at|in|on} followed by TIME-WITHINDieAGENT (immediately) followed by {killed}{killed} (immediately) followed by VICTIMVICTIM (immediately) followed by {be killed}AGENT followed by {killed} (immediately) followed by VICTIMTransportX immediately followed by {,|and} immediately followed by X, where X ?
{ORIGIN|DESTINATION}{from|leave} (immediately) followed by ORIGIN{at|in|to|into} immediately followed by DESTINATIONPERSON followed by {to|visit|arrived}Figure 3: The complete list of preference patterns used for the ?Die?
and ?Transport?
event.
We simply set ?p = 1.0 for all p?s.
Inother words, when a structure contains a pattern, its score is incremented by 1.0.
We use {} to refer to a set of possible words orarguments.
For example, {from|leave} means a word which is either from or leave.
The symbol () denotes optional.
For example,?
{killed} (immediately) followed by VICTIM?
is equivalent to the following two preferences: ?
{killed} immediately followed byVICTIM?, and ?
{killed} followed by VICTIM?.one could design arbitrarily good, domain-specificor even instance-specific preferences.
However, todemonstrate its general effectiveness, in this workwe only choose a minimal amount of general prefer-ence patterns for evaluations.We make our preference patterns as general aspossible.
As shown in the last column (#P) of Table2, we use only 7 preference patterns each for the ?At-tack?
and ?Meet?
events, and 6 patterns each for theother two events.
In Figure 3, we show the completelist of the 6 preference patterns for the ?Die?
and?Transport?
event used for our experiments.
Out ofthose 6 patterns, 2 are more general patterns sharedacross different events, and 4 are event-specific.
Incontrast, for example, for the ?Die?
event, the super-vised approach requires human to select from 174candidate mentions and annotate 89 of them.Despite its simplicity, it works very well in prac-tice.
Results are given in the column of ?PM?
ofTable 1.
It generally gives competitive performanceas compared to the supervised MaxEnt baselines.On the other hand, a completely unsupervised ap-proach where structured preferences are not speci-fied, performs substantially worse.
To run such com-pletely unsupervised models, we essentially followthe same training procedure as that of the prefer-ence modeling, except that structured preference in-formation is not in place when generating the n-bestlist.
In the absence of proper guidances, such a pro-cedure can easily converge to bad local minima.
Theresults are reported in the ?Unsup?
column of Ta-ble 1.
In practice, we found that very often, sucha model would prefer short structures where manymentions are not selected as desired.
As a result, theunsupervised model without preference informationcan even perform worse than the random baseline 4.Finally, we also compare against an approach thatregards the preferences as rules.
All such rules areassociated with a same weight and are used to jointlyscore each structure.
We then output the structurethat is assigned the highest total weight.
Such an ap-proach performs worse than our approach with pref-erence modeling.
The results are presented in thecolumn of ?Rule?
of Table 1.
This indicates thatour model is able to learn to generalize with featuresthrough the guidance of our informative preferences.However, we also note that the performance of pref-erence modeling depends on the actual quality andamount of preferences used for learning.
In the ex-treme case, where only few preferences are used, theperformance of preference modeling will be close tothat of the unsupervised approach, while the rule-based approach will yield performance close to thatof the random baseline.The results with automatically predicted mentionboundaries and types are given in Table 3.
Simi-lar observations can be made when comparing theperformance of preference modeling with other ap-proaches.
This set of results further confirms the ef-fectiveness of our approach using preference model-ing for the event extraction task.6 Related WorkStructured prediction with limited supervision is apopular topic in natural language processing.4For each event, we only performed 1 run with all the initialfeature weights set to zeros.842Event Random Unsup PM semi-CRFAttack 14.26 26.19 32.89 46.92Meet 26.65 14.08 45.28 58.18Die 19.17 9.09 44.44 48.57Transport 15.78 10.14 49.73 52.34Table 3: Event extraction performance with automatic mentionidentifier and typer.
We report F1 percentage scores for pref-erence modeling (PM) as well as two baseline approaches.
Wealso report performance of the supervised approach trained withthe semi-CRF model for comparison.Prototype driven learning (Haghighi and Klein,2006) tackled the sequence labeling problem in aprimarily unsupervised setting.
In their work, aMarkov random fields model was used, where somelocal constraints are specified via their prototype list.Constraint-driven learning (CoDL) (Chang et al,2007) and posterior regularization (PR) (Ganchev etal., 2010) are both primarily semi-supervised mod-els.
They define a constrained EM framework thatregularizes posterior distribution at the E-step ofeach EM iteration, by pushing posterior distributionstowards a constrained posterior set.
We have alreadydiscussed CoDL in Section 4 and gave a comparisonto our model.
Unlike CoDL, in the PR frameworkconstraints are relaxed to expectation constraints, inorder to allow tractable dynamic programming.
Seealso Samdani et al (2012) for more discussions.Contrastive estimation (CE) (Smith and Eisner,2005a) is another log-linear framework for primar-ily unsupervised structured prediction.
Their objec-tive function is related to the pseudolikelihood es-timator proposed by Besag (1975).
One challengeis that it requires one to design a priori an effectiveneighborhood (which also needs to be designed incertain forms to allow efficient computation of thenormalization terms) in order to obtain optimal per-formance.
The model has been shown to work in un-supervised tasks such as POS induction (Smith andEisner, 2005a), grammar induction (Smith and Eis-ner, 2005b), and morphological segmentation (Poonet al, 2009), where good neighborhoods can beidentified.
However, it is less intuitive what consti-tutes a good neighborhood in this task.The neighborhood assumption of CE is relaxedin another latent structure approach (Chang et al,2010a; Chang et al, 2010b) that focuses on semi-supervised learning with indirect supervisions, in-spired by the CoDL model described above.The locally normalized logistic regression (Berg-Kirkpatrick et al, 2010) is another recently proposedframework for unsupervised structured prediction.Their model can be regarded as a generative modelwhose component multinomial is replaced with aminiature logistic regression where a rich set of localfeatures can be incorporated.
Empirically the modelis effective in various unsupervised structured pre-diction tasks, and outperforms the globally normal-ized model.
Although modeling the semi-Markovproperties of our segments (especially the gap seg-ments) in our task is potentially challenging, we planto investigate in the future the feasibility for our taskwith such a framework.7 ConclusionsIn this paper, we present a novel model based onthe semi-Markov conditional random fields for thechallenging event extraction task.
The model takesin coarse mention boundary and type informationand predicts complete structures indicating the cor-responding argument role for each mention.To learn the model in an unsupervised manner,we further develop a novel learning approach calledstructured preference modeling that allows struc-tured knowledge to be incorporated effectively in adeclarative manner.Empirically, we show that knowledge about struc-tured preference is crucial to model and the prefer-ence modeling is an effective way to guide learn-ing in this setting.
Trained in a primarily unsuper-vised manner, our model incorporating structuredpreference information exhibits performance that iscompetitive to that of some supervised baseline ap-proaches.
Our event extraction system and code willbe available for download from our group web page.AcknowledgmentsWe would like to thank Yee Seng Chan, Mark Sam-mons, and Quang Xuan Do for their help with themention identification and typing system used inthis paper.
We gratefully acknowledge the sup-port of the Defense Advanced Research ProjectsAgency (DARPA) Machine Reading Program un-der Air Force Research Laboratory (AFRL) primecontract no.
FA8750-09-C-0181.
Any opinions,findings, and conclusions or recommendations ex-pressed in this material are those of the authorsand do not necessarily reflect the view of DARPA,AFRL, or the US government.843ReferencesT.
Berg-Kirkpatrick, A.
Bouchard-Co?te?, J. DeNero, andD.
Klein.
2010.
Painless unsupervised learning withfeatures.
In Proc.
of HLT-NAACL?10, pages 582?590.J.
Besag.
1975.
Statistical analysis of non-lattice data.The Statistician, pages 179?195.M.
Chang, L. Ratinov, and D. Roth.
2007.
Guiding semi-supervision with constraint-driven learning.
In Proc.of ACL?07, pages 280?287.M.
Chang, D. Goldwasser, D. Roth, and V. Srikumar.2010a.
Discriminative learning over constrained latentrepresentations.
In Proc.
of NAACL?10, 6.M.
Chang, V. Srikumar, D. Goldwasser, and D. Roth.2010b.
Structured output learning with indirect super-vision.
In Proc.
ICML?10.K.
Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.2010.
Posterior regularization for structured latentvariable models.
The Journal of Machine LearningResearch (JMLR), 11:2001?2049.A.
Haghighi and D. Klein.
2006.
Prototype-driven learn-ing for sequence models.
In Proc.
of HLT-NAACL?06,pages 320?327.J.
D. Lafferty, A. McCallum, and F. C. N. Pereira.
2001.Conditional random fields: Probabilistic models forsegmenting and labeling sequence data.
In Proc.
ofICML?01, pages 282?289.Y.
LeCun, L. Bottou, Y. Bengio, and P. Haffner.
1998.Gradient-based learning applied to document recogni-tion.
Proc.
of the IEEE, pages 2278?2324.D.C.
Liu and J. Nocedal.
1989.
On the limited memorybfgs method for large scale optimization.
Mathemati-cal programming, 45(1):503?528.D.
Okanohara, Y. Miyao, Y. Tsuruoka, and J. Tsujii.2006.
Improving the scalability of semi-markov con-ditional random fields for named entity recognition.
InProc.
of ACL?06, pages 465?472.H.
Poon, C. Cherry, and K. Toutanova.
2009.
Unsu-pervised morphological segmentation with log-linearmodels.
In Proc.
of HLT-NAACL?09, pages 209?217.L.
Ratinov and D. Roth.
2009.
Design challenges andmisconceptions in named entity recognition.
In Proc.of CoNLL?09, pages 147?155.L.
Ratinov, D. Roth, D. Downey, and M. Anderson.2011.
Local and global algorithms for disambiguationto wikipedia.
In Proc.
of ACL-HLT?11, pages 1375?1384.D.
Roth and W. Yih.
2005.
Integer linear programminginference for conditional random fields.
In Proc.
ofICML?05, pages 736?743.R.
Samdani, M. Chang, and D. Roth.
2012.
Unified ex-pectation maximization.
In Proc.
NAACL?12.S.
Sarawagi and W.W. Cohen.
2004.
Semi-markovconditional random fields for information extraction.NIPS?04, pages 1185?1192.N.A.
Smith and J. Eisner.
2005a.
Contrastive estimation:Training log-linear models on unlabeled data.
In Proc.of ACL?05, pages 354?362.N.A.
Smith and J. Eisner.
2005b.
Guiding unsupervisedgrammar induction using contrastive estimation.
InProc.
of IJCAI Workshop on Grammatical InferenceApplications, pages 73?82.J.
Stro?tgen and M. Gertz.
2010.
Heideltime: High qual-ity rule-based extraction and normalization of tempo-ral expressions.
In Proc.
of SemEval?10, pages 321?324.844
