2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 597?601,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsContext-Enhanced Citation Sentiment DetectionAwais AtharUniversity of CambridgeComputer Laboratory15 JJ Thomson AvenueCambridge, CB3 0FD, U.K.awais.athar@cl.cam.ac.ukSimone TeufelUniversity of CambridgeComputer Laboratory15 JJ Thomson AvenueCambridge, CB3 0FD, U.K.simone.teufel@cl.cam.ac.ukAbstractSentiment analysis of citations in scientific pa-pers and articles is a new and interesting prob-lem which can open up many exciting new ap-plications in bibliographic search and biblio-metrics.
Current work on citation sentimentdetection focuses on only the citation sen-tence.
In this paper, we address the problemof context-enhanced citation sentiment detec-tion.
We present a new citation sentiment cor-pus which has been annotated to take the dom-inant sentiment in the entire citation contextinto account.
We believe that this gold stan-dard is closer to the truth than annotation thatlooks only at the citation sentence itself.
Wethen explore the effect of context windows ofdifferent lengths on the performance of a state-of-the-art citation sentiment detection systemwhen using this context-enhanced gold stan-dard definition.1 IntroductionSentiment analysis of citations in scientific papersand articles is a new and interesting problem.
It canopen up many exciting new applications in biblio-graphic search and in bibliometrics, i.e., the auto-matic evaluation of the influence and impact of in-dividuals and journals via citations.
Automatic de-tection of citation sentiment can also be used as afirst step to scientific summarisation (Abu-Jbara andRadev, 2011).
Alternatively, it can help researchersduring search, e.g., by identifying problems with aparticular approach, or by helping to recognise un-addressed issues and possible gaps in the current re-search.However, there is a problem with the expressionof sentiment in scientific text.
Conventionally, thewriting style in scientific writing is meant to be ob-jective.
Any personal bias by authors has to behedged (Hyland, 1995).
Negative sentiment is po-litically particularly dangerous (Ziman, 1968), andsome authors have documented the strategy of pref-acing the intended criticism by slightly disingenuouspraise (MacRoberts and MacRoberts, 1984).
Thismakes the problem of identifying such opinions par-ticularly challenging.
This non-local expression ofsentiment has been observed in other genres as well(Wilson et al, 2009; Polanyi and Zaenen, 2006).Figure 1: Example of anaphora in citationsA typical case is illustrated in Figure 1.
While thefirst sentence praises some aspects of the cited pa-per, the remaining sentences list its shortcomings.
Itis clear that criticism is the intended sentiment, but597if we define our gold standard only by looking atthe citation sentence, we lose a significant amountof sentiment hidden in the text.
Given that most ci-tations are neutral (Spiegel-Rosing, 1977; Teufel etal., 2006), this makes it ever more important to re-cover what explicit sentiment there is from the con-text of the citation.However, the dominant assumption in current ci-tation identification methods (Ritchie et al, 2008;Radev et al, 2009) is that the sentiment present inthe citation sentence represents the true sentimentof the author towards the cited paper.
This is dueto the difficulty of determining the relevant context,whereas it is substantially easier to identify the cita-tion sentence.
In our example above, however, suchan approach would lead to the wrong prediction ofpraise or neutral sentiment.In this paper, we address the problem of context-enhanced citation sentiment detection.
We presenta new citation sentiment corpus where each citationhas been annotated according to the dominant sen-timent in the corresponding citation context.
Weclaim that this corpus is closer to the truth than an-notation that considers only the citation sentence it-self.
We show that it increases citation sentimentcoverage, particularly for negative sentiment.
Usingthis gold standard, we explore the effect of assum-ing context windows of different but fixed lengthson the performance of a state-of-the-art citation sen-timent detection system where the sentiment of ci-tation is considered in the entire context of the ci-tation and more than one single sentiment can beassigned.
Previous approaches neither detect cita-tion sentiment and context simultaneously nor useas large a corpus as we do.2 Corpus ConstructionWe chose the dataset used by Athar (2011) compris-ing 310 papers taken from the ACL Anthology (Birdet al, 2008).
The citation summary data from theACL Anthology Network1 (Radev et al, 2009) wasused.
This dataset is rather large (8736 citations) andsince manual annotation of context for each citationis a time consuming task, a subset of 20 papers wereselected corresponding to approximately 20% of theoriginal dataset.1http://www.aclweb.orgWe selected a four-class scheme for annotation.Every sentence that is in a window of 4 sentencesof the citation and does not contain any direct or in-direct mention of the citation was labelled as beingexcluded (x).
The window length was motivated byrecent research (Qazvinian and Radev, 2010) whichshows the best score for a four-sentence boundarywhen detecting non-explicit citation.
The rest of thesentences were marked either positive (p), negative(n) or objective/neutral (o).A total of 1,741 citations were annotated.
Al-though this annotation was performed by the firstauthor only, we know from previous work that simi-lar styles of annotation can achieve acceptable inter-annotator agreement (Teufel et al, 2006).
An exam-ple annotation for Smadja (1993) is given in Figure2, where the first column shows the line number andthe second one shows the class label.Figure 2: Example annotation of a citation context.To compare our work with Athar (2011), we alsoapplied a three-class annotation scheme.
In thismethod of annotation, we merge the citation contextinto a single sentence.
Since the context introducesmore than one sentiment per citation, we marked thecitation sentiment with the last sentiment mentionedin the context window as this is pragmatically mostlikely to be the real intention (MacRoberts and Mac-Roberts, 1984).As is evident from Table 1, including the 4 sen-tence window around the citation more than dou-bles the instances of subjective sentiment, and in thecase of negative sentiment, this proportion rises to 3.In light of the overall sparsity of detectable citationsentiment in a paper, and of the envisaged applica-598tions, this is a very positive result.
The reason forthis effect is most likely ?sweetened criticism?
?
au-thors?
strategic behaviour of softening the effect ofcriticism among their peers (Hornsey et al, 2008).Without Context With Contexto 87% 73%n 5% 17%p 8% 11%Table 1: Distribution of classes.3 Experiments and ResultsWe represent each citation as a feature set in a Sup-port Vector Machine (SVM) (Cortes and Vapnik,1995) framework and use n-grams of length 1 to 3as well as dependency triplets as features.
The de-pendency triplets are constructed by merging the re-lation, governor and dependent in a single string, forinstance, the relation nsubj(failed, method) is rep-resented as nsubj failed method .
This setuphas been shown to produce good results earlier aswell (Pang et al, 2002; Athar, 2011).The first set of experiments focuses on simulta-neous detection of sentiment and context sentences.For this purpose, we use the four-class annotatedcorpus described earlier.
While the original anno-tations were performed for a window of length 4,we also experiment with asymmetrical windows of lsentences preceding the citation and r sentences suc-ceeding it.
The detailed results are given in Table 2.l r x o n p Fmacro Fmicro0 0 - 1509 86 146 0.768 0.9321 1 2823 1982 216 200 0.737 0.8202 2 5984 2214 273 218 0.709 0.8513 3 9170 2425 318 234 0.672 0.8754 4 12385 2605 352 252 0.680 0.8920 4 5963 2171 322 215 0.712 0.8530 3 4380 2070 293 201 0.702 0.8320 2 2817 1945 258 193 0.701 0.8010 1 1280 1812 206 182 0.717 0.777Table 2: Results for joint context and sentiment de-tection.Because of the skewed class distribution, we useboth the Fmacro and Fmicro scores with 10-foldcross-validation.
The baseline score, shown in bold,is obtained with no context window and is compara-ble to the results reported by Athar (2011).
However,we can observe that the F scores decrease as morecontext is introduced.
This may be attributed to theincrease in the vocabulary size of the n-grams and aconsequent reduction in the discriminating power ofthe decision boundaries.
These results show that thetask of jointly detecting sentiment and context is ahard problem.For our second set of experiments, we use thethree-class annotation scheme.
We merge the textof the sentences in the context windows as well astheir dependency triplets to obtain the features.
Theresults are reported in Table 3 with best results inbold.
Although these results are not better than thecontext-less baseline, the reason might be data spar-sity since existing work on citation sentiment analy-sis uses more data (Athar, 2011).l r Fmacro Fmicro1 1 0.638 0.8272 2 0.620 0.7933 3 0.629 0.7864 4 0.628 0.7710 4 0.643 0.7960 3 0.658 0.8160 2 0.642 0.8240 1 0.731 0.871Table 3: Results using different context windows.4 Related WorkWhile different schemes have been proposed forannotating citations according to their function(Spiegel-Rosing, 1977; Nanba and Okumura, 1999;Garzone and Mercer, 2000), the only recent work oncitation sentiment detection using a relatively largecorpus is by Athar (2011).
However, this work doesnot handle citation context.
Piao et al (2007) pro-posed a system to attach sentiment information tothe citation links between biomedical papers by us-ing existing semantic lexical resources.A common approach for sentiment detection is touse a labelled lexicon to score sentences (Hatzivas-siloglou and McKeown, 1997; Turney, 2002; Yu andHatzivassiloglou, 2003).
However, such approaches599have been found to be highly topic dependent (En-gstro?m, 2004; Gamon and Aue, 2005; Blitzer et al,2007).Teufel et al (2006) worked on a 2,829 sentence ci-tation corpus using a 12-class classification scheme.Although they used context in their annotation, theirfocus was on determining the author?s reason for cit-ing a given paper.
This task differs from citation sen-timent, which is in a sense a ?lower level?
of analy-sis.For implicit citation extraction, Kaplan et al(2009) explore co-reference chains for citation ex-traction using a combination of co-reference reso-lution techniques.
However, their corpus consistsof only 94 sentences of citations to 4 papers whichis likely to be too small to be representative.
Themost relevant work is by Qazvinian and Radev(2010) who extract only the non-explicit citationsfor a given paper.
They model each sentence as anode in a graph and experiment with various win-dow boundaries to create edges between neighbour-ing nodes.
However, their dataset consists of only 10papers and their annotation scheme differs from ourfour-class annotation as they do not deal with anysentiment.5 ConclusionIn this paper, we focus on automatic detection ofcitation sentiment using the citation context.
Wepresent a new corpus and show that ignoring the cita-tion context would result in loss of a lot of sentiment,specially criticism towards the cited paper.
We alsoreport the results of the state-of-the-art citation sen-timent detection systems on this corpus when usingthis context-enhanced gold standard definition.Future work directions may include improvingthe detection algorithms by filtering the context sen-tences more intelligently.
For this purpose, exist-ing work on coreference resolution (Lee et al, 2011)may prove to be useful.
Context features may alsobe used for first filtering citations which have beenmentioned only in passing, and then applying con-text based sentiment classification to the remainingsignificant citations.ReferencesA.
Abu-Jbara and D. Radev.
2011.
Coherent citation-based summarization of scientific papers.
In Proc.
ofACL.A.
Athar.
2011.
Sentiment analysis of citations usingsentence structure-based features.
In Proc of ACL,page 81.S.
Bird, R. Dale, B.J.
Dorr, B. Gibson, M.T.
Joseph, M.Y.Kan, D. Lee, B. Powley, D.R.
Radev, and Y.F.
Tan.2008.
The acl anthology reference corpus: A ref-erence dataset for bibliographic research in computa-tional linguistics.
In Proc.
of LREC.J.
Blitzer, M. Dredze, and F. Pereira.
2007.
Biographies,bollywood, boom-boxes and blenders: Domain adap-tation for sentiment classification.
In Proc.
of ACL,number 1.C.
Cortes and V. Vapnik.
1995.
Support-vector networks.Machine learning, 20(3):273?297.C.
Engstro?m.
2004.
Topic dependence in sentiment clas-sification.
University of Cambridge.M.
Gamon and A. Aue.
2005.
Automatic identificationof sentiment vocabulary: exploiting low associationwith known sentiment terms.
In Proc.
of the ACL.M.
Garzone and R. Mercer.
2000.
Towards an automatedcitation classifier.
Advances in Artificial Intelligence.V.
Hatzivassiloglou and K.R.
McKeown.
1997.
Predict-ing the semantic orientation of adjectives.
In Proc.
ofACL, page 181.M.J.
Hornsey, E. Robson, J. Smith, S. Esposo, and R.M.Sutton.
2008.
Sugaring the pill: Assessing rhetori-cal strategies designed to minimize defensive reactionsto group criticism.
Human Communication Research,34(1):70?98.K.
Hyland.
1995.
The Author in the Text: Hedging Sci-entific Writing.
Hong Kong papers in linguistics andlanguage teaching, 18:11.D.
Kaplan, R. Iida, and T. Tokunaga.
2009.
Automaticextraction of citation contexts for research paper sum-marization: A coreference-chain based approach.
InProc.
of the 2009 Workshop on Text and Citation Anal-ysis for Scholarly Digital Libraries.H.
Lee, Y. Peirsman, A. Chang, N. Chambers, M. Sur-deanu, and D. Jurafsky.
2011.
Stanford?s multi-passsieve coreference resolution system at the conll-2011shared task.
ACL HLT 2011.M.H.
MacRoberts and B.R.
MacRoberts.
1984.
Thenegational reference: Or the art of dissembling.
So-cial Studies of Science, 14(1):91?94.H.
Nanba and M. Okumura.
1999.
Towards multi-papersummarization using reference information.
In IJCAI,volume 16, pages 926?931.
Citeseer.600B.
Pang, L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
: sentiment classification using machine learningtechniques.
In Proc.
of EMNLP.S.
Piao, S. Ananiadou, Y. Tsuruoka, Y. Sasaki, and J. Mc-Naught.
2007.
Mining opinion polarity relations of ci-tations.
In International Workshop on ComputationalSemantics (IWCS).
Citeseer.L.
Polanyi and A. Zaenen.
2006.
Contextual valenceshifters.
Computing attitude and affect in text: Theoryand applications, pages 1?10.V.
Qazvinian and D.R.
Radev.
2010.
Identifying non-explicit citing sentences for citation-based summariza-tion.
In Proc.
of ACL.D.R.
Radev, M.T.
Joseph, B. Gibson, and P. Muthukrish-nan.
2009.
A Bibliometric and Network Analysis ofthe field of Computational Linguistics.
Journal of theAmerican Soc.
for Info.
Sci.
and Tech.A.
Ritchie, S. Robertson, and S. Teufel.
2008.
Com-paring citation contexts for information retrieval.
InProc.
of ACM conference on Information and knowl-edge management, pages 213?222.
ACM.I.
Spiegel-Rosing.
1977.
Science studies: Bibliometricand content analysis.
Social Studies of Science.S.
Teufel, A. Siddharthan, and D. Tidhar.
2006.
Auto-matic classification of citation function.
In Proc.
ofEMNLP, pages 103?110.P.D.
Turney.
2002.
Thumbs up or thumbs down?
: seman-tic orientation applied to unsupervised classification ofreviews.
In Proc.
of ACL.T.
Wilson, J. Wiebe, and P. Hoffmann.
2009.
Rec-ognizing contextual polarity: an exploration of fea-tures for phrase-level sentiment analysis.
Comp.
Ling.,35(3):399?433.H.
Yu and V. Hatzivassiloglou.
2003.
Towards answeringopinion questions: Separating facts from opinions andidentifying the polarity of opinion sentences.
In Proc.of EMNLP, page 136.J.M.
Ziman.
1968.
Public Knowledge: An essay con-cerning the social dimension of science.
CambridgeUniv.
Press, College Station, Texas.601
