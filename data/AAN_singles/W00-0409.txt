Multi-document Summarization by Visualizing Topical ContentRie Kubota AndoDepartment of Computer Science, Cornell University, Ithaca, NY 14853-7501kubotar@cs, cornell, eduBranimir K. Boguraev, Roy J. Byrd, Mary  S. NeffIBM T.J. Watson Research Center, 30 Saw Mill River Road, Hawthorne, NY 10532{bkb, byrd, neff}@watson.ibm.comAbstractThis paper describes a framework for multi-document summarization which combines threepremises: coherent themes can be identified reli-ably; highly representative themes, running acrosssubsets of the document collection, can function asmulti-document summary surrogates; and effectiveend-use of such themes hould be facilitated by a vi-sualization environment which clarifies the relation-ship between themes and documents.
We present al-gorithms that formalize our framework, describe animplementation, and demonstrate a prototype sys-tem and interface.1 Introduction: multi-documentsummarization as an enablingtechnology for IRThe rapid growth of electronic documents hascreated a great demand for a navigation tool totraverse a large corpus.
Information retrieval(IR) technologies allow us to access the docu-ments presumably matching our interests.
How-ever, a traditional hit list-based architecture, whichreturns linearly organized single document sum-maries, no longer suffices, given the size of a typ-ical hit list (e.g.
submitting the query "summa-rization workshop" to a search engine Altavista(h t tp  : / /a l tav is ta .
corn) gave us more thanten million hits).To allow a more comprehensive and screen space-efficient presentation of query results, we proposein this paper a technology for summarizing collec-tions of multiple documents.
In our work, we fo-cus on identifying themes, representative of a docu-ment, and possibly running across documents.
Evenif we are unable to 'embody' atheme in coherentlygenerated prose, we start with the assumption that amapping exists between a theme and a tightly con-nected (and therefore intuitively interpretable) setof coherent linguistic objects, which would act asa 'prompting' device when presented to the user inan appropriate context.
As will become clear in therest of the paper, we refer to such themes astopics.Our view of multi-document summarizationcombines three premises: coherent opics can beidentified reliably; highly representative topics, run-ning across ubsets of the document collection, canfunction as multi-document summary surrogates;and effective nd-use of such topics hould be facil-itated by a visualization environment which clarifiesthe relationship between topics and documents.
Thework specifically addresses the following consider-ations.?
Multiple general topics We regard the abilityto respond to multiple topics in a document collec-tion - -  in contrast o a prevailing trend in multi-document summarization, seeking to present hesingle, possibly pre-determined, topic (see below)to be crucial to applications such as summariza-tion of query results.
In this work we choose notto narrow the topic detection process by the givenquery, since in IR it is a well-known concern thatuser-sPecified queries do not necessarily convey theuser's real interests thoroughly.
Thus, we need todeal with multiple general topics.?
Textual and graphical presentation Sinceour multi-document summaries will, by definition,incorporate multiple topics, the question arises ofoptimal representation f the relationships amongthe topics, the linguistic objects comprising eachtopic, and the documents associated with (possiblymore than one) topic.
In particular, for IR, wewant to show the relationships between topics anddocuments o that a user can access documentsin the context of the topics.
A topic by itselfcan clearly be represented largely by a set of textobjects.
However, we need also to present arbitrarynumber of such topics as part of the same summary.We believe that, for adequate representation of79the resulting many-to-many relationships (whichis crucial for the end-user fully understanding thesummary), additional graphical components areneeded in the interface.To our knowledge, the existing studies of multi-document summarization do not place emphasis onthese considerations.
Radev and McKeown (1998)have shown a methodology for 'briefing' newsarticles reporting the same event.
Barzilay et al(1999) have proposed a method for summarizing"news articles presenting different descriptions o fthe same event".
These studies focus on a singletopic in a document collection.
Mani and Bloedom(1999) have addressed summarizing of similarities,and differences among related documents withrespect o a specified query or profile.
In theirstudy, several presentation strategies are suggested.Although they mention a graphical strategy, suchas plotting documents haring more terms closertogether, no implementation is reported.There are a number of different studies that ad-dress graphical presentation of multi-document (ordocument corpus visualization) - The VIBE Sys-tem (Olsen et al, 1993; Korfhage and Olsen, 1995),Galaxy (Rennison, 1994), SPIRE Themescapes(Wise et al, 1995), LyberWodd (Hemmje et al,1994), and applications of self-organizing map uti-lizing neural network technique (Kohonen, 1997;Lin, 1993; Lagus et al, 1996).
In general, thesestudies consider documents as objects in a modelspace (document space, typically high-dimensional)?
and provide 2-D or 3-D representation f this docu-ment space.
Their focus is on detecting and present-ing structural relationships among documents in acorpus."
From our viewpoint, these two fields of researchaddress two different perspectives on the multi-document analysis problem: multi-document sum-marization efforts largely deliver their results in tex-tual form, while document corpus visualization re-search, which focuses on means for graphical rep-resentation of a document space, does not performany Summarization work.
While we believe thatboth textual and graphical representations are essen-tial in the context of IR, the technologies from thetwo fields, in general, cannot be easily combinedbecause of methodological differences ( uch as dif-ferences in modeling 1he document set, calculatingsimilarity measures, and choosing linguistic objectsin terms of which a summary would be constructed).Motivated by these observations, we propose oneuniform framework that provides both textual andgraphical representations of a document collection.In this framework, topics underlying a documentcollection are identified, and described by means oflinguistic objects in the collection.
Relationships,typically many-to-many, among documents and top-ics are graphically presented, together with the topicdescriptions, by means of a graphical user interfacespecifically designed for this purpose.
We focus onrelatively small document collections (e.g.
100 orso top-ranked ocuments), observing that in a real-istic environment users will not look much beyondsuch a cut-off point.
Our approach maps linguisticoSjects onto a multi-dimensional space (called se-mantic space).
As we will see below, the mappingis defined in a way that allows for topics with cer-tain properties to be derived and for linguistic ob-jects at any granularity to be compared as semanticconcepts.The rest of this paper is organized as follows.
Thenext section describes the multi-dimensional spacefor the document collection.
Section 3 demonstratesour prototype system and illustrates the interplaybetween textual and graphical aspects of the multi-document summary.
Section 4 highlights the im-plementation f the prototype system.
We will con-clude in Section 5.2 Mapping a document collection intosemantic spaceSemantic space is derived on the basis of analyz-ing relationships among linguistic objects - -  suchas terms, sentences, and documents - - in the entirecollection.
A term can be simply a 'content word',in the traditional IR sense, or it can also be con-strued as a phrasal unit, further epresentative of aconcept in the document domain.
In our implemen-tation, we do, in fact, take that broader definitionof terms, to incorporate all types of non-stoplexi-cal items as well as phrasal units such as named en-tities, technical terminology, and other multi-wordconstructions (see Section 4 below)..We map linguistic objects (such as terms, sen-tences, and documents) to vectors in a multi-dimensional space.
We construct this space so thatthe vectors for the objects behaving statisticallysimilarly (and therefore presumed to be semanti-cally similar) point in similar directions.
The vec-tors are called document vectors, sentence vectors,and term vectors, according to the original inguistic80IiIIIIIIIIIIiiIIiiIiIi!I!Iobjects they are derived from; however, all vectorshold the same status in the sense that they repre-sent some concepts.
In this work, we call this multi-dimensional space semantic space (Ando, 2000) todistinguish it from a traditional vector space (Saltonand McGill, 1983).
In essence, in our semanticspace, the terms related to each other are mappedto the vectors having similar directions, while a tra-ditional vector space model treats all terms as inde-pendent from each other.Our motivation for using semantic space is atleast twofold.
First, we believe that we need thehigh representational power of a multi-dimensionalspace since natural anguage objects are intrinsi-cally complicated, as Deerwester et al (1990) ar-gued.
Secondly, our definition of semantic spaceallows us to measure similarities among conceptsand linguistic units at any granularity.
Single-wordterms, multi-word terms, sentences, .and topics- allcan be equally treated as objects representing someconcept(s) when they are mapped to vectors in thisspace.
From the viewpoint of a summarization task,this is an advantage over a traditional vector spacein which terms are assumed to be independent ofone another.To detect opics underlying the document collec-tion, we create aset of vectors in the semantic spaceso that every document vector is represented by (orclose to) at least one vector (called topic vector)..In other words, we provide viewpoints in the se-imantic space so that every document can be viewed: somewhat closely from some viewpoint.
Given such.
vector epresentations for topics, we can quantita-tively measure the degree of associations between?
topics and linguistic objects by using a standard co-sine similarity measure between topic vectors andlinguistic object vectors.
The linguistic objects withthe.strongest association would represent the topicmost appropriately.The algorithm we use for semantic space con-struction (see Figure 5 in Section 4) is closely re-lated to singular value decomposition (SVD) used inLatent Semantic Indexing (LSI) (Deerwester tal.,1990).
As in SVD, this algorithm finds statistical re-lationships between documents and terms by com-puting eigenvectors, and it performs dimensional re-duction that results in a better statistical modeling.The advantages of the semantic space we describedabove are shared with similar approaches ( uch asSVD-based and Riemarmian SVD-based (Jiang andBerry, 1998)).
The algorithm we adopt, however,differs from others in that it achieves a high preci-sion of similarity measurement among all the doc-uments by capturing information more evenly fromevery document while, with other approaches, thedocuments whose statistical behaviors are differentfrom the others tend to be less well represented.This algorithm fits well in our framework since wewant to find topics by referring the similarities ofall pairs of documents ( hown later), and also wewant to assume all the documents are equal.
Fulldetails of the semantic space construction algorithmmay be found in (Ando, 2000), including evaluationresults compared with SVD.3 ,Visual presentation of a semantic space:combining text and graphicsIn this section, to illustrate how we combine tex-tual and graphical presentation, we demonstrate asummary that our prototype system created from50 documents (TREC documents relevant to 'non-proliferation treaty').The document set is presented in one full screenin relation to the underlying topics.
The prototypesystem detected six i topics in this document set (seeFigure 1).
For each topic, three types of informationare presented: a list of terms (topic terms), a list ofsentences (topic sentences), and a visual represen-tation of relevance of each document to the topic(document map).Below we highlight some essential features of theinterface.Topic terms and topic sentences: The topic pre-sented at the upper right comer of Figure I hasthe topic terms "Iraq", "Iraqi", "Kuwait", "SaddamHussein", "embargo", invasion", "disarm", and soon.
(The frame is scrollable, thus accommodatingall topic terms.)
A topic typically will be addressedby more than one sentence, presented in a closelyassociated scrollable frame.
The first topic sentencefor this topic is "israel's Air Force bombed Iraq'sOsirak ...".
Together, the Sets of topic terms and sen-tences describe the topic, i.e.
one 'thread' discussedin possibly several documents.Document proxy - a "'dot" represents a docu-ment: In a document map, a dot image representseach document (i.e.
document proxy).
A dot beforea topic sentence isalso a document proxy represent-ing the document containing that sentence.i The number of topics detected epends on the documentset and the parameter setting adjusting the granularity.81Document  map Top ic  te rms Top ic  sentences~ ~ +  + \]\]\]+ V ,  ,++~.++ , .....................~.aW., ~e~o pn, nut!era', nuclear wean on..~ssi!e.
So~.e~..~.
.
~ ........ ~ ~aq..
I ra~!~..K~t, .
.S addam Huss e i~.
.emb~p, .~y~.
.~:.They exchanged ratiSeafion protocols for ~-the Interme<~ate-P..m~e Nucle~ Forces -i.~~r e aty 01q1~ o e.~mhm~e m  <~m~-range |L~.o~ 1nuclear n~e, ,  which was ~ned ~t the !ii' '4m .~:  ,3o oW ~ n  smm~it last December and ~ .... | "ratified by the Senate last Friday and by the :~:,~:.Soviet asmnbly ofpresidants 17 hours ~'~'~ ~id.
cartUicatlon, carfiC'v.
John Kelly..suspension.
Stenhen~.-~-T,eonard Spector.
Im expert on the spread +~o+..++.+,.+.+++, o+ evidence leaves little doubt" that Pakistan is .indeed developing nuclear anna+ i~ 4 m ~g |,The continumgreview of Pakistan's nucleas " ~, +prog~ is pm of such concern.
~e~ s,~d, :~:,.. "citing a U.S. law, the Pressler amendmant, :~t.headwater  nu?learreactOr.
Norway, ~ase \ ] ,  Svfitzerlan d ~'~d~a, ton, .
.
.
.~ . '
l~nspo~al?
Norway does not allow the export ofheavy water to countries that have not : I  Js~ned the international nuclear ioo non-prol~'era~on agseement, includ~ns~cKa.
~ : @s g gg?
Heavy water, or deuler/mu o~de.
i. .
.
.
d ~ ~!as a coolaat in some nucle~ reactors, but ~t +'ca:) also be used to produce platonhnn for __.~use in nuckas ~m'm.
.:~:I~,?
Israel's Air Force bombed Iraq's Ofiraknuclear reactor in 1981 while Iraq was atwar with Iran, ~ me facility was being8go.
,  .
g\] ~1~ used to develop aton~c weapons.?
Some analysts in I.~rael.
wl~ch closelytracks \]raq's arm5 progrmn, he~mse :~ .i, Baghdad could be two to five year~ awaySouth Afi3ca.
Mrir an.
mspec~on, L'~tarnat/ona\] Atonue Ene~ .a~encv.?
In the past.
South Africa has refizsed to ~the 1969~uclearl'~on-ProSferationTreaty i~a~d to submit an its rmcle ar fac/lities to i~o~ I| * "I mlb inspectlonby~eVienna-basedlateraatlonalAtomic Ener~ Asency.
~+ \]:-Under the Treaty on ill= Non-Pro~fuation ~ ,,of Nuclear Weapons.
which has been s/~ned i~ '+~?
!
~rtalaon ~ m  eo~ensate ,  reprocess nuclear fuel l~ant ~ |1 ~ DIMEIqS'IOH 2"=41,-A federal appeals cotu't in Washington, ~ca~-~ the plant "one of  the most remmicabk t white elephants" in the nation's 1'~tory.
t~d in l:ebruary that plant owner AlSed-(3eneral l~'uclenr Services is not entitled to compensation, +" i?
The plant was deraed a 5cense ;,, 1977 ~'.i Iwhen former Prcfident Y:mmy Carter ....Figure 1: Example of the final output.Document maps - topic-document relevanceshown by document proxy placement and color gra-dation: In a document map, the horizontal place-ment of each dot represents the degree of relevanceof the corresponding document o the topic.
Docu-ments closer to the direction of the arrow are morer~levant o the topic.
The color intensity of thedot also represents the degree of relevance.
Forinstance, in the document map at the upper rightcomer of Figure 1, we see that there are six doc-uments closely related to this 'Iraq-topic'.
Theseflx dots are placed on the right (the direction of the?
arrow), and their colors are more intense than theother document proxies.
We see one more docu-ment to the left to the six documents, also with arelatively strong connection to this topic.
Two doc-uments, represented by dots almost at the center ofthe map, are only somewhat related to this topic.The rest of the documents, having dots that are al-most transparent and placed on the left, are not veryrelated to this topic.
Thus, users can tell, at a glance,how many documents are related to each topic andhow strongly they are related.
Note that each doc-ument map contains proxies for all the documents.Unlike a typical clustering approach, we do not di-vide documents into groups.
Clusters of documents,if any, are naturally observed in the document map.A document map is a projection of document vec-tors onto a topic vector.
The semantic space allowsus to detect and straightforwardly present he struc-tural relationships among the documents.Highlighting of document proxies - the rela-tionships between a document and multiple topics:When a mouse rolls over a dot, the title Of the doc-ument appears, and the color of the dots repreSent-ing the same document in all the document mapschanges.
(from blue to red) (see Figure 2).
Thiscolor change facilitates understanding the relation-ships between a document and multiple topics.A hot-link from a document proxy to full text:.82I,IIliIIIiiIiIiIiiIIIIIIIIi!!
!IIIiIiIIIWhen a mouse comes up, and all the proxies for the document a r e ~*They exchanged ratification protocols forthe Intermed~e-Range lquclear Forcestreaty ~ to e~minate med~n-racgenuclear missiles, w~ch was signed at theWashington sunm~ last December ~mdratified by the Senate last Friday a~d by theSoviet ass~nbly ofpresldents 17 hoursi| .Israel's Ak Force bombed Iraq's Os~raki\] nuclear reactor in 1981 while Iraqwas eti| war with Iran, daimi~ the faci~ty was being..... ~ i~ l  ~.. .
.
.
.  '
.~ ' ~ " .
~ ~  ?~;e ly  B~ Cha~e~ ~ m elm to ~ l~le~x De~ces tol~q\[il B~hdad codd be two to five ye~'s away.Leonard Spectar, ~m e:cpe~ on the spreadof nuclear weapons, has stud ~availableevidence l aves little dox~bt" that ~akistan isindeed eveloping m~le~ arms.?
The continuing review of Pakistan's n~clearprosrazn ispart of such concern, Kegy said.ching a U.S. law.
the Presslar amendment,,.~Torway does not allow the export ofheavy water to counhies that have not~ned the international nuclearnon-proliferation agreeme~, including Indi&?
Heavy water, or deuterium o:~de, is usedas a coolant in some nuclear reactors, but itcan ako be nsed to prodUCe p luto~n f~ruse in nuclear ~ms.4- :t?
In the past, South Afiica has refused to signthe 1969 lq'uclear l~'on-Proliferation Treatyand to subn'~t all its nuclem" fac ies  tO i~inspection by the Vienna-based International ~Atomic Ex~gy Agency.
r,~*:?
Under the Treaty on the Non-Proliferation ~of Nuclear We~ons.
which has been ~cd '~i| oA t'ed~al appeals court in Wastan~on.i| c~the  p~ "one of the most ,~ lei| white elephants" m the ~on's  history, ruled?
?
~ i| i~Februa~plaut?wn~'tnd/ied"C~merali| N=~ar s .~e,  '.,,) ~d toi| compensattm~\] ,The plant was denied a fleece in 1977_ .
== .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
r \ ]  when former ~'esideutYunmyCm'terFigure 2: When a mouse rolls over a dot:When a dot is clicked, the full text of the corre-sponding document is displayed in a separate win-dow.
This allows us to browse documents in thecontext of  document-topic relationships.Highlighting a topic sentence in the full text:When the clicked dot is associated with a topic sen-tence, the full text is displayed in a separate window,with the topic sentence highlighted.
This highlight-ing helps the user to understand the context of  thesentence quickly, and thus further facilitates focus-ing on the information of particular interest.Topic sentences: Finally, we illustrate some ofthe~topic sentences extracted by our system below.For each topic, the two sentences related to thetopic most closely are shown.'
l raq-topic ' :?
Israel's Air Force bombed Iraq "s Osirak nuclear eac-tor in 1981 while Iraq was at war with lran, claimingthe facility was being used to develop atomic weapons.?
Some analysts in Israel, which closely tracks Iraq'sarms program, believe Baghdad could be two to fiveyears away from producing its own atomic warheads formissiles or nuclear bombs to be dropped from jets.
'Pakistan-topic ' :?
Leonard Spector, an expert on the spread of  nuclearweapons, has said "available evidence leaves littledoubt" that Pakistan is indeed eveloping nuclear arms.?
The continuing review of Pakistan "s nuclear programis part of such concern, Kelly said, citing a U.S. law,the Pressler amendment, requiring the president tocertify annually that Pakistan does not possess anuclearweapon.'
South Afr ica-topic ' :?
In the past, South Africa has refused to sign the 1969Nuclear Non-Proliferation Treaty and to submit all itsnuclear facih'ties to inspection by the Henna-basedlnternational Atomic Energy Agency.?
Under the Treaty on the Non-Proliferation of Nuclear83-"-?-'+?-"-- P l .......
I i cread?n i I ...... l_~ map '~1  ,+++me+ fl 1 " i :~.,t,o.
i P'?P" II'\] creation 1 \[ .
.
.
.
.
.
.
.
.
2IIIIII/Figure 3: Overview of the process.A block arrow indicates the input to the process, and rectangles with double-line border are the output.
Rectangleswith dashed line border are sub-processes.
Other ectangles represent data.Weapons, which has been signed by 137 governmentssince its preparation in 1969, countries without suchweapons open their nuclear facilities to inspection byexperts from the International Atomic Energy Agency, aU.N.
agency based in Henna.Both for 'lraq-' and "Pakistan-topic', the twotopic sentences address two different aspects of thesimilar "doubt" or "concern".
For 'South Africa-topic', the second topic sentence gives backgroundknowledge of the specific fact described in thefirst topic sentence.
We find it interesting that,despite the fact that the two topic sentences areextracted from different documents, they appear tobe consecutive s quences from a uniform source.In essence, the design seeks to facilitate quick ap-preciation of the contents of a document space bysupporting browsing through adocument collectionWith easily switching between different views: topichighlights (terms), topical sentences, full documenttext, and inter-document relationships.
At present,there is no attempt to handle redundancy betweentopic sentences.4 ImplementationIn this section, we describe the implementation four prototype system.
The overall process flow ofthis system is shown in Figure 3.
Our descriptionomits the process Of creating raphical presentationthat is straightforwardly understood from Section3.
The system takes, as its input, the text of a givenset of documents.
Throughout this section, we usethe three small 'documents' hown below as anillustrative xample.
The data flow from these threedocuments othe final output is shown in Figure 4.Document # 1:Mary Jones has a little lamb.
The lamb is her good buddy.Document #2:Mary Jones is a veterinarian for ABC University.ABC University has many lambs.Document #3:Mike Smith is a programmer for XYZ Corporation.4.1 Term extractionFirst, we extract all terms contained in the docu-ments, using an infrastructure for document pro-cessing and analysis, comprising a number of in-terconnected, and mutually enabling, linguistic fil-ters; which operates without any reference to a pre-defined domain.
The whole infrastructure (here-after eferred to as  TEXTRACT)  is designed from theground up to perform avariety of linguistic featureextraction functions, ranging from straightforward,single pass, tokenization, lexical ook-up and mor-phological analysis, to complex aggregation f rep-resentative (salient) phrasal units across large multi-document collections (Boguraev and Neff, 2000).TEXTRACT combines functions for linguistic analy-sis, filtering, and normalization; these focus on mor-phological processing, named entity identification,technical terminology extraction, and other multi-word phrasal analysis; and are further enhanced bycross-document aggregation, resulting in some nor-IiaiiIiiiiII84 Idocument ext# 1 : Mary Jones has a little lamb.
( s l )The lamb is her good buddy.
(s2)#2: Mary Jones is a veterinarian for ABC University.
(s3)ABC University has many lambs.
(s4)#3: Mike Smith is a programmer for XYZ corporation.
(sS)term.document vectors#1 #2Mary Jones I !little I 0?conversion matriz(Wansposed)0.45 0 00.22 0 0.35Terms"Mary Jones", "little", "lamb", "goodbuddy", "veterinarian", "ABC University","Mike Smith", "programmer","XYZ Corporation"I 1term-sentence vectorssl s2 s3Ma W Jones I 0 1little I 0 0lamb 1 1 0.94 s00I lamb 2 1 0.67 0 0.38I good buddy I 0 0.22 0 0.35 good buddy I 0 0veterinarian 0 i 0.22 0 -0.35 veterinarian 0 0 I 0ABC Univ.
0 2 0.45 0 -0.71 ABC Univ.
0 0 I 1Mike Smith 0 0 0 0.58 0 Mike Smith 0 0 0 0programmer 0 0 0 0.58 0 programmer 0 0 0 0I XYZ corp. 0 0 0 0.58 0 XYZ corp. 0 0 0 0!
- -  topic vectors term vectors sentence vectorsterlTI Vectors are ?cum ?
Jt 01 #2 \[ #1 #2 column vectors0.84 0.84 #03.53 I 0 of the conversion0 0 -0.53 0 1 matrix.0.53 0.53 0 0 0t J lterm-topic relevancelittlelambveterinarianABC Univ.Mike Smith?
sl s2 s3 s4 s5 \[1.34 0.89 1.12 1.12 0I 0 01 0 1.74 0.70 0.70 .06 -0.36 0document-topic relevancee.g.
(doc 01, topic #1)= \[0.84,0,0.53\] \[i, 0, 0\] T= 0.84"1+0"0+0.53"0 = 0.84OUtpUt lamb, Mary Jones, ABC University?
Mary Jones has a littlelamb.?
Mary Jones is aveterinarian for ABCUniversity.?
ABC University hasmany lambs.sentence.to )ic relevancetopic #1 topic #2sl 1.34 0s2 0.89 0s3 1.12 0s4 1.12 0s5 0 1.74e.g.
(#1-l,topic #1)= \[ 1.34,0, 0.70\] \[1, 0, 0\] T= 1.34"1+0"0+0.70"0 = 1.34Mike Smith, programmer, XYZ corporationJ?
Mike Smith b aprogrammer for XYZcorporation.Figure 4: Example of data flow.85Procedure ConstructSemanticSpaceInput: term-document vectors dr, ..., dnOutput: conversion matrix CD = \[dl...dn\]/* Term-document matrix */R = D/* Initialize aresidual matrix with the term-document matrix */For i = 1 to kR, = \[It1 Iqrx---Ir,,Iqr,~\]/* Scale each of R's column vectors by a power of its own length */c /=  the eigenvector fR ,  R,  T with the largest eigenvalueR = R - \[(eiTrt)el...(ciTrn)ei\]/* Eliminate the direction of el from R's column vectors */End forC = \[el...ek\] r / *  Conversion matrix */Figure 5: Semantic space creation.
Scaling factor q ahd the dimensionality k are experimentally determined.malization to canonical forms, and simple types ofco-reference r solution.For the example mini-documents above, after e-moval of common stop words, the terms remainingas linguistic objects for the algorithm to operate onare listed at top of Figure 4.4.2 Vector creationWe construct the semantic space from term-document relationships by a procedure 2 shown inFigure 5.
In the semantic space, each of vec-tor elements represents a linear combination ofterms.
The conversion matrix returned by thesemantic space creation procedure keeps the in-formation of these linear combinations.
For in-stance, the conversion matrix for our example(see Figure 4) shows that the first element of avector in the semantic space is associated with0.45,"Mary Jones"+0.22*"iittle"+0.67*"lamb"+0.22,.
"good buddy"+0.22,"veterinarian"+0.45,"ABC Uni-versity".To map the documents o the vectors in the se-mantic space, we create the term-document vectorseach of whose elements represents he degree of rel-evance of each term to the document.
Our imple-?
mentation uses term frequency as the degree of rel-evance.
We create document vectors of the seman-tic space by multiplying term-document vectors andthe conversion matrix.
Sentences and terms can alsobe mapped to the vectors in the same way by treat-ing them as "small documents".2We do not describe the details of this procedure in this pa-per.
See Section 2.4.3 Identifying topicsUltimately, our multi-document summaries relycrucially on identifying topics representing all thedocuments in the set.
This is done by creating topicvectors o that each document vector is close to (i.e.represented by) at least one topic vector.
We imple-ment this topic vector creation process as follows.First, we create a document graph from the docu-ment vectors.
In the document graph, each noderepresents a document vector, and two nodes havean edge between them if and only if the similar-ity between the two document vectors is above athreshold.
Next, we detect he connected compo-nents in the document graph, and we create the topicvectors from each connected component by apply-ing the procedure 'DetectTopic' (Figure 6) recur-sively.
'DetectTopie' works as follows.
The unit eigen-vector of a covariance matrix of the document vec-tors in a set ,.q is computed as v. It is a representa-tive direction of  the document vectors in S. I f  thesimilarity between v and any document vector inS is below a threshold, then S is divided into twosets $1 and ,-q2 (as in Figure 7), and the procedureis called for $1 and $2 recursively.
Otherwise, v isreturned as a topic vector.
The granularity of topicdetection can be adjusted by the setting of thresholdparameters.Note that such a topic vector creation procedureessentially detects "cluster centroids" of documentvectors (not sentence vectors), although groupingdocuments into clusters is not our purpose.
Thisindicates that general vector-based clustering tech-nologies could be integrated into our framework if86IIIIIi!IIIiIIII!iiiIIIIIiIiIIIIIIIIIIit brings further improvement.4.4 Associations between topics and linguisticobjectsThe associations between topics and linguistic ob-jects (documents, entences, and terms) are.
mea-sured by computing the cosine (similarity measure-ment) between the topic vectors and linguistic ob-ject vectors.
The degree of association between top-ics and documents i  used to create document maps.The terms and sentences with the strongest associa-tions are chosen to be the topic terms and the topicsentences, respectively.As a result, for our example we get the outputshown at the bottom of Figure 4.4.5 Computational complexityLet m be the number of different erms in the doc-ument set (typically around 5000), and let n be thenumber of documents (typically 50 to 100) 3.
Giventhat ra 3> n, the semantic space is constructed inO(mn 2) time.
The topic vectors are created inO(n 3) time by using a separator t ee for the compu-tation of all-pairs minimum cut 4, assuming that thedocument vector set is divided evenly 5.
Let k be thedimensionality of the semantic space, and let h bethe number of detected topics.
Note that k and h areat most n, but are generally much smaller than n inpractice.
Regarding the number of terms containedin one sentence as a constant, opic sentences are ex-t:racted in O(skh) time where s is the total numberof sentences in the document set.
Topic terms areextracted in O(mkh) time.
We note that the proto-type system runs efficiently enough for an interac-tive system.
"5 Conclusion and further  work?
This paper proposes a framework for multiple doc-umet~t summarization that leverages graphical el-ements to present a summary as a 'constellation'of topical highlights, tn this framework, we detecttopics underlying a given documont collection, andwe describe the topics by extracting related termsand sentences from the document text.
Relation-ships~among topics and documents are graphicallypresented using gradation of color and placementof image objects.
We illustrate interactions with3In this work, we focus on relatively small document col-lections; ee Section I.4See (Ahuja et al, 1993) for all-pairs rain cut problem.~Note that Step 3 in the document vector division procedure(Figure 7) seeks for this.87Procedure DetectTopic(S)Input: a set of document vectors SOutput: topic vectorsv = the unit eigenvector fa covariance matrix ofdocument vectors in SLoop for each document vector d in Sif similarity between d and v is below a thresholdthen begindivide S into $I and $2Call DetectTopic(St)Call DetectTopic(S2) .,Exit the procedureEnd if, End loopReturn v as a topic vectorFigure 6: Topic vector creation.our prototype system, and describe its implemen-tation.
We re-emphasize that the framework pre-sented here derives its strength in equal part fromtwo components: the results of topical analysis ofthe document collection are displayed by meansof a multi-perspective graphical interface specifi-cally designed to highlight his analysis.
Withinsuch a philosophy for multi-document summariza-tion, sub-components of the analysis technology canbe modularly swapped in and replaced, without con-tradicting the overall approach.The algorithms and subsystems comprising thedocument collection analysis component have beenimplemented and are fully operational.
The paperdescribed one possible interface, focusing on certainvisual metaphors for highlighting collection topics.As this is work in progress, we plan to experimentwith alternative presentation metaphors.
We planto carry out user studies, to evaluate the interfacein general, and to determine optimal features, bestsuited to representing our linguistic object analysisand supporting navigation through query results.Other future work will focus on determining theeffects of analyzing linguistic objects to differentlevel of granularity on the overall results.
Questionsto consider here, for instance, would he: what isthe optimal definition of a term for this application;does it make sense to include larger phrasal unitsin the semantic space; or do operations over sen-tences, such as sentence merging or reduction, offeralternative ways of visualizing topical content.It is therefore worthwhile investigating whethercombining automatic summarization withintelligent multimedia presentation techniquescan make the briefing generation amenable tofull automation.
In other words, the authorshould be able to use a computer program togenerate an initial briefing, which she can thenedit and revise as needed.
The briefing can thenbe presented by the author if desired, or elsedirectly by the computer (particularly useful ifthe briefing is being sent to someone lse).
Thestarting point for this process would be a high-level outline of the briefing on the part of theauthor.
The outline would include references toparticular information sources that had to besummarized in particular ways.
If a programwere able to take such outlines and generatebriefings which didn't require extensive post-editing to massage into a state deemedacceptable for the task at hand, the programcould be regarded as a worthwhile time savingtool.2 ApproachOur work forms part of a larger DARPA-fundedproject aimed at improving analysis anddecision-making in crisis situations by providingtools that allow analysts to collaborate todevelop structured arguments in support ofparticular conclusions and to help predict likelyfuture scenarios.
These arguments, along withbackground evidence, are packaged together asbriefings to high-level decision-makers.
Inleveraging automatic methods along the linessuggested above to generate briefings, ourapproach needs to allow the analyst to take on as~uch of the briefing authoring as she wants to(e.g., it may take time for her to adapt o or trustthe machine, or she may want the machine topresent just part of the briefing).
The analyst'sorganisation usually will instantiate one ofseveral templates dictating the high=levelstructure of a briefing; for example, a briefingmay always have to begin with an executivesummary.
The summarization methods also needto be relatively domain-independent, given thatthe subject matter of crises are somewhatunpredictable; an analyst in a crisis situation islikely to be inundated with large numbers ofcrisis-related news and intelligence r ports frommany different sources.
This means that wecannot require that a domain knowledge base beavailable to help the briefing generation process.Given these task requirements, we have adoptedan approach that is flexible aboutaccommodating different degrees of authorinvolvement, that is relatively neutral about therhetorical theory underlying the briefingstructure (since a template may be provided byothers), and that is domain-independent.
I  ourapproach, the author creates the briefing outline,which is then fleshed out further by the systembased on information in the outline.
The systemfills out some content by invoking specifieds taBunarizers; it also makes decisions, whenneeded, about output media type; it introducesnarrative lements to improve the coherence ofthe briefing; and finally, it assembles the finalpresentation, making decisions about spatiallayout in the process.A briefing is represented asa tree.
The structureof the tree represents he rhetorical structure ofthe briefing.
Each node has a label, which offersa brief textual description of the node.
Each leafnode has an associated goal, which, whenrealized, provides content for that node.
Thereare two kinds of goals: content-level goals andnarrative-level goals.
Content-level goals arealso of two kinds: retrieve goals, which retrieveexisting media objects of a particular type (text,audio, image, audio, video) satisfying somedescription, and create goals, which create newmedia objects of these types using programs(called summarization filters).
Narrative-levelgoals introduce descriptions of content at othernodes: they include captions and running text formedia objects, and segues, which are rhetoricalmoves describing a transition to a node.Ordering relations reflecting temporal andspatial ayout are defined on nodes in the tree.Two coarse-grained relations, seq forprecedence, and par for simultaneity, are used tospecify a temporal ordering on the nodes in thetree.
As an example, temporal constraints for a(tiny) tree of 9 nodes may be expressed as:<ordering> <seq><par>7</par><par>8</par><par>3</par><par>4 5</par><par>6</par>90IIiiIIiIIIIIIIIIIIIIIiIIIII|<par> l 9</par><par>2</par></seq> </ordering>The tree representation, along with the temporalconstraints, can be rendered in text as XML; werefer to the XML representation as a script.
?~\] Tern#ateScript \[7Validator I~und~c,~\[ISMIL J Presentation \[User Brief'mgInterface G en~ator/Figure 1: System ArchitectureThe overall architecture of our system is shownin Figure I.
The user creates the briefing outlinein the form of a script, by using a GUI.
Thebriefing generator takes the script as input.
TheScript Validator applies an XML parser to thescript, to check for syntactic orrectness.
It thenbuilds a.tree representation for the script, whichrepresents the briefing outline, with temporalconstraints attached to the leaves of the tree.Next, a Content Creator takes the input tree andexpands it by introducing narrative-level goalsincluding segues to content nodes, and runningtext and captions describing media objects atcontent nodes.
Running text and short captionsare generated from meta-information associatedwith media objects, by using shallow textgeneration methods (canned text).
The end resultof content selection (which has an XMLrepresentation called a ground scrip0 is that thecomplete tree has been fully specified, with all91the create and retrieve goals fully specified,with all the output media types decided.
TheContent Creator is thus responsible for bothcontent selection and creation, in terms of treestructure and node content.Then, a Content Executor executes all the createand retrieve goals.
This is a very simple step,resulting in the generation of all the mediaobjects in the presentation, except for the audiofiles for speech to be synthesized.
Thus, this step.
results in realization of the content at the leavesof the tree.F ine ly ,  the Presentation Generator takes thetree which is output from Content Execution,along with its temporal ordering constraints, andgenerates the spatial ayout of the presentation.If no spatial ayout constraints are specified (thedefault is to not specify these), the systemallocates pace using a simple method based onthe temporal layout for nodes which have spatialmanifestations.
Speech synthesis is also carriedout here.
Once the tree is augmented with spatiallayout constraints, it is translated by thePresentation Generator into SMIL 2(Synchronized Multimedia IntegrationLanguage) (SMIL 99), a W3C-developedextension of HTML that can be played bystandard multimedia players (such as Real 3 andGrins 4.
This step thus presents the realizedcontent, synthesizing it into a multimediapresentation laid out spatially and temporally.This particular architecture, driven by the aboveproject requirements, does not use planning asan overall problem-solving strategy, as planningrequires domain knowledge.
It therefore differsfrom traditional intelligent multimediapresentation planners, e.g., (Wahlster et al 93).Nevertheless, the system does make a number ofintelligent decisions in organizing andcoordinating presentation decisions.
These arediscussed next, aRer which we turn to the mainpoint of the paper, namely the leveraging ofsummarization in automatic briefing generation.2 http://www.w3.org/AudioVideol3 www.real.com4 www.oratrix.com3 Intelligent Multimedia PresentationGenerationThe author of a briefing may choose to flesh outas little of the tree as desired, with the caveatthat the temporal ordering relations for non-narrative nodes need to be provided by her.When a media object is generated at a node by acreate goal, the running text and captions aregenerated by the system.
The motivation for thisis obvious: when a summarization filter (whichis a program under our control) is generating amedia object, we can often provide sufficientmeta-information about hat object o generate ashort caption and some running text.
By default,all segues and spatial layout relations are alsospecified by the system, so the author does nothave to know about these unless she wants to.Finally, the decision as to when to produceaudio, when not specified by the author, is left tothe system.When summarization filters are used (for creategoals), the media type of the output is specifiedas a parameter to the filter.
This media type maybe converted to some other type by the system,e.g., text to speech conversion using Festival(Taylor et al 98).
By default, all narrative nodesattempt to realize their goals as a speech mediatype, using roles based on text length andtruncatability to less than 250 bytes to decidewhen to use text-to-speech.
The truncationalgorithm is based on dropping syntacticconstituents, using a method similar to (Mani etal.
99).
Captions are always realized, in addition,as text (i.e., they have a text realization and apossible audio realization).Spatial layout is decided in the PresentationGenerator, after all the individual media objectsare created along with their temporal constraintsby the Content Executor.
The layout algorithmwalks through the temporal ordering insequence, allocating a segment o each set ofobjects that is designated to occursimultaneously (grouped by par in the temporalconstraints).
Each segment can have up to 4frames, in each of which a media object isdisplayed (thus, no more than 4 media objectscan be displayed at the same time).
Since mediaobjects declared to be simultaneous (using par)in the temporal constraints will go together in aseparate segment, the temporal constraintsdetermine what elements are grouped together ina segment.
The layout within a segment handlestwo special cases.
Captions are placed directlyunderneath their associated media object.Running text, when realized as text, is placedbeside the media object being described, so thatthey are paired together visually.
Thus,coherence of a segment is influenced mainly bythe temporal constraints (which have beenfleshed out by the Content Creator to includenarrative nodes), with further handling of specialcases.
Of course, an individual summarizationfilter may choose to coordinate componentmultimedia objects in particular ways in thecourse of generating a composite multimediaobject.Details such as duration and onset of particularframes are specified in the translation to SMIL.Duration is determined by the number of framespresent in a segment, unless there is an audiomedia object in the segment (this media objectmay have a spatial representation, e.g., as anaudio icon, or it may not).
If an audio mediaobject occurs in a frame, the duration of allmedia objects in that frame is equal to the lengthof all the audio files in the segment.
If there isno audio present in a segment, he duration is txseconds (tx has a default value of 5) times thenumber of frames created.4 Summarization FiltersAs mentioned above, create goals are satisfiedby summarization filters, which create newmedia objects ummarizing information sources.These programs are called summarization filtersbecause in the course of condensing information,they take input information and turn it into somemore abstract and useful representation, filteringout unimportant information.
Such filtersprovide a novel way of carrying out contentselection and creation for automatedpresentation generation.Our approach relies on component-basedsoftware composition, i.e., assembly of softwareunits that have contractually specified interfacesthat can be independently deployed and reused.The idea of assembling complex languageprocessing programs out of simpler ones is92IIIIlIIIIIhardly new; however, by employing currentindustry standards to specify the interactionbetween the components, we simultaneouslyincrease the robustness of the system, ensure thereusability of individual components and createa more fully plug-and-play capability.
Amongthe core technology standards that support hisplug-and-play component assembly capabilityare (a) Java interfaces, used to specify functionsthat all summarization components mustimplement in order to be used in the system, (b)the JavaBeans standard, which allows theparameters and methods of individualcomponents o be inspected by the system andrevealed to the users (c) the XML markupstandard, which we have adopted as an inter-component communication language.
Usingthese technologies, legacy or third-partysummarizers are incorporated into the system by"wrapping" them so as to meet the interfacespecification of the system.
These technologiesalso make possible a graphical environment toassemble and configure complex summarizationfilters from individual summarizationcomponents.Among the most important wins over thetraditional "piping" approach to filter assemblyis the ability to impose build-time restrictions onthe component assembly, disallowing "illegal"compositions, e.g.
component X cannot provideinput to component Y unless X's output typecorresponds to Y's input type.
Build-timerestrictions uch as these play a clear role inincreasing the overall robustness of the run-timesummarization system.
Another build-time winlies in the ability of JavaBeans to be serialized,i.e., written to disk in such a way as to preservethe state of its parameters settings, ensuring thatevery component in the system can beconfigured and run at different timesindependently of whether the componentprovides aparameter file facility.Establishing the standard functions required of asummarization filter is challenging on severalfronts.
One class of functions required by theinterface is necessary tohandle the technicalitiesof exchanging information between otherwisediscrete components.
This set includesfunctions for discovering a component's inputand output types, for handling messages,exceptions, and events passed betweencomponents and for interpreting XML based onone or more system-wide document typedefinitions (DTDs).
The other, more interestingset of functions gets to the core ofsummarization functionality.
Selecting thesefunctions involves identifying parameters likelyto be broadly applicable across most or allsummarizers and finding ways to group themand/or to generalize them.
This is desirable inorder to reduce the burden on the end user ofunderstanding the subtle differences between the.
various settings in the summarizers available toher.An example of the difficulty inherent in thisendeavor is provided by the compression(summary length divided by source length) vs.reduction (l's complement of compression) vs.target length paradigm.
Different summarizerswill implement one or more of these.
Thewrapper maps from the high-level interfacefunction, where the application/user can specifyeither compression ortarget length, but not both,to the individual summarizer's representation.Thus, a user doesn't need to know whichrepresentation(s) a particular summarizer usesfor reduction/compression.A vanilla summarization Bean includes thefollowing functionality, which every summarizermust be able to provide methods for:source: documents to be summarized(this can be a single document, or acollection)reduction-rate: either summarysize/source size, or target lengthaudience: user-focused or generic(user-focused requires the specificationof a bag of terms, which can be ofdifferent types)output-type: specific data formats(specified by DTDs)The above are parameters which we expect allsummarizers to support.
More specializedsummarizer beans can be constructed to reflectgroupings of summarizers.
Among otherparameters are output-fluency, which specifieswhether a textual summary is to be made up ofpassages (sentences, paras, blocks), namedentities, lists of words, phrases, or topics, etc.Given that definitions of summarization in more93theoretical terms have not been entirelysatisfactory (Mani 2000), it is worth noting thatthe above vanilla Bean provides an operationaldefinition of what a summarizer is.text, and segues.
The captions and running text,when not provided by the filters, are provided bythe script input.
In the case of retrieve goals, theobjects may not have any meta-information, iwhich case a default caption and running-text isgenerated.
Clearly, a system's explanatorynarrative will be enhanced by the availability ofrich meta-information.The segues are provided by the system.
Forexample, an item with a label "A biography ofbin Laden" could result in a generated segue"Here is a biography of bin Laden".
TheContent Creator, when providing content fornarrative nodes, uses a variety of differentcanned text patterns.
For the above example, thepattern would be "Here is @6.1abel", where 6 isthe number of a non-narrative node, with labelbeing its label.Figure 2: Summarization FilterCompositionIn addition to its practical utility in the ability toassimilate, combine and reuse components indifferent combinations, and to do so within aGUI, this approach is interesting because itallows powerful summarization functions to becreated by composing together simpler tools.
(Note that this is different from automaticallyfinding the best combination, which our systemdoes not address).
For example, Figure 2illustrates a complex filter created by using aGUI to compose together a named entityextractor, a date extractor, a component whichdiscovers significant associations between thetwo and writes the result to a table, and avisualizer which plots the results as a graph.
Theresulting summarizer takes in a large collectionof documents, and produces as a summary agraph (a jpeg) of salient named entity mentionsover time.
Each of its components can be easilyreused within the filter composition system tobuild other summarizers.5 Narrative SummarizationPeru Action Brief1 Preamble2 Situation Assessment2.1 Chronology of Events2.1.2 Late st document summarycre ate ("uu mmarize -ge n eric-compression.
l/peru/p32")2.2 Biographies2.2.1 Biography of Victor Polay2.2.1.1 Picture of @2.2.2.p~rsonrelrieveCD :h'awdata\polay.jpg')2.2.1.2 Biography of@~2.2.2.p~moncreate("~ummarize-bio-lwng~ 350-~pan multi -pwruon~2.2.2.per~n -out table3 Coda"Th/s briefing has assessed a~ec/~ of thesituation in Peru.
Overall, t\]~ crisisappears to be worsening.
"Figure 3: Input ScriptAs mentioned above, the system can construct anarrative to accompany the briefing.
Narrativenodes are generated to cover captions, running94Peru Action Brief1 Preambleaudio = "ln this briefing,/will go overthe ~2.1abeL This n i l  cover~2.1.1abel and @2.
3.1.laber"2 Situation Assessment2.1 "An overview of the @2.2.1abeF(Maa-2.2)2.2 Chronology of Events2.2.1 audio = "Here is the @2.2.2.1abeF(Meta-2.
2.
2)2.2.2 text = "Latest document summary"audio = text =ere ate ("summarize -gen eric-compression .1/peru/p32")2.3 Biographies2.3.1 audio ="A profile of @2.
3.
2.person"(Mete-2.3.2)2.3.2 Biography of Victor Polay2.3.2.1 audio = text ="A file photo of@2.3.2.person7(Meta-2.3,2.2)2.3.2.2 Picture of @2:3.2.personimage =retrie ve("D Arawdata~polay.jpg")2.3.2.3 audio = text ="Profile of @2.
3.2.\]~rson"(Meta-2.3.2.3)2.3.2.4 Biography of@2.3.2.personaudio = text =create ("summarize -bio -length 350-~'pan multi -person@2.2.2.person -out table~em/* ")3 Codaaudio = "This briefing has a~sessedas-pect$ of the situation in Peru.
Overall,the crisis appears to be worsening.
"<seq></seq><par> l</par><par>2.2.1 2.2.2</par>?par>2.3.
l </par><par>2.3.2.
l 2.3.2.22.3.2.3 2.3.2.4</par><par>3</par>Figure 4: Ground ScriptAll segue nodes are by default generatedautomatically by the system, based on nodelabels.
We always introduce a segue node at thebeginning of the presentation (called a preamblenode), which provides a segue covering the"crown" of the tree, i.e., all nodes upto aparticular depth d from the root (d=-2) aremarked with segue nodes.
A segue node is alsoproduced at the end (called a coda).
(Bothpreamble and segue can of course be specifiedby the author if desired).For introducing intervening segue nodes, we usethe following algorithm based on the distancebetween odes and the height in the tree.
Wetraverse the non-narrative l aves of the tree intheir temporal order, evaluating each pair ofadjacent nodes A and B where A precedes Btemporally.
A segue is introduced betweennodes A and B if either (a) the maximum of the2 distances from A and B to their least commonancestor is greater than 3 nodes or (19) the sum ofthe 2 distances from A and B to the leastcommon ancestor is greater than 4 nodes.
This isless intrusive than introducing segues at randomor between every pair of successive nodes, andappears to perform better than introducing asegue at each depth of the tree.6 An ExampleWe currently have a working version of thesystem with a variety of different single andmulti-document summarization filters.
Figure 3shows an input script created by an author (thescripts in Figure 3 and 4 are schematicrepresentations of the scripts, rather than the rawXML).
The script includes two create goals, onewith a single-document generic summarizationfilter, the other with a multi-document user-focused summarization filter.
Figure 4 shows theground script which was created automaticallyby the Content Creator component.
Note theaddition of media type specifications, theintroduction of narrative nodes, and theextemion of the temporal constraints.
The finalpresentation generated is shown in Figure 5.Here we show screen dumps of the six SMILsegments produced, with the audio if any foreach segment indicated in this paper next to anaudio icon.957 StatusThe summarization filters have incorporatedseveral summarizers, including some that havebeen evaluated in the DARPA SUMMACconference (Mani et al 99-1).
These carry outboth single-document and multi-documentsummarization, and include a preliminarybiographical summarizer we have developed.The running text for the biography table in thesecond-last segment of Figure 5 is producedfrom meta-information i the table XMLgenerated by the biographical summarizer.
Theproduction method for running text uses cannedtext which should work for any input tableconforming to that DTD.The summarization filters are b.eing tested aspart of a DARPA situated test with end-users.The briefing generator itself has been usedinternally to generate numerous briefings, andhas been demonstrated as part of the DARPAsystem.
We also expect ,to carry out anevaluation to assess the extent to which theautomation described here provides efficiencygains in briefing production.8 Related WorkThere is a fair amount of work on automaticauthoring of multimedia presentations, e.g.,(Wahlster et al 93), (Dalai et al 96), (Mittal etal.
95), (Andre and Rist 97) 5.
These effortsdiffer from ours in two ways: first, unlike us,they are not open-domain; and, second, theydon't use summarization components.
While..such efforts are extremely sophisticatedcompared to us in multimedia presentationplanning and fine-grained coordination andsynchronization capabilities, many of thecomponents used in those efforts are clearlyapplicable to our work.
For example, (Andre andRist 96) include methods for leveraging lifelikecharacters in this process; these characters canbe leveraged in our work as well, to helppersonify the computer narrator.
In addition, ourcaptions, which are very short, rely on cannedtext based on node labels in the initial script, orbased on shallow meta-information generated bythe summarization filter (in XML) along withthe created media object.
(Mittal et al 95)describe avariety of strategies for generation oflonger, more explanatory captions, some ofwhich may be exploited in our work bydeepening the level of meta-information, at leastfor summarization components developed by us.In our ability to leverage automaticsummarization, our work should be clearlydistinguished from work which attempts toformat a summary (from an XMLrepresentation) into something akin to aPowerpoint briefing, e.g., (Nagao and Hasida98).
Our work, by contrast, is focused on usingsummarization i generating briefings from anabstract outline.9 ConclusionWe have described methods for leveragingautomatic summarization in the automaticgeneration of multimedia briefings.
This workhas taken, an open-domain approach, in order tomeet the requirements of the DARPAapplication we are involved with.
We believethere is a stronger role that NL generation canplay in the narrative aspects of our briefings,which currently rely for the most part on cannedtext.
Our future work on description merging inbiographical summaries, and on introducingreferring expressions into the narrative nodes,would in effect ake advantage of more powerfulgeneration methods, without sacrificing open-domain capabilities.
This may require muchricher recta-information specifications than theones we currently use.Finally, we have begun the design of the ScriptCreator GUI (the only component in Figure 1remaining to be built).
This will allow the authorto create scripts for the briefing generator(instead of editing templates by hand), by layingout icons for media objects in temporal order.
Auser will be able to select a "standard" briefingtemplate from a menu, and then view it in abriefing/template structure ditor.
The user canthen provide content by adding annotations toany node in the briefing template.
The user willhave a choice of saving the edit version intemplate form, or in SMIL or possibly MicrosoftPowerpoint format.96t~, , ,  - -  ~Peru Act ion Br ie f  !!?
hectare  Summary  |o Hypotheds  .|Opt ions  ~* S lmadon A .
.
.
.
.
.
.
~o Chrono loT~/o f  ~'~ve~tso :mop-~Jd~ ii ?
SmKtm-ed  Arguments?
A l tensadve  V iews  i?
Deds ionsIn this briefing I will go over the situationassessment.
This will cover an overview of thechronology of events and a profile of VictorPolay.Next, a biography of Victor Polay.Here is an overview of the chronology ofevents.1: c~l  - PetuvLem rebe ls  te leane  2 hos~eages - Dec. lS th3: KbOUC ZOO hostages  remained l l~Lde  ~he home OZ Japaneselabassaclo:c ~Ol:lhlstt JLOkl, where  TUpOC Az~ru rebe ls  metec~m~ndlng  ~he re lease  ~tmn pc lson  o?
e~ouc  400 o f  ~he l rco l  leagues .qo Here is the latest document summary.Victor Polay, also known as ComandanteRolando, is the Tupac Amaru founder, aPeruvianguerrilla commander, a former ebelleader, and the Tupac Amaru rebels' top leader.He studied in both France and Spain.
His wife isRosa Polay and his mother is Otilia Campos dePolay.
His associates include Alan Garcia.o This briefing has assessed aspects of thesituation in Peru.
Overall, the crisis appears tobe worsening.Figure 5: Presentation97ReferencesAndre, E. and Rist, T. (1997) Towards a NewGeneration of Hypermedia Systems: ExtendingAutomated Presentation Design for Hypermedia.L.
Dybkjaer, ed., Proceedings of the Third SpokenDialogue and Discourse Workshop, Topics inNatural Interactive Systems 1.
The Maersk Mc-Kinney Moiler Institute for ProductionTechnology, Odense University, Denmark, pp.
10-27.Dalal, M., Feiner, S., McKeown, K., Pan, S., Zhou,M., Hollerer, T., Shaw, J., Feng, Y., and Framer, J.
(1996) Negotiation for Automated Generation ofTemporal MultimediaPresentations.
Proceedingsof ACM Multimedia '96.Mani, 1., Gates, B., and Bioedorn, E. (1999)Improving Summaries by Revising Them.Proceedings of the 37 ~ Annual Meeting of theAssociation for Computational Linguistics, CollegePark, MD, pp.
558-565.Mani, I., Firmin, T., House, D., Klein, G., Sundheim,B., and Hirschman, L. (1999) The TIPSTERSUMMAC Text Summarization Evaluation.Proceedings of EACL'99, Bergen, Norway, pp.
77-85.Mani, 1.
(2000)Automatic Text Summarization.
JohnBenjamins Publishing Company.
To appear.Mittal, V., Roth, S., Moore, J., Mattis, J., andCarenini, G. (1995) Generating ExplanatoryCaptions for Information Graphics.
Proceedings ofthe International Joint Conference on ArtificialIntelligence (IJCAr95), pp.
1276-1283.Nagao, K. and K. Hasida, K. (1998)Automatic TextSummarization Based on the Global DocumentAnnotation.
Proceedings of COLING'98, Montreal,pp.
917-921.Power, R. and Scott, D. (1998) Multilingual.. Authoring using Feedback Texts.
Proceedings ofCOL1NG'98, Montreal, pp.
1053-1059.Taylor, P., Black, A., and Caley, R. (1998) Thearchitecture of the Festival Speech SynthesisSystem.
Proceedings of the Third ESCA Workshopon Speech Synthesis, Jenolan Caves, Australia, pp.147-151.Wahlster, W., Andre, E., Finkler, W., Profitlich, H.-J., and Rist, T. (1993) Plan-Based Integration ofNatural Language and Graphics Generation.
AIJournal, 63.98
