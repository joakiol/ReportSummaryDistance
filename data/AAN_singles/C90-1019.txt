Deep Sentence Understanding in a Restricted Domain*Pierre Zweigenbaum and Marc CavazzaDIAM - -  INSERM U.194, 91 bd.
de l 'H6pital, 75634 Paris Cedex 13, Francee-mail: zweig@frsim51 (bitnet)AbstractWe present here the current prototype of thetext understanding system HELENE.
The ob-jective of this system is to achieve a deep un-derstanding of small reports dealing with a re-stricted domain.
Sentence understanding buildsa model of the state of the world described,through the application of several knowledgemodules: (i) LFG parsing, (ii) syntactic disam-biguation based on lexical entry semantic om-ponents, (iii) assembly of semantic omponentsand instantiation of domain entities, and (iv)construction of a world model through activa-tion of common sense and domain knowledge.1 Introduct ionWe present here the current prototype of thetext understanding system HI~LI~NE.
The ob-jective of this system is to achieve a deep un-derstanding of small reports dealing with a re-stricted domain (here, patient discharge sum-maries in a medical specialty).
This means thatH~LJ~NE should rely on an extensive descriptionof all types of required knowledge.
This impliesof course a deep domain knowledge base, includ-ing the needed common sense knowledge.Precise understanding must not only rely oncomplete domain knowledge, but also on enoughsyntactic information.
This is the reason whyH~LI~NE includes a full syntactic module, whosetask is to provide the semantic constructionmodule with the (deep) structures of sentences.One problem with syntactic processing is that itgives rise to numerous ambiguities.
These am-biguities are filtered on semantic grounds by adisambiguation module that does not build anysemantic representation.
*supported by AIM project 1003 and PRC Commu-nication Homme-Machine, PSle Langage Naturel.Semantic onstruction is concerned with therecognition of domain entities that can be ex-pressed by word groups.
We thus had to adopt alexical semantics approach compatible with de-scriptions.
Domain entities, once instantiated,provide the basis on which a model of the cur-rent state of the world (here, the patient state)is built.
The same lexical semantic in{brmationis used both to help syntactic processing, and ina more extensive way to access domain modelsin order to build semantic representations.The prototype includes the following mainmodules:The syntactic module implements the Lexi-cal Functional Grammar formalism \[7\].
Theparser builds c-structure and f-structurebottom-up in parallel on a chart, so that f-structure validity can constrain c--structureconstruction.Ambiguous attachments are submitted toevaluation and ranking by the disambigua-tion module.
This module applies a set ofgeneral heuristic rules that operate on thesemantic definition of the LFG predicates.Semantic construction relies on dynamicdomain models that integrate commonsense.
LFG predicates are characterized bysemantic omponents that point to parts ofthe knowledge base.The prototype runs in Common Lisp (VAXLisp) and K, a proprietary language mbeddedin Common Lisp.
The remaining sections de-scribe these modules in more detail.2 Parsing with a Lexical-Functional GrammarWe chose to implement he LFG fl:ameworkfor several reasons.
Being a linguistic theory,82 1it should provide better foundations for prin-cipled syntactic overage.
A formalism with acontext-free backbone was easier to implement.Furthermore, LFG extracts from a sentence apredicate-argument structure which consitutesa good starting point for semantic processing.Our implementation of LFG does not includeyet a schema for long-distance dependencies (orfunctional uncertainty) and coordination.
It al-lows cyclic f-structures.Our parser uses a chart to build both c-structure and f-structure.
Incomplete and com-plete constituents are represented by active andinactive cs-edges, while incomplete and com-plete fstructures are placed on active and in-active fs-edges.
The parsing strategy is bottom-up, left to right (left corner).
Top-down pars-ing is also available, as well as right to leftparsing.
LFG schemas are evaluated as soonas possible.
Equational (construction) schemasare evaluated when encountered, and constraintschemas (existential, equational and negation ofthose) are kept on fs-edges until they can beevaluated.
When fs-edges are combined, remain-ing constraints are propagated to the resultingfs-edge.
Each new active f-structure is testedfor consistency and coherence.
Furthermore, thevalue of a closed function is tested for complete-ness (this should be revised if a scheme for long-distance dependencies i  implemented).
Whena constraint is violated, its fs-edge is flagged asinvalid.Grammar rules are described as regular ex-pressions which are compiled into (reversible)transition etworks.
Each arc of those networksis labelled with a category and a disjunction ofconjunctions of schemas.
A model of hierarchi-cal lexical entry representation has been devel-oped, with data-driven lexical rules.
It is notcurrently coupled to the parser, and will notbe presented here.
The prototype uses a sim-ple word list with what would be the result ofthis model as lexical entries.The prototype uses a small French gram-mar that contains 14 networks, equivalent to 90rules.
It was assembled by borrowing from theliterature \[3,10\] and by completing with gram-mar manuals and real text confrontation.
It hasthe particularity of building cyclic f-structuresfor constructions where a head plays a role insidean adjunct.
This is how we process attributiveadjectives, participial phrases, and (in a verylimited way) relative phrases.3 Semantic rules for Syntact icDisambiguat ionStructural ambiguity is ubiquitous in our tar-get texts, since they contain descriptions that of-ten make use of series of prepositional phrases toqualify a noun.
We have then decided to submitambiguous attachments to semantic approvaland ranking before building complete parses.An ultimate test of semantic validity wouldconsist in comparing complete semantic repre-sentations built for each attachment proposal\[1\].
However, such a method is too expensive toallow systematic application.
Our system im-plements a more tractable approach that gen-eralizes selectional restrictions (or preferences).Evaluation is performed by executing a set ofheuristic positive and negative rules that votefor or against each proposal.
Rule conditionsembody criteria that refer to the semantic om-ponents (see below) of the predicates to be at-tached, and include the notion of isotopy \[8\].They apply not only to predicate-argument se-lection, but also to predicate-adjunct ombina-tion.4 Semantic Construct ionSemantic processing of a sentence results inthe activation of a relevant body of domainknowledge with related inferences within theknowledge base.Domain knowledge (here concerning a singledisease: thyroid cancer) is embedded in a model\[6,4\] describing domain objects, actions oper-ating on them and specific processes involvingthese objects.
Such a model is thus a dynamiccausal model rather than a memory structuredevoted to object and event integration \[9\].
Itis analogous to deep-knowledge models used inmodern expert systems \[2\].Domain objects are represented in a frame-like formalism.
Actions and operative aspects ofprocesses are described as production rules sim-ulating a distributed parallel activation \[4\].
Thewhole model corresponds to a dynamic, data-driven environment.Some domain concepts specifically representstates, relationships between objects, or state2 83transitions.
They can be triggered by theiroccurrence as word meanings in the sentence.Implicit occurrence of these concepts may alsobe recognized by observing the evolution of themodel.
In this case default procedures create thecorresponding concepts inside the model just asif these elements were explicitely stated in theproposition.
These concepts ubsume importantsituations in the model and translate them intoa higher description level, thus allowing outputto the user for a trace of correct understanding.No deep understanding would be possiblewithout a treatment, even partial, of commonsense, which in this application is concernedmainly with part-whole relationships \[5\], reason-ing about transitions and change, and elemen-tary physical actions (e.g., removing, touching).Default knowledge on actions, roles and refer-ence (e.g., used in the resolution of pragmaticanaphora) are associated to the common sensemodule.ColImlon sense mechanisms are incorporatedas production systems imilar to those describ-ing other active elements of the model, and canthus recombine freely with them in order to com-plete or modify existing representations.Domain representations are built from the as-sembly of lexical contents along the syntacticstructure of the proposition.
Words contain se-mantic, components \[8\], which are markers refer-ring to elements of the knowledge base or prop-erties of these representations.
The existence ofexplicit colnmon sense concepts in the knowl-edge base makes it possible to decompose ho-mogeneously technical and ordinary words.The lexical contents are assembled by heuris-tic rules to form candidate domain objects whichare recognized as instances of prototypes in therepresentation.
Lexical content itself is looselystructured; the association of the components icompleted according to their type (which is de-rived t rom the type of entity they refer to) andthe dependency (predicate-argument, predicate-adjunct) relations between the lexemes that con-tain such components, as provided by the LFG.As such elements of representation are recog-nized by the model, the reactive nvironment istriggered and interprets data until new informa-tion is analyzed.The prototype currently runs on a small set of30 sentences taken from patient discharge sum-maries.
These sentences were selected for thelinguistic issues they illustrate and the domaininferences they trigger.
A fully compiled versionof the program running on a VAX 8810 processesa sentence in an average 12 sec.
CPU time.References\[1\]\[2\]Birnbaum, L. (1985).
Lexical ambiguity as atouchstone for theories of language analysis.
IJ-CAI 9, Los Angeles, 815-820.Chandrasekaran, B. and Mittal, S. (1!183).
Ondeep versus compiled knowledge approaches tomedical diagnosis.
Int J Man-Machine S?udies19:425-436.\[3\]\[4\]IS\]\[6\]\[7\]\[8\]Orimshaw, J.
(1982).
On the lexical represen-tation of Romance reflexive clitics, in Bresnan(ed.
), The Mental Representation of Grammat-ical Relations, Cambridge, Mass., MIT Press.Holland, J.H., Holyoak, K.J., Nisbet~, R.E.,Thagard, P.R.
(1986).
Induction: Processesof Inference, Learning, and Discovery.
Cam-bridge: MIT Press.Iris, M.A., Litowitz, B.E., and Evens, M.(1988).
Problems of the part-whole relation.
InEvens, M.E., ed.
Rela$ional Models of the le~i-con.
Cambridge University Press.Johson-Laird, P.N.
(1983).
Mental Models,Cambridge University Press.Kaplan, R.M., and Bresnan, J.
(1982).
Lexical-Functional Grammar: A Formal System forGrammatical Representation, i  Bresnan (ed.
),The Mental Representation of Grammatical Re-lations, Cambridge, Mass., MIT Press.Rastier, F. (1987).
Sdmantique Interprdtative.Paris: Presses Universitaires de France.\[9\] Schank, R.C., and Abetson, R.P.
(1977).Scripts, Plans, Goals and Understanding.Lawrence Erlbaum Associates.\[10\] Waite, J.3.
(1986).
Orammaire Lexlcale-Fonctionnelle - -  Dislocation, inversion stylis-tique et constructions impersonnelles.
PhDThesis, University of Montreal.84 3
