Proceedings of EACL '99Detect ion of Japanese Homophone Errors by a Decis ion ListIncluding a Written Word as a Default EvidenceHiroyuki ShinnouIbaraki UniversityDept.
of Systems Engineering4-12-1 NakanarusawaHitachi, Ibaraki, 316-8511, JAPANsh innou@l i ly ,  dse .
ibarak i ,  ac .
jpAbstractIn this paper, we propose a practicalmethod to detect Japanese homophoneerrors in Japanese texts.
It is veryimportant o detect homophone rrorsin Japanese revision systems becauseJapanese texts suffer from homophoneerrors frequently.
In order to detect ho-mophone errors, we have only to solvethe homophone problem.
We can use thedecision list to do it because the homo-phone problem is equivalent to the wordsense disambiguation problem.
However,the homophone problem is different fromthe word sense disambiguation problembecause the former can use the writtenword but the latter cannot.
In this pa-per, we incorporate the written word intothe original decision list by obtaining theidentifying strength of the written word.The improved ecision list can raise theF-measure of error detection.1 IntroductionIn this paper, we propose a method of detect-ing Japanese homophone errors in Japanese texts.Our method is based on a decision list proposed byYarowsky (Yarowsky, 1994; Yarowsky, 1995).
Weimprove the original decision list by using writ-ten words in the default evidence.
The improveddecision list can raise the F-measure of error de-tection.Most Japanese texts are written using Japaneseword processors.
To input a word composed ofkanji characters, we first input the phonetic hira-gana sequence for the word, and then convert itto the desired kanji sequence.
However, multipleconverted kanji sequences are generally produced,and we must then choose the correct kanji se-quence.
Therefore, Japanese texts suffer from ho-mophone rrors caused by incorrect choices.
Care-lessness of choice alone is not the cause of homo-phone errors; Ignorance of the difference amonghomophone words is serious.
For example, manyJapanese are not aware of the difference between'.~.,'~,' and '~,~,', or between '~.~.'
and ,~ , t .In this paper, we define the term homophoneset as a set of words consisting of kanji charac-ters that have the same phone 2.
Then, we definethe term homophone word as a word in a ho-mophone set.
For example, the set { ~/~-~ (proba-bility), ~7 (establishment)} is a homophone setbecause words in the set axe composed of kanjicharacters that have the same phone 'ka-ku-ri-tu'.Thus, q /~ '  and '~f_ '  are homophone words.
Inthis paper, we name the problem of choosing thecorrect word from the homophone set the homo-phone problem.
In order to detect homophoneerrors, we make a list of homophone sets in ad-vance, find a homophone word in the text, andthen solve the homophone problem for the homo-phone word.Many methods of solving the homophone prob-lem have been proposed (Tochinai et al, 1986;Ibuki et al, 1997; Oku and Matsuoka, 1997; Oku,1994; Wakita and Kaneko, 1996).
However, theyare restricted to the homophone problem, that is,they are heuristic methods.
On the other hand,the homophone problem is equivalent to the wordsense disambiguation problem if the phone of thehomophone word is regarded as the word, and thehomophone word as the sense.
Therefore, we cansolve the homophone problem by using various1 '~'.-~.,~.
and '~.~..m~,' have a same phone 'i-sift'.
Themeaning of '~ , '  is a general will, and the meaning of'~:~'.~.,,... is a strong positive will.
'~.~.'
and '~ '  havea same phone 'cho-kkan'.
The meaning of 'l-ff__,~.
i is anintuition through a feeling, and the meaning of '~ 'is an intuition through a latent knowledge.ZWe ignore the difference of accents, stresses andparts of speech.
That is, the homophone set is theset of words having the same expression i  hiraganacharacters.180Proceedings of EACL '99statistical methods proposed for the word sensedisambiguation problem(Fujii, 1998).
Take thecase of context-sensitive spelling error detection3, which is equivalent to the homophone problem.For that problem, some statistical methods havebeen applied and succeeded(Golding, 1995; Gold-ing and Schabes, 1996).
Hence, statistical meth-ods axe certainly valid for the homophone prob-lem.
In particular, the decision list is valid forthe homophone problem(Shinnou, 1998).
The de-cision list arranges evidences to identify the wordsense in the order of strength of identifying thesense.
The word sense is judged by the evidence,with the highest identifying strength, in the con-text.Although the homophone problem is equivalentto the word sense disambiguation problem, theformer has a distinct difference from the latter.In the homophone problem, almost all of the an-swers axe given correctly, because almost all of theexpressions written in the given text are correct.It is difficult to decide which is the meaning of'crane', 'crane of animal' or 'crane of tool'.
How-ever, it is almost right that the correct expressionof '~ '  in a text is not '~-~ '  but '~1~' .
Inthe homophone problem, the choice of the writ-ten word results in high precision.
We should usethis information.
However, the method to alwayschoose the written word is useless for error detec-tion because it doesn't detect errors at all.
Themethod used for the homophone problem shouldbe evaluated from the precision and the recall ofthe error detection.
In this paper, we evaluate itby the F-measure to combine the precision andthe recall, and use the written word to raise theF-measure of the original decision list.We use the written word as an evidence of thedecision list.
The problem is how much strengthto give to that evidence.
If the strength is high,the precision rises but the recall drops.
On theother hand, if the strength is low, the decision listis not improved.
In this paper, we calculate thestrength that gives the maximum F-measure in atraining corpus.
As a result, our decision list canraise the F-measure of error detection.2 Homophone d isambiguat ion  by  adec is ion  l i s tIn this section, we describe how to construct thedecision list and to apply it to the homophoneproblem.SFor example, confusion between 'peace' and'piece', or between 'quiet' and 'quite' is the context-sensitive spelling error.2.1 Const ruct ion  of  the  decis ion listThe decision list is constructed by the followingsteps.step 1 Prepare homophone sets.In this paper, we use the 12 homophone setsshown in Table 1, which consist of homophonewords that tend to be mis-chosen.Table 1: Homophone setsPhone Homophone setsa-i-kenka-i-houkyo-u-cho-uji-shi-nka-n-shi-nta-i-ga-i{ ~,  ~?~ }{~,  ~}{ t~-~, ~ }{~,~#}{ ~,~,, r~,c, }{ ~,  ~,~% }u-n-ko-u { ~,  ~T }do-u-shi { NN, N?
}ka-te-i { ~_,  ~..~:?
}ji-kko-u { ~,  ~ }syo-ku-ryo-u { ~,  ~ }syo-u-ga-i { ~=-~, \[~=-~ }step 2 Set context information, i.e.
evidences, toidentify the homophone word.We use the following three kinds of evidence.?
word (w) in front of H: Expressed as w-?
word (w) behind H: Expressed as w+?
f i~tu words 4 surrounding H: We pick upthe nearest hree fir/tu words in front of andbehind H respectively.
We express them asw?3.step 3 Derive the frequency f rq (w i ,e j )  of thecollocation between the homophone word wlin the homophone set {Wl,W~,-.-,wn} andthe evidence j ,  by using a training corpus.For example, let us consider the homophone set{ ~_~1~ (running (of a ship, etc.
)), ~_~7 (running(ofa train, etc.))}
and the following two Japanesesentences.Sentence  1 r~g~)~J~;o~  - b J ~ ' ~ 7 ~ _(A west wind of 3 m/s  did not prevent heplane from flying.
)4The firitu word is defined as an independent wordwhich can form one bun-setu by itself.
Nouns, verbsand adjectives are examples.181Proceedings of EACL '99Table 2: Answers and identifying strength forEvid.~: + (to+)(of-)~T~ ?3 (plane?3)?
.
.~+ (hour+)~.~ ?3 (midnight?3)~K~ ?3 (shorten?3).
, .defaultI Freq.
of Freq.
of,~_~, ,~ ,77 53252 2824 014 110 480 41468 1422evidencesAns.
I IdentifyingStrength~ 0.538~ 0.162~ 5.358~.~t~ 0.345~ 8.910~ 5.358~ 0.046Sentence 2 F-~-~7)~'~~s~:~ '~.-f,= o J(Running hours in the early morning and dur-ing the night were shortened.
)From sentence 1, we can extract he followingevidences for the word '~ ' :and from sentence 2, we can extract he followingevidences for the word '~ ' :"~#r~?
+", "?)
- " ,  "~+~ ?3", "~@ +3","@r~ +Y', "~ +3", "~ +3".step 4 Define the strength est(wi, ej) of estimat-ing that the homophone word wl is correctgiven the evidence j:est(wi, ej ) = log( w, P(Pif:j l),e ~ )2.,k#i ~ kl j\]where P(wi\]ej) is approximately calculatedby:frq(wi, ej ) + aP(wl \[ej) = )-~k frq(wk, ej) + a"a in the above expression is included to avoidthe unsatisfactory case of frq(wl, ej) = O. Inthis paper, we set a : 0.15.
We also use thespecial evidence default, frq(wl, default) isdefined as the frequency of wl.s tep5  Pick the highest strength est(wh,ej)among5As in this paper, the addition of a small value isan easy and effective way to avoid the unsatisfactorycase, as shown in (Yarowsky, 1994).
{est(wl, ), ea(w , e#), ?
?
?, e e#)),and set the word wk as the answer for theevidence ej.
In this case, the identifyingstrength is est(wk, ej).For example, by steps 4 and 5 we can constructthe list shown in Table 2.step 6 Fix the answer wkj for each ej and sortidentifying strengths est(wkj, ej) in order ofdimension, but remove the evidence whoseidentifying strength is less than the identi-fying strength est(wkj,default) for the evi-dence default from the list.
This is the deci-sion list.After step 6, we obtain the decision list for thehomophone set { ~_~, ~.~ } as shown in Table 3.Table 3: Example of decision list~ i d .
~ g t h1 ~lJ~ ?3 (train?3) ~.~ 9.4532 ~ ?3 (ship?3) ~.~l~ 9.1063 ~ ?3 ~.~ 8.910(midnight?3)701 ~r,~- (hour-) ~ .~ 0.358746 ?
)+ (of+) ~.~ 0.162. .
.
.
, .
.
.
.
.
.
.
.
.
.760 default ~_~ 0.0462.2 Solving by a decision l lstIn order to solve the homophone problem by thedecision list, we first find the homophone word win the given text, and then extract evidences E forthe word w from the text:E = {e l ,  e : , .
.
.
,  e, }.182Proceedings of EACL '99Next, picking up the evidence from the deci-sion list for the homophone set for the homophoneword w in order of rank, we check whether the ev-idence is in the set E. If the evidence j is in theset E, the answer wkj for ej is judged to be thecorrect expression for the homophone word w. Ifwkj is equal to w, w is judged to be correct, andif it is not equal, then it is shown that w may bethe error for wkj.3 Use  o f  the  wr i t ten  wordIn this section, we describe the use of the writ-ten word in the homophone problem and how toincorporate it into the decision list.3.1 Evaluat ion of  error detect ion systemsAs described in the Introduction, the written wordcannot be used in the word sense disambiguationproblem, but it is useful for solving homophoneproblems.
The method used for the homophoneproblem is trivial if the method is evaluated bythe precision of distinction using the following for-mula:number o f  correct discr iminat ionsnumber of  all discriminationsThat is, if the expression is '~ \ ]~ '  (or '~.~' ) ,then we should clearly choose the word '~t~'(or the word '~ ' )  from the homophone set {~_~t~, ~_~T }.
This distinction method probablyhas better precision than any other methods forthe word sense disambiguation problem.
However,this method is useless because it does not detecterrors at all.The method for the homophone problem shouldbe evaluated from the standpoint of not error dis-crimination but error detection.
In this paper, weuse the F-measure (Eq.1) to combine the precisionP and the recall R defined as follows:number of  real errors in detected errors P=R= numbernumber of  detected errorsof  real errors in detected errorsnumber of  errors in the tezt2PRF -  P+R (1)3.2 Use o f  the ident i fy ing s t rength  o f  thewr i t ten  wordThe distinction method to choose the writtenword is useless, but it has a very high precisionof error discrimination.
Thus, it is valid to usethis method where it is difficult to use context osolve the homophone problem.The question is when to stop using the deci-sion from context and use the written word.
Inthis paper, we regard the written word as a kindof evidence on context, and give it an identifyingstrength.
Consequently we can use the writtenword in the decision list.3.3 Calcu lat ion o f  the ident i fy ings t rength  o f  the  wr i t ten  wordFirst, let z be the identifying strength of the writ-ten word.
We name the set of evidences withhigher identifying strength than z the set a, andthe set of evidences with lower identifying strengththan z the set f~,Let T be the number of homophone problemsfor a homophone set.
We solve them by the orig-inal decision list DLO.
Let G (or H) be the ratioof the number of homophone problems by judgedby a (or f~ ) to T. Let g (or h) be the precision ofa (or f~), and p be the occurrence probability ofthe homophone rror.The number of problems correctly solved by ais as follows:aT(1  - p), (2)and the number of problems incorrectly solved bya is as follows:GTp.
(3)The number of problems detected as errors in Eq.2and Eq.3 are GT(1 - p)(1 - g) and GTpg respec-tively.
Thus, the number of problems detected aserrors by a is as follows:GT((1 - p)(1 - g) + pg).
(4)In the same way, the number of problems detectedas errors by/~ is as follows:HT((1 - p)(1 - h) + ph).
(5)Consequently the total number of problems de-tected as errors is as follows:T(G((1 -p) (1  -g )  + pg) +H((1  -p) (1  - h )+ph) ) .
(6)The number of correct detections in Eq.6 isTp(Gg + Hh).
Therefore the precision P0 is asfollows:Po = p(Gg + Hh) /{G( (1  - p)(1 - g) + pg)+ H((1 - p)(1 - h) + ph)}Because the number of real errors in T is Tp, therecall R0 is Gg+Hh.
By using P0 and R0, we canget the F-measure F0 of DL0 by Eq.
1.Next, we construct the decision list incorporat-ing the written word into DL0.
We name this deci-sion list DL1.
In DL1, we use the written word tosolve problems which we cannot judge by c\[.
That183Proceedings of EACL '99iEvid.
Ans.
StrengthDLO%Evid.
Ans.
Strengthx+~Evid.
Arts.written f.r itten~.ord ~ .,,rd /DLIStrengthx+ ~XFigure 1: Construction of DL1is, DL1 is the decision list to attach the writtenword as the default evidence to a (see Fig.l).Next, we calculate the precision and the recallof DL1.
Because a of DL1 is the same as that ofDL0, the number of problems detected as errors bya is given by Eq.4.
In the case of DL1, problemsjudged by ~ of DL0 are judged by the writtenword.
Therefore, we detect no error from theseproblems.As a result, the number of problems detected aserrors by DL1 is given by Eq.4, and the number ofreal errors in these detections i TGpg.
Therefore,the precision P1 of DL1 is as follows:p1 = Pg(1 - p ) (1  - g )  + pg"Because the number of whole errors is Tp, therecall R1 of DL1 is Gg.
By using P1 and t/1, wecan get the F-measure F1 of DL1 by Eq.1.Finally, we try to define the identifying strengthz.
z is the value that yields the maximum F~ un-der the condition F1 > F0.
However, theoreticalcalculation alone cannot give z, because p is un-known, and functions of G,H,g, and h are alsounknown.In this paper, we set p = 0.05, and get values ofG, H, g, and h by using the training corpus whichis the resource used to construct he original deci-sion list DL0.
Take the case of the homophone set{ '~ ' ,  '~.~T'}.
For this homophone set, we try toget values of G, H, g, and h. The training corpushas 2,890 sentences which include the word '~.~\]~'or the word '~ .~ ' .
These 2,890 sentences are ho-mophone problems for that homophone set.
Theidentifying strength of DL0 for this homophoneset covers from 0.046 to 9.453 as shown in Table 3.Next we give z a value.
For example, we set z =2.5.
In this case, the number of problems judgedby a is 1,631, and the number of correct judgmentsin them is 1,593.
Thus, G = 1631/2890 = 0.564and g = 1593/1631 = 0.977.
In the same way,under this assumption z -- 2.5, the num-ber of problems judged by j3 is 1,259, andthe number of correct judgments in themis 854.
Thus, H = 1259/2890 = 0.436 andh = 854/1259 = 0.678.
As a result, if z = 2.5,then P0 = 0.225, R0 = 0.847, F0 = 0.356,P1 = 0.688, R1 = 0.551 and F1 = 0.612.
In Fig.2,Fig.3 and Fig.4, we show the experiment resultwhen z varies from 0.0 to 10.0 in units of 0.1.
Bychoosing the maximum value of F1 in Fig.4, wecan get the desired z.
In this homophone set, weobtain z = 3.0.4 Exper imentsFirst, we obtain each identifying strength of thewritten word for the 12 homophone sets shownin Table 1, by the above method.
We show thisresult in Table 4.
LRO in this table means thelowest rank of DL0.
That is, LR0 is the rank ofthe default evidence.
LR1 means the lowest rankof DL1.
That is, LR1 is the rank of the evidence ofthe written word.
Moreover, LR0 and LR1 meanthe sizes of each decision list DL0 and DL1.Second, we extract sentences which include aword in the 12 homophone sets from a corpus.
Wenote that this corpus is different from the trainingcorpus; the corpus is one year's worth of Mainichinewspaper articles, and the training corpus is oneyear's worth of Nikkei newspaper articles.
Theextracted sentences are the test sentences of theexperiment.
We assume that these sentences haveno homophone rrors.Last, we randomly select 5% of the test sen-tences, and forcibly put homophone rrors intothese selected sentences by changing the written184Proceedings of EACL '9910.90.80.70.60.50,40.30.2o?o ~  'DL-I" o'DI.-O" +o~ go~I r I = r I B = B1 2 3 4 S 6 7 It 9Figure 2: Precisions Po and P1Table 4: Identifying strength of the expressionIdentifyinghomophone set strength LR0 LR1of expression{ ~,  ~ } 4.9{ ~,  ~ } 4.6{ ~,  ~j~ } 4.3{ ~,  ~$P} 4.8{ ~,,~,, r~,t:, }{/~- ,  ~t .
}5.73.9{ ~.~,  ~.~T } 3.0{ ~\],:~,, ~\]=\]= } 4.55.1 ,~?
{ ,~+~, ~+~ }4.3{ ~}~, J~}~ } 4.7{ t~-~-=, ~=-~ } 5.11062 8441104 6711120 6671134 6221007 424921 921760 319811 788799 469760 665697 255695 3970,9o.80.70.60.50,40.3o.2o.100.70.60s0.40.30,2010\eoI i I I1 2 3 4%~oooo0oo  ~i i i i iS 6 7 8 9Figure 3: Recalls Ro and Rt'DL ' I '  o'DL'O' +oj -%%%o~I r f I f I I L I1 2 3 4 5 6 7 8 9Figure 4: F-measures Fo and Fthomophone word to another homophone word.As a result, the test sentences include 5% errors.From these test sentences, we detect homophoneerrors by DL0 and DL1 respectively.We conducted this experiment ten times, andgot the mean of the precision, the recall and theF-measure.
The result is shown in Table 5.For all homophone sets, the F-measure of ourproposed DL1 is higher than the F-measure of theoriginal decision list DL0.
Therefore, it is con-cluded that our proposed method is effective.5 RemarksThe recall of DL1 is no more than the recall ofDL0.
Our method aims to raise the F-measureby raising the precision instead of sacrificing therecall.
We confirmed the validity of the method byexperiments in sections 3 and 4.
Thus our methodhas only a little effect if the recall is evaluatedwith importance.
However, we should note thatthe F-measure of DL1 is always not worse thanthe F-measure of DL0.We set the occurrence probability of the homo-phone error at p = 0.05.
However, each homo-phone set has its own p. We need decide p exactlybecause the identifying strength of the writtenword depends on p. However, DL1 will producebetter results than DL0 if p is smaller than 0.05,because the precision of judgment by the writtenword improves without lowering the recall.
Therecall does not fall due to smaller p because It0and R1 are independent of p. Moreover, from thedefinitions of P0 and Pt, we can confirm that theprecision of judgments by the written word im-proves with smaller p.185Proceedings of EACL '99Table 5: Result of experimentshomophone set Number ofproblems{ ~,  t~ } 1,254{ ~,  ~-~ } 1,938{ }{{ r ,c, }{ )4,8453,6822,032618588{ ~,~,~,, ~\]:J= } 1,436{ ~,  ~? }
1,220{ )mean1,5631,0741,636I DLO DL1Po \[ Ro I Fo et \] R1 I Fx0.190 0.824 0.309 0.310 0.774 0.4430.295 0.899 0.443 0.573 0.835 0.6800.583 0.957 0.724 0.616 0.934 0.7420.343 0.911 0.499 0.470 0.725 0.5710.773 0.987 0.867 0.804 0.981 0.8840.708 0.980 0.822 0.806 0.980 0.8850.127 0.745 0.217 0.289 0.420 0.3420.391 0.939 0.552 0.440 0.913 0.5940.789 0.990 0.879 0.903 0.910 0.9060.548 0.966 0.700 0.617 0.911 0.7360.091 0.692 0.161 0.135 0.287 0.1830.681 0.976 0.802 0.760 0.858 0.806II 0.46010-906 I 0-581 II 0.560 10.79410.648 1,824The number of elements of all homophone setsused in this paper was two, but the number ofelements of real homophone sets may be more.However, the bigger this number is, the betterthe result produced by our method, because theprecision of judgments by the default evidence ofDL0 drops in this case, but that of DL1 does not.Therefore, our method is better than the originalone even if the number of elements of the homo-phone set increases.Our method has an advantage that the size ofDL1 is smaller.
The size of the decision list hasno relation to the precision and the recall, but asmall decision list has advantages of efficiency ofcalculation and maintenance.On the other hand, our method has a problem inthat it does not use the written word in the judg-ment from a; Even the identifying strength of theevidence in a must depend on the written word.We intend to study the use of the written wordin the judgment from a.
Moreover, homophoneerrors in our experiments are artifidal.
We mustconfrm the effectiveness of the proposed methodfor actual homophone errors.6 Conc lus ionsIn this paper, we used the decision list to solve thehomophone problem.
This strategy was based onthe fact that the homophone problem is equivalentto the word sense disambiguation problem.
How-ever, the homophone problem is different from theword sense disambiguation problem because theformer can use the written word but the lattercannot.
In this paper, we incorporated the writ-ten word into the original decision list by obtain-ing the identifying strength of the written word.We used 12 homophone sets in experiments.
Inthese experiments, our proposed ecision list hada higher F-measure than the original one.
A fu-ture task is to further integrate context and thewritten word in the decision list.AcknowledgmentsWe used Nikkei Shibun CD-ROM '90 andMainichi Shibun CD-ROM '94 as the corpus.
TheNihon Keizai Shinbun company and the MainichiShinbun company gave us permission of their col-lections.
We appreciate the assistance granted byboth companies.Re ferencesAtsushi Fujii.
1998.
Corpus-Based WordSence Disambiguation (in Japanese).
Journalof Japanese Society for Artificial Intelligence,13(6):904-911.Andrew R. Golding and Yves Schabes.
1996.Combining Trigram-based and Feature-basedMethods for Context-Sensitive Spelling Correc-tion.
In 3~th Annual Meeting of the Associationfor Computational Linguistics, pages 71-78.Andrew R. Golding.
1995.
A Bayesian HybridMethod for Context-Sensitive Spelling Correc-tion.
In Third Workshop on Very Large Corpora(WVLC-95), pages 39-53.Jun Ibuki, Guowei Xu, Takahiro Saitoh, and Ku-nio Matsui.
1997.
A new approach for JapaneseSpelling Correction (in Japanese).
SIG NotesNL-117-21, IPSJ.186Proceedings of EACL '99Masahiro Oku and Koji Matsuoka.
1997.
AMethod for Detecting Japanese HomophoneErrors in Compound Nouns based on Char-acter Cooccurrence and Its Evaluation (inJapanese).
Journal of Natural Language Pro-cessing, 4(3):83-99.Masahiro Oku.
1994.
Handling Japanese Homo-phone Errors in Revision Support System; RE-VISE.
In 4th Conference on Applied NaturalLanguage Processing (ANLP-9$), pages 156-161.Hiroyuki Shinnou.
1998.
Japanese HomohoneDisambiguation Using a Decision List GivenAdded Weight to Evidences on Compounds (inJapanese).
Journal of Information Processing,39(12):3200-3206.Koji Tochinai, Taisuke Itoh, and Yasuhiro Suzuki.1986.
Kana-Kanji Translation System with Au-tomatic Homonym Selection Using CharacterChain Matching (in Japanese).
Journal of In-formation Processing, 27(3):313-321.Sakiko Wakita and Hiroshi Kaneko.
1996.
Ex-traction of Keywords for "Homonym ErrorChecker" (in Japanese).
SIG Notes NL-111-5,IPSJ.David Yarowsky.
1994.
Decision Lists for Lex-ical Ambiguity Resolution: Application to Ac-cent Restoration i Spanish and French.
In 32thAnnual Meeting of the Association for Compu-tational Linguistics, pages 88-95.David Yarowsky.
1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.In 33th Annual Meeting of the Association forComputational Linguistics, pages 189-196.187
