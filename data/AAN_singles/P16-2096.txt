Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 591?598,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsThe Social Impact of Natural Language ProcessingDirk HovyCenter for Language TechnologyUniversity of CopenhagenCopenhagen, Denmarkdirk.hovy@hum.ku.dkShannon L. SpruitEthics & Philosophy of TechnologyDelft University of TechnologyDelft, The Netherlandss.l.spruit@tudelft.nlAbstractMedical sciences have long since estab-lished an ethics code for experiments, tominimize the risk of harm to subjects.
Nat-ural language processing (NLP) used toinvolve mostly anonymous corpora, withthe goal of enriching linguistic analysis,and was therefore unlikely to raise ethi-cal concerns.
As NLP becomes increas-ingly wide-spread and uses more datafrom social media, however, the situationhas changed: the outcome of NLP experi-ments and applications can now have a di-rect effect on individual users?
lives.
Untilnow, the discourse on this topic in the fieldhas not followed the technological devel-opment, while public discourse was oftenfocused on exaggerated dangers.
This po-sition paper tries to take back the initiativeand start a discussion.
We identify a num-ber of social implications of NLP and dis-cuss their ethical significance, as well asways to address them.1 IntroductionAfter the Nuremberg trials revealed the atrocitiesconducted in medical research by the Nazis, medi-cal sciences established a set of rules to determinewhether an experiment is ethical.
This involvedincorporating the principles of biomedical ethicsas a lingua franca of medical ethics (Beauchampand Childress, 2001).These guidelines were designed to balance thepotential value of conducting an experiment whilepreventing the exploitation of human subjects.Today, any responsible research institution usesthese?or comparable?criteria to approve or re-ject experiments before any research can be con-ducted.
The administrative body governing thesedecisions is the Institutional Review Board (IRB).IRBs mostly pertain to experiments that directlyinvolve human subjects, though, and so NLP andother data sciences have not employed such guide-lines.
Work on existing corpora is unlikely to raiseany flags that would require an IRB approval.1Data sciences have therefore traditionally beenless engaged in ethical debates of their subject,even though this seems to be shifting, see forinstance Wallach (2014), Galaz et al (2015),or O?Neil (2016).
The public outcry over the?emotional contagion?
experiment on Facebook(Kramer et al, 2014) further suggests that data sci-ences now affect human subjects in real time, andthat we might have to reconsider the application ofethical considerations to our research (Puschmannand Bozdag, 2014).
NLP research not only in-volves similar data sets, but also works with theircontent, so it is time to start a discussion of theethical issues specific to our field.Much of the ethical discussion in data sciencesto date, however, has centered around privacy con-cerns (Tse et al, 2015).
We do not deny the realityand importance of those concerns, but they involveaspects of digital rights management/access con-trol, policy making, and security, which are notspecific to NLP, but need to be addressed in thedata sciences community as a whole.
Steps to-wards this have been taken by Russell et al (2015).Instead, we want to move beyond privacy inour ethical analysis and look at the wider socialimpact NLP may have.
In particular, we wantto explore the impact of NLP on social justice,i.e., equal opportunities for individuals and groups(such as minorities) within society to access re-sources, get their voice heard, and be representedin society.1With few exceptions, such as dialogue research (JoelTetreault, pers.
comm.
)591Our contributions We believe ethical discus-sions are more constructive if led by practition-ers, since the public discussion of ethical aspectsof IT and data sciences is often loaded with fearof the unknown and unrealistic expectations.
Forexample, in the public discourse about AI (Hsu,2012; Eadicicco, 2015; Khatchadourian, 2015),people either dismiss the entire approach, or ex-aggerate the potential dangers (see Etzioni (2014)for a practioner?s view point).
This paper is an at-tempt to take back the initiative for NLP.At the same time, we believe that the field ofethics can contribute a more general framework,and so this paper is an interdisciplinary collabora-tion between NLP and ethics researchers.To facilitate the discussion, we also providesome of the relevant terminology from the liter-ature on ethics of technology, namely the conceptsof exclusion, overgeneralization, bias confirma-tion, topic under- and overexposure, and dual use.2 Does NLP need an ethics discussion?As discussed above, the makeup of most NLP ex-periments so far has not obviated a need for ethi-cal considerations, and so, while we are aware ofindividual discussions (Strube, 2015), there is lit-tle discourse in the community yet.
A search for?ethic*?
in the ACL anthology only yields threeresults.
One of the papers (McEnery, 2002) turnsout to be a panel discussion, another is a book re-view, leaving only Couillault et al (2014), whodevote most of the discussion to legal and qualityissues of data sets.
We know social implicationshave been addressed in some NLP curricula,2butuntil now, no discipline-wide discussion seems totake place.The most likely reason is that NLP researchhas not directly involved human subjects.3His-torically, most NLP applications focused on fur-ther enriching existing text which was not stronglylinked to any particular author (newswire), wasusually published publicly, and often with sometemporal distance (novels).
All these factors cre-ated a distance between text and author, which pre-vented the research from directly affecting the au-thors?
situation.2H?ector Mart?
?nez Alonso, personal communication3Except for annotation: there are a number of papers onthe status of crowdsource workers (Fort et al, 2011; Pavlicket al, 2014).Couillault et al (2014) also briefly discuss anno-tators, but mainly in the context of quality control.This situation has changed lately due to the in-creased use of social media data, where authors arecurrent individuals, who can be directly affectedby the results of NLP applications.
Couillault et al(2014) touch upon these issues under ?traceabil-ity?
(i.e., whether individuals can be identified):this is undesirable for experimental subjects, butmight be useful in the case of annotators.Most importantly, though: the subject of NLP?language?is a proxy for human behavior, and astrong signal of individual characteristics.
Peo-ple use this signal consciously, to portray them-selves in a certain way, but can also be identified asmembers of specific groups by their use of subcon-scious traits (Silverstein, 2003; Agha, 2005; Jo-hannsen et al, 2015; Hovy and Johannsen, 2016).Language is always situated (Bamman et al,2014), i.e., it is uttered in a specific situation ata particular place and time, and by an individualspeaker with all the characteristics outlined above.All of these factors can therefore leave an imprinton the utterance, i.e., the texts we use in NLP carrylatent information about the author and situation,albeit to varying degrees.This information can be used to predict authorcharacteristics from text (Rosenthal and McKe-own, 2011; Nguyen et al, 2011; Alowibdi et al,2013; Ciot et al, 2013; Liu and Ruths, 2013;Volkova et al, 2014; Volkova et al, 2015; Plankand Hovy, 2015; Preotiuc-Pietro et al, 2015a;Preot?iuc-Pietro et al, 2015b), and the character-istics in turn can be detected by and influence theperformance of our models (Mandel et al, 2012;Volkova et al, 2013; Hovy, 2015).As more and more language-based technologiesare becoming available, the ethical implications ofNLP research become more important.
What re-search is carried out, and its quality, directly affectthe functionality and impact of those technologies.The following is meant to start a discussion ad-dressing ethical issues that can emerge in (andfrom) NLP research.3 The social impact of NLP researchWe have outlined the relation between languageand individual traits above.
Language is also apolitical instrument, though, and an instrumentof power.
This influence stretches into politicsand everyday competition, for example for turn-taking (Laskowski, 2010; Bracewell and Tomlin-son, 2012; Prabhakaran and Rambow, 2013; Prab-592hakaran et al, 2014; Tsur et al, 2015; Khouzamiet al, 2015, inter alia), .The mutual relationships between language, so-ciety, and the individual are also the source forthe societal impact factors of NLP: failing to rec-ognize group membership (Section 3.1), implyingthe wrong group membership (see Section 3.2),and overexposure (Section 3.3).
In the following,we discuss sources of these problems in the data,modeling, and research design, and suggest possi-ble solutions to address them.3.1 ExclusionAs a result of the situatedness of language, anydata set carries a demographic bias, i.e., latentinformation about the demographics in it.
Over-fitting to these factors can have have severe ef-fects on the applicability of findings.
In psychol-ogy, where most studies are based on western,educated, industrialized, rich, and democratic re-search participants (so-called WEIRD, Henrich etal.
(2010)), the tacit assumption that human natureis so universal that findings on this group wouldtranslate to other demographics has led to a heav-ily biased corpus of psychological data.
In NLP,overfitting to the demographic bias in the trainingdata is due to the i.i.d.
assumption.
I.e., modelsimplicitly assume all language to be identical tothe training sample.
They therefore perform worseor even fail on data from other demographics.Potential consequences are exclusion or demo-graphic misrepresentation.
This in itself alreadyrepresents an ethical problem for research pur-poses, threatening the universality and objectiv-ity of scientific knowledge (Merton, 1973).
Theseproblems exacerbate, though, once they are ap-plied to products.
For instance, standard languagetechnology may be easier to use for white malesfrom California (as these are taken into accountwhile developing it) rather than women or citi-zens of Latino or Arabic descent.
This will re-inforce already existing demographic differences,and makes technology less user friendly for suchgroups, cf.
authors like Bourdieu and Passeron(1990) have shown how restricted language, likeclass specific language or scientific jargon, canhinder the expression of outsiders?
voices fromcertain practices.
A lack of awareness or de-creased attention for demographic differences inresearch stages can therefore lead to issues of ex-clusion of people along the way.Concretely, the consequences of exclusion forNLP research have recently been pointed out byHovy and S?gaard (2015) and J?rgensen et al(2015): current state-of-the-art NLP models scorea significantly lower accuracy for young peopleand ethnic minorities vis-`a-vis the modeled demo-graphics.Better awareness of these mechanism in NLPresearch and development can help prevent prob-lems further on.
Potential counter-measures to de-mographic bias can be as simple as downsamplingthe over-represented group in the training data toeven out the distribution.
The work by Moham-mady and Culotta (2014) shows another approach,by using existing demographic statistics as super-vision.
In general, measures to address overfittingor imbalanced data can be used to correct for de-mographic bias in data.3.2 OvergeneralizationExclusion is a side-effect of the data.
Overgener-alization is a modeling side-effect.As an example, we consider automatic infer-ence of user attributes, a common and interest-ing NLP task, whose solution also holds promisefor many useful applications, such as recommen-dation engines and fraud or deception detection(Badaskar et al, 2008; Fornaciari and Poesio,2014; Ott et al, 2011; Banerjee et al, 2014).The cost of false positives seems low: we mightbe puzzled or amused when receiving an email ad-dressing us with the wrong gender, or congratulat-ing us to our retirement on our 30th birthday.In practice, though, relying on models that pro-duce false positives may lead to bias confirmationand overgeneralization.
Would we accept the sameerror rates if the system was used to predict sexualorientation or religious views, rather than age orgender?
Given the right training data, this is just amatter of changing the target variable.To address overgeneralization, the guidingquestion should be ?would a false answer be worsethan no answer??
We can use dummy variables,rather than take a tertium non datur approach toclassification, and employ measures such as er-ror weighting and model regularization, as well asconfidence thresholds.3.3 The problem of exposureTopic overexposure creates biases Both exclu-sion and overgeneralization can be addressed algo-5932000-0102-03 04-05 06-07 08-09 10-11 12-13 14-15year020406080100120140160180grammarneuralFigure 1: ACL title keywords over timerithmically, while topic overexposure originatesfrom research design.In research, we can observe this effect in wavesof research topics that receive increased main-stream attention, often to fall out of fashion orbecome more specialized, cf.
ACL papers with?grammars?
vs. ?neural?
in the title (Figure 1).Such topic overexposure may lead to a psycho-logical effect called availability heuristic (Tver-sky and Kahneman, 1973): if people can recalla certain event, or have knowledge about specificthings, they infer it must be more important.
Forinstance, people estimate the size of cities theyrecognize to be larger than that of unknown cities(Goldstein and Gigerenzer, 2002).However, the same holds for individu-als/groups/characteristics we research.
Theheuristics become ethically charged when char-acteristics such as violence or negative emotionsare more strongly associated with certain groupsor ethnicities (Slovic et al, 2007).
If researchrepeatedly found that the language of a certaindemographic group was harder to process, it couldcreate a situation where this group was perceivedto be difficult, or abnormal, especially in thepresence of existing biases.
The confirmation ofbiases through the gendered use of language, forexample, has also been at the core of second andthird wave feminism (Mills, 2012).Overexposure thus creates biases which canlead to discrimination.
To some extent, the fran-tic public discussion on the dangers of AI can beseen as a result of overexposure (Sunstein, 2004).There are no easy solutions to this problem,which might only become apparent in hindsight.It can help to assess whether the research directionof a project feeds into existing biases, or whetherit overexposes certain groups.Underexposure can negatively impact evalua-tion.
Similar to the WEIRD-situation in psy-chology, NLP tends to focus on Indo-Europeandata/text sources, rather than small languages fromother language groups, for example in Asia orAfrica.
This focus creates an imbalance in theavailable amounts of labeled data.
Most of theexisitng labeled data covers only a small set oflanguages.
When analyzing a random sample ofTwitter data from 2013, we found that there wereno treebanks for 11 of the 31 most frequent lan-guages, and even fewer semantically annotatedresources (the ACE corpus covers only English,Arabic, Chinese, and Spanish).4Even if there is a potential wealth of dataavailable from other languages, most NLP toolsare geared towards English (Schnoebelen, 2013;Munro, 2013).
The prevalence of resources forEnglish has created an underexposure to typolog-ical variety: both morphology and syntax of En-glish are global outliers.
Would we have focusedon n-gram models to the same extent if Englishwas as morhpologically complex as, say, Finnish?While there are many approaches to developmulti-lingual and cross-lingual NLP tools for lin-guistic outliers (Yarowsky and Ngai, 2001; Dasand Petrov, 2011; S?gaard, 2011; S?gaard etal., 2015; Agi?c et al, 2015), there simply aremore commercial incentives to overexpose En-glish, rather than other languages.
Even if otherlanguages are equally (or more) interesting from alinguistic and cultural point of view, English is oneof the most widely spoken language and thereforeopens up the biggest market for NLP tools.
Thisfocus on English may be self-reinforcing: the ex-istence of off-the-shelf tools for English makes iteasy to try new ideas, while to start exploring otherlanguages requires a higher startup cost in terms ofbasic models, so researchers are less likely to workon them.4 Dual-use problemsEven if we address all of the above concerns anddo not intend any harm in our experiments, theycan still have unintended consequences that nega-tively affect people?s lives (Jonas, 1984).Advanced analysis techniques can vastlyimprove search and educational applications4Thanks to Barbara Plank for the analysis!594(Tetreault et al, 2015), but can re-enforce pre-scriptive linguistic norms when degrading onnon-standard language.
Stylometric analysiscan shed light on the provenance of historictexts (Mosteller and Wallace, 1963), but alsoendanger the anonymity of political dissenters.Text classification approaches help decode slangand hidden messages (Huang et al, 2013), buthave the potential to be used for censorship.
Atthe same time, NLP can also help uncovering suchrestrictions (Bamman et al, 2012).
As recentlyshown by Hovy (2016), NLP techniques can beused to detect fake reviews, but also to generatethem in the first place.All these examples indicate that we should be-come more aware of the way other people ap-propriate NLP technology for their own purposes.The unprecedented scale and availability can makethe consequences of NLP technologies hard togauge.The unintended consequences of research arealso linked to the incentives associated with fund-ing sources.
The topic of government and mili-tary involvement in the field deserves special at-tention in this respect.
On the one hand, Andersonet al (2012) show how a series of DARPA-fundedworkshops have been formative for ACL as a fieldin the 1990s.
On the other hand, there are schol-ars who refuse military-related funding for moralreasons.5While this decision is up to the individual re-searcher, the examples show that moral consider-ations go beyond the immediate research projects.We may not directly be held responsible for theunintended consequences of our research, but wecan acknowledge the ways in which NLP canenable morally questionable/sensitive practices,raise awareness, and lead the discourse on it in aninformed manner.
The role of the researcher insuch ethical discussions has recently been pointedout by Rogaway (2015).5 ConclusionIn this position paper, we outlined the potential so-cial impact of NLP, and discussed ways for thepractitioner to address this.
We also introducedexclusion, overgeneralization, bias confirmation,topic overexposure, and dual use.
Countermea-sures for exclusion include bias control techniques5For a perspective in a related field see https://web.eecs.umich.edu/?kuipers/opinions/no-military-funding.htmllike downsampling or priors; for overgeneraliza-tion: dummy labels, error weighting, or confi-dence thresholds.
Exposure problems can only beaddressed by careful research design, and dual-useproblems seem hardly addressable on the level ofthe individual researcher, but require the concertedeffort of our community.We hope this paper can point out ethical consid-erations for collecting our data, designing the ex-perimental setup, and assessing the potential ap-plication of our systems, and help start an opendiscussion in the field about the limitations andproblems of our methodology.AcknowledgementsThe authors would like to thank Joel Tetrault,Rachel Tatman, Joel C. Wallenberg, the membersof the COASTAL group, and the anonymous re-viewers for their detailed and invaluable feedback.The first author was funded under the ERC Start-ing Grant LOWLANDS No.
313695.
The secondauthor was funded by the Netherlands Organiza-tion for Scientific Research under grant number016.114.625.ReferencesAsif Agha.
2005.
Voice, footing, enregisterment.Journal of linguistic anthropology, pages 38?59.
?Zeljko Agi?c, Dirk Hovy, and Anders S?gaard.
2015.If all you have is a bit of the Bible: Learning POStaggers for truly low-resource languages.
In Pro-ceedings of the 53rd annual meeting of the ACL.Jalal S Alowibdi, Ugo A Buy, and Philip Yu.
2013.Empirical evaluation of profile characteristics forgender classification on twitter.
In Machine Learn-ing and Applications (ICMLA), 2013 12th Interna-tional Conference on, volume 1, pages 365?369.IEEE.Ashton Anderson, Dan McFarland, and Dan Jurafsky.2012.
Towards a computational history of the ACL:1980-2008.
In Proceedings of the ACL-2012 Spe-cial Workshop on Rediscovering 50 Years of Discov-eries, pages 13?21.
Association for ComputationalLinguistics.Sameer Badaskar, Sachin Agarwal, and Shilpa Arora.2008.
Identifying real or fake articles: Towardsbetter language modeling.
In Proceedings of theThird International Joint Conference on NaturalLanguage Processing: Volume-II.David Bamman, Brendan O?Connor, and Noah Smith.2012.
Censorship and deletion practices in Chinesesocial media.
First Monday, 17(3).595David Bamman, Chris Dyer, and Noah A. Smith.
2014.Distributed representations of geographically situ-ated language.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Lin-guistics, pages 828?834.
Proceedings of ACL.Ritwik Banerjee, Song Feng, Seok Jun Kang, and YejinChoi.
2014.
Keystroke patterns as prosody in digitalwritings: A case study with deceptive reviews andessays.
In Proceedings of the 2014 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 1469?1473.
Association for Com-putational Linguistics.Tom L Beauchamp and James F Childress.
2001.Principles of biomedical ethics.
Oxford UniversityPress, USA.Pierre Bourdieu and Jean-Claude Passeron.
1990.
Re-production in education, society and culture, vol-ume 4.
Sage.David Bracewell and Marc Tomlinson.
2012.
The lan-guage of power and its cultural influence.
In Pro-ceedings of COLING 2012: Posters, pages 155?164.The COLING 2012 Organizing Committee.Morgane Ciot, Morgan Sonderegger, and Derek Ruths.2013.
Gender Inference of Twitter Users in Non-English Contexts.
In Proceedings of the 2013 Con-ference on Empirical Methods in Natural LanguageProcessing, Seattle, Wash, pages 18?21.Alain Couillault, Kar?en Fort, Gilles Adda, and HuguesMazancourt (de).
2014.
Evaluating corpora docu-mentation with regards to the Ethics and Big DataCharter.
In Proceedings of the Ninth InternationalConference on Language Resources and Evaluation(LREC-2014).
European Language Resources Asso-ciation (ELRA).Dipanjan Das and Slav Petrov.
2011.
Unsupervisedpart-of-speech tagging with bilingual graph-basedprojections.
In Proceedings of the 49th annual meet-ing of the ACL.Lisa Eadicicco.
2015.
Bill Gates: Elon Musk Is Right,We Should All Be Scared Of Artificial IntelligenceWiping Out Humanity.
Business Insider, January 28.http://www.businessinsider.com/bill-gates-artificial-intelligence-2015-1Retrieved Feb 24, 2016.Oren Etzioni.
2014.
Its Time to Intelligently DiscussArtificial Intelligence.
Backchannel, December 9https://backchannel.com/ai-wont-exterminate-us-it-will-empower-us-5b7224735bf3#.eia6vtimy Retrieved Feb24, 2016.Tommaso Fornaciari and Massimo Poesio.
2014.Identifying fake amazon reviews as learning fromcrowds.
In Proceedings of the 14th Conference ofthe European Chapter of the Association for Com-putational Linguistics, pages 279?287.
Associationfor Computational Linguistics.Kar?en Fort, Gilles Adda, and K Bretonnel Cohen.2011.
Amazon mechanical turk: Gold mine or coalmine?
Computational Linguistics, 37(2):413?420.Victor Galaz, Fredrik Moberg, and FernandaTorre.
2015.
The Biosphere Code Manifesto.http://thebiospherecode.com/index.php/manifesto Retrieved Feb 24, 2016.Daniel G Goldstein and Gerd Gigerenzer.
2002.
Mod-els of ecological rationality: the recognition heuris-tic.
Psychological review, 109(1):75.Joseph Henrich, Steven J Heine, and Ara Norenzayan.2010.
The weirdest people in the world?
Behav-ioral and brain sciences, 33(2-3):61?83.Dirk Hovy and Anders Johannsen.
2016.
ExploringLanguage Variation Across Europe - A Web-basedTool for Computational Sociolinguistics.
In Pro-ceedings of LREC.Dirk Hovy and Anders S?gaard.
2015.
Tagging perfor-mance correlates with author age.
In Proceedingsof the 53rd Annual Meeting of the Association forComputational Linguistics.Dirk Hovy.
2015.
Demographic factors improve clas-sification performance.
In Proceedings of the 53rdAnnual Meeting of the Association for Computa-tional Linguistics.Dirk Hovy.
2016.
The Enemy in Your Own Camp:How Well Can We Detect Statistically-GeneratedFake Reviews?An Adversarial Study.
In Proceed-ings of the 54th Annual Meeting of the Associa-tion for Computational Linguistics.
Association forComputational Linguistics.Jeremy Hsu.
2012.
Control dangerous AI before itcontrols us, one expert says.
NBC News, March 1.http://www.nbcnews.com/id/46590591/ns/technology and science-innovationRetrieved Feb 24, 2016.Hongzhao Huang, Zhen Wen, Dian Yu, Heng Ji,Yizhou Sun, Jiawei Han, and He Li.
2013.
Re-solving entity morphs in censored data.
In Proceed-ings of the 51st Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Pa-pers), pages 1083?1093.
Association for Computa-tional Linguistics.Anders Johannsen, Dirk Hovy, and Anders S?gaard.2015.
Cross-lingual syntactic variation over age andgender.
In Proceedings of CoNLL.Hans Jonas.
1984.
The Imperative of Responsibil-ity: Foundations of an Ethics for the TechnologicalAge.
Original in German: Prinzip Verantwortung.
)Chicago: University of Chicago Press.Anna J?rgensen, Dirk Hovy, and Anders S?gaard.2015.
Challenges of studying and processing di-alects in social media.
In Workshop on Noisy User-generated Text (W-NUT).596Raffi Khatchadourian.
2015.
The Dooms-day Invention: Will artificial intelligencebring us utopia or destruction?
TheNew Yorker (magazine), November 23.http://www.newyorker.com/magazine/2015/11/23/doomsday-invention-artificial-intelligence-nick-bostromRetrieved Feb 24, 2016.Hatim Khouzami, Romain Laroche, and FabriceLefevre, 2015.
Proceedings of the 16th AnnualMeeting of the Special Interest Group on Dis-course and Dialogue, chapter Optimising Turn-Taking Strategies With Reinforcement Learning,pages 315?324.
Association for Computational Lin-guistics.Adam DI Kramer, Jamie E Guillory, and Jeffrey T Han-cock.
2014.
Experimental evidence of massive-scale emotional contagion through social networks.Proceedings of the National Academy of Sciences,111(24):8788?8790.Kornel Laskowski.
2010.
Modeling norms of turn-taking in multi-party conversation.
In Proceedingsof the 48th Annual Meeting of the Association forComputational Linguistics, pages 999?1008.
Asso-ciation for Computational Linguistics.Wendy Liu and Derek Ruths.
2013.
What?s in a name?using first names as features for gender inference intwitter.
In Analyzing Microtext: 2013 AAAI SpringSymposium.Benjamin Mandel, Aron Culotta, John Boulahanis,Danielle Stark, Bonnie Lewis, and Jeremy Ro-drigue, 2012.
Proceedings of the Second Workshopon Language in Social Media, chapter A Demo-graphic Analysis of Online Sentiment during Hur-ricane Irene, pages 27?36.
Association for Compu-tational Linguistics.Tony McEnery.
2002.
Ethical and legal issues incorpus construction.
In Proceedings of the ThirdInternational Conference on Language Resourcesand Evaluation (LREC?02).
European Language Re-sources Association (ELRA).Robert K Merton.
1973.
The normative structure ofscience.
The sociology of science: Theoretical andempirical investigations, 267.Sara Mills.
2012.
Gender matters: Feminist linguisticanalysis.
Equinox Pub.Ehsan Mohammady and Aron Culotta, 2014.
Proceed-ings of the Joint Workshop on Social Dynamics andPersonal Attributes in Social Media, chapter UsingCounty Demographics to Infer Attributes of TwitterUsers, pages 7?16.
Association for ComputationalLinguistics.Frederick Mosteller and David L Wallace.
1963.
In-ference in an authorship problem: A comparativestudy of discrimination methods applied to the au-thorship of the disputed federalist papers.
Journal ofthe American Statistical Association, 58(302):275?309.Robert Munro.
2013.
NLP for alllanguages.
Idibon Blog, May 22http://idibon.com/nlp-for-all Re-trieved May 17, 2016.Dong Nguyen, Noah A Smith, and Carolyn P Ros?e.2011.
Author age prediction from text using lin-ear regression.
In Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cul-tural Heritage, Social Sciences, and Humanities,pages 115?123.
Association for Computational Lin-guistics.Cathy O?Neil.
2016.
The Ethi-cal Data Scientist.
Slate, February 4http://www.slate.com/articles/technology/future tense/2016/02/how to bring better ethics to datascience.html Retrieved Feb 24, 2016.Myle Ott, Yejin Choi, Claire Cardie, and T. JeffreyHancock.
2011.
Finding deceptive opinion spamby any stretch of the imagination.
In Proceedings ofthe 49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 309?319.
Association for ComputationalLinguistics.Ellie Pavlick, Matt Post, Ann Irvine, Dmitry Kachaev,and Chris Callison-Burch.
2014.
The language de-mographics of amazon mechanical turk.
Transac-tions of the Association of Computational Linguis-tics ?
Volume 2, Issue 1, pages 79?92.Barbara Plank and Dirk Hovy.
2015.
Personalitytraits on twitterorhow to get 1,500 personality testsin a week.
In Proceedings of the 6th Workshopon Computational Approaches to Subjectivity, Sen-timent and Social Media Analysis, pages 92?98.Vinodkumar Prabhakaran and Owen Rambow.
2013.Written dialog and social power: Manifestations ofdifferent types of power in dialog behavior.
In Pro-ceedings of the Sixth International Joint Conferenceon Natural Language Processing, pages 216?224.Asian Federation of Natural Language Processing.Vinodkumar Prabhakaran, Ashima Arora, and OwenRambow.
2014.
Staying on topic: An indicatorof power in political debates.
In Proceedings of the2014 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 1481?1486.Association for Computational Linguistics.Daniel Preotiuc-Pietro, Vasileios Lampos, and Niko-laos Aletras.
2015a.
An analysis of the user oc-cupational class through twitter content.
In ACL.Daniel Preot?iuc-Pietro, Svitlana Volkova, VasileiosLampos, Yoram Bachrach, and Nikolaos Aletras.2015b.
Studying user income through language,behaviour and affect in social media.
PloS one,10(9):e0138717.597Cornelius Puschmann and Engin Bozdag.
2014.
Stak-ing out the unclear ethical terrain of online socialexperiments.
Internet Policy Review, 3(4).Phillip Rogaway.
2015.
The moral character of cryp-tographic work.
Technical report, IACR-CryptologyePrint Archive.Sara Rosenthal and Kathleen McKeown.
2011.
Ageprediction in blogs: A study of style, content, andonline behavior in pre-and post-social media genera-tions.
In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics: Hu-man Language Technologies-Volume 1, pages 763?772.
Association for Computational Linguistics.Stuart Russell, Daniel Dewey, Max Tegmark, JanosKramar, and Richard Mallah.
2015.
Research prior-ities for robust and beneficial artificial intelligence.Technical report, Future of Life Institute.Tyler Schnoebelen.
2013.
The weird-est languages.
Idibon Blog, June 21http://idibon.com/the-weirdest-languages Retrieved May 17, 2016.Michael Silverstein.
2003.
Indexical order and the di-alectics of sociolinguistic life.
Language & Com-munication, 23(3):193?229.Paul Slovic, Melissa L. Finucane, Ellen Peters, andDonald G. MacGregor.
2007.
The affect heuris-tic.
European Journal of Operational Research,177(3):1333 ?
1352.Anders S?gaard,?Zeljko Agi?c, H?ector Mart?
?nez Alonso,Barbara Plank, Bernd Bohnet, and Anders Jo-hannsen.
2015.
Inverted indexing for cross-lingualnlp.
In Proceedings of the 53rd annual meeting ofthe ACL.Anders S?gaard.
2011.
Data point selection for cross-language adaptation of dependency parsers.
In Pro-ceedings of ACL.Michael Strube.
2015.
It is never as simple as it seems:The wide-ranging impacts of ethics violations.
Eth-ical Challenges in the Behavioral and Brain Sci-ences, page 126.Cass R Sunstein.
2004.
Precautions against what?
theavailability heuristic and cross-cultural risk percep-tions.
U Chicago Law & Economics, Olin WorkingPaper, (220):04?22.Joel Tetreault, Jill Burstein, and Claudia Leacock,2015.
Proceedings of the Tenth Workshop on Inno-vative Use of NLP for Building Educational Appli-cations, chapter Proceedings of the Tenth Workshopon Innovative Use of NLP for Building EducationalApplications.
Association for Computational Lin-guistics.Jonathan Tse, Dawn E Schrader, Dipayan Ghosh, TonyLiao, and David Lundie.
2015.
A bibliomet-ric analysis of privacy and ethics in ieee securityand privacy.
Ethics and Information Technology,17(2):153?163.Oren Tsur, Dan Calacci, and David Lazer.
2015.
Aframe of mind: Using statistical models for detectionof framing and agenda setting campaigns.
In Pro-ceedings of the 53rd Annual Meeting of the Associ-ation for Computational Linguistics and the 7th In-ternational Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers), pages 1629?1638.
Association for Computational Linguistics.Amos Tversky and Daniel Kahneman.
1973.
Avail-ability: A heuristic for judging frequency and prob-ability.
Cognitive psychology, 5(2):207?232.Svitlana Volkova, Theresa Wilson, and DavidYarowsky.
2013.
Exploring demographic languagevariations to improve multilingual sentiment anal-ysis in social media.
In Proceedings of EMNLP,pages 1815?1827.Svitlana Volkova, Glen Coppersmith, and BenjaminVan Durme.
2014.
Inferring user political prefer-ences from streaming communications.
In Proceed-ings of the 52nd annual meeting of the ACL, pages186?196.Svitlana Volkova, Yoram Bachrach, Michael Arm-strong, and Vijay Sharma.
2015.
Inferring latentuser properties from texts published in social media(demo).
In Proceedings of the Twenty-Ninth Confer-ence on Artificial Intelligence (AAAI), Austin, TX,January.Hanna Wallach.
2014.
Big Data, MachineLearning, and the Social Sciences: Fair-ness, Accountability, and Transparency.https://medium.com/@hannawallach/big-data-machine-learning-and-the-social-sciences-927a8e20460d#.uhbcr4wa0 Retrieved Feb 24, 2016.David Yarowsky and Grace Ngai.
2001.
Inducing mul-tilingual POS taggers and NP bracketers via robustprojection across aligned corpora.
In Proceedings ofNAACL.598
