The NICE Fairy-tale Game System1Joakim Gustafson, Linda Bell, Johan Boye, Anders Lindstr?m and Mats Wir?nTeliaSonera AB, 12386 Farsta, Swedenfirstname.lastname@teliasonera.com1 The work described in this paper was supported by the EU/HLT funded project NICE (IST-2001-35293), www.niceproject.comAbstractThis paper presents the NICE fairy-tale gamesystem, in which adults and children caninteract with various animated characters in a3D world.
Computer games is an interestingapplication for spoken and multimodaldialogue systems.
Moreover, for thedevelopment of future computer games,multimodal dialogue has the potential togreatly enrichen the user?s experience.
In thispaper, we also present some requirements thathave to be fulfilled to successfully integratespoken dialogue technology with  a computergame application.1 IntroductionThe goal of the NICE project is to allow users of allages to interact with lifelike conversational charactersin a fairy-tale world inspired by the Danish authorH C Andersen.
To make these characters convincingin a computer game scenario, they have to possessconversational skills as well as the ability to performphysical actions in an interactive 3D world.What primarily distinguishes the NICE fairy-talegame system from other spoken dialogue systems isthat the human-computer dialogue takes place withinthe context of an interactive computer game.However, spoken and multimodal dialogue is notsupposed to be just an ?add-on?
to the game, but theuser?s primary means of progression through thestory.
The rationale for this is the great potential formore natural interaction we see in making methodsfrom multimodal dialogue systems available incontrolling gameplay.
Potentially, spoken andmultimodal interaction will make it possible to createa more engaging and immersive experience, or evenfacilitate the development of new kinds of computergames.Secondly, what makes NICE differ from typicalspoken dialogue systems is the attempt to move awayfrom strictly task-oriented dialogue.
Instead, theinteraction with the characters is domain-oriented.This means that the dialogue concerns differentsubplots in the fairy-tales, but without a clear goal-orientation and without other demands than it beingentertaining to the user.
Furthermore, socialinteraction plays an important role in the fairy-taleworld where the game takes place.
By engaging insocializing with the animated characters, the user willfind out things necessary to overcome variousobstacles and enable progression through the story.Thirdly, a feature that differentiates NICE fromother systems is that the main target user group of thesystem is children and young users.
Previous studieshave indicated that children employ partly differentstrategies when interacting with dialogue systemsthan adults do, and that there are also differencesbetween age groups.
For instance, younger childrenuse less overt politeness markers and verbalize theirfrustration more than older children do (Arunachalamet al 2001).
It has also been shown that children?suser experience is improved if they can communicatewith a system with a ?personality?
and that theybenefit from being able to choose from several inputmodalities (Narayanan and Potamianos 2002).Furthermore, since many young people have a lot ofexperience with computer games, the believability ofthe dialogue characters and natural expressions willbe critical aspects for the system?s success.Thus, computer games provide an excellentapplication area for research in spoken dialoguetechnology, requiring an advance of the state-of-the-art in several fronts.
Perhaps more importantly, gameplayers will have a lot to gain from a successfulincorporation of spoken dialogue technology intocomputer games.
Today?s computer games arelimited by the user?s input options, which are oftenrestricted to direct manipulation and simplecommands.
In the development of the next generationof computer games, we believe that multimodaldialogue has the potential to greatly enrichen theuser?s experience.
For instance, spoken interactionmakes it possible to refer to past events and objectscurrently not visible on the screen.
Social interaction,which is already part of popular games such as SIMS,can be improved with spoken dialogue.
Furthermore,speech and multimodal interaction supportscooperative games, where the user and characterworks together in solving a mutual problem.2 Spoken dialogue systemsSpoken dialogue systems have so far mostly beendesigned with an overall goal to carry out a specifictask, e.g.
accessing time table information or orderingtickets (e.g.
Zue et al 1991; Aust et al 1995).
Withtask-oriented systems, it is possible to build domainmodels that can be used to predefine the languagemodels and dialogue rules.
The existence ofpredefined tasks makes it rather straight-forward toevaluate the performance of the dialogue system.Recent developments have made it possible tomodify and extend the goals of spoken dialoguesystems.
Explorative dialogues, in which users areencouraged to browse through information withoutpursuing a specific task, have been presented by(Cassell et al 1999; Bell et al 2001).
Thesedialogues still contain tasks to be solved during theinteraction, e.g.
giving constraints or receivinginformation about objects.
However, explorativedialogue systems cannot be evaluated using merelythe number of turns between different userinteractions.
A user who continues speaking with thesystem for a long time may do so because she isfinding a lot of interesting information.Yet another type of dialogue system aims topresent its users with an engaging and entertainingexperience, without the presence of an externalpredetermined task.
Conversational kiosks, such asAugust (Gustafson and Bell 2000) and MACK(Cassell et al 2002), encourage users to engage insocial dialogues with embodied characters.
Suchdialogues are amenable to handling by a correctlydesigned dialogue system, since they primarily bringup features from the shared context.3 Interactive storytellingInteractivity has been defined as ?a kind of dramawhere the audience can modify the course of theactions [?]
thus having an active role?
(Szilas 1999).In interactive scenarios, the user helps the storyunfold and may affect its course depending on his orher active participation.
It has been argued thatinteractive storytelling will change computerentertainment by introducing better narrative contentand allowing users to interfere with the progressionof the storyline (Cavazza et al 2002).
However,Young (2001) suggests that the drama manager of thesystem should put a limit to the user?s actions by notallowing interference that violates the overallnarrative plan.
Most interactive games developed sofar allow users to intervene in the storytelling byacting on physical objects on the screen using directmaniputation (Young 2001; Cavazza et al 2002).Moreover, some systems allow users to interact withcharacters by means of written text input (Mateas andStern 2002).
In addition, Cavazza et al (2002)explored using a speech interface that handledisolated utterances from the user.4 The NICE fairy-tale game scenarioThe overall goal of the project is to provide userswith an immersive dialogue experience in a 3D fairy-tale world, see Figure 1.
To this end, we have chosento make spoken and multimodal dialogue the user?sprimary vehicle of progressing through the story.
It isalso by verbal and non-verbal communication that theuser can gain access to the goals and desires of thefairy-tale characters.
This will be critical as thecharacters will ask the users to help them in solvingproblems.
These problems either relate to objects thathave to be manipulated or information that has to beretrieved from other fairy-tale characters.Figure 1.
Cloddy Hans in the fairy-tale world.The fairy-tale domain was chosen because of itsclassic themes and stereotypical characters, well-known to most adults as well as children.
Some ofthese familiar characters are shown in Figure 2.Figure 2.
The fairy-tale characters.To facilitate the progression through the story, weintroduce Cloddy Hans, the user?s faithful assistant.Cloddy Hans?s character is conveyed to the users inthe following way: he is a bit slow to understand, orso it seems.
He sometimes appears hard of hearingand only understands spoken utterances and graphicalgestures at a rather simple level.
Cloddy Hans doesnot take a lot of initiatives, but is honest and anxiousto try to help the user.
In spite of his limitedintellectual and perceptual capabilities, he maysometimes provide important clues through suddenflashes of insight.The user can ask Cloddy Hans to manipulate objectsby referring to them verbally and/or by using themouse.
To understand the reason for not allowingusers to directly manipulate objects on the screen, wehave to recall what distinguishes NICE from othergames, namely, spoken multimodal dialogue.
Wethus want to ensure that multimodal dialogue isappreciated by the user not just as an ?add-on?
but asthe primary means of progressing in the game.
Ourkey to achieving this is to deliberately limit thecapabilities of the key actors ?
the user and CloddyHans ?
in such a way that they can succeed only bycooperating through spoken multimodal dialogue.
Inother words, the user is intelligent but cannot himselfaffect objects in the world; Cloddy Hans on the otherhand is a bit slow but capable of physical actionaccording to what he gets told (and he mayoccasionally also provide tips to the user).The fairy-tale game will start with an introductorydialogue, in which the user meets Cloddy Hans in H CAndersen?s fairy-tale laboratory, see Figure 3.
Thesimple task the user and Cloddy have to solvetogether is to take fairy-tale objects from a shelf andput them in the appropriate slot in a fairy-talemachine.
Each slot is labelled with a symbol, whichdenotes the type of object supposed to go there, butsince Cloddy Hans is not very bright, he needs helpunderstanding these labels.Figure 3.
Cloddy Hans in the fairy-tale labThe initial scenario is a ?grounding game?
set in thecontext of a narrow task.
In other words, its realpurpose is a training session in which the user andCloddy Hans agree on what different objects can beused for and how they can be referred to.
Thisprocess also lets the player find out (by trial-and-error) how to adapt in order to make it easier for thesystem to understand him or her.
Moreover, CloddyHans sometimes explicitly instructs the user.
Forexample, one lesson might be that it is sometimesmore efficient to use multimodal input instead of justspoken utterances.The subsequent game in the fairy-tale worlddepends on what objects have been chosen by theuser in the initial scenario.
The advantage of this isthat the objects are already grounded; for example, asack of gold will be visually recognized by the playerand there is an already agreed way of referring to it.5 System characteristicsThe game scenario as presented in the precedingsection puts a number of requirements on the system.The scenario involves several animated characters,each with its own intended distinct personality.
Thesepersonalities must be made explicit for the gameplayer, and manifest themselves on all levels: fromthe appearance of the characters, their gestures andvoices, choice of words, to their long-term behaviorand overall role in the fairy-tale world.
Furthermore,the characters need to be responsive, and be able toengage in conversation which makes sense to theplayer of the game.On the surface level, then, we need to havebeautifully crafted animated characters andenvironments (these have been designed by thecomputer-game company Liquid Media).
Eachcharacter must have its own voice that conveys thenature of that character?s personality, and be able touse prosodic cues to signal mood and emotions.
Tothis end, a unit-selection speech synthesizer has beendeveloped.
Cloddy Hans has been given a slow, deepvoice that goes along with his intended duncepersonality.
His repertoire of gestures and his style ofwalking also amplifies the impression of a slow-witted but friendly person.On the input side, we need to recognizecontinuous, unconstrained speech for users of allages.
Previous studies have shown that children?sspeech is associated with elevated error rates(Potamianos et al 1997; Oviatt and Adams 2000),making it necessary for Scansoft to retrain the NICErecognizer?s acoustic models.
In addition, we need totake into account the disfluent speech patterns thatare likely to arise, most probably because the usersare unused to the situation or distracted by the virtualenvironment.
On the other hand, not all input needsto be adequately interpreted.
Much of the socializingutterances from the user can be handled in asatisfactory way by using shallow methods.Furthermore, the interpretation of the goal orientedinteractions is simplified by the fact that the systemknows which objects are visible on the screen and,more importantly, since it already knows whatproblems the fairy-tale characters has asked the userto help them to solve.
Finally, the user also has thepossibility of referring to objects using a pointingdevice.
The software for the interpretation of thisgraphical input has been developed by LIMSI.The above characteristics have led us to design thesystem?s interpretation of user input in the followingway.
The system is implemented as a set of event-driven processes that communicate via message-passing.
The architecture is essentially an extensionof the one described in (Bell et al 2001).
Thisarchitecture allows, among other things, for highlyflexible turn-taking.
When the user speaks, thesystem first tries to categorize the utterance as eithersocial (needing only shallow interpretation) or goal-oriented (needing further analysis).Finally, the long-term behavior of a character isdecided by its set of internal goals and rules.
A goalis essentially a predicate (that can be either true orfalse) concerning of the state of the virtual world.
Forinstance, a character may have a goal to acquire acertain object or visit a certain place.
If a given goalis not fulfilled (the predicate is false), the characterwill try to fulfill it.
To this end it will use its set ofrules, that define actions and dialogue acts that arelikely to contribute to reaching the goal.6  Evaluation issuesTask-oriented spoken dialogue systems are usuallyevaluated in terms of objective and subjectivefeatures.
Objective criteria include the technicalrobustness and core functionality of the systemcomponents as well as system performance measuressuch as task completion rate.
Subjective usabilityevaluations estimate features like naturalness andquality of the interactions, as well as user satisfactionreported in post-experimental interviews.
However,many of these measures are simply not relevant forentertainment-type applications, where usersatisfaction increases rather than decreases with taskcompletion time.
It can even be difficult to definewhat the completion of the task would be.
In practice,computer games are usually evaluated byprofessional game reviewers and by the users interms of number of copies sold.In the evaluation of the NICE fairy-tale game salesfigures will not be possible to use, and several of thetraditional objective measures are less relevant due tothe domain.
Instead, subjective measures involvingfeatures like ?narrative progression?, ?characterbelievability?, and ?entertainment value?, will beused.
They will be obtained off-line, by interviewingthe users after their interactions and asking them tofill out questionnaires.
Users will be asked how theyperceived the quality of the actual interaction, as wellas the personality of the fairy-tale characters.
Expertevaluators, who will be able to replay the userinteractions and inspect the system logs, will also beemployed.
Examples of evaluation questions to theexperts include: ?Do the characters displaymeaningful roles and believable personalities thatcontribute to the story?
?, ?Do they succeed insignaling their level of understanding?, ?To whatextent is the user able to affect the plot?
?In order to be able to replay the user interactions withthe fairy-tale system, all communication between thesystem modules are logged with time stamps.
Thiswill be a valuable tool both in the iterative systemdevelopment and for system evaluations.
At present,we are in the process of collecting data with theintroductory game scenario.
The data collected willbe used to develop the subsequent scenarios in thefairy-tale game.ReferencesArunachalam, S., D. Gould, E. Andersen, D. Byrd and S. S.Narayanan.
(2001).
Politeness and frustration languagein child-machine interactions.
Proceedings ofEurospeech: 2675-2678.Aust, H., M. Oerder, F. Seide and V. Steinbiss (1995).
ThePhilips automatic train timetable information system.Speech Communication 17(3-4): 249-262.Bell, L., J. Boye and J. Gustafson (2001).
Real-timehandling of fragmented utterances.
Proc.
NAACL 2001workshop on Adaptation in Dialogue Systems.Cassell, J., T. Bickmore, M. Billinghurst, L. Campbell, K.Chang, H. Vilhj?lmsson and H. Yan (1999).Embodiment in conversational interfaces: Rea.Proceedings of CHI: 520-527.Cassell, J., T. Stocky, T. Bickmore, Y. Gao, Y. Nakano, K.Ryokai, D. Tversky, C. Vaucelle and H. Vilhjlmsson(2002).
MACK: Media lab AutonomousConversational Kiosk.
Imagina 02.
Monte Carlo.Cavazza, M., F. Charles and S. J. Mead (2002).
Character-based interactive storytelling.
IEEE IntelligentSystems, Special issue on AI in InteractiveEntertainment: 17-24.Gustafson, J. and L. Bell (2000).
Speech technology ontrial - Experiences from the August system.
NaturalLanguage Engineering 6(3-4): 273-286.Mateas, M. and A. Stern (2002).
Architecture, authorialidioms and early observations of the interactive dramaFacade.
Technical report CM-CS-02-198.Narayanan, S. and A. Potamianos (2002).
Creatingconversational interfaces for children.
IEEETransactions on Speech and Audio Proc.
10(2): 65-78.Oviatt, S. and B. Adams (2000).
Designing and evaluatingconversational interfaces with animated characters.Embodied Conversational Agents.
J. Cassell, J.Sullivan, S. Prevost and E. Churchill.
MIT Press.Potamianos, A., S. Narayanan and S. Lee (1997).Automatic speech recognition for children.Proceedings of Eurospeech.
5: 2371-2374.Szilas, N. (1999).
Interactive drama on the computer:beyond linear narrative.
AAAI 1999 Fall Symposiumon Narrative Intelligence.Young, R. M. (2001).
An Overview of the MimesisArchitecture: Integrating Intelligent Narrative Controlinto an Existing Gaming Environment.
Working Notesof the AAAI Spring Symposium on ArtificialIntelligence and Interactive Entertainment.Zue, V., J.
Glass, D. Goodline, H. Leung, M. Phillips, J.Polifroni and S. Seneff (1991).
Integration of speechrecognition and natural language processing in theMIT voyager system.
Proc.
ICASSP'91.
Toronto.
