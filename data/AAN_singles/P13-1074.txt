Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 752?760,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsPunctuation Prediction with Transition-based ParsingDongdong Zhang1, Shuangzhi Wu2, Nan Yang3, Mu Li11Microsoft Research Asia, Beijing, China2Harbin Institute of Technology, Harbin, China3University of Science and Technology of China, Hefei, China{dozhang,v-shuawu,v-nayang,muli}@microsoft.comAbstractPunctuations are not available in automaticspeech recognition outputs, which could cre-ate barriers to many subsequent text pro-cessing tasks.
This paper proposes a novelmethod to predict punctuation symbols for thestream of words in transcribed speech texts.Our method jointly performs parsing andpunctuation prediction by integrating a rich setof syntactic features when processing wordsfrom left to right.
It can exploit a global viewto capture long-range dependencies for punc-tuation prediction with linear complexity.
Theexperimental results on the test data sets ofIWSLT and TDT4 show that our method canachieve high-level performance in punctuationprediction over the stream of words in tran-scribed speech text.1 IntroductionStandard automatic speech recognizers output un-structured streams of words.
They neither performa proper segmentation of the output into sentences,nor predict punctuation symbols.
The unavailablepunctuations and sentence boundaries in tran-scribed speech texts create barriers to many sub-sequent processing tasks, such as summarization,information extraction, question answering andmachine translation.
Thus, the segmentation oflong texts is necessary in many real applications.For example, in speech-to-speech translation,continuously transcribed speech texts need to besegmented before being fed into subsequent ma-chine translation systems (Takezawa et al, 1998;Nakamura, 2009).
This is because current ma-chine translation (MT) systems perform the trans-lation at the sentence level, where various modelsused in MT are trained over segmented sentencesand many algorithms inside MT have an exponen-tial complexity with regard to the length of inputs.The punctuation prediction problem has at-tracted research interest in both the speech pro-cessing community and the natural language pro-cessing community.
Most previous work primar-ily exploits local features in their statistical mod-els such as lexicons, prosodic cues and hiddenevent language model (HELM) (Liu et al, 2005;Matusov et al, 2006; Huang and Zweig, 2002;Stolcke and Shriberg, 1996).
The word-level mod-els integrating local features have narrow viewsabout the input and could not achieve satisfiedperformance due to the limited context infor-mation access (Favre et al, 2008).
Naturally,global contexts are required to model the punctu-ation prediction, especially for long-range de-pendencies.
For instance, in English question sen-tences, the ending question mark is long-range de-pendent on the initial phrases (Lu and Ng, 2010),such as ?could you?
in Figure 1.
There has beensome work trying to incorporate syntactic featuresto broaden the view of hypotheses in the punctua-tion prediction models (Roark et al, 2006; Favreet al, 2008).
In their methods, the punctuationprediction is treated as a separated post-procedureof parsing, which may suffer from the problem oferror propagation.
In addition, these approachesare not able to incrementally process inputs andare not efficient for very long inputs, especially inthe cases of long transcribed speech texts frompresentations where the number of streamingwords could be larger than hundreds or thousands.In this paper, we propose jointly performingpunctuation prediction and transition-based de-pendency parsing over transcribed speech text.When the transition-based parsing consumes thestream of words left to right with the shift-reducedecoding algorithm, punctuation symbols are pre-dicted for each word based on the contexts of theparsing tree.
Two models are proposed to causethe punctuation prediction to interact with thetransition actions in parsing.
One is to conducttransition actions of parsing followed by punctua-tion predictions in a cascaded way.
The other is toassociate the conventional transition actions ofparsing with punctuation perditions, so that pre-dicted punctuations are directly inferred from the752(a).
The transcribed speech text without punctuations(b).
Transition-based parsing trees and predicted punctuations over transcribed text(c).
Two segmentations are formed when inserting the predicted punctuation symbols into the transcribed textFigure 1.
An example of punctuation prediction.parsing tree.
Our models have linear complexityand are capable of handling streams of words withany length.
In addition, the computation of modelsuse a rich set of syntactic features, which can im-prove the complicated punctuation predictionsfrom a global view, especially for the long rangedependencies.Figure 1 shows an example of how parsinghelps punctuation prediction over the transcribedspeech text.
As illustrated in Figure 1(b), twocommas are predicted when their preceding wordsact as the adverbial modifiers (advmod) duringparsing.
The period after the word ?menu?
is pre-dicted when the parsing of an adverbial clausemodifier (advcl) is completed.
The question markat the end of the input is determined when a directobject modifier (dobj) is identified, together withthe long range clue that the auxiliary word occursbefore the nominal subject (nsubj).
Eventually,two segmentations are formed according to thepunctuation prediction results, shown in Figure1(c).The training data used for our models is adaptedfrom Treebank data by excluding all punctuationsbut keeping the punctuation contexts, so that it cansimulate the unavailable annotated transcribedspeech texts.
In decoding, beam search is used toget optimal punctuation prediction results.
Weconduct experiments on both IWSLT data andTDT4 test data sets.
The experimental resultsshow that our method can achieve higher perfor-mance than the CRF-based baseline method.The paper is structured as follows: Section 2conducts a survey of related work.
The transition-based dependency parsing is introduced in Section3.
We explain our approach to predicting punctu-ations for transcribed speech texts in Section 4.Section 5 gives the results of our experiment.
Theconclusion and future work are given in Section 6.2 Related WorkSentence boundary detection and punctuation pre-diction have been extensively studied in thespeech processing field and have attracted re-search interest in the natural language processingfield as well.
Most previous work exploits localfeatures for the task.
Kim and Woodland (2001),Huang and Zweig (2002), Christensen et al(2001), and Liu et al (2005) integrate both pro-sodic features (pitch, pause duration, etc.)
and lex-ical features (words, n-grams, etc.)
to predictpunctuation symbols during speech recognition,where Huang and Zweig (2002) uses a maximumentropy model, Christensen et al (2001) focus onfinite state and multi-layer perceptron methods,and Liu et al (2005) uses conditional randomfields.
However, in some scenarios the prosodiccues are not available due to inaccessible originalraw speech waveforms.
Matusov et al (2006) in-tegrate segmentation features into the log-linearmodel in the statistical machine translation (SMT)framework to improve the translation perfor-mance when translating transcribed speech texts.Lu and Ng (2010) uses dynamic conditional ran-dom fields to perform both sentence boundary andsentence type prediction.
They achieved promis-ing results on both English and Chinese tran-scribed speech texts.
The above work only ex-anyway you may find your favorite if you go through the menu so could you tell me your choiceanyway you may find your favorite if you go  through the menu so could you tell me your choice, N N N N N N N N N N .
, N N N N N ?anyway, you may find your favorite if you go through the menu.
so, could you tell me your choice?nsubj nsubj possauxmark pobjiobjadvmodadvclnsubj dobjdet poss aux prepadvmod dobj753ploits local features, so they were limited to cap-turing long range dependencies for punctuationprediction.It is natural to incorporate global knowledge,such as syntactic information, to improve punctu-ation prediction performance.
Roark et al (2006)use a rich set of non-local features including par-ser scores to re-rank full segmentations.
Favre etal.
(2008) integrate syntactic information from aPCFG parser into a log-linear and combine it withlocal features for sentence segmentation.
Thepunctuation prediction in these works is per-formed as a post-procedure step of parsing, wherea parse tree needs to be built in advance.
As theirparsing over the stream of words in transcribedspeech text is exponentially complex, their ap-proaches are only feasible for short input pro-cessing.
Unlike these works, we incorporate punc-tuation prediction into the parsing which processleft to right input without length limitations.Numerous dependency parsing algorithmshave been proposed in the natural language pro-cessing community, including transition-basedand graph-based dependency parsing.
Comparedto graph-based parsing, transition-based parsingcan offer linear time complexity and easily lever-age non-local features in the models (Yamada andMatsumoto, 2003; Nivre et al, 2006b; Zhang andClark, 2008; Huang and Sagae, 2010).
Startingwith the work from (Zhang and Nivre, 2011), inthis paper we extend transition-based dependencyparsing from the sentence-level to the stream ofwords and integrate the parsing with punctuationprediction.Joint POS tagging and transition-based de-pendency parsing are studied in (Hatori et al,2011; Bohnet and Nivre, 2012).
The improve-ments are reported with the joint model comparedto the pipeline model for Chinese and other richlyinflected languages, which shows that it alsomakes sense to jointly perform punctuation pre-diction and parsing, although these two tasks ofPOS tagging and punctuation prediction are dif-ferent in two ways: 1).
The former usually workson a well-formed single sentence while the latterneeds to process multiple sentences that are verylengthy.
2).
POS tags are must-have features toparsing while punctuations are not.
The parsingquality in the former is more sensitive to the per-formance of the entire task than in the latter.3 Transition-based dependency parsingIn a typical transition-based dependency parsingprocess, the shift-reduce decoding algorithm isapplied and a queue and stack are maintained(Zhang and Nivre, 2011).
The queue stores thestream of transcribed speech words, the front ofwhich is indexed as the current word.
The stackstores the unfinished words which may be linkedwith the current word or a future word in thequeue.
When words in the queue are consumedfrom left to right, a set of transition actions is ap-plied to build a parse tree.
There are four kinds oftransition actions conducted in the parsing process(Zhang and Nivre, 2011), as described in Table 1.Action DescriptionShift Fetches the current word from thequeue and pushes it to the stackReduce Pops the stackLeftArc Adds a dependency link from the cur-rent word to the stack top, and  pops thestackRightArc Adds a dependency link from the stacktop to the current word, takes away thecurrent word from the queue andpushes it to the stackTable 1.
Action types in transition-based parsingThe choice of each transition action during theparsing is scored by a linear model that can betrained over a rich set of non-local features ex-tracted from the contexts of the stack, the queueand the set of dependency labels.
As described in(Zhang and Nivre, 2011), the feature templatescould be defined over the lexicons, POS-tags andthe combinations with syntactic information.In parsing, beam search is performed to searchthe optimal sequence of transition actions, fromwhich a parse tree is formed (Zhang and Clark,2008).
As each word must be pushed to the stackonce and popped off once, the number of actionsneeded to parse a sentence is always 2n, where nis the length of the sentence.
Thus, transition-based parsing has a linear complexity with thelength of input and naturally it can be extended toprocess the stream of words.4 Our method4.1 ModelIn the task of punctuation prediction, we are givena stream of words from an automatic transcriptionof speech text, denoted by ?1?
: = ?1, ?2, ?
, ??
.We are asked to output a sequence of punctuationsymbols ?1?
:= ?1, ?2, ?
, ??
where ??
is attachedto ??
to form a sentence like Figure 1(c).
If thereare no ambiguities, ?1?
is also abbreviated as ?,754similarly for ?1?
as ?.
We model the search of thebest sequence of predicted punctuation symbols??
as:??
= argmaxS?(?1?|?1?)
(1)We introduce the transition-based parsing tree?
to guide the punctuation prediction in Model (2),where parsing trees are constructed over the tran-scribed text while containing no punctuations.??
= argmax??
?(?|?1?)
?
?
(?1?|?, ?1?)?
(2)Rather than enumerate all possible parsing trees,we jointly optimize the punctuation predictionmodel and the transition-based parsing modelwith the form:(?
?, ??)
= argmax(?,?)?(?|?1?)
??
(?1?|?, ?1?)
(3)Let ?1?
be the constructed partial tree when ?1?is consumed from the queue.
We decompose theModel (3) into:(?
?, ??)
=argmax(?,?)?
?(?1?|?1?
?1, ?1?)
?
?(?
?|?1?, ?1?)?
?=1(4)It is noted that a partial parsing tree uniquelycorresponds to a sequence of transition actions,and vice versa.
Suppose ?1?
corresponds to the ac-tion sequence ?1?
and let ??
denote the last actionin ?1?
.
As the current word ??
can only be con-sumed from the queue by either Shift or RightArcaccording to Table 1, we have ??
?{????
?, ????????}
.
Thus, we synchronize thepunctuation prediction with the application ofShift and RightArc during the parsing, which is ex-plained by Model (5).(?
?, ??)
= argmax(?,?)?
?(?1?
, ?1?
|?1?
?1, ?1?)??=1?
?(??|??
, ?1?
, ?1?
)(5)The model is further refined by reducing thecomputation scope.
When a full-stop punctuationis determined (i.e., a segmentation is formed), wediscard the previous contexts and restart a new1 Specially, ??
is equal to 1 if there are no previous full-stoppunctuations.procedure for both parsing and punctuation pre-diction over the rest of words in the stream.
In thisway we are theoretically able to handle the unlim-ited stream of words without needing to alwayskeep the entire context history of streaming words.Let ??
be the position index of last full-stop punc-tuation1 before ?, ????
and ????
the partial tree andcorresponding action sequence over the words????
, Model (5) can be rewritten by:(?
?, ??)
=argmax(?,?)?
?(????
, ????
|????
?1, ???? )
???=1?(??|??
, ????
, ???? )
(6)With different computation of Model (6), weinduce two joint models for punctuation predic-tion: the cascaded punctuation prediction modeland the unified punctuation prediction model.4.2 Cascaded punctuation prediction model(CPP)In Model (6), the computation of two sub-modelsis independent.
The first sub-model is computedbased on the context of words and partial treeswithout any punctuation knowledge, while thecomputation of the second sub-model is condi-tional on the context from the partially built pars-ing tree ????
and the transition action.
As the wordsin the stream are consumed, each computation oftransition actions is followed by a computation ofpunctuation prediction.
Thus, the two sub-modelsare computed in a cascaded way, until the optimalparsing tree and optimal punctuation symbols aregenerated.
We call this model the cascaded punc-tuation prediction model (CPP).4.3 Unified punctuation prediction model(UPP)In Model (6), if the punctuation symbols can bedeterministically inferred from the partial tree,?(??|?
?, ????
, ???? )
can be omitted because it is al-ways 1.
Similar to the idea of joint POS taggingand parsing (Hatori et al, 2011; Bohnet and Nivre,2012), we propose attaching the punctuation pre-diction onto the parsing tree by embedding ??
into??
.
Thus, we extend the conventional transitionactions illustrated in Table 1 to a new set of tran-sition actions for the parsing, denoted by ???:755???
= {??????
?, ??????}
?
{?????(?)|?
?
?}?
{????????(?)|?
?
?
}where Q is the set of punctuation symbols to bepredicted, ?
is a punctuation symbol belonging toQ, Shift(s) is an action that attaches s to the currentword on the basis of original Shift action in pars-ing, RightArc(s) attaches ?
to the current word onthe basis of original RightArc action.With the redefined transition action set ??
?, thecomputation of Model (6) is reformulated as:(?
?, ??)
=argmax(?,?)?
?
(????
, ??????|????
?1, ??????
?1, ????
)?
?=1        (7)Here, the computation of parsing tree and punc-tuation prediction is unified into one model wherethe sequence of transition action outputs uniquelydetermines the punctuations attached to the words.We refer to it as the unified punctuation predic-tion model (UPP).(a).
Parsing tree and attached punctuation symbolsShift(,), Shift(N), Shift(N), LeftArc, LeftArc, LeftArc,Shift(N), RightArc(?
), Reduce, Reduce(b).
The corresponding sequence of transition actionsFigure 2.
An example of punctuation predictionusing the UPP model, where N is a null type punc-tuation symbol denoting no need to attach anypunctuation to the word.Figure 2 illustrates an example how the UPPmodel works.
Given an input ?so could you tellme?, the optimal sequence of transition actions inFigure 2(b) is calculated based on the UPP modelto produce the parsing tree in Figure 2(a).
Accord-ing to the sequence of actions, we can determinethe sequence of predicted punctuation symbolslike ?,NNN??
that have been attached to the wordsshown in Figure 2(a).
The final segmentation withthe predicted punctuation insertion could be ?so,could you tell me?
?.4.4 Model training and decodingIn practice, the sub-models in Model (6) and (7)with the form of ?(?|?)
is computed with a linearmodel ?????
(?, ?)
as?????
(?, ?)
= ?
(?, ?)
?
?where ?
(?, ?)
is the feature vector extractedfrom the output ?
and the context ?, and ?
is theweight vector.
For the features of the models, weincorporate the bag of words and POS tags as wellas tree-based features shown in Table 2, which arethe same as those defined in (Zhang and Nivre,2011).
(a) ws; w0; w1; w2; ps; p0; p1; p2; wsps; w0p0; w1p1;w2p2; wspsw0p0; wspsw0; wspsp0; wsw0p0;psw0p0; wsw0; psp0; p0p1; psp0p1; p0p1p2;(b) pshpsp0; pspslp0; pspsrp0; psp0p0l; wsd; psd; w0d;p0d; wsw0d; psp0d; wsvl; psvl; wsvr; psvr; w0vl;p0vl; wsh; psh; ts; w0l; p0l; t0l; w0r; p0r; t0r; w1l;p1l; t1l; wsh2; psh2; tsh; wsl2; psl2; tsl2; wsr2; psr2;tsr2; w0l2; p0l2; t0l2; pspslpsl2; pspsrpsr2; pspshpsh2;p0p0lp0l2; wsTl; psTl; wsTr; psTr; w0Tl; p0Tl;Table 2.
(a) Features of the bag of words and POStags.
(b).
Tree-based features.
w?word; p?POStag; d?distance between ws and w0; v?number ofmodifiers; t?dependency label; T?set of depend-ency labels; s, 0, 1 and 2 index the stack top andthree front items in the queue respectively; h?head;l?left/leftmost; r?right/rightmost; h2?head of ahead; l2?second leftmost; r2?second rightmost.The training data for both the CPP and UPPmodels need to contain parsing trees and punctu-ation information.
Due to the absence of annota-tion over transcribed speech data, we adapt theTreebank data for the purpose of model training.To do this, we remove all types of syntactic infor-mation related to punctuation symbols from theraw Treebank data, but record what punctuationsymbols are attached to the words.
We normalizevarious punctuation symbols into two types: Mid-dle-paused punctuation (M) and Full-stop punctu-ation (F).
Plus null type (N), there are three kindsof punctuation symbols attached to the words.
Ta-ble 3 illustrates the normalizations of punctuationsymbols.
In the experiments, we did not furtherdistinguish the type among full-stop punctuationbecause the question mark and the exclamationmark have very low frequency in Treebank data.so could you tell me, N N N ?nsubj iobjauxadvmod756But our CPP and UPP models are both independ-ent regarding the number of punctuation types tobe predicted.Punctuations NormalizationPeriod, question mark,exclamation markFull-stop punctuation(F)Comma, Colon, semi-colonMiddle-paused punctu-ation (M)Multiple Punctuations(e.g., !!!!?
)Full-stop punctuation(F)Quotations, brackets,etc.Null (N)Table 3.
Punctuation normalization in trainingdataAs the feature templates are the same for themodel training of both CPP and UPP, the traininginstances of CPP and UPP have the same contextsbut with different outputs.
Similar to work in(Zhang and Clark, 2008; Zhang and Nivre, 2011),we train CPP and UPP by generalized perceptron(Collins, 2002).In decoding, beam search is performed to getthe optimal sequence of transition actions in CPPand UPP, and the optimal punctuation symbols inCPP.
To ensure each segment decided by a full-stop punctuation corresponds to a single parsingtree, two constraints are applied in decoding forthe pruning of deficient search paths.
(1) Proceeding-constraint: If the partial pars-ing result is not a single tree, the full-stoppunctuation prediction in CPP cannot beperformed.
In UPP, if Shift(F) orRightArc(F) fail to result in a single parsingtree, they cannot be performed as well.
(2) Succeeding-constraint: If the full-stoppunctuation is predicted in CPP, or Shift(F)and RightArc(F) are performed in UPP, thefollowing transition actions must be a se-quence of Reduce actions until the stackbecomes empty.5 Experiments5.1 Experimental setupOur training data of transition-based dependencytrees are converted from phrasal structure trees inEnglish Web Treebank (LDC2012T13) and theEnglish portion of OntoNotes 4.0 (LDC2011T03)by the Stanford Conversion toolkit (Marneffe etal., 2006).
It contains around 1.5M words in totaland consist of various genres including weblogs,web texts, newsgroups, email, reviews, question-answer sessions, newswires, broadcast news andbroadcast conversations.
To simulate the tran-scribed speech text, all words in dependency treesare lowercased and punctuations are excluded be-fore model training.
In addition, every ten depend-ency trees are concatenated sequentially to simu-late a parsing result of a stream of words in themodel training.There are two test data sets used in our experi-ments.
One is the English corpus of the IWSLT09evaluation campaign (Paul, 2009) that is the con-versional speech text.
The other is a subset of theTDT4 English data (LDC2005T16) which con-sists of 200 hours of closed-captioned broadcastnews.In the decoding, the beam size of both the tran-sition-based parsing and punctuation prediction isset to 5.
The part-of-speech tagger is our re-imple-mentation of the work in (Collins, 2002).The evaluation metrics of our experiments areprecision (prec.
), recall (rec.)
and F1-measure(F1).For the comparison, we also implement a base-line method based on the CRF model.
It incorpo-rates the features of bag of words and POS tagsshown in Table 2(a), which are commonly used inprevious related work.5.2 Experimental resultsWe test the performance of our method on boththe correctly recognized texts and automaticallyrecognized texts.
The former data is used to eval-uate the capability of punctuation prediction ofour algorithm regardless of the noises from speechdata, as our model training data come from formaltext instead of transcribed speech data.
The usageof the latter test data set aims to evaluate the ef-fectiveness of our method in real applicationswhere lots of substantial recognition errors couldbe contained.
In addition, we also evaluate thequality of our transition-based parsing, as its per-formance could have a big influence on the qualityof punctuation prediction.5.2.1 Performance on correctly recognizedtextThe evaluation of our method on correctly recog-nized text uses 10% of IWSLT09 training set,which consists of 19,972 sentences from BTEC(Basic Travel Expression Corpus) and 10,061 sen-tences from CT (Challenge Task).
The average in-put length is about 10 words and each input con-tains 1.3 sentences on average.
The evaluation re-sults are presented in Table 4.757Measure   Middle-PausedFull-stop MixedBaseline(CRF)prec.
33.2% 81.5% 78.8%rec.
25.9% 83.8% 80.7%F1 29.1% 82.6% 79.8%CPPprec.
51% 89% 89.6%rec.
50.3% 93.1% 92.7%F1 50.6% 91% 91.1%UPPprec.
52.6% 93.2% 92%rec.
59.7% 91.3% 92.3%F1 55.9% 92.2% 92.2%Table 4.
Punctuation prediction performance oncorrectly recognized textWe achieved good performance on full-stoppunctuation compared to the baseline, whichshows our method can efficiently process sen-tence segmentation because each segment is de-cided by the structure of a single parsing tree.
Inaddition, the global syntactic knowledge used inour work help capture long range dependencies ofpunctuations.
The performance of middle-pausedpunctuation prediction is fairly low between allmethods, which shows predicting middle-pausedpunctuations is a difficult task.
This is because theusage of middle-paused punctuations is very flex-ible, especially in conversional data.
The last col-umn in Table 4 presents the performance of thepure segmentation task where the middle-pausedand full-stop punctuations are mixed and not dis-tinguished.
The performance of our method ismuch higher than that of the baseline, whichshows our method is good at segmentation.
Wealso note that UPP yields slightly better perfor-mance than CPP on full-stop and mixed punctua-tion prediction, and much better performance onmiddle-paused punctuation prediction.
This couldbe because the interaction of parsing and punctu-ation prediction is closer together in UPP than inCPP.5.2.2 Performance on automatically recog-nized textTable 5 shows the experimental results of punctu-ation prediction on automatically recognized textfrom TDT4 data that is recognized using SRI?sEnglish broadcast news ASR system where theword error rate is estimated to be 18%.
As the an-notation of middle-paused punctuations in TDT4is not available, we can only evaluate the perfor-mance of full-stop punctuation prediction (i.e., de-tecting sentence boundaries).
Thus, we mergeevery three sentences into one single input beforeperforming full-stop prediction.
The average inputlength is about 43 words.Measure   Full-stopBaseline(CRF)prec.
37.7%rec.
60.7%F1 46.5%CPPprec.
63%rec.
58.6%F1 60.2%UPPprec.
73.9%rec.
51.6%F1 60.7%Table 5.
Punctuation prediction performance onautomatically recognized textGenerally, the performance shown in Table 5 isnot as high as that in Table 4.
This is because thespeech recognition error from ASR systems de-grades the capability of model prediction.
Anotherreason might be that the domain and style of ourtraining data mismatch those of TDT4 data.
Thebaseline gets a little higher recall than our method,which shows the baseline method tends to makeaggressive segmentation decisions.
However,both precision and F1 score of our method aremuch higher than the baseline.
CPP has higher re-call than UPP, but with lower precision and F1score.
This is in line with Table 4, which consist-ently illustrates CPP can get higher recall on full-stop punctuation prediction for both correctly rec-ognized and automatically recognized texts.5.2.3 Performance of transition-based pars-ingPerformance of parsing affects the quality ofpunctuation prediction in our work.
In this section,we separately evaluate the performance of ourtransition-based parser over various domains in-cluding the Wall Street Journal (WSJ), weblogs,newsgroups, answers, email messages and re-views.
We divided annotated Treebank data intothree data sets: 90% for model training, 5% for thedevelopment set and 5% for the test set.
The accu-racy of our POS-tagger achieves 96.71%.
Thebeam size in the decoding of both our POS-tag-ging and parsing is set to 5.
Table 6 presents theresults of our experiments on the measures ofUAS and LAS, where the overall accuracy is ob-tained from a general model which is trained overthe combination of the training data from all do-mains.758We first evaluate the performance of our transi-tion-based parsing over texts containing punctua-tions (TCP).
The evaluation results show that ourtransition-based parser achieves state-of-the-artperformance levels, referring to the best depend-ency parsing results reported in the shared task ofSANCL 2012 workshop2, although they cannot becompared directly due to the different trainingdata and test data sets used in the experiments.Secondly, we evaluate our parsing model in CPPover the texts without punctuations (TOP).
Sur-prisingly, the performance over TOP is better thanthat over TCP.
The reason could be that wecleaned out data noises caused by punctuationswhen preparing TOP data.
These results illustratethat the performance of transition-based parsing inour method does not degrade after being inte-grated with punctuation prediction.
As a by-prod-uct of the punctuation prediction task, the outputsof parsing trees can benefit the subsequent textprocessing tasks.Data sets UAS LASTexts con-taining punc-tuations(TCP)WSJ 92.6% 90.3%Weblogs 90.7% 88.2%Answers 89.4% 85.7%Newsgroups 90.1% 87.6%Reviews 90.9% 88.4%Email Messages 89.6% 87.1%Overall 90.5% 88%Texts with-out punctua-tions (TOP)WSJ 92.6% 91.1%Weblogs 92.5% 91.1%Answers 95% 94%Newsgroups 92.6% 91.2%Reviews 92.6% 91.2%Email Messages 92.9% 91.7%Overall 92.6% 91.2%Table 6.
The performance of our transition-basedparser on written texts.
UAS=unlabeled attach-ment score; LAS=labeled attachment score6 Conclusion and Future WorkIn this paper, we proposed a novel method forpunctuation prediction of transcribed speech texts.Our approach jointly performs parsing and punc-tuation prediction by integrating a rich set of syn-tactic features.
It can not only yield parse trees, butalso determine sentence boundaries and predictpunctuation symbols from a global view of the in-2 https://sites.google.com/site/sancl2012/home/shared-task/resultsputs.
The proposed algorithm has linear complex-ity in the size of input, which can efficiently pro-cess the stream of words from a purely text pro-cessing perspective without the dependences oneither the ASR systems or subsequent tasks.
Theexperimental results show that our approach out-performs the CRF-based method on both the cor-rectly recognized and automatically recognizedtexts.
In addition, the performance of the parsingover the stream of transcribed words is state-of-the-art, which can benefit many subsequent textprocessing tasks.In future work, we will try our method on otherlanguages such as Chinese and Japanese, whereTreebank data is available.
We would also like totest the MT performance over transcribed speechtexts with punctuation symbols inserted based onour method proposed in this paper.ReferencesB.
Bohnet and J. Nivre.
2012.
A transition-based sys-tem for joint part-of-speech tagging and labelednon-projective dependency parsing.
In Proc.EMNLP-CoNLL 2012.H.
Christensen, Y. Gotoh, and S. Renals.
2001.
Punc-tuation annotation using statistical prosody models.In Proc.
of ISCA Workshop on Prosody in SpeechRecognition and Understanding.M.
Collins.
2002.
Discriminative training methods forhidden Markov models: Theory and experimentswith perceptron algorithms.
In Proc.
EMNLP?02,pages 1-8.B.
Favre, R. Grishman, D. Hillard, H. Ji, D. Hakkani-Tur, and M. Ostendorf.
2008.
Punctuating speechfor information extraction.
In Proc.
of ICASSP?08.B.
Favre, D. HakkaniTur, S. Petrov and D. Klein.
2008.Efficient sentence segmentation using syntactic fea-tures.
In Spoken Language Technologies (SLT).A.
Gravano, M. Jansche, and M. Bacchiani.
2009.
Re-storing punctuation and capitalization in transcribedspeech.
In Proc.
of ICASSP?09.J.
Hatori, T. Matsuzaki, Y. Miyao and J. Tsujii.
2011.Incremental joint POS tagging and dependencyparsing in Chinese.
In Proc.
Of IJCNLP?11.J.
Huang and G. Zweig.
2002.
Maximum entropymodel for punctuation annotation from speech.
InProc.
Of ICSLP?02.759J.H.
Kim and P.C.
Woodland.
2001.
The use of pros-ody in a combined system for punctuation genera-tion and speech recognition.
In Proc.
of Eu-roSpeech?01.Y.
Liu, A. Stolcke, E. Shriberg, and M. Harper.
2005.Using conditional random fields for sentenceboundary detection in speech.
In Proc.
of ACL?05.W.
Lu and H.T.
Ng.
2010.
Better Punctuation Predic-tion with Dynamic Conditional Random Fields.
InProc.
Of EMNLP?10.
Pages 177-186.M.
Marneffe, B. MacCartney, C.D.
Maning.
2006.Generating Typed Dependency Parses from PhraseStructure Parses.
In Proc.
LREC?06.E.
Matusov, A. Mauser, and H. Ney.
2006.
Automaticsentence segmentation and punctuation predictionfor spoken language translation.
In Proc.
ofIWSLT?06.S.
Nakamura.
2009.
Overcoming the language barrierwith speech translation technology.
In Science &Technology Trends - Quarterly Review.
No.
31.April 2009.J.
Nivre.
2003.
An efficient algorithm for projective de-pendency parsing.
In Proceedings of IWPT, pages149?160, Nancy, France.J.
Nivre and M. Scholz.
2004.
Deterministic depend-ency parsing of English text.
In Proc.
COLING?04.M.
Paul.
2009.
Overview of the IWSLT 2009 Evalua-tion Campaign.
In Proceedings of IWSLT?09.B.
Roark, Y. Liu, M. Harper, R. Stewart, M. Lease, M.Snover, I. Shafran, B. Dorr, J. Hale, A. Krasnyan-skaya, and L. Yung.
2006.
Reranking for sentenceboundary detection in conversational speech.
InProc.
ICASSP, 2006.A.
Stolcke and E. Shriberg, ?Automatic linguistic seg-mentation of conversational speech,?
Proc.
ICSLP,vol.
2, 1996.A.
Stolcke, E. Shriberg, R. Bates, M. Ostendorf, D.Hakkani, M. Plauche, G. Tur, and Y. Lu.
1998.
Au-tomatic detection of sentence boundaries and disflu-encies based on recognized words.
In Proc.
ofICSLP?
98.Takezawa, T. Morimoto, T. Sagisaka, Y. Campbell, N.Iida, H. Sugaya, F. Yokoo, A. Yamamoto, Seiichi.1998.
A Japanese-to-English speech translation sys-tem: ATR-MATRIX.
In Proc.
ICSLP?98.Y.
Zhang and J. Nivre.
2011.
Transition-based De-pendency Parsing with Rich Non-local Features.
InProc.
of ACL?11, pages 188-193.Y.
Zhang and S. Clark.
A Tale of Two Parsers: inves-tigating and combing graph-based and transition-based dependency parsing using beam-search.
2008.In Proc.
of EMNLP?08, pages 562-571.760
