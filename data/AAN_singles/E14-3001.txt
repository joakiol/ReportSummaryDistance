Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 1?10,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsLiterature-based discovery for Oceanographic climate scienceElias AamotDepartment of Informatics and Computer ScienceNorwegian University of Science and TechnologyTrondheim, Norwayeliasaa@stud.ntnu.noAbstractThis paper presents an overview of thefield of literature-based discovery, as orig-inally applied in biomedicine.
Further-more it identifies some of the challengesto employing the results of the field in anew domain, namely oceanographic cli-mate science, and elaborates on some ofthe research that needs to be conducted toovercome these challenges.1 IntroductionThe increase in growth rate of the scientific litera-ture over the past decades has forced researchers tobecome increasingly specialized in order to keepup with the state of the art.
This inevitably leadsto the fragmentation of science as researchers fromdifferent (sub-)disciplines rarely have time to readeach other?s papers.
Swanson (1986) claimed thatthis fragmentation of science can lead to undiscov-ered public knowledge: Conclusions that can bemade from existing literature, but have never beenmade because the knowledge fragments have beendiscovered in separate (sub-)disciplines.
Adopt-ing the terminology of Swanson (1991), a litera-ture can be informally defined as a collection ofpapers with a significant amount of cross-citationrelated to a single topic.
Two literatures are com-plementary if they contain knowledge fragmentswhich can be combined to form new knowledge,and disjoint if they have no articles in common,and exhibit little or no cross-citation.
The implicithypothesis is that such complementary but disjoint(CBD) literatures are common, giving rise to sig-nificant amounts of undiscovered public knowl-edge.
The field of Literature-based Discovery(LBD)1focuses on the development and applica-tion of computational tools to discover undiscov-ered public knowledge in scientific literature.1Also called Literature-based knowledge discovery(LBKD).Most work in LBD has been conducted in sub-fields of the biomedical literature, frequently em-ploying knowledge resources specific to that do-main.
This paper will present an overview of someof the research in LBD, and discuss some of thechallenges in reproducing the results made in theLBD field in a different domain, namely oceano-graphic climate science.
The structure of this pa-per is as follows: Section 2 will give an overviewof the LBD field, section 3 will discuss differ-ences between the biomedical domain and thatof oceanographic climate science, and section 4will discuss directions for research that will beconducted in order to adapt LBD methods to theoceanographic climate science domain.2 Literature-based discoverySwanson (1986) observed that if a literature L1as-serted a ?
b, and a disjoint literature L2assertedb ?
c, then the concept denoted by b could func-tion as a bridge between L1and L2, leading to thediscovery of the hypothesis a ?
c2.
One examplegiven by Swanson showed that fish oils reducedblood viscosity (fish oil ?
blood viscosity),and that patients of Raynaud?s disease tend to ex-hibit high blood viscosity (blood viscosity ?Raynaud).
These two facts led to the hypothe-sis that fish oils can be used in the treatment ofRaynaud?s disease (fish oil ?
Raynaud) whencombined.
This hypothesis was subsequently con-firmed experimentally (Digiacomo et al., 1989).Although the inference steps are not logicallysound, the procedure is able to produce interest-ing results.
The general approach of bridging dis-2A note on terminology: In the LBD literature, capitalletters are normally used for the A, B and C concepts.
Inthis paper, minuscules will be used to represent individualconcepts, while capital letters represent sets.Also, some authors use A to denote the the goal concept,and C for the starting concept.
This paper follows the mostcommonly used terminology, in which a always denotes thestarting concept, and c denotes the goal concept.1joint literatures by means of intermediary termshas been dubbed Swanson linking, and is also re-ferred to as the ABC model.Swanson and Smalheiser (1997) explain that thediscovery of the ABC structure and the fish oil-Raynaud?s disease connection happened acciden-tally.
This discovery led Swanson to conduct lit-erature searches aided by existing information re-trieval tools to search for more undiscovered pub-lic knowledge using the ABC model, resulting inthe discovery of eleven connections between mi-graine and magnesium (Swanson, 1988).
As thediscovery process was extremely time consum-ing, requiring the researcher to read hundreds ofpapers, Swanson later developed a computationaltool, Arrowsmith, to streamline the discovery pro-cess.There are two modes of discovery in the ABCmodel: Open discovery and closed discovery.
Inopen discovery, the researcher only knows thestarting concept a, and is interested in uncov-ering undiscovered public knowledge related toa.
A researcher who looks for consequences ofocean acidification might conduct an open dis-covery search with a = ocean acidification.In closed-discovery, the researcher knows boththe starting concept a and the goal concept c,and is interested in finding concepts B that provean explanation of the relationship between thetwo terms.
A researcher who hypothesizes thatocean acidification might cause a reduction in phy-toplankton population and tries to discover thecausality chain might conduct a closed discov-ery search with a = ocean acidification, c =phytoplankton population.This section will present an overview of thestate-of-the-art of the LBD field.
As this paperdiscusses the adaptation of LBD to new domains,approaches will be grouped into of three groupsaccording to their dependence on domain specifictools and resources, because reliance on these islikely to hinder cross-domain adaptation3.2.1 Group 1: Domain-independentapproachesIn the general Swanson linking paradigm, opendiscovery is conducted by extracting all relationsa ?
bifrom the literature of a, written L(a).
For3Some of the papers are presented as domain independent,even though they employ domain specific resources, becausetheir main research contributions can be adapted in a domain-independent manner.every bi, all relations bi?
cjare then extractedfrom L(bi).
The set of all a ?
bi?
cjrelations,dubbed discovery candidates is then are presentedto the user as potential discoveries, sorted accord-ing to some ranking metric.In most LBD approaches L(x) is definedas the set of documents returned when search-ing for x in a literature database.
The litera-ture database most commonly used in LBD isPubmed/Medline4, maintained by the US NationalLibrary of Medicine.
The original Arrowsmithsystem considered only paper titles, as Swansonconsidered these to hold the most compact knowl-edge, but it has become the standard approach inLBD to use abstracts and possibly index terms inaddition to the titles.
The motivation for this is thatabstracts and index terms contain more knowledgethan only titles.Somewhat surprisingly, few LBD systems usefull paper texts.
Schuemie et al.
(2004) show that30-40% of all information contained in a sectionis new to that section, meaning that significantamounts of knowledge is lost when only lookingat abstracts and index terms of a paper.
The needfor full text data is also pointed out by Cameronet al.
(2013).
The reason for not using full textseems to be that paper abstracts and index termsare available in xml format through the PubmedAPI, while full paper texts require accessing rightsand are normally stored as pdf.In co-occurrence based systems, a relation x ?y is postulated if x and y exhibit a high degreeof co-occurrence in L(x), either in terms of abso-lute frequency of co-occurrence, or in terms of sta-tistical unlikelihood given the statistical promis-cuity of the two concepts.
While a few systemsuse the sentence as the domain for counting co-occurrences, most systems count co-occurrencesacross entire abstracts.To present the user with only potential new dis-coveries, most LBD systems remove from C allterms that are already known to be in a relationwith a.
In co-occurrence based methods, this isdone by removing any (a, c) pairs that exhibithigher degrees if co-occurrence than a predefinedthreshold (normally 1 co-occurrence) in L(a).2.1.1 ArrowsmithThe original Arrowsmith system works as follows(Swanson and Smalheiser, 1997): L(a) is fetched4http://www.ncbi.nlm.nih.gov/pubmed/2by conducting a Medline search to retrieve the ti-tles of papers containing a in the title.
The setof potential B concepts is extracted as the list ofunique words in L(a), after a stop list of approxi-mately 5000 words has been applied.
The B-termset is further pruned by removing all the wordsthat have lesser relative frequency in L(a) than inMedline.
The potential B terms are subsequentlypresented to the user, who can then remove wordsthat are thought to be unsuitable.
For each bi?
B,L(bi) is retrieved and a set Ciis generated, subjectto the same stopword and frequency restrictions asbefore.
The terms in the union of the Cisets arethen ranked according to the number of b-termsthat connect them to the a-term.2.1.2 Information retrieval-based methodsGordon and Lindsay (1996) (Lindsay and Gordon,1999) developed a system in parallel, which dif-fered from Arrowsmith in several ways: Firstly,while Arrowsmith was word-based, their systemused n-grams as the unit of analysis.
A stop listwas applied by removing all n-grams that con-tained any stop word occurrence.
Secondly, theirsystem used entire Medline records, comprisingof keywords, abstracts and titles, whereas Arrow-smith only used paper titles.
Thirdly, their sys-tem employed information retrieval metrics suchas tf*idf to find b-terms among the generated can-didates, whereas Arrowsmith was based on rela-tive frequencies.The lexical statistical approach is so generic thatit lends itself directly to application in different do-mains.
In a later paper, Gordon et al.
(2001) em-ploy this approach to conduct LBD searches di-rectly on the World Wide Web, searching for ap-plication areas for genetic algorithms.
It shouldhowever be noted that the goal of this experimentwas not LBD in the sense of uncovering undiscov-ered public knowledge, instead focusing in discov-ering something that might be ?publicly known?but novel to the user.2.1.3 Ranking metricsWren et al.
(2004) pointed out that the structureof concept co-occurrence relationships is such thatmost concepts are connected to any other conceptwithin few steps.
This small world phenomenonimplies that research focus should be shifted awayfrom retrieving discovery candidates to rankingthem, because a significant portion of the con-cept space will be retrieved even within two co-occurrence relation steps.
The paper proposesranking implicit relationships by comparing thenumber of observed indirect connections betweena and c to the number of expected connections in arandom network model, given the relative promis-cuity of the intermediary terms.In another paper, Wren (2004) emphasizes theimportance of using a statistically sound methodof ranking relationship strengths, such as ?chi-square tests, log-likelihood ratios, z-scores or t-scores?, because co-occurrence based measuresbias towards more general, and thus less inter-esting relationships.
The paper further proposesan extension to the mutual information measure(MIM) as a ranking measure.2.1.4 Latent semantic indexingGordon and Dumais (1998) propose exploitingthe ability of certain vector-based semantic mod-els such as Latent semantic indexing (LSI) todiscover implicit relationships between terms forLBD.
They first train the semantic model on L(a),and let the user choose as b one of the terms mostsimilar to a.
A new semantic model is built fromL(b), and discovery candidates are ranked accord-ing to their similarity to a in the L(b)-model.
Theirexperiments showed that the resulting b- and c-term candidate lists closely resemble the lists pro-duced by the information retrieval inspired lexicalstatistics.In another experiment they built a semanticmodel from a random sample of all of Medline,and looked directly for c-terms in the semanticmodel by considering the terms most similar to a.This ?zoomed-out?
approach produced differentresults than the previous Swanson linking inspiredapproach, which the authors claimed meant thatthe two methods are complementary and couldtherefore be used in parallel, but no in-depth eval-uation was conducted on the quality of the results.2.1.5 Evaluation effortsLBD has a tradition for questionable evaluation ef-fort.
The original discoveries in LBD were mademanually by Swanson, and most computationalsystems are evaluated solely according to theirability to replicate one or more of Swanson?s dis-coveries.
This is problematic for several reasons:First of all, Swanson?s discoveries were never in-tended as a gold standard, and being able to ac-complish a single task that is known in advancedoes not mean that the results are generalizable.3Secondly, there is no quantitative basis for com-paring different approaches or metrics.Yetisgen-Yildiz and Pratt (2009) conducted thefirst systematic quantitative evaluation of discov-ery candidate ranking metrics and relation rank-ing/generation techniques.
They partitioned Med-line into two parts, according to a cut-off date.LBD was conducted on the pre-cut-off set, andthe post-cut-off set was used as a gold standardto compute precision and recall.
In the post-cut-off set, a connection was considered to exist iftwo terms co-occurred in any document.
Theranking metrics that were evaluated were Linkingterm count (LTC), that is the number of b-termsconnecting a and c, Average minimum weight(AMW), that is the average weight of the a ?b ?
c connections, and Literature cohesiveness(COH), a measure developed by Swanson but notwidely adopted.
Experiments showed that LTCgave better precision at all levels of recall.
The re-lation generation techniques that were consideredwere association rules, tf-idf, z-score and MIM.The experiment showed that association rules givethe best precision score (8.8%) but the worst recallscore (53.76%), while tf-idf gave the best recall(88.0%) but a rather low precision (2.29%).While the evaluation effort was an importantcontribution to the LBD field, more quantitativeevaluation is required.
First of all, all candidateranking/generation techniques and ranking met-rics were tested with only one value of the pa-rameters (for instance the cut-off score for tf-idf,and the cut-off probability for z-score).
Compar-ing the performance of different settings for theparameters would yield a better understanding ofeach of the metrics, and could lead to results com-pletely different than those reported.
Secondly,only a small subset of possible relation genera-tion/ranking techniques and discovery candidateranking metrics were tested.
For example, no re-lation extraction-based methods (see section 2.3)were included in the evaluation.The evaluation methodology can be critiqued inseveral ways.
Firstly, building the gold standardfrom the post-cut-off set is problematic for severalreasons: A co-occurrence can exist in the post-cut-off set without necessarily corresponding to a newdiscovery.
Also, as pointed out in Kostoff (2007),it is very difficult to verify that a discovery hasnot been made before the cut-off date.
Anotherproblem is that the post-cut-off set only containsdiscoveries that have been made in the present,all future discoveries are therefore excluded fromthe gold standard.
Secondly, it is not obvious thatquantitative measures reflect the usefulness of theLBD system: When at all is said and done, theusefulness of a LBD system equates to its abilityto support user in discovering knowledge.2.2 Group 2: Concept-based approachesSeveral researchers advocate using domain spe-cific concepts taken from an ontology or con-trolled vocabularies instead of n-gram tokens.
Us-ing concepts provides three benefits over n-grammodels: Firstly, synonyms and spelling variantsare mapped to the same semantic concept.
Sec-ondly, using concepts allows for ranking and fil-tering according to semantic categories.
Finally, itbecomes easier to constrain the search space by re-moving spurious or irrelevant n-grams at an earlystage, as they don?t map to any concept in the do-main.
On the other hand, concept extraction fromraw text is a non-trivial operation.In LBD concept extraction is conducted in oneof two ways: One option is to use NLP toolsdesigned for entity recognition.
The most com-monly used in the biomedical domain is MetaMap(Aronson and Lang, 2010), which extracts con-cepts from the Unified Medical Language System(UMLS) meta-thesaurus5.
The other option is touse Medical Subject Headings (MeSH)6.
MeSHis a controlled vocabulary for indexing biomedicalpapers, with which all Medline papers have beenmanually tagged.
MeSH keywords can be querieddirectly from the Medline API.
Both MeSH andUMLS terms are organized hierarchically accord-ing to semantic categories.2.2.1 DADIn their system, DAD (Disease-Adverse reaction-Drug), Weeber et al.
(2001) use MetaMap.
Theyshowed in an experiment that the number of con-cepts extracted is significantly lower than the num-ber of n-grams, even after stop lists are applied(8,362 n-grams vs. 5,998 concepts).
DAD also al-lows the user to specify which semantic categoriesto consider, by for instance only allowing conceptsof the type pharmacological substance as c con-cepts, reducing the number of search paths signif-icantly.5http://www.nlm.nih.gov/research/umls/6http://www.nlm.nih.gov/mesh/4Their approach was able to replicate both Swan-son?s Raynaud?s-fish oil and migraine-magnesiumdiscoveries, but it was discovered that MetaMapmaps both mg (milligram) and Mg (magnesium) tothe concept magnesium, giving optimistic resultsfor the migraine-magnesium experiment.
This isbut one example showing that one of the problemswith employing NLP tools in an LBD system isthat system performance becomes closely tied tothe performance of the tools it employs.2.2.2 LitLinkerPratt and Yetisgen-Yildiz (2003) developed asystem, LitLinker, which originally also usedMetaMap, but they later found it too computation-ally expensive for practical use (Yetisgen-Yildizand Pratt, 2006).
MeSH terms are therefore em-ployed instead.In a preprocessing step, LitLinker calculates theco-occurrence patterns of every MeSH term acrossthe literatures of every other MeSh term.
For ev-ery MeSH term, the mean and standard deviationof co-occurrence counts across the literatures iscalculated.
In the discovery process, a term isconsidered to be related to another term if theirco-occurrence is higher than statistically expected,based on its z-score.Yetisgen-Yildiz and Pratt identified threeclasses of uninteresting links and terms thatshould be pruned automatically by system: (1)too broad terms (giving the examples medicine,disease and human), (2) too closely related terms(giving the example migraine and headache), and(3) semantically nonsensical connections.
Thefirst class is handled by removing any concept if itis strictly more specific in the MeSH ontology hi-erarchy than any included term.
The second classis handled by pruning all links between termsthat are closely related (grandparents, parents,siblings and children) in the ontology.
The thirdclass is handled by letting the user specify whichsemantic classes of concepts are allowed to link.2.2.3 BitolaHristovski et al.
(2001) originally developed asystem called Bitola7that discovered associationrules between MeSH terms.
Association rulesmining is a common data mining method for dis-covering relations between variables in a database.Association rules are traditionally used for mar-ket basket analysis, in which rules of the type7http://ibmi3.mf.uni-lj.si/bitola/{pizza, steak} ?
{coca cola} are inferred, stat-ing that if somebody buys pizza and steak, he/sheis likely to buy coca cola as well.
In Bitola?s dis-covery step, basic associations are first mined fromthe co-occurrence patterns of MeSH terms.
Sub-sequently, indirect associations a ?
c are inferredby combining association rules on the form a ?
biand bi?
c, and ranked according to the sum ofstrengths of the connecting association rules.2.3 Group 3: Relation extraction-basedapproachesHristovski et al.
(2006) point out two prob-lems with the co-occurrence based LBD systems:Firstly, no explicit explanation of the relation be-tween the a and c terms is given.
Secondly, alarge number of spurious relations are discovered,as demonstrated by the low precision values wit-nessed during system evaluation.
Both aspectsincrease the time needed to examine the outputof the system by the human user.
They suggestthat employing natural language processing (NLP)techniques to extract explicit relations from the pa-pers can improve performance on both points.The biomedical information extraction toolmost commonly used in LBD is SemRep (Rind-flesch and Fiszman, 2003), which uses lin-guistically motived rules on top of the ouputfrom MetaMap and the Xerox POS Tag-ger to extract knowledge in the form of <subject, predicate, object > relation triplets.
Al-though the knowledge expressed in natural lan-guage is more complex than what can be rep-resented in simple relation triplets, SemRep isable to provide a better approximation to theknowledge content of scientific papers than do co-occurrence based methods.While most LBD research employs the sameNLP tool, systems differ as to how the extractedrelations are represented and how reasoning isconducted in the relation space.
Some researchersclosely follow the Swanson linking paradigm, anduse relation extraction based method instead ofor in addition to co-occurrence based methodsfor candidate generation and ranking.
Other re-searchers take an approach motivated by Wren?sobservation that a small-world property holds inthe network of concept relations in literature.
Assignificant portions of the concept-relation spacewill have to be explored in a two-step search any-way, it might be better to extract all relations from5the entire literature collection or from a randomsample thereof, and rather focus on valid and effi-cient reasoning within the entire concept-relationspace.Smalheiser (2012) critiques the usage of rela-tion extraction in LBD and claims that while rea-soning over explicit relations may lead to so-calledincremental discoveries, that is, discoveries thatlie close to the existing knowledge and thereforeare less interesting, they are not able to lead to anyradical discoveries, that is discoveries that seemunlikely at time of discovery.
He also claims thathuman discoveries, both incremental and radical,tend to be on a higher level, using analogies andabstract similarities rather than explicit relations,and that the benefit from using relation extractiontherefore is minimal8.2.3.1 Augmented BitolaIn two papers, Hristovski et al.
(2006; 2008) ex-periment with augmenting the Bitola system byusing relation extraction tools.
In addition to Sem-Rep, they also use another tool, BioMedLee, be-cause each of the tools exhibits better performancethan the other on certain types of relations.To guide search through the concept-relationspace, they introduce the notion of a discovery pat-tern.
A discovery pattern is a set of concept typesand relations between them that could imply an in-teresting relationship in the domain.
One discov-ery pattern, maybe treats can informally be statedas: If a disease leads to a biological change, anda drug leads to the opposite change, then the drugmay be able to treat the disease.The integration between Bitola and the NLPcomponents presented in the system is rathercrude; for a given query term, Bitola outputs a setof related terms and the set of papers connectingeach related term to the query term.
The connect-ing paper must then be manually input into theNLP components to extract the relation betweenthe query term and any related term.
Following adiscovery pattern requires extracting relations be-tween several concepts until a chain of the correctrelations has been found.
The possibility to in-tegrate Bitola and the NLP tools more tightly hasbeen raised as possible future work, but it has beennoted a concern that the computational load in-8Smalheiser?s critique also extends to many of the widelyemployed co-occurrence based methods.
The argument isthat research should focus on developing methods that rankinteresting relations highly.creases as the NLP component becomes less con-strained by the co-occurrence based components.2.3.2 Graph-based reasoningThe extracted relations can be represented as aPredications Graph in which each concept is rep-resented by a node and each relation is a labelled,directed edge from the subject concept to the ob-ject concept.
Representing the concept-relationspace as a graph provides two benefits: As a visualtool, a graph can display the knowledge extractedby the system in a way that is easily understood bythe user and can be navigated/explored easily.
Asa mathematical object, one can employ graph the-oretic results when developing algorithms for thereasoning process.In the work of Wilkowski et al.
(2011) an initialgraph is constructed by querying a pre-compileddatabase of predications extracted by SemRepfrom Medline for all relations containing the aconcept.
The user then incrementally expands thegraph by selecting which terms to query relationsfor from a list of concepts ranked by their degreecentrality (i.e.
their degree of connectivity in thegraph).
After graph construction, potential discov-ery paths are ranked according to summed degreecentrality.Although some work has been conducted ingraph-based LBD, seemingly no research has beenconducted on LBD in a global, large-scale pred-ications graph derived from all of Medline, or asample of it.2.3.3 Predication-based semantic indexingCohen et al.
(2012a) propose a hyperdimensionalcomputing technique they call predication-basedsemantic indexing (PSI) for efficient representa-tion and reasoning in the concept-relation space.In PSI, concepts and relations are representedas high-dimensional vectors, where the semanticcontent of a concept?s vector is a combination ofall the relations it occurs in and all the conceptsit is related to, weighted by the frequency of therelation.
The system uses SemRep to extract rela-tions from a sample of 8,182,882 Medline recordsas input to the training process.
Inference in thishyperdimensional space can be performed by ordi-nary vector operations.
The paper shows how PSIenables analogical reasoning along the lines of ?xis to what as y is to z??
without explicitly travers-ing the intermediary relation paths between y andz, leading to efficient inference.6The system could originally only infer analo-gies along a single one of the pathways connect-ing two concepts x and y.
In a later paper Co-hen et al.
(2012b) expanded the PSI to allow foranalogies along multiple pathways, by introducinga vector operation simulating quantum superposi-tion, efficiently reasoning over the entire subgraphconnecting x and y.
The paper claims that becausereal world concepts tend to interact through sev-eral pathways, literature-based discovery shouldstrive to be able to reason following a similar pat-tern.2.4 Approach type hierarchyFrom the previous section, it is easy to see theLBD approaches can be divided into a three-levelhierarchy according to their dependence on knowl-edge resources and NLP tools:Type 1 approaches do not require any knowl-edge resources: Terms are extracted directlyfrom text, and relations are hypothesized ac-cording to co-occurrence patterns.
Becauseall knowledge is extracted directly from textthey are completely domain-independent.Type 2 approaches choose terms from a prede-fined set of concepts.
Co-occurrence patternsare still used to determine relations.
The pre-defined concepts are normally gathered froma domain-specific ontology or vocabulary.Type 3 approaches use relation extraction toolsto extract concepts and relations from text.Because the relations of interest vary widelybetween domains, domain-specific NLP toolsare normally used.It is evident from the description above thatthere is a trade-off between reliance on knowledgeresources and system performance, as well as astrong correlation between reliance on knowledgeresources and domain-dependence.
This poses achallenge when adapting LBD approaches to newdomains.3 Domain differencesThe current work is a part of a project researchingthe effects of climate change on the oceanic foodweb (i.e.
who eats who, and how the relative pop-ulation sizes affect each other) and the biologicalpump (roughly the ocean?s ability to absorb andretain excess atmospheric CO2).
The followingsection will discuss some of the research issuesrelated to adapting the LBD techniques from thebiomedical domain to that of the target domain.Oceanographic climate science is a cross-disciplinary domain, bringing together researchersfrom fields such as biology, chemistry, earth sci-ence, climate science and oceanography.
Thecross-disciplinary nature gives rise to an abun-dance of disjoint literatures, providing strongincentives for LBD.
Unfortunately, in a cross-disciplinary domain, scientists from differentfields bring their own terminologies and scientificassumptions, creating challenges for LBD work.While substantial research and engineering ef-fort has gone into the development of NLPtools and computational knowledge sources in thebiomedical domain, oceanographic climate sci-ence is in this respect under-resourced.
To the bestof my knowledge, no domain specific NLP toolsexist for any sufficiently closely related domain,and although ontologies and controlled vocabular-ies exist for some of the related disciplines, suchas for biology and chemistry, substantial effort isrequired to identify and combine the desired re-sources.
As a result, it seems unlikely that any ofthe knowledge intensive (type 2 and 3) LBD meth-ods can be directly applied to oceanographic cli-mate science.
Oceanographic climate science alsolacks an indexed literature database that covers theentire field, akin to Medline.Epistemologically there might be a significantdifference between the fields: The objects of study(the ocean in oceanographic climate science andthe human body in biomedicine) and their pro-cesses are quite different, requiring different typesof scientific experiments.
It therefore seems likelythat the structure of the knowledge produced in thedifferent fields might be different.
In medicine,experiments can be conducted in a large popula-tion of complete systems (human bodies), while inoceanographic experiments must be conducted bysampling subsystems of a single complete system(the ocean).
It is therefore not surprising that pre-liminary observations seem to imply that the re-sults found in oceanographic climate science donot lend themselves to generalization as easily asdo those in biomedicine, and that the former havea stronger context dependence (Compare Eicos-apentaenoic acid AFFECTS Vascular constrictionto Increased labile dissolved organic carbon RE-DUCES carbon accumulation GIVEN THAT bac-7teria growth rate is limited).
To account for this,text mining tools must be able to extract precondi-tions as well as relations, or the user must be in-volved more closely during discovery pattern ap-plication to verify that the extracted relations in-deed hold true in the same context.Example discovery patterns for oceanographicclimate science have been developed in coopera-tion with a domain expert, shedding light on somedifferences between the domains.
One researchgoal of biomedicine is to understand the interac-tions between domain concepts in order to treatdiseases, which is reflected in discovery patternssuch as maybe treats (as mentioned in 2.3.1).
Thediscovery patterns developed for oceanographicclimate science target the interactions between di-rectional change events (increase or reduce) inquantitative variables, such as An increase in CO2causes a decrease in ocean pH.
The types of inter-actions targeted by these discovery patterns havea more complex structure than the binary relationsthat define maybe treats.
Because most relationextraction tools extract only binary relations, itseems that simply adapting existing relation ex-traction tools to the domain will not be sufficient.Ganiz et al.
(2006) discusses that LBD lacks asolid theoretic foundation, as most research is ap-plied, rather than theoretical in nature.
Althoughsome inquiry has been conducted into the natureof discoveries (Smalheiser, 2012), there is littleknowledge about which properties are required tohold in the domain for the LBD methods to be ap-plicable, but the current work assumes that all sci-entific disciplines are sufficiently similar for LBDmethods to be useful.4 Research directionsThe lack of available knowledge resources andNLP tools for the domain makes it hard to di-rectly employ any of the knowledge intensiveLBD methods.
The development of relation ex-traction tools for the domain falls outside the scopeof the current thesis, and therefore so does the ap-plication of type 3 approaches.
Instead, the currentthesis will focus on bridging the gap between thedifferent terminologies and writing styles causedby different backgrounds in the cross-disciplinaryfield.
To this end, I propose using an unsuper-vised approach to jointly learn a semantic parserand an ontology from the literature, following theapproach of Poon and Domingos (2010).Poon and Domingos (2009) show that a seman-tic parser that is able to make non-trivial abstrac-tions from syntactic structure and word usage canbe successfully learned in an unsupervised fash-ion.
The system they describe is for instance ableto map passive and active form into the same se-mantic representation and build realistic synonymhierarchies.
One challenge that must be addressedis that the current state-of-the-art clusters wordsbased on their argument frames, leading to highlyaccurate hierarchical clustering of verbs, but lowerperformance for nouns as these have less diverseargument frames.
One research question that willbe addressed is how a larger context can be ex-ploited to yield higher performance for nouns.In an LBD context, the learning process can beseen as bootstrapping a set of concepts for the do-main.
The resulting system can be considered ahybrid between a type 1 and type 2 approach interms of the hierarchy defined in 2.4, as it doesnot use any domain knowledge, but still proposesa set of concepts.
A hypothesis that will be evalu-ated empirically is whether this will provide betterresults than a pure type 1 system.The ontology learned by the system can beedited by a domain expert, or combined with on-tologies of related fields as they become available,thus providing an elegant interface for integrationwith domain knowledge in an incremental fashion.The proposed approach will use Markov Logic, aprobabilistic extension to first-order logic (FOL),as a knowledge representation language.
Back-ground knowledge can therefore easily be incor-porated by formulating it as FOL, and the proba-bilistic aspect enables the system handle contra-dictions that may occur when combining back-ground knowledge from multiple sources.The training data set will consist of paper ab-stracts collected by querying the Mendeley API9with a set of keywords that represent the most in-teresting topics in the domain.
The keywords willbe developed with the help of a domain expert.
Asa pre-processing step, the training sentences willbe dependency parsed using the Stanford Parser10.The proposed LBD system, Houyi11, will use syn-onym clusters as concepts, and generate a ?
bi9Mendeley is a web-based reference manager and aca-demic social network that has a large crowd-sourced databaseof meta-data, such as abstracts, on scientific papers.10nlp.stanford.edu/software/lex-parser.shtml11The system is named after a legendary archer in Chinesemythology.8and bi?
cjrelation candidates based on td-idfscores.
The choice of tf-idf as relation genera-tion/ranking mechanism is motivated by experi-ments showing that tf-idf gives high recall at thecost of mediocre precision (see section 2.1.5).
Be-cause the system is intended to be augmented byrelation extraction tools in the future, recall isfavoured over precision, as precision is expectedto increase in the final version.
The discovery can-didates are ranked by the number of paths connect-ing them to a, also motivated by the quantitativeexperiments described in section 2.1.5.Houyi will be evaluated quantitatively by com-paring performance on a data set divided intotraining and test data by a cut-off date, follow-ing the approach taken by Yetisgen-Yildiz andPratt (2009).
As discussed in section 2.1.5, thisis not a perfect evaluation procedure, but it willat least give an indication as to whether unsuper-vised semantic parsing and ontology building con-tributes to LBD performance.
The baseline sys-tem, Sheshou12, will use the same ranking met-ric and candidate generation mechanism as Houyi,and uses the NPs extracted by the Stanford Parseras terms.Development of domain specific ontologies andrelation extraction tools is required to apply type3 LBD methods in the domain.
Although outsidethe scope of the current thesis, it is expected thatthe resulting semantic parser and ontology can beuseful for the development of more sophisticatedtools: The semantic parser can function as a pre-processing step for the relation extraction tool byresolving syntactic and synonymic variations.
Theontology can be iteratively improved by integrat-ing existing ontologies and human editing, thusproviding a point of origin for domain knowledgeengineering.AcknowledgementsThis paper is a part of an ongoing master?s thesisunder the supervision of Pinar?Ozt?urk, with ErwinMarsi as co-supervisor.
I am extremely gratefulfor their feedback and support.ReferencesAlan R. Aronson and Franc?ois-Michel M. Lang.
2010.An overview of MetaMap: historical perspective and12Mandarin Chinese for ?archer?, a reference to Arrow-smith.recent advances.
Journal of the American MedicalInformatics Association : JAMIA, 17(3):229?236,May.Delroy Cameron, Olivier Bodenreider, Hima Yala-manchili, Tu Danh, Sreeram Vallabhaneni, Kr-ishnaprasad Thirunarayan, Amit P. Sheth, andThomas C. Rindflesch.
2013.
A graph-based re-covery and decomposition of swanson?s hypothesisusing semantic predications.
J. of Biomedical Infor-matics, 46(2):238?251, April.Trevor Cohen, Dominic Widdows, Roger W. Schvan-eveldt, Peter Davies, and Thomas C. Rindflesch.2012a.
Discovering discovery patterns withpredication-based Semantic Indexing.
Journal ofBiomedical Informatics, 45(6):1049?1065, Decem-ber.Trevor Cohen, Dominic Widdows, Lance Vine, RogerSchvaneveldt, and Thomas C. Rindflesch.
2012b.Many Paths Lead to Discovery: Analogical Re-trieval of Cancer Therapies.
In Quantum Interac-tion, volume 7620 of Lecture Notes in Computer Sci-ence, pages 90?101.
Springer Berlin Heidelberg.Ralph A. Digiacomo, Joel M. Kremer, and Dhiraj M.Shah.
1989.
Fish-oil dietary supplementation in pa-tients with Raynaud?s phenomenon: A double-blind,controlled, prospective study.
The American Jour-nal of Medicine, 86(2):158?164, January.Murat C. Ganiz, William M. Pottenger, and Christo-pher D. Janneck.
2006.
Recent Advances in Liter-ature Based Discovery.
In Journal of the AmericanSociety for Information Science and Technology.Michael D. Gordon and Susan Dumais.
1998.
Usinglatent semantic indexing for literature based discov-ery.
Journal of the American Society for InformationScience and Technology, 49(8):674?685, June.Michael D. Gordon and Robert K. Lindsay.
1996.Toward discovery support systems: a replication,re-examination, and extension of Swanson?s workon literature-based discovery of a connection be-tween Raynaud?s and fish oil.
Journal of the Ameri-can Society for Information Science and Technology,47(2):116?128, February.Michael Gordon, Robert K. Lindsay, and Weiguo Fan.2001.
Literature Based Discovery on the WorldWide Web.
In ACM Transactions on Internet Tech-nology, pages 261?275, New York, USA.
ACMPress.Dimitar Hristovski, J. Stare, B. Peterlin, and S. Dze-roski.
2001.
Supporting discovery in medicineby association rule mining in Medline and UMLS.Studies in health technology and informatics, 84(Pt2):1344?1348.Dimitar Hristovski, Carol Friedman, Thomas C. Rind-flesch, and Borut Peterlin.
2006.
Exploiting seman-tic relations for literature-based discovery.
AMIA ...Annual Symposium proceedings / AMIA Symposium.AMIA Symposium, pages 349?353.9Dimitar Hristovski, C. Friedman, T. C. Rindflesch, andB.
Peterlin.
2008.
Literature-Based KnowledgeDiscovery using Natural Language Processing.
InPeter Bruza and Marc Weeber, editors, Literature-based Discovery, volume 15 of Information Scienceand Knowledge Management, chapter 9, pages 133?152.
Springer, Heidelberg, Germany.Ronald N. Kostoff.
2007.
Validating discovery inliterature-based discovery.
Journal of BiomedicalInformatics, 40(4):448?450, August.Robert K. Lindsay and Michael D. Gordon.
1999.Literature-based discovery by lexical statistics.Journal of the American Society for Information Sci-ence, pages 574?587.Hoifung Poon and Pedro Domingos.
2009.
Unsuper-vised semantic parsing.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing: Volume 1 - Volume 1, EMNLP?09, pages 1?10, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Hoifung Poon and Pedro Domingos.
2010.
Unsuper-vised ontology induction from text.
In Proceedingsof the 48th Annual Meeting of the Association forComputational Linguistics, ACL ?10, pages 296?305, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Wanda Pratt and Meliha Yetisgen-Yildiz.
2003.LitLinker: capturing connections across the biomed-ical literature.
In Proceedings of the 2nd interna-tional conference on Knowledge capture, K-CAP?03, pages 105?112, New York, NY, USA.
ACM.Thomas C. Rindflesch and Marcelo Fiszman.
2003.The interaction of domain knowledge and linguis-tic structure in natural language processing: inter-preting hypernymic propositions in biomedical text.Journal of Biomedical Informatics, 36(6):462?477,December.M.
J. Schuemie, M. Weeber, B. J. Schijvenaars, E. M.van Mulligen, C. C. van der Eijk, R. Jelier, B. Mons,and J.
A. Kors.
2004.
Distribution of informationin biomedical abstracts and full-text publications.Bioinformatics, 20(16):2597?2604, November.Neil R. Smalheiser.
2012.
Literature-based discovery:Beyond the ABCs.
Journal of the American Societyfor Information Science and Technology, 63(2):218?224, February.Don R. Swanson and Neil R. Smalheiser.
1997.
Aninteractive system for finding complementary liter-atures: a stimulus to scientific discovery.
ArtificialIntelligence, 91(2):183?203, April.Don R. Swanson.
1986.
Undiscovered public knowl-edge.
The Library Quarterly, 56(2):pp.
103?118.Don R. Swanson.
1988.
Migraine and magnesium:eleven neglected connections.
Perspectives in Biol-ogy and Medicine, 31(4):526?557.Don R. Swanson.
1991.
Complementary structuresin disjoint science literatures.
In SIGIR ?91: Pro-ceedings of the 14th annual international ACM SI-GIR conference on Research and development in in-formation retrieval, pages 280?289, New York, NY,USA.
ACM.Marc Weeber, Henny Klein, Lolkje T. de Jong van denBerg, and Rein Vos.
2001.
Using concepts inliterature-based discovery: Simulating Swanson?sRaynaud-fish oil and migraine-magnesium discover-ies.
Journal of the American Society for InformationScience and Technology, 52(7):548?557.Bart?omiej Wilkowski, Marcelo Fiszman, Christo-pher M. Miller, Dimitar Hristovski, Sivaram Ara-bandi, Graciela Rosemblat, and Thomas C. Rind-flesch.
2011.
Graph-based methods for discoverybrowsing with semantic predications.
AMIA ... An-nual Symposium proceedings / AMIA Symposium.AMIA Symposium, 2011:1514?1523.Jonathan D. Wren, Raffi Bekeredjian, Jelena A. Stew-art, Ralph V. Shohet, and Harold R. Garner.
2004.Knowledge discovery by automated identificationand ranking of implicit relationships.
Bioinformat-ics (Oxford, England), 20(3):389?398, February.Jonathan D. Wren.
2004.
Extending the mutual infor-mation measure to rank inferred literature relation-ships.
BMC bioinformatics, 5, October.Meliha Yetisgen-Yildiz and Wanda Pratt.
2006.
Us-ing statistical and knowledge-based approaches forliterature-based discovery.
Journal of BiomedicalInformatics, 39(6):600?611, December.Meliha Yetisgen-Yildiz and Wanda Pratt.
2009.
A newevaluation methodology for literature-based discov-ery systems.
Journal of biomedical informatics,42(4):633?643, August.10
