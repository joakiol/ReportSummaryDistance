Corpus-Based Identification of Non-Anaphoric Noun PhrasesDav id  L. Bean and E l len  R i lo f fDepartment of Computer ScienceUniversity of UtahSalt Lake City, Utah 84112{bean,riloff}@cs.utah.eduAbst ractCoreference r solution involves finding antecedentsfor anaphoric discourse entities, such as definitenoun phrases.
But many definite noun phrases arenot anaphoric because their meaning can be un-derstood from general world knowledge (e.g., "theWhite House" or "the news media").
We havedeveloped a corpus-based algorithm for automat-ically identifying definite noun phrases that arenon-anaphoric, which has the potential to improvethe efficiency and accuracy of coreference resolu-tion systems.
Our algorithm generates li ts of non-anaphoric noun phrases and noun phrase patternsfrom a training corpus and uses them to recognizenon-anaphoric noun phrases in new texts.
Using1600 MUC-4 terrorism news articles as the trainingcorpus, our approach achieved 78% recall and 87%precision at identifying such noun phrases in 50 testdocuments.1 I n t roduct ionMost automated approaches to coreference r s-olution attempt o locate an antecedent for ev-ery potentially coreferent discourse ntity (DE)in a text.
The problem with this approach isthat a large number of DE's may not have an-tecedents.
While some discourse ntities suchas pronouns are almost always referential, def-inite descriptions I may not be.
Earlier workfound that nearly 50% of definite descriptionshad no prior referents (Vieira and Poesio, 1997),and we found that number to be even higher,63%, in our corpus.
Some non-anaphoric def-inite descriptions can be identified by lookingfor syntactic lues like attached prepositionalphrases or restrictive relative clauses.
But otherdefinite descriptions are non-anaphoric becausereaders understand their meaning due to com-mon knowledge.
For example, readers of this1In this work, we define adefinite description tobe anoun phrase beginning with the.paper will probably understand the real worldreferents of "the F.B.I.," "the White House,"and "the Golden Gate Bridge."
These are in-stances of definite descriptions that a corefer-ence resolver does not need to resolve becausethey each fully specify a cognitive representa-tion of the entity in the reader's mind.One way to address this problem is to cre-ate a list of all non-anaphoric NPs that couldbe used as a filter prior to coreference r solu-tion, but hand coding such a list is a daunt-ing and intractable task.
We propose a corpus-based mechanism toidentify non-anaphoric NPsautomatically.
We will refer to non-anaphoricdefinite noun phrases as existential NPs (Allen,1995).
Our algorithm uses statistical methodsto generate lists of existential noun phrases andnoun phrase patterns from a training corpus.These lists are then used to recognize xisten-tial NPs in new texts.2 P r io r  ResearchComputational coreference resolvers fall intotwo categories: systems that make no at-tempt to identify non-anaphoric discourse n-tities prior to coreference r solution, and thosethat apply a filter to discourse ntities, identify-ing a subset of them that are anaphoric.
Thosethat do not practice filtering include decisiontree models (Aone and Bennett, 1996), (Mc-Carthy and Lehnert, 1995) that consider all pos-sible combinations of potential anaphora ndreferents.
Exhaustively examining all possiblecombinations i  expensive and, we believe, un-necessary.Of those systems that apply filtering prior tocoreference r solution, the nature of the filter-ing varies.
Some systems recognize when ananaphor and a candidate antecedent are incom-patible.
In SRI's probabilistic model (Kehler,373The  ARCE battalion command has reported that about 50 peasants of various ages have beenkidnapped by terrorists of the Farabundo Marti National Liberation Front \[FMLN\] in SanMiguel Department.
According to that garrison, the mass kidnapping took place on 30 Decemberin San Luis de la Reina.
The source added that the terrorists forced the individuals, who weretaken to an unknown location, out of their residences, presumably toincorporate hem against theirwill into clandestine groups.Figure 1: Anaphoric and Non-Anaphoric NPs (definite descriptions highlighted.
)1997), a pair of extracted templates may beremoved from consideration because an out-side knowledge base indicates contradictory fea-tures.
Other systems look for particular con-structions using certain trigger words.
For ex-ample, pleonastic 2 pronouns are identified bylooking for modal adjectives (e.g.
"necessary")or cognitive verbs (e.g.
"It is thought hat...")in a set of patterned constructions (Lappin andLeass, 1994), (Kennedy and Boguraev, 1996).A more recent system (Vieira and Poesio,1997) recognizes a large percentage of non-anaphoric definite noun phrases (NPs) duringthe coreference r solution process through theuse of syntactic ues and case-sensitive rules.These methods were successful in many in-stances, but they could not identify them all.The existential NPs that were missed were ex-istential to the reader, not because they weremodified by particular syntactic onstructions,but because they were part of the reader's gen-eral world knowledge.Definite noun phrases that do not need to beresolved because they are understood throughworld knowledge can represent a significant por-tion of the existential noun phrases in a text.
Inour research, we found that existential NPs ac-count for 63% of all definite NPs, and 24% ofthem could not be identified by syntactic or lex-ical mea.ns.
This paper details our method foridentifying existential NPs that are understoodthrough general world knowledge.
Our systemrequires no hand coded information and can rec-ognize a larger portion of existential NPs thanVieira and Poesio's ystem.3 Def in i te  NP  TaxonomyTo better understand what makes an NPanaphoric or non-anaphoric, we found it usefulto classify definite NPs into a taxonomy.
We2Pronouns that are semantically empty, e.g.
"It isclear that...."first classified efinite NPs into two broad cat-egories, referential NPs, which have prior refer-ents in the texts, and existential NPs, which donot.
In Figure 1, examples of referential NPsare " the  mass k idnapping,"  " the ter ror -ists" and " the  individuals."
,  while examplesof existential NPs are " the  ARCE bat ta l ioncommand"  and " the  Farabundo Mar t i  Na-t ional  L iberat ion  Front."
(The full taxon-omy can be found in Figure 2.
)We should clarify an important point.
Whenwe say that a definite NP is existential, we saythis because it completely specifies a cognitiverepresentation f the entity in the reader's mind.That is, suppose "the F.B.I."
appears in bothsentence 1 and sentence 7 of a text.
Althoughthere may be a cohesive relationship betweenthe noun phrases, because they both completelyspecify independently, we consider them to benon-anaphoric.Definite Noun Phrases- Referential- Existential- Independent- Syntactic- Semantic- AssociativeFigure 2: Definite NP TaxonomyWe further classified existential NPs into twocategories, independent and associative, whichare distinguished by their need for context.
In-dependent existentials can be understood in iso-lation.
Associative xistentials are inherentlyassociated with an event, action, object or othercontext 3.
In a text about a basketball game,for example, we might find "the score," "thehoop" and "the bleachers."
Although they may3Our taxonomy mimics Prince's (Prince, 1981) inthat our independent existentials roughly equate to hernew class, our associative existentials to her inferableclass, and our referentials toher evoked class.374not have direct antecedents in the text, weunderstand what they mean because they areall associated with basketball games.
In isola-tion, a reader would not necessarily understandthe meaning of "the score" because context isneeded to disambiguate he intended word senseand provide a complete specification.Because associative NPs represent less than10% of the existential NPs in our corpus, our ef-forts were directed at automatically identifyingindependent existentials.
Understanding howto identify independent existential NPs requiresthat we have an understanding of why theseNPs are existential.
We classified independentexistentials into two groups, semantic and syn-tactic.
Semantically independent NPs are exis-tential because they are understood by readerswho share a collective understanding of currentevents and world knowledge.
For example, weunderstand the meaning of "the F.B.I."
withoutneeding any other information.
Syntacticallyindependent NPs, on the other hand, gain thisquality because they are modified structurally.For example, in "the man who shot Liberty Va-lence," "the man" is existential because the rel-ative clause uniquely identifies its referent.4 M in ing  Ex is tent ia l  NPs  f rom aCorpusOur goal is to build a system that can identifyindependent existential noun phrases automati-cally.
In the previous ection, we observed that"existentialism" can be granted to a definitenoun phrase either through syntax or seman-tics.
In this section, we introduce four methodsfor recognizing both classes of existentials.4.1 Syntactic HeuristicsWe began by building a set of syntactic heuris-tics that look for the structural cues of restric-tive premodification and restrictive postmod-ification.
Restrictive premodification is oftenfound in noun phrases in which a proper nounis used as a modifier for a head noun, for ex-ample, "the U.S.
president."
"The president"itself is ambiguous, but "the U.S. president" isnot.
Restrictive postmodification is often rep-resented by restrictive relative clauses, preposi-tional phrases, and appositives.
For example,"the president of the United States" and "thepresident who governs the U.S." are existen-tial due to a prepositional phrase and a relativeclause, respectively.We also developed syntactic heuristics to rec-ognize referential NPs.
Most NPs of the form"the <number> <noun>" (e.g., "the 12 men")have an antecedent, so we classified them as ref-erential.
Also, if the head noun of the NP ap-peared earlier in the text, we classified the NPas referential.This method, then, consists of two groups ofsyntactic heuristics.
The first group, which werefer to as the rule-in heuristics, contains evenheuristics that identify restrictive premodifica-tion or postmodification, thus targeting existen-tial NPs.
The second group, referred to as therule-out heuristics, contains two heuristics thatidentify referential NPs.4.2 Sentence One Extract ions (S l )Most referential NPs have antecedents that pre-cede them in the text.
This observation is thebasis of our first method for identifying seman-tically independent NPs.
If a definite NP occursin the first sentence 4 of a text, we assume theNP is existential.
Using a training corpus, wecreate a list of presumably existential NPs bycollecting the first sentence of every text andextracting all definite NPs that were not classi-fied by the syntactic heuristics.
We call this listthe S1 extractions.4.3 Existent ial  Head Patterns (EHP)While examining the S1 extractions, we foundmany similar NPs, for example "the SalvadoranGovernment," "the Guatemalan Government,"and "the U.S.
Government."
The similaritiesindicate that some head nouns, when premod-ified, represent existential entities.
By usingthe S1 extractions as input to a pattern gen-eration algorithm, we built a set of Existen-tial Head Patterns (EHPs) that identify suchconstructions.
These patterns are of the form"the <x+> 5 <nounl  ...nounN>" such as "the<x+> government" or "the <x+> Salvadorangovernment."
Figure 3 shows the algorithm forcreating EHPs.4Many of the texts we used were newspaper arti-cles and all headers, including titles and bylines, werestripped before processing.5<x+> = one or more words3751.
For each NP of more than two words, build a candidate pattern of the form "the <x+>headnoun."
Example: if the NP was "the new Salvadoran government," the candidate patternwould be "the <x+> government."2.
Apply that pattern to the corpus, count how many times it matches an NP.3.
If possible, grow the candidate pattern by inserting the word to the left of the headnoun, e.g.the candidate pattern ow becomes "the <x+> Salvadoran government."4.
Reapply the pattern to the corpus, count how many times it matches an NP.
If the new countis less that the last iteration's count, stop and return the prior pattern.
If the new count isequal to the last iteration's count, return to step 3.
This iterative process has the effect ofrecognizing compound head nouns.Figure 3: EHP AlgorithmIf the NP was identified via the S1 or EHP methods:Is its definite probability above an upper threshold?Yes: Classify as existential.No: Is its definite probability above a lower threshold?Yes: Is its sentence-number less than or equal to an early allowance threshold?Yes : Classify as existential.No : Leave unclassified (allow later methods to apply).No : Leave unclassified (allow later methods to apply).Figure 4: Vaccine Algorithm4.4 Definite-Only List (DO)It also became clear that some existentialsnever appear in indefinite constructions.
"TheF.B.I.," "the contrary," "the National Guard"are definite NPs which are rarely, if ever, seenin indefinite constructions.
The chances thata reader will encounter "an F.B.I."
are slim tonone.
These NPs appeared to be perfect can-didates for a corpus-based approach.
To locate"definite-only" NPs we made two passes overthe corpus.
The first pass produced a list of ev-ery definite NP and its frequency.
The secondpass counted indefinite uses of all NPs catalogedduring the first pass.
Knowing how often an NPwas used in definite and indefinite constructionsallowed us to sort the NPs, first by the probabil-ity of being used as a definite (its definite prob-ability), and second by definite-use frequency.For example, "the contrary" appeared high onthis list because its head noun occurred 15 timesin the training corpus, and every time it was ina definite construction.
From this, we created adefinite-only list by selecting those NPs whichoccurred at least 5 times and only in definiteconstructions.Examples from the three methods can befound in the Appendix.4.5 VaccineOur methods for identifying existential NPs areall heuristic-based and therefore can be incor-rect in certain situations.
We identified twotypes of common errors.1.
An incorrect $1 assumption.
When the S1 as-sumption falls, i.e.
when a definite NP in thefirst sentence of a text is truly referential, thereferential NP is added to the S1 list.
Later, anExistential Head Pattern may be built from thisNP.
In this way, a single misclassified NP maycause multiple noun phrases to be misclassifiedin new texts, acting as an "infection" (Roaxkand Charniak, 1998).2.
Occasional existentialism.
Sometimes an NPis existential in one text but referential in an-other.
For example, "the guerrillas" often refersto a set of counter-government forces that thereader of an E1 Salvadoran ewspaper wouldunderstand.
In some cases, however, a partic-ular group of guerrillas was mentioned previ-ously in the text ("A group of FMLN rebelsattacked the capital..."), and later referencesto "the guerrillas" referred to this group.To address these problems, we developed avaccine.
It was clear that we had a number of in-fections in our S1 list, including "the base," "the376For every definite NP in a text1.
Apply syntactic RuleOutHeuristics, if any fired, classify the NP as referential.2.
Look up the NP in the S1 list, if found, classify the NP as existential (unless stopped byvaccine).3.
Look up the NP in the DO list, if found, classify the NP as existential.4.
Apply all EHPs, if any apply, classify the NP as existential (unless topped by vaccine).5.
Apply syntactic RuleInHeuristics, if any fired, classify the NP as existential.6.
If the NP is not yet classified, classify the NP as referential.Figure 5: Existential Identification Algorithmindividuals," "the attack," and "the banks.
"We noticed, however, that many of these in-correct NPs also appeared near the bottom ofour definite/indefinite list, indicating that theywere often seen in indefinite constructions.
Weused the definite probability measure as a wayof detecting errors in the S1 and EHP lists.
Ifthe definite probability of an NP was above anupper threshold, the NP was allowed to be clas-sifted as existential.
If the definite probability ofan NP fell below a lower threshold, it was not al-lowed to be classified by the S1 or EHP method.Those NPs that fell between the two thresholdswere considered occasionally existential.Occasionally existential NPs were handled byobserving where the NPs first occurred in thetext.
For example, if the first use of "the guer-rillas" was in the first few sentences of a text,it was usually an existential use.
If the first usewas later, it was usually a referential use be-cause a prior definition appeared in earlier sen-tences.
We applied an early allowance thresholdof three sentences - occasionally existential NPsoccuring under this threshold were classified asexistential, and those that occurred above wereleft unclassified.
Figure 4 details the vaccine'salgorithm.5 A lgor i thm & Tra in ingWe trained and tested our methods on theLatin American newswire articles from MUC-4 (MUC-4 Proceedings, 1992).
The training setcontained 1,600 texts and the test set contained50 texts.
All texts were first parsed by SUN-DANCE, our heuristic-based partial parser de-veloped at the University of Utah.We generated the S1 extractions by process-ing the first sentence of all training texts.
Thisproduced 849 definite NPs.
Using these NPs asVaccineVaccine~ IDOEHP I ~'/ \Unresolved Markedreferential existentialdefinite NPs definite NPsFigure 6: Recognizing Existential NPsinput to the existential head pattern algorithm,we generated 297 EHPs.
The DO list was builtby using only those NPs which appeared at least5 times in the corpus and 100% of the time asdefinites.
We generated the DO list in two iter-ations, once for head nouns alone and once forfull NPs, resulting in a list of 65 head nouns and321 full NPs 6.Once the methods had been trained, we clas-sifted each definite NP in the test set as referen-tial or existential using the algorithm in Figure5.
Figure 6 graphically represents the main el-ements of the algorithm.
Note that we appliedvaccines to the S1 and EHP lists, but not to theDO list because gaining entry to the DO listis much more difficult - -  an NP must occur atleast 5 times in the training corpus, and everytime it must occur in a definite construction.6The full NP list showed best performance using pa-rameters of 5 and 75%, not the 5 and 100% used to createthe head noun only list.377Method Tested0.
Baseline1.
Syntactic Heuristics2.
Syntactic Heuristics + S13.
Syntactic Heuristics + EHP4.
Syntactic Heuristics + DO5.
Syntactic Heuristics + S1 + EHP6.
Syntactic Heuristics + S1 + EHP + DO7.
Syntactic Heuristics + S1 + EHP + DO + Va(70/25)8.
Syntactic Heuristics + S1 + EHP + DO + Vb(50/25)Recall100%43.0%66.3%60.7%69.2%79.9%81.7%77.7%79.1%Precision72.2%93.1%84.3%87.3%83.9%82.2%82.2%86.6%84.5%Figure 7: Evaluation ResultsTo evaluate the performance of our algorithm,we hand-tagged each definite NP in the 50 testtexts as a syntactically independent existential,a semantically independent existential, an asso-ciative existential or a referential NP.
Figure 8shows the distribution of definite NP types inthe test texts.
Of the 1,001 definite NPs tested,63% were independent existentials, o removingthese NPs from the coreference r solution pro-cess could have substantial savings.
We mea-sured the accuracy of our classifications usingrecall and precision metrics.
Results are shownin Figure 7.478 Independent existential, syntactic 48%53 Independent existential, semantic 15%Associative xistential 9%::1 Referential 28%TotalFigure 8: NP DistributionAs a baseline measurement, weconsidered theaccuracy of classifying every definite NP as ex-istential.
Given the distribution of definite NPtypes in our test set, this would result in recallof 100% and precision of 72%.
Note that weare more interested in high measures of preci-sion than recall because we view this methodto be the precursor to a coreference r solutionalgorithm.
Incorrectly removing an anaphoricNP means that the coreference r solver wouldnever have a chance to resolve it, on the otherhand, non-anaphoric NPs that slip through canstill be ruled as non-anaphoric by the corefer-ence resolver.We first evaluated our system using only thesyntactic heuristics, which produced only 43%recall, but 92% precision.
Although the syn-tactic heuristics are a reliable way to identifyexistential definite NPs, they miss 57% of thetrue existentials.6 Eva luat ionWe expected the $1, EHP, and DO methodsto increase coverage.
First, we evaluated eachmethod independently (on top of the syntac-tic heuristics).
The results appear in rows 2-4of Figure 7.
Each method increased recall tobetween 61-69%, but decreased precision to 84-87%.
All of these methods produced a substan-tial gain in recall at some cost in precision.Next, we tried combining the methods tomake sure that they were not identifying ex-actly the same set of existential NPs.
Whenwe combined the S1 and EHP heuristics, recallincreased to 80% with precision dropping onlyslightly to 82%.
When we combined all threemethods (S1, EHP, and DO), recall increasedto 82% without any corresponding loss of preci-sion.
These experiments show that these heuris-tics substantially increase recall and are identi-fying different sets of existential NPs.Finally, we tested our vaccine algorithm tosee if it could increase precision without sacri-ficing much recall.
We experimented with twovariations: Va used an upper definite probabil-ity threshold of 70% and ~ used an upper def-inite probability threshold of 50%.
Both vari-ations used a lower definite probability thresh-old of 25%.
The results are shown in rows 7-8of Figure 7.
Both vaccine variations increasedprecision by several percentage points with onlya slight drop in recall.In previous work, the system developed byVieria & Poesio achieved 74% recall and 85%precision for identifying "larger situation andunfamiliar use" NPs.
This set of NPs does notcorrespond exactly to our definition of existen-tial NPs because we consider associative NPs378to be existential and they do not.
Even so, ourresults are slightly better than their previous re-sults.
A more equitable comparison is to mea-sure our system's performance on only the in-dependent existential noun phrases.
Using thismeasure, our algorithm achieved 81.8% recallwith 85.6% precision using Va, and achieved82.9% recall with 83.5% precision using Vb.7 ConclusionsWe have developed several methods for auto-matically identifying existential noun phrasesusing a training corpus.
It accomplishes thistask with recall and precision measurementsthat exceed those of the earlier Vieira & Poesiosystem, while not exploiting full parse trees, ap-positive constructions, hand-coded lists, or casesensitive text z.
In addition, because the sys-tem is fully automated and corpus-based, it issuitable for applications that require portabil-ity across domains.
Given the large percentageof non-anaphoric discourse entities handled bymost coreference resolvers, we believe that us-ing a system like ours to filter existential NPshas the potential to reduce processing time andcomplexity and improve the accuracy of coref-erence resolution.Shalom Lappin and Herbert J. Leass.
1994.
An al-gorithm for pronomial anaphora resolution.
Com-putational Linguistics, 20(4):535-561.Joseph F. McCarthy and Wendy G. Lehnert.
1995.Using Decision Trees for Coreference Resolution.In Proceedings of the l~th International JointConference on Artificial Intelligence (IJCAI-95),pages 1050-1055.Ellen F. Prince.
1981.
Toward a taxonomy of given-new information.
In Peter Cole, editor, RadicalPragmatics, pages 223-255.
Academic Press.Brian Roark and Eugene Charniak.
1998.
Noun-phrase co-occurence statistics for semi-automaticsemantic lexcon construction.
In Proceedings ofthe 36th Annual Meeting of the Association forComputational Linguistics.R.
Vieira and M. Poesio.
1997.
Processing defi-nite descriptions in corpora.
In S. Botley andM.
McEnery, editors, Corpus-based and Compu-tational Approaches to Discourse Anaphora.
UCLPress.Re ferencesJames Allen.
1995.
Natural Language Understand-ing.
Benjamin/Cummings Press, Redwood City,CA.Chinatsu Aone and Scott William Bennett.
1996.Applying Machine Learning to Anaphora Reso-lution.
In Connectionist, Statistical, and Sym-bolic Approaches to Learning for Natural Lan-guage Understanding, pages 302-314.
Springer-Verlag, Berlin.Andrew Kehler.
1997.
Probabilistic oreference ininformation extraction.
In Proceedings of the Sec-ond Conference on Empirical Methods in NaturalLanguage Processing (EMNLP-97).Christopher Kennedy and Branimir Boguraev.
1996.Anaphor for everyone: Pronomial anaphora reso-lution without a parser.
In Proceedings of the 16thInternational Conference on Computational Lin-guistics (COLING-96).~Case sensitive text can have a significant positive f-fect on performance because it helps to identify propernouns.
Proper nouns can then be used to look for restric-tive premodification, something that our system cannottake advantage ofbecause the MUC-4 corpus is entirelyin uppercase.379Append ixExamples from the $1, EHP, & DO lists.$1 Extractions Existential Head Patterns Definite-Only NPsTHE FMLN TERRORISTS  THE <X+> NAT IONAL CAP ITOL  THE STATE DEPARTMENTTHE NAT IONAL CAP ITOL  THE <X+> AFFA IR  THE PAST  16 YEARSTHE FMLN REBELS  THE <X+> ATTACKS THE CENTRAL  AMERICAN UNIVERSITYTHE NAT IONAL REVOLUTIONARY NETWORK THE <X-.b> AUTHORIT IES  THE MEDIATHE PAVON PR ISON FARM THE <X--b> INST ITUTE THE 6TH INFRANTRY BR IGADETHE FMLN TERRORIST  LEADERS THETHE CUSCATLAN RADIO NETWORK THETHE PAVON REHABIL ITAT ION FARM THETHE PLO THETHE TELA AGREEMENTS THETHE SALVADORAN ARMY THETHE COLOMBIAN GUERRILLA  MOVEMENTS THETHE COLOMBIAN ARMY THETHE REL IG IOUS MONTHLY MAGAZINE 30 G IORNI  THETHE REVOLUTIONARY LEFT  THE<X+> GOVERNMENT<X+> COMMUNITY<X+> STRUCTURE< X.-\[- > PATROL<X+> BORDER<X+> SQUARE< X--b> COMMAND<X+> SENATE<X-bY NETWORK<X-bY LEADERSTHE PAST  FEW HOURSTHE U.N. SECRETARY GENERALTHE PENTAGONTHE CONTRARYTHE MRTATHE CARIBBEANTHE USSTHE DRUG TRAFF ICK ING MAF IATHE MAQUIL IGUASTHE MAYORSHIPTHE PERUVIAN ARMYTHE CENTRAL  AMERICAN PEOPLESTHE GUATEMALAN ARMYTHE BUSINESS SECTORTHE HONDURAN ARMTHE ANT ICOMMUNIST  ACT ION ALL IANCETHE DEMOCRATIC  SYSTEMTHE U.S.THE BUSH ADMIN ISTRAT IONTHE CATHOLIC  CHURCHTHE WARTHE <X-F> RESULTTHE <X-.I-> SECURITYTHE <X+> CRIMINALSTHE <X--b> HOSP ITALTHE <X+> CENTERTHE <X+> REPORTSTHE <X+> ELNTHE <X+> AGREEMENTSTHE <X--b> CONSTITUT IONTHE <X+> PEOPLESTHE <X+> EMBASSYTHE SANDIN ISTSTHE LATTERTHE WOUNDEDTHE SAMETHE C IT IZENRYTHE KREMLINTHE BESTTHE NEXTTHE MEANTIMETHE COUNTRYSIDETHE NAVY380
