Learning Tractable Word Alignment Modelswith Complex ConstraintsJoa?o V. Grac?a?L2F INESC-IDKuzman Ganchev?
?University of PennsylvaniaBen Taskar?University of PennsylvaniaWord-level alignment of bilingual text is a critical resource for a growing variety of tasks.
Proba-bilistic models for word alignment present a fundamental trade-off between richness of capturedconstraints and correlations versus efficiency and tractability of inference.
In this article, weuse the Posterior Regularization framework (Grac?a, Ganchev, and Taskar 2007) to incorporatecomplex constraints into probabilistic models during learning without changing the efficiencyof the underlying model.
We focus on the simple and tractable hidden Markov model, andpresent an efficient learning algorithm for incorporating approximate bijectivity and symmetryconstraints.
Models estimated with these constraints produce a significant boost in performanceas measured by both precision and recall of manually annotated alignments for six languagepairs.
We also report experiments on two different tasks where word alignments are required:phrase-based machine translation and syntax transfer, and show promising improvements overstandard methods.1.
IntroductionThe seminal work of Brown et al (1993b) introduced a series of probabilistic models(IBM Models 1?5) for statistical machine translation and the concept of ?word-by-word?
alignment, the correspondence between words in source and target languages.Although no longer competitive as end-to-end translation models, the IBM Models,as well as the hidden Markov model (HMM) of Vogel, Ney, and Tillmann (1996),are still widely used for word alignment.
Word alignments are used primarily forextracting minimal translation units for machine translation (MT) (e.g., phrases [Koehn,Och, and Marcu 2003] and rules [Galley et al 2004; Chiang et al 2005]) as well as for?
INESC-ID Lisboa, Spoken Language Systems Lab, R. Alves Redol 9, 1000-029 LISBOA, Portugal.E-mail: joao.graca@l2f.inesc-id.pt.??
University of Pennsylvania, Department of Computer and Information Science, Levine Hall, 3330 WalnutStreet, Philadelphia, PA 19104-6309.
E-mail: kuzman@cis.upenn.edu.?
University of Pennsylvania, Department of Computer and Information Science, 3330 Walnut Street,Philadelphia, PA 19104-6389.
E-mail: taskar@cis.upenn.edu.Submission received: 1 August 2009; revised submission received: 24 December 2009; accepted forpublication: 10 March 2010.?
2010 Association for Computational LinguisticsComputational Linguistics Volume 36, Number 3MT system combination (Matusov, Ueffing, and Ney 2006).
But their importance hasgrown far beyond machine translation: for instance, transferring annotations betweenlanguages (Yarowsky and Ngai 2001; Hwa et al 2005; Ganchev, Gillenwater, andTaskar 2009); discovery of paraphrases (Bannard and Callison-Burch 2005); and jointunsupervised POS and parser induction across languages (Snyder and Barzilay 2008).IBM Models 1 and 2 and the HMM are simple and tractable probabilistic models,which produce the target sentence one target word at a time by choosing a source wordand generating its translation.
IBM Models 3, 4, and 5 attempt to capture fertility (thetendency of each source word to generate several target words), resulting in probabilis-tically deficient, intractable models that require local heuristic search and are difficult toimplement and extend.
Many researchers use the GIZA++ software package (Och andNey 2003) as a black box, selecting IBM Model 4 as a compromise between alignmentquality and efficiency.
All of the models are asymmetric (switching target and sourcelanguages produces drastically different results) and the simpler models (IBM Models 1,2, and HMM) do not enforce bijectivity (the majority of words translating as a singleword).
Although there are systematic translation phenomena where one cannot hope toobtain 1-to-1 alignments, we observe that in over 6 different European language pairsthe majority of alignments are in fact 1-to-1 (86?98%).
This leads to the common practiceof post-processing heuristics for intersecting directional alignments to produce nearlybijective and symmetric results (Koehn, Och, and Marcu 2003).In this article we focus on the HMM word alignment model (Vogel, Ney, andTillmann 1996), using a novel unsupervised learning framework that significantlyboosts its performance.
The new training framework, called Posterior Regulariza-tion (Grac?a, Ganchev, and Taskar 2007), incorporates prior knowledge in the form ofconstraints on the model?s posteriors.
The constraints are expressed as inequalities onthe expected value under the posterior distribution of user-defined features.
Althoughthe base model remains unchanged, learning guides the model to satisfy these con-straints.
We propose two such constraints: (i) bijectivity: one word should not translateto many words; and (ii) symmetry: directional alignments should agree.
Both of theseconstraints significantly improve the performance of the model both in precision andrecall, with the symmetry constraint generally producing more accurate alignments.Section 3 presents the Posterior Regularization (PR) framework and describes how toencode such constraints in an efficient manner, requiring only repeated inference in theoriginal model to enforce the constraints.
Section 4 presents a detailed evaluation ofthe alignments produced.
The constraints over posteriors consistently and significantlyoutperform the unconstrained HMM model, evaluated against manual annotations.Moreover, this training procedure outperforms the more complex IBM Model 4 ninetimes out of 12.
We examine the influence of constraints on the resulting posterior dis-tributions and find that they are especially effective for increasing alignment accuracyfor rare words.
We also demonstrate a new methodology to avoid overfitting using asmall development corpus.
Section 5 evaluates the new framework on two differenttasks that depend on word alignments.
Section 5.1 focuses on MT and shows that thebetter alignments also lead to better translation systems, adding to similar evidencepresented in Ganchev, Grac?a, and Taskar (2008).
Section 5.2 shows that the alignmentswe produce are better suited for transfer of syntactic dependency parse annotations.An implementation of this work (Grac?a, Ganchev, and Taskar 2009) is available under aGPL license.11 www.seas.upenn.edu/?strctlrn/CAT/.482Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraints2.
BackgroundA word alignment for a parallel sentence pair represents the correspondence betweenwords in a source language and their translations in a target language (Brown et al1993b).
There are many reasons why a simple word-to-word (1-to-1) correspondenceis not possible for every sentence pair: for instance, auxiliary verbs used in one lan-guage but not the other (e.g., English He walked and French Il est alle?
), articles requiredin one language but optional in the other (e.g., English Cars use gas and PortugueseOs carros usam gasolina), cases where the content is expressed using multiple wordsin one language and a single word in the other language (e.g., agglutination such asEnglish weapons of mass destruction and German Massenvernichtungswaffen), and expres-sions translated indirectly.
Due to this inherent ambiguity, manual annotations usuallydistinguish between sure correspondences for unambiguous translations, and possible,for ambiguous translations (Och and Ney 2003).
The top row of Figure 1 shows twoword alignments between an English?French sentence pair.
We use the following nota-tion: the alignment on the left (right) will be referenced as source?target (target?source)and contains source (target) words as rows and target (source) words as columns.
Eachentry in the matrix corresponds to a source?target word pair, and is the candidate for analignment link.
Sure links are represented as squares with borders, and possible linksFigure 1Posterior marginal distributions for different models for an English to French sentencetranslation.
Left: EN?FR model.
Right: FR?
EN model.
Top: Regular HMM posteriors.Middle: After applying bijective constraint.
Bottom: After applying symmetric constraint.
Surealignments are squares with borders; possible alignments are squares without borders.
Circlesize indicates probability value.
Circle color in the middle and bottom rows indicates differencesin posterior from the top row: green = higher probability; red = lower probability.483Computational Linguistics Volume 36, Number 3Table 1Test corpora statistics: English?French, English?Spanish, English?Portuguese,Portuguese?Spanish, Portuguese?French, and Spanish?French.Corpus Sentence Pairs Ave Length Max Length % Sure % 1-1En/Fr 447 16/17 30/30 21 98En/Es 400 29/31 90/99 67 86En/Pt 60 11/11 20/20 54 91Pt/Es 60 11/11 20/20 69 92Pt/Fr 60 11/12 20/20 77 88Es/Fr 60 11/12 20/20 79 87are represented as squares without borders.
Circles indicate the posterior probabilityassociated with a given link and will be explained latter.We use six manually annotated corpora whose characteristics are summarized inTable 1.
The corpora are: the Hansard corpus (Och and Ney 2000) of English/FrenchCanadian Parliamentary proceedings (En-Fr), and the English/Spanish portion of theEuroparl corpus (Koehn 2005) where the annotation is from EPPS (Lambert et al 2005)(En-Es) using standard test and development set split.
We also used the English/Portuguese (En-Pt), Portuguese/Spanish (Pt-Es), Portuguese/French (Pt-Fr), andSpanish/French (Es-Fr) portions of the Europarl corpus using annotations describedby Grac?a et al (2008), where we split the gold alignments into a dev/test set in a ratio of40%/60%.
Table 1 shows some of the variety of challenges presented by each corpus.For example, En-Es has longer sentences and hence more ambiguity for alignment.Furthermore, it has a smaller percentage of bijective (1-to-1) alignments, which makesword fertility more important.
Overall, the great majority of links are bijective acrossthe corpora (86?98%).
This characteristic will be explored by the constraints describedin this article.
For the evaluations in Section 4, the percentage of sure links (out of alllinks) will correlate with difficulty because only sure links are considered for recall.2.1 HMM Word Alignment ModelIn this article we focus on the HMM for word alignment proposed by Vogel, Ney, andTillmann (1996).
This model generalizes IBM Models 1 and 2 (Brown et al 1993b),by introducing a first-order Markov dependence between consecutive alignment linkdecisions.
The model is an (input?output) HMM with I positions whose hidden statesequence z = (z1, .
.
.
, zI ) with zi ?
{null, 1, .
.
.
, J} corresponds to a sequence of sourceword positions, where J is the source sentence length, and with null representing un-aligned target words.
Each observation corresponds to a word in the target language xi.The probability of an alignment z and target sentence x given a source sentence y canbe expressed as:p?
(x, z | y) =I?i=1pd(zi | zi?1)pt(xi | yzi ) (1)where pt(xi | yzi ) is the probability of a target word at position i being a translation of thesource word at position zi (translation probability), and pd(zi | zi?1) is the probability484Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraintsof translating a word at position zi, given that the previous translated word was atposition zi?1 (distortion probability).
Note that this model is directional: Each targetword (observation) can be aligned to at most one source word (hidden state), whereas asource word could be used multiple times.We refer to translation parameters pt and distortions parameters pd jointly as ?.There are several important standard details of the parametrization: The distortionprobability pd(zi | zi?1) depends only on the distance (zi ?
zi?1) between the source po-sitions the states represent.
Only distances in the range ?5 are modeled explicitly, withlarger distances assigned equal probabilities.
The probability of the initial hidden state,pd(z1 | z0) is modeled separately from the other distortion probabilities.
To incorporatenull links, we add a translation probability given null: pt(xi | ynull).
Following standardpractice, null links also maintain position information and do not allow distortion.
Toimplement this, we create position-specific null hidden states for each source position,and set pd(nulli|yi? )
= 0 and pd(nulli|nulli? )
= 0 for all i = i?.
The model is simple, withcomplexity of inference O(I ?
J2).
There are several problems with the model that arisefrom its directionality, however. Non-bijective: Multiple target words can be linked to a single sourceword.
This is rarely desirable.
For instance, the model producesnon-bijective links 22% of the time for En-Fr instead of 2%. Asymmetric: By switching the (arbitrary) choice of which language issource and which is target, the HMM produces very different results.
Forexample, intersecting the sets of alignments produced by the two possiblechoices for source preserves less than half of their union for both En-Frand En-Pt.22.2 TrainingStandard HMM training seeks model parameters ?
that maximize the log-likelihood ofthe parallel corpus:Log-Likelihood : L(?)
= ?E[log p?
(x | y)] = ?E[log?zp?
(x, z | y)] (2)where ?E[ f (x, y)] = 1N?Nn=1 f (xn, yn) denotes the empirical average of a function f (xn, yn)over the N pairs of sentences {(x1, y1) .
.
.
, (xN, yN )} in the training corpus.
Becauseof the latent alignment variables z, the log-likelihood function for the HMM modelis not concave, and the model is fit using the Expectation Maximization (EM) algo-rithm (Dempster, Laird, and Rubin 1977).
EM maximizes L(?)
via block-coordinateascent on a lower bound F(q, ?)
using an auxiliary distribution over the latent variablesq(z | x, y) (Neal and Hinton 1998):EM Lower Bound : L(?)
?
F(q, ?)
= ?E[?zq(z | x, y) log p?
(x, z | y)q(z | x, y)](3)2 For both of these points, see the experimental setup in Section 4.1.485Computational Linguistics Volume 36, Number 3To simplify notation, we will drop the dependence on y and will write p?
(x, z | y) asp?
(x, z), p?
(z | x, y) as p?
(z | x) and q(z | x, y) as q(z | x).
The alternating E and M stepsat iteration t + 1 are given by:E : qt+1(z | x) = arg maxq(z|x)F(q, ?t) = arg minq(z|x)KL(q(z | x) || p?t (z | x)) = p?t (z | x) (4)M : ?t+1 = arg max?F(qt+1, ?)
= arg max?
?E[?zqt+1(z | x) log p?
(x, z)](5)where KL(q||p) = Eq[log q(?)p(?)
] is the Kullback-Leibler divergence.
The EM algorithm isguaranteed to converge to a local maximum of L(?)
under mild conditions (Neal andHinton 1998).
The E step computes the posteriors qt+1(z | x) = p?t (z | x) over the latentvariables (alignments) given the observed variables (sentence pair) and current param-eters ?t, which is accomplished by the forward-backward algorithm for HMMs.
The Mstep uses qt+1 to ?softly fill in?
the values of alignments z and estimate parameters ?t+1.This step is particularly easy for HMMs, where ?t+1 simply involves normalizing (ex-pected) counts.
This modular split into two intuitive and straightforward steps accountsfor the vast popularity of EM.In Figure 1, each entry in the alignment matrix contains a circle indicating the align-ment link posterior for that particular word pair after training an HMM model with theEM algorithm (see the experimental set up in Section 4.1).
Note that the link posteriorsare concentrated around particular source words (rare words occurring less than fivetimes in the corpus) in both directions, instead of being spread across different words.This is a well-known problem when training using EM called the ?garbage collector ef-fect?
(Brown et al 1993a).
A rare word in the source language links to many words in thetarget language that we would ideally like to see unaligned, or aligned to other wordsin the sentence.
The reason this happens is that the generative model has to distributetranslation probability for each source word among different candidate target words.If one translation is much more common than another, but the rare translation is usedin the sentence, the model might have a very low translation probability for the correctalignment.
On the other hand, because the rare source word occurs only in a few sen-tences it needs to spread its probability mass over fewer competing translations.
In thiscase, choosing to align the rare word to all of these words leads to a higher likelihoodthan correctly linking them or linking them to the special null word, because it increasesthe likelihood of this sentence without lowering the likelihood of many other sentences.2.3 DecodingAlignments are normally predicted using the Viterbi algorithm (which selects the singlemost probable path through the HMM?s lattice).Another possibility that often works better is to use Minimum Bayes-Risk (MBR)decoding (Kumar and Byrne 2002; Liang, Taskar, and Klein 2006; Grac?a, Ganchev, andTaskar 2007).
Using this decoding we include an alignment link i ?
j if the posteriorprobability that word i aligns to word j is above some threshold.
This allows theaccumulation of probability from several low-scoring alignments that agree on onealignment link.
The threshold is tuned on some small amount of labeled data?inour case the development set?to minimize some loss.
Kumar and Byrne (2002) studydifferent loss functions that incorporate linguistic knowledge, and show significant486Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraintsimprovement over likelihood decoding.
Note that this could potentially result in analignment having zero probability under the model, as many-to-many alignments canbe produced in this way.
MBR decoding has several advantages over Viterbi decoding.First, independently of the particular choice of the loss function, by picking a specificthreshold we can trade off precision and recall of the predicted word alignments.
Infact, in this work when comparing different alignment sets we do not commit to anyloss function but instead compare precision vs recall curves, by generating alignmentsfor different thresholds (0..1).
Second, with this method we can ignore the null wordprobabilities, which tend to be poorly estimated.3.
Posterior RegularizationWord alignment models in general and the HMM in particular are very gross over-simplifications of the translation process and the optimal likelihood parameters learnedoften do not correspond to sensible alignments.
One solution to this problem is toadd more complexity to the model to better reflect the translation process.
This is theapproach taken by IBM Models 4+ (Brown et al 1993b; Och and Ney 2003), and morerecently by the LEAF model (Fraser and Marcu 2007).
Unfortunately, these changesmake the models probabilistically deficient and intractable, requiring approximationsand heuristic learning and inference prone to search errors.
Instead, we propose touse a learning framework called Posterior Regularization (Grac?a, Ganchev, and Taskar2007) that incorporates side information into unsupervised estimation in the form ofconstraints on the model?s posteriors.
The constraints are expressed as inequalities onthe expected values under the posterior distribution of user-defined constraint features(not necessarily the same features used by the model).
Because in most applicationswhat we are interested in are the latent variables (in this case the alignments), con-straining the posteriors allows a more direct way to achieve the desired behavior.On the other hand, constraining the expected value of the features instead of addingthem to the model allows us to express features that would otherwise make the modelintractable.
For example, enforcing that each hidden state of an HMM model should beused at most once per sentence would break the Markov property and make the modelintractable.
In contrast, we will show how to enforce the constraint that each hiddenstate is used at most once in expectation.
The underlying model remains unchanged,but the learning method changes.
During learning, our method is similar to the EMalgorithm with the addition of solving an optimization problem similar to a maximumentropy problem inside the E Step.
The following subsections present the PosteriorRegularization framework, followed by a description of how to encode two pieces ofprior information aimed at solving the problems described at the end of Section 2.3.1 Posterior Regularization FrameworkThe goal of the Posterior Regularization (PR) framework is to guide a model duringlearning towards satisfying some prior knowledge about the desired latent variables(in this case word alignments), encoded as constraints over their expectations.
Thekey advantage of using regularization on posterior expectations is that the base modelremains unchanged, but during learning, it is driven to obey the constraints by settingappropriate parameters ?.
Moreover, experiments show that enforcing constraints in ex-pectation results in predicted alignments that also satisfy the constraints.
More formally,posterior information in PR is specified with sets Qx of allowed distributions over the487Computational Linguistics Volume 36, Number 3hidden variables z which satisfy inequality constraints on some user-defined featureexpectations, with violations bounded by  ?
0:Constrained Posterior Set : Qx = {q(z | x) : ?
?, Eq[f(x, z)] ?
bx ?
?
; ||?||22 ?
2} (6)Qx denotes the set of valid distributions where some feature expectations are boundedby bx and  ?
0 is an allowable violation slack.
Setting  = 0 enforces inequalityconstraints strictly.
In order to introduce equality constraints, we use two inequalityconstraints with opposite signs.
We assume that Qx is non-empty for each example x.Furthermore, the set Qx needs to be convex.
In this work we restrict ourselves tolinear inequalities because, as will be shown, subsequently this simplifies the learningalgorithm.
Note that Qx, f(x, z), and bx also depend on y, the corresponding sourcesentence, but we suppress the dependence for brevity.
In PR, the log-likelihood of amodel is penalized with the KL-divergence between the desired distribution space Qxand the model posteriors, KL(Qx ?
p?
(z|x)) = minq(z|x)?QxKL(q(z | x) ?
p?(z|x)).
The regu-larized objective is:Posterior Regularized Likelihood : L(?)
?
?E[KL(Qx ?
p?(z|x))].
(7)The objective trades off likelihood and distance to the desired posterior subspace (mod-ulo getting stuck in local maxima) and provides an effective method of controlling theposteriors.Another way of interpreting the objective is to express the marginal log-likelihoodL(?)
as a KL distance: KL(?
(xn) ?
p?
(x)) where ?
(xn) is a delta function at xn.
Hence theobjective is a sum of two average KL terms, one in the space of distributions over x andone in the space of distributions over z:?L(?)
+ ?E[KL(Qx ?
p?
(z|x))] = 1NN?n=1KL(?
(xn) ?
p?
(x)) + KL(Qxn ?
p?
(z|xn)) (8)This view of the PR objective is illustrated in Figure 2.Figure 2Maximizing the PR objective is equivalent to minimizing the empirical average of twoKL divergences: The negative log-likelihood ?L(?)
= 1N?Nn=1 KL(?
(xn) ?
p?
(x)) plus posteriorregularization 1N?Nn=1 KL(Qxn ?
p?
(z|xn)), where ?
(xn) is a delta function at xn.
The diagramillustrates the effect of the likelihood term and the regularization term operating over the twospaces of distributions: the observed variables x and the latent variables z.
(The effect of the prioron ?
is not shown.
)488Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex ConstraintsComputing the PR objective involves solving the optimization problem for each x:Primal Projection : KL(Qx ?
p?
(z|x)) = minq(z|x)?QxKL(q(z | x) ?
p?
(z|x)) (9)Directly minimizing this objective is hard because there is an exponential number ofalignments z; however, the problem becomes easy to solve in its dual formulation (seeAppendix A for derivation):Dual Projection : arg min?
?0bx ?
+ log Z(?)
+  ||?||2 (10)where Z(?)
=?z p?
(z|x) exp(??
?
f(x, z)) is the normalization constant and the primalsolution is q(z|x) = p?
(z|x) exp{?
?f(x, z)}/Z(?).
There is one dual variable per ex-pectation constraint, and the dual gradient at ?
= 0 is ?(?)
= bx ?
Eq[f(x, z)] +  ?i||?||2 .Note that this primal?dual relationship is very similar to the one between maximumlikelihood and maximum entropy.
If bx corresponds to empirical expectations andp?
(z|x) is uniform, then Equation (10) would be a log-likelihood and Equation (14) (fol-lowing) would be a maximum entropy problem.
As with maximum entropy, gradientcomputation involves computing an expectation under q(z | x), which can be performedefficiently if the features f(x, z) factor in the same way as the model p?
(x, z), and theconstraints are linear.
The conditional distribution over z represented by a graphicalmodel such as HMM can be written as a product of factors over cliques C:Factored Posterior : p(z | x) = 1Z?c?C?
(x, zc) (11)In an HMM, the cliques C are simply the nodes zi and the edges (zi, zi+1) and the factorscorrespond to the distortion and translation probabilities.
We will assume f is factorizedas a sum over the same cliques (we will show below how symmetry and bijectivityconstraints can be expressed in this way):Factored Features : f(x, z) =?c?Cf(x, zc) (12)Then q(z | x) has the same form as p?
(z | x):q(z | x) = 1Zp(z | x) exp(?
?f(x, z)) = 1Z?c?C?
(x, zc) exp?
?f(x,zc ) (13)Hence the projection step uses the same inference algorithm (forward?backward forHMMs) to compute the gradient, only modifying the local factors using the currentsetting of ?.
?i ?
0;1while ||?(?
)||2 > ?
do2??
(x, zc) ?
?
(x, zc) exp?
?f(x,zc );3q(z | x) ?
forwardBackward(??
(x, zc));4?
?
?
+ ???(?
);5end6Algorithm 1: Computing KL(Qx ?
p?
(z|x)) = minq?QxKL(q(z|x) ?
p?
(z|x))489Computational Linguistics Volume 36, Number 3We optimize the dual objective using the gradient based methods shown inAlgorithm 1.
Here ?
is an optimization precision, ?
is a step size chosen with the strongWolfe?s rule (Nocedal and Wright 1999).
Here, ??(?)
represents an ascent directionchosen as follows: For inequality constraints, it is the projected gradient (Bertsekas1999); for equality constraints with slack, we use conjugate gradient (Nocedal andWright 1999), noting that when ?
= 0, the objective is not differentiable.
In practicethis only happens at the start of optimization and we use a sub-gradient for the firstdirection.Computing the projection requires an algorithm for inference in the original model,and uses that inference as a subroutine.
For HMM word alignments, we need to makeseveral calls to forward?backward in order to choose ?.
Setting the optimization pre-cision ?
more loosely allows the optimization to terminate more quickly but at a lessaccurate value.
We found that aggressive optimization significantly improves alignmentquality for both constraints we used and consequently choose ?
so that tighter valuesdo not significantly improve performance.
This explains why we report better resultshere in this paper than in Ganchev, Grac?a, and Taskar (2008), which uses a more naiveoptimization (see Section 4.1).3.2 Posterior Regularization via Expectation MaximizationWe can optimize the PR objective using a procedure very similar to the expectationmaximization (EM) algorithm.
Recall from Equation (4) that in the E step, q(z | x) isset to the posterior over hidden variables given the current ?.
To converge to the PRobjective, we must modify the E step so that q(z | x) is a projection of the posteriors ontothe constraint set Qx for each example x (Grac?a, Ganchev, and Taskar 2007).E?
: arg minq,?KL(q(z|x) ?
p?t (z|x)) s.t.
Eq[f(x, z)] ?
bx ?
?
; ||?||22 ?
2 (14)The new posteriors q(z|x) are used to compute sufficient statistics for this instance andhence to update the model?s parameters in the M step (Equation (5)), which remainsunchanged.
This scheme is illustrated in Figure 3 and in Algorithm 2.
The only imple-mentation difference is that we must now perform the KL projection before collectingsufficient statistics.
We found it can help to also perform this projection at test time,using q(z | x) = arg minq(z|x)?QxKL(q(z | x)|p?
(z | x)) instead of p?
(z | x) to decode.for t = 1..T do1for each training sentence x do2E?-Step: qt+1(z | x) = arg minq(z|x)?QxKL(q(z | x)||p?t (z | x))3end4M-Step: ?t+1 = arg max?
?E[?z qt+1(z | x) log p?
(z, x)]5end6Algorithm 2: PR optimization via modified EM.
E?-Step is computed usingAlgorithm 1.490Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex ConstraintsFigure 3Modified EM for optimizing PR objective L(?)
?
?E[KL(Qx ?
p?
(z|x))].3.3 Bijectivity ConstraintsWe observed in Table 1 that most alignments are 1-to-1 and we would like to introducethis prior information into the model.
Unfortunately including such a constraint in themodel directly breaks the Markov property in a fairly fundamental way.
In particularcomputing the normalization would require the summation of 1-to-1 or near 1-to-1weighted matchings, which is a classic #P-complete problem.
Introducing alignmentdegree constraints in expectation using the PR framework is easy and tractable.
Weencode them as the constraint E[f(x, z)] ?
1 where we have one feature f for each sourceword j that counts how many times it is aligned to a target word in the alignment z:Bijective Features : fj(x, z) =?i1(zi = j).The second row of Figure 1 shows an example of the posteriors after applying bijectivityconstraints; the first row is before the projection.
Green (respectively, red) circles indicatethat the probability mass for that particular link increased (respectively, decreased)when compared with the EM-trained HMM.
For example, in the top left panel, theword schism is used more than once, causing erroneous alignments.
Projecting to thebijectivity constraint set prevents this and most of the mass is (for this example) movedto the correct word pairs.
Enforcing the constraint at training and decoding increasesthe fraction of 1-to-1 alignment links from 78% to 97.3% for En-Fr (manual annotationshave 98.1%); for En-Pt the increase is from 84.7% to 95.8% (manual annotations have90.8%) (see Section 4.1).3.4 Symmetry ConstraintsThe directional nature of the generative models used to recover word alignments con-flicts with their interpretation as translations.
In practice, we see that the choice of whichlanguage is source versus target matters and changes the mistakes made by the model(the first row of panels in Figure 1).
The standard approach is to train two modelsindependently and then intersect their predictions (Och and Ney 2003).
However, weshow that it is much better to train two directional models concurrently, couplingtheir posterior distributions over alignments to approximately agree.
Let the directionalmodels be defined as: ?
?p (?
?z ) (source?target) and ?
?p (?
?z ) (target?source).
We suppressdependence on x and y for brevity.
Define z to range over the union of all possible491Computational Linguistics Volume 36, Number 3directional alignments?
?Z ??
?Z .
We define a mixture model p(z) = 12?
?p (z) + 12?
?p (z)where ?
?p (?
?z ) = 0 and vice versa (i.e., the alignment of one directional model has prob-ability zero according to the other model).
We then define the following feature for eachtarget?source position pair i, j:Symmetric Features : fij(x, z) =????
?+1 z ?
?
?Z and ?
?z i = j?1 z ?
?
?Z and ?
?z j = i0 otherwise.If the feature fij has an expected value of zero, then both models predict the i, j linkwith equal probability.
We therefore impose the constraint Eq[ fij(x, z)] = 0 (possibly withsome small slack).
Note that satisfying this implies satisfying the bijectivity constraintpresented earlier.
To compute expectations of these features under the model q we onlyneed to be able to compute them under each directional HMM.
To see this, we have bythe definition of q?
and p?,q?
(z|x) =?
?p (z | x) + ?
?p (z | x)2exp{?
?f(x, z)}Z?=?
?q (z|x) Z??q?
?p (x) +?
?q (z|x) Z??q?
?p (x)2Z?
(15)where we have defined:?
?q (z|x) = 1Z??q?
?p (z, x) exp{?
?f(x, z)} with Z?
?q =?z?
?p (z, x) exp{?
?f(x, z)}?
?q (z|x) = 1Z??q?
?p (z, x) exp{?
?f(x, z)} with Z?
?q =?z?
?p (z, x) exp{?
?f(x, z)}All these quantities can be computed separately in each model using forward?backwardand, furthermore, Z?
= 12 (Z??q?
?p (x) +Z??q?
?p (x) ).
The effect of this constraint is illustrated inthe bottom panels of Figure 1.
The projected link posteriors are equal for the twomodels, and in most cases the probability mass was moved to the correct alignmentlinks.
The exception is the word pair internal/le.
In this case, the model chose to incor-rectly have a high posterior for the alignment link rather than generating internal fromnull in one direction and le from null in the other.We can measure symmetry of predicted alignments as the ratio of the size of theintersection to the size of the union.
Symmetry constraints increase symmetry from 48%to 89.9% for En-Fr and from 48% to 94.2% for En-Pt (see Section 4.1).4.
Alignment Quality EvaluationWe begin with a comparison of word alignment quality evaluated against manuallyannotated alignments as measured by precision and recall.
We use the six parallelcorpora with gold annotations described in the beginning of Section 2.4.1 Experimental SetupWe discarded all training data sentence pairs where one of the sentences containedmore than 40 words.
Following common practice, we added the unlabeled developmentand test data sets to the pool of unlabeled sentences.
We initialized the IBM Model 1translation table with uniform probabilities over word pairs that occur together in thesame sentence and trained the IBM Model 1 for 5 iterations.
All HMM alignment models492Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraintswere initialized with the translation table from IBM Model 1 and uniform distortionprobabilities.
We run each training procedure until the area under the precision/recallcurve measured on a development corpus stops increasing (see Figure 4 for an exampleof such a curve).
Using the precision/recall curve gives a broader sense of the model?sperformance than using a single point (by tuning a threshold for a particular metric).
Inmost cases this meant four iterations for normal EM training and two iterations usingposterior regularization.
We suspect that the constraints make the space easier to search.The convergence criterion for the projection algorithm was the normalized l2 normof the gradient (gradient norm divided by number of constraints) being smaller than?
(see Algorithm 1).
For bijective constraints, we set ?
to 0.005 and used zero slack.For symmetric constraints, ?
and slack were set to 0.001.
We chose ?
aggressivelyand lower values did not significantly increase performance.
Less aggressive settingscause degradation of performance: For example, for En-Fr using 10k sentences, andrunning four iterations of constrained EM, the area under the precision/recall curve forthe symmetric model changed from 70% with ?
= 0.1 to 85% using ?
= 0.001.
On theother hand, the number of iterations required to project the constraints increases forsmaller values of ?.
The number of forward?backward calls for normal HMM is 40k(one for each sentence and EM iteration), for the symmetric model using ?
= 0.1 wasaround 41k and using ?
= 0.001 was around 26M (14 minutes to 4 hours 14 minutesof training time, 17 times slower, for the different settings of ?).
We note that betteroptimization methods, such as L-BFGS, or using a warm start for the parameters at eachEM iteration (parameters from the previous iteration), or training the models online,would potentially decrease the running time of our method.The intent of this experimental section is to evaluate the gains from using con-straints during learning, hence the main comparison is between HMM trained withnormal EM vs. trained with PR plus constraints.
We also report results for IBM Model 4,because it is often used as the default word alignment model, and can be used as areference.
However, we would like to note that IBM Model 4 is a more complex model,able to capture more structure, albeit at the cost of intractable inference.
Because ourapproach is orthogonal to the base model used, the constraints described here couldbe applied in principle to IBM Model 4 if exact inference was efficient, hopefullyyielding similar improvements.
We used a standard implementation of IBM Model4 (Och and Ney 2003) and because changing the existing code is not trivial, we couldnot use the same stopping criterion to avoid overfitting and we are not able to produceprecision/recall curves.
We trained IBM Model 4 using the default configuration of theFigure 4Precision/Recall curves for different models using 1,000k sentences.
Precision on the horizontalaxis.
Left: Hansard EN-FR direction.
Right: EN-PT Portuguese-English direction.493Computational Linguistics Volume 36, Number 3Figure 5Word alignment precision when the threshold is chosen to achieve IBM Model 4 recall with adifference of ?
0.005.
The average relative increase in precision (against the HMM model) is10% for IBM Model 4, 11% for B-HMM, and 14% for S-HMM.MOSES training script.3 This performs five iterations of IBM Model 1, five iterations ofHMM, and five iterations of IBM Model 4.4.2 Alignment ResultsIn this section we present results on alignment quality.
All comparisons are made usingMBR decoding because this decoding method always outperforms Viterbi decoding.4For the models with constraints we project the posteriors at decode time (i.e., we useq(z | x) to decode).
This gives a small but consistent improvement.
Figure 4 showsprecision/recall curves for the different models on the En-Fr corpus using English asthe source language (left), and on the En-Pt corpus using Portuguese as the source.Precision/recall curves are obtained by varying the posterior threshold from 0 to 1 andthen plotting the different precision and recall values obtained.We observe several trends from Figure 4.
First, both types of constraints improveover the HMM in terms of both precision and recall (their precision/recall curve isalways above).
Second, S-HMM performs slightly better than B-HMM.
IBM Model 4is comparable with both constraints (after symmetrization).
The results for all languagepairs are in Figure 5.
For ease of comparison, we choose a decoding threshold for HMMmodels to achieve the recall of the corresponding IBM Model 4 and report precision.Our methods always improve over the HMM by 10% to 15%, and improve over IBMModel 4 nine times out of 12.
Comparing the constraints with each other we see that3 www.statmt.org/moses/?n=FactoredTraining.HomePage.4 IBM Model 4 uses Viterbi decoding as Giza++ does not support MBR decoding.494Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex ConstraintsFigure 6Word alignment precision as a function of training data size (number of sentence pairs).Posterior decoding threshold chosen to achieve IBM Model 4 recall in the Hansard corpus.
Right:English as source.
Left: French as source.S-HMM performs better than B-HMM in 10 out of 12 cases.
Because S-HMM indirectlyenforces bijectivity and models sequential correlations on both sides, this is perhaps notsurprising.Figure 6 shows performance as a function of training data size.
As before, we decodeto achieve the recall of IBM Model 4.
For small training corpora adding the constraintsprovides larger improvements (20?30%) but we still achieve significant gains even witha million parallel sentences (15%).
Greater improvements for small data sizes indicatethat our approach can be especially effective for resource-poor language pairs.4.3 Rare vs. Common WordsOne of the main benefits of using the posterior regularization constraints described isan alleviation of the garbage collector effect (Brown et al 1993a).
Figure 7 breaks downperformance improvements by common versus rare words.
As before, we use posteriordecoding, tuning the threshold to match IBM Model 4 recall.
For common words, thistuning maintains recall very close for all models so we do not show this in the figure.
Inthe top left panel of Figure 7, we see that precision of common words follows the patternwe saw for the corpus overall: Symmetric and bijective outperform both IBM Model 4and the baseline HMM, with symmetric slightly better than bijective.
The results forcommon words vary more slowly as we increase the quantity of training data than theydid for the full corpus.
In the top right panel of Figure 7 we show the precision for rarewords.
For the baseline HMM as well as for IBM Model 4, this is very low preciselybecause of the garbage collector problem: Rare words become erroneously aligned tountranslated words, leading to low precision.
In fact the constrained models achieveabsolute precision improvements of up to 50% over the baseline.
By removing theseerroneous alignments the translation table becomes more accurate, allowing higher re-call on the full corpus.
In the bottom panel of Figure 7, we observe a slightly diminishedrecall for rare words.
This slight drop in recall is due to moving the mass correspondingto rare words to null.4.4 SymmetrizationAs discussed earlier, the word alignment models are asymmetric, whereas most appli-cations require a single alignment for each sentence pair.
Typically this is achieved bya symmetrization heuristic that takes two directional alignments and produces a single495Computational Linguistics Volume 36, Number 3Figure 7Precision and Recall as a function of training data size for En-Fr by common and rare words.Top Left: Common Precision, Top Right: Rare Precision, Bottom: Rare Recall.alignment.
For MT the most commonly used heuristic is called grow diagonal final(Och and Ney 2003).
This starts with the intersection of the sets of aligned points andadds points around the diagonal that are in the union of the two sets of aligned points.The alignment produced has high recall relative to the intersection and only slightlylower recall than the union.
In syntax transfer the intersection heuristic is normallyused, because one wants to have high precision links to transfer knowledge betweenlanguages.
One pitfall of these symmetrization heuristics is that they can obfuscate thelink between the original alignment and the ones used for a specific task, making errorsmore difficult to analyze.
Because they are heuristics tuned for a particular phrase-based translation system, it is not clear when they will help and when they will hindersystem performance.
In this work we followed a more principled approach that usesFigure 8Precision/recall curves for the different models after soft union symmetrization.
Precision is onthe horizontal axis.
Left EN-FR, Right PT-ES.496Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraintsthe knowledge about the posterior distributions of each directional model.
We include apoint in the final alignment if the average of the posteriors under the two models for thatpoint is above a threshold.
This heuristic is called soft union (DeNero and Klein 2007).Figure 8 shows the Precision/Recall curves after symmetrization for the En-Fr corpus.The posterior regularization?trained models still performed better, but the differencesget smaller after doing the symmetrization.
This should not be very surprising, becausethe soft union symmetrization can be viewed as an approximation of our symmetryconstraint applied only at decode time.
Applying the symmetrization to the model withsymmetry constraints does not affect performance.4.5 AnalysisIn this section we discuss some scenarios in which the constraints make the alignmentsbetter, and some scenarios where they fail.
We have already discussed the garbagecollector effect and how both models address it.
Both of the constraints also bias themodel to have at most probability one in any row or column of the posterior matrix,encouraging 1-to-1 alignments.
Obviously whenever alignments are systematically not1-to-1 , this can lead to errors (for instance the examples described in Section 2).An example presented in Figure 9 shows the posterior marginal distributions for anEnglish/French sentence pair using the same notation as in Figure 1.
In the top panel ofFigure 9Posterior distributions for different models for an English to French sentence translation.
Left:EN?FR model.
Right: FR?
EN model.
Top: Regular HMM posteriors.
Middle: After applyingthe bijective constraint.
Bottom: After applying the symmetric constraint.
Sure alignments aresquares with borders; possible alignments are squares without borders.
Circle size indicatesprobability value.
Circle color in the middle and bottom rows indicates differences in posteriorfrom the top row; green = higher probability; red = lower probability.497Computational Linguistics Volume 36, Number 3Figure 9, we see the baseline models, where the English word met is incorrectly beingaligned to se?ance est ouverte.
This makes it impossible to recover the correct alignmenthouse/se?ance.
Either constraint corrects this problem.
On the other hand, by enforcinga 1-to-1 mapping the correct alignment met / est ouverte is lost.
Going back to the firstrow (regular HMM) this alignment is correct in one direction and absent in the other(due to the many-to-1 model restriction) but we can recover that information using thesymmetrization heuristics, since the point is present at least in one direction with highprobability mass.
This is not the case for the constraint-based models that reduce themass of that alignment in both directions.
Going back to the right panel of Figure 8, wecan see that for low values of precision the HMM model actually achieves better recallthan the constraint-based methods.
There are two possible solutions to alleviate thistype of problem, both with their caveats.
One solution is to model the fertility of eachword in a way similar to IBM Model 4, or more generally to model alignments of multi-ple words.
This can lead to significant computational burden, and is not guaranteed toimprove results.
A more complicated model may require approximations that destroyits performance gain, or require larger corpora to estimate its parameters.
Anotheroption is to perform some linguistically motivated pre-processing of the language pairto conjoin words.
This of course has the disadvantage that it needs to be specific to alanguage pair in order to include information such as ?English simple past is writtenusing a single word, so join together French passe?
compose?.?
An additional problemwith joining words to alleviate inter-language divergences is that it can increase datasparsity.5.
Task-Specific Alignment EvaluationIn this section we evaluate the alignments resulting from using the proposed constraintsin two different tasks: Statistical machine translation where alignments are used torestrict the number of possible minimal translation units; and syntax transfer, wherealignments are used to decide how to transfer dependency links.5.1 Phrase-Based Machine TranslationWe now investigate whether our alignments produce improvements in an end-to-endphrase-based machine translation system.
We use a state-of-the-art machine translationsystem,5 and follow the experimental setup used for the 2008 shared task on machinetranslation (ACL 2008 Third Workshop on Statistical Machine Translation).
The fullpipeline consists of the following steps: (1) prepare the data (lowercase, tokenize, andfilter long sentences); (2) build language models; (3) create word alignments in eachdirection; (4) symmetrize directional word alignments; (5) build phrase table; (6) tuneweights for the phrase table.
For more details consult the shared task description.6 Toevaluate the quality of the produced alignments, we keep the pipeline unchanged, anduse the models described earlier to generate the word alignments in Step 3.
For Step 4,we use the soft union symmetrization heuristic.
Symmetrization has almost no effect onalignments produced by S-HMM, but we use it for uniformity in the experiments.
Wetested three values of the threshold (0.2, 0.4, 0.6) which try to capture different tradeoffs5 The open source Moses (Hoang et al 2007) toolkit from www.statmt.org/moses/.6 www.statmt.org/wmt08/baseline.html.498Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex ConstraintsTable 2BLEU scores for all language pairs.
The best threshold was selected according to thedevelopment set after the last MERT iteration.
Bold denotes the best score.Fr ?
En En ?
Fr Es ?
En En ?
Es Pt ?
En En ?
PtIBM M4 GDF 35.7 31.2 32.4 31.6 31.4 28.9HMM SU 35.9 28.9 32.3 31.6 30.9 31.6B-HMM SU 36.0 31.5 32.6 31.7 31.0 32.2S-HMM SU 35.5 31.2 31.9 32.5 31.4 32.3of precision vs. recall, and pick the best according to the translation performance ondevelopment data.
Table 2 summarizes the results for the different corpora.
For refer-ence we include IBM Model 4 as suggested in the task description.
PR training alwaysoutperforms EM training and outperforms IBM Model 4 in all but one experiment.Differences in BLEU range from 0.2 to 0.9.
The two constraints help to a different extentfor different corpora and translation directions, in a somewhat unpredictable manner.In general our impression is that the connection between alignment quality and BLEUscores is complicated, and changes are difficult to explain and justify.
The number ofiterations for MERT optimization to converge varied from 2 to 28; and the best choice ofthreshold on the development set did not always correspond to the best on the test set.Contrary to conventional wisdom in the MT community, bigger phrase tables did notalways perform better.
In 14 out of 18 cases, the threshold picked was 0.4 (medium sizephrase tables) and the other four times 0.2 was picked (smaller phrase tables).
Whenwe include only high confidence alignments, more phrases are extracted but many ofthese are erroneous.
Potentially this leads to a poor estimate of the phrase probabilities.See Lopez and Resnik (2006) for further discussion.5.2 Syntax TransferIn this section, we compare the different alignments produced with and without PRbased on how well they can be used for transfer of linguistic resources across languages.We used the system proposed by Ganchev, Gillenwater, and Taskar (2009).
This systemuses a word-aligned corpus and a parser for a resource-rich language (source language)in order to create a parser for a resource-poor language (target language).
We considera parse tree on the source language as a set of dependency edges to be transferred.
Foreach such edge, if both end points are aligned to words in the target language, thenthe edge is transferred.
These edges are then used as weak supervision when traininga generative or discriminative dependency parser.
In order to evaluate the alignmentswe computed the fraction of correctly transferred edges as a function of the averagenumber of edges transferred by using supervised parse trees on the target side.
Bychanging the threshold in MBR decoding of alignments, we can trade off accuracy of thetransferred edges vs. transferring more edges.
We generated supervised parses usingthe first-order model from the MST parser (McDonald, Crammer, and Pereira 2005)trained on the Penn Treebank for English and the CoNLL X parses for Bulgarian andSpanish.
Following Ganchev, Gillenwater, and Taskar (2009), we filter alignment linksbetween words with incompatible POS tags.
Figure 10 shows our results for transferringfrom English to Bulgarian (En?Bg) and from English to Spanish (En?Es).
The En?Bg499Computational Linguistics Volume 36, Number 3Figure 10Edge conservation for cross-lingual grammar induction.
Left: En?Bg subtitle corpus; Right:En?Es parliamentary proceedings.
Vertical axis: percentage of transferred edges that are correct.Horizontal axis: average number of transferred edges per sentence.results are based on a corpus of movie subtitles (Tiedemann 2007), and are consequentlyshorter sentences, whereas the En?Es results are based on a corpus of parliamentaryproceedings (Koehn 2005).
We see in Figure 10 that for both domains, the models trainedusing posterior regularization perform better than the baseline model trained using EM.6.
Related WorkThe idea of introducing constraints over a model to better guide the learning processhas appeared before.
In the context of word alignment, Deng and Byrne (2005) use astate-duration HMM in order to model word-to-phrase translations.
The fertility of eachsource word is implicitly encoded in the durations of the HMM states.
Without anyrestrictions, likelihood prefers to always use longer phrases and the authors try to con-trol this behavior by multiplying every transition probability by a constant ?
> 1.
Thisencourages more transitions and hence shorter phrases.
For the task of unsuperviseddependency parsing, Smith and Eisner (2006) add a constraint of the form ?the averagelength of dependencies should be X?
to capture the locality of syntax (at least halfof the dependencies are between adjacent words), using a scheme they call structuralannealing.
They modify the model?s distribution over trees p?
(y) by a penalty termas: p??
(y) ?
p?(y)e(?
?e?y length(e)), where length(e) is the surface length of edge e. Thefactor ?
changes from a high value to a lower one so that the preference for short edges(hence a smaller sum) is stronger at the start of training.These two approaches also have the goal of controlling unsupervised learning, andthe form of the modified distributions is reminiscent of the form that the projectedposteriors take.
However, the approaches differ substantially from PR.
Smith and Eisner(2006) make a statement of the form ?scale the total length of edges?, which dependingon the value of ?
will prefer to have more shorter/longer edges.
Such statements arenot data dependent.
Depending on the value of ?, for instance if ?
?
0, even if the datais such that the model already uses too many short edges on average, this value of?
will push for more short edges.
By contrast the statements we can make in PR areof the form ?there should be more short edges than long edges?.
Such a statement isdata-dependent in the sense that if the model satisfies the constraints then we do notneed to change it; if it is far from satisfying it we might need to make very dramaticchanges.500Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex ConstraintsPR is closely related to the work of Mann and McCallum (2007, 2008), who concur-rently developed the idea of using penalties based on posterior expectations of featuresto guide semi-supervised learning.
They call their method generalized expectation (GE)constraints or alternatively expectation regularization.
In the original GE framework,the posteriors of the model on unlabeled data are regularized directly.
They train adiscriminative model, using conditional likelihood on labeled data and an ?expectationregularization?
penalty term on the unlabeled data:arg max?Llabeled(?)
?
??E[||Ep?
[f(x, z) ?
b||22].
(16)Notice that there is no intermediate distribution q.
For some kinds of constraints thisobjective is difficult to optimize in ?
and in order to improve efficiency, Bellare, Druck,and McCallum (2009) propose interpreting the PR framework as an approximationto the GE objective in Equation (16).
They compare the two frameworks on severaldata sets and find that performance is similar.
Liang, Jordan, and Klein (2009) castthe problem of incorporating partial information about latent variables into a Bayesianframework using ?measurements,?
and after several approximation steps, they arriveat the objective we optimize.The idea of jointly training two directional models has been explored by Liang,Taskar, and Klein (2006), although under a very different formalization.
They de-fine a joint objective max?1,?2?E[log?
?p ?1 (x) + log?
?p ?2 (x) + log?z?
?p ?1 (z | x)?
?p ?2 (z | x)].
However, theproduct distribution ?
?p ?1 (z | x)?
?p ?2 (z | x) ranges over all one-to-one alignments andcomputing it is #P-complete (Liang, Taskar, and Klein 2006).
They approximate thisdistribution as a product of marginals: q(z) =?i,j?
?p ?1 (zi,j | x)?
?p ?2 (zi,j | x), but it is notclear what objective the approximate procedure actually optimizes.7.
ConclusionIn this article we explored a novel learning framework, Posterior Regularization, forincorporating rich constraints over the posterior distributions of word alignments.
Wefocused on the HMM word alignment model, and showed how we could incorpo-rate complex constraints like bijectivity and symmetry while keeping the inferencein the model tractable.
Using these constraints we showed consistent and significantimprovements in six different language pairs even when compared to a more complexmodel such as IBM Model 4.
In addition to alleviating the ?garbage collector?
effect, weshow that the obtained posterior distributions better reflect the desired alignments.
Bothconstraints are biasing the models towards 1-to-1 alignments, which may be inappro-priate in some situations, and we show some systematic mistakes that the constraintsintroduce and suggest possible fixes.We experimented with two different tasks that rely on word alignments, phrase-based MT and syntax transfer.
For phrase-based MT, the improved alignments leadto a modest increase in BLEU performance.
For syntax transfer, we have shown thatthe number of edges of a dependency tree that can be accurately transferred from onelanguage to another increases as a result of improved alignments.Our framework opens up the possibility of efficiently adding many other con-straints that are directly applicable to word alignments, such as preferring alignmentsthat respect dependency tree structure, part of speech tags, or syntactic boundaries.501Computational Linguistics Volume 36, Number 3Appendix A: Modified E-Step Dual DerivationThe modified E step involves a projection step that minimizes the Kullback-Leiblerdivergence:E?
: arg minq(z|x),?KL( q(z|x) ?
p?
(z|x)) s.t.
Eq[f(x, z)] ?
bx ?
?
; ||?||22 ?
2.Assuming the set Qx = { q(z|x) : ?
?, Eq[f(x, z)] ?
bx ?
?
; ||?||22 ?
2} is non-empty, thecorresponding Lagrangian is max?,?,?minq(z|x),?L( q(z|x), ?, ?, ?, ?)
with ?
?
0 and ?
?
0,whereL( q(z|x), ?, ?, ?, ?)
= KL( q(z|x) ?
p?
(z|x)) + ?(Eq[f(x, z)] ?
bx ?
?
)+ ?
(||?||22 ?
2) + ?
(?zq(z|x) ?
1)?L( q(z|x), ?, ?, ?, ?)?
q(z|x) = log( q(z|x)) + 1 ?
log( p?
(z|x)) + ?f(x, z) + ?
= 0=?
q(z|x) = p?
(z|x) exp(?
?f(x, z))e exp(?
)?L( q(z|x), ?, ?, ?, ?)?
?i= 2?
?i ?
?i = 0 =?
?i =?i2?Plugging q(z|x) and ?
in L( q(z|x), ?, ?, ?, ?)
and taking the derivative with respect to ?
:?L(?, ?, ?)??
=?zp?
(z|x) exp(?
?f(x, z))e exp(?)?
1 = 0 =?
?
= log(?z p?
(z|x) exp(?
?f(x, z))e )Simplifying q(z|x) = p?
(z|x) exp(?
?f(x,z))Z?where Z?
=?z p?
(z|x) exp(?
?f(x, z)) en-sures that q(z|x) is properly normalized.
Plugging ?
into L(?, ?, ?)
and taking thederivative with respect to ?, we get:L(?, ?)
= ?
log(Z?)
?
bx ??||?||222?
+||?||224?
?
?2 (A.1)?L(?, ?)??
=||?||222?2?
||?||224?2?
2 = 0 =?
?
= ||?||22 (A.2)Replacing back into L(?, ?)
we get the dual objective:Dual E?
: arg max?
?0?bx ??
log(Z?)
?
||?||2  (A.3)AcknowledgmentsJ.
V. Grac?a was supported by a fellowshipfrom Fundac?a?o para a Cie?ncia e Tecnologia(SFRH/ BD/ 27528/ 2006) and by FCTproject CMU-PT/HuMach/0039/2008.K.
Ganchev was partially supported byNSF ITR EIA 0205448.
Ben Taskar waspartially supported by DARPA CSSG2009 grant.ReferencesBannard, Colin and Chris Callison-Burch.2005.
Paraphrasing with bilingual parallelcorpora.
In ACL ?05: Proceedings of the43rd Annual Meeting of the Association forComputational Linguistics, pages 597?604,Morristown, NJ.Bellare, Kedar, Gregory Druck, and AndrewMcCallum.
2009.
Alternating projections502Grac?a, Ganchev, and Taskar Learning Alignment Models with Complex Constraintsfor learning with expectation constraints.In Proceedings of the Twenty-Fifth ConferenceAnnual Conference on Uncertainty inArtificial Intelligence, pages 43?50,Corvallis, OR.Bertsekas, Dimitri P. 1999.
NonlinearProgramming: 2nd Edition.
AthenaScientific, Nashua, NH.Brown, Peter F., Stephen A. Della Pietra,Vincent J. Della Pietra, Meredith J.Goldsmith, Jan Hajic, Robert L. Mercer,and Surya Mohanty.
1993a.
Butdictionaries are data too.
In HLT ?93:Proceedings of the Workshop on HumanLanguage Technology, pages 202?205,Morristown, NJ.Brown, Peter F., Stephen A. Della Pietra,Vincent J. Della Pietra, and Robert L.Mercer.
1993b.
The mathematics ofstatistical machine translation: Parameterestimation.
Computational Linguistics,19(2):263?311.Chiang, David, Adam Lopez, NitinMadnani, Christof Monz, Philip Resnik,and Michael Subotin.
2005.
The Hieromachine translation system: Extensions,evaluation, and analysis.
In Proceedingsof the Human Language TechnologyConference and Conference on EmpiricalMethods in Natural Language Processing,pages 779?786, Vancouver.Dempster, Arthur P., Nan M. Laird, andDonald B. Rubin.
1977.
Maximumlikelihood from incomplete data via theem algorithm.
Royal Statistical Society,Series B, 39(1):1?38.DeNero, John and Dan Klein.
2007.
Tailoringword alignments to syntactic machinetranslation.
In Proceedings of the 45thAnnual Meeting of the Association ofComputational Linguistics, pages 17?24,Prague.Deng, Yonggang and William Byrne.
2005.HMM word and phrase alignment forstatistical machine translation.
In HLT ?05:Proceedings of the Conference on HumanLanguage Technology and EmpiricalMethods in Natural Language Processing,pages 169?176, Morristown, NJ.Association for Computational Linguistics.Fraser, Alexander and Daniel Marcu.
2007.Getting the structure right for wordalignment: Leaf.
In Proceedings of the JointConference on Empirical Methods in NaturalLanguage Processing and ComputationalNatural Language Learning(EMNLP-CoNLL), pages 51?60, Prague.Galley, Michel, Mark Hopkins, Kevin Knight,and Daniel Marcu.
2004.
What?s in atranslation rule?
In HLT-NAACL 2004:Main Proceedings, pages 273?280,Boston, MA.Ganchev, Kuzman, Jennifer Gillenwater, andBen Taskar.
2009.
Dependency grammarinduction via bitext projection constraints.In ACL-IJCNLP ?09: Proceedings of the JointConference of the 47th Annual Meetingof the ACL and the 4th International JointConference on Natural Language Processingof the AFNLP: Volume 1, pages 369?377,Morristown, NJ.Ganchev, Kuzman, Joa?o V. Grac?a, and BenTaskar.
2008.
Better alignments = bettertranslations?
In Proceedings of ACL-08: HLT,pages 986?993, Columbus, OH.Grac?a, Joa?o V., Kuzman Ganchev, and BenTaskar.
2007.
Expectation maximizationand posterior constraints.
In J. C. Platt,D.
Koller, Y.
Singer, and S. Roweis, editors,Advances in Neural Information ProcessingSystems 20.
MIT Press, Cambridge, MA,pages 569?576.Grac?a, Joa?o V., Kuzman Ganchev, andBen Taskar.
2009.
Postcat - posteriorconstrained alignment toolkit.
The PragueBulletin Of Mathematical Linguistics - SpecialIssue: Open Source Tools for MachineTranslation, 91:27?37.Grac?a, Joa?o V., Joana P. Pardal, Lu?
?sa Coheur,and Diamantino Caseiro.
2008.
Buildinga golden collection of parallelmulti-language word alignment.
InProceedings of the Sixth InternationalLanguage Resources and Evaluation(LREC?08), Marrakech.Hoang, Hieu, Alexandra Birch, ChrisCallison-Burch, Richard Zens, RwthAachen, Alexandra Constantin, MarcelloFederico, Nicola Bertoldi, Chris Dyer,Brooke Cowan, Wade Shen, ChristineMoran, and Ondrej Bojar.
2007.
Moses:Open source toolkit for statistical machinetranslation.
In Proceedings of the 45thAnnual Meeting of the Association forComputational Linguistics CompanionVolume Proceedings of the Demo and PosterSessions, pages 177?180, Prague.Hwa, Rebecca, Philip Resnik, AmyWeinberg, Clara Cabezas, and Okan Kolak.2005.
Bootstrapping parsers via syntacticprojection across parallel texts.
NaturalLanguage Engineering, 11:11?311.Koehn, Philipp.
2005.
Europarl: A parallelcorpus for statistical machine translation.In Machine Translation Summit,12?15 September, Phuket.Koehn, Philipp, Franz Josef Och, and DanielMarcu.
2003.
Statistical phrase-based503Computational Linguistics Volume 36, Number 3translation.
In Proceedings of the 2003Conference of the North American Chapter ofthe Association for Computational Linguisticson Human Language Technology (NAACL),pages 48?54, Morristown, NJ.Kumar, Shankar and William Byrne.
2002.Minimum Bayes-Risk word alignments ofbilingual texts.
In Proceedings of the ACL-02Conference on Empirical Methods in NaturalLanguage Processing, pages 140?147,Philadelphia, PA.Lambert, Patrik, Adria` De Gispert, RafaelBanchs, and Jose?
B. Marino.
2005.Guidelines for word alignment evaluationand manual alignment.
Language Resourcesand Evaluation, 39(4):267?285.Liang, Percy, Michael I. Jordan, and DanKlein.
2009.
Learning from measurementsin exponential families.
In ICML ?09:Proceedings of the 26th Annual InternationalConference on Machine Learning,pages 641?648, New York, NY.Liang, Percy, Ben Taskar, and Dan Klein.2006.
Alignment by agreement.
InProceedings of the Human LanguageTechnology Conference of the NAACL, MainConference, pages 104?111, New York, NY.Lopez, Adam and Philip Resnik.
2006.Word-based alignment, phrase-basedtranslation: Whats the link?
In Proceedingsof the 7th Conference of the Association forMachine Translation in the Americas(AMTA): Visions for the Future of MachineTranslation, pages 90?99, Boston, MA.Mann, G. and A. McCallum.
2007.
Simple,robust, scalable semi-supervised learningvia expectation regularization.
InProceedings of the 24th InternationalConference on Machine Learning, page 600,Corvallis, OR.Mann, Gideon S. and Andrew McCallum.2008.
Generalized expectation criteriafor semi-supervised learning ofconditional random fields.
In Proceedingsof ACL-08: HLT, pages 870?878,Columbus, OH.Matusov, Evgeny, Nicola Ueffing, andHermann Ney.
2006.
Computingconsensus translation from multiplemachine translation systems usingenhanced hypotheses alignment.
InProceedings of the EACL, pages 33?40,Cambridge.McDonald, Ryan, Koby Crammer, andFernando Pereira.
2005.
Onlinelarge-margin training of dependencyparsers.
In ACL ?05: Proceedings of the43rd Annual Meeting of the Association forComputational Linguistics, pages 91?98,Morristown, NJ.Neal, Radford M. and Geoffrey E. Hinton.1998.
A new view of the EM algorithm thatjustifies incremental, sparse and othervariants.
In M. I. Jordan, editor, Learning inGraphical Models.
Kluwer, Amsterdam,pages 355?368.Nocedal, Jorge and Stephen J. Wright.1999.
Numerical Optimization.
Springer,Berlin.Och, Franz Josef and Hermann Ney.
2000.Improved statistical alignment models.In ACL ?00: Proceedings of the 38thAnnual Meeting on Association forComputational Linguistics, pages 440?447,Morristown, NJ.Och, Franz Josef and Hermann Ney.
2003.A systematic comparison of variousstatistical alignment models.
ComputationalLinguistics, 29(1):19?51.Smith, Noah A. and Jason Eisner.
2006.Annealing structural bias in multilingualweighted grammar induction.
In ACL-44:Proceedings of the 21st InternationalConference on Computational Linguistics andthe 44th Annual Meeting of the Association forComputational Linguistics, pages 569?576,Morristown, NJ.Snyder, Benjamin and Regina Barzilay.2008.
Unsupervised multilingual learningfor morphological segmentation.
InProceedings of ACL-08: HLT, pages 737?745,Columbus, OH.Tiedemann, Jo?rg.
2007.
Building amultilingual parallel subtitle corpus.
InProceedings of the 17th Conference onComputational Linguistics in the Netherlands(CLIN 17), Leuven.Vogel, Stephan, Hermann Ney, andChristoph Tillmann.
1996.
Hmm-basedword alignment in statistical translation.In Proceedings of the 16th Conference onComputational Linguistics, pages 836?841,Morristown, NJ.Yarowsky, David and Grace Ngai.
2001.Inducing multilingual POS taggers and NPbracketers via robust projection acrossaligned corpora.
In Proceedings of the NorthAmerican Chapter Of The Association ForComputational Linguistics, pages 1?8,Morristown, NJ.504
