Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1437?1447,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsContext-dependent Semantic Parsing for Time ExpressionsKenton Lee?, Yoav Artzi?, Jesse Dodge?
?, and Luke Zettlemoyer?
?Computer Science & Engineering, University of Washington, Seattle, WA{kentonl, yoav, lsz}@cs.washington.edu?Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PAjessed@cs.cmu.eduAbstractWe present an approach for learningcontext-dependent semantic parsers toidentify and interpret time expressions.We use a Combinatory Categorial Gram-mar to construct compositional meaningrepresentations, while considering contex-tual cues, such as the document creationtime and the tense of the governing verb,to compute the final time values.
Exper-iments on benchmark datasets show thatour approach outperforms previous state-of-the-art systems, with error reductions of13% to 21% in end-to-end performance.1 IntroductionTime expressions present a number of challengesfor language understanding systems.
They haverich, compositional structure (e.g., ?2nd Friday ofJuly?
), can be easily confused with non-temporalphrases (e.g., the word ?May?
can be a monthname or a verb), and can vary in meaning in dif-ferent linguistic contexts (e.g., the word ?Friday?refers to different dates in the sentences ?We meton Friday?
and ?We will meet on Friday?).
Recov-ering the meaning of time expressions is thereforechallenging, but provides opportunities to studycontext-dependent language use.
In this paper, wepresent the first context-dependent semantic pars-ing approach for learning to identify and interprettime expressions, addressing all three challenges.Existing state-of-the-art methods use hand-engineered rules for reasoning about time expres-sions (Str?otgen and Gertz, 2013).
This includesboth detection, identifying a phrase as a time ex-pression, and resolution, mapping such a phraseinto a standardized time value.
While rule-basedapproaches provide a natural way to express ex-pert knowledge, it is relatively difficult to en-?Work conducted at the University of Washington.code preferences between similar competing hy-potheses and provide prediction confidence.
Re-cently, methods for learning probabilistic seman-tic parsers have been shown to address such limi-tations (Angeli et al, 2012; Angeli and Uszkoreit,2013).
However, these approaches do not accountfor any surrounding linguistic context and weremainly evaluated with gold standard mentions.We propose to use a context-dependent se-mantic parser for both detection and resolutionof time expressions.
For both tasks, we makeuse of a hand-engineered Combinatory Catego-rial Grammar (CCG) to construct a set of mean-ing representations that identify the time beingdescribed.
For example, this grammar maps thephrase ?2nd Friday of July?
to the meaning repre-sentation intersect(nth(2 , friday), july), whichencodes the set of all such days.
Detection is thenperformed with a binary classifier to prune the setof text spans that can be parsed with the gram-mar (e.g., to tell that ?born in 2000?
has a timeexpression but ?a 2000 piece puzzle?
does not).For resolution, we consider mentions sequentiallyand use a log-linear model to select the most likelymeaning for each.
This choice depends on contex-tual cues such as previous time expressions andthe tense of the governing verb (e.g., as requiredto correctly resolve cases like ?We should meet onthe 2nd Friday of July?
).Such an approach provides a good balance be-tween hand engineering and learning.
For the rel-atively closed-class time expressions, we demon-strate that it is possible to engineer a high qualityCCG lexicon.
We take a data-driven approach forgrammar design, preferring a grammar with highcoverage even if it results in parsing ambiguities.We then learn a model to accurately select betweencompeting parses and incorporate signals from thesurrounding context, both more difficult to modelwith deterministic rules.For both problems, we learn from TimeML an-1437notations (Pustejovsky et al, 2005), which markmentions and the specific times they reference.Training the detector is a supervised learningproblem, but resolution is more challenging, re-quiring us to reason about latent parsing andcontext-dependent decisions.We evaluate performance in two domains: theTempEval-3 corpus of newswire text (Uzzaman etal., 2013) and the WikiWars corpus of Wikipediahistory articles (Mazur and Dale, 2010).
On thesebenchmark datasets, we present new state-of-the-art results, with error reductions of up to 28% forthe detection task and 21% for the end-to-end task.2 Formal OverviewTime Expressions We follow the TIMEX3 stan-dard (Pustejovsky et al, 2005) for defining timeexpressions within documents.
Let a documentD = ?w1, .
.
.
, wn?
be a sequence of n words wiand a mention m = (i, j) indicate start and endindices for a phrase ?wi, .
.
.
, wj?
in D. Definea time expression e = (t, v) to include both atemporal type t and value v.1The temporal typet ?
{Date, Time, Duration, Set} can take one offour possible values, indicating if the expressione is a date (e.g., ?January 10, 2014?
), time (e.g.,?11:59 pm?
), duration (e.g., ?6 months?
), or set(e.g., ?every year?).
The value v is an extensionof the ISO 8601 standard, which encodes the timethat mentionm refers to in the context provided bydocument D. For example, in a document writtenon Tuesday, January 7, 2014, ?Friday,?
?three dayslater,?
and ?January 10th?
would all resolve to thevalue 2014-01-10.
The time values are similarlydefined for a wide range of expressions, such asunderspecified dates (e.g., XXXX-01-10 for ?Ja-nunary 10th?
when the year is not inferable fromcontext) and durations (P2D for ?two days?
).Tasks Our goal is to find all time expressions inan input document.
We divide the problem intotwo parts: detection and resolution.
The detectionproblem is to take an input documentD and outputa mention set M = {mi| i = 1 .
.
.
n} of phrasesin D that describe time expressions.
The resolu-tion problem (often also called normalization) is,given a document D and a set of mentions M , to1Time expressions also have optional modifier valuesfor non-TIMEX properties (e.g., the modifier would containEARLY for the phrase ?early march?).
We do recover thesemodifiers but omit them from the discussion since they arenot part of the official evaluation metrics.map each m ?
M to the referred time expressione.
This paper addresses both of these tasks.Approach We learn separate, but related, mod-els for detection and resolution.
For both tasks, wedefine the space of possible compositional mean-ing representations Z , where each z ?
Z definesa unique time expression e. We use a log-linearCCG (Steedman, 1996; Clark and Curran, 2007)to rank possible meanings z ?
Z for each men-tion m in a document D, as described in Sec-tion 4.
Both detection (Section 5) and resolution(Section 6) rely on the semantic parser to identifylikely mentions and resolve them within context.For learning we assume access to TimeML datacontaining documents labeled with time expres-sions.
Each document D has a set {(mi, ei)|i =1 .
.
.
n}, where each mention mimarks a phrasethat resolves to the time expression ei.Evaluation We evaluate performance (Sec-tion 8) for both newswire text and Wikipediaarticles.
We compare to the state-of-the-artsystems for end-to-end resolution (Str?otgen andGertz, 2013) and resolution given gold men-tions (Bethard, 2013b), both of which do not useany machine learning techniques.3 Representing TimeWe use simply typed lambda calculus to representtime expressions.
Our representation draws heav-ily from the representation proposed by Angeli etal.
(2012), who introduced semantic parsing forthis task.
There are five primitive types: durationd, sequence s, range r, approximate reference a,and numeral n, as described below.
Table 1 liststhe available constants for each type.Duration A period of time.
Each duration is amultiple of one of a closed set of possible basedurations (e.g., hour, day, and quarter), whichwe refer to as its granularity.
Table 1 includes thecomplete set of base durations used.Range A specific interval of time, following aninterval-based theory of time (Allen, 1981).
Theinterval length is one of the base durations, whichis the granularity of the range.
Given two rangesR and R?, we say that R ?
R?if the endpoints ofR lie on or within R?.Sequence A set of ranges with identical granu-larity.
The granularity of the sequence is that ofits members.
For example, thursday , which has a1438Type Primitive ConstantsDuration second , minute , hour , timeofday , day ,month , season , quarter , weekend ,week , year , decade , century , temp dSequence monday , tuesday , wednesday ,thursday , friday , saturday , sunday ,january , february , march , april ,may , june , july , august , september ,october , november , december , winter ,spring , summer , fall , night , morning ,afternoon , eveningRange ref timeApproximatereferencepresent , future , past , unknownNumeral 1 , 2 , 3 , 1999 , 2000 , 2001 , .
.
.Table 1: The types and primitive logical constants sup-ported by the logical language for time.day granularity, denotes the set of all day-granularranges enclosing specific Thursdays.
Given arange R and sequence S, we say that R ?
S ifR is a member of S. Given two sequences S andS?we say that S ?
S?if R ?
S implies R ?
S?.Approximate Reference An approximate timerelative to the reference time.
For example, pastand future.
To handle mentions such as ?a while,?we add the constant unknown .Numeral An integer, for example, 5 or 1990 .Numerals are used to denote specific ranges, suchas the year 2001, or to modify a duration?s length.Functions We also allow for functional types,for example ?s, r?
is assigned to a function thatmaps from sequences to ranges.
Table 2 lists allsupported functions with example mentions.Context Dependent Constants To mark placeswhere context-dependent choices will need to bemade during resolution, we use two placeholderconstants.
First, ref time denotes the mention ref-erence time, which is later set to either the docu-ment time or a previously resolved mention.
Sec-ond, temp d is used in the shift function to deter-mine its return granularity, as described in Table 2,and is later replaced with the granularity of eitherthe first or second argument of the enclosing shiftfunction.
Section 4.3 describes how these deci-sions are made.4 Parsing Time ExpressionsWe define a three-step derivation to resolve men-tions to their TIMEX3 value.
First, we use a CCGto generate an initial logical form for the mention.Next, we apply a set of operations that modify theone week agoC N NP\NP1 week ?x.shift(ref time,?1 ?
x, temp d)N/N?x.1 ?
x>N1 ?
weekNP1 ?
week<NPshift(ref time,?1 ?
1 ?
week , temp d)Figure 1: A CCG parse tree for the mention ?one weekago.?
The tree includes forward (>) and backward (<)application, as well as two type-shifting operationsinitial logical form, as appropriate for its context.Finally, the logical form is resolved to a TIMEX3value using a deterministic process.4.1 Combinatory Categorial GrammarsCCG is a linguistically motivated categorial for-malism for modeling a wide range of languagephenomena (Steedman, 1996; Steedman, 2000).
ACCG is defined by a lexicon and a set of combina-tors.
The lexicon pairs words with categories andthe combinators define how to combine categoriesto create complete parse trees.For example, Figure 1 shows a CCG parse treefor the phrase ?one week ago.?
The parse tree isread top to bottom, starting from assigning cate-gories to words using the lexicon.
The lexical en-try ago ` NP\NP : ?x.shift(ref time,?1 ?x, temp d) for the word ?ago?
pairs it with a cate-gory that has syntactic type NP\NP and seman-tics ?x.shift(ref time,?1 ?
x, temp d).
Eachintermediate parse node is then constructed by ap-plying one of a small set of binary or unary opera-tions (Steedman, 1996; Steedman, 2000), whichmodify both the syntax and semantics.
We usebackward (<) and forward (>) application andseveral unary type-shifting rules to handle numbercombinations.
For example, in Figure 1 the cate-gory of the span ?one week?
is combined with thecategory of ?ago?
using backward application (<).Parsing concludes with a logical form representingthe meaning of the complete mention.Hand Engineered Lexicon To parse time ex-pressions, we use a CCG lexicon that includes 287manually designed entries, along with automati-cally generated entries such as numbers and com-mon formats of dates and times.
Figure 2 showsexample entries from our lexicon.1439Function Description ExampleOperations on durations.??n,?d,d?
?Given a duration D and a numeral N , return a duration D?that is N times longer than D.?after three days of questioning?3?
daysome?d,d?Given a durationD, returnsD?, s.t.
D?is the result ofD?nfor some n > 1.?he left for a few days?some(day)seq?d,s?Given a duration D, generate a sequence S, s.t.
S includesall ranges of type D.?went to last year?s event?previous(seq(year), ref time)Operations for extracting a specific range from a sequence.this?s,?r,r?
?Given a sequence S and a range R, returns the range R?
?S, s.t.
there exists a range R?
?where R ?
R?
?and R??R?
?, and the length of R?
?is minimal.
?a meeting this friday?this(friday, ref time)next?s,?r,r??previous?s,?r,r?
?Given a sequenceS and a rangeR, returns the range R??
Sthat is the one after/before this(S,R).
?arriving next month?next(seq(month), ref time)nearest forward?s,?r,r?
?nearest backward?s,?r,r?
?Given a sequenceS and a rangeR, returns the range R??
Sthat is closest to R in the forward/backward direction.
?during the coming weekend?nearest forward(seq(weekend), ref time)Operations for sequences.nth?n,?s,?s,s???nth?n,?s,s?
?Given a number N , a sequence S and a sequence S?, returnsa sequence S???
S s.t.
for each Q ?
S?
?there existsP ?
S?and Q is the N -th entry in S that is a sub-intervalof P .
For the two-argument version, we use heuristics toinfer the third argument by determining a sequence of highergranularity that is likely to contain the second argument.
?until the second quarter of the year?nth(2 , seq(quarter), seq(year))intersect?s,?s,s?
?Given sequences S, S?, where the duration of entries in S isshorter than these in S?, return a sequence S???
S, wherefor each R ?
S?
?there exists R??
S?s.t.
R ?
R?.
?starts on June 28?intersect(june,nth(28 , seq(day),seq(month)))shift?r,?d,?d,r??
?Given a range R, a duration D, and a duration G, return therange R?, s.t.
the starting point of R?is moved by the lengthof D. R?is converted to represent a range of granularity Gby expanding if G has larger granularity, and is undefined ifG has smaller granularity.
?a week ago, we went home?shift(ref time,?1 ?
1 ?
week , temp d)Operations on numbers.??n,?n,n?
?Given two numerals, N?and N?
?, returns a numeral N??
?representing their product N??N??.
?the battle lasted for one hundred days?1 ?
100 ?
day+?n,?n,n?
?Given two numerals, N?and N?
?, returns a numeral N??
?representing their sum N?+ N??.
?open twenty four hours?
(20 + 4)?
hourOperations to mark sequences for specific TIMEX3 type annotations.every?s,s?Given a sequence S, returns a sequence with SET temporaltype.
?one dose each day?every(seq(day))bc?s,s?Convert a year to BC.
?during five hundred BC?bc(nth(500 , seq(year)))Table 2: Functional constants used to build logical expressions for representing time.Manually Designed Entries:several ` NP/N : ?x.some(x)this ` NP/N : ?x.this(x, ref time)each ` NP/N : ?x.every(x)before ` N\NP/NP :?x.
?y.shift(x,?1 ?
y, temp d)year ` N : yearwednesday ` N : wednesday?20s ` N : nth(192 , seq(decade))yesterday ` N : shift(ref time,?1 ?
day , temp d)Automatically Generated Entries:1992 ` N : nth(1992 , seq(year))nineteen ninety two ` N : nth(1992 , seq(year))09:30 ` N : intersect(nth(10 , seq(hour), seq(day)),nth(31 , seq(minute), seq(hour)))3rd ` N\N :?x.intersect(x,nth(3 , seq(day), seq(month)))Figure 2: Example lexical entries.4.2 Context-dependent OperationsTo correctly resolve mentions to TIMEX3 val-ues, the system must account for contextual in-formation from various sources, including previ-ous mentions in the document, the document cre-ation time, and the sentence containing the men-tion.
We consider three types of context opera-tions, each takes as input a logical form z?, mod-ifies it and returns a new logical form z. Eachcontext-dependent parse y specifies one operatorof each type, which are applied to the logical formconstructed by the CCG grammar, to produce thefinal, context-dependent logical form LF(y).Reference Time Resolution The logical con-stant ref time is replaced by either dct , repre-senting the document creation time, or last range,the last r-typed mention resolved in the document.For example, consider the mention ?the follow-ing year?, which is represented using the logicalform next(seq(year), ref time).
Within the sen-tence ?1998 was colder than the following year?,the resolution of ?the following year?
depends onthe previous mention ?1998?.
In contrast, in ?Thefollowing year will be warmer?, its resolution de-pends on the document creation time.1440Directionality Resolution If z?is s-typedwe modify it to nearest forward(z?, ref time),nearest backward(z?, ref time), or z?.
For ex-ample, given the sentence ?.
.
.
will be launchedin april?, the mention ?april?, and its logi-cal form april , we would like to resolve it tothe coming April, and therefore modify it tonearest forward(april , ref time).Shifting Granularity Every occurrence of thelogical constant temp d , which is used as an ar-gument to the function shift (see Table 2), is re-placed with the granularity of either the first argu-ment, the origin of the shift, or the second argu-ment, the delta of the shift.
This determines thefinal granularity of the output.
For example, if thereference time is 2002-01, the mention ?two yearsearlier?
would resolve to either a month (since thereference time is of month granularity) or a year(since the delta is of year granularity).4.3 Resolving Logical FormsFor a context-dependent parse y, we compute theTIMEX3 value TM(y) from the logical form z =LF(y) with a deterministic step that performs asingle traversal of z.
Each primitive logical con-stant from Table 1 contributes to setting part of theTIMEX3 value (for example, specifying the day ofthe week) and the functional constants in Table 2dictate transformations on the TIMEX3 values (forexample, shifting forward or backward in time).25 DetectionThe detection problem is to take an input docu-ment D and output a mention set M = {mi| i =1, .
.
.
, n}, where each mention miindexes a spe-cific phrase in D that delimits a time expression.Algorithm The detection algorithm considersall phrases that our CCG grammar ?
(Section 4)can parse, uses a learned classifier to further filterthis set, and finally resolves conflicts between anyoverlapping predictions.
We use a CKY algorithmto efficiently determine which phrases the CCGgrammar can parse and only allow logical formsfor which there exists some context in which theywould produce a valid time expression, e.g.
rul-ing out intersect(monday , tuesday).
Finally, webuild the set M of non-overlapping mentions us-ing a step similar to non-maximum suppression:2The full details are beyond the scope of this paper, but animplementation is available on the author?s website.the mentions are sorted by length (longest first)and iteratively added to M , as long as they do notoverlap with any mention already in M .Filtering Model Given a mention m, its docu-ment D, a feature function ?, the CCG lexicon ?,and feature weights ?, we use a logistic regressionmodel to define the probability distribution:P (t|m,D; ?, ?)
=e???(m,D,?
)1 + e???(m,D,?
)where t indicates whether m is a time expression.Features We use three types of indicator fea-tures that test properties of the words in andaround the potential mention m.Context tokens Indicate the presence of a set ofmanually specified tokens near the mention.
Theseinclude quotations around the mention, the word?old?
after the mention, and prepositions of time(such as ?in?, ?until?, and ?during?)
before.Part of speech Indicators that pair each wordwith its part of speech, as assigned by the Stanfordtagger (Toutanova et al, 2003).Lexical group Each lexical entry belongs to oneof thirteen manually defined lexical groups whichcluster entries that contribute to the final time ex-pression similarly.
These groups include numbers,days of the week, months, seasons, etc.
For eachgroup, we include a feature indicating whether theparse includes a lexical entry from that group.Determiner dependency Indicates the presenceof a determiner in the mention and whether its par-ent in the dependency tree (generated by the Stan-ford parser (de Marneffe et al, 2006)) also resideswithin the mention.Learning Finally, we construct the training databy considering all spans that (1) the CCG tempo-ral grammar can parse and (2) are not strict sub-spans of an annotated mention.
All spans that ex-actly matched the gold labels are used as positiveexamples and all others are negatives.
Given thisrelaxed data, we learn the feature weights ?
withL1-regularization.
We set the probability thresh-old for detecting a time expression by optimizingthe F1 score over the training data.6 ResolutionThe resolution problem is to, given a document Dand a set of mentions M , map each m ?
M tothe correct time expression e. Section 4 defined1441the space of possible time expression that can beconstructed for an input mention m in the contextof a document D. In general, there will be manydifferent possible derivations, and we will learn amodel for selecting the best one.Model Let y be a context-dependent CCG parse,which includes a parse tree TR(y), a set of contextoperations CNTX(y) applied to the logical format the root of the tree, a final context-dependentlogical form LF(y) and a TIMEX3 value TM(y).Define ?
(m,D, y) ?
Rdto be a d-dimensionalfeature?vector representation and ?
?
Rdto be aparameter vector.
The probability of a parse y formention m and document D is:P (y|m,D; ?,?)
=e???(m,D,y)?y?e???(m,D,y?
)The inference problem at test time requires find-ing the best resolution by solving y?
(m,D) =arg maxyP (y|m,D; ?,?
), where the final outputTIMEX3 value is TM(y?
(m,D)).Inference We find the best context-dependentparse y by enumeration, as follows.
We firstparse the input mention m with a CKY-style algo-rithm, following previous work (Zettlemoyer andCollins, 2005).
Due to the short length of timeexpressions and the manually constructed lexicon,we can perform exact inference.
Given a parse,we then enumerate all possible outcomes for thecontext resolution operators.
In practice, there arenever more than one hundred possibilities.Features The resolution features test propertiesof the linguistic context surrounding the mentionm, relative to the context-dependent CCG parse y.Governor verb We define the governor verb to bethe nearest ancestor verb in the dependency parseof any token in m. We include features indicat-ing the concatenation of the part-of-speech of thegovernor verb, its auxiliary verb if present, andthe selected direction resolution operator (see Sec-tion 4.2).
This feature helps to distinguish ?Theymet on Friday?
from ?They will meet on Friday.
?Temporal offset If the final logical form LF (y)is a range, we define t to be the time differencebetween TM(y) and the reference time.
For ex-ample, if the reference time is 2000-01-10 and themention resolves to 2000-01-01, then t is -9 days.This feature indicates one of eleven bucketed val-ues for t, including same day, less than a week,less than a month, etc.
It allows the model to en-code the likely temporal progression of a narrative.This feature is ignored if the granularity of TM(y)or the reference time is greater than a year.Shift granularity The logical constant shift (Ta-ble 2) takes three arguments: the origin (range),the delta (duration), and the output granularity(duration).
This indicator feature is the concate-nation of each argument?s granularity for everyshift in LF (y).
It allows the model to determinewhether ?a year ago?
refers to a year or a day.Reference type Let r denote whether the refer-ence time is the document creation time dct or thelast range last range.
Let gland grdenote thegranularities of LF (y) and the reference time, re-spectively.
We include features indicating the con-catenations: r+gl, r+gr, and r+gl+gr.
Addition-ally, we include features indicating the concatena-tion of r with each lexical entry used in the parseTR(y).
These features allow the model to encodepreferences in selecting the correct reference time.Fine-grained type These features indicate thefine-grained type of TM(y), such as day of themonth or week of the year.
We also include a fea-ture indicating the concatenation of each of thesefeatures with the direction resolution operator thatwas used.
These features allow the model to repre-sent, for example, that minutes of the year are lesslikely than days of the month.Intersections These features indicate the concate-nation of the granularities of any two sequencesthat appear as arguments to an intersect constant.Learning To estimate the model parameters ?we assume access to a set of training examples{(mi, di, ei) : i = 1, .
.
.
, n}, where each mentionmiis paired with a document diand a TIMEX3value ei.
We use the AdaGrad algorithm (Duchiet al, 2011) to optimize the conditional, marginallog-likelihood of the data.
For each mention, wemarginalize over all possible context-dependentparses, using the predictions from the model on theprevious gold mentions to fill in missing context,where necessary.
After parameter estimation, weset a probability threshold for retaining a resolvedtime expression by optimizing value F1 (see Sec-tion 8) over the training data.7 Related WorkSemantic parsers map sentences to logical repre-sentations of their underlying meaning, e.g., Zelle1442and Mooney (1996), Zettlemoyer and Collins(2005), and Wong and Mooney (2007).
Re-cently, research in this area has focused on learn-ing for various forms of relatively weak but eas-ily gathered supervision.
This includes learn-ing from question-answer pairs (Clarke et al,2010; Liang et al, 2011; Kwiatkowski et al,2013), from conversational logs (Artzi and Zettle-moyer, 2011), with distant supervision (Krish-namurthy and Mitchell, 2012; Cai and Yates,2013), and from sentences paired with system be-havior (Goldwasser and Roth, 2011; Chen andMooney, 2011; Artzi and Zettlemoyer, 2013b).Recently, Angeli et al introduced the idea oflearning semantic parsers to resolve time expres-sions (Angeli et al, 2012) and showed that the ap-proach can generalize to multiple languages (An-geli and Uszkoreit, 2013).
Similarly, Betharddemonstrated that a hand-engineered semanticparser is also effective (Bethard, 2013b).
How-ever, these approaches did not use the semanticparser for detection and did not model linguisticcontext during resolution.We build on a number of existing algorithmicideas, including using CCGs to build meaningrepresentations (Zettlemoyer and Collins, 2005;Zettlemoyer and Collins, 2007; Kwiatkowski etal., 2010; Kwiatkowski et al, 2011), buildingderivations to transform the output of the CCGparser based on context (Zettlemoyer and Collins,2009), and using weakly supervised parameter up-dates (Artzi and Zettlemoyer, 2011; Artzi andZettlemoyer, 2013b).
However, we are the first touse a semantic parsing grammar within a mentiondetection algorithm, thereby avoiding the need torepresent the meaning of complete sentences, andthe first to develop a context-dependent model forsemantic parsing of time expressions.Time expressions have been extensively stud-ied as part of the TimeEx task, including 9 teamswho competed in the 2013 TempEval-3 com-petition (Uzzaman et al, 2013).
This line ofwork builds on ideas from TimeBank (Puste-jovsky et al, 2003) and a number of differentformal models for temporal reasoning, e.g.
Allen(1983), Moens and Steedman (1988).
In 2013,HeidelTime (Str?otgen and Gertz, 2013) was thetop performing system.
It used deterministic rulesdefined over regular expressions to perform bothdetection and resolution, and will provide a com-parison system for our evaluation in Section 9.
InCorpus Doc.
Token TimeExTempEval-3 (Dev) 256 95,391 1,822TempEval-3 (Test) 20 6,375 138WikiWars (Dev) 17 98,746 2,228WikiWars (Test) 5 19,052 363Figure 3: Corpus statistics.general, many different rule-based systems, e.g.NavyTime (Chambers, 2013) and SUTime (Changand Manning, 2012), and learning systems, e.g.ClearTK (Bethard, 2013a) and MANTime (Filan-nino et al, 2013), did well for detection.
How-ever, rule-based approaches dominated in resolu-tion; none of the top performers attempted to learnto do resolution.
Our approach is a hybrid of rulebased and learning, by using latent-variable learn-ing techniques to estimate CCG parsing and con-text resolution models from the provided data.8 Experimental SetupData We evaluate performance on theTempEval-3 (Uzzaman et al, 2013) and Wiki-Wars (Mazur and Dale, 2010) datasets.
Figure 3shows summary statistics for both datasets.
Forthe TempEval-3 corpus, we use the given trainingand testing set splits.
Since the training sethas lower inter-annotator agreement than thetesting set (Uzzaman et al, 2013), we manuallycorrected all of the mistakes we found in thetraining data.3The original training set is denotedDev* and the corrected Dev.
We report (1)cross-validation development results on Dev*, (2)cross-validation development and ablation resultsfor Dev, and (3) held-out test results after trainingwith Dev.
For WikiWars, we randomly assignedthe data to include 17 training documents (2,228time expressions) and 5 test documents (363 timeexpressions).
We use cross-validation on the train-ing data for development.
All cross-validationexperiments used 10 folds.Implementation Our system was implementedusing the open source University of WashingtonSemantic Parsing Framework (Artzi and Zettle-moyer, 2013a).
We used LIBLINEAR (Fan et al,2008) to learn the detection model.Parameter Settings We use the same set of pa-rameters for both datasets, chosen based on devel-opment experiments.
For detection, we set the reg-ularization parameter to 10 with a stopping crite-3We modified the annotations for 18% of the mentions.This relabeled corpus is available on the author?s website.1443SystemStrict Detection Relaxed Detection Type Res.
Value ResolutionPre.
Rec.
F1 Pre.
Rec.
F1 Acc.
F1 Acc.
Pre.
Rec.
F1Dev*This work 84.6 83.4 84.0 92.8 91.5 92.1 94.6 87.1 84.0 77.9 76.8 77.4HeidelTime 83.7 83.4 83.5 91.7 91.4 91.6 95.0 87.0 84.1 77.1 76.8 77.0DevThis work 92.7 89.6 91.1 97.4 94.1 95.7 97.1 92.9 91.5 89.1 86.1 87.6Context ablation 92.7 89.3 91.0 97.5 93.9 95.7 97.1 92.9 89.8 87.6 84.3 85.9HeidelTime 90.2 84.8 87.4 96.5 90.7 93.5 96.1 89.9 88.4 85.3 80.2 82.7TestThis work 86.1 80.4 83.1 94.6 88.4 91.4 93.4 85.4 90.2 85.3 79.7 82.4HeidelTime 83.9 79.0 81.3 93.1 87.7 90.3 90.9 82.1 86.0 80.1 75.4 77.7NavyTime 78.7 80.4 79.6 89.4 91.3 90.3 88.9 80.3 78.6 70.3 71.8 71.0ClearTK 85.9 79.7 82.7 93.8 87.0 90.2 93.3 84.2 71.7 67.3 62.4 64.7Figure 4: TempEval-3 development and test results, compared to the top systems in the shared task.SystemStrict Detection Relaxed Detection Value ResolutionPre.
Rec.
F1 Pre.
Rec.
F1 Acc.
Pre.
Rec.
F1DevThis work 90.3 83.0 86.5 98.1 90.1 93.9 87.6 85.9 78.9 82.3Context ablation 90.9 80.1 85.2 98.2 86.5 92.0 68.5 67.3 59.3 63.0HeidelTime 86.0 75.3 80.3 95.4 83.5 89.0 90.5 86.3 75.6 80.6TestThis work 87.7 78.8 83.0 97.6 87.6 92.3 84.6 82.5 74.1 78.1HeidelTime 85.2 79.3 82.1 92.6 86.2 89.3 83.7 77.5 72.1 74.7Figure 5: WikiWars development and test results.rion of 0.01.
For resolution, we set the learningrate to 0.25 and ran AdaGrad for 5 iterations.
Allfeatures are initialized to have zero weights.Evaluation Metrics We use the officialTempEval-3 scoring script and report the standardmetrics.
We report detection precision, recall andF1 with relaxed and strict metrics; a gold mentionis considered detected for the relaxed metric ifany of the output candidates overlap with it and isdetected for the strict metric if the extent of anyoutput candidates matches exactly.
For resolution,we report value accuracy, measuring correctnessof time expressions detected according to therelaxed metric.
We also report value precision,recall, and F1, which score an expression ascorrect if it is both correctly detected (relaxed)and resolved.
For end-to-end performance, valueF1 is the primary metric.
Finally, we reportaccuracy and F1 for temporal types, as defined inSection 2, for the TempEval dataset (WikiWarsdoes not include type labels).Comparison Systems We compare our systemprimarily to HeidelTime (Str?otgen and Gertz,2013), which is state of the art in the end-to-end task.
For the TempEval-3 dataset, we alsocompare to two other strong participants of theshared task.
These include NavyTime (Chambers,2013), which had the top relaxed detection score,and ClearTK (Bethard, 2013a), which had the topstrict detection score and type F1 score.
We alsoinclude a comparison with Bethard?s synchronousSystem Dev* Dev TestThis work 81.8 90.1 82.6SCFG 77.0 81.6 78.9Figure 6: TempEval-3 gold mention value accuracy.context free grammar (SCFG) (Bethard, 2013b),which is state-of-the-art in the task of resolutionwith gold mention boundaries.9 ResultsEnd-to-end results Figure 4 shows develop-ment and test results for TempEval-3.
Figure 5shows these numbers for WikiWars.
In bothdatasets, we achieve state-of-the-art test scores.For detection, we show up to 3-point improve-ments in strict and relaxed F1 scores.
These num-bers outperform all systems participating in theshared task, which used a variety of techniques in-cluding hand-engineered rules, CRF tagging mod-els, and SVMs.
For resolution, we show up to4-point improvements in the value F1 score, alsooutperforming participating systems, all of whichused hand-engineered rules for resolution.Gold Mentions Figure 6 reports developmentand test results with gold mentions.4Our approachoutperforms the state of the art, SCFG (Bethard,2013b), which also used a hand engineered gram-mar, but did not use machine learning techniques.4These numbers vary slightly from those reported; we didnot count the document creation times as mentions.144465 70 75 80 85 90848688909294ValuePrecision(%)65 70 75 80 85 90848688909294This workHeidelTimeTempEval-3 DevWikiWars DevValue Recall (%)Figure 7: Value precision vs. recall for 10-fold crossvalidation on TempEval-3 Dev and WikiWars Dev.Precision vs. Recall Our probabilistic modelof time expression resolution allows us to eas-ily tradeoff precision and recall for end-to-endperformance by varying the resolution probabilitythreshold.
Figure 7 shows the precision vs. recallof the resolved values from 10-fold cross valida-tion of TempEval-3 Dev and WikiWars Dev.
Weare able to achieve precision at or above 90% withreasonable recall, nearly 70% for WikiWars andover 85% for TempEval-3.Ablation Study Figures 4-5 also show compar-isons for our system with no context.
We ablatethe ability to refer to the context during resolutionby removing contextual information from the res-olution features and only allowing the documentcreation time to be the reference time.We see an interesting asymmetry in the effect ofmodeling context across the two domains.
We findthat context is much more important in WikiWars(19 point difference) than in TempEval (2 pointdifference).
This result reaffirms the difference indomains that Str?otgen and Gertz (2012) noted dur-ing the development of HeidelTime: history arti-cles have narrative structure that moves back andforth through time while newspaper text typicallydescribes events happening near the document cre-ation time.
This difference helps us to understandwhy previous learning systems have been able toignore context and perform well on newswire text.Error Analysis To investigate the source of er-ror, we compute oracle results for resolving goldmentions over the TempEval-3 Dev dataset.
Wefound that our system produces a correct candidatederivation for 96% of the mentions.We also manually categorized all resolutionerrors for end-to-end performance with 10-foldcross validation of the TempEval-3 Dev dataset,Error description %Wrong directionality context operator 34.6Wrong reference time context operator 15.7Wrong shifting granularity context operator 14.4Requires joint reasoning with events 9.2Cascading error due to wrong detection 7.8CCG parse error 2.0Other error 16.3Figure 8: Resolution errors from 10-fold cross valida-tion of the TempEval-3 Dev dataset.shown in Figure 8.
The lexicon allows for effec-tive parsing, contributing to only 2% of the overallerrors.
However, context is more challenging.
Thethree largest categories, responsible for 64.7% ofthe errors, were incorrect use of the context oper-ators.
More expressive modeling will be requiredto fully capture the complex pragmatics involvedin understanding time expressions.10 ConclusionWe presented the first context-dependent semanticparsing system to detect and resolve time expres-sions.
Both models used a Combinatory Catego-rial Grammar (CCG) to construct a set of possibletemporal meaning representations.
This grammardefined the possible phrases for detection and theinputs to a context-dependent reasoning step thatwas used to construct the output time expressionduring resolution.
Experiments demonstrated thatour approach outperforms state-of-the-art systems.In the future, we aim to develop joint modelsfor reasoning about events and time expressions,including detection and resolution of temporal re-lations.
We are also interested in testing coveragein new domains and investigating techniques forsemi-supervised learning and learning with noisydata.
We hypothesize that semantic parsing tech-niques could help in all of these settings, provid-ing a unified mechanism for compositional analy-sis within temporal understanding problems.AcknowledgmentsThe research was supported in part byDARPA under the DEFT program throughthe AFRL (FA8750-13-2-0019) and the CSSG(N11AP20020), and the NSF (IIS-1115966, IIS-1252835).
The authors thank Nicholas FitzGerald,Tom Kwiatkowski, and Mark Yatskar for helpfuldiscussions, and the anonymous reviewers forhelpful comments.1445ReferencesJames F. Allen.
1981.
An interval-based representa-tion of temporal knowledge.
In Proceedings of the7th International Joint Conference on Artificial In-telligence.James F Allen.
1983.
Maintaining knowledge abouttemporal intervals.
Communications of the ACM,26(11):832?843.Gabor Angeli and Jakob Uszkoreit.
2013.
Language-independent discriminative parsing of temporal ex-pressions.
In Proceedings of the Conference of theAssociation of Computational Linguistics.Gabor Angeli, Christopher D Manning, and Daniel Ju-rafsky.
2012.
Parsing time: Learning to interprettime expressions.
In Proceedings of the Conferenceof the North American Chapter of the Associationfor Computational Linguistics.Y.
Artzi and L.S.
Zettlemoyer.
2011.
Bootstrapping se-mantic parsers from conversations.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.Y.
Artzi and L.S.
Zettlemoyer.
2013a.
UW SPF: TheUniversity of Washington Semantic Parsing Frame-work.Y.
Artzi and L.S.
Zettlemoyer.
2013b.
Weakly super-vised learning of semantic parsers for mapping in-structions to actions.
Transactions of the Associa-tion for Computational Linguistics, 1(1):49?62.Steven Bethard.
2013a.
Cleartk-timeml: A minimalistapproach to tempeval 2013.
In Second Joint Confer-ence on Lexical and Computational Semantics.Steven Bethard.
2013b.
A synchronous context freegrammar for time normalization.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.Q.
Cai and A. Yates.
2013.
Semantic parsing free-base: Towards open-domain semantic parsing.
InJoint Conference on Lexical and Computational Se-mantics: Proceedings of the Main Conference andthe Shared Task: Semantic Textual Similarity.Nathanael Chambers.
2013.
Navytime: Event andtime ordering from raw text.
In Second Joint Con-ference on Lexical and Computational Semantics.Angel X Chang and Christopher Manning.
2012.
Su-time: A library for recognizing and normalizing timeexpressions.
In Proceedings of the 8th InternationalConference on Language Resources and Evaluation.D.L.
Chen and R.J. Mooney.
2011.
Learning to in-terpret natural language navigation instructions fromobservations.
In Proceedings of the National Con-ference on Artificial Intelligence.S.
Clark and J. R. Curran.
2007.
Wide-coverage ef-ficient statistical parsing with CCG and log-linearmodels.
Computational Linguistics, 33(4):493?552.J.
Clarke, D. Goldwasser, M. Chang, and D. Roth.2010.
Driving semantic parsing from the world?s re-sponse.
In Proceedings of the Conference on Com-putational Natural Language Learning.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of the 5th International Conference onLanguage Resources and Evaluation.John Duchi, Elad Hazan, and Yoram Singer.
2011.Adaptive subgradient methods for online learningand stochastic optimization.
The Journal of Ma-chine Learning Research, 12:2121?2159.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin.
2008.
LIBLINEAR:A library for large linear classification.
Journal ofMachine Learning Research, 9:1871?1874.Michele Filannino, Gavin Brown, and Goran Nenadic.2013.
Mantime: Temporal expression identificationand normalization in the tempeval-3 challenge.
InSecond Joint Conference on Lexical and Computa-tional Semantics.D.
Goldwasser and D. Roth.
2011.
Learning fromnatural instructions.
In Proceedings of the Interna-tional Joint Conference on Artificial Intelligence.J.
Krishnamurthy and T. Mitchell.
2012.
Weakly su-pervised training of semantic parsers.
In Proceed-ings of the Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning.T.
Kwiatkowski, L.S.
Zettlemoyer, S. Goldwater, andM.
Steedman.
2010.
Inducing probabilistic CCGgrammars from logical form with higher-order uni-fication.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing.T.
Kwiatkowski, L.S.
Zettlemoyer, S. Goldwater, andM.
Steedman.
2011.
Lexical Generalization in CCGGrammar Induction for Semantic Parsing.
In Pro-ceedings of the Conference on Empirical Methodsin Natural Language Processing.T.
Kwiatkowski, E. Choi, Y. Artzi, and L. Zettlemoyer.2013.
Scaling semantic parsers with on-the-fly on-tology matching.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Pro-cessing.P.
Liang, M.I.
Jordan, and D. Klein.
2011.
Learn-ing dependency-based compositional semantics.
InProceedings of the Conference of the Association forComputational Linguistics.1446Pawet Mazur and Robert Dale.
2010.
Wikiwars: a newcorpus for research on temporal expressions.
In Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing.Marc Moens and Mark Steedman.
1988.
Temporal on-tology and temporal reference.
Computational lin-guistics, 14(2):15?28.James Pustejovsky, Patrick Hanks, Roser Sauri, An-drew See, Robert Gaizauskas, Andrea Setzer,Dragomir Radev, Beth Sundheim, David Day, LisaFerro, et al 2003.
The timebank corpus.
In Corpuslinguistics.James Pustejovsky, Bob Ingria, Roser Sauri, Jose Cas-tano, Jessica Littman, Rob Gaizauskas, Andrea Set-zer, Graham Katz, and Inderjeet Mani.
2005.
Thespecification language timeml.
The language oftime: A reader, pages 545?557.M.
Steedman.
1996.
Surface Structure and Interpreta-tion.
The MIT Press.M.
Steedman.
2000.
The Syntactic Process.
The MITPress.Jannik Str?otgen and Michael Gertz.
2012.
Tempo-ral tagging on different domains: Challenges, strate-gies, and gold standards.
In Proceedings of the EigthInternational Conference on Language Resourcesand Evaluation.Jannik Str?otgen and Michael Gertz.
2013.
Multilin-gual and cross-domain temporal tagging.
LanguageResources and Evaluation, 47(2):269?298.Kristina Toutanova, Dan Klein, Christopher D Man-ning, and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency network.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology-Volume 1.N.
Uzzaman, H. Llorens, L. Derczynski, M. Verhagen,J.
Allen, and J. Pustejovsky.
2013.
Semeval-2013task 1: Tempeval-3: Evaluating time expressions,events, and temporal relations.
In Proceedings of theInternational Workshop on Semantic Evaluation.Y.W.
Wong and R.J. Mooney.
2007.
Learningsynchronous grammars for semantic parsing withlambda calculus.
In Proceedings of the Conferenceof the Association for Computational Linguistics.J.M.
Zelle and R.J. Mooney.
1996.
Learning toparse database queries using inductive logic pro-gramming.
In Proceedings of the National Confer-ence on Artificial Intelligence.L.S.
Zettlemoyer and M. Collins.
2005.
Learning tomap sentences to logical form: Structured classifica-tion with probabilistic categorial grammars.
In Pro-ceedings of the Conference on Uncertainty in Artifi-cial Intelligence.L.S.
Zettlemoyer and M. Collins.
2007.
Online learn-ing of relaxed CCG grammars for parsing to logi-cal form.
In Proceedings of the Joint Conference onEmpirical Methods in Natural Language Processingand Computational Natural Language Learning.L.S.
Zettlemoyer and M. Collins.
2009.
Learningcontext-dependent mappings from sentences to log-ical form.
In Proceedings of the Joint Conferenceof the Association for Computational Linguisticsand International Joint Conference on Natural Lan-guage Processing.1447
