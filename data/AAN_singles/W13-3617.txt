Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task, pages 123?127,Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational LinguisticsKUNLP Grammatical Error Correction SystemFor CoNLL-2013 Shared TaskBong-Jun Yi, Ho-Chang Lee, and Hae-Chang RimDepartment of Computer and Radio Communications EngineeringKorea UniversityAnam-dong 5-ga, Seongbuk-gu, Seoul, South Korea{bjyi,hclee,rim}@nlp.korea.ac.krAbstractThis paper describes an English grammat-ical error correction system for CoNLL-2013 shared task.
Error types covered byour system are article/determiner, prepo-sition, and noun number agreement.
Thiswork is our first attempt on grammaticalerror correction research.
In this work,we only focus on reimplementing the tech-niques presented before and optimizingthe performance.
As a result of the imple-mentation, our system?s final F1-score bym2 scorer is 0.1282 in our internal test set.1 IntroductionAs the number of English learners is increas-ing world widely, the research topic of auto-mated grammar error correction is lively dis-cussed.
However, automated grammar error cor-rection is a very difficult field and the result is notsatisfactory.
Therefore, the shared task about En-glish error correction has been annually held andmany researchers are trying to solve this problem.Helping Our Own (HOO) 2011 is a pilot sharedtask for automated correction of errors in non-native English speakers?
papers.
The shared taskevaluates the performance of detection, recogni-tion, correction on thirteen types of English gram-matical errors by using F1-score.
Because eacherror type has different characteristics, they haveto use different approaches to correct appropriateerror types.In HOO 2012, only two types of errors, prepo-sition and determiner were handled.
This sharedtask also evaluated the performance of detection,recognition, correction by using F1-score.
Thebest result of the preposition error correction is0.2371 in F1-score and the determiner error cor-rection is 0.3460 in F1-score.
These are remark-able achievement.This year CoNLL 2013 shared task covers fivetypes of errors based on the result of HOO 2012.These error types are determiner, preposition,noun number, verb form, and subject-verb agree-ment.
Because of the limited amount of time andmanpower, we only focus on preposition, deter-miner and noun number.2 Previous WorksMost methods for grammar error correction havetried to correct one type of errors.
Researchershave never attempted to correct different types oferrors at the same time.In this work, we try to solve the error correctionproblem based on the previous research presentinggood performance.First, the preposition error correction is basedon (Han et al 2010).
They tried to correct themost commonly used 10 preposition errors basedon the classification approach.
10 prepositions areabout, at, by, for, from, in, of, on, to, with.
Theyhave implemented 11-way classifier to output 11types of proper word(10 prepositions + ?NULL?
)for 11 types of source words.
This work assumesthat three kinds of corrections exist.
If ?NULL?
istaken as input and some preposition is produced, itis omission.
If some preposition is taken as inputand another preposition is produced, it is replace-ment.
If some preposition is taken as input and?NULL?
is produced, it is commission.
In the caseof replacement, correction precision is 0.817 andrecall is 0.132.
Furthermore, they reported thatthe performance is much better when they train themodel with well edited error tagged corpus.
(Felice and Pulman, 2008) also used a methodbased on classification.
It is, nevertheless, unusualthat they did not use error tagged learner?s corpusbut error free British National Corpus.
Withoutusing an error tagged corpus, they have achieved51.5% accuracy for error correction.To improve low recall of Han?s method, to con-123struct large training data is the best way.
However,it is very costly and hard work to obtain well editederror tagged corpus.
By the way, error free corpuslike news articles is relatively easy to acquire.
Weplan to utilize large error free corpus as the train-ing data to overcome the problem of low recall.That plan motivated by Felice?s work has not beentried on the proposed system.
We will attempt toreimplement the system by utilizing the error freecorpus in the near future.3 System DescriptionOur system is composed of three components,preposition error corrector, article error corrector,and noun number error corrector.
In this work,we do not consider complex cases of grammar er-rors, thus we assume that the order of correctiondoes not influence the result of correction.
Andall components are based on the machine learningmethod.3.1 Preposition Error CorrectionIn the training corpus, there are more article errorsthan preposition errors in number.
However, thepreposition error correction is much more difficultand the performance of correction is worse thanthe article error correction.We select preposition error candidates for re-placement or commission or omission as follows.?
Replacement or Commission?
Preposition : tagged as ?IN?
or ?TO?and dependency relation with its par-ent(DPREL) is identified as a ?prep??
Omission?
In front of a noun phrase : the precedingword of the noun phrase is not preposi-tion?
In front of a verb phrase : the preced-ing word of the verb phrase including?VBG?
(verb, gerund/present participle)is not prepositionAs described above, we use allwords(preposition and ?NULL?
when omis-sion) in that place as source word for prepositioncorrection.We have implemented only one classifier thattakes a source word as input and produces cor-rected preposition or ?NULL?
as output.
We useNo.
Feature Name Description1 s the source word2 wd-1 the word preceding s3 wd+1 the word following s4 wd-1,2 s the two words preceding sand s5 s wd+1,2 s and the two words fol-lowing s6 3GRAM the trigram, wd-1, s,wd+17 5GRAM the five-gram, wd-2, wd-1, s, wd+1, wd+28 MOD the lexical head which thepreposition modifies9 ARG the lexical head of thepreposition argument10 MOD ARG MOD and ARG11 MOD s MOD and s12 s ARG s and ARG13 MOD s ARG MOD, s, ARG14 MODt ARGt POS tags of MOD andARG15 MODt s the POS tag of MOD ands16 s ARGt s and the POS tag of ARG17 MODt s ARGt MODt and s and ARGt18 TRIGRAMt POS trigram19 wd L 3 words preceding s20 wd R 3 words following sTable 1: Set of features proposed by (Han et al2010)the part of feature set(Table 1) proposed by (Hanet al 2010) for learning.
They are presented inthe experiment part.Each feature represents the word itself in theHan?s work.
However, the same word can be ex-tracted again as a different kind of features.
In or-der to distinguish the same word used for the dif-ferent features, we attach the feature name to theword as postfix.
This naming convention can makethe feature sparse, but increase the discriminationpower and improve the performance of the classi-fier.
In our experiment, we have tested the systemwith two different sets of features(i.e.
raw wordand with feature names).1243.2 Article Error CorrectionWe have implemented the article error correctorjust like the preposition error corrector.
When weexperiment the pilot article correction system justlike the preposition correction system, it shows agood performance unexpectedly.
There is a littledifference in presenting set of features.
In prepo-sition error corrector, we add postfix to the set offeature to keep sort of features(e.g.
word ?in?
assource word feature, postfix is ?S?, final featureis ?in S?).
This method gives more discriminationability to the classifier.
But in case of article, usingraw word lead to a better result.3.3 Noun Number Error CorrectionNoun number error indicates improper use ofsingular or plural form of nouns.
For example,the singular form ?problem?
should be correctedto the plural form ?problems?
in the followingsentence.
?They are educational and resource problem.
?As far as we know, there have been few at-tempts to correct noun number agreement errors.In this shared task, we propose a novel noun num-ber agreement correction system based on a ma-chine learning method trained with basic features.In order to extract nouns from the input sen-tences, we parse the sentence and extract the lastnoun in every noun phrase for the error correctioncandidates.
If there is a coordinating conjunctionin the noun phrase, we split the noun phrase intotwo parts and extract two candidates.
[S [NP Relevant information] [VP are [ADJPreadily ROOT available [PP on [NP [NP theinternet] and [NP article] [PP in [NP maga-zines and newspapers] .
]]]Figure 1: Extracting candidates for error correc-tion of noun number(candidates are indicated bybold)Figure 1 shows the example of selecting can-didates for the error correction of noun number.We classify a noun into four classes using fea-tures of Table 2 based on the machine learn-ing method.
Four classes are NN(plural noun),NNP(plural proper noun), NNS(singular noun),and NNPS(singular proper noun).
It is based onthe observation that the common noun and theNo.
Feature Name Description1 p POS tag for the source word2 s the source word3 DET the determiner of the noun ar-gument4 CD boolean value whether thecardinal number exists5 UCNT boolean value whether thenoun is uncountable6 MOD the lexical head which thenoun modifies7 MMOD the lexical head which MODmodifies8 ARG the lexical head of the nounargument9 AARG the lexical head of the ARGargument10 MOD s ARG MOD, s, and ARG11 MODt POS tag for MOD12 MMODt POS tag for MMOD13 ARGt POS tag for ARG14 AARGt POS tag for AARG15 MODt p ARGt MODt, p, and ARGt16 MMOD MOD s MMOD, MOD, and s17 s ARG AARG s, ARG, and AARG18 MOD s ARG MOD, s, and ARG19 MM M s A AA MMOD, MOD, s, ARG, andAARG20 MMODt MODt p MMODt, MODt, and p21 p ARGt AARGt p, ARGt, and AARGt22 MODt p ARGt MODt, p, and ARGt23 MMt Mt s At AAt MMODt, MODt, s, ARGt,and AARGtTable 2: Set of features for learning noun numbererror correctionproper noun have many different characteristic.The set of features used for learning is shown inTable 2.4 Experiments4.1 CorpusWe use only NUS Corpus of Leaner En-glish(NUCLE)((Dahlmeier, 2013)) provided fromCoNLL 2013 shared task.
We construct the devel-opment set with first sentences for every 10 sen-tence and the test set with second sentences andthe training set with the rest of sentences.
Thesystem is trained to learn error correction with thetraining set and optimized with the developmentset and finally evaluated with the test set.4.2 Preposition Correction ExperimentTable 1 shows 20 types of features used by (Hanet al 2010).
We have found that the features con-sist of various types and the learning world be dis-turbed by too many features.
In our experiment,125Number of feature 20 18 9RawWordPrecision 0.0571 0.1194 0.0196Recall 0.0402 0.0402 0.1256F1-score 0.0472 0.0602 0.0339WithFeatureNamePrecision 0.1034 0.1750 0.0208Recall 0.0302 0.0352 0.1307F1-score 0.0467 0.0586 0.0359Table 3: The result of preposition error correctionwe exclude wd L(19), wd R(20) and employ 18kinds of features.We will try to train the correction model by us-ing large amount of error free corpus in order toovercome the problem of low recall.
To parse largecorpus is very time consuming task.
So, in thisexperiment, we select 9 features which can be ex-tracted without parsing, and test the possibility ofusing 9 features by training and testing the correc-tion model.We have performed two different experiments.In the first experiment, we have used the word it-self as a feature.
In the tables 3?5, ?Raw Word?represents the case when we use just the worditself.
In the second experiment, we have usedthe feature name as the postfix of the feature.
Inthe tables 3?5, ?With Feature Name?
representsthe case when we attach the feature name to thefeature and use it as a feature.
For all experi-ments, we have tried to differentiate the numberof features.
20 features are same as Han?s work.18 features are the case when we exclude 2 fea-tures(i.e.
wd L(19), wd R(20)).
9 features are thecase when we use only features which do not re-quire parsing.We have experimented with Maximum Entropylearning method, and fixed the iteration number to200.
Table 3 shows that the precision has highlyincreased although the recall has decreased whenwe add the feature name to the set of features usedfor learning.When we use 18 features except wd L(3 wordspreceding s) and wd R(3 words following s), theerror correction system achieves the best perfor-mance.
According to the experimental result, wecan achieve the better result when we use 18 fea-tures and the raw word.
But we select final optionusing 18 features and the word with feature namebecause of optimization strategies that improve theprecision.Number of feature 20 18 9RawWordPrecision 0.1827 0.3176 0.0914Recall 0.1123 0.1264 0.1139F1-score 0.1391 0.1808 0.1014WithFeatureNamePrecision 0.1942 0.3174 0.1059Recall 0.1154 0.1139 0.1061F1-score 0.1448 0.1676 0.1060Table 4: The result of article error correctionKinds of feature BasicBasic&Indep-endentBasic&Com-plexRawWordPrecision 0.2462 0.1435 0.2469Recall 0.0379 0.0811 0.0540F1-score 0.0662 0.1036 0.0887WithFeatureNamePrecision 0.2413 0.1676 0.2875Recall 0.0378 0.0838 0.0621F1-score 0.0654 0.1117 0.1022Table 5: The result of noun number error correc-tion4.3 Article Correction ExperimentTable 4 shows that the feature name addition doesnot improve the precision in the case of article cor-rection, and the set of 18 features achieves the bestperformance for article correction.
Therefore, wejust use raw words for features and select 18 fea-tures for article correction.4.4 Noun Number Correction ExperimentIn Table 2, features of number 1?5 belong to thebasic feature set and features of number 6?15 be-long to the independent feature set and featuresof number 16?23 belong to the complex featureset.
The experimental result with various combi-nations of feature sets shows that the set of basicand complex features achieves the best precisionin spite of low recall as shown in Table 5.
We usethis option and experimentally select the iterationnumber 700.5 ConclusionsWe develop a grammatical error correction systemwhich can recognize and correct preposition, arti-cle, and noun number errors.
In this experiment,we have found out the set of good features forpreposition and article error correction, and pro-posed a novel noun number error correction tech-nique based on the machine learning method.
For126the future work, we will try to utilize large amountof external resources such as well written errorfree corpus.ReferencesDaniel Dahlmeier, Hwee Tou Ng, Siew Mei Wu 2013.Building a Large Annotated Corpus of Learner En-glish: The NUS Corpus of Learner English, Pro-ceedings of the 8th Workshop on Innovative Use ofNLP for Building Educational Applications (BEA2013), Atlanta, Georgia, USA.Rachele De Felice and Stephen G. Pulman 2008.
Aclassifier-based approach to preposition and deter-miner error correction in L2 English, Proceedingsof the 22nd International Conference on Computa-tional Linguistics (Coling 2008), 169?176, Manch-ester, UKNa-Rae Han, Joel Tetreault, Soo-Hwa Lee, Jin-YoungHa 2010.
Using an Error-Annotated LearnerCorpus to Develop an ESL/EFL Error CorrectionSystem, Proceedings of the Seventh InternationalConference on Language Resources and Evaluation(LREC 2010), 763?770, Malta127
