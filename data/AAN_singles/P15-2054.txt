Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 327?333,Beijing, China, July 26-31, 2015. c?2015 Association for Computational LinguisticsCo-Simmate: Quick Retrieving All Pairwise Co-Simrank ScoresWeiren Yu, Julie A. McCannDepartment of Computing,Imperial College London, UK{weiren.yu, j.mccann}@imperial.ac.ukAbstractCo-Simrank is a useful Simrank-like mea-sure of similarity based on graph structure.The existing method iteratively computeseach pair of Co-Simrank score from a dotproduct of two Pagerank vectors, entailingO(log(1/?
)n3) time to compute all pairsof Co-Simranks in a graph with n nodes,to attain a desired accuracy ?.
In this study,we devise a model, Co-Simmate, to speedup the retrieval of all pairs of Co-Simranksto O(log2(log(1/?
))n3) time.
Moreover,we show the optimality of Co-Simmateamong other hop-(uk) variations, and inte-grate it with a matrix decomposition basedmethod on singular graphs to attain higherefficiency.
The viable experiments verifythe superiority of Co-Simmate to others.1 IntroductionMany NLP applications require a pairwise graph-based similarity measure.
Examples are bilinguallexicon extraction (Laws et al, 2010), sentimentanalysis (Scheible and Schu?tze, 2013), synonymextraction (Minkov and Cohen, 2014), named en-tity disambiguation (Alhelbawy and Gaizauskas,2014), acronym expansion (Zhang et al, 2011).Recently, Co-Simrank (Rothe and Schu?tze, 2014)becomes an appealing graph-theoretical similaritymeasure that integrates both features of Simrank(Jeh and Widom, 2002) and Pagerank (Berkhin,2005).
Co-Simrank works by weighing all thenumber of connections between two nodes to eval-uate how similar two nodes are.
The intuition be-hind Co-Simrank is that ?more similar nodes arelikely to be pointed to by other similar nodes?.Co-Simrank is defined in a recursive style:S = cATSA+ I, (1)where S is the exact Co-Simrank matrix, A is thecolumn-normalised adjacency matrix of the graph,c is a decay factor, and I is an identity matrix.The best-known method by (Rothe and Schu?tze,2014) computes a single element of S iterativelyfrom a dot product ?
?, ??
of two Pagerank vectors:Sk(a, b) = ck?pk(a),pk(b)?
+ Sk?1(a, b) (2)where pk(a) is a Pagerank vector, defined aspk(a) = ATpk?1(a) with p0(a) = I(?, a) (3)This method is highly efficient when only a smallfraction of pairs of Co-Simranks need computingbecause there is no need to access the entire graphfor computing only a single pair score.
However,partial pairs retrieval is insufficient for many real-world applications (Zhou et al, 2009; Yu et al,2012a; Zwick, 2002; Leicht et al, 2006) which re-quire all-pairs scores.
Let us look at two examples.a) Co-Citation Analysis.
In a co-citation network,one wants to retrieve the relevance between anytwo given documents at any moment based ontheir references.
To answer such an ad-hoc query,quantifying scores of all document-pairs providesa comprehensive way to show where low and highrelevance of pairwise documents may exist (Li etal., 2010; Yu et al, 2014; Haveliwala, 2002).b) Water Burst Localization.
In a water network,nodes denote deployed pressure sensor locations,and edges are pipe sections that connect the nodes.To determine the burst location, one needs to eval-uate ?proximities?
of all pairs of sensor nodes first,and then compare all these ?proximities?
with thedifference in the arrival times of the burst transientat sensor locations, to find the sensor node nearestto the burst event.
(Srirangarajan and Pesch, 2013;Srirangarajan et al, 2013; Stoianov et al, 2007)Hence, the retrieval of all pairwise Co-Simranksis very useful in many applications.
Unfortunately,when it comes to all pairs computation of S(?, ?
),the way of (2) has no advantage over the naive waySk= cATSk?1A+ I with S0= I (4)327as both entail O(log(1/?
)n3) time to compute allpairs of Co-Simranks to attain desired accuracy ?.The complexity O(log(1/?
)n3) has two parts:The first part O(n3) is for matrix multiplications(ATSk?1A) at each step.
A careful implementa-tion, e.g., partial sums memoisation (Lizorkin etal., 2010) or fast matrix multiplications (Yu et al,2012b),1 can optimise this part further to O(dn2)or O(nlog2 7), with d the average graph degree.The second part O(log(1/?))
is the total numberof steps required to guarantee a given accuracy ?,because, as implied by (Rothe and Schu?tze, 2014),|Sk(a, b) ?
S(a, b)| ?
ck+1.
?a, b, ?k (5)To the best of our knowledge, there is a paucity ofwork on optimising the second part O(log(1/?
)).Yu et al (2012b) used a successive over-relaxation(SOR) method to reduce the number of steps forSimrank, which is also applicable to Co-Simrank.However, this method requires a judicious choiceof an internal parameter (i.e., relaxation factor ?
),which is hard to determine a-priori.
Most recently,Yu et al (2015) propose an exponential model tospeed up the convergence of Simrank:?S0= exp(?c) ?
I, d?St/dt = AT ?
S ?A.However, ?S and S do not produce the same results.Thus, this exponential model, if used to computeCo-Simrank, will lose some ranking accuracy.Contributions.
In this paper, we propose an effi-cient method, Co-Simmate, that computes all pairsof Co-Simranks in just O(log2(log(1/?
))n3) time,without any compromise in accuracy.
In addition,Co-Simmate is parameter-free, and easy to imple-ment.
It can also integrate the best-of-breed matrixdecomposition based method by Yu and McCann(2014) to achieve even higher efficiency.2 Co-Simmate ModelFirst, we provide the main idea of Co-Simmate.We notice that Co-Simrank solution S in (1) isexpressible as a matrix series:S = I+ cATA+ c2(AT)2A2+ c3(AT)3A3+ c4(AT)4A4+ ?
?
?
(6)The existing iterative method (4) essentially usesthe following association to compute (6):S =(cAT=S2?
??
?
(cAT(cATA+ I)?
??
?=S1A+ I)A+ I)+ ?
?
?
(7)1These Simranks methods also suit Co-Simranks.The downside of this association is that the result-ing Sk?1of the last step can be reused only onceto compute Sk.
Thus, after k iterations, Skin (4)grasps only the first k-th partial sums of S in (6).To speed up the computation, we observe that(6) can be reorganised as follows:S =(I+ cATA)+(c2(AT)2A2+ c3(AT)3A3)++(c4(AT)4A4+ ?
?
?+ c7(AT)7A7)+ ?
?
?=(I+ cATA)+(c2(AT)2(I+ cATA)A2)++(c4(AT)4(I+ cATA+ ?
?
?+ c3(AT)3A3)A4)+ ?
?
?Thereby, we can derive the following novel associ-ation, referred to as Co-Simmate, to compute (6):S =(=R1?
??
?
(I+ cATA) + (cAT)2=R1?
??
?
(I+ cATA)A2)?
??
?=R2+ (8)(cAT)4((I+ cATA)+(cAT)2(I+ cATA)A2)?
??
?=R2A4+ ?
?
?There are two advantages of our association: oneis that the resulting Rk?1from the last step canbe reused twice to compute Rk.
Hence, Rkcangrasp the first (2k ?1)-th partial sums2 of S in (6).Another merit is that A2k can be obtained fromthe result of squaring A2k?1 , e.g., A4 = (A2)2.With these advantages, Co-Simmate can computeall pairs of scores much faster.Next, let us formally introduce Co-Simmate:Definition 1.
We call Rka Co-Simmate matrix atk-th step if it is iterated as????
?R0= I, A0= ARk+1= Rk+ c2k(AkTRkAk)Ak+1= Ak2(9)By successive substitution in (9), one can verifythat limk?
?Rkis the exact solution of S in (6).More precisely, the following theorem shows that,at step k, how many first terms of S in (6) can begrasped by Rk, showing the fast speedup of (9).Theorem 1.
Let Rkbe the Co-Simmate matrix in(9), and Skthe Co-Simrank matrix in (4).
Then,Rk= S2k?1?k = 0, 1, 2, ?
?
?
(10)2This amount of the first partial sums will be proved later.328S1S2S3S4S5S6S7S0S1S2S3S4S5S6R2ATAATAATAATAATAATAATA((AT)2)2(A2)2S0R1R3R0R1ATAR0(AT)2A2R2R1(AT)2A2R2((AT)2)2(A2)2R2((AT)2)2(A2)2R2((AT)2)2(A2)2Figure 1: Co-Simmate speeds up Co-Simrank by aggregating more first terms of S in (6) at each stepProof.
Successive substitution in (4) producesSk=?ki=0ci(Ai)TAi (11)Thus, proving (10) is equivalent to showing thatRk=?2k?1i=0ci(Ai)TAi (12)To show (12), we will use induction on k.1.
For k = 0, we have R0= I = c0(A0)TA0.2.
When k > 0, we assume that (12) holds for k,and want to prove that (12) holds for k + 1.From Ak+1= Ak2 and A0= A follows thatAk= Ak?12= Ak?222= ?
?
?
= A2k (13)Plugging Rk(12) and Ak(13) into (9) yieldsRk+1= {using (12) and (13)}= Rk+ c2k(A2k)T(?2k?1i=0ci(Ai)TAi)A2k= Rk+?2k?1i=0ci+2k(Ai+2k)TAi+2k= Rk+?2k?1+2kj=2kcj(Aj)TAj=?2k+1?1j=0cj(Aj)TAjLastly, coupling (11) and (12) concludes (10).Theorem 1 implies that, at each step k,Rkin (9)can grasp the first (2k ?
1)-th terms of S, whereasSkin (4) can grasp only the first k-th terms of S.Thus, given the number of steps K , Co-Simmateis always more accurate than Co-Simrank becauseRKis exponentially closer to S than SKto S.Convergence Rate.
We next provide a quantita-tive result on how closer Rkis to S than Skto S.Theorem 2.
For any given step k, the differencebetween Rkand S can be bounded by|Rk(a, b) ?
S(a, b)| ?
c2k, ?a, b (14)Proof.
The Co-Simrank result in (5) implies that|S2k?1(a, b) ?
S(a, b)| ?
c2k, ?a, bPlugging (10) into this inequality yields (14).Theorem 2 implies that, to attain a desired accu-racy ?, Co-Simmate (9) takes exponentially fewersteps than Co-Simrank (4) since the total numberof steps required for RK, as implied by (14), isK = max{0, ?log2logc??
+ 1},in contrast to the ?logc??
steps required for SK.Total Computational Cost.
Though Co-Simmatetakes fewer steps than Co-Simrank for a desired ?,in each step Co-Simmate (9) performs one morematrix multiplication than Co-Simrank (4).
Next,we compare their total computational time.Theorem 3.
To guarantee a desired accuracy ?,the total time of Co-Simmate (9) is exponentiallyfaster than that of Co-Simrank (4).Proof.
For k = 1, both Co-Simmate (9) and Co-Simrank (4) take 2 matrix multiplications.For k > 1, Co-Simmate (9) takes 3 matrix mul-tiplications (2 for ATkRkAkand 1 for A2k), whilstCo-Simrank (4) takes 2 (only for ATkSkAk).Let |M| be the number of operations for onematrix multiplication.
Then, for Co-Simmate (9),(total # of operations for Rk) = 3k|M|,whereas for Co-Simrank (4), by Theorem 1,(total # of operations for Sk) = 2(2k ?
1)|M|.Since 3k|M| ?
2(2k ?
1)|M|, ?k = 2, 3, ?
?
?
, wecan conclude that the total time of Co-Simmate isexponentially faster than that of Co-Simrank.Example.
Figure 1 pictorially visualises how Co-Simmate accelerates Co-Simrank computation byaggregating more first terms of S in (6) each step.329Algorithm 1: Co-Simmate on Singular GraphsInput : A ?
column-normalised adjacency matrix,c ?
decay factor, ?
?
desired accuracy.1 Decompose A s.t.
[Vr,HTr]?
Gram-Schmidt(A).2 Compute P?
HTrVr.3 Initialise K ?
max{0, ?log2logc??
+ 1}.4 Initialise S0?
Ir, P0?
P.5 for k ?
0, 1, ?
?
?
,K ?
1 do6 Compute Sk+1?
c2k(Pk)TSk(Pk) + Sk.7 Compute Pk+1?
(Pk)2.8 return S?
cHrSKHTr+ I.At k-th step, Co-Simrank Skconnects only twonew hop-1 paths with the old retrieved paths Sk?1,whereas Co-Simmate Rkconnects two new hop-(2k) paths (by squaring the old hop-(2k?1) paths)with the old retrieved paths Rk?1.
Consequently,in each step of Co-Simrank, Co-Simmate is expo-nential steps faster than Co-Simrank.
Moreover,the speedup is more obvious as k grows.Optimality of Co-Simmate.
To compute S in (6),besides the prior association methods (7) and (8),the following association can also be adopted:S ==T1?
??
?
(I+ cATA+ c2(AT)2A2)+ (15)c3(AT)3(I+ cATA+ c2(AT)2A2)?
??
?=T1A3+ ?
?
?More generally, we can write the following modelthat covers (8) and (15) as special cases:??????????????????
?R(u)0= I, A0= AR(u)k+1= R(u)k+ cuk?ATk?R(u)k?Ak+ c2?uk?
(Ak2)T?R(u)k?Ak2+ ?
?
?++ c(u?1)?uk?
(Aku?1)T?R(u)k?Aku?1Ak+1= Aku(u = 2, 3, ?
?
?
)R(u)kis a hop-(uk) Co-Simmate matrix at step k.R(u)kbecomes Co-SimmateRkin (8) when u = 2;and reduces to Tkin (15) when u = 3.
For all u,it is easy to verify that limk?
?R(u)k= S. Below,we show that Co-Simmate (8) (u = 2) is optimal.Theorem 4.
To attain a desired accuracy ?, the to-tal time of Co-Simmate (8) is minimum among allhop-(uk) Co-Simmate modelsR(u)k(u = 2, 3, ?
?
?
).Proof.
Similar to Theorem 1, we can show that|R(u)k(a, b) ?
S(a, b)| ?
cuk, ?a, b, ?u (16)Thus, given ?, the total number of steps forR(u)KisK = max{0, ?logulogc??
+ 1}.For each step k, for hop-(uk) Co-SimmateR(u)k,(# of operations) = ((u ?
1) +?u?2i=0i)|M| =(u?1)u2|M|.Therefore, the total time of computing R(u)kisO(max{0, ?logulogc??
+ 1}(u ?
1)u|M|).This complexity is increasing with u = 2, 3, ?
?
?
.Thus, Co-Simmate (8) (u = 2) is minimum.Incorporate Co-Simmate into Singular Graphs.Co-Simmate (9) can also be combined with otherfactorisation methods, e.g., Sig-SR, a Co-Simrankalgorithm proposed by (Yu and McCann, 2014),to speed up all pairs of Co-Simrank computationfrom O(rn2 +Kr3) to O(rn2 +(log2K)r3) timefurther on a singular graph with rank r forK steps.The enhanced Sig-SR is shown in Algorithm 1.3 Experiments3.1 Experimental SettingsDatasets.
We use both real and synthetic datasets.Three real graphs (Twitter, Email, Facebook) aretaken from SNAP (Leskovec and Sosic?, 2014).1) Twitter is a who-follows-whom social graphcrawled from the entire Twitter site.
Each node isa user, and each edge represents a social relation.2) Email is an Email communication networkfrom Enron.
If an address i sent at least one emailto address j, there is a link from i to j.3) FB contains ?circles?
(or ?friends lists?)
fromFacebook.
This dataset is collected from the sur-vey participants using the Facebook app, includingnode features (profiles), circles, and ego networks.The statistics of these datasets are as follows:Datasets # edges # nodes ave degreeTwitter 1,768,149 81,306 21.70Email 183,831 36,692 5.01FB 88,234 4,039 21.84To build synthetic data, we use Boost toolkit(Lee et al, 2001).We control the number of nodesn and edges m to follow densification power laws(Leskovec et al, 2005; Faloutsos et al, 1999).Baselines.
We compare our Co-Simmate with 1)Ite-Mat (Rothe and Schu?tze, 2014), a Co-Simrankmethod using the dot product of Pagerank vectors.2) K-Sim (Kusumoto et al, 2014), a linearizedmethod modified to Co-Simrank.
3) Sig-SR (Yuand McCann, 2014), a SVD Co-Simrank method.All experiments are on 64bit Ubuntu 14.04 withIntel Xeon E2650 2.0GHz CPU and 16GB RAM.33010?2 10?1 10005101520accuracy (?
)#ofsteps(k)SimmateSimrank(a) Rate of Convergence(on FB dataset, c = 0.8)Twitter Email FB102104106Time(sec)SimmateSig?SRIte?MatK?Sim(b) Total Computational Time(on three real datasets, c = 0.8)?c = 0.6 c = 0.7 c = 0.8SM SR SM SR SM SR0.1 3 4 3 6 4 100.01 4 9 4 12 5 200.001 4 13 5 19 5 300.0001 5 18 5 25 6 410.00001 5 22 6 32 6 51(c) Effect of Damping Factor c on Iterations k (on FB)4K 5K 6K 7K 8K 9K 10K05001000150020002500nTime(sec)SimmateSimrank (Ite?Mat)(d) Scalability w.r.t.
# nodes(on 7 synthetic datasets)2 3 4 5 6050100150200uTime(sec)hop-(uk) Simmate3364 3k(e) Effect of Hop-(uk)(on FB dataset, c = 0.8)Figure 2: Compare Co-Simmate with Baselines3.2 Experimental ResultsExp-I.
Convergence Rate.
We compare the num-ber of steps k needed for Co-Simmate and Co-Simrank (Ite-Mat) to attain a desired accuracy ?
onTwitter, Email, FB.
The results on all the datasetsare similar.
Due to space limits, Figure 2(a) onlyreports the result on FB.
We can discern that, when?
varies from 0.01 to 1, k increases from 1 to 5for Co-Simmate, but from 1 to 20 for Co-Simrank.The fast convergence rate of Co-Simmate is due toour model that twice reuses Rk?1of the last step.Exp-II.
Total Computational Time.
Figure 2(b)compares the total computational time of Co-Simmate with 3 best-known methods on real data.The result shows Co-Simmate runs 10x, 5.6x, 4.3xfaster than K-Sim, Ite-Mat, Sig-SR, respectively.This is because 1) K-Sim is efficient only when afraction pair of scores are computed, whereas Co-Simmate can efficiently handle all pairs scores, bytwice sharing Rk?1and repeated squaring A2k?1 .2) Co-Simmate grasps exponential new terms of Sper step, but Ite-Mat grasps just 1 new term of S.3) Sig-SR does not adopt association tricks in thesubspace, unlike our methods that integrate (9).Exp-III.
Effect of Damping Factor c. Using realdatasets (Twitter, Email, FB), we next evaluate theeffect of damping factor c on the number of itera-tions k to guarantee a given accuracy ?.
We vary ?from 0.1 to 0.00001 and c from 0.6 to 0.8, the re-sults of k on all the datasets are similar.
For the in-terests of space, Figure 2(c) tabularises only the re-sults on FB, where ?SM?
columns list the numberof iterations required for Co-Simmate, and ?SR?columns lists that for Co-Simrank.
From the re-sults, we can see that, for any given ?
and c, thenumber of iterations for Co-Simmate is consis-tently smaller than that for Co-Simrank.
Their gapis more pronounced when ?
becomes smaller orc is increased.
This is because, at each iteration,Co-Simmate can grasp far more first terms of Sthan Co-Simrank.
Thus, for a fixed accuracy, Co-Simmate requires less iterations than Co-Simrank.This is consistent with our analysis in Theorem 2.Exp-IV.
Scalability.
By using synthetic datasets,we fix ?
= 0.0001 and vary n from 4,000 to10,000.
Figure 2(d) depicts the total time of Co-Simmate and Ite-Mat.
We can notice that, as ngrows, the time of Co-Simmate does not increaseso fast as Co-Simrank.
The reason is that the num-ber of steps of Co-Simmate is greatly cut down bytwice Rk?1sharing and A2k?1 memoisation.Exp-V. Effect of Hop-uk.
Finally, we test the im-pact of u on the total time of our hop-(uk) Co-Simmate variations on real datasets.
Due to sim-ilar results, Figure 2(e) merely reports the resultson FB.
It can be observed that, as u grows from2 to 6, the total number of steps for hop-(uk) Co-Simmate decreases, but their total time still grows.This is because, in each step, the cost of hop-(uk)Co-Simmate is increasing with u.
Thus, the lowestcost is Co-Simmate when u = 2.4 ConclusionsWe propose an efficient algorithm, Co-Simmate,to speed up all pairs Co-Simranks retrieval fromO(log(1/?
)n3) to O(log2(log(1/?
))n3) time, toattain a desired accuracy ?.
Besides, we integrateCo-Simmate with Sig-SR on singular graphs toattain higher efficacy.
The experiments show thatCo-Simmate can be 10.2x faster than the state-of-the-art competitors.
As future work, we will incor-porate our partial-pairs Simrank (Yu and McCann,2015) into partial-pairs Co-Simmate search.Acknowledgement.
This research is supported byNEC Smart Water Network research project.331ReferencesAyman Alhelbawy and Robert J. Gaizauskas.
2014.Graph ranking for collective named entity disam-biguation.
In Proceedings of the 52nd Annual Meet-ing of the Association for Computational Linguistics(ACL 2014), pages 75?80.Pavel Berkhin.
2005.
Survey: A survey on PageRankcomputing.
Internet Mathematics, 2(1):73?120.Michalis Faloutsos, Petros Faloutsos, and ChristosFaloutsos.
1999.
On power-law relationships ofthe internet topology.
In Proceedings of the Confer-ence on Applications, Technologies, Architectures,and Protocols for Computer Communication (SIG-COMM 1999), pages 251?262.Taher H Haveliwala.
2002.
Topic-sensitive PageRank.In Proceedings of the 11th International Conferenceon World Wide Web (WWW 2002), pages 517?526.ACM.Glen Jeh and Jennifer Widom.
2002.
SimRank: Ameasure of structural-context similarity.
In Proceed-ings of the 8th ACM SIGKDD International Con-ference on Knowledge Discovery and Data Mining(SIGKDD 2002), pages 538?543.Mitsuru Kusumoto, Takanori Maehara, and Ken-ichiKawarabayashi.
2014.
Scalable similarity searchfor SimRank.
In Proceedings of the 2014 ACM SIG-MOD International Conference on Management ofData (SIGMOD 2014), pages 325?336.Florian Laws, Lukas Michelbacher, Beate Dorow,Christian Scheible, Ulrich Heid, and HinrichSchu?tze.
2010.
A linguistically grounded graphmodel for bilingual lexicon extraction.
In Pro-ceedings of the 23rd International Conference onComputational Linguistics (COLING 2010, Poster),pages 614?622.Lie-Quan Lee, AndrewLumsdaine, and JeremyG Siek.2001.
The boost graph library.
http://www.boost.org/.E.
A. Leicht, Petter Holme, and M. E. J. Newman.2006.
Vertex similarity in networks.
Physical Re-view E, 73(2):026120.Jure Leskovec and Rok Sosic?.
2014.
SNAP: A gen-eral purpose network analysis and graph mining li-brary in C++.
http://snap.stanford.edu/snap, June.Jure Leskovec, Jon Kleinberg, and Christos Faloutsos.2005.
Graphs over time: Densification laws, shrink-ing diameters and possible explanations.
In Pro-ceedings of the 11th ACM SIGKDD InternationalConference on Knowledge Discovery in Data Min-ing (SIGKDD 2005), pages 177?187.
ACM.Cuiping Li, Jiawei Han, Guoming He, Xin Jin, YizhouSun, Yintao Yu, and Tianyi Wu.
2010.
Fast compu-tation of SimRank for static and dynamic informa-tion networks.
In Proceedings of the 13th Interna-tional Conference on Extending Database Technol-ogy (EDBT 2010), pages 465?476.Dmitry Lizorkin, Pavel Velikhov, Maxim N. Grinev,and Denis Turdakov.
2010.
Accuracy estimate andoptimization techniques for SimRank computation.The VLDB Journal (The International Journal onVery Large Data Bases), 19(1):45?66.Einat Minkov and William W. Cohen.
2014.
Adap-tive graph walk-based similarity measures for parsedtext.
Natural Language Engineering, 20(3):361?397.Sascha Rothe and Hinrich Schu?tze.
2014.
CoSim-Rank: A flexible & efficient graph-theoretic simi-larity measure.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Lin-guistics (ACL 2014), pages 1392?1402.Christian Scheible and Hinrich Schu?tze.
2013.
Senti-ment relevance.
In Proceedings of the 51st AnnualMeeting of the Association for Computational Lin-guistics (ACL 2013), pages 954?963.Seshan Srirangarajan and Dirk Pesch.
2013.
Sourcelocalization using graph-based optimization tech-nique.
In IEEE Wireless Communications and Net-working Conference (WCNC 2013), pages 1127?1132.Seshan Srirangarajan, Michael Allen, Ami Preis, Mu-dasser Iqbal, HockBeng Lim, and AndrewJ.Whittle.2013.
Wavelet-based burst event detection and lo-calization in water distribution systems.
Journal ofSignal Processing Systems, 72(1):1?16.Ivan Stoianov, Lama Nachman, Steve Madden, TimurTokmouline, and M Csail.
2007.
PIPENET: Awireless sensor network for pipeline monitoring.
InThe 6th International Symposium on InformationProcessing in Sensor Networks (IPSN 2007), pages264?273.Weiren Yu and Julie A. McCann.
2014.
Sig-SR: Sim-Rank search over singular graphs.
In Proceedingsof the 37th ACM SIGIR International Conference onResearch & Development in Information Retrieval(SIGIR 2014), pages 859?862.Weiren Yu and Julie A McCann.
2015.
Efficientpartial-pairs SimRank search on large networks.Proceedings of the VLDB Endowment (PVLDB2015), 8(5):569?580.Weiren Yu, Xuemin Lin, Wenjie Zhang, Ying Zhang,and Jiajin Le.
2012a.
SimFusion+: Extending Sim-Fusion towards efficient estimation on large and dy-namic networks.
In Proceedings of the 35th ACMSIGIR International Conference on Research & De-velopment in Information Retrieval (SIGIR 2012),pages 365?374.332Weiren Yu, Wenjie Zhang, Xuemin Lin, Qing Zhang,and Jiajin Le.
2012b.
A space and time efficientalgorithm for SimRank computation.
World WideWeb, 15(3):327?353.Weiren Yu, Xuemin Lin, and Wenjie Zhang.
2014.Fast incremental SimRank on link-evolving graphs.In Proceedings of the 30th IEEE International Con-ference on Data Engineering (ICDE 2014), pages304?315.Weiren Yu, Xuemin Lin, Wenjie Zhang, and Julie A.McCann.
2015.
Fast all-pairs SimRank assess-ment on large graphs and bipartite domains.
IEEETransactions on Knowledge and Data Engineering(TKDE), 27(7):1810?1823.Wei Zhang, Yan Chuan Sim, Jian Su, and Chew LimTan.
2011.
Entity linking with effective acronymexpansion, instance selection and topic modeling.
InProceedings of the 22nd International Joint Confer-ence on Artificial Intelligence (IJCAI 2011), pages1909?1914.Yang Zhou, Hong Cheng, and Jeffrey Xu Yu.
2009.Graph clustering based on structural / attribute sim-ilarities.
Proceedings of the VLDB Endowment(PVLDB), 2(1):718?729.Uri Zwick.
2002.
All pairs shortest paths using bridg-ing sets and rectangular matrix multiplication.
Jour-nal of the ACM (JACM), 49(3):289?317.333
