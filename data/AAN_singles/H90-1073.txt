Session 12: Speech Recognition IIJordan Cohen, ChairIDA Center for Communication ResearchThanet RoadPrinceton, NJ 08540This session was the final formal meeting, and con-tained the "et cetera" papers.
These all discussed speechrecognition algorithms, but these differed from the standardHMM's reported uring most of the meeting.
Each ofthese papers comes to grips with an aspect of training data,uncertainty in the recognition, and number of parameters tobe set.In the first paper, Jim Glass sketched some of theavenues pursued in the MIT SUMMIT work.
They havebeen working on input normalization, different segmentalrepresentations, and issues in experimental phonetics.
Theauditory model requires careful normalization (aconditionalso explored by IBM in several ICASSP papers), and anon-linear adaptive technique was described withoutresults.
Boundary classification was discussed, and amodified metric for computing edges was shown to giveimproved phonetic recognition.
In addition, an MLP clas-sifter was developed and tested using an augmented bound-ary representation.
Every time additional information wasincluded in the MLP classifier performance improved, butoverall the best classification was not as good as thatreported by Phillips in JASA.Ron Cole then presented his recent work on spoken al-phabet recognition using MLP techniques and a variety ofacoustical and segmental features.
He reported reasonableerror rates, and success in performing name retrieval from adatabase using spelled input.
Secondary networks wereused to resolve acoustic ambiguity, and were not univer-sally successful in this task.
Unfortunately Ron did notpresent performance figures on Brown's substantial E-setcorpus, so it is difficult o calibrate his work with previousresults.Matt Lennig presented a review of the INRS work withlarge vocabulary recognition for isolated English usingHMM techniques.
He outlined the development of trigrammodels, microsegmental models, and duration models inthe traditional framework.
The most important recentdevelopment was switching from a VQ front end to a mix-ture of Gaussians.
Performance was in the range of 7%word error with the best system using an 86,000 wordvocabulary.The final paper was a presentation by Martin Russellreviewing the RSRE results on the Airborne Reconnais-sance Task.
The speaker dependent task uses HMM tech-niques with highly stylized text.
The most interesting ob-servations from this work were observed variations in per-formance as a function of the number of free parameters inthe model - an obvious peak in performance an be seen at40-80 thousand parameters.
Martin observes that withfewer parameters the system cannot capture the speechvariability, while with more parameters the training data inhis corpus is inadequate oset the model.These papers taken together were a refreshing look atnon-ARPA funded speech recognition projects, togetherwith a few novel ideas from MIT.
The audience was quietand undemanding.Charles Wayne ended the session on a positive note,remarking that there continued to be progress in speechrecognition, and that the natural language ffort had passedan historic milestone in its quantitative t sts of the tAGdata.
He wished everyone more success in the future.379
