Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1358?1367,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPImproved Statistical Machine Translation for Resource-Poor LanguagesUsing Related Resource-Rich LanguagesPreslav NakovDepartment of Computer ScienceNational University of Singapore13 Computing DriveSingapore 117417nakov@comp.nus.edu.sgHwee Tou NgDepartment of Computer ScienceNational University of Singapore13 Computing DriveSingapore 117417nght@comp.nus.edu.sgAbstractWe propose a novel language-independentapproach for improving statistical ma-chine translation for resource-poor lan-guages by exploiting their similarity toresource-rich ones.
More precisely, weimprove the translation from a resource-poor source language X1into a resource-rich language Y given a bi-text contain-ing a limited number of parallel sentencesfor X1-Y and a larger bi-text for X2-Yfor some resource-rich language X2thatis closely related to X1.
The evaluationfor Indonesian?English (using Malay)and Spanish?English (using Portugueseand pretending Spanish is resource-poor)shows an absolute gain of up to 1.35 and3.37 Bleu points, respectively, which is animprovement over the rivaling approaches,while using much less additional data.1 IntroductionRecent developments in statistical machine trans-lation (SMT), e.g., the availability of efficient im-plementations of integrated open-source toolkitslike Moses (Koehn et al, 2007), have made it pos-sible to build a prototype system with decent trans-lation quality for any language pair in a few daysor even hours.
In theory.
In practice, doing sorequires having a large set of parallel sentence-aligned bi-lingual texts (a bi-text) for that lan-guage pair, which is often unavailable.
Large high-quality bi-texts are rare; except for Arabic, Chi-nese, and some official languages of the EuropeanUnion (EU), most of the 6,500+ world languagesremain resource-poor from an SMT viewpoint.While manually creating a small bi-text couldbe relatively easy, building a large one is hard,e.g., because of copyright.
Most bi-texts for SMTcome from parliament debates and legislation ofmulti-lingual countries (e.g., French-English fromCanada, and Chinese-English from Hong Kong),or from international organizations like the UnitedNations and the European Union.
For exam-ple, the Europarl corpus of parliament proceed-ings consists of about 1.3M parallel sentences (upto 44M words) per language for 11 languages(Koehn, 2005), and the JRC-Acquis corpus pro-vides a comparable amount of European legisla-tion in 22 languages (Steinberger et al, 2006).The official languages of the EU are especiallylucky in that respect; while this includes such?classic SMT languages?
like English and French,and some important international ones like Span-ish and Portuguese, most of the rest have a limitednumber of speakers and were resource-poor untilrecently; this is changing quickly because of theincreasing volume of EU parliament debates andthe ever-growing European legislation.
Thus, be-coming an official language of the EU has turnedout to be an easy recipe for getting resource-rich inbi-texts quickly.
Of course, not all languages arethat ?lucky?, but many can still benefit.In this paper, we propose using bi-texts forresource-rich language pairs to build better SMTsystems for resource-poor ones by exploiting thesimilarity between a resource-poor language and aresource-rich one.The proposed method allows non-EU languagesto benefit from being closely related to one ormore official languages of the EU, the mostobvious candidates being Norwegian (related toSwedish), Moldavian1(related to Romanian), andMacedonian2(related to Bulgarian).
After Croa-tia joins the EU, Serbian, Bosnian and Montene-grin will be able to benefit from Croatian graduallyturning resource-rich (all four split from Serbo-Croatian after the breakup of Yugoslavia).
Thenewly-made EU-official (and thus not as resource-1Not recognized by Romania.2Not recognized by Bulgaria and Greece.1358rich) Czech and Slovak are another possible pairof candidates.
As we will see below, even suchresource-rich languages like Spanish and Por-tuguese can benefit from the proposed method.
Ofcourse, many pairs of closely related languagescan be also found outside of Europe, Malay andIndonesian being just one such example we willexperiment with.The remainder of the present paper is organizedas follows: Section 2 presents our method, Sec-tion 3 describes the experiments, and Section 4discusses the results and the general applicabilityof the approach.
Section 5 provides an overviewof the related work.
Finally, Section 6 concludesand suggests possible directions for future work.2 MethodWe propose a novel language-independent ap-proach for improving statistical machine trans-lation for resource-poor languages by exploitingtheir similarity to resource-rich ones.
More pre-cisely, we improve the translation from a resource-poor source language X1into a resource-rich tar-get language Y given a bi-text containing a limitednumber of parallel sentences forX1-Y and a muchlarger bi-text forX2-Y for some resource-rich lan-guage X2that is closely related to X1.Our method exploits the similarity between re-lated languages with respect to word order, syntax,and, most importantly, vocabulary overlap ?
re-lated languages share a large number of cognates.Before we present the method, we will describetwo simple strategies for integrating the bi-text forX2-Y into a phrase-based SMT system for X1-Y .2.1 Merging Bi-textsWe can simply concatenate the bi-texts for X1-Yand X2-Y into one large bi-text and use it to trainan SMT system.This offers several advantages.
First, it canyield improved word alignments for the sentencesthat came from the X1-Y bi-text, e.g., since theadditional sentences can provide new contexts forthe rare words in that bi-text; rare words arehard to align, which could have a disastrous ef-fect on the subsequent phrase extraction stage.Second, it can provide new source-language sidetranslation options, thus increasing the lexicalcoverage and reducing the number of unknownwords at translation time; it can also provide newuseful non-compositional phrases on the source-language side, thus yielding more fluent transla-tion output.
Third, it can offer new target-languageside phrases for known source phrases, whichcould improve fluency by providing more trans-lation options for the language model (LM) tochoose from.
Fourth, bad phrases including wordsfrom X2that do not exist in X1will be effectivelyignored at translation time since they could neverpossibly match the input, while bad new target-language translations still have the chance to befiltered out by the language model.However, simple concatenation can be problem-atic.
First, when concatenating the small bi-textfor X1-Y with the much larger one for X2-Y , thelatter will dominate during word alignment andphrase extraction, thus hugely influencing bothlexical and phrase translation probabilities, whichcan yield poor performance.
This can be counter-acted by repeating the small bi-text several timesso that the large one does not dominate.
Sec-ond, since the bi-texts are merged mechanically,there is no way to distinguish between phrases ex-tracted from the bi-text for X1-Y (which shouldbe good), from those coming from the bi-text forX2-Y (whose quality might be questionable).2.2 Combining Phrase TablesAn alternative way of making use of the additionalbi-text for X2-Y to train an improved SMT sys-tem for X1?
Y is to build separate phrase ta-bles from X1-Y and X2-Y , which can then be(a) used together, e.g., as alternative decodingpaths, (b) merged, e.g., using one or more extrafeatures to indicate the bi-text each phrase camefrom, or (c) interpolated, e.g., using simple linearinterpolation.Building two separate phrase tables offers sev-eral advantages.
First, the good phrases from thebi-text forX1-Y are clearly distinguished from (orgiven a higher weight in the linear interpolationcompared to) the potentially bad ones from theX2-Y bi-text.
Second, the lexical and the phrasetranslation probabilities are combined in a princi-pled manner.
Third, using an X2-Y bi-text that ismuch larger than that for X1-Y is not problematicany more.
Fourth, as with bi-text merging, thereare many additional source- and target-languagephrases, which offer new translation options.On the negative side, the opportunity is lostto obtain improved word alignments for the sen-tences in the X1-Y bi-text.13592.3 Proposed MethodTaking into account the potential advantages anddisadvantages of the above strategies, we pro-pose a method that tries to get the best of both:(i) increased lexical coverage by using additionalphrase pairs independently extracted from X2-Y ,and (ii) improved word alignments for X1-Y bybiasing the word alignment process with addi-tional sentence pairs from X2-Y (possibly also re-peating X1-Y several times).
A detailed descrip-tion of the method follows:1.
Build a bi-text Bcatthat is a concatenationof the bi-texts for X1-Y and X2-Y .
Gener-ate word alignments forBcat, extract phrases,and build a phrase table Tcat.2.
Build a bi-text Brepfrom the X1-Y bi-textrepeated k times followed by one copy of theX2-Y bi-text.
Generate word alignments forBrep, then truncate them, only keeping wordalignments for one copy of the X1-Y bi-text.Use these word alignments to extract phrases,and build a phrase table Trep trunc.3.
Produce a phrase table Tmergedby combin-ing Tcatand Trep trunc, giving priority to thelatter, and use it in an X1?
Y SMT system.2.4 TransliterationAs we mentioned above, our method relies on theexistence of a large number of cognates betweenrelated languages.
While linguists define cognatesas words derived from a common root3(Bickfordand Tuggy, 2002), computational linguists typi-cally ignore origin, defining them as words in dif-ferent languages that are mutual translations andhave a similar orthography (Bergsma and Kon-drak, 2007; Mann and Yarowsky, 2001; Melamed,1999).
In this paper, we adopt the latter definition.Cognates between related languages often ex-hibit minor spelling variations, which can be sim-ply due to different rules of orthography, (e.g.,senhor vs. se?nor in Portuguese and Spanish), butoften stem from real phonological differences.
Forexample, the Portuguese suffix -c?
?ao correspondsto the Spanish suffix -ci?on, e.g., evoluc?
?ao vs.evoluci?on.
Such correspondences can be quite fre-quent and thus easy to learn automatically4.
Even3E.g., Latin tu, Old English thou, Spanish t?u, Greek s?u andGerman du are all cognates meaning ?2ndperson singular?.4Not all such differences are systematic; many apply to aparticular word only, e.g., kerana vs. karena in Malay andIndonesian, or dizer vs. decir in Portuguese and Spanish.more frequent can be the inflectional variations.For example, in Portuguese and Spanish respec-tively, verb endings like -ou vs. -?o (for 3rd personsingular, simple past tense), e.g., visitou vs. visit?o,or -ei vs. -?e (for 1st person singular, simple pasttense), e.g., visitei vs. visit?e.If such systematic differences exist between thelanguages X1and X2, it might be useful to learnand to use them as a pre-processing step in orderto transliterate the X2side of the X2-Y bi-textand thus increase its vocabulary overlap with thesource language X1.We will describe our approach to automatictransliteration in more detail in Section 3.4 below.3 Experiments3.1 Language PairsWe experimented with two language pairs: theclosely relatedMalay and Indonesian and the moredissimilar Spanish and Portuguese.Malay and Indonesian are mutually intelligible,but differ in pronunciation and vocabulary.
An ex-ample follows5:?
Malay: Semua manusia dilahirkan bebasdan samarata dari segi kemuliaan dan hak-hak.?
Indonesian: Semua orang dilahirkanmerdeka dan mempunyai martabat danhak-hak yang sama.Spanish and Portuguese also exhibit a notice-able degree of mutual intelligibility, but differ inpronunciation, spelling, and vocabulary.
UnlikeMalay and Indonesian, however, they also differsyntactically and have a high degree of spellingdifferences as demonstrated by the following ex-amples6:?
Spanish: Se?nora Presidenta, estimados cole-gas, lo que est?a sucediendo en Oriente Medioes una tragedia.?
Portuguese: Senhora Presidente, caros cole-gas, o que est?a a acontecer no Medio Oriente?e uma trag?edia.5In English: All human beings are born free and equal indignity and rights.
(from Article 1 of the Universal Declara-tion of Human Rights)6In English: Madam President, ladies and gentlemen, theevents in the Middle East are a real tragedy.13603.2 DatasetsIn our experiments, we used the following numberof training sentence pairs (number of words shownin parentheses) for English (en), Indonesian (in),Malay (ml), Portuguese(pt), and Spanish (es):?
Indonesian-English (in-en):?
28,383 pairs (0.8M, 0.9M words);?
monolingual English enin: 5.1M words.?
Malay-English (ml-en):?
190,503 pairs (5.4M, 5.8M words);?
monoling.
English enml: 27.9M words.?
Spanish-English (es-en):?
1,240,518 pairs (35.7M, 34.6M words);?
monolingual English enes:pt: 45.3Mwords (the same as for pt-en).?
Portuguese-English (pt-en):?
1,230,038 pairs (35.9M, 34.6M words).?
monolingual English enes:pt: 45.3Mwords (the same as for es-en).All of the above datasets contain sentences withup to 100 tokens.
In addition, for each of thefour language pairs, we have a development anda testing bi-text, each with 2,000 parallel sentencepairs.
We made sure the development and the test-ing bi-texts shared no sentences with the trainingbi-texts; we further excluded from the monolin-gual English data all sentences from the Englishsides of the training and the development bi-texts.The training bi-text datasets for es-en and pt-enwere built from release v.3 of the Europarl corpus,excluding the Q4/2000 portion out of which wecreated our testing and development datasets.We built the in-en bi-texts from texts that wedownloaded from the Web.
We translated the In-donesian texts to English using Google Translate,and we matched7them against the English textsusing a cosine similarity measure and heuristicconstraints based on document length in wordsand in sentences, overlap of numbers, words inuppercase, and words in the title.
Next, we ex-tracted pairs of sentences from the matched doc-ument pairs using competitive linking (Melamed,2000), and we retained the ones whose similaritywas above a pre-specified threshold.
The ml-enwas built in a similar manner.7Note that the automatic translations were used for match-ing only; the final bi-text contained no automatic translations.3.3 Baseline SMT SystemIn the baseline, we used the following setup: Wefirst tokenized and lowercased both sides of thetraining bi-text.
We then built separate directedword alignments for English?X andX?English(X?
{Indonesian, Spanish}) using IBM model 4(Brown et al, 1993), combined them using the in-tersect+grow heuristic (Och and Ney, 2003), andextracted phrase-level translation pairs of maxi-mum length seven using the alignment templateapproach (Och and Ney, 2004).
We thus obtaineda phrase table where each pair is associated withfive parameters: forward and reverse phrase trans-lation probabilities, forward and reverse lexicaltranslation probabilities, and phrase penalty.We then trained a log-linear model using stan-dard SMT feature functions: trigram languagemodel probability, word penalty, distance-based8distortion cost, and the parameters from the phrasetable.
We set al weights by optimizing Bleu (Pap-ineni et al, 2002) using minimum error rate train-ing (MERT) (Och, 2003) on a separate develop-ment set of 2,000 sentences (Indonesian or Span-ish), and we used them in a beam search decoder(Koehn et al, 2007) to translate 2,000 test sen-tences (Indonesian or Spanish) into English.
Fi-nally, we detokenized the output, and we evaluatedit against a lowercased gold standard using Bleu9.3.4 TransliterationAs was mentioned in Section 2, transliteration canbe helpful for languages with regular spelling dif-ferences.
Thus, we built a system for translitera-tion from Portuguese into Spanish that was trainedon a list of automatically extracted likely cognates.The system was applied on the Portuguese side ofthe pt-en training bi-text.Classic approaches to automatic cognate extrac-tion look for non-stopwords with similar spellingthat appear in parallel sentences in a bi-text (Kon-drak et al, 2003).
In our case, however, we need toextract cognates between Spanish and Portuguesegiven pt-en and es-en bi-texts only, i.e., withouthaving a pt-es bi-text.
Although it is easy to con-struct a pt-es bi-text from the Europarl corpus,we chose not to do so since, in general, synthe-8We also tried lexicalized reordering (Koehn et al, 2005).While it yielded higher absolute Bleu scores, the relative im-provement for a sample of our experiments was very similarto that achieved with distance-based re-ordering.9We used version 11b of the NIST scoring tool:http://www.nist.gov/speech/tools/1361sizing a bi-text for X1-X2would be impossible:e.g., it cannot be done for ml-in given our trainingdatasets for in-en andml-en since the English sidesof these bi-texts have no sentences in common.Thus, we extracted the list of likely cognates be-tween Portuguese and Spanish from the trainingpt-en and es-en bi-texts using English as a pivot asfollows: We started with IBM model 4 word align-ments, from which we extracted four conditionallexical translation probabilities: Pr(pj|ei) andPr(ei|pj) for Portuguese-English, and Pr(sk|ei)and Pr(ei|sk) for Spanish-English, where pj, eiand skstand for a Portuguese, an English anda Spanish word respectively.
Following Wu andWang (2007), we then induced conditional lexicaltranslation probabilities Pr(pj|sk) and Pr(sk|pj)for Portuguese-Spanish as follows:Pr(pj|sk) =?iPr(pj|ei, sk)Pr(ei|sk)Assuming pjis conditionally independent of skgiven ei, we can simplify the above expression:Pr(pj|sk) =?iPr(pj|ei)Pr(ei|sk)Similarly, for Pr(sk|pj), we obtainPr(sk|pj) =?iPr(sk|ei)Pr(ei|pj)We excluded all stopwords, words of length lessthan three, and those containing digits.
We furthercalculated Prod(pj, sk) = Pr(pj|sk)Pr(sk|pj),and we excluded all Portuguese-Spanish wordpairs (pj, sk) for which Prod(pj, sk) < 0.01.From the remaining pairs, we extracted likely cog-nates based on Prod(pj, sk) and on the ortho-graphic similarity between pjand sk.Following Melamed (1995), we measured theorthographic similarity using the longest commonsubsequence ratio (LCSR), defined as follows:LCSR(s1, s2) =|LCS(s1,s2)|max(|s1|,|s2|)where LCS(s1, s2) is the longest common subse-quence of s1and s2, and |s| is the length of s.We retained as likely cognates all pairs forwhich LCSR was 0.58 or higher; that value wasfound by Kondrak et al (2003) to be optimal for anumber of language pairs in the Europarl corpus.Finally, we performed competitive linking(Melamed, 2000), assuming that each Portuguesewordform had at most one Spanish best cognatematch.
Thus, using the values of Prod(pj, sk),we induced a fully-connected weighted bipartitegraph.
Then, we performed a greedy approxima-tion to the maximum weighted bipartite match-ing in that graph (i.e., competitive linking) as fol-lows: First, we accepted as cognates the cross-lingual pair (pj, sk) with the highest Prod(pj, sk)in the graph, and we discarded pjand skfrom fur-ther consideration.
Then, we accepted the nexthighest-scored pair, and we discarded the involvedwordforms and so forth.
The process was repeateduntil there were no matchable pairs left.As a result of the above procedure, we endedup with 28,725 Portuguese-Spanish cognate pairs,9,201 (or 32%) of which had spelling differences.For each pair in the list of cognate pairs, we addedspaces between any two adjacent letters for bothwordforms, and we further appended the start andthe end characters ?
and $.
For example, the cog-nate pair evoluc?
?ao ?
evoluci?on became?
e v o l u c?
?a o $ ?
?
e v o l u c i ?o n $We randomly split the resulting list into a train-ing (26,725 pairs) and a development dataset(2,000 pairs), and trained and tuned a character-level phrase-based monotone SMT system similarto (Finch and Sumita, 2008) to transliterate a Por-tuguese wordform into a Spanish wordform.
Weused a Spanish language model trained on 14Mword tokens (obtained from the above-mentioned45.3M-token monolingual English corpus after ex-cluding punctuation, stopwords, words of lengthless than three, and those containing digits): oneper line and character-separated with added startand end characters as in the above example.
We setboth the maximum phrase length and the languagemodel order to ten; this value was found by tun-ing on the development dataset.
The system wastuned using MERT, and the feature weights weresaved.
The tuning Bleu was 95.22%, while thebaseline Bleu, for leaving the Portuguese wordsintact, was 87.63%.
Finally, the training and thetuning datasets were merged, and a new traininground was performed.
The resulting system wasused with the saved feature weights to transliteratethe Portuguese side of the training pt-en bi-text,which yielded a new ptes-en training bi-text.We did the same for Malay into Indonesian.
Weextracted 5,847 cognate pairs, 844 (or 14.4%) ofwhich had spelling differences, and we trained atransliteration system.
The highest tuning Bleuwas 95.18% (for maximum phrase size and LMorder of 10), but the baseline was 93.15%.
Wethen re-trained the system on the combination ofthe training and the development datasets, and wetransliterated the Malay side of the training ml-enbi-text, obtaining a new mlin-en training bi-text.1362# Train LM Dev Test 10K 20K 40K 80K 160K 320K 640K 1230K1 ml-en enmlml-en ml-en 44.93 46.98 47.15 48.04 49.01 ?
?
?2 mlin-en enmlml-en ml-en 38.99 40.96 41.02 41.88 42.81 ?
?
?3 ml-en enmlml-en in-en 13.69 14.58 14.76 15.12 15.84 ?
?
?4 ml-en enmlin-en in-en 13.98 14.75 14.91 15.51 16.27 ?
?
?5 ml-en eninin-en in-en 15.56 16.38 16.52 17.04 17.90 ?
?
?6 mlin-en eninin-en in-en 16.44 17.36 17.62 18.14 19.15 ?
?
?7 pt-en enes:ptpt-en pt-en 21.28 23.11 24.43 25.72 26.43 27.10 27.78 27.968 ptes-en enes:ptpt-en pt-en 10.91 11.56 12.16 12.50 12.83 13.27 13.48 13.719 pt-en enes:ptpt-en es-en 4.40 4.77 4.57 5.02 4.99 5.32 5.08 5.3410 pt-en enes:ptes-en es-en 4.91 5.12 5.64 5.82 6.35 6.87 6.44 7.1011 ptes-en enes:ptes-en es-en 8.18 9.03 9.97 10.66 11.35 12.26 12.69 13.79Table 1: Cross-lingual SMT experiments (shown in bold).
Columns 2-5 present the bi-texts used fortraining, development and testing, and the monolingual data used to train the English language model.The following columns show the resulting Bleu (in %s) for different numbers of training sentence pairs.3.5 Cross-lingual TranslationIn this subsection, we study the similarity betweenthe original and the additional source languages.First, we measured the vocabulary overlap be-tween Spanish and Portuguese, which was fea-sible since our training pt-en and es-en bi-textsare from the same time span in the Europarl cor-pus and their English sides largely overlap.
Wefound 110,053 Portuguese and 121,444 Spanishword types, and 44,461 (or 36.6%) of them wereidentical.
Unfortunately, we could not do the samefor Malay and Indonesian since the English sidesof the in-en and ml-en bi-texts do not overlap.Second, following the setup of the baseline sys-tem, we performed cross-lingual experiments.
Theresults are shown in Table 1.
As we can see, thisyielded a huge decrease in Bleu compared to thebaseline ?
three to five times ?
even for very largetraining datasets, and even when a proper EnglishLM and development dataset were used: compareline 1 to lines 3-6, and line 7 to lines 9-11.Third, we tried transliteration.
Bleu doubled forSpanish (see lines 10-11), but improved far less forIndonesian (lines 5-6).
Training on the translit-erated data and testing on Malay and Portugueseyielded about 10-12% relative decrease for Malay(lines 1-2) but 50% for Portuguese (lines 7-8).10Thus, unlike Spanish and Portuguese, therewere far less systematic spelling variations be-tween Malay and Indonesian.
A closer inspec-tion confirmed this: many extracted likely Malay-Indonesian cognate pairs with spelling differenceswere in fact forms of a word existing in both lan-guages, e.g., kata and berkata (?to say?
).10However, as lines 8 and 11 show, a system trained on1.23M ptes-en sentence pairs, performs equally well whentranslating Portuguese and Spanish text: 13.71% vs. 13.79%.3.6 Using an Additional LanguageWe performed various experiments combining theoriginal and an additional training bi-text:Two-tables: We built two separate phrase tablesfor the two bi-texts, and we used them in the alter-native decoding path model of Birch et al (2007).Interpolation: We built two separate phrasetables for the original and for the additional bi-text, and we used linear interpolation to com-bine the corresponding conditional probabilities:Pr(e|s) = ?Prorig(e|s) + (1 ?
?
)Prextra(e|s).We optimized the value of ?
on the developmentdataset, trying .5, .6, .7, .8 and .9; we used thesame ?
for all four conditional probabilities.Merge: We built separate phrase tables, Torigand Textra, for the original and for the additionaltraining bi-text.
We then concatenated them giv-ing priority to Torig: We kept all phrase pairs fromTorig, adding to them those ones from Textrathatwere not present in Torig.
For each phrase pairadded, we retained its associated conditional prob-abilities and the phrase penalty.
We further addedthree additional features to each entry in the newtable: F1, F2and F3.
The value of F1was 1 ifthe phrase pair came from Torig, and 0.5 other-wise.
Similarly, F2=1 if the phrase pair came fromTextra, and F2=0.5 otherwise.
The value of F3was 1 if the pair came from both Torigand Textra,and 0.5 otherwise.
We experimented using (1)F1only, (2) F1and F2, (3) F1, F2, and F3.
We setall feature weights using MERT, and we optimizedthe number of features on the development set.1111In theory, we should have also re-normalized the proba-bilities since they may not sum to one.
In practice, this wasnot that important since the log-linear SMT model does notrequire that the features be probabilities at all (e.g., the phrasepenalty), and we had extra features whose impact was bigger.1363Concat?k: We concatenated k copies of theoriginal and one copy of the additional training bi-text; we then trained and tuned an SMT system asfor the baseline.
The value for k was optimized onthe development dataset.Concat?k:align: We concatenated k copies ofthe original and one copy of the additional train-ing bi-text.
We then generated IBM model 4 wordalignments, and we truncated them, only keepingthem for one copy of the original training bi-text.Next, we extracted phrase pairs, thus buildng aphrase table, and we tuned an SMT system as forthe baseline.Our Method: Our method was described inSection 2.
We used merge to combine the phrasetables for concat?k:align and concat?1, consid-ering the former as Torigand the latter as Textra.We had two parameters to tune: k and the numberof extra features in the merged phrase table.Figure 1: Impact of k on Bleu for concat?k fordifferent number of extra ml-en sentence pairsin Indonesian?English SMT.4 Results and DiscussionFirst, we studied the impact of k on concat?kfor Indonesian?English SMT using Malay as anadditional language.
We tried all values of ksuch that 1?k?16 with 10000n extra ml-en sen-tence pairs, n?{1,2,4,8,16}.
As we can see inFigure 1, the highest Bleu scores are achievedfor (n; k)?
{(1;2),(2;2),(4;4),(8;7),(16;16)}, i.e.,when k ?
n. In order to limit the search space,we used this relationship between k and n in ourexperiments (also for Portuguese and Spanish).Table 2 shows the results for experiments onimproving Indonesian?English SMT using 10K,20K, .
.
., 160K additional ml-en pairs of paral-lel sentences.
Several observations can be made.First, using more additional sentences yields bet-ter results.
Second, with one exception, all ex-periments yield improvements over the baseline.Third, the improvements are always statisticallysignificant for our method, according to (Collinset al, 2005)?s sign test.
Overall, among the dif-ferent bi-text combination strategies, our methodperforms best, followed by concat?k, merge, andinterpolate, which are very close in performance;these three strategies are the only ones to consis-tently yield higher Bleu as the number of addi-tional ml-en sentence pairs grows.
Methods likeconcat?1, concat?k:align and two-tables aresomewhat inconsistent in that respect.
The lattermethod performs worst and is the only one to gobelow the baseline (for 10K ml-en pairs).Table 3 shows the results when using pt-en datato improve Spanish?English SMT.
Overall, theresults and the conclusions that can be made areconsistent with those for Table 2.
We can furtherobserve that, as the size of the original bi-text in-creases, the gain in Bleu decreases, which is to beexpected.
Note also that here transliteration is veryimportant: it doubles the absolute gain in Bleu.Finally, Table 4 shows a comparison to the piv-oting technique of Callison-Burch et al (2006).for English?Spanish SMT.
Despite using justPortuguese, we achieve an improvement that is, infive out of six cases, much better than what theyachieve with eight pivot languages (which includenot only Portuguese, but also two other Romancelanguages, French and Italian, which are closelyrelated to Spanish).
Moreover, our method yieldsimprovements for very large original datasets ?1.2M pairs, while theirs stops improving at 160K.However, our improvements are only statisticallysignificant for 160K original pairs or less.
Finally,note that our translation direction is reversed.Based on the experimental results, we can makeseveral conclusions.
First, we have shown that us-ing bi-text data from related languages improvesSMT: we achieved up to 1.35 and 3.37 improve-ment in Bleu for in-en (+ml-en) and es-en (+pt-en) respectively.
Second, while simple concate-nation can help, it is problematic when the ad-ditional sentences out-number the ones from theoriginal bi-text.
Third, concatenation can workvery well if the original bi-text is repeated enoughtimes so that the additional bi-text does not dom-inate.
Fourth, merging phrase tables giving prior-ity to the original bi-text and using additional fea-1364in-en ml-en Baseline Two tables Interpol.
Merge concat?1 concat?k concat?k:align Our method28.4K 10K 23.80< ?23.79<23.89<(.9)23.97<(3)24.29<24.29<(1)24.01<(1)<24.51(2;1)(+0.72)28.4K 20K 23.80<24.24<24.22<(.8)?24.46<(3)24.37< ?24.48(2)<24.35<(2)<24.70(2;2)(+0.90)28.4K 40K 23.80<24.27<24.27<(.8)24.43?(3)24.38?
?24.54(4)<24.39<(4)<24.73(4;2)(+0.93)28.4K 80K 23.80<24.11< ?24.46<(.8)<24.67(3)24.17< ?24.65<(8)24.18<(8)<24.97(8;3)(+1.17)28.4K 160K 23.80< <24.58< <24.58<(.8)<24.79?
(3)?24.43< <25.00(16)?24.27<(16)<25.15(16;3)(+1.35)Table 2: Improving Indonesian?English SMT using ml-en data.
Shown are the Bleu scores (in %s)for different methods.
A subscript shows the best parameter value(s) found on the development set andused on the test set to produce the given result.
Bleu scores that are statistically significantly better thanthe baseline/our method are marked on the left/right side by<(for p < 0.01) or?
(for p < 0.05).es-en pt-en Transl.
Baseline Two tables Interpol.
Merge concat?1 concat?k concat?k:align Our method10K 160K no 22.87< <23.81<23.73(.5)<23.60(2)<23.54< <23.83<(16)22.93<(16)<23.98(16;3)(+1.11)yes 22.87< <25.29?
<25.22<(.5)<25.16<(2)<25.26<25.42(16)<23.31<(16)<25.73(16;3)(+2.86)20K 160K no 24.71< <25.22?25.02<(.5)<25.32?
(3)<25.19< <25.29<(8)24.91<(8)<25.65(8;2)(+0.94)yes 24.71< <26.07?
<26.07(.7)<26.04<(3)<26.16?
<26.18?
(8)24.88<(8)<26.36(8;3)(+1.65)40K 160K no 25.80<25.96<26.15<(.6)25.99<(3)26.24<25.92<(4)25.99<(4)<26.49(4;2)(+0.69)yes 25.80< <26.68<26.43(.7)<26.64(3)<26.78<26.93(4)25.88<(4)<26.95(4;3)(+1.15)80K 160K no 27.08?
?26.89<27.04<(.8)27.02<(3)27.23 27.09<(2)27.01<(2)?27.30(2;2)(+0.22)yes 27.08<27.20<27.42(.5)27.29?
(3)27.26< ?27.53(2)27.09<(2)<27.49(2;3)(+0.41)160K 160K no 27.90 27.99 27.72(.5)27.95(2)27.83<27.83<(1)27.94(1)28.05(1;3)(+0.15)yes 27.90 28.11?28.13(.6)?28.17(2)?28.14?28.14(1)28.06(1)28.16(1;2)(+0.26)Table 3: Improving Spanish?English SMT using 160K additional pt-en sentence pairs.
Columnthree shows whether transliteration was used; the following columns list the Bleu scores (in %s) fordifferent methods.
A small subscript shows the best parameter value(s) found on the development setand used on the test set to produce the given result.
Bleu scores that are statistically significantly betterthan the baseline/our method are marked on the left/right side by<(for p < 0.01) or?
(for p < 0.05).tures is a good strategy.
Fifth, part of the improve-ment when combining bi-texts is due to increasedvocabulary coverage because of cognates, but an-other part comes from improved word alignments.Sixth, the best results are achieved when the lattertwo sources are first isolated and then combined(our method).
Finally, transliteration can help a lotin case of systematic spelling variations betweenthe original and the additional source languages.5 Related WorkIn this section, we describe two general lines ofrelated previous research: using cognates betweenthe source and the target language, and source-language side paraphrasing with a pivot language.5.1 CognatesMany researchers have used likely cognates toobtain improved word alignments and thus buildbetter SMT systems.
Al-Onaizan et al (1999)extracted such likely cognates for Czech-Englishusing one of the variations of LCSR (Melamed,1995) described in (Tiedemann, 1999) as a simi-larity measure.
They used these cognates to im-prove word alignments with IBM models 1-4 inthree different ways: (1) by seeding the parametersof IBM model 1, (2) by constraining the word co-occurrences when training IBM models 1-4, and(3) by adding the cognate pairs to the bi-text asadditional ?sentence pairs?.
The last approach per-formed best and was later used by Kondrak et al(2003) who demonstrated improved SMT for nineEuropean languages.Unlike these approaches, which extract cog-nates between the source and the target language,we use cognates between the source and someother related language that is different from thetarget.
Moreover, we only implicitly rely on theexistence of such cognates; we do not try to ex-tract them at all, and we leave them in their origi-nal sentence contexts.1212However, in some of our experiments, we extract cog-nates for training a transliteration system from the resource-rich source language X2into the resource-poor one X1.1365Direction System 10K 20K 40K 80K 160K 320K 1,230Ken?es baseline 22.6 25.0 26.5 26.5 28.7 30.0 ?pivoting (+8 languages ?
?1.3M pairs) 23.3 26.0 27.2 28.0 29.0 30.0 ?improvement +0.7 +1.0 +0.7 +1.5 +0.3 +0.0 ?es?en baseline 22.87 24.71 25.80 27.08 27.90 28.46 29.90our method (+1 language ?
160K pairs) 23.98?25.65?26.49?27.3028.05 28.52 29.87improvement +1.11?+0.94?+0.69?+0.22+0.15 +0.06 -0.03our method (translit., +1 lang.
?
160K) 25.73?26.36?26.95?27.49?28.16 28.43 29.94improvement +2.86?+1.65?+1.15?+0.41?+0.26 -0.03 +0.04our method (+1 language ?
1.23M pairs) 24.23?25.70?26.78?27.49 28.2228.58 29.84improvement +1.36?+0.99?+0.98?+0.41 +0.32+0.12 -0.06our method (translit., +1 lang.
?
1.23M) 26.24?26.82?27.47?27.85?28.50?28.70 29.99improvement +3.37?+2.11?+1.67?+0.77?+0.60?+0.24 +0.09Table 4: Comparison to the pivoting technique of Callison-Burch et al (2006) for English?Spanish.Shown are Bleu scores (in %s) and absolute improvement over the baseline for training bi-texts withdifferent numbers of parallel sentences (10K, 20K, .
.
., 1230K) and fixed amount of additional data:(1) about 1.3M sentence pairs for each of eight additional languages in Callison-Burch et al (2006)?spivoting, and (2) 160K and 1,230K pairs for one language (Portuguese) for our method.
Statisticallysignificant improvements over the baseline are marked with a?
(for p < 0.01) and with a(for p < 0.05).5.2 Paraphrasing with a Pivot-LanguageAnother relevant line of research is on using multi-lingual parallel corpora to improve SMT using ad-ditional languages as pivots.Callison-Burch et al (2006) improvedEnglish?Spanish and English?French SMTusing source-language paraphrases extracted withthe pivoting technique of Bannard and Callison-Burch (2005) and eight additional languages fromthe Europarl corpus (Koehn, 2005).
For example,using German as a pivot, they extracted Englishparaphrases from a parallel English-Germancorpus by looking for English phrases that werealigned to the same German phrase: e.g., if undercontrol and in check were aligned to unter con-trolle, they were hypothesized to be paraphraseswith some probability.
Such (English) paraphraseswere added as additional entries in the phrasetable of an English?Spanish/English?Frenchphrase-based SMT system and paired with theforeign (Spanish/French) translation of the origi-nal (English) phrase.
The system was then tunedwith MERT using an extra feature penalizinglow-probability paraphrases; this yielded up to1.8% absolute improvement in Bleu.Other important publications about pivoting ap-proaches for machine translation include (Wu andWang, 2007), (Utiyama and Isahara, 2007), (Haji?cet al, 2000) and (Habash and Hu, 2009).Unlike pivoting, which can only improvesource-language lexical coverage, we augmentboth the source- and the target-language sides.Second, while pivoting ignores context when ex-tracting paraphrases, we take it into account.Third, by using as an additional language one thatis related to the source, we are able to get increasein Bleu that is comparable and even better thanwhat pivoting achieves with eight pivot languages.On the negative side, our approach is limited inthat it requires that X2be related to X1, while thepivoting language Z does not need to be related toX1nor to Y .
However, we only need one addi-tional parallel corpus (for X2-Y ), while pivotingneeds two: one for X1-Z and one for Z-Y .
Fi-nally, note that our approach is orthogonal to piv-oting, and thus the two can be combined.6 Conclusion and Future WorkWe have proposed a novel method for improvingSMT for resource-poor languages by exploitingtheir similarity to resource-rich ones.In future work, we would like to extend that ap-proach in several interesting directions.
First, wewant to make better use of multi-lingual parallelcorpora, e.g., while we had access to a Spanish-Portuguese-English corpus, we used it as twoseparate bi-texts Spanish-English and Portuguese-English.
Second, we would like to exploit multi-ple auxiliary resource-rich languages the resource-poor source language is related to.
Third, we couldalso experiment with using auxiliary languagesthat are related to the target language.AcknowledgmentsThis research was supported by research grantPOD0713875.1366ReferencesYaser Al-Onaizan, Jan Curin, Michael Jahr, KevinKnight, John Lafferty, Dan Melamed, Franz JosephOch, David Purdy, Noah Smith, and DavidYarowsky.
1999.
Statistical machine translation.Technical report, CLSP, Johns Hopkins University,Baltimore, MD.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Pro-ceedings of ACL?05, pages 597?604.Shane Bergsma and Grzegorz Kondrak.
2007.Alignment-based discriminative string similarity.
InProceedings of ACL?07, pages 656?663.Albert Bickford and David Tuggy.
2002.Electronic glossary of linguistic terms.http://www.sil.org/mexico/ling/glosario/E005ai-Glossary.htm.Alexandra Birch, Miles Osborne, and Philipp Koehn.2007.
CCG supertags in factored statistical machinetranslation.
In Proceedings of WMT?2007, pages 9?16.Peter Brown, Vincent Della Pietra, Stephen DellaPietra, and Robert Mercer.
1993.
The mathematicsof statistical machine translation: parameter estima-tion.
Computational Linguistics, 19(2):263?311.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine trans-lation using paraphrases.
In Proceedings of HLT-NAACL?06, pages 17?24.Michael Collins, Philipp Koehn, and Ivona Ku?cerov?a.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of ACL?05, pages 531?540.Andrew Finch and Eiichiro Sumita.
2008.
Phrase-based machine transliteration.
In Proceedings ofWTCAST?08, pages 13?18.Nizar Habash and Jun Hu.
2009.
Improving Arabic-Chinese statistical machine translation using Englishas pivot language.
In Proceedings of the WMT?09,pages 173?181.Jan Haji?c, Jan Hric, and Vladislav Kubo?n.
2000.
Ma-chine translation of very close languages.
In Pro-ceedings of ANLP?00, pages 7?12.Philipp Koehn, Amittai Axelrod, Alexandra BirchMayne, Chris Callison-Burch, Miles Osborne, andDavid Talbot.
2005.
Edinburgh system descriptionfor the 2005 IWSLT speech translation evaluation.In Proceedings of IWSLT?05.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, and Evan Herbst.
2007.
Moses:Open source toolkit for statistical machine transla-tion.
In Proceedings of ACL?07.
Demonstration ses-sion, pages 177?180.Philipp Koehn.
2005.
Europarl: A parallel corpus forevaluation of machine translation.
In Proceedings ofMT Summit, pages 79?86.Grzegorz Kondrak, Daniel Marcu, and Kevin Knight.2003.
Cognates can improve statistical translationmodels.
In Proceedings of NAACL?03, pages 46?48.Gideon Mann and David Yarowsky.
2001.
Multipathtranslation lexicon induction via bridge languages.In Proceedings of NAACL?01, pages 1?8.Dan Melamed.
1995.
Automatic evaluation and uni-form filter cascades for inducing N-best translationlexicons.
In Proceedings of WVLC?95, pages 184?198.Dan Melamed.
1999.
Bitext maps and alignmentvia pattern recognition.
Computational Linguistics,25(1):107?130.Dan Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4):417?449.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Proceedings ofACL?03, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automaticevaluation of machine translation.
In Proceedingsof ACL?02, pages 311?318.Ralf Steinberger, Bruno Pouliquen, Anna Widiger,Camelia Ignat, Tomaz Erjavec, Dan Tufis, andDaniel Varga.
2006.
The JRC-Acquis: A multilin-gual aligned parallel corpus with 20+ languages.
InProceedings of LREC?2006, pages 2142?2147.Jorg Tiedemann.
1999.
Automatic construction ofweighted string similarity measures.
In Proceedingsof EMNLP-VLC?99, pages 213?219.Masao Utiyama and Hitoshi Isahara.
2007.
A com-parison of pivot methods for phrase-based statisti-cal machine translation.
In Proceedings of NAACL-HLT?07, pages 484?491.Hua Wu and Haifeng Wang.
2007.
Pivot language ap-proach for phrase-based statistical machine transla-tion.
Machine Translation, 21(3):165?181.1367
