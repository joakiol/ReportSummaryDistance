Recognition Using Classificationand Segmentation Scoring*Owen Kimball t, Mari Ostendorf t, Robin Rohlicekt Boston University :~ BBN Inc.44 Cummington St. 10 Moulton St.Boston, MA 02215 Cambridge, MA 02138ABSTRACTTraditional statistical speech recognition systems typicallymake strong assumptions about the independence of obser-vation frames and generally do not make use of segmentalinformation.
In contrast, when the segmentation is known,existing classifiers can readily accommodate s gmental infor-mation in the decision process.
We describe an approach toconnected word recognition that allows the use of segmentalinformation through an explicit decomposition of the recog-nition criterion into classification and segmentation scoring.Preliminary experiments are presented, emonstrating thatthe proposed framework, using fixed length sequences ofcep-stral feature vectors for classification of individual phonemes,performs comparably to more traditional recognition ap-proaches that use the entire observation sequence.
We expectthat performance gain can be obtained using this structurewith additional, more general features.1.
INTRODUCTIONAlthough hidden-Markov-model (HMM) based speechrecognition systems have achieved very high perfor-mance, it may be possible to improve on their perfor-mance by addressing the known deficits of the HMM.Perhaps the most obvious weaknesses of the model arethe reliance on frame-based feature extraction and theassumption of conditional independence of these featuresgiven an underlying state sequence.
The assumption ofindependence disagrees with what is known of the ac-tual speech signal, and when this framework is accepted,it is difficult to incorporate potentially useful measure-ments made across an entire segment of speech.
Much ofthe linguistic knowledge of acoustic-phonetic propertiesof speech is most naturally expressed in such segmentalmeasurements, and the inability to use such measure-ments may represent a significant loss in potential per-formance.In an attempt o address this issue, a number of mod-els have been proposed that use segmental features asthe basis of recognition.
Although these models al-low the use of segmental measurements, they have notyet achieved significant performance gains over HMMs*This research was jointly funded by NSF and DARPA underNSF grant number IRI-8902124.because of difficulties associated with modeling a vari-able length observation with segmental features.
Manyof these models represent the segmental characteristicsas a fixed-dimensional vector of features derived fromthe variable-length observation sequence.
Although suchfeatures may work quite well for classification of individ-ual units, such as phonemes or syllables, it is less obvioushow to use fixed-length features to score a sequence ofthese units where the number and location of the unitsis not known.
For example, simply taking the productof independent phoneme classification probabilities usingfixed length measurements is inadequate.
If this is done,the total number of observations used for an utteranceis F x N, where F is the fixed number of features persegment and N is the number of phonemes in the hypoth-esized sentence.
As a result, the scores for hypotheseswith different numbers of phonemes will effectively becomputed over different dimensional probability spaces,and as such, will not be comparable.
In particular, longsegments will have lower costs per frame than short seg-ments.In this paper, we address the segment modeling prob-lem using an approach that decomposes the recognitionprocess into a segment classification problem and a seg-mentation scoring problem.
The explicit use of a clas-sification component allows the direct use of segmentalmeasures as well as a variety of classification techniquesthat are not readily accommodated with other formu-lations.
The segmentation score component effectivelynormalizes the scores of different length sequences, mak-ing them comparable.2.
CLASS IF ICAT ION ANDSEGMENTATION SCORING2.1.
Genera l  Mode lThe goal of speech recognition systems is to find the mostlikely label sequence, A = al, ..., air given a sequence ofacoustic observations, X.
For simplicity, we can restrictthe problem to finding the label sequence, A, and seg-mentation, $ = s l , .
.
.
,SN,  that have the highest jointlikelihood given the observations.
(There is typically no197explicit segmentation component in the formulation forHMMs; in this case, the underlying state sequence isanalogous to the segmentation-label sequence.)
The re-quired optimization is then to find labels A* such thatA* = argmaxp(A,S IX)A,S= argmaxp(A, S, X).
(1)A,SThe usual decomposition f this probability isp(A, S, X) = p(X \[ A, S)p(S \[ A)p(A) (2)as is commonly used in HMMs and has been used in ourprevious segment modeling.
However, we can consideran alternative decomposition:p(A, S, X) = p(A \[ S, X)p(S, X).In this case, the optimization problem has two compo-~C1 nents a lassffication probability," p(A I S,X), and a"probability of segmentation", p(S, X).
We refer to thisapproach as classification-in-recognition (CIR).The CIR approach as a number of potential advan-tages related to the use of a classification component.First, segmental features can be accommodated in thisapproach by constraining p(A \] X, S) to have the formp(A I Y(X), S), where y(X) is some function of the orig-inal observations.
The possibilities for this function in-clude the complete observation sequence itself, as wellas fixed dimensional segmental feature vectors computedfrom it.
A second advantage is that a number of differentclassifiers can be used to compute the posterior proba-bility, including neural networks and classification trees,as well as other approaches.To simplify initial experiments, we have made the as-sumption that phoneme segments are generated inde-pendently.
In this case (1) is rewritten asA* = argmax H p(ai I X(sl), si)p(si, X(si))A,S iwhere ai is one label of the sequence, si is a single seg-ment of the segmentation 1, and X(sl) is the portion ofthe observation sequence corresponding tosi.
Segmentalfeatures are incorporated by constraining p(a~ IX(s0, s~)to be of the form p(a~ If(X(sl)), s0, as mentioned above.There are a number of segment-based systems that takea classification approach to recognition \[1, 2, 3\].
Withthe exception of \[2\], however, these do not include an ex-plicit computation of the segmentation probability.
Our1 If si is defined as the start and end times of the segment,clearly consecutive si are not independent.
To avoid this problem,we think of si as corresponding to the length of the segment.approach differs from \[2\] in the types of models used andin the method of obtaining the segmentation score.
In\[2\], the classification and segmentation probabilities areestimated with separate multi-layer perceptrons.2.2.
C lass i f i ca t ion  ComponentThe formulation described above is quite general, allow-ing the use of a number of different classification and seg-mentation components.
The particular classifier used inthe experiments described below is based on the Stochas-tic Segment Model (SSM) \[4\], an approach that uses seg-mental measurements in a statistical framework.
Thismodel represents he probability of a phoneme based onthe joint statistics of an entire segment of speech.
Severalvariants of the SSM have been developed since its intro-duction \[5, 6\], and recent work has shown this model tobe comparable in performance to hidden-Markov modelsystems for the task of word recognition \[7\].
The use ofthe SSM for classification i  the CIR formalism is de-scribed next.Using the formalism of \[4\], p(X(8i)\[8i, ai) is character-ized as p(f(X(si))\[si,ai), where f(.)
is a linear timewarping transformation that maps variable length X(sl)to a fixed length sequence of vectors Y = f(X(si)) .
Thespecific model for Y is multi-variate Gaussian, gener-ally subject o some assumptions about the covariancestructure to reduce the number of free parameters inthe model.
The posterior probability used in the clas-sification work here is obtained from this distributionaccording top(f(X(si))  I hi, si) p(ai, si)p(ai I f(X(si)) ,  si) = Ea,  p(f(X(si))  I hi, si) p(ai, si)"There are more efficient methods for direct computationof the posterior distribution p(ai \[ f(X(si)), si), such aswith tree-based classifiers or neural networks.
However,the above formulation, which uses class-conditional den-sities of the observations, p(f(X(si)) \[ai,si), has theadvantage that we can directly compare the CIR ap-proach to the traditional approach and therefore betterunderstand the issues associated with using fixed-lengthmeasurements and the effect of the segmentation score.In addition, this approach allows us to take advantageof recent improvements to the SSM, such as the dynam-ical system model \[6\], at a potentially lower cost due tosubsampling of observations.2.3.
Segmentat ion  ComponentThere are several possibilities for estimating the segmen-tation probability, and two fundamentally different ap-proaches are explored here.
First we note that we can198estimate ither p(S I x )  or p(S, X) for the segmentationprobability, leading to the two equivalent expressions in0).One method is to simply compute a mixture distributionof segment probabilities to find p(sl, X(si)):p(s,,X(s0) =J= ~p(X(s , ) l s , , c Jp (s , , c J  (3)Jwhere {cj } is a set of classes, such as linguistic classes orcontext-independent phones.
In order to find the scorefor the complete sequence of observations, the terms inthe summation in (3) are instances of the more tradi-tional formulation of (2).
This method uses the completeobservation sequence, as in \[4\], to determine the segmen-tation probabilities, as opposed to the features used forclassification, which may be substantially reduced fromthe original observations and may lack some cues to seg-ment boundaries, uch as transitional acoustic events.Another method for computing the segmentation prob-ability, similar to that presented in \[2\], is to find theposterior probability p(S \[ X).
In this approach, we usedistributions that model presence versus absence of asegment boundary at each frame, based on local features.The segmentation probability is written asp(S IX) = Hp(s ,  \[ X(s,)) (4)iand the probability of an individual segment of length LisL -1p(s, Ix(s0) = p(bn IX(s,)) r I  p(Tix(s,)), (5)j=lwhere bL is the event hat there is a boundary after frameL and bj is the event that there is not a boundary afterthe jth frame of the segment.
We estimate the frameboundary probabilities asLKp(bj I X(si)) - 1 + LKwhere K = p(b)/p('b) andxj+  1%)"The component conditional probabilities are computedasp(xj, xj+, IT) = ~p(x / ,  aj+l\[~) p(~) (6)andp(zj, Zj+l I b~) = E E p(zj I/~l)p(zj+l \[tim) P(fll, f12),(7)where fl ranges over the manner-of-articulation phonemeclasses: stops, nasals, fricatives, liquids, vowels, and ad-ditionally, silence.The two segmentation models presented have differentadvantages.
The first method makes use of the completeset of SSM phone models in determining likely bound-aries for each segment and hence may have a more com-plete model of the speech process.
On the other hand,the second approach uses models explicitly trained to dif-ferentiate between boundary and non-boundary acousticevents.
The best choice of segmentation score is an em-pirical question that we have begun to address in thiswork .3.
EXPERIMENTSExperiments have been conducted to determine the feasi-bility of the recognition approach described here.
First,we wished to determine whether fixed-length measure-ments could be as effective in recognition as using thecomplete observation sequence, as is normally done inother SSM work and in HMMs.
This test would tellwhether the segmentation score can compensate for theuse of fixed-length measurements.
Second, we investi-gated the comparative performance of the two segmen-tation scoring mechanisms outlined in the previous ec-tion.3.1.
C IR  Feas ib i l i tyThe feasibility of fixed-length measurements was in-vestigated first in a phoneme classification framework.Since we planned to eventually test our algorithms inword recognition on the Resource Management (RM)database, our phone classification experiments were alsorun on this database.
Since the RM database is not pho-netically labeled, we used an automatic labeling schemeto determine the reference phoneme sequence and seg-mentation for each sentence in the database.
The la-beler, a context-dependent SSM, took the correct ortho-graphic transcription, a pronunciation dictionary, andthe speech for a sentence and used a dynamic program-ming algorithm to find the best phonetic alignment.
Theprocedure used an initial labeling produced by the BBNBYBLOS system \[8\] as a guide, but allowed some varia-tion in pronunciations, according to the dictionary, aswell as in segmentation.
The resulting alignment isflawed in comparison with carefully hand transcribedspeech, as in the TIMIT database.
However, our ex-perience has shown that using comparable models and199analysis, there is only about a 4-6% loss in classificationperformance ( .g., from 72% to 68% correct for context-independent models) between the two databases, and theRM labeling is adequate for making preliminary compar-isons of classification algorithms.
The final test of anyclassification algorithm is made under the CIR formal-ism in word recognition experiments, for which the RMdatabase is well suited.In classification, the observation vectors in each segmentwere linearly sampled to obtain a fixed number of vec-tors per segment, m = 5 frames.
For observed segmentsof length less than five frames, the transformation re-peated some vectors more than once.
The feature vectorfor each frame consisted of 14 Mel-warped cepstral co-efficients and their first differences as well as differencedenergy.
Each of the rn distributions of each segmentwere modeled as independent full covariance Gaussiandistributions.
Separate models were trained for malesand females by iteratively segmenting and estimating themodels using the algorithm described in \[4\].
The testingmaterial came from the standard "Feb89" and "Oct89"test sets.
In classification experiments using the Feb89test set, the percent correct is reported over the completeset of phoneme instances, 11752 for our transcription.Several simplifying assumptions were made to facilitateimplementation.
Only context-independent models wereestimated, and the labels and segments of the observa-tion sequence were considered independent.On the Feb89 test set the classification results were65.8% correct when the entire observation sequence wasused and 66.4% correct when a fixed number of obser-vations was used for each segment.
This result indicatesthat, in classification, using fixed length measurementscan work as well as using the entire observation.Having verified that fixed-length features are useful inclassification, the next step was to evaluate their use inrecognition with the CIR formalism.
In recognition, wemake use of the N-best formalism.
Although originallydeveloped as an interface between the speech and natu-ral language components of a spoken language system \[9\],this mechanism can also be used to rescore hypotheseswith a variety of knowledge sources \[10\].
Each knowl-edge source produces its own score for every hypothesis,and the decision as to the most likely hypothesis i de-termined according to a weighted combination of scoresfrom all knowledge sources.
The algorithm reduces thesearch of more computationally expensive models, likethe SSM, by eliminating very unlikely sentences in thefirst pass, performed with a less expensive model, suchas the HMM.
In this work, the BBN BYBLOS system\[8\] is used to generate 20 hypotheses per sentence.Using the N-best formalism, an experiment was runcomparing the CIR recognizer to an SSM recognizer thatuses all observations.
The classifier for the CIR systemwas the same as that used in the previous experiment.The joint probability of segmentation a d observations,p(X, S), was computed as in Equation (3), using a ver-sion of the SSM that considered the complete observa-tion sequence for a segment.
That is, not just m, but allobservation vectors in a segment were mapped to the dis-tributions and used in finding the score.
The weights forcombining scores in the N-best formalism were trainedon the Feb89 test set.
In this case the scores to be com-bined were simply the SSM score, the number of wordsand the number of phonemes in a sentence.In evaluating performance using the N-best formalism,the percent word error is computed from the highest-ranked of the rescored hypotheses.
On the Feb89 test setthe word error for both the classification-in-recognitionmethod and the original recognition approach was 9.1%.To determine if these results were biased due to train-ing the weights for combining scores on the same testdata, this experiment was repeated on the Oct89 testset using the weights developed on the Feb89 test set.The performance for the CIR recognizer was 9.4% worderror (252 errors in a set of 2684 reference words) andthe performance for the original approach using the com-plete observation sequence was 9.1% word error (244 er-rors).
The performance of the new recognition formal-ism is thus very close to that of the original scheme, andin fact the difference between them could be attributedto differences associated with suboptimal N-best weightestimation techniques \[11\].3.2.
Segmentat ion  ScoreAs mentioned previously, some current systems use aclassification scheme with no explicit probability of seg-mentation.
We attempted to simulate this effect withthe classification recognizer by simply suppressing thescore for the joint probability of segmentation a d ob-servations.
This is equivalent to assuming that the seg-mentation probabilities are equally likely for all hypothe-ses considered.
Scores were computed for the utterancewith and without the p(X, S) term on the Feb89 testset.
When just the classification scores were used, worderror went from from 9.1% to 10.8%, an 18% degrada-tion in performance.
Apparently, the joint probability ofsegmentation a d observations has a significant effect innormalizing the posterior probability for better ecogni-tion.Experiments were also run to compare the two meth-ods of segmentation scoring described above.
In the firstmethod, based on equation (3), the same analysis de-200scribed earlier was used at each frame (cepstra plus dif-ferenced cepstra and differenced energy) and the sum-mation was over the set of context independent phones.In the second method, which computes p(S IX) usingequations (4)-  (7), we modeled each of the conditionaldensities in (6) and (7) as the joint, full covariance, Gaus-sian distribution of the cepstral parameters of the twoframes adjoining the hypothesized boundary.
In orderto reduce the number of free parameters to estimate inthe Gaussian model, we used only the cepstral coeffi-cients as features for each frame.
On the Feb89 testset the first method had 9.1% combined word error formale and female speakers, while the second method had11.0% word error.
Using the best weights for the N-bestcombination from this test set, the segmentation algo-rithms were also run on the Oct89 test set.
In this case,the word error rates for the two methods were 9.4% and11.9%, respectively.This result suggests that the boundary-based segmenta-tion score yields performance that is worse than no seg-mentation score.
However, the "no segmentation" caseactually uses an implicit segmentation score in that theN hypotheses are assumed to have equally likely seg-mentations (while all other segmentations have proba-bility zero) and in that phoneme and word counts areused in the combined score.
Although we suspect hatthe marginal distribution model for segmentation scoresmay still be preferable, clearly more experiments areneeded with a larger number of sentence hypotheses tobetter understand the characteristics of the different ap-proaches.4.
D ISCUSSIONIn summary, we have described an alternative approachto speech recognition that combines classification andsegmentation scoring to more effectively use segmentalfeatures.
Our pilot experiments demonstrate hat theclassification-in-recognition approach can achieve per-formance comparable to the traditional formalism whenframe-based features and equivalent Gaussian distribu-tions are used, and that the segmentation score can be animportant component of a classification approach.
Weanticipate performance gains with the additional use ofsegmental features in the classification component of theCIP~ model.
We also plan to extend the model to incor-porate context-dependent u its.Our initial experiments with the segmentation probabil-ity indicate that finding this component via marginalprobabilities computed with a detailed model may bemore accurate than estimating boundary likelihoodbased on local observations, although this conclusionshould be verified with experiments u ing a larger num-ber of hypotheses per sentence than the 20 used so far.A number of improvements can be mode to both mod-els, including using different choices for mixture com-ponents and eliminating some of the independence as-sumptions.
Additionally, in the second method we planto increase both the number of features per frame andthe number of boundary-odjacent frames considered incomputing the boundary probabilities.
Eventually a hy-brid method that combines elements of both approachesmay prove to be the most effective.References1.
S. Austin, J. Makhoul, R. Schwartz and G. Zavaliagkos,"Continuous Speech Recognition using Segmental Neu-ral Nets," Proceedings of the DARPA Workshop onSpeech and Natural Language, pp.
249-252, Feb. 1991.2.
H. C. Leung, I. L. Hetherington and V. Zue, "SpeechRecognition Using Stochastic Explicit-Segment Model-ing," Second European Conference on Speech Communi-cation and Technology, Genova, Italy, September, 1991.3.
P. Ramesh, S. Katagiri and C. H. Lee, "A NewConnected Word Recognition Algorithm based onHMM/LVQ Segmentation a d LVQ Classification," Pro-ceedings IEEE Int.
Conf.
Acoust., Speech, Signal Pro-cessing, pp.
113-116, Toronto, May 1991.4.
M. Ostendoff and S. Roukos, "A Stochastic SegmentModel for Phoneme-Based Continuous Speech Recogni-tion," IEEE Trans.
on Acoust., Speech and Signal Pro-cessing, Dec. 1989, pp.
1857-1869.5.
S. Roukos, M. Ostendorf, H. Gish and A. Derr, "Stochas-tic Segment Modeling Using the Estimate-Maximize Al-gorithm," Proceedings IEEE Int.
Conf.
Acoust., Speech,Signal Processing, pp 127-130, New York, New York,April 1988.6.
V. Digalakis, J. R. Rohlicek, M. Ostendorf, "A Dynam-ical System Approach to Continuous Speech Recogni-tion," Proceedings IEEE Int.
Conf.
Acoust., Speech, Sig-nal Processing, pp.
289-292, Toronto, May 1991.7.
O. Kimball, M. Ostendorf and I. Bechwati, "ContextModeling with the Stochastic Segment Model," to ap-pear in IEEE Trans.
Signal Processing.8.
F. Kubala, S. Austin, C. Barry, J. Makhoul, P. Placeway,R.
Schwartz, "BYBLOS Speech Recognition Bench-mark Results," Proceedings of the DARPA Workshop onSpeech and Natural Language, pp.
77-82, February 1991.9.
R. Schwartz and Y.-L. Chow, "The N-Best Algorithm:An Efficient and Exact Procedure for Finding the NMost Likely Sentence Hypotheses," Proceedings IEEEInt.
Conf.
Acoust., Speech, Signal Processing, pp.
1857-1869, April 1990.10.
M. Ostendorf, A. Kannan, S. Austin, O. Kimball,R.
Schwartz, J. R. Rohlicek, "Integration of DiverseRecognition Methodologies Through Reevaluation of N-Best Sentence Hypotheses," Proceedings of the DARPAWorkshop on Speech and Natural Language, pp.
83-87,Asilomar, CA, Feb. 1991.11.
A. Kannan, M. Ostendorf, J. R. Rohlicek, "Weight Es-timation for N-Best Rescoring," this proceedings.201
