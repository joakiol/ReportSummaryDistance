SEMANTIC  EVALUATION FORSPOKEN-LANGUAGE SYSTEMSRobert C. MooreArtificial Intelligence CenterSRI InternationalMenlo Park, California 94025ABSTRACTDevelopment has begun on a semantic evaluation (Se-mEval) methodology and infrastructure for the ARPA Spo-ken Language Program.
SemEval is an attempt o define atask-independent technology-based evaluation for language-understanding systems consisting of three parts: word-senseidentification, predicate-argument structure determination,and identification of coreference r lations.
An initial spoken-language SemEval on ATIS data is planned for Novem-ber/December 1994, concurrent with the next ATIS CAS(database answer) evaluation.1.
INTRODUCTIONSince the summer of 1993, there has been considerable discus-sion in the ARPA HLT community of moving the evaluationof understanding systems for both spoken and written lan-guage away from application-based metrics (such as correctdatabase response in ATIS, or template fills in MUG) towaxdtechnology-based metrics.
The benefits hoped to be derivedfrom such a shift include greater focus on underlying tech-nology issues, rather than application issues, and loweringthe overhead required to participate in evaluations in termsof developing application systems.
The discussions have fo-cused on the concept of a semantic evaluation, or "SemEval"consisting of three components: word-sense identification,predicate-argument structure determination, and coreferencedetermination.
This paper reports on how these ideas arebeing developed within the ARPA spoken-language commu-nity, in preparation for an initial spoken-language S mEvalon ATIS data concurrent with the ATIS GAS (database an-swer) evaluation planned for November/December 1994.A meeting was held at SRI, 21-23 October 1993, to beginfleshing out these ideas for the evaluation of spoken-languageunderstanding systems.
The meeting was attended by re-searchers, annotators, and evaluators involved in both theARPA Spoken Language Program and the ARPA WrittenLanguage Program: Fernando Pereira from AT&T Bell Labo-ratories; Rusty Bobrow and Dave Stallaxd from BBN; WayneWard and Sergei Nirenburg from CMU; Stephanie Seneff andEric Brill from MIT; Robert Moore, Kate Hunicke-Smith,Jerry Hobbs, Harry Bratt, and Mark Gawron from SRI; Deb-hie Dald and Lew Norton from Unisys; Mitch Marcus andGrace Kim from the University of Pennsylvania; Nancy Chin-chor from SAIG; George Doddingtou from ARPA; GeorgeMiller from Princeton University; Dave Pallett and BruceLurid from NIST; and Ralph Grishman from NYU.
This pa-per is derived from the discussions at the October meetingand from subsequent proposals made and discussed by theparticipants.2.
WHY DO SEMEVAL?A question that has received, and continues to receive, exten-sive discussion is ~'Why do we want to do SemEval at allT"George Doddington \[1\] has addressed this from ARPA's per-spective as follows:Why is SemEval a good idea?
Well, first,ARPA's goal in the HLT Program is to make strate-gic advances in core human language technology.This goal is a technology goal (to produce usefulfunctionality).
It is not a science goal (to producescientific understanding), nor is it an applicationgoal (to produce useful applications embodying hu-man language technology).
So, why do SemEvalinstead of only doing task-level evaluations (suchas ATIS CAS)?
There are three reasons:1.
SemEval offers the possibility of providing amuch more direct and objective valuation ofunderlying technical issues.
It thus promisesgreater diagnostic leverage which would yieldmore rapid and efficient development of core.technology.2.
SemEval, by measuring performance at atechnical evel rather than an applicationlevel, eliminates much overhead and researchinefficiency by obviating the need to supportapplication effort and other back-end issues.This makes research much more efficient byfocusing a greater fraction of effort on re-search and technical issues of direct interest.It also makes it more attractive and much eas-ier for a new player to enter the game.3.
Semgval, by virtue of measuring performancebelow the application level, offers the oppor-tunity to compare performance across differ-ent applications and to support formal evalu-ation among a much larger research commu-nity.
Thus the potential benefit and evalu-ation support goes far beyond the relativelyfew ARPA HLT sites.The risk is that SemEval may end up measuringtechnical aspects of systems that axe not directlyrelevant or do not represent the important issuesin HLT.
We need to try hard to avoid this.
And we126won't immediately abandon other task-level evalu-ations such as the ATIS GAS.
But a successful Se-mEval has the potential to create a larger researchchallenge and to accelerate HLT  progress very sig-nificantly.
The potential payoff is high and we needto give SemEval the best shot we can.3.
METHODOLOGICAL PRINCIPLESPerhaps the main difficulty in defining SemEval is that thereis no single generally accepted notation for representing themeaning of natural-language utterances.
Instead, there arenumerous notations and theories, from which we have to syn-thesize a notation that is compatible with as wide a varietyof points of view as possible.
Two methodological principleshave been proposed to guide us in this task.The first is proposed as a strategy for helping us define anno-tations without bogging down in theoretical disputes: Takeas our mantra =It's just a notation, not a theory."
That is,the overriding consideration should be whether a proposednotation is a convenient way of marking a distinction thatwe agree we should mark, and that whether it meets other,theory-driven conditions (e.g., supporting a truth-conditionalsemantics, assigning a type-theoretic interpretation to everysubexpression, being compositional, assigning one predicateper morpheme) is beside the point.The second methodological principle is a default rule for de-ciding when to make distinctions.
There are many caseswhere it is not immediately clear whether to mark a dis-tinction or not.
The proposed efault is not to mark distinc-tions.
That is, it should take some positive argument hat ifthe distinction is not marked, two utterances that we agreeshould be assigned ifferent structures will be assigned thesame structure.
(Often, the most compelling such argumentsare truth-conditional.
That is, we can describe a situationwhere one utterance is clearly true and the other is dearlyfalse.
)The reason for defaulting to not making distinctions is thatsystems that make more distinctions than necessary shouldbe able to collapse them for purposes of translation to thecanonical representation fairly easily, but a system thatdoesn't make a distinction at all will be severely penalizedif it is scored incorrect for not making it.
Hence, we needevidence that the system is wrong not to make the distinc-tion.
Note that marking distinctions does not mean that thenotation will represent a superficial analysis of the utterance.Quite the contrary, it will often require giving a common rep-resentation to many expressions that are quite different syn-tactically and, hence, push toward deeper epresentations.4.
PREDICATE-ARGUMENTSTRUCTURE ISSUESSo far, most of the detailed proposals that have been dis-cussed pertain to predicate-argument structure issues.4.1.
Syntax for Predicate-ArgumentStructureIn discussions of a possible syntax for predicate-argumentstructure, it has been evident hat there are considerable vari-ations in preferences for the amount of syntactic sugar to beused.
To accommodate hese differences in preferences, threeintertranslatable levels of notation have been proposed.
Thefirst is simply LISP-style nested functor-argument otation,with two notational additions.
First, we use angle brackets<...> to indicate implicit conjunction, arising, for example,from iterated modifiers in the utterance.
Second, we use nu-merical indices followed by a colon to label expressions thatmay fill more than one argument position in the predicate-argument structure.
For example, if we make the assumptionthat ta l l ,  b lock,  and blue,  are one-place predicates and weignore tense, Every blue block is tall might be represented:(dea l  ( ta l l  l : (every  <(block 1) (b lue 1)>)))(The recursion implicit in the use of the index 1 will be ex-plained in the discussion of quantification below.
)A second level of representation is obtained by assigning ev-ery expression an index, and breaking the structure downinto a list of atomic predications, interrelated by the indices:2 : (dec l  3)3 : ( ta l l  1)1 : (every  <4 5>)4 : (b lock  1)5 : (b lue  1)Finally, we may wish to break this notation down to an evenmore atomic level for the purpose of counting errors for scor-ing:Cfunct 2 decl)(argl 2 3)(funct 3 ta l l )(a rg l  3 1)Cfunct I every)(argl I 4)(argl 1 5)Cfunct 4 block)(argl 4 1)(~unct 5 blue)(argl 5 1)4.2.
Scope of Quantified Noun PhrasesThere has been general agreement hat quantified nounphrases hould be represented "in place," without their ex-act scope being represented.
To be more precise, for a gen-eralized quantifier Q(X, Y) corresponding to a noun phrasedeterminer like some or every, since the restriction X is essen-tially the content of the noun phrase, that would be indicatedin the notation, but the body Y, not being structurally de-terrnined by the syntax, would be left vague.
This means wewill give different representations to127Every tall block is blue.Every blue block is talland the complements are distinguished by the position theyfill in the argument list:since t:he difference between these is structurally determinedand unambiguous, but we will not give different representa-tions to the two scopings ofSome girl likes every boy.that is,(P X Y Z)In the other approach, a "Davidsonian" \[2\] notation is used,in which an "event" described by the head is introduced, andthe complements axe treated as fillers of role relations forthe event.
In the notation we have adopted, this comes outlooking something likeTJ~ere is some girl such that she likes every boy.. .
.
.
.
.
.
.
.
For every boy, there is some girl who likes him.since that distinction is not structurally determined (al-though structure has some influence), and it is often difficultto judge.An additional constraint that has been agreed on is that thenotation should not have what has come to be called the"linchpin problem"; that is, the notation should not be suchthat, if one key piece is missed, the whole thing falls apart andcredit is given for virtually nothing.
In paxticular, it shouldbe possible to miss which pieces belong inside or outside therestriction of the quantifier, and still get credit for recognizingall the predications of the "quantified variable.
~The solution that has been developed is illustrated by thepredicate-argument structure given above for the phrase ev-ery blue block:l:(every <(block l)(blue I)>)The expression as a whole is given an index that is also used.in the argument positions inside the restriction of the quanti-fier that correspond to "quantified variable" positions?
Thatway, the notation can clearly indicate which predications axepart of the quantifier estriction, but every argument positionthat would be filled by the quantified variable in a standardlogical representation is filled with the same index, whetherthe predication is inside or outside of the quantifier estric-tion.Quantified noun phrases are not the only constructs wherethe issue of scope arises.
Others include modal verbs, nega-tion, and propositional attitude verbs (e.g., want, know).
Ithas generally been agreed that items whose scope is largelydetermined by linguistic structure would have their scope in-dicated in predicate-axgument structure (usually by treatingthem as having propositions as arguments), and that itemswhose scope is not determined by linguistic structure (suchas only), would have their structure left underspecified inpredicate-axgument structure.4.3.
What are the Predicates andArguments?There are two widely used schemes for mapping linguisticheads (e.g., main verbs) and complements (e.g., subjectsand objects) into predicate-argument structures.
In one ap-proach, the head is treated as a multi-argument predicate<(ev-type 1 P) (R1 1 X) (R2 1 ?)
(R3 1Z)>We have chosen the Davidsonian-style notation, because ofits flexibility in leaving open exactly what complements (andadjuncts) a head has.After the decision to use a Davidsonian representation, thequestion came up of how widely to apply it.
Davidson's orig-inal proposal was intended to apply only to verbs (in particu-lar, only to action verbs), but examples arise with adjectives,adverbs, nouns, and even prepositions that seem to requirea similar treatment.
We have tentatively decided, therefore,to apply it to all of these types of expr6ssions, but to pro-vide syntactic sugar to hide some of the complexity in simplecases .4.4.
Collapsing Lexical and SyntacticDistinctionsIt has been tentatively agreed that a number of syntacticdistinctions hould be collapsed in predicate-argument struc-ture:Active vs. passive: Mary kissed John, vs. John waskissed by Mary.Dative movement: John gave Mary a book, vs. Johngave a book to Mary.Raising verbs: It seems that John is here, vs. Johnseems to be here.It has also been agreed that verbs and their event nominal-izations should be given the same underlying predicates, forexample, arrive and arrival.It also appears that there are cases where multiple subcat-egorization patterns for the same verb can be handled bya single underlying predicate with different roles expressed.For example, in John baked Mary a cake, and John baked acake, bake would be taken to express the same predicate, butwith who the cake was for expressed by a role relation in onlythe first case.
Other examples falling under this heading in-clude "control" verbs, where if a certain role is not expressed,it is constrained to be filled by the same item as one of theother roles--for example, John expected Mary to win vs. Johnexpected to win (= John expected himself to win).Another category of verbs that first seemed to fall into thisclass axe those for which both transitive and intransitiveforms exist and it appears that the object of the transitiveform may fill the same role as the subject of the intransitive128form--for example, John melted the butter, vs.
The buttermelted.
On closer examination, however, it seems there maybe good reasons for treating these as distinct predicates, othis issue remains open.ticket's priceprice of a ticketprice for a ticketprice on a ticket4.5.
Complex PredicatesSo far we have represented all predicates as atomic, but wemight in some cases want to have predicates that are them-selves tructurally complex.
One case is complex determinerphrases.
We have treated determiners like some and everyas a sort of predicate, but sometimes determiners are com-plex phrases like no more than seven.
A second potentialexample of complex predicates are families of rdated prepo-sitions, like at, before, and alter.
It has been suggested thatthese might be profitably treated as utilizing a single under-lying predicate, whose interpretation varies from domain todomain, together with a set of numerical comparison opera-tions defined in terms of that predicate but fixed across alldomains.5.
WORD SENSE AND ROLEIDENTIFICATION ISSUESMuch of the discussion of word-sense identification issues hasrevolved around whether WordNet \[3\] would be a suitablelexical resource to use as a source for word senses.
The gen-eral impression seems to be that it probably is, but the detailsremain to be worked out.The choice of the Davidsonian representation for head-complement relations raises an important issue closely relatedto that of word-sense identification--namely, identificationof the role-relations that hold between the events and thecomplements (R1, R2, and so forth in the discussion above).One possibility is to use fairly superficial identifiers (such asabbreviations for "logical subject" and "logical object") orsurface prepositions for role names, to keep the annotationsdomain-independent.
An objection to this is that it is toosyntactically oriented and does not represent a deep enoughlevel of understanding.The approach currently being explored is to attempt to definea set of semantic classes relevant to the domain and constructrole names from those classes.
If there is only one relationbetween a pair of classes alient enough to be expressed by agrammatical role or preposition, then a simple concatenationof the class names would be used.
For example, for '% flighton an airline", there is really only one salient relation be-tween flights and airlines, so f l ight_a i r l ine  might as wellbe used to name that relation.
If there is more than onesalient relation between two semantic lasses, a grammati-cal relation ame or preposition can be interpolated betweenthe semantic lass names.
So, since f l ight .a i rpor t  wouldbe ambiguous between origin and destination, we would havef l ight_from_airport  and f l ight_to_ai rport  instead.Since theory-laden terms are not used to name the roles, thisapproach should avoid arguments such as whether a particu-lar role is really an agent or is merely an experiencer.
It alsooffers the possibility of expressing deeper regularities thangrammatical roles or surface prepositions, ince it allows usto say thatall involve the same relation between a ticket and a price.A number of key issues raised by this approach remain to beresolved, including the following:1.2.Roles may be expressed (at least) by grammatical rela-tions, prepositions, possessives, and the verb have.
Onequestion is whether we ever want to treat any of theseconstructions as having an autonomous sense, ratherthan expressing a role of some predicate.
For exam-ple, one might want to say that in a book on a table, onsimply expresses a relation between the book and thetable that depends only on an autonomous sense of onindependent of the predicate book, while in a price on aticket, on expresses the role of the predicate price thatis filled by a ticket.Under this proposal, it is necessary to know what thesemantic lass of the head of a phrase is in order to knowwhat to call the roles that are expressed.
Some phraseshave null heads or contentless heads that pose a problemfor this approach--for example,Show me the ones on United.In this case, we need to know what the ones refers to inorder to know what relation on expresses.
Conversely,conjunction can create situations where a phrase pro-vides a role filler for two different heads:Show me the flights and \]ares to Boston.In a case like this, the notation eeds to allow to Bostonto supply a role filler for both flights and \]ares.6.
COREFERENCEDETERMINAT ION ISSUESWe take the term "coreference" very broadly to include avariety of types of constraints from context.
Most of thecases that have been considered so far can be classified intothree categories:1.
Strict coreference, where one expression denotes exactlythe same entity as some other expression:Show the flights from Boston to Dallas andthe times they arrive.they = the flights from Boston to Dallas2.
Relational coreference, where one expression denotessomething bearing a specific relation to an entity de-noted by some other expression:Show flights from Boston to Dallas and dis-count fares.discount fares = discount fares \]or flightsfrom Boston to Dallas3.
General constraints from context:129I need to go from Boston to Dallas.
Show meall the morning flights.the morning flights = the morning flightsIrom Boston to DallasThe current proposal for annotating these relations is touse a combination of co-indexing and expressing contextualconstraints by constructing additional pieces of predicate-argument structure (which might or might not be copies ofpieces of predicate-argument structure in the context).
Thefeasibility of specifying these additional pieces of predicate-argument structure in a sufficiently constrained way to yielda canonical representation is currently being assessed.7.
ANNOTATION AND TEST  ISSUESthey proceed.
One suggestion is an iterative process, wherebya subset of the data would be annotated using a partial lexi-con, with the annotators having the option of choosing "noneof the above" for a word sense or role relation.
A concordancewould be produced for the =none of the above" occurrences ofeach lexical item and role marker, and new word senses androles would be added to the lexicon based on an analysis ofthe concordance.
It has also been suggested that a thresholdbe set in terms of frequency of occurrence, and until someword sense or role relation exceeded the threshold, it couldbe left in the none-of-the-above bucket, and that none-of-the-above would be deemed the correct answer if that word senseor role relation turned up in test data.
(None-of-the-abovewould also be deemed the correct answer if a completely newword sense or role relation turned up in test data.
)We assume that SLS SemEval will work as much as possiblelike the ATIS GAS evaluations in terms of how we organizethe collection and annotation of data and administration ofthe evaluation.
In the general case, the expected process is:8.
ANNOTATION AND TESTSOFTWAREA number of pieces of software will be needed to support heoverall process:1.
At multiple sites, data will be collected, transcribed, andshipped to NIST.2.
NIST will partit ion data into training and test and shipdata to third-party annotators.3.
Annotators will perform classification and annotateword-sense, predicate-argument structure, and corder-ence, and ship annotations back to NIST.4.
NIST will distribute training data with classificationsand annotations to system developers.5.
A committee will resolve issues about how to classifyand annotate data and' to maintain documentation onthe same.6.
A mechanism will be established for reporting trainingdata bugs to NIST, having the bugs corrected, and dis-tributing the fixes.7.
NIST will release test data shortly before the evalua-tion, and participants will submit annotations producedby their systems to NIST for comparison with referenceannotations.8.
An adjudication process will be set up to resolve disputesabout the transcription, classification, and annotation oftest data.Note that for the initial SLS SemEval the first two steps havealready been completed, because we will use some of the samedata for training and test that has already been collected forATIS CAS.Obtaining consistent annotation of the data is an importantrequirement.
It is clear that a detailed annotation manualand good annotation tools need to be developed and thattight feedback between the annotators and an analog of theATIS CAS Principles of Interpretation committee will be re-quired.1.
Annotator aids - -  Annotators cannot be expected tocreate complex annotations for utterances completelyby hand.
For ATIS CAS, NLParse was used, but for Se-mEval, NLParse is not suitable.
One possibility wouldbe to use one or more participants' ystems to produce afirst-pass annotation, which the annotators would thencorrect.
There is some concern that this would pro-duce annotations that are biased in favor of the systemused to produce the initial structures.
This might bepartly alleviated by using multiple systems to producea first pass, perhaps presenting to the annotators onlythe parts of the annotation that multiple systems agreeon.
The annotators will also need specialized editingtools tailored to creating and correcting SemEval struc-tures.
Such tools have been created by the Penn Tree-bank project \[4\] for producing syntactic bracketings ofutterances, and it may be possible to adapt these forSemEval.2.
Annotation checker - -  The annotations themselves willhave a quite complex syntax and semantics.
Softwareto check the resulting annotations will no doubt catchmany annotation errors.
It might be possible to buildthis functionality directly into the editing tools.3.
Annotation translators - - We have defined several levelsof notation for SemEval.
The highest, most syntacticallysugared level seems likely to be used by the annotators,and the lowest level seems likely to be that to which thecomparator is applied.
However many levels are used,software to translate between them will be needed.4.
Comparator - -  It will be necessary to build a compara-tot for hypotheses and reference answers.
This needs tobe implemented in a way that permits all sites to useit, which would probably make C the implementationlanguage of choice.Another important question is whether a detailed lexiconwith patterns il lustrating word senses and roles for the major-ity of the vocabulary will need to be constructed before anno-tation, or whether this can be developed by the annotators as9.
CONCLUSIONSSemEval holds out the promise of shifting the focus oflanguage-understanding evaluation from specific application130tasks to genetic technology.
It is hoped that this will lowerthe overhead of participation in evaluations and focus the ef-forts of participating sites on key technological issues, therebyaccelerating the rate of progress in the field.
A substantialstart has been made on defining SemEvM for spoken-languageunderstanding, but much work remains to be done.
Over thenext few months we expect to see these efforts converge on aworkable plan for a spoken-language S mEval in late 1994.AcknowledgmentsI wish to thank everyone who has participated in the dis-cussions of SLS SemEval, particularly those who attendedthe SLS SemEvai meeting at SRI in October 1993.
Specialthanks are due to Debbie Dahl whose very extensive andexcellent notes of that meeting provided an invaluable re-source in the preparation of this paper, which was supportedby the Advanced Research Projects Agency under ContractN00014-93-C-0142 with the Office of Naval Research.References1.
G. Doddington, edited transcript of comments made atspoken-language S mEval Meeting at SRI International,Menlo Park, California (21-23 October 1993).2.
D: Davidson, "The Logical Form of Action Sentences,"in Essays on Actions and Events, pp.
105-148 (Claren-don Press, Oxford, England, 1980).3.
G. A. Miller (ed.
), "WordNet: An On-Line LexicalDatabase," International Journal of Lexicography (spe-cial issue), Vol.
3, No.
4, pp.
235-312 (1990).4.
M. P. Marcus, B. Santotini, and M. A. Marcinkiewicz,"Building a Large Annotated Corpus of English: ThePenn Treebank," Computational Linguistics, Vol.
19,No.
2, pp.
313-330 (June 1993).131
