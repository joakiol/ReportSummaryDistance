Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1639?1649,Austin, Texas, November 1-5, 2016. c?2016 Association for Computational LinguisticsEvent-Driven Emotion Cause Extraction with Corpus ConstructionLin Gui1, Dongyin Wu1, Ruifeng Xu1,2?, Qin Lu3 and Yu Zhou11.
School of Computer Science and Technology, Harbin Institute of Technology,Shenzhen Graduate School, Shenzhen, China2.
Guangdong Provincial Engineering Technology Research Center for Data Science3.
Department of Computing, the Hong Kong Polytechnic University, Hong Kongguilin.nlp@gmail.com;wudongyinhit@gmail.com;xuruifeng@hitsz.edu.cn;csluqin@comp.polyu.edu.hk;zhouyu.nlp@gmail.comAbstractIn this paper, we present our work in emo-tion cause extraction.
Since there is no opendataset available, the lack of annotated re-sources has limited the research in this area.Thus, we first present a dataset we built usingSINA city news.
The annotation is based onthe scheme of the W3C Emotion Markup Lan-guage.
Second, we propose a 7-tuple defini-tion to describe emotion cause events.
Basedon this general definition, we propose a newevent-driven emotion cause extraction methodusing multi-kernel SVMs where a syntacticaltree based approach is used to represent eventsin text.
A convolution kernel based multi-kernel SVM are used to extract emotion caus-es.
Because traditional convolution kernels donot use lexical information at the terminal n-odes of syntactic trees, we modify the kernelfunction with a synonym based improvemen-t.
Even with very limited training data, wecan still extract sufficient features for the task.Evaluations show that our approach achieves11.6% higher F-measure compared to refer-enced methods.
The contributions of our workinclude resource construction, concept defini-tion and algorithm development.1 IntroductionWith the rapid growth of Internet, people can easilyshare experiences and emotions through this power-ful medium anywhere and anytime.
How to analyzethe emotions of individuals through their writingsbecomes a new challenge for NLP.
In recent years, s-?corresponding authortudies in emotion analysis focus on emotion classifi-cation including detection of emotions expressed bywriters of text (Gao et al, 2013) as well as predic-tion of reader emotions (Chang et al, 2015).
Thereare also some information extraction tasks in emo-tion analysis, such as extracting the feeler of emo-tion (Das and Bandyopadhyay, 2010).
However,these methods need to observe emotion linked ex-pressions.
Sometimes, however, we care more aboutthe stimuli, or the cause of an emotion.
For instance,manufacturers want to know why people love, orhate a certain product.
The White House may al-so prefer to know the cause of the emotional text?Let us hit the streets?
rather than the distribution ofdifferent emotions.There are three main challenges in the study of e-motion cause extraction.
The first is that, up to now,there is no open dataset available for emotion causeextraction.
This may explain why there are only fewstudies on emotion causes.
The second is that, thereis no formal definition about event in emotion causeextraction even though some researches claim thatthey extract events of emotion causes (Lee et al,2010; Chen et al, 2010).
The third is that, due tothe complexity in annotation, the size of corpus foremotion cause extraction is usually very small.
Dueto this limitation, many machine learning method-s are not suited for emotion cause detection.
Howto mine deep knowledge of a language for emotioncauses is another thorny issue.In this paper, we first present an annotated datasetfor emotion cause extraction to be released to thepublic.
We then propose to use a 7-tuple to defineemotion cause events.
Based on this general defi-1639nition, we then present a new event-driven emotioncause extraction method.
The basic idea is to ex-tract events in the context of emotional text throughdependency parsing.
Then, a syntactic structure isused to represent nearby events.
Based on this struc-tured representation of events, a modified convolu-tion kernel which also takes lexical features(as ter-minal nodes) is used to determine whether an eventis emotion cause relevant.
This method can detectall possible combinations of syntactic structures toobtain sufficient features for emotion analysis us-ing a limited training set.
Compared to existingmethods, which either use manual rules or com-monsense knowledge to extend information, our ap-proach is completely machine learning based and itstill achieves state-of-the-art performance.
The con-tributions of this work include both resource devel-opment and algorithm development.The rest of the paper is organized as follows.
Sec-tion 2 provides a review of related works on emotionanalysis.
Section 3 presents emotion cause relat-ed definitions and the construction of emotion causeextraction corpus.
Section 4 gives the event-drivenemotion cause extraction method and section 5 isthe evaluations and discussions.
Section 6 concludesthis work and gives the future directions.2 Related WorksIdentifying emotion categories in text is an essen-tial subject in NLP and its applications (Liu, 2015).Moreover, emotion causes can provide important in-formation on why there is any emotion changes.
Inthis section, we introduce related works on the emo-tion analysis and emotion cause extraction.The first issue in emotion analysis is to determinethe taxonomy of emotions.
Researchers have pro-posed a list of primary emotions(Plutchik, 1980; Ek-man, 1984; Turner, 2000).
In this study, we adop-t Ekman?s emotion classification (Ekman, 1984),which identifies six primary emotions, namely hap-piness, sadness, fear, anger, disgust and surprise,known as the ?Big6?1 scheme in the W3C EmotionMarkup Language.
This list is agreed upon by mostprevious works in Chinese emotion analysis.The second issue is how to do emotion clas-sification and emotion information extraction.1http://www.w3.org/TR/emotion-voc/xml#big6Beck (Beck et al, 2014) proposed a Multi-taskGaussian-process based method for emotion clas-sification.
Xu (Xu et al, 2012) used a coarse tofine method to classify emotions in Chinese blog.Gao (Gao et al, 2013) proposed a joint model to co-train a polarity classifier and an emotion classifier.Chang (Chang et al, 2015) used linguistic templateto predict reader?s emotions.
Das (Das and Bandy-opadhyay, 2010) used an unsupervised method toextract emotion feelers from Bengali blog.
Thereare other studies focused on joint learning with sen-timent (Luo et al, 2015; Mohtarami et al, 2013),emotion in tweets or blog (Hasegawa et al, 2013;Qadir and Riloff, 2014; Ou et al, 2014; Liu et al,2013; Quan and Ren, 2009), and emotional lexiconconstruction (Yang et al, 2014; Staiano and Gueri-ni, 2014; Mohammad and Turney, 2013).
However,these related works all focused on analysis of emo-tion expressions rather than emotion causes..Sophia M. Y. Lee first proposed a task on emotioncause extraction (Lee et al, 2010).
They manual-ly constructed a corpus from Academia Sinica Bal-anced Chinese Corpus.
Based on this corpus, Chenand Lee (Chen et al, 2010) proposed a rule basedmethod to detect emotion causes.
The basic idea isto make linguistic rules for cause extraction.
Somestudies (Gui et al, 2014; Li and Xu, 2014; Gao et al,2015) extended the rule based method to in-formaltext in Weibo text (Chinese tweets).Other than rule based methods, Ghazi (Ghaz-i et al, 2015) used CRFs to extract emotion caus-es.
However, it requires emotion cause and emo-tion keywords to be in the same sentence.
I. Rus-so (Russo et al, 2011) proposed a crowd-sourcingmethod to obtain emotion cause related common-sense knowledge.
But it is challenging to extend thecommonsense knowledgebase automatically.Resources used in the above works are not pub-licly accessible.
Most of the methods used are rulebased.
Learning based methods are quite limited be-cause annotated data is quite small in size due tohigh cost for annotation.
Thus, rule based meth-ods seem to be the easiest way to achieve acceptableperformance.
Since machine learning methods re-quire more knowledge, which is difficult to general-ize.
So automatic methods only focused on simpletext genre.16403 Construction of Emotion Cause CorpusIn this section, we first describe the linguistic phe-nomenon in emotion expressions.
It serves as the in-spiration to develop the annotated dataset.
We thenintroduce details of the annotation scheme, followedby the construction of the dataset.3.1 Linguistic Phenomenon of Emotion CausesEmotion causes play an important role in emotionexpressions.
An emotion cause reveals the stimulusof an emotion.
Considering linguistic phenomenonof emotion causes, we follow three basic principlesin corpus construction: (1) Keep the whole contextof emotion expression; (2) The basic processing unitis at the clause level; and (3) Use of formal text.In written text, there is an emotion keyword,which is used to express an emotion, in the contextof the emotion cause.
Thus, finding the appropri-ate context of emotion keywords in the annotationis the pre-requisite to identify its cause.
It is thereason why we keep the whole context of emotionkeywords.Another important kind of cues is the presence ofconjunctions and prepositions.
These words indi-cate the discourse information between clauses.
Inorder to make use of discourse information, the ba-sic analysis unit should be at clause level rather thanat sentence level.In the third principle, we choose the formal tex-t in corpus construction.
According to the relatedworks, emotion expressions can have overlapping e-motion cause and emotion target (Gui et al, 2014)in informal text.
This is why some studies even in-corporate cause extraction with target identificationto improve performance.
However, our focus is onemotion cause identification.
We use formal newstext to avoid the potential mix up.3.2 Collection and AnnotationWe first take 3 years (2013-15) Chinese city newsfrom NEWS SINA2 containing 20,000 articles as theraw corpus.
Based on a list of 10,259 Chinese pri-mary emotion keywords (keywords for short) (Xuet al, 2008), we extract 15,687 instances by key-word matching from the raw data.
Here, we call thepresence of an emotion keyword as an instance in2http://news.sina.com.cn/society/the corpus.
For each matched keyword, we extractthree preceding clauses and three following clausesas the context of an instance.
If a sentence has morethan 3 clauses in each direction, the context will in-clude the rest of the sentence to make the contextcomplete.
For simplicity, we omit cross paragraphcontext.Note that the presence of keywords does not nec-essarily convey emotional information due to differ-ent possible reasons such as negative polarity andsense ambiguity.
For example, ???/wishes?
isan emotion word of ?happiness?.
It can also bethe name of a song.
Also, the presence of emotionkeywords does not necessarily guarantee the exis-tence of emotional cause neither.
After removingthose irrelevant instances, there are 2,105 instancesremain.
For each emotional instance, two annotatorsmanually annotate the emotion categories and thecause(es) in the W3C Emotion Markup Language(EML) format.
Ex1 shows an example of an anno-tated emotional sentence in the corpus, presented bythe original simplified Chinese, followed by its En-glish translation.
To save space, we remove the xmltags in the annotation.
The original annotated datais in a subsidiary file3.
The basic analysis unit is aclause.
Emotion cause is marked by <cause>, andthe emotion keyword is marked by<keywords>.
E-motion type, POS, position and the length of anno-tation are also annotated in Emotionml format.Ex.1: ????55??1979???????19????36??????????????????????????????????????????????????
?<cause POS=?v?Dis=?-1?>?
?
?
?
?
?
?</cause>?
?
?
?
?<keywords type=happiness>??</keywords>?Mr.
Zhu is 55 years old.
He started workingin 1979 as a barber when he was 19 , and has 36years of experience.
?I was assigned to work at theBarbershop in Danyang, Nanjing.
It is the largestbarbershop in Danyang.
I won many awards andhonors there.?
<cause POS=?v?
Dis=?-1?>Talkingabout his honors</cause>, Mr. Zhu is so <keywordstype=?happiness?> proud </keywords>.Ex.1 only contains one cause.
However, one key-word may have more than one corresponding emo-tion causes.
In Ex.2, there are two relevant causes3http://hlt.hitsz.edu.cn/?page id=6941641Item NumberInstance 2,105Clauses 11,799Emotion Cause 2,167Document with 1 emotion 2,046Document with 2 emotion 56Document with 3 emotion 3Table 1: Details of the Datasetfor one keyword.
In our dataset, only 59 instanceshave two or more causes.Ex.2: ???????????????????
?<cause POS=?v?
Dis=?-2?>??????
?</cause>?<cause POS=?v?
Dis=?-1?>??????
?</cause>?<keywords type=sadness>??</keywords>???????
?During persuasion, firemen realized that the womanattempted suicide because of <cause POS=?v?
Dis=?-2?>the hold back of wages by the employer</cause>,and <cause POS=?v?
Dis=?-1?>her family askedfor money urgently</cause>, she feels <keywordstype=sadness>helpless</keywords> and thus3.3 Details of Dataset and Its AnnotationsEach instance in our dataset contains only one emo-tion keyword and at least one emotion cause.
It isensured that the keyword instance and the causes arerelevant.
The number of extracted instances, claus-es, and emotion causes are listed in Table 1.
Notethat 97.2% of the instances has only one emotioncause, and instances that have two and three emo-tion causes hold 2.6% and 0.2% respectively.
Table2 shows the distribution of emotion types and Ta-ble 3 shows the distribution of cause positions.
Inthe latter we can see that 78% emotion causes ad-join the emotion keywords at the clause level.
Ap-parently, position plays a very important role in e-motion cause extraction.
Thus, using distance basedfeatures for emotion cause extraction is rational andnecessary.
Table 4 lists the phrase types of emotioncauses.
Verbs and verb phrases cover 93% of al-l cause events.
Thus, our learning algorithm mainlyfocus on them.Two annotators work independently during theannotation process.
The key point is to distinguishclause level and phrase level in cause annotation.The clause level labels the clause which containsthe emotion cause.
The phrase level determines theboundary of an emotion cause.
When two annota-Emotion Number PercentageHappiness 544 25.83%Sadness 567 26.94%Fear 379 18.00%Anger 302 14.35%Disgust 225 10.69%Surprise 88 4.18%Table 2: Distribution of Emotion TypesPosition Number PercentagePrevious 3 clauses 37 1.71%Previous 2 clauses 167 7.71%Previous 1 clauses 1,180 54.45%In the same clauses 511 23.58%Next 1 clauses 162 7.47%Next 2 clauses 48 2.22%Next 3 clauses 11 0.51%Other 42 1.94%Table 3: Cause Position of Each Emotiontors have different opinion on one instance at clauselevel, we involve a third annotator as the arbitrator.In the phrase level, we use the larger boundary ofthe two annotations when they have the same anno-tation at the clause level.
We reach 0.9287 for thekappa value on clause level annotation which con-firmed the reliability of our annotation.4 Event-Driven Emotion Cause ExtractionDue to the complexity of annotation in emotioncause identification, the size of annotated corpus isusually small.
Since we aim to use machine learningmethods to automatically learn and identify caus-es, we use a convolution kernel to detect all pos-sible combinations in the syntactic structure.
Thisallows learning from syntactic representations for e-motion cause extraction.
The basic idea of our pro-posed method is to use a tree-structure representa-tion to capture features for emotion cause identifica-tion.
For training data, we extract all valid tree struc-tures for each event, referred to as the ETs (Even-t Trees).
If an event is a cause, the correspondingET is positive.
Otherwise, the corresponding ET isnegative.
Then, we train a convolution kerneland aPOS/phrase type Number PercentageNoun/Noun phrase 147 6.78%Verb/Verb phrase 2020 93.21%Table 4: Distribution of the POS Tag1642multi-kernel SVMs using the training set to classi-fy candidate ETs in the testing set.
Since more than97% emotion keywords only have one cause, andmore than 95% causes are near the emotion key-words, candidate ETs are extracted from the contextof emotion keywords.
We only choose the ET withthe highest probability in the classification result asthe emotion cause.4.1 Event Tree ConstructionEven though there are related works on event identi-fication in emotion cause detection, there is no for-mal definition of events In area of artificial intelli-gence (AI), researchers, such as Radinsky (Radinskyet al, 2012), gave a formal definition of an even-t as ?action, actor, object, instrument, location andtime?.
In our work, we need to give clear definitionof event first.In emotion cause extraction, the components ofan event should be simpler.
We are only interestedin the action, the actor and the object, which are de-noted as P , O1, O2, respectively, following the con-ventions in AI.
Since Chinese is a SVO language,the actor is the subject and the action is the verb.The subject and the object of a sentence may haveattributes and a predicate may have adverbial andcomplement.
Since these components may also behelpful in emotion cause extraction, we formally de-fine an emotion cause event as a 7-tuple:e = (AttO1 , O1, Adv, P, Cpl, AttO2 , O2).Here, AttO1 is the attribute of O1?AttO2 is theattribute of O2?Adv is the adverbial of the predi-cate P?and Cpl is P ?s complement.
In case syn-tactic components are not present, NIL values areused.
Note that the main cue in an event is P , the ac-tion.
So, in our algorithm, we extract all verbs fromthe text, and use dependency parsing4 to extract allrelevant syntactic components specified in e. Then,we can construct an ET.An ET has has a fixed height of four levels.
Thetop level is the root node.
Since Chinese is a SVOlanguage, the descendant of the root is S(subject),V(verb), and O(object).
Then, the seven even-t components can be categorized and filled up inthe relevant slots.
(AttO1 ,O1) belongs to S(O1),(Adv,P ,Cpl) belong to V , and (AttO2 ,O2) belongs4https://github.com/HIT-SCIR/ltpFigure 1: Example ETs of Emotion Causes.toO.
Then we can get the ET based on the definitionof an event.Let us review Ex.1 and Ex.2 again.
There arethree emotion cause events below with their corre-sponding ETs shown in Figure 1.1.???????
?/Talking about his honors?2.???????
?/ the hold back wages by employ-ers?3.???????
?/ her family asked for money ur-gently?After the construction of the ETs, emotion causeextraction becomes a classification problem.
If anET is an emotion cause, the label should be positive.Otherwise, the label should be negative.
A binaryclassifier should be used.4.2 Emotion Cause ExtractionAfter the construction of ETs, we obtain positive andnegative ET samples.
Due to small amount of train-ing samples, it is necessary to capture all features inthe ETs.
We choose convolution kernel based SVMsbecause it can search all possible syntactic featuresunder a tree structure.Convolution kernel function1643The convolution kernel, also known as the tree k-ernel (Collins and Duffy, 2002), is widely used inmany NLP tasks (Srivastava et al, 2013; Moschitti,2006).
For any two inputs T1 and T2 based on a treestructure , the kernel is defined as:K(T1, T2) =?n1?T1?n2?T2?
(n1, n2).
(1)Here, n1 and n2 are tree nodes.
?
is a functiondefined recursively:1.?
(n1, n2) = 0 if the productions of n1 and n2 aredifferent; 2.Else, ?
(n1, n2) = 1 if n1 and n2 arematching in pre-terminals; 3.Otherwise,?
(n1, n2) =?i(1 + ?
(c(n1, i), c(n2, i))).Here, c(n, i) is the i-th node of n.However, the above tree kernel definition doesnot consider terminals, which means that the actualwords in a sentence are ignored.
As emotions causesare semantically meaningful, we need to incorporatelexical information into the convolution kernel.Modified kernel functionIn order to distinguish different ETs, we need tomodify the definition of the tree kernel to includelexical words in a clause.
So we add one more defi-nition to include the terminals:4.If n1 and n2 are terminal nodes, ?
(n1, n2) = 1if and only if n1 and n2 are synonyms.
Otherwise?
(n1, n2) = 0.Here a synonym is defined in Tongyici Cilin (Ex-tended).5 which has 17,817 synonyms and 77,343words.
We use the synonym rather than word match-ing because the size of the corpus is limited.
simpleword matching is quite sparse.Let KET?O denote the original kernel andKET?M denote the modified kernel, respectively.It can be easily proven that KET?M is a valid ker-nel function.
Following the notation in (Collins andDuffy, 2002), KET?O = ?ihi(T1) ?
hi(T2), wherehi(T1) =?n1?N1Ii(n1), hi(T2) = ?n2?N2Ii(n2) andthe function Ii(n) is 1 if the sub-tree i is rootedat node n and 0 otherwise.
So the original tree k-ernel is an inner product and the kernel matrix is5http://ir.hit.edu.cn/demo/ltp/Sharing Plan.htmsemi-definite.
In our modified kernel, the func-tion Ii(n) is more complicated.
Beside the defi-nition above, it has the following additional defi-nition : Ii(n) is 1 if i is a terminal node and itis a synonym of n. The new indicator is markedas I ?i(n).
Then we have: KET?M (T1, T2) =?n1?T1?n2?T2?iI ?i(n1)I ?i(n2).
This means that themodified kernel is symmetrical and the kernel matrixis semi-definite.
In our work, KET?M uses SVMoptimization and the code is from SVM-light-TK6.Multi-kernel functionSince there are only syntactic information andsynonyms in the convolution kernel based method,we need to add some lexical features.
Given a 7-tuple event e, we obtain the bag-of-words based orword embedding based representation for each com-ponent in e, and the distance between a componentand emotion keywords are used as the features, re-spectively.
Let the features of each component in ebe Ri, for every i ?
e. Then, we can capture thefeature set, F , of an ET by a joint operation, calledthe ET features:F = {RAttO1 ?RO1 ?
...?RAttO2}.
(2)We can join the ET features with syntactic informa-tion by a multi-kernel function.
For any two ETs T1and T2, with the respective features F1 and F2, thetwo new multi-kernels can be defined as:Knew+O(T1, T2) = KET?O(T1, T2) +Kvec(F1, F2), (3)Knew?O(T1, T2) = KET?O(T1, T2)?Kvec(F1, F2), (4)Knew+M (T1, T2) = KET?M (T1, T2) +Kvec(F1, F2), (5)Knew?M (T1, T2) = KET?M (T1, T2)?Kvec(F1, F2).
(6)Here, Kvec denotes a kernel function which canbe a linear kernel, a polynomial kernel or a Gaussiankernel.
The next step is to train the classifier basedon the multi-kernel function.The training data is already in labeled ET format.To prepare testing data, we extract all ETs from agiven instance as candidate ETs.
A classifier is usedto obtain the probability of emotion cause for eachET to produce a ranked list of candidate ETs.
TheET with the highest rank serves as the cause eventfor the current instance.6http://disi.unitn.it/moschitti/Tree-Kernel.htm16445 Performance Evaluations5.1 Experimental SetupIn the experiments, we stochastically select 90% ofthe dataset as training data and 10% as testing da-ta.
In order to obtain statistically credible results,we evaluate our methods and the reference methods25 times.
We conduct two sets of experiments.
Thefirst one evaluates the performance at the clause lev-el to identify the clauses that contain emotion caus-es.
The second one evaluates emotion causes usingverb classification.
This is because 93.21% of emo-tion causes are verb/verb phrase and verbs serve asthe action component in event definition.5.2 Emotion Cause ExtractionWe use the commonly accepted measure proposedby Lee (Lee et al, 2010) for emotion cause extrac-tion (Gao et al, 2015; Li and Xu, 2014).
In thismeasure, if a roposed emotion cause covers the an-notated answer, the sequence is considered correct.Te precision, recall, and F-measure are defined byPrecision =?correct cause1?proposed cause1 ,Recall =?correct cause1?annotated cause1 ,F ?measure = 2?
Precision?RecallPrecision+Recall .In the experiment, evaluation is conducted for thefollowing works:1.RB(Rule based method): Among several rulebased methods (Lee et al, 2010; Gui et al, 2014;Li and Xu, 2014).
We use lee2010?s rules (listed inAppendix of this paper).2.CB(Commonsense based method): In order to re-produce this method (Russo et al, 2011), we usethe Chinese Emotion Cognition Lexicon (Xu et al,2013) as the commonsense.
The lexicon containsmore than 5,000 emotion stimulations and their cor-responding reflection words.3.ML(Rule base features for machine learning):Rules are used as features with other manual fea-tures for emotion cause classification (Chen et al,2010).4.
Kvec : Features are defined in Formula (2) in thetraining of classifier.Method Precision Recall F-measureRB 0.6747 0.4287 0.5243CB 0.2672 0.7130 0.3887RB+CB 0.5435 0.5307 0.5370RB+CB+ML 0.5921 0.5307 0.5597Kvec 0.4200 0.4375 0.4285Kword2vec 0.4301 0.4233 0.4136KET?O 0.3982 0.4134 0.4057KET?M 0.4583 0.4745 0.4662Knew+O 0.6446 0.6779 0.6608Knew?O 0.6492 0.6701 0.6595Knew+M 0.6588 0.6927 0.6752Knew?M 0.6673 0.6841 0.6756Table 5: Performance on the Dataset5.Kword2vec: Word2vec (Mikolov et al, 2013) isused to learn word representation.
Use the repre-sentation according to Formula (2) in the training ofclassifier.6.KET?O : This is the original tree kernel.7.KET?M : This is the modified tree kernel in For-mula (1).8.Knew+O, Knew?O, Knew+M and Knew?M : Usethe multi-kernel gives by formulas from (3) to (6).The performance result is given in Table 5.
A-mong all methods, Knew?M achieves the top perfor-mance in F-measure.
Compared to other methods,the improvement is significant with p-value less than0.01 in t-test.Even though RB achieves the top precision, its F-measure is limited by the low recall.
Since CB isopposite to RB, the performance by RB+CB is im-proved.
However, the improvement is quite limited,at 0.0127 in F-measure.
The F-measure of our re-produced RB is similar to mentioned result of otherreferences (Gui et al, 2014; Li and Xu, 2014).
Theyrepeat Lee?s (Lee et al, 2010) method and achievethe F-measure with 0.55 more or less.
(Chen et al, 2010) reported that by using hand-crafted rules as features to train a classifier withsome additional features such as conjunction, actionand epistemic verbs, performance can be improvedsignificantly.
In our experiment, the result is oppo-site to this claim.
The main reason is the samplesin (Chen et al, 2010) are less complex.
About 85%of the emotion causes are in the same clause wherethe emotion keywords are.
Our corpus is quite dif-ferent.
The percentage of causes in the same clausewhere the emotion keyword itself is has only about164523.6%.
(Chen et al, 2010)?s method does not han-dle long distance relations well.
This explains whyit does not work well for our dataset.
Although(RB+CB+ML) does not perform well, there is still0.0334 improvement in F-measure compare to RB.Among our proposed methods, Kvec on the ET fea-ture achieves 0.4285 in F-measure.
Compare to CBand ML, the performance is not satisfactory.
How-ever, as a simple feature to represent lexical informa-tion, the performance is acceptable.
word2vec alsoyield similar result.
Maybe the joint operation is toosimple to handle composition.For the modified tree kernel KET?M , the perfor-mance is 0.0605 higher than the original tree ker-nel KET?O in F-measure.
It means that the consid-eration of terminal node improves the performanceof the tree kernel significantly.
The modified treekernel KET?M is also 0.0377 higher than Kvec,and 0.0526 higher than Kword2vec in F-measure.This means kernel based syntactic representationdoes have better generalization ability.
The origi-nal kernel function KET?O has syntactic informa-tion but no lexicon, and it not only underperformscompared to KET?M but also Kvec and Kword2vec.This demonstrates our modified kernel function caneffectively turn an inferior method into a superiorone.
Compared to rule based method, the perfor-mance still needs to be enhanced and a multi-kernelis necessary.
After the combination with ET featureusing a multi-kernel, the performance of Knew?Machieves a higher level with 0.6756 in F-measure.Compare to RB, the improvement in F-measure is0.1513.
Compare to the combination of existingmethods, the improvement is 0.1159.
The reasonis that our method represents events at the syntacticlevel.
Synonym information gives the model moregeneralization ability.5.3 Verb Classification for Emotion CauseIn this section, we examine the performance of ETsclassification with respect to verbs identified in theemotion clauses.ETs ClassificationOur method is based on ETs classification tochoose the candidate ET with the highest probabili-ty.
The performance is measured by the verbs in theidentified ET.
Results are shown in Table 6.Note that Kword2vec performs much better thanMethod Precision Recall F-measureKvec 0.3500 0.2951 0.3192Kword2vec 0.3200 0.4833 0.3848KET?O 0.3906 0.2773 0.3228KET?M 0.3978 0.3303 0.3473Knew+O 0.4211 0.7219 0.5319Knew?O 0.4197 0.7305 0.5331Knew+M 0.4407 0.7694 0.5651Knew?M 0.4532 0.7504 0.5646Table 6: Performance on ETs ClassificationKvec in verb identification, contrary to their simi-lar performance in clause identification.
The rea-son is that extraction result is based on ranking andonly top ranked event affects the performance.
Inother words, precision is more important than re-call here.
For the same reason, Knew+M is betterthan Knew?M in classification of ETs, although on-ly marginally.
Nonetheless, using revised convolu-tion kernel with multi-kernel training is still signifi-cantly better than the original kernelKnew?M whichachieves the best performance in Table 5.
When theprecision of the two methods are similar, such asKET?O and KET?M , the effect of recall becomesimportant.The multi-kernel not only achieves the best per-formance on both precision and recall, the increasein performance is also significant with at least0.2173 (between KET?M and Knew?M ).
Obvious-ly, multi-kernel is not just a simple voting or jointfor the components, it benefits from two kernels toachieve better performance.5.4 Error AnalysisThere are mainly three types of errors in our model.We use case examples to show them.a) Cascading EventsIn some cases, events may happen like a chain re-action.
An event that leads to an emotion may be theconsequent of another event.
Identifying the rightevent in a chain is more challenging.
In the follow-ing example:Ex.3: ?????????????<cause>?????</cause>?????????<keywords>??</keywords>??????????????????????
?John Watson fell into icy water.
<cause>Thechilly water</cause> made him feel so cold and<keywords>scared</keywords> John Watson had to1646use his broken Chinese to call for help.the emotion cause should be ?????
?/thechilly water?.
Our method output ???????
?/fell into icy water?
as the emotion cause withprobability 60.83%.
The probability of the correc-t cause is 58.89%.
As a probability based method,our method does not have the ability to analyze thesequence of events nor the relation between them.b) Sensory verbsSensory verbs usually indicate the emotion cause.There are exceptional cases as shown below:Ex.4: ???????????????????????????<keywords>??</keywords>???<cause>???????
?</cause>After investigation on bullying, the head says thatthe students realized their mistake and were also<keywords>scared</keywords>.
They <cause> mayneed to do community service</cause>In this case, the cause of ?scared?
is the punish-ment of community service.
But the template of ?????
?/realized ... and felt?
usually indicate thatthere is an emotion cause between the two senso-ry verbs.
Our algorithm gives ????
?/ realizedtheir mistake?
a probability of 61.65% as a cause, al-though this is incorrect.
But, this actually indicatesthat our method can learn latent patterns in text.c) Coverage of cause candidatesIn the construction of ETs, we use actions as thecue to construct candidate events.
However, 6.78%of our clauses do not have action words.
So, theseclauses are not selected as candidates.6 ConclusionIn this paper, we present our work on emotion causeextraction.
Due to the lack of open resources for thisarea of study, we first construct an annotated datasetfrom news text which will be released for public use.We also propose an event-driven emotion cause ex-traction method to capture the triggering events e-motion changes.
In this method, we propose a 7-tuple representation of events using syntactic struc-tures to identify events.
Based on this structured rep-resentation of events and the inclusion of lexical fea-tures, a convolution kernel based learning method isdesigned to train a multi-kernel classifier to identifyemotion cause events.
Compared to manually con-structed rules and commonsense knowledge basedmethods, our proposed model can automatically ob-tain structure features and lexical features to achievestate-of-the-art performance on this dataset.AcknowledgmentThis work was supported by the National Natural Sci-ence Foundation of China 61370165, 61632011, National863 Program of China 2015AA015405, Shenzhen Pea-cock Plan Research Grant KQCX20140521144507925and Shenzhen Foundational Research Funding J-CYJ20150625142543470, Guangdong Provincial Engi-neering Technology Research Center for Data Science2016KF09.
The project is also partially supported by HKGRF grant PolyU 152111/14E.AppendixNo.
Rules1i) C(B/F) + I(F) + E(F) + K(F)ii) E = the nearest Na/Nb/Nc/Nh after I in Fiii) C = the nearest (N)+(V)+(N) before I in F/B2i) E(B/F) + II/IV/V/VI(B/F) + C(B/F) + K(F)ii) E=the nearest Na/Nb/Nc/Nh before II/IV/V/VI in B/Fiii) C = the nearest (N)+(V)+(N) before K in F3i) II/IV/V/VI (B) + C(B) + E(F) + K(F)ii) E = the nearest Na/Nb/Nc/Nh before K in Fiii) C = the nearest (N)+(V)+(N) after II/IV/V/VI in B4i) E(B/F) + K(F) + IV/VII(F) + C(F/A)ii) E = a: the nearest Na/Nb/Nc/Nh before K in F; b: the first Na/Nb/Nc/Nh in Biii) C = the nearest (N)+(V)+(N) after IV/VII in F/A5i) E(F)+K(F)+VI(A)+C(A)ii) E = the nearest Na/Nb/Nc/Nh before K in Fiii) C = the nearest (N)+(V)+(N) after VI in A6i) I(F) + E(F) + K(F) + C(F/A)ii) E = the nearest Na/Nb/Nc/Nh after I in Fiii) C = the nearest (N)+(V)+(N) after K in F or A7i) E(B/F) + yue4 C yue4 K ?the more C the more K?
(F)ii) E = the nearest Na/Nb/Nc/Nh before the first yue4 in B/Fiii) C = the V in between the two yue4?s in F8i) E(F) + K(F) + C(F)ii) E = the nearest Na/Nb/Nc/Nh before K in Fiii) C = the nearest (N)+(V)+(N) after K in F9i) E(F) + IV(F) + K(F)ii) E = the nearest Na/Nb/Nc/Nh before IV in Fiii) C = IV+(an aspectual marker) in F10i) K(F) + E(F) + de ?possession?
(F) + C(F)ii) E = the nearest Na/Nb/Nc/Nh after K in Fiii) C = the nearest (N)+V+(N)+??
?+N after de in F11i) C(F) + K(F) + E(F)ii) E = the nearest Na/Nb/Nc/Nh after K in Fiii) C = the nearest (N)+(V)+(N) before K in F12i) E(B) + K(B) + III (B) + C(F)ii) E = the nearest Na/Nb/Nc/Nh before K in Fiii) C = the nearest (N)+(V)+(N) after III in F13i) III(B) + C(B) + E(F) + K(F)ii) E = the nearest Na/Nb/Nc/Nh before K in Fiii) C = the nearest (N)+(V)+(N) after III in B14i) C(B) + E(F) + K(F)ii) E = the nearest Na/Nb/Nc/Nh before K in Fiii) C = the nearest (N)+(V)+(N) before K in B15i) E(B) +C(B) + K(F)ii) E = the first Na/Nb/Nc/Nh in Biii) C = the nearest (N)+(V)+(N) before K in BTable 7: Linguistic Rules in RBHere, C = Cause event; E = Experiencer; K = Key-word/emotion verb; B = Clause before the focus clause;F = Focus clause/the clause containing the emotion ver-b; A = Clause after the focus clause; I to VII are cuewords in (Lee et al, 2010); Na/Nb/Nc/Nh is commonnoun/proper noun/place noun/pronoun.1647ReferencesDaniel Beck, Trevor Cohn, and Lucia Specia.
2014.
Jointemotion analysis via multi-task gaussian processes.
InEMNLP, pages 1798?1803.Yung-Chun Chang, Cen-Chieh Chen, Yu-Lun Hsieh, andWL Hsu.
2015.
Linguistic template extraction forrecognizing reader-emotion and emotional resonancewriting assistance.
ACL-IJCNLP, pages 775?780.Ying Chen, Sophia Yat Mei Lee, Shoushan Li, and Chu-Ren Huang.
2010.
Emotion cause detection with lin-guistic constructions.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistic-s, pages 179?187.
Association for Computational Lin-guistics.Michael Collins and Nigel Duffy.
2002.
New rank-ing algorithms for parsing and tagging: Kernels overdiscrete structures, and the voted perceptron.
In Pro-ceedings of the 40th annual meeting on association forcomputational linguistics, pages 263?270.
Associationfor Computational Linguistics.Dipankar Das and Sivaji Bandyopadhyay.
2010.
Findingemotion holder from bengali blog texts?an unsuper-vised syntactic approach.
In PACLIC, pages 621?628.Paul Ekman.
1984.
Expression and the nature of emo-tion.
Approaches to emotion, 3:19?344.Wei Gao, Shoushan Li, Sophia Yat Mei Lee, GuodongZhou, and Chu-Ren Huang.
2013.
Joint learning onsentiment and emotion classification.
In Proceedingsof the 22nd ACM international conference on Confer-ence on information & knowledge management, pages1505?1508.
ACM.Kai Gao, Hua Xu, and Jiushuo Wang.
2015.
A rule-based approach to emotion cause detection for chi-nese micro-blogs.
Expert Systems with Applications,42(9):4517?4528.Diman Ghazi, Diana Inkpen, and Stan Szpakowicz.2015.
Detecting emotion stimuli in emotion-bearingsentences.
In Computational Linguistics and Intelli-gent Text Processing, pages 152?165.
Springer.Lin Gui, Li Yuan, Ruifeng Xu, Bin Liu, Qin Lu, andYu Zhou.
2014.
Emotion cause detection with lin-guistic construction in chinese weibo text.
In NaturalLanguage Processing and Chinese Computing, pages457?464.
Springer.Takayuki Hasegawa, Nobuhiro Kaji, Naoki Yoshinaga,and Masashi Toyoda.
2013.
Predicting and elicitingaddressee?s emotion in online dialogue.
In ACL (1),pages 964?972.Sophia Yat Mei Lee, Ying Chen, and Chu-Ren Huang.2010.
A text-driven rule-based system for emo-tion cause detection.
In Proceedings of the NAACLHLT 2010 Workshop on Computational Approaches toAnalysis and Generation of Emotion in Text, pages 45?53.
Association for Computational Linguistics.Weiyuan Li and Hua Xu.
2014.
Text-based emotion clas-sification using emotion cause extraction.
Expert Sys-tems with Applications, 41(4):1742?1749.Huanhuan Liu, Shoushan Li, Guodong Zhou, Chu-RenHuang, and Peifeng Li.
2013.
Joint modeling of newsreader?s and comment writer?s emotions.
In ACL (2),pages 511?515.Bing Liu.
2015.
Sentiment analysis: Mining opinion-s, sentiments, and emotions.
Cambridge UniversityPress.Kun-Hu Luo, Zhi-Hong Deng, Liang-Chen Wei, andHongliang Yu.
2015.
Jeam: A novel model forcross-domain sentiment classification based on emo-tion analysis.
In EMNLP, pages 2503?2508.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean.
2013.
Distributed representa-tions of words and phrases and their compositionality.In Advances in neural information processing systems,pages 3111?3119.Saif M Mohammad and Peter D Turney.
2013.
Crowd-sourcing a word?emotion association lexicon.
Com-putational Intelligence, 29(3):436?465.Mitra Mohtarami, Man Lan, and Chew Lim Tan.
2013.Probabilistic sense sentiment similarity through hid-den emotions.
In ACL (1), pages 983?992.Alessandro Moschitti.
2006.
Efficient convolution k-ernels for dependency and constituent syntactic trees.In Machine Learning: ECML 2006, pages 318?329.Springer.Gaoyan Ou, Wei Chen, Tengjiao Wang, Zhongyu Wei,Binyang Li, Dongqing Yang, and Kam-Fai Wong.2014.
Exploiting community emotion for microblogevent detection.
In EMNLP, pages 1159?1168.Robert Plutchik.
1980.
Emotion: A psychoevolutionarysynthesis.Ashequl Qadir and Ellen Riloff.
2014.
Learning emo-tion indicators from tweets: Hashtags, hashtag pattern-s, and phrases.
In EMNLP, pages 1203?1209.Changqin Quan and Fuji Ren.
2009.
Construction of ablog emotion corpus for chinese emotional expressionanalysis.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing:Volume 3-Volume 3, pages 1446?1454.
Association forComputational Linguistics.Kira Radinsky, Sagie Davidovich, and Shaul Markovitch.2012.
Learning to predict from textual data.
Journalof Artificial Intelligence Research, pages 641?684.Irene Russo, Tommaso Caselli, Francesco Rubino, EsterBoldrini, and Patricio Mart??nez-Barco.
2011.
Emo-cause: an easy-adaptable approach to emotion causecontexts.
In Proceedings of the 2nd Workshop on1648Computational Approaches to Subjectivity and Senti-ment Analysis, pages 153?160.
Association for Com-putational Linguistics.Shashank Srivastava, Dirk Hovy, and Eduard H Hovy.2013.
A walk-based semantically enriched tree ker-nel over distributed word representations.
In EMNLP,pages 1411?1416.Jacopo Staiano and Marco Guerini.
2014.
De-pechemood: a lexicon for emotion analysisfrom crowd-annotated news.
arXiv preprint arX-iv:1405.1605.Jonathan H Turner.
2000.
On the origins of human e-motions: A sociological inquiry into the evolution ofhuman affect.
Stanford University Press Stanford, CA.Linhong Xu, Hongfei Lin, Yu Pan, Hui Ren, and JianmeiChen.
2008.
Constructing the affective lexicon ontol-ogy.
Journal of the China Society for Scientific andTechnical Information, 27(2):180?185.Jun Xu, Ruifeng Xu, Qin Lu, and Xiaolong Wang.2012.
Coarse-to-fine sentence-level emotion classifi-cation based on the intra-sentence features and senten-tial context.
In Proceedings of the 21st ACM interna-tional conference on Information and knowledge man-agement, pages 2455?2458.
ACM.Ruifeng Xu, Chengtian Zou, Yanzhen Zheng, Xu Jun, LinGui, Bin Liu, and Xiaolong Wang.
2013.
A new e-motion dictionary based on the distinguish of emotionexpression and emotion cognition.
Journal of ChineseInformation Processing, 27(6):82?90.Min Yang, Dingju Zhu, and Kam-Pui Chow.
2014.
Atopic model for building fine-grained domain-specificemotion lexicon.
In ACL (2), pages 421?426.1649
