Automatic Acquisition of Two-Level Morphological RulesPieter  TheronDept.
of Computer ScienceStellenbosch UniversityStellenbosch 7600, South Africaptheron@cs, un.
ac.
zaIan CloeteDept.
of Computer ScienceStellenbosch UniversityStellenbosch 7600~ South Africaia /~@cs,  sun .
ac .
zaAbstractWe describe and experimentally evaluatea complete method for the automatic ac-quisition of two-level rules for morphologi-cal analyzers/generators.
The input to thesystem is sets of source-target word pairs,where the target is an inflected form of thesource.
There are two phases in the acquisi-tion process: (1) segmentation fthe targetinto morphemes and (2) determination ofthe optimal two-level rule set with minimaldiscerning contexts.
In phase one, a mini-mal acyclic finite state automaton (AFSA)is constructed from string edit sequences ofthe input pairs.
Segmentaiion of the wordsinto morphemes i achieved through view-ing the AFSA as a directed acyclic graph(DAG) and applying heuristics using prop-erties of the DAG as well as the elemen-tary edit operations.
For phase two, thedetermination of the optimal rule set ismade possible with a novel representationof rule contexts, with morpheme bound-aries added, in a new DAG.
We introducethe notion of a delimiter edge.
Delimiteredges are used to select the correct two-level rule type as well as to extract minimaldiscerning rule contexts from the DAG.
Re-sults are presented for English adjectives,Xhosa noun locatives and Afrikaans nounplurals.1 Introduct ionComputational systems based on the two-levelmodel of morphology (Koskenniemi, 1983) have beenremarkably successful for many languages (Sproat,1992).
The language specific information of such asystem is stored as1.
a morphotactic description of the words to beprocessed as well as2.
a set of two-level morphonological (or spelling)rules.Up to now, these two components had to be codedlargely by hand, since no automated method existedto acquire a set of two-level rules for input source-target word pairs.
To hand-code a 100% correctrule set from word pairs becomes almost impossi-ble when a few hundred pairs are involved.
Fur-thermore, there is no guarantee that such a handcoded lexicon does not contain redundant rules orrules with too large contexts.
The usual approachis rather to construct general rules from small sub-sets of the input pairs.
However, these general rulesusually allow overrecognition a d overgeneration - -even on the subsets from which they were inferred.Simons (Simons, 1988) describes methods forstudying morphophonemic alternations (using anno-tated interlinear text) and Grimes (Grimes, 1983)presents a program for discovering affix posi-tions and cooccurrence restrictions.
Koskenniemi(Koskenniemi, 1990) provides a sketch of a discoveryprocedure for phonological two-level rules.
Goldingand Thompson (Golding and Thompson, 1985) andWothke (Wothke, 1986) present systems to automat-icaily calculate a set of word-formation rules.
Theserules are, however, ordered one-level rewrite rulesand not unordered two-level rules, as in our system.Kuusik (Kuusik, 1996) also acquires ordered one-level rewrite rules, for stem sound changes in Esto-nian.
Daelemans et al (Daelemans el al., 1996) usea general symbolic machine learning program to ac-quire a decision tree for matching Dutch nouns totheir correct diminutive suffixes.
The input to theirprocess is the syllable structure of the nouns and agiven set of five suffix allomorphs.
They do not learnrules for possible sound changes.
Our process au-tomatically acquires the necessary two-level soundchanging rules for prefix and suffix allomorphs, aswell as the rules for stem sound changes.
Connec-tionist work on the acquisition of morphology hasbeen more concerned with implementing psycholog-ically motivated models, than with acquisition ofrules for a practical system ((Sproat, 1992, p.216)and (Gasser, 1994)).The contribution of this paper is to present a com-plete method for the automatic acquisition of an op-103timal set of two-level rules (i.e.
the second com-ponent above) for source-target word pairs.
It isassumed that the target word is formed from thesource through the addition of a prefix and/or asuffix 1.
Furthermore, we show how a partial acqui-sition of the morphotactic description (componentone) results as a by-product of the rule-acquisitionprocess.
For example, the morphotactic descriptionof the target word in the input pair\[1\]Source Targethappy happieris computed as\[2\]happier = happy + erThe right-hand side of this morphotactic descriptionis then mapped on the left-hand side,\[z\]happy+erhapp i  0 e rFor this example the two-level rule\[ 4\]y:i ?~ p:p -can be derived.
These processes are described in de-tail in the rest of the paper: Section 2 provides anoverview of the two-level rule formalism, Section 3describes the acquisition of morphotactics throughsegmentation and Section 4 presents the method forcomputing the optimal two-level rules.
Section 5evaluates the experimental results and Section 6summarizes.2 Two- leve l  Ru le  Formal i smTwo-level rules view a word as having a lezical anda surface representation, with a correspondence b -tween them (Antworth, 1990), e.g.
:\[51Lexical: h appy  + e rSurface: h app i  0 e rEach pair of lexical and surface characters i calleda feasible pair.
A feasible pair can be written aslezicabcharac~er:surface-charac~er.
Such a pair iscalled a default pair when the lexicai character andsurface character are identical (e.g.
h:h).
When thelexical and surface character differ, it is called a spe-cial pair (e.g.
y:i).
The null character (0) may ap-pear as either a lexical character (as in +:0) or asurface character, but not as both.1Non-linear operations (such as infixation) are notconsidered here, since the basic two-level model dealswith it in a round-about way.
We can note that exten-sions to the basic two-level model have been proposed tohandle non-linear morphology (Kiraz, 1996).Two-level rules have the following syntax (Sproat,1992, p.145):\[ 6\]CP op LC _ RCce  (correspondence part), LC (le# contezt) and ac(right contez~) are regular expressions over the al-phabet of feasible pairs.
In most, if not all, imple-mentations based on the two-level model, the corre-spondence part consists of a single special pair.
Wealso consider only single pair CPs in this paper.
Theoperator op is one of four types:1.
Exclusion rule: a:b /~  LC  _ RC2.
Context restriction rule: a:b ::~ LC  _ RC3.
Surface coercion rule: a:b ~ LC  _ RC4.
Composite rule: a:b ?V LC  _ RCThe exclusion rule ( /~)  is used to prohibit the ap-plication of another, too general rule, in a particularsubcontext.
Since our method does not overgener-alize, we will consider only the ~,  ~ and ~:~ ruletypes.3 Acqu is i t ion  o f  Morphotact i csThe morphotactics of the input words are acquiredby (1) computing the string edit difference betweeneach source-target pair and (2) merging the edit se-quences as a minimal acyclic finite state automa-ton.
The automaton, viewed as a DAG, is used tosegment he target word into its constituent mor-phemes.3.1 Determin ing  St r ing Edi t  SequencesA string edit sequence is a sequence of elementaryoperations which change a source string into a tar-get string (Sankoff and Kruskal, 1983, Chapter 1).The elementary operations used in this paper aresingle character deletion (DELETE), insertion (IN-SERT) and replacement (REPLACE).
We indicatethe copying of a character by NOCHANGE.
A costis associated with each elementary operation.
Typ-ically, INSERT and DELETE have the same (posi-tive) cost and NOCHANGE has a cost of zero.
RE-PLACE could have the same or a higher cost thanINSERT or DELETE.
Edit sequences can be rankedby the sum of the costs of the elementary opera-tions that appear in them.
The interesting edit se-quences are those with the lowest total cost.
Formost word pairs, there are more than one edit se-quence (or mapping) possible which have the sameminimal total cost.
To select a single edit sequencewhich will most likely result in a correct segmen-tation, we added a morphology-specific heuristic toa general string edit algorithm (Vidal et al, 1995).This heuristic always selects an edit sequence con-taining two subsequences which identify prefix-rootand root-suffix boundaries.
The heuristic depends104on the elementary operations being limited only toINSERT, DELETE and NOCHANGE, i.e.
no RE-PLACEs are allowed.
We assume that the tar-get word contains more morphemes than the sourceword.
It therefore follows that there are more IN-SERTs than DELETEs in an edit sequence.
Fur-thermore, the letters forming the morphemes of thetarget word appear only as the right-hand compo-nents of INSERT operations.
Consider the edit se-quence to change the string happy into the stringunhappier:0:u INSERT0:n INSERTh:h NOCHANGEa:a NOCHANGEp:p NOCHANGEp:p NOCHANGEy:0 DELETE0:i INSERT0:e INSERT0:r INSERT\[7\]Note that the prefix un- as well as the suffix -er consist only of INSERTs.
Furthermore, theprefix-root morpheme boundary is associated withan INSERT followed by a NOCHANGE and theroot-suffix boundary by a NOCHANGE-DELETE-INSERT sequence.
In general, the prefix-rootboundary is just the reverse of the root-suffix bound-ary, i.e.
INSERT-DELETE-NOCHANGE,  with theDELETE operation being optional.
The heuristicresulting from this observation is a bias giving high-est precedence to INSERT operations, followed byDELETE and NOCHANGE, in the first half of theedit sequence.
In the second half, the precedence isreversed.3.2 Merg ing  Edi t  SequencesA single source-target edit sequence may containspurious INSERTs which are not considered to formpart of a morpheme.
For example, the O:i insertionin Example 7 should not contribute to the suffix -er to form -ier, since -ier is an allomorph of -er.To combat these spurious INSERTs, all the edit se-quences for a set of source-target words are mergedas follows: A minimal acyclic finite state automaton(AFSA) is constructed which accepts all and onlythe edit sequences as input strings.
This AFSA isthen viewed as a DAG, with the elementary edit op-erations as edge labels.
For each edge a count is keptof the number of different edit sequences which passthrough it.
A path segment in the DAG consistingof one or more INSERT operations having a simi-lar count, is then considered to be associated with amorpheme in the target word.
The O:e O:r INSERTsequence associated with the -er suffix appears moretimes than the O:i O:e O:r INSERT sequence asso-ciated with the - ier suffix, even in a small set ofadjectively-related source-target pairs.
This meansthat there is a rise in the edge counts from O:i to O:e(indicating a root-suffix boundary), while O:e andO:r have similar frequency counts.
For prefixes a fallin the edge frequency count of an INSERT sequenceindicates a prefix-root boundary.To extract the morphemes of each target word,every path through the DAG is followed and onlythe target-side of the elementary operations ervingas edge labels, are written out.
The null characters(0) on the target-side of DELETEs are ignored whilethe target-side of INSERTs are only written if theirfrequency counts indicate that they are not sporadicallomorph INSERT operations.
For Example 7, thefollowing morphotactic description results:is\]Target Word -- Prefix + Source + Suffixunhappier = un + happy + erPhase one can segment only one layer of affix ad-ditions at a time.
However, once the morphemeboundary markers (+) have been inserted, phasetwo should be able to acquire the correct two-levelrules for an arbitrary number of affix additions:prefizl  +prefiz2+.
.
.
+roo~+suffizl +suff iz2+ .
.
.
.4 Acquiring Optimal RulesTo acquire the optimal rules, we first determinethe full length lexical-sufface representation of eachword pair.
This representation is required for writ-ing two-level rules (Section 2).
The morphotactic de-scriptions from the previous section provide source-target input pairs from which new string edit se-quences are computed: The right-hand side of themorphotactic description is used as the source andthe left-hand side as the target string.
For instance,Example 8 is written as:\[ 9\]Source: un+happy+erTarget: unhappierThe edit sequence\[ 10\]u:u n:n -t-:O h:h a:a p:p p:p y:i 4 :0  e:e r:rmaps the source into the target and provides thelexical and surface representation required by thetwo-level rules:\[ 11\]Lexical: u n + h a pp  y + e rSurface: u n 0 h a pp i  0 e rThe REPLACE elementary string edit operations(e.g.
y:i) are now allowed since the morphemeboundary markers (+) are already present in thesource string.
REPLACEs allow shorter edit se-quences to be computed, since one REPLACE does105the same work as an adjacent INSERT-DELETEpair.
REPLACE, INSERT and DELETE have thesame associated cost and NOCHANGE has a costof zero.
The morpheme boundary marker (+) isalways mapped to the null character (0), whichmakes for linguistically more understandable map-pings.
Under these conditions, the selection of anyminimal cost string edit mapping provides an ac-ceptable lexical-surface representation 2.To formulate a two-level rule for the source-targetpair happy-unhappier, we need a correspondencepair (CP) and a rule type (op), as well as a left con-text (LC) and a right context (RC) (see Section 2).Rules need only be coded for special pairs, i.e.
IN-SERTs, DELETEs or REPLACEs.
The only specialpair in the above example is y:i, which will be theCP of the rule.
Now the question arises as to howlarge the context of this rule must be?
It shouldbe large enough to uniquely specify the positionsin the lexical-surface input stream where the ruleis applied.
On the other hand, the context shouldnot be too large, resulting in an overspecified con-text which prohibits the application of the rule tounseen, but similar, words.
Thus to make a rule asgeneral as possible, its context (LC and RC) shouldbe as short as possible s .
By inspecting the edit se-quence in Example 10, we see that y changes intoi when y is preceded by a p:p, which serves as ourfirst attempt at a (left) context for y:i.
Two ques-tions must be asked to determine the correct ruletype to be used (Antworth, 1990, p.53):Quest ion  1 Is E the only environment in which L:Sis allowed?Quest ion  2 Must L always be realized as S in E?The term environment denotes the combined leftand right contexts of a special l~air.
E in our ex-ample is "p:p_", L is y and S is i.
Thus the answerto question one is true, since y:i only occurs afterp:p in our example.
The answer to question two isalso true, since y is always realized as i after a p:pin the above edit sequence.
Which rule type to useis gleaned from Table 1.
Thus, to continue our ex-ample, we should use the composite rule type (?
:~):\[ 12\]y:i ?~ p:p _2Our assumption is that such a minimal cost mappingwill lead to an optimal rule set.
In most (if not all) of theexamples een, a minimal mapping was also intuitivelyacceptable.sit abstractions (e.g.
sets such as V denoting vow-els) over the regular pairs are introduced, it will not beso simple to determine what is "a more general con-text".
However, current implementations require ab-stractions to be explicitly instantiated during the compi-lation process ((Karttunen and Beesley, 1992, pp.19-21)and (Antworth, 1990, pp.49-50)) .
Thus, with the cur-rent state of the art, abstractions serve only to make therules more readable.Q1 Q2 opfalse false nonetrue falsefalse truetrue true ?~zTable 1: Truth table to select the correct rule type.This example shows how to go about coding theset of two-level rules for a single source-target pair.However, this soon becomes a tedious and errorprone task when the number of source-target pairsincreases, due to the complex interplay of rules andtheir contexts.4.1 M in ima l  D iscern ing  Ru le  ContextsIt is important o acquire the minimal discerningcontext for each rule.
This ensures that the rulesare as general as possible (to work on unseen wordsas well) and prevents rule conflicts.
Recall that oneneed only code rules for the special pairs.
Thus itis necessary to determine a rule type with associ-ated minimal discerning context for each occurrenceof a special pair in the final edit sequences.
This isdone by comparing all the possible contiguous 4 con-texts of a special pair against all the possible con-texts of all the other feasible pairs.
To enable thecomputational comparison of the growing left andright contexts around a feasible pair, we developeda "mixed-context" representation.
We call the par-ticular feasible pair for which a mixed-context is tobe constructed, a marker pair (MP), to distinguishit from the feasible pairs in its context.
The mixed-context representation is created by writing the firstfeasible pair to the left of the marker pair, then thefirst right-context pair, then the second left-contextpair and so forth:\[ 13\]LC1, RC1, LC2, RC2, LC3, RC3, .
.
.
,  MPThe marker pair at the end serves as a label.
Specialsymbols indicate the start (SOS) and end (EOS) ofan edit sequence.
If, say, the right-context o fa  MP isshorter than the left-context, an out-of-bounds sym-bol (OOB) is used to maintain the mixed-contextformat.
For example the mixed-context of y:i in theedit sequence in Example 10, is represented as:\[ 14\]p:p, +:0, p:p, e:e, a:a, r:r, h:h, EOS, +:0, OOB,n:n, OOB, u:u, SOS, OOB, y:iThe common prefixes of the mixed-contexts aremerged by constructing a minimal AFSA which ac-cepts all and only these mixed-context sequences.4A two-level rule requires a contiguous context.106Question 2have theThe transitions (or edges, when viewed as a DAG) ofthe AFSA are labeled with the feasible pairs and spe-cial symbols in the mixed-context sequence.
Thereis only one final state for this minimal AFSA.
Notethat all and only the terminal edges leading to thisfinal state will be labeled with the marker pairs,since they appear at the end of the mixed-contextsequences.
More than one terminal edge may be la-beled with the same marker pair.
All the possible(mixed) contexts of a specific marker pair can berecovered by following every path from the root tothe terminal edges labeled with that marker pair.I f  a path is traversed only up to an intermediateedge, a shortened context surrounding the markerpair can be extracted.
We will call such an interme-diate edge a de l imi te r  edge,  since it delimits a short-ened context.
For example, traversing the mixedcontext path of y: i  in Example 14 up to e:e wouldresult in the (unmixed) shortened context:\[ 25\]p:p  p :p  _ +:0  e:eFrom the shortened context we can write a two-levelrule\[ 26\]y: i  op p:p  p :p  _ ?
:0  e:ewhich is more general than a rule using the full con-text:\[ 27\]y:i  op SOS u:u  n :n  h:h a:a p :p  p :p  _ +:0  e:e r:rEOSFor each marker pair in the DAG which is also aspecial pair, we want to find those delimiter edgeswhich produce the shortest contexts providing a t rueanswer to at least one of the two rule type de-cision questions given above.
The mixed-contextprefix-merged AFSA, viewed as a DAG, allow us torephrase the two questions in order to find answersin a procedural way:Quest ion  1 Traverse all the paths from the rootto the terminal edges labeled with the markerpair L :S .
Is there an edge el in the DAG whichall these paths have in common?
If so, thenquestion one is t rue  for the environment E con-structed from the shortened mixed-contexts a -sociated with the path prefixes delimited by el.Consider the terminal edges whichsame L-component as the marker pairL :S  and which are reachable from a commonedge e2 in the DAG.
Do all of these terminaledges also have the same S-component as themarker pair?
If so, then question two is t rue  forthe environment E constructed from the short-ened mixed-contexts associated with the pathprefixes delimited by e2.For each marker pair, we traverse the DAG and markthe delimiter edges neares t  to the root which allowa true answer to either question one, question twoor both (i.e.
el = e2).
This means that each pathfrom the root to a terminal edge can have at mostthree marked delimiter edges: One delimiting a con-text for a ~ rule, one delimiting a context for arule and one delimiting a context for a ~ rule.
Themarker pair used to answer the two questions, servesas the correspondence part (Section 2) of the rule.To continue with Example 14, let us assume that theDAG edge labeled with e:e is the closest edge to theroot which answers true only to question one.
Thenthe ~ rule is indicated:\[ IS\]y: i  ~ p :p  p :p  _ +:0  e:eHowever, if the edge labeled with r:r answers trueto both questions, we prefer the composite rule (?#)associated with it although this results in a largercontext:\[19\]y: i  ?
* a:a p :p  p :p  _ ?
:0  e:e r : rThe reasons for this preference are that the ?~ rule?
provides a more precise statement about the ap-plicable environment of the rule and it?
seems to be preferred in systems designed bylinguistic experts.Furthermore, from inspecting examples, a delimiteredge indicating a ~ rule generally delimits the short-est contexts, followed by the delimiter for ?~ andthe delimiter for ~ .
The shorter the selected con-text, the more generally applicable is the rule.
Wetherefore select only one rule per path, in the fol-lowing preference order: (1) ?~, (2) ~ and (3) ~ .Note that any of the six possible precedence orderswould provide an accurate analysis and generationof the pairs used for learning.
However, our sug-gested precedence seems to strike the best balancebetween over- or underrecognition and over- or un-dergeneration when the rules would be applied tounseen pairs.The mixed-context representation has one obviousdrawback: If an optimal rule has only a left or onlya right context, it cannot be acquired.
To solve thisproblem, two additional minimal AFSAs are con-structed: One containing only the left context in-formation for all the marker pairs and one contain-ing only the right context information.
The sameprocess is then followed as with the mixed contexts.The final set of rules is selected from the output ofall three the AFSAs: For each special pair1.
we select any of the ?~ rules with the shortestcontexts of which the special pair is the left-hand side, or1072.
if no ?~ rules were found, we select the shortestand ~ rules for each occurrence of the specialpair.
They are then merged into a single ?~ rulewith disjuneted contexts.The rule set learned is complete since all possiblecombinations of marker pairs, rule types and con-texts are considered by traversing all three DAGs.Furthermore, the rules in the set have the shortestpossible contexts, since, for a given DAG, there isonly one delimiter edge closest to the root for eachpath, marker pair and rule type combination.5 Results and EvaluationOur process works correctly for examples given in(Antworth, 1990).
There were two incorrect seg-mentations in the twenty one adjective pairs givenon page 106.
It resulted from an incorrect string editmapping of (un)happy to (un)happily.
For the suf-fix, the sequence .
.. O:i O:l y:y was generated insteadof the sequence.. ,  y:O O:i 0:I O:y.
The reason for thisis that the root word and the inflected form end inthe same letter (y) and one NOCHANGE (y:y) hasa lower cost than a DELETE (y:O) plus an INSERT(O:y).
The acquired segmentation for the 21 pairs,with the suffix segmentation of (un)happily manu-ally corrected, is:\[ 20\]Target : Prefix + Source + Suffixbigger = big + erbiggest = big + estunclear = un + clearunclearly -- un + clear ?
lyunhappy = un + happyunhappier = un + happy ?
erunhappiest = un ?
happy + estunhappily : un + happy ?
lyunreal = un + realcooler = cool -4- ercoolest = cool -4- estcoolly = cool -4- lyclearer -= clear -4- erclearest : clear -4- estclearly = clear -4- lyredder : red -4- erreddest = red + estreally : real + lyhappier : happy -4- erhappiest : happy -4- esthappily = happy -4- lyFrom these segmentations, the morphotactic com-ponent (Section 1) required by the morphologicalanalyzer/generator is generated with uncomplicatedtext-processing routines.
Three correct ~ rules,including two gemination rules, resulted for thesetwenty one pairsS:5The results in this paper were verified on the two-level processor PC-KIMMO (Antworth, 1990).
The two-\[ 21\]0:d ~ d :d_+:00:g ?=~ g:g_ +:0y:i ~=~ _ +:0To better illustrate the complexity of the rulesthat can be learned automatically by our process,consider the following set of fourteen Xhosa noun-locative pairs:Source Word --~ Target Wordinkosi --~ enkosiniiinkosi ~ ezinkosiniihashe -~ ehasheniimbewu -~ embewiniamanzi --~ emanziniubuchopho -~ ebucotsheniilizwe --, elizweniilanga --* elangeniingubo -~ engubeniingubo - ,  engutyeniindlu - ,  endliniindlu --~ endlwiniikhaya ~ ekhayeniikhaya --~ ekhaya\[ 22\]Note that this set contains ambiguity: The locativeof ingubo is either engubeni or engutyeni.
Our pro-cess must learn the necessary two-level rules to mapingubo to engubeni and engutyeni, as well as to mapboth engubeni and engutyeni in the other direction,i.e.
to ingubo.
Similarly, indlu and ikhaya eachhave two different locative forms.
Furthermore, thetwo source words inkosi and iinkosi (the plural ofinkosi) differ only by a prefixed i, but they have dif-ferent locative forms.
This small difference betweensource words provides an indication of the sensitiv-ity required of the acquisition process to provide thenecessary discerning information to a two-level mor-phological processor.
At the same time, our pro-cess needs to cope with possibly radical modifica-tions between source and target words.
Considerthe mapping between ubuchopho and its locativeebucotsheni.
Here, the only segments which staythe same from the source to the target word, are thethree letters -buc-, the letter -o -  (the deletion ofthe first -h -  is correct) and the second -h - .The target words are correctly segmented uringphase one as:level rule compiler KGEN (developed by Nathan Miles)was used to compile the acquired rules into the statetables required by PC-KIMMO.
Both PC-KIMMO andKGEN are available from the Summer Institute of Lin-guistics.108\[ 23\]Target = Prefix + Sourceenkosini = e + inkosiezinkosini = e + iinkosiehasheni = e + ihasheembewini  = e + imbewuemanzini  = e + amanziebucotsheni = e + ubuchophoelizweni = e + ilizweelangeni = e + i langaengubeni = e + inguboengutyeni = e + inguboendlini = e + indluendlwini = e + indluekhayeni = e + ikhayaekhaya = e + ikhayaNote that  the prefix e+put target words, whilea l ternat ive of ekhayen i )From this segmentedcomputes 24 min imal  context rules:+ Suffix-4- nl+ m-4- nl-4- nl+ nlA- nl-4- mA- nl-4- m-4- nl-4- m-4- m-4- nlis computed for all the in-all but ekhaya  (a correcthave +hi  as a suffix.ata,  phase two correctlyO:e ?
:~ o :y+:O _ n:nO:i ?
:> u :w+:O _ n:nO:s ?~ p:t _ h:hq-:O ~ e:e _+:0 ~ o:y _+:0 ~ u:w _+:0 ~ _ n:n\[ 24\]a:0 ?~ _m:ma:e ?~ _+:0n:nb:t ?=> _ o:yh:O ?~ _ o:oi:O ~ +:0 _ n:ni:O ~ _ h:hi:O ~ _ k:ki:O ~ _ l:li:O ~ _m:mi:O =~ +:0 _i:z ?~ _ i:io:e ~ _ +:0 n:no:y ~:~ b:t _p:t ?~ o:o _u:0 ?=> +:0 _ b:bu:i ?
:~ _ +:0 n:nu:w ~- 1:1 -+:00: iThe ~ and ~ rules of  a special pair can be mergedinto a single ~=~ rule.
For example the four rulesabove for the special pair q-:O can be merged into\[ 25\]4-:0 ?=~ e:e _ \[ o :y  _ \] u :w _ \[ _ n :nbecause both the two questions becomes t rue  forthe dis juncted environment e:e _ I o :y  _ I u :w - I -n :n .
The vertical bar ("1") is the t rad i t iona l  two-level notat ion which indicate the dis junct ion of two(or more) contexts.
The five ~ rules and the singlerule of the special pair i:O in Example  24 can bemerged in a similar way.
In this instance, the contextof the ~ rule (4- :0 -) needs to be added to some ofthe contexts of the ~ rules of i:O.
The following ?
:~rule results:\[26\]i:O ~ 4-:0 - n :n  I 4-:0 _ h:h I 4-:0 _ k:k I 4-:0 - l:l I4-:0 _ m:mIn this way the 24 rules are reduced to a set of 16rules which contain only a single ?~ rule for eachspecial pair.
This merged set of 16 two-level rulesanalyze and generate the input  word pairs 100% cor-rectly.The next step was to show the feasibi l i ty of au-tomat ica l ly  acquir ing a min imal  rule set for a widecoverage parser.
To get hundreds or even thousandsof input pairs, we implemented routines to extractthe lemmas ("head words") and their inflected formsfrom a machine-readable dict ionary.
In this waywe extracted 3935 Afr ikaans noun-plural  pairs whichserved as the input to our process.
Afr ikaans plu-rals are almost always derived with the addi t ion ofa suffix (mostly -e  or - s )  to the singular form.
Dif-ferent sound changes may occur dur ing this process.For example 6, geminat ion,  which indicates the short-ening of a preceding vowel, occurs frequently (e.g.hat  ---* kat te ) ,  as well as consonant- insert ion (e.g.has  ---* haste )  and elision (ampseed --~ ampsede) .Several sound changes may occur in the same word.For example, elision, consonant replacement andgeminat ion occurs in l oo f  ---* lowwe.
Afr ikaans (aGermanic  language) has borrowed a few words fromLatin.
Some of these words have two plural  forms,which introduces ambigui ty  in the word mappings:One plural  is formed with a Lat in suffix ( -a )  (e.g.emet ikum --~ emet ika)  and one with an indigenoussuffix (-s) (emetih.m emetih ms).
Allomorphsoccur as well, for example -ens  is an a l lomorph ofthe suffix - s  in bed + s ---, beddens .During phase one, all but eleven (0.3%) of the3935 input word pairs were segmented correctly.
Tofaci l i tate the evaluat ion of phase two, we define as imple  ru le  as a rule which has an environment con-sisting of a single context.
This is in contrast  withan environment consisting of two or more contextsdis juncted together.
Phase two acquired 531 s impleru les  for 44 special pairs.
Of these 531 simple rules,500 are ~ rules, nineteen are ?~ rules and twelveare ~ rules.
The average length of the simple rulecontexts is 4.2 feasible pairs.
Compare this with thenAil the examples comes from the 3935 input wordpairs.109average length of the 3935 final input edit sequenceswhich is 12.6 feasible pairs.
The 531 simple rulescan be reduced to 44 ~ rules (i.e.
one rule per spe-cial pair) with environments consisting ofdisjunctedcontexts.
These 44 ~ rules analyze and generate the3935 word pairs 100% correctly.
The total numberof feasible pairs in the 3935 final input edit stringsis 49657.
In the worst case, all these feasible pairsshould be present in the rule contexts to accuratelymodel the sound changes which might occur in theinput pairs.
However, the actual result is much bet-ter: Our process acquires a two-level rule set whichaccurately models the sound changes with only 4.5%(2227) of the input feasible pairs.To obtain a prediction of the analysis and gener-ation accuracy over unseen words, we divided the3935 input pairs into five equal sections.
Each fifthwas held out in turn as test data while a set oftwo-level rules was learned from the remaining four-fifths.
The average recognition accuracy as well asthe generation accuracy over the held out test datais 93.9%.6 SummaryWe have described and experimentally evaluated, forthe first time, a process which automatically ac-quires optimal two-level morphological rules frominput word pairs.
These can be used by a pub-licly available two-level morphological processor.
Wehave demonstrated that our acquisition process isportable between at least three different languagesand that an acquired rule set generalizes well towords not in the training corpus.
Finally, we haveshown the feasibility of automatically acquiring two-level rule sets for wide-coverage parsers, with wordpairs extracted from a machine-readable dictionary.7 AcknowledgementsPart of this work was completed uring the first au-thor's stay as visiting researcher at ISSCO (Univer-sity of Geneva).
We gratefully acknowledge the sup-port of ISSCO, as well as the Swiss Federal Govern-ment for providing a bursary which made this visitpossible.
For helpful comments on an earlier draft ofthe paper, we wish to thank Susan Armstrong andSabine Lehmann as well as the anonymous review-ers.ReferencesEvan L. Antworth.
1990.
PC-KIMMO: A Two-levelProcessor for Morphological Analysis.
Summer In-stitute of Linguistics, Dallas, Texas.Walter Daelemans, Peter Berck and Steven Gillis.1996.
Unsupervised Discovery of PhonologicalCategories through Supervised Learning of Mor-phological Rules.
In COLING-96: 16th Interna-tional Conference on Computational Linguistics,pages 95-100, Copenhagen, Denmark.Michael Gasser.
1994.
Acquiring Receptive Mor-phology: A Connectionist Model.
In Proceedingsof ACL-94.
Association for Computational Lin-guistics, Morristown, New Jersey.Andrew R. Golding and Henry S. Thompson.
1985.A morphology component for language programs.Linguistics, 23:263-284.Joseph E. Grimes.
1983.
Affiz positions and cooc-currences: the PARADIGM program.
Summer In-stitute of Linguistics Publications in LinguisticsNo.
69.
Dallas: Summer Institute of Linguisticsand University of Texas at Arlington.Laud Karttunen and Kenneth R. Beesley.
1992.Two-level Rule Compiler.
Technical Report ISTL-92-2.
Xerox Palo Alto Research Center.George Anton Kiraz.
1996.
SEMHE: A general-ized two-level System.
In Proceedings of ACL-96.Association for Computational Linguistics, pages159-166, Santa Cruz, California.Kimmo Koskenniemi.
1983.
Two-level Morphol-ogy: A General Computational Model for Word-Form Recognition and Production.
PhD Disserta-tion.
Department of General Linguistics, Univer-sity of Helsinki.Kimmo Koskenniemi.
1990.
A discovery procedurefor two-level phonology.
Computational Lexicol-ogy and Lexicography: Special Issue dedicated toBernard Quemada, Vol.
I (Ed.
L. Cignoni, C. Pe-ters).
Linguistica Computazionale, Pisa, VolumeVI, 1990, pages 451-465.Evelin Kuusik.
1996.
Learning Morphology: Al-gorithms for the Identification of Stem Changes.In COLING-96: i6th International Conferenceon Computational Linguistics, pages 1102-1105,Copenhagen, Denmark.David Sankoff and Joseph B. Kruskal.
1983.
Timewarps, string edits, and macromoleeules: the the-ory and practice of sequence comparison.
Addison-Wesley, Massachusetts.Gary F. Simons.
1988.
Studying morphophonemicalternation i annotated text, parts one and two.Notes on Linguistics, 41:41-46; 42:27-38.Richard Sproat.
1992.
Morphology and Computa-tion.
The MIT Press, Cambridge, England.Enrique Vidal, AndrOs Marzal and Pablo Aibar.1995.
Fast Computation of Normalized Edit Dis-tances.
IEEE Trans.
Pattern Analysis and Ma-chine Intelligence, 17:899-902.Klaus Wothke.
1986.
Machine learning of morpho-logical rules by generalization and analogy.
InCOLING-86: 11~h International Conference onComputational Linguistics, pages 289-293, Bonn.110
