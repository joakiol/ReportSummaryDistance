Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1567?1578, Dublin, Ireland, August 23-29 2014.The Wisdom of Minority: Unsupervised Slot Filling Validation based onMulti-dimensional Truth-FindingDian Yu1, Hongzhao Huang1, Taylor Cassidy2,3, Heng Ji1Chi Wang4, Shi Zhi4, Jiawei Han4, Clare Voss2, Malik Magdon-Ismail11Computer Science Department, Rensselaer Polytechnic Institute2U.S.
Army Research Lab3IBM T. J. Watson Research Center4Computer Science Department, Univerisity of Illinois at Urbana-Champaign1{yud2,huangh9,jih,magdon}@rpi.edu,2,3{taylor.cassidy.ctr,clare.r.voss.civ}@mail.mil4{chiwang1,shizhi2,hanj}@illinois.eduAbstractInformation Extraction using multiple information sources and systems is beneficial due to multi-source/system consolidation and challenging due to the resulting inconsistency and redundancy.We integrate IE and truth-finding research and present a novel unsupervised multi-dimensionaltruth finding framework which incorporates signals from multiple sources, multiple systems andmultiple pieces of evidence by knowledge graph construction through multi-layer deep linguisticanalysis.
Experiments on the case study of Slot Filling Validation demonstrate that our approachcan find truths accurately (9.4% higher F-score than supervised methods) and efficiently (finding90% truths with only one half the cost of a baseline without credibility estimation).1 IntroductionTraditional Information Extraction (IE) techniques assess the ability to extract information fromindividual documents in isolation.
However, similar, complementary or conflicting information mayexist in multiple heterogeneous sources.
We take the Slot Filling Validation (SFV) task of the NIST TextAnalysis Conference Knowledge Base Population (TAC-KBP) track (Ji et al., 2011) as a case study.
TheSlot Filling (SF) task aims at collecting from a large-scale multi-source corpus the values (?slot fillers?
)for certain attributes (?slot types?)
of a query entity, which is a person or some type of organization.
KBP2013 has defined 25 slot types for persons (per) (e.g., age, spouse, employing organization) and 16 slottypes for organizations (org) (e.g., founder, headquarters-location, and subsidiaries).
Some slot typestake only a single slot filler (e.g., per:birthplace), whereas others take multiple slot fillers (e.g., org:topemployees).We call a combination of query entity, slot type, and slot filler a claim.
Along with each claim, eachsystem must provide the ID of a source document and one or more detailed context sentences as evidencewhich supports the claim.
A response (i.e., a claim, evidence pair) is correct if and only if the claim istrue and the evidence supports it.Given the responses produced by multiple systems from multiple sources in the SF task, the goal ofthe SFV task is to determine whether each response is true or false.
Though it?s a promising line ofresearch, it raises two complications: (1) different information sources may generate claims that varyThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1567in trustability; and (2) a large-scale number of SF systems using different resources and algorithms maygenerate erroneous, conflicting, redundant, complementary, ambiguously worded, or inter-dependentclaims from the same set of documents.
Table 1 presents responses from four SF systems for the queryentity Ronnie James Dio and the slot type per:city of death.
Systems A, B and D return Los Angeleswith different pieces of evidence1extracted from different information sources, though the evidence ofSystem D does not decisively support the claim.
System C returns Atlantic City, which is neither truenor supported by the corresponding evidence.Such complications call for ?truth finding?
: determining the veracity of multiple conflicting claimsfrom various sources and systems.
We propose a novel unsupervised multi-dimensional truth findingframework to study credibility perceptions in rich and wide contexts.
It incorporates signals frommultiple sources and systems, using linguistic indicators derived from knowledge graphs constructedfrom multiple evidences using multi-layer deep linguistic analysis.
Experiments demonstrate that ourapproach can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (find90% truths with only one half cost of a baseline without credibility estimation).System Source Slot Filler EvidenceA Agence France-Presse, NewsLos Angeles The statement was confirmed by publicist Maureen O?Connor, who said Diodied in Los Angeles.B New YorkTimes, NewsLos Angeles Ronnie James Dio, a singer with the heavy-metal bands Rainbow, BlackSabbath and Dio, whose semioperatic vocal style and attachment to demonicimagery made him a mainstay of the genre, died on Sunday in Los Angeles.C Discussion Fo-rumAtlantic City Dio revealed last summer that he was suffering from stomach cancer shortlyafter wrapping up a tour in Atlantic City.D AssociatedPressWorldstream,NewsLos Angeles LOS ANGELES 2010-05-16 20:31:18 UTC Ronnie James Dio, the metal godwho replaced Ozzy Osbourne in Black Sabbath and later piloted the bandsHeaven, Hell and Dio, has died, according to his wife and manager.Table 1: Conflicting responses across different SF systems and different sources (query entity = RonnieJames Dio, slot type = per:city of death).2 Related Work & Our Novel ContributionsMost previous SFV work (e.g., (Tamang and Ji, 2011; Li and Grishman, 2013)) focused on filteringincorrect claims from multiple systems by simple heuristic rules, weighted voting, or costly supervisedlearning to rank algorithms.
We are the first to introduce the truth finding concept to this task.The ?truth finding?
problem has been studied in the data mining and database communities (e.g., (Yinet al., 2008; Dong et al., 2009a; Dong et al., 2009b; Galland et al., 2010; Blanco et al., 2010; Pasternackand Roth, 2010; Yin and Tan, 2011; Pasternack and Roth, 2011; Vydiswaran et al., 2011; Ge et al.,2012; Zhao et al., 2012; Wang et al., 2012; Pasternack and Roth, 2013)).
Compared with the previouswork, our truth finding problem is defined under a unique setting: each response consists of a claim andsupporting evidence, automatically generated from unstructured natural language texts by a SF system.The judgement of a response concerns both the truth of the claim and whether the evidence supportsthe claim.
This has never been modeled before.
We mine and exploit rich linguistic knowledge frommultiple lexical, syntactic and semantic levels from evidence sentences for truth finding.
In addition,previous truth finding work assumed most claims are likely to be true.
However, most SF systems havehit a performance ceiling of 35% F-measure, and false responses constitute the majority class (72.02%)due to the imperfect algorithms as well as the inconsistencies of information sources.
Furthermore,certain truths might only be discovered by a minority of good systems or from a few good sources.
Forexample, 62% of the true responses are produced only by 1 or 2 of the 18 SF systems.1Hereafter, we refer to ?pieces of evidence?
with the shorthand ?evidences?.
Note that SF systems may include multiplesentences as ?evidence?
within their responses.1568r1Response<Claim, Evidence>t1t2Systems1r2r3s2Sourcet3r4 t4s3r5Figure 1: Heterogeneous networks for MTM.3 MTM: A Multi-dimensional Truth-Finding ModelMTM ConstructionA response is trustworthy if its claim is true and its evidence supports the claim.
A trustedsource always supports true claims by giving convincing evidence, and a good system tends to extracttrustworthy responses from trusted sources.
We propose a multi-dimensional truth-finding model (MTM)to incorporate and compute multi-dimensional credibility scores.Consider a set of responses R = {r1, .
.
.
, rm} extracted from a set of sources S = {s1, .
.
.
, sn} andprovided by a set of systems T = {t1, .
.
.
, tl}.
A heterogeneous network is constructed as shown inFig.
1.
Let weight matrices be Wrsm?n= {wrsij} and Wrtm?l= {wrtik}.
A link wrsij= 1 is generatedbetween riand sjwhen response riis extracted from source sj, and a link wrtik= 1 is generated betweenriand tkwhen response riis provided by system tk.Credibility InitializationEach source is represented as a combination of publication venue and genre.
The credibility scoresof sources S are initialized uniformly as1n, where n is the number of sources.
Given the set of systemsT = {t1, .
.
.
, tl}, we initialize their credibility scores c0(t) based on their interactions on the predictedresponses.
Suppose each system tigenerates a set of responses Rti.
The similarity between two systemstiand tjis defined as similarity(ti, tj) =|Rti?Rtj|log (|Rti|)+log (|Rtj|)(Mihalcea, 2004).
Then we construct aweighted undirected graph G = ?T,E?, where T (G) = {t1, .
.
.
, tl} and E(G) = {?ti, tj?
}, ?ti, tj?
=similarity(ti, tj), and apply the TextRank algorithm (Mihalcea, 2004) on G to obtain c0(t).We got negative results by initializing system credibility scores uniformly.
We also got negative resultsby initializing system credibility scores using system metadata, such as the algorithms and resources thesystem used at each step, its previous performance in benchmark tests, and the confidence values itproduced for its responses.
We found the quality of an SF system depends on many different resourcesinstead of any dominant one.
For example, an SF system using a better dependency parser does notnecessarily produce more truths.
In addition, many systems are actively being improved, renderingprevious benchmark results unreliable.
Furthermore, most SF systems still lack reliable confidenceestimation.The initialization of the credibility scores for responses relies on deep linguistic analysis of theevidence sentences and the exploitation of semantic clues, which will be described in Section 4.Credibility Propagation1569We explore the following heuristics in MTM.HEURISTIC 1: A response is more likely to be true if derived from many trustworthy sources.
A sourceis more likely to be trustworthy if many responses derived from it are true.HEURISTIC 2: A response is more likely to be true if it is extracted by many trustworthy systems.
Asystem is more likely to be trustworthy if many responses generated by it are true.Based on these two heuristics we design the following credibility propagation approach to mutuallyreinforce the trustworthiness of linked objects in MTM.By extension of Co-HITS (Deng et al., 2009), designed for bipartite graphs, we develop a propagationmethod to handle heterogeneous networks with three types of objects: source, response and system.
Letthe weight matrices beWrs(between responses and sources) andWrt(between responses and systems),and their transposes beWsrandWtr.
We can obtain the transition probability that vertex siin S reachesvertex rjin R at the next iteration, which can be formally defined as a normalized weight psrij=wsrij?kwsriksuch that?rj?Rpsrij= 1.
We compute the transition probabilities prsji, prtjkand ptrkjin an analogousfashion.Given the initial credibility scores c0(r), c0(s) and c0(t), we aim to obtain the refined credibility scoresc(r), c(s) and c(t) for responses, sources, and systems, respectively.
Starting with sources, the updateprocess considers both the initial score c0(s) and the propagation from connected responses, which weformulated as:c(si) = (1?
?rs)c0(si) + ?rs?rj?Rprsjic(rj) (1)Similarly, the propagation from responses to systems is formulated as:c(tk) = (1?
?rt)c0(tk) + ?rt?rj?Rprtjkc(rj) (2)Each response?s score c(rj) is influenced by both linked sources and systems:c(rj) = (1?
?sr?
?tr)c0(rj) + ?sr?si?Spsrijc(si) + ?tr?tk?Tptrkjc(tk) (3)where ?rs, ?rt, ?srand ?tr?
[0, 1].
These parameters control the preference for the propagated overinitial score for every type of random walk link.
The larger they are, the more we rely on link structure2.The propagation algorithm converges (10 iterations in our experimental settings) and a similar theoreticalproof to HITS (Peserico and Pretto, 2009) can be constructed.
Algorithm 1 summarizes MTM.4 Response Credibility InitializationEach evidence along with a claim is expressed as a few natural language sentences that include the queryentity and the slot filler, along with semantic content to support the claim.
We analyze the evidence ofeach response in order to initialize that response?s credibility score.
This is done using heuristic rulesdefined in terms of the binary outputs of various linguistic indicators (Section 4.1).4.1 Linguistic IndicatorsWe encode linguistic indicators based on deep linguistic knowledge acquisition and use them todetermine whether responses provide supporting clues or carry negative indications (Section 4.3).
Theseindicators make use of linguistic features on varying levels - surface form, sentential syntax, semantics,and pragmatics - and are defined in terms of knowledge graphs (Section 4.2).
We define a heuristic rulefor each slot type in terms of the binary-valued linguistic indicator outputs to yield a single binary value(1 or 0) for each response.
If a response?s linguistic indicator value is 1, the credibility score of a responseis initialized at 1.0, and 0.5 otherwise.2We set ?rs= 0.9, ?sr= 0.1, ?rt= 0.3 and ?tr= 0.2, optimized from a development set.
See Section 5.1.1570Input: A set of responses (R), sources (S) and systems (T ).Output: Credibility scores (c(r)) for R.1: Initialize the credibility scores c0(s) for S as c0(si) =1|S|;2: Use TextRank to compute initial credibility scores c0(t) for T ;3: Initialize the credibility scores c0(r) using linguistic indicators (Section 4);4: Construct heterogeneous networks across R, S and T ;5: k ?
0, diff?
10e6;6: while k < MaxIteration and diff > MinThreshold do7: Use Eq.
(1) to compute ck+1(s);8: Use Eq.
(2) to compute ck+1(t);9: Use Eq.
(3) to compute ck+1(r);10: Normalize ck+1(s), ck+1(t), and ck+1(r);11: diff??(|ck+1(r)?
ck(r)|);12: k ?
k + 113: end whileAlgorithm 1:Multi-dimensional Truth-Finding.4.2 Knowledge Graph ConstructionA semantically rich knowledge graph is constructed that links a query entity, all of its relevant slotfiller nodes, and nodes for other intermediate elements excerpted from evidence sentences.
There is oneknowledge graph per sentence.Fig.
2 shows a subregion of the knowledge graph built from the sentence: ?Mays, 50, died in his sleepat his Tampa home the morning of June 28.?.
It supports 3 claims: [Mays, per: city of death, Tampa],[Mays, per: date of death, 06/28/2009] and [Mays, per: age, 50].Formally, a knowledge graph is an annotated graph of entity mentions, phrases and their links.
It mustcontain one query entity node and one or more slot filler nodes.
The annotation of a node includes itsentity type, subtype, mention type, referent entities, and semantic category (though not every node haseach type of annotation).
The annotation of a link includes a dependency label and/or a semantic relationbetween the two linked nodes.The knowledge graph is constructed using the following procedure.
First, we annotate the evidencetext using dependency parsing (Marneffe et al., 2006) and Information Extraction (entity, relation andevent) (Li et al., 2013; Li and Ji, 2014).
Two nodes are linked if they are deemed related by one of theannotation methods (e.g., [Mays, 50] is labeled with the dependency type amod, and [home, Tampa] islabeled with the semantic relation located in).
The annotation output is often in terms of syntactic heads.Thus, we extend the boundaries of entity, time, and value mentions (e.g., people?s titles) to include anentire phrase where possible.
We then enrich each node with annotation for entity type, subtype andmention type.
Entity type and subtype refer to the role played by the entity in the world, the latter beingmore fine-grained, whereas mention type is syntactic in nature (it may be pronoun, nominal, or propername).
For example, ?Tampa?
in Fig.
2 is annotated as a Geopolitical (entity type) Population-Center(subtype) Name (mention type) mention.
Every time expression node is annotated with its normalizedreference date (e.g., ?June, 28?
in Fig.
2 is normalized as ?06/28/2009?
).Second, we perform co-reference resolution, which introduces implicit links between nodes that referto the same entity.
Thus, an entity mention that is a nominal or pronoun will often be co-referentiallylinked to a mention of a proper name.
This is important because many queries and slot fillers areexpressed only as nominal mentions or pronouns in evidence sentences, their canonical form appearingelsewhere in the document.Finally, we address the fact that a given relation type may be expressed in a variety of ways.
Forexample, ?the face of ?
indicates the membership relation in the following sentence: ?Jennifer Dunn wasthe face of the Washington state Republican Party for more than two decades.?
We mined a large1571MayshaddiedsleephishomeTampa50June,28amodnsubjauxprep_inpossprep_atprep_ofnnposslocated_in{PER.Individual, NAM, Billy Mays}?Query?
{NUM }?Per:age?
{Death-Trigger}{PER.Individual.PRO, Mays}{GPE.Population-Center.NAM, FL-USA}?
Per:place_of_death?
{FAC.Building-Grounds.NOM}{06/28/2009, TIME-WITHIN}?
per:date_of_death?Figure 2: Knowledge Graph Example.number of trigger phrases for each slot type by mapping various knowledge bases, including WikipediaInfoboxes, Freebase (Bollacker et al., 2008), DBPedia (Auer et al., 2007) and YAGO (Suchanek etal., 2007), into the Gigaword corpus3and Wikipedia articles via distant supervision (Mintz et al.,2009)4.
Each intermediate node in the knowledge graph that matches a trigger phrase is then assigned acorresponding semantic category.
For example, ?died?
in Fig.
2 is labeled a Death-Trigger.4.3 Knowledge Graph-Based VerificationWe design linguistic indicators in terms of the properties of nodes and paths that are likely to be bear onthe response?s veracity.
Formally, a path consists of the list of nodes and links that must be traversedalong a route from a query node to a slot filler node.Node indicators contribute information about a query entity or slot filler node in isolation, thatmay bear on the trustworthiness of the containing evidence sentence.
For instance, a slot filler for theper:date of birth slot type must be a time expression.Node Indicators1.
Surface: Whether the slot filler includes stop words; whether it is lower cased but appears in news.These serve as negative indicators.2.
Entity type, subtype and mention type: For example, the slot fillers for ?org:top employees?
must beperson names; and fillers for ?org:website?
must match the url format.
Besides the entity extractionsystem, we also exploited the entity attributes mined by the NELL system (Carlson et al., 2010)from the KBP source corpus.Each path contains syntactic and/or semantic relational information that may shed light on the mannerin which the query entity and slot filler are related, based on dependency parser output, IE output,and trigger phrase labeling.
Path indicators are used to define properties of the context in whichwhich query-entity and slot-filler are related in an evidence sentence.
For example, whether the path3http://catalog.ldc.upenn.edu/LDC2011T074Under the distant supervision assumption, sentences that appear to mention both entities in a binary relation contained inthe knowledge base were assumed to express that relation.1572associated with a claim about an organization?s top employee includes a title commonly associated withdecision-making power can be roughly represented using the trigger phrases indicator.Path Indicators1.
Trigger phrases: Whether the path includes any trigger phrases as described in Section 4.2.2.
Relations and events: Whether the path includes semantic relations or events indicative of the slottype.
For example, a ?Start-Position?
event indicates a person becomes a ?member?
or ?employee?of an organization.3.
Path length: Usually the length of the dependency path connecting a query node and a slot fillernode is within a certain range for a given slot type.
For example, the path for ?per:title?
is usuallyno longer than 1.
A long dependency path between the query entity and slot filler indicates a lackof a relationship.
In the following evidence sentence, which does not entail the ?per:religion?relation between ?His?
and the religion ?Muslim?, there is a long path (?his-poss-moment-nsubj-came-advcl-seized-militant-acmod-Muslim?
): ?His most noticeable moment in the public eye camein 1979, when Muslim militants in Iran seized the U.S. Embassy and took the Americans stationedthere hostage.
?.Detecting and making use of interdependencies among various claims is another unique challenge inSFV.
After initial response credibility scores are calculated by combining linguistic indicator values, weidentify responses that have potentially conflicting or potentially supporting slot-filler candidates.
Forsuch responses, their credibility scores are changed in accordance with the binary values returned by thefollowing indicators.Interdependent Claims Indicators1.
Conflicting slot fillers: When fillers for two claims with the same query entity and slot type appearin the same evidence sentence, we apply an additional heuristic rule designed for the slot type inquestion.
For example, the following evidence sentence indicates that compared to ?Cathleen P.Black?, ?Susan K. Reed?
is more likely to be in a ?org:top employees/members?
relation with ?TheOprah Magazine?
due to the latter pair?s shorter dependency path: ?Hearst Magazine?s PresidentCathleen P. Black has appointed Susan K. Reed as editor-in-chief of the U.S. edition of TheOprah Magazine.?.
The credibility scores are accordingly changed (or kept at) 0.5 for responsesassociated with the former claim, and 1.0 for those associated with the latter.2.
Inter-dependent slot types: Many slot types are inter-dependent, such as ?per:title?
and?per:employee of ?, and various family slots.
After determining initial credibility scores for eachresponse, we check whether evidence exists for any implied claims.
For example, given initialcredibility scores of 1.0 for two responses supporting the claims that (1)?David?
is ?per:children?of ?Carolyn Goodman?
and (2)?Andrew?
is ?per:sibling?
of ?David?, we check for any responsessupporting the claim that (3)?Andrew?
is ?per:children?
of ?Carolyn Goodman?, and set theircredibility scores to 1.0.
For example, a response supporting this claim included the evidencesentence, ?Dr.
Carolyn Goodman, her husband, Robert, and their son, David, said goodbye toDavid?s brother, Andrew.
?.5 Experimental ResultsThis section presents the experiment results and analysis of our approach.5.1 DataThe data set we use is from the TAC-KBP2013 Slot Filling Validation (SFV) task, which consists of themerged responses returned by 52 runs (regarded as systems in MTM) from 18 teams submitted to the Slot1573Methods Precision Recall F-measure Accuracy Mean Average Precision1.Random 28.64% 50.48% 36.54% 50.54% 34%2.Voting 42.16% 70.18% 52.68% 62.54% 62%3.Linguistic Indicators 50.24% 70.69% 58.73% 72.29% 60%4.SVM (3 + System + Source) 56.59% 48.72% 52.36% 75.86% 56%5.MTM (3 + System + Source) 53.94% 72.11% 61.72% 81.57% 70%Table 2: Overall Performance Comparison.Filling (SF) task.
The source collection has 1,000,257 newswire documents, 999,999 web documentsand 99,063 discussion forum posts, which results in 10 different sources (combinations of publicationvenues and genres) in our experiment.
There are 100 queries: 50 person and 50 organization entities.After removing redundant responses within each single system run, we use 45,950 unique responses asthe input to truth-finding.
Linguistic Data Consortium (LDC) human annotators manually assessed allof these responses and produced 12,844 unique responses as ground truth.
In order to compare withstate-of-the-art supervised learning methods for SFV (Tamang and Ji, 2011; Li and Grishman, 2013), wetrained a SVMs classifier5as a counterpart, incorporating the same set of linguistic indicators, sourcesand systems as features.
We picked 10% (every 10th line) to compose the development set for MTM andthe training set for the SVMs.
The rest is used for blind test.5.2 Overall PerformanceTable 2 shows the overall performance of various truth finding methods on judging each response as trueor false.
MTM achieves promising results and even outperforms supervised learning approach.
Table 3presents some examples ranked at the top and the bottom based on the credibility scores produced byMTM.We can see that majority voting across systems performs much better than random assessment, but itsaccuracy is still low.
For example, the true claim T5 was extracted by only one system because mostsystems mistakenly identified ?Briton Stuart Rose?
as a person name.
In comparison, MTM obtainedmuch better accuracy by also incorporating multiple dimensions of source and evidence information.Method 3 using linguistic indicators alone, already achieved promising results.
For example, manyclaims are judged as truths through trigger phrases (T1 and T5), event extraction (T2), coreference (T4),and node type indicators (T3).
On the other hand, many claims are correctly judged as false becausetheir evidence sentences did not include the slot filler (F1, F4, F5) or valid knowledge paths to connectthe query entity and the slot filler (F2, F3).
The performance gain (2.99% F-score) from Method 3 toMethod 5 shows the need for incorporating system and source dimensions.
For example, most truths arefrom news while many false claims are from newsgroups and discussion forum posts (F1, F2, F5).The SVMs model got very low recall because of the following two reasons: (1) It ignored the inter-dependency between multiple dimensions; (2) the negative instances are dominant in the training data,so the model is biased towards labeling responses as false.5.3 Truth Finding EfficiencyTable 3 shows that some truths (T1) are produced from low-ranked systems whereas some false responsesfrom high-ranked systems (F1, F2).
Note that systems are ranked by their performance in KBP SF task.In order to find all the truths, human assessors need to go through all the responses returned by multiplesystems.
This process was proven very tedious and costly (Ji et al., 2010; Tamang and Ji, 2011).Our MTM approach can expedite this process by ranking responses based on their credibility scoresand asking human to assess the responses with high credibility first.
Traditionally, when human assessresponses, they follow an alphabetical order or system IDs in a ?passive learning?
style.
This is set asour baseline.
For comparison, we also present the results using only linguistic indicators, using votingin which the responses which get more votes across systems are assessed first, and the oracle methodassessing all correct responses first.
Table 2 shows our model can successfully rank trustworthy responsesat high positions compared with other approaches.5We used the LIBSVM toolkit (Chang and Lin, 2011) with Gaussian radial basis function kernel.1574Response Ranked by MTMSourceSystemRankClaimEvidenceQuery Entity Slot Type Slot FillerTopTruthsT1 ChinaBankingRegulatoryCommissionorg:topmember-s/employeesLiuMingkangLiu Mingkang, the chairman ofthe China Banking RegulatoryCommissionCentralNewsAgencyof TaiwanNewsNews 15T2 GalleonGrouporg:foundedbyRajRajaratnamGalleon Group, founded by bil-lionaire Raj RajaratnamNew YorkTimesNews 9T3 Mike Penner per:age 52 L.A. Times Sportswriter MikePenner, 52, DiesNew YorkTimesNews 1T4 ChinaBankingRegulatoryCommissionorg:alternatenamesCBRC ...China Banking Regulatory Com-mission said in the notice.
The fivebanks ... according to CBRC.Xinhua,NewsNews 5T5 Stuart Rose per:origin Briton Bolland, 50, will replace BritonStuart Rose at the start of 2010.AgenceFrance-PresseNews 3BottomFalseClaimsF1 AmericanAssociationfor the Ad-vancement ofScienceorg:topmembersemployeesFreedman erica.html &gt; American LibraryAssociation, President: MauriceFreedman &lt; http://www.aft.org&gt; American Federation ofTeachers ...Google Newsgroup4F2 Jade Goody per:origin Britain because Jade Goody?s the onlyperson to ever I love BritainDiscussion Forum 3F3 Don Hewitt per:spouse Swap ...whether ?Wife Swap?
on ABCor ?Jon &amp; Kate?
on TLCNew YorkTimesNews 7F4 Council ofMortgageLendersorg:website www.cml.org.ukme purchases in the U.K. jumpedby 16 percent in April, suggestingthe property market slump mayhave bottomed outAssociatedPressWorld-streamNews 18F5 Don Hewitt per:alternatenamesHewitt M-chenUS DoMIna THOMPson LACtaTehaVeD [3866 words]Google Newsgroup13Table 3: Top and Bottom Response Examples Ranked by MTM.Fig.
3 summarizes the results from the above 6 approaches.
The common end point of all curvesrepresents the cost and benefit of assessing all system responses.
We can see that the baseline is veryinefficient at finding the truths.
If we employ linguistic indicators, the process can be dramaticallyexpedited.
MTM provides further significant gains, with performance close to the Oracle.
With only halfthe cost of the baseline, MTM can already find 90% truths.5.4 Enhance Individual SF SystemsFinally, as a by-product, our MTM approach can also be exploited to validate the responses from eachindividual SF system based on their credibility scores.
For fair comparison with the official KBPevaluation, we use the same ground-truth in KBP2013 and standard precision, recall and F-measuremetrics as defined in (Ji et al., 2011).
To increase the chance of including truths which may be particularlydifficult for a system to find, LDC prepared a manual key which was assessed and included in the finalground truth.
According to the SF evaluation setting, F-measure is computed based on the number ofunique true claims.
After removing redundancy across multiple systems, there are 1,468 unique trueclaims.
The cutoff criteria for determining whether a response is true or not was optimized from thedevelopment set.Fig.
4 presents the F-measure scores of the best run from each individual SF system.
We can see thatour MTM approach consistently improves the performance of almost all SF systems, in an absolute gainrange of [-1.22%, 5.70%].
It promotes state-of-the-art SF performance from 33.51% to 35.70%.
OurMTM approach provides more gains to SF systems which mainly rely on lexical or syntactic patternsthan other systems using distant supervision or logic rules.157510 10000 20000 30000 400000200040006000800010000120001400013 245#truths6 Oracle5 MTM4 SVM3 Linguistic Indicator2 Voting1 Baseline#total responses6Figure 3: Truth Finding Efficiency.0 2 4 6 8 10 12 14 16 18 2005101520253035F-mesaure(%)SystemBeforeAfterFigure 4: Impact on Individual SF Systems.15766 Conclusions and Future WorkTruth finding has received attention from both Natural Language Processing (NLP) and Data Miningcommunities.
NLP work has mostly explored linguistic analysis of the content, while Data Miningwork proposed advanced models in resolving conflict information from multiple sources.
They haverelative strengths and weaknesses.
In this paper we leverage the strengths of these two distinct,but complementary research paradigms and propose a novel unsupervised multi-dimensional truth-finding framework incorporating signals both from multiple sources, multiple systems and multipleevidences based on knowledge graph construction with multi-layer linguistic analysis.
Experiments ona challenging SFV task demonstrated that this framework can find high-quality truths efficiently.
In thefuture we will focus on exploring more inter-dependencies among responses such as temporal and causalrelations.AcknowledgmentsThis work was supported by the U.S. Army Research Laboratory under Cooperative AgreementNo.
W911NF-09-2-0053 (NS-CTA), the U.S. Army Research Office under Cooperative AgreementNo.
W911NF-13-1-0193, U.S. National Science Foundation grants IIS-0953149, CNS-0931975,IIS-1017362, IIS-1320617, IIS-1354329, U.S. DARPA Award No.
FA8750-13-2-0041 in the DeepExploration and Filtering of Text (DEFT) Program, IBM Faculty Award, Google Research Award,DTRA, DHS and RPI faculty start-up grant.
The views and conclusions contained in this document arethose of the authors and should not be interpreted as representing the official policies, either expressedor implied, of the U.S. Government.
The U.S. Government is authorized to reproduce and distributereprints for Government purposes notwithstanding any copyright notation here on.ReferencesS.
Auer, C. Bizer, G. Kobilarov, J. Lehmann, and Z. Ives.
2007.
Dbpedia: A nucleus for a web of open data.
InProc.
the 6th International Semantic Web Conference.L.
Blanco, V. Crescenzi, P. Merialdo, and P. Papotti.
2010.
Probabilistic models to reconcile complex datafrom inaccurate data sources.
In Proc.
Int.
Conf.
on Advanced Information Systems Engineering (CAiSE?10),Hammamet, Tunisia, June.K.
Bollacker, R. Cook, and P. Tufts.
2008.
Freebase: A shared database of structured general human knowledge.In Proc.
National Conference on Artificial Intelligence.A.
Carlson, J. Betteridge, B. Kisiel, B.
Settles, Estevam R Hruschka Jr, and Tom M Mitchell.
2010.
Toward anarchitecture for never-ending language learning.
In AAAI.C.
Chang and C. Lin.
2011.
Libsvm: a library for support vector machines.
ACM Transactions on IntelligentSystems and Technology (TIST), 2(3):27.H.
Deng, M. R. Lyu, and I.
King.
2009.
A generalized co-hits algorithm and its application to bipartite graphs.
InProceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,KDD ?09, pages 239?248, New York, NY, USA.
ACM.X.
L. Dong, L. Berti-Equille, and D. Srivastavas.
2009a.
Integrating conflicting data: The role of sourcedependence.
In Proc.
2009 Int.
Conf.
Very Large Data Bases (VLDB?09), Lyon, France, Aug.X.
L. Dong, L. Berti-Equille, and D. Srivastavas.
2009b.
Truth discovery and copying detection in a dynamicworld.
In Proc.
2009 Int.
Conf.
Very Large Data Bases (VLDB?09), Lyon, France, Aug.A.
Galland, S. Abiteboul, A. Marian, and P. Senellart.
2010.
Corroborating information from disagreeing views.In Proc.
ACM Int.
Conf.
on Web Search and Data Mining (WSDM?10), New York, NY, Feb.L.
Ge, J. Gao, X. Yu, W. Fan, and A. Zhang.
2012.
Estimating local information trustworthiness via multi-source joint matrix factorization.
In Data Mining (ICDM), 2012 IEEE 12th International Conference on, pages876?881.
IEEE.1577H.
Ji, R. Grishman, H. T. Dang, K. Griffitt, and J. Ellis.
2010.
An overview of the tac2010 knowledge basepopulation track.
In Proc.
Text Analytics Conf.
(TAC?10), Gaithersburg, Maryland, Nov.H.
Ji, R. Grishman, and H.T.
Dang.
2011.
Overview of the tac 2011 knowledge base population track.
In TextAnalysis Conf.
(TAC) 2011.X.
Li and R. Grishman.
2013.
Confidence estimation for knowledge base population.
In Proc.
Recent Advancesin Natural Language Processing (RANLP).Q.
Li and H. Ji.
2014.
Incremental joint extraction of entity mentions and relations.Q.
Li, H. Ji, and L. Huang.
2013.
Joint event extraction via structured prediction with global features.M.
D. Marneffe, B. Maccartney, and C. D. Manning.
2006.
Generating typed dependency parses from phrasestructure parses.
In LREC, pages 449,454.R.
Mihalcea.
2004.
Graph-based ranking algorithms for sentence extraction, applied to text summarization.
InProc.
ACL2004.M.
Mintz, S. Bills, R. Snow, and D. Jurafsky.
2009.
Distant supervision for relation extraction without labeleddata.
In Proc.
ACL2009.J.
Pasternack and D. Roth.
2010.
Knowing what to believe (when you already know something).
InProceedings of the 23rd International Conference on Computational Linguistics, pages 877?885.
Associationfor Computational Linguistics.J.
Pasternack and D. Roth.
2011.
Making better informed trust decisions with generalized fact-finding.
In Proc.2011 Int.
Joint Conf.
on Artificial Intelligence (IJCAI?11), Barcelona, Spain, July.J.
Pasternack and D. Roth.
2013.
Latent credibility analysis.
In Proc.
WWW 2013.E.
Peserico and L. Pretto.
2009.
Score and rank convergence of hits.
In Proceedings of the 32nd internationalACM SIGIR conference on Research and development in information retrieval, pages 770?771.
ACM.Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum.
2007.
Yago: A Core of Semantic Knowledge.
In16th international World Wide Web conference (WWW 2007), New York, NY, USA.
ACM Press.S.
Tamang and H. Ji.
2011.
Adding smarter systems instead of human annotators: Re-ranking for slot fillingsystem combination.
In Proc.
CIKM2011 Workshop on Search & Mining Entity-Relationship data, Glasgow,Scotland, UK, Oct.VG Vydiswaran, C.X.
Zhai, and D. Roth.
2011.
Content-driven trust propagation framework.
In Proceedingsof the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 974?982.ACM.D.
Wang, L. Kaplan, H. Le, and T. Abdelzaher.
2012.
On truth discovery in social sensing: A maximum likelihoodestimation approach.
In Proc.
ACM/IEEE Int.
Conf.
on Information Processing in Sensor Networks (IPSN?12),pages 233?244, Beijing, China, April.X.
Yin and W. Tan.
2011.
Semi-supervised truth discovery.
In Proc.
2011 Int.
World Wide Web Conf.
(WWW?11),Hyderabad, India, March.X.
Yin, J. Han, and P. S. Yu.
2008.
Truth discovery with multiple conflicting information providers on the Web.IEEE Trans.
Knowledge and Data Engineering, 20:796?808.B.
Zhao, B. I. P. Rubinstein, J. Gemmell, and J. Han.
2012.
A Bayesian approach to discovering truth fromconflicting sources for data integration.
In Proc.
2012 Int.
Conf.
Very Large Data Bases (VLDB?12), Istanbul,Turkey, Aug.1578
