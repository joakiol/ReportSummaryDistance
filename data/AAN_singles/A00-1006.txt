Translation using Information on Dialogue ParticipantsSetsuo Yamada, E i i ch i ro  Sumi ta  and  H idek i  KashiokaATR Interpreting Telecommunications Research Laboratories*2-2, Hikaridai, Seika-cho, Soraku-gun,Kyoto, 619-0288, JAPAN{ syamada, sumita, kashioka} @itl.atr.co.jp tAbstractThis paper proposes a way to improve the trans-lation quality by using information on dialogueparticipants that is easily obtained from out-side the translation component.
We incorpo-rated information on participants' ocial rolesand genders into transfer ules and dictionaryentries.
An experiment with 23 unseen dia-logues demonstrated a recall of 65% and a preci-sion of 86%.
These results howed that our sim-ple and easy-to-implement method is effective,and is a key technology enabling smooth con-versation with a dialogue translation system.1 I n t roduct ionRecently, various dialogue translation systemshave been proposed (Bub and others, 1997;Kurematsu and Morimoto, 1996; Rayner andCarter, 1997; Ros~ and Levin, 1998; Sumitaand others, 1999; Yang and Park, 1997; Vi-dal, 1997).
If we want to make a conversationproceed smoothly using these translation sys-tems, it is important o use not only linguis-tic information, which comes from the sourcelanguage, but also extra-linguistic nformation,which does not come from the source language,but, is shared between the participants of theconversation.Several dialogue translation methods thatuse extra-linguistic information have been pro-posed.
Horiguchi outlined how "spoken lan-guage pragmatic information" can be trans-lated (Horiguchi, 1997).
However, she did notapply this idea to a dialogue translation system.LuperFoy et al proposed a software architec-*Current affiliation is ATR Spoken Language Trans-lation Research LaboratoriesCurrent mail addresses are{ setsuo.yarnada, eiichiro.sumita, hideki.kashioka}@slt.
atr.
co.jpture that uses '% pragmatic adaptation" (Lu-perFoy and others, 1998), and Mima et al pro-posed a method that uses "situational informa-tion" (Mima and others, 1997).
LuperFoy et alsimulated their method on man-machine inter-faces and Mima et al preliminarily evaluatedtheir method.
Neither study, however, appliedits proposals to an actual dialogue translationsystem.The above mentioned methods will need timeto work in practice, since it is hard to obtainthe extra-linguistic nformation on which theydepend.We have been paying special attention to "po-liteness," because a lack of politeness can inter-fere with a smooth conversation between twoparticipants, uch as a clerk and a customer.
Itis easy for a dialogue translation system to knowwhich participant is the clerk and which is thecustomer from the interface (such as the wiresto the microphones).This paper describes a method of "polite-ness" selection according to a participant's so-cial role (a clerk or a customer), which is eas-ily obtained from the extra-linguistic environ-ment.
We incorporated each participant's so-cial role into transfer ules and transfer dictio-nary entries.
We then conducted an experimentwith 23 unseen dialogues (344 utterances).
Ourmethod achieved a recall of 65% and a preci-sion of 86%.
These rates could be improved to86% and 96%, respectively (see Section 4).
Itis therefore possible to use a "participant's so-cial role" (a clerk or a customer in this case)to appropriately make the translation results"polite," and to make the conversation proceedsmoothly with a dialogue translation system.Section 2 analyzes the relationship between aparticular participant's social role (a clerk) andpoliteness in Japanese.
Section 3 describes ourproposal in detail using an English-to-Japanese37translation system.
Section 4 shows an exper-iment and results, followed by a discussion inSection 5.
Finally, Section 6 concludes this pa-per.2 A Par t i c ipant ' s  Soc ia l  Ro le  andPo l i tenessThis section focuses on one participant's socialrole.
We investigated Japanese outputs of a di-alogue translation system to see how many ut-terances hould be polite expressions in a cur-rent translation system for travel arrangement.We input 1,409 clerk utterances into a TransferDriven Machine Translation system (Sumitaand others, 1999) (TDMT for short).
The in-puts were closed utterances, meaning the sys-tem already knew the utterances, enabling theutterances to be transferred at a good quality.Therefore, we used closed utterances as the in-puts to avoid translation errors.As a result, it was shown that about 70%(952) of all utterances should be improved to usepolite expressions.
This result shows that a cur-rent translation system is not enough to makea conversation smoothly.
Not surprisingly, if allexpressions were polite, some Japanese speakerswould feel insulted.
Therefore, Japanese speak-ers do not have to use polite expression in allutterances.We classified the investigated ata into dif-ferent ypes of English expressions for Japanesepoliteness, i.e., into honorific titles, parts ofspeech such as verbs, and canned phrases,as shown in Table 1; however, not all typesappeared in the data.
For example, whenthe clerk said "How will you be paying, Mr.Suzuki," the Japanese translation was madepolite as "donoyouni oshiharaininarimasu-kasuzuki-sama" in place of the standard expres-sion "donoyouni shiharaimasu-ka suzuki-san.
"Table 1 shows that there is a difference inhow expressions should be made more polite ac-cording to the type, and that many polite ex-pressions can be translated by using only localinformation, i.e., transfer rules and dictionaryentries.
In the next section, we describe how toincorporate the information on dialogue partic-ipants, such as roles and genders, into transferrules and dictionary entries in a dialogue trans-lation system.3 A Method  of  Us ing  In fo rmat ionon  D ia logue  Par t i c ipantsThis section describes how to use informationon dialogue participants, such as participants'social roles and genders.
First, we describeTDMT, which we also used in our experiment.Second, we mention how to modify transferrules and transfer dictionary entries accordingto information on dialogue participants.3.1 Transfer  Dr iven  Mach ineTrans la t ionTDMT uses bottom-up left-to-right chart pars-ing with transfer rules as shown in Figure 1.The parsing determines the best structure andbest transferred result locally by performingstructural disambiguation using semantic dis-tance calculations, in parallel with the deriva-tion of possible structures.
The semantic dis-tance is defined by a thesaurus.
(source pattern)==~J ((target pattern 1)((source xample 1)(source xample 2)?
"- )(target pattern 2)?o* )Figure 1: Transfer ule formatA transfer ule consists of a source pattern,a target pattern, and a source example.
Thesource pattern consists of variables and con-stituent boundaries (Furuse and Iida, 1996).A constituent boundary is either a functionalword or the part-of-speech of a left constituent'slast word and the part-of-speech of a right con-stituent's first word.
In Example (1), the con-stituent boundary IV-CN) is inserted between"accept" and "payment," because "accept" isa Verb and "payment" is a Common Noun.The target pattern consists of variables that cor-respond to variables in the source pattern andwords of the target language.
The source exam-ple consists of words that come from utterancesreferred to when a person creates transfer ules(we call such utterances closed utterances).Figure 2 shows a transfer ule whose sourcepattern is (X (V-CN) Y).
Variable X corre-sponds to x, which is used in the target pat-tern, and Y corresponds to y, which is also38Table 1: Examples of polite expressionsType: verb, titleEng: How will you be paying, Mr. SuzukiStandard: donoyouni shiharaimasu-ka suzuki-sanPolite: donoyouni o_shiharaininarimasu-ka suzuki-samaGloss: How pay-QUESTION suzuki-Mr.Type: verb, common nounEng: We have two types of rooms availableStandard: aiteiru ni-shurui-no heya-ga ariraasuPolite: aiteiru ni-shurui-no oheya-ga gozaimasuGloss: available two-types-of room-TOP haveType: auxiliary verbEng: You can shop for hoursStandard: suujikan kaimono-wo surukotogadekimasuPolite: suujikan kaimono-wo shiteitadakemasuGloss: for hours make-OBJ canType: pronounEng: Your room number, pleaseStandard: anatano heya bangou-woPolite: okyakusamano heya bangou-woGloss: Your room number-so objonegaishirnasuonegaishimasupleaseType: canned phraseEng: How can I help youStandard: dou shimashitakaPolite: douitta goyoukendeshoukaGloss: How can I help youExample (1)Eng: We accept payment by credit cardStandard: watashitachi-wa kurejitlo-kaado-deno shiharai-wo ukelsukemasuPolite: watashidomo-wa kurejitto-kaado-deno o_shiharai-wo ukeshimasuGloss: We-TOP credit-card-by payment-OBJ acceptused in the target pattern.
The source exam-ple (("accept") ("payment")) comes from Ex-ample (1), and the other source examples comefrom the other closed utterances.
This transferrule means that if the source pattern is (X (V-CN) Y) then (y "wo" x) or (y "ni" x) is selectedas the target pattern, where an input word paircorresponding to X and Y is semantically themost similar in a thesaurus to, or exactly thesame as, the source example.
For example, ifan input word pair corresponding to X and Yis semantically the most similar in a thesaurusto, or exactly the same as, (("accept") ("pay-ment")), then the target pattern (y "wo" x) isselected in Figure 2.
As a result, an appropriatetarget pattern is selected.After a target pattern is selected, TDMT cre-ates a target structure according to the pattern(X (V-CN) Y)((y "wo" x)((("accept") ("payment"))(("take") ("picture")))(y "hi" x)((("take") ("bus"))(("get") ("sunstroke"))))Figure 2: Transfer ule exampleby referring to a transfer dictionary, as shownin Figure 3.
If the input is "accept (V -CN)payment," then this part is translated into "shi-harai wo uketsukeru."
"wo" is derived from thetarget pattern (y "wo" x), and "shiharai" and"uketsukeru" are derived from the transfer dic-tionary, as shown in Figure 4.39(source pattern)(((target pattern 11) :pattern-cond 11(target pattern 12) :pattern-cond 12itarget pattern In) :default)((source xample 1)?
oo )(((source xample 1) ~ (target word lt) :word-cond 11(source example 1) --* (target word 12) :word-cond 12??
.
(source example 1) --* (target word lm) :default)o . "
)(((target pattern 21) :pattern-cond 21. .
.  )
) )Figure 5: Transfer ule format with information on dialogue participants(((source word 1) --* (target word 11) :cond 11 I(source word 1) -* (target word 12) :cond 12 II .
.
.
(source word 1) -~ (target word lk) :default)\[o*.  )
IFigure 6: Dictionary format with information on dialogue participants((source word) ~ (target word)? "
.
)Figure 3: Transfer dictionary format(("accept") --* ("uketsukeru') I ("payment") --* ("shiharai"))Figure 4: Transfer dictionary example(X "sama")((("Mr." x) :h-gender male("Ms." x) :h-gender female("Mr-ms." x))(("room number"))))Figure 7: Transfer ule example with the par-ticipant's gender3.2 Transfer Rules and Entr iesaccording to Information onDialogue Part ic ipantsFor this research, we modified the transfer ulesand the transfer dictionary entries, as shown inFigures 5 and 6.
In Figure 5, the target pattern"target pattern 11" and the source word "sourceexample 1" are used to change the translationaccording to information on dialogue partici-pants.
For example, if ":pattern-cond 11" is de-fined as ":h-gender male" as shown in Figure 7,then "target pattern 11" is selected when thehearer is a male, that is, "("Mr." x)" is selected.Moreover, if ":word-cond 11" is defined as ":s-role clerk" as shown in Figure 8, then "sourceexample 1" is translated into "target word 11"when the speaker is a clerk, that is, "accept" istranslated into "oukesuru."
Translations uchas "target word 11" are valid only in the sourcepattern; that is, a source example might notalways be translated into one of these targetwords.
If we always want to produce transla-tions according to information on dialogue par-ticipants, then we need to modify the entriesin the transfer dictionary like Figure 6 shows.Conversely, if we do not want to always changethe translation, then we should not modify theentries but modify the transfer ules.
Severalconditions can also be given to ":word-cond"and ":pattern-cond."
For example, ":s-role cus-tomer and :s-gender female," which means thespeaker is a customer and a female, can begiven.
In Figure 5, ":default" means the de-40fault target pattern or word if no condition ismatched.
The condition is checked from up todown in order; that is, first, ":pattern-cond 11,"second, ":pattern-cond 1~," ... and so on.
(X (V-CN) Y)((y "wo" x)((("accept") ("payment"))(("take") ("picture")))((("accept") -~ ("oukesuru"):s-role clerk( "accept" ) --+ ( "uketsukeru" ) )))Figure 8: Transfer ule example with a partici-pant's role((("payment") --~ ("oshiharai") :s-role clerk( "payment" ) ---* ( "shiharai" ))(("we") --* ("watashidomo") :s-role clerk("we") --~ ("watashltachi")))Figure 9: Transfer dictionary example with aspeaker's roleEven though we do not have rules and en-tries for pattern conditions and word condi-tions according to another participant's infor-mation, such as ":s-role customer'(which meansthe speaker's role is a customer) and ":s-gendermale" (which means the speaker's gender ismale), TDMT can translate xpressions corre-sponding to this information too.
For example,"Very good, please let me confirm them" willbe translated into "shouchiitashimasita kakuninsasete itadakimasu" when the speaker is a clerkor "soredekekkoudesu kakunin sasete kudasai"when the speaker is a customer, as shown inExample (2).By making a rule and an entry like the ex-amples shown in Figures 8 and 9, the utter-ance of Example (1) will be translated into"watashidomo wa kurejitto kaado deno oshi-harai wo oukeshimasu" when the speaker is aclerk.4 An  Exper imentThe TDMT system for English-to-Japanese atthe time Of the experiment had about 1,500transfer ules and 8,000 transfer dictionary en-tries.
In other words, this TDMT system wascapable of translating 8,000 English words intoJapanese words.
About 300 transfer ules and40 transfer dictionary entries were modified toimprove the level of "politeness.
"We conducted an experiment using the trans-fer rules and transfer dictionary for a clerk with23 unseen dialogues (344 utterances).
Our inputwas off-line, i.e., a transcription of dialogues,which was encoded with the participant's socialrole.
In the on-line situation, our system cannot infer whether the participant's social role isa clerk or a customer, but can instead eterminethe role without error from the interface (suchas a microphone or a button).In order to evaluate the experiment, we clas-sifted the Japanese translation results obtainedfor the 23 unseen dialogues (199 utterances froma clerk, and 145 utterances from a customer,making 344 utterances in total) into two types:expressions that had to be changed to more po-lite expressions, and expressions that did not.Table 2 shows the number of utterances that in-cluded an expression which had to be changedinto a more polite one (indicated by "Yes") andthose that did not (indicated by "No").
We ne-glected 74 utterances whose translations weretoo poor to judge whether to assign a "Yes" or"No.
"Table 2: The number of utterances to bechanged or notNecessity | The numberof change I of utterancesYes 104No 166Out of scope 74Total \[ 344* 74 translations were too poor to handle for the"politeness" problem, and so they are ignored in thispaper.The translation results were evaluated to seewhether the impressions of the translated re-sults were improved or not with/without mod-ification for the clerk from the viewpoint of"politeness."
Table 3 shows the impressionsobtained according to the necessity of changeshown in Table 2.The evaluation criteria are recall and preci-sion, which are defined as follows:Recall =number of utterances whose impression is betternumber of utterances which should be more polite41Example (2)Eng: Very good, please let me confirm themStandard: wakarimasita kakunin saseteClerk: shouchiitashimasita kakunin sase~eCustomer: soredekekkoudesu kakunin saseteGloss: very good con:firm let mekudasaiitadakimasukudasaipleaseTable 3: Evaluation on using the speaker's roleNecessityof changeYes(lo4)No(166)~ Impressionbettersameworseno-diffbetters alTleworseno-diffThe numberof utterances685328030163bet ter :  Impression of a translation is better.same:  Impression of a translation has not changed.worse: Impression of a translation is worse.no-diff: There is no difference between the twotranslations.Precision =number of utterances whose impression is betternumber of utterances whose expression has beenchanged by the modified rules and entriesThe recall was 65% (= 68 - (68 + 5 + 3 + 28))and the precision was 86% (= 68 -: (68 + 5 + 3 +0+3+0)).There are two main reasons which bring downthese rates.
One reason is that TDMT does notknow who or what the agent of the action inthe utterance is; agents are also needed to se-lect polite expressions.
The other reason is thatthere are not enough rules and transfer dictio-nary entries for the clerk.It is easier to take care of the latter problemthan the former problem.
If we resolve the lat-ter problem, that is, if we expand the transferrules and the transfer dictionary entries accord-ing to the "participant's social role" (a clerk anda customer), then the recall rate and the preci-sion rate can be improved (to 86% and 96%,respectively, as we have found).
As a result, wecan say that our method is effective for smoothconversation with a dialogue translation system.5 D iscuss ionIn general, extra-linguistic information is hardto obtain.
However, some extra-linguistic infor-mation can be easily obtained:(1) One piece of information is the participant'ssocial role, which can be obtained from the in-terface such as the microphone used.
It wasproven that a clerk and customer as the socialroles of participants are useful for translationinto Japanese.
However, more research is re-quired on another participant's social role.
(2) Another piece of information is the par-ticipant's gender, which can be obtained by aspeech recognizer with high accuracy (Takezawaand others, 1998; Naito and others, 1998).
Wehave considered how expressions can be usefulby using the hearer's gender for Japanese-to-English translation.Let us consider the Japanese honorific title"sama" or "san."
If the heater's gender is male,then it should be translated "Mr." and if thehearer's gender is female, then it should betranslated "Ms." as shown in Figure 7.
Ad-ditionally, the participant's gender is useful fortranslating typical expressions for males or fe-males.
For example, Japanese "wa" is often at-tached at the end of the utterance by females.It is also important for a dialogue translationsystem to use extra-linguistic information whichthe system can obtain easily, in order to makea conversation proceed smoothly and comfort-ably for humans using the translation system.We expect hat other pieces of usable informa-tion can be easily obtained in the future.
Forexample, age might be obtained from a cellulartelephone if it were always carried by the sameperson and provided with personal information.In this case, if the system knew the hearer was achild, it could change complex expressions intoeasier ones.6 Conc lus ionWe have proposed a method of translation us-ing information on dialogue participants, which42is easily obtained from outside the translationcomponent, and applied it to a dialogue trans-lation system for travel arrangement.
Thismethod can select a polite expression for anutterance according to the "participant's socialrole," which is easily determined by the inter-face (such as the wires to the microphones).
Forexample, if the microphone is for the clerk (thespeaker is a clerk), then the dialogue translationsystem can select a more polite expression.In an English-to-Japanese translation system,we added additional transfer ules and transferdictionary entries for the clerk to be more po-lite than the customer.
Then, we conducted anexperiment with 23 unseen dialogues (344 ut-terances).
We evaluated the translation resultsto see whether the impressions of the results im-proved or not.
Our method achieved a recall of65% and a precision of 86%.
These rates couldeasily be improved to 86% and 96%, respec-tively.
Therefore, we can say that our methodis effective for smooth conversation with a dia-logue translation system.Our proposal has a limitation in that if thesystem does not know who or what the agentof an action in an utterance is, it cannot ap-propriately select a polite expression.
We areconsidering ways to enable identification of theagent of an action in an utterance and to ex-pand the current framework to improve the levelof politeness even more.
In addition, we intendto apply other extra-linguistic nformation to adialogue translation system.ReferencesThomas Bub et al 1997.
Verbmobih Thecombination of deep and shallow processingfor spontaneous speech translation.
In the1997 International Conference on Acoustics,Speech, and Signal Processing: ICASSP 97,pages 71-74, Munich.Osamu Furuse and Hitoshi Iida.
1996.
In-cremental translation utilizing constituentboundary patterns.
In Proceedings ofCOLING-96, pages 412-417, Copenhagen.Keiko Horiguchi.
1997.
Towards translatingspoken language pragmatics in an analogicalframework.
In Proceedings ofA CL/EA CL-97workshop on Spoken Language Translation,pages 16-23, Madrid.Akira Kurematsu and Tsuyoshi Morimoto.1996.
Automatic Speech Translation.
Gordonand Breach Publishers.Susann LuperFoy et al 1998.
An architecturefor dialogue management, context tracking,and pragmatic adaptation i  spoken dialoguesystem.
In Proceedings of COLING-A CL'98,pages 794-801, Montreal.Hideki Mima et al 1997.
A situation-basedapproach to spoken dialogue translation be-tween different social roles.
In Proceedings ofTMI-97, pages 176-183, Santa Fe.Masaki Naito et al 1998.
Acoustic and lan-guage model for speech translation systemATR-MATRIX.
In the Proceedings of the1998 Spring Meeting of the Acoustical Soci-ety of Japan, pages 159-160 (in Japanese).Manny Rayner and David Carter.
1997.
Hy-brid language processing in the spoken lan-guage translator.
In the 1997 InternationalConference on Acoustics, Speech, and SignalProcessing: ICASSP 97, pages 107-110, Mu-nich.Carolyn Penstein Ros~ and Lori S. Levin.
1998.An interactive domain independent approachto robust dialogue interpretation.
In Proceed-ings of COLING-ACL'98, pages 1129-1135,Montreal.Eiichiro Sumita et al 1999.
Solutions to prob-lems inherent in spoken-language translation:The ATR-MATRIX approach.
In the Ma-chine Translation Summit VII, pages 229-235, Singapore.Toshiyuki Takezawa et al 1998.
A Japanese-to-English speech translation system: ATR-MATRIX.
In the 5th International Con-ference On Spoken Language Processing:ICSLP-98, pages 2779-2782, Sydney.Enrique Vidal.
1997.
Finite-state speech-to-speech translation.
In the 1997 InternationalConference on Acoustics, Speech, and SignalProcessing: ICASSP 97, pages 111-114, Mu-nich.Jae-Woo Yang and Jun Park.
1997.
An exper-iment on Korean-to-English and Korean-to-Japanese spoken language translation.
In the1997 International Conference on Acoustics,Speech, and Signal Processing: ICASSP 97,pages 87-90, Munich.43
