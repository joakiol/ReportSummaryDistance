Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 24?32,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsRobust and Efficient Page Rank for Word Sense DisambiguationDiego De Cao, Roberto Basili, Matteo Luciani, Francesco Mesiano, Riccardo RossiDept.
of Computer Science,University of Roma Tor Vergata, Roma, Italy{decao,basili}@info.uniroma2.it{matteo.lcn,fra.mesiano,ricc.rossi}@gmail.comAbstractGraph-based methods that are en voguein the social network analysis area, suchas centrality models, have been recentlyapplied to linguistic knowledge bases, in-cluding unsupervised Word Sense Disam-biguation.
Although the achievable accu-racy is rather high, the main drawback ofthese methods is the high computationaldemanding whenever applied to the largescale sense repositories.
In this paperan adaptation of the PageRank algorithmrecently proposed for Word Sense Dis-ambiguation is presented that preservesthe reachable accuracy while significantlyreducing the requested processing time.Experimental analysis over well-knownbenchmarks will be presented in the paperand the results confirm our hypothesis.1 IntroductionLexical ambiguity is a fundamental aspect of natu-ral language.
Word Sense Disambiguation (WSD)investigates methods to automatically determinethe intended sense of a word in a given contextaccording to a predefined set of sense definitions,provided by a semantic lexicon.
Intuitively, WSDcan be usefully exploited in a variety of NLP (e.g.Machine Translation (Chan et al, 2007; Carpuatand Wu, 2007)) and Information Retrieval taskssuch as ad hoc retrieval (Krovetz, 1997; Kim etal., 2004) or Question Answering (Beale et al,2004).
However controversial results have beenoften obtained, as for example the study on textclassification reported in (Moschitti and Basili,2004).
The impact of WSD on IR tasks is still anopen issue and large scale assessment is needed.For this reason, unsupervised approaches to in-ductive WSD are appealing.
In contrast with su-pervised methods that strongly rely on manuallylabeled data sets, those methods do not require an-notated examples for all words and can thus sup-port realistic (large scale) benchmarks, as neededin IR research.In recent years different approaches to WordSense Disambiguation task have been evaluatedthrough comparative campaigns, such as the ear-lier Senseval evaluation exercises.
(Palmer et al,2001; Snyder and Palmer, 2004) or the most recent(Pradhan et al, 2007).The best accuracy is reached by WSD based onsupervised methods that exploit large amounts ofhand-tagged data to train discriminative or gen-erative disambiguation models.
The common al-ternative to supervised systems are knowledge-based WSD systems that try to exploit informa-tion made available by large Lexical KnowledgeBases (LKB).
They enable the definition of sev-eral metrics to estimate semantic similarity (e.g.
(Lesk, 1986) or (Agirre and Rigau, 1996), (Basiliet al, 2004) methods) and then use it to rank thealternative senses according to the incoming con-text.
Moreover they make available large relation-ship sets between pairs of lexical meaning units,such as synonymy, hyponymy or meronymy.
Theresulting networks represent at various grains anddegrees of approximation models of the mentallexicons.
It is not by chance that early researchon WSD based on semantic dictionaries were ap-plying models of network activation processes (inparticular simulated annealing as in (Cowie et al,1992)) for precise and fast disambiguation.It has been more recently that graph-basedmethods for knowledge-based WSD have gainedmuch attention in the NLP community ((Sinhaand Mihalcea, 2007), (Navigli and Lapata, 2007),(Agirre and Soroa, 2008), (Agirre and Soroa,2009)).
In these methods a graph representa-tion for senses (nodes) and relation (edges) is firstbuilt.
Then graph-based techniques that are sen-sible to the structural properties of the graph areused to find the best senses for words in the in-coming contexts.
The relation employed by thedifferent methods are of several types such as syn-onymy, antonymy but also co-occurrence basedlexical similarity computed externally over a cor-pus.
These give rise to real-valued weights thatdetermine large weighted directed graphs.
Usu-24ally, the employed disambiguation is carried outby ranking the graph nodes.
Thus the conceptswith highest ranks are assigned to the correspond-ing words.
In (Agirre and Soroa, 2009), a com-parative analysis of different graph-based mod-els over two well known WSD benchmarks is re-ported.
In the paper two variants of the randomsurfer model as defined by PageRank model (Brinand Page, 1998) are analyzed.
A special emphasisfor the resulting computational efficiency is alsoposed there.
In particular, a variant called Per-sonalized PageRank (PPR) is proposed (Agirreand Soroa, 2009) that tries to trade-off betweenthe amount of the employed lexical informationand the overall efficiency.
In synthesis, along theideas of the Topic sensitive PageRank (Haveli-wala, 2002), PPR suggests that a proper initial-ization of the teleporting vector ~p suitably capturesthe context information useful to drive the randomsurfer PageRank model over the graph to convergetowards the proper senses in fewer steps.
The ba-sic idea behind the adoption of PPR is to imposea personalized vector that expresses the contextsof all words targeted by the disambiguation.
Thismethod improves on the complexity of the previ-ously presented methods (e.g.
(Agirre and Soroa,2008)) as it allows to contextualize the behaviorsof PageRank over a sentence, without asking fora different graph: in this way the WordNet graphis always adopted, in a word or sentence orientedfashion.
Moreover, it is possible to avoid to rebuilda graph for each target word, as the entire sen-tence can be coded into the personalization vector.In (Agirre and Soroa, 2009), a possible, and moreaccurate alternative, is also presented called PPRword2word (PPRw2w) where a different person-alization vector is used for each word in a sen-tence.
Although clearly less efficient in terms oftime complexity, this approach guarantees the bestaccuracy, so that it can be considered the state-of-the art in unsupervised WSD.In this paper a different approach to personal-ization of the PageRank is presented, aiming atpreserving the suitable efficiency of the sentenceoriented PPR algorithm for WSD but achievingan accuracy at least as high as the PPRw2w one.We propose to use distributional evidence that canbe automatically acquired from a corpus to definethe topical information encoded by the personal-ization vector, in order to amplify the bias on theresulting PPR and improve the performance ofthe sentence oriented version.
The intuition is thatdistributional evidence is able to cover the gap be-tween word oriented usages of the PPR as for thePPRw2w defined in (Agirre and Soroa, 2009),and its sentence oriented counterpart.
In this waywe can preserve higher accuracy levels while lim-iting the number of PageRank runs, i.e.
increasingefficiency.The paper is structured as follows.
We first givea more detailed overview of the PageRank andPersonalized PageRank algorithms in Section 2.In Section, 3 a description of our distributional ap-proach to the personalized PageRank is provided.A comparative evaluation with respect to previousworks is then reported in Section 4 while section 5is left for conclusions.2 Graph-based methods for Word SenseDisambiguationWord sense disambiguation algorithms in theclass of graph-based method are unsupervised ap-proaches to WSD that rely almost exclusively onthe lexical KB graph structure for inferring the rel-evance of word senses for a given context.
Muchcurrent work in WSD assume that meaning dis-tinctions are provided by a reference lexicon (theLKB), which encodes a discrete set of sensesfor each individual word.
Although the largelyadopted reference resource is WordNet (Miller etal., 1990), the graph-based algorithms are not lim-ited to this particular lexicon.
In these methods,nodes are derived from the sense units, i.e.
thesynsets, and edges are derived from semantic re-lations established between synsets.
We will here-after use WordNet to discuss the details of the dif-ferent steps.
Every algorithm can be decomposedin a set of general steps:Building the graph.
The first step proceedsto the definition of the graph structure.
As in-troduced before, WordNet is mapped into a graphwhose nodes are concepts (represented by synsets(i.e., synonym sets)) and whose edges are seman-tic relations between concepts (e.g., hyperonymy,meronymy).
For each sentence, a graph G =(V,E) is built, which is derived from the entiregraph of the reference lexicon.
More formally,given a sentence ?
= w1, w2, .
.
.
, wn, where wiis a word, the following steps are executed tobuild G: (1) the sense vocabulary V?
is derivedas V?
:=?ni=1 Senses(wi), where Senses(wi)is the set of senses of any of the wi of the sen-25tence.
(2) For each node v ?
V?, a visit of theWordNet graph is performed: every time a nodev?
?
V?(v?
6= v) is encountered along a pathv ?
v1 ?
.
.
.
?
vk ?
v?
all intermedi-ate nodes and edges on the path from v to v?
areadded to the graph: V := V?
{v1, .
.
.
, vk} andE := E?
{(v, v1), .
.
.
, (vk, v?)}.
The constructedgraph is the subgraph covering the nodes and rela-tions of all the relevant vocabulary in the sentence.Sense Ranking.
The derived graph is then usedwith different ranking models to find the correctsenses of words into the sentence ?.
A suitable in-terpretation of the source sentence can be in factobtained by ranking each vertex in the graph Gaccording its centrality.
In (Navigli and Lapata,2007) different ranking models are described.
Thespecific algorithm presented in (Agirre and Soroa,2008) is the major inspiration of the present pa-per, and makes use of PageRank (Brin and Page,1998) to rank edges in the graph G. PageRanktries to separate these nodes from the other candi-date synsets of words in ?, which are expected toactivate less relations on average and remain iso-lated.
Let the vector ~Rank express the probabilityto reach any of the vertices V?, and letM representthe edge information.
The expected rank betweensenses satisfies:~Rank = (1?
?
)M ?
~Rank + ?~p (1)whereas 0 ?
?
?
1. ?
is called the dampingfactor.
It models the amount of likelihood thata generic Web surfer, standing at a vertex, ran-domly follows a link from this vertex toward anyother vertex in the graph: the uniform probabilitypi = 1N ?i, is assigned to each one of the N ver-tices in G. While it guarantees the convergence ofthe algorithm, it expresses the trade-off betweenthe probability of following links provided by theWeb graph and the freedom to violate them.
Aninteresting aspect of the ranking process is the ini-tial state.
Many algorithms (as well as the one pro-posed by (Agirre and Soroa, 2009)) initialize theranks of the vertex at a uniform value (usually 1/Nfor a graph with N vertices).
Then Equation 1 isiterated until convergence is achieved or a maxi-mum fix number of iterations has been reached.Disambiguation.
Finally, the disambiguationstep is performed by assigning to each word wi inthe source sentence ?, the associated j-th conceptsenseij (i.e.
the j-th valid interpretation for wi)associated to the maximum resulting rank.
In caseof ties all the concepts with maximum rank are as-signed to wi ?
?.The above process has several sources of com-plexity, but the major burden is related to the Senseranking step.
While complex methods have beenproposed (as discussed in (Navigli and Lapata,2007)), sentence oriented algorithms, that buildthe graph G once per each sentence ?, whateverthe number of wi ?
?
is, are much more efficient.The problem is twofold:?
How different sentences can be targeted with-out major changes in the graph G?
How thematrix M can be made as much reusable aspossible??
How to encode in Eq.
1 the incoming con-text in order to properly address the differentwords in the sentence ?
?In order to address the above problems, in linewith the notion of topic-sensitive PageRank, a per-sonalized PageRank approach has been recentlydevised (Agirre and Soroa, 2009) as discussed inthe next section.2.1 Personalizing PageRank for WSDIn (Agirre and Soroa, 2009), a novel use of PageR-ank for word sense disambiguation is presented.
Itaims to present an optimized version of the algo-rithm previously discussed in (Agirre and Soroa,2008).
The main difference concerns the methodused to initialize and use the graph G for disam-biguating a sentence with respect to the overallgraph (hereafter GKB) that represents the com-plete lexicon.Previous methods (such as (Agirre and Soroa,2008)) derive G as the subgraph of GKB whosevertices and edges are particularly relevant for thegiven input sentence ?.
Such a subgraph is oftencalled the disambiguation subgraph ?, GD(?
).GD is a subgraph of the original GKB, obtainedby computing the shortest paths between the con-cepts of the words co-occurring in the context.These are expected to capture most of the infor-mation relevant to the disambiguation (i.e.
senseranking) step.The alternative proposed in (Agirre and Soroa,2009) allows a more static use of the full LKB.Context words are newly introduced into the graphG as nodes, and linked with directed edges (i.e.the lexical relations) to their respective concepts(i.e.
synsets).
Topic-sensitive PageRank over thegraph G (Haveliwala, 2002) is then applied: theinitial probability mass is concentrated uniformly26over the newly introduced word nodes through thesetting of the personalization vector ~p in Eq.
1(Haveliwala, 2002).
Words are linked to the con-cepts by directed edges that act as sources to prop-agate probability into the GKB concepts they areassociated with.
A personalized PageRank vectoris finally produced that defines a measure of the(topological) relevance of the GKB nodes (con-cepts) activated by the input context.
The overalltime complexity is limited by the above sketchedPersonalized PageRank approach (PPR) as a sin-gle initialization of the graph GKB is requestedfor an entire target sentence.
This sentence ori-ented method reuses the GKB of the entire lexi-con, while the second step runs the sense rankingonce for all the words.
This method reduces thenumber of invocations of PageRank thus loweringthe average disambiguation time.A word oriented version of the algorithm isalso proposed in (Agirre and Soroa, 2009).
Itdefines different initializations for the differentwords wi ?
?
: these are obtained by setting theinitial probability mass in ~p to 0 for all the sensesSense(wi) of the targetedwi.
In this way, only thecontext words and not the target are used for thepersonalization step1.
This approach to the per-sonalized PageRank is termed word-by-word orPPRw2w version in (Agirre and Soroa, 2009).PPRw2w is run on the same graph but with ndifferent initializations where n is the number ofwords in ?.
Although less efficient, PPRw2w isshown to outperform the sentence oriented PPRmodel.3 A distributional extensionof PageRankThe key idea in (Agirre and Soroa, 2009) is toadapt the matrix initialization step in order to ex-ploit the available contextual evidence.
Notice thatpersonalization in Word Sense Disambiguationis inspired by the topic-sensitive PageRank ap-proach, proposed in (Haveliwala, 2002), for Websearch tasks.
It exploits a context dependent defi-nition of the vector ~p in Eq.
1 to influence the link-based sense ranking achievable over a sentence.Context is used as only words of the sentence(or words co-occurring with the target wi in thew2w method) are given non zero probability mass1This seems to let the algorithm to avoid strong biasestoward pairs of senses of a given word that may appear insome semantic relations (thus connected in the graph), thatwould be wrongly emphasized by the PPR method.in ~p: this provides a topical bias to PageRank.A variety of models of topical information havebeen proposed in IR (e.g.
(Landauer and Dumais,1997)) to generalize documents or shorter texts(e.g.
query).
They can be acquired through largescale corpus analysis in the so called distributionalapproaches to language modeling.
While contextscan be defined in different ways (e.g as the setof words surrounding a target word), their anal-ysis over large corpora has been shown to effec-tively capture topical and paradigmatic relations(Sahlgren, 2006).
We propose to use the topicalinformation about a sentence ?, acquired throughLatent Semantic Analysis (Landauer and Dumais,1997), as a source information for the initializa-tion of the vector ~p in the PPR (or PPRw2w)disambiguation methods.SVD usually improves the word similarity com-putation for three different reasons.
First, SVDtends to remove the random noise present in thesource matrix.
Second, it allows to discover thelatent meanings of a target word through the cor-pus, and to compute second-order relations amongtargets, thus improving the similarity computation.Third, similarities are computed in a lower dimen-sional space, thus speeding up the computation.For the above reasons by mapping a word, or asentence, in the corresponding Latent SemanticSpace, we can estimate the set of its similar wordsaccording to implicit semantic relations acquiredin an unsupervised fashion.
This can be profitablyused as a personalization model for PPR.For the WSD task, our aim is to exploit an ex-ternally acquired semantic space to expand the in-coming sentence ?
into a set of novel terms, dif-ferent but semantically related with the words in?.
In analogy with topic-driven PageRank, the useof these words as a seed for the iterative algorithmis expected to amplify the effect of local informa-tion (i.e.
?)
onto the recursive propagation acrossthe lexical network: the interplay of the global in-formation provided by the whole lexical networkwith the local information characterizing the ini-tialization lexicon is expected to maximize theirindependent effect.More formally, let the matrix Wk := UkSk bethe matrix that represents the lexicon in the k-dimensional LSA space.
Given an input sentence?, a vector representation?
?wi for each term wi in ?is made available.
The corresponding representa-tion of the sentence can be thus computed as the27linear combination through the original tf ?
idfscores of the corresponding ?
?wi: this provides al-ways an unique representation???
for the sentence.???
locates the sentence in the LSA space and theset of terms that are semantically related to thesentence ?
can be easily found in the neighbor-hood.
A lower bound can be imposed on the co-sine similarity scores over the vocabulary to com-pute the lexical expansion of ?, i.e.
the set of termsthat are enough similar to ???
in the k dimensionalspace.
Let D be the vocabulary of all terms, wedefine as the lexical expansion T (?)
?
D of???
asfollows:T (?)
= {wj ?
D : sim(?
?wj ,??? )
> ?}
(2)where ?
represents a real-valued threshold in theset [0, 1).
In order to improve precision it is alsopossible to impose a limit on the cardinality ofT (?)
and discard terms characterized by lowersimilarity factors.Let the t = |T (?
)| be the number of terms in theexpansion, we extend the original set ?
of terms inthe sentence, so that the new seed vocabulary is?
?
T (?)
= {w1, w2, .
.
.
, wn, wn+1, .
.
.
, wn+t}.The nodes in the graph G will be thus computedas V ext?
:=?n+ti=1 Senses(wi) and a new per-sonalization vector ~pext will then replace ~p in Eq.1: it will assign a probability mass to the wordsw1, ..., wn+t proportional to their similarity to ???
,i.e.pki =sim(??wi,???
)?n+tj=1 sim(?
?wj ,???
)?i = 1, ..., n+ t (3)whereas ki is the index of the node correspondingto the word wi in the graph.
Finally, the later stepsof the PPR methods remain unchanged, and thePageRank works over the corresponding graph Gare carried out as described in Section 2.4 Empirical EvaluationThe evaluation of the proposed model was focusedon two main aspects.
First we want to measurethe impact of the topical expansion at sentencelevel on the accuracy reachable by the personal-ized PageRank PPR.
This will be done also com-paratively with the state of the art of unsupervisedsystems over a consolidated benchmark, i.e.
Se-meval 2007.
In Table 1 a comparison betweenthe official Semeval 2007 results for unsupervisedmethods is reported.
Table 1 shows also the re-sults of the standard PPR methods over the Se-meval 2007 dataset.
Second, we want to analyzethe efficiency of the algorithm and its impact in asentence (i.e.
PPR) or word oriented (i.e.
w2w)perspective.
This will allow to asses its applicabil-ity to realistic tasks, such as query processing ordocument indexing.Experimental Set-up In order to measure ac-curacy, the Senseval 2007 coarse WSD dataset2(Navigli et al, 2007) has been employed.
It in-cludes 245 sentences for a total number of 2,269ambiguous words.
In line with the results reportedin (Agirre and Soroa, 2009), experiments againsttwo different WordNet versions, 1.7 and 3.0, havebeen carried out.
Notice that the best results in(Agirre and Soroa, 2009) were obtained over theenriched version of the LKB, i.e.
the combinationof WordNet and extra information supplied by ex-tended WordNet (Harabagiu and Moldovan, 1999).The adopted vector space has been acquiredover a significant subset of the BNC 2.0 corpus,made of 923k sentences.
The most frequent 200kwords (i.e.
the contextual features) were acquiredthrough LSA.
The corpus has been processed withthe LTH parser (Johansson and Nugues, 2007) toobtain POS tags for every token.
Moreover, a di-mensionality reduction factor of k = 100 was ap-plied.In subsection 4.1, a comparative analysis of theaccuracy achieved in the disambiguation task isdiscussed.
Subsection 4.2 presents a correspond-ing study of the execution times aiming to com-pare the relative efficiency of the methods andtheir application into a document semantic taggingtask.4.1 Comparative evaluation: accuracy on theSemeval ?07 dataThe approaches proposed in Semeval 2007 can bepartitioned into two major types.
The supervisedor semi-supervised approaches and the unsuper-vised ones that rely usually on WordNet.
As thebasic Page Rank as well as our LSA extensionmakes no use of sense labeled data, we will mainlyfocus on the comparative evaluation among unsu-pervised WSD systems.
In order to compare thequality of the proposed approach, the results of thepersonalized PageRank proposed in (Agirre andSoroa, 2009) over the same dataset are reported inTable 1 (The * systems, denoted by UKB).
As alsosuggested in (Agirre and Soroa, 2009) the best per-2The dataset is publicly available fromhttp://nlp.cs.swarthmore.edu/semeval/tasks/task07/data.shtml28System P R F1LSA UKB 1.7x 71.66 71.53 71.59UKB 1.7x * 71.38 71.13 71.26TKB-UO 70.21 70.21 70.21UKB 3.0g * 68.47 68.05 68.26LSA UKB 3.0g 67.02 66.73 66.87LSA UKB 1.7 66.96 65.66 66.31LSA UKB 3.0 66.60 65.31 65.95RACAI-SYNWSD 65.71 65.71 65.71UKB 3.0 * 63.29 61.92 62.60SUSSX-FR 71.73 52.23 60.44UKB 1.7 * 59.30 57.99 58.64UOFL 52.59 48.74 50.60SUSSX-C-WD 54.54 39.71 45.96SUSSX-CR 54.30 39.53 45.75Table 1: Official Results over the Semeval?07dataset.
The * systems was presented in (Agirreand Soroa, 2009).
The LSA UKB 1.7 andLSA UKB 3.0 show the rank of the model pro-posed in this paper.formances are obtained according to the PPRw2wword oriented approach.For sake of comparison we applied the LSA-based expansion to the Personalized Page Rank ina sentence oriented fashion (i.e., only one PageR-ank is run for all the target words of a sentence,PPR).
Notice that PPR models the context ofthe sentence with a single iterative run of PageR-ank, while PPRw2w disambiguates each wordwith a dedicated PageRank.
In line with (Agirreand Soroa, 2009), different types of WordNetgraphs are employed in our experiments:WN17 all hyponymy links between synsets of theWN1.7 dictionary are considered;WN17x all hyponymy links as well as the ex-tended 1.7 version of WordNet, whereas thesyntactically parsed glosses, are semanticallydisambiguated and connected to the corre-sponding synsets;WN3.0 all hyponymy links between synsets ofthe WN3.0 dictionary are considered;WN30g all hyponymy links as well as the ex-tended 3.0 version of WordNet, whereas thesyntactically parsed glosses, are semanticallydisambiguated and connected to the corre-sponding synsets;The impact of the LSA sentence expansiontechnique proposed in this paper on the differentinvolved resources, i.e.
WN1.7 to WN30g, hasbeen measured.
The 1.7 configuration providesPPR w2wModel Iter.
Prec Rec F1 Prec Rec F117 LSA1005 65.8 64.5 65.2 65.7 64.4 65.115 65.6 64.3 65.0 66.3 65.0 65.717 UKB5 60.9 59.7 60.3 65.3 63.8 64.515 61.3 60.1 60.7 61.6 60.2 60.917x LSA1005 71.5 71.4 71.5 71.1 71.0 71.115 71.5 71.4 71.4 71.6 71.5 71.517x UKB5 67.4 67.3 67.4 70.9 70.6 70.715 67.5 67.4 67.5 71.3 71.1 71.230 LSA1005 66.5 65.2 65.8 65.7 64.4 65.115 66.9 65.6 66.2 66.6 65.3 65.930 UKB5 61.7 60.5 61.1 64.7 63.3 64.015 63.5 62.2 62.8 63.2 61.9 62.630g LSA1005 66.6 66.3 66.4 66.6 66.3 66.515 66.7 66.4 66.5 67.0 66.7 66.830g UKB5 60.8 60.5 60.6 68.1 67.7 67.915 60.7 60.5 60.6 68.4 68.0 68.2Table 2: Accuracy of the LSA-based sentence ex-pansion PageRank model, as compared with thesentence (PPR) and word oriented (w2w) ver-sions of the personalized PageRank over the Se-meval 2007 datasets.
17x and 30g refer to the ex-tended resources of WordNet 1.7 and 3.0, respec-tively.the most efficient one as it runs the original PPRagainst a graph built around the only hyponymyrelations among synsets.
We used the Senseval?02and Senseval?03 datasets to fine tune parametersof our LSA model, that are: (1) the dimensional-ity cut k to derive the LSA space; (2) the thresh-old ?
to determine the expansion dictionary in theLSA space for every POS tag (e.g.
noun or ad-jectives), that may require different values; (3)the damping factor ?
and (4) the number of iter-ation over the graph.
In (Agirre and Soroa, 2009)the suggested parameters are ?
= 0.85 as thedamping factor and 30 as the upper limit to thePageRank iterations.
We always adopted this set-ting to estimate the performances of the standardPPR and PPRw2w algorithms referred throughUKB.
Due the novel configuration of the graphthat in our model also includes many other simi-lar terms, the damping factor and the number ofiterations have been re-estimated.
k has been setto 100 as different values did not seem to influ-ence accuracy.
We adopted fixed limits for sen-tence expansion where values from 20 up to 150terms have been tested.
The good scores obtainedon the development set suggested that a number ofiterations lower than 30 is in general enough to getgood accuracy levels: 15 iterations, instead of 30,have been judged adequate.
Finally, on average,the total number of lexical items in the expandedsentence T (?)
includes about 40% of nouns, 30%of verbs, 20% of adjectives and 10% of adverbs.29Finally, a damping factor ?
= 0.98 has been used.Table 2 reports Precision, Recall and F1 scoresof the different models as obtained over the testSemEval ?07 data.
Every row pair comparesthe LSA model with the original correspondingUKB version over a given graph (from WN1.7to WN30g).
For each model the accuracy corre-sponding to two iterations (5 and 15) is reportedto analyze also the overall trend during PageRank.The best F1 scores between any pair are empha-sized in bold, to comparatively asses the results.As a confirmation of the outcome in (Agirre andSoroa, 2009), different lexical resources achievedifferent results.
In general by adopting the graphderived from WN3.0 (i.e.
WN30 and WN30g)lower performance can be achieved.
Moreover,the word-by-word model (last three columns forthe w2w side of the Table) is evidently superior.Interestingly, almost on every type of graph andfor every approach (sentence or word oriented) theLSA-based method outperforms the original UKBPPR.
This confirms that the impact of the topicalinformation provided by the LSA expansion of thesentence is beneficial for a better use of the lexicalgraph.
An even more interesting outcome is thatthe improvement implied by the proposed LSAmethod on the sentence oriented model (i.e.
thestandard PPR method of (Agirre and Soroa, 2009))is higher, so that the difference between the per-formances of the PPRw2w model are no longerstrikingly better than the PPR one.
For exam-ple, on the simple WN1.7 hyponymy network thePPR ?
LSA100 3 method abolishes the gap ofabout 4% previously observed for the PPR-UKBmodel.
When LSA is used, it seems that the word-by-word approach is no longer required.
On thecontrary, in the WN17x case the best figure af-ter 5 iterations is obtained by the PPR-LSA100method instead of the w2w-LSA100 one (71.5%vs.
71.1%).
The good accuracy reachable by thesentence oriented strategy (i.e.
LSA100 and w2w)is also very interesting as for the higher efficiencyof the PPR approach with respect to the word-by-word PPRw2w one.4.2 Time EfficiencyIn the attempt to validate the hypothesis that LSAis helpful to improve time complexity of the WSD,we analyzed the processing times of the differentdata sets, in order to cross compare methods and3100 refers to the dimension k of the LSA spaceresources4.
The aim of the evaluation is to studythe contribution of the sentence expansion usingLatent Semantic Analysis and the Page Rank al-gorithm.
Tests were performed comparing dif-ferent parameter values (e.g.
cardinality t of thesentence expansion, different values for the ac-ceptability threshold) as well as several settingsof the damping factor for the personalized PageR-ank algorithm (Eq 1) and the number of iterationsover the KB Graph.
In figure 1, the processingspeed, measured as seconds per sentence, has beenplot for different graphs and configurations.
No-tice that one sentence is equivalent on average to9,6 target words.
As clearly shown in the figure,the processing times for the word-by-word methodover the extended WN 1.7 (i.e.
WN17x) are notacceptable for IR tasks such as query processing,or document indexing.
For an entire documentof about 20 sentences the overall amount of pro-cessing required by the w2w 17x UKB method isabout 45 minutes.
Word-by-word methods are justslightly more efficient whenever applied to graphswith lower connectivity (e.g.
WN17 vs. WN17xas in Fig.
1 left plot).
The same tasks with PPRmethods are solved in a quite faster way, with ageneral ratio of 1:14 with the extended versionsand 1:6 with the hyponymy graphs.
The process-ing time of the proposed LSA method is thus atleast 6 times faster than the UKB method with thecomparable accuracy level.
Moreover, as accu-racy between PPR and w2w is comparable whenLSA is adopted, this efficiency can be guaranteedat no loss in accuracy.
By integrating the evi-dence of Figure 1 with the ones of Table 1, weobserve that accuracy reachable by LSA-UKB isindependent by the standard or word-by-word con-figuration so that the overall process can be madeabout 10 times faster.
Notice that the representa-tion in the LSA space that is projected for a tar-get sentence can be easily obtained also for longertext fragments.
Moreover, as for the one senseper discourse hypothesis it is possible that everyword can be processed once in an entire text.
Thissuggests that a document oriented usage of thepersonalized PageRank based on LSA can be de-signed achieving the maximal efficiency.
In or-der to evaluate the corresponding impact on accu-racy a dedicated dataset has been defined and moretests have been run, as discussed hereafter.4Tests were carried out on a 32-bit machine with a 3.2Ghz CPU and 2 Gbyte Memory.
Gnu/Linux operative systemis installed on it, with the kernel 2.6.28-16-generic.30Figure 1: Processing Times for the PPR, w2w and LSA methods as applied on the WN 1.7 (left plot)and WN 3.0 (right plot) resources, respectively: 17x and 30g refer to test over the extended resources.4.3 Document oriented PPRWhile the LSA model has been actually appliedto determine an expansion for the entire targetsentence, nothing prevents to apply it to largertext units, in order to bias the PageRank for allwords in a document.
In order to verify if such aprocess disambiguation could preserve the sameaccuracy, we measured the accuracy reachableover the same Semeval?07 data organized in doc-uments.
The sentences have been grouped in 5documents, made of about about 250 sentences:during the tagging process, the system generatesa lexical expansion for an entire document, about450 target words on average.
Then PageRank iscarried out and the resulting ranking is projectedto the senses of all the targeted words in the doc-ument.
Due to the much wider locality managedin this process, a larger cardinality for the expan-sion is used and the most similar 400 words arecollected as a bias for the PageRank.
The accu-racy reachable is reported in Table 4.3.
As ex-pected, the same trends as for the sentence basedapproach are observed: the best resource is stillthe WN17x for which the best results is obtained.However, the crucial result here is that no drop inperformance is also observed.
This implies thatthe much more efficient document oriented strat-egy can be always applied through LSA withoutmajor changes in accuracy.
Also results related tothe processing time follow the trends of the sen-tence based method.
Accordingly 28 seconds re-quired to process a document in the worst case isan impressive achievement because the same ac-curacy was obtained, without LSA, in 2 orders ofmagnitude more time.5 ConclusionsIn this paper an extension of a PageRank-based al-gorithm for Word Sense Disambiguation has beenModel Iter.
Prec Rec F1PPR 17 LSA4005 0.6670 0.6540 0.660415 0.6800 0.6668 0.6733PPR 17 UKB5 0.6440 0.6316 0.637715 0.6360 0.6236 0.6297PPR 17x LSA4005 0.7130 0.7118 0.712415 0.7152 0.7140 0.7146PPR 17x UKB5 0.7108 0.7096 0.710215 0.7073 0.7060 0.7067PPR 30 LSA4005 0.6593 0.6465 0.652915 0.6688 0.6558 0.6622PPR 30 UKB5 0.6445 0.6320 0.638215 0.6724 0.6593 0.6658PPR 30g LSA4005 0.6636 0.6606 0.662115 0.6653 0.6624 0.6639PPR 30g UKB5 0.6543 0.6514 0.652815 0.6565 0.6536 0.6550Table 3: Accuracy of the LSA-based PPR modelwhen applied in a document oriented fashion onthe Semeval ?07 dataset.
LSA400 stands for thesize t of the applied sentence expansion T (?).presented.
It suggests a kind of personalizationbased on sentence expansion, obtained as a sideeffect of Latent Semantic Analysis.
The major re-sults achieved are in terms of improved efficiencythat allows to use smaller resources or less iter-ations with similar accuracy results.
The result-ing speed-up can be also improved when the dis-ambiguation is run in a document oriented fash-ion, and the PageRank is run once per each doc-ument.
The overall results can achieve a speed-up of two order of magnitude at no cost in accu-racy.
Moreover the presented approach constitutesthe state-of-the-art among the unsupervised WSDalgorithms over the Semeval?07 datasets, whileimproving the efficiency of the PPR method bya factor 10 in the worst case.
This work opensperspectives towards more sophisticated distribu-tional models (such as syntax-driven ones) as wellas cross-linguistic applications supported by mul-tilingual lexical sense repositories.31ReferencesE.
Agirre and G. Rigau.
1996.
Word sense disam-biguation using conceptual density.
In Proceedingsof COLING-96, Copenhagen, Denmark.Eneko Agirre and Aitor Soroa.
2008.
Usingthe multilingual central repository for graph-basedword sense disambiguation.
In Proceedings of theLREC?08, Marrakech, Morocco, May.E.
Agirre and A. Soroa.
2009.
Personalizing pagerankfor word sense disambiguation.
In Proceedings ofthe 12th conference of EACL ?09, Athens, Greece,March 30 - April 3.R.
Basili, M. Cammisa, and F.M.
Zanzotto.
2004.A semantic similarity measure for unsupervised se-mantic disambiguation.
In Proceedings of LREC-04, Lisbon, Portugal.Stephen Beale, Benoit Lavoie, Marjorie McShane,Sergei Nirenburg, and Tanya Korelsky.
2004.
Ques-tion answering using ontological semantics.
InTextMean ?04: Proceedings of the 2nd Workshop onText Meaning and Interpretation, pages 41?48, Mor-ristown, NJ, USA.
Association for ComputationalLinguistics.Sergey Brin and Lawrence Page.
1998.
Theanatomy of a large-scale hypertextual web searchengine.
Computer Networks and ISDN Systems,30(1?7):107?117.M.
Carpuat and D. Wu.
2007.
Improving statis-tical machine translation using word sense disam-biguation.
In Proceedings of the Joint ConferenceEMNLP-CoNLL ?09, Prague, Czech Republic.Y.
Chan, H. Ng, and D. Chiang.
2007.
Word sensedisambiguation improves statistical machine transla-tion.
In Proceedings of the ACL ?09, Prague, CzechRepublic.Jim Cowie, Louise Guthrie, and Joe Guthrie.
1992.Lexical disambiguation using simulated annealing.In Proc.
of 14th Int.
Conf.
COLING ?92, pages 359?365, Nantes, France.Sanda M. Harabagiu and Dan I. Moldovan.
1999.Enriching the wordnet taxonomy with contextualknowledge acquired from text.
In in Iwanska, L.M.,and Shapiro, S.C. eds 2000.
Natural Language Pro-cessing and Knowledge Representation: Language,pages 301?334.
AAAI/MIT Press.T.
H. Haveliwala.
2002.
Topic-sensitive pagerank.
InProc.
of 11th Int.
Conf.
on World Wide Web, page517526, New York, USA.
ACM.Richard Johansson and Pierre Nugues.
2007.
Se-mantic structure extraction using nonprojective de-pendency trees.
In Proceedings of SemEval-2007,Prague, Czech Republic, June 23-24.S.
B. Kim, H. Seo, and H. Rim.
2004.
Informationretrieval using word senses: root sense tagging ap-proach.
In Proceedings of the International ACM-SIGIR Conference ?09, Sheffield, UK, July.H.
Krovetz.
1997.
Homonymy and polysemy in in-formation retrieval.
In Proceedings of the 35th ACL?09.Tom Landauer and Sue Dumais.
1997.
A solution toplato?s problem: The latent semantic analysis the-ory of acquisition, induction and representation ofknowledge.
Psychological Review, 104:211?240.M.
Lesk.
1986.
Automatic sense disambiguation us-ing machine readable dictionaries: how to tell a pinecone from an ice cream cone.
In SIGDOC ?86: Pro-ceedings of the 5th annual international conferenceon Systems documentation, New York, NY, USA.G.
Miller, R. Beckwith, C. Fellbaum, D. Gross, andK.
Miller.
1990.
An on-line lexical database.
Inter-national Journal of Lexicography, 13(4):235?312.Alessandro Moschitti and Roberto Basili.
2004.
Com-plex linguistic features for text classification: Acomprehensive study.
In Proc.
of the EuropeanConf.
on IR, ECIR, pages 181?196, New York, USA.Roberto Navigli and Mirella Lapata.
2007.
Graphconnectivity measures for unsupervised word sensedisambiguation.
In Proceedings of IJCAI?07, pages1683?1688, San Francisco, CA, USA.
MorganKaufmann Publishers Inc.Roberto Navigli, Kenneth C. Litkowski, and Orin Har-graves.
2007.
Semeval-2007 task 07: coarse-grained english all-words task.
In SemEval ?07,pages 30?35, Morristown, NJ, USA.
Association forComputational Linguistics.M.
Palmer, C. Fellbaum, S. Cotton, L. Delfs, and H.T.Dang.
2001.
English tasks: All-words and verblexical sample.
In Proceedings of SENSEVAL-2,Tolouse, France, July.S.
Pradhan, E. Loper, D. Dligach, and M. Palmer.2007.
Semeval-2007 task-17: English lexical sam-ple srl and all words.
In Proceedings of SemEval-2007, Prague, Czech Republic, June.Magnus Sahlgren.
2006.
The Word-Space Model.
De-partment of Linguistics, Stockholm University.Ravi Sinha and Rada Mihalcea.
2007.
Unsupervisedgraph-based word sense disambiguation using mea-sures of word semantic similarity.
In IEEE ICSC2007.B.
Snyder and M. Palmer.
2004.
The english all-wordstask.
In Proceeding of ACL 2004 Senseval-3 Work-shop, Barcelona, Spain, July.32
