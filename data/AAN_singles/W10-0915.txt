Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 122?127,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsPRISMATIC: Inducing Knowledge from a Large Scale Lexicalized RelationResource?James Fan and David Ferrucci and David Gondek and Aditya KalyanpurIBM Watson Research Lab19 Skyline DrHawthorne, NY 10532{fanj, ferrucci, gondek, adityakal}@us.ibm.comAbstractOne of the main bottlenecks in natural lan-guage processing is the lack of a comprehen-sive lexicalized relation resource that containsfine grained knowledge on predicates.
In thispaper, we present PRISMATIC, a large scalelexicalized relation resource that is automati-cally created over 30 gb of text.
Specifically,we describe what kind of information is col-lected in PRISMATIC and how it compareswith existing lexical resources.
Our main fo-cus has been on building the infrastructure andgathering the data.
Although we are still inthe early stages of applying PRISMATIC toa wide variety of applications, we believe theresource will be of tremendous value for AIresearchers, and we discuss some of potentialapplications in this paper.1 IntroductionMany natural language processing and understand-ing applications benefit from the interpretation oflexical relations in text (e.g.
selectional preferencesfor verbs and nouns).
For example, if one knows thatthings being annexed are typically geopolitical enti-ties, then given the phrase Napoleon?s annexation ofPiedmont, we can infer Piedmont is a geopoliticalentity.
Existing linguistic resources such as VerbNetand FrameNet provide some argument type infor-mation for verbs and frames.
However, since theyare manually built, they tend to specify type con-straints at a very high level (e.g, Solid, Animate),?Research supported in part by Air Force Contract FA8750-09-C-0172 under the DARPA Machine Reading Programconsequently they do not suffice for cases such asthe previous example.We would like to infer more fine grained knowl-edge for predicates automatically from a largeamount of data.
In addition, we do not want to re-strict ourselves to only verbs, binary relations, or toa specific type hierarchy.In this paper, we present PRISMATIC, a largescale lexicalized relation resource mined from over30 gb of text.
PRISMATIC is built using a suite ofNLP tools that includes a dependency parser, a rulebased named entity recognizer and a coreferenceresolution component.
PRISMATIC is composedof frames which are the basic semantic representa-tion of lexicalized relation and surrounding context.There are approximately 1 billion frames in our cur-rent version of PRISMATIC.
To induce knowledgefrom PRISMATIC, we define the notion of frame-cuts, which basically specify a cut or slice operationon a frame.
In the case of the previous Napoleonannexation example, we would use a noun-phrase?
object type cut to learn the most frequent typeof things being annexed.
We believe there are manypotential applications that can utilize PRISMATIC,such as type inference, relation extraction textual en-tailment, etc.
We discuss some of these applicationsin details in section 8.2 Related Work2.1 Manually Created ResourcesSeveral lexical resources have been built man-ually, most notably WordNet (Fellbaum, 1998),FrameNet(Baker et al, 1998) and VerbNet(Baker et122al., 1998).
WordNet is a lexical resource that con-tains individual word synset information, such asdefinition, synonyms, antonyms, etc.
However, theamount of predicate knowledge in WordNet is lim-ited.FrameNet is a lexical database that describes theframe structure of selected words.
Each frame rep-resents a predicate (e.g.
eat, remove) with a list offrame elements that constitutes the semantic argu-ments of the predicate.
Different words may map tothe same frame, and one word may map to multipleframes based on different word senses.
Frame ele-ments are often specific to a particular frame, andeven if two frame elements with the same name,such as ?Agent?, may have subtle semantic mean-ings in different frames.VerbNet is a lexical database that maps verbs totheir corresponding Levin (Levin, 1993) classes, andit includes syntactic and semantic information of theverbs, such as the syntactic sequences of a frame(e.g.
NP V NP PP) and the selectional restrictionof a frame argument value must be ANIMATE,Compared to these resources, in addition to beingan automatic process, PRISMATIC has three majordifferences.
First, unlike the descriptive knowledgein WordNet, VerbNet or FrameNet, PRISMATIC of-fers only numeric knowledge of the frequencies ofhow different predicates and their argument valuesthrough out a corpus.
The statistical profiles are eas-ily to produce automatically, and they allow addi-tional knowledge, such as type restriction (see 8.1),to be inferred from PRISMATIC easily.Second, the frames are defined differently.
Theframes in PRISMATIC are not abstract conceptsgeneralized over a set of words.
They are definedby the words in a sentence and the relations betweenthem.
Two frames with different slot values are con-sidered different even though they may be semanti-cally similar.
For example, the two sentences ?Johnloves Mary?
and ?John adores Mary?
result in twodifferent frame even though semantically they arevery close.
By choosing not to use frame conceptsgeneralized over words, we avoid the problem ofdetermining which frame a word belongs to whenprocessing text automatically.
We believe there willbe enough redundancy in a large corpus to producevalid values for different synonyms and variations.Third, PRISMATIC only uses a very small set ofslots (see table 1) defined by parser and relation an-notators to link a frame and its arguments.
By usingthese slots directly, we avoid the problem of map-ping parser relations to frame elements.2.2 Automatically Created ResourcesTextRunner (Banko et al, 2007) is an informationextraction system which automatically extracts re-lation tuples over massive web data in an unsuper-vised manner.
TextRunner contains over 800 mil-lion extractions (Lin et al, 2009) and has provento be a useful resource in a number of importanttasks in machine reading such as hypernym discov-ery (Alan Ritter and Etzioni, 2009), and scoring in-teresting assertions (Lin et al, 2009).
TextRunnerworks by automatically identifying and extractingrelationships using a conditional random field (CRF)model over natural language text.
As this is a rela-tively inexpensive technique, it allows rapid applica-tion to web-scale data.DIRT (Discovering Inference Rules from Text)(Lin and Pantel, 2001) automatically identifies in-ference rules over dependency paths which tend tolink the same arguments.
The technique consists ofapplying a dependency parser over 1 gb of text, col-lecting the paths between arguments and then cal-culating a path similarity between paths.
DIRT hasbeen used extensively in recognizing textual entail-ment (RTE).PRISMATIC is similar to TextRunner and DIRTin that it may be applied automatically over mas-sive corpora.
At a representational level it differsfrom both TextRunner and DIRT by storing fullframes from which n-ary relations may be indexedand queried.
PRISMATIC differs from TextRun-ner as it applies a full dependency parser in orderto identify dependency relationships between terms.In contrast to DIRT and TextRunner, PRISMATICalso performs co-reference resolution in order to in-crease coverage for sparsely-occurring entities andemploys a named entity recognizer (NER) and rela-tion extractor on all of its extractions to better repre-sent intensional information.3 System OverviewThe PRISMATIC pipeline consists of three phases:1.
Corpus Processing Documents are annotated123Figure 1: System Overviewby a suite of components which perform depen-dency parsing, co-reference resolution, namedentity recognition and relation detection.2.
Frame Extraction Frames are extracted basedon the dependency parses and associated anno-tations.3.
Frame-Cut Extraction Frame-cuts of interest(e.g.
S-V-O cuts) are identified over all framesand frequency information for each cut is tabu-lated.4 Corpus ProcessingThe key step in the Corpus Processing stage is theapplication of a dependency parser which is usedto identify the frame slots (as listed in Table 1) forthe Frame Extraction stage.
We use ESG (McCord,1990), a slot-grammar based parser in order to fillin the frame slots.
Sentences frequently require co-reference in order to precisely identify the participat-ing entity, and so in order to not lose that informa-tion, we apply a simple rule based co-reference reso-lution component in this phase.
The co-reference in-formation helps enhance the coverage of the frame-cuts, which is especially valuable in cases of sparsedata and for use with complex frame-cuts.A rule based Named Entity Recognizer (NER) isused to identify the types of arguments in all frameslot values.
This type information is then registeredin the Frame Extraction stage to construct inten-tional frames.5 Frame ExtractionRelation Description/Examplesubj subjectobj direct objectiobj indirect objectcomp complementpred predicate complementobjprep object of the prepositionmod nprep Bat Cave in Toronto is a tourist attraction.mod vprep He made it to Broadway.mod nobj the object of a nominalized verbmod ndet City?s budget was passed.mod ncomp Tweet is a word for microblogging.mod nsubj A poem by Byronmod aobj John is similar to Steve.isa subsumption relationsubtypeOf subsumption relationTable 1: Relations used in a frame and their descriptionsThe next step of PRISMATIC is to extract a set offrames from the parsed corpus.
A frame is the basicsemantic unit representing a set of entities and theirrelations in a text snippet.
A frame is made of a setof slot value pairs where the slots are dependencyrelations extracted from the parse and the values arethe terms from the sentences or annotated types.
Ta-ble 2 shows the extracted frame based on the parsetree in figure 2.In order to capture the relationship we are inter-ested in, frame elements are limited to those thatrepresent the participant information of a predicate.Slots consist of the ones listed in table 1.
Further-more, each frame is restricted to be two levels deepat the most, therefore, a large parse tree may re-sult in multiple frames.
Table 2 shows how twoframes are extracted from the complex parse treein figure 2.
The depth restriction is needed for tworeasons.
First, despite the best efforts from parserresearchers, no parser is perfect, and big complexparse trees tend to have more wrong parses.
By lim-iting a frame to be only a small subset of a complexparse tree, we reduce the chance of error parse ineach frame.
Second, by isolating a subtree, eachframe focuses on the immediate participants of apredicate.Non-parser information may also be included in aframe.
For example, the type annotations of a wordfrom a named entity recognizer are included, andsuch type information is useful for the various ap-124Figure 2: The parse tree of the sentence In 1921, Einstein received the Nobel Prize for his original work on thephotoelectric effect.Frame01verb receivesubj Einsteintype PERSON / SCIENTISTobj Nobel prizemod vprep inobjprep 1921type YEARmod vprep forobjprep Frame02Frame02noun workmod ndet his / Einsteinmod nobj onobjprep effectTable 2: Frames extracted from Dependency Parse in Fig-ure 2plications described in section 8.
We also includea flag to indicate whether a word is proper noun.These two kinds of information allow us to easilyseparate the intensional and the extensional parts ofPRISMATIC.6 Frame CutOne of the main reasons for extracting a largeamount of frame data from a corpus is to induceinteresting knowledge patterns by exploiting redun-dancy in the data.
For example, we would like tolearn that things that are annexed are typically re-gions, i.e., a predominant object-type for the noun-phrase ?annexation of?
is ?Region?
where ?Region?is annotated by a NER.
To do this kind of knowledgeinduction, we first need to abstract out specific por-tions of the frame - in this particular case, we needto isolate and analyze the noun-phrase ?
object-type relationship.
Then, given a lot of data, andframes containing only the above relationship, wehope to see the frame [noun=?annexation?, prepo-sition=?of?, object-type=?Region?]
occur very fre-quently.To enable this induction analysis, we defineframe-cuts, which basically specify a cut or slice op-eration on a frame.
For example, we define an N-P-OT frame cut, which when applied to a frame onlykeeps the noun (N), preposition (P) and object-type(OT) slots, and discards the rest.
Similarly, we de-fine frame-cuts such as S-V-O, S-V-O-IO, S-V-P-Oetc.
(where S - subject, V - verb, O - object, IO -indirect object) which all dissect frames along dif-125ferent dimensions.
Continuing with the annexationexample, we can use the V-OT frame cut to learnthat a predominant object-type for the verb ?annex?is also ?Region?, by seeing lots of frames of the form[verb=?annex?, object-type=?Region?]
in our data.To make frame-cuts more flexible, we allow themto specify optional value constraints for slots.
Forexample, we can define an S-V-O frame cut, whereboth the subject (S) and object (O) slot values areconstrained to be proper nouns, thereby creatingstrictly extensional frames, i.e.
frames containingdata about instances, e.g., [subject=?United States?verb=?annex?
object=?Texas?].
The opposite ef-fect is achieved by constraining S and O slot val-ues to common nouns, creating intensional framessuch as [subject=?Political-Entity?
verb=?annex?object=?Region?].
The separation of extensionalfrom intensional frame information is desirable,both from a knowledge understanding and an appli-cations perspective, e.g.
the former can be used toprovide factual evidence in tasks such as questionanswering, while the latter can be used to learn en-tailment rules as seen in the annexation case.7 DataThe corpora we used to produce the initial PRIS-MATIC are based on a selected set of sources, suchas the complete Wikipedia, New York Times archiveand web page snippets that are on the topics listed inwikipedia.
After cleaning and html detagging, thereare a total of 30 GB of text.
From these sources, weextracted approximately 1 billion frames, and fromthese frames, we produce the most commonly usedcuts such as S-V-O, S-V-P-O and S-V-O-IO.8 Potential Applications8.1 Type Inference and Its Related UsesAs noted in Section 6, we use frame-cuts to dis-sect frames along different slot dimensions, and thenaggregate statistics for the resultant frames acrossthe entire dataset, in order to induce relationshipsamong the various frame slots, e.g., learn the pre-dominant types for subject/object slots in verb andnoun phrases.
Given a new piece of text, we canapply this knowledge to infer types for named en-tities.
For example, since the aggregate statisticsshows the most common type for the object ofthe verb ?annex?
is Region, we can infer from thesentence ?Napoleon annexed Piedmont in 1859?,that ?Piedmont?
is most likely to be a Region.Similarly, consider the sentence: ?He ordered aNapoleon at the restaurant?.
A dictionary basedNER is very likely to label ?Napoleon?
as a Per-son.
However, we can learn from a large amountof data, that in the frame: [subject type=?Person?verb=?order?
object type=[?]
verb prep=?at?
ob-ject prep=?restaurant?
], the object type typicallydenotes a Dish, and thus correctly infer the type for?Napoleon?
in this context.
Learning this kind offine-grained type information for a particular con-text is not possible using traditional hand-crafted re-sources like VerbNet or FrameNet.
Unlike previ-ous work in selectional restriction (Carroll and Mc-Carthy, 2000; Resnik, 1993), PRISMATIC basedtype inference does not dependent on a particulartaxonomy or previously annotated training data: itworks with any NER and its type system.The automatically induced-type information canalso be used for co-reference resolution.
For ex-ample, given the sentence: ?Netherlands was ruledby the UTP party before Napolean annexed it?, wecan use the inferred type constraint on ?it?
(Region)to resolve it to ?Netherlands?
(instead of the ?UTPParty?
).Finally, typing knowledge can be used for wordsense disambiguation.
In the sentence, ?Tom Cruiseis one of the biggest stars in American Cinema?, wecan infer using our frame induced type knowledgebase, that the word ?stars?
in this context refers to aPerson/Actor type, and not the sense of ?star?
as anastronomical object.8.2 Factual EvidenceFrame data, especially extensional data involvingnamed entities, captured over a large corpus can beused as factual evidence in tasks such as questionanswering.8.3 Relation ExtractionTraditional relation extraction approach (Zelenko etal., 2003; Bunescu and Mooney, 2005) relies on thecorrect identification of the types of the argument.For example, to identify ?employs?
relation between?John Doe?
and ?XYZ Corporation?, a relation ex-tractor heavily relies on ?John Doe?
being annotated126as a ?PERSON?
and ?XYZ Corporation?
an ?OR-GANIZATION?
since the ?employs?
relation is de-fined between a ?PERSON?
and an ?ORGANIZA-TION?.We envision PRISMATIC to be applied to rela-tion extraction in two ways.
First, as described insection 8.1, PRISMATIC can complement a namedentity recognizer (NER) for type annotation.
Thisis especially useful for the cases when NER fails.Second, since PRISMATIC has broad coverage ofnamed entities, it can be used as a database tocheck to see if the given argument exist in relatedframe.
For example, in order to determine if ?em-ploys?
relation exists between ?Jack Welch?
and?GE?
in a sentence, we can look up the SVO cutof PRISMATIC to see if we have any frame that has?Jack Welch?
as the subject, ?GE?
as the object and?work?
as the verb, or frame that has ?Jack Welch?as the object, ?GE?
as the subject and ?employs?
asthe verb.
This information can be passed on as anfeature along with other syntactic and semantic fea-tures to th relation extractor.9 Conclusion and Future WorkIn this paper, we presented PRISMATIC, a largescale lexicalized relation resource that is built au-tomatically over massive amount of text.
It providesusers with knowledge about predicates and their ar-guments.
We have focused on building the infras-tructure and gathering the data.
Although we arestill in the early stages of applying PRISMATIC, webelieve it will be useful for a wide variety of AI ap-plications as discussed in section 8, and will pursuethem in the near future.ReferencesStephen Soderland Alan Ritter and Oren Etzioni.
2009.What is this, anyway: Automatic hypernym discovery.In Proceedings of the 2009 AAAI Spring Symposiumon Learning by Reading and Learning to Read.Collin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The berkeley framenet project.
In Proceedingsof the 17th international conference on Computationallinguistics, pages 86?90, Morristown, NJ, USA.
Asso-ciation for Computational Linguistics.Michele Banko, Michael J Cafarella, Stephen Soderl,Matt Broadhead, and Oren Etzioni.
2007.
Openinformation extraction from the web.
In In Inter-national Joint Conference on Artificial Intelligence,pages 2670?2676.Razvan C. Bunescu and Raymond J. Mooney.
2005.
Ashortest path dependency kernel for relation extrac-tion.
In HLT ?05: Proceedings of the conference onHuman Language Technology and Empirical Meth-ods in Natural Language Processing, pages 724?731,Morristown, NJ, USA.
Association for ComputationalLinguistics.John Carroll and Diana McCarthy.
2000.
Word sensedisambiguation using automatically acquired verbalpreferences.
Computers and the Humanities SensevalSpecial Issue, 34.Christiane Fellbaum, 1998.
WordNet: An Electronic Lex-ical Database.Beth Levin, 1993.
English Verb Classes and Alterna-tions: A Preliminary Investigation.Dekang Lin and Patrick Pantel.
2001.
Dirt - discoveryof inference rules from text.
In In Proceedings of theACM SIGKDD Conference on Knowledge Discoveryand Data Mining, pages 323?328.Thomas Lin, Oren Etzioni, and James Fogarty.
2009.Identifying interesting assertions from the web.
InCIKM ?09: Proceeding of the 18th ACM conference onInformation and knowledge management, pages 1787?1790, New York, NY, USA.
ACM.Michael C. McCord.
1990.
Slot grammar: A systemfor simpler construction of practical natural languagegrammars.
In Proceedings of the International Sympo-sium on Natural Language and Logic, pages 118?145,London, UK.
Springer-Verlag.Philip Resnik.
1993.
Selection and Information:A Class-Based Approach to Lexical Relationships.Ph.D.
thesis, University of Pennsylvania.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relationextraction.
J. Mach.
Learn.
Res., 3:1083?1106.127
