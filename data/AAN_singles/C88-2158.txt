Object-Oriented Parallel Parsing for Context-Free GrammarsAkinori YonezmvaIchiro OhsawaDepartment ofInformation ScienceTokyo Institute o\] TechnologyOokayama, Meguro-kuTokyo 152, Japanyonezawa ~is.
tilech.junet ~utokyo- rela y. csnet @relay.
es.
netohsawa~i~.titech.junet~utokyo-rclay, csnet@relay, cs.
netAbst rac tThis paper describes a new parallel parsing scheme forcontext-free grammars and our experience of implementingthis scheme, and it also reports the result of our simula-tion for running the parsing program on a massive parallelprocessor.In our basic parsing scheme, a set of context free-grammar :,:ules is represented by a network of processor-like computing agents each having its local memory.
Eachcomputing agent in the network corresponds to an occur-fence of a non-terminal or terminal symbol appearing inthe grammar ules.
Computing agents in the network workconcurrently and communicate with one another by passingmessages which are partial parse trees.This scheme is shown to he fast (0(n,h) time for thefirst complete parse tree, where n is the length of an inputsentence and h is the height of the parse tree) and useful invarious modes of parsing such as on-line parsing, overlapparsing, on-line unparsing, pipe-lining to semantics pro-cessing, etc.
Performance valuation for implementing thisscheme on a massive parallel machine is conducted by dis-tributed event simulation using the Time Warp mechanism/Jeffersong5/.Our parsing scheme is implemented in a programminglanguage called ABCL/1 which is designed for object-oriented concurrent programming and used for various con-current programming/Yonezawa86/.
The program is cur-rently runing on standard single-cpu nlachines such asSUN3s and Symbolics Lisp machines (by simulated par-allelism).In our experiment and simulation, a set of about 250context-free grammar ules specifying a subset of Englishis represented by the corresponding network of objects (i.e.,computing agents) and about 1100 concurrently executableobjects are involved.1 In t roduct ionThis paper prcsents a new approach to parsing forcontext-free grammars, which is Conceptually very sim-ple.
The significance of our approach is supported by re-cent trends in computer-related fields.
In computationallinguistics, much attention has been drawn to parsing ofcontext-free grammars owing to the progress of context-free based grammatical frameworks for natural languagessuch as LFG /Kaplan82/, GPSG /Gazdar85/.
Further-more, many practical natural language interface systemsare based on context-free (phrase structure) grammars.In computer architecture and programming, exploitationof parallelism has be actively pursued; innovative com-puter architectures utilizing a large number of proces-sors /Gottl ieb83/ Seitz85/ have been developed and ac-cordingly new methodologies for concurrent l)rogramming/AghaS6//GelernterS6//Yonezawa87/ha.re been activelystudied.In our basic parsing scheme, a given set of context-free grammar rules is viewed as a network of terminaland non-terminal symbols, and a corresponding networkof processor-like computing agents with internal memory(or simple processors) is constructed.
The node set of thenetwork has a direct one-to-one correspondence to the setof occurrences of symbols appearing in the grammar ulesand the link topology of the network is directly derivedfrom the structure of the set of grammar ules.
Our pars-ing scheme produces all the possible parse trees for a giveninput string without duplication.Since the notion of objects in object-oriented concurrentprogramming /Yonezawa87/ naturally fits the computingagents composing the network, this parsing scheme hasbeen implemented in an object-oriented language for con?current programming ABCI,/1/Yonezawa86/by represent-ing each computing agent in the network as an object ofABCL/L2 The Basle Scheme2:1 A Symbol  as a Comi )ut lng  AgentOur approach is basically bottom-up.
Suppose we have acontext fi-ee grammar ule such as:VP --> V NP (1)In bottom-up arsing, a usual interpretation of this kindof rule is:In a substring of an input string, if its firsthalf portion can he reduced to a category(terminal/non-terminal symbol) V and subse-quently, if its second half portion can be reducedto a category VP, then the whole substring can bereduced to a category VP.This interpretation is implicitly based upon the followingtwo assumptions about parsing process:- a single computing agent (processor or process) isworking on the input string, and?
non-terminal or terminal symbols such as VP, V, andNP are viewed as passive tokens or data.773r VP tl t2Figure 1:Instead, we will take a radically different approach, illwhich* more than one, actually, a number of computing agentsare allowed to work concurrently, each performing arather simple task,?
for each occurrence of a non-terminal or terminal sym-bol in grammar ules, a computing agent is assumed,?
such a computing agent receives data (messages), ma-nipulates and stores data in its local memory, andalso can send data (messages) asynchronously to othercomputing agents that correspond to non-terminal orterminal symbols, and?
data to be passed around among such computingagents are partial parse trees.Suppose that the computing agent which acts for the Vsymbol in Rule (1) has received a (token that representsa) partial parse tree tl.
Also suppose that the computingagent which acts for the NP symbol in Rule (1) has receiveda partial parse tree t2.
If the terminal symbol which isthe right boundary of t l  is, in the original input string,adjacent o the terminal symbol which is the left boundaryof t2, then t l  and t2 can be put together and they canform a larger partial parse tree which corresponds to theVP symbol in Rule (1).
See Figure i.For example, let us consider an input string:I saw a girl wflh a ~elescope.If t l  is a parse tree constructed from 'saw' and t2 is a parsetree constructed from 'a girl', then the right boundary of t lis adjacenl to the left boundary of t2.
But if t2 is a parsetree constructed from ~a telescope', then t l  and t2 are notadjacent and a larger parse tree cannot be constructed fromthem.Now, which computing agent should check the bound-ary adjacency, and which one should perform the tree-constructing task?
In our scheme, it is natural that thecomputing agent acting for the NP symbol does the bound-ary checking because, in many simple cases, the NP agentoften receives t2 after the V agent receives t l  (due to theleft-to-right nature of on-llne processing).
In order for theNP agent o be able to perform this task, the V agent mustsend tl  to the NP agent.
Upon receiving t l  from the Vagent, tl~e NP agent checks the boundary adjacency be-tween t l  and t2 if it has already received t2.
If t2 hasnot arrived yet, the NP agent has to postpone the bound-ary checking until t2 arrives and t l  will be stored in theNP agent's local memory.
If the two boundaries are notadjacent, the NP agent stores t l  in its local memory forfuture references.
Later on.when the NP agent receivessubsequently arriving partial parse trees, their left bound-ary will be checked againt the right boundary of tl.When the adjacency test succeeds, the NP agent con-catenates t l and t2 and sends them to the computing agent774acting for the non-terminal symbol VP in Rule (1).
TheVP agent constructs, out of t l  and t2, a partial parse treewith the root-node tag being the non-terminal symbol 'VP.
'This newly constructed partial parse tree is then distribuledby tile VP agent to all the computing agents each of whichacts for an occurrence of symbol VP in the right-hand sideof a rule.
This distributed tree in turn plays a role of data(messages) to the computing agents in exactly the sameway as tl and t2 play roles of data to the V and NP agentsabove.This is the basic idea of our parsing scheme.
It is verysimple.
It is the matter of course that every single comput-ing agent acting for a non-terminal or terminal symbol canwork independently, in parallel and asynchronously.
Rule(1) is represented as the computing agent network illus-trated in Figure 1.
(This is part of a larger network.)
Boxesand arrows denote computing agents and flows of trees, re-spectively.2.2 A Set of  Rules as a Netwol 'k  of  Comput ingAgentsIt should be clear from the previous subsection that a setof context-free grammar ules (even a singleton grammar)is represented as a network of computing agents each ofwhich acts for an occurrence of a non-terminal or terminalsymbol in a grammar ule.
More precisely, the correspon-dence between the set of computing agents and the set ofoccurrences of symbols in the set of grammar ules is one-to-one; for each occurrence of a symbol in a rule, there isone distinct computing agent.
For example, the followingset of rules (including Rule (1)) is represented as the net-work depicted in Figure 2.s --> NP vP (2)s --> s PP (3)NP --> DET N (4)PP - -> PREP NP (5)A white box corresponds to the computing agent actingfor a symbol in the right-hand side of a grammar ule anda dark box corresponds to the computing agent acting forthe non-terminal symbol in the left-hand side of a gram-mar rule.
Note that the dark box labeled with 'NP' (atthe bottom of the figure) is linked to three boxes labeledwith 'NP.'
This means that a partial parse tree constructedby the computing agent acting for the left symbol NP inRule (4) is distributed to the three computing agents act-ing for tile three occurrences of symbol NP ill Rules (1),(2), and (5).
Note that Rule (3) is left-recursive, which isrepresented as the feed-back link in Figure 2.2.3 Three  Types  of  Comput ing  Agents1As the reader might have already noticed, there are threetypes of computing agents: Type-1 corresponds to the leftsymbol in a grammar ule, 'type-2 corresponds to the left--corner (i.e.
left-most) right symbol, and Type-3 corre-sponds to other right symbols.
(If a grammar ule has morethan two right symbols, each of tlle right symbols exceptthe left-corner symbol is represented as a Type-3 agent.
)For example, ill Rule (1), VP is Type-l, V is Type-2, andNP is Type-3.l This subsection may be skipped if the idea of the scheme is al-ready clear.L-I-t t :Figure 2:A Type-1 computing agent A1 receives a concatenationof parse trees from the Type-3 agent acting for the right-most right symbol (e.g., NP for the case of Rule (1)) andconstructs a new parse tree with its root node being thenon-terminal symbol that A1 acts for and distributes it toall the Type-2 or Type73 agents acting for the occurrencesof the same non-terminal symbol (e.g., 'NP' in the abovecase).A Type-2 computing agent A2 receives a partial parsetree from some computing agent that is acting for the oc-currence of the same symbol as A2 acts for, and simplypasses it to the computing agent acting for the symbol oc-currence which is right-adjacent to the symbol occurrencethat A2 is acting for.
In the case of Rule (1), a Type-2 agentacting for V simply passes the received partial parse treeto the computing agent acting for NP.
In the case where agrammar ule has just one right symbol as inNP --> N, (6)a Type-2 agent acting for N sends a partial parse tree tothe 'type-1 agent acting for NP.A Type-3 computing agent has two kinds of sources ofparse trees to receive: one from Type-1 agents and theother from the Type-2 or Typeo3 agent acting for its left-adjacent symbol occurrence.
In the case of Rule (1), theType-3 agent acting for NP receives partial parse trees fromType-1 agents acting for occurrences of symbol NP in otherrules and also from the Type-2 agent acting for V in Rule(1).
Upon receiving a partial parse tree t l  from one of thesources, a Type-3 agent A3 checks to see if it has alreadyreceived, from the other kind of source, a partial parse treewhich clears the boundary adjacency test against l. If sucha parse tree t2 has already arrived at A3, then A3 concate-nates t l  and t2 and passes them to the computing agentacting ibr the symbol occurrence which is right-adjacentto the symbol occurrence A3 acting for.
If no such parsetree has arrived yet, A3 stores t l  in its local memory forthe future use.
In the case where no right-adjacent symbolexits in the grammar ule, (which means that the symboloccurrence A3 is acting for is the right-most right symbolin the glamrnar ule), A3 sends the concatenated trees tothe Type--1 computing agent acting for the left symbol ofthe grammar ule.2.4 Termina l  Symbols  as Comput ing  AgentsIt should be noted that, ill our basic scheme we do not makeany distinction between on-terminal symbols and terminalsymbols.
In fact, this unlfonn treatment contributes to theconceptual simplicity of our parsing scheme.
We do nothave to make a special treatment for grammar ules suchas:NP --> NP and NP (7)where a lower case symbol 'and' is a terminal symbol.
Theuniformity implies that a word of a natural language, say'fly' in English, which has more than one grammatical cat-egory should be described as follow:v- -> fly (8)--> ~ly (9)where Rules (8) and (9) indicate that a word 'fly' can be averb or noun.
The two rules are represented by two Type-1agents acting for V and N, and two Type-2 agents act-ing for the two occurrences of 'fly' in Rules (8) and (9).Thus, in our parsing scheme, the grammatical categoriesof each word in the whole vocabulary in use are describedby grammar ules with a single right symbol.
This meansthat conceptually, one or more computing agents exist foreach word.
(Those who might worry about the number ofcomputing agents acting for words should read Subsection4.2.
)2.5 Input  to the  NetworkIn our parsing scheme, a given set of grammar ules is com-piled as a network of computing agents in the manner de-scribed above.
Then, how is an input string fed into thenetwork of computing agents?
We assume that an inputstring is a sequence of words (namely, terminal symbols).In feeding an input string into the network, two thingshas to be taken into account.
One is: for each word inan input string, appropriate computing agents, to whichthe word should be sent, must be found.
Of course, suchcomputing agents are ones that act for the occurrences of.the word in the grammar ules.
Notice that there can bemore than one such computing agent for each word, dueto multiplicity of grammatical category and the multipleoccurrences of the same symbol in grammar ules.
Sincethe set of appropriate computing agents can be known incompiling a given set of grammar ules, such informationshould be kept in a special computing agent which does themanagerial work for the network.
Let us call it the manageragent The manager agent, receives an input string andsends (or distributes) each word in the input string to thecorresponding agents in the network in the on-line manner.The other thing needed to be considered in feeding the in-put is: the information about the order of words appearingin an input string must be provided to computing agentsin the network in an appropriate manner.
This is becauseType-3 computing agents need such information to performthe boundary adjacency test.
For this, each word to be sent(or distributed) to computing agents in the network shouldbe accompanied with its positional information in the in-put string.
Snppose an input string is I saw a g i r l  witha te lescope.
Then a word g i r l  should be sent with thepair of its starting position and its ending position.
The775~ 4 , A  NETWORK(0 1 z)  II .
.
.
.
.
.
.
.
I -'HL-_~ ,~,'H' I' (~ 2 .
;,~ I I - - - - ~ ~T ~ I'?----I' (3 4 ,i,-z, I I  I/ / ........ .1 ' , ,swish) .
.
.l L- - -  ,::r-"~ Manager"- - - ' I '  'saw' 'a' 'girl' 'with' ...0 1 2 3 4 5Figure 3:actual form of data (message) for the word g i r l  may looklike (3 4 g i r l ) .
See Figure 3.
This data form conventionis adopted in dealing with more general parse trees.
(Infact, a single word (terminal symbol) is also the simplestcase of parse tree.
)2.6 How Part ial  Parse Trees FlowTo get a more concrete feeling of how symbols are processedin the network, let us look at the flows of words a andg i r l  in the initial phase.
(See Figure 4) Assuming thatthe following rules are compiled in addition to Rules (1)through (5),DET - ->  a ( lO)N - ->  girl (11)the manager agent sends (2 3 a) and (3 4 girl) to theType-2 computing agent acting for a in Rule (10) and theType-2 computing agent acting for g i r l  in Rule (11), re-spectively.
They are in turn sent to a Type-1 agent Detlacting for DET in Rule (10) and a Type-1 agent N1 actingfor N in Rule (11), respectively.
These Type-1 agents con-struct a parse tree with its root node label being DET or N.Then the parse tree constructed by Detl is sent o a Type-2agent Det2 acting for DET in Rule (4).
Similarly, the parsetree constructed by N1 is sent to a Type-3 agent N2 actingfor N in Rule (4).
In both cases, the positional informationis accompanied.
That is, the actual data forms to be sentare (:2 3 (DET a)) and (3 4 (N g i r l ) ) .Agent Det2 simply passes the parse tree to agent N2.N2 performs the boundary adjacency test between (2 3(DET a)) and (3 4 (N g i r l ) )  and finds the test to beok.
Since the test is ok, N2 concatenates the two dataforms, constructing a new single data form:(2 4 (DET a) (N girl))This new data form is then sent to the Type-1 agent actingfor NP in Rule (4).
This agent constructs a data form ofthe parse tree for NP, which looks like:(2 4 (NP (DET a) (N girl)))This data form will be distributed among the Type-2 andType-3 computing agents acting for symbol NP in the net-work.
(See Figure 4.)
Finally, when a computing agentacting for S receives a message (0 7" (S .
.
.
)), we can saythat a complete parse tree for the input string has beenconstructed as part of the message.It should be reminded that actions taken by computingagents uch as Detl, Det2, N1, and N2 are performed all776(2 4 (NP (DET a)(N g i r l )(N g i r l ) )(2 3 (DET a)) (3 4 (N l i r J ) )~I I  ~ I (@ N N. .
.
.
.
.
.
.
.
.10 7 (S .
.
. )
)Figure 4:in parallel.
Also note that such computing agents keep be-ing activated as long as data forms continue to arrive, andcomputing agents acting for S receive messages containing(partial) parse trees with the root node label being S.3 Applieatlons3.1 On-Line Pars ing and Overlap ParsingIn starting the parsing process, our scheme does not re-quire the network of computing agents to be fed any tokenthat indicates the end of an input string.
That is, an inputstring can be processed one by one from the beginning inan on-line fashion.
Even if feeding an input string to thenetwork is suspended in the middle of the "string, partialparse trees can be constructed based on the part of the in-put string that has been fed so far, and the feeding of therest of the input string can be resumed at any moment.Thus, our parsing scheme is quite useful in real-time appli-cations uch as interpreting telephony (simultaneous inter-pretation).
Notice that our scheme does not require thatan input string is fed in the left-to-right manner; wordsin the input string can be fed in any order as long as thepositional information of each word in the input string isaccompanied.
(cf.
Subsection 2.5)Our parsing scheme has no difficulty even when morethan one input string is fed to the network simultaneouslyas long as different input strings are fed separately.
Theseparation can be easily made by attaching the same tag(or token) to each word in the same input string.
Sucha tag is copied and inherited to partial parse trees whichare constructed from the same input string.
When a Type-3 computing agent ests the boundary adjacency betweentwo partial parse trees, the sameness of the tags of the twopartial parse trees are checked additionally.
This capabilityof handling the multiple input strings is useful in process-ing the overlapping utterances by more than two personsengaged in conversation.This way of handling the multiplicity of input strings issimilar to the idea of color tokens used in data-flow com-puter architectures.NP "))l ProcessingP .
.
.
( *  * (NPFigure 5:3.2 UnparsingSuppose the user is typing an input string on a keyboardand s/he hits the 'backspace' key to correct previouslytyped words.
In the case where these incorrect words havealready been fed to the network, our parsing scheme is ableto unpart;e the incorrect portion of the input string andallows the user to retype it.
Furthermore, the user cancontinue to type the rest of the originally intended inputstring.This unparsing capability is realized by the use of anti-messages.
The anti-message/Jefferson85/of a message Msent to a computing agent A is a message that will be sentto A in order to cancel the effects caused by M. The actualtask of cancelling the effects is carried out by A.
(ThusA has been programmed beforehand so that it can acceptcancelling messages and perform the cancelling task.)
Ifnecessary, A must in turn send anti-messages to cancel theeffects caused by the messages A itself has already sent.
Inimplementing the unparsing capability, the express-modemessage passing in ABCL/1/Yonezawa86/is u eful, whichiz a kind of interrupt-like high priority message passing.3.3 Pipe-Linlng to Semantic Processing AgentsOur parsing scheme produces all the possible (partial) parsetrees for a given input string.
In fact, if each Typed com-puting agent in the network stores in its local memory allthe parse trees it constructs, all the components of the tri-angle matrix used in CKY parsing method (i.e., all thepossible parse trees) are in fact stored among the Type-1 agents in the network in a distributed manner.
If thesemantic processing is required, these partial or completeparse trees can be sent to some computing agents which dosemantics processing.Actually, parse trees can be sent to semantic processingagents in a pipe..liniTtg manner.
Suppose a Type-1 com-puting agent Npl is acting for an occurrence of a non-terminal symbol NP.
Instead of letting Npl distribute theparse trees it constructs o Type-2 or Type-3 agents actingfor occurrences ofthe symbol NP, we can let Npl send theparse trees to the semantics processing agent which checksthe semantic validity of the parse trees in tim pipe-liningmanner.
After filtered by the semantic processing agent,only semantically valid parse trees (possibly with seman-tics information being attached) are distributed to Type-2or Type-3 computing agents acting for NP.
See Figure 5.These ,~emantic filtering agents can be inserted at anylinks between Type-1 agents and Type-2 or Type-3 agents.The complete separation of the semantic processing phasefrom the syntactic processing phase in usual natural lan-guage processing systems corresponds to the placing se-mantic processing agents only after the Type-1 computingagents that act for tile non-terminal symbol S that standsfor correct sentences.4 Analysis and Discussion4.1 Implementat ion a d ExperimentOur parsing scheme has been implemented using an object-oriented concurrent language ABCL/1.
In this implemen-tation, each computing agent in the network is representedas an ABCL/1 object which becomes active when it receivea message~ and data forms containing partial parse trees arerepresented asmessages that are passed around by objects.The parsing program written in ABCL/1 runs on a stan-dard single-cpu machine (e.g., Symbolics Lisp machines andSun3s) in which parallelism is simulated by time-slicing.
(The code for a simplified version of this program and sam-ple session are given in /Yonezawa87a/.)
Using this prc~gram, we have been conducting an experiment ofour pro-posed parsing scheme for a context-free English grammar/Tomita86/with t e following characteristics:?
224 context-free rules for non-terminal symbols (e.g.,NP -> DET N),?
445 context-free rules for terminal symbols (e.g., N ->fly),?
94 distinct nonterminal symbols and 679 occurrences,and?
295 distinct erminal symbols and 445 occurrences.About 40 input sentences are used for the experiment andthey are typically: 10 - 30 in length, and 10 - 20 in height(the height of a correct parse tree).4.2 The Number of Comput ing Agents (Objects)As is obvious from the construction of the network, thenumber of computing agents is exactly the same as that ofthe nodes of the network.
Since the node set of the networkhas one-to-one correspondence to the set of symbol occur-rences in a given set of grammar rules, the nmnber of com-puting agents can be very large if the grammar iscomplex.Thus the number of computing agents (i.e., objects) of thenetwork representing the above English grammar amountsto more than 1100 (more exactly 1124 = 445+679).Of course, not all these agents can be active simultane-ously.
The number of all the agents that become activein processing an input string is small compared to that ofthe computing agents consisting of the network.
Since themain task of a Type-1 agent (acting for the left symbol of agrammar rule) is just to distribute a constructed parse tree,this task Can be performed by the Type-3 agent which actsfor the rightmost right symbol of the grammar rule.
Thusall the Typed ag~ents can be eliminated.
This reduces thenumber of computing agents considerably.
Furthermore,there are number of other ways to reduce the number ofcomputing agents at the sacrifice of both processing speedand the conceptual clarity of the parsing scheme.
(We,however, believe that maturity of the technology for ex-ploitation of parallelism will dispel the apprehensions re-garding the number of computing agents.
)7774.3 Performance Analysis by Distr ibuted EventSimulationWe are interested in the performance of our parsing schemein the case where the scheme is implemented on a paral-lal architecture which allocates a single processor for eachcomputing agent (i.e., object) in the network.
Since it isnot much interesting to theoretically analyze the complex-ity of our parsing scheme, we have conducted simulation.The simulation has been done by using a distributedevent simulation technique.
The very parsing programwritten in ABCL/1 was reused and slightly modified toform our distributed simulation program.
As we mentionedabove, the Original parsing program is written in such a waythat each computing agent in the network is represetntedby a concurrently executable object which becomes activewhen it receives a message.
The simulation program pre-serves the original network structure of objects (i.e., com-puting agents in the scheme) of the parsing program.
Theonly modifications made to the original parsing programare:?
each object keeps its local time,?
each message passed around by objects additionallycontains a time stamp indicating the time of the mes-sage transmission measured at the local time of theobject which sent the message,?
each object sends anti-messages~Jefferson85/when itreceives a message containing a time stamp indicat-ing an earlier time than the current local time of theobject, and?
accordingly, each object can handle an anti-messagewhich requests to cancel the effects made by the orig-inal message.The initial result of our simulation is that the first com-plete parse tree is produced from the network in 0(n.h)time, measuring from the beginning of feeding an inputstring to the network, where n is the length of the inputstring and h is the height of the parse tree (not the height of.the network).
This result was obtained for the context-freeEnglish grammar mentioned in Section 4.1.
In this simu-lation we assumed that both processing of a partial parsetree by a single object (i.e., a single computing agent) anda message transmission between two objects (i.e., two com-puting agents) take a single unit time.Since all the possible complete parse trees for a giveninput string are produced from the network in the pipe-lining manner, the second and subsequent complete treesare expected to be produced in a short interval one by one.We have not yet analyzed the simulation results for theseparse trees.4 .4  General i ty of the Parsing SchemeOur parsing scheme can handle the most general class ofcontext free grammars except cyclic grammars.
If a setof grammar ules has circularity 9, infinite message pass-ing may take place in the network.
To detect or avoidsuch infinite message passing~ a special provision must bemade.
But fortunately such a provision can be done at thetime of compiling the set of grammar ules into the cor-responding network of computing agents.
As suggested in2A simple example of circular ules is:  1 --> B, B - - )  A, B -->C.Subsection 2.2 and Figure 2, left-recursive grammar rulescan be handled without any modification to the grammarrules.
However, from the nature of bottom-up arsing, ourparsing scheme cannot handle an e-rule (a rule that pro-duces a null string).
But ms is well known/Hopcroft79/, allthe e-rules can be eliminated from a given set of grammarrules by transforming the set of rules without changing thegenerative power of the original set of rules.
3 It shouldbe noted that our scheme can be extended to cope withcontext-sensitive grammars (or more expressive ones).4.5 Previous WorkR.M.
Kaplan advocated in /Kaplan73/ that natural an-guage parsing should be conceptualized and implementedas a collection of asyncbronous communicating parallel pro-cesses.
Our work is basically along his line, but our algo-rithm is completely different from his and is based on finergrain and more massive parallelism than his idea illustratedin/Kaplan73/.References\[Agha86\] G. Agha, Actors: A Model of Concurrent Com-putation in Distributed Systems, The MIT Press, 1986.\[Gazdar85\] G. Gazdar, E. Klein, G. K. Pullum and I. A.Sag, Generalized Phrase Structure Grammar, BasicBlackwell Publisher, 1985.\[Gelernter86\] D. Gelernter, Domesticating Parallelism,IEEE Computers, No.
8, 1986.\[Gottlieb83\] A. Gottlieb et al: The NYU Ultracomputer- Designing an MIMD Shared Memory Parallel Com-puter, IEEE Trans.
Computers, C-32, No.2, 1983.\[Hopcroft79\] J. E. H0pcroft and :I. D. Ullman, Introduc.lion to Automata Theory, Languages, and Computa-tion, Addison-Wesley, 1979.\[Jefferson85\] D. R. Jefferson: Virtual Time, ACM Trans.Prog.
Lang.
Syst., Vol.7, No.3, 1985.\[Kaplan73\] R. M. Kaplan: A,Multi-Processing Approachto Natural Language , Proc.
NCC, 1973.\[Kaplan82\] R. M. Kaplan and J. Bresnan: Lexical-Functional Grammar: A Formal System for Gram-mar Representation, i  The Menlal Representationof Grammatical Relations J. Bresnan (ed.
), The MITPress, 1982.\[Kay67\] M. Kay: Experiments with a Powerful Parser,RM-5,~52-PR, The Rand Corporation, 1967.\[Seitz85\] C. L. Seitz: The Cosmic Cube, CACM, Vol.28,No.
I, 1985.\[Tomita86\] M. Tomita, Efficient Parsing for Natural Lan-guage, Kluwer Academic Publisher, 1986.\[Yonezawa86\] A. Yonezawa, J.-P. Briot and E. Shibayama:Object-Oriented Concurrent Programmingin ABCL/1, Proc.
1st ACM Symposium on Object-Orie,ted Programming, Systems, Languages, and Ap-plications, 1983.\[Yonezawa87\] A. Yonezawa and M. Tokoro (Eds), Object-Oriented Concurrent Programming, The MIT Press,1987.\[Yonezawa87a\] A, Yonezawa and I. Ohsawa: A New Ap-proach to Parallel Parsing for Context-Free Gram-mars, Res.
Report, C-78, Dept.
of Info.
Sci., TokyoInst.
of Tech., September 1978.3The original anguage is assumed to contain no null symbol.778
