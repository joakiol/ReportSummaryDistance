From Structured Prediction to Inverse Reinforcement LearningHal Daume?
IIISchool of Computing, University of Utahand UMIACS, University of Marylandme@hal3.name1 IntroductionMachine learning is all about making predictions;language is full of complex rich structure.
Struc-tured prediction marries these two.
However,structured prediction isn?t always enough: some-times the world throws even more complex dataat us, and we need reinforcement learning tech-niques.
This tutorial is all about the how and thewhy of structured prediction and inverse reinforce-ment learning (aka inverse optimal control): par-ticipants should walk away comfortable that theycould implement many structured prediction andIRL algorithms, and have a sense of which onesmight work for which problems.2 Content OverviewThe first half of the tutorial will cover the ?ba-sics?
of structured prediction: the structured per-ceptron and Magerman?s incremental parsing al-gorithm.
It will then build up to more advanced al-gorithms that are shockingly reminiscent of thesesimple approaches: maximum margin techniquesand search-based structured prediction.The second half of the tutorial will ask the ques-tion: what happens when our standard assump-tions about our data are violated?
This is whatleads us into the world of reinforcement learning(the basics of which we?ll cover) and then to in-verse reinforcement learning and inverse optimalcontrol.Throughout the tutorial, we will see exam-ples ranging from simple (part of speech tagging,named entity recognition, etc.)
through complex(parsing, machine translation).The tutorial does not assume attendees knowanything about structured prediction or reinforce-ment learning (though it will hopefully be inter-esting even to those who know some!
), but doesassume some knowledge of simple machine learn-ing (eg., binary classification).3 Tutorial OutlinePart I: Structured prediction?
What is structured prediction??
Refresher on binary classification?
What does it mean to learn??
Linear models for classification?
Batch versus stochastic optimization?
From perceptron to structured perceptron?
Linear models for structured prediction?
The ?argmax?
problem?
From perceptron to margins?
Search-based structured prediction?
Training classifiers to make parsing de-cisions?
Searn and generalizationsPart II: Inverse reinforcement learning?
Refersher on reinforcement learning?
Markov decision processes?
Q learning?
Inverse optimal control and A* search?
Maximum margin planning?
Learning to search?
Apprenticeship learning?
Open problemsReferencesSee http://www.cs.utah.edu/?suresh/mediawiki/index.php/MLRG/spring10.
