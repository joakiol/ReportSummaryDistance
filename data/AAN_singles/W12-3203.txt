Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 22?32,Jeju, Republic of Korea, 10 July 2012. c?2012 Association for Computational LinguisticsDiscovering Factions in the Computational Linguistics CommunityYanchuan Sim Noah A. SmithLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USA{ysim,nasmith}@cs.cmu.eduDavid A. SmithDepartment of Computer ScienceUniversity of MassachusettsAmherst, MA 01003, USAdasmith@cs.umass.eduAbstractWe present a joint probabilistic model of whocites whom in computational linguistics, andalso of the words they use to do the citing.
Themodel reveals latent factions, or groups of in-dividuals whom we expect to collaborate moreclosely within their faction, cite within the fac-tion using language distinct from citation out-side the faction, and be largely understandablethrough the language used when cited fromwithout.
We conduct an exploratory data anal-ysis on the ACL Anthology.
We extend themodel to reveal changes in some authors?
fac-tion memberships over time.1 IntroductionThe ACL Anthology presents an excellent datasetfor studying both the language and the social con-nections in our evolving research field.
Extensivestudies using techniques from the field of biblio-metrics have been applied to this dataset (Radev etal., 2009a), quantifying the importance and impactfactor of both authors and articles in the commu-nity.
Moreover, recent work has leveraged the avail-ability of digitized publications to study trends andinfluences within the ACL community (Hall et al,2008; Gerrish and Blei, 2010; Yogatama et al, 2011)and to analyze academic collaborations (Johri et al,2011).To the best of our knowledge, however, existingwork has mainly pursued ?macroscopic?
investiga-tions of the interaction of authors in collaboration,citation networks, or the textual content of wholepapers.
We seek to complement these results with a?microscopic?
investigation of authors?
interactionsby considering the individual sentences authors useto cite each other.In this paper, we present a joint model of whocites whom in computational linguistics, and also ofhow they do the citing.
Central to this model is theidea of factions, or groups of individuals whom weexpect to (i) collaborate more closely within theirfaction, (ii) cite within the faction using languagedistinct from citation outside the faction, (iii) belargely understandable through the language usedwhen cited from without, and (iv) evolve over time.1Factions can be thought of as ?communities,?
whichare loosely defined in the literature on networksas subgraphs where internal connections are denserthan external ones (Radicchi et al, 2004).
The dis-tinction here is that the strength of connections de-pends on a latent language model estimated from ci-tation contexts.This paper is an exploratory data analysis using aBayesian generative model.
We aim both to discovermeaningful factions in the ACL community and alsoto illustrate the use of a probabilistic model for suchdiscovery.
As such, we do not present any objectiveevaluation of the model or make any claims that thefactions optimally explain the research community.Indeed, we suspect that reaching a broad consensusamong community members about factions (i.e., a?gold standard?)
would be quite difficult, as any so-cial community?s factions are likely perceived very1Our factions are computational abstractions?clusters ofauthors?discovered entirely from the corpus.
We do not claimthat factions are especially contentious, any more than ?sub-communities?
in social networks are especially collegial.22subjectively.
It is for this reason that a probabilisticgenerative model, in which all assumptions are madeplain, is appropriate for the task.
We hope this analy-sis will prove useful in future empirical research onsocial communities (including scientific ones) andtheir use of language.2 ModelIn this paper, our approach is a probabilistic modelover (i) coauthorship relations and (ii) the wordsin sentences containing citations.
The words areassumed to be generated by a distribution that de-pends on the (latent) faction memberships of the cit-ing authors, the cited authors, and whether the au-thors have coauthored before.
To model these dif-ferent effects on language, we use a sparse additivegenerative (SAGE) model (Eisenstein et al, 2011).In contrast to the popular Dirichlet-multinomial fortopic modeling, which directly models lexical prob-abilities associated with each (latent) topic, SAGEmodels the deviation in log frequencies from a back-ground lexical distribution.
Imposing a sparsity-inducing prior on the deviation vectors limits thenumber of terms whose probabilities diverge fromthe background lexical frequencies, thereby increas-ing robustness to limited training data.
SAGE can beused with or without latent topics; our model doesnot include topics.
Figure 1 shows the plate diagramfor our model.We describe the generative process:?
Generate the multinomial distribution over fac-tion memberships from a Dirichlet distribution:?
?
Dir(?).?
Generate the binomial distribution for whethertwo authors coauthor, given that they are in thesame faction, from a Beta distribution: ?same?Beta(?same0 , ?same1 ).
Generate the analogous bi-nomial, given that they are in different factions:?diff?
Beta(?diff0 , ?diff1 ).?
For each author i, draw a faction indicatorai ?
Multinomial(?).?
For all ordered pairs of factions (g, h), draw adeviation vector ?(g,h)?
Laplace(0, ?).
Thisvector, which will be sparse, corresponds to the??a(i)a(j)z(i,j)?same?same?diff?diffw(i,j)N(i,j)A?Am?
(g,h)?G?GFigure 1: Plate diagram for our graphical model.
A andG are the fixed numbers of authors and factions, respec-tively.
m is the background word distribution, ?, ?
, ?are hyperparameters, a are latent author factions, z andw are the observed coauthorship relations and observedwords in citation sentences between authors, respectively.Each of the a(i), denoting author i?s faction alignment,are sampled once every iteration conditioned on all theother a(j).
If i and j are coauthors or i cited j in somepublication, a(i)and a(j)will not be conditionally inde-pendent due to the v-structure.
?sameand ?diffare bino-mial distributions over whether two authors have collab-orated together before, given that they are assigned to thesame/different factions.
Dashed variables are collapsedout in the Gibbs sampler, while double bordered variablesare optimized in the M-step.deviations in word log-frequencies when fac-tion g is citing faction h.?
For each word v in the vocabulary, let the uni-gram probability that an author in faction g usesto cite an author in faction h be?
(g,h)v =exp(?
(g,h)v +mv)?v?
exp(?(g,h)v?
+mv?).?
For each ordered pair of authors (i, j),?
For each word that i uses to cite j, draww(i,j)k ?
Multinomial(?(a(i),a(j))).?
If the authors are from the same faction,i.e., a(i) = a(j), draw coauthorship indi-23cator z(i,j)?
Binomial(?same); else, drawz(i,j)?
Binomial(?diff).Thus, our goal is to maximize the conditional like-lihood of the observed datap(w, z | ?,?, ?,m,?)
=????
?ap(w, z,?,?,a | ?,?, ?,m,?
)with respect to ?
and ?.
We fix ?
and ?, which arehyperparameters that encode our prior beliefs, andm, which we assume to be a fixed background worddistribution.Exact inference in this model is intractable, so weresort to an approximate inference technique basedon Markov Chain Monte Carlo simulation.
We per-form Bayesian inference over the latent author fac-tions while using maximum a posteriori estimatesof ?
because Bayesian inference of ?
is problematicdue to the logistic transformation.
We refer the in-terested reader to Eisenstein et al (2011).
We takean empirical Bayes approach to setting the hyper-parameter ?.
Our overall learning procedure is aMonte Carlo Expectation Maximization algorithm(Wei and Tanner, 1990).3 Learning and InferenceOur learning algorithm is a two-step iterative pro-cedure.
During the E-step, we perform collapsedGibbs sampling to obtain distributions over factionsfor each author, given the current setting of the hy-perparameters.
In the M-step, we obtain point es-timates for the hyperparameters ?
and ?
given thecurrent posterior distributions for the author fac-tions.3.1 E-stepAs the Dirichlet and Beta distributions are conjugatepriors to the multinomial and binomial respectively,we can integrate out the latent variables ?, ?
(same)and ?(diff).
For an author i, we sample his factionalignment a(i)conditioned on faction assignmentsto all other authors and citation words between i andother authors (in both directions).
Denoting a?iasthe current faction assignments for all the authorsexcept i,p(a(i) = g | a(?i),w,?,?,?)?
p(a(i) = g,a(?i),w | ?,?,?)?
(Ng + ?g)A?j?z +Nz?0 + ?1 +N0 +N1p(w(i) | ?
)where Ng is the number of authors (except i) whoare assigned to faction g, ij = ?same?
if g = a(j)and ij = ?diff?
otherwise, and N 1, N0 denotesthe number of author pairs that have/have not coau-thored before respectively, given the status of theirfactions .
We elide the subscripts of  and super-script of z for notational simplicity and abuse nota-tion to let w(i)refer to all author i?s citation words,both incoming and outgoing.
Using SAGE, the fac-tor for an author?s words isp(w(i) | ?)
=?j?v(?
(g,a(j))v)w(i,j)v (?
(a(j),g)v)w(j,i)vwhere w(i,j)v is the observed count of the number oftimes word v has been used when author i cites j; jranges over the A authors.We sample each author?s faction in turn and do soseveral times during the E-step, collecting samplesto estimate our posterior distribution over a.3.2 M-stepIn the M-step, we optimize all ?
(g,h)and ?
giventhe posterior distribution over author factions.Optimizing ?.
Eisenstein et al (2011) postu-lated that the components of ?
are drawn froma compound model?N (?
;?, ?)E(?
; ?
)d?, whereE(?
; ?)
indicates the Exponential distribution.
Theyfit a variational distribution Q(?)
and optimized thelog-likelihood of the data by iteratively fitting theparameters ?
using a Newton optimization step andmaximizing the variational bound.The compound model described is equivalent tothe Laplace distribution L(?
;?, ?)
(Lange and Sin-sheimer, 1993; Figueiredo, 2003).
Moreover, a zeromean Laplace prior has the same effect as placing anL1 regularizer on ?.
Therefore, we can equivalently24maximize the regularized likelihood?c(g,h)?T?(g,h)?
?C(g,h)?
log?vexp(?
(g,h)v +mv)?
?????(g,h)??
?1with respect to ?(g,h).
?c(g,h)?
is a vector of expectedcount of the words that faction g used when citingfaction h, ?c(g,h)?
=?v ?c(g,h)v ?
and ?
is the regu-larization constant.
The regularization constant andLaplace variance are related by ?
= ?
?1 (Tibshirani,1996).We use the gradient-based optimization routineOWL-QN (Andrew and Gao, 2007) to maximize theabove objective function with respect to ?
(g,h)foreach pair of factions g and h.Optimizing ?.
As in the empirical Bayes ap-proach, we learn the hyperparameter setting of ?from the data by maximizing the log likelihoodwith respect to ?.
By treating ?
as the parame-ter of a Dirichlet-multinomial compound distribu-tion, we can directly use the samples of author fac-tions produced by our Gibbs sampler to estimate?.
Minka (2009) describes in detail several itera-tive approaches to estimate ?
; we use the linear-time Newton-Raphson iterative update to estimatethe components of ?.4 Data Analysis4.1 DatasetWe used the ACL Anthology Network Corpus(Radev et al, 2009b), which currently contains18,041 papers written by 12,777 authors.
These pa-pers are published in the field of computational lin-guistics between 1965 and 2011.2Furthermore, thecorpus provides bibliographic data such as authorsof the papers and bibliographic references betweeneach paper in the corpus.
We extracted sentencescontaining citations using regular expressions andlinked them between authors with the help of meta-data provided in the corpus.We tokenized the extracted sentences and down-cased them.
Words that are numeric, appear less2For a list of the journals, conferences and workshopsarchived by the ACL anthology, please visit http://aclweb.org/anthology-new.than 20 times, or are in a stop word list are dis-carded.
For papers with multiple authors, we dividedthe word counts by the number of pairings betweenauthors in both papers, assigning each word to eachauthor-pair (i.e., a count of1nn?
if a paper with n au-thors cites a paper with n?authors).Due to the large number of authors, we only usedthe 500 most cited authors (within the corpus) whohave published at least 5 papers.
Papers with no au-thors left are removed from the dataset.
As a re-sult, we have 8,144 papers containing 80,776 cita-tion sentences (31,659 citation pairs).
After text pro-cessing, there are 391,711 tokens and 3,037 wordtypes.In each iteration of the EM algorithm, we run theE-step Gibbs sampler for 300 iterations, discardingthe first 100 samples for burn-in and collecting sam-ples at every 3rd iteration to avoid autocorrelation.At the M-step, we update our ?
and ?
using thesamples collected.
We run the model for 100 EMiterations.We fixed ?
= 5, ?same = (0.5, 1) and ?diff =(1, 0.5).
Our setting of ?
reflects our prior beliefsthat coauthors tend to be from the same faction.4.2 Factions in ACL (1965?2011)We ran the model withG = 30 factions and selectedthe most probable faction for each author from theposterior distribution of the author-faction alignmentobtained in the final E step.
Only 26 factions wereselected as most probable for some author.3Table 1presents members of selected factions, along withcitation words that have the largest positive log fre-quency deviation from the background distribution.4Table 2 shows a list of the top three authors associ-ated with factions not shown in Table 1.
Incoming(outgoing) citation words are found by summing thelog deviation vectors ?
across citing (cited) factions.The author factions are manually labeled.We see from Table 1, the model has selected key-words that are arguably significant in certain sub-fields in computational linguistics.
Incoming cita-tions are generally indicative of the subject areas in3In future work, nonparametric priors might be employed toautomate the selection of G.4We found it quite difficult to make sense of terms with neg-ative log frequency deviations.
This suggests exploring a modelallowing only positive deviations; we leave that for future work.25Formalisms (31) Fernando Pereira, Jason M. Eisner, Stuart M. Shieber, Walter Daelemans, Hitoshi Isa-haraSelf cites: parsingIn cites: parsing, semiring, grammars, tags, grammar, tag, lexicalized, dependencyOut cites: tagger, regular, dependency, transformationbased, tagging, stochastic, grammars, senseEvaluation (17) Salim Roukos, Eduard Hovy, Marti A. Hearst, Chin-Yew Lin, Dekang LinSelf cites: automatic, bleu, linguistics, evaluation, computational, text, proceedingsIn cites: automatic, bleu, segmentation, method, proceedings, dependency, parses, textOut cites: paraphrases, cohesion, agreement, hierarchical, entropy, phrasebased, evaluation, tree-bankSemantics (26) Martha Palmer, Daniel Jurafsky, Mihai Surdeanu, David Weir, German RigauSelf cites: sense, semantic, wordnetIn cites: framenet, sense, semantic, task, wordnet, word, project, questionOut cites: sense, wordnet, moses, preferences, distributional, semantic, focus, supersenseMachine Translation(MT1) (9)Kevin Knight, Michel Galley, Jonathan Graehl, Wei Wang, Sanjeev P. KhudanpurSelf cites: inference, scalable, modelIn cites: scalable, inference, machine, training, generation, translation, model, syntaxbasedOut cites: phrasebased, hierarchical, inversion, forest, transduction, translation, ibm, discourseWord Sense Disam-biguation (WSD) (42)David Yarowsky, Rada Mihalcea, Eneko Agirre, Ted Pedersen, Yorick WilksSelf cites: sense, wordIn cites: sense, preferences, wordnet, acquired, semcor, word, semantic, calleOut cites: sense, subcategorization, acquisition, automatic, corpora, lexical, processing, wordnetParsing (20) Michael John Collins, Eugene Charniak, Mark Johnson, Stephen Clark, MassimilianoCiaramitaSelf cites: parser, parsing, model, perceptron, parsers, dependencyIn cites: parser, perceptron, supersense, parsing, dependency, results, hmm, modelsOut cites: parsing, forest, treebank, model, coreference, stochastic, grammar, taskDiscourse (29) Daniel Marcu, Aravind K. Joshi, Barbara J. Grosz, Marilyn A. Walker, Bonnie LynnWebberSelf cites: discourse, structure, centeringIn cites: discourse, phrasebased, centering, tag, focus, rhetorical, tags, lexicalizedOut cites: discourse, rhetorical, framenet, realizer, tags, resolution, grammars, synonymsMachine Translation(MT2) (9)Franz Josef Och, Hermann Ney, Mitchell P. Marcus, David Chiang, Dekai WuSelf cites: training, errorIn cites: error, giza, rate, alignment, training, minimum, translation, phrasebasedOut cites: forest, subcategorization, arabic, model, translation, machine, models, heuristicTable 1: Key authors and citation words associated with some factions.
For each faction, we show the 5 authors withhighest expected incoming citations (i.e p(faction | author) ?
citations).
Factions are labeled manually, referring tokey sub-fields in computational linguistics.
Faction sizes are in parenthesis following the labels.
The citation wordswith the strongest positive weights in the deviation vectors are shown.which the faction holds recognized expertise.
Forinstance, the faction labeled ?semantics?
has cita-tion terms commonly associated with propositionalsemantics: sense, framenet, wordnet.
On the otherhand, outgoing citations hint at the related work thata faction builds on; discourse might require buildingon components involving framenet, grammars, syn-onyms, while word sense disambiguation involvessolving problems like acquisition and modeling sub-categorization.4.3 SensitivityGiven the same initial parameters, we found ourmodel to be fairly stable across iterations of Monte26Adam Lopez, Paul S. Jacobs (2)Regina Barzilay, Judith L. Klavans, Robert T. Kasper (3)Lauri Karttunen, Kemal Oflazer, Kimmo Koskenniemi (3)John Carroll, Ted Briscoe, Scott Miller (7)Vincent J. Della Pietra, Stephen A. Della Pietra, Robert L.Mercer (25)Thorsten Brants, Liang Huang, Anoop Sarkar (9)Christoph Tillmann, Kenji Yamada, Sharon Goldwater (7)Alex Waibel, Keh-Jiann Chen, Katrin Kirchhoff (3)Lynette Hirschman, Claire Cardie, Vincent Ng (26)Erik F. Tjong Kim Sang, Ido Dagan, Marius Pas?ca (21)Yuji Matsumoto, Dragomir R. Radev, Chew Lim Tan (18)Christopher D. Manning, Owen Rambow, Ellen Riloff (19)Richard Zens, Hieu Hoang, Nicola Bertoldi (9)Dan Klein, Jun?ichi Tsujii, Yusuke Miyao (6)Janyce Wiebe, Mirella Lapata, Kathleen R. McKeown (50)I. Dan Melamed, Ryan McDonald, Joakim Nivre (10)Philipp Koehn, Lillian Lee, Chris Callison-Burch (80)Kenneth Ward Church, Eric Brill, Richard M. Schwartz(19)Table 2: Top 3 authors of the remaining 18 factions notdisplayed in Table 1.Carlo EM.
We found that when G was too small(e.g., 10), groups were more mixed and the ?
vectorscould not capture variation among them well.
WhenG was larger, the factions were subjectively cleaner,but fields like translation split into many factions (asis visible in the G = 30 case illustrated in Tables 1and 2.
Strengthening the L1 penalty made ?
moresparse, of course, but gave less freedom in fitting thedata and therefore more grouping of authors into afewer effective factions.4.4 Inter-Faction RelationshipsBy using the most probable a posteriori faction foreach author, we can compute the number of cita-tions between factions.
We define the average inter-faction citations by:IFC(g, h) =?
(g ?
h) + ?(h?
g)Ng +Nh(1)where ?
(g ?
h) is the total number of papers writ-ten by authors in g that cite papers written by authorsin h.Figure 2 presents a graph of selected factionsand how these factions talk about each other.
Aswe would expect, the machine translation faction isquite strongly connected to formalisms and parsingfactions, reflecting the heavy use of grammars andAverageout-citation countsFormalismsEvaluationMT 1ParsingMT 2SemanticsWSDDiscourseFormalismsEvaluationMT 1ParsingMT 2SemanticsWSDDiscourseFigure 3: Heat map showing citation rates across selectedfactions.
Factions on the horizontal axis are being cited;factions on the vertical axis are citing.
Darker shades de-note higher average?
(g?h)Ng.parsing algorithms in translation.
Moreover, we canobserve that ?deeper?
linguistics research, such assemantics and discourse, are less likely to be citedby the other factions.
This is reflected in Figure 3,where the statistical MT and parsing factions in thebottom left exhibit higher citation activity amongsteach other.
In addition, we note that factions tend toself-cite more often than out of their own factions;this is unsurprising given the prior we selected.The IFC between discourse and MT2 (as shownby the edge thickness in figure 2) is higher than ex-pected, given our prior knowledge of the computa-tional linguistics community.
Further investigationrevealed that, Daniel Marcu, posited by our modelto be a member of the discourse faction, has coau-thored numerous highly cited papers in MT in re-cent years (Marcu and Wong, 2002).
However, themodel split the translation field, which fragmentedthe counts of MT related citation words.
Thus,assigning Daniel Marcu to the discourse faction,which also has a less diverse citation vocabulary, ismore probable than assigning him to one of the MTfactions.
In ?4.6, we consider a model of factionsover time to mitigate this problem.4.5 Comparison to Graph ClusteringWork in the field of bibliometrics has largely fo-cused on using the link structure of citation net-works to study higher level structures.
See Osareh(1996) for a review.
Popular methods include bib-liographic coupling (Kessler, 1963), and co-citation27DiscourseFormalismsMT 2ParsingSemanticsWord SenseDisambiguation?parse,parsing,training?model,algorithms,grammar?alignment,giza,using,model?parsing,parser,percep-tron,hmm,dependency?alignment, giza, training?phrase, model, joint,translation, probability?parsing?parsing?preferences,sense,word-net,acquired,semcor?sense,semantic,lexical,wordnet,disambiguation?using, alignment,giza, translation, model?memory, judges,voice, allow, sequences?tags,lexicalized,gram-mars,adjoining,trees?tags,grammars,lexical-ized,synchronous,formalism?supersense,results,wordnet,parsing,perceptron?task,informationFigure 2: Citations among some factions.
The size of a node is relative to the faction size and edge thickness is relativeto the average number of inter-faction citations (equation 1).
The words on the edges are the highest weighted wordsfrom the deviation vectors ?, with the arrow denoting the direction of the citation.
Edges with below average IFCscores are represented as dashed lines, and their citations words are not shown to preserve readability.analysis (Small, 1973).
By using authors as an unitof analysis in co-citation pairs, author co-citationshave been presented as a technique to analyze theirsubject specialties (White and Griffith, 1981).
Usingstandard graph clustering algorithms on these authorco-citation networks, one can obtain a semblance ofauthor factions.
Hence, we performed graph clus-tering on both collaboration and citation graphs5ofauthors in our dataset using Graclus6, a graph clus-tering implementation based on normalized cuts andratio associations (Dhillon et al, 2004).In Table 3, we compare, for selected authors,how their faction-mates obtained by our model andgraph clustering differ.
When clustering on the au-thor collaboration network, we obtained some clus-ters easily identified with research labs (e.g., DanielMarcu at the Information Sciences Institute).
Theco-citation graph leads to groupings dominated by5We converted the directed citation graph into a symmetricgraph by performing bibliometric symmetrization described inSatuluri and Parthasarathy (2011, section 3.3).6http://www.cs.utexas.edu/users/dml/Software/graclus.htmlheavily co-cited papers in major research areas.While we do not have an objective measurementof quality or usefulness, we believe that the fac-tions identified by our model align somewhat bet-ter with familiar technical themes around whichsub-communities naturally form than major researchproblems or institutions.4.6 Factions over TimeFaction alignments may be dynamic; we expect that,over time, individual researchers may move fromone faction to another as their interests evolve.
Weconsider a slightly modified model whereby authorsare split into different copies of themselves during anon-overlapping set of discrete time periods.
Givena set of disjoint time periods T , we denote eachauthor-faction node by {a(i,t)| (i, t) ?
A?
T}.
Aswe treat each ?incarnation?
of an author as a distinctindividual, we can simply use the same inference al-gorithm described in ?2.
(In future work we mightimpose an expectation of gradual changes along amore continuous representation of time.
)28Our Model Collaboration Network Co-citation NetworkFranz Josef OchFranz Josef Och, Hermann Ney,Mitchell P. Marcus, David Chiang,Dekai WuFranz Josef Och, Hermann Ney, RichardZens, Stephan Vogel, Nicola UeffingFranz Josef Och, Hermann Ney, VincentJ.
Della Pietra, Daniel Marcu, Robert L.Mercererror, giza, rate, alignment, training giza, mert, popovic, moses, alignments giza, bleu, phrasebased, alignment, mertDaniel MarcuDaniel Marcu, Aravind K. Joshi, Bar-bara J. Grosz, Marilyn A. Walker, Bon-nie Lynn WebberDaniel Marcu, Kevin Knight, DanielGildea, David Chiang, Liang HuangFranz Josef Och, Hermann Ney, VincentJ.
Della Pietra, Daniel Marcu, Robert L.Mercerdiscourse, phrasebased, centering, tag,focusphrasebased, forest, cube, spmt, hiero giza, bleu, phrasebased, alignment, mertMichael John CollinsEugene Charniak, Michael John Collins,Mark Johnson, Stephen Clark, Massim-iliano CiaramitaMichael John Collins, Joakim Nivre,Llu?
?s M?arquez, Xavier Carreras, JanHaji?cMichael John Collins, Christopher D.Manning, Dan Klein, Eugene Charniak,Mark Johnsonparser, perceptron, supersense, parsing,dependencypseudoprojective, maltparser, percep-tron, malt, averagedtnt, prototypedriven, perceptron,coarsetofine, pcfgKathleen R. McKeownMirella Lapata, Janyce Wiebe, KathleenR.
McKeown, Dan Roth, Ralph Grish-manKathleen R. McKeown, Regina Barzi-lay, Owen Rambow, Marilyn A. Walker,Srinivas BangaloreKenneth Ward Church, DavidYarowsky, Eduard Hovy, KathleenR.
McKeown, Lillian Leesemantic, work, learning, corpus, model centering, arabic, pyramid, realpro, cue rouge, minipar, nltk, alignment, mon-trealTable 3: Comparing selected factions between our model and graph clustering algorithms.
Authors with highestincoming citations are shown.
For our model, we show the largest weighted words in the SAGE vector of incomingcitations for the faction, while for graph clustering, we show words with the highest tf-idf weight.We split the same data as the earlier sections intofour disjoint time periods, 1965?1989, 1990?1999,2000?2005 and 2006?2011.
The split across timeis unequal due to the number of papers published ineach period: these four periods include 1,917, 3,874,3,786, and 8,105 papers, respectively.
Here we usedG = 20 factions for faster runtime, leading to di-minished interpretability, though the sparsity of thedeviation vectors mitigates this problem somewhat.Figure 4 shows graphical plots of selected authorsand their faction membership posteriors over time(drawn from the final E-step).With a simple extension of the original model,we can learn shifts in the subject area the author ispublishing about.
Consider Eugene Charniak: themodel observed a major change in faction align-ment around 2000, when one of the popular Char-niak parsers (Charniak, 2000) was released; this issomewhat later than Charniak?s interests shifted, andthe earlier faction?s words are not clearly an ac-curate description of his work at that time.
Morefine-grained modeling of time and also accountingfor the death and birth of factions might amelioratethese inconsistencies with our background knowl-edge about Charniak.
The model finds that Ar-avind Joshi was associated with the tagging/parsingfaction in the 1990s and in recent years movedback towards discourse (Prasad et al, 2008).
DavidYarowsky, known for his early work on word sensedisambiguation, has since focused on applying wordsense disambiguation techniques in a multilingualcontext (Garera et al, 2009; Bergsma et al, 2011).As mentioned in the previous section, we observethat the extended model is able to capture DanielMarcu?s shift from discourse-related work to MTwith his work in phrase-based statistical MT (Marcuand Wong, 2002).5 Related WorkA number of algorithms use topic modeling to an-alyze the text in the articles.
Topic models suchas latent Dirichlet alocation (Blei et al, 2003) andits variations have been increasingly used to studytrends in scientific literature (McCallum et al, 2006;Dietz et al, 2007; Hall et al, 2008; Gerrish and Blei,2010), predict citation information (McNee et al,2900.20.40.60.811970-1989 1990-1999 2000-2005 2006-2011yearEugene Charniak00.20.40.60.811970-1989 1990-1999 2000-2005 2006-2011yearAravind K. Joshi00.20.40.60.811990-1999 2000-2005 2006-2011yearDaniel Marcu00.20.40.60.811990-1999 2000-2005 2006-2011yearDavid Y owsky00.20.40.60.811970-1989 1990-1999 2000-2005 2006-2011yearKathleen R. McKeown00.20.40.60.811990-1999 2000-2005 2006-2011yearMichael J. Collins00.20.40.60.811970-1989 1990-1999 2000-2005 2006-2011yearMartha Palmer00.20.40.60.811990-1999 2000-2005 2006-2011yearDaniel Jurafskyparser, parsing, stylistic, treebank, reductionsense, npcomplete, inducing, wsd, unsupervisedbuilding, annotated, discourse, treebank, kappacotraining, scalable, moses, open, implemenframenet, roles, variation, semantic, propbankmoses, meteor, open, bbn, discoverybleu, automatic, method, rouge, evalpcfg, temporal, logic, linguistic, nounbengston, shallow, conll, learning, kernelmultitext, linking, alignment, competitive, bilinguphrasebased, forest, joint, hierarchical, kbestwhats, moses, open, rule, source, syntaxbasedhuman, metric, spade, evaluation, metricsdistributional, rasp, similarity, clustering, deeptagger, pos, entropy, partofspeech, mathematicspropbank, labelled, dependency, lfg, correlationvari, perceptron, ccg, counts, connectivesdependency, parser, proc, parse, parsingcontrastive, minimize, synchron, anneal, logistgiza, lins, minipar, error, alignmentFigure 4: Posterior probability of faction alignment over time periods for eight researchers with significant publicationrecords in at least three periods.
The key for each entry contains the five highest weighted words in the deviationvectors for the faction?s incoming citations.
For each author, we show factions with which he or she is associated withprobability > 0.1 in at least one time period.2002; Ib?a?nez et al, 2009; Nallapati et al, 2008) andanalyze authorship (Rosen-Zvi et al, 2004; Johri etal., 2011).Assigning author factions can be seen as networkclassification problem, where the goal is to labelnodes in a network such that there is (i) a corre-lation between a node?s label and its observed at-tributes and (ii) a correlation between labels of in-terconnected nodes (Sen et al, 2008).
Such collec-tive network-based approaches have been used onscientific literature to classify papers/web pages intoits subject categories (Kubica et al, 2002; Getoor,2005; Angelova and Weikum, 2006).
If we knewthe word distributions between factions beforehand,learning the author factions in our model would beequivalent to the network classification task, whereour edge weights are proportional to the probabilityof coauthorship multiplied by the probability of ob-serving the citation words given the author?s factionlabels.6 ConclusionIn this work, we have defined factions in terms ofhow authors talk about each other?s work, going be-yond co-authorship and citation graph representa-tions of a research community.
We take a first steptoward computationally modeling faction formationby using a latent author faction model and appliedit to the ACL community, revealing both factionsand how they cite each other.
We also extended themodel to capture authors?
faction changes over time.30AcknowledgmentsThe authors thank members of the ARK group and theanonymous reviewers for helpful feedback.
We gratefullyacknowledge technical assistance from Matthew Fiorillo.This research was supported in part by an A?STAR fel-lowship to Y. Sim, NSF grant IIS-0915187 to N. Smith,and the Center for Intelligent Information Retrieval andNSF grant IIS-0910884 for D. Smith.ReferencesG.
Andrew and J. Gao.
2007.
Scalable training of L1-regularized log-linear models.
In Proc.
of ICML.R.
Angelova and G. Weikum.
2006.
Graph-based textclassification: learn from your neighbors.
In Proc.
ofSIGIR.S.
Bergsma, D. Yarowsky, and K. Church.
2011.
Usinglarge monolingual and bilingual corpora to improvecoordination disambiguation.
In Proc.
of ACL.D.
M. Blei, A. Y. Ng, and M. I. Jordan.
2003.
LatentDirichlet alocation.
The Journal of Machine LearningResearch, 3:993?1022.E.
Charniak.
2000.
A maximum-entropy-inspired parser.In Proc.
of NAACL.I.
S. Dhillon, Y. Guan, and B. Kulis.
2004.
Kernel k-means: spectral clustering and normalized cuts.
InProc.
of KDD.L.
Dietz, S. Bickel, and T. Scheffer.
2007.
Unsupervisedprediction of citation influences.
In Proc.
of ICML.J.
Eisenstein, A. Ahmed, and E. P. Xing.
2011.
Sparseadditive generative models of text.
In Proc.
of ICML.M.
A. T. Figueiredo.
2003.
Adaptive sparseness forsupervised learning.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 25(9):1150?1159.N.
Garera, C. Callison-Burch, and D. Yarowsky.
2009.Improving translation lexicon induction from mono-lingual corpora via dependency contexts and part-of-speech equivalences.
In Proc.
of CoNLL.S.
Gerrish and D. M. Blei.
2010.
A language-basedapproach to measuring scholarly impact.
In Proc.
ofICML.L.
Getoor.
2005.
Link-based classification.
In Ad-vanced Methods for Knowledge Discovery from Com-plex Data, pages 189?207.
Springer.D.
Hall, D. Jurafsky, and C. D. Manning.
2008.
Studyingthe history of ideas using topic models.
In Proc.
ofEMNLP.A.
Ib?a?nez, P. Larra?naga, and C. Bielza.
2009.
Predict-ing citation count of bioinformatics papers within fouryears of publication.
Bioinformatics, 25(24):3303?3309.N.
Johri, D. Ramage, D. A. McFarland, and D. Juraf-sky.
2011.
A study of academic collaborations incomputational linguistics using a latent mixture of au-thors model.
In Proc.
of the ACL Workshop on Lan-guage Technology for Cultural Heritage, Social Sci-ences, and Humanities.M.
M. Kessler.
1963.
Bibliographic coupling betweenscientific papers.
American documentation, 14(1):10?25.J.
Kubica, A. Moore, J. Schneider, and Y. Yang.
2002.Stochastic link and group detection.
In Proc.
of AAAI.K.
Lange and J. S. Sinsheimer.
1993.
Nor-mal/independent distributions and their applicationsin robust regression.
Journal of Computational andGraphical Statistics, 2(2):175?198.D.
Marcu and W. Wong.
2002.
A phrase-based, jointprobability model for statistical machine translation.In Proc.
of EMNLP.A.
McCallum, G. S. Mann, and D. Mimno.
2006.
Biblio-metric impact measures leveraging topic analysis.
InProc.
of JCDL.S.
M. McNee, I. Albert, D. Cosley, P. Gopalkrishnan,S.
K. Lam, A. M. Rashid, J.
A. Konstan, and J. Riedl.2002.
On the recommending of citations for researchpapers.
In Proc.
of CSCW.T.
P. Minka.
2009.
Estimating a Dirich-let distribution.
Available online at http://research.microsoft.com/en-us/um/people/minka/papers/dirichlet/minka-dirichlet.pdf.R.
M. Nallapati, A. Ahmed, E. P. Xing, and W. W. Cohen.2008.
Joint latent topic models for text and citations.In Proc.
of KDD.F.
Osareh.
1996.
Bibliometrics, citation analysis andco-citation analysis: A review of literature I. Libri,46(3):149?158.R.
Prasad, N. Dinesh, A. Lee, E. Miltsakaki, L. Robaldo,A.
Joshi, and B. Webber.
2008.
The Penn discoursetreebank 2.0.
In Proc.
of LREC.D.
R. Radev, M. T. Joseph, B. Gibson, and P. Muthukrish-nan.
2009a.
A bibliometric and network analysis ofthe field of computational linguistics.
Journal of theAmerican Society for Information Science and Tech-nology.D.
R. Radev, P. Muthukrishnan, and V. Qazvinian.
2009b.The ACL Anthology Network corpus.
In Proceed-ings of the Workshop on Text and Citation Analysis forScholarly Digital Libraries.F.
Radicchi, C. Castellano, F. Cecconi, V. Loreto,D.
Parisi, and G. Parisi.
2004.
Defining and iden-tifying communities in networks.
Proceedings of theNational Academy of Sciences of the United States ofAmerica, 101(9):2658?2663.31M.
Rosen-Zvi, T. Griffiths, M. Steyvers, and P. Smyth.2004.
The author-topic model for authors and docu-ments.
In Proc.
of UAI.V.
Satuluri and S. Parthasarathy.
2011.
Symmetrizationsfor clustering directed graphs.
In Proc.
of Interna-tional Conference on Extending Database Technology.P.
Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher,and T. Eliassi-Rad.
2008.
Collective classification innetwork data.
AI magazine, 29(3):93.H.
Small.
1973.
Co-citation in the scientific literature:A new measure of the relationship between two docu-ments.
Journal of the American Society for informa-tion Science, 24(4):265?269.R.
Tibshirani.
1996.
Regression shrinkage and selectionvia the lasso.
Journal of the Royal Statistical Society.Series B (Methodological), 58(1):267?288.G.
C. G. Wei and M. A. Tanner.
1990.
A Monte Carloimplementation of the EM algorithm and the poorman?s data augmentation algorithms.
Journal of theAmerican Statistical Association, 85(411):699?704.H.
D. White and B. C. Griffith.
1981.
Author cocitation:A literature measure of intellectual structure.
Jour-nal of the American Society for Information Science,32(3):163?171.D.
Yogatama, M. Heilman, B. O?Connor, C.Dyer, B. R.Routledge, and N. A. Smith.
2011.
Predicting a sci-entific community?s response to an article.
In Proc.
ofEMNLP.32
