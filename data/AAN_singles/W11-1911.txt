Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 76?80,Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational LinguisticsETS: An Error Tolerable System for Coreference ResolutionHao Xiong , Linfeng Song , Fandong Meng , Yang Liu , Qun Liu and Yajuan Lu?Key Lab.
of Intelligent Information ProcessingInstitute of Computing TechnologyChinese Academy of SciencesP.O.
Box 2704, Beijing 100190, China{xionghao,songlinfeng,mengfandong,yliu,liuqun,lvyajuan}@ict.ac.cnAbstractThis paper presents our error tolerable sys-tem for coreference resolution in CoNLL-2011(Pradhan et al, 2011) shared task (closedtrack).
Different from most previous reportedwork, we detect mention candidates based onpacked forest instead of single parse tree, andwe use beam search algorithm based on theBell Tree to create entities.
Experimental re-sults show that our methods achieve promisingresults on the development set.1 IntroductionOver last decades, there has been increasing inter-est on coreference resolution within NLP commu-nity.
The task of coreference resolution is to iden-tify expressions in a text that refer to the same dis-course entity.
This year, CoNLL1 holds a sharedtask aiming to model unrestricted coreference inOntoNotes.2 The OntoNotes project has created alarge-scale, accurate corpus for general anaphoriccoreference that covers entities and events not lim-ited to noun phrases or a limited set of entity types.And Pradhan et al (2007) have ever used this corpusfor similar unrestricted coreference task.Our approach to this year?s task could be dividedinto two steps: mention identification and creationof entities.
The first stage is conducted on the anal-ysis of parse trees produced by input data.
The of-ficial data have provided gold and automatic parsetrees for each sentences in training and development1http://conll.bbn.com/2http://www.bbn.com/ontonotes/set.
However, according to statistics, almost 3%mentions have no corresponding constituents in au-tomatic parse trees.
Since only automatic parse treeswill be provided in the final test set, the effect ofparsing errors are inevitable.
To alleviate this issue,based on given automatic parse trees, we modify astate-of-the-art parser (Charniak and Johnson, 2005)to generate packed forest, and determine mentioncandidates among all constituents from both givenparse tree and packed forest.
The packed forest is acompact representation of all parse trees for a givensentence.
Readers can refer to (Mi et al, 2008) fordetailed definitions.Once the mentions are identified, the left step isto group mentions referring to same object into sim-ilar entity.
This problem can be viewed as binaryclassification problem of determining whether eachmention pairs corefer.
We use a Maximum Entropyclassifier to predict the possibility that two mentionsrefer to the similar entity.
And mainly following thework of Luo et al (2004), we use a beam searchalgorithm based on Bell Tree to obtain the globaloptimal classification.As this is the first time we participate competi-tion of coreference resolution, we mainly concen-trate on developing fault tolerant capability of oursystem while omitting feature engineering and otherhelpful technologies.2 Mention DetectionThe first step of the coreference resolution tries torecognize occurrences of mentions in documents.Note that we recognize mention boundaries only ondevelopment and test set while generating training76Figure 1: Left side is parse tree extracted from develop-ment set, and right side is a forest.
?my daughter?
is amention in this discourse, however it has no correspond-ing constituent in parse tree, but it has a correspondingconstituent NP0 in forest.instances using gold boundaries provided by officialdata.The first stage of our system consists of followingthree successive steps:?
Extracting constituents annotated with NP,NNP, PRP, PRP$ and VBD POS tags from sin-gle parse tree.?
Extracting constituents with the same tags asthe last step from packed forest.?
Extracting Named Entity recognized by givendata.It is worth mentioning that above three steps willproduce duplicated mentions, we hence collect allmentions into a list and discard duplicated candi-dates.
The contribution of using packed forest is thatit extends the searching space of mention candidates.Figure 1 presents an example to explain the advan-tage of employing packed forest to enhance the men-tion detection process.
The left side of Figure 1 isthe automatic parse tree extracted from developmentset, in which mention ?my daughter?
has no corre-sponding constituent in its parse tree.
Under nor-mal strategy, such mention will not be recognizedand be absent in the clustering stage.
However, wefind that mention has its constituent NP0 in packedforest.
According to statistics, when using packedforest, only 0.5% mentions could not be recognizedwhile the traditional method is 3%, that means thetheoretical upper bound of our system reaches 99%compared to baseline?s 97%.Since the requirement of this year?s task isto model unrestricted coreference, intuitively, weshould not constraint in recognizing only nounphrases but also adjective phrase, verb and so on.However, we find that most mentions appeared incorpus are noun phrases, and our experimental re-sults indicate that considering constituents annotatedwith above proposed POS tags achieve the best per-formance.3 Determining CoreferenceThis stage is to determine which mentions belong tothe same entity.
We train a Maximum Entropy clas-sifier (Le, 2004) to decide whether two mentions arecoreferent.
We use the method proposed by Soon, etal.
?s to generate the training instances, where a posi-tive instance is formed between current mention Mjand its closest preceding antecedent Mi, and a neg-ative instance is created by paring Mj with each ofthe intervening mentions, Mi+1, Mi+2,...,Mj?1.We use the following features to train our classi-fier.Features in Soon et al?s work (Soon et al, 2001)Lexical featuresIS PREFIX: whether the string of one mention isprefix of the other;IS SUFFIX: whether the string of one mention issuffix of the other;ACRONYM: whether one mention is the acronymof the other;Distance featuresSENT DIST: distance between the sentences con-taining the two mentions;MEN DIST: number of mentions between twomentions;Grammatical featuresIJ PRONOUN: whether both mentions are pro-noun;I NESTED: whether mention i is nested in an-other mention;J NESTED: whether mention j is nested in an-other mention;Syntax featuresHEAD: whether the heads of two mentions havethe same string;HEAD POS: whether the heads of two mentionshave the same POS;HEA POS PAIRS: pairs of POS of the two men-tions?
heads;77Semantic featuresWNDIST: distance between two mentions inWordNet;I ARG0: whether mention i has the semantic roleof Arg0;J ARG0: whether mention j has the semantic roleof Arg0;IJ ARGS: whether two mentions have the seman-tic roles for similar predicate;In the submitted results, we use the L-BFGS pa-rameter estimation algorithm with gaussian priorsmoothing (Chen and Rosenfeld, 1999).
We set thegaussian prior to 2 and train the model in 100 itera-tions.3.1 Creation of EntitiesThis stage aims to create the mentions detected inthe first stage into entities, according to the predic-tion of classifier.
One simple method is to use agreedy algorithm, by comparing each mention to itsprevious mentions and refer to the one that has thehighest probability.
In principle, this algorithm istoo greedy and sometimes results in unreasonablepartition (Ng, 2010).
To address this problem, wefollow the literature (Luo et al, 2004) and proposeto use beam search to find global optimal partition.Intuitively, creation of entities can be casted aspartition problem.
And the number of partitionsequals the Bell Number (Bell, 1934), which has a?closed?
formula B(n) = 1e??k=0knk!
.
Clearly, thisnumber is very huge when n is large, enumeration ofall partitions is impossible, so we instead designinga beam search algorithm to find the best partition.Formally, the task is to optimize the following ob-jective,y?
= argmax??P?e?
?Prob(e) (1)where P is all partitions, Prob(e) is the cost ofentity e. And we can use the following formula tocalculate the Prob(e),Prob(e) =?i?e,j?epos(mi,mj)+?i?e,j /?eneg(mi,mj)(2)where pos(mi,mj) is the score predicted by clas-sifier that the possibility two mentions mi and mjgroup into one entity, and neg(mi,mj) is the scorethat two mentions are not coreferent.Theoretically, we can design a dynamic algorithmto obtain the best partition schema.
Providing thereare four mentions from A to D, and we have ob-tained the partitions of A, B and C. To incorporateD, we should consider assigning D to each entity ofevery partition, and generate the partitions of fourmentions.
For detailed explanation, the partitionsof three mentions are [A][B][C], [AB][C], [A][BC]and [ABC], when considering the forth mention D,we generate the following partitions:?
[A][B][C][D], [AD][B][C], [A][BD][C],[A][B][CD]?
[AB][C][D], [ABD][C],[AB][CD]?
[A][BC][D], [AD][BC], [A][BCD]?
[ABC][D], [ABCD]The score of partition [AD][B][C] can becalculated by score([A][B][C]) + pos(A,D) +neg(B,D) + neg(C,D).
Since we can computerpos and neg score between any two mentions inadvance, this problem can be efficiently solved bydynamic algorithm.
However, in practice, enumer-ating the whole partitions is intractable, we insteadexploiting a beam with size k to store the top k parti-tions of current mention size, according to the scorethe partition obtain.
Due to the scope limitation, weomit the detailed algorithm, readers can refer to Luoet al (2004) for detailed description, since our ap-proach is almost similar to theirs.4 Experiments4.1 Data PreparationThe shared task provided data includes informationof lemma, POS, parse tree, word sense, predicatearguments, named entity and so on.
In addition tothose information, we use a modified in house parserto generate packed forest for each sentence in devel-opment set, and prune the packed forest with thresh-old p=3 (Huang, 2008).
Since the OntoNotes in-volves multiple genre data, we merge all files and78Mention MUC BCUBED CEAFM CEAFE BLANCbaseline 58.97% 44.17% 63.24% 45.08% 37.13% 62.44%baseline gold 59.18% 44.48% 63.46% 45.37% 37.47% 62.36%sys forest 59.07% 44.4% 63.39% 45.29% 37.41% 62.41%sys btree 59.44% 44.66% 63.77% 45.62% 37.82% 62.47%sys forest btree 59.71% 44.97% 63.95% 45.91% 37.96% 62.52%Table 1: Experimental results on development set (F score).Mention MUC BCUBED CEAFM CEAFE BLANCsys1 54.5% 39.15% 63.91% 45.32% 37.16% 63.18%sys2 53.06% 35.55% 59.68% 38.24% 32.03% 50.13%Table 2: Experimental results on development set with different training division (F score).take it as our training corpus.
We use the sup-plied score toolkit 3 to compute MUC, BCUBED,CEAFM, CEAFE and BLANC metrics.4.2 Experimental ResultsWe first implement a baseline system (baseline)that use single parse tree for mention detectionand greedy algorithm for creation of entities.
Wealso run the baseline system using gold parse tree,namely baseline gold.
To investigate the contribu-tion of packed forest, we design a reinforced sys-tem, namely sys forest.
And another system, namedas sys btree, is used to see the contribution of beamsearch with beam size k=10.
Lastly, we combinetwo technologies and obtain system sys forest btree.Table 1 shows the experimental results on devel-opment data.
We find that the system using beamsearch achieve promising improvement over base-line.
The reason for that has been discussed in lastsection.
We also find that compared to baseline,sys forest and baseline gold both achieve improve-ment in term of some metrics.
And we are glad tofind that using forest, the performance of our sys-tem is approaching the system based on gold parsetree.
But even using the gold parse tree, the im-provement is slight.
4 One reason is that we usedsome lexical and grammar features which are dom-3http://conll.bbn.com/download/scorer.v4.tar.gz4Since under task requirement, singleton mentions are fil-tered out, it is hard to recognize the contribution of packed for-est to mention detection, while we may incorrectly resolve somementions into singletons that affects the score of mention detec-tion.inant during prediction, and another explanation isthat packed forest enlarges the size of mentions butbrings difficulty to resolve them.To investigate the effect of different genres to de-velop set, we also perform following compared ex-periments:?
sys1: all training corpus + WSJ developmentcorpus?
sys2: WSJ training corpus + WSJ developmentcorpusTable 2 indicates that knowledge from other genrescan help coreference resolution.
Perhaps the reasonis the same as last experiments, where syntax diver-sity affects the task not very seriously.5 ConclusionIn this paper, we describe our system for CoNLL-2011 shared task.
We propose to use packed for-est and beam search to improve the performance ofcoreference resolution.
Multiple experiments provethat such improvements do help the task.6 AcknowledgementThe authors were supported by National NaturalScience Foundation of China, Contracts 90920004.We would like to thank the anonymous reviewersfor suggestions, and SHUGUANG COMPUTINGPLATFORM for supporting experimental platform.79ReferencesE.T.
Bell.
1934.
Exponential numbers.
The AmericanMathematical Monthly, 41(7):411?419.E.
Charniak and M. Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative reranking.
InProceedings of the 43rd Annual Meeting on Associ-ation for Computational Linguistics, pages 173?180.Association for Computational Linguistics.Stanley F. Chen and Ronald Rosenfeld.
1999.
A gaussianprior for smoothing maximum entropy models.
Tech-nical report, CMU-CS-99-108.Liang Huang.
2008.
Forest reranking: Discriminativeparsing with non-local features.
In Proceedings ofACL-08: HLT, pages 586?594, Columbus, Ohio, June.Z.
Le.
2004.
Maximum entropy modeling toolkit forPython and C++.X.
Luo, A. Ittycheriah, H. Jing, N. Kambhatla, andS.
Roukos.
2004.
A mention-synchronous corefer-ence resolution algorithm based on the bell tree.
InProceedings of the 42nd Annual Meeting on Associa-tion for Computational Linguistics, pages 135?es.
As-sociation for Computational Linguistics.H.
Mi, L. Huang, and Q. Liu.
2008.
Forestbased transla-tion.
In Proceedings of ACL-08: HLT, pages 192?199.Citeseer.Vincent Ng.
2010.
Supervised noun phrase coreferenceresearch: The first fifteen years.
In Proceedings of the48th Annual Meeting of the Association for Compu-tational Linguistics, pages 1396?1411, Uppsala, Swe-den, July.
Association for Computational Linguistics.Sameer Pradhan, Lance Ramshaw, Ralph Weischedel,Jessica MacBride, and Linnea Micciulla.
2007.
Unre-stricted Coreference: Identifying Entities and Eventsin OntoNotes.
In in Proceedings of the IEEE Inter-national Conference on Semantic Computing (ICSC),September 17-19.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, and Nianwen Xue.2011.
Conll-2011 shared task: Modeling unrestrictedcoreference in ontonotes.
In Proceedings of the Fif-teenth Conference on Computational Natural Lan-guage Learning (CoNLL 2011), Portland, Oregon,June.W.M.
Soon, H.T.
Ng, and D.C.Y.
Lim.
2001.
A ma-chine learning approach to coreference resolution ofnoun phrases.
Computational Linguistics, 27(4):521?544.80
