Fast Generat ion of Abstracts from General DomainText Corpora by Extract ing Relevant SentencesKlaus ZechnerComputat iona l  L ingu is t i cs  P rogramDepar tment  of  Ph i losophy135 Baker  Hal lCarneg ie  Mel lon Un ivers i tyP i t t sburgh ,  PA  15213-3890, USAzechner@andrew,  cmu.
eduAbstractThis paper describes a system for gen-erating text abstracts which relies ona general, purely statistical principle,i.e., on the notion of "relevance", asit is defined in terms of the combina-tion of tf*idf weights of words in a sen-tence.
The system generates abstractsfrom newspaper articles by selecting the"most relevant" sentences and combin-ing them in text order.
Since neitherdomain knowledge nor text-sort-specificheuristics are involved, this system pro-vides maximal generality and flexibility.Also, it is fast and can be efficiently iln-plemented for both on-line and off-linepurposes.
An experiment shows that re-call and precision for the extracted sen-tences (taking the sentences extractedby human subjects as a baseline) iswithin the same range as recall/precisionwhen the human subjects are coinparedamongst each other: this means in factthat tile performance of the system is in-distinguishable from the performance ofa human abstractor.
Finally, the systemyields significantly better results thana default "lead" algorithm does whichchooses just some initial sentences fromthe text.1 Int roduct ionWith increasing amounts of machine readable in-formation being available, one of the major prob-lems for users is to find those texts that are mostrelevant o their interests and needs in as short anamount of time as possible.The traditional IR approach is that the userinputs a boolean query (possibly in a naturallanguage-like formulation) and the system re-sponds by presenting to the user the texts thatare a "best match" to his query.
In corpora whereabstracts are not already provided it might facil-itate the retrieval process a lot if text abstractscould be generated automatically either off-line tobe stored together with tile texts (e.g., as rankedsentence numbers), or on-line, in accordance withthe user's query.So far, there have been two main approachesin this field (for overviews on abstracting andsummarizing see, e.g., (?)
or (?)).
One is ori-ented more towards information extraction, work-ing with a knowledge base in a limited domain("top down", see e.g., (?
; ?
; ?
)), tile other typerelies mainly on various heuristics ("bottom up",see e.g., (?
; ?))
which are less dependent on thedomain but are still at least; tuned to the text sortand thus have to be adapted whenever the systemwould have to be applied outside its original en-vironment.
Combinations of these methods havealso been attempted recently (see e.g.
(?
)).The focus of this paper will be the descriptionand evaluation of an abstracting system whichavoids the disadvantages coming along with mostof these traditional approaches, while still be-ing able to achieve a performance which matchesclosely the results of an identical abstracting taskperformed by human subjects in a comparativestudy.The results indicate that it is indeed possible tobuild a system relying on a simple and efficient al-gorithm, using standard tf*idf weights only, whilestill achieving a satisfying output}2 A System for  Generat ing  TextAbstractsKupiec et al (?)
present the results of a studywhere 80% of the sentences in man-made abstractswere "close sentence matches", i.e., they were "ei-ther extracted verbatim from the original or withminor modifications" (p.70).
Therefore, we arguethat it is not only an easy way but indeed an ap-propriate one for an automatic system to choose anumber of the most relevant sentences and present1By "satisfying" we mean at least indicative for thecontent of ~he respective text, if not also informativeabout it.986these as a "text; abstract;" to the user.
~ We furtherargue that; coherence, although certainly desir-able, is imi)ossible without a large scale knowledgebased 1;ext mldersl;an(ling syst;em which would notonly slow down dm l)erformance signiticantly butnecessarily could not be domain inde,1)endent.Our design goal was to use as simple and effl-cleat an algorithm as t)ossibh',, avoiding "hem(s-tics" and "fe, al;ures" emph)yed by other systems(e.g., (?))
wlfich may be hell)tiff in a specific textdomain but would have to be redesigned wheneverit were ported to a new domain, a In this respect,our system can be compared with the approachof (?)
wit() also t)resent an abstracting system forgeneral domain texts.
However, whereas their fo-cus is on the evaluation of abstracl; readability (asstand-alone texts), ours is rather on abstract rele-vance.
A flirther difference is the (non-standard)method of tf* idfweight ('ah:ulation timy are usingfor their system.Our sysl;em was deveh)ped in C+.t-, using li-braries for dealing with texts marke(l ut) in SGMLformat.
The algorithm performs the followingsl;et)s: 41.
Take an arl;Me fl'om the corl)uS 5 andlmild a word weight; matrix for all con-tellt words across all sentences (l;f*idf(:omputal;ion, where the idf-vahms ttte r(>trieved fl'om a preconqmted file).
(; Iligit fre-(tuency closed class words (like A, THE, ONetc.)
are excluded via a stop list file.2.
Determine the sentence weights for all sen-ten(:es in tim arl;Me: Compltt;e the sum over2Clem'ly, there will be less (:oherence than in a man-made abstract, but, the extracted passages can t)e pre-sented in a way which indicates their relative positionin tim text, thus avoiding a possil)ly wrong inti)ressionof adjacency.aln fact,, it t,urned out that fact,ors which couhl 1)ethought of as %l)ecitic for newspaper articles", su(:has increased weights for title words or sentences inthe beginning, did not have a sign(titan( eriect (m thesys|;el l l~s per \ [ 'o rntance , .4Due to space limitations, we cannot, give all tilt;details here.
The reader is ref('xred t,O (?)
for thereinformation on this algorithm, various odter nte, thotlsthat were tested and their respective result,s.
(Tiffspaper can I)e el)rained Kern t,im author's heine 1)agewhose URL is:ht tp://www.h:l.cmu.e(lu/~zechner/klaus.htnfl.
)'~'We used the Daily Telegral)h Corpus which com-prises approx.
44.000 articles (15 mil l ion words).
(~tt*idf=term frequency in a document (tfk) timest,he logarithm of the nunlber of documents in a collec-l;ion (N), divi(led I)y the IlnI\[lber of do(;untents wherethis term oc(:nrs (Ilk): tfk * log ~_N This formula n kyields a high numl)er for words which are frequent inone dneument but; api)e.ar in very few documents only;hence, they can be considered a.s "indicative" fbr therespective document.all tf*idf-values of the (:on(eat words 7 for eachsentence, s3.
Sort the sentences according to l;heir weightsand extract the N highest weighted sentencesin text order to yield (,he abstract of the doc-llHleltt.To r(~thtce the size of the vocabulary, our system(;()nv(',rts every word to Ul)I)er (:ase and (runt:aleswords after the sixth character.
This is also rout:itfaster than a word stemming algorithm which hasto perh)rm a inorphological analysis.
For our ex-periment;s, the, amount of new ambiguities therebyintroduced id not cause specific problems for timsystem.For the test set, we (:host', 6 articles fl'om the cor-ires whi(:h are (:los(; t;o tim gh)bal cortms a,verageof \] 7 senl;en(:es per ardcl(;; these artich',s (:ontainapprox.
550 words alt(l 22 sentences on the, aver-age (range: 19 23).
All these artMes are at)out asingle topic, i)robably becmme of our choi(:e al)outa ret)resenl;ative t xt, lengdL We (lo not addressttm issue of multi-topicality here; however, it iswell-known that texts with more (hall olle tel)itare.
hm'd to deal wit;it for all kinds of Ill.
systeltlS.E.g., the ANES system, described i)y ('?
), triesto i(lenl;iily l;hese texts beforehand to 1)e ex(:ludedfl'om abstracl;ing.The system's rllll-til\[te ()It a SUN St)arc worksta-l;ion (UNIX, SUN OS 4.1.3) is appro?.
3 secondsfor an article of th(; test, set.3 Exper iment :  Abst rac ts  asExt rac ts  Generated  by HumanSubjectsIn order to bc able to ewfluate the quality of timabstracts t)rodueed by our system, we, conductedan experiment where we asked 13 human subjectsto choose the "most relevant 5-7 sentences" fromthe six articles Dom the test set.
9 \ ]b  t;~cilitatetheir (;ask, the subjects should first give each ofthe sentences in an artMe a "relewmce score" froml ("barely re lewmt") to  5 ("highly relevant;") andfinally choose tit(', trust scored sentences for th(;irabstracts.
The subjects were all native speakersof English (since we used an Englistl cortms) andwere.
paid for their task.
Compared l;o about 3 set:-ends for the machine system, the hmnans nee(h;drThis provides a bias towards longer sentences.
Ex-periment,s with methods that normalized for sentencelength yiehled worse results, so dtis bias appears to beapI)roI)riate.SWords in the title and/or appearing in t,ln!first,/last few sent,enees (:all be given I nore  weight bytneans of an editable parame.l;e.r tilt;.
It turns out,, how-ever, that, these weights do not, lead to an improvement,of the syst,em's performance.9This number corresponds in fact, well to the obser-vation of (Y) that, the opt,ilnal smnmary length is be-t;ween 20% and 30% of the original document length.987about 8 minutes (two orders of magnitude moretime) for determining the most relevant sentencesfor an article.4 Resul ts  and Discuss ion4.1 Automatical ly  created abstractsTable 1 shows the precision/recall values for thetf*idf-method escribed in section ??
and for adefault method that selects just the first N sen-fences fi'om the beginning of each artMe ("lead"-method).
Whereas tile lead method most likelyprovides a higher readability (see Brandow et al(?
)), tile data clearly indicates that the tf*idfmethod is superior to this default approach interms of relevance, l?
The computation of theseprecision/recall values is based on the sentenceswhich were chosen by the human subjects fromthe experiinent, i.e., an average was built over theprecision/recall between the machine system andeach individual subject.4.2 Abstracts produced by humansubjectsThe global analysis shows a surprisingly goodcorrelation across the hunmn subjects for the sen-tence scores of all six articles (see table ??
): inthe Pearson-r correlation matrix, 71 coefticientsare significant at the 0.01 level (***), 5 at the 0.05level (*), and only 2 are non significant (n.s.).
Thisresult indicates that there is a good inter-subjectagreement about the relative "relevance" of sen-tences in these texts.4.3 Comparison of machine-made andhurnan-Inade abstractsWe computed precision/recall for (;very humansubject, compared to all the other 12 subjects(taking the average precision/recall).
From theseindividual recall/precision values, the average wascomputed to yield a global measure for inter-huinan precision/recall.
Depending oil the article,these values range from 0.43/0.43 to 0.58/0.58, themean being 0.49/0.49.
As we can see, these re-sults are in the same range as the results for themachine system discussed previously (0.46/0.55,for abstracts with 6' sentences).
This means thatif we compare the output of the automatic sys-tem to the output of an average human subject inthe experiment, here is no noticeable ditference interms of precision/recall the machine l)erforlnsas well as human subjects do, given the task ofselecting the most relevant sentences from a text.1?The tf*idf nmtho<t proved itself better than all theother methods of weight computation which we tested(see (?
)); in particular, those using a combination ofw~rious other heuristics, as proposed, e.g., in (?
).5 Suggest ions for further work5.1 Dealing with mult i -topical textsIt can be argued that so far we have only dealtwith short texts about a single topic.
It is notclear how well the system would be able to handh;texts where multiple threads of contents occur;possibly, one couhl employ the method of text-tiling here (see e.g., (?
)), which helps determin-ing coherent sections within a text and thus could"guide" the abstracting system ill that it wouldbe able to track a sequence of multit)le topics in atext,.5.2 On-line abstractingWhile our system currently produces abstracts off-line, it is feasible to extend it in a way whereit uses the user's query in an IR environment todetermine tile relevant sentences of the retrieveddocuments, tIere, instead of producing a "generalabstract", the resulting on-line abstract would re-flect more of the "user's perspective" on the re-spective text.
However, it would have to be in-vestigated, how nmch weight-increase the wordsfrom the user's query should get in order not tobias tile resulting output in too strong a way.Further issues concerning the human-inaehineinterface are:?
highlighting passages containing the querywords?
listing of top ranked keywords in tile retrievedtext(s)?
indicating the relative position of the ex-tracted sentences in the text?
allowing for scrolling in the main text, start-ing at an arbitrary position within the ab-stract6 Conclus ionsIll this paper, we have shown that it is possible toimplement a system for generating text abstractswhich purely operates with word frequency statis-tics, without using either domain specific knowl-edge or text, sort specific heuristics.It was demonstrated that the resulting ab-stracts have the same quality in terms of preci-sion/recall as the abstracts created by human sub-jects ill an experiment.While a simple lead-method is more likely toproduce higher readability judgments, the advan-tage of the tf*idf-method for abstracting is its, su-periority in terms of capturing content relevance.AcknowledgmentsTile major part of this work has been drawn frolnthe author's dissertation at the Centre for Cogni-tive Science, University of Edinburgh, UK.
I wishto thank lily supervisors Steve Finch and Richard988Tal)lc' l: lh'ecision/r(!call wdues tbr default (lead) and tf*id\[' methods.3-  .
.
.
.
.
6.agfi).s o .ss/o.s l  | 0.45/0.a810 0.37/0.62 | 0.41/0.7412 0.a4/0.
( 9 | 0.ag/0.sa14 0"33/0"79 l 0.37/0.91Table 2: Significance of sentence score correlation between human sul)jeet, s: All 6 articlesHS2HS4HS3HS8IIS9HS1HS5HS12ITS11HS13ITS10HS14heighttlS4 IIS3 IIS8 ItS9 IIS1 HS5 ITS12 I1S11 \[IS13 HS10 HS14 IIS15gg*  #~# g#g ##g *gg  ### ###gg*  *g*  *g# g*g  g*g  *# *## *g# #g*  ggg?
g# #**  g #ggg  ***  #*@?
## gg###$**g  #*# *## g*g### ### #gg **g#*~ ~**  g*g  g*#%*g #gg *g*  #***#$ ##* g#*  #*##gg #g*  ggg  #**g#~ g*$  gg# g**### #%* g*# \]L,S.IL.S.
* ***ggShillcock for vahlal)le discussions, uggestions andadvice.. Also, I am grateful to Chris Manning forhis comments on an (~arlier draft;, as well as t,o thet;WO allOllyi\[lOllS r(wieweI'8 whose, reillarks gre.al;lyhelped in improving t, his l)aper.The author has l)eeal supi)orted in part bygrants from the Austrian Chamber of Com-merce and ~Dade (lhlndeswirtsehafl;skammer) andthe Austrian Ministry of Science and Research(BMWF).ReferencesBrandow, R., Mitze, K., Ibm, L.F. 1995.
Auto-mat;it Condensation of Electronic Publicationsby Se, ntence Selection.
In: Information P,,vccss-ing 84 Management, ,71(,5).
pp.675 685Edmundson, H.P.
1969.
New Methods in Au-tomatic Extracting.
In: Journal of the ACM,16(2).
pp.264 285Hearst, M.A., Plaunt, C. 1993.
Subt;opie Sl;ruc-luring for Pull-Length Docmn(mt Access.
In:Proceedings of the 16th ACM-SIGII~ Confl;r-trice, t)p.59 68Hobbs, ,I.R., At)I)elt, D.E., Bear, ,1.S., Israel, l).J.,Tyson, W.M.
1992.
FASTUS: A System forExtra(:ting Int'ormation h'oln Natural LanguageText.
SRI International, Technical Note 519,Menlo Park, CAJaeobs, P.S., Rau, L.F. 1990.
SCISOR: Extract-ing Informal;ion Dora On-line News.
ht: Com-munications of the ACM, .73 (11).
pp.88 97Kupiec, J., Pedersen, J., (\]hen, F. :1995.
A Train-al)le, Docmne.nt Summarizer.
In: l'r'oce?
'.dings ofthe.
18th ACM-SIGIR Confe~w~,cc.. t)p.68 73Mauhlin, M.L.
11989.
Information l/.etrieval l)yTexl; Skimming.
CMU-CS-89-193, CarnegieMclhm University, Pittsbllrgh, PAMiike, S., It;oh, E., Ono, K., Sumita, K. 1994.A Full-Text Retrieval System with a DynamicAbstract; Generation Funct;ion.
In: Proceedingsof the 17th ACM-SIGIR Um~fl:~v.'nce.
t)t).152161Morris, A.H., Kasper, G., Adams, D. 1992.The Effects and Limitations of Automated T('~xt;Condensing on Reading Comi)rehension Per-formaime.
In: Information Systems l},esea'rch,3(1).
1)t).17 35Paice, C.I).
1990.
Constructing l,il;era-lure Abstracts t)y Comlmter: \[\[>(:hniques andProst)ecl;s. In: Information Processing 84 Man-ageme.nt , 26(1).
t)1).7171 86Salt(m, G., Allan, J., Buekley, C. \]993.
Ap-proa(-hes to Passage Ret, rieval in Full ~l~,xt In-formation Systems.
TR 93-1334 (1993), CornellUniversity, \[thaca, NYSparck Jones, K., En(lres-Niggemeyer, i3.
:1995.Automal;i(: Summarizing.
In: Information P~v-cessing I"i Management, 31(5).
pp.625 630Zeehner, K. 1995.
Automatic Text Abstractingby Selecting Relewmt Passages.
M.Se, i)isser-ration, Centre for Uognitive Science, Universityof Edinburgh, UK989
