Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 120?124,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsDetecting Semantic Equivalence and Information Disparityin Cross-lingual DocumentsYashar Mehdad Matteo Negri Marcello FedericoFondazione Bruno Kessler, FBK-irstTrento , Italy{mehdad|negri|federico}@fbk.euAbstractWe address a core aspect of the multilingualcontent synchronization task: the identifica-tion of novel, more informative or semanti-cally equivalent pieces of information in twodocuments about the same topic.
This can beseen as an application-oriented variant of tex-tual entailment recognition where: i) T andH are in different languages, and ii) entail-ment relations between T and H have to bechecked in both directions.
Using a combi-nation of lexical, syntactic, and semantic fea-tures to train a cross-lingual textual entailmentsystem, we report promising results on differ-ent datasets.1 IntroductionGiven two documents about the same topic writ-ten in different languages (e.g.
Wiki pages), con-tent synchronization deals with the problem of au-tomatically detecting and resolving differences inthe information they provide, in order to producealigned, mutually enriched versions.
A roadmap to-wards the solution of this problem has to take intoaccount, among the many sub-tasks, the identifica-tion of information in one page that is semanticallyequivalent, novel, or more informative with respectto the content of the other page.
In this paper weset such problem as an application-oriented, cross-lingual variant of the Textual Entailment (TE) recog-nition task (Dagan and Glickman, 2004).
Along thisdirection, we make two main contributions:(a) Experiments with multi-directional cross-lingual textual entailment.
So far, cross-lingualtextual entailment (CLTE) has been only appliedto: i) available TE datasets (uni-directional rela-tions between monolingual pairs) transformed intotheir cross-lingual counterpart by translating the hy-potheses into other languages (Negri and Mehdad,2010), and ii) machine translation (MT) evaluationdatasets (Mehdad et al, 2012).
Instead, we ex-periment with the only corpus representative of themultilingual content synchronization scenario, andthe richer inventory of phenomena arising from it(multi-directional entailment relations).
(b) Improvement of current CLTE methods.
TheCLTE methods proposed so far adopt either a ?piv-oting approach?
based on the translation of the twoinput texts into the same language (Mehdad et al,2010), or an ?integrated solution?
that exploits bilin-gual phrase tables to capture lexical relations andcontextual information (Mehdad et al, 2011).
Thepromising results achieved with the integrated ap-proach, however, still rely on phrasal matching tech-niques that disregard relevant semantic aspects ofthe problem.
By filling this gap integrating linguis-tically motivated features, we propose a novel ap-proach that improves the state-of-the-art in CLTE.2 CLTE-based content synchronizationCLTE has been proposed by (Mehdad et al, 2010) asan extension of textual entailment which consists ofdeciding, given a text T and an hypothesis H in dif-ferent languages, if the meaning of H can be inferredfrom the meaning of T. The adoption of entailment-based techniques to address content synchronizationlooks promising, as several issues inherent to suchtask can be formalized as entailment-related prob-120lems.
Given two pages (P1 and P2), these issuesinclude identifying, and properly managing:(1) Text portions in P1 and P2 that express the samemeaning (bi-directional entailment).
In such casesno information has to migrate across P1 and P2, andthe two text portions will remain the same;(2) Text portions in P1 that are more informa-tive than portions in P2 (forward entailment).
Insuch cases, the entailing (more informative) portionsfrom P1 have to be translated and migrated to P2 inorder to replace or complement the entailed (less in-formative) fragments;(3) Text portions in P2 that are more informa-tive than portions in P1 (backward entailment), andshould be translated to replace or complement them;(4) Text portions in P1 describing facts that are notpresent in P2, and vice-versa (the ?unknown?
casesin RTE parlance).
In such cases, the novel infor-mation from both sides has to be translated and mi-grated in order to mutually enrich the two pages;(5) Meaning discrepancies between text portions inthe two pages (?contradictions?
in RTE parlance).CLTE has been previously modeled as a phrasematching problem that exploits dictionaries andphrase tables extracted from bilingual parallel cor-pora to determine the number of word sequences inH that can be mapped to word sequences in T. Inthis way a semantic judgement about entailment ismade exclusively on the basis of lexical evidence.When only unidirectional entailment relations fromT to H have to be determined (RTE-like setting), thefull mapping of the hypothesis into the text usuallyprovides enough evidence for a positive entailmentjudgement.
Unfortunately, when dealing with multi-directional entailment, the correlation between theproportion of matching terms and the correct entail-ment decisions is less strong.
In such framework, forinstance, the full mapping of the hypothesis into thetext is per se not sufficient to discriminate betweenforward entailment and semantic equivalence.
Tocope with these issues, we explore the contributionof syntactic and semantic features as a complementto lexical ones in a supervised learning framework.3 Beyond lexical CLTEIn order to enrich the feature space beyond pure lex-ical match through phrase table entries, our modelbuilds on two additional feature sets, derived from i)semantic phrase tables, and ii) dependency relations.Semantic Phrase Table (SPT) matching repre-sents a novel way to leverage the integration of se-mantics and MT-derived techniques.
SPT matchingextends CLTE methods based on pure lexical matchby means of ?generalized?
phrase tables annotatedwith shallow semantic labels.
SPTs, with entries inthe form ?
[LABEL] word1...wordn [LABEL]?, areused as a recall-oriented complement to the phrasetables used in MT.
A motivation for this augmenta-tion is that semantic tags allow to match tokens thatdo not occur in the original bilingual parallel cor-pora used for phrase table extraction.
Our hypothe-sis is that the increase in recall obtained from relaxedmatches through semantic tags in place of ?out ofvocabulary?
terms (e.g.
unseen person names) is aneffective way to improve CLTE performance, evenat the cost of some loss in precision.Like lexical phrase tables, SPTs are extractedfrom parallel corpora.
As a first step we annotatethe parallel corpora with named-entity taggers forthe source and target languages, replacing namedentities with general semantic labels chosen froma coarse-grained taxonomy (person, location, orga-nization, date and numeric expression).
Then, wecombine the sequences of unique labels into one sin-gle token of the same label, and we run Giza++ (Ochand Ney, 2000) to align the resulting semanticallyaugmented corpora.
Finally, we extract the seman-tic phrase table from the augmented aligned corporausing the Moses toolkit (Koehn et al, 2007).
Forthe matching phase, we first annotate T and H in thesame way we labeled our parallel corpora.
Then, foreach n-gram order (n=1 to 5) we use the SPT to cal-culate a matching score as the number of n-grams inH that match with phrases in T divided by the num-ber of n-grams in H.1Dependency Relation (DR) matching targets theincrease of CLTE precision.
Adding syntactic con-straints to the matching process, DR features aim toreduce the amount of wrong matches often occur-ring with bag-of-words methods (both at the lexi-cal level and with recall-oriented SPTs).
For in-stance, the contradiction between ?Yahoo acquired1When checking for entailment from H to T, the normaliza-tion is carried out dividing by the number of n-grams in T.121Overture?
and ?Overture compro?
Yahoo?, which isevident when syntax is taken into account, can notbe caught by shallow methods.
We define a de-pendency relation as a triple that connects pairs ofwords through a grammatical relation.
DR matchingcaptures similarities between dependency relations,combining the syntactic and lexical level.
In a validmatch, while the relation has to be the same, the con-nected words can be either the same, or semanticallyequivalent terms in the two languages (e.g.
accord-ing to a bilingual dictionary).
Given the dependencytree representations of T and H, for each grammati-cal relation (r) we calculate a DR matching score asthe number of matching occurrences of r in T andH, divided by the number of occurrences of r in H.Separate DR matching scores are calculated for eachrelation r appearing both in T and H.4 Experiments and results4.1 Content synchronization scenarioIn our first experiment we used the English-Germanportion of the CLTE corpus described in (Negri etal., 2011), consisting of 500 multi-directional entail-ment pairs which we equally divided into trainingand test sets.
Each pair in the dataset is annotatedwith ?Bidirectional?, ?Forward?, or ?Backward?
en-tailment judgements.
Although highly relevant forthe content synchronization task, ?Contradiction?and ?Unknown?
cases (i.e.
?NO?
entailment in bothdirections) are not present in the annotation.
How-ever, this is the only available dataset suitable togather insights about the viability of our approach tomulti-directional CLTE recognition.2 We chose theENG-GER portion of the dataset since for such lan-guage pair MT systems performance is often lower,making the adoption of simpler solutions based onpivoting more vulnerable.To build the English-German phrase tables wecombined the Europarl, News Commentary and ?de-news?3 parallel corpora.
After tokenization, Giza++and Moses were respectively used to align the cor-pora and extract a lexical phrase table (PT).
Simi-larly, the semantic phrase table (SPT) has been ex-2Recently, a new dataset including ?Unknown?
pairs hasbeen used in the ?Cross-Lingual Textual Entailment for ContentSynchronization?
task at SemEval-2012 (Negri et al, 2012).3http://homepages.inf.ed.ac.uk/pkoehn/tracted from the same corpora annotated with theStanford NE tagger (Faruqui and Pado?, 2010; Finkelet al, 2005).
Dependency relations (DR) have beenextracted running the Stanford parser (Rafferty andManning, 2008; De Marneffe et al, 2006).
The dic-tionary created during the alignment of the parallelcorpora provided the lexical knowledge to performmatches when the connected words are different, butsemantically equivalent in the two languages.
Tocombine and weight features at different levels weused SVMlight (Joachims, 1999) with default pa-rameters.In order to experiment under testing conditionsof increasing complexity, we set the CLTE problemboth as a two-way and as a three-way classificationtask.
Two-way classification casts multi-directionalentailment as a unidirectional problem, where eachpair is analyzed checking for entailment both fromleft to right and from right to left.
In this condi-tion, each original test example is correctly clas-sified if both pairs originated from it are correctlyjudged (?YES-YES?
for bidirectional, ?YES-NO?for forward, and ?NO-YES?
for backward entail-ment).
Two-way classification represents an intu-itive solution to capture multidirectional entailmentrelations but, at the same time, a suboptimal ap-proach in terms of efficiency since two checks areperformed for each pair.
Three-way classification ismore efficient, but at the same time more challeng-ing due to the higher difficulty of multiclass learn-ing, especially with small datasets.Results are compared with two pivoting ap-proaches, checking for entailment between the orig-inal English texts and the translated German hy-potheses.4 The first (Pivot-EDITS), uses an op-timized distance-based model implemented in theopen source RTE system EDITS (Kouylekov andNegri, 2010; Kouylekov et al, 2011).
The second(Pivot-PPT) exploits paraphrase tables for phrasematching, and represents the best monolingualmodel presented in (Mehdad et al, 2011).
Table1 demonstrates the success of our results in prov-ing the two main claims of this paper.
(a) In bothsettings all the feature sets used outperform the ap-proaches taken as terms of comparison.
The 61.6%accuracy achieved in the most challenging setting4Using Google Translate.122PT PT+DR PT+SPT PT+SPT+DR Pivot-EDITS Pivot-PPTCont.
Synch.
(2-way) 57.8 58.6 62.4 63.3 27.4 57.0Cont.
Synch.
(3-way) 57.4 57.8 58.7 61.6 25.3 56.1RTE-3 AVG Pivot PPTRTE3-derived 62.6 63.6 63.5 64.5 62.4 63.5Table 1: CLTE accuracy results over content synchronization and RTE3-derived datasets.
(3-way) demonstrates the effectiveness of our ap-proach to capture meaning equivalence and informa-tion disparity in cross-lingual texts.
(b) In both settings the combination of lexical, syn-tactic and semantic features (PT+SPT+DR) signif-icantly improves5 the state-of-the-art CLTE model(PT).
Such improvement is motivated by the jointcontribution of SPTs (matching more and longer n-grams, with a consequent recall improvement), andDR matching (adding constraints, with a consequentgain in precision).
However, the performance in-crease brought by DR features over PT is mini-mal.
This might be due to the fact that both PT andDR features are precision-oriented, and their effec-tiveness becomes evident only in combination withrecall-oriented features (SPT).Cross-lingual models also significantly outper-form pivoting methods.
This suggests that the noiseintroduced by incorrect translations makes the pivot-ing approach less attractive in comparison with themore robust cross-lingual models.4.2 RTE-like CLTE scenarioOur second experiment aims at verifying the effec-tiveness of the improved model over RTE-derivedCLTE data.
To this aim, we compare the results ob-tained by the new CLTE model with those reportedin (Mehdad et al, 2011), calculated over an English-Spanish entailment corpus derived from the RTE-3dataset (Negri and Mehdad, 2010).In order to build the English-Spanish lexicalphrase table (PT), we used the Europarl, News Com-mentary and United Nations parallel corpora.
Thesemantic phrase table (SPT) was extracted from thesame corpora annotated with FreeLing (Carreras etal., 2004).
Dependency relations (DR) have been ex-tracted parsing English texts and Spanish hypotheseswith DepPattern (Gamallo and Gonzalez, 2011).5p < 0.05, calculated using the approximate randomizationtest implemented in (Pado?, 2006).Accuracy results have been calculated over 800test pairs of the CLTE corpus, after training the SVMbinary classifier over the 800 development pairs.Our new features have been compared with: i) thestate-of-the-art CLTE model (PT), ii) the best mono-lingual model (Pivot-PPT) presented in (Mehdad etal., 2011), and iii) the average result achieved byparticipants in the monolingual English RTE-3 eval-uation campaign (RTE-3 AVG).
As shown in Ta-ble 1, the combined feature set (PT+SPT+DR) sig-nificantly5 outperforms the lexical model (64.5%vs 62.6%), while SPT and DR features separatelyadded to PT (PT+SPT, and PT+DR) lead to marginalimprovements over the results achieved by the PTmodel alone (about 1%).
This confirms the con-clusions drawn from the previous experiment, thatprecision-oriented and recall-oriented features leadto a larger improvement when they are used in com-bination.5 ConclusionWe addressed the identification of semantic equiv-alence and information disparity in two documentsabout the same topic, written in different languages.This is a core aspect of the multilingual content syn-chronization task, which represents a challengingapplication scenario for a variety of NLP technolo-gies, and a shared research framework for the inte-gration of semantics and MT technology.
Castingthe problem as a CLTE task, we extended previouslexical models with syntactic and semantic features.Our results in different cross-lingual settings provethe feasibility of the approach, with significant state-of-the-art improvements also on RTE-derived data.AcknowledgmentsThis work has been partially supported by the EU-funded project CoSyne (FP7-ICT-4-248531).123ReferencesX.
Carreras, I. Chao, L.
Padro?, and M. Padro?.
2004.FreeLing: An Open-Source Suite of Language Ana-lyzers.
In Proceedings of the 4th Language Resourcesand Evaluation Conference (LREC 2004), volume 4.I.
Dagan and O. Glickman.
2004.
Probabilistic TextualEntailment: Generic Applied Modeling of LanguageVariability.
In Proceedings of the PASCAL Workshopof Learning Methods for Text Understanding and Min-ing.M.C.
De Marneffe, B. MacCartney, and C.D.
Man-ning.
2006.
Generating Typed Dependency Parsesfrom Phrase Structure Parses.
In Proceedings of the5th Language Resources and Evaluation Conference(LREC 2006), volume 6, pages 449?454.M.
Faruqui and S. Pado?.
2010.
Training and Evaluat-ing a German Named Entity Recognizer with Seman-tic Generalization.
In Proceedings of the 10th Con-ference on Natural Language Processing (KONVENS2010), Saarbru?cken, Germany.J.R.
Finkel, T. Grenager, and C. Manning.
2005.
Incor-porating Non-local Information into Information Ex-traction Systems by Gibbs Sampling.
In Proceedingsof the 43rd Annual Meeting on Association for Com-putational Linguistics (ACL 2005).P.
Gamallo and I. Gonzalez.
2011.
A grammatical for-malism based on patterns of part of speech tags.
Inter-national Journal of Corpus Linguistics, 16(1):45?71.T.
Joachims.
1999.
Advances in kernel methods.
chap-ter Making large-scale support vector machine learn-ing practical, pages 169?184.
MIT Press, Cambridge,MA, USA.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
In Proceedings ofthe 45th Annual Meeting on Association for Computa-tional Linguistics, Demonstration Session (ACL 2007).M.
Kouylekov and M. Negri.
2010.
An Open-SourcePackage for Recognizing Textual Entailment.
In Pro-ceedings of the 48th Annual Meeting of the Associationfor Computational Linguistics, system demonstrations(ACL 2010).M.
Kouylekov, Y. Mehdad, and M. Negri.
2011.
Is itWorth Submitting this Run?
Assess your RTE Sys-tem with a Good Sparring Partner.
Proceedings of theEMNLP TextInfer 2011 Workshop on Textual Entail-ment.Y.
Mehdad, M. Negri, and M. Federico.
2010.
TowardsCross-Lingual Textual Entailment.
In Proceedings ofthe 11th Annual Conference of the North AmericanChapter of the Association for Computational Linguis-tics (NAACL HLT 2010).Y.
Mehdad, M. Negri, and M. Federico.
2011.
UsingBilingual Parallel Corpora for Cross-Lingual TextualEntailment.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics:Human Language Technologies (ACL HLT 2011).Y.
Mehdad, M. Negri, and M. Federico.
2012.
Matchwithout a Referee: Evaluating MT Adequacy withoutReference Translations.
In Proceedings of the Ma-chine Translation Workshop (WMT2012).M.
Negri and Y. Mehdad.
2010.
Creating a Bi-lingualEntailment Corpus through Translations with Mechan-ical Turk: $100 for a 10-day Rush.
In Proceedings ofthe NAACL HLT 2010 Workshop on Creating Speechand Language Data with Amazons?
Mechanical Turk.M.
Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo, andA.
Marchetti.
2011.
Divide and Conquer: Crowd-sourcing the Creation of Cross-Lingual Textual Entail-ment Corpora.
Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Processing(EMNLP 2011).M.
Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, andD.
Giampiccolo.
2012.
Semeval-2012 Task 8: Cross-lingual Textual Entailment for Content Synchroniza-tion.
In Proceedings of the 6th International Workshopon Semantic Evaluation (SemEval 2012).F.J.
Och and H. Ney.
2000.
Improved Statistical Align-ment Models.
In Proceedings of the 38th AnnualMeeting of the Association for Computational Linguis-tics (ACL 2000).S.
Pado?, 2006.
User?s guide to sigf: Significance test-ing by approximate randomisation.A.N.
Rafferty and C.D.
Manning.
2008.
Parsing ThreeGerman Treebanks: Lexicalized and UnlexicalizedBaselines.
In In Proceedings of the ACL 2008 Work-shop on Parsing German.124
