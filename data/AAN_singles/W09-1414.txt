Proceedings of the Workshop on BioNLP: Shared Task, pages 103?106,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsFrom Protein-Protein Interaction to Molecular Event ExtractionRune S?tre?, Makoto Miwa?, Kazuhiro Yoshida?
and Jun?ichi Tsujii?
{rune.saetre,mmiwa,kyoshida,tsujii}@is.s.u-tokyo.ac.jp?Department of Computer Science?Information Technology CenterUniversity of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo, JapanAbstractThis document describes the methods and re-sults for our participation in the BioNLP?09Shared Task #1 on Event Extraction.
It alsocontains some error analysis and a brief dis-cussion of the results.
Previous shared tasks inthe BioNLP community have focused on ex-tracting gene and protein names, and on find-ing (direct) protein-protein interactions (PPI).This year?s task was slightly different, sincethe protein names were already manually an-notated in the text.
The new challenge wasto extract biological events involving thesegiven gene and gene products.
We modi-fied a publicly available system (AkanePPI)to apply it to this new, but similar, proteininteraction task.
AkanePPI has previouslyachieved state-of-the-art performance on allexisting public PPI corpora, and only smallchanges were needed to achieve competitiveresults on this event extraction task.
Our of-ficial result was an F-score of 36.9%, whichwas ranked as number six among submissionsfrom 24 different groups.
We later balancedthe recall/precision by including more predic-tions than just the most confident one in am-biguous cases, and this raised the F-score onthe test-set to 42.6%.
The new Akane programcan be used freely for academic purposes.1 IntroductionWith the increasing number of publications report-ing on protein interactions, there is also a steadilyincreasing interest in extracting information fromBiomedical articles by using Natural Language Pro-cessing (BioNLP).
There has been several sharedtasks arranged by the BioNLP community to com-pare different ways of doing such Information Ex-traction (IE), as reviewed in Krallinger et al(2008).Earlier shared tasks have dealt with Protein-Protein Interaction (PPI) in general, but thistask focuses on more specific molecular events,such as Gene expression, Transcription, Pro-tein catabolism, Localization and Binding, plus(Positive or Negative) Regulation of proteins orother events.
Most of these events are related to PPI,so our hypothesis was that one of the best perform-ing PPI systems would perform well also on thisnew event extraction task.
We decided to modify apublicly available system with flexible configurationscripting (Miwa et al, 2008).
Some adjustments hadto be made to the existing system, like adding newtypes of Named Entities (NE) to represent the eventsmentioned above.
The modified AkaneRE (for Re-lation Extraction) can be freely used in academia1.2 Material and MethodsThe event extraction system is implemented in apipeline fashion (Fig.
1).2.1 Tokenization and Sentence BoundaryDetectionThe text was split into single sentences by a sim-ple sentence detection program, and then each sen-tence was split into words (tokens).
The tokeniza-tion was done by using white-space as the token-separator, but since all protein names are known dur-ing both training and testing, some extra tokeniza-tion rules were applied.
For example, the protein1http://www-tsujii.is.s.u-tokyo.ac.jp/?satre/akane/103Recursive TemplateOutputPOS taggingParsing(Enju & GDep)Event CluewordRecognitionEvent TemplateExtractionMachineLearning (ML)Training DataML FilteringPOS taggingEvent CluewordRecognitionEvent TemplateFillingTest DataModels withTemplatesParsing(Enju & GDep)Tokenization TokenizationFigure 1: System Overviewname ?T cell factor 1?
is treated as a single token,?T cell factor 1?, and composite tokens including aprotein name, like ?
(T cell factor 1)?, are split intoseveral tokens, like ?
(?, ?T cell factor 1?
and ?
)?, byadding space around all given protein names.
Also,punctuation (commas, periods etc.)
were treated asseparate tokens.2.2 POS-tagging and ParsingWe used Enju2 and GDep3 to parse the text.
Theseparsers have their own built-in Part-of-Speech (POS)taggers, and Enju also provides a normalized lemmaform for each token.2.3 Event Clue-word taggingEvent clue-word detection was performed by a Ma-chine Learning (ML) sequence labeling program.This named-entity tagger program is based on a firstorder Maximum Entropy Markov Model (MEMM)and is described in Yoshida and Tsujii (2007).
Theclue-word annotation of the shared-task training setwas converted into BIO format, and used to train the2http://www-tsujii.is.s.u-tokyo.ac.jp/enju/3http://www.cs.cmu.edu/?sagae/parser/gdep/MEMM model.
The features used in the MEMMmodel was extracted from surface strings and POSinformation of the words corresponding to (or ad-jacent to) the target BIO tags.
The clue-word tag-ger was applied to the development and test sets toobtain the marginal probability that each word is aclue-word of a certain category.
The probabilitieswere obtained by marginalizing the n-best output ofthe MEMM tagger.
We later also created clue-wordprobability annotation of the training set, to enablethe template extraction program to access clue-wordprobability information in the training phase.2.4 Event Template ExtractionThe training data was used to determine whichevents to extract.
As input to the system, a list ofNamed Entity (NE) types and the Roles they canplay were provided.
The roles can be thought of asslots for arguments in event-frames, and in this taskthe roles were Event (clue), Theme and Cause.
Inthe original AkanePPI (based on the AIMed corpus),the only NE type was Protein, and the only role wasTheme (p1 and p2).
All the (PPI) events were pair-wise interactions, and there was no explicit event-clue role.
This means that all the events could berepresented with the single template shown first inTable 1.The BioNLP shared task used eight other NEtypes, in addition to manually annotated Proteins,namely Binding, Gene expression, Localization,Protein catabolism, Transcription, Regulation, Pos-itive Regulation and Negative Regulation.
The firstfive events have only Theme slots, which can onlybe filled by Proteins, while the last three regulationevents are very diverse.
They also have one Themeslot, but they can have a Cause slot as well, and eachrole/slot can be filled with either Proteins, or otherEvents.
See the first half of Table 1.148 templates were extracted and clustered intonine homogeneous groups which were classifiedas nine separate sub-problems.
The grouping wasbased on whether the templates had an Event or aProtein in the same role-positions.
This way of orga-nizing the groups was motivated by the fact that theProteins are 100% certain, while the accuracy of theclue-word recognizer is only around 50% (estimatedon the training data).
The bottom of Table 1 showsthe resulting nine general interaction templates.1042.5 Machine Learning with Maximum EntropyModelsWe integrated Maximum Entropy (ME) modeling,also known as Logistic Regression, into AkaneRE.This was done by using LIBLINEAR4, which han-dles multi-class learning and prediction.
Gold tem-plates were extracted during training, and each tem-plate was matched with all legal combinations ofNamed Entities (including gold proteins/clue-wordsand other recognized clue-word candidates) in eachsentence.
The positive training examples were la-beled as gold members of the template, and all othercombinations matching a given template were la-beled as negative examples within that specific tem-plate class.
The templates were grouped into thenine general templates shown in the bottom of Ta-ble 1.
Using one-vs-rest logistic regression, wetrained one multi-class classifier for each of the ninegroups individually.
The ML features are shown inTable 2.In the test-phase, we extracted and labeled all re-lation candidates matching all the templates from thetraining-phase.
The ML component was automati-cally run independently for each of the nine groupslisted in the bottom of Table 1.
Each time, all thecandidate template-instances in the current groupwere assigned a confidence score by the classifier forthat group.
This score is the probability that a can-didate is a true relation, and a value above a certainthreshold means that the extracted relation will bepredicted as a true member of its specific template.LIBLINEAR?s C-value parameter and the predictionthreshold were selected by hand to produce a goodF-score (according to the strict matching criterion)on the development-test set.2.6 Filtering and recursive output of the mostconfident template instancesAfter machine learning, all the template instanceswere filtered based on their confidence score.
Af-ter tuning the threshold to the development test-set,we ended up using 1 as our C-value, and 3.5% asour confidence threshold.
Because the predictionof Regulation Events were done independent fromthe sub-events (or proteins) affected by that event,some sub-events had to be included for complete-4http://www.csie.ntu.edu.tw/?cjlin/liblinear/ness, even if their confidence score was below thethreshold.3 Results and DiscussionOur final official result was an F-score of 36.9%,which was ranked as number six among the sub-missions from 24 different groups.
This means thatthe AkanePPI system can achieve good results whenused on other PPI-related relation-extraction tasks,such as this first BioNLP event recognition sharedtask.
The most common error was in predicting reg-ulation events with other events as Theme or Cause.The problem is that these events involve more thanone occurrence of event-trigger words, so the perfor-mance is more negatively affected by our imperfectclue-word detection system.Since the recall was much lower on the test-setthan on the development test-set, we later allowedthe system to predict multiple confident alternativesfor a single event-word, and this raised our score onthe test-set from 36.9% to 42.6%.
In hindsight, thisis obvious since there are many such examples inthe training data: E.g.
?over-express?
is both posi-tive regulation and Gene expression.
The new sys-tem, named AkaneRE (for Relation Extraction), canbe used freely for academic purposes.As future work, we believe a closer integrationbetween the clue-word recognition and the templateprediction modules can lead to better performance.Acknowledgments?Grant-in-Aid for Specially Promoted Research?and ?Genome Network Project?, MEXT, Japan.ReferencesMartin Krallinger et al 2008.
Evaluation of text-miningsystems for biology: overview of the second biocre-ative community challenge.
Genome Biology, 9(S2).Makoto Miwa, Rune S?tre, Yusuke Miyao, TomokoOhta, and Jun?ichi Tsujii.
2008.
Combining multi-ple layers of syntactic information for protein-proteininteraction extraction.
In Proceedings of SMBM 2008,pages 101?108, Turku, Finland, September.Kazuhiro Yoshida and Jun?ichi Tsujii.
2007.
Rerankingfor biomedical named-entity recognition.
In Proceed-ings of the Workshop on BioNLP 2007, June.
Prague,Czech Republic.105Freq Event Theme1 Theme2 Theme3 Theme4 Cause- PPI Protein Protein613 Binding Protein213 Binding Protein Protein3 Binding Protein Protein Protein2 Binding Protein Protein Protein Protein217 Regulation Protein Protein12 Regulation Binding Protein48 +Regulation Transcription Protein4 +Regulation Phosphorylation Binding5 -Regulation +Regulation Protein... ... ... ...Total 148 TemplatesCount General Templates Theme1 Theme2 Theme3 Theme4 Cause9 event templates Protein1 event template Protein Protein1 event template Protein Protein Protein1 event template Protein Protein Protein Protein3 event templates Protein Protein12 event templates Protein Event27 event templates Event26 event templates Event Protein68 event templates Event EventTable 1: Interaction Templates from the training-set.
Classic PPI at the top, compared to Binding and Regulationevents in the middle.
148 different templates were automatically extracted from the training data by AkaneRE.
Atthe bottom, the Generalized Interaction Templates are shown, with proteins distinguished from other Named Entities(Events)Feature ExampleText The binding of the most prominent factor, named TCF-1 ( T cell factor 1 ),is correlated with the proto-enhancer activity of TCEd.BOW B TheBOW M0 -comma- -lparen- factor most named of prominent PROTEIN theBOW A -comma- -rparen- activity correlated is of proto-enhancer the TCEd withEnju PATH (ENTITY1) (<prep arg12arg1) (of) (prep arg12arg2>) (factor)(<verb arg123arg2) (name) (verb arg123arg3>) (ENTITY2)pairs (ENTITY1 <prep arg12arg1) (<prep arg12arg1 of) (of prep arg12arg2>) ...triples (ENTITY1 <prep arg12arg1 of) (<prep arg12arg1 of prep arg12arg2>) ...GDep PATH (ENTITY1) (<NMOD) (name) (<VMOD) (ENTITY2)pairs/triples (ENTITY1 <NMOD) (<NMOD name) ... (ENTITY1 <NMOD name) ...Vector BOW B BOW M0...BOW M4 BOW A Enju PATH GDep PATHTable 2: Bag-Of-Words (BOW) and shortest-path features for the machine learning.
Several BOW feature groups werecreated for each template, based on the position of the words in the sentence, relative to the position of the template?sNamed Entities (NE).
Specifically, BOW B was made by the words from the beginning of the sentence to the first NE,BOW A by the words between the last NE and the end of the sentence, and BOW M0 to BOW M4 was made by thewords between the main event clue-word and the NE in slot 0 through 4 respectively.
The path features are made fromone, two or three neighbor nodes.
We also included certain specific words, like ?binding?, as features.106
