Proceedings of ACL-08: HLT, pages 407?415,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsInducing Gazetteers for Named Entity Recognitionby Large-scale Clustering of Dependency RelationsJun?ichi KazamaJapan Advanced Institute ofScience and Technology (JAIST),Asahidai 1-1, Nomi,Ishikawa, 923-1292 Japankazama@jaist.ac.jpKentaro TorisawaNational Institute of Information andCommunications Technology (NICT),3-5 Hikaridai, Seika-cho, Soraku-gun,Kyoto, 619-0289 Japantorisawa@nict.go.jpAbstractWe propose using large-scale clustering of de-pendency relations between verbs and multi-word nouns (MNs) to construct a gazetteer fornamed entity recognition (NER).
Since depen-dency relations capture the semantics of MNswell, the MN clusters constructed by usingdependency relations should serve as a goodgazetteer.
However, the high level of computa-tional cost has prevented the use of clusteringfor constructing gazetteers.
We parallelizeda clustering algorithm based on expectation-maximization (EM) and thus enabled the con-struction of large-scale MN clusters.
Wedemonstrated with the IREX dataset for theJapanese NER that using the constructed clus-ters as a gazetteer (cluster gazetteer) is a effec-tive way of improving the accuracy of NER.Moreover, we demonstrate that the combina-tion of the cluster gazetteer and a gazetteer ex-tracted from Wikipedia, which is also usefulfor NER, can further improve the accuracy inseveral cases.1 IntroductionGazetteers, or entity dictionaries, are important forperforming named entity recognition (NER) accu-rately.
Since building and maintaining high-qualitygazetteers by hand is very expensive, many meth-ods have been proposed for automatic extraction ofgazetteers from texts (Riloff and Jones, 1999; The-len and Riloff, 2002; Etzioni et al, 2005; Shinzato etal., 2006; Talukdar et al, 2006; Nadeau et al, 2006).Most studies using gazetteers for NER are basedon the assumption that a gazetteer is a mappingfrom a multi-word noun (MN)1 to named en-tity categories such as ?Tokyo Stock Exchange ?
{ORGANIZATION}?.2 However, since the corre-spondence between the labels and the NE categoriescan be learned by tagging models, a gazetteer will beuseful as long as it returns consistent labels even ifthose returned are not the NE categories.
By chang-ing the perspective in such a way, we can exploremore broad classes of gazetteers.
For example, wecan use automatically extracted hyponymy relations(Hearst, 1992; Shinzato and Torisawa, 2004), or au-tomatically induced MN clusters (Rooth et al, 1999;Torisawa, 2001).For instance, Kazama and Torisawa (2007) usedthe hyponymy relations extracted from Wikipediafor the English NER, and reported improved accu-racies with such a gazetteer.We focused on the automatically induced clus-ters of multi-word nouns (MNs) as the source ofgazetteers.
We call the constructed gazetteers clus-ter gazetteers.
In the context of tagging, there areseveral studies that utilized word clusters to preventthe data sparseness problem (Kazama et al, 2001;Miller et al, 2004).
However, these methods cannotproduce the MN clusters required for constructinggazetteers.
In addition, the clustering methods used,such as HMMs and Brown?s algorithm (Brown etal., 1992), seem unable to adequately capture the se-mantics of MNs since they are based only on theinformation of adjacent words.
We utilized richer1We used the term, ?multi-word?, to emphasize that agazetteer includes not only one-word expressions but alsomulti-word expressions.2Although several categories can be associated in general,we assume that only one category is associated.407syntactic/semantic structures, i.e., verb-MN depen-dencies to make clean MN clusters.
Rooth et al(1999) and Torisawa (2001) showed that the EM-based clustering using verb-MN dependencies canproduce semantically clean MN clusters.
However,the clustering algorithms, especially the EM-basedalgorithms, are computationally expensive.
There-fore, performing the clustering with a vocabularythat is large enough to cover the many named entitiesrequired to improve the accuracy of NER is difficult.We enabled such large-scale clustering by paralleliz-ing the clustering algorithm, and we demonstrate theusefulness of the gazetteer constructed.We parallelized the algorithm of (Torisawa, 2001)using the Message Passing Interface (MPI), with theprime goal being to distribute parameters and thusenable clustering with a large vocabulary.
Apply-ing the parallelized clustering to a large set of de-pendencies collected from Web documents enabledus to construct gazetteers with up to 500,000 entriesand 3,000 classes.In our experiments, we used the IREX dataset(Sekine and Isahara, 2000) to demonstrate the use-fulness of cluster gazetteers.
We also comparedthe cluster gazetteers with the Wikipedia gazetteerconstructed by following the method of (Kazamaand Torisawa, 2007).
The improvement was largerfor the cluster gazetteer than for the Wikipediagazetteer.
We also investigated whether thesegazetteers improve the accuracies further when theyare used in combination.
The experimental resultsindicated that the accuracy improved further in sev-eral cases and showed that these gazetteers comple-ment each other.The paper is organized as follows.
In Section 2,we explain the construction of cluster gazetteers andits parallelization, along with a brief explanation ofthe construction of the Wikipedia gazetteer.
In Sec-tion 3, we explain how to use these gazetteers as fea-tures in an NE tagger.
Our experimental results arereported in Section 4.2 Gazetteer Induction2.1 Induction by MN ClusteringAssume we have a probabilistic model of a multi-word noun (MN) and its class: p(n, c) =p(n|c)p(c), where n ?
N is an MN and c ?
C is aclass.
We can use this model to construct a gazetteerin several ways.
The method we used in this studyconstructs a gazetteer: n ?
argmaxcp(c|n).
Thiscomputation can be re-written by the Bayes rule asargmaxcp(n|c)p(c) using p(n|c) and p(c).Note that we do not exclude non-NEs when weconstruct the gazetteer.
We expect that taggingmodels (CRFs in our case) can learn an appropri-ate weight for each gazetteer match regardless ofwhether it is an NE or not.2.2 EM-based Clustering using DependencyRelationsTo learn p(n|c) and p(c) for Japanese, we use theEM-based clustering method presented by Torisawa(2001).
This method assumes a probabilistic modelof verb-MN dependencies with hidden semanticclasses:3p(v, r, n) =?cp(?v, r?|c)p(n|c)p(c), (1)where v ?
V is a verb and n ?
N is an MN thatdepends on verb v with relation r. A relation, r,is represented by Japanese postpositions attached ton.
For example, from the following Japanese sen-tence, we extract the following dependency: v =??
(drink), r = ?
(?wo?
postposition), n =???
(beer).???
(beer)?
(wo)??
(drink) (?
drink beer)In the following, we let vt ?
?v, r?
?
VT for thesimplicity of explanation.To be precise, we attach various auxiliary verbsuffixes, such as ???
(reru)?, which is for pas-sivization, into v, since these greatly change the typeof n in the dependent position.
In addition, we alsotreated the MN-MN expressions, ?MN1 ?
MN2?(?
?MN2 of MN1?
), as dependencies v = MN2,r = ?, n = MN1, since these expressions alsocharacterize the dependent MNs well.Given L training examples of verb-MN depen-dencies {(vti, ni, fi)}Li=1, where fi is the numberof dependency (vti, ni) in a corpus, the EM-basedclustering tries to find p(vt|c), p(n|c), and p(c) thatmaximize the (log)-likelihood of the training exam-ples:LL(p) =?ifi log(?cp(vti|c)p(ni|c)p(c)).
(2)3This formulation is based on the formulation presented inRooth et al (1999) for English.408We iteratively update the probabilities using the EMalgorithm.
For the update procedures used, see Tori-sawa (2001).The corpus we used for collecting dependencieswas a large set (76 million) of Web documents,that were processed by a dependency parser, KNP(Kurohashi and Kawahara, 2005).4 From this cor-pus, we extracted about 380 million dependenciesof the form {(vti, ni, fi)}Li .2.3 Parallelization for Large-scale DataThe disadvantage of the clustering algorithm de-scribed above is the computational costs.
The spacerequirements are O(|VT ||C|+ |N ||C|+ |C|) for stor-ing the parameters, p(vt|c), p(n|c), and p(c)5, plusO(L) for storing the training examples.
The timecomplexity is mainly O(L ?
|C| ?
I), where I isthe number of update iterations.
The space require-ments are the main limiting factor.
Assume that afloating-point number consumes 8 bytes.
With thesetting, |N | = 500, 000, |VT | = 500, 000, and|C| = 3, 000, the algorithm requires more than 44GB for the parameters and 4 GB of memory for thetraining examples.
A machine with more than 48GB of memory is not widely available even today.Therefore, we parallelized the clustering algo-rithm, to make it suitable for running on a clusterof PCs with a moderate amount of memory (e.g., 8GB).
First, we decided to store the training exampleson a file since otherwise each node would need tostore all the examples when we use the data splittingdescribed below, and having every node consume 4GB of memory is memory-consuming.
Since the ac-cess to the training data is sequential, this does notslow down the execution when we use a bufferingtechnique appropriately.6We then split the matrix for the model parameters,p(n|c) and p(vt|c), along with the class coordinate.That is, each cluster node is responsible for storingonly a part of classes Cl, i.e., 1/|P | of the parame-ter matrix, where P is the number of cluster nodes.This data splitting enables linear scalability of mem-ory sizes.
However, doing so complicates the updateprocedure and, in terms of execution speed, may4Acknowledgements: This corpus was provided by Dr.Daisuke Kawahara of NICT.5To be precise, we need two copies of these.6Each node has a copy of the training data on a local disk.Algorithm 2.1: Compute p(cl|vti, ni)localZ = 0, Z = 0for cl ?
Cl do??
?d = p(vti|c)p(ni|c)p(c)p(cl|vti, ni) = dlocalZ += dMPI Allreduce( localZ, Z, 1, MPI DOUBLE,MPI SUM, MPI COMM WORLD)for cl ?
Cl do p(cl|vti, ni) /= ZFigure 1: Parallelized inner-most routine of EM cluster-ing algorithm.
Each node executes this code in parallel.offset the advantage of parallelization because eachnode needs to receive information about the classesthat are not on the node in the inner-most routine ofthe update procedure.The inner-most routine should compute:p(c|vti, ni) = p(vti|c)p(ni|c)p(c)/Z, (3)for each class c, where Z =?c p(vti|c)p(ni|c)p(c)is a normalizing constant.
However, Z cannot becalculated without knowing the results of other clus-ter nodes.
Thus, if we use MPI for parallelization,the parallelized version of this routine should re-semble the algorithm shown in Figure 1.
This rou-tine first computes p(vti|cl)p(ni|cl)p(cl) for eachcl ?
Cl, and stores the sum of these values as localZ.The routine uses an MPI function, MPI Allreduce,to sum up localZ of the all cluster nodes and toset Z with the resulting sum.
We can computep(cl|vti, ni) by using this Z to normalize the value.Although the above is the essence of our paralleliza-tion, invoking MPI Allreduce in the inner-most loopis very expensive because the communication setupis not so cheap.
Therefore, our implementation cal-culates p(cl|vti, ni) in batches of B examples andcalls MPI Allreduce at every B examples.7 We useda value of B = 4, 096 in this study.By using this parallelization, we successfully per-formed the clustering with |N | = 500, 000, |VT | =500, 000, |C| = 3, 000, and I = 150, on 8 clus-ter nodes with a 2.6 GHz Opteron processor and 8GB of memory.
This clustering took about a week.To our knowledge, no one else has performed EM-based clustering of this type on this scale.
The re-sulting MN clusters are shown in Figure 2.
In termsof speed, our experiments are still at a preliminary7MPI Allreduce can also take array arguments and apply theoperation to each element of the array in one call.409Class 791 Class 2760???
?
?
?
?(WINDOM)???/?????
?????
(Chiba Marine Stadium [abb.])?
?
?
?
?
?
?(CAMRY)??/???
????????
(Osaka Dome)???
?
?
?
?(DIAMANTE)??/?
????????
(Nagoya Dome [abb.])?
???
?
?
?(ODYSSEY)??/?????????
??
(Fukuoka Dome)????????(INSPIRE)??/??
?????????
(Osaka Stadium)?
?
?
?
?
?(SWIFT)??/???????????
(Yokohama Stadium [abb.
])Figure 2: Clean MN clusters with named entity entries(Left: car brand names.
Right: stadium names).
Namesare sorted on the basis of p(c|n).
Stadium names areexamples of multi-word nouns (word boundaries are in-dicated by ?/?)
and also include abbreviated expressions(marked by [abb.])
.stage.
We have observed 5 times faster execution,when using 8 cluster nodes with a relatively smallsetting, |N | = |VT | = 50, 000, |C| = 2, 000.2.4 Induction from WikipediaDefining sentences in a dictionary or an encyclope-dia have long been used as a source of hyponymy re-lations (Tsurumaru et al, 1991; Herbelot and Copes-take, 2006).Kazama and Torisawa (2007) extracted hy-ponymy relations from the first sentences (i.e., defin-ing sentences) of Wikipedia articles and then usedthem as a gazetteer for NER.
We used this methodto construct the Wikipedia gazetteer.The method described by Kazama and Torisawa(2007) is to first extract the first (base) noun phraseafter the first ?is?, ?was?, ?are?, or ?were?
in the firstsentence of a Wikipedia article.
The last word in thenoun phase is then extracted and becomes the hyper-nym of the entity described by the article.
For exam-ple, from the following defining sentence, it extracts?guitarist?
as the hypernym for ?Jimi Hendrix?.Jimi Hendrix (November 27, 1942) was an Ameri-can guitarist, singer and songwriter.The second noun phrase is used when the first nounphrase ends with ?one?, ?kind?, ?sort?, or ?type?,or it ended with ?name?
followed by ?of?.
Thisrule is for treating expressions like ?...
is one ofthe landlocked countries.?
By applying this methodof extraction to all the articles in Wikipedia, we# instancespage titles processed 550,832articles found 547,779(found by redirection) (189,222)first sentences found 545,577hypernyms extracted 482,599Table 1: Wikipedia gazetteer extractionconstruct a gazetteer that maps an MN (a title of aWikipedia article) to its hypernym.8 When the hy-pernym extraction failed, a special hypernym sym-bol, e.g., ?UNK?, was used.We modified this method for Japanese.
After pre-processing the first sentence of an article using amorphological analyzer, MeCab9, we extracted thelast noun after the appearance of Japanese postpo-sition ??
(wa)?
(?
?is?).
As in the English case,we also refrained from extracting expressions corre-sponding to ?one of?
and so on.From the Japanese Wikipedia entries of April10, 2007, we extracted 550,832 gazetteer entries(482,599 entries have hypernyms other than UNK).Various statistics for this extraction are shown inTable 1.
The number of distinct hypernyms inthe gazetteer was 12,786.
Although this Wikipediagazetteer is much smaller than the English versionused by Kazama and Torisawa (2007) that has over2,000,000 entries, it is the largest gazetteer that canbe freely used for Japanese NER.
Our experimen-tal results show that this Wikipedia gazetteer can beused to improve the accuracy of Japanese NER.3 Using Gazetteers as Features of NERSince Japanese has no spaces between words, thereare several choices for the token unit used in NER.Asahara and Motsumoto (2003) proposed usingcharacters instead of morphemes as the unit to alle-viate the effect of segmentation errors in morpholog-ical analysis and we also used their character-basedmethod.
The NER task is then treated as a taggingtask, which assigns IOB tags to each character ina sentence.10 We use Conditional Random Fields(CRFs) (Lafferty et al, 2001) to perform this tag-ging.The information of a gazetteer is incorporated8They handled ?redirections?
as well by following redirec-tion links and extracting a hypernym from the article reached.9http://mecab.sourceforge.net10Precisely, we use IOB2 tags.410ch ?
?
?
?
?
?
?
?
?
?match O B I I O O O ?
?
?
(w/ class) O B-??
I-??
I-??
O O O ?
?
?Figure 3: Gazetteer features for Japanese NER.
Here, ?????
means ?SONY?, ????
means ?company?, and ????
means ?to develop?.as features in a CRF-based NE tagger.
We followthe method used by Kazama and Torisawa (2007),which encodes the matching with a gazetteer entityusing IOB tags, with the modification for Japanese.They describe using two types of gazetteer features.The first is a matching-only feature, which usesbare IOB tags to encode only matching information.The second uses IOB tags that are augmented withclasses (e.g., B-country and I-country).11 Whenthere are several possibilities for making a match,the left-most longest match is selected.
The smalldifferences from their work are: (1) We used char-acters as the unit as we described above, (2) WhileKazama and Torisawa (2007) checked only the wordsequences that start with a capitalized word and thusexploited the characteristics of English language, wechecked the matching at every character, (3) Weused a TRIE to make the look-up efficient.The output of gazetteer features for Japanese NERare thus as those shown in Figure 3.
These annotatedIOB tags can be used in the same way as other fea-tures in a CRF tagger.4 Experiments4.1 DataWe used the CRL NE dataset provided in theIREX competition (Sekine and Isahara, 2000).
Inthe dataset, 1,174 newspaper articles are annotatedwith 8 NE categories: ARTIFACT, DATE, LO-CATION, MONEY, ORGANIZATION, PERCENT,PERSON, and TIME.12 We converted the data intothe CoNLL 2003 format, i.e., each row correspondsto a character in this case.
We obtained 11,892 sen-tences13 with 18,677 named entities.
We split thisdata into the training set (9,000 sentences), the de-11Here, we call the value returned by a gazetteer a ?class?.Features are not output when the returned class is UNK in thecase of the Wikipedia gazetteer.
We did not observe any signif-icant change if we also used UNK.12We ignored OPTIONAL category.13This number includes the number of -DOCSTART- tokensin CoNLL 2003 format.Name Descriptionch character itselfct character type: uppercase alphabet, lower-case alphabet, katakana, hiragana, Chinesecharacters, numbers, numbers in Chinesecharacters, and spacesm mo bare IOB tag indicating boundaries of mor-phemesm mm IOB tag augmented by morpheme string,indicating boundaries and morphemesm mp IOB tag augmented by morpheme type, in-dicating boundaries and morpheme types(POSs)bm bare IOB tag indicating ?bunsetsu?
bound-aries (Bunsetsu is a basic unit in Japaneseand usually contains content words fol-lowed by function words such as postpo-sitions)bi bunsetsu-inner feature.
See (Nakano andHirai, 2004).bp adjacent-bunsetsu feature.
See (Nakanoand Hirai, 2004).bh head-of-bunsetsu features.
See (Nakanoand Hirai, 2004).Table 2: Atomic features used in baseline model.velopment set (1,446 sentences), and the testing set(1,446 sentences).4.2 Baseline ModelWe extracted the atomic features listed in Table 2at each character for our baseline model.
Thoughthere may be slight differences, these features arebased on the standard ones proposed and used inprevious studies on Japanese NER such as those byAsahara and Motsumoto (2003), Nakano and Hirai(2004), and Yamada (2007).
We used MeCab as amorphological analyzer and CaboCha14 (Kudo andMatsumoto, 2002) as the dependency parser to findthe boundaries of the bunsetsu.
We generated thenode and the edge features of a CRF model as de-scribed in Table 3 using these atomic features.4.3 TrainingTo train CRF models, we used Taku Kudo?s CRF++(ver.
0.44) 15 with some modifications.16 We14http://chasen.org/?taku/software/CaboCha15http://chasen.org/?taku/software/CRF++16We implemented scaling, which is similar to that forHMMs (Rabiner, 1989), in the forward-backward phase and re-placed the optimization module in the original package with the411Node features:{?
?, x?2, x?1, x0, x+1, x+2} ?
y0where x = ch, ct, m mm, m mo, m mp, bi,bp, and bhEdge features:{?
?, x?1, x0, x+1} ?
y?1 ?
y0where x = ch, ct, and m mpBigram node features:{x?2x?1, x?1x0, x0x+1} ?
y0x = ch, ct, m mo, m mp, bm, bi, bp, and bhTable 3: Baseline features.
Value of node feature is deter-mined from current tag, y0, and surface feature (combina-tion of atomic features in Table 2).
Value of edge featureis determined by previous tag, y?1, current tag, y0, andsurface feature.
Subscripts indicate relative position fromcurrent character.used Gaussian regularization to prevent overfitting.The parameter of the Gaussian, ?2, was tuned us-ing the development set.
We tested 10 points:{0.64, 1.28, 2.56, 5.12, .
.
.
, 163.84, 327.68}.
Westopped training when the relative change in the log-likelihood became less than a pre-defined threshold,0.0001.
Throughout the experiments, we omittedthe features whose surface part described in Table3 occurred less than twice in the training corpus.4.4 Effect of Gazetteer FeaturesWe investigated the effect of the cluster gazetteer de-scribed in Section 2.1 and the Wikipedia gazetteerdescribed in Section 2.4, by adding each gazetteerto the baseline model.
We added the matching-only and the class-augmented features, and we gen-erated the node and the edge features in Table 3.17For the cluster gazetteer, we made several gazetteersthat had different vocabulary sizes and numbers ofclasses.
The number of clustering iterations was 150and the initial parameters were set randomly with aDirichlet distribution (?i = 1.0).The statistics of each gazetteer are summarizedin Table 4.
The number of entries in a gazetteer isgiven by ?# entries?, and ?# matches?
is the numberof matches that were output for the training set.
Wedefine ?# e-matches?
as the number of matches thatalso match a boundary of a named entity in the train-ing set, and ?# optimal?
as the optimal number of ?#e-matches?
that can be achieved when we know theLMVM optimizer of TAO (version 1.9) (Benson et al, 2007)17Bigram node features were not used for gazetteer features.oracle of entity boundaries.
Note that this cannotbe realized because our matching uses the left-mostlongest heuristics.
We define ?pre.?
as the precisionof the output matches (i.e., # e-matches/# matches),and ?rec.?
as the recall (i.e., # e-matches/# NEs).Here, # NEs = 14, 056.
Finally, ?opt.?
is the op-timal recall (i.e., # optimal/# NEs).
?# classes?
isthe number of distinct classes in a gazetteer, and?# used?
is the number of classes that were out-put for the training set.
Gazetteers are as follows:?wikip(m)?
is the Wikipedia gazetteer (matchingonly), and ?wikip(c)?
is the Wikipedia gazetteer(with class-augmentation).
A cluster gazetteer,which is constructed by the clustering with |N | =|VT | = X ?
1, 000 and |C| = Y ?
1, 000, is indi-cated by ?cXk-Y k?.
Note that ?# entries?
is slightlysmaller than the vocabulary size since we removedsome duplications during the conversion to a TRIE.These gazetteers cover 40 - 50% of the named en-tities, and the cluster gazetteers have relatively widercoverage than the Wikipedia gazetteer has.
The pre-cisions are very low because there are many erro-neous matches, e.g., with a entries for a hiraganacharacter.18 Although this seems to be a seriousproblem, removing such one-character entries doesnot affect the accuracy, and in fact, makes it worsenslightly.
We think this shows one of the strengthsof machine learning methods such as CRFs.
We canalso see that our current matching method is not anoptimal one.
For example, 16% of the matches werelost as a result of using our left-most longest heuris-tics for the case of the c500k-2k gazetteer.A comparison of the effect of these gazetteers isshown in Table 5.
The performance is measuredby the F-measure.
First, the Wikipedia gazetteerimproved the accuracy as expected, i.e., it repro-duced the result of Kazama and Torisawa (2007)for Japanese NER.
The improvement for the test-ing set was 1.08 points.
Second, all the tested clus-ter gazetteers improved the accuracy.
The largestimprovement was 1.55 points with the c300k-3kgazetteer.
This was larger than that of the Wikipediagazetteer.
The results for c300k-Y k gazetteers showa peak of the improvement at some number of clus-ters.
In this case, |C| = 3, 000 achieved the bestimprovement.
The results of cXk-2k gazetteers in-18Wikipedia contains articles explaining each hiragana char-acter, e.g., ??
is a hiragana character?.412Name # entries # matches # e-matches # optimal pre.
(%) rec.
(%) opt.
rec.
(%) # classes # usedwikip(m) 550,054 225,607 6,804 7,602 3.02 48.4 54.1 N/A N/Awikip(c) 550,054 189,029 5,441 6,064 2.88 38.7 43.1 12,786 1,708c100k-2k 99,671 193,897 6,822 8,233 3.52 48.5 58.6 2,000 1,910c300k-2k 295,695 178,220 7,377 9,436 4.14 52.5 67.1 2,000 1,973c300k-1k ?
?
?
?
?
?
?
1,000 982c300k-3k ?
?
?
?
?
?
?
3,000 2,848c300k-4k ?
?
?
?
?
?
?
4,000 3,681c500k-2k 497,101 174,482 7,470 9,798 4.28 53.1 69.7 2,000 1,951c500k-3k ?
?
?
?
?
?
?
3,000 2,854Table 4: Statistics of various gazetteers.Model F (dev.)
F (test.)
best ?2baseline 87.23 87.42 20.48+wikip 87.60 88.50 2.56+c300k-1k 88.74 87.98 40.96+c300k-2k 88.75 88.01 163.84+c300k-3k 89.12 88.97 20.48+c300k-4k 88.99 88.40 327.68+c100k-2k 88.15 88.06 20.48+c500k-2k 88.80 88.12 40.96+c500k-3k 88.75 88.03 20.48Table 5: Comparison of gazetteer features.Model F (dev.)
F (test.)
best ?2+wikip+c300k-1k 88.65 *89.32 0.64+wikip+c300k-2k *89.22 *89.13 10.24+wikip+c300k-3k 88.69 *89.62 40.96+wikip+c300k-4k 88.67 *89.19 40.96+wikip+c500k-2k *89.26 *89.19 2.56+wikip+c500k-3k *88.80 *88.60 10.24Table 6: Effect of combination.
Figures with * mean thataccuracy was improved by combining gazetteers.dicate that the larger a gazetteer is, the larger the im-provement.
However, the accuracies of the c300k-3kand c500k-3k gazetteers seem to contradict this ten-dency.
It might be caused by the accidental low qual-ity of the clustering that results from random initial-ization.
We need to investigate this further.4.5 Effect of Combining the Cluster and theWikipedia GazetteersWe have observed that using the cluster gazetteerand the Wikipedia one improves the accuracy ofJapanese NER.
The next question is whether thesegazetteers improve the accuracy further when theyare used together.
The accuracies of models thatuse the Wikipedia gazetteer and one of the clustergazetteers at the same time are shown in Table 6.The accuracy was improved in most cases.
How-Model F(Asahara and Motsumoto, 2003) 87.21(Nakano and Hirai, 2004) 89.03(Yamada, 2007) 88.33(Sasano and Kurohashi, 2008) 89.40proposed (baseline) 87.62proposed (+wikip) 88.14proposed (+c300k-3k) 88.45proposed (+c500k-2k) 88.41proposed (+wikip+c300k-3k) 88.93proposed (+wikip+c500k-2k) 88.71Table 7: Comparison with previous studiesever, there were some cases where the accuracy forthe development set was degraded.
Therefore, weshould state at this point that while the benefit ofcombining these gazetteers is not consistent in astrict sense, it seems to exist.
The best performance,F = 89.26 (dev.)
/ 89.19 (test.
), was achieved whenwe combined the Wikipedia gazetteer and the clus-ter gazetteer, c500k-2k.
This means that there wasa 1.77-point improvement from the baseline for thetesting set.5 Comparison with Previous StudiesSince many previous studies on Japanese NER used5-fold cross validation for the IREX dataset, wealso performed it for some our models that had thebest ?2 found in the previous experiments.
The re-sults are listed in Table 7 with references to the re-sults of recent studies.
These results not only re-confirmed the effects of the gazetteer features shownin the previous experiments, but they also showedthat our best model is comparable to the state-of-the-art models.
The system recently proposed by Sasanoand Kurohashi (2008) is currently the best systemfor the IREX dataset.
It uses many structural fea-tures that are not used in our model.
Incorporating413such features might improve our model further.6 Related Work and DiscussionThere are several studies that used automatically ex-tracted gazetteers for NER (Shinzato et al, 2006;Talukdar et al, 2006; Nadeau et al, 2006; Kazamaand Torisawa, 2007).
Most of the methods (Shin-zato et al, 2006; Talukdar et al, 2006; Nadeau etal., 2006) are oriented at the NE category.
Theyextracted a gazetteer for each NE category and uti-lized it in a NE tagger.
On the other hand, Kazamaand Torisawa (2007) extracted hyponymy relations,which are independent of the NE categories, fromWikipedia and utilized it as a gazetteer.
The ef-fectiveness of this method was demonstrated forJapanese NER as well by this study.Inducing features for taggers by clustering hasbeen tried by several researchers (Kazama et al,2001; Miller et al, 2004).
They constructed wordclusters by using HMMs or Brown?s clustering algo-rithm (Brown et al, 1992), which utilize only infor-mation from neighboring words.
This study, on theother hand, utilized MN clustering based on verb-MN dependencies (Rooth et al, 1999; Torisawa,2001).
We showed that gazetteers created by usingsuch richer semantic/syntactic structures improvesthe accuracy for NER.The size of the gazetteers is also a novel point ofthis study.
The previous studies, with the excep-tion of Kazama and Torisawa (2007), used smallergazetteers than ours.
Shinzato et al (2006) con-structed gazetteers with about 100,000 entries intotal for the ?restaurant?
domain; Talukdar et al(2006) used gazetteers with about 120,000 entriesin total, and Nadeau et al (2006) used gazetteerswith about 85,000 entries in total.
By paralleliz-ing the clustering algorithm, we successfully con-structed a cluster gazetteer with up to 500,000 en-tries from a large amount of dependency relationsin Web documents.
To our knowledge, no one elsehas performed this type of clustering on such a largescale.
Wikipedia also produced a large gazetteerof more than 550,000 entries.
However, compar-ing these gazetteers and ours precisely is difficult atthis point because the detailed information such asthe precision and the recall of these gazetteers werenot reported.19 Recently, Inui et al (2007) investi-19Shinzato et al (2006) reported some useful statistics aboutgated the relation between the size and the quality ofa gazetteer and its effect.
We think this is one of theimportant directions of future research.Parallelization has recently regained attention inthe machine learning community because of theneed for learning from very large sets of data.
Chuet al (2006) presented the MapReduce frameworkfor a wide range of machine learning algorithms, in-cluding the EM algorithm.
Newman et al (2007)presented parallelized Latent Dirichlet Allocation(LDA).
However, these studies focus on the distri-bution of the training examples and relevant com-putation, and ignore the need that we found for thedistribution of model parameters.
The exception,which we noticed recently, is a study by Wolfe etal.
(2007), which describes how each node storesonly those parameters relevant to the training dataon each node.
However, some parameters need tobe duplicated and thus their method is less efficientthan ours in terms of memory usage.We used the left-most longest heuristics to findthe matching gazetteer entries.
However, as shownin Table 4 this is not an optimal method.
We needmore sophisticated matching methods that can han-dle multiple matching possibilities.
Using modelssuch as Semi-Markov CRFs (Sarawagi and Cohen,2004), which handle the features on overlapping re-gions, is one possible direction.
However, even ifwe utilize the current gazetteers optimally, the cov-erage is upper bounded at 70%.
To cover most ofthe named entities in the data, we need much largergazetteers.
A straightforward approach is to increasethe number ofWeb documents used for theMN clus-tering and to use larger vocabularies.7 ConclusionWe demonstrated that a gazetteer obtained by clus-tering verb-MN dependencies is a useful featurefor a Japanese NER.
In addition, we demonstratedthat using the cluster gazetteer and the gazetteer ex-tracted from Wikipedia (also shown to be useful)can together further improves the accuracy in sev-eral cases.
Future work will be to refine the match-ing method and to construct even larger gazetteers.their gazetteers.414ReferencesM.
Asahara and Y. Motsumoto.
2003.
Japanese namedentity extraction with redundant morphological analy-sis.S.
Benson, L. C. McInnes, J.
More?, T. Munson, andJ.
Sarich.
2007.
TAO user manual (revision 1.9).Technical Report ANL/MCS-TM-242, Mathematicsand Computer Science Division, Argonne NationalLaboratory.
http://www.mcs.anl.gov/tao.P.
F. Brown, V. J. Della Pietra, P. V. deSouza, J. C. Lai,and R. L. Mercer.
1992.
Class-based n-gram mod-els of natural language.
Computational Linguistics,18(4):467?479.C.-T. Chu, S. K. Kim, Y.-A.
Lin, Y. Yu, G. Bradski, A. Y.Ng, and K. Olukotun.
2006.
Map-reduce for machinelearning on multicore.
In NIPS 2006.O.
Etzioni, M. Cafarella, D. Downey, A. M. Popescu,T.
Shaked, S. Soderland, D. S. Weld, and A. Yates.2005.
Unsupervised named-entity extraction from theWeb ?
an experimental study.
Artificial IntelligenceJournal.M.
A. Hearst.
1992.
Automatic acquisition of hyponymsfrom large text corpora.
In Proc.
of the 14th In-ternational Conference on Computational Linguistics,pages 539?545.A.
Herbelot and A. Copestake.
2006.
Acquiring onto-logical relationships from Wikipedia using RMRS.
InWorkshop on Web Content Mining with Human Lan-guage Technologies ISWC06.T.
Inui, K. Murakami, T. Hashimoto, K. Utsumi, andM.
Ishikawa.
2007.
A study on using gazetteers fororganization name recognition.
In IPSJ SIG TechnicalReport 2007-NL-182 (in Japanese).J.
Kazama and K. Torisawa.
2007.
Exploiting Wikipediaas external knowledge for named entity recognition.In EMNLP-CoNLL 2007.J.
Kazama, Y. Miyao, and J. Tsujii.
2001.
A maxi-mum entropy tagger with unsupervised hiddenMarkovmodels.
In NLPRS 2001.T.
Kudo and Y. Matsumoto.
2002.
Japanese dependencyanalysis using cascaded chunking.
In CoNLL 2002.S.
Kurohashi and D. Kawahara.
2005.
KNP (Kurohashi-Nagao parser) 2.0 users manual.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Con-ditional random fields: Probabilistic models for seg-menting and labeling sequence data.
In ICML 2001.S.
Miller, J. Guinness, and A. Zamanian.
2004.
Nametagging with word clusters and discriminative training.In HLT-NAACL04.D.
Nadeau, Peter D. Turney, and Stan Matwin.
2006.Unsupervised named-entity recognition: Generatinggazetteers and resolving ambiguity.
In 19th CanadianConference on Artificial Intelligence.K.
Nakano and Y. Hirai.
2004.
Japanese named entityextraction with bunsetsu features.
IPSJ Journal (inJapanese).D.
Newman, A. Asuncion, P. Smyth, and M. Welling.2007.
Distributed inference for latent dirichlet alo-cation.
In NIPS 2007.L.
R. Rabiner.
1989.
A tutorial on hidden Markov mod-els and selected applications in speech recognition.Proceedings of the IEEE, 77(2):257?286.E.
Riloff and R. Jones.
1999.
Learning dictionaries forinformation extraction by multi-level bootstrapping.In 16th National Conference on Artificial Intelligence(AAAI-99).M.
Rooth, S. Riezler, D. Presher, G. Carroll, and F. Beil.1999.
Inducing a semantically annotated lexicon viaEM-based clustering.S.
Sarawagi and W. W. Cohen.
2004.
Semi-Markov ran-dom fields for information extraction.
In NIPS 2004.R.
Sasano and S. Kurohashi.
2008.
Japanese named en-tity recognition using structural natural language pro-cessing.
In IJCNLP 2008.S.
Sekine and H. Isahara.
2000.
IREX: IR and IE evalu-ation project in Japanese.
In IREX 2000.K.
Shinzato and K. Torisawa.
2004.
Acquiring hy-ponymy relations from Web documents.
In HLT-NAACL 2004.K.
Shinzato, S. Sekine, N. Yoshinaga, and K. Tori-sawa.
2006.
Constructing dictionaries for named en-tity recognition on specific domains from the Web.
InWeb Content Mining with Human Language Technolo-gies Workshop on the 5th International Semantic Web.P.
P. Talukdar, T. Brants, M. Liberman, and F. Pereira.2006.
A context pattern induction method for namedentity extraction.
In CoNLL 2006.M.
Thelen and E. Riloff.
2002.
A bootstrapping methodfor learning semantic lexicons using extraction patterncontext.
In EMNLP 2002.K.
Torisawa.
2001.
An unsupervised method for canoni-calization of Japanese postpositions.
In NLPRS 2001.H.
Tsurumaru, K. Takeshita, K. Iami, T. Yanagawa, andS.
Yoshida.
1991.
An approach to thesaurus construc-tion from Japanese language dictionary.
In IPSJ SIGNotes Natural Language vol.83-16, (in Japanese).J.
Wolfe, A. Haghighi, and D. Klein.
2007.
Fully dis-tributed EM for very large datasets.
In NIPS Workshopon Efficient Machine Learning.H.
Yamada.
2007.
Shift-reduce chunking for Japanesenamed entity extraction.
In ISPJ SIG Technical Report2007-NL-179.415
