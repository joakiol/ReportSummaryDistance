Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 697?700,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsIntegrating Joint n-gram Featuresinto a Discriminative Training FrameworkSittichai Jiampojamarn?
and Colin Cherry?
and Grzegorz Kondrak?
?Department of Computing Science ?National Research Council CanadaUniversity of Alberta 1200 Montreal RoadEdmonton, AB, T6G 2E8, Canada Ottawa, ON, K1A 0R6, Canada{sj,kondrak}@cs.ualberta.ca Colin.Cherry@nrc-cnrc.gc.caAbstractPhonetic string transduction problems, suchas letter-to-phoneme conversion and nametransliteration, have recently received muchattention in the NLP community.
In the pastfew years, two methods have come to dom-inate as solutions to supervised string trans-duction: generative joint n-gram models, anddiscriminative sequence models.
Both ap-proaches benefit from their ability to considerlarge, flexible spans of source context whenmaking transduction decisions.
However, theyencode this context in different ways, provid-ing their respective models with different in-formation.
To combine the strengths of thesetwo systems, we include joint n-gram fea-tures inside a state-of-the-art discriminativesequence model.
We evaluate our approachon several letter-to-phoneme and translitera-tion data sets.
Our results indicate an improve-ment in overall performance with respect toboth the joint n-gram approach and traditionalfeature sets for discriminative models.1 IntroductionPhonetic string transduction transforms a sourcestring into a target representation according to itspronunciation.
Two important examples of this taskare letter-to-phoneme conversion and name translit-eration.
In general, the problem is challenging be-cause source orthography does not unambiguouslyspecify the target representation.
When consider-ing letter-to-phoneme, ambiguities and exceptionsin the pronunciation of orthography complicate con-version.
Transliteration suffers from the same ambi-guities, but the transformation is further complicatedby restrictions in the target orthography that may notexist in the source.Joint n-gram models (Bisani and Ney, 2002;Chen, 2003; Bisani and Ney, 2008) have beenwidely applied to string transduction problems (Li etal., 2004; Demberg et al, 2007; Jansche and Sproat,2009).
The power of the approach lies in buildinga language model over the operations used in theconversion from source to target.
Crucially, this al-lows the inclusion of source context in the generativestory.
Smoothing techniques play an important rolein joint n-gram models, greatly affecting their per-formance.
Although joint n-gram models are capa-ble of capturing context information in both sourceand target, they cannot selectively use only sourceor target information, nor can they consider arbitrarysequences within their context window, as they arelimited by their back-off schedule.Discriminative sequence models have also beenshown to perform extremely well on string transduc-tion problems.
These begin with a Hidden MarkovModel architecture, augmented with substring op-erations and discriminative training.
The primarystrength of these systems is their ability to includerich indicator features representing long sequencesof source context.
We will assume a specific in-stance of discriminative sequence modeling, DI-RECTL (Jiampojamarn et al, 2009), which achievedthe best results on several language pairs in theNEWS Machine Transliteration Shared Task (Li etal., 2009).
The same system matches or exceeds theperformance of the joint n-gram approach on letter-to-phoneme conversion (Jiampojamarn et al, 2008).Its features are optimized by an online, margin-697based learning algorithm, specifically, the MarginInfused Relaxed Algorithm, MIRA (Crammer andSinger, 2003).In this paper, we propose an approach that com-bines these two different paradigms by formulatingthe joint n-gram model as a new set of features in thediscriminative model.
This leverages an advantageof discriminative training, in that it can easily andeffectively incorporate arbitrary features.
We eval-uate our approach on several letter-to-phoneme andtransliteration data sets.
Our results demonstrate animprovement in overall performance with respect toboth the generative joint n-gram approach and theoriginal DIRECTL system.2 BackgroundString transduction transforms an input string x intothe desired output string y.
The input and output aredifferent representations of the same entity; for ex-ample, the spelling and the pronunciation of a word,or the orthographic forms of a word in two differentwriting scripts.One approach to string transduction is to viewit as a tagging problem where the input charac-ters are tagged with the output characters.
How-ever, since sounds are often represented by multi-character units, the relationship between the inputand output characters is often complex.
This pre-vents the straightforward application of standardtagging techniques, but can be addressed by sub-string decoders or semi-Markov models.Because the relationship between x and y is hid-den, alignments between the input and output char-acters (or substrings) are often provided in a pre-processing step.
These are usually generated in anunsupervised fashion using a variant of the EM al-gorithm.
Our system employs the many-to-manyalignment described in (Jiampojamarn et al, 2007).We trained our system on these aligned examples byusing the online discriminative training of (Jiampo-jamarn et al, 2009).
At each step, the parameterupdate is provided by MIRA.3 FeaturesJiampojamarn et al (2009) describe a set of indica-tor feature templates that include (1) context features(2) transition features and (3) linear-chain features.context xi?c yi.
.
.xi+c yixi?cxi?c+1 yi.
.
.xi+c?1xi+c yi.
.
.
.
.
.xi?c .
.
.
xi+c yitransition yi?1 yilinear-chain xi?c yi?1 yi.
.
.xi+c yi?1 yixi?cxi?c+1 yi?1 yi.
.
.xi+c?1xi+c yi?1 yi.
.
.
.
.
.xi?c .
.
.
xi+c, yi?1 yijoint n-gram xi+1?nyi+1?nxiyi.
.
.xi?1yi?1xiyixi+1?nyi+1?nxi+2?nyi+2?nxiyi.
.
.xi?2yi?2xi?1yi?1xiyi.
.
.
.
.
.xi+1?nyi+1?n .
.
.
xi?1yi?1xiyiTable 1: Feature templateTable 1 summarizes these features and introducesthe new set of joint n-gram features.The context features represent the source side ev-idence that surrounds an input substring xi as it gen-erates the target output yi.
These features includeall possible n-grams that fit inside a source-side con-text windows of size C, each conjoined with yi.
Thetransition features enforce the cohesion of the gen-erated output with target-side bigrams.
The linear-chain features conjoin context and transition fea-tures.The set of feature templates described abovehas been demonstrated to achieve excellent perfor-mance.
The context features express rich informa-tion on the source side, but no feature template al-lows target context beyond yi?1,yi.
Target andsource context are considered jointly, but only in avery limited fashion, as provided by the linear chainfeatures.
Jiampojamarn et al (2008) report that con-text features contribute the most to system perfor-mance.
They also report that increasing the Markovorder in the transition features from bigram to tri-698Figure 1: System accuracy as a function of the beam sizegram results in no significant improvement.
Intu-itively, the joint information of both source and tar-get sides is important in string transduction prob-lems.
By integrating the joint n-gram features intothe online discriminative training framework, we en-able the system to not only enjoy rich context fea-tures and long-range dependency linear-chain fea-tures, but we also take advantage of joint informa-tion between source and target substring pairs, asencoded by the joint n-gram template shown in thebottom of Table 1.An alternative method to incorporate a joint n-gram feature would compute the generative joint n-gram scores, and supply them as a real-valued fea-ture to the model.
As all of the other features inthe DIRECTL framework are indicators, the trainingalgorithm may have trouble scaling an informativereal-valued feature.
Therefore, we represent thesejoint n-gram features as binary features that indi-cate whether the model has seen particular stringsof joint evidence in the previous n ?
1 operationswhen generating yi from xi.
In this case, the sys-tem learns a distinct weight for each substring of thejoint n-gram.In order to accommodate higher-order joint n-grams, we replace the exact search algorithm of Ji-ampojamarn et al (2008) with a beam search.
Dur-ing our development experiments, we observed nosignificant decrease in accuracy after introducingthis approximation.
Figure 1 shows the system per-formance in terms of the word accuracy as a functionof the beam size on a development set.
The perfor-mance starts to converge quickly and shows no fur-ther improvement for values grater than 20.
In theremaining experiments we set the beam size to 50.We also performed development experimentsFigure 2: System accuracy as a function of n-gram sizewith a version of the system that includes only jointn-gram indicators.
Figure 2 shows the word ac-curacy with different values of n. The accuracyreaches its maximum for n = 4, and actually fallsoff for larger values of n. This anomaly is likelycaused by the model using its expanded expressivepower to memorize sequences of operations, overfit-ting to its training data.
Such overfitting is less likelyto happen in the generative joint n-gram model,which smooths high-order estimates very carefully.4 Experiments and ResultsWe evaluate our new approach on two string trans-duction applications: (1) letter-to-phoneme conver-sion and (2) name transliteration.
For the letter-to-phoneme conversion, we employ the English Celex,NETtalk, OALD, CMUdict, and the French Brulexdata sets.
In order to perform direct comparison withthe joint n-gram approach, we follow exactly thesame data splits as Bisani and Ney (2008).
The train-ing sizes range from 19K to 106K words.
For thetransliteration task, we use three data sets providedby the NEWS 2009 Machine Transliteration SharedTask (Li et al, 2009): English-Russian (EnRu),English-Chinese (EnCh), and English-Hindi (EnHi).The training sizes range from 10K to 30K words.We set n = 6 for the joint n-gram features; other pa-rameters are set on the respective development sets.Tables 2 and 3 show the performance of our newsystem in comparison with the joint n-gram ap-proach and DIRECTL.
The results in the rightmostcolumn of Table 2 are taken directly from (Bisaniand Ney, 2008), where they were evaluated on thesame data splits.
The results in the rightmost col-umn of Table 3 are from (Jansche and Sproat, 2009),which was the best performing system based on joint699Data set this work DIRECTL joint n-gramCelex 89.23 88.54 88.58CMUdict 76.41 75.41 75.47OALD 85.54 82.43 82.51NETtalk 73.52 70.18 69.00Brulex 95.21 95.03 93.75Table 2: Letter-to-phoneme conversion accuracyData set this work DIRECTL joint n-gramEnRu 61.80 61.30 59.70EnCh 74.17 73.34 64.60EnHi 50.30 49.80 41.50Table 3: Name transliteration accuracyn-grams at NEWS 2009.
We report all results interms of the word accuracy, which awards the sys-tem only for complete matches between system out-puts and the references.Our full system outperforms both D IRECTL andthe joint n-gram approach in all data sets.
Thisshows the utility of adding joint n-gram features tothe DIRECTL system, and confirms an advantage ofdiscriminative approaches: strong competitors cansimply be folded into the model.Comparing across tables, one can see that the gapbetween the generative joint n-gram and the DI-RECTL methods is much larger for the transliter-ation tasks.
This could be because joint n-gramsare a poor fit for transliteration, or the gap couldstem from differences between the joint n-gram im-plementations used for the two tasks.
Looking atthe improvements to DIRECTL from joint n-gramfeatures, we see further evidence that joint n-gramsare better suited to letter-to-phoneme than they areto transliteration: letter-to-phoneme improvementsrange from relative error reductions of 3.6 to 17.3,while in transliteration, the largest reduction is 3.1.5 ConclusionWe have presented a new set of joint n-gram featuresfor the DIRECTL discriminative sequence model.The resulting system combines two successful ap-proaches for string transduction ?
D IRECTL andthe joint n-gram model.
Joint n-gram indicator fea-tures are efficiently trained using a large marginmethod.
We have shown that the resulting systemconsistently outperforms both DIRECTL and strongjoint n-gram implementations in letter-to-phonemeconversion and name transliteration, establishing anew state-of-the-art for these tasks.AcknowledgementsThis research was supported by the Alberta Ingenu-ity Fund and the Natural Sciences and EngineeringResearch Council of Canada.ReferencesMaximilian Bisani and Hermann Ney.
2002.
Investi-gations on joint-multigram models for grapheme-to-phoneme conversion.
In Proc.
ICSLP, pages 105?108.Maximilian Bisani and Hermann Ney.
2008.
Joint-sequence models for grapheme-to-phoneme conver-sion.
Speech Communication, 50(5):434?451.Stanley F. Chen.
2003.
Conditional and joint mod-els for grapheme-to-phoneme conversion.
In Proc.Eurospeech-2003.Koby Crammer and Yoram Singer.
2003.
Ultraconserva-tive online algorithms for multiclass problems.
Jour-nal of Machine Learning Research, 3:951?991.Vera Demberg, Helmut Schmid, and Gregor Mo?hler.2007.
Phonological constraints and morphologicalpreprocessing for grapheme-to-phoneme conversion.In Proc.
ACL, pages 96?103.Martin Jansche and Richard Sproat.
2009.
Named entitytranscription with pair n-gram models.
In Proc.
ACL-IJCNLP Named Entities Workshop, pages 32?35.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand Hidden Markov Models to letter-to-phoneme con-version.
In Proc.
HLT-NAACL, pages 372?379.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2008.
Joint processing and discriminativetraining for letter-to-phoneme conversion.
In Proc.ACL, pages 905?913.Sittichai Jiampojamarn, Aditya Bhargava, Qing Dou,Kenneth Dwyer, and Grzegorz Kondrak.
2009.
Di-recTL: a language independent approach to translitera-tion.
In Proc.
ACL-IJCNLP Named Entities Workshop,pages 28?31.Haizhou Li, Min Zhang, and Jian Su.
2004.
A jointsource channel model for machine transliteration.
InProc.
ACL, pages 159?166.Haizhou Li, A Kumaran, Vladimir Pervouchine, and MinZhang.
2009.
Report of NEWS 2009 machine translit-eration shared task.
In Proc.
ACL-IJCNLP Named En-tities Workshop, pages 1?18.700
