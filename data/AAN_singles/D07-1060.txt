Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
571?580, Prague, June 2007. c?2007 Association for Computational LinguisticsCross-lingual Distributional Profiles of Conceptsfor Measuring Semantic DistanceSaif Mohammad?
Iryna Gurevych?
Graeme Hirst?
Torsten Zesch??Dept.
of Computer ScienceUniversity of TorontoToronto, Canada{smm,gh}@cs.toronto.edu?Ubiquitous Knowledge Processing GroupDarmstadt University of TechnologyDarmstadt, Germany{gurevych,zesch}@tk.informatik.tu-darmstadt.deAbstractWe present the idea of estimating seman-tic distance in one, possibly resource-poor,language using a knowledge source in an-other, possibly resource-rich, language.
Wedo so by creating cross-lingual distributionalprofiles of concepts, using a bilingual lexi-con and a bootstrapping algorithm, but with-out the use of any sense-annotated data orword-aligned corpora.
The cross-lingualmeasures of semantic distance are evaluatedon two tasks: (1) estimating semantic dis-tance between words and ranking the wordpairs according to semantic distance, and(2) solving Reader?s Digest ?Word Power?problems.
In task (1), cross-lingual mea-sures are superior to conventional monolin-gual measures based on a wordnet.
In task(2), cross-lingual measures are able to solvemore problems correctly, and despite scoresbeing affected by many tied answers, theiroverall performance is again better than thebest monolingual measures.1 IntroductionAccurately estimating the semantic distance be-tween concepts or between words in context has per-vasive applications in computational linguistics, in-cluding machine translation, information retrieval,speech recognition, spelling correction, and text cat-egorization (see Budanitsky and Hirst (2006) for dis-cussion), and it is becoming clear that basing suchmeasures on a combination of corpus statistics witha knowledge source, such as a dictionary, publishedthesaurus, or WordNet, can result in higher accu-racies (Mohammad and Hirst, 2006b).
This is be-cause such knowledge sources capture semantic in-formation about concepts and, to some extent, worldknowledge.
They also act as sense inventories forthe words in a language.However, applying algorithms for semantic dis-tance to most languages is hindered by the lack oflinguistic resources.
In this paper, we propose anew method that allows us to compute semantic dis-tance in a possibly resource-poor language by seam-lessly combining its text with a knowledge sourcein a different, preferably resource-rich, language.We demonstrate the approach by combining Germantext with an English thesaurus to create English?German distributional profiles of concepts, which inturn will be used to measure the semantic distancebetween German words.Two classes of methods have been used in deter-mining semantic distance.
Semantic measures ofconcept-distance, such as those of Jiang and Con-rath (1997) and Resnik (1995), rely on the structureof a knowledge source, such as WordNet, to deter-mine the distance between two concepts defined init (see Budanitsky and Hirst (2006) for a survey).Distributional measures of word-distance1, suchas cosine and ?-skew divergence (Lee, 2001), deem1Many distributional approaches represent the sets of con-texts of the target words as points in multidimensional co-occurrence space or as co-occurrence distributions.
A measure,such as cosine, that captures vector distance or a measure, suchas ?-skew divergence, that captures distance between distribu-tions is then used to measure distributional distance.
We willtherefore refer to these measures as distributional measures.571two words to be closer or less distant if they occur insimilar contexts (see Mohammad and Hirst (2005)for a comprehensive survey).Distributional measures rely simply on raw textand possibly some shallow syntactic processing.They do not require any other manually-created re-source, and tend to have a higher coverage.
How-ever, by themselves they perform poorly when com-pared to semantic measures (Mohammad and Hirst,2006b) because when given a target word pairwe usually need the distance between their closestsenses, but distributional measures of word-distancetend to conflate the distances between all possiblesense pairs.
Latent semantic analysis (LSA) (Lan-dauer et al, 1998) has also been used to measure dis-tributional distance with encouraging results (Rapp,2003).
However, it too measures the distance be-tween words and not senses.
Further, the dimen-sionality reduction inherent to LSA has the effect ofmaking the predominant sense more dominant whilede-emphasizing the other senses.
Therefore, anLSA-based approach will also conflate informationfrom the different senses, and even more emphasiswill be placed on the predominant senses.
Given thesemantically close target nouns play and actor, forexample, a distributional measure will give a scorethat is some sort of a dominance-based average ofthe distances between their senses.
The noun playhas the predominant sense of ?children?s recreation?
(and not ?drama?
), so a distributional measure willtend to give the target pair a large (and thus erro-neous) distance score.
Also, distributional word-distance approaches need to create large V ?V co-occurrence and distance matrices, where V is thesize of the vocabulary (usually at least 100,000).2Mohammad and Hirst (2006b) proposed a wayof combining written text with a published the-saurus to measure distance between concepts (orword senses) using distributional measures, therebyeliminating sense-conflation and achieving resultsbetter than the simple word-distance measures andindeed also most of the WordNet-based semanticmeasures.
We called these measures distributionalmeasures of concept-distance.
Concept-distance2LSA is especially expensive as singular value decomposi-tion, a key component for dimensionality reduction, requirescomputationally intensive matrix operations; making it lessscalable to large amounts of text (Gorman and Curran, 2006).measures can be used to measure distance betweena word pair by choosing the distance between theirclosest senses.
Thus, even though ?children?s recre-ation?
is the predominant sense of play, the ?drama?sense is much closer to actor and so their dis-tance will be chosen.
These distributional concept-distance approaches need to create only V ?C co-occurrence and C?C distance matrices, where C isthe number of categories or senses (usually about1000).
It should also be noted that unlike the bestWordNet-based measures, distributional measures(both word- and concept-distance ones) can be usedto estimate not just semantic similarity but also se-mantic relatedness?useful in many tasks includ-ing information retrieval.
However, the high-qualitythesauri and (to a much greater extent) WordNet-likeresources that these methods require do not exist formost of the 3000?6000 languages in existence todayand they are costly to create.In this paper, we introduce cross-lingual distri-butional measures of concept-distance, or simplycross-lingual measures, that determine the distancebetween a word pair belonging to a resource-poorlanguage using a knowledge source in a resource-rich language and a bilingual lexicon3.
We will usethe cross-lingual measures to calculate distances be-tween German words using an English thesaurus anda German corpus.
Although German is not resource-poor per se, Gurevych (2005) has observed that theGerman wordnet GermaNet (Kunze, 2004) (about60,000 synsets) is less developed than the EnglishWordNet (Fellbaum, 1998) (about 117,000 synsets)with respect to the coverage of lexical items and lex-ical semantic relations represented therein.
On theother hand, substantial raw corpora are available forthe German language.
Crucially for our evaluation,the existence of GermaNet alows comparison of ourcross-lingual approach with monolingual ones.2 Monolingual Distributional MeasuresIn order to set the context for cross-lingual concept-distance measures (Section 3), we first summarizemonolingual distributional approaches, with a focuson distributional concept-distance measures.3For most languages that have been the subject of academicstudy, there exists at least a bilingual lexicon mapping the corevocabulary of that language to a major world language and acorpus of at least a modest size.5722.1 Word-distanceWords that occur in similar contexts tend to be se-mantically close.
In our experiments, we defined thecontext of a target word, its co-occurring words, tobe ?5 words on either side (but not crossing sen-tence boundaries).
The set of contexts of a targetword is usually represented by the strengths of as-sociation of the target with its co-occurring words,which we refer to as the distributional profile (DP)of the word.
Here is a constructed example DP ofthe word star:DP of a wordstar: space 0.28, movie 0.2, famous 0.13,light 0.09, rich 0.04, .
.
.Simple counts are made of how often the target wordco-occurs with other words in text and how oftenthe words occur individually.
A suitable statistic,such as pointwise mutual information (PMI), is thenapplied to these counts to determine the strengthsof association between the target and co-occurringwords.
The distributional profiles of two targetwords represent their contexts as points in multi-dimensional word-space.
A suitable distributionalmeasure (for example, cosine) gives the distance be-tween the two points, and thereby an estimate of thesemantic distance between the target words.2.2 Concept-distanceIn Mohammad and Hirst (2006b), we show how dis-tributional profiles of concepts (DPCs) can be usedto measure semantic distance.
Below are the DPCsor DPs of two senses of the word star (the sensesor concepts themselves are glossed by a set of near-synonymous words, placed in parentheses):DPs of concepts?celestial body?
(celestial body,sun, .
.
.
): space 0.36, light 0.27,constellation 0.11, .
.
.?celebrity?
(celebrity, hero, .
.
.
):famous 0.24, movie 0.14, rich 0.14, .
.
.Thus the profiles of two target concepts representtheir contexts as points in multi-dimensional word-space.
A suitable distributional measure (for exam-ple, cosine) can then be used to give the distribu-tional distance between the two concepts in the sameway that distributional word-distance is measured.But to calculate the strength of association ofa concept with co-occurring words, in order tocreate DPCs, we must determine the number oftimes a word used in that sense co-occurs withsurrounding words.
In Mohammad and Hirst(2006a), we proposed a way to determine thesecounts without the use of sense-annotated data.Briefly, a word?category co-occurrence matrix(WCCM) is created having English word typeswen as one dimension and English thesaurus cat-egories cen as another.
We used the MacquarieThesaurus (Bernard, 1986) both as a very coarse-grained sense inventory and a source of possiblyambiguous English words that together unam-biguously represent each category (concept).
TheWCCM is populated with co-occurrence countsfrom a large English corpus (we used the BritishNational Corpus (BNC)).
A particular cell mi j,corresponding to word weni and concept cenj , ispopulated with the number of times weni co-occurs(in a window of ?5 words) with any word that hascenj as one of its senses (i.e., weni co-occurs with anyword listed under concept cenj in the thesaurus).cen1 cen2 .
.
.
cenj .
.
.wen1 m11 m12 .
.
.
m1 j .
.
.wen2 m21 m22 .
.
.
m2 j .
.
...................weni mi1 mi2 .
.
.
mi j .
.
.......... .
.
.......This matrix, created after a first pass of the cor-pus, is the base word?category co-occurrence ma-trix (base WCCM) and it captures strong associa-tions between a sense and co-occurring words.4 Thisis similar to how Yarowsky (1992) identifies wordsthat are indicative of a particular sense of the target.We know that words that occur close to a targetword tend to be good indicators of its intended sense.Therefore, we make a second pass of the corpus, us-ing the base WCCM to roughly disambiguate thewords in it.
For each word, the strength of associ-ation of each of the words in its context (?5 words)4From the base WCCM we can determine the number oftimes a word w and concept c co-occur, the number of timesw co-occurs with any concept, and the number of times c co-occurs with any word.
A statistic such as PMI can then give thestrength of association between w and c.573with each of its senses is summed.
The sense thathas the highest cumulative association is chosen asthe intended sense.
A new bootstrapped WCCMis created such that each cell mi j, corresponding toword weni and concept cenj , is populated with thenumber of times weni co-occurs with any word usedin sense cenj .Mohammad and Hirst (2006a) used the DPCs cre-ated from the bootstrapped WCCM to attain near-upper-bound results in the task of determining wordsense dominance.
Unlike the McCarthy et al (2004)dominance system, our approach can be appliedto much smaller target texts (a few hundred sen-tences) without the need for a large similarly-sense-distributed text5.
In Mohammad and Hirst (2006a),the DPC-based monolingual distributional measuresof concept-distance were used to rank word pairsby their semantic similarity and to correct real-word spelling errors, attaining markedly better re-sults than monolingual distributional measures ofword-distance.
In the spelling correction task, thedistributional concept-distance measures performedbetter than all WordNet-based measures as well, ex-cept for the Jiang and Conrath (1997) measure.3 Cross-lingual Distributional MeasuresWe now describe how distributional measures ofconcept-distance can be used in a cross-lingualframework to determine the distance between wordsin (resource-poor) language L1 by combining its textwith a thesaurus in (resource-rich) language L2, us-ing an L1?L2 bilingual lexicon.
We will comparethis approach with the best monolingual approaches;the smaller the loss in performance, the more ca-pable the algorithm is of overcoming ambiguitiesin word translation.
An evaluation, therefore, re-quires an L1 that in actuality has adequate knowl-edge sources.
Therefore we chose German to standin as the resource-poor language L1 and English asthe resource-rich L2; the monolingual evaluation inGerman will use GermaNet.
The remainder of thepaper describes our approach in terms of Germanand English, but the algorithm itself is language in-dependent.5The McCarthy et al (2004) system needs to first gener-ate a distributional thesaurus from the target text (if it is largeenough?a few million words) or from another large text with adistribution of senses similar to the target text.3.1 Concept-distanceGiven a German word wde in context, we use aGerman?English bilingual lexicon to determine itsdifferent possible English translations.
Each En-glish translation wen may have one or more possi-ble coarse senses, as listed in an English thesaurus.These English thesaurus concepts (cen) will be re-ferred to as cross-lingual candidate senses of theGerman word wde.6 Figure 1 depicts examples.7As in the monolingual distributional measures,the distance between two concepts is calculated byfirst determining their DPs.
However, in the cross-lingual approach, a concept is now glossed by near-synonymous words in an English thesaurus, whereasits profile is made up of the strengths of associ-ation with co-occurring German words.
Here areconstructed example cross-lingual DPs of the twosenses of star:Cross-lingual DPs of concepts?celestial body?
(celestial body, sun,.
.
.
): Raum 0.36, Licht 0.27,Konstellation 0.11, .
.
.?celebrity?
(celebrity, hero, .
.
.
):beru?hmt 0.24, Film 0.14, reich 0.14, .
.
.In order to calculate the strength of association, wemust first determine individual word and conceptcounts, as well as their co-occurrence counts.3.2 Cross-lingual word?categoryco-occurrence matrixWe create a cross-lingual word?category co-occurrence matrix with German word types wde asone dimension and English thesaurus concepts cen6Some of the cross-lingual candidate senses of wde mightnot really be senses of wde (e.g., ?celebrity?, ?river bank?, and?judiciary?
in Figure 1).
However, as substantiated by experi-ments in Section 4, our algorithm is able to handle the addedambiguity.7Vocabulary of German words needed to understand this dis-cussion: Bank: 1. financial institution, 2. bench (furniture);beru?hmt: famous; Film: movie (motion picture); Himmels-ko?rper: heavenly body; Konstellation: constellation; Licht:light; Morgensonne: morning sun; Raum: space; reich: rich;Sonne: sun; Star: star (celebrity); Stern: star (celestial body)574}star bankriverbankbenchfurniturejudiciarycelestial bodycelebrity}institutionfinancial }Stern Bank wdecenwenFigure 1: The cross-lingual candidate senses of Ger-man words Stern and Bank.as another.cen1 cen2 .
.
.
cenj .
.
.wde1 m11 m12 .
.
.
m1 j .
.
.wde2 m21 m22 .
.
.
m2 j .
.
...................wdei mi1 mi2 .
.
.
mi j .
.
.......... .
.
.......The matrix is populated with co-occurrence countsfrom a large German corpus; we used the newspapercorpus, taz8 (Sep 1986 to May 1999; 240 millionwords).
A particular cell mi j, corresponding to wordwdei and concept cenj , is populated with the numberof times the German word wdei co-occurs (in a win-dow of ?5 words) with any German word having cenjas one of its cross-lingual candidate senses.
For ex-ample, the Raum?
?celestial body?
cell will have thesum of the number of times Raum co-occurs withHimmelsko?rper, Sonne, Morgensonne, Star, Stern,and so on (see Figure 2).
We used the MacquarieThesaurus (Bernard, 1986) (about 98,000 words)for our experiments.
The possible German trans-lations of an English word were taken from theGerman?English bilingual lexicon BEOLINGUS9(about 265,000 entries).This base word?category co-occurrence matrix(base WCCM), created after a first pass of the cor-pus captures strong associations between a category(concept) and co-occurring words.
For example,even though we increment counts for both Raum?
?celestial body?
and Raum??celebrity?
for a particu-lar instance where Raum co-occurs with Star, Raumwill co-occur with a number of words such as Him-melsko?rper, Sonne, and Morgensonne that each havethe sense of celestial body in common (see Figure2), whereas all their other senses are likely different8http://www.taz.de9http://dict.tu-chemnitz.de... }... }}sunSonne Morgensonne Starcelestial bodycelestial bodySternstar wenwdecenHimmelsko?rperFigure 2: Words having ?celestial body?
as one oftheir cross-lingual candidate senses.and distributed across the set of concepts.
There-fore, the co-occurrence count of Raum and ?celestialbody?
will be relatively higher than that of Raum and?celebrity?.As in the monolingual case, a second pass ofthe corpus is made to disambiguate the (German)words in it.
For each word, the strength of associ-ation of each of the words in its context (?5 words)with each of its cross-lingual candidate senses issummed.
The sense that has the highest cumula-tive association with co-occurring words is chosenas the intended sense.
A new bootstrapped WCCMis created by populating each cell mi j, correspond-ing to word wdei and concept cenj , with the number oftimes the German word wdei co-occurs with any Ger-man word used in cross-lingual sense cenj .
A statisticsuch as PMI is then applied to these counts to deter-mine the strengths of association between a targetconcept and co-occurring words, giving the distri-butional profile of the concept.Following the ideas described above, Mohammadet al (2007) created Chinese?English DPCs fromChinese text, a Chinese?English bilingual lexicon,and an English thesaurus.
They used these DPCs toimplement an unsupervised na?
?ve Bayes word senseclassifier that placed first among all unsupervisedsystems taking part in the Multilingual Chinese?English Lexical Sample Task (task #5) of SemEval-07 (Jin et al, 2007).4 EvaluationWe evaluated the newly proposed cross-lingual dis-tributional measures of concept-distance on the tasksof (1) measuring semantic distance between Germanwords and ranking German word pairs according tosemantic distance, and (2) solving German ?WordPower?
questions from Reader?s Digest.
In orderto compare results with state-of-the-art monolingualapproaches we conducted experiments using Ger-575(Cross-lingual) Distributional Measures (Monolingual) GermaNet MeasuresInformation Content?based Lesk-like?-skew divergence (Lee, 2001) (ASD) Jiang and Conrath (1997) (JC) hypernym pseudo-gloss (HPG)cosine (Schu?tze and Pedersen, 1997) (Cos) Lin (1998b) (LinGN) radial pseudo-gloss (RPG)Jensen-Shannon divergence (JSD) Resnik (1995) (Res)Lin?s measure (1998a) (Lindist)Table 1: Distance measures used in our experiments.Dataset Year Language # pairs PoS Scores # subjects CorrelationGur65 2005 German 65 N discrete {0,1,2,3,4} 24 .810Gur350 2006 German 350 N, V, A discrete {0,1,2,3,4} 8 .690Table 2: Comparison of datasets used for evaluating semantic distance in German.maNet measures as well.
The specific distributionalmeasures10 and GermaNet-based measures we usedare listed in Table 1.
The GermaNet measures areof two kinds: (1) information content measures,11and (2) Lesk-like measures that rely on n-gram over-laps in the glosses of the target senses, proposed byGurevych (2005)12.The cross-lingual measures combined the Germannewspaper corpus taz with the English MacquarieThesaurus using the German?English bilingual lex-icon BEOLINGUS.
Multi-word expressions in thethesaurus and the bilingual lexicon were ignored.We used a context of ?5 words on either side of thetarget word for creating the base and bootstrappedWCCMs.
No syntactic pre-processing was done,nor were the words stemmed, lemmatized, or part-of-speech tagged.4.1 Measuring distance in word pairs4.1.1 DataA direct approach to evaluate distance measures isto compare them with human judgments.
Gurevych10JSD and ASD calculate the difference in distributions ofwords that co-occur with the targets.
Lindist (distributionalmeasure) and LinGN (GermaNet measure) follow from Lin?s(1998b) information-theoretic definition of similarity.11Information content measures rely on finding the lowestcommon subsumer (lcs) of the target synsets in a hypernym hi-erarchy and using corpus counts to determine how specific orgeneral this concept is.
In general, the more specific the lcs isand the smaller the difference of its specificity with that of thetarget concepts, the closer the target concepts are.12As GermaNet does not have glosses for synsets, Gurevych(2005) proposed a way of creating a bag-of-words-type pseudo-gloss for a synset by including the words in the synset and insynsets close to it in the network.
(2005) and Zesch et al (2007) asked native Germanspeakers to mark two different sets of German wordpairs with distance values.
Set 1 (Gur65) consistsof a German translation of the English Rubensteinand Goodenough (1965) dataset.
It has 65 noun?noun word pairs.
Set 2 (Gur350) is a larger datasetcontaining 350 word pairs made up of nouns, verbs,and adjectives.
The semantically close word pairsin Gur65 are mostly synonyms or hypernyms (hy-ponyms) of each other, whereas those in Gur350have both classical and non-classical relations (Mor-ris and Hirst, 2004) with each other.
Details of thesesemantic distance benchmarks13 are summarizedin Table 2.
Inter-subject correlations are indicativeof the degree of ease in annotating the datasets.4.1.2 Results and DiscussionWord-pair distances determined using differentdistance measures are compared in two ways withthe two human-created benchmarks.
The rank order-ing of the pairs from closest to most distant is evalu-ated with Spearman?s rank order correlation ?
; thedistance judgments themselves are evaluated withPearson?s correlation coefficient r. The higher thecorrelation, the more accurate the measure is.
Spear-man?s correlation ignores actual distance values af-ter a list is ranked?only the ranks of the two setsof word pairs are compared to determine correla-tion.
On the other hand, Pearson?s coefficient takesinto account actual distance values.
So even if twolists are ranked the same, but one has distances be-13The datasets are publicly available at:http://www.ukp.tu-darmstadt.de/data/semRelDatasets576tween consecutively-ranked word-pairs more in linewith human-annotations of distance than the other,then Pearson?s coefficient will capture this differ-ence.
However, this makes Pearson?s coefficientsensitive to outlier data points, and so one must in-terpret the Pearson correlations with caution.Table 3 shows the results.14 Observe that on bothdatasets and by both measures of correlation, cross-lingual measures of concept-distance perform notjust as well as the best monolingual measures, but infact better.
In general, the correlations are lower forGur350 as it contains cross-PoS word pairs and non-classical relations, making it harder to judge evenby humans (as shown by the inter-annotator corre-lations for the datasets in Table 2).
ConsideringSpearman?s rank correlation, ?-skew divergence andJensen-Shannon divergence perform best on bothdatasets.
The correlations of cosine and Lindist arenot far behind.
Amongst the monolingual GermaNetmeasures, radial pseudo-gloss performs best.
Con-sidering Pearson?s correlation, Lindist performs bestoverall and radial pseudo-gloss does best amongstthe monolingual measures.
Thus, we see that onboth datasets and as per both measures of correla-tion, the cross-lingual measures perform not just aswell as the best monolingual measures, but indeedslightly better.4.2 Solving word choice problems fromReader?s Digest4.2.1 DataIssues of the German edition of Reader?s Digestinclude a word choice quiz called ?Word Power?.Each question has one target word and four alter-native words or phrases; the objective is to pick thealternative that is most closely related to the target.The correct answer may be a near-synonym of thetarget or it may be related to the target by some otherclassical or non-classical relation (usually the for-mer).
For example:15Duplikat (duplicate)a. Einzelstu?ck (single copy) b. Doppelkinn (double chin)c. Nachbildung (replica) d. Zweitschrift (copy)Our approach to evaluating distance measures fol-14In Table 3, all values are statistically significant at the 0.01level (2-tailed), except for the one in italic (0.212), which issignificant at the 0.05 level (2-tailed).15English translations are in parentheses.lows that of Jarmasz and Szpakowicz (2003), whoevaluated semantic similarity measures through theirability to solve synonym problems (80 TOEFL (Lan-dauer and Dumais, 1997), 50 ESL (Turney, 2001),and 300 (English) Reader?s Digest Word Powerquestions).
Turney (2006) used a similar approachto evaluate the identification of semantic relations,with 374 college-level multiple-choice word anal-ogy questions.The Reader?s Digest Word Power (RDWP)benchmark for German consists of 1072 of theseword-choice problems collected from the January2001 to December 2005 issues of the German-language edition (Wallace and Wallace, 2005).
Wediscarded 44 problems that had more than one cor-rect answer, and 20 problems that used a phrase in-stead of a single term as the target.
The remaining1008 problems form our evaluation dataset, which issignificantly larger than any of the previous datasetsemployed in a similar evaluation.We evaluate the various cross-lingual and mono-lingual distance measures by their ability to choosethe correct answer.
The distance between the targetand each of the alternatives is computed by a mea-sure, and the alternative that is closest is chosen.
Iftwo or more alternatives are equally close to the tar-get, then the alternatives are said to be tied.
If oneof the tied alternatives is the correct answer, thenthe problem is counted as correctly solved, but thecorresponding score is reduced.
We assign a scoreof 0.5, 0.33, and 0.25 for 2, 3, and 4 tied alterna-tives, respectively (in effect approximating the scoreobtained by randomly guessing one of the tied al-ternatives).
If more than one alternative has a sensein common with the target, then the thesaurus-basedcross-lingual measures will mark them each as theclosest sense.
However, if one or more of these tiedalternatives is in the same semicolon group of thethesaurus16 as the target, then only these are chosenas the closest senses.The German RDWP dataset contains manyphrases that cannot be found in the knowledgesources (GermaNet or Macquarie Thesaurus viatranslation list).
In these cases, we remove stop-16Words in a thesaurus category are further partitioned intodifferent paragraphs and each paragraph into semicolon groups.Words within a semicolon group are more closely related thanthose in semicolon groups of the same paragraph or category.577Gur65 Gur350Measure ?
r ?
rMonolingualHPG 0.672 0.702 0.346 0.331RPG 0.764 0.565 0.492 0.420JC 0.665 0.748 0.417 0.410LinGN 0.607 0.739 0.475 0.495Res 0.623 0.722 0.454 0.466Cross-lingualASD 0.794 0.597 0.520 0.413Cos 0.778 0.569 0.500 0.212JSD 0.793 0.633 0.522 0.422Lindist 0.775 0.816 0.498 0.514Table 3: Correlations of distance measures with hu-man judgments.words (prepositions, articles, etc.)
and split thephrase into component words.
As German wordsin a phrase can be highly inflected, we lemmatizeall components.
For example, the target ?imagina?r?
(imaginary) has ?nur in der Vorstellung vorhanden?
(?exists only in the imagination?)
as one of its alter-natives.
The phrase is split into its component wordsnur, Vorstellung, and vorhanden.
We compute se-mantic distance between the target and each phrasalcomponent and select the minimum value as the dis-tance between target and potential answer.4.2.2 Results and DiscussionTable 4 presents the results obtained on the Ger-man RDWP benchmark for both monolingual andcross-lingual measures.
Only those questions forwhich the measures have some distance informationare attempted; the column ?Att.?
shows the numberof questions attempted by each measure, which isthe maximum score that the measure can hope toget.
Observe that the thesaurus-based cross-lingualmeasures have a much larger coverage than theGermaNet-based monolingual measures.
The cross-lingual measures have a much larger number of cor-rect answers too (column ?Cor.?
), but this number isbloated due to the large number of ties.17 ?Score?is the score each measure gets after it is penalizedfor the ties.
The cross-lingual measures Cos, JSD,and Lindist obtain the highest scores.
But ?Score?by itself does not present the complete picture ei-17We see more ties when using the cross-lingual measuresbecause they rely on the Macquarie Thesaurus, a very coarse-grained sense inventory (around 800 categories), whereas thecross-lingual measures operate on the fine-grained GermaNet.Reader?s Digest Word Power benchmarkMeasure Att.
Cor.
Ties Score P R FMonolingualHPG 222 174 11 171.5 .77 .17 .28RPG 266 188 15 184.7 .69 .18 .29JC 357 157 1 156.0 .44 .16 .23LinGN 298 153 1 152.5 .51 .15 .23Res 299 154 33 148.3 .50 .15 .23Cross-lingualASD 438 185 81 151.6 .35 .15 .21Cos 438 276 90 223.1 .51 .22 .31JSD 438 276 90 229.6 .52 .23 .32Lindist 438 274 90 228.7 .52 .23 .32Table 4: Performance of distance measures on wordchoice problems.
(Att.
: Attempted, Cor.
: Correct)ther as, given the scoring scheme, a measure that at-tempts more questions may get a higher score justfrom random guessing.
We therefore present pre-cision, recall, and F-scores (P = Score/Att; R =Score/1008; F = 2?P?R/(P + R)).
Observe thatthe cross-lingual measures have a higher coverage(recall) than the monolingual measures but lowerprecision.
The F scores show that the best cross-lingual measures do slightly better than the bestmonolingual ones, despite the large number of ties.The measures of Cos, JSD, and Lindist remain thebest cross-lingual measures, whereas HPG and RPGare the best monolingual ones.5 ConclusionWe have proposed a new method to determine se-mantic distance in a possibly resource-poor lan-guage by combining its text with a knowledgesource in a different, preferably resource-rich, lan-guage.
Specifically, we combined German text withan English thesaurus to create cross-lingual distri-butional profiles of concepts?the strengths of as-sociation between English thesaurus senses (con-cepts) of German words and co-occurring Germanwords?using a German?English bilingual lexiconand a bootstrapping algorithm designed to overcomeambiguities of word-senses and translations.
No-tably, we do so without the use of sense-annotatedtext or word-aligned parallel corpora.
We did notparse or chunk the text, nor did we stem, lemmatize,or part-of-speech-tag the words.We used the cross-lingual DPCs to estimate se-mantic distance by developing new cross-lingual578distributional measures of concept-distance.
Thesemeasures are like the distributional measures ofconcept-distance (Mohammad and Hirst, 2006a,2006b), except they can determine distance betweenwords in one language using a thesaurus in a differ-ent language.
We evaluated the cross-lingual mea-sures against the best monolingual ones operatingon a WordNet-like resource, GermaNet, through anextensive set of experiments on two different Ger-man semantic distance benchmarks.
In the process,we compiled a large German benchmark of Reader?sDigest word choice problems suitable for evaluatingsemantic-relatedness measures.
Most previous se-mantic distance benchmarks are either much smalleror cater primarily to semantic similarity measures.Even with the added ambiguity of translatingwords from one language to another, the cross-lingual measures performed better than the bestmonolingual measures on both the word-pair taskand the Reader?s Digest word-choice task.
Fur-ther, in the word-choice task, the cross-lingual mea-sures achieved a significantly higher coverage thanthe monolingual measure.
The richness of En-glish resources seems to have a major impact, eventhough German, with GermaNet, a well-establishedresource, is in a better position than most other lan-guages.
This is indeed promising, because achievingbroad coverage for resource-poor languages remainsan important goal as we integrate state-of-the-art ap-proaches in natural language processing into real-life applications.
These results show that our algo-rithm can successfully combine German text with anEnglish thesaurus using a bilingual German?Englishlexicon to obtain state-of-the-art results in measur-ing semantic distance.These results also support the broader and far-reaching claim that natural language problems ina resource-poor language can be solved using aknowledge source in a resource-rich language (e.g.,Cucerzan and Yarowsky?s (2002) cross-lingual PoStagger).
Our future work will explore other taskssuch as information retrieval and text categoriza-tion.
Cross-lingual DPCs also have tremendous po-tential in tasks inherently involving more than onelanguage, such as machine translation and multi-language multi-document summarization.
We be-lieve that the future of natural language process-ing lies not in standalone monolingual systems butin those that are powered by automatically createdmultilingual networks of information.AcknowledgmentsWe thank Philip Resnik, Michael Demko, SuzanneStevenson, Frank Rudicz, Afsaneh Fazly, and AfraAlishahi for helpful discussions.
This research is fi-nancially supported by the Natural Sciences and En-gineering Research Council of Canada, the Univer-sity of Toronto, the German Research Foundationunder the grant ?Semantic Information Retrieval?
(SIR), GU 798/1-2.ReferencesJ.R.L.
Bernard, editor.
1986.
The Macquarie Thesaurus.Macquarie Library, Sydney, Australia.Alexander Budanitsky and Graeme Hirst.
2006.
Evalu-ating WordNet-based measures of semantic distance.Computational Linguistics, 32(1):13?47.Silviu Cucerzan and David Yarowsky.
2002.
Boot-strapping a multilingual part-of-speech tagger in oneperson-day.
In Proceedings of the 6th Conferenceon Computational Natural Language Learning, pages132?138, Taipei, Taiwan.Christiane Fellbaum.
1998.
WordNet An Electronic Lex-ical Database.
MIT Press, Cambridge, MA.James Gorman and James R. Curran.
2006.
Scaling dis-tributional similarity to large corpora.
In Proceedingsof the 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Associ-ation for Computational Linguistics, pages 361?368,Sydney, Australia.Iryna Gurevych.
2005.
Using the Structure of a Concep-tual Network in Computing Semantic Relatedness.
InProceedings of the 2nd International Joint Conferenceon Natural Language Processing, pages 767?778, JejuIsland, Republic of Korea.Mario Jarmasz and Stan Szpakowicz.
2003.
Roget?sThesaurus and semantic similarity.
In Proceedings ofthe International Conference on Recent Advances inNatural Language Processing (RANLP-2003), pages212?219.Jay J. Jiang and David W. Conrath.
1997.
Semanticsimilarity based on corpus statistics and lexical tax-onomy.
In Proceedings of International Conferenceon Research on Computational Linguistics (ROCLINGX), Taiwan.579Peng Jin, Yunfang Wu, and Shiwen Yu.
2007.
SemEval-2007 task 05: Multilingual Chinese-English lexicalsample task.
In Proceedings of the Fourth Inter-national Workshop on the Evaluation of Systems forthe Semantic Analysis of Text (SemEval-07), Prague,Czech Republic.Claudia Kunze, 2004.
Lexikalisch-semantische Wort-netze, chapter Computerlinguistik und Sprachtech-nologie, pages 423?431.
Spektrum AkademischerVerlag.Thomas K. Landauer and Susan T. Dumais.
1997.
A so-lution to Plato?s problem: The latent semantic analysistheory of acquisition, induction, and representation ofknowledge.
Psychological Review, 104:211?240.Thomas K. Landauer, Peter W. Foltz, and Darrell Laham.1998.
Introduction to latent semantic analysis.
Dis-course Processes, 25(2?3):259?284.Lillian Lee.
2001.
On the effectiveness of the skew di-vergence for statistical language analysis.
In ArtificialIntelligence and Statistics 2001, pages 65?72.Dekang Lin.
1998a.
Automatic retreival and cluster-ing of similar words.
In Proceedings of the 17th In-ternational Conference on Computational Linguistics(COLING-98), pages 768?773, Montreal, Canada.Dekang Lin.
1998b.
An information-theoretic definitionof similarity.
In Proceedings of the 15th InternationalConference on Machine Learning, pages 296?304, SanFrancisco, CA.
Morgan Kaufmann.Diana McCarthy, Rob Koeling, Julie Weeds, and JohnCarroll.
2004.
Finding predominant senses in un-tagged text.
In Proceedings of the 42nd Annual Meet-ing of the Association for Computational Linguistics(ACL-04), pages 280?267, Barcelona, Spain.Saif Mohammad and Graeme Hirst.
2005.Distributional measures as proxies forsemantic relatedness.
In submission,http://www.cs.toronto.edu/compling/Publications.Saif Mohammad and Graeme Hirst.
2006a.
Determiningword sense dominance using a thesaurus.
In Proceed-ings of the 11th Conference of the European Chap-ter of the Association for Computational Linguistics(EACL), Trento, Italy.Saif Mohammad and Graeme Hirst.
2006b.
Distribu-tional measures of concept-distance: A task-orientedevaluation.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP-2006), Sydney, Australia.Saif Mohammad, Graeme Hirst, and Philip Resnik.
2007.Distributional profiles of concepts for unsupervisedword sense disambigution.
In Proceedings of theFourth International Workshop on the Evaluation ofSystems for the Semantic Analysis of Text (SemEval-07), Prague, Czech Republic.Jane Morris and Graeme Hirst.
2004.
Non-classical lex-ical semantic relations.
In Proceedings of the Work-shop on Computational Lexical Semantics, HumanLanguage Technology Conference of the North Ameri-can Chapter of the Association for Computational Lin-guistics, Boston, Massachusetts.Reinhard Rapp.
2003.
Word sense discovery based onsense descriptor dissimilarity.
In Proceedings of theMachine Translation Summit IX, pages 315?322, NewOrleans, Louisiana.Philip Resnik.
1995.
Using information content to evalu-ate semantic similarity.
In Proceedings of the 14th In-ternational Joint Conference on Artificial Intelligence(IJCAI-95), pages 448?453, Montreal, Canada.Herbert Rubenstein and John B. Goodenough.
1965.Contextual Correlates of Synonymy.
Communicationsof the ACM, 8(10):627?633.Hinrich Schu?tze and Jan O. Pedersen.
1997.
Acooccurrence-based thesaurus and two applications toinformation retreival.
Information Processing andManagement, 33(3):307?318.Peter Turney.
2001.
Mining the Web for synonyms:PMI-IR versus LSA on TOEFL.
In Proceedings of theTwelfth European Conference on Machine Learning(ECML-2001), pages 491?502, Freiburg, Germany.Peter Turney.
2006.
Expressing implicit semantic rela-tions without supervision.
In Proceedings of the 21stInternational Conference on Computational Linguis-tics and the 44th annual meeting of the ACL, pages313?320, Sydney, Australia.DeWitt Wallace and Lila Acheson Wallace.
2005.Reader?s Digest, das Beste fu?r Deutschland.
Jan2001?Dec 2005.
Verlag Das Beste, Stuttgart.David Yarowsky.
1992.
Word-sense disambiguation us-ing statistical models of Roget?s categories trained onlarge corpora.
In Proceedings of the 14th InternationalConference on Computational Linguistics (COLING-92), pages 454?460, Nantes, France.Torsten Zesch, Iryna Gurevych, and Max Mu?hlha?user.2007.
Comparing Wikipedia and German WordNet byevaluating semantic relatedness on multiple datasets.In Proceedings of Human Language Technologies:The Annual Conference of the North American Chap-ter of the Association for Computational Linguistics(NAACL HLT 2007), pages 205?208, Rochester, NewYork.580
