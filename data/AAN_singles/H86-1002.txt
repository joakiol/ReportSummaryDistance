PROTEUS and PUNDIT:RESEARCH IN TEXT UNDERSTANDINGatthe Department of Computer  Science, New York UniversityandSystem Development Corporation -- A Burroughs Companyprepared byRalph Grishman(New York University)andLynette Hirschman(System Development Corporation)1.
IntroductionWe are engaged in the development of systems capable of analyzing short narrativemessages dealing with a limited domain and extracting the information contained in thenarrative.
These systems are initially being applied to messages describing equipmentfailure.
This work is a joint effort  of New York University and the System DevelopmentCorp.
for the Strategic Computing Program.
Our aim is to create a system reliable enoughfor use in an operational environment.
This is a formidable task, both because the texts areunedited (and so contain various errors) and because the complexity of any real domainprecludes us from assembling a "complete" collection of the relationships and domainknowledge relevant o understanding texts in the domain.A number of laboratory prototypes have been developed for the analysis of shortnarratives.
None of the systems we know about, however,  is reliable enough for use in anoperational environment (the possible exceptions are expectation-driven systems, whichsimply ignore anything deviating from these built-in expectations).
Typical success ratesreported are that 75-80% of sentences are correctly analyzed, and that many erroneousanalyses pass the system undetected; this is not acceptable for most applications.
We see thecentral task of the work to be described below as the construction of a substantially morereliable system for narrative analysis.Our basic approach to increasing reliability will be to bring to bear on the analysistask as many different types of constraints as possible.
These include constraintsrelated to syntax, semantics, domain knowledge, and discourse structure.
In order to beable to capture the detailed knowledge about the domain that is needed for correct messageanalysis, we are initially limiting ourselves to messages about one particular piece ofequipment (the "starting air compressor");  if we are successful in this narrow domain, weintend to apply the system to a broader domain.The risk with having a rich set of constraints is that many of the sentences willviolate one constraint or another.
These violations may arise from problems in themessages or in the knowledge base.
On the one hand, the messages frequently containtypographical or grammatical errors (in addition to the systematic use of fragments,  whichcan be accounted for by our grammar).
On the other hand, it is unlikely that we will be ableto build a "complete" model of domain knowledge; gaps in the knowledge base willlead to constraint violations for some sentences.
To cope with these violations, we intendto develop a "forgiving" or flexible analyzer which will find a best analysis (one violatingthe fewest constraints) if no "perfect" analysis is possible.
One aspect of this is the useOf syntactic and semantic information on an equal footing in assembling an analysis, so that11neither a syntactic nor a semantic error would, by itself, block an analysis.2.
ApplicationThis work is work is a component of the Fleet Command Center Battle ManagementProgram (FCCBMP), which is part of the Strategic Computing Program.
The FCCBMPhas two natural language components: one for interactive natural language access, theother for message processing.
The interactive component -- which is to provide access to adata base and multiple expert systems -- is being integrated by Bolt Beranek and Newman.The message processing component is being integrated as a joint effort of New YorkUniversity and the System Development Corporation.Much of the information received by the Fleet Command Center is in the form ofmessages.
Some of these messages have a substantial natural language component.Consequently, natural language analysis is required if the information in these messages ito be recorded in a data base in a form usable by other programs.
The specific class ofmessages which we are studying are CASREPs, which are reports of equipment failureson board ships.
These messages contain a brief narrative, typically 3 tO 10 sentences inlength, describing the symptoms, diagnosis, and possibly the attempts at repair of thefailure.
A typical narrative is shown in Figure 1.
The problems we face in analyzing thesemessages are similar to those in analyzing short messages and reports in other technicaldomains, and we therefore expect that the solutions we develop will be widelyapplicable.3.
Project organizationThis work is a joint research effort of New York University and the SystemDevelopment Corporation.
NYU has principal responsibility for development of the domainknowledge base; SDC has principal responsibility for development of the flexible parser andfor the domain-independent discourse components.
The division of the other tasks is notedin the detailed component descriptions below.
We will also be integrating work on theknowledge base being done by SRI, which is a component technology developer for theFCCBMP natural anguage work.The work by NYU is being done in LISP (primarily in COMMON LISP), as is most ofthe Strategic Computing research.
SDC is doing its development in PROLOG becauseProlog provides a powerful framework for writing grammars; it also provides the inferenceengine necessary for knowledge structuring and reasoning about the discourse structures intext processing.
This division will permit us to make some valuable comparisons between theLISP and PROLOG development environments, and between the resulting systems.The system being developed in LISP by NYU is called PROTEUS (PROtotype TExtUnderstanding System) (Grishman et al.
,  submitted for publication); the SDC system iscalled PUNDIT (Prolog UNDerstander of Integrated Text) (Palmer et al 1986).Notwithstanding the difference in implementation languages, we have tried to maintain a highlevel of compatibility between the two systems.
We use essentially the same grammar andhave agreed on common representations for the output of the syntactic analyzer (theregularized syntactic structure) and the output of the semantic analyzer.
This commonalitymakes is possible assign primary responsibility for the design of a component to one group,and then to take the design developed for one system and port it to the other in astraightforward way.We are currently developing baseline systems which incorporate substantial domainknowledge but use a traditional sequential processing organization.
When these systems arecomplete, we will begin experimenting with flexible parsing algorithms.
The systemscurrently being developed (Figure 2) process input in the following stages: lexical look-up,parsing, syntactic regularization, semantic analysis, integration with the domain knowledge.1.2representation, and discourse analysis.
These components, and other tasks which are part ofour research program, are described individually below.4.
System Components4.1.
Lexicon (SDC + NYU)The lexicon consists of a modified version of the lexicon of the NYU Linguistic StringProject, with words classified as to part of speech and subcategorized for various grammaticalproperties (e.g., verbs and adjectives are subclassified for their complement types).4.2.
Lexical acquisition (SDC)The message vocabulary is large and will grow steadily as the system is modified tohandle a wider range of equipment; several measures are planned to manage the growth ofthe lexicon.
An interactive lexical entry program has been developed to facilitate addingwords to the dictionary.
Special constructions uch as dates, times, and part numbers areprocessed using a small definite clause grammar defining special shapes.
Future plansinclude addition of a component to use morphological nalysis and selectional patterns toaid in classification of new lexical items.4.3.
Syntax analysis (NYU + SDC)4.3.1.
GrammarThe syntactic component uses a grammar of BNF definitions with associatedrestrictions that enforce context-sensitive constraints on the parse.
This grammar isgenerally modelled after that developed by the NYU Linguistic String Project (Sager 1981).The grammar has been expanded to cover the fragmentary constructions and complex nounphrases characteristic of the Navy message domain.
A wide range of conjunction typesis parsed by a set of conjunction rules which are automatically generated by metarules(Hirschman, in press).
To serve as an interface between the syntactic and semanticcomponents, an additional set of rules produces a normalized intermediate representationof the syntax.4.3.2.
Top-Down ParsersTwo top-down parsers have been implemented using the common grammar justdescribed.
In each case, the analyzer applies the BNF definitions and their associatedconstraints to produce explicit surface structure parses of the input; the analyzer also invokesthe regularization rules which produce the normalized intermediate r presentation.In the NYU (LISP-based) system the basic algorithm is a chart parser, which providesgoal- directed analysis along with the recording (for possible re-use) of all intermediate goalstried.
The context sensitive constraints are expressed in a version of Restriction Language(Sager 1975) which is compiled into LISP.
The SDC (PROLOG-based) system uses a top-down left-to-right Prolog implementation f a version of the restriction grammar (Hirschmanand Puder 1986).4.4.
Flexible Analyzer (SDC)A major research focus for SDC during the first two years will be to produce aflexible analyzer that integrates application of syntactic and semantic constraints.
Theflexible analyzer will focus more quickly on the correct analysis and will have recoverystrategies to prevent syntactic analysis from becoming a bottleneck for subsequentprocessing.134.5.
Semantic AnalysisThe task of the semantic analyzer is to transform the regularized syntactic analysis intoa semantic representation.
This representation provides unique identifiers for specificequipment components mentioned in the text.
It consists of predicates describing states andevents involving the equipment, and higher-order predicates capturing the syntactically-expressed time and causal relations.
Roughly speaking, the clauses from the syntacticanalysis map into states and events, while the noun phrases map into particular objects (thereare several exceptions, including nominalizations, e.g., "loss of pressure", and adjectives ofstate, such as "broken valve").
Accordingly, the semantic analysis is divided into two majorparts, clause semantics and noun phrase semantics.
In addition to these two main parts, atime analysis component captures the time information which can be extracted from theinput.4.5.1.
Clause semantics (SDC)Semantic analysis of clauses is performed by Inference Driven Semantic Analysis(Palmer 1985), which analyzes verbs into their component meanings and fills their semanticroles, producing a semantic representation in predicate form.
This representationincludes information ormally found in a case-frame representation, but is more detailed.The task of filling in the semantic roles is used to integrate the noun phrase analysis(described in the next section) with the clausal semantic analysis.
In particular, the selectionrestriction information on the roles can be used to reject inappropriate referents for nounphrases.The semantics also provides a filtering function, by checking selectionalconstraints on verbs and their arguments.
The selectional constraints draw on domainknowledge for type and component information, as well as for information aboutpossible relationships between objects in the domain.
This function is currently used toaccept or reject a completed parse.
The goal for the flexible analyzer is to apply selectionalfiltering compositionally to partial syntactic analyses to rule out semanticallyunacceptable phrases as soon as they are generated in the parse.4.5.2.
Noun phrase semantics (SDC + NYU)A noun phrase resolution component determines the reference of noun phrases,drawing on two sources: a detailed equipment model, and cumulative information regardingreferents in previous entences.
SDC has concentrated on the role of prior discourse, and hasdeveloped a procedure which handles a wide variety of noun phrase types, includingpronouns and missing noun phrases, using a focusing algorithm based on surface syntacticstructure (Dahl, submitted for publication).
NYU, as part of its work on the domain model,has developed a procedure which can identify a component in the model from any of thenoun phrases which can name that component (Ksiezyk and Grishman, submitted forpublication).
After further development, these procedures wiU be integrated into acomprehensive noun phrase semantic analyzer.4.5.3.
Time analysis (SDC)SDC has started to develop a module to process time information.
Sources of timeinformation include verb tense, adverbial time expressions, prepositional phrases, co-ordinateand subordinate conjunctions.
These are all mapped into a small set of predicates expressinga partial time ordering among the states and events in the message.4.6.
Domain model (NYU)The domain model captures the detailed information about the general class ofequipment, and about the specific pieces of equipment involved in the messages; this14information needed in order to fully understand the messages.
The model integratespart/whole information, type/instance links, and functional information about the variouscomponents (Ksiezyk and Grishman, submitted for publication).The knowledge base performs several functions: it provides the domain-specificconstraints needed for the semantics to select the correct arguments for a predicate, so thatmodifiers are correctly attached to noun phrases.
It enables noun phrase semantics toidentify the correct referent for a phrase.
It provides the prototype information structureswhich are instantiated in order to record the information in a particular message.
It providesthe information on equipment structure and function which is used by the discourse rules inestablishing probable causal links between the sentences.
And finally, associated with thecomponents in the knowledge base are procedures for graphically displaying the status of theequipment as the message is interpreted.These functions are performed by a large network of frames implemented using theSymbolics Zetalisp flavors system.4.7.
Discourse analysis (NYU)The semantic analyzer generates eparate semantic representations for the individualsentences of the message.
For many applications it is important o establish the (normallyimplicit) intersentential relationships between the sentences.
This is performed by a set ofinference rules which (using the domain model) identify plausible causal and enablingrelationships among the sentences.
These relationships, once established, can serve toresolve some semantic ambiguities.
They can also supplement the time information extractedduring semantic analysis and thus clarify temporal relations among the sentences.4.8.
Diagnostics (NYU)The diagnostic procedures are intended to localize the cause of failure of the analysisand provide meaningful feedback when some domain-specific constraint has been violated.We are initially concentrating on violations of local (selectional) constraints, and have built asmall component for diagnosing such violations and suggesting acceptable sentence forms;later work will study more global discourse constraints.REFERENCESDahl, Deborah A.
(submitted for publication).
Focusing and Reference Resolution inPUNDIT.Grishman, Ralph, Tomasz Ksiezyk, and Ngo Thanh Nhan.
(submitted for publication).Model-based Analysis of Messages about Equipment.Hirschman, Lynette and Karl Puder (1986).
Restriction Grammar: A PrologImplementation, i  Logic Programming and its Applications, ed.
D.H.D.
Warren andM.
VanCaneghem, pp.
244-261, Ablex Publishing Co., Norwood, N.J.Hirschman, Lynette.
(in press).
"Conjunction in Meta-Restriction Grammar."
Journal ofLogic Programming.Ksiezyk, Tomasz, and Ralph Grishman.
(submitted for publication).
An Equipment Modeland its Role in the Interpretation of Nominal Compounds.Palmer, Martha S. (1985) Driving Semantics for a Limited Domain.
Ph.D. thesis.University of Edinburgh.15Palmer, Martha, Deborah Dahl, Rebecca Schiffman, Lynette Hirschman, MarciaLinebarger, and John Dowding.
(1986) Recovering Implicit Information.
To appearin Proc.
24th Annl.
Meeting Assn.
Computational Linguistics.Sager, Naomi and Ralph Grishman (1975).
The Restriction Language for ComputerGrammars of Natural Language.
Comm.
of the ACM, vol.
18, pp.
390-400.Sager, Naomi (1981).
Natural Language Information Processing: A Computer Grammar ofEnglish and its Applications.
Addison-Wesley, Reading, MA.16A Sample CASREPabout a SAC (Starting Air Compressor)DURING NORMAL START CYCLE OF 1A GAS TURBINE,APPROX 90 SEC AFTER CLUTCH ENGAGEMENT, LOWLUBE OIL AND FAIL TO ENGAGE ALARM WERERECEIVED ON THE ACC.
(ALL CONDITIONS WERENORMAL INITIALLY).
SAC WAS REMOVED ANDMETAL CHUNKS FOUND IN OIL PAN.
LUBE OIL PUMPWAS REMOVED AND WAS FOUND TO BE SEIZED.DRIVEN GEAR WAS SHEARED ON PUMP SHAFT.Figure iPROTEUS/PUNDIT SYSTEM STRUCTURELEXICON \]GRAMMAR(RESTRICTIONLANGUAGE)SYNTACTICREGULARIZATIONRULESDOMAIN INFORMATION:?
SEMAN.
MAPPING RULES?
PROTOTYPE FRAMES, (for equipment structureand function, discoursestru ctu re),IMESSAGE TEXT,I wn ~oo~u~ ICATEGORY/ATTRB.
LISTS~"~1PARSE TREESSYNTACTIC REGULAR.
IOPERATOR-OPERAND TREES~'~M SEMANTIC AND I ANAPHORI~ANALYSIS IANTIC CAS~MARKED TREESI~ / DOMAIN KNOWLEDGE /INSTANTIA D FRAMES- CAUSALITY- TIME1,ANALYZED MESSAGEFigure 218
