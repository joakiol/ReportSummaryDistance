Evaluating Smoothing Algorithms against Plausibility JudgementsMaria Lapata and Frank KellerDepartment of Computational LinguisticsSaarland UniversityPO Box 15 11 5066041 Saarbru?cken, Germanyfmlap, kellerg@coli.uni-sb.deScott McDonaldLanguage Technology GroupUniversity of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW, UKscottm@cogsci.ed.ac.ukAbstractPrevious research has shown that theplausibility of an adjective-noun com-bination is correlated with its corpusco-occurrence frequency.
In this paper,we estimate the co-occurrence frequen-cies of adjective-noun pairs that fail tooccur in a 100 million word corpususing smoothing techniques and com-pare them to human plausibility rat-ings.
Both class-based smoothing anddistance-weighted averaging yield fre-quency estimates that are significantpredictors of rated plausibility, whichprovides independent evidence for thevalidity of these smoothing techniques.1 IntroductionCertain combinations of adjectives and nouns areperceived as more plausible than others.
A classi-cal example is strong tea, which is highly plausi-ble, as opposed to powerful tea, which is not.
Onthe other hand, powerful car is highly plausible,whereas strong car is less plausible.
It has beenargued in the theoretical literature that the plausi-bility of an adjective-noun pair is largely a collo-cational (i.e., idiosyncratic) property, in contrastto verb-object or noun-noun plausibility, which ismore predictable (Cruse, 1986; Smadja, 1991).The collocational hypothesis has recentlybeen investigated in a corpus study byLapata et al (1999).
This study investigatedpotential statistical predictors of adjective-nounplausibility by using correlation analysis to com-pare judgements elicited from human subjectswith five corpus-derived measures: co-occurrencefrequency of the adjective-noun pair, nounfrequency, conditional probability of the noungiven the adjective, the log-likelihood ratio, andResnik?s (1993) selectional association measure.All predictors but one were positively correlatedwith plausibility; the highest correlation wasobtained with co-occurrence frequency.
Resnik?sselectional association measure surprisinglyyielded a significant negative correlation withjudged plausibility.
These results suggest thatthe best predictor of whether an adjective-nouncombination is plausible or not is simply howoften the adjective and the noun collocate in arecord of language experience.As a predictor of plausibility, co-occurrencefrequency has the obvious limitation that it can-not be applied to adjective-noun pairs that neveroccur in the corpus.
A zero co-occurrence countmight be due to insufficient evidence or mightreflect the fact that the adjective-noun pair is in-herently implausible.
In the present paper, we ad-dress this problem by using smoothing techniques(distance-weighted averaging and class-basedsmoothing) to recreate missing co-occurrencecounts, which we then compare to plausibilityjudgements elicited from human subjects.
Bydemonstrating a correlation between recreatedfrequencies and plausibility judgements, we showthat these smoothing methods produce realisticfrequency estimates for missing co-occurrencedata.
This approach allows us to establish the va-lidity of smoothing methods independent from aspecific natural language processing task.2 Smoothing MethodsSmoothing techniques have been used in a varietyof statistical natural language processing applica-tions as a means to address data sparseness, an in-herent problem for statistical methods which relyon the relative frequencies of word combinations.The problem arises when the probability of wordcombinations that do not occur in the trainingdata needs to be estimated.
The smoothing meth-ods proposed in the literature (overviews are pro-vided by Dagan et al (1999) and Lee (1999)) canbe generally divided into three types: discount-ing (Katz, 1987), class-based smoothing (Resnik,1993; Brown et al, 1992; Pereira et al, 1993),and distance-weighted averaging (Grishman andSterling, 1994; Dagan et al, 1999).Discounting methods decrease the probabilityof previously seen events so that the total prob-ability of observed word co-occurrences is lessthan one, leaving some probability mass to be re-distributed among unseen co-occurrences.Class-based smoothing and distance-weightedaveraging both rely on an intuitively simple idea:inter-word dependencies are modelled by relyingon the corpus evidence available for words thatare similar to the words of interest.
The two ap-proaches differ in the way they measure wordsimilarity.
Distance-weighted averaging estimatesword similarity from lexical co-occurrence infor-mation, viz., it finds similar words by taking intoaccount the linguistic contexts in which they oc-cur: two words are similar if they occur in sim-ilar contexts.
In class-based smoothing, classesare used as the basis according to which the co-occurrence probability of unseen word combina-tions is estimated.
Classes can be induced directlyfrom the corpus (Pereira et al, 1993; Brown et al,1992) or taken from a manually crafted taxonomy(Resnik, 1993).
In the latter case the taxonomy isused to provide a mapping from words to concep-tual classes.In language modelling, smoothing techniquesare typically evaluated by showing that a lan-guage model which uses smoothed estimates in-curs a reduction in perplexity on test data over amodel that does not employ smoothed estimates(Katz, 1987).
Dagan et al (1999) use perplexityto compare back-off smoothing against distance-weighted averaging methods and show that thelatter outperform the former.
They also com-pare different distance-weighted averaging meth-ods on a pseudo-word disambiguation task wherethe language model decides which of two verbsv1 and v2 is more likely to take a noun n as itsobject.
The method being tested must reconstructwhich of the unseen (v1,n) and (v2,n) is a validverb-object combination.In our experiments we recreated co-occurrencefrequencies for unseen adjective-noun pairs usingtwo different approaches: taxonomic class-basedsmoothing and distance-weighted averaging.1 Weevaluated the recreated frequencies by comparingthem with plausibility judgements elicited fromhuman subjects.
In contrast to previous work, thistype of evaluation does not presuppose that therecreated frequencies are needed for a specificnatural language processing task.
Rather, our aimis to establish an independent criterion for thevalidity of smoothing techniques by comparingthem to plausibility judgements, which are knownto correlate with co-occurrence frequency (Lapataet al, 1999).In the remainder of this paper we present class-1Discounting methods were not included asDagan et al (1999) demonstrated that distance-weightedaveraging achieves better language modelling performancethan back-off.based smoothing and distance-weighted averag-ing as applied to unseen adjective-noun combina-tions (see Sections 2.1 and 2.2).
Section 3 detailsour judgement elicitation experiment and reportsour results.2.1 Class-based SmoothingWe recreated co-occurrence frequencies for un-seen adjective-noun pairs using a simplified ver-sion of Resnik?s (1993) selectional associationmeasure.
Selectional association is defined as theamount of information a given predicate carriesabout its argument, where the argument is rep-resented by its corresponding classes in a taxon-omy such as WordNet (Miller et al, 1990).
Thismeans that predicates which impose few restric-tions on their arguments have low selectional as-sociation values, whereas predicates selecting fora restricted number of arguments have high se-lectional association values.
Consider the verbssee and polymerise: intuitively there is a greatvariety of things which can be seen, whereasthere is a very specific set of things which canbe polymerised (e.g., ethylene).
Resnik demon-strated that his measure of selectional associa-tion successfully captures this intuition: selec-tional association values are correlated with verb-argument plausibility as judged by native speak-ers.However, Lapata et al (1999) found that thesuccess of selectional association as a predictorof plausibility does not seem to carry over toadjective-noun plausibility.
There are two poten-tial reasons for this: (1) the semantic restrictionsthat adjectives impose on the nouns with whichthey combine appear to be less strict than theones imposed by verbs (consider the adjective su-perb which can combine with nearly any noun);and (2) given their lexicalist nature, adjective-noun combinations may defy selectional restric-tions yet be intuitively plausible (consider the pairsad day, where sadness is not an attribute of day).To address these problems, we replacedResnik?s information-theoretic measure with asimpler measure which makes no assumptionswith respect to the contribution of a semanticclass to the total quantity of information providedby the predicate about the semantic classes ofits argument.
We simply substitute the noun oc-curring in the adjective-noun combination withthe concept by which it is represented in thetaxonomy and estimate the adjective-noun co-occurrence frequency by counting the number oftimes the concept corresponding to the noun is ob-served to co-occur with the adjective in the cor-pus.
Because a given word is not always repre-sented by a single class in the taxonomy (i.e., theAdjective Class f (a,n)proud hentityi 13.70proud hlife fromi 9.80proud hcausal agenti 9.50proud hpersoni 9.00proud hleaderi .75proud hsuperiori .08proud hsupervisori .00Table 1: Frequency estimation for proud chief us-ing WordNetnoun co-occurring with an adjective can gener-ally be the realisation of one of several conceptualclasses), we constructed the frequency counts foran adjective-noun pair for each conceptual classby dividing the contribution from the adjective bythe number of classes to which it belongs (Lauer,1995; Resnik, 1993):f (a,c)  ?n02cf (a,n0)jclasses(n0)j(1)where f (a,n0) is the number of times the ad-jective a was observed in the corpus with con-cept c 2 classes(n0) and jclasses(n0)j is the num-ber of conceptual classes noun n0 belongs to.
Notethat the estimation of the frequency f (a,c) relieson the simplifying assumption that the noun co-occurring with the adjective is distributed evenlyacross its conceptual classes.
This simplificationis necessary unless we have a corpus of adjective-noun pairs labelled explicitly with taxonomic in-formation.2Consider the pair proud chief which isnot attested in the British National Corpus(BNC) (Burnard, 1995).
The word chief hastwo senses in WordNet and belongs to sevenconceptual classes (hcausal agenti, hentityi,hleaderi, hlife formi, hpersoni, hsuperiori,and hsupervisori) This means that the co-occurrence frequency of the adjective-noun pairwill be constructed for each of the seven classes,as shown in Table 1.
Suppose for example thatwe see the pair proud leader in the corpus.
Theword leader has two senses in WordNet andbelongs to eight conceptual classes (hpersoni,hlife fromi, hentityi, hcausal agenti,hfeaturei, hmerchandisei, hcommodityi, andhobjecti).
The words chief and leader have fourconceptual classes in common, i.e., hpersoni andhlife formi, hentityi, and hcausal agenti.This means that we will increment the observedco-occurrence count of proud and hpersoni,proud and hlife formi, proud and hentityi,and proud and hcausal agenti by 18 .
Since we2There are several ways of addressing this problem, e.g.,by discounting the contribution of very general classes byfinding a suitable class to represent a given concept (Clarkand Weir, 2001).do not know the actual class of the noun chief inthe corpus, we weight the contribution of eachclass by taking the average of the constructedfrequencies for all seven classes:f (a,n) =?c2classes(n)?n02cf (a,n0)jclasses(n0)jjclasses(n)j(2)Based on (2) the recreated frequency for the pairproud chief in the BNC is 6.12 (see Table 1).2.2 Distance-Weighted AveragingDistance-weighted averaging induces classes ofsimilar words from word co-occurrences with-out making reference to a taxonomy.
A key fea-ture of this type of smoothing is the functionwhich measures distributional similarity from co-occurrence frequencies.
Several measures of dis-tributional similarity have been proposed in theliterature (Dagan et al, 1999; Lee, 1999).
Weused two measures, the Jensen-Shannon diver-gence and the confusion probability.
Those twomeasures have been previously shown to givepromising performance for the task of estimat-ing the frequencies of unseen verb-argument pairs(Dagan et al, 1999; Grishman and Sterling, 1994;Lapata, 2000; Lee, 1999).
In the following wedescribe these two similarity measures and showhow they can be used to recreate the frequenciesfor unseen adjective-noun pairs.Jensen-Shannon Divergence.
The Jensen-Shannon divergence is an information-theoreticmeasure that recasts the concept of distributionalsimilarity into a measure of the ?distance?
(i.e., dissimilarity) between two probabilitydistributions.Let w1 and w01 be an unseen sequence oftwo words whose distributional similarity is tobe determined.
Let P(w2jw1) denote the condi-tional probability of word w2 given word w1 andP(w2jw01) denote the conditional probability ofw2 given w01.
For notational simplicity we writep(w2) for P(w2jw1) and q(w2) for P(w2jw01).
TheJensen-Shannon divergence is defined as the av-erage Kullback-Leibler divergence of each of twodistributions to their average distribution:J(p,q) =12Dp????p+q2+Dq???
?p+q2(3)where (p+q)/2 denotes the average distribution:12(P(w2jw1)+P(w2jw01)(4)The Kullback-Leibler divergence is aninformation-theoretic measure of the dissim-ilarity of two probability distributions p and q,defined as follows:D(pjjq) = ?ipi logpiqi(5)In our case the distributions p and q are theconditional probability distributions P(w2jw1)and P(w2jw01), respectively.
Computation of theJensen-Shannon divergence depends only on thelinguistic contexts w2 which the two words w1and w01 have in common.
The Jensen-Shannon di-vergence, a dissimilarity measure, is transformedto a similarity measure as follows:WJ(p,q) = 10?
?J(p,q)(6)The parameter ?
controls the relative influence ofthe words most similar to w1: if ?
is high, onlywords extremely similar to w1 contribute to theestimate, whereas if ?
is low, less similar wordsalso contribute to the estimate.Confusion Probability.
The confusion proba-bility is an estimate of the probability that wordw01 can be substituted by word w1, in the sense ofbeing found in the same linguistic contexts.Pc(w1jw01) = ?w2P(w1jw2)P(w2jw01)(7)where Pc(w01jw1) is the probability that word w01occurs in the same contexts w2 as word w1, aver-aged over these contexts.Let w2w1 be two unseen co-occurring words.We can estimate the conditional probabilityP(w2jw1) of the unseen word pair w2w1 by com-bining estimates for co-occurrences involvingsimilar words:PSIM(w2jw1) = ?w012S(w1)W (w1,w01)N(w1)P(w2jw01)(8)where S(w1) is the set of words most similar tow1, W (w1,w01) is the similarity function betweenw1 and w01, and N(w1) is a normalising factorN(w1) = ?w01 W (w1,w01).
The conditional proba-bility PSIM(w2jw1) can be trivially converted toco-occurrence frequency as follows:f (w1,w2) = PSIM(w2jw1) f (w1)(9)Parameter Settings.
We experimented withtwo approaches to computing P(w2jw01): (1) us-ing the probability distribution P(nja), which dis-covers similar adjectives and treats the noun asthe context; and (2) using P(ajn), which discoverssimilar nouns and treats the adjective as the con-text.
These conditional probabilities can be easilyestimated from their relative frequency in the cor-pus as follows:P(nja) =f (a,n)f (a) P(ajn) =f (a,n)f (n)(10)The performance of distance-weighted averagingdepends on two parameters: (1) the number ofitems over which the similarity function is com-puted (i.e., the size of the set S(w1) denoting theset of words most similar to w1), and (2) theJensen-Shannon Confusion Probabilityproud chief proud chiefyoung chairman lone ventureold venture adverse chairmandying government grateful importancewealthy leader sole forcelone official wealthy representativedead scientist elderly presidentrich manager registered officialpoor initiative dear managerelderly president deliberate directorTable 2: The ten most similar adjectives to proudand the ten most similar nouns to chiefvalue of the parameter ?
(which is only relevantfor the Jensen-Shannon divergence).
In this studywe recreated adjective-noun frequencies usingthe 1,000 and 2,000 most frequent items (nounsand adjectives), for both the confusion probabil-ity and the Jensen-Shannon divergence.3 Further-more, we set ?
to .5, which experiments showedto be the best value for this parameter.Once we know which words are most simi-lar to the either the adjective or the noun (irre-spective of the function used to measure similar-ity) we can exploit this information in order torecreate the co-occurrence frequency for unseenadjective-noun pairs.
We use the weighted aver-age of the evidence provided by the similar words,where the weight given to a word w01 dependson its similarity to w1 (see (8) and (9)).
Table 2shows the ten most similar adjectives to the wordproud and then the ten most similar nouns to theword chief using the Jensen-Shannon divergenceand the confusion probability.
Here the similarityfunction was calculated over the 1,000 most fre-quent adjectives in the BNC.3 Collecting Plausibility RatingsIn order to evaluate the smoothing methods intro-duced above, we first needed to establish an inde-pendent measure of plausibility.
The standard ap-proach used in experimental psycholinguistics isto elicit judgements from human subjects; in thissection we describe our method for assemblingthe set of experimental materials and collectingplausibility ratings for these stimuli.3.1 MethodMaterials.
We used a part-of-speech annotated,lemmatised version of the BNC.
The BNC is alarge, balanced corpus of British English, consist-ing of 90 million words of text and 10 millionwords of speech.
Frequency information obtained3These were shown to be the best parameter settings byLapata (2000).
Note that considerable latitude is availablewhen setting these parameters; there are 151,478 distinct ad-jective types and 367,891 noun types in the BNC.Adjective Nounshungry tradition innovation preyguilty system wisdom wartimetemporary conception surgery statuenaughty regime rival protocolTable 3: Example stimuli for the plausibilityjudgement experimentfrom the BNC can be expected to be a reason-able approximation of the language experience ofa British English speaker.The experiment used the same set of 30 adjec-tives discussed in Lapata et al (1999).
These ad-jectives were chosen to be minimally ambiguous:each adjective had exactly two senses accordingto WordNet and was unambiguously tagged as?adjective?
98.6% of the time, measured as thenumber of different part-of-speech tags assignedto the word in the BNC.
For each adjective weobtained all the nouns (excluding proper nouns)with which it failed to co-occur in the BNC.We identified adjective-noun pairs by usingGsearch (Corley et al, 2001), a chart parser whichdetects syntactic patterns in a tagged corpus byexploiting a user-specified context free grammarand a syntactic query.
From the syntactic anal-ysis provided by the parser we extracted a ta-ble containing the adjective and the head of thenoun phrase following it.
In the case of compoundnouns, we only included sequences of two nouns,and considered the rightmost occurring noun asthe head.
From the adjective-noun pairs obtainedthis way, we removed all pairs where the nounhad a BNC frequency of less than 10 per million,in order to reduce the risk of plausibility ratingsbeing influenced by the presence of a noun un-familiar to the subjects.
Each adjective was thenpaired with three randomly-chosen nouns from itslist of non-co-occurring nouns.
Example stimuliare shown in Table 3.Procedure.
The experimental paradigm wasmagnitude estimation (ME), a technique stan-dardly used in psychophysics to measure judge-ments of sensory stimuli (Stevens, 1975), whichBard et al (1996) and Cowart (1997) have ap-plied to the elicitation of linguistic judgements.The ME procedure requires subjects to estimatethe magnitude of physical stimuli by assigningnumerical values proportional to the stimulusmagnitude they perceive.
In contrast to the 5- or7-point scale conventionally used to measure hu-man intuitions, ME employs an interval scale, andtherefore produces data for which parametric in-ferential statistics are valid.ME requires subjects to assign numbers toa series of linguistic stimuli in a proportionalPlaus Jena Confa Jenn ConfnJena .058Confa .214* .941**Jenn .124 .781** .808**Confn .232* .782** .864** .956**WN .356** .222* .348** .451** .444***p < .05 (2-tailed) **p < .01 (2-tailed)Table 4: Correlation matrix for plausibility andthe five smoothed frequency estimatesfashion.
Subjects are first exposed to a modulusitem, which they assign an arbitrary number.
Allother stimuli are rated proportional to the modu-lus.
In this way, each subject can establish theirown rating scale, thus yielding maximally fine-graded data and avoiding the known problemswith the conventional ordinal scales for linguis-tic data (Bard et al, 1996; Cowart, 1997; Schu?tze,1996).In the present experiment, subjects were pre-sented with adjective-noun pairs and were askedto rate the degree of adjective-noun fit propor-tional to a modulus item.
The experiment was car-ried out using WebExp, a set of Java-Classes foradministering psycholinguistic studies over theWorld-Wide Web (Keller et al, 1998).
Subjectsfirst saw a set of instructions that explained theME technique and included some examples, andhad to fill in a short questionnaire including basicdemographic information.
Each subject saw theentire set of 90 experimental items.Subjects.
Forty-one native speakers of Englishvolunteered to participate.
Subjects were re-cruited over the Internet by postings to relevantnewsgroups and mailing lists.3.2 ResultsCorrelation analysis was used to assess the degreeof linear relationship between plausibility ratings(Plaus) and the three smoothed co-occurrencefrequency estimates: distance-weighted averagingusing Jensen-Shannon divergence (Jen), distance-weighted averaging using confusion probability(Conf), and class-based smoothing using Word-Net (WN).
For the two similarity-based measures,we smoothed either over the similarity of the ad-jective (subscript a) or over the similarity of thenoun (subscript n).
All frequency estimates werenatural log-transformed.Table 4 displays the results of the corre-lation analysis.
Mean plausibility ratings weresignificantly correlated with co-occurrence fre-quency recreated using our class-based smooth-ing method based on WordNet (r = .356, p <.01).As detailed in Section 2.2, the Jensen-Shannondivergence and the confusion probability are pa-rameterised measures.
There are two ways tosmooth the frequency of an adjective-noun com-bination: over the distribution of adjectives orover the distribution of nouns.
We tried both ap-proaches and found a moderate correlation be-tween plausibility and both the frequency recre-ated using distance-weighted averaging and con-fusion probability.
The correlation was significantboth for frequencies recreated by smoothing overadjectives (r = .214, p < .05) and over nouns(r = .232, p < .05).
However, co-occurrence fre-quency recreated using the Jensen-Shannon di-vergence was not reliably correlated with plausi-bility.
Furthermore, there was a reliable correla-tion between the two Jensen-Shannon measuresJena and Jenn (r = .781, p < .01), and similarlybetween the two confusion measures Confa andConfn (r = .864, p < .01).
We also found a highcorrelation between Jena and Confa (r = .941,p < .01) and Jenn and Confn (r = .956, p < .01).This indicates that the two similarity measuresyield comparable results for the given task.We also examined the effect of varying onefurther parameter (see Section 2.2).
The recre-ated frequencies were initially estimated usingthe n = 1,000 most similar items.
We examinedthe effects of applying the two smoothing meth-ods using a set of similar items of twice the size(n = 2,000).
No improvement in terms of the cor-relations with rated plausibility was found whenusing this larger set, whether smoothing over theadjective or the noun: a moderate correlation withplausibility was found for Confa (r = .239, p <.05) and Confn (r = .239, p < .05), while the cor-relation with Jena and Jenn was not significant.An important question is how well people agreein their plausibility judgements.
Inter-subjectagreement gives an upper bound for the task andallows us to interpret how well the smoothingtechniques are doing in relation to the humanjudges.
We computed the inter-subject correlationon the elicited judgements using leave-one-out re-sampling (Weiss and Kulikowski, 1991).
Aver-age inter-subject agreement was .55 (Min = .01,Max = .76, SD = .16).
This means that our ap-proach performs satisfactorily given that there isa fair amount of variability in human judgementsof adjective-noun plausibility.One remaining issue concerns the validityof our smoothing procedures.
We have shownthat co-occurrence frequencies recreated usingsmoothing techniques are significantly correlatedwith rated plausibility.
But this finding consti-tutes only indirect evidence for the ability of thismethod to recreate corpus evidence; it depends onthe assumption that plausibility and frequency areadequate indicators of each other?s values.
DoesWN Jena Confa Jenn ConfnActual freq.
.218* .324** .646** .308** .728**Plausibility .349** .268* .395** .247* .416***p < .05 (2-tailed) **p < .01 (2-tailed)Table 5: Correlation of recreated frequencies withactual frequencies and plausibility (using Lapataet al?s (1999) stimuli)smoothing accurately recreate the co-occurrencefrequency of combinations that actually do occurin the corpus?
To address this question, we ap-plied the class-based smoothing procedure to aset of adjective-noun pairs that occur in the cor-pus with varying frequencies, using the materialsfrom Lapata et al (1999).First, we removed all relevant adjective-nouncombinations from the corpus.
Effectively weassumed a linguistic environment with no evi-dence for the occurrence of the pair, and thusno evidence for any linguistic relationship be-tween the adjective and the noun.
Then we recre-ated the co-occurrence frequencies using class-based smoothing and distance-weighted averag-ing, and log-transformed the resulting frequen-cies.
Both methods yielded reliable correlationbetween recreated frequency and actual BNC fre-quency (see Table 5 for details).
This result pro-vides additional evidence for the claim that thesesmoothing techniques produce reliable frequencyestimates for unseen adjective-noun pairs.
Notethat the best correlations were achieved for Confaand Confn (r = .646, p < .01 and r = .728, p <.01, respectively).Finally, we carried out a further test of thequality of the recreated frequencies by correlat-ing them with the plausibility judgements re-ported by Lapata et al (1999).
Again, a signifi-cant correlation was found for all methods (seeTable 5).
However, all correlations were lowerthan the correlation of the actual frequencieswith plausibility (r = .570, p < .01) reportedby Lapata et al (1999).
Note also that the con-fusion probability outperformed Jensen-Shannondivergence, in line with our results on unfamiliaradjective-noun pairs.3.3 DiscussionLapata et al (1999) demonstrated that the co-occurrence frequency of an adjective-noun com-bination is the best predictor of its rated plausibil-ity.
The present experiment extended this result toadjective-noun pairs that do not co-occur in thecorpus.We applied two smoothing techniques in orderto recreate co-occurrence frequency and foundthat the class-based smoothing method was thebest predictor of plausibility.
This result is inter-guilty dangerous stop giantguilty dangerous stop giantinterested certain moon companyinnocent different employment manufacturerinjured particular length artistlabour difficult detail industrysocialist other page firmstrange strange time stardemocratic similar potential masterruling various list armyhonest bad turn rivalTable 6: The ten most similar words to the adjec-tives guilty and dangerous and the nouns stop andgiant discovered by the Jensen-Shannon measureesting because the class-based method does notuse detailed knowledge about word-to-word rela-tionships in real language; instead, it relies on thenotion of equivalence classes derived from Word-Net, a semantic taxonomy.
It appears that makingpredictions about plausibility is most effectivelydone by collapsing together the speaker?s experi-ence with other words in the semantic class occu-pied by the target word.The distance-weighted averaging smoothingmethods yielded a lower correlation with plausi-bility (in the case of the confusion probability),or no correlation at all (in the case of the Jensen-Shannon divergence).
The worse performance ofdistance-weighted averaging is probably due tothe fact that this method conflates two kinds ofdistributional similarity: on the one hand, it gen-erates words that are semantically similar to thetarget word.
On the other hand, it also generateswords whose syntactic behaviour is similar to thatof the target word.
Rated plausibility, however,seems to be more sensitive to semantic than tosyntactic similarity.As an example refer to Table 6, which displaysthe ten most distributionally similar words to theadjectives guilty and dangerous and to the nounsstop and giant discovered by the Jensen-Shannonmeasure.
The set of similar words is far from se-mantically coherent.
As far as the adjective guiltyis concerned the measure discovered antonymssuch as innocent and honest.
Semantically unre-lated adjectives such as injured, democratic, or in-terested are included; it seems that their syntacticbehaviour is similar to that of guilty, e.g., they allco-occur with party.
The same pattern can be ob-served for the adjective dangerous, to which noneof the discovered adjectives are intuitively seman-tically related, perhaps with the exception of bad.The set of words most similar to the noun stopalso does not appear to be semantically coherent.This problem with distance-weighted averag-ing is aggravated by the fact that the adjectiveor noun that we smooth over can be polysemous.Take the set of similar words for giant, for in-stance.
The words company, manufacturer, indus-try and firm are similar to the ?enterprise?
senseof giant, whereas artist, star, master are similarto the ?important/influential person?
sense of gi-ant.
However, no similar word was found for ei-ther the ?beast?
or ?heavyweight person?
sense ofgiant.
This illustrates that the distance-weightedaveraging approach fails to take proper accountof the polysemy of a word.
The class-based ap-proach, on the other hand, relies on WordNet, alexical taxonomy that can be expected to covermost senses of a given lexical item.Recall that distance-weighted averaging dis-covers distributionally similar words by look-ing at simple lexical co-occurrence information.In the case of adjective-noun pairs we concen-trated on combinations found in the corpus ina head-modifier relationship.
This limited formof surface-syntactic information does not seemto be sufficient to reproduce the detailed knowl-edge that people have about the semantic relation-ships between words.
Our class-based smoothingmethod, on the other hand, relies on the semantictaxonomy of WordNet, where fine-grained con-ceptual knowledge about words and their rela-tions is encoded.
This knowledge can be used tocreate semantically coherent equivalence classes.Such classes will not contain antonyms or itemswhose behaviour is syntactically related, but notsemantically similar, to the words of interest.To summarise, it appears that distance-weighted averaging smoothing is only partiallysuccessful in reproducing the linguistic depen-dencies that characterise and constrain the forma-tion of adjective-noun combinations.
The class-based smoothing method, however, relies on apre-defined taxonomy that allows these depen-dencies to be inferred, and thus reliably estimatesthe plausibility of adjective-noun combinationsthat fail to co-occur in the corpus.4 ConclusionsThis paper investigated the validity of smoothingtechniques by using them to recreate the frequen-cies of adjective-noun pairs that fail to occur ina 100 million word corpus.
We showed that therecreated frequencies are significantly correlatedwith plausibility judgements.
These results werethen extended by applying the same smoothingtechniques to adjective-noun pairs that occur inthe corpus.
These recreated frequencies were sig-nificantly correlated with the actual frequencies,as well as with plausibility judgements.Our results provide independent evidence forthe validity of the smoothing techniques we em-ployed.
In contrast to previous work, our evalu-ation does not presuppose that the recreated fre-quencies are used in a specific natural languageprocessing task.
Rather, we established an in-dependent criterion for the validity of smooth-ing techniques by comparing them to plausibil-ity judgements, which are known to correlatewith co-occurrence frequency.
We also carriedout a comparison of different smoothing meth-ods, and found that class-based smoothing outper-forms distance-weighted averaging.4From a practical point of view, our findingsprovide a very simple account of adjective-noun plausibility.
Extending the results ofLapata et al (1999), we confirmed that co-occurrence frequency can be used to estimate theplausibility of an adjective-noun pair.
If no co-occurrence counts are available from the corpus,then counts can be recreated using the corpus anda structured source of taxonomic knowledge (forthe class-based approach).
Distance-weightedaveraging can be seen as a ?cheap?
way to obtainthis sort of taxonomic knowledge.
However, thismethod does not draw upon semantic informa-tion only, but is also sensitive to the syntacticdistribution of the target word.
This explains thefact that distance-weighted averaging yieldeda lower correlation with perceived plausibilitythan class-based smoothing.
A taxonomy likeWordNet provides a cleaner source of conceptualinformation, which captures essential aspects ofthe type of knowledge needed for assessing theplausibility of an adjective-noun combination.ReferencesEllen Gurman Bard, Dan Robertson, and Antonella Sorace.1996.
Magnitude estimation of linguistic acceptability.Language, 72(1):32?68.Peter F. Brown, Vincent J. Della Pietra, Peter V. de Souza,and Robert L. Mercer.
1992.
Class-based n-grammodels of natural language.
Computational Linguistics,18(4):467?479.Lou Burnard, 1995.
Users Guide for the British NationalCorpus.
British National Corpus Consortium, OxfordUniversity Computing Service.Stephen Clark and David Weir.
2001.
Class-based probabil-ity estimation using a semantic hierarchy.
In Proceedingsof the 2nd Conference of the North American Chapterof the Association for Computational Linguistics, Pitts-burgh, PA.Steffan Corley, Martin Corley, Frank Keller, Matthew W.Crocker, and Shari Trewin.
2001.
Finding syntactic4Two anonymous reviewers point out that this conclusiononly holds for an approach that computes similarity based onadjective-noun co-occurrences.
Such co-occurrences mightnot reflect semantic relatedness very well, due to the idiosyn-cratic nature of adjective-noun combinations.
It is possiblethat distance-weighted averaging would yield better results ifapplied to other co-occurrence data (e.g., subject-verb, verb-object), which could be expected to produce more reliableinformation about semantic similarity.structure in unparsed corpora: The Gsearch corpus querysystem.
Computers and the Humanities, 35(2):81?94.Wayne Cowart.
1997.
Experimental Syntax: Applying Ob-jective Methods to Sentence Judgments.
Sage Publica-tions, Thousand Oaks, CA.D.
A. Cruse.
1986.
Lexical Semantics.
Cambridge Text-books in Linguistics.
Cambridge University Press, Cam-bridge.Ido Dagan, Lillian Lee, and Fernando Pereira.
1999.Similarity-based models of word cooccurrence probabil-ities.
Machine Learning, 34(1):43?69.Ralph Grishman and John Sterling.
1994.
Generalizing au-tomatically generated selectional patterns.
In Proceed-ings of the 15th International Conference on Computa-tional Linguistics, pages 742?747, Kyoto.Slava M. Katz.
1987.
Estimation of probabilities fromsparse data for the language model component of aspeech recognizer.
IEEE Transactions on AcousticsSpeech and Signal Processing, 33(3):400?401.Frank Keller, Martin Corley, Steffan Corley, Lars Konieczny,and Amalia Todirascu.
1998.
WebExp: A Java tool-box for web-based psychological experiments.
TechnicalReport HCRC/TR-99, Human Communication ResearchCentre, University of Edinburgh.Maria Lapata, Scott McDonald, and Frank Keller.
1999.Determinants of adjective-noun plausibility.
In Proceed-ings of the 9th Conference of the European Chapter of theAssociation for Computational Linguistics, pages 30?36,Bergen.Maria Lapata.
2000.
The Acquisition and Modeling of Lexi-cal Knowledge: A Corpus-based Investigation of System-atic Polysemy.
Ph.D. thesis, University of Edinburgh.Mark Lauer.
1995.
Designing Statistical Language Learn-ers: Experiments on Compound Nouns.
Ph.D. thesis,Macquarie University, Sydney.Lilian Lee.
1999.
Measures of distributional similarity.
InProceedings of the 37th Annual Meeting of the Associa-tion for Computational Linguistics, pages 25?32, Univer-sity of Maryland, College Park.George A. Miller, Richard Beckwith, Christiane Fellbaum,Derek Gross, and Katherine J. Miller.
1990.
Introductionto WordNet: An on-line lexical database.
InternationalJournal of Lexicography, 3(4):235?244.Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993.Distributional clustering of English words.
In Proceed-ings of the 31st Annual Meeting of the Association forComputational Linguistics, pages 183?190, Columbus,OH.Philip Stuart Resnik.
1993.
Selection and Information: AClass-Based Approach to Lexical Relationships.
Ph.D.thesis, University of Pennsylvania, Philadelphia, PA.Carson T. Schu?tze.
1996.
The Empirical Base of Linguis-tics: Grammaticality Judgments and Linguistic Method-ology.
University of Chicago Press, Chicago.Frank Smadja.
1991.
Macrocoding the lexicon with co-occurrence knowledge.
In Uri Zernik, editor, Lexical Ac-quisition: Using Online Resources to Build a Lexicon,pages 165?189.
Lawrence Erlbaum Associates, Hillsdale,NJ.S.
S. Stevens.
1975.
Psychophysics: Introduction to its Per-ceptual, Neural, and Social Prospects.
John Wiley, NewYork.Sholom M. Weiss and Casimir A. Kulikowski.
1991.
Com-puter Systems that Learn: Classification and PredictionMethods from Statistics, Neural Nets, Machine Learning,and Expert Systems.
Morgan Kaufmann, San Mateo, CA.
