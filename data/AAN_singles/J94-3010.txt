Phonological Analysis in TypedFeature SystemsSteven Bird*University of EdinburghEwan Klein*University of EdinburghResearch on constraint-based grammar f ameworks has focused on syntax and semantics largely tothe exclusion of phonology.
Likewise, current developments in phonology have generally ignoredthe technical and linguistic innovations available in these frameworks.
In this paper we suggestsome strategies for reuniting phonology and the rest of grammar in the context of a uniformconstraint formalism.
We explain why this is a desirable goal, and we present some conservativeextensions to current practice in computational linguistics and in nonlinear phonology that webelieve are necessary and sufficient for achieving this goal.We begin by exploring the application of typed feature logic to phonology and propose asystem of prosodic types.
Next, taking HPSG as an exemplar of the grammar f ameworks we havein mind, we show how the phonology attribute can be enriched so that it can encode multi-tiered,hierarchical phonological representations.
Finally, we exemplify the approach in some detail for thenonconcatenative morphology ofSierra Miwok and for schwa lternation i  French.
The approachtaken in this paper lends itself particularly well to capturing phonological generalizations intermsof high-level prosodic onstraints.1.
Phonology in Constraint-Based GrammarClassical generative phonology is couched within the same set of assumptions thatdominated standard transformational grammar.
Despite some claims that "deriva-tions based on ordered rules (that is, external ordering) and incorporating interme-diate structures are essential to phonology" (Bromberger and Halle 1989:52), muchrecent work has tended toward a new model, frequently described in terms of con-straints on well-formedness (Paradis 1988; Goldsmith 1993; McCarthy and Prince 1993;Prince and Smolensky 1993).
While this work has an increasingly declarative flavor,most versions retain procedural devices for repairing representations that fail to meetcertain constraints, or for constraints to override each other.
This view is in markedcontrast o the interpretation of constraints in grammar frameworks like LFG, GPSG,and HPSG 1 and in constraint programming systems more generally (Jaffar and Lassez1987; Smolka 1992).
In such approaches, constraints cannot be circumvented, thereare no 'intermediate structures,' and the well-formedness constraint (Partee 1979) isobserved (i.e.
ill-formed representations can never be created).
The advantage of theseframeworks is that they allow interesting linguistic analyses to be encoded whileremaining computationally tractable.
* University of Edinburgh, Centre for Cognitive Science, 2 Buccleuch Place, Edinburgh EH8 9LW, U.K.E-maih steven.ewan@cogni.ed.ac.uk1 Lexical Functional Grammar (Kaplan and Bresnan 1982), Generalized Phrase Structure Grammar(Gazdar, Klein, Pullum, and Sag 1985), and Head-Driven Phrase Structure Grammar (Pollard and Sag1987).?
1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 3Here, we are interested in the question of what a theory of phonology ought to looklike if it is to be compatible with a constraint-based grammar framework.
This issuehas already received attention, 2 although a thoroughgoing integration of phonologyinto constraint-based grammars has yet to be attempted.
To ease exposition, we shalltake HPSG dS a suitably representative candidate of such approaches.
Although we arebroadly committed to a sign-oriented approach to grammar, none of our proposalsdepends crucially on specific tenets of HPSG.Rather than attempting to theorize at an abstract level about constraint-basedphonology, we shall engage in two case studies intended to give a concrete illustra-tion of important issues: these involve templatic morphology in Sierra Miwok andschwa alternation in French.
Before launching into these studies, however, we presentan overview of some aspects of phonology that present a challenge to standard as-sumptions taken in sign-oriented constraint-based grammars.
Then we describe a (sim-plified) version of HPSG that will make it possible to illustrate the approach withoutirrelevant echnical machinery.1.1 The Challenge of PhonologyGiven that the dominant focus of most research in constraint-based grammar hasbeen syntax and semantics, it is not surprising that the phonological content of wordsand phrases has been largely limited to orthographic strings, supplemented with aconcatenation operation.
How far would such representations have to be enriched ifwe wanted to accommodate a more thoroughgoing treatment of phonology?As remarked earlier, recent work in theoretical phonology has apparently movedcloser to a constraint-based perspective, and is thus a promising starting point for ourinvestigation.
Yet there are at least three challenges that confront anyone looking intotheoretical phonology from the viewpoint of computational linguistics.
Most strikingperhaps is the relative informality of the language in which theoretical statements arecouched.
Bird and Ladd (1991) have catalogued several examples of this: notationalambiguity (incoherence), definition by example (informality), variable interpretationof notation depending on subjective criteria (inconsistency), and uncertainty aboutempirical content (indeterminacy).
When a clear theoretical statement can be found,it is usually expressed in procedural terms, which clouds the empirical ramificationsmaking a theory difficult to falsify.
Finally, even when explicit and nonproceduralgeneralizations are found, they are commonly stated in a nonlinear model, whichclearly goes beyond the assumptions about phonology made in HPSG as it currentlystands.We approach these challenges by adopting a formal, nonprocedural, nonlinearmodel of phonology and showing how it can be integrated into HPSG, following onthe heels of recent work by the authors (Bird and Klein 1990; Bird 1992; Klein 1992).One of the starting assumptions of this work is that phonological representationsare intensional, i.e.
each representation is actually a description of a class of utterances.Derivations progress by refining descriptions, further constraining the class of denotedobjects.
Lexical representations are likewise partial, and phonological constraints arecast as generalizations in a lexical inheritance hierarchy or in a prosodic inheritancehierarchy.
When set against he background of constraint-based grammar, this inten-sional approach is quite natural (cf.
Johnson \[1988\]).
Moreover, some recent hinking onthe phonology-phonetics nterface supports this view (Pierrehumbert 1990; Coleman2 (Bach and Wheeler 1981; Wheeler 1981; Bird 1990; Cahill 1990; Coleman 1991; Scobbie 1991; Bird 1992;Walther 1992; Mastroianni 1993; Russell 1993)456Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems1992).
However, it represents a fundamental split with the generative tradition, whererules do not so much refine descriptions as alter the objects themselves (Keating 1984).While it is clearly possible to integrate an essentially generative model into themold of constraint-based grammar (Krieger, Pirker, and Nerbonne 1993), it is less clearthat this is the approach most phonologists would wish to take nowadays.
It is be-coming increasingly apparent that rule-based relationships between surface forms andhypothetical lexical forms are unable to capture important generalizations about sur-face forms.
This concern was voiced early in the history of generative phonology, whenKisseberth (1970) complained that such rules regularly conspire to achieve particularsurface configurations, but are unable to express the most elementary observationsabout what those surface configurations are.
As a criticism of rule-based systems,Kisseberth's complaint remains valid and has been echoed several times since then(Shibatani 1973; Hooper 1976; Hudson 1980; Manaster Ramer 1981).
However, recentwork in phonology has moved away from models involving rules that relate lexicaland surface forms toward models involving general systems of interacting constraints,where this problem has been side-stepped.Accordingly, we avoid the theoretical framework of early generative phonology,focusing instead on encoding phonological constraints in a constraint-based grammarframework.
We present an overview of the grammar framework in the next section.1.2 Mot ivat ionAt this point, we should briefly address the question: What is gained by integratingphonology into a constraint-based grammar?
One pragmatic answer is that approacheslike HPSG have already taken this step, by introducing a PHONOLOGY attribute thatparallels attributes for SYNTAX and SEMANTICS.
Since, as we have already pointed out,the value of PHONOLOGY needs to be enriched somehow if it is to be linguisticallyadequate, it is reasonable to ask whether the formalism allows insightful statementsof phonological generalizations.An objection might take the following form: phonology is formally less complexthan syntax, as shown by the body of work on finite state analyses of phonology (cf.Section 1.4).
Hence, it is inappropriate to encode phonology in a general purpose for-malism that has been designed to accommodate more complex phenomena.
As a firstresponse, we would maintain that formalisms hould not be confused with theories.Certainly, we want to have a restrictive theory of phonology and its interactions withother levels of grammar.
But we view constraint-based formalisms as languages forexpressing such theories, not as theories themselves.
Moreover, the fact that we use auniform constraint formalism does not force us to use homogeneous inferential mech-anisms for that formalism; this issue is discussed further in Section 1.4 and Section 6.A further question might be: do natural language grammars require the kindof interaction between phonology and other levels of grammar made possible byconstraint-based formalisms?
This is not the place to explore this issue in the detailit deserves.
However, even if we accept he contention of Pullum and Zwicky (1984)that the interactions between phonology and syntax (narrowly construed) are highlyrestricted, there are still good reasons for wanting to accommodate phonological rep-resentations as one of the constraints in a sign-based grammar framework.To begin with, it is relatively uncontroversial that morphology needs to be in-terfaced with both syntax and phonology.
Approaches like that of Krieger and Ner-bonne (in press) have shown that both derivational and inflectional morphology canbe usefully expressed within the constraint-based paradigm.
Taking the further stepof adding phonology seems equally desirable.Second, the use of typed feature structures within the lexicon has been strongly457Computational Linguistics Volume 20, Number 3argued for by Briscoe (1991) and Copestake t al.
(in press).
That is, even when weignore syntactic ombination, constraint-based grammar frameworks turn out to bewell suited to expressing the category and semantic information fields of lexical entries.But the interaction of phonology with categorial information inside the lexicon is welldocumented.
Lexical phonology (Kiparsky 1982) has shown in detail how phonologicalphenomena are conditioned by morphologically specified omains.
If direct interactionbetween phonology and morpho-syntax is prohibited, one can only resort to ad hocand poorly motivated iacritic features.Turning to a different empirical domain, it can be argued that focus constructionsexhibit an interaction between information structure (at the semantic-pragmatic level)with prosodic structure (at the phonological level).
This interaction can be directlyexpressed in a sign-oriented approach.
In other frameworks it is common practice toavoid direct reference to phonology by invoking a morpho-syntactic FOCUS feature(e.g.
Selkirk 1984; Rooth 1985); the mediation of syntax in this way appears to be morean artifact of the grammar architecture than an independently motivated requirement.Equally, it has been argued that the phenomenon of heavy NP shift is a kind of syntax-phonology interaction that is simply stated in a constraint-based approach, where thelinear precedence constraints of syntax are sensitive to the phonological category ofweight (Bird 1992).1.3 Theoretical FrameworkTyped feature structures (Carpenter 1992) impose a type discipline on constraint-basedgrammar formalisms.
A partial ordering over the types gives rise to an inheritancehierarchy of constraints.
As Emele and Zajac (1990) point out, this object-orientedapproach brings a number of advantages to grammar writing, such as a high level ofabstraction, inferential capacity and modularity.On the face of it, such benefits hould extend beyond syntax--to phonology forexample.
Although there have been some valuable efforts to exploit inheritance andtype hierarchies within phonology (e.g.
Reinhard and Gibbon 1991), the potential oftyped feature structures for this area has barely been scratched so far.
In this section, wepresent a brief overview of HPSG (Pollard and Sag 1987), a constraint-based grammarformalism built around a type system that suits our purposes in phonology.In order to formulate the type system of our grammar, we need to make twokinds of TYPE DECLARATION.
The first kind contains information about he subsumptionordering over types.
For example, the basic grammar object in HPSG is the featurestructure of type sign.
The type sign has some SUBTYPES.
If a is a subtype of T, then ~rprovides at least as much information as T. A type declaration for sign defines it asthe following disjunction of subtypes: 3Example 1sign ~ morph V stem V word V phraseThe second kind of declaration is an APPROPRIATENESS CONDITION.
That is, for eachtype, we declare (all and only) the attributes for which it is specified, and additionallythe types of values which those attributes can take.
4 For example, objects of type sign3 The constraints proposed here deviate in various respects from the standard version of HPSG.
Wefollow Carpenter (1992) in us ing the notation a =~ ?
to specify that type ~ satisfies constraint ?.4 We are using what Carpenter (1992) calls TOTAL WELL-TYPING.
That is, (i) the only attributes and valuesthat can be specified for a given feature structure of type T are those appropriate for ~-; and (ii) everyfeature structure of type ~- must  be specified for all attributes appropriate for T.458Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systemscould be constrained to have the following features defined:Example 2PHON : phon\[SYNSEM : synsemsign \[DTRS : listThat is, feature structures of type sign must contain the attributes PHON (i.e.
phonol-ogy), SYNSEM (i.e.
syntax/semantics), 5 and DTRS (i.e.
daughters) and these attributesmust take values of a specific type (i.e., phon, synsem, and list, respectively).
A furthercrucial point is that appropriateness conditions are inherited by subtypes.
For exam-ple, since morph is a subtype of sign, it inherits all the constraints obeyed by sign.Moreover, as we shall see in Section 3.2, it is subject o some further appropriatenessconditions that are not imposed on any of its supertypes.Continuing in the same vein, we can assign appropriateness conditions to the typessynsem and phon that occurred as values in (2), (simplifying substantially from standardHPSG).
Here we give the constraints for synsem.
The type phon will be discussed inSection 2.Example 3CAT : catAGR : agrSUBCAT : listSEM : semanticssynsemTo conclude this section, we shall look very briefly at matters of interpretationand inference.
As shown by Carpenter (1992) and Zajac (1992, in press), we can useconstraint resolution to carry out type inference for feature terms.
Following Zajac, letus say that a GROUND feature term is a term all of whose type symbols are minimal(i.e., the most specific types in the hierarchy immediately above _L).
A WELL-TYPEDfeature term is one that obeys all the type definitions.
Then the meaning of a featureterm F is given by the set of all well-typed ground feature terms that are subsumed byF.
Evaluating F, construed as a query, involves describing F's denotation; for example,enumerating all the well-typed ground feature terms it subsumes.
Since the type deft-nitions obeyed by F might be recursive, its denotation is potentially infinite.
Considerfor example the following definitions (where "nelist" and 'elist" stand for nonempty listand empty list respectively, and T subsumes every type):Example 4a.
list =~ nelist V elistb.FIRST : T \]nelist \[REST : list J5 Earlier versions of HPSG kept syntax and semantics a separate attributes, and we shall sometimesrevert o the latter when borrowing examples from other people's presentations.459Computational Linguistics Volume 20, Number 3Here, the denotation of the type symbol list is the set of all possible ground lists.In practice, a constraint solver could recursively enumerate all these solutions; analternative proposed by Zajac would be to treat the symbol LIST as the best finiteapproximation of the infinite set of all lists.1.4 Finite-State PhonologyOver the last decade much has been written on the application of finite-state trans-ducers (FSTs) to phonology, centering on the TWO-LEVEL MODEL of Koskenniemi (1983).Antworth (1990) and Sproat (1992) give comprehensive introductions to the field.
Theformalism is an attractive computational model for 1960s generative phonology.
How-ever, as has already been noted, phonologists have since moved away from complexstring rewriting systems to a range of so-called nonlinear models of phonology.
Thecentral innovation of this more recent work is the idea that phonological representa-tions are not strings but collections of strings, synchronized like an orchestral score.There have been some notable recent attempts to rescue the FST model from itslinearity in order to encompass nonlinear phonology (Kay 1987; Kornai 1991; Wiebe1992).
However, from our perspective, these refinements to the FST model still admitunwarranted operations on phonological representations, as well as rule conspiraciesand the like.
Rather, we believe a more constrained and linguistically appealing ap-proach is to employ finite-state automata (FSAs) in preference to FSTS, since it hasbeen shown how FSAS can encode autosegmental representations and a variety of con-straints on those representations (Bird and Ellison 1994).
The leading idea in this workis that each tier is a partial description of a string, and tiers are put together using theintersection operation defined on FSAs.Apart from being truer to current phonological theorizing, this one-level modelhas a second important advantage over the two-level model.
Since the set of FSAs formsa Boolean lattice under intersection, union, and complement (a direct consequence ofthe standard closure properties for regular languages), we can safely conjoin ('unify'),disjoin, and negate phonological descriptions.
Such a framework is obviously compat-ible with constraint-based grammar formalisms, and there is no reason in principleto prevent us from augmenting HPSG with the data type of regular expressions.
Inpractice, we are not aware of any existing implementations of HPSG (or other feature-based grammars) that accommodate r gular expressions.
Ideally, we would envisage acomputational interpretation of typed feature structures where operations on regularexpression values are delegated to a specialized engine that manipulates the corre-sponding FSAs and returns regular expression results.
6This issue is discussed furtherin Section 6.1.5 Overview of the PaperThe structure of the paper is as follows.
In the next section, we present our assump-tions about phonological representations and phenomena, couched in the frameworkof typed feature logic.
In Section 3 we discuss our view of the lexicon, borrowing heav-ily on HPSG's lexical type hierarchy, and developing some operations and representa-tions needed for morphology.
The next two sections investigate various applicationsof the approach to two rather differing phenomena, namely Sierra Miwok templaticmorphology and French schwa.
Section 6 discusses ome implementation issues.
Thepaper concludes with a summary and a discussion of future prospects.6 A similar approach is envisaged by Krieger, Pirker, and Nerbonne (1993).460Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems2.
String-Based PhonologyIn this section we present a string-based phonology based on the HPSG list notation.We present he approach in Section 2.1 and Section 2.2, concluding in Section 2.3 witha discussion of prosodic constituency.2.1 List NotationsAs a concession to existing practice in HPSG, we have taken the step of using lists inplace of strings.
We shall use angle bracket notation as syntactic sugar for the standardFIRST/REST encoding.We shall assume that the type system allows parameterized types of the formlist(a), where a is an atomic type.Example 5list(a) ~ elist(a) V nelist(a)FIRST : a \]nelist(a) \[REST : list(a) 3We can now treat a* and a + as abbreviations for list(a) and nelist(a) respectively.Another useful abbreviatory notation is parenthesized elements within lists.
Weshall interpret (a(b)) --- L, a list consisting of an a followed by an optional b concate-nated with an arbitrary list L, as the following constraint:Example 6FIRST : a IFIRST : 1list \[REST :listWe shall see applications of these list notations in the next section.2.2 A Prosodic Type HierarchyA PROSODIC TYPE HIERARCHY is a subsumption network akin to the lexical hierarchy ofHPSG (Pollard and Sag 1987).
The type constraints we have met so far can be used todefine a type hierarchy, which for present purposes will be a Boolean lattice.
In thissection we present in outline form a prosodic hierarchy that subsequent analyses willbe based on.
Example (7) defines the high-level types in the hierarchy.Example 7phon ~ utterance v phrase V foot v syl V segmentEach of these types may have further structure.
For example, following Clements(1985:248) we may wish to classify segments in terms of their place and manner ofarticulation, using the following appropriateness declaration.461Computational Linguistics Volume 20, Number 3Example 8segmentLARYNGEAL :SUPRALARYNGEAL :SPREAD : booleanCONSTRICTED : booleanVOICED : boolean"NASAL : boolean"vIANNER : CONTINUANT : booleanSTRIDENT : booleanCORONAL : booleanPLACE : ANTERIOR : booleanDISTRIBUTED : booleanSuppose now that we wished to use these structures in a constraint for English homor-ganic nasal assimilation.
This phenomenon does not occur across phonological phraseboundaries and so the constraint will be part of the definition of the type (phonologi-cal) phrase.
Let us assume that a phrase is equivalent to segment*, i.e.
a list of segments.Informally speaking, we would like to impose a negative filter that bars any nasalwhose value for place of articulation differs from that of the stop consonant that im-mediately follows.
Here, we use SL as an abbreviation for SUPRALARYNGEAL, CONT forCONTINUANT,  MN for MANNER, and PL fo r  PLACE.Example 9~phrase I'"segment \[SL : \[ c d PL : segment \[SL : PL : 'While the abbreviatory conventions in this filter might appear suspicious, it is straight-forwardly translated into the constraint in (10).
This constraint is divided into threeparts.
The first simply requires that hna be a subtype of list(segment).
The second partis lifted from (9), ensuring that the first two positions in the list do not violate theassimilation constraint.
The third part propagates the assimilation constraint o therest of the list.Example 10-1 {FIRST\[SL :hna =- list(segment) A L REsTIFIRsTIsL, NABLPL :I MNICONT :L PL :A \[REST : hna\]462Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsStandard techniques can now be used to move the negation in (10) inward.
7 Sinceconstraints on adjacent list elements generally seem to be more intelligible in theformat exhibited by (9), we shall stick to that notation in the remainder of the paper.2.3 Prosodic ConstituencyOne standard phonological approach assumes that prosodic onstituency is like phrasestructure (Selkirk 1984).
For example, one might use a rewrite rule to define a (phono-logical) phrase as a sequence of feet, and a foot as sequence of syllables:Example 11a.
phrase ~ foot +b.
foot --* syl +Within the framework of HPSG, it would be simple to mimic such constituency byadmitting a feature structure of type phrase whose DTRS (i.e.
daughters) are a list offeature structures of type foot, and so on down the hierarchy.
However, there appearsto be no linguistic motivation for building such structure.
Rather, we would like tosay that a phrase is just a nonempty list of feet.
But a foot is just a list of syllables, andif we abandon hierarchical structure (e.g.
by viewing lists as strings), we seem to bestuck with the conclusion that phrases are also just lists of syllables.
In a sense this isindeed the conclusion that we want.
However, not any list of syllables will constitute aphrase, and not every phrase will be a foot.
That is, although the data structure may bethe same in each case, there will be additional constraints that have to be satisfied.
Forexample, we might insist that elements at the periphery of phrases are exempt fromcertain sandhi phenomena; nd similarly, that feet have no more than three syllables,and only certain combinations of heavy and light syllables are permissible.
Thus, weshall arrive at a scheme like the following, where the Ci indicate the extra constraints: 8Example 12a.
phrase =_ foot + A C1 A .
.
.
A Ckb.
foot = syl + ACt A .
.
.
A CnThis concludes our discussion of string-based phonology.
We have tried to show howa phonological model based on FSAs is compatible with the list notation and typeregime of HPSG.
Next we move onto a consideration of morphology and the lexicon.7 These techniques employ the following equivalences:~\[A: ~\] = -~\[A: ~\]V~\[B: @\]-~\[A: q~\] = \[-~(A: T)\]V\[A: ~*\]Here ~(A:T) indicates that the attribute A is not appropriate for this feature structure.8 Sproat and Brunson (1987) have also proposed a model in which prosodic onstituents are defined asconjunctions of constraints.463Computational Linguistics Volume 20, Number 33.
Morphology and the Lexicon3.1 Linguistic HierarchyThe subsumption ordering over types can be used to induce a hierarchy of grammat-ically well-formed feature structures.
This possibility has been exploited in the HPSGanalysis of the lexicon: lexical entries consist of the idiosyncratic information particu-lar to the entry, together with an indication of the minimal lexical types from which itinherits.
To take an example from Pollard and Sag (1987), the base form of the Englishverb like is given in Example 13.Example 13main A base A strict-transPHON : (1 a t k)SYN\]LOqSUBCAT : (\[lIT\] \[\]\[-~)\[RELN : ~e\ ]SEMICONT : /LIKER :L LIKEESince main is a subtype of verb, the entry for like will inherit the constraint hat itsmajor class feature is V; by virtue of the type strict-trans, it will inherit the constraintthat the first element in the SUBCAT list is an accusative NP, while the second ele-ment is a nominative NP; and so on for various other constraints.
Figure 1 shows asmall and simplified portion of the lexical hierarchy in which the verb like is a leafnode.Along the phonological dimension of signs, lexical entries will have to observeany morpheme or word level constraints that apply to the language in question.
Whenwords combine as syntactic phrases, they will also have to satisfy all constraints onwell-formed phonological phrases (which is not to say that phonological phrases areisomorphic with syntactic ones).
In the general case, we may well want to treat wordsin the lexicon as unsyllabified sequences of segments.
It would then follow that, for ex-ample, the requirement that syllable-initial voiceless obstruents be aspirated in Englishlexical-signverbYmainx .basex .jlikeunsaturatedtransstrict-transj .,1" J,1"Figure 1A portion of the lexical hierarchy.464Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systemswould have to be observed by each syllable in a phrase (which in the limiting case,might be a single word), rather than lexical entries per se.In some languages we may require there to be a special kind of interaction betweenthe lexical and the prosodic hierarchy.
For example, Archangeli and Pulleyblank (1989)discuss the tongue root harmony of Yoruba, which is restricted to nouns.
If atr (i.e.advanced tongue root) was the type of harmonic utterances, then we could expressthe necessary constraint thus:Example 14atr \]\] PHON : phon A\[SYNJLOC\]HEAD : r MAJ: fLEX:n+ ?unYlOblllThis kind of constraint is known as a morpheme structure constraint, and phonol-ogists have frequently needed to have recourse to these (Kenstowicz and Kisseberth1979).
Another interaction between prosody and morphology is the phenomenon ofprosodic morphology, an example of which can be found in Section 4.3.2 Morphological ComplexityGiven the syntactic framework of HPSG, it seems tempting to handle morphologicalcomplexity in an analogous manner to syntactic omplexity.
That is, morphologicalheads would be analyzed as functors that subcategorize for arguments of the appro-priate type, and morphemes would combine in a Word-Grammar scheme.
Simplifyingdrastically, such an approach would analyze the English third person singular presentsuffix -s in the manner shown in (15), assuming that affixes are taken to be heads.Example 15PHON :SYNSEMISUBCAT :affixIs> 1{verb-stem}JBy adding appropriately modified versions of the Head Feature Principle, Subcategor-ization Principle, and linear order statements, uch a functor would combine with averb stem to yield a tree-structured sign for walks.Example 16 \[P ON: EP ON  {ver _s e \[PHONverbWhile one may wish to treat derivational morphology in this way (cf.
Kriegerand Nerbonne \[in press\]), a more economical treatment of inflectional morphologyis obtained if we analyze affixes as partially instantiated word forms.
9Example (17)illustrates this for the suffix -s, where 3ps is a subtype of sign.9 See Riehemann (1992) for a detailed working out of this idea for German derivational morphology.465Computational Linguistics Volume 20, Number 3Example 17PHON :MORPH :3psE\] -Daffix-morphIA STEM :FHXPHON : \[~\]\]verb-,;tem\[PHON: \[~(S}\]/\]Note that we have added to sign a new attribute MORPH, with a value morph.
Thelatter has two subtypes, affix-morph and basic-morph, depending on whether the valuecontains a stem and affix or just a stem.Example 18morph ~ affix-morph V basic-morphWhile both of these types will inherit the attribute STEM, affix-morph must also bedefined for the attribute AFFIX:Example 19a.
\[STEM:stem\]morphb.
affix_morph \[ AFFIx:affix\]Moreover, affix has two subtypes:Example 20affix ~ prefix V suffixThus, (17) is a third person singular verb form whose stem is unspecified.As indicated in Section 1.3, we can take the interpretation of a complex type tobe equivalent to the disjunction of all of its subtypes.
Now, suppose that our lexiconcontained only two instances of verb-stems, namely walk and meet.
Then (17) wouldevaluate to exactly two fully specified word forms, where verb-stem was expandedto the signs for walk and meet respectively.
Example 21 illustrates the first of theseoptions.Example 21"PHON :MORPH :3psN .Daffix-morphSTEM :AFFIX :"PHON : \[~(w OI k} \]SYNSEM: \[CAT: verb\]\]verb-stemsuffix \[PHON : \[\]\[\] (s} 1466Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsOf course, this statement of suffixation would have to be slightly enriched toallow for the familiar allomorphic alternation -s,,~z,,,~z.
The first pair of allomorphs canbe handled by treating the suffix as unspecified for voicing, together with a voicingassimilation rule similar to the homorganic nasal rule in (9).
The third allomorphwould admit an analysis imilar to the one we propose for French schwa in Section 5.A second comment on (21) is that the information about ordering of affixes relativeto the stem should be abstracted into a more general pair of statements (one for prefixesand one for suffixes) that would apply to all morphologically complex lexical signs(e.g.
of type affixed); this is straightforward to implement:Example 22a.I PHON : MORPH : affixea STEMIPHON : \ [ \ ]  AFFIX : prefix \[PHONb.affix~PHON:MORPH : rSTEMIPHON : \ [ \ ]AFFIX : SUffix \[PHONGiven this constraint, it is now unnecessary to specify the phonology attribute forfeature terms like (21).Additionally, it is straightforward to prevent multiple copies of the plural suffixfrom being attached to a word by ensuring that 3ps and verb-stem are disjoint.3.3 Morphophonological OperationsIn and of itself, HPSG imposes no restrictions on the kind of operations that can beperformed in the course of composing morphemes into words, or words into phrases.As an illustration, consider the data from German verb inflections analyzed by Krieger,Pirker, and Nerbonne (1993).
As they point out, the second person singular presentinflection -st has three different allomorphs, phonologically conditioned by the stem:Example 23sag+st arba~t+0st m~ks+t'say' 'work' 'mix'Although the main thrust of their paper is to show how an FST treatment of thisallomorphy can be incorporated into an HPSG-style morphological analysis, from apurely formal point of view, the FST is redundant.
Since the lexical sign incorporatesthe phonologies of both stem and affix, segments can be freely inserted or deleted inconstructing the output phonology.
This is exemplified in (24) for arbeitest and mixtrespectively.467Computational Linguistics Volume 20, Number 3Example 24a.2psb.2psPHON :MORPH :SYNILOCIHEADIAGR :PHON :MORPH :SYN\[LOCIHEADIAGR :STEM : IT\](... {t,d}}\]SUFFIX : \[-~(S t} \[N O: :.\]PER :STEM: \ [ \ ] ( .
.
.
{S~Z, X}>"SUFFIX: (S} ~, \[-~(t}NUM : ;g\]PER :That is, we can easily stipulate that o is intercalated in the concatenation of stem andsuffix if the stem ends with a dental stop (i.e either t or d); and that the s of the suffix isomitted if the stem ends with alveolar or velar fricative.
Although an actual analysisalong these lines would presumably be stated as a conditional, depending on theform of the stem, the point remains that all the information eeded for manipulatingthe realization of the suffix (including the fact that there is a morpheme boundary)is already available without resorting to two level rules} ?
Of course, the questionthis raises is whether such operations hould be permitted, given that they appear toviolate the spirit of a constraint-based approach.
The position we shall adopt in thispaper is that derivations like (24) should in fact be eschewed.
That is, we shall adoptthe following restriction:Phonological Compositionality:The phonology of a complex form can only be produced by either unifying or con-catenating the phonologies of its parts.We believe that some general notion of phonological compositionality is method-ologically desirable, and we assume that Krieger, Pirker, and Nerbonne would adopta similar position to ours.
The specific formulation of the principle given above isintended to ensure that information-combining operations at the phonological levelare monotonic, in the sense that all the information in the operands is preserved inthe result.
As we have just seen, the constraint-based approach does not guaranteethis without such an additional restriction.4.
Sierra Miwok Templatic MorphologyNoncatenative morphology has featured centrally in the empirical motivations forautosegmental phonology, since McCarthy's demonstration that the intercalation ofvowels in Arabic consonantal verb roots could be elegantly handled within this frame-work (McCarthy 1981).
This section presents an approach to intercalation that uses key10 This approach of using restructuring devices in the process of a derivation has been explored in thecontext of extended Montague frameworks by Wheeler (1981) and Hoeksema and Janda (1988).468Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systemsinsights from autosegmental phonology.
However, they are captured within constraint-based grammar where the inflectional paradigm is realized as an inheritance hierarchyof partially instantiated stem forms (cf.
Reinhard and Gibbon \[1991\]).
We also showthat autosegmental association of consonants and vowels to a skeleton can be mod-eled by reentrancy.
Rather than classical Arabic, we use the simpler data from SierraMiwok that Goldsmith (1990) chose to illustrate the phenomenon of intercalation ihis textbook.This section is divided into four subsections.
In Section 4.1 we present an overviewof the data, and in Section 4.2 we briefly show what a traditional generative analysismight look like.
Our encoding of association by reentrancy is given in Section 4.3,while Section 4.4 contains our constraint-based analysis of Sierra Miwok stem forms.4.1 Descriptive OverviewAs mentioned above, Goldsmith (1990) takes data from Sierra Miwok verb stems toillustrate morphologically determined alternations in skeletal structure.
He discussesthree of the four types of stem, where the division into types depends primarilyon the syllable structure of the basic form, which is the form used for the presenttense.
The three types are given the following autosegmental representations by Gold-smith:Example 25a.
Type I k iC Vc a w/\C V V Cb.
Type II c erC V1 k uC C Vc.
Type III h a m eI / \1C V C C VAs shown in (26), each type has forms other than the basic one, depending on themorphological orgrammatical context; these additional forms are called second, third,and fourth stems.Although the associations of vowels and consonants exhibited above are taken asdefinitional for the three stem Types, from the data in (26) it appears that the distinctionis only relevant to so-called Basic stem forms.469Computational Linguistics Volume 20, Number 3Example 26Gloss Basic stem Second stem Third stem Fourth stemType Ibleed kicaaw kicaww kiccaw kicwajump tuyaa~ tuyar3r  tuyya U tuyr3atake patiit patitt pattit pattiroll huteel hutell huttel hutleType IIquit celku celukk celluk celkugo home wo?lu wo?ull wo?
?ul wo?lucatch up with nakpa nakapp nakkap nakpaspear wimki wimikk wimmik wimkiType IIIbury hamme hame??
hamme?
ham?edive ?uppi ?upi??
?uppi~ ~up?ispeak liwwa liwa??
liwwa?
liw?asing milli mili??
milli?
mil?i4.2 Segmental AnalysisGoldsmith (1990) has shown just how complex a traditional segmental account ofSierra Miwok would have to be, given the assumption that all of the stem forms arederived by rule from a single underlying string of segments (e.g.
that kicaww, kiccawand kicwa are all derived from kicaaw).
Here, we simplify Goldsmith's analysis o thatit just works for Type I stems.
The left-hand column of (27) contains four rules, andthese are restricted to the different forms according to the second column.Example 27RulesV~-,O/C--V~C\]Ci--~CiCi/--\]Ci--~CiCi/\[CV--VVC\]--*CVFormall234Second Third Fourthk icaaw k icaaw k icaawk icaw k icaw k icawk icaww - -- -  k i ccaw- -  k i cwak icaww k iccaw k icwaThus, the first rule requires that a vowel Vi is deleted if it occurs after a consonantand immediately before an identical vowel Vi that in turn is followed by a stem-finalconsonant.
Goldsmith soundly rejects this style of analysis in favor of an autosegmentalone:This analysis, with all its morphologically governed phonological rules,arbitrary rule ordering, and, frankly, its mind-boggling inelegance,ironically misses the most basic point of the formation of the pasttense in Sierra Miwok.
As we have informally noted, all the second470Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systemsstern forms are of the shape CVCVCC, with the last consonant a gem-inate, and the rules that we have hypothetically posited so far allendeavor to achieve that end without ever directly acknowledging it.
(Goldsmith 1990:87)4.3 AssociationWe shall not attempt here to give a general encoding of association, although thetechnique used in Sections 5.4 could be applied to achieve this end.
Moreover, likeGoldsmith we shall ignore the role of syllable structure in the data, though it clearlydoes play a role.
Instead, we shall confine our attention to the manner in which skeletalslots are linked to the consonant and vowel melodies.
Consider again the skeletalstructure of Type I verb stems shown in (25a).
As Goldsmith (1990) points out, thereis a closely related representation that differs only in that the CV information is splitacross two tiers (and which allows a much more elegant account of metathesis andgemination):Example 28consonantal melody k c wskeleton X Xvowel melody iX X X X\/aThe diagram in Example 28 can be translated into the following feature term:Example 29CON :VOW :phon \[SKEL :@k @c Dw} \](\[-~i \[\]a} \] (DSDDSD}That is, since association i  (28) consists of slot-filling (rather than the more generaltemporal interpretation), it can be adequately encoded by coindexing.4.4 Basic Stem FormsThe analysis tarts from the assumption that the Sierra Miwok lexicon will containminimally redundant entries for the three types of verb root.
Let us consider the rootcorresponding to the basic stem form kicaaw.
We take the unpredictable informationto be the consonantal nd vowel melodies, the valency, the semantics, and the fact itis a Type I verb stem.
This is stated as (30), together with the declaration that lex-bleedis a subtype of v-root-I.471Computational Linguistics Volume 20, Number 3Example 30PHON :SYNSEM :lex-bleed\[CON : (k c w')\]phon \[VOW: (i a) \]SUBCAT : (NP)\]synsem SEM : bh,ed \]Notice that we have said nothing about how the melodies are anchored to askeleton--this will be a task for the morphology.
Additionally, this entry will inheritvarious properties by virtue of its type v-root-I.
The three types of verb root share atleast one important property, namely that they are all verbs.
This is expressed in thenext two declarations:Example 31a.
v-root ~ v-root-I V v-root-II V v-root-IIIb.
v_root ISYNSEM\[CAT : verb\]We shall also assume, for generality, that every v-root is a root, and that every root isa morph.
Anticipating the rest of this section, we show how all the postulated typesare related in Figure 2.
The next step is to show how a v-root-I like (30) undergoesmorphological modification to become a basic verb stem; that is, a form with skeletalstructure.
Our encoding of the morphology will follow the lines briefly sketched inSection 3.2.We begin by stating types that encode the patterns of skeletal anchoring associatedwith the three types of basic stem.Example 32phon =~ template-I V template-II V template-IIIsign v-root morph-dtrs p"p'honphra//\word stem morphaffixe~d roo//t ~basic affixv-r?
?t-/~Iv-root-II\v-root-III5\bas-morph~-dtrs~ basic-I basic-IIIaff-morph-dtrs basic-IIFigure 2Sierra Miwok type hierarchy.472Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsThe appropriateness constraints on these types are given in (33).
As an aid toreadability, the numerical tags are supplemented with a C or a V to indicate the typeof value involved.Example 33CON :a.
\[vow :template-I LSKEL :<E\]c E\]c \[~c><frlV rqv><EOC Nv Sc frlV rrlv IEC>b.template-lICON :VOW :SKEL :@c Dc Dc>@\]v ~v>@c Dv \[~c E\]v E\]c>c.template-IIICON :VOW :SKEL :<EF Dc> I @\]v ~v  <E\]c Dv E\]c @c Fqv >Each of these types specializes the constraints on the type phon, and each can be unifiedwith the phon value earlier assigned to the root form of kicaaw in (30).
In particular,the conjunction of constraints given in (34) evaluates to (29), repeated here:Example 34CON :phon \[VOW :(k c w}\](i a} j A template-IExample 29F CON : IVOW :phon LSKEL(V~k Dc @w> \]<\[i\]i E\]a} \] <SSD@S~>However, we also need to specify the dependency between the three types of verbroot, and the corresponding phonological exponents that determine the appropriatebasic stem forms (cf.
Anderson \[1992\]).
As a first attempt o express this, let us saythat stem can be either basic or affixed:Example 35stem ~ affixed V basicType declaration (35) ensures that basic will inherit from stem the following constraint,namely that its SYNSEM value is to be unified with its MORPH'S ROOT'S SYNSEM value:Example 36ISYNSEM :ORPHIROOTISYNSEM : ~\ ]stem473Computational Linguistics Volume 20, Number 3We could now disjunctively specify the following three sets of constraints on basic:Example 37a.basicPHON : phon A template-I 1MORPH: IROOT: v-root-Illb.basic"PHON :MORPH :phon A template-II 1 I oow: v-roo,-l \]JC.basic"PHON :MORPH :phon A template-III 1\[ROOT: v-root-III\]\]Although the example in question does not dramatize the fact, this manner of en-coding morphological dependency is potentially very redundant, since all the commonconstraints on basic have to be repeated each time.
n In this particular case, however,it is easy to locate the dependency in the phon value of the three subtypes of v-root, asfollows:Example 38v_root_I IPHON : template-l\]v_root_ii \[PHON : template-Illv_root_III\[PHON : template-Ill\]We then impose the following constraint on basic:Example 39IPH?
: \[\]MO PH'ROOT"  _roo IBy iterating through each of the subtypes of v-root, we can infer the appropriatevalue of PHON within MORPH'S ROOT, and hence infer the value of PHON at the top levelof the feature term.
Example 40 illustrates the result of specializing the type v-root olex-bleed:11 In an attempt to find a general solution to this problem in the context of German verb morphology,Krieger and Nerbonne (in press) adopt the device of 'distributed isjunction' to iteratively associatemorphosyntactic features in one list with their corresponding phonological exponents in another list.474Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsF CON : \[\] \[s%OW:phoniuAT: verb \]BEAT: (NP)\]EM : bleed\]Ftemplate-morph \[ROOT : v-root-IExam ~le 40PHON :SYNSEM : \ [ \ ]synsemMORPH :basic(NND@E\]PHON :SYNSEM :Exactly the same mechanisms will produce the basic stem for the other two types ofverb root.
For an account of the other alternations presented in Goldsmith's paradigm,and for some discussion of how lexical and surface forms determine ach other, seeKlein (1993).We have just seen an application of constraint-based phonology to Sierra Miwok.In order to illustrate some of the other expressive capabilities of the approach, we nowturn to the phenomenon of French schwa.5.
French SchwaMany phonological alternations can be shown to depend on properties of prosodicstructure.
In this section we show how the French phenomenon of schwa-zero al-ternation arises out of the interplay of various syllable structure requirements.
This isdone by introducing a system of prosodic types for syllables and a special type declar-ation showing how a string of segments can be 'parsed' into syllables.
The standard(but nonmonotonic) ONSET MAXIMIZATION PRINCIPLE is reinterpreted in the system, aswell as the exceptions to this principle due to a class of words known as h-aspir6words.
We also show how a certain kind of disjunction can be used to deal with freevariation.
As we shall see, some linguistic analyses are more amenable to a declarativeencoding than others.
In order to demonstrate his, it will be necessary to go into somedetail concerning the linguistic data.This section is divided into four subsections.
In Section 5.1 we present a descriptiveoverview of the data, 12 and in Section 5.2 we sketch a traditional generative analysis.
Amore recent, nonlinear analysis appears in Section 5.3 while our own, constraint-basedversion is presented in Section 5.4.5.1 Descriptive OverviewUnlike schwa in English, the French schwa (or mute e) is a full vowel, usually realizedas the low-mid front rounded vowel ce (and sometimes as the high-mid front roundedvowel o in certain predictable nvironments).
Its distinctive characteristic is that under12 The data is from standard French taken from (cited) literature, although in some instances we havefound speakers with different acceptability judgments han reported here.
See Morin (1987) for adiscussion of some problems with the treatment ofFrench data in the literature.475Computational Linguistics Volume 20, Number 3certain conditions, it fails to be realized phonetically.
13From now on we shall use theterm 'schwa' to refer to the vowel with this characteristic, rather than to the segment o.Although schwa is associated witlh orthographic e,not all es will concern us here.For example, the orthographic e of samedi \[sam.di\] 'Saturday' can be taken to indicatethat the previous vowel should not be nasalized, while the final e of petite \[poe.tit\]indicates that the final t should be pronounced.
In morphology, orthographic e marksfeminine gender, first-conjugation verbs, and subjunctive mood.Instead, we shall be concerned with the pattern of realization and non-realizationexhibited by schwa--a pattern that we interpret as grounded in the alternation of twoallophones of schwa: oe and 0 (zero).
This alternation is manifested in forms like (41), 14where the dots indicate syllable boundaries.Example 41a.
six melons \[si.moe.15\] ,,~ \[sim.15\]b. sept melons \[s~t.moe.15\], *\[s~tmlS\]Observe that while six melons can be pronounced with or without the schwa,sept melons requires the schwa in order to break up the tml cluster that would oth-erwise be formed.
Unfortunately, the conditions on the distribution of schwa are notas simple (and purely phonological) as this example implies.
As we shall see, schwaalternation in French is governed by an interesting mixture of lexical and prosodicconstraints.In the remainder of this section, we dispel the initial hypothesis that arises from(41), namely that schwa alternation is to be treated as a general epenthesis process, isConsider the following data (Morin 1978:111).Example 42ClusterrdrrfsklpsSchwa Possible/Obligatorybordereau \[b3r.doe.ro\]derechef \[doe.roe.fef\]squelette \[skoe.lct\]d6pecer \[de.poe.se\]Schwa Impossibleperdrix \[pEr.dri\]torchon \[t~r.ff\]scl6rose \[skle.roz\]6clipser \[ek.lip.se\]The table in (42) gives data for the clusters \[rdr\], \[r f\], \[skl\] and \[ps\].
In the first columnof data, the oe is possible or obligatory, while in the second column, it is absent.
Thus,we see that the apperance of oe cannot be predicted on phonotactic grounds alone.Consequently, we shall assume that schwa must be encoded in lexical representations.Note that it is certainly not the case that a lexical schwa will be posited whereverthere is an orthographic e.Consider the data in (43), where these orthographic es areunderlined.13 The data used in this section is drawn primarily from the careful descriptive work of Morin (1978) andTranel (1987b).
The particular approach to French schwa described in the following paragraphs mostclosely resembles the analysis of Tranel (1987a).14 We shall not be concerned with another ce~0 alternation known as elision.
This is a phonologicallyconditioned allomorphy involving alternations such as le~l', for example, le chat \[loe.faL l'ami \[la.mi\].15 This epenthesis hypothesis was advanced by Martinet (1972).476Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsExample 43Orthographybordereaufais-lesix melonspelleterieWith Schwa\[bar.doe.ro\]\[f~.lo\]\[si.mce.15\]Without Schwa\[sim.15\]\[p~l.tri\]In a purely synchronic analysis there is no basis for discussing an alternating vowelfor bordereau, fais-l?
and pelleterie.
Many orthographic esthat are not in the first syllableof a word come into this category.Accordingly, we begin our analysis with three background assumptions: the alter-nating schwa is (i) prosodically conditioned, (ii) lexically conditioned, and (iii) not indirect correspondence with orthographic e.Next we present a generative analysis ofschwa due to Dell, followed by an autosegmental analysis due to Tranel.
We concludewith our own, syllable-based analysis.5.2 A Traditional Generative AnalysisThe traditional approach to vowel-zero alternations i to employ either a rule ofepenthesis or a deletion rule.
Dell discusses the case of the word secoue, whose pro-nunciation is either \[sku\] or \[soeku\], in a way that parallels (41).In order to account for alternations such as that between \[sku\] and\[soeku\] there are two possibilities: the first consists of positing theunderlying representation /sku/  where no vowel appears between/ s /  and /k / ,  and to assume that there exists a phonological rule ofepenthesis that inserts a vowel ce between two consonants at the be-ginning of a word when the preceding word ends in a consonant .
.
.
.The second possibility is preferable: the vowel \[oe\] that appears inJacques secoue is the realisation of an underlying vowe l /o /wh ich  canbe deleted in certain cases.
We shall posit the VCE1 rule, which deletesany /a /  preceded by a single word-initial consonant when the pre-ceding word ends in a vowel.VCEI: 0--+ 0 / V "#1 C(Dell, 1980:161f)Suppose we were to begin our analysis by asking the question: how are we toexpress the generalization about schwa expressed in the above rule?
Since our declar-ative, monostratal framework does not admit deletion rules, we would have to giveup.
As we shall see below, however, we begin with a different question: how are we toexpress the observation about the distribution of schwa that Dell encodes in the aboverule?There is another good reason for taking this line.
As it happens, there is an em-pirical problem with the above rule, which Dell addresses by admitting a potentiallylarge number of lexical exceptions to the rule and by making ad hoc stipulations (Dell1980).
Additionally, adding diacritics to lexical entries to indicate which rules theyundergo and employing rules that count # boundaries would seem to complicate agrammar formalism unnecessarily.
As we saw above for the discussion of the wordbordereau, in the approach taken here we have the choice between positing a stable477Computational Linguistics Volume 20, Number 3oe or one that alternates with zero (i.e.
a schwa) in the lexicon, whereas Dell mustmark lexical items to indicate which rules they must not undergo.
There is also someevidence for a distinction between the phonetic identity of the ce allophone of schwaand the phonetic identity of a nonalternating lexical oe in some varieties of French,requiring that the two be distinguished phonologically (Morin 1978).Thus, the fact that Dell's analysis involves deletion does not provide a signifi-cant stumbling block to our approach.
However, Dell employs another proceduraldevice, namely rule ordering, in the application of the rule.
In discussing the phrasevous me le dites \[vu.m(oe).l(oe).dit\], in which either schwa (but not both) may be omitted,Dell writes:VCE1 begins on the left and first deletes the schwa of me, producing/vu#m#1o#dit/.
ButVCE1 cannot operate again and delete the schwaof le, for, although this schwa was subject o the rule in the originalrepresentation, it no longer is once the schwa of me has been dropped.In other words, the first application of VCE1 creates new conditionsthat prevent it from operating again in the following syllable (Dell1980:228).Again, we are not interested in encoding Dell's particular generalization, and infact we are unable to.
Rather, it is necessary to look at the underlying observationabout the distribution of schwa.
The observation is that schwa does not appear as itszero allophone in consecutive syllables.
This observation is problematic for us, in thatit refers to two levels of representation, an underlying (or lexical) level involving aschwa segment, and a surface level involving a zero allophone.
We cannot formulatethis observation monostratally.
However, we can come up with a different observation,namely that the vowel is never omitted if the omission results in unacceptable syllablestructure.
In the case of Dell's example, vous me le dites, if both schwas are omitted theresult is a \[vml\] cluster, which cannot be broken up into a valid coda-onset sequence.This new observation makes a different empirical prediction, namely that schwa canbe omitted in consecutive syllables just in case the result is syllabifiable.
As we shallsee below in (51), this prediction is actually borne out.Before proceeding with our own analysis, we present an overview of an autoseg-mental analysis of French schwa due to Tranel.
This analysis is interesting becauseit demonstrates the oft-repeated phenomenon of enriched representations leading todramatically simplified rule systems.
Given the heavy restriction on rules in a mono-stratal framework, it will be more natural to take Tranel's (rather than Dell's) analysisas our starting point.5.3 Tranel's AnalysisTranel (1987a) provides an insightful analysis of French schwa cast in the framework ofautosegmental phonology.
In this section we give an overview of this analysis.
In thefollowing section we shall endeavour to provide an empirically equivalent analysis.Tranel adopts a CV skeleton tier and a segmental tier.
Schwa is represented asanunlinked vowel, as shown in the following representation for melons.Example 44C C Vm oe 1 5478Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsOn top of this two-tiered structure, Tranel proposes a level of hierarchical organ-ization for representing syllable structure.
Tranel adopts the two syllable formationrules given in (45).
A third (unstated) rule is assumed to incorporate unsyllabifiedconsonants into coda position.Example 45a.
Basic syllable formation b. Schwa-syllable formationO" (7 /\ /\O R O RrC V --* C V C ~ C V\[F\] ~ \[F\] 0Note that (45a) does not apply to the mo~ sequence in (44), as the schwa is not linkedto a V node as required on the left-hand side of rule (45a).
(Tranel later adopts arefinement to (45a), preventing it from applying if the V is the first vowel of an h-aspir6morpheme.)
For the phrases ix melons and sept melons, the basic syllable formation rulebuilds the following structures.Example 46O" /\O RJC V CIs i m/\ /\ /\OR OR ORI r IC V C V C C C Vr l  I I~ 1 5 s ~ t m ~ 1 5The remaining consonants must either be syllabified leftward into an unsaturatedcoda or remain unsyllabified and rescued by the schwa syllable formation rule.
Forsix melons, both options are possible, as illustrated below.
Note that the unlinked oe isassumed to be phonetically uninterpreted.Example 47O" /\O RI \C V C~ L Ls i mO" O" O" O" /\ /\ /\ /\OR OR O R ORJ f r I I IC V C V C V C VI I L I I I t Ice 1 5 s i m oe I 5This gives us the two options, \[sim.lS\] and \[si.mce.15\], according with the observation479Computational Linguistics Volume 20, Number 3in (41).
For sept melons, however, there is just the one option.
The t must be syllabifiedinto the preceding coda, and the m requires the presence of schwa, and so we have\[set.mce.15\].
Further examples of this particular kind of schwa alternation are givenbelow (Tranel 1987b:91).Example 48Schwa Requiredde qui parlez-vous?
\[doekiparlevu\]te casse pas la t~te \[tcekaspctlat~t\]debout \[doebu\]depuis quatre ans \[dcept\[ikatr~t\]dedans \[dced~t\]je joue \[~3oe3u\]le lait \[lcele\]ce salon \[scesal6\]Schwa Optionalvous parlez de qui?ne te casse pas la t~teil est deboutc'est depuis quatre ansla-dedansmais je jouedans le laitdans ce salon\[vuparled(ce)ki\]\[ncet(ce)kctspctlat~t\]\[iled(ce)bul\[s~d(ce)ptIikatr~tl\[lad(ce)d0~l\[mc3(ce)3u\]\[d~(ce)l~\]\[d~ts(ce)sal6\]So far, we have seen the case where the leftward syllabification of a consonantlicenses the omission of schwa.
Now we turn to a similar case, but where the consonantsyllabifies rightward into a following onset provided that the resulting onset clusteris permitted.
The data in (49) are from Tranel (1987b:92).Example 49secoue pas la t6teje pense pasce bona rien\[sku.pct.la.t~t\]~\[soe.ku.pct.la.tet\]\[fp~ts.pct\],,~ [ 3oe.pgls.p ~t\]\[zbS.a.rj~\]~-,\[sce.bS.a.rj~\]'don't shake your head''I don't think so''this good-for-nothing'Tranel gives two additional syllable formation rules, shown in (50).Example 50a.
Onset accretion b. Onset accretion across schwaO OI / \C C --* C C C\[ L I\[F\] \[G\] \[Fl \[GI IF\] ceO OC --+ C C\[G\] IF\] ce \[G\]Restriction:must create a valid onsetRestriction:\[F\] must be word-initialRule (50a) incorporates as many consonants as possible into an onset so long as theonset conforms to the phonotactic onstraints of the language.
Rule (50b), of mostinterest here, allows for a consonant to be incorporated into a following onset even ifthere is an intervening schwa, provided that the consonant is word-initial (and thatthe resulting onset is allowable).
The intervening schwa remains unpronounced.
Rule(50b), which is optional, correctly captures the alternations displayed in (49).
This ruleis restricted to apply word-initially "so as to avoid the generation of wordqnternaltriliteral consonant clusters from under ly ing/CCoC/sequences (compare marguerite480Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systems/margorit/ \[margorit\] *\[margrit\] and margrave /margrav/ \[margrav\] *\[margorav\])"(Tranel 1987a:852).
Thus, although many CCC sequences are acceptable phonologically,they are not permitted if a schwa is available to break up the cluster.We also note that Tranel's analysis (Tranel 1987a) gives the correct result for casesof deletion of schwa in consecutive syllables.
Consider the following data.Example 51a.
on ne se moque pas \[6n.sm3k.pct\] (Valdman 1976:120)b. sur le chemin \[syl.fm~\] (Morin 1978:82)For both of these cases we observe an "underlying" ClceC2ce pattern, but where bothces are omitted and where C1 syllabifies into the preceding coda and C2 syllabifiesinto the following onset.To conclude, we can summarize the empirical content of Tranel's analysis asfollows:(a) Every consonant must be syllabified.
(b) Schwa must be realized if it provides the syllable nucleus for animmediately preceding consonant that:(i) cannot be syllabified into a coda, and(ii) cannot form a permissible (word) onset with an immediatelyfollowing consonant.Naturally, this statement is not the last word on French schwa and there may beways in which it needs to be revised, such as for the treatment of word-final schwasand thematic schwas (Tranel 1987a:855ff).
However, since our purpose is primarily toillustrate the workings of the theoretical model, we shall take the above statement asa well-defined starting point on which to base the following analysis.5.4 A Constraint-Based AnalysisGiven our formal semantics for the autosegmental notation, it would be a relativelystraightforward matter to implement Tranel's analysis directly, especially since therules only involve the building of structure, and there is no use of destructive processes.Tranel's analysis is fully declarative.However, as it happens, there is no need for us to adopt the rich representationTranel employs.
We can simulate his analysis using a single tier (rather than two) whileretaining a representation f syllable structure.
Observe that the use of the CV tier andthe melody tier was motivated solely by the need to have a floating autosegment, the~e.
It is equivalent to collapse these two tiers, using the alternation ce~0 in place of thefloating ce.
This style of approach to zero alternations, which dates back to Bloomfield(1926), will employ the parenthesis notation for optional items that was defined inSection 2.1.
We follow Tranel in representing syllable structure and we shall do thisusing the notation shown in (52).
1616 Our analysis is not crucially tied to this particular version of syllable structure, which is most closelyrelated to the proposals of Kahn (1976) and Clements and Keyser (1983).481Computational Linguistics Volume 20, Number 3Example 52 I ONS " onset |NUC : nucleussyl \[CODA : codaAn independent tier that represents yllable structure will be encoded as a se-quence of such syllables, where the segmental constituents of the syllable structureare coindexed with a separate segmental tier, as defined in (53).
Note that the indicesin (53) range over lists that may be empty in the case of onsets and codas, and thatthe type phrase denotes phonological phrases.Example 53a.SYLS :SEGSphrase< D\]> o \] NUC : ~,syl LCODA :E\] ~- E\]~- E\]r- E\]I SYLS : ~r~_\]l \[SEGSphraseb.
rSYCS qphrase LSEGS :The notation of (53) states that in order for something to be a well-formed phrase,its sequence of segments must be parsed into a sequence of well-formed syllables.
Inmore familiar terms, one could paraphrase (53) as stating that the domain of syllabi-fication in French is the phrase.As a simple illustration of the approach, consider again the word melons.
The pro-posed lexical representation for the phonology attribute of this word is\[SEGS : (m (ce) 1 5}\].
When we insist that any phrase containing this word must con-sist of a sequence of well-formed syllables, we can observe the following pattern ofbehavior for six melons.Example 54a.phrase\[ <rONSLcoDA '>'>\] tONS ,m>\] tONS SYLS: /NUC: (i} |NUC: } /NUC: (5}LCODA IT <> : : LCODA : syl syl sylLSECS (s i m ce 1 5}b.phraseI { toNs: SYLS ?
/ NUC : syl LCODA : LSEGS (S i m 1 O} ,s>l  ONS il\]>\] <,>l LcoN~CA >(m)Jsy IObserve in the above example that the syllabic position of m is variable.
In Exam-ple 54a m is in an onset while in 54b it is in a coda.
Therefore, it is inappropriate to482Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systemsonsetinternal-onset(obs, liq)((cons), (glide)}codain terna l -coda~, n) (cons, cons}(obs, son} ((cons)}(s, stop, liq)Figure 3Parts of French type hierarchy.insist that the syllabic affiliation of segments i determined lexically.
Rather, we haveopted for the prosodic type phrase, insisting that anything of this type consists of oneor more well-formed syllables (cf.
Example 11).Now consider the case of the phrase sept melons.
This is similar to the situation in(54), except hat we must find a way of ruling out the tml cluster as a valid coda-onsetsequence.
We are not aware of any exhaustive study of possible French consonant clus-ters, although one can find discussions of particular clusters (e.g., Tranel \[1987b:95ff\]shows that CLj onset clusters are not tolerated).
Consequently, the two hierarchies inFigure 3 are necessarily preliminary, and are made more for the sake of being explicitthan for their precise content.
Note that parentheses indicate optionality, so, for ex-ample, both onsets and codas are allowed to be null.
Additional stipulations will benecessary to ensure that an intervocalic onsonant is syllabified with the material toits right.
We can do this by preventing an onsetless yllable from following a closedsyllable, with the type onset-max-1.Example 55/,... rCODA:ne, st\]onset-max-1 - ~ \ syl k sylphraseNow consider again the phrase six melons.
The syllabification *\[si.moel.5\] wouldbe represented as follows:Example 56/ IONS  IONS" e' s'l  , IONS: (s)\] / NUC: (~e/ LNUC (~/j /syl LNUC: (i)Jsyl LCODA : nelist(1) sylObserve that this list of syllables contains a violation of (55), so \[si.moel.5\] is ruledout.
Now that we have considered vowel-consonant-vowel (VCV) sequences, we shallmove on to more complex intervocalic onsonant clusters.Although the constraints in Figure 3 produce the desired result for VLLV clus-ters (L--liquid), by assigning each liquid to a separate syllable (Tranel 1987b), thereis still ambiguity with VOLV clusters (O=obstruent), which are syllabified as V.OLVaccording to Tranel.
We can deal with this and similar ambiguities by further refining483Computational Linguistics Volume 20, Number 3the classification of syllables and imposing suitable constraints on syllable sequences.Here is one way of doing this, following the same pattern that we saw in (55).Example 57onset-max-2 ~ -~phrase< syl I CODA : < obs >\] IONS: syl t <obs >l >This constraint states that it is not permissible to have an obstruent in a syllablecoda if the following onset lacks an obstruent.
Equivalently, we could say that if asyllable coda contains an obstruent hen the following onset must also contain anobstruent.
To see why these constraints are relevant o schwa, consider the case ofdemanderions, (also discussed by Tranel \[1987b\]).
The constraints in Figure 3 rule out* \[doe.m~t.drjS\], since the underlined onset cluster is too complex.
The constraint in (57)rules out *\[doe.m0~d.rj6\], where the obstruent d is assigned to the preceding syllable toleave an rj onset.
The remaining two possible pronunciations are \[dce.m~t.dc~.rj6\] and\[dce.m0~.dri.j6\], as required.
(Note that the ions suffix has the two forms, \[j6\] and \[ij6\].
)Now let us consider the case of h-aspir6 words.
These vowel-initial words donot tolerate a preceding consonant being syllabified into the word-initial onset.
Whathappens to the V.CV and V.OLV constraints when the second vowel is in the firstsyllable of an h-aspir6 word, as we find in sept haches \[s~t.a ~\], *\[s~.ta~\] and quatre haches\[katr.ay\], *\[kat.ray\], *\[ka.tray\]?
Here, it would appear that Tranel's analysis breaksdown.
Our conjecture is that the constraints in (55) and (57) should only apply whenthe second syllable is not an h-aspir6 syllable.
So we need to introduce a furtherdistinction in syllable types, introducing ha-syl for h-aspir6 syllables and nha-syl forthe rest.Example 58syl ~ ha-syl V nha-sylNow ha-syl is defined as follows:Example 59IONSET : elist\]ha-syl I.Accordingly, the constraints (55) and (57) are refined, so that the second syllableis of the type nha-syl.
The revised constraints are given in (60).Example 60 <  CODa ne,/st  a. onset-max-l' -- -~ " syl nha-sylphraseb.
< ICOD :<o   >\] \[ONS: <o s >\]> onset-max-2' =-- ~ "" syl nha-sylphraseNow, h-aspir6 words will be lexically specified as having an initial ha-syl.
How-ever, we must not specify any more syllable structure than is absolutely necessary.Example 61 displays the required constraint for the word haut.484Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsExample 61lexical-sign\[SYLS (hasy,\[ CPHON: LSEGS : (r/-\] o)phonSYNSEMICAT : nounSo although syllabification operates at the phrase level rather than the morphemelevel (see Example 53), we are still able to impose lexically conditioned constraints onsyllable structure directly.It remains to be shown how this treatment ofh-aspir6 bears on schwa.
Fortunately,Tranel (1987b:94) has provided the example we need.
Consider the phrase dans le haut\[d~t.lce.o\].
This contains the word le \[l(ee)\], which is lexically specified as having anoptional ce, indicated by parentheses.
17 There are three possible syllabifications, onlythe last of which is well formed.Example 62 < '?NS: ii' \] l?N : a.
* |NUC:  ) NUC:  (o)LCODA : CODA:  0syl ha-sylb.< tONS ,d,1 ('ONSET " \ ] ) I  ONSET"\]>* /NUC: <C~> I /NUC: (oe) NUC: (o)LCODA: (l) J k C?DA: 0 L CODA: 0syl syl ha-sylC.<,ONS ,d,\] ONSET,l, 1 I ONSET,,\]>NUC : NUC : LCODA I~ ~ NUC: LCODA 7 ~ <o> : : k CODa: 0 syl syl ha-sylThe syllabification i (62a) is unavailable, since the syllable corresponding to the wordhaut is lexically specified as ha-syl, which means that its onset must be an elist from(59).
The syllabifications in (62b) are likewise unavailable since these both consist of asyllable with a coda followed by a syllable without an onset, in contravention f (60a).This only leaves (62c), which corresponds to the attested form \[d~t.lce.o\].We conclude this section with an example derivation for the phrase on ne se moquepas \[6n.smak.pct\], which was presented in (51).
We assume that at some stage of aderivation, the PHON attribute of a sign is as follows:Example 63F/SEGS : (6) --- (n (oe)) --- (s (oe)) --- (m a k) --- (p ?)
/..1phon L J17 As stated above, we do not address the phenomenon of elision here; this example shows that ananalysis of elision would not require a separate stipulation for h-aspir6 words.485Computational Linguistics Volume 20, Number 3When the appropriate grammatical conditions are met, this phonology attribute willbe given the type phrase.
The definition in (53) will accordingly specialize the SYLSattribute.
One possible specialization :is given in Example 64.Example 64f / \[  ?Ns: rONBET:,BI,1YLS: NUC: I NUC: /CODA: LCODA: {k) J syl sylphrase LSEGS : (6 n s m o k p ct)(P)1\1 ,NUC.
j;\] Lcoo -I  /The reader can check that the onset and coda sequences comply with the constraints inFigure 3, that the first syllable can have an empty onset because there is no precedingsyllable that could have a coda that matches the requirements of (60a), and that theobstruent k is permitted by constraint (60b) to appear in the coda of the second syllablebecause there is another obstruent p in the following onset.This concludes our discussion of French schwa.
We believe our treatment of schwais empirically equivalent to that of Tranel (1987a), except for the analysis of h-aspir6.Several empirical issues remain, but we are optimistic that further refinements toour proposals will be able to take additional observations on board.
Notwithstandingsuch further developments, we hope to have demonstrated that the procedural de-vices of deletion and rule ordering are unnecessary in a typed feature-based grammarframework, and that constraints represent a perspicuous way of encoding linguisticobservations.6.
Prospects for ImplementationIn the preceding sections we have shown how the use of parameterized lists in HPSGis sufficient for encoding a variety of phonological generalizations.
While we like thisapproach for the purposes of specification and exposition, as stated in Section 1.4,we actually envisage an implementation employing finite-state automata for stringmanipulation.
This is simply because we favor the use of existing well-understoodtechnology when it comes to producing an efficient implementation.As we have already explained in Section 1.4, we have linguistic reasons for notwishing to use finite-state transducers and the concomitant two-level model, and in-stead are interested in exploring the prospects of integrating our work with the au-tomaton model of Bird and Ellison (1994).
In this section we give an overview of thisautomaton model and briefly outline the view of automata s types that was originallyproposed in Bird (1992).6.1 One-Level PhonologyFor a variety of reasons already laid out in Section 1, we would like to achieve a closerintegration between phonology and constraint-based grammar frameworks like HPSG.However, for such an integration to work, it is necessary to adopt a rather unusualview of phonology; one characterized by such notions as compositionality, intensional-ity, and lexicalism, and which has come to be called constraint-based phonology (Bird1990).Recently, Bird and Ellison (1994) have reinterpreted the constraint-based approachto phonology using finite-state automata.
Nonlinear phonological representations and486Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systemsx i!iiiiii!iiiiilq!iii!!!!!
ii{iiiiii ~!i YFigure 4Two views of autosegmental association.rules are encoded as automata.
The key insight is that if autosegmental associationis viewed as overlap between intervals with duration (Bird and Klein 1990), then theoverlap can be simulated by using synchronization primitives on automata.
Figure 4illustrates this idea.
The diagram on the left of Figure 4 shows two temporal intervalsx and y that overlap during the shaded period.
On the right, the intervals x andy themselves are represented as sequences of contiguous tape cells where each cellcontains a copy of the appropriate information (here, simply repeats of x and y).Again, the shaded period indicates the period of 'overlap' of the two intervals.
Thereader is referred to Bird and Ellison (1994) for further details.Although this kind of phonology employs formal devices very similar to the two-level FST model, there are some important differences in how the two models are used.In the two-level model the traditional distinction in phonology between RULES andREPRESENTATIONS is evident in the transducers and tapes respectively.
As in constraint-based grammar more generally, one-level phonology does not have this distinction;rules and representations alike are interpreted as automata.
Figure 5 illustrates thisdifference.Now that we have outlined the one-level model and briefly discussed its relation-ship with the two-level model, we shall sketch the link to typed feature systems.
(a) Two Level PhonologyLexical Representation\] I I I I JRulesI r J I I \[Surface Representation(b) One Level Phonology~ - Lexical Representation~-F-S-~ - Lexical Constraint/ , , /  ~F-~ - Prosodic Constraint-~ - Surface RepresentationFigure 5Comparison of two-level and one-level phonology.487Computational Linguistics Volume 20, Number 36.2 Types as AutomataA type denotes aset of objects.
Thus, types are descriptions, and they can be combinedusing the familiar operations of meet, join, and negation.
Similarly, an automaton de-notes a set of objects, namely strings (o1" automaton tapes).
And likewise, the operationsof meet, join, and negation are defined for automata nd correspond to intersection,union, and complement of the corresponding sets.
Of course, a further operation ofconcatenation is defined for automata.
We envisage a system for processing linguis-tic descriptions that implements a subset of the types (which we might simply callSTRING types) as finite-state automata over some predefined alphabet.
When the infer-ence engine requires that two string types be 'unified,' the meet of the correspondingautomata will be formed.Although these string types may be declared as the appropriate values for certainattributes in a typed feature system, string types are only declared in terms of thebasic alphabet and other string types.
It is not possible to employ non-string types inthe definition of string types.
This is a severe restriction, since list types (say, in HPSG)allow arbitrary feature structures as elements, and we would like to be able to do thesame for string types.
Work on overcoming this limitation is currently in progress, andbuilds on the well-known similarity between feature structures and automata, whenviewed as directed graphs (Kasper and Rounds 1986).7.
ConclusionIn this paper, we have tried to give the reader an impression of how two rather differentphonological phenomena can be given a declarative ncoding in a constraint-basedgrammar.
Although we have focused on phonology, we have also placed our analyseswithin a morphological context as befits the multi-dimensional perspective of HPSG.The formal framework of HPSG is rather powerful; certainly powerful enough tocapture many analyses in the style of classical generative phonology in which arbi-trary mappings are allowed between underlying and surface representations.
Wehavelimited ourselves further by allowing only one phonological stratum in the grammar,and by adopting anotion of phonological compositionality that supports monotonicity.These restrictions make it much harder to carry over generalizations that depended ona procedural rule format.
This is not a handicap, we contend, since it is heuristicallyvaluable to view the data in a new light rather than just coercing traditional analysesinto a modern grammar formalism.So what is a constraint-based style of phonological nalysis?
An important key, weclaim, is the use of generalizations expressed at the level of prosodic types.
Coupledwith a systematic underspecification of lexical entries and a regime of type inheritance,this allows us to have different levels of linguistic abstraction while maintaining a'concrete' relation between lexical and surface representations of phonology.We hope to have given enough illustration to show that our approach is viable.
Infuture, we wish to extend these same techniques to a typologically diverse range ofother linguistic phenomena.
A second important goal is to show how the technologyof finite-state automata can be invoked to deal with phonological information i  HPSG.For although we have placed phonology within a general framework of linguisticconstraints, the analyses we have presented only involve manipulation of regularexpressions.AcknowledgmentsThis research is funded by the U.K. Scienceand Engineering Research Council, undergrant GR/G-22084 Computational Phonology:A Constraint-Based Approach, and has beencarried out as part of the research program488Steven Bird and Ewan Klein Phonological Analysis in Typed Feature Systemsof the Human Communication ResearchCentre, supported by the U.K. Economicand Social Research Council.
We aregrateful to Ted Briscoe, Tomaz Erjavec,Dani61e Godard, John Nerbonne, MarcPlenat, Bernard Tranel, and Ivan Sag fordiscussions and correspondence relating tothis work, and to two anonymous reviewersfor their helpful suggestions.ReferencesAnderson, S. R. (1992).
A-MorphousMorphology, Volume 62 of CambridgeStudies in Linguistics.
CambridgeUniversity Press.Antworth, E. (1990).
PC-KIMMO: ATwo-Level Processor for MorphologicalAnalysis.
Summer Institute of Linguistics.Archangeli, D., and Pulleyblank, D.
(1989).
"Yoruba vowel harmony."
LinguisticInquiry, 20, 173-217.Bach, E., and Wheeler, D. W.
(1981).
"Montague phonology: A firstapproximation."
University ofMassachusetts Occasional Papers inLinguistics, 7, 27-45.Bird, S. (1990).
Constraint-based phonology.Doctoral dissertation, University ofEdinburgh.
To be published in revisedform by Cambridge University Press,Studies in Natural Language Processing.Bird, S. (1992).
"Finite-state phonology inHPSG."
In Proceedings ofthe 14thInternational Conference on ComputationalLinguistics (COLING-92).
74-80.Bird, S., and Ellison, T. M.
(1994).
"One-level phonology: Autosegmentalrepresentations and rules as finiteautomata."
Computational Linguistics, 20,55-90.Bird, S., and Klein, E. (1990).
"Phonologicalevents."
Journal of Linguistics, 26, 33-56.Bird, S., and Ladd, D. R. (1991).
"Presentingautosegmental phonology."
Journal ofLinguistics, 27, 193-210.Bloomfield, L. (1926).
"A set of postulatesfor the science of language."
Language, 2,153-164.
Reprinted in Readings inLinguistics h The Development of DescriptiveLinguistics in America 1925-56, edited byMartin Joos.
26-31.Briscoe, T. (1991).
"Lexical issues in naturallanguage processing."
In Natural Languageand Speech, edited by E. Klein andE Veltman, 39-68.
Springer-Verlag.Bromberger, S., and Halle, M. (1989).
"Whyphonology is different."
Linguistic Inquiry,20, 51-70.Cahill, L. J.
(1990).
"Syllable-basedmorphology."
In Proceedings, 13thInternational Conference on ComputationalLinguistics, Volume 3, edited byH.
Karlgren, 48-53.Carpenter, B.
(1992).
The Logic of TypedFeature Structures.
Volume 32 of CambridgeTracts in Theoretical Computer Science.Cambridge University Press.Clements, G. (1985).
"The geometry ofphonological features."
PhonologyYearbook, 2, 225-252.Clements, G. N., and Keyser, S. J.
(1983).
CVPhonology: A Generative Theory of theSyllable.
MIT Press.Coleman, J. S. (1991).
Phonologicalrepresentations--their names, forms andpowers.
Doctoral dissertation, Universityof York.Coleman, J. S. (1992).
"The phoneticinterpretation f headed phonologicalstructures containing overlappingconstituents."
Phonology, 9, 1-44.Copestake, A.; Sanfilippo, A.; Briscoe, T.;and de Paiva, V. (in press).
"TheACQUILEX LKB: An introduction."
InDefault Inheritance in Unification BasedApproaches tothe Lexicon, edited byT.
Briscoe, A. Copestake, and V. de Paiva.Cambridge University Press.Dell, E (1980).
Generative Phonology andFrench Phonology.
Cambridge UniversityPress.Emele, M. C., and Zajac, R. (1990).
"Typedunification grammars."
In Proceedings,13th International Conference onComputational Linguistics.
293-298.Gazdar, G.; Klein, E.; Pullum, G.; and Sag, I.(1985).
Generalized Phrase StructureGrammar.
Blackwell.Goldsmith, J.
(1990).
Autosegmental andMetrical Phonology.
Blackwell.Goldsmith, J.
A.
(1993).
"Harmonicphonology."
In The Last Phonological Rule:Reflections on Constraints and Derivations,edited by J.
A. Goldsmith, 21--60.University of Chicago Press.Hoeksema, J., and Janda, R.
(1988).
"Implications of process morphology forcategorial grammar."
In CategorialGrammars and Natural Language Structures,edited by R. T. Oehrle, E. Bach, and D. W.Wheeler, 199-247.
Reidel.Hooper, J.
(1976).
An Introduction to NaturalGenerative Phonology.
Academic Press.Hudson, G. (1980).
"Automatic alternationsin non-transformational phonology.
"Language, 56, 94-125.Jaffar, J., and Lassez, J.-L.
(1987).
"Constraint logic programming."
In ACMSymposium on Principles of ProgrammingLanguages, II1-119.Johnson, M. (1988).
Attribute-value logic and489Computational Linguistics Volume 20, Number 3the theory of grammar.
Doctoraldissertation, Stanford University.Kahn, D. (1976).
Syllable-based Generalizationsin English Phonology.
Indiana UniversityLinguistics Club.Kaplan, R. M., and Bresnan, J.
(1982).
"Lexical-Functional Grammar: A forma1system for grammatical representation.
"In The Mental Representation f GrammaticalRelations, edited by J. Bresnan.
MIT Press.Kasper, R. T., and Rounds, W. C. (1986).
"Alogical semantics for feature structures.
"In Proceedings, 24th Annual Meeting of theAssociation for Computational Linguistics.257-266.Kay, M. (1987).
"Nonconcatenativefinite-state morphology."
In Proceedings,Third Meeting of the European Chapter of theAssociation for Computational Linguistics.2-10.Keating, P. (1984).
"Phonetic andphonological representation f stopconsonant voicing."
Language, 60, 286-319.Kenstowicz, M., and Kisseberth, C. (1979).Generative Phonology: Description andTheory.
Academic Press.Kiparsky, P. (1982).
Lexical Morphology andPhonology.
Hanshin Publishing Co.Kisseberth, C. W. (1970).
"On the functionalunity of phonological rules."
LinguisticInquiry, 1,291-306.Klein, E. (1992).
"Data types incomputational phonology."
In Proceedings,14th International Conference onComputational Linguistics (COLING-92).149-155.Klein, E. (1993).
"An HPSG approach toSierra Miwok verb stems."
In Phonologyand Computation, edited by T. M. Ellisonand J. M. Scobbie.
University ofEdinburgh, 19-35.Kornai, A.
(1991).
Formal phonology.
Doctoraldissertation, Stanford University.Koskenniemi, K. (1983).
Two-level morphology:A general computational model for word-formrecognition and production.
Doctoraldissertation, University of Helsinki.Krieger, H.-U., and Nerbonne, J.
(in press).
"Feature-based inheritance networks forcomputational lexicons."
In DefaultInheritance in Unification Based Approaches tothe Lexicon, edited by T. Briscoe,A.
Copestake, and V. de Paiva.Cambridge University Press.Krieger, H.-U.
; Pirker, H.; and Nerbonne, J.(1993).
"Feature-based allomorphy."
InProceedings, 31st Annual Meeting of theAssociation for Computational Linguistics,140-147.Manaster Ramer, A.
(1981).
How abstruse isphonology?
Doctoral dissertation,University of Chicago.Martinet, A.
(1972).
"La naturephonologique d'e caduc."
In Papers inLinguistics and Phonetics to the Memory ofPierre Delattre, edited by A. Valdman.Mouton.Mastroianni, M. (1993).
Attribute LogicPhonology.
CMU-LCL 93-4, CarnegieMellon University.McCarthy, J.
(1981).
"A prosodic theory ofnon-concatenative morphology.
"Linguistic Inquiry, 12, 373-418.McCarthy, J., and Prince, A.
(1993).
"Prosodic morphology I---Constraintinteraction and satisfaction."
UnpublishedReport.Morin, Y.-C. (1978).
"The status of mute 'e'.
"Studies in French Linguistics, 1, 79-140.Morin, Y.-C. (1987).
"French data andphonological theory."
Linguistics, 25,815-843.Paradis, C. (1988).
"On constraints andrepair strategies."
The Linguistic Review, 6,71-97.Partee, B. H. (1979).
"Montague grammarand the well-formedness constraint."
InSyntax and Semantics 10: Selections from theThird Groningen Round Table, edited byE Heny and H. SchneUe, 275-313.Academic Press.Pierrehumbert, J.
(1990).
"Phonological ndphonetic representation."
Journal ofPhonetics, 18, 375-394.Pollard, C., and Sag, I.
(1987).Information-Based Syntax and Semantics.Volume 13 of CSLI Lecture Notes.
Stanford:Center for the Study of Language andInformation.Prince, A. S., and Smolensky, P.
(1993).
"Optimality theory: Constraint interactionin generative grammar."
TechnicalReport 2, Center for Cognitive Science,Rutgers University.Pullum, G. K., and Zwicky, A. M.
(1984).
"The syntax-phonology boundary andcurrent syntactic theories."
In Ohio StateUniversity Working Papers in Linguistics:Papers on Morphology, edited by A. Zwickyand R. Wallace.
Ohio State University.Reinhard, S., and Gibbon, D.
(1991).
"Prosodic inheritance and morphologicalgeneralizations."
In Proceedings, 5thEuropean ACL Meeting, 131-136.Riehemann, S. (1992).
Word formation inlexical type hierarchies: A case study ofbar-adjectives in German.
Master's thesis,Department of Linguistics, University ofTiibingen.Rooth, M. (1985).
Association with focus.Doctoral dissertation, University ofMassachusetts-Amherst.490Steven Bird and Ewan Klein Phonological Analysis in Typed Feature SystemsRussell, K. (1993).
A constraint-based approachto phonology.
Doctoral dissertation,University of Southern California.Scobbie, J.
(1991).
Attribute-value phonology.Doctoral dissertation, University ofEdinburgh.Selkirk, E. (1984).
Phonology and Syntax.
MITPress.Shibatani, M. (1973).
"The role of surfacephonetic onstraints in generativephonology."
Language, 49, 87-106.Smolka, G. (1992).
"Feature constraint logicsfor unification grammars."
Journal of LogicProgramming, 12, 51-87.Sproat, R. (1992).
Morphology andComputation.
Natural LanguageProcessing.
MIT Press.Sproat, R., and Brunson, B.
(1987).
"Constituent-based morphologicalparsing: A new approach to the problemof word-recognition."
In Proceedings, 25thAnnual Meeting of the Association forComputational Linguistics.
65-72.Tranel, B.
(1987a).
"French schwa andnonlinear phonology."
Linguistics, 25,845-866.Tranel, B.
(1987b).
The Sounds of French--AnIntroduction.
Cambridge University Press.Valdman, A.
(1976).
Introduction to FrenchPhonology and Morphology.
NewburyHouse.Walther, M. (1992).
Deklarative Silbifizierungin einem constraintbasiertenGrammatikformalismus.
Master's thesis,University of Stuttgart.Wheeler, D. (1981).
Aspects of a CategorialTheory of Phonology.
Doctoral dissertation,University of Massachusetts-Amherst.Wiebe, B.
(1992).
Modelling autosegmentalphonology with multi-tape finite statetransducers.
Master's thesis, Simon FraserUniversity.Zajac, R. (1992).
"Inheritance andconstraint-based grammar formalisms.
"Computational Linguistics, 18, 159-182.Zajac, R. (in press).
"Issues in the design ofa language for representing linguisticinformation based on inheritance andfeature structures."
In Default Inheritance inUnification Based Approaches tothe Lexicon,edited by T. Briscoe, A. Copestake, andV.
de Paiva.
Cambridge University Press.491
