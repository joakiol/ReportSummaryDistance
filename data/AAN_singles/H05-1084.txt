Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 668?675, Vancouver, October 2005. c?2005 Association for Computational LinguisticsAnalyzing models for semantic role assignment using confusabilityKatrin Erk and Sebastian Pad?Computational LinguisticsSaarland UniversitySaarbr?cken, Germany{erk,pado}@coli.uni-sb.deAbstractWe analyze models for semantic roleassignment by defining a meta-modelthat abstracts over features and learningparadigms.
This meta-model is based onthe concept of role confusability, is de-fined in information-theoretic terms, andpredicts that roles realized by less specificgrammatical functions are more difficultto assign.
We find that confusability isstrongly correlated with the performanceof classifiers based on syntactic features,but not for classifiers including semanticfeatures.
This indicates that syntactic fea-tures approximate a description of gram-matical functions, and that semantic fea-tures provide an independent second viewon the data.1 IntroductionSemantic roles have become a focus of research incomputational linguistics during the recent years.The driving force behind this interest is the prospectthat semantic roles, as a shallow meaning represen-tation, can improve many NLP applications, whilestill being amenable to automatic analysis.
Thebenefit of semantic roles has already been demon-strated for a number of tasks, among others for ma-chine translation (Boas, 2002), information extrac-tion (Surdeanu et al, 2003), and question answer-ing (Narayanan and Harabagiu, 2004).Robust and accurate automatic semantic role as-signment, a prerequisite for the wide-range use ofsemantic roles in NLP, has been investigated in anumber of studies and shared tasks.
Typically, roleassignment has been modeled as a classificationtask, with models being estimated from large cor-pora (Gildea and Jurafsky, 2002; Moschitti, 2004;Xue and Palmer, 2004; Surdeanu et al, 2003; Prad-han et al, 2004; Litkowski, 2004; Carreras andM?rquez, 2005).Within this framework, there is a number of archi-tectural parameters which lend themselves to opti-mization: the machine learning framework, the fea-ture set, pre- and postprocessing, each of which hasbeen investigated in the context of semantic role as-signment.
The current paper concentrates on featureengineering, since the feature set is a pivotal com-ponent of any kind of machine learning system, andallows us to incorporate and test linguistic intuitionson the role assignment task.We approach feature engineering not by directlyoptimizing system performance.
Instead, we pro-ceed by error analysis, like Pado and Boleda (2004).Our aim is to form a global hypothesis that explainsthe distribution of errors across classes.
Insofar asthe model does not contain model-specific infor-mation, following this methodology can provide ameta-model of a model family which abstracts overconcrete features and over the learning paradigm.The concrete global hypothesis we test is: (1) Allfeatures of current models approximate a descrip-tion of grammatical functions, and the complete sys-tems approximate an assignment based on grammat-ical functions.
(2) System performance for a givenrole depends on how easily it is confused with otherroles.
We will give this concept of role confusabilitya formal, information-theoretic definition.The present study specifically analyzes mod-els for semantic role assignment in the FrameNet668paradigm (Fillmore et al, 2003).
We are going toshow that our hypothesis indeed holds for a varietyof models ?
but only models that comprise exclu-sively syntactic features.
We conclude that syntacticfeatures approximate a description of grammaticalfunctions, but that semantic features model a dif-ferent aspect of the role assignment mapping.
To-gether with the reasonable performance of a solelysemantics-based system, this leads us to suggest acloser investigation of semantic features ?
and inparticular, a co-training approach with syntactic andsemantic features as different views on the role as-signment data.Plan of the paper.
In Section 2, we give abrief introduction to FrameNet, the semantic roleparadigm and corpus we are using in this study.
Ourfirst experiment, described in Section 3, establishesthat there is a high variance in performance acrossroles, and that this variance is itself stable acrossmodels and learners.
In Section 4, we state our hy-pothesis, namely that this variance can be explainedthrough role confusability, and formalize the con-cept .
In Section 5, we perform detailed correlationtests to verify our hypothesis and discuss our find-ings.
Section 6 concludes the paper.2 FrameNetThis section presents the semantic role paradigm andthe role-annotated corpus on which the present studyis based.
FrameNet1 is a lexical resource based onFillmore?s Frame Semantics (Fillmore, 1985).
It de-scribes frames, representations of prototypical situa-tions.
Each frame provides its set of semantic roles,the entities or concepts pertaining to the prototypi-cal situation.
Each frame is further associated with aset of target predicates (nouns, verbs or adjectives),occurrences of which can introduce the frame.FrameNet provides manually annotated examplesfor each predicate, sampled from the British Na-tional Corpus (Burnard, 1995).
The size of this cor-pus exceeds 135,000 sentences.
The following sen-tences are examples for verbs in the IMPACT frame,which describes a situation in which typically ?anIMPACTOR makes sudden, forcible contact with theIMPACTEE, or two IMPACTORS both ... [make]forcible contact?
:1http://www.icsi.berkeley.edu/~framenet/(1) [Impactee His car] was struck [Impactor by athird vehicle].
(2) [Impactor The door] slammed [Result shut].
(3) [Impactors Their vehicles] collided [Place atPond Hill].FrameNet manual annotation also comprises a layerof grammatical functions: For example, the subjectof finite verbs is labeled Ext, and Mod is a labelused for modifiers of heads, e.g.
an adjective mod-ifying a noun.
The grammatical functions used inFrameNet are listed in Fillmore and Petruck (2003).Note that the frame-specificity of semantic rolesin FrameNet has important consequences for seman-tic role assignment, since there is no direct wayto generalize role assignments across frames, andlearning has to proceed frame-wise.
This com-pounds the data sparseness problem, and automaticassignment for frames with no training data is verydifficult (Gildea and Jurafsky, 2002).3 Experiment 1: Variance in roleassignmentSeveral studies have established that there is con-siderable variance in semantic role assignment per-formance across different semantic roles within sys-tems (Carreras and M?rquez, 2004; Carreras andM?rquez, 2005; Pado and Boleda Torrent, 2004).However, these studies used either the PropBanksemantic role paradigm (Carreras and M?rquez)or a limited of experimental conditions (Pado andBoleda).
For this reason, we perform a first experi-ment to replicate this phenomenon in our setting.Note that the vast majority of participant sys-tems in recent shared tasks divides semantic role as-signment into multiple sequential steps.
The max-imal decomposition is as follows: preprocessing,e.g.
removal of unlikely argument candidates; ar-gument recognition, the distinction between role-bearing and non-role-bearing instances; argumentlabeling, the actual classification of role-bearing in-stances; and postprocessing, e.g.
by inference overprobable role sequences.Following this distinction, we concentrate in thisstudy on the argument labeling step, i.e.
distinguish-ing between roles, rather than distinguishing roles669from non-roles.
This is justified by earlier empiri-cal results, namely that the argument labeling steprequires more training data than argument recogni-tion (Fleischmann and Hovy, 2003), and that it callsfor more sophisticated feature construction (Xue andPalmer, 2004).
We take this as evidence that thequality of the argument labeling step is central to agood semantic role assignment system.In order to isolate the effects of argument label-ing, we assume perfect argument recognition by us-ing gold standard role boundaries; however, we donot use gold standard parse trees, but rather automat-ically computed ones, which realistically introducessome noise (see the following paragraph).Data and preprocessing.
As experimental mate-rial, we used the same data that was used in theSenseval-3 semantic role assignment task: 40 framesfrom FrameNet version 1.1, comprising 66,777 in-stances.
The number of roles per frame ranged from2 to 22, and the number of role instances rangedfrom 593 to 8,378.
The data was randomly split intotraining (90%) and test instances (10%).The data was parsed with the Collinsmodel 3 (1996) parser; in addition, all tokenswere lemmatized with TreeTagger (Schmid, 1994).Modeling.
We model role assignment as a clas-sification task, with parse tree constituents as in-stances to be classified.
We repeated the classifica-tion with two different learners: The first learner,TiMBL (Daelemans et al, 2003) is an implementa-tion of nearest-neighbor classification algorithms inthe memory-based learning paradigm2.
The secondlearner, Malouf?s probabilistic maximum entropy(Maxent) system (Malouf, 2002), uses the LMVMalgorithm to estimate log-linear models.
We did notperform smoothing.Table 5 shows the features we use.
Here as in thesystem setup, we keep close to current existing mod-els for semantic role assignment in order to make ourresults as representative as possible.
We investigatedifferent feature sets in order to verify our results.
InExp.
1, we limit ourselves to two feature sets, Syn(syntactic features) and Sem (lexical features) fromthe bottom of Table 5.
The feature sets were exactlythe same for both learners.2TiMBL was set to k-NN classification, using the MVDMdistance metric and 5 neighbors.Syn/Sem SynMBL 87.1 ?
12.7 82.2 ?
17.8Maxent 87.5 ?
13.4 82.4 ?
18.
2Table 1: Exp.
1: Overall results (F-scores and stan-dard deviation across roles).Syn/Sem SynRole FMBL FMaxent FMBL FMaxentFrame: CHANGE_POSITION_ON_A_SCALEATTR 79.0 80.7 57.6 66.1CO_VAR 55.6 64.0 22.2 31.6DIFF 87.1 84.9 75.0 66.7ITEM 68.6 70.3 48.0 61.3VALUE_1 88.0 91.7 78.3 72.7VALUE_2 93.3 90.9 89.3 85.2Frame: KINSHIPALTER 87.0 89.2 87.8 87.4EGO 96.7 98.8 96.7 95.5Frame: PART_ORIENTATIONALPART 98.2 96.4 97.6 97.0WHOLE 100 100 98.2 100Frame: TRAVELAREA 31.6 52.6 25.0 45.5GOAL 74.4 71.4 68.3 62.2MODE 46.2 72.7 12.5 15.4PATH 66.7 53.3 50.0 40.0SOURCE 66.7 72.7 66.7 66.7TIME 77.8 66.7 15.4 40.0TRAVELER 90.9 90.6 90.9 90.6Table 2: Exp.
1: Role-specific figures of system per-formance for four example frames.Results.
Table 1 shows the systems?
overall F-scores and standard deviation across roles.
Table 2illustrates the differences in performance acrossroles on four frames: It lists all roles with ?
5 oc-currences for each frame.
PART_ORIENTATIONALshows very little variance, while the roles ofCHANGE_POSITION_ON_A_SCALE and especiallyTRAVEL differ widely.
For KINSHIP, the systemshows good performance for both roles, but the F-scores still differ by around 9 points.Discussion.
Table 1 shows that there is consider-able variance across roles, with a standard devia-tion in the range of 18% for the syntax-only model.We note that the deviation decreases to 13% for thecombined syntax-semantics model.
Table 2 con-firms that this is not purely between-frames, butalso within-frames variance.
This confirms the phe-nomenon described at the beginning of this section.670fr framefe role (frame element)fes(fr) roles of a framegfs(fr) gramm.
functions of a framegfsfr (fe) gramm.
functions realizing a role ina frameTable 3: Notation summary4 A meta-model for role assignment:ConfusabilityThe experiment of the previous section has shown aconsiderable variance in system performance acrossroles.
The aim of this section is to develop a meta-model which can explain this variance.The models we have explored in Exp.
1 relymainly on syntactic features: Even in the combinedsyntax-semantics model, 24 of the 31 features de-scribe syntactic structure.
This predominance ofsyntactic features can be observed in many currentmodels for semantic role assignment.
Accordingly,our meta-model focuses on the uniformity of themapping from syntactic structure to semantic roles.We formalize the variance in this mapping by theconfusability of a semantic role.
It implements thefollowing hypothesis:(1) The semantic role assignment systems we studyapproximate role assignment through gram-matical functions.
(2) System performance for a given role depends onthe role?s confusability: A role is highly con-fusable if the grammatical functions that in-stantiate it often also instantiate other roles.By using the ideal, manually assigned grammat-ical functions that are available from the FrameNetdata ?
and which are not passed on to the learner ?our meta-model abstracts over concrete feature sets.Our definition of confusability proceeds in twosteps.
First we model the informativity of a gram-matical function by the entropy of semantic rolesthat it maps to.
Then we compute the confusabil-ity of a role as a weighted average of the entropiesof the grammatical functions that realize it.Grammatical function entropy.
Viewing a gram-matical function as a random variable with semanticGrammatical function entropyGF DEG THM DEP LOC HMod 69 43 24 0 1.46Comp 18 491 12 41 0.72Ext 0 17 0 561 0.16Head 0 0 0 273 0.0Obj 0 0 0 3 0.0Role ConfusabilityRole Mod Comp Ext Head Obj ConfDEG 69 18 0 0 0 1.31THM 43 491 17 0 0 0.76DEP 24 12 0 0 0 1.22LOC 0 41 561 273 3 0.16Table 4: Grammatical function entropy and role con-fusability for the frame ABUNDANCEroles as values, we define the entropy of a grammat-ical function gf within the frame fr asHfr (gf ) =?fe?fes(fr)?p(fe|gf ) log p(fe|gf )where p(fe|gf ) = f(gf ,fe)f(gf ) is the conditional proba-bility of roles fe given gf (cf.
the notation in Table 3).Role confusability.
The confusability of a roleis the sum of its grammatical function entropies,weighted by the conditional probabilities p(gf |fe) =f(gf ,fe)f(fe) of grammatical functions gf given fe.cfr (fe) =?gf ?gfs(fr)p(gf |fe)Hfr (gf )An example.
Table 4 shows the grammatical func-tion entropies and role confusabilities for the frameABUNDANCE, both computed on the training data.The upper part of Table 4 lists the entropies ofthe grammatical functions Mod, Comp, Ext,Head and Obj3 and the counts f(gf, fe) of occur-rences of the grammatical functions together withthe roles DEGREE (DEG), THEME (THM), DEPIC-TIVE (DEP) and LOCATION (LOC).
The entropy ofMod, with similar numbers of occurrences for threedifferent roles, is relatively high, while Ext occursalmost exclusively for one role and has a much lowerentropy.
The lower part of Table 4 shows the confus-ability for the same set of roles.
The confusability of3See Fillmore and Petruck (2003) for a glossary ofFrameNet?s grammatical functions.671DEGREE is relatively high even though it is mostlyrealized by Mod because Mod has a high entropy, i.e.it indicates multiple roles; LOCATION on the otherhand is not very confusable even though it occursfrequently as both Ext and Head, since both gram-matical functions indicate this role.Related work.
Our approach is similar to Padoand Boleda (2004) in that they also use the unifor-mity of linking as an explanation for performancevariations in semantic role assignment.
However,their analysis is located at the frame level.
We ex-amine individual roles, which allows us to derive asimpler and more intuitive formalization of linkinguniformity.
Also, our model will ultimately lead usto a different conclusion: the uniformity of linkingis a good predictor of the performance of role as-signment systems, but only for exclusively syntacticmodels (see Section 5).5 Experiment 2: Relating confusabilityand system performanceIn this section, we test the validity of our meta-model.
We assess whether confusability, defined inSection 4, can explain the variance in role assign-ment that we have found in Section 3, by testing thecorrelation between the two variables.Experimental setup.
We use the same data set(Senseval-3) and the same two classifiers (memory-based and maximum entropy classification) as inExp.
1.
To cover a wider range of models and thusincrease the validity of our analysis, we split up theSyn feature set from Exp.
1 into the four smallersets described in the upper part of Table 5.
We usethese sets individually, combined, and together withthe lexical features in the Sem set.
This results in atotal of 20 different models (10 for each classifier),for which we computed role-specific F-scores.In parallel, we estimated the confusability as de-scribed in Section 4, with FrameNet?s manually as-signed grammatical functions as a basis, using onlythe training portion of our data.
We did not smooth,but omitted roles occurring less than 5 times toavoid sparse and thus unreliable data points.
Re-call that confusability does not vary with the featureset, since its central asset is to abstract over concretemodel parameters and feature sets.Feature set FMBL FMaxentPath0 70.9 71.3Path 73.3 72.6Pt 78.8 79.0Path/Pt 80.8 79.8Path/Sibling 76.7 76.6Pt/Sibling 78.8 79.1Syn 82.2 82.4Sem 80.3 80.7Syn/Sem 87.1 87.5Table 6: Exp.
2: Results for different feature setsResults.
The F-scores for the subdivided Syn fea-ture set are shown in the upper part of Table 6, withthe complete Syn and Sem sets and their combina-tion below.
There is a clear relationship betweenfeatures and F-score: additional features are consis-tently rewarded with higher performance.
Interest-ingly, phrase type information appears to be a betterrole predictor than path (compare models Path andPt).
Also, the semantic feature set alne (Sem) per-forms at over 80% F-Score, slightly better any of theindividual syntactic feature groups.The high F-score variance between individualroles which we have shown for the feature sets Synand Syn/Sem in Exp.
1 generalizes to the other fea-ture sets; all individual syntactic feature sets exhibita higher variance than Syn, and Sem shows a highervariance than the Syn/Sem combination.
This doesnot come as a surprise, since the two models ofExp.
1 use the two richest feature sets, and we wouldexpect less robust behavior for weaker models.
An-other point to note is that the performance of the twolearners is remarkably similar.The high variance in the F-scores is mirrored inthe confusability figures; we obtain an average con-fusability for our semantic roles of 1.79 with a highstandard deviation of 0.84.
A scatter plot of F-scoresagainst confusability figures (Fig.1) suggests a linearcorrelation analysis.Analysis 1: Correlating confusability and F-score.
Since the data does not appear to be nor-mally distributed, we apply Kendall?s nonparamet-ric rank test.
The results, which are listed in Table 7,show an extremely significant negative correlationbetween confusability and F-score: higher confus-672Path0 These are features centered around the path from the target lemma to the constituent: the pathitself, its length, partial path up to the lowest common ancestor, the grammatical rule thatexpands the target predicate?s parent, relative position of constituent to targetPath Feature set Path, plus target lemmaPt These are features related to phrase type and part of speech: the phrase type of the constituentand its parent, the POS of the constituent first word, last word and head as well as the POS ofan informative content word of the constituent (for PP and SBar constituents only: the head ofthe head?s complement), as well as the target lemmaSibling Phrase type and POS of the head of the left and right sibling constituent, and the Collins parser?sjudgment on the argumenthood of the constituentSyn This set combines Path, Sibling and Pt.
Additional features are: target voice; the constituent?spreposition; a feature combining path with target voice and target POS; and two rule-basedfeatures judging argumenthood and grammatical function of the constituentSem These are lexical features: Head words of the constituent and of its left and right siblings;leftmost and rightmost word of the constituent; informative content word lemma (see set Pt fordetails); and the governing verb of the target predicateTable 5: Feature groups used in the experimentsFigure 1: Scatter plot: F-score against confusability(Feature set Syn).ability appears to be related to lower F-score.However, note that the correlation is extremelysignificant even for the model which only uses se-mantic features.
This is unexpected at best andmakes a strong interpretation of this correlationdoubtful: it is rather likely that there is a third vari-able with which both F-score and confusability arecorrelated.
The most obvious candidate for such aconfounding variable is the size of the training set ?clearly, we expect our models to perform better withlarger training sets.
In order to get a more realisticMBL MaxEntFeature set z p z pPath0 -11.72 10?15 -11.76 10?15Path -12.29 10?15 -11.23 10?15Pt -10.64 10?15 -11.12 10?15Path/Pt -11.19 10?15 -10.45 10?15Path/Sibling -12.65 10?15 -11.76 10?15Pt/Sibling -10.58 10?15 -9.90 10?15Syn -9.47 10?15 -9.38 10?15Sem -6.90 10?11 -8.23 10?15Syn/Sem -8.30 10?15 -8.29 10?15Table 7: Exp.
2, Analysis 1: Correlation between F-Score and confusability.
z: Kendall?s tau coefficient,p: significance levelassessment of the relationship between confusabil-ity and F-score, we perform an additional analysisto disconfound confusability and frequency.Analysis 2: Disconfounding confusability andfrequency.
One way of factoring out the influ-ence of a confounding variable is to perform a par-tial correlation analysis, which explicitly removesthe effects of a third variable when determining thestrength of a correlation between two variables.
Likea normal correlation analysis, it yields a partial cor-relation coefficient.673MBL MaxEntFeatures rc rf rc rfPath0 -.29???
-.03 -.29???
-.03Path -.30???
-.02 -.27???
-.07?
?Pt -.19???
-.11??
-.21???
-.12?
?Path/Pt -.22???
-.07?
-.19???
-.16??
?Path/Sibl -.31???
+.01 -.28???
-.06?Pt/Sibl -.20???
-.10??
-.18???
-.16??
?Syn -.10?
-.17???
-.12?
-.19??
?Sem +.01 -.27???
-.02 -.24??
?Syn/Sem +.02 -.25???
-.01 -.25??
?Table 8: Exp.
2, Analysis 2: Partial correlationcoefficients.
rc: correlation between F-score andconfusability, controlling for training set size.
rf :correlation between F-score and training set size,controlling for confusability.
Significance levels:???
: p<0.001; ??
: p<0.01; ?
: p<0.05.We first compute partial correlation coefficientsbetween F-score and confusability, controlling fortraining set size.
The results, which indicate the?true?
relationship between performance and con-fusability, are shown in the rc columns of Table 8.For both learners, confusability is significantly cor-related with F-score for all syntactic feature sets, butnot for the semantic feature set and for the combinedset Syn/Sem.We also compute the partial correlation coeffi-cients between F-score and training set size, control-ling for confusability.
These figures are reported inthe rf columns of Table 8 and show the ?true?
rela-tionship between performance and training set size.There is no significant correlation between trainingset size and performance for simple syntax based-models, but the correlation is highly significant forcomplex syntactic models and all semantic models.Discussion.
The partial correlation analysis con-firms that confusability is a meta-model that can ex-plain the performance of a range of different modelsfor semantic role assignment, namely those modelswhich rely exclusively on syntactic features.
Sincewe used the gold standard features provided byFrameNet and did not introduce implementation- orfeature-specific knowledge, this points to a generallimitation of syntax-based models.
In contrast, se-mantic features behave completely differently; theircontribution is not limited by a role?s confusabil-ity.
At the very least, it cannot be captured byour current meta-model, but the absolute increase inperformance indicates that integrating semantics isthe way forward, which is surprising given that thepurely lexical features we use the present study areusually extremely sparse.The analysis of the partial correlation between F-score and training set size also allows interestingconclusions.
The correlation is not significant forsmall syntactic feature sets like Path, indicating thatmodels for such features can be learned satisfacto-rily from relatively small training sets (but which arealso limited in expressivity).
This is markedly dif-ferent for richer feature sets.
Arguably, these featuresets are sparser and can therefore profit more froman increased amount of training data.
Again, the ef-fect is most pronounced for the semantic feature set.6 ConclusionIn this paper, we have formulated a meta-model forsemantic role assignment.
We have used the confus-ability of roles to predict classification performanceindependently of the classification framework andfeature sets used.
We have defined role confusabilityin two steps: First, we have formalized the certaintywith which we can predict a semantic role from agiven grammatical function with grammatical func-tion entropy.
Then, we have defined the confusabil-ity of a role as a weighted sum of grammatical func-tion entropies.We have found that role confusability is highlysignificantly correlated with system performance formodels based solely on syntactic features.
We con-clude that syntactic features approximate a descrip-tion of grammatical functions, but that semantic fea-tures model a different aspect of the world.Much of current research in semantic role assign-ment is centered on the refinement of syntactic fea-tures.
Our study suggests that it may be worth-while to explore the refinement of semantic fea-tures as well.
The most obvious choice is to in-vestigate features related to selectional preferences.Possible features include goodness of fit relative topre-computed preferences (Baldewein et al, 2004),named entities (Pradhan et al, 2004), or broad on-tological classes like ?animate?
or ?artifact?.
Fol-674lowing up on this idea, a natural continuation of thepresent study would be to create a meta-model thatsubsumes semantic features.
Such a model coulduse optimal selectional restrictions as a predictor.The next step would then be to construct a combinedmeta-model that describes the behavior of systemswith both syntactic and semantic features.Another interesting research direction that ourstudy suggests is the combination of syntactic andsemantic models in co-training.
Co-training canbe sensibly applied only when conditional indepen-dence holds for the two target functions and the dis-tribution (Blum and Mitchell, 1998), i.e.
when ituses two independent views on the instance set.
Bypointing out a highly significant distinction betweensyntactic and semantic features with respect to roleconfusability, our study provides empirical evidencethat syntactic and semantic features model differentaspects of the role assignment mapping, and that co-training may be feasible by using syntactic and se-mantic features as views.Acknowledgments.
We are grateful to theDeutsche Forschungsgemeinschaft (DFG) forfunding the SALSA-II project (grant PI-154/9-2).ReferencesU.
Baldewein, K. Erk, S. Pado, D. Prescher.
2004.
Se-mantic role labelling with similarity-based generali-sation using em-based clustering.
In Proceedings ofSENSEVAL-3.A.
Blum, T. Mitchell.
1998.
Combining labeled and un-labeled data with co-training.
In COLT: Proceedingsof the Workshop on Computational Learning Theory,Morgan Kaufmann Publishers.H.
C. Boas.
2002.
Bilingual framenet dictionaries formachine translation.
In Proceedings of LREC 2002,1364?1371, Las Palmas, Canary Islands.L.
Burnard, 1995.
User?s guide for the British NationalCorpus.
British National Corpus Consortium, OxfordUniversity Computing Services, 1995.X.
Carreras, L. M?rquez.
2004.
Introduction to theCoNLL-2004 shared task: semantic role labeling.
InProceedings of CoNLL 2004, Boston, MA.X.
Carreras, L. M?rquez.
2005.
Introduction to theCoNLL-2005 shared task: semantic role labeling.
InProceedings of CoNLL 2005, Ann Arbor, MI.M.
J. Collins.
1996.
A new statistical parser based onbigram lexical dependencies.
In A. Joshi, M.
Palmer,eds., Proceedings of the Thirty-Fourth Annual Meetingof the Association for Computational Linguistics, 184?191, San Francisco.
Morgan Kaufmann Publishers.W.
Daelemans, J. Zavrel, K. van der Sloot, A. van denBosch.
2003.
Timbl: Tilburg memory basedlearner, version 5.0, reference guide.
Technical Re-port ILK 03-10, Tilburg University, 2003.
Availablefrom http://ilk.uvt.nl/downloads/pub/papers/ilk0310.ps.gz.C.
J. Fillmore, M. R. Petruck.
2003.
FrameNet glossary.International Journal of Lexicography, 16:359?361.C.
J. Fillmore, C. R. Johnson, M. R. Petruck.
2003.Background to FrameNet.
International Journal ofLexicography, 16:235?250.C.
J. Fillmore.
1985.
Frames and the semantics of under-standing.
Quaderni di Semantica, IV(2).M.
Fleischmann, E. Hovy.
2003.
A maximum en-tropy approach to framenet tagging.
In Proceedingsof HLT/NAACL 2003, Edmonton, Canada.D.
Gildea, D. Jurafsky.
2002.
Automatic labeling of se-mantic roles.
Computational Linguistics, 28(3):245?288.K.
Litkowski.
2004.
Senseval-3 task: Automatic label-ing of semantic roles.
In R. Mihalcea, P.
Edmonds,eds., Proceedings of Senseval-3: The Third Interna-tional Workshop on the Evaluation of Systems for theSemantic Analysis of Text, Barcelona, Spain.R.
Malouf.
2002.
A comparison of algorithms for maxi-mum entropy parameter estimation.
In Proceedings ofCoNLL 2002, Taipei, Taiwan.A.
Moschitti.
2004.
A study on convolution kernel forshallow semantic parsing.
In Proceedings of the ACL2004, Barcelona, Spain.S.
Narayanan, S. Harabagiu.
2004.
Question answeringbased on semantic structures.
In Proceedings of COL-ING 2004, Geneva, Switzerland.S.
Pado, G. Boleda Torrent.
2004.
The influence of ar-gument structure on semantic role assignment.
In Pro-ceedings of EMNLP 2004, Barcelona, Spain.S.
Pradhan, W. Ward, K. Hacioglu, J. H. Martin, D. Ju-rafsky.
2004.
Shallow semantic parsing using sup-port vector machines.
In Proceedings of HLT/NAACL2004, Boston, MA.H.
Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In Proceedings of NeMLaP 1994.M.
Surdeanu, S. Harabagiu, J. Williams, P. Aarseth.2003.
Using predicate-argument structures for infor-mation extraction.
In Proceedings of ACL 2003, Sap-poro, Japan.N.
Xue, M. Palmer.
2004.
Calibrating features for se-mantic role labeling.
In Proceedings of EMNLP 2004,Barcelona, Spain.675
