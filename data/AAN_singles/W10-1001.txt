Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 1?9,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsReadability Assessment for Text SimplificationSandra Aluisio1, Lucia Specia2, Caroline Gasperin1 and Carolina Scarton11Center of Computational Linguistics (NILC) 2Research Group in Computational LinguisticsUniversity of S?o Paulo University of WolverhamptonS?o Carlos - SP, Brazil Wolverhampton, UK{sandra,cgasperin}@icmc.usp.br,carol.scarton@gmail.comL.Specia@wlv.ac.ukAbstractWe describe a readability assessment ap-proach to support the process of text simplifi-cation for poor literacy readers.
Given an in-put text, the goal is to predict its readabilitylevel, which corresponds to the literacy levelthat is expected from the target reader: rudi-mentary, basic or advanced.
We complementfeatures traditionally used for readability as-sessment with a number of new features, andexperiment with alternative ways to modelthis problem using machine learning methods,namely classification, regression and ranking.The best resulting model is embedded in anauthoring tool for Text Simplification.1 IntroductionIn Brazil, the National Indicator of Functional Lite-racy (INAF) index has been computed annuallysince 2001 to measure the levels of literacy of theBrazilian population.
The 2009 report presented aworrying scenario: 7% of the individuals are illite-rate; 21% are literate at the rudimentary level; 47%are literate at the basic level; only 25% are literateat the advanced level (INAF, 2009).
These literacylevels are defined as:(1) Illiterate: individuals who cannot performsimple tasks such as reading words and phrases;(2) Rudimentary: individuals who can find ex-plicit information in short and familiar texts (suchas an advertisement or a short letter);(3) Basic: individuals who are functionally lite-rate, i.e., they can read and understand texts of av-erage length, and find information even when it isnecessary to make some inference; and(4) Advanced: fully literate individuals, who canread longer texts, relating their parts, comparingand interpreting information, distinguish fact fromopinion, make inferences and synthesize.In order to promote digital inclusion and acces-sibility for people with low levels of literacy, par-ticularly to documents available on the web, it isimportant to provide text in a simple and easy-to-read way.
This is a requirement of the Web Con-tent Accessibility Guidelines 2.0?s principle ofcomprehensibility and accessibility of Web con-tent1.
It states that for texts which demand readingskills more advanced than that of individuals withlower secondary education, one should offer an al-ternative version of the same content suitable forthose individuals.
While readability formulas forEnglish have a long history ?
200 formulas havebeen reported from 1920 to 1980s (Dubay, 2004) ?the only tool available for Portuguese is an adapta-tion of the Flesch Reading Ease index.
It evaluatesthe complexity of texts in a 4-level scale corres-ponding to grade levels (Martins et al, 1996).In the PorSimples project (Alu?sio et al, 2008)we develop text adaptation methods (via text sim-plification and elaboration approaches) to improvethe comprehensibility of texts published on gov-ernment websites or by renowned news agencies,which are expected to be relevant to a large au-dience with various literacy levels.
The projectprovides automatic simplification tools to aid (1)poorly literate readers to understand online content?
a browser plug-in for automatically simplifyingwebsites ?
and (2) authors producing texts for thisaudience ?
an authoring tool for guiding the crea-tion of simplified versions of texts.This paper focuses on a readability assessmentapproach to assist the simplification process in theauthoring tool, SIMPLIFICA.
The current versionof SIMPLIFICA offers simplification operationsaddressing a number of lexical and syntactic phe-nomena to make the text more readable.
The au-1 http://www.w3.org/TR/WCAG20/1thor has the freedom to choose when and whetherto apply the available simplification operations, adecision based on the level of complexity of thecurrent text and on the target reader.A method for automatically identifying suchlevel of complexity is therefore of great value.With our readability assessment tool, the author isable to automatically check the complexi-ty/readability level of the original text, as well asmodified versions of such text produced as he/sheapplies simplification operations offered bySIMPLIFICA, until the text reaches the expectedlevel, adequate for the target reader.In this paper we present such readability as-sessment tool, developed as part of the PorSimplesproject, and discuss its application within the au-thoring tool.
Different from previous work, the tooldoes not model text difficulty according to lineargrade levels (e.g., Heilman et al, 2008), but in-stead maps the text into the three levels of literacydefined by INAF: rudimentary, basic or advanced.Moreover, it uses a more comprehensive set of fea-tures, different learning techniques and targets anew language and application, as we discuss inSection 4.
More specifically, we address the fol-lowing research questions:1.
Given some training material, is it possible todetect the complexity level of Portuguese texts,which corresponds to the different literacy levelsdefined by INAF?2.
What is the best way to model this problemand which features are relevant?We experiment with nominal, ordinal and interval-based modeling techniques and exploit a numberof the cognitively motivated features proposed byCoh-Metrix 2.0 (Graesser et al, 2004) and adaptedto Portuguese (called Coh-Metrix-PORT), alongwith a set of new features, including syntactic fea-tures to capture simplification operations and n-gram language model features.In the remainder of this paper, we first providesome background information on the need for areadability assessment tool within our text simpli-fication system (Section 2) and discuss prior workon readability assessment (Section 3), to thenpresent our features and modeling techniques (Sec-tion 4) and the experiments performed to answerour research questions (Section 5).2.
Text Simplification in PorSimplesText Simplification (TS) aims to maximize readingcomprehension of written texts through their sim-plification.
Simplification usually involves substi-tuting complex by simpler words and breakingdown and changing the syntax of complex, longsentences (Max, 2006; Siddharthan, 2003).To meet the needs of people with different le-vels of literacy, in the PorSimples project we pro-pose two types of simplification: natural andstrong.
The first type results in texts adequate forpeople with a basic literacy level and the second,rudimentary level.
The difference between thesetwo is the degree of application of simplificationoperations to complex sentences.
In strong simpli-fication, operations are applied to all complex syn-tactic phenomena present in the text in order tomake it as simple as possible, while in natural sim-plification these operations are applied selectively,only when the resulting text remains ?natural?.One example of original text (a), along with itsnatural (b) and strong (c) manual simplifications, isgiven in Table 1.
(a) The cinema theaters around the world were show-ing a production by director Joe Dante in which ashoal of piranhas escaped from a military laborato-ry and attacked participants of an aquatic show.(...)
More than 20 people were bitten by palometas(Serrasalmus spilopleura, a species of piranhas)that live in the waters of the Sanchuri dam.
(b) The cinema theaters around the world were show-ing a production by director Joe Dante.
In the pro-duction a shoal of piranhas escaped from a militarylaboratory and attacked participants of an aquaticshow.
(?)
More than 20 people were bitten by pa-lometas that live in the waters of the Sanchuri dam.Palometas are Serrasalmus spilopleura, a speciesof piranhas.
(c) The cinema theaters around the world were show-ing a movie by director Joe Dante.
In the movie ashoal of piranhas escaped from a military laborato-ry.
The shoal of piranhas attacked participants ofan aquatic show.
(...).
Palometas have bitten morethan 20 people.
Palometas live in the waters of theSanchuri dam.
Palometas are Serrasalmus spilop-leura, a species of piranhas.Table 1: Example of original and simplified textsThe association between these two types of simpli-fication and the literacy levels was identified bymeans of a corpus study.
We have manually built acorpus of simplified texts at both natural and2strong levels and analyzed their linguistic struc-tures according to the description of the two litera-cy levels.
We verified that strong simplified sen-tences are more adequate for rudimentary levelreaders, and natural ones for basic level readers.This claim is supported by several studies whichrelate capabilities and performance of the workingmemory with reading levels (Siddharthan, 2003;McNamara et al, 2002).2.1 The Rule-based Simplification SystemThe association between simplification operationsand the syntactic phenomena they address is im-plemented within a rule-based syntactic simplifica-tion system (Candido Jr. et al, 2009).
This systemis able to identify complex syntactic phenomena ina sentence and perform the appropriate operationsto simplify each phenomenon.The simplification rules follow a manual forsyntactic simplification in Portuguese also devel-oped in PorSimples.
They cover syntactic con-structions such as apposition, relative clauses,coordination and subordination, which had alreadybeen addressed by previous work on text simplifi-cation (Siddharthan, 2003).
Additionally, they ad-dress the transformation of sentences from passiveinto active voice, normalization of sentences intothe Subject-Verb-Object order, and simplificationof adverbial phrases.
The simplification operationsavailable are: sentence splitting, changing particu-lar discourse markers by simpler ones, transform-ing passive into active voice, inverting the order ofclauses, converting to subject-verb-object order,relocating long adverbial phrases.2.2 The SIMPLIFICA ToolThe rule-based simplification system is part ofSIMPLIFICA, an authoring tool for writers toadapt original texts into simplified texts.
WithinSIMPLIFICA, the author plays an active role ingenerating natural or strong simplified texts by ac-cepting or rejecting the simplifications offered bythe system on a sentence basis and post-editingthem if necessary.Despite the ability to make such choices at thesentence level, it is not straightforward for the au-thor to judge the complexity level of the text aswhole in order to decide whether it is ready for acertain audience.
This is the main motivation forthe development of a readability assessment tool.The readability assessment tool automaticallydetects the level of complexity of a text at anymoment of the authoring process, and thereforeguides the author towards producing the adequatesimplification level according to the type of reader.It classifies a text in one of three levels: rudimenta-ry, basic or advanced.Figure 1 shows the interface of SIMPLIFICA,where the complexity level of the current text asgiven by the readability assessment tool is shownat the bottom, in red (in this case, ?N?vel Pleno?,which corresponds to advanced).
To update thereadability assessment of a text the author canchoose ?N?vel de Inteligibilidade?
(readability lev-el) at any moment.The text shown in Figure 1 is composed of 13sentences, 218 words.
The lexical simplificationmodule (not shown in the Figure 1) finds 10 candi-date words for simplification in this text, and thesyntactic simplification module selects 10 sen-tences to be simplified (highlighted in gray).When the author selects a highlighted sentence,he/she is presented with all possible simplificationsproposed by the rule-based system for this sen-tence.
Figure 2 shows the options for the first sen-tence in Figure 1.
The first two options cover non-finite clause and adverbial adjuncts, respectively,while the third option covers both phenomena inone single step.
The original sentence is also givenas an option.It is possible that certain suggestions of auto-matic simplifications result in ungrammatical orinadequate sentences (mainly due to parsing er-rors).
The author can choose not to use such sug-gestions as well as manually edit the original orautomatically simplified versions.
The impact ofthe author?s choice on the overall readability levelof the text is not always clear to the author.
Thegoal of the readability assessment function is toprovide such information.Simplified texts are usually longer than theoriginal ones, due to sentence  splittings andrepetition of information to connect suchsentences.
We  acknowledge  that  low literacyreaders prefer short texts, but in this tool theshortening of the text is a responsibility of theauthor.
Our focus is on the linguistic structure ofthe texts; the length of the text actually is a featureconsidered by our readability assessment system.3Figure 1: SIMPLIFICA interfaceFigure 2.
Simplification options available for the first sentence of the text presented in Figure 13.
Readability AssessmentRecent work on readability assessment for theEnglish language focus on: (i) the feature set usedto capture the various aspects of readability, toevaluate the contribution of lexical, syntactic, se-mantic and discursive features; (ii) the audience ofthe texts the readability measurement is intendedto; (iii) the genre effects on the calculation of textdifficult; (iv) the type of learning techniquewhich is more appropriate: those producing nomi-nal, ordinal or interval scales of measurement, and(v) providing an application for the automatic as-sessment of reading difficulty.Pitler and Nenkova (2008) propose a unifiedframework composed of vocabulary, syntactic,elements of lexical cohesion, entity coherence anddiscourse relations to measure text quality, whichresembles the composition of rubrics in the area ofessay scoring (Burstein et al, 2003).The following studies address readability as-sessment for specific audiences: learners of Eng-lish as second language (Schwarm and Ostendorf,2005; Heilman et al, 2007), people with intellec-tual disabilities (Feng et al, 2009), and people withcognitive impairment caused by Alzheimer (Roarkat al, 2007).Sheehan et al (2007) focus on models forliterary and expository texts, given that traditionalmetrics like Flesch-Kincaid Level score tend tooverpredict the difficulty of literary texts andunderpredict the difficulty of expository texts.Heilman et al (2008) investigate an appropriatescale of measurement for reading difficulty ?nominal, ordinal, or interval ?
by comparing theeffectiveness of statistical models for each type ofdata.
Petersen and Ostendorf (2009) useclassification and regression techniques to predict areadability score.Miltsakali and Troutt (2007; 2008) propose anautomatic tool to evaluate reading difficulty ofWeb texts in real time, addressing teenagers andadults with low literacy levels.
Using machinelearning, Gl?ckner et al (2006) present a tool forautomatically rating the readability of Germantexts using several linguistic information sourcesand a global readability score similar to the FleschReading Ease.44.
A Tool for Readability AssessmentIn this section we present our approach to readabil-ity assessment.
It differs from previous work inthe following aspects: (i) it uses a feature set withcognitively-motivated metrics and a number of ad-ditional features to provide a better explanation ofthe complexity of a text; (ii) it targets a new audi-ence: people with different literacy levels; (iii) itinvestigates different statistical models for non-linear data scales: the levels of literacy defined byINAF, (iv) it focus on a new application: the use ofreadability assessment for text simplification sys-tems; and (v) it is aimed at Portuguese.4.1 Features for Assessing ReadabilityOur feature set (Table 2) consists of 3 groups offeatures.
The first group contains cognitively-motivated features (features 1-42), derived fromthe Coh-Metrix-PORT tool (see Section 4.1.1).The second group contains features that reflect theincidence of particular syntactic constructionswhich we target in our text simplification system(features 43-49).
The third group (the remainingfeatures in Table 2) contains features derived fromn-gram language models built considering uni-grams, bigrams and trigrams probability and per-plexity plus out-of-vocabulary rate scores.
We laterrefer to a set of basic features, which consist ofsimple counts that do not require any linguistic toolor external resources to be computed.
This set cor-responds to features 1-3 and 9-11.4.1.1 Coh-Metrix-PortThe Coh-Metrix tool was developed to computefeatures potentially relevant to the comprehensionof English texts through a number of measures in-formed by linguistics, psychology and cognitivestudies.
The main aspects covered by the measuresare cohesion and coherence (Graesser et al, 2004).Coh-Metrix 2.0, the free version of the tool, con-tains 60 readability metrics.
The Coh-Metrix-PORT tool (Scarton et al, 2009) computes similarmetrics for texts in Brazilian Portuguese.
The ma-jor challenge to create such tool is the lack of someof the necessary linguistic resources.
The follow-ing metrics are currently available in the tool (werefer to Table 2 for details):1.
Readability metric: feature 12.2.
Words and textual information:Basic counts: features 1 to 11.1 Number of words2 Number of sentences3 Number of paragraphs4 Number of verbs5 Number of nouns6 Number of adjectives7 Number of adverbs8 Number of pronouns9 Average number of words per sentence10 Average number of sentences per paragraph11 Average number of syllables per word12 Flesch index for Portuguese13 Incidence of content words14 Incidence of functional words15 Raw Frequency of content words16 Minimal frequency of content words17 Average number of verb hypernyms18 Incidence of NPs19 Number of NP modifiers20 Number of words before the main verb21 Number of high level constituents22 Number of personal pronouns23 Type-token ratio24 Pronoun-NP ratio25 Number of ?e?
(and)26 Number of ?ou?
(or)27 Number of ?se?
(if)28 Number of negations29 Number of logic operators30 Number of connectives31 Number of positive additive connectives32 Number of negative additive connectives33 Number of positive temporal connectives34 Number of negative temporal connectives35 Number of positive causal connectives36 Number of negative causal connectives37 Number of positive logic connectives38 Number of negative logic connectives39 Verb ambiguity ratio40 Noun ambiguity ratio41 Adverb ambiguity ratio42 Adjective ambiguity ratio43 Incidence of clauses44 Incidence of adverbial phrases45 Incidence of apposition46 Incidence of passive voice47 Incidence of relative clauses48 Incidence of coordination49 Incidence of subordination50 Out-of-vocabulary words51 LM probability of unigrams52 LM perplexity of unigrams53 LM perplexity of unigrams, without line break54 LM probability of bigrams55 LM perplexity of bigrams56 LM perplexity of bigrams, without line break57 LM probability of trigrams58 LM perplexity of trigrams59 LM perplexity of trigrams, without line breakTable 2.
Feature set5Frequencies: features 15 to 16.Hypernymy: feature 17.3.
Syntactic information:Constituents: features 18 to 20.Pronouns: feature 22Types and Tokens: features 23 to 24.Connectives: features 30 to 38.4.
Logical operators: features 25 to 29.The following resources for Portuguese were used:the MXPOST POS tagger (Ratnaparkhi, 1996), aword frequency list compiled from a 700 million-token corpus2, a tool to identify reduced nounphrases (Oliveira et al, 2006), a list of connectivesclassified as positives/negatives and according tocohesion type (causal, temporal, additive or logi-cal), a list of logical operators and WordNet.Br(Dias-da-Silva et al, 2008).In this paper we include seven new metrics toCoh-Metrix-PORT: features 13, 14, 21, and 39 to42.
We used TEP3 (Dias-da-Silva et al, 2003) toobtain the number of senses of words (and thustheir ambiguity level), and the Palavras parser(Bick, 2000) to identify the higher level constitu-ents.
The remaining metrics were computed basedon the POS tags.According to a report on the performance ofeach Coh-Metrix-PORT metric (Scarton et al,2009), no individual feature provides sufficient in-dication to measure text complexity, and thereforethe need to exploit their combination, and also tocombine them with the other types of features de-scribed in this section.4.1.2 Language-model FeaturesLanguage model features were derived from alarge corpus composed of a sample of the Braziliannewspaper Folha de S?o Paulo containing issuesfrom 12 months taken at random from 1994 to2005.
The corpus contains 96,868 texts and26,425,483 tokens.
SRILM (Stolcke, 2002), astandard language modelling toolkit, was used toproduce the language model features.4.2 Learning TechniquesGiven that the boundaries of literacy level classesare one of the subjects of our study, we exploitthree different types of models in order to check2 http://www2.lael.pucsp.br/corpora/bp/index.htm3 http://www.nilc.icmc.usp.br/tep2/index.htmwhich of them can better distinguish among thethree literacy levels.
We therefore experiment withthree types of machine learning algorithms: a stan-dard classifier, an ordinal (ranking) classifier and aregressor.
Each algorithm assumes different rela-tions among the groups: the classifier assumes norelation, the ordinal classifier assumes that thegroups are ordered, and the regressor assumes thatthe groups are continuous.As classifier we use the Support Vector Ma-chines (SVM) implementation in the Weka4 toolkit(SMO).
As ordinal classifier we use a meta clas-sifier in Weka which takes SMO as the base classi-fication algorithm and performs pairwise classifi-cations (OrdinalClassClassifier).
For regression weuse the SVM regression implementation in Weka(SMO-reg).
We use the linear versions of the algo-rithms for classification, ordinal classification andregression, and also experiment with a radial basisfunction (RBF) kernel for regression.5.
Experiments5.1 CorporaIn order to train (and test) the different machinelearning algorithms to automatically identify thereadability level of the texts we make use of ma-nually simplified corpora created in the PorSimplesproject.
Seven corpora covering our three literacylevels (advanced, basic and rudimentary) and twodifferent genres were compiled.
The first corpus iscomposed of general news articles from the Brazil-ian newspaper Zero Hora (ZH original).
These ar-ticles were manually simplified by a linguist, ex-pert in text simplification, according to the twolevels of simplification: natural (ZH natural) andstrong (ZH strong).
The remaining corpora arecomposed of popular science articles from differ-ent sources: (a) the Caderno Ci?ncia section of theBrazilian newspaper Folha de S?o Paulo, a main-stream newspaper in Brazil (CC original) and amanually simplified version of this corpus usingthe natural (CC natural) and strong (CC strong)levels; and (b) advanced level texts from a popularscience magazine called Ci?ncia Hoje (CH).
Table3 shows a few statistics about these seven corpora.5.2 Feature AnalysisAs a simple way to check the contribution of dif-ferent features to our three literacy levels, we com-4 http://www.cs.waikato.ac.nz/ml/weka/6Corpus Doc Sent Words Avg.
wordsper text (std.deviation)Avg.words p.sentenceZH original 104 2184 46190 444.1 (133.7) 21.1ZH natural 104 3234 47296 454.7 (134.2) 14.6ZH strong 104 3668 47938 460.9 (137.5) 13.0CC original 50 882 20263 405.2 (175.6) 22.9CC natural 50 975 19603 392.0 (176.0) 20.1CC strong 50 1454 20518 410.3 (169.6) 14.1CH 130 3624 95866 737.4 (226.1) 26.4Table 3.
Corpus statisticsputed the (absolute) Pearson correlation betweenour features and the expected literacy level for thetwo sets of corpora that contain versions of thethree classes of interest (original, natural andstrong).
Table 4 lists the most highly correlatedfeatures.Feature Corr.1 Words per sentence 0.6932 Incidence of apposition 0.6883 Incidence of clauses 0.6144 Flesch index  0.5805 Words before main verb  0.5166 Sentences per paragraph  0.5097 Incidence of relative clauses  0.4178 Syllables per word 0.4149 Number of positive additive connectives  0.39710 Number of negative causal connectives 0.388Table 4: Correlation between features and literacy levelsAmong the top features are mostly basic and syn-tactic features representing the number of apposi-tive and relative clauses and clauses in general, andalso features from Coh-Metrix-PORT.
This showsthat traditional cognitively-motivated features canbe complemented with more superficial featuresfor readability assessment.5.3 Predicting Complexity LevelsAs previously discussed, the goal is to predict thecomplexity level of a text as original, naturally orstrongly simplified, which correspond to the threeliteracy levels of INAF: rudimentary, basic and ad-vanced level.Tables 5-7 show the results of our experimentsusing 10-fold cross-validation and standard classi-fication (Table 5), ordinal classification (Table 6)and regression (Table 7), in terms of F-measure(F), Pearson correlation with true score (Corr.)
andmean absolute error (MAE).
Results using ourcomplete feature set (All) and different subsets ofit are shown so that we can analyze theperformance of each group of features.
We alsoexperiment with the Flesch index on its own as afeature.Features Class F Corr.
MAEAll original 0.913 0.84 0.276natural 0.483strong 0.732LanguageModeloriginal 0.669 0.25 0.381natural 0.025strong 0.221Basic original 0.846 0.76 0.302natural 0.149strong 0.707Syntactic original 0.891 0.82 0.285natural 0.32strong 0.74Coh-Metrix-PORToriginal 0.873 0.79 0.290natural 0.381strong 0.712Flesch original 0.751 0.52 0.348natural 0.152strong 0.546Table 5: Standard ClassificationFeatures Class F Corr.
MAEAll original 0.904 0.83 0.163natural 0.484strong 0.731LanguageModeloriginal 0.634 0.49 0.344natural 0.497strong 0.05Basic original 0.83 0.73 0.231natural 0.334strong 0.637Syntactic original 0.891 0.81 0.180natural 0.382strong 0.714Coh-Metrix-PORToriginal 0.878 0.8 0.183natural 0.432strong 0.709Flesch original 0.746 0.56 0.310natural 0.489strong 0Table 6: Ordinal classificationThe results of the standard and ordinal classifica-tion are comparable in terms of F-measure and cor-relation, but the mean absolute error is lower forthe ordinal classification.
This indicates that ordi-nal classification is more adequate to handle ourclasses, similarly to the results found in (Heilmanet al, 2008).
Results also show that distinguishingbetween natural and strong simplifications is aharder problem than distinguishing between theseand original texts.
This was expected, since thesetwo levels of simplification share many features.However, the average performance achieved isconsidered satisfactory.Concerning the regression model (Table 7), theRBF kernel reaches the best correlation scores7among all models.
However, its mean error ratesare above the ones found for classification.
A lin-ear SVM (not shown here) achieves very poor re-sults across all metrics.Features Corr.
MAEAll 0.8502 0.3478Language Model 0.6245 0.5448Basic 0.7266 0.4538Syntactic 0.8063 0.3878Coh-Metrix-PORT 0.8051 0.3895Flesch 0.5772 0.5492Table 7: Regression with RBF kernelWith respect to the different feature sets, we canobserve that the combination of all features consis-tently yields better results according to all metricsacross all our models.
The performances obtainedwith the subsets of features vary considerably frommodel to model, which shows that the combinationof features is more robust across different learningtechniques.
Considering each feature set independ-ently, the syntactic features, followed by Coh-Metrix-PORT, achieve the best correlation scores,while the language model features performed thepoorest.These results show that it is possible to predictwith satisfactory accuracy the readability level oftexts according to our three classes of interest:original, naturally simplified and strongly simpli-fied texts.
Given such results we embedded theclassification model (Table 5) as a tool for read-ability assessment into our text simplification au-thoring system.
The linear classification is oursimplest model, has achieved the highest F-measure and its correlation scores are comparableto those of the other models.6.
ConclusionsWe have experimented with different machinelearning algorithms and features in order to verifywhether it was possible to automatically distin-guish among the three readability levels: originaltexts aimed at advanced readers, naturally simpli-fied texts aimed at people with basic literacy level,and strongly simplified texts aimed at people withrudimentary literacy level.
All algorithms achievedsatisfactory performance with the combination ofall features and we embedded the simplest modelinto our authoring tool.As future work, we plan to investigate the con-tribution of deeper cognitive features to this prob-lem, more specifically, semantic, co-reference andmental model dimensions metrics.
Having this ca-pacity for readability assessment is useful not onlyto inform authors preparing simplified materialabout the complexity of the current material, butalso to guide automatic simplification systems toproduce simplifications with the adequate level ofcomplexity according to the target user.The authoring tool, as well as its text simplifica-tion and readability assessment systems, can beused not only for improving text accessibility, butalso for educational purposes: the author can pre-pare texts that are adequate according to the levelof the reader and it will also allow them to improvetheir reading skills.ReferencesSandra M. Alu?sio, Lucia Specia, Thiago A. S. Pardo,Erick G. Maziero, Renata P. M. Fortes (2008).
To-wards Brazilian Portuguese Automatic Text Simpli-fication Systems.
In the Proceedings of the 8th ACMSymposium on Document Engineering, pp.
240-248.Eckhard Bick (2000).
The Parsing System "Palavras":Automatic Grammatical Analysis of Portuguese in aConstraint Grammar Framework.
PhD Thesis.
Uni-versity of ?rhus, Denmark.Jill Burstein, Martin Chodorow and Claudia Leacock(2003).
CriterionSM Online Essay Evaluation: AnApplication for Automated Evaluation of StudentEssays.
In the Proceedings of the Fifteenth AnnualConference on Innovative Applications of ArtificialIntelligence, Acapulco, Mexico.Arnaldo Candido Jr., Erick Maziero, Caroline Gasperin,Thiago A. S. Pardo, Lucia Specia, and Sandra M.Aluisio (2009).
Supporting the Adaptation of Textsfor Poor Literacy Readers: a Text SimplificationEditor for Brazilian Portuguese.
In NAACL-HLTWorkshop on Innovative Use of NLP for BuildingEducational Applications, pages 34?42, Boulder?.Helena de M. Caseli, Tiago de F. Pereira, L?cia Specia,Thiago A. S. Pardo, Caroline Gasperin and SandraMaria Alu?sio (2009).
Building a Brazilian Portu-guese Parallel Corpus of Original and SimplifiedTexts.
In the Proceedings of CICLing.Max Coltheart (1981).
The MRC psycholinguistic data-base.
In Quartely Jounal of Experimental Psycholo-gy, 33A, pages 497-505.Scott Deerwester, Susan T. Dumais, George W. Furnas,Thomas K. Landauer e Richard Harshman (1990).Indexing By Latent Semantic Analysis.
In Journal ofthe American Society For Information Science, V.41, pages 391-407.Bento C. Dias-da-Silva and Helio R. Moraes (2003).
Aconstru?
?o de um thesaurus eletr?nico para o portu-gu?s do Brasil.
In ALFA- Revista de Ling?
?stica, V.847, N. 2, pages 101-115.Bento C Dias-da-Silva, Ariani Di Felippo and Maria dasGra?as V. Nunes (2008).
The automatic mapping ofPrinceton WordNet lexical conceptual relations ontothe Brazilian Portuguese WordNet database.
In Pro-ceedings of the 6th LREC, Marrakech, Morocco.William H. DuBay (2004).
The principles of readability.Costa Mesa, CA: Impact Information: http://www.impact-information.com/impactinfo/readability02.pdfChristiane Fellbaum (1998).
WordNet: An electroniclexical database.
Cambridge, MA: MIT Press.Lijun Feng, No?mie Elhadad and Matt Huenerfauth(2009).
Cognitively Motivated Features for Reada-bility Assessment.
In the Proceedings of EACL2009, pages 229-237.Ingo Gl?ckner, Sven Hartrumpf, Hermann Helbig, Jo-hannes Leveling and Rainer Osswald (2006b).
Anarchitecture for rating and controlling text readabili-ty.
In Proceedings of KONVENS 2006, pages 32-35.Konstanz, Germany.Arthur C. Graesser, Danielle S. McNamara, Max M.Louwerse and Zhiqiang Cai (2004).
Coh-Metrix:Analysis of text on cohesion and language.
In Beha-vioral Research Methods, Instruments, and Comput-ers, V. 36, pages 193-202.Ronald K. Hambleton, H. Swaminathan and H. JaneRogers (1991).
Fundamentals of item responsetheory.
Newbury Park, CA: Sage Press.Michael Heilman, Kevyn Collins-Thompson, JamieCallan and Max Eskenazi (2007).
Combining lexicaland grammatical features to improve readabilitymeasures for first and second language texts.
In theProceedings of NAACL HLT 2007, pages 460-467.Michael Heilman, Kevyn Collins-Thompson and Max-ine Eskenazi (2008).
An Analysis of StatisticalModels and Features for Reading Difficulty Predic-tion.
In Proceedings of the 3rd Workshop on Innova-tive Use of NLP for Building Educational Applica-tions, pages 71-79.INAF (2009).
Instituto P. Montenegro and A?
?o Educa-tiva.
INAF Brasil - Indicador de Alfabetismo Funcio-nal - 2009.
Available online at http://www.
ibope.com.br/ipm/relatorios/relatorio_inaf_2009.pdfTeresa B. F. Martins, Claudete M. Ghiraldelo, Mariadas Gra?as V. Nunes e Osvaldo N. de Oliveira Jr.(1996).
Readability formulas applied to textbooks inbrazilian portuguese.
ICMC Technical Report, N.28, 11p.Aur?lien Max (2006).
Writing for Language-impairedReaders.
In Proceedings of CICLing, pages 567-570.Danielle McNamara, Max Louwerse, and Art Graesser,2002.
Coh-Metrix: Automated cohesion and coher-ence scores to predict text readability and facilitatecomprehension.
Grant proposal.
http://cohmetrix.memphis.edu/cohmetrixpr/publications.htmlEleni Miltsakaki and Audrey Troutt (2007).
Read-X:Automatic Evaluation of Reading Difficulty of WebText.
In the Proceedings of E-Learn 2007, Quebec,Canada.Eleni Miltsakaki and Audrey Troutt (2008).
Real TimeWeb Text Classification and Analysis of ReadingDifficulty.
In the Proceedings of the 3rd Workshopon Innovative Use of NLP for Building EducationalApplications, Columbus, OH.Cl?udia Oliveira, Maria C. Freitas, Violeta Quental, C?-cero N. dos Santos, Renato P. L. and Lucas Souza(2006).
A Set of NP-extraction rules for Portuguese:defining and learning.
In 7th Workshop on Computa-tional Processing of Written and Spoken Portuguese,Itatiaia, Brazil.Sarah E. Petersen and Mari Ostendorf (2009).
A ma-chine learning approach to reading level assess-ment.
Computer Speech and Language 23, 89-106.Emily Pitler and Ani Nenkova (2008).
Revisiting reada-bility: A unified framework for predicting text quali-ty.
In Proceedings of EMNLP, 2008.Adwait Ratnaparkhi (1996).
A Maximum Entropy Part-of-Speech Tagger.
In Proceedings of the First Em-pirical Methods in Natural Language ProcessingConference, pages133-142.Brian Roark, Margaret Mitchell and Kristy Holling-shead (2007).
Syntactic complexity measures for de-tecting mild cognitive impairment.
In the Proceed-ings of the Workshop on BioNLP 2007: Biological,Translational, and Clinical Language Processing,Prague, Czech Republic.Caroline E. Scarton, Daniel M. Almeida, Sandra M. A-lu?sio (2009).
An?lise da Inteligibilidade de textosvia ferramentas de Processamento de L?ngua Natu-ral: adaptando as m?tricas do Coh-Metrix para oPortugu?s.
In Proceedings of STIL-2009, S?o Carlos,Brazil.Sarah E. Schwarm and Mari Ostendorf (2005).
ReadingLevel Assessment Using Support Vector Machinesand Statistical Language Models.
In the Proceedingsof the 43rd Annual Meeting of the ACL, pp 523?530.Kathleen M. Sheehan, Irene Kostin and Yoko Futagi(2007).
Reading Level Assessment for Literary andExpository Texts.
In D. S. McNamara and J. G.Trafton (Eds.
), Proceedings of the 29th Annual Cog-nitive Science Society, page 1853.
Austin, TX: Cog-nitive Science Society.Advaith Siddharthan (2003).
Syntactic Simplificationand Text Cohesion.
PhD Thesis.
University of Cam-bridge.Andreas Stolcke.
SRILM -- an extensible languagemodeling toolkit.
In Proceedings of the InternationalConference on Spoken Language Processing, 2002.9
