Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 193?200Manchester, August 2008Re-estimation of Lexical Parameters for Treebank PCFGsTejaswini DeoskarDepartment of LinguisticsCornell Universitytd72@cornell.eduAbstractWe present procedures which pool lexicalinformation estimated from unlabeled datavia the Inside-Outside algorithm, with lex-ical information from a treebank PCFG.The procedures produce substantial im-provements (up to 31.6% error reduction)on the task of determining subcategoriza-tion frames of novel verbs, relative to asmoothed Penn Treebank-trained PCFG.Even with relatively small quantities ofunlabeled training data, the re-estimatedmodels show promising improvements inlabeled bracketing f-scores on Wall StreetJournal parsing, and substantial benefitin acquiring the subcategorization prefer-ences of low-frequency verbs.1 IntroductionIn order to obtain the meaning of a sentence au-tomatically, it is necessary to have access to itssyntactic analysis at some level of complexity.Many NLP applications like translation, question-answering, etc.
might benefit from the avail-ability of syntactic parses.
Probabilistic parserstrained over labeled data have high accuracy on in-domain data: lexicalized parsers get an f-score ofup to 90.0% on Wall Street Journal data (Charniakand Johnson (2005)?s re-ranking parser), while re-cently, unlexicalized PCFGs have also been shownto perform much better than previously believed(Klein and Manning, 2003).
However, the limitedsize of annotated training data results in many pa-rameters of a PCFG being badly estimated whenc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.trained on annotated data.
The Zipfian nature ofa text corpus results in PCFG parameters relatedto the properties of specific words being espe-cially badly estimated.
For instance, about 38% ofverbs in the training sections of the Penn Treebank(PTB) (Marcus et al, 1993) occur only once ?
thelexical properties of these verbs (such as their mostcommon subcategorization frames ) cannot be rep-resented accurately in a model trained exclusivelyon the Penn Treebank.The research reported here addresses this issue.We start with an unlexicalized PCFG trained onthe PTB.
We then re-estimate the parameters ofthis PCFG from raw text using an unsupervisedestimation method based on the Inside-Outside al-gorithm (Lari and Young, 1990), an instance ofthe Expectation Maximization algorithm (Demp-ster et al, 1977) for PCFG induction.
The re-estimation improves f-score on the standard testsection of the PTB significantly.
Our focus is onlearning lexical parameters i.e.
those parametersrelated to the lexico-syntactic properties of open-class words.
Examples of such properties are: sub-categorization frames of verbs and nouns, attach-ment preference of adverbs to sentential, verbal ornominal nodes, attachment preference of PPs to averbal or nominal node, etc.The current research is related to semi-supervised training paradigms like self-training ?these methods are currently being explored to im-prove the performance of existing PCFG modelsby utilizing unlabeled data.
For example, Mc-Closkey et al (2006) achieve a 1.1% improvementin labeled bracketing f-score by the use of un-labeled data to self-train the parser-reranker sys-tem from Charniak and Johnson (2005).
Ear-lier research on inside-outside estimation of PCFGmodels has reported some positive results as well193(Pereira and Schabes, 1992; Carroll and Rooth,1998; Beil et al, 1999; imWalde, 2002).
Insome of these cases, an initial model is derivedby other means ?
inside-outside is used to re-estimate the initial model.
However, many ques-tions still remain open about its efficacy for PCFGre-estimation.
Grammars used previously havenot been treebank grammars (for e.g., Carroll andRooth (1998) and Beil et al (1999) used hand-crafted grammars), hence these models could notbe evaluated according to standardized evaluationsin the parsing literature.
In the current work, weuse a Penn Treebank based grammar; hence all re-estimated grammars can be evaluated using stan-dardized criteria.The rest of the paper is organized as follows:First, we describe in brief the construction of anunlexicalized PCFG from the PTB.
We then de-scribe a procedure based on the inside-outside al-gorithm to re-estimate the lexical parameters ofthis PCFG from unlabeled Wall Street Journaldata.
Finally, we present evaluations of the re-estimated models, based on labeled bracketingmeasures and on the detection of subcategorizationframes of verbs: there is a 31.6% reduction in er-ror for novel verbs and up to 8.97% reduction inoverall subcategorization error.2 Unlexicalized treebank PCFGWe build an unlexicalized PCFG from the stan-dard training sections of the PTB.
As is common(Collins, 1997; Johnson, 1998; Klein and Man-ning, 2003; Schmid, 2006), the treebank is firsttransformed in various ways, in order to give an ac-curate PCFG.
In our framework, treebank trees areaugmented with extra features; the methodologyinvolves constructing a feature-constraint grammarfrom a context-free treebank backbone grammar.The detailed methodology is described in Deoskarand Rooth (2008)1.
A PCFG is trained on thetransformed treebank, with these added featuresincorporated into the PCFG?s non-terminal cate-gories.
The framework affords us the flexibilityto stipulate the features to be incorporated in thePCFG categories, as parameters of the PCFG.Our features are largely designed to have alinguistically relevant interpretation2 .
For exam-1The reason for using this framework (as opposed to usingavailable unlexicalized PCFGs) is that it allows us flexibilityin designing features of interest, and can also be used for lan-guages other than English with existing treebanks.2In addition we also have some features that do not have athis paper Schmid K&MRecall 86.5 86.3 85.1Precision 86.7 86.9 86.3F-score 86.6 86.6 85.7Table 1: Labeled bracketing scores, PTB sec.
23.ple, there is a feature on verbs which denotes thesubcategorization frame of the verb (with valueslike intransitive, transitive, etc.).
Similarly, thereare features which denote the type of clause (fi-nite, infinite, small clause, etc.
), the subject typeof clausal nodes, the attachment of adverbs, va-lence of nouns, etc.
Unlike most existing treebankPCFGs, all PTB function tags are retained, as areall empty categories.As a measure of the quality of the transformed-PTB based PCFG, Table 1 gives the labeled brack-eting scores on the standard test section 23 ofthe PTB, comparing them to unlexicalized PCFGscores in (Schmid, 2006) and (Klein and Man-ning, 2003) (K&M).
The current PCFG f-score iscomparable to the state-of-the-art in unlexicalizedPCFGs ((Schmid, 2006), to our knowledge).
Westopped grammar development when the f-scorereached state-of-the-art since our goal was to usethis grammar as the initial model and baselinefor the unsupervised re-estimation procedure, de-scribed in the next section.3 Inside-Outside Re-estimationAs a basic unsupervised estimation method, weuse standard inside-outside estimation of PCFGs,which realizes EM estimation (Lari and Young,1990; Pereira and Schabes, 1992).
We use thenotation I(C, e) to designate the new frequencymodel, computed via inside-outside from the cor-pus C by using a probability model based on thefrequency model e3.
The iterative inside-outsidere-estimation procedure has the following sim-ple form (Eq.1), where each successive frequencymodel ei+1is estimated from the corpus C using aprobability model determined by the previous fre-quency model ei.
Our notation always refers to fre-linguistic interpretation, but result in a good PCFG, such as aparent feature on some categories, following Johnson (1998).3The inside-outside algorithm uses an existing grammarmodel and a raw text corpus (incomplete data) to obtain cor-responding complete data (a set of analyses/parses for the cor-pus sentences).
A new grammar model is then estimated fromthis complete data.
See (Prescher, 2003) for an explanationusing the standard EM notions of incomplete/complete data.194quency models such as ei, rather than the relative-frequency probability models they determine4.e1= I(C, e0)...ei+1= I(C, ei)(1)3.1 Interleaved Inside-OutsideIt is well-known that while lexicalization is use-ful, lexical parameters determined from the tree-bank are poorly estimated because of the sparse-ness of treebank data for particular words (e.g.Hindle and Rooth (1993)).
Gildea (2001) andBikel (2004) show that removing bilexical de-pendencies hardly hurts the performance of theCollins Model2 parser, although there is the ben-efit of lexicalization in the form of lexico-syntacticdependencies ?
structures being conditioned onwords.
On the other hand, structural parametersare comparatively well-estimated from treebankssince they are not keyed to particular words.
Thus,it might be beneficial to use a combination of su-pervised and unsupervised estimation for lexicalparameters, while obtaining syntactic (structural)parameters solely by supervised estimation (i.e.from a treebank).
The experiments in this paperare based on this idea.
In an unlexicalised PCFGlike the one described in ?2, it is easy to makethe distinction between structural parameters (non-terminal rules) and lexical parameters (preterminalto terminal rules).To this end, we define a modified inside-outsideprocedure in which a frequency transformationT (c, t) is interleaved between the iterations of thestandard inside-outside procedure.
The form ofthis interleaved procedure is shown in Eq.
2.
InEq.
2, t designates a smoothed treebank model (thesmoothing procedure is described later in ?3.1.1).This smoothed treebank model is used as the priormodel for the inside-outside re-estimation proce-dure.
For each iteration i, cirepresent models ob-tained by inside-outside estimation.
direpresentderived models obtained by performing a transfor-mation T on ci.
The transformation T combinesthe re-estimated model ciand the smoothed tree-4We use a frequency-based notation because we use out-of-the-box software Bitpar (Schmid, 2004) which implementsinside-outside estimation ?
Bitpar reads in frequency modelsand converts them to relative frequency models.
We justifythe use of the frequency-based notation by ensuring that allmarginal frequencies in the treebank model are always pre-served in all other models.bank model t (hence represented as T (ci, t)).d0= t smoothed treebank modelc1= I(C, d0) estimation stepd1= T (c1, t) transformation step...ci+1= I(C, di) estimation stepdi+1= T (ci+1, t) transformation step(2)The lexical parameters for the treebank model tor the re-estimated models ciare represented ast(w, ?, ?)
or ci(w, ?, ?
), where w is the terminalword, ?
is the PTB-style PoS tag, and ?
is thesequence of additional features incorporated intothe PoS tag (the entries in our lexicon have theform w.?.?
with an associated frequency).
Thetransformation T preserves the marginal frequen-cies seen in the treebank model.
A marginal tag-incorporation frequency is defined by summation:f(?, ?)
=?wf(w, ?, ?).
(3)The transformation T is used to obtain the derivedmodels diand consists of two parts, correspondingto the syntactic and the lexical parameters of di:?
The syntactic parameters of diare copiedfrom t.?
To obtain the lexical parameters of di, lex-ical parameters from the treebank model tand lexical parameters from the re-estimatedmodel are linearly combined, shown in Eq.
4.di(w, ?, ?)
= (1?
??,?
)t(w, ?, ?)
+ ?
?,?c?i(w, ?, ?
)(4)where ?
?,?is a parameter with 0 < ?
?,?< 1 whichmay depend on the tag and incorporation.
Theterm c?i(w, ?, ?)
in Eq.
4 is obtained by scaling thefrequencies in ci(w, ?, ?
), as shown in Eq.
5.c?i(w, ?, ?)
=t(?, ?
)ci(?, ?
)ci(w, ?, ?).
(5)In terms of probability models determined fromthe frequency models, the effect of T is to allocatea fixed proportion of the probability mass for each?, ?
to the corpus, and share it out among words win proportion to relative frequencies ci(w,?,?)ci(?,?
)in theinside-outside estimate ci.
Eqs.
6 and 7 verify thatmarginals are preserved in the derived model d.c?
(?, ?)
=?wc?
(w, ?, ?)
=?wt(?,?)c(?,?
)c(w, ?, ?)=t(?,?)c(?,?
)?wc(w, ?, ?)=t(?,?
)c(?,i)c(?, ?)
= t(?, ?).
(6)195d(?, ?)
=?wd(w, ?, ?)=?w(1?
??,?
)t(w, ?, ?)
+ ??,?c?
(w, ?, ?
)= (1?
??,?
)?wt(w, ?, ?
)+ ??,??wc?
(w, ?, ?
)= (1?
??,?
)t(?, ?)
+ ??,?c?
(?, ?
)= (1?
??,?
)t(?, ?)
+ ?
?,?t(?, ?
)= t(?, ?).
(7)3.1.1 Smoothing the treebank modelTo initialize the iterative procedures, a smooth-ing scheme is required which allocates frequencyto combinations of words w and PoS tags ?
whichare not present in the treebank model but arepresent in the corpus, and also to all possible in-corporations of a PoS tag.
Otherwise, if the un-smoothed treebank model (t0) has zero frequencyfor some lexical parameter, the inside-outside es-timate I(C, t0) for that parameter would also bezero, and new lexical entries would never be in-duced.The smoothed treebank model t is obtained fromthe unsmoothed model t0as follows.
First a PoStagger (Treetagger, (Schmid, 1994)) is run on theunsupervised corpus C , which assigns PTB-stylePoS tags to the corpus.
Tokens of words andPoS tags are tabulated to obtain a frequency tableg(w, ?).
Each frequency g(w, ?)
is split amongpossible incorporations ?
in proportion to a ratio ofmarginal frequencies in t0:g(w, ?, ?)
=t0(?, ?)t0(?
)g(w, ?)
(8)The smoothed model t is defined as an interpola-tion of g and t0for lexical parameters as shown in9, with syntactic parameters copied from t0.t(w, ?, ?)
= (1?
??,?
)t0(w, ?, ?)
+ ?
?,?g(w, ?, ?
)(9)3.2 Experimental setupThe treebank grammar is trained over sections 0-22 of the transformed PTB (minus about 7000 sen-tences held out for testing).
Testset I contains 1331sentences and is constructed as follows: First, weselect 117 verbs whose frequency in PTB sections0-22 is between 10-20 (mid-frequency verbs).
Allsentences containing occurrences of these verbsare held out from the training data to form Test-set I.
The effect of holding out these sentences isto make these 117 verbs novel (i.e.
unseen in train-ing).
This testset is used to evaluate the learning ofsubcategorization frames of novel verbs.
We alsoconstruct another testset (Testset II) by holding outevery 10th sentence in PTB sections 0-22 (4310sentences).The corpus used for re-estimation is about 4 mil-lion words of unannotated Wall Street Journal text(year 1997) (sentence length<25 words).
The re-estimation was carried out using Bitpar (Schmid,2004) for inside-outside estimation.
The parame-ter ?
in Eq.
4 was set to 0.5 for all ?
and ?, givingequal weight to the treebank and the re-estimatedlexicons.
Starting from a smoothed treebank gram-mar t, we separately ran 6 iterations of the inter-leaved estimation procedure defined in Eq.
2, and4 iterations of standard inside-outside estimation.This gave us two series of models correspondingto the two procedures.4 Labeled Bracketing ResultsAs a basic evaluation of the re-estimated gram-mars, we report the labeled bracketing scores onthe standard test section 23 of the PTB (Table 2).Using the re-estimated models, maximum proba-bility (viterbi) parses were obtained for all sen-tences in sec.
23, after stripping away the treebankannotation, including the pre-terminal tag.
Thebaseline is the treebank model t0t5.
The scoresfor re-estimated grammars from successive itera-tions are under columns It 1, It 2, etc.
All modelsobtained using the interleaved procedure show animprovement over the baseline.
The best modelis obtained after 2 iterations, after which the scorereduces a little.
Statistically significant improve-ments are marked with *, with p<0.005 for recalland p<0.0001 for precision for the best model.
Ta-ble 2 also shows scores for grammars estimatedusing the standard inside-outside procedure.
Thefirst re-estimated model is better than any modelobtained from either procedure.
Notice however,the disparity in precision and recall ?
precisionis much lower than recall.
This is not surpris-ing; inside-outside is known to converge to incor-rect solutions for PCFGs (Lari and Young, 1990;de Marcken, 1995).
This causes the f-score to de-teriorate in successive iterations.5This baseline is slightly lower than that reported in Ta-ble 1 due to holding out an additional 7000 sentences fromthe treebank training set.
In order to accommodate unknownwords from the test data (sec 23), the treebank model t0issmoothed in a manner similar to that shown in Eq.
9, withthe test words (tagged using Treetagger) forming g(w, ? )
and?
= 0.1.
A testset is always merged with a given model inthis manner before parsing, to account for unknown words.196t0tIt 1 It 2 It 3 It 4 It 5 It 6Interleaved Recall 86.48 86.72 *86.79 *86.79 *86.78 86.81 86.72Procedure Precision 86.61 86.95 *87.07 *87.06 *87.07 87.04 87.01f-score 86.55 86.83 *86.93 *86.92 *86.92 86.92 86.86Standard Recall 86.48 87.95 87.11 86.42 85.55Procedure Precision 86.61 85.99 84.79 83.37 82.06f-score 86.5 86.96 85.93 84.87 83.77Table 2: Labeled Bracketing scores for various models, on PTB section 23.The improvement in labeled bracketing f-scorefor the interleaved procedure is small, but is an en-couraging result.
The benefit to the re-estimatedmodels comes only from better estimates of lex-ical parameters.
We expect that re-estimationwill benefit parameters associated with low fre-quency words - lexical parameters for high fre-quency words are bound to be estimated accuratelyfrom the treebank.
We did not expect a large im-pact on labeled bracketing scores, given that lowfrequency words have correspondingly few occur-rences in this test dataset.
It is possible that the im-pact on f-score will be higher for a test set from adifferent domain.
Note also that the size of our un-labeled training corpus (?4M words) is relativelysmall ?
only about 4 times the PTB.5 Verbal SubcategorizationWe focus on learning verbal subcategorization, asa typical case of lexico-syntactic information.
Thesubcategorization frame (SF) of verbs is a parame-ter of our PCFG - verbal tags in the PCFG are fol-lowed by an incorporation sequence that denotesthe SF for that verb.
We evaluate the re-estimatedmodels on the task of detecting correct SFs of verbsin maximum-probability (viterbi) parses obtainedusing the models.
All tokens of verbs and theirpreterminal symbols (consisting of a PoS tag andan incorporation sequence encoding the SF) are ex-tracted from the viterbi parses of sentences in atestset.
This tag-SF sequence is compared to a goldstandard, and is scored correct if the two match ex-actly.
PoS errors are scored as incorrect, even if theSF is correct.
The gold standard is obtained fromthe transformed PTB trees.The incorporation sequence corresponding tothe SF consists of 3 features: The first one denotesbasic categories of subcategorization such as tran-sitive, intransitive, ditransitive, NP-PP, S, etc.
Thesecond feature denotes, for clausal complements,the type of clause (finite, infinite, small clause,Figure 1: A subcat.
frame for control verb want.etc.).
The third feature encodes the nature of thesubject of the clausal complements (empty cate-gory or non-empty).
For example, the verb con-sidered in the treebank sentence They are officiallyconsidered strategic gets a preterminal sequence ofVBD.s.e.sc.
This sequence indicates a past tenseverb (VBD) with a clausal complement (s) whichhas an empty subject (e) since the sentence is pas-sive and is of the type small clause (sc).
A controlverb (with an infinitival complement) in the sen-tence fragment ..did not want to fund X.. gets theframe s.e.to (see Fig.
1 for an example of a verbwith its complement, as parsed by our PCFG).
Wehave a total of 81 categories of SFs (without count-ing specific prepositions for prepositional frames),making fairly fine-grained distinctions of verbalcategories.5.1 Learning Subcat Frames of Novel VerbsWe measure the error rate in the detection of thesubcategorization frame of 1360 tokens of 117verbs in Testset I.
Recall from ?3.2 that theseverbs are novel verbs with respect to the treebankmodel.
Table 3 shows this error rate (i.e.
thefraction of test items which receive incorrect tag-incorporations in viterbi parses) for various mod-els obtained using the interleaved and standard re-estimation procedures.
t0t1is the treebank modelt0with the test data from Testset I merged in (to197Iteration i Interleaved StandardProcedure Proceduret0t133.36 33.361 *24.40 28.692 *23.45 25.563 *23.05 27.864 *22.89 28.415 *22.81 -6 *22.83 -Table 3: Subcat.
error for novel verbs (Testset I).account for unknown words) using the smoothingscheme given in Eq.
9.
This model has no verbspecific information for the test verbs.
For eachtest verb, it has a smoothed SF distribution pro-portional to the SF distribution for all verbs of thattag.
The baseline error is 33.36%.
This means thatthere is enough information in the average distri-bution of all verbs to correctly assign the subcat-egorization frame to novel verbs in 66.64% cases.For the models obtained using the interleaved re-estimation, the error rate falls to the lowest valueof 22.81% for the model obtained in the 5th iter-ation: an absolute reduction of 10.55 points, anda percentage error-reduction of 31.6%.
The er-ror reduction is statistically significant for all it-erations compared to the baseline, with the 5th it-eration being also significantly better than the 1st.The models obtained using standard re-estimationdo not perform as well.
Even for the model fromthe first iteration, whose labeled bracketing scorewas highest, the SF error is higher than the cor-responding model from the interleaved procedure(possibly due to the low precision of this model).The error rate for the standard procedure starts toincrease after the 2nd iteration in contrast to the in-terleaved procedure.5.2 Analysis of subcategorization learningWhile the re-estimation clearly results in gains inSF detection for novel verbs, we also perform anevaluation for all verbs (novel and non-novel) in agiven testset (Testset II as described in ?3.2).
Theoverall error reduction using the interleaved proce-dure is 8.97% (in Iteration 1).
In order to better un-derstand the relative efficacy of the supervised andunsupervised estimation for lexical items of differ-ent frequencies, we break up the set of test verbsinto subsets based on their frequency of occurrencein the PTB training data, and evaluate them sepa-TB Freq t0t2It 1 Abs.Reduc %Reducall 18.5 16.84 1.66 *8.970 41.26 33.01 8.25 *19.991 32.69 24.52 8.17 *24.992 36.55 22.76 13.79 *37.733 26.59 19.08 7.51 *28.244 22.38 20.28 2.1 9.385 24.63 19.40 5.23 *21.236-10 22.24 19.59 2.65 **11.9211-20 21.54 18.02 3.52 *16.3421-50 19.41 19.11 0.3 1.5551-100 19.44 19.09 0.35 1.80101-200 18.71 18.57 0.14 0.75201-500 23.06 22.31 0.75 3.25501-1K 18.07 16.82 1.25 6.921K-2K 12.38 12.25 0.13 1.052K-5K 9.42 7.62 1.8 *19.11>5K 10.54 10.13 0.41 3.89Table 4: Subcat.
error breakup (Testset II)rately.
Table 4 shows the error rates for verbs di-vided into these sets.
We present error rates onlyfor Iteration 1 in Table 4, since most of the errorreduction takes place with the 1st iteration.
Sta-tistically significant reductions are marked with *(confidence>99.9) and ** (>95).
The second rowshows error rates for verbs which have zero fre-quency in the treebank training data (i.e.
novelverbs): Note that this error reduction is much lessthan the 31.6% in Testset I.
These verbs are trulyrare and hence have much fewer occurrences inthe unlabeled corpus than Testset I verbs, whichwere artificially made novel (but are really mid-frequency verbs).
This might indicate that errorrates will decrease further if the size of the unla-beled corpus is increased.
There is substantial er-ror reduction for low-frequency verbs (<21 PTBoccurrences).
This is not hard to understand: thePTB does not provide enough data to have goodparameter estimates for these verbs.
For mid-to-high frequency verbs (from 21 to 500), the benefitof the unsupervised procedure reduces, though er-ror reduction is still positive.
Surprisingly, the er-ror reduction for very high frequency verbs (morethan 500 occurrences in the treebank) is also fairlyhigh: we expected that parameters for high fre-quency words would benefit the least from the un-supervised estimation, given that they are alreadycommon enough in the PTB to be accurately esti-mated from it.
The high frequency verbs (>500198occurrences) consist of very few types?
mainlyauxiliaries, some light verbs (make, do) and a fewothers (rose, say).
It is possible that re-estimationfrom large data is beneficial for light verbs sincethey have a larger number of frames.
The fre-quency range 2K-5K consists solely of auxiliaryverbs.
Examination of viterbi parses shows thatimproved results are largely due to better detectionof predicative frames in re-estimated models.To measure the impact of more unlabeled train-ing data, we ran the interleaved procedure with 8Mwords of WSJ text.
The SF error for novel verbs re-duces to 22.06% in the 2nd iteration (significantlydifferent from the best error of 22.81% in the 5thiteration for 4M words of training data)).
We alsoget an improved overall error reduction of 9.9% onTestset II for the larger training data, as comparedto 8.97% previously.5.3 Previous WorkWhile there has been substantial previous workon the task of SF acquisition from corpora (Brent(1991); Manning (1993); Briscoe and Carroll(1997); Korhonen (2002), amongst others), we findthat relatively few parsing-based evaluations arereported.
Since their goal is to build probabilisticSF dictionaries, these systems are evaluated eitheragainst existing dictionaries, or on distributionalsimilarity measures.
Most are evaluated on testsetsof high-frequency verbs (unlike the present work),in order to gauge the effectiveness of the acquisi-tion strategy.
Briscoe and Carroll (1997) report atoken-based evaluation for seven verb types?
theirsystem gets an average recall accuracy of 80.9%for these verbs (which appear to be high-frequencyverbs).
This is slightly lower than the present sys-tem, which has an overall accuracy of 83.16% (onTestset II (It 1), as shown in Table 4).
However,for low frequency verbs (exemplars <10) they re-port that their results are around chance.
A parsingevaluation of their lexicon using an unlexicalizedgrammar as baseline, on 250 sentences from theSuzanne treebank gave a small (but not statisticallysignificant) improvement in f-score (from 71.49 to72.14%).
Korhonen (2002) reports a parsing-basedevaluation on 500 test sentences.
She found asmall increase in f-score (of grammatical relationsmarkup) from 76.03 to 76.76.
In general PARSE-VAL measures are not very sensitive to subcatego-rization (Carroll et al, 1998); they therefore usea dependency-based evaluation.
In the present re-search as well, we obtain statistically significantbut quite small improvements in f-score (?4).
Sincewe are interested in acquisition of PCFG lexicons,we focus our evaluations on verbal subcategoriza-tion of token occurrences of verbs in viterbi parses.6 ConclusionsWe have presented a methodology for incorporat-ing additional lexical information from unlabeleddata into an unlexicalized treebank PCFG.
We ob-tain a large error reduction (31.6%) in SF detectionfor novel verbs as compared to a treebank base-line.
The interleaved re-estimation scheme givesa significant increase in labeled bracketing scoresfrom a relatively small unlabeled corpus.
The in-terleaved scheme has an advantage over standardinside-outside PCFG estimation, as measured bothby labeled bracketing scores and on the task of de-tecting SFs of novel verbs.
Since our re-estimatedmodels are treebank models, all evaluations areagainst treebank standards.The grammar we worked with has very few in-corporated features compared to the grammar usedby, say Klein and Manning (2003).
It would makesense to experiment with grammars with muchricher sets of incorporated features.
Features re-lated to structure-selection by categories other thanverbs ?
nouns, adverbs and adjectives ?
might bebeneficial.
These features should be incorporatedas PCFG parameters, similar to verbal subcate-gorization.
Experiments with 8 million words oftraining data gave significantly better results thanwith 4 million words, indicating that larger train-ing sets will be beneficial as well.
It would also beuseful to make the transformation T of lexical pa-rameters sensitive to treebank frequency of words.For instance, more weight should be given to thetreebank model rather than the corpus model formid-to-high frequency words, by making the pa-rameter ?
in T sensitive to frequency.This methodology is relevant to the task ofdomain-adaption.
Hara et al (2007) find that re-training a model of HPSG lexical entry assign-ments is more critical for domain adaptation thanre-training a structural model alone.
Our PCFGcaptures many of the important dependencies cap-tured in a framework like HPSG; in addition, wecan use unlabeled data from a new domain in anunsupervised fashion for re-estimating lexical pa-rameters, an important consideration in domain-adaption.
Preliminary experiments on this task us-199ing New York Times unlabeled data with the PTB-trained PCFG show promising results.AcknowledgmentsI am grateful to Mats Rooth for extensive com-ments and guidance during the course of this re-search.
The inside-outside re-estimation was con-ducted using the resources of the Cornell Univer-sity Center for Advanced Computing.ReferencesF.
Beil, G. Carroll, D. Prescher, S. Riezler, andM.
Rooth.
1999.
Inside-outside estimation ofa lexicalized PCFG for German.
In Proceedingsof the 37th meeting of ACL.Dan Bikel.
2004.
Intricacies of Collins?
Parser.Computational Linguistics, 30(4):479?511.M.
Brent.
1991.
Automatic acquisition of subcat-egorization frames from untagged text.
In Pro-ceedings of the 29th meeting of ACL.Ted Briscoe and John Carroll.
1997.
AutomaticExtraction of Subcategorization from Corpora.In Proceedings of the 5th ACL Conference onApplied NLP.G.
Carroll and M. Rooth.
1998.
Valence inductionwith a head-lexicalized PCFG.
In Proceedingsof EMNLP 1998.J.
Carroll, G. Minnen, and E. Briscoe.
1998.
Cansubcategorization probabilities help parsing.
InProceedings of 6th ACL/SIGDAT Workshop onVery Large Corpora.Eugene Charniak and Mark Johnson.
2005.Coarse-to-fine n-best parsing and MaxEnt dis-criminative reranking.
In Proceedings of 43rdmeeting of ACL.Michael Collins.
1997.
Three generative, lexi-calised models for statistical parsing.
In Pro-ceedings of the 35th meeting of ACL.Carl de Marcken.
1995.
On the unsupervised in-duction of Phrase Structure grammars.
In 3rdWorkshop on Very Large Corpora.A.
P. Dempster, N. M. Laird, and D. B. Rubin.1977.
Maximum likelihood estimation from in-complete data via the EM algorithm.
J. RoyalStatistical Society, 39(B):1?38.Tejaswini Deoskar and Mats Rooth.
2008.
Induc-tion of Treebank-Aligned Lexical Resources.
InProceedings of 6th LREC.Daniel Gildea.
2001.
Corpus Variation and ParserPerformance.
In Proceedings of EMNLP 2001.T.
Hara, Y. Miyao, and J. Tsujii.
2007.
Evalu-ating Impact of Re-training a Lexical Disam-biguation Model on Domain Adaptation of anHPSG Parser.
In Proceedings of the 10th Inter-national Conference on Parsing Technologies.Donald Hindle and Mats Rooth.
1993.
Structuralambiguity and lexical relations.
ComputationalLinguistics, 18(2):103?120.Sabine Schulte imWalde.
2002.
A Subcategori-sation Lexicon for German Verbs induced froma Lexicalised PCFG.
In Proceedings of LREC2002.Mark Johnson.
1998.
PCFG models of linguistictree representations.
Computational Linguistics,24(4).D.
Klein and C. Manning.
2003.
Accurate unlexi-calized parsing.
In Proceedings of the 41st ACL.Anna Korhonen.
2002.
Subcategorization Acqui-sition.
Ph.D. thesis, Univ.
of Cambridge.K.
Lari and S. J.
Young.
1990.
The estimationof stochastic context-free grammars using theInside-Outside algorithm.
Computer Speechand Language, 4:35?56.C.
Manning.
1993.
Automatic acquisition of alarge subcategorization dictionary from corpora.In Proceedings of the 31st meeting of ACL.M.
P. Marcus, B. Santorini, and M. A.Marcinkiewicz.
1993.
Building a Large Anno-tated Corpus of English: The Penn Treebank.Computational Linguistics, 19(2):313?330.D.
McCloskey, E. Charniak, and M. Johnson.2006.
Effective Self-Training for Parsing.
InProceedings of HLT-NAACL 2006.Pereira and Schabes.
1992.
Inside-Outside re-estimation from partially bracketed corpora.
InProceedings of the 30th meeting of ACL.Detlef Prescher.
2003.
A Tutorial on theExpectation-Maximization Algorithm Includ-ing Maximum-Likelihood Estimation and EMTraining of Probabilistic Context-Free Gram-mars.
ESSLLI 2003.Helmut Schmid.
1994.
Probabilistic Part-of-Speech Tagging Using Decision Trees.
In Pro-ceedings of International Conference on NewMethods in Language Processing.Helmut Schmid.
2004.
Efficient Parsing of HighlyAmbiguous Context-Free Grammars with BitVectors.
In Proceedings of the 20th COLING.Helmut Schmid.
2006.
Trace Prediction and Re-covery with Unlexicalised PCFGs and SlashFeatures.
In Proceedings of the 21st Conferenceon Computational Linguistics (COLING).200
