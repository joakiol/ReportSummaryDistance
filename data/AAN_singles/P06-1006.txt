Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 41?48,Sydney, July 2006. c?2006 Association for Computational LinguisticsKernel-Based Pronoun Resolution with Structured Syntactic KnowledgeXiaofeng Yang?
Jian Su?
Chew Lim Tan?
?Institute for Infocomm Research21 Heng Mui Keng Terrace,Singapore, 119613{xiaofengy,sujian}@i2r.a-star.edu.sg?
Department of Computer ScienceNational University of Singapore,Singapore, 117543tancl@comp.nus.edu.sgAbstractSyntactic knowledge is important for pro-noun resolution.
Traditionally, the syntac-tic information for pronoun resolution isrepresented in terms of features that haveto be selected and defined heuristically.In the paper, we propose a kernel-basedmethod that can automatically mine thesyntactic information from the parse treesfor pronoun resolution.
Specifically, weutilize the parse trees directly as a struc-tured feature and apply kernel functions tothis feature, as well as other normal fea-tures, to learn the resolution classifier.
Inthis way, our approach avoids the effortsof decoding the parse trees into the set offlat syntactic features.
The experimentalresults show that our approach can bringsignificant performance improvement andis reliably effective for the pronoun reso-lution task.1 IntroductionPronoun resolution is the task of finding the cor-rect antecedent for a given pronominal anaphorin a document.
Prior studies have suggested thatsyntactic knowledge plays an important role inpronoun resolution.
For a practical pronoun res-olution system, the syntactic knowledge usuallycomes from the parse trees of the text.
The is-sue that arises is how to effectively incorporate thesyntactic information embedded in the parse treesto help resolution.
One common solution seen inprevious work is to define a set of features that rep-resent particular syntactic knowledge, such as thegrammatical role of the antecedent candidates, thegoverning relations between the candidate and thepronoun, and so on.
These features are calculatedby mining the parse trees, and then could be usedfor resolution by using manually designed rules(Lappin and Leass, 1994; Kennedy and Boguraev,1996; Mitkov, 1998), or using machine-learningmethods (Aone and Bennett, 1995; Yang et al,2004; Luo and Zitouni, 2005).However, such a solution has its limitation.
Thesyntactic features have to be selected and definedmanually, usually by linguistic intuition.
Unfor-tunately, what kinds of syntactic information areeffective for pronoun resolution still remains anopen question in this research community.
Theheuristically selected feature set may be insuffi-cient to represent all the information necessary forpronoun resolution contained in the parse trees.In this paper we will explore how to utilize thesyntactic parse trees to help learning-based pro-noun resolution.
Specifically, we directly utilizethe parse trees as a structured feature, and then usea kernel-based method to automatically mine theknowledge embedded in the parse trees.
The struc-tured syntactic feature, together with other nor-mal features, is incorporated in a trainable modelbased on Support Vector Machine (SVM) (Vapnik,1995) to learn the decision classifier for resolution.Indeed, using kernel methods to mine structuralknowledge has shown success in some NLP ap-plications like parsing (Collins and Duffy, 2002;Moschitti, 2004) and relation extraction (Zelenkoet al, 2003; Zhao and Grishman, 2005).
However,to our knowledge, the application of such a tech-nique to the pronoun resolution task still remainsunexplored.Compared with previous work, our approachhas several advantages: (1) The approach uti-lizes the parse trees as a structured feature, whichavoids the efforts of decoding the parse trees intoa set of syntactic features in a heuristic manner.
(2) The approach is able to put together the struc-tured feature and the normal flat features in atrainable model, which allows different types of41information to be considered in combination forboth learning and resolution.
(3) The approachis applicable for practical pronoun resolution asthe syntactic information can be automatically ob-tained from machine-generated parse trees.
Andour study shows that the approach works well un-der the commonly available parsers.We evaluate our approach on the ACE data set.The experimental results over the different do-mains indicate that the structured syntactic fea-ture incorporated with kernels can significantlyimprove the resolution performance (by 5%?8%in the success rates), and is reliably effective forthe pronoun resolution task.The remainder of the paper is organized as fol-lows.
Section 2 gives some related work that uti-lizes the structured syntactic knowledge to do pro-noun resolution.
Section 3 introduces the frame-work for the pronoun resolution, as well as thebaseline feature space and the SVM classifier.Section 4 presents in detail the structured featureand the kernel functions to incorporate such a fea-ture in the resolution.
Section 5 shows the exper-imental results and has some discussion.
Finally,Section 6 concludes the paper.2 Related WorkOne of the early work on pronoun resolution rely-ing on parse trees was proposed by Hobbs (1978).For a pronoun to be resolved, Hobbs?
algorithmworks by searching the parse trees of the currenttext.
Specifically, the algorithm processes one sen-tence at a time, using a left-to-right breadth-firstsearching strategy.
It first checks the current sen-tence where the pronoun occurs.
The first NPthat satisfies constraints, like number and genderagreements, would be selected as the antecedent.If the antecedent is not found in the current sen-tence, the algorithm would traverse the trees ofprevious sentences in the text.
As the searchingprocessing is completely done on the parse trees,the performance of the algorithm would rely heav-ily on the accuracy of the parsing results.Lappin and Leass (1994) reported a pronounresolution algorithm which uses the syntactic rep-resentation output by McCord?s Slot Grammarparser.
A set of salience measures (e.g.
Sub-ject, Object or Accusative emphasis) is derivedfrom the syntactic structure.
The candidate withthe highest salience score would be selected asthe antecedent.
In their algorithm, the weights ofCategory: whether the candidate is a definite noun phrase,indefinite noun phrase, pronoun, named-entity or others.Reflexiveness: whether the pronominal anaphor is a reflex-ive pronoun.Type: whether the pronominal anaphor is a male-personpronoun (like he), female-person pronoun (like she), sin-gle gender-neuter pronoun (like it), or plural gender-neuterpronoun (like they)Subject: whether the candidate is a subject of a sentence, asubject of a clause, or not.Object: whether the candidate is an object of a verb, anobject of a preposition, or not.Distance: the sentence distance between the candidate andthe pronominal anaphor.Closeness: whether the candidate is the candidate closestto the pronominal anaphor.FirstNP: whether the candidate is the first noun phrase inthe current sentence.Parallelism: whether the candidate has an identical collo-cation pattern with the pronominal anaphor.Table 1: Feature set for the baseline pronoun res-olution systemsalience measures have to be assigned manually.Luo and Zitouni (2005) proposed a coreferenceresolution approach which also explores the infor-mation from the syntactic parse trees.
Differentfrom Lappin and Leass (1994)?s algorithm, theyemployed a maximum entropy based model to au-tomatically compute the importance (in terms ofweights) of the features extracted from the trees.In their work, the selection of their features ismainly inspired by the government and bindingtheory, aiming to capture the c-command relation-ships between the pronoun and its antecedent can-didate.
By contrast, our approach simply utilizesthe parse trees as a structured feature, and lets thelearning algorithm discover all possible embeddedinformation that is necessary for pronoun resolu-tion.3 The Resolution FrameworkOur pronoun resolution system adopts the com-mon learning-based framework similar to thoseby Soon et al (2001) and Ng and Cardie (2002).In the learning framework, a training or testinginstance is formed by a pronoun and one of itsantecedent candidate.
During training, for eachpronominal anaphor encountered, a positive in-stance is created by paring the anaphor and itsclosest antecedent.
Also a set of negative instancesis formed by paring the anaphor with each of the42non-coreferential candidates.
Based on the train-ing instances, a binary classifier is generated usinga particular learning algorithm.
During resolution,a pronominal anaphor to be resolved is paired inturn with each preceding antecedent candidate toform a testing instance.
This instance is presentedto the classifier which then returns a class labelwith a confidence value indicating the likelihoodthat the candidate is the antecedent.
The candidatewith the highest confidence value will be selectedas the antecedent of the pronominal anaphor.3.1 Feature SpaceAs with many other learning-based approaches,the knowledge for the reference determination isrepresented as a set of features associated withthe training or test instances.
In our baseline sys-tem, the features adopted include lexical property,morphologic type, distance, salience, parallelism,grammatical role and so on.
Listed in Table 1, allthese features have been proved effective for pro-noun resolution in previous work.3.2 Support Vector MachineIn theory, any discriminative learning algorithm isapplicable to learn the classifier for pronoun res-olution.
In our study, we use Support Vector Ma-chine (Vapnik, 1995) to allow the use of kernels toincorporate the structured feature.Suppose the training set S consists of labelledvectors {(xi, yi)}, where xi is the feature vectorof a training instance and yi is its class label.
Theclassifier learned by SVM isf(x) = sgn(?i=1yiaix ?
xi + b) (1)where ai is the learned parameter for a supportvector xi.
An instance x is classified as positive(negative) if f(x) > 0 (f(x) < 0)1.One advantage of SVM is that we can use ker-nel methods to map a feature space to a particu-lar high-dimension space, in case that the currentproblem could not be separated in a linear way.Thus the dot-product x1 ?
x2 is replaced by a ker-nel function (or kernel) between two vectors, thatis K(x1, x2).
For the learning with the normalfeatures listed in Table 1, we can just employ thewell-known polynomial or radial basis kernels thatcan be computed efficiently.
In the next section we1For our task, the result of f(x) is used as the confidencevalue of the candidate to be the antecedent of the pronoundescribed by x.will discuss how to use kernels to incorporate themore complex structured feature.4 Incorporating Structured SyntacticInformation4.1 Main IdeaA parse tree that covers a pronoun and its an-tecedent candidate could provide us much syntac-tic information related to the pair.
The commonlyused syntactic knowledge for pronoun resolution,such as grammatical roles or the governing rela-tions, can be directly described by the tree struc-ture.
Other syntactic knowledge that may be help-ful for resolution could also be implicitly repre-sented in the tree.
Therefore, by comparing thecommon substructures between two trees we canfind out to what degree two trees contain similarsyntactic information, which can be done using aconvolution tree kernel.The value returned from the tree kernel reflectsthe similarity between two instances in syntax.Such syntactic similarity can be further combinedwith other knowledge to compute the overall simi-larity between two instances, through a compositekernel.
And thus a SVM classifier can be learnedand then used for resolution.
This is just the mainidea of our approach.4.2 Structured Syntactic FeatureNormally, parsing is done on the sentence level.However, in many cases a pronoun and an an-tecedent candidate do not occur in the same sen-tence.
To present their syntactic properties andrelations in a single tree structure, we construct asyntax tree for an entire text, by attaching the parsetrees of all its sentences to an upper node.Having obtained the parse tree of a text, we shallconsider how to select the appropriate portion ofthe tree as the structured feature for a given in-stance.
As each instance is related to a pronounand a candidate, the structured feature at leastshould be able to cover both of these two expres-sions.
Generally, the more substructure of the treeis included, the more syntactic information wouldbe provided, but at the same time the more noisyinformation that comes from parsing errors wouldlikely be introduced.
In our study, we examinethree possible structured features that contain dif-ferent substructures of the parse tree:Min-Expansion This feature records the mini-mal structure covering both the pronoun and43Min-Expansion Simple-Expansion Full-ExpansionFigure 1: structured-features for the instance i{?him?, ?the man?
}the candidate in the parse tree.
It only in-cludes the nodes occurring in the shortestpath connecting the pronoun and the candi-date, via the nearest commonly commandingnode.
For example, considering the sentence?The man in the room saw him.
?, the struc-tured feature for the instance i{?him?,?theman?}
is circled with dash lines as shown inthe leftmost picture of Figure 1.Simple-Expansion Min-Expansion could, tosome degree, describe the syntactic relation-ships between the candidate and pronoun.However, it is incapable of capturing thesyntactic properties of the candidate orthe pronoun, because the tree structuresurrounding the expression is not taken intoconsideration.
To incorporate such infor-mation, feature Simple-Expansion not onlycontains all the nodes in Min-Expansion, butalso includes the first-level children of thesenodes2.
The middle of Figure 1 shows such afeature for i{?him?, ?the man?}.
We can seethat the nodes ?PP?
(for ?in the room?)
and?VB?
(for ?saw?)
are included in the feature,which provides clues that the candidate ismodified by a prepositional phrase and thepronoun is the object of a verb.Full-Expansion This feature focusses on thewhole tree structure between the candidateand pronoun.
It not only includes all thenodes in Simple-Expansion, but also thenodes (beneath the nearest commanding par-ent) that cover the words between the candi-date and the pronoun3.
Such a feature keepsthe most information related to the pronoun2If the pronoun and the candidate are not in the same sen-tence, we will not include the nodes denoting the sentencesbefore the candidate or after the pronoun.3We will not expand the nodes denoting the sentencesother than where the pronoun and the candidate occur.and candidate pair.
The rightmost picture ofFigure 1 shows the structure for feature Full-Expansion of i{?him?, ?the man?}.
As illus-trated, different from in Simple-Expansion,the subtree of ?PP?
(for ?in the room?)
isfully expanded and all its children nodes areincluded in Full-Expansion.Note that to distinguish from other words, weexplicitly mark up in the structured feature thepronoun and the antecedent candidate under con-sideration, by appending a string tag ?ANA?
and?CANDI?
in their respective nodes (e.g.,?NN-CANDI?
for ?man?
and ?PRP-ANA?
for ?him?
asshown in Figure 1).4.3 Structural Kernel and Composite KernelTo calculate the similarity between two structuredfeatures, we use the convolution tree kernel that isdefined by Collins and Duffy (2002) and Moschitti(2004).
Given two trees, the kernel will enumerateall their subtrees and use the number of commonsubtrees as the measure of the similarity betweenthe trees.
As has been proved, the convolutionkernel can be efficiently computed in polynomialtime.The above tree kernel only aims for the struc-tured feature.
We also need a composite kernelto combine together the structured feature and thenormal features described in Section 3.1.
In ourstudy we define the composite kernel as follows:Kc(x1, x2) = Kn(x1, x2)|Kn(x1, x2)| ?Kt(x1, x2)|Kt(x1, x2)|(2)where Kt is the convolution tree kernel definedfor the structured feature, and Kn is the kernelapplied on the normal features.
Both kernels aredivided by their respective length4 for normaliza-tion.
The new composite kernel Kc, defined as the4The length of a kernel K is defined as |K(x1, x2)| =?K(x1, x1) ?K(x2, x2)44multiplier of normalized Kt and Kn, will return avalue close to 1 only if both the structured featuresand the normal features from the two vectors havehigh similarity under their respective kernels.5 Experiments and Discussions5.1 Experimental SetupIn our study we focussed on the third-personpronominal anaphora resolution.
All the exper-iments were done on the ACE-2 V1.0 corpus(NIST, 2003), which contain two data sets, train-ing and devtest, used for training and testing re-spectively.
Each of these sets is further dividedinto three domains: newswire (NWire), newspa-per (NPaper), and broadcast news (BNews).An input raw text was preprocessed automati-cally by a pipeline of NLP components, includingsentence boundary detection, POS-tagging, TextChunking and Named-Entity Recognition.
Thetexts were parsed using the maximum-entropy-based Charniak parser (Charniak, 2000), based onwhich the structured features were computed au-tomatically.
For learning, the SVM-Light soft-ware (Joachims, 1999) was employed with theconvolution tree kernel implemented by Moschitti(2004).
All classifiers were trained with defaultlearning parameters.The performance was evaluated based on themetric success, the ratio of the number of cor-rectly resolved5 anaphor over the number of allanaphors.
For each anaphor, the NPs occurringwithin the current and previous two sentenceswere taken as the initial antecedent candidates.Those with mismatched number and gender agree-ments were filtered from the candidate set.
Also,pronouns or NEs that disagreed in person with theanaphor were removed in advance.
For training,there were 1207, 1440, and 1260 pronouns withnon-empty candidate set found pronouns in thethree domains respectively, while for testing, thenumber was 313, 399 and 271.
On average, apronoun anaphor had 6?9 antecedent candidatesahead.
Totally, we got around 10k, 13k and 8ktraining instances for the three domains.5.2 Baseline SystemsTable 2 lists the performance of different systems.We first tested Hobbs?
algorithm (Hobbs, 1978).5An anaphor was deemed correctly resolved if the foundantecedent is in the same coreference chain of the anaphor.NWire NPaper BNewsHobbs (1978) 66.1 66.4 72.7NORM 74.4 77.4 74.2NORM MaxEnt 72.8 77.9 75.3NORM C5 71.9 75.9 71.6S Min 76.4 81.0 76.8S Simple 73.2 82.7 82.3S Full 73.2 80.5 79.0NORM+S Min 77.6 82.5 82.3NORM+S Simple 79.2 82.7 82.3NORM+S Full 81.5 83.2 81.5Table 2: Results of the syntactic structured fea-turesDescribed in Section 2, the algorithm uses heuris-tic rules to search the parse tree for the antecedent,and will act as a good baseline to compare with thelearned-based approach with the structured fea-ture.
As shown in the first line of Table 2, Hobbs?algorithm obtains 66%?72% success rates on thethree domains.The second block of Table 2 shows the baselinesystem (NORM) that uses only the normal featureslisted in Table 1.
Throughout our experiments, weapplied the polynomial kernel on the normal fea-tures to learn the SVM classifiers.
In the table wealso compared the SVM-based results with thoseusing other learning algorithms, i.e., MaximumEntropy (Maxent) and C5 decision tree, which aremore commonly used in the anaphora resolutiontask.As shown in the table, the system with normalfeatures (NORM) obtains 74%?77% success ratesfor the three domains.
The performance is simi-lar to other published results like those by Kellerand Lapata (2003), who adopted a similar fea-ture set and reported around 75% success rateson the ACE data set.
The comparison betweendifferent learning algorithms indicates that SVMcan work as well as or even better than Maxent(NORM MaxEnt) or C5 (NORM C5).5.3 Systems with Structured FeaturesThe last two blocks of Table 2 summarize the re-sults using the three syntactic structured features,i.e, Min Expansion (S MIN), Simple Expansion(S SIMPLE) and Full Expansion (S FULL).
Be-tween them, the third block is for the systems us-ing the individual structured feature alone.
Wecan see that all the three structured features per-45NWire NPaper BNewsSentence Distance 0 1 2 0 1 2 0 1 2(Number of Prons) (192) (102) (19) (237) (147) (15) (175) (82) (14)NORM 80.2 72.5 26.3 81.4 75.5 33.3 80.0 65.9 50.0S Simple 79.7 70.6 21.1 87.3 81.0 26.7 89.7 70.7 57.1NORM+S Simple 85.4 76.5 31.6 87.3 79.6 40.0 88.6 74.4 50.0Table 3: The resolution results for pronouns with antecedent in different sentences apartNWire NPaper BNewsType person neuter person neuter person neuter(Number of Prons) (171) (142) (250) (149) (153) (118)NORM 81.9 65.5 80.0 73.2 74.5 73.7S Simple 81.9 62.7 83.2 81.9 82.4 82.2NORM+S Simple 87.1 69.7 83.6 81.2 86.9 76.3Table 4: The resolution results for different types of pronounsform better than the normal features for NPaper(up to 5.3% success) and BNews (up to 8.1% suc-cess), or equally well (?1 ?
2% in success) forNWire.
When used together with the normal fea-tures, as shown in the last block, the three struc-tured features all outperform the baselines.
Es-pecially, the combinations of NORM+S SIMPLEand NORM+S FULL can achieve significantly6better results than NORM, with the success rateincreasing by (4.8%, 5.3% and 8.1%) and (7.1%,5.8%, 7.2%) respectively.
All these results provethat the structured syntactic feature is effective forpronoun resolution.We further compare the performance of thethree different structured features.
As shown inTable 2, when used together with the normalfeatures, Full Expansion gives the highest suc-cess rates in NWire and NPaper, but neverthe-less the lowest in BNews.
This should be be-cause feature Full-Expansion captures a largerportion of the parse trees, and thus can providemore syntactic information than Min Expansionor Simple Expansion.
However, if the texts areless-formally structured as those in BNews, Full-Expansion would inevitably involve more noisesand thus adversely affect the resolution perfor-mance.
By contrast, feature Simple Expansionwould achieve balance between the informationand the noises to be introduced: from Table 2 wecan find that compared with the other two features,Simple Expansion is capable of producing aver-age results for all the three domains.
And for this6p < 0.05 by a 2-tailed t test.reason, our subsequent reports will focus on Sim-ple Expansion, unless otherwise specified.As described, to compute the structured fea-ture, parse trees for different sentences are con-nected to form a large tree for the text.
It wouldbe interesting to find how the structured featureworks for pronouns whose antecedents reside indifferent sentences.
For this purpose we testedthe success rates for the pronouns with the clos-est antecedent occurring in the same sentence,one-sentence apart, and two-sentence apart.
Ta-ble 3 compares the learning systems with/withoutthe structured feature present.
From the table,for all the systems, the success rates drop withthe increase of the distances between the pro-noun and the antecedent.
However, in most cases,adding the structured feature would bring consis-tent improvement against the baselines regardlessof the number of sentence distance.
This observa-tion suggests that the structured syntactic informa-tion is helpful for both intra-sentential and inter-sentential pronoun resolution.We were also concerned about how the struc-tured feature works for different types of pro-nouns.
Table 4 lists the resolution results for twotypes of pronouns: person pronouns (i.e., ?he?,?she?)
and neuter-gender pronouns (i.e., ?it?
and?they?).
As shown, with the structured feature in-corporated, the system NORM+S Simple can sig-nificantly boost the performance of the baseline(NORM), for both personal pronoun and neuter-gender pronoun resolution.461 2 3 4 5 6 7 8 9 100.650.70.750.8Number of Training DocumentsSuccessNORMS_SimpleNORM+S_Simple 2 4 6 8 10 120.650.70.750.8Number of Training DocumentsSuccessNORMS_SimpleNORM+S_Simple 1 2 3 4 5 6 7 80.650.70.750.8Number of Training DocumentsSuccessNORMS_SimpleNORM+S_SimpleNWire NPaper BNewsFigure 2: Learning curves of systems with different features5.4 Learning CurvesFigure 2 plots the learning curves for the sys-tems with three feature sets, i.e, normal features(NORM), structured feature alone (S Simple),and combined features (NORM+S Simple).
Wetrained each system with different number of in-stances from 1k, 2k, 3k, .
.
.
, till the full size.
Eachpoint in the figures was the average over two trailswith instances selected forwards and backwardsrespectively.
From the figures we can find that(1) Used in combination (NORM+S Simple), thestructured feature shows superiority over NORM,achieving results consistently better than the nor-mal features (NORM) do in all the three domains.
(2) With training instances above 3k, the struc-tured feature, used either in isolation (S Simple)or in combination (NORM+S Simple), leads tosteady increase in the success rates and exhibitsmoother learning curves than the normal features(NORM).
These observations further prove the re-liability of the structured feature in pronoun reso-lution.5.5 Feature AnalysisIn our experiment we were also interested to com-pare the structured feature with the normal flatfeatures extracted from the parse tree, like fea-ture Subject and Object.
For this purpose wetook out these two grammatical features from thenormal feature set, and then trained the systemsagain.
As shown in Table 5, the two grammatical-role features are important for the pronoun resolu-tion: removing these features results in up to 5.7%(NWire) decrease in success.
However, when thestructured feature is included, the loss in successreduces to 1.9% and 1.1% for NWire and BNews,and a slight improvement can even be achieved forNPaper.
This indicates that the structured featurecan effectively provide the syntactic informationNWire NPaper BNewsNORM 74.4 77.4 74.2NORM - subj/obj 68.7 76.2 72.7NORM + S Simple 79.2 82.7 82.3NORM + S Simple - subj/obj 77.3 83.0 81.2NORM + Luo05 75.7 77.9 74.9Table 5: Comparison of the structured feature andthe flat features extracted from parse treesFeature Parser NWire NPaper BNewsCharniak00 73.2 82.7 82.3S Simple Collins99 75.1 83.2 80.4NORM+ Charniak00 79.2 82.7 82.3S Simple Collins99 80.8 81.5 82.3Table 6: Results using different parsersimportant for pronoun resolution.We also tested the flat syntactic feature set pro-posed in Luo and Zitouni (2005)?s work.
As de-scribed in Section 2, the feature set is inspiredthe binding theory, including those features likewhether the candidate is c commanding the pro-noun, and the counts of ?NP?, ?VP?, ?S?
nodesin the commanding path.
The last line of Table 5shows the results by adding these features into thenormal feature set.
In line with the reports in (Luoand Zitouni, 2005) we do observe the performanceimprovement against the baseline (NORM) for allthe domains.
However, the increase in the successrates (up to 1.3%) is not so large as by adding thestructured feature (NORM+S Simple) instead.5.6 Comparison with Different ParsersAs mentioned, the above reported results werebased on Charniak (2000)?s parser.
It would beinteresting to examine the influence of differentparsers on the resolution performance.
For thispurpose, we also tried the parser by Collins (1999)47(Mode II)7, and the results are shown in Table 6.We can see that Charniak (2000)?s parser leads tohigher success rates for NPaper and BNews, whileCollins (1999)?s achieves better results for NWire.However, the difference between the results of thetwo parsers is not significant (less than 2% suc-cess) for the three domains, no matter whether thestructured feature is used alone or in combination.6 ConclusionThe purpose of this paper is to explore how tomake use of the structured syntactic knowledge todo pronoun resolution.
Traditionally, syntactic in-formation from parse trees is represented as a setof flat features.
However, the features are usu-ally selected and defined by heuristics and maynot necessarily capture all the syntactic informa-tion provided by the parse trees.
In the paper, wepropose a kernel-based method to incorporate theinformation from parse trees.
Specifically, we di-rectly utilize the syntactic parse tree as a struc-tured feature, and then apply kernels to such a fea-ture, together with other normal features, to learnthe decision classifier and do the resolution.
Ourexperimental results on ACE data set show thatthe system with the structured feature includedcan achieve significant increase in the success rateby around 5%?8%, for all the different domains.The deeper analysis on various factors like trainingsize, feature set or parsers further proves that thestructured feature incorporated with our kernel-based method is reliably effective for the pronounresolution task.ReferencesC.
Aone and S. W. Bennett.
1995.
Evaluating auto-mated and manual acquisition of anaphora resolu-tion strategies.
In Proceedings of the 33rd AnnualMeeting of the Association for Compuational Lin-guistics, pages 122?129.E.
Charniak.
2000.
A maximum-entropy-inspiredparser.
In Proceedings of North American chapterof the Association for Computational Linguistics an-nual meeting, pages 132?139.M.
Collins and N. Duffy.
2002.
New ranking algo-rithms for parsing and tagging: kernels over discretestructures and the voted perceptron.
In Proceed-ings of the 40th Annual Meeting of the Association7As in their pulic reports on Section 23 of WSJ TreeBank,Charniak (2000)?s parser achieves 89.6% recall and 89.5%precision with 0.88 crossing brackets (words ?
100), againstCollins (1999)?s 88.1% recall and 88.3% precision with 1.06crossing brackets.for Computational Linguistics (ACL?02), pages 263?270.M.
Collins.
1999.
Head-Driven Statistical Models forNatural Language Parsing.
Ph.D. thesis, Universityof Pennsylvania.J.
Hobbs.
1978.
Resolving pronoun references.
Lin-gua, 44:339?352.T.
Joachims.
1999.
Making large-scale svm learningpractical.
In Advances in Kernel Methods - SupportVector Learning.
MIT Press.F.
Keller and M. Lapata.
2003.
Using the web to ob-tain freqencies for unseen bigrams.
ComputationalLinguistics, 29(3):459?484.C.
Kennedy and B. Boguraev.
1996.
Anaphorafor everyone: pronominal anaphra resolution with-out a parser.
In Proceedings of the 16th Inter-national Conference on Computational Linguistics,pages 113?118, Copenhagen, Denmark.S.
Lappin and H. Leass.
1994.
An algorithm forpronominal anaphora resolution.
ComputationalLinguistics, 20(4):525?561.X.
Luo and I. Zitouni.
2005.
Milti-lingual coreferenceresolution with syntactic features.
In Proceedings ofHuman Language Techonology conference and Con-ference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 660?667.R.
Mitkov.
1998.
Robust pronoun resolution with lim-ited knowledge.
In Proceedings of the 17th Int.
Con-ference on Computational Linguistics, pages 869?875.A.
Moschitti.
2004.
A study on convolution kernelsfor shallow semantic parsing.
In Proceedings of the42nd Annual Meeting of the Association for Compu-tational Linguistics (ACL?04), pages 335?342.V.
Ng and C. Cardie.
2002.
Improving machine learn-ing approaches to coreference resolution.
In Pro-ceedings of the 40th Annual Meeting of the Associa-tion for Computational Linguistics, pages 104?111,Philadelphia.W.
Soon, H. Ng, and D. Lim.
2001.
A machinelearning approach to coreference resolution of nounphrases.
Computational Linguistics, 27(4):521?544.V.
Vapnik.
1995.
The Nature of Statistical LearningTheory.
Springer.X.
Yang, J. Su, G. Zhou, and C. Tan.
2004.
Improv-ing pronoun resolution by incorporating coreferen-tial information of candidates.
In Proceedings of42th Annual Meeting of the Association for Compu-tational Linguistics, pages 127?134, Barcelona.D.
Zelenko, C. Aone, and A. Richardella.
2003.
Ker-nel methods for relation extraction.
Journal of Ma-chine Learning Research, 3(6):1083 ?
1106.S.
Zhao and R. Grishman.
2005.
Extracting rela-tions with integrated information using kernel meth-ods.
In Proceedings of 43rd Annual Meeting of theAssociation for Computational Linguistics (ACL05),pages 419?426.48
