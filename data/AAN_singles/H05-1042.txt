Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 331?338, Vancouver, October 2005. c?2005 Association for Computational LinguisticsCollective Content Selection for Concept-To-Text GenerationRegina BarzilayComputer Science and Artificial Intelligence LaboratoryMassachusetts Institute of Technologyregina@csail.mit.eduMirella LapataSchool of InformaticsUniversity of Edinburghmlap@inf.ed.ac.ukAbstractA content selection component deter-mines which information should be con-veyed in the output of a natural languagegeneration system.
We present an effi-cient method for automatically learningcontent selection rules from a corpus andits related database.
Our modeling frame-work treats content selection as a col-lective classification problem, thus allow-ing us to capture contextual dependen-cies between input items.
Experimentsin a sports domain demonstrate that thisapproach achieves a substantial improve-ment over context-agnostic methods.1 IntroductionContent selection is a fundamental task in concept-to-text generation (Reiter and Dale, 2000).
A practi-cal generation system typically operates over a largedatabase with multiple entries that could potentiallybe included in a text.
A content selection compo-nent determines what subset of this information toinclude in the generated document.For example, consider the task of automaticallygenerating game summaries, given a database con-taining statistics on Americal football.
Table 1shows an excerpt from such a database, and its cor-responding game summary written by a journalist.A single football game is typically documented inhundreds of database entries ?
all actions, playerpositions, and scores are recorded, along with a widerange of comparative and aggregate statistics.
Onlya small fraction of this information is featured in agame summary.
The content selection componentaims to identify this subset.1In existing generation systems the content se-lection component is manually crafted.
Specify-ing content selection rules is, however, notoriouslydifficult, prohibitively so in large domains.
It in-volves the analysis of a large number of texts from adomain-relevant corpus, familiarity with the associ-ated database, and consultation with domain experts.Moreover, the task must be repeated for each domainanew.This paper proposes a data-driven method forlearning the content-selection component for aconcept-to-text generation system.
We assume thatthe learning algorithm is provided with a parallelcorpus of documents and a corresponding database,in which database entries that should appear in doc-uments are marked.One possible approach is to formulate content se-lection as a standard binary classification task: pre-dict whether an item is to be included on the basisof its attributes alone.
In fact, this method is com-monly used for content selection in text summariza-tion (e.g., Kupiec et al, 1995).
However, by treatingeach instance in isolation, we cannot guarantee thatthe selected database entries are related in a mean-ingful way, which is essential for the generation of acoherent text.Rather than selecting each item separately, wepropose a method for collective content selection,where all candidates are considered simultaneouslyfor selection.
Collective selection thereby allowsus to explicitly optimize coherence in the generated1The organization of the selected information and its sur-face realization is typically handled by other components of thegeneration system, which are outside the scope of this paper.331PassingPLAYER CP/AT YDS AVG TD INTBrunell 17/38 192 6.0 0 0Garcia 14/21 195 9.3 1 0. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.RushingPLAYER REC YDS AVG LG TDSuggs 22 82 3.7 25 1. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.FumblesPLAYER FUM LOST REC YDSColes 1 1 0 0Portis 1 1 0 0Davis 0 0 1 0Little 0 0 1 0. .
.
.
.
.
.
.
.
.
.
.
.
.
.Suggs rushed for 82 yards and scored atouchdown in the fourth quarter, leadingthe Browns to a 17-13 win over the Wash-ington Redskins on Sunday.
Jeff Garciawent 14-of-21 for 195 yards and a TD forthe Browns, who didn?t secure the win untilColes fumbled with 2:08 left.
The Redskins(1-3) can pin their third straight loss on go-ing just 1-for-11 on third downs, mental mis-takes and a costly fumble by Clinton Por-tis.
Brunell finished 17-of-38 for 192 yards,but was unable to get into any rhythm becauseCleveland?s defense shut down Portis.
TheBrowns faked a field goal, but holder Der-rick Frost was stopped short of a first down.Brunell then completed a 13-yard pass toColes, who fumbled as he was being takendown and Browns safety Earl Little recov-ered.Table 1: Sample target game description and example of database entries; boldface indicates correspon-dences between the text and the database (CP/AT: completed out of attempted, YDS: yards, AVG: average,TD: touchdown, INT: interception, REC: received, LG: longest gain, FUM: fumble).text: semantically related entries are often selectedtogether.
In essence, the algorithm seeks a subsetof candidates that is consistent with the individualpreferences of each candidate, and at the same timemaximally satisfies contextual constraints.
A graph-based formulation of this optimization problem al-lows us to find an exact, globally optimal solution,using a min-cut algorithm.Collective content selection is particularly ben-eficial to generation systems that operate over re-lational databases.
Rich structural informationavailable in a database can be readily utilized todetermine semantic relatedness between differentdatabase entries.
For instance, we can easily findall actions (e.g., touchdowns and fumbles) associ-ated with a specific player in a game, which could berelevant for generating a summary centered aroundan individual.
We show how to utilize database re-lations for discovering meaningful contextual linksbetween database entries.We evaluate our collective content selectionmodel in a sports domain.
The proposed contentselection component operates over a large databasecontaining descriptive statistics about Americanfootball games.
Our model yields a 10% increase inF-score, when compared to a standard classificationapproach, thus demonstrating the benefits of collec-tive content selection on this complex domain.
Fur-thermore, our results empirically confirm the contri-bution of discourse constraints for content selection.In the following section, we provide an overviewof existing work on content selection.
Then, we de-fine the learning task and introduce our approach forcollective content selection.
Next, we present ourexperimental framework and data.
We conclude thepaper by presenting and discussing our results.2 Related WorkThe generation literature provides multiple exam-ples of content selection components developed forvarious domains (Kukich, 1983; McKeown, 1985;Sripada et al, 2001; Reiter and Dale, 2000).
A com-mon theme across different approaches is the em-phasis on coherence: related information is selected?to produce a text that hangs together?
(McKeown,1985).
Similarly, our method is also guided by co-herence constraints.
In our case these constraints arederived automatically, while in symbolic generationsystems coherence is enforced by analyzing a largenumber of texts from a domain-relevant corpus and332careful hand-crafting of content selection rules.Duboue and McKeown (2003) were the first topropose a method for learning content selectionrules automatically, thus going beyond mere corpusanalysis.
They treat content selection as a classifi-cation task.
Given a collection of texts associatedwith a domain-specific database, their model learnswhether a database entry should be selected for pre-sentation or not.
Their modeling approach uses anexpressive feature space while considering databaseentries in isolation.Similarly to Duboue and McKeown (2003), weview content selection as a classification task andlearn selection rules from a database and its corre-sponding corpus.
In contrast to them, we considerall database entries simultaneously, seeking a glob-ally optimal selection.
Thus, we avoid the need forextensive feature engineering by incorporating dis-course constraints into the learning framework.
Inaddition, we assess whether data-driven methods forcontent selection scale up to large databases withthousands of interrelated entries, by evaluating ourmodel in a sports domain.
Previous work (Duboueand McKeown, 2003) has tackled the content selec-tion problem for biographical summaries, a simplerdomain with fewer entities and interactions amongthem.3 The TaskWe assume that the content selection componenttakes as input a set of database entries.2 Each en-try has a type and a set of attributes associated withits type.
For instance, the database shown in Table 1contains entries of three types ?
Passing, Rushingand Fumbles.
Two entries are of type Passing, andeach of them has six attributes ?
PLAYER, CP/AT,YDS, AVG, TD, INT.
In addition, each entry has a la-bel that specifies whether it should be included in agenerated text or not.During the training process, the learning algo-rithm is provided with n sets of database entries,each associated with a label whose value is known.In practice, we only require a parallel corpus ofgame summaries and database entries ?
label val-ues are derived automatically via alignment (seeSection 4 for more details).2A terminological note: a database entry is analogous to arow in a relational table; throughout this paper we use the termsentity and database entry interchangeably.The goal of the content selection component isto select entries from a database, i.e., to determinewhether their label values are 0 or 1.
Under this for-mulation, content selection is restricted to informa-tion available in the database; there is no attempt toinduce new facts through inference.In the next section, we describe our learningframework, and explain how it is applied to the con-tent selection task.3.1 The Collective Classification ApproachGeneration of a coherent text crucially depends onour ability to select entities that are related in ameaningful way (McKeown, 1985).
A content se-lection component that considers every entity in iso-lation does not have any means to enforce this im-portant discourse constraint.
We therefore formulatecontent selection as a collective classification task,where all entities that belong to the same database(i.e., the same football game) are considered simul-taneously.
This framework thus enables us to en-force contextual constraints by selecting related en-tities.When considered in isolation, some database en-tries are more likely to be selected than others.
Inthe American football domain, for example, entriesof type Rushing are often extracted if they yield atouchdown.3 Other Rushing entries (e.g., which donot deliver scoring points) are typically omitted.
Ingeneral, the attributes of an entry can provide use-ful cues for predicting whether it should be selected.Therefore, we can perform content selection by ap-plying a standard classifier on each entry.
In Sec-tion 3.2, we explain in more detail how such a clas-sifier can be trained.We can also decide about entity selection by an-alyzing how entities relate to each other in thedatabase.
For instance, in a game where both quar-terbacks4 score, it is fairly unorthodox to mentionthe passing statistics for only one of them.
Label as-signments in which either both quarterbacks are se-lected, or both of them are omitted should be there-3A touchdown is the primary method of scoring in Americanfootball; a touchdown is worth six points and is accomplishedby gaining legal possession of the ball in the opponent?s endzone.4A quarterback in American football is the leader of a team?soffense.
In most offenses his primary duty is passing the ball.Quarterbacks are typically evaluated on their passing statistics,including total yardage, completion ratio, touchdowns, and theability to avoid interceptions.333fore preferred.
This relation between quarterbackpassing statistics exemplifies one type of link thatcan hold between entities.
Other link types mayencode contextual constraints, for instance captur-ing temporal and locational information.
(In Sec-tion 3.3, we describe a method for discovering linktypes which encapsulate meaningful contextual de-pendencies.)
By taking into account links betweenrelated entities, a content selection component canenforce dependencies in the labeling of related enti-ties.Our goal is to select a subset of database entitiesthat maximally satisfies linking constraints and isas consistent as possible with the individual prefer-ences of each entity.
Thus, content selection can benaturally stated as an optimization problem ?
wewish to find a label assignment that minimizes thecost of violating the above constraints.Let C+ and C?
be a set of selected and omitted en-tities, respectively; ind+(x) and ind?
(x) are scoresthat capture the individual preference of x to be ei-ther selected or omitted, and linkL(x,y) reflects thedegree of dependence between the labels of x and ybased on a link of type L. Thus, the optimal labelassignment for database entries x1, .
.
.
,xn will mini-mize:?x?C+ind?
(x)+ ?x?C?ind+(x)+?L?xi?C+x j?C?linkL(xi,x j)The first two elements in this expression cap-ture the penalty for assigning entities to classesagainst their individual preferences.
For instance,the penalty for selecting an entry x ?
C+ will equalind?
(x), i.e., x?s individual preference of being om-mitted.
The third term captures a linking penalty forall pairs of entities (xi,x j) that are connected by alink of type L, and are assigned to different classes.This formulation is similar to the energy mini-mization framework, which is commonly used inimage analysis (Besag, 1986; Boykov et al, 1999)and has been recently applied in natural languageprocessing (Pang and Lee, 2004).
The principal ad-vantages of this formulation lie in its computationalproperties.
Despite seeming intractable ?
the num-ber of possible subsets to consider for selection isexponential in the number of database entities ?
theinference problem has an exact solution.
Providedthat the scores ind+(x), ind?
(x), and linkL(x,y) arepositive, we can find a globally optimal label as-signment in polynomial time by computing a min-imal cut partition in an appropriately constructedgraph (Greig et al, 1989).In the following we first discuss how individualpreference scores are estimated.
Next, we describehow to induce links and estimate their scores.3.2 Computing Individual Preference ScoresThe individual preference scores are estimated byconsidering the values of entity attributes, recordedin the database.
The type and number of the at-tributes are determined by the entity type.
There-fore, we separately estimate individual preferencescores for each entity type.
For example, individ-ual scores for entities of type Passing are computedbased on six attributes : PLAYER, CP/AT, YDS, AVG,TD, INT (see Table 1).Considerable latitude is available when selectinga classifier for delivering the individual preferencescores.
In our experiments we used the publiclyavailable BoosTexter system (Schapire and Singer,2000).
BoosTexter implements a boosting algo-rithm that combines many simple, moderately accu-rate categorization rules into a single, highly accu-rate rule.
For each example, it outputs a predictionalong with a weight whose magnitude indicates theclassifier?s confidence in the prediction.
We thus setthe individual preference scores to the weights ob-tained from BoosTexter.
The weights range from ?1to 1; we obtained non-negative numbers, simply byadding 1.It is important to note that BoosTexter is a fairlyeffective classifier.
When applied to text categoriza-tion (Schapire and Singer, 2000), it outperformed anumber of alternative classification methods, includ-ing Naive Bayes, decision trees, and k-nearest neigh-bor.3.3 Link Selection and ScoringThe success of collective classification depends onfinding links between entities with similar label pref-erences.
In our application ?
concept-to-text gen-eration, it is natural to define entity links in termsof their database relatedness.
Since the underlyingdatabase contains rich structural information, we canexplore a wide range of relations between databaseentities.The problem here is finding a set of links that334capture important contextual dependencies amongmany possible combinations.
Instead of manu-ally specifying this set, we propose a corpus-drivenmethod for discovering links automatically.
Auto-matic link induction can greatly reduce human ef-fort.
Another advantage of the method is that it canpotentially identify relations that might escape a hu-man expert and yet, when explicitly modeled, aid incontent selection.We induce important links by adopting agenerate-and-prune approach.
We first automati-cally create a large pool of candidate links.
Next, weselect only links with aconsistent label distributions.Construction of Candidate Links An importantdesign decision is the type of links that we allowour algorithm to consider.
Since our ultimate goal isthe generation of a coherent text, we wish to focuson links that capture semantic connectivity betweendatabase entities.
An obvious manifestation of se-mantic relatedness is attribute sharing.
Therefore,we consider links across entities with one or moreshared attributes.
An additional constraint is impliedby computational considerations: our optimizationframework, based on minimal cuts in graphs, sup-ports only pairwise links, so we restrict our attentionto binary relations.We generate a range of candidate link types us-ing the following template: For every pair of entitytypes Ei and E j, and for every attribute k that is asso-ciated with both of them, create a link of type Li, j,k.A pair of entities ?a,b?
is linked by Li, j,k , if a is oftype Ei, b is of type E j and they have the same valuefor the attribute k. For example, a link that asso-ciates statistics on Passing and Rushing performedby the same player is an instantiation of the abovewith Ei = Rushing, E j = Passing, and k = Player.In a similar fashion, we construct link types thatconnect together entities with two or three attributesin common.
Multiple pairs of entries can be con-nected by the same link type.If the database consists of n entity types, and thenumber of attribute types is bounded by m, thenthe number of link types constructed by this processdoes not exceed O(n2(m +(m2)+(m3))) ?
O(n2m3).In practice, this bound is much lower, since only afew attributes are shared among entity types.
Linkscan be efficiently computed using SQL?s SELECT op-erator.Link Filtering Only a small fraction of the auto-matically generated link types will capture meaning-ful contextual dependencies.
To filter out spuriouslinks, we turn to the labels of the entities partici-pating in each link.
Only link types in which en-tities have a similar distribution of label values areselected from the pool of candidates.We measure similarity in label distribution usingthe ?2 test.
This test has been successfully applied tosimilar tasks, such as feature selection in text clas-sification (Rogati and Yang, 2002), and can be eas-ily extended to our application.
Given a binary link,our null hypothesis H0 is that the labels of entitiesrelated by L are independent.
For each link, wecompute the ?2 score over a 2-by-2 table that storesjoint label values of entity pairs, computed across alldatabase entries present in the training set.
For linkswith ?2 > ?, the null hypothesis is rejected, and thelink is considered a valid discourse constraint.
Thevalue of ?
is set to 3.84, which corresponds to a 5%level of statistical significance.Link Weights The score of a link type L is definedas follows:linkL(x,y) ={?L i f (x,y) are linked by L0 otherwiseWe estimate link weights ?L using simulated anneal-ing.
The goal is to find weight values that minimizean objective function, defined as the error rate onthe development set5 (see Section 4 for details).
Theindividual scores and the link structure of the enti-ties in the development set are predicted automat-ically using the models trained on the training set.Starting from a random assignment of weight val-ues, we compute the objective function and generatenew weight values using Parks?
(1990) method.
Theprocedure stops when no sufficient progress is ob-served in subsequent iterations.4 Evaluation FrameworkWe apply the collective classification method justpresented to the task of automatically learning con-tent selection rules from a database containingfootball-related information.
In this section, we firstpresent the sport domain we are working with, and5Our objective function cannot be optimized analytically.We therefore resort to heuristic search methods such as simu-lated annealing.335Entity Type Attr Inst %Aligned Entity Type Attr Inst %AlignedDefense 8 14,077 0.00 Passing 5 1,185 59.90Drive 10 11,111 0.00 Team comparison 4 14,539 0.00Play-by-Play 8 83,704 3.03 Punt-returns 8 940 5.74Fumbles 8 2,937 17.78 Punting 9 950 0.87Game 6 469 0.00 Receiving 8 6,337 11.19Interceptions 6 894 45.05 Rushing 8 3,631 9.17Kicking 8 943 26.93 Scoring-sum 9 3,639 53.34Kickoff-returns 8 1,560 5.24 Team 3 4 0.00Officials 8 464 0.00Table 2: Entity types and their attributes in the NFL database; percentage of database entries that are alignedto summary sentences.describe how we collected a corpus for evaluatingcollective content selection.
Next, we explain howwe automatically obtained annotated data for train-ing and testing our model.Data As mentioned previously our goal is togenerate descriptions of football games.
Thesports domain has enjoyed popularity among natu-ral language generation practitioners (Robin, 1994;Tanaka-Ishii et al, 1998).
The appeal is partly dueto the nature of the domain ?
it exhibits severalfixed patterns in content organization and is there-fore amenable to current generation approaches.
Atthe same time, it is complex enough to present chal-lenges at almost all stages of the generation process.We compiled a corpus of descriptions of footballgames from the web.
More specifically, we obtainedgame summaries from the official site of the Ameri-can National Football League6 (NFL).
We collectedsummaries for the 2003 and 2004 seasons.
Theseare typically written by Associated Press journalists.The corpus consists of 468 texts in total (436,580words).
The average summary length is 46.8 sen-tences.The site not only contains a summary for eachgame, but also a wealth of statistics describing theperformance of individual players and their teams.It includes a scoring summary and a play-by-playsummary giving details of the most important eventsin the game together with temporal (i.e., time re-maining) and positional (i.e., location in the field)information.
In sum, for each game the site offersa rich repository of tabulated information which wetranslated into a relational database.
An excerpt of6See http://www.nfl.com/scores.the database is shown in Table 1.
Table 2 displaysthe entity types contained in our NFL database andlists the number of attributes (Attr) and instantia-tions (Inst) per type.
The database contains 73,400entries in total.Alignment Recall that our collective classificationmethod is supervised.
The training instances aredatabase entries and the class labels indicate whetheran instance should be selected for presentation ornot.
We could obtain this information via manual an-notation performed by domain experts.
Instead, weopted for a less costly, automatic solution that yieldslarge quantities of training and testing data.
To in-fer which database entries correspond to sentencesin the verbalized game summaries, we used a sim-ple anchor-based alignment technique.
In our do-main, numbers and proper names appear with highfrequency, and they constitute reliable anchors foralignment.
Similar to previous work (Duboue andMcKeown, 2003; Sripada et al, 2001), we employa simple matching procedure that considers anchoroverlap between entity attributes and sentence to-kens.Overall, the alignment procedure produced 7,513pairs.
7.1% of the database entries were verbalizedin our corpus and 31.7% of the corpus sentences hada database entry.
Table 2 presents the proportion ofdatabase entries which are verbalized in our corpus,broken down by entity type (see %Aligned).To evaluate the accuracy of this procedure, wecompared our output with a gold-standard align-ment produced by a domain expert.
After analyz-ing the data from five games, the expert produced52 alignment pairs; 47 of these pairs were identified336Majority Baseline Standard Classifier Collective ClassifierPrec Rec F-score Prec Rec F-score Prec Rec F-scoreMean 29.40 68.19 40.09 44.88 62.23 49.75 52.71 76.50 60.15Min 3.57 28.57 6.45 12.50 8.33 13.33 12.50 27.27 19.05Max 57.14 100.00 65.12 76.92 100.00 75.00 100.00 100.00 100.00Std Dev 10.93 15.75 12.25 15.36 18.33 13.98 21.29 18.93 19.66Table 3: Results on content selection (precision, recall and F-score are averages over individual game sum-maries); comparison between the majority baseline, standard and collective classification.by the automatic alignment.
In addition, three pairsproduced by the program did not match the gold-standard alignment.
Thus, the automatic methodachieved 94.0% precision and 90.4% recall.Data Annotation For training and testing pur-poses, we only considered entity types forwhich alignments were observed in our corpus(e.g., Fumbles, Interceptions; see Table 2).Types without alignments can be trivially regardedas inappropriate for selection in the generated text.We considered database entries for which we foundverbalizations in the corpus as positive instances(i.e., they should be selected); accordingly, non-verbalized entries were considered negative in-stances (i.e., they should not be selected).
Theoverall dataset contained 105,792 instances (corre-sponding to 468 game summaries).
Of these, 15%(68 summaries) were reserved for testing.
We heldout 1,930 instances (10 summaries) from the train-ing data for development purposes.5 ResultsOur results are summarized in Table 3.
We comparethe performance of the collective classifier against astandard classifier.
This can be done in our frame-work, simply by setting the link scores to zero.
Wealso report the performance of a majority baseline.The latter was obtained by defaulting to the major-ity class for each entity type in the training data.
Ascan be seen from Table 2, only for two relations ?Passing and Scoring-sum ?
the majority classpredicts that the corresponding database instancesshould be selected for presentation.Our results confirm that a content selection com-ponent can be automatically engineered for the foot-ball domain.
The collective classifier achieves anF-score of 60.15%.
This result compares favor-ably with Duboue and McKeown (2003) whose bestmodel has an F-score of 51.00% on a simpler do-main.
Our method has high recall (we want toavoid missing out information that should be pre-sented in the output) but tends to overgenerate asdemonstrated by the relatively moderate precisionin Table 3.
Erroneous content selection decisionscould be remedied by other components later in thegeneration process.
Alternatively, the obtained con-tent selection rules could be further refined or post-processed by a domain expert.
Finally, better clas-sification performance should be possible with moreexpressive feature sets.
As we can see from the weakperformance of the standard classifier, attribute val-ues of database entries may not be sufficiently strongpredictors.
Considering additional features tailoredto the NFL domain could further enhance perfor-mance.
However, feature selection is not one of themain objectives of this work.Our results empirically validate the importance ofdiscourse constraints for content selection (Table 4illustrates examples of constraints that the modeldiscovered).
We observe that adding contextual in-formation leads to a 10.4% F-score increase over thestandard classifier.
We used a paired t test to exam-ine whether the differences are statistically signifi-cant.
The collective model significantly outperformsthe standard model on both precision (t = 4.824,p < 0.01) and recall (t = 8.445, p < 0.01).
It is alsosignificantly better than the majority baseline, bothin terms of recall (t = 3.181, p < 0.01) and preci-sion (t = 8.604, p < 0.01).
The standard classifierperforms significantly better than the majority base-line on precision (t = 7.043, p < 0.01) but worse onrecall (t =-2.274, p < 0.05).6 Conclusions and Future WorkIn this paper we have presented a novel, data-drivenmethod for automating content selection.
Central337{?a,b?
| a ?
Sum?b ?
Sum?a.Quarter = b.Quarter}{?a,b?
| a ?
Sum?b ?
Play?Sum.Player1 = Play.Player1 ?Sum.Action = Play.Action}{?a,b?
| a ?
Fumbles?b ?
Interceptions ?Fumbles.Player = Interceptions.Player}Table 4: Examples of automatically derived links.to our approach is the use of a collective classifi-cation model that captures contextual dependenciesbetween input items.
We show that incorporationof discourse constraints yields substantial improve-ment over context-agnostic methods.
Our approachis linguistically grounded, computationally efficient,and viable in practical applications.In the future, we plan to explore how to integratemore refined discourse models in the content selec-tion process.
Currently, we consider a limited set ofcontextual dependencies based on attribute similar-ity.
Ideally, we would like to express more complexrelations between items.
For instance, we may wantto represent disjunctive constraints, such as ?at leastone of the defense players should be mentioned inthe summary.?
Such dependencies can be efficientlyhandled in a collective classification framework byusing approximate probabilistic inference (Taskar etal., 2002).
Another promising approach is the com-bination of our automatically acquired cross-entitylinks with domain knowledge.Needless to say, content selection is one of sev-eral components within a working generation sys-tem.
An interesting question is how to integrate ourcomponent into a generation pipeline, using feed-back from other components to guide collective con-tent selection.AcknowledgmentsThe authors acknowledge the support of the National ScienceFoundation (Barzilay; CAREER grant IIS-0448168 and grantIIS-0415865) and EPSRC (Lapata; grant GR/T04540/01).We are grateful to Eli Barzilay for his help with data collec-tion, and Luke Zettelmoyer who explained the many rules ofAmerican football to us.
Thanks to Michael Collins, AmitDubey, Noemie Elhadad, Dina Katabi, Frank Keller, IgorMalioutov, Smaranda Muresan, Martin Rinard, Kevin Simlerand the anonymous reviewers for helpful comments and sug-gestions.
Any opinions, findings, and conclusions or recom-mendations expressed above are those of the authors and do notnecessarily reflect the views of the National Science Foundationor EPSRC.ReferencesJ.
Besag.
1986.
On the statistical analysis of dirty pic-tures.
Journal of the Royal Statistical Society, 48:259?302.Y.
Boykov, O. Veksler, R. Zabih.
1999.
Fast approximateenergy minimization via graph cuts.
In ICCV, 377?384.P.
A. Duboue, K. R. McKeown.
2003.
Statistical acqui-sition of content selection rules for natural languagegeneration.
In Proceedings of the EMNLP, 121?128.D.
Greig, B. Porteous, A. Seheult.
1989.
Exact maxi-mum a posteriori estimation for binary images.
Jour-nal of the Royal Statistical Society, 51(2):271?279.K.
Kukich.
1983.
Design of a knowledge-based reportgenerator.
In Proceedings of the ACL, 145?150.J.
Kupiec, J. O. Pedersen, F. Chen.
1995.
A trainabledocument summarizer.
In Proceedings of the SIGIR,68?73.K.
R. McKeown.
1985.
Text Generation: Using Dis-course Strategies and Focus Constraints to GenerateNatural Language Text.
Cambridge University Press.B.
Pang, L. Lee.
2004.
A sentimental education: Senti-ment analysis using subjectivity summarization basedon minimum cuts.
In Proceedings of the ACL, 271?278, Barcelona, Spain.G.
Parks.
1990.
An intelligent stochastic optimizationroutine for nuclear fuel cycle design.
Nuclear Tech-nology, 89:233?246.E.
Reiter, R. Dale.
2000.
Building Natural LanguageGeneration Systems.
Cambridge University Press,Cambridge.J.
Robin.
1994.
Revision-Based Generation of Natu-ral Language Summaries Providing Historical Back-ground.
Ph.D. thesis, Columbia University.M.
Rogati, Y. Yang.
2002.
High-performing feature se-lection for text classification.
In Proceedings of theCIKM, 659?661.R.
E. Schapire, Y.
Singer.
2000.
Boostexter: A boosting-based system for text categorization.
Machine Learn-ing, 39(2/3):135?168.S.
G. Sripada, E. Reiter, J.
Hunter, J. Yu.
2001.
A two-stage model for content determination.
In Proceedingsof the ACL-ENLG, 3?10.K.
Tanaka-Ishii, K. Hasida, I. Noda.
1998.
Reactivecontent selection in the generation of real-time soc-cer commentary.
In Proceedings of the ACL/COLING,1282?1288.B.
Taskar, P. Abbeel, D. Koller.
2002.
Discriminativeprobabilistic models for relational data.
In Proceed-ings of the UAI, 485?495.338
