A :SEMANTIC  INTERPRETER FORSYSTEMIC  GRAMMARSTim F. O'Donoghuet immy@uk, ac.
leeds, aiDivision of Artificial IntelligenceSchool of Computer StudiesThe University of LeedsLeeds LS2 9JT.
UK+44 532 33.5430ABSTRACTThis paper describes a method for obtaining thesemantic representation for a syntax tree in Sys-temic Grammar (SG).
A prototype implementationof this method - -  the REVELATION1 semantic inter-preter - -  has been ldeveloped.
It is derived froma SG generator foe a large subset of English - -GENESYS - -  and is !thus, in contrast with most re-versible grammars, fan interpreter based on a gen-erator.
A task decomposition approach is adoptedfor this reversal process which operates within theframework of SG, thus demonstrating that SystemicGrammars can be reversed and hence that a SG isa truly bi-directional formalism,pIntroduct ionSG (see Butler \[4\] for a good introduction) is auseful model of lan~guage, having found many ap-plications in the areas of stylistics, text analy-sis, educational linggistics and artificial intelligence.Some of these applications have been colnputa-tional, the best known probably being Winograd'sSHRDLU \[22\].
Howdver, most computational ppli-cations have been designed from a text-generationviewpoint (such as Davey's PROTEUS \[6\], Mantaand Matthiessen's NmEL \[16, 17\] and Fawcett andrlhtcker's ?ENESYS \[!0\]).Because of this text-generation viewpoint of sys-ten tic grammarians, the mechanism for sentenceanalysis within SG (the reverse of the sentence gen-eration process) h~ received much less attention.This paper describes one stage of the sentence anal-ysis process: semant ic  in terpreta t ion .
l1 This assumes that Isentence analysis can be decomposedinto two  processes :  syntact i c  ana lys i s  (parsing) plus semanticIn Fawcett's SG, 2 a syntax tree (whose leaves de-fine a sentence) is generated from a set of semanticchoices.
R.EVELATION1 reverses this process: it at-tempts to find the set of semantic hoices neededto generate a given syntax tree.
In sentence gener-ation, a tree is generated, but only the leaves (thewords) are 'output',  the rest of the tree is simplydeleted.
In tile reverse process, when a sentence isinput, a syntax tree must first be found before it canbe interpreted.
REVELATION1 assumes that a sepa-rate SG parser (not discussed here) is available; foran example of such a parser see O'Donoghue \[20\].Thus REVELATION1 directly mirrors the generator,while the parser mirrors tlle tree deletion process.REVELATION1 has been developed within thePoPI.OG environment, a It is coded in a com-bination of PoPl l  \[1\] and Prolog \[5\] and utilizesGENESYS.
GENESYS is a very large SG generator forEnglish, written in Prolog (Fawcett and Tucker \[10\])and it is version PG1.5 that has been used for the de-velopment and testing of REVELATIONI.
GENESYSand REVELATION are part of a much larger project,the COMMUNAL 4 Project, the aim of which isto build a natural language interface to a rich SGoriented IKBS in tim domain of personnel manage-interp|~etation.
These processes  are  not necessarily sequential,although it greatly simplifies things if they are treated assuch.
tlere I assume a sequential scheme in which the parsingprocess passes asyntax tree to the interpreter.2Fawcett's Systemic Functional Grammar \[8, 9\], his devel-opment of a HMlidayan SG.3POPLOG is a multi-language d velopment environmentcontaiifing incremental compilers for POPII (the base lan-guage), Prolog, Comnmn Lisp and Standard ML, an inte-grated editor and numerous support ools \[12\].4The COMMUNAL Project at University of ~Vales Col-lege of Cardiff (UWCC) Computational Linguistics Unit andLeeds University School of Computer Studies was sponsoredby RSRE Malvern, ICL and Longman.129whor71open+ingI|!the  big-, I -esl7oneF r"lFigure 1: A Typical Pal.5 Syntax Treement.This is not the first time a semantic interpreterhas been attempted for a large SG: Kasper \[13\] hasdeveloped a sentence analysis method (both pars-ing and interpretation together in my terminology)based on the NIGEL grammar.
In his approach theSG is compiled into a Functional Unification Gram-mar (FUG) (see Kay \[14\], a representation languagewith some systemic links) and then existing (but ex-tended) FUG parsing techniques are used to find asyntax tree plus an interpretation for a sentence.The REVELATION1 approach differs from this com-pilation method since the interpretation is achievedwithin a systemic framework.
No other SG-basedmodel (to my knowledge) has been used for bothgeneration and interpretation i  this way.Sys temic  GrammarFawcett's SG is a meaning-oriented model of lan-guage in which there is a large 'and/or' network ofsemantic features, defining the choices in meaningthat are available.
A syntax tree is generated bytraversing multiple paths (see later) through thisnetwork, making choices in meaning, and so defin-ing the meaning of the syntax tree to be generated.These choices fire realization rules which specify tilestructural implication of choosing certain features;they map the semantic hoices onto syntactic struc-tures and so transform the chosen meaning into asyntax tree (and hence a sentence) which expressesthat meaning.As an example of the syntax trees which are gemerated by Pol.5, consider Figure 1.
Systemic syn-tax trees consist of a number of levels of structurecalled units; the tree in Figure 1 has four: one clause(CI), two nominal groups (ngp) and a quantity-quality group (qqgp).
The components (immedi-ate constituents) ofeach unit are elements of struc-ture labelled to represent the functions fulfilled bythat component with respect o its unit.
For exam-ple: subject (S), main verb (M), second complement(C2) and ender (E) in the clause, superlative de-terminer (ds) and head (h) in the nominal groups,superlative deictic determiner (dds) and apex (a)in the quantity-quality group.
Some items may ex-pound more than one function in a unit, e.g.
"is"flmctions both as operator (O) and period-markingauxiliary (Xpd) in the clause and is labelled withthe conflated functional label O /Xpd.
Some ele-ments may be conflated with participant roles, e.g.
"who" is a subject playing the role of agent (At)and so is labelled S/Ag.
Similarly "the big+estone" is a complement playing the role of affected(Af) and hence is labelled C2/Af .
The immedi-ate constituent ofan element of structure is either alexical item (either a word or punctuation, in whichcase we say that the item expounds the element, e.g.the lexical item "one" expounds h), or a further unit(when we say a unit fills the element, e.g.
the unitqqgp fills ds).Ilaving introduced the type of syntax tree that isgenerated, let us now consider the actual process ofgeneration.
The key concept in SG is that of choicebetween small sets of meanings ( ystems of semanticfeatures).
For example, the NUMBER system containstile choices s ingular  and p lura l .
The choiee sys-tems in a systemic grammar are linked together by'and' and 'or' relationships to form a complex sys-tem network, specifying the preconditions and con-sequences of choosing features.
Consider the sys-tem network presented in Figure 2 (an excerpt fromeo 1.5 which contains ~450 systems, some contain-ing many more features than the binary systems il-lustrated in this example).
In the systemic nota-tion curly braces represent conjunctions and verti-cal bars represent exclusive disjunctions, i.e.
choice.The upper-case labels are the names of systems and130MOOD \] information__\[ directiveI retrospective05 __.)?
\] not-retrospectivekEXPl~CT I expect(15.4)_._\] not-expect k V, TYPI~ \]Ipas t-from- expect (15.7)not-past-from-expectimmediate-expect(15.6)unmarked-expect (1 S.5 )Figure 2: A fragment of the English 'tense' Networkdirectiveinformation,information,information,information,information,information,information,retros )strive, not-expect ..................................................................... "touch"retrol mctive, expect, immediate-expect ................................... "has beenahout to touch"retros ~sctive, expect, unmarked-expect .................................... "has heengoing to touch"not - re t rospect ive ,  expect, immediate-expect, past-from-expect .
.
.
.
.
.
.
.
.
'qsabout to have touched"not-retrospective, expect, immediate-expect, not-past-from-expect .
.
.
.
.
.
.
.
.
.
.
.
'qsahout to touch"not-retrospective, expect, unmarked-expect, past-from-expect .
.
.
.
.
.
.
.
.
.
.
"is going to have touched"not - re t rospect ive ,  expect ,  unmarked-expect ,  not -pas t - f rom-expect  .
.
.
.
.
.
.
.
.
.
.
.
.
.
"is going to touch'tFigure 3: Examples of 'tense' Selection Expressions and their realizations\]15.5 : unmarked-expect :G Q 73, G < "going to".15.6 : immediate-expect :G @ 73, G < "about to".15.7 : past-from-expe'ct :Xpf @ 85, Xpf < "have",if period-marked then Xpd <+ "en"else if unmarked-passive then Xp <+ "en".Figure 4: iRealisation Rulesthe lower-case labels are the names of the features inthose systems.
Each sjrstem has an entry condition;a precondition which must be met in order to en-ter the system and make a choice.
For example, toenter the RETR0 (retrOspectivity) and EXPECT (ex-pectation) systems, i n fo rmat ion  must have beenchosen.
To enter the PFE (past from expectation)system, both not - re t~ospect ive  and expect  musthave been chosen.
The :sets of choices in meaning de-fined by this network fr:agment are listed in Figure 3.Each set of choices is a se lect ion express ion,  i.e.a path (typically bifurcating) through the network.Associated with certain features are realizationrules.
In Figure 2, the bracketted numbers are point-ers to realization rules;i thus realization rule 15.7 istriggered by the feature past - f rom-expect .
A real-ization rule specifies the structural consequences ofchoosing a feature; they map the semantic hoicesonto syntactic structures.
Often conditions are in-volved; consider the realization rules shown in Fig-ure 4 (PG1.5 contains ~500 realization rules, manyof which are far more complex than these examples).The main types of rule are:* Components Rules: ElaN, stating that the el-ement E1 is at place II in the current unit(thus placing an ordering on the componentsof the unit currently being generated).
Theseplace numbers are relative rather than physi-cal; an element at place S states that the el-ement (if realized) will appear after elementswhose places are less than N and before thoseelements whose places are greater than 1I.Filling Rules: i s_ f i l led_by U, defining theunit U to be generated, e.g.
U=ngp.. Conflation Rules: F2 by F1, stating that thetwo functions F1 and F2 are conflated withone another in the current unit (e.g.
a Sub-ject which also functions as an Agent).. Exponence Rules: El<Word, stating that theelement El is expounded by an item (e.g.N<"open"), i.e.
exponents creates terminalconstituents.?
Re-entry Rules: fo r  F re_enter_at  f, stat-ing that the function F is filled by a unit whichis generated by re-entering the network a t thefeature :t.?
Preference Rules: fo r  F p re fer  I f .
.
.
\ ] ,131Selection Expressio~ ~for CI filling Z / t !
I, ' , \[ Subtaskial \[ Subtasklb\]Selection Expression~ \[Selection Expressio dfor ngp filling S | I for ngp filling C2 | AND-node AND-node OPv-node OR-nodeISelection Expressio~for qqgp filling as | Figure 6: AO Tree PrimitivesFigure 5: A Prototype Semantic Representationstating that when re-entering to generate aunit to fill the function F, the features \ [ : f .
.
.
\]should be preferred, either absolutely (i.e.
'pre-selection') or tentatively (expressed as apercentage).A sentence is generated by generating the syntaxtree for the sentence, the leaves in this tree beingthe words of the sentence.
The tree is generated bygenerating each of its units in a top-down fashion.Each unit is generated by a single pass through thesystem network.
This pass is expressed as a selec-tion expression which lists the features chosen onthat pass.
For example, suppose we wanted to gen-erate the sentence "the prisoner was going to havebeen killed".
The selection expression for the clausewould contain the features (plus many others, ofcourse):information, not-retrospective, expect,unmarked-expect, past-from-expect.Any realization rules associated with features in theselection expression are then executed.
Rules 15.5and 15.7 in Figure 4 generate a structure whoseleaves are " .
.
.
going to .
.
.
have .
.
.
(be)en .
.
. "
.
Forexample, to generate the clause structure in Fig-ure 1, the following realization statements were ex-ecuted:is_filled_by C1S@35, 0@37, M@94, C2@I06, E@200hg by S, Xpdby 0, Af by C2O<"is", N<"open", M<+"+ing", E<"?
"for Ag re_enter_at stereotypical_thingfor Af re_enter_at thingThe re-entry realization statements how whichfunctions are to be filled by re-entering the systemnetwork to generate further units.
Re-entry can bethought of as a recursive function call which gener-ates a lower layer of structure in the tree - -  buttypically with some of the choices 'preferred' viathe preference realization statement.
Thus the syn-tax tree in Figure 1 is generated with four passes:the clause is generated first, followed by the nomi-nal group filling the subject agent, followed by thenominal group filling the affected complement, andfinally the quantity-quality group filling the superla-tive determiner.The information required to generate a syntaxtree can be expressed as a tree of selection expres-sions; this is the semant ic  representat ion  for thesentence.
Each node in the  semantic representa-tion corresponds to a unit in the syntax tree andis labelled by the selection expression for that unit.For example, a semantic representation of the formshown in Figure 5 is needed to generate the syntaxtree in Figure 1.In terpret ing  a Syntax  TreeGiven a syntax tree, the aim of interpretation is tofind the semantic representation which would gener-ate that tree.
This semantic representation i cludesall the features that are needed to generate the treeand so defines the 'meaning content' of the syntaxtree.In the process of generation, a syntax tree is gen-erated by generating its units; in the process of in-terpretation a syntax tree is understood by inter-preting all of its units in a precisely analogous way.Thus a unit interpretation is the selection expres-sion which generated that unit.
In general there canbe more than one selection expression for any givenunit, since the same syntactic structure can havemore than one meaning, just as a whole sentencecan have more than one meaning.
The potentialunit interpretations are defined by constructing anAO tree ~ whose goal (root) is to prove unit realiza-tion, i.e.
prove that the unit can be generated.
Eachpotential solution of this AO tree defines a poten-5 AO (AND/OR) trees provide ameans for describing taskdecomposition.
These structures were first proposed by Sla-gle \[21\] and have since been used in a variety of applicationsincluding symbolic integration and theorem proving (Nilsson\[18\] lists a number of applications with references).
The AOtree notation used throughout this paper is illustrated in Fig-ure 6 with leaves - -  terminal tasks which cannot be decom-posed any further - -  being represented asbold nodes.132IRealisation ofDescriptor 1Unit Interpret, atio dII Unit  ea|isationl\[ Realis'ation of Realisation of \[Descriptor i \[ I .
.
.
.
.
.
.
.
Descriptor n IFigure 7: Decomposition of Unit Interpretationtial selection expression for the unit.
The semanticrepresentation for the tree is given by some feasiblecombination of the :potential selection expressionsfor each unit in the: syntax tree.
Not all combina-tions of selection expressions are feasible since thegeneration passes, alnd hence the selection expres- isions, are interdepelident.
Thus:?
A pass is dependent upon previous, higherpasses througl~ the use of the unary booleanoperators on_.p~ev_pass and on_f i rs t_pass  inconditions inside realization rules.
These op-erators are usdd to test the values of featuresin passes for ~igher units in the syntax tree.For example !the condition on..:first_l~asswritten is only true if uritten is selected onthe first pass.?
Subsequent passes are dependent upon thepre-sclections that are made with the pref-erence rules.
For example, when gen-erating a que:stion (such as that in Fig-ure I) it is n#cessary to pre-select the fea-ture seeking-'specification-of-thing forthe nominal group which fills the subjectagent.
This t ensures that a Wh-subject is gen-erated.Decomposing Unit InterpretationThe first step in unit interpretation is the de-composition of the :unit's structure into a set ofdescriptors; 6 each describing a different aspect ofthe unit's structure.
For example, the descriptorsrequired to describe the clause in Figure 1 are:unit  (c1)e l (1 ,s ) ,  e l (2 ,0) ,  el(3,M), e1(4,C2), el(5,E)conf(S,Ag), conf(O,Xpd), conf(C2,Af)stem(O, "is"), .stem(M,"open"), stem(E, "?
")suff ix (M, "+ing" )6A descriptor is simply an abstract description of a real-ization; it attempts to ~apture the effect of the realizationstatements without using any of their syntax.re_enter(S,Ag), re_enter(C2,Af)Tile un i t  descriptor specifies the name of the cur-rent unit, the e l  descriptor specifies the order-ing of the component elements, the ?on:f descrip-tor specifies the conflation relationships, the stemand su f f ix  descriptors pecify the items expound-ing lexical elements, and the re_enter  descriptorspecifies the non-terminal elements requiring a sub-sequent pass to generate a unit to fill them.Decompos i t ion  1 \[Unit Interpretation\] Unit in-terpretation is achieved by proving that the unit canbe realized.
To do this, the unit's structure is de-scribed, using a set of descriptors, and hence unitrealization is decomposed into a number of separaterealizations, with one realization for each descriptor.Thus unit interpretation is achieved by realizing alldescriptors (hence realizing the whole unit).
Thisdecomposition is illustrated in Figure 7.Each descriptor is realized by some realizationstatement (which will appear somewhere in the re-alization rules).
There is a simple mapping betweendescriptors and suitable realization statements.
Forsome descriptors there is only a single suitable re-alization statement: for example, un i t (U)  is onlyrealized by the statement is_filled_by O. Otherdescriptors can be realized by a number of differ-ent realization statements: for example, e l ( i ,E l i )is realized by statements of the form EliQN, wherethe place N is greater than the places for El i_i  andless than the places for Eli+l.
This ensures correctordering of the constituent elements.For each descriptor, a search of the realizationruh,s is performed to find any statements which re-alize the descriptor.
For example, for the descrip-tor un i t (e l )  we would search for all occurrencesof i s _ f i l l ed .by  Cl in the realization rules.
Afterthe search is complete there will be a set of poten-tially active rules for each descriptor, with each po-tentially active rule containing a suitable statement(or possibly more than one suitable statement) hat133Descriptor Realisation \]I\[ Suitable Statementsl' I ' I I J I t. I I r .
.
.
.
.
.
.
.
.
3IOccurrencel I .
.
.
.
.
.
.
.
.
.
.
.
.
.
IOccurrenceil  .
.
.
.
.
.
.
.
.
.
.
.
.
IOccurrencen \]' \] 'f - - -  - - J "  - - - -  "I f -  -- - - L  -- -- - I, , I I , ,I  ule  ctivatioo I I O.e P,eco.ditioo holds II l I\[ Precond 1 = T\] .
.
.
.
I P reco-~m= W IFigure 8: Decomposition of Descriptor Realisationwould realize the descriptor.
Associated with eachpotentially active rule is a set of preconditions, oneprecondition for each suitable statement.
(If thestatement has no precondition, then the set of pre-conditions will be empty.
)Decompos i t ion  2 \[Descriptor Realization\] Prov-ing that a descriptor can be realized is decomposedinto (i) activating any one of its potentially activerules, and (ii) proving that any one of the precondi-tions associated with that rule holds true (assumingthere are any preconditions).
This decomposition isillustrated in Figure 8.What is required for a rule to be active?
A rulecan only be active if there is a feasible path (feasi-ble in the sense that all features on that path canbe selected) through the system network to a fea-ture associated with that rule.
There will be atleast one potential path to each rule; 'at least' isrequired since a rule can have more than one poten-tim path if (i) it is associated with more than onefeature or (ii) it is dependent upon a disjunctive n-try condition.
Thus the potential paths to a rulecan be represented as a boolean expression; i.e.
asan exclusive disjunction of conjunctions:pathl xor path2 xor ... xor pathNwhere the path components are conjunctions com-posed from the features in each potential path andthe exclusive disjunction represents choice betweenpotential paths.
This expression can be simplifiedinto an expression of the form:common and(var iant l  xor .
.
.
xor var iantN)where common is a conjunction of features thatis common to all potential paths and var iant l?
.
.
var iantN are the conjunctions of features pecu-liar to each potential path?
This expression can beconsidered as a precondition for rule activation andso must be true for the rule to be active.Decompos i t ion  3 \[Rule Activation\] Rule Activa-tion is achieved by activating one of the potentialpaths to that rule.
The potential paths can be de-composed into a common component and a numberof variant components.
One potential path is activeif and only if the common component is active andits variant component is also active.
This decompo-sition is illustrated in Figure 9.At this stage in the decomposition all tip nodesare problems of the form 'boolean expression = T',i.e.
satisfiability problems.
In order to define howsatisfiability problems are solved, the concept of atruth function must first be introduced.
A truthfunction is a mapping between features and a threevalued logic (with truth values false, true and unde-fined) which defines the value of each feature; trueindicating selected and false indicating not selected?Tile problem of satisfiability for a boolean expres-sion involves finding a truth function such that theboolean expression evaluates ?
to be true, such atruth function is called a satisfying truth functionfor tile boolean expression.
Unfortunately, this isall intractable problem since a disjunction with ndisjuncts can have 3" -1  potential satisfying truthfunctions, i.e.
the task is exponential in problem size(in fact, the problem of satisfiability has the honorof being the first NP-Complete problem; see Gareyand Johnson \[11\]).
As is the case with inherently in-tractable problems; it is not worth searching for anefficient, exact algorithm to perform the task; it is7Evaluation is performed with respect to Kleene's threevalued logic \[15\].134, II Oo~on Path is Active I' I1 ?
?~?n  ?
?rid-- ~1Rule Activation \[I\[ Path Activation \[II\[ One Variant is Active \[I '0 II v~ian~ ~ is Active I .
.
.
.
.
.
.
.
I Variant n i. Aot've II II 0ondi  = ?
I I~ond n = ?
IFigure 9: Decomposition of Rule ActivationInterpret el lII Re~|i'e \[CI''''\] I!.
.
.
.
.
.
.
.r -  \[,!I ' Only O~currence-7\[ ~on.ru;ot.~.
II!\[ P .
.
.
.
nditions\[I oo, o?o~ked--,qI I I\[ First Occu .
.
.
.
.
.
\]!\[ Rule2.04 \]' I ~I ~.?
?t-p,-.-~ .
.
.
.
.
I III II s .
.
.
.
d O .
.
.
.
.
.
* ' "  I| I I\[ Rule 6-21 IIFigure 10: Part of the AO Tree for Clause Interpretationmore appropriate to:consider a less ambitious prob-lem.
Consider the problem of partial satisfiability: itis essentially the salfie as satisfiability except hat itdoes not attempt o satisfy disjunctive components(since it is these components which make the satis-fiability problem 'hard').
It requires a redefinitionof a truth function: in  partial satisfiability a truthfunction is a mappin~g between boolean expressions(rather than simply features) and truth values.
Forexample, the expres?ion (a or b) and ?
and notd is partially satisfied by the fimction v:v : v(a or b )=T,  v (c )=T,  v (d )=FSince disjunctions are effectively ignored, there isa single unique partially satisfying truth functionfor any boolean expression.
Thus tip nodes labelledwith satisfiability problems are (partially) decom-posed into a numbei, of and-nodes; each and-nodebeing labelled by a feature (possibly negated) or adisjunction which must be true.
As an example ofa fldly decomposed AO tree for unit interpretation,consider the skeleton tree in Figure 10 which de-fines the potential interpretations of the clause inFigure 1.A potential solution of an AO tree is specified bya subset of the leaves that are necessary for the roottask to be achieved.
A backtracking search is usedto generate potential solutions: since the AO tree isfinite, it is possible to inspect the structure of thetree and order the search in such a way so that theminimum amount of backtracking is performed, s Afeasible interpretation for a unit is one of the po-tential solutions in which the statements labellingthe leaves are all consistent.
There are two ways inwhich a leaf statement may be inconsistent:s The search scheme involves incrementally evaluating andpruning the AO tree.
Full details can be found in O'Donoghue\[19\], an in-depth report on the interpreter.135Selection Expression for CI filling ZI s itttat ion, congru.entt-sit, in.f?rrnatlon, seeker, no.cor~-modMity ,  I per loo- rnarkea j  a lng\ [e-ou~l( ler -sth ,  matsr i3 | ,  two-role.process, I agent-c~ntre( l .
t rp ,  lUS-Sllecte~, ~tl~ent.~-th~me-mat.aou\[ht,  I oVert.~ffected:a.U, ogerl.~Hected.s~l.pr,~sentecl~ qver t?
affe~Yed, af- u nt hernat ised,  lc~nglng-colangujr&tion&J-st at e, c nangtng-  posit Lone&J- con f igurat ion , l cnanglng.state-ol .openness,  tm &k e. opt  n ,~.ge nt.
;5- t h e rne- a.f" JSelection Expression f(~r ngp fillings Selection Expllession for ng p filling C2I s ' th ink .
rgcnt - th in .~stereotyp i~.
l - th ing ,\[ th ing K , .
t~aing~stereotypic&l - t , i ,g ,  ' .
.
.
.
.
.
.
.
.
.
.
.I l l  putsrdex, s'~ekto,g-spec'~fi~&tmn-Ol-thtng, outslcter, cffltur~l-c|~s~stPc~.ttpn-recov~r&.vLe, ?
I nurn&n|ty.spec|neo.sst,  human-ss t ,  peTson-sat count lsn .ccr ,  se lecteo- l rom.Dy-super l~t lv|z&t|on I !Sclection expression for qqgp filling ds\[ qpal i ty ,  qua l i ty :o f .
th ing,  presentinK-qu~l.llty.
?f-\[.hi~g, I olmerlSlOrl-quallty, SIZe, big, not .po~enttal ly-oen&vloural -qu&l i ty .
IFigure 11: A Semantic Representation found by REVELATION I?
The statements logically contradict, for exam-ple: leaves labelled a = T and a = F. Orb or e=Tandb=F,e=F.?
The statements ystemically contradict, forexample: a = T and b = T when a and bare members of the same choice system (fromwhich at most one feature can be chosen).The leaf statements in a feasible solution definewhich features must be true (i.e.
selected) for theunit to be realized, i.e.
they specify a selection ex-pression for the unit.Resu l ts  and  D iscuss ionThe semantic representation found by REVELATION 1for the syntax tree in Figure 1 is presented in Fig-ure 11.
We can get a flavor of the semantic repre-sentation by identifying key features: the sentenceis a question (information, seeker) about an on-going event (per iod-marked) which involves open-ing something (make-open).
It is a person that weare seeking (person-ss t ) .
The thing that is beingopened is selected by superlativization (in fact it isthe biggest) and it is recoverable from the previousdiscourse (the "one" referring to something that haspreviously been mentioned).Unfortunately this semantic representation is in-complete.
One of the factors contributing to this in-completeness is that of 'unrealized' selections: theseare features which have no associated realization(e.g.
not-expect in Figure 2).
Consider tile wayin which interpretation works: it tries to prove thatobserved realizations have taken place and in so do-ing infer the features that were selected.
However,if a realization does not take place as a (not nec-essarily direct) result of a selection, then there isno way to infer that the unrealized feature was se-lected.
Consider the POLARITY system where thereis a choice between pos i t ive  and negat ive .
Thepos i t ive  choice is unrealized where as negat ive  isassociated with the realization rule:17:negative:do_support,0 <+ "n't".Suppose we have a positive clause, "Who is openingthe biggest one?"
(the example sentence from Fig-ure 1).
There is no way to tell from the structure ofthe clause that the sentence is positive.
Howeverby inspecting the realization rule associated withnegative we find that the (unconditional) state-ment 0<+"n ' t "  can never be active as this wouldrealize the sentence "Who isn't opening the biggestone?".
Thus rule 17 can never be active and sonegat ive  can't be chosen, hence pos i t ive  must bechosen.
Thus by a process of eliminating featureswhich cannot be true, it is possible to determineunrealized features.
REVELATION2 (currently underdevelopment) will attempt to implement his pro-cess of elimination by moving forward through thesystem network (after a partial semantic represen-tation has been obtained) systematically verifyingany realization rules that it meets, eliminating fea-tures that cannot be chosen and so possibly inferringsomething about unrealized features which need tobe chosen.The other factor contributing to incompletenessis the definition of partial satisfiability.
Some fea-tures in the network do not have realization rulesattached to them: typically these appear as condi-tions on statements in realization rules.
However,if any of these features appear in disjunctive con-ditions or disjunctive ntry conditions to systems,then nothing can be inferred about their values incethe definition of partial satisfiability ignores all dis-136junctions.
This problem can only be overcome bysearching for (exact) satisfying truth functions fromwhich all feature values can be inferred.
REVELA-TION2 attempts to solve this problem by deferringthe search for exact satisfying truth functions un-til after a partial in,terpretation has been obtained:the partial interpretation is obtained as for REVE-LATION1, and then any disjunctions that have beenignored while obtaining this interpretation are ex-actly satisfied to try and fill the gaps in the partialinterpretation.In addition to the work on the next generation ofinterpreter, some work is being carried out on P(~ 1.5to make it more efficient; it is being tuned for inter-pretation by simplifying and normalizing conditionsin the realization rules.
This involves 'tightening up'the conditions by su~bstituting xor for or  whereverpossible and reducin'g the scope of any valid disjunc-tions that remain (eig.
a and (b or c) rather thana and b or a and c).Clearly efficiency is a problem, since the AO treesexplode into or-nod:es, through the use of (i) dis-junctive entry conditions in the system network and(ii) disjunctive conditions in the realization rules.
It \[has been proved (Brew \[3\]) that systemic classifica-tion is NP-Hard and is thus inherently intractable.This led to the choice of partial satisfiabillty ratherthan exact satisfiablility (which itself is NP-Ilard)in REVELATIONI, and the development of an effi-cient technique for isearching the AO trees whichutilizes incremental ievaluation and pruning to re-duce the number of backtracking points (full detailsin O'Donoghue \[19\])i The delayed use of exact satis-fiability being inves!igated in REVELATION2 is sim-ilar to Brew's 'partial' algorithm for checking sys-temic descriptions.
IBrew's checking algorithm hastwo stages, the first i being a simplification stage inwhich all disjunctive:entry conditions are eliminatedfrom the system netivork by replacing them with auniquely generated feature.
The resultant simplifiednetwork can then be searched efficiently.
The secondstage involves checking all of the features generatedin the first stage, each generated feature referring toa disjunctive ntry c~ondition.
IIere also we find adelaying tactic in which disjunctions are satisfied aslate as possible in the search.Although no theoretical calculations as to thecomplexity of the REVELATION1 method and Pc, l.5have been nndertaken, we can get a feel for the scaleof the problem by considering the amount of CPUtime that was needed to obtain the semantic repre-sentation of Figure 1!1.
On a SPARCstation 1 with16M this task required ,~25 CPU seconds, with thistime being halved on a Sun 4/490 with 32M.
Whenreading these timings bear in mind that REVELA-TION1 is coded in POPLOG languages which are in-crementally compiled into an interpreted virtual ma-chine code.ConclusionsREVELATION1 has demonstrated that Fawcett's SGis a bi-directional formalism, although in the caseof PG 1.5, some reorganization was required to makeit run ill reverse.
The main problem in reversing aSG seems to be that systemic grammars are writtenfrom a predominantly text-generation viewpoint.
Indeveloping their grammars ystemic grammariansare concerned with how the grammar will generaterather than its suitability for interpretation.
Forinstance, special care ought to be taken when ex-pressing conditions in realization rules: writing axor b rather than a or b can be a godsend to aninterpreter.
Similarly, simplifying and normalizingconditions o that they are as simple and specific aspossible is a great aid to interpretation.
It reducesthe search space and hence speeds up interpretation- -  even though, from a generative point of view, itmay make more sense to express a condition in a'long winded' fashion that captures the generaliza-tion the linguist is attempting to make.Fawcett states (private communication) that indeveloping his version of SG (which is different ina number of ways - -  especially in the realizationcomponent - -  from the NIGEL grammar of Mannand Matthiessen) he always had in mind its poten-tial for reversibility.
Perhaps the surprising thingis not that modifications in GENESYS are indicatedby work on REVELATION, but how few modificationsappear to be required.
Clearly, the need now is forclose collaboration between the builders of the suc-cessor versions of GENESYS and and the successorversions of REVELATION.
Current research as pre-cisely this goal; and we shall report the results indue course.REVELATION1 combined with Fawcett's SG ap-pears to be a step in the right direction towardsa hi-directional systemic grammar.
REVELATION2may take a step closer.
But a bi-directional systemicgrammar will only be achieved when interpretation-minded people and generation-minded people get to-gether and collaborate in developing such a gram-mar.137AcknowledgementsI would like to thank Eric Atwell and Clive Souter(Leeds University) for their valuable contributionsto earlier drafts of this paper and Robin Fawcett(UWCC) for his comments and suggestions on thefinal version.Re ferences\[1\] Rosalind Barrett, Allan Ramsay, and AaronSloman.
POPII: a Practical Language for Ar-tificial Intelligence.
Ellis tlorwood, Chichester,1985.\[2\] James D. Benson and William S. Greaves, ed-itors.
Systemic Perspectives on Discourse: se-lected papers from the 9th International Sys-temic Workshop.
Ablex, London, 1985.\[3\] Chris Brew.
"Partial Descriptions and SystemicGrammar".
In Proceedings of the 13th Interna-tional Conference on Computational Linguis-tics (COLING '90), 1990.\[4\] Christopher S. Butler.
Systemic Linguistics:Theory and Applications.
Batsford, London,1985.\[5\] William F. Clocksin and Chris S. Mellish.
Pro-gramming in Prolog.
Springer Verlag, 3rd edi-tion, 1987.\[6\] Anthony Davey.
Discourse Production: AComputer Model of Some Aspects of a Speaker.Edinburgh University Press, 1978.\[7\] David R. Dowty, Lauri Karttunen, andArnold M. Zwicky, editors.
Natural LanguageParsing: psychological, computational nd the-oretical perspectives.
Studies in Natural Lan-guage Processing.
Cambridge University Press,1985.\[8\] Robin P. Fawcett.
Cognitive Linguistics andSocial Interaction, volume 5 of Exeter Linguis-tic Studies.
Julius Groos Verlag, Heidlberg,1980.\[9\] Robin P. Fawcett.
"Language Generation asChoice in Social Interaction".
In Zock andSubah \[24\], chapter 2, pages 27-49.\[10\] Robin P. Fawcett and Gordon H.
Tucker.
"Demonstration f GENESYS: a very large se-mantically based Systemic Functional Gram-mar".
In Proceedings of the 13th Interna-tional Conference on Computational Linguis-tics (COLING '90), 1990.\[11\] Michael R. Garey and David S. Johnson.
Com-puters and Intractability: A Guide to the The-ory of NP-Completeness.
Freeman, San Fran-cisco, 1979.\[12\] John Gibson.
"AI Programming Environmentsand the POPLOG System".
In Yazdani \[23\],chapter 2, pages 35-47.\[13\] Robert T. Kasper.
"An Experimental Parserfor Systemic Grammars".
In Proceedings ofthe lgth International Conference on Computa-tional Linguistics (COLING '88), August 1988.Also available as USC/Information Sciences In-stitute Reprint RS-88-212.\[14\] Martin Kay.
"Parsing in Functional UnificationGrammnar".
In Dowty et al \[7\], chapter 7, pages251-278.\[15\] Stephen C. Kleene.
Introduction to Metamath.ematics.
North-Holland, 1952.\[16\] William C. Mann and Christian M. I. M.Matthiessen.
"NIGEL: A Systemic Grammarfor Text Generation".
In Benson and Greaves\[2\].
Also available as USC/Information SciencesInstitute Reprint RS-83-105.\[17\] Christian M. I. M. Matthiessen and John A.Bateman.
Text Generation and Systemic-Functional Linguistics: experiences from En-glish and Japanese.
Pinter, London, 1991.
(inpress).\[18\] Ntis Nilsson.
Principles of Artificial Intelli-gence.
Springer Verlag, 1983.\[19\] Tim F. O'Donoghue.
"The REVELATION1 Se-mantic Interpreter".
COMMUNAL Report 22,School of Computer Studies, University ofLeeds, 1991.\[20\] Tim F. O'Donoghue.
"The Vertical StripParser: a lazy approach to parsing".
Report91.15, School of Computer Studies, Universityof Leeds, 1991.\[21\] J. R. Slagle.
"A Heuristic Program that SolvesSymbolic Integration Problems in FreshmanCalculus".
In E. Feigenbaum and J. Feldman,editors, Computers and Thought, pages 191-203.
McGraw=Hill, New York, 1963.\[22\] Terry Winograd.
Language as a Cognitive Pro-cess, Volume I: Syntax.
Addison Wesley, 1983.\[23\] Masoud Yazdani, editor.
Artificial h~telligence:principles and applications.
Chapman Hall,1986.\[24\] Michael Zock and Gerard Subah, editors.
Ad-vances in Natural Language Generation (Vol-ume 2).
Pinter, London, 1988.138
