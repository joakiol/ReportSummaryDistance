A MARKOV LANGUAGE LEARNING MODELFOR F IN ITE  PARAMETER SPACESPartha Niyogi and Robert C. BerwickCenter for Biological and Computational LearningMassachusetts Institute of TechnologyE25-201Cambridge, MA 02139, USAInternet: pn@ai.mit.edu, berwick@ai.nfit.eduAbstractThis paper shows how to formally characterize lan-guage learning in a finite parameter space as a Markovstructure, hnportant new language learning results fol-low directly: explicitly calculated sample complexitylearning times under different input distribution as-sumptions (including CHILDES database language in-put) and learning regimes.
We also briefly describe anew way to formally model (rapid) diachronic syntaxchange.BACKGROUND MOTIVATION:TR IGGERS AND LANGUAGEACQUIS IT IONRecently, several researchers, including Gibson andWexler (1994), henceforth GW, Dresher and Kaye(1990); and Clark and Roberts (1993) have modeledlanguage learning in a (finite) space whose grammarsare characterized by a finite number of parameters or n-length Boolean-valued vectors.
Many current linguistictheories now employ such parametric models explicitlyor in spirit, including Lexical-Functional Grammar andversions of HPSG, besides GB variants.With all such models, key questions about samplecomplexity, convergence time, and alternative model-ing assumptions are difficult to assess without a pre-cise mathematical formalization.
Previous research asusually addressed only the question of convergence inthe limit without probing the equally important ques-tion of sample complexity: it is of not much use that alearner can acquire a language if sample complexity isextraordinarily high, hence psychologically implausible.This remains a relatively undeveloped area of languagelearning theory.
The current paper aims to fill thatgap.
We choose as a starting point the GW TriggeringLearning Algorithm (TLA).
Our central result is thatthe performance of this algorithm and others like it iscompletely modeled by a Markov chain.
We explorethe basic computational consequences of this, includingsome surprising results about sample complexity andconvergence time, the dominance of random walk overgradient ascent, and the applicability of these results toactual child language acquisition and possibly languagechange.Background.
Following Gold (1967) the basic frame-work is that of identification in the limit.
We assumesome familiarity with Gold's assumptions.
The learnerreceives an (infinite) sequence of (positive) example sen-tences from some target language.
After each, thelearner either (i) stays in the same state; or (ii) movesto a new state (change its parameter settings).
If aftersome finite number of examples the learner converges tothe correct arget language and never changes its guess,then it has correctly identified the target language inthe limit; otherwise, it fails.In the GW model (and others) the learner obeys twoadditional fundamental constraints: (1) the single.valueconstraint--the learner can change only 1 parametervalue each step; and (2) the greediness constraint--ifthe learner is given a positive example it cannot recog-nize and changes one parameter value, finding that itcan accept the example, then the learner retains thatnew value.
The TLA essentially simulates this; see Gib-son and Wexler (1994) for details.THE MARKOV FORMULATIONPrevious parameter models leave open key questions ad-dressable by a more precise formalization as a Markovchain.
The correspondence is direct.
Each point i in theMarkov space is a possible parameter setting.
Transi-tions between states stand for probabilities b that thelearner will move from hypothesis tate i to state j.As we show below, given a distribution over L(G), wecan calculate the actual b's themselves.
Thus, we canpicture the TLA learning space as a directed, labeledgraph V with 2 n vertices.
See figure 1 for an example ina 3-parameter system.
1 We can now use Markov theoryto describe TLA parameter spaces, as in lsaacson and1GW construct an identical transition diagram in thedescription of their computer program for calculating lo-cal maxima.
However, this diagram is not explicitly pre-sented as a Markov structure and does not include transitionprobabilities.171Madsen (1976).
By the single value hypothesis, the sys-tem can only move 1 Hamming bit at a time, either to-ward the target language or 1 bit away.
Surface stringscan force the learner from one hypothesis tate to an-other.
For instance, if state i corresponds to a gram-mar that generates a language that is a proper subsetof another grammar hypothesis j, there can never bea transition from j to i, and there must be one from ito j .
Once we reach the target grammar there is noth-ing that can move the learner from this state, since allremaining positive evidence will not cause the learnerto change its hypothesis: an Absorb ing  State  (AS)in the Markov literature.
Clearly, one can conclude atonce the following important learnability result:Theorem 1 Given a Markov chain C corresponding toa GW TLA learner, 3 exactly 1 AS (corresponding tothe target grammar/language) iff C is learnable.Proof.
?::.
By assumption, C is learnable.
Now assumefor sake of contradiction that there is not exactly oneAS.
Then there must be either 0 AS or > 1 AS.
In thefirst case, by the definition of an absorbing state, thereis no hypothesis in which the learner will remain for-ever.
Therefore C is not learnable, a contradiction.
Inthe second case, without loss of generality, assume thereare exactly two absorbing states, the first S correspond-ing to the target parameter setting, and the second S ~corresponding to some other setting.
By the definitionof an absorbing state, in the limit C will with somenonzero probability enter S I, and never exit S I. ThenC is not learnable, a contradiction.
Hence our assump-tion that there is not exactly 1 AS must be false.=?..
Assume that there exists exactly 1 AS i in theMarkov chain M. Then, by the definition of an absorb-ing state, after some number of steps n, no matter whatthe starting state, M will end up in state i, correspond-ing to the target grammar.
|Coro l la ry  0.1 Given a Markov chain corresponding toa (finite) family of grammars in a G W learning sys-tem, if there exist 2 or more AS, then that family is notlearnable.DERIVAT ION OF TRANSIT IONPROBABIL IT IES  FOR THEMARKOV TLA STRUCTUREWe now derive the transition probabilities for theMarkov TLA structure, the key to establishing sam-ple complexity results.
Let the target language L~ beL~ = {sl, s2, s3, ...} and P a probability distribution onthese strings.
Suppose the learner is in a state corre-sponding to language Ls.
With probability P(sj),  itreceives a string sj.
There are two cases given currentparameter settings.Case I.
The learner can syntactically analyze the re-ceived string sj.
Then parameter values are unchanged.This is so only when sj ?
L~.
The probability of re-maining in the state s is P(sj) .Case I I .
The learner cannot syntactically analyzethe string.
Then sj ~ Ls; the learner is in state s,and has n neighboring states (Hamming distance of 1).The learner picks one of these uniformly at random.
Ifnj of these neighboring states correspond to languageswhich contain sj and the learner picks any one of them(with probability n j /n) ,  it stays in that state.
If thelearner picks any of the other states (with probability( n - n j ) /n)  then it remains in state s. Note that njcould take values between 0 and n. Thus the probabilitythat the learner emains in state s is P(sj)((  n -n j  )/n).The probability of moving to each of the other nj statesis P(s j ) (n j /n) .The probability that the learner will remain in itsoriginal state s is the sum of the probabilities of thesetwo cases :  ~,jEL, P(sj)  + E, jCL,(1 - nj /n)P(s j ) .To compute the transition probability from s tok, note that this transition will occur with proba-bility 1/n for all the strings sj E Lk but not inL~.
These strings occur with probability P(sj)  eachand so the transition probability is:P\[s ~ k\] =~,jeL,, , j?L, , , jeLk (1/n)P(s i )  ?Summing over all strings sj E ( Lt N Lk ) \ L, (set dif-ference) it is easy to see that sj ?
( Lt N Lk ) \ Ls ?~ sj ?
(L, N nk) \ (L, n Ls).
Rewriting, we have P\[s ---* k\] =~, je(L,nLk)\(L,nL.
)(1/n)P(s j ) .
Now we can computethe transition probabilities between any two states.Thus the self-transition probability can be given as,P\[s --, s\] = 1-~-'~ k is a neighboring state o f ,  P\[s ---, k\].Example.Consider the 3-parameter natural language system de-scribed by Gibson and Wexler (1994), designed to coverbasic word orders (X-bar structures) plus the verb-second phenomena of Germanic languages, lts binaryparameters are: (1) Spec(ifier) initial (0) or final (1);(2) Compl(ement) initial (0) or final (1); and Verb Sec-ond (V2) does not exist (0) or does exist (l).
Possi-ble "words" in this language include S(ubject), V(erb),O(bject), D(irect) O(bject), Adv(erb) phrase, and soforth.
Given these alternatives, Gibson and Wexler(1994) show that there are 12 possible surface stringsfor each ( -V2)  grammar and 18 possible surface stringsfor each (+V2) grammar, restricted to unembedded or"degree-0" examples for reasons of psychological plau-sibility (see Gibson and Wexler for discussion).
For in-stance, the parameter setting \[0 1 0\]= Specifier initial,Complement final, and -V2,  works out to the possi-ble basic English surface phrase order of Subject-Verb-Object (SVO).As in figure 1 below, suppose the SVO ("English",setting #5=\[0 1 0\]) is the target grammar.
The figure'sshaded rings represent increasing Hamming distancesfrom the target.
Each labeled circle is a Markov state.Surrounding the bulls-eye target are the 3 other param-eter arrays that differ from \[0 1 0\] by one binary digit:e.g., \[0, 0, 0\], or Spec-first, Comp-first, -V2,  basic orderSOV or "Japanese".172j:.-.-i \ii":':!i<::::::.
:: .
.
.
.
.
.
.
:::.~-.~-':~Figure 1: The 8 parameter settings in the GW example, shown as a Markov structure, with transition probabilitiesomitted.
Directed arrows between circles (states) represent possible nonzero (possible learner) transitions.
The targetgrammar (in this case, number 5, setting \[0 1 0\]), lies at dead center.
Around it are the three settings that differfrom the target by exactly one binary digit; surrounding those are the 3 hypotheses two binary digits away from thetarget; the third ring out contains the single hypothesis that differs from the target by 3 binary digits.173Plainly there are exactly 2 absorbing states in thisMarkov chain.
One is the target grammar (by defini-tion); the other is state 2.
State 4 is also a sink thatleads only to state 4 or state 2.
GW call these twonontarget states local maxima because local gradientascent will converge to these without reaching the de-sired target.
Hence this system is not learnable.
Moreimportantly though, in addition to these local maxima,we show (see below) that there are other states (notdetected in GW or described by Clark) from which thelearner will never reach the target with (high) positiveprobability.
Example: we show that if the learner startsat hypothesis VOS-V2,  then with probability 0.33 inthe limit, the learner will never converge to the SVOtarget.
Crucially, we must use set differences to buildthe Markov figure straightforwardly, as indicated in thenext section.
In short, while it is possible to reach "En-glish"from some source languages like "Japanese," thisis not possible for other starting points (exactly 4 otherinitial states).It is easy to imagine alternatives to the TLA thatavoid the local maxima problem.
As it stands thelearner only changes a parameter setting if that changeallows the learner to analyze the sentence it could notanalyze before.
If we relax this condition so that underunanalyzability the learner picks a random parameterto change, then the problem with local maxima disap-pears, because there can be only 1 Absorbing State, thetarget grammar.
All other states have exit arcs.
Thus,by our main theorem, such a system is learnable.
Wediscuss other alternatives below.CONVERGENCE T IMES FOR THEMARKOV CHAIN  MODELPerhaps the most significant advantage of the Markovchain formulation is that one can calculate the numberof examples needed to acquire a language.
Recall itis not enough to demonstrate convergence in the limit;learning must also be feasible.
This is particularly truein the case of finite parameter spaces where convergencemight not be as much of a problem as feasibility.
Fortu-nately, given the transition matrix of a Markov chain,the problem of how long it takes to converge has beenwell studied.SOME TRANSIT ION MATRICES ANDTHEIR  CONVERGENCE CURVESConsider the example in the previous ection.
The tar-get grammar is SVO-V2 (grammar ~5 in GW).
Forsimplicity, assume a uniform distribution on L5.
Thenthe probability of a particular string sj in L5 is 1/12 be-cause there are 12 (degree-0) strings in L~.
We directlycompute the transition matrix (0 entries elsewhere):L1L2L3L4L5L6L7LsL1J.2L2 L3 L4 L5 L6 L7 Ls?
?6 33_ Z !4 ~ 6 !12 1211_ 52_ 1__12 36 9States 2 and 5 are absorbing; thus this chain containslocal maxima.
Also, state 4 exits only to either itselfor to state 2, hence is also a local maximum.
If T isthe transition probability matrix of a chain, then thecorresponding i, j element of T m is the probability thatthe learner moves from state i to state j in m steps.For learnability to hold irrespective starting state, theprobability of reaching state 5 should approach 1 as mgoes to infinity, i.e., column 5 of T m should contain alll's, and O's elsewhere.
Direct computation shows thisto be false:L1L2L3L4LsL6L7LsL1 L2 L3 L4 L5 L6 L7 Ls!31131We see that if the learner starts out in states 2 or 4,it will certainly end up in state 2 in the limit.
Thesetwo states correspond to local maxima grammars in theGW framework.
We also see that if the learner startsin states 5 through 8, it will certainly converge in thelimit to the target grammar.States 1 and 3 are much more interesting, and con-stitute new results about this parameterization.
If thelearner starts in either of these states, it reaches thetarget grammar with probability 2/3 and state 2 withprobability 1/3.
Thus, local maxima are not the onlyproblem for parameter space learnability.
To our knowl-edge, GW and other researchers have focused exclu-sively on local maxima.
However, while it is true thatstates 2 and 4 will, with probability l, not converge tothe target grammar, it is also true that states l and3 will not converge to the target, with probability 1/3.Thus, the number of "bad" initial hypotheses i signif-icantly larger than realized generally (in fact, 12 out of56 of the possible source-target grammar pairs in the 3-parameter system).
This difference is again due to thenew probabilistic framework introduced in the currentpaper.174Figure 2 shows a plot of the quantity p(m) =min{pi(rn)} as a function of m, the number of exam-ples.
Here Pi denotes the probability of being in state 1at the end of m examples in the case where the learnerstarted in state i.
Naturally we wantlim p i (m)= 1and for this example this is indeed the case.
The nextfigure shows a plot of the following quantity as a func-tion of m, the number of examples.p(m) = min{pi(m)}The quantity p(m) is easy to interpret.
Thus p(m) =0.95 rneans that for every initial state of the learnerthe probability that it is in the target state after mexamples is at least 0.95.
Further there is one initialstate (the worst initial state with respect o the target,which in our example is Ls) for which this probabilityis exactly 0.95.
We find on looking at the curve thatthe learner converges with high probability within 100to 200 (degree-0) example sentences, a psychologicallyplausible number.We can now compare the convergence time of TLA toother algorithms.
Perhaps the simplest is random walk:start the learner at a random point in the 3-parameterspace, and then, if an input sentence cannot be ana-lyzed, move 1-bit randomly from state to state.
Notethat this regime cannot suffer from the local maximaproblem, since there is always some finite probability ofexiting a non-target state.Computing the convergence curves for a random walkalgorithm (RWA) on the 8 state space, we find that theconvergence times are actually faster than for the TLA;see figure 2.
Since the RWA is also superior in that itdoes not suffer from the same local maxima problemas TLA, the conceptual support for the TLA is by nomeans clear.
Of course, it may be that the TLA hasempirical support, in the sense of independent evidencethat children do use this procedure (given by the pat-tern of their errors, etc.
), but this evidence is lacking,as far as we know.D ISTR IBUT IONAL ASSUMPTIONS:PART IIn the earlier section we assumed that the data was uni-formly distributed.
We computed the transition matrixfor a particular target language and showed that con-vergence times were of the order of 100-200 samples.
Inthis section we show that the convergence times dependcrucially upon the distribution.
In particular we canchoose a distribution which will make the convergencetime as large as we want.
Thus the distribution-freeconvergence time for the 3-parameter system is infinite.As before, we consider the situation where the targetlanguage is L1.
There are no local maxima problemsfor this choice.
We begin by letting the distribution beparametrized by the variables a, b, c, d wherea = P(A = {Adv(erb)Phrase V S})b = P(B  = {Adv V O S, Adv Aux V S})c = P (C={AdvV O1 O2S,  AdvAuxVOS,Adv Aux V O1 02 S})d = P(D={VS})Thus each of the sets A, B, C and D contain differentdegree-O sentences of L1.
Clearly the probability of theset L, \{AUBUCUD} is 1 - (a+b+c+d) .
The elementsof each defined subset of La are equally likely with re-spect to each other.
Setting positive values for a, b, c, dsuch that a + b + c + d < 1 now defines a unique prob-ability for each degree(O) sentence in L1.
For example,the probability of AdvVOS is b/2, the probability ofAdvAuxVOS is c/3, that of VOS is (1 - (a+b+c+d) ) /6and so on; see figure 3.
We can now obtain the tran-sition matrix corresponding to this distribution.
If wecompare this matrix with that obtained with a uniformdistribution on the sentences of La in the earlier section.This matrix has non-zero elements (transition proba-bilities) exactly where the earlier matrix had non-zeroelements.
However, the value of each transition prob-ability now depends upon a,b, c, and d. In particularif we choose a = 1/12, b = 2/12, c = 3/12, d = 1/12(this is equivalent to assuming a uniform distribution)we obtain the appropriate transition matrix as before.Looking more closely at the general transition matrix,we see that the transition probability from state 2 tostate 1 is (1 -  (a+b+c) ) /3 .
Clearly if we make aarbitrarily close to 1, then this transition probabilityis arbitrarily close to 0 so that the number of samplesneeded to converge can be made arbitrarily large.
Thuschoosing large values for a and small values for b willresult in large convergence times.This means that the sample complexity cannot bebounded in a distribution-free s nse, because by choos-ing a highly unfavorable distribution the sample com-plexity can be made as high as possible.
For example,we now give the convergence curves calculated for dif-ferent choices of a, b,c, d. We see that for a uniformdistribution the convergence occurs within 200 sam-ples.
By choosing a distribution with a = 0.9999 andb = c = d = 0.000001, the convergence time can bepushed up to as much as 50 million samples.
(Of course,this distribution is presumably not psychologically re-alistic.)
For a = 0.99, b = c = d = 0.0001, the samplecomplexity is on the order of 100,000 positive examples.Remark.
The preceding calculation provides a worst-case convergence time.
We can also calculate averageconvergence times using standard results from Markovchain theory (see Isaacson and Madsen, 1976), as intable 2.
These support our previous results.There are also well-known convergence theorems de-rived from a consideration of the eigenvalues of thetransition matrix.
We state without proof a conver-gence result for transition matrices stated in terms ofits eigenvalues.175Table 1: Complete list of problem states, i.e., all combinations ofstarting rammar and target grammar which resultin non-learnability of the target.
The items marked with an asterisk are those listed in the original paper by Gibsonand Wexler (1994).Initial Grammar Target Grammar(svo-v2)(svo+v2)*(soy-v2)(SOV+V2)*(VOS-V2)(VOS+V2)*(OVS-V2)(ovs+v2)*(vos-v2)(VOS+V2)*(OVS-V2)(OVS+V2)*(OVS-V2)(ovs-v2)(ovs-v2)(ovs-v2)(svo-v2)(svo-v2)(svo-v2)(svo-v2)(sov-v2)(soy-v2)(soy-v2)(sov-v2)State of Initial Grammar(Markov Structure)Not SinkProbability of NotConverging to TargetNot SinkSink0.5Sink 1.00.15Not SinkSinkNot SinkNot SinkNot Sink1.0Not SinkSink0.331.00.331.00.33Sink 1.00.081.0~f  f ...............~m~o;?1-@6 16o 260 360 460Number of examples (m}Figure 2: Convergence as a function of number of examples.
The probability of converging to the target state afterm examples is plotted against m. The data from the target is assumed to be distributed uniformly over degree-0sentences.
The solid line represents TLA convergence times and the dotted line is a random walk learning algorithm(RWA) which actually converges fasler than the TLA in this case.176OE8O-o  d", ....IittIttt t, /' \[?
.
.
.
.= ,  r "  .
.
.
.o lo 2'o 3o 4oLog(Number of Samples)Figure 3: Rates of convergence for TLA with L1 as the target language for different distributions.
The probabilityof converging to the target after m samples is plotted against log(m).
The three curves show how unfavorabledistributions can increase convergence times.
The dashed nine assumes uniform distribution and is the same curveas plotted in figure 2.Table 2: Mean and standard deviation convergence times to target 5 (English) given different distributions overthe target language, and a uniform distribution over initial states.
The first distribution is uniform over the targetlanguage; the other distributionsLearning Mean abs.scenario timeTEA (uniform) 34.8TLA (a = 0.99) 45000TLA (a = 0.9999) 4.5 ?
106RW 9.6alter the value of a as discussed in the main text.Std.
Dev.of abs.
time22.3330003.3 ?
l0610.1177Theorem 2 Let T be an n x n transition matrix withn linearly independent left eigenvectors x l  .
.
.
.
xn cor-responding to eigenvalues .~l , .
.
.
, .~n.
Let x0 (an n-dimensional vector) represent he starting probability ofbeing in each state of the chain and r be the limitingprobability of being in each state.
Then after k transi-tions, the probability of being in each state x0T k can bedescribed bynI1 x0T k-~ I1=11 ~ mfx0y~x, I1~< max I~,lk ~ II x0y,x, II2<i<ni=1  - - i=2where the Yi 's are the right eigenvectors o fT .This theorem bounds the convergence rate to thelimiting distribution 7r (in cases where there is onlyone absorption state, 7r will have a 1 corresponding tothat state and 0 everywhere lse).
Using this resultwe bound the rates of convergence (in terms of num-ber k of samples).
It should be plain that these resultscould be used to establish standard errors and confi-dence bounds on convergence times in the usual way,another advantage of our new approach; see table 3.D ISTR IBUT IONAL ASSUMPTIONS,PART I IThe Markov model also allows us to easily determinethe effect of distributional changes in the input.
Thisis important for either computer or child acquisitionstudies, since we can use corpus distributions to com-pute convergence times in advance.
For instance, itcan be easily shown that convergence times depend cru-cially upon the distribution chosen (so in particular theTLA learning model does not follow any distribution-free PAC results).
Specifically, we can choose a distribu-tion that will make the convergence time as large as wewant.
For example, in the situation where the targetlanguage is L1, we can increase the convergence timearbitrarily by increasing the probability of the string{Adv(verb) V S}.
By choosing a more unfavorable dis-tribution the convergence time can be pushed up to asmuch as 50 million samples.
While not surprising in it-self, the specificity of the model allows us to be preciseabout the required sample size.CHILDES D ISTRIBUT IONSIt is of interest o examine the fidelity of the model us-ing real language distributions, namely, the CHILDESdatabase.
We have carried out preliminary direct ex-periments using the CHILDES caretaker English inputto "Nina" and German input to "Katrin"; these consistof 43,612 and 632 sentences each, respectively.
We note,following well-known results by psycholinguists, thatboth corpuses contain a much higher percentage of aux-inversion and wh-questions than "ordinary" text (e.g.,the LOB): 25,890 questions, and 11,775 wh-questions;201 and 99 in the German corpus; but only 2,506 ques-tions or 3.7% out of 53,495 LOB sentences.To test convergence, an implemented system using anewer version of deMarcken's partial parser (see deMar-cken, 1990) analyzed each degree-0 or degree-1 sentenceas falling into one of the input patterns SVO, S Aux V,etc., as appropriate for the target language.
Sentencesnot parsable into these patterns were discarded (pre-sumably "too complex" in some sense following a tradi-tion established by many other researchers; ee Wexlerand Culicover (1980) for details).
Some examples ofcaretaker inputs follow:this is a book ?
what do you see in the book ?how many rabbits ?what is the rabbit doing ?
( .
.
.
)is he hopping ?
oh .
and what is he playing with ?red mir doch nicht alles nach!ja , die schw~tzen auch immer alles nach (.
.
.
)When run through the TLA, we discover that con-vergence falls roughly along the TLA convergence timedisplayed in figure 1-roughly 100 examples to asymp-tote.
Thus, the feasibility of the basic model is con-firmed by actual caretaker input, at least in this simplecase, for both English and German.
We are contin-uing to explore this model with other languages anddistributional assumptions.
However, there is one veryimportant new complication that must be taken intoaccount: we have found that one must (obviously) addpatterns to cover the predominance of auxiliary inver-sions and wh-questions.
However, that largely begs thequestion of whether the language is verb-second or not.Thus, as far as we can tell, we have not yet arrived ata satisfactory parameter-setting account for V2 acqui-sition.VARIANTS OF  THE LEARNINGMODEL AND EXTENSIONSThe Markov formulation allows one to more easily ex-plore algorithm variants.
Besides the TLA, we considerthe possible three simple learning algorithm regimes bydropping either or both of the Single Value and Greed-iness constraints.
The key result is that ahnost anyother regime works faster than local gradient ascent andavoids problems with local maxima.
See figure 4 for arepresentative r sult.
Thus, most interestingly, param-eterized language learning appears particularly robustunder algorithmic hanges.EXTENSIONS,  D IACHRONICCHANGE AND CONCLUSIONSWe remark here that the "batch" phonological param-eter learning system of Dresher and Kaye (1990) is sus-ceptible to a more direct PAC-type analysis, since theirsystem sets parameters in an "off-line" mode.
We statewithout proof some results that can be given in suchcases .178Learning scenarioTLA (uniform)TLA(a = 0.99)TLA(a = 0.9999)RWTable 3: Convergence rates derived from eigenvalue calculations.Rate of Convergence0(0.94 ~)o( (1 -  lo-~) ~)o((1 - 10-6) k)o(0.89 k)q~, dd,/ /i// / '////L.~,2'0 4'o 6'0 s'o 6oNumber of samplesFigure 4: Convergence rates for different learning algorithms when L1 is the target language.
The curve with theslowest rate (large dashes) represents the TLA, the one with the fastest rate (small dashes) is the Random Walk(RWA) with no greediness or single value constraints.
Random walks with exactly one of the greediness and singlevalue constraints have performances in between.179Theorem 3 If the learner draws more than M =1 In(l/b) samples, then it will identify the tar- ln(l/(1-bt))get with confidence greater than 1 - 6.
( Here bt =P(Lt \ Uj~tLj)).Finally, the Markov model also points to an intrigu-ing new model for syntactic hange.
One simply has tointroduce two or more target languages that emit posi-tive example strings with (probably different) frequen-cies: each corresponding to difference language sources.If the model is run as before, then there can be a largeprobability for a learner to converge to a state differentfrom the highest frequency emitting target state: thatis, the learner can acquire a different parameter setting,for example, a -V2 setting, even in a predominantly+V2 environment.
This is of course one of the histor-ical changes that occurred in the development of En-glish.
Space does not permit us to explore all the con-sequences of this new Markov model; we remark herethat once again we can compute convergence times andstability under different distributions of target frequen-cies, combining it with the usual dynamical models ofgenotype fixation.
In this case, the interesting result isthat the TLA actually boosts diachronic hange by or-ders of magnitude, since as observed earlier, it can per-mit the learner to arrive at a different convergent stateeven when there is just one target language mitter.
Incontrast, the local maxima targets are stable, and neverundergo change.
Whether this powerful "boost" effectplays a role in diachronic hange remains a topic for fu-ture investigation.
As far as we know, the possibility forformally modeling the kind of saltation indicated by theMarkov model has not been noted previously and hasonly been vaguely stated by authors uch as Lightfoot(1990).In conclusion, by introducing a formal mathematicalmodel for language acquisition, we can provide rigor-ous results on parameter learning, algorithmic varia-tion, sample complexity, and diachronic syntax change.These results are of interest for corpus-based acquisitionand investigations of child acquisition, as well as point-ing the way to a more rigorous bridge between moderncomputational learning theory and computational lin-guistics.ACKNOWLEDGMENTSWe would like to thank Ken Wexler, Ted Gibson, andan anonymous ACL reviewer for valuable discussionsand comments on this work.
Dr. Leonardo Topa pro-vided invaluable programming assistance.
All residualerrors are ours.
This research is supported by NSFgrant 9217041-ASC and ARPA under the HPCC pro-gram.REFERENCESClark, Robin and Roberts, Ian (1993).
"A Compu-tational Model of Language Learnability and Lan-guage Change."
Linguistic Inquiry, 24(2):299-345.deMarcken, Carl (1990).
"Parsing the LOB Corpus.
"Proceedings of the 25th Annual Meeting of the As-sociation for Computational Linguistics.
Pitts-burgh, PA: Association for Computational Linguis-tics, 243-251.Dresher, Elan and Kaye, Jonathan (1990).
"A Compu-tational Learning Model For Metrical Phonology.
"Cognition, 34(1):137-195.Gibson, Edward and Wexler, Kenneth (1994).
"Trig-gers."
Linguistic Inquiry, to appear.Gold, E.M. (1967).
"Language Identification in theLimit."
Information and Control, 10(4): 447-474.Isaacson, David and Masden, John (1976).
MarkovChains.
New York: John Wiley.Lightfoot, David (1990).
How to Set Parameters.
Cam-bridge, MA: MIT Press.Wexler, Kenneth and Culicover, Peter (1980).
FormalPrinciples of Language Acquisition.
Cambridge,MA: MIT Press.180
