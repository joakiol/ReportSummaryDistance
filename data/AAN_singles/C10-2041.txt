Coling 2010: Poster Volume, pages 356?364,Beijing, August 2010A Semantic Network Approach to Measuring RelatednessBrian HarringtonOxford University Computing Laboratorybrian.harrington@comlab.ox.ac.ukAbstractHumans are very good at judging thestrength of relationships between twoterms, a task which, if it can be au-tomated, would be useful in a rangeof applications.
Systems attempting tosolve this problem automatically havetraditionally either used relative po-sitioning in lexical resources such asWordNet, or distributional relation-ships in large corpora.
This paper pro-poses a new approach, whereby rela-tionships are derived from natural lan-guage text by using existing nlp tools,then integrated into a large scale se-mantic network.
Spreading activationis then used on this network in orderto judge the strengths of all relation-ships connecting the terms.
In com-parisons with human measurements,this approach was able to obtain re-sults on par with the best purpose builtsystems, using only a relatively smallcorpus extracted from the web.
Thisis particularly impressive, as the net-work creation system is a general toolfor information collection and integra-tion, and is not specifically designed fortasks of this type.1 IntroductionThe ability to determine semantic relatednessbetween terms is useful for a variety of nlp ap-plications, including word sense disambigua-tion, information extraction and retrieval, andtext summarisation (Budanitsky and Hirst,2006).
However, there is an important dis-tinction to be made between semantic relat-edness and semantic similarity.
As (Resnik,1999) notes, ?Semantic similarity represents aspecial case of semantic relatedness: for ex-ample, cars and gasoline would seem to bemore closely related than, say, cars and bi-cycles, but the latter pair are certainly moresimilar?.
(Budanitsky and Hirst, 2006) fur-ther note that ?Computational applicationstypically require relatedness rather than justsimilarity; for example, money and river arecues to the in-context meaning of bank thatare just as good as trust company?.Systems for automatically determining thedegree of semantic relatedness between twoterms have traditionally either used a mea-surement based on the distance between theterms within WordNet (Banerjee and Ped-ersen, 2003; Hughes and Ramage, 2007), orused co-occurrence statistics from a large cor-pus (Mohammad and Hirst, 2006; Pado?
andLapata, 2007).
Recent systems have, how-ever, shown improved results using extremelylarge corpora (Agirre et al, 2009), and ex-isting large-scale resources such as Wikipedia(Strube and Ponzetto, 2006).In this paper, we propose a new approachto determining semantic relatedness, in whicha semantic network is automatically createdfrom a relatively small corpus using exist-ing NLP tools and a network creation systemcalled ASKNet (Harrington and Clark, 2007),and then spreading activation is used to de-termine the strength of the connections withinthat network.
This process is more analogousto the way the task is performed by humans.Information is collected from fragments andassimilated into a large semantic knowledgestructure which is not purposely built for asingle task, but is constructed as a generalresource containing a wide variety of infor-mation.
Relationships represented within this356structure can then be used to determine thetotal strength of the relations between any twoterms.2 Existing Approaches2.1 Resource Based MethodsA popular method for automatically judgingsemantic distance between terms is throughWordNet (Fellbaum, 1998), using the lengthsof paths between words in the taxonomy as ameasure of distance.
While WordNet-basedapproaches have obtained promising resultsfor measuring semantic similarity (Jiang andConrath, 1997; Banerjee and Pedersen, 2003),the results for the more general notion of se-mantic relatedness have been less promising(Hughes and Ramage, 2007).One disadvantage of using WordNet forevaluating semantic relatedness is its hierar-chical taxonomic structure.
This results interms such as car and bicycle being close inthe network, but terms such as car and gaso-line being far apart.
Another difficulty arisesfrom the non-scalability of WordNet.
Whilethe quality of the network is high, the man-ual nature of its construction means that arbi-trary word pairs may not occur in the network.Hence in this paper we pursue an approach inwhich the resource for measuring semantic re-latedness is created automatically, based onnaturally occurring text.A similar project, not using WordNet isWikiRelate (Strube and Ponzetto, 2006),which uses the existing link structure ofWikipedia as its base network, and uses sim-ilar path based measurements to those foundin WordNet approaches to compute semanticrelatedness.
This project has seen improvedresults over most WordNet base approaches,largely due to the nature of Wikipedia, wherearticles tend to link to other articles which arerelated, rather than just ones which are simi-lar.2.2 Distributional MethodsAn alternative method for judging semanticdistance is using word co-occurrence statisticsderived from a very large corpus (McDonaldand Brew, 2004; Pado?
and Lapata, 2007) orfrom the web using search engine results (Tur-ney, 2001).In a recent paper, Agirre et al (2009) parsed4 billion documents (1.6 Terawords) crawledfrom the web, and then used a search func-tion to extract syntactic relations and con-text windows surrounding key words.
Thesewere then used as features for vector space,in a similar manner to work done in (Pado?and Lapata, 2007), using the British NationalCorpus (bnc).
This system has produced ex-cellent results, indicating that the quality ofthe results for these types of approaches is re-lated to the size and coverage of their corpus.This does however present problems movingforward, as 1.6 Terawords is obviously an ex-tremely large corpus, and it is likely that therewould be a diminishing return on investmentfor increasingly large corpora.
In the same pa-per, another method was shown which usedthe pagerank algorihm, run over a networkformed from WordNet and the WordNet glosstags in order to produce equally impressive re-sults.3 A Semantic Network ApproachThe resource we use is a semantic network,automatically created by the large scale net-work creation program, ASKNet.
The rela-tions between nodes in the network are basedon the relations returned by a parser and se-mantic analyser, which are typically the argu-ments of predicates found in the text.
Henceterms in the network are related by the chainof syntactic/semantic relations which connectthe terms in documents, making the networkideal for measuring the general notion of se-mantic relatedness.Distinct occurrences of terms and entitiesare combined into a single node using a novelform of spreading activation (Collins and Lof-tus, 1975).
This combining of distinct men-tions produces a cohesive connected network,allowing terms and entities to be relatedacross sentences and even larger units such asdocuments.
Once the network is built, spread-ing activation is used to determine semantic357relatedness between terms.
For example, todetermine how related car and gasoline are,activation is given to one of the nodes, saycar, and the network is ?fired?
to allow theactivation to spread to the rest of the net-work.
The amount of activation received bygasoline is then a measure of the strength ofthe semantic relation between the two terms.We use three datasets derived from humanjudgements of semantic relatedness to test ourtechnique.
Since the datasets contain generalterms which may not appear in an existingcorpus, we create our own corpus by harvest-ing text from the web via Google.
This ap-proach has the advantage of requiring littlehuman intervention and being extensible tonew datasets.
Our results using the semanticnetwork derived from the web-based corpusare comparable to the best performing exist-ing methods tested on the same datasets.4 Creating the Semantic NetworksASKNet creates the semantic networks usingexisting nlp tools to extract syntactic and se-mantic information from text.
This informa-tion is then combined using a modified versionof the update algorithm used by Harringtonand Clark (2007) to create an integrated large-scale network.
By mapping together conceptsand objects that relate to the same real-worldentities, the system is able to transform theoutput of various nlp tools into a single net-work, producing semantic resources which aremore than the sum of their parts.
Combin-ing information from multiple sources resultsin a representation which would not have beenpossible to obtain from analysing the originalsources separately.The nlp tools used by ASKNet are theC&C parser (Clark and Curran, 2007) andthe semantic analysis program Boxer (Boset al, 2004), which operates on the ccgderivations output by the parser to producea first-order representation.
The named en-tity recognizer of Curran and Clark (2003)is also used to recognize the standard set ofmuc entities, including person, location andorganisation.As an example of the usefulness of infor-mation integration, consider the monk -asylumexample, taken from the rg dataset (de-scribed in Section 5.1).
It is possible that evena large corpus could contain sentences linkingmonk with church, and linking church withasylum, but no direct links between monk andasylum.
However, with an integrated seman-tic network, activation can travel across mul-tiple links, and through multiple paths, andwill show a relationship, albeit probably nota very strong one, between monk and asylum,which corresponds nicely with our intuition.Figure 1, which gives an example net-work built from duc documents describing theElian Gonzalez custody battle, gives an indi-cation of the kind of network that ASKNetbuilds.
This figure does not give the full net-work, which is too large to show in a sin-gle figure, but shows the ?core?
of the net-work, where the core is determined using thetechnique described in (Harrington and Clark,2009).
The black boxes represent named en-tities mentioned in the text, which may havebeen mentioned a number of times across doc-uments, and possibly using different names(e.g.
Fidel Castro vs. President Castro).
Thediamonds are named directed edges, whichrepresent relationships between entities.A manual evaluation using human judgeshas been performed to measure the accuracyof ASKNet networks.
On a collection of ducdocuments, the ?cores?
of the resulting net-works were judged to be 80% accurate on av-erage, where accuracy was measured for themerged entity nodes in the networks and therelations between those entities (Harringtonand Clark, 2009).
The motivation for fully au-tomatic creation is that very large networks,containing millions of edges, can be created ina matter of hours.Automatically creating networks does resultin lower precision than manual creation, butthis is offset by the scalability and speed ofcreation.
The experiments described in thispaper are a good test of the automatic cre-ation methodology.358Figure 1: Example network core derived from duc documents describing a news story from 2000.The update algorithmIn order to merge information from multi-ple sources into a single cohesive resource,ASKNet uses a spreading activation based up-date algorithm (Harrington and Clark, 2007).As the system encounters new information, itattempts to map named entities in the newsentences it encounters to those already in itsnetwork.
Each new sentence is turned into anupdate fragment ; a fragment of the networkrepresenting the information contained in thesentence.
Initial mapping scores, based onlexical similarity and named entity type, aremade between the update fragment?s namedentities and those in the main network.
Thejob of the update algorithm is to improve uponthose initial scorings using the semantic infor-mation contained within the network.The update algorithm iterates over eachnamed entity node in the update fragment.This base node is provided with activation,which is allowed to spread throughout thefragment.
All named entities which receiveactivation in this process, then transfer theiractivation to their target named entity nodes(nodes in the main network with which theyhave a current mapping score greater thanzero).
The amount transferred is based on thestrength of the mapping score.
The activationis then allowed to circulate through the mainnetwork until it reaches a stable state.
At thispoint, the base node?s mappings are updatedbased on which of its target nodes receivedactivation.
The more activation a target nodereceives, the more its mapping score with the359base node will increase.The intuition behind the update algorithmis that we can use relatedness of nodes inthe update fragment to determine appropriatemappings in the main network.
So if our basenode has the label ?Crosby?, and is relatedto named entity nodes referring to ?Canada?,?Vancouver?
and ?2010?, those nodes willpass their activation onto their main networktargets, and hopefully onto the node repre-senting the ice hockey player Sidney Crosby.We would then increase the mapping score be-tween our base node and this target, while atthe same time decreasing the mapping scorebetween out base node and the singer BingCrosby, who (hopefully) would have receivedlittle or no activation.
The update algorithmis also self-reinforcing, as in the successivestages, the improved scores will focus the ac-tivation further.
In our example, in successiveiterations, more of the activation coming tothe ?Crosby?
node will be sent to the appro-priate target node, and therefore there will beless spurious activation in the network to cre-ate noise.For the purposes of these experiments, weextended the update algorithm to map to-gether general object nodes, rather than fo-cusing solely on named entities.
This was nec-essary due to the nature of the task.
Sim-ply merging named entities would not be suf-ficient, as many of the words in datasets wouldnot likely be associated strongly with any par-ticular named entities.
Extending the algo-rithm in this way resulted in a much higherfrequency of mapping, and a much more con-nected final network.
Because of this, wefound that several of the parameters had tobe changed from those used in Harringtonand Clark (2009).
Our initial activation in-put was set to double that used in Harring-ton and Clark?s experiments (100 instead of50), to compensate for the activation lost overthe higher number of links.
We also foundthat the number of iterations required to reacha stable state had increased to more than 4times the previous number.
This was to beexpected due to the increased number of linkspassing activation.
We also had to remove thenamed entity type calculation from the initialmapping score, thus leaving the initial scor-ing to be simply the ratio of labels in the twonodes which overlapped.
These changes wereall done after manual observation of test net-works built from searches not relating to anydataset, and were not changed once the exper-iments had begun.4.1 Measuring semantic relatednessOnce a large-scale network has been con-structed from a corpus of documents, spread-ing activation can be used to efficiently obtaina distance score between any two nodes in thenetwork, which will represent the semantic re-latedness of the pair.
Each node in the net-work has a current amount of activation anda threshold (similar to classical ideas from theneural network literature).
If a node?s activa-tion exceeds its threshold, it will fire, sendingactivation to all of its neighbours, which maycause them to fire, and so on.
The amount ofactivation sent between nodes decreases withdistance, so that the effect of the original fir-ing is localized.
The localized nature of thealgorithm is important because it means thatsemantic relatedness scores can be calculatedefficiently even for pairs of nodes in very largenetworks.To obtain a score between nodes x and y,first a set amount of activation is placed innode x; then the network is fired until it sta-bilises, and the total amount of activation re-ceived by node y is stored as act(x,y).
Thisprocess is repeated starting with node y to ob-tain act(y,x).
The sum of these two values,which we call dist(x,y), is used as the mea-sure of semantic relatedness between x and y.1dist(x,y) is a measure of the totalstrength of connection between nodes x andy, relative to the other nodes in their region.This takes into account not just direct paths,but also indirect paths, if the links along thosepaths are of sufficient strength.
Since the1The average could be used also but this has noeffect on the ranking statistics used in the later exper-iments.360networks potentially contain a wide varietyof relations between terms, the calculation ofdist(x,y) has access to a wide variety of in-formation linking the two terms.
If we con-sider the (car, gasoline) example mentionedearlier, the intuition behind our approach isthat these two terms are likely to be closelyrelated in a semantic network built from text,either fairly directly because they appear inthe same sentence or document, or indirectlybecause they are related to the same entities.5 ExperimentsThe purpose of the experiments was to de-velop an entirely automated approach forreplicating human judgements of semantic re-latedness of words.
We used three existingdatasets of human judgements: the Hodg-son, Rubenstein & Goodenough (rg) andWordsimilarity-353 (ws-353) datasets.
Foreach dataset we created a corpus using re-sults returned by Google when queried foreach word independently (Described in Sec-tion 5.2).
We then built a semantic networkfrom that corpus and used the spreading acti-vation technique described in the previous sec-tion to measure semantic relatedness betweenthe word pairs in the dataset.The parser and semantic analysis tool usedto create the networks were developed onnewspaper data (a ccg version of the PennTreebank (Steedman and Hockenmaier, 2007;Clark and Curran, 2007)), but our impres-sion from informally inspecting the parseroutput was that the accuracy on the webdata was reasonable.
The experimental re-sults show that the resulting networks wereof high enough quality to closely replicate hu-man judgements.5.1 The datasetsMany studies have shown a marked prim-ing effect for semantically related words.
Inhis single-word lexical priming study, (Hodg-son, 1991) showed that the presentation ofa prime word such as election directly fa-cilitates processing of a target word such asvote.
Hodgson showed an increase in both re-sponse speed and accuracy when the primeand target are semantically related.
143 wordpairs were tested across 6 different lexical re-lations: antonymy (e.g., enemy, friend); con-ceptual association (e.g., bed, sleep); categorycoordination (e.g., train, truck); phrasal as-sociation (e.g., private, property); superordi-nation/subordination (e.g., travel, drive); andsynonymy (e.g., value, worth).
It was shownthat equivalent priming effects (i.e., reducedprocessing time) were present across all rela-tion types, thus indicating that priming was aresult of the terms?
semantic relatedness, notmerely their similarity or other simpler rela-tion type.The Hodgson dataset consists of the 143word pairs divided by lexical category.
Therewere no scores given as all pairs were shownto have relatively similar priming effects.
Noexamples of unrelated pairs are given in thedataset.
We therefore used the unrelated pairscreated by McDonald and Brew (2004).The task in this experiment was to obtainscores for all pairs, and to do an ANOVA testto determine if there is a significant differencebetween the scores for related and unrelatedpairs.The ws-353 dataset (Finkelstein et al,2002) contains human rankings of the seman-tic distance between pairs of terms.
Althoughthe name may imply that the scores are basedon similarity, human judges were asked toscore 353 pairs of words for their relatednesson a scale of 1 to 10, and so the dataset isideal for our purposes.
For example, the pair(money, bank) is in the dataset and receivesa high relatedness score of 8.50, even thoughthe terms are not lexically similar.The dataset contains regular nouns andnamed entities, as well as at least oneterm which does not appear in WordNet(Maradona).
In this experiment, we calcu-lated scores for all word pairs, and then usedrank correlation to compare the similarity ofour generated scores to those obtained fromhuman judgements.The rg dataset (Rubenstein and Goode-nough, 1965) is very similar to the ws-353,361though with only 65 word pairs, except thatthe human judges were asked to judge thepairs based on synonymy, rather than over-all relatedness.
Thus, for example, the pair(monk,asylum), receives a significantly lowerscore than the pair (crane,implement).5.2 Data collection, preparation andprocessingIn order to create a corpus from which to buildthe semantic networks, we first extracted eachindividual word from the pairings, resultingin a list of 440 words for the ws-353 collec-tion, 48 words for the rg (some words wereused in multiple pairings), and 282 words forthe Hodgson collection.
For each of the wordsin this list, we then performed a query usingGoogle, and downloaded the first 5 page re-sults for that query.
The choice of 5 as thenumber of documents to download for eachword was based on a combination of infor-mal intuition about the precision and recall ofsearch engines, as well as the practical issue ofobtaining a corpus that could be processed inreasonable space and time.Each of the downloaded web pages was thencleaned by a set of Perl scripts which removedall HTML markup.
Statistics for the resultingcorpora are given in Table 1.Three rules were added to the retrieval pro-cess to deal with problems encountered in for-matting of web-pages:1.
Pages from which no text could be re-trieved were ignored and replaced withthe next result.2.
HTML lists preceded by a colon were re-combined into sentences.3.
For Wikipedia disambiguation pages(pages which consist of a list of links toarticles relating to the various possiblesenses of a word), all of the listed linkswere followed and the resulting pagesadded to the corpus.Each of these heuristics was performed au-tomatically and without human intervention.The largest of the networks, created for thews-353 dataset, took slightly over 24 hourscorpus sentences wordsHodgson 814,779 3,745,870rg 150,165 573,148ws-353 1,042,128 5,027,947Table 1: Summary statistics for the corpora gener-ated for the experiments.to complete, including time for parsing andsemantic analysis.6 Results6.1 Hodgson priming datasetAfter processing the Hodgson corpus tobuild a semantic network with approximately500,000 nodes and 1,300,000 edges, the appro-priate node pairs were fired to obtain the dis-tance measure as previously described.
Thosemeasurements were then recorded as measure-ments of semantic relatedness between twoterms.
If a term was used as a label in twoor more nodes, all nodes were tried, and thehighest scoring pairs were used.As the Hodgson dataset did not provide ex-amples of unrelated pairs against which wecould compare, unrelated pairs were gener-ated as described in (McDonald and Brew,2004).
This is not an ideal method, as sev-eral pairs that were identified as unrelated didhave some relatively obvious relationship (e.g.tree ?
house, poker ?
heart).
However we choseto retain the methodology for consistency withprevious literature as it was also used in (Pado?and Lapata, 2007).Scores were obtained from the network forthe word pairs, and for each target an aver-age score was calculated for all primes in itscategory.
Example scores are given in Table2.Two-way analysis of variance (ANOVA)was carried out on the network scores withthe the relatedness status of the pair beingthe independent variable.
A reliable effectwas observed for the network scores with theprimes for related words being significantlylarger than those for unrelated words.
Theresults are given in Table 3.The use of ANOVA shows that there is a362Word pair Related Network Scoreempty - full Yes 10.13coffee - mug Yes 5.86horse - goat Yes 0.96dog - leash Yes 4.70friend - antonym No 0.53vote - conceptual No 1.37property - phrasal No 2.47drive - super/sub No 1.86Table 2: Example scores obtained from the networkfor related and unrelated word pairs from the Hodgsondatasetdifference in the scores of the related and un-related word pairs that cannot be accountedfor by random variance.
However, in orderto compare the strength of the experimentaleffects between two experiments, additionalstatistics must be used.
Eta-squared (?2) isa measure of the strength of an experimentaleffect.
A high ?2 indicates that the indepen-dent variable accounts for more of the variabil-ity, and thus indicates a stronger experimen-tal effect.
In our experiments, we found an?2 of 0.411, which means that approximately41% of the overall variance can be explainedby the relatedness scores.For comparison, we provide the ANOVAresults for experiments by (McDonald andBrew, 2004) and (Pado?
and Lapata, 2007) onthe same dataset.
Both of these experimentsobtained scores using vector based modelspopulated with data from the bnc.We also include the results obtained fromperforming the same ANOVA tests on Point-wise Mutual Information scores collected overour corpus.
These results were intended toprovide a baseline when using the web-basedcorpus.
To calculate the pmi scores for this ex-periment, we computed scores for the numberof times the two words appeared in the sameparagraph or document, and the total numberof occurrences of words in the corpus.
The pmiscores were calculated by simply dividing thenumber of times the words co-occurred withina paragraph, by the product of the number ofoccurrences of each word within a document.F MSE p ?2McDonald & Brew 71.73 0.004 < 0.001Pado?
& Lapata 182.46 0.93 < 0.01 0.332pmi 42.53 3.79 < 0.001 0.263Network 50.71 3.28 < 0.0001 0.411Table 3: ANOVA results of scores generated fromthe Hodgson dataset compared to those reported forexisting systems.
(F = F-test statistic, MSE = Meansquared error, p = P-value, ?2 = Effect size)6.2 ws-353 and rg datasetsThe methodology used to obtain scores for thews-353 and rg collections was identical tothat used for the Hodgson data, except thatscores were only obtained for those pairs listedin the data set.
Because both collections pro-vided direct scores, there was no need to re-trieve network scores for unrelated pairings.ws-353 rgWikiRelate!
0.48 0.86Hughes-Ramage 0.55 0.84Agirre Et Al 0.66 0.89pmi 0.41 0.80Network 0.62 0.86Table 4: Rank correlation scores for the semanticnetwork and pmi-based approaches, calculated on thews-353 and rg collections, shown against scores forexisting systems.For consistency with previous literature, thescores obtained by the semantic network werecompared with those from the collections us-ing Spearman?s rank correlation.
The correla-tion results are given in Table 4.
For compar-ison, we have included the results of the samecorrelation on scores from three top scoringsystems using the approaches described above.We also include the scores obtained by usinga simple pmi calculation as in the previous ex-periment.The scores obtained by our system were notan improvement on those obtained by existingsystems.
However, our scores were on par withthe best performing systems, which were pur-pose built for this application, and at least inthe case of the system by Agirre et al used acorpus several orders of magnitude larger.3637 ConclusionIn this paper we have shown that a semanticnetwork approach to determining semantic re-latedness of terms can achieve performance onpar with the best purpose built systems.
Thisis interesting for two reasons.
Firstly, the ap-proach we have taken in this paper is muchmore analogous to the way humans performsimilar tasks.
Secondly, the system used wasnot purpose built for this application.
It isinstead a general tool for information collec-tion and integration, and this result indicatesthat it will likely be useful for a wide varietyof language processing applications.ReferencesAgirre, Eneko, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pasca, and Aitor Soroa.
2009.
Astudy on similarity and relatedness using distribu-tional and wordnet-based approaches.
In Proceed-ings of NAACL-HLT.Banerjee, Satanjeev and T. Pedersen.
2003.
Extendedgloss overlaps as a measure of semantic relatedness.In Proceedings of the Eighteenth International Con-ference on Artificial Intelligence, Acapulco, Mexico.Bos, Johan, Stephen Clark, Mark Steedman, James R.Curran, and Julia Hockenmaier.
2004.
Wide-coverage semantic representations from a CCGparser.
In Proceedings of the 20th Interna-tional Conference on Computational Linguistics(COLING-04), pages 1240?1246, Geneva, Switzer-land.Budanitsky, Alexander and Graeme Hirst.
2006.
Eval-uating wordnet-based measures of semantic dis-tance.
Computational Linguistics, 32:13 ?
47,March.Clark, Stephen and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with CCGand log-linear models.
Computational Linguistics,33(4):493?552.Collins, Allan M. and Elizabeth F. Loftus.
1975.
Aspreading-activation theory of semantic processing.Psychological Review, 82(6):407?428.Curran, James R. and Stephen Clark.
2003.
Languageindependent NER using a maximum entropy tagger.In Proceedings of the Seventh Conference on Natu-ral Language Learning, pages 164?167, Edmonton,Canada.Fellbaum, Christiane, editor.
1998.
WordNet : AnElectronic Lexical Database.
MIT Press, Cam-bridge, Mass, USA.Finkelstein, Lev, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-tan Ruppin.
2002.
Placing search in context: Theconcept revisited.
In ACM Transactions on Infor-mation Systems, volume 20(1), pages 116?131.Harrington, Brian and Stephen Clark.
2007.
Asknet:Automated semantic knowledge network.
In Pro-ceedings of the 22nd National Conference on Arti-ficial Intelligence (AAAI?07), pages 889?894, Van-couver, Canada.Harrington, Brian and Stephen Clark.
2009.
Asknet:Creating and evaluating large scale integrated se-mantic networks.
International Journal of Seman-tic Computing, 2(3):343?364.Hodgson, James.
1991.
Information constraints onpre-lexical priming.
Language and Cognitive Pro-cesses, 6:169 ?
205.Hughes, Thad and Daniel Ramage.
2007.
Lexical se-mantic relatedness with random graph walks.
InProceedings of the 2007 Joint Conference on Em-pirical Methods in Natural Language Processing andComputational Natural Language Learning, pages581?589, Prague, Czech Republic.Jiang, J. J. and D. W. Conrath.
1997.
Seman-tic similarity based on corpus statistics and lexi-cal taxonomy.
In International Conference on Re-search on Computational Linguistics, Taipei, Tai-wan, September.McDonald, Scott and Chris Brew.
2004.
A distri-butional model of semantic context effects in lexi-cal processing.
In Proceedings of the 42th AnnualMeeting of the Association for Computational Lin-guistics, pages 17 ?
24, Barcelona, Spain.Mohammad, Saif and Graeme Hirst.
2006.
Dis-tributional measures of concept-distance: A task-oriented evaluation.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP 2006), Sydney, Australia.Pado?, Sebastian and Mirella Lapata.
2007.Dependency-based construction of semantic spacemodels.
Computational Linguistics, 33(2):161?199.Resnik, Philip.
1999.
Semantic similarity in a tax-onomy: An information-based measure and its ap-plication to problems of ambiguity in natural lan-guage.
Journal of Artificial Intelligence Research,11:95?130.Rubenstein, H. and J.B. Goodenough.
1965.
Contex-tual correlates of synonymy.
Computational Lin-guistics, 8:627 ?
633.Steedman, Mark and Julia Hockenmaier.
2007.
Ccg-bank: A corpus of ccg derivations and dependencystructures extracted from the penn treebank.
Com-putational Linguistics, 33:355?396.Strube, Michael and Simone Paolo Ponzetto.
2006.Wikirelate!
computing semantic relatedness usingwikipedia.
In Proceedings of the 21st national con-ference on Artificial intelligence, pages 1419?1424.AAAI Press.Turney, Peter D. 2001.
Lecture notes in computerscience 1: Mining the web for synonyms: PMI-IRversus LSA on TOEFL.364
