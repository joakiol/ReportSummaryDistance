Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 183?192, Dublin, Ireland, August 23-29 2014.Political Tendency Identification in Twitterusing Sentiment Analysis TechniquesFerran Pla and Llu??s-F.
HurtadoDepartament de Sistemes Inform`atics i Computaci?oUniversitat Polit`ecnica de Val`enciaCam??
Vera s/n 46022 Val`encia (Spain){lhurtado|fpla}@dsic.upv.esAbstractThis paper describes an approach for political tendency identification of Twitter users.
We definesome metrics that take into account the polarity of the political entities in the tweets of each user.To obtain this polarities we present the sentiment analysis system developed.
The evaluation wasperformed on the general corpus developed at TASS2013 workshop for Spanish.
To our knowl-edge, the results obtained for the sentiment analysis task and the political tendency identificationtask are the best results published until now using this data set.1 IntroductionSocial media are usually used to express opinions and feelings about companies, products, services,hobbies, politics, etc.
Therefore, enterprises, organizations, governments, and different groups in generalhave shown interest in the opinions that users have for their activities.
They are also interested to knownthe way users use these media, the communication behaviour, and some users attributes such as gender,age, geographical location, political orientation, etc.
In general, the main aim is to provide personalizedservices, particularized offers, or simply to know what people think about something in order to improvetheir activities.The scientific community has made a great effort to provide effective solutions to analyse, structure,and process the large amount of on-line reviews in social media.
A wide set of techniques of Senti-ment Analysis (SA) are used in micro-blogging texts to extract the polarity (positive, negative, mixed orneutral) that users express in these texts.
In this respect, Twitter has become a popular micro-bloggingsite in which users express their opinions on a variety of topics in real time.
The texts used in Twit-ter are called tweets, which are short texts of a maximum of 140 characters and a language that doesnot have any restriction on the form and content.
The nature of these texts poses new challenges forresearchers in Natural Language Processing (NLP).
In some cases, the tweets are written with ungram-matical sentences with a lot of emoticons, abbreviations, specific terminology, slang, etc.
Therefore, theusual techniques of NLP must be adapted to these characteristics of the language, and new approachesmust be proposed in order to successfully address this problem.
NLP tools like POS taggers, parsers, orNamed Entity Recognition (NER) tools usually fail when processing tweets because they generally aretrained on grammatical texts and they perform poorly in micro-blogging texts.In this work we present a system for addressing the task of political tendency identification of Twitterusers based on SA techniques.
For each user, we collect all their tweets and we extract all the entitiesrelated to the political subject.
Then, we automatically assign a polarity to these entities and we define apolitical tendency metric that uses this entity polarity information combined with another tendency metricfor classifying the political tendency of each user in four categories: Left, Right, Center, or Undefined.The evaluation of our system is performed on the General Corpus, a corpus of Spanish tweets providedby the organization of the TASS2013 workshop.The paper is organized as follows.
In section 2 we present relevant works for Twitter user classificationand Sentiment Analysis.
In Section 3 we present a description of the corpus used to evaluate our userThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/183political tendency system.
This system is based on SA techniques.
A description of our SA system isdescribed in section 4.
In Section 5 we describe the way we classify users according to their politicalleading.
The evaluation and discussion of the results obtained are presented in section 6.
Finally, insection 7 we present some conclusions and possible directions for future works.2 Related worksThe different approaches for estimating the political leaning of Twitter users explore features that rangefrom text content, users behavior (taking into account the tweets and retweets information) and theTwitter structure (by considering the followers users, following users, etc.).
An interesting study of someuseful features to classify latent users attributes (gender, age, regional origin, and political orientation) ispresented in (Rao et al., 2010).
In (Conover et al., 2011a; Conover et al., 2011b) and study of the politicalalignment of Twitter users is performed by analyzing the way users communicates by means of retweetsand user mentions.
In (O?Connor et al., 2010a) SA techniques are used to determine the positive andnegative polarity of Twitter messages.
They also study the connexion between these polarities and thepublic opinion derived from traditional polling in order to substitute or complement them.
(Pennacchiottiand Popescu, 2011) present a machine learning approach to Twitter user classification in democrats orrepublicans.
With respect to the linguistic content they considered prototypical words and hashtags thatare common in democrats or republicans users which provides clues for the classification.
They also useSA tecniques based on lexicons for the classification task.
In (Boutet et al., 2012) polical leading of usersis performed by counting the amount of tweets related to political parties analysing the hashtags.
Theyalso consider the interaction among parties by analyzing the retweets and mentions.
Users interaction byanalysing tweets and retweets is also the main idea of the work presented in (Wong et al., 2013).In (Cohen and Ruths, 2013) previous works on political orientation of Twitter users are analyzed toconclude that the accuracy results reported are overstimated do to the way the data sets are constructed.When these approaches are applied to normal Twitter users accuracy results significantly decrease.Sentiment Analysis (SA) has been widely studied in the last decade in multiple domains.
Most workfocuses on classifying the polarity of the texts as positive, negative, mixed, or neutral.
The pioneeringworks in this field used supervised (Pang et al., 2002) or unsupervised (knowledge-based) (Turney, 2002)approaches.
In (Pang et al., 2002), the performance of different classifiers on movie reviews was eval-uated.
In (Turney, 2002), some patterns containing POS information were used to identify subjectivesentences in reviews to then estimate their semantic orientation.The construction of polarity lexicons is another widely explored field of research.
Opinion lexiconshave been obtained for English language (Liu et al., 2005) (Wilson et al., 2005) and also for Spanishlanguage (Perez-Rosas et al., 2012).
A good presentation of the SA problem and a description of thestate-of-the-art of the more relevant approaches to SA can be found in (Liu, 2012).
An overview ofthe current state of different approaches to the subjectivity and SA task is presented in (Montoyo et al.,2012).Research works about SA on Twitter are much more recent.
Twitter appeared in the year 2006 andthe early works in this field are from 2009 when Twitter started to achieve popularity.
Some of the mostsignificant works are (Barbosa and Feng, 2010), (Jansen et al., 2009), and (O?Connor et al., 2010b).
Asurvey of the most relevant approaches to SA on Twitter can be see in (Mart?
?nez-C?amara et al., 2012) ,(Vinodhini and Chandrasekaran, 2012).
The SemEval2013 competition has also dedicated a specific taskfor SA on Twitter (Wilson et al., 2013), which shows the great interest of the scientific community in thisfield.
The TASS2013 workshop has proposed different tasks for SA and political tendency identificationfocused on the Spanish language (Villena-Rom?an and Garc?
?a-Morera, 2013).3 The CorpusThe General Corpus of TASS20131(Villena-Rom?an and Garc?
?a-Morera, 2013) contains approximately68000 Twitter messages (tweets) written in Spanish (between November 2011 and March 2012) by 158well-known personalities of the world of politics, economy, communication, mass media, and culture.1This corpus is freely available on the web page of TASS2013 (http://www.daedalus.es/TASS2013).184The corpus is encoded in XML.
Each tweet includes its ID (tweetid), the creation date (date), andthe user ID (user).
It is tagged with its global polarity using N and N+ labels for negative polarity withdifferent intensity, P and P+ labels for positive polarity with different intensity, and the NEU label forneutral polarity.
Label NONE was used to represent tweets with no polarity at all.
Moreover, the polarityto the entities that are mentioned in the tweet was also included.
The level of agreement of the expressedsentiment is annotated both for global and entity level.
Also, a selection of a set of topics was madebased on the thematic areas covered by the corpus, such as politics, soccer, literature, entertainment, etc.Each message is also assigned to one or several of these topics.N N+ NEU NONE P P+training 1,335 (18.49%) 847 (11.73%) 670 ( 9.28%) 1,483 (20.54%) 1,232 (17.07%) 1,652 (22.88%)test 11,287 (18.56%) 4,557 ( 7.50%) 1,305 ( 2.15%) 21,416 (35.22%) 1,488 ( 2.45%) 20,745 (34.12%)Table 1: The distribution of the polarity of the tweets in the corpus.Table 1 shows the distribution of tweets per polarity in the corpus.
It is divided into two sets: training(about 10%, 7219 tweets) and test (about 90%, 60798 tweets).
It can be observed that this distributionis not balanced for the different polarities.
Finally, each user from the test set of the General corpus islabeled with their political tendency in four possible values: Left, Right, Centre, and Undefined.4 Description and Evaluation of the Sentiment Analysis SystemFigure 1 shows an overview of our system for the SA problem.
The system consists of 4 modules.
Thefirst module is the Pre-processing module, which performs the tokenization, lemmatization, and NamedEntities recognition of the input tweet.
A lemma reduction and a POS tagging process is also carriedout in this module.
The second module is optional.
It allows us to obtain the polarity of the entitiescontained in the tweet.
If we omitted this step the global polarity of the tweet is obtained.
The thirdmodule is the Feature Extraction module, which selects the features from the pre-processed tweet (orfrom the segments of tweets) and obtains a feature vector.
Some features require the use of a polaritylexicon of lemmas and words.
To determine the best features, a tuning process is required during thetraining phase.
The fourth module is the Polarity Classifier module, which uses a classifier (learned fromfeature vectors of the training set) to assign a polarity label to the tweet.Figure 1: Sentiment Analysis System Overview4.1 Pre-processing of TweetsBefore addressing the SA task, it is necessary to make a proper tokenization of the tweets.
Although thereare a lot of tokenizers available on the web, they need to be adapted in order to address the segmentationof tokens of a tweet.
Furthermore, most of these resources are for the English language, which adds adegree of difficulty for their use in processing Spanish tweets.185Moreover, the use of NLP resources such as stemmers, POS taggers, parsers, NER systems, WordSense Disambiguation (WSD) systems, etc.
are impractical if the characteristics of the tweets are nottaken into account.
Therefore, an adjustment and adaptation must be made for the Twitter domain.In our system, we decided to use and adapt available tools for tokenization, lemmatization, NER,and POS tagging.
We adapted the package Tweetmotif2that is described in (O?Connor et al., 2010b)to process Spanish tweets.
We also used Freeling3(Padr?o and Stanilovsky, 2012) (with the appropri-ate modifications for handling Twitter messages) for stemming, Named Entity Recognition, and POStagging.We added some functions to process special tokens (e.g., grouping all hashtags into a single token,grouping all web addresses into a single token or grouping all url into a single token).
We also groupedthe dates into a single token, the numbers into a single token, and the punctuation marks into a singletoken.4.2 The SegmenterFor the proposed approach we need to determine the polarity of political entities that contains a tweet.It is because the polarity of each entity could be different of the global polarity of the tweet.
In thetweet of the corpus4: ?Rajoy?s government goes up the pensions.
PSOE cuts back all things except theunemployment.?
we have two entities, Rajoy (the president of Spanish government from the right-wingparty PP) and PSOE (a Spanish left-wing party).
This tweet is labeled with a neutral global polarity, buteach entity have a different polarity (ENTITY (Rajoy): Positive.
ENTITY (PSOE): Negative).Even for tweets with only one entity we must decide what fragments of text refers to that entity.
In theexample: ?Rajoy already has been talking for an hour.
Not saving anywhere only expenses, all reformscost a lot of money.
Did he tell us something at the end?
?, to determine the polarity of entity Rajoy,we must take into account all the tweet, because the two last sentences references to ENTITY(Rajoy).In contrast, in the example: ?Today 349 members attending to the formation of the lower house.
Onlythe AMAIUR deputy for Navarra is missing?, only the sentence containing the AMAIUR entity is beingrequired to determine its polarity.Obtaining the polarity at entity level is a hard problem and introduces additional complexity becausethe part of the tweet refers to each of the entities must be determined.
To resolve this problem it shouldmake a deep parsing of the tweet and perform a study of such dependencies.
This is not a solved problemin NLP even considering normative texts and is further aggravated in Twitter texts.
Besides, in manycases, the dependencies are between different sentences, and problems such as coreference must betaking into account in order to determine, for example, which pronoun refers to a certain entity.
Otherproblems such as synonyms and acronyms of certain entities can make this problem harder.We have chosen a more simple and practice approach that consists in defining a set of heuristics todetermine which segment of the tweet refers to each of the entities present on it.
We defined some rulesto do this segmentation.
If the tweet contains only one entity the context considered was all the tweet.We evaluated other alternatives, but due to the short length of tweets, with that decision the best globalresults were obtained.
If the tweet contains two entities, the casuistry is greater.
If both entities are placedtogether at the beginning or the end of the tweet all the tweet is considered as a context for both entities.By contrast, if separate, and has sufficient context, the tweet is segmented by defining the context of eachentity.
Next, we show some examples and the segmentation produced by the defined rules.Example 1 is the easier case due the two entities are in separated sentences.
When both entities are inthe same sentence, in Example 2 the rule applied determines that the context for the first entity is fromthe beginning until the second entity, and the rest of the sentence is the context for the second entity.Example 3 is more difficult, and the rules applied produce segmentations like this [On March 25 we electbetween the immobility of the @PSOE] [and the renovation and the hope of the @ppandaluz.
]), that arenot correct but can be useful for determining the polarity of each entity.
In addition, due to the shortlength of the tweets, the context of an entity is often so small that it does not contain information enough2https://github.com/brendano/tweetmotif.3http://nlp.lsi.upc.edu/freeling/4All the exemples have been translated to English.186Example 1[Rajoy?s government goes up the pensions.]
[PSOE cuts back all things except the unemployment.
]GLOBAL POLARITY: NEU.
ENTITY (Rajoy): Positive.
ENTITY (PSOE): NegativeExample 2[As IU gains confidence in Andaluc?
?a] [PP loses members.
]GLOBAL POLARITY: NEU.
ENTITY (IU): Positive.
ENTITY (PP): NegativeExample 3On March 25 we elect between [the immobility of the @PSOE] and [the renovation and the hope of the @ppandaluz.
]GLOBAL POLARITY: NEU.
ENTITY (@PSOE): Negative.
ENTITY (@ppandaluz): Positiveto correctly classify the polarity of the entity.
In such case, the option that was chosen is to establish athreshold of context, and if it is below than this threshold, it was assigned the same polarity to all theentities of the tweet.
When the number of entities is greater than two in much cases we assigned thesame polarity to all the entities of the tweet because we had not enough context.4.3 Feature SelectionThe feature selection process was performed by cross validation (10-fold validation) using the trainingset to select the set of relevant features.We considered the following set of features: unigrams and bigrams of lemmas obtained in the prepro-cessing of the tweets that belong to a set of selected POS.
We considered only the lemmas of a minimumfrequency (f) in the training set.
We unified all hashtags, user references, dates, punctuations as a singlefeature.
We classified the emoticons in the following categories: happy, sad, tongue, wink, and other.Finally, we used external polarity lexicons of lemmas and words.Some of the features required further adjustment.
For the POS feature we selected the lemas thatbelongs to the nouns, verbs, adjectives, and adverbs POS and also exclamations and emoticons.
Weestimated the minimum frequency of the lemmas to be selected (f =2).
Finally, we selected the externallexicons to be used.
One of the lexicons used was originally for English language (Wilson et al., 2005)that was translated into Spanish automatically, and other (Perez-Rosas et al., 2012) lexicon was a list ofwords that was originally in Spanish.
Then, we combined these two resource with the lexicon presentedin (Saralegi and San Vicente, 2013).4.4 Polarity ClassifierThe task was addressed as a classification problem that consisted of determining the polarity of eachtweet.
We used WEKA5, which is a tool that includes (among other utilities) a collection of machine-learning algorithms that can be used for classification tasks.
Specifically, we used a SVM-based approachbecause it is a well-founded formalism, that has been successfully used in many classification problems.In the SA task, SVM has shown it ability to handle large feature spaces and to determine the relevantfeatures (Joachims, 1998).We used the NU-SVM algorithm (Sch?olkopf et al., 2000) from an external library called LibSVM6,which is very efficient software for building SVM classifiers.
It is easy to integrate this software withWEKA thus allowing us to use all of WEKA?s features.
We used the bag of words approach to representeach tweet as a feature vector that contains the frequency of the selected features of the training set.4.5 Evaluation of the Sentiment Analysis SystemWe evaluated our system on the SA tasks defined at the TASS2013 workshop.
Two different sub-taskscalled 5-level and 3-level were proposed.
Both sub-tasks differ only in the polarity granularity consid-ered.
The 5-level sub-task uses the labels N, N+, P, P+, and NEU.
The 3-level sub-task uses the labels N,P, and NEU.
In both sub-tasks, an additional label (NONE) was used to represent tweets with no polarity.The accuracy results obtained on the unseen data test were: 62.88%?0.38% for 5-level task and70.25%?0.36% for 3-level task.
This results outperformed all the approaches at TASS2013 workshopwith statistical significance (with a 95% level of confidence).
The official results ranged from 61.6% to13.5% for the 5-level task and from 66.3% to 38.8% for the 3-level task.
The F1result obtained in the5http://www.cs.waikato.ac.nz/ml/weka/6http://www.cs.iastate.edu/?
yasser/wlsvm/187Sentiment Analysis at Entity level task was worse (F1=0.40), but it still is the best result reported in thesentiment analysis at entity level task at TASS2013 competition.5 Political tendency identificationThe objective of this task is to estimate the political tendency of each user from the test set of the Generalcorpus in four possible values: Left, Right, Centre, and Undefined.
Next, we describe the approachwe proposed for this task.
This approach uses the SA system previously described in section 4.To perform the classification of users we assume the following hypothesis: the positive opinions on apolitical party is a political orientation similarly to the user performing the review for this party, on thecontrary, a negative opinion about a party is a political orientation opposite to that shown by this party.In this way, to classify users by their political orientation, first we identify entities associated withpolitical parties and secondly we analyze the polarity of these entities in the tweets of each user.We consider three types of entities: entities labeled by Freeling as proper names (i.e.,comit?e del pp de madrid), Twitter users (i.e., @38congresopsoe), and Twitter hashtags (i.e., #upyd).Among all possible entities we selected those containing the acronym for a political party or the nameof a political leader.
A total of 864 entities related to political parties and political leaders were detected.Table 2 shows the parties and political leaders considered and some examples of the selected entities.Party Tendency Examples of EntitiesPP right #17congesoPP, congreso nacional pp, ppopular, congresopp, #ppfachasPSOE left elpsoe, #adiosalpsoeenandalucia, #38congresopsoeIU left asamblea de iu, iumalaga, diputados de iu, #iuUPyD centre upydeuskadi, #demagogiaupyd, #mareamagenta, upyd asturiasCiU right ciu+tripartito, #ciu, ciu-mintiendo-crujenPolitical Leader Party Examples of EntitiesRajoy PP #rajoynoeslasoluci?on, espa?na de rajoy, irpf de rajoyGonz?alez Pons PP @gonzalezpons, rajoy para gonz?alez ponsRubalcaba PSOE #rubalcabaenlaser, @conrubalcaba, rubalcaba para el psoeZapatero PSOE nueva via de zapatero, presidente zapatero, zapatero tvCayo Lara IU @cayo lara, cayo lara, cayoTable 2: Tendency of political parties and political leaders.We defined a tendency measure Tendency that assigned a value of ?1 to those entities related to leftparties, a value of +1 to entities related to right parties and a value of 0 to the entities related to centreparties.Next we show how has been numerically calculated the political orientation of users.
For each user Uiof the General corpus we obtain the set Tithat includes all of their tweets that contain political entities.For users who do not have any tweet that contain political entities the Undefined label is assigned.For each tweet Tij?
Ti, j = 1 ?
?
?
|Ti|, we identify the political entities that are contained on it.
LetEijbe the set of entities of the tweet Tij.
We denote each of the entities contained in Eijas Eijk?Eij, k = 1 ?
?
?
|Eij|.We obtained the polarity of each entity by using the system described in section 4.
After that, weassigned a numerical value to each polarity.
In this respect, we assigned Polarity = +1 to the entitieswith positive polarity (label P), Polarity = ?1 to the entities with negative polarity (label N) and finally,Polarity = 0 to the entities without polarity, that is, to the NEU and NONE labels.We combined7the Tendency and Polarity measures previously presented to define a new measure(Political Tendency) to obtain the political orientation of each user.7We have considered multiple combination strategies, in this work we present the combination with the best results.188Political Tendency(Ui) =?j=1???|Ti|?k=1??
?|Eij|Polarity(Eijk) ?
Tendency(Eijk)?j=1??
?|Ti||Eij|(1)From the Political Tendency values obtained for each user, we classified the user tendencytanking into account the following: users without political entities in their tweets are classified asUndefined; users with Political Tendency between -0.05 and +0.05 are classified as Centre; userswith Political Tendency lower than -0.05 are classified as Left; and users with Political Tendencygreater than +0.05 are classified as Right.6 Experimental Evaluation of the Political Identification SystemThe measures selected to evaluate our approach were the Precision, the Recall, and the F-measure for?
= 1 (F1).
Table 3 summarizes the experimental results of our proposal.
The table includes both theoverall results (Global) and the results for each one of the political tendencies (Left, Right, Centre, andUndefined).
It also includes the distribution of the tendencies in the gold-standard (%Ref).
For the globalresult, the precision and the recall are the same since each user in the test set had a tendency assignedand the task consist to assign a tendency to all the users.Tendency %Ref Precision Recall F1Left 21.5 0.658 0.735 0.694Centre 17.7 0.478 0.393 0.431Right 39.9 0.786 0.698 0.739Undefined 20.9 0.780 0.970 0.865Global 100 0.709 0.709 0.709Table 3: Experimental results obtained in the political tendency identification task of TASS2013.The result obtained by our system (0.709) is the best result reported so far for this corpus, to ourknowledge.
The tendency for what we get better results is the Undefined (F1=0.865).
We considerthe political tendency of a user to be Undefined if he did not have any tweet that references any of themajority parties.
This assumption may be too strict for common users, but it seems reasonable for thewell-know users that form the test corpus.The tendency that our system had more trouble identifying was Centre (F1=0.431).
The tendency of auser can be identified as Centre when he expressed -in his tweets- opinions about entities related to centreparties, even when these opinions were negative.
This is because the neutral value of Centre entities.
Inaddition, users with opinions on right and left parties with the same polarity may be identified as Centre,which can be wrong in many cases.Precision0,20,30,40,50,60,70,80,91Polarity_Tendency?1 ?0,8 ?0,6 ?0,4 ?0,2 0 0,2 0,4 0,6 0,8 1PrecisionFigure 2: Precision results depending on the Political Tendency assigned by the system.189Although it seems that the ability of our system to identify Left and Right tendencies was similar(F1=0.694 for Left and F1=0.739 for Right), analyzing the results considering the values of Politi-cal Tendency some significant differences can be observed.
Figure 2 shows the results, in terms ofPrecision, considering the value of Political Tendency assigned to each user by our system, from a valueof -1 (the maximum value for Left) to a value of +1 (the maximum for Right).As expected, most identification errors occurred for Political Tendency value near zero, should re-member that values between -0.05 and 0.05 were considered Centre.
Considering the Right tendency,all users that obtained Political Tendency value greater than 0.25 were correctly identified as Right, per-formed better than would be expected.
However, the behavior of the Left tendency was not symmetrical.It seems that values between -0.3 and -0.1 were better to determine correctly this tendency.Although we have no clear explanation for this behavior, it could be due to multiple factors, including:the simplicity of the proposal, labeling errors in the polarity of certain entities, or the greater difficulty ofnumerically identify the Left tendency (at least in this corpus).7 ConclusionsWe have described our approach for political tendency identification of Twitter users.
We have defined ametric, called Political Tendency, that takes into account the polarity of entities related to political partiesthat appear in the tweets of the user.
The Sentiment Analysis system developed in order to obtain thepolarity of these entities was also presented.The evaluation was performed using a corpus of Spanish tweets developed at TASS2013 workshop.This corpus was used for a specific political tendency identification task at this workshop.
To our knowl-edge, the results obtained by our system are the best results published until now using this corpus.We are very interested in SA tasks and in identifying tendencies in social media.
In this sense, wehave several ideas on how to improve our approach to identifying the political tendency in Twitter.It would be interesting to test our approach using a larger corpus of tweets from normal user.
We thinkthat the characteristics of the users of the test corpus -figures of culture, journalism and politics in Spain-made the task a little easier.
Perhaps the political tendency of ordinary users would be more difficultto identify.
Moreover, the political spectrum would be more diverse and should increase the catalog ofpolitical parties.
Moreover, the political spectrum would be more varied and, consequently, the catalogof political parties should be increased.It should be emphasized the difficulty of building an annotated corpus of tweets that could be usedto evaluate and compare different alternative systems.
A great effort of acquisition of the tweets and asubsequent manual labeling process is required.
In addition, a validation process is needed to correct theerrors introduced by manual labeling.
Even using crowdsourcing-based solutions it is a very expensivetask both in money and time.
In this context, to have a labeled corpus as the one provided by TASS2013is a great help for the scientific community.On the portability of the system, we think that it will be easy to adapt our proposal to another politicalcontext.
This adaptation should focus on two different aspects.
First, the Sentiment Analysis Systemshould be adapted to a new language.
In the case of languages with linguistic resources freely availablethe adaptation would be very simple.
Second, political entities should be changed to fit the politicalcontext where we want to test the system.
It would be sufficient to identify the most relevant parties andtheir leaders and classify them according to their political tendency.
However, it is possible that in otherpolitical contexts different to Spanish, the Left, Centre, and Right tendencies also need to be adapted.Finally, we have interest in using Machine Learning techniques for the task of identifying politicaltendency on twitter.
On this point, we are working on a system in which Political Tendency, as definedin this paper, will be a feature within a wider classification system.
In this new system, we want toinclude additional information (not available in the TASS2013 corpus) about user behavior and Twitterstructure in order to improve our approach.AcknowledgementsThis work has been partially funded by the Spanish MEC projects DIANA (TIN2012-38603-C02-01)and T?
?mpano (TIN2011-28169-C05-01).190ReferencesLuciano Barbosa and Junlan Feng.
2010.
Robust sentiment detection on twitter from biased and noisy data.In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 36?44.Association for Computational Linguistics.Antoine Boutet, Hyoungshick Kim, and Eiko Yoneki.
2012.
What?s in Your Tweets?
I Know Who You Sup-ported in the UK 2010 General Election.
In The International AAAI Conference on Weblogs and Social Media(ICWSM), Dublin, Irlande, June.Raviv Cohen and Derek Ruths.
2013.
Classifying political orientation on twitter: It?s not easy!
In InternationalAAAI Conference on Weblogs and Social Media.M Conover, B Gonc?alves, J Ratkiewicz, A Flammini, and F Menczer.
2011a.
Predicting the political alignment oftwitter users.
In Proceedings of 3rd IEEE Conference on Social Computing (SocialCom).Michael Conover, Jacob Ratkiewicz, Matthew Francisco, Bruno Gonc?alves, Alessandro Flammini, and FilippoMenczer.
2011b.
Political polarization on twitter.
In Proc.
5th International AAAI Conference on Weblogs andSocial Media (ICWSM).Bernard J Jansen, Mimi Zhang, Kate Sobel, and Abdur Chowdury.
2009.
Twitter power: Tweets as electronicword of mouth.
Journal of the American society for information science and technology, 60(11):2169?2188.Thorsten Joachims.
1998.
Text categorization with support vector machines: learning with many relevant features.In Claire N?edellec and C?eline Rouveirol, editors, Proceedings of ECML-98, 10th European Conference onMachine Learning, number 1398, pages 137?142, Chemnitz, DE.
Springer Verlag, Heidelberg, DE.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.
Opinion observer: Analyzing and comparing opinions onthe web.
In Proceedings of the 14th International Conference on World Wide Web, WWW ?05, pages 342?351,New York, NY, USA.
ACM.Bing Liu.
2012.
Sentiment Analysis and Opinion Mining.
A Comprehensive Introduction and Survey.
Morgan &Claypool Publishers.Eugenio Mart?
?nez-C?amara, M. Teresa Mart?
?n-Valdivia, L. Alfonso Ure?na-L?opez, and Arturo Montejo-Ra?ez.
2012.Sentiment analysis in twitter.
Natural Language Engineering, 1(1):1?28.Andr?es Montoyo, Patricio Mart?
?nez-Barco, and Alexandra Balahur.
2012.
Subjectivity and sentiment analysis: Anoverview of the current state of the area and envisaged developments.
Decision Support Systems, 53(4):675?679.Brendan O?Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith.
2010a.
From tweets topolls: Linking text sentiment to public opinion time series.
In William W. Cohen and Samuel Gosling, editors,ICWSM.
The AAAI Press.Brendan O?Connor, Michel Krieger, and David Ahn.
2010b.
Tweetmotif: Exploratory search and topic summa-rization for twitter.
In William W. Cohen and Samuel Gosling, editors, Proceedings of the Fourth InternationalConference on Weblogs and Social Media, ICWSM 2010, Washington, DC, USA, May 23-26, 2010.
The AAAIPress.Llu?
?s Padr?o and Evgeny Stanilovsky.
2012.
Freeling 3.0: Towards wider multilinguality.
In Proceedings of theLanguage Resources and Evaluation Conference (LREC 2012), Istanbul, Turkey, May.
ELRA.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002.
Thumbs up?
sentiment classification using machinelearning techniques.
In IN PROCEEDINGS OF EMNLP, pages 79?86.Marco Pennacchiotti and Ana-Maria Popescu.
2011.
A machine learning approach to twitter user classification.In Lada A. Adamic, Ricardo A. Baeza-Yates, and Scott Counts, editors, ICWSM.
The AAAI Press.Veronica Perez-Rosas, Carmen Banea, and Rada Mihalcea.
2012.
Learning sentiment lexicons in spanish.
InNicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet U?gur Do?gan, Bente Mae-gaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Confer-ence on Language Resources and Evaluation (LREC?12), Istanbul, Turkey, may.
European Language ResourcesAssociation (ELRA).Delip Rao, David Yarowsky, Abhishek Shreevats, and Manaswi Gupta.
2010.
Classifying latent user attributesin twitter.
In Proceedings of the 2Nd International Workshop on Search and Mining User-generated Contents,SMUC ?10, pages 37?44, New York, NY, USA.
ACM.191Xabier Saralegi and I?naki San Vicente.
2013.
Elhuyar at tass 2013.
In Proceedings of the TASS workshop atSEPLN 2013.
IV Congreso Espa?nol de Inform?atica.Bernhard Sch?olkopf, Alex J. Smola, Robert C. Williamson, and Peter L. Bartlett.
2000.
New support vectoralgorithms.
Neural Comput., 12(5):1207?1245, May.Peter D. Turney.
2002.
Thumbs up or thumbs down?
semantic orientation applied to unsupervised classificationof reviews.
In ACL, pages 417?424.Julio Villena-Rom?an and Janine Garc??a-Morera.
2013.
Workshop on sentiment analysis at sepln 2013: An overview.
In Proceedings of the TASS workshop at SEPLN 2013.
IV Congreso Espa?nol de Inform?atica.G Vinodhini and RM Chandrasekaran.
2012.
Sentiment analysis and opinion mining: A survey.
InternationalJournal, 2(6).Theresa Wilson, Paul Hoffmann, Swapna Somasundaran, Jason Kessler, Janyce Wiebe, Yejin Choi, Claire Cardie,Ellen Riloff, and Siddharth Patwardhan.
2005.
Opinionfinder: A system for subjectivity analysis.
In Proceed-ings of HLT/EMNLP on Interactive Demonstrations, pages 34?35.
Association for Computational Linguistics.Theresa Wilson, Zornitsa Kozareva, Preslav Nakov, Sara Rosenthal, Veselin Stoyanov, and Alan Ritter.
2013.Semeval-2013 task 2: Sentiment analysis in twitter.
Proceedings of the International Workshop on SemanticEvaluation, SemEval, 13.Felix Ming Fai Wong, Chee Wei Tan, Soumya Sen, and Mung Chiang.
2013.
Quantifying political leaning fromtweets and retweets.
In Emre Kiciman, Nicole B. Ellison, Bernie Hogan, Paul Resnick, and Ian Soboroff,editors, ICWSM.
The AAAI Press.192
