Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 39?46,Sydney, July 2006. c?2006 Association for Computational LinguisticsSearching for Sentences Expressing Opinionsby using Declaratively Subjective CluesNobuaki Hiroshima, Setsuo Yamada, Osamu Furuse and Ryoji KataokaNTT Cyber Solutions Laboratories, NTT Corporation1-1 Hikari-no-oka Yokosuka-Shi Kanagawa, 239-0847 Japanhiroshima.nobuaki@lab.ntt.co.jpAbstractThis paper presents a method for search-ing the web for sentences expressingopinions.
To retrieve an appropriatenumber of opinions that users may wantto read, declaratively subjective clues areused to judge whether a sentence ex-presses an opinion.
We collected declara-tively subjective clues in opinion-expressing sentences from Japanese webpages retrieved with opinion search que-ries.
These clues were expanded with thesemantic categories of the words in thesentences and were used as feature pa-rameters in a Support Vector Machine toclassify the sentences.
Our experimentalresults using retrieved web pages onvarious topics showed that the opinionexpressing sentences identified by theproposed method are congruent with sen-tences judged by humans to expressopinions.1 IntroductionReaders have an increasing number of opportu-nities to read opinions (personal ideas or beliefs),feelings (mental states), and sentiments (positiveor negative judgments) that have been written orposted on web pages such as review sites, per-sonal web sites, blogs, and BBSes.
Such subjec-tive information on the web can often be a usefulbasis for finding out what people think about aparticular topic or making a decision.A number of studies on automatically extract-ing and analyzing product reviews or reputationson the web have been conducted (Dave et al,2003; Morinaga et al, 2002; Nasukawa and Yi,2003; Tateishi et al, 2004; Kobayashi et al,2004).
These studies focus on using sentimentanalysis to extract positive or negative informa-tion about a particular product.
Different kindsof subjective information, such as neutral opin-ions, requests, and judgments, which are not ex-plicitly associated with positive/negative as-sessments, have not often been considered inprevious work.
Although sentiments provideuseful information, opinion-expressing sentenceslike ?In my opinion this product should bepriced around $15,?
which do not express ex-plicitly positive or negative judgments (unlikesentiments) can also be informative for a userwho wants to know others?
opinions about aproduct.
When a user wants to collect opinionsabout an event, project, or social phenomenon,requests and judgments can be useful as well assentiments.
With open-domain topics, sentencesexpressing sentiments should not be searchedexclusively; other kinds of opinion expressingsentences should be searched as well.The goal of our research is to achieve a websearch engine that locates opinion-expressingsentences about open-domain topics on products,persons, events, projects, and social phenomena.Sentence-level subjectivity/objectivity classifica-tion in some of the previous research (Riloff andWiebe, 2003; Wiebe and Riloff, 2005) can iden-tify subjective statements that include specula-tion in addition to positive/negative evaluations.In these efforts, the subjectivity/objectivity of acurrent sentence is judged based on the existenceof subjective/objective clues in both the sentenceitself and the neighboring sentences.
The subjec-tive clues, some adjective, some noun, and someverb phrases, as well as other collocations, arelearned from corpora (Wiebe, 2000; Wiebe et al,2001).
Some of the clues express subjectivemeaning unrestricted to positive/negative meas-urements.
The sentence-level subjectivity ap-39proach suggests a way of searching for opinionexpressing sentences in the open domain.The problem of applying sentence-level sub-jectivity classification to opinion-expressing sen-tence searches is the likelihood of collecting toomany sentences for a user to read.
According tothe work of Wiebe et al (2001), 70% of sen-tences in opinion-expressing articles like editori-als and 44% of sentences in non-opinion ex-pressing articles like news reports were judgedto be subjective.
In analyzing opinions (Cardieet al, 2003; Wilson et al, 2004), judging docu-ment-level subjectivity (Pang et al, 2002; Tur-ney, 2002), and answering opinion questions(Cardie et al, 2003; Yu and Hatzivassiloglou,2003), the output of a sentence-level subjectivityclassification can be used without modification.However, in searching opinion-expressing sen-tences, it is necessary to designate criteria foropinion-expressing sentences that limit the num-ber of retrieved sentences so that a user can sur-vey them without difficulty.
While it is difficultto formally define an opinion, it is possible topractically tailor the definition of an opinion tothe purpose of the application (Kim and Hovy,2004).This study introduces the notion of declara-tively subjective clues as a criterion for judgingwhether a sentence expresses an opinion andproposes a method for finding opinion-expressing sentences that uses these clues.
De-claratively subjective clues such as the subjec-tive predicate part of the main clause and subjec-tive sentential adverb phrases suggest that thewriter is the source of the opinion.
We hypothe-size that a user of such an ?opinion-expressingsentence?
search wants to read the writer?s opin-ions and that explicitly stated opinions are pre-ferred over quoted or implicational opinions.
Wesuppose that writer?s ideas or beliefs are explic-itly declared in a sentence with declarativelysubjective clues whereas sentences without de-claratively subjective clues mainly describethings.
The number of sentences with declara-tively subjective clues is estimated to be lessthan the number of subjective sentences definedin the previous work.
We expect that the opinionexpressing sentences identified with our methodwill be appropriate from the both qualitative andquantitative viewpoints.Section 2 describes declaratively subjectiveclues and explains how we collected them fromopinion-expressing sentences on Japanese webpages retrieved with opinion search queries.
Sec-tion 3 explains our strategy for searching opin-ion-expressing sentences by using declarativelysubjective clues.
Section 4 evaluates the pro-posed method and shows how the opinion-expressing sentences found by the proposedmethod are congruent with the sentences judgedby humans to be opinions.2 Declaratively Subjective CluesDeclaratively subjective clues are a basic crite-rion for judging whether a sentence expresses anopinion.
We extracted the declaratively subjec-tive clues from Japanese sentences that evalua-tors judged to be opinions.2.1 Opinion-expressing Sentence JudgmentWe regard a sentence to be ?opinion expressing?if it explicitly declares the writer?s idea or beliefat a sentence level.
We define as a ?declarativelysubjective clue?, the part of a sentence that con-tributes to explicitly conveying the writer?s ideaor belief in the opinion-expressing sentence.
Forexample, "I am glad" in the sentence "I am gladto see you" can convey the writer?s pleasure to areader, so we regard the sentence as an ?opinion-expressing sentence?
and ?I am glad?
as a ?de-claratively subjective clue.?
Another example ofa declaratively subjective clue is the exclamationmark in the sentence "We got a contract!"
It con-veys the writer?s emotion about the event to areader.If a sentence only describes something ab-stract or concrete even though it has word-levelor phrase-level subjective parts, we do not con-sider it to be opinion expressing.
On the otherhand, some word-level or phrase-level subjectiveparts can be declaratively subjective clues de-pending on where they occur in the sentence.Consider the following two sentences.
(1) This house is beautiful.
(2) We purchased a beautiful house.Both (1) and (2) contain the word-level subjec-tive part "beautiful".
Our criterion would lead usto say that sentence (1) is an opinion, because"beautiful" is placed in the predicate part and (1)is considered to declare the writer?s evaluationof the house to a reader.
This is why ?beautiful?in (1) is eligible as a declaratively subjectiveclue.
On the other hand, sentence (2) is notjudged to contain an opinion, because "beauti-ful" is placed in the noun phrase, i.e., the objectof the verb ?purchase,?
and (2) is considered toreport the event of the house purchase rather ob-40jectively to a reader.
Sentence (2) partially con-tains subjective information about the beauty ofthe house; however this information is unlikelyto be what a writer wants to emphasize.
Thus,"beautiful" in (2) does not work as a declara-tively subjective clue.These two sentences illustrate the fact that thepresence of a subjective word (?beautiful?)
doesnot unconditionally assure that the sentence ex-presses an opinion.
Additionally, these examplesdo suggest that sentences containing an opinioncan be judged depending on where such word-level or phrase-level subjective parts as evalua-tive adjectives are placed in the predicate part.Some word-level or phrase-level subjectiveparts such as subjective sentential adverbs can bedeclaratively subjective clues depending onwhere they occur in the sentence.
In sentence (3),?amazingly?
expresses the writer?s feeling aboutthe event.
Sentence (3) is judged to contain anopinion because there is a subjective sententialadverb in its main clause.
(3) Amazingly, few people came to my party.The existence of some idiomatic collocationsin the main clause also affects our judgment asto what constitutes an opinion-expressing sen-tence.
For example, sentence (4) can be judgedas expressing an opinion because it includes ?mywish is?.
(4) My wish is to go abroad.Thus, depending on the type of declarativelysubjective clue, it is necessary to consider wherethe expression is placed in the sentence to judgewhether the sentence is an opinion.2.2 Clue Expression CollectionWe collected declaratively subjective clues inopinion-expressing sentences from Japanese webpages.
Figure 1 illustrates the flow of collectionof eligible expressions.type query?s topicProduct cell phone, car, beer, cosmeticEntertainment sports, movie, game, animationFacility  museum, zoo, hotel, shopPolitics diplomacy, electionPhenomena diction, social behaviorEvent firework, festivalCulture artwork, book, musicOrganization companyFood cuisine, noodle, ice creamCreature birdTable 1: Topic ExamplesFirst, we retrieved Japanese web pages fromforty queries covering a wide range of topicssuch as products, entertainment, facilities, andphenomena, as shown in Table 1.
We used que-ries on various topics because we wanted to ac-quire declaratively subjective clues for open-domain opinion web searches.
Most of the que-ries contain proper nouns.
These queries corre-spond to possible situations in which a userwants to retrieve opinions from web pages abouta particular topic, such as ?Cell phone X,?
?Ymuseum,?
and ?Football coach Z?s ability?,where X, Y, and Z are proper nouns.Next, opinion-expressing sentences were ex-tracted from the top twenty retrieved web pagesin each query, 800 pages in total.
There were75,575 sentences in these pages.Figure 1: Flow of Clue Expression Collection41Three evaluators judged whether each sen-tence contained an opinion or not.
The 13,363sentences judged to do so by all three evaluatorswere very likely to be opinion expressing.
Thenumber of sentences which three evaluatorsagreed on as non-opinion expressing was42,346.1 Out of the 13,363 opinion expressingsentences, 8,425 were then used to extract de-claratively subjective clues and learn positiveexamples in a Support Vector Machine (SVM),and 4,938 were used to assess the performanceof opinion expressing sentence search (Section4).
Out of the 42,346 non-opinion sentences,26,340 were used to learn negative examples,and 16,006 were used to assess, keeping thenumber ratio of the positive and negative exam-ple sentences in learning and assessing.One analyst extracted declaratively subjectiveclues from 8,425 of the 13,363 opinion-expressing sentences, and another analystchecked the result.
The number of declaratively1 Note that not all of these opinion-expressing sentencesretrieved were closely related to the query because some ofthe pages described miscellaneous topics.subjective clues obtained was 2,936.
These clueswere classified into fourteen types as shown inTable 2, where the underlined expressions inexample sentences are extracted as declarativelysubjective clues.
The example sentences in Table2 are Japanese opinion-expressing sentences andtheir English translations.
Although some Eng-lish counterparts of Japanese clue expressionsmight not be cogent because of the characteristicdifference between Japanese and English, theclue types are likely to be language-independent.We can see that various types of expressionscompose opinion-expressing sentences.As mentioned in Section 2.1, it is important tocheck where a declaratively subjective clue ap-pears in the sentence in order to apply our crite-rion of whether the sentence is an opinion or not.The clues in the types other than (b), (c) and (l)usually appear in the predicate part of a mainclause.The declaratively subjective clues in Japaneseexamples are placed in the rear parts of sen-tences except in types (b), (c) and (l).
This re-flects the heuristic rule that Japanese predicatetype example sentence (English translation of Japanese sentence)(a) Thought Kono hon wa kare no dato omou.
(I think this book is his.
)(b) Declarative adverb Tabun rainen yooroppa ni iku.
(I will possibly go to Europe next year.
)(c) Interjection Waa, suteki.
(Oh, wonderful.
)(d) Intensifier Karera wa totemo jouzu ni asonda.
(They played extremely well)(e) Impression Kono yougo wa yayakoshii.
(This terminology is confusing.
)(f) Emotion Oai dekite ureshii desu.
(I am glad to see you.
)(g) Positive/negative judgment Anata no oodio kiki wa sugoi.
(Your audio system is terrific.
)(h) Modality about propositional attitude Sono eiga wo miru beki da.
(You should go to the movie.
)(i) Value judgment Kono bun wa imi fumei da.
(This sentence makes no sense.
)(j) Utterance-specific sentence form Towa ittemo,ima wa tada no yume dakedo.
(Though, it's literally just a dream now.
)(k) Symbol Keiyaku wo tottazo!
(We got a contract!
)(l) Idiomatic collocation Ii nikui.
(It's hard to say.
)(m) Uncertainty Ohiru ni nani wo tabeyou kanaa.
(I am wondering what I should eat for lunch.
)(n) Imperative Saizen wo tukushi nasai.
(Give it your best.
)Table 2: Clue Types42parts are in principle placed in the rear part of asentence.3 Opinion-Sentence ExtractionIn this section, we explain the method of classi-fying each sentence by using declaratively sub-jective clues.The simplest method for automatically judgingwhether a sentence is an opinion is a rule-basedone that extracts sentences that include declara-tively subjective clues.
However, as mentionedin Section 2, the existence of declaratively sub-jective clues does not assure that the sentenceexpresses an opinion.
It is a daunting task towrite rules that describe how each declarativelysubjective clue should appear in an opinion-expressing sentence.
A more serious problem isthat an insufficient collection of declarativelysubjective clues will lead to poor extraction per-formance.For that reason, we adopted a learning methodthat binarily classifies sentences by using de-claratively subjective clues and their positions insentences as feature parameters of an SVM.With this method, a consistent framework ofclassification can be maintained even if we addnew declaratively subjective clues, and it is pos-sible that we can extract the opinion-expressingsentences which have unknown declarativelysubjective clues.3.1 Augmentation by Semantic CategoriesBefore we can use declaratively subjective cluesas feature parameters, we must address two is-sues:?
Cost of building a corpus:  It is costlyto provide a sufficient amount of taggedcorpus of opinion-expressing-sentence la-bels to ensure that learning achieves ahigh-performance extraction capability.?
Coverage of words co-occurring withdeclaratively subjective clues:  Many ofthe declaratively subjective clue expres-sions have co-occurring words in theopinion-expressing sentence.
Consider thefollowing two sentences.
(5) The sky is high.
(6) The quality of this product is high.Both (5) and (6) contain the word "high"in the predicate part.
Sentence (5) is con-sidered to be less of an opinion than (6)because an evaluator might judge (5) to bethe objective truth, while all evaluators arelikely to judge (6) to be an opinion.
Theadjective "high" in the predicate part canbe validated as a declaratively subjectiveclue depending on co-occurring words.However, it is not realistic to provide allpossible co-occurring words with eachdeclaratively subjective clue expression.Semantic categories can be of help in dealingwith the above two issues.
Declaratively subjec-tive clue expressions can be augmented by se-mantic categories of the words in the expressions.An augmentation involving both declarativelysubjective clues and co-occurrences will increasefeature parameters.
In our implementation, weadopted the semantic categories proposed byIkehara et al (1997).
Utilization of semanticcategories has another effect: it improves theextraction performance.
Consider the followingtwo sentence patterns:(7) X is beautiful.
(8) X is pretty.The words "beautiful" and "pretty" are adjec-tives in the common semantic category, "appear-ance", and the degree of declarative subjectivityof these sentences is almost the same regardlessof what X is.
Therefore, even if "beautiful" islearned as a declaratively subjective clue but"pretty" is not, the semantic category "appear-ance" that the learned word "beautiful" belongsto, enables (8) to be judged opinion expressingas well as (7).3.2 Feature Parameters to LearnWe implemented our opinion-sentence extrac-tion method by using a Support Vector Machine(SVM) because an SVM can efficiently learn themodel for classifying sentences into opinion-expressing and non-opinion expressing, based onthe combinations of multiple feature parameters.The following are the crucial feature parametersof our method.?
2,936 declaratively subjective clues?
2,715 semantic categories that words ina sentence can fall intoIf the sentence has a declaratively subjectiveclue of type (b), (c) or (l) in Table 2, the featureparameter about the clue is assigned a value of 1;if not, it is assigned 0.
If the sentence has de-claratively subjective clues belonging to types43other than (b), (c) or (l) in the predicate part, thefeature parameter about the clue is assigned 1; ifnot, it is assigned 0.The feature parameters for the semantic cate-gory are used to compensate for the insufficientamount of declaratively subjective clues pro-vided and to consider co-occurring words withclue expressions in the opinion-expressing sen-tences, as mentioned in Section 3.1.The following are additional feature parame-ters.?
150 frequent words?
13 parts of speechEach feature parameter is assigned a value of 1 ifthe sentence has any of the frequent words orparts of speech.
We added these feature parame-ters based on the hypotheses that some frequentwords in Japanese have the function of changingthe degree of declarative subjectivity, and thatthe existence of such parts of speech as adjec-tives and adverbs possibly influences the de-clarative subjectivity.
The effectiveness of theseadditional feature parameters was confirmed inour preliminary experiment.4 ExperimentsWe conducted three experiments to assess thevalidity of the proposed method: comparisonwith baseline methods, effectiveness of positioninformation in SVM feature parameters, and ef-fectiveness of SVM feature parameters such asdeclaratively subjective clues and semantic cate-gories.All experiments were performed using theJapanese sentences described in Section 2.1.
Weused 8,425 opinion expressing sentences, whichwere used to collect declaratively subjectiveclues as a training set, and used 4,938 opinion-expressing sentences as a test set.
We also used26,340 non-opinion sentences as a training setand used 16,006 non-opinion sentences as a testset.
The test set was divided into ten equal sub-sets.
The experiments were evaluated with thefollowing measures following the variablescheme in Table 3:baaPop +=   caaRop +=opopopopop RPRPF +=2dcdP opno +=_  dbdR opno +=_opnoopnoopnoopnoopno RPRPF_____2+=dcbadaA ++++=We evaluated ten subsets with the abovemeasures and took the average of these results.4.1  Comparison with Baseline MethodsWe first performed an experiment comparingtwo baseline methods with our proposed method.We prepared a baseline method that regards asentence as an opinion if it contains a number ofdeclaratively subjective clues that exceeds a cer-tain threshold.
The best threshold was setthrough trial and error at five occurrences.
Wealso prepared another baseline method thatlearns a model and classifies a sentence usingonly features about a bag of words.The experimental results are shown in Table 4.It can be seen that our method performs betterthan the two baseline methods.
Though the dif-ference between our method?s results and thoseof the bag-of-words method seems rather small,the superiority of the proposed method cannot berejected at the significance level of 5% in t-test.AnswerSystemOpinion No opinionOpinion a bNo opinion c dOpinion No opinionMethodPrecision Recall F-measure Precision Recall F-measureAccuracyOccurrences of DS clues(baseline 1)66.4% 35.3% 46.0% 82.6% 94.5% 88.1% 80.5%Bag of words(baseline 2)80.9% 64.2% 71.6% 89.6% 95.3% 92.4% 88.0%Proposed 78.6% 70.8% 74.4% 91.3% 94.0% 92.6% 88.6%Table 4: Results for comparison with baseline methodsTable 3: Number of sentences in a test set444.2 Feature Parameters with Position In-formationWe inspected the effect of position informationof 2,936 declaratively subjective clues based onthe heuristic rule that a Japanese predicate partalmost always appears in the last ten words in asentence.
Instead of more precisely identifyingpredicate position from parsing information, weemployed this heuristic rule as a feature parame-ter in the SVM learner for practical reasons.Table 5 lists the experimental results.
"Allwords" indicates that all feature parameters arepermitted at any position in the sentence.
"Last10 words" indicates that all feature parametersare permitted only if they occur within the lastten words in the sentence.We can see that feature parameters with posi-tion information perform better than those with-out position information in all evaluations.
Thisresult confirms our claim that the position of thefeature parameters is important for judgingwhether a sentence is an opinion or not.However, the difference did not indicate supe-riority between the two results at the significancelevel of 5%.
In the ?last 10 word?
experiment,we restricted the position of 422 declarativelysubjective clues like (b), (c) and (l) in Table 2,which appear in any position of a sentence, tothe same conditions as with the other types of2,514 declaratively subjective clues.
The factthat the equal position restriction on all declara-tively subjective clues slightly improved per-formance suggests there will be significant im-provement in performance from assigning theindividual position condition to each declara-tively subjective clue.4.3 Effect of Feature ParametersThe third experiment was designed to ascertainthe effects of declaratively subjective clues andsemantic categories.
The declaratively subjectiveclues and semantic categories were employed asfeature parameters for the SVM learner.
The ef-fect of each particular feature parameter can beseen by using it without the other feature pa-rameter, because the feature parameters are in-dependent of each other.The experimental results are shown in Table 6.The first row shows trials using only frequentwords and parts of speech as feature parameters.
"Y" in the first and second columns indicatesexclusive use of declaratively subjective cluesand semantic categories as the feature parame-ters, respectively.
For instance, we can deter-mine the effect of declaratively subjective cluesby comparing the first row with the second row.The results show the effects of declarativelysubjective clues and semantic categories.
Theresults of the first row show that the method us-ing only frequent words and parts of speech asthe feature parameters cannot precisely classifysubjective sentences.
Additionally, the last rowof the results clearly shows that using both de-claratively subjective clues and semantic catego-ries as the feature parameters is the most effec-tive.
The difference between the last row of theresults and the other rows cannot be rejectedeven at the significance level of 5%.Feature sets Opinion No opinionDScluesSemanticcategoriesPrecision Recall F-measurePrecision Recall F-measureAccuracy71.4% 53.2% 60.9% 87.7% 94.1% 90.8% 85.2%Y  79.9% 64.3% 71.2% 89.6% 95.0% 92.2% 87.8%Y 76.1% 68.9% 72.2% 90.7% 93.3% 92.0% 87.5%Y Y 78.6% 70.8% 74.4% 91.3% 94.0% 92.6% 88.6%Opinion No opinion PositionPrecision Recall F-measure Precision Recall F-measureAccuracyAll words 76.8% 70.6% 73.5% 91.2% 93.4% 92.3% 88.0%Last 10 words 78.6% 70.8% 74.4% 91.3% 94.0% 92.6% 88.6%Table 5: Results for feature parameters with position informationTable 6: Results for effect of feature parameters455 Conclusion and Future WorkWe proposed a method of extracting sentencesclassified by an SVM as opinion-expressing thatuses feature sets of declaratively subjective cluescollected from opinion-expressing sentences inJapanese web pages and semantic categories ofwords obtained from a Japanese lexicon.
Thefirst experiment showed that our method per-formed better than baseline methods.
The secondexperiment suggested that our method performedbetter when extraction of features was limited tothe predicate part of a sentence rather than al-lowed anywhere in the sentence.
The last ex-periment showed that using both declarativelysubjective clues and semantic categories as fea-ture parameters yielded better results than usingeither clues or categories exclusively.Our future work will attempt to develop anopen-domain opinion web search engine.
Tosucceed, we first need to augment the proposedopinion-sentence extraction method by incorpo-rating the query relevancy mechanism.
Accord-ingly, a user will be able to retrieve opinion-expressing sentences relevant to the query.
Sec-ond, we need to classify extracted sentences interms of emotion, sentiment, requirement, andsuggestion so that a user can retrieve relevantopinions on demand.
Finally, we need to sum-marize the extracted sentences so that the usercan quickly learn what the writer wanted to say.ReferencesClaire Cardie, Janyce Wiebe, Theresa Wilson, andDiane J. Litman.
2003.
Combining Low-Level andSummary Representations of Opinions.
for Multi-Perspective Question Answering.
Working Notes -New Directions in Question Answering (AAAISpring Symposium Series) .Kushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: Opinion extractionand semantic classification of product reviews.
Pro-ceedings of the 12th International World Wide WebConference, 519-528.Satoru Ikehara, Masahiro Miyazaki, Akio Yokoo, Sato-shi Shirai, Hiromi Nakaiwa, Kentaro Ogura, Yoshi-fumi Ooyama, and Yoshihiko Hayashi.
1997.
Ni-hongo Goi Taikei ?
A Japanese Lexicon.
IwanamiShoten.
5 volumes.
(In Japanese).Soo-Min Kim and Eduard Hovy.
2004.
Determining theSentiment of Opinions.
Proceedings of the.
COLING-04.Nozomi Kobayashi, Kentaro Inui, Yuji Matsumoto,Kenji Tateishi, and Toshikazu Fukushima.
2004.
Col-lecting Evaluative Expressions for Opinion Extrac-tion.
Proceedings of the First International Joint Con-ference on Natural Language Processing (IJCNLP-04), 584-589.Satoshi Morinaga, Kenji Yamanishi, and Kenji Tateishi.2002.
Mining Product Reputations on the Web.
Pro-ceedings of the eighth ACM SIGKDD InternationalConference on Knowledge Discovery and Data Min-ing (KDD 2002).Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
Sentiment Classification usingMachine Learning Techniques.
Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing (EMNLP-2002), 76-86.Tetsuya Nasukawa and Jeonghee Yi.
2003.
SentimentAnalysis: Capturing Favorability Using NaturalLanguage Processing.
Proceedings of the 2nd Inter-national Conference on Knowledge Capture(K-CAP2003).Ellen Riloff and Janyce Wiebe.
2003.
Learning Extrac-tion Patterns for Subjective Expressions.
Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing (EMNLP-03), 105-112.Kenji Tateishi, Yoshihide Ishiguro, and Toshikazu Fu-kushima, 2004.
A Reputation Search Engine thatCollects People?s Opinions by Information Extrac-tion Technology, IPSJ Transactions Vol.
45No.SIG07, 115-123.Peter Turney.
2002.
Thumbs Up or Thumbs Down?
Se-mantic Orientation Applied to Unsupervised Classifi-cation of Reviews.
Proceedings of the 40th AnnualMeeting of the Association for Computational Lin-guistics (ACL-2002), 417-424.Janyce Wiebe.
2000.
Learning Subjective Adjectivesfrom Corpora.
Proceedings of the 17th National Con-ference on Artificial Intelligence (AAAI -2000).Janyce Wiebe, Theresa Wilson, and Matthew Bell.
2001.Identifying Collocations for Recognizing Opinions.Proceedings of ACL/EACL 2001 Workshop on Col-location.Janyce Wiebe and Ellen Riloff.
2005.
Creating Subjec-tive and Objective Sentence Classifiers from Unanno-tated Texts.
Proceedings of Sixth International Con-ference on Intelligent Text Processing and Computa-tional Linguistics (CICLing-2005), 486-497.Theresa Wilson, Janyce Wiebe, and Rebecca Hwa, 2004.Just how mad are you?
Finding strong and weakopinion clauses.
Proceeding of the AAAI SpringSymposium on Exploring Attitude and Affect inText: Theories and Applications.Hong Yu and Vasileios Hatzivassiloglou.
2003.
To-wards Answering Opinion Questions: SeparatingFacts from Opinions and Identifying the Polarity ofOpinion Sentences.
Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP-2003).46
