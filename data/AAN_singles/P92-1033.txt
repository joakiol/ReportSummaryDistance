A PARAMETERIZED APPROACH TO INTEGRATING ASPECTWITH LEX ICAL-SEMANTICS  FOR MACHINE TRANSLAT IONBonn ie  J .
Dor r*Inst i tute for Advanced Computer  StudiesA.V.
Wil l iams Bui ldingUniversity of Mary landCollege Park, MD 20742bonnie@umiacs.umd.eduABSTRACTThis paper discusses how a two-level knowledge rep-resentation model for machine translation i tegrates as-pectual information with lexical-semantic information bymeans of parameterization.
The integration of aspectwith lexical-semantics s especially critical in machinetranslation because of the lexical selection and aspec-tual realization processes that operate during the pro-duction of the target-language sentence: there are of-ten a large number of lexical and aspectual possibili-ties to choose from in the production of a sentence froma lexical semantic representation.
Aspectual informa-tion from the source-language sentence constrains thechoice of target-language terms.
In turn, the target-language terms limit the possibilities for generation ofaspect.
Thus, there is a two-way communication chan-nel between the two processes.
This paper will showthat the selection/realization processes may be parame-terized so that they operate uniformly across more thanone language and it will describe how the parameter-based approach is currently being used as the basis forextraction of aspectual information from corpora.INTRODUCTIONThis paper discusses how the two-level knowledgerepresentation model for machine translation presentedby Dorr (1991) integrates aspectual information withlexical-semantic information by means of parameteriza-tion.
The parameter-based approach borrows certainideas from previous work such as the lexical-semanticmodel of Jackendoff (1983, 1990) and models of as-pectual representation i cluding Bach (1986), Comrie(1976), Dowty (1979), Mourelatos (1981), Passonneau(1988), Pustejovsky (1988, 1989, 1991), and Vendler(1967).
However, unlike previous work, the currentapproach examines aspectual considerations within thecontext of machine translation.
More recently, Bennett*This paper describes research done in the Institute forAdvanced Computer Studies at the University of Maryland.A special thanks goes to Terry Gaasterland and Ki Lee forhelping to close the gap between properties of aspectual in-formation and properties of lexical-semantic structure.
Inaddition, useful guidance and commentary during this re-search were provided by Bruce Dawson, Michael Herweg,Jorge Lobo, Paola Merlo, Norbert Hornstein, Patrick Saint-Dizier, Clare Voss, and Amy Weinberg.
(1) Syntact ic :(a)  Nu l l  Sub ject  d ivergence:E: I have seen Mary 4.
S: He vlsto a Mar ls(Have seen (to)  Mary)(b) Const i tuent  Order  d ivergence ,E: I have seen Mary 4.
G: Ich habe Marie gesehen( I  have Mar~" seen)(2) Lex ice l -Semant ic :(a) Thematic divergence:E: I like Mary 4.
$: Mar ls  me gusts a mf (Mary pleases me)(b) S t ruc tura l  divergence:E: John entered the house 4.
S: Juan  entr6 en la cas&(John entered in the house)(c) Cat  esor la l  divergence:E: Yo ten~o hambre  4* S: Ich habe Hun~er ( I  have hun~er)(3) Aepectuah(a) l terat ive Divergence:E: John stabbed Mary 4.S: Juan le dio una puflaJada a Mar ls(John gave a knife-wound to Mary)S: Juan le dio pufialadas a Mar ls(John gave knife-wounds to Mary)(b) Durat lve  D ivergence ,E: John met/knew Mary 4*S: Juan coaoci6 a Mar ls  ( John met  Mary)S: Juan conoci?
a M&rfa (John knew Merit)Figure 1: Three Levels of MT Divergenceset el.
(1990) have examined aspect and verb semanticswithin the context of machine translation in the spiritof Moens and Steedman (1988).
This paper borrowsfrom, and extends, these ideas by demonstrating howthis theoretical framework might be adapted for cross-linguistic applicability.
The framework has been testedwithin the context of an interlingual machine transla-tion system and is currently being used as the basis forextraction of aspectual information from corpora.The integration of aspect with lexical-semantics s es-pecially critical in machine translation because of thelexical selection and aspectual realization processes thatoperate during the production of the target-languagesentence: there are often a large number of lexical andaspectual possibilities to choose from in the productionof a sentence from a lexical semantic representation.
As-pectual information from the source-language sentenceconstrains the choice of target-language terms.
In turn,the target-language terms limit the possibilities for gen-eration of aspect.
Thus, there is a two-way communica-tion channel between the two processes.Figure 1 shows some of the types of parametric diver-9ences (Dorr, 1990a) that can arise cross-linguistically.257We will focus primarily on the third type, aspectual dis-tinctions, and show how these may be discovered throughthe extraction of information in a monolingual corpus.We adopt the viewpoint hat the algorithms for extrac-tion of syntactic, lexical-semantic, and aspectual infor-mation must be well-grounded in linguistic theory.
Oncethe information is extracted, it may then be used as thebasis of parameterized machine translation.
Note thatwe reject the commonly held assumption that the use ofcorpora necessarily suggests that statistical or example-based techniques be used as the basis for a machinetranslation system.The following section discusses how the two levels ofknowledge, aspectual and lexical-semantic, are used inan interlingual model of machine translation.
We thendescribe how this information may be parameterized.
Fi-nally, we discuss how the automatic acquisition of newlexical entries from corpora is achieved within this frame-work.TWO-LEVEL  K i t  MODEL:  ASPECTUALAND LEX ICAL-SEMANTIC  KNOWLEDGEThe hypothesis proposed by Tenny (1987, 1989) isthat the mapping between cognitive structure and syn-tactic structure is governed by aspectual properties.The implication is that lexical-semantic knowledge x-ists at a level that does not include aspectual infor-mation (though these two types of knowledge may de-pend on each other in some way).
This hypothesisis consistent with the view adopted here: we assumethat lexical semantic knowledge consists of such notionsas predicate-argument structure, well-formedness condi-tions on predicate-argument structures, and proceduresfor lexical selection of surface-sentence tokens; all othertypes of knowledge must be represented at some otherlevel.Figure 2 shows the overall design of the UNITRANmachine translation system (Dorr, 1990a, 1990b).
Thesystem includes a two-level model of knowledge represen-tation (KR) (see figure 2(a)) in the spirit of Dorr (1991).The translation example shown here illustrates the factthat the English sentence John went to the store whenMary arrived can be translated in two ways in Spanish.This example will be revisited later.The lexical-semantic representation that is used as theinterlingua for this system is an extended version of lexi.cal conceptual structure (henceforth, LCS) (see Jackend-off (1983, 1990)).
This representation is the basis for thelexical-semantic level that is included in the KR compo-nent.
The second level that is included in this componentis the aspectual structure.The KR component is parameterized by means of se-lection charts and coercion functions.
The notion of se-lection charts is described in detail in Dorr and Gaaster-land (submitted) and will be discussed in the contextof machine translation in the section on the Selectionof Temporal Connectives.
The notion of coercion func-tions was introduced for English verbs by Bennett et al(1990).
We extend this work by parameterizing the coer-cion functions and setting the parameters to cover Span-ish; this will be discussed in the section on Selection and(~)(b)I Lexical-SemanticStructureI AspectualStructureISyntacticStructureSelect ion ~ndCoerc ion  P&r&metersfor Engl ishSe lect ion  andCoerc ion  P~r~metersfor SpanishJohn went  to the storewhen Mary ?
r r ivedJuan fue 8 Is t iend ?.
.~cu ?ndo  M?r f ?
l leg6-4~ Ju ?n  fue ?
18 fiend&81 l legar Mar f ?Figure 2: Overall Design of UNITRANAspectual Realization of Verbs.An example of the type of coercion that will be con-sidered in this paper is the use of durative adverbials:{ foranhour. }
(4) (i) John ransacked the house until Jack arrived.
{ foranhour. }
(ii) John destroyed the house until Jack arrived.
(iii), John obliterated the house{ for an hour.until Jack arrived.
}Durative adverbials (e.g., for an hour and unt i l .
.
.
)are viewed as anti-cuiminators (following Bennett et al(1990)) in that they change the main verb from an ac-tion that has a definite moment of completion to an ac-tion that has been stopped but not necessarily finished.For example, the verb ransack is allowed to be modifiedby a durative adverbial since it is inherently durative;thus, no coercion is necessary in order to use this verbin the durative sense.
In contrast, the verb destroy isinherently non-durative, but it is coerced into a durativeaction by means of adverbial modification; this accountsfor the acceptability of sentence (4)(ii).
1 The verb oblit-erate must necessarily be non-durative (i.e., it is inher-ently non-durative and non-coercible), thus accountingfor the ill-formedness of sentence (4)(iii).In addition to the KR component, here is also a syn-tactic representation (SR) component (see figure 2(b))that is used for manipulating the syntactic structure ofa sentence.
We will omit the discussion of the SR compo-nent of UNITRAN (see, for example, Dorr (1987)) andwill concern ourselves only with the KR component forthe purposes of this paper.The remainder of this section defines the dividing linebetween lexical knowledge (i.e., properties of predicates1 Some native speakers consider sentence (4)(ii) to be odd,at best.
This is additional evidence for the existence of in-herent features and suggests that, in some cases (i.e., forsome native speakers), the inherent features are consideredto be absolute overrides, even in the presence of modifiersthat might potentially change the aspectual features.258and their arguments) and non-lexical knowledge (i.e.,aspect), and discusses how these two types of knowledgeare combined in the Kit component.Lex lca l -Semant ic  S t ructure .
Lexical-semantic struct-ure exists at a level of knowledge representation thatis distinct from that of aspect in that it encodes infor-mation about predicates and their arguments, plus thepotential realization possibilities in a given language.In terms of the representation proposed by Jackendoff(1983, 1990), the lexical-semantic structures for the twoevents of figure 2 would be the following:(5) (i) \[Event GOLoc(\[Thing John\],\[Position TOboc (\[Thing John\], \[Location Storel)l)\](ii) \[Event GOLoc(\[Thin s Mary\],\[Position TOLoc (\[Thing Mary\], \[Location el)\])\] 2Although temporal connectives are not included in Jack-endoff's theory, it is assumed that these two structureswould be related by means of a lexical-semantic tokencorresponding to the temporal relation between the twoevents.The lexical-semantic representation provided by Jack-endoff distinguishes between events and states; however,this distinction alone is not sufficient for choosing amongsimilar predicates that occur in different aspectual cat-egories.
In particular, events can be further subdividedinto more specific types so that non-cnlminative vents(i.e., events that do not have a definite moment of com-pletion) such as ransack can be distinguished from cul-minative events (i.e., events that have a definite momentof completion) such as obliterate.
This is a crucial dis-tinction given that these two similar words cannot beused interchangeably in all contexts.
Such distinctionsare handled by augmenting the lexical-semantic frame-work so that it includes aspectual information, which wewill describe in the next section.Aspectua l  S t ructure .
Aspect is taken to have twocomponents, one comprised of inherent features (i.e.,those features that distinguish between states andevents) and another comprised of non-inherent features(i. e., those features that define the perspective, .g., sim-ple, progressive, and perfective).
This paper will focusprimarily on inherent features, zPrevious representational frameworks have omittedaspectual distinctions among verbs, and have typicallymerged events under the single heading of dynamic (see,e.g., Yip (1985)).
However, a number of aspectuallyoriented lexical-semantic representations have been pro-posed that more readily accommodate he types of as-pectual distinctions discussed here.
The current workborrows extends these ideas for the development of aninterlingual representation.
For example, Dowty (1979)and Vendler (1967) have proposed a four-way aspectualclassification system for verbs: states, activities, achieve-ments, and accomplishments, each of which has a dif-ferent degree of telicity (i.e., culminated vs. nonculmi-2The empty location denoted by e corresponds to an un-realized argument of the predicate arrive.aSee Dorr and Gaasterland (submitted) for a discussionabout non-inherent aspectua\] features.nated), and/or atomicity (i.e., point vs. extended).
4 Asimilar scheme has been suggested by Bach (1986) andPustejovsky (1989) (following Mourelatos (1981) andComrie (1976)) in which actions are classified into states,processes, and events.The lexical-semantic structure adopted for UNITRANis an augmented form of Jackendoff's representationin which events are distinguished from states (as be-fore), but events are further subdivided into activities,achievements, and accomplishments.
The subdivision isachieved by means of three features proposed by Ben-nett etal.
(1990) following the framework of Moens andSteedman (1988): -t-dynamic (i.e., events vs. states,as in the Jackendoff ramework), +telic (i.e., culmina-tive events (transitions) vs. noneulminative events (ac-tivities)), and -I-atomic (i.e., point events vs. extendedevents).
We impose this system of features on top ofthe current lexical-semantic framework.
For example,the lexical entry for all three verbs, ransack, obliterate,and destroy, would contain the following lexical-semanticrepresentation:(6) \[Event CAUSE (\[Thing X\], \[Event GOLoc(\[Thing X\],\[Position TOLoc (\[X John\], \[Property DESTROYED\])\])\])\]The three verbs would then be distinguished by annotat-ing this representation with the aspectual features \[+d,-t,-a\] for the verb ransack, \[+d,+t,-a\] for the verb destroy,and \[+d,+t,+a\] for the verb obliterate, thus providingthe appropriate distinction for cases such as (4).
5In the next section, we will see how the lexical-semantic representation and the aspeetual structure arecombined parametrically to provide the framework forgenerating a target-language surface form.CROSS-L INGUIST IC  APPL ICABIL ITY :PARAMETERIZAT ION OF THETWO-LEVEL  MODELAlthough issues concerning lexical-semantics and as-pect have been studied extensively, they have not beenexamined sufficiently in the context of machine trans-lation.
Machine translation provides an appropriatetestbed for trying out theories of lexical semantics andaspect.
The problem of lexical selection during genera-tion of the target language is the most crucial issue inthis regard.
The current framework facilitates the se-lection of temporal connectives and the aspectual real-ization of verbs.
We will discuss each of these, in turn,4Dowty's version of this classification collapses achieve-ments and accomplishments into a single event type calleda transition, which covers both the point and extended ver-sions of the event type.
The rationale for this move is thatall events have some duration, even in the case of so-calledpunctual events, depending on the granulaxity of time in-volved.
(See Passonneau (1988) for an adaptation of thisscheme as implemented in the PUNDIT system.)
For thepurposes of this discussion, we will maintain the distinctionbetween achievements and accomplishments.5This system identifies five distinct categories of predi-State: i-d\] (llke, know)Activity (point): i-t-d, -t, -I-a\] (tap, wink)cates:  Activity (extended): i-I-d, -t, -a I (ransack, swim)Achievement: \[+d, +t, h-a\] (obliterate, kill)Accomplishment: i-I-d, -I-t, -a\] (destroy, 8rrlve)259Matrix Adjunct SelectedFeatures Perspective Type Perspective Word\[4-d,-t,4-a pelf \[+d,+t,4- a/ simp, perf When\[4-d,-t,:l: a 1 perfeetive l+d,+t,-I-a I strop, perf Cuando\[4-d,-t-t,4- ~ perf \[+d,+t,+a\] romp, perf AIFigure 3: Selection Charts for When, Cuando, and Alshowing how selection charts and coercion functions areused as a means of parameterization for these processes.Se lect ion of Temporal Connectives: Select ionChar ts .
In order to ensure that the framework pre-sented here is cross-linguistically applicable, we mustprovide a mechanism for handling temporal connectiveselection in languages other than English.
For the pur-poses of this discussion, we will examine distinctions be-tween English and Spanish only.Consider the following example:(7) (i) John went  to the store when Mary arrived.
(it) John had gone to the store when Mary arrived.In Dorr (1991), we discussed the selection of the lexicalconnective when on the basis of the temporal relationbetween the main or matrix clause and the subordinateor adjunct clause.
6 For the purposes of this paper, wewill ignore the temporal component of word selectionand will focus instead on how the process of word selec-tion may be parameterized using the aspectual featuresdescribed in the last section.To translate (7)0) and (it) into Spanish, we mustchoose between the lexical tokens cuando and al in or-der to generate the equivalent emporal connective forthe word when.
In the case of (7)(i), there are two pos-sible translations, one that uses the connective cuando,and one that uses the connective ai:(S) (i) Juan fue a la tienda euando Maria lleg6.
(it) Juan fue a la tienda al llegar Maria.Either one of these sentences i an acceptable translationfor (7)0).
However, the same is not true of (7)(it): 7(9) (i) Juan habfa ido a la tienda euando Maria lleg6.
(it) Juan habia ido a la tienda al Ilegar Maria.Sentence (9)(i) is an acceptable translation of (7)(it),but (9)(it) does not mean the same thing as (7)(it).
Thissecond sentence implies that John has already gone tothe store and come back, which is not the preferred read-ing.In order to establish an association between these con-nectives and the aspectual interpretation for the twoevents (i.e., the matrix and adjunct clause), we com-pile a table, called a selection chart, for each languagethat specifies the contexts in which each connective maybe used.
Figure 3 shows the charts for when, cuando,and al.
sThe selection charts can be viewed as inverted dic-tionary entries in that they map features to words, notSThis work was based on theories of tense/time by Horn-stein (1990) and Allen (1983, 1984).rI am indebted to Jorge Lobo (personal communication,1991) for pointing this out to me.aThe perfective and simple aspects are denoted as per\]and strop, respectively.words to features.
9 The charts serve as a means of pa-rameterization for the program that generates sentencesfrom the interlingual representation i  that they are al-lowed to vary from language to language while the pro-cedure for choosing temporal connectives applies cross-linguistically, l?
The key point to note is that the chartfor the Spanish connective al is similar to that for theEnglish connective when except hat the word al requiresthe matrix event to have the +telic feature (i.e., the ma-trix action must reach a culmination).
This accounts forthe distinction between cuando and al in sentences (9)(i)and (9)(it) above.
11,1~These tables are used for the selection of temporalconnectives during the generation process (for which therelevant index into the tables would be the aspectualfeatures associated with the interlingual representation).The selection of a temporal connective, then, is simply atable look-up procedure based on the aspectual featuresassociated with the events.Se lect ion and  Aspectua l  Rea l i za t ion  of  Verbs:Coerc ion  Funct ions .
Above, we considered the se-lection of temporal connectives without regard to theselection and aspectual realization of the lexical itemsthat were being connected.
Again, to ensure that theframework presented here is cross-linguistically applica-ble, we must provide a mechanism for handling lexical se-lection and aspectual realization in languages other thanEnglish.Consider the English sentence I stabbed Mary.
Thismay be realized in at least two ways in Spanish: 13(10) (i) Juan le dio pufialadaa  Maria(it) Juan le dio una pufialada Maria9 Note, however, that the features correspond to the eventsconnected by the words, not to the words themselves.1?Because we are not discussing the real ization of temporalin format ion (i.e., the t ime relat ions between the matr ix  andadjunct  events),  an abbreviated form of the actual  chart  isbeing used.
Specifically, the chart  shown in figure 3 assumesthat  the matr ix  event occurs before the adjunct  event.
SeeDorr (1991) and Dorr and Gaaster land (submit ted)  for moredetai ls about  the relat ionship between tempora l  informationand aspectual in format ion and the actual  procedures that  areused for the selection of tempora l  connectives.11 It has recently been pointed out  by Michael Herweg (per-sonal communicat ion,  1991b) that  the telic feature is nottradit ional ly  used to indicate a revoked consequence state(e.g., the consequence state that results after returning fromthe "going to the store" event), but it is generally intendedto indicate an irrevocable, culminative, consequence state.Thus, it has been suggested that al acts more as a com-plementizer than as a "pure" adverbial connective such ascuando; this would explain the realization of the adjunct notas a tensed adverbial clause, but as an infinitival subordinateclause.
This possibility is currently under investigation.12Space limitations do not permit the enumeration of theother selection charts for temporal connectives, but see Dorrand Gaasterland (submitted) for additional examples.
Someof the connectives that have been compiled into tables are:after, as soon as, at the moment that, before, between, during,since, so long as, until, while, etc.13Many other possibilities are available that are not listedhere (e.g., Juan le acuchill6 a Maria).260Both of these sentences translate literally to "John gavestab wound(s) to Mary."
However, the first sentenceis the repetitive version of the action (i.e., there weremultiple stab wounds), whereas the second sentence isthe non-repetitive version of the action (i.e., there wasonly one stab wound).
This distinction is character-ized by means of the atomicity feature.
In (10)(i), theevent is associated with the features \[+d,+t,-a\], whereas,in (10)(it) the event is associated with the features\[+d,+t,+a\].According to Bennett et al (1990), predicates are al-lowed to undergo an atomicity "coercion" in which aninherently non-atomic predicate (such as dio) may be-come atomic under certain conditions.
These conditionsare language-specific in nature, i.e., they depend on thelexical-semantic structure of the predicate in question.Given the current featural scheme that is imposed ontop of the lexical-semantic framework, it is easy to spec-ify coercion functions for each language.We have devised a set of coercion functions for Spanishanalogous to those proposed for English by Bennett et alThe feature coercion parameters for Spanish differ fromthose for English.
For example, the atomicity functiondoes not have the same applicability in Spanish as itdoes for English.
We saw this earlier in sentence (10), inwhich a singular NP verbal object maps a \[-a\] predicateinto a \[+a\] predicate, i.e., a non-atomic event becomesatomic if it is associated with a singular NP object.
Theparameterized mappings that we have constructed forSpanish are shown in figure 4(a).
For the purposes ofcomparison, the analogous English functions proposedby Bennett et al (1990) are shown in figure 4(b).
14Using the functions, we are able to apply the notionof feature-based coercion cross-linguistically, while stillaccounting for parametric distinctions.
Thus, featurecoercion provides a useful foundation for a model of in-terlingual machine translation.A key point about the aspectual features and coercionfunctions is that they allow for a two-way communica-tion channel between the two processes of lexical selec-tion and aspectual realization, is To clarify this point, wereturn to our example that compares the three Englishverbs, ransack, destroy, and obliterate (see example (4)above).
Recall that the primary distinguishing featureamong these three verbs was the notion of telicity (i.e.,culminated vs. nonculminated).
The lexical-semanticrepresentation for all three verbs is identical, but thetelicity feature differs in each case.
The verb ransack is+telic, obliterate is -telic, and destroy is inherently -telic,although it may be coerced to +telic through the use ofa durative adverbial phrase.
Because destroy is a "co-14Figure 4(b) contains a subset of the English functions.The reader is referred to Bennett et al (1990) for additionalfunctions.
The abbreviations C and AC stand for culminator,and anti-culminator, respectively.lSBecause the focus of this paper is on the lexical-semanticrepresentation a d associated aspectual parameters, the de-tails of the algorithms behind the implementation f the two-way communication channel are not presented here; these arepresented in Dorr and Gaasterland (submitted).
We will il-lustrate the intuition here by means of example.
(a)(b)MappingTelicity (C)f ( - t ) - .+tTelicity (AC)f (+t ) -* - tAtomicityf(+a)--.
*-aParameterssingular  NPcomplements' preter i t  pastprogressivemorphemeimperfect pastprogressivemorphemeplural NPcomplementsSpan ishExamplesJuan le dio una pufialadaa Marts' John s tabbed Mary (once)'Juan conoci6 a Marts' John met  Mary (once) 'Lee estaba p intando uncuadro'Lee was painting a picture(~r  some t ime) 'Lee conocfa a Maria'Lee knew Mary(for some t ime) 'Chris est?
estornudan?lo'Chris is sneez ing( repeated ly ) 'Juan le dio pufialadasa Maria' John s tabbed Mary( repeated ly ) 'MappingTelicity (C)f(-t)--*+tTelicity (AC)f (+t ) - * - tAtomicityf(+a)--*-aEn l$1 ishParameterssingular  NPcomplementseulminat ivedurat ivesprogressivemorphemenon-culminat ivedurat ivesprogressivemorphemefrequencyadverbialsExamplesJohn ran a mileJohn ran until  6proLee was paint ing a pictureLee painted the pict'urefor an hourChris is sneez ingChris ate a sandwicheverydayFigure 4: Parameterization of Coercion Functions forEnglish and Spanishercible" verb, it is stored in the lexicon as +telic with aflag that forces -telic to be the inherent (i. e., default) set-ting.
Thus, if we are generating a surface sentence froman interlingual form that matches these three verbs butwe know the value of the telic feature from the contextof the source-language s ntence (i.e., we are able to de-termine whether the activity reached a definite point ofcompletion), then we will choose ransack, if the settingis +telic, or obliterate or destroy, if the setting is -telic.In this latter case, only the word destroy will be selectedif the interlingua includes a component that will be re-alized as a durative adverbial phrase.Once the aspectual features have guided the lexicalselection of the verbs, we are able to use these selectionsto guide the aspectual realizations that will be used inthe surface form.
For example, if we have chosen theword obliterate we would want to realize the verb inthe simple past or present (e.g., obliterated or obliter-ate) rather than in the progressive (e.g., was obliteratingor is obliterating).
Thus, the aspectual features (and co-ercion functions) are used to choose lexical items, andthe choice of lexical items is used to realize aspectualfeatures.The coercion functions are crucial for this two-waychannel to operate properly.
In particular, we must takecare not to blindly forbid non-atomic verbs from beingrealized in the progressive since point activities, whichare atomic (e.g., tap), are frequently realized in the pro-gressive (e.g., he was tapping the table).
In such casesthe progressive morpheme is being used as an iteratorof several identical atomic events as defined in the func-tions shown in figure 4.
Thus, we allow "coercible" verbs261(i.e., those that have a +<feature> specification) to beselected and realized with the non-inherent feature set-ting if coercion is necessary for the aspectual realizationof the verb.ACQUIS IT ION OF  NOVEL  LEX ICALENTRIES:  D ISCOVERING THE L INKBETWEEN LCS AND ASPECTIn evaluating the parameterization framework pro-posed here, we will focus on one evaluation metric,namely the ease with which lexical entries may be au-tomatically acquired from on-line resources.
While test-ing the framework against this metric, a number of re-suits have been obtained, including the discovery of afundamental relationship between aspectual informationand lexical-semantic information that provides a link be-tween the primitives of Jackendoff's LCS representationsand the features of the aspectual scheme described here.Approach .
A program has been developed for the au-tomatic acquisition of novel lexical entries for machinetranslation.
16 We are in the process of building an En-glish dictionary, and intend to use the same approachfor building dictionaries in other languages, (e.g., Span-ish, German, Korean, and Arabic).
The program au-tomatically acquires aspeetual representations from cor-pora (currently the Lancaster/Oslo-Bergen 17 (LOB) cor-pus) by examining the context in which all verbs occurand then dividing them into four groups: state, activity,accomplishment, and achievement.
As we noted earlier,these four groups correspond to different combinations ofaspectual features (i.e., telic, atomic, and dynamic) thathave been imposed on top of the lexieal-semantic frame-work.
Thus, if we are able to isolate these componentsof verb meaning, we will have made significant progresstoward our ultimate goal of automatically acquiring fulllexical-semantic representations of verb meaning.The division of verbs into these four groups is based onseveral syntactic tests that are well-defined in the linguis-tic literature such as those by Dowty (1979) shown in fig-ure 5. is Some tests of verb aspect shown here could notbe implemented in the acquisition program because theyrequire human interpretations.
These tests are markedby asterisks (*).
For example, Test 2 requires humaninterpretation to determine whether or not a verb hashabitual interpretation i simple present ense.The algorithm for determining the aspectual categoryof verbs is shown in figure 6.
Note that step 3 appliesDowty's tests to a set of sentences corresponding to aparticular verb until a unique category has been iden-tified.
In order for this step to succeed, we must en-sure that Dowty's tests allow the four categories to beuniquely identified.
However, a complication arises forthe state category: out of the six tests that have beenimplemented from Dowty's table, only Test 1 uniquely16The implementat ion  deta i l s  o f  th i s  p rogram are  repor tedin Dorr and Lee (1992).lrICAME - -  Norwegian Computing Center for the Human-ities (tagged version).lSThis table is presented in Bennett et al (1990), p. 250,based on Dowry (1979).Test  STA ACT ACC ACH1.
X- ing Is g rammat ica l  no yes yes yes* 2. has hab i tua l  in terpretat ion  no yes yes yesin simple present tense3.
spend an  hour  X-ing, yes yes yes noX for an hour4.
take an  hour  X-ing, no no yes yesX in an hour* 5.
X for an hour  entai ls yes yes no noX at  all t imes in the hour* 6.
Y is X- ing entai ls  no yes no noY has X-ed7.
complement  of  stop yes yes yes no8.
complement  of  f inish no no yes no* 9. ambigu i ty  with a lmost  no no yes no*10.
Y X-ed in an  hour  entai ls  no no yes noY was X- ing dur ingthat  hour11.
occurs  with no yes yes nostudiously, carefully, etc .Figure 5: Dowty's Eleven Tests of Verb Aspect1.
Pick out  main  verbs f rom all sentences in the corpus  and storethem in a list cal led VERBS.2.
For  each verb v in VERBS,  f ind all sentences conta in ing  v andstore them in an ar ray  SENTENCES\ [ i \ ]  (where  i is the indexicalposi t ion of  v in VERBS) .3.
For  each sentence set Sj in SENTENCE\ [ j \ ] ,  loop through eachsentence s in Sj:(a) Loop  through each test  t in f igure 5.
(b) See if t appl ies to  s; if so, e l iminate all aspectua l  categor ieswith a NO in the row of f igure 5 cor respond ing  to test t.(c) E l iminate  possibi l it ies unti l  a un ique aspectua l  category  isidentif ied or unti l  all sentences in SENTENCES have beenexhausted.Figure 6: Algorithm for Determining Aspectual Cate-goriessets states apart from the other three aspectual cate-gories.
That is, Test 1 is the only implemented test thathas a value in the first column that is different from theother three columns.
Note, however, that the value inthis column is NO, which poses a problem for the abovealgorithm.
Herein lies one of the major stumbling blocksfor the extraction of information from corpora: it is onlypossible to derive new information in cases where thereis a YES value in a given column.
By definition, a cor-pus only provides positive evidence; it does not providenegative evidence.
We cannot say anything about sen-tences that do not appear in the corpus.
Just becausea given sentence does not occur in a particular sampleof English text does not mean that it can never showup in English.
This means we are relying solely on theinformation that does appear in the corpus, i.e., we areonly able to learn something new about a verb when itcorresponds to a YES in one of the rows of figure 5.19Given that the identification of stative verbs could notbe achieved by Dowty's tests alone, a number of hypothe-ses were made in order to identify states by other means.A preliminary analysis of the sentences in the corpus re-veals that progressive verbs are generally preceded byverbs such as be, like, hate, go, stop, start, etc.
These19 Note  that  th i s  is  cons is tent  w i th  pr inc ip les  o f  recent  mod-e ls  o f  language acqu is i t ion .
For  example ,  the  Subset Principleproposed by  Berwick  (1985,  p .
37)  s ta tes  that  " the  learnershould hypothesize languages in such a way that positive v-idence can  re fu te  an  incor rect  guess .
"262Verbs  Jackendof fP r imi t ivebe BElike BEhate BEgo GOstop GOstart GOfinish GOavoid STAYcontinue STAYkeep STAYAspectua lCategorystate ~STA)state (STA)state (STA)non-state q ACH)non-state ~ ACH)non-state q ACH)non-state q ACH)non-state ACT)non-state ACT)non-state ACT)Aspectua lFeatures\[-d l+d, +t, +a\]+d, +t, +a l+d, +t, +a\]+d, +t, -t-a\]l+d, -t l\[+d, -t\]\[+d, -t\]Figure 7: Circumstantial Verbs Categorized By Jackend-off's PrimitivesTest to see if X appears in the progressive.1.
If YES, then apply one of the tests that distinguishes ac-tivities from achievements (i.e., Test 3, Test 4, or Test 7).2.
If NO, apply Test 3 to rule out achievement or Test 4 touniquely identify as an achievement.3.
Finally, if the aspectual category is not yet uniquely iden-tified, either apply Test 11 to rule out activity or assumestate.Figure 8: Algorithm for Identifying Stative Verbsverbs fall under a lexical-semantic ategory identified byJackendoff (1983, 1990) as the circumstantial category.Based on this observation, the following hypothesis hasbeen made:Hypothes is  1: The only types of verbs that are allowed toprecede progressive verbs are circumstantial verbs.Circumstantial verbs subsume stative verbs, but theyalso include verbs in other categories.
In terms ofthe lexical-semantic primitives proposed by Jackendoff(1983, 1990), the circumstantial verbs found in a sub-set of the corpus are categorized as shown in figure 7.An intriguing result of this categorization is that thecircumstantial verbs provide a systematic partitioningof Dowty's aspectual categories (i.e., states, activities,and achievements) into primitives of Jackendoff's system(i.e., BE, STAY, and GO).
Thus, the analysis of the cor-pora has provided a crucial link between the primitives ofJackendoff's LCS representation and the features of theaspectual scheme described earlier.
If this is the case,then the framework has proven to be well-suited to thetask of automatic construction of conceptual structuresfrom corpora.Assuming this partitioning is correct and complete,Hypothesis 1 can be refined as follows:Hypothes is  1'~ The only types of verbs that are allowed toprecede progressive verbs are states, achievements, and activi-ties.If this hypothesis is valid, the program is in a better posi-tion to identify stative verbs because it corresponds to atest that requires positive evidence rather than negativeevidence.
The hypothesis can be described by addingthe following line to figure 5:Verbs  Aspectua l  Category(s )doing (ACC)facing (ACC ACT)asking (ACC ACT)made (ACC)drove ~ACC ACT)welcome (STA ACC ACT ACH)emphasized (STA ACC ACT ACH)thanked (ACC ACT STA)staged (ACC)make (ACC)continue ~ACC ACT)writes ~ACC)building ~ACC)running (ACC ACT)paint { ACC)finds ( ACC ACT)arrives { ACC ACT)jailed {ACC ACT STA)nominating (ACH ACT ACCread ( ACC ACT) )ensure (STA ACC ACT ACH)act ( ACT  ACC)carry (ACC)exercise (ACC)impose (STA ACC ACT ACH)contain ~STA ACC ACT ACH)infuriate (ACC ACT)Figure 9: Aspectual Classification Resultswhether X is stative.
2?Another hypothesis that has been adopted pertains tothe distribution of progressives with respect to the verbgo:Hypothes is  ~z The only types of progressive verbs that areallowed to follow the verb go are activities.This hypothesis was adopted after it was discoveredthat constructions such as go running, go skiing, goswimming, etc.
appeared in the corpus, but not construc-tions such as go eating, go writing, etc.
The hypothesiscan be described by adding the following line to figure 5:\[ Test \[ STA \[ ACT \[ ACC \] ACH \[13. go X-ing is grammatical no yes no noThe combination of Dowty's tests and these hypoth-esized tests allows the four aspectual categories to bemore specifically identified.Resu l ts  and Future  Work.
Preliminary results havebeen obtained from running the program on 219 sen-tences of the LOB corpus (see figure 9).
21 Note that theprogram was not able to pare down the aspectual cate-gory to one in every case.
We expect to have a significantimprovement in the classification results once the samplesize is increased.Presumably more tests would be needed for additionalimprovements in results.
For example, we have not pro-posed any tests that would guarantee the unique identi-fication of accomplishments.
Such tests are the subjectof future research.I Te., i I I Ace i AC.
I 12.
X <verb>-in~ is ~rammatical yes yes no yesBecause there is a YES in the column headed by STA,verbs satisfying this test are potentially stative.
Thus,once a verb X is found that satisfies this test, we applythe (heuristic) algorithm shown in figure 8 to determine2?Note that this algorithm does not guarantee that stateswill be correctly identified in all cases given that step 3 is aheuristic assumption.
However, if Test 12 has applied, andstate is still an active possibility, it is considerably safer toassume the verb is a state than it would be otherwise becausewe have eliminated accomplishments.21 For brevity, only a subset of the verbs are shown here.263In addition, research is currently underway to deter-mine the restrictions (analogous to those shown in fig-ure 5) that exist for other languages (e.g., Spanish, Ger-man, Korean, and Arabic).
Because the program is para-metrically designed, it is expected to operate uniformlyon corpora in other languages as well.Another future area of research is the automatic ac-quisition of parameter settings for the construction ofselection charts and aspectual coercion mappings on aper-language basis.SUMMARYThis paper has examined a two-level knowledge repre-sentation model for machine translation that integratesaspectual information based on theories by Bach (1986),Comrie (1976), Dowty (1979), mourelatos (1981), Pas-sonneau (1988), Pustejovsky (1988, 1989, 1991), andVendler (1967), and more recently by Bennett et al(1990) and Moens and Steedman (1988), with lexical-semantic information based on Jackendoff (1983, 1990).We have examined the question of cross-linguistic ap-plicability showing that the integration of aspect withlexical-semantics is especially critical in machine transla-tion when there are a large number of temporal connec-tives and verbal selection/realization possibilities thatmay be generated from a lexical semantic representa-tion.
Furthermore, we have illustrated that the se-lection/realization processes may be parameterized, bymeans of selection charts and coercion functions, so thatthe processes may operate uniformly across more thanone language.
Finally, we have discussed the applicationof the theoretical foundations to the automatic acquisi-tion of aspectual representations from corpora in order toaugment the lexical-semantic representations that havealready been created for a large number of verbs.REFERENCESAllen, James.
F. (1983) "Maintaining Knowledge about Temporal In-tervals," Communications ol the ACM 26:11,832-843.Allen, James.
F. (1984) "Towards a General Theory of Action andTime," Artificial Intelligence 23:2, 123-160.Bach, Emmon (1986) "The Algebra of Events," Linguistics and Phi-losophy 9, 5-16.Bennett, Winfield S., Tangs Herlick, Katherine Hoyt, Joseph Liro andAna Santistebem (1990) "A Computational Model of Aspect andVerb Semantics," Machine Translation 4:4, 247-280.Berwick, Robert C. (1985) The Acquisition of Syntactic Knowledge,MIT Press, Cambridge, MA.Cowrie, Bernard (1976) Aspect, Cambridge University Press, Cam-bridge, England.Dorr, Bonnie J.
(1987) "UNITRAN: A Principle-Ba~ed Approach toMachine Translation," AI Technical Report 1000, Master of Sciencethesis, Department of Electrical Engineering and Computer Science,Massachusetts Institute of Technology.Dorr, Bonnie J.
(1990a) "Solving Thematic Divergences in MachineTranslation," Proceedings of the ~Sth Annual Conference of theAssociation for Computational Linguistics, University of Pitts-burgh, Pittsburgh, PA, 127-134.Dorr, Bonnie J.
(1990b) "A Cross-Linguistic Approach to MachineTranslation," Proceedings of the Third International Conferenceon Theoretical and Methodological Issues in Machine Translationof Natural Languages, Linguistics Research Center, The Universityof Texas, Austin, TX,  13-32.Dorr, Bonnie J.
(1991) "A Two-Level Knowledge Representation forMachine Translation: Lexical Semantics and Tense/Aspect," Pro-ceedings of the Lexical Semantics and Knowledge RepresentationWorkshop, ACL-91, University of California, Berkeley, CA, 250-263.264Dorr, Bonnie J. and Ki Lee (1992) "Building a Lexicon for MachineTranslation: Use of Corpora for Aspectual Classification of Verbs,"Institute for Advanced Computer Studies, University of Maryland,UMIACS TR 92-41, CS TR 2876.Dorr, Bonnie J., and Terry Gaasterland (submitted) "Using Temporaland Aspectual Knowledge to Generate Event Combinations froma Temporal Database," Third International Conference on Prin-ciples of Knowledge Representation and Reasoning, Cambridge,MA, 1992.Dowty, David (1979) Word Meaning and Montague Grammar, Reidel,Dordrecht, Netherlands.Herweg, Michael (1991a) "Aspectual Requirements of Temporal Con-nectives: Evidence for a Two-level Approach to Semantics," Pro-ceedings of the Lexical Semantics and Knowledge RepresentationWorkshop, ACL-91, University of California, Berkeley, CA, 152-164.Hornstein, Norbert (1990) As Time Goes By, MIT Press, Cambridge,MA.ICAME - -  Norwegian Computing Center for the Humanities (taggedversion) Laneaster/Oslo-Bergen Corpus, Bergen University, Nor-way.Jackendoff, Hay S. (1983) Semantics and Cognition, MIT Press, Cam-bridge, MA.Jackendoff, Ray S. (1990) Semantic Structures, MIT Press, Cam-bridge, MA.Lobs, Jorge (1991) personal communication.Moens, Marc and Mark Steedman (1988) "Temporal Ontology andTemporal Reference," Computational Linguistics 14:2, 15-28.Mourelatos, Alexander (1981) "Events, Processes and States," inTense and Aspect, P. J. Tedeschi and A. Zaenen (eds.
), AcademicPress, New York, NY.Passonneau, Rebecca J.
(1988) "A Computational Model of the Seman-tics of Tense and Aspect," Computational Linguistics 14:2, 44-60.Pustejovsky, James (1988) "The Geometry of Events," Center for Cog-nitive Science, Massachusetts Institute of Technology, Cambridge,MA, Lexicon Project Working Papers #24.Pustejovsky, James (1989) "The Semantic Representation of LexicaiKnowledge," Proceedings of the First Annual Workshop on LexiealAcquisition, IJCAI.89, Detroit, Michigan.Pustejovsky, James (1991) "The Syntax of Event Structure," Cogni-tion.Tenny, Carol (1987) "Grammatiealizing Aspect and Affectedness,"Ph.D. thesis, Department of Electrical Engineering and ComputerScience, Massachusetts Institute of Technology.Tenny, Carol (1989) "The Aspectual Interface Hypothesis," Centerfor Cognitive Science, Massachusetts Institute of Technology, Cam-bridge, MA, Lexicon Project Working Papers #31.Vendler, Zeno (1967) "Verbs and Times," Linguistics in Philosophy,97-121.Yip, Kenneth M. (1985) "Tense, Aspect and the Cognitive Represen-tation of Time," Proceedings of the 23rd Annual Conference of theAssociation for Computational Linguistics, Chicago, IL, 18-26.
