Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1405?1415,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsCross-Cutting Models of Lexical SemanticsJoseph ReisingerDepartment of Computer SciencesThe University of Texas at AustinAustin, TX 78712joeraii@cs.utexas.eduRaymond MooneyDepartment of Computer SciencesThe University of Texas at AustinAustin, TX 78712mooney@cs.utexas.eduAbstractContext-dependent word similarity can bemeasured over multiple cross-cutting dimen-sions.
For example, lung and breath are sim-ilar thematically, while authoritative and su-perficial occur in similar syntactic contexts,but share little semantic similarity.
Both ofthese notions of similarity play a role in deter-mining word meaning, and hence lexical se-mantic models must take them both into ac-count.
Towards this end, we develop a novelmodel, Multi-View Mixture (MVM), that rep-resents words as multiple overlapping clus-terings.
MVM finds multiple data partitionsbased on different subsets of features, sub-ject to the marginal constraint that feature sub-sets are distributed according to Latent Dirich-let Allocation.
Intuitively, this constraint fa-vors feature partitions that have coherent top-ical semantics.
Furthermore, MVM uses softfeature assignment, hence the contribution ofeach data point to each clustering view is vari-able, isolating the impact of data only to viewswhere they assign the most features.
Througha series of experiments, we demonstrate theutility of MVM as an inductive bias for captur-ing relations between words that are intuitiveto humans, outperforming related models suchas Latent Dirichlet Allocation.1 IntroductionHumans categorize objects using multiple orthogo-nal taxonomic systems, where category generaliza-tion depends critically on what features are relevantto one particular system.
For example, foods can beorganized in terms of their nutritional value (high infiber) or situationally (commonly eaten for Thanks-giving; Shafto et al (2006)).
Human knowledge-bases such as Wikipedia also exhibit such multipleclustering structure (e.g.
people are organized by oc-cupation or by nationality).
The effects of theseoverlapping categorization systems manifest them-selves at the lexical semantic level (Murphy, 2002),implying that lexicographical word senses and tra-ditional computational models of word-sense basedon clustering or exemplar activation are too impov-erished to capture the rich dynamics of word usage.In this work, we introduce a novel probabilis-tic clustering method, Multi-View Mixture (MVM),based on cross-cutting categorization (Shafto et al,2006) that generalizes traditional vector-space ordistributional models of lexical semantics (Curran,2004; Pado?
and Lapata, 2007; Schu?tze, 1998; Tur-ney, 2006).
Cross-cutting categorization finds multi-ple feature subsets (categorization systems) that pro-duce high quality clusterings of the data.
For exam-ple words might be clustered based on their part ofspeech, or based on their thematic usage.
Context-dependent variation in word usage can be accountedfor by leveraging multiple latent categorization sys-tems.
In particular, cross-cutting models can be usedto capture both syntagmatic and paradigmatic no-tions of word relatedness, breaking up word featuresinto multiple categorization systems and then com-puting similarity separately for each system.MVM leverages primitives from Dirichlet-ProcessMixture Models (DPMMs) and Latent Dirichlet Al-location (LDA).
Each clustering (view) in MVM con-sists of a distribution over features and data andviews are further subdivided into clusters based on aDPMM.
View marginal distributions are determinedby LDA, allowing data features to be distributed overmultiple views, explaining subsets of features.1405We evaluate MVM against several other model-based clustering procedures in a series of humanevaluation tasks, measuring its ability to find mean-ingful syntagmatic and paradigmatic structure.
Wefind that MVM finds more semantically and syntac-tically coherent fine-grained structure, using bothcommon and rare n-gram contexts.2 Mixture Modeling and LexicalSemanticsDistributional, or vector space methods attempt tomodel word meaning by embedding words in a com-mon metric space, whose dimensions are derivedfrom, e.g., word collocations (Schu?tze, 1998), syn-tactic relations (Pado?
and Lapata, 2007), or latentsemantic spaces (Finkelstein et al, 2001; Landauerand Dumais, 1997; Turian et al, 2010).
The distribu-tional hypothesis addresses the problem of modelingword similarity (Curran, 2004; Miller and Charles,1991; Schu?tze, 1998; Turney, 2006), and can be ex-tended to selectional preference (Resnik, 1997) andlexical substitution (McCarthy and Navigli, 2007) aswell.
Such methods are highly scalable (Gormanand Curran, 2006) and have been applied in infor-mation retrieval (Manning et al, 2008), large-scaletaxonomy induction (Snow et al, 2006), and knowl-edge acquisition (Van Durme and Pas?ca, 2008).Vector space models fail to capture the richnessof word meaning since similarity is not a globallyconsistent metric.
It violates, e.g., the triangle in-equality: the sum of distances from bat to club andclub to association is less than the distance from batto association (Griffiths et al, 2007; Tversky andGati, 1982).1 Erk (2007) circumvents this problemby representing words as multiple exemplars deriveddirectly from word occurrences and embedded in acommon vector space to capture context-dependentusage.
Likewise Reisinger and Mooney (2010) takea similar approach using mixture modeling com-bined with a background variation model to generatemultiple prototype vectors for polysemous words.Both of these approaches still ultimately embedall words in a single metric space and hence arguefor globally consistent metrics that capture human1Similarity also has been shown to violate symmetry (e.g.people have the intuition that China is more similar to NorthKorea than North Korea is to China).intuitive notions of ?similarity.?
Rather than assum-ing a global metric embedding exists, in this workwe simply leverage the cluster assumption, e.g.
thatsimilar words should appear in the same clusters, inparticular extending it to multiple clusterings.
Thecluster assumption is a natural fit for lexical seman-tics, as partitions can account for metric violations.The end result is a model capable of representingmultiple, overlapping similarity metrics that resultin disparate valid clusterings leveraging theSubspace Hypothesis: For any pair ofwords, the set of ?active?
features govern-ing their apparent similarity differs.
Forexample wine and bottle are similar andwine and vinegar are similar, but it wouldnot be reasonable to expect that the fea-tures governing such similarity computa-tions to overlap much, despite occurringin similar documents.MVM can extract multiple competing notions of sim-ilarity, for example both paradigmatic, or thematicsimilarity, and syntagmatic or syntactic similarity, inaddition to more fine grained relations.3 Multi-View Clustering with MVMAs feature dimensionality increases, the number ofways the data can exhibit interesting structure goesup exponentially.
Clustering is commonly used toexplain data, but often there are several equallyvalid, competing clusterings, keying off of differentsubsets of features, especially in high-dimensionalsettings such as text mining (Niu et al, 2010).
Forexample, company websites can be clustered by sec-tor or by geographic location, with one particularclustering becoming predominant when a majorityof features correlate with it.
In fact, informative fea-tures in one clustering may be noise in another, e.g.the occurrence of CEO is not necessarily discrimi-native when clustering companies by industry sec-tor, but may be useful in other clusterings.
Multi-ple clustering is one approach to inferring featuresubspaces that lead to high quality data partitions.Multiple clustering also improves the flexibility ofgenerative clustering models, as a single model isno longer required to explain all the variance in thefeature dimensions (Mansinghka et al, 2009).1406exceedinglysincerelylogicallyjustlyappropriatelyunwillingwillingreluctantrefusinggladaboutbecauseand are ___which was ___who are ___and is ___we are ___he is ___toyotanissanmercedesvolvoaudisamsungpanasonictoshibasonyepsondunlopyokohamatoyouniroyalmichelinresults for ___the latest ___to buy ___brand new ___selection of ______ for saleFigure 1: Example clusterings from MVM applied toGoogle n-gram data.
Top contexts (features) for eachview are shown, along with examples of word clusters.Although these particular examples are interpretable, ingeneral the relationship captured by the view?s contextsubspace is not easily summarized.MVM is a multinomial-Dirichlet multiple clus-tering procedure for distributional lexical seman-tics that fits multiple, overlapping Dirichlet ProcessMixture Models (DPMM) to a set of word data.
Fea-tures are distributed across the set of clusterings(views) using LDA, and each DPMM is fit using asubset of the features.
This reduces clustering noiseand allows MVM to capture multiple ways in whichthe data can be partitioned.
Figure 1 shows a sim-ple example, and Figure 2 shows a larger sample offeature-view assignments from a 3-view MVM fit tocontexts drawn from the Google n-gram corpus.We implement MVM using generative modelprimitives drawn from Latent Dirichlet Allocation(LDA) and the Dirichlet Process (DP).
|M | disparateclusterings (views) are inferred jointly from a set ofdata D  twd|d P r1 .
.
.
Dsu.
Each data vectorwd is associated with a probability distribution overviews ?|M |d .
Empirically, ?|M |d is represented as aset of feature-view assignments zd, sampled via thestandard LDA collapsed Gibbs sampler.
Hence, eachview maintains a separate distribution over features.The generative model for feature-view assignment isgiven by?|M |d |?
 Dirichletp?q, d P D,?m|?
 Dirichletp?q, m P |M |,zdn|?d  Discretep?dq, n P |wd|,wdn|?zdnm  Discretep?zdnmq, n P |wd|,where ?
and ?
are hyperparameters smoothing theper-document topic distributions and per-topic worddistributions respectively.Conditional on the feature-view assignment tzu,a clustering is inferred for each view using the Chi-nese Restaurant Process representation of the DP.The clustering probability is given byppc|z,wq 9 pptcmu, z,wqM?m1|D|?d1ppwrzmsd |cm, zqppcm|zq.where ppcm|zq is a prior on the clustering for viewm, i.e.
the DPMM, and ppwrzmsd |cm, zq is the like-lihood of the clustering cm given the data point wdrestricted to the features assigned to view m:wrzmsddef twid|zid  mu.Thus, we treat them clusterings cm as conditionallyindependent given the feature-view assignments.The feature-view assignments tzu act as a set ofmarginal constraints on the multiple clusterings, andthe impact that each data point can have on eachclustering is limited by the number of features as-signed to it.
For example, in a two-view model,zid  1 might be set for all syntactic features (yield-ing a syntagmatic clustering) while zid  2 is set fordocument features (paradigmatic clustering).By allowing the clustering model capacity to varyvia the DPMM, MVM can naturally account for thesemantic variance of the view.
This provides a novelmechanism for handling feature noise: noisy fea-tures can be assigned to a separate view with poten-tially a small number of clusters.
This phenomenonis apparent in cluster 1, view 1 in the example infigure 2, where place names and adjectives are clus-tered together using rare contextsFrom a topic modeling perspective, MVM findstopic refinements within each view, similar to hier-archical methods such as the nested Chinese Restau-rant Process (Blei et al, 2003).
The main differ-ence is that the features assigned to the second ?re-fined topics?
level are constrained by the higher1407wordcontext___ home page___ open this result in___ who hada kind of ___along the ___and ___ theirare ___ tobe ___ tobut the ___ ofhe is ___in these ___is an ___many ___ andmight be ___of ___ haveof being ___posts by ___that ___ arethat was ___the ___ familythe ___ must bethe ___ of thatthe american ___the very ___were not ___who are ______ some ofa more ___also ___ theand ___ hisand are ___and is ___and was ___as ___ asbe ___ orbeen ___ andcould be ___his ___ ofi was ___is also ___near the ___of a ___ andof the ___ wereshe was ___so many ___the more ___to be ___ andwas ___ towe are ___were ___ inwhich ___ thewhich was ___who is ___you are ___do not ______ high school___ said that___ was bornan ___ andborn in ___by ___ onby ___ tocreate a ___degree of ___dsl ___ dslfromthe ___ togoing to ___hotels in ___in ___ thein an ___like ___ andlocated in ___message to ___name of ___posted by ___ atpresence of ___private message to ___the ___ does notthe city of ___to ___ atown of ___was the ___ ofwelcome to ___city of ___estate in ___hotels ___ hotelsof ___ mayreal estate in ___way of ___written by ___and an ___of ___ fromthethe little ______ of humanfirst ___ ofside of the ___to an ___0?0arbitraryaustinbaltimorecharacteristiccomparativedallasevolutionaryfranklinfundamentalinadequateinferiorintegraljacksonkentlikelihoodliverpoolmysticalnewcastlepittsburghpoeticproportionalpsychologicalradicalrichmondsingular0?10betrayedconquereddisappointeddivorcedembarkedfrustratedguardedhatedknockedmurderedpraisedstationedstolesummonedwounded0?77secretly1?0arbitrarybetrayedcharacteristicconquereddisappointeddivorcedembarkedevolutionaryexaminefranklinfrustratedfundamentalguardedhatedinadequateinferiorintegraljacksonknockedlikelihoodmurderedmysticalpoeticpraisedproportionalradicalsecretlysingularstationedstolesummonedsystematicwounded1?34kentliverpoolmanchesternewcastle1?94austinbaltimorecharlottedallaspittsburghrichmond2?0austinbetrayedcharlotteconquereddisappointeddivorcedembarkedfrustratedguardedhatedjacksonkentknockedmurderednewcastlepraisedrichmondsecretlystationedstolesummonedwounded2?47arbitrarycharacteristiccomparativeevolutionaryfundamentalinadequateinferiorintegralmysticalpoeticpsychologicalradicalsingularsystematicView1Cluster1Cluster2View2Cluster1View3Cluster1Cluster2Figure 2: Topics with Senses: Shows top 20% of features for each view in a 3-view MVM fit to Google n-gram contextdata; different views place different mass on different sets of features.
Cluster groupings within each view are shown.View 1 cluster 2 and View 3 cluster 1 both contain past-tense verbs, but only overlap on a subset of syntactic features.1408level, similar to hierarchical clustering.
Unlike hi-erarchical clustering, however, the top level top-ics/views form an admixture, allowing individualfeatures from a single data point to be assigned tomultiple views.The most similar model to ours is Cross-cuttingcategorization (CCC), which fits multiple DPMMs tonon-overlapping partitions of features (Mansinghkaet al, 2009; Shafto et al, 2006).
Unlike MVM,CCC partitions features among multiple DPMMs,hence all occurrences of a particular feature willend up in a single clustering, instead of assigningthem softly using LDA.
Such hard feature partition-ing does not admit an efficient sampling procedure,and hence Shafto et al (2006) rely on Metropolis-Hastings steps to perform feature assignment, mak-ing the model less scalable.3.1 Word RepresentationMVM is trained as a lexical semantic model onWeb-scale n-gram and semantic context data.
N-gram contexts are drawn from a combination of theGoogle n-gram and Google books n-gram corpora,with the head word removed: e.g.
for the term ar-chitect, we collect contexts such as the of thehouse, an is a, and the of the universe.
Se-mantic contexts are derived from word occurrencein Wikipedia documents: each document a word ap-pears in is added as a potential feature for that word.This co-occurrence matrix is the transpose of thestandard bag-of-words document representation.In this paper we focus on two representations:1.
Syntax-only ?
Words are represented as bagsof ngram contexts derived slot-filling proceduredescribed above.2.
Syntax+Documents ?
The syntax-only repre-sentation is augmented with additional docu-ment contexts drawn from Wikipedia.Models trained on the syntax-only set are only ca-pable of capturing syntagmatic similarity relations,that is, words that tend to appear in similar contexts.In contrast, the syntax+documents set broadens thescope of modelable similarity relations, allowing forparadigmatic similarity (e.g.
words that are topicallyrelated, but do not necessarily share common syntac-tic contexts).Given such word representation data, MVM gener-ates a fixed set of M context views corresponding todominant eigenvectors in local syntactic or seman-tic space.
Within each view, MVM partitions wordsinto clusters based on each word?s local representa-tion in that view; that is, based on the set of con-text features it allocates to the view.
Words have anon-uniform affinity for each view, and hence maynot be present in every clustering (Figure 2).
Thisis important as different ways of drawing distinc-tions between words do not necessarily apply to allwords.
In contrast, LDA finds locally consistent col-lections of contexts but does not further subdividewords into clusters given that set of contexts.
Hence,it may miss more fine-grained structure, even withincreased model complexity.4 Experimental Setup4.1 CorporaWe derive word features from three corpora: (1) theEnglish Google Web n-gram corpus, containing n-gram contexts up to 5-gram that occur more than 40times in a 1T word corpus of Web text, (2) the En-glish Google Books n-gram corpus2, consisting ofn-gram contexts up to 5-gram that occur more than40 times in a 500B word corpus of books, and (3) asnapshot of the English Wikipedia3 taken on Octo-ber 11, 2010 containing over 3M articles.MVM is trained on a sample of 20k English wordsdrawn uniformly at random from the top 200k En-glish terms appearing in Wikipedia (different partsof speech were sampled from the Google n-gramcorpus according to their observed frequency).
Twoversions of the syntax-only dataset are created fromdifferent subsets of the Google n-gram corpora: (1)the common subset contains all syntactic contextsappearing more than 200 times in the combined cor-pus, and (2) the rare subset, containing only contextsthat appear 50 times or fewer.4.2 Human EvaluationOur main goal in this work is to find models thatcapture aspects of the syntactic and semantic orga-nization of word in text that are intuitive to humans.2http://ngrams.googlelabs.com/datasets3http://wikipedia.org1409Context Intrusionis characterized top of the country tosymptoms of of understood or lesscases of along the a yearin cases of portion of the per dayreal estate in side of the or moreWord Intrusionmetal dues humorfloral premiums ingenuitynylon pensions advertiserswhat did delightruby damages astonishmentDocument IntrusionPuerto Rican cuisine Adolf Hitler History of the Han DynastyGreek cuisine List of General Hospital characters Romance of the Three KingdomsThinkPad History of France List of dog diseasesPalestinian cuisine Joachim von Ribbentrop Conquest of Wu by JinField ration World War I MongoliaTable 1: Example questions from the three intrusion tasks, in order of difficulty (left to right, easy to hard; computedfrom inter-annotator agreement).
Italics show intruder items.According to the use theory of meaning, lexical se-mantic knowledge is equivalent to knowing the con-texts that words appear in, and hence being able toform reasonable hypotheses about the relatedness ofsyntactic contexts.Vector space models are commonly evaluated bycomparing their similarity predictions to a nom-inal set of human similarity judgments (Curran,2004; Pado?
and Lapata, 2007; Schu?tze, 1998; Tur-ney, 2006).
In this work, since we are evaluatingmodels that potentially yield many different simi-larity scores, we take a different approach, scoringclusters on their semantic and syntactic coherenceusing a set intrusion task (Chang et al, 2009).In set intrusion, human raters are shown a set ofoptions from a coherent group and asked to identifya single intruder drawn from a different group.
Weextend intrusion to three different lexical semantictasks: (1) context intrusion, where the top contextsfrom each cluster are used, (3) document intrusion,where the top document contexts from each clus-ter are used, and (2) word intrusion, where the topwords from each cluster are used.
For each clus-ter, the top four contexts/words are selected and ap-pended with another context/word from a differentcluster.4 The resulting set is then shuffled, and thehuman raters are asked to identify the intruder, af-4Choosing four elements from the cluster uniformly at ran-dom instead of the top by probability led to lower performanceacross all models.ter being given a short introduction (with commonexamples) to the task.
Table 1 shows sample ques-tions of varying degrees of difficulty.
As the seman-tic coherence and distinctness from other clusters in-creases, this task becomes easier.Set intrusion is a more robust way to account forhuman similarity judgments than asking directly fora numeric score (e.g., the Miller and Charles (1991)set) as less calibration is required across raters.
Fur-thermore, the additional cluster context significantlyreduces the variability of responses.Human raters were recruited from Amazon?s Me-chanical Turk.
A total of 1256 raters completed30438 evaluations for 5780 unique intrusion tasks(5 evaluations per task).
2736 potentially fraudulentevaluations from 11 raters were rejected.5 Table 3summarizes inter-annotator agreement.
Overall wefound ?
 0.4 for most tasks; a set of commentsabout the task difficulty is given in Table 2, drawnfrom an anonymous public message board.5 ResultsWe trained DPMM, LDA and MVM modelson the syntax-only and syntax+documentsdata across a wide range of settings for M Pt3, 5, 7, 10, 20, 30, 50, 100, 200, 300, 500, 1000u,65(Rater Quality) Fraudulent Turkers were identified usinga combination of average answer time, answer entropy, averageagreement with other raters, and adjusted answer accuracy.6LDA is run on a different range of M settings from MVM(50-1000 vs 3-100) in order to keep the effective number of1410% correctMVM?100M?0.1?0.01MVM?50M?0.1?0.01MVM?30M?0.1?0.01MVM?20M?0.1?0.01MVM?10M?0.1?0.005MVM?10M?0.1?0.01MVM?5M?0.1?0.005MVM?5M?0.1?0.01MVM?3M?0.1?0.01LDA?1000M?0.1?0.01LDA?1000M?0.1?0.1LDA?500M?0.1?0.01LDA?500M?0.1?0.1LDA?300M?0.1?0.01LDA?300M?0.1?0.1LDA?200M?0.1?0.01LDA?200M?0.1?0.1LDA?100M?0.1?0.01LDA?100M?0.1?0.1LDA?50M?0.1?0.01LDA?50M?0.1?0.1DPMM?0.1?0.01DPMM?0.1?0.1context intrusionll0.0 0.2 0.4 0.6 0.8 1.0word intrusionll lll lll ll l ll0.0 0.2 0.4 0.6 0.8 1.0(a) Syntax-only, common n-gram contexts.% correctMVM?100M?0.1?0.01MVM?50M?0.1?0.01MVM?30M?0.1?0.01MVM?20M?0.1?0.01MVM?10M?0.1?0.005MVM?10M?0.1?0.01MVM?5M?0.1?0.005MVM?5M?0.1?0.01MVM?3M?0.1?0.01LDA?1000M?0.1?0.01LDA?1000M?0.1?0.1LDA?500M?0.1?0.01LDA?500M?0.1?0.1LDA?300M?0.1?0.01LDA?300M?0.1?0.1LDA?200M?0.1?0.01LDA?200M?0.1?0.1LDA?100M?0.1?0.01LDA?100M?0.1?0.1LDA?50M?0.1?0.01LDA?50M?0.1?0.1DPMM?0.1?0.01DPMM?0.1?0.1context intrusionllllll0.0 0.2 0.4 0.6 0.8 1.0word intrusionlll lllll0.0 0.2 0.4 0.6 0.8 1.0(b) Syntax-only, rare n-gram contexts.% correctMVM?100M?0.1?0.01MVM?50M?0.1?0.01MVM?30M?0.1?0.01MVM?20M?0.1?0.01MVM?10M?0.1?0.005MVM?10M?0.1?0.01MVM?5M?0.1?0.005MVM?5M?0.1?0.01MVM?3M?0.1?0.01LDA?1000M?0.1?0.01LDA?1000M?0.1?0.1LDA?500M?0.1?0.01LDA?500M?0.1?0.1LDA?300M?0.1?0.01LDA?300M?0.1?0.1LDA?200M?0.1?0.01LDA?200M?0.1?0.1LDA?100M?0.1?0.01LDA?100M?0.1?0.1LDA?50M?0.1?0.01LDA?50M?0.1?0.1DPMM?0.1?0.01DPMM?0.1?0.1context intrusionl lll0.0 0.2 0.4 0.6 0.8 1.0document intrusionl llll0.0 0.2 0.4 0.6 0.8 1.0word intrusionll lll l lll llllll l0.0 0.2 0.4 0.6 0.8 1.0(c) Syntax+Documents, common n-gram contexts.Figure 3: Average scores for each model broken down by parameterization and data source.
Error bars depict 95%confidence intervals.
X-axis labels show Model-views-?-?.
Dots show average rater scores; bar-charts show standardquantile ranges and median score.
1411U1 I just tried 30 of the what doesn?t belong ones.They took about 30 seconds each due to think-ing time so not worth it for me.U2 I don?t understand the fill in the blank ones tobe honest.
I just kinda pick one,since I don?tknow what?s expected lolU3 Your not filling in the blank just ignore theblank and think about how the words they showrelate to each other and choose the one thatrelates least.
Some have just words and noblanks.U4 These seem very subjective to mw.
i hopethere isn?t definite correct answers becausesome of them make me go [emoticon of head-scratching]U5 I looked and have no idea.
I guess I?m a wordidiot because I don?t see the relation betweenthe words in the preview HIT - too scared to tryany of these.U6 I didn?t dive in but I did more than I should havethey were just too easy.
Most of them I couldtell what did not belong, some were pretty iffythough.Table 2: Sample of comments about the task taken verba-tim from a public Mechanical Turk user message board(TurkerNation).
Overall the raters report the task to bedifficult, but engaging.?
P t0.1, 0.01u, and ?
P t0.1, 0.05, 0.01u inorder to understand how they perform relativelyon the intrusion tasks and also how sensitive theyare to various parameter settings.7 Models wererun until convergence, defined as no increase inlog-likelihood on the training set for 100 Gibbssamples.
Average runtimes varied from a few hoursto a few days, depending on the number of clustersor topics.
There is little computational overheadfor MVM compared to LDA or DPMM with a similarnumber of clusters.Overall, MVM significantly outperforms both LDAand DPMM (measured as % of intruders correctlyidentified) as the number of clusters increases.Coarse-grained lexical semantic distinctions areeasy for humans to make, and hence models withfewer clusters tend to outperform models with moreclusters.
Since high granularity predictions are moreclusters (and hence model capacity) roughly comparable.7We did not compare directly to Cross-cutting categoriza-tion, as the Metropolis-Hasting steps required that model weretoo prohibitively expensive to scale to the Google n-gram data.model size (clusters)%correct 0.00.51.00.00.51.0lll lll lllllll ll lllllllll ll lllllllll l102 102.5 103context intrusionword intrusion(a) Syntax-only, common n-gram contexts.model size (clusters)%correct 0.00.51.00.00.51.0llll lll l l lll ll lllllll lll lllll ll ll ll101.8 102 102.2 102.4 102.6 102.8 103 103.2context intrusionword intrusion(b) Syntax-only, rare n-gram contexts.Figure 4: Scatterplot of model size vs. avg score for MVM(dashed, purple) and LDA (dotted, orange).useful for downstream tasks, we focus on the inter-play between model complexity and performance.5.1 Syntax-only ModelFor common n-gram context features, MVM perfor-mance is significantly less variable than LDA on boththe word intrusion and context intrusion tasks, andfurthermore significantly outperforms DPMM (Fig-ure 3(a)).
For context intrusion, DPMM, LDA, andMVM average 57.4%, 49.5% and 64.5% accuracyrespectively; for word intrusion, DPMM, LDA, andMVM average 66.7%, 66.1% and 73.6% accuracyrespectively (averaged over all parameter settings).These models vary significantly in the average num-ber of clusters used: 373.5 for DPMM, 358.3 for LDAand 639.8 for MVM, i.e.
the MVM model is signifi-1412Model Syntax Syntax+Documents OverallDPMM 0.30 0.40 0.33LDA 0.33 0.39 0.35MVM 0.44 0.49 0.46Overall 0.37 0.43 0.39Table 3: Fleiss?
?
scores for various model and data com-binations.
Results from MVM have higher ?
scores thanLDA or DPMM; likewise Syntax+Documents data yieldshigher agreement, primarily due to the relative ease of thedocument intrusion task.cantly more granular.
Figure 4(a) breaks out modelperformance by model complexity, demonstratingthat MVM has a significant edge over LDA as modelcomplexity increases.For rare n-gram contexts, we obtain similar re-sults, with MVM scores being less variable acrossmodel parameterizations and complexity (Figure3(b)).
In general, LDA performance degrades fasteras model complexity increases for rare contexts, dueto the increased data sparsity (Figure 4(b)).
Forcontext intrusion, DPMM, LDA, and MVM average45.9%, 36.1% and 50.9% accuracy respectively;for word intrusion, DPMM, LDA, and MVM aver-age 67.4%, 45.6% and 67.9% accuracy; MVM per-formance does not differ significantly from DPMM,but both outperform LDA.
Average cluster sizes aremore uniform across model types for rare contexts:384.0 for DPMM, 358.3 for LDA and 391 for MVM.Human performance on the context intrusion taskis significantly more variable than on the word-intrusion task, reflecting the additional complexity.In all models, there is a high correlation betweenrater scores and per-cluster likelihood, indicatingthat model confidence reflects noise in the data.5.2 Syntax+Documents ModelWith the syntax+documents training set, MVM sig-nificantly outperforms LDA across a wide range ofmodel settings.
MVM also outperforms DPMM forword and document intrusion.
For context intru-sion, DPMM, LDA, and MVM average 68.0%, 51.3%and 66.9% respectively;8 for word intrusion, DPMM,LDA, and MVM average 56.3%, 64.0% and 74.9%respectively; for document intrusion, DPMM, LDA,8High DPMM accuracy is driven by the low number of clus-ters: 46.5 for DPMM vs. 358.3 for LDA and 725.6 for MVM.model size (clusters)%correct0.00.51.00.00.51.00.00.51.0llllllllllllll lllll lll llllllllllll lllll llllll llll lllll ll ll ll102 102.5 103 103.5context intrusiondocument intrusionword intrusionFigure 5: Scatterplot of model size vs. avg score forMVM (dashed, purple) and LDA (dotted, orange); Syn-tax+Documents data.and MVM average 41.5%, 49.7% and 60.6% re-spectively.
Qualitatively, models trained on syn-tax+document yield a higher degree of paradig-matic clusters which have intuitive thematic struc-ture.
Performance on document intrusion is sig-nificantly lower and more variable, reflecting thehigher degree of world knowledge required.
As withthe previous data set, performance of MVM mod-els trained on syntax+documents data degrades lessslowly as the cluster granularity increases (Figure 5).One interesting question is to what degree MVMviews partition syntax and document features versusLDA topics.
That is, to what degree do the MVMviews capture purely syntagmatic or purely paradig-matic variation?
We measured view entropy for allthree models, treating syntactic features and docu-ment features as different class labels.
MVM withM  50 views obtained an entropy score of 0.045,while LDA with M  50 obtained 0.073, and thebest DPMM model 0.082.9 Thus MVM views may in-deed capture pure syntactic or thematic clusterings.9The low entropy scores reflect the higher percentage of syn-tactic contexts overall.14135.3 DiscussionAs cluster granularity increases, we find that MVMaccounts for feature noise better than either LDAor DPMM, yielding more coherent clusters.
(Changet al, 2009) note that LDA performance degradessignificantly on a related task as the number of top-ics increases, reflecting the increasing difficulty forhumans in grasping the connection between termsin the same topic.
This suggests that as topics be-come more ne-grained in models with larger num-ber of topics, they are less useful for humans.
Inthis work, we find that although MVM and LDA per-form similarity on average, MVM clusters are signif-icantly more interpretable than LDA clusters as thegranularity increases (Figures 4 and 5).
We arguethat models capable of making such fine-grained se-mantic distinctions are more desirable.The results presented in the previous two sectionshold both for unbiased cluster selection (e.g.
whereclusters are drawn uniformly at random from themodel) and when cluster selection is biased basedon model probability (results shown).
Biased selec-tion potentially gives an advantage to MVM, whichgenerates many more small clusters than either LDAor DPMM, helping it account for noise.6 Future WorkModels based on cross-cutting categorization isa novel approach to lexical semantics and henceshould be evaluated on standard baseline tasks, e.g.contextual paraphrase or lexical substitution (Mc-Carthy and Navigli, 2007).
Additional areas for fu-ture work include:(Latent Relation Modeling) Clusterings formedfrom feature partitions in MVM can be viewed as aform of implicit relation extraction; that is, insteadof relying on explicit surface patterns in text, rela-tions between words or concepts are identified in-directly based on common syntactic patterns.
Forexample, clusterings that divide cities by geographyor clusterings partition adjectives by their polarity.
(Latent Semantic Language Modeling) Genera-tive models such as MVM can be used to build bet-ter priors for class-based language modeling (Brownet al, 1992).
The rare n-gram results demonstratethat MVM is potentially useful for tail contexts; i.e.inferring tail probabilities from low counts.
(Explicit Feature Selection) In this work we rely onsmoothing to reduce the noise of over-broad extrac-tion rather than performing feature selection explic-itly.
All of the models in this paper can be combinedwith feature selection methods to remove noisy fea-tures, and it would be particularly interesting to drawparallels to models of ?clutter?
in vision.
(Hierarchical Cross-Categorization) Human con-cept organization consists of multiple overlappinglocal ontologies, similar to the loose ontologicalstructure of Wikipedia.
Furthermore, each ontologi-cal system has a different set of salient properties.
Itwould be interesting to extend MVM to model hier-archy explicitly, and compare against baselines suchas Brown clustering (Brown et al, 1992), the nestedChinese Restaurant Process (Blei et al, 2003) andthe hierarchical Pachinko Allocation Model (Mimnoet al, 2007).7 ConclusionThis paper introduced MVM, a novel approach tomodeling lexical semantic organization using mul-tiple cross-cutting clusterings capable of captur-ing multiple lexical similarity relations jointly inthe same model.
In addition to robustly handlinghomonymy and polysemy, MVM naturally capturesboth syntagmatic and paradigmatic notions of wordsimilarity.
MVM performs favorably compared toother generative lexical semantic models on a set ofhuman evaluations, over a wide range of model set-tings and textual data sources.AcknowledgementsWe would like to thank the anonymous reviewers fortheir extensive comments.
This work was supportedby a Google PhD Fellowship to the first author.ReferencesDavid Blei, Thomas Griffiths, Michael Jordan, andJoshua Tenenbaum.
2003.
Hierarchical topicmodels and the nested Chinese restaurant process.In Proc.
NIPS-2003.Peter F. Brown, Peter V. deSouza, Robert L. Mercer,Vincent J. Della Pietra, and Jenifer C. Lai.
1992.Class-based n-gram models of natural language.Computational Linguistics, 18:467?479.1414Jonathan Chang, Jordan Boyd-Graber, Chong Wang,Sean Gerrish, and David M. Blei.
2009.
Readingtea leaves: How humans interpret topic models.In NIPS.James Curran.
2004.
From Distributional to Seman-tic Similarity.
Ph.D. thesis, University of Edin-burgh.Katrin Erk.
2007.
A simple, similarity-based modelfor selectional preferences.
In Proc.
of the ACL.Association for Computer Linguistics.Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-tan Ruppin.
2001.
Placing search in context: theconcept revisited.
In Proc.
of WWW 2001.James Gorman and James R. Curran.
2006.
Scalingdistributional similarity to large corpora.
In Proc.of ACL 2006.Thomas L. Griffiths, Mark Steyvers, and Joshua B.Tenenbaum.
2007.
Topics in semantic representa-tion.
Psychological Review, 114:2007.Thomas Landauer and Susan Dumais.
1997.
A solu-tion to Plato?s problem: The latent semantic anal-ysis theory of acquisition, induction and repre-sentation of knowledge.
Psychological Review,104(2):211?240.Christopher D. Manning, Prabhakar Raghavan, andHinrich Schu?tze.
2008.
Introduction to Informa-tion Retrieval.
Cambridge University Press.Vikash K. Mansinghka, Eric Jonas, Cap Petschu-lat, Beau Cronin, Patrick Shafto, and Joshua B.Tenenbaum.
2009.
Cross-categorization: Amethod for discovering multiple overlapping clus-terings.
In Proc.
of Nonparametric Bayes Work-shop at NIPS 2009.Diana McCarthy and Roberto Navigli.
2007.SemEval-2007 task 10: English lexical substitu-tion task.
In SemEval ?07: Proceedings of the 4thInternational Workshop on Semantic Evaluations.Association for Computational Linguistics.George A. Miller and Walter G. Charles.
1991.
Con-textual correlates of semantic similarity.
Lan-guage and Cognitive Processes, 6(1):1?28.David Mimno, Wei Li, and Andrew McCallum.2007.
Mixtures of hierarchical topics withpachinko allocation.
In ICML.Gregory L. Murphy.
2002.
The Big Book of Con-cepts.
The MIT Press.Donglin Niu, Jennifer G. Dy, and Michael I. Jor-dan.
2010.
Multiple non-redundant spectralclustering views.
In Johannes Fu?rnkranz andThorsten Joachims, editors, Proceedings of the27th International Conference on Machine Learn-ing (ICML-10), pages 831?838.Sebastian Pado?
and Mirella Lapata.
2007.Dependency-based construction of semanticspace models.
Computational Linguistics,33(2):161?199.Joseph Reisinger and Raymond J. Mooney.
2010.A mixture model with sharing for lexical seman-tics.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP-2010).Philip Resnik.
1997.
Selectional preference andsense disambiguation.
In Proceedings of ACLSIGLEX Workshop on Tagging Text with LexicalSemantics, pages 52?57.
ACL.Hinrich Schu?tze.
1998.
Automatic word sensediscrimination.
Computational Linguistics,24(1):97?123.Patrick Shafto, Charles Kemp, Vikash Mansinghka,Matthew Gordon, and Joshua B. Tenenbaum.2006.
Learning cross-cutting systems of cate-gories.
In Proc.
CogSci 2006.Rion Snow, Daniel Jurafsky, and Andrew Ng.
2006.Semantic taxonomy induction from heterogenousevidence.
In Proc.
of ACL 2006.Joseph Turian, Lev Ratinov, and Yoshua Bengio.2010.
Word representations: a simple and generalmethod for semi-supervised learning.
In Proc.
ofthe ACL.Peter D. Turney.
2006.
Similarity of semantic rela-tions.
Computational Linguistics, 32(3):379?416.Amos Tversky and Itamar Gati.
1982.
Similarity,separability, and the triangle inequality.
Psycho-logical Review, 89(2):123?154.Benjamin Van Durme and Marius Pas?ca.
2008.Finding cars, goddesses and enzymes:Parametrizable acquisition of labeled instancesfor open-domain information extraction.
In Proc.of AAAI 2008.1415
