Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically Rich Languages, pages 97?107,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsAn Empirical Study on the Effect of Morphological and Lexical Features inPersian Dependency ParsingMojtaba Khallash, Ali Hadian and Behrouz Minaei-BidgoliDepartment of Computer EngineeringIran University of Science and Technology{khallash,hadian}@comp.iust.ac.ir, b minaei@iust.ac.irAbstractThis paper investigates the impact of dif-ferent morphological and lexical informationon data-driven dependency parsing of Per-sian, a morphologically rich language.
Weexplore two state-of-the-art parsers, namelyMSTParser andMaltParser, on the recently re-leased Persian dependency treebank and es-tablish some baselines for dependency pars-ing performance.
Three sets of issues areaddressed in our experiments: effects of us-ing gold and automatically derived features,finding the best features for the parser, anda suitable way to alleviate the data sparsityproblem.
The final accuracy is 87.91% and88.37% labeled attachment scores for Malt-Parser and MSTParser, respectively.1 IntroductionResearchers have paid a lot of attention to data-driven dependency parsing in recent years (Bohnetand Kuhn, 2012; Bohnet and Nivre, 2012; Balles-teros and Nivre, 2013).
This approach is language-independent and is solely dependent on the availabil-ity of annotated corpora.
Using data-driven parsersfor some languages requires careful selection of fea-tures and tuning of the parameters to reach maxi-mum performance.
Difficulty of dependency pars-ing in each language depends on having either freeword order or morphological information.
Lan-guages with free word order have a high degreeof freedom in arranging the words of a sentence.Consequently, they usually have a high percentageof non-projective structures.
Morphology is deter-mined by large inventory of word forms (Tsarfaty etal., 2010).According to the results from CoNLL sharedtask 2007, languages are classified to three classes,namely low, medium and high accuracy languages.Among them, low-accuracy languages have high de-gree of free word order along with inflection (Nivreet al 2007a).
Languages which are more challeng-ing in parsing are called morphologically rich lan-guages (MRLs).
In MRLs, multiple levels of infor-mation, concerning syntactic units and relations, areexpressed at the word-level (Tsarfaty et al 2010).Free word order can be handled by non-projectiveparsing algorithms via either post-processing theoutput of a strictly projective parser (Nivre andNilsson, 2005), combining adjacent (Nivre, 2009)or non-adjacent sub-structures (McDonald et al2005).
Nevertheless, there is no general solutionfor resolving rich morphology issue and hence manyresearcher focus on features of a specific language.Most data-driven dependency parsers do not use anyinformation that is specific to the language beingparsed, but it is shown that using language specificfeatures has a crucial role in improving the overallparsing accuracy (Ambati et al 2010a).Persian is an Indo-European language that is writ-ten in Perso-Arabic script (written from right toleft).
The canonical word order of Persian is SOV97(subject-object-verb), but there are a lot of frequentexceptions in word order that turn this language intoa free word order language (Shamsfard, 2011).
Thislanguage has a high degree of free word order andcomplex inflections.
As an example of rich mor-phology, there are more than 100 conjugates and2800 declensions for some lemmas in Persian (Ra-sooli et al 2011).Dependency treebank for Persian (Rasooli et al2013) language has newly become available.
Due tothe lack of deep research on dependency parsing inPersian, we establish some baselines for dependencyparsing performance.
We also conduct a set of ex-periments in order to estimate the effect of errors inmorphological disambiguation on the parsers.
Weshow that with two simple changes to the input data,performance of the two parsers can be improved forboth gold (manually annotated) and predicted data.The remainder of the paper is organized as fol-lows.
Section 2 presents a brief overview of recentstudies on parsing morphologically rich languages.In section 3, we introduce available morphologicalfeatures annotated in our experiments.
Section 4 de-scribes the experimental setup, including corpus andparsers we use, and presents our experiments.
Ex-perimental evaluation and analysis of parsing errorsare demonstrated in Section 5.
Finally, we draw con-clusions and suggest future work in Section 6.2 Related workMany studies have been done on using morpholog-ical features for parsing morphologically rich lan-guages, (e.g.
Bengoetxea and Gojenola (2010),Seeker and Kuhn (2013), etc.).
Koo et al(2008) in-troduce cluster-based features that incorporate wordclusters derived from a large corpus of plain text, toimprove statistical dependency parsing for Englishand Czech.
Agirre et al(2011) use lexical semanticinformation derived from WordNet.Marton et al(2011) augment the baseline modelfor Arabic with nine morphological features.
Theyshow that using predicted features causes a substan-tial drop in accuracy while it greatly improves per-formance in the gold settings.
They show that us-ing noisy morphological information is worse thanusing nothing at all.
Same phenomenon is re-ported for Hebrew (Goldberg and Elhadad, 2010),except that using morphological-agreement featureimproves the accuracy of both gold and predictedmorphological information.Another interesting research direction is to findthe most beneficial features for dependency parsingfor each language.
Ambati et al(2010b) exploredthe pool of features for Hindi through a series of ex-periments.
In their setting, features are incremen-tally selected to create the best parser feature set.
InKorean, Choi and Palmer (2011b) focus on featureextraction and suggest a rule-based way of selectingimportant morphemes to use only these as featuresto build dependency parsing models.For the Persian language, Seraji et al(2012b) in-vestigated state-of-the-art dependency parsing algo-rithms on UPDT1 (Seraji et al 2012a).
They testthree feature settings, namely gold POS tags for boththe training and the test sets (GG), gold POS tags forthe training set and auto-generated POS tags for thetest set (GA), and auto-generated POS tags for boththe training and the test sets (AA).
The best resultis obtained in GG setting with 68.68% and 63.60%LAS, for MaltParser (Nivre et al 2007b) and MST-Parser (McDonald et al 2005) respectively.
UsingAA and GA settings show worse results than GG,namely 2.29% and 3.66% drop in accuracy for Malt-Parser, and 1.8% and 3.23% drop for MSTParser.They only explore the effect of gold and non-goldPOS tags with a small treebank with about 1,300sentences.
We apply GG and AA settings in our ex-periments on a larger treebank that contains richermorphological information.
We define pool of 10morphological and lexical semantic features in or-der to create the best feature set for the parser.3 Features of PersianIn this section, among possible morphological andsemantic features that exist in Persian, we briefly re-view a subset of them that is either annotated in Per-sian dependency treebank (Rasooli et al 2013) or isavailable from other studies.3.1 Features from TreebankTable 1 represents the features available in the Per-sian dependency treebank, along with possible val-ues for each feature.1Uppsala Persian Dependency Treebank98Feature ValuesAttachment {NXT, PRV, ISO}Animacy {animate, inanimate}Number {singular, plural}Person {1, 2, 3}Comparison {positive, comparative, superlative}TMA see Table 2Table 1: Description of features in TreebankIn some special cases, we have to break a wordinto smaller parts in order to capture the syntac-tic relations between the elements of the sentence.For example, the two-word sentence XQ?
??'@Y?
?se-dAyam kard?
(called me), consist of three mor-phemes: @Y?
(calling), ??
'(me), and XQ?
(to do)that have NXT (attached to the next word), PRV(attached to the previous word), and ISO (isolatedword) attachment, respectively.Person and number play a role in constrainingsyntactic structure.
Verbs usually agree with sub-ject in person and number (Shamsfard, 2011).
Thisagreement is useful feature to detect subject of sen-tence.
for example in ?Y	JJ 	?P A?
?m'.
,Q??
?
(hey boy,the kids are gone) sentence, both boy and kids arenoun, but only kids has number agreement with verb.Tense, mood, and aspect are not separately anno-tated in the treebank, but they can be induced fromthe TMA value.
Table 2 shows the conversion ta-ble which consists of 14 valid TMA values.
There isnot a unique mapping from TMA to aspect, becausein some conditions there is interference between theaspects.
For example, in indicative imperfective per-fect, the verb has perfect or continuous aspects.3.2 Automatic Semantic FeaturesWord Clusters [WC] We use all the words of thetreebank as inputs to the modified version of Brownclustering algorithm (Liang, 2005).
In order to tunethe parameters for the two parsers, we tweak thecluster count from 50 to 300 with steps of 50, and bitstrings from 4 to 14.
Finally, we choose 300 clustersand 6?bit strings for MaltParser and 150 clusters and10?bit strings for MSTParser2.2https://github.com/mojtaba-khallash/word-clusteringTMA Meaning Mood TenseHA Imperative Imp.
Pres.AY Indicative Future Ind.
Fut.GNES Indicative Imperfective Perfect Ind.
PastGBES Indicative Imperfective Pluperfect Ind.
PastGES Indicative Imperfective Preterit Ind.
PastGN Indicative Perfect Ind.
PastGB Indicative Pluperfect Ind.
PastH Indicative Present Ind.
Pres.GS Indicative Preterit Ind.
PastGBESE Subjunctive Imperfective Pluperfect Sub.
PastGESEL Subjunctive Imperfective Preterit Sub.
PastGBEL Subjunctive Pluperfect Sub.
PastHEL Subjunctive Present Sub.
Pres.GEL Subjunctive Preterit Sub.
PastTable 2: Tense/Mood/Aspect types in Persian verbs.Imp., Ind., Sub., Fut., and Pres.
stand for imperative, in-dicative, subjunctive, future and present, respectively.Semantic Verb Clustering [VC]: Semantic verbcluster is a generalization over verbs according totheir semantic properties that capture large amountsof verb meaning without defining details for eachverb.
Aminian et al(2013) clustered 1082 Persianverbs into 43 (fine-grained) semantic classes usingspectral clustering.
For each verb in the treebank,we included the corresponding cluster ID if the verbexists in the list of clustered verbs3.Synset Identifier [SID]: FarsNet (Shamsfard etal., 2010) is a lexical ontology for the Persian lan-guage that contains approximately 10000 synsets.For each word in the treebank, we look up for pos-sible synsets in FarsNet.
If any synset is found, weadd the ID of the first synset to our feature set.
About59% of words in the treebank were supplied with asynset.Semantic File [SF]: In English WordNet, eachsynset belongs to a unique semantic file.
There isa total of 45 semantic files (1 for adverbs, 3 foradjectives, 15 for verbs, and 26 for nouns), basedon syntactic and semantic categories (Agirre et al2011).
FarsNet has a mapping to those of WordNetsynsets.
We use both synsetID and semantic filesas instances of fine-grained and coarse-grained se-mantic representations, respectively.
Thus, we can3https://github.com/mojtaba-khallash/verb-spectral-cluster99learn what level of granularity in semantic featurescan help improve performance of the parser4.4 ExperimentsCorpus Persian dependency treebank version1.0 (Rasooli et al 2013) is a freely-available re-source5 with about 30,000 sentences, and half a mil-lion tokens, annotated with syntactic roles in addi-tion to morpho-syntactic features.
The annotationemploys 17 coarse-grained and 30 fine-grained POStags, 22 morphological feature values and 43 depen-dency labels.
21.93% of the sentences and 2.47% ofthe edges are non-projective.Table 3 provides statistical properties of Persiandependency treebank, compared to UPDT6.
In Per-sian dependency treebank, syntactic and/or morpho-logical features are represented as key-value pairsseparated by vertical bars (?|?
), while in UPDT, theyare represented as a single atomic feature.Treebank Persian DT UPDTTok 498081 151671Sen 29982 6000AvgSL 16.61 25.28Lem yes noCPoS 17 15PoS 30 30MSF 22 30Dep 43 48NPT 2.47% 0.17%NPS 21.93% 2.73%Table 3: Comparison of UPDT (Seraji et al 2012a)and Persian dependency treebank (Rasooli et al 2013).Tok = number of tokens; Sen = number of sentences;AvgSL = Average sentence length; Lem = lemmatiza-tion present; CPoS = number of coarse-grained part-of-speech tags; PoS = number of (fine-grained) part-of-speech tags; MSF = number of morphosyntactic features(split into atoms); Dep = number of dependency types;NPT = proportion of non-projective dependencies/tokens(%); NPS = proportion of non-projective dependencygraphs/sentences (%)The data is split into standard train, development4https://github.com/mojtaba-khallash/semantic-tagger5http://www.dadegan.ir/en6Freely available at http://stp.lingfil.uu.se/?mojgan/UPDT.htmland test sets by the ratio of 80-10-10 percent in theCoNLL dependency format.
Furthermore, the tree-bank is released in two representations with littlechanges in their annotations.
A sample comparisonbetween the two annotations is shown in Figure 1.In the first representation, which is manually anno-tated, the accusative case marker @P /rA/ is supposedto be the head of the object plus rA.
In the secondrepresentation, which is an automatic conversion ofthe first one obtained by reverse ordering the man-ual annotation, rA is not the head of the object word.Instead, rA is regarded as the accusative case markerfor the direct object.. ?Y	K @?
k ?
?
??
??
@P ?G.
AJ?
root.
read said that acc.
the bookPUNC V V SUBR POSTP NPUNCROOTOBJPREDEPNCLPOSDEP(a) First representation: Manually annotating accusative casemarker @P as object of the sentence.
?Y	K @?
k ?
?
??
??
@P ?G.
AJ?
root.
read said that acc.
the bookPUNC V V SUBR POSTP NPUNCROOTOBJACC-CASENCLPOSDEP(b) Second representation: Automatic conversion of first rep-resentation.
The accusative case marker @P depends on originalobject of the sentence.Figure 1: Two representation of object-verb relation for?I read the book that you mentioned.?
(Rasooli et al2013).Evaluation metric The most commonly usedmetrics for dependency parsing are unlabeled attach-ment score (UAS), labeled attachment score (LAS)and label accuracy (LA).
UAS is the proportion ofwords that are assigned the correct head, LAS isthe proportion of words that are assigned the correcthead and dependency type, and LA is the proportionof words that are assigned the correct dependency100type.
We use LAS as our evaluation metric andtake punctuation into account as for evaluating outparsing results.
We use McNemars statistical signif-icance test as implemented by (Nilsson and Nivre,2008), and denote p < 0.05 and p < 0.01 with +and ++, respectively.Parsers We use two off-the-shelf data-drivenparsers, namely MaltParser (Nivre et al 2007b)and MSTParser (McDonald et al 2005), which arethe two state-of-the-art dependency parsers that rep-resent dominant approaches in data-driven depen-dency parsing.MaltParser7 is based on a transition-based ap-proach to dependency parsing.
Transition-based ap-proach is based on transition systems for derivingdependency trees, that greedily searches for highestscoring transitions and uses features extracted fromparse history to predict the next transition (Choi andPalmer, 2011a).
We use MaltParser 1.7.1 along withnine different parsing algorithms.
In order to se-lect the best algorithm and tune the parameters ofMaltParser, we use MaltOptimizer (Ballesteros andNivre, 2012) on the whole of training data.
Mal-tOptimizer analyzes data in three-phase optimiza-tion process: data analysis, parsing algorithm selec-tion, and feature selection.MSTParser8 is based on a graph-based approachto dependency parsing.
The algorithm searchesglobally in a complete graph to extract a spanningtree during derivations using dynamic programming.We use MSTParser 0.5 which has two implementa-tions of maximum spanning tree (MST) algorithmwith projective and non-projective models9.Baseline Experiments We run three phases ofMaltOptimizer on the training set in order to findthe best parsing algorithm in MaltParser.
The firstphase validates the data and gains 84.02% LAS withthe default settings.
In the second phase, usingnon-projective version of the Covington algorithm,which has the best accuracy, and after parameter tun-7http://www.maltparser.org/8http://www.seas.upenn.edu/?strctlrn/MSTParser/MSTParser.html9We developed an all-in-one dependency parsing tool-box that integrates different dependency parsing algo-rithms: https://github.com/mojtaba-khallash/dependency-parsing-toolboxing, 85.86% LAS was obtained.
In the third phase,the feature model was optimized and by tuning theregularization parameter of the multiclass SVM; itled to 87.43% LAS.
Finally, we trained the bestalgorithm with optimized settings on training setand parsed on development set, thereby we reached87.70% LAS as the baseline of MaltParser.We tested four parsing algorithms that exist inMSTParser and as a result, non-projective algorithmwith a second-order feature decoder gave 88.04%LAS, which shows the highest improvement.
There-fore, we selected that as our baseline for MSTParser.The baselines are obtained on the first represen-tation of the treebank.
We found baselines for thesecond representation of the treebank on the devel-opment set.
Results are compared in Table 4.The first representation performs better than thesecond one.
This was expected before, since rA is aconstant word that is annotated as the object of a sen-tence in the first representation.
This helps parsers tofind the object in a sentence.
Moreover, as shown inFigure 1, rA is closer to the verb than the direct ob-ject, hence it has more chance to select.Representation Malt MSTFirst 87.70 88.04Second 87.22 (-0.48) 87.03 (-1.01)Table 4: Comparison of two representations of PersiantreebankResults In our experiments, we use the first repre-sentation of treebank with algorithms and new con-figurations presented in previous paragraph.
For allexperiments in this section, we use training and de-velopment sets of the treebank.
In order to studythe effects of morphology in dependency parsing ofPersian, we organize experiments into three typesof challenges which are presented by Tsarfaty et al(2010): architecture and setup, representation andmodeling, and estimation and smoothing.Architecture and Setup When using dependencyparsing on real-world tasks, we usually face withsentences that must be tokenized, lemmatized, andtagged with part of speech and morphological infor-mation to offer those information as input featuresto the parsing algorithms.
Bijankhan corpus (Bi-jankhan, 2004) is the first manually tagged Persian101corpus that consists of morpho-syntactic and mini-mal semantic annotation of words.
It is commonlyused to train POS tagger, but its POS tagset is differ-ent from tagset of the treebank that we use.
Sarabi etal.
(2013) introduce PLP Toolkit which is a compre-hensive Persian Language Processing (PLP) toolkitthat contains fundamental NLP tools such as to-kenizer, POS tagger, lemmatizer and dependencyparser.
They merged the POS tagset of 10 millionwords from bijankhan corpus with Persian depen-dency treebank in order to create a bigger corpuswith the same tagset.
They choose the tagset of Per-sian dependency treebank as the base setting andconvert Bijankhan tagset to them.
They have 11coarse-grained and 45 fine-grained POS tags.
PLPPOS tagger can automatically recognize three mor-phological features, namely number, person, andTMA.
TMA values of the PLP tool are not the sameas Persian dependency treebank.
Despite 14 possi-ble TMA values in dependency treebank (Table 2),only four out of the 14 values exist in PLP (AY, GS,H, and HA), because there is no other value in Bi-jankhan tagset for verbs.
The accuracy of PLP POStagger on the fine grained tagset is about 98.5%.
Weuse this tagger and apply it on our training, develop-ment, and test data.
Results from these experimentsare presented in Table 5.POS tags type Malt MSTGold 87.70 88.04Predicted 86.98 (-0.72) 86.81 (-1.23)Table 5: Effect of gold vs. predicted POS tags and mor-phological information in dependency parsers for Per-sian.Representation and Modeling In our experi-ment, we use ten features of morphological and se-mantic information.
Using a forward selection pro-cedure, the best feature set for each parser can befound.
Beside morphological features which existin the treebank (Attachment [A], Person [P],Num-ber [N], TMA), we add Tense [T] and Mood [M]with a simple conversion table, shown in Table 2,based on the value of TMA.Table 6 shows the effect of each feature for Malt-Parser and MSTParser parser.
For the former, moodwith slight differences achieves the best result andFeature Malt Feature MSTBaseline 87.70 Baseline 88.04M 87.77 TMA 88.21+TMA 87.77 M 88.17T 87.73 P 88.09SF 87.70 T 88.04WC 87.69 N 88.04VC 87.68 SID 88.03SID 87.67 SF 88.03A 87.67 WC 88.02P 87.66 VC 87.98N 87.65 A 87.93Table 6: Effect of each feature on two parsersfor the latter, TMA has the highest accuracy thanother features.
TMA and two derivate features,namely T and M, stands at the top of this ranking,and four semantic features are placed in the middle.This means that our newly added features can helpto improve performance of each parser.In the next steps, we incrementally add one fea-ture to the best result from previous step.
As shownin Table 7, combination of M and SF obtains thebest result for MaltParser (87.81%), while for MST-Parser, combination of TMA and WC is the best(88.25%).
In the second step, adding one seman-tic feature gets the best result.
By trying to continuethis approach, we do not see any improvement in theaccuracy for both parser10.Feature Malt Feature MST{M,SF} 87.81 {TMA,WC} 88.25{M,T} 87.79 {TMA,SID} 88.21{M,VC} 87.78 {TMA,N} 88.16{M,TMA} 87.77 {TMA,P} 88.14{M,N} 87.76 {TMA,M} 88.13{M,WC} 87.75 {TMA,A} 88.11{M,A} 87.75 {TMA,T} 88.11{M,P} 87.73 {TMA,VC} 88.07{M,SID} 87.69 {TMA,SF} 88.05Table 7: Combinations of two features10https://github.com/mojtaba-khallash/treebank-transform102Estimation and Smoothing Using a few trainingdata, especially for languages with rich morphol-ogy, lexical features may infrequently appear duringtraining.
In MRLs like Persian, due to many featurecombination by the inflectional system, we face ahigh rate of out-of-vocabulary.
There are some waysto cope with this problem:?
Replacing word forms by lemma: Lemma ofa word has less data sparsity than word form.?
Number Normalization This is the default ap-proach in MSTParser, in which each number isreplaced by a constant.
We apply this approachfor numbers written either in English or Persianscripts.?
Word Clustering and Semantic File: Thecluster ID of a word or its semantic file can beused instead of the original word form.
Theseare two ways to categorize words into a groupbigger than their lemma.Table 8 illustrates the effect of each smoothingmethod on the accuracy for parsing MaltParser andMSTParser.
For MaltParser, number normalizationis the only technique that improves the accuracy.For MSTParser, replacing word forms by lemma andnumber normalization improves the accuracy.
In thecase of MSTParser, we apply each method sepa-rately and simultaneously on the development set,but replacing word forms by lemma gets the best im-provement, and hence we use it in our final configu-ration.Smoothing Malt MSTBaseline 87.70 88.04Replacing word forms by lemma 87.38 88.10Number Normalization 87.71 88.09Word Clustering 86.98 87.47Semantic File 87.31 85.25Table 8: Accuracy obtained after applying differentsparsity-reduction tricks.5 Error AnalysisWe use the best configurations from the previoussection on the training and test data, for gold an-notation and an automatically derived one.
Table 9shows the final test results of the two parsers for Per-sian.
In addition to LAS, we also include UAS andLA to facilitate comparisons in the future.
Baselineresults are included in the table.
In the case of Malt-Parser, after applying new configurations on data,we repeat the third phase of MaltOptimizer in orderto find the best feature template for the new trainingdata.
It seems that the graph-based parser performsbetter than transitions-based parsers in general.
De-spite a high overall parsing accuracy, only 1017 and922 (33.91% and 30.74%) of sentences in the testset (with 2999 sentences) are parsed without errorsby MaltParser and MSTParser, respectively.
Malt-Parser has lower overall accuracy compared to MST-Parser, but the number of completely correct parsedsentences for MaltParser is more than MSTParser.In the case of predicted setting, as mentioned in sec-tion 4, there are four values for TMA.
This meansthat we cannot create tense and mood from TMA.For this reason, we force to use TMA in the finalconfiguration of both parsers in the predicted setting.In order to evaluate parsing errors, we use thesame approach as (McDonald and Nivre, 2011) toshows a set of linguistic and structural properties ofthe baseline and our best setting for each parser11.Length Factors Figure 2 shows the accuracy rel-ative to the sentence length in test data.
Since thereare very limited long sentences in our treebank,the parser cannot predict longer sentences correctly.Consequently, the two parsers tend to have lower ac-curacies for longer sentences.
Both parsers have thesame performance, but MSTParser tends to performbetter on shorter sentences, that is in contrast withresults showed by McDonald and Nivre (2011).
Wecompare each parser with its corresponding base-lines.
Both parsers in all lengths perform better thantheir baselines.
For MaltParser, improvements occurfor longer sentences while for MSTParser improve-ments occur at smaller sentences.
These results arein contrast with the results reported by McDonaldand Nivre (2011).Graph Factors Figure 3 shows the accuracy forarcs relative to their distance to the artificial rootnode12.
The area under the curve of final MaltParser11In our analysis, we useMaltEval (Nilsson and Nivre, 2008).12Number of arcs in the reverse path from the modifier of thearc to the root.103Parser Method LAS UAS LAMaltBaseline 87.68 (87.04) 90.41 (89.92) 90.03 (89.49)Final 87.91++ (87.16)+ 90.58+ (90.05)++ 90.22+ (89.60)+Diff.
+0.23 (+0.12) +0.17 (+0.13) +0.19 (+0.11)MSTBaseline 87.98 (86.82) 91.30 (90.27) 90.53 (89.90)Final 88.37++ (86.97) 91.55++ (90.36) 90.86++ (90.05)Diff.
+0.39 (+0.15) +0.25 (+0.09) +0.33 (+0.15)Table 9: Baseline and final results of gold (predicted) test data for MaltParser1?10 11?20 21?30 31?40 41?50 >507580859095Sentence LengthDependencyAccuracyFinalBaseline(a) Accuracy of MaltParser per sentence length1?10 11?20 21?30 31?40 41?50 >507580859095Sentence LengthDependencyAccuracyFinalBaseline(b) Accuracy of MSTParser per sentence lengthFigure 2: Accuracy relative to sentence length.
Bothparsers perform better than their baselines.is less than baseline, but it is over baseline for MST-Parser.
F-score of MSTParser for shorter distance ismuch better than the baseline and by increasing thedistance to root, F-score degrades to be less than thebaseline.Linguistic Factors MaltParser and MSTParsercan find 90.22% and 90.86% of all labels correctly.Figure 4 shows the F-score of some important de-pendency labels in the test data.
MaltParser onlyimproves subject and object categories, while MST-Parser improves object, ROOT, and adverb cate-1 2 3 4 5 6 >68586878889Distance to RootF-Score(a) Baseline ( ) and final ( ) accuracy of MaltParser1 2 3 4 5 6 >686878889Distance to RootF-Score(b) Baseline ( ) and final ( ) accuracy of MSTParserFigure 3: Dependency arc F-score relative to the distanceto rootgories.
If we only consider the final results, Malt-Parser performs better for predicting subject and ob-ject, while MSTParser performs better for predictingROOT and ezafe dependent (MOZ)13, and both havethe same accuracy for adverb.Table 10 gives the accuracy of arcs for each de-pendent part-of-speech.
Final MSTParser performs13Ezafe construction is referred to nouns or pronouns that im-ply a possessed-possessor relation (like first name-last name).The relation between the possessed and possessor is calledmozaf (MOZ) that its sign is a vowel /e/ that pronounced rightafter the head noun (Dadegan Research Group, 2012).104SBJ OBJ ROOT MOZ ADV020406080100Dependency TypeF-ScoreBaselineF inal(a) Accuracy of MaltParser per dependency typeSBJ OBJ ROOT MOZ ADV020406080100Dependency TypeF-ScoreBaselineF inal(b) Accuracy of MSTParser per dependency typeFigure 4: Dependency label F-score relative to some de-pendency types.better than its baseline for all categories, except pro-nouns and better than MaltParser for all categories,except preposition.
Final MaltParser, performs bet-ter than its baseline in all categories, except preposi-tion.6 ConclusionIn this paper, we have investigated a number of is-sues in data-driven dependency parsing of Persian.Because there is no previous study on parsing thePOSMalt MSTBaseline Final Baseline FinalVerb 89.96 90.09 90.96 91.86Noun 89.67 90.13 90.15 90.23Pronoun 92.56 92.94 93.53 93.43Adjective 87.80 88.37 87.77 88.56Adverb 80.80 82.37 82.61 83.94Conjunction 86.03 86.40 86.58 87.36Preposition 70.93 70.32 69.74 70.76Table 10: Accuracy for each dependent part of speechPersian dependency treebank (Rasooli et al 2013),we first have drawn the baseline for each parser, byselecting best performing algorithm and tuning itsparameters.
For MaltParser (Nivre et al 2007b) dif-ferent between best algorithm (non-projective ver-sion of Covington) with default settings and after op-timizing feature template by the third phase of Mal-tOptimizer (Ballesteros and Nivre, 2012) is about1.5 percent.
This shows that the definition of fea-ture template is a crucial aspect of transition-basedparsing.Our first experiment shows the effect of using au-tomatic annotation of POS tags and morphologicalinformation.
Our new configuration improves twoparsers in both gold and predicted setting, but theimprovement for MSTParser is higher than for Malt-Parser.
MSTParser has higher accuracy in the goldsetting, while MaltParser has better performance inpredicted setting.
It might mean that MaltParser ismore robust against noisy information.In the second experiment, we have explored thebest combination of morphological and lexical se-mantic features for dependency parsing of Persian.We find that the combination of one morphologicalfeature and one lexical semantic feature gets the bestcombination for each parser.
Our lexical semanticfeatures can be automatically produced for any wordand thus we need to predict one morphological fea-ture for real-world settings.Finally we have proposed two simple methods forreducing data sparsity of each parser.
After apply-ing our solutions to three types of challenges, wereached 87.91% and 88.37% LAS on the test set(0.23% and 0.39% improvement over our baseline)for MaltParser and MSTParser, respectively.Note that all of the experiments we reported inthis paper use existing parsers as black boxes.
Weonly changed the input data to obtain the best pos-sible performance given our data sets.
We plan toexplore modifications of the underlying parsing al-gorithms to better make use of morphological infor-mation.AcknowledgmentsWe would like to thank Mohammad-Sadegh Rasooliand our anonymous reviewers for helpful feedbackand suggestions.
We would also thank Zahra Sarabi105for providing us the data and information about thePLP toolkit.ReferencesEneko Agirre, Kepa Bengoetxea, Koldo Gojenola, andJoakim Nivre.
2011.
Improving Dependency Pars-ing with Semantic Classes.
In Proceedings of the 49thAnnual Meeting of the Association for ComputationalLinguistics (ACL ?11): shortpapers, pages 699?703.Baharat Ram Ambati, Samar Husain, Sambhav Jain,Dipti Misra Sharma, and Rajeev Sangal.
2010a.
Twomethods to incorporate local morphosyntactic fea-tures in Hindi dependency parsing.
In Proceedingsof NAACL HLT 2010 First workshop on StatisticalParsing of Morphologically-Rich Languages (SPMRL2010), pages 22?30.Baharat Ram Ambati, Samar Husain, Joakim Nivre, andRajeev Sangal.
2010b.
On the Role of Morphosyntac-tic Features in Hindi Dependency Parsing.
In Proceed-ings of the NAACL HLT 2010 First Workshop on Sta-tistical Parsing of Morphologically-Rich Languages,pages 94?102.MaryamAminian, Mohammad Sadegh Rasooli, and Hos-sein Sameti.
2013.
Unsupervised Induction of PersianSemantic Verb Classes Based on Syntactic Informa-tion.
In Language Processing and Intelligent Informa-tion Systems, pages 112?124.Miguel Ballesteros and Joakim Nivre.
2012.
MaltOp-timizer: A System for MaltParser Optimization.
InProceedings of the Eighth International Conferenceon Language Resources and Evaluation (LREC 2012),pages 23?27.Miguel Ballesteros and Joakim Nivre.
2013.
Going tothe Roots of Dependency Parsing.
Computational Lin-guistics, pages 5?13.Kepa Bengoetxea and Koldo Gojenola.
2010.
Applica-tion of Different Techniques to Dependency Parsing ofBasque.
In Proceedings of the NAACL HLT 2010 FirstWorkshop on Statistical Parsing of Morphologically-Rich Languages, pages 31?39.Mahmood Bijankhan.
2004.
The role of the corpus inwriting a grammar: An introduction to a software.
Ira-nian Journal of Linguistics.Bernd Bohnet and Jonas Kuhn.
2012.
The Best ofBoth Worlds A Graph-based Completion Model forTransition-based Parsers.
In Proceedings of the 13thConference of the European Chapter of the Associa-tion for Computational Linguistics, pages 77?87.Bernd Bohnet and Joakim Nivre.
2012.
A Transition-Based System for Joint Part-of-Speech Tagging andLabeled Non-Projective Dependency Parsing.
In Pro-ceedings of the 2012 Joint Conference on EmpiricalMethods in Natural Language Processing and Compu-tational Natural Language Learning (EMNLP-CoNLL2012), pages 1455?1465.Jinho D. Choi and Martha Palmer.
2011a.
Getting theMost out of Transition-based Dependency Parsing.
InProceedings of the 49th Annual Meeting of the Associ-ation for Computational Linguistics (ACL ?11): short-papers, pages 687?692.Jinho D. Choi and Martha Palmer.
2011b.
Statistical De-pendency Parsing in Korean: From Corpus Genera-tion To Automatic Parsing.
In Proceedings of the 2ndWorkshop on Statistical Parsing of Morphologically-Rich Languages (SPMRL 2011), pages 1?11.Dadegan Research Group.
2012.
Persian DependencyTreebank Annotation Manual and User Guide.
Tech-nical report, SCICT.Yoav Goldberg and Michael Elhadad.
2010.
Easy FirstDependency Parsing of Modern Hebrew.
In Proceed-ings of the NAACL HLT 2010 First Workshop on Sta-tistical Parsing of Morphologically-Rich Languages,pages 103?107.Terry Koo, Xavier Carreras, and Michael Collins.
2008.Simple Semi-supervised Dependency Parsing.
In Pro-ceedings of ACL-08: HLT, pages 595?603.Percy Liang.
2005.
Semi-Supervised Learning for Natu-ral Language.
Ph.D. thesis, Massachusetts Institute ofTechnology.Yuval Marton, Nizar Habash, and Owen Rambow.
2011.Improving Arabic Dependency Parsing with Form-based and Functional Morphological Features.
In Pro-ceedings of the 49th Annual Meeting of the Associationfor Computational Linguistics (ACL ?11), pages 1586?1596.Ryan McDonald and Joakim Nivre.
2011.
Analyzingand Integrating Dependency Parsers.
ComputationalLinguistics, pages 197?230.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005.
Non-projective Dependency Parsingusing Spanning Tree Algorithms.
In Proceedings ofthe conference on Human Language Technology andEmpirical Methods in Natural Language Processing,pages 523?530.Jens Nilsson and Joakim Nivre.
2008.
MaltEval: AnEvaluation and Visualization Tool for DependencyParsing.
In Proceedings of the Sixth InternationalLanguage Resources and Evaluation (LREC ?08).Joakim Nivre and Jens Nilsson.
2005.
Pseudo-ProjectiveDependency Parsing.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL ?05), pages 99?106.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan McDon-ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.2007a.
The CoNLL 2007 Shared Task on Dependency106Parsing.
In Proceedings of the CoNLL Shared TaskSession of EMNLP-CoNLL 2007, pages 915?932.Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,Gu?lsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,and Erwin Marsi.
2007b.
MaltParser: A language-independent system for data-driven dependency pars-ing.
Natural Language Engineering, pages 95?135.Joakim Nivre.
2009.
Non-Projective Dependency Pars-ing in Expected Linear Time.
In Proceedings ofthe Joint Conference of the 47th Annual Meeting ofthe ACL and the 4th International Joint Conferenceon Natural Language Processing (IJCNLP) of theAFNLP, pages 351?359.Mohammad Sadegh Rasooli, Omid Kashefi, and BehrouzMinaei-Bidgoli.
2011.
Effect of Adaptive SpellChecking in Persian.
In 7th International Conferenceon Natural Language Processing andKnowledge En-gineering (NLP-KE), pages 161?164.Mohammad Sadegh Rasooli, Manouchehr Kouhestani,and Amirsaeid Moloodi.
2013.
Development of a Per-sian Syntactic Dependency Treebank.
In Proceedingsof the 2013 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies, pages 306?314.Zahra Sarabi, Hooman Mahyar, and Mojgan Farhoodi.2013.
PLP Toolkit: Persian Language ProcessingToolkit.
In 3rd International eConference on Com-puter and Knowledge Engineering (ICCKE 2013).Wolfgang Seeker and Jonas Kuhn.
2013.
Morphologicaland Syntactic Case in Statistical Dependency Parsing.Computational Linguistics, pages 23?55.Mojgan Seraji, Bea?ta Megyesi, and Joakim Nivre.
2012a.Bootstrapping a Persian Dependency Treebank.
Lin-guistic Issues in Language Technology, pages 1?10.Mojgan Seraji, Bea?ta Megyesi, and Joakim Nivre.
2012b.Dependency Parsers for Persian.
In Proceedings of10th Workshop on Asian Language Resources, COL-ING 2012, 24th International Conference on Compu-tational Linguistics.Mehrnoush Shamsfard, Akbar Hesabi, Hakimeh Fadaei,Niloofar Mansoory, Ali Famian, Somayeh Bagher-beigi, Elham Fekri, Maliheh Monshizadeh, andS.
Mostafa Assi.
2010.
Semi Automatic DevelopmentOf FarsNet: The Persian Wordnet.
In Proceedings of5th Global WordNet Conference (GWA2010).Mehrnoush Shamsfard.
2011.
Challenges and OpenProblems in Persian Text processing.
In The 5th Lan-guage and Technology Conference (LTC 2011), pages65?69.Reut Tsarfaty, Djame?
Seddah, Yoav Goldberg, SandraKu?bler, Marie Candito, Jennifer Foster, Yannick Ver-sley, Ines Rehbein, and Lamia Tounsi.
2010.
Sta-tistical Parsing of Morphologically Rich Languages(SPMRL) What, How and Whither.
In Proceedingsof the NAACL HLT 2010 First Workshop on StatisticalParsing of Morphologically-Rich Languages, pages 1?12.107
