Workshop on Computational Linguistics for Literature, pages 18?25,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsTowards a Literary Machine Translation:The Role of Referential CohesionRob Voigt Dan JurafskyCenter for East Asian Studies Department of LinguisticsStanford University Stanford Universityrobvoigt@stanford.edu jurafsky@stanford.eduAbstractWhat is the role of textual features above thesentence  level  in  advancing  the  machinetranslation of literature?
This paper examineshow  referential  cohesion  is  expressed  inliterary  and  non-literary  texts  and  how  thiscohesion affects translation.
We first show in acorpus study on English that literary texts usemore dense reference chains to express greaterreferential  cohesion  than  news.
We  thencompare the referential  cohesion of machineversus  human  translations  of  Chineseliterature and news.
While human translatorscapture  the  greater  referential  cohesion  ofliterature,  Google  translations  perform  lesswell at capturing literary cohesion.
Our resultssuggest  that  incorporating discourse  featuresabove  the  sentence  level  is  an  importantdirection for MT research if it is to be appliedto literature.IntroductionThe concept of literary machine translationmight  seem at  first  to  be a  near-contradiction interms.
The  field  of  machine  translation  hastraditionally aimed its sights at  the translation oftechnical or otherwise informative texts,  with thestrongest focus on newswire and other informativetexts relevant to the goals of government funders.Nevertheless, the prospect of literary MT isappealing.
Human translation of literary texts is anextremely time- and money-intensive task, but onethat  is  a crucial  element of the global  system oftranscultural  literary exchange.
From a  technicalstandpoint, since ?by definition, literature is the artthat  uses  language?
(Chapman  1973),  literarytranslation  represents  perhaps  the  strongestformulation  of  the  machine  translation  problem.Jonathan  Slocum,  writing  in  1985,  essentiallyrejects  the  idea of  literary MT altogether,  notingthat  it  is  serendipitous  for  technical  MT  thatemphasis  is  placed  on  semantic  fidelity  to  thesource text, whereas literary translation must takeinto  account  larger  considerations  such  as  stylewith which ?computers do not  fare well.?
Giventhe explosion of statistical  methodologies in MT,are we now at a point where we can hope to begintackling some of the  questions associated with apotential literary machine translation?This  problem  is  severely  understudied.Regardless of the plausibility (or even desirability)of  eventually  using  MT to  produce  full-fledgedtranslations  of  literary  texts,  a  seriousconsideration  of  the  unique  difficulties  posed  byliterary translation may well serve to push forwardour computational understanding of literature andthe language of translation.In particular,  literary translation seems todemand  that  we  address  larger-scale  textualfeatures  beyond  the  sentence-level  approachcommonly  employed  by  contemporary  MTsystems.
There  is  a  substantial  body of  work byscholars  in  the  field  of  translation  studiesaddressing  greater-than-sentence-level  textualfeatures  from a  linguistic  and  literary-theoreticalperspective,  and  this  existing  work  can  offerconceptual understanding and a parallel vocabularywith  which  to  discuss  progress  in  this  regard  inmachine translation.Eugene Nida (1964), for example, used theterms  ?formal  equivalence?
and  ?dynamicequivalence?
to  differentiate  between translationsaiming to  replicate  the  form of  their  source  andthose aiming to replicate the source text's effectson its  readers.
Hatim and Mason (1995)  broughtthe  ?seven  standards  of  textuality?
set  forth  byBeaugrande  and  Dressler  (1981)  into  thetranslation studies context as metrics for evaluatingthe  ?expectation-fulfilling?
or  ?expectation-defying?
outcome of a translated text.18Cohesion  is  defined  by  Beaugrande  andDressler  as  ?concern[ing]  the  ways  in  which thecomponents  of  the  textual  world,  i.e.,  theconfiguration  of  concepts  and  relations  whichunderlie the surface text,  are mutually accessibleand  relevant."
Cohesion  considers  the  limitedhuman capacity for storing the ?surface materials?of a text long enough to relate them semanticallyduring the act of reading.We therefore  propose to  study referentialcohesion (Halliday and Hasan 1976), the relationbetween co-referring entities in a narrative, as animportant  component  of  cohesion.
Referentialcohesion  has  a  significant  literature  in  naturallanguage processing (Grosz et al 1995, Mani et al1998, Marcu 2000, Karamanis et al 2004, Kibbleand  Power  2004,  Elsner  and  Charniak  2008,Barzilay  and  Lapata  2008,  inter  alia)  as  doesautomatic  coreference  resolution,  which  hassignificantly increased in accuracy in recent years(Bengston  and  Roth  2008,  Haghighi  and  Klein2009, Haghighi and Klein 2010, Rahman and Ng2011, Pradhan et al 2011, Lee et al 2011).We formulate  and test  two hypotheses inthis position paper: First, we anticipate that givenstylistic  considerations  and  their  fundamentalnarrative  function,  prose  literary  texts  areinherently ?more cohesive?
than news.
Second, inlight of the aforementioned necessity for ?dynamicequivalence?
in  the  literary  translation,  weanticipate that current machine translation systems,built  with  newswire  texts  in  mind,  will  be  lesssuccessful at conveying cohesion for literary textsthan for news.2.
Investigating Literary CohesionOur first preliminary experiment examineshow  referential  cohesion  in  literary  texts  differsfrom  news  text  by  examining  coreference  in  amonolingual  English-language  corpus,  withoutconsidering machine-translated texts.We created a small corpus of twelve shortstories  for  comparison  with  twelve  recent  long-form news stories from the New York Times, WallStreet Journal, The Atlantic, and the news blog TheDaily Beast.
The stories chosen were written by avariety  of  authors:  Isaac  Asimov,  J.D.
Salinger,Edgar Allen Poe, Tobias Wolff, Vladimir Nabokov,Sir  Arthur  Conan  Doyle,  Shirley  Jackson,  JackLondon,  Mark  Twain,  Willa  Cather,  AmbroseBierce,  and  Stephen  Crane  ?
in  the  interest  ofavoiding over-specificity to any particular genre orstyle.
The  corpus  thus  included  12  short  storieswith  76,260  words  and  12  news  articles  with23,490  words,  for  a  total  corpus  size  of  24documents and 99,750 words.We used standard publicly-available  NLPtools to process the corpus.
We used the StanfordCoreNLP suite1 to tokenize and sentence-split boththe human and MT versions of each text and thento run the multi-pass sieve coreference resolutionsystem described in Lee et al (2011).This  system  works  by  making  multiplepasses  over  the  text,  first  doing  recall-orientedmention  extraction,  then  resolving  coreferencethrough a series of sieves moving from highest tolowest  precision.
This  system  is  state-of-the-art,with a B3 F1 score of 68.9 with no gold mentionboundaries  on  the  CoNLL 2011  shared  task  testset.
Nevertheless,  it  is  likely  to  introduce  somemeasure of noise into our results.For the rest of the paper we use the term?cluster?
to refer to clusters agglomerated by thesystem  that  co-refer  to  the  same  entity,  and?mention?
to refer to individual instances of eachentity in the text.Clusters per100 TokensMentions per100 TokensDensity:Mentionsper ClusterShortStories3.6 19.3 5.4NewsText3.9 15.0 3.9Table  1.
Cohesion  as  measured  by  coreference  inliterary  vs.  non-literary  texts.
Figures  given  are  theoverall average across all documents.Table 1 reports the numbers of clusters andmentions (normalized per 100 tokens).
The literarytexts had the same number of clusters (entities) asthe news texts (one-tailed t-test,  p = 0.080), albeitwith a  trend towards fewer  clusters  in  literature.But  literary text had more mentions (p < 0.001),and a higher number of mentions per cluster (p <0.001) than the news texts.The  results  of  this  preliminary  studysuggest that the literary text tended to discuss thesame number of entities as the non-fiction, but to1 Available online atnlp.stanford.edu/software/corenlp.shtml19Suddenly,  the nurse resorted to direct measures.
Sheseized  the boy?s upper arm in one  hand and dippedthe other in the milk.
She dashed the milk across hislips,  so  that  it dripped  down  cheeks  and  recedingchin....Always,  his frightened eyes were on  her, watching,watching for the one false move.
She found herselfsoothing  him, trying to move  her hand very slowlytoward  his hair, letting  him see  it every inch of theway, see there was no harm in it.
And she succeededin stroking his hair for an instant.
?Instead, she turned on the night light and moved thebed.
The poor thing was huddled in the corner, kneesup against  his chin,  looking up at  her with  blurredand apprehensive eyes.
?She looked down at those eager brown eyes turned upto hers and passed her hands softly through his thick,curly hair.Figure  1.
Human  markup  of  cohesion  throughoutAsimov's ?The Ugly Little Boy.?
Recurring entities arecolor-coded: red is the character Edith Fellowes, grey isher hands, blue is the character Timmie, light green ishis eyes, dark green is his chin, yellow is his hair, andmagenta is  the milk.
This sample contains  149 wordsand 7 recurring entities with a total of 29 mentions.mention each entity more often.
In other words,literary text uses more dense reference chains as away of creating a higher level of cohesion.Figures  1  and  2  provide  representativeexamples, hand-labeled for coreference, to offer aqualitative intuition for this difference in cohesion.In the literary example in Figure 1 we find sevenrecurring entities with an average of 4.1 mentionseach.
In  the  news  example  in  Figure  2  we  findseven  recurring  entities  but  only  3.0  averagementions,  resulting  in  qualitatively  less  densereference chains in the news sample.Our  results  are  consistent  with  Biber(1988),  whose  factor  analysis  study  found  thatfiction tended to have a high frequency of third-person  personal  pronouns.
This  is  true  in  ourcorpus;  third-person pronouns occur  57.7% morein the fiction as opposed to the non-fiction texts(16.9  vs  10.7  occurrences  per  100  words).
Buteven  when  we  count  ignoring  third-personpronouns, we found a greater density of mentionsper cluster for literature than for news (4.0 vs 3.3,p = 0.015).
The result that literature seems to havemore to say about each entity thus extends andTwo studies have found that  weight-loss  operationsworked much better than  the standard therapies forType  2  diabetes in  obese  and  overweight  peoplewhose blood sugar was out of control.
Those who hadsurgery, which stapled the  stomach and rerouted thesmall  intestine,  were  much  more  likely  to  have  acomplete  remission  of  diabetes,  or  to  need  lessmedicine,  than  people who  were  given  the  typicalregimen of drugs, diet and exercise....The new studies, published on Monday by The NewEngland  Journal  of  Medicine,  are  the  first  torigorously  compare  medical  treatment with  theseparticular  stomach and intestinal  operations as waysto  control  diabetes.
Doctors had  been  noticing  foryears that weight-loss operations, also called bariatricsurgery, could sometimes get rid of Type 2  diabetes.But they had no hard data....One  of  the  studies,  conducted  at  the  CatholicUniversity in Rome, compared two types of  surgerywith usual medical treatment.Figure 2.
Human markup of cohesion throughout a NYTnews article.
Recurring entities are color-coded, similarto  the  above.
This  sample  contains  152 words  and  7recurring entities with a total of 21 mentions.explains  Biber's  finding  that  literature  has  morethird-person pronouns.While  our  results  are  suggestive,  theyremain  preliminary.
A more  detailed  follow-upwill need to look at the specific realization of thementions and the kind of local coherence relationsthat  link them (Althaus et al  2004,  Poesio et  al.2004,  Barzilay  and  Lapata  2008,  Elsner  andCharniak  2008),  and  to  investigate  the  differentaspects  of  referential  chains  with  larger  corporaand more varying genres.3.
MT Success at Conveying CohesionTo evaluate the impact of this difference inexpressed  cohesion  on  machine  translationsystems, we compared coreference output betweenhuman  and  machine  translations  of  literary  andinformative texts from Chinese.
For this task wechose  a  small  dataset  of  sixteen  short  stories  inChinese by the early 20th-century author Lu Xun(??)
and their corresponding English translationsby  Gladys  Yang.
We  chose  Lu  Xun  for  hisprominence  as  the  ?father  of  modern  Chineseliterature?
and vernacular style, and because Yang'sEnglish translations are widely accepted as being20of  high  quality  by  the  literary  community.
Forcomparison to news text, we chose a series of sixlong-form  articles  from  the  magazine  Sinoramaand  their  corresponding  English  referencetranslations in the  LDC's ?Chinese English NewsMagazine  Parallel  Text?
corpus  (LDC2005T10).These  magazine  texts  were  chosen  because  thebrief newswire texts often used in MT evaluationare too short to allow for meaningful textual-levelcomparisons  of  this  sort.
Thus  our  corpuscontained  16  human-translated  short  stories  with90,712 words, 16 machine-translated short storieswith 82,475 words, 6 human-translated magazinearticles  with  45,310  words,  and  6  machine-translated magazine articles with 39,743 words, fora total size of 44 documents and 258,240 words.We  used  Google  Translate  as  our  MTtranslation  engine,  first  because  the  large  web-based resources behind that system might help tomitigate  the  inevitable  complication  of  domainspecificity in the training data, and second becauseof  its  social  position  internationally  as  the  mostlikely  way  average  readers  might  encountermachine translation.We first used Google Translate to producemachine  translations  of  both  the  literary  andmagazine texts, and then used the Lee et al (2011)coreference  system  in  Stanford  CoreNLP  asdescribed above to evaluate cohesion on both thehuman  and  machine  English  translations.
Asacknowledged  in  the  prior  section,  automaticcoreference is likely to introduce some amount ofnoise, but there is no reason to think that this noisewould be biased in any particular direction for MT.Results  from the  coreference  analysis  ofthe literary and magazine texts are shown in Table2.
The results  in  the  two rows labeled ?Human?substantiate our findings from the previous section.The human translations of the short stories have asignificantly (p  =  0.003)  higher  referential  chaindensity  (5.2)  than  the  human  translations  of  themagazine  pieces  (4.2).
Translators,  or  at  leastGladys  Yang  in  these  translations,  seem  to  actsimilarly to  source-text  writers  in  creating  moredense referential  chains in literature than in non-fiction genres.In order to study the success of machinetranslation in dealing with cohesion, we took thehuman translations as a gold standard in each case,using this translation to normalize the number ofclusters and mentions to the length of the referenceClusters per100 TokensMentions per100 TokensDensity:Mentionsper ClusterShort StoryHuman 3.7 19.0 5.2Machine 4.1 16.4 3.8MagazineHuman 3.9 16.0 4.2Machine 3.9 14.0 3.7Table 2.
Cohesion as measured by coreference in humanand machine translations of  Lu Xun short  stories  andSinorama magazine articles.
The first two columns arenormalized  to  the  length  of  the  human  ?gold?translations,  and figures given are the overall  averageacross all documents.documents to address the length variance causedby the MT system.The  results  in  Table  2  show  littleunderclustering for the MT output.
The number ofclusters (entities) in the machine translations (4.1and 3.9) do not differ from the human translations(3.7 and 3.9), (p = 0.074), although there is a trendtoward underclustering for literature.The main difference we see is in referentialchain  density  (mentions  per  cluster).
Whereasthese  experiments  reconfirm  the  trend  towardsmore  mentions  per  cluster  in  literature  thaninformative  text,  referential  chains  in  the  MToutput do not differ between the two genres.
Themachine translation only captures 79.4% (13,846vs.
17,438)  of  the  human-translated  mentions  inthe literary texts.In  the  literary  genre  the  automaticcoreference system finds more than one additionalmention per  cluster  in  the  human translations  ascompared  to  MT  (p  <  0.001),  while  in  themagazine case the human and MT translations arethe same, though there is a similar trend towardsless  dense  referential  chains  in  MT output  (p  =0.055).4.
Examples and DiscussionIt  is  worth  first  acknowledging  thesomewhat  surprising  ability  of  MT  to  maintaincohesion in both domains.
The fact that a systemoperating  almost  exclusively  on  a  sentence-by-sentence basis is able to maintain upwards of three-quarters  of  the  mentions  in  the  difficult  andlinguistically distant context of Chinese-to-English21MT is remarkable in and of itself, and speaks to therelative success of modern MT.
There is, of course,no  guarantee  that  these  mentions  found  by  thecoreference system are in fact all the correct ones,so the true figure is likely somewhat lower, but aqualitative  examination  of  the  system's  outputshows that they are largely accurate.What is actually causing the discrepanciesin  cohesion  noted  above  as  regards  our  twodomains?
Below we look at some specific cases ofreduced cohesion in our results from the Lu Xunstory ?Flight to the Moon.?
In these examples thehuman  translator  was  forced  to  rely  on  greater-than-sentence-level features of the text to effect anappropriately  cohesive  translation  that  the  MTsystem was unable to convey.Zero AnaphoraZero  anaphora  is  a  well-documented  andcommon linguistic phenomena in Chinese (Li andThompson  1979,  Huang  1989).
Kim  (2000)investigated subject drop in Chinese and English,finding  that  English  overtly specifies  subjects  in96% of cases, while the figure for Chinese is only64%, and a significant amount of prior work hasfocused  on  the  computational  identification  andresolution  of  zero  anaphora in  Chinese (see  Yehand  Chen  2001,  Converse  2006,  Zhao  and  Ng2007,  Kong  and  Zhou  2010).
The  followingexample sentences demonstrate this difficulty.Human TranslationWhen the big game was finished  they atewild boars, rabbits and pheasants.
He was such a finearcher, he could shoot as much as he pleased.Machine TranslationLater large animal shot down, ate wild boar,rabbit pheasant; shooting method and high strength,many as you want.Original Chinese????????????????????????????
?Figure 3.
Reduced cohesion via zero anaphora in MToutput.
Relevant mentions are hand-annotated in bold.In  a  qualitative  analysis  of  our  results,problems  such  as  these  were  by  far  the  mostcommon  cause  of  cohesion  errors,  and  as  thereader will notice, they often lead to an output thatloses crucial elements for maintaining the cohesionof the narrative, such as in this case the distinctionbetween the husband/wife couple, ?they,?
and thehusband individually, ?he.
?Inconsistent ReferenceHaving  no  process  for  maintainingconsistency of reference to entities in the narrative,the  following  non-consecutive  coreferencingsentences illustrate how in the MT version of thetext  the  cohesiveness  of  the  ?hen?
cluster  in  theoriginal is lost.Human Translation-"Who are you?
Why have you shot my best blacklaying hen?"-"What!
A hen?"
he echoed nervously.
"I thought  itwas a wood pigeon.
"-"Imagine mistaking a hen for a wood pigeon!
"-"I am Yi."
While saying this he saw that his arrowhad pierced the hen's heart, killing it outright.-"What about this hen?
"-"She was my best: she laid me an egg every day.
"-"I'll give you these for your hen"Machine Translation-"Who are you what?
How good black  hen shot tothe top of my house?"-"Ah!
Chicken?
I  only  said  a  wood  pigeonpartridge," he said in dismay.-"hens do  not  know,  will  be  treated  as  the  woodpigeon partridge"-"I Yi Yi."
He said, to see his shot arrows, is beingconsistently the heart of the hen, of course, died-"Chicken how to do it?
"-"Lost my best hen every day to lay eggs.
"-"they brought lost your chicken.
"Original Chinese-??????????????????????"-???????????????
??
??????-"??????????????"-?
???????
??????????????????????????-???
?
?????-????????????????"-"????????
"Figure 4.
Reduced cohesion via inconsistent reference inMT output.
Relevant  mentions  are  hand-annotated  inbold.The reader will notice that in the originalChinese,  ji (?
,  lit.
?chicken?)
is used here as a22shortened  version  of  muji (??
,  lit.
?hen?)
incolloquial  speech,  which  the  human  translatorclearly  notes  and  translates  each  mentionconsistently to maintain cohesion.
Similarly, beingthat  number is  not  explicitly marked in  Chinese,the MT system translates  lian muji (???
,  lit.
?even hen?)
as ?hens?
instead of catching that here??
refers back to the entity being discussed.De (?)
DropsIt is common in Chinese for the noun headof a nominalization formed by the particle de (?
)to  be  implicit,  yet  in  many  cases  the  humantranslator will add it for clarity and, presumably, tomaintain cohesion.Human Translation"There are those who know my name.
"Machine Translation?Some people is one to know.
"Original Chinese?
?
?
?
?
?
?
?
??
??
"Exist  some  people be  one  hear  then    know  NOMFigure  5.
Reduced  cohesion  via  de dropping  in  MToutput.
Relevant mentions are hand-annotated in bold.This  phenomenon  reminds  of  translationtheorist  Mona  Baker's  (1996)  concept  of?explicitation?
: ?an overall tendency to spell thingsout rather than leave them implicit in translation.
?Indeed, Olohan and Baker (2000) demonstrate thisempirically using the Translational English Corpus,finding  a  strong  tendency  in  translated  texts  toexplicitly  mark  the  ?that?-connective  followingwords such as ?say,?
?tell,?
?promise,?
and so onwhere it could have been omitted.5.
Implications and Future ResearchWe  found  in  two  separate  analyses thatliterary texts had more dense reference chains thaninformative  texts.
This  result  supports  ourhypothesis  that  literary  texts  are  indeed  morecohesive in general than informative texts; that isto  say,  the  stylistic  and  narrative  demands  ofliterature  lead  to  prose  being  more  cohesively?about?
its  subjects  than  news.
It  remains  toreplicate  this  experiment  on  a  large,  carefullysampled  cross-genre  corpus  to  confirm  thesepreliminary findings,  perhaps  integrating  a  morecomplex measure of cohesion as in Barzilay andLapata (2008).We  also  found  that  MT  systems  haddifficulty  in  conveying  the  cohesion  in  literarytexts.
Of course these results are preliminary andmay be confounded by the nature of the trainingdata  used  by  modern  MT systems.
The  uses  ofGoogle  Translate  as  an  MT system and  longer-form  magazine  articles  as  our  informative  textswere aimed at mitigating these concerns to someextent, but for now these results primarily serve asindicative of the need for further research in thisarea.Cohesion, as well, is only one of the seven?standards of textuality?
put forth by Beaugrandeand Dressler  (1981)  and taken up by Hatim andMason (1997) in the translation context.
Some ofthese  have  an  existing  literature  addressing  theircomputational  identification  and  analysis  (eg.Morris and Hirst 1991), in which cases we mightapply existing methods to identify genre effects inliterary text.
For  others,  such  as  situationality,  itremains  to  investigate  appropriate  computationalanalogues  for  large-scale  automatic  analysis  andapplication  to  literary  text.
Studies  addressingrelevant  textual-level  concerns  in  literature  showincreasing promise,  such as  Elson et  al.
(2010)'swork  in  automatically extracting  social  networksfrom fiction.Once  these  sorts  of  genre  effects  inliterature are more clearly understood, they can beaddressed  on  a  large  scale  for  comparisonsbetween  machine-  and  human-translated  literarytexts  in  the  manner  carried  out  in  this  paper,  inorder to identify further potential stumbling blocksfor  machine  translation  on  the  textual  level  asregards  literary  texts.
Our  preliminary  work  aspresented  here  suggests,  at  the  very  least,  thepotential value and necessity of such analyses if weare  to  make  progress  towards  a  true  literarymachine translation.AcknowledgementsThanks  to  Heeyoung  Lee  for  help  with  thecoreference  system,  three  anonymous  reviewers  for  theircareful  reading  and  helpful  comments,  and  the  U.S.Department of Education for the Foreign Language and AreaStudies grant that helped fund this research.23ReferencesAlthaus,  Ernst,  Nikiforos  Karamanis,  andAlexander  Koller.
2004.
Computinglocallycoherent discourses.
In ACL.Baker,  Mona.
1996.
Corpus-based  translationstudies:  The  challenges  that  lie  ahead.
InTerminology, LSP and Translation: Studies inlanguage  engineering.
John  Benjamins,Amsterdam.Barzilay,  Regina  and  Mirella  Lapata.
2008.Modeling  Local  Coherence:  An  Entity-basedApproach.
Computational Linguistics, 34(1).Beaugrande, Robert and Wolfgang Dressler.
1981.Introduction  to  Text  Linguistics.
Longman,London.Bengston, E. and Dan Roth.
2008.
Understandingthe value of features for coreference resolution.In EMNLP.Biber, Douglas.
1988.
Variation across speech andwriting.
Cambridge  University  Press,Cambridge.Chapman,  Raymond.
1973.
Linguistics  andLiterature.
Edward Arnold, London.Converse,  Susan.
2006.
Pronominal  anaphoraresolution for Chinese.
Ph.D. thesis.Elsner,  Micha  and  Eugene  Charniak.
2008.Coreference-inspired  Coherence  Modeling.
InProceedings of ACL 2008.Elson,  David,  Nicholas  Dames,  and  KathleenMcKeown.
2010.
Extracting  social  networksfrom literary fiction.
In ACL.Grosz,  Barbara,  Aravind  K.  Joshi,  and  ScottWeinstein.
1995.
Centering:  A framework  formodeling  the  local  coherence  of  discourse.Computational Linguistics, 21(2).Haghighi,  Aria  and  Dan  Klein.
2009.
Simplecoreference  resolution  with  rich  syntactic  andsemantic features.
In EMNLP.Haghighi, Aria and Dan Klein.
2010.
Coreferenceresolution in a modular, entity-centered model.In HLT-NAACL.Halliday,  M.  A.  K.  and  Ruqaiya  Hasan.
1976.Cohesion in English.
Longman, London.Hatim, Basil and Ian Mason.
1997.
The Translatoras Communicator.
Routledge, London.Huang, James C.-T. 1989.
Pro drop in Chinese, ageneralized control approach.
In O, Jaeggli andK.
Safir,  editors,  The Null  Subject  Parameter.D.
Reidel Dordrecht.Karamanis,  Nikiforos,  Massimo  Poesio,  ChrisMellish, and Jon Oberlander.
2004.
Evaluatingcentering-based  metrics  of  coherence  for  textstructuring using a reliably annotated corpus.
InACL.Kibble,  Rodger  and  Richard  Power.
2004.Optimizing  Referential  Coherence  in  TextGeneration.
Computational Linguistics 30(4).Kim, Young-Joo.
2000.
Subject/object drop in theacquisition  of  Korean:  A  cross-linguisticcomparison.
Journal of East Asian Linguistics,9(4).Kong,  Fang  and  Guodong  Zhou,  2010.
A TreeKernel-based  Unified  Framework  for  ChineseZero Anaphora Resolution.
In EMNLP.Lee,  Heeyoung,  Yves  Peirsman,  Angel  Chang,Nathanael  Chambers,  Mihai  Surdeanu,  DanJurafsky.
Stanford's  Multi-Pass  SieveCoreference Resolution System at the CoNLL-2011 Shared Task.
2011.
In Proceedings of theCoNLL-2011 Shared Task.Li,  Charles  and Sandra Thompson.
1979.
Third-person pronouns and zero-anaphora in Chinesediscourse.
Syntax and Semantics, 12:311-335.Ma,  Xiaoyi.
2005.
Chinese  English  NewsMagazine Parallel Text.
LDC2005T10.Mani, Inderjeet, Barbara Gates, and Eric Bloedorn.1998.
Using Cohesion and Coherence Modelsfor Text Summarization.
In AAAI.Marcu, Daniel.
2000.
The Theory and Practice ofDiscourse  Parsing  and  Summarization.
MITPress, Cambridge, MA.Morris,  Jane  and  Graeme  Hirst.
1991.
LexicalCohesion Computed by Thesaural Relations asan  Indicator  of  the  Structure  of  Text.Computational Linguistics, 17(1).Nida,  Eugene.
1964.
Towards  a  Science  ofTranslating.
Brill, Leiden.Olohan, Maeve and Mona Baker.
2000.
Reportingthat in  translated  English:  Evidence  forsubconscious processes of explicitation?
AcrossLanguages and Cultures 1.Poesio, Massimo, Rosemary Stevenson, Barbara diEugenio, and Janet Hitzeman, 2004.
Centering:A  Parametric  theory  and  its  instantiations.Computational Linguistics, 30(3).Pradhan,  Sameer,  Lance  Ramshaw,  MitchellMarcus, Martha Palmer, Ralph Weischedel, andNianwen Xue.
2011.
CoNLL-2011 Shared Task:Modeling  Unrestricted  Coreference  inOntoNotes.
In CoNLL.24Rahman, Altaf and Vincent Ng.
2011.
Coreferenceresolution with world knowledge.
In ACL.Slocum,  Jonathan.
1985.
A Survey  of  MachineTranslation:  its  History,  Current  Status,  andFuture  Prospects.
Computational  Linguistics,11(1).Zhao,  Shanheng  and  Hwee  Tou  Ng.
2007.Identification and Resolution of Chinese ZeroPronouns:  A Machine  Learning  Approach.
InProceedings  of  EMNLP  CoNLL  JointConference.25
