Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 154?157,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsFactored Machine Translation Systems for Russian-EnglishSte?phane Huet, Elena Manishina and Fabrice Lefe`vreUniversite?
d?Avignon, LIA/CERI, FranceFirstName.LastName@univ-avignon.frAbstractWe describe the LIA machine transla-tion systems for the Russian-English andEnglish-Russian translation tasks.
Variousfactored translation systems were built us-ing MOSES to take into account the mor-phological complexity of Russian and weexperimented with the romanization of un-translated Russian words.1 IntroductionThis paper presents the factored phrase-basedMachine Translation (MT) systems (Koehn andHoang, 2007) developed at LIA, for the Russian-English and English-Russian translation tasks atWMT?13.
These systems use only data providedfor the evaluation campaign along with the LDCEnglish Gigaword corpus.We summarize in Section 2 the resources usedand the main characteristics of the systems basedon the MOSES toolkit (Koehn et al 2007).
Sec-tion 3 reports experiments on the use of fac-tored translation models.
Section 4 describes thetransliteration process used to improve the Russianto English task.
Finally, we conclude in Section 5.2 System Architecture2.1 Pre-processingThe corpora available for the workshop were pre-processed using an in-house script that normal-izes quotes, dashes, spaces and ligatures.
Longsentences or sentences with many numeric ornon-alphanumeric characters were also discarded.Since the Yandex corpus is provided as lower-cased, we decided to lowercase all the other cor-pora.
The same pipeline was applied to the LDCGigaword; also only the documents classified as?story?
were retained.
Table 1 summarizes theused data and introduces designations that we fol-low in the remainder of this paper to refer to thesecorpora.Russian is a morphologically rich language withnouns, adjectives and verbs inflected for case,number and gender.
This property requires in-troducing morphological information inside theMT system to handle the lack of many inflec-tional forms inside training corpora.
For thispurpose, each corpus was previously tagged withPart-of-Speech (PoS) tags.
The tagger TREE-TAGGER (Schmid, 1995) was selected for itsgood performance on several comparable tasks.The Russian tagger associates each word (e.g.?????
(boxes)) with a complex PoS includingmorphological information (e.g.
?Ncmpnn?
for?Noun Type=common Gender=masculine Num-ber=plural Case=nominative Animate=no?)
andits lemma (e.g.
????
(box)).
A description ofthe Russian tagset can be found in (Sharoff et al2008).
The English tagger provides also a lemma-tization and outputs PoS from the Penn Treebanktagset (Marcus et al 1993) (e.g.
?NNS?
for?Noun plural?
).In order to simplify the comparison of differ-ent setups, we used the tokenizer included in theTREETAGGER tool to process all the corpora.2.2 Language ModelsKneser-Ney discounted LMs were builtfrom monolingual corpora using the SRILMtoolkit (Stolcke, 2002).
5-gram LMs were trainedfor words, 7-gram LMs for lemmas and PoS.
ALM was built separately on each monolingual cor-pus: mono-news-c and news-s.
Since ldc was toolarge to be processed as one file, it was split intothree parts according to the original publicationyear of the document.
These LMs were combinedthrough linear interpolation.
Weights were fixedby optimizing the perplexity on a corpus made ofthe WMT test sets from 2008 to 2011 for Englishand on the WMT 2012 test set for Russian (the154CORPORA DESIGNATION SIZE (SENTENCES)English-Russian Bilingual trainingNews Commentary v8 news-c 146 kCommon Crawl crawl 755 kYandex yandex 978 kEnglish Monolingual trainingNews Commentary v8 mono-news-c 247 kShuffled News Crawl corpus (from 2007 to 2012) news-s 68 MLDC Gigaword ldc 190 MRussian Monolingual trainingNews Commentary v8 mono-news-c 182 kShuffled News Crawl corpus (from 2008 to 2012) news-s 20 MDevelopmentnewstest2012 test12 3,003Table 1: Used bilingual and monolingual corporaonly available at that time).2.3 Alignment and Translation ModelsAll parallel corpora were aligned usingMGIZA++ (Gao and Vogel, 2008).
Our transla-tion models are phrase-based models (PBMs) builtwith MOSES using default settings.
Weights ofLM, phrase table and lexicalized reordering modelscores were optimized on test12, thanks to theMERT algorithm (Gao and Vogel, 2008).
Sinceonly one development corpus was made availablefor Russian, we used a 3-fold cross-validationso that MERT is repeated three times for eachtranslation model on a 2,000-sentence subsampleof test12.To recase the corpora, translation models weretrained using a word-to-word translation modeltrained on the parallel corpora aligning lowercasedand cased sentences of the monolingual corporamono-news-c and news-s.3 Experiments with FactoredTranslation ModelsThe evaluation was performed using case-insensitive BLEU and was computed with themteval-v13a.pl script provided by NIST.The BLEU scores shown in the tables below areall averaged on the test parts obtained from the 3-fold cross validation process.In the remainder of the paper, we employ thenotation proposed by Bojar et al(2012) to referto factored translation models.
For example, tW-W:tL-L+tP-P+gLaP-W, where ?t?
and ?g?
standfor ?translation?
and ?generation?, denotes a trans-lation system with two decoding paths:?
a first one directly translates words to words(tW-W),?
a second one is divided into three steps:1. translation from lemmas to lemmas (tL-L),2. translation from PoS to PoS (tP-P) and3.
generation of target words from targetlemmas and PoS (gLaP-W).3.1 Baseline Phrase-Based SystemsTable 2 is populated with the results of PBMswhich use words as their sole factor.
When LMsare built on mono-news-c and news-s, an improve-ment of BLEU is observed each time a trainingparallel corpus is used, both for both translation di-rections (columns 1 and 3).
We can also notice anabsolute increase of 0.4 BLEU score when the En-glish LM is additionally trained on ldc (column 2).3.2 Decomposition of factorsKoehn and Hoang (2007) suggested from their ex-periments for English-Czech systems that ?it isbeneficial to carefully consider which morpholog-ical information to be used.?
We therefore testedvarious decompositions of the complex RussianPoS tagset (P) output by TREETAGGER.
We con-sidered the grammatical category alone (C), mor-phological information restrained to case, number155EN?
RU RU?
EN+LDCnews-c 26.52 26.82 19.89+crawl 29.49 29.82 21.06+yandex 31.08 31.49 22.16Table 2: BLEU scores measured with standardPBMs.Tagset #tags ExamplesC 17 Af, Vm, P, CM1 95 fsg, -s-, fsa, ?M2 380 fsg, -s-, fsa, ???
(that)M3 580 fsg, -s-1ife, fsa3, ???
(that)P 604 Afpfsg, Vmif1s-a-e, P-3fsa, CTable 3: Statistics on Russian tagsets.and gender (M1), the fields included in M1 alongwith additional information (lemmas) for conjunc-tions, particles and adpositions (M2), and finallythe information included in M2 enriched with per-son for pronouns and person, tense and aspect forverbs (M3).
Table 3 provides the number of tagsand shows examples for each used tagset.To speed up the training of translation models,we experimented with various setups for factor de-composition from news-c.
The results displayedon Table 4 show that factors with morphologi-cal information lead to better results than a PBMtrained on word forms (line 1) but that finally thebest system is achieved when the complex PoS tagoutput by TREETAGGER is used without any de-composition (last line).tW-W 19.89tW-WaC 19.81tW-WaM1 20.04tW-WaCaM1 19.95tW-WaM2 19.92tW-WaCaM2 19.91tW-WaM3 19.98tW-WaCaM3 19.89tW-WaP 20.30Table 4: BLEU scores for EN?RU using news-cas training parallel corpus.tL-W 29.23tW-W 31.49tWaP-WaP 31.62tW-W:tL-W 31.69tW-WaP 31.80tW-WaP:tL-WaP 31.89Table 5: BLEU scores for RU?EN using the threeavailable parallel corpora.3.3 Experimental Results for FactoredModelsThe many inflections for Russian induce a hightout-of-vocabulary rate for the PBMs, which gener-ates many untranslated Russian words for Russianto English.
We experimented with the training ofa PMB on lemmatized Russian corpora (Table 5,line 1) but observed a decrease in BLEU scorew.r.t.
a PBM trained on words (line 2).
With twodecoding paths ?
one from words, one from lem-mas (line 4) ?
using the MOSES ability to managemultiple decoding paths for factored translationmodels, an absolute improvement of 0.2 BLEUscore was observed.Another interest of factored models is disam-biguating translated words according to their PoS.Translating a (word, PoS) pair results in an ab-solute increase of 0.3 BLEU (line 5), and of 0.4BLEU when considering two decoding paths (lastline).
Disambiguating source words with PoS didnot seem to help the translation process (line 3).The Russian inflections are far more problem-atic in the other translation direction since mor-phological information, including case, genderand number, has to be induced from the Englishwords and PoS, which are restrained for that lan-guage to the grammatical category and knowledgeabout number (singular/plural for nouns, 3rd per-son singular or not for verbs).
Disambiguatingtranslated Russian words with their PoS resultedin a dramatic increase of BLEU by 1.6 points (Ta-ble 6, last line vs line 3).
The model that trans-lates independently PoS and lemmas, before gen-erating words, albeit appealing for its potential todeal with data sparsity, turned out to be very dis-appointing (first line).
We additionally led ex-periments training generation models gLaP-W onmonolingual corpora instead of the less volumi-nous parallel corpora, but we did not observed again in terms of BLEU.156tL-L+tP-P+gLaP-W 17.06tW-W 22.16tWaP-WaP 23.34tWaP-LaP+gLaP-W 23.48tW-LaP+gLaP-W 23.58tW-WaP 23.72Table 6: BLEU scores for EN?RU using the threeavailable parallel corpora.BEFORE AFTERtW-WaP 31.80 32.15tW-WaP:tL-WaP 31.89 32.21Table 7: BLEU scores for RU ?
EN before andafter transliteration.4 TransliterationWords written in Cyrillic inside the English trans-lation output were transliterated into Latin letters.We decided to restrain the use of transliteration forthe English to Russian direction since we foundthat many words, especially proper names, are in-tentionally used in Latin letters in the Russian ref-erence.Transliteration was performed in two steps.Firstly, untranslated words in Cyrillic are lookedup in the guessed-names.ru-en file provided for theworkshop and built from Wikipedia.
Secondly, theremaining words are romanized with rules of theBGN/PCGN romanization method for Russian (onGeographic Names, 1994).
Transliterating wordsin Cyrillic resulted in an absolute improvement of0.3 BLEU for our two best factor-based system(Table 7, last column).The factored model with the tW-WaP:tL-WaP translation path and a transliteration post-processing step is the final submission for theRussian-English workshop translation task, whilethe tW-WaP is the final submission for the othertranslation direction.5 ConclusionThis paper presented experiments carried out withfactored phrase-based translation models for thetwo-way Russian-English translation tasks.
A mi-nor gain was observed after romanizing Russianwords (+0.3 BLEU points for RU ?
EN) andhigher improvements using word forms, PoS inte-grating morphological information and lemma asfactors (+0.4 BLEU points for RU?
EN and +1.6for EN ?
RU w.r.t.
to a phrase-based restrainedto word forms).
However, these improvementswere observed with setups which disambiguatewords according to their grammatical category ormorphology, while results integrating a generationstep and dealing with data sparsity were disap-pointing.
It seems that further work should bedone to fully exploit the potential of this optioninside MOSES.ReferencesOndr?ej Bojar, Bushra Jawaid, and Amir Kamran.
2012.Probes in a taxonomy of factored phrase-based mod-els.
In 7th NAACL Workshop on Statistical MachineTranslation (WMT), pages 253?260.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Proceedings ofthe ACL Workshop: Software Engineering, Testing,and Quality Assurance for Natural Language Pro-cessing, pages 49?57.Philipp Koehn and Hieu Hoang.
2007.
Factored trans-lation models.
In Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 868?-876.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-dra Constantin, and Evan Herbst.
2007.
Moses:Open source toolkit for statistical machine transla-tion.
In 45th Annual Meeting of the Association forComputational Linguistics (ACL), Companion Vol-ume, pages 177?180.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
Computa-tional Linguistics, 2:313?330.U.S.
Board on Geographic Names.
1994.
Romaniza-tion systems and roman-script spelling conventions.Technical report, Defense Mapping Agency.Helmut Schmid.
1995.
Improvements in part-of-speech tagging with an application to german.
InACL SIGDAT Workshop, pages 47?50.Serge Sharoff, Mikhail Kopotev, Tomaz?
Erjavec, AnnaFeldman, and Dagmar Divjak.
2008.
Designingand evaluating a russian tagset.
In 6th InternationalConference on Language Resources and Evaluation(LREC), pages 279?285.Andreas Stolcke.
2002.
SRILM ?
an extensible lan-guage modeling toolkit.
In 7th International Con-ference on Spoken Language Processing (ICSLP).157
