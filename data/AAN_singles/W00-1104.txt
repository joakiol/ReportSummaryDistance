Semantic Indexing using WordNet SensesRada Mihalcea and Dan MoldovanDepartment  of Computer  Science and EngineeringSouthern Methodist  UniversityDallas, Texas, 75275-0122{rada, moldovan}@seas.smu.eduAbst rac tWe describe in this paper a booleanInformation l~.etrieval system thatadds word semantics to the classicword based indexing.
Two of themain tasks of our system, namelythe indexing and retrieval compo-nents, are using a combined word-based and sense-based approach.The key to our system is a methodol-ogy for building semantic represen-tations of open text, at word and col-location level.
This new technique,called semantic indexing, shows im-proved effectiveness over the classicword based indexing techniques.1 In t roduct ionThe main problem with the traditionalboolean word-based approach to InformationRetrieval (IR) is that it usually returns toomany results or wrong results to be useful.Keywords have often multiple lexical func-tionalities (i.e.
can have various parts ofspeech) or have several semantic senses.
Also,relevant information can be missed by notspecifying the exact keywords.The solution is to include more informationin the documents to be indexed, such as toenable a system to retrieve documents basedon the words, regarded as lexical strings, orbased on the semantic meaning of the words.With this idea in mind, we designed anIR system which performs a combined word-based and sense-based indexing and retrieval.The inputs to ~ systems consist of a ques-tion/query and a set of documents from whichthe information has to be retrieved.
We addlexical and semantic information to both thequery and the documents, during a prepro-cessing phase in which the input questionand the texts are disambiguated.
The disam-biguation process relies on contextual infor-mation, and identify the meaning of the wordsbased on WordNet 1 (FeUbaum, 1998) senses.As described in the fourth section, we haveopted for a disambiguation algorithm whichis semi-complete (it dis~mbiguates about 55%of the nouns and verbs), but is highly precise(over 92~ accuracy), instead of using a com-plete but less precise disambiguation.
A partof speech tag is also appended to each word.After adding these lexical and semantic tagsto the words, the documents are ready to beindexed: the index is created using the wordsas lexical strings (to ensure a word-based re-trieval), and the semantic tags (for the sense-based retrieval).Once the index is created, an input query is~n~wered using the document retrieval com-ponent of our system.
First, the query is fullydisambiguated; then, it is adapted to a spe-cific format which incorporates semantic in-formation, as found in the index, and usesthe AND and OR operators implemented inthe retrieval module.Hence, using semantic indexing, we try tosolve the two main problems of the m systemsdescribed earlier.
(1) relevant information isnot missed by not specifying the exact key-words; with the new tags added to the words,we also retrieve words which are semanticallyrelated to the input keywords; (2) using thesense-based component of our retrieval sys-XWordNet 1.6 is used in our system.35tern, the number of results returned from asearch can be reduced, by specifying exactlythe lexical functionality and/or the meaningof an input keyword.The system was tested using the Cran-field standard test collection.
This collec-tion consists of 1400 docllments, SGML for-mated, from the aerodynamics field.
Fromthe 225 questions associated with this dataset, we have randomly selected 50 questionsand build for each of them three types ofqueries: (1) a query that uses only keywordsselected from the question, stemmed using theWordNet stemmer2; (2) a query that uses thekeywords from the question and the synsets3 for these keywords and (3) a query thatuses the keywords from the question, thesynsets for these keywords and the synsets forthe keywords hypernyms.
All these types ofqueries have been run against the semanticindex described in this paper.
Comparativeresults indicate the performance benefits of aretrieval system that uses a combined word-based and synset-based indexing and retrievalover the classic word based indexing.2 Re la ted  WorkThere are three main approaches reportedin the literature regarding the incorpora-tion of semantic information into IR systems:(1)conceptual inde~ng, (2) query expansionand (3) semantic indexing.
The former isbased on ontological taxonomies, while thelast two make use of Word Sense Disambigua-tion aigorithm~.2.1 Conceptual indexlr~gThe usage of concepts for document index-ing is a relatively new trend within the IRfield.
Concept matching is a technique thathas been used in limited domains, like the le-gal field were conceptual indexing has beenapplied by (Stein, 1997).
The FERRET sys-tem (Mauldin, 1991) is another example of2WordNet stemmer = words are stemmed based onWordNet definitions (using the morphstr function)3The words in  WordNet are organized in synonymsets, called synsets.
A synset is associated with a par-ticular sense of a word, and thus we use sense-basedand synset-based interchangeably.how concept identification can improve II:tsystems.To our knowledge, the most intensive workin this direction was performed by Woods(Woods, 1997), at Sun Microsystems Labo-ratories.
He creates ome custom built onto-logical taxonomies based on subsumtion andmorphology for the purpose of indexing andretrieving documents.
Comparing the per-formance of the system that uses conceptualindexing, with the performance obtained us-ing classical retrieval techniques, resulted inan increased performance and recall.
He de-fines also a new measure, called success ratewhich indicates if a question has an answerin the top ten documents returned by a re-trieval system.
The success rate obtained inthe case of conceptual indexing was 60%, re-spect to a maximum of 45~0 obtained usingother retrieval systems.
This is a signi~cantimprovement and shows that semantics canhave a strong impact on the effectiveness ofIR systems.The experiments described in (Woods,1997) refer to small collections of text, asfor example the Unix manual pages (about10MB of text).
But, as shown in (Ambroziak,1997), this is not a limitation; conceptual in-dexing can be successfully applied to muchlarger text collections, and even used in Webbrowsing.2.2 Query  ExpungionQuery expansion has been proved to havepositive effects in retrieving relevant informa-tion (Lu and Keefer, 1994).
The purpose ofquery extension can be either to broaden theset of documents retrieved or to increase theretrieval precision.
In the former case, thequery is expanded with terms similar withthe words from the original query, while inthe second case the expansion procedure addscompletely new terms.There are two main techniques used in ex-panding an original query.
The first one con-siders the use of Machine Readable Dictio-nary; (Moldovan and Mihaicea, 2000) and(Voorhees, 1994) are making use of WordNetto enlarge the query such as it includes words36which are semantically related to the conceptsfrom the original query.
The basic semanticrelation used in their systems is the synonymyrelation.
This technique requires the disam-biguation of the words in the input query andit was reported that this method can be usefulif the sense disambiguation is highly accurate.The other technique for query expan.qion isto use relevance f edback, as used in SMART(Buckley et al, 1994).2.3 Semantic indexingThe usage of word senses in the process ofdocument indexing is a pretty much debatedfield of discussions.
The basic idea is to in-dex word meanings, rather than words takenas lexical strings.
A survey of the efforts ofincorporating WSD into IR is presented in(Sanderson, 2000).
Experiments performedby different researchers led to various, some-time contradicting results.
Nevertheless, theconclusion which can be drawn from all theseexperiments i that a highly accurate WordSense Disambiguation algorithm is needed inorder to obtain an increase in the performanceof IR systems.Ellen Voorhees (Voorhees, 1998) (Voorhees,1999) tried to resolve word ambiguity in thecollection of documents, as well as in thequery, and then she compared the results ob-tained with the performance of a standardrun.
Even if she used different weightingschemes, the overall results have shown adegradation in IR effectiveness when wordmeanings were used for indexing.
Still, as shepointed out, the precision of the WSD tech-nique has a dramatic influence on these re-sults.
She states that a better WSD can leadto an increase in IR performance.A rather "artificial" experiment in the samedirection of semantic indexing is provided in(Sanderson, 1994).
He uses pseudo-wordsto test the utility of disambiguation i IR.A pseudo-word is an artificially created am-biguous word, like for example "banana-door"(pseudo-words have been introduced for thefirst time in (Yarowsky, 1993), as means oftesting WSD accuracy without the costs as-sociated with the acquisition of sense taggedcorpora).
Different levels of ambiguity wereintroduced in the set of documents prior to in-dexing.
The conclusion drawn was that WSDhas little impact on IR performance, to thepoint that only a WSD algorithm with over90% precision could help IR systems.The reasons for the results obtained bySanderson have been discussed in (Schutzeand Pedersen, 1995).
They argue that theusage of pseudo-words does not always pro-vide an accurate measure of the effect of WSDover IR performance.
It is shown that in thecase of pseudo-words, high-frequency wordtypes have the majority of senses of a pseudo-word, i.e.
the word ambiguity is not realisti-cally modeled.
More than this, (Schutze andPedersen, 1995) performed experiments whichhave shown that semantics can actually helpretrieval performance.
They reported an in-crease in precision of up to 7% when sensebased indexing is used alone, and up to 14%for a combined word based and sense basedindexing.One of the largest studies regarding theapplicability of word semantics to IR is re-ported by Krovetz (Krovetz and Croft, 1993),(Krovetz, 1997).
When talking about wordambiguity, he collapses both the morpholog-ical and semantic aspects of ambiguity, andrefers them as polysemy and homonymy.
Heshows that word senses hould be used in ad-dition to word based indexing, rather thanindexing on word senses alone, basically be-cause of the uncertainty involved in sense dis-ambiguation.
He had extensively studied theeffect of lexical ambiguity over ~ the ex-periments described provide a clear indicationthat word meanings can improve the perfor-mance of a retrieval system.
(Gonzalo et al, 1998) performed experi-ments in sense based indexing: they used theSMART retrieval system and a manually dis-ambiguated collection (Semcor).
It turnedout that indexing by synsets can increase re-call up to 29% respect to word based indexing.Part of their experiments was the simulationof a WSD algorithm with error rates of 5%,10%, 20%, 30% and 60%: they found that er-ror rates of up to 10% do not substantially af-37fect precision, and a system with WSD errorsbelow 30% still perform better than a stan-dard run.
The results of their experimentsare encouraging, and proved that an accurateWSD algorithm can significantly help IR sys-tems.We propose here a system which triesto combine the benefits of word-based andsynset-based indexing.
Both words andsynsets are indexed in the input text, and theretrieval is then performed using either one orboth these sources of information.
The key toour system is a WSD method for open text.3 System Arch i tec tureThere are three main modules used by thissystem:1.
Word  Sense Dis~rnbiguation (WSD)module, which performs a semi-completebut precise disambiguation f the wordsin the documents.
Besides semantic in-formation, this module also adds part ofspeech tags to each word and stems theword using the WordNet stemmlug algo-rithm.
Every document in the input setof documents i  processed with this mod-ule.
The output is a new document inwhich each word is replaced with the newformatPoslStemlPOSlO.f.f setwhere: Pos is the position of the wordin the text; Stem is the stemmed form ofthe word; POS is the part of speech andOffset is the offset of the WordNet synsetin which this word occurs.In the case when no sense is assigned bythe WSD module or if the word cannotbe found in WordNet, the last field is leftempty.2.
Indexing module, which indexes thedocuments, after they are processed bythe WSD module.
From the new for-mat of a word, as returned by the WSDfunction, the Stem and, separately, theOffset{POS are added to the index.
Thisenables the retrieval of the words, re-garded as lexical strings, or the retrievalof the synset of the words (this actuallymeans the retrieval of the given sense ofthe word and its synonyms).. Retr ieval  module, which retrieves doc-uments, based on an input query.
Aswe are using a combined word-based andsynset-based indexing, we can retrievedocuments containing either (1) the in-put keywords, (2) the input keywordswith an assigned sense or (3) synonymsof the input keywords.4 Word  Sense  D is~mbiguat ionAs stated earlier, the WSD is performed forboth the query and the documents from whichwe have to retrieve information.The WSD algorithm used for this purposeis an iterative algorithm; it was for the firsttime presented in (Mihalcea and Moldovan,2000).
It determines, in a given text, a set ofnouns and verbs which can be disambiguatedwith high precision.
The semantic tagging isperformed using the senses defined in Word-Net.In this section, we present the variousmethods used to identify the correct sense of aword.
Then, we describe the main algorithmin which these procedures are invoked in aniterative manner.PROCEDUP.~ 1.
This procedure identifies theproper nonn.q in the text, and marked themas having sense ~1.Example.
c C Hudson,, is identified as aproper noun and marked with sense #1.PROCEDURE 2.
Identify the words havingonly one sense in WordNet (monosemouswords).
Mark them with sense #1.Example.
The noun subco~ait tee has onesense defined in WordNet.
Thus, it is amonosemous word and can be marked as hav-ing sense #1.PROCEDURE 3.
For a given word Wi, at po-sition i in the text, form two pairs, one withthe word before W~ (pair Wi-l-Wi) and theother one with the word after Wi (pair Wi-Wi+i).
Determiners or conjunctions cannot38be part of these pairs.
Then, we extract allthe occurrences of these pairs found withinthe semantic tagged corpus formed with the179 texts from SemCor(Miller et al, 1993).
If,in all the occurrences, the word Wi has onlyone sense #k,  and the number of occurrencesof this sense is larger than 3, then mark theword Wi as having sense #k.Example.
Consider the word approva l  inthe text fragment ' ' commit tee approva lo f '  '.
The pairs formed are ' ~cown-itteeapprova l '  and ' ~ approva l  of  ' '.
No oc-currences of the first pair are found in thecorpus.
Instead, there are four occurrences ofthe second pair, and in all these occurrencesthe sense of approva l  is sense #1.
Thus,approva l  is marked with sense #1.PROCEDURE 4.
For a given noun N in thetext, determine the noun-context of each ofits senses.
This noun-context is actually a listof nouns which can occur within the contextof a given sense i of the noun N. In order toform the noun-context for every sense Ni, weare determining all the concepts in the hyper-nym synsets of Ni.
Also, using SemCor, wedetermine all the nouns which occur within awindow of 10 words respect o Ni.All of these nouns, determined using Word-Net and SemCor, constitute the noun-contextof Ni.
We can now calculate the number ofcommon words between this noun-context andthe original text in which the noun N is found.Applying this procedure to all the senses ofthe noun N will provide us with an orderingover its possible senses.
We pick up the sensei for the noun N which: (1) is in the top ofthis ordering and (2) has the distance to thenext sense in this ordering larger than a giventhreshold.Example.
The word d iameter ,  as it appearsin the document 1340 from the Cranfield col-lection, has two senses.
The common wordsfound between the noun-contexts of its sensesand the text are: for d iameter#l :  { property,hole, ratio } and for d iameter#2: { form}.For this text, the threshold was set to 1, andthus we pick d:i.ameter#1 as the correct sense(there is a difference larger than 1 betweenthe number of nouns in the two sets).PROCEDURE 5.
Find words which are se-mantically connected to the already disam-biguated words for which the connection dis-tance is 0.
The distance is computed basedon the Word_Net hierarchy; two words are se-mantically connected at a distance of 0 if theybelong to the same synset.Example.
Consider these two words ap-pearing in the text to be disambiguated:author i ze  and c lear .
The verb author i zeis a monosemous word, and thus it is disam-biguated with procedure 2.
One of the sensesof the verb c lear ,  namely sense #4,  appearsin the same synset with author i ze#I ,  andthus c lear  is marked as having sense #4.PROCEDURE 6.
Find words which are seman-tically connected, and for which the connec-tion distance is 0.
This procedure is weakerthan procedure 5: none of the words con-sidered by this procedure are already disamobiguated.
We have to consider all the sensesof both words in order to determine whetheror not the distance between them is 0, andthis makes this procedure computationally in-tensive.Example.
For the words measure and b i l l ,both of them ambiguous, this procedure triesto find two possible senses for these words,which are at a distance of 0, i.e.
they be-long to the same synset.
The senses foundare measure#4 and b i l l# l ,  and thus the twowords are marked with their correspondingsenses .PROCEDURE 7.
Find words which are se-mantically connected to the already disam-biguated words, and for which the connectiondistance is maximum 1.
Again, the distanceis computed based on the WordNet hierar-chy; two words are semantically connected ata maximum distance of 1 if they are synonymsor they belong to a hypernymy/hyponymy re-lation.Example.
Consider the nouns subcommitteeand committee.
The first one is disarmbiguated with procedure 2, and thus it ismarked with sense #1.
The word committeewith its sense #1 is semantically linked withthe word subcommittee by a hypernymy re-lation.
Hence, we semantically tag this word39with sense ~1.PROCEDURE 8.
Find words which are se-mantically connected between them, and forwhich the connection distance is maximum 1.This procedure is similar with procedure 6:both words are ambiguous, and thus all theirsenses have to be considered in the process offinding the distance between them.Example.
The words g i f t  and donat ionare both ambiguous.
This procedure findsg i f t  with sense #1 as being the hypernymof donat ion,  also with sense ~1.
Therefore,both words are disambiguated and markedwith their assigned senses.The procedures presented above are appliediteratively.
This allows us to identify a set ofnouns and verbs which can be disambiguatedwith high precision.
About 55% of the nounsand verbs are disambiguated with over 92%accuracy.A lgor i thmStep 1.
Pre-process the text.
This impliestokenization and part-of-speech tagging.
Thepart-of-speech tagging task is performed withhigh accuracy using an improved version ofBrill's tagger (Brill, 1992).
At this step, wealso identify the complex nominals, based onWordNet definitions.
For example, the wordsequence ' 'p ipel ine companies '  ' is foundin WordNet and thus it is identified as a singleconcept.
There is also a list of words whichwe do not attempt o dis~.mbiguate.
Thesewords are marked with a special flag to in-dicate that they should not be considered inthe disrtmbiguation process.
So far, this listconsists of three verbs: be, have, do.Step 2.
Initi~\]i~.e the Set of DisambiguatedWords (SDW) with the empty set SDW={}.Initialize the Set of Ambiguous Words (SAW)with the set formed by all the nouns and verbsin the input text.Step 3.
Apply procedure 1.
The named en-tities identified here are removed from SAWand added to SDW.Step 4.
Apply procedure 2.
The monosemouswords found here axe removed from SAW andadded to SDW.Step 5.
Apply procedure 3.
This step allowsus to disambiguate words based on their oc-currence in the semantically tagged corpus.The words whose sense is identified with thisprocedure are removed from SAW and addedto SDW.Step 6.
Apply procedure 4.
This will identifya set of nouns which can be disambiguatedband on their noun-contexts.Step 7.
Apply procedure 5.
This proceduretries to identify a synonymy relation betweenthe words from SAW and SDW.
The wordsdisambiguated are removed from SAW andadded to SDW.Step 8.
Apply procedure 6.
This step is dif-ferent from the previous one, as the synonymyrelation is sought among words in SAW (noSDW words involved).
The words disam-biguated are removed from SAW and addedto SDW.Step 9.
Apply procedure 7.
This step triesto identify words from SAW which are linkedat a distance of maximum 1 with the wordsfrom SDW.
Remove the words dis ambiguatedfrom SAW and add them to SDW.Step 10.
Apply procedure 8.
This procedurefinds words from SAW connected at a distanceof maximum I.
As in step 8, no words fromSDW are involved.
The words disambiguatedare removed from SAW and added to SDW.Resu l tsTo determine the accuracy and the recallof the disambiguation method presented here,we have performed tests on 6 randomly se-lected files from SemCor.
The following fileshave been used: br-a01, br-a02, br-k01, br-k18, br-m02, br-r05.
Each of these files wassplit into smaller files with a maximum of 15lines each.
This size limit is based on ourobservation that small contexts reduce theapplicability of procedures 5-8, while largecontexts become a source of errors.
Thus,we have created a benchmark with 52 texts,on which we have tested the disambiguationmethod.In table 1, we present he results obtalnedfor these 52 texts.
The first cohlmn indicatesthe file for which the results are presented.The average number of no, ms and verbs con-sidered by the disambiguation algorithm foreach of these files is shown in the second col-40Table I: Results for the WSD algorithm applied on 52 textsNo.
Proc.l+2 Proc.3 Proc.4 Proc.5+6 Proc.7+8File words No.
Ace.
No.
Ace.
No.
Acc.
No.
Ace.
No.
Acc.br-a01 132 40 100% 43 99.7~ 58.5 94.6% 63.8 92.7% 73.2 89.3%br-a02 135 49 100% 52.5 98.5% 68.6 94% 75.2 92.4% 81.2 91.4%br-k01 -68.1 17.2 100% 23.3 99.7% 38.1 97.4% 40.3 97.4% 41.8 96.4%br-k18 60.4 18.1 100% 20.7 99.1% 26.6 96.9% 27.8 95.3% 29.8 93.2%br-m02 63 17.3 100% 20.3 98.1% 26.1 95% 26.8 94.9% 30.1 93.9%br-r05 72.5 14.3 100% 16.6 98.1% 27 93.2% 30.2 91.5% 34.2 89.1%AVERAGE 88.5 25.9 100% 29.4 98.8% 40.8 95.2% 44 94% 48.4 92.2%umn.
In columns 3 and 4, there are presentedthe average number of words disambiguatedwith procedures 1 and 2, and the accuracyobtained with these procedures.
Column 5and 6 present the average number of wordsdisambiguated and the accuracy obtained af-ter applying procedure 3 (cumulative results).The cumulative results obtained after apply-ing procedures 3, 4 and 5, 6 and 7, are shownin columns 7 and 8, 9 and 10, respectivelycolumns 10 and 11.The novelty of this method consists of thefact that the disambiguation process is donein an iterative manner.
Several procedures,described above, are applied such as to builda set of words which are disambiguated withhigh accuracy: 55% of the nouns and verbsare disambiguated with a precision of 92.22%.The most important improvements whichare expected to be achieved on the WSD prob-lem are precision and speed.
In the case ofour approach to WSD, we can also talk aboutthe need for an increased fecal/, meaning thatwe want to obtain a larger number of wordswhich can be disambiguated in the input text.The precision of more than 92% obtainedduring our experiments i very high, consid-ering the fact that Word.Net, which is the dic-tionary used for sense identification, is veryfine grained and sometime the senses are veryclose to each other.
The accuracy obtained isclose to the precision achieved by humans insense disambiguation.5 Index ing  and  Ret r ieva lThe indexing process takes a group of docu-ment files and produces a new index.
Suchthings as unique document identifiers, properSGML tags, and other artificial constructs areignored.
In the current version of the system,we are using only the AND and OR booleanoperators.
Future versions will consider theimplementation of the NOT and NEAR oper-ators.The information obtained from the WSDmodule is used by the main indexing process,where the word stem and location are indexedalong with the WordNet synset (if present).Collocations are indexed at each location thata member of the collocation occurs.All elements of the document are indexed.This includes, but is not limited to, dates,numbers, document identifiers, the stemmedwords, collocations, WordNet synsets (ifavailable), and even those terms which otherindexers consider stop words.
The only itemscurrently excluded from the index are punc-tuation marks which are not part of a wordor collocation.The benefit of this form of indexing is thatdocuments may be retrieved using stemmedwords, or using synset offsets.
Using synsetoffset values has the added benefit of retriev-ing documents which do not contain the orig-inal stemmed word, but do contain synonymsof the original word.The retrieval process is limited to the use ofthe Boolean operators AND and OR.
Thereis an auxiliary front end to the retrieval en-gine which allows the user to enter a textualquery, such as, "What financial institutionsare .found along the banks of the Nile?"
Theauxiliary front end will then use the WSD todisambiguate the query and build a Booleanquery for the standard retrieval engine.For the preceding example, the auxil-41iary front end would build the query: (fi-nanciaLinstitution OR 60031M\[NN) AND(bank OR 68002231NN) AND (Nile OR68261741NN) where the numbers in the pre-vious query represent the offsets of the synsetsin which the words with their determinedmeaning occur.Once a list of documents meeting the queryrequirements has been determined, the com-plete text of each matching document is re-trieved and presented to the user.6 An  ExampleConsider, for example, the following ques-tion: "Has anyone investigated the effect ofsurface mass transfer on hypersonic viscousinteractionsf'.
The question processing in-volves part of speech tagging, stemming andword sense disambiguation.The question be-comes: "Has anyone investigate I VB1535831the effectlNN 17766144 o/surfacelN~3447223massl NN139234 35 transferl Nhq132095on hypersoniclJJ viscouslJJ interactionlNNl7840572".The selection of the keywords is not aneasy task, and it is performed using the setof 8 heuristics presented in (Moldovan et al,1999).
Because of space limitations, we arenot going to detail here the heuristics and thealgorithm used for keywords election.
Themain idea is that an initial nnmber of key-words is determined using a subset of theseheuristics.
If no documents are retrieved,more keywords are added, respectively a toolarge number of documents will imply thatsome of the keywords are dropped in the re-versed order in which they have been entered.For each question, three types of query areformed, using the AND and OR.
operators.1.
QwNstem.
Keywords from the question,stemmed based on WordNet, concate-nated with the AND operator.2.
QwNoffset.
Keywords from the ques-tion, stemmed based on WordNet, con-catenated using the OR.
operator withthe associated synset offset, and con-catenated with the AND operator amongthem.. QwNHyperOfSset.
Keywords from thequestion, stemmed based on WordNet,concatenated using the OR operator withthe associated synset offset and with theoffset of the hypernym synset, and con-catenated with the AND operator amongthem.All these types of queries are run againstthe semantic index created based on wordsand synset offsets.
We denote these rime withRWNStem, RWNOyfset and RWNHyperOffset.The three query formats, for the given ques-tion, are presented below:QwNstern.
effect AND surface AND massAND flow AND interactionQwNoyyset.
(effect OR 77661441NN) AND(surface OR 3447223\[NN) AND (mass OR392343651NN) AND (transfer OR 1320951NN)AND (interaction OR 78405721NN)QWNHyperOf fset (effect OR 77661441NN OR20461\]NN) AND (surface OR3447223\]NN OR 119371NN ) AND (mass OR.39234351NN OR 3912591\[NN) AND (transferOR 1320951NN OR.
1304701NN) AND (inter-action OR.
784057?~NN OR.
7770957~NN)Using the first type of query, 7 documentswere found out of which 1 was consideredto be relevant.
With the second and thirdtypes of query, we obtained 11, respectively17 documents, out of which 4 were found rel-evant, and actually contained the answer tothe question.
(sample answer) ... the present report gives an ac-count  of the development o\] an approzimate theory tothe problem of hypersonic strong viscous interactionon a fiat plate with mass-transfer at the plate surface.the disturbance flow region is divided into inviscid andviscous flo~ regions .... (craniield0305).77 Resu l tsThe system was tested on the Cranfield col-lection, including 1400 documents, SGMLformated 4.
From the 225 questions provided4Demo available online athttp://pdpl 3.seas.smu.edu/rada/sem.ind./42with this collection, we randomly selected 50questions and used them to create a bench-mark against which we have performed thethree runs described in the previous ections:RW N Stem , RW N O f f set and 1-~W N HyperO f f set.For each of .these questions, the systemforms three types of queries, as describedabove.
Below, we present 10 of these ques-tions and show the results obtained in Table2.I .
Has  anyone investigated the effect of surface mass trans-fer  on hypersonic ~'L~cwas interactions?$.
What is the combined effect of surface heat and masstransfer on hypersonic f low?3.
What are the existing solutions for hypersonic viscous in-teractions over an insulated fiat plate?4.
What controls leading-edge attachment at transonic ve-locities ?5.
What are wind-tunnel corrections for a two-dimensionalaerofoil mounted off-centre in a tunnel?6.
What is the present state of the theory of quasi-conicalflows ?7.
References on the methods available for accurately esti-mating aerodynamic heat transfer to conical bodies for bothlaminar and turbulent flow.8.
What parameters can seriously influence natural transi-tion from laminar to turbulent f low on a model in a windtunnel?9.
Can a satisfactory e~perimental technique be devel-oped for measuring oscillatory derivatives on slender sting-mounted models in supersonic wind tunnels?I0.
Recent data on shock-induced boundary-layer separation.Three measures are used in the evaluationof the system performance: (1) precision, de..fined as the number of relevant documents re-trieved over the total number of documentsretrieved; (2) real/, defined as the numberof relevant documents retrieved over the totalnumber of relevant documents found in thecollection and (3) F-measure, which combinesboth the precision and recall into a single for-mula:Fmeas~re = (32 + l'O) * P * R?
P) + Rwhere P is the precision, R is the recall andis the relative importance given to recallover precision.
In our case, we consider bothprecision and recall of equal importance, andthus the factor fl in our evaluation is 1.The tests over the entire set of 50 questionsled to 0.22 precision and 0.25 recall when theWordNet stemmer is used, 0.23 precision and0.29 recall when using a combined word-basedand synset-based indexing.
The usage of hy-pernym synsets led to a recall of 0.32 and aprecision of 0.21.The relative gain of the combined word-based and synset-based indexing respect othe basic word-based indexing was 16% in-crease in recall and 4% increase in precision.When using the hypernym synsets, there is a28% increase in recall, with a 9% decrease inprecision.The conclusion of these experiments is thatindexing by synsets, in addition to the clas-sic word-based indexing, can actually improveIR effectiveness.
More than that, this is thefirst time to our knowledge when a WSD algo-rithm for open text was actually used to au-tomaticaUy disambiguate a collection of textsprior to indexing, with a disambiguation ac-curacy high enough to actually increase therecall and precision of an IR system.An issue which can be raised here is the ef-ficiency of such a system: we have introduceda WSD stage into the classic IR process and itis well known that WSD algorithm.~ are usu-ally computationally intensive; on the otherside, the disambiguation f a text collectionis a process which can be highly parallelized,and thus this does not constitute a problemanymore.8 Conc lus ionsThe full understanding of text is still an elu-sive goal.
Short of that, semantic indexingoffers an improvement over current IR tech-niques.
The key to semantic indexing is fastWSD of large collections of documents.In this paper we offer a WSD method foropen domains that is fast and accurate.
Sinceonly 55% of the words can be disambiguatedso far, we use a hybrid indexing approach thatcombines word-based and sense-based index-ing.
The senses in WordNet are fine grain andthe WSD method has to cope with this.
The43Table 2: Results for 10 questions run against he three indices created on the Cranlleld collection.
The bottomline shows the results for the entire set of questions.Question .RW N Stcmnumber recall precision Lmeasure1 0.08 0.14 0.052 0.06 0.17 0.043 0.47 0.70 0.284 0.25 0.60 0.185 0.33 0.50 0.206 0.00 0.00 0.007 0.17 0.17 0.098 0.20 0.II 0.079 0.67 0.50 0.2910 0.29 0.07 0.06Avo/50 0.25 0.22 0.09recall0.31 0.36 0.170.25 0.44 0.160.47 0.70 0.280.25 0.60 0.181.00 0.25 0.200.00 0.00 0.000.17 0.17 0.090.20 0.II 0.070.67 0.50 0.290.29 0.07 0.06Query typeRw N o f f ~et RW l~ H ~rO y.f setprecision f-measure recall precc~mn f-measure0.29 0.23 0.110.31 0.24 0.140.25 0.31 0.140.53 0.67 0.300.25 0.60 0.181.00 0.19 0.160.00 0.00 0.000.17 0.17 0.090.20 0.11 0.071.00 0.38 0.280.29 0.06 0.050.32 0.21 0.10WSD algorithm presented here is new for theNLP community and proves to be well suitedfor a task such as semantic indexing.The continuously increasing amount of in-formation available today requires more andmore sophisticated IR techniques, and seman-tic indexing is one of the new trends when try-ing to improve IR effectiveness.
With seman-tic indexing, the search may be expanded toother forms of semantically related conceptsas done by Woods (Woods, 1997).
Finally,semantic indexing can have an impact on thesemantic Web technology that is under con-sideration (Hellman, 1999).Re ferencesJ.
Ambroziak.
1997.
Conceptually assisted Webbrowsing.
In Sixth International World WideWeb conference, Santa Clara, CA.
full paperavailable online at http://www.scope.gmd.de\[info/www6/posters/702/guide2.html.E.
Brill.
1992.
A simple rule-based part of speechtagger.
In Proceedings of the 3rd Conference onApplied Natural Language Processing, Trento,Italy.C.
Buckley, G. Salton, J. Allan, and A. Singhal.1994.
Automatic query expansion using smart:Trec 3.
In Proceedings of the Text REtrievalConference (TREC-3), pages 69--81.C.
Fellbaurn.
1998.
WordNet, An Electronic Lex-ical Database.
The MIT Press.J.
Gonzalo, F. Verdejo, I. Chugur, and J. Cigar-ran.
1998.
Indexing with WordNet synsetscan improve text retrieval.
In Proceedingsof COLING-ACL '98 Workshop on Usage ofWord.Net in Natural Language Processing Sys-tems, Montreal, Canada, August.R.
HeUman.
1999.
A semantic approach addsmeaning to the Web.
Computer, pages 13-16.R.
Krovetz and W.B.
Croft.
1993.
Lexical ambi-guity and in_formation retrieval.
A CM Transac-tions on Information Systems, 10(2):115--141.R.
Krovetz.
1997.
Homonymy and polysemy in in-formation retrieval.
In Proceedings of the 35thAnnual Meeting of the Association for Compu-tational Linguistics (A CL-97}, pages 72-79.X.A.
Lu and R.B.
Keefer.
1994.
Query expan-sion/reduction and its impact on retrieval ef-fectiveness.
In The Text REtrieval Conference(TREC-3), pages 231-240.M.L.
Mauldin.
1991.
Retrieval performancein FERRET: a conceptual information re-trieval system.
In Proceedings of the lSthInternational ACM-SIGIR Conference on Re-search and Development in Information Re-trieval, pages 347-355, Chicago, IL, October.R.
Mihalcea and D.I.
Moldovan.
2000.
An iter-ative approach to word sense disambiguation.In Proceedings of FLAIRS-2000, pages 219-223,Orlando, FL, May.G.
Miller, C. Leacock, T. Randee, and R. Bunker.1993.
A semantic oncordance.
In Proceedingsof the 3rd DARPA Workshop on Human Lan-guage Technology, pages 303-308, Plaln~boro,New Jersey.D Moldovan and tL Mihalcea.
2000.
Using Word-Net and lexical operators to improve Internetsearches.
IEEE Internet Computing, 4(1):34--43.44D.
Moldovan, S. Harabagiu, M. Pasca, R. Mihal-cea, R. Goodrum, R. Girju, and V. Rus.
1999.LASSO: A tool for surfing the answer net.
InProceedings of the Text Retrieval Conference(TREU-8), November.M.
Sanderson.
1994.
Word sense disambiguationand information retrieval.
In Proceedings of the17th Annual International ACM-SIGIR Con-ference on Research and Development in In-formation Retrieval, pages 142-151, Springer-Verlag.M.
Sanderson.
2000.
Retrieving with good sense.Information Retrieval, 2(1):49--69.H.
Schutze and J. Pedersen.
1995.
Information re-trieval based on word senses.
In Proceedings ofthe 4th Annual Symposium on Document Anal-ysis and Information Retrieval, pages 161-175.J.A.
Stein.
1997.
Alternative methods of index-ing legal material: Development ofa conceptualindex.
In Proceedings of the Conference "LawVia the Internet g7", Sydney, Australia.E.M.
Voorhees.
1994.
Query expansion usinglexical-semantic relations.
In Proceedings of the17th Annual International ACM SIGIR, Con-ference on Research and Development in Infor-mation Retrieval, pages 61-69, Dublin, Ireland.E.M.
Voorhees.
1998.
Using WordNet for textretrieval.
In WordNet, An Electronic LexicalDatabase, pages 285-303.
The MIT Press.E.M.
Voorhees.
1999.
Natural language pro-eessing and information retrieval.
In Infor-mation Extraction: towards scalable, adaptablesystems.
Lecture notes in Artificial Intelligence,#1714, pages 32-48.W.A.
Woods.
1997.
Conceptual indexing: Abetter way to organize knowledge.
Techni-cal Report SMLI TR-97-61, Sun Mierosys-terns Laboratories, April.
available onlineat: http:l/www.sun.com I researeh/techrep/1997/abstract-61.html.D.
Yarowsky.
1993.
One sense per collocation.In Proceedings o\] the ARPA Human LanguageTechnology Workshop.45
