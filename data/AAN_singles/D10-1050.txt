Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 513?523,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsTitle Generation with Quasi-Synchronous GrammarKristian Woodsend, Yansong Feng and Mirella LapataSchool of Informatics, University of EdinburghEdinburgh EH8 9AB, United Kingdomk.woodsend@ed.ac.uk, Y.Feng-4@sms.ed.ac.uk, mlap@inf.ed.ac.ukAbstractThe task of selecting information and render-ing it appropriately appears in multiple con-texts in summarization.
In this paper wepresent a model that simultaneously optimizesselection and rendering preferences.
Themodel operates over a phrase-based represen-tation of the source document which we ob-tain by merging PCFG parse trees and depen-dency graphs.
Selection preferences for in-dividual phrases are learned discriminatively,while a quasi-synchronous grammar (Smithand Eisner, 2006) captures rendering prefer-ences such as paraphrases and compressions.Based on an integer linear programming for-mulation, the model learns to generate sum-maries that satisfy both types of preferences,while ensuring that length, topic coverage andgrammar constraints are met.
Experiments onheadline and image caption generation showthat our method obtains state-of-the-art per-formance using essentially the same model forboth tasks without any major modifications.1 IntroductionSummarization is the process of condensing a sourcetext into a shorter version while preserving its infor-mation content.
Humans summarize on a daily ba-sis and effortlessly, yet the automatic production ofhigh-quality summaries remains a challenge.Most work today focuses on extractive summa-rization, where a summary is created by identifyingand subsequently concatenating the most importantsentences in a document.
The advantage of this ap-proach is that it does not require a great deal of lin-guistic analysis to generate grammatical sentences,assuming the source document was well written.Unfortunately, extracts generated this way are oftendocuments of low readability and text quality, andcontain much redundant information.
The concise-ness can be improved when sentence extraction isinterfaced with sentence compression, where wordsand clauses are deleted based on rules typically op-erating over parsed input (Jing, 2000; Daume?
IIIand Marcu, 2002; Lin, 2003; Daume?
III, 2006; Zajicet al, 2007; Martins and Smith, 2009).An alternative abstractive or ?bottom-up?
ap-proach involves identifying high-interest words andphrases in the source text, and combining them intonew sentences guided by a language model (Bankoet al, 2000; Soricut and Marcu, 2007).
This ap-proach has the potential to work well, breaking outof the single-sentence paradigm.
Unfortunately, theresulting summaries are not always coherent ?
indi-vidual constituent phrases are often combined with-out any semantic constraints ?
or grammatical be-yond the n-gram horizon imposed by the languagemodel.Constituent deletion and recombination aremerely two of the many rewrite operations profes-sional editors and abstractors employ when creatingsummaries (Jing, 2002).
Additional operations in-clude truncating sentences, aggregating them, andparaphrasing at word or syntax level.
Furthermore,professionals write summaries in a task-specificstyle.
News headlines for example are typicallyshort (three to six words), written in the presenttense and active voice, and often leave out forms ofthe verb be.
There are also different ways of writinga headline either directly by stating what the docu-513ment is about or indirectly by raising a question inthe reader?s mind, which the document answers.The automatic generation of summaries similar tothose produced by human abstractors is challengingbecause of the many constraints imposed by the task:the summary must be maximally informative andminimally redundant, grammatical, coherent, adhereto a pre-specified length and stylistic conventions.Importantly, these constraints are conflicting; thedeletion of certain phrases may avoid redundancybut result in ungrammatical output and informationloss.In this paper we propose a model for summariza-tion that attempts to capture and optimize these con-straints jointly.
We learn both how to select themost important information (the content), and howto render it appropriately (the style).
Selection pref-erences are learned discriminatively, while a quasi-synchronous grammar (QG, Smith and Eisner 2006)captures rendering preferences such as paraphrasesand compressions.
The entire solution space ofpossible extractions and QG-generated paraphrasesis searched efficiently through use of integer lin-ear programming.
The ILP framework allows us tomodel naturally as constraints, additional require-ments such as sentence length, overall summarylength, topic coverage and, importantly, grammati-cality.We argue that QG is attractive for describ-ing rewrite operations common in summarization.Rather than assuming a strictly synchronous struc-ture over the source and target sentences, QG iden-tifies a ?sloppy?
alignment of parse trees assumingthat the target tree is in some way ?inspired by?
thesource tree.
A key insight in our approach is toformulate the summarization problem at the phraselevel: both QG rules and information extraction op-erate over individual phrases rather than (as is thenorm) sentences.
At this smaller unit level, QGrules become more widely applicable and compres-sion falls naturally because only phrases deemed im-portant should appear in the summary.We evaluate the proposed model on headline gen-eration and the related task of image caption gen-eration.
However, there is nothing inherent in ourformulation that is specific to those two tasks; it ispossible for the model to generate longer or shortersummaries, for a single or multiple documents.
Ex-perimental results show that our method obtainsstate-of-the-art performance, both in terms of gram-maticality and informativeness for both tasks usingthe same summarization model.2 Related workMuch effort in automatic summarization has beendevoted to sentence extraction which is often for-malized as a classification task (Kupiec et al, 1995).Given appropriately annotated training data, a bi-nary classifier learns to predict for each documentsentence if it is worth extracting.
A few previ-ous approaches have attempted to interface sentencecompression with summarization.
A straightforwardway to achieve this is by adopting a two-stage ar-chitecture (e.g., Lin 2003) where the sentences arefirst extracted and then compressed or the other wayround.Other work implements a joint model wherewords are deleted and sentences selected from a doc-ument simultaneously (Daume?
III and Marcu, 2002;Martins and Smith, 2009; Woodsend and Lapata,2010).
ILP models have also been developed forsentence rather than document compression (Clarkeand Lapata, 2008).
Dras (1999) discusses the appli-cation of ILP to reluctant paraphrasing, i.e., the taskof choosing between paraphrases while conformingto length, readability, or style constraints.
Again,the aim is to rewrite text without, however, con-tent selection.
Rewrite operations other than dele-tion tend to be hand-crafted and domain specific(Jing and McKeown, 2000).
Notable exceptions areCohn and Lapata (2008) and Zhao et al (2009) whopresent a model that can both compress and para-phrase individual sentences without however gener-ating document-level summaries.Headline generation is a well-studied task withinsingle-document summarization, due to its promi-nence in the DUC-03 and DUC-04 evaluation com-petitions.1 Many approaches identify the most infor-mative sentence in a given document (typically thefirst sentence for the news genre) and subsequentlyapply a form of sentence compression such thatthe headline meets some length requirement (Dorr1Approaches to headline generation are too numerous to listin detail; see the proceedings of DUC-03 and DUC-04 for anoverview.514et al, 2003).
The compressed sentence may also be?padded?
with important content words or phrasesto ensure that the topic of the document is covered(Zajic et al, 2004).
Other work generates headlinesin a bottom-up fashion starting from important, indi-vidual words and phrases, that are glued together tocreate a fluent sentence.
For example, Banko et al(2000) draw inspiration from Machine Translationand generate headlines using statistical models forcontent selection and sentence realization.Relatively little work has focused on caption gen-eration, a task related to headline generation.
Theaim here is to create a short, title-like description ofan image embedded in a news article.
Like head-lines, captions have to be short and informative.
Inaddition, a good caption must clearly identify thesubject of the picture and establish its relevance tothe article.
Feng and Lapata (2010a) develop ex-tractive and abstractive caption generation modelsthat operate over the output of a probabilistic im-age annotation model that preprocesses the picturesand suggests keywords to describe their content.Their best model is an extension of Banko et al?s(2000) word-based model for headline generation tophrases.Our own work develops an ILP-based summariza-tion model with rewrite operations that are not lim-ited to deletion, are defined over phrases, and en-coded in quasi-synchronous grammar.
The QG for-malism has been previously applied to parser adap-tation and projection (Smith and Eisner, 2009), para-phrase identification (Das and Smith, 2009), andquestion answering (Wang et al, 2007); howeverthe use of QG in summarization is novel to ourknowledge.
Unlike most synchronous grammar for-malisms, QG does not posit a strict isomorphism be-tween a source sentence and its target translation; itonly loosely links the syntactic structure of the two,and is therefore well suited to describing the rela-tionship between a document and its abstract.
Wepropose an ILP formulation which not only allowsto efficiently search through the space of many QGrules but also to incorporate constraints relating tocontent, style, and the task at hand.3 ModelingThere are three components to our model.
Contentselection is performed discriminatively; an SVMlearns which information in the source documentshould be in the summary, and gives a real-valuedsalience score for each phrase.
QG rules are usedto generate compressions and paraphrases of thesource sentences.
An ILP model combines the out-put of these two components into an output sum-mary, while optimizing content selection and surfacerealization preferences jointly.3.1 Document RepresentationOur model operates on documents annotated withsyntactic information which we obtain by parsingevery sentence twice, once with a phrase structureparser and once with a dependency parser.
The out-put from the two representations is combined into asingle data structure, by mapping the dependenciesto the edges of the phrase structure tree.
The proce-dure is described in detail in Woodsend and Lapata(2010).
However, we do not merge the leaf nodesinto phrases here, but keep the full tree structure,as we will apply compression to phrases throughthe QG.
In our experiments, we obtain this com-bined representation from the output of the Stan-ford parser (Klein and Manning, 2003) but any otherbroadly similar parser could be used instead.3.2 Quasi-synchronous grammarGiven an input sentence S1 or its parse tree T1, theQG constructs a monolingual grammar for parsing,or generating, the possible translation (or here, para-phrase) trees T2.
A grammar node in the target treeT2 is modeled on a subset of nodes in the source tree,with a rather loose alignment between the trees.In our approach, the process of learning the gram-mar is unsupervised.
Each sentence of the sourcedocument is compared to each sentence in the targetdocument ?
headline or caption, depending on thetask.
Using the combined PCFG-dependency treerepresentation described above, we build up a list ofleaf node alignments based on lexical identity, afterstemming and removing stop words.
We align directparent nodes where more than one child node aligns.A grammar rule is created if the all the nodes in thetarget tree can be explained using nodes from the515(a) NPNNP/nnSaudiJJ/amoddissidentNNP/nnOsamaNNP/nnbinNNP/?LadenNPNNP/nnbinNNP/?Laden(b) PP/prep inIN/?inDT/dettheJJ/amoddisputedNN/?territoryPP/prep ofIN/?ofNNP/nnEastNNP/?TimorPP/prep inIN/?inNNP/nnEastNNP/?Timor(c) NP/dobjDT/dettheNN/?extraditionPP/prep ofIN/?ofNNP/nnKurdishNN/nnleaderNNP/?OcalanNP/dobjNP/possOcalan?sNN/?extraditionFigure 1: Examples of QG alignments betweensource node (left) and target node (right).
(a) align-ment of child nodes, involving compression throughdeletion; (b) rewriting involving child and grand-child nodes; (c) reordering of child nodes (with fur-ther compression through applying other QG ruleson children).
Nodes bear phrase and dependency la-bels.
Dotted lines show alignments in the grammarbetween source and target child nodes.
Examplesare taken from the QG rules discovered in the DUC-03 data set of headlines.source; this helps to improve the quality in what isinherently a noisy process.
Finally, QG rules are cre-ated from aligned nodes above the leaf node level,recording the phrase and dependency label of nodes,and the alignment of child nodes.Unlike previous work involving QG which hasused dependency graphs exclusively (e.g., Wanget al 2007; Das and Smith 2009), our approach op-erates over a combined PCFG-dependency represen-tation.
As a result, some configurations in Smith andEisner (2006) are not so relevant here ?
instead,we found that deletions, reorderings, flattening ofnodes, and the addition of text elements were im-CHOICE/?PP/prep inIN/?inDT/dettheJJ/amoddisputedNN/?territoryPP/prep ofIN/?ofNNP/nnEastNNP/?TimorPP/prep inIN/?inNNP/nnEastNNP/?TimorFigure 2: Alternative paraphrases are represented asa CHOICE sub-tree.portant operations for the grammar.Figure 1 shows some example alignments that arecaptured by the QG, with the source node on theleft and the target node on the right.
Leaf nodeshave their original text, while other nodes have acombined phrase and dependency label that they ob-tain in the merged representation described in Sec-tion 3.1 above (e.g., NP/dobj is a noun phrase and adirect object, NNP/nn is a proper noun and a nomi-nal modifier, whereas NN/?
is a head noun).
Align-ments between the children are shown by dottedlines.
In Figure 1(a), some child nodes are alignedwhile others are not present in the target tree.
Thistype of rule is common in our training data, and typ-ically arises from the compression of names in nounphrases.
Another frequent compression, shown inFigure 1(b), is flattening the tree structure by in-corporating grand-child elements at the child level.Figure 1(c) shows a rule involving the reorderingof child nodes, and where additional rules are ap-plied recursively to achieve further compression anda transformation in the phrase constituency.Paraphrases are created from source sentenceparse trees by applying suitable rules recursively.Suitable rules have matching structure in terms ofphrase and dependency label, for both the parent andchild nodes.
Additionally, the proposed paraphrasesub-tree must be suitable for the target tree beingcreated (i.e., the root node of the paraphrase mustmatch the phrase and dependency label of the corre-sponding node in the target tree).
Where more thanone paraphrase is possible, the alternatives are incor-porated into the target parse tree under a CHOICEnode, as is shown in Figure 2.
Note that unlike pre-516vious QG approaches, we do not use the probabilitymodel proposed by Smith and Eisner (2006); insteadthe QG is used to represent rewrite operations, andwe simply record a frequency count for how ofteneach rule is encountered in the training data.3.3 ILP modelThe objective of our model is to create the most in-formative text possible, subject to constraints whichcan be tailored to the specific task.
These relate tosentence length, overall summary length, the inclu-sion of specific topics, and grammaticality.
Theseconstraints are global in their scope, and cannot beadequately satisfied by optimizing each one of themindividually.
Our approach therefore uses an ILPformulation which will provide a globally optimalsolution, and which can be efficiently solved usingstandard optimization tools.
Specifically, the modelselects phrases and paraphrases from which to formthe output sentence.
Here, we focus on a singlesentence as this is most appropriate for title gener-ation.
However, multi-sentence output can be easilygenerated by setting a summary length constraint.The model operates over the merged phrase struc-ture trees described in Section 3.1, augmented withparaphrase choice nodes such as shown in Figure 2rather than raw text.Let S be the set of sentences in a document, P bethe set of phrases, and Ps ?
P be the set of phrasesin each sentence s ?
S .
Let the sets Di ?
P , ?i ?
Pcapture the phrase dependency information for eachphrase i, where each set Di contains the phrases thatdepend on the presence of i.
In a similar fashion,C ?
P is the set of choice nodes throughout the doc-ument, which represent nodes in the tree where morethan one QG rule can be applied; Ci ?
P , i ?
C arethe sets of phrases that are direct children of eachchoice node, in other words they are the individualalternative paraphrases.
Let li be the length of eachphrase i, in tokens.For caption generation, the model has as addi-tional input a list of tags (keywords drawn from thesource document) that correspond to the image, andwe refer to this set of tags as T .
Pt ?
P is the set ofphrases containing the tag t ?
T .
We use the proba-bilistic image annotation model of Feng and Lapata(2010a) to generate the list of keywords.
The lat-ter highlight the objects depicted in the image andshould be in all likelihood included in the caption.The model is cast as an integer linear program:maxx ?i?P( fi +?gi)xi (1a)s.t.
?i?Plixi ?
Lmax (1b)?i?Plixi ?
Lmin (1c)?i?Pt ,t?Txi ?
Tmin (1d)x j?
xi ?i ?
P , j ?Di (1e)?j?Cix j = xi ?i ?
C , j ?
Ci (1f)xi?
ys ?s ?
S , i ?
Ps (1g)?s?Sys ?
NS (1h)xi ?
{0,1} ?i ?
P (1i)ys ?
{0,1} ?s ?
S .
(1j)A vector of binary variables x?
{0,1}|P | indicatesif each phrase is to be part of the output.
The vectorof auxiliary binary variables y ?
{0,1}|S | indicatesfrom which sentences the chosen phrases come, seeEquation (1g).Our objective function (1a) is the weighted sum oftwo components for each phrase: a salience score,and a measure of how frequently the QG rule wasseen in the training data.
Let fi denote the saliencescore for phrase i, determined by the machine learn-ing algorithm.
We apply a paraphrase penalty gi toeach phrase,gi = log(nrNr),where nr is a count of the number of times this par-ticular QG rule r was seen in the training data, andNr is the number of times all suitable rules for thisphrase node were seen.
If no suitable rules exist,we set gi = 0.
The intuition here is that commonparaphrases should be more trustworthy, and thusare given a smaller penalty than rare ones.
Para-phrase penalties are weighted by the constant param-eter ?.
which controls the amount of paraphrasingwe allow in the output.
The objective function isthe sum of the salience scores and paraphrase penal-ties of all the phrases chosen to form the output of agiven document, subject to the constraints in Equa-517tions (1b)?(1j).
The latter provide a natural way ofdescribing the requirements the output must meet.Constraints (1b) and (1c) ensure that the gener-ated output stays within the acceptable length rangeof (Lmin,Lmax) tokens.
Equation (1d) is a set-covering constraint, requiring that at least Tmin wordsin T appear in the output.
This is important wherewe want to focus on some aspect of the source doc-ument, for instance on the subject of an image.Constraint (1e) ensures that the phrase dependen-cies are respected and thus enforces grammaticalcorrectness.
Phrases that depend on phrase i are con-tained in the set Di.
Variable xi is true, and thereforephrase i will be included, if any of its dependentsx j ?Di are true.
The phrase dependency constraints,contained in the set Di and enforced by (1e), are theresult of three principles based on the typed depen-dency information:1.
Where the QG provides alternative para-phrases, it makes sense of course to select onlyone.
This is controlled by constraint (1f), andby placing all paraphrases in the set Di for thechoice node i.2.
Where there are no applicable QG rules toguide the model, in general we require all childnodes j of the current node i to be included inthe summary if node i is included.
As excep-tions, we allow the subtree represented by nodej to be deleted if the dependency label for theconnecting edge i?
j is of type advcl (adver-bial clause) or some form of conj (conjunction).3.
In general, we force the parent node p of thecurrent node i to be included in the output if iis, resulting in all ancestors up to the root nodebeing included.
We allow a break, and the sub-tree at i to be used as a stand-alone sentence, ifthe PCFG parser has marked i with an S (sen-tence) label.Constraint (1g) tells the ILP to output a sentence ifone of its constituent phrases is chosen.
Finally, (1h)limits the output to a maximum of NS sentences.4 Experimental Set-upAs mentioned earlier we evaluated the performanceof our model on two title generation tasks, namelyheadline and caption generation.
In this section wegive details on the corpora and grammars we used,model parameters and features.
We also describe thebaselines used for comparison with our approach,and explain how system output was evaluated.Training We obtained phrase-based saliencescores using a supervised machine learning algo-rithm.
For the headline generation task, the fullDUC-03 (Task 1) corpus was used for training;it contains 500 documents and 4 headline-stylesummaries per document.
For the captions, trainingdata was gathered from the CNN news website.2We used 200 documents and their correspondingcaptions.
Sentences were first tokenized to separatewords and punctuation, and then parsed to obtainphrases and dependencies as described in Section 3using the Stanford parser (Klein and Manning,2003).
Document phrases were marked as positiveor negative automatically.
If there was a unigramoverlap (excluding stop words) between the phraseand any of the original title or caption, we markedthis phrase with a positive label.
Non-overlappingphrases were given negative labels.Our feature set comprised surface features such assentence and paragraph position information, POStags, and whether high-scoring tf.idf words werepresent in the phrase.
Additionally, the caption train-ing set contained features for unigram and bigramoverlap with the title.
We learned the feature weightswith a linear SVM, using the software SVM-OOPS(Woodsend and Gondzio, 2009).
This tool gave usdirectly the feature weights as well as support vec-tor values, and it allowed different penalties to beapplied to positive and negative misclassifications,enabling us to compensate for the unbalanced dataset.
The penalty hyper-parameters chosen were theones that gave the best F-scores, using 10-fold vali-dation.For each of the two tasks, QG rules were extractedfrom the same data used to train the SVM, resultingin 2,910 distinct rules for headlines and 2,757 rulesfor the captions.
Table 1 shows that for both tasks,the majority of rules apply to PP and NP phrases.Both tasks involve considerable compression, butthe proportions of the rewrite operations involved in-dicate differences in style between them.
Compared2See http://edition.cnn.com/.518Label Prop?n Proportion for Labelof set Unmod Del Ins Re-ordPP 40% 5% 93% 12% 6%NP 31% 5% 87% 14% 7%S 20% 1% 96% 15% 7%SBAR 6% 4% 95% 28% 6%(a) HeadlinesLabel Prop?n Proportion for Labelof set Unmod Del Ins Re-ordPP 30% 17% 81% 7% 4%NP 29% 17% 76% 11% 3%S 27% 10% 84% 16% 6%SBAR 10% 13% 80% 16% 3%(b) CaptionsTable 1: QG rules generated for (a) headline and(b) caption tasks (top 4 labels shown).
The columnsshow label of root node, proportion of the full rule-set, then the proportions of rules for this label in-volving no modification, deletions, insertions andre-orderings.to headlines, captions involve slightly less deletionand a higher proportion of the phrases are unmod-ified.
The QG learning mechanism also discoversmore alignments between source sentences and cap-tions than it does for the headline task.Title generation For the headline generation task,we evaluated our model on a testing partition fromthe DUC-04 corpus (75 documents, Task 1).
For thecaption task, we used the test set (240 documents)described in Feng and Lapata (2010a).
Their corpuswas downloaded from the BBC news site and con-tains documents, images, and their captions.3We created and solved an ILP for each docu-ment.
For each phrase, features were extracted andsalience scores calculated from the feature weightsdetermined through SVM training.
The distancefrom the SVM hyperplane represents the saliencescore.
Parameters for the ILP models for the twotasks are shown in Table 2.
The ?
parameter wasset to 0.2 to ensure that paraphrases were included;other parameters were chosen to capture the prop-3Available from http://homepages.inf.ed.ac.uk/s0677528/data.html.Parameter Headlines CaptionsMin length Lmin 8 8Max length Lmax 16 20Min keywords Tmin 0 2Max sentences NS 5 1Paraphrase ?
0.2 0.1Table 2: ILP model parameters for the two tasks.erties seen in the majority of the training set.
Notethe maximum number of sentences allowed to forma headline is set to 5 as some of the headlines in theDUC dataset contained multiple sentences.To solve the ILP model we used the ZIB Opti-mization Suite software (Achterberg, 2007; Koch,2004).
The solution was converted into a sentenceby removing nodes not chosen from the tree rep-resentation, then concatenating the remaining leafnodes in order.Model Comparison For the headline task, wecompared our model to the DUC-04 standard base-line of the first sentence, truncated at the first wordboundary after 75 characters; and the output of theTopiary system (Zajic et al, 2004), which came topin almost all measures in the DUC-04 evaluation.In order to generate a headline, Topiary first com-presses the lead sentence using linguistically moti-vated heuristics and then enhances it with topic key-words.
For the captions, we compared our modelagainst the highest-scoring document sentence ac-cording to the SVM and against the probabilisticmodel presented in Feng and Lapata (2010a).
Thelatter estimates the probability of a phrase appear-ing in the caption given the same phrase appearingin the corresponding document and uses a languagemodel to select among many different surface real-izations.
The language model is adapted with prob-abilities from an image annotation model (Feng andLapata, 2010b).Evaluation We evaluated the quality of the head-lines using ROUGE (Lin and Hovy, 2003).
TheDUC-04 dataset provides four reference head-lines per document.
We report unigram overlap(ROUGE-1) and bigram overlap (ROUGE-2) as ameans of assessing informativeness, and the longestcommon subsequence (ROUGE-L) as a means of as-519sessing fluency.
Original DUC-04 ROUGE parame-ters were used.
We also use ROUGE to evaluate theautomatic captions with the original BBC captionsas reference.In addition, we evaluated the generated headlinesby eliciting human judgments.
Participants werepresented with a news article and its correspond-ing headline and were asked to rate the latter alongtwo dimensions: informativeness (does the headlinecapture the article?s most important information?
),and grammaticality (is it fluent and easy to under-stand?).
The subjects used a seven point rating scale;an ideal system would receive high numbers forboth measures.
We randomly selected twelve docu-ments from the test set and generated headlines withour model.
We also included the output of Topiaryand the human written DUC-04 headlines as a goldstandard.
We thus obtained ratings for 48 (12 ?
4)document-highlights pairs.We elicited judgments for the generated captionsin a similar fashion.
Participants were presentedwith a document, an associated image, and its cap-tion, and asked to rate the latter (using a 1?7 ratingscale) with respect to grammaticality and informa-tiveness (does it describe succinctly the content ofthe image and document?).
Again, we randomly se-lected 12 document-image pairs from the test set andgenerated captions for them using the highest scor-ing document sentence according to the SVM, ourILP-based model, and the output of Feng and Lap-ata?s (2010a) system.
We also included the originalBBC captions as an upper bound.
Both studies wereconducted over the Internet using WebExp (Kelleret al, 2009).
80 unpaid volunteers rated the head-lines and 65 the captions, all self reported native En-glish speakers.5 ResultsWe report results on the headline generation task inFigure 3, with ROUGE-1, ROUGE-2 and ROUGE-L.
In ROUGE-1 and ROUGE-L measures, the bestscores are obtained by the Topiary system, slightlybetter than the lead sentence baseline, while forROUGE-2 the ordering is reversed.
Our model doesnot outperform the lead sentence or Topiary.
Notethat the 95% confidence level intervals reported byROUGE are so large that no results are statisticallyLead The chances for a new, strictly secular government inTurkey faded Wednesday.Topiary TURKEY YILMAZ PARTY ECEVIT chances strictlysecular government faded.ILP Bulent Ecevit needs Turkey?s two-center right parties tohammer together secular coalition.DUC Chance for new, secular, Turkish government fades; whatwill Ecevit do now?Source Premier-designate Bulent Ecevit needs Turkey?s two-center right parties to hammer together a secular coali-tion, but Tansu Ciller, the ex-premier who commands 99votes in parliament, rebuffed him Wednesday.Lead U.S. President Bill Clinton won South Korea?s supportSaturday for confronting.Topiary NUCLEAR U.S. President Bill Clinton won for con-fronting North Korea.ILP North Koreans have denied construction site has nuclearpurpose.DUC U.S. warns N. Korea not to waste chance for peace overalleged nuclear site.Source The North Koreans have denied the underground con-struction site has any nuclear purpose, and it has de-manded a dlrs 300 million payment for proving that.Lead By only one vote, the center-left prime minister of Italy,Romano Prodi.Topiary PRODI By only one vote center left prime minister andtoppled from power.ILP Political system changes, Italy is condemned to politicalinstability.DUC Prodi loses confidence vote; will stay as caretaker untilnew government.Source ?Unless the Italian political system changes, Italy is con-demned to political instability,?
said Sergio Romano, aformer diplomat and political science professor.Table 3: Example headline output.F&L The former paramedic training officer stood at the nextgeneral election.ILP The majority are now believing that war in Iraq waswrong.BBC L/Cpl Thomas Keys was shot 18 times, his inquest heard.Source The majority of people in this country are now believingthat the war in Iraq was wrong, and I do believe we willget support.F&L The state government of Victoria take as those tests forcannabis.ILP Police in Victoria have begun randomly testing drivers forthe drug ecstasy.BBC Police say drugs like Ecstasy can be as dangerous as al-cohol for drivers.Source Police in the Australian state of Victoria have begun ran-domly testing drivers for the drug ecstasy.F&L The US Government Professor Holdren called for morethan a year.ILP ?We are experiencing dangerous human disruption ofglobal climate,?
Professor Holdren said.BBC Sea levels could rise by 4m over the coming century, hewarns.Source ?We are experiencing dangerous human disruption of theglobal climate and we?re going to experience more,?
Pro-fessor Holdren said.Table 4: Example caption output.52000.050.10.150.20.250.3Lead-1 Topiary ILPScoreRouge-1Rouge-LRouge-2Figure 3: ROUGE-1, ROUGE-2 and ROUGE-L re-sults on the DUC-04 headlines for our ILP model,the lead sentence baseline and Topiary.00.050.10.150.2SVM F&L ILPScoreRouge-1Rouge-LRouge-2Figure 4: ROUGE-1, ROUGE-2 and ROUGE-L re-sults on the BBC captions for our ILP model, thesentence baseline chosen by the SVM, and Feng andLapata?s (2010) model.significant.
We also investigated using an ILP modelwith just the QG rules or just dependency label in-formation (see constraint (1e) in Section 3.3).
Bothsettings gave less compressed output, and the result-ing ROUGE scores were lower on all measures.
TheROUGE results for the caption generation task fol-low a similar pattern (see Figure 4).
Our model isslightly better than the best sentence baseline butperforms worse than Feng and Lapata (2010a).
Ta-bles 3 and 4 show example output for the ILP modeland the baselines on the headline and caption tasksrespectively.
In the tables, Source refers to the sen-tence chosen by the ILP, but before any paraphrasingis applied.
We can see that deletion rules dominate,and a more compressive style of paraphrasing hasbeen learned for the headline task.The results of our human evaluation study forthe DUC-04 headlines are summarized in Table 5.Means differences were compared using a Post-hocModel Grammaticality ImportanceLead-1 4.95 3.30Topiary 3.03 3.43ILP 5.36 4.94Reference 5.12 5.17Table 5: Average human ratings of DUC-04 head-lines, for our ILP model, the lead sentence baseline,the output of Topiary and the human-written refer-ence.Model Grammaticality ImportanceSVM 5.24 5.01F&L 4.42 4.74ILP 5.49 5.25Reference 5.61 5.18Table 6: Average human ratings of captions, forour ILP model, the sentence baseline chosen by theSVM, Feng and Lapata?s (2010) model and the ref-erence BBC caption.Tukey test.
The headlines created by our modelwere considered significantly more important andmore grammatical than those of the Topiary sys-tem (?
< 0.01), despite the better overlap of Topi-ary with the reference headlines as indicated in theRouge results above.
Compared to the lead sentenceof the article (the DUC-04 baseline), our model wasalso rated significantly higher in terms of importance(?
< 0.01) but not grammaticality.Table 6 summarizes the results of our secondjudgment elicitation study.
The captions generatedby our model are significantly more grammaticalthan those of Feng and Lapata (2010a) (?
< 0.01).The SVM, ILP model and reference captions do notdiffer significantly in terms of grammaticality.
Interms of importance, the ILP model is significantlybetter than the SVM (?
< 0.01) and Feng and Lap-ata (?
< 0.01) and comparable to the reference.The human ratings are more favorable to ourmodel than ROUGE for both tasks.
There are tworeasons for this.
Firstly, the model is not bi-ased towards selecting the lead sentence as a head-line/caption and is disadvantaged in ROUGE evalua-tions as professional abstractors often reuse the leador parts of it to create a title.
Secondly, the modeloften generates an appropriate title that is lexically521distinct from the reference even though it expressessimilar meaning.6 ConclusionsIn this paper we proposed a joint content se-lection and surface realization model for single-document summarization.
The model operates overa syntax-rich representation of the source docu-ment and learns which phrases should be in thesummary.
Content selection preferences are cou-pled with a quasi-synchronous grammar whose rulesencode surface realization preferences (e.g., para-phrases and compressions).
Both types of prefer-ences are optimized simultaneously in an integer lin-ear program subject to grammaticality, length andcoverage constraints.
Importantly, the QG allowsthe model to adapt to the writing and stylistic con-ventions of different tasks.
The results of our hu-man studies show that our system creates grammati-cal and informative summaries whilst outperformingseveral competitive baselines.The model itself is relatively simple and achievesgood performance without any task-specific modifi-cation.
One potential stumbling block may be theavailability of parallel data for acquiring the QG.The Internet provides a large repository of newsdocuments with headlines, images and captions.
Insome cases news articles are even accompanied with?story highlights?
which could be used as trainingdata for longer summaries.4 For other domains ob-taining such data may be more difficult.
However,our experiments have shown that relatively smallparallel corpora (in the range of 200?500 pairs) suf-fice to learn many of the writing conventions for agiven task.In the future, we plan to explore how to inte-grate more sophisticated QG rules in the generationprocess.
Currently we consider deletions, reorder-ings and insertions.
Ideally, we would also like tomodel arbitrary substitutions between words but alsolarger constituents (e.g., subclauses, sentence aggre-gation).
Beyond summarization, we would also liketo apply our model to other generation tasks, such asparaphrasing and text simplification.4On-line CNN news articles are prefaced by storyhighlights?three or four short sentences that are written by hu-mans and give a brief overview of the article.Acknowledgments We are grateful to David Chi-ang and Noah Smith for their input on earlier ver-sions of this work.
We would also like to thankAndreas Grothey and members of ICCS at theSchool of Informatics for valuable discussions andcomments.
We acknowledge the support of EP-SRC through project grants EP/F055765/1 andGR/T04540/01.ReferencesAchterberg, Tobias.
2007.
Constraint Integer Program-ming.
Ph.D. thesis, Technische Universita?t Berlin.Banko, Michele, Vibhu O. Mittal, and Michael J. Wit-brock.
2000.
Headline generation based on statisti-cal translation.
In Proceedings of the 38th ACL.
HongKong, pages 318?325.Clarke, James and Mirella Lapata.
2008.
Global infer-ence for sentence compression: An integer linear pro-gramming approach.
Journal of Artificial IntelligenceResearch 31:399?429.Cohn, Trevor and Mirella Lapata.
2008.
Sentence com-pression beyond word deletion.
In Proceedings of the22nd COLING.
Manchester, UK, pages 137?144.Das, Dipanjan and Noah A. Smith.
2009.
Paraphraseidentification as probabilistic quasi-synchronousrecognition.
In Proceedings of the ACL-IJCNLP.Suntec, Singapore, pages 468?476.Daume?
III, Hal.
2006.
Practical Structured LearningTechniques for Natural Language Processing.
Ph.D.thesis, University of Southern California.Daume?
III, Hal and Daniel Marcu.
2002.
A noisy-channelmodel for document compression.
In Proceedings ofthe 40th ACL.
Philadelphia, PA, pages 449?456.Dorr, Bonnie, David Zajic, and Richard Schwartz.2003.
Hedge trimmer: A parse-and-trim approachto headline generation.
In Proceedings of the HLT-NAACL 2003 Text Summarization Workshop and Doc-ument Understanding Conference.
Edmondon, Al-berta, pages 1?8.Dras, Mark.
1999.
Tree Adjoining Grammar and the Re-luctant Paraphrasing of Text.. Ph.D. thesis, MacquarieUniversity.Feng, Yansong and Mirella Lapata.
2010a.
How manywords is a picture worth?
Automatic caption gener-ation for news images.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics.
Association for Computational Linguis-tics, Uppsala, Sweden, pages 1239?1249.Feng, Yansong and Mirella Lapata.
2010b.
Topic mod-els for image annotation and text illustration.
In Pro-522ceedings of the NAACL HLT .
Association for Com-putational Linguistics, Los Angeles, California, pages831?839.Jing, Hongyan.
2000.
Sentence reduction for automatictext summarization.
In Proceedings of the 6th ANLP.Seattle, WA, pages 310?315.Jing, Hongyan.
2002.
Using hidden Markov modeling todecompose human-written summaries.
ComputationalLinguistics 28(4):527?544.Jing, Hongyan and Kathleen McKeown.
2000.
Cutand paste summarization.
In Proceedings of the 1stNAACL.
Seattle, WA, pages 178?185.Keller, Frank, Subahshini Gunasekharan, Neil Mayo, andMartin Corley.
2009.
Timing accuracy of web experi-ments: A case study using the WebExp software pack-age.
Behavior Research Methods 41(1):1?12.Klein, Dan and Christopher D. Manning.
2003.
Accurateunlexicalized parsing.
In Proceedings of the 41st ACL.Sapporo, Japan, pages 423?430.Koch, Thorsten.
2004.
Rapid Mathematical Prototyping.Ph.D.
thesis, Technische Universita?t Berlin.Kupiec, Julian, Jan O. Pedersen, and Francine Chen.1995.
A trainable document summarizer.
In Proceed-ings of SIGIR-95.
Seattle, WA, pages 68?73.Lin, Chin-Yew.
2003.
Improving summarization perfor-mance by sentence compression ?
a pilot study.
InProceedings of the 6th International Workshop on In-formation Retrieval with Asian Languages.
Sapporo,Japan, pages 1?8.Lin, Chin-Yew and Eduard H. Hovy.
2003.
Automaticevaluation of summaries using n-gram co-occurrencestatistics.
In Proceedings of HLT NAACL.
Edmonton,Canada, pages 71?78.Martins, Andre?
and Noah A. Smith.
2009.
Summariza-tion with a joint model for sentence extraction andcompression.
In Proceedings of the Workshop on In-teger Linear Programming for Natural Language Pro-cessing.
Boulder, Colorado, pages 1?9.Smith, David and Jason Eisner.
2006.
Quasi-synchronousgrammars: Alignment by soft projection of syntacticdependencies.
In Proceedings on the Workshop on Sta-tistical Machine Translation.
Association for Compu-tational Linguistics, New York City, pages 23?30.Smith, David A. and Jason Eisner.
2009.
Parser adapta-tion and projection with quasi-synchronous grammarfeatures.
In Proceedings of the EMNLP.
Suntec, Sin-gapore, pages 822?831.Soricut, R. and D. Marcu.
2007.
Abstractive head-line generation using WIDL-expressions.
InformationProcessing and Management 43(6):1536?1548.
TextSummarization.Wang, Mengqiu, Noah A. Smith, and Teruko Mita-mura.
2007.
What is the Jeopardy model?
a quasi-synchronous grammar for QA.
In Proceedings of theEMNLP-CoNLL.
Prague, Czech Republic, pages 22?32.Woodsend, Kristian and Jacek Gondzio.
2009.
Exploitingseparability in large-scale linear support vector ma-chine training.
Computational Optimization and Ap-plications Published online.Woodsend, Kristian and Mirella Lapata.
2010.
Automaticgeneration of story highlights.
In Sandra Carberry andStephen Clark, editors, Proceedings of the 48th ACL.Uppsala, Sweden, pages 565?574.Zajic, David, Bonnie Dorr, and Richard Schwartz.
2004.BBN/UMD at DUC-2004: Topiary.
In Proceedingsof the NAACL Workshop on Document Understanding.Boston, MA, pages 112?119.Zajic, David, Bonnie J. Dorr, Jimmy Lin, and RichardSchwartz.
2007.
Multi-candidate reduction: Sentencecompression as a tool for document summarizationtasks.
Information Processing Management Special Is-sue on Summarization 43(6):1549?1570.Zhao, Shiqi, Xiang Lan, Ting Liu, and Sheng Li.
2009.Application-driven statistical paraphrase generation.In Proceedings of the Joint Conference of the 47thAnnual Meeting of the ACL and the 4th InternationalJoint Conference on Natural Language Processing ofthe AFNLP.
Suntec, Singapore, pages 834?842.523
