The GOD modelAlfio Massimiliano GliozzoITC-irstTrento, Italygliozzo@itc.itAbstractGOD (General Ontology Discovery) is anunsupervised system to extract semanticrelations among domain specific entitiesand concepts from texts.
Operationally,it acts as a search engine returning a setof true predicates regarding the query in-stead of the usual ranked list of relevantdocuments.
Our approach relies on twobasic assumptions: (i) paradigmatic rela-tions can be established only among termsin the same Semantic Domain an (ii) theycan be inferred from texts by analyzing theSubject-Verb-Object patterns where twodomain specific terms co-occur.
A quali-tative analysis of the system output showsthat GOD provide true, informative andmeaningful relations in a very efficientway.1 IntroductionGOD (General Ontology Discovery) is an un-supervised system to extract semantic relationsamong domain specific entities and concepts fromtexts.
Operationally, it acts as a search engine re-turning a set of true predicates regarding the queryinstead of the usual ranked list of relevant docu-ments.
Such predicates can be perceived as a setof semantic relations explaining the domain of thequery, i.e.
a set of binary predicated involving do-main specific entities and concepts.
Entities andconcepts are referred to by domain specific terms,and the relations among them are expressed by theverbs of which they are arguments.To illustrate the functionality of the system, be-low we report an example for the query God.god:lord hear prayergod is creatorgod have mercyfaith reverences godlord have mercyjesus_christ is godgod banishing himgod commanded israelitesgod was trinityabraham believed godgod requires abrahamgod supply human_needgod is holynoah obeyed godFrom a different perspective, GOD is first of alla general system for ontology learning from texts(Buitelaar et al, 2005).
Likewise current state-of-the-art methodologies for non-hierarchical re-lation extraction it exploits shallow parsing tech-niques to identify syntactic patterns involving do-main specific entities (Reinberger et al, 2004),and statistical association measures to detect rel-evant relations (Ciaramita et al, 2005).
In con-trast to them, it does not require any domain spe-cific collection of texts, allowing the user to de-scribe the domain of interest by simply typingshort queries.
This feature is of great advantagefrom a practical point of view: it is obviously moreeasy to formulate short queries than to collect hugeamounts of domain specific texts.Even if, in principle, an ontology is supposed torepresent a domain by a hierarchy of concepts andentities, in this paper we concentrate only on thenon-hyrarchical relation extraction process.
In ad-dition, in this work we do not address the problemof associating synonyms to the same concept (e.g.god and lord in the example above).147In this paper we just concentrate on describ-ing our general framework for ontology learning,postponing the solution of the already mentionedproblems.
The good quality of the results and thewell foundedness of the GOD framework motivateour future work.2 The GOD algorithmThe basic assumption of the GOD model is thatparadigmatic relations can be established onlyamong terms in the same Semantic Domain, whileconcepts belonging to different fields are mainlyunrelated (Gliozzo, 2005).
Such relations canbe identified by considering Subject-Verb-Object(SVO) patterns involving domain specific terms(i.e.
syntagmatic relations).When a query Q = (q1, q2, .
.
.
, qn) is formu-lated, GOD operates as follows:Domain Discovery Retrieve the ranked listdom(Q) = (t1, t2, .
.
.
, tk) of domain spe-cific terms such that sim(ti, Q) > ?
?, wheresim(Q, t) is a similarity function capturingdomain proximity and ??
is the domainspecificity threshold.Relation Extraction For each SVO pattern in-volving two different terms ti ?
dom(Q) andtj ?
dom(Q) such that the term ti occurs inthe subject position and the term tj occurs inthe object position return the relation tivtj ifscore(ti, v, tj) > ??
?, where score(ti, v, tj)measures the syntagmatic association amongti, v and tj .In Subsection 2.1 we describe into details theDomain Discovery step.
Subsection 2.2 is aboutthe relation extraction step.2.1 Domain DiscoverySemantic Domains (Magnini et al, 2002) are clus-ters of very closely related concepts, lexicalizedby domain specific terms.
Word senses are de-termined and delimited only by the meanings ofother words in the same domain.
Words belongingto a limited number of domains are called domainwords.
Domain words can be disambiguated bysimply identifying the domain of the text.As a consequence, concepts belonging to dif-ferent domains are basically unrelated.
This ob-servation is crucial from a methodological pointof view, allowing us to perform a large scale struc-tural analysis of the whole lexicon of a language,otherwise computationally infeasible.
In fact, re-stricting the attention to a particular domain is away to reduce the complexity of the overall rela-tion extraction task, that is evidently quadratic inthe number of terms.Domain information can be expressed by ex-ploiting Domain Models (DMs) (Gliozzo et al,2005).
A DM is represented by a k ?
k?
rectan-gular matrix D, containing the domain relevancefor each term with respect to each domain, wherek is the cardinality of the vocabulary, and k?
is thesize of the Domain Set.DMs can be acquired from texts in a totallyunsupervised way by exploiting a lexical coher-ence assumption (Gliozzo, 2005).
To this aim,term clustering algorithms can be adopted: eachcluster represents a Semantic Domain.
The de-gree of association among terms and clusters, es-timated by the learning algorithm, provides a do-main relevance function.
For our experiments weadopted a clustering strategy based on Latent Se-mantic Analysis, following the methodology de-scribed in (Gliozzo, 2005).
This operation is doneoff-line, and can be efficiently performed on largecorpora.
To filter out noise, we considered onlythose terms having a frequency higher than 5 inthe corpus.Once a DM has been defined by the matrix D,the Domain Space is a k?
dimensional space, inwhich both texts and terms are associated to Do-main Vectors (DVs), i.e.
vectors representing theirdomain relevances with respect to each domain.The DV ~t?i for the term ti ?
V is the ith row of D,where V = {t1, t2, .
.
.
, tk} is the vocabulary ofthe corpus.
The similarity among DVs in the Do-main Space is estimated by means of the cosineoperation.When a query Q = (q1, q2, .
.
.
, qn) is formu-lated, its DV ~Q?
is estimated by~Q?
=n?j=1~q?j (1)and then compared to the DVs of each term ti ?
Vby adopting the cosine similarity metricsim(ti, Q) = cos(~t?i, ~Q?)
(2)where ~t?i and ~q?j are the DVs for the terms ti andqj , respectively.All those terms whose similarity with the queryis above the domain specificity threshold ??
are148then returned as an output of the function dom(Q).Empirically, we fixed this threshold to 0.5.
In gen-eral, the higher the domain specificity threshold,the higher the relevance of the discovered relationsfor the query (see Section 3), increasing accuracywhile reducing recall.
In the previous example,dom(god) returns the terms lord, prayer, creatorand mercy, among the others.2.2 Relation extractionAs a second step, the system analyzes all the syn-tagmatic relations involving the retrieved entities.To this aim, as an off-line learning step, the sys-tem acquires Subject-Verb-Object (SVO) patternsfrom the training corpus by using regular expres-sions on the output of a shallow parser.In particular, GOD extracts the relations tivtjfor each ordered couple of domain specific terms(ti, tj) such that ti ?
dom(Q), tj ?
dom(Q)and score(ti, v, tj) > ???.
The confidence scoreis estimated by adopting the heuristic confidencemeasure described in (Reinberger et al, 2004), re-ported below:score(ti, v, tj) =F (ti,v,tj)min(F (ti),F (tj))F (ti,v)F (ti) +F (v,tj)F (tj)(3)where F (t) is the frequency of the term t in thecorpus, F (t, v) is the frequency of the SV patterninvolving both t and v, F (v, t) is the frequencyof the VO pattern involving both v and t, andF (ti, v, tj) is the frequency of the SVO pattern in-volving ti, v and tj .
In general, augmenting ???
is away to filter out noisy relations, while decreasingrecall.It is important to remark here that all the ex-tracted predicates occur at least once in the corpus,then they have been asserted somewhere.
Even ifit is not a sufficient condition to guarantee theirtruth, it is reasonable to assume that most of thesentences in texts express true assertions.The relation extraction process is performed on-line for each query, then efficiency is a crucial re-quirement in this phase.
It would be preferableto avoid an extensive search of the required SVOpatterns, because the number of sentences in thecorpus is huge.
To solve this problem we adoptedan inverted relation index, consisting of three hashtables: the SV(VO) table report, for each term,the frequency of the SV(VO) patterns where it oc-curs as a subject(object); the SVO table reports,for each ordered couple of terms in the corpus,the frequency of the SVO patterns in which theyco-occur.
All the information required to estimateFormula 3 can then be accessed in a time propor-tional to the frequencies of the involved terms.
Ingeneral, domain specific terms are not very fre-quent in a generic corpus, allowing a fast compu-tation in most of the cases.3 EvaluationPerforming a rigorous evaluation of an ontologylearning process is not an easy task (Buitelaar etal., 2005) and it is outside the goals of this paper.Due to time constraints, we did not performed aquantitative and objective evaluation of our sys-tem.
In Subsection 3.1 we describe the data andthe NLP tools adopted by the system.
In Subsec-tion 3.2 we comment some example of the systemoutput, providing a qualitative analysis of the re-sults after having proposed some evaluation guide-lines.
Finally, in Subsection 3.3 we discuss issuesrelated to the recall of the system.3.1 Experimental SettingsTo expect high coverage, the system would betrained on WEB scale corpora.
On the other hand,the analysis of very large corpora needs efficientpreprocessing tools and optimized memory allo-cation strategies.
For the experiments reported inthis paper we adopted the British National Cor-pus (BNC-Consortium, 2000), and we parsed eachsentence by exploiting a shallow parser on the out-put of which we detected SVO patterns by meansof regular expressions1.3.2 AccuracyOnce a query has been formulated, and a set ofrelations has been extracted, it is not clear how toevaluate the quality of the results.
The first fourcolumns of the example below show the evaluationwe did for the query Karl Marx.Karl Marx:TRIM economic_organisation determines superstructureTRUM capitalism needs capitalistsFRIM proletariat overthrow bourgeoisieTRIM marx understood capitalism??
?E marx later marxistsTRIM labour_power be productionTRIM societies are class_societies?RIM private_property equals exploitationTRIM primitive_societies were classlessTRIM social_relationships form economic_basisTRIM max_weber criticised marxist_view1For the experiments reported in this paper we used amemory-based shallow parser developed at CNTS Antwerpand ILK Tilburg (Daelemans et al, 1999) together with a setof scripts to extract SVO patterns (Reinberger et al, 2004)kindly put at our disposal by the authors.149TRIM contradictions legitimizes class_structure?R?E societies is political_level?R?E class_society where false_consciousness?RUE social_system containing such_contradictionsTRIM human_societies organizing productionSeveral aspects are addressed: truthfulness (i.e.True vs. False in the first column), relevancefor the query (i.e.
Relevant vs. Not-relevant inthe second column), information content (i.e.
In-formative vs. Uninformative, third column) andmeaningfulness (i.e.
Meaningful vs. Error, fourthcolumn).
For most of the test queries, the majorityof the retrieved predicates were true, relevant, in-formative and meaningful, confirming the qualityof the acquired DM and the validity of the relationextraction technique2.From the BNC, GOD was able to extract goodquality information for many different queries invery different domains, as for example music,unix, painting and many others.3.3 RecallAn interesting aspect of the behavior of the systemis that if the domain of the query is not well rep-resented in the corpus, the domain discovery stepretrieves few domain specific terms.
As a conse-quece, just few relations (and sometimes no re-lations) have been retrieved for most of our testqueries.
An analysis of such cases showed that thelow recall was mainly due to the low coverage ofthe BNC corpus.
We believe that this problem canbe avoided by training the system on larger scalecorpora (e.g.
from the Web).4 Conclusion and future workIn this paper we reported the preliminary resultswe obtained from the development of GOD, asystem that dynamically acquires ontologies fromtexts.
In the GOD model, the required domain isformulated by typing short queries in an Informa-tion Retrieval style.
The system is efficient andaccurate, even if the small size of the corpus pre-vented us from acquiring domain ontologies formany queries.
For the future, we plan to evaluatethe system in a more rigorous way, by contrast-ing its output to hand made reference ontologiesfor different domains.
To improve the coverage ofthe system, we are going to train it on WEB scale2It is worthwhile to remark here that evaluation stronglydepends on the point of view from which the query hasbeen formulated.
For example, the predicate private propertyequals exploitation is true in the Marxist view, while it is ob-viously false with respect to the present economic system.text collections and to explore the use of super-vised relation extraction techniques.
In addition,we are improving relation extraction by adoptinga more sophisticated syntactic analisys (e.g.
Se-matic Role Labeling).
Finally, we plan to explorethe usefulness of the extracted relations into NLPsystems for Question Answering, Information Ex-traction and Semantic Entailment.AcknowledgmentsThis work has been supported by the ONTOTEXTproject, funded by the Autonomous Province ofTrento under the FUP-2004 research program.Most of the experiments have been performedduring my research stage at the University ofAntwerp.
Thanks to Walter Daelemans and CarloStrapparava for useful suggestions and commentsand to Marie-Laure Reinberger for having pro-vided the SVO extraction scripts.ReferencesBNC-Consortium.
2000.
British national corpus.P.
Buitelaar, P. Cimiano, and B. Magnini.
2005.
On-tology learning from texts: methods, evaluation andapplications.
IOS Press.M.
Ciaramita, A. Gangemi, E. Ratsch, J. Saric, andI.
Rojas.
2005.
Unsupervised learning of seman-tic relations between concepts of a molecular biol-ogy ontology.
In In proceedings of IJCAI-05, Edim-burgh, Scotland.W.
Daelemans, S. Buchholz, and J. Veenstra.
1999.Memory-based shallow parsing.
In Proceedings ofCoNLL-99.A.
Gliozzo, C. Giuliano, and C. Strapparava.
2005.Domain kernels for word sense disambiguation.
InProceedings of ACL-05, pages 403?410, Ann Arbor,Michigan.A.
Gliozzo.
2005.
Semantic Domains in Compu-tational Linguistics.
Ph.D. thesis, University ofTrento.B.
Magnini, C. Strapparava, G. Pezzulo, andA.
Gliozzo.
2002.
The role of domain informationin word sense disambiguation.
Natural LanguageEngineering, 8(4):359?373.M.L.
Reinberger, P. Spyns, A. J. Pretorius, andW.
Daelemans.
2004.
Automatic initiation of an on-tology.
In Proceedings of ODBase?04, pages 600?617.
Springer-Verlag.150
