Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 25?30,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsExamining the Effect of Improved Context Sensitive Morphology onArabic Information RetrievalKareem Darwish Hany Hassan and Ossama EmamDept.
of Information Engineering & Technology IBM Technology Development CenterGerman University in Cairo P.O.
Box 1665th District, New Cairo, Cairo, Egypt El-Ahram, Giza, EgyptandIBM Technology Development Center{hanyh,emam}@eg.ibm.comP.O.
Box 166, El-Ahram, Giza, Egyptkareem@darwish.orgAbstractThis paper explores the effect ofimproved morphological analysis,particularly context sensitive morphology,on monolingual Arabic InformationRetrieval (IR).
It also compares the effectof context sensitive morphology to non-context sensitive morphology.
The resultsshow that better coverage and improvedcorrectness have a dramatic effect on IReffectiveness and that context sensitivemorphology further improves retrievaleffectiveness, but the improvement is notstatistically significant.
Furthermore, theimprovement obtained by the use ofcontext sensitive morphology over the useof light stemming was not significantlysignificant.1 IntroductionDue to the morphological complexity of the Arabiclanguage, much research has focused on the effectof morphology on Arabic Information Retrieval(IR).
The goal of morphology in IR is to conflatewords of similar or related meanings.
Severalearly studies suggested that indexing Arabic textusing roots significantly increases retrievaleffectiveness over the use of words or stems [1, 3,11].
However, all the studies used small testcollections of only hundreds of documents and themorphology in many of the studies was donemanually.Performing morphological analysis for Arabic IRusing existing Arabic morphological analyzers,most of which use finite state transducers [4, 12,13], is problematic for two reasons.
First, theywere designed to produce as many analyses aspossible without indicating which analysis is mostlikely.
This property of the analyzers complicatesretrieval, because it introduces ambiguity in theindexing phase as well as the search phase ofretrieval.
Second, the use of finite statetransducers inherently limits coverage, which thenumber of words that the analyzer can analyze, tothe cases programmed into the transducers.Darwish attempted to solve this problem bydeveloping a statistical morphological analyzer forArabic called Sebawai that attempts to rankpossible analyses to pick the most likely one [7].He concluded that even with ranked analysis,morphological analysis did not yield statisticallysignificant improvement over words in IR.
A laterstudy by Aljlayl et al on a large Arabic collectionof 383,872 documents suggested that lightlystemmed words, where only common prefixes andsuffixes are stripped from them, were perhapsbetter index term for Arabic [2].
Similar studies byDarwish [8] and Larkey [14] also suggested thatlight stemming is indeed superior to morphologicalanalysis in the context of IR.25However, the shortcomings of morphology mightbe attributed to issues of coverage and correctness.Concerning coverage, analyzers typically fail toanalyze Arabized or transliterated words, whichmay have prefixes and suffixes attached to themand are typically valuable in IR.
As forcorrectness, the presence (or absence) of a prefixor suffix may significantly alter the analysis of aword.
For example, for the word ?Alksyr?
isunambiguously analyzed to the root ?ksr?
and stem?ksyr.?
However, removing the prefix ?Al?introduces an additional analysis, namely to theroot ?syr?
and the stem ?syr.?
Perhaps suchambiguity can be reduced by using the context inwhich the word is mentioned.
For example, for theword ?ksyr?
in the sentence ?sAr ksyr?
(and hewalked like), the letter ?k?
is likely to be a prefix.The problem of coverage is practically eliminatedby light stemming.
However, light stemmingyields greater consistency without regard tocorrectness.
Although consistency is moreimportant for IR applications than linguisticcorrectness, perhaps improved correctness wouldnaturally yield great consistency.
Lee et al [15]adopted a trigram language model (LM) trained ona portion of the manually segmented LDC ArabicTreebank in developing an Arabic morphologysystem, which attempts to improve the coverageand linguistic correctness over existing statisticalanalyzers such as Sebawai [15].
The analyzer ofLee et al will be henceforth referred to as theIBM-LM analyzer.
IBM-LM's analyzer combinedthe trigram LM (to analyze a word within itscontext in the sentence) with a prefix-suffix filter(to eliminate illegal prefix suffix combinations,hence improving correctness) and unsupervisedstem acquisition (to improve coverage).
Lee et alreport a 2.9% error rate in analysis compared to7.3% error reported by Darwish for Sebawai [7].This paper evaluates the IBM-LM analyzer in thecontext of a monolingual Arabic IR application todetermine if in-context morphology leads toimproved retrieval effectiveness compared to out-of-context analysis.
To determine the effect ofimproved analysis, particularly the use of in-context morphology, the analyzer is used toproduce analyses of words in isolation (with nocontext) and in-context.
Since IBM-LM onlyproduces stems, Sebawai was used to produce theroots corresponding to the stems produced byIBM-LM.
Both are compared to Sebawai and lightstemming.The paper will be organized as follows:  Section 2surveys related work; Section 3 describes the IRexperimental setup for testing the IBM-LManalyzer; Section 4 presents experimental results;and Section 5 concludes the paper.2 Related WorkMost early studies of character-coded Arabic textretrieval relied on relatively small test collections[1, 3, 9, 11].
The early studies suggested thatroots, followed by stems, were the best index termsfor Arabic text.
More recent studies are based on asingle large collection (from TREC-2001/2002) [9,10].
The studies examined indexing using words,word clusters [14], terms obtained throughmorphological analysis (e.g., stems and roots [9]),light stemming [2, 8, 14], and character n-grams ofvarious lengths [9, 16].
The effects of normalizingalternative characters, removal of diacritics andstop-word removal have also been explored [6,19].
These studies suggest that perhaps lightstemming and character n-grams are the betterindex terms.Concerning morphology, some attempts weremade to use statistics in conjunction with rule-based morphology to pick the most likely analysisfor a particular word or context.
In most of theseapproaches an Arabic word is assumed to be of theform prefix-stem-suffix and the stem part may ormay not be derived from a linguistic root.
SinceArabic morphology is ambiguous, possiblesegmentations (i.e.
possible prefix-stem-suffixtuples) are generated and ranked based on theprobability of occurrence of prefixes, suffixes,stems, and stem template.
Such systems that usethis methodology include RDI?s MORPHO3 [5]and Sebawai [7].
The number of manually craftedrules differs from system to system.
FurtherMORPHO3 uses a word trigram model to improvein-context morphology, but uses an extensive set ofmanually crafted rules.
The IBM-LM analyzeruses a trigram language model with a minimal setof manually crafted rules [15].
Like otherstatistical morphology systems, the IBM-LManalyzer assumes that a word is constructed asprefix-stem-suffix.
Given a word, the analyzergenerates all possible segmentations by identifyingall matching prefixes and suffixes from a table of26prefixes and suffixes.
Then given the possiblesegmentations, the trigram language model score iscomputed and the most likely segmentation ischosen.
The analyzer was trained on a manuallysegmented Arabic corpus from LDC.3 Experimental DesignIR experiments were done on the LDCLDC2001T55 collection, which was used in theText REtrieval Conference (TREC) 2002 cross-language track.
For brevity, the collection isreferred to as the TREC collection.
The collectioncontains 383,872 articles from the Agence FrancePress (AFP) Arabic newswire.
Fifty topics weredeveloped cooperatively by the LDC and theNational Institute of Standards and Technology(NIST), and relevance judgments were developedat the LDC by manually judging a pool ofdocuments obtained from combining the top 100documents from all the runs submitted by theparticipating teams to TREC?s cross-languagetrack in 2002.
The number of known relevantdocuments ranges from 10 to 523, with an averageof 118 relevant documents per topic [17].
This ispresently the best available large Arabicinformation retrieval test collection.
The TRECtopic descriptions include a title field that brieflynames the topic, a description field that usuallyconsists of a single sentence description, and anarrative field that is intended to contain anyinformation that would be needed by a humanjudge to accurately assess the relevance of adocument [10].
Queries were formed from theTREC topics by combining the title anddescription fields.
This is intended to model thesort of statement that a searcher might initiallymake when asking an intermediary, such as alibrarian, for help with a search.Experiments were performed for the queries withthe following index terms:?
w:  words.?
ls:  lightly stemmed words, obtained using Al-Stem [17]1.?
SEB-s:  stems obtained using Sebawai.?
SEB-r:  roots obtained using Sebawai.1 A slightly modified version of Leah Larkey?s Light-10 lightstemmer [8] was also tried, but the stemmer produced verysimilar results to Al-Stem.?
cIBM-LMS:  stems obtained using the IBM-LM analyzer in context.
Basically, the entireTREC collection was processed by theanalyzer and the prefixes and suffixes in thesegmented output were removed.?
cIBM-SEB-r:  roots obtained by analyzing thein-context stems produced by IBM-LM usingSebawai.?
IBM-LMS:  stems obtained using the IBM-LManalyzer without any contextual information.Basically, all the unique words in thecollection were analyzed one by one and theprefixes and suffixes in the segmented outputwere removed.?
IBM-SEB-r:  roots obtained by analyzing theout-of-context stems produced by IBM-LMusing Sebawai.All retrieval experiments were performed using theLemur language modeling toolkit, which wasconfigured to use Okapi BM-25 term weightingwith default parameters and with and without blindrelevance feedback (the top 20 terms from the top5 retrieved documents were used for blindrelevance feedback).
To observe the effect ofalternate indexing terms mean uninterpolatedaverage precision was used as the measure ofretrieval effectiveness.
To determine if thedifference between results was statisticallysignificant, a Wilcoxon signed-rank test, which is anonparametric significance test for correlatedsamples, was used with p values less than 0.05 toclaim significance.4 Results and DiscussionFigure 1 shows a summary of the results fordifferent index terms.
Tables 1 and 2 showstatistical significance between different indexterms using the p value of the Wilcoxon test.When comparing index terms obtained using IBM-LM and Sebawai, the results clearly show thatusing better morphological analysis producesbetter retrieval effectiveness.
The dramaticdifference in retrieval effectiveness betweenSebawai and IBM-LM highlight the effect of errorsin morphology that lead to inconsistency inanalysis.
When using contextual information inanalysis (compared to analyzing words in isolation?
out of context) resulted in only a 3% increase inmean average precision when using stems (IBM-LMS), which is a small difference compared to the27effect of blind relevance feedback (about 6%increase) and produced mixed results when usingroots (IBM-SEB-r).
Nonetheless, the improvementfor stems was almost statistically significant with pvalues of 0.063 and 0.054 for the cases with andwithout blind relevance feedback.
Alsoconsidering that improvement in retrievaleffectiveness resulted from changing the analysisfor only 0.12% of the words in the collection (fromanalyzing them out of context to analyzing them incontext)2 and that the authors of IBM-LM reportabout 2.9% error rate in morphology, perhapsfurther improvement in morphology may lead tofurther improvement in retrieval effectiveness.However, further improvements in morphologyand retrieval effectiveness are likely to be difficult.One of difficulties associated with developingbetter morphology is the disagreement on whatconstitutes ?better?
morphology.
For example,should ?mktb?
and ?ktb?
be conflated?
?mktb?translates to office, while ktb translates to books.Both words share the common root ?ktb,?
but theyare not interchangeable in meaning or usage.
One2 Approximately 7% of unique tokens had two or more differ-ent analysis in the collection when doing in-context morphol-ogy.
In tokens with more than one analysis, one of theanalyses was typically used more than 98% of the time.would expect that increasing conflation wouldimprove recall at the expense of precision anddecreasing conflation would have the exactopposite effect.
It is known that IR is moretolerant of over-conflation than under-conflation[18].
This fact is apparent in the results whencomparing roots and stems.
Even though rootsresult in greater conflation than stems, the resultsfor stems and roots are almost the same.
Anotherproperty of IR is that IR is sensitive to consistencyof analysis.
In the case of light stemming,stemming often mistakenly removes prefixes andsuffixes leading to over conflation, for which IR istolerant, but the mistakes are done in a consistentmanner.
It is noteworthy that sensedisambiguation has been reported to decreaseretrieval effectiveness [18].
However, sinceimproving the correctness of morphologicalanalysis using contextual information is akin tosense disambiguation, the fact that retrieval resultsimproved, though slightly, using context sensitivemorphology is a significant result.In comparing the IBM-LM analyzer (in context orout of context) to light stemming (using Al-Stem),although the difference in retrieval effectiveness issmall and not statistically significant, using theIBM-LM analyzer, unlike using Al-Stem, leads toFigure 1.
Comparing index term with and without blind relevance feedback using mean averageprecision0.3080.3030.3200.2560.3180.3270.2970.3000.2170.2170.2870.2630.3190.3320.2670.2780.000.050.100.150.200.250.300.350.40w ls SEB-s SEB-r IBM-LMSIBM-SEB-rcIBM-LMScIBM-SEB-rIndex Termsno feedbackwith feedback28statistically significant improvement over usingwords.
Therefore there is some advantage, thoughonly a small one, to using statistical analysis overusing light stemming.
The major drawback tomorphological analysis (specially in-contextanalysis) is that it requires considerably morecomputing time than light stemming3.5 ConclusionThe paper investigated the effect of improvedmorphological analysis, especially contextsensitive morphology, in Arabic IR applicationscompared to other statistical morphologicalanalyzers and light stemming.
The results showthat improving morphology has a dramatic effecton IR effectiveness and that context sensitivemorphology slightly improved Arabic IR over non-context sensitive morphology, increasing IR3 The processing of the TREC collection using the in-contextIBM-LM required 16 hours on a 2.4 GHz Pentium 4 machinewith 1 Gigabyte of RAM compared to 10 minutes to performlight stemming.effectiveness by approximately 3%.
Theimprovement is almost statistically significant.Developing better morphology could lead togreater retrieval effectiveness, but improvinganalyzers is likely to be difficult and would requirecareful determination of the proper level ofconflation.
In overcoming some of the difficultiesassociated with obtaining ?better?
morphology (ormore fundamentally the proper level of wordconflation), adaptive morphology done on a perquery term basis or user feedback might provevaluable.
Also, the scores that were used to rankthe possible analyses in a statistical morphologicalanalyzer may prove useful in further improvingretrieval.
Other IR techniques, such as improvedblind relevance feedback or combination ofevidence approaches, can also improvemonolingual Arabic retrieval.Perhaps improved morphology is particularlybeneficial for other IR applications such as cross-language IR, in which ascertaining propertranslation of words is particularly important, andls SEB-s SEB-rIBM-LMSIBM-SEB-rcIBM-LMScIBM-SEB-r0.055 0.475 0.671 0.038 0.027 0.019 0.049 w0.004 0.023 0.560 0.359 0.946 0.505 ls0.633 0.005 0.001 0.001 0.012 SEB-s0.039 0.007 0.020 0.064 SEB-r0.0968 0.063 0.758IBM-LMS0.396 0.090IBM-SEB-r0.001cIBM-LMSTable 1.
Wilcoxon p values (shaded=significant) , with blind  relevance feedback.ls SEB-s SEB-rIBM-LMSIBM-SEB-rcIBM-LMScIBM-SEB-r0.261 0.035 0.065 0.047 0.135 0.011 0.016 w0.000 0.000 0.968 0.757 0.515 0.728 ls0.269 0.000 0.000 0.000 0.000 SEB-s0.000 0.000 0.000 0.000 SEB-r0.732 0.054 0.584IBM-LMS0.284 0.512IBM-SEB-r0.005cIBM-LMSTable 2.
Wilcoxon p values (shaded=significant) , without blind relevanc e feedback29in-document search term highlighting for displayto a user.References1.
Abu-Salem, H., M. Al-Omari, and M. Evens.Stemming Methodologies Over Individual QueryWords for Arabic Information Retrieval.
JASIS,1999.
50(6): p.  524-529.2.
Aljlayl, M., S. Beitzel, E. Jensen, A. Chowdhury, D.Holmes, M. Lee, D.  Grossman, and O. Frieder.
IITat TREC-10.
In TREC.
2001.
Gaithersburg, MD.3.
Al-Kharashi, I. and M Evens.
Comparing Words,Stems, and Roots as Index Terms in an ArabicInformation Retrieval System.
JASIS, 1994.
45(8): p.548 - 560.4.
Antworth, E. PC-KIMMO: a two-level processor formorphological analysis.
In Occasional Publicationsin Academic Computing.
1990.
Dallas, TX: SummerInstitute of Linguistics.5.
Ahmed, Mohamed Attia.
A Large-ScaleComputational Processor of the Arabic Morphology,and Applications.
A Master?s Thesis, Faculty ofEngineering, Cairo University, Cairo, Egypt, 2000.6.
Chen, A. and F. Gey.
Translation Term Weightingand Combining Translation Resources in Cross-Language Retrieval.
In TREC, 2001.
Gaithersburg,MD.7.
Darwish, K. Building a Shallow MorphologicalAnalyzer in One Day.
ACL Workshop onComputational Approaches to Semitic Languages.2002.8.
Darwish, K. and D. Oard.
CLIR Experiments atMaryland for  TREC 2002:   Evidence Combinationfor Arabic-English Retrieval.
In TREC.
2002.Gaithersburg, MD.9.
Darwish, K. and D. Oard.
Term Selection forSearching Printed Arabic.
SIGIR, 2002.
Tampere,Finland.
p. 261 - 268.10.
Gey, F. and D. Oard.
The TREC-2001 Cross-Language Information Retrieval Track: SearchingArabic Using English, French or Arabic Queries.TREC, 2001.
Gaithersburg, MD.
p. 16-23.11.
Hmeidi, I., G. Kanaan, and M. Evens.
Design andImplementation of Automatic Indexing forInformation Retrieval with Arabic Documents.JASIS, 1997.
48(10):  p. 867 - 881.12.
Kiraz, G. Arabic Computation Morphology in theWest.
In The 6th International  Conference andExhibition on Multi-lingual Computing.
1998.Cambridge.13.
Koskenniemi, K., Two Level Morphology:  AGeneral Computational Model for Word-formRecognition and Production.
1983, Department ofGeneral Linguistics, University of Helsinki.14.
Larkey, L., L. Ballesteros, and M. Connell.Improving Stemming for Arabic InformationRetrieval:  Light Stemming and Co-occurrenceAnalysis.
SIGIR 2002.  p. 275-282, 2002.15.
Lee, Y., K. Papineni, S. Roukos, O. Emam, and H.Hassan.
Language Model Based Arabic WordSegmentation.
In the Proceedings of the 41st AnnualMeeting of the Association for ComputationalLinguistics, July 2003, Sapporo, Japan.
p. 399 - 406.16.
Mayfield, J., P. McNamee, C. Costello, C. Piatko,and A. Banerjee.
JHU/APL at TREC 2001:Experiments in Filtering and in Arabic, Video, andWeb Retrieval.
In TREC 2001.
Gaithersburg, MD.
p.322-329.17.
Oard, D. and F. Gey.
The TREC 2002Arabic/English CLIR Track.
In TREC 2002.Gaithersburg, MD.18.
Sanderson, M.  Word sense disambiguation andinformation  retrieval.
In Proceedings  of the 17thACM SIGIR Conference, p. 142-151, 199419.
Xu, J., A. Fraser, and R. Weischedel.
2001 Cross-Lingual Retrieval at BBN.
In TREC, 2001.Gaithersburg, MD.
p. 68 - 75.30
