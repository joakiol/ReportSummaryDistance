Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 353?360,Sydney, July 2006. c?2006 Association for Computational LinguisticsSelection of Effective Contextual Informationfor Automatic Synonym AcquisitionMasato Hagiwara, Yasuhiro Ogawa, and Katsuhiko ToyamaGraduate School of Information Science,Nagoya UniversityFuro-cho, Chikusa-ku, Nagoya, JAPAN 464-8603{hagiwara, yasuhiro, toyama}@kl.i.is.nagoya-u.ac.jpAbstractVarious methods have been proposed forautomatic synonym acquisition, as syn-onyms are one of the most fundamen-tal lexical knowledge.
Whereas manymethods are based on contextual cluesof words, little attention has been paidto what kind of categories of contex-tual information are useful for the pur-pose.
This study has experimentally inves-tigated the impact of contextual informa-tion selection, by extracting three kinds ofword relationships from corpora: depen-dency, sentence co-occurrence, and prox-imity.
The evaluation result shows thatwhile dependency and proximity performrelatively well by themselves, combina-tion of two or more kinds of contextual in-formation gives more stable performance.We?ve further investigated useful selectionof dependency relations and modificationcategories, and it is found that modifi-cation has the greatest contribution, evengreater than the widely adopted subject-object combination.1 IntroductionLexical knowledge is one of the most important re-sources in natural language applications, making italmost indispensable for higher levels of syntacti-cal and semantic processing.
Among many kindsof lexical relations, synonyms are especially use-ful ones, having broad range of applications suchas query expansion technique in information re-trieval and automatic thesaurus construction.Various methods (Hindle, 1990; Lin, 1998;Hagiwara et al, 2005) have been proposed for syn-onym acquisition.
Most of the acquisition meth-ods are based on distributional hypothesis (Har-ris, 1985), which states that semantically similarwords share similar contexts, and it has been ex-perimentally shown considerably plausible.However, whereas many methods which adoptthe hypothesis are based on contextual clues con-cerning words, and there has been much consid-eration on the language models such as LatentSemantic Indexing (Deerwester et al, 1990) andProbabilistic LSI (Hofmann, 1999) and synonymacquisition method, almost no attention has beenpaid to what kind of categories of contextual infor-mation, or their combinations, are useful for wordfeaturing in terms of synonym acquisition.For example, Hindle (1990) used co-occurrences between verbs and their subjectsand objects, and proposed a similarity metricbased on mutual information, but no explorationconcerning the effectiveness of other kinds ofword relationship is provided, although it isextendable to any kinds of contextual information.Lin (1998) also proposed an information theory-based similarity metric, using a broad-coverageparser and extracting wider range of grammaticalrelationship including modifications, but he didn?tfurther investigate what kind of relationshipsactually had important contributions to acquisi-tion, either.
The selection of useful contextualinformation is considered to have a critical impacton the performance of synonym acquisition.
Thisis an independent problem from the choice oflanguage model or acquisition method, and shouldtherefore be examined by itself.The purpose of this study is to experimen-tally investigate the impact of contextual infor-mation selection for automatic synonym acqui-sition.
Because nouns are the main target of353synonym acquisition, here we limit the target ofacquisition to nouns, and firstly extract the co-occurrences between nouns and three categories ofcontextual information ?
dependency, sentenceco-occurrence, and proximity ?
from each ofthree different corpora, and the performance ofindividual categories and their combinations areevaluated.
Since dependency and modification re-lations are considered to have greater contribu-tions in contextual information and in the depen-dency category, respectively, these categories arethen broken down into smaller categories to ex-amine the individual significance.Because the consideration on the languagemodel and acquisition methods is not the scope ofthe current study, widely used vector space model(VSM), tf?idf weighting scheme, and cosine mea-sure are adopted for similarity calculation.
The re-sult is evaluated using two automatic evaluationmethods we proposed and implemented: discrimi-nation rate and correlation coefficient based on theexisting thesaurus WordNet.This paper is organized as follows: in Section2, three kinds of contextual information we useare described, and the following Section 3 explainsthe synonym acquisition method.
In Section 4 theevaluation method we employed is detailed, whichconsists of the calculation methods of referencesimilarity, discrimination rate, and correlation co-efficient.
Section 5 provides the experimental con-ditions and results of contextual information se-lection, followed by dependency and modificationselection.
Section 6 concludes this paper.2 Contextual InformationIn this study, we focused on three kinds of con-textual information: dependency between words,sentence co-occurrence, and proximity, that is, co-occurrence with other words in a window, detailsof which are provided the following sections.2.1 DependencyThe first category of the contextual information weemployed is the dependency between words in asentence, which we suppose is most commonlyused for synonym acquisition as the context ofwords.
The dependency here includes predicate-argument structure such as subjects and objectsof verbs, and modifications of nouns.
As the ex-traction of accurate and comprehensive grammat-ical relations is in itself a difficult task, the so-dependentmodncmod xmod cmod detmodarg_mod arg aux conjsubj_or_dobjsubjncsubj xsubj csubjcompobj clausalobj2dobj iobjxcomp ccompmodsubjobjFigure 1: Hierarchy of grammatical relations andgroupsphisticated parser RASP Toolkit (Briscoe and Car-roll, 2002) was utilized to extract this kind ofword relations.
RASP analyzes input sentencesand provides wide variety of grammatical infor-mation such as POS tags, dependency structure,and parsed trees as output, among which we paidattention to dependency structure called grammat-ical relations (GRs) (Briscoe et al, 2002).GRs represent relationship among two or morewords and are specified by the labels, which con-struct the hierarchy shown in Figure 1.
In this hier-archy, the upper levels correspond to more generalrelations whereas the lower levels to more specificones.
Although the most general relationship inGRs is ?dependent?, more specific labels are as-signed whenever possible.
The representation ofthe contextual information using GRs is as fol-lows.
Take the following sentence for example:Shipments have been relatively levelsince January, the Commerce Depart-ment noted.RASP outputs the extracted GRs as n-ary rela-tions as follows:(ncsubj note Department obj)(ncsubj be Shipment _)(xcomp _ be level)(mod _ level relatively)(aux _ be have)(ncmod since be January)(mod _ Department note)(ncmod _ Department Commerce)354(detmod _ Department the)(ncmod _ be Department)While most of GRs extracted by RASP are bi-nary relations of head and dependent, there aresome relations that contain additional slot or ex-tra information regarding the relations, as shown?ncsubj?
and ?ncmod?
in the above example.
Toobtain the final representation that we require forsynonym acquisition, that is, the co-occurrencebetween words and their contexts, these relation-ships must be converted to binary relations, i.e.,co-occurrence.
We consider the concatenation ofall the rest of the target word as context:Department ncsubj:note:*:objshipment ncsubj:be:*:_January ncmod:since:be:*Department mod:_:*:noteDepartment ncmod:_:*:CommerceCommerce ncmod:_:Department:*Department detmod:_:*:theDepartment ncmod:_:be:*The slot for the target word is replaced by ?*?
inthe context.
Note that only the contexts for nounsare extracted because our purpose here is the auto-matic extraction of synonymous nouns.2.2 Sentence Co-occurrenceAs the second category of contextual information,we used the sentence co-occurrence, i.e., whichsentence words appear in.
Using this context is,in other words, essentially the same as featuringwords with the sentences in which they occur.Treating single sentences as documents, this fea-turing corresponds to exploiting transposed term-document matrix in the information retrieval con-text, and the underlying assumption is that wordsthat commonly appear in the similar documents orsentences are considered semantically similar.2.3 ProximityThe third category of contextual information,proximity, utilizes tokens that appear in the vicin-ity of the target word in a sentence.
The basic as-sumption here is that the more similar the distri-bution of proceeding and succeeding words of thetarget words are, the more similar meaning thesetwo words possess, and its effectiveness has beenpreviously shown (Macro Baroni and Sabrina Bisi,2004).
To capture the word proximity, we considera window with a certain radius, and treat the la-bel of the word and its position within the windowas context.
The contexts for the previous examplesentence, when the window radius is 3, are then:shipment R1:haveshipment R2:beshipment R3:relativelyJanuary L1:sinceJanuary L2:levelJanuary L3:relativelyJanuary R1:,January R2:theJanuary R3:CommerceCommerce L1:theCommerce L2:,Commerce L3:JanuaryCommerce R1:Department...Note that the proximity includes tokens such aspunctuation marks as context, because we supposethey offer useful contextual information as well.3 Synonym Acquisition MethodThe purpose of the current study is to investigatethe impact of the contextual information selection,not the language model itself, we employed oneof the most commonly used method: vector spacemodel (VSM) and tf?idf weighting scheme.
In thisframework, each word is represented as a vectorin a vector space, whose dimensions correspondto contexts.
The elements of the vectors given bytf?idf are the co-occurrence frequencies of wordsand contexts, weighted by normalized idf.
Thatis, denoting the number of distinct words and con-texts as N and M , respectively,wi = t[tf(wi, c1) ?
idf(c1) ... tf(wi, cM ) ?
idf(cM )],(1)where tf(wi, cj) is the co-occurrence frequency ofword wi and context cj .
idf(cj) is given byidf(cj) = log(N/df(cj))maxk log(N/df(vk)) , (2)where df(cj) is the number of distinct words thatco-occur with context cj .Although VSM and tf?idf are naive and simplecompared to other language models like LSI andPLSI, they have been shown effective enough forthe purpose (Hagiwara et al, 2005).
The similar-ity between two words are then calculated as thecosine value of two corresponding vectors.4 EvaluationThis section describes the evaluation methods weemployed for automatic synonym acquisition.
Theevaluation is to measure how similar the obtainedsimilarities are to the ?true?
similarities.
We firstlyprepared the reference similarities from the exist-ing thesaurus WordNet as described in Section 4.1,355and by comparing the reference and obtained sim-ilarities, two evaluation measures, discriminationrate and correlation coefficient, are calculated au-tomatically as described in Sections 4.2 and 4.3.4.1 Reference similarity calculation usingWordNetAs the basis for automatic evaluation methods, thereference similarity, which is the answer value thatsimilarity of a certain pair of words ?should take,?is required.
We obtained the reference similarityusing the calculation based on thesaurus tree struc-ture (Nagao, 1996).
This calculation method re-quires no other resources such as corpus, thus it issimple to implement and widely used.The similarity between word sense wi and wordsense vj is obtained using tree structure as follows.Let the depth1 of node wi be di, the depth of nodevj be dj , and the maximum depth of the commonancestors of both nodes be ddca.
The similaritybetween wi and vj is then calculated assim(wi, vj) = 2 ?
ddcadi + dj , (3)which takes the value between 0.0 and 1.0.Figure 2 shows the example of calculating thesimilarity between the word senses ?hill?
and?coast.?
The number on the side of each wordsense represents the word?s depth.
From this treestructure, the similarity is obtained:sim(?hill?, ?coast?)
= 2 ?
35 + 5 = 0.6.
(4)The similarity between word w with sensesw1, ..., wn and word v with senses v1, ..., vm is de-fined as the maximum similarity between all thepairs of word senses:sim(w, v) = maxi,jsim(wi, vj), (5)whose idea came from Lin?s method (Lin, 1998).4.2 Discrimination RateThe following two sections describe two evalua-tion measures based on the reference similarity.The first one is discrimination rate (DR).
DR, orig-inally proposed by Kojima et al (2004), is the rate1To be precise, the structure of WordNet, where someword senses have more than one parent, isn?t a tree but aDAG.
The depth of a node is, therefore, defined here as the?maximum distance?
from the root node.entity     0inanimate-object     1natural-object     2geological-formation     34 natural-elevation5 hillshore     4coast     5Figure 2: Example of automatic similarity calcu-lation based on tree structure(answer, reply)(phone, telephone)(sign, signal)(concern, worry)(animal, coffee)(him, technology)(track, vote)(path, youth)?
?highly related unrelatedFigure 3: Test-sets for discrimination rate calcula-tion.
(percentage) of pairs (w1, w2) whose degree of as-sociation between two words w1, w2 is success-fully discriminated by the similarity derived bythe method under evaluation.
Kojima et al dealtwith three-level discrimination of a pair of words,that is, highly related (synonyms or nearly syn-onymous), moderately related (a certain degree ofassociation), and unrelated (irrelevant).
However,we omitted the moderately related level and lim-ited the discrimination to two-level: high or none,because of the difficulty of preparing a test set thatconsists of moderately related pairs.The calculation of DR follows these steps: first,two test sets, one of which consists of highly re-lated word pairs and the other of unrelated ones,are prepared, as shown in Figure 3.
The similar-ity between w1 and w2 is then calculated for eachpair (w1, w2) in both test sets via the method un-der evaluation, and the pair is labeled highly re-lated when similarity exceeds a given threshold tand unrelated when the similarity is lower than t.The number of pairs labeled highly related in thehighly related test set and unrelated in the unre-lated test set are denoted na and nb, respectively.356DR is then given by:12( naNa +nbNb), (6)where Na and Nb are the numbers of pairs inhighly related and unrelated test sets, respectively.Since DR changes depending on threshold t, max-imum value is adopted by varying t.We used the reference similarity to create thesetwo test sets.
Firstly, Np = 100, 000 pairs ofwords are randomly created using the target vo-cabulary set for synonym acquisition.
Propernouns are omitted from the choice here becauseof their high ambiguity.
The two testsets are thencreated extracting n = 2, 000 most related (withhigh reference similarity) and unrelated (with lowreference similarity) pairs.4.3 Correlation coefficientThe second evaluation measure is correlation co-efficient (CC) between the obtained similarity andthe reference similarity.
The higher CC value is,the more similar the obtained similarities are toWordNet, thus more accurate the synonym acqui-sition result is.The value of CC is calculated as follows.
Letthe set of the sample pairs be Ps, the sequence ofthe reference similarities calculated for the pairsin Ps be r = (r1, r2, ..., rn), the correspondingsequence of the target similarity to be evaluatedbe r = (s1, s2, ..., sn), respectively.
Correlationcoefficient ?
is then defined by:?
=1n?ni=1(ri ?
r?
)(si ?
s?
)?r?s , (7)where r?, s?, ?r, and ?s represent the average of rand s and the standard deviation of r and s, re-spectively.
The set of the sample pairs Ps is cre-ated in a similar way to the preparation of highlyrelated test set used in DR calculation, except thatwe employed Np = 4, 000, n = 2, 000 to avoidextreme nonuniformity.5 ExperimentsNow we desribe the experimental conditions andresults of contextual information selection.5.1 ConditionWe used the following three corpora for the ex-periment: (1) Wall Street Journal (WSJ) corpus(approx.
68,000 sentences, 1.4 million tokens),(2) Brown Corpus (BROWN) (approx.
60,000sentences, 1.3 million tokens), both of which arecontained in Treebank 3 (Marcus, 1994), and (3)written sentences in WordBank (WB) (approx.190,000 sentences, 3.5 million words) (Hyper-Collins, 2002).
No additional annotation such asPOS tags provided for Treebank was used, whichmeans that we gave the plain texts stripped off anyadditional information to RASP as input.To distinguish nouns, using POS tags annotatedby RASP, any words with POS tags APP, ND, NN,NP, PN, PP were labeled as nouns.
The windowradius for proximity is set to 3.
We also set athreshold tf on occurrence frequency in order tofilter out any words or contexts with low frequencyand to reduce computational cost.
More specifi-cally, any words w such that ?c tf(w, c) < tf andany contexts c such that ?w tf(w, c) < tf wereremoved from the co-occurrence data.
tf was setto tf = 5 for WSJ and BROWN, and tf = 10 forWB in Sections 5.2 and 5.3, and tf = 2 for WSJand BROWN and tf = 5 for WB in Section 5.4.5.2 Contextual Information SelectionIn this section, we experimented to discover whatkind of contextual information extracted in Sec-tion 2 is useful for synonym extraction.
The per-formances, i.e.
DR and CC are evaluated for eachof the three categories and their combinations.The evaluation result for three corpora is shownin Figure 4.
Notice that the range and scale of thevertical axes of the graphs vary according to cor-pus.
The result shows that dependency and prox-imity perform relatively well alone, while sen-tence co-occurrence has almost no contributionsto performance.
However, when combined withother kinds of context information, every category,even sentence co-occurrence, serves to ?stabilize?the overall performance, although in some casescombination itself decreases individual measuresslightly.
It is no surprise that the combination of allcategories achieves the best performance.
There-fore, in choosing combination of different kinds ofcontext information, one should take into consid-eration the economical efficiency and trade-off be-tween computational complexity and overall per-formance stability.5.3 Dependency SelectionWe then focused on the contribution of individualcategories of dependency relation, i.e.
groups ofgrammatical relations.
The following four groups35765.0%65.5%66.0%66.5%67.0%67.5%68.0%68.5%discriminationrate(DR)a0.090.100.110.120.13correlationcoefficient(CC))DRCCdep sent prox depsentdepproxsentproxall(1) WSJDR= 52.8%CC= -0.0029sent:65.0%65.5%66.0%66.5%67.0%67.5%68.0%68.5%69.0%discriminationrate(DR)a0.130.140.15correlationcoefficient(CC))DRCCdep sent prox depsentdepproxsentproxall(2) BROWNDR= 53.8%CC= 0.060sent:66.0%66.5%67.0%67.5%68.0%68.5%69.0%discriminationrate(DR)a0.160.170.180.19correlationcoefficient(CC))DRCCdep sent prox depsentdepproxsentproxall(3) WBDR= 52.2%CC= 0.0066sent:Figure 4: Contextual information selection perfor-mancesDiscrimination rate (DR) and correlation coefficient (CC)for (1) Wall Street Journal corpus, (2) Brown Corpus, and(3) WordBank.of GRs are considered for comparison conve-nience: (1) subj group (?subj?, ?ncsubj?, ?xsubj?,and ?csubj?
), (2) obj group (?obj?, ?dobj?, ?obj2?,and ?iobj?
), (3) mod group (?mod?, ?ncmod?,?xmod?, ?cmod?, and ?detmod?
), and (4) etcgroup (others), as shown in the circles in Figure1.
This is because distinction between relationsin a group is sometimes unclear, and is consid-ered to strongly depend on the parser implemen-tation.
The final target is seven kinds of combina-tions of the above four groups: subj, obj, mod, etc,subj+obj, subj+obj+mod, and all.The two evaluation measures are similarly cal-culated for each group and combination, andshown in Figure 5.
Although subjects, objects,and their combination are widely used contextualinformation, the performances for subj and objcategories, as well as their combination subj+obj,were relatively poor.
On the contrary, the re-sult clearly shows the importance of modification,which alone is even better than widely adoptedsubj+obj.
The ?stabilization effect?
of combina-tions observed in the previous experiment is alsoconfirmed here as well.Because the size of the co-occurrence datavaries from one category to another, we conductedanother experiment to verify that the superiorityof the modification category is simply due to thedifference in the quality (content) of the group,not the quantity (size).
We randomly extracted100,000 pairs from each of mod and subj+obj cat-egories to cancel out the quantity difference andcompared the performance by calculating aver-aged DR and CC of ten trials.
The result showedthat, while the overall performances substantiallydecreased due to the size reduction, the relationbetween groups was preserved before and after theextraction throughout all of the three corpora, al-though the detailed result is not shown due to thespace limitation.
This means that what essentiallycontributes to the performance is not the size ofthe modification category but its content.5.4 Modification SelectionAs the previous experiment shows that modifica-tions have the biggest significance of all the depen-dency relationship, we further investigated whatkind of modifications is useful for the purpose.
Todo this, we broke down the mod group into thesefive categories according to modifying word?s cat-egory: (1) detmod, when the GR label is ?det-35854.0%56.0%58.0%60.0%62.0%64.0%66.0%68.0%discriminationrate(DR)a0.000.020.040.060.080.100.120.14correlationcoefficient(CC))DRCCsubj obj mod etc subjobjsubjobjmodall(1) WSJ54.0%56.0%58.0%60.0%62.0%64.0%66.0%68.0%discriminationrate(DR)a0.000.020.040.060.080.100.120.140.16correlationcoefficient(CC))DRCCsubj obj mod etc subjobjsubjobjmodall(2) BROWN54.0%56.0%58.0%60.0%62.0%64.0%66.0%68.0%70.0%discriminationrate(DR)a0.000.020.040.060.080.100.120.140.160.180.20correlationcoefficient(CC))DRCCsubj obj mod etc subjobjsubjobjmodall(3) WBFigure 5: Dependency selection performancesDiscrimination rate (DR) and correlation coefficient (CC)for (1) Wall Street Journal corpus, (2) Brown Corpus, and(3) WordBank.50.0%52.0%54.0%56.0%58.0%60.0%62.0%64.0%66.0%discriminationrate(DR)a0.000.020.040.060.080.100.12correlationcoefficient(CC))DRCCdetmodncmod-nncmod-jncmod-petc all(1) WSJ50.0%52.0%54.0%56.0%58.0%60.0%62.0%64.0%66.0%discriminationrate(DR)a0.000.020.040.060.080.100.120.14correlationcoefficient(CC))DRCCdetmodncmod-nncmod-jncmod-petc all(2) BROWNCC= -0.01857.0%59.0%61.0%63.0%65.0%67.0%discriminationrate(DR)a0.040.060.080.100.120.140.160.18correlationcoefficient(CC))DRCCdetmodncmod-nncmod-jncmod-petc all(3) WBFigure 6: Modification selection performancesDiscrimination rate (DR) and correlation coefficient (CC)for (1) Wall Street Journal corpus, (2) Brown Corpus, and(3) WordBank.359mod?, i.e., the modifying word is a determiner, (2)ncmod-n, when the GR label is ?ncmod?
and themodifying word is a noun, (3) ncmod-j, when theGR label is ?ncmod?
and the modifying word is anadjective or number, (4) ncmod-p, when the GRlabel is ?ncmod?
and the modification is through apreposition (e.g.
?state?
and ?affairs?
in ?state ofaffairs?
), and (5) etc (others).The performances for each modification cate-gory are evaluated and shown in Figure 6.
Al-though some individual modification categoriessuch as detmod and ncmod-j outperform other cat-egories in some cases, the overall observation isthat all the modification categories contribute tosynonym acquisition to some extent, and the ef-fect of individual categories are accumulative.
Wetherefore conclude that the main contributing fac-tor on utilizing modification relationship in syn-onym acquisition isn?t the type of modification,but the diversity of the relations.6 ConclusionIn this study, we experimentally investigated theimpact of contextual information selection, by ex-tracting three kinds of contextual information ?dependency, sentence co-occurrence, and proxim-ity ?
from three different corpora.
The acqui-sition result was evaluated using two evaluationmeasures, DR and CC using the existing thesaurusWordNet.
We showed that while dependency andproximity perform relatively well by themselves,combination of two or more kinds of contextualinformation, even with the poorly performing sen-tence co-occurrence, gives more stable result.
Theselection should be chosen considering the trade-off between computational complexity and overallperformance stability.
We also showed that modi-fication has the greatest contribution to the acqui-sition of all the dependency relations, even greaterthan the widely adopted subject-object combina-tion.
It is also shown that all the modification cate-gories contribute to the acquisition to some extent.Because we limited the target to nouns, the re-sult might be specific to nouns, but the same exper-imental framework is applicable to any other cate-gories of words.
Although the result also showsthe possibility that the bigger the corpus is, thebetter the performance will be, the contents andsize of the corpora we used are diverse, so theirrelationship, including the effect of the window ra-dius, should be examined as the future work.ReferencesMarco Baroni and Sabrina Bisi 2004.
Using cooccur-rence statistics and the web to discover synonymsin a technical language.
Proc.
of the Fourth Interna-tional Conference on Language Resources and Eval-uation (LREC 2004).Ted Briscoe and John Carroll.
2002.
Robust Accu-rate Statistical Annotation of General Text.
Proc.
ofthe Third International Conference on Language Re-sources and Evaluation (LREC 2002), 1499?1504.Ted Briscoe, John Carroll, Jonathan Graham and AnnCopestake 2002.
Relational evaluation schemes.Proc.
of the Beyond PARSEVAL Workshop at theThird International Conference on Language Re-sources and Evaluation, 4?8.Scott Deerwester, et al 1990.
Indexing by Latent Se-mantic Analysis.
Journal of the American Societyfor Information Science, 41(6):391?407.Christiane Fellbaum.
1998.
WordNet: an electroniclexical database.
MIT Press.Masato Hagiwara, Yasuhiro Ogawa, KatsuhikoToyama.
2005.
PLSI Utilization for AutomaticThesaurus Construction.
Proc.
of The Second In-ternational Joint Conference on Natural LanguageProcessing (IJCNLP-05), 334?345.Zellig Harris.
1985.
Distributional Structure.
JerroldJ.
Katz (ed.)
The Philosophy of Linguistics.
OxfordUniversity Press.
26?47.Donald Hindle.
1990.
Noun classification frompredicate-argument structures.
Proc.
of the 28th An-nual Meeting of the ACL, 268?275.Thomas Hofmann.
1999.
Probabilistic Latent Seman-tic Indexing.
Proc.
of the 22nd International Con-ference on Research and Development in Informa-tion Retrieval (SIGIR ?99), 50?57.Kazuhide Kojima, Hirokazu Watabe, and TsukasaKawaoka.
2004.
Existence and Application ofCommon Threshold of the Degree of Association.Proc.
of the Forum on Information Technology(FIT2004) F-003.Collins.
2002.
Collins Cobuild Mld Major New Edi-tion CD-ROM.
HarperCollins Publishers.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar words.
Proc.
of the 36th Annual Meet-ing of the Association for Computational Linguis-tics and 17th International Conference on Compu-tational linguistics (COLING-ACL ?98), 786?774.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1994.
Building a large annotatedcorpus of English: The Penn treebank.
Computa-tional Linguistics, 19(2):313?330.Makoto Nagao (ed.).
1996.
Shizengengoshori.The Iwanami Software Science Series 15, IwanamiShoten Publishers.360
