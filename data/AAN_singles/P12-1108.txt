Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 1025?1034,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsA Cost Sensitive Part-of-Speech Tagging:Differentiating Serious Errors from Minor ErrorsHyun-Je Song1 Jeong-Woo Son1 Tae-Gil Noh2 Seong-Bae Park1,3 Sang-Jo Lee11School of Computer Sci.
& Eng.
2Computational Linguistics 3NLP Lab.Kyungpook Nat?l Univ.
Heidelberg University Dept.
of Computer ScienceDaegu, Korea Heidelberg, Germany University of Illinois at Chicago{hjsong,jwson,tgnoh}@sejong.knu.ac.kr sbpark@uic.edu sjlee@knu.ac.krAbstractAll types of part-of-speech (POS) tagging er-rors have been equally treated by existing tag-gers.
However, the errors are not equally im-portant, since some errors affect the perfor-mance of subsequent natural language pro-cessing (NLP) tasks seriously while others donot.
This paper aims to minimize these seriouserrors while retaining the overall performanceof POS tagging.
Two gradient loss functionsare proposed to reflect the different types of er-rors.
They are designed to assign a larger costto serious errors and a smaller one to minorerrors.
Through a set of POS tagging exper-iments, it is shown that the classifier trainedwith the proposed loss functions reduces se-rious errors compared to state-of-the-art POStaggers.
In addition, the experimental resulton text chunking shows that fewer serious er-rors help to improve the performance of sub-sequent NLP tasks.1 IntroductionPart-of-speech (POS) tagging is needed as a pre-processor for various natural language processing(NLP) tasks such as parsing, named entity recogni-tion (NER), and text chunking.
Since POS tagging isnormally performed in the early step of NLP tasks,the errors in POS tagging are critical in that theyaffect subsequent steps and often lower the overallperformance of NLP tasks.Previous studies on POS tagging have shownhigh performance with machine learning techniques(Ratnaparkhi, 1996; Brants, 2000; Lafferty et al,2001).
Among the types of machine learning ap-proaches, supervised machine learning techniqueswere commonly used in early studies on POS tag-ging.
With the characteristics of a language (Rat-naparkhi, 1996; Kudo et al, 2004) and informa-tive features for POS tagging (Toutanova and Man-ning, 2000), the state-of-the-art supervised POS tag-ging achieves over 97% of accuracy (Shen et al,2007; Manning, 2011).
This performance is gen-erally regarded as the maximum performance thatcan be achieved by supervised machine learningtechniques.
There have also been many studies onPOS tagging with semi-supervised (Subramanya etal., 2010; S?gaard, 2011) or unsupervised machinelearning methods (Berg-Kirkpatrick et al, 2010;Das and Petrov, 2011) recently.
However, there stillexists room to improve supervised POS tagging interms of error differentiation.It should be noted that not all errors are equallyimportant in POS tagging.
Let us consider the parsetrees in Figure 1 as an example.
In Figure 1(a),the word ?plans?
is mistagged as a noun where itshould be a verb.
This error results in a wrong parsetree that is severely different from the correct treeshown in Figure 1(b).
The verb phrase of the verb?plans?
in Figure 1(b) is discarded in Figure 1(a)and the whole sentence is analyzed as a single nounphrase.
Figure 1(c) and (d) show another tagging er-ror and its effect.
In Figure 1(c), a noun is tagged asa NNS (plural noun) where its correct tag is NN (sin-gular or mass noun).
However, the error in Figure1(c) affects only locally the noun phrase to which?physics?
belongs.
As a result, the general structureof the parse tree in Figure 1(c) is nearly the same as1025SVPVPNPThe treasurytoraise 150 billion in cash.DT NNPTOVB CD CD IN NNSplansNNS(a) A parse tree with a serious error.SVPNPThe   treasuryDT NNPSVPVPtoraise 150 billion in cash.TOVB CD CD IN NNplansVBZ(b) The correct parse tree of the sentence?The treasuryplans .
.
.
?.SNP VPWePRPalteredVBNNPNP PPthe chemistry and physicsDTof the atmosphereNN CC NNS INDT NN(c) A parse tree with a minor error.SNP VPWePRPalteredVBNNPNP PPthe chemistry and physicsDTof the atmosphereNN CC NN INDT NN(d) The correct parse tree of the sentence ?We altered.
.
.
?.Figure 1: An example of POS tagging errorsthe correct one in Figure 1(d).
That is, a sentenceanalyzed with this type of error would yield a cor-rect or near-correct result in many NLP tasks suchas machine translation and text chunking.The goal of this paper is to differentiate the seri-ous POS tagging errors from the minor errors.
POStagging is generally regarded as a classification task,and zero-one loss is commonly used in learning clas-sifiers (Altun et al, 2003).
Since zero-one loss con-siders all errors equally, it can not distinguish errortypes.
Therefore, a new loss is required to incorpo-rate different error types into the learning machines.This paper proposes two gradient loss functions toreflect differences among POS tagging errors.
Thefunctions assign relatively small cost to minor er-rors, while larger cost is given to serious errors.They are applied to learning multiclass support vec-tor machines (Tsochantaridis et al, 2004) which istrained to minimize the serious errors.
Overall accu-racy of this SVM is not improved against the state-of-the-art POS tagger, but the serious errors are sig-nificantly reduced with the proposed method.
Theeffect of the fewer serious errors is shown by apply-ing it to the well-known NLP task of text chunking.Experimental results show that the proposed methodachieves a higher F1-score compared to other POStaggers.The rest of the paper is organized as follows.
Sec-tion 2 reviews the related studies on POS tagging.
InSection 3, serious and minor errors are defined, andit is shown that both errors are observable in a gen-eral corpus.
Section 4 proposes two new loss func-tions for discriminating the error types in POS tag-ging.
Experimental results are presented in Section5.
Finally, Section 6 draws some conclusions.2 Related WorkThe POS tagging problem has generally been solvedby machine learning methods for sequential label-1026Tag category POS tagsSubstantive NN, NNS, NNP, NNPS, CD, PRP, PRP$Predicate VB, VBD, VBG, VBN, VBP, VBZ, MD, JJ, JJR, JJSAdverbial RB, RBR, RBS, RP, UH, EX, WP, WP$, WRB, CC, IN, TODeterminer DT, PDT, WDTEtc FW, SYM, POS, LSTable 1: Tag categories and POS tags in Penn Tree Bank tag seting.
In early studies, rich linguistic features and su-pervised machine learning techniques are applied byusing annotated corpora like the Wall Street Journalcorpus (Marcus et al, 1994).
For instance, Ratna-parkhi (1996) used a maximum entropy model forPOS tagging.
In this study, the features for rarelyappearing words in a corpus are expanded to im-prove the overall performance.
Following this direc-tion, various studies have been proposed to extendinformative features for POS tagging (Toutanovaand Manning, 2000; Toutanova et al, 2003; Man-ning, 2011).
In addition, various supervised meth-ods such as HMMs and CRFs are widely applied toPOS tagging.
Lafferty et al (2001) adopted CRFsto predict POS tags.
The methods based on CRFsnot only have all the advantages of the maximumentropy markov models but also resolve the well-known problem of label bias.
Kudo et al (2004)modified CRFs for non-segmented languages likeJapanese which have the problem of word boundaryambiguity.As a result of these efforts, the performance ofstate-of-the-art supervised POS tagging shows over97% of accuracy (Toutanova et al, 2003; Gime?nezand Ma`rquez, 2004; Tsuruoka and Tsujii, 2005;Shen et al, 2007; Manning, 2011).
Due to the highaccuracy of supervised approaches for POS tagging,it has been deemed that there is no room to im-prove the performance on POS tagging in supervisedmanner.
Thus, recent studies on POS tagging focuson semi-supervised (Spoustova?
et al, 2009; Sub-ramanya et al, 2010; S?gaard, 2011) or unsuper-vised approaches (Haghighi and Klein, 2006; Gold-water and Griffiths, 2007; Johnson, 2007; Graca etal., 2009; Berg-Kirkpatrick et al, 2010; Das andPetrov, 2011).
Most previous studies on POS tag-ging have focused on how to extract more linguisticfeatures or how to adopt supervised or unsupervisedapproaches based on a single evaluation measure,accuracy.
However, with a different viewpoint forerrors on POS tagging, there is still some room toimprove the performance of POS tagging for subse-quent NLP tasks, even though the overall accuracycan not be much improved.In ordinary studies on POS tagging, costs of er-rors are equally assigned.
However, with respectto the performance of NLP tasks relying on the re-sult of POS tagging, errors should be treated differ-ently.
In the machine learning community, cost sen-sitive learning has been studied to differentiate costsamong errors.
By adopting different misclassifica-tion costs for each type of errors, a classifier is op-timized to achieve the lowest expected cost (Elkan,2001; Cai and Hofmann, 2004; Zhou and Liu, 2006).3 Error Analysis of Existing POS TaggerThe effects of POS tagging errors to subsequentNLP tasks vary according to their type.
Some errorsare serious, while others are not.
In this paper, theseriousness of tagging errors is determined by cat-egorical structures of POS tags.
Table 1 shows thePenn tree bank POS tags and their categories.
Thereare five categories in this table: substantive, pred-icate, adverbial, determiner, and etc.
Serious tag-ging errors are defined as misclassifications amongthe categories, while minor errors are defined as mis-classifications within a category.
This definition fol-lows the fact that POS tags in the same categoryform similar syntax structures in a sentence (Zhaoand Marcus, 2009).
That is, inter-category errors aretreated as serious errors, while intra-category errorsare treated as minor errors.Table 2 shows the distribution of inter-categoryand intra-category errors observed in section 22?24 of the WSJ corpus (Marcus et al, 1994) that istagged by the Stanford Log-linear Part-Of-Speech1027Predicted categorySubstantive Predicate Adverbial Determiner EtcSubstantive 614 479 32 10 15Predicate 585 743 107 2 14True category Adverbial 41 156 500 42 2Determiner 13 7 47 24 0Etc 23 11 3 1 0Table 2: The distribution of tagging errors on WSJ corpus by Stanford Part-Of-Speech Tagger.Tagger (Manning, 2011) (trained with WSJ sections00?18).
In this table, bold numbers denote inter-category errors while all other numbers show intra-category errors.
The number of total errors is 3,471out of 129,654 words.
Among them, 1,881 errors(54.19%) are intra-category, while 1,590 of the er-rors (45.81%) are inter-category.
If we can reducethese inter-category errors under the cost of mini-mally increasing intra-category errors, the taggingresults would improve in quality.Generally in POS tagging, all tagging errors areregarded equally in importance.
However, inter-category and intra-category errors should be distin-guished.
Since a machine learning method is opti-mized by a loss function, inter-category errors canbe efficiently reduced if a loss function is designedto handle both types of errors with different cost.
Wepropose two loss functions for POS tagging and theyare applied to multiclass Support Vector Machines.4 Learning SVMs with Class SimilarityPOS tagging has been solved as a sequential labelingproblem which assumes dependency among words.However, by adopting sequential features such asPOS tags of previous words, the dependency can bepartially resolved.
If it is assumed that words areindependent of one another, POS tagging can be re-garded as a multiclass classification problem.
Oneof the best solutions for this problem is by using anSVM.4.1 Training SVMs with Loss FunctionAssume that a training data set D ={(x1, y1), (x2, y2), .
.
.
, (xl, yl)} is given wherexi ?
Rd is an instance vector and yi ?
{+1,?1}is its class label.
SVM finds an optimal hyperplanesatisfyingxi ?
w + b ?
+1 for yi = +1,xi ?
w + b ?
?1 for yi = ?1,where w and b are parameters to be estimated fromtraining data D. To estimate the parameters, SVMsminimizes a hinge loss defined as?i = Lhinge(yi, w ?
xi + b)= max{0, 1 ?
yi ?
(w ?
xi + b)}.With regularizer ||w||2 to control model complexity,the optimization problem of SVMs is defined asminw,?12||w||2 + Cl?i=1?i,subject toyi(xi ?
w + b) ?
1?
?i, and ?i ?
0 ?i,where C is a user parameter to penalize errors.Crammer et al (2002) expanded the binary-classSVM for multiclass classifications.
In multiclassSVMs, by considering all classes the optimizationof SVM is generalized asminw,?12?k?K||wk||2 + Cl?i=1?i,with constraints(wyi ?
?
(xi, yi))?
(wk ?
?
(xi, k)) ?
1?
?i,?i ?
0 ?i, ?k ?
K \ yi,where ?
(xi, yi) is a combined feature representationof xi and yi, and K is the set of classes.1028POSSUBSTANTIVEPREDICATE ADVERBIALOTHERSNOUNPRONOUNDETERMINERDTPDTNNSNN NNPNNPSCDPRP PRP$VERBVBDVBVBGVBNVBPVBZMDADJECTJJRJJ JJSSYMFW POSLSADVERBWH- CONJUNCTIONRBRRB RBSRPUHEXWPWP$WRBINCC TOWDTFigure 2: A tree structure of POS tags.Since both binary and multiclass SVMs adopt ahinge loss, the errors between classes have the samecost.
To assign different cost to different errors,Tsochantaridis et al (2004) proposed an efficientway to adopt arbitrary loss function, L(yi, yj) whichreturns zero if yi = yj , otherwise L(yi, yj) > 0.Then, the hinge loss ?i is re-scaled with the inverseof the additional loss between two classes.
By scal-ing slack variables with the inverse loss, margin vi-olation with high loss L(yi, yj) is more severely re-stricted than that with low loss.
Thus, the optimiza-tion problem with L(yi, yj) is given asminw,?12?k?K||wk||2 + Cl?i=1?i, (1)with constraints(wyi ?
?
(xi, yi))?
(wk ?
?
(xi, k)) ?
1?
?iL(yi, k),?i ?
0 ?i, ?k ?
K \ yi,With the Lagrange multiplier ?, the optimizationproblem in Equation (1) is easily converted to thefollowing dual quadratic problem.min?12l?i,j?ki?K\yi?kj?K\yj?i,ki?j,kj ?J(xi, yi, ki)J(xj , yj, kj)?l?i?ki?K\yi?i,ki ,with constraints?
?
0 and?ki?K\yi?i,kiL(yi, ki)?
C, ?i = 1, ?
?
?
, l,where J(xi, yi, ki) is defined asJ(xi, yi, ki) = ?
(xi, yi)?
?
(xi, ki).4.2 Loss Functions for POS taggingTo design a loss function for POS tagging, this paperadopts categorical structures of POS tags.
The sim-plest way to reflect the structure of POS tags shownin Table 1 is to assign larger cost to inter-categoryerrors than to intra-category errors.
Thus, the lossfunction with the categorical structure in Table 1 isdefined asLc(yi, yj) =??????
?0 if yi = yj ,?
if yi 6= yj but they belongto the same POS category,1 otherwise,(2)where 0 < ?
< 1 is a constant to reduce the value ofLc(yi, yj) when yi and yj are similar.
As shown inthis equation, inter-category errors have larger costthan intra-category errors.
This loss Lc(yi, yj) isnamed as category loss.The loss function Lc(yi, yj) is designed to reflectthe categories in Table 1.
However, the structureof POS tags can be represented as a more complexstructure.
Let us consider the category, predicate.1029?Class NN Class NNSClass VB(a) Multiclass SVMs with hinge lossClass NN Class NNSClass VB?L(NN, VB)?L(NN, NNS)(b) Multiclass SVMs with the proposed lossfunctionFigure 3: Effect of the proposed loss function in multiclass SVMsThis category has ten POS tags, and can be furthercategorized into two sub-categories: verb and ad-ject.
Figure 2 represents a categorical structure ofPOS tags as a tree with five categories of POS tagsand their seven sub-categories.To express the tree structure of Figure 2 as a loss,another loss function Lt(yi, yj) is defined asLt(yi, yj) =12[Dist(Pi,j , yi) +Dist(Pi,j, yj)]?
?, (3)where Pi,j denotes the nearest common parent ofboth yi and yj , and the function Dist(Pi,j, yi) re-turns the number of steps from Pi,j to yi.
The userparameter ?
is a scaling factor of a unit loss for asingle step.
This loss Lt(yi, yj) returns large valueif the distance between yi and yj is far in the treestructure, and it is named as tree loss.As shown in Equation (1), two proposed lossfunctions adjust margin violation between classes.They basically assign less value for intra-categoryerrors than inter-category errors.
Thus, a classi-fier is optimized to strictly keep inter-category er-rors within a smaller boundary.
Figure 3 shows asimple example.
In this figure, there are three POStags and two categories.
NN (singular or mass noun)and NNS (plural noun) belong to the same cate-gory, while VB (verb, base form) is in another cat-egory.
Figure 3(a) shows the decision boundary ofNN based on hinge loss.
As shown in this figure, asingle ?
is applied for the margin violation amongall classes.
Figure 3(b) also presents the decisionboundary of NN, but it is determined with the pro-posed loss function.
In this figure, the margin vio-lation is applied differently to inter-category (NN toVB) and intra-category (NN to NNS) errors.
It re-sults in reducing errors between NN and VB even ifthe errors between NN and NNS could be slightlyincreased.5 Experiments5.1 Experimental SettingExperiments are performed with a well-known stan-dard data set, the Wall Street Journal (WSJ) corpus.The data is divided into training, development andtest sets as in (Toutanova et al, 2003; Tsuruoka andTsujii, 2005; Shen et al, 2007).
Table 3 shows somesimple statistics of these data sets.
As shown inthis table, training data contains 38,219 sentenceswith 912,344 words.
In the development data set,there are 5,527 sentences with about 131,768 words,those in the test set are 5,462 sentences and 129,654words.
The development data set is used only to se-lect ?
in Equation (2) and ?
in Equation (3).Table 4 shows the feature set for our experiments.In this table, wi and ti denote the lexicon and POStag for the i-th word in a sentence respectively.
Weuse almost the same feature set as used in (Tsuruokaand Tsujii, 2005) including word features, tag fea-1030Training Develop TestSection 0?18 19?21 22?24# of sentences 38,219 5,527 5,462# of terms 912,344 131,768 129,654Table 3: Simple statistics of experimental dataFeature Name DescriptionWord features wi?2, wi?1, wi, wi+1, wi+2wi?1 ?
wi, wi ?
wi+1Tag featuresti?2, ti?1, ti+1, ti+2ti?2 ?
ti?1, ti+1 ?
ti+2ti?2 ?
ti?1 ?
ti+1, ti?1 ?
ti+1 ?
ti+2ti?2 ?
ti?1 ?
ti+1 ?
ti+2Tag/Wordcombinationti?2?wi, ti?1 ?wi, ti+1?wi, ti+2?witi?1 ?
ti+1 ?
wiPrefix features prefixes of wi (up to length 9)Suffix features suffixes of wi (up to length 9)Lexical featureswhether wi contains capitalswhether wi has a numberwhether wi has a hyphenwhether wi is all capitalwhether wi starts with capital andlocates at the middle of sentenceTable 4: Feature template for experimentstures, word/tag combination features, prefix and suf-fix features as well as lexical features.
The POS tagsfor words are obtained from a two-pass approachproposed by Nakagawa et al (2001).In the experiments, two multiclass SVMs with theproposed loss functions are used.
One is CL-MSVMwith category loss and the other is TL-MSVM withtree loss.
A linear kernel is used for both SVMs.5.2 Experimental ResultsCL-MSVM with ?
= 0.4 shows the best overall per-formance on the development data where its errorrate is as low as 2.71%.
?
= 0.4 implies that thecost of intra-category errors is set to 40% of that ofinter-category errors.
The error rate of TL-MSVMis 2.69% when ?
is 0.6. ?
= 0.4 and ?
= 0.6 are setin the all experiments below.Table 5 gives the comparison with the previouswork and proposed methods on the test data.
As canbe seen from this table, the best performing algo-rithms achieve near 2.67% error rate (Shen et al,2007; Manning, 2011).
CL-MSVM and TL-MSVMError(%)# of Intraerror# of Intererror(Gime?nez and Ma`rquez,2004) 2.841,995(54.11%)1,692(45.89%)(Tsuruoka and Tsujii,2005) 2.85 - -(Shen et al, 2007) 2.67 1,856(53.52%)1,612(46.48%)(Manning, 2011) 2.68 1,881(54.19%)1,590(45.81%)CL-MSVM (?
= 0.4) 2.69 1,916(55.01%)1,567(44.99%)TL-MSVM (?
= 0.6) 2.68 1,904(54.74%)1,574(45.26%)Table 5: Comparison with the previous worksachieve an error rate of 2.69% and 2.68% respec-tively.
Although overall error rates of CL-MSVMand TL-MSVM are not improved compared to theprevious state-of-the-art methods, they show reason-able performance.For inter-category error, CL-MSVM achieves thebest performance.
The number of inter-category er-ror is 1,567, which shows 23 errors reduction com-pared to previous best inter-category result by (Man-ning, 2011).
TL-MSVM also makes 16 less inter-category errors than Manning?s tagger.
When com-pared with Shen?s tagger, both CL-MSVM and TL-MSVM make far less inter-category errors even iftheir overall performance is slightly lower than thatof Shen?s tagger.
However, the intra-category er-ror rate of the proposed methods has some slightincreases.
The purpose of proposed methods is tominimize inter-category errors but preserving over-all performance.
From these results, it can be foundthat the proposed methods which are trained with theproposed loss functions do differentiate serious andminor POS tagging errors.5.3 Chunking ExperimentsThe task of chunking is to identify the non-recursivecores for various types of phrases.
In chunking, thePOS information is one of the most crucial aspects inidentifying chunks.
Especially inter-category POSerrors seriously affect the performance of chunkingbecause they are more likely to mislead the chunkcompared to intra-category errors.Here, chunking experiments are performed with1031POS tagger Accuracy (%) Precision Recall F1-score(Shen et al, 2007) 96.08 94.03 93.75 93.89(Manning, 2011) 96.08 94 93.8 93.9CL-MSVM (?
= 0.4) 96.13 94.1 93.9 94.00TL-MSVM (?
= 0.6) 96.12 94.1 93.9 94.00Table 6: The experimental results for chunkinga data set provided for the CoNLL-2000 sharedtask.
The training data contains 8,936 sentenceswith 211,727 words obtained from sections 15?18of the WSJ.
The test data consists of 2,012 sentencesand 47,377 words in section 20 of the WSJ.
In orderto represent chunks, an IOB model is used, whereevery word is tagged with a chunk label extendedwith B (the beginning of a chunk), I (inside a chunk),and O (outside a chunk).
First, the POS informa-tion in test data are replaced to the result of our POStagger.
Then it is evaluated using trained chunkingmodel.
Since CRFs (Conditional Random Fields)has been shown near state-of-the-art performance intext chunking (Fei Sha and Fernando Pereira, 2003;Sun et al, 2008), we use CRF++, an open sourceCRF implementation by Kudo (2005), with defaultfeature template and parameter settings of the pack-age.
For simplicity in the experiments, the valuesof ?
in Equation (2) and ?
in Equation (3) are setto be 0.4 and 0.6 respectively which are same as theprevious section.Table 6 gives the experimental results of textchunking according to the kinds of POS taggers in-cluding two previous works, CL-MSVM, and TL-MSVM.
Shen?s tagger and Manning?s tagger shownearly the same performance.
They achieve an ac-curacy of 96.08% and around 93.9 F1-score.
On theother hand, CL-MSVM achieves 96.13% accuracyand 94.00 F1-score.
The accuracy and F1-score ofTL-MSVM are 96.12% and 94.00.
Both CL-MSVMand TL-MSVM show slightly better performancesthan other POS taggers.
As shown in Table 5, bothCL-MSVM and TL-MSVM achieve lower accura-cies than other methods, while their inter-categoryerrors are less than that of other experimental meth-ods.
Thus, the improvement of CL-MSVM and TL-MSVM implies that, for the subsequent natural lan-guage processing, a POS tagger should considersdifferent cost of tagging errors.6 ConclusionIn this paper, we have shown that supervised POStagging can be improved by discriminating inter-category errors from intra-category ones.
An inter-category error occurs by mislabeling a word witha totally different tag, while an intra-category erroris caused by a similar POS tag.
Therefore, inter-category errors affect the performances of subse-quent NLP tasks far more than intra-category errors.This implies that different costs should be consid-ered in training POS tagger according to error types.As a solution to this problem, we have proposedtwo gradient loss functions which reflect differentcosts for two error types.
The cost of an error type isset according to (i) categorical difference or (ii) dis-tance in the tree structure of POS tags.
Our POSexperiment has shown that if these loss functionsare applied to multiclass SVMs, they could signif-icantly reduce inter-category errors.
Through thetext chunking experiment, it is shown that the multi-class SVMs trained with the proposed loss functionswhich generate fewer inter-category errors achievehigher performance than existing POS taggers.We have shown that cost sensitive learning can beapplied to POS tagging only with multiclass SVMs.However, the proposed loss functions are generalenough to be applied to other existing POS taggers.Most supervised machine learning techniques areoptimized on their loss functions.
Therefore, theperformance of POS taggers based on supervisedmachine learning techniques can be improved by ap-plying the proposed loss functions to learn their clas-sifiers.AcknowledgmentsThis research was supported by the Converg-ing Research Center Program funded by theMinistry of Education, Science and Technology(2011K000659).ReferencesYasemin Altun, Mark Johnson, and Thomas Hofmann.2003.
Investigating Loss Functions and Optimiza-tion Methods for Discriminative Learning of Label Se-quences.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing.
pp.145?152.1032Talyor Berg-Kirkpatrick, Alexandre Bouchard-Co?te?,John DeNero, and Dan Klein.
2010.
Painless Un-supervised Learning with Features.
In Proceedingsof the North American Chapter of the Association forComputational Linguistics.
pp.
582?590.Thorsten Brants.
2000.
TnT-A Statistical Part-of-SpeechTagger.
In Proceedings of the Sixth Applied NaturalLanguage Processing Conference.
pp.
224?231.Lijuan Cai and Thomas Hofmann.
2004.
Hierarchi-cal Document Categorization with Support Vector Ma-chines.
In Proceedings of the Thirteenth ACM Inter-national Conference on Information and KnowledgeManagement.
pp.
78?87.Koby Crammer, Yoram Singer.
2002.
On the Algorith-mic Implementation of Multiclass Kernel-based Vec-tor Machines.
Journal of Machine Learning Research,Vol.
2. pp.
265?292.Dipanjan Das and Slav Petrov.
2011.
Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Pro-jections.
In Proceedings of the 49th Annual Meetingof the Association of Computational Linguistics.
pp.600?609.Charles Elkan.
2001.
The Foundations of Cost-SensitiveLearning.
In Proceedings of the Seventeenth Interna-tional Joint Conference on Artificial Intelligence.
pp.973?978.Jesu?s Gime?nez and Llu?
?s Ma`rquez.
2004.
SVMTool: Ageneral POS tagger generator based on Support VectorMachines.
In Proceedings of the Fourth InternationalConference on Language Resources and Evaluation.pp.
43?46.Sharon Goldwater and Thomas T. Griffiths.
2007.
Afully Bayesian Approach to Unsupervised Part-of-Speech Tagging.
In Proceedings of the 45th AnnualMeeting of the Association of Computational Linguis-tics.
pp.
744?751.Joao Graca, Kuzman Ganchev, Ben Taskar, and FernandoPereira.
2009.
Posterior vs Parameter Sparsity in La-tent Variable Models.
In Advances in Neural Informa-tion Processing Systems 22. pp.
664?672.Aria Haghighi and Dan Klein.
2006.
Prototype-drivenLearning for Sequence Models.
In Proceedings of theNorth American Chapter of the Association for Com-putational Linguistics.
pp.
320?327.Mark Johnson.
2007.
Why doesn?t EM find good HMMPOS-taggers?
In Proceedings of the 2007 Joint Meet-ing of the Conference on Empirical Methods in Natu-ral Language Processing and the Conference on Com-putational Natural Language Learning.
pp.
296?305.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying Conditional Random Fields toJapanese Morphological Analysis.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing.
pp.
230?237.Taku Kudo.
2005.
CRF++: Yet another CRF toolkit.http://crfpp.sourceforge.net.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional Random Fields: Probabilistic Mod-els for Segmenting and Labeling Sequence Data.
InProceedings of the Eighteenth International Confer-ence on Machine Learning.
pp.
282?289.Christopher D. Manning.
2011.
Part-of-Speech Taggingfrom 97% to 100%: Is It Time for Some Linguistics?.In Proceedings of the 12th International Conferenceon Intelligent Text Processing and Computational Lin-guistics.
pp.
171?189.Tetsuji Nakagawa, Taku Kudo, and Yuji Matsumoto.2001.
Unknown Word Guessing and Part-of-SpeechTagging Using Support Vector Machines.
In Proceed-ings of the Sixth Natural Language Processing PacificRim Symposium.
pp.
325?331.Adwait Ratnaparkhi.
1996.
A Maximum Entropy Modelfor Part-Of-Speech Tagging.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing.
pp.
133?142.Fei Sha and Fernando Pereira.
2003.
Shallow Parsingwith Conditional Random Fields.
In Proceedings ofthe Human Language Technology and North AmericanChapter of the Association for Computational Linguis-tics.
pp.
213?220.Libin Shen, Giorgio Satta, and Aravind K. Joshi 2007.Guided Learning for Bidirectional Sequence Classifi-cation.
In Proceedings of the 45th Annual Meetingof the Association of Computational Linguistics.
pp.760?767.Anders S?gaard 2011.
Semisupervised condensed near-est neighbor for part-of-speech tagging.
In Proceed-ings of the 49th Annual Meeting of the Association ofComputational Linguistics.
pp.
48?52.Drahom?
?ra ?johanka?
Spoustova`, Jan Hajic?, Jan Raab,and Miroslav Spousta 2009.
Semi-supervised trainingfor the averaged perceptron POS tagger.
In Proceed-ings of the European Chapter of the Association forComputational Linguistics.
pp.
763?771.Amarnag Subramanya, Slav Petrov and Fernando Pereira2010.
Efficient Graph-Based Semi-Supervised Learn-ing of Structured Tagging Models.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing.
pp.
167?176.Xu Sun, Louis-Philippe Morency, Daisuke Okanoharaand Jun?ichi Tsujii 2008.
Modeling Latent-Dynamicin Shallow Parsing: A Latent Conditional Model withImproved Inference.
In Proceedings of the 22nd In-ternational Conference on Computational Linguistics.pp.
841?848.Kristina Toutanova, Dan Klein, Christopher D. Man-ning, and Yoram Singer.
2003.
Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network.1033In Proceedings of the Human Language Technologyand North American Chapter of the Association forComputational Linguistics.
pp.
252?259.Kristina Toutanova and Christopher D. Manning.
2000.Enriching the Knowledge Sources Used in a Maxi-mum Entropy Part-of-Speech Tagger.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing.
pp.
63?70.Ioannis Tsochantaridis, Thomas Hofmann, ThorstenJoachims, and Yasemi Altun.
2004.
Support Vec-tor Learning for Interdependent and Structured OutputSpaces.
In Proceedings of the 21st International Con-ference on Machine Learning.
pp.
104?111.Yoshimasa Tsuruoka and Jun?ichi Tsujii.
2005.
Bidi-rectional Inference with the Easiest-First Strategy forTagging Sequence Data.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing.
pp.
467?474.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1994.
Building a Large AnnotatedCorpus of English: The Penn Treebank.
Computa-tional Linguistics, Vol.
19, No.2 .
pp.
313?330.Qiuye Zhao and Mitch Marcus.
2009.
A Simple Un-supervised Learner for POS Disambiguation RulesGiven Only a Minimal Lexicon.
In Proceedings ofthe Conference on Empirical Methods in Natural Lan-guage Processing.
pp.
688?697.Zhi-Hua Zhou and Xu-Ying Liu 2006.
On Multi-ClassCost-Sensitive Learning.
In Proceedings of the AAAIConference on Artificial Intelligence.
pp.
567?572.1034
