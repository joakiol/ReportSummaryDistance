Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 379?386, Vancouver, October 2005. c?2005 Association for Computational LinguisticsDetection of Entity Mentions Occurring in English and Chinese TextKadri Hacioglu, Benjamin Douglas and Ying ChenCenter for Spoken Language ResearchUniversity of Colorado at Boulder{hacioglu,benjamin.douglas,yc}@colorado.eduAbstractIn this paper, we describe an integratedapproach to entity mention detection thatyields a monolithic, almost language in-dependent system.
It is optimal in thesense that all categorical constraints are si-multaneously considered.
The system iscompact and easy to develop and main-tain, since only a single set of features andclassifiers are needed to be designed andoptimized.
It is implemented using one-versus-all support vector machine (SVM)classifiers and a number of feature extrac-tors at several linguistic levels.
SVMsare well known for their ability to han-dle a large set of overlapping features withtheoretically sound generalization proper-ties.
Data sparsity might be an impor-tant issue as a result of a large numberof classes and relatively moderate train-ing data size.
However, we report re-sults that the integrated system performsas good as a pipelined system that decom-poses the problem into a few smaller sub-tasks.
We conduct all our experiments us-ing ACE 2004 data, evaluate the systemsusing ACE metrics and report competitiveperformance.1 IntroductionThe entity-relation (ER) model (Chen, 1976) viewsthe physical world as a collection of entities withcomplex relationships.
Automatic extraction ofthis model from raw text is important for creat-ing a knowledge base (such as relational databases,marked-up text etc.)
that can be used to achieve bet-ter end-to-end performances in several natural lan-guage processing (NLP) applications including in-formation retrieval, question answering and machinetranslation.
For example, in a typical QA system thisknowledge base can be used to facilitate extractionof answers and retrieval of relevant documents.Entities and relations in a document can be men-tioned in several different ways.
For example, a per-son entity, e.g.
Bill Clinton, can be expressed inmany different ways such as The President, Presi-dent Clinton, Mr. Clinton, he, him etc.
Similarly,one can express a geo-political entity, e.g.
UnitedStates, as his country or another person entity, e.g.Hillary Clinton, as his wife, and their relation to theentity Bill Clinton as ?president-of?
and ?family?,respectively.
It is clear that the detection of thesementions is the first crucial step for the extraction ofthe ER model to populate a database or an ontology.Extraction of entities and their relationships isusually done in a pipelined system that first iden-tifies entity mentions, next resolves mentions intounique entities (co-reference) and finally finds rela-tions among them (Florian et al, 2004; Kambhatla,2004).
In that architecture, the errors in the firststage propagate and reduce the performance of sub-sequent stages; namely, co-reference resolver, thatclusters all different mentions of an entity into aunique entity, and relation finder, that links entitiesaccording to their relationships.
In fact, the subtaskof entity mention detection itself is a very challeng-379Table 1: Categorical structure of entities in ACE programEntity MentionEntity MentionType Sub-Type Class Type Roleing subtask since respective expressions can haverelatively complex syntactic and categorical (?se-mantic?)
structures.
That is, entity mentions in abody of text can occur in relatively complex embed-ded constructs with many attributes.
Table 1 illus-trates the categorical structure of an entity mentionas specified in the Automatic Content Extraction(ACE) program run by NIST (ACE, 2004).
Com-pared to the previous years the number of entitytypes and subtypes is greater.The following segment of a sentence provides atypical example of the annotation:[The [[Jordanian] military] spokesman] added ...For simplicity, the entity mention attributes areexcluded.
The annotation clearly shows the em-bedded structure of entity mentions.
We identifythree entity mentions as The Jordanian militaryspokesman, Jordanian military and Jordanian.Due to its complex nature, it is not uncommon thatthe mention detection task itself is also divided intoa number of smaller sub-tasks.
However, in this pa-per, we adopt an integrated classification approachto this problem that yields a monolithic structure.This allows all attributes, which define the categori-cal (?semantic?)
structure of a mention, to be jointlyconsidered.
The system has the ability to achievebetter performance in principle provided that thereis ?enough?
data to train, is easier to maintain anddevelop, and has a single set of features and classi-fiers to be engineered.
All possible class labels areobtained by filling in the values of each attribute inthe label etype subtype class mtype role, where,to avoid confusion, etype and mtype are used to de-note entity and mention types, respectively.Our data representation requires segmenting doc-uments into sentences and then tokenizing sentencesinto words and punctuation.
Each word is then as-signed a label depending on its role in the mention.This data representation reduces the problem to atagging task.
For each token in focus, we create anumber of features at lexical, syntactic and semanticlevels.
Additionally, we augment those features us-ing features from external resources (e.g.
named en-tity taggers, gazetteers, wordnet).
We train a numberof one-versus-all classifiers (Allwein et.
al, 2000)using SVMs (Vapnik, 1995; Burges, 1998).
Duringtesting, classification of each token is performed ina greedy left-to-right manner using a finite-size slid-ing context window centered at the token in focus(Kudo and Matsumato, 2000).This approach yields a large number of classesand a large number of overlapping features.
We useda machine learning framework based on SVM clas-sification since a large number of classes (in a one-versus-all set-up) and a large number of overlappingfeatures can be easily handled with good general-ization properties.
We argue that data sparsity andcomputational complexity is not as severe as it mightbe expected in the other machine learning methodsthat are based on maximum likelihood parameter es-timation.
In other words, we claim that the large setof classification labels and training data sparsenessare not major drawbacks.
To provide evidence forthis we also consider an approach that divides thetask into relatively simpler tasks with considerablysmaller numbers of labels.
The approach yields apipelined structure in which the decisions in earlierstages are used in later stages.
We report results thatthe integrated approach performs similar to, and insome cases, even slightly better than the pipelinedstructure.We also implement a novel post-processingscheme based on an entity base (EB) created fromthe tagged test data.
This is motivated by the factthat an entity is identically referenced several timesin a document.
However, depending on the capital-ization information of the entity mention and contextin which it occurs, the entity can be missed at severalpositions in the document.
A simple postprocess-ing algorithm that checks untagged tokens with lowconfidence against the EB is implemented.
In doingso, it is highly likely that some of those missed en-tities could be identified.
This is expected to reducemisses at the expense of false alarms.
We report re-sults that support our expectation.The paper is organized as follows.
Section 2 de-scribes the ACE 2004 data used for training andevaluation.
In Section 3, the problem is explained380Table 2: ACE 2004 corpus statistics for English and Chinesetext.Language Train TestEnglish ?
150K words ?
50K wordsChinese ?
150K words ?
50K wordsand its data representation is introduced.
Section 4describes the general system architecture, that con-sists of a number of feature extractors, a (machine-learned) classifier and a simple post processor.
Insection 5, the features used for both English andChinese systems are described.
In section 6, we de-scribe an alternative pipelined system.
A novel postprocessing algorithm is introduced in section 7.
Sec-tion 8 reports experimental results.
Concluding re-marks are made in the final section.2 ACE DataThe ACE 2004 corpus consists of various text an-notated for entities and relations.
This corpus wascreated by the Linguistic Data Consortiom (LDC)in three languages: English, Chinese and Arabic(with support from the ACE program that began in1999).
Resources for data are newswire reports andbroadcast news programs.
Table 2 gives train andtest statistics of this corpus for English and Chineselanguages.
Both languages have almost the sameamount of data for both training and evaluation.3 Problem Description and DataRepresentationAs shown in Table 1, an entity mention is charac-terized along 5 dimensions; namely etype, sub-typeclass, mtype and role.
The ACE program speci-fies seven entity types; person, organization, geo-political, location, facility, vehicle, weapon.
All en-tity types except person are further divided into sev-eral sub-types.
For example, organization has gov-ernment, commercial, educational, non-prot andother as its sub-types.
The class attribute describesthe kind of reference the entity mention makes tothe entity in the world by taking one of the values{generic, specic, negative, under-specied} .
En-tity mentions are further characterized according tolinguistic types of references as name (proper noun),nominal (common noun), pronominal (pronoun) andpremodifier.
The role of entity mention applies onlyto geo-political entities indicating the role of the en-tity in the context of the mention as one of person,location, organization and geo-political.
For furtherdetails the reader is referred to (ACE, 2004)All entity mentions in the original data areXML tagged with their respective attributes.
Inaddition to the full extent of mentions, mentionheads are also tagged.
Referring to the previousexample, the entity mention ?The Jordanian militaryspokesman?
which refers to a PERSON has theword ?spokesman?
as its head.
Similarly, the entitymention ?Jordanian military?
which refers to anORGANIZATION has the word ?military?
as itshead.
If one reduces the problem of entity mentiondetection to the detection of its head, the natureof the problem changes and the annotation of databecomes flat;The [GPE Jordanian] [ORG military] [PERspokesman] .....This allows us to consider the problem as atagging/chunking problem and describe each wordas beginning (B) an entity mention, inside (I) anentity mention or outside (O) an entity mention(Ramhsaw and Marcus, 1995; Sang and Veenstra,1999).
However, we believe that the informationregarding the embedded structure in which theheads of entities occur is also useful for subse-quent stages of an IE system including inferenceof relations among heads occurring in the sameembedded construct.
So, in addition to the IOB tagswe introduce bracketing tags that might partiallyrecover the embedded structure surrounding theheads.
We refer to the following simple example[Javier Trevino] was [the campaign manager for[the [ruling party] candidate [Fox] beat ]].to illustrate our tokenwise vertical representa-tion:#SNT BEG#Javier B-PER NAMTrevino I-PER NAMwas O381LexicalAnalysisSyntacticAnalysisSemanticAnalysisExternalTaggers LookupResourceFeature CombinerDocuments PreprocessorSVMModelsTaggedDocumentsPostprocessorClassifierWordNetGazetteersFigure 1: System Architecturethe (*campaign *manager B-PER NOMfor *the (*ruling *party B-ORG NOMcandidate B-PER NOMFox B-PER NAMbeat *)).
O#SNT END#If one does not use the bracketing representation, allnon-head tokens will be labeled as ?Outside?.
Webelieve that it is useful to discriminate the tokens thattake part in mentions from those that do not occur inmentions.4 General System ArchitectureThe general system block diagram is illustrated inFigure 1.
It consists of a pre-processor, several fea-ture extractors, a classifier and a post-processingmodule.
Although the architecture is language in-dependent, there are some minor language specificdifferences in some modules depending on the na-ture of the language and availability of resources forthat language.
In the following, we briefly describeboth English and Chinese systems and indicate dif-ferences between them.In the English system, the pre-processor segmentsthe documents into sentences.
It also includes acaser that restores the capitalization information oftext without case (e.g.
broadcast news) and a to-kenizer that separates contractions and punctuationfrom words.
Tokenized sentences are then processedat different linguistic levels to create features.
Atthis stage, we employ a lexical pattern analyzer,part-of-speech tagger, a base phrase chunker, a syn-tactic parser, a dependency analyzer, look-up inter-faces to external knowledge sources, and externalsmall scale named entity taggers trained on differentgenres of text with different machine learning algo-rithms.
All features are combined and then input toa classifier based on one-versus-all SVM classifiers.Finally, we perform simple post-processing to makesure that the final bracketing information is consis-tent.The POS tagger and BP chunker are trainedin-house using the Penn TreeBank.
The syntac-tic parser is the Charniak parser which has mod-els trained on the Penn TreeBank.
The depen-dency analyzer performs dependency analysis usinga set of head rules.
The software was generouslymade available to us by the University of Maryland.The look-up interface to external knowledge sourcessuch as WordNet or gazetteers is implemented usingsimple pattern matching.In the Chinese system, the pre-processor isslightly different from that of the English system.It (obviously) does not need a caser and consid-ers single Chinese characters as the minimal unitsof processing.
It jointly segments a documentinto sentences and words.
Then, it passes bothword and sentence segmentation information to thesubsequent stages along with Chinese characters.The SVM-based joint sentence/word segmenter istrained using the Chinese TreeBank (CTB).
Linguis-382tic analysis at different levels is performed in a man-ner similar to the analysis in the English system.In the Chinese system, the CTB is used to traina SVM-based POS tagger and BP chunker.
Thesyntactic parser is trained on the CTB using DanBikel?s parser.
Dependency analysis is performedas in the English system using a set of Chinese headrules.
Several in-house external taggers are trainedusing SVMs and different corpora.
We have usedonly gazetteers for chinese as external knowledgesources.5 FeaturesThe following features are used in the English sys-tem:?
tokens: words in their original and all lower-cased forms?
n-grams: token prefixes and suffixes of lengthless than and equal to four?
lexical patterns: indicate case information(all lower-case, mixed case, first letter capital,all upper-case), is hyphen, type (numeral, al-phanumeral, alpha, other)?
Part of Speech tags?
BP Positions: The position of a token in a BPusing the IOB representation (e.g.
B-NP, I-NP,O etc.)?
Clause tags: The tags that mark token posi-tions in a sentence with respect to clauses.
(e.g*S)*S) marks a position that two clauses end)?
Named entities-1: The IOB tags of named en-tities.
There are four categories; LOC, ORG,PERSON and MISC.
A SVM-based taggerwhich is trained on CoNLL 2003 shared taskdata is used.?
Named entities-2: IOB tags of named enti-ties found by the Identifinder (Bikel et.
al,1999); a HMM-based named entity tagger with29 classes?
Named entities-3: IOB tags from a named en-tity tagger trained on MUC-6 and MUC-7 datausing only the entity classes PERSON, LOCA-TION and ORGANIZATION.?
Gazetteer labels: indicate the name of the listto which the token belongs.
Simple patternmatching is employed here.?
WordNet categories: concepts or class namesin the WordNet 2.0 hypernym hierarchy rootedat ?entity?
concept.
We trace hypernym hier-archies of the two most frequent senses of to-kens that are tagged as nouns (NN, NNS, NNPetc.)
to the top concepts.
We count the num-ber of concepts (that match to ACE entity typesand subtypes) that occur in the hypernym hier-archy indicating that token is a (kind of) con-cept.
The concepts (i.e entity/types/subtypes)with the maximum counts in the top two sensesare selected as features (can also be consideredas ?maybe?
labels)?
Syntactic tags: patterns of non-terminals andbrackets that indicate the position of tokens insyntactic trees.?
Head words: words that the tokens depend?
POS of Head words:?
main verb: the verb at which the dependencyparse tree is rooted.?
Relations: the grammatical and semantic rela-tions between tokens and their heads.?
Head word flag: indicates whether the tokenplays a role of head in the sentence.The features used in the Chinese system are?
tokens: Chinese characters?
token positions: IOB tags that indicate posi-tion of characters in words?
Part of Speech tags: POS tags of words towhich tokens (characters) belong?
BP Positions: The position of a token in a BPusing the IOB representation (e.g.
B-NP, I-NP,O etc.)?
Named entities-1: IOB tags of two type of en-tities; location and person.
A SVM based tag-ger trained on part of the Sinica corpus fromTaiwan is used to generate these features.383?
Named entities-2: IOB tags of named enti-ties: person, location, organization etc.
An-other SVM based tagger trained on the PeopleDaily data from mainland of China.?
Gazetteer labels: indicate the name of the listto which the token belongs.
Simple patternmatching is employed here.
Examples are la-bels that indicate Chinese last name, foreignperson last name, first name etc.?
Syntactic labels: base phrase chunk labels andpaths in syntactic trees?
Head words: as determined by Chinese depen-dency analysis?
POS of Head words:?
Relations: the grammatical and semantic rela-tions between tokens and their heads.6 A Pipelined SystemAs mentioned earlier the structure of entity men-tion categories is very complex.
Considering all at-tributes together yields a large number of classes.One can argue that the large number of classes anddata sparsity is an important issue here that it mighthave significant effect on performance.
However,several attempts to divide the task into simpler sub-tasks have failed to yield a system with a better per-formance than that of the integrated system.
In thissection, we describe one such system.The system consists of three stages in cascade: (i)entity mention extent detector, , (ii) mention type de-tector and (iii) entity type, subtype and mention roledetector.
Referring to the earlier example, the datarepresentation in terms of class labels at each levelis as follows:#SNT BEG#Javier (* B-NAM PERTrevino *) I-NAM PERwas O O Othe (* O Ocampaign * O Omanager * B-NOM PERfor * O Othe (* O Oruling (* O Oparty *) B-NOM ORGcandidate *) B-NOM PERFox * B-NAM PERbeat *)) O O. O O O#SNT END#where the second column is for the extent labels ofmentions in bracketed representation, the third col-umn is for the mention type labels in IOB represen-tation and the last column is for the type labels (sub-type and role labels are omitted for the sake of sim-plicity) of entity mentions in plain representation.The pipelined system operates as follows.
First itdetects embedding structure of mention extents.
Us-ing that information the second stage identifies thetype of mentions.
In the final stage, the system iden-tifies entity types, subtypes and mention roles usinginformation (as features within context) from previ-ous stages.
Finally we combine all information intoentity mention attributes and resolve inconsistenciesby simple postprocessing.Here, we have not done any feature selection spe-cific to each stage.
Instead we used the same fea-tures in all stages.
One can argue that this is not theoptimal set up for a cascaded system; separate fea-ture design and selection should be made for eachstage.
Also we acknowledge that there are severalother ways of dividing the task into smaller, simplersubtasks.
Although we have not explored all pos-sible pipelined architectures with all possible fea-ture selections , we conjecture that the data sparsityis not as big an issue in SVMs as expected to bein the other machine learning algorithms based onmaximum likelihood parameter estimation such asthose based on maximum entropy (ME) or condi-tional random fields (CRF) frameworks.7 A Novel Post-Processing MethodIn our experiments, we have consistently observedthat the identical mentions of a unique entity aremissed depending on the missing capitalization in-formation, unseen context and errors in feature ex-traction.
For example, although the name mentionof person ?Eminem?
is captured at several positionsin the document, the entity mention ?eminem?
ismissed, probably, due to its missing capitalization.384Table 3: Statistics on ACE 2004 data.Language Train Samples Test Samples # Joint Classes # Pipelined ClassesExtent MType EType-SubTypey-RoleEnglish ?
167K ?
61K 384 24 9 93Chinese ?
307K ?
105K 374 15 7 95As a solution we propose a post-processingmethod that is based on an entity base (EB) cre-ated from the tagged text.
We populate the EB withall entity mentions (particularly with those that havename values) identified in the text.
After we createthe EB, we tag the text again by case insensitive pat-tern matching.
We determine all tagged tokens thatwere initially left untagged or tagged with a differ-ent label by the SVM classifier.
Using the SVM out-put (distance from separating hyperplane) as a confi-dence measure, we accept or reject the new tag basedon a preselected threshold.8 Experiments and ResultsIn this section, we describe the experiments con-ducted and results obtained using the ACE 2004data.
The number of training and test examples,which are words/punctuations in English and char-acters in Chinese, are summarized in Table 3.
Thenumber of classes in the joint task and in eachpipelined subtask are also included.In the first set of experiments we evaluated ourintegrated system and investigated the performancewith respect to broad classes of features introducedin section 5, by adding one group of features at atime.
Grouping of features into broad classes weredone as follows:?
baseline features: tokens?
lexical features: POS, lexical patterns?
syntactic features: base phrase chunks, syntac-tic tree features?
?semantic?
features: heads and grammatical re-lations?
external features: features from external re-sources; e.g.
wordnet, gazetteers, other entitytaggers etc.Table 4: English system performance with respect to broadclasses of features; lex: lexical features, syn: syntactic fea-tures, sem: ?semantic?
features, ext: external features, Fuw:unweighted F-score, Fw: weighted F-score, ACE: ACE value.Feature class Fuw Fw ACEbaseline (tokens) 56.5 54.8 36.1baseline+lex 76.8 86.7 75.6baseline+lex+syn 76.9 87.4 76.8baseline+lex+syn+sem 77.1 87.8 77.6baseline+lex+syn+sem+ext 82.0 90.7 82.9The results are summarized in Table 4 and Table5 for both English and Chinese systems.
Both un-weighted and weighted F-scores, and also ACE val-ues are reported.
It is interesting to note that sig-nificant gains were achieved by simple lexical andexternal features when they are added.
The degreeof improvement by using computationally intensivesyntactic and dependency analysis is marginal.
Thismight partly be due to the type of features derivedfrom parse trees and partly due to the mismatch ofthe genre of text to the text on which the syntacticchunker and parser is trained.
Since the dependencyanalysis is based on the syntactic analysis using aset of head rules, the extracted dependency basedfeatures might also be inaccurate.
Although weobserved moderate improvement for English, thosefeatures slightly hurt the performance of the Chinesesystem.
This is because of the fact that the Chinesesyntactic parser performs relatively worse than theEnglish syntactic parser.Table 6 presents the integrated and pipelined sys-tem performances using all features extracted forEnglish and Chinese.
Post-processing results arealso included.
It shows notable performance im-provement with the recovery of many misses bypost-processing.
It should be noted that, in thepipelined architecture the post-processing is per-formed twice; at both mention and entity levels.385Table 5: Chinese system performance with respect to broadclasses of features; lex: lexical features, syn: syntactic fea-tures, sem: ?semantic?
features, ext: external features, Fuw:unweighted F-score, Fw: weighted F-score, ACE: ACE value.Feature class Fuw Fw ACEbaseline (tokens) 77.6 83.5 70.8baseline+lex 78.3 85.2 73.4baseline+lex+syn 76.1 83.7 70.8baseline+lex+syn+sem 74.8 83.6 70.8baseline+lex+syn+sem+ext 78.4 86.8 76.19 ConclusionsWe have discussed the significance of the entitymention detection in ER model extraction fromraw text and presented the complex syntactic andcategorical structure of the entity mentions speci-fied in the ACE program.
We have explored dif-ferent ways of representing the problem and im-plemented two architecturally different (supervised)machine-learning based systems to accomplish thetask; namely, a monolithic system and a cascadedsystem.
We have described those systems in detailand empirically compared them.
Both systems haveachieved comparable performances on English text.However, the integrated system has achived moder-ately better performance on Chinese text.
We haveargued that it is easier to develop and maintain themonolithic system since it has a single set of featuresand classifiers to be tuned.
We believe that the per-formance levels achieved at mid 80s (in ACE values)for English and at upper 70s for Chinese, using onlythe ACE data, are competitive.
We have introduceda post-processing algorithm based on an entity basecreated during the testing.
It has worked very wellfor both languages to recover several missed en-tity mentions and considerably improved the perfor-mance.10 AcknowledgementWe extend our special thanks to Wayne Ward,Steven Bethard, James H. Martin and Dan Juraf-sky for their useful feedback during this work.
Thiswork is supported by the ARDA Aquaint II Programvia contract NBCHC040040.Table 6: English and Chinese system performances with allfeatures and post-processing: Fuw: unweighted F-score, Fw:weighted F-score, ACE: ACE value.English System Fuw Fw ACEIntegrated 82.0 90.7 82.9Pipelined 82.1 90.8 83.1Integrated+Post 82.2 91.5 84.3Pipelined+Post 82.3 91.3 84.0Chinese SystemIntegrated 78.4 86.8 76.1Pipelined 76.9 85.7 74.1Integrated+Post 79.6 87.7 77.5Pipelined+Post 79.1 86.6 75.6ReferencesE.
L. Allwein, R. E Schapire and Y.
Singer.
2000.
Re-ducing multiclass to binary: A unifying approach formargin classifiers.
Journal of Machine Learning Re-search, 1:113-141,Dan M. Bikel, Robert L. Schwartz, and Ralph M.Weischedel.
1999 An algorithm that learns what?sin a name.
Machine Learning, Vol.
34, pp.
211-231.Chiristopher J. C. Burges 1998.
Tutorial on Support Vec-tor Machines for Pattern Recognition.
Data Miningand Knowledge Discovery, 2(2), pages 1-47.Peter P. Chen 1976.
The Entity-Relationship Model:Toward a Unified View of Data.
ACM Trans.
onDatabase Systems, Vol.
1, No.
1, pages 1-36.R.
Florian, H. Hassan, A. Ittycheriah, H. Jing, N. Kamb-hatla, X. Luo, N. Nicolov, and S. Roukos.
2004.
AStatistical Model for Multilingual Entity Detection andTracking.
Proceedings of HLT-2004.Nanda Kambhatla.
2004.
Combining Lexical Syntacticand Semantic Features with Maximum Entropy Mod-els for Extracting Relations.
Proceedings of ACL-04.Taku Kudo and Yuji Matsumato.
2000.
Use of supportvector learning for chunk identification.
Proc.
of the4th Conference on Very Large corpora, pages 142-144.Lance E. Ramhsaw and Mitchel P. Marcus.
1995.Text Chunking Using Transformation Based Learning.Proceedings of the 3rd ACL Workshop on Very LargeCorpora, pages 82-94.Erik F. T. J. Sangand and Jorn Veenstra 1999.
Repre-senting text chunks.
Proceedings of EACL?99, pages173-179.The Automatic Content Extraction (ACE) EvaluationPlan.
2004. www.nist.gov/speech/tests/ace/Vladamir Vapnik.
1995.
The Nature of Statistical Learn-ing Theory.
Springer Verlag, New York, USA.386
