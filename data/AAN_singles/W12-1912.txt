NAACL-HLT Workshop on the Induction of Linguistic Structure, pages 90?95,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsInduction of Linguistic Structure with Combinatory Categorial GrammarsYonatan Bisk and Julia HockenmaierDepartment of Computer ScienceUniversity of Illinois at Urbana-Champaign201 N Goodwin Ave. Urbana IL, 61801{bisk1,juliahmr}@illinois.eduAbstractOur system consists of a simple, EM-basedinduction algorithm (Bisk and Hockenmaier,2012), which induces a language-specificCombinatory Categorial grammar (CCG) andlexicon based on a small number of linguisticprinciples, e.g.
that verbs may be the roots ofsentences and can take nouns as arguments.1 IntroductionMuch of the recent work on grammar induction hasfocused on the development of sophisticated statisti-cal models that incorporate expressive priors (Cohenand Smith, 2010) or linguistic universals (Naseem etal., 2010; Boonkwan and Steedman, 2011) that haveall been shown to be very helpful.
But, with somenotable exceptions, such as (Cohn et al, 2011),the question of what underlying linguistic represen-tation to use has received considerably less atten-tion.
Our induction algorithm is based on Com-binatory Categorial Grammar (Steedman, 2000), alinguistically expressive, lexicalized grammar for-malism which associates words with rich syntacticcategories that capture language-specific facts aboutbasic word order and subcategorization.
WhileBoonkwan and Steedman (2011) have shown thatlinguists can easily devise a language-specific in-ventory of such categories that allows a parser toachieve high performance in the absence of anno-tated training data, our algorithm automatically dis-covers the set of categories it requires to parse thesentences in the training data.2 Combinatory Categorial Grammar(CCG)The set of CCG categories is built recursively fromtwo atomic types, S (sentence) and N (noun).
Com-plex types are of the form X/Y or X\Y, and repre-sent functions which combine with an argument oftype Y to yield a constituent of type X as result.
Theslash indicates whether the Y precedes (\) or follows(/) the functor.
An English lexicon should containcategories such as S\N and (S\N)/N for verbs: bothtransitive and intransitive verbs subcategorize for apreceding subject, and the transitive verb addition-ally takes an object to its right.
In this manner,the argument slots of lexical categories also defineword-word dependencies between heads and theirarguments (Clark and Hockenmaier, 2002; Hocken-maier and Steedman, 2007).
Modifiers are gener-ally of the form X|X: in English, pre-nominal adjec-tives are N/N, whereas adverbs may be (N/N)/(N/N),S/S, or S\S, and prepositions can have categoriessuch as (N\N)/N or (S\S)/N.
That is, CCG assumesthat the direction of the corresponding dependencygoes from the modifier to the head.
This discrep-ancy between CCG and most other analyses can eas-ily be removed under the assumption that all cate-gories of the form X|X are modifiers whose depen-dencies should be reversed when comparing againstother frameworks.Adjacent constituents can be combined accordingto a small, universal set of combinatory rules.
Forthe purposes of this work we restrict ourselves tofunction application and B1 composition:X/Y Y ?
X (>)90Y X\Y ?
X (<)X/Y Y|iZ ?
X|iZ (B1>)Y|iZ X\Y ?
X|iZ (B1<)Here the slash variable |i can be instantiated witheither the forward or backward slash.These rules allow derivations (parses) such as:The man ate quicklyDT NNS VBD RBN/N N S\N S\S> <BN S\N<SCCG also has unary type-raising rules of the formX ?
T/(T\X) ( >T)X ?
T\(T/X) ( <T)We only allow nouns to be type-raised, and imposethe restriction that the argument T\N (or T/N) of thetype-raised category has to already be present in thelexicon of the language.This restricted set of combinatory rules providessufficient power for reasonable parse accuracy butdoes not allow us to capture non-projective (cross-ing) dependencies.Coordination is handled by a ternary ruleX conj X ?
X (>)which we binarize as:X X[conj] ?
X (< &)conj X ?
X[conj] (> &)Punctuation, when present, can be absorbed byrules of the formX Pct ?
X (< p)Pct X ?
X (> p)The iterative combination of these categories re-sulting in S or N is considered a successful parse.
Inorder to avoid spurious ambiguities, we restrict ourderivations to be normal-form (Hockenmaier andBisk, 2010).3 An algorithm for unsupervised CCGinductionWe now describe our induction algorithm, whichconsists of two stages: category induction (creationof the grammar), followed by parameter estimationfor the probability model.3.1 Category inductionWe assume there are two atomic categories, N (nounsor noun phrases) and S (sentences), a special con-junction category conj, and a special start symbolTOP.
We assume that all strings we encounter areeither nouns or sentences:N?
TOP S?
TOPWe also assume that we can group POS-tags intofour groups: nominal tags, verbal tags, conjunctions,and others.
This allows us to create an initial lexiconL(0), which only contains entries for atomic cate-gories, e.g.
for the English Penn Treebank tag set(Marcus et al, 1993):N : {NN,NNS,NNP,PRP,DT}S : {MD,VB,VBZ,VBG,VBN,VBD}conj : {CC}We force any string that contains one or more verbs(besides VBG in English), to be parsed with the S?TOP rule.Since the initial lexicon would only allow usto parse single word utterances (or coordinationsthereof), we need to induce complex functor cat-egories.
The lexicon entries for atomic categoriesremain, but all POS-tags, including nouns and con-junctions, will be able to acquire complex categoriesduring induction.
We impose the following con-straints on the lexical categories we induce:1.
Nouns (N) do not take any arguments.2.
The heads of sentences (S|...) and modifiers(X|X, (X|X)|(X|X)) may take N or S as arguments.3.
Sentences (S) may only take nouns (N) as argu-ments.
(We assume S\S and S/S are modifiers).4.
Modifiers (X/X or X\X) can be modifiedby categories of the form (X/X)|(X/X) or(X\X)|(X\X).5.
The maximal arity of any lexical category is 3.6.
Since (S\N)/N is completely equivalent to(S/N)\N, we only allow the former category.Induction is an iterative process.
At each stage,we aim to parse all sentences Si in our training cor-pus D = {S1, ...., SD} with the current lexicon91L(t).
In order to parse a sentence S = w0...wn, allwords wi ?
S need to have lexical categories that al-low a complete parse (resulting in a constituent TOPthat spans the entire sentence).
Initially, only somewords will have lexical categories:The man ate quicklyDT NNS VBD RB- N S -We assume that any word may modify adjacent con-stituents:The man ate quicklyDT NNS VBD RBN/N N, S/S S, N\N S\SWe also assume that any word that previously hada category other than N (which we postulate doesnot take any arguments) can take any adjacent non-modifier category as argument, leading us here tointroduce S\N for the verb:The man ate quicklyDT NNS VBD RBN/N N, S/S S, N\N, S\N S\SWith these categories, we obtain the correct parse:The man ate quicklyDT NNS VBD RBN/N N S\N S\S> <BN S\N<SWe then update the lexicon with all new tag-categorypairs that have been found, excluding those that didnot lead to a successful parse:N/N : {DT} S\N : {VBD,VBZ} S\S : {RB,NNS,IN}The first stage of induction can only introduce func-tors of arity 1, but many words, such as prepositionsor transitive verbs, require more complex categories,leading us to complete, but incorrect parses such asThe man eats with friendsDT NNS VBZ IN NNSN/N N S\N S\S S\S> <BN S\N<BS\N<SDuring the second iteration, we can discover addi-tional simple, as well as more complex, categories.We now discover transitive verb categories:The man ate chipsDT NNS VBD NNSN/N N (S\N)/N N> >N S\N<SThe second stage also introduces a large numberof complex modifiers of the form (X/X)|(X/X) or(X\X)|(X\X), e.g.
:The man ate very quicklyDT NNS VBD RB RBN/N, N, S/S S, N\N, S\S, S\S,(S/S)/(S/S) (N\N)/(N\N) S\N (S\S)/(S\S) (S\S)\(S\S)(N/N)\(N/N) (S/S)\(S/S) (N\N)\(N\N)(S\S)/(S\S)The final induction step takes adjacent constituentsthat can be derived from the existing lexicon intoaccount.
This allows us to induce (S\S)/N for IN,since we can combine a and friend to N.3.2 Parameter estimationAfter constructing the lexicon, we parse the trainingcorpus, and use the Inside-Outside algorithm (Lariand Young, 1991), a variant of the Expectation-Maximization algorithm for probabilistic context-free grammars, to estimate model parameters.
Weuse the baseline model of Hockenmaier and Steed-man (2002), which is a simple generative model thatis equivalent to an unlexicalized PCFG.
In a CFG,the set of terminals and non-terminals is disjoint, butin CCG, not every category can be lexical.
Sincethis model is also the basis of a lexicalized modelthat captures dependencies, it distinguishes betweenlexical expansions (which produce words), unary ex-pansions (which are the result of type-raising or theTOP rules), binary expansions where the head is theleft child, and binary expansions whose head is theright child.
Each tree is generated top-down from thestart category TOP.
For each (parent) node, first itsexpansion type exp ?
{Lex,Unary,Left,Right} isgenerated.
Based on the expansion type, the modelthen produces either the word w, or the category ofthe head child (H), and, possibly the category of thenon-head sister category (S):92Lexical pe(exp=Lex | P)?
pw(w | P, exp=Lex)Unary pe(exp=Unary | P)?
pH(H | P, exp=Unary)Left pe(exp=Left | P)?
pH(H | P, exp=Left)?
pS(S | P,H, exp=Left)Right pe(exp=Right | P)?
pH(H | P, exp=Right)?
pS(S | P,H, exp=Right)3.3 Dependency generationWe use the following regime for generating depen-dencies from the resulting CCG derivations:1.
Arguments Y are dependents of their heads X|Y2.
Modifiers X|X are dependents of their heads Xor X|Y.3.
The head of the entire string is a dependent ofthe root node (0)4.
Following the CoNLL-07 shared task represen-tation (Johansson and Nugues, 2007), we ana-lyze coordinations (X1 conj X2) as creating adependency from the first conjunct, X1, to theconjunction conj, and from conj to the sec-ond conjunct X2.In the case of parse failures we return a right-branching dependency tree.3.4 Training detailsThe data provided includes fine, coarse and univer-sal part-of-speech tags.
Additionally, the data wassplit into train, test and development sets though theorganizers encouraged merging the data for train-ing.
Finally, while punctuation was present, it wasnot evaluated but potentially provided an additionalsource of signal during training and test.
We chosefrom among these options and maximum sentencelength based on performance on the developmentset.
We primarily focused on training with shortersentences but grew the dataset if necessary or if, asis the case in Arabic, there was very little short sen-tence data.
Our final training settings were:Language Tags Max Len PuncArabic Fine 40 XBasque Coarse 20Childes Fine 20 XCzech Fine 10Danish Fine 20 XDutch Fine 10 XSlovene Fine 10 XSwedish Fine 15PTB Fine 10Portuguese Fine 10In the case of Czech, we only trained on the test-set because the data set was so large and the resultsfrom randomly downsampling the merged datasetwere equivalent to simply using the previously de-fined test-set.3.5 Future directionsSince our current system is so simple, there is amplespace for future work.
We plan to investigate theeffect of more complex statistical models and priorsthat have been shown to be helpful in dependencygrammar-based systems.
We also wish to relax theassumption that we know in advance which part-of-speech tags are nouns, verbs, or conjunctions.4 Final observations regarding evaluationAlthough the analysis of constructions involving ba-sic head-argument and head-modifier dependenciesis generally uncontroversial, many common con-structions allow a number of plausible analyses.This makes it very difficult to evaluate and comparedifferent unsupervised approaches for grammar in-duction.
The corpora used in this workshop alsoassume different conventions for a number of con-structions.
Figure 1 shows the three different typesof analysis for coordination adopted by the corporaused in this shared task (as well as the standardCCG analysis).
The numbers to the side indicatefor each corpus what percentage of our system?s er-ror rate is due to missed dependencies within coor-dinated structures (i.e between a conjunction and aconjunct, or between two conjuncts).
It is importantto note that the way in which we extract dependen-cies from coordinations is somewhat arbitrary (andcompletely independent of the underlying probabil-ity model, which currently captures no explicit de-93WILS-12Ar 25.5%Eu 22.6%???
?????
???
??????
?Childes 7.7%Cz 21.4%Da 13.1%Nl 15.3%PTB 18.1%???
?????
???
??????
?WILS-12Sl 17.2%Sv 11.1%???
?????
???
??????
?WILS-12 & CoNLL-07Pt 7.8%???
?????
???
??????
?Standard CCGFigure 1: Different analyses of coordination in thevarious corpora used in this shared task.
Our sys-tem adopts the CoNLL-07 convention, instead of thestandard CCG analysis.
For the development set ofeach corpus, we also indicate what percentage of theerrors our system makes is due to missed coordina-tion dependencies.pendencies).
These systematic differences of anal-ysis are also reflected in our final results.
The onlyexception is the Childes corpus, where coordinationis significantly rarer.However, this is a general problem.
There aremany other constructions for which no agreed-uponstandard exists.
For example, the Wall Street Journaldata used in this shared task assumes a dependencybetween the verb of the main clause and the verb ofa subordinate clause, whereas the CoNLL-07 anal-ysis stipulates a dependency between the main verband the subordinating conjunction:????????????????????????????????????????????????????????????????????????????
(a) CoNLL-07????????????????????????????????????????????????????????????????????????????
(b) WILS-12We therefore believe that much further work isrequired to address the problems surrounding eval-uation and comparison of unsupervised inductionsystems adequately.
Even if the community can-not agree on a single gold standard, systems shouldnot be penalized for producing one kind of linguisti-cally plausible analysis over another.
The systematicdivergences that arise with coordination for our ap-proach are relatively easy to fix, since we only needto change the way in which we read off dependen-cies.
But this points to a deeper underlying problemthat affects the entire field.AcknowledgementsThis research is supported by the National ScienceFoundation through CAREER award 1053856 andaward 0803603.ReferencesYonatan Bisk and Julia Hockenmaier.
2012.
Simple Ro-bust Grammar Induction with Combinatory CategorialGrammars.
In Association for the Advancement of Ar-tificial Intelligence.Prachya Boonkwan and Mark Steedman.
2011.
Gram-mar Induction from Text Using Small Syntactic Pro-totypes.
In International Joint Conference on NaturalLanguage Processing, pages 438?446, November.Stephen Clark and Julia Hockenmaier.
2002.
Evaluatinga wide-coverage CCG parser.
In Proceedings of theLREC Beyond PARSEVAL workshop, page 2002, LasPalmas, Spain.S.
B. Cohen and N. A. Smith.
2010.
Covariance in unsu-pervised learning of probabilistic grammars.
Journalof Machine Learning Research, 11:3017?3051.Trevor Cohn, Phil Blunsom, and Sharon Goldwater.2011.
Inducing tree-substitution grammars.
Jour-nal of Machine Learning Research, pages 3053?3096,November.Julia Hockenmaier and Yonatan Bisk.
2010.
Normal-form parsing for Combinatory Categorial Grammarswith generalized composition and type-raising.
InCOLING.Julia Hockenmaier and Mark Steedman.
2002.
Gen-erative models for statistical parsing with Combina-tory Categorial Grammar.
In Association for Compu-tational Linguistics, pages 335?342.Julia Hockenmaier and Mark Steedman.
2007.
CCG-bank: a corpus of CCG derivations and dependencystructures extracted from the Penn Treebank.
Compu-tational Linguistics, pages 355?396, January.94Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for english.
InProceedings of NODALIDA 2007, Tartu, Estonia.K Lari and S Young.
1991.
Applications of stochasticcontext-free grammars using the inside-outside algo-rithm.
Computer speech & language, 5(3):237?257,January.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguistics, 19(2):313?330.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowledgeto guide grammar induction.
In Empirical Methods inNatural Language Processing, pages 1234?1244, Oc-tober.Mark Steedman.
2000.
The syntactic process.
MITPress, January.95
