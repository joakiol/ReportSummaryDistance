Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 105?112Manchester, August 2008Regenerating Hypotheses for Statistical Machine TranslationBoxing Chen, Min Zhang, Aiti Aw and Haizhou LiDepartment of Human Language TechnologyInstitute for Infocomm Research21 Heng Mui Keng Terrace, 119613, Singapore{bxchen, mzhang, aaiti, hli}@i2r.a-star.edu.sgAbstractThis paper studies three techniques thatimprove the quality of N-best hypothesesthrough additional regeneration process.Unlike the multi-system consensus ap-proach where multiple translation sys-tems are used, our improvement isachieved through the expansion of the N-best hypotheses from a single system.
Weexplore three different methods to im-plement the regeneration process: re-decoding, n-gram expansion, and confu-sion network-based regeneration.
Ex-periments on Chinese-to-English NISTand IWSLT tasks show that all threemethods obtain consistent improvements.Moreover, the combination of the threestrategies achieves further improvementsand outperforms the baseline by 0.81BLEU-score on IWSLT?06, 0.57 onNIST?03, 0.61 on NIST?05 test set re-spectively.1 IntroductionState-of-the-art Statistical Machine Translation(SMT) systems usually adopt a two-pass searchstrategy (Och, 2003; Koehn, et al, 2003) asshown in Figure 1.
In the first pass, a decodingalgorithm is applied to generate an N-best list oftranslation hypotheses, while in the second pass,the final translation is selected by rescoring andre-ranking the N-best translations through addi-tional feature functions.
The fundamental as-sumption behind using a second pass is that thegenerated N-best list may contain better transla-?
2008.
Licensed under the Creative Commons Attri-bution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.tions than the best choice found by the decoder.Therefore, the performance of a two-pass SMTsystem can be improved from two aspects, i.e.scoring models and the quality of the N-best hy-potheses.Rescoring pass improves the performance ofmachine translation by enhancing the scoringmodels with more global sophisticated and dis-criminative feature functions.
The idea for apply-ing two passes instead of one is that some globalfeature functions cannot be easily decomposedinto local scores and computed during decoding.Furthermore, rescoring allows some feature func-tions, such as word and n-gram posterior prob-abilities, to be estimated on the N-best list (Uef-fing, 2003; Chen et al, 2005; Zens and Ney,2006).In this two-pass method, translation perform-ance hinges on the N-best hypotheses that aregenerated in the first pass (since rescoring occurson these), so adding the translation candidatesgenerated by other MT systems to these hypothe-ses could potentially improve the performance.This technique is called system combination(Bangalore et al, 2001; Matusov et al, 2006;Sim et al, 2007; Rosti et al, 2007a; Rosti et al,2007b).We have instead chosen to regenerate new hy-potheses from the original N-best list, a tech-nique which we call regeneration.
Regenerationis an intermediate pass between decoding andrescoring as depicted in Figure 2.
Given theoriginal N-best list (N-best1) generated by thedecoder, this regeneration pass creates new trans-lation hypotheses from this list to form anotherN-best list (N-best2).
These two N-best lists arethen combined and given to the rescoring pass toderive the best translation.We implement three methods to regeneratenew hypotheses: re-decoding, n-gram expansionand confusion network.
Re-decoding (Rosti et al,2007a) based regeneration re-decodes the sourcesentence using original LM as well as new trans-105lation and reordering models that are trained onthe source-to-target N-best translations generatedin the first pass.
N-gram expansion (Chen et al,2007) regenerates more hypotheses by continu-ously expanding the partial hypotheses throughan n-gram language model trained on the originalN-best translations.
And confusion network gen-erates new hypotheses based on confusion net-work decoding (Matusov et al, 2006), where theconfusion network is built on the original N-besttranslations.Confusion network and re-decoding have beenwell studied in the combination of different MTsystems (Bangalore et al, 2001; Matusov et al,2006; Sim et al, 2007; Rosti et al, 2007a; Rostiet al, 2007b).
Researchers have used confusionnetwork to compute consensus translations fromthe outputs of different MT systems and improvethe performance over each single systems.
(Rostiet al, 2007a) also used re-decoding to do systemcombination by extracting sentence-specificphrase translation tables from the outputs of dif-ferent MT systems and running a phrase-baseddecoding with this new translation table.
Finally,N-gram expansion method (Chen et al, 2007)collects sub-strings occurring in the N-best list toproduce alternative translations.This work demonstrates that a state-of-the-artMT system can be further improved by means ofregeneration which expands its own N-besttranslations other than taking the translation can-didates from the other MT systems.Figure 1: Structure of a typical two-pass ma-chine translation system.
N-best translations aregenerated by the decoder and the 1-best transla-tion is returned after rescored with additionalfeature functions.Figure 2: Structure of a three-pass machinetranslation system with the new regenerationpass.
The original N-best translations list (N-best1) is expanded to generate a new N-besttranslations list (N-best2) before the rescoringpass.2 SMT ProcessPhrase-based statistical machine translation sys-tems are usually modeled through a log-linearframework (Och and Ney, 2002).
By introducingthe hidden word alignment variable a  (Brown etal., 1993), the optimal translation can besearched for based on the following criterion:*1,arg max( ( , , ))Mm mme ae h?== e f a?
            (1)where  is a string of phrases in the target lan-guage,eff ais the source language string ofphrases,  h e  are feature functions,weights( , , )mm?
are typically optimized to maximizethe scoring function (Och, 2003).Our MT baseline system is based on Mosesdecoder (Koehn et al, 2007) with word align-ment obtained from GIZA++ (Och et al, 2003).The translation model (TM), lexicalized wordreordering model (RM) are trained using thetools provided in the open source Moses package.Language model (LM) is trained with SRILMtoolkit (Stolcke, 2002) with modified Kneser-Ney smoothing method (Chen and Goodman,1998).3 Regeneration MethodsGiven the original N-best translations, regenera-tion pass is to generate M new target translationswhich are not seen in the original N-best choices.3.1 Regeneration with Re-decodingOne way of regeneration is by running the de-coding again to obtain new hypotheses through are-decoding process (Rosti et al, 2007a).
In thiswork, the same decoder (Moses) is used to pro-duce the new M-best translations using a newtranslation model and reordering model trainedover the word-aligned source input and originalN-best target hypotheses.
Although the target-to-source phrase alignments are available in theoriginal N-best hypotheses, to enlarge the differ-ence between the new M-best translations andthe original N-best translations, we re-align thewords using GIZA++.Weights of the decoder are re-optimized bythe tool in the Moses package over the develop-ment set.
The process of such a re-decoding issummarized as follows:1061.
Run GIZA++ to align the words between thesource input and target N-best translations;2.
Train translation and reordering model;3.
Optimize the weights of the decoder withthe new models;4.
Decode the source input by using new mod-els and new weights to generate N+M dis-tinct translations (?distinct?
here refers tothe target language string only, not consider-ing the phrase segmentation, etc.);5.
Output M-best translations which are notseen in the original N-best translations.Re-decoding on test set follows the same steps,but without the tuning step, step 3.3.2 Regeneration with N-gram ExpansionN-gram expansion (Chen et al, 2007) combinesthe sub-strings occurred in the original N-besttranslations to generate new hypotheses.
Firstly,all n-grams from the original N-best translationsare collected.
Then the partial hypotheses arecontinuously expanded by appending a wordthrough the n-grams collected in the first step.We explain this method in more detail using thefollowing example.Suppose we have four original hypothesesshown in Figure 3.
Firstly, we collect all the 3-grams from the original hypotheses.
The first n-grams of all original entries in the N-best list areset as the initial partial hypotheses.
They are: it's5 minutes, it is 5, it?s about 5 and i walk 5.
Thenthe expansion of a partial hypothesis starts bycomputing the set of n-grams matching its last n-1 words.
As shown in Figure 4, the n-gram 5minutes on matches the last two words of thepartial hypothesis it?s about 5 minutes.
So thehypothesis is expanded to it?s about 5 minutes on.The expansion continues until the partial hy-pothesis ends with a special end-of-sentencesymbol that occurs at the end of all N-best strings.Figure 5 shows some new hypotheses that aregenerated from the example in Figure 3.
This isan example excerpted from our development data.One reference is also given in Figure 5; the firstnew generated hypothesis is equal to this refer-ence.
But unfortunately, there is no such hy-pothesis in the original N-best translations.During the new hypotheses generation, thetranslation outputs of a given source sentence arecomputed through a beam-search algorithm witha log-linear combination of the feature functions.In addition to n-gram frequency and n-gram pos-terior probability which have been used in (Chenet al, 2007), we also used language model, di-rect/inverse IBM model 1, and word penalty inthis work.
The size of the beam is set to N+M, toensure more than M new hypotheses are gener-ated.Originalhypotheses1.
it's 5 minutes on foot .2. it is 5 minutes on foot .3. it?s about 5 minutes?
to walk .4. i walk 5 minutes .n-gramsit's 5 minutes, 5 minutes on, ?
?on foot ., about 5 minutes ?
?5 minutes .Figure 3: Example of original hypotheses and 3-grams collected from them.partial hyp.
it?s about 5 minutesn-gram +                    5    minutes    onnew partial hyp.
it?s about 5 minutes onFigure 4: Expanding a partial hypothesis via amatching n-gram.Newhypothesesit?s about 5 minutes on foot .it's 5 minutes .i walk 5 minutes on foot .?
?Reference it's about five minutes on foot .Figure 5: New generated hypotheses through n-gram expansion and one reference.3.3 Regeneration with Confusion NetworkConfusion network based regeneration builds aconfusion network over the original N-best hy-potheses, and then extracts M-best hypothesesfrom it.
The word order in the N-best translationscould be very different, so we need to choose ahypothesis with the ?most correct?
word order asthe confusion network skeleton (alignment refer-ence), then align and reorder other hypotheses inthis word order.Some previous work compute the consensustranslation under MT system combination, whichdiffer from ours in the way of choosing the skele-ton and aligning the words.
Matusov et al (2006)let every hypothesis play the role of the skeletononce and used GIZA++ to get word alignment.Bangalore et al (2001), Sim et al (2007), Rostiet al (2007a), and Rosti et al (2007b) chose thehypothesis that best agrees with other hypotheseson average as the skeleton.
Bangalore et al(2001) used a WER based alignment and Sim etal.
(2007), Rosti et al (2007a), and Rosti et al(2007b) used minimum Translation Error Rate107(TER) based alignment to build the confusionnetwork.1.
it?s 5 minutes on foot .Originalhypotheses2.
it is 5 minutes on foot .Choosing alignment reference: Since the N-best translations are ranked, choosing the firstbest hypothesis as the skeleton is straightforwardin our work.3.
it?s about 5 minutes?
to walk .4. i walk 5 minutes .
?
it?s 5 minutes on foot .Alignments it 5 minutes on foot .
isAligning words: As a confusion network can beeasily built from a one-to-one alignment, we de-velop our algorithm based on the one-to-one as-sumption and use competitive linking algorithm(Melamed, 2000) for our word alignment.
Firstly,an association score is computed for every possi-ble word pair from the skeleton and sentence tobe aligned.
Then a greedy algorithm is applied toselect the best word-alignment.
In this paper, weuse a linear combination of multiple associationscores, as suggested in (Kraif and Chen, 2004).As the two sentences to be aligned are in thesame language, the association scores are com-puted on the following four clues.
They are cog-nate (Saboutit?s 5 minutes?
to walk .1), word class (S2), synonyms (S3), andposition difference (S4).
The four scores are line-arly combined with empirically determinedweights as shown is Equation 2.41( , )j i k kkS f e S?== ??
(2)Reordering words: After word alignment, thewords in all other hypotheses are reordered tomatch the word order of the skeleton.
Thealigned words are reordered according to theiralignment indices.
The unaligned words are reor-dered in two strategies: moved with its previousword or next word.
In this work, additional ex-periments suggested that moving the unalignedword with its previous word achieve better per-formance.
In the case that the first word is un-aligned, it will be moved with its next word.Each word is assigned a score based on a simplevoting scheme.
Figure 6 shows an example ofcreating a confusion network.Extracting M-best translations: New transla-tions are extracted from the confusion network.We again use beam-search algorithm to derivenew hypotheses.
The same feature functionsproposed in Section 3.2 are used to score the par-tial hypotheses.
Moreover, we also use positionbased word probability (i.e.
in Figure 6, thewords in position 5, ?on?
scored a probability of0.5, and ??
?
scored a probability of 0.25) as afeature function.
Figure 6 shows some examplesof new hypotheses generated through confusionnetwork regeneration.i 5 minutes ?
walk .
?
it?s 5 minutes on foot .Confusionnetworkit is 5 minutes on foot .it?s about 5 minutes?
to walk .
?i  5 minutes ?
walk .1. it's about five minutes on foot .New 2. it about five minutes on foot .hypotheses 3. it's about five minutes on walk .4. i about 5 minutes to work .Figure 6: Example of creating a confusion net-work from the word alignments, and new hy-potheses generated through the confusion net-work.
The sentence in bold is the alignment ref-erence.4 Rescoring modelSince the final N+M-best hypotheses are pro-duced either from different methods or same de-coder with different models, local feature func-tions of each hypothesis are not directly compa-rable, and thus inadequate for rescoring.
Wehence exploit rich global feature functions in therescoring models to compensate the loss of localfeature functions.
We apply the following 10 fea-ture functions and optimize the weight of eachfeature function using the tool in Moses package.?
direct and inverse IBM model 1 and 3?
association score, i.e.
hyper-geometric distri-bution probabilities and mutual information?
lexicalized word/block reordering rules(Chen et al, 2006)?
6-gram target LM?
8-gram target word-class based LM, word-classes are clustered by GIZA++?
length ratio between source and target sen-tence?
question feature (Chen et al, 2005)?
linear sum of n-grams relative frequencieswithin N-best translations (Chen et al, 2005)?
n-gram posterior probabilities within the N-best translations (Zens and Ney, 2006)?
sentence length posterior probabilities (Zensand Ney, 2006)1085 Experiments data Chinese English5.1 TasksWe carried out two sets of experiments on twodifferent datasets.
One is in spoken languagedomain while the other is on newswire corpus.Both experiments are on Chinese-to-Englishtranslation.Experiments on spoken language domain werecarried out on the Basic Traveling ExpressionCorpus (BTEC) (Takezawa et al, 2002) Chi-nese- to-English data augmented with HIT-corpus1.
BTEC is a multilingual speech corpuswhich contains sentences spoken by tourists.
40Ksentence-pairs are used in our experiment.
HIT-corpus is a balanced corpus and has 500K sen-tence-pairs in total.
We selected 360K sentence-pairs that are more similar to BTEC data accord-ing to its sub-topic.
Additionally, the Englishsentences of Tanaka corpus2 were also used totrain our LM.
We ran experiments on anIWSLT 3  challenge track which uses IWSLT-20064 DEV clean text set as development set andIWSLT-2006 TEST clean text as test set.
Table 1summarizes the statistics of the training, dev andtest data for IWSLT task.Experiments on newswire domain were car-ried out on the FBIS5 corpus.
We used NIST62002 MT evaluation test set as our developmentset, and the NIST 2003, 2005 test sets as our testsets.
Table 2 summarizes the statistics of thetraining, dev and test data for NIST task.data Chinese EnglishSentences 406,122Words 4,443K 4,591KTrainVocabulary 69,989 61,087Sentences 489 489?7Dev.Words 5,896 45,449Sentences 500 500?7TestWords 6,296 51,227Sentences - 155K Additionaltarget data Words - 1.7MTable 1: Statistics of training, development andtest data for IWSLT task.1 http://mitlab.hit.edu.cn/2 http://www.csse.monash.edu.au/~jwb/tanakacorpus.html3 International Workshop for Spoken Language Trans-lation4 http:// www.slc.atr.jp/IWSLT2006/5 LDC2003E146 http://www.nist.gov/speech/tests/mt/Sentences 238,761Train Words 7.0M 8.9MVocabulary 56,223 63,941Sentences 878 878?4 NIST 02(dev) Words 23,248 108,616Sentences 919 919?4 NIST 03(test) Words 25,820 116,547Sentences 1,082 1,082?4NIST 05(test) Words 30,544 141,915Sentences - 2.2M Additionaltarget data Words - 61.5MTable 2: Statistics of training, development andtest data for NIST task.Dev set Test setSystem #hypo BLEU NIST BLEU NIST1-best - 29.98 7.468 29.10 7.103RESC1 1,200 31.60 7.657 30.42 7.165RD 1,200 32.46 7.664 30.95 7.175NE 1,200 32.58 7.660 31.02 7.178CN 1,200 32.33 7.671 30.82 7.200RESC2 2,000 31.72 7.659 30.55 7.16632.98 7.673 31.36 7.202COMB 2,000Table 3: Translation performances (BLEU% andNIST scores) of IWSLT task: decoder (1-best),rescoring on original 1,200 N-best (RESC1) and2,000 N-best hypotheses (RESC2), re-decoding(RD), n-gram expansion (NE), confusion net-work (CN) and combination of all hypotheses(COMB).5.2 ResultsWe set N = 800 and M = 400 for IWSLT task, i.e.800 distinct translations for each source input areextracted from the decoder and used for regen-eration; and 400 new hypotheses are generatedfor each regeneration system: re-decoding (RD),n-gram expansion (NE) and confusion network(CN).
System COMB combines the original N-best and the three regenerated M-best hypotheseslists (totally, 2,000 distinct hypotheses: 800 +3?400).
Then each system computes the 1-besttranslation through rescoring and re-ranking itshypotheses list.
For comparison purpose, the per-formance of rescoring on two sets of original N-best translations are also computed and they areapplied based on 1,200 (RESC1) and 2,000(RESC2) distinct hypotheses extracted from thedecoder.
For NIST task, we set N = 1,600, andM = 800, thus, RESC2 and COMB compute 1-109NIST?02 (dev) NIST?03 (test) NIST?05 (test)System#hypo BLEU NIST BLEU NIST BLEU NIST1-best 1 27.67 8.498 26.68 8.271 24.82 7.856RESC1 2,400 28.13 8.519 27.09 8.312 25.29 7.868RD 2,400 28.46 8.518 27.34 8.320 25.54 7.897NE 2,400 28.52 8.539 27.47 8.329 25.65 7.907CN 2,400 28.40 8.545 27.30 8.332 25.54 7.913RESC2 4,000 28.27 8.522 27.21 8.320 25.43 7.875COMB 4,000 28.92 8.602 27.78 8.401 26.04 7.994Table 4: Translation performances (BLEU% and NIST scores) of NIST task: decoder (1-best), rescoringon original 2,400 N-best (RESC1) and 4,000 N-best hypotheses (RESC2), re-decoding (RD), n-gramexpansion (NE), confusion network (CN) and combination of all hypotheses (COMB).Reference No tax is needed for this item .
Thank you .RESC2 you don't have to do not need to pay duty on this .
thank you .1COMB (RD) not need to pay duty on this .
thank you .Reference Certainly .
The fitting room is over there .
Please come with me .RESC2 the fitting room is over there .
can you come with me .2COMB (NE) yes , you can .
the fitting room is over there .
please come with me .Reference OK .
I will bring it to you in five minutes .RESC2 a good five minutes , we will give you .3COMB (CN) ok .
after five minutes , i will give it to you .Table 5: Translations output by system RESC2 and COMB on IWSLT task (case-insensitive).best from 4,000 (1,600 + 3 800) distinct hy-potheses.
?Our evaluation metrics are BLEU (Papineni etal., 2002) and NIST, which are to perform case-insensitive matching of n-grams up to n = 4.
Thetranslation performance of IWSLT task andNIST task is reported in Tables 3 and 4 respec-tively.
The row ?1-best?
reports the scores of thetranslations produced by the decoder.
The col-umn ?#hypo?
means the size of the N-best hy-potheses involved in rescoring.
Note that on topof the same global feature functions as men-tioned in Section 4, the local feature functionsused during decoding were also involved in res-coring RESC1 and RESC2.First of all, we note that both BLEU and NISTscores of the first decoding step were improvedthrough rescoring.
If rescoring was applied afterregeneration on the N+M best lists, additionalimprovements were gained for all the develop-ment and test sets on all three regeneration sys-tems.
Absolute improvement on BLEU score of0.4-0.6 on IWSLT?06 test set and 0.25-0.35 onNIST test sets were obtained when comparedwith system RESC1.
Comparing the performanceof three regeneration methods, we can see thatre-decoding and confusion network basedmethod achieved very similar improvement;while n-gram expansion based regeneration ob-tained slightly better improvement than the othertwo methods.
Combining all regenerated hy-potheses with the original hypotheses further in-creased the scores on both tasks.
Compared withRESC2, system COMB obtained absolute im-provement of 0.81 (31.36 ?
30.55) BLEU scoreon IWSLT?06 test set, 0.57 (27.28 ?
27.21)BLEU score on NIST?03 and 0.61 (26.04 ?
25.43)BLEU score on NIST?05 respectively.We further illustrate the effectiveness of theregeneration mechanism using some translationexamples obtained from system RESC2 andCOMB as shown in Table 5.6 DiscussionTo better interpret the performance improvement;first let us check if the regeneration pass has pro-duced better hypotheses.
We computed the oraclescores on all four 1,200-best lists in IWSLT task.The oracle chooses the translation with the low-est word error rate (WER) with respect to thereferences in all cases.
The results are reported inTable 6.
It is worth noticing that the first 800-best (original N-best) hypotheses are the same in110all four lists, with differences found only in theremaining 400 hypotheses (M-best).
The consis-tent improvement of oracle scores shows that thetratheses contain better onesthan the original ones.nslation candidates have been really improved.From another viewpoint, Table 7 shows thenumber of translations generated by each methodin the final translation output (translations ofCOMB).
After re-ranking N+3M entries, it isobserved that more than 25% (e.g.
for IWSLT?06test set, (50+74+39)/500=32.6%; NIST?03 testset, (77+85+68)/919=25.1%; NIST?05 test set,(95+110+82)/1082=26.5%) of best scored out-puts were generated by the regeneration pass,showing that new generated translations are quiteoften the rescoring winner.
This also proved thatthe new-generated hypoList BLEU NIST WER PERM  oses 46.10 8.765 36.29 30.94RD 46.91 8.764 35.29 30.62NE 46.95 8.811 36.05 30.72Dev.CN 46.85 8.769 36.17 30.83M  oses 45.09 8.403 37.07 32.04RD 45.67 8.418 36.50 31.82NE 45.82 8.481 36.44 31.70TestCN 45.68 8.471 36.55 31.81Table 6: Oracle scores (BLEU%, NIST, WER%and PER%) on IWSLT task 1,200-best lists offour systems: decoder (Moses), re-decoding(RD), n-gram expansion (NE) and confusionetwork (CN).n# sentenceSet Tot.
Orig.
RD NE CNDev 489 325 52 76 36IWSLTTest 500 337 50 74 39NIST 02 878 613 92 100 73NIST 03 919 689 77 85 68NISTNIST 05 1082 795 95 110 82Table 7: Number of translations generated byeach method in the final translation output ofsystem COMB: decoder (Orig.
), re-decoding(RD), n-gram expansion (NE) and confusionnetwork (CN).
?Tot.?
is the size of the dev/testset.ities of words occur in the N-best translations.n, and confusionneree methods further im-prthe N-best list through hypotheses regeneration.S., pages 351?354.
Madonna diP.ation.
Com-B.Federico.
2005.
The ITC-irst SMT System forThen, let us consider each single regenerationmethod to understand why regeneration can pro-duce better hypotheses.
Re-decoding may intro-duce new and better phrase-pairs which are ex-tracted from the N-best hypotheses to the transla-tion model thus generate better hypotheses.
N-gram expansion can (almost) fully exploit thesearch space of target strings, which can be gen-erated by an n-gram LM.
As a result, it can pro-duce alternative translations which contain wordre-orderings and phrase structures not consideredby the search algorithm of the decoder (Chen, etal., 2007).
Confusion network based regenerationreinforces the word choice by considering theposterior probabil7 ConclusionsIn this paper, we proposed a novel three-passSMT framework against the typical two-passsystem.
This framework enhanced the quality ofthe translation candidates generated by our pro-posed regeneration pass and improved the finaltranslation performance.
Three regenerationmethods were introduced, namely, re-decoding,word-based n-gram expansiotwork based regeneration.Experiments were based on the state-of-the-artphrase-based decoder and carried out on theIWSLT and NIST Chinese-to-English task.
Weshowed that all three methods improved the per-formance with the n-gram expansion methodachieving the greatest improvement.
Moreover,the combination of the thoves the performance.We conclude that translation performance canbe improved by increasing the potential of trans-lation candidates to contain better translations.We have presented an alternative solution toameliorate the quality of translation candidates ina way that differs from system combinationwhich takes translations from other MT systems.We demonstrated that the translation perform-ance could be self-boosted by expandingReferencesBangalore, G. Bordel, and G. Riccardi.
2001.Computing consensus translation from multiplemachine translation systems.
In Proceeding ofIEEE workshop on Automatic Speech Recognitionand UnderstandingCampiglio, Italy.F.
Brown, V. J. Della Pietra, S. A. Della Pietra & R.L.
Mercer.
1993.
The Mathematics of StatisticalMachine Translation: Parameter Estimputational Linguistics, 19(2) 263-312.Chen, R. Cattoni, N. Bertoldi, M. Cettolo and M.111IWSLT-2005.
In Proceeding of IWSLT-2005,pp.98-104, Pittsburgh, USA, October.B.
Chen, M. Cettolo and M. Federico.
2006.
Reorder-ing Rules for Phrase-based Statistical MachineTranslation.
In Proceeding of IWSLT-2006, Kyoto,Japan.B.
Chen, M. Federico and M. Cettolo.
2007.
Better N-best Translations through Generative n-gram Lan-guage Models.
In Proceeding of MT Summit XI.Copenhagen, Denmark.S.
F. Chen and J. T. Goodman.
1998.
An EmpiricalStudy of Smoothing Techniques for LanguageModeling.
Technical Report TR-10-98, ComputerScience Group, Harvard University.P.
Koehn, F. J. Och and D. Marcu.
2003.
StatisticalPhrase-based Translation.
In Proceedings ofHLT/NAACL, pp 127-133, Edmonton, Canada.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch, M.Federico, N. Bertoldi, B. Cowan, W. Shen, C.Moran, R. Zens, C. Dyer, O. Bojar, A. Constantinand E. Herbst.
2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
In Proceedingof ACL-2007, pp.
177-180, Prague, Czech Republic.O.
Kraif, B. Chen.
2004.
Combining clues for lexicallevel aligning using the Null hypothesis approach.In Proceeding of COLING-2004, Geneva, pp.1261-1264.E.
Matusov, N. Ueffing, and H. Ney.
2006.
Comput-ing consensus translation from multiple machinetranslation systems using enhanced hypothesesalignment.
In Proceeding of EACL-2006, Trento,Italy.I.
D. Melamed.
2000.
Models of translational equiva-lence among words.
Computational Linguistics,26(2), pp.
221-249.F.
J. Och.
2003.
Minimum error rate training in statis-tical machine translation.
In Proceedings of ACL-2003.
Sapporo, Japan.F.
J. Och and H. Ney.
2003.
A Systematic Compari-son of Various Statistical Alignment Models.Computational Linguistics, 29(1), pp.
19-51.K.
Papineni, S. Roukos, T. Ward, and W.J.
Zhu.
2002.BLEU: a method for automatic evaluation of ma-chine translation.
In Proceeding of ACL-2002.A.
Rosti, N. F. Ayan, B. Xiang, S. Matsoukas, R.Schwartz and B. Dorr.
2007a.
Combining Outputsfrom Multiple Machine Translation Systems.
InProceeding of NAACL-HLT-2007, pp.
228-235.Rochester, NY.A.
Rosti, S. Matsoukas and R. Schwartz.
2007b.
Im-proved Word-Level System Combination for Ma-chine Translation.
In Proceeding of ACL-2007,Prague.K.
C. Sim, W. J. Byrne, M. J.F.
Gales, H. Sahbi, andP.
C. Woodland.
2007.
Consensus network decod-ing for statistical machine translation system com-bination.
In Proceeding of  ICASSP-2007.A.
Stolcke.
2002.
SRILM - an extensible languagemodelling toolkit.
In Proceeding of ICSLP-2002.901-904.T.
Takezawa, E. Sumita, F. Sugaya, H. Yamamoto,and S. Yamamoto.
2002.
Toward a broad-coveragebilingual corpus for speech translation of travelconversations in the real world.
In Proceeding ofLREC-2002, Las Palmas de Gran Canaria, Spain.R.
Zens and H. Ney.
2006.
N-gram Posterior Prob-abilities for Statistical Machine Translation.
InProceeding of HLT-NAACL Workshop on SMT, pp.72-77, NY.112
