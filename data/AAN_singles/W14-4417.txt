Proceedings of the 8th International Natural Language Generation Conference, pages 113?117,Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational LinguisticsDetermining Content for Unknown Users: Lessons fromthe MinkApp Case StudyGemma Webster, Somayajulu G. Sripada, Chris Mellish, Yolanda Melero, Koen Arts,Xavier Lambin, Rene Van Der WalUniversity of Aberdeen{gwebster, yaji.sripada, c.mellish, y.melero, k.arts, x.lambin, r.vanderwal}@abdn.ac.ukAbstractIf an NLG system needs to be put inplace as soon as possible it is not alwayspossible to know in advance who the us-ers of a system are or what kind of in-formation will interest them.
This paperdescribes the development of a systemand contextualized text for unknown us-ers.
We describe the development, designand initial findings with a system for un-known users that allows the users to de-sign their own contextualised text.1 IntroductionRequirements of an NLG system are derivedcommonly by analysing a gold standard corpus.Other knowledge acquisition (KA) techniquessuch as interviewing experts and end-users arealso frequently employed.
However, when theseKA studies result in only a partial specificationof the system requirements or complicationsmake carrying out a detailed user study in thetime available difficult, an initial system for un-known users may need to be developed.
The ini-tial system needs to fulfil the known require-ments making a number of assumptions to fill thegaps in the requirements.
In this paper, we con-centrate on the content determination problemfor such a system.We encountered this particular problem whenproducing an initial NLG system to give feed-back to volunteers submitting information aboutsigns of American Mink, an invasive species inScotland.
Our response can be viewed, on onehand, as that of exposing an early prototype forevaluation in real use.
On the other hand, it canbe viewed as an approach to allowing users to?design their own contextualised text?.
We ex-pected that this approach would have a numberof advantages.
In the paper, we draw our conclu-sions about how this worked out in our exampleapplication.2 Background - MinkAppThe Scottish Mink Initiative (SMI) project aimsto protect native wildlife by removing breedingAmerican Mink (an invasive species) from theNorth of Scotland.
SMI in the form discussedhere was launched in May 2011 and ran untilAugust 2013, after which it continued but on amuch smaller funding base.
SMI?s success andfuture rely on an ongoing network of volunteersfrom across Scotland to monitor the Americanmink population.
During the period from 2011 to2013, these volunteers were coordinated by 4 andlater 3 full-time Mink Control officers (MCOs)who had 2.5 year fixed term contracts, had nocommunal offices and were geographically lo-cated across Scotland.At present volunteers are provided with rafts tomonitor American mink.
Rafts are simple devic-es that float on water and are monitored by vol-unteers who regularly check a clay pad for minkfootprints.
In the past, volunteers in turn reportedsigns or lack of signs to their correspondingMCO.
Now volunteers can do the same throughthe MinkApp website, introduced in 2012,though some choose to continue to use the previ-ous reporting method.
The data should ideally beentered roughly every 10 days; it concerns eitherpositive or negative records from raft checks, orvisual sightings of mink and actual mink cap-tures.
The records contain geographical infor-mation and a timestamp.
MinkApp checkswhether this data is complete and then informsthe respective mink officer for that volunteer?sarea and enters the data into the database.Volunteers used to receive a quarterly newsletterthat had some regional specific content but wasnot volunteer specific.
They could receive spo-radic contact from their mink control officer inthe form of a phone call or email.
MinkApp al-lowed an infrastructure to be developed to pro-vide volunteers with specific and immediate113feedback upon submission of their observationsby means of contextualised feedback text.SMI?s funding base was severely reduced in Au-gust 2013 and MinkApp has proven central to itsendurance.
Volunteer activities of the SMI arenow supported by staff from 10 local rivers andfisheries trusts (as one of their many activities).This limited amount of staff time available couldmake the development of automatic personalisedfeedback generation vital to allow volunteers tohave tailored information on the progress of theproject and to keep volunteers engaged.3 The Problem - SMI Volunteers: TheUnknown UsersThe nearest to a gold standard for what infor-mation to offer was the corpus of newsletterscontaining information on the project as a whole.However, we learned that these newsletters wereoften not read and we have no way of judgingtheir level of success.
These newsletters, alongwith emails and discussions conducted with SMIemployees on their interactions with volunteers,however, gave us ideas about potential contentthat could be selected and indication of potentiallexical structure and word use when addressingvolunteers.Although some SMI volunteers monitor mink aspart of their job (e.g.
gamekeepers), they could infact be anyone with a desire to contribute to na-ture conservation.
Volunteers are located in verydisparate geographical locations across Scotland,with no set gender or age range and so volun-teers?
motivations, computer skills and profes-sions are mostly unknown.
Because of the rangeof types of people who could in principle be vol-unteers, they can be expected to be very varied.It is extremely difficult to contact all volunteersas each SMI catchment is managed and orga-nized in different ways and volunteers are con-tacted using different media e.g.
mail, email, tel-ephone, face-to-face.
SMI is also careful to avoidattempting to contact volunteers too often, con-scious that they are providing their services forfree and should not be bothered unnecessarily.There is also some uncertainty about which vol-unteers are active, as records are often partial orout of date.
It is known anecdotally from MCOsthat many volunteers are unwilling to use anykind of computer system and so it is unclearwhat kind of people will be reached throughMinkApp.
Finally, most observations of minksigns that arise are ?null records?, i.e.
records ofobserving no mink prints on rafts.
It is not knownwhich volunteers will be sufficiently motivatedto submit ?null records?
and which will remainapparently inactive because they have nothingpositive to report.So, even though there was a need for automati-cally generated feedback now, there was a realquestion of who the readers would be and how toselect the content to include in the feedback.4 Related WorkA standard approach to establish user require-ments for NLG is to assemble a corpus of hu-man-authored texts and their associated inputs(Reiter & Dale, 2000).
This can be the basis ofderiving rules by hand, or one can attempt to rep-licate content selection rules from the corpus bymachine learning (Duboue & McKeown, 2003;Konstas & Lapata, 2012).
To produce a usefulcorpus, however, one has to know one?s users orhave reliable expert authors.As first pointed out by Levine et al.
(1991), anNLG system that produces hypertext, rather thanstraight text, can avoid some content selectiondecisions, as the user makes some of these deci-sions by selecting links to follow.
A similar ad-vantage applies to other adaptive hypertext sys-tems (Brusilovsky, 2001).
Another general pos-sibility is to allow users to design aspects of thetexts they receive.
For instance, ICONOCLAST(Power, Scott, & Bouayad-Agha, 2003) allowsusers to make choices about text style.
However,relatively little is known about how such ap-proaches work ?in the wild?.Various previous work has attempted to buildmodels of users through observing interactionswith an interface (Fischer, 2001).
Alternatively,it is possible to explicitly ask questions to theuser about their interests (Tintarev & Masthoff,2008), though this requires the users to have thetime and motivation to take part in an initial ac-tivity with no direct reward.Our approach can be seen to have similaritieswith hypertext generation, in that we are offeringalternative texts to users, and non-invasive ap-proaches to user modelling.1145 Approach to Content SelectionTo overcome the ?unknown?
user and ?unknown?feedback problem it was decided to implement arelatively quick exploratory tool that could beused to help understand user requirements, pro-vide initial evaluation of feedback content andbuild an understanding of user interests.
Toachieve these aims we developed a tool that al-lows users to generate their own text, selectingcontent from a larger set of possibilities.
The in-formation on the type of feedback generated bythe user would allow us to investigate user stere-otypes, their detection and the automatic adapta-tion of content based on their interests(Zancanaro, Kuflik, Boger, Goren-Bar, &Goldwasser, 2007).5.1 Exploratory Tool - The Feedback FormThe feedback form (Figure 1) is displayed to us-ers of the MinkApp system once they have sub-mitted a raft check.
The form allows the user toselect which raft they wish to have their feedbackgenerated on from a list of the rafts they manage.The users have four types of information theycan select to have feedback generated on: Signs(information on signs of mink reported throughraft checks), Captures (information on mink cap-tures), My Rafts (information on their personalraft checks and submission record) and MinkEcology (information on mink behaviour andseasonality).Two of the four options, Signs and Captures,allow the user to select to what geographic scalethey would like their feedback based on: thewhole of the SMI project area, their river or theircatchment ?
the geographical region that theyreport to e.g.
Aberdeenshire, Tayside etc.Once the user has made their selection the per-sonalised feedback based on their choices is gen-erated and displayed along with an option to rankhow interesting they found this feedback or anycomments they wish to make.
The user can gen-erate multiple texts in one session.
All data fromeach click of an option, the generated text anduser comments on the text are recorded.5.2 Generation of the paragraphsThe structure of the text is separated out intoself-contained paragraphs to allow analysis ofwhat volunteers regularly view.
For each type,the structure of the generated paragraph is de-termined by a simple schema:Signs:Neighbourhood (based on user selection) ?
In theDon catchment there have been 6 signs of minkreported over the past 12 months which is higherthan the previous 12 monthsAdditional Information / Motivation ?
Mink arecoming into your area to replace captured mink.This shows your area has good ecology for minkand it is important to keep monitoring.Personal ?
There have been no signs of mink (inthe form of either footprints or scat) in the past30 days.
No signs of mink recently does not meanthey are gone - remain vigilant.Captures:Neighbourhood (based on user selection) ?
In theSpey catchment we have trapped 5 mink over thepast 12 months which is lower than the previous12 months.Additional Information / Motivation ?
Infor-mation available on this year's captures: Anadult female mink was captured on: 2014-02-19.My Rafts:Personal ?You have been very active over thepast 60 days with 7 'no mink signs' reported and2 signs of mink (in the form of either footprintsor scat) reported, the last of which was loggedon 14 Sep 2013 23:00:00 GMT.Additional Information / Motivation ?
Pleasekeep checking your raft as this evidence meansthere are mink in your area.Mink Ecology:Temporal - We are in the normal mink breedingseason!Motivation ?
During the breeding season femalemink will defend an area covering approximately1.5 miles.Additional Information - Female mink are smallenough to fit into water vole burrows which theyexplore in search of prey.Did you know there canbe brown, black, purple, white and silver minkwhich reflects the colours bred for fur?115To produce the actual content to fill the slots ofthe schemas, the system was designed to reasonover geographical location to allow examinationof the various notions of neighbourhood(Tintarev et al 2012).
The system also looks attemporal trends when developing text based onthe number of record submissions for a giventime.
The system initially looks at record sub-missions in the past week then opens out to amonth, season and finally activity between thesame seasons on different years.
This use oftemporal trends ensures volunteers are suppliedwith the most relevant (recent) mink activity in-formation first in busy periods such as the breed-ing season but ensures ?cleared?
areas with littlemink activity are still provided with informativefeedback.6 Evaluation of the Feedback ApproachWe were initially apprehensive about how muchusage the feedback system would get.
MinkAppwas launched through the SMI newsletters, butwe knew that volunteers were not always receiv-ing or reading these.
Also it turned out that theinitial estimate of active volunteers was over-inflated.
Indeed, initially the usage of MinkAppin general was much lower than was expected.So we worked hard to promote the system, forinstance asking the fisheries trusts to actively askany volunteers they had contact with if they hadheard of MinkApp and to try to use it.
As a re-sult, we did manage to increase the system usageto a level where some initial conclusions can bedrawn.MinkApp and specifically the feedback form usewere monitored for 50 days (7 weeks).
Duringthis time 308 raft checks were submitted by vol-unteers for 98 different rafts by 44 unique users.The feedback system was used by volunteers togenerate 113 different texts about 36 differentrafts.
32 out of the 44 (72.7%) of all MinkAppusers requested generated feedback at least once.In 47% of the feedback form use sessions multi-ple texts were generated and there are some par-ticularly interesting use patterns:?
?Regular explorer?
: One user accessedMinkApp seven times and generatedfeedback text on every use: 1 text, 3texts, 5 texts, 5 texts, 4 texts, 2 texts and1 text?
?Periodic explorer?
: One user accessedMinkApp six times and generated atleast one feedback text on every seconduse?
?Try once only?
: The user who accessedMinkApp the most with eleven differentsessions only generated feedback text ontheir first use of MinkApp.These different patterns of use require furtherinvestigation as the number of users usingMinkApp increases.
The patterns can be affectedby idiosyncratic factors.
For instance, one volun-teer informed the project coordinator that theycontinually selected Captures within their area asthey had caught a mink and their capture had notyet been added to the system - the volunteer wasusing the feedback form to monitor how long ittook for mink capture data to appear inMinkApp.Of the four types of information available to vol-unteers Signs was the most viewed althoughCaptures was what SMI staff had felt volunteerswould be most interested in.
Signs had 56.6% ofthe overall use and catchment was the mostwidely selected option for geographic area forboth Signs and Captures.
However there was noclearly predominant second choice for infor-mation option with Captures and My Rafts hav-ing only 2.7% of a difference within their use.Mink Ecology was the least used category, partlyto do with the lack of clarity in the name ?MinkEcology?.
Signs on a local geographical scalewere the most common selection for volunteersbut the actual use was not clear enough to sup-port a fixed text type or removing other options.7 ConclusionsThe results of this initial study did support thevalue of feedback to volunteers (more directlythan we would have been able to determine inadvance) with 73% of volunteers choosing togenerate feedback.
The feedback enabled us tooffer contextualized information to volunteersquickly, without initial extensive user studies,which was very important for supporting thecontinuation of SMI.The fact that the volunteer population was rela-tively unknown meant that there were some un-pleasant surprises in terms of uptake and interest.It was necessary to make special efforts to en-courage participation to get larger numbers.116When our system gets used over longer periodswe might observe more meaningful patterns ofbehaviour.The patterns of interest we observed were noisyand were influenced by many contextual factorsmeaning there was little potential yet for statisti-cal analysis or machine learning.8 Future WorkIn-depth analysis is required as more volunteersuse MinkApp and the feedback form to fully un-derstand patterns of behaviour.
Additionallyqualitative studies such as interviews with volun-teers could help explain use and preferences.These studies could help us improve the feed-back system and text to better suit the user?sneeds.
In the meantime, we have a working sys-tem that offers choices to users to ?generate theirown text?
even though we had hoped to be ableto tailor to individual volunteer preferencessooner.9 AcknowledgmentsWe would like to thank SMI for their on-goingcommitment to this research.
This work is sup-ported by the Rural Digital Economy ResearchHub (EPSRC EP/G066051/1).ReferenceArts, K., Webster, G.
., Sharma, N.
., Melero, Y.
.,Mellish, C., Lambin, X., & Van der Wal, R.(2013).
Capturing mink and data.
Interacting with asmall and dispersed environmental initiative overthe introduction of digital innovation Uploader.Case study for the online platform ?Framework forResponsible Research and Innovation in ICT.?
Re-trieved from http://responsible-innovation.org.uk/torrii/resource-detail/1059Beirne, C., & Lambin, X.
(2013).
Understanding theDeterminants of Volunteer Retention ThroughCapture-Recapture Analysis: Answering SocialScience Questions Using a Wildlife EcologyToolkit.
Conservation Letters, 6(6), 391?401.doi:10.1111/conl.12023Brusilovsky, P. (2001).
Adaptive Hypermedia.
UserModeling and User-Adapted Interaction, 11(1-2),87?110.
doi:10.1023/A:1011143116306Bryce, R., Oliver, M. K., Davies, L., Gray, H., Ur-quhart, J., & Lambin, X.
(2011).
Turning back thetide of American mink invasion at an unprecedent-ed scale through community participation andadaptive management.
Biological conservation,144(1), 575?583.
Retrieved fromhttp://cat.inist.fr/?aModele=afficheN&cpsidt=23779637Duboue, P. A., & McKeown, K. R. (2003).
Statisticalacquisition of content selection rules for naturallanguage generation.
In Proceedings of the 2003conference on Empirical methods in natural lan-guage processing - (Vol.
10, pp.
121?128).
Morris-town, NJ, USA: Association for ComputationalLinguistics.
doi:10.3115/1119355.1119371Fischer, G. (2001).
User Modeling in Human?Computer Interaction.
User Modeling and User-Adapted Interaction, 11(1-2), 65?86.doi:10.1023/A:1011145532042Konstas, I., & Lapata, M. (2012).
Concept-to-textgeneration via discriminative reranking, 369?378.Retrieved fromhttp://dl.acm.org/citation.cfm?id=2390524.2390576Levine, J., Cawsey, A., Mellish, C., Poynter, L.,Reiter, E., Tyson, P., & Walker, J.
(1991).
IDAS:Combining hypertext and natural language genera-tion.
In Procs of the Third European Workshop onNLG (pp.
55?62).
Innsbruck, Austria.Power, R., Scott, D., & Bouayad-Agha, N. (2003).Generating texts with style, 444?452.
Retrievedfromhttp://dl.acm.org/citation.cfm?id=1791562.1791619Reiter, E., & Dale, R. (2000).
Building Applied Natu-ral Language Generation Systems.
clt.mq.edu.au(Vol.
33.).
Cambridge: Cambridge university press.Retrieved fromhttp://clt.mq.edu.au/~rdale/publications/papers/1997/jnle97.pdfTintarev, N., & Masthoff, J.
(2008).
Adaptive Hyper-media and Adaptive Web-Based Systems.
(W.Nejdl, J. Kay, P. Pu, & E. Herder, Eds.)
(Vol.5149, pp.
204?213).
Berlin, Heidelberg: SpringerBerlin Heidelberg.
doi:10.1007/978-3-540-70987-9Tintarev, N., Melero, Y., Sripada, S., Tait, E., VanDer Wal, R., & Mellish, C. (2012).
MinkApp: gen-erating spatio-temporal summaries for nature con-servation volunteers, 17?21.
Retrieved fromhttp://dl.acm.org/citation.cfm?id=2392712.2392720Zancanaro, M., Kuflik, T., Boger, Z., Goren-Bar, D.,& Goldwasser, D. (2007).
Analyzing museum vis-itors?
behavior patterns.
In C. Conati, K. McCoy,& G. Paliouras (Eds.
), 11th International Confer-ence on User Modeling (Vol.
4511, pp.
238?246).Berlin, Heidelberg: Springer Berlin Heidelberg.doi:10.1007/978-3-540-73078-1117
