S-MINDS 2-Way Speech-to-Speech Translation SystemFarzad Ehsani, Jim Kimzey, Demitrios Master,Karen Sudre, David DomingoHunil ParkEngineering DepartmentSehda, Inc.
Independent ConsultantMountain View, CA 94043 Seoul, Korea{farzad, jkimzey, dlm, karen, ddomingo}@sehda.com phunil@hotmail.comAbstractSehda?s 2-way speech translationsystem, S-MINDS, interprets betweenprovider and patient in routine medicalinteractions with very high accuracy.Optimizing the system for new tasksor languages requires very little data.New developments include a hybridtranslation approach that allowsparticipants to say complex or out-of-domain utterances, the expansion ofhands-free functionality, and theability to deliver the most urgentexpressions instantaneously.1 IntroductionSpeech translation technology has the potentialto give nurses and other clinicians immediateaccess to consistent, easy-to-use, and accuratemedical interpretation for routine patientencounters.
This could improve safety andquality of care for patients who speak a differentlanguage from that of the healthcare provider.The most common hospital interactions areinterview-style dialogs where the provider?s andpatient?s utterances are simple and relativelypredictable.
Sehda?s speech translation system,S-MINDS, focuses on translating in suchsituations with extremely high accuracy.One key difference between S-MINDS and otherspeech translation systems is the amount of datarequired in development.
Most other systemsdepend on a moderate amount of domain-specific data being available.
If the data is notalready available, it is extremely time- andlabor-intensive for a developer to collect enoughrealistic data to effectively model a pure SMTsystem ?
even if the developer has direct accessto a group of actual users for whom its system isbeing optimized.For this and other reasons, Sehda focuses onrapid building and deployment of speechtranslation systems for tasks or languages wherelittle or no data is available.2 System DescriptionThis section describes the speech recognition,translation, speech generation, interface andhardware components that make up S-MINDS.2.1 Speech RecognitionS-MINDS uses a number of voice-independentautomated speech recognition (ASR) engines,with the usage dependent on the languages andthe particular domain.
These engines includeNuance 8.5i, SRI EduSpeak 2.0ii, and Entropic?sHTK-based engine.iiiSehda?s (internal) dialog/translation creationtools allow developers to compile and run newdialogs with any ASR engine so they do nothave to be encumbered by the nuances of anyparticular engine.2.2 TranslationS-MINDS processes ASR output using acombination of grammars and language modelsthat is selected based on the task and theavailability of training data.S-MINDS first employs a semantic parser toextract the essential words and phrases from theASR output.
This information is then fed intoSehda?s proprietary interpretation engine, whichmatches the information against a finite set ofconcepts in the specified domain.
The resultingtranslation is extremely accurate ?
often moreaccurate than the ASR output itself.
However, asthe name suggests, this engine does not directlytranslate users?
utterances but interprets whatthey say and paraphrases their statements.2.3 Speech GenerationS-MINDS uses its own voice generation system,which splices human recordings, to output mosttranslations.
If recordings do not exist for a wordor phrase, S-MINDS generates the speech usinga text-to-speech (TTS) engine.S-MINDS includes a set of tools by which userscan modify and augment the existing systemwith additional words and phrases in the field ina matter of a few minutes.2.4 InterfaceA variety of interface features make S-MINDSparticularly easy to use in a hospitalenvironment.Most S-MINDS functions can be performedhands-free and eyes-free via a voice userinterface (VUI) so the provider can focus on thepatient and the operation of hospital equipment.A picture viewer allows digital images to bedisplayed to aid communication with the patientand add clarity to the log.Verbal or on-screen verification can beemployed (with adjustable upper and lowerthresholds) to put an additional check onrecognition accuracy.2.5 HardwareA complete S-MINDS system contains threemain hardware components: a Windows XPcomputer with S-MINDS software installed;a headset microphone, which the healthcareprovider uses to control S-MINDS andcommunicate with the patient; and atelephone handset, which the patient uses tocommunicate with the provider.3 Current DevelopmentsUnder a contract with DARPA, Sehda hasdeveloped a more interactive system using acombination of SMT and interpretationengines.
This allows the users to speakmore freely.
If an utterance is too complex ortoo far ?out of domain?
to be handled by theinterpretation engine, S-MINDS falls back to theSMT engine, which returns a fairly reliableword-for-word translation of the ASR output.The VUI in S-MINDS is being enhanced toinclude nearly all system control functions,reducing the need to change settingsmanually.
In addition, users will be able todeliver some urgent expressions (such as?Hold still?
or ?You can breathe?
)instantaneously without saying a ?hotword?first.i   http://www.nuance.com/nuancerecognition/ii   http://www.speechatsri.com/products/eduspeak.shtmliii   http://htk.eng.cam.ac.uk/
