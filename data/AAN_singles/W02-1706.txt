XML-Based NLP Tools for Analysing and Annotating Medical LanguageClaire Grover, Ewan Klein, Mirella Lapata and Alex LascaridesDivision of InformaticsThe University of Edinburgh2 Buccleuch PlaceEdinburgh EH8 9LW, UK{C.Grover, E.Klein, M.Lapata, A.Lascarides}@ed.ac.ukAbstractWe describe the use of a suite of highly flexibleXML-based NLP tools in a project for processing andinterpreting text in the medical domain.
The mainaim of the paper is to demonstrate the central rolethat XML mark-up and XML NLP tools have playedin the analysis process and to describe the resultantannotated corpus of MEDLINE abstracts.
In additionto the XML tools, we have succeeded in integratinga variety of non-XML ?off the shelf?
NLP tools intoour pipelines, so that their output is added into themark-up.
We demonstrate the utility of the anno-tations that result in two ways.
First, we investigatehow they can be used to improve parse coverage of ahand-crafted grammar that generates logical forms.And second, we investigate how they contribute toautomatic lexical semantic acquisition processes.1 IntroductionIn this paper we describe our use of XML for an anal-ysis of medical language which involves a numberof complex linguistic processing stages.
The ulti-mate aim of the project is to to acquire lexical se-mantic information from MEDLINE through parsing,however, a fundamental tenet of our approach is thathigher-level NLP activities benefit hugely from be-ing based on a reliable and well-considerered initialstage of tokenisation.
This is particularly true forlanguage tasks in the biomedical and other technicaldomains since general purpose NLP technology maystumble at the first hurdle when confronted withcharacter strings that represent specialised techni-cal vocabulary.
Once firm foundations are laid thenone can achieve better performance from e.g.
chun-kers and parsers than might otherwise be the case.We show how well-founded tools, especially XML-based ones, can enable a variety of NLP componentsto be bundled together in different ways to achievedifferent types of analysis.
Note that in fields suchas information extraction (IE) it is common to usestatistical text classification methods for data anal-ysis.
Our more linguistic approach may be of as-sistence in IE: see Craven and Kumlien (1999) fordiscussion of methods for IE from MEDLINE.Our processing paradigm is XML-based.
As amark-up language for NLP tasks, XML is expres-sive and flexible yet constrainable.
Furthermore,there exist a wide range of XML-based tools for NLPapplications which lend themselves to a modular,pipelined approach to processing whereby linguis-tic knowledge is computed and added as XML an-notations in an incremental fashion.
In processingMEDLINE abstracts we have built a number of suchpipelines using as key components the programsdistributed with the LT TTT and LT XML toolsets(Grover et al, 2000; Thompson et al, 1997).
Wehave also successfully integrated non-XML public-domain tools into our pipelines and incorporatedtheir output into the XML mark-up using the LT XMLprogram xmlperl (McKelvie, 2000).In Section 2 we describe our use of XML-basedtokenisation tools and techniques and in Sections 3and 4 we describe two different approaches toanalysing MEDLINE data which are built on top ofthe tokenisation.
The first approach uses a hand-coded grammar to give complete syntactic and se-mantic analyses of sentences.
The second approachperforms a shallower statistically-based analysiswhich yields ?grammatical relations?
rather thanfull logical forms.
This information about gram-matical relations is used in a statistically-trainedmodel which disambiguates the semantic relationsin noun compounds headed by deverbal nominali-sations.
For this second approach we compare twoseparate methods of shallow analysis which requirethe use of two different part-of-speech taggers.2 Pre-parsing of Medline AbstractsFor the work reported here, we have used theOHSUMED corpus of MEDLINE abstracts (Hersh et<RECORD><ID>395</ID><MEDLINE-ID>87052477</MEDLINE-ID><SOURCE>Clin Pediatr (Phila) 8703; 25(12):617-9 </SOURCE><MESH>Adolescence; Alcoholic Intoxication/BL/*EP; Blood Glucose/AN; Canada; Child; Child, Preschool;Electrolytes/BL; Female; Human; Hypoglycemia/ET; Infant; Male; Retrospective Studies.</MESH><TITLE>Ethyl alcohol ingestion in children.
A 15-year review.</TITLE><PTYPE>JOURNAL ARTICLE.</PTYPE><ABSTRACT><SENT><W P=?DT?>A</W> <W P=?JJ?>retrospective</W><W P=?NN?
LM=?study?>study</W><W P=?VBD?
LM=?be?>was</W><W P=?VBN?
LM=?conduct?>conducted</W><W P=?IN?>by</W> <W P=?NN?
LM=?chart?>chart</W><W P=?NNS?
LM=?review?>reviews</W><W P=?IN?
>of</W> <W P=?CD?>27</W><W P=?NNS?
LM=?patient?>patients</W> <W P=?IN?>with</W> <W P=?JJ?>documented</W><W P=?NN?
LM=?ethanol?>ethanol</W><W P=?NN?
LM=?ingestion?>ingestion</W><W P=?.
?>.</W></SENT> <SENT> .. .
</SENT> <SENT> .. .
</SENT></ABSTRACT><AUTHOR>Leung AK.</AUTHOR></RECORD>Figure 1: A sample from the XML-marked-up OHSUMED Corpusal., 1994) which contains 348,566 references takenfrom the years 1987?1991.
Not every referencecontains an abstract, thus the total number of ab-stracts in the corpus is 233,443.
The total number ofwords in those abstracts is 38,708,745 and the ab-stracts contain approximately 1,691,383 sentenceswith an average length of 22.89 words.By pre-parsing we mean identification of wordtokens and sentence boundaries and other lower-level processing tasks such as part-of-speech (POS)tagging and lemmatisation.
These initial stages ofprocessing form the foundation of our NLP workwith MEDLINE abstracts and our methods are flex-ible enough that the representation of pre-parsingcan be easily tailored to suit the input needs of sub-sequent higher-level processors.
We start by con-verting the OHSUMED corpus from its original for-mat to an XML format (see Figure 1).
From thispoint on we pass the data through pipelines whichare composed of calls to a variety of XML-basedtools from the LT TTT and LT XML toolsets.
Thecore program in our pipelines is the LT TTT programfsgmatch, a general purpose transducer which pro-cesses an input stream and rewrites it using rulesprovided in a hand-written grammar file, where therewrite usually takes the form of the addition ofXML mark-up.
Typically, fsgmatch rules specifypatterns over sequences of XML elements and use aregular expression language to identify patterns in-side the character strings (PCDATA) which are thecontent of elements.
For example, the followingrule for decimals such as ?.25?
is searching for asequence of two S elements where the first containsthe string ?.?
as its PCDATA content and the secondhas been identified as a cardinal number (C=?CD?,e.g.
any sequence of digits).
When these two S el-ements are found, they are wrapped in a W elementwith the attribute C=?CD?
(targ sg).
(Here S ele-ments encode character sequences, see below, andW elements encode words.
)<RULE name="decimal" targ_sg="W[C=?CD?
]"><REL match="S/#??[\.
]$"></REL><REL match="S[C=?CD?
]"></REL></RULE>Subparts of a pipeline can be thought of as dis-tinct modules so that pipelines can be configured todifferent tasks.
A typical pipeline starts with a two-<S C=?UCA?>A</S><S C=?LCA?>rterial</S><S C=?WS?> </S><S C=?UCA?>P</S><S C=?LCA?>a</S><S C=?UCA?>O</S><S C=?CD?>2</S><S C=?WS?> </S><S C=?LCA?>as</S><S C=?WS?> </S><S C=?LCA?>measured</S>Figure 2: Character Sequence (S) Mark-upstage process to identify word tokens within ab-stracts.
First, sequences of characters are bundledinto S (sequence) elements using fsgmatch.
For eachclass of character a sequence of one or more in-stances is identified and the type is recorded as thevalue of the attribute C (UCA=upper case alphabetic,LCA=lower case alphabetic, WS=white space etc.
).Figure 2 shows the string Arterial PaO2 as mea-sured marked up for S elements (line breaks addedfor formatting purposes).
Every single character in-cluding white space and newline is contained in Selements which become building blocks for the nextcall to fsgmatch where words are identified.
An al-ternative approach would find words in a single stepbut our two-step method provides a cleaner set ofword-level rules which are more easily modified andtailored to different purposes: modifiability is criti-cal since the definition of what is a word can differfrom one subsequent processing step to another.A pipeline which first identifies words and thenperforms sentence boundary identification and POStagging followed by lemmatisation is shown in Fig-ure 3 (somewhat simplified and numbering addedfor ease of exposition).
The Perl program in step 1wraps the input inside an XML header and footeras a first step towards conversion to XML.
Step 2calls fsgmatch with the grammar file ohsumed.gr toidentify the fields of an OHSUMED entry and convertthem into XML mark-up: each abstract is put insidea RECORD element which contains sub-structure re-flecting e.g.
author, title, MESH code and the ab-stract itself.
From this point on, all processing is di-rected at the ABSTRACT elements through the query?.*/ABSTRACT?1.
Steps 3 and 4 make calls to fsg-match to identify S and W (word) elements as de-scribed above and after this point, in step 5, the Smark-up is discarded (using the LT TTT programsgdelmarkup) since it has now served its purpose.Step 6 contains a call to the other main LT TTTprogram, ltpos (Mikheev, 1997), which performsboth sentence identification and POS tagging.
Thesubquery (-qs) option picks out ABSTRACTs as theelements within RECORDs (-q option) that are tobe processed; the -qw option indicates that the in-put has already been segmented into words marked1The query language that the LT TTT and LT XML tools useis a specialised XML query language which pinpoints the partof the XML tree-structure that is to be processed at that point.This query language pre-dates XPath and in expressiveness itconstitutes a subset of XPath except that it also allows regularexpressions over text content.
Future plans include modifyingout tools to allow for the use of XPath as a query language.up as W elements; the -sent option indicates thatsentences should be wrapped as SENT elements; the-tag option is an instruction to output POS tags andthe -pos attr option indicates that POS tags shouldbe encoded as the value of the attribute P on W ele-ments.
The final resource.xml names the resourcefile that ltpos is to use.
Note that the tagset usedby ltpos is the Penn Treebank tagset (Marcus et al,1994).1. ohs2xml.perl \2.
| fsgmatch -q ".
*/TEXT" ohsumed.gr \3.
| fsgmatch -q ".
*/ABSTRACT" pretok.gr \4.
| fsgmatch ".
*/ABSTRACT" tok.gr \5.
| sgdelmarkup -q ".
*/S" \6.
| ltpos -q ".
*/RECORD" -qs ".
*/ABSTRACT" \-qw ".
*/W" -sent SENT \-tag -pos_attr P resource.xml \7.
| xmlperl lemma.ruleFigure 3: Basic Tokenisation PipelineUp to this point, each module in the pipeline hasused one of the LT TTT or LT XML programs whichare sensitive to XML structure.
There are, however,a large number of tools available from the NLP com-munity which could profitably be used but which arenot XML-aware.
We have integrated some of thesetools into our pipelines using the LT XML programxmlperl.
This is a program which makes underly-ing use of an XML parser so that rules defined ina rule file can be directed at particular parts of theXML tree-structure.
The actions in the rules are de-fined using the full capabilities of Perl.
This givesthe potential for a much wider range of transforma-tions of the input than fsgmatch allows and, in par-ticular, we use Perl?s stream-handling capabilitiesto pass the content of XML elements out to a non-XML program, receive the result back and encode itback in the XML mark-up.
Step 7 of the pipeline inFigure 3 shows a call to xmlperl with the rule filelemma.rule.
This rule file invokes Minnen et al?s(2000) morpha lemmatiser: the PCDATA content ofeach verbal or nominal W element is passed to thelemmatiser and the lemma that is returned is en-coded as the value of the attribute LM.
A sampleof the output from the pipeline is shown in Figure 1.3 Deep Grammatical AnalysisAs part of our work with OHSUMED, we havebeen attempting to improve the coverage of a hand-crafted, linguistically motivated grammar whichprovides full-syntactic analysis paired with logicalforms.
The grammar and parsing system we useis the wide-coverage grammar, morphological anal-yser and lexicon provided by the Alvey Natural Lan-guage Tools (ANLT) system (Carroll et al 1991,Grover et al 1993).
Our first aim was to increasecoverage up to a reasonable level so that parse rank-ing techniques could then be applied.The ANLT grammar is a feature-based unificationgrammar based on the GPSG formalism (Gazdar etal., 1985).
In this framework, lexical entries carrya significant amount of information including sub-categorisation information.
Thus the practical parsesuccess of the grammar is significantly dependenton the quality of the lexicon.
The ANLT grammaris distributed with a large lexicon and, while thisprovides a core of commonly-occurring lexical en-tries, there remains a significant problem of inade-quate lexical coverage.
If we try to parse OHSUMEDsentences using the ANLT lexicon and no other re-sources, we achieve very poor results (2% coverage)because most of the medical domain words are sim-ply not in the lexicon and there is no ?robustness?strategy built into ANLT.
Rather than pursue thelabour-intensive course of augmenting the lexiconwith domain-specific lexical resources, we have de-veloped a solution which does not require that newlexicons be derived for each new domain type andwhich has robustness built into the strategy.
Fur-thermore, this solution does not preclude the use ofspecialist lexical resources if these can be used toachieve further improvements in performance.Our approach relies on the sophisticated XML-based tokenisation and POS tagging described in theprevious section and it builds on this by combin-ing POS tag information with the existing ANLT lex-ical resources.
We preserve POS tag information forcontent words (nouns, verbs, adjectives, adverbs)since this is usually reliable and informative andwe dispose of POS tags for function words (com-plementizers, determiners, particles, conjunctions,auxiliaries, pronouns, etc.)
since the ANLT hand-written entries for these are more reliable and aretuned to the needs of the grammar.
Furthermore,unknown words are far more likely to be contentwords, so knowledge of the POS tag will most oftenbe needed for content words.Having retained content word tags, we use themduring lexical look-up in one of two ways.
If theword exists in the lexicon with the same basic cat-egory as the POS tag then the POS tag plays a ?dis-ambiguating?
role, filtering out entries for the wordwith different categories.
If, on the other hand, theword is not in the lexicon or it is not in the lexiconwith the relevant category, then a basic underspeci-fied entry for the POS tag is used as the lexical entryfor the word, thereby allowing the parse to proceed.For example, if the following partially tagged sen-tence is input to the parser, it is successfully parsed.We studied VBD the value NN oftranscutaneous JJ carbon NN dioxide NNmonitoring NN during transport NNWithout the tags the parse would fail since the wordtranscutaneous is not in the ANLT lexicon.
Further-more, monitoring is present in the lexicon but as averb and not as a noun.
For both these words, or-dinary lexical look-up fails and the entries for thetags have to be used instead.
Note that the caseof monitoring would be problematic for a strategywhere tagging is used only in case lexical look-upfails, since here it is incomplete rather than failed.The implementation of our word tag pair look-upmethod is specific to the ANLT system and uses itsmorphological analysis component to treat tags as anovel kind of affix.
Space considerations precludediscussion of this topic here but see Grover and Las-carides (2001) for further details.Another impediment to parse coverage is theprevalence of technical expressions and formulae inbiomedical and other technical language.
For ex-ample, the following sentence has a straightforwardoverall syntactic structure but the ANLT grammardoes not contain specialist rules for handling ex-pressions such as 5.0+/-0.4 grams tension and thusthe parse would fail.Control tissues displayed a reproducible response tobethanechol stimulation at different calciumconcentrations with an ED50 of 0.4 mM calciumand a peak response of 5.0+/-0.4 grams tension.Our response to issues like these is to place a fur-ther layer of processing in between the output ofthe initial tokenisation pipeline in Figure 3 and theinput to the parser.
Since the ANLT system is notXML-based, we already use xmlperl to convert sen-tences to the ANLT input format of one sentence perline with tags appended to words using an under-score.
We can add a number of other processes atthis point to implement a strategy of using fsgmatchgrammars to package up technical expressions so asto render them innocuous to the parser.
Thus allof the following ?words?
have been identified usingfsgmatch rules and can be passed to the parser asunanalysable units.
The classification of these ex-amples as nouns reflects a hypothesis that they canslot into the correct parse as noun phrases but thereis room for experimentation since the conversion toparser input format can rewrite the tag in any way.<W P=?NN?>P less than 0.001</W><W P=?NN?>166 +/- 77 mg/dl</W><W P=?NN?>2 to 5 cc/day</W><W P=?NN?>2.5 mg i.v.</W>In addition to these kinds of examples, we alsopackage up other less technical expressions such ascommon multi-word words and spelled out num-bers:<W P=?CD?>thirty-five</W> thirty-five CD<W P=?CD?>Twenty one</W> Twenty?one CD<W P=?IN?>In order to</W> In?order?to IN<W P=?JJ?>in vitro</W> in?vitro JJIn order to measure the effectiveness of our at-tempts to improve coverage, we conducted an ex-periment where we parsed 200 sentences taken atrandom from OHSUMED.
We processed the sen-tences in three different ways and gathered parsesuccess rates for each of the three methods.
Ver-sion 1 established a ?no-intervention?
baseline byusing the initial pipeline in Figure 3 to identifywords and sentences but otherwise discarding allother mark-up.
Version 2 addressed the lexical ro-bustness issue by retaining POS tags to be used bythe grammar in the way outlined above.
Version 3applied the full set of preprocessing techniques in-cluding the packaging-up of formulaic and othertechnical expressions.
The parse results for theseruns are as follows:Version 1 Version 2 Version 3Parses 4 (2%) 32 (16%) 79 (39.5%)Even in Version 3, coverage is still not very high butthe difference between the three versions demon-strates that our approach has made significant in-roads into the problem.
Moreover, the increase incoverage was achieved without any significant al-terations to the general-purpose grammar and thetokenisation of formulaic expressions was by nomeans comprehensive.4 Shallow AnalysisIn contrast to the full syntactic analysis experi-ments described in the previous section, here wedescribe two distinct methods of shallow analy-sis from which we acquire frequency informationwhich is used to predict lexical semantic relationsin a particular kind of noun compound.4.1 The TaskThe aim of the processing in this task is to pre-dict the relationship between a deverbal nominalisa-tion head and its modifier in noun-noun compoundssuch as tube placement, antibody response, pain re-sponse, helicopter transport.
In these examples, themeaning of the head noun is closely related to themeaning of the verb from which it derives and therelationship between this noun and its modifier cantypically be matched onto a relationship betweenthe verb and one of its arguments.
For example,there is a correspondence between the compoundtube placement and the verb plus direct object stringplace the tube.
When we interpret the compoundwe describe the role that the modifier plays in termsof the argument position it would fill in the corre-sponding verbal construction:tube placement objectantibody response subjectpain response to-objecthelicopter transport by-objectWe can infer that tube in tube placement fills theobject role in the place relation by gathering in-stances from the corpus of the verb place and dis-covering that tube occurs more frequently in objectposition than in other positions and that the objectinterpretation is therefore more probable.To interpret such compounds in this way, we needaccess to information about the verbs from whichthe head nouns are derived.
Specifically, for eachverb, we need counts of the frequency with whichit occurs with each noun in each of its argumentslots.
Ultimately, in fact, in view of the sparse dataproblem, we need to back off from specific noun in-stances to noun classes (see Section 4.4).
The cur-rent state-of-the-art in NLP provides a number ofroutes to acquiring grammatical relations informa-tion about verbs, and for our experiment we chosetwo methods in order to be able to compare the tech-niques and assess their utility.4.2 Chunking with CassOur first method of acquiring verb grammatical re-lations is that used by Lapata (2000) for a similartask on more general linguistic data.
This methoduses Abney?s (1996) Cass chunker which uses thefinite-state cascade technique.
A finite-state cas-cade is a sequence of non-recursive levels: phrasesat one level are built on phrases at the previouslevel without containing same level or higher-levelphrases.
Two levels of particular importance arechunks and simplex clauses.
A chunk is the non-recursive core of intra-clausal constituents extend-ing from the beginning of the constituent to its head,excluding post-head dependents (i.e., NP, VP, PP),whereas a simplex clause is a sequence of non-recursive clauses (Abney, 1996).
Cass recognizeschunks and simplex clauses using a regular expres-sion grammar without attempting to resolve attach-ment ambiguities.
The parser comes with a large-scale grammar for English and a built-in tool thatextracts predicate-argument tuples out of the parsetrees that Cass produces.
Thus the tool identifiessubjects and objects as well as PPs without how-ever distinguishing arguments from adjuncts.
Weconsider verbs followed by the preposition by anda head noun as instances of verb-subject relations.Our verb-object tuples also include prepositionalobjects even though these are not explicitly iden-tified by Cass.
We assume that PPs adjacent to theverb and headed by either of the prepositions in, to,for, with, on, at, from, of, into, through, upon areprepositional objects.The input to the process is the entire OHSUMEDcorpus after it has been converted to XML, to-kenised, split into sentences and POS tagged us-ing ltpos as described in Section 2.
The output ofthis tokenisation is converted to Cass?s input formatwhich is a non-XML file with one word per line andtags separated by tab.
We achieve this conversionusing xmlperl with a simple rule file.
The outputof Cass and the grammatical relations processor is alist of each verb-argument pair in the corpus:manage :obj refibrillationrespond :subj psoriasisaccess :to system4.3 Shallow Parsing with the Tag SequenceGrammarOur second method of acquiring verb grammati-cal relations uses the statistical parser developed byBriscoe and Carroll (1993, 1997) which is an ex-tension of the ANLT grammar development systemwhich we used for our deep grammatical analysis asreported in Section 3 above.
The statistical parser,known as the Tag Sequence Grammar (TSG), uses ahand-crafted grammar where the lexical entries arefor POS tags rather than words themselves.
Thus itis strings of tags that are parsed rather than stringsof words.
The statistical part of the system is theparse ranking component where probabilities are as-sociated with transitions in an LR parse table.
Thegrammar does not achieve full-coverage but on theOHSUMED corpus we were able to obtain parses for99.05% of sentences.
The number of parses foundper sentence ranges from zero into the thousandsbut the system returns the highest ranked parse ac-cording to the statistical ranking method.
We donot have an accurate measure of how many of thehighest ranked parses are actually correct but even apartially incorrect parse may still yield useful gram-matical relations data.In recent developments (Carroll and Briscoe,2001), the TSG authors have developed an algorithmfor mapping TSG parse trees to representations ofgrammatical relations within the sentence in the fol-lowing format:These centres are efficiently trapped in proteins at lowtemperatures(|ncsubj| |trap| |centre| |obj|)(|iobj| |in| |trap| |protein|)(|detmod| |centre| |These|)(|mod| |trap| |efficiently|)(|aux| |trap| |be|)(|ncmod| |temperature| |low|)(|ncmod| |at| |trap| |temperature|)This format can easily be mapped to the same for-mat as described in Section 4.2 to give counts of thenumber of times a particular verb occurs with a par-ticular noun as its subject, object or prepositionalobject.As explained above, the TSG parses sequencesof tags, however it requires a different tagset fromthat produced by ltpos, namely the CLAWS2 tagset(Garside, 1987).
To prepare the corpus for parsingwith the TSG we therefore tagged it with Elworthy?s(1994) tagger and since this is a non-XML tool weused xmlperl to invoke it and to incorporate its re-sults back into the XML mark-up.
Sentences werethen prepared as input to the TSG?this involved us-ing xmlperl to replace words by their lemmas and toconvert to ANLT input format:These DD2 centre NN2 be VBR efficiently RRtrap VVN in II protein NN2 at II low JJtemperature NN2The lemmas are needed in order that the TSG out-puts them rather than inflected words in the gram-matical relations output shown above.4.4 Compound InterpretationHaving collected two different sets of frequencycounts from the entire OHSUMED corpus for verbsand their arguments, we performed an experiment todiscover (a) whether it is possible to reliably predictsemantic relations in nominalisation-headed com-pounds and (b) whether the two methods of col-lecting frequency counts make any significant dif-ference to the process.To collect data for the experiment we needed toadd to the mark-up already created by the basicpipeline in Figure 3, (a) to mark up deverbal nomi-nalisations with information about their verbal stemto give nominalisation-verb equivalences and (b) tomark up compounds in order to collect samples oftwo-word compounds headed by deverbal nominal-isations.
For the first task we combined further useof the lemmatiser with the use of lexical resources.In a first pass we used the morpha lemmatiser tofind the verbal stem for -ing nominalisations suchas screening and then we looked up the remainingnouns in a nominalisation lexicon which we createdby combining the nominalisation list which is pro-vided by UMLS (2000) with the NOMLEX nominali-sation lexicon (MacLeod et al, 1998) As a result ofthese stages, most of the deverbal nominalisationscan be marked up with a VSTEM attribute whosevalue is the verbal stem:<W P=?NN?
LM=?reaction?
VSTEM=?react?>reaction</W><W P=?NN?
LM=?growth?
VSTEM=?grow?>growth</W><W P=?NN?
LM=?control?
VSTEM=?control?>control</W><W P=?NN?
LM=?coding?
VSTEM=?code?>coding</W>To mark up compounds we developed an fsgmatchgrammar for compounds of all lengths and kindsand we used this to process a subset of the first twoyears of the corpus.We interpret nominalisations in the biomedicaldomain using a machine learning approach whichcombines syntactic, semantic, and contextual fea-tures.
Using the LT XML program sggrep weextracted all sentences containing two-word com-pounds headed by deverbal nominalisations andfrom this we took a random sample of 1,000 nom-inalisations.
These were manually disambiguatedusing the following categories which denote theargument relation between the deverbal head andits modifier: SUBJ (age distribution), OBJ (weightloss), WITH (graft replacement), FROM (blood elim-ination), AGAINST (seizure protection), FOR (non-stress test ), IN (vessel obstruction), BY (aerosol ad-ministration), OF (water deprivation), ON (knee op-eration), and TO (treatment response).
We also in-cluded the categories NA (non applicable) for nom-inalisations with relations other than the ones pre-dicted by the underlying verb?s subcategorisationframe (e.g., death stroke) and NV (non deverbal) forcompounds that were wrongly identified as nomi-nalisations.We treated the interpretation of nominalisationsas a classification task and experimented with dif-ferent features using the C4.5 decision tree learner(Quinlan, 1993).
Some of the features we took intoaccount were the context surrounding the candidatenominalisations (encoded as words or POS-tags), thenumber of times a modifier was attested as an argu-ment of the verb corresponding to the nominalisedhead, and the nominalisation affix of the deverbalhead (e.g., -ation, -ment).
In the face of sparsedata, linguistic resources such as WordNet (Millerand Charles, 1991) and UMLS were used to recre-ate distributional evidence absent from our corpus.We obtained several different classification modelsas a result of using different marked-up versions ofthe corpus, different parsers, and different linguisticresources.
Full details of the results are describedin Grover et al (2002); we only have space for abrief summary here.
Our best results achieved anaccuracy of 73.6% (over a baseline of 58.5%) whenusing the type of affixation of the deverbal head, theTSG, and WordNet for recreating missing frequen-cies.5 ConclusionsWe have performed a number of different NLP taskson the OHSUMED corpus of MEDLINE abstractsranging from low-level tokenisation through shal-low parsing to deep syntactic and semantic analy-sis.
We have used XML as our processing paradigmand we believe that without the core XML tools thetask would have become extremely hard.
Further-more, we have built fully-automatic pipelines andhave not resorted to hand-coding at any point so thatour output annotations are completely reproducableand our resources are reusable on new data.
Ourapproach of building a firm foundation of low-leveltokenisation has proved invaluable for a variety ofhigher-level tasks.The XML-annotated OHSUMED corpus which hasresulted from our project will be useful for a num-ber of different tasks in the biomedical domain.
Forthis reason we are developing a web-site from whichmany of our resources (including the pipelinesdescribed in this paper) are available: http://www.ltg.ed.ac.uk/disp/.
In addition, we pro-vide various marked-up and tokenised versions ofOHSUMED, including the output of the parsers de-scribed here.ReferencesSteven Abney.
1996.
Partial parsing via finite-statecascades.
In John Carroll, editor, Proceedingsof Workshop on Robust Parsing at Eighth Sum-mer School in Logic, Language and Information,pages 8?15.
University of Sussex.Ted Briscoe and John Carroll.
1993.
Generalisedprobabilistic LR parsing of natural language (cor-pora) with unification grammars.
ComputationalLinguistics, 19(1):25?60.Ted Briscoe and John Carroll.
1997.
Automaticextraction of subcategorization from corpora.
InProceedings of the Fifth ACL Conference on Ap-plied Natural Language Processing, 356?363.John Carroll and Ted Briscoe.
2001.
High preci-sion extraction of grammatical relations.
In Pro-ceedings of the 7th ACL/SIGPARSE InternationalWorkshop on Parsing Technologies, pages 78?89,Beijing, China.Mark Craven and Johan Kumlien.
1999.
Construct-ing biological knowledge bases by extracting in-formation from text sources.
In Proceedings ofthe 7th Interntaional Conference on IntelligentSystems for Molecular Biology (ISMB-99).David Elworthy.
1994.
Does Baum-Welch re-estimation help taggers?
In Proceedings of the4th ACL conference on Applied Natural Lan-guage Processing, pages 53?58, Stuttgart, Ger-many.Roger Garside.
1987.
The CLAWS word-taggingsystem.
In Roger Garside, Geoffrey Leech, andGeoffrey Sampson, editors, The ComputationalAnalysis of English.
Longman, London.Gerald Gazdar, Ewan Klein, Geoff Pullum, and IvanSag.
1985.
Generalized Phrase Structure Gram-mar.
Basil Blackwell, London.Claire Grover, Colin Matheson, Andrei Mikheev,and Marc Moens.
2000.
LT TTT?a flexibletokenisation tool.
In LREC 2000?Proceedingsof the Second International Conference on Lan-guage Resources and Evaluation, pages 1147?1154.Claire Grover and Alex Lascarides.
2001.
XML-based data preparation for robust deep parsing.In Proceedings of the Joint EACL-ACL Meeting(ACL-EACL 2001).Claire Grover, Mirella Lapata and Alex Lascarides.2002.
A Comparison of Parsing Technologies forthe Biomedical Domain.
Submitted to Journal ofNatural Language Engineering.William Hersh, Chris Buckley, TJ Leone, and DavidHickam.
1994.
OHSUMED: an interactive re-trieval evaluation and new large test collection forresearch.
In W. Bruce Croft and C. J. van Rijsber-gen, editors, Proceedings of the 17th Annual In-ternational Conference on Research and Devel-opment in Information Retrieval, pages 192?201.Maria Lapata.
2000.
The automatic interpretationof nominalizations.
In Proceedings of the 17thNational Conference on Artificial Intelligence,pages 716?721, Austin, TX.Catherine MacLeod, Ralph Grishman, Adam Mey-ers, Leslie Barrett, and Ruth Reeves.
1998.NOMLEX: a lexicon of nominalisations.
In EU-RALEX?98, pages 187?194.Mitchell Marcus, Grace Kim, Mary AnnMarcinkiewicz, Robert MacIntyre, Ann Bies,Mark Ferguson, Karen Katz, and Britta Schas-berger.
1994.
The Penn treebank: annotatingpredicate argument structure.
In ARPA HumanLanguage Technologies Workshop.David McKelvie.
2000.
XMLPERL 1.7.2.
A RuleBased XML Transformation Language http://www.cogsci.ed.ac.uk/?dmck/xmlperl.Andrei Mikheev.
1997.
Automatic rule inductionfor unknown word guessing.
Computational Lin-guistics, 23(3):405?423.George A. Miller and William G. Charles.
1991.Contextual correlates of semantic similarity.Language and Cognitive Processes, 6(1):1?28.Guido Minnen, John Carroll, and Darren Pearce.2000.
Robust, applied morphological generation.In Proceedings of 1st International Natural Lan-guage Conference (INLG ?2000).Ross J. Quinlan.
1993.
C4.5: Programs for Ma-chine Learning.
Morgan Kaufman, San Mateo,CA.Henry S. Thompson, Richard Tobin, David McK-elvie, and Chris Brew.
1997.
LT XML.
Soft-ware API and toolkit for XML processing.
http://www.ltg.ed.ac.uk/software/.UMLS.
2000.
Unified Medical Language System(UMLS) Knowledge Sources.
National Library ofMedicine, Bethesda (MD), 11th edition edition.
