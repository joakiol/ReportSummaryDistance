Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1769?1773,October 25-29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsCipher Type DetectionMalte NuhnHuman Language Technologyand Pattern Recognition GroupComputer Science DepartmentRWTH Aachen Universitynuhn@cs.rwth-aachen.deKevin KnightInformation Sciences InstituteUniversity of Southern Californiaknight@isi.eduAbstractManual analysis and decryption of enci-phered documents is a tedious and errorprone work.
Often?even after spend-ing large amounts of time on a par-ticular cipher?no decipherment can befound.
Automating the decryption of var-ious types of ciphers makes it possibleto sift through the large number of en-crypted messages found in libraries andarchives, and to focus human effort onlyon a small but potentially interesting sub-set of them.
In this work, we train a clas-sifier that is able to predict which enci-pherment method has been used to gener-ate a given ciphertext.
We are able to dis-tinguish 50 different cipher types (speci-fied by the American Cryptogram Associ-ation) with an accuracy of 58.5%.
This is a11.2% absolute improvement over the bestpreviously published classifier.1 IntroductionLibraries and archives contain a large number ofencrypted messages created throughout the cen-turies using various encryption methods.
For thegreat majority of the ciphers an analysis has notyet been conducted, simply because it takes toomuch time to analyze each cipher individually, orbecause it is too hard to decipher them.
Automaticmethods for analyzing and classifying given ci-phers makes it possible to sift interesting messagesand by that focus the limited amount of human re-sources to a promising subset of ciphers.For specific types of ciphers, there exist au-tomated tools to decipher encrypted messages.However, the publicly available tools often de-pend on a more or less educated guess whichtype of encipherment has been used.
Furthermore,they often still need human interaction and areonly restricted to analyzing very few types of ci-phers.
In practice however, there are many differ-ent types of ciphers which we would like to an-alyze in a fully automatic fashion: Bauer (2010)gives a good overview over historical methods thathave been used to encipher messages in the past.Similarly, the American Cryptogram Association(ACA) specifies a set of 56 different methods forenciphering a given plaintext:Each encipherment method Mican be seen asa function that transforms a given plaintext into aciphertext using a given key, or short:cipher = Mi(plain, key)When analyzing an unknown ciphertext, we areinterested in the original plaintext that was used togenerate the ciphertext, i.e.
the opposite direction:plain = M?1i(cipher, key)Obtaining the plaintext from an enciphered mes-sage is a difficult problem.
We assume that thedecipherment of a message can be separated intosolving three different subproblems:1.
Find the encipherment method Mithat wasused to create the ciphercipher ?
Mi.2.
Find the key that was used together with themethodMito encipher the plaintext to obtaincipher = Mi(plain, key).3.
Decode the message using Miand keycipher ?
M?1i(cipher, key)Thus, an intermediate step to deciphering an un-known ciphertext is to find out which encryptionmethod was used.
In this paper, we present a clas-sifier that is able to predict just that: Given an un-known ciphertext, it can predict what kind of en-cryption method was most likely used to generate1769?
Type: CMBIFID?
Plaintext:WOMEN NSFOO TBALL ISGAININGI NPOPU LARIT YANDTHETOU RNAME?
Key:LEFTKEY=?IACERATIONS?RIGHTKEY=?KNORKOPPING?PERIOD=3, LROUTE=1RROUTE=1, USE6X6=0?
Ciphertext:WTQNG GEEBQ BPNQP VANENKDAOD GAHQS PKNVI PTAAPDGMGR PCSGNFigure 1: Example ?CMBIFID?
cipher: Text isgrouped in five character chunks for readability.it.
The results of our classifier are a valuable inputto human decipherers to make a first categoriza-tion of an unknown ciphertext.2 Related WorkCentral to this work is the list of encryption meth-ods provided by the American Cipher Associa-tion1.
This list contains detailed descriptions andexamples of each of the cipher types, allowing usto implement them.
Figure 3 lists these methods.We compare our work to the only previouslypublished cipher type classifier for classical ci-phers2.
This classifier is trained on 16, 800 cipher-texts and is implemented in javascript to run in theweb browser: The user can provide the ciphertextas input to a web page that returns the classifier?spredictions.
The source code of the classifier isavailable online.
Our work includes a reimple-mentation of the features used in that classifier.As examples for work that deals with the auto-mated decipherment of cipher texts, we point to(Ravi and Knight, 2011), and (Nuhn et al., 2013).These publications develop specialized algorithmsfor solving simple and homophonic substitutionciphers, which are just two out of the 56 ciphertypes defined by the ACA.
We also want to men-tion (de Souza et al., 2013), which presents a ci-pher type classifier for the finalist algorithms ofthe Advanced Encryption Standard (AES) contest.1http://cryptogram.org/cipher_types.html2See http://bionsgadgets.appspot.com/gadget_forms/refscore_extended.html and https://sites.google.com/site/bionspot/cipher-id-testsplaintext keyencipherciphertextclassifier trainingtypeFigure 2: Overview over the data generation andtraining of the classifier presented in this work.3 General ApproachGiven a ciphertext, the task is to find the right en-cryption method.
Our test set covers 50 out of 56cipher types specified by ACA, as listed in Fig-ure 3.
We are going to take a machine learning ap-proach which is based on the observation that wecan generate an infinite amount of training data.3.1 Data FlowThe training procedure is depicted in Figure 2:Based upon a large English corpus, we first choosepossible plaintext messages.
Then, for each enci-pherment method, we choose a random key andencipher each of the plaintext messages using theencipherment method and key.
By doing this, wecan obtain (a theoretically infinite) amount of la-beled data of the form (type, ciphertext).
We canthen train a classifier on this data and evaluate iton some held out data.Figure 1 shows that in general the key can con-sist of more than just a codeword: In this case,the method uses two codewords, a period length,two different permutation parameters, and a gen-eral decision whether to use a special ?6?6?
vari-ant of the cipher or not.
If not defined otherwise,we choose random settings for these parameters.If the parameters are integers, we choose randomvalues from a uniform distribution (in a sensiblerange).
In case of codewords, we choose the 450kmost frequent words from an English dictionary.We train on cipher texts of random length.3.2 ClassifiersThe previous state-of-the-art classifier by BIONuses a random forest classifier (Breiman, 2001).The version that is available online, uses 50 ran-1770?
6x6bifid?
6x6playfair?
amsco?
bazeries?
beaufort?
bifid6?
bifid7?
(cadenus)?
cmbifid?
columnar?
digrafid?
dbl chckrbrd?
four square?
fracmorse?
grandpre?
(grille)?
gromark?
gronsfeld?
homophonic?
mnmedinome?
morbit?
myszkowski?
nicodemus?
nihilistsub?
(nihilisttransp)?
patristocrat?
period 7 vig.?
periodic gro-mark?
phillips?
plaintext?
playfair?
pollux?
porta?
portax?
progkey beau-fort?
progressivekey?
quagmire2?
quagmire3?
quagmire4?
ragbaby?
randomdigit?
randomtext?
redefence?
(route transp)?
runningkey?
seriatedpfair?
swagman?
tridigital?
trifid?
trisquare?
trisquare hr?
two square?
two sq.
spiral?
vigautokey?
(vigenere)?
(vigslidefair)Figure 3: Cipher types specified by ACA.
Our classifier is able to recognize 50 out of these 56 ciphers.The braced cipher types are not covered in this work.dom decision trees.
The features used by this clas-sifier are described in Section 4.Further, we train a support vector machine usingthe libSVM toolkit (Chang and Lin, 2011).
Thisis feasible for up to 100k training examples.
Be-yond this point, training times become too large.We perform multi class classification using ?-SVCand a polynomial kernel.
Multi class classificationis performed using one-against-one binary classifi-cation.
We select the SVM?s free parameters usinga small development set of 1k training examples.We also use Vowpal Wabbit (Langford et al.,2007) to train a linear classifier using stochasticgradient descent.
Compared to training SVMs,Vowpal Wabbit is extremely fast and allows usinga lot of training examples.
We use a squared lossfunction, adaptive learning rates and don?t employany regularization.
We train our classifier with upto 1M training examples.
The best performing set-tings use one-against-all classification, 20 passesover the training data and the default learning rate.Quadratic features resulted in much slower train-ing, while not providing any gains in accuracy.4 FeaturesWe reimplemented all of the features used in theBION classifier, and add three newly developedsets of features, resulting in a total of 58 features.In order to further structure these features, wegroup these features as follows: We call the setof features that relate to the length of the cipherLEN.
This set contains binary features firing whenthe cipher length is a multiple of 2, 3, 5, 25, anyof 4-15, and any of 4-30.
We call the set of fea-tures that are based on the fact that the cipher-text contains a specific symbol HAS.
This set con-tains binary features firing when the cipher con-tains a digit, a letter (A-Z), the ?#?
symbol, theletter ?j?, the digit ?0?.
We also introduce an-other set of features called DGT that contains twofeatures, firing when the cipher is starting or end-ing with a digit.
The set VIG contains 5 features:The feature score is based on the best possible bi-gram LM perplexity of a decipherment compatiblewith the decipherment process of the cipher typesAutokey, Beaufort, Porta, Slidefair and Vigenere.Further, we also include the features IC, MIC,MKA, DIC, EDI, LR, ROD and LDI, DBL, NOMOR,RDI, PTX, NIC, PHIC, BDI, CDD, SSTD, MPIC,SERP, which were introduced in the BION classi-fier3.
Thus, the first 22 data points in Figure 4 arebased on previously known features by BION.
Wefurther present the following additional features.4.1 Repetition Feature (REP)This set of features is based on how often the ci-phertext contains symbols that are repeated ex-actly n times in a row: For example the cipher-text shown in Figure 1 contains two positions withrepetitions of length n = 2, because the cipher-text contains EE, as well as AA.
Beyond length2, there are no repeats.
These numbers are thennormalized by dividing them by the total numberof repeats of length 2 ?
n ?
5.4.2 Amsco Feature (AMSC)The idea of the AMSCO cipher is to fill consec-utive chunks of one and two plaintext charactersinto n columns of a grid (see Table 1).
Then apermutation of the columns is performed, and theresulting permuted plaintext is read of line by lineand forms the final ciphertext.
This feature readsthe ciphertext into a similar grid of up to 5 columns3See http://home.comcast.net/?acabion/acarefstats.html1771Plaintext w om e ns foo t ba l liPermutation 3 5 1 4 2Table 1: Example grid used for AMSCO ciphers.and then tries all possible permutations to retainthe original plaintext.
The result of this opera-tion is then scored with a bigram language model.Depending on whether the difference in perplexitybetween ciphertext and deciphered text exceeds agiven threshold, this binary feature fires.4.3 Variant Feature (VAR)In the variant cipher, the plaintext is written intoa block under a key word.
All letters in the firstcolumn are enciphered by shifting them using thefirst key letter of the key word, the second columnuses the second key letter, etc.
For different pe-riods (i.e.
lengths of key words), the ciphertextis structured into n columns and unigram statis-tics for each column are calculated.
The frequencyprofile of each column is compared to the unigramfrequency profile using a perplexity measure.
Thisbinary feature fires when the resulting perplexitiesare lower than a specific threshold.5 ResultsFigure 4 shows the classification accuracy for theBION baseline, as well as our SVM and VW basedclassifiers for a test set of 305 ciphers that havebeen published in the ACA.
The classifiers shownin this figure are trained on cipher texts of ran-dom length.
We show the contribution of all thefeatures we used in the classifier on the x-axis.Furthermore we also vary the amount of trainingdata we use to train the classifiers from 10k to 1Mtraining examples.
It can be seen that when usingthe same features as BION, our prediction accu-racy is compatible with the BION classifier.
Themain improvement of our classifier stems from theREP, AMSC and VAR features.
Our best classi-fier is more than 11% more accurate than previousstate-of-the-art BION classifier.We identified the best classifier on a held-outset of 1000 ciphers, i.e.
20 ciphers for each ci-pher type.
Here the three new features improve theVW-1M classifier from 50.9% accuracy to 56.0%accuracy, and the VW-100k classifier from 48.9%to 54.6%.
Note that this held-out set is based onthe exact same generator that we used to create thetraining data with.
However, we also report theresults of our method on the completely indepen-dently created ACA test set in Figure 4.6 ConclusionWe presented a state-of-the art classifier for ciphertype detection.
The approach we present is easilyextensible to cover more cipher types and allowsincorporating new features.AcknowledgementsWe thank Taylor Berg-Kirkpatrick, Shu Cai, BillMason, Be?ata Megyesi, Julian Schamper, andMegha Srivastava for their support and ideas.
Thiswork was supported by ARL/ARO (W911NF-10-1-0533) and DARPA (HR0011-12-C-0014).102030405060HASLENVIGICMICMKADICEDILRRODLDIDBLNMORRDIPTXNICPHICBDICDDSSTDMPICSERPREPAMSCVARFeaturesAccuracy(%)BIONSVM 10kSVM100kVW 100kVW 1MFigure 4: Classifier accuracy vs. training data and set of features used.
From left to right more andmore features are used, the x-axis shows which features are added.
The feature names are described inSection 4.
The features right of the vertical line are presented in this paper.
The horizontal line showsthe previous state-of-the art accuracy (BION) of 47.3%, we achieve 58.49%.1772ReferencesF.L.
Bauer.
2010.
Decrypted Secrets: Methods andMaxims of Cryptology.
Springer.Leo Breiman.
2001.
Random forests.
Machine Learn-ing, 45(1):5?32, October.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A library for support vector machines.
ACMTransactions on Intelligent Systems and Technol-ogy, 2:27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.William AR de Souza, Allan Tomlinson, and Luiz MSde Figueiredo.
2013.
Cipher identification with aneural network.John Langford, Lihong Li, and Alex Strehl.
2007.Vowpal Wabbit.
https://github.com/JohnLangford/vowpal_wabbit/wiki.Malte Nuhn, Julian Schamper, and Hermann Ney.2013.
Beam search for solving substitution ciphers.In ACL (1), pages 1568?1576.Sujith Ravi and Kevin Knight.
2011.
Bayesian Infer-ence for Zodiac and Other Homophonic Ciphers.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics (ACL), pages239?247, Stroudsburg, PA, USA, June.
Associationfor Computational Linguistics.1773
