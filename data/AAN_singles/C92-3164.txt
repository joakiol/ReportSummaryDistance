A SPOKEN LANGUAGE TRANSLAT ION SYSTEM : SL -TRANS2Tsuyosh i  MORIMOTO,  Masami  SUZUKI ,  Tosh iyuk i  TAKEZAWA,Gen ' i ch i ro  K IKU I ,  Masaak i  NAGATA,  Mutsuko  TOMOKIYOATR In terpret ing  Te lephony  Research  Laborator iesSeika.cho, Souraku-gun, Kyoto, 619-02, JAPAN1.
In t roduct ionAn automatic telephone interpreting systemwil l  undoubted ly  be used to overcomecommunicat ion  bar r ie rs  between peoplespeaking different languages.
Recently, greatinterest has been growing in this area \[Saitoh-88\], \[Waibel-91l, \[Kitano-91\], \[Roe-92\].
SL-TRANS2 .1~ is an experimental system developedat ATR, which translates Japanese speech toEnglish speech.
It is composed of three basiccomponents: peech recognition, translation andspeech synthesis.
This paper introduces thesystem with emphas is  on the t rans la t ioncomponent.
The discourse domain is a dialogueconcern ing  an in ternat iona l  conferenceregistration.
The dist inctive features of thesystem are as follows.
(1) Japanese continuous peech input can berecognized with h igh accuracy.
Moreover,speaker independent recognition using speakeradaptation technique has been developed.
(2) Various expressions pecul iar to spokenlanguage can be accepted and translated properlyinto the target language.
In Japanese, the style ofspoken sentences is generally quite differentfrom that of written texts.
Spoken utterances arefragmentary and include the speaker's intentiondirectly or indirectly.
The system extracts theintention and then transcribes it to a properexpression i the target language.
(3) Linguistic knowledge sources necessary forthe translation are defined declaratively to theextent .
Such de f in i t ion  improves  h ighmodularity, readability and easy maintenance ofknowledge description.In the next section, the system is overviewedand a brief description of the speech recognition*1) SL-TRANS2 is the extended version of SL-TRANS \[Morimoto-90\]mechanism is given.
In the following threesections, distinctive technical features of eachcomponent  of the t rans la t ion  sys tem aredescribed.
Experiment results  are shown insection 6.2.
System Overv iewA block diagram of the system is shown inFig.1.
Using a speaker adaptation technique, theInput SpeechI ISpeechRecognitionGenerationLanguageAnalysisOutput Speech, tSpeech Synthesis \]Zero Anaphora J \] Resolution ~ TransferFig.
1 SL-TRANS2speech recognizer can accept any speaker'sspeech.
Phone level Hidden Marker  Models(HMM) and syntactic rules for Japanese aredefined in the recognizer \[Kita-90\].
By referringto these rules, the recognizer predicts the nextpossible phones and verifies their existence bymatching them with corresponding HMMs.
Theprocess is invoked for many hypotheses inparallel until the end of the utterance is reached.Finally, the n-best sentential hypotheses areoutput, with their respective recognition scores.The output hypotheses are tagged with wordinformation such as a part-of-speech label, thenAcI~ DE COLING-92, NANTES.
23-28 AOC'r I992 1 0 4 8 PROC.
OF COLING-92, NArcrEs, AUG. 23-28, 1992the speech recognizer works as a kind ofmorphological nalyzer for the following analysiscomponent.
These hypotheses are all well-formedsyntactically, hut not always semantically,pragmatically orcontextually.The next analysis component checks thevalidity of each hypothesis and selects the mostplausible one*2).
After analysis, some zeroanaphora  (noun phrase  e l l ipses)  aresupplemented using pragmatics such as honorificexpressions in Japanese.
Then, the semantics ofthe sentence is output in the form of a featurestructure.
This feature structure is generallycomposed of two parts: an intentional content anda propositional content.
The former indicates thespeaker's intention and is expressed in terms oflanguage-independent conccpts.
The latter isexpressed in terms of language-dependentconcepts.
The subsequent transfer systemtransfers only the propositional content o theirtarget language concepts.
During Um generationprocess, tim two components are merged and af'mal surface xpression i the target language isgenerated.
Finally, synthesized English speech isoutput from the synthesizer.
Currently,  acommercial English language speech synthesizeris used in the system.3.
Ana lys i s3.1 Grammar  Formal i za t ionThe grammar  formalisnl adopted wasoriginally based on HPSG ( and its Japaneseversion JPSG) \[Kogure-90\].
In each lexical entry,syntactic onstraints, emantic onstraints andeven pragmatic onstraints are defined as afeature structure (Fig.2).Parsing is basically accomplished using aunification operation between lexical items orsuccessively derived constituents.
This iseffective in parsing Japanese spoken sentenceswhich have a variety of expressions.
Accordingto the JPSG theory, a few principles (the headfeature principle, the subeategorization featureprinciple, etc.)
and one grammar rule (a motheris composed of a daughter and a head) are*2) The contextual evaluation function isnot yet implemented in the current system(deflex-named ~-1  ~ vstern(< !rn syn head grfs> = =\[subj ?
(subj \[\[sysn \[\[head \[\[pos N\]\[form i9~'\]\]\]\]\[sem ?subj-sem\]\])\]\[ohj ?
(obj \[\[sysn \[\[head \[\[pos N\]\[form ~ \]\]\]\]\[sem ?obj-sem\]\])\]ffsc-sl-2 ?subj ?obj)< !m !sere > = = \[\[rein ~-1 \ ]\[agen ?subj-sern\]\[obj ?obj-seml\])<Ira !prag> = =....)Fig.2 Lexieal Entry for Analysissufficient o cover all linguistic phenomena.ltowever, naive implementation f the theory asa practical system brings an explosion ofprocessing time and memory consumption, evenfor a simple sentence.
To solve this problem,medium grained context free grammar (CFG)rules are introduced \[Nagata-92\].
The grammarrules are constructed to maintain declarativedescription of lexieal constraints and also tosuppress unnecessary unification execution.
Forinstance, the concatenation conditions betweenJapanese verbs and auxil iaries are definedexplicitly by the rules.3,2 Pars ing  A lgor i thmPars ing is guided by CFG ru les andaccomplished by the unification operation asdescribed above.
Genera l ly ,  most of theprocessing time in a unification-based parsingmethod is consumed for the unification operation.In this system, besides dividing CFG rules asmentioned above, other efficiency improvingtechnologies have been introduced.
For instance,unification execution is delayed until all CFGrules have been applied.
Another approach is toimprove the unification procedure itself.
In oursystem, an efficient unification mechanism usingseveral techniques such as the quasi-destructivegraph unification algorithm \[Tomabechi-91\] hasbeen implemented.
Using these improvements,tiffs system can analyze an input utterance in afairly short ime.3.3 Zero  Anaphora  Reso lu t ionACRES DE COLING-92, NANTES, 23-28 hotter 1992 i 0 4 9 Paoc.
OF COLING-92.
NANTES, AUO.
23-28, 1992Some zero anaphora are resolved andsupplemented using pragmatic information inJapanese \[Dohsaka-90l.
In general, pronounsindicating the participants such as "I" or "You"are seldom explicit in spoken Japanese.
On theother hand, Japanese is abundant in honorificexpressions, and such information can be used tointerpret some zero pronouns.
For instance, inthe following example, the agent of the predicate"okuru" (send) in the last phrase can be inferredto be the speaker because he (she) is stating apromise and expressing it politely.
Then, theindirect object of"okuru" is decided as the hearer,if the dialogue only concerns two participants.tourokuyoushi-wo(a registration form-ACC j4)ookuri-itashimasu(send-Polite~Promise)Other zero anaphora, especially a subject, ina sentence wi thout  such in format ion  isinterpreted as the speaker.4.
T rans ferInput to the transfer process is a featurestructure indicating the semantics of anutterance.
The feature structure is representedrecursively using relationships.
A relationshipconsists of a relationship name and its case roles.A relationship name is essentially a concept.
Inthe analysis system, the surface illocutionaryforce type for the utterance is calculated from thesurface expression.
This is converted to anappropriate illocutionary force type by analyzingand taking into consideration the speaker's planin that situation.
In the current system, however,this conversion is done straight from the surfaceillocutionary force type because a contextualprocessing mechan ism has not yet beenintegrated into the system.
Typical illocutionaryforce types establ ished for goal -or ienteddialogues, uch as those in the target domain, areshown in Table 1.The transfer system transfers only thefeature structure of the propositional contentusing a feature structure rewrit ing system\[Hasegawa-90\].
The rewriting system traversesan input feature structure and rewrites itaccording to a set of rewriting rules.
There areTable 1 Examples oflllocutionary Force TypeType ExplanationPHATIC Phatic expression suchas those to open or closedialogue (Hello, Thankyou)INFORM Inform a hearer of somefactsREQUEST Request ahearer tocarry out some action(Please tell me---)QUESTIONIF Yes/No questionQUESTIONREF WH question, .
=many kinds of rules such as concept-to-concepttransfer ules or structural transfer ules fromJapanese-to-English; or even Japanese-to-Japanese paraphras ing rules which maket rans fer r ing  eas ier .
A ru le is def ineddeclaratively and composed of three sub-specifications as in Fig.4: an environmentcondition, an input condition and an outputspecification.
The environment condition is usedon <rein> ~ts=9 in :phase J-Ein= \[\[rein ~\ ]\[agen ?agen\]\[obje ?object\]?rest\]out =\[\[retn have\]\[agen ?agen\]\[obje ?object\]?rest\]Fig,3 Transfer Ruleto control the application of rules instead ofencoding explicit relationships between rules;when some condition is given, only the rulessatisfying it are applied.
It could also be used totransfer the input properly based on a givencontext.Another important problem in the transferprocess i  how to disambiguate polysemous wordsand how to choose aproper target concept.
In thissystem, a thesaurus of concepts is defined andused for this purpose.
This thesaurus  isACRES DE COTING-92, NANTES, 23-28 AOt~T 1992 1 0 S 0 PREC.
OF COLING-92, NANTES, AUO.
23-28, 1992implemented as a type system and referred to byrelated rules.5.
Generat ionThe basic method used in the generationsystem is also a unification algorithm.
However,unlike the analysis system, each linguisticgeneration rule is defined for a comparativelylarge unit.
This is because the variety ofsentences tobe generated is not as great as thatin analysis, e.g.
an idiomatic expression can beused in certain cases.
A generation rule is definedas a phrase definition \[Kikui-92\].
A phrasedefinition is basically composed of three sub-specifications as shown in Fig.4: a syntacticphrase structure, syntactic constraints andsemantics, and an application environment.structure (S-TOP (S AUX (NP PRON) VP) SIGN)annotation(S-TOP \[\[syn \[\[e-cat S-TOP\]\]\]\[sem \[rein REQUEST\]\[agen ?agen *SP*\]\[recp *HR*\]\[obje ?action\]\]\]\])(S \[\[syn \[\[e-catS\]\[e-inv +\]\[e-slash -\]\]\]\])(AUX \[\[syn \[\[e-catAUX\]\[e-lex "would"\]\]\]\])(NP \[\[syn \[\[e-cat NP\]\]\]I)(PRON \[\[syn \[\[e-cat PRON\]\[e-lex "you'\]\]\]\[sem *SP*\]\])(VP \[\[syn \[\[e-cat VP\]\[e-vform BSE\]\[e-subj \[\[sem ?agen\]\]\]\]\]\[sem ?action\]\])(SIGN \[\[syn \[e-catSIGN\]\[e-lex "?~\]\]\])environment \[ \]Fig.4 Phrase Definition RuleIn principle, a phrase definition is equivalentto a syntactic derivation rule augmented withsemantics, other linguistic constraints andenvironmental  constraints.
Generat ion isexecuted by activating related phrase definitionssuccessively which can subsume the wholesemantics of the input feature structure.
Thevalidity of a combination ofphrase definitions isexamined using the unification algorithm.Finally, a set of phrase definitions is determinedand their combined syntactic structure isproduced as a result.
An environment descriptionis not used in the current system, but will be usedto generate a more appropriate xpression i  agiven context.6.
Exper imentThe SL-TKANS2 system as developed so farcan treat utterances from about 600 vocabularyitems.
It runs on a UNIX-workstation such asSPARC-2.
Average run time for one utterance isabout one minute, half for speech recognition andhalf for translation.
A preliminary experimenthas been carried out on five dialogues, whichinclude 101 sentences.
The resu l t s  aresummarized in Table 2.
Input speech materialare specific speaker's utterances.
Abilities o?Table 2 Experiment ResultCorrectOutputIncorrectOutputNo OutputAs a Component TotalSystemSR TR*3) (SR + TR)86 99 85(85%) (98%) (84%)12 2 4(12%) (2%) (4%)3 0 12(3%) (0%) (12%)Number of sentences(Percuntage)speech recognition (SR) and translation (TR) as asingle component arc about 85% and 98%respectively.
Correctness of t rans lat ion isevaluated whether the generated sentences arcgrammat ica l ly  correct and semant ica l lyunderstandable (minor errors those involvingdeterminers are ignored).
We can see that thetranslation part has high translation ability as a*3) The xperiment was carried out on stringinputsACRES DE COLING-92, NANTES, 23-28 AOI~T 1992 1 0 5 1 PROC, OF COLING-92, NANTES, AUG. 23-28, 1992single component.
Only two sentences indicatedbelow fall to t rans late  properly.J l :  4-man-yen-desu(40-thousand-yen-is)El :  I am 40 thousand yen.J2: touroku-youshi-wo( regis tration-form-A CC .4)okur imasu-node,(send- CA U)sore-we goran-kudasa i(it-ACC see-please)E2: Please see i t s ince  I send an  announcementof the conferenceIn J1 ,  the subject  of the sentence  is notuttered explicit ly, because it is easi ly inferable as"registrat ion- fee" from the context.
The system,however,  erroneously supplements  'T '  s ince nohonorif ic expression appears  in the sentence.In Japanese  sentence  J2 ,  a ma in  c lauseappears  later  and a pronoun "sore" (it) referr ingto " teuroku-yoush i"  (a registration-form} in thef irst c lause is used.
The system does not see thisre ferent ia l  re la t ionsh ip ,  and  so i t  fa i l s  togenerate  a proper Engl ish sentence.As a total  system, about  84% of the samplesentences  are  recognized and t rans la ted  intoEng l i sh  cor rect ly .
Some examples  are  shownbelow.J3: 9 -gatsu  27-n ieh i - i kou-no  to r ikesh i -n i -ta i suru  hara imodosh i -wa dek imasenE3: The re fund  to the cance l la t ion  a f te rSeptember 27th is not possible.J4 :  dewa dareka-ga  watash i -no  kawar i -n isankasuru-koto -wa dek imasu-ka?E4: Then, can  someone at tend instead of me?Genera l ly  speak ing ,  it  is des i rab le  that  at rans lat ion  system be able to detect er roneousspeech recognit ion output.
In our system, most  ofsuch fa i lures are  f i ltered out, but  two sentencesare t rans la ted  into Engl ish.
These undes i rab leoutcomes are due to inadequacy  of se lect ionalrestr ict ions used in the t rans lat ion component,  asindicated below.\[ Input\] J5:kouzabangou-n i*4)Meanings of symbols used here are;ACC:Aecusat ive,  CAU:Cause, TP:To -Place(the bank-account-TP)fur ikonde -kudasa i(transfer-please)\ [Output  f rom SR\] J5':kouzabangou-wo(the bank.account-ACC~fur ikonde -kudasa i(transfer-please)\ [Output  f rom TR\] E5':P lease t ransfer  the bank  account.7.
ConclusionThe main  features  of  the  t rans la t ioncomponent of SL -TRANS2 are  descr ibed.
Thepre l iminary  exper iment  has  shown promis ingresults.
We are current ly  extending not only thevocabulary  size from 600 up to 1500, but  also thefunct ional i ty  of the system by improv ing severalfunct ions  and  in t roduc ing  a contextua lprocessing mechanism.Reference\[Saitoh-98\] Salts, H., Tomita, M. : ~Paraing Noisy Sentences ~.Prec.
of COLINC~88,1988\[Walbel-911 Waibel, A. et al : "JANUS: a Speech-to-speechTranslation System Using Conneetionist and SymbolicProcessing Strategies", Prec.
oflCASSP-91,1991\[Kitano-91\] Kitano,li.
: ~DM-Dialog M,Computsr,june,1991\[Roe.92\] Roe, D.B.
et al :"Efficient Grammar Processing for aSpoken Language Translation System ~, Prec.
of ICASSP-92,1992\[Morlmoto-90\] Morimoto,T., lida,H.?
Kurematsu,A.,Shikano, K., Aizawa,T.
: "Spoken Language Translation -Toward Realizing an Automatic Telephone InterpretationSystem ~, Prsc.
oflnfo Japan-90, Tokyo, 1990\[Kogure-90\] Kogure,K., Hesegawa,T., Ogura,K.
: "NADINE -An  Experimental Dialogue Translation System fromJapanese to English", Prec.
of Info Japan-90, Tokyo, 1990\[Kita-90\] Kita,K., Takezawa,T., Hosaka,j., Ehara,T.,Morimoto,T.
: UContinuous Speech Recognition Using Two-level LR Parsing ~, Prec.
of ICSLP-90,1990\[Hasegawa-90\] Hasegawa,T.
: "Rule Application ControlMethod in a Lexlcon-driven Transfer Model of a DialogueTranslation System ~, Prec.
of ECA1-90,1990\[Dohsaka-90\] Dohsaka,K.
: Mldentifying the Referents of Zero-Pronouns in Japanese Based an Pragmatic ConstraintInterpretation ", Prec.
of ECAI-90,1990\[Tomabechi.91\] Tomabechi, H. : "Quasi-destructive GraphUnification ", Prec.
of ACl~91,1991\[Negate-92\] Nagata,M.
: "An Empirical Study on RuleGranularity and Unification Interleaving Toward anEfficient Unification-based Parsing System ", Submitted toCOLINC--92\[Kikul.92\] Kikui,G.
: ~Featurs Structure based SemanticHead Driven Generation ~, Submitted to CO LINCr92AcrEs DE COLING-92, NANTES, 23-28 AOt~'r 1992 I 0 S 2 PROC.
OF COLING-92, NANTES.
AUG. 23-28, 1992
