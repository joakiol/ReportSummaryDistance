Semantic Role Labeling of Chinese Using Transductive SVM andSemantic HeuristicsYaodong Chen        Ting Wang         Huowang Chen        Xishan XuDepartment of Computer Science and Technology, School of Computer,National University of Defense TechnologyNo.137, Yanwachi Street, Changsha, Hunan 410073, P.R.China{yaodongchen, tingwang, hwchen}@nudt.edu.cn   xxs@hnmcc.comAbstractSemantic Role Labeling (SRL) as aShallow Semantic Parsing causes moreand more attention recently.
The shortageof manually tagged data is one of mainobstacles to supervised learning, which iseven serious in SRL.
Transductive SVM(TSVM) is a novel semi-supervised learn-ing method special to small mount oftagged data.
In this paper, we introduce anapplication of TSVM in Chinese SRL.
Toimprove the performance of TSVM, someheuristics have been designed from thesemantic perspective.
The experiment re-sults on Chinese Propbank showed thatTSVM outperforms SVM in small taggeddata, and after using heuristics, it performsfurther better.1 IntroductionSemantic analysis is one of the fundamental andkey problems for the research in computationallinguistics.
Traditional semantic research ismainly concerned with deep analysis, which pro-vides a representation of the sentence in predicatelogic or other formal specification.
Recently, shal-low semantic parsing is becoming a hotspot insemantic analysis research.
Semantic Role Label-ing is a shallow semantic parsing technology anddefined as a shared task in CoNLL-04.
It aims atrecognizing semantic roles (i.e.
arguments) foreach target verb in sentence and labeling them tothe corresponding syntactic constituents.
ManySRL research utilizes machine learning methods(Park, 2005; Pradhan, 2005; Cohn, 2005), inwhich the high performance reported was attrib-uted to large tagged dataset (Carreras, 2005).
Butone of the main obstacles to supervised learning isthe shortage of manually labeled data, which iseven serious in SRL.
It could bring about onequestion: whether these methods perform wellwhen large mount of tagged data are not available?In this paper, we investigate Transductive SVM(Joachims, 1999), a semi-supervised learningmethod, for this question.
The proposed methoduses large untagged data in training with the sup-port of the linguistic knowledge of semantic roles.Generally speaking, not all constituents in syn-tactic tree could act as argument candidates inSRL.
Large redundant constituents lead to a hightraining cost and decrease the performance of sta-tistical model especially when tagged data is small.In contrast to the pruning algorithms in Park(2005) and Xue (2004) which are based on syntax,some argument-specific heuristics, based on wordsemantic features of arguments, make semanticrestrictions on constituent candidates to optimizedataset of statistical models.
The experiment re-sults on Chinese Propbank shows that TSVM out-performs regular statistical models in small taggeddata, and after using argument-specific heuristics,it performs further better.The rest of this paper is organized as follows.Section 2 gives the definition, method, and re-sources about SRL.
Section 3 discusses how toapply TSVM for SRL.
Some argument-specificheuristics are introduced in Section 4.
And then,section 5 shows the experiment results of the pro-posed methods and compare it with SVM.
Finally,we conclude our work in section 6.9192 Problem Definitions & Related WorksComparing with full parsing, SRL acts on partof constituents in sentences in order to achievehigh performance and robustness, as well as lowcomplexity in practices.
The SRL problem can bedescribed as follows.Definition Given a semantic role (or argument)collect R and a sentence S, for any substring c of S,SRL is a function: c?R?NONE, where NONE isthe value excluded in R.Notice that c usually indicates phrases in a sen-tence.
SRL can be classified to two steps:z Identification: c?
{NONE, ARG}.
It is abinary-value function where ARG is assignedto c when it should be labeled at some ele-ment of R, or NONE is assigned.
Identifica-tion separates the argument substrings fromthe rest of sentence, in another words, findsthe argument candidates.z Classification: c?R.
It is a multi-value func-tion which assigns a role value to c, that is,labels a role to some candidate.Some typical systems, based on inductive learn-ing, have been evaluated in CoNLL-05 (Carreras,2005).
It concluded that the performance of SRLdepends on the combination of several factors in-cluding models, features, and results of syntacticparsing.
The best result achieved F1=75.04 1 .These systems have strong dependency on largetagged data.
This paper evaluates the performanceof a classical supervised learning method--SVMin small tagged data and introduces a novel semi-supervised method to handle this problem.There are two tagged corpora available for SRL:one is Proposition Bank (Propbank); the other isFrameNet.
The Propbank annotates the PennTreebank with verb argument structure accordingas Levin class (Levin, 1993).
It defines a generalset of arguments for all types of predicates, andthese arguments are divided into core and adjunctones.
FrameNet, as a linguistic ontology, describethe scenario related to each predicates.
The sce-nario (i.e.
frame) is filled with specific partici-pants (i.e.
role).
In this paper, we use ChinesePropbank 1.0 provided by Linguistic Data Consor-tium (LDC), which is based on Chinese Treebank.It consists of 37,183 propositions indexed to the1 F1 measure computes the harmonic mean of precisionand recall of SRL systems in CoNLL-2005first 250k words in Chinese Treebank 5.1, includ-ing 4,865 verb types and 5,298 framesets.3 TSVM based SRL3.1 TSVMThere are two kinds of learning modes that areapplied in Artificial Intelligence, i.e.
inductiveinference and transductive inference.
In classifica-tion problems, inductive inference trains a globalmodel based on tagged instances from the wholeproblem space and classify new untagged in-stances by it.
The classical statistical models suchas SVM, ME have been developed in this way.Since large mount of tagged data are usually ac-quired difficultly in practice, and the global mod-els are hard to get when tagged training data arenot enough to find the target function in the hy-pothesis space.
In addition, this global model maybe unnecessary sometimes when we only care forspecific data.
Compared with inductive inference,transductive inference classifies untagged in-stances by a local model based on the clusteringdistribution of these untagged instances.
TheTSVM, a representative of transductive inferencemethod, was introduced by Joachims (1999).TSVM is a good semi-supervised method specialto some cases where the tagged data is difficult toacquire on a large scale while large untagged datais easily available.
TSVM can be formulated as anoptimization problem:Minimize Over (y1*..yn*, w, b,?1..?n, ?*..
?k*) in**ww2111__ ?
?==?+?+kiiniiTCC ??
, subject to:0for  -1  b)  xw( y 1      ii__in1i ??>+??
== ini ?
?0*for   * -1  b)  *xw( *y k 1iii__ik1i ??>+??
== i?
?where (x1,y1),?,(xn,yn) ?
Strain, y1,?,yn?
{-1,+1}, x1*,?,xn*?Stest, y1*,?,yn* is the labels ofx1*,?, xn*, C and C* , specified by user, are theeffect factor of the tagged and untagged examplesrespectively, C*?i* is the effect term of the ithuntagged example in the above objective function.In addition, a cost-factor Ctemp, which indicates theratio of positive untagged examples, should bespecified experientially by user before training.Here we introduce the algorithm briefly, andthe detail is referred to Joachims (1999).
The algo-rithm starts with training regular SVM with the920tagged examples and then classifies the untaggedexamples by the trained model.
Then several cou-ples of examples (one is positive, the other isnegative) are switched in class labels according tosome rule, and the model is retrained to minimumthe objective function.
At the same time, Ctemp willincrease in consistent way.
The iteration will endwhen Ctemp goes beyond C*.
The algorithm isproved to converge in a finite number of steps.3.2 Apply TSVM for SRLThe SRL using TSVM is related to followingportions:Dataset The principle of TSVM described inabove section implicitly indicates the performancedepends deeply on dataset (including tagged anduntagged data).
In particular, tagged data have aninfluence on original regular SVM in the first stepof training, while the untagged data will affect thefinal performance through the iteration of training.It is obvious that the more even the data set distri-bution is, the better the learning classifier will per-form.
Similar to most practical classification task,a serious uneven problem (Li, 2003) exists in SRL.For instance, the number of constituents labeled toarguments (positive instances) is much less thanthe number of the rest (negative instances).
Tohandle this problem, we design some heuristicsfor several kinds of arguments (that is, ARG0,ARGM-TMP, ARGM-LOC, ARGM-MNR,ARGM-DIR and ARGM-EXT) semantically.These heuristics filter out redundant constituentsand raise the ratio of positive instances in thedataset.
We will compare these argument-specificheuristics with Xue (2004), and some results areshowed in Section 4.Parameters The ratio of positive examples indataset, P, is a key parameter in TSVM andshould be assigned as one prior value in experi-ment.
In this paper, P is dynamically assigned ac-cording to different argument since different heu-ristics could produce different proportion of posi-tive and negative instances used to training data.Features A wide range of features have beenshown to be useful in previous work on SRL(Pradhan, 2005; Xue et al 2004).
This paperchooses 10 features in classification because oftwo reasons: at first, they are the core featuresconsidered to have significance on the perform-ance of SRL (Carreras, 2005); secondly, thesefeatures provide a standard to evaluate differentmethods of Chinese SRL.
These features are listedin Table 1, detail description referred in Xue(2005).Feature DescriptionPredicate The predicate lemmaSubcat-Frame The rule that expands the parent ofverbPath The syntactic path through the parsetree from the parse constituent  tothe predicate being classifiedPosition A binary feature identifying whetherthe phrase is before or after thepredicatePhrase Type The syntactic category of the phrasecorresponding to the argumentPhrase type of thesibling to the leftThe syntactic category of the phraseis sibling to the argument in the leftHead Word andPart Of SpeechThe syntactic head of the phraseFirst and last wordof the constituentin focusFirst and last word of phrase corre-sponding to the argumentSyntactic Frame The syntactic frame consists of theNPs that surround the predicateTable 1.
The features of Semantic Role LabelingIt should be mentioned that we have not con-sidered the Combination features (Xue et al 2005)because the above 10 features have already codedthem.
Verb class is also not be used here since wehave no idea about the syntactic alternations usedfor verb classification in Xue (2005) and could notevaluate them equally.
So, the experiment in thispaper refers to the results without verb class inXue (2005).Classifiers Chinese Propbank has 22 argumenttypes, in which 7 argument types appearing lessthan ten times or even having no appearance havenot been considered, that is,ARGM-FRQ, ARGM-ASP, ARGM-PRD, ARGM-CRD, ARGM-T, andARGM-DGR.
So we have developed 15 binaryclassifiers for those 15 type of arguments and ex-cluded the above 7 because they hardly provideuseful information for classification, as well ashave slightly influence on results (account for0.02% in all arguments appeared in the corpus).4 HeuristicsIn this section, we discuss the principle of thedesigning of the argument-specific heuristics.
Tohandle the uneven problem in SRL, six semanticheuristics have been designed for six types of ar-guments, such as ARG0, ARGM-TMP, ARGM-921LOC, ARGM-MNR, ARGM-DIR, and ARGM-EXT.
The heuristic is actually some restrictiverules which can be viewed as pre-processing ofidentification.
(Xue et al 2004) introduced a pri-mary algorithm for pruning argument non-candidates.
The algorithm still remain large re-dundant unnecessary constituents yet (correct ar-guments account for 7.31% in all argument candi-dates extracted).
(Park, 2005) used the clauseboundary restriction and tree distance restrictionfor extracting candidates based on Governmentand Binding Theory.
All of these restrictive rules,however, are on the syntax level.
Here we con-sider several semantic features directly extractedby the head word of the argument in lexicon.
Thisis based on facts that ARG0 contain mostly NPswhose head words are animate objects or entities.
(Yi, 2007) shows agent and experiencer as ARG0accounts for 93% in all ARG0s in Propbank.
Inaddition, some head words of the constituents la-beled by ARGM-TMP have temporal sense,which is the same as ARGM-LOC whose headwords usually have spatial sense.
The semanticinformation can be extracted from a Chinese-English bilingual semantic resource: HowNet(Dong, 2000).
HowNet is an on-line common-sense knowledge base providing a universal lexi-cal concept representation mechanism.
Wordsense representations are encoded by a set of ap-proximately 2,000 primitive concepts, called se-memes.
A word sense is defined by its primarysememes.
For example, ??
(child) is definedwith sememes ?human|?
?, ?young|??
; ??
(atpresent) has sememes ?time|??
?, ?now|??
; ?
(street) contains sememes ?location|??
?, ?route|??.
We considered sememes as the basis of heu-ristics, and Table 2 shows these heuristics.Table 2 shows the argument-specific heuristicson the semantics level, for example, only whenthe head word of a PP contains a sememe ?time|??
?, it could be a candidate of ARGM-TMP,such as ?
?, ??
; only a sememe ?location|???
has a head word of one phrase, it may be la-beled to ARGM-LOC.
Furthermore, we make acomparison with Xue (2004) in whole argumenttypes on Chinese Propbank (the extraction princi-ple about argument types which are not listed inTable 1 is the same as Xue (2004)).
We find theargument-specific heuristics decrease in unevenproblem more effectively than Xue (2004).
Theoverall coverage 2 rises from 7.31% to 20.30%, thatis, 65% constituents which have no possibility tolabeling have been pruned based on six types ofarguments.
And the overall recall of arguments incorpus decline slightly from 99.36% to 97.28%.Args Def Heuristic Cover-ageARG0 agent,exp-eriencerthe NP whose headword has sememe that ishyponymy with animate|??
or whose head word isplace or organization38.90ARGM-TMPtemporal The NP and LCP whosehead word has sememetime|??
or the PP whoseprep is from|?, from|?,to|?, in|?, or at|?58.7ARGM-LOClocation The NP and LCP whosehead word has sememelocation|??
or the PPwhose prep is in|?
,at|?or from|?44.4ARGM-MNRmanner The PP whose prep is ?ac-cording to|?
?, ?,?, ???
or by|?
?, as|?
?30.98ARGM-DIRdirectional The PP whose prep is to|?or from|?, to|?20.56ARGM-EXTextent The NP and QP whose headword is number70.27Table 2.
The arguments-specific heuristics.5 Experiment and discussionThis section will describe the experiment on theSRL in Chinese Treebank, compare TSVM withregular SVM, and evaluate the effect of the pro-posed argument-specific heuristics.5.1 Experiment SettingSVM-light3 is used as a SVM classifier toolkitin the experiment, which includes some sub-toolsfor optimizing performance and reducing trainingtime.
It also provides an approximate implementa-tion of transductive SVM.
At first, about 80%propositions (1711891) has been extracted ran-domly from the corpus as the dataset, which hadbeen divided into tagged set and untagged set ac-cording to 4:1.
Then, for each type of arguments,2The coverage means the ratio of arguments in all rolecandidates extracted from Chinese Propbank by givenheuristic.3 http://svmlight.joachims.org/922numeric vectors are extracted from these two sets(one proposition could produce many instances)as the dataset for the following learning modelsthrough the heuristics in Table 2.
When trainingthe classifier, linear kernel function had used, set-ting the C to 2 experientially.5.2 Results and DiscussionA baseline was developed with 10 features and15 SVM classifiers (tagged set for training,untagged set for testing) as described in Section 3.We made a comparison between the baseline andthe work in Xue (2005), and then used the argu-ment-specific heuristics for baseline.
Table 3shows the performance of these methods.
Baselinematches Xue approximately despite of the absenceof combination features.
We also find that the ar-gument-specific heuristics improve the perform-ance of baseline from 89.97% to 90.86% for F1and beyond the Xue.
It can be explained that whenusing heuristics, the proportion of positive andnegative instances in dataset are adjusted reasona-bly to improve the model.
About 1 percent im-provement attributes to the effectivity of these sixargument-specific heuristics.Systems Precision Recall F1Baseline 89.70 90.24 89.97Xue 90.40 90.30 90.30Heuristics 91.45 90.28 90.86Table 3.
A comparison among baseline, Xue andheuristics through regular SVMIn order to investigating the learning perform-ance of SVM, TSVM and TSVM using argument-specific heuristics in small tagged data, we ex-tracted randomly different number of propositionsin Propbank as tagged data and another 5000propositions held out as untagged data.
Both ofthem are used for training TSVM model.
Table 4shows the overall performance and the perform-ances of two arguments--ARG0 and ARGM-TMP--along with the different training data size.As we can see in (a) of Table 4, the TSVM leadsto an improved performance on overall argumenttypes when tagged data less than 100 propositions(raising F1 about 10%).
It indicates that transduc-tive inference performs much better than inductiveinference because it makes use of the additionalinformation about the distribution of 5000untagged propositions.
More important, we findthat TSVM using argument-specific heuristics,comparing to TSVM, has a distinctive improve-ment (raising about 3%).
It confirmed that ourheuristics have positive influences on transductiveinference.Number of taggedpropositionsSVM TSVM TSVM +Heuristics10 36.51 50.51 50.8220 41.65 50.52 53.6640 41.64 55.42 60.63160 76.40 80.84 82.321000 82.00 83.87 84.005000 84.41 85.61 86.45(a).
The overall results on all argument types.Number of taggedpropositionsSVM TSVM TSVM +Heuristics10 20.51 29.51 30.2120 22.34 32.45 38.5440 35.00 45.42 50.63160 45.45 50.45 55.741000 52.43 55.43 57.405000 58.00 60.34 61.45(b) The detail results on ARG0Number of taggedpropositionsSVM TSVM TSVM +Heuristics10 15.98 20.45 19.9820 25.34 29.45 35.4340 30.32 32.80 39.43160 38.31 40.00 45.091000 48.43 50.43 55.455000 60.34 62.34 63.90(c) The detail results on ARGM-TMPTable 4.
A comparison with Regular SVM, TSVMand TSVM using argument-specific heuristics hold-ing 5000 untagged propositionsNumber of untaggedpropositionsSVM TSVM TSVM +Heuristics500 69.03 68.50 69.441000 70.12 70.22 70.822000 68.64 71.30 73.014000 69.53 72.01 76.505000 68.95 72.54 77.2110000 70.28 74.78 79.74Table 5.
A comparison with Regular SVM, TSVMand TSVM using argument-specific heuristics hold-ing 100 tagged propositionsWe then evaluate the six argument-specificheuristics introduced in Section 4 with the same5000 untagged propositions.
It is noticeable thatthe training time of TSVM doubles that of SVMapproximately.
The (b) and (c) of Table 4 give thedetail results on ARG0 and ARGM-TMP.
Com-923pared with (a), it is obvious that the improvementbetween TSVM using heuristics with TSVM forARG0 and ARGM-TMP is larger than the overallimprovement.
That is to say, the more distinctiveknowledge is embedded in heuristics, the betterperformance can be achieved for the correspond-ing argument.
This observation encourages us toinvestigate more heuristics for more arguments.Finally, the influence of untagged data on per-formance of TSVM has been investigated.
Weextract different size of untagged propositions andhold 100 tagged propositions for training TSVM.Table 5 shows the results.
It should be mentionthat the result of SVM fluctuates slightly, which isdue to different number of testing examples.
Onthe other hand, TSVM and TSVM using argu-ment-specific heuristics improve highly as theincrease in untagged data size.
The bigger theuntagged data, the larger the performance gap be-tween SVM and TSVM and the gap betweenTSVM and TSVM using argument-specific heu-ristics.
It indicates that the argument-specific heu-ristics, optimizing the dataset, have substantialeffectivity in the performance of TSVM whenuntagged data is large.6 ConclusionsMost machine learning methods such as SVM,ME have a strong dependence on tagged data,which lead to a poor generalization when largetagged data are not available.
This paper intro-duces a novel semi-supervised method--TSVM forthis problem.
TSVM can effectively use clusteringinformation from untagged data for training themodel.
The experiment demonstrated the TSVMachieve better performance than regular SVMwhen only very few tagged examples are available.Aiming at serious uneven problem in SRL, argu-ment-specific heuristics are proposed correspondto six kinds of arguments.
These heuristics aredeveloped by extracting semantic features of ar-guments from HowNet.
The experiment provesthat these heuristics have much effect not only inthe inductive inference (regular SVM) but also intransductive inference (TSVM), especially whenthe untagged data is large.
The high performanceof six heuristics demonstrated that semantic char-acteristics are significant on SRL, which encour-ages us to develop more semantic characteristicsof more arguments in the future.Acknowledgement This research is supported bythe National Natural Science Foundation of China(60403050), Program for New Century Excellent Tal-ents in University (NCET-06-0926) and the NationalGrand Fundamental Research Program of China underGrant (2005CB321802).ReferencesLevin Beth.
1993.
English Verb Class and Alternations:A Preliminary Investigation.
Chicago: University ofChicago Press.Xavier Carreras and Llu?
?s M`arquez, 2005.
Introduc-tion to the CoNLL-2005 Shared Task: Semantic RoleLabeling.
CoNLL-2005.Trevor Cohn and Philip Blunsom.
2005.
Semantic rolelabeling with tree conditional random fields.
CoNLL-2005.Zhendong Dong.
2000. http://www.keenage.com/.Thorsten Joachims.
1999.
Transductive inference fortext classification using support vector machines.ICML-99, pages 200?209, Bled, Slovenia, Jun.Yaoyong Li and John Shawe-Taylor.
2003.
The SVMwith Uneven Margins and Chinese Document Catego-rization.
PACLIC-2003, Singapore.Kyung-Mi Park and Hae-Chang Rim.
2005.
Maximumentropy based semantic role labeling.
CoNLL-2005.Pradhan S, Hacioglu K, Krugler V, et al 2005.
SupportVector Learning for Semantic Argument Classification.Machine Learning journal.
60(1-3): 11-39.Nianwen Xue and Martha Palmer.
2004.
CalibratingFeatures for Semantic Role Labeling.
EMNLP.Nianwen Xue and Martha Palmer.
2005, AutomaticSemantic Role Labeling for Chinese Verbs.
The IJCAI-2005, Edinburgh, Scotland.Szuting Yi, Edward Loper and Martha Palmer.
2007.Can Semantic Roles Generalize Across Genres?NAANL-HLT 07, Rochester, N Y.924
