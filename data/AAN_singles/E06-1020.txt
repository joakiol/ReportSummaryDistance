Improved Lexical Alignment by Combining Multiple ReifiedAlignmentsDan Tufi?Institute for ArtificialIntelligence13, ?13 Septembrie?,050711, Bucharest 5,Romaniatufis@racai.roRadu IonInstitute for ArtificialIntelligence13, ?13 Septembrie?,050711, Bucharest 5,Romaniaradu@racai.roAlexandru Ceau?uInstitute for ArtificialIntelligence13, ?13 Septembrie?,050711, Bucharest 5,Romaniaalceausu@racai.roDan ?tef?nescuInstitute for ArtificialIntelligence13, ?13 Septembrie?,050711, Bucharest 5,Romaniadanstef@racai.roAbstractWe describe a word alignment platformwhich ensures text pre-processing (to-kenization, POS-tagging, lemmatization,chunking, sentence alignment) as re-quired by an accurate word alignment.The platform combines two differentmethods, producing distinct alignments.The basic word aligners are described insome details and are individually evalu-ated.
The union of the individual align-ments is subject to a filtering post-processing phase.
Two different filteringmethods are also presented.
The evalua-tion shows that the combined wordalignment contains 10.75% less errorsthan the best individual aligner.1 IntroductionIt is almost a truism that more decision makers,working together, are likely to find a better solu-tion than when working alone.
Dieterich (1998)discusses conditions under which different deci-sions (in his case classifications) may be com-bined for obtaining a better result.
Essentially, asuccessful automatic combination method wouldrequire comparable performance for the decisionmakers and, additionally, that they should notmake similar errors.
This idea has been exploitedby various NLP researchers in language model-ling, statistical POS tagging, parsing, etc.We developed two quite different word align-ers, driven by two distinct objectives: the firstone was motivated by a project aiming at the de-velopment of an interlingually aligned set ofwordnets while the other one was developedwithin an SMT ongoing project.
The first onewas used for validating, against a multilingualcorpus, the interlingual synset equivalences andalso for WSD experiments.
Although, initially, itwas concerned only with open class words re-corded in a wordnet, turning it into an ?allwords?
aligner was not a difficult task.
Thisword aligner, called YAWA is described in sec-tion 3.A quite different approach from the one usedby YAWA, is implemented in our second wordaligner, called MEBA, described in section 4.
Itis a multiple parameter and multiple step algo-rithm using relevance thresholds specific to eachparameter, but different from each step to theother.
The implementation of MEBA wasstrongly influenced by the notorious five IBMmodels described in (Brown et al 1993).
Weused GIZA++ (Och and Ney 2000; Och and Ney,2003) to estimate different parameters of theMEBA aligner.The alignments produced by MEBA werecompared to the ones produced by YAWA andevaluated against the Gold Standard (GS)1 anno-tations used in the Word Alignment SharedTasks (Romanian-English track) organized atHLT-NAACL2003 (Mihalcea and Pedersen2003).Given that the two aligners are based on quitedifferent models and that their F-measures arecomparable, it was quite a natural idea to com-bine their results and hope for an improved align-ment.
Moreover, by analyzing the alignment er-rors done by each word aligner, we found thatthe number of common mistakes was small, so1 We noticed in the GS Alignment various errors (both sen-tence and word alignment errors) that were corrected.
Thetokenization of the bitexts used in the GS Alignment wasalso modified, with the appropriate modification of the ref-erence alignment.
These reference data are available athttp://www.racai.ro/res/WA-GS153the premises for a successful combination werevery good (Dieterich, 1998).
The CombinedWord Aligner, COWAL-described in section 5,is a wrapper of the two aligners (YAWA andMEBA) merging the individual alignments andfiltering the result.
At the Shared Task on WordAlignment organized by the ACL2005 Work-shop on ?Building and Using Parallel Corpora:Data-driven Machine Translation and Beyond?
(Martin, et al 2005), we participated (on theRomanian-English track) with the two alignersand the combined one (COWAL).
Out of 37competing systems, COWAL was rated the first,MEBA the 20th and TREQ-AL (Tufi?
et al2003), the former version of YAWA, was ratedthe 21st.
The usefulness of the aligner combina-tion was convincingly demonstrated.Meanwhile, both the individual aligners andtheir combination were significantly improved.COWAL is now embedded into a larger platformthat incorporates several tools for bitexts pre-processing (briefly reviewed in section 2), agraphical interface that allows for comparing andediting different alignments, as well as a wordsense disambiguation module.2 The bitext processingThe two base aligners and their combination usethe same format for the input data and providethe alignments in the same format.
The inputformat is obtained from two raw texts that repre-sent reciprocal translations.
If not already sen-tence aligned, the two texts are aligned by oursentence aligner that builds on Moore?s aligner(Moore, 2002) but which unlike it, is able to re-cover the non-one-to-one sentence alignments.The texts in each language are then tokenized,tagged and lemmatized by the TTL module (Ion,2006).
More often than not, the translationequivalents have the same part-of speech, butrelying on such a restriction would seriously af-fect the alignment recall.
However, when thetranslation equivalents have different parts ofspeech, this difference is not arbitrary.
Duringthe training phase, we estimated POS affinities:{p(POSmRO|POSnEN)} and p(POSnEN|POSmRO)}and used them to filter out improbable translationequivalents candidates.The next pre-processing step is represented bysentence chunking in both languages.
Thechunks are recognized by a set of regular expres-sions defined over the tagsets and they corre-spond to (non-recursive) noun phrases, adjectivalphrases, prepositional phrases and verb com-plexes (analytical realization of tense, aspectmood and diathesis and phrasal verbs).
Finally,the bitext is assembled as an XML document(Tufi?
and Ion, 2005), which is the standard inputfor most of our tools, including COWAL align-ment platform.3 YAWAYAWA is a three stage lexical aligner that usesbilingual translation lexicons and phrase bounda-ries detection to align words of a given bitext.The translation lexicons are generated by a dif-ferent module, TREQ (Tufi?, 2002), which gen-erates translation equivalence hypotheses for thepairs of words (one for each language in the par-allel corpus) which have been observed occur-ring in aligned sentences more than expected bychance.
The hypotheses are filtered by a log-likelihood score threshold.
Several heuristics(string similarity-cognates, POS affinities andalignments locality2) are used in a competitivelinking manner (Melamed, 2001) to extract themost likely translation equivalents.YAWA generates a bitext alignment by in-crementally adding new links to those created atthe end of the previous stage.
The existing linksact as contextual restrictors for the new addedlinks.
From one phase to the other new links areadded without deleting anything.
This monotonicprocess requires a very high precision (at theprice of a modest recall) for the first step.
Thenext two steps are responsible for significantlyimproving the recall and ensuring an increasedF-measure.In the rest of this section we present the threestages of YAWA and evaluate the contributionof each of them to the final result.3.1 Phase 1: Content Words AlignmentYAWA begins by taking into account only veryprobable links that represent the skeleton align-ment used by the second phase.
This alignment isdone using outside resources such as translationlexicons and involves only the alignment of con-tent words (nouns, verbs, adjective and adverbs).The translation equivalence pairs are rankedaccording to an association score (i.e.
log-likelihood, DICE, point-wise mutual informa-2 The alignments locality heuristics exploits the observationmade by several researchers that adjacent words of a text inthe source language tend to align to adjacent words in thetarget language.
A more strict alignment locality constraintrequires that all alignment links starting from a chunk in theone language end in a chunk in the other language.154tion, etc.).
We found that the best filtering of thetranslation equivalents was the one based on thelog-likelihood (LL) score with a threshold of 9.Each translation unit (pair of aligned sen-tences) of the target bitext is scanned for estab-lishing the most likely links based on a competi-tive linking strategy that takes into account theLL association scores given by the TREQ trans-lation lexicon.
If a candidate pair of words is notfound in the translation lexicon, we computetheir orthographic similarity (cognate score(Tufi?, 2002)).
If this score is above a predeter-mined threshold (for Romanian-English task weused the empirically found value of 0.43), thetwo words are treated as if they existed in thetranslation lexicon with a high association score(in practice we have multiplied the cognate scoreby 100 to yield association scores in the range 0.. 100).
The Figure 1 exemplifies the links cre-ated between two tokens of a parallel sentence bythe end of the first phase.Figure 1: Alignment after the first step3.2 Phase 2: Chunks AlignmentThe second phase requires that each part of thebitext is chunked.
In our Romanian-English ex-periments, this requirement was fulfilled by us-ing a set of regular expressions defined over thetagsets used in the target bitext.
These simplechunkers recognize noun phrases, prepositionalphrases, verbal and adjectival or adverbial group-ings of both languages.In this second phase YAWA produces firstchunk-to-chunk matching and then aligns thewords within the aligned chunks.
Chunk align-ment is done on the basis of the skeleton align-ment produced in the first phase.
The algorithmis simple: align two chunks c(i) in source lan-guage and c(j) in the target language if c(i) andc(j) have the same type (noun phrase, preposi-tional phrase, verb phrase, adjectival/adverbialphrase) and if there exist a link ?w(s), w(t)?
sothat w(s) ?
c(i) then w(t) ?
c(j).After alignment of the chunks, a language pairdependent module takes over to align the un-aligned words belonging to the chunks.
Ourmodule for the Romanian-English pair of lan-guages contains some very simple empiricalrules such as: if b is aligned to c and b is pre-ceded by a, link a to c, unless there exist d in thesame chunk with c and the POS category of d hasa significant affinity with the category of a. Thesimplicity of these rules derives from the shallowstructures of the chunks.
In the above example band c are content words while a is very likely adeterminer or a modifier for b.
The result of thesecond alignment phase, considering the samesentence in Figure 1, is shown in Figure 2.
Thenew links are represented by the double lines.Figure 2: Alignment after the second step3.3 Phase 3: Dealing with sequences of un-aligned wordsThis phase identifies contiguous sequences ofwords (blocks) in each part of the bitext whichremain unaligned and attempts to heuristicallymatch them.
The main criteria used to this endare the POS-affinities of the remaining unalignedwords and their relative positions.
Let us illus-trate, using the same example and the resultshown in Figure 2, how new links are added inthis last phase of the alignment.
At the end ofphase 2 the blocks of consecutive words that re-main to be aligned are: English {en0 = (you), en1= (that), en2 = (is, not), en3 = (and), en4 = (.)}
and155Romanian {ro0 = (), ro1 = (c?
), ro2 = (nu, e), ro3 =(?i), ro4 = (.)}.
The mapping of source and targetunaligned blocks depends on two conditions: thatsurrounding chunks are already aligned and thatpairs in candidate unaligned blocks have signifi-cant POS-affinity.
For instance in the figureabove, blocks en1 = (that) and ro1 = (c?)
satisfythe above conditions because they appear amongalready aligned chunks (<?ll notice> ?
<ve?iobserva> and <D?ncu ?s generosity> ?
<gene-rozitatea lui D?ncu>) and they contain wordswith the same POS.After block alignment3, given a pair of alignedblocks, the algorithm links words with the samePOS and then the phase 2 is called again withthese new links as the skeleton alignment.
InFigure 3 is shown the result of phase 3 alignmentof the sentence we used as an example through-out this section.
The new links are shown (asbefore) by double lines.Figure 3: Alignment after the third stepThe third phase is responsible for significantimprovement of the alignment recall, but it alsogenerates several wrong links.
The detection ofsome of them is quite straightforward, and weadded an additional correction phase 3.f.
By ana-lysing the bilingual training data we noticed the trans-lators?
tendency to preserve the order of thephrasal groups.
We used this finding (whichmight not be valid for any language pair) as aremoval heuristics for the links that cross two ormore aligned phrase groups.
One should noticethat the first word in the English side of the ex-ample in Figure 3 (?you?)
remained unaligned(interpreted as not translated in the Romanianside).
According to the Gold Standard used for3 Only 1:1 links are generated between blocks.evaluation in the ACL2005 shared task, this in-terpretation was correct, and therefore, for theexample in Figure 3, the F-measure for theYAWA alignment was 100%.However, Romanian is a pro-drop languageand although the translation of the English pro-noun is not lexicalized in Romanian, one couldargue that the auxiliary ?ve?i?
should be alignedalso to the pronoun ?you?
as it incorporates thegrammatical information carried by the pronoun.Actually, MEBA (as exemplified in Figure 4)produced this multiple token alignment (and waspenalized for it!
).3.4 Performance analysisThe table that follows presents the results of theYAWA aligner at the end of each alignmentphase.
Although the Precision decreases fromone phase to the next one, the Recall gains aresignificantly higher, so the F-measure is mono-tonically increasing.Precision Recall F-MeasurePhase 1 94.08% 34.99% 51.00%Phase 1+2 89.90% 53.90% 67.40%Phase 1+2+3 88.82% 73.44% 80.40%Phase 1+2+3+3.f 88.80% 74.83% 81.22%Table 1: YAWA evaluation4 MEBAMEBA uses an iterative algorithm that takes ad-vantage of all pre-processing phases mentionedin section 2.
Similar to YAWA aligner, MEBAgenerates the links step by step, beginning withthe most probable (anchor links).
The links to beadded at any later step are supported or restrictedby the links created in the previous iterations.The aligner has different weights and differentsignificance thresholds on each feature and itera-tion.
Each of the iterations can be configured toalign different categories of tokens (named enti-ties, dates and numbers, content words, func-tional words, punctuation) in decreasing order ofstatistical evidence.The first iteration builds anchor links with ahigh level of certainty (that is cognates, numbers,dates, pairs with high translation probability).The next iteration tries to align content words(open class categories) in the immediate vicinityof the anchor links.
In all steps, the candidatesare considered if and only if they meet the mini-mal threshold restrictions.A link between two tokens is characterized bya set of features (with values in the [0,1] inter-val).
We differentiate between context independ-156ent features that refer only to the tokens of thecurrent link (translation equivalency, part-of-speech affinity, cognates, etc.)
and context de-pendent features that refer to the properties of thecurrent link with respect to the rest of links in abi-text (locality, number of traversed links, to-kens indexes displacement, collocation).
Also,we distinguish between bi-directional features(translation equivalence, part-of-speech affinity)and non-directional features (cognates, locality,number of traversed links, collocation, indexesdisplacement).Precision Recall F-measure?Anchor?
links 98.50% 26.82% 42.16%Words around?anchors?
96.78% 42.41% 58.97%Funct.
wordsand punctuation 94.74% 59.48% 73.08%Probable links 92.05% 71.00% 80.17%Table 2: MEBA evaluationThe score of a candidate link (LS) between asource token i and a target token j is computedby a linear function of several features scores(Tiedemann, 2003).
?niii ScoreFeatjiLS1*),( O ; 11?niiOEach feature has defined a specific signifi-cance threshold, and if the feature?s value is be-low this threshold, the contribution to the LS ofthe current link of the feature in case is nil.The thresholds of the features and lambdas aredifferent from one iteration to the others and theyare set by the user during the training and systemfine-tuning phases.
There is also a generalthreshold for the link scores and only the linksthat have the LS above this threshold are retainedin the bitext alignment.
Given that this conditionis not imposing unique source or target indexes,the resulting alignment is inherently many-to-many.In the following subsections we briefly discussthe main features we use in characterising a link.4.1 Translation equivalenceThis feature may be used for two types of pre-processed data: lemmatized or non-lemmatizedinput.
Depending on the input format, MEBAinvokes GIZA++ to build translation probabilitylists for either lemmas or the occurrence forms ofthe bitext4.
Irrespective of the lemmatisation op-tion, the considered token for the translationmodel build by GIZA++ is the respective lexicalitem (lemma or wordform) trailed by its POS tag(eg.
plane_N, plane_V, plane_A).
In this way weavoid data sparseness and filter noisy data.
Forinstance, in case of highly inflectional languages(as Romanian is) the use of lemmas significantlyreduces the data sparseness.
For languages withweak inflectional character (as English is) thePOS trailing contributes especially to the filter-ing the search space.
A further way of removingthe noise created by GIZA++ is to filter out allthe translation pairs below a LL-threshold.
Wemade various experiments and, based on the es-timated ratio between the number of false nega-tives and false positive, empirically set the valueof this threshold to 6.
All the probability lossesby this filtering were redistributed proportionallyto their initial probabilities to the surviving trans-lation equivalence candidates.4.2 Translation equivalence entropy scoreThe translation equivalence relation is a se-mantic one and it directly addresses the notion ofword sense.
One of the Zipffian laws prescribes askewed distribution of the senses of a word oc-curring several times in a coherent text.
We usedthis conjecture as a highly informative informa-tion source for the validity of a candidate link.The translation equivalence entropy score is afavouring parameter for the words that have fewhigh probability translations.
Since this feature isdefinitely sensitive to the order of the lexicalitems, we compute an average value for the link:DES(A)+EES(B).
Currently we use D=E=0.5, butit might be interesting to see, depending on dif-ferent language pairs, how the performance ofthe aligner would be affected by a different set-tings of these parameters.NTRWpTRWpNiiiWES log),(log*),(11)(?4.3 Part-of-speech affinityIn faithful translations the translated words tendto be translated by words of the same part-of-speech.
When this is not the case, the differentPOSes, are not arbitrary.
The part of speech af-finity, P(cat(A)|cat(B), can be easily computedfrom a gold standard alignment.
Obviously, this4 Actually, this is a user-set parameter of the MEBA aligner;if the input bitext contain lemmatization information, bothtranslation probability tables may be requested.157is a directional feature, so an averaging operationis necessary in order to ascribe this feature to alink: PA=DP(cat(A)|cat(B)) + EP(cat(B)|cat(A)).Again, we used D=E=0.5 but different values ofthese weights might be worthwhile investigating.4.4 CognatesThe similarity measure, COGN(TS, TT), is im-plemented as a Levenstein metric.
Using theCOGN test as a filtering device is a heuristicbased on the cognate conjecture, which says thatwhen the two tokens of a translation pair areorthographically similar, they are very likely tohave similar meanings (i.e.
they are cognates).The threshold for the COGN(TS, TT) test wasempirically set to 0.42.
This value depends onthe pair of languages in the bitext.
The actualimplementation of the COGN test includes a lan-guage-dependent normalisation step, which stripssome suffixes, discards the diacritics, reducessome consonant doubling, etc.
This normalisa-tion step was hand written, but, based on avail-able lists of cognates, it could be automaticallyinduced.4.5 ObliquenessEach token in both sides of a bi-text is character-ized by a position index, computed as the ratiobetween the relative position in the sentence andthe length of the sentence.
The absolute value ofthe difference between tokens?
position indexes,subtracted from 15, gives the link?s ?oblique-ness?.
)()(1),(TSji SentlengthjSentlengthiTWSWOBL This feature is ?context free?
as opposed to thelocality feature described below.4.6 LocalityLocality is a feature that estimates the degree towhich the links are sticking together.MEBA has three features to account for local-ity: (i) weak locality, (ii) chunk-based localityand (iii) dependency-based locality.The value of the weak locality feature is de-rived from the already existing alignments in awindow of N tokens centred on the focused to-ken.
The window size is variable, proportional tothe sentence length.
If in the window there existk linked tokens and the relative positions of the5 This is to ensure that values close to 1 are ?good?
ones andthose near 0 are ?bad?.
This definition takes into account therelatively similar word order in English and Romanian.tokens in these links are <i1 j1>, ?<ik jk> thenthe locality feature of the new link <ik+1, jk+1> isdefined by the equation below:)||||1,1min(1 11?km mkmkjjiikLOCIf the new link starts from or ends in a tokenalready linked, the index difference that wouldbe null in the formula above is set to 1.
This way,such candidate links would be given support bythe LOC feature (and avoid overflow error).
Inthe case of chunk-based locality the windowspan is given by the indexes of the first and lasttokens of the chunk.Dependency-based locality uses the set of thedependency links of the tokens in a candidatelink for the computation of the feature value.
Inthis case, the LOC feature of a candidate link<ik+1, jk+1> is set to 1 or 0 according to the fol-lowing rule:if between ik+1 and iD there is a (source lan-guage) dependency and if between jk+1 and jEthere is also a (target language) dependency thenLOC is 1 if iD and jE are aligned, and 0 otherwise.Please note that in case jk+1{ jE a trivial depend-ency (identity) is considered and the LOC attrib-ute of the link <ik+1, jk+1> is set to always to 1.Figure 4: Chunk and dependency-based locality4.7 CollocationMonolingual collocation is an important clue forword alignment.
If a source collocation is trans-lated by a multiword sequence, very often thelexical cohesion of source words can also befound in the corresponding translated words.
Inthis case the aligner has strong evidence for158many to many linking.
When a source colloca-tion is translated as a single word, this feature isa strong indication for a many to 1 linking.Bi-gram lists (only content words) were builtfrom each monolingual part of the training cor-pus, using the log-likelihood score (threshold of10) and minimal occurrence frequency (3) forcandidates filtering.We used the bi-grams list to annotate thechains of lexical dependencies among the con-tents words.
Then, the value of the collocationfeature is computed similar to the dependency-based locality feature.
The algorithm searches forthe links of the lexical dependencies around thecandidate link.5 Combining the reified alignmentsFrom a given alignment one can compute a se-ries of properties for each of its links (such as theparameters used by the MEBA aligner).
A linkbecomes this way a structured object that can bemanipulated in various ways, independent of thebitext (or even of the lexical tokens of the link)from which it was extracted.
We call this proce-dure alignment reification.
The properties of thelinks of two or more alignments are used for ourmethods of combining the alignments.One simple, but very effective method ofalignment combination is a heuristic procedure,which merges the alignments produced by two ormore word aligners and filters out the links thatare likely to be wrong.
For the purpose of filter-ing, a link is characterized by its type defined bythe pair of indexes (i,j) and the POS of the tokensof the respective link.
The likelihood of a link isproportional to the POS affinities of the tokens ofthe link and inverse proportional to the boundedrelative positions (BRP) of the respective tokens:where avg is the averagedisplacement in a Gold Standard of the alignedtokens with the same POSes as the tokens of thecurrent link.
From the same gold standard weestimated a threshold below which a link is re-moved from the final alignment.||||1 avgjiBRP A more elaborated alignment combination(with better results than the previous one) ismodelled as a binary statistical classificationproblem (good / bad) and, as in the case of theprevious method, the net result is the removal ofthe links which are likely to be wrong.
We usedan ?off-the-shelf?
solution for SVM training andclassification - LIBSVM6 (Fan et al, 2005) with6 http://www.csie.ntu.edu.tw/~cjlin/libsvm/the default parameters (C-SVC classification andradial basis kernel function).
Both context inde-pendent and context dependent features charac-terizing the links were used for training.
Theclassifier was trained with both positive andnegative examples of links.
A set of links ex-tracted from the Gold Standard alignment wasused as positive examples set.
The same numberof negative examples was extracted from thealignments produced by COWAL and MEBAwhere they differ from the Gold Standard.It is interesting to notice that for the examplediscussed in Figures 1-4, the first combinerdidn?t eliminate the link <you ve?i> producingthe result shown in Figure 4.
This is because therelative positions of the two words are the sameand the POS-affinity of the English personalpronouns and the Romanian auxiliaries is signifi-cant.
On the other hand, the SVM-based com-biner deleted this link, producing the resultshown in Figure 3.
The explanation is that, ac-cording to the Gold Standard we used, the linksbetween English pronouns and Romanian auxil-iaries or main verbs in pro-drop constructionswere systematically dismissed (although weclaim that they shouldn?t and that the alignmentin Figure 4 is better than the one in Figure 3).The evaluation (according to the Gold Standard)of the SVM-based combination (COWAL),compared with the individual aligners, is shownin Table 3.Aligner Precision Recall F-measureYAWA 88.80% 74.83% 81.22%MEBA 92.05% 71.00% 80.17%COWAL 86.99% 79.91% 83.30%Table 3: Combined alignment6 Conclusions and further workNeither YAWA nor MEBA needs an a priori bi-lingual dictionary, as this will be automaticallyextracted by TREQ or GIZA++.
We madeevaluation of the individual alignments in bothexperimental settings: without a start-up bilin-gual lexicon and with an initial mid-sized bilin-gual lexicon.
Surprisingly enough, we found thatwhile the performance of YAWA increases alittle bit (approx.
1% increase of the F-measure)MEBA is doing better without an additional lexi-con.
Therefore, in the evaluation presented in theprevious section MEBA uses only the trainingdata vocabulary.YAWA is very sensitive to the quality of thebilingual lexicons it uses.
We used automaticallytranslation lexicons (with or without a seed lexi-159con), and the noise inherently present might havehad a bad influence on YAWA?s precision.
Re-placing the TREQ-generated bilingual lexiconswith validated (reference bilingual lexicons)would further improve the overall performanceof this aligner.
Yet, this might be a harder tomeet condition for some pairs of languages thanusing parallel corpora.MEBA is more versatile as it does not requirea-priori bilingual lexicons but, on the other hand,it is very sensitive to the values of the parametersthat control its behaviour.
Currently they are setaccording to the developers?
intuition and afterthe analysis of the results from several trials.Since this activity is pretty time consuming (hu-man analysis plus re-training might take a coupleof hours) we plan to extend MEBA with a super-vised learning module, which would automati-cally determine the ?optimal?
parameters(thresholds and weights) values.It is worth noticing that with the current ver-sions of our basic aligners, significantly im-proved since the ACL shared word alignmenttask in June 2005, YAWA is now doing betterthan MEBA, and the COWAL F-measure in-creased with 9.4%.
However, as mentioned be-fore, these performances were measured on adifferent tokenization of the evaluation texts andon the partially corrected gold standard align-ment (see footnote 1).ReferencesPeter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, Robert J. Mercer.
1993.
The mathe-matics of statistical machine translation: Parameterestimation.
Computational Linguistics, 19(2): 263?311.Thomas G. Dietterich.
1998.
Approximate StatisticalTests for Comparing Supervised ClassificationLearning Algorithms.
Neural Computation, 10 (7)1895-1924.Rong-en Fan, Pai-Hsuen Chen, Chij-Jen Lin.
2005.Working set selection using the second orderinformation for training SVM.
Technical report,Department of Computer Science, National TaiwanUniversity (www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf).William A. Gale, Kenneth W. Church.
1991.
Identify-ing word correspondences in parallel texts.
In Pro-ceedings of the Fourth DARPA Workshop onSpeech and Natural Language.
Asilomar, CA:152?157.Radu Ion.
2006.
TTL: A portable framework for to-kenization, tagging and lemmatization of large cor-pora.
PhD thesis progress report.
Research Institutefor Artificial Intelligence, Romanian Academy,Bucharest (in Romanian), 22p.Dan Melamed.
2001.
Empirical Methods for Exploit-ing Parallel Texts.
Cambridge, MA, MIT Press.Rada Mihalcea, Ted Pedersen.
2003.
An EvaluationExercise for Word Alignment.
Proceedings of theHLT-NAACL 2003 Workshop: Building and UsingParallel Texts Data Driven Machine Translationand Beyond.
Edmonton, Canada: 1?10.Joel Martin, Rada Mihalcea, Ted Pedersen.
2005.Word Alignment for Languages with Scarce Re-sources.
In Proceeding of the ACL2005 Workshopon ?Building and Using Parallel Corpora: Data-driven Machine Translation and Beyond?.
June,2005, Ann Arbor, Michigan, June, Association forComputational Linguistics, 65?74Robert Moore.
2002.
Fast and Accurate SentenceAlignment of Bilingual Corpora in Machine Trans-lation: From Research to Real Users.
In Proceed-ings of the 5th Conference of the Association forMachine Translation in the Americas, Tiburon,California), Springer-Verlag, Heidelberg, Ger-many: 135-244.Franz J. Och, Herman Ney.
2003.
A Systematic Com-parison of Various Statistical Alignment Models,Computational Linguistics, 29(1):19-51.Franz J. Och, Herman Ney.
2000.
Improved StatisticalAlignment Models.
In Proceedings of the 38th Con-ference of ACL, Hong Kong: 440-447.Joerg Tiedemann.
2003.
Combining clues for wordalignment.
In Proceedings of the 10th EACL, Bu-dapest, Hungary: 339?346.Dan Tufi?.
2002.
A cheap and fast way to build usefultranslation lexicons.
In Proceedings of COL-ING2002, Taipei, China: 1030-1036.Dan Tufi?, Ana-Maria Barbu, Radu Ion.
2003.
TREQ-AL: A word-alignment system with limited lan-guage resources.
In Proceedings of the NAACL2003 Workshop on Building and Using ParallelTexts; Romanian-English Shared Task, Edmonton,Canada: 36-39.Dan Tufi?, Radu Ion, Alexandru Ceau?u, Dan Ste-f?nescu.
2005.
Combined Aligners.
In Proceedingof the ACL2005 Workshop on ?Building and UsingParallel Corpora: Data-driven Machine Transla-tion and Beyond?.
June, 2005, Ann Arbor, Michi-gan, June, Association for Computational Linguis-tics, pp.
107-110.Dan Tufi?, Radu Ion.
2005.
Multiple Sense Invento-ries and Test-Bed Corpora.
In C. Burileanu (ed.
)Trends in Speech Technology, Publishing House ofthe Romanian Academy, Bucharest: 49-58.160
