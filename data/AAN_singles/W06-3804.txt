Workshop on TextGraphs, at HLT-NAACL 2006, pages 25?28,New York City, June 2006. c?2006 Association for Computational LinguisticsMeasuring Aboutness of an Entity in a TextMarie-Francine Moens Patrick JeuniauxLegal Informatics and Information Retrieval Department.
of PsychologyKatholieke Universiteit Leuven, Belgium University of Memphis, USAmarie-france.moens@law.kuleuven.be pjeuniaux@mail.psyc.memphis.eduRoxana Angheluta Rudradeb MitraLegal Informatics and Information Retrieval Mission Critical, ITKatholieke Universiteit Leuven, Belgium Brussels, Belgiumanghelutar@yahoo.com rdm@missioncriticalit.comAbstractIn many information retrieval and selec-tion tasks it is valuable to score how mucha text is about a certain entity and to com-pute how much the text discusses the en-tity with respect to a certain viewpoint.
Inthis paper we are interested in giving anaboutness score to a text, when the inputquery is a person name and we want tomeasure the aboutness with respect to thebiographical data of that person.
We pre-sent a graph-based algorithm and compareits results with other approaches.1 IntroductionIn many information processing tasks one is inter-ested in measuring how much a text or passage isabout a certain entity.
This is called aboutness ortopical relevance (Beghtol 1986; Soergel 1994).Simple word counts of the entity term often giveonly a rough estimation of aboutness.
The true fre-quency of the entity might be hidden by corefer-ents.
Two entities are considered as coreferentswhen they both refer to the same entity in the situa-tion described in the text (e.g., in the sentences:"Dan Quayle met his wife in college.
The Indianasenator married her shortly after he finished hisstudies": "his", "Indiana senator" and "he" all core-fer to "Dan Quayle").
If we want to score theaboutness of an entity with respect to a certainviewpoint, the aboutness is also obfuscated by thereferents that refer to the chosen viewpoint and inwhich context the entity is mentioned.
In the ex-ample ?Dan Quayle ran for presidency?, ?presi-dency?
can be considered as a referent for ?DanQuayle?.
Because, coreferents and referents can bedepicted in a graphical representation of the dis-course content, it seems interesting to exploit thisgraph structure in order to compute aboutness.
Thisapproach is inspired by studies in cognitive scienceon text comprehension (van Dijk and Kintsch,1983).
When humans read a text, they make manyinferences about and link information that is foundin the text, a behavior that influences aboutnessassessment.
Automated aboutness computation hasmany applications such as text indexing, summari-zation, and text linking.We focus on estimating the aboutness score of atext given an input query in the form of a personproper name.
The score should reflect how muchthe text deals with biographical information aboutthe person.
We present an algorithm based on ei-genvector analysis of the link matrix of the dis-course graph built by the noun phrase coreferentsand referents.
We test the approach with a small setof documents, which we rank by decreasing about-ness of the input entity.
We compare the resultswith results obtained by traditional approachessuch as a normalized term frequency (possibly cor-rected by coreference resolution and augmentedwith other referent information).
Although the re-sults on a small test set do not pretend to give firmevidence on the validity of our approach, our con-tribution lies in the reflection of using graph baseddocument representations of discourse content andexploiting this structure in content recognition.2 MethodsOur approach involves the detection of entities andtheir noun phrase coreferents, the generation ofterms that are correlated with biographical infor-25mation, the detection of references between enti-ties, and the computation of the aboutness score.As linguistic resources we used the LT-POS taggerdeveloped at the University of Edinburgh and theCharniak parser developed at Brown University.2.1 Noun Phrase Coreference ResolutionCoreference resolution focuses on detecting ?iden-tity'' relationships between noun phrases (i.e.
noton is-a or whole/part links).
It is natural to viewcoreferencing as a partitioning or clustering of theset of entities.
The idea is to group coreferents intothe same cluster, which is accomplished in twosteps: 1) detection of the entities and extraction oftheir features set; 2) clustering of the entities.
Forthe first subtask we use the same set of features asin Cardie and Wagstaff (1999).
For the second stepwe used the progressive fuzzy clustering algorithmdescribed in Angheluta et al (2004).2.2 Learning Biographical TermsWe learn a term?s biographical value as the corre-lation of the term with texts of biographical nature.There are different ways of learning associationspresent in corpora (e.g., use of the mutual informa-tion statistic, use of the chi-square statistic).
Weuse the likelihood ratio for a binomial distribution(Dunning 1993), which tests the hypothesiswhether the term occurs independently in texts ofbiographical nature given a large corpus of bio-graphical and non-biographical texts.
For consider-ing a term as biography-related, we set a likelihoodratio threshold such that the hypothesis can be re-jected with a certain significance level.2.3 Reference Detection between EntitiesWe assume that the syntactic relationships betweenentities (proper or common nouns) in a text give usinformation on their semantic reference status.
Inour simple experiment, we consider reference rela-tionships found within a single sentence, and morespecifically we take into account relationships be-tween two noun phrase entities.
The analysis re-quires that the sentences are syntactically analyzedor parsed.
The following syntactic relationships aredetected in the parse tree of each sentence:1) Subject-object: An object refers to the subject(e.g., in the sentence He eats an apple, an applerefers to He).
This relationship type also coversprepositional phrases that are the argument of averb (e.g., in the sentence He goes to Hollywood,Hollywood refers to He).
The relationship holdsbetween the heads of the respective noun phrasesin case other nouns modify them.2) NP-PP{NP}: A noun phrase is modified by aprepositional noun phrase: the head of the preposi-tional noun phrase refers to the head of the domi-nant noun phrase (e.g., in the chunk The nomineefor presidency, presidency refers to The nominee).3) NP-NP: A noun phrase modifies another nounphrase: the head of the modifying noun phrase re-fers to the head of the dominant noun phrase (e.g.,in the chunk Dan Quayle's sister, Dan Quayle re-fers to sister, in the chunk sugar factory, sugarrefers to factory).When a sentence is composed of different sub-clauses and when one of the components of thefirst two relationships has the form of a subclause,the first noun phrase of the subclause is consid-ered.
When computing a reference relation with anentity term, we only consider biographical termsfound as described in (2.2).2.4 Computing the Aboutness ScoreThe aboutness of a document text D for the inputentity E is computed as follows:aboutness(D,E) = entity _ score(E)entity _ score(F)F?distinctentities of D?entity_score is zero when E does not occur in D.Otherwise we compute the entity score as follows.We represent D as a graph, where nodes representthe entities as mentioned in the text and theweights of the connections represent the referencescore (in our experiments set to 1 when the entitiesare coreferents, 0.5 when the entities are other ref-erents).
The values 1 and 0.5 were selected ad hoc.Future fine-tuning of the weights of the edges ofthe discourse graph based on discourse featurescould be explored (cf.
Giv?n 2001).
The edge val-ues are stored in a link matrix A.
The authority ofan entity is computed by considering the values ofthe principal eigenvector of ATA.
(cf.
Kleinberg1998) (in the results below this approach is re-ferred to as LM).
In this way we compute the au-thority of each entity in a text.26We implemented four other entity scores: theterm frequency (TF), the term frequency aug-mented with noun phrase coreference information(TFCOREF), the term frequency augmented withreference information (weighted by 0.5) (TFREF)and the term frequency augmented with corefer-ence and reference information (TFCOREFREF).The purpose is not that the 4 scoring functions aremutually comparable, but that the ranking of thedocuments that is produced by each of them can becompared against an ideal ranking built by hu-mans.3 Experiments and ResultsFor learning person related words we used a train-ing corpus consisting of biographical texts of per-sons obtained from the Web (fromhttp://www.biography.com) and biographical andnon-biographical texts from DUC-2002 and DUC-2003.
For considering a term as biography-related,we set a likelihood ratio threshold such that thehypothesis of independence can be rejected with asignificance level of less than 0.0025, assuring thatthe selected terms are really biography-related.In order to evaluate the aboutness computation,we considered five input queries consisting of aproper person name phrase ("Dan Quayle" (D),"Hillary Clinton" (H), "Napoleon" (N), "SadamHussein" (S) and "Sharon Stone" (ST)) anddownloaded for each of the queries 5 texts fromthe Web (each text contains minimally once anexact match with the input query).
Two personswere asked to rank the texts according to rele-vancy, if they were searching biographical infor-mation on the input person (100% agreement wasobtained).
Two aspects are important in determin-ing relevancy: a text should really and almost ex-clusively contain biographical information of theinput person in order not to lose time with otherinformation.
For each query, at least one of thetexts is a biographical text and one of the texts onlymarginally mentions the person in question.
Alltexts except for the biography texts speak aboutother persons, and pronouns are abundantly used.The "Hillary Clinton" texts do not contain manyother persons except for Hillary, in contrast withthe "Dan Quayle", "Napoleon" and "Sadam Hus-sein" texts.
The "Hillary Clinton" texts are in gen-eral quite relevant for this first lady.
For"Napoleon" there is one biographical text on Napo-leon's surgeon that mentions Napoleon only mar-ginally.
The ?Dan Quayle?
texts contain a lot ofdirect speech.
For "Sharon Stone" 4 out of the 5texts described a movie in which this actressplayed a role, thus being only marginally relevantfor a demand of biographical data of the actress.Then we ranked the texts based on the TF,TFCOREF, TFREF, TFCOREFREF and LMscores and computed the congruence of each rank-ing (Rx) with the manual ranking (Rm).
We used thefollowing measure of similarity of the rankings:sim(Rx, Rm) =1?rx, i?
rm, ii?floorn22*100where n is the number of items in the 2 rankingsand rx,i and rm,i denote the position of the ith item inRx and Rm.
respectively.
Table 1 shows the results.4 Discussion of the Results and RelatedResearchFrom our limited experiments we can draw thefollowing findings.
It is logical that erroneouscoreference resolution worsens the results com-pared to the TF baseline.
In one of the "Napoleon?texts, one mention of Napoleon and one mention ofthe name of his surgeon entail that a large numberof pronouns in the text are wrongly resolved.
Theyall refer to the surgeon, but the system considersthem as referring to Napoleon, making that theranking of this text is completely inversed com-pared to the ideal one.
Adding other reference in-formation gives some mixed results.
The rankingbased on the principal eigenvector computation ofthe link matrix of the text that represents referencerelationships between entities provides a naturalway of computing a ranking of the texts with re-gard to the person entity.
This can be explained asfollows.
Decomposition into eigenvectors breaksdown the original relationships into linear inde-pendent components.
Sorting them according totheir corresponding eigenvalues sorts the compo-nents from the most important information to theless important one.
When keeping the principaleigenvector, we keep the most important informa-tion which best distinguishes it from other infor-mation while ignoring marginal information.
Inthis way we hope to smooth some noise that isgenerated when building the links.
On the otherhand, when relationships that are wrongly detected27are dominant, they will be reinforced (as is the casein the ?Napoleon?
text).
Although an aboutnessscore is normalized by the sum of a text?s entityscores, the effect of this normalization and the be-havior of eigenvectors in case of texts of differentlength should be studied.The work is inspired by link analysis algorithmssuch as HITS, which uses theories of spectral parti-tioning of a graph for detecting authoritative pagesin a graph of hyperlinked pages (Kleinberg 1998).Analogically, Zha (2002) detects terms and sen-tences with a high salience in a text and uses thesefor summarization.
The graph here is made oflinked term and sentence nodes.
Other work ontext summarization computes centrality on graphs(Erkan and Radev 2004; Mihalcea and Tarau2004).
We use a linguistic motivation for linkingterms in texts founded in reference relationshipssuch as coreference and reference by biographicalterms in certain syntactical constructs.
Intuitively,an important entity is linked to many referents; themore important the referents are, the more impor-tant the entity is.
Latent semantic indexing (LSI) isalso used to detect main topics in a set of docu-ments/sentences, it will not explicitly model theweights of the edges between entities.Our implementation aims at measuring theaboutness of an entity from a biographical view-point.
One can easily focus upon other viewpointswhen determining the terms that enter into a refer-ence relationship with the input entity (e.g., com-puting the aboutness of an input animal name withregard to its reproductive activities).5 ConclusionIn this paper we considered the problem of rankingtexts when the input query is in the form of a per-son proper name and when we are interested inbiographical information.
The ranking based on thecomputation of the principal eigenvector of thelink matrix that represents coreferent and otherreferent relationships between noun phrase entitiesoffers novel directions for future research.6 AcknowledgementsThe research was sponsored by the IWT-grant Nr.ADV/000135/KUL).Table 1.
Similarity of the system made rankings com-pared to the ideal ranking for the methods used withregard to the input queries.TF TFCOREF TFREF TFCOREFREF LMD 0.33 0.00 0.33 0.00 0.50H 0.33 0.50 0.33 0.33 0.66N 0.66 0.33 0.66 0.66 0.33S 0.83 0.66 0.66 0.66 1.00ST 0.00 0.33 0.16 0.50 0.837 ReferencesAngheluta, R., Jeuniaux, P., Mitra, R. and Moens, M.-F.(2004).
Clustering algorithms for noun phrasecoreference resolution.
In Proceedings JADT - 2004.7?mes Journ?es internationales d'Analyse statistiquedes Donn?es Textuelles.
Louvain-La-Neuve, Bel-gium.Beghtol, C. (1986).
Bibliographic classification theoryand text linguistics: Aboutness analysis, intertextual-ity and the cognitive act of classifying documents.Journal of Documentation, 42(2): 84-113.Cardie C. and Wagstaff K. (1999).
Noun phrase co-reference as clustering.
In Proceedings of the JointConference on Empirical Methods in NLP and VeryLarge Corpora.Dunning, T. (1993).
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics, 19: 61-74.Erkan, G. and Radev, D.R.
(2004).
LexRank: Graph-based lexical centrality as salience in text summariza-tion.
Journal of Artificial Intelligence Research, 22:457-479.Giv?n, T. (2001).
Syntax.
An Introduction.
Amsterdam:John Benjamins.Kleinberg, J.M.
(1998).
Authoritative sources in a hy-perlinked environment.
In Proceedings 9th ACM-SIAM Symposium on Discrete Algorithms (pp.
668-677).Mihalcea, R. and Tarau, P. (2004).
TextRank : Bringingorder into texts.
In Proceedings of EMNLP (pp.
404-411).Soergel, D. (1994).
Indexing and retrieval performance:The logical evidence.
Journal of the American Soci-ety for Information Science, 45 (8): 589-599.Van Dijk, T. A. and Kintsch, W. (1983).
Strategies ofDiscourse Comprehension.
New York: AcademicPress.Zha, H. (2002).
Generic summarization and keyphraseextraction using mutual reinforcement principle andsentence clustering.
In Proceedings of the 25th An-nual International ACM SIGIR Conference on Re-search and Development in Information Retrieval(pp.
113-120).
New York : ACM.28
