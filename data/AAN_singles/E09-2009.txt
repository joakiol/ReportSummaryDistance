Proceedings of the EACL 2009 Demonstrations Session, pages 33?36,Athens, Greece, 3 April 2009. c?2009 Association for Computational LinguisticsThe Software Architecture for theFirst Challenge on Generating Instructions in Virtual EnvironmentsAlexander KollerSaarland Universitykoller@mmci.uni-saarland.deDonna ByronNortheastern Universitydbyron@ccs.neu.eduJustine CassellNorthwestern Universityjustine@northwestern.eduRobert DaleMacquarie UniversityRobert.Dale@mq.edu.auJohanna MooreUniversity of EdinburghJ.Moore@ed.ac.ukJon OberlanderUniversity of EdinburghJ.Oberlander@ed.ac.ukKristina StriegnitzUnion Collegestriegnk@union.eduAbstractThe GIVE Challenge is a new Internet-based evaluation effort for natural lan-guage generation systems.
In this paper,we motivate and describe the software in-frastructure that we developed to supportthis challenge.1 IntroductionNatural language generation (NLG) systems arenotoriously hard to evaluate.
On the one hand,simply comparing system outputs to a gold stan-dard is not appropriate because there can be mul-tiple generated outputs that are equally good, andfinding metrics that account for this variability andproduce results consistent with human judgmentsand task performance measures is difficult (Belzand Gatt, 2008; Stent et al, 2005; Foster, 2008).On the other hand, lab-based evaluations with hu-man subjects to assess each aspect of the system?sfunctionality are expensive and time-consuming.These characteristics make it hard to compare dif-ferent systems and measure progress.GIVE (?Generating Instructions in Virtual En-vironments?)
(Koller et al, 2007) is a researchchallenge for the NLG community designed toprovide a new approach to NLG system evalua-tion.
In the GIVE scenario, users try to solvea treasure hunt in a virtual 3D world that theyhave not seen before.
The computer has a com-plete symbolic representation of the virtual envi-ronment.
The challenge for the NLG system isto generate, in real time, natural-language instruc-tions that will guide the users to the successfulcompletion of their task (see Fig.
1).
One cru-cial advantage of this generation task is that theNLG system and the user can be physically sepa-rated.
This makes it possible to carry out a task-based evaluation over the Internet ?
an approachthat has been shown to provide generous amountsFigure 1: The GIVE Challenge.of data in earlier studies (von Ahn and Dabbish,2004; Orkin and Roy, 2007).In this paper, we describe the software archi-tecture underlying the GIVE Challenge.
The soft-ware connects each player in a 3D game worldwith an NLG system over the Internet.
It is imple-mented and open source, and can be a used onlineduring EACL at www.give-challenge.org.In Section 2, we give an introduction to the GIVEevaluation methodology by describing the experi-ence of a user participating in the evaluation, thenature of the data we collect, and our scientificgoals.
Then we explain the software architecturebehind the scenes and sketch the API that concreteNLG systems must implement in Section 3.
InSection 4, we present some preliminary evaluationresults, before we conclude in Section 5.2 Evaluation methodUsers participating in the GIVE evaluationstart the 3D game from our website at www.give-challenge.org.
They then see a 3Dgame window as in Fig.
1, which displays instruc-tions and allows them to move around in the worldand manipulate objects.
The first room is a tuto-rial room where users learn how to interact with33b2 b3b4 b5b6b7b1playerb8b9b10b11 b14b13b12safedoorb1 opens doorto room 3b9 moves picture tob8: part of safe sequencereveal safe?
to win you have to retrieve the trophy from the safe in room 1?
use button b9 to move the picture (and get access to the safe)?
if the alarm sounds, the game is over and you have lost?
press buttons b8, b6, b13, b13, b10 (in this order) to open the safe;if a button is pressed in the wrong order, the whole sequence is resetb14 makes alarm soundb10, b13: part of safe sequence door to room 2b7 opens/closesstepping on this tiletriggers alarmalarmroom 3b2 turns off alarm tileb3 opens/closes door to room 2b6: part of safe sequenceroom 1b5 makes alarm soundroom 2doordoorlampcouchchairflowerpicturetrophyFigure 2: The map of a virtual world.the system; they then enter one of three evaluationworlds, where instructions for solving the treasurehunt are generated by an NLG system.The map of one of the game worlds is shown inFig.
2: In this world, players must pick up a trophy,which is in a wall safe behind a picture.
In orderto access the trophy, they must first push a buttonto move the picture to the side, and then push an-other sequence of buttons to open the safe.
Onefloor tile is alarmed, and players lose the gameif they step on this tile without deactivating thealarm first.
There are also a number of distrac-tor buttons which either do nothing when pressedor set off an alarm.
These distractor buttons are in-tended to make the game harder and, more impor-tantly, to require appropriate reference to objectsin the game world.
Finally, game worlds can con-tain a number of objects such as chairs and flowerswhich are irrelevant for the task, but can be usedas landmarks by a generation system.Users are asked to fill out a before- and after-game questionnaire that collects some demo-graphic data and asks the user to rate various as-pects of the instructions they received.
Every ac-tion that players take in a game world, and everyinstruction that a generation system generates forthem, is recorded in a database.
In addition to thequestionnaire data, we are thus able to compute anumber of objective measures such as:?
the percentage of users each system leads toa successful completion of the task;?
the average time, the average number of in-structions, and the average number of in-game actions that this success requires;?
the percentage of generated referring expres-sions that the user resolves correctly; and?
average reaction times to instructions.It is important to note that we have designedthe GIVE Challenge not as a competition, but asa friendly evaluation effort where people try tolearn from each other?s successes.
This is reflectedin the evaluation measures above, which are intension with one another: For instance, a systemwhich gives very low-level instructions (?moveforward?
; ?ok, now move forward?
; ?ok, now turnleft?)
will enjoy short reaction times, but it will re-quire more instructions than a system that aggre-gates these.
To further emphasize this perspective,we will also provide a number of diagnostic tools,such as heat maps that show how much time usersspent on each tile, or a playback function whichdisplays an entire game run in real time.In summary, the GIVE Challenge is a novelevaluation effort for NLG systems.
It is motivatedby real applications (such as pedestrian navigationand the generation of task instructions), makesno assumptions about the internal structure of anNLG system, and emphasizes the situated genera-tion of discourse in a simulated physical environ-ment.
The game world is scalable; it can be mademore complex and it can be adapted to focus onspecific issues in natural language generation.3 ArchitectureA crucial aspect of the GIVE evaluation methodol-ogy is that it physically separates the user and theNLG system and connects them over the Internet.To achieve this, the GIVE software infrastructureconsists of three components:1. the client, which displays the 3D world tousers and allows them to interact with it;2. the NLG servers, which generate the natural-language instructions; and3.
the Matchmaker, which establishes connec-tions between clients and NLG servers.These three components run on different ma-chines.
The client is downloaded by users fromour website and run on their local machine; eachNLG server is run on a server at the institutionthat implemented it; and the Matchmaker runs ona central server we provide.34Game ClientMatchmakerNLG ServerNLG ServerNLG ServerFigure 3: The GIVE architecture.When a user starts the client, it connects overthe Internet to the Matchmaker.
The Matchmakerthen selects a game world and an NLG server atrandom, and requests the NLG server to spawna new server instance.
It then sends the gameworld to the client and the server instance and dis-connects from them, ready to handle new connec-tions from other clients.
The client and the serverinstance play one game together: Whenever theuser does something, the client sends a messageabout this to the server instance, and the server in-stance can also send a message back to the clientat any time, which will then be displayed as an in-struction.
When the game ends, the client and theserver instance disconnect from each other.
Theserver instance sends a log of all game events tothe Matchmaker, and the client sends the ques-tionnaire results to the Matchmaker; these then arestored in the database for later analysis.All of these components are implemented inJava.
This allows the client to be portable acrossall major operating systems, and to be started di-rectly from the website via Java Web Start withoutthe need for software installation.
We felt it wasimportant to make startup of the client as effort-less as possible, in order to maximize the num-ber of users willing to play the game.
Unsurpris-ingly, we had to spend the majority of the pro-gramming time on the 3D graphics (based on thefree jMonkeyEngine library) and the networkingcode.
We could have reduced the effort requiredfor these programming tasks by building upon anexisting virtual 3D world system such as SecondLife.
However, we judged that the effort needed toadapt such a system to our needs would have beenat least as high (in particular, we would have hadto ensure that the user could only move accordingto the rules of the GIVE game and to instrumentthe virtual world to obtain real-time updates aboutevents), and the result would have been less exten-abstract class NlgSystem:void connectionEstablished();void connectionDisconnected();void handleStatusInformation(Position playerPosition,Orientation playerOrientation,List?String?
visibleObjects);void handleAction(Atom actionInstance,List?Formula?
updates);void handleDidNotUnderstand();void handleMoveTurnAction(Direction direction);.
.
.Figure 4: The interface of an NLG system.sible to future installments of the challenge.Since we provided all the 3D, networking, anddatabase code, the research teams being evaluatedwere able to concentrate on the development oftheir NLG systems.
Our only requirement wasthat they implement a concrete subclass of theclass NlgSystem, shown in Fig.
4.
This involvesoverriding the six abstract callback methods inthis class with concrete implementations inwhich the NLG system reacts to specific events.The methods connectionEstablishedand connectionDisconnected are calledwhen users enter the game world and whenthey disconnect from the game.
The methodhandleAction gets called whenever the userperforms some physical action, such as pushing abutton, and specifies what changed in the worlddue to this action; handleMoveTurnActiongets called whenever the user moves;handleDidNotUnderstand gets calledwhenever users press the H key to signal thatthey didn?t understand the previous instruction;and handleStatusInformation gets calledonce per second and after each user action toinform the server of the player?s position andorientation and the visible objects.
Ultimately,each of these method calls gets triggered by amessage that the client sends over the networkin reaction to some event; but this is completelyhidden from the NLG system developer.The NLG system can use the method send tosend a string to the client to be displayed.
It alsohas access to various methods querying the state ofthe game world and to an interface to an externalplanner which can compute a sequence of actionsleading to the goal.4 First resultsFor this first installment of the GIVE Challenge,four research teams from the US, the Netherlands,35and Spain provided generation systems, and anumber of other research groups expressed theirinterest in participating, but weren?t able to partic-ipate due to time constraints.
Given that this wasthe first time we organized this task, we find thisa very encouraging number.
All four of the teamsconsisted primarily of students who implementedthe NLG systems over the Northern-hemispheresummer.
This is in line with our goal of tak-ing this first iteration as a ?dry run?
in which wecould fine-tune the software, learn about the easyand hard aspects of the challenge, and validate theevaluation methodology.Public involvement in the GIVE Challenge waslaunched with a press release in early Novem-ber 2008; the Matchmaker and the NLG serverswere then kept running until late January 2009.During this time, online users played over 1100games, which translates into roughly 75 game runsfor each experimental condition (i.e., five differ-ent NLG systems paired with three different gameworlds).
To our knowledge, this makes GIVE thelargest NLG evaluation effort yet in terms of ex-perimental subjects.While we have not yet carried out the detailedevaluation, the preliminary results look promising:a casual inspection shows that there are consider-able differences in task success rate among the dif-ferent systems.While there is growing evidence from differ-ent research areas that the results of Internet-basedevaluations are consistent with more traditionallab-based experiments (e.g., (Keller et al, 2008;Gosling et al, 2004)), the issue is not yet set-tled.
Therefore, we are currently conducting a lab-based evaluation of the GIVE NLG systems, andwill compare those results to the qualitative andquantitative data provided by the online subjects.5 ConclusionIn this paper, we have sketched the GIVE Chal-lenge and the software infrastructure we have de-veloped for it.
The GIVE Challenge is, to thebest of our knowledge, the largest-scale NLG eval-uation effort with human experimental subjects.This is made possible by connecting users andNLG systems over the Internet; we collect eval-uation data automatically and unobtrusively whilethe user simply plays a 3D game.
While we willreport on the results of the evaluation in more de-tail at a later time, first results seem encouragingin that the performance of different NLG systemsdiffers considerably.In the future, we will extend the GIVE Chal-lenge to harder tasks.
Possibilities includ mak-ing GIVE into a dialogue challenge by allowingthe user to speak as well as act in the world; run-ning the challenge in a continuous world ratherthan a world that only allows discrete movements;or making it multimodal by allowing the NLGsystem to generate arrows or virtual human ges-tures.
All these changes would only require lim-ited changes to the GIVE software architecture.However, the exact nature of future directions re-mains to be discussed with the community.ReferencesA.
Belz and A. Gatt.
2008.
Intrinsic vs. extrinsic eval-uation measures for referring expression generation.In Proceedings of ACL-08:HLT, Short Papers, pages197?200, Columbus, Ohio.M.
E. Foster.
2008.
Automated metrics that agreewith human judgements on generated output for anembodied conversational agent.
In Proceedings ofINLG 2008, pages 95?103, Salt Fork, OH.S.
D. Gosling, S. Vazire, S. Srivastava, and O. P. John.2004.
Should we trust Web-based studies?
A com-parative analysis of six preconceptions about Inter-net questionnaires.
American Psychologist, 59:93?104.F.
Keller, S. Gunasekharan, N. Mayo, and M. Corley.2008.
Timing accuracy of web experiments: A casestudy using the WebExp software package.
Behav-ior Research Methods, to appear.A.
Koller, J. Moore, B. di Eugenio, J. Lester, L. Stoia,D.
Byron, J. Oberlander, and K. Striegnitz.
2007.Shared task proposal: Instruction giving in virtualworlds.
In M. White and R. Dale, editors, Work-ing group reports of the Workshop on Shared Tasksand Comparative Evaluation in Natural LanguageGeneration.
Available at http://www.ling.ohio-state.edu/nlgeval07/report.html.J.
Orkin and D. Roy.
2007.
The restaurant game:Learning social behavior and language from thou-sands of players online.
Journal of Game Develop-ment, 3(1):39?60.A.
Stent, M. Marge, and M. Singhai.
2005.
Evaluatingevaluation methods for generation in the presence ofvariation.
In Proceedings of CICLing 2005.L.
von Ahn and L. Dabbish.
2004.
Labeling imageswith a computer game.
In Proceedings of the ACMCHI Conference.36
