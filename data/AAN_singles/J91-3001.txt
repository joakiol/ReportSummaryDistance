An Algorithm for High Accuracy NamePronunciation by Parametric SpeechSynthesizerTony Vitale"Digital Equipment CorporationAutomatic and accurate pronunciation of personal names by parametric speech synthesizer hasbecome a crucial limitation for applications within the telecommunications i dustry, since thetechnology is needed to provide new automated services such as reverse directory assistance(number to name).Within text-to-speech technology, however, it was not possible to offer such functionality.This was due to the inability of a text-to-speech device optimized for a specific language (e.g.,American English) to accurately pronounce names that originate from very different languagefamilies.
That is, a telephone book from virtually any section of the country will contain namesfrom scores of languages as diverse as English and Mandarin, French and Japanese, Irish andPolish.
All such non-Anglo-Saxon ames have traditionally been mispronounced by a speechsynthesizer resulting in gross errors and unintelligible speech.This paper describes how an algorithm for high accuracy name pronunciation was imple-mented in software based on a combination of cryptanalysis, statistics, and linguistics.
Thealgorithm behind the utility is a two-stage procedure: (1) the decoding of the name to determineits etymological grouping; and (2) specific letter-to-sound rules (both segmental rules as wellas stress-assignment rules) that provide the synthesizer parameters with sufficient additionalinformation to accurately pronounce the name as would a typical speaker of American En-glish.
Default language and thresholds are settable parameters and are also described.
Whilethe complexity of the software is invisible to applications writers as well as users, this function-ality now makes possible the automation of highly accurate name pronunciation by parametricspeech synthesizer.1.
BackgroundThere has been a great deal of interest recently in the generation of accurate phoneticequivalences for proper names.
New and enhanced services in the telecommunica-tions industry as well as the increasing interest in speech I /O for the workstationhas renewed interest in applications such as the automation of name pronunciationby speech synthesizer in reverse directory assistance (number to name) applications(Karhan et al 1986).
In addition, speech recognition research can benefit by automaticlexicon construction tobe ultimately used in such applications as directory assistance(name to number) and a variety of workstation applications (Cole et al 1989).?
30 Forbes Rd.
(NRO5/I4), Northboro, MA 01532 USA(~) 1991 Association for Computational LinguisticsComputational Linguistics Volume 17, Number 3The inaccuracy of name pronunciation by parametric speech synthesizer has beena problem often addressed in the literature (Church 1986; Golding and Rosenbloom1991; Liu and Haas 1988; Macchi and Spiegel 1990; Spiegel 1985, 1990; Spiegel andMacchi 1990; Vitale 1987, 1989a, 1989b, and others).
The difficulty stemmed from thefact that high-quality speech synthesizers were so optimized for a particular language(e.g., American English), that a non-English form such as an unassimilated or partiallyassimilated loanword would be processed according to English letter-to-sound rulesonly) Since non-Anglo-Saxon personal names fall into the category of loanwords, thepronunciation of these forms ranged from slightly inaccurate to grossly unintelligible.1.1 General Letter-to-Sound RulesLetter-to-sound rules are a requirement in any text-to-speech architecture and takeslightly different forms from system to system; however, they typically follow a stan-dard linguistic format such as x - .
y/z, where x is some grapheme sequence, y somephoneme sequence, and z the environment, usually graphemic.
The following is atypical example of a set of letter to sound rules:C ~ I s /  /-{Eft,Y}C --* /k /This set would handle all such forms as CELLAR, CILIA, CY, CAT, COD, etc., butclearly not loanwords uch as CELLO for exactly the same reasons that make the pro-nunciation of last names so difficult for a synthesizer having only English letter-to-sound rules.
A number of letter-to-sound rule sets are in the public domain, (e.g.,Hunnicutt 1976; Divay 1984, 1990).
However, many rule sets that are currently in usein commercial speech synthesizers emain confidential.
Venezky (1970) contains anextensive discussion of issues involving phoneme-grapheme correspondence.The accuracy of pronunciation of normal text in high-quality speech synthesizersusing exclusively or primarily letter-to-sound processing can now range as high as95+%.
2 In tests we ran, however, this accuracy (without dictionary lookup), was de-graded by as much as 30% or more when the corpus changed to high-frequency propernames.
The degradation was even higher when the names were chosen at random andcould be from any language group.
Spiegel (1985) cites the average rror rate for thepronunciation of names over four synthesizers as 28.7%, which was consistent withour results.The reason for this degradation is due to the fact that the phonological intelligenceof a speech synthesizer for a given language cannot discriminate among loanwordsthat are not contained in its memory (i.e., dictionary).
In the Case of names, these arereally loanwords ranging from the commonly found Indo-European languages such asFrench, Italian, Polish, Spanish, German, Irish, etc.
to the more "exotic" ones such asJapanese, Armenian, Chinese, Latvian, Arabic, Hungarian, and Vietnamese.
Clearly,the pronunciation of these names from the many ethnic groups does not conformto the phonological pattern of English.
For example, as pronounced by the averageEnglish speaker, most German ames have syllable-initial stress, Japanese and Spanishnames tend to have penultimate stress, and some French names have word-final stress.1 That is, phonemic rules.
Obviously, the phonetics output by a synthesizer would not be sufficient formultiple languages.2 In an informal study, Klatt (personal communication) tested our rule set for English by replicating astudy by Bill Huggins (Bolt, Beranek and Newman) using letter to sound rules without dictionary over1678 complex polysyllabic forms.
The algorithm tested (and the one used in this study) had an errorrate of 5.1%.
The error ate using a dictionary would be much lower.258Vitale Algorithm for High Accuracy Name PronunciationChinese names tend to be monosyllabic and consequently stress is a non-issue; inItalian names, stress may be penultimate or antepenultimate s is the case with Slaviclanguages and certain other groups.But while stress patterns are relatively few in number, the letter-to-sound corre-spondences are extremely varied.
For example, the orthographic sequence CH is pro-nounced \[~\] in English names e.g., CHILDERS, \[~\] in French names e.g., CHARPENTIER,and \[k\] in Italian names e.g.
BRONCHETTI or the anglicized version of some Germannames e.g., BACH.
This means that letter-to-sound must account for a potentially largenumber of diverse languages in order to output he correct phonetics.Most researchers understand that in order to process the name accurately, at leasttwo parameters must be known: (1) that the string is a name and thus needs to beprocessed by a special algorithm; and (2) that the string must be identified with aparticular set of languages or language groups such that the specifics of the pronunci-ation (i.e., the letter-to-sound rules) can be formally described (Church 1986; Liu andHaas 1988; and others).
While there has been some interest in attempting to identifya word as a name from random text, this present work assumes a database in whichname fields are indexed as such (e.g., a machine-readable telephone directory) and nofurther mention of this will be made.
This paper simply describes an implementationof this two-stage process, and details the first stage - -  the correct identification of aname as belonging to a certain language group.
It should be stressed that there havebeen other attempts to implement similar algorithms, although few descriptions ofsuch implementations are available.1.2 Language GroupsFor purposes of identification, sets of similar languages are more efficiently groupedtogether.
However, the language groups used in this study may not always corre-spond to the set of language families familiar to most linguists.
For example, whileJapanese or Greek may be in groups by themselves, languages such as Spanish andPortuguese may be grouped together into a So.
Romance group and this set may bedifferent from, Say, Italian, which may be grouped with Rumanian, or French, whichmay be grouped by itself.
This is done to reduce the complexity of letter-to-sound (Sec-tion 4.1).
However, the software is set up such that groupings can be moved aroundto accommodate different letter-to-sound rule sets.
In addition, the number of groupsis a variable parameter and could be modified as would the inclusion of any new rulesets in the letter-to-sound subsystem.
Thus, for n language groups, the probability Pof some language group Li  being the correct etymology is P(L i )  - 1 -  ~ .1.3 EtymologyIdentification ofa particular language group in the United States and many countries ofWestern Europe is not an easy task.
According to the United States Social Security files(Smith 1969), there are approximately 1.5 million different last names in the UnitedStates, with about one-third of these being unique in that they occur only once inthe register.
3 Furthermore, the etymologies of the names pan the entire range of theworld's languages, although the spread of these groupings is obviously related togeopolitical units and historical patterns of immigration and is different in the UnitedStates than it is, say, in Iceland, Ireland, or Italy.3 Spiegel (1985) points this out.
This is an excellent article that contains a number of useful statistics onpersonal names.259Computational Linguistics Volume 17, Number 32.
Role of the DictionaryThe first step in the process was the construction of a dictionary that contained bothcommon and unusual names in their orthographic representation a d phonetic equiv-alent.
All sophisticated speech synthesizers today use: a lexical database for dictionarylookup to process words that are, for one reason oi" another, exceptions to the rule.In generic synthesizers, these are typically functors that undergo vowel or stress re-duction, partially assimilated or unassimilated loanwords that cannot be processedby language-specific letter-to-sound rules, abbreviations that are both generic anddomain-specific, homographs that need to be distinguished phonetically, and selectedproper nouns, such as geographical place names or company names.In the case of proper surnames, however, dictionary lookups, while necessary, areof limited use.
There are a number  of reasons for this.
First, while the most commonnames would have an extremely high hit rate (much like functors in a generic sys-tem), the curve quickly becomes asymptotic.
Church (1986) has shown that while themost common 2,000 names can account for 46% of the Kansas City telephone book, itwould take 40,000 entries to obtain a 93% accuracy rate.
Furthermore, accuracy woulddecrease if one considers that geographic area has a profound influence on namegrouping, and thus the figures for a large East or West Coast metropol itan area wouldcertainly be significantly lower.
It can be easily shown that the functional load of eachname changes with the geographical location.
4 The name SCHMIDT, for example, isnot in the list of the most frequent 2,000 names, yet it appears in the Social Securityfiles as the most common name in Milwaukee (Spiegel 1985).
Liu and Haas (1988)conducted a similar experiment that included 75 million households in the U.S. Thefirst few thousand names account for 60% of the database, but the curve flattens outafter 50,000 names and it would take 175,000 names in a dictionary to cover 88.7% ofthe population.
This would mean that even with an extremely large dictionary (eachentry of which would have to be phoneticized), there would still be an error rate ofover 11%.Even with these limitations, dictionary lookups are still quite important.
Fre-quently occurring names, like functors, have a high functional oad (above).
Spiegel(1985) claims that if the most common 5,000 names are used in a dictionary for apopulat ion of 10 million people, even if letter-to-sound had an accuracy of only 75%(which is extremely low for a high-quality speech synthesizer), the error rate would be< 2.5%.
Most other researchers have also assumed a dictionary lookup as part of anyprocedure to increase the accuracy of name pronunciation.
Therefore the general flowof text from the grapheme space to the phonetic realization must  proceed first througha dictionary.
Common last names such as SMITH, JOHNSON, WILLIAMS, BROWN, JONES,MILLER, DAVIS, WILSON, ANDERSON, TAYLOR, etc.
and common names (both first andlast names) from a variety of other languages hould be included.
The size of thisdictionary is up to its creator.
The dictionary used in this software contained about4,000 lexical entries that were proper names, s There is, however, no reason to exclude4 Functional load here is used in a slightly different sense than in linguistics.
The functional load of agrapheme is its frequency of occurrence, in relation to other graphemes in the language, weightedequally, as measured over a sizable corpus of orthographic data.5 In practice, the name dictionary could be contained within a larger dictionary that would be part of agenetic text-to-speech system.
Moreover, the dictionary should be easily modifiable by an applicationswriter.
Functions uch as add, remove, find, modify, and the like can be used to maximize the effect of thedictionary, especially if some preliminary analysis has been done on population statistics.
Experiencehas also shown that a programmer should be able to easily merge new word or name lists with a basedictionary and quickly examine avariety of statistics including the size in entries, bytes, or blocks as260Vitale Algorithm for High Accuracy Name Pronunciationvery large dictionaries (e.g., > 50,000 words) although the choice of a search algorithmthen becomes more important in real-time implementations.When a dictionary lookup is used and a match occurs, the result is simply atranslation from graphemes to phonemes, and the phoneme string (along with manyother acoustic parameters picked up along the way) is output o the synthesizer.
6 Whenthere is no match, (i.e., most cases), however, some algorithm is needed to increasepronunciation accuracy.3.
Identif ication PassIt is assumed that certain textual elements are identified as names and are intentionallyprocessed as such.
This algorithm does not address the identification ofproper namesin random text, although there has been some activity in this area in recent years withthe increased attention to voice prosthesis, remote access to electronic mail, and otherapplications.
In database retrieval applications this is not usually a problem, sincenames fields in a database are typically marked by some field identifier.
Similarly, thesyntax of electronic mail message headers can often be used to mark a personal name.The first stage in the identification procedure is the analysis of the sequence ofgraphemes that makes up the name, and its indexing as belonging to some languagegroup.
The concept of identification by orthographic trigram is by no means new andhas been discussed in the literature (e.g., Church 1986; Liu and Haas 1988; and others).In our implementation, the identification is a complex procedure that includes filterrules for identification or elimination, graphemic (non-trigram) and morphologicalanalysis, as well as trigram analysis.
While this scheme may seem complex, it will runin real time, and thus the complexity is invisible to the user.3.1 Filter RulesIt is well known in both linguistics and cryptanalysis that a text string from a lan-guage Li will have unique sequence characteristics that distinguish Li from all otherlanguages in the set {Li, Lj,... Ln }.
All alphabetic languages (as opposed to syllabariesor ideographic systems) have a quantifiable functional load of graphemes as well asphonemes, and this functional load will differ greatly from language to language.
Wehave therefore created a set of rules that we call filter rules.
Filter rules are rules thatmay positively identify a name or positively eliminate a name from further consider-ation.
The use of nonoccurrence is not new but is refined to include a more elaboratefilter mechanism for variable length grapheme sequences.
When scanning the name todetermine tymology, if the name cannot be positively identified, it is more efficient toeliminate some groups from consideration, thereby increasing the speed of the search(below).There are some unique identification characteristics of grapheme strings from cer-tain languages.
In these cases, a grapheme G may help identify a string as being fromLi.
For example, the grapheme E in English is well known as the most common letter,and has a functional load of 12.4% (Daly 1987).
Scrabble and similar games are interest-ing indicators of this and mark functional load of graphemes by values of individualletters; the lower the value, the higher the functional load.
Naturally, quantitative dif-ferences occur from language to language.
While z has an extremely low functionalload in English, it is one of the most common letters in Polish.
As an example of thiswell as the average l ngth of each field of an entry.6 A dictionary entry in currently-used generic text-to-speech algorithms is really nothing more than acomplex context-free l tter-to-sound rule.261Computational Linguistics Volume 17, Number 3metric, if we take 1+ occurrences of the letter K in a name over the total number ofunique names in a corpus, in Japanese, the frequency of this letter is 40.1%, in Ger-man it is only 18.9% and in Italian, the letter does :not occur.
Since the distributionof letters in proper names will differ from that of the general exicon, statistics onletter frequency in names should be compiled independently but could be used fordetermining probabilities.
Similarly, the orthographic length of a name, like the lengthof a common noun, could, in a more elaborate scheme, be also used as a factor indetermining probabilities.
In the dictionary used in this study, both names and non-names together had an average length of slightly under 7.5 graphemes.
This coincideswith the findings of Daly (1987), in which normal words had an average length of 7.35graphemes.
7 Neither of these were used as factors in determining probabilities in thisimplementation.Sequences of graphemes are much more useful in determining the identificationof a language group.
Sequences of 2 or more letters including larger morphological el-ements within a name may be considered characteristic of a language group althougheach of these may also effectively exclude a set of other language groups.
For exam-ple, sequences uch as cz, PF, SH, EE (or longer ones) unambiguously define certainlanguage groups.
A trivial example of this would be the sequence #MC (where # isa word-boundary), which unambiguously identifies the word as Irish resulting in aprobability of 1 for the identification of the corresponding language group.However, even if a sequence cannot identify a language group unambiguously, thefilter rules often eliminate one or more groups from consideration, thereby drasticallyaltering the statistical chances of an incorrect guess.
As might be expected, the longerthe (legal) sequence in Li, the less likely it is to occur in another language group.
Insome languages, either alphabetic ones or those that are transliterated into alphabeticsystems (e.g., Japanese), certain letters do not occur.
For example, the letter L does notoccur in Japanese, x does not occur in Polish, J does not occur in Italian, and so on.The occurrence of any of these graphemes in a name string would then immediatelyeliminate that language from consideration.
Thus, if m language groups have beeneliminated, the probability of some language group Li being the correct etymology isnow P(Li) = ~_-~.
Analysis has shown that the filter rules eliminate an average of 54%of all possible language groups, sFilter rules, therefore, consist of (a) identification rules and (b) elimination rules.Identification rules match a grapheme sequence against an identical sequence in thename.
A match is a positive identification and the filter routines top.
Elimination rulesalso match a grapheme sequence against an identical grapheme sequence in the name.A match eliminates that language group from consideration.
There are a number ofdifferent ways these rules could be applied.
One of the more efficient methods is tocreate a hash table of grapheme strings and search for substrings for identification andelimination at the same time.
Whichever way a compiler for these rules is written, it isclear that the routines stop after a positive identification occurs.
The benefit of usingfilter rules prior to the trigram analysis (below) is one of speed.One minor problem that had to be examined was the fact that many names havebeen anglicized from their original form, resulting in varied and disparate pronuncia-7 The average l ngth of an English word is 3.98 letters when the words are weighted by frequency ofappearance (Daly 1987) clearly due to the shorter length of commonly occurring forms such as functionwords.
While no similar statistics have been compiled for names, it is doubtful whether thediscrepancy in length between weighted and unweighted would be as large.8 The ISO-Latin character set (or an equivalent) could also be utilized in situations where proper namescan be written with special symbols (e.g., i~, o, 6 and others), since these orthographic symbols couldbe used to eliminate or positively identify language groups.262Vitale Algorithm for High Accuracy Name Pronunciationtions (not to mention some rather strange spellings, including raphemes that do notexist in the source language).
For example, a Polish name such as ALEXANDROWICZcontains the grapheme x, although x does not occur in Polish (i.e.
KS --* X).
The ortho-graphic sequence scI (= \[~\]) in Italian is occasionally anglicized as SH even throughthe sequence StI does not occur in the language.
Therefore, the elimination rules haveto be carefully tailored to take such phenomena into consideration.
Sequences thatpositively identify a language must also be carefully screened for the same reason.Names like O'SHINSKI are not uncommon.
9 In this case, whether the name is consid-ered Irish or Polish may not matter in terms of the phonemic output, but there arecases where it would make enough of a difference to cause intelligibility problems inthe final output.3.2 Trigram Analysis 1?The job of the filter is to positively identify a language or to effectively eliminate one ormore groups within the set of possible language groups when positive identification isnot possible.
Elimination obviously reduces the complexity of the task of the remaininganalysis of the input name.
Assuming that no language group is positively identifiedas the language group of origin by the filter, some further analysis is needed.
Thisfurther analysis is performed by a trigram analyzer, which receives the input namestring and a vector of uneliminated language groups.
The trigram analyzer parses thestring into trigrams.
If word boundary symbols are included as part of the string, thenthe number of trigrams in the string will always be equal to the number of elements(graphemes).
Thus, the name SMITH ==~ #SMITH# will contain five trigrams: #SM, SMI,MIT, ITH, and  TH#.A trigram table is a four-dimensional rray of trigram elements and languagegroup.
This array contains numbers that are probabilities (generated from a largereference corpus of names labeled as belonging to a particular language group) thatthe trigram is a member of that language group.
Probabilities are taken only to fourdecimal places, although there is no empirical reason for this.3.2.1 Creation of Trigram Databases.
The creation of a trigram database would be anextensive and time-consuming task if it were to be done manually.
Nevertheless, itwas initially necessary to hand-label a large list of names with language group tagsassociated with each name.
Fortunately, this was expedited with country-specific per-sonnel ists from a large company.
11Once these lists were completed, computationalanalysis was performed on the list, decomposing each name into grapheme sequencesof varying lengths, including trigrams, and searching for recurring morphological e e-ments as well.
This analysis, in turn, created a set of tables (language-specific n-grams,trigrams, etc.
), which was then used for further analysis.
The language identifier itselfcan be utilized as a tool to pre-filter a new database in order to refine the probabilitytable.
This is illustrated in Figure 1.
The name, language group tag, and statistics fromthe language identifier are received as input.
This analysis block takes this informationand outputs the name and language group tag to a master language file and producesrules to a filter rule-set.
In this way, the database of the system is expanded as new9 Murray Spiegel (personal communication) has pointed out that there are 79 households in the U.S. thathave this name.10 For our purposes here, trigram will be used synonymously with the term trigraph.
Trigram analysis isby no means new and has been discussed often in the literature (e.g., Church 1986).11 Although these had to be carefully verified because of the increasing numbers of expatriates living andworking in any given country.263Computational Linguistics Volume 17, Number 3Figure 1I !name I Language Id &J Phonetic- Realizationrulesname/Lang, tag/phonemics'\[' trigramprobabilitiesCompute Probabilitiesname Lang.
tagstats AnalysisMasterLanguage FileElimination & \[IdentificationRules \[nameLang.
ta!input names are processed so that new names can be more accurately recognized.The filter rule store provides the filter rules to the filter module for identification orelimination.3.2.2 Trigram Array and Statistical Analysis.
The final trigram table itself then hasfour dimensions: one for each grapheme of the trigram and one for the language group.The trigram probabilities are sent to the language group blocks, phonetic realizationblock, and to the trigram analysis, which produces a vector of probabilities that thegrapheme string belongs to the various language groups.The master file contains all grapheme strings and their language group tag.
Thetrigram probabilities are arranged in a data structure designed for ease of searching agiven input trigram.
For example, if we use an n-deep three-dimensional matrix wheren is the number of language groups, then trigram probabilities can be computed fromthe master file using the following algorithm:compute total number of occurrences of each tr igram forall language groups L (l-n)for all grapheme strings S in Lfor all tr igrams T in Sif (count \[T\] \[L\] = O)uniq \[L\] + = 1count \[T\] \[L\] + = ifor all possible tr igrams T in mastersum= 0for all language groups Lsum + = count \[T\] \[L\] /uniq \[L\]for all language groups Lif sum > 0, prob\[T\] \[L\]=count \[T\] \[L\] /uniq \[L\] /sumelse prob\[T\] \[L\]=O.O;264Vitale Algorithm for High Accuracy Name PronunciationTable 1Sample matrix of probabilities.Trigram Li L i ... Ln#VI .0679 .4659 .
.
.
.
2093VIT .0263 .4145 .
.
.
.
0000ITA .0490 .7851 .
.
.
.
0564TAL .1013 .4422 .
.
.
.
2384ALE .0867 .2602 .
.
.
.
2892LE# .1884 .3181 .
.
.
.
0688AV.
.0866 .4477 .
.
.
.
1437In any case, the result of the trigram analysis is a vector of probabilities for a giventrigraph over the number of language groups.
Table 1 shows an example of what theprobability matrix would look like for the name string VITALE.In the matrix shown in Table 1, L is a language group, and n is the number oflanguage groups not eliminated by the filter rules.
The probability that the graphemestring #VITALE# belongs to a particular language group is actually produced as a vectorof probabilities from the total probability line.
In this case, the trigram #vI has aprobability of .0679 of being from language group Li .4659 of being from the languagegroup Lj and only .2093 of being from the language group Ln.
The average of theprobability table entries identifies Lj as being the most probable language group.
Inthis case, Lj was Italian.The probability of a trigram being a member of a particular language group canbe derived by a number of different methods.
For example, one could use a standardBayesian formula that would derive the probability of a language group, given atrigraph T, as P(LilT) whereP(TILi)P(Li)P(Li)IT) = Y~,k P(TILk)P(Lk)Furthermore, where x is the number of times the token T occurred in the languagegroup Li and y is the number of uniquely occurring tokens in the language group Li,always, where n is the number of language groups (nonoverlapping).
Therefore,P(Li\]T) - P(TILi) P(TfLi) ~k=l P(~ Lk) Ek=l P(TILk)While this is not the most mathematically optimal or elegant method (since averag-ing tends to favor a noneven distribution of trigram probabilities) and is certainly asimplistic method of performing such calculations, it works reasonably well and iscomputationally inexpensive.
It should be noted, however, that multiplying proba-bilities, calculating and adding log probabilities, or even averaging the two highestprobabilities, may all work, but each of these approaches assumes that trigrams areindependent of one another.
It is beyond the scope of this paper to discuss the eleganceof one mathematical solution over another but it would be interesting to examine otheroptions, such as higher order conditional probabilities, e.g.,P(LiIT1, T2, T3) = P(TIlT2, T3, Li)P(T21T3, Li)P(T3 Li)P(Li)P(T1, T2, T3)although these would clearly be computationally quite expensive.265Computational Linguistics Volume 17, Number 3Table 2Name pronunciation statistics.Name Identified Language Highest ProbabilityPartington English .4527Bischeltsrieder German 1.000Villalobos Spanish .4377Kuchenreuther German .6973O'Banion Irish 1.000Zecchitella Italian 1.000Pederson English .3258Hashiguchi Japanese 1.000Machiorlatti Italian 1.000Andruszkiewicz Polish 1.000Fujishima Japanese 1.000Macutkiewicz Polish .6153Fauquembergue French .4619Zwischenberger German 1.000Youngblood English .8685Laracuente Italian .2675Laframboise French .3778McAllister Irish 1.000Abbruzzese Italian .5113Rodriguez Spanish .6262Yanagisako Japanese .7074Migneault French 1.000Znamierowski Polish 1.000Shaughnessy Irish .6239Table 2 is an example of the output of the language group identification module.The table consists of twenty-four proper names randomly but equally selected fromthe eight separate language groups.
12 Twenty-three out of twenty-four were correctlyidentified.
The only error is on the name LARACUENTE, which is the lowest score andis identified as Italian instead of Spanish.Note also that .2675 is the lowest score in the list.
In practice, this would nothave presented a problem, since the letter-to-sound rules for language groups such asItalian and Spanish are very similar (e.g., the stress pattern would be penultimate, tc.
)and thus the phonetic realization would be almost identical.
When pronunciation isincluded in the evaluation, the scores would be slightly higher in certain cases, sincean incorrect identification does not always result in an incorrect pronunciation.3.3 ThresholdingSince the output of the etymology analyzer is a vector of probabilities and only thehighest score is chosen (i.e., a best guess), a number of different situations can ariseregarding the total spread among the numbers, the difference in spread between anytwo numbers, or the spread between some number and 0 (i.e.
an absolute comparison).For this reason, and to make use of this information, thresholding has been applied.Essentially, thresholding allows for analysis to be made over the vector of proba-bilities such that statistical information can be used to help determine the confidencelevel for the language group with the highest score (i.e., the best guess).
Two types ofthreshold criteria have been applied: absolute and relative.12 Randomly selected from names over 7 graphemes in length to increase complexity somewhat.266Vitale Algorithm for High Accuracy Name Pronunciation3.3.1 Absolute Thresholding.
Absolute thresholding can apply when the highest prob-ability determined by the trigram analyzer is less than a predetermined threshold thatis variable or can be set programmatically.
This would mean that the trigram analyzercould not determine, from among the language groups, a single language group witha specified egree of confidence.
For example, if empirical evidence (i.e., over a givencorpus) suggests that P < n (where P is the highest probability and n is some numberpredetermined to be too low for an adequate confidence l vel), then some other actionshould be taken, n should be set by analysis of data.
While this "other action" is vari-able, one approach would be to choose a default language that may or may not be thesame as the language group identified by the highest probability.
Evidence suggeststhat typically it is not.As an example, if the absolute threshold were set at P < .1000 and the highestscore were .0882 for some language Li, then the default language is chosen whetheror not this is the same as Li.
There may be circumstances where the accuracy might beable to be tuned by adjusting the absolute threshold.
13However, this parameter shouldbe construed more as a partial filter which, if set to some reasonable value, will filterout only scores showing a very low confidence l vel, and thus it would rarely affectthe result.3.3.2 Relative Thresholding.
Another type of thresholding scheme that was imple-mented is a relative thresholding.
In this case, A spans a number of probabilitiesprovided that the distance between the highest score and the default language is < n.Therefore, if Pj was the probability assigned to the default language group, no matterwhere this occurred relative to the best guess Pi, if A(Pi, Pj) < n, the default languageis chosen.
(Typically, n is a smaller number than it was for absolute thresholding.)
Thisis, of course, empirical and should be judged according to an analysis of the databaseused.
It is our impression that if the default language group falls within the A, thealgorithm should force a choice of the default language.It should be noted, however, that there are other ways in which relative threshold-ing could have been implemented, e.g., when the distance in probabilities between thelanguage group identified as having the highest probability and that identified as hav-ing the second highest probability is < n, where again n is some number determinedby analysis of the data.
Thus where Pi is the highest probability and Pj the secondhighest, then, if A(Pi, Pj), < n, the default language is chosen.
The problem with thisapproach is that it would result in two close scores (i.e.
between similar languages),forcing a default o a third and possibly structurally dissimilar language.
For example,a name for which the scores for Italian or Spanish fell within the A might then beforced into the default language, say English.
This is clearly not optimal for a genericuse of the algorithm, although it might be useful under certain application-specificcircumstances.3.4 Default LanguageTo solve practical application problems of name pronunciation, it was necessary todefine a default language group.
The concept of using a default language provesto be useful for several reasons: (1) it is consistent with the philosophy that where13 Such a priori probabilities for thresholding can either be adjusted once arly in the application rmayeven be biased by a running average based on the population that used the application within someparticular time frame.267Computational Linguistics Volume 17, Number 3mistakes are made, they will reflect human errors in pronunciation; 14 (2) the softwareunderlying this algorithm is designed to be used in speech communities anywhere inthe world; and (3) the default language could be adjusted for communities in the U.S.or elsewhere where one language group predominates.If Pi or A(Pi~Pj) falls within some range, it signals, for whatever eason, a lowconfidence l vel.
Humans, when faced with a decision in these circumstances, oftenopt for the "familiar," in this case, some predefined efault pronunciation.
This wouldalmost always be the language of the speech community in which the application isrunning.
In other words, if the confidence l vel is measured as low via some thresh-olding mechanism, then a conservative approach would be to default o some "safe"language group, even if this might result in an error in the correct pronunciation (seefn.
14).Secondly, whether an application is running in Berlin, Paris, Dublin, or Milan, thedefault language setting could be changed to reflect he predominant language group.In Germany, for example, in cases where threshold confidence l vel scores are too lowfor the language group identifier, the default (presumably German) would reflect areasonable guess.The default language parameter could also be used in other cases where the pre-dominant linguistic base of an area is known to be different from that of the widerspeech community.
In telecommunications applications, for example, telephone num-ber prefixes are unambiguous indicators of geographical reas, some of which arerelatively homogeneous in ethnic makeup.
In cases like these, an application mightmake use of an automatic default language change for calls pertaining to these areas.Thus, in a Hispanic neighborhood, the default would be to Spanish.
This could alsobe used for homographic first and last names in an elaboration of this system suchthat ambiguities like JULIO, JESUS, and the like could be resolved.
The default lan-guage setting is certainly the most important of any of the settable parameters, inceit determines the base language that is used in all cases of low confidence.4.
Letter-to-Sound RulesMuch of the discussion of this paper has been devoted to an explanation of the identifi-cation of the etymology of the name.
While this is certainly the more difficult problemto solve, there is a great deal more that needs to be done to arrive at some reasonableapproximation of a phonetic realization.
The identifier merely takes an orthographicsequence and adds a tag that marks it as a member of a particular language group.The output remains a graphemic sequence.
It is the tag, however, that forces the namethrough one of a special set of letter-to-sound rules optimized for the languages ofthat particular group.
Therefore, the sole difference between a name run through theidentifier and a word from generic English text is that the name is tagged as a specialcase and undergoes different letter-to-sound rules.4.1 Optimization of Rule SetsThe letter-to-sound module is a knowledge-rich omplex subsystem that takes a graph-eme input and converts it into its appropriate phonemic equivalent.
In normal etter-to-sound systems that apply to generic text (see Klatt 1987 p. 767ff), an orthographic se-quence is, according to some rule set, converted into symbols that typically correspond14 As Spiegel (1985) has pointed out, "the guiding principal behind all work should be that he synthesisrules hould make rrors that are similar to human mistakes.
"268Vitale Algorithm for High Accuracy Name Pronunciation1Dictionary \],LElimination &Identification RulesTagnmAnalysisCLet~er-to-soun Language Group 1Letter-to-soundLanguageGroup 2~p~pnFigure 2to segmental phonemes and stress patterns for that form.
In this case, however, thetask becomes much more complex because of the many language groups involved(Section 1.1).When the tag (above) is attached to some name thereby identifying it as belongingto some language group Li, the orthographic sequence is funneled through a specialset of letter-to-sound rules for Li, and similarly for Lj,..., Ln.
Figure 2 is a block di-agram of the entire flow of the procedure with the letter-to-sound modules (slightlyoversimplified) occurring after identification has been completed.While the concept of separate rule sets is a valid one, in practice this would bean unnecessarily complex system since it is obvious that there would be a great dealof redundancy and overlapping of rules from one rule set to the other.
For example,the simple rule (K ~ /k /  might be valid for many of the language groups.
Thiswould fail to capture the generalization that this rule can be shared by a subset of thetotal number of language groups, would therefore waste computing resources, andconsequently is architecturally suboptimal.As a result of this need for rule-sharing, a slightly different strategy can be devised.Using a complex rule-set, a single rule can contain from 1 to n language identifica-tion tags, n again being equal to the total number of language groups.
In practice,there are rarely more than four tags on a single rule.
However, this does reduce thecomputational complexity and redundancy of having separate rule sets.269Computational Linguistics Volume 17, Number 35.
Some Further Issues5.1 First NamesHistorically, surnames in many parts of the world are s imply extensions of the firstname to distinguish different owners of the same first name.
As a consequence of this,first names have a higher frequency of occurrence than surnames ince the list of firstnames is a smaller set for most languages.
~s Therefore, many of these are appropriatelyincluded in the lexicon or dictionary.
In addition, the same first name may span a widevariety of languages.
Common European first names are found in disparate regionsof the world, due to extralinguistic factors such as the geography of former colonialpowers.
Put another way, more people in anglophone countries have the first nameJOHN than have the last name SMITH.
16 For this reason, the most common first namesin each language group are included in the dictionary.
However,  in the event thatthere is no dictionary match on first names, they should still be processed, like thesurname, by the language identification module (below).Processing the first name can be done independently or, in an elaboration of thealgorithm, may be done in conjunction with the surname.
For example, if the nameYUKIO KOBAYASHI were processed and one name was found by a dictionary lookup,that identification could assist in the identification of the other.
If the probabil ity ofboth names were low but the best guess showed the same language group identifiedfor both, this could also be used as a factor in the determination of the correct ety-mology.
In this scheme, caution must  be used especially with female names in manycountries with a heterogeneous ethnic makeup (e.g.
the United States) since a surname(taken from a husband) and female first name will often be from different languagegroups.
This, of course, can be overcome by marking such names in the lexicon asfemale.
However,  it was found that such additional loading is not necessary sincethe etymology of names can be accurately ascertained without utilizing informationoutside of the name itself.5.2 Hyphenated SurnamesHyphenated names would be processed as if they were two separate names.
Again,this is because of the potential confusion that could occur where part of the hyphenatedname is a marr ied name and the other a birth name.
Thus, surnames uch as ARRO?O-PETERSEN, MAHONEY-RIZZO, KILBURY-MEISNER, and the like should be treated as if thehyphen were a language separator.
Furthermore, in such combinations, the sequenceis often unpredictable.
Some cultures adopt the convention (for women) of birth name-married name (e.g., English, Polish), while others have the opposite order of marr iedname-birth name (e.g., German).
175.3 HomographsA classic problem that faces letter-to-sound algorithms is the existence of homographs.These are words that are spelled the same but have two different pronunciations, usu-ally signaling a difference in form class.
English contains, in its general vocabulary,15 Certain languages, however, have a more open-ended system than those of the familiar Indo-Europeanlanguages.
In Chinese languages, for example, individuals have a wide variety of names which derivefrom the general lexicon.
A female name might be WANG MEI HWA where WANG is the surname,MEI "beautiful' and HWA 'flower'.
Her sister might be WANG MEI YEH "beautiful leaves.
'16 Liu and Haas (1988) point out that the name SMITH occurs 676,080 times for a database of 75 millionhouseholds in the U.S. representing 1% of the total.17 In certain Slavic languages, names function as adjectives and are marked for gender.
In Polish, forexample, the common ame KOWALSKA is the female counterpart of the male name KOWALSKI.270Vitale Algorithm for High Accuracy Name Pronunciationover 300 of these, some of which are high frequency forms.
Examples of this are DE-LIBERATE, ARITHMETIC, REFUSEr PRODUCE, COORDINATE, SOW, BASS, and many others.Modern-day text-to-speech systems do not yet process these automatically.
An evenmore difficult problem faces a proper name pronunciation algorithm.
Whereas onecould, in principle, devise a method for generic text using form class or part of speechto distinguish pairs such as those just mentioned, it is not always possible to predictwhich variant will occur in a proper name.
TM5.4 Free Variation and Cross-Language Variation5.4.1 Homographic Variation and Cross-Language Variation.
Different pronuncia-tions may occur in either free variation or in cross-language variation, with the twooccasionally overlapping.
Free variation occurs when the same last name occurs withtwo or more different pronunciations but these are from the same language group.One person with the name BERNSTEIN may pronounce it \[br'nstaYn\], whereas a secondperson may pronounce it \[br.'nstl~n\].
This is true free variation where typically one pro-nunciation represents something closer to the source language.
In a slightly differenttype of variation, one name may indeed be from a different language group or else thealternation reflects a radical anglicization of the name, e.g., PACE may be pronouncedeither \[pds\] or \[pd~i\].
Stress patterns also vary greatly depending upon the degree ofassimilation into English.
For example, Slavic names show a great deal of variationfrom penultimate stress (which is the canonical stress pattern) to antepenultimate (theassimilated pattern).
E.g., ANDRUSZKIEWICZ could be \[andru~kY6vi~\] or \[andrt~kYevi~\].Often, cues such as orthography may give a hint as to the degree of assimilation.
Ifthe native Slavic phoneme Iv\] is written orthographically as W, for example, it has ahigher chance of retaining the source (i.e.
penultimate) stress pattern than if the samephoneme were written orthographically as V.Cross-language variation causes greater problems in this regard, since names arelisted in the dictionary in only one way.
However, this algorithm is not language-specific but can be used anywhere in the world.
While the entry could be modified,no procedure that would allow for different lexical entries for the same spelling hasbeen implemented.
In any case, names like ROBERT could be \[rdbrt\] or \[rob&\] depend-ing upon whether the name is English or French.
Similarly, names like JULIO, PETER,WALTER, GILES, BERNARD, GUY, RICHARD, JAN, CLAUDE, and hundreds of others havedifferent segmental forms or stress patterns depending upon where they originatefrom and whether the name has been assimilated into English.
One way in which thiscould be handled is by marking these in a dictionary and then using the 'loading"strategy of last name etymology as discussed above (Section 5.1).
Another method issimply to adopt one variant as the default with the others also listed as homographsand marked for language type with the corresponding phonetic equivalents.
Since thedefault language is a settable parameter (Section 3.4), multiple phonetic entries could,in principle, be used.5.5 Loanword Assimilation and Segmental ModificationIt is obvious that the segmental phonetic output of letter-to-sound rules is restrictedto the inventory of allophones of the synthesizer.
That is, an English-based speechsynthesizer should not be expected to make a French uvular \[R\] or a German velarfricative.
Moreover, it would be counterproductive to even attempt o approximate18 Distinguishing non-name homographs automatically could, in principle, be done with a front-endparser, which would provide the syntactic information ecessary to choose one pronunciation or theother.271Computational Linguistics Volume 17, Number 3these sounds, since the listener would not be expecting this and intelligibility of thename would certainly decrease.
For this same reason, even the segmental phonemesof the source language can distract he listener's attention and reduce intelligibility.For example, while the name CARBONE must have penultimate stress to be consideredcorrect, it would be inappropriate ophonemicize the final orthographic vowel as a midfront /e / ,  as would be the case in the target language (i.e., Italian).
This is becausethe assimilation of this and other similar names into English has raised the vowelphonemically to / i /  (and diphthongized it phonetically to \[iy\].
Thus, while CARBONEwould be /karb6ne/ in  Italian, it would be /karb6ni / in  anglophone countries uchas the United States.Furthermore, the different degrees of assimilation can be formally described inan elaboration of the algorithm presented here.
For example, assuming allophones asproduced by a speech synthesizer a e optimized to American English, one could applya number of rules to the name CARBONE as follows:1.
Orthography --* (CARBONE)2.
Phonemicization ~ /karb6ne/3.
Assimilation Rule 1 --+ /karb6ni/4.
Assimilation Rule 2 (optional) ~ /karb6n/Thus, we can place different degrees of assimilation on the target language (i.e.English) using formal (ordered) rules.
This would allow a generic synthesizer's letterto sound (and allophonic) rules the ability to change degree of assimilation i  muchthe same way that we will eventually be able to specify shifts in style and registerwithin text-to-speech systems.6.
Testing and Evaluation6.1 PerformanceThe performance goal of the software developed around this algorithm was real-timeprocessing.
We benchmarked the performance on a Digital Equipment CorporationVax 8800 running VMS V5.1.
A total of 34,337 names were processed in 25 minutesand 27 seconds, or equivalently 22.65 names per second.
After some code optimizationand streamlining of the filter rules, we later ran similar tests using the same databaseson an 33 MHz PC running MS-DOS V5.0.
While these tests were run on the iden-tification portion only, we were able to process everal thousand names per second.Large commercial applications will have similar compute power, and thus real-timeprocessing is not a problem.
It should be noted that many applications do not requirereal-time processing since the processed name and address can be simply stored in aseparate field in the database.
The routines can thus be used to create a database ofphonemicized names by preprocessing the name, storing the phonemic equivalent ofthe name in some field, and sending that field to the synthesizer at some later time.6.2 Pronunciation AccuracyA number of different ests were conducted for accuracy of pronunciation.
Accuracyhere was measured in terms of the level of segmental nd suprasegmental (i.e., stressplacement) output determined by a linguist o be reasonable behavior.
A more elabo-rate (and possibly more practical) criterion for accuracy might include the transcrip-tion (by a linguist) of a number of pronunciation tokens provided by nonlinguists.272Vitale Algorithm for High Accuracy Name PronunciationTable 3Names vs. generic lexical items.Lexical type % Error before % Error after DictionaryAll function words2000 common surnamesComplex poly test828 Single L-group surnames0 0 +31.9 0 +5.1 5.1 -92 6.3 -Our reasoning was that the output should minimally model human behavior.
How-ever, because the algorithm contains more linguistic information than is known by theaverage person, the software has the potential to be more accurate than a person (i.e.,make fewer gross pronunciation errors).
Testing of human vs. computer pronunciationof names from a test database is being conducted independently at the present imewithin the artificial intelligence community (Golding and Rosenbloom 1991) as wellas within the telephone industry.One of the problems we faced is a definition of what constitutes correctness.
Veryoften, more than one pronunciation is acceptable and many readers of this paperhave had their own names pronounced ifferently by other individuals.
Even profes-sional linguists faced with names such as MOUDRY, FUCHS, SOUTO, D'ANGELO, BADKE,DUJMUCH, SMYTHE, and others cannot say definitively whether one pronunciation iscorrect or not (Hochberg et al 1990).
For the purposes of our evaluation, in caseslike these, a pronunciation was accepted if linguists felt that the segmental phonemicoutput and stress placement were reasonable.
Again, another and possibly more re-alistic approach might be to phonemicize a set of names from the pronunciation ofa group of individuals who are not owners of the name.
These pronunciations couldthen be phonemicized by a linguist and correctness could then be evaluated by asimple matching of the majority pronunciation.
In any case, both \[fyuks\] and \[fu6\]were considered correct for FUCHS but \[ffi~iz\] and \[f^ks\] were not; \[smaYO\] and \[smIO\]for SMYTHE but not \[smIOiI; \[diY~njelo\] and \[degnjelo\] for D'ANGELO but not \[daenj61o\]and so on.
Similarly, because of homographic variation (Section 5.4.1) and the attemptto make errors replicate what humans might say, we would accept certain pronunci-ations for names that we knew came from two very different sources as long as onewere reasonable.
For example, \[p6s\] would be an acceptable pronunciation for PACEeven if the first name were Antonio.
In fact, often one cannot say definitively thatone pronunciation or the other is the one used without asking the person who ownsthe name.
Again, with the loading strategy factoring in first name (above), one mightincrease the probability of a reasonable pronunciation.Testing was done with several databases that were not used to compile the tri-grams.
Some degradation was expected when using a new (test) database.
However,as shown in Figure 1, after testing, a new database could be merged with the referencedatabase, and new and more complete trigram statistics calculated.Table 3 shows the error rate with and without a dictionary over different subsetsof a corpus.
The dictionary covered all functors and the 2000 most common surnames.The complex polysyllabic test (see fn.
3) is simply a benchmark for the generic letterto sound rules without use of a dictionary.
The last line of the table suggests theimprovement possible in name pronunciation (in this case, Japanese names were used).Note the degradation i performance (without he name pronunciation software) fromcommon names to Japanese names.273Computational Linguistics Volume 17, Number 3Table 4Database tests - -  no dictionary.Database % Error no ident.
% Error with ident.Reference - set 1 18% 8%Reference - set 2 24% 8%Test - hardcopy 32% 15%Test - softcopy 22% 12%Table 5First, last, and street names.Word type No dictionary DictionaryLast names 12% 7%Street names 24% 7%First names 23% 1%In a second test, we had a subject randomly choose two sets of 100 names fromour reference database and two further sets of 100 names from each of two telephonebooks.
One telephone book was hardcopy from a large region in the East and thesecond was an on-line directory from a large region in the mid-West.
In the case of thehardcopy listings, the data were put on line to be analyzed.
The softcopy was edited toremove unwanted materiaU 9 We included the softcopy database to minimize any bias,conscious or otherwise, that the subject may have had and these names were chosenwith a simple program that pulled out the required number  of names from the namefield.
In spite of the fact that tr igrams tend to be repeated over a database (above), wenevertheless expected some degradation going to new test lists, as the data in Table 4illustrate.
The error rate was calculated with and without the identification algorithmon four databases of 100 names each using no dictionary lookup.Because of the high functional load of dictionary entries (see Section 2), scores wereexpected to be considerably higher when the dictionary lookup module was included.We tested this hypothesis and found that when the dictionary was included in thesoftcopy test-database analysis (above), the error rate was reduced from 12% to 7%.Other tests also indicated that the use of a dictionary cuts the error rate approximatelyin half.Due to the fact that many applications written around this software will require theaccurate pronunciations of first name and street name as well as last name, we decidedto examine the accuracy for each of these categories as well.
The anticipation was thatthe accuracy rate for first names (using a dictionary) would be slightly higher than thatof last names and that the accuracy rate for street names would be slightly lower.
This isbecause of the higher frequency of occurrence of first names (above) as well as the factthat the pronunciation of street names tends to be extremely variable and, like placenames, has been observed to vary between local and non-local populat ion groups.Table 5 indicates the error rates of the first name and street name tests compared withthe last name tests mentioned above, run over the test database with and without adictionary.19 Telephone listings typically contain a variety of information i cluding, inter alia, the telephone numberand street number, demarcation ofupper case (e.g., MC*ADOO) special symbols for unlisted numbersand so on.274Vitale Algorithm for High Accuracy Name PronunciationNote that both street names and first names have much lower accuracy than lastnames without the use of a dictionary.
First names, like functors and irregular verbforms, exhibit unusual behavior in terms of the canonical segmental phonology of thelanguage, e.g., THOMAS, where the first segment is / t /  rather than / (9/ ,  MICHAEL,where orthographic CH, is /k /  and not /~/ ,  and so on.
In the case of street names,many are the same as place names (OTTAWA BLVD), first names (JOYCE ST.), or lastnames (EISENHOWER AVE).
In any event, note that the use of the dictionary with thesename fields is crucial to the success of the algorithm, much more so than in thecase of surnames.
In fact, the non-Anglo-Saxon surnames (LUELLA, LEONARDO, etc.
)are handled quite adequately without use of a dictionary lookup.
In the case of firstnames, the error rate is extremely low since the vast majority of these would be foundin the dictionary.Naturally, the final and most crucial test of accuracy is the overall intelligibility ofthe name, that is, whether an individual on the receiving end of a telephone line (withits reduced bandwidth) can hear, repeat, and correctly transcribe (in normal orthogra-phy) a person's name and address.
These tests and others remain for future research.We set out simply to attempt o improve pronunciation accuracy of proper names bycreating a more intelligent front-end processor and a more complex letter-to-sound ruleset that would take into account he variability of the text to be processed.
Tests indicatethat an algorithm can be successfully implemented to significantly increase accuracyof name pronunciation.
This helps make possible applications in which proper namesare output intelligibly using a speech synthesizer, as well as text-processing functionssuch as the construction of a name dictionary for automatic speech recognition.
Thealgorithm has, in fact, been implemented for speech synthesis and is currently beingused in a commercially available product within the telecommunications i dustry.AcknowledgmentsI would like to thank Patrick Gili, DaveConroy, Bob Curtis, and Tom Levergood ofDigital Equipment Corporation for theirmany ideas and their programmingexpertise, which allowed for thedevelopment of tools that helped determinethe initial feasibility of the algorithm andlater helped improve accuracy of theidentification pass; and Murray Spiegel ofBell Communications Research fornumerous discussions and a profitableexchange of ideas.
I also thank Janine Haleyof CONTEL and Bob Weide of CarnegieMellon University who shared databaseswhich allowed me to test and refine theidentification portion of the algorithm.ReferencesChurch, K. W. (1986).
"Stress assignment inletter to sound rules for speechsynthesis."
In Proceedings, IEEEInternational Conference on Acoustics Speechand Signal Processing 4, pp.
2423-2426.Cole, R. A.; Inouye, J. W. T,; Muthasamy,Y.
K.; and Gopalakrishnan, M.
(1989).
"Language identification with neuralnetworks: A feasibility study."
InProceedings, IEEE Pacific Rim Conference onCommunications, Computers and SignalProcessing.Daly, N. A.
(1987).
Recognition of Words fromTheir Spellings: Integration of MultipleKnowledge Sources.
M.Sc.
Thesis,Massachusetts Institute of Technology.Divay, Michel (1990).
"A written textprocessing expert system for text tophoneme conversion."
In Proceedings,International Conference on Spoken LanguageProcessing (ICSLP).
Kobe, Japan.pp.
853-856.Divay, Michel (1984).
"De l'6crit vers l'oralou contribution a l'6tude des traiternentsdes textes 6crits en vue de leurprononciation sur synth6tiseur de parole.
"Thbse d'Etat, Universit6 de Rennes.Golding, A. R.; and Rosenbloom, P. S.(1991).
"A comparison of anapron withseven other name pronunciationsystems."
Knowledge Systems LaboratoryReport No.
KSL 91-26.
StanfordUniversity.Golding, A. R.; and Rosenbloom, E S.(1989).
"Combining analytical andsimilarity-based CBR."
In Proceedings, 2ndCase-Based Reasoning Workshop.
Pensacola,FL.275Computational Linguistics Volume 17, Number 3Hochberg, J.; Mniszewski, S. M.; Calleja, %;and Papcun, G. J.
(1990).
"What's in aName?
: Last Names as a ComputationalProblem."
Unpublished paper, LosAlamos National Laboratory, Los Alamos,NM.Hunnicutt, S. (1976).
"Phonological rules fora text-to-speech system."
American Journalof Computational Linguistics Microfiche 57.Karhan, C.; Hardzinski, M.; Holinka, V.; andViets, M. (1986).
"Text-to-speech synthesisfor pronouncing names and addresses ina telecommunications service: designingthe user interface."
In Proceedings, VoiceI/0 Systems Applications Conference "85.pp.
51-57.Klatt, D. H. (1987).
"Review oftext-to-speech onversion for English.
"Journal of the Acoustical Society of America82/3.
pp.
737-793.Liu, F. C.; and Haas, L. J.
(1988).
"Syntheticspeech technology for enhancement ofvoice-store-and-forward systems."
InProceedings, American Voice Input/OutputSociety.Macchi, M.; and Spiegel, M. (1990).
"Usinga demisyllable inventory to synthesizenames."
In Proceedings, Speech Tech '90.pp.
208-212.Smith, E. C. (1969).
American Surnames.Rednor, PA: Chilton.Spiegel, M. (1990).
"Speech synthesis fornetwork applications."
In Proceedings,Speech Tech '90.
pp.
347-355.Spiegel, M. (1985).
"Pronouncing surnamesautomatically."
In Proceedings, AmericanVoice Input~Output Society.
pp.
109-132.Spiegel, M.; and Macchi, M.
(1990).
"Synthesis of names by ademisyllable-based speech synthesizer.
"Journal of the American Voice Input/OutputSociety 7, pp.
1-10.Venezky, R. L. (1970).
The Structure ofEnglish Orthography.
The Hague: Mouton.Vitale, A. J.
(1989a).
"Application-driventechnology: automated customer nameand address."
In Proceedings, AmericanVoice Input/Output Society.
NewportBeach, CA.Vitale, A. J.
(1989b).
"The automation ofname and address output as a utility forthe telecommunications industry."
InProceedings, National CommunicationsForum 43(2), pp.
1109-1113.Vitale, A. J.
(1987).
"Engineering speechsystems to meet market needs."
InProceedings, Speech Tech '87.
pp.
149-151.276
