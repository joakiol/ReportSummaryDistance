Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 322?331,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsTowards an Empirically Motivated Typology of Follow-Up Questions:The Role of Dialogue ContextManuel Kirschner and Raffaella BernardiKRDB Centre, Faculty of Computer ScienceFree University of Bozen-Bolzano, Italy{kirschner,bernardi}@inf.unibz.itAbstractA central problem in Interactive Ques-tion Answering (IQA) is how to answerFollow-Up Questions (FU Qs), possiblyby taking advantage of information fromthe dialogue context.
We assume that FUQs can be classified into specific typeswhich determine if and how the correctanswer relates to the preceding dialogue.The main goal of this paper is to proposean empirically motivated typology of FUQs, which we then apply in a practicalIQA setting.
We adopt a supervised ma-chine learning framework that ranks an-swer candidates to FU Qs.
Both the an-swer ranking and the classification of FUQs is done in this framework, based on ahost of measures that include shallow anddeep inter-utterance relations, automati-cally collected dialogue management metainformation, and human annotation.
Weuse Principal Component Analysis (PCA)to integrate these measures.
As a result,we confirm earlier findings about the ben-efit of distinguishing between topic shiftand topic continuation FU Qs.
We thenpresent a typology of FU Qs that is morefine-grained, extracted from the PCA andbased on real dialogue data.
Since all ourmeasures are automatically computable,our results are relevant for IQA systemsdealing with naturally occurring FU Qs.1 IntroductionWhen real users engage in written conversationswith an Interactive Question Answering (IQA)system, they typically do so in a sort of dia-logue rather than asking single shot questions.The questions?
context, i.e., the preceding interac-tions, should be useful for understanding Follow-Up Questions (FU Qs) and helping the systempinpoint the correct answer.
In previous work(Kirschner et al, 2009; Bernardi et al, 2010;Kirschner, 2010), we studied how dialogue con-text should be considered to answer FU Qs.
Wehave used Logistic Regression Models (LRMs),both for learning which aspects of dialogue struc-ture are relevant to answering FU Qs, and for com-paring the accuracy with which the resulting IQAsystems can correctly answer these questions.
Un-like much of the related research in IQA, whichused artificial collections of user questions, ourwork has been based on real user-system dialogueswe collected via a chatbot-inspired help-desk IQAsystem deployed on the web site of our UniversityLibrary.Previously, our experiments used a selectionof shallow (Kirschner et al, 2009) and deep(Bernardi et al, 2010) features, all of which de-scribe specific relations holding between two ut-terances (i.e., user questions or system answers).In this paper we present additional features derivedfrom automatically collected dialogue meta-datafrom our chatbot?s dialogue management com-ponent.
We use Principal Component Analysis(PCA) to combine the benefits of all these infor-mation sources, as opposed to using only certainhand-selected features as in our previous work.The main goal of this paper is to learn from dataa new typology of FU Qs; we then compare it to anexisting typology based on hand-annotated FU Qtypes, as proposed in the literature.
We show howthis new typology is effective for finding the cor-rect answer to a FU Q.
We produce this typologyby analyzing the main components of the PCA.This paper presents two main results.
A new,empirically motivated typology of FU Qs confirmsearlier results about the practical benefit of dis-tinguishing between topic continuation and topicshift FU Qs, which are typically based on handannotation.
We then show that we can do withoutsuch hand annotations, in that our fully automatic,322on-line measures ?
which include automaticallycollected dialogue meta-data from our chatbot?sdialogue manager ?
lead to better performance inidentifying correct answers to FU Qs.In the remainder of this paper, we first reviewrelevant previous work concerning FU Q typolo-gies in IQA.
Section 3 then introduces our col-lection of realistic IQA dialogues which we willuse in all our experiments; the section includesdescriptions of meta information in the form ofdialogue management features and post-hoc hu-man annotations.
In Section 4 we introduce ourexperimental framework, based on inter-utterancefeatures and LRMs.
Our experimental results arepresented in Section 5, which is followed by ourconclusions.2 Related workMuch of previous work on dialogue processing inthe domain of contextual or interactive QuestionAnswering (QA) (Bertomeu, 2008; van Schootenet al, 2009; Chai and Jin, 2004; Yang et al, 2006)has been based on (semi-)artificially devised setsof context questions.
However, the importance ofevaluating IQA against real user questions and theneed to consider preceding system answers has al-ready been emphasized (Bernardi and Kirschner,2010).
The corpus of dialogues we deal with con-sists of real logs in which actual library users wereconversing (by typing) with a chat-bot to obtaininformation in a help-desk scenario.
(Yang et al, 2006) showed that shallow simi-larity features between a FU Q and the precedingutterances are useful to determine whether the FUQ is a continuation of the on-going topic (?topiccontinuation?
), or it is a ?topic shift?.
The authorsshowed that recognizing these two basic types ofFU Qs is important for deciding which contextfusion strategies to employ for retrieving the an-swer to the FU Q.
(Kirschner et al, 2009) showedhow shallow measures of lexical similarity be-tween questions and answers in IQA dialogues areas effective as manual annotations for distinguish-ing between these basic FU Q types.
However,that earlier work was based on a much smaller setof dialogue data than we use in this paper, mak-ing for statistically weaker results.
(Bernardi etal., 2010) improved on this approach by increas-ing the data set, and adding ?deep?
features thatquantify text coherence based on different theoriesof dialogue and discourse structure.
However, FUQ classification was performed using either single,hand-selected shallow or deep features, or a hand-selected combination of one shallow and one deepfeature.
In this paper, we adopt the most promisingmeasures of similarity and coherence from the twoaforementioned papers, add new features basedon automatically collected dialogue managementmeta-data, and combine all this information viaPrincipal Component Analysis (PCA).
By usingPCA, we circumvent the theoretical problem thatpotentially multicollinear features pose to our sta-tistical models, and at the same time we have aconvenient means for inducing a new typology ofFU Qs from our data, by analyzing the composi-tion of the principal components of the PCA.More fine-grained typologies of FU Qs havebeen suggested, and different processing strategieshave been proposed for the identified types.
Inthis paper, we start from our own manual annota-tion of FU Qs into four basic classes, as suggestedby the aforementioned literature (Bertomeu, 2008;van Schooten et al, 2009; Sun and Chai, 2007).We then compare it to our new PCA-based FU Qtypology.3 DataWe now introduce the set of IQA dialogue datawhich we will use in our experiments.
For the pur-pose of calculating inter-utterance features withinthese user-system interactions ?
as described inSection 4.4 ?
we propose to represent utterancesin terms of dialogue snippets.
A dialogue snip-pet, or snippet for short, contains a FU Q, alongwith a 2-utterance window of the preceding dia-logue context.
In this paper we use a supervisedmachine learning approach for evaluating the cor-rectness of a particular answer to a FU Q; we thusrepresent also the answer candidate as part of thesnippet.
Introducing the naming convention weuse throughout this paper, a snippet consists of thefollowing four successive utterances: Q1, A1, Q2,and A2.
The FU Q is thus referred to as Q2.The data consists of 1,522 snippets of 4-turnhuman-machine interactions in English: users askquestions and the system answers them.
The dataset was collected via the Bolzano Bot (BoB) webapplication that has been working as an on-linevirtual help desk for the users of our UniversityLibrary since October 2008.1 The snippets were1www.unibz.it/library.
More information on theBoB dialogue corpus: bob.iqa-dialogues.net.323extracted from 916 users?
interactions.Table 3 shows three example dialogue snippetswith correct A1 and A2; these examples are meantto give an idea of the general shape of the BoBdialogue data.
In the third example snippet, A1and A2 actually contain clickable hyperlinks thatopen an external web-site.
We represent them hereas dots in parentheses.Our library domain experts manually checkedthat each FU Q was either correctly answered inthe first place by BoB, or they corrected BoB?s an-swer by hand, by assigning to it the correct answerfrom BoB?s answer repository.
In this way, the di-alogue data contain 1,522 FU Qs, along with theirrespective contexts (Q1 and A1) and their correctanswers (A2).
The resulting set of correct A2scontains 306 unique answers.2The BoB dialogue data also contain two levelsof meta information that we will use in this paper.On the one hand, we have automatically collecteddialogue meta-data from BoB?s dialogue managerthat describe the internal state of the BoB systemwhen a FU Q was asked; this information is de-scribed in Section 4.2.
On the other hand, 417 ofthe 1,522 FU Qs were hand-annotated regardingFU Q type, as described in Section 4.3.4 ModelOur goal is, given a FU Q (Q2 in our dialoguesnippets), to pick the best answer from the fixedcandidate set of 306 A2s, by assigning a score toeach candidate, and ranking them by this score.Different FU Q types might require different an-swer picking strategies.
Thus, we specify bothA2 (identification) features, aiming at selecting thecorrect A2 among candidates, and context (iden-tification) features, that aim at characterizing thecontext.
The A2 identification features measurethe similarity or coherence between an utterancein the context (e.g., Q2) and a candidate A2.
Con-text features measure the similarity or coherencebetween pairs of utterances in the context (e.g.,Q1 and Q2).
They do not provide direct infor-mation about A2, but might cue a special context(say, an instance of topic shift) where we shouldpay more attention to different A2 identificationfeatures (say, less attention to the relation between2Many of the 306 answer candidates overlap semantically.This is problematic, given that our evaluation approach as-sumes exactly one candidate to be correct, while all other 305answers to be wrong.
In this paper, we shall accept this fact,for the merit of simplicity.Q2 and A2, and more to the one between A1 andA2).We implement these ideas by estimating a gen-eralized linear model from training data to predictthe probability that a certain A2 is correct giventhe context.
In this model, we enter A2 features asmain effects, and context features in interactionswith the former, allowing for differential weightassignment to the same A2 features depending onthe values of the context features.4.1 Logistic RegressionLogistic regression models (LRMs) are general-ized linear models that describe the relationshipbetween features (independent variables) and a bi-nary outcome (Agresti, 2002).
LRMs are closelyrelated to Maximum Entropy models, which haveperformed well in many NLP tasks.
A major ad-vantage of using logistic regression as a super-vised machine learning framework (as opposed toother, possibly better performing approaches) isthat the learned coefficients are easy to interpretand assess in terms of their statistical significance.The logistic regression equations specify the prob-ability for a particular answer candidate A2 beingcorrect, depending on the ?
coefficients (repre-senting the contribution of each feature to the totalanswer correctness score), and the feature valuesx1, .
.
.
, xk.
In our setting, we are only interestedin the rank of each A2 among all answer candi-dates, which can be easily and efficiently calcu-lated through the linear part of the LRM: score= ?1x1 + .
.
.+ ?kxk.FU Q typology is implicitly modeled by inter-action terms, given by the product of an A2 fea-ture and a context feature.
An interaction termprovides an extra ?
to assign a differential weightto an A2 feature depending on the value(s) of acontext feature.
In the simplest case of interactionwith a binary 0-1 feature, the interaction ?
weightis only added when the binary feature has the 1-value.As described in (Kirschner, 2010), we esti-mate the model parameters (the beta coefficients?1, .
.
.
, ?k) using maximum likelihood estima-tion.
Moreover, we put each model we constructunder trial by using an iterative backward elimina-tion procedure that keeps removing the least sig-nificant predictor from the model until a specificstopping criterion that takes into account the sta-tistical goodness of fit is satisfied.
All the results324we report below are obtained with models that un-derwent this trimming procedure.There is a potential pitfall when using multi-ple regression models such as LRMs with multi-collinear predictors, i.e., predictors that are inter-correlated, such as our alternative implementa-tions of inter-utterance string similarity.
In suchsituations, the model may not give valid resultsabout the importance of the individual predictors.In this paper, we use PCA to circumvent the prob-lem by combining potentially multicollinear pre-dictors to completely uncorrelated PC-based pre-dictors.In the following three sections, we describe thedifferent types of information that are the basis forour features.4.2 BoB dialogue management meta-dataWhen BoB interacts with a user, it keeps log filesof the IQA dialogue.
First of all, these logs in-clude a timed protocol of user input and BoB?sresponses: the user and system utterances are theliteral part of the information.
On the other hand,BoB also logs two dimensions of meta informa-tion, both of which are based on BoB?s internalstatus of its dialogue management routine.
Thisroutine is based on a main initiative-response loop,mapping user input to some canned-text answer,where the user input should be matched by (atleast) one of a set of hand-devised regular expres-sion question patterns.Sub-dialogues Whenever BoB asks a system-initiated question, the main loop is suspended, andthe system goes into a sub-dialogue state, where itwaits for a specific response from the user ?
typ-ically a short answer indicating the user?s choiceabout one of the options suggested by BoB.
Thenext user input is then matched against a smallnumber of regular expression patterns specificallydesigned for the particular system-intiative ques-tion at hand.
Depending on this user input, thesub-dialogue can:Continue: the user input matched one of theregular expression patterns intended to capturepossible user choicesBreak: the user broke the sub-dialogue by en-tering something unforeseen, e.g., a new questionThe first two parts of Table 4 give an overviewof the statistics of BoB?s dialogue management-based meta information concerned with sub-dialogue status.
Besides continue and break, forQ1 we consider also a third, very common casethat a user question was not uttered in a sub-dialogue setting at all.
Note that we excluded fromour data collection all those cases where Q2 con-tinues a sub-dialogue from our collection of IQAdialogues, since we do not consider such Q2s asFU Qs, as they are highly constrained by the pre-vious dialogue.Apology responses The third part of Table 4gives statistics of whether a particular system re-sponse A1 was an apology message stating thatBoB did not understand the user?s input, i.e., noneof BoB?s question patterns matched the user ques-tion.4.3 Manual dialogue annotationWe now turn to the meta information in BoB dia-logue data that stems from post-hoc human anno-tation.
For a portion of BoB?s log files, we addedup to two additional levels of meta information, byannotating the log files after they were collected.3The following paragraphs explain the individ-ual levels of annotation by giving the correspond-ing annotator instructions; Table 5 contains anoverview of the corresponding features.
First ofall, we annotated FU Qs with their FU Q type.Our choice of the particular four levels of theFUQtype feature was influenced by the followingliterature literature: from (De Boni and Manand-har, 2005) and (Yang et al, 2006) we adopted thedistinction between topic shift and topic continua-tion, while from (Bertomeu et al, 2006) we tookthe notions of rephrases and context dependency.Our annotation scheme is described in Figure 1;note that topic continuations have three sub-types,which are spelled out below.FUQtype = isTopicShift: marks a FU Qas a topic shift based on an intuitive notion ofwhether the FU Q ?switches to something com-pletely different?.FUQtype = isRephrase: marks whetherthe FU Q is an attempt to re-formulate the samequestion.
The FU Q could be a literal repetition ofthe previous question, or it could be a rephrasing.FUQtype = isContextDepentFUQ:marks whether the FU Q needs to be consid-ered along with some information provided by3All annotations were performed by either one of the au-thors.325the dialogue context in order to be correctlyunderstood.FUQtype = isFullySpecifiedFUQ:marks whether the FU Q does not need anyinformation from the dialogue context in order tobe correctly understood.The second level of hand-annotation concerns amanual check of the correctness of A1.
It is avail-able for 1,179 of our 1,522 snippets.A1.isAnswer.correct: marks whether thesystem response is correct for the given question.A1.isApology.correct: marks whetherBoB?s apology message is correct for the givenquestion.4.4 Shallow/deep inter-utterance relationsWe exploit shallow features, which measure thesimilarity between two utterances within a snip-pet, and deep features, which encode coherencebetween two utterances based on linguistic the-ory.
For each feature we will use names encodingthe utterances involved; e.g., distsim.A1.Q2stands for the Distributional Similarity feature cal-culated between A1 and Q2.Shallow features The detailed description of allthe shallow features we used in our experimentscan be found in (Kirschner et al, 2009).
The in-tuition is that a high similarity between Q and Atends to indicate a correct answer, while in thecase of high similarity between the dialogue con-text and the FU Q, it indicates a ?topic continua-tion?
FU Q (as opposed to a ?topic shift?
FU Q),and thus helps discriminating these two classes ofFU Qs.Lexical Similarity (lexsim): Iftwo utterances share some terms, they are simi-lar; the more discriminative the terms they share,the more similar the utterances.
Implements a TF-IDF-based similarity metric.
DistributionalSimilarity (distsim.svd): Two utter-ances are similar not only if they share the sameterms, but also if they share similar terms (e.g.,book and journal).
Term similarity is estimatedon a corpus, by representing each content word(noun, verb, adjective) as a vector that recordsits corpus co-occurrence with other content wordswithin a 5-word span.
Action sequence(action): Based on the notion that in our help-desk setting we are dealing with task-based dia-logues, which revolve around library-related ac-tions (e.g., ?borrow?, ?search?).
The action fea-ture indicates whether two utterances contain thesame action.Deep features These features encode differenttheories of discourse and dialogue coherence.
Re-fer to (Bernardi et al, 2010) for a full descriptionof all deep features we used experimentally, alongwith more details on the underlying linguistic the-ories, and our implementation choices for thesefeatures.We introduce a four-level feature, center,that encodes the four transitions holding betweenadjacent utterances that Centering Theory de-scribes (Brennan et al, 1987; Grosz et al, 1995).Somewhat differently from that classic theory,(Sun and Chai, 2007) define the transitions de-pending on whether both the head and the modi-fier of the Noun Phrases (NP) representing the pre-ferred centers4 are continued (cont) or switched(rough shift: roughSh) betweenQ1 andQ2.
Theremaining two transitions are defined in similarterms.4.5 PCA-based context classification featuresPrincipal Component Analysis (PCA) (Manly,2004) is a statistical technique for finding patternsin high-dimensional data, or for reducing their di-mensionality.
Intuitively, PCA rotates the axes ofthe original data dimensions in such a way thatfew of the new axes already cover a large portionof the variation in the data.
These few new axesare represented by the so-called principal compo-nents (PCs).
We employ this technique as a toolfor combining a multitude of potentially multi-collinear predictors for context classification, i.e.,all predictors that involve Q2 and some precedingutterance.
In our experiments we will also want tolook at the correlations of each of the top PCs withthe original context classification features; thesecorrelations are called loadings in PCA.
We exper-iment with the following three versions of PCA:PCAA: without BoB dialogue managementmeta-data features PCA performed over allcontext classification features of the shallow anddeep types described in Section 4.4.4Centers are noun phrases.
The syntactic structure of anoun phrase comprises a head noun, and possibly a modi-fier, e.g., an adjective.
We use a related approach, describedin (Ratkovic, 2009), to identify the preferred center of eachquestion.326PCAB: with BoB dialogue management meta-data features PCAA plus BoB?s dialogue-management meta-data features (Section 4.2).PCAC: with BoB dialogue management meta-data features and manual A1 correctness checkPCAB plus additional manual annotation of A1correctness (Section 4.3).5 EvaluationWe employ a standard 10-fold cross-validationscheme for splitting training and prediction data.We assess our LRMs by comparing the ranks thatthe models assign to the gold-standard correct A2candidate (i.e., the single A2 that our library do-main experts had marked as correct for each of the1,522 FU Qs).
To determine whether differencesinA2 ranking performance are significant, we con-sult both the paired t-test and the Wilcoxon signedrank test about the difference of the 1,522 ranks.5.1 Approximating hand-annotated FU Qtypes with PCA-based featuresWe begin the evaluation of our approach by ex-ploring the value of the hand-annotation-based FUQ type as cues for expressing the relevance andtopical relatedness of that particular FU Q?s dia-logue context.For this purpose, we use the subset of 417dialogue snippets which we annotated with theFUQtype feature described in the first half of Ta-ble 5.
Figure 1 depicts our FU Q type taxonomy,and the distribution of the four types in our data.First of all, for this hand-annotated subset of di-alogue snippets, we try to improve the A2 rankingresults of a ?main effects only?
baseline LRM,i.e., a model which does not distinguish betweendifferent FU Q types.
This baseline model wasproposed in earlier work (Kirschner et al, 2009).We tried the following features as interactionterm(s) in our models, one after the other: whetherthe hand-annotated FUQType feature indicates atopic shift or not; the full four levels of FUQType;a linear combination of the top five PCs of each ofthe three PCA feature sets introduced in Section4.5.
After applying our automatic predictor elimi-nation routine described in Section 4.1 and evalu-ating the A2 ranking results of each of these mod-els, none of the interactive models significantlyoutperform our baseline.
PCA-based context clas-sification using only fully automatic BoB meta in-formation features (PCAB in Section 4.5) resultsin the largest improvement over baseline; however,this improvement does not reach statistical signifi-cance, most likely due to the small data set of only417 cases.
Still, using the hand-annotated FU Qtype feature FUQType, we can visualize how thetop PCs cluster the 417 FU Qs, and how this clus-tering mirrors some of the distinctions of manuallyassigned FU Q types: see Figure 2.
E.g., plottingthe FU Qs along their PC1 and PC2 values seemsto mimic the annotator?s distinction between topicshift FU Qs and the other three FU Q types.
Theother pairs of PCs also appear to show certain clus-ters.
Overall, the automatic context classificationfeatures that served as input to the PCA are usefulfor describing different context-related behaviorsof different FU Qs.5.2 Optimizing A2 ranking scores usingPCA-based featuresHaving shown the usefulness (in terms of assign-ing high ranks to the gold-standard correct A2) ofFU Q classification via a PCA-based combinationof purely automatic context classification features,we can now consider the full sample of 1,522 di-alogue snippets described in Section 3, for whichwe do not in general possess manual FU Q typeannotations.The first row of Table 1 shows the A2 rankingresults of our baseline LRM.
In the remainder ofthe table, we compare this baseline model to threedifferent models which use a linear combinationof different versions of the top five PCs as interac-tion terms.
The three versions (A, B and C) wereintroduced in Section 4.5.5.3 Analysis of PC-based context featuresThe main goal of this paper is to devise an empiri-cally motivated typology of FU Qs, under consid-eration of automatically collected dialogue man-agement meta information.
We then want to showhow this new typology is effective for finding thecorrect answer to a specific FU Q, in that for thegiven FU Q it indicates the relevance and top-ical relatedness of the question?s particular dia-logue context.
In Section 5.2 we have seen howall PCA-based context classification features per-form clearly better than a non-interactive baselinemodel; more specifically, the top five PCs fromthe PCAB scheme yield significantly better A2ranking results than the PCAA scheme which doesnot consider BoB dialogue management meta-datafeatures.
Based on these results, we now look in327Model ID Interaction terms Mean rank Median rank Standard p (Paired p (Wilcoxoncorrect A2 correct A2 dev.
t-test) signed rank)baseline none 48.72 14 69.35PCAA PC1 + .
.
.+ PC5 44.25 12 64.58 < 0.0001 < 0.0001PCAB PC1 + .
.
.+ PC5 42.72 12 62.53 0.0006 0.0087PCAC PC1 + .
.
.+ PC5 42.87 12 62.94 not sig.
not sig.Table 1: Improving ranking of correct A2 (out of 306 answer candidates) with different PCA-basedinteraction terms.
Significance tests of rank differences wrt.
result in preceding row.more detail at the relevance of the top five PC fea-tures in PCAB , and at their most important load-ings, i.e., the original context classification fea-tures that are most highly correlated with the valueof each particular PC.
After running our predic-tor elimination routine, the corresponding LRMhas kept three of these five top PCs as interactionterms: PC1, PC2 and PC5.
Table 2 describes thetop three positive and top three negative loadingsof these PCs.
The table also shows how in modelPCAB , each of the interaction terms correspond-ing to the three PCs influences the score that is cal-culated for everyA2 candidate, either positively ornegatively.Interpreting the results of Table 2 on a high,dialogue-specific level, we draw the followingconclusions:PC1 seems to capture a rather general distinc-tion of topic shift versus topic continuation.
AFU Q with high lexical similarity to the preced-ing utterances (i.e., a ?topic continuation?)
shouldpreferably get an A2 with higher lexical similar-ity with respect to both A1 and Q2.
In this con-text, ?topic shift?
is partly described by a featurefrom Centering Theory, and two of BoB?s dia-logue management meta-data features.PC2 shows relatively weak positive correlationswith any context classification features.
On thenegative end, PC2 seems to describe a class of FUQs that are uttered after a Q1 that did neither con-tinue nor exit a sub-dialogue.
Also,A1 was a regu-lar system answer (as opposed to an apology mes-sage by BoB).
Such FU Qs can thus be interpretedas ?single shot?
questions that a user poses aftertheir previous question was already dealt with inA1.
Because of the negative loadings, the value ofPC2 becomes negative, resulting in the avoidanceof any A2 that is highly similar to the precedingA1.PC5 distinguishes FU Qs that are mostly relatedto the previous answer from those that are morerelated to the previous question.
Depending onwhether PC5 turns positive or negative, A2s arepreferred that are more similar to A1 or Q2, re-spectively.
Q1.Q2 similarity is determined by bothlexical similarity and Centering Theory features.6 ConclusionIn this paper we have experimentally explored theproblem of FU Q types and their correspondinganswer identification strategies.
The first result isthat our hand-annotated FU Q types did not sig-nificantly improveQ2 answering performance (forthe annotated sub-set of 417 snippets).
We at-tribute this negative result in part to the difficultyof the 4-level FU Q type annotation task.
On theother hand, we believe it is encouraging that withpurely automatic features for context classifica-tion, combined through PCA, we significantly out-performed our baseline.
Adding BoB?s dialoguemanagement meta information ?
which is also au-tomatically available when using our dialogue col-lection scheme ?
for context classification helpedimprove the scores even further.
We analyzed thetop loadings of three PCs that our best-performingLRM uses for FU Q type classification.
We usedPCA both for circumventing the problem of mul-ticollinear predictors in LRM, and as a diagnostictool to analyze the most important components ofautomatically combined FU Q classification fea-tures.
Finally, a potentially difficult and cumber-some manual annotation of the correctness of theprevious system answer A1 did not improve A2ranking performance.ReferencesAlan Agresti.
2002.
Categorical Data Analysis.Wiley-Interscience, New York.Raffaella Bernardi and Manuel Kirschner.
2010.
From328LOADINGSPC1 PC2 PC50.33 distsim.Q1.Q2 0.05 Q1.bob.contSubdial 0.45 distsim.A1.Q20.26 distsim.A1.Q2 0.04 Q2.center.roughSh 0.31 A1.bob.isApology0.26 action.Q1.Q2 0.02 Q2.bob.breakSubdial 0.29 lexsim.A1.Q2.........?0.13 A1.bob.isApology ?0.22 A1.bob.isAnswer ?0.18 lexsim.Q1.Q2?0.15 Q2.bob.noSubdial ?0.30 Q2.bob.noSubdial ?0.23 Q2.center.cont?0.22 Q2.center.roughSh ?0.31 Q1.bob.noSubdial ?0.26 A1.bob.isAnswerINFLUENCE ON A2 SELECTION IN MODEL PCABpos for each A2 similar to Q2 pos for each A2 similar to A1 pos for each A2 similar to A1pos for each A2 similar to A1 neg for each A2 similar to Q2Table 2: Strongest loadings for the three PCs retained as interaction terms in Model PCAB , and indicationof each PC?s positive/negative influence on lexical similarity-based A2 selection featuresartificial questions to real user interaction logs: Realchallenges for interactive question answering sys-tems.
In Proc.
of Workshop on Web Logs and Ques-tion Answering (WLQA?10), Valletta, Malta.Raffaella Bernardi, Manuel Kirschner, and ZoranaRatkovic.
2010.
Context fusion: The role of dis-course structure and centering theory.
In Proceed-ings of the Seventh conference on International Lan-guage Resources and Evaluation (LREC?10), Val-letta, Malta.
European Language Resources Associ-ation (ELRA).Nu?ria Bertomeu, Hans Uszkoreit, Anette Frank, Hans-Ulrich Krieger, and Brigitte Jo?rg.
2006.
Contextualphenomena and thematic relations in database QAdialogues.
In Proc.
of the Interactive Question An-swering Workshop at HLT-NAACL 2006, pages 1?8,New York, NY.Nuria Bertomeu.
2008.
A Memory and Attention-Based Approach to Fragment Resolution and its Ap-plication in a Question Answering System.
Ph.D.thesis, Department of Computational Linguistics,Saarland University.Susan E. Brennan, Marilyn W. Friedman, and Carl J.Pollard.
1987.
A centering approach to pronouns.In Proceedings of the 25th annual meeting on Asso-ciation for Computational Linguistics, pages 155?162, Stanford, California.Joyce Y. Chai and Rong Jin.
2004.
Discourse structurefor context question answering.
In Proc.
of the HLT-NAACL 2004 Workshop on Pragmatics in QuestionAnswering, Boston, MA.Marco De Boni and Suresh Manandhar.
2005.
Im-plementing clarification dialogues in open domainquestion answering.
Journal of Natural LanguageEngineering, 11(4):343?361.Barbara J. Grosz, Aravind K. Joshi, and Scott Wein-stein.
1995.
Centering: A framework for model-ing the local coherence of discourse.
ComputationalLinguistics, 21(2):203?225.Manuel Kirschner, Raffaella Bernardi, Marco Baroni,and Le Thanh Dinh.
2009.
Analyzing InteractiveQA dialogues using Logistic Regression Models.
InProc.
of XIth International Conference of the ItalianAssociation for Artificial Intelligence (AI*IA), Reg-gio Emilia, Italy.Manuel Kirschner.
2010.
The Structure of RealUser-System Dialogues in Interactive Question An-swering.
Ph.D. thesis, Free University of Bozen-Bolzano, Italy.Bryan F. J. Manly.
2004.
Multivariate StatisticalMethods: A Primer.
Chapman & Hall/CRC, 3rdedition.Zorana Ratkovic.
2009.
Deep analysis in iqa: evalua-tion on real users?
dialogues.
Master?s thesis, Euro-pean Masters Program in Language and Communi-cation Technologies.Mingyu Sun and Joyce Y. Chai.
2007.
Discourse pro-cessing for context question answering based on lin-guistic knowledge.
Know.-Based Syst., 20(6):511?526.Boris van Schooten, R. op den Akker, R. Rosset,O.
Galibert, A. Max, and G. Illouz.
2009.
Follow-up question handling in the IMIX and Ritel systems:A comparative study.
Journal of Natural LanguageEngineering, 15(1):97?118.Fan Yang, Junlan Feng, and Giuseppe Di Fabbrizio.2006.
A data driven approach to relevancy recogni-tion for contextual question answering.
In Proc.
ofthe Interactive Question Answering Workshop atHLT-NAACL 2006, pages 33?40, New York City,NY.329Q1 where in the library can i find booksA1 Most of our holdings are accessible in the open-shelves area.
In the repository we only keepsome older volumes of journals or the outsize stuff.Q2 shelf markA2 Shelf marks are a combination of letters and numbers, which exactly define the location of abook in a Library.
If you find a book or a journal in the catalogue, you also see the shelf mark.The shelf marks of the University Library consist of an alphanumeric code (e.g.
ES 560 K19).Would you like to know how you search them?Q1 When can I return a book?A1 Books and other media can be consigned at the information desk during the regular openinghours of the Library.
You can also leave them at the book drop located in front of the mainentrance of the university building - 24 hours a day.Q2 I want to read the newspaper on the computerA2 If you haven?t got a Library Card you can visit the Library to read books, journals or newspapers.If you want to borrow something or use the other services we offer you should get a Library Card.Do you want to know how it works?Q1 i need the opacA1 Here (.
.
. )
is the page with our OPAC for you.
You can search the complete holdings of theLibrary.Q2 where is the advisory serviceA2 The University?s Advisory Service provides an information service for prospective students whowould like to know more about which degree course to study.
It also provides a support servicefor enrolled students during their entire time at the University.
You can get further informationfrom this (.
.
. )
site.Table 3: Example dialogue snippets with correctly identified A2Feature name Freq.
DescriptionQ1.bob.contSubdial 7.6% Q1 continues system-initiated sub-dialogueQ1.bob.breakSubdial 9.6% Q1 breaks out of system-initiated sub-dialogueQ1.bob.noSubdial 82.9% BoB not in sub-dialogue mode when Q1 was utteredQ2.bob.breakSubdial 13.6% Q2 breaks out of system-initiated sub-dialogueQ2.bob.noSubdial 86.4% BoB not in sub-dialogue mode when Q2 was utteredA1.bob.isAnswer 75.6% A1 is regular answer retrieved by BoBA1.bob.isApology 24.4% A1 is apology message: BoB did not understandTable 4: BoB dialogue management meta information.
Proportions out of those 1,441 of total 1,522snippets for which this information was logged.Feature name Freq.
DescriptionFUQtype=isTopicShift 40.0% (of 417) Q2 is topic shiftFUQtype=isRephrase 19.2% (of 417) Q2 is rephrasing of Q1FUQtype=isContextDepentFUQ 6.5% (of 417) Q2 is context dependentFUQtype=isFullySpecifiedFUQ 34.3% (of 417) Q2 is not context dependentA1.isAnswer.correct 66.5% (of 1,179) BoB?s regular answer A1 is correctA1.isAnswer.false 19.0% (of 1,179) BoB?s regular answer A1 is falseA1.isApology.correct 1.3% (of 1,179) BoB?s apology message A1 is correctA1.isApology.false 13.2% (of 1,179) BoB?s apology message A1 is falseTable 5: Manual annotation meta information.
Proportions out of those sub-sets of total 1,522 snippetswith available annotation.330TopiccontinuationTopic shiftRelated/salienttransitionFU QRephraseContext-dependentFullyspecified1438025027170417167Figure 1: Manual FU Q type annotation scheme, with counts of FU Q typesScatter Plot MatrixPC12462 4 6-4-20-4 -2 0PC22462 4 6-4-20-4 -2 0PC30240 2 4-6-4-2-6 -4 -2PC42462 4 6-202-2 0 2PC50240 2 4-4-20-4 -2 0FU Q types in 'context classification features' spaceisContextDependentisFullySpecifiedisRephraseisTopicShiftFigure 2: Distribution of hand-annotated FU Q types in PC-based feature space (PCAB)331
