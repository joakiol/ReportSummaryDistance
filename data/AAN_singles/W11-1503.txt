Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 19?23,Portland, OR, USA, 24 June 2011. c?2011 Association for Computational LinguisticsEvaluating an ?off-the-shelf?
POS-tagger on Early Modern German textSilke Scheible, Richard J. Whitt, Martin Durrell and Paul BennettSchool of Languages, Linguistics, and CulturesUniversity of ManchesterSilke.Scheible, Richard.Whitt@manchester.ac.ukMartin.Durrell, Paul.Bennett@manchester.ac.ukAbstractThe goal of this study is to evaluate an ?off-the-shelf?
POS-tagger for modern German onhistorical data from the Early Modern period(1650-1800).
With no specialised tagger avail-able for this particular stage of the language,our findings will be of particular interest tosmaller, humanities-based projects wishing toadd POS annotations to their historical databut which lack the means or resources to traina POS tagger themselves.
Our study assessesthe effects of spelling variation on the perfor-mance of the tagger, and investigates to whatextent tagger performance can be improved byusing ?normalised?
input, where spelling vari-ants in the corpus are standardised to a mod-ern form.
Our findings show that adding sucha normalisation layer improves tagger perfor-mance considerably.1 IntroductionThe work described in this paper is part of a largerinvestigation whose goal is to create a representativecorpus of Early Modern German from 1650-1800.The GerManC corpus, which is due to be completedthis summer, was developed to allow for compara-tive studies of the development and standardisationof English and German in the 17th and 18th cen-turies.
In order to facilitate corpus-linguistic inves-tigations, one of the major goals of the project isto annotate the corpus with POS tags.
However,no specialised tools are yet available for process-ing data from this period.
The goal of this study istherefore to evaluate the performance of an ?off-the-shelf?
POS-tagger for modern German on data fromthe Early Modern period, in order to assess if mod-ern tools are suitable for a semi-automatic approach,and how much manual post-processing work wouldbe necessary to obtain gold standard POS annota-tions.We report on our results of running the TreeTag-ger (Schmid, 1994) on a subcorpus of GerManCcontaining over 50,000 tokens of text annotated withgold standard POS tags.
This subcorpus is the firstresource of its kind for this variant of German, anddue to its complex structure it represents an ideal testbed for evaluating and adapting existing NLP toolson data from the Early Modern period.
The studydescribed in this paper represents a first step towardsthis goal.
Furthermore, as spelling variants in ourcorpus have been manually normalised to a modernstandard, this paper also aims to explore the extentto which tagger performance is affected by spellingvariation, and to what degree performance can beimproved by using ?normalised?
input.
Our findingspromise to be of considerable interest to other cur-rent corpus-based projects of earlier periods of Ger-man (Jurish, 2010; Fasshauer, 2011; Dipper, 2010).Before presenting the results in Section 4, we de-scribe the corpus design (Section 2), and the prepro-cessing steps necessary to create the gold standardannotations, including adaptations to the POS tagset(Section 3).2 Corpus designIn order to be as representative of Early Modern Ger-man as possible, the GerManC corpus design con-siders three different levels.
First, the corpus in-cludes a range of text types: four orally-oriented19genres (dramas, newspapers, letters, and sermons),and four print-oriented ones (narrative prose, andhumanities, scientific, and legal texts).
Secondly, inorder to enable historical developments to be traced,the period is divided into three fifty year sections(1650-1700, 1700-1750, and 1750-1800).
Finally,the corpus also aims to be representative with re-spect to region, including five broad areas: NorthGerman, West Central, East Central, West Upper(including Switzerland), and East Upper German(including Austria).
Three extracts of around 2000words were selected per genre, period, and region,yielding a corpus size of nearly a million words.The experiments described in this paper were car-ried out on a manually annotated gold standard sub-corpus of GerManC, GerManC-GS.
The subcorpuswas developed to enable an assessment of the suit-ability of existing NLP tools on historical data, witha view to adapting them to improve their perfor-mance.
For this reason, GerManC-GS aims to be asrepresentative of the main corpus as possible.
How-ever, to remain manageable in terms of annotationtimes and cost, the subcorpus only considers twoof the three corpus variables, ?genre?
and ?time?, asthey alone were found to display as much if not morevariation than ?region?.
GerManC-GS thus includestexts from the North German region, with one sam-ple file per genre and time period.
The corpus con-tains 57,845 tokens in total, and was annotated withgold standard POS tags, lemmas, and normalisedword forms (Scheible et al, to appear).3 Creating the gold standard annotationsThis section provides an overview of the preprocess-ing work necessary to obtain the gold standard an-notations in GerManC-GS.
We used the GATE plat-form to produce the initial annotations, which facil-itates automatic as well as manual annotation (Cun-ningham et al, 2002).
First, GATE?s German Lan-guage plugin1 was used to obtain word tokens andsentence boundaries.
The output was manually in-spected and corrected by one annotator, who fur-ther added a layer of normalised spelling variants.This annotation layer was then used as input for theTreeTagger (Schmid, 1994), obtaining annotationsin terms of POS tags and lemmas.
All annotations1http://gate.ac.uk/sale/tao/splitch15.htmlwere subsequently corrected by two annotators, anddisagreements were reconciled to produce the goldstandard.3.1 TokenisationAs German orthography was not yet codified in theEarly Modern period, a number of specific deci-sions had to be made in respect of tokenisation.
Forexample, clitics can occur in various non-standardforms.
To allow for accurate POS tagging, cliticsshould be tokenised as separate items, similar to thenegative particle n?t in can?t in English, which isconventionally tokenised as ca|n?t.
A case in pointis hastu, a clitic version of hast du (?have you?
),which we tokenise as has|tu.
Furthermore, Ger-man ?to-infinitive?
verb forms are often directly ap-pended to the infinitival marker zu without interven-ing whitespace (e.g.
zugehen instead of zu gehen,?to go?).
Such cases are tokenised as separate forms(zu|gehen) to allow for their accurate tagging aszu/PTKZU gehen/VVINF.A further problem can be found in multi-wordtokens, where the same expression is sometimestreated as a compound (e.g.
obgleich), but at othertimes written separately (ob gleich).
Such cases rep-resent a problem for POS-tagging as the variantshave to be treated differently even though their func-tion in the sentence is the same.
Our tokenisationscheme deals with these in a similar way to nor-mal conjunctions consisting of two words, wherethe most suitable tags are assigned to each token(e.g.
als/KOKOM wenn/KOUS).
Thus, the com-pound obgleich is tagged KOUS, while the multi-word variant ob gleich is tagged as ob/KOUS gle-ich/ADV.3.2 Normalising spelling variantsAll spelling variants in GerManC-GS were nor-malised to a modern standard.
We view the taskof normalising spelling variation as a type of pre-lemmatisation, where each word token occurringin a text is labelled with a normalised head vari-ant.
As linguistic searches require a historically ac-curate treatment of spelling variation, our schemehas a preference for treating two seemingly simi-lar tokens as separate items on historical grounds(e.g.
etwan vs. etwa).
On the other hand, thescheme normalises variants to a modernised form20even where the given lexical item has since died out(e.g.
obsolete verbs ending in -iren are normalisedto -ieren), in order to support automatic tools usingmorphological strategies such as suffix probabilities(Schmid, 1994).
Inter-annotator agreement for an-notating spelling variation was 96.9%, which indi-cates that normalisation is a relatively easy task.Figure 1 shows the proportion of normalised wordtokens in the individual corpus files plotted againsttime.
The graph clearly shows a decline of spellingvariants over time: while the earlier texts contain 35-40% of normalised tokens, the proportion is lowerin later texts (11.3% in 1790, and 5.4% in 1798).This suggests that by the end of the period (1800)codification of the German language was already atan advanced stage.Figure 1: Proportion of normalised tokens (plottedagainst time)3.3 Adapting the POS tagset (STTS)To account for important differences between mod-ern and Early Modern German (EMG), and to facil-itate more accurate searches, we adapted the STTStagset (Schiller et al, 1999).
The STTS-EMG tagsetmerges two categories, as the criteria for distinguish-ing them are not applicable in EMG (1.
), and pro-vides a number of additional ones to account for spe-cial EMG constructions (2. to 6.):1.
PIAT (merged with PIDAT): Indefinite de-terminer, as in ?viele solche Bemerkungen?
(?many such remarks?)2.
NA: Adjectives used as nouns, as in ?derGesandte?
(?the ambassador?)3.
PAVREL: Pronominal adverb used as relative,as in ?die Puppe, damit sie spielt?
(?the dollwith which she plays?)4.
PTKREL: Indeclinable relative particle, as in?die Fa?lle, so aus Schwachheit entstehen?
(?thecases which arise from weakness?)5.
PWAVREL: Interrogative adverb used asrelative, as in ?der Zaun, woru?ber sie springt?
(?the fence over which she jumps?)6.
PWREL: Interrogative pronoun used as rel-ative, as in ?etwas, was er sieht?
(?somethingwhich he sees?
)Around 2.0% (1132) of all tokens in the corpuswere tagged with one of the above POS categories.Inter-annotator agreement for the POS tagging taskwas 91.6%.4 ?Off-the-shelf?
tagger evaluation onEarly Modern German dataThe evaluation described in this section aims tocomplement the findings of Rayson et al (2007) forEarly Modern English, and a recent study by Dip-per (2010), in which the TreeTagger is applied to acorpus of texts from Middle High German (MHG)- i.e.
a period earlier than ours, from 1050-1350.Both studies report considerable improvement ofPOS-tagging accuracy on normalised data.
How-ever, unlike Dipper (2010), whose experiments in-volve retraining the TreeTagger on a modified ver-sion of STTS, our experiments assess the ?off-the-shelf?
performance of the modern tagger on histor-ical data.
We further explore the question of whateffect spelling variation has on the performance of atagger, and what improvement can be achieved whenrunning the tool on normalised data.Table 1 shows the results of running the Tree-Tagger on the original data vs. normalised data inour corpus using the parameter file for modern Ger-man supplied with the tagger2.
The results show thatwhile overall accuracy for running the tagger on theoriginal input is relatively low at 69.6%, using thenormalised tokens as input results in an overall im-provement of 10% (79.7%).2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html21O NAccuracy 69.6% 79.7%Table 1: TreeTagger accuracy on original (O) vs. nor-malised (N) inputHowever, improvement through normalisation isnot distributed evenly across the corpus.
Figure 2shows the performance curves of using TreeTaggeron original (O) and normalised (N) input plottedagainst publication date.
While both curves grad-ually rise over time, the improvement curve (mea-sured as difference in accuracy between N and O)diminishes, a direct result of spelling variation be-ing more prominent in earlier texts (cf.
Figure 1).Figure 2: Tagger performance plotted against publicationdateCompared with the performance of the TreeTag-ger on modern data (ca.
97%; Schmid, (1995)), thecurrent results seem relatively low.
However, two is-sues should be taken into account when interpretingthese findings: First, the modern accuracy figuresresult from an evaluation of the tagger on the texttype it was developed on (newspaper text), whileGerManC-GS includes a variety of genres, whichis bound to result in lower performance.
Secondly,inter-annotator agreement was also found to be con-siderably lower in the present task (91.6%) than inone reported for modern German (98.6%; Brants,2000a).
This is likely to be due to the large numberof unfamiliar word forms and variants in the corpus,which represent a problem for human annotators.Finally, Figure 3 provides a more detailedoverview of the effects of spelling variation on POStagger performance.
Of 12,744 normalised tokens inthe corpus, almost half (5981; 47%) are only taggedcorrectly when using the normalised variants as in-put.
Using the original word form as input resultsin a false POS tag in these cases.
Overall, this ac-counts for an improvement of around 10.3% (5981out of 57,845 tokens in the corpus).
However, 32%(4119) of normalised tokens are tagged correctly us-ing both N and O input, while 18% (2339) of to-kens are tagged incorrectly using both types of input.This means that for 50% of all annotated spellingvariants, normalisation has no effect on POS taggerperformance.
In a minority of cases (305; 3%) nor-malisation has a negative effect on tagger accuracy.Figure 3: Effect of using original (O)/normalised (N) in-put on tagger accuracy for normalised tokens (+: cor-rectly tagged; -: incorrectly tagged)5 Conclusion and future workThe results of our study show that using an ?off-theshelf?
German POS tagger on data from the EarlyModern period achieves reasonable results (69.6%on average), but requires a substantial amount ofmanual post-editing.
We further demonstrated thatadding a normalisation layer can improve results by10%.
However, using the current manual normalisa-tion scheme only half of all annotations carried outhave a positive effect on tagger performance.
In fu-ture work we plan to investigate if the scheme canbe adapted to account for more cases, and to whatextent normalisation can be reliably automated (Jur-ish, 2010).
Finally, we plan to retrain state-of-the-artPOS taggers such as the TreeTagger and TnT Tagger(Brants, 2000b) on our data and compare the resultsto the findings of this study.22ReferencesTorsten Brants.
2000a.
Inter-annotator agreement fora German newspaper corpus.
Second InternationalConference on Language Resources and Evaluation(LREC 2000), Athens, Greece.Torsten Brants.
2000b.
TnT ?
a statistical part-of-speechtagger.
Proceedings of the 6th Applied NLP Confer-ence, ANLP-2000, Seattle, WA.Hamish Cunningham, Diana Maynard, KalinaBontcheva, and Valentin Tablan.
2002.
GATE:A framework and graphical development environmentfor robust NLP tools and applications.
Proceedings ofthe 40th Anniversary Meeting of the Association forComputational Linguistics.Stefanie Dipper.
2010.
POS-Tagging of historical lan-guage data: First experiments in semantic approachesin Natural Language Processing.
Proceedings ofthe 10th Conference on Natural Language Processing(KONVENS-10).
Saarbru?cken, Germany.
117-121.Vera Fasshauer.
2011. http://www.indogermanistik.uni-jena.de/index.php?auswahl=184Accessed 30/03/2011.Bryan Jurish.
2010.
Comparing canonicalizations of his-torical German text.
Proceedings of the 11th Meetingof the ACL Special Interest Group on ComputationalMorphology and Phonology (SIGMORPHON), Upp-sala, Sweden.
72-77.Paul Rayson, Dawn Archer, Alistair Baron, JonathanCulpeper, and Nicholas Smith.
2007.
Tagging theBard: Evaluating the accuracy of a modern POS taggeron Early Modern English corpora.
Proceedings of theCorpus Linguistics Conference (CL2007), Universityof Birmingham, UK.Silke Scheible, Richard J. Whitt, Martin Durrell, and PaulBennett.
To appear.
A Gold Standard Corpus of EarlyModern German.
Proceedings of the Fifth LinguisticAnnotation Workshop (LAW V), Portland, Oregon.Anne Schiller, Simone Teufel, Christine Sto?ckert, andChristine Thielen.
1999.
Guidelines fu?r das Taggingdeutscher Textcorpora mit STTS.
Technical Report.Institut fu?r maschinelle Sprachverarbeitung, Stuttgart.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
International Conferenceon NewMethods in Language Processing, Manchester,UK.
44?49.Helmut Schmid.
1995.
Improvements in Part-of-SpeechTagging with an Application to German.
Proceedingsof the ACL SIGDAT-Workshop.
47?50.23
