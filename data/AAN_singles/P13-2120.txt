Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 684?689,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsMapping Source to Target Strings without Alignment by AnalogicalLearning: A Case Study with TransliterationPhilippe LanglaisRALI / DIROUniversite?
de Montre?alMontre?al, Canada, H3C 3J7felipe@iro.umontreal.caAbstractAnalogical learning over strings is a holis-tic model that has been investigated by afew authors as a means to map forms of asource language to forms of a target lan-guage.
In this study, we revisit this learn-ing paradigm and apply it to the translit-eration task.
We show that alone, it per-forms worse than a statistical phrase-basedmachine translation engine, but the com-bination of both approaches outperformseach one taken separately, demonstratingthe usefulness of the information capturedby a so-called formal analogy.1 IntroductionA proportional analogy is a relationship betweenfour objects, noted [x : y :: z : t], which reads as?x is to y as z is to t?.
While some strategies havebeen proposed for handling semantic relationships(Turney and Littman, 2005; Duc et al, 2011),we focus in this study on formal proportionalanalogies (hereafter formal analogies or simplyanalogies), that is, proportional analogies involv-ing relationships at the graphemic level, such as[atomkraftwerken : atomkriegen :: kraftwerks :kriegs] in German.Analogical learning over strings has been in-vestigated by several authors.
Yvon (1997) ad-dressed the task of grapheme-to-phoneme conver-sion, a problem which continues to be studied ac-tively, see for instance (Bhargava and Kondrak,2011).
Stroppa and Yvon (2005) applied analog-ical learning to computing morphosyntactic fea-tures to be associated with a form (lemma, part-of-speech, and additional features such as number,gender, case, tense, mood, etc.).
The performanceof the analogical engine on the Dutch languagewas as good as or better than the one reported in(van den Bosch and Daelemans, 1993).
Lepageand Denoual (2005) pioneered the application ofanalogical learning to Machine Translation.
Dif-ferent variants of the system they proposed havebeen tested in a number of evaluation campaigns,see for instance (Lepage et al, 2009).
Langlaisand Patry (2007) investigated the more specifictask of translating unknown words, a problem si-multaneously studied in (Denoual, 2007).Analogical learning has been applied to variousother purposes, among which query expansion ininformation retrieval (Moreau et al, 2007), clas-sification of nominal and binary data, and hand-written character recognition (Miclet et al, 2008).Formal analogy has also been used for solvingRaven IQ tests (Correa et al, 2012).In this study, we investigate the relevanceof analogical learning for English proper nametransliteration into Chinese.
We compare it tothe statistical phrase-based machine translationapproach (Koehn et al, 2003) initially proposedfor transliteration by Finch and Sumita (2010).We show that alone, analogical learning underper-forms the phrase-based approach, but that a com-bination of both outperforms individual systems.We describe in section 2 the principle of ana-logical learning.
In section 3, we report on ex-periments we conducted in applying analogicallearning on the NEWS 2009 English-to-Chinesetransliteration task.
Related works are discussedin section 4.
We conclude in section 5 and identifyavenues we believe deserve investigations.2 Analogical Learning2.1 Formal AnalogyIn this study, we use the most general definitionof formal analogy we found, initially describedin (Yvon et al, 2004).
It handles a large varietyof relations, including but not limited to affixa-tion operations (i.e.
[capital : anticapitalisme ::commun : anticommuniste] in French), stem mu-684tations (i.e.
[lang : la?nge :: stark : sta?rke] in Ger-man), and even templatic relations (i.e [KaaTiB :KuTaaB :: QaaRi?
: QuRaa? ]
in Arabic).Informally,1 this definition states that 4 formsx, y, z and t are in analogical relation iff we canfind a d-factorization (a factorization into d fac-tors) of each form, such that the ith factors (i ?
[1, d]) of x and z equal (in ensemble terms) the ithfactors of y and t.For instance, [this guy drinks : this boat sinks:: these guys drank : these boats sank ] holds be-cause of the following 4-uple of 5-factorizations,whose factors are aligned column-wise for clarity,and where spaces (underlined) are treated as regu-lar characters ( designates the empty factor):fx ?
( this guy  dr inks )fy ?
( this boat  s inks )fz ?
( these guy s dr ank )ft ?
( these boat s s ank )This analogy ?captures?
among other thingsthat in English, changing this for these implies aplural mark (s) to the corresponding noun.
Notethat analogies can relate arbitrarily distant sub-strings.
For instance the 3rd-person singular markof the verbs relates to the first substring this .2.2 Analogical LearningWe now clarify the process of analogical learning.Let L = {(i(xk), o(xk))k} be a training set (ormemory) gathering pairs of input i(xk) and out-put o(xk) representations of elements xk.
In thisstudy, the elements we consider are pairs of En-glish / Chinese proper names in a transliterationrelation.
Given an element t for which we onlyknow i(t), analogical learning works by:1. building Ei(t) = {(x, y, z) ?
L3 | [i(x) :i(y) :: i(z) : i(t)]}, the set of triples in thetraining set that stand in analogical propor-tion with t in the input space,2.
building Eo(t) = {[o(x) : o(y) :: o(z) :?]
| (x, y, z) ?
Ei(t)}, the set of solutions tothe output analogical equations obtained,3.
selecting o(t) among the solutions aggre-gated into Eo(t).In this description, we define an analogicalequation as an analogy with one form missing, and1We refer the reader to (Stroppa and Yvon, 2005) for amore technical exposition.we note [x : y :: z : ? ]
the set of its solutions (i.e.undoable ?
[reader : doer :: unreadable : ?
]).2L = { (Schell,??
), (Zemens,???
), (Zell,??),(Schemansky,????
), (Clise,???),(Rovine,??
), (Rovensky,????
), .
.
.}.
[Schell : Zell :: Schemansky : Zemansky]?
?
?
?[??
: ??
:: ????
: ?]
[4 sols] :????
????
????
.
.
.. [Rovine : Rovensky :: Zieman : Zemansky]?
?
?
?[??
: ????
:: ??
: ?]
[6 sols] :????
????
????
.
.
.. [Stephens : Stephansky :: Zemens : Zemansky]?
?
?
?[????
: ?????
:: ???
: ?]
[9 sols] :????
????
????
.
.
....31 solutions: ????
(77) ????
(59)????
(29) ?????
(20) .
.
.Figure 1: Excerpt of a transliteration session forthe English proper name Zemansky.
31 solutionshave been identified in total (4 by the first equationreported); the one underlined (actually the mostfrequently generated) is the sanctioned one.Figure 1 illustrates this process on a translit-eration session for the English proper nameZemansky.
The training corpus L is a set ofpairs of English proper names and their Chi-nese Transliteration(s).
Step 1 identifies analogiesamong English proper names: 7 such analogies areidentified, 3 of which are reported (marked with a. sign).
Step 2 projects the English forms in ana-logical proportion into their known transliteration(illustrated by a ?
sign) in order to solve Chineseanalogical equations.
Step 3 aggregates the solu-tions produced during the second step.
In the ex-ample, it consists in sorting the solutions in de-creasing order of the number of time they havebeen generated during step 2 (see next section fora better strategy).There are several important points to considerwhen deploying the learning procedure shownabove.
First, the search stage (step 1) has a timecomplexity that can be prohibitive in some appli-cations of interest.
We refer the reader to (Langlaisand Yvon, 2008) for a practical solution to this.Second, we need a way to solve an analogical2Analogical equation solvers typically produce several so-lutions to an equation.685equation.
We applied the finite-state machine pro-cedure described in (Yvon et al, 2004).
Suffice itto say that typically, this solver produces severalsolutions to an equation, most of them spurious,3reinforcing the need for an efficient aggregationstep (step 3).
Last, it might happen that the over-all approach fails at producing a solution, becauseno input analogy is identified during step 1, or be-cause the input analogies identified do not lead toanalogies in the output space.
This silence issue isanalyzed in section 3.
A detailed account of thoseproblems and possible solutions are discussed in(Somers et al, 2009).We underline that analogies in both source andtarget languages are considered independently: theapproach does not attempt to align source and tar-get substrings, but relies instead on the inductivebias that input analogies (often) imply output ones.3 Experiments3.1 SettingThe task we study is part of the NEWS evalua-tion campaign conducted in 2009 (Li et al, 2009).The dataset consists of 31 961 English-Chinesetransliteration examples for training the system(TRAIN), 2 896 ones for tuning it (DEV), and 2 896for testing them (TEST).We compare two different approaches totransliteration: a statistical phrase-based machinetranslation engine ?
which according to Li etal.
(2009) was popular among participating sys-tems to NEWS ?
as well as differently flavoredanalogical systems.We trained (on TRAIN) a phrase-based transla-tion device with the Moses toolkit (Koehn et al,2007), very similarly to (Finch and Sumita, 2010),that is, considering each character as a word.
Thecoefficients of the log-linear function optimized byMoses?
decoder were tuned (with MERT) on DEV.For the analogical system, we investigated theuse of classifiers trained in a supervised way torecognize the good solutions generated duringstep 2.
For this, we first transliterated the DEVdataset using TRAIN as a memory.
Then, wetrained a classifier, taking advantage of the DEVcorpus for the supervision.
We tried two typesof learners ?
support vector machines (Cortesand Vapnik, 1995) and voted perceptrons (Freund3A spurious solution is a string that does not belong to thelanguage under consideration.
See Figure 1 for examples.and Schapire, 1999)4 ?
and found the former toslightly outperform the latter.
Finally, we translit-erated the TEST corpus using both the TRAIN andDEV corpora as a memory,5 and applied our clas-sifiers on the solutions generated.The lack of space prevents us to describe the 61features we used for characterizing a solution.
Weinitially considered a set of features which charac-terizes a solution (frequency, rank in the candidatelist, language model likelihood, etc.
), and the pro-cess that generated the solution (i.e.
number ofanalogies involved), but no feature that would usescored pairs of substrings (such as mutual infor-mation of substrings).6 Thus, we also consideredin a second stage a set of features that we collectedthanks to a n-best list of solutions computed byMoses (Moses?
score given to a solution, its rankin the n-best list, etc.
).3.2 ResultsWe ran the NEWS 2009 official evaluation script7in order to compute ACC (the accuracy of thefirst solution), F1 (the F-measure which givespartial credits proportional to the longest subse-quence between the reference transliteration andthe first candidate), and the Mean Reciprocal Rank(MRR), where 100/MRR roughly indicates the av-erage rank of the correct solution over the session.Table 1 reports the results of several transliter-ation configurations we tested.
The first two sys-tems are pure analogical devices, (M) is the Mosesconfiguration, (AM1) is a variant discussed further,(AM2) is the best configuration we tested (a com-bination of Moses and analogical learning), andthe last two lines show the lowest and highest per-forming systems among the 18 standard runs reg-istered at NEWS 2009 (Li et al, 2009).
Severalobservations have to be made.First, none of the variants tested outperformedthe best system reported at NEWS 2009.
This isnot surprising since we conducted only prelimi-nary experiments with analogy.
Still, we werepleased to observe that the best configuration wedevised (AM2) would have ranked fourth on thistask.4We used libSVM (Chang and Lin, 2011) for trainingsvms, and an in-house package for training voted perceptrons.5This is fair since there is no training involved.
Manyparticipants to the NEWS campaign did this as well.6We avoided this in order to keep the classifiers simple totrain.7http://translit.i2r.a-star.edu.sg/news2009/evaluation/.686The ana-freq system is an analogical devicewhere the aggregation step consists in sorting so-lutions in decreasing order of frequency.
It isclearly outperformed by the Moses system.
Theana-svma system is an analogical device wherethe solutions are selected by the SVM trained onanalogical features only.
Learning to recognizegood solutions from spurious ones improves accu-racy (over A1).
Still, we are far from the accuracywe would observe by using an oracle classifier(ACC = 81.5).
Clearly, further experiments withbetter feature engineering must be conducted.
Itis noteworthy that the pure analogical devices wetested (A1 and A2) did not return any solution for3.7% of the test forms, which explains some lossin performance compared to the SMT approach,which always delivers a solution.8System ana-svma+m (AM1) is an analogicaldevice where the classifier makes uses of the fea-tures extracted by Moses.
Obviously, those fea-tures drastically improve accuracy of the classifier.Configuration (AM2) is a combination which cas-cades the hybrid device (AM1) with the SMT en-gine (M).
This means that the former system istrusted whenever it produces a solution, and thelatter one is used as a backup.
This configurationoutperforms Moses, which demonstrates the com-plementarity of the analogical information.Configuration ACC F1 MRR rankA1 ana-freq 56.6 79.1 63.0 16A2 ana-svma 58.0 80.0 58.8 15M moses 66.6 85.9 66.6 6AM1 ana-svma+m 63.4 82.0 64.1 10AM2 AM1 + M 68.5 86.9 69.0 4last NEWS 2009 19.9 60.6 22.9 23first NEWS 2009 73.1 89.5 81.2 1Table 1: Evaluation of different configurationswith the metrics used at NEWS.
The last columnindicates the rank of systems as if we had submit-ted the top 5 configurations to NEWS 2009.4 Related WorkMost approaches to transliteration we know relyon some form of substring alignment.
This align-ment can be learnt explicitly as in (Knight and8Removing the solutions produced by the SMT engine forthe 3.7% test forms that receive no solution from the analog-ical devices would result in an accuracy score of 65.0.Graehl, 1998; Li et al, 2004; Jiampojamarn et al,2007), or it can be indirectly modeled as in (Oh etal., 2009) where transliteration is seen as a taggingtask (that is, labeling each source grapheme with atarget one), and where the model learns correspon-dences at the substring level.
See also the semi-supervised approach of (Sajjad et al, 2012).
Ana-logical inference differs drastically from those ap-proaches, since it finds relations in the source ma-terial and solves target equations independently.Therefore, no alignment whatsoever is required.Transliteration by analogical learning has beenattempted by Dandapat et al (2010) for anEnglish-to-Hindi transliteration task.
They com-pared various heuristics to speed up analogicallearning, and several combinations of phrase-based SMT and analogical learning.
Our resultsconfirm the observation they made that combiningan analogical device with SMT leads to gains overindividual systems.
Still, their work differs fromthe present one in the fact that they considered thetop frequency aggregator (similar to A1), which weshowed to be suboptimal.
Also, they used the def-inition of formal analogy of Lepage (1998), whichis provably less general than the one we used.
Theimpact of this choice for different language pairsremains to be investigated.Aggregating solutions produced by analogicalinference with the help of a classifier has been re-ported in (Langlais et al, 2009).
The authors in-vestigated an arguably more specific task: translat-ing medical terms.
Another difference is that weclassify solutions produced by analogical learning(roughly 100 solutions per test form), while theyclassified pairs of input/target analogies, whosenumber can be rather high, leading to huge andhighly unbalanced learning tasks.
The authors re-port training experiments with millions of exam-ples and only a few positive ones.
In fact, weinitially attempted to recognize fruitful analogicalpairs, but found it especially slow and disappoint-ing.5 ConclusionWe considered the NEWS 2009 English-to-Chinese transliteration task for investigating ana-logical learning, a holistic approach that does notrely on an alignment or segmentation model.
Wehave shown that alone, the approach fails to trans-late 3.7% of the test forms, underperforms thestate-of-the-art SMT engine Moses, while still de-687livering decent performance.
By combining bothapproaches, we obtained a system which outper-forms the individual ones we tested.We believe analogical inference over strings hasnot delivered all his potential yet.
In particular,we have observed that there is a huge room forimprovements in the aggregation step.
We havetested a simple classifier approach, mining a tinysubset of the features that could be put at use.More research on this issue is warranted, notablylooking at machine-learned ranking algorithms.Also, the silence issue we faced could be tack-led by the notion of analogical dissimilarity intro-duced by Miclet et al (2008).
The idea of usingnear analogies in analogical learning has been suc-cessfully investigated by the authors on a numberof standard classification testbeds.AcknowledgmentsThis work has been founded by the NaturalSciences and Engineering Research Council ofCanada.
We are grateful to Fabrizio Gotti for hiscontribution to this work, and to the anonymousreviewers for their useful comments.
We are alsoindebted to Min Zhang and Haizhou Li who pro-vided us with the NEWS 2009 English-Chinesedatasets.ReferencesAditya Bhargava and Grzegorz Kondrak.
2011.
Howdo you pronounce your name?
Improving G2P withtransliterations.
In 49th ACL/HLT, pages 399?408,Portland, USA.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A Library for Support Vector Machines.ACM Trans.
Intell.
Syst.
Technol., 2(3):1?27, May.William Fernando Correa, Henri Prade, and GillesRichard.
2012.
When intelligence is just a matterof copying.
In 20th ECAI, pages 276?281, Mont-pellier, France.Corinna Cortes and Vladimir Vapnik.
1995.
Support-Vector Networks.
Mach.
Learn., 20(3):273?297.Sandipan Dandapat, Sara Morrissey, Sudip Ku-mar Naskar, and Harold Somers.
2010.
Mitigat-ing Problems in Analogy-based EBMT with SMTand vice versa: a Case Study with Named En-tity Transliteration.
In 24th Pacific Asia Confer-ence on Language Information and Computation(PACLIC?10), pages 365?372, Sendai, Japan.E?tienne Denoual.
2007.
Analogical translation ofunknown words in a statistical machine translationframework.
In MT Summit XI, pages 135?141,Copenhagen, Denmark.Nguyen Tuan Duc, Danushka Bollegala, and MitsuruIshizuka.
2011.
Cross-Language Latent RelationalSearch: Mapping Knowledge across Languages.
In25th AAAI, pages 1237 ?
1242, San Francisco, USA.Andrew Finch and Eiichiro Sumita.
2010.
Translit-eration Using a Phrase-based Statistical MachineTranslation System to Re-score the Output of a JointMultigram Model.
In 2nd Named Entities Workshop(NEWS?10), pages 48?52, Uppsala, Sweden.Y.
Freund and R. E. Schapire.
1999.
Large Mar-gin Classification Using the Perceptron Algorithm.Mach.
Learn., 37(3):277?296.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying Many-to-Many Alignmentsand Hidden Markov Models to Letter-to-PhonemeConversion.
In NAACL/HLT?07, pages 372?379.Kevin Knight and Jonathan Graehl.
1998.
MachineTransliteration.
Comput.
Linguist., 24(4):599?612.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical Phrase-Based Translation.
InNAACL/HLT?03, pages 48?54, Edmonton, Canada.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondr?ej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In 45th ACL, pages 177?180.
Interactive Poster andDemonstration Sessions.Philippe Langlais and Alexandre Patry.
2007.
Trans-lating Unknown Words by Analogical Learning.
InEMNLP/CoNLL?07, pages 877?886, Prague, CzechRepublic.Philippe Langlais and Franc?ois Yvon.
2008.
Scalingup Analogical Learning.
In 22nd COLING, pages51?54, Manchester, United Kingdom.
Poster.Philippe Langlais, Franc?ois Yvon, and Pierre Zweigen-baum.
2009.
Improvements in Analogical Learn-ing: Application to Translating multi-Terms of theMedical Domain.
In 12th EACL, pages 487?495,Athens, Greece.Yves Lepage and E?tienne Denoual.
2005.
Purest everexample-based machine translation: Detailed pre-sentation and assesment.
Mach.
Translat, 19:25?252.Yves Lepage, Adrien Lardilleux, and Julien Gosme.2009.
The GREYC Translation Memory for theIWSLT 2009 Evaluation Campaign: one step be-yond translation memory.
In 6th IWSLT, pages 45?49, Tokyo, Japan.688Yves Lepage.
1998.
Solving Analogies on Words: anAlgorithm.
In COLING/ACL, pages 728?733, Mon-treal, Canada.Haizhou Li, Min Zhang, and Jian Su.
2004.
A JointSource-Channel Model for Machine Transliteration.In 42nd ACL, pages 159?166, Barcelona, Spain.Haizhou Li, A. Kumaran, Vladimir Pervouchine, andMin Zhang.
2009.
Report of NEWS 2009 MachineTransliteration Shared Task.
In 1st Named EntitiesWorkshop (NEWS?09): Shared Task on Translitera-tion, pages 1?18, Singapore.Laurent Miclet, Sabri Bayroudh, and Arnaud Delhay.2008.
Analogical Dissimilarity: Definitions, Algo-rithms and two experiments in Machine Learning.Journal of Artificial Intelligence Research, pages793?824.Fabienne Moreau, Vincent Claveau, and PascaleSe?billot.
2007.
Automatic Morphological QueryExpansion Using Analogy-based Machine Learn-ing.
In 29th European Conference on IR research(ECIR?07), pages 222?233, Rome, Italy.Jong-hoon Oh, Kiyotaka Uchimoto, and Kentaro Tori-sawa.
2009.
Machine Transliteration using Target-Language Grapheme and Phoneme: Multi-engineTransliteration Approach.
In 1st Named EntitiesWorkshop (NEWS?09): Shared Task on Transliter-ation, pages 36?39, Singapore.Hassan Sajjad, Alexander Fraser, and Helmut Schmid.2012.
A Statistical Model for Unsupervised andSemi-supervised Transliteration Mining.
In 50thACL, pages 469?477, Jeju Island, Korea.Harold Somers, Sandipan Sandapat, and Sudip KumarNaskar.
2009.
A Review of EBMT Using Pro-portional Analogies.
In 3rd Workshop on Example-based Machine Translation, pages 53?60, Dublin,Ireland.Nicolas Stroppa and Franc?ois Yvon.
2005.
An Ana-logical Learner for Morphological Analysis.
In 9thCoNLL, pages 120?127, Ann Arbor, USA.P.D.
Turney and M.L.
Littman.
2005.
Corpus-basedLearning of Analogies and Semantic Relations.
InMachine Learning, volume 60, pages 251?278.Antal van den Bosch and Walter Daelemans.
1993.Data-Oriented Methods for Grapheme-to-PhonemeConversion.
In 6th EACL, pages 45?53, Utrecht,Netherlands.Franc?ois Yvon, Nicolas Stroppa, Arnaud Delhay, andLaurent Miclet.
2004.
Solving Analogies on Words.Technical Report D005, E?cole Nationale Supe?rieuredes Te?le?communcations, Paris, France.Franc?ois Yvon.
1997.
Paradigmatic Cascades: a Lin-guistically Sound Model of Pronunciation by Anal-ogy.
In 35th ACL, pages 429?435, Madrid, Spain.689
