Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 14?24, Dublin, Ireland, August 23-29 2014.Cross-lingual Coreference Resolution of PronounsMichal Nov?ak and Zden?ek?Zabokrtsk?yCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostransk?e n?am?est??
25, CZ-11800{mnovak,zabokrtsky}@ufal.mff.cuni.czAbstractThis work is, to our knowledge, a first attempt at a machine learning approach to cross-lingualcoreference resolution, i.e.
coreference resolution (CR) performed on a bitext.
Focusing on CRof English pronouns, we leverage language differences and enrich the feature set of a standardmonolingual CR system for English with features extracted from the Czech side of the bitext.Our work also includes a supervised pronoun aligner that outperforms a GIZA++ baseline interms of both intrinsic evaluation and evaluation on CR.
The final cross-lingual CR system hassuccessfully outperformed both a monolingual CR and a cross-lingual projection system.1 IntroductionCoreference resolution (CR) is a well-established task in the field of Natural Language Processing (NLP).The majority of papers published so far has focused on the monolingual CR, mostly experimenting onthe English data.
An important step towards multilingual CR was the CoNLL-2012 Shared Task inModeling Multilingual Unrestricted Coreference in OntoNotes, where the participants were asked tobuild a CR system that could be applied on three typologically different languages contained in theOntoNotes corpus (Hovy et al., 2006): English, Chinese, and Arabic.Same just as in other NLP tasks such as part-of-speech tagging or parsing, recent years have witnesseda rising interest in cross-lingual projection techniques, mostly aiming at under-resourced languages.However, little attention is paid to leveraging cross-lingual information for CR in two resource-richlanguages.
This is probably due to lack of bilingual resources annotated with coreference since suchtechniques would require rich linguistic annotation on both sides of the bitext.
Moreover, to solve thisissue using a supervised learner, one needs the gold standard of coreference at least on the target side ofthe bitext.
On the other hand, given such data, the typological differences in languages can be exploitedto aid a CR system to perform better than if CR is performed independently for each language.The motivation for solving this task is threefold.
Firstly, even though Statistical Machine Translation(SMT) has been attracting interest of the community for years, most systems do not take information be-yond the sentence boundary into account, leaving the issues of discourse coherence unresolved.
Havinga better-quality bitext with coreference resolved could drive research in discourse-aware SMT forward.Secondly, although inter-sentential relations are neglected in SMT, current phrase-based system uninten-tionally resolve some of the coreference links within the sentence, using just the power of phrases.
Thismight be leveraged by using the SMT output instead of a human-translated output in a cross-lingual CRscenario.
Finally, even monolingual CR may be improved by applying semi-supervised learning methodsin a smart way on a large bilingual corpus with automatic rich annotations, such as CzEng 1.0 (Bojar etal., 2012).Our work examines cross-lingual CR on the Czech-English language pair.
We focus on CR of Englishpronouns, particularly the 3rd person central pronouns.
Central pronouns is a term coined by Quirk(1985) embracing personal, possessive and reflexive pronouns.
For the sake of simplicity, we will denoteThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/143rd person central pronouns by the word pronouns in the following.
We ignore noun phrase coreferencefor two reasons.
First, there has been no data set available for the Czech-English language pair withnoun phrase coreference annotated, yet.
Second, the language differences between languages show moreclearly on pronouns than on nouns, as pronouns tend to be more constrained by various grammar rulesacross different languages.Czech and English are typologically distant languages, which is also reflected in different behavior ofpronouns.
A cross-lingual CR system could substantially benefit from the necessity of the anaphor and itsantecedent to agree in gender.
Czech uses grammatical genders which are more evenly distributed amongnouns than the notional genders1used in English, where male and female gender2are solely allocatedto living objects.
However, benefiting from the pronoun?s gender becomes problematic for personalpronouns in subject position which are usually dropped from the surface representation in Czech.
If theirgoverning verb is in the past tense, the correct gender can be reconstructed from its form.
With the verb inpresent or future tense, the pronoun?s gender remains hidden.
Possessive pronouns are used to a greaterextent in English than in Czech.
Same as articles, they play the role of determiners whereas in Czech,the determination and possession must be understood from the context.
A missing Czech counterpart ofan English possessive pronoun may indicate its antecedent to be in the same sentence.
Moreover, Czechuses reflexive possessive pronouns, whose antecedent is easier to detect than for non-reflexive pronouns.On the other hand, English reflexive pronouns, unlike the Czech, carry gender and number informationthe resolver can benefit from.In this work, we make to our knowledge a first attempt to leverage the language differences usinga machine learning approach to improve CR on bitexts.
To achieve this goal, we create a supervisedCR model, proposing two sets of cross-lingual features: projected features used for Czech CR and anindicator feature of a projected Czech coreference link obtained by a Czech CR system.
Note that for thelatter set (actually comprising only a single feature), the Czech CR system would require gold annotationof Czech coreference.
We did not consider new features that would address specific Czech-Englishcorrespondences.The fact that a Czech counterpart is missing for many English pronouns has a negative effect ontraditional unsupervised alignment approaches.
We address this issue by a supervised aligner of pronounsthat incorporates the result of the traditional aligner as a feature and adds other features that help detectthe true Czech counterparts of English pronouns.The structure of this paper is as follows: After introducing related work in Section 2 and describing thedata used in experiments in Section 3, we present the design of a supervised approach to improve Englishpronoun alignment in Section 4.
Section 5 describes the cross-lingual CR system and the experimentsconducted with it.
Finally, we discuss the main observations made in the experiments in Section 6 andconclude the paper in Section 7.2 Related workThe task of coreference resolution has been studied for a few decades, with supervised systems dominat-ing the field.
The most popular approaches have been thoroughly summarized by Ng (2010).The system for English CR we use has been built for automatic coreference annotation in the Czech-English parallel treebank CzEng 1.0 (Bojar et al., 2012).
It is an implementation of the so-called mentionranking model, first introduced by Denis and Baldridge (2007).Parallel bilingual data is often exploited to solve well-known tasks such as part-of-speech tagging(Das and Petrov, 2011), named entity recognition (Kim et al., 2012), name tagging (Li et al., 2012),and semantic role labeling (Zhuang and Zong, 2010).
Undoubtedly, this approach is most popular withparsing.
Joint parsing of both the source and the target text along with searching for the best alignmentbetween the trees has been approached in a more (Burkett et al., 2010) or less (Smith and Smith, 2004;Burkett and Klein, 2008) integrated approach.
However, much closer to our work is the research on1?Nouns are classified semantically according to their coreferential relations with personal, reflexive and wh-pronouns.?
(Quirk et al., 1985, p.314)2Quirk (1985) uses these terms instead of terms masculine and feminine related to grammatical gender.15bilingually-informed parsing by Haulrich (2012), in which English trees are used to enrich the featureset for a Danish parser and vice-versa.
Rosa et al.
(2012) explored the same approach on the Czech-English language pair.
Moreover, they adapted this technique to parse the output of an SMT system.As for coreference resolution in a bilingual scenario, most works focus on coreference projection (deSouza and Orsan, 2011; Rahman and Ng, 2012; Ogrodniczuk, 2013).
Research on cross-lingual CR hasbeen inhibited by the lack of coreference-annotated parallel corpora.
There are only few such corpora, forinstance an English-Romanian corpus containing full hand-annotated coreference chains including nounphrase coreference (Postolache et al., 2006) and two corpora with pronoun coreference annotations ?Prague Czech-English Dependency Treebank 1.0 (Haji?c et al., 2012, PCEDT) and the recently publishedEnglish-German corpus ParCor 1.0 (Guillou et al., 2014).However, the only attempts at cross-lingual CR date back to the time before these corpora were re-leased.
Harabagiu and Maiorano (2000) designed a CR system for English-Romanian bitexts whileMitkov and Barbu (2003) focused on the English-French language pair.
Both extended their rule-basedmonolingual CR systems to apply some high-precision rules from one language to enhance the resultin the other language.
They both reported an improvement of about 4% in precision compared to themonolingual systems.As concerns a machine learning approach, in the work by Veselovsk?a et al.
(2012), PCEDT wasemployed in related tasks ?
to identifying types of the English personal pronoun it and Czech types ofthe unexpressed subject.
The tasks have been addressed by the isolated monolingual systems as well asby taking advantage of the features from the other language.3 Main source of the dataAs mentioned in Section 2, Czech is one of a few languages for which a coreference-annotated parallelcorpus has been built ?
The Prague Czech-English Dependency Treebank (Haji?c et al., 2012, PCEDT).3PCEDT is a manually annotated Czech-English parallel treebank comprising over 1.2 million wordsfor each language in almost 50,000 sentence pairs.
The English part contains the entire Penn Treebank?Wall Street Journal Section (Linguistic Data Consortium, 1999) transformed into dependency trees,whereas the Czech part comprises the translations of all the texts from the English part.
The data fromboth parts are annotated on three layers of linguistic description following the Prague tectogrammaticstheory (Sgall, 1967; Sgall et al., 1986) ?
the morphological layer (where each token from the sentencegets a lemma and a POS tag), the analytical layer (surface syntax in the form of a dependency tree, whereeach node corresponds to a token in the sentence) and the tectogrammatical layer.
Tectogrammatical rep-resentation of a sentence is a dependency tree, where only content words have their own nodes; on theother hand, it contains additional nodes, e.g., for pronouns unexpressed on the surface.
This is also thelayer where the coreference relations are annotated.
PCEDT includes annotation of pronoun coreferenceand the so-called grammatical coreference4for Czech as well as English.For the purpose of this work, we ignore all annotations originally provided by PCEDT.
Annotationson the tectogrammatical layer, which is in the center of this work?s attention, are mostly manual there.But to truly simulate the real-world scenario when given just a pair of parallel texts, we need to replacethem with ones carried out in a fully automatic manner.
The only two exceptions, where we employ thegold annotations, are the relations we aim to model, i.e.
coreference links and our own annotation ofalignment for English personal pronouns (see Section 4.1).3.1 Fully Automatic AnnotationWe have conducted automatic linguistic analysis on both the English and the Czech part of PCEDT,transforming the individual sentences into multi-layer dependency tree structures based on the Praguetectogrammatics theory.
The analysis was carried out within the Treex framework (Popel and?Zabokrtsk?y,2010).3http://hdl.handle.net/11858/00-097C-0000-0015-8DAF-44Its antecedent is imposed by the grammar of the language, e.g.
coreference of relative pronouns.16Treex is a multi-purpose open-source framework for NLP applications development, which integratesa wide range of modules, such as tools for sentence splitting, tokenization, morphological analysis,part-of-speech tagging, shallow and deep syntax parsing, named entity recognition, anaphora resolution,among others.Moreover, we performed an unsupervised word alignment on the complete PCEDT using theMGIZA++ tool (Gao and Vogel, 2008), which is a multi-threaded version of the popular GIZA++ (Ochand Ney, 2000) that supports applying a saved model on a new sentence pair.
We used a model trainedon CzEng 1.0, which is about 300 times bigger in terms of the number of sentence pairs.
The resultingalignment of the intersection and grow-diag-final-and types was subsequently projected onto thetectogrammatical layer.
Furthermore, a simple heuristic was applied to find the English counterparts forreconstructed Czech personal pronouns.
We denote this alignment as the original in the following.4 Supervised alignmentThe alignment described in the previous section is sufficiently accurate for content words, such as verbs,nouns, and adjectives.
However, errors become more frequent as we move to pronouns.
Some reasonsfor this have already been outlined in Section 1, i.e.
dropped subject personal pronouns and omittedpossessive pronouns in Czech.
In addition, English uses a pleonastic variant of the pronoun it, whichalso has no correspondence in Czech.
Personal pronouns function in a sentence as a replacement ofnouns.
Thus, it is no exception if a pronoun is translated into a noun.
And finally, the translation may bereworded to such an extent that the pronoun would carry no valuable information, and it disappears.
Allthese cases are difficult for GIZA++ to tackle.The pronoun correspondence problem has been already faced concerning the alignment of the personalpronoun it by Nov?ak et al.
(2013).
The authors tried to find the Czech counterpart of it by taking thenode that is aligned to the parent of it on the Czech side and picking the argument of the aligned nodethat agrees on the semantic role with the particular it.
This approach assumed that the unsupervisedalignment of the parent, which is likely to be a content word, is of higher quality than the alignment ofit itself.
Furthermore, it relied on high-accuracy semantic role labeling, which could only be justifiedbecause the experiments were conducted on data manually annotated with semantic roles.As we are working with fully automatic annotations (i.e., much less reliable) and a wider range ofwords to align, we cannot just copy this rule-based approach.
However, we can take a more robustapproach of supervised machine learning and transform Nov?ak et al.
?s rule to one of the features in ouralignment model.In Section 4.1, we describe the manual annotation of alignment, then introduce the supervised modelin Section 4.2, using features described in Section 4.3.
Finally, we show the evaluation results of thealignment model in Section 4.4.4.1 Manual Annotation of the DataSupervised learning requires that the training data are manually labeled with a target variable.
For thispurpose, we set aside the section 19 of PCEDT.
In this data, all occurrences of English personal pronounshave been coupled with its Czech counterpart by one human annotator.
If no suitable Czech expressionwas found, the annotator identified a possible cause of the missing counterpart.
The causes were thencategorized into three classes ?
pleonastic it, missing possessive pronoun and missing correspondencedue to translation rewording.
So far, we do not distinguish these classes in our models and treat them inthe same manner.We managed to align 471 occurrences of personal pronouns, which account for over 50% of all occur-rences in the section.
The overall statistics of how English personal pronouns are translated into Czechis shown in Table 1.It shows that more than 55% of English personal pronouns are dropped from the surface representationof the Czech sentence, though still present in its deep structure.
In contrast, English pleonastic pronounsare not present even there.
An interesting observation is that more than half of English possessivesare either translated as reflexive possessives or completely missing in the Czech sentence.
All these17CS\EN personal possessive reflexive Totalpersonal unexpressed 147 1 148personal 37 2 39demonstrative 17 1 18noun 15 6 21possessive 3 78 81reflexive possessive 68 68reflexive 1 2 5 8other 6 1 3 10pleonastic 24 24reword 12 4 16no possessive 38 38Total 262 201 8 471Table 1: The statistics on the correspondence of English personal pronouns to their Czech counterparts.The last three Czech categories indicate the reason why there is no corresponding word in Czech for anEnglish pronoun.phenomena might in the end be a source of helpful information to the CR system.4.2 ModelThe nature of the task of aligning a given English pronoun to its Czech counterpart is to pick the best-fitting one from a bunch of candidates.
The set of candidates consists of all tectogrammatical nodes inthe aligned Czech sentence.
To allow the system to select no correspondence for a pronoun, we add aspecial candidate representing the null alignment.We represent the candidate ranking task as a discriminative log-linear model trained in a cost-sensitive,one-against-all strategy with label-dependent features (csoaa-ldf) provided by the Vowpal Wabbit5machine learning toolkit.
The feature weights are optimized by running stochastic gradient descent in 40passes over the training data.4.3 FeaturesThe feature set consists of the following types of features, which consider an English pronoun and aCzech candidate from the corresponding Czech tree:?
Original alignment features: presumably the most valuable set of features.
It indicates if there isa link between the two nodes in the original alignment and if there is any between their parents.?
Graph features: we designed these features to somehow reflect the distance between the nodes.The pair of aligned tectogrammatical trees is treated as a bipartite graph and a shortest path betweenthe nodes is found using a sequence of dependency edges and a single alignment link.
We appliedthe Dijkstra algorithm to find the shortest path.
We ensure that it only uses a single alignmentlink by setting large weights to alignments and small weights to dependency edges, i.e., 100 and 1,respectively.
The features then comprise the length of the shortest path and the sequence of edgelabels (parent, child, alignment).?
Grammatical features: these include lemmas, part-of-speech tags, reflexivity indicators, semanticrole labels both for each of the nodes individually and as a concatenation of the two.?
Combined features: these features combine selected features from the types mentioned above.
Theconcatenation of parents?
alignment and semantic role correspondence mimics the rule Nov?ak et al.
(2013) used to get better Czech counterparts for English it (see Section 4).
Furthermore, featurescombining lemmas with direct alignment or alignment through parents are included.5https://github.com/JohnLangford/vowpal_wabbit/wiki18Method Train TestA P R F A P R FORIGINAL ?
?
?
?
73.04 75.55 82.40 78.83SUPERVISED 88.37 90.18 90.34 90.26 84.50 88.52 86.40 87.45Table 2: Evaluation results of English-to-Czech pronoun alignment.
The quality is measured in terms ofaccuracy (A), precision (P), recall (R), and F1-score (F).4.4 Experiments and ResultsThe small amount of manually annotated data led us to evaluate alignment models by 10-fold cross-validation, with the results on the train and test partitions averaged over all folds.We measured the quality of produced the alignment links in terms of both accuracy and F1-score, i.e.,as the harmonic mean of precision and recall.
While accuracy positively scores also the cases when anode is correctly labeled as having no alignment, precision and recall neglect these cases at all, thusdescribing how good a method is in finding the correct counterpart for a node.Table 2 shows the performance of the supervised model with the best combination of features andlearning method parameters and compares it to the original alignment described in Section 3.1.
It showsan improvement of about 9% absolute in terms of both accuracy and F-score.5 Cross-lingual coreference resolver for EnglishIn this section, we describe cross-lingual coreference resolution.
The CR system we use definitely doesnot aim to compete with current state-of-the-art systems.
However, for the purpose of research on cross-lingual CR, it can be employed as a reasonable baseline.In Section 5.1, we describe the supervised CR model trained and tested on the data described inSection 5.2.
We elaborate more on the design of English and aligned features in Section 5.3 and Section5.4, respectively.
Finally, several variants of the CR system are evaluated and compared in Section 5.5.5.1 Coreference modelOur resolver employs a supervised model denoted as mention ranker by Ng (2010).
Its advantage lies injudging all antecedent candidates simultaneously, and then picking the candidate with the highest scoreas the predicted antecedent.
However, it is unable to exploit features that describe already formed clustersof mentions belonging to the same entity.
A typical issue related to ranking models is how to deal withnon-anaphoric mentions.
We use the approach introduced by Rahman and Ng (2009) ?
adding a specialcandidate that indicates no anaphor.Since this work focuses only on the so-called pronoun resolution, all the anaphor candidates are En-glish 3rd person central pronouns, i.e.
personal, possessive and reflexive pronouns.For every anaphor, we collect in the set of its antecedent candidates all semantic nouns6from theprevious sentence and the part of the current sentence prior to the anaphor.CR can be treated as a ranking task, so we represent it in the same way as we handled alignment inSection 3.1 ?
as a discriminative log-linear model trained in the csoaa-ldf strategy by the VowpalWabbit tool.
The feature weights are optimized by running stochastic gradient descent in 20-80 passes(the number differs across the experiments) over the training data.5.2 DataModels for coreference were trained on data extracted from sections 00?18 of the automatically analyzedPCEDT (as described in Section 3).
Sections 20?21 have been employed as development testing dataand Sections 22?24 as evaluation testing data.
The development set has been used to select the bestconfiguration, which was subsequently tested on the evaluation set.
The training, development, andevaluation set consist of 19,294, 1,988 and 2,591 instances with 86%, 67%, and 73% anaphoric instances,respectively.6Semantic nouns are all nouns as well as pronouns acting as a noun.195.3 English FeaturesA wide range of features used by us had already been proven to be beneficial for the task of CR inmultiple prior works.
The majority of the features presented here have already been used in the CRsystem for Czech (Nguy et al., 2009); we keep just the language-independent.
Furthermore, severalgrammatical and positional features proposed by Charniak and Elsner (2009) have been added.
Finally,the feature set has been enriched with the information on named entities and WordNet7classes.
All thefeatures disregard dependent members of a mention, describing just the head of the mention.
They canbe divided into several categories:?
Distance features: number of sentences, clauses, and words between the anaphor and the an-tecedent candidate; the order of the candidate,?
Grammatical features: morphological number and gender of both the anaphor and the antecedentcandidate, agreement in gender and number; part-of-speech tag,?
Function features: they exploit dependency labels on the analytical layer and semantic roles onthe tectogrammatical layer; they also include an indicator of whether the mention plays a role of anargument or an adjunct in the governing phrase,?
Parent features: the features of both nodes?
parents, e.g.
their lemmas or semantic roles, arecompared; an indicator of whether a mention is in coordination,?
Semantic features: WordNet classes the head word is assigned to,?
Named entity features: the named entity category and subcategory returned by Stanford namedentity recognizer.8This includes also the indicator of whether the mention is a name of a person,?
Charniak features: anaphor type (pronoun in subject position, in object position, possessive pro-noun, reflexive pronoun, other); antecedent type (noun, pronoun, other); antecedent syntactic type(subject, object, prepositional phrase, other).We denote this feature set as EN in all our experiments.5.4 Alignment featuresThe features from the Czech nodes aligned to the given English anaphor and antecedent candidate areobtained by moving to the corresponding Czech nodes and extracting the features as though we are tryingto resolve a Czech coreference link.
As outlined in Section 1, we designed two sets of features: CS andCS-COREF.The CS set consists of features introduced by Nguy et.
al (2009).
Most of them, namely the categoriesof distance, function, and parent features, are extracted in the same manner as the English ones in theprevious section.
Grammatical features also contain the full positional morphological tag as designed byHaji?c (2004).
Semantic features employ a different knowledge base, replacing WordNet by the Czechportion of EuroWordNet (Vossen, 1998).
In addition to the features more or less shared with the Englishside, the Czech feature set includes a probability estimate of the antecedent candidate co-occurring withits governing verb.
This statistics has been collected on Czech National Corpus (CNC, 2005).The CS-COREF set consists of a single binary feature indicating if there is a coreference relationbetween the nodes predicted by the Czech CR system (Nguy et al., 2009), or not.7http://wordnet.princeton.edu8http://nlp.stanford.edu/software/CRF-NER.shtml205.5 Experiments and ResultsThe different feature sets proposed in the previous sections suggest an obvious set of experiments.
Thesystem trained only on the monolingual EN features is put as a baseline.The rest our experimental setups use alignment features, forming three combinations with EN features:EN + CS, EN + CS-COREF, and EN + CS + CS-COREF.
Moreover, these three experiments can be runon the data provided either with the original or supervised alignment, which serves as extrinsic evaluationof alignment approaches.
This allows us to confirm or deny the hypothesis that the alignment plays asignificant role in cross-lingual CR (see Section 4).For comparison, we also evaluated the system that simply projects coreference links obtained by theCzech CR system to English.The performance of a CR system is usually measured by scores that treat CR as a clustering problem,e.g., MUC, B3, CEAF.
As this work focuses merely on a subset of coreference expressions ?
pronouns?
and we only compare different feature sets trained in the same framework, we resorted to the simplestmetrics with a sufficient expression power.
For each English pronoun we test if its predicted antecedenthits any of the true antecedents within the window of the current and the previous sentence.
Giventhis indicator we calculate precision, recall, and F1-score, which takes into account only the nodes forwhich a relation with another node exists ?
referential pronouns in this case (similarly to the alignmentevaluation in Section 4.4).
Likewise, in order to assess quality of detecting non-referential pronouns,accuracy is computed as well.The final results are shown in Table 3.
The overall higher numbers on the evaluation set than on thedevelopment set probably result from a different proportion of non-anaphoric pronouns (see Section 5.2).The smaller difference in F1-score than in accuracy also supports this explanation.The coreference projection scores a great deal below the baseline, which suggests that this approachis worth using only if manual annotation for at least a small amount of target language data (English inour case) is extremely expensive.As for the cross-lingual CR on the original alignment, all three feature set combinations have beatenthe baseline.
The EN + CS-COREF system confirmed the added value of the CS-COREF feature, which,unlike the CS feature set, conveys latent information on true Czech coreference links.
Even the combi-nation of all features performs worse than CS-COREF alone.Moving to the experiments with supervised alignment, we can see the findings from Section 4.4 con-firmed also in the extrinsic evaluation.
All three systems outperform not only the baseline, but also allthe systems working on the original alignment.
Moreover, both accuracy and F1-score order the threefeature combinations in the expected way, where the overall winner improves over the baseline in morethan 1% absolute.
This improvement is significant9at p-level p ?
0.1 but not at p-level p ?
0.05.6 DiscussionUsing information from Czech parallel texts in English CR led to an improvement in terms of automaticmeasures.
To see what the main aspects in which the Czech text positively impacts the CR performanceare, we compared the output of the system trained only on the EN features with systems working onthe EN + CS and EN + CS-COREF feature sets.
We used the results of the experiments run on thedevelopment set with supervised alignment for this comparison.Out of 1988 coreference instances in the development set, the EN + CS system improved the outputin 49 cases, while it worsened the output in 23 cases.
The rest remained unchanged.
Likewise, the EN +CS-COREF system scored better than the EN one in 63 instances, while it failed in 39 instances.The inspection of 10% instances for which the systems differed revealed that the cases when thecross-lingual system scored better than the monolingual concur with the language differences describedin Section 1.
We found that in these cases, the pronoun is often a pleonastic it or a possessive pronounwith a Czech reflexive possessive counterpart.
Finally, we noticed improvements in cases where theCzech antecedent is easier to determine due to agreement in gender and number.9Significance has been calculated by bootstrap resampling using 100,000 samples.21Setup Train Dev EvalA P R F A P R F A P R FEN 79.13 80.12 86.00 82.96 60.97 60.28 79.14 68.43 63.72 63.28 78.78 70.19Original alignmentCS-COREF projection 28.64 49.57 21.75 30.23 36.55 41.98 24.66 31.07 33.33 42.38 21.58 28.60EN + CS-COREF 78.31 79.27 85.25 82.15 61.77 61.07 80.45 69.44 64.30 63.74 79.62 70.80EN + CS 83.32 84.05 89.97 86.91 61.97 61.15 80.23 69.40 64.07 63.72 78.62 70.39EN + CS + CS-COREF 80.75 81.52 87.61 84.46 62.27 61.33 80.96 69.79 64.03 63.59 79.57 70.69Supervised alignmentCS-COREF projection 30.74 49.91 24.87 33.20 36.60 41.38 27.61 33.12 33.60 41.85 23.98 30.49EN + CS 83.19 83.98 89.73 86.76 62.27 61.42 80.60 69.72 64.53 64.13 79.09 70.83EN + CS-COREF 79.27 80.20 85.89 82.95 62.17 61.27 81.11 69.81 64.65 64.11 79.67 71.05EN + CS + CS-COREF 81.99 82.78 88.53 85.56 62.68 61.59 81.62 70.20 64.69 64.38 79.67 71.22Table 3: Evaluation results of monolingual CR, CR via projection, and cross-lingual CR system trainedand tested on the data with both the original and supervised alignment.
Performance is measured in termsof accuracy (A), precision (P), recall (R) and F1-score (F).We did not encounter an example of improvement for an English possessive pronoun having no Czechcounterpart.
We might have inspected too little data for it to appear.
However, these cases may getcovered after the features combining English and Czech features will be introduced.7 ConclusionThis work introduced a largely unexplored task in the field of CR ?
cross-lingual CR.
Given a Czech-English bitext, we sought to improve the performance of an English pronoun CR system by enrichingthe feature set with features from the aligned Czech text.
Consistent improvements over the monolingualsystem confirmed that cross-language differences in pronoun behavior are big enough to affect the result.Furthermore, we have found that the quality of alignment is vital for this task.In future work, we plan to apply this approach on a much larger parallel corpus and employ semi-supervised techniques to improve cross-lingual as well as monolingual CR.
Moreover, human translationin the bitext can be replaced with the output of SMT system to see if we can produce valuable featuresfor CR from the machine-translated source text.AcknowledgmentsThis work has been supported by the EU FP7 project Khresmoi (contract no.
257528).
This work hasbeen using language resources developed and/or stored and/or distributed by the LINDAT/CLARINproject of the Ministry of Education, Youth and Sports of the Czech Republic (project LM2010013).We would like to thank our colleague Ond?rej Du?sek for language correction and three anonymous re-viewers for their remarks and suggestions.ReferencesOnd?rej Bojar, Zden?ek?Zabokrtsk?y, Ond?rej Du?sek, Petra Galu?s?c?akov?a, Martin Majli?s, David Mare?cek, Ji?r??
Mar?s?
?k,Michal Nov?ak, Martin Popel, and Ale?s Tamchyna.
2012.
The joy of parallelism with CzEng 1.0.
In Proceedingsof LREC 2012, Istanbul, Turkey.
European Language Resources Association.David Burkett and Dan Klein.
2008.
Two languages are better than one (for syntactic parsing).
In Proceedings ofthe Conference on Empirical Methods in Natural Language Processing, Stroudsburg, PA, USA.
Association forComputational Linguistics.David Burkett, John Blitzer, and Dan Klein.
2010.
Joint parsing and alignment with weakly synchronized gram-mars.
In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of theAssociation for Computational Linguistics, Stroudsburg, PA, USA.
Association for Computational Linguistics.Eugene Charniak and Micha Elsner.
2009.
EM works for pronoun anaphora resolution.
In Proceedings of the 12thConference of the European Chapter of the Association for Computational Linguistics, Stroudsburg, PA, USA.Association for Computational Linguistics.22CNC.
2005.
Czech national corpus ?
SYN2005.
Prague, Czech Republic.
Institute of the Czech National Corpus.Dipanjan Das and Slav Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projections.In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human LanguageTechnologies - Volume 1, Stroudsburg, PA, USA.
Association for Computational Linguistics.Jos?e Guilherme Camargo de Souza and Constantin Orsan.
2011.
Can projected chains in parallel corpora helpcoreference resolution?
In Proceedings of the 8th International Conference on Anaphora Processing andApplications, Berlin, Heidelberg.
Springer-Verlag.Pascal Denis and Jason Baldridge.
2007.
A ranking approach to pronoun resolution.
In Proceedings of the 20thInternational Joint Conference on Artifical Intelligence, San Francisco, CA, USA.Morgan Kaufmann PublishersInc.Qin Gao and Stephan Vogel.
2008.
Parallel implementations of word alignment tool.
In Software Engineer-ing, Testing, and Quality Assurance for Natural Language Processing, Stroudsburg, PA, USA.
Association forComputational Linguistics.Liane Guillou, Christian Hardmeier, Aaron Smith, Jrg Tiedemann, and Bonnie Webber.
2014.
ParCor 1.0: Aparallel pronoun-coreference corpus to support statistical MT.
In Proceedings of the 9th International Confer-ence on Language Resources and Evaluation (LREC-2014), Reykjavik, Iceland.
European Language ResourcesAssociation.Jan Haji?c, Eva Haji?cov?a, Jarmila Panevov?a, Petr Sgall, Ond?rej Bojar, Silvie Cinkov?a, Eva Fu?c?
?kov?a, MarieMikulov?a, Petr Pajas, Jan Popelka, Ji?r??
Semeck?y, Jana?Sindlerov?a, Jan?St?ep?anek, Josef Toman, Zdeka Ure?sov?a,and Zden?ek?Zabokrtsk?y.
2012.
Announcing Prague Czech-English Dependency Treebank 2.0.
In Proceedingsof the 8th International Conference on Language Resources and Evaluation (LREC 2012), Istanbul, Turkey.European Language Resources Association.Jan Haji?c.
2004.
Disambiguation of Rich Inflection (Computational Morphology of Czech).
Nakladatelstv?
?Karolinum.Sanda M. Harabagiu and Steven J. Maiorano.
2000.
Multilingual coreference resolution.
In Proceedings of theSixth Conference on Applied Natural Language Processing, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Martin Wittorff Haulrich.
2012.
Data-driven bitext dependency parsing and alignment.
Ph.D. thesis, CopenhagenBusiness School.Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel.
2006.
OntoNotes: the90% solution.
In Proceedings of the Human Language Technology Conference of the NAACL, CompanionVolume: Short Papers, Stroudsburg, PA, USA.
Association for Computational Linguistics.Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.
2012.
Multilingual named entity recognition using paralleldata and metadata from Wikipedia.
In Proceedings of the 50th Annual Meeting of the Association for Computa-tional Linguistics: Long Papers - Volume 1, Stroudsburg, PA, USA.
Association for Computational Linguistics.Qi Li, Haibo Li, Heng Ji, Wen Wang, Jing Zheng, and Fei Huang.
2012.
Joint bilingual name tagging forparallel corpora.
In Proceedings of the 21st ACM International Conference on Information and KnowledgeManagement, New York, NY, USA.
ACM.Linguistic Data Consortium.
1999.
Penn Treebank 3.
LDC99T42.Ruslan Mitkov and Catalina Barbu.
2003.
Using bilingual corpora to improve pronoun resolution.
Languages incontrast, 4(2).Vincent Ng.
2010.
Supervised noun phrase coreference research: The first fifteen years.
In Proceedings of the48th Annual Meeting of the Association for Computational Linguistics, Stroudsburg, PA, USA.
Association forComputational Linguistics.Giang Linh Nguy, V?aclav Nov?ak, and Zden?ek?Zabokrtsk?y.
2009.
Comparison of classification and rankingapproaches to pronominal anaphora resolution in Czech.
In Proceedings of the SIGDIAL 2009 Conference,London, UK.
The Association for Computational Linguistics.Michal Nov?ak, Anna Nedoluzhko, and Zden?ek?Zabokrtsk?y.
2013.
Translation of ?it?
in a deep syntax frame-work.
In 51st Annual Meeting of the Association for Computational Linguistics Proceedings of the Workshopon Discourse in Machine Translation, Sofija, Bulgaria.
Omnipress, Inc.23Franz Josef Och and Hermann Ney.
2000.
Improved statistical alignment models.
In Proceedings of the 38thAnnual Meeting on Association for Computational Linguistics, Stroudsburg, PA, USA.
Association for Compu-tational Linguistics.Maciej Ogrodniczuk.
2013.
Translation- and projection-based unsupervised coreference resolution for Polish.
InLanguage Processing and Intelligent Information Systems, number 7912, Berlin / Heidelberg.
Springer.Martin Popel and Zden?ek?Zabokrtsk?y.
2010.
TectoMT: Modular NLP framework.
In Lecture Notes in ArtificialIntelligence, Proceedings of the 7th International Conference on Advances in Natural Language Processing(IceTAL 2010), volume 6233, Berlin / Heidelberg.
Springer.Oana Postolache, Dan Cristea, and Constantin Orasan.
2006.
Transferring coreference chains through word align-ment.
In Proceedings of the Fifth International Conference on Language Resources and Evaluation, Genoa,Italy.
European Language Resources Association.Randolph Quirk, Sidney Greenbaum, Geoffrey Leech, and Jan Svartvik.
1985.
A Comprehensive Grammar of theEnglish Language.
Longman.Altaf Rahman and Vincent Ng.
2009.
Supervised models for coreference resolution.
In Proceedings of the 2009Conference on Empirical Methods in Natural Language Processing: Volume 2 - Volume 2, Stroudsburg, PA,USA.
Association for Computational Linguistics.Altaf Rahman and Vincent Ng.
2012.
Translation-based projection for multilingual coreference resolution.
InProceedings of the 2012 Conference of the North American Chapter of the Association for Computational Lin-guistics: Human Language Technologies, Stroudsburg, PA, USA.
Association for Computational Linguistics.Rudolf Rosa, Ond?rej Du?sek, David Mare?cek, and Martin Popel.
2012.
Using parallel features in parsing ofmachine-translated sentences for correction of grammatical errors.
In Proceedings of the Sixth Workshop onSyntax, Semantics and Structure in Statistical Translation, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Petr Sgall, Eva Haji?cov?a, and Jarmila Panevov?a.
1986.
The Meaning of the Sentence in Its Semantic and PragmaticAspects.
D. Reidel Publishing Company, Dordrecht.Petr Sgall.
1967.
Generativn??
popis jazyka a ?cesk?a deklinace.
Academia, Prague, Czech Republic.David A. Smith and Noah A. Smith.
2004.
Bilingual parsing with factored estimation: Using English to parseKorean.
In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing.
Asso-ciation for Computational Linguistics.Kate?rina Veselovsk?a, Giang Linh Nguy, and Michal Nov?ak.
2012.
Using Czech-English parallel corpora inautomatic identification of ?it?.
In The Fifth Workshop on Building and Using Comparable Corpora,?Istanbul,Turkey.
European Language Resources Association.Piek Vossen, editor.
1998.
EuroWordNet: A Multilingual Database with Lexical Semantic Networks.
KluwerAcademic Publishers, Norwell, MA, USA.Tao Zhuang and Chengqing Zong.
2010.
Joint inference for bilingual semantic role labeling.
In Proceedings of the2010 Conference on Empirical Methods in Natural Language Processing, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.24
