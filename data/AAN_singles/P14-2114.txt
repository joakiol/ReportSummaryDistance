Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 700?705,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsA Simple Bayesian Modelling Approach to Event Extraction from TwitterDeyu Zhou?
?Liangyu Chen?Yulan He?
?School of Computer Science and Engineering, Key Laboratory of Computer Networkand Information Integration, Ministry of Education, Southeast University, China?State Key Laboratory for Novel Software Technology, Nanjing University, China?School of Engineering and Applied Science, Aston University, UKd.zhou@seu.edu.cn, cly1cn@126.com, y.he@cantab.netAbstractWith the proliferation of social mediasites, social streams have proven to con-tain the most up-to-date information oncurrent events.
Therefore, it is crucial toextract events from the social streams suchas tweets.
However, it is not straight-forward to adapt the existing event ex-traction systems since texts in social me-dia are fragmented and noisy.
In this pa-per we propose a simple and yet effec-tive Bayesian model, called Latent EventModel (LEM), to extract structured rep-resentation of events from social media.LEM is fully unsupervised and does notrequire annotated data for training.
Weevaluate LEM on a Twitter corpus.
Ex-perimental results show that the proposedmodel achieves 83% in F-measure, andoutperforms the state-of-the-art baselineby over 7%.1 IntroductionEvent extraction is to automatically identify eventsfrom text with information about what happened,when, where, to whom, and why.
Previous work inevent extraction has focused largely on news ar-ticles, as the newswire texts have been the bestsource of information on current events (Hogen-boom et al, 2011).
Approaches for event ex-traction include knowledge-based (Piskorski et al,2007; Tanev et al, 2008), data-driven (Piskorskiet al, 2008) and a combination of the above twocategories (Grishman et al, 2005).
Knowledge-based approaches often rely on linguistic and lexi-cographic patterns which represent expert domainknowledge for particular event types.
They lackthe flexibility of porting to new domains since ex-traction patterns often need to be re-defined.
Data-driven approaches require large annotated data totrain statistical models that approximate linguisticphenomena.
Nevertheless, it is expensive to obtainannotated data in practice.With the increasing popularity of social media,social networking sites such as Twitter have be-come an important source of event information.As reported in (Petrovic et al, 2013), even 1% ofthe public stream of Twitter contains around 95%of all the events reported in the newswire.
Never-theless, the social stream data such as Twitter datapose new challenges.
Social media messages areoften short and evolve rapidly over time.
As such,it is not possible to know the event types a prioriand hence violates the use of existing event extrac-tion approaches.Approaches to event extraction from Twittermake use of a graphical model to extract canonicalentertainment events from tweets by aggregatinginformation across multiple messages (Benson etal., 2011).
In (Liu et al, 2012), social events in-volving two persons are extracted from multiplesimilar tweets using a factor graph by harvestingthe redundancy in tweets.
Ritter et al (2012) pre-sented a system called TwiCal which extracts anopen-domain calendar of significant events repre-sented by a 4-tuple set including a named entity,event phrase, calendar date, and event type fromTwitter.In our work here, we notice a very importantproperty in social media data that the same eventcould be referenced by high volume messages.This property allows us resort to statistical mod-els that can group similar events based on the co-occurrence patterns of their event elements.
Here,event elements include named entities such as per-son, company, organization, date/time, location,and the relations among them.
We can treat anevent as a latent variable and model the genera-tion of an event as a joint distribution of its indi-vidual event elements.
We thus propose a LatentEvent Model (LEM) which can automatically de-tect events from social media without the use oflabeled data.700LatentEventModelPost-processingTweets Pre-processingPOSTaggingNamed EntityRecognition StemmingTemporal ResolutionExtracted EventsName Entity Time Location Key words...AmyWinehouse2011/07/23 LondonDie,Death, ..Space ShuttleAtlantis2011/07/08KennedySpace Center Land ...Figure 1: The proposed framework for event extraction from tweets.Our work is similar to TwiCal in the sense thatwe also focus on the extraction of structured repre-sentation of events from Twitter.
However, TwiCalrelies on a supervised sequence labeler trainedon tweets annotated with event mentions for theidentification of event-related phrases.
We pro-pose a simple Bayesian modelling approach whichis able to directly extract event-related keywordsfrom tweets without supervised learning.
Also,TwiCal uses G2test to choose an entity y withthe strongest association with a date d to form abinary tuple ?y, d?
to represent an event.
On thecontrary, the structured representation of eventscan be directly extracted from the output of ourLEM model.
We have conducted experiments ona Twitter corpus and the results show that our pro-posed approach outperforms TwiCal, the state-of-the-art open event extraction system, by 7.7% inF-measure.2 MethodologyEvents extracted in our proposed framework arerepresented as a 4-tuple ?y, d, l, k?, where y standsfor a non-location named entity, d for a date, l for alocation, and k for an event-related keyword.
Eachevent mentioned in tweets can be closely depictedby this representation.
It should be noted that forsome events, one or more elements in their corre-sponding tuples might be absent as their related in-formation is not available in tweets.
As illustratedin Figure 1, our proposed framework consists ofthree main steps, pre-processing, event extractionbased on the LEM model and post-processing.The details of our proposed framework are de-scribed below.2.1 Pre-processingTweets are pre-processed by time expressionrecognition, named entity recognition, POS tag-ging and stemming.Time Expression Recognition.
Twitter usersmight represent the same date in various forms.For example, ?tomorrow?, ?next Monday?, ?
Au-gust 23th?
in tweets might all refer to the sameday, depending on the date that users wrote thetweets.
To resolve the ambiguity of the time ex-pressions, SUTime1(Chang and Manning, 2012)is employed, which takes text and a reference dateas input and outputs a more accurate date whichthe time expression refers to.Named Entity Recognition.
Named entityrecognition (NER) is a crucial step since theresults would directly impact the final extracted4-tuple ?y, d, l, k?.
It is not easy to accuratelyidentify named entities in the Twitter data sincetweets contain a lot of misspellings and abbrevi-ations.
However, it is often observed that eventsmentioned in tweets are also reported in newsarticles in the same period (Petrovic et al, 2013).Therefore, named entities mentioned in tweets arelikely to appear in news articles as well.
We thusperform named entity recognition in the followingway.
First, a traditional NER tool such as theStanford Named Entity Recognizer2is used toidentify named entities from the news articlescrawled from BBC and CNN during the sameperiod that the tweets were published.
The recog-nised named entities from news are then used tobuild a dictionary.
Named entities from tweetsare extracted by looking up the dictionary throughfuzzy matching.
We have also used a namedentity tagger trained specifically on the Twitterdata3(Ritter et al, 2011) to directly extract namedentities from tweets.
However, as will be shownin Section 3 that using our constructed dictionaryfor named entity extraction gives better results.We distinguish between location entities, denotedas l, and non-location entities such as person ororganization, denoted as y.1http://nlp.stanford.edu/software/sutime.shtml2http://nlp.stanford.edu/software/CRF-NER.shtml3http://github.com/aritter/twitter-nlp701Finally, we use a POS tagger4trained ontweets (Gimpel et al, 2011) to perform POS tag-ging on the tweets data and apart from the pre-viously recognised named entities, only wordstagged with nouns, verbs or adjectives are kept.These remaining words are subsequently stemmedand words occurred less than 3 times are filtered.After the pre-processing step, non-location enti-ties y, locations l, dates d and candidate keywordsof the tweets are collected as the input to the LEMmodel for event extraction.2.2 Event Extraction using the Latent EventModel (LEM)We propose an unsupervised latent variable model,called the Latent Event Model (LEM), to extractevents from tweets.
The graphical model of LEMis shown in Figure 2.MNy?
?d l keE?
?
?
??
?
?
?Figure 2: Laten Event Model (LEM).In this model, we assume that each tweet mes-sage m ?
{1..M} is assigned to one event in-stance e, while e is modeled as a joint distributionover the named entities y, the date/time d whenthe event occurred, the location l where the eventoccurred and the event-related keywords k. Thisassumption essentially encourages events that in-volve the same named entities, occur at the sametime and in the same location and have similarkeyword to be assigned with the same event.The generative process of LEM is shown below.?
Draw the event distribution pie?Dirichlet(?)?
For each event e ?
{1..E}, draw multino-mial distributions ?e?
Dirichlet(?),?e?Dirichlet(?),?e?
Dirichlet(?),?e?Dirichlet(?).4http://www.ark.cs.cmu.edu/TweetNLP?
For each tweet w?
Choose an event e ?
Multinomial(pi),?
For each named entity occur in tweetw, choose a named entity y ?Multinomial(?e),?
For each date occur in tweet w, choosea date d ?
Multinomial(?e),?
For each location occur in tweet w,choose a location l ?
Multinomial(?e),?
For other words in tweet w, choose aword k ?
Multinomial(?e).We use Collapsed Gibbs Sampling (Griffithsand Steyvers, 2004) to infer the parameters of themodel and the latent class assignments for events,given observed data D and the total likelihood.Gibbs sampling allows us repeatedly sample froma Markov chain whose stationary distribution isthe posterior of emfrom the distribution over thatvariable given the current values of all other vari-ables and the data.
Such samples can be used toempirically estimate the target distribution.
Let-ting the subscript ?m denote a quantity that ex-cludes data from mth tweet , the conditional pos-terior for emis:P (em= t|e?m,y,d, l,z,?)
?n?mt+ ?M + E??Y?y=1?n(m)t,yb=1(nt,y?
b+ ?)?n(m)tb=1(nt?
b+ Y ?)?D?d=1?n(m)t,db=1(nt,d?
b+ ?)?n(m)tb=1(nt?
b+D?)?L?l=1?n(m)t,lb=1(nt,l?
b+ ?)?n(m)tb=1(nt?
b+ L?)?V?k=1?n(m)t,kb=1(nt,k?
b+ ?)?n(m)tb=1(nt?
b+ V ?
)where ntis the number of tweets that have beenassigned to the event t; M is the total number oftweets, nt,yis the number of times named entity yhas been associated with event t; nt,dis the num-ber of times dates d has been associated with eventt; nt,lis the number of times locations l has beenassigned with event t; nt,kis the number of timeskeyword k has associated with event t, counts with(m) notation denote the counts relating to tweetm only.
Y,D,L, V are the total numbers of dis-tinct named entities, dates, locations, and wordsappeared in the whole Twitter corpus respectively.E is the total number of events which needs to beset.Once the class assignments for all events areknown, we can easily estimate the model param-eters {pi,?,?,?,?}.
We set the hyperparame-ters ?
= ?
= ?
= ?
= ?
= 0.5 and run Gibbs702sampler for 10,000 iterations and stop the iterationonce the log-likelihood of the training data con-verges under the learned model.
Finally we selectan entity, a date, a location, and the top 2 keywordsof the highest probability of every event to form a4-tuple as the representation of that event.2.3 Post-processingTo improve the precision of event extraction, weremove the least confident event element from the4-tuples using the following rule.
If P (element)is less than1?P (S), where P (S) is the sum ofprobabilities of the other three elements and ?
is athreshold value and is set to 5 empirically, the ele-ment will be removed from the extracted results.3 ExperimentsIn this section, we first describe the Twitter corpusused in our experiments and then present how webuild a baseline based on the previously proposedTwiCal system (Ritter et al, 2012), the state-of-the-art open event extraction system on tweets.
Fi-nally, we present our experimental results.3.1 DatasetWe use the First Story Detection (FSD)dataset (Petrovic et al, 2013) in our experi-ment.
It consists of 2,499 tweets which aremanually annotated with the corresponding eventinstances resulting in a total of 27 events.
Thetweets were published between 7th July and 12thSeptember 2011.
These events cover a range ofcategories, from celebrity news to accidents, andfrom natural disasters to science discoveries.
Itshould be noted here that some event elementssuch as location is not always available in thetweets.
Automatically inferring geolocation of thetweets is a challenging task and will be consideredin our future work.
For the tweets without timeexpressions, we used the tweets?
publication datesas a default.
The number of tweets for each eventranges from 2 to around 1000.
We believe that inreality, events which are mentioned in very fewtweets are less likely to be significant.
Therefore,the dataset was filtered by removing the eventswhich are mentioned in less than 10 tweets.
Thisresults in a final dataset containing 2468 tweetsannotated with 21 events.3.2 Baseline constructionThe baseline we chose is TwiCal (Ritter et al,2012).
The events extracted in the baseline arerepresented as a 3-tuple ?y, d, k?5, where y standsfor a non-location named entity, d for a date andk for an event phrase.
We re-implemented thesystem and evaluate the performance of the base-line on the correctness of the exacted three ele-ments excluding the location element.
In the base-line approach, the tuple ?y, d, k?
are extracted inthe following ways.
Firstly, a named entity rec-ognizer (Ritter et al, 2011) is employed to iden-tify named entities.
The TempEx (Mani and Wil-son, 2000) is used to resolve temporal expressions.For each date, the baseline approach chose the en-tity y with the strongest association with the dateand form the binary tuple ?y, d?
to represent anevent.
An event phrase extractor trained on an-notated tweets is required to extract event-relatedphrases.
Due to the difficulties of re-implementingthe sequence labeler without knowing the actualfeatures set and the annotated training data, we as-sume all the event-related phrases are identifiedcorrectly and simply use the event trigger wordsannotated in the FSD corpus as k to form the event3-tuples.
It is worth noting that the F-measure re-ported for the event phrase extraction is only 64%in the baseline approach (Ritter et al, 2012).3.3 Evaluation MetricTo evaluate the performance of the propose ap-proach, we use precison, recall, and F ?measure as in general information extraction sys-tems (Makhoul et al, 1999).
For the 4-tuple?y, d, l, k?, the precision is calculated based on thefollowing criteria:1.
Do the entity y, location l and date d that wehave extracted refer to the same event?2.
Are the keywords k in accord with the eventthat other extracted elements y, l, d refer toand are they informative enough to tell uswhat happened?If the extracted representation does not containkeywords, its precision is calculated by check-ing the criteria 1.
If the extracted representationcontains keywords, its precision is calculated bychecking both criteria 1 and 2.3.4 Experimental ResultsThe number of events, E, in the LEM modelis set to 25.
The performance of the proposed5TwiCal also groups event instances into event types suchas ?Sport?
or ?Politics?
using LinkLDA which is not consid-ered here.703Method Tuple Evaluated Precision Recall F-measureBaseline ?y, d, k?
75% 76.19% 75.59%Proposed ?y, d, l?
96% 80.95% 87.83%Proposed ?y, d, l, k?
92% 76.19% 83.35%Table 1: Comparison of the performance of eventextraction on the FSD dataset.Method Tuple Evaluated Precision Recall F-measureTW-NER ?y, d, l?
88% 76.19% 80.35%TW-NER ?y, d, l, k?
84% 76.19% 79.90%NW-NER ?y, d, l?
96% 80.95% 87.83%NW-NER ?y, d, l, k?
92% 76.19% 83.35%Table 2: Comparison of the performance of eventextraction using different NER method.framework is presented in Table 1.
The base-line re-implemented here can only output 3-tuples?y, d, k?
and we simply use the gold standard eventtrigger words to assign to k. Still, we observethat compared to the baseline approach, the per-formance of our proposed framework evaluated onthe 4-tuple achieves nearly 17% improvement onprecision.
The overall improvement on F-measureis around 7.76%.3.5 Impact of Named Entity RecognitionWe experimented with two approaches for namedentity recognition (NER) in preprocessing.
Oneis to use the NER tool trained specifically on theTwitter data (Ritter et al, 2011), denoted as ?TW-NER?
in Table 2.
The other uses the traditionalStanford NER to extract named entities from newsarticles published in the same period and thenperform fuzzy matching to identify named enti-ties from tweets.
The latter method is denotedas ?NW-NER?
in Table 2.
It can be observedfrom Table 2 that by using NW-NER, the per-formance of event extraction system is improvedsignificantly by 7.5% and 3% respectively on F-measure when evaluated on 3-tuples (without key-words) or 4-tuples (with keywords).3.6 Impact of the Number of Events EWe need to set the number of events E in theLEM model.
Figure 3 shows the performance ofevent extraction versus different value of E. It canbe observed that the performance of the proposedframework improves with the increase of the valueofE until it reaches 25, which is close to the actualnumber of events in our data.
If further increasingE, we notice more balanced precision/recall val-ues and a relatively stable F-measure.
This showsthat our LEM model is less sensitive to the num-ber of events E so long as E is set to a relativelylarger value.10 15 20 25 30 35 400.20.30.40.50.60.70.80.9performanceEPrecisionRecallF-meatureFigure 3: The performance of the proposed frame-work with different number of events E.4 Conclusions and Future WorkIn this paper we have proposed an unsupervisedBayesian model, called the Latent Event Model(LEM), to extract the structured representation ofevents from social media data.
Instead of em-ploying labeled corpora for training, the proposedmodel only requires the identification of namedentities, locations and time expressions.
After that,the model can automatically extract events whichinvolving a named entity at certain time, location,and with event-related keywords based on the co-occurrence patterns of the event elements.
Ourproposed model has been evaluated on the FSDcorpus.
Experimental results show our proposedframework outperforms the state-of-the-art base-line by over 7% in F-measure.
In future work,we plan to investigate inferring geolocations au-tomatically from tweets.
We also intend to studya better method to infer date more accurately fromtweets and explore efficient ranking strategies torank evens extracted for a better presentation ofresults.AcknowledgmentsThis work was funded by the National NaturalScience Foundation of China (61103077), Ph.D.Programs Foundation of Ministry of Educationof China for Young Faculties (20100092120031),Scientific Research Foundation for the ReturnedOverseas Chinese Scholars, State Education Min-istry, the Fundamental Research Funds for theCentral Universities, and the UK?s EPSRC grantEP/L010690/1.704ReferencesEdward Benson, Aria Haghighi, and Regina Barzilay.2011.
Event discovery in social media feeds.
InProceedings of the 49th Annual Meeting of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies - Volume 1, HLT ?11, pages389?398, Stroudsburg, PA, USA.
Association forComputational Linguistics.Angel X. Chang and Christopher D. Manning.
2012.Sutime: A library for recognizing and normaliz-ing time expressions.
In 8th International Confer-ence on Language Resources and Evaluation (LREC2012).Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: Annotation, features, and experiments.In Proceedings of ACL.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
In Proceedings of the Na-tional Academy of Sciences 101 (Suppl.
1), page5228C5235.Ralph Grishman, David Westbrook, and Adam Meyers.2005.
Nyu?s english ace 2005 system description.In ACE 05 Evaluation Workshop.Frederik Hogenboom, Flavius Frasincar, Uzay Kay-mak, and Franciska de Jong.
2011.
An overview ofevent extraction from text.
In Workshop on Detec-tion, Representation, and Exploitation of Events inthe Semantic Web (DeRiVE 2011) at Tenth Interna-tional Semantic Web Conference (ISWC2011), pages48?57.Xiaohua Liu, Xiangyang Zhou, Zhongyang Fu, FuruWei, and Ming Zhou.
2012.
Exacting social eventsfor tweets using a factor graph.
In Proceedings ofthe Twenty-Sixth AAAI Conference on Artificial In-telligence, pages 1692?1698.John Makhoul, Francis Kubala, Richard Schwartz, andRalph Weischedel.
1999.
Performance measures forinformation extraction.
In Proceedings of DARPABroadcast News Workshop.Inderjeet Mani and George Wilson.
2000.
Robust tem-poral processing of news.
In Proceedings of the38th Annual Meeting on Association for Computa-tional Linguistics, ACL ?00, pages 69?76, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Sasa Petrovic, Miles Osborne, Richard McCreadie,Craig Macdonald, Iadh Ounis, and Luke Shrimpton.2013.
Can twitter replace newswire for breakingnews?
In Proceedings of ICWSM?13.J.
Piskorski, H. Tanev, and P. Oezden Wennerberg.2007.
Extracting violent events from on-line newsfor ontology population.
In Business InformationSystems, pages 287?300.J.
Piskorski, H. Tanev, M. Atkinson, and E. VanDer Goot.
2008.
Cluster-centric approach to newsevent extraction.
In International Conference onNew Trends in Multimedia and Network InformationSystems, pages 276?290.Alan Ritter, Sam Clark, Oren Etzioni, et al 2011.Named entity recognition in tweets: an experimentalstudy.
In Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, pages1524?1534.
Association for Computational Linguis-tics.Alan Ritter, Mausam, Oren Etzioni, and Sam Clark.2012.
Open domain event extraction from twitter.In Proceedings of the 18th ACM SIGKDD Inter-national Conference on Knowledge Discovery andData Mining, KDD ?12, pages 1104?1112, NewYork, NY, USA.
ACM.H.
Tanev, J. Piskorski, and M. Atkinson.
2008.
Real-time news event extraction for global crisis monitor-ing.
In 13th International Conference on Applica-tions of Natural Language to Information Systems(NLDB), pages 207?218.705
