A Logic for Semantic Interpretation IEugene Charniak and Robert GoldmanDepartment of Computer ScienceBrown University, Box 1910Providence RI 02912Abst rac tWe propose that logic (enhanced to encode probabilityinformation) is a good way of characterizing semantic in-terpretation.
In support of this we give a fragment ofan axiomatization for word-sense disambiguation, oun-phrase (and verb) reference, and case disambiguation.We describe an inference ngine (Frail3) which actuallytakes this axiomatization and uses it to drive the semanticinterpretation process.
We claim three benefits from thisscheme.
First, the interface between semantic interpreta-tion and pragmatics has always been problematic, sinceall of the above tasks in general require pragmatic infer-ence.
Now the interface is trivial, since both semanticinterpretation and pragmatics use the same vocabularyand inference ngine.
The second benefit, related to thefirst, is that semantic guidance of syntax is a side effectof the interpretation.
The third benefit is the eleganceof the semantic interpretation theory.
A few simple rulescapture a remarkable diversity of semantic phenomena.I .
In t roduct ionThe use of logic to codify natural anguage syntax is wellknown, and many current systems can parse directly offtheir axiomatizations (e.g.,)\[l\].
Many of these systemssimultaneously construct an intermediate "logical form"using the same machinery.
At the other end of languageprocessing, logic is a well-known tool for expressing thepragmatic information eeded for plan recognition andspeech act recognition \[2-4\].
In between these extremeslogic appears much less.
There has been some movementin the direction of placing semantic interpretation on amore logical footing \[5,6\], but it is nothing like what hashappened at the extremes of the ~anguage understandingprocess.To some degree this is understandable.
These "mid-dle" parts, such as word-sense disambiguation, nounphrase reference, case disambiguation, etc.
are notori-ously difficult, and poorly understood, at least comparedto things like syntax, and the construction of interme-diate logical form.
Much of the reason these areas arel This work has been supported in part by the National ScienceFoundation under grants IST 8416034 and IST 8515005 and Office~)f Nav~l Research under grant N00014-79-C-0529.so dark is that they are intimately bound up with prag-matic reasoning.
The correct sense of a word depends oncontext, as does pronoun resolution, etc.Here we rectify this situation by presenting an ax-iomatization of fragment of semantic interpretation, o-tably including many aspects previously excluded: word-sense disambiguation, oun-phrase reference determina-tion, case determination, and syntactic disambiguation.Furthermore we describe an inference engine, Frail3,which can use the logical formulation to carry out seman-tic interpretation.
The description of Frail3 is brief, sincethe present paper is primarily concerned with semanticinterpretation.
For a more detailed description, see \[7\].The work closest to what we present is that by Hobbs\[5\]; however, he handles only noun-phrase r ference fromthe above list, and he does not consider intersententialinfluences at all.Our system, Wimp2 (which uses Frail3), is quitepretty in *,wo respects.
First, it integrates semantic andpragmatic processing into a uniform whole, all done inthe logic.
Secondly, it provides an elegant and conciseway to specify exactly what has to be done by a seman-tic interpreter.
As we shall see, a system that is roughlycomparable to other state-of-the-art semantic interpreta-tion systems \[6,8\] can be written down in a pagc or so oflogical rules.Wimp2 has been implemented and works on all ofthe examples in this paper.I I .
Vocabu lar ies87Let us start by giving an informal semantics for the spe-cial predicates and terms used by the system.
Since weare doing semantic interpretation, we are translating be-tween a syntactic tree on one hand and the logical, or in-ternal, representation  the other.
Thus.we distinguishthree vocabularies: one for trees, one for the internal rep-resentation, and one to aid in the translation between thetwo.The vocabulary for syntactic trees assumes that eachword in the sentence is represented as a word instancewhich is represented as a word with a numerical post-fix (e.g., boy22).
A word instance is associated with theactual lexical entry by the predicate word-inst:(word-inst word-instance part-ofospeech lexwal-item).For example, (word-inst case26 noun case).
(We use "partof speech" to denote those syntactic categories that aredirectly above the terminal symbols in the grammars,that is, directly above words.
)The relations between word instances are encodedwith two predicates: syn-pos, and syn-pp.
Syn-pos(syn-pos relation head sub-constituent),indicates that the sub-constituent is the relation of thehead.
We distinguish between positional relations andthose indicated by prepositional phrases, which use thepredicate syn-pp, but otherwise look the same.
Thepropositions denoting syntactic relations are generatedduring the parse.
The parser follows all possible parsesin a breadth-first search and outputs propositions on aword-by-word basis.
If there is more than one parse andthey disagree on the propositional output, a disjunctionof the outputs is a.~ert.ed into the database.
The corre-spondence between trees and formulas is as follows:Treess - -  up (vp ... head-v...)vp .
.
.
.
head-v np ...vp ~ ... head-v nplnp2 ...vp .
.
.
.
head-v ...(pp prep ...)pp ~ prep npFormulas(syn-pos subject head-v np)head-v symbol is s symbol(syn-pos object head-v up)(syn-pos indirect-objecthead-v npl)(syn-pos object head-v npg)(syn-pp head-prep head-vprep)(-yn-pp prel>-np prep rip)np - -  ... head-n ... head-n symbol is np symbolnp - -  pronoun pronoun symbol isnp symbolnp - -  propernoun propernoun symbol isnp symbolnp .
.
.
.
adj head-n ... (syn-pos adj adj head-n)np .
.
.
.
head-n ...(pp prep ...)up that ss - -  np (vp ... copula(pp prep ...))s - -  np (vp ... copulaadj)(syn-pp head-prep head-nprep)s symbol is np symbol(syn-pp head-prep np prep)(syn-pos adj ad3 np)This is enough to express a wide variety of simple declar-ative sentences.
Furthermore, since our current parserimplements a transformational ccount of imperatives,questions (both yes-no and wh), complement construc-tions, and subordinate clauses, these are automaticallyhandled by the above as well.
For example, given an ac-count of "Jack wants to borrow the book."
as derivedfrom "Jack wants (np that (s Jack borrow the book)).
"or something similar, then the above rules would producethe following for both (we also indicate after what wordthe formula is produced):88WordsJackwantstoborrowthebookI"ornnl a.s(word-inst jackl propernoun jack)(word-inst want1 verb want)(syn-pos subject want1 jackl)(word-inst borrowl verb borrow)(syn-pos object want1 borrowl)(syn-pos subject borrow1 jack1)(word-inst bookl noun book)(syn-pos object borrowl bookl)This is, of course, a fragment, and most things are nothandled by this analysis: negation, noun-noun combina-tions, particles, auxiliary verbs, etc.Now let us consider the internal representation usedfor inference about the world.
Here we use a simplepredicate-calculus version of frames, and slots.
We as-sume only two predicates for this: == and inst.
Inst,(inst instance frame),is a two-place predicate on an instance of a frame andthe frame itself, where a "frame" is a set of objects, allof which are of the same natural kind.
Thus (inst boylboy-) asserts that boyl is a member of the set of boys, de-noted by boy-.
(Frames are symbols containing hyphens,e.g., supermarket-shoping.
Where a single English word issufficiently descriptive, the hyphen is put at the end.
)The other predicate used to describe the world is the%etter name" relation ==:(---- worse-name better-name).This is a restricted use of equality.
The second argumentis a "better name" for the first, and thus may be freelysubstituted for it (but not the reverse).
Since slots arerepresented as functions, - -  is used to fill slots in frames.To fill the agent slot of a particular action, say borrowl,with a particular person, say jackl, we say(== (agent borrow1)jack1).At an implementation level, -=  causes everything knownabout its first argument (the worse name) to be assertedabout the second (the better name).
This has the effect.of concentrating all knowledge about all of an object'snames as facts about the best name.Frail will take as input a simple frame representationand translate it into predicate-calculus form.
Figure 1shows a frame for shopping along with the predicate-calculus translation.Naturally, a realistic world model requires more thanthese two predicates plus slot functions, but the relativesuccess of fairly simple frame models of reasoning indi-cates that they are a good starting set.
The last set ofpredicates (word-sense, case, and roie-inst) are used in thetranslation itself.
They will be defined later.
(defframeisaslotsactsshop-action;(inst ?s.shop- action)(agent (person-)):(inst (agent.
?s.shop-) person-)(store-of (store-));( inst ( store-of ?s.shop-) store-)(go-step(go- (agent (agent ?shop-))(destination (store-of ?shop-)))); (== (agent (go-step ?shop-)) (agent ?shop-));(== (destination (go-step ?s.shop-)); (store-of ?s.shop-))Figure 1: A frame for shoppingI I I .
Word-Sense  D isambiguat ionWe can now write down some semantic interpretationrules.
Let us assume that all words in English have one ormore word senses as their meaning, that these word sensescorrespond to frames, and that any particular word in-stance has as its meaning exactly one of these senses.
Wecan express this fact for the instances of any particularlexical entry as follows:(word-inst inst part-of.speech word) =~(inst rest sense1) V ... V (inst inst sense,=)where sense1 through sense,= are senses of word when itis used as a part.of.speech (i.e., as a noun, verb, etc.
)Not all words in English have meanings in this sense.
"The" is an obvious example.
Rather than complicatethe above rules, we assign such words a "null" mean-ing, which we represent by the term garbage*.
Nothingis known about garbage* so this has no consequences.A better axiomatization would also include words whichseem to correspond to functions (e.g., age), but we ignoresuch complications.A minor problem with the above rule is that it re-quires us to be able to say at the outset (i.e., when weload the program) what all the word senses are, and newsenses cannot be added in a modular fashion.
To fix thiswe introduce a new predicate, word-sense:(word-sense lez-item part-of-speech frame)(word-sense straw noun drink-straw)(word-sense straw noun animal-straw).This states that let-item when used as a part.of.speechcan mean frame.We also introduce a pragmatically difl'erent form ofdisjunction, - -OR:(~OR formulal formula2).In terms of implementation, think of this as inferringformula1 in all possible ways and then asserting the dis-junction of the formula,s with each set of bindings.
So ifthere are two seLs of bindings, the result will be to assert 89(OR f ormula2/biltdingsl f ormula2/bindings~ ).Logically, the meaning of - -OR is that if xl ... x ,  areunbound variables i, for'rnulal, then there nmst exist xl... z ,  that make formulal and formula2 true.We can now express our rule of word-sense ambiguityas :(word-inst ?instance ?part-of-speech ?lex-item) =:,(--OR (word-sense ?lex-item ?part-of-speech ?frame)(inst ?instance ?frame))IV .
The  In fe rence  Eng ineWhile it seems clear that the above rule expresses a rathersimple-minded idea of how words relate to their mean-ings, its computational import may not be so clear.
Thuswe now discuss Wimp2, our language comprehension pro-gram, and its inference ngine, Frail3.Like most rule-based systems, Frail distinguishes for-ward and backward-chaining use of modus-ponens.
Allof our semantic interpretation rules are forward-chainingrules'.
(--- (word-inst ?instance ?part-of-speech ?lex-item)(--OR (word-sense ?lex-item ?part-of-speech ?frame)(inst ?instance ?frame)))Thus, whenever a new word instance is asserted, weforward-chain to a statement that the word denotes aninstance of one of a set of frames.Next, Frail uses an ATMS \[9,10\] to keep track ofdisjunctions.
That is, when we assert (OR fo rmula l... formula,=) we create n assumptions (following DeK-leer, these are simply integers) and assert each formulainto the data-base, each with a label indicating that theformula is not true but only true given some assumptions.Here is an example of how some simple disjunctions comeout.A (-- A (OR B C))(-- B (OR D El)Formulas AssumptionsAB 1?
2D 3E 4Labels(0)((1))((2))((1 3))((1 4))Figure 2 represents this pictorially.
Here D, for example,has the label ((13)), which means that it is true if we grantassumptions 1 and 3.
If an assumption (or more gener-ally, a set of assumptions) leads to a contradiction, theassumption is declared a "nogood" and formulas whichdepend on it are no longer believed.
Thus if we learn (notD) then (1 3 / is x nogood.
This also has the consequencethat E now has the label (1/.
It is as if different setsof assumptions correspond to different worlds.
Seman-tic interpretation then is finding the "best" of the worldsdefined by the linguistic possibilities.t ADFigure 2: Pictorial representation f disju.ctio.sWe said "best" ill the last sentence deliberately.When alternatives can be ruled out on logical grounds thecorresponding assumptions become nogoods, and conclu-sions from them go away.
But it is rare that.
all of the can-didate interpretations (of words, of referents, etc.)
reduceto only one that is logically possible.
Rather, there areilsually several which are logically .co,sistent, but someare more "probable" than others, For this rea.so,, Frailassociates probabilities with sets of assumptions ("alter-native worlds") and Wimp eventually "garbage collects"statements which remain low-probability alter,atives be-cause their assumptions are unlikely.
Probabilities alsoguide which interpretation to explore.
Exactly how thisworks is described in \[7\].
Here we will simply note thatthe probabilities are designed to capture the followingintuitions:1.
Uncommon vs. common word-senses {marked vs.unmarked) are indicated by probabilities input bythe system designer and stored in the lexicon.2.
Wimp prefers to find referents for entities (ratherthan not finding referents).3.
Possible reasons for actions and entities are preferredthe more specific they are to.
the action or entity.
(E.g., "shopping" is given a higher probability than"meeting someone" as an explanation for going tothe supermarket.)4.
Formulas derived in two differents ways are moreprobable than they would have been if derived ineither way alone.5.
Disjunctions which lead to already considered"'worlds" are preferred over those which do not hookup in this way.
(We will illustrate this later.
}V .
Case  D isarnb iguat ionCases are indicated by positional relations (e.g., subject)and prepositional phrases.
We make the simplifying as-sumption that prepositional phrases only indicate caserelations.
As we did for word-sense disambiguation, weintroduce a new predicate that allows us to incrementallyspecify how a particular head (a noun or verb) relates toits syntactic roles.
The new predicate,(case head syntactic-relation slot),90states that head can have its slol filled by things whichstand itl syntacttc.lvlation to it.
For example0nst ?g go-) =~ (case ?g subject agent).This Call also be expressed in Frail using the typed vari-ables(case ?g.go- subject agent).This says that any instance of a go- can use the subjectposition to indicate the agent of the go- event.
These factscan be inherited in the typical way via the isa hierarchy,so this fact would more generally be expressed as(case ?a.action- subject agent),Using case and the previously introduced - -OR connec-tive, we can express the rule of case relations.
Formally,it says that for all syntactic positional relations and allmeanings of the head, there must exist a case relationwhich is the significance of that syntactic position:(syn-pos ?tel ?head ?val) A (inst ?head ?frame) =~('--*OR (case ?hea~l ?tel ?slot)(== (?slot ?hesd) ?val)))So, we might have(syn-pos ubject gol jackl) A (inst gol go-)h (case gol subject agent)::~ ( ' ---  (agent gol)jackl).A similar rule holds for case relations indicated byprepositional phrases.
(syn-pp head-prep ?head ?pinst)A (syn-pp prep-np ?pinst ?np)A (word-inst ?pinst prep ?prep) A (inst ?head ?frame)=~ (--"OR (case ?head ?prep ?slot)(=--- (7slot ?head) ?np))For example, "Jack went to the supermarket."
wouldgive us(syn-pp head-prep gol tol) A (case gol to destination)A (syn-pp prep-np to1 supermarket1)A (word-inst ol prep to) A (;nst gol go-)=~ (== (destination go1) supermarketl).We now have enough machinery to describe two waysin which word senses and case relations can help disam-biguate each other.
First consider the sentenceJack went to the supermarket.Wimp currently knows two meanings of "go," to traveland to die.
After "Jack went" Wimp prefers travel (basedupon probability rule 1 and the probabilities assigned tothese two readings in the lexicon) but both are possible.After "Jack went to" the die reading goes away.
This isbecause the only formulas atisfying(case gol to ?slot)all require gol to be a travel rather than a die.
Thus"die" cannot be a reading since it makes(~OR (case ?head ?prep ?slot)(---- (?slot ?head) ?val))false (a disjunction of zero disjuncts is false).We also have enough machinery to see how "'selec-tional restrictions" work in Wimp2.
Consider the sen-tenceJack fell at the store.and suppose that Wimp knows two case relatious for "'at,"Ioc and time.
This will initially lead to the followingdisjunction:((1)).
(== (Ioc fell1) store1)(syn-pp head-prep fell1 at1)<((2) )(== (time fell1) store1).However, Wimp will know that(inst (time ?a.aetion) time-).As we mentioned earlier, == statements cause everythingknown about the first argument o be asserted about thesecond.
Thus Wimp will try to believe that store1 is atime, so (2) becomes a nogood and (1) becomes just tmte.It is important to note that both of these disam-biguation methods fall out from the basics of the system.Nothing had to be added.VL Reference and ExplanationDefinite noun phrases (rip's) typically refer to somethingalready mentioned.
Occasionally they do not, however,and some, like proper names may or may not refer toan already mentioned entity.
Let us simplify by sayingthat all rip's may or may not refer to something alreadymentioned.
(We will return to indefinite np's later.)
Werepresent np's by always creating a new instance whichrepresents the entity denoted by the np.
Should there bea referent we assert equality between the newly mintedobject and the previously mentioned one.
Thus, in "Jackwent to the supermarket.
He found some milk on theshelf.
", the recognition that "He" refers to Jack would beindicated by(== he24 jack3).
(Remember that == is a best name relation, so this saysthat jack3 is a better name for the new instance we cre-ated to represent he "he," he24.
)As for representing the basic rule of reference, theidea is to see the call for a referent, as a statement thatsomething exists.
Thus we might try to say(inst ?x ?frame) =~ (Exists (y \ ?frame) (== ?x ?y)).This is intended to say, if we are told of an object of type?frame then there must exist an earlier one y of this sametype to which the new one can be set equal.The trouble with this formula is that it does not say"earlier one."
Exists simply says that there has to be one,whether or not it was mentioned.
Furthermore, since weintend to represent an np like "the taxi" by (inst taxi2791taxi-) and then look for an earlier taxi.
the Exists wouldbe trivially satisfied by taxi27 itself.Our solution is to introduce a new quantifier called"previously exists" or PExists.
(In \[5\] a similar end isachieved by putting weights on formula and looking fora minimum-weight proof.)
Using this new quantifier, weh aye(inst ?x ?frame) =~ (PExists (y \ ?frame) (== ?x ?y)).If there is more than one a disjunction of equality state-ments is created.
For example, consider the storyJack went to the supermarket.
He found themilk on the shelf.
He paid for it.The "it" in the last sentence could refer to any of the threeinanimate objects mentioned, so initially the followingdisjunction is created:(== it8 shelf(})(inst it8 inanimate-)~-(== it8 milk5)? "
\ (== it8 supermarket2).This still does not allow for the case when there isno referent for the np.
To understand our solution to thisproblem it is necessary to note that we originally set outto create a plan-recognition system.
That is to say, wewanted a program which given a sentence like "Jack gota rope.
He wanted to kill himself."
would recognize thatJack plans to hang himself.
We discuss this aspect ofWimp2 in greater detail in \[7\].
Here we simply note thatplans in Wimp2 are represented as frames (as shown inFigure 1.)
and that sub tasks of plans are actions whichfill certain slots of the frame.
So the shop- plan has ago-step in Figure 1. and recognizing the import of "Jackwent to the supermarket."
would be to infer that (==(go-step shop-74) go61) where go61 represented the verbin "Jack went to the supermarket."
We generalize thisslightly and say that all inputs must be "explained"; bythis we mean that we must find (or postulate) a framein which the input fills a slot.
Thus the go-step state-ment explains go61.
The presence of a supermarket in thestory would be explained by (== (store-of shop-74) super-market64).
The rule that everything mentioned must beexplained looks like this:(inst?x ?frame) ::~(---,OR (roJe-inst ?x ?slot ?superfrm)(Exists (y \ ?superfrm) (== (?slot ?y) ?x))).
(Some things cannot be explained, so this rule is notstrict.)
Here the role-inst predicate says that 7?
canfill the ?slot role of the frame ?supedrm.
E.g., (ro!e-inst?r.store- store-of shop-) says that stores can fill the store-of slot in the shop- frame.
Here we use Exists, not PExistssince, as in the rope example, we explained the existenceof the rope by postulating a new hanging event.
The se-mantics of Exists is therefore quite standard, simply say-ing that one must exist, and making no commitment towhether it was mentioned earlier or not.
As a matter ofimplementation, we note that it works simply by alwayscreating a new instance.
The impact of this will be seeni, a moment.We said that all inputs must be explained, and thatwe explain by seeing that the entity fills a slot in a pos-tulated frame.
There is one exception to this.
if a newlymentioned entity refers to an already extant one, thenthere is no need to explain it, since it was presumablyexplained the first time it was seen.
Thus we combineour rule of reference with our rule of explanation.
Or, toput it.
slightly differently, we handle the exceptions to therule of reference (some things do not refer to entities al-ready present) by saying that those which do not so refermust be explained instead.
This gives the following rule:(inst ?x ?frame) A (not (= ?frame garbage*)) :=~(OR (PExists (y \ ?frame) (== ?x ?y)) .9(--,OR (role-inst ?x ?superfrm ?slot)(Exists (s \ ?superfrm)(== ( slot ?s)Here we added the restriction that the frame in questioncannot be the garbage* frame, which has no properties bydefinition.
We have also added probabilities to the dis-junctions that are intended to capture the preference forpreviously existing objects (probability rule 2).
The ruleof reference has several nice properties.
First, it mightseem odd that our rule for explaining things is expressedin terms of the Exists quantifier, which we said always cre-ates a new instance.
What about a case like "Jack wentto the supermarket.
He found the milk on the shelf.
"where we want to explain the second line in terms of theshopping plan created in the first?
As we have things setup, it simply creates a new shopping plan.
But note whatthen occurs.
First the system asserts (inst new-shopping5shopping-).
This activates the above rule, which must ei-ther find a referent for it, or try to explain it in termsof a frame for which it fills a role.
In this case there is areferent, namely the shopping created in the course of thefirst line.
Thus we get (== new-shopping5 shopping4) andwe have the desired outcome.
This example also showsthat the reference rule works on event reference, not justnp reference.This rule handles reference to "related objects"rather well.
Consider "Jack wanted to play the stereo.He pushed the on-off button."
Here "the on-off button"is to be understood as the button "related" to the stereomentioned in the first line.
In Wimp this falls out fromthe rules already described.
Upon seeing "the on-off but-ton" Wimp creates a new entity which must then eitherhave a referent or an explanation.
It does not have thefirst, but one good explanation for the presence of an on-off button is that it fills the on-off-switch slot for somepower-machine.
Thus Wimp creates a machine and themachine then has to be explained.
In this case a referentis found, the stereo from the first sentence.92V I I .
P ragmat ic  In f luenceWe iinish with three examples illustrating how our se-mantic interpretation process easily integrates pragmaticinfluences: one example of pronoun reference, one ofword-sense disambiguatiom and one of syntactic ambi-guity.
First pronoml reference:Jack went to the supermarket.
He found themilk on the shelf.
He paid for it.In this example the "milk" of sentence two is seen as thepurchased of shop-1 and the "pay" of sentence three ispostulated to be the pay-step of a shopping event, andthen further postulated to be the same shopping event asthat created earlier.
(In each case other possibilities willbe considered, but their probabilities will be much lower.
)Thus when "it" is seen Wimp is in the situation shown inFigure 3.
The important thing here is that the statement(== it7 milk5) can be derived in two different ways, andthus its probability is much'higher than the other possiblerefereuts for "'it" (probability rule 4).
(One derivation hasit that since one pays for what one is shopping for, andJack is shopping for milk, he mdst be paying for the milk.The other derivation is that "it" must refer to something,and tile milk is one alternative.
)The second example is one of word-sense disam-biguation:Jack ordered a soda.
He picked up the straw.Here sentence one is seens as the order-step of a newlypostulated eaboutl.
The soda suggests a drinking event,which in turn can be explained as the eat-step of caboutl.
The straw in line two can be one of two kinds ofstraw, but the drink-straw interpretation suggests (via arole-inst statement) a straw-drinking event.
This is postu-lated, and Wimp looks for a previous uch event (usingthe normal reference rule) and finds the one suggestedby the soda.
Wimp prefers to assume that the drink-ing event suggested by "soda" and that from "straw" arethe same event (probability rule 2) and this preferenceis passed back to become a preference for the drink-strawmeaning of "straw" (by probability rule 5).
The result isshown in Figure 4.Our third and last example shows how semanticguidance of syntax works:Janet wanted to kill the boy with some poison.Starting with the "with" there are two parses which dis-agree on the attachment of the prepositional phrase (pp).There are also two case relations the "with" can indi-cate if it modifies "kill," instrument and accompaniment.When Wimp sees "poison" it looks for an explanation ofits presence, postulates a poisoning and which is foundto be potentially coreferential with the "kill."
The resultlooks like Figure 5.
In this interpretation the poison canbe inferred to be the instrument of the poisoning, so thisoption llas higher probability (probability rule 4).
This!
Other  allernative,9(inst pay7 pay-) ~ 1== (pay-step shop-l) ~ : .
.
.
.
.
/{(inst it8 inanimate-) l ~  ~ (== it8 shelf6)(== it9 supermarket2)Figure 3: -k pronoun example(== it8 milk5) \]i ~   Other alternatives i(inst orcler2 orcler-):~-~(=~" (orcler-step eat-outl) orcler2) (= (eat-step eat-outl) clrink3) I< Y (= (patient clrink3) socla4) (inst soda4 soda-)Other alternatives I(word-inst traw3 noun s~'aw)~ (inst ~ traw3~animal-straw)~ J\]\] ~ (= (straw-of clrink3) Straw3) IFigure 4: A word-sense xampleL the boy with Il(syn-pp head-prep Iboy1 with1) ~.
.~ Accompany(syn-pp head-prepkilll withl) I "~  Instrument ..... ~_  \[(== (instr killl) poison4) I(inst poison4 poison-) ~ e s  JFigure 5: A syntactic disambiguation example93higher probability is passed back to the disjuncts repre-senting a) t, he choice of instrument over accompanyment,and b) the choice of attaching to ~kill" over "boy" (prob-ability rule 5).
This last has the effect of telling the parserwhere to attach the pp.VIII.
Future ResearchThis work can be extended in many ways: increased syn-tactic coverage, more realistic semantic rules, improvedsearch techniques for possible explanations, etc.
Here wewill simply look at some fairly straightforward extensionsto the model.Our rule preferring finding a referent to not finding areferent is not reasonable for indefinite np's.
Thus Wimpcurrently misinterprets3ack bought a gun.
Mary bought a gun.since it wants to interpret he second gun as coreferen-tial with the first.
A simple change would be to havetwo rules of reference/explanation.
The rule for indefi-nite np's would look like this:(inst ?x ?frame) A (not (= ?frame garbage*))A (syn-pos indef-det ?x ?det)=~ (OR (PExists (y \ ?frame) (== ?x ?y)) .1(--*OR (role-inst ?x ?superfrm ?slot)(Exists (s \ ?superfrm)(== (?s=ot ?s) ?x))) .9)This looks just like our earlier rule, except a check foran indefinite determiner is added, and the probabilitiesare reversed so as to prefer a new object over an alreadyexisting one.
The earlier reference rule would then bemodified to make sure that the object did not have anindefinite determiner.Another aspect of language which fits rather nicelyinto this framework is metonymy.
We have already notedthat the work closest to ours is \[5\], and in fact we canadopt the analysis presented there without a wrinkle.This analysis assumes that every np corresponds to twoobjects in the story, the one mentioned and the one in-tended.
For example:I read Proust over summer vacation.The two objects are the entity literally described by thenp (here the person "Proust')  and that intended by thespeaker (here a set of books by Proust).
The syntacticanalysis would be modified to produce the two objects,here proustl and read-objl respectively~(syn-pos direct-object read1 read-objl)(word-inst proustl propernoun proust)(syn-pos metonymy rea6-objl proustl)It is then assumed that there are a finite number ofrelations that may hold between these two entities, mostnotably equality, but others as well.
The rule relating thetwo entities would look like this:( - ,  (syn-pos metonymy ?intended ?given)(OR (=-  ?intended ?given) .9(------ (creator-of ?intended) ?given) .02)...)).This rule would prefer assuming that the two individualsare the same, but would allow other possibilities.IX .
Conc lus ion  "We have presented logical rules for a fragment of thesemantic interpretation (and plan recognition) process.The four simple rules we gave already capture a widevariety of semantic and pragmatic phenomena.
We arecurrently working on diverse aspects of semantics, suchas definite vs. indefinite np's, noun-noun combinations,adjectives, non-case uses of prepositions, metonymy andrelative clauses.P~t~erences\[1\] F. Pereira & D. Warren, "Definite clause grammarfor language analysis - a survey of the formalism anda comparison with augmented transition networks,"Artificial Intelligence 13 (1980), 231-278.\[2\] Philip K. Cohen ~ C. Raymond Perrault, "Elementsof a plan-based theory of speech acts," Cognitive Sci-ence 3 (1979), 177-212.\[3\] Eugene Charniak, "A neat theory of marker passing,"AAAI-86 (1986).\[4\] Henry Kautz & James Allen, "Generalized plan recog-nition," AAAI-86 (1986).\[5\] Jerry R. Hobbs & Paul Martin, "Local pragmatics,"ljcai-87 (1987).\[6\] Graeme Hirst, Semantic Interpretation and the Res-olution of Ambiguity, Cambridge University Press,Cambridge, 1987.\[7\] Robert Goldman & Eugene Charniak, "A probabilis-tic ATMS for plan recognition," forthcomming.\[8\] Barbara J. Grosz, Douglas E. Appelt, Paul A. Mar-tin ~ Fernando C.N.
Pereira, "Team: an experimentin the design of transportable natural-language inter-faces," Artificial Intelligence 32 (1987), 173-243.\[9\] Drew V. McDermott, "Contexts and data depen-dencies: a synthesis," IEEE Transactions on PatternAnaJysis and Machine Intelligence PAMI-5 (1983).\[10\] Johan deKleer, "An assumption-based TMS," Artifi-cial Intelligence 28 (1986), 127-162.94
