OOOO@O@$@O@@O@OO@OOOO@O@@O@@@OKnowledge-Lean Coreference Reso lut ion and its Re la t ion  toTextual  Cohesion and CoherenceSanda M. HarabagiuSouthern Methodist UniversityDallas, TX 75275-0122sanda@seas ,  smu.
eduSteven J .
Ma ioranoAATWashington, D.C. 20505stevejm~ucia, govAbstractIn this paper we present a new empiricalmethod for coreference r solution, imple-mented in the COCKTAIL system.
The re-suits of COCKTAIL are used for lightweightabduction of cohesion and coherence struc-tures.
We show that referential cohesioncan be integrated with lexical cohesionto produce pragmatic knowledge.
Uponthis knowledge coherence abduction takesplace.I Mot ivat ionCoreference evaluation was introduced as a newdomain-independent task at the 6th Message Under-standi~ Conference (MUC-6) in 1995.
The task fo-cused on a subset of coreference, namely the ide~tiQ/coreference, stablished between ouns, pronounsand noun phrases (including proper names) that re-fer to the same entity.
In d~- ; ,~  the coreferencetask (d. (Hirschnum and Chinchor, 1997)) specialcare was taken to use the coreference output notonly for supporting Information Extraction(IE), thecentral task of the MUCs, but also to create meansfor re.arch on corefea~mce and discourse phenom~independent of IE.Annotated corpora were made available, usingSGML tagging with~, the text stream.
The anno-tated texts served as tralz~g examples for a variety.of corderence r solution methods, that had to focusnot only on precision and recall, but also on robust-ness.
Two general classes of approaches were distin-guished.
The first class is characterized byadapta-tions of previously known reference algon'thms (e.g.
(Lappin and Leass, 1994), (Brennan et al, 1987))the scarce syntactic and semantic knowledge avail-able m an w. system (e.g.
(Kameyama, 1997)).The second class is based on statistical and machinelearning techniques that rely on the tagged corporato extract features of the coreferential relations (e.g.
(Aone and Bennett, 1994) (Kehler, 1997)).?
In the past two MUC competitions, the high scor-ing systems achieved a recall in the high 50's to low60's and a precision in the low 70's (d. (Hirschmanet al, 1998)).
A study z of the contribution ofeach form of coreference to the overall performanceshows that generally, proper name anaphora resolu-tion have the highest precision (69%), followed bypronominal reference (62%).
The  worse .precisionis obtained by the resolution of d~_ n!te nominalsanaphors (46%).
However, these results need to becontrasted with the distribution of coreferential linkson the tagged corpora.
The majority of coreferencelinks (38.42%) connect names Of people, organiza-tions or locations.
In addition, 19.68% of the taggedco~ce links are accounted by appositives.
Only16.35% of the tagged coreferences are pronominal.Nominal anaphors account for 25.55% of the coref-erence links, and their resolution is generally poorlyrepresented in IE systems.Due to the distribution of coreference links innewswire texts, a coreference module that is merelycapable of handling recognition of appositives withhigh precision and incorporates rules of name aliasidentification can achieve a baseline coreference pre-cision up to 58.1%, without sophisticated syntacticor discourse information.
Precision increase is ob-tained by extending lfigh-performance pronoun res-olution methods (e.g.
(Lappin and Leass, 1994)) tonominal corderence aswell.
Such enhancements relyon semantic and discourse knowledge.In this paper we describe COCKTAIL, a high-performance oreference r solution system that op-eratas on a mixture of heuristics that combine se-mantic and discourse information.
The resultingtThe study, reported in (Kameyama, 1997), was per-formed on the coreference module of SRI's FASTUS (Ap-pelt et al, I993), an IE system representative of today'sIE technology.29coreference chains are shown to contribute in thederivation of cohesive chains and coherence graphs.Both cohesive and coherence structures are consid-ered, partly because of their incremental complex-ity and partly because the tradition (started with(Hobbs, 1979)) of studying the interaction of coref-erence and coherence.
Section 2 presents COCKTAILand the coreference methods it built upon.
Sections3 and 4 describe the derivation the cohesion and co-herence structures.2 Coreference ResolutionCoreference resolution relies on a combination of lin-guistic and cognitive aspects of language.
Linguis-tic constraints are provided mostly by the syntacticmodeling of language, whereas computational mod-els of discourse bring forward the cognitive aesump-lions of anaphora resolution.
Three different meth-ods of combining anaphoric constraints am knownto date.
The Rrst one integrates anaphora resolutionin computational models of discourse interpretation.Dynamic properties of discourse, especially focusingand centering are invoked as the primary b~-~|~ foridentifying antecedents.
Such computational meth-ods were presented in (Grosz et al, 1995) and (Web-ber, 1988).A second category of approaches combines a v~riety of syntactic, semantic and discourse factors asa multi-dimensional metric for ranking antecedentcandidates.
Anaphora resolution is determined bya composite of several distinct scoring procedures,each of which scores the prominence of the candidatewith respect to a specific.type of information.
Thesystems described in (Asher and Wada, 1988) (Car-bonell and Brown, 1988) and (Rich and Luperfoy,1988) are examples of the mixed evaluation strat-egy.Alternatively, other discourse-based methods con-sider co~eference resolution a by-product of therecognition of coher~ce relations between sentences.Such methods were presented in (Hoblm et al, 1993)and ~flensky, 1978).
Although M-complete, thisapproach as the appeal that it resolves the mostcomplicated cases of coreference, uncovered by syn-tactic or semantic ues.
We have revisited thesemethods by setting the relation between coreferenceand coherence on empirical grounds.2.1 Pronominal CoreferenceTwo tendencies characterize current pronominalcoreference algorithms.
The first one makes use ofthe advances in the parsing technology or on theavailability of large parsed corpora (e.g.
Trcebank(Marcus et al1993)) to produce algorithms inspiredby Hobbs' baseline method (Hobbs, 1978).
For ex-ample, the Resolution of Anaphor~ Procedure (RAP)i~itroduced in (Lappin and Leass, 1994) combinessyntactic information with agreement and salienceconstraints.
Recently, a probabilistic approach topronominal coreference r solution was also devised(Ge et al, 1998), using the parsed data availablefrom Treebank.
The knowledge-based method ofLappin and Leass produces better results.
Never-theless, RkPSTAT, a version of RAP obtained by usingstatistically measured preference patterns for the an-tecedents, prodticed a slight enhancement ofperfor-mance over RAP.Other pronominal resolution approaches promoteknowledge-poor methods (Mitkov , 1998), either byusing an ordered set of general heuristics or bycombining scores assigned to candidate antecedents.The CogNIAC algorithm (Baldwin, 1997) uses sixheuristic rules to resolve coreference, whereas thealgorithm presented in (Mitkov, 1998) is based on alimited set of preferences (e.g.
definitiveness, lexicalreiteration or immediate reference).
Both these al-gorithm rely only on part-of-speech tagging of textsand on patterns for NP identification.
Their per-formance (dose to 90% for certain types of pro-nouns) indicates that full syntactic knowledge is notrequired by certain forms of pronominal coreference.The same claim is made in (Kennedy and Bogu-raev,  1996) and (Kameyama, 1997), where algo-rithm~ approximating RAP for poorer syntactic inputobtain precision of 75% and 71%, respectively, a sur-prising small precision decay from RAP's 86%.
Theseresults prompted us to devise COCKTAIL, a corder-ence resolution system, as a mixture of heuristicsperforming on the various syntactic, semantic anddL~ourse cues.
COCKTAIL is a composite of heuris-tics learned from the tagged corpora, which has thefollowing novel characteristics:1.
C0cErIIL covers both nominal and pronoun cord-er~ce, but distinct sets of heuristics operate fordifferent forms of anaphors.
We have devised sepa-rate heuristics for reflexive, possessive, relative, 3rdperson and 1st person pronouns.
Similarly, de/initenomlo-t~ are treated ifferently than bare or indd-inite nominals.2.
c0crr/IL performs emantic hecks between an-tecedents and ~phorL  These chedm combine sot-tal co~aints  from WordNet with co-occurance in-formation from (a) Treebank and (b) conceptual3.
In COCET~L antecedents are sought not only in theac~e~ble t xt region, but we also throughout thecurrent co~efe~nce hains.
In this way cohesive in-formation, represented incorderence chains, is em-ployed i~ the resolution pr _~___.4.
The heuristics d ~cErAIL allow for lexi~dizations(e.g.
when the anaphor is an adjunct ofa commmd-cation verbs) and of simplified coherence cues (e.g.30Vwhen the anaphor is the subject of verb add, theantecedent may be a preceding subject of a com-munication vehb).To exemplify some COCKTAIL heuristics that re-solve pronominal coreference, we first present heuris-tics applicable for reflexive pronoun and then we listheuristics for possessive pronouns and 3rd personpronoun resolution.
Brevity imposes the omissionof heuristics for other forms of pronoun resolution.COCKTAIL operates by successively applying the fol-lowing heuristics to the pronoun Pro~Oif (Pron is reflezive) then apply successively:oHenristic 1-Reflexive(H1R)Search for PN, the closest proper name from Prgnin the same sentence, in right to left order.if (PN agrees in number and gender with Pron)if (PN belongs to core/erence hain CC)then Pick the element from CC which isclosest o Pron in Text.else Pick PN.o Henr/stic 2-Refle~'ve(H2R)Search for a sequence Noun.Relative.Pronoun,in the same sentence, in rigld to left order.if (Noun agrees in number and gender with Pron)i f  (Noun belongs to earefe~n~ chain CC)then Pick the dement from CC which isclosest o Iron in Tezt.else Pick Noun.oHeur/sHc $-Refle~'/~e(H3R)Search for Pron" the closest prenoun from Pronin the same sentence, in right to left order.if  (Pron" agrees in number and gender with Pron)i f  (Pron' ~gs  to wreferen~ chain CC)then Pick the dement from CC which isclosest o Pron in Tcet.eLse Pick Pron:o Heuristie 4-Reflezive(H4R)Search/or Noun.e, the dosest noun .from Pronin the same sentence, in right to left order.if (Noun.c a#n~a in number and gender with Pron)then Pick Noun.~Resolution examples for reflexive pronouns are il-lustrated in Table L The antecedents produced byCOCKTAIL are boldfaced, whereas the referring ex-pressions are emphasized.
Both referring expressionsand resolved antecedents and underlined.
Precisionresults are listed in Table 2.Antecedents of reflexive pronouns are alwayssought in the same sentence.
Antecedents of othertypes of pronouns are sought in preceding sentencestoo, starting from the immediately preceding sen-tence.
Inside the sentence, the search for a specificword is performed from the current position towardsthe beginning of the sentence ,  whereas in the pre-Before Pennzoii's court fight with Texaco over theGetty purchase, Mr. Liedtke - one of the ploy's fore-most practitioners - portrayed him.~elfas somethingof an oil-patch tube, a notable f~---'~"~-~nsidering hisdiplomas from Amherst College and Harvard BusinessSchool.The' woman who is kuown to me as hard-working and.responsible, clearly isn't hersel/.Unlike many of her peers, m~t of whom are malesin their 30s, s.he never takes herself too seriously.Table h Examples of reflexive pronounsHeuristic HIR H2R H3R H4KPrecision on a testset of I00 randomly 95% 92% 98% 89%selected pronounsTable 2: Coreference precision (reflexive pronovns)ceding sentences, the search starts at the beginningof the sentence and proceeds in a left to right fash-ion.
The same search order was used in (Kameyama,1997).
From now on, we indicate this search bySearchl.
This search is employed by heuristics forpossessive pronoun resolution:Oif (Pron is possessive) (i.e.
we have a sequence\[Pron nouno\], where nouno is the head of the NPcontaining Pron) then apply suco,~_~sieely:o Henris6?.
l-Pouessive(H IPos )Searchl /or a posses~ve comb'uct of the form\[.ounl's ,~n2\],if (\[Pron nouno\] and\[nounl's noun2\] agree in gender, n-tuber andare semantically consistent)then if (noun2 belonga to coreyerence hain CC)and there is andement from CC which isclosest o Pron in Tezt, Pick that dement.Pick noun,.oHcur/sfc 2-pouess/ve(H2Pos)Senrchl for PN, the closest proper name from Pronif  (PN agrees in number and gender with Pron)if (PN belongs to corefe~n~ chain CC)then ~ the dement from CC ~hich isclosest o Pron in Teztelse Pick PN.oHeuris6c 3-Possessive(H3Pce).Search for Pron" the closest pronoun .from Pron .if  (Pron" egre~ in number and fender e~h Pron).i f  (Pron' belongs to coreferen~ chain CC)and there is an dement from CC which isclosest o Pron in Text, Pick that element.else Pick Pron'oHenrist~ .Possessiee(H4Pos)Search for Noun, the closest eammon oun from Ironif (Noun agrees in number and gender with Pron)31if (Noun belongs to core f~ chain CC)and there is an element from CC which iscloses~ to Pron in Tezt, Pick that element.else Pick NounExamples and precision results are listed in Ta-ble 3 and Table 4, respectively.The timing of Mr. Shad's departure is likely todepend on how rapidly the Senate BankingCommittee moves to confirm his successor.Ronald Reagan sends him-a list of h/s film roles.The 20-minute tiigfit )~elps him forget h/s troubles.The president renewed h/s promise to veto"tax-rate increases.
"Table 3: Examples of possessive pronounsPrecision on100 random 96% 93% 78% 86%pronounsTable 4: Coreference precision (possessive pronouns)Given a possessive pronotm in a sequence \[PronNoon0\], the antecedent Ante of Pron is semanti.cal\]y consistent if the same possessive relationshipcan be established between Ante and Noono.
theproblem is that the possessive r lation semanticallycorresponds to an open list of relations.
For exam-ple, Nouno may be a feature of Ante.
Ante may ownNoono or Ante may have pe, formed the action lex-ical/zed by the nominali~-~on Nouno.COCKTAIL's test of semantic onsistency blends to-gerber information available from WordNet and onstatistics gathered from ~ebank .
Different consis-tency checks are modeled for each of the heuristics.We detail here the check that applies to heuristicHIPos, that resolves the possessive from the first ex-ample listed in Table 3.
For this heuristic, we haveto test whether from the possessive \[Ante Nount\]we can grant the pos~_~ve \[Ante Noone\] as well.There axe three cases that allow us to do so:?
~ase 1 Nount and Nouno corder.?
Case ~Theceis ase~se ss of Nounx and asense soof Nouno such that a synonym of Noun~ i or of itsimmediate hypernym is found in the gloss of Noon~or vicevers&?
~ There is a sense st of  Nounx and a senseSo of Nouno such that a common concept is foundin their glosses.Cases 2 and 3 extend to synsets obtained throughderivational morphology as well (e.g.
nominaliza-tions).
For cases 2 and 3 COCKTAIL reinforcesthe coreference hypothesis by using a possessive.similarity metric based on Resuik's imilarity mea-sures for noun groups (B___,~m_ i k, 1995).
From a subsetof Treebank, we collect all possessives, and measurewhether the similarity~clam of Nouno, Noun1 andtheir eventual common concept is above a thresholdproduced off-line.Other pronominal coreference heuristics employSearch2, a search procedure that enhances Searchx,since it prefers antecedents hat are immediatelysucceeded by relative pronouns.
This search is in.corporated in COCKTAIL's heuristics that resolve 3rdperson pronominal coreference:o Heuristic 1-Prono.un_(HIPron)Search2 in the same sentence for the same5rd person pronoun Pron'if (Pron' belongs to coreference hain CC)and there is an element from CC which isclosest o Pron in Text, Pick that dement.else Pick Pron"oHeuristic ~-Prenoon(H2Pron)Search2 for PN, the closest proper name from Pronif (PN agrees in number and gender with'Pron)i f  (PN belongs" to coreference hain CC)then Pick the element from CC which isclosest o Pron in.
Text.else Pick PN.oHeuristic 3-Prenoon(H3Pron)if Pron collocates with a communication verbthen Searcht for pronoon Pron'--Iif (Pron" belongs to ?oreference hain CC)and there is an clement from CC e~hich isclosest o Iron in Tezt, Pick that dementelse Pick Pron"oHeuristic ~-Pronoun(H4Pron)if Pron collocates with a communication verbthell Search\] communicator Nouni f  (#oun belongs to coreyeren~ chain CC) -and there im an clement from CC u#sich isclos/Jt to Pmn in Te.zt, Pick that dement.else Pick Noo~o Heuristic 5-Pmnoon(HSPron).
Searcha for Pron', the closest pronoun from Pronif (Pron' agrees in number and gender with Pron)if (Pron' belonga to ?oneference hain CC)and there is an dement from CC tnhich isdo, eat to Pron in Teffit, Pick that dementelse Pick Pren"oHfu~ 6-Proooen(H6Pron)Search2 for Noun, the closest noun from.Pronif (Noun agrees in number and gender with Pron)if (Noon belongs to coreferen~ chain CC)and there is an element from CC which isdosest o Iron in Tezt, Pick that dement.else Pick NounCOCKTAIL doesn't employ semantic consistencychecks for this form of pronominal coreference r s-320OOOO0O@@OO00OO@@000eO00OO000@000@@000000O@@olution.
FYom our initial experiments, we do notsee the need for special semantic consistency checks,since all heuristics performed with precision in ex-cess of 90% Part of this is explained by our usage ofpleonastic filters and of recognizers of idiomatic us-age.
Table 5 illustrates some of the successful coref-erence resolutions.H_qe says that in many years as a banker he has grownaccustomed to "dealing with honest people 99% ofthe time.sen.
Byrd takes pains to reassure the voter that hewill see to it that the trade picture improves.A..nurse who deals with the new patient ~Jmits sh.._~eisn't afraid of her temper.Table 5: Examples of 3rd person pronouns2.2 Nominal CoreferenceNoun phrases can represent referring expressions ina variety of cases.
For example, it is known thatnot all definite NPs are anaphoric.
Conditions thatdefine anaphoric NPs are still under research (cf.
(Poesio and Vieira, 1998)).
In the tagged corpora,we have found only 20.93% of the nominal corefer-ence cases to be definites, the majority (78.85%) be-ing bare nominals 2, and only 1.32% were inclefiuites.However, more than 50% of the nominal referringexpressions were names of people, org~n!-~tions orlocations.
Adding to this, 15.22% of nominal coref-erence links are accounted by appositives.
Basedon this evidence, COCKTtIL implements special rulesfor name alias identification and for robust recog-nition of appositions.
Moreover, the heuristics fornominal coreference r solution apply Senrchs, andenhancement of Search~ that searches starting withthe coreference chains, and then with the accessi-ble text.
To resolve nominal coref~eace, COCKTAILsuccessively applies the following heuristics:oHeuristic l.Nominal(H1Nom)if (Noun is the head of an appositive)then Pick the preceding NP.o Heuristic P..Nor~inal(H2Nom)if (Noun belongs to an NP, Searchs /or NP'such that Noun'ffiaame_name(head(NP),head(NP'))or Noun'--same.name(adj(NP),adj(Ne')))then if (Noun' belongs to core/erence chain CO)then Pick the element ~vm CC which isclosest o Noun in Text.else Pick Noun:oHeuristif.
3-Nominal(H3Nom)if Noun is the head of an NPthen Searchs for proper name PN2We count as bare nominals coreferring adjuncts aswell.such that head(PN)-Nouni f  (PN belongs to coreference chain CG)and there is an element from CC which isclosest o Noun in Text, Pick that element.else Pick PN.o Houristie 4-Nominal( H4N om)Searchs \]or a proper name PN with the samecategory as Nouni f  (PN belongs to core-ference hain CC)and there is an element from CO which isclosest o Noun in Tezt, Pick that element.else Pick PN.oHeuristic 5-Nominai(H5Nom)Searchs Noun" a spnenym or hyponyrn of Nounif  (Noun' belongs to core/erence chain CC)and there is an element fl'om CO which isclosest o Noun in Text, Pick that dement.else Pick Noun'.oH.
euristic 6-Nominal(H6Nom )Searchs for Noun either in definites orin NPs having adjuncts in coreyerence hain CU)if Ante 8emantieally consistent with Nounif  (Ante belongs to core/erenee chain UC)and there is an dement from UU which isclosest o Noun in Text, Pick that element:else Pick Ante.oHeuristic 7-Nomine/(H7Nom)i f  (Noun or one ol his hz~n~nrtsor holonyms is a nominalization N)then Search/or the verb V deriving Nor one o/ its synen~ns)then P/ok NP, the closest adjunct o /Vif  (NP belongs to ?ore!erence hain 00)az~d there is an dement from CO which isclosest o Noun in Te~, Pick that element.else Pick NPoHeuristi?
&N0m/na/(H8Nom)i f  (Noun is the head o/a prepositionalphrase preceded by a nominalization N)then Search/or the verb V deriving Nor one oI its s~um~ns)if (Noun" is on adjunct o/ V) and(Noun" and Noun have the same category?
i f  (Noun' belongs to ?ore/erenea chain CC)and there is an dement from CC which isclosest o ~Voen in Text, Pick that dement~else Pick Noun"oHouristi~ 9-Nominal(H9Nom)Searchs Jar Noun', a metonymp whosecoercion is NounPick Noun'me o p. es lby appositions, whereas heuristic H2Nom promotes33IMB and Mr. York would;t discuss his compensationpackage which could easily reach into seven figures.~ e c t  is sensitive at a time when IMBis !aying off thousands of employeesMr Iacocca led Chrysler through one of the 'largeststock sales ever for a U.S. industrial company, raising.$1.78 billion.
Chrysler is using most of the proceedsto reduce its $4.4.
billion unfunded pension liability.We read where the Clinton White Houseis seeking adeputy to chief of staff Mack McLarty toimpose some disciplined coherence on the p/ace's?
ambunctious young staff.Table 6: Examples of nominal coreferencethe term repetition indicator, when consistencychecks apply.
For this heuristic, consistency checksare conservative, imposing that either the adjunctsbe identical, coreferring or the adjunct of the ref-erent be less specific than the antecedent.
Speci-ficity principles apply also to HSNom, where hy-ponymy is promoted, similarly to (Poesio and Vieirs,1998).
Heuristic H3Nom allows coreference b tween"the Securities and F_,z~ange Commission n and .~hecommission ~ but it bans links between ~ReardonSteel Co." and "tons of steal".Many times coreferring nomln~l~ share a~o se-mantic relations (e.g.
synonym#).
Heuristic HSNomidentifies such cases, by applying consistency hecks.Based on experiments with the coreference moduleof FASTUS, where this heuristic was initially imple-mented, we require that most frequent senses ofnouns be promoted.
The same precedence of f~-quent senses is implemented in the assi~ment ofcategories, defined as the immediate WordN~ h~pernTpn.
The category of proper names is dictatedby the proper name recognizer, ~qlo~ing such cate-gories m Person, Organization orIn this way, coreference between "IBM ~ and ~hewo,mded computer 9lent ~ can be estab!|~bed, sincesense 3 of noun #/ant is Organim6on, the categoryof ~IBM~.
Simi!m- ~tegory-based semaatic cheCkSallow the recognition of the antecedent of proceedsfrom the second example listed in Table 6.
Theh~l~ern~ of ~eceezk is ga/n, whose glou genus isamount, the category of $1.78 biUio~ Semanticchecks are also required in H?Nom and HSNom,heuristic that rely on derivational morphology.
Thefirst example from Table 6 is resolved by HTNom,since d/scass/on the nominalization of d/scuss b~_qthe category communication, a hypernym of subject,The antecedent is the object of the verb d/scuss.The last heuristic, H9Nom identifies coreferringlinks with coerced entities of nominals.
Coercionsare obtained as paths of meronyms or hypernyms.
(Harabagiu, 1998) discusses a coercion methodol-ogy based on WordNet and Treebank.
Since in ourtest corpus there we very few cases of metonymicanaphors, Table 7 lists the precision of the otherheuristics only.I Heuristic I\[ H1Nom i H2Nom H3Nom j H4Nom 1Precision on \[\[ 98% 95% 82% 88%100 random \[\['HSNo.m He~om ti7Nom HSNomTable 7: Nom!~nal coreference precisionThe empirical ?
methods employed in COCKTAIL arean alternative tothe inductive approaches describedin (Cardie and Wagstatf, 1999) and (McCarthy andLehnert, 1995).
Our results how that high-precisionempirical techniques can be ported from pronominalcoreference r solution to the more difficult problemof nominal coreference.3 Lexical Cohes ionThe heuristics encoded in  COCKTAIL make lightuse of textual cohesion, i.e.
the property oftexts to Ustick together s by using related words.Both pronominal nd nominal coherence r solutionheuristics use cohesion cues indicated by term rep-etition while nominal corofexence r lies on semanticrelations between anaphors and their antecedents.In addition, coreference hains are a form of textualcohesion, known as referential cohesion (d. (Halli-day and Haesan, 1976)).Until now, lex/m/cohes/on, arising from semanticconnections between words, was successfully used asthe  only form of textual cohesive structure, known as?
lez/cd chdn& At present there are three methodsof generating lexical chains.
The first one, imple-mented in the TextTning algorithm (Hearst, 1997),counts the f~lUencies of term repetitions and is anideal, lightweight tool for segmenting texts.
The sec-ond method, adds knowledge from semantic dictio-naries (e.g.
Roget's Thesaurus in the work of (Mor-ris and Hirst, 1991) or WordNet in the methodspresented in (B~y and Elhadad, 1997), (Hirstand St-Onge, 1998)).
Besides term repetition, thisapproach reco~i,~s relations between text wordsthat are connected in the dictionaries with prede-fined patterns.
This method was applied for gen-eration of text ~lmmm'ies, the recognition of theintentional structure of texts and in the detectionof malapropism.
The third method is based on apath-finding algorithm detailed in (Harabagiu andMoldovan, 1998).
This method creates a richerSDefiuition i troduced in (Halliday and Ha.man, 1976)and (Morris and Hirst, 1991)34000@0@0OO0@00@000000@0@0@0000@000000000000O@OOOOOOOOOOO@OOO0OOOOOOO@O0O@OOOO@OOOOO@O@OO@structure, useful for the al~duction of coherer~e r -lations from the knowledge ncoded in WordNet.Here we describe a new cohesion structure that(a) incorporates both lexical and referential cohesionand (b) produces a unique chain that contains notonly single words, but also textual entities encom-passing head-adjunct lists.
We use the finite-stateparses of FaSTU$ (Appelt et al, 1993) for recogniz-ing these entities, but the method extends to anybasic phrasal parser 4.We produce this novel cohesive structure to ex-ploit the close relation between text cohesion andcoherence.
It is known (cf.
(Harabagiih 1999)) thatcohesion, as a surface indicator of the text coherence,can indicate the lexico-semantic knowledge uponwhich coherence is inferred.
Our aim is to use thiscohesive chain for producing axiomatic knowledgefor CICERO, a TACITUS-like system that abducts co-herence relations.
TACITU$ (Hobbs etal., 1993) is asuccessful abductive system when provided with ex-tensive pra?~n~ic and linguistic knowledge.
CICEROis des~ned as a Jightwe~t version of TACITUS, thatperforms reliable abductions, with minimal knowl-edge and effective searches.
Translating all the lexi-cal, morphological, synta~'c and semantic ambigu-ities from texts would make the search intractable.Out solution for CICERO is to use a cohesive chainto create manageable knowledge upon which the ab-duction can be performed.
Section 4 describes thisknowledge and the operation of CICERO.Our cohesive chain is a link~!
structure consist-ing of three parts: (1) the connected text entity, (2)its incoming and outgoing pointers and (3) a fez/co-semantic.
~ph~ containing paths of WordNet con--cepts and relations.
The lexico-semantic structureis later translated in the axiomatic knowledge thatsupports coherence inference.
To exemplify the co-hesion chain, we use the following text, spanned bythe coreference hains produced with COCKTAIL:\[Toys R Us\]~ named Midmd Goldstein \[chief ezecut/veo~,  ending ymrs o l ~eculation~ about ~ohou,~/l su~d \[6'horla,/,aw~\]s, \[the \[to~ retaaer\], 'sfounder and chief architetrt.\]s\[Robert Nalmsone\]4, \[former vice chairman andudddy regarded as t~ other st~riou~ cont~ufer for\[the top ezecuti~e\]~ '8 job\]4, ~m named presidentand chief opueting o~=r, both ne~ positions.The indexes indicate the four coreference chains.This text has only two repeating terms, the verbname and the noun executive, thus it generates littleinformation with the TeztTiling algorithm.
The co-hesion method etailed in (Barzilay and Elhadad,4Such aparser operates on part-of-speech tagged text,with several noun and verb grouping rules.1997) can detect one lexical chain: \[chief execu-tive o~cer, chairman, executive, .president\].
Wewould like to obtain richer lexico-semantic informa-tion, thus we build a cohesion chain that containslarger textual entities.
To recognize the entities, weuse the coreference hains and the following parse,pro duc.ecl, by FASTUS:#<P~(OR~ISlZATION-NANE) :"Toys R gs">J<PBBISE (B~5I?)
:~named'>#<PHKASE(PERSOIJ-g~) : "Nicl~el ~ l~te ln">8<PHRISE(|G):mch/ef xecut ive  o f f i cer">8<P~5~(~)  : -oadlag'>8e~J~U~(|~) :~yt~ Of epOCl~latiOIlw~#<pna=~=(pKEp) : "shoutS>8<PHUSEfB~SIC) :"~iZ1 succeed">IcPRRISE(PELS~I-NIM~) : 'Char les  Lazaru  , the toy  re ta i le r  "sfounder and ch /e f  erchigect">S<PHRISE(PEP, SmI - J I~)  : "1obor~ Nakasou .fo rmr ly  vice chs i rnu">|<pNltA~(COLI) : walMl">8<Pwst~_(BISIC) : "g ide ly  rogsrdod">8<Pnt~(PR~)  : "u">8<PH~SE(i~) : ' the  o ther  sor ioas  contenderS>8<l~mt-~_fJ~):%ho top execut ive  J8 Jo\]}m>8<Pna~(CO~A)  : " .
">8~qLt~E(BLSIC) : ~ nued '>#<PHIJ~E(B~) : 'p res ident  and ch ie f  operat in  K o f f i cer .both  nee poeit icm8">Textual entities are either basic phrases containedin the coreference haln.q or lists of phrases collectedfrom the parse, by scanning for all NGs or NAME-phrases directly connected to a verb phrase througha S~bject, Ob3ect or prepositional relations.
For ex-ample, as phrase "Toys R (.ramie the antecedent froma coreference hain, its corresponding textual entityis:|a~oys R Us"-Subject-+ '%ame"\]\[ |nm~-Object l -  "Mid~d GoMste/n~ .
1 "\ [n~-Ob ject2 -  "cA/e/e~cuffve offu~,~The cohesion chain for our.
text is illustrated inFigure 1.
The algorithm that generates cohesionchains is:Algorithm Cohesion-Chaln-BuilderI.
i f  (current N@ belongs to a core/erenc~ chain) .Create its te.z'htal entity TE and place .it on the Chain~,.
i f  (the an ~__dent @ already/in the chain)Place the core fer~ pointer bet~eea the two TEs3.
i f  (the ooreferen~ is not an appositive)Populate the lezico-semantic s~ctu~(TE) "The derivation of the lexico-semantic structure(LSS) follows the steps:Lfor every re/at/on r(wt,,n2) from a TEif(there is st a sense of wl a.d s2 a sense ofwa such that the same relation r'(ws,w4)/8 foundin a gtoss ~ the hierorchies of ,z~' or w~' )Add relation r" to LS$~.for every word tv in a TE35if (there is a concept C in LSS such that there is acollocation \[~1 c\] in a gloss from the hierarchy(w))Add to to LSS3.
if (word w is already in LSS)Add ne~a connection to w in LSSFor example, in the first TE illustrated in Fig-ure I, we have the relation Object(name, CEO).
Wefind art Object relation also in the gloss of appoint,the hypernym of sense 3of verb name.
The new Obo\]ect relation connect verb assume with the synset{duty, responsibility, obligation}.
A hypernym ofCEO is manager, collocating with position in thegloss of managership.
Noun position belongs to thehierarchy of duty, thus the new Object relation canbe added to the LSS.+ n rea~olD ~ L~t~.5~ Smmmre (LSS)I W+.,.
'*' 1 "xl~n~ l " Obj?,?
'lI i + ,.+,jI - -I IIT I~ M_-.-,*j~ .$ h mp e.~m~'*.l~Figure 1: Cohesion chain4 Text  CoherenceWe base our consideration f textual coherence onthe definitions introduced in (Hobbs, 1985).
Theformal definition of relations that capture the coher-ence between textual assertious i based on the re-lations between the states they infer, their changesand their logical connections.
States, changes andlogical connections can be retrieved from pragmaticknowledge, accessible in lexical knowledge bases likeWordNet.
The complex structure of our cohesionchains help guiding these inferences.
0For each textual unit, defined from the parse of the Otext, axiomatic knowledge produced.
The acquisi-tion of axiomatic knowledge is cued by the concepts Oand relations from the LSS portion of the cohesion Ochain, and is mined from WordNet.
CICERO, our sys-tem, adds to this knowledge axioms that feature the Ocharacteristics of every coherence r lation.
CICER0's Ojob is to abduct he coherence structure of a text.To do so, it follows the steps: 0/.for every textual unit TUi @~.
Derive pragmatic knowledge for TUi @3.  for every pair (TUi,TUj),i ~ j4- for every coherence r lation 7~k O5.
hypothesize R~(TU.
TUj)6.
Perform abduction R~ (TU.
TUj) O7.
Choose cheapest abduction @For the text illustrated in Section 3, this proce- Odure generates the coherence graph illustrated in @Figure 2.Remit Elab, m~en e',,im,m.immwnd~oma" I l ~olmmi~omo+,  J " J t " 'Figure 2: Coherence graphWe exemplify the operation of CICERO on this textby presenting the way it derives the Elaboration rela-tion between the textual unit from the first sentencethat announces the nomination of Michael Goldstein(TU.)
and the textual unit from the same sentencethat deals with the succession of Charles Lazarus(TUb).
l~st, CICERO generates the knowledge uponwhich the abductions can be performed.
This knowl-edge is represented in axiomatic form, using the no-tation proposed in (Hobbs et al, 1993) and previ-ously implemented in TACITUS.
In this formalismeach text unit represents an event or a state, thushas a special variable associated with it.
Eventsare lexicalized by verbs, which are reaped into pred-icates verb(e,z,y), where z represents he subject ofthe event, and y represents its object (in the case ofintransitive verbs, y is not attached to a predicate,36eoo@ooooooo@oo@o@o@o@oo@oo@@oooe@ooo@o@o@ooewhereas in the case of bitransitive v rbs, y is mapped"into Yl and l~2).
"Moreover, predicates from the textare related to other predicates, derived from a knowl-edge base.
These relations are captured in first or-der predicate calculus.
For example, the pragmaticknowledge used for the derivation of the Elaborationrelation between TUa and TUbis:TU,:assiqn( e~ ,z~ )&positionz~ =~vac'ant-position( el ) ~ aJsign( e~ , z l )& Positionz lTUb: .
.I l~e(e~, zl, z2),t'l~rson(zl)&~jmon(z2) =~I ~acanLposition(e~)\[ lea~'e(et , zh  z~)k~rs(m(z~ )&position(z,)&\[ a~sume(e2, zs, z2)&person(zs) =~In the next step, ~!1 coherence relations are hy-pothesized, and the cost of their abduction is ob-tained.
The appendix lists the LISP function cre-ated on the fly by CICERO that produces the ab-duction of the Elaboration function.
Because of thecomputational expense, an intermediary Step sim-plifies the axiomatic knowledge.
The appendix listsalso the full abduciton and its cost.
CICERO is a sys-tem still under development, and at present we didnot evaluate the precision of its results.5 Conc lus ionWe have introduced a new empirical method forcoreference r solution, implemented in the COCgTtILsystem.
The results of this algorithm are used to?
guide the abduction of coherence r lations, as per-formed in our ClC~0 system.
In an intermediarystep, a rich cohesion structure is produced.
Thisnovel relation between coreference and coherencecontrasts with the traditional view that coreferenceis a by-product of coherence resolution.
Moreover,we reiterate the belief that coherence builds up fromcohesion.ReferencesChinatsu Aone and Scott W. Bennett.
1997.
Evaluatingautomated and mam~ acqui~tioa of anaphom res-olution strat~e& In Proceedings of the $Sth AnnualMeeting of the A~odation for Computational f, ingu~.tics (ACL.gT), pages 122-129, Madrid, Spain.Douglas E. Appelt, Jerry R. Hobbs, John Beat, DavidIsrael, Megumi Kameyama and Mabry Tyson.
1993.The SRI MUC-5 JV-FASTUS Information ExtractionSystem.
In Proceedings of the Fifth Me.uage Under-standing Conference (MOC-5).Nicholas Asher and Henri Wad& 1988.
A computationalaccount of syntactic, semantic and discourse principlesfor anap.hora esolution.
Journal of Semantics, 6:309-344.Brack Baldwin.
1997.
CogNIAC: high precision corefer-ence with limited knowledge and linguistic resources.In Proceedings of the A CL '97/EA CL '97 Workshop onOperutional factors in practical, robust anaphora reJ-olution, pages 38-45, Madrid, Spain.Regina Barzilay and Michael Elhadad.
1997.
Using Lex-ical Chains for Text Summarization.
I  Proceedinga ofthe A CL '97/BA CL '97 Workshop on Intelligent Scal-able Text Summarization, Madrid, Spain.Susan E. Brennan, Marilyn Walker Friedman and CarlJ.
Pollard.
1987.
A centering approach to pronouns.In Proceedings of the P.Sth Annual Meeting of the ACL(ACL-87), pages 155-162.Jaime Carbonell and Richard Brown.
1988.
AnaphoraResolution: A Multi-Strategy Approach.
In Proceed-ings of the l~h  International Conference on Com.m~-rational Linguistics, pages 96-101.Claire Cardie and Kiri Wagstaff.
1999.
Noun phrasecoreference asclustering.
In Proceed imJs of the JointConference on Bmpirical Methods in NI, P and VeryLarge Corpor?Niyu Ge, John Gale and Eugene Charuiak.
1998.Anaphora Resolution: A Multi-Strategy Approach.
InProceedings of the 6th Workshop on Very Large CoP.pore, (coLnvG/ACL 'gS).Barbara J. grca, Aravind K. Joshi and Scott Weinstein.1995.
Centering.
A Framework for Modeling the LocalCoherence of Discourse.
Computational Linguistics,21(2).M.A.K.
Halliday and 1~ Hassan.
1976.
Cohesion in Enoglisk Longman, London.Sanda M. Harabagiu.
1998.
Deriving metonymic coer-dons from WordNet.
In Proceedings of the Worlc~hopof the OsmJe of WordaVet in Natural .Language Pro-ce~ir~ SysternJ, CO LING.A CI, "gs, pages 142-148.Sanda M. Harabagiu and Dan I. Moldovan.
1998.
A Par-allel System for Text Inference Using Marker Propaga-tions.
IBB8 Tmnaactions on Pandlel and 'D~ib~,ff/sl~s, 9(8):729--747.Sands M. Harabagiu.
1999.
From Lexical Cohesion toTextual Coherence:.
A Data Driven Persoective.
lmternational Journal of Pattern Recofnition and Arti-tidal Intelligence, 13(2):1-18.Ma~ A. Hearst.
1997.
TextTiling: Segmenting Textinto Multi-paragraph Subtopic Passages.
Computa-tional L in~t ics ,  23(1):33--64.Lynette Hirslunan and Nancy Chinchor.
1997.
MUC-7Coreference Task D,~nition.Lynette Itirshman, Patricia Robinson, John Burger andMarc Vilain.
1998.
The role of Annotated TrainingData.37Graeme Hirst and David St-Onge.
1998.
Lexical Chainsas Representations of Context for the Detection andCorrection of Malapropism.
In WordNet - An Elec.tronic Lexical Databaze, Edited by Christiane Fell-baum, MIT Press.Jerry R. Hobbs.
Resolving pronoun references.
Lingua,44:311-338.Jerry R. Hobbs.
1979.
Coherence and coreferen'ce.
Cog-nitive Science, 3(1):67-90.Jerry R. Hobbs.
1985.
On the coherence and structureof discourse Technical Report CSLI-85-37, StanfordUn ivers i ty .Jerry It .
Hobbs, Mark  Stickel, Doug.E.
Appelt ,  and PaulMart in.
1993.
Interpretat ion as abduction.
ArtificialInteUigence; 63:69--142.Shalom LapPin and Herbert Learn.
1994.
An algorithmfor pronominal anaphora resolution.
ComputationalLinguistics, 20(4)'535-662.Megumi Kameyama.
1997.
Recognizing Re~erentialLi, I~: An Information Extraction Perspective.
InProe~-~-inos /the Workshop on Operational Factormin Practica~ Robu~rt Anaphom Resolution for Un-re.drict~d Texts, (A CL-97/BA OL.
97), pages 46-53,Madrid, Spa=.Andrew Kehler.
1997.
ProbabilLstic Coreference in In-formation Extraction.
In Pro,:ee~_ings of the SecondCon/erenc~ on Empirical Methods in Natural Lan-guage PreceJsin9 ($IGDA T), pages 163-173.Christopher Kennedy end Braulmir Bagure~v.
1996.Aaaphora for everyone: Pronomln~d anaphora reso-lution without a parser.
In Proc_eedings of the 16thInternational Conferenc~ on Computational Linguis-tic~ (COLhVQ.96).William (2.
Mann and Sandra A. Thompson 1988.Rhetorical Structure ~ I Toward a functionaltheory of text organization.
Te~ 8:243-281.M.
Marcus, B. Santorini and M.A.
Mar~/-t~ewics.1993.
Building & large annotated corpm of En-glish: The Penn Tteebank.
Computational Linguis-19(2):313-330, 1993.Joseph F. McCarthy and Weady Lelmert.
1995.
Us-Lug ded~'on trees f-~ corefereace r solution.
In Pro-eenlin~ o/the IJth lntmmtior~ Joint Con/.~,.-.~e onArtificial Intdligen~ (IJOAI-95), pages 1050-1055.Kathy McKeown.
198,5.
Discourm~ strategies for gem-eragmg natural-language text.
Artificial Intdligenee,27:1--41, 1985.George A. Miller.
1995.
WordNet: A Le~d Database.Communication f the A CM, 38(11):39-41.Ruslan Mitkov.
1998.
Robust pronoun resolutionwith limited knowledge.
In ProeePdings of COLING-A 0L'98, pages 869-875.Jane Morris and Graeme Hirst.
1991.
Lexieal cohesioncomputed by thesaura\] relations as an indicator of the?
structure of text.
Computational Linguistics, 17:21-48.Massimo Poesio and Renata VieLra.
1998.
A corpus-baaed investigation of definite description use.
Com.putational Linguistics, 24(2):183-216.Philip Resnik.
1995.
Using information content to evalu-ate semantic similarity in a taxonomy.
In Proceedingsof the 14th lnt~natiomd Joint Conference on Artifi.cial Intdligenee (IJCAI-95), pages 448-453.Elaine Rich and Susan Luperfoy.
1988.
An architecturefor anaphora resolution.
In Proceedin9s of the ?6thAnnual Meeting of the Association for ComputationalLinguistics (ACL-88), pages 18-24.Bonnie Webber.
Discourse deixis: Reference to discoursesegments.
In Prveeedings of the ,~6th Annual Meet-ing of the Association for Computational Linguistics(ACI,.88), pages 113-121.Robert  W'flensky.
1987.
Understondin90oal.B~ed Sto-r/?J.
Phi) thesis, Yale University, New Haven, CT.Appendix(def~m nue-nccudO(ccmplle-uAms~(( ( (~1 e l l  ~A)l.2))((u~mmJ-posL~JLon e21 zl)(~Laboral~i~ e21 e11)) O )((((asmma-~sitlm .22 z2).IS)((e~ty-posi~ioa *22 z2).6))((nO-Sl~?~la~Imm ,22 x2)) O )( ( ( ( l~L~.
lms  ,2~ e13)1.2))((Co1~1 .13 *23 e13))O)(O  ((mine1.1 4 )  O ))  six ' (e l  a))(41*~e~ret (complIo-loK'X col-.~orm?
(C(~ltel  e l  e2 e) lO)((no-specula~:l.oa~ 02 8)10)) n i l  nlZ)))?
Cna=e-,mcc,,.UO Corn:: 20 /n/l:tal losical toz-a:((C0ML FA Z2 EJoI0.00o0)((II0-SN~(~Z.&TZ01S E2 A).I0.00o0)I Cost: 22.0 fraa e .z.~-~,;~ nm,~.
in 0 us4q; ,-,Los 3.0:( (n  ~wJ~12011 E!
~) , I2 .00 ,1) ( (XO-S~I~OXS ~ 1),10.00,0)(CO~ \[1 i~ El)Con: 22.0 2ro8 .
e ~  IIO-SPECI~'rZOIIS :1~ 0 ~:rmg u:lLeo 2.0:((CO~lJ~ FA E2 F.).I0.00.0)((ASSOI~-FOSZTZ~ E2 l),S.00,1)(0~pl'Yoposrrza E2 A), 6.00o 1)cIm-s~q~cuu'l~lnls E2 A)3 Cost: 24.400002 fz~8 e ~  ~_ltrquLT1/H in I uJLng mrA~ 1.1:(L~ilIME-P0$XI'XUM El A)(U, AI011ATXOM E2 Z44)(M0-SPECOLITXO~J E2 A)(co~ E1 E2 ?1)S Cost: 10 tz~m ezpiadJa 8 ~ ix  3 using az l~ 4.0:((ll0-MPEC0UTI0ml E2 A), 10.00.
0)01AM~ I~.
A)~. '
J rx0g E!
i~.
)(J~-P0SI'rxIMI !~ A)(Cling.
El El Zl)9 Co~: 8.0 ~rm eZlXUd/q \]I0-~Ur..AI'ZUS/a 8 u tz~ aztcm 2.0:(ORetY-p0~l~J~ !~ 1).e.00.1)(10-SPECNA~ I~ 13 ( ~  IU, A)(EL~WIUIT'J\[ml Z2 El)(L~qOME-P0~Frx011 I~ A)(~m~n El.
!~ El)10 Cost: 211.400002 #oa expud/q  IIO--SI~,ODL~I"208 :i~ 3uh~ az/~.. 2.0:( (~  F.A X42), 14.o40o 2) ( ( J~'~- i~I~ZOM E2 a)06.00, 1)((exP~r-i,0~lTzl~l E!
i ) ,  S.00, t)OIO-SPi~TZmlS I~ ~)C I~TZB E2 \[1)238000@0@0OO000O000O0000O@0@@0@@00@00000OO0O0@0
