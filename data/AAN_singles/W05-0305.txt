Proceedings of the Workshop on Frontiers in Corpus Annotation II: Pie in the Sky, pages 29?36,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsAttribution and the (Non-)Alignment of Syntactic and Discourse Argumentsof ConnectivesNikhil Dinesh and Alan Lee and Eleni Miltsakaki and Rashmi Prasad and Aravind JoshiUniversity of PennsylvaniaPhiladelphia, PA 19104 USAfnikhild,aleewk,elenimi,rjprasad,joshig@linc.cis.upenn.eduBonnie WebberUniversity of EdinburghEdinburgh, EH8 9LW Scotlandbonnie@inf.ed.ac.ukAbstractThe annotations of the Penn DiscourseTreebank (PDTB) include (1) discourseconnectives and their arguments, and (2)attribution of each argument of each con-nective and of the relation it denotes.
Be-cause the PDTB covers the same text asthe Penn TreeBank WSJ corpus, syntac-tic and discourse annotation can be com-pared.
This has revealed significant dif-ferences between syntactic structure anddiscourse structure, in terms of the argu-ments of connectives, due in large part toattribution.
We describe these differences,an algorithm for detecting them, and fi-nally some experimental results.
These re-sults have implications for automating dis-course annotation based on syntactic an-notation.1 IntroductionThe overall goal of the Penn Discourse Treebank(PDTB) is to annotate the million word WSJ cor-pus in the Penn TreeBank (Marcus et al, 1993) witha layer of discourse annotations.
A preliminary re-port on this project was presented at the 2004 work-shop on Frontiers in Corpus Annotation (Miltsakakiet al, 2004a), where we described our annotationof discourse connectives (both explicit and implicit)along with their (clausal) arguments.Further work done since then includes the an-notation of attribution: that is, who has expressedeach argument to a discourse connective (the writeror some other speaker or author) and who has ex-pressed the discourse relation itself.
These ascrip-tions need not be the same.
Of particular interest isthe fact that attribution may or may not play a rolein the relation established by a connective.
This maylead to a lack of congruence between arguments atthe syntactic and the discourse levels.
The issue ofcongruence is of interest both from the perspectiveof annotation (where it means that, even within asingle sentence, one cannot merely transfer the an-notation of syntactic arguments of a subordinate orcoordinate conjunction to its discourse arguments),and from the perspective of inferences that these an-notations will support in future applications of thePDTB.The paper is organized as follows.
We give a briefoverview of the annotation of connectives and theirarguments in the PDTB in Section 2.
In Section 3,we describe the annotation of the attribution of thearguments of a connective and the relation it con-veys.
In Sections 4 and 5, we describe mismatchesthat arise between the discourse arguments of a con-nective and the syntactic annotation as provided bythe Penn TreeBank (PTB), in the cases where all thearguments of the connective are in the same sen-tence.
In Section 6, we will discuss some implica-tions of these issues for the theory and practice ofdiscourse annotation and their relevance even at thelevel of sentence-bound annotation.2 Overview of the PDTBThe PDTB builds on the DLTAG approach to dis-course structure (Webber and Joshi, 1998; Webberet al, 1999; Webber et al, 2003) in which con-nectives are discourse-level predicates which projectpredicate-argument structure on a par with verbs at29the sentence level.
Initial work on the PDTB hasbeen described in Miltsakaki et al (2004a), Milt-sakaki et al (2004b), Prasad et al (2004).The key contribution of the PDTB design frame-work is its bottom-up approach to discourse struc-ture: Instead of appealing to an abstract (and arbi-trary) set of discourse relations whose identificationmay confound multiple sources of discourse mean-ing, we start with the annotation of discourse con-nectives and their arguments, thus exposing a clearlydefined level of discourse representation.The PDTB annotates as explicit discourse connec-tives all subordinating conjunctions, coordinatingconjunctions and discourse adverbials.
These pred-icates establish relations between two abstract ob-jects such as events, states and propositions (Asher,1993).1We use Conn to denote the connective, and Arg1and Arg2 to denote the textual spans from which theabstract object arguments are computed.2 In (1), thesubordinating conjunction since establishes a tem-poral relation between the event of the earthquakehitting and a state where no music is played by acertain woman.
In all the examples in this paper, asin (1), Arg1 is italicized, Arg2 is in boldface, andConn is underlined.
(1) She hasn?t played any music since the earthquakehit.What counts as a legal argument?
Since we takediscourse relations to hold between abstract objects,we require that an argument contains at least oneclause-level predication (usually a verb ?
tensed oruntensed), though it may span as much as a sequenceof clauses or sentences.
The two exceptions arenominal phrases that express an event or a state, anddiscourse deictics that denote an abstract object.1For example, discourse adverbials like as a result are dis-tinguished from clausal adverbials like strangely which requireonly a single abstract object (Forbes, 2003).2Each connective has exactly two arguments.
The argumentthat appears in the clause syntactically associated with the con-nective, we call Arg2.
The other argument is called Arg1.
BothArg1 and Arg2 can be in the same sentence, as is the case forsubordinating conjunctions (e.g., because).
The linear order ofthe arguments will be Arg2 Arg1 if the subordinate clause ap-pears sentence initially; Arg1 Arg2 if the subordinate clause ap-pears sentence finally; and undefined if it appears sentence me-dially.
For an adverbial connective like however, Arg1 is in theprior discourse.
Hence, the linear order of its arguments will beArg1 Arg2.Because our annotation is on the same corpus asthe PTB, annotators may select as arguments textualspans that omit content that can be recovered fromsyntax.
In (2), for example, the relative clause isselected as Arg1 of even though, and its subject canbe recovered from its syntactic analysis in the PTB.In (3), the subject of the infinitival clause in Arg1 issimilarly available.
(2) Workers described ?clouds of blue dust?
that hungover parts of the factory even though exhaust fansventilated the air.
(3) The average maturity for funds open only to institu-tions, considered by some to be a stronger indicatorbecause those managers watch the market closely,reached a high point for the year ?
33 days.The PDTB also annotates implicit connectives be-tween adjacent sentences where no explicit connec-tive occurs.
For example, in (4), the two sentencesare contrasted in a way similar to having an explicitconnective like but occurring between them.
Anno-tators are asked to provide, when possible, an ex-plicit connective that best describes the relation, andin this case in contrast was chosen.
(4) The $6 billion that some 40 companies are looking toraise in the year ending March 21 compares with only$2.7 billion raise on the capital market in the previousyear.
IMPLICIT - in contrast In fiscal 1984, beforeMr.
Gandhi came into power, only $810 millionwas raised.When complete, the PDTB will contain approxi-mately 35K annotations: 15K annotations of the 100explicit connectives identified in the corpus and 20Kannotations of implicit connectives.33 Annotation of attributionWiebe and her colleagues have pointed out theimportance of ascribing beliefs and assertions ex-pressed in text to the agent(s) holding or makingthem (Riloff and Wiebe, 2003; Wiebe et al, 2004;Wiebe et al, 2005).
They have also gone a consid-erable way towards specifying how such subjectivematerial should be annotated (Wiebe, 2002).
Sincewe take discourse connectives to convey semanticpredicate-argument relations between abstract ob-jects, one can distinguish a variety of cases depend-ing on the attribution of the discourse relation or its3The annotation guidelines for the PDTB are available athttp://www.cis.upenn.edu/pdtb.30arguments; that is, whether the relation or argumentsare ascribed to the author of the text or someoneother than the author.Case 1: The relation and both arguments are at-tributed to the same source.
In (5), the concessiverelation between Arg1 and Arg2, anchored on theconnective even though is attributed to the speakerDick Mayer, because he is quoted as having saidit.
Even where a connective and its arguments arenot included in a single quotation, the attribution canstill be marked explicitly as shown in (6), where onlyArg2 is quoted directly but both Arg1 and Arg2 canbe attibuted to Mr. Prideaux.
Attribution to somespeaker can also be marked in reported speech asshown in the annotation of so that in (7).
(5) ?Now, Philip Morris Kraft General Foods?
parentcompany is committed to the coffee business and toincreased advertising for Maxwell House,?
says DickMayer, president of the General Foods USA division.
?Even though brand loyalty is rather strong for cof-fee, we need advertising to maintain and strengthenit.?
(6) B.A.T isn?t predicting a postponement because theunits ?are quality businesses and we are en-couraged by the breadth of inquiries,?
said Mr.Prideaux.
(7) Like other large Valley companies, Intel also notedthat it has factories in several parts of the nation,so that a breakdown at one location shouldn?t leavecustomers in a total pinch.Wherever there is a clear indication that a relationis attributed to someone other than the author of thetext, we annotate the relation with the feature valueSA for ?speaker attribution?
which is the case for(5), (6), and (7).
The arguments in these examplesare given the feature value IN to indicate that they?inherit?
the attribution of the relation.
If the rela-tion and its arguments are attributed to the writer,they are given the feature values WA and IN respec-tively.Relations are attributed to the writer of the text bydefault.
Such cases include many instances of re-lations whose attribution is ambiguous between thewriter or some other speaker.
In (8), for example,we cannot tell if the relation anchored on althoughis attributed to the spokeswoman or the author of thetext.
As a default, we always take it to be attributedto the writer.Case 2: One or both arguments have a different at-tribution value from the relation.
While the defaultvalue for the attribution of an argument is the attribu-tion of its relation, it can differ as in (8).
Here, as in-dicated above, the relation is attributed to the writer(annotated WA) by default, but Arg2 is attributed toDelmed (annotated SA, for some speaker other thanthe writer, and other than the one establishing therelation).
(8) The current distribution arrangement ends in March1990 , although Delmed said it will continue to pro-vide some supplies of the peritoneal dialysis prod-ucts to National Medical, the spokeswoman said.Annotating the corpus with attribution is neces-sary because in many cases the text containing thesource of attribution is located in a different sen-tence.
Such is the case for (5) where the relationconveyed by even though, and its arguments are at-tributed to Dick Mayer.We are also adding attribution values to the anno-tation of the implicit connectives.
Implicit connec-tives express relations that are inferred by the reader.In such cases, the author intends for the reader toinfer a discourse relation.
As with explicit connec-tives, we have found it useful to distinguish implicitrelations intended by the writer of the article fromthose intended by some other author or speaker.
Togive an example, the implicit relation in (9) is at-tributed to the writer.
However, in (10) both Arg1and Arg2 have been expressed by the speaker whosespeech is being quoted.
In this case, the implicit re-lation is attributed to the speaker.
(9) Investors in stock funds didn?t panic the week-end after mid-October?s 190-point market plunge.IMPLICIT-instead Most of those who left stockfunds simply switched into money market funds.
(10) ?People say they swim, and that may mean they?vebeen to the beach this year,?
Fitness and Sports.
?It?shard to know if people are responding truthfully.IMPLICIT-because People are too embarrassed tosay they haven?t done anything.
?The annotation of attribution is currently under-way.
The final version of the PDTB will include an-notations of attribution for all the annotated connec-tives and their arguments.Note that in the Rhetorical Structure Theory(RST) annotation scheme (Carlson et al, 2003), at-tribution is treated as a discourse relation.
We, onthe other hand, do not treat attribution as a discourse31relation.
In PDTB, discourse relations (associatedwith an explicit or implicit connective) hold betweentwo abstracts objects, such as events, states, etc.
At-tribution relates a proposition to an entity, not to an-other proposition, event, etc.
This is an importantdifference between the two frameworks.
One conse-quence of this difference is briefly discussed in Foot-note 4 in the next section.4 Arguments of SubordinatingConjunctions in the PTBA natural question that arises with the annotationof arguments of subordinating conjunctions (SUB-CONJS) in the PDTB is to what extent they can bedetected directly from the syntactic annotation in thePTB.
In the simplest case, Arg2 of a SUBCONJ is itscomplement in the syntactic representation.
This isindeed the case for (11), where since is analyzed asa preposition in the PTB taking an S complementwhich is Arg2 in the PDTB, as shown in Figure 1.
(11) Since the budget measures cash flow, a new $1 di-rect loan is treated as a $1 expenditure.Furthermore, in (11), since together with its com-plement (Arg2) is analyzed as an SBAR which mod-ifies the clause a new $1 direct loan is treated as a$1 expenditure, and this clause is Arg1 in the PDTB.Can the arguments always be detected in thisway?
In this section, we present statistics showingthat this is not the case and an analysis that showsthat this lack of congruence between the PDTB andthe PTB is not just a matter of annotator disagree-ment.Consider example (12), where the PTB requiresannotators to include the verb of attribution saidand its subject Delmed in the complement of al-though.
But although as a discourse connective de-nies the expectation that the supply of dialysis prod-ucts will be discontinued when the distribution ar-rangement ends.
It does not convey the expectationthat Delmed will not say such things.
On the otherhand, in (13), the contrast established by while is be-tween the opinions of two entities i.e., advocates andtheir opponents.44This distinction is hard to capture in an RST-based pars-ing framework (Marcu, 2000).
According to the RST-based an-notation scheme (Carlson et al, 2003) ?although Delmed said?and ?while opponents argued?
are elementary discourse units(12) The current distribution arrangement ends in March1990, although Delmed said it will continue to pro-vide some supplies of the peritoneal dialysis prod-ucts to National Medical, the spokeswoman said.
(13) Advocates said the 90-cent-an-hour rise, to $4.25 anhour by April 1991, is too small for the working poor,while opponents argued that the increase will stillhurt small business and cost many thousands ofjobs.In Section 5, we will identify additional cases.
Whatwe will then argue is that it will be insufficient totrain an algorithm for identifying discourse argu-ments simply on the basis of syntactically analysedtext.We now present preliminary measurements ofthese and other mismatches between the two corporafor SUBCONJS.
To do this we describe a proceduralalgorithm which builds on the idea presented at thestart of this section.
The statistics are preliminary inthat only the annotations of a single annotator wereconsidered, and we have not attempted to excludecases in which annotators disagree.We consider only those SUBCONJS for which botharguments are located in the same sentence as theconnective (which is the case for approximately 99%of the annotated instances).
The syntactic configura-tion of such relations pattern in a way shown in Fig-ure 1.
Note that it is not necessary for any of Conn,Arg1, or Arg2 to have a single node in the parse treethat dominates it exactly.
In Figure 1 we do obtain asingle node for Conn, and Arg2 but for Arg1, it isthe set of nodes fNP; V Pg that dominate it exactly.Connectives like so that, and even if are not domi-nated by a single node, and cases where the annota-tor has decided that a (parenthetical) clausal elementis not minimally necessary to the interpretation ofArg2 will necessitate choosing multiple nodes thatdominate Arg2 exactly.Given the node(s) in the parse tree that dominateConn (fINg in Figure 1), the algorithm we presenttries to find node(s) in the parse tree that dominateArg1 and Arg2 exactly using the operation of treesubtraction (Sections 4.1, and 4.2).
We then discussits execution on (11) in Section 4.3.annotated in the same way: as satellites of the relation Attribu-tion.
RST does not recognize that satellite segments, such asthe ones given above, sometimes participate in a higher RSTrelation along with their nuclei and sometimes not.32S12SBAR NPA new $1 directloanVPis treated as a$1 expenditureIN S2the budget mea-sures cash flowsinceGiven NConn= fINg, our goal is to find NArg1=fNP; V Pg, and NArg2= fS2g.
Steps: hConn= IN xConn+Arg2= SBAR  parent(hConn) xConn+Arg1+Arg2= S12 lowest Ancestorparent(xConn+Arg2)with la-bel S or SBAR.
Note that x 2 Ancestorx NArg2= xConn+Arg2 NConn= SBAR  fINg= fS2g NArg1= xConn+Arg1+Arg2  fxConn+Arg2g= S12  fSBARg= fNP; V PgFigure 1: The syntactic configuration for (11), and the execution of the tree subtraction algorithm on this configuration.4.1 Tree subtractionWe will now define the operation of tree subtractionthe graphical intuition for which is given in Figure2.
Let T be the set of nodes in the tree.Definition 4.1.
The ancestors of any node t 2 T ,denoted by Ancestort T is a set of nodes suchthat t 2 Ancestortand parent(u; t) ) ([u 2Ancestort] ^ [Ancestoru Ancestort])Definition 4.2.
Consider a node x 2 T , and a setof nodes Y  T   fxg, we define the set Z 0 =fnjn 2 T   fxg ^ x 2 Ancestorn^ (8y 2 Y; y 62Ancestorn^ n 62 Ancestory)g. Given such an xand Y , the operation of tree subtraction gives a setof nodes Z such that, Z = fz1jz12 Z0^ (8z22Z0; z262 (Ancestorz1  fz1g))gWe denote this by x  Y = Z .The nodes z 2 Z are the highest descendants ofx, which do not dominate any node y 2 Y and arenot dominated by any node in Y .4.2 Algorithm to detect the argumentsFor any t 2 T , let Ltdenote the set of leaves(orterminals) dominated by t and for A  T we denotethe set of leaves dominated by A as LA=[8a2ALa.X   fy1; y2g = fz1; z2gXy1z2y2z1Figure 2: Tree subtraction x  Y = ZFor any set of leaves L we define N 0Lto be a setof nodes of maximum cardinality such that LN0L=[8n2N0LLn= LThe set NL= fn1jn12 N0L^ (8n22 N0L; n262(Ancestorn1  fn1g))g. We can think of Conn,Arg1 and Arg2 each as a set of leaves and we useNConn, NArg1and NArg2to denote the set of high-est nodes which dominate them respectively.Given NConn, our task is then to find NArg1and33NArg2.
The algorithm does the following:1.
Let hConn(the head) be the last node in NConnin an in-order traversal of the tree.2.
xConn+Arg2 parent(hConn)3.
Repeat while parent(xConn+Arg2) has label S or SBAR,and has only two children:xConn+Arg2= parent(xConn+Arg2)This ensures the inclusion of complementizers and subor-dinating conjuctions associated with the clause in Arg1.The convention adopted by the PDTB was to include suchelements in the clause with which they were associated.4.
xConn+Arg1+Arg2is the lowest node with label S orSBAR such that:xConn+Arg1+Arg22 Ancestorparent(xConn+Arg2)5.
Repeat while parent(xConn+Arg1+Arg2) has label S orSBAR, and has only two children:xConn+Arg1+Arg2= parent(xConn+Arg1+Arg2)6.
NArg2= xConn+Arg2 NConn(tree subtraction)7.
NArg1= xConn+Arg1+Arg2 fxConn+Arg2g (tree sub-traction)4.3 Executing the algorithm on (11)The idea behind the algorithm is as follows.
Sincewe may not be able to find a single node that domi-nates Conn, Arg1, and/or Arg2 exactly, we attemptto find a node that dominates Conn and Arg2 to-gether denoted by xConn+Arg2(SBAR in Figure 1),and a node that dominates Conn, Arg1 and Arg2together denoted by xConn+Arg1+Arg2(S12in Fig-ure 1).
Note that this is an approximation, and theremay be no single node that dominates Conn, andArg2 exactly.Given xConn+Arg2the idea is to remove all thematerial corresponding to Conn (NConn) under thatnode and call the rest of the material Arg2.
This iswhat the operation of tree subtraction gives us, i.e.,xConn+Arg2 NConnwhich is fS2g in Figure 1.Similarly, given xConn+Arg1+Arg2we would liketo remove the material corresponding to Connand Arg2 and fxConn+Arg2g is that material.xConn+Arg1+Arg2  fxConn+Arg2g gives us thenodes fNP; V Pg which is the desired Arg1.5 Evaluation of the tree subtractionalgorithmDescribing the mismatches between the syntacticand discourse levels of annotation requires a detailedanalysis of the cases where the tree subtraction al-gorithm does not detect the same arguments as an-notated by the PDTB.
Hence this first set of exper-iments was carried out only on Sections 00-01 ofthe WSJ corpus (about 3500 sentences), which is ac-cepted by the community to be development data.First, the tree subtraction algorithm was run onthe PTB annotations in these two sections.
The ar-guments detected by the algorithm were classifiedas: (a) Exact, if the argument detected by the al-gorithm exactly matches the annotation; (b) ExtraMaterial, if the argument detected contains someadditional material in comparison with the annota-tion; and (c) Omitted Material, if some annotatedmaterial was not included in the argument detected.The results are summarized in Table 1.Argument Exact Extra Material Omitted MaterialArg1 82.5% 12.6% 4.9%(353) (54) (21)Arg2 93.7% 2.6% 3.7%(401) (11) (16)Table 1: Tree subtraction on the PTB annotations for SUB-CONJS.
Section 00-01(428 instances)5.1 Analysis of the results in Table 15.1.1 Extra MaterialThere were 54 (11) cases where Arg1 (Arg2) inthe PTB (obtained via tree subtraction) containedmore material than the corresponding annotation inthe PDTB.
We describe only the cases for Arg1,since they were a superset of the cases for Arg2.Second VP-coordinate - In these cases, Arg1 ofthe SUBCONJ was associated with the second of twocoordinated VPs.
Example (14) is the relation an-notated by the PDTB, while (15) is the relation pro-duced by tree subtraction.
(14) She became an abortionist accidentally, and continuedbecause it enabled her to buy jam, cocoa and otherwar-rationed goodies.
(15) She became an abortionist accidentally, and contin-ued because it enabled her to buy jam, cocoa andother war-rationed goodies.Such mismatches can be either due to the factthat the algorithm looks only for nodes of type Sor SBAR, or due to disagreement between the PTBand PDTB.
Further investigation is needed to under-34stand this issue more precisely.5 The percentage ofsuch mismatches (with respect to the total numberof cases of extra material) is recorded in the first col-umn of Table 2, along with the number of instancesin parentheses.Lower Verb - These are cases of a true mismatchbetween the PDTB and the PTB, where the PDTBhas associated Arg1 with a lower clause than thePTB.
9 of the 13 ?lower verb?
cases for Arg1 weredue to verbs of attribution, as in (12).
(The percent-age of ?lower verb?
mismatches is given in the sec-ond column of Table 2, along with the number ofinstances in parentheses.
)Clausal Adjuncts - Finally, we considered caseswhere clause(s) judged not to be minimally neces-sary to the interpretation of Arg1 were included.
(16) shows the relation annotated by the PDTB,where the subordinate clause headed by partly be-cause is not part of Arg1, but the tree subtractionalgorithm includes it as shown in (17).
(16) When Ms. Evans took her job, several importantdivisions that had reported to her predecessor weren?tincluded partly because she didn?t wish to be a fulladministrator.
(17) When Ms. Evans took her job, several importantdivisions that had reported to her predecessor weren?tincluded partly because she didn?t wish to be a fulladministrator.To get an idea of the number of cases where asingle irrelevant clause was included, we determinedthe number of instances for which pruning out onenode from Arg1 resulted in an exact match.
This isgiven in the third column of Table 2.
The secondrow of Table 2 illustrates the same information forArg2.
Most of these are instances where irrelevantclauses were included in the argument detected fromthe PTB.Argument Second VP Lower One Node OtherCoordinate Verb PrunedArg1 16.7% 24.1% 31.5% 27.7%(9) (13) (17) (15)Arg2 0% 9.1% 72.7% 18.2%(0) (1) (8) (2)Table 2: Cases which result in extra material being includedin the arguments.5It is also possible for the PDTB to associate an argumentwith only the first of two coordinated VPs, but the number ofsuch cases were insignificant.5.1.2 Omitted MaterialThe main source of these errors in Arg1 are thehigher verb cases.
Here the PDTB has associatedArg1 with a higher clause than the PTB.
Examples(18) and (19) show the annotated and algorithmi-cally produced relations respectively.
This is the in-verse of the aforementioned lower verb cases, andthe majority of these cases are due to the verb of at-tribution being a part of the relation.
(18) Longer maturities are thought to indicate declininginterest rates because they permit portfolio man-agers to retain relatively higher rates for a longerperiod.
(19) Longer maturities are thought to indicate declining in-terest rates because they permit portfolio managersto retain relatively higher rates for a longer period.To get an approximate idea of these errors, wechecked if selecting a higher S or SBAR made theArg1 exact or include extra material.
These are thecolumns Two up exact and Two up extra includedin Table 3.
At this time, we lack a precise under-standing of the remaining mismatches in Arg1, andthe ones resulting in material being omitted fromArg2.Argument Two up exact Two up extra OtherincludedArg1 47.6% (10) 14.3% (3) 28.1% (8)Table 3: Cases which result in material being omitted fromArg1 as a result of excluding a higher verb5.2 Additional experimentsWe also evaluated the performance of the tree sub-traction procedure on the PTB annotations on Sec-tions 02-24 of the WSJ corpus, and the results aresummarized in Table 4.Argument Exact Extra Material Omitted MaterialArg1 76.1% 17.6% 6.3%Arg2 92.5% 3.6% 3.9%Table 4: Tree subtraction on PTB annotations for the SUB-CONJS(approx.
5K instances).
Sections 02-24Finally we evaluated the algorithm on the outputof a statistical parser.
The parser implementation in(Bikel, 2002) was used in this experiment and it wasrun in a mode which emulated the Collins (1997)parser.
The parser was trained on Sections 02-21and Sections 22-24 were used as test data, where35the parser was run and the tree subtraction algorithmwas run on its output.
The results are summarized inTable 5.Argument Exact Extra Material Omitted MaterialArg1 65.5% 25.2% 9.3%Arg2 84.7% 0% 15.3%Table 5: Tree subtraction on the output of a statistical parser(approx.
600 instances).
Sections 22-24.6 ConclusionsWhile it is clear that discourse annotation goes be-yond syntactic annotation, one might have thoughtthat at least for the annotation of arguments of subor-dinating conjunctions, these two levels of annotationwould converge.
However, we have shown that thisis not always the case.
We have also described analgorithm for discovering such divergences, whichcan serve as a useful baseline for future efforts to de-tect the arguments with greater accuracy.
The statis-tics presented suggest that the annotation of the dis-course arguments of the subordinating conjunctionsneeds to proceed separately from syntactic annota-tion ?
certainly when annotating other English cor-pora and very possibly for other languages as well.A major source of the mismatches between syn-tax and discourse is the effect of attribution, eitherthat of the arguments or of the relation denoted bythe connective.
We believe that the annotation of at-tribution in the PDTB will prove to be a useful aidto applications that need to detect the relations con-veyed by discourse connectives with a high degreeof reliability, as well as in constraining the infer-ences that may be drawn with respect to the writer?scommitment to the relation or the arguments.
Theresults in this paper also raise the more general ques-tion of whether there may be other mismatches be-tween the syntactic and discourse annotations at thesentence level.ReferencesNicholas Asher.
1993.
Reference to Abstract Objects in Dis-course.
Kluwer Academic Press.Daniel Bikel.
2002.
Design of a Multi-lingual, Parallel-processing Statistical Parsing Engine.
In HLT.Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski,2003.
Current Directions in Discourse and Dialogue, chap-ter Building a Discourse-Tagged Corpus in the frameworkof Rhetorical Structure Theory, pages 85?112.
Kluwer Aca-demic Publishers.Michael Collins.
1997.
Three Generative, Lexicalized Modelsfor Statistical Parsing.
In 35th Annual Meeting of the ACL.Katherine Forbes.
2003.
Discourse Semantics of S-ModifyingAdverbials.
Ph.D. thesis, Department of Linguistics, Uni-versity of Pennsylvania.Daniel Marcu.
2000.
The Rhetorical Parsing of UnrestrictedTexts: A Surface-Based Approach.
Computational Linguis-tics, 26(3):395?448.Mitchell Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large scale anno-tated corpus of english: the Penn Treebank.
ComputationalLinguistics, 19.Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and BonnieWebber.
2004a.
Annotating Discourse Connectives andtheir Arguments.
In the HLT/NAACL workshop on Frontiersin Corpus Annotation, Boston, MA.Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and BonnieWebber.
2004b.
The Penn Discourse Treebank.
In the Lan-guage Resources and Evaluation Conference, Lisbon, Portu-gal.Rashmi Prasad, Eleni Miltsakaki, Aravind Joshi, and BonnieWebber.
2004.
Annotation and Data Mining of the PennDiscourse TreeBank.
In ACL Workshop on Discourse Anno-tation, Barcelona, Spain.Ellen Riloff and Janyce Wiebe.
2003.
Learning Extraction Pat-terns for Subjective Expressions.
In Proceedings of the SIG-DAT Conference on Empirical Methods in Natural LanguageProcessing (EMNLP ?03), pages 105?112, Sapporo, Japan.Bonnie Webber and Aravind Joshi.
1998.
Anchoring aLexicalized Tree-Adjoining Grammar for Discourse.
InACL/COLING Workshop on Discourse Relations and Dis-course Markers, Montreal, Canada, August.Bonnie Webber, Alistair Knott, Matthew Stone, and AravindJoshi.
1999.
Discourse Relations: A Structural and Presup-positional Account using Lexicalized TAG.
In ACL, CollegePark, MD, June.Bonnie Webber, Aravind Joshi, Matthew Stone, and AlistairKnott.
2003.
Anaphora and Discourse Structure.
Computa-tional Linguistics, 29(4):545?87.Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew Bell,and Melanie Martin.
2004.
Learning subjective language.Computational Linguistics, 30(3):277?308.Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005.
An-notating expressions of opinions and emotions in language.Language Resources and Evaluation, 1(2).Janyce Wiebe.
2002.
Instructions for annotating opinions innewspaper articles.
Technical Report TR-02-101, Depart-ment of Computer Science, University of Pittsburgh.36
