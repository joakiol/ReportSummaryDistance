Bui ld ing a Large Knowledge Basefor a Natura l  Language SystemJerry R. HobbsArtificial Intelligence CenterSRI  Internat ionalandCenter for the Study of Language and InformationStanford UniversityAbst ractA sophisticated natural language system requires alarge knowledge base.
A methodology is described for con-structing one in a principled way.
Facts are selected for theknowledge base by determining what facts are linguisticallypresupposed by a text in the domain of interest.
The factsare sorted into clnsters, and within each cluster they areorganized according to their logical dependencies.
Finally,the facts are encoded as predicate calculus axioms.1.
The Prob lem IIt is well-known that the interpretation of naturallanguage discourse can require arbitrarily detailed worldknowledge and that a sophisticated natural anguage sys-tem must have a large knowledge base.
But heretofore, theknowledge bases in natural language systems have eitherencoded only a few kinds of knowledge - e.g., sort hier-archies - or facts in only very narrow domains.
The aimof this paper is to present a methodology for construct-ing an intermediate-size knowledge base for a natural an-guage system, which constitutes a manageable and princi-pled midway point between these simple knowledge  basesand the impossibly detailed knowledge bases that peopleseem to use.The work described in this paper has been carried outas part of a project to build a system for natural anguageaccess to a computerized medical textbook on hepatitis.The user asks a question in English, and rather than at-tempting to answer it, the system returns the passages inthe text relevant o the question.
The English query istranslated into a logical form by a syntactic and semantictranslation component \[Grosz et al, 1982\].
The textbook isrepresented by a "text structure", consisting, among otherthings, of summaries of the contents of individual passages,expressed in a logical anguage.
Inference procedures, mak-ing use of a knowledge base, seek to match the logical formi I am indebted to Bob Amsler and Don Walker for discussions concern-ing this work.
This research was supported by NIH Grant LM03611from the National Library of Medicine, by Grant IST-8209346 fromthe National Science Foundation, and by a gift from the Systems De=velopment Foundation.of the query with some part of the text structure.
In ad-dition, they attempt o attempt o solve various pragmaticproblems posed by the query, including the resolution ofcoreference, metonymy, and tile implicit predicates ill com-pound nominals.
The inference procedures are discussedelsewhere \[Walker and Hobbs, 1981\].
In this paper a briefexample will have to suffice.Suppose the user asks the question, "Can a patient withmild hepatitis engage in strenuous exercise?"
The relevantpassage in the textbook is labelled, "Management of thePatient: Requirements for Bed Rest".
The inference pro-cedures must show that this heading is relevant to this ques-tion by drawing the appropriate inferences from the knowl-edge base.
Thus the knowledge base must contain the factsthat rest is an activity that consumes little energy, that ex-ercise is an activity, and that if something is strenuous itconsumes much energy, and axioms that relate the concepts"can" and "require" via the concept of possibility.One way to build the knowledge base would have beento analyze the queries in some target dialogs we collectedto determine what facts they seem to require, and to putjust these facts into our knowledge base.
llowever, weare interested in discovering cneral principles of selectionand structuring of such intermediate-sized knowledge bases,principles that would give us reason to believe our knowl-edge base would be useful for unanticipated queries.Thus we have developed a three-stage methodology:I.
Select he facts that should be in the knowledge baseby determining what facts are linguistically presul)posed bythe medical textbook.
This gives us a very good indicationof what knowledge of the domain the user is expected tobring to the textbook and would bring to the system.2.
Organize the facts into clusters and organize the factswithin each cluster according to the logical dependenciesamong the concepts they involve.3.
Encode the facts as predicate calculus axioms, regu-larizing the concepts, or predicates, as necessary.These  stages are discussed in the next three sections.2.
Select ing the FactsTo be useful, a natural language system nmst have a283large vocabulary.
Moreover, when one sets out to axioma-tize a domain, unl-ss one haz a rich set of predicates andfacts to be respousible f-r, a sense of coherence in the ax-iomatizatio, i~ hard to achieve.
One's efforts seem ad hoe.So the first step in building the knowledge base is to makeup an extensive list of words, or predicates, or concepts(the three terms will be used interchangeably here), and anextensiv,~ list of rebwant facts about these predicates.
Wechose about 350 w,,rds from our target dialogs and headingsin the textl,-ok :,ld encoded the relevant facts involvingthese con~'epts.
Because there are dozens of facts one couldstate involving any one of these predicates, we were facedwith the problem of determining those facts that would bemost pertinent for natural language understanding in thisdomain.Our principal tool at this stage was a full-sentence con-cordance of the textbook, displaying the contexts in whichthe words were used.
Our method was to examine thesecontexts and to ask what facts about each concept wererequired to justify each of these uses, what did their useslinguist ically presuppose.The three principal linguistic phenomena we lookedat were predicate-argument relations, compound nominals,and conjoined phrases.
As an example of the first, considertwo uses of the word "data".
The phrase "extensive dataon histocoml)atibility antigens" points to the fact aboutdata that it.
is a set (justifying "extensive") of particularfacts abo~d some subjecl (justifying the "on" argument).The phrase "the data do not consistently show ..." pointsto the fact that data is mssembled to support some conclu-sion.
To arrive at the facts, we ask questions like "Whatis data that it can be extensive or that it can show some-thing?"
For coml)ound nominals we ask, "What generalfacts about the two nouns underlie the implicit relation?
"So for "casual contact circumstances" we posit that contactis a concomitant of activities, and the phrase "contact modeof transmission" leads us to the fact that contact possiblyleads to transmi.-:sion of an agent.
Conjoined noun phrasesindicate the existence of a superordinate in a sort hierar-chy covering all the conjoined concepts.
Thus, the phrase"epidemiolo~, clinical aspects, pathology, diagnosis, andmarmgement" tells us to encode the facts that all of theseare aspects of a disease.As an il l ,stration of the method, let us examine varioususes of the word "disease" to see what facts it suggests:?
"destructive liver disease": A disease has a harmfuleffect on one or more body parts.?
"hepatitis A virus plays a role in chronic liver dis-ease": A disease may be caused by an agent.?
"the clinical manifestations of a disease": A diseaseis detectable by signs and symptoms.?
"the course of a disease" : A disease goes through sev-eral stages in time.?
"infectious disease": A disease can be transmitted.?
'% notifiable disease": A disease has patterns in thepopulation that can be traced by the medical com-munity.We emphasize that this is not a mechanical procedurebut a method of discovery that relies on our informed in-tuitions.
Since it is largely background knowledge we areafter, we can not expect to get it directly by interviewingexperts.
Our method is a way of extracting it frorn thepresuppositions behind linguistic use.The first thing our method gives us is a great deal ofselectivity in the facts we encode.
Consider the word "an-imal".
There are hundreds of facts that we know aboutanimals.
However, in this domain there are only two factswe need.
Animals are used in experiments, ms seen in tl-ecompound nominal "laboratory animal", and animals canhave a disease, and thus transmit it, a.s seen in the phrase"animals implicated in hepatitis".
Similarly, the only rele-vant fact about "water" is that it may be a medium for thetransmission of disease.Secondly, the method points us toward generalizationswe might otherwise miss, when we see a number of usesthat seem to fall within the same class.
For example, theuses of the word "laboratory" seem to be of two kinds:1.
"laboratory animals", "laboratory spores", "labora-tory contamination", laboratory nwthods".2.
"a study by a research laboratory", "laboratory test-ing", "laboratory abnormalities", ':laboratory charac-teristics of hepatitis A ' ,  "laboratory picture".The first of these rests on the fact that experiments involv-ing certain events and entities take place in laboratories.The second rests on the fact that information is acquiredthere.A classical issue in lexical semantics that arises at thisstage is the problem of polysemy.
Should we consider aword, or predicate, as ambiguous, or should we try to find avery general characterization of its meaning that abstractsaway from its use in various contexts?
The concordancemethod suggests a solution.
The rule of thumb we havefollowed is this: if the uses fall into two or three distinct,large classes, the word is treated a.s having separate senses .
.
.
.
.
.
.
.whereas if the uses seem to be spread all over the map, wetry to find a general characterization that covers them all.The word "derive" is an example of the first case.
A deriva-tion is either of information from an investigative activity,as in "epidemiologic patterns derived from historical stud-ies", or of chemicals from body parts, as in "enzymes de-rived from intestinal mucosa".
By contr,~st, the word "pro-duce" (and the word "product"} can be used in a variety ofways: a disease can produce a condition, a virus can pro-duce a disease or a viral particle, something can produce avirus ("the amount of virus produced in the carrier state"),intestinal flora can produce compounds, and something canproduce chemicals from blood ("blood products").
All ofthis suggests that we want to encode only the fact that if xproduces y, then x causes y to come into existence.At this stage in our method, we aimed at only infor-mal, English statements of the facts.
We ended up withapproximately 1000 facts for the knowledge base.
"-2843.
Organizing the Knowledge BaseThe next step is to sort the facts into natural "clusters"(cf.
\[Hayes, 1984\]).
For example, the fact "If x produces y,then x causes y to exist" is a fact about causality.
The fact"The replication of a virus requires components of a cell ofan organism" is a fact about viruses.
The fact "A householdis an environment with a high rate of intimate contact, thusa high risk of transmission" is in the cluster of facts aboutpeople and their activities.
The fact "If bilirubin is notsecreted by the liver, it may indicate injury to the livertissues" is in the medical practice cluster.It is useful to distinguish between clusters of "coreknowledge" that is common to most domains and "domain-specific knowledge".
Among the clusters of core knowledgeare space, time, belief, and goal-directed behavior.
Thedomain-specific knowledge includes clusters of facts aboutviruses, imnmnology, physiology, disease, and medical prac-tice.
The cluster of facts about people and their activitieslies somewhere in between these two.We are taking a rather novel approach to the axiom-atization of core knowledge.
Much of our knowledge andlanguage seems to be based on an underlying "topology",which is then instantiated in many other areas, like space,time, belief, social organizations, and so on.
We have be-gun by axiomatizing this fundamental topology.
At its baseis set theory, axiomatized along traditional lines.
Next isa theory of granularity, in which the key concept is "x isindistinguishable from y with respect o grain g' .
A the-ory of scalar concepts combines granularity and partial or-ders.
The concept of change of state and the interactions ofcontainment and causality are given (perhaps overly sim-ple) axiomatizations.
Finally there is a cluster centeredaround the notion of a "system", which is defined as a setof entities and a set of relations among them.
In the "sys-tem" cluster we provide an interrelated set of predicatesenabling one to characterize the "structure" of a system,producer-consumer r lations among the components, the':function" of a component of a system as a relation be-tween the component's behavior and the behavior of thesystem as a whole, notions of normality, and distributionsof properties among the elements of a system.
The appli-cability of the notion of "system" is very wide; among theentities that can be viewed as systems are viruses, organs,activities, populations, and scientific disciplines.Other general commonsense knowledge is built on topof this naive topolog'y.
The domain of time is seen as aparticular kind of scale defined by change of state, and theaxiomatization builds toward such predicates as "regular"and "persist".
The domain of belief has three principalsubclusters in this application: learning, which includessuch predicates as "find", "test" and "manifest"; reasoning,explicating predicates such as "leads-to" and "consistent";and classifying, with such predicates as "distinguish", "dif-ferentiate" and "identify".
The domain of modalities expli-cates such concepts as necessity, possibility, and likelihood.Finally, in the domain of goal-directed behavior, we char-acterize such predicates as "help", "care" and "risk".In the lowest-level domain-specific clusters - viruses,immunology, physiology, and people and their activities -we begin by specifying their ontology (the different sortsof entities and classes of entities in the cluster), tile inclu-sion relations among the classes, the behaviors of entitiesin the clusters and their interactions with other entities.The "Disease" cluster is axiomatized primarily in terms ofa temporal schema of the progress of an infection.
Thecluster of "Medical Practice", or medical intervention inthe natural course of the disease, can be axiomatized as aplan, in the AI sense, for maintaining or achieving a state ofhealth in the patient, where different branches of the plancorrespond to where in the temporal schema for disease thephysician intervenes and to the mode of intervention.Most of the content of the domain-specific cluster.~ isspecific to medicine, but the general principles along whichit was constructed are relevant o many applications.
Fre-quently the best way to proceed is first to identify the enti-ties and classification schemes in several clusters, state therelationships among the entities, and encode axioms artic-ulating clusters with higher- and lower-level clusters.
Oftenone then wants to specify temporal schemas involving inter-actions of entities from several domains and goal-directedintervention i  the natural course of these schemas.The concordance method of the second stage is quiteuseful in ferreting out the relevant facts, but it leaves omelacunae, or gaps, that become apparent when we look atthe knowledge base as a whole.
The gaps are especially fre-quent in commonsense knowledge.
The general pl'inciple wefollow in encoding this lowest level of the knowledge base isto aim for a vocabulary of predicates that is minimally ad-equate for expressing the higher-level, medical facts and toencode the obvious connections among them.
One heuristichas proved useful: If the axioms in higher-level domains areespecially complicated to express, this indicates that someunderlying domain has not been sufficienlly explicated andaxiomatized.
For example, this consideration h:~s h~d to afuller elaboration of the "systems" domain.
Another ex-ample concerns the predicates '~parenteral", "needle" and"bite", appearing in the domain of "disease transmission".Initial attempts to axiomatize them in4icated the need foraxioms, in the "naive topology" domain, about m(unbranesand the penetration of membranes allowing substances tomove from one side of the membrane to the other.Within each cluster, concepts and facts seem Ic, fall intosmall groups that need to be defined together.
I%r cxample.the predicates "clean" and "contaminate" need to be de-fined in tandem.
There is a larger example in the "DiseaseTransmission" cluster.
The predicate "transmit" is funda-mental, and once it has been characterized ,~s the motionof an infectious agent from a person or animal to a personvia some medium, the predicates "source", "route", "mech-anism", "mode", "vehicle" and "expose" can be de, fined interms of its schema.
In addition, relevant facts about bodyfluids, food, water, contamination, eedles, bites, propaga-tion, and epidemiology rest on an under~tanding of "trans-mit".
In each domain there tends to be a core of central ?predicates whose nature must be explicated with some care.A large number of other predicates can then be character-ized fairly easily in terms of these.2854.
Encod ing  the Facts in Pred icateCalculusEncoding world knowledge in a logical language is of-ten tal,:en to be a very hard problem.
It is my belief thatthe di|licultics result from attempts to devise representa-tions that lend themselves in obvious ways to efficient de-duction algorithms and that adhere to stringent ontologicalscruples.
I h;~.ve abandoned the latter constraint altogether(see \[llobbs, 198.1\], for arguments} and believe the formerconcern should be postponed until we have a better ideaof precisely what sort of deductions need to be optimized.Under these ground rules, translating individual facts intopredicate calculus is usually fairly straightforward.There are still considerable difficulties in making theaxioms mesh well together.
A predicate should not be usedin some higher-level c uster unless it has been elucidated inthat or some lower-level cluster.
This necessarily restrictsone's vocabulnry.
For example, the predicate "in" doesa lot of work.
There are facts about viruses in tissues,chemicals in body fluids, infections in patient's bodies, andso on, and a direct translation ofsome of these axioms backinto English is somewhat awkward.
One has the feelingth~tt subtle .~hades of meaning have been lost.
But this isinevitable in a knowledge base whose size is intended to beintermediate rather than exhaustive.Jersey.Hobbs, J.
1984.
Ontological promiscuity.
Manuscript.Walker, D. and J. Hobbs, 1981.
Natural anguage access to med-ical text.
SRI International Technical Note 240.
March1981.5.
SummaryMuch of this paper has been written almost as a casestudy.
It would be useful for me to highlight he new andgeneral principles and results that come out of this project.Tile method of using linguistic presuppositions a  a "fore-lug function" fi~r the underlying knowledge is fairly gen-erally apl)licable in any domain for which there is a largebody of text to exploit.
It has been used in ethnography:rod discourse anal.vsis, but to my knowledge it has notbeen previously used in the construction of an AI knowl-edge base.
The core knowledge has been encoded in waysIhat are indel)endent of domain and hence should be usefulfor any natural language application.
Of particular interesthere is the klentification and axiomatization f the topologi-cal .~ubstructure of language The domain-specific knowledgewill not of course carry over to other applications, but, asmentioned above, certain general principles of axiomatizingcoml)lex domains have emerged.ReferencesGrosz, B., N. llaas, G. tlendrix, J. llobbs, P. Martin, R. Moore,.1.
Robinson, and S. l~osensehein, 1982.
DIALOGIC: Acore natural lan,ouiage processing system.
Proceedings of theNinth Internation(d Conference on Computational Linguis-tics.
95-1/~i,.
Prno~w, Czechoslovakia.llayes, P., 1981.
The second naive physics manifesto.
In Hobbs,d.
and R. Moore (Eds.
), Formal Theories of the Common-sense World.
Ablex Publishing Company, Norwood, New286
