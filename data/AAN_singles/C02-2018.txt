An XML-based document suiteDietmar Ro?sner and Manuela KunzeOtto-von-Guericke-Universita?t MagdeburgInstitut fu?r Wissens- und SprachverarbeitungP.O.box 4120, 39016 Magdeburg, Germany(roesner,makunze)@iws.cs.uni-magdeburg.deAbstractWe report about the current state of development of adocument suite and its applications.
This collection oftools for the flexible and robust processing of documentsin German is based on the use of XML as unifying for-malism for encoding input and output data as well asprocess information.
It is organized in modules withlimited responsibilities that can easily be combined intopipelines to solve complex tasks.
Strong emphasis is laidon a number of techniques to deal with lexical and con-ceptual gaps that are typical when starting a new appli-cation.IntroductionWe have designed and implemented the XDOC docu-ment suite as a workbench for the flexible processing ofelectronically available documents in German.
We havedecided to exploit XML (Bray et al, 1998) and its ac-companying formalisms (e.g.
XSLT (Site, 2002b)) andtools (e.g.
xt (Clark, 2002) ) as a unifying framework.All modules in the XDOC system expect XML docu-ments as input and deliver their results in XML format.XML ?
and ist precursor SGML ?
offers a formal-ism to annotate pieces of (natural language) texts.
To bemore precise: If a text is (as a simple first approximation)seen as a sequence of characters (alphabetic and white-space characters) then XML allows to associate arbitrarymarkup with arbitrary subsequences of contiguous char-acters.
Many linguistic units of interest are representedby strings of contiguous characters (e.g.
words, phrases,clauses etc.).
To use XML to encode information aboutsuch a substring of a text interpreted as a meaningful lin-guistic unit and to associate this information directly withthe occurrence of the unit in the text is a straightforwardidea.
The basic idea is further backed by XMLs demandthat XML elements have to be properly nested.
This isfully concordant with standard linguistic practice: com-plex structures are made up from simpler structures cov-ering substrings of the full string in a nested way.The end users of our applications are domain experts(e.g.
medical doctors, engineers, ...).
They are interestedin getting their problems solved but they are typicallyneither interested nor trained in computational linguis-tics.
Therefore the barrier to overcome before they canuse a computational linguistics or text technology systemshould be as low as possible.This experience has consequences for the design ofthe document suite.
The work in the XDOC project isguided by the following design principles that have beenabstracted from a number of experiments and applica-tions with ?realistic?
documents (i.a.
emails, abstracts ofscientific papers, technical documentation, ...): The tools shall be usable for ?realistic?
documents.One aspect of ?realistic?
documents is that they typi-cally contain domain-specific tokens that are not di-rectly covered by classical lexical categories (likenoun, verb, ...).
Those tokens are nevertheless oftenessential for the user of the document (e.g.
an en-zyme descriptor like EC 4.1.1.17 for a biochemist). The tools shall be as robust as possible.In general it can not be expected that lexicon in-formation is available for all tokens in a document.This is not only the case for most tokens from ?non-lexical?
types ?
like telephone numbers, enzymenames, material codes, ...
?, even for lexical typesthere will always be ?lexical gaps?.
This may eitherbe caused by neologisms or simply by starting toprocess documents from a new application domainwith a new sublanguage.
In the latter case lexicalitems will typically be missing in the lexicon (?lex-ical gap?)
and phrasal structures may not or not ad-equately be covered by the grammar. The tools shall be usable independently but shall al-low for flexible combination and interoperability. The tools shall not only be usable by developers butas well by domain experts without linguistic train-ing.Here again XML and XSLT play a major role: XSLstylesheets can be exploited to allow different presen-tations of internal data and results for different targetgroups; for end users the internals are in many cases nothelpful, whereas developers will need them for debug-ging.The tools in the XDOC document suite can be groupedaccording to their function: preprocessing structure detection POS tagging syntactic parsing semantic analysis tools for the specific application: e.g.
informationextractionIn all tools the results of processing is encoded withXML tags delimiting the respective piece of text.
Theinformation conveyed by the tag name is enriched withXML attributes and their resp.
values.PreprocessingTools for preprocessing are used to convert documentsfrom a number of formats into the XML format amenablefor further processing.
As a subtask this includes treat-ment of special characters (e.g.
for umlauts, apostrophes,...).Structure detectionWe accept raw ASCII texts without any markup as in-put.
In such cases structure detection tries to uncoverlinguistic units (e.g.
sentences, titles, ...) as candidatesfor further analysis.
A major subtask is to identify therole of interpunction characters.If we have the structures in a text explicitly availablethis may be exploited by subsequent linguistic process-ing.
An example: For a unit classified as title or subtitleyou will accept an NP whereas within a paragraph youwill expect full sentences.In realistic texts even the detection of possible sen-tence boundaries needs some care.
A period charactermay not only be used as a full stop but may as well be partof an abbreviation (e.g.
?z.B.?
?
engl.
: ?e.g.?
?
or ?Dr.?
),be contained in a number (3.14), be used in an email ad-dress or in domain specific tokens.
The resources em-ployed are special lexica (e.g.
for abbreviations) andfinite automata for the reliable detection of token fromspecialized non-lexical categories (e.g.
enzyme names,material codes, ...).These resources are used here primarily to identifythose full stop characters that function as sentence de-limiters (tagged as IP).
In addition, the information aboutthe function of strings that include a period is tagged inthe result (e.g.
ABBR).Example 1 results of structure detectionAnwesend<IP>:</IP><ABBR>Univ.-Prof.</ABBR><ABBR>Dr.</ABBR><ABBR>med.</ABBR>Dieter Krause<IP>,</IP>Direktor des Institutes fuer RechtsmedizinPOS taggingTo try to assign part-of-speech information to a token isnot only a preparatory step for parsing.
The informationgained about a document by POS tagging and evaluatingits results is valuable in its own right.
The ratio of to-ken not classifiable by the POS tagger to token classifiedmay e.g.
serve as an indication of the degree of lexicalcoverage.In principle a number of approaches is usable for POStagging (e.g.
(Brill, 1992)).
We decided to avoid ap-proaches based on (supervised) learning from tagged cor-pora, since the cost for creating the necessary trainingdata are likely to be prohibitive for our users (especiallyin specialized sublanguages).The approach chosen was to try to make best use ofavailable resources for German and to enhance them withadditional functionality.
The tool chosen is not only usedin POS tagging but serves as a general morpho-syntacticcomponent for German: MORPHIX.The resources employed in XDOC?s POS tagger are:- the lexicon and the inflectional analysis from themorphosyntactic component MORPHIX- a number of heuristics (e.g.
for the classification oftoken not covered in the lexicon)For German the morphology component MORPHIX(Finkler and Neumann, 1988) has been developed in anumber of projects and is available in different realisa-tions.
This component has the advantage that the closedclass lexical items of German as well as all irregularverbs are covered.
The coverage of open class lexicalitems is dependent on the amount of lexical coding.
Theparadigms for e.g.
verb conjugation and noun declina-tion are fully covered but to be able to analyze and gen-erate word forms their roots need to be included in theMORPHIX lexicon.We exploit MORPHIX - in addition to its role insyntactic parsing - for POS tagging as well.
If a to-ken in a German text can be morphologically analysedwith MORPHIX the resulting word class categorisationis used as POS information.
Note that this classifica-tion need not be unique.
Since the tokens are analysedin isolation multiple analyses are often the case.
Someexamples: the token ?der?
may either be a determiner(with a number of different combinations for the featurescase, number and gender) or a relative pronoun, the to-ken ?liebe?
may be either a verb or an adjective (againwith different feature combinations not relevant for POStagging).In addition since we do not expect extensive lexiconcoding at the beginning of an XDOC application sometokens will not get a MORPHIX analysis.
We then em-ploy two techniques: We first try to make use of heuris-tics that are based on aspects of the tokens that can eas-ily be detected with simple string analysis (e.g.
upper-/lowercase, endings, ...) and/or exploitation of the tokenposition relative to sentence boundaries (detected in thestructure detection module).
If a heuristic yields a classi-fication the resulting POS class is added together with thename of the employed heuristic (marked as feature SRC,cf.
example 3).
If no heuristics are applicable we classifythe token as member of the class unknown (tagged withXXX).To keep the POS tagger fast and simple the disam-biguation between multiple POS classes for a token andthe derivation of a possible POS class from context foran unknown token are postponed to syntactic processing.This is in line with our general principle to accept resultswith overgeneration when a module is applied in isola-tion (here: POS tagging) and to rely on filtering ambigu-ous results in a later stage of processing (here: exploitingthe syntactic context).Example 2 domain-specific tagging<PRODUCT Method="Sandguss" Material="CC333G"><N>Gussstueck</N><NORM><N>EN</N><NR>1982</NR></NORM><IP>-</IP><MAT-ID>CC333G</MAT-ID><IP>-</IP><METHODE>GS</METHODE><IP>-</IP><MODELLNR>XXXX</MODELLNR></PRODUCT>The example above is the result of tagging a domain-specific identifier.
The token is annotated as a PROD-UCT with description of the used method and material.It is a typical token in the domain of casting technology.Syntactic parsingFor syntactic parsing we apply a chart parser basedon context free grammar rules augmented with featurestructures.Again robustness is achieved by allowing as input ele-ments: multiple POS classes, unknown classes of open world tokens and tokens with POS class, but without or only partialfeature information.Example 3 unknown token classified as noun withheuristics<NP TYPE="COMPLEX" RULE="NPC3" GEN="FEM"NUM="PL" CAS="_"><NP TYPE="FULL" RULE="NP1" CAS="_"NUM="PL" GEN="FEM"><N SRC="UNG">Blutanhaftungen</N></NP><PP CAS="DAT"><PRP CAS="DAT">an</PRP><NP TYPE="FULL" RULE="NP2" CAS="DAT"NUM="SG" GEN="FEM"><DETD>der</DETD><N SRC="UC1">Gekroesewurzel</N></NP></PP></NP>The latter case results from some heuristics in POStagging that allow to assume e.g.
the class noun for atoken but do not suffice to detect its full paradigm fromthe token (note that there are ca two dozen different mor-phosyntactic paradigms for noun declination in German).For a given input the parser attempts to find all com-plete analyses that cover the input.
If no such completeanalysis is achievable it is attempted to combine maximalpartial results into structures covering the whole input.A successful analysis may be based on an assump-tion about the word class of an initially unclassified to-ken (tagged XXX).
This is indicated in the parsing result(feature AS) and can be exploited for learning such clas-sifications from contextual constraints.
In a similar waythe successful combination from known feature valuesfrom closed class items (e.g.
determiners, prepositions)with underspecified features in agreement constraints al-lows the determination of paradigm information fromsuccessfully processed occurrences.
In example 4 fea-tures of the unknown word ?Mundhoehle?
could be de-rived from the features of the determiner within the PP.Example 4 unknown token classified as adjective andfeatures derived through contextual constraints<NP TYPE="COMPLEX" RULE="NPC3" GEN="MAS" NUM="SG"CAS="NOM"><NP TYPE="FULL" RULE="NP3" CAS="NOM" NUM="SG"GEN="MAS"><DETI>kein</DETI><XXX AS="ADJ">ungehoeriger</XXX><N>Inhalt</N></NP><PP CAS="DAT"><PRP CAS="DAT">in</PRP><NP TYPE="FULL" RULE="NP2" CAS="DAT" NUM="SG"GEN="FEM"><DETD>der</DETD><N SRC="UC1">Mundhoehle</N></NP></PP></NP>"The grammar used in syntactic parsing is organized ina modular way that allows to add or remove groups ofrules.
This is exploited when the sublanguage of a do-main contains linguistic structures that are unusual oreven ungrammatical in standard German.Example 5 Excerpt from syntactic analysis<PP CAS="AKK"><PRP CAS="AKK">durch</PRP><NP TYPE="COMPLEX" RULE="NPC1" GEN="NTR" NUM="SG"CAS="AKK"><NP TYPE="FULL" RULE="NP1" CAS="AKK" NUM="SG"GEN="NTR"><N>Schaffen</N></NP><NP TYPE="FULL" RULE="NP2" CAS="GEN" NUM="SG"GEN="MAS"><DETD>des</DETD><N>Zusammenhalts</N></NP></NP></PP>Semantic analysisAt the time of writing semantic analysis uses three meth-ods:Semantic taggingFor semantic tagging we apply a semantic lexicon.
Thislexicon contains the semantic interpretation of a tokenand a case frame combined with the syntactic valence re-quirements.
Similar to POS tagging the tokens are anno-tated with their meaning and a classification in seman-tic categories like e.g.
concepts and relations.
Againit is possible, that the classification of a token in iso-lation is not unique.
Multiple classification can be re-solved through the following analysis of the case frameand through its combination with the syntactic structurewhich includes the token.Analysis of case framesBy the case frame analysis of a token we obtain detailsabout the type of recognized concepts (resolving multi-ple interpretations) and possible relations to other con-cepts.
The results are tagged with XML tags.
The fol-lowing example describes the DTD for the annotation ofthe results of case frame analysis.Example 6 DTD for the annotation by case frame anal-ysis<!ELEMENT CONCEPTS (CONCEPT)*><!ELEMENT CONCEPT (WORD, DESC, SLOTS?
)><!ATTLIST CONCEPT TYPE CDATA #REQUIRED><!ELEMENT WORD (#PCDATA)><!ELEMENT DESC (#PCDATA)><!ELEMENT SLOTS (RELATION+)><!ELEMENT RELATION (ASSIGN_TO, FORM, CONTENT)><!ATTLIST RELATION TYPE CDATA #REQUIRED><!ELEMENT ASSIGN_TO (#PCDATA)><!ELEMENT FORM (#PCDATA)><!ELEMENT CONTENT (#PCDATA)>We use attributes to show the description of the con-cepts and we can annotate the relevant relations betweenthe concepts through nested tags (e.g.
the tag SLOTS).Example 7 Excerpt from case frame analysis<CONCEPT TYPE=Prozess><WORD>Fertigen</WORD><DESC>Schaffung von etwas</DESC><SLOTS><RELATION><RESULT FORM="N(gen, fak) P(akk, fak, von)">fester Koerper</RESULT><SOURCE FORM="P(dat, fak, aus)">aus formlosemStoff </SOURCE><INSTRUMENT FORM="P(akk, fak, durch)">durchSchaffen des Zusammen-halts</INSTRUMENT></RELATION></SLOTS></CONCEPT>The example above is part of the result of the analysisof the German phrase: Fertigen fester Koerper aus form-losem Stoff durch Schaffen des Zusammenhalts1.
The to-ken Fertigen is classified as process with the relationssource, result and instrument.
The following phrases(noun phrases and preposition phrases) are checked tomake sure that they are assignable to the relation require-ments (semantic and syntactic) of the token Fertigen.Semantic interpretation of the syntactic structureAn other step to analyze the relations between tokens canbe the interpretation of the syntactic structure of a phraseor sentences respectively.
We exploit the syntactic struc-ture of the sublanguage to extract the relation betweenseveral tokens.
For example a typical phrase from an au-topsy report: Leber dunkelrot.2From semantic tagging we obtain the following infor-mation:Example 8 results of semantic tagging<CONCEPT TYPE="organ">Leber</CONCEPT><PROPERTY TYPE="color">dunkelrot</PROPERTY><XXX>.</XXX>In this example we can extract the relation ?has-color?between the tokens Leber and dunkelrot.
This is an ex-ample of a simple semantic relation.
Other semantic rela-tions can be described through more complex variations.In these cases we must consider linguistic structures likemodifiers (e.g.
etwas), negations (e.g.
nicht), coordi-nations (e.g.
Beckengeruest unversehrt und fest gefuegt)and noun groups (e.g.
Bauchteil der grossen Koerper-schlagader).Current state and future workThe XDOC document workbench is currently employedin a number of applications.
These include: knowledge acquisition from technical documenta-tion about casting technology extraction of company profiles from WWW pages analysis of autopsy protocolsThe latter application is part of a joint project withthe institute for forensic medicine of our university.
Themedical doctors there are interested in tools that helpthem to exploit their huge collection of several thousandautopsy protocols for their research interests.
The con-frontation with this corpus has stimulated experimentswith ?bootstrapping techniques?
for lexicon and ontologycreation.The core idea is the following:When you are confronted with a new corpus from anew domain, try to find linguistic structures in the textthat are easy to detect automatically and that allow to1In English: production of solid objects from formless matter bycreating cohesion2In English: Liver dark red.classify unknown terms in a robust manner both syntac-tically as well as on the knowledge level.
Take the resultsfrom a run of these simple but robust heuristics as an ini-tial version of a domain dependent lexicon and ontology.Exploit these initial resources to extend the processing tomore complicated linguistic structures in order to detectand classify more terms of interest automatically.An example: In the sublanguage of autopsy proto-cols (in German) a very telegrammatic style is dominant.Condensed and compact structures like the following arevery frequent:Harnblase leer.Harnleiter frei.Nierenoberflaeche glatt.Vorsteherdruese altersentsprechend.. .
.These structures can be abstracted syntactically asNounAdjectiveFullstop and semantically asreporting a finding in the form Anatomic-entityhas Attribute-value and they are easily detectable(Ro?sner and Kunze, 2002).In our experiments we have exploited this characteris-tic of the corpus extensively to automatically deduce aninitial lexicon (with nouns and adjectives) and ontology(with concepts for anatomic regions or organs and theirrespective features and values).
The feature values werefurther exploited to cluster the concept candidates intogroups according to their feature values.
In this way con-tainer like entities with feature values like ?leer?
(empty)or ?gefuellt?
(full) can be distinguished from e.g.
entitiesof surface type with feature values like ?glatt?
(smooth).Related WorkThe work in XDOC has been inspired by a number ofprecursory projects:In GATE (Site, 2002a; Cunningham and Wilks, 1988)the idea of piping simple modules in order to achievecomplex functionality has been applied to NLP with sucha rigid architecture for the first time.
The project LTXML has been pioneering XML as a data format for lin-guistic processing.Both GATE and LT XML ((LTG), 1999) were em-ployed for processing English texts.
SMES (Neumannet al, 1997) has been an attempt to develop a toolboxfor message extraction from German texts.
A disadvan-tage of SMES that is avoided in XDOC is the lack of auniform encoding formalism, in other words, users areconfronted with different encodings and formats in eachmodule.System availabilityMajor components of XDOC are made publicly accessi-ble for testing and experiments under the URL:http://lima.cs.uni-magdeburg.de:8000/SummaryWe have reported about the current state of the XDOCdocument suite.
This collection of tools for the flexibleand robust processing of documents in German is basedon the use of XML as unifying formalism for encodinginput and output data as well as process information.
Itis organized in modules with limited responsibilities thatcan easily be combined into pipelines to solve complextasks.
Strong emphasis is laid on a number of techniquesto deal with lexical and conceptual gaps and to guaranteerobust systems behaviour without the need for a priori in-vestment in resource creation by users.
When end usersare first confronted with the system they typically are in-terested in quick progress in their application but shouldnot be forced to be engaged e.g.
in lexicon build up andgrammar debugging, before being able to start with ex-periments.
This is not to say that creation of specializedlexicons is unnecessary.
There is a strong correlation be-tween prior investment in resources and improved per-formance and higher quality of results.
Our experienceshows that initial results in experiments are a good mo-tivation for subsequent efforts of users and investment inextended and improved linguistic resources but that a pri-ori costs may be blocking the willingness of users to getreally involved.ReferencesTim Bray, Jean Paoli, and C.M.
Sperberg-McQueen.1998.
Extensible Markup Language (XML) 1.0.http://www.w3.org/TR/1998/REC-xml-19980210.E.
Brill.
1992.
A simple rule-based part-of-speech tag-ger.
In Proceeding of the Third Conference on AppliedNatural Language Processing, pages 152?155.J.
Clark.
2002. http://www.jclark.com.H.
Cunningham and Y. Wilks.
1988.
GATE - a Gen-eral Architecture for Text Engineering.
Proccedingsof COLING-96.
http://gate.ac.uk.W.
Finkler and G. Neumann.
1988.
MORPHIX: afast Realization of a classification-based Approachto Morphology.
In H. Trost, editor, Proc.
der 4.?Osterreichischen Artificial-Intelligence Tagung,Wiener Workshop Wissensbasierte Sprachverar-beitung, pages 11?19.
Springer Verlag, August.Language Technology Group (LTG).
1999.
LT XMLversion 1.1. http://www.ltg.ed.ac.uk/software/xml/.G.
Neumann, R. Backofen, J. Baur, M. Becker, andC.
Braun.
1997.
An information extraction core sys-tem for real world german text processing.
pages 208?215, March.D.
Ro?sner and M. Kunze.
2002.
Exploiting sublan-guage and domain characteristics in a bootstrappingapproach to lexicon and ontology creation.
In Pro-ceedings of the OntoLex 2002 - Ontologies and Lex-ical Knowledge Bases at the LREC 2002.GATE Site.
2002a.
http://gate.ac.uk.XSL Site.
2002b.
http://www.w3.org/style/xsl.
