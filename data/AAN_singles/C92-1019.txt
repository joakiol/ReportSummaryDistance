WORD IDENTIFICATION FOR MANDARIN CI l INESE SENTENCESAbstractKeh- J iann Chen Sh ing- l luan  LiuInstitute of lnfl~rmation ScienceAcademia  SinicaChinese sentences are composed with string ofcharacters without blanks to mark words.
However thebasic unit for sentence parsing and understanding isword.
Therefore the first step of processing Chinesesentences i to identify the words.
The difficulties ofidentifying words include (l) the identification of com-plex words, such as Determinative-Measure, redupli-cations, derived words etc., (2) the identification ofproper names,(3) resolving the ambiguous segmenta-tions.
In this paper, we propose the possible solutionsfor the above difficulties.
We adopt a matching algo-rithm with 6 different heuristic rules to resolve the am-biguities and achieve an 99.77% of the success rate.The statistical data supports that the maximal match-ing algorithm is the most effective heuristics.1.
IntroductionChinese sentences arc cx)mposed with string ofcharacters without blanks to mark words.
However thebasic unit for sentence parsing and understanding isword.
Therefore the first step of processing Chinesesentences is to identify the words( i.e.
segment thecharacter strings of the sentences into word strings).Most of the current Chinese natural languageprocessing systems include a processor for word iden-tification.
Also there are many word segmentationtechniques been developed.
Usually they use a lexiconwith a large set of entries to match input sentences\[2,10,12,13,14,21\].
It is very often that there are manyl~)ssible different successful matchings.
Therefore themajor focus for word identification were on thc resolu-tion of ambiguities.
However many other important as-pects, such as what should be done, in what depth andwhat are considered to be the correct identificationswere totally ignored.
High identification rates areclaimed to be achieved, but none of them were mea-sured under equal bases.
There is no agreement inwhat extend words are considered to be correctly iden-tified.
For instance, compounds occur very often in Chi-nese text, but none of the existing systems except ourspay much attention to identify them.
Proper name isanother type of words which cannot be listed exhaus-tively in the lexicon.
Therefore simple matching algo-rithms can not successfully identify either compoundsor proper names.
In this paper, we like to raise theptx~blems and the difficulties in identifying words andsuggest the possible solutions.2.
Difficulties in the Identification of WordsAs we mentioned in the prevkms chapter, theba-sic technique to identify the words is by matching algo-rithms.
It requires a well prepared lexicon with suffi-cient amount of lexical entries which covers all of theChinese words.
Iqowcver such a large lexicon is neverexisting nor will be composed, since the set of words isopen ended.
Not only because the new words will begenerated but because there are unlimited number ofcompounds.
Most of the word identification systemsdeliberately ignore the problem of compounds andleave the problem unsolved until the stage of parsing.We don't agree their view points and believe that dif-ferent type of Compounds should be handled by thedifferent meth~Ms at different stages.
Some types ofthe compounds had better to be handled before pars-ing, for they require different grammatical representa-tions and idcntificalion strategies compared with theparsing of phrase structures.
On the camtrary, if thelnorphological rules \[or compounds have the ~me re-presentation asthe phrase structure rules, it is better tobe identified at parsing stage.
We will di~uss this issuein more details in the later sections.The other problem is that ambiguous segmenta-tions frequently tv.
:cur during thc processing of wordmatching.
It is because that very often a multisyllabicword contains monosyllabic words as its components.We have to try the different strategies to re~flve suchambiguities.Many problems need to be ~lved, but first of all alexicon shotdd be composed for the matching algo-rithm.2.1 What are the Set of WordsAccording to Liang's \[14,15\] definition, word is asmallest,meaningful, and freely used unit.
It is the basicprocessing unit fur Chinese natural anguage process-ing.
Since there is no morphological features as wordsegmentation marks, we have to adopt such a wtguedefinition of the Chinese word.
Liang \[151 also pro-pose a word segmentation standard.
However some ofhis view points are debatable and self contradictory.
Infact it is almost impossible to define a standard for COr-rect identification.
Thcrefl)re instead of proposing aAcrEs DE COLING-92.
NAm'as, 23-28 Aot)r 1992 1 0 1 PRoe.
ov COL1NG-92, NANTES, AUG. 23-28, 1992standard, we propose a criterion which should be fol-lowed by a good word segmentation algorithm.
It isthat a good segmentation algorithm should be able toproduce a result which is suitable and sufficient forthe propose of later processing, such as parsing and un-derstanding.The set of words is open ended.
~lherefore theexisting lexicons contain lexical entries which vary from40 to 120 thousands.
A large lexicon usually includesmany compounds as well as many proper names, for itis hard to distinguish a word and a compound.
Fbrsystems with a small lexicou, they might not performworse than systems with a large lexicon, if they incor-porate algorithms to identify compounds and propernames.
However on the other hand there is no harm tohave a large lexicon, once there is a way of handling theambiguities, since statistically a large lexicon has thebetter chance to match words as well as producingambiguous egmentations.
Therefore we have thefollow principle to collect he word set for the purposeof word segmentation.Principle for composing a lexicon:qqm lexicon should contam as many as possiblewords.
If there is a doubt whether a string of charac-ters is a word or a compound, you can just collect it asan entry.Currently we have a lexicon of around 90 thou-sands entries, and keep updating for new words.
A lexi-con with such a s~e of course would still leave out manycompounds and proper names.
We use this lexicon tomatch the Chinese text, the result of the algorithm is asequence of words defined in the lexicon.
(1) is an in-stance of result.(1)a.
jieshuoyuan Jau Shian-Ting yindau tameninterpreter Jau Shian-Ting uide them'q'he interpreter Shian-Ting Jau guidedthem."b.
j ieshuo-yuan-Jau-Shian-Ting-yindau-ta-menHowever we can see that ~me of the compoundsand proper names are not identified as shown in (1lb.They were segmented into words or characters.
There-fore at later stage those pieces of segments should beregrouped into compounds and proper names.
We willdiscuss tile issue at next two sections.2.2 Compmmds1here are many different ype of compounds inChinese and should be handled ifferently \[3, 6, 7, 11,17, 191.a.
determinative-measure compounds (DM)A determinative-measure compound iscomposedof one or more determinatives, together with an op-tional mcasm'e.
(2) je san benthis three CL"these three"It is used to determine the reference or the quan-tity of the noun phrase that co-~w.curs with it.
De~i tethe fact that I~)th categories of determinatives andmeasures are closed, the comhinations of them are not.However the set of DMs is a regular language whichcan be expressed by regular expressions and reCOg-nized by finite automata \[19\].
Mo \[191 also point outthat the structure of I)Ms are exocentric.
They arehardly similar to other phrase structures which are en-docentric and context-free and can bc analyzed by headdriven parsing strategies.
Therefore we suggest hattile identification of DMs should be done in parallelwith the identification of common words.
There are 76rules for DMs which covers ahnost all of the DMs \[19\].Dor word identification, those rules function as a sup-plement for the lexicon, which works as ff the lexiconcontains all of the DMs.
We will show the test result inthe section 3.3.b.
ReduplicationsIn Chinese many verhs can be reduplicated todenote all additional meaning of flying the actionsgently and relaxedly(3)\[7\].
(3) tiau tiau wujump jump dance"dance a little"This kind of molphological construction will m)tchange the argument structure of the verbs, but dochange their s3mtactic behavior.
For instance, the re-duplications can not cooccur with the adjuncts of post-verbal location, aspect marker, duration, and quantifier\[171.
In \[17\], they derived 12 different reduplicationrules which cover the reduplication construction ofverbs.
Ill addition, there are 3 rules for the reduplica-tion of DMs and 5 rules for A-not -A questions forma-tion.The identification of the reduplication construc-tion should be done after the words have been identi-fied, since it is better to sec the words and then checkwhether part of the words has been reduplicated.
It is akind of context dependent process, so a separated pro-cess other than the process for DMs or Phrase struc-tures, should be incorporated.A(ZlT.S I)E COLING-92, NArCrl~s, 23-28 Ao(rr 1992 1 0 2 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992c.
A -not -A  constructionA -not -A  constructions are commonly used inChinese to form a questiou \[13,71.
Aswe mentioned be-fore, for A--not~A construction, there are 5 differentrules for reduplicating part of tile verbs and coverbs\[17\].
(4) fang-bu- fangshinput not stop-worry"stop worrying or not"A -no f .A  constructien is a kind of reduplicationconstrution.
Therefore the technique for the idemifi-cation of reduplication is aim applicable for the identi-fication of the A-not--A construction.d.
Derived WordsA derived word is at compound which (x)mposedwith a word of stem and a prefix or a suffix \[ 11 \].
I)erivative affixes are very productive in Mandarin Chinese.
(5) difang-shingplace quality"localityr"Those affixes usually are bound morphemes.
In\[11\], we collect a sct of most frcqucntly occurred af-fixes and study their morphological behaviors.
Wefound that there are syntactic and semantic restrictionsbctween modifiers and heads.
Such a nrorphok)gicalpatterns can bereprcsentedintermsof lnfonnat ion- .based Case Grammar\[5\], which is also the grammaticalformalism adopted for representing Chinese phrasestructures in our parsing system\[5,ll\].
Following is anexample of representation.
(6) shingSemantic:meaning: equivalent of "-NESS","-lq~(", for cxprcssing abstract notationSyntactic: ategory: Nadfeature: bound; I + N,--V\]constraints: MR: {Vhl, V\[ + transitivc \[, N} < < *Since the grammatical representation f derivedwords is the same as the representation f phrase struc-tures, wc suggest that the identification of the dcrivcdwords are better to be done at tile parsing stage.
Fur-thermore, the Ixoundaries of the derived words ave syJt-tactically ambigu(ms.
They can not he identified with-out checking the contextual information.2.3 Proper NamesProper names (w.cur very frequently in all kinds ofarticles.
~\[lte identification of proper nanlcs becomeone of the most difficult problems in Chinese naturallanguage processing, since we can not exhaustly list allt,f the ptToper name in the lcxiceu.
Also there is no mor-phologieal nor punctuation makers to denote a propername.
Besides that a proper name may contain a suh-string of common words.
It makes the identification ofthe proper names even harder.
The only clue might beusetul in identifying proper names is the occurrencesnf Ix)and nu)ll)heules.
Usually each Chinese characteris a meaningful nit.
Some of them can I;e used freelyas a word.
Some are not; they have to be combined withother characters to form a word.
Such characters cannot be used freely as words, are named bound nmr-.phemes.
If bound moqflmmes occur after word match-ing process, it means that there are derived words orproper names occurred iu the text and have not beenidentified.
The semantic lassification of morphemescan be utilized to identify the different type of propernames.
For instance,in \[11, the setofsurnames wereused its a clue to identify people's names and titles.There is no general solutions o far to handle the dif-ferent types of proper names.
The only suggestion isthat mark the proper names before identification pro-cuss or treat the unknown strings as proper names.2.4 AmbiguitiesFor Chiuese character strings,they might havemany different well fl~rmed segmentations, but ust,-ally there is tndy one grammatically aud semanticallysound segmemation fur ~lch sentence (7).
(7) yijing jeuglichu jiegnoaheady arrangc~out result'q'he result has come out.
"yijiug-\[jengli-ehu\]-jiegnoyijing-ljengqichu \] -jiegunTherefore many algorithms were proposed andheuristic or statistical pretcrence rules were adoptedfor remlving ambiguities.
However none of those ruleshas been thoruughly tested and provided their successrates, ht the next section, we will state our algorithm aswell as tile heuristic rulesand alsoprovides the experiomerit results in section 3.2 to show the success rate ofeach individual tall:.3.Wnvd Identification AlgnrithmAccording to the discussion of the chapter 2, thepicture of the word identificatinn algoxithm should beclearly its Icit\[ows.
(u)In fact trot all of the above processes were thor-oughly studies, but more ov less some of them werestudied and have successful results \[2, 8, 12, 13, 14, 16,19, 20,211.
Our word identification system adopt tl,ealnlve sequence of algorithms, lint we defer the secondlast prlycess of finding derived words until parsing stageand tile last In'ocess of finding proper names is tempo+Acrt!s DE COLING-92, NANIES, 23-28 Aot'n' 1992 1 0 3 PROC.
OV COLING 92, NANIES, A~,IG.
23.-28, 1992Words and DMs q l "~ | Lexicon and |matchingI Find compounds of ~1.
redupli~tion2, A-not-Arary ignored for not having a feasible identification al-gorithm.3.1 Matching algorithm and disambiguationrulesThe first two steps of word identification algo-rithm are the word matching and disambiguation.These two processes were performed in parallel.
Oncean ambiguous match occurs, the disambiguation pro-cess is invoked immediately.
The algorithm reads theinput sentences from left to right.
Then match the in-put character string with lexemes as well as DMs rules,If an ambiguous segmentation do occur, then thematching algorithm looks ahead two more words, thenapply the disambiguation rules for those three wordchunks.
For instance,ha (9), the first matched wordcould be 'wan' or 'wancheng'.
Then the algorithm willlook ahead to take all of the possible combinations ofthree word chunks, as shown in (10), into consideration.
(9) wanchengjianding haugaucomplete authenticate r port"complete the report about authenticating"(10) wan~:heng-jiandingwancheng-jianding-bauwancheng-jianding-baugauThe disambiguation algorithm will select he firstword of the most plausible chunk as the solution.
Inthis case, it is the word 'wancheng'.
The algorithm thenproceeds to process the next word until all the inputtext been processed.
'/'he most powerful and commonly used disambi-guation rule is the heuristic of maximal matching \[12,13, 14, 21\].
There are a few variations of the sense ofmaximal matching, but after we have done the experi-ments with each of different variations, we adopt thefollowing maximal matching rules.Heuristic rule 1:The most plausible segmentation is the threeword sequence with the maximal length.This heuristic rules achieves as high as 99.69%accuracy and 93.21% of the ambiguities were resolvedby this rule.
We will see the detail statistics in the nextsection.
However there are still about 6.79% of ambi-guities till can not be re~lved by the maximal match-ing rule.
Therefore we adopt the next heuristic rule.Heuristic rule 2:Pick the three word chunk which has the smalleststandard eviation in the word length.
This is equiva-lent to find the chunk with the minimal value on (L(W1)-Mean) **2 + (L(W2)-Mean)**2 + (14'W3)-Mean)**2 ,where Wl,W2,and W3 are three words in achunk; Mean is the average length of Wl,W2.,and W3;L(W) denotes the length of the word W.Heuristic rule 2 simply says that the word lengthare usually evenly distributed.
For instance in (11), thesegmentation f ( l la) has the value 0, but (1 lb) has val-ue 2.
Therefore according to the heuristic rule number2, the ( l la) will be the selected solution and it is thecorrect segmentation.
(11) yianjiou shengminchiyuanresearch life origin"to investigate he origin of life"a.
\[yianjiou-shengminl-chiyuanb.
\[yianjiousheng-min\]-chiyuanHowever it may happen that there are more thantwo chunks with the same length and variance, weneed a further esolution.Heuristic rule 3:Pick the chunk with fewer bound morphemes.Heuristic rule 4:Pick the chunk with fewer characters in DMs.That is to say the normal words get higher prior-ity than the bound morphemes and DMs.
For instancesexamples (12,13) were resolved by the rule 3 and 4 re-spectively.
(12a) and (13a) are right choices.
(12) shietiau shang shoushiu jiau mafannegotiate up procedure more trouble-someAcrEs DE COLING-92, NANTES.
23-28 hOt'q" 1992 1 0 4 PROC.
OF COLING-92, Nhr?rEs, AUG. 23-28, 1992"In negotiation, the process is more compli-cated."a.
shietiau-\[shang-shoushiu\]-j iau-mafanb.
shietiau-\[shangshou-shiu\]-i iau-mafan(13) ta benrenhe serf"he himself"a. ta-benrenb.
taben-renThe heuristic rules 2,3,and 4only resolve 1.71%of the ambiguities as shown in the table 2 of the nextsection.
After we observe the remaining ambiguities wefound that many ambiguities were occurred ue to theoccurrences of monosyllabic words.
For instances, thecharacter string in (14a) can be segmented as (14b) or(14c), but none of the above resolution rules Can re-solve this case.
(14) ganran de chiuanshrrenshu shieshialaiinfect DE real number writedown"write down the precise number of the in-fected"ganran-\[de-chiuanshr\]-renshu-shieshialaiganran-\[dechiuan-shr\]-renshu-shieshialaiIf we compare the correct segmentations withthe incorrect segmentations, we find out that almostall of the monosyllabic word in the correct answerare function words, such as prepositions,con\]unctions,as well as a few high frequent adverbs.
And that themonosyllabic words in the incorrect segmentations arelower frequency words.
The set of such frequently oc-curred monosyllabic words are shown in appendix 1.We then have the following heuristic rule.Heuristic rule 5:Pickthechunk with the high frequentlyoccurredmonosyllabic words.This rule contributes 3.46% of the success of theambiguity resolution.
The remaining unsolved ambi-guities are about 1.62% of the total input words.
Theyusually should be resolved by applying real wurldknowledge or by checking grammatical validity.
How-ever it is almost impossible to apply real world knowl-edge nor to check the grammatical validity at this stage,so applying Markov m(v..lel is a possible solution\[21\].The other solution is much simpler ,i.e.
to pick thechunk with the highest accumulated frequency ofwords\[221.
It requires the frequency counts for eachwords only instead of word bigram or trigram which re-quired by the Markov model.Heuristic rule 6:Pick the chunk with the highest probability value.q~e prohability value of the sequence of words' W 1 W2W3' can be estimated by eithera) Markov model with the bigram approximationP~P(W01Wl  ) * P(WI\[W2) * P(W21W3) *P(W3) ; orb) Word probability accumulationP = P fWl )  + t , (w2)  + P(W3)Heuristic rule 6a might not be feasible, since it re-quires word bigram a matrix of size in the order of10"'10.
But heuristic 6b) might not produce a satis-factory resolution.
According to our experiment thesuccess rate for 6b) is less than 70%.
qlaerefore theother solution is to retain the ambiguities and resolveat the parsing stage,3.2 Experiment ResultsWe designed a word identification system to testthe matchingalgorithm and the above mentioned heu-ristic rules.
The lexicon for our system has about 90thousands lexical entries plus mflimited amount of theDMs generated from 76 regular expressions.
The 90thousands lexemes form a word tree data structure inorder to speed up the word matching \[4,10\].For thesame reasons, DM rules are compiled first to produce aChomsky Normal Form like parsing table.
The parsingtable will then he interpreted during the word matchingstage\[19\].
'l~vo sets of test data are randomly selectedfrom a Chinese corpus of 20 million characters.
Wesummarize the testing result in "lhhle 1. qhble 2 showsthe success rates and applied rates for each heuristicrule.qhe recall rate and recognition rate in the abovetable are defined as follows.
LetNI = the number of words m the input text,N2 = the number of words segmented by the systemfor the input text.N3 = the number of words were correctly identified.Then the recall rate ss defined to bc N3/NI and theprecision rate ks N3/N2.
"lhc dclmlta)n of the other sta-tistical result are t~vlousJ) I'ollnwed the conven-tion.The above testing algorithm do not include theprocess of handling derived ~4 wds.
"lhcrefore the abovestatistics do not ta)unt he mt~lakcs occurred ue to theexistence of derived word,,, or proper names.We can sec that the maximal matching algorithmis the most effective hcunst~t~, lbcrc  are 10311 num-ber of ambiguities out of 17404 occurrences of the seg-ACRES DECOL\]NG-92, NANTES.
23-28 AO(;r 1992 l 0 5 PROC.
OF COLING-92, NANTES, Aua.
23-28.
1992mentations.
It counts 58.94% of the total segmenta-tions and 93.21% of ambiguities were resolved by thisheuristics.4.Discussions and Concluding RemarksFrom the statistical results hown in table 2, it isclear that the ma.,dmal matching algorithm is the mostuseful heuristic method.
Most of the mistakes causedby this heuristic are due to the occurrences ofthe wordswhich are composed by two subwords.
Those words areneeded to have further investigations.
If we want tofurther improve our system's performance, it seemsthat employing lexically dependent rules is unavoid-able.The errors caused by the heuristic rule 2are due tot he cases of a three character word followed by a mono-syllabic word and which can he divided into two hisyl-labic words, for instance (15).
(15) tzai shia san jouat down three week"in the followlug three week"\[tzai-shiasanjou\]\[tzaishia-sanjou\]Such mistakes can be avoided by giving the sec-ond bisyllabic words a lexically dependent markerwhich denotes that a low priority is given to this wordwhen the heuristic rule 2 is applied.Table 1.
Testm resultsSample 1 Sample 2 Total# of sentences 833 1968 2801# of characters 8455 20879 29334# of v~ords 5085 12409 17494+ ,# of words identified 5076 12399 17475by the system# of correct 5O64 12370 17434identifications.
,recall rate 99.58% 99.69% 99.66%precision rate 99.76% 99.77% 99.77%guLe2~e4H~mt~Hcalrllt~Rule6Table 2.
The success rates of the heuristic rulesSample 1 S+mple 2 Total# of laentdicattom # of error~ succe~ts rate $ of mentilioaiom i of erron ~ucoms rate i r of klentificltlor # of errors suCCX~s rate2875 13 99.58% 6938 17 99,75% 9813 30 99.09%36 4 8~.89% 74 3 95.98% 110 7 93.64%0 0 100% 5 0 100% 8 0 100%18 O 100% 32 1 96.86% 50 1 98.00%104 2 98,08% .238 12 94.96% 342 14 95 90%48 15 6878% 109 36 66,97% 157 51 67.52%ACrF~ DE COL1NG-92, NANTES, 23-28 nOt3T 1992 1 0 6 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992'FILe heuristic rules #3 and #4 are the mostreliable disambiguation rules.
However they only con-tribute 0.53% of the disambiguation processes.The heuristic rule #5 is ugeful, but the priority val-ues for each high frequent monosyllabic word has tobe carefully rearranged inorder to reduce possible mis-takes \[181.The heuristic title #6 needs to be further studied.It will be much more easier to use the bigram or trigrambased on gt-ammatical categories instead of the wordbigram or the simple accumulation of the word fre-quencies.
It will be the future study.About the identification of the proper names, itrequires a further investigation on the results of theproper names 'after segmentation algorithm isapplied.5.Referenees\[1\] J. S. Chang, "A Multiple-Corpus Approach toIdenti cation nf Chinese Surname-Names."
Proc.of Natural Language Processing Pacific Rim Sym-posium, Singapore, 1991\[2\] 3".
S. Chang, J. I. Chang and S. D. Chert, "A Meth-?yd of Constraint Satisfaction and Statistical Opti-mization for Chinese Word Segmentation," Proc.of the 1~1 R. O.
C Computational LinguisticsConference, Taiwan, 1991\[3\] Y.R.
Chad, A Grammar of Spoken Chinese, Uni~versity of California Press, California, 1968\[4\] K.J.
Chen, C. J. Chert and L. 3".
Lee, "Analysis andResearch in Chinese Sentences - - Segmentationand Construction," Technical Report, TR-864X)4,Nankang, Academia Sinica, 1986\[51 K. 3.
Chen and C. R. Huang, "lutonnation-basedCase Grammar," COLING - 90, Vol 2, p.54 - p.59\[61 K.J.
Chen et al "Compounds and I~arsing in Mau~darin Chinese," Plot.
of National Computer Sym-posium, 1987\[71 G.Y.
Chen, " A-not-A Questions in Chinese,"manuscript, CKIP group, Academia Sinica, 'Pulp-el, 1991\[8\] C.K.
Fan and W. H. q.t;ai," Automatic Word Iden-tification in Chinese Sentences by the Relaxation"/~chniqne," Computer Processing of Chinese andOriental Languages, Vol.4, No.l, November 1988\[9\] R. Garside, G. Leech and (;.
Sampson, " TheComputational Analysis of English - -  a Corpus-based Approach," lamgman Group UK Limited,1987\[10\] W. H. Ho, " Automatic Recognition of ChineseWords," Master Thesis, National Taiwan Instituteof qi:chnology, "Paipei, "lhiwan, 1983\[I1\] W. M. Hong, C. R. Huaug, T. Z. qhng and K. J.Chen," The Morphological Rules of Chinese De-rivative Words," rib be presented atthe 1991 Inter-national Conference on "lEaching Chinese as aSecond Language, December, 1991, 'Ihipei\[12\] C. Y. Jie, Y. Lin and N. Y. Liang, "On Methods ofChinese Automatic Segmentation," Journal ofChinese hfformation Processing, VoL3, No.l,1989\[13\] B. I. Li, S. Lien, C, F. Sun and M. S. Sun, "A Maxbreal Matching Automatic Chinese Word Segmen-tation Algorithm Using Corpus "lhgging for Ambbguity Resolution," Proc.
of the 1991 R. O.
C Com-putational Linguistics Conference, Taiwan, 1991\[14\] N. Y. Liang, "Automatic Chinese Text Word Seg-mentation System --  CI)WS", Journal of ChineseInformation Processing, VoL1, No.2, 1987\[151 N. Y. Liang, "Contemporary Chinese LanguageWord Segmentation Standard Used for Informa-tion Processing," 1989, a draft proposal\[16\] N. Y. Liang, "Fhe Knowledge of Chinese WordsSegmentation," Journal of Chinese InformationProcessing, Vol.4, No.2., 1990\[ 17\] M. L. Lin, "The Grammatical nd Semantic Prop-erties of Reduplications," manuscript, CKIPgroup, Academia Sinica, 1991\[ 18\] I. M. Liu, C. Z. Chang and S. C. Wang, "FrequencyCount of Frequently Used Chinese Words," 'Pulp-el, qMwan, Lucky Bcmk Co., 1975\[19\] R. E Mo, Y. J. Yang, K. J. Chen and C. R. Huang,"Determinative-Measure Compounds inManda-rin Chinese : Their Formation Rules and ParserImplementation," Proc.
of the 1991 R.O.C Com-putational Linguistics Conference, qhiwan, 199l\[20\] R. Sproat and C. Shih, "A Statistical Method forFinding Word Boundaries inChinese 'lext," Com-puter Processing of Chinese and Oriental Lan-guages, Vol.4, No.4, March 1990\[21\] C. L. Yeh and H. J. Lee, "Rule-based Word Iden-tification fi3r Mandarin Chinese Sentences - -  AUnification Approach," Computer Processing ofChinese and Oriental Languages, Vol.5, No.2,March 1991Append~~ ~ ~ ~ ~ ~ T ~ b ~ ~AcEs DECOLING-92, NAbn'Es, 23-28 Ao~rr 1992 1 0 7 PP.oc.
OF COLING-92, NAI~rES, Auo.
23-28, 1992
