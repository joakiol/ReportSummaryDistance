Answering Questions Using Advanced Semantics andProbabilistic InferenceSrini NarayananInternational Computer Science Institute1947 Center St., Suite 600,Berkeley, CA 94704snarayan@icsi.berkeley.eduSanda HarabagiuHuman Language Technology ResearchInstitute - University of Texas at Dallas2601 N. Floyd Rd.
EC 31, ECSS 3.908ARichardson, TX 75083sanda@hlt.utdallas.eduAbstractIn this paper we argue that access to rich se-mantic structures  derived from questions andanswers will enable both the retrieval of moreaccurate answers to simple questions and en-able inference processes that explain the va-lidity and contextual coverage of answers tocomplex questions.
Processing complex ques-tions involves the identifications of severalforms of complex semantic structures.
AnswerExtraction is performed by recognizing eventinter-relationships and by inferring over mul-tiple sentences and texts, using backgroundknowledge.1 IntroductionCurrent Question Answering systems extract an-swers from large text collections by (1) classifyingquestions by the answer type they expect; (2) usingquestion keywords or patterns associated with questionsto identify candidate answer passages and (3) rankingthe candidate answers to decide which passage containsthe exact answer.
A few systems also justify the answer,by performing abduction in first-order predicate logic[Moldovan et al, 2003].
This paradigm is limited by theassumption that the answer can be found because it usesthe question words.
Although this may happen some-times, this assumption does not cover the many caseswhere an informative answer is missed because its iden-tification requires more sophisticated semantic process-ing than named entity recognition and the identificationof an answer type.
Therefore access to rich semanticstructures derived from questions and answers will en-able the retrieval of more accurate answers as well asinference processes that explain the validity and contex-tual coverage of answers.Several stages of deeper semantic processing may beconsidered for processing complex questions.
A firststep in this direction is the incorporation of ?semanticparsers?
or identifiers of predicate argument structuresin the processing of both questions and documents.Processing complex questions consists of: (1) a syntac-tic parse of the question and of the document collection;(2) Named Entity recognition that along with the syntac-tic parse enable (3) the identification of predicate-argument structures; and (4) identification of the answertypes, which no longer consist of simple concepts, butrather complex conceptual structures, and (5) keywordsextraction that allows candidate answers to be identi-fied.
Document processing is performed by indexingand retrieval that uses three forms of semantic informa-tion: (1) Classes of named entities; (2) Predicate-argument structures and (3) Ontologies of possible an-swer types.
Additionally, as more complex semanticstructures are evoked by the question and recognized indocuments, indexing and retrieval models are enhancedby taking into account conceptual schemas and topicmodels.
Answer processing is concerned with the rec-ognition of the answer structure, which is a natural ex-tension of recognizing exact answers when they arerepresented as single concepts.
Since many times theanswer is merged from several sources, enhanced an-swer processing also requires a set of special operatorsfor answer fusion.The rest of the paper is organized as follows.
Section2 presents question processing that uses deeper semanticresources.
Section 3 details the methods for answer ex-traction whereas Section 4 describes methods for repre-senting and reasoning with rich semantic structures.Section 5 summarizes the conclusions.2 Question Processing that uses a varietyof semantic resourcesGiven the size of today?s very large document re-positories, one can expect that any complex topic willbe covered from multiple points of view.
This feature isexploited by the question decomposition techniques,which generate a set of multiple questions in order tocover all of the possible interpretations of a complextopic.
However, a set of decomposed questions mayend up producing a disparate (and potentially contradic-tory) set of answers.
In order for Q/A systems to usethese collections of answers to their advantage, answerfusion must be performed in order to identify a single,unique, and coherent answer.We view answer fusion as a three-step process.
First,an open-domain, template-based answer formalization isconstructed based on predicate-argument frames.
Sec-ond, a probabilistic model is trained to detect relationsbetween the extracted templates.
Finally, a set of tem-plate merging operators are introduced to construct themerged answer.
The block architecture for answer fu-sion is illustrated in Figure 2.
The system functionalityis demonstrated with the example illustrated in Figure 3.Our method first converts the extracted answers intoa series of open-domain templates, which are based onpredicate-argument frames (Surdeanu et al 2003).
Thenext component detects generic inter-template relations.Typical ?greedy?
approaches in Information Extraction(Hobbs et al 1997; Surdeanu and Harabagiu, 2002) useheuristics that favor proximity for template merging.The example in Figure 3 proves that this is not alwaysthe best decision, even for templates that share the samepredicate and have compatible slots.Processing complex questions involves the identifi-cation of several forms of complex semantic structures.Namely we need to first recognize the answer type thatis expected, which is a rich semantic structure, in thecase of complex question or a mere concept in the caseof a factual question.
At least three forms of informationare needed for detecting the answer type: (1) questionclasses and named entity classes; (2) syntactic depend-ency information, enabling the recognition of (3) predi-cate-argument structures.
Each of the following threequestions illustrates the significance of the three formsof semantic information in question processing:For question Q-Ex1, the question stem ?when?
indi-cates that the answer type is a temporal unit, eventuallyexpressed as a date.
To find candidate answers, the rec-ognition of India and other related named entities, e.g.Indian, as well as the name of the Prithvi missile or ofits related program are important.
Named entity recogni-tion is also important for processing question Q-Ex2,because not only ?North Korea?
needs to be recognizedas a country, but names of other countries need to beidentified in the candidate answer paragraph.
Processingquestion Q-Ex2 involves syntactic information as well,e.g.
the identification of the complex nominal ?missilelaunch pad metals?.
To better process question Q-Ex2,additional semantic information in the form of predi-cate- arguments structures enables the recognition of theanswer type more precisely.
Instead of looking only forcountry names when processing the documents, a searchfor countries that export missile launch pad metals or ofcounties from which North Korea imports such com-modities refines the search space.
This is made possibleby the transformation of question Q-Ex2 in the structureillustrated in Figure 2.The role set for the arguments of predicate ?import?was used as it is currently defined in the PropBank pro-ject.
Predicate-argument structures are also essential tothe processing of question Q-Ex3, because the questionis too ambiguous.
The stem ?what?
and the named en-tity ?India?
may relate to a large range of events andentities.Q-Ex1: When was India?s Prithvi missile launched for the firsttime?Q-Ex2: From which country did North Korea import its missilelaunch pad metals?Q-Ex3: What stimulated India?s missile programs?Figure 2: Predicate-argument structure of question Q-Ex2Predicate : importArg 0 : (role = importer) : North KoreaArg 1 : (role = commodity) : missile launch pad metalsArg 2 : (role = exporter) : ANSWERFigure 1: FrameNet structuring of question Q-Ex3Frame: Subject_stimulusFrame element CIRCUMSTANCES: ANSWER (part 3)Frame element COMPARISON SET: ANSWER (part 4)Frame element EXPERIENCER: India?s missile pro-gramFrame element Parameter: nuclear proliferationFrame: StimulateFrame element CIRCUMSTANCES: ANSWER (part 1)Frame element (EXPERIENCER):  India?s missile pro-gramFrame element (STIMULUS):  ANSWER (part 2)Figure 3: Predicate-argument structure for question Q-Ex3Predicate: StimulateArg0 (role = agent):  ANSWER (part 1)Arg1 (role = thing increasing):  India?s missile programArg2 (role = instrument):  ANSWER (part 2)The predicate-argument structure illustrated in Fig-ure 3 indicates that the answer may have the role of theagent or even the role of the instrument.
When semanticinformation from FrameNet is also used, Figure 4 showsthat the answer may have in fact four other semanticroles.To illustrate the semantic knowledge that needs tobe recognized and the inference process that they en-able, we shall use one of the questions employed in theAQUAINT Pilot 2 for Dialog Processing of CNS Sce-narios, illustrated in Figure 5.Processing Q-Sem cannot be done by simply usingthe question stem ?how?
to identify manners of detec-tion or even by employing the predicate-argument struc-ture illustrated in Figure 6.
The answer contains a singletroponym of the verb ?detect?, namely ?look at?, andthe agent is ?Milton Leitenberg, an expert on biologicalweapons?.
However returning the name of Milton Le-itenberg as the answer is not informative enough.Instead of relying only on the question stem and thepredicate-argument structure, question processing takesadvantage of a more complex semantic structure madeavailable by the enhanced architecture: the topic model.The topic model contributes to the interpretation of theonly argument fully specified in the predicate-argumentstructure illustrated in Figure 6, namely Arg1 represent-ing the ?detected?
role, expressed as ?the biologicalweapons program?.
The interpretation of this complexnominal is made possible by two semantic representa-tions: (1) the typical connections in the topic model; and(2) the possible paths of action characterizing the topicalmodel as represented in Figure 6.Figure 6 lists only two of the semantic representa-tion typical of the scenario defined in Figure 8, namelytypical connections between events and entities or be-tween events.
A special kind of relations between eventsis represented by the possible paths of action.
The twopaths of actions that are listed in Figure 6 enable the twointerpretations of the detected object.
It is to be notedthat such semantic knowledge as the one represented inthe topic model is not available from WordNet or Fra-meNet at present, and thus need to be encoded andmade accessible to the Q/A system.
For structuring thecomplex answer type expected by question Q-Sem, a setQ-Sem: How can a biological weapons program be detected?Answer (Q-Sem)In recent months, Milton Leitenberg, an expert on biological weapons, has been looking at this murkiest and most dangerous cor-ner of Saddam Hussein's armory.
He says a series of reports add up to indications that Iraq may be trying to develop a new viralagent, possibly in underground laboratories at a military complex near Baghdad where Iraqis first chased away inspectors sixyears ago.
A new assessment by the United Nations suggests Iraq still has chemical and biological weapons - as well as the rock-ets to deliver them to targets in other countries.
The UN document says Iraq may have hidden a number of Scud missiles, as wellas launchers and stocks of fuel.
US intelligence believes Iraq still has stockpiles of chemical and biological weapons and guidedmissiles, which it hid from the UN inspectors.Figure 5: Complex question and its answer derived from the CNS collectionQ-Sem: How can a biological weapon program be detected?Question PATTERN: How can X be detected?Topic ModelProgram ?
develop1) development ?
production ?
stockpiling ?
delivery2) development ?
acquisition ?
stockpiling ?
deliveryTypical connec-Possible paths of actionPredicate-argument structurePredicate = detectArg0 = detector: Answer(1)Arg1 = detected: biological  weapons programArg2 = instrument: Answer(2)Detect-object: complex nominal = biological weapons pro-gram1) program for developing biological weaponsPossible interpreta-tiFigure 4: Question processing based on topic semanticsQ-Sem: How can a biological weapons program be detected?Question pattern: How can X be detected?
X = Biological Weapons Program1 Conceptual Schemas1.1 INSPECTION Schema 1.2 POSSESSION Schema1.3 Structure of Complex Answer Type: EVIDENCEof conceptual schemas need also to be recognized.
Fig-ure 7 shows some of the schemas instantiated by thequestion processing.
The inspection schema is evokedby the question verb ?detect?
; the possession schema isevoked by the complex nominal ?biological weaponsprogram?.Along with the answer structure, the enhanced ques-tion processing module generates the structure of theintentions uncovered by question Q-Sem.
The generalintention of finding evidence that there is a biologicalweapons program in Iraq is structured in four differ rep-resentations illustrated in Figure 8.
Intention structuresare also dependent on the topic model.3 Answer Extraction based on semanticprocessingIn the baseline architecture, the answer type as well asthe predicate-argument structure determine the answerextraction.
Complex questions like Q-Sem are providedwith an answer by filling the semantic information oftheir complex answer types.Figure 9 illustrates the answer extracted for question Q-Sem in the form of: (1) the text where the answer isfound (2) the semantic structure of the answer with in-formation derived from the text; and (3) pointers linkingthe fillers of the semantic structure of the answer withthe text source.
Such pointers may be supplementedwith traces of the inferential processes.
The answertype, labeled ?evidence-combined?
has several semanticclasses that are in turn filled with semantic representa-tions for (1) the content of evidence; (2) the source ofthe evidence; (3) the quality of evidence and (4) thejudgment of evidence.
The content structure lists bothpredicate-argument-like structures as well as such at-tributes as: (a) the justification, accounting for the con-ceptual schema that identified the content; (b) the statusof the event/state recognized by the schema; (c) the like-lihood of the eventuality of the event/state and (d) inten-tions and abilities from the past, present or future.
Thesource representation is also structured as (a) author, (b)type and (c) reliability.
The quality of the inferred an-swer is measured by (a) the judges; (b) the judge types;(c) judgment manner and (d) judgment stage.
Finally, aqualitative assessment of the reliability of the answer isgiven, to complement the reliability score computedthrough probabilistic inference.4 Representing and Reasoning with RichSemantic Structures for Advanced QAThe ICSI work on embodied cognition is based on cog-nitive linguistics.
Research in this field has shown thatmany concepts and inferences are based on a relativelysmall number of /image schemas/, which are deeplyembodied and are apparently universal across lan-guages.
For example, the ideas of container, goal andoppositional force occur prominently in language andthought.4.1 Cross-Linguistic Conceptual Schemas andInferenceMuch of narrative text relies on a relatively con-strained set of conceptual schemas.
For instance, theexample above uses some of the most potent generalschemas: POSSESSION, EVASION, SPATIALRELATION, EVENT STRUCTURE, and SOURCE-PATH-GOAL which involves an agent trying to obtaina particular goal (finding WMD) by moving along apath of actions.
These are all basic embodied schemaswhose inferential structure is common cross-linguistically.
Furthermore, these schemas are oftensources of metaphor (PHYSICAL POSSESSION mapsto INFORMATION POSSESION, SPATIALLOCATIONS MAP TO INFORMATION STATES(murky and dangerous corner), PHYSICAL ACTIONS(look) MAP to ABSTRACT ACTIONS (scrutinize in-formation) [35]).
It appears that only a few dozen suchgeneral schemas suffice to describe a very wide range ofscenarios.
These have been extensively studied formany languages by linguists, but only recently formal-ized (as part of our AQUAINT Phase 1 effort).
Nowthat we have the formalism in hand, we believe andhope to demonstrate in Phase II that the combination ofembodied schemas with metaphorical mappings to otherdomains can yield a significant improvement in inferen-tial power over traditional approaches.4.2 Reasoning about Event StructureQ-Sem: How can a biological weapons program be detected?INTENTION STRUCTURE: Evidence/information about biological weapons program in Iraq?
CONTEXT/enabler ?
for finding evidence of biological weapons program?
MEANS: how can one develop/acquire biological weapons?
PURPOSE/MOTIVATION: why biological weapons are used?
RESULTS: consequences of using biological weaponsFigure 6: Intentional StructurePerforming QA with complex scenarios requires so-phisticated reasoning about actions and events.
For in-stance, in the example above knowing the stage of aprocess (interrupted inspection due to a chase awayevent), gives valuable predictive information (Iraq mayhave hidden the WMD) as well as pre-suppositionalinformation (Iraq had WMD before the inspections(signaled by the use of still has in the example sce-nario)).
Of course, this information is probabilistic (Iraqis only likely to have WMD (note the use of indica-tions, may be, suggests, believes, and other linguisticmarkers of evidentials) and often 3) abductive (Iraq?sgoal of chasing away the inspectors was probably to beable to hide the WMD).
In all complex scenarios eventdescriptions are 1) dynamic (has been looking, still has,trying to develop, etc.
), 2) resource specific (WMD de-ployment needs launchers, inspections need inspectors),3) context sensitive (all inferences are conditioned onthe scenario context which suggests among other thingsthat a) Iraq intends and is probably trying to developWMD and b) it is likely that Iraq will try to hide theseWMD from the Inspectors), often 4) figurative (as inANSWER: Evidence-Combined:Pointer to Text Source:A1 In recent months, Milton Leitenberg, an expert on biological weapons, has been looking at this murkiest and most dangerous corner of Saddam Hussein's armory.
A1A2He says a series of reports add up to indications that Iraq may be trying to develop a new viralagent, possibly in underground laboratories at a military complex near Baghdad where Iraqis firstchased away inspectors six years ago.A2A3 A new assessment by the United Nations suggests Iraq still has chemical and biological weapons - as well as the rockets to deliver them to targets in other countries.
A3A4 The UN document says Iraq may have hidden a number of Scud missiles, as well as launchers and stocks of fuel.
A4A5US intelligence believes Iraq still has stockpiles of chemical and biological weapons and guidedmissiles, which it hid from the UN inspectors.
A5Content: Biological Weapons Program:develop(Iraq, Viral_Agent(instance_of:new))Justification:POSSESSION SchemaPrevious (Intent and Ability): Prevent(ability, Inspection);Inspection terminated; Possible resumption of abilityStatus: Attempt ongoing Likelihood: Medium Confirmability: difficult, obtuse, hiddenpossess(Iraq, Chemical and Biological Weapons)Justification:POSSESSION SchemaPrevious (Intent and Ability):Hidden from InspectorsLikelihood:Mediumpossess(Iraq, delivery Systems (type: rockets, target: Other countries))Justification:POSSESSION SchemaPrevious (Intent and Ability):Hidden from InspectorsStatus:OngoingLikelihood:Mediumpossess(Iraq, delivery Systems (type: scud missiles, target: Other countries))Justification:POSSESSION SchemaPrevious (Intent and Ability):Hidden from InspectorsStatus:OngoingLikelihood:Mediumpossess(Iraq, delivery Systems (type: launchers, target: Other countries))Justification:POSSESSION SchemaPrevious (Intent and Ability):Hidden from InspectorsStatus:OngoingLikelihood:Mediumpossess(Iraq, fuel stocks (purpose: power(launchers)))Justification:POSSESSION SchemaPrevious (Intent and Ability):Hidden from InspectorsStatus:OngoingLikelihood:Mediumhide(Iraq, Seeker: UN Inspectors, Hidden: CBW stockpiles)Justification:POSSESSION SchemaDetection Process:InspectionStatus:PastLikelihood:MediumSource: UN document, US IntelligenceSource.Type: assessment reports Source.Reliability: med_highReliability: mediumJudge: UN, US Intelligence, Milton Leitenberg (Biological Weapons Expert)Judge_type: Mixed Judge_manner: Judge_stage: OngoingQuality: low_mediumFigure 7: Answer to complex questionmurky and dangerous corner, reports add up to indica-tions, UN document says etc.
), may incorporate thespecific 7) perspectives of the various participants (Mil-ton Leitenberg, US intelligence, UN inspectors etc.
)Over the last decade and in Phase I of AQUAINT,we have developed a rich model of event structure thathas been shown to be capable to capturing the eventstructure distinctions in complex text in a variety oflanguages (Narayanan99a, Narayanan99b, Chang et al2002, 2003).
The model forms the basis and providesthe underlying operational semantics for the DARPAfunded DAML-S process model (NM 2003, ISWC2001) for the semantic web.
This model is also beingused in the ongoing ARDA video event recognitionontology effort (Hobbs and Nevatia 2003).4.3 Building Deep Semantic Structure From TextWe now have a set of wide-coverage lexical re-sources such as FrameNet (FN) and WordNet (WN) thatcan potentially aid knowledge formation in the rapiddevelopment of scenario models for inference in QA.An explicit representation of such semantic informationis needed to fully realize use in text interpretation andinference.
Previously we have worked out a formalismthat unpacks the shorthand of frames into structuredevent representations.
These dynamic representationsallow annotated FrameNet data to parameterize eventsimulations based on the PIN model (Section II.B.7)(Chang et al2002) in a manner capable of producing thefine-grained, context-sensitive inferences required forlanguage processing.. We anticipate that wide-coverageresources will be useful for the focused data AQUAINTPhase II task and we propose to enable developers toaccess these resources like FrameNet through a JavaAPI.
We propose to undertake the following relatedtasks.
1)  Build a common API to WN and FN so wecan combine the resources.
2) Produce an OWL-S(http://www.daml.org/services) port of FrameNet so thatFrameNet information can be combined with other on-tologies and in particular with specialized domain on-tologies of use to the DoD and intelligencecommunities.
3) Build PIN (Section II.B.7)  models ofFrameNet frames that are of use to the CNS scenarios.4) Evaluate the ease of using FrameNet based modelsand the amount of human intervention required to in-stantiate them as Probabilistic Inference Networks.
5)Explore further automation of the mapping from Fra-meNet frame descriptions to Probabilistic InferenceNetworks.4.4 A Construction Grammar based deep seman-tic analyzerThe ICSI group has developed a powerful semanticgrammar formalism ?
Embodied Construction Grammar(ECG), partially with Phase 1 AQUAINT support.
Itwill not be possible to develop robust, full coverageECG grammars from this base during phase 2 and ef-forts in this task will focus on the detailed analysis ofcomplex questions in context.
An ECG grammar ex-ploits constructions, starting from individual words andextending through complex linguistic forms, in a similarmanner to other unification grammars such as HPSG.Central novel ideas are use of conceptual links, theevokes mechanism for activating other concepts, use ofroles for describing schemas, and a meaning sectionthat specifies introduced semantic relations.Given that an ECG grammar can map linguisticform to deep semantic relations, it remains to build sys-tems that exploit this capability.
John Bryant has builtsuch an analyzer as part of the ICSI Phase 1 effort andhis Master?s thesis.
It is basically a unification basedchart parser using chunking methods for efficiency androbustness.
One major innovation is the use of deepsemantic unification in the basic matching step ?
thisimproves both efficiency and robustness.
The ECG se-mantic analysis system has been coupled to the ICSIinference engine of task 7 to produce a pilot completeQA system for news stories.
For Phase 2, ICSI will ex-tend the existing system in several ways.
The semanticunification methodology will be extended to handlelinguistic and situational context.
This is a natural ex-tension and has the promise of providing much morerobust integration over extended discourse.
In addition,there will be specific effort aimed at the analysis of que-ries and the supporting declarations.
This is intended toaddress the fact that analysts ask much more complexquestions than Phase 1 systems can understand.4.5 Probabilistic Inference Networks for combin-ing ontological, statistical and linguisticknowledge for advanced QAModern inference systems deal with the ambiguityand uncertainty inherent in any large, real-word domainusing probabilistic reasoning.
Such models have manyadvantages, including the ability to deal with missingand uncertain data.
Bayesian networks have workedextremely well in moderate sized cases, but do not scaleto situations of the size and complexity needed here tomodel QA with complex scenarios as in the CNS data.To handle such data, we need techniques that combinereasoning about uncertainty with relational knowledgebases and dynamic linguistic knowledge and context.
Ingeneral, reasoning with linguistic structure, ambiguity,and dynamics requires modeling coordinated temporalprocesses and complex, structured states.
A significantamount of work has gone into different aspects of over-all problem.5 ConclusionsIn this paper we show that, while there has beenmuch progress in natural language analysis there is stilla large gap in representing knowledge and reasoningwith it for advanced QA.
We have developed a methodfor processing complex questions which involves theidentification of several forms of complex semanticstructures.
This involves the development of a powerfulsemantic grammar formalism - Embodied ConstructionGrammar (ECG) and applying it to the analysis of com-plex questions.
Answer Extraction will be performed byrecognizing event inter-relationships, recognized bynovel relation extraction techniques.
Question extractionat the level the AQUAINT program seeks requires amechanism for performing inference over multiple sen-tences and texts, using background knowledge.
We pro-pose to build a software package which we refer to asProbabilistic Inference Networks (PIN) to provide amechanism for performing context-sensitive inferenceover multiple sentences and discourse fragments, usingencoded knowledge.ReferencesA.
L. Berger, S. A. Della Pietra and V. J. Della Pietra.
Amaximum entropy approach to natural languageprocessing.
Computational Linguistics, 22(1):39-72,March 1996.Jennifer Chu-Carroll and Sandra Carberry.
GeneratingInformation-Sharing Subdialogues in Expert-UserConsultation.
In Proceedings of the 14th InternationalJoint Conference on Artificial Intelligence (IJCAI-95), pages 1243-1250, Montreal, Canada, 1995.Michael Collins.
A New Statistical Parser Based onBigram Lexical Dependencies.
In Proceedings of the34th Annual Meeting of the Association for Computa-tional Linguistics, ACL-96, pages 184-191, 1996.Abdessamad Echihabi and Daniel Marcu.
A Noisy-Channel Approach to Question Answering.
In Pro-ceedings of the 41st Annual Meeting of the Associa-tion for Computational Linguistics (ACL-2003),Sapporo, Japan, 2003.Christiane Fellbaum (Editor).
WordNet ?
An ElectronicLexical Database.
MIT Press, 1998.C.J.
Fillmore and C.F.
Baker and H. Sato.
The  Frame-Net Database  and  Software Tools.
In M. Gonz?lez-Rodr?guez and C.P.
Su?rez-Araujo, Eds.
In Proceed-ings of the Third International Conference on Lan-guage Resources and Evaluation.
Las Palmas, Spain,2002.Michael Fleischman, Eduard Hovy and AbdessamadEchihabi.
Offline Strategies for Online Question An-swering: Answering Questions Before They AreAsked.
In Proceedings of the 41st Annual Meeting ofthe Association for Computational Linguistics (ACL-2003), pages 1-7, Sapporo, Japan, 2003.Sanda Harabagiu, Marius Pa ca and Steven Maiorano.Experiments with Open-Domain Textual QuestionAnswering.
In Proceedings of the 18th InternationalConference on Computational Linguistics (COLING-2000), pages 292-298, Saarbrucken, Germany, 2000.Sanda Harabagiu, Dan Moldovan, Christine Clark,Mitchell Bowden, John Williams and JeremyBensley.
Answer Mining by Combining ExtractionTechniques with Abductive Reasoning.
In Proceed-ings of the 12th Text Retrieval Conference (TREC2003).Jerry R. Hobbs, Doug E. Appelt, John Bear, David Is-rael, Megumi Kameyama, Mark Stickel and MabryTyson.
FASTUS: A Cascaded Finite-State Trans-ducer for Extracting Information Natural-LanguageText.
In Finite State Language Processing, Edited byEmmanuel Roche and Yves Schabes, MIT Press,1997.E.H.
Hovy, U. Hermjakob, C.-Y.
Lin, ?The Use of Ex-ternal Knowledge in Factoid QA?, TREC-10 confer-ence, November 2001.Dan I. Moldovan, Sanda M. Harabagiu, Marius Pa ca,Rada Mihalcea, Roxana G?rju, Richard Goodrum andVasile Rus.
The Structure and Performance of anOpen-Domain Question Answering System.
In Pro-ceedings of the 38th Annual Meeting of the Associa-tion for Computational Linguistics (ACL-2000),2000.John Prager, Eric Brown, Anni Coden and DragomirRadev.
Question-answering by predictive annotation.In Proceedings of the 23rd annual international ACMSIGIR conference on Research and development ininformation retrieval, pages: 184-191, Athens,Greece, 2000.Dragomir R. Radev and Kathleen McKeown.
Generat-ing natural languages summaries from multiple on-line sources.
Computational Linguistics, 24(3):469-500, 1998.
