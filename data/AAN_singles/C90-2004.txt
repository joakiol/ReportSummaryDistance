Bot tom-Up F i l te r ing  : a Pars ing  St ra tegy  fo r  GPSGPhilippe BLACt IE  (*) and Jean-Yves MORIN (**)*Groupe Repr6sentation et 'Fraitement des ConnaissancesCEN\]llE NATIONAL DE LA RECIIERCItE SCIENTIHQUE31, Ch.
Joseph Aiguier13402 Marseille Codex 09 (France)e-mail :grtc@frmopl 1 .bitnet** Ddpartement deLinguistique t PhilologioUNIVERSITI~, DE MONTRI~,ALCP 6128, Succ.
A, H3C 3J7Montr6al (Canada)e-mail :morinjy@ iro,umontreal.caAbstractIn this paper, we propose an optimized strategy, called Bottom-Up Filtering, for parsingGPSGs.
This strategy is based on a particular, high level, interpretation fGPSGs.
It permiksa significant reduction of fl~e non-determinism inherent to the rule selection process.IntroductionLinguistic theories are becoming increasingly importantfor natural language parsing.
In earlier work in thisdomain, few approaches were based on full-fledgedlinguistic descriptions, Nowadays, this is becoming therule rather than the exception !.Among all\[ the current linguistic thcories, we think thatGPSG allows the simplest interface between linguisticand computational theory.
But its naive computationalinterpretation, although fairly straightforward, mightresult in a computationally e?pensive implementation.Barton showed that universal ID/LP parsing could bereduced to the vertex-cover p oblem, and so was NP-complete.
In theory, we can only search for heuristics.in actual practice we might still look for efficientimplementations.
Several authors (Evans, Ristad,Kilbury...) developed an interpretation of the theorythat can support an efficient implementation.
Some, like\[Shieber86\], are more interested in the algorithmicviewpoint.In this paper, we shall review some of the mostimportant factors of intractability before giving apresentation of Bottom-Up Filtering.
This presentationis twofold: interpretation f GPSG and implementationof this interpretation using Bottom-Up Filtering.1 Cf.
for instance \[Abramson89\], \[(;azdar89\], [Uszkoreit88\].
Seealso \[,Iensen88\] for file contrary position.1.
ComplexiO' of GPSG parsingSeveral studies like \[Barton84\] or \[Ristad86\] discussedthe theoretical complexity of universal GPSG parsing.Here we shall focus on the effective complexity ofGPSG parsing and especially on the problem of non-determinism in rule selection.Rule selection generates everal problems moreparticularly due to local ambiguity: the parser can selecta wrong rule and cause backtracking.
This non-determinism problem is one of the most important innatural anguage processing.
Several mechanisms suchas lookahead or knowledge of leftmost constituentshave been proposed to constrain the operation of ruleselection and reduce this non determinism.The ID/LP formalization separates two aspects ofphrase structure which are merged in a standard(context-free) phrase structure rule: hierarchicalconstituency and constituent order.
Constituency rules(ID-rules) are represented with unordered right-handsides.
Hence, for an ID-rule like X --~ At ..... Ak, anunconstrained expansion can generate k~ phrase-structure rules.
Moreover, metarules increase thisovergeneration problem.
To summarize this problem,we can say that there are two main sources of non-determinism (and henceforth of actual computationalcomplexity) in GPSG:19(1) ID-rules:- derivation is a non-detenninistic process- possibility of null transition (rules with empty right-hand sides), permitting large structures with few"supporting" terminals- unordered right-hand sides(2) Metarules:- induction of null transition and ambiguity- exponential increase of ID-rules- non-deterministic application to ID-rulesThere are several other factors of complexity.
Most ofthe parsing problems come from non-determinism,which can be reduced in two ways: constraints on theunderlying linguistic theory and development of newparsing strategies.2.
Constraining GPSGThe interpretation f a linguistic theory consists in theadaptation of the abstract model to make itcompulationally tractable.
This adaptation has to bejustified both lingafistically and computationally.This notion is quite recent in the domain of naturallanguage parsing systems: most of them use only asmall part of the theory, often not in a coherent way,and so introduce many adhocities.
Moreover, we cangive many differents interpretations to the same theory.In the case of GPSG, we can for example interpret i asan independently justified theory or just as a particularformalism tbr context-free grammars.
There is a choicebetween indirect interpretation (compilation into acontext-free grammar, which is then interpreted) anddirect interpretation of a GPSG.
A compilaticn of aGSPG consists in several expansion steps whichtransform it into a context-free equivalent grammar.Compiling a GPSG amounts to considering it as anotational variant of ordinary context-free phrase-structure grannnar.
As noted by \[Evans 87\], a directinterpretation is more in keeping with the high levelmechanisms of GPSG and might even be actually moreefficient han the indirect interpretation approach.Our interpretation of GPSG does not use a pre-compilation level.
It is more particularly orientedtowards an adaptation of the ID-rules formalization:problems caused by non-determinism are known to bedirectly related to grammar representation.
I  the case ofGPSG, these problems arise from the use of unorderedrules.We think that we must respect he high level andgenerality of GPSG.
So, we propose the use of verylarge ID-rules, called extensive ID-rules, able todescribe many different constructions for the samephrase.
Hence, we partially eliminate subcategorization(whose informational and predictive value has beenlargely overestimated) and replace it with a Bottom-UpFiltering mechanism.We propose to apply to GPSG the notion of automataminimization exposed in \[Aho72\].
This notion, basedon the concept of distinguishability between two states,is used to generate reduced automata (i.e.
automata inwhich no state is unaccessible) 2.
We apply this conceptto ID/LP formalization to achieve what we can callgrammar minimization: no two rules describing thesame phrase have more than one common category (thehead of the current phrase).
In other words, we will usedifferent rules only for very different constructions.Consequently, we never have sets of ID-ruleslike \[ G azdar85\] :~?T ~ 11131, NP, PP\[to\] (give)VP -~ II\[41, NP, PPlj+br\] (buy)As for automata, we first have to define equivalenceclasses for ID-rules.
From these classes (also calledfamilies of rules), we extract a representative elementwhich will be the extensive ID-rule.
These concepts areformally defined as follows:- head of a phrase : a head h of a phrase P is aconstituent with particular properties : its presence isnecessary for some constructions of P and moreover,the values of both the N and V features must be thes,'une in the descriptions of the head and of the phrase.Hence, we can define a function head from P(KuX) toK (where K is the set of categories,2J the set ofterminals and P(X) denotes the set of all subsets of X)as follow : let an ID-rule of the form A --->ai C1 ..... C,~,then :head(A) = { Ci / (Ci(\[N1) = A(IN\]) ) and(Ci ( \ [W) = A( \ [W) ) \]let G be a GPSG, R be the set of ID-rules of G,andr~ R,r is of the form s --9 t, cl .
.
.
.
.
cj (with 0 _<i _~j),where t is the head of swe define the following operations on R :2 This is central  for our approach:  no two dist inct states areindist inguishable.20 2(1) left-lhand side of a rule:utS( r )  = {s)(2) right-hand side of a rule:RHS(r) = {t, ci ... .
.
cj }(3) reduced right-hand side of a rule:RHS'(r) = {ci ..... cj }(4) rule inclusion (noted ~)let rl, r2 e R, rl ~_ r2 iffLHS(rl ) = LtlS(r2), head(r1) = head(r2)and RIlS- (rl ) ~_ RHS-(r2 )We define a rule clustering function F from R to R asfo l lows :F ( r )={r  i E R / r i ~r  v r  ~r i}Hence, an extensive D-rule is define as follows :let r e R, r is an extensive ID-rule iffV r' ~ F(r) , r' ~ rSuch a formalization of the grammar considerablyreduces the problem of non-determinism during theselection of a rule: if two rules are different, their right-hand sides have at most one element in common.
Thisallows us to establish strong selection constraints.
Tosummm'ize, using extensive ID-rules allows a very highlevel of generality for the representation f a GPSG,preserving its succinctness property.3.
Bottom-Up Fi lteringThe Bottom-Up Filtering strategy is based on thedetection of the first constituent of a phrase.\[Pereira871, in a presentation of bottom-up arsing,describes the left-corner parsing method.
This strategywas first introduced in \[Rosenkrantz70\].
It consists infinding the leftmost constituent ~of a phrase P, so as toselect a phrase structure rule P -9 c~ ~ and thenproving that ~ is actually the left-corner of such aphrase by application of the rest (N) of the selected rule.There are two stages in the process: a bottom-up one(detecting the left corner) and a top-down one (parsingthe rest of the phrase).
Using both strategies isinteresting, particularly for the selection of a phrasestructure rule: knowledge of the leftmost constituentconstrains this stage and so reduces non-determinism.Hence, this strategy, like ours, is based upon thedetection of the leflmost constituent of a pttrase.
But thesimilarity stops here: the use of unordered rules,inherent to the ID/LP formalism, would forcemodification and introduction of new mechanisms.Moreover, this strategy allows only a small reAuction ofnon-determinism, especially because the top-downstage is used in a classical way.Based on our interpretation of GPSG and theformalization of extensive ID-rules we propose astrategy that ,allows the initialization of the phrase levelupon determination of the leftmost constituents.
Afterthis bottom-up stage, the parse is completed by a top-down process consisting in the selection of the adequateextensive ID-rules and the generation of phrase-structure rules.
We insist on the fact that we don't useexpansion or a selection function for this last stage, buta genuine generation process: the rules are actuallydeduced by formal operations from the grammar.
Thisstage is largely constrained by both our formalizationand the bottom-up filtering that initializes the phrases.We obtain a strategy in which non-determinism isdrastically reduced.Bottom-Up Filtering parsing is achieved in three stages:(i) creation of prediction tables(ii) phrase level initialization(iii) generation of phrase-structure rules3.1.
Prediction tablesUsing file extensive ID-rule formalization, we deduceinformations that will allow us to determine the leftmostconstituent.
We use two main concepts: first legaldaughter and immediate precedence.Definition: the first legal daughter of a constituent is acategory of any level that can occur in the first positionof the right-hand side of a phrase-structure ruledescribing thi,~ constituent.So, according to LP constraints, a given constituentmay have scwzral first lcgal daughters which we collectinto a set.We note < the linear precedence r lation.Let P be a phrase, V oc such that P --~ ~ then First, theset of first legal daughters, is defined as follows:First(P) = {c ~ o~ .
.
.
.
.
.
.
.
such that Vx ~ a-{c}, then c<x} tThe second concept, the immediate precedence r lation,allows us to determine all the constituents that canprecede, according with LP constraints, a first legal3 21daughter ~n a right-hand side of ID-rule.
Theseconstituents can themselves be first legal daughters ofthe considered phrase, or not.
The reason is,particularly when using the extensive ID-rulesformalism, that several ID-rules describe severaldifferent constructions of a given phrase type.
So, theremay be constituents hat cannot initialize a phrase but, insome constructions, that can precede a constituentwhich is actually a first daughter in anotherconstruction.
This relation defines sets of immediateprecedence; asfollows:Let P be a phrase, k /a  such that P --~ a ,  let x be anon-terminal, let c ~ First(P), then IPp(c), the set ofimmediate precedence of c for P, is defined as follows:\[Pp(c) = {x such that (x < c) or (x e a andneither x < c nor c < x exist)}Prediction tables are made of the sets of first legaldaughters for all phrases and those of immediateprecedence for each first legal daughter.
These sets arespecified during the implementation f the grammar.Note that this is not a compilation of the grammar,because we only have to determine the leftmostconstituents for the rules, whereas compilation wouldgenerate all the possible permutations for entire rules.The sets are thus kept reasonably small.3.2.
Phrase level init ial izationWith the aid of the prediction tables, we can nowdescribe the mechanisms used in the initialization of thephrase level.
This consists in determining all the firstdaughters in the input sentence, and so all the phrasesbelonging to the syntactic structure.
This stage consistsin two phases: categorization a d actual initialization.The categorization is a trivial function, used in allbottom-up strategies, which we enhance with a specialdevice for easier esolution of lexical ambiguities: theresulting data are stored as possible backtracking pointsfor our parser.The initialization stage is based upon a simple principle:an element of the sequence of categories is a firstdaughter of a phrase if it belongs to the set of first legaldaughters of this phrase and if the previous categorydoes not belong to its immediate precedence set.
Wedefine the initialize relation as follows :Let G be a GPSG, L(G) the language generated by G,let I be a string such that I ~ L(G), let C the list ofcategories of I, k/ c ~ C, -~ c' ~ N such that c'precedes c in C ;c initialize S iffc ~ First(S) and c' ?~ IPs(c)This stage yields a new list made of the lexicalcategories and the initialized phrases.We can give a very simple example of phrase levelinitialization.Let G a very small ID/LP grammar :Extensive ID-rules :S --)id NP, VPNP '-)id Det, N, AP, PPNP --~'id NVP --~ id V, NP, PPAP -~id AdjPP ~id  Prep, NPLP-rules (given here in a binary formalization) ?V< NP V < PP NP < VP Det < NDet < AP Det < PP N < SP Prep < NPSets of  First Legal Daughter :First( S ) = {NP} First(NP) = {Det, N}First( VP ) = {V} First(PP) = {Prep}First( AP ) = {Adj}Sets of  Immediate Precedence :IPs(NP) = O IPvp( V ) = OIPNp( Det ) = O IPNp( N ) = { Det,  AP }IPAP( Adj ) = O IPpp( Prep ) = OPHRASE LEVEL INITIALIZATIONLet the sentence :Peter walks down the street.
(1) Categor izat ion :N .
V .
P rep .
Det .
N(2) Phrase level initialization :Current catNVPrepDetLNFirst(P) Precedent catNPVP N 'PP VNP PrepNP DetlPp(c) ActionN/NPO V/VPp~.
!~O Det / NPWe obtain the following list :S.  < NP, N >.
< VP, V >.
<PP, Prep >.
<NP, Det>.NWe must keep in mind that the construction of theprediction tables is a pre-processing.
The actual step ofinitialization just consists in applying to the set of lexical22 4,categories the relation as defined before.
Hence, thisstep of our strategy is cornpulationally trivial.3.3.
Phrase-structure rules generationIn this last stage the phrase construction is completed byselecting apattern ID-rule and then generating the rightphrase structure rule.The pattern ID-rule selection is largely constrained byour formalization using extensive D-rules, but also bythe knowledge of left-hand side and the leftmostelement of right-hand side of the rule.
It is ahnost adeterministic process.The general.ion stage can only be roughly sketched here.It consists in a top-down search in the list of initializedphrases for the constituents of the current phrase.
Foreach category we scan this list of initialized phrases,adding to lhe phrase structure rule under generation allthe categories belonging to the pattern ID-rule.
If acategory does not belong to the pattern rule, it can be ,anindirect constituent (i.e.
a category belonging to aconstituent itself belonging itself to the phrase which isbeing parsed).
So, we have a process which allows usto generate the phrase structure rules required for theparse.ConclusionThe Boltom-Up Filtering strategy formalizes theoreticalconstraints which allow us to reduce the non-determinism problem due to local ambiguities 3.
Wehave implemented an algorithm based on the Bottom-Up Filtering strategy in Prolog II on a Macintosh SE/30and obtained interesting results: for a non trivial GPSGof French, most of the analyses for "usual" sentencestake less than 1 second.
More complicated constructionslike passive, coordination or discontinuous constituentstake between 1and 2.5 seconds.ReferenceslAbramson89\] Abramson, 1I.
& V. Dahl (1989) LogicGrammars, Springer-Verlag.\[Aho72\] Aho A.
& J. Ullmau (1972) The Theory ofParsing, Translation and Compiling, Volume 1:Parsing, lhentice-Ihdl.IBis'he90\]\[Blaser88\]\[Barton84\]\[Barton87\]lBerwick82\]\[Berwick85j\[Earley70\]\[Evans85\]\[Evans87\]\[ Gazdar85a\]\[Gazdar85b\]l G azdzu'89 \]\[Jensen88\]\[ Kilbury88 \]lMorin66\]\[Morin89\]lPereira871IPerrault83\]\[Phillips86\]\[R istad86\]\[ R istad87\]\[RosenkrantzTO\]lShieber84\]\[Sh&ber 86\]\[Uszkoreit 88\]Blache P. (1990) "L'analyse par FiltrageAscendant : une stratdgie efficace pour lesGrammaires Syntagrnatiques Gdn&alisdes",10 th International Workshop Expert Systemsand their Applications, AvignonBlaser, A.
(1988 ed.)
Natural Language at theComputer, Springer-Verlag.Barton G. (1984) "On the complexity of ID/LPparsing", AI Memo # 812, MIT.Barton G., R. Berwick, E. Ristad (1987)Computational Complexity and NaturalLanguage, MIT Press.Berwick R., A. Weinberg (1982) "ParsingEfficiency, Computational Complexity and theEvaluation of Grammatical Theories",Linguistic bzquiry, t3, 2.Bcrwick R., A. Weinberg (1985) "l)cterministicParsing and IJnguistic Explanation", Languageand Cognitive Processes, I 2.Earley J.
(1970) "An Efficient Context-FreeParsing Algorithm", Commnications of theACM, 13, 94-102.Evans R. (1985) "ProGram - a development toolfor GPSG grammars", Linguistics, 23.Evans R. (1987) Theoretical and ComputationalInterpretations of GPSG, Ph.
D. Dissertation,University of Sussex.Gazdar G., G. Pullum (1985) "ComputationallyRelevant Properties of Natural l,anguages andtheir Gnmmmrs", New Generation Computing,:3.Gazdar, G., et al (1985) Generalized PhraseStructure Gramtmtr, Blackwell.Gazdar, G. & C. Mellish (1989) Naturall.,anguage Processing in Prolog, Addisou-Wesley.Jenscn, K. (1988) "Issues in Parsing", in \[Biaser88\]: 65-83.Kilbury J.
(1988) "Parsing with CategoryC,mxzcurrence Restrucfions", COLING 88: 324-327,Morin, J.Y (1986) Th~orie syntaxique et th~oriedu parsage, Ddp.
linguistique & phflologie,Univ de Montr6"al et GIA, Faeult6 des Sciencesde.
Lumlny.Morin, J.Y (1989) Particules et parsageuniversel, in 1t.
Weydt (1989 ed.)
Sprechen mitP&rtikeln, W',dter de Gruyter (Berhn).Pereira F., S. Shieber (1987) Prolog and NaturalLanguage Analysis, CSLI Ix~cture Notes # 10.1)errault C. (1983) "On the MathematicalProperties of IJnguistie Theories", ACL-2 l.Phillips J., II.
Thompson (1986) A Parser forGPSG,  D.A.I Research Paper n ?
289,University of Edinburgh.Ristad E. (1986) "Computational Complexityof Current GPSG Theory", proceedings of ACL.Ristad E. (1987) "Revised GPSG", ACL-25.Rosenkrantz D., P. Lewis (1970) "DeterministicLeft-Come/" Parser", 1EEE Conference record ofthe 111h Annual Symposium on Switching andAutomata Theory.Shieber S. (1984) "Direct parsing of ID/LPgrammars", Linguistics and Philosophy, 7,135-154.Shieber S. (1986) "A Simple Reconstruction ofGPSG", COLING 86: 211-5.Uszkoreit, II.
(1988) "From Feature Bundles toAbstract Data Types: New Directions in theRepresentation and Processing of LinguisticKnowledge", in \[Bl~er 88\]: 31-64.3 Our phrase level initialization principle is related to the UniversalProjection Principle proposed for independent reasons in \[Morin89\].5 23
