JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 69?75,Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCPAlgorithme automatique non supervis?
pour le Deft 2012Murat Ahat 1 Coralie Petermann 1, 2 Yann Vigile Hoareau 3 Soufian BenAmor 1 Marc Bui 2(1) Prism, Universit?
de Versailles Saint-Quentin-en-Yvelines, 35 avenue des Etats-Unis, F-78035 Versailles.
(2) LaISC, Ecole Pratique des Hautes Etudes, 41 rue Gay-Lussac, F-75005 Paris.
(3) CHArt, 41 rue Gay-Lussac, F-75005 Paris.murat.ahat@prism.uvsq.fr, coralie.petermann@laisc.net,hoareau@lutin-userlab.fr, soufian.ben-amor@uvsq.fr, marc.bui@ephe.sorbonne.frR?SUM?Nous d?crivons l?approche mise en oeuvre dans le cadre du D?fi de Fouille de Texte 2012 pourla piste 1 qui consistait ?
identifier, pour un article scientifique et son r?sum?
donn?s, la listedes mots cl?s qui lui correspondent parmi un ensemble de mot cl?s possibles.
Cette approcheest bas?e sur le couplage entre les m?thodes d?espaces s?mantiques pour la repr?sentation desconnaissances s?mantiques d?une part, et les graphes pour la d?cision sur l?affectation d?un motcl?
?
un article, d?autre part.
La m?thode propos?e est enti?rement automatique, sans phase deparam?trage, non-supervis?e et ne n?cessite aucune ressource externe.ABSTRACTAutomatic unsupervised algorithm for Deft 2012We describe our approach in Deft 2012 for track 1, which consist in identifying a correspondinglist of key word, for a given scientific paper and summary, from a set of possible key words.The approach is based on the one hand, semantic space for the representation of semanticknowledge, and, on the other hand, graphs for the decision on the allocation of a key word to adocument.
The proposed method is fully automatic, without any particular tuning, unsupervisedand requires no external resources.MOTS-CL?S : Espace s?mantique, Graphe, Random Indexing.KEYWORDS: Semantic Space, Graph, Random Indexing.691 IntroductionDans cette ?dition 2012 du D?fi Fouille de Texte, nous avons appliqu?
notre m?thode d?j?pr?sent?e lors du Deft 2011 (Hoareau et al, 2011b), qui consiste ?
mixer deux m?thodes derepr?sentation des connaissances : les espaces s?mantiques qui sont des espaces vectoriels ?grandes dimensions et les mod?les de graphes.
L?int?r?t du couplage des deux approches estde b?n?ficier d?une part des propri?t?s d?apprentissage non-supervis?
ainsi que des propri?t?ss?mantiques latentes associ?s aux espaces s?mantiques et, d?autre part de la sophistication desmath?matiques sous-jacentes ?
la th?orie des graphes.Pour ce faire, la premi?re contrainte ?respecter est de produire un graphe ayant les m?mes propri?t?s que l?espace s?mantique en ce quiconcerne la repr?sentation des relations s?mantiques latentes entre les mots ou les documents(Louwerse et al, 2006).
Cette contrainte satisfaite, des applications peuvent alors ?tre r?alis?esdirectement ?
partir du graphe.
Un exemple d?application de cette approche mixte est celui de lavisualisation des relations s?mantiques latentes entre documents au sein de grandes bases dedonn?es textuelles (Hoareau et al, 2011a).L?an pass?, le challenge consistait ?
associer un article ?
son r?sum?.
Dans la suite de cet article,nous allons voir si cette ann?e, toujours sans param?trage ni apprentissage, notre m?thodeproduit d?aussi bon r?sultats pour la t?che 1 qui consiste ?
apparier un article et son r?sum??
une liste de mots cl?s.
Cette m?thode a ?t?
instanci?e de telle sorte ?
repr?senter la relations?mantique entre chaque mot cl?
et chaque couple article/r?sum?
dans un graphe construit ?partir d?un espace s?mantique, puis ?
utiliser ce graphe complet pour associer ?
chaque article unou plusieurs mot cl?.L?article est organis?
de la fa?on suivante.
Dans la premi?re section nous d?crivons le cadreth?orique de notre algorithme en pr?sentant les espaces s?mantiques et les algorithmes decr?ation de tels espaces ?
partir d?un quelconque contenu, ainsi que les bases de la th?orie desgraphes n?cessaires ?
notre approche, afin de repr?senter les documents sous la forme d?ungraphe ayant les m?mes propri?t?s que l?espace s?mantique construit.
Dans la deuxi?me section,nous d?crivons notre algorithme.
Dans le troisi?me section, nous pr?sentons bri?vement lesr?sultats de notre approche et les comparons avec les r?sultats obtenus l?an pass?.
Enfin, nousconcluons l?article en pr?sentant les perspectives de recherche qui pourraient prolonger le pr?senttravail.2 Cadre th?orique2.1 Les espaces s?mantiquesLa th?orie des espaces s?mantiques est un ensemble de m?thodes alg?briques permettant derepr?senter des documents de tout type selon leur contenu.
Plusieurs m?thodes permettent demod?liser des espaces s?mantiques.
Elles admettent toutes l?hypoth?se distributionnelle suivante :les mots ayant un sens proche apparaissent dans des documents similaires.
Mais toutes reposentsur la s?mantique vectorielle : les corpus sont analys?s et mod?lis?s sous forme de vecteurs ?grandes dimensions, rassembl?s dans une matrice de co-occurences.
Cette matrice peut ?treconstruite de deux mani?res selon les algorithmes :?
matrice mots-documents, utilis?e par exemple dans LSA et RI, qui compte le nombre d?occur-70rences de chaque mot dans chaque document?
matrice mots-mots, utilis?e par HAL, qui regroupe les probabilit?s de co-occurences pourchaque groupe de motsEtant donn?e une repr?sentation vectorielle d?un corpus de documents, on peut introduire unenotion d?espace vectoriel permettant de mettre en place la notion math?matique de proximit?entre documents.
En introduisant des mesures de similarit?
adapt?es, on peut quantifier laproximit?
s?mantique entre diff?rents documents.
Les mesures de similarit?
sont choisies enfonction de l?application.Une mesure tr?s utilis?e est la similarit?
cosinus, qui consiste ?
quantifier la similarit?
entredeux documents en calculant le cosinus de l?angle entre leurs vecteurs.
Ainsi, un cosinus nul,signe de l?orthogonalit?
des deux vecteurs, indiquera que ces 2 documents n?ont aucun mot encommun.
L?avantage de cette m?thode est que la longueur des documents n?influe en rien ler?sultat obtenu.Une autre mesure possible est la distance de Manhattan (appel?e aussi city-block), qui elle, prenden compte la longueur des documents compar?s.2.2 Random IndexingRandom Indexing (Kanerva et al, 2000) est un mod?le d?espace s?mantique bas?
sur des projec-tions al?atoires.La m?thode de construction d?un espace s?mantique avec RI est la suivante :?
Cr?er une matrice A (d ?
N), contenant des vecteurs-index, o?
d est le nombre de documentsou de contextes correspondant au corpus et N , le nombre de dimensions (N > 1000) d?finipar l?exp?rimentateur.
Les vecteurs-index sont creux et alatoirement g?n?r?s.
Ils consistent enun petit nombre de (+1) et de (-1) et de centaines de 0 ;?
Cr?er une matrice B (M ?
N) contenant les vecteurs-termes, o?
M est le nombre de termesdiff?rents dans le corpus.
Pour commencer la compilation de l?espace, les valeurs des cellulesdoivent ?tre initialis?es ?
0 ;?
Parcourir chaque document du corpus.
Chaque fois qu?un terme ?
appara?t dans un docu-ment d, il faut accumuler le vecteur-index correspondant au document d au vecteur-termecorrespondant au terme ?.?
la fin du processus, les vecteurs-termes qui sont apparus dans des contextes (ou documents)similaires, auront accumul?
des vecteurs-index similaires.Cette m?thode a d?montr?
des performances comparables (Kanerva et al, 2000) et parfois m?mesup?rieures (Karlgren et Sahlgren, 2001) ?
celles de LSA pour le test de synonymie du TOEFL(Landauer et Dumais, 1997).
RI a ?t?
aussi appliqu?
?
la cat?gorisation d?opinion (Sahlgren etC?ster, 2004).2.3 Th?orie des graphesLa th?orie des graphes est une th?orie informatique et math?matique.
Cette th?orie est largementutilis?e dans tous les domaines li?s ?
la notion de r?seau (r?seau social, r?seau informatique,t?l?communications, etc.)
et dans bien d?autres domaines (g?n?tique, transports...).71Un graphe G = (V, A) est une paire compos?e de (Berge, 1970) :1. un ensemble V = {x1, x2, ..., xn} appel?
sommets (en r?f?rence aux poly?dres) ou noeuds(en r?f?rence ?
la loi des noeuds).2. une famille A= (a1, a2, ..., an) d?
?l?ments du produit Cart?sien V ?
V = {(x , y)/x ?
V, y ?V} appel?s arcs (cas d?un graphe orient?)
ou ar?tes (cas d?un graphe non orient?
).En g?n?ral, on note n le nombre de noeuds (aussi not?
|V (G)|) et m le nombre d?arcs (aussi not?|A(G)|).Un chemin P est compos?
de k arcs tels que P = (a1, a2, ..., ai , ..., ak) o?
pour chaque arc ai , lafin co?ncide avec le d?but de ai+1.
Une chaine est l?
?quivalent d?un chemin dans le cadre nonorient?.Un graphe est simple si au plus une ar?te relie deux sommets et s?il n?y a pas de boucle sur unsommet.
Dans les cas o?
une ar?te relie un sommet ?
lui-m?me (une boucle), ou plusieurs ar?tesrelient deux m?mes sommets, on appelle ces graphes des multigraphes.FIGURE 1 ?
Multigraphe.Un graphe est biparti si ses sommets peuvent ?tre divis?s en deux ensembles X et Y , de sorteque toutes les ar?tes du graphe relient un sommet dans X ?
un sommet dans Y (dans l?exempleci-dessous, on a X = 1,3,5 et Y = 2,4).FIGURE 2 ?
Graphe biparti.Dans notre m?thode, nous utiliserons des graphes simples bipartis, afin d?associer chaque article?
une liste de mots cl?s.
Dans la section suivante, nous pr?sentons notre algorithme en d?tails.723 Notre algorithmeCette section d?crit le processus de construction (i) d?un graphe complet repr?sentant les pro-pri?t?s s?mantiques d?un espace s?mantique, puis (ii) d?un graphe biparti ?
partir d?un espaces?mantique.Notre m?thode d?bute par une ?tape de pr?traitements qui consiste ?
supprimer les mots videsde sens tels que les conjonction de coordination, articles ind?fini, pronoms...Le proc?d?
consiste ensuite ?
g?n?rer notre espace s?mantique ?
l?aide de la m?thode RI puis?
calculer la distance euclidienne pond?r?e entre chaque document et chaque mots cl?s del?espace s?mantique afin de construire un graphe biparti complet.
L?int?r?t de cette m?thode tr?ssimple est de g?n?rer automatiquement un graphe biparti et de permettre ainsi d?y appliquer lesm?thodes issues de la th?orie des graphes (Hoareau et al, 2011a).FIGURE 3 ?
Notre algorithme.L?algorithme d?crit ci-apr?s a pour objectif de construire un graphe biparti ?
partir d?un espaces?mantique.
Il prend en entr?e un ensemble d?articles .
Une matrice m "article ?
mots cl?s" estconstruite.
Cette matrice contient dans chaque cellule mi, j , la valeur de la distance euclidiennepond?r?e entre les vecteurs de l?article i et du mots cl?s j. ?
partir de cette matrice, un graphebiparti complet g est produit.
Un processus de filtre est appliqu?
?
ce graphe afin de produire ungraphe biparti o?
?
un article est connect?
?
ces mots cl?s.Procedure main()VarA as Article Set;K as Kew word Set;N as number of articles;M as number of keywords;m as Matrix Article Key word;g as graph (article --> key word);BeginspaceSemantic = RandomIndexing(A)For (i:=1 to N)artVector = spaceSemantic(A[i]);73For (j:=1 to M)keyVector = spaceSemantic(R[j]);m[i,j] = cosine(artVector, resVector);End For; //jEnd For; //ig = createGraph(m);End Procedure //main()Procedure createGraph(m);Varm as Matrix Article Key word;g as graph (article --> key word);knumList as number of keywords for articles;Beging = emptyGraph();For (i:= 1 to N)templist = Max(m[i,:],knumbList);g.add(i,templist);EndReturn g;End Procedure //createGraph()4 R?sultats et discussionPour le d?fi Deft 2012, nous avons soumis deux groupes de r?sultats, obtenus ?
l?aide dedeux espaces s?mantiques diff?rents.
Le premier est cr??
?
partir des documents de test etd?apprentissage, alors que le second est cr??
uniquement ?
partir des documents de test.
Lalibrairie utilis?e impl?mentant random indexing est semantic vectors, et la dimension des vecteursa ?t?
param?tr?e ?
2048 avec un cycle d?entrainement.
M?me si notre algorithme nous a fournide bons r?sultats pour Deft 2011 en nous hissant sur la premi?re place ex aequo du podium(Hoareau et al, 2011b), les r?sultats obtenus cette ann?e ne sont pas satisfaisants (voir le tableausuivant).Run Pr?cision Rappel F-score1 0,0428 0,0428 0,04282 0,0242 0,0242 0,0242TABLE 1 ?
Scores pour les t?ches d?appariement du DEFT 2012Nous avons tent?
en vain d?am?liorer nos r?sultats avec des param?trages diff?rents des espacess?mantiques pour tester des dimensions jusqu??
6000 et jusque 5 cycle d?entrainement.
Nousassumons alors que la m?thode de random indexing peut ?tre une des causes de cet ?chec.
Nouspoursuivons donc nos recherches sur ce sujet, en testant diverses m?thodes de constructionsd?espaces s?mantiques et divers outils concernant les espaces s?mantiques.745 Conclusion et perspectivesLa m?thode propos?e dans le cadre de notre participation au Deft repose sur le couplageentre les espaces s?mantiques et les graphes.
Le faible nombre de documents disponibles pourl?apprentissage constituait une contrainte forte pour notre m?thode enti?rement bas?e sur uneapproche distributionnelle.
En 2011, nous avions obtenu de bons r?sultats mais la t?che du Deft2012 a montr?
les limites de notre m?thode.De prochaines exp?riences seront r?alis?es afin de comparer notre m?thode, et am?liorer sonparam?trage.R?f?rencesBERGE, C. (1970).
Graphes et Hypergraphes.
Dunod, Paris.HOAREAU, Y. V., AHAT, M., MEDERNACH, D. et BUI, M. (2011a).
Un outil de navigation dans unespace s?mantique.
In KHENCHAF, A. et PONCELET, P., ?diteurs : Extraction et gestion des connais-sances (EGC?2011), volume RNTI-E-20 de Revue des Nouvelles Technologies de l?Information,pages 275?278.
Hermann-?ditions.HOAREAU, Y. V., AHAT, M., PETERMANN, C. et BUI., M. (2011b).
Couplage d?espaces s?mantiqueset de graphes pour le deft 2011 : une approche automatique non supervis?e.
In D?fi Fouille deTextes (DEFT 2011), Montpellier, France.KANERVA, P., KRISTOFERSON, J. et HOLST, A.
(2000).
Random Indexing of Text Samples forLatent Semantic Analysis.
In GLEITMAN, L. et JOSH, A., ?diteurs : Proceedings of the 22nd AnnualConference of the Cognitive Science Society, Mahwah.
Lawrence Erlbaum Associates.KARLGREN, J. et SAHLGREN, M. (2001).
From Words to Understanding.
In UESAKA, Y., KANERVA, P.et ASOH, H., ?diteurs : Foundations of Real-World Intelligence.
CSLI Publications, Stanford.LANDAUER, T. et DUMAIS, S. (1997).
A Solution to Plato?s Problem : The Latent SemanticAnalysis Theory of Acquisition, Induction and Representation of Knowledge.
PsychologicalReview, 104(2):211?240.LOUWERSE, M., CAI, Z., HU, X., VENTURA, M. et JEUNIAUX, P. (2006).
Cognitively inspired natural-language based knowledge representations : Further explorations of latent semantic analysis.International Journal of Artificial Intelligence Tools, 15:1021?1039.SAHLGREN, M. et C?STER, R. (2004).
Using bag-of-concepts to improve the performance ofsupport vector machines in text categorization.
In COLING ?04 : Proceedings of the 20th interna-tional conference on Computational Linguistics, page 487, Morristown, NJ, USA.
Association forComputational Linguistics.75
