Lexical Choice Criteria in Language GenerationManf red  StedeDepartment ofComputer ScienceUniversity of TorontoToronto M5S 1A4, Canadamstede~cs.toronto.edu1 In t roduct ionIn natural anguage generation (NLG), a semanticrepresentation f some k ind-  possibly enriched withpragmatic attributes - -  is successively transformedinto one or more linguistic utterances.
No matterwhat particular architecture is chosen to organizethis process, one of the crucial decisions to be madeis lexicalization: selecting words that adequately ex-press the content hat is to be communicated and,if represented, the intentions and attitudes of thespeaker.
Nirenburg and Nirenburg \[1988\] give thisexample to illustrate the lexical choice problem: Ifwe want to express the meaning "a person whosesex is male and whose age is between 13 and 15years", then candidate realizations include: boy, kid,teenager, youth, child, young man, schoolboy, ado-lescent, man.
The criteria influencing such choicesremain largely in the dark, however.As it happens, the problem of lexical choice hasnot been a particularly popular one in NLG.
Forinstance, Marcus \[1987\] complained that most gen-erators don't really choose words at all; McDonald\[1991\], amongst others, lamented that lexical choicehas attracted only very little attention i  the researchcommunity.
Implemented generators tend to providea one-to-one mapping from semantic units to lexicalitems, and their producers occasionally acknowledgethis as a shortcoming (e.g., \[Novak, 1991, p. 666\]);thereby the task of lexical choice becomes a non-issue.
For many applications, this is indeed a feasiblescheme, because the sub-language under considera-tion can be sufficiently restricted such that a directmapping from content o words does not present adrawback - -  the generator is implicitly tailored to-wards the type of situation (or register) in which itoperates.
But in general, with an eye on more ex-pressive and versatile generators, this state of affairscalls for improvement.Why is lexical choice difficult?
Unlike many otherdecisions in generation (e.g., whether to express anattribute of an object as a relative clause or an ad-jective) the choice of a word very often carries impli-catures that can change the overall message signifi-cantly - -  if in some sentence the word boy is replacedwith one of the alternatives above, the meaning shiftsconsiderably.
Also, often there are quite a few sim-ilar lexical options available to a speaker, whereasthe number of possible syntactic sentence construc-tions is more limited.
To solve the choice problem,first of all the differences between similar words haveto be represented in the lexicon, and the criteria forchoosing among them have to be established.
In thefollowing, I give a tentative list of choice criteria,classify them into constraints and preferences, andoutline a (partly implemented) model of lexicaliza-tion that can be incorporated into language genera-tors.2 Word  Cho ice  Cr i te r iaOnly few contributions have been made towardsestablishing word choice criteria in NLG.
1 Hovy's\[1988\] generator PAULINE selected lexical items ac-cording to pragmatic aspects of the situation (rhetor-ical goals of the speaker giving rise to stylistic goals,which in turn lead to certain lexical choices).
Alsolooking at the pragmatic level, Elhadad \[1991\] ex-amined the influence of a speaker's argumentativeintent on the choice of adjectives.
Wanner and Bate-man \[1990\] viewed lexical choice from a situation-dependent perspective: the various aspects of themessage to be expressed by the generator can havedifferent degrees of salience, which may give riseto certain thematizations and also influence lexicalchoice.
Reiter \[1990\] demonstrated the importanceof basic-level categories (as used by Rosch \[1978\]) forgeneration, overriding the popular heuristic of alwayschoosing the most specific word available.Generally speaking, the point of "interesting" lan-guage generation (that is, more than merely map-ping semantic elements one-to-one onto words) is totailor the output o the situation at hand, where 'sit-uation' is to be taken in the widest sense, includingthe regional setting, the topic of the discourse, thesocial relationships between discourse participants,etc.
There is, however, no straightforward one-to-one mapping from linguistic features to the param-eters that characterize a situation, as, for example,stylisticians point out \[Crystal nd Davy, 1969\].
Var-ious levels of description are needed to account forthe complex relationships between the intentions ofthe speaker and the variety of situational parameters,which together determine the (higher-level) rhetori-cal means for accomplishing the speaker's goM(s) andthen on lower levels their stylistic realizations.Here we are interested in the descriptional levelof lexis: we want to identify linguistic features that1 Considerable work has been done on the construc-tion of referring expressions, but this is just one specificsub-problem of lexical choice, and moreover a context-sensitive one.
In this paper, we restrict ourselves tochoice criteria that apply independently of the linguis-tic context.454serve as a basis for choosing a particular lexical itemfrom a set of synonyms.
Not all these features areequally interesting, however; as Crystal and Davy\[1969\] noted, the relation between situational fea-tures and linguistic features is on a scale from to-tal predictability to considerable freedom of choice.Among the less interesting dimensions are dialectand genre (sub-languages pertaining to particular do-mains, for example legal language or sports talk),because they tend to merely fix a subset of the vo-cabulary instead of Mlowing for variation: the factthat what Americans call a lightning rod is a light-ning conductor in British English does not imply ameaningful (in particular, not a goal-directed) choicefor a speaker; one rarely switches to some dialect fora particular purpose.
More interesting is the degreeof semantic specificity of lexical items.
An examplefrom Cruse \[1986\]: see is a general term for hav-ing a visual experience, but there is a wide rangeof more specific verbs that convey additional mean-ing; for instance, watch is used when one pays atten-tion to a changing or a potentially changing visualstimulus, whereas look at implies that the stimulus isstatic.
Such subtle semantic distinctions demand afine-grained knowledge representation if a generatoris expected to make these choices \[DiMarco et ai.,1993\].An important factor in lexical choice are collo-calionai constraints tating that certain words canco-occur whereas others cannot.
For instance, wefind rancid butter, putrid fish, and addled eggs, butno alternative combination, although the adjectivesmean very much the same thing.
2 Collocations holdamong lexemes, as opposed to underlying semanticconcepts, and hence have to be represented aslexicairelations.
They create the problem that individuallexical choices for parts of the semantic representa-tion may not be independent: roughly speaking, thechoice of word x for concept a can enforce the choiceof word y for concept b.Finally, a highly influential, though not yet verywell-understood, factor in lexical choice is style.3 Lex ica l  S ty leThe notion of style is most commonly associated withliterary theory, but that perspective is not suitablefor our purposes here.
Style has also been inves-tigated from a linguistic perspective (e.g., Sanders\[1973\]), and recently a computational treatment hasbeen proposed by DiMarco and Hirst \[1993\].
What,then, is style?
Like Sanders, we view it broadly asthe choice between the various ways of expressingthe same message.
Linguists interested in style, as,for instance, Crystal and Davy \[1969\], have analyzedthe relationships between situational parameters (in2In NLG, collocation knowledge has been employedby, inter alia, Smadja and McKeown \[1991\] and Iordan-skaja, Kittredge and Polgu~re \[1991\].particular, different genres) and stylistic hoice, andwork in artificial intelligence has added the impor-tant aspect of (indirectly) linking linguistic choicesto the intentions of a speaker \[Hovy, 1988\].
Clearly,the difficult part of the definition given above is todraw the line between message and style: what partsof an utterance are to be attributed to its invariantcontent, and what belongs to the chosen mode ofexpressing that content?In order to approach this question for the levelof lexis, hence to investigate iezicai style, it helpsto turn the question "What criteria do we employfor word choice?"
around and to start by analyz-ing what different words the language provides tosay roughly the same thing, for example with thehelp of thesauri.
By contrastively comparing simi-lar words, their differences can be pinned down, andappropriate features can be chosen to characterizethem.
A second resource besides the thesaurus areguidebooks on "how to write" (especially in foreign-language teaching), which occasionally attempt oexplain differences between similar words or proposecategories of words with a certain "colour" (cf.
\[Di-Marco et ai., 1993\]).
One problem here is to deter-mine when different suggested categories are in factthe same (e.g., what one text calls a 'vivid' word islabelled 'concrete' in another).An investigation of lexical style should thereforelook for sufficiently general features: those that canbe found again and again when analyzing differ-ent sets of synonymous words.
It is important toseparate stylistic features from semantic ones, cf.the choice criterion of semantic specificity mentionedabove.
The whole range of phenomena that havebeen labelled as associative meaning (or as one as-pect under the even more fuzzy heading connotation)has to be excluded from this search for features.
Forexample, the different overtones of the largely syn-onymous words smile, grin (showing teeth), simper(silly, affected), smirk (conceit, self-satisfaction) donot qualify as recurring stylistic features.
Similarly,a sentence like Be a man, my son/alludes to aspectsof meaning that are clearly beyond the standard 'def-inition' of man (human being of male sex) but againshould not be classified as stylistic.
And as a finalillustration, lexicM style should not be put in chargeto explain the anomaly in The lady held a white lilyin her delicate fist, which from a 'purely' semanticviewpoint should be all right (with fist being definedas closed hand).Stylistic features can be isolated by carefully com-paring words within a set of synonyms, from which agenerator is supposed to make a lexical choice.
Oncea feature has been selected, the words can be rankedon a corresponding umerical scale; the experimentsso far have shown that a range from 0 to 3 is sufficientto represent the differences.
Several features, how-ever, have an 'opposite nd' and a neutral positionin the middle; here, the scale is -3 .
.
.
3.455Ranking words is best being done by construct-ing a "minimal" context for a paradigm of synonymsso that the semantic influence exerted by the sur-rounding words is as small as possible (e.g.
: Theydestroyed/annihilated/ruined/razed/.., the building).Words can hardly be compared with no context atall - -  when informants are asked to rate words on aparticular scale, they typically respond with a ques-tion like "In what sentence?"
immediately.
If, on theother hand, the context is too specific, i.e., semanti-cally loaded, it becomes more difficult to get accessto the inherent qualities of the particular word inquestion.These are the stylistic features that have been de-termined by investigating various guides on goodwriting and by analyzing a dozen synonym-sets hatwere compiled from thesauri:?
FORMALITY: -3 .
.
.3This is the only stylistic dimension that lin-guists have thoroughly investigated and that iswell-known to dictionary users.
Words can berated on a scale from 'very formal' via 'collo-quial' to 'vulgar' or something similar (e.g., mo-tion picture-movie-flick).?
EUPHEMISM: 0 .
.
.3The euphemism is used in order to avoid the"real" word in certain social situations.
Theyare frequently found when the topic is stronglyconnected to emotions (death, for example) orsocial taboos (in a washroom, the indicated ac-tivity is merely a secondary function of the in-stallation).?
SLANT: -3 .
.
.3A speaker can convey a high or low opinionon the subject by using a slanted word: afavourable or a pejorative one.
Often this in-volves metaphor: a word is used that in factdenotes a different concept, for example whenan extremely disliked person is called a rat.
Butthe distinction can also be found within sets ofsynonyms, e.g., gentleman vs.
jerk.?
ARCHAIC .
.
.
TRENDY: -3 .
.
.
3The archaic word is sometimes called 'obsolete',but it is not: old words can be exhumed on pur-pose to achieve specific effects, for example bycalling the pharmacist apothecary.
This stylis-tic dimension holds not only for content words:albeit is the archaic variant of even though.
Atthe opposite end is the trendy word that hasonly recently been coined to denote some mod-ern concept or to replace an existent word thatis worn out.?
FLOPdDITY: -3 .
.
.3This is one of the dimensions suggested by Hovy\[1988\].
A more flowery expression for consideris entertain the thought.
At the opposite endof the scale is the trite word.
Floridity is occa-sionally identified with high formality, but thetwo should be distinguished: The flowery wordis used when the speaker wants to sound im-pressively "bookish", whereas the formal wordis "very correct".
Thus, the trite house can becalled habitation to add sophistication, but thatwould not be merely 'formal'.
Another reasonfor keeping the two distinct is the opposite endof the scale: a non-flowery word is not the sameas a slang term.?
ABSTRACTNESS: -3 .
.
.3Writing-guidebooks often recommend to replacethe abstract with the concrete word that evokesa more vivid mental image in the hearer.
Butwhat most examples found in the literature re-ally do is to recommend semantically more spe-cific words (e.g., replace to fly with to float orto glide), which add traits of meaning and aretherefore not always interchangeable; thus thechoice is not merely stylistic.
A more suitableexample is to characterize an unemployed person(abstract) as out of work (concrete).?
FORCE: 0 .
.
.3Some words are more forceful, or "stronger"than others, for instance destroy vs. annihilate,or big vs. monstrous.There is an interesting relationship (that shouldbe investigated more thoroughly) between these fea-tures and the notion of core vocabulary as it is knownin applied linguistics.
Carter \[1987\] characterizescore words as having the following properties: theyoften have clear antonyms (big--small); they have awide collocational range (fat cheque, fat salary but.corpulent cheque, .chubby salary); they often serveto define other words in the same lexical set (to beam= to smile happily, to smirk = to smile knowingly);they do not indicate the genre of discourse to whichthey belong; they do not carry marked connotationsor associations.
This last criterion, the connotationalneutrality of core words could be measured usingour stylistic features, with the hypothesis being thatcore words tend to assume the value 0 on the scales.However, the coreness of a word is not only a mat-ter of style, but also of semantic specificity: Carternotes that they are often superordinates, and thisis also the reason for their role in defining similarwords, which are, of course, semantically more spe-cific.
It seems that the notion of core words corre-sponds with basic-level categories, which have beenemployed in NLG by Reiter \[1990\], but which hadoriginated not in linguistics but in cognitive psychol-ogy \[Rosch, 1978\].4 Towards  a Mode l  fo r  Lex ica l i za t ionWhen the input to the generator is some sort of asemantic net (and possibly additional pragmatic pa-rameters), lexical items are sought that express allthe parts of that net and that can be combined into agrammatical sentence.
The hard constraint on which456(content) words can participate in the sentence isthat they have the right meaning, i.e., they correctlyexpress some aspect of the semantic specification.The second constraint is that collocations are not tobe violated, to avoid the production of a phrase likeaddled butter.
The other factors mentioned above en-ter the game as preferences, because their completeachievement cannot be guaranteed - - if we want tospeak 'formally', we can try to find particularly for-mal words for the concepts to be expressed; but ifthe dictionary does not offer any, we have to be con-tent with more 'standard' words, at least for some ofthe concepts underlying the sentence.
We can max-imize the achievement of lexical-stylistic goals, butnot strive to fully achieve them.To arrive at this kind of elaborate lexical choice, Ifirst employ a iexical option finder (following ideasby Miezitis \[1988\]) that scans the input semanticnet and produces all the lexical items that are se-mantically (or truth-conditionally) appropriate forexpressing parts of the net.
If the set of options con-tains more than one item for the same sub-net, theseitems can differ either semantically (be more or lessspecific) or connotationally (have different stylisticfeatures associated with them).The second task is to choose from this pool a setof lexical items that together express the completenet, respect collocational constraints (if any are in-volved), and are maximal under a preference func-tion that determines the degree of appropriatenessof items in terms of their stylistic and other conno-tational features.
Finally, the choice process has tobe integrated with the other decisions to be made ingeneration (sentence scope and structure, theme con-trol, use of conjunctions and cue words, etc.
), suchthat syntactic onstraints are respected.Two parts of the overall system have been realizedso far.
First, a lexical option finder was built withLOOM, a KL-ONE dialect.
Lexical items correspondto configurations of concepts and roles (not just tosingle concepts, as it is usually done in generation),and the option finder determines the set of all itemsthat can cover a part of the input proposition (repre-sented as LOOM instances).
Using inheritance, themost specific as well as the appropriate more generalitems are retrieved (e.g., if the event in the proposi-tion is darning a sock, the items darn, mend, fix areproduced for expressing the action).5 S ty l i s t i c  Lex ica l  Cho ice  inPENMANAt the 'front end' of the overall system, a lexicalchoice process based on the stylistic features listedin section 3 has been implemented using the PEN-MAN sentence generator \[Penman-Group, 1989\].Its systemic-functional grammar has been extendedwith systems that determine the desired stylistic"colour" and, with the help of a distance metric (seebelow), determine the most appropriate l xical itemsthat fit the target specification.Figure 1 shows a sample run of the system, wherethe : lexstyle keyword is in charge of the variation;its filler (here, s lang or newspaper)  is being trans-lated into a configuration of values for the stylisticfeatures.
This is handled by the standard mech-anism in  PENMAN that associates keyword-fillerswith answers to inquiries posed by the grammaticalsystems.
In the example, the keyword governs theselection from the synonym-sets for evict, destroy,and building (stored in Penman's lexicon with theirstylistic features).
The chosen transformation f the: lexstyle filler into feature values is merely a firststep towards providing a link from low-level featuresto more abstract parameters; a thorough specifica-tion of these parameters and their correspondencewith lexical features has not been done yet.More specifically, for every stylistic dimension onesystem is in charge to determine its numeric targetvalue (on the scale -3  to 3).
Therefore, the par-ticular : lexstyle filler translates into a set of fea-ture/value pairs.
When all the value-inquiries havebeen made, the subsequent system in the grammarlooks up the words associated with the concept o beexpressed and determines the one that best matchesthe desired feature/value-specification.
For everyword, the distance metric adds the squares of thedifferences between the target feature value (tf) andthe value found in the lexical entry (wf) for each ofthe n features: ~i~=l(tfi - wfi) 2The fine-tuning of the distance-metric is subject oexperimentation; i  the version shown, the motiva-tion for taking the square of the difference is to, forexample, favour a word that differs in two dimen-sions by one point over another one that differs inone dimension by two points (they would otherwisebe equivalent).
The word with the lowest total dif-ference is chosen; in case of conflict, a random choiceis made.6 Summary  and  Future  WorkAn important task in language generation is tochoose the words that most adequately fit into the ut-terance situation and serve to express the intentionsof the speaker.
I have listed a number of criteria forlexical choice and then explored stylistic dimensionsin more detail: Arguing in favour of a 'data-driven'approach, sets of synonyms have been extracted fromthesauri and dictionaries; comparing them led to aproposed set of features that can discriminate syn-onyms on stylistic grounds.
The features chosen inthe implementation have been selected solely on thebasis of the author's intuitions (albeit using a sys-tematic method) - -  clearly, these findings have to bevalidated through psychological experiments (askingsubjects to compare words and rate them on appro-priate scales).
Also, it needs to be explored in moredetail whether different parts of speech should be457(say-sp l  ' ( r r  / rst -sequence:domain (d / EVICT :actor (p / PERSON :name tom):actee (t  / TENANT :determiner the :number p lura l ):tense past : lexs ty le  slang):range (e / DESTROY :actor p:actee (b / BUILDING :determiner the):tense past :lexstyle slang)))"Tom threw the tenants out, then he pulverized the shed.
"(say-sp l  ' ( r r  / rst -sequence< same as above >:tense past : lexs ty le  newspaper)))"Tom evicted the tenants, then he tore the building down.
"Figure h Sample run of style-enhanced PENMANcharacterized by different feature sets.An overall model of lexicalization i  the generationprocess has been sketched that first determines allcandidate lexical items for expressing parts of a mes-sage (including all synonyms and less-specific tems),and a preferential choice process is supposed to makethe selections.
The front-end of this system has beenimplemented by extending the PENMAN sentencegenerator so that it can choose words on the basis ofa distance function that compares the feature/valuepairs of lexical entries (of synonyms) with a targetspecification.
This target specification has so far onlybeen postulated as corresponding to various stereo-typical genres, the name of which is a part of theinput specification to PENMAN.
In future work, thestylistic features need to be linked more systemati-cally to rhetorical goals of the speaker and to param-eters characterizing the utterance situation.
One ofthe tasks here is to determine which features houldbe valid for the whole text to be generated (e.g., for-mality), or only for single sentences, or only for singleconstituents (e.g., slant).Besides, ultimately the work on lexical style hasto be integrated with efforts on syntactic style \[Di-Marco and Hirst, 1993\].
Other criteria for lexicalchoice, like those mentioned in section two, have tobe incorporated into the choice process.
And finally,it has to be examined how lexical decisions interactwith the other decisions to be made in the gener-ation process (sentence scope and structure, themecontrol, use of conjunctions and cue words, etc.
).AcknowledgementsFinancial support from the Natural Sciences and En-gineering Research Council of Canada and the Infor-mation Technology Research Centre of Ontario is ac-knowledged.
Part of the work reported in this paperoriginated uring a visit to the Information SciencesInstitute (ISI) at the University of Southern Califor-nia; thanks to Eduard Hovy for hospitality and in-spiration.
For helpful comments on earlier versionsof this paper, I thank Graeme ttirst and two anony-mous reviewers.Re ferences\[Carter, 1987\] Ronald Carter.
Vocabulary: AppliedLinguistic Perspectives.
Allen ~c Unwin, London,1987.\[Cruse, 1986\] D. Alan Cruse.
Lexical Semantics.Cambridge University Press, 1986.\[Crystal and Davy, 1969\] David Crystal and DerekDavy.
Investigating English Style.
Edward Arnold,London, 1969.\[DiMarco and Hirst, 1993\] Chrysanne DiMarco andGraeme Hirst.
A Computational Theory of Goal-Directed Style in Syntax.
Computational Linguis-tics, 19(??
), 1993.
Forthcoming.\[DiMarco et al, 1993\] Chrysanne DiMarco, GraemeHirst, and Manfred Stede.
The Semantic andStylistic Differentiation of Synonyms and Near-Synonyms.
In Working Notes of the AAAI SpringSymposium on Building Lexicons for MachineTranslation.
Stanford University, 1993.
Forthcom-ing.\[Elhadad, 1991\] Michael Elhadad.
Generating Ad-jectives to Express the Speaker's ArgumentativeIntent.
In Proceedings of the Fifth National Con-ference on Artificial Intelligence (AAAI-91), pages98-104, 1991.\[Hovy, 1988\] Eduard H. Hovy.
Generating NaturalLanguage Under Pragmatic Constraints.
LawrenceErlbaum, Hillsdale, N J, 1988.\[Iordanskaja etal., 1991\]Lidija Iordanskaja, Richard Kittredge, and AlainPolgu~re.
Lexical Selection and Paraphrase in aMeaning-Text Generation Model.
In C. L. Paris,W.
R. Swartout, and W. C. Mann, editors, Natu-ral Language Generation in Artificial Intelligenceand Computational Linguistics, chapter 11, pages293-312.
Kluwer, Dordrecht, 1991.458\[Marcus, 1987\] Mitchell Marcus.
Generation Sys-tems Should Choose Their Words.
In YorickWilks, editor, Theoretical Issues in Natural Lan-guage Processing, pages 211-214.
New MexicoState University, Las Cruces, 1987.\[McDonald, 1991\] David D. McDonald.
On thePlace of Words in the Generation Process.
In C. L.Paris, W. R. Swartout, and W. C. Mann, editors,Natural Language Generation in Artificial Intelli-gence and Computational Linguistics, pages 227-248.
Kluwer, Dordrecht, 1991.\[Miezitis, 1988\] Mara Anita Miezitis.
GeneratingLexical Options by Matching in a KnowledgeBase.
Technical Report CSRI-217, University ofToronto, 1988.\[Nirenburg and Nirenburg, 1988\] Sergei Nirenhurgand Irene Nirenburg.
A Framework for Lexical Se-lection in Natural Language Generation.
In Pro-ceedings of the 12th International Conference onComputational Linguistics (COLING-88), pages471-475, Budapest, 1988.\[Novak, 1991\] Hans-Joachim Novak.
Integrating aGeneration Component into a Natural LanguageUnderstanding System.
In O. Herzog and C. R.Rollinger, editors, Text Understanding in LILOG,pages 659-669.
Springer, Berlin/Heidelberg, 1991./Penman-Group, 1989\] Penman-Group.
The Pen-man Documentation.
Unpublished documentationfor the Penman system, 1989.\[Reiter, 1990\] Ehud Reiter.
Generating Descriptionsthat Exploit a User's Domain Knowledge.
InR.
Dale, C. Mellish, and M. Zock, editors, CurrentResearch in Natural Language Generation.
Aca-demic Press, 1990.\[Rosch, 1978\] Eleanor Rosch.
Principles of Catego-rization.
In E. Rosch and B. Lloyd, editors, Cogni-tion and Categorization.
Lawrence Erlbaum, Hills-dale, NJ, 1978.\[Sanders, 1973\] Willy Sanders.
Linguistische Stilthe-orie.
Vandenhoeck & Ruprecht, GSttingen, 1973.\[Smadjaand McKeown, 1991\] Frank Smadja andKathleen R. MeKeown.
Using Collocations forLanguage Generation.
Computational Intelligence,7:229-239, 1991.\[Wanner and Bateman, 1990\]Leo Wanner and John A. Bateman.
A Colloca-tional Based Approach to Salience-Sensitive Lex-ical Selection.
In Proceedings of the Fifth Inter-national Natural Language Generation Workshop,pages 31-38, Dawson, PA, 1990.459
