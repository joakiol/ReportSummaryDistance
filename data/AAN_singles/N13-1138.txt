Proceedings of NAACL-HLT 2013, pages 1185?1195,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsSupervised Learning of Complete Morphological ParadigmsGreg Durrett?Computer Science DivisionUniversity of California, Berkeleygdurrett@cs.berkeley.eduJohn DeNeroGoogle, Inc.denero@google.comAbstractWe describe a supervised approach to predict-ing the set of all inflected forms of a lexicalitem.
Our system automatically acquires theorthographic transformation rules of morpho-logical paradigms from labeled examples, andthen learns the contexts in which those trans-formations apply using a discriminative se-quence model.
Because our approach is com-pletely data-driven and the model is trainedon examples extracted from Wiktionary, ourmethod can extend to new languages withoutchange.
Our end-to-end system is able to pre-dict complete paradigms with 86.1% accuracyand individual inflected forms with 94.9% ac-curacy, averaged across three languages andtwo parts of speech.1 IntroductionFor natural languages with rich morphology, knowl-edge of how to inflect base forms is critical for bothtext generation and analysis.
Hand-engineered, rule-based methods for predicting inflections can offerextremely high accuracy, but they are laborious toconstruct and do not exist with full lexical cover-age in all languages.
By contrast, a large numberof example inflections are freely available in a semi-structured format on the Web.
The English Wik-tionary1 is a crowd-sourced lexical resource that in-cludes complete inflection tables for many lexicalitems in many languages.
We present a supervised?Research conducted during an internship at Google.1http://en.wiktionary.orgsystem that, given only data from Wiktionary, au-tomatically discovers and learns to apply the ortho-graphic transformations governing a language?s in-flectional morphology.2Our data-driven approach is designed to extend toany language for which we have a substantial num-ber of example inflection tables.
The design of ourmodel is guided by three structural assumptions:1.
The inflections of many lexical items aregoverned by a few repeated morphologicalparadigms.2.
A morphological paradigm can be decom-posed into independent orthographic transfor-mation rules (including prefix, suffix, and stemchanges), which are triggered by orthographiccontext.3.
A base form is transformed in consistent, cor-related ways to produce its inflected variants.Learning proceeds in two stages that both utilizethe same training set of labeled inflection tables.First, an inventory of interpretable transformationrules is generated by aligning each base form to allof its inflected forms.
Second, a semi-Markov con-ditional random field (CRF) (Sarawagi and Cohen,2004) is trained to apply these rules correctly to un-seen base forms.
As we demonstrate experimentally,the CRF is most effective when jointly predicting allinflected forms of a lexical item together, forcing thesystem to adopt a single consistent analysis of eachbase form.2See http://eecs.berkeley.edu/~gdurrett forour datasets and code.1185Previous work has also described supervised andsemi-supervised approaches to predicting inflec-tional morphology (Yarowsky and Wicentowski,2000; Wicentowski, 2004; Dreyer and Eisner, 2011).Our approach differs primarily in its use of auto-matically extracted morphological rules and our dis-criminative prediction method which jointly mod-els entire inflection tables.
These modeling choicesare directly inspired by the data setting: Wiktionarycontains complete inflection tables for many lexicalitems in each of a large number of languages, so itis natural to make full use of this information with ajoint model of all inflected forms.We evaluate our predictions on held-out Wik-tionary inflection tables for three languages and twoparts of speech.
Our language-independent methodpredicts inflections for unseen base forms with ac-curacies ranging from 88.9% (German nouns) to99.7% (Spanish verbs).
For comparability with pre-vious work, we also evaluate our approach on Ger-man verb forms in the CELEX lexical database(Baayen et al 1995).
Our approach outperformsthe semi-supervised hierarchical Bayesian model ofDreyer and Eisner (2011), while employing scal-able exact inference and interpretable transforma-tion rules.2 Background: Inflectional MorphologyAmong the valid words W and parts of speech Pin a language, the base forms B ?
W ?
P are thecanonical forms of the language?s lexical items.
Abase form relates to an inflected form via an inflec-tional relation (b, w, a), where b ?
B is a base form,w ?
W is the inflected form, and a is a vector ofmorphological attributes.
An inflection table T (b) isthe set of all such relations for a base form b.Two partial inflection tables are shown in Table 1,for the base forms (infinitives) of the German verbsmachen and schleichen, containing such inflec-tional relations as (machen, mache, [1P,PRES,SING])and (machen, gemacht, [PAST PART.]).
Only asmall sample of the valid attribute combinations areshown; a full inflection table for a German verb inour Wiktionary dataset contains 27 relations.The goal of this paper is to learn how to map bto T (b).
We generate candidate inflection tables byapplying compact, interpretable orthographic trans-INFINITIVE machen schleichen1P,PRES,SING mache schleiche2P,PRES,SING machst schleichst3P,PRES,SING macht schleichtPAST PART.
gemacht geschlichen... ... ...Table 1: Two partial inflection tables for the Germanverbs machen (to make) and schleichen (to crawl).formation rules that have been extracted from ex-ample tables.
As an example of our rule applica-tion process, to inflect machen appropriately in theforms listed in Table 1, one could apply the follow-ing rules:1.
Replace a suffix -en with -e for first person, -stfor second person, -t for third person, and -t forthe past participle.2.
Add a prefix ge- for the past participle.To inflect schleichen, one could apply a larger set ofthree rules:1.
Replace a suffix -en with -e for first person, -stfor second person, -t for third person, and -enfor the past participle.2.
Add a prefix ge- for the past participle.3.
Delete the first e for the past participle.The inflection tables of other German verbs can begenerated using precisely the same rules above, anddifferent inflection patterns may share rules, such asthe repeated rule 2.
This example illustrates one ofour chief assumptions, that the inflections of manybase forms can be modeled with a small number ofsuch rules, applied in various combinations.3 Learning Transformation RulesFrom a training set of inflection tables{T (b1), ..., T (bn)}, our system learns a set oforthographic transformation rules.
A rule is a func-tion R : s, a?
s?
that takes as input a substring s ofa base form and an attribute vector a and outputs areplacement substring s?.
The suffix transformationfrom Section 2 for machen can be described using a1186Algorithm 1 Learning rules from examples.Input: n training instances T (b1), .
.
.
, T (bn)Rule setR ?
{}for i?
1 to n doChanged source spans C ?
{}for all a ?
A doCa ?
PROJECTSPANS(ALIGN(bi, Ta(bi)))C ?
UNIONSPANS(C,Ca)end forfor all c ?
C doR ?
R?
{EXTRACTRULE(c)}end forend forreturn Rrule with four entries:R(en, [1P,PRES,SING]) = eR(en, [2P,PRES,SING]) = stR(en, [3P,PRES,SING]) = tR(en, [PAST PART.])
= tOur method for learning rules from examples isdescribed in Algorithm 1 and depicted in Figure 1.We extract rules from each observed inflection tableT (bi) independently, and the final set of rules is sim-ply the union of the sets of rules learned from eachexample.
The procedure for a single inflection tablehas three steps:Alignment: Align each inflected form to the baseform with an iterated edit-distance algorithm.Span Merging: Extract the set of spans of thebase form that changed to produce the inflectedform, and take their union across all attribute vec-tors to identify maximal changed spans.Rule Extraction: Extract a rule for each maxi-mal changed span.Alignment.
For each setting of attributes a, wefind the lowest-cost transformation of the base formb into the corresponding inflected form Ta(b) usingsingle-character insertions, deletions, and substitu-tions.
This minimum edit distance calculation iscomputed via the following recurrence, where i isan index into the base form b and j is an index intos c h l e i c h e  ns c h l e i c h es c h l     i c hg e s c h l     i c h e ns c h l  e  i c h e ns c h l e i c h e ns c h l e i c h es c h l  i c hg e s c h l  i c h e n......AlignmentSpan Mergings c h l  e  i c h  e n||||||||| D||| ||||D D D|||| |||||I I DRule Extraction...s c h li c he nes c h ls c h ls c h lee e ni c hg ei c hi c hFigure 1: Demonstration of the rule extraction algorithmwith the base form schleichen and three inflected forms:schleiche (first person singular present), schlich (first per-son singular past), and geschlichen (past participle).
Weideally want to extract appropriate transformation ruleslike those described in Section 2.
In the alignment step,we minimize the edit distance between each inflectedform and the base form to identify changed spans.
Inthe span merging step, we project changes onto the baseform and take the union of adjacent or overlapping spans.In the rule extraction step, we project these spans backonto the inflected forms to identify transformation rules.an inflected form Ta(b):L(i, j) = min{L(i, j ?
1) + I,L(i?
1, j) +D,L(i?
1, j ?
1) + S(i, j)}I , D, and S are insertion, deletion, and substi-tion costs, respectively.
Tracing the computation ofL(len(b), len(Ta(b))) yields an optimal sequence ofedit operations.
The alignments output by this pro-cedure are depicted in the first panel of Figure 1.The most typical cost scheme sets I = 1, D = 1,and S(i, j) = (1 ?
I[match(i, j)]), i.e.
0 if the ithcharacter of b is the same as the jth character ofTa(b), and 1 otherwise.
However, this cost schemedid not yield intuitive alignments for some of ourtraining instances.
For example, in the case of theverb denken aligning to its past participle gedacht,1187the initial d and g will be aligned and the follow-ing e?s will be aligned, preventing the algorithmfrom recognizing the addition of the prefix ge-.
Tosolve this problem, we use a dynamic edit distancecost scheme in which I , D, and unmatched substi-tutions all have a cost of 0.
Matched substitutionshave a negative cost ?ci, where i is the index in thebase form and ci is the number of other inflectedforms for which i is aligned to a matching char-acter.
The inflected forms are iteratively realignedwith the base form until the ci converge (Eisner,2002; Oncina and Sebban, 2006).
This cost schemeencourages a single consistent analysis of the baseform as it aligns to all of its inflected forms.Span Merging.
From each aligned pair of words,the PROJECTSPANS procedure identifies sequencesof character edit operations with contiguous spans ofthe base form.
We construct a set of changed spansCa of b as follows: include the span (i, j) if andonly if no characters between i and j were alignedto matching characters in Ta(b) and no smaller spancaptures the same set of changes.
Projected spansfor the inflected forms of schleichen are shown inthe ?Span Merging?
panel of Figure 1.The UNIONSPANS procedure combines two setsof spans by iteratively merging any two spans thatare overlapping or adjacent.
Repeating this proce-dure to accumulate spans for each setting of a yieldsthe set C of maximal changed spans for a base form.Any span inC is bordered either by word boundariesor by characters that are match-aligned in every in-flected form, meaning that we have isolated a regioncharacterized by a particular orthographic transfor-mation.Rule Extraction.
The final step of Algorithm 1extracts one rule for each maximal changed span ofthe base form.
The Rule Extraction panel of Figure 1depicts how maximal changed spans in the baseform correspond to transformation rules.
BecauseUNIONSPANS guarantees that match-aligned char-acters border each maximal changed span, there isno ambiguity about the segmentation of transforma-tions.
The EXTRACTRULE procedure produces onerule R(s, a) corresponding to each changed span.Table 2 contains examples of the transformationrules we extract from German verbs.
The extractedAttributes Suffix Stem Pre.INFINITIVE en en en n e1P,PRES,SING e e e e e1P,PAST,SING te te te2P,PRES,SING st t st st e2P,PAST,SING test test st test3P,PRES,SING t t t t e3P,PAST,SING te te tePAST PART.
t t en t ge... ... ... ... ... ... ...Label Rsuf,1 Rsuf,2 Rsuf,3 Rsuf,4 Rst,1 Rpre,1Table 2: Each column is an example of a morphologicaltransformation rule extracted by our approach.
The firstfour are suffix changes; these apply to, in order, regularverbs such as machen, verbs ending in -zen or -sen such assetzen, verbs such as schleichen and beheben, and verbsending in -ern or -eln such as sprenkeln.
The stem changeoccurs in strong verbs of the first class such as schleichen,greifen, and streiten.
Finally, we learn that ge- can beadded as a prefix to indicate the past participle.rules are interpretable descriptions of common in-flection patterns.4 Applying Transformation RulesFor a novel base form b, the inventory of learnedtransformation rules R = {R(s, a)} can typicallygenerate many candidate inflection tables T (b) forus to choose between.
A rule can potentially applyto a base form in a number of places; we define ananchored rule A = (R, i, j, b) to be the applicationof R to a span (i, j) in b.
A is only a valid anchoringif the substring of b between i and j matches theinput of rule R.Given a set A of non-overlapping anchored rulesfor b, each entry of T (b) can be deterministicallyproduced by rewriting each anchored rule?s span(i, j) using the ruleR.
Therefore, the task of predict-ing T (b) is equivalent to selecting a coherent subsetA of anchored rules from the set of all possible an-chored rules for this base form.
By coherent, wemean that the selected rules are anchored to non-overlapping, non-adjacent3 spans of b.
Figure 2ashows two coherent anchored rule subsets for schle-ichen (the top one being correct).
Underlining indi-3During rule extraction, any adjacent changed spans aremerged into a single rule.
Disallowing adjacent spans heretherefore prevents us from synthesizing new rules.1188cates length-one spans S = (i, i + 1, b) that are notpart of any anchored rule in A.
We denote the set ofsuch spans by S(A); this set is uniquely defined forthe given base form by the selected anchored rules.We use a log-linear model to place a conditionaldistribution over valid anchored rule subsetsA giventhe base form b:pw(A|b) ?
expwT???A?A?
(A) +?S?S(A)?(S)?
?where w is a weight vector, ?
(A) computes a fea-ture vector for anchored rule A, and ?
(S) computesa feature vector for preserved spans S. We trainthis model to maximize the regularized conditionallog-likelihood of the training data, which consists ofbase forms bi and gold subsets of anchored rulesA?iderived using Algorithm 1 on the gold inflection ta-bles.L(w) =n?i=1log p(A?i |bi) +?2?w?2.We find w?
= argmaxw L(w) using L-BFGS (Liuand Nocedal, 1989), which requires computing ?L?w .This gradient takes the standard form of the differ-ence between gold feature counts and expected fea-ture counts under the model:?L?w =n?i=1?????A?A?i?
(A) +?S?S(A?i )?(S)??
????A?A(R,b)Epw?
(A) +?S?S(b)Epw?(S)?????
?wwhere, by a slight abuse of notation, S(b) is the setof all length-one spans of b.In general, the normalizer of pw and the expec-tation over pw cannot be computed directly, sincethere may be exponentially many coherent subsetsof anchored rules.
However, we note that A andits corresponding S(A) form a segmentation of thebase form b, with features decomposing over indi-vidual segments.
Our model can therefore be vieweda semi-Markov model over b (Sarawagi and Co-hen, 2004); more precisely, a zeroth-order semi-Markov model, since we do not include features onstate transitions.
At training time, we can use thes c h l e i c h e ns c h l e i c h e na)b)s c h l e i c h e nRpre,1Rst,1Rst,1Rpre,1Rst,1:l[e]Rst,1:[e]iRsuf,3S:c[h]S:[h]e  Figure 2: a) Two possible anchored rule sets for schle-ichen.
The indicated rules are prefix, stem, and suffixrules as found in Table 2.
The top anchoring is correct,while the bottom misplaces the stem change and does notinclude a suffix change.
Underlined letters indicate pre-served spans S. b) Bigram context features computed by?
(Rst,1), where the stem change is applied to the high-lighted e, and similar features computed by ?
(S) for theunderlined h, which is unchanged by the applied rules.forward-backward algorithm for semi-Markov mod-els to compute the gradient of pw, and at test time,the Viterbi algorithm can exactly find the best rulesubset under the model: A?
= argmaxA pw(A|b).Features.
The feature function ?
captures contex-tual information in the base form surrounding thesite of the anchored rule application.
It is well under-stood that different morphological rules may requireexamining different amounts of context to apply cor-rectly (Kohonen, 1986; Torkkola, 1993; Shalonovaand Gole?nia, 2010); to this end, we will use localcharacter n-gram features, which have been success-fully applied to related problems (Jiampojamarn etal., 2008; Dinu et al 2012).A sketch of our feature computation scheme isshown in Figure 2b.
Our basic feature template isan indicator on a character n-gram with some off-set from the rule application site, conjoined with theidentity of the rule R being applied.
Our featureslook at variable amounts of context: we include fea-tures on unigrams through 4-grams, starting up tofive letters behind the anchored rule span and end-ing up to five letters past the anchored rule span.These features can model most hand-coded morpho-logical rules, but are in many cases more numerousthan necessary.
However, we find that regularizationis effective at balancing high model capacity withgeneralization, and reducing the size of the featureset empirically harms overall accuracy.We also employ factored features that only look atpredictions over particular inflected forms; these are1189coarser features that are shared between two ruleswhen they predict the same orthographic change fora particular setting of attributes.
These features areindicators onRa (the restriction ofR to attributes a),the context n-gram, and its offset from the span.The feature function ?
is almost identical to ?,but instead of indicating a rule appearing in somecontext, it instead indicates that a particular length-one span is being preserved in its n-gram context.Examples of ?
features are shown in Figure 2b.Pruning.
Thus far, the only requirement on an an-choring A is that the source side of its rule R mustmatch the span it is anchored to in the base formb.
We further filter the set of possible A as follows:if every occurrence of R in the training set is pre-ceded by the same character (including a start-of-word character) or followed by the same character(including an end-of-word character), any anchoringA must be preceded or followed accordingly.
Thisstipulation is most useful in restricting prefixing orsuffixing insertions, which have an empty sourceside, to apply only at the beginnings or ends of baseforms (rather than at arbitrary points throughout).
Indoing so, we prune out many erroneous anchoredrules and speed up inference substantially withoutprohibiting correct rule applications.5 Wiktionary Morphology DataOur primary source of supervised inflection tabledata is English Wiktionary.
The collective editorsof English Wiktionary have created complete, con-sistent inflection tables for many lexical items inmany languages.
Previous work has successfullyparsed other information from Wiktionary, such asparts of speech, glosses, and etymology (Zesch etal., 2008; Li et al 2012); however, to our knowl-edge, inflection tables have not previously been ex-tracted in a format easily amenable to natural lan-guage processing applications.
These inflection ta-bles are challenging to extract because the layout oftables varies substantially by language (beyond theexpected changes due to differing sets of relevantmorphological attributes), and some tables containannotations in addition to word forms.In order to extract this data, we built a Wiktionaryscraper which generates fully structured output byinterpreting the templates that generate the renderedLang/POS Base forms Infl.
forms per baseDE-NOUNS 2764 8DE-VERBS 2027 27ES-VERBS 4055 57FI-NOUNS 40589 28FI-VERBS 7249 53Table 3: Number of full morphology tables extractedfrom Wiktionary for each language and part of speechpair that we considered, as well as the number of inflectedforms associated with each base form.inflection tables.
Table 3 gives statistics for the num-ber of base forms and inflected forms extracted fromWikitionary.
When multiple forms were listed in aninflection table for the same base form and attributevector, we selected the first in linear order; applyingthe same principle, we also kept only the first inflec-tion table when more than one was listed for a givenbase form.
Furthermore, base forms and inflectedforms separated by spaces, hyphens, or colons werediscarded.
As a result, we discarded German verb-preposition compounds such as ablehnen4 and Span-ish reflexives such as lavarse.6 ExperimentsWe evaluate our model under two experimental con-ditions.
First, we use the German verb lexicon inthe CELEX lexical database (Baayen et al 1995)with the same train/test splits as Dreyer and Eisner(2011).
Second, we train on our Wiktionary data de-scribed in Section 5 and evaluate on held-out formsfrom this same dataset.In each case, we evaluate two variants of ourmodel in order to examine the importance of jointlymodeling the production of the entire inflection ta-ble.
Our JOINT model is exactly as defined in Sec-tion 4.
For our FACTORED model, the dictionary ofrules is extracted separately for each setting of theattributes a; i.e., we run the entire procedure in Sec-tion 3 with only one inflected form at a time andforego the UNIONSPANS step.
A separate predic-tion model is trained for each a and so features arenot shared across multiple predictions as they are inthe JOINT case.
Note that this FACTORED approach4This class of verbs was also ignored by Dreyer and Eisner(2011).1190No.
of training examples50 100 200NAI?VE 87.61 87.70 87.70FACTORED 89.61 91.40 92.64JOINT 90.47 92.31 93.18DE11 89.9 91.5DE11+CORPUS 90.9 92.2ORACLE 95.47 96.09 96.77Table 4: Accuracies on reconstructing individual in-flected forms in CELEX, averaged over the 5415 inflec-tion tables in each of 10 test sets.
Three training setsizes are reported.
DE11 indicates a reported result fromDreyer and Eisner (2011), with blank results unreportedin that work.
Our FACTORED model is able to do approx-imately as well as the DE11 baseline method, and ourJOINT model performs better yet, performing compara-bly to DE11+CORPUS, which uses additional monolin-gual text.
All models substantially outperform the NAI?VEsuffixing baseline.
The relatively low ORACLE accuracyindicates that some errors arise from failing to apply rulesthat are not attested in these small training sets.can produce inflection tables that the JOINT modelcannot, due to its ability to ?mix and match?
ortho-graphic changes in the same inflection table.We also evaluate a NAI?VE method for applyingthe joint rules which selects the most common suffixrule available after pruning.5 Finally, we report theORACLE accuracy attainable with the morphologi-cal rule dictionary of the JOINT model.For our conditional likelihood objective, we use?
= 0.0002; this parameter and the feature set weretuned on a small development set and held fixed forall experiments.6.1 CELEX ExperimentsDreyer and Eisner (2011) construct ten train/testsplits of the 5615 German verb forms in the CELEXlexical database, keeping 200 forms for training ineach case, which they further subsample.
These ran-dom splits serve to control for instability due to thesmall training set sizes.
Each infinitive verb formhas 22 corresponding inflected forms capturing vari-ation such as person, number, mood, and tense.5For example, for German verbs ending in -en, this appliesthe most regular -en suffix change, that exhibited by machenand many other verbs.Table 4 shows our results compared to those ofDreyer and Eisner (2011).
The FACTORED modelperforms on par with the DE11 baseline model, butthe stronger performance of the JOINT model in-dicates that making joint predictions is important.With 100 training examples, our model is able toequal the performance of DE11+CORPUS, whichadditionally uses ten million tokens of monolingualGerman text.We emphasize that this is not the data conditionfor which our model was designed.
It is unfavor-able for two reasons: first, feature-rich models canbe learned more stably on larger training sets, andsecond, the train/test splits are chosen randomly, andtherefore the test sets may contain completely irreg-ular verbs using morphological rules that we havenever observed.
As can be seen from the ORA-CLE results in Table 4, a substantial fraction of themissed test examples cannot be produced using ourextracted rules simply because we have not seen therelevant examples; in many cases, even a humancould not generalize correctly from the given ex-amples without exploiting external knowledge of theGerman language.6.2 Held-Out Wiktionary DataOur algorithm was designed with the fundamentalassumption that the training set should be a com-prehensive description of the morphology of a givenlanguage, which is not true for the CELEX data.
Inorder to evaluate on a broader set of languages underthese training conditions, we turn to our Wiktionarydata.
For each language and part of speech, we trainon all but 400 inflection tables, holding back 200 ex-amples as a development set and 200 examples as ablind test set.6 The forms selected for the develop-ment and test data were purposely chosen not to beamong the 200 most frequently occurring forms inthe language, since these common cases can be eas-ily memorized from Wiktionary.Results are shown in Table 5.
As with the CELEXresults, we see that the joint prediction improves ac-curacy over the factored model, obtaining a 9% er-ror reduction on individual forms and a 35% errorreduction on exact match.
The more pronounced6For Finnish nouns, because there were so many inflectiontables, we trained only on the first 6000 examples.
Using moreexamples did not significantly change performance.1191Exact table match Individual form accuracyLang/POS NAI?VE FACT.
JOINT ORACLE NAI?VE FACT.
JOINT ORACLEDE-VERBS 42.0 74.5 85.0 99.5 89.13 94.76 96.19 99.98DE-NOUNS 12.0 74.0 79.5 98.5 49.06 88.31 88.94 99.25ES-VERBS 81.5 93.5 95.0 99.5 97.20 99.61 99.67 99.99FI-VERBS 33.5 82.0 87.5 99.5 75.32 97.23 96.43 99.86FI-NOUNS 31.0 69.0 83.5 100.0 61.23 92.14 93.41 100.00AVG 40.0 78.6 86.1 99.4 74.39 94.41 94.93 99.81Table 5: Accuracies on reconstructing complete inflection tables and individual inflected forms for held-out base formsin our Wiktionary dataset.
Results are shown for our fully JOINT model, a FACTORED model that predicts individualinflected forms independently, a NAI?VE baseline that picks the most common applicable suffix rule, and an ORACLEthat selects the best inflection table within our model?s capacity.
For each language and part of speech, regardless oftraining set size, evaluation is based on a blind test set of 200 held-out forms.improvement on exact match is unsurprising, sincewe expect that the joint predictions should get in-flection tables correct in an ?all-or-nothing?
fashion,whereas factored predictions are more likely to re-flect divergent feature weights of the different com-ponent models.
The NAI?VE baseline performs ratherpoorly overall, indicating our algorithm is being so-phisticated about applying more than just the mostcommon changes.
Finally, we note that the ORA-CLE performance is much higher in this case thanon the CELEX data, confirming our intuition thatwith the appropriate level of supervision our modelat least has the capacity to make correct predictionsin almost every case.6.3 Error AnalysisWe conducted an error analysis on the output ofour JOINT model on German nouns.
From 2364paradigms, we learn 53 different orthographic trans-formation rules, of which our 200-example develop-ment set exhibits 14.7On our development set, 196 inflection tables arewithin the capacity of our model.
Of those 196, 159are exactly correct.
In Table 6, we show the topsix rules by frequency in the development set, along7Nineteen of our 53 extracted rules only occur on one ex-ample; this suggests a few reasons that fewer rules are appliedthan are extracted.
First, very common base forms with irreg-ular morphology may give rise to completely irregular rules.Second, our edit distance alignment procedure can sometimesmerge two adjacent rules if the orthographic context is such thatthere are multiple minimum-cost analyses.
Finally, errors andinconsistencies in Wiktionary can yield nonsense rules that arenever applied elsewhere.NOM,SING aNOM,PL n e a?
enACC,SING aACC,PL n e a?
enDAT,SING aDAT,PL n en a?
n enGEN,SING es a sGEN,PL n e a?
enExample Klasse Krieg Haus Nutzer FrauGold 49 48 26 26 20Prec 95.7 72.9 88.0 82.8 87.0Rec 91.8 89.6 84.6 92.3 100.0F1 93.8 80.4 86.3 87.3 93.0Table 6: Breakdown of errors by morphological rule be-ing applied by the JOINT model on the DE-NOUNS devel-opment set.
We show the rule itself, treating the nomina-tive singular as the base form, an example of a Germanword using that rule, and then the model?s accuracy atpredicting applications of that rule.
Errors are spread outover many rules, but it generally appears that commonrules are to blame for the errors that are made, due inlarge part to gender confusion in this case.with the precision, recall, and F-measure that ourmodel attains for each rule.8 These rules are mostlyinterpretable: for example, the first two columnscorrespond to common suffix rules for feminine andmasculine nouns, respectively.
Our model?s per-formance is consistently high for each of the rulesshown, including a stem change (a changing to a?in plural forms), providing further evidence that ourmodel is useful for modeling rarer morphological8Gold rules are obtained by running our rule extraction pro-cedure over the examples in question.1192paradigms as well as more common ones.As a concrete example of an error our model doesmake, Lo?we (lion) is incorrectly predicted to havethe first suffix, instead of the correct suffix (notshown) which adds an -n for accusative, genitive,and dative singular as well.
However, making thisprediction correctly is essentially beyond the capac-ity of a model based purely on orthography.
Wordsending in -e are commonly feminine, and none ofour other training examples end in -we, so guess-ing that Lo?we follows a common feminine inflec-tion pattern is reasonable (though Lo?we is, in fact,masculine).
Disambiguating this case requires ei-ther features on observed genders, a more complexmodel of the German language, or observing theword in a large corpus.
Generally, when the modelfails, as in this case, it is because of a fundamentallinguistic information source that it does not haveaccess to.7 Related WorkMuch of the past work on morphology has focusedon concatenative morphology using unsupervisedmethods (Goldsmith, 2001; Creutz and Lagus, 2007;Monson, 2008; Poon et al 2009; Goldwater et al2009) or weak forms of supervision (Snyder andBarzilay, 2008).
These methods can handle aspectsof derivational morphology that we cannot, such ascompounding, but we can handle a much larger sub-set of inflectional morphology, including more com-plex prefix and suffix rules, stem changes, and ir-regular forms.
Some unsupervised work has specifi-cally targeted these sorts of phenomena by, for ex-ample, learning spelling rules for mildly noncon-catenative cases (Dasgupta and Ng, 2007; Narad-owsky and Goldwater, 2009) or mining lemma-baseform pairs from a corpus (Schone and Jurafsky,2001), but it is extremely difficult to make unsu-pervised methods perform as well as supervised ap-proaches like ours.Past supervised work on nonconcatenative inflec-tional morphology has typically targeted individualpairs of base forms and inflected forms for the pur-poses of inflection (Clark, 2001) or lemmatization(Yarowsky and Wicentowski, 2000; Wicentowski,2004; Linde?n, 2008; Toutanova and Cherry, 2009).Some of these methods may use analysis (Linde?n,2008) or decoding (Toutanova and Cherry, 2009)steps similar to those of our model, but none attemptto jointly predict a complete inflection table basedon automatically extracted rules.Some previous work has addressed the joint anal-ysis (Zajac, 2001; Monson, 2008) or prediction(Linde?n and Tuovila, 2009; Dinu et al 2012) ofwhole inflection tables, as we do, but rarely areboth aspects addressed simultaneously and most ap-proaches are tuned to one particular language oruse language-specific, curated resources.
In over-all setup, our work most closely resembles that ofDreyer and Eisner (2011), but they focus on incor-porating large amounts of raw text data rather thanusing large training sets effectively.Broadly similar techniques are also employed insystems to filter candidate rules and aid in human an-notation of paradigms (Zajac, 2001; Forsberg et al2006; De?trez and Ranta, 2012) for resources such asGrammatical Framework (Ranta, 2011).8 ConclusionIn this work, we presented a method for inflectingbase forms in morphologically rich languages: wefirst extract orthographic transformation rules fromobserved inflection tables, then learn to apply theserules to new base forms based on orthographic fea-tures.
Training examples for our supervised methodcan be collected from Wiktionary for a large numberof languages and parts of speech.
The changes weextract are interpretable and can be associated withparticular classes of words.
Moreover, our modelcan successfully apply these changes to unseen baseforms with high accuracy, allowing us to rapidlygenerate lexicons for new languages of interest.Our Wiktionary datasets and an open-source version of our code are available athttp://eecs.berkeley.edu/~gdurrettAcknowledgmentsWe are grateful to Klaus Macherey and David Talbotfor assistance with the examples and helpful discus-sions throughout the course of this work.
We wouldalso like to thank the three anonymous reviewers fortheir useful comments.1193ReferencesR.
H. Baayen, R. Piepenbrock, and L. Gulikers.
1995.The CELEX Lexical Database (Release 2).
LinguisticData Consortium, University of Pennsylvania.Alexander Clark.
2001.
Partially Supervised Learningof Morphology with Stochastic Transducers.
In Pro-ceedings of Natural Language Processing Pacific RimSymposium, pages 341?348, Tokyo, Japan.Mathias Creutz and Krista Lagus.
2007.
UnsupervisedModels for Morpheme Segmentation and MorphologyLearning.
ACM Transactions on Speech and Lan-guage Processing, 4(1):3:1?3:34, Feb.Sajib Dasgupta and Vincent Ng.
2007.
High Per-formance, Language-Independent Morphological Seg-mentation.
In Proceedings of the North AmericanChapter of the Association for Computational Linguis-tics.Gre?goire De?trez and Aarne Ranta.
2012.
SmartParadigms and the Predictability and Complexity ofInflectional Morphology.
In Proceedings of the Eu-ropean Chapter of the Association for ComputationalLinguistics.Liviu P. Dinu, Vlad Niculae, and Octavia-Maria S?ulea.2012.
Learning How to Conjugate the RomanianVerb: Rules for Regular and Partially Irregular Verbs.In Proceedings of the European Chapter of the Asso-ciation for Computational Linguistics.Markus Dreyer and Jason Eisner.
2011.
DiscoveringMorphological Paradigms from Plain Text Using aDirichlet Process Mixture Model.
In Proceedings ofEmpirical Methods in Natural Language Processing,pages 616?627, Edinburgh, Scotland, UK.Jason Eisner.
2002.
Parameter Estimation for Probabilis-tic Finite-State Transducers.
In Proceedings of the As-sociation for Computational Linguistics.Markus Forsberg, Harald Hammarstro?m, and AarneRanta.
2006.
Morphological Lexicon Extraction fromRaw Text Data.
In Proceedings of Advances in Natu-ral Language Processing.John Goldsmith.
2001.
Unsupervised Learning of theMorphology of a Natural Language.
ComputationalLinguistics, 27(2):153?198, June.Sharon Goldwater, Thomas L. Griffiths, and Mark John-son.
2009.
A Bayesian Framework for Word Segmen-tation: Exploring the Effects of Context.
Cognition,112(1):21?54.Sittichai Jiampojamarn, Colin Cherry, and GrzegorzKondrak.
2008.
Joint Processing and Discrimina-tive Training for Letter-to-Phoneme Conversion.
InProceedings of the Association for Computational Lin-guistics.Teuvo Kohonen.
1986.
Dynamically Expanding Con-text, With Application to the Correction of SymbolStrings in the Recognition of Continuous Speech.
InProceedings of the International Conference on Pat-tern Recognition.Shen Li, Joa?o V. Grac?a, and Ben Taskar.
2012.
Wiki-lySupervised Part-of-speech Tagging.
In Proceedings ofEmpirical Methods in Natural Language Processing.Krister Linde?n and Jussi Tuovila.
2009.
Corpus-basedParadigm Selection for Morphological Entries.
InProceedings of the Nordic Conference of Computa-tional Linguistics.Krister Linde?n.
2008.
A Probabilistic Model for Guess-ing Base Forms of New Words by Analogy.
In Pro-ceedings of Computational Linguistics and IntelligentText Processing.Dong C. Liu and Jorge Nocedal.
1989.
On the limitedmemory BFGS method for large scale optimization.Mathematical Programming, 45(3):503?528, Decem-ber.Christian Monson.
2008.
ParaMor: From ParadigmStructure to Natural Language Morphology Induction.Ph.D.
thesis, Carnegie Mellon University.Jason Naradowsky and Sharon Goldwater.
2009.
Im-proving Morphology Induction by Learning SpellingRules.
In Proceedings of the International Joint Con-ferences on Artificial Intelligence.Jose Oncina and Marc Sebban.
2006.
Learning Stochas-tic Edit Distance: Application in Handwritten Char-acter Recognition.
Pattern Recognition, 39(9):1575?1587, September.Hoifung Poon, Colin Cherry, and Kristina Toutanova.2009.
Unsupervised Morphological Segmentationwith Log-Linear Models.
In Proceedings of the NorthAmerican Chapter of the Association for Computa-tional Linguistics.Aarne Ranta.
2011.
Grammatical Framework: Pro-gramming with Multilingual Grammars.
CSLI Pub-lications, Stanford.Sunita Sarawagi and William W. Cohen.
2004.
Semi-Markov Conditional Random Fields for InformationExtraction.
In Advances in Neural Information Pro-cessing Systems 17.Patrick Schone and Daniel Jurafsky.
2001.
Knowledge-Free Induction of Inflectional Morphologies.
In Pro-ceedings of the North American Chapter of the Asso-ciation for Computational Linguistics.Ksenia Shalonova and Bruno Gole?nia.
2010.
Weakly Su-pervised Morphology Learning for Agglutinating Lan-guages Using Small Training Sets.
In Proceedings ofthe Conference on Computational Linguistics.Benjamin Snyder and Regina Barzilay.
2008.
Unsuper-vised Multilingual Learning for Morphological Seg-mentation.
In Proceedings of the Association for Com-putational Linguistics.1194Kari Torkkola.
1993.
An Efficient Way to Learn EnglishGrapheme-to-Phoneme Rules Automatically.
In Pro-ceedings of the International Conference on Acoustics,Speech, and Signal Processing: Speech Processing -Volume II.Kristina Toutanova and Colin Cherry.
2009.
A GlobalModel for Joint Lemmatization and Part-of-SpeechPrediction.
In Proceedings of the Association forComputational Linguistics.Richard Wicentowski.
2004.
Multilingual Noise-RobustSupervised Morphological Analysis Using the Word-Frame Model.
In Proceedings of the ACL Special In-terest Group in Computational Phonology.David Yarowsky and Richard Wicentowski.
2000.
Min-imally Supervised Morphological Analysis by Multi-modal Alignment.
In Proceedings of the Associationfor Computational Linguistics.Re?mi Zajac.
2001.
Morpholog: Constrained and Super-vised Learning of Morphology.
In Proceedings of theConference on Natural Language Learning.Torsten Zesch, Christof Mu?ller, and Iryna Gurevych.2008.
Extracting Lexical Semantic Knowledge fromWikipedia and Wiktionary.
In Proceedings of Lan-guage Resources and Evaluation.1195
