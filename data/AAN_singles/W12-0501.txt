Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data (Hybrid2012), EACL 2012, pages 1?9,Avignon, France, April 23 2012. c?2012 Association for Computational LinguisticsExperiments on Hybrid Corpus-Based Sentiment Lexicon AcquisitionGoran Glavas?, Jan S?najder and Bojana Dalbelo Bas?ic?Faculty of Electrical Engineering and ComputingUniversity of ZagrebZagreb, Croatia{goran.glavas, jan.snajder, bojana.dalbelo}@fer.hrAbstractNumerous sentiment analysis applicationsmake usage of a sentiment lexicon.
Inthis paper we present experiments on hy-brid sentiment lexicon acquisition.
The ap-proach is corpus-based and thus suitablefor languages lacking general dictionary-based resources.
The approach is a hy-brid two-step process that combines semi-supervised graph-based algorithms and su-pervised models.
We evaluate the perfor-mance on three tasks that capture differ-ent aspects of a sentiment lexicon: polar-ity ranking task, polarity regression task,and sentiment classification task.
Exten-sive evaluation shows that the results arecomparable to those of a well-known senti-ment lexicon SentiWordNet on the polarityranking task.
On the sentiment classifica-tion task, the results are also comparable toSentiWordNet when restricted to monosen-timous (all senses carry the same senti-ment) words.
This is satisfactory, given theabsence of explicit semantic relations be-tween words in the corpus.1 IntroductionKnowing someone?s attitude towards events, en-tities, and phenomena can be very important invarious areas of human activity.
Sentiment anal-ysis is an area of computational linguistics thataims to recognize the subjectivity and attitude ex-pressed in natural language texts.
Applicationsof sentiment analysis are numerous, includingsentiment-based document classification (Riloffet al, 2006), opinion-oriented information extrac-tion (Hu and Liu, 2004), and question answering(Somasundaran et al, 2007).Sentiment analysis combines subjectivity anal-ysis and polarity analysis.
Subjectivity analy-sis answers whether the text unit is subjectiveor neutral, while polarity analysis determineswhether a subjective text unit is positive or nega-tive.
The majority of research approaches (Hatzi-vassiloglou and McKeown, 1997; Turney andLittman, 2003; Wilson et al, 2009) see subjec-tivity and polarity as categorical terms (i.e., clas-sification problems).
Intuitively, not all words ex-press the sentiment with the same intensity.
Ac-cordingly, there has been some research effort inassessing subjectivity and polarity as graded val-ues (Baccianella et al, 2010; Andreevskaia andBergler, 2006).
Most of the work on sentence ordocument level sentiment makes usage of senti-ment annotated lexicon providing subjectivity andpolarity information for individual words (Wilsonet al, 2009; Taboada et al, 2011).In this paper we present a hybrid approachfor automated acquisition of sentiment lexicon.The method is language independent and corpus-based and therefore suitable for languages lack-ing general lexical resources such as WordNet(Fellbaum, 2010).
The two-step hybrid pro-cess combines semi-supervised graph-based algo-rithms and supervised learning models.We consider three different tasks, each captur-ing different aspect of a sentiment lexicon:1.
Polarity ranking task ?
determine the relativerankings of words, i.e., order lexicon itemsdescendingly by positivity and negativity;2.
Polarity regression task ?
assign each wordabsolute scores (between 0 and 1) for posi-tivity and negativity;3.
Sentiment classification task ?
classify each1word into one of the three sentiment classes(positive, negative, or neutral).Accordingly, we evaluate our method using threedifferent measures ?
one to evaluate the qualityof the ordering by positivity and negativity, otherto evaluate the absolute sentiment scores assignedto each corpus word, and another to evaluate theclassification performance.The rest of the paper is structured as follows.In Section 2 we present the related work on senti-ment lexicon acquisition.
Section 3 discusses thesemi-supervised step of the hybrid approach.
InSection 4 we explain the supervised step in moredetail.
In Section 5 the experimental setup, theevaluation procedure, and the results of the ap-proach are discussed.
Section 6 concludes the pa-per and outlines future work.2 Related WorkSeveral approaches have been proposed for deter-mining the prior polarity of words.
Most of theapproaches can be classified as either dictionary-based (Kamps et al, 2004; Esuli and Sebastiani,2007; Baccianella et al, 2010) or corpus-based(Hatzivassiloglou and McKeown, 1997; Turneyand Littman, 2003).
Regardless of the resourceused, most of the approaches focus on bootstrap-ping, starting from a small seed set of manuallylabeled words (Hatzivassiloglou and McKeown,1997; Turney and Littman, 2003; Esuli and Se-bastiani, 2007).
In this paper we also follow thisidea of the semi-supervised bootstrapping as thefirst step of the sentiment lexicon acquisition.Dictionary-based approaches grow the seedsets according to the explicit paradigmatic seman-tic relations (synonymy, antonymy, hyponymy,etc.)
between words in the dictionary.
Kampset al (2004) build a graph of adjectives basedon synonymy relations gathered from WordNet.They determine the polarity of the adjective basedon its shortest path distances from positive andnegative seed adjectives good and bad.
Esuli andSebastiani (2007) first build a graph based on agloss relation (i.e., definiens ?
definiendum rela-tion) from WordNet.
Afterwards they perform avariation of the PageRank algorithm (Page et al,1999) in two runs.
In the first run positive PageR-ank value is assigned to the vertices of the synsetsfrom the positive seed set and zero value to allother vertices.
In the second run the same is donefor the synsets from the negative seed set.
Word?spolarity is then decided based on the differencebetween its PageRank values of the two runs.
Wealso believe that graph is the appropriate struc-ture for the propagation of sentiment properties ofwords.
Unfortunately, for many languages a pre-compiled lexical resource like WordNet does notexist.
In such a case, semantic relations betweenwords may be extracted from corpus.In their pioneering work, Hatzivassiloglou andMcKeown (1997) attempt to determine the po-larity of adjectives based on their co-occurrencesin conjunctions.
They start with a small manu-ally labeled seed set and build on the observa-tion that adjectives of the same polarity are oftenconjoined with the conjunction and, while adjec-tives of the opposite polarity are conjoined withthe conjunction but.
Turney and Littman (2003)use pointwise mutual information (PMI) (Churchand Hanks, 1990) and latent semantic analysis(LSA) (Dumais, 2004) to determine the similarityof the word of unknown polarity with the wordsin both positive and negative seed sets.
The afore-mentioned work presumes that there is a corre-lation between lexical semantics and sentiment.We base our work on the same assumption, butinstead of directly comparing the words with theseed sets, we use distributional semantics to builda word similarity graph.
In contrast to the ap-proaches above, this allows us to potentially ac-count for similarities between all pairs of wordsfrom corpus.
To the best of our knowledge, suchan approach that combines corpus-based lexicalsemantics with graph-based propagation has notyet been applied to the task of building senti-ment lexicon.
However, similar approaches havebeen proven rather efficient on other tasks suchas document level sentiment classification (Gold-berg and Zhu, 2006) and word sense disambigua-tion (Agirre et al, 2006).3 Semi-supervised Graph-basedMethodsThe structure of a graph in general provides agood framework for propagation of object proper-ties, which, in our case, are the sentiment valuesof the words.
In a word similarity graph, weightsof edges represent the degree of semantic similar-ity between words.In the work presented in this paper we buildgraphs from corpus, using different notions of2word similarity.
Each vertex in the graph repre-sents a word from corpus.
Weights of the edgesare calculated in several different ways, usingmeasures of word co-occurrence (co-occurrencefrequency and pointwise mutual information) anddistributional semantic models (latent semanticanalysis and random indexing).
We manuallycompiled positive and negative seed sets, eachconsisting of 15 words:positiveSeeds = {good, best, excel-lent, happy, well, new, great, nice,smart, beautiful, smile, win, hope, love,friend}negativeSeeds = {bad, worst, violence,die, poor, terrible, death, war, enemy,accident, murder, lose, wrong, attack,loss}In addition to these, we compiled the third seedset consisting of neutral words to serve as sen-timent sinks for the employed label propagationalgorithm:neutralSeeds = {time, place, company,work, city, house, man, world, woman,country, building, number, system, ob-ject, room}Once we have built the graph, we label the ver-tices belonging to the words from the polar seedset with the sentiment score of 1.
All other ver-tices are initially unlabeled (i.e., assigned a sen-timent score of 0).
We then use the structure ofthe graph and one of the two random-walk algo-rithms to propagate the labels from the labeledseed set vertices to the unlabeled ones.
The ran-dom walk algorithm is executed twice: once withthe words from the positive seed set being ini-tially labeled and once with the words from thenegative seed set being initially labeled.
Once therandom walk algorithm converges, all unlabeledvertices will be assigned a sentiment label.
How-ever, the final sentiment values obtained after theconvergence of the random-walk algorithm are di-rectly dependent on the size of the graph (which,in turn, depends on the size of the corpus), thesize of the seed set, and the choice of the seed setwords.
Thus, they should be interpreted as rela-tive rather than absolute sentiment scores.
Nev-ertheless, the scores obtained from the graph canbe used to rank the words by their positivity andnegativity.3.1 Similarity Based on CorpusCo-occurrenceIf the two words co-occur in the corpus within awindow of a given size, an edge in the graph be-tween their corresponding vertices is added.
Theweight of the edge should represent the measureof the degree to which the two words co-occur.There are many word collocation measures thatmay be used to calculate the weights of edges(Evert, 2008).
In this work, we use raw co-occurrence frequency and pointwise mutual in-formation (PMI) (Church and Hanks, 1990).
Inthe former case the edge between two words isassigned a weight indicating a total number ofco-occurrences of the corresponding words in thecorpus within the window of a given size.
In thelatter case, we use PMI to account for the indi-vidual frequencies of each of the two words alongwith their co-occurrence frequency.
The most fre-quent corpus words tend to frequently co-occurwith most other words in the corpus, includingwords from both positive and negative seed sets.PMI compensates for this shortcoming of the rawco-occurrence frequency measure.3.2 Similarity Based on Latent SemanticAnalysisLatent semantic analysis is a well-known tech-nique for identifying semantically related con-cepts and dimensionality reduction in large vectorspaces (Dumais, 2004).
The first step is to cre-ate a sparse word-document matrix.
Matrix ele-ments are frequencies of words occurring in docu-ments, usually transformed using some weightingscheme (e.g., tf-idf ).
The word-document matrixis then decomposed using singular value decom-position (SVD), a well-known linear algebra pro-cedure.
Finally, the dimensionality reduction isperformed by approximating the original matrixusing only the top k largest singular values.We build two different word-document matri-ces using different weighting schemes.
The el-ements of the first matrix were calculated usingthe tf-idf weighting scheme, while for the sec-ond matrix the log-entropy weighting scheme wasused.
In the log-entropy scheme, each matrix ele-ment, mw,d, is calculated using logarithmic valueof word-document frequency and the global wordentropy (entropy of word frequency across thedocuments), as follows:3mw,d = log (tfw ,d + 1 ) ?
ge(w)withge(w) = 1 +1log n?d?
?Dtfw ,d ?gf wlogtfw ,d ?gf wwhere tfw ,d represents occurrence frequency ofword w in document d, parameter gf w representsglobal frequency of word w in corpus D, and nis the number of documents in corpus D. Next,we decompose each of the two matrices usingSVD in order to obtain a vector for each wordin the vector space of reduced dimensionality k(k  n).
LSA vectors tend to express semanticproperties of words.
Moreover, the similarity be-tween the LSA vectors may be used as a measureof semantic similarity between the correspondingwords.
We compute this similarity using the co-sine between the LSA vectors and use the ob-tained values as weights of graph edges.
Becauserunning random-walk algorithms on a completegraph would be computationally intractable, wedecided to reduce the number of edges by thresh-olding the similarity values.3.3 Similarity Based on Random IndexingRandom Indexing (RI) is another word space ap-proach, which presents an efficient and scalablealternative to more commonly used word spacemethods such as LSA.
Random indexing is a di-mensionality reduction technique in which a ran-dom matrix is used to project the original word-context matrix into the vector space of lower di-mensionality.
Each context is represented by itsindex vector, a sparse vector with a small numberof randomly distributed +1 and ?1 values, theremaining values being 0 (Sahlgren, 2006).
Foreach corpus word its context vector is constructedby summing index vectors of all context elementsoccurring within contexts of all of its occurrencesin the corpus.
The semantic similarity of the twowords is then expressed as the similarity betweenits context vectors.We use two different definitions for the contextand context relation.
In the first case (referred toas RI with document context), each corpus docu-ment is considered as a separate context and theword is considered to be in a context relation ifit occurs in the document.
The context vector ofeach word is then simply the sum of random in-dex vectors of the documents in which the wordoccurs.
In the second case (referred to as RI withwindow context), each corpus word is consideredas a context itself, and the two words are consid-ered to be in a context relation if they co-occur inthe corpus within the window of a given size.
Thecontext vector of each corpus word is then com-puted as the sum of random index vectors of allwords with which it co-occurs in the corpus in-side the window of a given size.
Like in the LSAapproach, we use the cosine of the angle betweenthe context vectors as a measure of semantic simi-larity between the word pairs.
To reduce the num-ber of edges, we again perform the thresholdingof the similarity values.3.4 Random-Walk AlgorithmsOnce the graph building phase is done, we startpropagating the sentiment scores from the verticesof the seed set words to the unlabeled vertices.To this end, one can use several semi-supervisedlearning algorithms.
The most commonly usedalgorithm for dictionary-based sentiment lexiconacquisition is PageRank.
Along with the PageR-ank we employ another random-walk algorithmcalled harmonic function learning.PageRankPageRank (Page et al, 1999) was initially de-signed for ranking web pages by their relevance.The intuition behind PageRank is that a vertexv should have a high score if it has many high-scoring neighbours and these neighbours do nothave many other neighbours except the vertexv.
Let W be the weighted row-normalized ad-jacency matrix of graph G. The algorithm itera-tively computes the vector of vertex scores a inthe following way:a(k) = ?a(k?1)W + (1?
?)ewhere?
is the PageRank damping factor.
Vector emodels the normalized internal source of score forall vertices and its elements sum up to 1.
We as-sign the value of ei to be 1|SeedSet | for the verticeswhose corresponding words belong to the seed setand ei = 0 for all other vertices.Harmonic FunctionThe second graph-based semi-supervisedlearning algorithm we use is the harmonic func-4tion label propagation (also known as absorbingrandom walk) (Zhu and Goldberg, 2009).
Har-monic function tries to propagate labels betweensources and sinks of sentiment.
We perform tworuns of the algorithm: one for positive sentiment,in which we use the words from the positive seedset as sentiment sources, and one for the negativesentiment, in which we use the words from thenegative seed set as sentiment sources.
In bothcases, we use the precompiled seed set of neutralwords as sentiment sinks.
Note that we couldnot have used positive seed set words as sourcesand negative seed set words as sinks (or viceversa) because we aim to predict the positive andnegative sentiment scores separately.The value of the harmonic function for a la-beled vertex remains the same as initially labeled,whereas for an unlabeled vertex the value is com-puted as the weighted average of its neighbours?values (Zhu and Goldberg, 2009):f(vk) =?j?|V |wkj ?
f(vj)?j?|V |wkjwhere V is the set of vertices of graph G andwkj is the weight of the edge between the ver-tices vk and vj .
If there is no graph edge be-tween vertices vk and vj , the value of the weightwkj is 0.
This equation also represents the updaterule for the iterative computation of the harmonicfunction.
However, it can be shown that there isa closed-form solution of the harmonic function.Let W be the unnormalized weighted adjacencymatrix of the graph G, and let D be the diagonalmatrix with the element Dii =?j?|V |wij be-ing the weighted degree of the vertex vi.
Thenthe unnormalized graph Laplacian is defined withL = D ?W .
Assuming that the labeled seed setvertices are ordered before the unlabeled ones, thegraph Laplacian can be partitioned in the follow-ing way:L =(Lll LluLul Luu)The closed form solution for the harmonicfunction of the unlabeled vertices is then given by:fu = ?L?1uuLulylwhere yl if the vector of labels of the seed set ver-tices (Zhu and Goldberg, 2009).4 Supervised Step HybridizationThe sentiment scores obtained by the semi-supervised graph-based approaches describedabove are relative because they depend on thegraph size as well as on the size and content ofthe seed sets.
As such, these values can be used torank the words by positivity or negativity, but notas absolute positivity and negativity scores.
Thus,in the second step of our hybrid approach, we usesupervised learning to obtain the absolute senti-ment scores (polarity regression task) and the sen-timent labels (sentiment classification task).Each score obtained on each graph representsa single feature for supervised learning.
Thereare altogether 24 different semi-supervised fea-tures used as input for the supervised learners.These features are both positive and negative la-bels generated from six different semi-supervisedgraphs (co-occurence frequency, co-occurrencePMI, LSA log-entropy, LSA tf-idf, random in-dexing with document context, and random in-dexing with window context) using two differentrandom-walk algorithms (harmonic function andPageRank).
We used the occurrence frequency ofwords in corpus as an additional feature.For polarity regression, learning must be per-formed twice: once for the negative and once forthe positive sentiment score.
We performed theregression using SVM with radial-basis kernel.The same set of features used for regression wasused for sentiment classification, but the goal wasto predict the class of the word (positive, negative,or neutral) instead of separate positivity or nega-tivity scores.
SVM with radial-basis kernel wasused to perform classification learning as well.5 Evaluation and ResultsAll the experiments were performed on the ex-cerpt of the New York Times corpus (years 2002?2007), containing 434,494 articles.
The corpuswas preprocessed (tokenized, lemmatized, andPOS tagged) and only the content lemmas (nouns,verbs, adjectives, and adverbs) occurring at least80 times in the corpus were considered.
Lemmasoccurring less than 80 were mainly named entitiesor their derivatives.
The final sentiment lexiconconsists of 41,359 lemmas annotated with posi-tivity and negativity scores and sentiment class.11Sentiment lexicon is freely available athttp://takelab.fer.hr/sentilex55.1 Sentiment AnnotationsTo evaluate our methods on the three tasks, wecompare the results against the Micro-WN(Op)dataset (Cerini et al, 2007).
Micro-WN(Op) con-tains sentiment annotations for 1105 WordNet 2.0synsets.
Each synset s is manually annotated withthe degree of positivity Pos(s) and negativityNeg(s), where 0 ?
Pos(s) ?
1, 0 ?
Neg(s) ?1, and Pos(s) +Neg(s) ?
1.
Objectivity score isdefined as Obj (s) = 1?
(Pos(s) + Neg(s)).This gives us a list of 2800 word-sense pairswith their sentiment annotations.
For reasons thatwe explain below, we retain from this list onlythose words for which all senses from WordNethave been sentiment-annotated, which leaves uswith a list of 1645 word-sense pairs.
From thislist we then filter out all words that occur lessthan 80 times in our corpus, leaving us with a listof 1125 word-sense pairs (365 distinct words, ofwhich 152 are monosemous).
We refer to this setof 1125 sentiment-annotated word-sense pairs asMicro-WN(Op)-0.Because our corpus-based methods are unableto discriminate among various senses of a pol-ysemous word, we wish to be able to eliminatethe negative effect of polysemy in our evalua-tion.
The motivation for this is twofold: first, itgives us a way of measuring how much polysemyinfluences our results.
Secondly, it provides uswith the answer how well our method could per-form in an ideal case where all the words fromcorpus have been pre-disambiguated.
Becauseeach of the words in Micro-WN(Op)-0 has all itssenses sentiment-annotated, we can determine foreach of these words how sentiment depends on itssense.
Expectedly, there are words whose senti-ment differs radically across its senses or parts-of-speech (e.g., catch, nest, shark, or hot), butalso words whose sentiment is constant or simi-lar across all its senses.
To eliminate the effectof polysemy on sentiment prediction, we furtherfilter the Micro-WN(Op)-0 list by retaining onlythe words whose sentiment is constant or nearlyconstant across all their senses.
We refer to suchwords as monosentimous.
We consider a wordto be monosentimous iff (1) pairwise differencesbetween all sentiment scores across senses areless than 0.25 (separately for both positive andnegative sentiment) and (2) the sign of the dif-ference between positive and negative sentimentscore is constant across all senses.
Note that ev-ery monosemous word is by definition monosen-timous.
Out of 365 words in Micro-WN(Op)-0, 225 of them are monosentimous.
To obtainthe sentiment scores of monosentimous words,we simply average the scores across their senses.We refer to the so-obtained set of 225 sentiment-annotated words as Micro-WN(Op)-1.5.2 Semi-supervised Step EvaluationThe semi-supervised step was designed to prop-agate sentiment properties of the labeled words,ordering the words according to their positivityor negativity.
Therefore, we decided to use theevaluation metric that measures the quality ofthe ranking in ordered lists, Kendall ?
distance.The performance of the semi-supervised graph-based methods was evaluated both on the Micro-WN(Op)-1 and Micro-WN(Op)-0 sets.In order to be able to compare our results toSentiWordNet (Baccianella et al, 2010), the defacto standard sentiment lexicon for English, weuse the p-normalized Kendall ?
distance betweenthe rankings generated by our semi-supervisedgraph-based methods and the gold standard rank-ings.
The p-normalized Kendall ?
distance (Faginet al, 2004) is a version of the standard Kendall ?distance that accounts for ties in the ordering:?
=nd + p ?
ntZwhere nd is the number of pairs in disagreement(i.e., pairs of words ordered one way in the goldstandard and the opposite way in the ranking un-der evaluation), nt is the number of pairs whichare ordered in the gold standard and tied in theranking under evaluation, p is the penalizationfactor to be assigned to each of the nt pairs (usu-ally set to p = 12 ), and Z is the number of pairs ofwords that are ordered in the gold standard.
Table1 presents the results for each of the methods usedto build the sentiment graph and for both random-walk algorithms.
The results were obtained byevaluating the relative rankings of words againstthe Micro-WN(Op)-1 as gold standard.
For com-parison, the p-normalized Kendall ?
scores forSentiWordNet 1.0 and SentiWordNet 3.0 are ex-tracted from (Baccianella et al, 2010).Rankings for the negative scores are consis-tently better across all methods and algorithms.We believe that the negative rankings are better6Table 1: The results on the polarity ranking taskHarmonic function PageRankPositive Negative Positive NegativeCo-occurrence freq.
0.395 0.298 0.540 0.544LSA log-entropy 0.425 0.308 0.434 0.370LSA tf-idf 0.396 0.320 0.417 0.424Co-occurrence PMI 0.321 0.256 0.550 0.576Random indexing document context 0.402 0.433 0.534 0.557Random indexing window context 0.455 0.398 0.491 0.436Positive NegativeSentiWordNet 1.0 0.349 0.296SentiWordNet 3.0 0.281 0.231for two reasons.
Firstly, the corpus contains manymore articles describing negative events such aswars and accidents than the articles describingpositive events such as celebrations and victo-ries.
In short, the distribution of articles is signif-icantly skewed towards ?negative?
events.
Sec-ondly, the lemma new, which was included inthe positive seed set, occurs in the corpus veryfrequently as a part of named entity collocationssuch as ?New York?
and ?New Jersey?
in whichit does not reflect its dominant sense.
The har-monic function label propagation generally out-performs the PageRank algorithm.
The best per-formance on the Micro-WN(Op)-0 set was 0.380for the positive ranking and 0.270 for the nega-tive ranking, showing that the performance de-teriorates when polysemy is present.
However,the drop in performance, especially for the neg-ative ranking, is not substantial.
Our best method(graph built based on PMI of corpus words used incombination with harmonic function label prop-agation) outperforms SentiWordNet 1.0 and per-forms slightly worse than SentiWordNet 3.0 forboth positive and negative rankings.5.3 Evaluation of the Supervised StepSupervised step deals with the polarity regressiontask and the sentiment classification task.
Polarityregression maps the ?virtual?
sentiment scores ob-tained on graphs to the absolute sentiment scores(on a scale from 0 to 1).
The regression was per-formed twice: once for the positive scores andonce for the negative scores.
We evaluate theperformance of the polarity regression against theMicro-WN(Op)-0 gold standard in terms of rootmean square error (RMSE).
We used the aver-age of the labeled polarity scores (positive andnegative) of all monosentimous words in Micro-WN(Op)-1 as a baseline for this task.Sentiment classification uses the scores ob-tained on graphs as features in order to assigneach word with one of the three sentiment la-bels (positive, negative, and neutral).
The clas-sification performance is evaluated in terms ofmicro-F1 measure.
The labels for the classifica-tion are assigned according to the positivity andnegativity scores (the label neutral is assigned ifObj (s) = 1?Pos(s)?Neg(s) is larger than bothPos(s) and Neg(s)).
The majority class predictorwas used as a baseline for the classification task.Due to the small size of the labeled sets (e.g.,225 for Micro-WN(Op)-1) we performed the 10?
10 CV evaluation (10 cross-validation trials,each on randomly permuted data) (Bouckaert,2003) both for regression and classification.
Forcomparison, we evaluated the SentiWordNet inthe same way ?
we averaged the SentiWordNetscores for all the senses of monosentimous wordsfrom the Micro-WN(Op)-1.Although the semi-supervised step itself wasnot designed to deal with polarity regression taskand sentiment classification task, we decided toevaluate the results gained from graphs on thesetasks as well.
This gives us an insight to howmuch the supervised step adds in terms of perfor-mance.
The positivity and negativity scores ob-tained from graphs were directly evaluated on theregression task measuring the RMSE against thegold standard.
Classification labels were deter-7mined by comparing the positive rank of the wordagainst the negative rank of the word.
The wordwas classified as neutral if the absolute differencebetween its positive and negative rank was belowthe given treshold t. Empirically determined opti-mal value of the treshold was t = 1000.Table 2 we present the results of the hybridmethod on both the regression (for both positiveand negative scores) and classification tasks com-pared with the performance of the SentiWordNetand the baselines.
Additionally, we present theresults obtained using only the semi-supervisedstep.
On both the regression and classificationtask our method outperforms the baseline.
Theperformance is comparable to SentiWordNet onthe sentiment classification task.
However, theperformance of our corpus-based approach is sig-nificantly lower than SentiWordNet on the polar-ity regression task ?
a more detailed analysis isrequired to determine the cause of this.
The hy-brid approach performs significantly better thanthe semi-supervised method alone, confirming theimportance of the supervised step.Models trained on the Micro-WN(Op)-1 wereapplied on the set of words from the Micro-WN(Op)-0 not present in the Micro-WN(Op)-1(i.e., the difference between the two sets) in orderto test the performance on non-monosentimouswords.
The obtained results on this set are, sur-prisingly, slightly better (positivity regression ?0.337; negativity regression ?
0.313; and classi-fication ?
57.55%).
This is most likely due to thefact that, although not all senses have the samesentiment, most of them have similar sentiment,which is often also the sentiment of the dominantsense in the corpus.6 ConclusionWe have described a hybrid approach to sentimentlexicon acquisition from corpus.
On one hand, theapproach combines corpus-based lexical seman-tics with graph-based label propagation, while onthe other hand it combines semi-supervised andsupervised learning.
We have evaluated the per-formance on three sentiment prediction tasks: po-larity ranking task, polarity regression task, andsentiment classification task.
Our experimentssuggest that the results on the polarity rankingtask are comparable to SentiWordNet.
On thesentiment classification task, the results are alsocomparable to SentiWordNet when restricted tomonosentimous words.
On the polarity regressiontask, our results are worse than SentiWordNet, al-though still above the baseline.Unlike with the WordNet-based approaches, inwhich sentiment is predicted based on sentiment-preserving semantic relations between synsets,the corpus-based approach operates at the levelof words and thus suffers from two major limi-tations.
Firstly, the semantic relations extractedfrom corpus are inherently unstructured, vague,and ?
besides paradigmatic relations ?
also in-clude syntagmatic and very loose topical rela-tions.
Thus, sentiment labels propagate in a lesscontrolled manner and get influenced more easilyby the context.
For example, words ?understand-able?
and ?justifiable?
get labeled as predomi-nately negative, because they usually occur innegative contexts.
Secondly, in the approach wedescribed, polysemy is not accounted for, whichintroduces sentiment prediction errors for wordsthat are not monosentimous.
It remains to beseen whether this could be remedied by employ-ing WSD prior to sentiment lexicon acquisition.For future work we intend to investigate howsyntax-based information can be used to intro-duce more semantic structure into the graph.We will experiment with other hybridization ap-proaches that combine semantic links from Word-Net with corpus-derived semantic relations.AcknowledgmentsWe thank the anonymous reviewers for theiruseful comments.
This work has been sup-ported by the Ministry of Science, Education andSports, Republic of Croatia under the Grant 036-1300646-1986.ReferencesE.
Agirre, D.
Mart?
?nez, O.L.
de Lacalle, and A. Soroa.2006.
Two graph-based algorithms for state-of-the-art wsd.
In Proc.
of the 2006 Conference on Em-pirical Methods in Natural Language Processing,pages 585?593.
Association for Computational Lin-guistics.A.
Andreevskaia and S. Bergler.
2006.
Mining word-net for fuzzy sentiment: Sentiment tag extractionfrom wordnet glosses.
In Proc.
of EACL, volume 6,pages 209?216.S.
Baccianella, A. Esuli, and F. Sebastiani.
2010.Sentiwordnet 3.0: An enhanced lexical resourcefor sentiment analysis and opinion mining.
In8Table 2: The performance on the polarity regression task and sentiment classification taskRegression (RMSE) Classification (micro-F1)Positivity NegativityHybrid approach 0.363 ?
0.005 0.387 ?
0.003 0.548 ?
0.126Baseline 0.383 0.413 0.427Semi-supervised 0.443 0.466 0.484SentiWordNet 0.284 0.294 0.582Proc.
of the Seventh International Conference onLanguage Resources and Evaluation (LREC?10),Valletta, Malta.
European Language Resources As-sociation (ELRA).R.R.
Bouckaert.
2003.
Choosing between twolearning algorithms based on calibrated tests.In Machine learning-International workshop thenconference-, volume 20, pages 51?58.S.
Cerini, V. Compagnoni, A. Demontis, M. For-mentelli, and G. Gandini.
2007.
Micro-WNOp:A gold standard for the evaluation of automati-cally compiled lexical resources for opinion mining.Language resources and linguistic theory: Typol-ogy, second language acquisition, English linguis-tics, pages 200?210.K.W.
Church and P. Hanks.
1990.
Word associa-tion norms, mutual information, and lexicography.Computational linguistics, 16(1):22?29.S.T.
Dumais.
2004.
Latent semantic analysis.
An-nual Review of Information Science and Technol-ogy, 38(1):188?230.A.
Esuli and F. Sebastiani.
2007.
Pageranking word-net synsets: An application to opinion mining.
InAnnual meeting-association for computational lin-guistics, volume 45, pages 424?431.S.
Evert.
2008.
Corpora and collocations.
Cor-pus Linguistics.
An International Handbook, pages1212?1248.R.
Fagin, R. Kumar, M. Mahdian, D. Sivakumar, andE.
Vee.
2004.
Comparing and aggregating rank-ings with ties.
In Proc.
of the twenty-third ACMSIGMOD-SIGACT-SIGART symposium on Princi-ples of database systems, pages 47?58.
ACM.C.
Fellbaum.
2010.
Wordnet.
Theory and Applica-tions of Ontology: Computer Applications, pages231?243.A.B.
Goldberg and X. Zhu.
2006.
Seeing starswhen there aren?t many stars: graph-based semi-supervised learning for sentiment categorization.
InProc.
of the First Workshop on Graph Based Meth-ods for Natural Language Processing, pages 45?52.Association for Computational Linguistics.V.
Hatzivassiloglou and K.R.
McKeown.
1997.
Pre-dicting the semantic orientation of adjectives.
InProc.
of the eighth conference on European chap-ter of the Association for Computational Linguis-tics, pages 174?181.
Association for ComputationalLinguistics.M.
Hu and B. Liu.
2004.
Mining opinion features incustomer reviews.
In Proc.
of the National Confer-ence on Artificial Intelligence, pages 755?760.J.
Kamps, MJ Marx, R.J. Mokken, and M. De Rijke.2004.
Using WordNet to measure semantic orienta-tions of adjectives.L.
Page, S. Brin, R. Motwani, and T. Winograd.
1999.The PageRank citation ranking: Bringing order tothe web.E.
Riloff, S. Patwardhan, and J. Wiebe.
2006.
Featuresubsumption for opinion analysis.
In Proc.
of the2006 Conference on Empirical Methods in NaturalLanguage Processing, pages 440?448.
Associationfor Computational Linguistics.M.
Sahlgren.
2006.
The Word-Space Model: Us-ing Distributional Analysis to Represent Syntag-matic and Paradigmatic Relations between Wordsin High-Dimensional Vector Spaces.
Ph.D. thesis,Stockholm University, Stockholm, Sweden.S.
Somasundaran, T. Wilson, J. Wiebe, and V. Stoy-anov.
2007.
Qa with attitude: Exploiting opiniontype analysis for improving question answering inon-line discussions and the news.
In Proc.
of the In-ternational Conference on Weblogs and Social Me-dia (ICWSM).
Citeseer.M.
Taboada, J. Brooke, M. Tofiloski, K. Voll, andM.
Stede.
2011.
Lexicon-based methods for sen-timent analysis.
Computational Linguistics, (EarlyAccess):1?41.P.
Turney and M.L.
Littman.
2003.
Measuring praiseand criticism: Inference of semantic orientationfrom association.
In ACM Transactions on Infor-mation Systems (TOIS).T.
Wilson, J. Wiebe, and P. Hoffmann.
2009.
Rec-ognizing contextual polarity: an exploration of fea-tures for phrase-level sentiment analysis.
Computa-tional Linguistics, 35(3):399?433.X.
Zhu and A.B.
Goldberg.
2009.
Introduction tosemi-supervised learning.
Synthesis lectures on ar-tificial intelligence and machine learning, 3(1):1?130.9
