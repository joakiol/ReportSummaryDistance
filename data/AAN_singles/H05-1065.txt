Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 515?522, Vancouver, October 2005. c?2005 Association for Computational LinguisticsDisambiguation of Morphological Structure using a PCFGHelmut SchmidInstitute for Natural Language Processing (IMS)University of StuttgartGermanyschmid@ims.uni-stuttgart.deAbstractGerman has a productive morphology andallows the creation of complex wordswhich are often highly ambiguous.
Thispaper reports on the development of ahead-lexicalized PCFG for the disam-biguation of German morphological anal-yses.
The grammar is trained on unla-beled data using the Inside-Outside algo-rithm.
The parser achieves a precisionof more than 68% on difficult test data,which is 23% more than the baseline ob-tained by randomly choosing one of thesimplest analyses.
Remarkable is the factthat precision drops to 52% without lexi-calization.1 IntroductionGerman words may be as complex as the fol-lowing title of a bill: Rindfleischetikettierungs-u?berwachungsaufgabenu?bertragungsgesetz (law forthe transfer of the task of controlling the labelingof beef).
The complexity is due to the productivemorphological processes of derivation (e.g.
Etiket-tierung (labeling) = Etikett (label) + ier (deriva-tional suffix) + ung (nominalization suffix)) andcompounding (e.g.
Rindfleisch (beef) = Rind (cattle)+ Fleisch (meat)).
For many words, there is morethan one possible analysis.
The German SMORmorphology (Schmid et al, 2004) e.g.
generates 24analyses for the word Abteilungen.
If differences inthe case feature are ignored, there are still six analy-ses, all of them plural:?
Abt (abbot) Ei (egg) Lunge (lung) n (plural in-flectional ending)?
Abt (abbot) ei (abbot ?
abbey) Lunge (lung) n(plural inflectional ending)?
Abt (abbot) eil (hurry) ung (nominalization suf-fix) en (plural inflectional ending)?
Abtei (abbey) Lunge (lung) n (plural inflec-tional ending)?
Abteilung (department) en (plural inflectionalending)?
ab (separable verb prefix) teil (divide) ung(nominalization suffix) en (plural inflectionalending)Here ?
and in many other cases, as well ?
the leastcomplex analysis (defined as the number of deriva-tion and compounding steps), namely the plural ofAbteilung (department), is the correct one.
Thisheuristic is not always successful, however.
Theword Reisende e.g.
is analyzed as the compound ofReis (rice) + Ende (end), and alternately as the nom-inalization of the present participle reisend (travel-ing).
The latter one is correct although it requirestwo derivational steps (formation of the participleplus nominalization), while the former requires onlyone compounding step.The least complex analysis is not necessarilyunique.
One reason is, that German word forms areoften ambiguous wrt.
number, gender and case.
Theadjective kleine (small) e.g.
receives 7 analyses bySMOR which differ only in the agreement features.515Another reason is that word forms are ambiguouswrt.
the part of speech.
The word gerecht e.g.
is ei-ther an adjective (fair) or the past participle of theverb rechen (to rake).
Similarly, the word geradeis either an adjective (straight) or an adverb (just).These ambiguities can be resolved based on the con-text e.g.
with a part-of-speech tagger.Other types of ambiguities are not disambiguatedby the syntactic context because the morphosyntac-tic features are invariant.
Compounds with three el-ements like Sonderpreisliste, for instance, are sys-tematically ambiguous between a left-branching (listof special prices) and a right-branching structure(special price-list), but unambiguous regarding theirpart of speech and agreement features.
Some wordforms like Schmerzfreiheit (absence of pain) can ei-ther be analyzed as derivations (schmerzfrei-heit ??painless-ness?)
or as compounds (Schmerz-freiheit?
?pain freedom?).
Again, there is no difference inthe morphosyntactic features.
A further source ofambiguity are the stems: Consider the word Mit-telzuweisung (allocation of resources).
The com-pounding stem mittel could either originate from theadjective mittel (average) or from the noun Mittel(means).
All these ambiguities are not resolvable bythe syntactic context because their syntactic prop-erties are identical.
However, most of these wordshave a preferred reading.
Nah verkehrs zug (com-muter train) e.g.
is likely to have a left-branchingstructure, whereas the correct analysis of Computerbild schirm (computer monitor) is right-branching.Considering these features of German morphol-ogy, the following disambiguation strategy for mor-phological ambiguities is proposed: Frequent wordsshould be manually disambiguated and the cor-rect analysis/analyses should be explicitly stored inthe lexicon.
Ambiguities involving different mor-phosyntactic features should be resolved by a taggeror parser.
The elimination of the remaining ambigui-ties, namely ambiguities of rare words which are notreflected by the morphosyntactic features, requires adifferent method.
A general strategy is to generatethe set of possible analyses, to rank them accord-ing to some criterion and to return the best analysis(or analyses).
One very simple ranking criterion isthe complexity of the analysis e.g.
measured by thenumber of derivational and compounding steps.
Wewill use this criterion as a baseline to which we com-pare our method.Given an FST-based morphological analyzer anda training corpus consisting of manually disam-biguated analyses, it is also possible to estimate tran-sition probabilities for the finite state transducer andto disambiguate by choosing the most probable paththrough the transducer network for a given word.
Adrawback of this approach is the limitation of thetype of analyses that finite state transducers can gen-erate.
A finite state transducer maps a regular lan-guage, the set of word forms, to another regular lan-guage, the set of analyses.
Therefore it is not able toproduce structured analyses as shown in figure 1 (forarbitrary depths).
It also fails to represent non-localdependencies, like the one between Vertrag (con-tract) and Lo?sung (solution) in the second analysisof figure 1.ungaufLosung..NN NV N V Nmiet Vertrag saufVlos..N NNV Nmiet VertragsV SuffPrefFigure 1: Two morphological analyses of the Ger-man word Mietvertragsauflo?sung (leasing contractcancellation); the first one is correct.Given the limitations of weighted finite-statetransducers, we propose to use a more power-ful formalism, namely head-lexicalized probabilis-tic context-free grammars (Carroll and Rooth, 1998;Charniak, 1997) to rank the analyses.
Context-freegrammars have, of course, no difficulties to generatethe analyses shown in figure 1.
By assigning prob-abilities to the grammar rules, we obtain a proba-bilistic context-free grammar (PCFG) which allowsthe parser to distinguish between frequent and raremorphological constructions.
Nouns e.g.
are muchmore likely to be compounds than verbs.
In head-lexicalized PCFGs (HL-PCFGs), the probability ofa rule also depends on the lexical head of the con-stituent.
HL-PCFGs are therefore able to learn thatnouns headed by Problem (problem) are more likelyto be compounds (e.g.
Schulprobleme (school prob-lems)) than nouns headed by Samstag (Saturday).Moreover, HL-PCFGs represent lexical dependen-516cies like that between Vertrag and Lo?sung in fig-ure 1.b b b bb bbbAbtAb unglungeenneieilAbteiAbteilungteilFigure 2: Morpheme latticeIn this paper, we present a HL-PCFG-based dis-ambiguator for German.
Using the SMOR morpho-logical analyzer, the input words are first split intomorpheme sequences and then analyzed with a HL-PCFG parser.
Due to ambiguities, the parser?s inputis actually a lattice rather than a sequence (see theexample in figure 2).The rest of the paper is organized as follows:In section 2, we briefly review head-lexicalizedPCFGs.
Section 3 summarizes some important fea-tures of SMOR.
The development of the grammarwill be described in section 4.
Section 5 explains thetraining strategy, and section 6 reports on the annota-tion of the test data.
Section 7 presents the results ofan evaluation, section 8 comments on related work,and section 9 summarizes the main points of the pa-per.
Finally, section 10 gives an outlook on futurework.2 Head-Lexicalized PCFGsA head-lexicalized parse tree is a parse tree in whicheach constituent is labeled with its category and itslexical head.
The lexical head of a terminal symbolis the symbol itself and the lexical head of a non-terminal symbol is the lexical head of its (unique)head child.In a head-lexicalized PCFG (HL-PCFG) (Carrolland Rooth, 1998; Charniak, 1997), one symbol onthe right-hand side of each rule is marked as thehead.
A HL-PCFG assumes that (i) the probabilityof a rule depends on the category and the lexicalhead of the expanded constituent and (ii) that thelexical head of a non-head node depends on itsown category, and the category and the lexicalhead of the parent node.
The probability of ahead-lexicalized parse tree is therefore:pstart(cat(root)) pstart(head(root)|cat(root))?
?n?N prule(rule(n)|cat(n), head(n))?
?n?A phead(head(n)|cat(n), pcat(n), phead(n))whereroot is the root node of the parse treecat(n) is the syntactic category of node nhead(n) is the lexical head of node nrule(n) is the grammar rule which expands node npcat(n) is the syntactic category of the parent of nphead(n) is the lexical head of the parent of nHL-PCFGs have a large number of parameterswhich need to estimated from training data.
Inorder to avoid sparse data problems, the parametersusually have to be smoothed.
HL-PCFGs can eitherbe trained on labeled data (supervised training) oron unlabeled data (unsupervised training) usingthe Inside-Outside algorithm, an instance of theEM algorithm.
Training on labeled data usuallygives better results, but it requires a treebankwhich is expensive to create.
In our experiments,we used unsupervised training with the LoParparser which is available at http://www.ims.uni-stuttgart.de/projekte/gramotron/SOFTWARE/LoPar-en.html.3 SMORSMOR (Schmid et al, 2004) is a German FST-based morphological analyzer which covers inflec-tion, compounding, and prefix as well as suffixderivation.
It builds on earlier work reported in(Schiller, 1996) and (Schmid et al, 2001).SMOR uses features to represent derivation con-straints.
German derivational suffixes select theirbase in terms of part of speech, the stem type(derivation or compounding stem)1, the origin (na-tive, classical, foreign), and the structure (simplex,compound, prefix derivation, suffix derivation) ofthe stem which they combine with.
This informa-tion is encoded with features.
The German deriva-tion suffix lich e.g.
combines with a simplex deriva-tion stem of a native noun to form an adjective.
Thefeature constraints of lich are therefore (1) part ofspeech = NN (2) stem type = deriv (3) origin = na-tive and (4) structure = simplex.1Suffixes which combine with compounding stems histori-cally evolved from compounding constructions.5174 The GrammarThe grammar used by the morphological disam-biguator has a small set of rather general cate-gories for prefixes (P), suffixes (S), uninflected basestems (B), uninflected base suffixes (SB), inflec-tional endings (F) and other morphemes (W).
Thereis only one rule for compounding and prefix andsuffix derivation, respectively, and two rules for thestem and suffix inflection.
Additional rules intro-duce the start symbol TOP and generate specialword forms like hyphenated (Thomas-Mann-Stra?e)or truncated words (Vor-).
Overall, the base gram-mar has 13 rules.
Inflection is always attached lowin order to avoid spurious ambiguities.
The part ofspeech is encoded as a feature.Like SMOR, the grammar encodes derivationconstraints with features.
Number, gender and caseare not encoded.
Ambiguities in the agreement fea-tures are therefore not reflected in the parses whichthe grammar generates.
This allows us to abstractaway from this type of ambiguity which cannot beresolved without contextual information.
If someapplication requires agreement information, it has tobe reinserted after disambiguation.The feature grammar is compiled into a context-free grammar with 1973 rules.
In order to reducethe grammar size, the features for origin and com-plexity were not compiled out.
Figure 3 shows acompounding rule (building a noun base stem froma noun compounding stem and a noun base stem),a suffix derivation rule (building an adjective basestem from a noun derivation stem and a derivationsuffix), a prefix derivation rule (prefixing a verbalcompounding stem) and two inflection rules (for theinflection of a noun and a nominal derivation suffix,respectively) from the resulting grammar.
The quotesymbol marks the head of a rule.W.NN.base ?
W.NN.compound W.NN.base?W.ADJ.base ?
W.NN.deriv S.NN.deriv.ADJ.baseW.V.compound ?
P.V W.V.compound?W.NN.base ?
B.NN.base?
F.NNS.ADJ.deriv.NN.base ?
SB.ADJ.deriv.NN.base?F.NNFigure 3: Some rules from the context-free grammarThe parser retrieves the categories of the mor-phemes from a lexicon which also contains infor-mation about the standard form of a morpheme.The representation of the morphemes returned bythe FST-based word splitter is close to the surfaceform.
Only capitalization is taken over from thestandard form.
The adjective ursa?chlich (causal), forinstance, is split into Ursa?ch and lich.
The lexiconassigns to Ursa?ch the category W.NN.deriv and thestandard form Ursache (cause).5 PCFG TrainingPCFG training normally requires manually anno-tated training data.
Because a treebank of Ger-man morphological analyses was not available,we decided to try unsupervised training using theInside-Outside algorithm (Lari and Young, 1990).We worked with unlexicalized as well as head-lexicalized PCFGs (Carroll and Rooth, 1998; Char-niak, 1997).
The lexicalized models used the stan-dard form of the morphemes (see the previous sec-tion) as heads.The word list from a German 300 million wordnewspaper corpus was used as training data.
Fromthe 3.2 million tokens in the word list, SMOR suc-cessfully analyzed 2.3 million tokens which wereused in the experiment.
Training was either type-based (with each word form having the same weight)or token-based (with weights proportional to the fre-quency).
We experimented with uniform and non-uniform initial distributions.
In the uniform model,each rule had an initial frequency of 1 from whichthe probabilities were estimated.
In the non-uniformmodel, the frequency of two classes of rules was in-creased to 1000.
The first class are the rules whichexpand the start symbol TOP to an adjective or ad-verb, leading to a preference of these word classesover other word classes, in particular verbs.
Thesecond class is formed by rules generating inflec-tional endings, which induces a preference for sim-pler analyses.6 Test DataThe test data was extracted from a corpus of the Ger-man newspaper Die Zeit which was not part of thetraining corpus.
We prepared two different test cor-pora.
The first test corpus (data1) consisted of 425words extracted from a randomly selected part of the518corpus.
We only extracted words with at least oneletter which were ambiguous (ignoring ambiguitiesin number, gender and case) and either nouns, verbsor adjectives and not from the beginning of a sen-tence.
Duplicates were retained.
The words wereparsed and manually disambiguated.
We looked atthe context of a word, where this was necessary fordisambiguation.
Words without a correct analysiswere deleted.In order to obtain more information on the typesof ambiguity and their frequency, 200 words weremanually classified wrt.
the class of the ambiguity.The following results were obtained:?
39 words (25%) were ambiguous between anadjective and a verb like gerecht - ?just?
(ad-jective) vs. past participle of rechen (to rake).?
28 words (18%) were ambiguous between anoun and a proper name like Mann - ?man?
vs.Thomas Mann?
19 words were ambiguous between an adjectiveand an adverb like gerade - ?straight?
vs.
?just?(adverb)?
14 words (9%) showed a complex ambiguityinvolving derivation and compounding like theword u?berlieferung (tradition) which is eithera nominalization of the prefix verb u?berliefern(to bequeath) or a compound of the stems u?ber(over) and Lieferung (delivery).?
13 words (8%) were compounds which wereambiguous between a left-branching and aright-branching structure like Welt rekord ho?he(world record height)?
In 10 words (5%), there was an ambiguity be-tween an adjective and a proper name or nounstem - as in Ho?chstleistung (maximum perfor-mance) where ho?chst can be derived from theproper name Ho?chst (a German city) or the su-perlative ho?chst (highest)?
6 words (3%) showed a systematic ambigu-ity between an adjective and a noun causedby adding the suffix er to a city name, likeMoskauer - ?Moskau related?
vs. ?person fromMoskau??
Another 6 words were ambiguous between twodifferent noun stems like Halle which is eithersingular form of Halle (hall) or the plural formof Hall (reverberation)Overall 50% of the ambiguities involved a part-of-speech ambiguity.The second set of test data (data2) was designedto contain only infrequent words which were notambiguous wrt.
part of speech.
It was extractedfrom the same newspaper corpus.
Here, we ex-cluded words which were (1) sentence-initial (in or-der to avoid problems with capitalized words) (2)not analyzed by SMOR (3) ambiguous wrt.
part ofspeech (4) from closed word classes or (5) simplexwords.
Furthermore, we extracted only words withmore than one simplest2 analysis, in order to makethe test data more challenging.
The extracted wordswere sorted by frequency and a block of 1000 wordforms was randomly selected from the lower fre-quency range.
All of them had occurred 4 times.
Wefocussed on rare words because frequent words arebetter disambiguated manually and stored in a table(see the discussion in the introduction).The 1000 selected word forms were parsed andmanually disambiguated.
193 problematic wordswere deleted from the evaluation set because either(1) no analysis was correct (e.g.
Elsevier, which wasnot analyzed as a proper name) or (2) there was atrue ambiguity (e.g.
Rottweiler which is either a dogbreed or a person from the city of Rottweil or (3)the lemma was not unique (Drehtu?r (revolving door)could be lemmatized to Drehtu?r or Drehtu?re with nodifference in meaning.)
or (4) several analyses wereequivalent.
The disambiguation was often difficult.Even among the words retained in the test set, therewere many that we were not fully sure about.
Anexample is the compound Natur eis bahn (?naturalice rink?)
which we decided to analyze as Natur-Eisbahn (nature ice-rink) rather than Natureis-Bahn(nature-ice rink).7 ResultsThe parser was trained using the Inside-Outside al-gorithm.
By default, (a) the initialization of the rule2The complexity of an analysis is measured by the numberof derivation and compounding steps.519probabilities was non-uniform as described in sec-tion 5, (b) training was based on tokens (i.e.
thefrequency of the training items was taken into ac-count), and (c) all training iterations were lexical-ized.
Training was quite fast.
One training iterationon 2.3 million word forms took about 10 minutes ona Pentium IV running at 3 GHz.Figure 4 shows the exact match accuracy of theViterbi parses depending on the number of trainingiterations, which ranges from 0 (the initial, untrainedmodel) to 15.
For comparison, a baseline result isshown which was obtained by selecting the set ofsimplest analyses and choosing one of them at ran-dom3.
The baseline accuracy was 45.3%.
The pars-ing accuracy of the default model jumps from a start-ing value of 41.8% for the untrained model (which isbelow the baseline) to 58.5% after a single trainingiteration.
The peak performance is reached after 8iterations with 65.4%.
The average accuracy of themodels obtained after 6-25 iterations is 65.1%.404550556065700 2 4 6 8 10 12 14 16accuracyiterationsdefaulttype-baseduniformunlexicalisedbaselineFigure 4: Exact match accuracy on data2Results obtained with type-based training, whereeach word receives the same weight ignoring itsfrequency, were virtually identical to those of thedefault model.
If the parser training was startedwith a uniform initial model, however, the accu-racy dropped by about 6 percentage points.
Figure 4also shows that the performance of an unlexicalized3In fact, we counted a word with n simplest analyses as 1/ncorrect instead of actually selecting one analysis at random, inorder to avoid a dependency of the baseline result on the randomnumber generation.PCFG is about 13% lower.We also experimented with a combination of un-lexicalized and lexicalized training.
Lexicalizedmodels have a huge number of parameters.
There-fore, there is a large number of locally optimal pa-rameter settings to which the unsupervised trainingcan be attracted.
Purely lexicalized training is likelyto get stuck in a local optimum which is close to thestarting point.
Unlexicalized models, on the otherhand, have fewer parameters, a smaller number oflocal optima and a smoother search space.
Unlex-icalized training is therefore more likely to reach aglobally (near-)optimal point and provides a betterstarting point for the lexicalized training.Figure 5 shows that initial unlexicalized trainingindeed improves the accuracy of the parser.
Withone iteration of unlexicalized training (see ?unlex 1?in figure 5), the accuracy increased by about 3%.The maximum of 68.4% was reached after 4 iter-ations of lexicalized training.
The results obtainedwith 2 iterations of unlexicalized training were verysimilar.
With 3 iterations, the performance droppedalmost to the level of the default model.
It seemsthat some of the general preferences learned duringunlexicalized training are so strong after three itera-tions that they cannot be overruled anymore by thelexeme-specific preferences learned in the lexical-ized training.404550556065700 2 4 6 8 10 12 14 16 18accuracyiterationsdefaultunlex 1unlex 2unlex 3Figure 5: Results on data2 with 0 (default), 1, 2,or 3 iterations of unlexicalized training, followed bylexicalized trainingIn order to assess the parsing results qualitatively,520100 parsing errors of version ?unlex 2?
were ran-domly selected and inspected.
It turned out thatthe parser always preferred right-branching struc-tures over left-branching structures in complex com-pounds with three or more elements, which resultedin 57 errors caused by left-branching structures.Grammars trained without the initial unlexicalizedtraining showed no systematic preference for right-branching structures.
In the test data, left-branchingstructures were two times more frequent than right-branching structures.29 disambiguation errors resulted from selectingthe wrong stem although the structure of the analy-sis was otherwise correct.
In the word Rechtskon-struktion (legal construction), for instance, the firstelement Rechtswas derived from the adjective rechts(right) rather than the noun Recht (law).
Similarly,the adjective quelloffen (open-source) was derivedfrom the verb quellen (to swell) rather than the nounQuelle (source).Six errors involved a combination of compound-ing and suffix derivation (e.g.
the word Flugbe-gleiterin (stewardess)).
The parser preferred theanalysis where the derivation is applied first (Flug-Begleiterin (flight attendant[female])), whereas inthe gold standard analysis, the compound is formedfirst (Flugbegleiter-in (steward-ess).In order to better understand the benefits of unlex-icalized training, we also examined the differencesbetween the best model obtained with one iterationof unlexicalized (unlex1), and the best model ob-tained without unlexicalized training (default).30 cases involved left-branching vs. right-branching compounds.
The unlex1 model showed ahigher preference for right-branching structures thanthe default model, but produced also left-branchingstructures (unlike the model unlex2).
In 15 ofthe 30 cases, unlex1 correctly decided for a right-branching structure; in 13 cases, unlex1 was wrongwith proposing a right-branching structure.
In twocases, unlex1 correctly predicted a left-branchingstructure and the default model predicted a right-branching structure.32 differences were caused by lexical ambigui-ties.
In 24 cases, only one stem was ambiguous.
15times unlex1 was right (e.g.
Moskaureise - Moskowtrip[sg] vs. Moskow rice[pl]) and nine times the de-fault model was right (e.g.
Jodtabletten - iodine pillvs.
iodine tablet).
In 8 cases, two morphemes wereinvolved in the ambiguity.
In all these cases, un-lex1 generated the correct analysis (e.g.
Sportraum -?sport room?
vs. ?Spor[name] dream?
).Nine ambiguities involved the length of verb pre-fixes.
Six times, unlex1 correctly decided for alonger prefix (e.g.
gegenu?ber-stehen (to face) insteadof gegen-u?berstehen (to ?counter-survive?
).5152535455565758590 5 10 15 20 25accuracyiterationsdefaultunlex 1unlex 2Figure 6: Accuracy on data1 after 0, 1, or 2 itera-tions of unlexicalized training followed by lexical-ized trainingIn another experiment, we tested the parser on thefirst test data set (data1) where simplex words, part-of-speech ambiguities, frequent words and repeatedoccurrences were not removed.
The baseline accu-racy on this data was 43.75%.
Figure 6 shows theresults obtained with different numbers of unlexical-ized training iterations analogous to figure 5.
Strictlylexicalized training produced the best results, here.The maximal accuracy was 58.59% which was ob-tained after 7 iterations.
In contrast to the exper-iments on data2, the accuracy decreased by morethan 1.5% when the training was continued.
As saidin the introduction, we think that part-of-speech am-biguities are better resolved by a part-of-speech tag-ger and that frequent words can be disambiguatedmanually.8 Related WorkNew methods are often first developed for Englishand later adapted to other languages.
This might ex-plain why morphological disambiguation has been521so rarely addressed in the past: English morphologyis seldom ambiguous except for noun compounds.We are not aware of any work on the disam-biguation of morphological analyses which is di-rectly comparable to ours.
Mark Lauer (1995) onlyconsidered English noun compounds and applied adifferent disambiguation strategy based on word as-sociation scores.Koehn and Knight (2003) proposed a splittingmethod for German compounds and showed thatit improves statistical machine translation.
Com-pounds are split into smaller pieces (which have tobe words themselves) if the geometric mean of theword frequencies of the pieces is higher than the fre-quency of the compound.
Information from a bilin-gual corpus is used to improve the splitting accuracy.Andreas Eisele (unpublished work) implementeda statistical disambiguator for German based onweighted finite-state transducers as described in theintroduction.
However, his system fails to representand disambiguate the ambiguities observed in com-pounds with three or more elements and similar con-structions with structural ambiguities.9 SummaryWe presented a disambiguation method for Germanmorphological analyses which is based on a head-lexicalized probabilistic context-free grammar.
Thewords are split into morpheme lattices by a finitestate morphology, and then parsed with the prob-abilistic context-free grammar.
The grammar wastrained on unlabeled data using the Inside-Outsidealgorithm and evaluated on 807 manually disam-biguated analyses of infrequent words.
Differenttraining strategies have been compared.
A com-bination of one iteration of unlexicalized trainingand four iterations of lexicalized training returnedthe best results with over 68% exact match accu-racy, compared to a baseline of 45% which was ob-tained by randomly choosing one of the minimallycomplex analyses.
Without lexicalization, the ac-curacy dropped by 15 percentage points, indicatingthat lexicalization is essential for morphological dis-ambiguation.10 Future WorkThere are several starting points for improvement.Guidelines should be developed for the manual an-notation of data in order to make it less dependent onthe annotator?s intuitions.
More data should be an-notated to create a treebank of morphological anal-yses.
Given such a treebank, the parser could betrained on labeled data or on a combination of la-beled and unlabeled data, which presumably wouldfurther increase the parsing accuracy.ReferencesGlenn Carroll and Mats Rooth.
1998.
Valence induc-tion with a head-lexicalized PCFG.
In Proceedings ofthe Third Conference on Empirical Methods in NaturalLanguage Processing, Granada, Spain.Eugene Charniak.
1997.
Statistical parsing with acontext-free grammar and word Statistics.
In Proceed-ings of the 14th National Conference on Artificial In-telligence, Menlo Parc.Philipp Koehn and Kevin Knight.
2003.
Empirical meth-ods for compound splitting.
In Proceedings of the 10thConference of the European Chapter of the Associ-ation for Computational Linguistics, Budapest, Hun-gary.K.
Lari and S. Young.
1990.
The estimation of stochas-tic context-free grammars using the inside-outside al-gorithm.
Computation Speech and Language Process-ing, 4:35?56.Mark Lauer.
1995.
Corpus statistics meet the noun com-pound: Some empirical results.
In Proceedings of the33rd Annual Meeting of the ACL, Massachusetts In-stitute of Technology, pages 47?54, Cambridge, Mass.electronically available at http://xxx.lanl.gov/abs/cmp-lg/9504033.Anne Schiller.
1996.
Deutsche Flexions- und Kom-positionsmorphologie mit PC-KIMMO.
In RolandHausser, editor, Proceedings, 1.
Morpholympics, Er-langen, 7./8.
Mrz 1994, Tu?bingen.
Niemeyer.Tanja Schmid, Anke Ldeling, Bettina Suberlich, UlrichHeid, and Bernd Mbius.
2001.
DeKo: Ein System zurAnalyse komplexer Wrter.
In GLDV - Jahrestagung2001, pages 49?57.Helmut Schmid, Arne Fitschen, and Ulrich Heid.
2004.SMOR: A German computational morphology cover-ing derivation, composition and inflection.
In Pro-ceedings of the 4th International Conference on Lan-guage Resources and Evaluation, volume 4, pages1263?1266, Lisbon, Portugal.522
