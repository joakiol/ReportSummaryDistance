Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182?192,Dublin, Ireland, August 23-24 2014.Syntactic Transfer Patterns of German Particle Verbs and their Impact onLexical SemanticsStefan Bott Sabine Schulte im WaldeInstitut f?ur Maschinelle SprachverabeitungUniversit?at StuttgartPfaffenwaldring 5b, 70569 Stuttgart, Germany{stefan.bott,schulte}@ims.uni-stuttgart.deAbstractGerman particle verbs, like anblicken (togaze at) combine a base verb (blicken)with a particle (an) to form a specialkind of Multi Word Expression.
Parti-cle verbs may share the semantics of thebase verb and the particle to a variable de-gree.
However, while syntactic subcate-gorization frames tend to be good predic-tor for the semantics of verbs in general(verbs that are similar in meaning also tendto have similar subcategorization framesand selectional preferences), there are reg-ular changes in subcategorization framesby particle verbs with regard to the corre-sponding base verbs.
This paper demon-strates that the syntactic behavior of par-ticle verbs and base verbs together (mod-eling regular changes in subcategorizationframes by particle verbs and correspond-ing base verbs) and applying clusteringtechniques allows us to distinguish parti-cle verb meaning and shows the tight con-nection between transfer patterns and thesemantic classes of particle verbs.1 IntroductionIn German, particle verbs (PVs), like anblicken in(1), are a highly productive class.
PVs presentchallenges for a both theoretical analysis and theircomputational treatment.
One of the central prob-lems is the prediction of their meaning from theirconstituent parts: the base verb (BV, e.g.
blickenin (1)) and the particle (e.g.
an).
Many PVs de-rive their meaning from the corresponding BVs ?with a varying degree of transparency.
It is oftenThis work is licensed under a Creative Commons Attribution4.0 International Licence.
Page numbers and proceedingsfooter are added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/not clear, however, how to interpret the semanticsof the particles and their contribution to the mean-ing of the PVs.
Since particles never occur iso-lated, without the context of the verb, it is difficultto assign them a lexical semantic entry on theirown.
Even more, German particles are a notori-ously ambiguous word class.
(1) DasTheKindchildblicktgazesseinehis-accMuttermotheran.PRT.The child looks at his mother.One way to approximate the meaning of parti-cles is to group together the particle verbs whichshare the same particle into semantic groups (suchas anblicken, anstarren, anschauen ?to stare/lookat?
), such that both the meaning of the PV and themeaning of the BV is similar in each group.
Thisallows us to make inferences like ?taking a BVfrom semantic group ?
and particle ?, we will de-rive a PV from semantic group ??.
Such groupscan be established and they represent productiveparadigms.
Springorum et al.
(2013) have shownin a generation experiment setup that subjects areable to associate a meaning to artificially created,previously unattested PVs and to construct exam-ple sentences for them.1Different subjects alsoagree to a large degree on the meaning they at-tribute to the newly formed lexical items.But this approach also rises a series of ques-tions, especially concerning the way in which suchgroups can be distinguished, both from a theoreti-cal and a corpus-based perspective.
For example,which kinds of linguistic features allow us to dis-criminate such semantic classes?
In this paper weinvestigate the influence of syntax, which repre-sents one of the possible feature sources.
Syn-1For example for the neologism anlauschen, referring to apartitive meaning of the particle, senentence like the follow-ing could be found: Er hatte an der Wand angelauscht undwusste Bescheid.
(?He had listened at the wall and kneweverything.?
)182tactic subcategorization frames tend to be goodpredictors for the semantics of verbs in general:verbs that are similar in meaning also tend to havesimilar subcategorization frames and selectionalpreferences (Schulte im Walde, 2000; Merlo andStevenson, 2001; Korhonen et al., 2003; Schulteim Walde, 2006a; Joanis et al., 2008).
But, aswe will show below, PV-BV pairs tend to have aspecial behavior with respect to their subcatego-rization, even if their meanings are closely related.Because we are interested in pairs of PVs and theirBVs, we thus have to look at pairs of subcatego-rization preferences, and rely on the concept ofsyntactic transfer.
We use syntactic transfer asa technical term here, which we define as regularchanges in subcategorization frames by PVs andcorresponding BVs, e.g., the incorporation or ad-dition of complements of PVs in comparison totheir BVs (Stiebels, 1996; L?udeling, 2001; Fleis-cher and Barz, 2012a).
We claim that the syntac-tic behavior of PVs and BVs together allows us todistinguish semantic classes.A better understanding of the nature of the con-nection between syntactic transfer patterns and se-mantic classes may be beneficial for both theoret-ical and computational linguistics.
On the theo-retical side we can hope to find new arguments toguide and justify lexical semantic classifications.We may also shed light on what particles actu-ally mean, a topic which is not trivial by itself.In computational semantics, a better understand-ing of syntactic transfer patterns can potentiallycontribute to a better treatment of PVs in meaning-related areas, such as machine translation and in-formation retrieval.In sum, this paper makes the following contri-butions:?
We show that the meaning of verb particlescan be modeled as classes of pairs of PVs andtheir corresponding BVs, where both PVsand BVs in each class are closely related inmeaning.
In addition, the PV-BV pairs ineach class undergo the same syntactic trans-fers, i.e.
the selectional preferences of PV-BV pairs within each class tend to be verysimilar, even if the subcategorization pref-erences may be different between PVs andBVs.?
We show that automatic clustering can repli-cate a gold standard classification of PV-BVpairs to a large degree when clustering onlyrelies on syntax and the gold standard reflectssemantic regularities.The rest of this paper is organized as follows: Insection 2 we describe the task and our goals.
Herewe also define the term syntactic transfer pattern,which is central to our discussion.
Section 3 isdedicated to related work relevant for our study.In section 4 we describe the experimental setup,while sections 5 and 6 present the experiment re-sults and discuss them.2 Goal and MotivationThe work we describe here centers around the con-cept of semantic classes and syntactic transfer pat-terns.
As concerning the semantic side, the PVswhich share the same particle may be grouped intodifferent classes according to their meaning.
Forexample, among the PVs incorporating the parti-cle an we find a group of verbs whose meaningscenter around the concept of ?to look at some-one/something in manner X?, ?to attach somethingsomewhere in manner X?, ?to make an unpleasantsound towards someone in a manner X?
and ?tostart an action X on something which starts con-suming it?, as exemplified in (2) a-d.(2) a. AAblickt/schaut/starrt/stiert/looks/stares/gazesBBan.PRT.A looks/stares/gazes at B.b.
AAklebt/heftet/schraubt/nageltglues/affixes/screwsBBanat/ontoCCan.PRT.A glues/affixes/screws B onto C.c.
AAbr?ullt/faucht/bellt/meckertroars/hisses/bleatsBBan.PRT.A brawls/hisses/scolds at B.d.
AAschneidet/bricht/rei?tcuts/breaks/tearsBBan.PRT.A cuts/breaks/tears the firstslice/piece of B.Such semantic classes are not easy to define andthey are also difficult to induce automatically.
Al-though there is general agreement in the theo-retical literature that such semantic classes forPVs exist (cf.
Lechler and Ro?deutscher (2009),Kliche (2011) and Springorum (2011)) the agree-ment on the number and nature of such classes isnot very high.
For example, Springorum (2011)(who develops her analysis within Discourse Rep-183resentation Theory (Kamp and Reyle, 1993)) dis-tinguishes between 11 classes of PVs with the par-ticle an, while Fleischer and Barz (2012b) onlydistinguish 3 major de-verbal classes, based ontheir aktionsart, which can be divided into some9 minor classes.2It should be noted that all thePVs and BVs in (2) a-d are not only quite homo-geneous in their semantics; they also form coher-ent syntactic classes.
The PVs and BVs of theseexamples are quite similar in the way they typi-cally select their syntactic complements.
For ex-ample, the BVs of (2-a) typically take a PP argu-ment that expresses the direction of gaze using aprepositional phrases with one of the prepositionsauf, zu, nach or in subcategorizing a dative nounphrase.
The corresponding PVs, however, typi-cally express this semantic role by an accusativeobject.
The type of change from the typical frameof a BV to the typical frame of a PV is an exampleof what we mean by a syntactic transfer pattern.So, while similar syntactic behavior of twoverbs in general may indicate that the verbs arealso semantically similar, this is typically not thecase for PV-BV pairs.
Compare (1) to (3), whichare nearly synonymous but (3) uses the BV blickeninstead of the PV anblicken in (1).
We can only in-duce the similarity of the PV and the BV if we takethe syntactic transfer into consideration.
(3) a. DasTheKindchildblicktlookszuatseinerhis-datMutter.mother.b.
DasTheKindchildstiert/starrt/schautstares/stares/lookszuatseinerhis-datMutter.Mother.Looking at the class to which this PV belongs, allthe variants of (3-b) are semantically very similarto (3-a).
This also corresponds to a syntactic sim-ilarity: all the verbs of this group share the samepreferred syntactic subcategorization frames.
Thedominant frame of theses verbs is ?NPnom+PP-dat?
(the head preposition of the PP may vary, butwithin well-defined limits).
But this is not the casefor the PV anblicken in (1).
(1) is nearly synony-mous to (3-a), but the PV in this example has a to-tally different frame, namely the simple transitive?NPnom+NP-acc?.
It may not come as a surprisethat all of the verbs in (3-b) have PV counterparts(anstieren, anstarren, etc.
), which all behave syn-2The subdivision is, however not fully spelled out andonly implicit in their description.tactically like anblicken.In sum, we part from the hypothesis that thereis a tight connection between transfer patterns andthe semantic classes of PVs.
There is only onemore point to make: the classes shown in (2),could actually be seen as reflecting different mean-ings of the particle an itself.3 Related WorkParticle verbs have been studied from the theo-retical perspective and, to a more limited extend,from the aspect of the computational predictabil-ity of the degree of semantic compositionality (thetransparency of their meaning with respect to themeaning of the base verb and the particle) and thesemantic classifiabilty of PVs.For English, there is work on the automaticextraction of PVs from corpora (Baldwin andVillavicencio, 2002; Baldwin, 2005; Villavicen-cio, 2005) and the determination of composition-ality (McCarthy et al., 2003; Baldwin et al., 2003;Bannard, 2005).To the best of our knowledge Aldinger (2004)is the first work that studies German PVs from acorpus based perspective, with an emphasis on thesyntactic behavior and syntactic change.
Schulteim Walde (2004), Schulte im Walde (2005) andSchulte im Walde (2006b) present preliminary dis-tributional studies to explore salient features at thesyntax-semantics interface that determine the se-mantic nearest neighbours of German PVs.
Re-lying on the insights of those studies, Schulteim Walde (2006b) and Hartmann (2008) describeexperiments which model the subcategorizationtransfer of German PVs with respect to their BVsin order to strengthen PV-BV distributional simi-larity.
The main goal for them is to use transfer in-formation in order to predict the degree of seman-tic compositionality of PVs.
K?uhner and Schulteim Walde (2010) use clustering to determine thedegree of compositionality of German PVs, viacommon PV-BV cluster membership.
They are,again, mainly interested in the assessment of com-positionality, which is done on the basis of lexi-cal information.
They use syntactic information,but only as a filter and for lexical heads as cooc-currence features in order to limit the selected ar-gument slots to certain syntactic functions.
Theyconclude that the best results can be obtained withinformation stemming from direct objects and PP-objects.
The incorporation of syntactic informa-184tion in the form of dependency arc labels (concate-nated with the head nouns) does not yield satisfac-tory results, putting the syntactic transfer problemin evidence, again.
They conclude that an incor-poration of syntactic transfer information betweenBVs and PVs could possibly improve the results.Based on a theoretical study (Springorum,2011), which explains particle meanings in termsof Discourse Representation Theory (Kamp andReyle, 1993), Springorum et al.
(2012) show thatfour classes of PVs with the particle an can beclassified automatically.
They take a supervisedapproach using decision trees.
The use of decisiontrees also allows them to manually inspect and an-alyze the decisions made by the classifier.
As pre-dictive features they use the head nouns of objects,generalized classes of these nouns and PP types.The approach we take here is not fully compa-rable to any of the former approaches, since wetry to derive a semantic classification BV-PP pairsin an unsupervised manner and we only use syn-tactic features, stemming from corpus instances ofboth the BVs and the PVs.
In other words, we donot attempt to classify PVs, but we try to classifysyntactic transfers and, by doing so, we identifysyntactic transfer patterns which we hypothesizeto have a close relation to semantic PV classes andthe semantics of the particles.4 Experimental Setup4.1 Gold Standard ClassificationFor testing our hypothesis, we created a gold stan-dard of 32 PVs, including 14 with the particle anand 18 with the particle auf.
We concentrated ontwo particles here in order to have a small and con-trolled test bed which allows us to study the syn-tactic transfers.We based the creation of the gold standard onthe classification by Fleischer and Barz (2012b),but we further distinguished the classes basedon the meanings of the BVs.
For example, wegrouped all the BVs with the meaning of ?lookingin a manner X?
or ?tying X to Y in a manner Z?.From these classes we selected those which hada clear subcategorization pattern for both the BVsand the PVs.
We discarded such PVs where ei-ther the PV itself or its underlying BV was clearlyambiguous.
The full gold standard can be seen intable 2.
The table also lists the expected dominantsubcategorization frames for the BVs and PVs ofeach category.While the gold standard was based on theo-retic considerations, we expected it to correlatewith human intuitions.
To test this, we presentedthe gold standard verbs to 6 human raters.
Theseraters were all German native speakers with work-ing practice in various areas of linguistics or lan-guage didactics.
The raters were not directly askedto group PVs into categories.
Instead the PVs werepresented in pairs3and raters had to make a deci-sion on whether or not the pairs belong to the samesemantic category (even if they could not thinkof a name or description of that category).
Nopre-defined categories were given, nor were ratersasked to provide a name or description for thesecategories.
The annotators were asked to take thesimilarity of the BVs and the similarity of the PVsinto consideration for their judgements.
In orderto avoid possible bias, the verbs were presentedwithout given context.
What is important here isthat we did not ask them to take any syntactic cri-terion into consideration, the criterion we used forthe initial compilation of the gold standard.The inter-annotator agreement was substantialwith a Fleiss?
Kappa score of 0.68 (Fleiss, 1971).4As a measure of agreement between raters and thepreviously created gold standard, we performedpair-wise calculations between the ratings of eachannotator and the gold standard.
For the compar-ison, the gold standard was transformed into PVpairs and the value true was assigned if the twoverbs of a pairs belonged to the same category, andfalse otherwise.
We calculated the Kappa scoresfor each annotator and took the average of theagreement scores.
Table 1 resumes the compari-son.
Values are given for the parts of the gold stan-dard corresponding to PVs with an and auf sepa-rately and also for the gold standard as a whole.It can clearly be seen that humans agreementwith the gold standard is as high as the agree-ment among different annotators.
This shows thatthe gold standard used here is a valid represen-tation of human language intuition.
Most impor-tantly, the annotators did not use syntactic criteria3All possible PV combinations were generated, but thePVs with an were kept separate from those with auf in orderto avoid an unnecessary explosion of the number of pairs tobe rated.4One of the 6 raters showed less agreement with the otherraters.
If we eliminate this rater from the calculation of agree-ment, we achieve an even higher Kappa score of 0.76 and alsoagreement scores with the gold standard improved.
Two ofthe annotators even achieved Kappa scores of over 0.80 whencompared to the gold standard.185and still validated a gold standard whose creationwas explicitly based on syntactic subcategoriza-tion frames.
In other words: there is an apparenttight interrelation between syntax and semanticsfor PVs, at least in the sense that semantic dis-tinctions can be used to predict different syntacticbehaviour.
The inverse case - predicting semanticclasses from syntactic information - will be dis-cussed below.4.2 Corpus DataWe used a lemmatized and tagged version of theSdeWaC corpus (Faa?
and Eckart, 2013), a webcorpus of 880 million words.
For linguistic pre-processing we used the MATE parser (Bohnet,2010), which allowed us to extract syntactic sub-categorization frames.4.3 Feature SelectionFor each PV-BV pair we extracted two parallel setsof features, one pertaining to the BV and one forthe PV.
This allows us to model the syntactic trans-fer.
For example, we expected that an ideal trans-fer from a group of transitive BVs to a group ofintransitive PVs should be reflected in high valuesfor the features BV:transitive and PV:intransitive5and, in turn, low values for BV:intransitive andPV:transitive.We had two ways of selecting the feature types:manually and automatically.
For the manual fea-ture selection we extracted only those featuresfrom the parsed frames which we already used inthe creation of the gold standard and which arelisted in table 2.
This resulted in a small featureset of 30 features (15 features for PVs and BVs,respectively).
For the automatic feature selectionwe simply used the n most frequent frames whichcould be observed in the corpus for the set of verbsof the gold standard.From the syntactic dependency representationprovided by the parser, we excluded subjects andmodifiers (except for PP-modifiers) in the repre-sentation of subcat frames.
We did not use infor-mation on subjects, because in German all verbshave subjects, which may be implicit in the caseof subordinate clauses.
We found that for thisreason that with the representation of subjects inthe extracted features no relevant information was5Note that transitive and transitive are only convenientabreviations for the labels NPnom and NPnom+NPacc, whichare used in table2.gained, but some distortion was introduced.
Mod-ifiers in the MATE parser represent informationwhich is too general to be good predictors.
Basedon theoretical considerations on the best lexico-graphic representation of verbs, we included PP-modifiers, however, because quantitative informa-tion on PP-adjuncts has proven successful next tothat of PP-arguments (Schulte im Walde, 2006a;Joanis et al., 2008), and in addition the parser of-ten distinguishes poorly between PP-modifiers andPP-arguments.In order to create an idealized artificial upperbound, we also created a set of idealized ?lexico-graphic?
descriptions in the form of manually in-stantiated feature vectors and feature values, us-ing the manually selected feature configurationwe just described (and ultimately based on thegold standard description represented by table 2).These idealized vectors were also used for clus-tering experiments in order to estimate an upperbound.4.4 Clustering MethodsFor the clustering experiments we used two dif-ferent clustering algorithms: K-means and La-tent Semantic Classes (LSC).
K-means is a stan-dard flat, hard-clustering algorithm; we used theWeka implementation (Witten and Frank, 2005).LSC (Rooth, 1998; Rooth et al., 1999) is atwo-dimensional soft-clustering algorithm whichlearns three probability distributions: one for theclusters, and one for the output probabilities ofeach element and for each feature type with regardto a cluster.
The latter two (elements and features)correspond to the two dimensions of the cluster-ing.
In our case the elements are the PV-BV pairs,and the features are normalized counts of the sub-categorization frames.4.5 EvaluationOur feature vectors are a combination of the fea-ture vector for the BV and the feature vector forthe PV of each PV-BV pair.
Since the length ofeach vector depends on the base frequency of eachverb we need to apply a feature normalization: wesimply reduce each feature to its unit vector oflength 1.
Because the frequency ratio between BVand PV may vary strongly, we need to normalizePV vectors and BV vectors separately before theycan be combined.The vector combination for each PV-BV pair isdone by simply adding the dimensions (and not the186an auf an+aufInter-annotator agreement 0.79 0.64 0.70Average agreement between 0.73 0.74 0.73annotators and gold standardTable 1: Inter-annotator agreement and comparison of the gold standard to the ratings of 6 human anno-tators (Fleiss?
Kappa Scores).Particle Typical frames Typical frames Semantic Verbs in Classfor the BV for the PV ClassanNPnom+NPacc+PP-anNPnom+NPacc+PP-anlocative/relationaltyingan|binden to tie atan|ketten to chain atNPnom+PP-zu/in/nach/aufNPnom+NPacclocative/relationalgazean|blicken to glance atan|gucken to look atan|starren to stare atNPnom+NPacc+PP-mitNPnom+NPacc+PP-mitingressiveconsump-tionan|brechen start to breakan|rei?en start to tearan|schneiden start to cutNPnomNPnom+NPacclocative/relationalsoundan|br?ullen to roar atan|fauchen to hiss atan|meckern to bleat atNPnom+NPacc+PP-anNPnom+NPacclocative/relationalfixationan|heften to stick atan|kleben to glue atan|schrauben to screw ataufNPnom NPnomlocativeblaze-bubbleauf|brodeln to bubble upauf|flammen to light upauf|lodern to blaze upauf|spudeln to bubble upNPnom+PP-zu/in/nach/aufNPnomlocativegazeauf|blicken to glance upauf|schauen to look upauf|sehen to look upNPnom+NPaccNPnom+NPacclocative/dimensionalinstigateauf|hetzen to instigateauf|scheuchen to rouseNPnom+NPacc+PP-aufNPnom+NPacclocative/relationalfixationauf|heften to staple onauf|kleben to glue onauf|pressen to press onNPnom NPnomingressivesoundauf|br?ullen suddenly roarauf|heulen suddenly howlauf|klingen suddenly soundauf|kreischen suddenly screamauf|schluchzen suddenly sobauf|st?ohnen suddenly moanTable 2: The gold standard classes for the experiments, with subcategorization patterns.187an auf an+aufPurity RI ARI Purity RI ARI Purity RI ARIHuman 0.93 0.92 0.92ratingsK-meansidealized features 0.83 0.91 0.70 0.88 0.92 0.72 0.93 0.97 8.2(manually set)selected features 0.67 0.82 0.29 0.75 0.87 0.52 0.46 0.88 0.32(extracted)20 feat 0.58 0.74 0.18 0.69 0.69 0.40 0.43 0.88 0.1450 feat 0.67 0.80 0.20 0.75 0.83 0.38 0.43 0.90 0.19100 feat 0.67 0.79 0.18 0.75 0.83 0.40 0.49 0.90 0.21200 feat 0.58 0.74 0.13 0.81 0.86 0.52 0.43 0.88 0.18LSC selected features 0.63 0.78 0.22 0.80 0.85 0.55 0.85 0.92 0.59(extracted)Cutoff: 0.1Table 3: Comparison of the results from different clustering methods and feature configurations.dimension extensions) of the two vectors.
In thisway, each subcategorization frame is representedseparately for the BV and the PV.
For example,the vectors for the intransitive frame will be repre-sented as BV:intransitive and PV:intransitive.We evaluated the clusterings in terms of Pu-rity (Manning et al., 2008), Rand Index and Ad-justed Rand Index (Rand, 1971; Hubert and Ara-bie, 1985).
Purity is a measure with values be-tween 0 and 1 which captures the purity of indi-vidual clusters in terms of the ratio between thenumber of elements of the majority class in eachcluster and the total of elements in the cluster.
Aperfect clustering will have a purity of 1.
What Pu-rity does not capture is the amount of clusters overwhich each target class is distributed.
That meansthat also non-perfect clusters may achieve a Purityof 1 if there are more clusters than target classes.As long as the number of clusters is constant, how-ever, purity is a good and intuitive approximationto clustering evaluation.The Rand Index (RI) looks at pairs of ele-ments and assesses whether they have been cor-rectly placed in the same cluster (which is correctif they pertain to the same target class) or in dif-ferent clusters (correct if they belong to differenttarget classes).
RI is sensitive to the number ofnon-empty clusters and can capture both the qual-ity of individual clusters and the amount to whichelements of target categories have been groupedtogether.
RI looks as pair-wise decisions, whichmakes it also applicable to the human ratings de-scribed in section 4.1.
The Adjusted Rand Index(ARI) is a version of RI which is corrected forchance.
While RI has values between 0 and 1, ARIcan have negative values; 1 still represents a per-fect clustering.The Adjusted Rand Index (ARI) is a version ofRI which is corrected for chance.
While RI hasvalues between 0 and 1, ARI can have negativevalues; 1 still represents a perfect clustering.We evaluated the clustering of the verbs with theparticles an and auf separately from each other,since we have to expect that there is a different setof semantic classes for each verb particle.
We alsoran the same experiments for the gold standard asa whole (an+auf ), in order to test if we could findsome tendencies across clusters.We set the number of clusters equal to the num-ber of target categories from the gold standard.This gave us 5 clusters for both the an-set and theauf -set and 10 clusters for the classification of thewhole gold standard.Note that LSC is a soft clustering algorithm.
Forthe evaluation of LSC clusters with respect to pu-rity and RI and ARI, a conversion to hard clus-tering must be done.
We did this conversion bysimply applying a cutoff value for the output prob-abilities for cluster membership.
We tried out var-ious cut-off levels and found that for the sets of anand auf PVs the value of 0.1 gave a good trade-offbetween coverage (the total number of elementsretained in all clusters) and ARI (cf also Table 4below).
This value is also the one used in K?uhnerand Schulte im Walde (2010).1885 ResultsThe comparison of the results from different meth-ods can be seen in table 3.
The strongest automati-cally obtained results are printed in bold face.
Thehuman rating scores are given in the first row andallow for a direct comparison between automaticclustering and human decisions.6The second rowshows the artificial upper bound represented by themanually set feature vectors as lexicographic en-tries.
Note that this is an artificial upper boundand not an experimental result, even if obtainedby clustering.The third row corresponds to the evaluation re-sults for the manually selected corpus-based fea-ture configuration used within K-means.
They areto be compared with the following rows concern-ing the results based on automatically selected nmost frequent features.
The last row shows theresults obtained with the LSC soft clustering al-gorithm, applying a cutoff of 0.1 output probabil-ity for cluster membership, again for the manu-ally selected feature configuration.
This result isnot fully comparable to the rows above, which areobained with K-means or human ratings.
SinceLSC is a soft clustering algorithm, there is a trade-off between coverage and accuracy which dependson the cutoff point selected for the conversion intohard clusters.Note that the Purity values are comparableamong each other since the number of clusters washeld constant.
We always chose a number of clus-ters equal to the number of target categories (5 cat-egories for an, 5 for auf and 10 for an+auf ).Table 4 shows the results for LSC clusteringin more detail.
The soft clusterings have to beconverted to hard clusterings.
Because of thisthe cut-off point within the conversion becomesan important parameter.
We chose here cut-offpoints which correspond to the output probabil-ity of cluster-elements (e.g.
PV-BV pairs) withregard to each cluster.
The table shows a clear ten-dency towards better ARI scores when higher cut-off points are chosen.
But this is counterbalancedby the fact that for higher cutoff points less ele-ments are retained.
Below a certain cutoff-pointthe total number of elements retaind is smaller6RI is a measure which is based on pair-wise clusteringdecisions, we were able to calculate these scores for the hu-man ratings described in section 4.1.
Since purity is not basedon a pair-wise decision, it was not applicable to the humanratings.
For the same reason ARI was also not adaptable tothe human rating scenario.than the target set of verbs in the gold standard.6 DiscussionIt is not surprising that the manually defined fea-ture configuration in our ?lexicographic?
settingperform best.
These results are also similar tothose obtained by the human validation of the goldstandard.
They do not get perfect scores of 1 be-cause of small lexicographic differences concern-ing individual entries.
The automatic clusteringresults relying on corpus-based features are worse,as expected, but they still represent a very strongtendency to group together PV-BV pairs into se-mantic classes.
We can achieve relatively high pu-rity scores, thus demonstrating that our approachis generally valid.Concerning the feature selection for the corpus-based data, the manually selected set seems to per-form slightly better than the automatic feature se-lection settings.
Moreover, the manual selectionrepresents a more stable setting since automaticselection seems to vary with the number n of fea-tures.
There appears to be no optimal setting for nwhich gives the best results for all sets.
For the anset the local maximum is reached with the selec-tion of the 50 or 100 most frequent subcat frames.The selection of more or less features leads toworse evaluation scores.
For the auf set this lo-cal maximum is reach with much higher values forn.
The manually created feature set, on the otherhand, always results in a relatively good perfor-mance.
This is also an expected result since thefeature selection already contains human linguis-tic knowledge on which syntactic arguments rep-resent the core set of the semantic roles which theverbs can realize.It is apparently surprising that for the joint goldstandard set an+auf LSC performs much betterthan K-means.
But this high ARI value comes atthe cost of a very low coverage.
If we comparethis value to table 4, it can be seen that the cutoffpoint of 0.1, which works very well for sets of anand auf is inadequate for the set an+auf : only 20verbs are retained in the converted clusters whilethe target size is 32.
While we can observe thegeneral tendency of LSC to perform on a roughlycomparable level to K-means, an exact compari-son is hard to obtain with the used evaluation met-rics.
There are, nevertheless, possible problem set-tings where soft clusters are more adequate, whichjustifies to include LSC in this comparison.189an auf an+aufCutoff ARI nclustARI nclustARI nclust0.07 0.17 25 0.39 22 0.31 400.08 0.18 23 0.55 20 0.39 320.09 0.19 21 0.55 20 0.56 230.10 0.22 19 0.55 20 0.59 200.11 0.30 16 0.5 19 0.48 170.12 0.30 16 0.41 16 0.56 16nclasses14 18 32Table 4: Evaluation with LSC using extracted selected features for different cutoff points (probabilitiesof class membership) when creating hard clusters from soft clusters.
(nclassesrefers to the number ofelements across target classes, nclustrefers to the number of elements across hard clusters.
)The class of anketten/anbinden tends to end upin singleton clusters, especially anketten.
We firstsuspected that this is due to the fact that anket-ten is a relatively infrequent verb and is repre-sented by a sparse vector.
But a comparison tothe human ratings reveals that human raters showa similar and quite consistent disagreement withthe gold standad with respect to this the locativerelational tying and fixation classes.
All 6 ratersjudged anheften (a fixation verb) and anbinden(a tying verb) as pertaining to the same category,contrary to the gold standard.
Interestingly, thisfixation-tying distinction is the only one, wherea majority of raters deviated in their judgementsfrom the gold standard at the same point.
On theother hand some of the raters were confused by thefact the class of aufbrodeln combines two differentelements: water and fire.
This did not affect themajority of raters, nor was the disagreement con-sistent, but it is reflected in the somewhat lowerinter-annotator agreement for the auf set (cf.
table1).
These findings strongly suggest that the prob-lem should be located in the gold standard ratherthan in the clustering method.Finally, is interesting to compare the automaticclustering results to the human ratings from sec-tion 4.1.
The human annotation task was com-plementary to the automatic clustering becauseclustering was done on the basis of corpus-basedpurely syntactic features while for the human rat-ing the annotators focused on purely semantic in-formation.
Apart from the expectably worse per-formance of an automatic clustering it can be con-cluded that both information from the semanticand the syntactic perspectives ultimately lead tothe creation of quite similar clusters, which isprobably the most important conclusion we candraw from the experiment.7 ConclusionIn this paper we have shown that a pairwise clus-tering of particle verbs in combination with theirbase verbs can be done with success if syntac-tic subcategorization frames for PVs and BVs aretaken as features separately.
By combining the ex-tracted subcategorization frame count from baseverbs and particle verbs as separate dimensionsin a common vector space, we are able to modelsyntactic transfer patterns.
We can also show thatwithin our setting we are able to replicate a goldstandard classification with a reasonable degree ofsuccess when we apply various clustering algo-rithms.
The gold standard by itself can be vali-dated by human judgements to a high degree.
Hu-man judges based their annotations on semanticfactors and still they converge largely with an au-tomatic clustering which is purely based on syn-tactic subcategorization.In future work we plan to adress the problemof finding correspondences between the syntacticsubcategorization slots, hence model the syntactictransfer proper, and to investigate if the syntactictransfer information can be used to predict the de-gree of semantic compositionality of PVs.AcknowledgementsThis work was funded by the DFG ResearchProject ?Distributional Approaches to SemanticRelatedness?
(Stefan Bott, Sabine Schulte imWalde), and the DFG Heisenberg FellowshipSCHU-2580/1-1 (Sabine Schulte im Walde).
Wewould also like to thank the participants of the hu-man rating experiment.190ReferencesNadine Aldinger.
2004.
Towards a Dynamic Lexi-con: Predicting the Syntactic Argument Structureof Complex Verbs.
In Proceedings of the 4th In-ternational Conference on Language Resources andEvaluation, Lisbon, Portugal.Timothy Baldwin and Aline Villavicencio.
2002.
Ex-tracting the Unextractable: A Case Study on VerbParticles.
In Proceedings of the Sixth Conference onComputational Natural Language Learning, pages98?104, Taipei, Taiwan.Timothy Baldwin, Colin Bannard, Takaaki Tanaka, andDominic Widdows.
2003.
An Empirical Modelof Multiword Expression Decomposability.
In Pro-ceedings of the ACL-2003 Workshop on MultiwordExpressions: Analysis, Acquisition and Treatment,pages 89?96, Sapporo, Japan.Timothy Baldwin.
2005.
Deep Lexical Acquisition ofVerb?Particle Constructions.
Computer Speech andLanguage, 19:398?414.Collin Bannard.
2005.
Learning about the Meaning ofVerb?Particle Constructions from Corpora.
Com-puter Speech and Language, 19:467?478.Gertrud Faa?
and Kerstin Eckart.
2013.
SdeWaC ?a Corpus of Parsable Sentences from the Web.
InProceedings of the International Conference of theGerman Society for Computational Linguistics andLanguage Technology, Darmstadt, Germany.
To ap-pear.Wolfgang Fleischer and Irmhild Barz.
2012a.
Wort-bildung der deutschen Gegenwartssprache.
deGruyter.Wolfgang Fleischer and Irmhild Barz.
2012b.
Wortbil-dung der deutschen Gegenwartssprache.
Walter deGruyter, 4th edition.Joseph L. Fleiss.
1971.
Measuring nominal scaleagreement among many raters.
Psychological Bul-letin, 76(5):378?382.Silvana Hartmann.
2008.
Einfluss syntaktischer undsemantischer Subkategorisierung auf die Komposi-tionalit?at von Partikelverben.
Studienarbeit.
Insti-tut f?ur Maschinelle Sprachverarbeitung, Universit?atStuttgart.
Supervision: Sabine Schulte im Walde andHans Kamp.Lawrence Hubert and Phipps Arabie.
1985.
Compar-ing Partitions.
Journal of Classification, 2:193?218.Eric Joanis, Suzanne Stevenson, and David James.2008.
A General Feature Space for AutomaticVerb Classification.
Natural Language Engineer-ing, 14(3):337?367.Hans Kamp and Uwe Reyle.
1993.
From discourse tologic: Introduction to modeltheoretic semantics ofnatural language, formal logic and discourse repre-sentation theory.
Number 42.
Springer.Fritz Kliche.
2011.
Semantic Variants of German Par-ticle Verbs with ?ab?.
Leuvense Bijdragen, 97:3?27.Anna Korhonen, Yuval Krymolowski, and Zvika Marx.2003.
Clustering Polysemic SubcategorizationFrame Distributions Semantically.
In Proceedingsof the 41st Annual Meeting of the Association forComputational Linguistics, pages 64?71, Sapporo,Japan.Natalie K?uhner and Sabine Schulte im Walde.
2010.Determining the Degree of Compositionality of Ger-man Particle Verbs by Clustering Approaches.
InProceedings of the 10th Conference on Natural Lan-guage Processing, pages 47?56, Saarbr?ucken, Ger-many.Andrea Lechler and Antje Ro?deutscher.
2009.
Ger-man Particle Verbs with auf.
Reconstructing theirComposition in a DRT-based Framework.
Linguis-tische Berichte, 220.Anke L?udeling.
2001.
On German Particle Verbs andSimilar Constructions in German.
Dissertations inLinguistics.
CSLI Publications, Stanford, CA.Christopher D Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
Introduction to informa-tion retrieval, volume 1.
Cambridge university pressCambridge.Diana McCarthy, Bill Keller, and John Carroll.
2003.Detecting a Continuum of Compositionality inPhrasal Verbs.
In Proceedings of the ACL-SIGLEXWorkshop on Multiword Expressions: Analysis, Ac-quisition and Treatment, Sapporo, Japan.Paola Merlo and Suzanne Stevenson.
2001.
Auto-matic Verb Classification Based on Statistical Distri-butions of Argument Structure.
Computational Lin-guistics, 27(3):373?408.William M. Rand.
1971.
Objective Criteria for theEvaluation of Clustering Methods.
Journal of theAmerican Statistical Association, 66(336):846?850.Mats Rooth, Stefan Riezler, Detlef Prescher,Glenn Carr oll, and Franz Beil.
1999.
Inducinga Semantically Annotated Lexicon via EM-BasedClustering.
In Proceedings of the 37th AnnualMeeting of the Association for Co mputationalLinguistics, Maryland, MD.Mats Rooth.
1998.
Two-Dimensional Clustersin Grammatical Relations.
In Inducing Lexiconswith the EM Algorithm, AIMS Report 4(3).
Insti-tut f?ur Maschinelle Sprachverarbeitung, Universit?atStuttgart.Sabine Schulte im Walde.
2000.
Clustering VerbsSemantically According to their Alternation Be-haviour.
In Proceedings of the 18th InternationalConference on Computational Linguistics, pages747?753, Saarbr?ucken, Germany.191Sabine Schulte im Walde.
2004.
Identification, Quan-titative Description, and Preliminary DistributionalAnalysis of German Particle Verbs.
In Proceedingsof the COLING Workshop on Enhancing and Us-ing Electronic Dictionaries, pages 85?88, Geneva,Switzerland.Sabine Schulte im Walde.
2005.
Exploring Featuresto Identify Semantic Nearest Neighbours: A CaseStudy on German Particle Verbs.
In Proceedingsof the International Conference on Recent Advancesin Natural Language Processing, pages 608?614,Borovets, Bulgaria.Sabine Schulte im Walde.
2006a.
Experiments onthe Automatic Induction of German Semantic VerbClasses.
Computational Linguistics, 32(2):159?194.Sabine Schulte im Walde.
2006b.
The Syntax-Semantics Interface of German Particle Verbs.Panel discussion at the 3rd ACL-SIGSEM Work-shop on Prepositions at the 11th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics.Sylvia Springorum, Sabine Schulte im Walde, and An-tje Ro?deutscher.
2012.
Automatic Classification ofGerman an Particle Verbs.
In Proceedings of the 8thInternational Conference on Language Resourcesand Evaluation, pages 73?80, Istanbul, Turkey.Sylvia Springorum, Sabine Schulte im Walde, and An-tje Ro?deutscher.
2013.
Sentence Generation andCompositionality of Systematic Neologisms of Ger-man Particle Verbs.
Talk at the 5th Conference onQuantitative Investigations in Theoretical Linguis-tics.Sylvia Springorum.
2011.
DRT-based Analysis of theGerman Verb Particle ?an?.
Leuvense Bijdragen,97:80?105.Barbara Stiebels.
1996.
Lexikalische Argumente undAdjunkte.
Zum semantischen Beitrag von verbalenPr?afixen und Partikeln.
Akademie Verlag, Berlin.Aline Villavicencio.
2005.
The Availability of Verb-Particle Constructions in Lexical Resources: Howmuch is enough?
Computer Speech & Language,19(4):415?432.Ian H. Witten and Eibe Frank.
2005.
Data Mining:Practical Machine Learning Tools and Techniqueswi th Java Implementations.
Morgan Kaufmann.192
