Bootstrapping Both Product Features and Opinion Words from Chi-nese Customer Reviews with Cross-Inducing1Bo WangInstitute of Computational LinguisticsPeking UniversityBeijing, 100871, Chinawangbo@pku.edu.cnHoufeng WangInstitute of Computational LinguisticsPeking UniversityBeijing, 100871, Chinawanghf@pku.edu.cnAbstractWe consider the problem of 1  identifyingproduct features and opinion words in aunified process from Chinese customer re-views when only a much small seed set ofopinion words is available.
In particular,we consider a problem setting motivated bythe task of identifying product featureswith opinion words and learning opinionwords through features alternately and it-eratively.
In customer reviews, opinionwords usually have a close relationshipwith product features, and the associationbetween them is measured by a revisedformula of mutual information in this paper.A bootstrapping iterative learning strategyis proposed to alternately both of them.
Alinguistic rule is adopted to identify low-frequent features and opinion words.
Fur-thermore, a mapping function from opinionwords to features is proposed to identifyimplicit features in sentence.
Empirical re-sults on three kinds of product reviews in-dicate the effectiveness of our method.1 IntroductionWith the rapid expansion of network application,more and more customer reviews are available on-line, which are beneficial for product merchants totrack the viewpoint of old customers and to assistpotential customers to purchase products.
However,1 Supported by National Natural Science Foundation of Chinaunder grant No.60675035 and Beijing Natural Science Foun-dation under grant No.4072012it?s time-consuming to read all reviews in person.As a result, it?s significant to mine customer re-views automatically and to provide users withopinion summary.In reality, product features and opinion wordsplay the most important role in mining opinions ofcustomers.
One customer review on some cellphone is given as follows:(a) ?????????????????
(Theappearance is beautiful, the screen is bigand the photo effect is OK.)Product features are usually nouns such as ????
(appearance) and ????
(screen) or nounphrases such as ??????
(photo effect) express-ing which attributes the customers are mostly con-cerned.
Opinion words (opword is short for ?opin-ion word?)
are generally adjectives used to expressopinions of customers such as ????
(beautiful),???
(big) and ???
(well).
As the core part of anopinion mining system, this paper is concentratedon identifying both product features and opinionwords in Chinese customer reviews.There is much work on feature extraction andopinion word identification.
Hu and Liu (2004)makes use of association rule mining (Agrawal andSrikant, 1994) to extract frequent features, the sur-rounding adjectives of any extracted feature areconsidered as opinion words.
Popescu and Etzioni(2005) has utilized statistic-based point-wise mu-tual information (PMI) to extract product features.Based on the association of opinion words withproduct features, they take the advantage of thesyntactic dependencies computed by the MINIPARparser (Lin, 1998) to identify opinion words.
Tur-289ney (2002) applied a specific unsupervised learn-ing technique based on the mutual in-formationbetween document phrases and two seed words?excellent?
and ?poor?.Nevertheless, in previous work, identifyingproduct features and opinion words are alwaysconsidered two separate tasks.
Actually, mostproduct features are modified by the surroundingopinion words in customer reviews, thus they arehighly context dependent on each other, which isreferred to as context-dependency property hence-forth.
With the co-occurrence characteristic, identi-fying product features and opinion words could becombined into a unified process.
In particular, it ishelpful to identify product features by using identi-fied opinion words and vice versa.
That impliesthat such two subtasks can be carried out alter-nately in a unified process.
Since identifyingproduct features are induced by opinion words andvice versa, this is called cross-inducing.As the most important part of a feature-basedopinion summary system, this paper focuses onlearning product features and opinion words fromChinese customer reviews.
Two sub-tasks are in-volved as follows:Identifying features and opinion words: Resort-ing to context-dependency property, a bootstrap-ping iterative learning strategy is proposed to iden-tify both of them alternately.Identifying implicit features: Implicit featuresoccur frequently in customer reviews.
An implicitfeature is defined as a feature that does not appearin an opinion sentence.
The association betweenfeatures and opinion words calculated with the re-vised mutual information is used to identify im-plicit features.This paper is sketched as follows: Section 2 de-scribes the approach in detail; Experiment in sec-tion 3 indicates the effectiveness of our approach.Section 4 presents related work and section 5 con-cludes and presents the future work.2 The ApproachFigure 1 illustrates the framework of an opinionsummary framework, the principal parts related tothis paper are shown in bold.
The first phase?identifying features and opinion words?, worksiteratively to identify features with the opinionwords identified and learn opinion words throughthe product features identified alternately.
Then,one linguistic rule is used to identify low-frequentfeatures and opinion words.
After that, a mappingfunction is designed to identify implicit features.Figure 1.
The framework of an opinion summarysystem2.1 Iterative Learning StrategyProduct features and opinion words are highly con-text-dependent on each other in customer reviews,i.e., the feature ????
(body) for digital cameraoften co-occur with some opinion words such as???
(big) or ????
(delicate) while the feature?????
(the proportion of performance to price)often co-occurs with the opinion word ???
(high).Product features can be identified resorting tothe surrounding opinion words identified beforeand vice versa.
A bootstrapping method that worksiteratively is proposed in algorithm 1.Algorithm 1 works as follows: given the seedopinion words and all the reviews, all noun phrases(noun phrases in the form ?noun+?)
form CandFe-aLex (the set of feature candidates) and all adjec-tives compose of CandOpLex (the set of the candi-dates of opinion words).
The sets ResFeaLex andResOpLex are used to store final features and opin-ion words.
Initially, ResFeaLex is set empty whileResOpLex is composed of all the seed opinionwords.
At each iterative step, each feature candi-date in CandFeaLex is scored by its context-dependent association with each opword in ResO-pLex, the candidate whose score is above the pre-specified threshold Thresholdfeature is added to Res290Algorithm 1.
Bootstrap learning product features and opinion words with cross-inducingBootstrap-Learning (ReviewData, SeedOpLex, Thresholdfeature, Thresholdopword)1   Parse(ReviewData);2   ResFeaLex = {}, ResOpLex = SeedOpLex;3   CandFeaLex = all noun phrases in ReviewData;4   CandOpLex = all adjectives in ReviewData;5   while  (CandFeaLex?
{} && CanOpLex?
{})6        do for each candfea?CandFeaLex7              do for each opword?ResOpLex8                    do calculate RMI(candfea,opword) with ReviewData;9                score(canfea)=?opword?ResOpLexRMI(candfea,opword)/|ResOpLex|;10         sort CandFeaLex by score;11         for each candfea?CandFeaLex12               do  if  (score(candfea)> Thresholdfeature)13                       then   ResFeaLex=ResFeaLex+{candfea};14                                CanFeaLex=CandFeaLex ?
{candfea};15          for each candop?CandOpLex16                 do for each feature?ResFeaLex17                      do calculate RMI(candop,feature) with D;18                 score(candop)=?feature?ResFeaLexRMI(feature,candop)/|ResFeaLex| ;19          sort  CandOpLex by score;20          for each candop?CandOpLex21       do  if  (score (candop)>Thresholdopword)22               then  ResOpLex=ResOpLex+{candop };23                     CanOpLex=CandOpLex ?
{candop};24          if  (neither candfea and candop is learned) then break;25   return ResFeaLex, ResOpLex;FeaLex and subtracted from CandFeaLex.
Simi-larly, opinion words are processed in this way, butthe scores are related to features in ResFeaLex.The iterative process continues until neither Res-FeaLex nor ResOpLex is altered.
Any feature can-didate and opinion word candidate, whose relativedistance in sentence is less than or equal to thespecified window size Minimum-Offset, are re-garded to co-occur with each other.
The associa-tion between them is calculated by the revised mu-tual information denoted by RMI, which will bedescribed in detail in the following section andemployed to identify implicit features in sentences.2.2  Revised Mutual InformationIn customer reviews, features and opinion wordsusually co-occur frequently, features are usuallymodified by the surrounding opinion words.
If theabsolute value of the relative distance in a sentencefor a feature and an opinion word is less thanMinimum-Offset, they are considered context-dependent.Many methods have been proposed to measurethe co-occurrence relation between two words suchas ?2 (Church and Mercer,1993) , mutual informa-tion (Church and Hanks, 1989; Pantel and Lin,2002), t-test (Church and Hanks, 1989), and log-likelihood (Dunning,1993).
In this paper a revisedformula of mutual information is used to measurethe association since mutual information of a low-frequency word pair tends to be very high.Table 1 gives the contingency table for twowords or phrases w1 and  w2, where A is the num-ber of reviews where w1 and w2 co-occur; B indi-cates the number of reviews where w1 occurs butdoes not co-occur with w2; C denotes the numberof reviews where w2 occurs but does not co-occurwith w1; D is number of reviews where neither w1nor w2 occurs; N = A + B + C + D.With the table, the revised formula of mutual in-formation is designed to calculate the associationof w1 with w2 as formula (1).w2 ~w2w1 A B~w1 C DTable 1:  Contingency table2911 21 2 1 21 2( , )( , ) ( , ) log( ) ( )p w wRMI w w freq w wp w p w= ?
ilog( ) (N AA)A B A C?= ?
+ ?
+                           (1)2.3 Identifying Low-Frequent Features andOpinion WordsIn Chinese reviews, one linguistic rule ?noun+ ad-verb* adjective+?
occurs frequently and most ofthe instances of the rule are used to express posi-tive or negative opinions on some features, i.e., ??
?/noun ?
?/adverb ??/adjective?
(The body israther delicate) , where each Chinese word and itspart-of-speech is separated by the symbol ?/?.Intuitively, this linguistic rule can be used toimprove the output of the iterative learning.
Foreach instance of the rule, if ?noun+?
exists in Res-FeaLex, the ?adjective?
part would be added toResOpLex, and if ?adjective+?
exists in ResOpLex,the noun phrase ?noun+?
part will be added toResFeaLex.
After that, most low-frequent featuresand opinion words will be recognized.2.4 Identifying Implicit FeaturesThe context-dependency property indicates thecontext association between product features andopinion words.
As a result, with the revised mutualinformation, the implicit features can be deducedfrom opinion words.
A mapping function f: op-word?
feature is used to deduce the mapping fea-ture for opword , where f(opword) is defined as thefeature with the largest association with opinionword.If an opinion sentence contains opinion words,but it does not have any explicit features, the map-ping function f: opword?
feature is employed togenerate the implicit feature for each opinion wordand the feature is considered as an implicit featurein the opinion sentence.
Two instances are given in(b) and (c), where the implicit features are insertedin suitable positions and they are separated in pa-rentheses.
Since f (????
(beautiful)) = ????
(appearance) and f (????
(fashionable)) = ????
(appearance), ????
(appearance) is an im-plicit feature in (b).
Similarly, the implicit featuresin (c) are ????
(performance) and ????
(pic-ture).
(b) (??)????(??)??
?It?s (appear-ance) beautiful and (appearance) fashion-able.
(c) (??)??????(??)???
?It?s(performance) very stable and (picture)very clear.3 Experiment3.1 Data CollectionWe have gathered customer reviews of three kindsof electronic products from http://it168.com: digi-tal camera, cell-phone and tablet.
The first 300 re-views for each kind of them are downloaded.
Oneannotator was asked to label each sentence withproduct features (including implicit features) andopinion words.
The annotation set for features andopinion words are shown in table 2.ProductNameNo.
of Fea-turesNo.
of Opin-ion Wordsdigital camera 135 97cell-phone 155 125tablet 96 83Table 2 .
Annotation set for product features andopinion wordsUnlike English, Chinese are not separated byany symbol.
Therefore, the reviews are tokenizedand tagged with part-of-speech by a toolICTCLAS2.One example of the output of this toolis as (d).
(d) ?
?/n  ?
?/n  ?/d  ?/d  ?/a  ?/w  ?
?/n  ??
?/n  ?
?/v  ?/d  ?
?/v  ??/v?
?/n  ?
?/n  ?/w  ?
?/n  ?
?/vn  ?
?/vn  ?/d  ?/d  ?
?/a  ?/wThe seed opinion words employed in the itera-tive learning are: ????
(clear), ???
(quick),???
(white), ????
(weak).
???
(good), ????
(good), ???
(high), ???
(little), ???
(many),?
?
?
(long).
Empirically, Thresholdfeature andThresholdopword in Algorithm 1 is set to 0.2, Mini-mum-Offset is set to 4.2 http://www.nlp.org.cn292On Set On Sentence  Product NamePrecision Recall F-Score Precision Recall F-Scoredigital camera 64.03% 45.92% 53.49% 46.62% 65.72% 54.55%cell-phone 54.43% 43.87% 48.58% 34.17% 55.15% 42.19%tablet 51.45% 59.38% 55.13% 41.39% 60.21% 49.06%average 56.64% 49.72% 52.40% 40.73% 60.36% 48.60%Table 3.
Evaluation of apriori algorithmOn Set On Sentence Type Product NamePrecision Recall F-Score Precision Recall F-score73.57% 54.81% 62.82% 55.80% 68.69% 61.58%digital camera78.20% 73.33% 75.69% 54.71% 70.80% 63.49%80.92% 45.81% 58.50% 47.31% 58.59% 52.35%cell-phone 82.30% 66.46% 73.53% 49.22% 61.63% 54.73%72.73% 57.29% 64.09% 49.79% 61.03% 54.84%tablet 77.99% 73.96% 75.92% 52.54% 64.43% 57.88%75.74% 52.64% 61.80% 50.97% 62.77% 56.26%featureaverage 79.50% 71.25% 75.05% 52.16% 65.62% 58.70%89.02% 38.02% 53.28% 72.35% 50.24% 59.30%digital camera87.31% 60.94% 71.78% 69.40% 85.28% 76.53%87.95% 30.80% 45.63% 66.44% 42.84% 52.09%cell-phone 88.49% 51.90% 65.43% 63.14% 79.51% 70.39%77.94% 30.64% 43.98% 61.30% 42.69% 50.34%tablet 80.73% 50.87% 62.41% 63.92% 81.02% 71.46%84.97% 33.15% 47.63% 66.70% 45.26% 53.91%opwordaverage 85.51% 54.57% 66.54% 65.49% 81.94% 72.79%Table 4.
Evaluation of iterative learning (the upper) and the combination of iterative learning and thelinguistic rule (the lower).3.2 Evaluation MeasurementAs Hu and Liu (2004), the features mined form theresult set while the features in the manually anno-tated corpus construct the answer set.
With the twosets, precision, recall and f-score are used to evalu-ate the experiment result on set level.In our work, the evaluation is also conducted onsentence for three factors: Firstly, each feature oropinion word may occur many times in reviews butit just occurs once in the corresponding answer set;Secondly, implicit features should be evaluated onsentence; Besides, to generate an opinion summary,the features and the opinion words should be iden-tified for each opinion sentence.On sentence, the features and opinion wordsidentified for each opinion sentence are comparedwith the annotation result in the corresponding sen-tence.
Precision, recall and f-score are also used tomeasure the performance.3.3 EvaluationHu and Liu (2004) have adopted associate rulemining to mine opinion features from customerreviews in English.
Since the original corpus andsource code is not available for us, in order tomake comparison with theirs, we have re-implemented their algorithm, which is denoted asapriori method as follows.
To be pointed out is that,the two pruning techniques proposed in Hu and Liu(2004): compactness pruning and redundancypruning, were included in our experiment.
Theevaluation on our test data is listed in table 3.
Therow indexed by average denotes the average per-formance of the corresponding column and eachentry in it is bold.Table 4 shows our testing result on the samedata, the upper value in each entry presents the re-sult for iterative learning strategy while the lowervalues denote that for the combination of iterativelearning and the linguistic rule.
The average row293shows the average performance for the correspond-ing columns and each entry in the row is shown inbold.On feature, the average precision, recall and f-score on set or sentence increase according to theorder apriori < iterative <  ite+rule, where aprioriindicates Hu and Liu?s method, iterative representsiterative strategy and iterative+rule denotes thecombination of iterative strategy and the linguisticrule.
The increase range from apriori to itera-tive+rule of f-score on set gets to 22.65% while onsentence it exceeds 10%.
The main reason for thepoor performance on set for apriori is that manycommon words such as ????
(computer), ????
(China) and ????
(time of use) with high fre-quency are extracted as features.
Moreover, thepoor performance on sentence for apriori method isdue to that it can?t identify implicit features.
Fur-thermore, the increase in f-score from iterative toite+rule on set and on sentence shows the perform-ance can be enhanced by the linguistic rule.Table 4 also shows that the performance inlearning opinion words has been improved afterthe linguistic rule has been used.
On set, the aver-age precision increases from 84.97% to 85.51%while the average recall from 33.15% to 54.57%.Accordingly, the average f-score increase signifi-cantly by about 18.91%.On sentence, although there is a slow decreasein the average precision, there is a dramatic in-crease in the average recall, thus the average f-score has increased from 53.91% to 72.79%.
Fur-thermore, the best f-score (66.54%) on set and thebest f-score (72.79%) on sentence indicate the ef-fectiveness of ite+rule on identifying opinionwords.4 Related WorkOur work is much related to Hu?s system (Hu andLiu,2004), in which association rule mining is usedto extract frequent review noun phrase as features.After that, two pruning techniques: compactnesspruning and redundancy pruning, are utilized.
Fre-quent features are used to find potential opinionwords (adjectives) and WordNet syno-nyms/antonyms in conjunction with a set of seedwords are used in order to find actual opinionwords.
Finally, opinion words are used to extractassociated infrequent features.
The system onlyextracts explicit features.
Our work differs fromhers at two aspects: (1) their method can?t identifyimplicit features which occur frequently in opinionsentences; (2) Product features and opinion wordsare identified on two separate steps in Hu?s systembut they are learned in a unified process here andinduced by each other in this paper.Popescu and Etzioni (2005) has used web-basedpoint-wise mutual information (PMI) to extractproduct features and use the identified features toidentify potential opinion phrases with co-occurrence association.
They take advantage of thesyntactic dependencies computed by the MINIPARparser.
If an explicit feature is found in a sentence,10 extraction rules are applied to find the heads ofpotential opinion phrases.
Each head word togetherwith its modifier is returned as a potential opinionphrase.
Our work is different from theirs on twoaspects: (1) Product features and opinion words areidentified separately but they are learned simulta-neously and are boosted by each other here.
(2)They have utilized a syntactic parser MINIPAR,but there?s no syntactic parser available in Chinese,thus the requirement of our algorithm is only asmall seed opinion word lexicon.
Although co-occurrence association is used to derive opinionwords from explicit features in their work, the wayhow co-occurrence association is represented isdifferent.
Besides, the two sub-tasks are boosted byeach other in this paper.On identifying opinion words, Morinaga et al(2002)has utilized information gain to extract clas-sification features with a supervised method; Hat-zivassiloglou and Wiebe (1997) used textual  junc-tions such as ?fair and legitimate?
or ?simplisticbut well-received?
to separate similarity- and op-positely-connoted words; Other methods are pre-sent in (Riloff et al 2003; Riloff and Wiebe, 2003;Gamon and Aue, 2005; Wilson et al 2006) Theprincipal difference from previous work is that,they have considered extracting opinion words as aseparate work but we have combined identifyingfeatures and opinion words in a unified process.Besides, the opinion words are identified for sen-tences but in their work they are identified for re-views.5 ConclusionIn this paper, identifying product features andopinion words are induced by each other and arecombined in a unified process.
An iterative learn-294ing strategy based on context-dependence propertyis proposed to learn product features and opinionwords alternately, where the final feature lexiconand opinion word lexicon are identified with veryfew knowledge (only ten seed opinion words) andaugmented by each other alternately.
A revisedformula of mutual information is used to calculatethe association between each feature and opinionword.
A linguistic rule is utilized to recall low-frequent features and opinion words.
Besides, amapping function is designed to identify implicitfeatures in sentence.
In addition to evaluating theresult on set, the experiment is evaluated on sen-tence.
Empirical result indicates that the perform-ance of iterative learning strategy is better thanapriori method and that features and opinion wordscan be identified with cross-inducing effectively.Furthermore, the evaluation on sentence shows theeffectiveness in identifying implicit features.In future, we will learn the semantic orientationof each opinion word, calculate the polarity of eachsubjective sentence, and then construct a feature-based summary system.ReferencesAna Maria Popescu and Oren Etzioni.
2005.
ExtractingProduct Features and Opinions from Reviews.
Pro-ceedings of HLT-EMNLP (2005)De-Kang Lin.
1998.
Dependency-Based Evaluation ofMINIPAR.
In:Proceedings of the Workshop on theEvaluation of Parsing Systems, Granada, Spain, 1998,298?312Ellen Riloff, Janyce Wiebe, and Theresa Wilson.
2003.Learning Subjective Nouns Using Extraction PatternBootstrapping.
Seventh Conference on Natural Lan-guage Learning (CoNLL-03).
ACL SIGNLL.
Pages25-32.Ellen Riloff and Janyce Wiebe.
2003.
Learning Extrac-tion Patterns for Subjective Expressions.
Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP-03).
ACL SIGDAT.
2003, 105-112.Kenneth Ward Church and Robert L. Mercer.
1993.Introduction to the special issue on computationallinguistics using large corpora.
Computational Lin-guistics 19:1-24Kenneth Ward Church and Patrick Hanks.
1989.
WordAssociation Norms, Mutual Information and Lexi-cography.
Proceedings of the 26th Annual Confer-ence of the Association for Computational Linguis-tics(1989).Michael Gamon and Anthony Aue.
2005.
Automaticidentification of sentiment vocabulary: exploiting lowassociation with known sentiment terms.
In :ACL2005 Workshop on Feature Engineering,2005.Minqing Hu and Bing Liu.
2004.
Mining Opinion Fea-tures in Customer Reviews.
Proceedings of NineteethNational Conference on Artificial Intellgience(AAAI-2004), San Jose, USA, July 2004.Patrick Pantel and Dekang Lin.
2002.
Document Clus-tering with Committees.
In Proceedings of ACMConference on Research and Development in Infor-mation Retrieval (SIGIR-02).
pp.
199-206.
Tampere,Finland.Peter D. Turney.
2002.
Thumbs Up or Thumbs Down?Semantic Orientation Applied to Unsupervised Clas-sification of Reviews.
ACL 2002: 417-424Rakesh Agrawal and Ramakrishan Srikant.
1994.
Fastalgorithm for mining association rules.
VLDB?94,1994.Satoshi Morinaga, Kenji Yamanishi, Kenji Tateishi, andToshikazu Fukushima.
2002.
Mining Product Repu-tations on the WEB, Proceedings of 8th ACMSIGKDD International Conference on Knowledge.Discover and Data Mining, (2002) 341-349Ted Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics 19:61-74Theresa Wilson , Janyce Wiebe, and Rebecca Hwa.2006.
Recognizing strong and weak opinion clauses.Computational Intelligence 22 (2): 73-99.295
