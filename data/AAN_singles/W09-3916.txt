Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 120?123,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsA Two-tier User Simulation Model for Reinforcement Learning ofAdaptive Referring Expression Generation PoliciesSrinivasan JanarthanamSchool of InformaticsUniversity of Edinburghs.janarthanam@ed.ac.ukOliver LemonSchool of InformaticsUniversity of Edinburgholemon@inf.ed.ac.ukAbstractWe present a new two-tier user simula-tion model for learning adaptive referringexpression generation (REG) policies forspoken dialogue systems using reinforce-ment learning.
Current user simulationmodels that are used for dialogue pol-icy learning do not simulate users withdifferent levels of domain expertise andare not responsive to referring expres-sions used by the system.
The two-tier model displays these features, thatare crucial to learning an adaptive REGpolicy.
We also show that the two-tiermodel simulates real user behaviour moreclosely than other baseline models, usingthe dialogue similarity measurebased on Kullback-Leibler divergence.1 IntroductionWe present a new user simulation model forlearning adaptive referring expression generation(REG) policies for spoken dialogue systems us-ing reinforcement learning methods.
An adap-tive REG policy equips a dialogue system to dy-namically modify its utterances in order to adaptto user?s domain knowledge level.
For instance,to refer to domain objects, the system might usesimple descriptive expressions with novices andtechnical jargon with experts.
Such adaptationshelp grounding between the dialogue partners (Is-sacs and Clark, 1987).
Since the user?s knowl-edge level is unknown, the system must be able toadapt dynamically during the conversation.
Hand-coding such a policy could be extremely difficult.
(Janarthanam and Lemon, 2009b) have shownthat such policies can be learned using simula-tion based reinforcement learning (RL) methods.The quality of such learned policies is directly de-pendent on the performance of the user simula-tions used to train them.
So far, only hand-codeduser simulations have been employed.
In contrast,we now present a data driven two-tier user sim-ulation model trained on dialogue data collectedfrom real users.
We also show that the two-tiermodel simulates real users more faithfully thanother data driven baseline n-gram models (Eckertet al, 1997).In section 2 we briefly discuss other work re-lated to user simulations for dialogue policy learn-ing using RL.
In section 3 we describe the dataused to build the simulation.
Section 4 describesthe simulation models in detail.
In section 5 and6 we present the evaluation metrics used and theresults.2 Related workSeveral user simulation models have been pro-posed for dialogue management policy learning(Schatzmann et al, 2006; Schatzmann et al,2007).
However, these models cannot be directlyused for REG policy learning because they inter-act with the dialogue system only using high-leveldialogue acts.
Also, they do not simulate differ-ent user groups like experts, novices, etc.
In orderto learn adaptive REG policies, user simulationsneed to respond to the system?s choice of referringexpressions and simulate user groups with differ-ent knowledge levels.
We propose a two-tier simu-lation which simulates users with different knowl-edge levels and is sensitive to the system?s choiceof referring expressions.1203 CorpusThe ?Wizard-of-Oz?
(WOZ) methodology is awidely accepted way of collecting dialogue datafor user simulation modeling (Whittaker et al,2002).
In this setup, real users interact with a hu-man wizard disguised as a dialogue system.
Thewizard interprets the users responses and passesthem on to the dialogue system.
The dialogue sys-tem updates the dialogue state and decides the re-sponses to user?s moves.
The task of the partici-pant is to interact with the dialogue system to getinstructions to setup a broadband Internet connec-tion.
The referring expression generation strategyis chosen before the dialogue starts and stays thesame for the whole session.
The strategies usedwere ?jargon?, ?descriptive?
and ?tutorial?.
In thejargon strategy the system instructs the user us-ing technical terms (e.g.
?Plug the broadbandfilter into the phone socket.?).
In the de-scriptive strategy, it uses descriptive terms (e.g.
?Plug the small white box into the squarewhite box on the wall.?).
In the tutorialstrategy, the system uses both jargon and descrip-tive terms together.
The system provides clari-fications on referring expressions when users re-quest them.
The participant?s domain knowledgeis also recorded during the task.
Please refer to (Ja-narthanam and Lemon, 2009a) for a more detailson our Wizard-of-Oz environment for data collec-tion.
The dialogues were collected from 17 par-ticipants (one dialogue each) with around 24 to 35turns per dialogue depending on the strategy anduser?s domain knowledge.4 User Simulation modelsThe dialogue data and knowledge profiles wereused to build user simulation models.
These mod-els take as input the system?s dialogue act As,t (atturn t) and choice of referring expressions RECs,tand output the user?s dialogue Au,t and environ-ment EAu,t acts.
User?s observation and manipu-lation of the domain objects is represented by theenvironment act.4.1 Advanced n-gram modelA simple approach to model real user behaviouris to model user responses (dialogue act andenvironment act) as advanced n-gram models(Georgila et al, 2006) based on many context vari-ables - all referring expressions used in the utter-ance (RECs,t), the user?s knowledge of the REs(DKu), history of clarification requests on theREs (H), and the system?s dialogue act (As,t), asdefined below:P (Au,t|As,t, RECs,t, DKu,H)P (EAu,t|As,t, RECs,t, DKu,H)Although this is an ideal model of the real userdata, it covers only a limited number of contextsowing to the limited size of the corpus.
Therefore,it cannot be used for training as there may be alarge number of unseen contexts which the modelneeds to respond to.
For example, this model can-not respond when the system uses a mix of jar-gon and descriptive expressions in its utterance be-cause such a context does not exist in our corpus.4.2 A Two-tier modelInstead of using a complex context model, we di-vide the large context in to several sub-contextsand model the user?s response based on them.
Wepropose a two-tier model, in which the simulationof a user?s response is divided into two steps.
First,all the referring expressions used in the system?sutterance are processed as below:P (CRu,t|REs,t, DKRE,u,HRE , As,t)This step is repeated for each expression REs,tseparately.
The above model returns a clarifi-cation request based on the referring expressionREs,t used, the user?s knowledge of the expres-sion DKRE,u, and previous clarification requestson the expression HRE and the system dialogueact As,t.
A clarification request is highly likely incase of the jargon strategy and less likely in otherstrategies.
Also, if a clarification has already beenissued, the user is less likely to issue another re-quest for clarification.
In such cases, the clarifica-tion request model simply returns none.In the next step, the model returns a user di-alogue act Au,t and an environment act EAu,tbased on the system dialogue act As,t and the clar-ification request CRu,t, as follows:P (Au,t|As,t, CRu,t)P (EAu,t|As,t, CRu,t)By dividing the complex context into smallersub-contexts, the two-tier model simulates realusers in contexts that are not directly observed inthe dialogue data.
The model will therefore re-spond to system utterances containing a mix ofREG strategies (for example, one jargon and onedescriptive expression in the same utterance).1214.3 Baseline Bigram modelA bigram model was built using the dialogue databy conditioning the user responses only on the sys-tem?s dialogue act (Eckert et al, 1997).P (Au,t|As,t)P (EAu,t|As,t)Since it ignores all the context variables exceptthe system dialogue act, it can be used in contextsthat are not observed in the dialogue data.4.4 Trigram modelThe trigram model is similar to the bigram model,but with the previous system dialogue act As,t?1as an additional context variable.P (Au,t|As,t, As,t?1)P (EAu,t|As,t, As,t?1)4.5 Equal Probability model baselineThe equal probability model is similar to the bi-gram model, except that it is not trained on thedialogue data.
Instead, it assigns equal probabil-ity to all possible responses for the given systemdialogue act.4.6 SmoothingWe used Witten-Bell discounting to smooth allour models except the equal probability model,in order to account for unobserved but possibleresponses in dialogue contexts.
Witten-Bell dis-counting extracts a small percentage of probabilitymass, i.e.
number of distinct responses observedfor the first time (T ) in a context, out of the to-tal number of instances (N ), and redistributes thismass to unobserved responses in the given context(V ?
T ) (where V is the number of all possibleresponses) .
The discounted probabilities P ?
ofobserved responses (C(ei) > 0) and unobservedresponses (C(ei) = 0) are given below.P ?
(ei) = C(ei)N+T if(C(ei) > 0)P ?
(ei) = t(N+T )(V?T ) if(C(ei) = 0)On analysis, we found that the Witten-Belldiscounting assigns greater probability to unob-served responses than to observed responses, incases where the number of responses per con-text is very low.
For instance, in a partic-ular context, the possible responses, their fre-quencies and their original probabilities were -provide info (3, 0.75), other (1, 0.25),request clarification (0, 0).
After dis-counting, the revised probabilities P ?
are 0.5,0.167 and 0.33. request clarificationgets the whole share of extracted probability asit is the only unobserved response in the contextand is more than the other responses actuallyobserved in the data.
This is counter-intuitive forour application.
Therefore, we use a modified ver-sion of Witten-Bell discounting (given below) tosmooth our models, where the extracted proba-bility is equally divided amongst all possible re-sponses.
Using the modified version, the revisedprobabilities for the illustrated example are 0.61,0.28 and 0.11 respectively.P ?
(ei) = C(ei)N+T + T(N+T )V5 Metrics for evaluation of simulationsWhile there are many proposed measures to rankuser simulation models with respect to real userdata (Schatzmann et al, 2005; Georgila et al,2006; Rieser and Lemon, 2006a; Williams, 2008),we use the Dialogue Similarity measurebased on Kullback-Leibler (KL) (Cuayahuitl etal., 2005; Cuayahuitl, 2009) divergence to mea-sure how similar the probability distributions ofthe simulation models are to the original real hu-man data.5.1 Dialogue SimilarityDialogue Similarity is a measure of divergence be-tween real and simulated dialogues and can mea-sure how similar a model is to real data.
The mea-sure is based on Kullback-Leibler (KL) divergenceand is defined as follows:DS(P ||Q) = 1N?Ni=1DKL(P ||Q)+DKL(Q||P )2DKL(P ||Q) =?Mi=1 pi ?
log(piqi )The metric measures the divergence betweendistributions P and Q in N different contextswith M responses per context.
Ideally, the dia-logue similarity between two similar distributionsis close to zero.6 Evaluation resultsWe consider the Advanced N-gram model to bea realistic model of the real human dialogue cor-pus, as it takes into account all context variablesand is reasonably smoothed to account for unob-served user responses.
Therefore, we compare theprobability distributions of all the other models to122Model Au,t EAu,tTwo-tier 0.078 0.018Bigram 0.150 0.139Trigram 0.145 0.158Equal Probability 0.445 0.047Table 1: Dialogue Similarity with ModifiedWitten-Bell discounting w.r.t Advanced N-grammodelthe advanced n-gram model using the dialoguesimilarity measure.
The results of the evalu-ation are given in table 1.The results show that the two-tier model ismuch closer (0.078, 0.018) to the Advanced N-gram model than the other models.
This is due tothe fact that the bigram and trigram models don?ttake into account factors like the user?s knowl-edge, the strategy used, and the dialogue history.By effectively dividing the RE processing and theenvironment interaction, the two-tier simulationmodel is not only realistic in observed contexts butalso usable in unobserved contexts (unlike the Ad-vanced N-gram model).7 ConclusionWe have presented a data driven user simulationmodel called the two-tier model for learning REGpolicies using reinforcement learning.
We havealso shown that the two-tier model is much closerto real user data than the other baseline models.We will now train REG policies using the two-tiermodel and test them on real users in the future.AcknowledgementsThe research leading to these results has re-ceived funding from the EPSRC (project no.EP/E019501/1) and from the European Commu-nity?s Seventh Framework Programme (FP7/2007-2013) under grant agreement no.
216594 (CLAS-SiC project www.classic-project.org),and from the British Council?s UKERI pro-gramme.ReferencesH.
Cuayahuitl, S. Renals, O.
Lemon, and H. Shi-modaira.
2005.
Human-Computer Dialogue Sim-ulation Using Hidden Markov Models.
In Proc.
ofASRU 2005.H.
Cuayahuitl.
2009.
Hierarchical ReinforcementLearning for Spoken Dialogue Systems.
Ph.D. the-sis, University of Edinburgh, UK.W.
Eckert, E. Levin, and R. Pieraccini.
1997.
UserModeling for Spoken Dialogue System Evaluation.In Proc.
of ASRU97.K.
Georgila, J. Henderson, and O.
Lemon.
2006.
UserSimulation for Spoken Dialogue System: Learningand Evaluation.
In Proc of ICSLP 2006.E.
A. Issacs and H. H. Clark.
1987.
References inconversations between experts and novices.
Journalof Experimental Psychology: General, 116:26?37.S.
Janarthanam and O.
Lemon.
2009a.
A Wizard-of-Oz environment to study Referring Expression Gen-eration in a Situated Spoken Dialogue Task.
In Proc.ENLG?09.S.
Janarthanam and O.
Lemon.
2009b.
Learning Lexi-cal Alignment Policies for Generating Referring Ex-pressions for Spoken Dialogue Systems.
In Proc.ENLG?09.V.
Rieser and O.
Lemon.
2006a.
Cluster-based UserSimulations for Learning Dialogue Strategies.
InProc.
Interspeech/ICSLP.J.
Schatzmann, K. Georgila, and S. J.
Young.
2005.Quantitative Evaluation of User Simulation Tech-niques for Spoken Dialogue Systems.
In Proc.
SIG-dial workshop on Discourse and Dialogue ?05.J.
Schatzmann, K. Weilhammer, M. N. Stuttle, and S. J.Young.
2006.
A Survey of Statistical User Sim-ulation Techniques for Reinforcement Learning ofDialogue Management Strategies.
Knowledge Engi-neering Review, pages 97?126.J.
Schatzmann, B. Thomson, K. Weilhammer, H. Ye,and S. J.
Young.
2007.
Agenda-based User Simula-tion for Bootstrapping a POMDP Dialogue System.In Proc of HLT/NAACL 2007.S.
Whittaker, M. Walker, and J. Moore.
2002.
Fishor Fowl: A Wizard of Oz Evaluation of DialogueStrategies in the Restaurant Domain.
In LanguageResources and Evaluation Conference.J.
Williams.
2008.
Evaluating User Simulations withthe Cramer-von Mises Divergence.
Speech Commu-nication, 50:829?846.123
