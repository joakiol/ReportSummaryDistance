Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1318?1326,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsTranslationese and Its DialectsMoshe Koppel Noam OrdanDepartment of Computer Science Department of Computer ScienceBar Ilan University University of HaifaRamat-Gan, Israel 52900 Haifa, Israel 31905moishk@gmail.com noam.ordan@gmail.comAbstractWhile it is has often been observed that theproduct of translation is somehow differentthan non-translated text, scholars have empha-sized two distinct bases for such differences.Some have noted interference from the sourcelanguage spilling over into translation in asource-language-specific way, while othershave noted general effects of the process oftranslation that are independent of source lan-guage.
Using a series of text categorizationexperiments, we show that both these effectsexist and that, moreover, there is a continuumbetween them.
There are many effects oftranslation that are consistent among textstranslated from a given source language, someof which are consistent even among textstranslated from families of source languages.Significantly, we find that even for widelyunrelated source languages and multiple ge-nres, differences between translated texts andnon-translated texts are sufficient for a learnedclassifier to accurately determine if a giventext is translated or original.1 IntroductionThe products of translation (written or oral) aregenerally assumed to be ontologically differentfrom non-translated texts.
Researchers have em-phasized two aspects of this difference.
Some(Baker 1993) have emphasized general effects ofthe process of translation that are independent ofsource language and regard the collective productof this process in a given target language as an ?in-terlanguage?
(Selinker, 1972), ?third code?
(Fraw-ley, 1984) or ?translationese?
(Gellerstam, 1986).Others (Toury, 1995) have emphasized the effectsof interference, the process by which a specificsource language leaves distinct marks or finger-prints in the target language, so that translationsfrom different source languages into the same tar-get language may be regarded as distinct dialectsof translationese.We wish to use text categorization methods toset both of these claims on a firm empirical foun-dation.
We will begin by bringing evidence for twoclaims:(1) Translations from different source languagesinto the same target language are sufficiently dif-ferent from each other for a learned classifier toaccurately identify the source language of a giventranslated text;(2) Translations from a mix of source languagesare sufficiently distinct from texts originally writ-ten in the target language for a learned classifier toaccurately determine if a given text is translated ororiginal.Each of these claims has been made before, butour results will strengthen them in a number ofways.
Furthermore, we will show that the degree ofdifference between translations from two sourcelanguages reflects the degree of difference betweenthe source languages themselves.
Translationsfrom cognate languages differ from non-translatedtexts in similar ways, while translations from unre-lated languages differ from non-translated texts indistinct ways.
The same result holds for families oflanguages.The outline of the paper is as follows.
In the fol-lowing section, we show that translations from dif-ferent source languages can be distinguished fromeach other and that closely related source languag-es manifest similar forms of interference.
In sec-tion 3, we show that, in a corpus involving fiveEuropean languages, we can distinguish translatio-nese from non-translated text and we considersome salient markers of translationese.
In section13184, we consider the extent to which markers oftranslationese cross over into non-European lan-guages as well as into different genres.
Finally, weconsider possible applications and implications forfuture studies.2 Interference Effects in TranslationeseIn this section, we perform several text categoriza-tion experiments designed to show the extent towhich interference affects (both positively and ne-gatively) our ability to classify documents.2.1 The Europarl CorpusThe main corpus we will use throughout this paperis Europarl (Koehn, 2005), which consists of tran-scripts of addresses given in the European Parlia-ment.
The full corpus consists of texts translatedinto English from 11 different languages (and viceversa), as well as texts originally produced in Eng-lish.
For our purposes, it will be sufficient to usetranslations from five languages (Finnish, French,German, Italian and Spanish), as well as originalEnglish.
We note that this corpus constitutes acomparable corpus (Laviosa, 1997), since it con-tains (1) texts written originally in a certain lan-guage (English), as well as (2) texts translated intothat same language, matched for genre, domain,publication timeframe, etc.
Each of the five trans-lated components is a text file containing just un-der 500,000 words; the original English componentis a file of the same size as the aggregate of theother five.The five source languages we use were selectedby first eliminating several source languages forwhich the available text was limited and thenchoosing from among the remaining languages,those of varying degrees of pairwise similarity.Thus, we select three cognate (Romance) languag-es (French, Italian and Spanish), a fourth less re-lated language (German), and a fifth even furtherremoved (Finnish).
As will become clear, the mo-tivation is to see whether the distance between thelanguages impacts the distinctiveness of the trans-lation product.We divide each of the translated corpora into250 equal chunks, paying no attention to naturalunits within the corpus.
Similarly, we divide theoriginal English corpus into 1250 equal chunks.We set aside 50 chunks from each of the translatedcorpora and 250 chunks from the original Englishcorpus for development purposes (as will be ex-plained below).
The experiments described belowuse the remaining 1000 translated chunks and 1000original English chunks.2.2 Identifying source languageOur objective in this section is to measure the ex-tent to which translations are affected by sourcelanguage.
Our first experiment will be to use textcategorization methods to learn a classifier thatcategorizes translations according to source lan-guage.
We will check the accuracy of such clas-sifiers on out-of-sample texts.
High accuracywould reflect that there are exploitable differencesamong translations of otherwise comparable textsthat differ only in terms of source language.The details of the experiment are as follows.
Weuse the 200 chunks from each translated corpus, asdescribed above.
We use as our feature set a list of300 function words taken from LIWC (Pennebak-er, 2001) and represent each chunk as a vector ofsize 300 in which each entry represents the fre-quency of the corresponding feature in the chunk.The restriction to function words is crucial; wewish to rely only on stylistic differences rather thancontent differences that might be artifacts of thecorpus.We use Bayesian logistic regression (Madigan,2005) as our learning method in order to learn aclassifier that classifies a given text into one of fiveclasses representing the different source languages.We use 10-fold cross-validation as our testing me-thod.We find that 92.7% of documents are correctlyclassified.In Table 1 we show the confusion matrix for thefive languages.
As can be seen, there are more mis-takes across the three cognate languages than be-tween those three languages and German and stillfewer mistakes involving the more distant Finnishlanguage.It Fr Es De FiIt 169 19 8 4 0Fr 18 161 12 8 1Es 3 11 172 11 3De 4 12 3 178 3Fi 0 1 2 5 192Table 1: Confusion matrix for 10-fold cross validationexperiment to determine source language of texts trans-lated into English1319This result strengthens that of van Halteren(2008) in a similar experiment.
Van Halteren, alsousing Europarl (but with Dutch as the fifth sourcelanguage, rather than Finnish), obtained accuracyof 87.2%-96.7% for a two-way decision on sourcelanguage, and 81.5%-87.4% for a six-way decision(including the original which has no source lan-guage).
Significantly, though, van Halteren?s fea-ture set included content words and he notes thatmany of the most salient differences reflected dif-ferences in thematic emphasis.
By restricting ourfeature set to function words, we neutralize sucheffects.In Table 2, we show the two words most over-represented and the two words most under-represented in translations from each source lan-guage (ranked according to an unpaired T-test).For each of these, the difference between frequen-cy of use in the indicated language and frequencyof use in the other languages in aggregate is signif-icant at p<0.01.over-represented under-representedFr of, finally here, alsoIt upon, moreover also, hereEs with, therefore too, thenDe here, then of, moreoverFi be, example me, whichTable 2: Most salient markers of translations from eachsource language.The two most underrepresented words forFrench and Italian, respectively, are in fact identic-al.
Furthermore, the word too which is underrepre-sented for Spanish is a near synonym of also whichappears in both French and Spanish.
This suggeststhe possibility that interference effects in cognatelanguages such as French, Italian and Spanishmight be similar.
We will see presently that this isin fact the case.When a less related language is involved we seethe opposite picture.
For German, both underrepre-sented items appear as overrepresented in theRomance languages, and, conversely, underrepre-sented items in the Romance languages appear asoverrepresented items for German.
This may castdoubt on the idea that all translations share univer-sal properties and that at best we may claim thatparticular properties are shared by closely relatedlanguages but not others.
In the experiments pre-sented in the next subsection, we?ll find that trans-lationese is gradable: closely related languagesshare more features, yet even further removed lan-guages share enough properties to hold the generaltranslationese hypothesis as valid.2.3 Identifying translationese per source lan-guageWe now wish to measure in a subtler manner theextent to which interference affects translation.
Inthis experiment, the challenge is to learn a classifi-er that classifies a text as belonging to one of onlytwo classes: original English (O) or translated-into-English (T).
The catch is that all our training textsfor the class T will be translations from some fixedsource language, while all our test documents in Twill be translations from a different source lan-guage.
What accuracy can be achieved in such anexperiment?
The answer to this question will tellus a great deal about how much of translationese isgeneral and how much of it is language dependent.If accuracy is close to 100%, translationese is pure-ly general (Baker, 1993).
(We already know fromthe previous experiment that that's not the case.).
Ifaccuracy is near 50%, there are no general effects,just language-dependent ones.
Note that, whereasin our first experiment above pair-specific interfe-rence facilitated good classification, in this expe-riment pair-specific interference is an impedimentto good classification.The details of the experiment are as follows.
Wecreate, for example, a ?French?
corpus consistingof the 200 chunks of text translated from Frenchand 200 original English texts.
We similarly createa corpus for each of the other source languages,taking care that each of the 1000 original Englishtexts appears in exactly one of the corpora.
Asabove, we represent each chunk in terms of fre-quencies of function words.
Now, using Bayesianlogistic regression, we learn a classifier that distin-guishes T from O in the French corpus.
We thenapply this learned classifier to the texts in, for ex-ample, the equivalent ?Italian?
corpus to see if wecan classify them as translated or original.
We re-peat this for each of the 25 ?train_corpus,test_corpus?
pairs.In Table 3, we show the accuracy obtained foreach such pair.
(For the case where the trainingcorpus and testing corpus are identical ?
the di-1320agonal of the matrix ?
we show results for ten-foldcross-validation.
)We note several interesting facts.
First, results ofcross-validation within each corpus are verystrong.
For any given source language, it is quiteeasy to distinguish translations from original Eng-lish.
This corroborates results obtained by Baroniand Bernardini (2006), Ilisei et al (2010), Kuro-kawa et al (2009) and van Halteren (2008), whichwe will discuss below.We note further, that for the cases where wetrain on one source language and test on another,results are far worse.
This clearly indicates thatinterference effects from one source languagemight be misleading when used to identify transla-tions from a different language.
Thus, for example,in the Finnish corpus, the word me is a strong indi-cator of original English (constituting 0.0003 oftokens in texts translated from Finnish as opposedto 0.0015 of tokens in original English texts), butin the German corpus, me is an indicator of trans-lated text (constituting 0.0020 of tokens in texttranslated from German).The most interesting result that can be seen inthis table is that the accuracy obtained when train-ing using language x and testing using language ydepends precisely on the degree of similarity be-tween x and y.
Thus, for training and testing withinthe three cognate languages, results are fairlystrong, ranging between 84.5% and 91.5%.
Fortraining/testing on German and testing/training onone of the other European languages, results areworse, ranging from 68.5% to 83.3%.
Finally, fortraining/testing on Finnish and testing/training onany of the European languages, results are stillworse, hovering near 60% (with the single unex-plained outlier for training on German and testingon Finnish).Finally, we note that even in the case of trainingor testing on Finnish, results are considerably bet-ter than random, suggesting that despite the con-founding effects of interference, some generalproperties of translationese are being picked up ineach case.
We explore these in the following sec-tion.3 General Properties of TranslationeseHaving established that there are source-language-dependent effects on translations, let?s now con-sider source-language-independent effects ontranslation.3.1 Identifying translationeseIn order to identify general effects on translation,we now consider the same two-class classificationproblem as above, distinguishing T from O, exceptthat now the translated texts in both our train andtest data will be drawn from multiple source lan-guages.
If we succeed at this task, it must be be-cause of features of translationese that crosssource-languages.The details of our experiment are as follows.
Weuse as our translated corpus, the 1000 translatedchunks (200 from each of five source languages)and as our original English corpus all 1000 originalEnglish chunks.
As above, we represent eachchunk in terms of function words frequencies.
Weuse Bayesian logistic regression to learn a two-class classifier and test its accuracy using ten-foldcross-validation.Remarkably, we obtain accuracy of 96.7%.This result extends and strengthens results re-ported in some earlier studies.
Ilisei et al (2010),Kurokawa (2009) and van Halteren (2008) eachobtained above 90% accuracy in distinguishingtranslation from original.
However, in each casethe translations were from a single source lan-guage.
(Van Halteren considered multiple sourcelanguages, but each learned classifier used onlyone of them.)
Thus, those results do not prove thattranslationese has distinctive source-language-independent features.
To our knowledge, the onlyearlier work that used a learned classifier to identi-fy translations in which both test and train sets in-volved multiple source languages is Baroni andBernardini (2006), in which the target languagewas Italian and the source languages were knownto be varied.
The actual distribution of source lan-guages was, however, not known to the research-ers.
They obtained accuracy of 86.7%.
Their resultwas obtained using combinations of lexical andsyntactic features.TrainIt Fr Es De FiIt 98.3 91.5 86.5 71.3 61.5Fr 91 97 86.5 68.5 60.8Es 84.5 88.3 95.8 76.3 59.5De 82 83.3 78.5 95 80.8Fi 56 60.3 56 62.3 97.3Table 3: Results of learning a T vs. O classifier us-ing one source language and testing it using anothersource language13213.2 Some distinguishing featuresLet us now consider some of the most salient func-tion words for which frequency of usage in T dif-fers significantly from that in O.
While there aremany such features, we focus on two categories ofwords that are most prominent among those withthe most significant differences.First, we consider animate pronouns.
In Table 4,we show the frequencies of animate pronouns in Oand T, respectively (the possessive pronouns, mine,yours and hers, not shown, are extremely rare inthe corpus).
As can be seen, all pronouns are un-der-represented in T; for most (bolded), the differ-ence is significant at p<0.01.By contrast, the word the is significantly overre-presented in T (15.32% in T vs. 13.73% in O; sig-nificant at p<0.01).word freq O freq TI 2.552% 2.148%we 2.713% 2.344%you 0.479% 0.470%he 0.286% 0.115%she 0.081% 0.039%me 0.148% 0.141%us 0.415% 0.320%him 0.066% 0.033%her 0.091% 0.056%my 0.462% 0.345%our 0.696% 0.632%your 0.119% 0.109%his 0.218% 0.123%Table 4: Frequency of pronouns  in O and T in the Eu-roparl corpus.
Bold indicates significance at p<0.01.In Table 5, we consider cohesive markers,tagged as adverbs (Schmid, 2004).
(These are ad-verbs that can appear at the beginning of a sen-tence followed immediately by a comma.
)word freq O freq Ttherefore 0.153% 0.287%thus 0.015% 0.041%consequently 0.006% 0.014%hence 0.007% 0.013%accordingly 0.006% 0.011%however 0.216% 0.241%nevertheless 0.019% 0.045%also 0.460% 0.657%furthermore 0.012% 0.048%moreover 0.008% 0.036%indeed 0.098% 0.053%actually 0.065% 0.042%Table 5: Frequency of cohesive adverbs  in O and T inthe Europarl corpus.
Bold indicates significance atp<0.01.We note that the preponderance of such cohesivemarkers are significantly more frequent in transla-tions.
In fact, we also find that a variety of phrasesthat serve the same purpose as cohesive adverbs,such as in fact and as a result are significantlymore frequent in translationese.The general principle underlying these pheno-mena is subject to speculation.
Previous research-ers have noted the phenomenon of explicitation,according to which translators tend to render im-plicit utterances in the source text into explicit ut-terances in the target text (Blum-Kulka, 1986,Laviosa-Braithwaite, 1998), for example by fillingout elliptical expressions or adding connectives toincrease cohesion of the text (Laviosa-Braithwaite,1998).
It is plausible that the use of cohesive ad-verbs is an instantiation of this phenomenon.With regard to the under-representation of pro-nouns and the over-representation of the, there area number of possible interpretations.
It may be thatthis too is the result of explicitation, in which ana-phora is resolved by replacing pronouns with nounphrases (e.g., the man instead of he).
But it alsomight be that this is an example of simplification(Laviosa- Braithwaite 1998, Laviosa 2002), ac-cording to which the translator simplifies the mes-sage, the language, or both.
Related resultsconfirming the simplification hypothesis werefound by Ilisei et al (2010) on Spanish texts.
Inparticular, they found that type-to-token ratio (lexi-cal variety/richness), mean sentence length andproportion of grammatical words (lexical densi-ty/readability) are all smaller in translated texts.We note that Van Halteren (2008) and Kurokawaet al (2009), who considered lexical features,found cultural differences, like over-representationof ladies and gentlemen in translated speeches.Such differences, while of general interest, are or-thogonal to our purposes in this paper.13223.3 Overriding language-specific effectsWe found in Section 2.3 that when we trained inone language and tested in another, classificationsucceeded to the extent that the source languagesused in training and testing, respectively, are re-lated to each other.
In effect, general differencesbetween translationese and original English werepartially overwhelmed by language-specific differ-ences that held for the training language but not thetest language.
We thus now revisit that earlier ex-periment, but restrict ourselves to features that dis-tinguish translationese from original Englishgenerally.To do this, we use the small development corpusdescribed in Section 2.1.
We use Bayesian logisticregression to learn a classifier to distinguish be-tween translationese and original English.
We se-lect the 10 highest-weighted function-wordmarkers for T and the 10 highest-weighted func-tion-word markers for O in the development cor-pus.
We then rerun our train-on-source-language-x,test-on-source-language-y experiment using thisrestricted set as our feature set.
We now find thateven in the difficult case where we train on Finnishand test on another language (or vice versa), wesucceed at distinguishing translationese from orig-inal English with accuracy above 80%.
This consi-derably improves the earlier results shown in Table3.
Thus, a bit of feature engineering facilitateslearning a good classifier for T vs. O even acrosssource languages.4 Other Genres and Language FamiliesWe have found both general and language-specificdifferences between translationese and originalEnglish in one large corpus.
It might be wonderedwhether the phenomena we have found hold inother genres and for a completely different set ofsource languages.
To test this, we consider asecond corpus.4.1 The IHT corpusOur second corpus includes three translated corpo-ra, each of which is an on-line local supplement tothe International Herald Tribune (IHT): Kathime-rini (translated from Greek), Ha?aretz (translatedfrom Hebrew), and the JoongAng Daily (translatedfrom Korean).
In addition, the corpus includesoriginal English articles from the IHT.
Each of thefour components contains four different domainsbalanced roughly equally: news (80,000 words),arts and leisure (50,000), business and finance(50,000), and opinion (50,000) and each covers theperiod from April-September 2004.
Each compo-nent consists of about 230,000 tokens.
(Unlike forour Europarl corpus, the amount of English textavailable is not equal to the aggregate of the trans-lated corpora, but rather equal to each of the indi-vidual corpora.
)It should be noted that the IHT corpus belongsto the writing modality while the Europarl corpusbelongs to the speaking modality (although possi-bly post-edited).
Furthermore, the source languag-es (Hebrew, Greek and Korean) in the IHT corpusare more disparate than those in the Europarl cor-pus.Our first objective is to confirm that the resultswe obtained earlier on the Europarl corpus hold forthe IHT corpus as well.Perhaps more interestingly, our second objectiveis to see if the gradability phenomenon observedearlier (Table 3) generalizes to families of lan-guages.
Our first hypothesis is that a classifier foridentifying translationese that is trained on Euro-parl will succeed only weakly to identify transla-tionese in IHT.
But our second hypothesis is thatthere are sufficient general properties of translatio-nese that cross language families and genres that alearned classifier can accurately identify transla-tionese even on a test corpus that includes bothcorpora, spanning eight disparate languages acrosstwo distinct genres.4.2 Results on IHT corpusRunning essentially the same experiments as de-scribed for the Europarl corpus, we obtain the fol-lowing results.First of all, we can determine source languagewith accuracy of 86.5%.
This is a somewhat weak-er result than the 92.7% result obtained on Euro-parl, especially considering that there are onlythree classes instead of five.
The difference is mostlikely due to the fact that the IHT corpus is abouthalf the size of the Europarl corpus.
Nevertheless,it is clear that source language strongly affectstranslationese in this corpus.Second, as can be seen in Table 6, we find thatthe gradability phenomenon occurs in this corpusas well.
Results are strongest when the train and1323test corpora involve the same source language andtrials involving Korean, the most distant language,are somewhat weaker than those across Greek andHebrew.TrainGr He KoGr 89.8 73.4 64.8He 82.0 86.3 65.5Ko 73.0 72.5 85.0Table 6: Results of learning a T vs. O classifier usingone source language and testing it using another sourcelanguageThird, we find in ten-fold cross-validation expe-riments that we can distinguish translationese fromoriginal English in the IHT corpus with accuracyof 86.3%.
Thus, despite the great distance betweenthe three source languages in this corpus, generaldifferences between translationese and originalEnglish are sufficient to facilitate reasonably accu-rate identification of translationese.4.3 Combining the corporaFirst, we consider whether a classifier learned onthe Europarl corpus can be used to identify trans-lationese in the IHT corpus, and vice versa.
Itwould be consistent with our findings in Section2.3, that we would achieve better than randomresults but not high accuracy, since there are nodoubt features common to translations from thefive European languages of Europarl that are dis-tinct from those of translations from the very dif-ferent languages in IHT.In fact, we find that training on Europarl andtesting on IHT yields accuracy of 64.8%, whiletraining on IHT and testing on Europarl yieldsaccuracy of 58.8%.
The weak results reflect bothdifferences between the families of source lan-guages involved in the respective corpora, as wellas genre differences.
Thus, for example, we findthat of the pronouns shown in Table 4 above, onlyhe and his are significantly under-represented intranslationese in the IHT corpus.
Thus, that effectis specific either to the genre of Europarl or to theEuropean languages considered there.Now, we combine the two corpora and check ifwe can identify translationese across two genresand eight languages.
We run the same experimentsas described above, using 200 texts from each ofthe eight source languages and 1600 non-translatedEnglish texts, 1000 from Europarl and 600 fromIHT.In 10-fold cross-validation, we find that we candistinguish translationese from non-translated Eng-lish with accuracy of 90.5%.This shows that there are features of translatio-nese that cross genres and widely disparate lan-guages.
Thus, for one prominent example, we findthat, as in Europarl, the word the is over-represented in translationese in IHT (15.36% in Tvs.
13.31% in O; significant at p<0.01).
In fact, thefrequencies across corpora are astonishingly con-sistent.To further appreciate this point, let?s look at thefrequencies of cohesive adverbs in the IHT corpus.We find essentially, the same pattern in IHT aswe did in Europarl.
The preponderance of cohesiveadverbs are over-represented in translationese,most of them with differences significant atp<0.01.
Curiously, the word actually is a counter-example in both corpora.5 ConclusionsWe have found that we can learn classifiers thatdetermine source language given a translated text,as well as classifiers that distinguish translated textfrom non-translated text in the source language.These text categorization experiments suggest thatboth source language and the mere fact of beingword freq O freq Ttherefore 0.011% 0.031%thus 0.011% 0.027%consequently 0.000% 0.004%hence 0.003% 0.007%accordingly 0.003% 0.003%however 0.078% 0.129%nevertheless 0.008% 0.018%also 0.305% 0.453%furthermore 0.003% 0.011%moreover 0.009% 0.008%indeed 0.018% 0.024%actually 0.032% 0.018%Table 7: Frequency of cohesive adverbs in O and Tin the IHT corpus.
Bold indicates significance atp<0.01.1324translated play a crucial role in the makeup of atranslated text.It is important to note that our learned classifiersare based solely on function words, so that, unlikeearlier studies, the differences we find are unlikelyto include cultural or thematic differences thatmight be artifacts of corpus construction.In addition, we find that the exploitability of dif-ferences between translated texts and non-translated texts are related to the difference be-tween source languages: translations from similarsource languages are different from non-translatedtexts in similar ways.Linguists use a variety of methods to quantifythe extent of differences and similarities betweenlanguages.
For example, Fusco (1990) studiestranslations between Spanish and Italian and con-siders the impact of structural differences betweenthe two languages on translation quality.
Studyingthe differences and distance between languages bycomparing translations into the same language mayserve as another way to deepen our typologicalknowledge.
As we have seen, training on sourcelanguage x and testing on source language y pro-vides us with a good estimation of the distance be-tween languages, in accordance with what we findin standard works on typology (cf.
Katzner, 2002).In addition to its intrinsic interest, the findingthat the distance between languages is directly cor-related with our ability to distinguish translationsfrom a given source language from non-translatedtext is of great importance for several computa-tional tasks.
First, translations can be studied inorder to shed new light on the differences betweenlanguages and can bear on attested techniques forusing cognates to improve machine translation(Kondrak & Sherif, 2006).
Additionally, given theresults of our experiments, it stands to reason thatusing translated texts, especially from relatedsource languages, will prove beneficial for con-structing language models and will outperformresults obtained from non-translated texts.
This,too, bears on the quality of machine translation.Finally, we find that there are general propertiesof translationese sufficiently strong that we canidentify translationese even in a combined corpusthat is comprised of eight very disparate languagesacross two distinct genres, one spoken and the oth-er written.
Prominent among these properties is theword the, as well as a number of cohesive adverbs,each of which is significantly over-represented intranslated texts.ReferencesMona Baker.
1993.
Corpus linguistics and translationstudies: Implications and applications.
In Gill FrancisMona Baker and Elena Tognini Bonelli, editors, Textand technology: in honour of John Sinclair, pages233-252.
John Benjamins, Amsterdam.Marco Baroni and Silvia Bernardini.
2006.
A new ap-proach to the study of Translationese: Machine-learning the difference between original and trans-lated text.
Literary and Linguistic Computing,21(3):259-274.Shoshan Blum-Kulka.
Shifts of cohesion and coherencein translation.
1986.
In Juliane House and ShoshanaBlum-Kulka (Eds), Interlingual and InterculturalCommunication (17-35).
T?bingen: G?nter Narr Ver-lag.William Frawley.
1984.
Prolegomenon to a theory oftranslation.
In William Frawley (ed), Translation.
Li-terary, Linguistic and Philosophical Perspectives(179-175).
Newark: University of Delaware Press.Maria Antonietta Fusco.
1990.
Quality in conferenceinterpreting between cognate languages: A prelimi-nary approach to the Spanish-Italian case.
The Inter-preters?
Newsletter, 3, 93-97.Martin Gellerstam.
1986.
Translationese in Swedishnovels translated from English, in Lars Wollin &Hans Lindquist (eds.
), Translation Studies in Scandi-navia (88-95).
Lund: CWK Gleerup.Iustina Ilisei, Diana Inkpen, Gloria Corpas Pastor, andRuslan Mitkov.
Identification of translationese: Amachine learning approach.
In Alexander F. Gel-bukh, editor, Proceedings of CICLing-2010: Compu-tational Linguistics and Intelligent Text Processing,11th International, volume 6008 of Lecture Notes inComputer Science, pages 503-511.
Springer, 2010.Kenneth Katzner.
2002.
The Languages of the World.Routledge.Grzegorz Kondrak and Tarek Sherif.
2006.
Evaluationof several phonetic similarity algorithms on the taskof cognate identification.
In Proceedings of theWorkshop on Linguistic Distances (LD '06).
43-50.David Kurokawa, Cyril Goutte, and Pierre Isabelle.2009.
Automatic detection of translated text and itsimpact on machine translation.
In Proceedings ofMT-Summit XII.Sara Laviosa: 1997.
How Comparable can 'ComparableCorpora' Be?.
Target, 9 (2), pp.
289-319.1325Sara Laviosa-Braithwaite.
1998.
In Mona Baker (ed.
)Routledge Encyclopedia of Translation Studies.
Lon-don/New York: Routledge, pp.288-291.Sara Laviosa.
2002.
Corpus-based Translation Studies.Theory, Findings, Applications.
Amsterdam/NewYork: Rodopi.David Madigan, Alexander Genkin, David D. Lewis andDmitriy Fradkin 2005.
Bayesian Multinomial Logis-tic Regression for Author Identification, In MaxentConference, 509-516.James W. Pennebaker, Martha E. Francis, and Roger J.Booth.
2001.
Linguistic Inquiry and Word Count(LIWC): LIWC2001 Manual.
Erlbaum Publishers,Mahwah, NJ, USA.Helmut Schmid.
Probabilistic Part-of-Speech TaggingUsing Decision Trees.
2004.
In Proceedings of In-ternational Conference on New Methods in Lan-guage Processing.Larry Selinker.1972.
Interlanguage.
International Re-view of Applied Linguistics.
10, 209-241.Gideon Toury.
1995.
Descriptive Translation Studiesand beyond.
John Benjamins, Amsterdam / Philadel-phia.Hans van Halteren.
2008.
Source language markers inEUROPARL translations.
In COLING '08: Proceed-ings of the 22nd International Conference on Compu-tational Linguistics, pages 937-944.1326
