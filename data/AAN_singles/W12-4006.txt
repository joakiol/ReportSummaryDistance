Proceedings of the 3rd Workshop on the People?s Web Meets NLP, ACL 2012, pages 34?43,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsExtracting Context-Rich Entailment Rules from Wikipedia Revision HistoryElena CabrioINRIA2004, route de Lucioles BP9306902 Sophia Antipolis, France.elena.cabrio@inria.frBernardo MagniniFBKVia Sommarive 1838100 Povo-Trento, Italy.magnini@fbk.euAngelina IvanovaUniversity of OsloGaustadalle?en 23BOle-Johan Dahls husN-0373 Oslo, Norway.angelii@ifi.uio.noAbstractRecent work on Textual Entailment has showna crucial role of knowledge to support entail-ment inferences.
However, it has also beendemonstrated that currently available entail-ment rules are still far from being optimal.
Wepropose a methodology for the automatic ac-quisition of large scale context-rich entailmentrules from Wikipedia revisions, taking advan-tage of the syntactic structure of entailmentpairs to define the more appropriate linguis-tic constraints for the rule to be successfullyapplicable.
We report on rule acquisition ex-periments on Wikipedia, showing that it en-ables the creation of an innovative (i.e.
ac-quired rules are not present in other availableresources) and good quality rule repository.1 IntroductionEntailment rules have been introduced to providepieces of knowledge that may support entailmentjudgments (Dagan et al, 2009) with some degree ofconfidence.
More specifically, an entailment rule isdefined (Szpektor et al, 2007) as a directional rela-tion between two sides of a pattern, correspondingto text fragments with variables (typically phrasesor parse sub-trees).
The left-hand side (LHS) ofthe pattern entails the right-hand side (RHS) of thesame pattern under the same variable instantiation.Given the Text-Hypothesis pair (T-H) in Example 1:Example 1.T: Dr. Thomas Bond established a hospital in Philadel-phia for the reception and cure of poor sick persons.H: Dr.
Bond created a medical institution for sick people.a (directional) lexical rule like:1) LHS: hospital?
RHS: medical institutionprobability: 0.8brings to a TE system (aimed at recognizing thata particular target meaning can be inferred fromdifferent text variants in several NLP application,e.g.
Question Answering or Information Extraction)the knowledge that the word hospital in Text canbe aligned, or transformed, into the word medicalinstitution in the Hypothesis, with a probability 0.8that this operation preserves the entailment relationamong T and H. Similar considerations apply formore complex rules involving verbs, as:2) LHS: X establish Y ?
RHS: X create Yprobability: 0.8where the variables may be instantiated by any tex-tual element with a specified syntactic relation withthe verb.
Both kinds of rules are typically ac-quired either from structured sources (e.g.
WordNet(Fellbaum, 1998)), or from unstructured sources ac-cording for instance to distributional properties (e.g.DIRT (Lin and Pantel, 2001)).
Entailment rulesshould typically be applied only in specific contexts,defined in (Szpektor et al, 2007) as relevant con-texts.
Some existing paraphrase and entailment ac-quisition algorithms add constraints to the learnedrules (e.g.
(Sekine, 2005), (Callison-Burch, 2008)),but most do not.
Because of a lack of an adequaterepresentation of the linguistic context in which the34rules can be successfully applied, their concrete usereflects this limitation.
For instance, rule 2 (ex-tracted from DIRT) fails if applied to ?The mathe-matician established the validity of the conjecture?,where the sense of establish is not a synonym ofcreate (but of prove, demonstrate), decreasing sys-tem?s precision.
Moreover, these rules often sufferfrom lack of directionality, and from low accuracy(i.e.
the strength of association of the two sides ofthe rule is often weak, and not well defined).
Suchobservations are also in line with the discussion onablation tests carried out at the last RTE evaluationcampaigns (Bentivogli et al, 2010).Additional constraints specifying the variabletypes are therefore required to correctly instantiatethem.
In this work, we propose to take advantageof Collaboratively Constructed Semantic Resources(CSRs) (namely, Wikipedia) to mine informationuseful to context-rich entailment rule acquisition.More specifically, we take advantage of material ob-tained through Wikipedia revisions, which providesat the same time real textual variations from whichwe may extrapolate the relevant syntactic context,and several simplifications with respect to alterna-tive resources.
We consider T-H pairs where T is arevision of a Wikipedia sentence and H is the origi-nal sentence, as the revision is considered more in-formative then the revised sentence.We demonstrate the feasibility of the proposedapproach for the acquisition of context-rich rulesfrom Wikipedia revision pairs, focusing on two casestudies, i.e.
the acquisition of entailment rules forcausality and for temporal expressions.
Both phe-nomena are highly frequent in TE pairs, and for boththere are no available resources yet.
The result ofour experiments consists in a repository that can beused by TE systems, and that can be easily extendedto entailment rules for other phenomena.The paper is organized as follows.
Section 2reports on previous work, highlighting the speci-ficity of our work.
Section 3 motivates and de-scribes the general principles underlying our ac-quisition methodology.
Section 4 describes in de-tails the steps for context-rich rules acquisition fromWikipedia pairs.
Section 5 reports about the experi-ments on causality and temporal expressions and theobtained results.
Finally, Section 6 concludes the pa-per and suggests directions for future improvements.2 Related workThe use of Wikipedia revision history in NLP taskshas been previously investigated by a few works.In (Zanzotto and Pennacchiotti, 2010), two versionsof Wikipedia and semi-supervised machine learningmethods are used to extract large TE data sets sim-ilar to the ones provided for the RTE challenges.
(Yatskar et al, 2010) focus on using edit historiesin Simple English Wikipedia to extract lexical sim-plifications.
Nelken and Yamangil (2008) comparedifferent versions of the same document to collectusers?
editorial choices, for automated text correc-tion, sentence compression and text summarizationsystems.
(Max and Wisniewski, 2010) use the revi-sion history of French Wikipedia to create a corpusof natural rewritings, including spelling corrections,reformulations, and other local text transformations.In (Dutrey et al, 2011), a subpart of this corpus isanalyzed to define a typology of local modifications.Because of its high coverage, Wikipedia is usedby the TE community for lexical-semantic rules ac-quisition, named entity recognition, geographical in-formation1 (e.g.
(Mehdad et al, 2009), (Mirkin etal., 2009), (Iftene and Moruz, 2010)), i.e.
to provideTE systems with world and background knowledge.However, so far it has only been used as source offactual knowledge, while in our work the focus is onthe acquisition of more complex rules, concerningfor instance spatial or temporal expressions.The interest of the research community in produc-ing specific methods to collect inference and para-phrase pairs is proven by a number of works in thefield, which are relevant to the proposed approach.As for paraphrase, Sekine?s Paraphrase Database(Sekine, 2005) is collected using an unsupervisedmethod, and focuses on phrases connecting twoNamed Entities.
In the Microsoft Research Para-phrase Corpus2, pairs of sentences are extractedfrom news sources on the web, and manually an-notated.
As for rule repositories collected using dis-tributional properties, DIRT (Discovery of InferenceRules from Text)3 is a collection of inference rules1http://www.aclweb.org/aclwiki/index.php?title=RTE_Knowledge_Resources2http://research.microsoft.com/en-us/downloads3http://www.aclweb.org/aclwiki/index.php?title=DIRT_Paraphrase_Collection35(Lin and Pantel, 2001), obtained extracting binaryrelations between a verb and an object-noun (or asmall clause) from dependency trees.
Barzilay andLee (2003) present an approach for generating sen-tence level paraphrases, learning structurally simi-lar patterns of expression from data and identifyingparaphrasing pairs among them using a comparablecorpus.
Since the data sets cited so far are para-phrase collections, rules are bidirectional, while oneof the peculiarities of the entailment relation is thedirectionality, addressed in our work.Aharon et al (2010) presented FRED, an algo-rithm for generating entailment rules between pred-icates from FrameNet.
Moreover, the TEASE col-lection of entailment rules (Szpektor et al, 2004)consists of 136 templates provided as input, plusall the learned templates.
Their web-based extrac-tion algorithm is applied to acquire verb-based ex-pressions.
No directionality of the pairs is specified,but additional guessing mechanisms it are proposed.In (Szpektor and Dagan, 2008), two approaches forunsupervised learning of unary rules (i.e.
betweentemplates with a single variable) are investigated.In (Zhao et al, 2009), a pivot approach for ex-tracting paraphrase patterns from bilingual paral-lel corpora is presented, while in (Callison-Burch,2008) the quality of paraphrase extraction from par-allel corpora is improved by requiring that phrasesand their paraphrases have the same syntactic type.Our approach is different from theirs in many re-spects: their goal is paraphrase extraction, while weare extracting directional entailment rules; as textualresources for pattern extraction they use parallel cor-pora (using patterns in another language as pivots),while we rely on monolingual Wikipedia revisions(taking benefit from its increasing size); the para-phrases they extract are more similar to DIRT, whileour approach allows to focus on the acquisition ofrules for specific phenomena frequent in entailmentpairs, and not covered by other resources.3 General methodologyThe general approach we have implemented is basedon the idea that, given a seed word, we extract allthe entailment rules from Wikipedia revision pairswhere the seed word appears as the head of the ruleeither in T or H. The head is the non-variable partof the rule on which the other parts depend (i.e.
theword establish is the head of rule 2).Entailment judgment.
A Wikipedia revision maybe consistent with the original sentence, bringing toan entailment relation, or it may introduce inconsis-tency, expressing a contradiction w.r.t.
the originalsentence.
We manually checked a sample of revisionpairs (?200), and we found out that in about 95%of the revisions entailment is preserved, in line with(Zanzotto and Pennacchiotti, 2010).
We assume thisone as the default case in our experiments.Monothematic pairs.
The capability of automaticextraction of entailment rules is affected by the com-plexity of the pairs from which we extract the rules.In our experiments we take advantage of revisionpairs with minimal difference between T and H, andwe assume that for such pairs we have only one ruleto extract.
Under this perspective, T-H pairs derivedfrom Wikipedia revisions have strong similarity withmonothematic pairs (i.e.
pairs where the entailmentjudgment is due to only one linguistic phenomenon,as suggested in (Bentivogli et al, 2010)).
Section4.2 describes the algorithm for filtering out revisionpairs with more than one phenomenon.Directionality.
A Wikipedia revision, in principle,may be interpreted as either T entailing H, or as Hentailing T. However, through a manual inspectionof a revision sample (?200 pairs), it came out thatin most of the cases the meaning of the revised sen-tence (T) entails the meaning of the original one (H).Given such observation, for our experiments (Sec-tions 4 and 5) we assume that for all revision pairs,the revised sentence (T) entails the original one (H).Context of a rule.
We have defined the notion ofcontext of a rule R as a set of morpho-syntactic con-straints C over the application of R in a specific T-Hpair.
Ideally, the set of such constraints should bethe minimal set of constraints over R such that theproportion of successful applications of R is max-imized (e.g.
the precision-recall mean is highest).Intuitively, given an entailment rule, in absence ofconstraints we have the highest recall (the rule is al-ways applied when the LHS is activated in T andthe RHS is activated in H), although we may findcases of wrong application of the rule (i.e.
low preci-sion).
On the other side, as syntactic constraints are36required (e.g.
the subject of a verb has to be a noun)the number of successful applications increases, al-though we may find cases where the constraints pre-vent the correct application (e.g.
low recall).In the absence of a data set where we can em-pirically estimate precision and recall of rule appli-cation, we have approximated the ideal context onthe basis of linguistic intuitions.
More specifically,for different syntactic heads of the rules, we definethe most appropriate syntactic constraints through asearch algorithm over the syntactic tree produced onT and H (see Section 4.4 for a detailed explanation).4 Entailment rules acquisitionIn the next sections, the steps for the acquisition ofrules from Wikipedia pairs are described in detail.4.1 Step 1: preprocessing Wikipedia dumpsWe downloaded two dumps of the EnglishWikipedia (one dated 6.03.2009, Wiki 09, andone dated 12.03.2010, Wiki 10).4 We used thescript WikiExtractor.py5 to extract plain text fromWikipedia pages, discarding any other informationor annotation, but keeping the reference to the orig-inal document.
For our goal, we consider only non-identical documents present in both Wiki 09 and Wiki10 (i.e.
1,540,870 documents).4.2 Step 2: extraction of entailment pairsFor both Wiki 09 and Wiki 10 each document hasbeen sentence-splitted, and the sentences of the twoversions have been aligned to create pairs.
To mea-sure the similarity between the sentences in eachpair, we adopted the Position Independent Word Er-ror Rate (PER) (Tillmann et al, 1997), a metricbased on the calculation of the number of wordswhich differ between a pair of sentences (diff func-tion in (1)).
Such measure is based on Levenshteindistance, but works at word level, and allows for re-ordering of words and sequences of words betweenthe two texts (e.g.
a translated text s and a referencetranslation r).
It is expressed by the formula:PER(s, r) = diff(s,r)+diff(r,s)?r?
(1)4http://en.wikipedia.org/wiki/Wikipedia:Database_download5http://medialab.di.unipi.it/wiki/Wikipedia_ExtractorPairs are clustered according to different thresholds:?
Pairs composed by identical sentences werediscarded; if only one word was different in thetwo sentences, we checked if it was a typo cor-rection using (Damerau, 1964) distance.
If thatwas the case, we discarded such pairs as well.?
Pairs in which one of the sentences contains theother one, meaning that the users added someinformation to the new version, without modi-fying the old one (set a: 1,547,415 pairs).?
Pairs composed by very similar sentences,where users carried out minor editing (PER <0.2) (set b: 1,053,114 pairs).
We filtered outpairs where differences were correction of mis-spelling and typos, and two-word sentences.?
Pairs composed by sentences where major edit-ing was carried out (0.2 < PER < 0.6), but stilldescribe the same event (set c: 2,566,364).?
Pairs in which the similarity between sentencesis low (PER > 0.6) were discarded.To extract entailment rules, we consider only thepairs contained in set b.
For each pair, we intuitivelyset the sentence extracted from Wiki 10 as the Text,since we assume that it contains more (and moreprecise) information w.r.t.
the sentence extractedfrom Wiki 09.
We set the sentence extracted fromWiki 09 as the Hypothesis (see Examples 2 and 3).Example 2.T: The Oxford Companion to Philosophy says ?there isno single defining position that all anarchists hold [...]?H: According to the Oxford Companion to Philosophy?there is no single defining position that all anarchistshold [...] ?Example 3.T: Bicycles are used by all socio-economic groups be-cause of their convenience [...].H: Bicycles are used by all socio-economic groups due totheir convenience [...].4.3 Step 3: extraction of entailment rulesPairs in set b are collected in a data set, and pro-cessed with the Stanford parser (Klein and Manning,372003); chunks are extracted from each pair usingthe script chunklink.pl.6 The assumption underlyingour approach is that the difference between T andH (i.e.
the editing made by the user on a specificstructure) can be extracted from such pairs andidentified as an entailment rule.
The rule extractionalgorithm was implemented to this purpose.
Indetails, for each sentence pair the algorithm itera-tively compares the chunks of T and H to extractthe ones that differ.
It can be the case that severalchunks of H are identical to a given chunk of T, as in:T:<NP>[The DT][Oxford NNP][Companion NNP]</NP><PP>[to TO]</PP> <NP>[Philosophy NNP]</NP><VP>[says VBZ]</VP>...H:<PP>[According VBG]</PP><PP>[to TO]</PP><NP>[the DT][Oxford NNP][Companion NNP]</NP><PP>[to TO]</PP><NP>[Philosophy NNP]</NP>...Therefore, to decide for instance which chunk<PP>[to TO]</PP> from H corresponds to theidentical chunk in T, the algorithm checks if theprevious chunks are equal as well.
If this is thecase, such chunks are matched.
In the exampleabove, the second chunk <PP>to</PP> from His considered as a good match because previouschunks in T and H are equal as well (<NP>theOxford Companion</NP>).
If the previouschunks in T and H are not equal, the algorithmkeeps on searching.
If such match is not found, thealgorithm goes back to the first matching chunkand couples the chunk from T with it.
Rules arecreated setting the unmatched chunks from T asthe left-hand side of the rule, and the unmatchedchunks from H as the right-hand side of the rule.Two consecutive chunks (different in T and H) areconsidered part of the same rule.
For instance, fromExamples 2 and 3:2) <LHS> says </LHS><RHS> according to </RHS>3) <LHS> because of </LHS><RHS> due to </RHS>On the contrary, two non consecutive chunks gener-ate two different entailment rules.6http://ilk.uvt.nl/team/sabine/chunklink/README.html4.4 Step 4: rule expansion with minimalcontextAs introduced before, our work aims at providingprecise and context-rich entailment rules, to maxi-mize their correct application to RTE pairs.
So far,rules extracted by the rule extraction algorithm (Sec-tion 4.3) are too general with respect to our goal.To add the minimum context to each rule (as dis-cussed in Section 3), we implemented a rule expan-sion algorithm: both the file with the syntactic rep-resentation of the pairs (obtained with the Stanfordparser), and the file with the rules extracted at Step 3are provided as input.
For every pair, and separatelyfor T and H, the words isolated in the correspondingrule are matched in the syntactic tree of that sen-tence, and the common subsumer node is detected.Different strategies are applied to expand the rule,according to linguistic criteria.
In details, if thecommon subsumer node is i) a Noun Phrase (NP)node, the rule is left as it is; ii) a PrepositionalPhrase node (PP), all the terminal nodes of thesubtree below PP are extracted; iii) a clause intro-duced by a subordinating conjunction (SBAR), allthe terminal nodes of the subtree below SBAR areextracted; iv) an adjectival node (ADJP), all theterminal nodes of the tree below the ADJP nodeare extracted; v) a Verbal Phrase node (VP), thedependency tree under the VP node is extracted.For Example 3 (see Figure 1), the LHS of the rulebecause of is matched in the syntactic tree of T andthe prepositional phrase (PP) is identified as com-mon subsumer node.
All the terminal nodes and thePoS of the tree below PP are then extracted.
Thesame is done for the RHS of the rule, where the com-mon subsumer node is an adjectival phrase (ADJP).5 Experiments and resultsIn the previous section, we described the stepscarried out to acquire context-rich entailment rulesfrom Wikipedia revisions.
To show the applicabilityof the adopted methodology, we have performedtwo experiments focusing, respectively, on entail-ment rules for causality and temporal expressions.In particular, as case studies we chose two seeds:the conjunction because to derive rules for causality,and the preposition before for temporal expressions.38(a) LHS rule (b) RHS ruleFigure 1: Rule expansion with minimal context (Example 3)causality (because) temporal exp.
(before)(PP(RB because)(IN of)(NP(JJ)(NNS))?
(SBAR(IN before)(S))?
(ADJP(JJ due)(PP(TO to)(NP(JJ)(NNS)))) (ADVP(RB prior)(PP(TO to)(S)e.g.
: because of contractual conflicts ?
due to contractual conflicts e.g.
: before recording them ?
prior to recording them(SBAR(IN because)(S))?
(VP(PP(IN on)(NP(DT the) (ADVP(RB prior)(PP(TO to)(NP(DT)(NN))))?
(NNS grounds)))(SBAR (IN that)(S) (SBAR(IN before)(NP(DT)(NN)))e.g.
: because it penalized people ?
on the grounds that it penalized people e.g.
: prior to the crash ?
before the crash(PP(RB because)(IN of)(NP(DT)(NN)))?
(PP(IN as)(NP (SBAR(IN until)(NP(CD)))?
(NP(DT a)(NN result))(PP(IN of)(NP(DT)(NN))))) (SBAR(IN before)(NP(CD)))e.g.
: because of an investigation ?
as a result of an investigation e.g.
: until 1819 ?
before 1819Table 1: Sample of extracted entailment rules.Accordingly, we extracted from set b only the pairscontaining one of these two seeds (either in T orin H) and we built two separate data sets for ourexperiments.
We run the rule extraction algorithm,and then we filtered again the rules acquired, tocollect only those containing one of the two seeds(either in the LHS or in the RHS).
This secondfiltering has been done because there could be pairsin which either because or before are present, butthe differences in T and H do not concern thoseseeds.
The algorithm for rule expansion has thenbeen applied to the selected rules to add the minimalcontext.
The resulting rule for Example 3 is:<rule ruleid="23" docid="844" pairid="15"><LHS> (PP(RB 8 because) (IN 9 of)(NP(PRP 10 their)(NN 11 convenience))) </LHS><RHS> (ADJP(JJ 8 due)(PP(TO 9 to) (NP(PRP 10 their)(NN 11 convenience)))) </RHS></rule>To create entailment rules balancing high-precision with their recall (Section 3), when thewords of the context added to the rule in Step 4are identical we substitute them with their PoS.
ForExample 3, the rule is generalized as follows:<rule ruleid="23" docid="844" pairid="15"><LHS> (PP(RB because) (IN of)(NP(PRP)(NN))) </LHS><RHS> (ADJP(JJ due)(PP(TO to) (NP(PRP)(NN)))) </RHS></rule>The intuition underlying the generalization phase isto allow a more frequent application of the rule,while keeping some constraints on the allowed con-text.
The application of the rule from Example 3 is39allowed if the subtrees below the seed words are thesame (the rule can be applied in another T-H pair as,e.g.
because of his status?
due to his status).Contradictions (e.g.
antonyms and semantic op-positions) are generally very infrequent, but in cer-tain cases they can have high impact (one of the mostfrequent rule collected for temporal expression is be-fore S?
after S).
For this reason, we used WordNet(Fellbaum, 1998) to identify and filter antonyms outduring the generalization phase.
We also checkedfor awkward inconsistencies due to mistakes of thealgorithm on noisy Wikipedia data (e.g.
rules withthe same seed word in both the LHS and the RHS),and we automatically filtered them out.
Table 1 re-ports a sample of rules extracted for each seed word.Statistics about the resulting data sets, i.e.
the num-ber of acquired rules both before and after the gener-alization phase are shown in Table 2.
Identical rulesare collapsed into a unique one, but the value of theirfrequency is kept in the header of that rule.
Such in-dex can then be used to estimate the correctness ofthe rule and, according to our intuition, the probabil-ity that the rule preserves the entailment relation.7causality temporal exp.# rules before gen. 1671 813# rules after gen. 977 457rules frequency ?
2 66 27Table 2: Resulting sets of entailment rules5.1 EvaluationDue to the sparseness of the phenomena under con-sideration (i.e.
causality and temporal expressions)in RTE data sets, evaluating the acquired rules onsuch data does not provide interesting results.For this reason, (following (Zhao et al, 2009),(Callison-Burch, 2008), (Szpektor et al, 2004)), weopted for a manual analysis of a sample of 100rules per set, including all the rules whose fre-quency is ?2 (Table 2), plus a random set of ruleswith frequency equal to 1.
Two annotators withskills in linguistics annotated such rules according7It is difficult to compare our results with related work, sincesuch phenomena are not covered by other resources.
The cor-rect comparison would be with the subset of e.g.
DIRT para-phrases dealing with causality and temporal relations, if any.to five possible values (rules have been presentedwith the sentence pairs from which they have beenacquired): entailment=yes (YES), i.e.
correctness ofthe rule; entailment=more-phenomena (+PHEN), i.e.the rule is correct, but more than one phenomenonis involved, see Section 5.2; entailment=unknown(UNK), i.e.
there is no entailment between the LHSand the RHS of the rule, often because the editingchanged the semantics of the proposition; entail-ment=unknown:reverse entailment (REV), wrongdirectionality, i.e.
the RHS of the rule entails theLHS; entailment=error (ERR), i.e.
the rule is wrong,either because the editing in Wiki10 was done to cor-rect mistakes, or because the rule is not well-formeddue to mistakes produced by our algorithm.The inter-annotator agreement has been calcu-lated, counting when judges agree on the assignedvalue.
It amounts to 80% on the sample of rulesfor causality, and to 77% on the sample of rules fortemporal expressions.
The highest inter-annotatoragreement is for correct entailment rules, whereasthe lowest agreement rates are for unknown and er-ror judgments.
This is due to the fact that detectingcorrect rules is straightforward, while it is less clearwhether to consider a wrong rule as well-formed butwith an unknown judgment, or to consider it as notappropriate (i.e.
error).
Table 3 shows the outcomesof the analysis of the two sets of rules, as resultingafter a reconciliation phase carried out by the an-notators.
Such results, provided both for the wholesamples8 and for the rules whose frequency is ?2only, are discussed in the next section.YES +PHEN UNK REV ERRcaus.all 67 2 13 8 10fr?2 80.3 0 16.7 1.5 1.5temp.all 36 6 23 7 28fr?2 52 3.7 37 7.3 0Table 3: Accuracy (%) of the extracted sets of rules.5.2 Discussion and error analysisDue to the amount of noisy data present inWikipedia, on average 19% of the collected rules8We are aware of the fact that including all the most frequentrules in the sample biases the results upwards, but our choice ismotivated by the fact that we aim at verifying that with redun-dancy the accuracy is actually improved.40include editing done by the users for spelling andtypos corrections, or are just spam (Table 3).
To dis-card such cases, spell-checkers or dictionary-basedfilters should be used to improve our filtering tech-niques.
Moreover, to select only reliable rules weconsider making use of their frequency in the data toestimate the confidence that a certain rule maintainsthe entailment.
The accuracy of the rules occurringmore than once is indeed much higher than the ac-curacy estimated on the whole sample.
Also the per-centage of incorrect rules is strongly reduced whenconsidering redundant rules.
Our assumption aboutthe directionality of entailment rules extracted fromWikipedia versions is also verified (less than 10% ofthe rules per set are tagged as reverse-entailment).However, since the acquisition procedure privi-leges precision, only a few rules appear very fre-quently (Table 2), and this can be due to the con-straints defined for the context extraction.
This factmotivates also the lower precision of the rules fortemporal expressions, where 73% of the sample weanalyzed involved rules with frequency equal to 1.Moreover, in most of the rules annotated as un-known, the editing of Wiki10 changed the semanticsof the pair, e.g.
before 1990 ?
1893, or when xproduced?
because x produced.
Further strategiesto empirically estimate precision and recall of ruleapplication should be experimented as future work.Indeed, several rules appearing only once representcorrect rules, and should not be discarded a priori.Finally, the idea of using only very similar pairs toextract entailment rules is based on the assumptionthat such rules should concern one phenomenon at atime (Bentivogli et al, 2010).
Despite the strategiesadopted to avoid multiple phenomena per rule, inabout 10% of the cases two phenomena (e.g lexicaland syntactic) are collapsed on consecutive tokens,making it complex to separate them automatically:e.g.
in because of his divorce settlement cost?
dueto the cost of his divorces settlement, the causative(because of x?
due to x) and the argument realiza-tion (x cost?
cost of x) rules should be separated.6 Conclusion and future workWe have presented a methodology for the automaticacquisition of entailment rules from Wikipedia re-vision pairs.
The main benefits are the follow-ing: i) potential large-scale acquisition, given the in-creasing size of Wikipedia revisions; ii) new cover-age, because Wikipedia revisions contain linguisticphenomena (e.g.
causality, temporal expressions),which are not covered by existing resources: as aconsequence, the coverage of current TE systemscan be significantly extended; iii) quality: we intro-duce the notion of context of a rule as the minimalset of syntactic features maximizing its successfulapplication, and we have implemented it as a searchover the syntactic representation of revision pairs.Results obtained on two experimental acquisi-tions on causality and temporal expressions (seedsbecause and before) show both good quality andcoverage of the extracted rules.
The obtained re-sources9: i) cover entailment and paraphrasing as-pects not represented in other similar sets of rules,ii) can be easily extended by applying the algorithmsto automatically collect rules for other phenomenarelevant to inference; and iii) are periodically up-dated, as Wikipedia revisions change continuously.We consider such aspects as part of our future work.These results encourage us to further improve theapproach, considering a number of directions.
First,we plan to improve our filtering techniques to ex-clude revision pairs containing more than one phe-nomenon considering the syntactic structure of thesentence.
Moreover, we are planning to carry outmore extended evaluations, according to two pos-sible strategies: i) applying the instance-based ap-proach (Szpektor et al, 2007) on the Penn Treebankdata (i.e.
for each PTB sentence that contains theLHS of an entailment rule from our set, a pair sen-tence will be generated by replacing the LHS of therule with its RHS.
Human judges will then judgeeach pair); ii) integrating the extracted rules intoexisting TE systems.
However, this evaluation hasto be carefully designed, as the ablation tests car-ried on at the RTE challenges show.
In particular,as RTE tasks are moving towards real applications(e.g.
summarization) we think that knowledge re-flecting real textual variations produced by humans(as opposed to knowledge derived from linguistic re-sources) may introduce interesting and novel hints.9Available at http://www.aclweb.org/aclwiki/index.php?title=Textual_Entailment_Resource_Pool.
We encourage its integration into TEsystems, to obtain feedback on its utility in TE tasks.41AcknowledgmentsThis work has been partially supported by the EC-funded project EXCITEMENT (FP7 ICT-287923).ReferencesRoni Ben Aharon, Idan Szpektor, Ido Dagan.
2010.
Gen-erating Entailment Rules from FrameNet.
Proceedingsof the ACL 2010 Conference Short Papers.
July 11-16.Uppsala, Sweden.Regina Barzilay, Lillian Lee.
2003.
Learning to Para-phrase: An Unsupervised Approach Using Multiple-Sequence Alignment.
Proceedings of the HLT-NAACL.
May 27-June 1.
Edmonton, Canada.Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa T. Dang,Danilo Giampiccolo.
2010.
The Sixth PASCAL Rec-ognizing Textual Entailment Challenge.
Proceedingsof the TAC 2010 Workshop on TE.
November 15-16.Gaithersburg, Maryland.Luisa Bentivogli, Elena Cabrio, Ido Dagan, Danilo Gi-ampiccolo, Medea Lo Leggio, Bernardo Magnini.2010.
Building Textual Entailment Specialized DataSets: a Methodology for Isolating Linguistic Phenom-ena Relevant to Inference.
Proceedings of the Seventhconference on International Language Resources andEvaluation.
May 19-21.
Malta.Chris Callison-Burch.
2008.
Syntactic constraints onparaphrases extracted from parallel corpora.
Pro-ceedings of the Conference on Empirical Methods inNatural Language Processing (EMNLP2008) October25-27.
Honolulu, Hawaii.Ido Dagan, Bill Dolan, Bernardo Magnini, Dan Roth.2009.
Recognizing textual entailment: Rational, eval-uation and approaches.
Natural Language Engineer-ing (JNLE).
Special Issue 04, volume 15, i-xvii.
Cam-bridge University Press.Fred J. Damerau.
1964.
A technique for computer de-tection and correction of spelling errors.
Commun.ACM, 7 (3), pages 171?176.
ACM, New York, NY,USA.Camille Dutrey, Houda Bouamor, Delphine Bernhard andAurelien Max 2011.
Local modifications and para-phrases in Wikipedia?s revision history.
SEPLN jour-nal (Revista de Procesamiento del Lenguaje Natural),46:51-58.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
Language, Speech and Communi-cation.
MIT Press.Adrian Iftene, Mihai-Alex Moruz.
2010.
UAIC Partici-pation at RTE-6.
Proceedings of the TAC 2010 Work-shop on TE.
November 15-16.
Gaithersburg, Mary-land.Dan Klein, Christopher D. Manning.
2003.
AccurateUnlexicalized Parsing.
Proceedings of the 41st Meet-ing of the Association for Computational Linguistics.July 7-12.
Sapporo, Japan.Dekang Lin, Patrick Pantel.
2001.
Discovery of Infer-ence Rules for Question Answering.
Natural LanguageEngineering 7(4):343-360.Rowan Nairn, Cleo Condoravdi, Lauri Karttunen.
2006.Computing relative polarity for textual inference.
In-ference in Computational Semantics (ICoS-5).
April20-21.
Buxton, UK.Aurelien Max, Guillaume Wisniewski.
2010.
Miningnaturally-occurring corrections and paraphrases fromwikipedia?s revision history.
Proceedings of the Sev-enth conference on International Language Resourcesand Evaluation.
May 19-21.
Valletta, Malta.Yashar Mehdad, Matteo Negri, Elena Cabrio,Milen Kouylekov, Bernardo Magnini.
2009.
UsingLexical Resources in a Distance-Based Approach toRTE.
Proceedings of the TAC 2009 Workshop on TE.November 17.
Gaithersburg, Maryland.Shachar Mirkin, Roy Bar-Haim, Jonathan Beran, Ido Da-gan, Eyal Shnarch, Asher Stern, Idan Szpektor.
2009.Addressing Discourse and Document Structure in theRTE Search Task.
Proceedings of the TAC 2009 Work-shop on TE.
November 17.
Gaithersburg, Maryland.Rani Nelken, Elif Yamangil.
2008.
Mining Wikipedia?sArticle Revision History for Training ComputationalLinguistics Algorithms.
Proceedings of the AAAIWorkshop on Wikipedia and Artificial Intelligence.July 13-14, Chicago, Illinois.Satoshi Sekine.
2005.
Automatic Paraphrase Discoverybased on Context and Kwywords between NE Pairs.Proceedings of the International Workshop on Para-phrasing (IWP-05).
October 14.
Jeju Island, SouthKorea.Idan Szpektor, Hristo Tanev, Ido Dagan, Bonaven-tura Coppola.
2004.
Scaling Web-based Acquisition ofEntailment Relations.
Proceedings of the 2004 Con-ference on Empirical Methods in Natural LanguageProcessing.
July 25-26.
Barcelona, Spain.Idan Szpektor, Ido Dagan.
2008.
Learning EntailmentRules for Unary Templates.
Proceedings of the 22ndInternational Conference on Computational Linguis-tics (Coling 2008).
August 18-22.
Manchester, UK.Idan Szpektor, Eyal Shnarch, Ido Dagan.
2007.Instance-based Evaluation of Entailment Rule Acqui-sition.
Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics.
June 23-30.
Prague, Czech Republic.Christoph Tillmann, Stephan Vogel, Hermann Ney,Alex Zubiaga, Hassan Sawaf.
1997.
Accelerated DPbased search for statistical translation.
Proceedings42of the European Conf.
on Speech Communication andTechnology, pages 26672670.
September.
Rhodes,Greece.Mark Yatskar, Bo Pang, Cristian Danescu-Niculescu-Mizil, Lillian Lee.
2010.
For the sake of simplicity:Unsupervised extraction of lexical simplifications fromWikipedia.
Proceedings of the NAACL, pp.
365-368,2010.
Short paper.
June 1-6.
Los Angeles, USA.Fabio Massimo Zanzotto, Marco Pennacchiotti.
2010.Expanding textual entailment corpora from Wikipediausing co-training.
Proceedings of the COLING-Workshop on The Peoples Web Meets NLP: Collabo-ratively Constructed Semantic Resources.
August 28.Beijing, China.Shiqi Zhao, Haifeng Wang, Ting Liu, Sheng Li.
2009.Extracting Paraphrase Patterns from Bilingual Paral-lel Corpora.
Journal of Natural Language Engineer-ing, 15 (4): 503:526.43
