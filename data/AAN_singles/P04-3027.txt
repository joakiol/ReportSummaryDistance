Automatic clustering of collocationfor detecting practical sense boundarySaim ShinKAISTKorTermBOLAmiror@world.kaist.ac.krKey-Sun ChoiKAISTKorTermBOLAkschoi@world.kaist.ac.krAbstractThis paper talks about the deciding practicalsense boundary of homonymous words.
Theimportant problem in dictionaries or thesauriis the confusion of the sense boundary by eachresource.
This also becomes a bottleneck inthe practical language processing systems.This paper proposes the method aboutdiscovering sense boundary using thecollocation from the large corpora and theclustering methods.
In the experiments, theproposed methods show the similar resultswith the sense boundary from a corpus-baseddictionary and sense-tagged corpus.1 IntroductionThere are three types of sense boundaryconfusion for the homonyms in the existingdictionaries.
One is sense boundaries?
overlapping:two senses are overlapped from some semanticfeatures.
Second, some senses in the dictionary arenull (or non-existing) in the used corpora.Conversely, we have to generate more sensesdepending on the corpora, and we define thesesenses with practical senses.
Our goal in this studyis to revise sense boundary in the existingdictionaries with practical senses from the large-scaled corpus.The collocation from the large-scaled corpuscontains semantic information.
The collocation forambiguous words also contains semanticinformation about multiple senses for thisambiguous word.
This paper uses the ambiguity ofcollocation for the homonyms.
With the clusteringalgorithms, we extract practical sense boundaryfrom the collocations.This paper explains the collocation ambiguity inchapter 2, defines the extracted collocation andproposes the used clustering methods and thelabeling algorithms in chapter 3.
After explainingthe experimental results in chapter 4, this papercomes to the conclusion in chapter 5.2 Collocation and Senses2.1 Impractical senses in dictionaryIn (Patrick and Lin, 2002), senses in dictionary ?especially in WordNet ?
sometimes don?t containthe senses appearing in the corpus.
Some senses inthe manual dictionary don?t appear in the corpus.This situation means that there exist differencesbetween the senses in the manual dictionaries andpractical senses from corpus.
These differencesmake problems in developing word sensedisambiguation systems and applying semanticinformation to language processing applications.The senses in the corpus are continuouslychanged.
In order to reflect these changes, we mustanalyze corpus continuously.
This paper discussesabout the analyzing method in order to detectpractical senses using the collocation.2.2 Homonymous collocationThe words in the collocation also have theircollocation.
A target word for collocation is calledthe ?central word?, and a word in a collocation isreferred to as the ?contextual word?.
?Surroundingwords?
mean the collocation for all contextualwords.
The assumption for extracting senseboundary is like this: the contextual words used inthe same sense of the central word show thesimilar pattern of context.
If collocation patternsbetween contextual words are similar, it means thatthe contextual words are used in a similar context -where used and interrelated in same sense of thecentral word - in the sentence.
If contextual wordsare clustered according to the similarity incollocations, contextual words for homonymouscentral words can be classified according to thesenses of the central words.
(Shin and Choi, 2004)The following is a mathematical representationused in this paper.
A collocation of the centralword x, window size w and corpus c is expressedwith function f: V N C ?
2PC/V.
In this formula, Vmeans a set of vocabulary, N is the size of thecontextual window that is an integer, and C meansa set of corpus.
In this paper, vocabulary refers toall content words in the corpus.
Function f showsall collocations.
C/V means that C is limited to V aswell as that all vocabularies are selected from agiven corpus and 2PC/VP is all sets of C/V.
In theequation (1), the frequency of x is m in c. We canalso express m=|c/x|.
The window size of acollocation is 2w+1.
}),,{()( xIiixxg ?=  is a word sense assignmentfunction that gives the word senses numbered i ofthe word x. Ix is the word sense indexing functionof x that  gives an  index to each sense of the wordx.
All contextual words xi?j of a central word x havetheir own contextual words in their collocation,and they also have multiple senses.
This problem isexpressed by the combination of g and f as follows:??????????=++??++??)(),...,(),,(),(),...,(..........
)(),...,(),1,(),(),...,()),,((11111111whhxhwhwhhhwhdmmmmixgxgIxxgxgxgxgxxgxgcwxfgh o(1)In this paper, the problem is that the collocationof the central word is ordered according to wordsenses.
Figure 1 show the overall process for thispurpose.Figure 1 Processing for detecting senseboundary3 Automatic clustering of collocationFor extracting practical senses, the contextualwords for a central word are clustered by analyzingthe pattern of the surrounding words.
With thismethod, we can get the collocation without senseambiguity, and also discover the practical senseboundary.In order to extract the correct sense boundaryfrom the clustering phase, it needs to remove thenoise and trivial collocation.
We call this processnormalization, and it is specifically provided as [8].The statistically unrelated words can be said thatthe words with high frequency appear regardless oftheir semantic features.
After deciding thestatistically unrelated words by calculating tf?idfvalues, we filtered them from the originalsurrounding words.
The second normalization isusing LSI (Latent Semantic Indexing).
Throughoutthe LSI transformation, we can remove thedimension of the context vector and express thehidden features into the surface of the contextvector.3.1 Discovering sense boundaryWe discovered the senses of the homonyms withclustering the normalized collocation.
Theclustering classifies the contextual words havingsimilar context ?
the contextual words havingsimilar pattern of surrounding words - into samecluster.
Extracted clusters throughout the clusteringsymbolize the senses for the central words andtheir collocation.
In order to extract clusters, weused several clustering algorithms.
Followings arethe used clustering methods:z K-means clustering (K) (Ray and Turi, 1999)z Buckshot (B) (Jensen, Beitzel, Pilotto,Goharian and Frieder, 2002)z Committee based clustering (CBC) (Patrickand Lin, 2002)z Markov clustering (M1, M2) 1  (Stijn vanDongen, 2000)z Fuzzy clustering (F1, F2)2 (Song, Cao andBruza, 2003)Used clustering methods cover both thepopularity and the variety of the algorithms ?
softand hard clustering and graph clustering etc.
In allclustering methods, used similarity measure is thecosine similarity between two sense vectors foreach contextual word.We extracted clusters with these clusteringmethods, tried to compare their discovered sensesand the manually distributed senses.3.2 Deciding final sense boundaryAfter clustering the normalized collocation, wecombined all clustering results and decided theoptimal sense boundary for a central word.
},...,,{},...,,...,{)),((},...,{)),,((1001 1xmxxxniixmdxdxddxssSdddDdxnummhhScwxfghiii=====o(2)In equation (2), we define equation (1) as Sxdi,this means extracted sense boundary for a centralword x with di.
The elements of D are the appliedclustering methods, and Sx is the final combinationresults of all clustering methods for x.1 M1and M2 have different translating methods between context and graph.2 F1and F2 are different methods deciding initial centers.This paper proposes the voting of appliedclustering methods when decides final senseboundary like equation (3).xiDdSdwnumxNumi==?
)},({)( max  (3)We determined the number of the final senseboundary for each central word with the number ofclusters that the most clustering algorithms wereextracted.After deciding the final number of senses, wemapped clusters between clustering methods.
Bycomparing the agreement, the pairs of themaximum agreement are looked upon the sameclusters expressing the same sense, and agreementis calculated like equation (4), which is theagreement between k-th cluster with i-th clusteringmethod and l-th cluster with j-th clustering methodfor central word x.
}{}{}{}{xldjxkdxldjxkdhhhhagreementiiUI=(4)))},,(({max),( cwxfghwSVotikidVx Ddx o??
?= (5))1,...,1,1(21 ??
?= nx anananS wNwNwNzr (6)The final step is the assigning elements into thefinal clusters.
In equation (5), all contextual wordsw are classified into the maximum results ofclustering methods.
New centers of each cluster arerecalculated with the equation (6) based on thefinal clusters and their elements.Figure 2 represents the clustering result for thecentral word ?chair?.
The pink box shows thecentral word ?chair?
and the white boxes show theselected contextual words.
The white and blue areameans the each clusters separated by the clusteringmethods.
The central word ?chair?
finally makestwo clusters.
The one located in blue area containsthe collocation for the sense about ?the position ofprofessor?.
Another cluster in the white area is thecluster for the sense about ?furniture?.
The wordsin each cluster are the representative contextualwords which similarity is included in ranking 10.4 Experimental resultsWe extracted sense clusters with the proposedmethods from the large-scaled corpus, andcompared the results with the sense distribution ofthe existing thesaurus.
Applied corpus for theexperiments for English and Korean is Penn treebank3 corpus and KAIST4 corpus.3 http://www.cis.upenn.edu/~treebank/home.html4 http://kibs.kaist.ac.krFigure 2  The clustering example for 'chair'For evaluation, we try to compare clusteringresults and sense distribution of dictionary.
In caseof English, used dictionary is WordNet 1.75 - Fine-grained (WF) and coarse-grained distribution(WC).
The coarse-grained senses in WordNet areadjusted sense based on corpus for SENSEVALtask.
In order to evaluate the practical word sensedisambiguation systems, the senses in the WordNet1.7 are adjusted by the analyzing the appearingsenses from the Semcor.
For the evaluation ofKorean we used Korean Unabridged Dictionary(KD) for fine-grained senses and YonseiDictionary (YD) for corpus-based senses.Table 1 shows the clustering results by eachclustering algorithms.
The used central words are786 target homonyms for the English lexicalsamples in SENSEVAL26.
The numbers in Table 1shows the average number of clusters with eachclustering method shown chapter 3 by the part ofspeech.
WC and WF are the average number ofsenses by the part of speech.In Table 1 and 2, the most clustering methodsshow the similar results.
But, CBC extracts moreclusters comparing other clustering methods.Except CBC other methods extract similar sensedistribution with the Coarse-grained WordNet(WC).Nouns Adjectives Verbs AllK 3 3.046 3.039 3.027B 3.258 3.218 3.286 3.266CBC 6.998 3.228 5.008 5.052F1 3.917 2.294 3.645 3.515F2 4.038 5.046 3.656 4.013Final 3.141 3.08 3.114 3.13WC 3.261 2.887 3.366 3.252WF 8.935 8.603 9.422 9.129Table 1  The results of English5 http://www.cogsci.princeton.edu/~wn/6 http://www.cs.unt.edu/~rada/senseval/K B C F1 F2 M1Nouns 2.917 2.917 5.5 2.833 2.583 4.083KD YD M2Nouns 11.25 3.333 3.833Table 2  The results of KoreanTable 3 is the evaluating the correctness of theelements of cluster.
Using the sense-taggedcollocation from English test suit in SENSEVAL27,we calculated the average agreement for all centralwords by each clustering algorithms.K B C F1 F298.666 98.578 90.91 97.316 88.333Table 3 The average agreement by clusteringmethodsAs shown in Table 3, overall clustering methodsrecord high agreement.
Among the variousclustering algorithms, the results of K-means andbuckshot are higher than other algorithms.
In theK-means and fuzzy clustering, the decidingrandom initial shows higher agreements.
But,clustering time in hierarchical deciding is fasterthan random deciding5 ConclusionThis paper proposes the method for boundarydiscovery of homonymous senses.
In order toextract practical senses from corpus, we use thecollocation from the large corpora and theclustering methods.In these experiments, the results of the proposedmethods are different from the fine-grained sensedistribution - manually analyzed by the experts.But the results are similar to the coarse-grainedresults ?
corpus-based sense distribution.
Therefore,these experimental results prove that we canextract practical sense distribution using theproposed methods.For the conclusion, the proposed methods showthe similar results with the corpus-based senseboundary.For the future works, using this result, it?ll bepossible to combine these results with the practicalthesaurus automatically.
The proposed method canapply in the evaluation and tuning process forexisting senses.
So, if overall research issuccessfully processed, we can get a automaticmechanism about adjusting and constructingknowledge base like thesaurus which is practicaland containing enough knowledge from corpus.There are some related works about this research.Wortchartz is the collocation dictionary with theassumption that Collocation of a word expresses7 English lexical sample for the same central wordsthe meaning of the word (Heyer, Quasthoff andWolff, 2001).
(Patrick and Lin, 2002) tried todiscover senses from the large-scaled corpus withCBC (Committee Based Clustering) algorithm.. Inthis paper, used context features are limited only1,000 nouns by their frequency.
(Hyungsuk, Plouxand Wehrli, 2003) tried to extract sense differencesusing clustering in the multi-lingual collocation.6 AcknowledgementsThis work has been supported by Ministry ofScience and Technology in Korea.
The result ofthis work is enhanced and distributed throughBank of Language Resources supported by grantNo.
R21-2003-000-10042-0 from Korea Science &Technology Foundation.ReferencesRay S. and Turi R.H. 1999.
Determination ofNumber of Clusters in K-means Clustering andApplication in Colour Image Segmentation, In?The 4th International Conference on Advancesin Pattern Recognition and Digital Techniques?,Calcuta.Heyer G., Quasthoff U. and Wolff C. 2001.Information Extraction from Text Corpora, In?IEEE Intelligent Systems and TheirApplications?, Volume 16, No.
2.Patrick Pantel and Dekang Lin.
2002.
DiscoveringWord Senses from Text, In ?ACM Conferenceon Knowledge Discovery and Data Mining?,pages  613?619, Edmonton.Hyungsuk Ji, Sabine Ploux and Eric Wehrli.
2003,Lexical Knowledge Representation withContexonyms, In ?The 9th Machine Translation?,pages 194-201, New OrleansEric C.Jensen, Steven M.Beitzel, Angelo J.Pilotto,Nazli Goharian, Ophir Frieder.
2002,Parallelizing the Buckshot Algorithm forEfficient Document Clustering, In ?The 2002ACM International Conference on Informationand Knowledge Management, pages 04-09,McLean, Virginia, USA.Stijn van Dongen.
2000, A cluster algorithm forgraphs, In ?Technical Report INS-R0010?,National Research Institute for Mathematics andComputer Science in the Netherlands.Song D., Cao G., and Bruza P.D.
2003, Fuzzy K-means Clustering in Information Retrieval, In?DSTC Technical Report?.Saim Shin and Key-Sun Choi.
2004, AutomaticWord Sense Clustering using Collocation forSense Adaptation, In ?Global WordNetconference?, pages 320-325, Brno, Czech.
