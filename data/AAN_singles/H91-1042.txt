Statistical Agenda ParsingRobert J. BobrowBBN Systems and Technologies10 Moul ton Street.Cambridge, MA 02138ABSTRACTThis paper presents the results of converting a standardGreham/Harrison/Ruzzo (GHR) parser for a unification grammar into anagenda-driven parsing system.
The agenda is controlled by statisticalmeasures ofgrammar-rule likelihood obtained from a training set.The techniques in the agenda parser lead to substantial reductions inchart size and parse time, and can be applied to any chart-based parsingalgorithm without hand-tuning.INTRODUCTIONIn a Graham/Harrison/Ruzzo (GHR) parser, the chart is usedto maintain a record of syntactic onstituents hat have beenfound (terms) and grammatical rules that have been partiallymatched (dotted rules).
Parsing strategies such as GHR, CKYand other algorithms can be viewed as methodical ways offilling the chart which guarantee to explore all possibleextensions of dotted rules by terms.An agenda is an alternative chart-filling algorithm with thegoal of finding some term covering the entire input withoutnecessarily filling in all of the chart.
If terms can be ranked by"goodness" and the grammar can produce multiple analyses of agiven string, then one goal for an agenda is to produce the"best" parse first.The alternative goal we have chosen for DELPHI is to use theagenda mechanism to reduce the search necessary to produceACCEPTABLE (see below) parses.
This results in sparselypopulated charts, approaching the extreme (and probablyunattainable) goal of deterministic parsing, in which the onlyterms and dotted rules entered into the chart are those whichappear as parts of the final parse.The techniques involved in statistical agenda parsing allow"low probability" rules to be added to a grammar withoutsignificant cost in terms of either erroneous parses or increasedparse time.
These low probability rules greatly increase thecoverage and robustness of the system by accounting forunusual or marginal constructions.DELPHI  AGENDA PARSINGMost techniques for search splice reduction involve carefultuning of the grammar or the parsing mechanism.
This is verylabor intensive and can place limits on the grammaticalcoverage of the system (Abney 1990).
Our approach is to usean automated statistical technique for ranking rules based ontheir use in parsing a training set with the same grammar (underthe control of an all-paths GHR parser without humansupervision).This approach also allows us to include grammatical rulesthat are of use only rarely, or in specialized omains, and tolearn how applicable they are to a body of sentences.
To takeinto account general inguistic tendencies, we augment hestatistical ranking by a small number of general agendaordering strategies.The DELPHI agenda mechanism is based on three"scbedulable" action types:1. the insertion of a term into the chart,2.
the insertion of a dotted rule into the chart, and3.
the (conditional) "pair extension" of a dotted rule by aterm.In principle one would like to order those actions in terms ofthe probability that they lead to a final parse.
The initialimplementation of the agenda mechanism uses anapproximation to this ordering.USE  OF  STAT IST ICAL  MEASURESThere are two types of measures that one might estimate tohelp the agenda parsing mechanism.
They are (1) categoryexpansion probabilities and (2) rule success probabilities.Category Expansion ProbabilitiesCategory expansion probabilities are perhaps the moreobvious of the two measures.
The goal is to determine theprobability that a given syntactic category (e.g., NP) isexpanded by a given grammar rule in a valid parse.These probabilities allow one to estimate the probabilitythat a given tree is the expansion of a given category.
Bayes'rule may be used to calculate the relative probabilities ofvarious parse trees for a specified input string.Rule Success ProbabilitiesUsing rule success probabilities, the goal is to determine theprobability that a term inserted into the chart by a particularrule will be part of a Fmal parse.222TrainingIn order to train the agenda mechanism, a set of sentences iparsed using the all-paths GHR parser and their charts areanalyzed.For each rule (R) in the grammar we determine threenumbers:1.
NT(R), the number of terms in the charts based on that rule.2.
NDR(R), the number of dotted rules initiated in the chartbased on that rule.3.
NGT(R), the number of "good terms" based on that rule,ones that are constituents of an ACCEPTABLE parse (i.e.,ones leading to executable database commands for ATIS).For each category C in the grammar, we calculate onenumber:4.
NGT(C), the number of terms with that category which areconstituents in an acceptable parse.The ratio NGT(R)/NT(R) is an estimate of the probabilitythat a term based on R will appear in the final parse, andNGT(R)\]NDR(R) is an estimate of the probability that theinitiation of a dotted rule based on R will lead to a good term.
(Note that in DELPHI, each word sense is treated as if it were aseparate grammar ule, and so this mechanism takes intoaccount he relative likdihood of various word senses in thetraining set.
)If C(R) is the category produced by the rule R, then thecategory expansion probability of R is NGT(R)/NGT(C(R)).Preliminary Results for Different MeasuresUsing rule success probabilities leads to substantialreduction (a factor of more than 3) in chart size.
In general, onemight expect hat better estimates of such probabilities, basedon category expansion probabilities in the tree below the term,would lead to improved results, even though these estimatesrequire somewhat more computation than rule successprobabilities alone.We have compared the use of category expansionprobabilities with the use of rule success probabilities inseveral variations of the agenda mechanism, and have foundthat rule success probabilities produce superior results,although the reasons for this are not entirely clear.An experiment using category expansion probabilitiesalone led to larger charts than produced by the use of rulesuccess probabilities in isolation.
Combining categoryexpansion probabilities with rule success probabilitiesappeared to be no better than just using the rule successprobabilities.AGENDA STRUCTURESThe structure of the agenda mechanism appears to be asimportant as the statistical measures used to order agendaitems.
Experience with probabilistic agendas in speechprocessing would suggest an approach in which all informationrelevant to ordering is combined into a single numeric measureand used to order a single queue.
In principal, this allowsdifferent measures to interact and for strength in one measure tomake up for weakness in another.We experimented with this approach in a system which had asingle agenda in which all three of the schedulable action typesdescribed above were placed.
The statistical measures describedabove were combined in a weighted fashion with prioritiesbased on the size of the constituents, the position of the righthand end of the constituent and the action type.
A number ofexperiments were run, giving different weightings to thedifferent parameters, but all of these experiments led to chartsthat were 20% to 40% larger than the alternative structuredagenda described below.The structured-agenda approach involves the creation of a2-dimansional array of agendas, as illustrated in figure 1.Act ionTypeNPa i rs  A1 A4Rlghtmost  EndpolntN-1 .
.
.
1 0Rules A2 A5Terms A3 A6Figure I: AgendaEach cell of the array consists of a single type of action,e.g.
term insertion, and all of the actions in the list Ai in a cellhave the same rightmost end.
Within the cell, the actions inthe list Ai are ordered by probability estimates.For each step, the first non-empty cell (starting with A1 andgoing in the order shown in figure 1) is chosen, and the firstitem on its agenda is run.
This has the effect of reinforcingprogress to the right through the input string, of choosing themost appropriate action for such motion at each step, andfavoring close attachment of modifiers.223DELPHI RESULTSMeasurements of chart-size and time reductions for BBN'sDELPHI grammar running on the ATIS training and test setsindicate the improvements possible with several variations ofthe basic agenda mechanism.
For example, using the structuredagenda on 551 sentences of training data from June 1990, thechart size was reduced by a factor of 3.24, and the totalprocessing time reduced by a factor of 1.82.This result underestimates the improvement gained byagenda parsing, since somewhat more than 10% of the"sentences" in the training data were ill-formed according toour grammar (many were ill-formed according to any plausiblegrammar!).
Since a properly operating agenda system willeventually produce the same chart hat the GHR parser does, andsince that entire chart must be searched before a string isdetermined to be unparseable, the performance of any agendamechanism ust reduce to that of the GHR parser for suchinputs.Another set of experiments was performed with a set of 539"parseable" strings taken from the combination of the June1990 and February 1991 ATIS training set.
For this set thespeedup was a factor of 3.8 and the chart size reduction was wellover 3.5.
(The hedge on chart size reduction is because data forthe chart size of 5 sentences in the GHR parser was notobtained, the charts overflowed available memory .
At thistime the ratio of that chart size to the size of the agenda parserchart was over 30.
)The introduction of probabilistic agenda parsing, combinedwith the application of software engineering techniques, hassped up natural language analysis considerably.
The averagetime for parsing, semantic interpretation and discourseprocessing (of a 551 sentence training corpus) in our DELPHIsystem was lowered to 1.43 seconds per sentence, with amedian time of 0.99 seconds, on a Sun 4/280.REFERENCES1.
Abney, Steven P. "Rapid Incremental Parsing with Repair",Proceedings of the Sixth Annual Conference of the UW Centre for theNew Oxford English Dictionary and Text Research,University ofWaterloo, Waterloo, Ontario, Canada, October 28-30, 1990,.2.
Graham, Susan L., Michael A. Harrison, and Walter L. Ruzzo,"AnImproved Context-Free Recognizer", ACM Transactions onProgramming Languages and Systems, Vol.
2, Number 3,1980,.3.
Kasami, T. "An Efficient Recognition and Syntax AnalysisAlgorithm for Context-Free Languages", Science Report AFCRL-65-758, Air Force Carnbddge Research Laboratory, 1966.4.
Bates, M., Boisen, S., Ingria, R. and Stallard, D. "BBN ATISSystem Progress Report - Jtme 1990", Proceedings of the Speech andNatural Language Workshop (June, 1990), Morgan KaufmannPublishers, Inc., 1990.224
