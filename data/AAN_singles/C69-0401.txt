Preprint No.
4 Classification: IR 2.3Automatic Processing of Foreign Language DocumentsG.
Salton*AbstractExperiments conducted over the last few years with the SMART docu-ment retrieval system have shown that fully automatic text processingmethods using relatively simple linguistic tools are as effective for pur-poses of document indexing, classification, search, and retrieval as themore elaborate manual methods normally used in practice.
Up to now, allexperiments were carried out entirely with English language queries and docu-ments.The present study describes an extension of the SMAKT procedures toGerman language materials.
A multi-lingual thesaurus is used for the ana-lysis of documents and search requests, and tools are provided which makeit possible to process English language documents against German queries,and vice versa.
The methods are evaluated, and it is shown that the effec-tiveness of the mixed language processing is approximately equivalent tothat of the standard process operating within a single language only.i.
IntroductionFor some years, experiments have been under way to test the effec-tiveness of automatic language analysis and indexing methods in informationretrieval, Specifically, document and query texts are processed fully auto-matically, and content identifiers are assigned using a variety of linguistic~Department of Computer Science, Cornell University, Ithaca, N. Y.
14850.This study was supported in part by the National Science Foundation undergrant GN-750.-2-tools, including word stem analysis, thesaurus look-up, phrase recognition,statistical term association~ syntactic analysis, and so on.
The resultingconcept identifiers assigned to each document and search request are thenmatched, and the documents whose identifiers are sufficiently close to thequeries are retrieved for the user's attention.The automatic analysis methods can be made to operate in real-time --while the customer waits for an answer _ by restricting the query-documentcomparisons to only certain document classes, and interactive user-controlledsearch methods can be implemented which adjust the search request during thesearch in such a way that more useful, and less useless, material is retrievedfrom the file.The experimental evidence accumulated over the last few years indi-cates that retrieval systems based on automatic text  processing methods --including fully automatic content analysis as well as automatic documentclassification and retrieval -- are not in general inferior in retrieval effec-tiveness to conventional systems based on human indexing and human queryformulation.One of the major objections to the praetical utilization of theautomatic text processing methods has been the inability automatically tohandle foreign language texts of the kind normally stored in documentationand library systems.
Recent experiments performed with document abstractsand search requests in French and German appear to indicate that these ob-jections may be groundless.In the present study~ the SMART documsnt retrieval system is usedto carry out experlments using as input foreign language documents andqueries.
The foreign language texts are automatically processed using a-3-thesaurus (synonym dictionary) translated directly from a previously avail-able English version.
Foreign language query and document texts are looked-up in the foreign language thesaurus and the analyzed forms of the queriesand documents are then compared in the standard manner before retrieving thehighly matching items.
The language analysis methods incorporated into theSMART system are first briefly reviewed.
Thereafter, the main proceduresused to process the foreign language documents are described, and the retrie-val effectiveness of the English text processing methods is compared withthat of the foreign language material.2.
The SMART SystemSMART is a fully-automatic document retrieval system operating onthe IBM 7094 and 360 model 65.
Unlike other computer-based retrieval systems,the SMART system does not rely on manually assigned key words or index termsfor the identification of documents and search requests, nor does it useprimarily the frequency of occurrence of certain words or phrases includedin the texts of documents.
Instead, an attempt is made to go beyond simpleword-matchlng procedures by using a variety of intellectual aids in the formof synonym dictionaries, hierarchical arrangements of subject identifiers,statistical and syntactic phrase generation methods and the like, in orderto obtain the content identifications useful for the retrieval process.Stored documents and search requests are then processed without anyprior manual analy~i__sby one of several hundred automatic content analysismethods, and those documents which most nearly match a given search requestare extracted from the document file in answer to the request.
The systemmay be controlled by the use~, in that a search request can be processed-4-first in a standard mode; the user can then analyze the output obtained and,depending on his further requirements, order a reproeessing of the requestunder new conditions.
The new output can again be examined and the processiterated until the right kind and amount of information are retrieved.
\[1,2,3\]SMART is thus designed as an experimental automatic retrieval systemof the kind that may become current in operational environments some yearshence.
The following facilities, incorporated into the SMART system forpurposes of document analysis may be of principal interest:a) a system for separating English words into stems and affixes(the so-called suffix 's' and stem thesaurus methods) whichcan be used to construct document identifications consistingof the stems of words contained in the documents;b) a synonym dictionary, or thesaurus, which can be used torecognize synonyms by replacing each word stem by one ormore "concept" numbers; these concept numbers then serve ascontent identifiers instead of the original word stems;c) a hierarchical arrangement of the concepts included in thethesaurus which makes it possible, given any concept number,to find its "parents" in the hierarchy, its "sons", its"brothers", and any of a set of possible cross references;the hierarchy can be used to obtain more general contentidentifiers than the ones originally given by going up inthe hierarchy, more spsclflc ones by going down, and a set ofrelated ones by picking up brothers and cross-references;d) statistical procedures to compate similarity coefficientsbased on co-occurrences of concepts within the sentences ofa given collection; the ~elated concepts, determined bystatistical association, can then be added to the originallyavailable concepts to identify the various documents;e~ syntactic analysis methods which make it possible to compare-5-the syntactically analyzed sentences of documents and searchrequests with a pre-coded dictionary of syntactic structures("criterion trees") in such a way that the same concept numberis assigned to a large number of semantically equivalent, butsyntactically quite different constructions;f) statistical ~hrgse matching methods which operate like thepreceding syntactic phrase procedures, that is, by using apreeonstructed dictionary to identify phrases used as contentidentifiers; however, no syntactic analysis is performed inthis case, and phrases are defined as equivalent if the conceptnumbers of all components match, regardless of the syntacticrelationshlps between components;g) a dictionary u~datln~ system, designed to revise the severaldictionaries included in the system:i) word stem dictionaryii) word suffix dictionaryiii) common word dictionary (for words to be deletedduping analysis)iv) thesaurus (synonym dictionary)v) concept hierarchyvi) statistical phrase dictionaryvii) syntactic ("criterion") phmase dictionary.The operations of the system are built around a supemvisory systemwhich decodes the input instructions and arranges the processing sequencein accordance with the instructions received.
The SMART systems organizationmakes it possible to evaluate the effectiveness of the various processingmethods by comparing the outputs produced by a variety of different runs.This is achieved by processing the same search requests against the same docu-ment collections several times, and making judicious changes in ~e analysisprocedures between runs.
In each case, the search effectiveness is evaluatedby presenting paired comparisons of the average perfommance over many searchrequests for two given search and retrieval methodologies.-6-3.
The Evaluation of Language Analysis MethodsMany different criteria may suggest themselves for measuring theperformance of an information system.
In the evaluation work carried out withthe SMART system, the effectiveness of an information system is assumed todepend on its ability to satisfy the users' information needs by retrievingwanted material, while rejecting unwanted items.
Two measures have beenwidely used for this purpose, known as recall and precision, and representingrespectively the proportion of relevant material actually retrieved, and theproportion of retrieved material actually relevant.
\[3\] (Ideally, all rele-vant items should be retrieved, while at the same time, all nonrelevant itemsshould be rejected, as reflected by perfect recall and precision values equalto i).It should be noted that both the recall and precision figures achie-vable by a given system are adjustable, in the sense that a relaxation ofthe search conditions often leads to high recall, while a tightening of thesearch criteria leads to high precision.
Unhappily, experience has shownthat on the average recall and precision tend to vary inversely since theretrieval of more relevant items normally also leads to the retrieval ofmore irrelevant ones.
In practice, a compromise is usually made, and a per-for~nance level is chosen such that much of the relevant material is retrieved,while the number of nonrelevant items which are also retrieved is kept withintolerable limits.In theory, one might expect that the performance of a retrieval sys-Item would improve as the language analysis methods used for document andquery processing become more sophisticated.
In actual fact, this turns outnot to be the case.
A first indication of the fact that retrieval effec--7-tiveness does not vary directly with the complexity of the document or queryanalysis was provided by the output of the Asllb-Cranfield studies.
Thisproject tested a large variety of indexing languages in a retrieval envir-onment, and came to the astonishing conclusion that the simplest type ofindexing language would produce the best results.
\[4\] Specifically, threetypes of indexing languages were tested, called respectively single terms(that is, individual terms, or concepts assigned to documents and queries),controlled terms (that is, single terms assigned under the control of thewell-known EJC Thesaurus of Engineering and Scientific Terms), and finallysimple conce~ts (that is, phrases consisting of two or more single terms).The results of the Cranfield tests indicated that single terms are moreeffective for retrieval purposes than either controlled terms, or completephrases.
\[4\]These results might be dismissed as being due to certain peculiartest conditions if it were not for the fact that the results obtained withthe automatic SMART retrieval system substantially confirqn the earlier Cran-field output.
\[3\] Specifically, the following basic conclusions can bedrawn from the main SMART experiments:a) the simplest automatic language analysis procedure consistingof the assignment to queries and documents of weighted wordstems originally contained in these documents, produces aretrieval effectiveness almost equivalent to that obtainedby intellectual indexing carried out manually under controlledconditions; \[3,5\]b) use of a thesaurus look-up process, designed to recognizesynonyms and other term relations by repla<~ing the original wordstems by the corresponding thesaurus categories, improves theretrieval effectiveness by about ten percent in both recall and-8-precision;c) additional, more sophisticated language analysis procedures,including the assignment of phrases instead of individualterms, the use of a concept hierarchy, the determinationof syntactic relations between terms, and so on, do not, onthe average, provide improvements over the standard thesaurusprocess.An example of a typical recall-precision graph produced by the SMARTsystem is shown in Fig.
i, where a statistical phrase method is comparedwith a syntactic phrase procedure.
In the former case, phrases are assignedas content identifiers to documents and queries whenever the individualphrase components are all present within a given document; in the latter case,the individual components must also exhibit an appropriate syntactic rela-tionship before the phrase is assigned as an identifier.
The output of Fig.lshows that the use of syntax degrades performance (the ideal perfor~nanceregion is in the upper right-hand corner of the graph where both the recalland the precision are close to i).
Several arguments may explain the outputof Fig.
i:a) the inadequacy of the syntactic analyzer used to generatesyntactic phrases;b) the fact that phrases are often appropriate content identi-fiers even when the phrase components are not syntacticallyrelated in a given context (e.g.
the sentence "people whoneed information, require adequate retrieval services" isadequately identified by the phrase "information retrieval",even though the components are not related in the sentence);c) the variability of the user population which makes it unwiseto overspecify document content;d) the ambiguity inherent in natural language texts which maywork to advantage when attempting to satisfy the informationneeds of a heterogeneous user population with diverse infor-mation needs.-9 -Precisioni.O.8.6.4.2o--- - -o Statistical phrasesa-- - , -a Syntactic phrases/ - Idea l- ~P '  Performance-~...~ ~d Region Recall0.30.50.7"o  0.9i I , I = - Recall .2 .4 .6 .8 1.0 vPrecision0 ~ 0  13- .
.
.
.
D.960 : .938.834  I .776.769 : .735.706 I .625.546 I .467 IComparison Between Statist ical  and Syntactic Phrases(averages aver 17 queries\]F?g, i-i0-Most likely a combination of some of the above factors is responsiblefor the fact that relatively simple content analysis methods are generallypreferable in a retrieval environment to more sophisticated methods.
Theforeign language processing to be described in the remainder of this studymust be viewed in the light of the foregoing test results.4.
Multi-lii~ual ThesaurusThe multi-lingual text processing experiment is motivated by thefollowing principal considerations:a) in typical American libraries up to fifty percent of the storedmaterials may not be in English; about fifty percent of thematerial processed in a test at the National Library of Medi-cine in Washington was not in English (of this, German accountedfor about 25%, French for 23%, Italian for 13%, Russian for11%, Japanese for 6%, Spanish for 5%, and Polish for 5%); \[6\]b) in certain statistical text processing experiments carriedout with foreign language documents, the test results wereabout equally good for German as for English; \[7\]c) simple text processing methods appear to work well for English,and there is no a priori reason why they should not workequally well for another language.The basic multi~lingual system used for test purposes is outlinedin Fig.
2.
Document (or query)texts are looked-up in a thesaurus and re-duced to "concept vector" form; query vectors and document vectors are thencompared, and document vectors sufficiently similar to the query are with-drawn from the file.
In order to insure that mixed language input is pro-perly processed, the thesaurus must assign the same concept oategories~ nomatter what the input language.
The SMART system therefore utilizes a- l l -E~'::3?.3Or~?/\]CWm?..W0I -C0(1)-?
I~ .
-3.  c _~_ ,~._ G) ::}D 0 ~ ~on"I m4,-,i r "E=:I00O/o0Eoo4J\[-4gN)O4r~-12-multi-lingual thesaurus in which one concept category corresponds both toa family of English words, or word stems, as well as to their German trans-lation.A typical thesaurus excerpt is shown in Fig.
3, giving respectivelyconcept numbers, English word class, and corresponding German word class.This thesaurus was produced by manually translating into German an origi-nally available English version.
Tables 1 and 2 show the results of thethesaurus look-up operation for the English and German versions of queryQB 13.
The original query texts in three languages (English, French, andGerman) are shown in Fig.
4.
It may be seen that seven out of 9 "English"concepts are common with the German concept vector for the same query.
Inview of this, one may expect that the German query processed against theGerman thesaurus could be matched against English language documents aseasily as the English version of the query.
Tables i and 2 also show thatmore query words were not found during look-up in the German thesaurus thanin the English one.
This is due to the fact th~ only a preliminary incom-plete version of the German thesaurus was available at run time.5.
Foreign Language Retrieval ExperimentTo test the simple multi-lingual thesaurus process two collectionsof documents in the area of library science and documentation (the Ispracollection) were processed against a set of 48 search requests in documen-tation area.
The English collection consisted of 1095 document abstracts,whereas the German collection contained only 468 document abstracts.
Theoverlap between the two collections included 50 common documents.
All 48queries were originally available in English; they were manually translated-13 -Z30 ART2311NOEPENDa3a ASSOCZAXZVe233 DIVIDE23~ A~TI~EACTIVITY.USAGE23~.
'CATHODEG~TUiOOEFLYING~-SROTRAYRELAISRELAYSCANNERTUBE23b KEDUNbANG?REQUNOAN?Z37 CHARGEENTE~ENTRYINSERTPOST238 MULTI-LEVELMULI IL~VEL239 INTELLEC~INTELLECTUAL~NTELLIGMENTAL~UN-INTELLEGTUALi~O ACTUALPRAGT&GE~EALExcerpt f~om Multi Lingua\]_ ThesaurusFig.
3ARGHITEKTURSELBSTAENDIGUNA~HAENGIGAKTIVAK I IV ITAETTAEI IGKEiTDIODEVEKZ~EIGEREINGANGEINGEGANGENEIHGEGEBENEINSATZEINSTELLENEINTIU~GUNGGEISTIGP~AXIS-14-English Quer \[ QB 13Concepts Weights Thesaurus Category3 J19 /33 /4965 J147 /2o7 /267 /34512121212\].212121212computer, processorautomatic, semiautomaticanalyze, analyzer~ analysis, etc.compendium, compile, depositauthorship, originatordiscourse, language, linguisticarea, branch, subfieldconcordance, keyword-in-context,KWIC bellanonymous, lettres/ common concept with German querywords not found in thesaurusThesaurus Look-up for English Query QB 13Table i-15-German Query QB 13Concepts Weights Thesaurus Categorys/\].9 /2183 /456465 /68147 /207 /267 y12124644121261212Computer, DatenverarbeitungAutomatisch, KybernetikArtikel, Presse, ZeitschriftAnalyse, SprachenanalyseHerausgabe, PublikationBuch, Heft, WerkAutor, VerfasserLiteraturLinguistik, SpracheArbeitsgebiet, FachKonkordanz, KWICschoenen, hilfrelch, vermutliehanonymen, zusammenzustellen/ common concept with English query* words not found in thesaurusThesaurus Look-up for German Query QB 13Table 2-16-SFIND QI3BAUIHQRSiN WHAI WAYS ARE CDMPUIER SYSIEMS BELNGAPPLIED IO RESEARCH iN THE FIELD OF IHEBELLES LEI IRES ?
HAS MACHINE ANALYSIS OFLANGUAGE PROVED u~EFUL FOR INSIANC?, iNDEIER~IJ~ING PKOBABLE AUTHORSHIP OFANONYMOUS ~ORKS OR i~  CQM@ILZNGC ONC OdDANC E.S ?L)A~S WUEL SEN3 LES GALCULAIEUKS;>UNI--IL3 APPLIQUEb A LA RECAHE~ttE UAN~LE bOMAINE DES BE&LE$-LETIRE$ ?
E$I-{,E~UE L*ANALY.~t..,AUTOMAIIQUE DES IE&TE~ AETE UTL~.E, PAR ExEMPLE, POUR DETEKMANERL?AUTEUR PROBABLE DoOUVKAGE~ ANUNVME~ UUPOUR, FA~RE DES C,~\]N~UI~UAN~,E$ ?INWIEwEIT  HERUEN COMPUTER-SYSTEME ZURFOK~CHUN~ AUF UEM ~|ET  DER $CHUENENL|TEKAIUR VERWENDET ?
HAT SIGHMA~CH|NELLE SPRACHENANALYSE ALSH ILFRb lCH ERH|E~EN, UM Z .~.
DIEVERMU|LIGHE AUIORENSGHAFT ~EI ANONYMENWERKEN ZU EEST|MMEN ODER UM.KONKORDANZENZU&AMMENZUSIELLEN ?.Query QB 13 in Three LanguagesFig.
4-17 -into German by a native German speaker.
The English queries were thenprocessed against both the English and the German collections (runs E-E andE-G), and the same was done for the translated German queries (runs G-E andG-G, respectively).
Relevance assessments were made for each English docu-ment abstract with respect to each English query by a set of eight Americanstudents in library science, and the assessors were not identical to theusers who originally submitted the search requests.
The German relevanceassessments (German documents against German queries), on the other hand,were obtained from a different, German speaking, assessor.The principal evaluation results for the four runs using the the-saurus process are shown in Fig.
5, averaged over 48 queries in each case.It is clear from the output of Fig.
5 that the cross-language runs, E-G(English queries - German documents} and G-E (German queries - English docu-ments), are not substantially inferior to the corresponding output withina single language (G-G and E-E, respectively), the difference being of theorder of 0.02 to 0.03 for a given recall level.
On the other hand, bothruns using the German document collection are inferior to the runs with theEnglish collection.The output of Fig.
5 leads to the following principal conclusions:a) the query processing is comparable in both languages; for ifthis were not the case, then one would expect one set ofquery runs to be much less effective than the other (that is,either E-E and E-G, or else G-G and G-El;b) the language processing methods (that is, thesaurus categories,suffix cut-off procedures, etc.)
are equally effective inboth cases; if this were not the case, one would expect oneof the single language runs to come out very poorly, but-18 -t .
.
~0 t ' -  m ~NmO~o ~_~o .~ ~ o ~ o=~ ~=.
I I / / /?
~ 'o  ~.
~.
~.
~.Q.?
- _  I ~ I I II1.
- -I J)Ue a.oq).
cI -L.00E L_?D(.9u~r *u )?~c~t -uJt -o u )?moE0oUU)0mu~-19-c)d)The foreignneither E-E, nor G-G came out as the poorest run;the cross-language runs are performed properly, for if thiswere not the cased one would expect E-G and G-E to performmuch less well than the runs within a single language; sincethis is not the case, the principal conclusion is then ob-vious that documents in one language can be matched againstqueries in.~nothe F nearl \[ as well a 9 documents a~d ~ue~iesin a single language;'the runs using the German document collection (E-G and G-G)are less effective than those performed with the Englishcollection; the indication is then apparent that some char-acteristic connected with the German document collectionitself - for example, the type of abstract, or the languageof the abstract, or the relevance assessments - requiresimprovement; the effectiveness of the cross-language pro-cessing, however, is not at issue.language analysis is summarized in Table 3.6.
Failure AnalysisSince the query processing operates equally well in both languages,while the German document collection produces a degraded performance, itbecomes worthwhile to examine the principal differences between the twodocument collections.
These are summarized in Table 4.
The following prin-cipal distinctions arise:a) the organization of the thesaurus used to group words orword stems into thesaurus categories;b) the completeness of the thesaurus in terms of words includedin it;c) the type of document abstracts included in the collection;-20-TranslationProblemPoor query processingor poor translationPoor language processingPoor cross-languageprocessingPoor processing of onedocument collectionCorresponding ObservationE-E and E-G much betterthan G-E and G-G, orvice-versaEither E-E or G-G muchpoorer than cross-languagerunsBoth E-G and G-E poorerthan other runsEither E-G and G-G, orelse G-E and E-E simul-taneously poorObservationConfirmedNoNoNoYesE-E: English-quePies - English documentsE-G: English queries - German documentsG-E: German queries - English documentsG-G: German queries - Get, nan documentsAnalysis of Foreign Language ProcessingTable 3-21-Document Collection Characteristics of CollectionsEnglish GermanNumber of document abstracts 1095 468Number of documents common to 50 50both collectionsNumber of queries used in test 48 48Number of relevance assessors 8 1Number of common relevance 0 0assessorsGenerality of collection 0.013 0.029(number of relevant documentsover total number of documentsin collection)Average number of word occurrences 6.5 15.5not found in the thesaurusduring look-up of documentabstractsCharacteristics of Document CollectionsTable 4-22-d) the accuracy of the relevance assessments obtained from thecollections.Concerning first the organization of the multi-lingual thesaurus,it does not appear that any essential difficulties arise on that account.This is confirmed by the fact that the cross-language runs operate satis-factorily, and by the output of Fig.
6 (a) comparing a German word stemrun (using standard suffix cut-off and weighting procedures~ with a Germanthesaurus run.
It is seen that the German thesaurus improves performanceover word stems for the German collection in the same way as the Englishthesaurus was seen earlier to improve retrieval effectiveness over the Eng-lish word stem analysis.
\[2,3\]The other thesaurus characteristic - that is its completeness -appears to present a more serious problem.
Table 4 shows that only approx-imately 6.5 English words per document abstract were not included in theEnglish thesaurus, whereas over 15 words per abstract were missing fromthe German thesaurus.
Obviously, if the missing words turn out to beimpe~;tant for content analysis purposes, the German abstracts will be moredifficult to analyze than their English counterpart.
A brief analysisconfirms that many of the missing German words, which do not therefore pro-duce concept numbers assignable to the documents, are indeed important forcontent identification.
Fig.
7, listing the words not found for document0059 shows that 12 out of 14 missing words appear to be important for theanalysis of that document.
It would therefore seem essential that a morecomplete thesaurus be used under operational conditions and for futureexperiments.The other two collection characteristics, including the type of-23 -I ~ "  ~ro  .
.
.
.
N .
- -~"GI1.~.
N. -- --  .ILli I n-c; I::o o.9"G-  o ~~ -O.II a I?
oo, -  ou qO.~.
~.
- o. q~ 1 ~  O~o c; c; c~ c~ I| I I ii .0o,I)n-ID4-  =10, .cE ~U ~C C I?1U~ 0~ ....-Oo4)E"o4) ut-o4)"ocoiht .
_o Iht -F -~oL~-24 -00Q.u J, ,~~U~w~.~ ~ ~ ~ ~ 0 ~ .~, ~ 1~ ~;  ~ 1~ ~1~ X ~ ,1~, , l~ ,~ ,~.
~z ~ '  .
, j  UA ,- -  ~,- Z*~, ,0 uJ t,,, ,~  ~ ~3 ~u UJ .,,J ~1,~.
~,, .~f4F-,I:::I o,~;::10 r. .4-~000g,,-4o0 t-,00 .
?2 0 0 0 0 ~ 0-25-abstracts and the accuracy of the relevance judgments are more difficultto assess, since these are not subject to statistical analysis.
It is afact that for some of the German documents informative abstracts are notavailable.
For example, the abstract for document 028, included in Fig.
8,indicates that the corresponding document is a conference proceedings; verylittle is known about the subject matter of the conference, but the docu-ment was nevertheless judged relevant to six different queries (nos.
17, 27,31, 32, 52, and 531 dealing with subjects as diverse as "behavioral studiesof information system users" (query 17~, and "the study of machine transla-tion" (query 27).
One might quarrel with such relevance assessments, andwith the inclusion of such documents in a test collection, particularlyalso since Fig.
6 (b} shows that the German queries operate more effectivelywith the English collection (using English relevance assessments) than withthe German assessments.
However, earlier studies using a variety of rele-vance assessments with the sam~document collection have shown that recall-precision results are not affected by ordinary differences in relevanceassessments.
\[81 For this reason, it would be premature to assume that theperformance differences are primarily due to distinctions in the relevanceassessments or in the collection make-up.7.
ConclusionAn experiment using a multi-lingual thesaurus in conjunction withtwo d~.fferent document collections, in German and English respectively, hasshown that cross-language processing (for example, German queries againstEnglish documents) is nearly as effective as processing within a single lan-guage.
Furthermore, a simple translation of thesaurus categories appears' 0  ,,J t~ l - .
,.J .
,~' ~i,~,~ .
i I  U j  uiI --I Iml ,~ 'u J~CJU JLSQJ ~.~a~~U i~U U~U J~ ~U~ , .
, .Z  :I~C3 ,~.~ZC~ 0~, ,~Vl  OU.V) U. '
I a .~i .
i i -~  I,L,I,( '~ , .
.~7w, .
.
,  w :~C~Z,Z  ~ I -Lo .1 t~ z~)  a=:~,.
.
,  .ut (~rK.~.
~ l J J,C) a.
"ru .~ 'Z  t.3, .~UJ l - .
Z ~1~ uJ~-~Z u JLO l~.
l .
.
.o ~  zo r~ c~ u j  r ~l.,.
,4  U.
Z Z~ ' ~~ ~ .
~, .
~  .
.
.
.~ ~ : ~~ ~ ~~U ~ !
; ~ '~ '~ ~ Z ' ~, ~ ~~ ~ ~~z  ~W ~ W ~ W Z-26-~'ZI~UJtn lM ?~~-., =C qt)r3I I J  * "~ "V' ,,JUJ I "  ?m~tU,U J~NU: l :~ I,,'1 C) zz~,: : )u J,.J t~') c)Zu Jc )Z k,-Z : l :w .
J  0uJ .
J  u,.
(,.~ I,,,.
,,,~=~.knC3 u't 0~ ::::) Z~?3Z.
JZO:3  u t  ~d:)... t,u Z~ U Z ~  ~ z ~7 ~ Z ~ .Z~ ~ .~ z ~  ~~~ O~ ~ z~ ~ ~ ~ ~.
~  ~Z Q ~ Z~ Z ~ z ~E-,0oill,-tu.~co ...-I-27-to produce a document content analysis which is equally effective in Eng-lish as in German.
In particular, differences in morphology (for example,in the suffix cut-off rules\], and in language ambiguities do not seem tocause a substantial degradation when moving from one language to another.For these reasons, the automatic retrieval methods used in the SMART systemfor English appear to be applicable also to foreign language material.Future experiments with foreign language documents should be carriedout using a thesaurus that is reasonably complete in all languages, andwith identical query and document collections for which the same relevancejudgments may then be applicable across all runs.-28-References\[i~ G. Salton and M. E. Lesk, The SMART Automatic Document RetrievalSystem - An Illustration, Communications of the ACM, Vol.
8, No.
6,June 1965.\[21 G. Salton, Automatic Information Organization and Retrieval, McGrawHill Book Company, New York, 1968, 514 pages.\[3\] G. Salton and M. E. Lesk, Computer Evaluation of Indexing and TextProcessing, Journal of the ACM, Vol.
15, No.
i, January 1968.\[41 C. W. Cleverdon and E. M. Keen, Factors Determining the Performanceof Indexing Systems, Vol.
i: Design, Vol.
2: Test Results, AslibCranfield Research Project, Cranfield, England, 1966.\[51 G. Salton, A Comparison Between Manual and Automatic Indexing Methods,American Documentation, Vol.
20, No.
i, January 1969.\[6\] F. W. Lancaster, Evaluation of the Operating Efficiency of Medlars,Final Report, National Library of Medicine, Washington, January 1969.\[7J J. H. Williams, Computer Classification of Documents, FID-IFIPConference on Mechanized Documentation, Rome, June 1967.\[8\] M. E. Lesk and G. Salton, Relevance Assessments and Retrieval SystemEvaluation, Information Storage and Retrieval, Vol.
4~ No.
4, October1968.
