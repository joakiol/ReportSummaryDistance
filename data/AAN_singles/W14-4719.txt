Zock/Rapp/Huang (eds.
): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 144?153,Dublin, Ireland, August 23, 2014.Lexical Access Preference and Constraint Strategies for ImprovingMultiword Expression Association within Semantic MT EvaluationDekai Wu Lo Chi-kiu Markus SaersHKUSTHuman Language Technology CenterDepartment of Computer Science and EngineeringHong Kong University of Science and Technology{dekai|jackielo|masaers|dekai}@cs.ust.hkAbstractWe examine lexical access preferences and constraints in computing multiword expression asso-ciations from the standpoint of a high-impact extrinsic task-based performance measure, namelysemantic machine translation evaluation.
In automated MT evaluation metrics, machine transla-tions are compared against human reference translations, which are almost never worded exactlythe sameway except in the most trivial of cases.
Because of this, one of the most important factorsin correctly predicting semantic translation adequacy is the accuracy of recognizing alternativelexical realizations of the same multiword expressions in semantic role fillers.
Our results com-paring bag-of-words, maximum alignment, and inversion transduction grammars indicate thatcognitively motivated ITGs provide superior lexical access characteristics for multiword expres-sion associations, leading to state-of-the-art improvements in correlation with human adequacyjudgments.1 IntroductionWe investigate lexical access strategies in the context of computing multiword expression associationswithin automatic semantic MT evaluation metrics?a high-impact real-world extrinsic task-based per-formance measure.
The inadequacy of lexical coverage of multiword expressions is one of the seriousissues in machine translation and automatic MT evaluation; there are simply too many forms to enumer-ate explicitly within the lexicon.
Automatic MT evaluation has driven machine translation research for adecade and a half, but until recently little has been done to use lexical semantics as the main foundationfor MT metrics.
Common surface-form oriented metrics like BLEU (Papineni et al., 2002), NIST (Dod-dington, 2002), METEOR (Banerjee and Lavie, 2005), CDER (Leusch et al., 2006), WER (Nie?en et al.,2000), and TER (Snover et al., 2006) do not explicitly reflect semantic similarity between the referenceand machine translations.
Several large scale meta-evaluations (Callison-Burch et al., 2006; Koehn andMonz, 2006) have in fact reported that BLEU significantly disagrees with human judgments of translationadequacy.Recently, the MEANT semantic frame based MT evaluation metrics (Lo and Wu, 2011a, 2012; Lo etal., 2012; Lo andWu, 2013b), have instead directly couchedMT evaluation in the more cognitive terms ofsemantic frames, by measuring the degree to which the basic event structure is preserved by translation?the ?who did what to whom, for whom, when, where, how and why?
(Pradhan et al., 2004)?emphasizingthat a good translation is one that can successfully be understood by a human.
Across a variety of languagepairs and genres, MEANT was shown to correlate better with human adequacy judgment than both n-gram based MT evaluation metrics such as BLEU (Papineni et al., 2002), NIST (Doddington, 2002), andMETEOR (Banerjee and Lavie, 2005), as well as edit-distance based metrics such as CDER (Leusch etal., 2006), WER (Nie?en et al., 2000), and TER (Snover et al., 2006) when evaluatingMT output (Lo andWu, 2011a, 2012; Lo et al., 2012; Lo and Wu, 2013b; Mach?
?ek and Bojar, 2013).
Furthermore, tuningthe parameters of MT systems with MEANT instead of BLEU or TER robustly improves translationThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedingsfooter are added by the organizers.
License details: \url{http://creativecommons.org/licenses/by/4.0/144Figure 1: Examples of automatic shallow semantic parses.
Both the reference and machine translationsare parsed using automatic English SRL.
There are no semantic frames for MT3 since automatic SRLdecided to drop the predicate.adequacy (Lo et al., 2013a; Lo and Wu, 2013a; Lo et al., 2013b) across different languages (Englishand Chinese) and different genres (formal newswire text, informal web forum text and informal publicspeech).Because of this, we have chosen to run our lexical association experiments in the context of the neces-sity of recognizingmatching semantic role fillers, approximately 85%ofwhich aremultiword expressionsin our data, the overwhelming majority of which would not be enumerated within conventional lexicons.We compare four common lexical access approaches to aggregation, preferences, and constraints: bag-of-words, two different types of maximal alignment, and inversion transduction grammar based methods.2 BackgroundThe MEANT metric measures weighted f-scores over corresponding semantic frames and role fillersin the reference and machine translations.
Whereas HMEANT uses human annotation, the automaticversions of MEANT instead replace humans with automatic SRL and alignment algorithms.
MEANTtypically outperforms BLEU, NIST, METEOR, WER, CDER and TER in correlation with human ade-quacy judgment, and is relatively easy to port to other languages, requiring only an automatic semanticparser and a monolingual corpus of the output language, which is used to gauge lexical similarity betweenthe semantic role fillers of the reference and translation.
More precisely, MEANT computes scores asfollows:1.
Apply an automatic shallow semantic parser to both the references and MT output.
(Figure 1 showsexamples of automatic shallow semantic parses on both reference and MT.)2.
Apply the maximum weighted bipartite matching algorithm to align the semantic frames betweenthe references and MT output according to the lexical similarities of the predicates.3.
For each pair of the aligned frames, apply the maximum weighted bipartite matching algorithm toalign the arguments between the reference and MT output according to the lexical similarity of rolefillers.4.
Compute the weighted f-score over the matching role labels of these aligned predicates and rolefillers according to the following definitions:145q0i,j?
ARG j of aligned frame i in MTq1i,j?
ARG j of aligned frame i in REFw0i?#tokens filled in aligned frame i of MTtotal #tokens in MTw1i?#tokens filled in aligned frame i of REFtotal #tokens in REFwpred ?
weight of similarity of predicateswj?
weight of similarity of ARG jei,pred ?
the pred of the aligned frame i of the machine translationfi,pred ?
the pred of the aligned frame i of the reference translationei,j?
the ARG j of the aligned frame i of the machine translationfi,j?
the ARG j of the aligned frame i of the reference translations(e, f) = lexical similarity of token e and fprece,f =?e?e maxf?fs(e, f)| e |rece,f =?f?f maxe?es(e, f)| f |precision =?iw0iwpredsi,pred+?jwjsi,jwpred+?jwj|q0i,j|?iw0irecall =?iw1iwpredsi,pred+?jwjsi,jwpred+?jwj|q1i,j|?iw1iMEANT = 2 ?
precision ?
recallprecision + recallwhere the possible approaches to defining the lexical associations si,pred and si,j are discussed in thefollowing section.
q0i,jand q1i,jare the argument of type j in frame i in MT and REF, respectively.
w0iand w1iare the weights for frame i in MT and REF, respectively.
These weights estimate the degreeof contribution of each frame to the overall meaning of the sentence.
wpred and wj are the weights ofthe lexical similarities of the predicates and role fillers of the arguments of type j of all frame betweenthe reference translations and the MT output.
There is a total of 12 weights for the set of semantic rolelabels in MEANT as defined in Lo and Wu (2011b).
For MEANT, they are determined using supervisedestimation via a simple grid search to optimize the correlation with human adequacy judgments (Lo andWu, 2011a).
For UMEANT (Lo and Wu, 2012), they are estimated in an unsupervised manner usingrelative frequency of each semantic role label in the references and thus UMEANT is useful when humanjudgments on adequacy of the development set are unavailable.3 Comparison of multiword expression association approachesTo assess alternative lexical access preferences and constraints for computing multiword expressionassociations, we now consider four alternative approaches to defining the lexical similarities si,pred andsi,j, all of which employ a standard context vector model of the individual words/tokens in the multiwordexpression arguments between the reference and machine translations, as descibed by Lo et al.
(2012)and Tumuluru et al.
(2012).3.1 Bag of words (geometric mean)The original MEANT approaches employed standard a bag-of-words strategy for lexical association.This baseline approach applies no alignment constraints on multiword expressions:si,pred = e?e?ei,pred?f?fi,predlg(s(e,f))|ei,pred|?|fi,pred|si,j= e?e?ei,j?f?fi,jlg(s(e,f))|ei,j|?|fi,j|1463.2 Maximum alignment (precision-recall average)In the first maximum alignment based approach we will consider, the definitions of si,pred and si,j areinspired by Mihalcea et al.
(2006) who normalize phrasal similarities according to the phrase length.si,pred =12(precei,pred,fi,pred + recei,pred,fi,pred)si,j=12(precei,j,fi,j+ recei,j,fi,j)3.3 Maximum alignment (f-score)The second of the maximum alignment based approaches replaces the above linear averaging of pre-cision and recall with a proper f-score.
Although this is less consistent with the previous literature, suchas Mihalcea et al.
(2006), it seems more consistent with the overall f-score based approach of MEANT,and thus we include it in our comparison as a variant of the maximum alignment strategy.si,pred =2 ?
precei,pred,fi,pred ?
recei,pred,fi,predprecei,pred,fi,pred + recei,pred,fi,predsi,j=2 ?
precei,j,fi,j?
recei,j,fi,jprecei,j,fi,j+ recei,j,fi,j3.4 Inversion transduction grammar basedThere has been to date relatively little use of inversion transduction grammars (Wu, 1997) to improvethe accuracy of MT evaluation metrics?despite (1) long empirical evidence the vast majority of transla-tion patterns between human languages can be accommodated within ITG constraints, and (2) the obser-vation thatmost current state-of-the-art SMT systems employ ITG decoders.
Especially when consideringsemanticMTmetrics, ITGs would seem to be a natural strategy for multiword expression association forseveral cognitively motivated reasons, having to do with language universal properties of cross-linguisticsemantic frame structure.To begin with, it is quite natural to think of sentences as having been generated from an abstract conceptusing a rewriting system: a stochastic grammar predicts how frequently any particular realization of theabstract concept will be generated.
The bilingual analogy is a transduction grammar generating a pairof possible realizations of the same underlying concept.
Stochastic transduction grammars predict howfrequently a particular pair of realizations will be generated, and thus represent a good way to evaluatehow well a pair of sentences correspond to each other.The particular class of transduction grammars known as ITGs tackle the problem that the (bi)parsingcomplexity for general syntax-directed transductions (Aho and Ullman, 1972) is exponential.
Byconstraining a syntax-directed transduction grammar to allow only monotonic straight and invertedreorderings, or equivalently permitting only binary or ternary rank rules, it is possible to isolate the lowend of that hierarchy into a single equivalence class of inversion transductions.
ITGs are guaranteed tohave a two-normal form similar to context-free grammars, and can be biparsed in polynomial time andspace (O(n6)time and O(n4)space).
It is also possible to do approximate biparsing in O(n3)time(Saers et al., 2009).
These polynomial complexities makes it feasible to estimate the parameters of anITG using standard machine learning techniques such as expectation maximization (Wu, 1995b) .At the same time, inversion transductions have also been directly shown to be more than sufficientto account for the reordering that occur within semantic frame alternations (Addanki et al., 2012).
Thislanguage universal property has an evolutionary explanation in terms of computational efficiency andcognitive load for language learnability and interpretability (Wu, 2014).ITGs are thus an appealing alternative for evaluating the possible links between both semantic rolefillers in different languages as well as the predicates, and how these parts fit together to form entiresemantic frames.
We believe that ITGs are not only capable of generating the desired structural corre-spondences between the semantic structures of two languages, but also provide meaningful constraintsto prevent alignments from wandering off in the wrong direction.Following this reasoning, alternate definitions of si,pred and si,j can be constructed in terms of brack-eting ITGs (also known as BITGs or BTGs) which are ITGs containing only a single non-differentiated147nonterminal category (Wu, 1995a).
The idea is to attack a potential weakness of the foregoing threelexical association strategies, namely that word/token alignments between the reference and machinetranslations are severely underconstrained.
No bijectivity or permutation restrictions are applied, evenbetween compositional segments where this should be natural.
This can cause multiword expressions ofsemantic role fillers to be matched even when they should not be.
In contrast, using a bracketing inver-sion transduction grammar can potentially better constrain permissible token alignment patterns betweenaligned role filler phrases.
Figure 2 illustrates how the ITG constraints are consistent with the neededpermutations between semantic role fillers across the reference and machine translations for a samplesentence from the evaluation data.In this approach, both alignment and scoring are performed utilizing a length-normalized weightedBITG (Wu, 1997; Zens and Ney, 2003; Saers and Wu, 2009; Addanki et al., 2012).
We define si,pred andsi,jas follows.si,pred = lg?1?
?lg(P(A ??
ei,pred/fi,pred|G))max(| ei,pred |, | fi,pred |)?
?si,j= lg?1?
?lg(P(A ??
ei,j/fi,j|G))max(| ei,j|, | fi,j|)?
?whereG ?
?
{A} ,W0,W1,R,A?R ?
{A ?
[AA] ,A ?
?AA?,A ?
e/f}p ([AA] |A) = p (?AA?|A) = 1p (e/f |A) = s(e, f)Here G is a bracketing ITG whose only nonterminal is A, and R is a set of transduction rules withe ?
W0?
{?}
denoting a token in the MT output (or the null token) and f ?
W1 ?
{?}
denotinga token in the reference translation (or the null token).
The rule probability (or more accurately, ruleweight) function p is set to be 1 for structural transduction rules, and for lexical transduction rules it isdefined by MEANT?s lexical similarity measure on English Gigaword context vectors.
To calculate theinside probability (or more accurately, inside score) of a pair of segments, P(A ??
e/f|G), we use thealgorithm described in Saers et al.
(2009).
Given this, si,pred and si,j now represent the length normalizedBITG parse scores of the predicates and role fillers of the arguments of type j between the reference andmachine translations.4 ExperimentsIn this section we discuss experiments comparing the four alternative lexical access preference andconstraint strategies.4.1 Experimental setupWe compared using the DARPA GALE P2.5 Chinese-English translation test set, as used in Lo andWu (2011a).
The corpus includes the Chinese input sentences, each accompanied by an English referencetranslation and three participating state-of-the-art MT systems?
output.We computed sentence-level correlations following the benchmark assessment procedure used byWMT and NIST MetricsMaTr (Callison-Burch et al., 2008, 2010, 2011, 2012; Mach?
?ek and Bojar,2013), which use Kendall?s ?
correlation coefficient, to evaluate the correlation of evaluation metricsagainst human judgment on ranking the translation adequacy of the three systems?
output.
A highervalue for Kendall?s ?
indicates more similarity to the human adequacy rankings by the evaluation met-rics.
The range of possible values of Kendall?s ?
correlation coefficient is [-1, 1], where 1 means the148Table 1: Sentence-level correlation with human adequacy judgements on different partitions of GALEP2.5 data.
For reference, the human HMEANT upper bound is 0.53?so the fully automatic ITG basedMEANT approximation is not far from closing the gap.Kendall correlationMEANT + ITG based 0.51MEANT + maximum alignment (f-score) 0.48MEANT + maximum alignment (average of precision & recall) 0.46MEANT + bag of words (geometric mean) 0.38NIST 0.29METEOR 0.20BLEU 0.20TER 0.20PER 0.20CDER 0.12WER 0.10systems are ranked in the same order as the human judgment by the evaluation metric; and -1 means thesystems are ranked in the reverse order as human judgment by the evaluation metric.For both reference and machine translations, the ASSERT (Pradhan et al., 2004) semantic role labelerwas used to automatically predict semantic parses.4.2 Results and discussionThe sentence-level correlations in Table 1 show that the ITG based strategy outperforms other auto-matic metrics in correlation with human adequacy judgment.
Note that this was achieved with no tuningwhatsoever of the rule weights (suggesting that the performance could be further improved in the futureby slightly optimizing the ITG weights).The ITG based strategy shows 3 points improvement over the next best strategy, which is maximalalignment under f-score aggregation.
The ITG based approach produces much higher HAJ correlationsthan any of the other metrics.In fact, the ITG based strategy even comes within a few points of the human upper bound bench-mark HAJ correlations computed using the human labeled semantic frames and alignments used in theHMEANT.Data analysis reveals two reasons that the ITG based strategy correlates with human adequacy judge-ment more closely than the other approaches.
First, BITG constraints indeed provide more accuratephrasal similarity aggregation, compared to the naive bag-of-words based heuristics.
Similar resultshave been observed while trying to estimate word alignment probabilities where BITG constraints out-performed alignments from GIZA++ (Saers and Wu, 2009).
Secondly, the permutation and bijectivityconstraints enforced by the ITG provide better leverage to reject token alignments when they are notappropriate, compared with the maximal alignment approach which tends to be rather promiscuous.
TheITG tends whenever appropriate to accept clean, sparse alignments for role fillers, prefering to leavetokens unaligned instead of aligning them anyway as the other strategies tend to do.
Note that it is notsimply a matter of lowering thresholds for accepting token alignments: Tumuluru et al.
(2012) showedthat the competitive linking approach (Melamed, 1996) does not work as well as the strategies consideredin this paper, whereas the ITG appears to be selective about the token alignments in a manner that betterfits the semantic structure.5 ConclusionWe have compared four alternative lexical access strategies for aggregation, preferences, and con-straints in scoringmultiword expression associations that are far too numerous to be explicitly enumeratedin lexicons, within the context of semantic frame based machine translation evaluation: bag-of-words,149Figure 2: An example of aligning automatic shallow semantic parses under ITGs, visualized using bothbiparse tree and alignment matrix depictions, for the Chinese input sentence ????????????????????
Both the reference and machine translations are parsed using automatic English SRL.Compositional alignments between the semantic frames and the tokens within role filler phrases obeyinversion transduction grammars.150two maximum alignment based approaches, and an inversion transduction grammar based approach.Controlled experiments within the MEANT semantic MT evaluation framework shows that the cog-nitively motivated ITG based strategy achieves significantly higher correlation with human adequacyjudgments of MT output quality than the more typically used lexical association approaches.
The resultsshow how to improve upon previous research showing that MEANT?s explicit use of semantic framesleads to state-of-the-art automatic MT evaluation, by aligning and scoring semantic frames under a sim-ple, consistent ITG that provides empirically informative permutation and bijectivity biases, instead ofmore naive maximal alignment or bag-of-words assumptions.Cognitive studies of the lexicon are often described using intrinsic measures of quality.
Our exper-iments complement this by situating the empirical comparisons within extrinsic real-world task-basedperformance measures.
We believe that progress can be accelerated via a combination of intrinsic andextrinsic measures of lexicon acquisition and access models.AcknowledgmentsThis material is based upon work supported in part by the Defense Advanced Research ProjectsAgency (DARPA) under BOLT contract nos.
HR0011-12-C-0014 and HR0011-12-C-0016, and GALEcontract nos.
HR0011-06-C-0022 and HR0011-06-C-0023; by the European Union under the FP7grant agreement no.
287658; and by the Hong Kong Research Grants Council (RGC) research grantsGRF620811, GRF621008, and GRF612806.
Any opinions, findings and conclusions or recommenda-tions expressed in this material are those of the authors and do not necessarily reflect the views of DARPA,the EU, or RGC.ReferencesKarteek Addanki, Chi-kiu Lo, Markus Saers, and Dekai Wu.
LTG vs. ITG coverage of cross-lingual verbframe alternations.
In 16th Annual Conference of the European Association for Machine Translation(EAMT-2012), Trento, Italy, May 2012.Alfred V. Aho and Jeffrey D. Ullman.
The Theory of Parsing, Translation, and Compiling.
Prentice-Halll,Englewood Cliffs, New Jersey, 1972.Satanjeev Banerjee and Alon Lavie.
METEOR: An automatic metric for MT evaluation with improvedcorrelation with human judgments.
In Workshop on Intrinsic and Extrinsic Evaluation Measures forMachine Translation and/or Summarization, Ann Arbor, Michigan, June 2005.Chris Callison-Burch, Miles Osborne, and Philipp Koehn.
Re-evaluating the role of BLEU in machinetranslation research.
In 11th Conference of the European Chapter of the Association for ComputationalLinguistics (EACL-2006), 2006.Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder.
Furthermeta-evaluation of machine translation.
In Third Workshop on Statistical Machine Translation (WMT-08), 2008.Chris Callison-Burch, Philipp Koehn, Christof Monz, Kay Peterson, Mark Pryzbocki, and Omar Zaidan.Findings of the 2010 joint workshop on statistical machine translation and metrics for machine trans-lation.
In Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR (WMT10), pages17?53, Uppsala, Sweden, 15-16 July 2010.Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar F. Zaidan.
Findings of the 2011Workshop on Statistical Machine Translation.
In 6th Workshop on Statistical Machine Translation(WMT 2011), 2011.Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia.
Find-ings of the 2012 workshop on statistical machine translation.
In 7th Workshop on Statistical MachineTranslation (WMT 2012), pages 10?51, 2012.151George Doddington.
Automatic evaluation of machine translation quality using n-gram co-occurrencestatistics.
In The second international conference on Human Language Technology Research(HLT ?02), San Diego, California, 2002.Philipp Koehn and Christof Monz.
Manual and automatic evaluation of machine translation betweeneuropean languages.
InWorkshop on Statistical Machine Translation (WMT-06), 2006.Gregor Leusch, Nicola Ueffing, and Hermann Ney.
CDer: Efficient MT evaluation using block move-ments.
In 11th Conference of the European Chapter of the Association for Computational Linguistics(EACL-2006), 2006.Chi-kiu Lo and Dekai Wu.
MEANT: An inexpensive, high-accuracy, semi-automatic metric for evaluat-ing translation utility based on semantic roles.
In 49th Annual Meeting of the Association for Compu-tational Linguistics: Human Language Technologies (ACL HLT 2011), 2011.Chi-kiu Lo and Dekai Wu.
SMT vs. AI redux: How semantic frames evaluate MT more accurately.
InTwenty-second International Joint Conference on Artificial Intelligence (IJCAI-11), 2011.Chi-kiu Lo and Dekai Wu.
Unsupervised vs. supervised weight estimation for semantic MT evaluationmetrics.
In Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation (SSST-6),2012.Chi-kiu Lo and Dekai Wu.
Can informal genres be better translated by tuning on automatic semanticmetrics?
In 14th Machine Translation Summit (MT Summit XIV), 2013.Chi-kiu Lo and Dekai Wu.
MEANT at WMT 2013: A tunable, accurate yet inexpensive semantic framebased mt evaluation metric.
In 8th Workshop on Statistical Machine Translation (WMT 2013), 2013.Chi-kiu Lo, Anand Karthik Tumuluru, and Dekai Wu.
Fully automatic semantic MT evaluation.
In 7thWorkshop on Statistical Machine Translation (WMT 2012), 2012.Chi-kiu Lo, Karteek Addanki, Markus Saers, and Dekai Wu.
Improving machine translation by trainingagainst an automatic semantic frame based evaluationmetric.
In 51st AnnualMeeting of the Associationfor Computational Linguistics (ACL 2013), 2013.Chi-kiu Lo, Meriem Beloucif, and Dekai Wu.
Improving machine translation into Chinese by tuningagainst Chinese MEANT.
In International Workshop on Spoken Language Translation (IWSLT 2013),2013.Matou?
Mach?
?ek and Ond?ej Bojar.
Results of the WMT13 metrics shared task.
In Eighth Workshopon Statistical Machine Translation (WMT 2013), Sofia, Bulgaria, August 2013.I.
DanMelamed.
Automatic construction of clean broad-coverage translation lexicons.
In 2nd Conferenceof the Association for Machine Translation in the Americas (AMTA-1996), 1996.Rada Mihalcea, Courtney Corley, and Carlo Strapparava.
Corpus-based and knowledge-based measuresof text semantic similarity.
In The Twenty-first National Conference on Artificial Intelligence (AAAI-06), volume 21.
Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, 2006.Sonja Nie?en, Franz Josef Och, Gregor Leusch, and Hermann Ney.
A evaluation tool for machine transla-tion: Fast evaluation forMT research.
In The Second International Conference on Language Resourcesand Evaluation (LREC 2000), 2000.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
BLEU: a method for automatic evalua-tion of machine translation.
In 40th Annual Meeting of the Association for Computational Linguistics(ACL-02), pages 311?318, Philadelphia, Pennsylvania, July 2002.Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James H. Martin, and Dan Jurafsky.
Shallow semanticparsing using support vector machines.
In Human Language Technology Conference of the NorthAmerican Chapter of the Association for Computational Linguistics (HLT-NAACL 2004), 2004.Markus Saers and Dekai Wu.
Improving phrase-based translation via word alignments from stochasticinversion transduction grammars.
In Third Workshop on Syntax and Structure in Statistical Translation(SSST-3), pages 28?36, Boulder, Colorado, June 2009.152Markus Saers, JoakimNivre, and DekaiWu.
Learning stochastic bracketing inversion transduction gram-mars with a cubic time biparsing algorithm.
In 11th International Conference on Parsing Technologies(IWPT?09), pages 29?32, Paris, France, October 2009.Matthew Snover, Bonnie Dorr, Richard Schwartz, LinneaMicciulla, and JohnMakhoul.
A study of trans-lation edit rate with targeted human annotation.
In 7th Biennial Conference Association for MachineTranslation in the Americas (AMTA 2006), pages 223?231, Cambridge, Massachusetts, August 2006.Anand Karthik Tumuluru, Chi-kiu Lo, and Dekai Wu.
Accuracy and robustness in measuring the lex-ical similarity of semantic role fillers for automatic semantic MT evaluation.
In 26th Pacific AsiaConference on Language, Information, and Computation (PACLIC 26), 2012.Dekai Wu.
An algorithm for simultaneously bracketing parallel texts by aligning words.
In 33rd An-nual Meeting of the Association for Computational Linguistics (ACL 95), pages 244?251, Cambridge,Massachusetts, June 1995.Dekai Wu.
Trainable coarse bilingual grammars for parallel text bracketing.
In Third Annual Workshopon Very Large Corpora (WVLC-3), pages 69?81, Cambridge, Massachusetts, June 1995.Dekai Wu.
Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.
Com-putational Linguistics, 23(3):377?403, 1997.Dekai Wu.
The magic number 4: Evolutionary pressures on semantic frame structure.
In 10th Interna-tional Conference on the Evolution of Language (Evolang X), Vienna, Apr 2014.Richard Zens and Hermann Ney.
A comparative study on reordering constraints in statistical machinetranslation.
In 41st Annual Meeting of the Association for Computational Linguistics (ACL-2003),pages 144?151, Stroudsburg, Pennsylvania, 2003.153
