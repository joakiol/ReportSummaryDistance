Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 230?233,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsUCD-Goggle: A Hybrid System for Noun Compound ParaphrasingGuofu LiSchool of Computer Scienceand InformaticsUniversity College Dublinguofu.li@ucd.ieAlejandra Lopez-FernandezSchool of Computer Scienceand InformaticsUniversity College Dublinalejandra.lopez-fernandez@ucd.ieTony VealeSchool of Computer Scienceand InformaticsUniversity College Dublintony.veale@ucd.ieAbstractThis paper addresses the problem of rank-ing a list of paraphrases associated with anoun-noun compound as closely as possi-ble to human raters (Butnariu et al, 2010).UCD-Goggle tackles this task using se-mantic knowledge learnt from the Googlen-grams together with human-preferencesfor paraphrases mined from training data.Empirical evaluation shows that UCD-Goggle achieves 0.432 Spearman correla-tion with human judgments.1 IntroductionNoun compounds (NC) are sequences of nounsacting as a single noun (Downing, 1977).
Re-search on noun compounds involves two maintasks: NC detection and NC interpretation.
Thelatter has been studied in the context of manynatural language applications, including question-answering, machine translation, information re-trieval, and information extraction.The use of multiple paraphrases as a semanticintepretation of noun compounds has recently be-come popular (Kim and Baldwin, 2006; Nakovand Hearst, 2006; Butnariu and Veale, 2008;Nakov, 2008).
The best paraphrases are thosewhich most aptly characterize the relationship be-tween the modifier noun and the head noun.The aim of this current work is to provide aranking for a list of paraphrases that best approxi-mates human rankings for the same paraphrases.We have created a system called UCD-Goggle,which uses semantic knowledge acquired fromGoogle n-grams together with human-preferencesmined from training data.
Three major com-ponents are involved in our system: B-score,produced by a Bayesian algorithm using seman-tic knowledge from the n-grams corpus with asmoothing layer of additional inference; Rt-scorecaptures human preferences observed in the taildistribution of training data; and Rp-score cap-tures pairwise paraphrase preferences calculatedfrom the training data.
Our best system forSemEval-2 task 9 combines all three componentsand achieves a Spearman correlation of 0.432 withhuman rankings.This paper is organized as follows: the BayesianB-score is introduced in section 2.
In section 3we describe two supervised approaches to miningthe preferences of human raters from training data.Finally, section 4 presents the results of our empir-ical evaluation of the UCD-Goggle system.2 Semantic Approach2.1 Collecting DataGoogle have made their web n-grams, also knownas Web-1T corpus, public via the Linguistic DataConsortium (Brants and Franz, 2006).
This cor-pus contains sequences of n terms that occur morethan 40 times on the web.We view the paraphrase task as that of suggest-ing the right verb phrase for two nouns (But-nariu and Veale, 2008).
Previous work has shownthe n-grams corpus to be a promising resourcefor retrieving semantic evidence for this approach.However, the corpus itself needs to be tailored toserve our purpose.
Since the n-grams corpus is acollection of raw snippets from the web, togetherwith their web frequency, certain pre-processingsteps are essential before it can be used as a semi-structured knowledge base.
Following a syntac-tic pattern approach, snippets in the n-grams thatagree with the following patterns are harvested:1.
Head VP Mod2.
Head VP DET Mod3.
Head [that|which] VP Mod4.
Head [that|which] VP DET ModHere, DET denotes any of the determiners (i.e.,230the set of {an, a, the} for English), Head and Modare nouns for heads and modifiers, and VP standsfor verb-based paraphrases observed in the testdata.
It must be highlighted that, when we collectsnippets for the KB, any Head or Mod that falls outof the range of the dataset are also accepted via aprocess of semantic slippage (to be discussed inSect.
2.4).
The patterns listed above enable us tocollect examples such as:1.
?bread containing nut?2.
?pill alleviates the headache?3.
?novel which is about crimes?4.
?problem that involves the students?After a shallow parse, these snippets are formal-ized into the triple format ?Head, Para,Mod?.The sample snippets above are represented as:1.
?bread, contain, nut?2.
?pill, alleviate, headache?3.
?novel, be about, crime?4.
?problem, involve, student?We use ?Head, Para,Mod?
to denote the fre-quency of ?Head, Para,Mod?
in the n-grams.2.2 Loosely Coupled Compound AnalysisTens of millions of snippets are harvested andcleaned up in this way, yet expecting even thislarge set to provide decent coverage over the testdata is still unrealistic.
We calculated the proba-bility of an example in the test data to appear inKB at less than 1%.
To overcome the coverage is-sue, a loosely coupled analysis and representationof compounds is employed.
Despite the fact thatboth modifier and head can influence the rankingof a paraphrase, we believe that either the modifieror the head is the dominating factor in most cases.This assumption has been shown to be plausibleby earlier work (Butnariu and Veale, 2008).
Thus,instead of storing complete triples in our KB, wedivide each complete triple into two partial triplesas shown below:?Head, Para,Mod?
?
{?Head, Para, ???
?, Para,Mod?We can also retrieve these partial triples directlyfrom the n-grams corpus using partial patterns like?Head Para?
and ?Para Mod?.
However, just asshorter incomplete patterns can produce a largerKB, they also accept much more noise.
For in-stance, single-verb paraphrases are very commonamong the test data.
In these cases, the partial pat-tern approach would need to harvest snippets withthe form ?NN VV?
or ?VV NN?
from 2-grams,which are too common to be reliable.2.3 Probabilistic FrameworkIn the probabilistic framework, we define the B-score as the conditional probability of a para-phrase, Para, being suggested for a given com-pound Comp:B(Para;Comp) ?
P (Para|Comp) (1)Using the KB, we can estimate this conditionalprobability by applying the Bayes theorem:P (Para|Comp) =P (Comp|Para)P (Para)P (Comp)(2)The loose-coupling assumption (Sect.
2.2) allowsus to estimate P (Comp) as:P (Comp) ?
P (Mod ?Head).
(3)Meanwhile, a priori probabilities such asP (Para) can be easily inferred from the KB.2.4 Inferential Smoothing LayerAfter applying the loose-coupling technique de-scribed in Section 2.2, the coverage of the KBrises to 31.78% (see Figure 1).
To further in-crease this coverage, an inference layer is addedto the system.
This layer aims to stretch the con-tents of the KB via semantic slippage to the KB, asguided by the maximization of a fitness function.A WordNet-based similarity matrix is employed(Seco et al, 2004) to provide a similarity measurebetween nouns (so sim(x, x) is 1).
Then, a su-perset of Head or Mod (denoted as H andM re-spectively) can be extracted by including all nounswith similarity greater than 0 to any of them in thetest data.
Formally, for Head we have:H = {h|sim(h,Head) ?
0, Head in dataset}.
(4)The definition ofM is analogous to that ofH.A system of equations is defined to produce al-ternatives for Head and Mod and their smoothedcorpus frequencies (we show only the functionsfor head here):h0= Head (5)fit(h) = sim2(h, hn)?
?h, p, ??
(6)hn+1= arg maxh?Hfit(h) (7)231Here, fit(h) is a fitness function of the can-didate head h, in the context of a paraphrase p.Empirically, we use h1for Head and fit(h1) for?Head, Para, ??
when calculating the B-scoreback in the probabilistic framework (Sect.
2.3).
Intheory, we can apply this smoothing step repeat-edly until convergence is obtained.Figure 1: Comparison on coverage.This semantic slippage mechanism allows acomputer to infer the missing parts of the KB, bybuilding a bridge between the limitations of a fi-nite KB and the knowledge demands of an appli-cation.
Figure 1 above shows how the coverage ofthe system increases when using partial matchingand the smoothing technique, over the use of exactmatching with the KB.3 Preferences for Paraphrases3.1 Tail-based PreferenceSimilar to various types of data studied by socialscientists, the distribution of strings in our corpustends to obey Zipf?s law (Zipf, 1936).
The sameZipfian trend was also observed in the compound-paraphrase dataset: more than 190 out of 250 com-pounds in the training data have 60% of their para-phrases in an undiscriminating tail, while 245 of250 have 50% of their paraphrases in the tail.
Wethus assume the existence of a long tail in the para-phrase list for each compound.The tail of each paraphrase list can be a valuableheuristic for modeling human paraphrase prefer-ences.
We refer to this model as the tail-basedpreference model.
We assume that an occurrenceof a paraphrase is deemed to occur in the tail iff itis mentioned by the human raters only once.
Thus,the tail preference is defined as the probability thata paraphrase appears in the non-tail part of the listfor all compounds in the training data.
Formally,it can be expressed as:Rt(p) =?c?C?
(c, p)f(c, p)?c?Cf(c, p)(8)where C is the set of all compounds in the trainingdata and f(c, p) is the frequency of paraphrase pon compound c as given by the human raters.
The?
(c, p) is a filter coefficient as shown below:?
(c, p) ={1, f(c, p) > 1,0, f(c, p) = 1.
(9)The tail-based preference model is simple buteffective when used in conjunction with seman-tic ranking via the KB acquired from n-grams.However, an important drawback is that the tailmodel assigns a static preference to paraphrase(i.e., tail preferences are assumed to be context-independent).
More than that, this preference doesnot take information from non-tail paraphrasesinto consideration.
Due to these downsides, weuse pairwise preferences described below.3.2 Pairwise PreferenceTo fully utilize the training data, we employ an-other preference mining approach called pairwisepreference modeling.
This approach applies theprinciple of pairwise comparison (David, 1988)to determine the rank of a paraphrase inside a list.We build a pairwise comparison matrix ?
forparaphrases using the values of Equation 10 (herewe have assumed that each of the paraphrases hasbeen mapped into numeric values):?i,j={n(pi,pj)n(pi,pj)+n(pj,pi), n(pi, pj) > n(pj, pi),0, otherwise.
(10)where n(pi, pj) is the relative preferability of pito pj.
To illustrate the logic behind n(x, y), weimagine a scenario with three compounds shownin Table 1:abor.
prob.
abor.
vote arti.
desc.involve 12 8 3concern 10 9 5be about 3 9 15Table 1: An example1to illustrate n(x, y)1In this example, abor.
prob.
stands for abortion problem,abor.
vote stands for abortion vote, and arti.
desc.
stands forartifact description232The relative preferability is given by the numberof times that the frequency of pifrom human ratersis greater than that of pj.
Observing that 1 out of3 times involve is ranked higher than concern, wecan calculate their relative preferability as:n(involve, concern) = 1n(concern, involve) = 2Once the matrix is built, the preference score fora paraphrase i is calculated as:Rp(i; c) =?j?Pc?i,j|Pc|(11)wherePcis the list of paraphrases for a given com-pound c in the test data.
The pairwise preferenceputs a paraphrase in the context of its company, sothat the opinions of human raters can be approxi-mated more precisely.4 Empirical ResultsWe evaluated our system by tackling theSemEval-2 task 9 test data.
We created three systems withdifferent combinations of the three components(B, Rt, Rp).
Table 2 below shows the perfor-mance of UCD-Goggle for each setting:System Config Spearman ?
Pearson rI B + Rt0.380 0.252II Rp0.418 0.375III B + Rt+ Rp0.432 0.395* Baseline 0.425 0.344Table 2: Evaluation results on different settings ofthe UCD-Goggle system.The first setting is a hybrid system which firstcalculates a ranking according to the ngrams cor-pus and then applies a very simple preferenceheuristic (Sect.
2.3 and 3.1).
The second settingsimply applies the pairwise preference algorithmto the training data to learn ranking preferences(Sect.
3.2).
Finally, the third setting integratesboth of these settings in a single approach.The individual contribution of B-score and Rtwas tested by two-fold cross validation applied tothe training data.
The training data was split intotwo subsets and preferences were learnt from onepart and then applied to the other.
As an unsuper-vised algorithm, B-score produced Spearman cor-relation of 0.31 while the Rt-score gave 0.33.
Wenoticed that more than 78% of the paraphrases had0 score by Rt.
This number not only reconfirmedthe existence of the long-tail phenomenon, but alsosuggested thatRt-score alone could hardly capturethe preference on the non-tail part.
On the otherhand, with more than 80% chance we could expectB to produce a non-zero score for a paraphrase,even if the paraphrase fell out of the topic.
Whencombined together, B and Rtcomplemented eachother and improved the performance considerably.However, this combined effort still could not beatthe pairwise preference Rpor the baseline system,which had no semantic knowledge involved.
Themajor limitation of our system is that the seman-tic approach is totally ignorant of the training data.In future work, we will intend to use it as a valu-able resource in both KB construction and rankingstage.ReferencesT.
Brants and A. Franz.
2006.
Web 1T 5-gram Version1.
Linguistic Data Consortium.C.
Butnariu and T. Veale.
2008.
A concept-centeredapproach to noun-compound interpretation.
In Proc.of the 22nd COLING, pages 81?88, Manchester,UK.C.
Butnariu, S. N. Kim, P. Nakov, D.?O S?eaghdha,S.
Szpakowicz, and T. Veale.
2010.
Semeval-2 task9: The interpretation of noun compounds using para-phrasing verbs and prepositions.
In Workshop onSemantic Evaluation, Uppsala, Sweden.H.
A. David.
1988.
The Method of Paired Compar-isons.
Oxford University Press, New York.P.
Downing.
1977.
On the creation and use of Englishcompound nouns.
In Language 53, pages 810?842.S.
N. Kim and T. Baldwin.
2006.
Interpreting seman-tic relations in noun compounds via verb semantics.In Proc.
of the COLING/ACL, pages 491?498, Mor-ristown, NJ, USA.P.
Nakov and M. A. Hearst.
2006.
Using verbs to char-acterize noun-noun relations.
In Proc.
of AIMSA,pages 233?244.P.
Nakov.
2008.
Noun compound interpretation usingparaphrasing verbs: Feasibility study.
In Proc.
ofthe 13th AIMSA, pages 103?117, Berlin, Heidelberg.Springer-Verlag.N.
Seco, T. Veale, and J. Hayes.
2004.
An intrinsicinformation content metric for semantic similarityin WordNet.
In Proc.
of the 16th ECAI, Valencia,Spain.
John Wiley.G.
K. Zipf.
1936.
The Psycho-Biology of Language:An Introdution to Dynamic Philology.
Routledge,London.233
