Proceedings of the ACL 2007 Demo and Poster Sessions, pages 73?76,Prague, June 2007. c?2007 Association for Computational LinguisticsA Feature Based Approach to Leveraging Context for ClassifyingNewsgroup Style Discussion SegmentsYi-Chia Wang, Mahesh JoshiLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213{yichiaw,maheshj}@cs.cmu.eduCarolyn Penstein Ros?Language Technologies Institute/Human-Computer Interaction InstituteCarnegie Mellon UniversityPittsburgh, PA 15213cprose@cs.cmu.eduAbstractOn a multi-dimensional text categorizationtask, we compare the effectiveness of a fea-ture based approach with the use of a state-of-the-art sequential learning technique thathas proven successful for tasks such as?email act classification?.
Our evaluationdemonstrates for the three separate dimen-sions of a well established annotationscheme that novel thread based featureshave a greater and more consistent impacton classification performance.1 IntroductionThe problem of information overload in personalcommunication media such as email, instant mes-saging, and on-line discussion boards is a welldocumented phenomenon (Bellotti, 2005).
Be-cause of this, conversation summarization is anarea with a great potential impact (Zechner, 2001).What is strikingly different about this form ofsummarization from summarization of expositorytext is that the summary may include more thanjust the content, such as the style and structure ofthe conversation (Roman et al, 2006).
In this pa-per we focus on a classification task that will even-tually be used to enable this form of conversationsummarization by providing indicators of the qual-ity of group functioning and argumentation.Lacson and colleagues (2006) describe a form ofconversation summarization where a classificationapproach is first applied to segments of a conversa-tion in order to identify regions of the conversationrelated to different types of information.
This aidsin structuring a useful summary.
In this paper, wedescribe work in progress towards a different formof conversation summarization that similarly lev-erages a text classification approach.
We focus onnewsgroup style interactions.
The goal of assess-ing the quality of interactions in that context is toenable the quality and nature of discussions thatoccur within an on-line discussion board to becommunicated in a summary to a potential new-comer or group moderators.We propose to adopt an approach developed inthe computer supported collaborative learning(CSCL) community for measuring the quality ofinteractions in a threaded, online discussion forumusing a multi-dimensional annotation scheme(Weinberger & Fischer, 2006).
Using this annota-tion scheme, messages are segmented into ideaunits and then coded with several independent di-mensions, three of which are relevant for our work,namely micro-argumentation, macro-argumentation, and social modes of co-construction, which categorizes spans of text asbelonging to one of five consensus building cate-gories.
By coding segments with this annotationscheme, it is possible to measure the extent towhich group members?
arguments are well formedor the extent to which they are engaging in func-tional or dysfunctional consensus building behav-ior.This work can be seen as analogous to work on?email act classification?
(Carvalho & Cohen,2005).
However, while in some ways the structureof newsgroup style interaction is more straightfor-ward than email based interaction because of theunambiguous thread structure (Carvalho & Cohen,2005), what makes this particularly challenging73from a technical standpoint is that the structure ofthis type of conversation is multi-leveled, as wedescribe in greater depth below.We investigate the use of state-of-the-art se-quential learning techniques that have proven suc-cessful for email act classification in comparisonwith a feature based approach.
Our evaluationdemonstrates for the three separate dimensions of acontext oriented annotation scheme that novelthread based features have a greater and more con-sistent impact on classification performance.2 Data and CodingWe make use of an available annotated corpus ofdiscussion data where groups of three students dis-cuss case studies in an on-line, newsgroup stylediscussion environment (Weinberger & Fischer,2006).
This corpus is structurally more complexthan the data sets used previously to demonstratethe advantages of using sequential learning tech-niques for identifying email acts (Carvalho &Cohen, 2005).
In the email act corpus, each mes-sage as a whole is assigned one or more codes.Thus, the history of a span of text is defined interms of the thread structure of an email conversa-tion.
However, in the Weinberger and Fischer cor-pus, each message is segmented into idea units.Thus, a span of text has a context within a message,defined by the sequence of text spans within thatmessage, as well as a context from the largerthread structure.The Weinberger and Fischer annotation schemehas seven dimensions, three of which are relevantfor our work.1.
Micro-level of argumentation [4 categories]How an individual argument consists of aclaim which can be supported by a groundwith warrant and/or specified by a qualifier2.
Macro-level of argumentation [6 categories]Argumentation sequences are examined interms of how learners connect individual ar-guments to create a more complex argument(for example, consisting of an argument, acounter-argument, and integration)3.
Social Modes of Co-Construction [6 catego-ries] To what degree or in what ways learn-ers refer to the contributions of their learn-ing partners, including externalizations,elicitations, quick consensus building, inte-gration oriented consensus building, or con-flict oriented consensus building, or other.For the two argumentation dimensions, the mostnatural application of sequential learning tech-niques is by defining the history of a span of text interms of the sequence of spans of text within amessage, since although arguments may build onprevious messages, there is also a structure to theargument within a single message.
For the SocialModes of Co-construction dimension, it is lessclear.
However, we have experimented with bothways of defining the history and have not observedany benefit of sequential learning techniques bydefining the history for sequential learning in termsof previous messages.
Thus, for all three dimen-sions, we report results for histories defined withina single message in our evaluation below.3 Feature Based ApproachIn previous text classification research, more atten-tion to the selection of predictive features has beendone for text classification problems where verysubtle distinctions must be made or where the sizeof spans of text being classified is relatively small.Both of these are true of our work.
For the basefeatures, we began with typical text features ex-tracted from the raw text, including unstemmed uni-grams and punctuation.
We did not remove stopwords, although we did remove features that occuredless than 5 times in the corpus.
We also included afeature that indicated the number of words in thesegment.Thread Structure Features.
The simplest context-oriented feature we can add based on the threadedstructure is a number indicating the depth in thethread where a message appears.
We refer to thisfeature as deep.
This is expected to improve per-formance to the extent that thread initial messagesmay be rhetorically distinct from messages thatoccur further down in the thread.
The other con-text oriented feature related to the thread structureis derived from relationships between spans of textappearing in the parent and child messages.
Thisfeature is meant to indicate how semantically re-lated a span of text is to the spans of text in theparent message.
This is computed using the mini-mum of all cosine distance measures between thevector representation of the span of text and that ofeach of the spans of text in all parent messages,74which is a typical shallow measure of semanticsimilarity.
The smallest such distance measure isincluded as a feature indicating how related thecurrent span of text is to a parent message.Sequence-Oriented Features.
We hypothesized thatthe sequence of codes within a message follows asemi-regular structure.
In particular, the discussionenvironment used to collect the Weinberger andFischer corpus inserts prompts into the messagebuffers before messages are composed in order tostructure the interaction.
Users fill in text under-neath these prompts.
Sometimes they quote mate-rial from a previous message before inserting theirown comments.
We hypothesized that whether ornot a piece of quoted material appears before aspan of text might influence which code is appro-priate.
Thus, we constructed the fsm feature,which indicates the state of a simple finite-stateautomaton that only has two states.
The automatonis set to initial state (q0) at the top of a message.
Itmakes a transition to state (q1) when it encounters aquoted span of text.
Once in state (q1), the automa-ton remains in this state until it encounters aprompt.
On encountering a prompt it makes a tran-sition back to the initial state (q0).
The purpose isto indicate places where users are likely to make acomment in reference to something another par-ticipant in the conversation has already contributed.4 EvaluationThe purpose of our evaluation is to contrast ourproposed feature based approach with a state-of-the-art sequential learning technique (Collins,2002).
Both approaches are designed to leveragecontext for the purpose of increasing classificationaccuracy on a classification task where the codesrefer to the role a span of text plays in context.We evaluate these two approaches alone and incombination over the same data but with three dif-ferent sets of codes, namely the three relevant di-mensions of the Weinberger and Fischer annota-tion scheme.
In all cases, we employ a 10-foldcross-validation methodology, where we apply afeature selection wrapper in such as way as to se-lect the 100 best features over the training set oneach fold, and then to apply this feature space andthe trained model to the test set.
The completecorpus comprises about 250 discussions of the par-ticipants.
From this we have run our experimentswith a subset of this data, using altogether 1250annotated text segments.
Trained coders catego-rized each segment using this multi-dimensionalannotation scheme, in each case achieving a levelof agreement exceeding .7 Kappa both for segmen-tation and coding of all dimensions as previouslypublished (Weinberger & Fischer, 2006).For each dimension, we first evaluate alternativecombinations of features using SMO, Weka?s im-plementation of Support Vector Machines (Witten& Frank, 2005).
For a sequential learning algo-rithm, we make use of the Collins PerceptronLearner (Collins, 2002).
When using the CollinsPerceptron Learner, in all cases we evaluate com-binations of alternative history sizes (0 and 1) andalternative feature sets (base and base+AllContext).In our experimentation we have evaluated largerhistory sizes as well, but the performance was con-sistently worse as the history size grew larger than1.
Thus, we only report results for history sizes of0 and 1.Our evaluation demonstrates that we achieve amuch greater impact on performance with carefullydesigned, automatically extractable context ori-ented features.
In all cases we are able to achieve astatistically significant improvement by addingcontext oriented features, and only achieve a statis-tically significant improvement using sequentiallearning for one dimension, and only in the ab-sence of context oriented features.4.1 Feature Based Approach0.610.710.520.620.730.670.610.700.660.610.730.690.400.450.500.550.600.650.700.75Social Macro MicroDimensionKappafrom10-foldCVBase Base+Thread Base+Seq Base+AllContextFigure 1.
Results with alternative featuressets75We first evaluated the feature based approachacross all three dimensions and demonstrate thatstatistically significant improvements are achievedon all dimensions by adding context oriented fea-tures.
The most dramatic results are achieved onthe Social Modes of Co-Construction dimension(See Figure 1).
All pairwise contrasts between al-ternative feature sets within this dimension are sta-tistically significant.
In the other dimensions,while Base+Thread is a significant improvementover Base, there is no significant difference be-tween Base+Thread and Base+AllContext.4.2 Sequential Learning0.540.630.430.560.640.520.560.630.590.560.650.610.400.450.500.550.600.650.700.75Social Macro MicroDimensionKappafrom10-foldCVBase / 0 Base /  1 Base+AllContext / 0 Base+AllContext / 1Figure 2.
Results with Sequential LearningThe results for sequential learning are weaker thanfor the feature based (See Figure 2).
While theCollins Perceptron learner possesses the capabilityof modeling sequential dependencies betweencodes, which SMO does not possess, it is not nec-essarily a more powerful learner.
On this data set,the Collins Perceptron learner consistently per-forms worse that SMO.
Even restricting ourevaluation of sequential learning to a comparisonbetween the Collins Perceptron learner with a his-tory of 0 (i.e., no history) with the same learnerusing a history of 1, we only see a statistically sig-nificant improvement on the Social Modes of Co-Construction dimension.
This is when only usingbase features, although the trend was consistentlyin favor of a history of 1 over 0.
Note that the stan-dard deviation in the performance across folds wasmuch higher with the Collins Perceptron learner,so that a much greater difference in average wouldbe required in order to achieve statistical signifi-cance.
Performance over a validation set was al-ways worse with larger history sizes than 1.5 ConclusionsWe have described work towards an approach toconversation summarization where an assessmentof conversational quality along multiple processdimensions is reported.
We make use of a well-established annotation scheme developed in theCSCL community.
Our evaluation demonstratesthat thread based features have a greater and moreconsistent impact on performance with this data.This work was supported by the National Sci-ence Foundation grant number SBE0354420, andOffice of Naval Research, Cognitive and Neural Sci-ences Division Grant N00014-05-1-0043.ReferencesBellotti, V., Ducheneaut, N., Howard, M. Smith, I.,Grinter, R. (2005).
Quality versus Quantity: Email-centric task management and its relation with over-load.
Human-Computer Interaction, 2005, vol.
20Carvalho, V. & Cohen, W. (2005).
On the CollectiveClassification of Email ?Speech Acts?, Proceedingsof SIGIR ?2005.Collins, M (2002).
Discriminative Training Methods forHidden Markov Models: Theory and Experimentswith Perceptron Algorithms.
In Proceedings ofEMNLP 2002.Lacson, R., Barzilay, R., & Long, W. (2006).
Automaticanalysis of medical dialogue in the homehemodialy-sis domain: structure induction and summarization,Journal of Biomedical Informatics 39(5), pp541-555.Roman, N., Piwek, P., & Carvalho, A.
(2006).
Polite-ness and Bias in Dialogue Summarization : Two Ex-ploratory Studies, in J. Shanahan, Y. Qu, & J.
Wiebe(Eds.)
Computing Attitude and Affect in Text: Theoryand Applications, the Information Retrieval Series.Weinberger, A., & Fischer, F. (2006).
A framework toanalyze argumentative knowledge construction incomputer-supported collaborative learning.
Com-puters & Education, 46, 71-95.Witten, I. H. & Frank, E. (2005).
Data Mining: Practi-cal Machine Learning Tools and Techniques, sec-ond edition, Elsevier: San Francisco.Zechner, K. (2001).
Automatic Generation of ConciseSummaries of Spoken Dialogues in UnrestrictedDomains.
Proceedings of ACM SIG-IR 2001.76
