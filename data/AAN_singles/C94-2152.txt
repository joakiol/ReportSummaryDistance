Hypothesis Scoring over Theta Grids Informationin Parsing Chinese Sentences with Serial Verb ConstructionsKoong H. C. Lin and Von-Wun SooDepartment of Computer Science, National Tsing-Hua University HsinChu,Hsinchu, 30043, Taiwan, R.O.C.E-Mail:soo@cs.nthu.edu.twAbst rac tSerial verb constructions (SVCs) h~ Chinese are popularstructural ambiguities which make parsing difficult, bl thispaper, we propose a quantitative model, ~-model', based ontheta grids hJfo~Tnation, that can systematically resolveambiguities of SVCs to arbitrate competence between verbs h~parsing SVCs sentences.
S-model has three majorcharacteristics."
(1) it can resolve SVCs without relying on,~Tecific types of SVCs classified by linguists; (2) it can handlelong SVCs, i.e., SVCs with more than two verbs; (3) it cansimultaneously determine whether a verb candidate is reallyacts as a verb in the sentence.1 Introductionin Mandarin Chincse, it is common that there aretwo or more verbs in a sentence without any markerindicating the relationships between them.
Such peculiarconstruct is called Serial verb constructions (SVCs) \[Liand Thompson 1981\].
For example, in the sentence: "~~~ ),~,~- ~(~"  (the defendant hol~ ~ la in t i f f~ )  (The defendant hoped that the plaintiff couldforgive him.
), there are two verbs: "~-~"  (hope) and "~" (forgive); however, there are no such markers assubordination markers, conjunctions, preposition, orother morphological cues, which indicate therelationships between them.
In developing a parser,SVCs cause considerable problems.
We have designed amodified chart parser using theta grids information.
Inparsing sentences with SVCs, different verbs willcompete in searching the chart for their own theta roles.Thus, some mechanism for arbitrating among thecompeting verbs for the ownership of each constituent inthe chart must be designed.
The theta grid chart parser isto be described in the next section.The study of SVCs is still primitive.
Most previouswork lChang and Knflee 1991\] \[Yeh and Lee 1992\]were based on Li and Thompson's classification of SVCs\[Li and Thompson 1981\].
Surveying their work, we findthere are some limitations.
Yang \[19871 and Chang ct al.\[Chang and Krulee 1991\] dealt with only subsets ofSVCs.
Moreover, it is not clear how the implementationsof Yang \[1987\], Chang et al \[Chang and Krulce 1991\],and Yeh et al \[Yeh and Lee 1992\] can be extended tohandle long SVCs, i.e., those sentences containing morethan two occurrences o f  verbs.
It is because their workwere based on the classification of SVCs, and theclassification was based on two-verbs cases only.
Pun\[19911 claimed that his work could handle long SVCs;however, did not report how to systematically extend hismethod to SVCs with three or more verbs.
In our model,there are three characteristics: First, instead ofclassifying SVCs into several types, we make use of anumerical scoring function to determine a prcferredstructure.
It is an attempt o make the SVCs handlingprocess more ,systematic.
The information encoded intheta grids are used as bases for scoring.
Second, it canhandle long SVCs.
Third, category, ambiguities can betaken into consideration at the same time.
Namely, wecan simultaneously determine whether a verb candidateactually plays a vclb or not.
While in previous work,before the SVC handling processes are triggcred, it mustdetermine the actual verbs in the sentence.This work is part of our long-term research forbuilding a natural language front-end of a verdictunderstanding system.
Thus, the corpora we use arejudicial verdict documents from the Kaohsiuug districtcourt lTaiwan 1990a\]\[Taiwan 1990b\], which werewritten in a special official-document s yle.
Thus, ouranalysis is based on such kind of sub-language.2 A Theta-grid Chart ParserSince the mechanism we propose is under theframework of a theta-grid chart parser, in this section,we introduce the parser briefly.
Thematic inJbrmation isone of the information sources that can bridge the gapbetween syntactic and semantic processing phases.
Intheta-grid theory ITang 1992\], rich thematic informationis incorporated for the analysis of human languages.
Theidea of theta-grid theory is as follows: we use a predicate,say, a verb, as the center of a "grid" and, by finding thetheta-roles registered in the lexical entries of thispredicate, we can construct a grid formed by thispredicate and then construe the sentence (or clause)spanned by this predicate.
We think the thcta-gridrepresentation suitable for processing Chinese.
Thisshares similar viewpoint with other work of designingChinese parser which uses thematic information, such asICG parser \[Chcn and Huar, g 1990\].
Tocomputationalize theta-grid theory, some controlstrategies for parsing must be implemented.The well-known chart parser \[Kay 19801, whichutilizes the data structure "chart" to record the partialparsing results, is suitable for our work.
Since it keepsall possible combination of constituents, it can acceptsentences with missing thcta roles.
Thus, we designed amodified chart parser called TG-Chart parser \[Lin andSoo 1993\] by combining thcta-grid theory and chartparser.
Note that currently in our work, only the theta942grids for verbs are considered.
For each verb, there aretwo kinds of theta roles registered: the obligatory roles,which must bc found for this verb to construct a legal"grid"; the optional roles, with their appearance beingoptional.
Takc "~ ~)~" for example, its theta roles areregistercd as: +lTh (Pd) Agl; thus, two NPs must bcfound in the chart for the constntction of a legal grid(From ,~yntactic clues, both "Ag" and "Th" are alwaysplayed by NPs.
ILiu and See 19931.
), while theappearance of a clause to serve as a "Pd" role is optional.A brief dcscriptiou of our parsing algoritlun is as follows:\[Step 1\] Search the sentence for positions of all "verb candidates".
(What we call verb candidates are thosewords that have the verb-categol7 asone of its syntactic ategories in the dictionary.
)\[Step 2\] By considcring all possible combination, the chart parser groups the words into syntactic onstituents.Syntactic knowlcdge is used in this step.\[Step 3\] If only one verb candidate ix lbund in I Slep l\], search the chart \[or constituents which can play thetheta rolcs of ttfis verb.\[Step 4\] If more than one verb candidate are lbund, call S-model to deterlnine the most preferred structure.
S-model will be describcd in scction 3.3 The S-modelWe design a model which utilizes scoring fimctionsand thela-grid theoiy to handle the SVCs problem.
Thismodel, called S-model (au abbreviation of "SVCslmndling model"), consists of four modules: acombinalion genera|or, a combination filter, a scorecvaluator, and a struclure selector as shown in Ifigurc 1 I.Wc now dcscri/)c Ihcsc modtdcs as follows:I F i l l  I1\[ ISentences with SVCsConstituents fromchart parserTheta gridsfor each verb candidateCombination Generate 1+Combination Filter /\[,rS ooro vo'uotor /Scores for every verb candidate~ /  Struclure Select?r /a most preferred sfructurReturn to TG-chart parserFigm'e 1 Modules of S-modelVerb-string Gcucrator gcncralcs all possible verb stringsAs wc know, all verb candidates compete to act asverbs.
'/'Ire qt.cstion is: "wlfich candidates can actuallyact as vcrbs?"
and, "what is thcir correlation?".
If we canenumcratc all possible combination and cwfluale theirscores respectively, we can determine the most preferredconstruction.
Take the two-verb-candidates case as anexample, let the two verb candidates be vl, v2, there arcfive combination: (1) only vl  is a verb whilc v2 is not, (2)only v2 is a verb, (3) both vl aml v2 arc vcrbs, whilethere is not any subordination relation bclweeu them.
(4)both arc verbs, and vl is subordinatc to v2.
(5) both arcverbs, alld v2 is subordinate tovl.3.1 Combination GeneratorCombination Geucrator consisls of two submodules:Verb-string Generator and Subordination-relationTagger.
We illustrate a case with three verb candidates:by sequentially cnmucrating tile biua O' string: 001, 010,011, 100, 101, llO, 111.
The verb string "101"represents the situation where vl and v3 acl as verbs,wlfile v2 docsn't.
And then, SubordinatiouorelationTagger tags these verb strings with possiblesubordination relations.
II divides these strings into threeclasses according to the occurrences of l's in lhe siring,that is, the number of verb candidates in the sentencc.These three classes arc: (I) For the one-1 class (i.c., 001,010, 100), there is obviously no subordination relation.Thai ix, there is only one possible case to consider: thiscandidate acts as the only verb in Ibis sentence.
(2) Forthe two-I class (i.e., 011.
101, 110), there are threepossibilities to consider: vl=v2, vl<v2, and vl>v2.
Wcfollow the notations used by Pun \[Ibm 1991\], where"vl>v2" means v2 is subordinate to v\[; "vl-~v2", nosubordination relalions exist between the two verbs.
(3)943For the three-1 class (i.e., 111), there are seventeen cases.We use abbreviated notations to represent them, where"><" is the abbreviation of "vl > \[v2<v31", with squarebrackets being represented by underlines, meaning thatlocally v2 is subordinate to v3, and they together form aclause, which then plays a prepositional role for vl, and,for another example, "=<" is the abbreviation of "lvl=v2\]< v3".
These seventeen cases are: ==, =% =% =>, =>,<=, <=, <<, <<, <>, <>, >=, >=, ><, ><, >>, and >>.Thcse cases are gcneratcd simply by enumeratingpossiblc ombinations of thesc threc symbols: =, <, and >.For each pair of symbols Sj ,S~, two combinations arcpossible: S,S 2 and ,5~S 2.
Note that " - : "  and "=-"represents the same case; thus, only a single "==" isgenerated.
Therefore, 3x3  x2-1  = 17 cases arcpossible.
By summarizing classes (1), (2), and (3),Combination Generator generatesC~ x 1 + C 3 x 3 + C~ 3x 17 = 29 cases.
It is easy todesign a routine which ,~ystematically enumerates thesepossibilities.3.2 Combination FilterThe Combination Generator above does not takelinguistic knowledge into consideration.
Actually, tliereare some cases which will never happen in a realsentence according to syntactic onstraints.
Thus, it isnot necessary to pass it to the score evaluator.Combination Filter is responsible for filtering outimpossible cases.
We illustrate three circumstances.Firstly, for "vl > v2", the Combination Filter will checkthe theta grid for v l ;  if there is a Pd or Pc role registeredin vl,  it is possible, since v2 can be subordinate to vlonly if vl also expects a prepositional role; othenvisc,such a case is filtered out.
The second circumstance is,when vl has only a single syntactic ategory, verb, itmust act as a verb in the sentence.
Thus, the case that v2acts as a verb while vl  doesn't is removed.
The thirdcircumstance regards the three-candidates situations.Combinalion Generator generates seventeen cases;however, under some circumstances, there are four caseswhich are impossible: << <> <> and >> Thesecircumstances happens when the main verb of theprepositional part (i.e., the part marked by a underline.
)expects an animate agent.
In such circumstances, a VPcannot be subordinate to an "event".
Thus, these fourwill be filtered out by Combination Filter.
For example,the following sentence, with the relation "<>" (i.e., ~-f <~>~h~\] ) ,  is impossible: ";t~ N ~.
~-~h~,  ~-~'~ I~ " (11~_ thunder hope attend the labor insurance)(Thundering hoped to attend the labor insurance.).
It isbecause "~ ~ "expects an animate NP to act as its Ag,the VP "-~T '~" thus cannot act as itsAg role.There are still many linguistic knowledge andconstraints which can be used by Combination Filter.However, some of them, such as the third circumstancementioned above, are too specific and thus must be usedcarefully to avoid over-constraints.
Therefore, how tocollect and select hose constraints and knowledge whichare general enough is still our filturc concern.The main function of Combination Filter is toimprove the performance of the S-model.
Note that inthis paper, for the beneficiary of brevity, CombinationGenerator and Combination Filter are designed as twoseparate modules.
However, Combination Filter canbehave as an embedded module of CombinationGenerator so that it can cut off some generating brancheswhich are impossible as early as possible.
It is also ourfuture concern.3.3 Score EvaluatorWhenever Combination Filter passes a feasible caseinto Score Evaluator, the Score Evaluator utilizes ascoring function to compute the score of the input caseand then, passes the evaluated score to lhe structureselector.
We will now describe it:3.3.1 The S-functionIn our legal domain corpora, there are manyoccurrences of SVCs.
Since our parser is based on tiletheta grids, in case of SVCs, different verbs will competein finding their own theta roles.
Thus, some mechanismfor arbitrating among verbs for the ownership of eachconstituent in tile chart must be designed.
Just as whatYorick Wilks said, language does not always allow theformation of "lO0%-correct" theories \[ltirst 19811;therefore, we attempt o find a more flexible melhod forrecognizing SVCs.
We propose a scoring fimction toselect a "preferable" construction for the sentence withSVCs.
(For the "preference" notion, sec \[Wilks 19751\[Fass and Wilks 19831.)
The scoring fimctiou is called S-fimction, an abbreviation for "SVCs scoring fimction".S-function is defined as in lfigurc 21, where RWR is theabbreviation of "Ratio of Words included in some phrasewith Roles assigned", RRF, "Ratio of Roles Found",OBR, "OBligatory Role", and OPR, "OPtional Role"(Note that OBR and OPR indicate those roles registeredin theta grids'.
):944Score .- Per  - VerbScore - ~w ~,~, (I)number of verbsScore - t 'e r -  Verb = RIU; x RWR (2)RRF = \](number of OBR found) x k + (number of OPR found) I (3)Basemm~ber of words included in some phrase with roles assignedR WR =number of words in the chmscBase = k x (number of OBR)4- (number of OPR) (5)Figure 2.
The S-flmction(4)The score is calculated as the average value of scoresobtained by each verb in the sentence (as in equation l).For each verb, the score is eslimatcd by two factors: f i rst,the ratio of lheta roles found, i.e., RRF, and, second, theratio of words with roles assigned, i.e., RWR.
Fordetailed formula, see equation (2).
The relativesignificance between obligatory roles and optional rolesis heuristically weighted by 2:1, as m (3) and (5); thus,the value ofk  is set to be 2.
In some cases, the verb findsmany theta roles in the clause it constructs, but the wordsin this clause are not all assigned roles.
Wc considersuch assignment doesn't constrnc the real construction ofthe sentence.
Thus, to reflect such cases, we calculateRWR by dividing the number of words which areincluded in some phrase with a role assigned by the totalnumber of words in the clause (see equation 4).3 .3 .2  I l l us t ra t ion  o f  S - funct ionNow, let's illustrate the calculation of S-function by thefbllowin~ examples: ..: : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : : :  : :  ::::::: i  : : : : : :  " ; : : .
: : :5 : ;  : : :\[== =  ===}= :i ==:i: := i ==== i i #==!
:  i: i =:=== :  ~ f f  ====:=~=i =  fit~ =:==~:  == =::: =i== : = 1In this example, we demonstrate how to determinewhether  a verb candidate ean actual ly act as a verb.
in\[Step 11, "~ ~ " (file) and "~, ) i  " (tell) are both foundas "verb candidates".
Here " {~-?,# " has two syntacticcategories registered in its lexical entry: the verb and thenoun, while " ~ ~\[~ " has only one category, the verb.The theta grid for "~ ~ " is ~\[Th Ag\], " @ ~,)~ " I \[Th(Pd) Agl.
So, to decide whether " ~ ~)# " is treated as averb or a noun, there are tbnr cases to be considered:(1) ":~?~ " is treated as a verb, while "~ i,~-" a noun.q- -CAg (Ma)In the above, "~ ~ " enveloped by a box means it playsa verb.
When it searches for theta roles, "),~?, ~"  ,rod "~g)) " are respectively found as its Ag and Th, the twoobligatory theta roles registered in its lexical entry.
Thescore is calculated as folk~ws: For "~ ~ ", there are twoobligatory roles, so Base = 2 ?
2 = 4.
Moreover, inthis sentence, "N ~ ", "~ ~ "," t~_ tt~ ",and "~t~_ 1~ ,, are allassigned some roles; thus, RWR = 4/4 -- 1.
And then,Score-Per-Verb = {\[(number of OBR tbund)*2 +(number of OPR tbund)\]/Base} * RWR = {\[2 X 2 + 01/41X 1 -  l. Finally, Score = 1/1 = 1.00.. .
ZF  ,4  - .
(2) "~ ~ and ~z ~,1~.
both are treated as verbs.
Score:-- (0.5+0.4)/2 = 0.45.
(3) "~ ~ " and "~i~ )~" both are treated as verbs, while "G- ~,}~" is subordinate to "~ ~ ".
Score - (0.375 + 0)/2 =0.1775(4) "~ ~5 " and "~ ~)~" both are treated as verbs, while ";~ ~ " is subordinate to ,, ~aj~ - )~.
,,  Score -- (0.5+0.2)/2= 0.35.From the above discussions, case(l) apparently gets thehighest score (1.00).
So, the parsed structure in case(I)is preferable to those in the other cases.
That is, in thissentence, " ~ ~ " plays the only verh, while " ~ ~ "plays a noun.
Therefore, the right syntact ic  category fo r"~f f / "  in this sentence is determined.In this example, we will demonstrate how to determinethe rehuionship between verbs.
In \[Step 1\], " ~-~i ~ "(request) and "~ Jt~" (divorce) are both found as "verbcandidates".
Here " ~-i,~- " and " ~ J/~ " both have twosyntactic categories registerexl in its lexical entry: theverb and the minn.
The theta grid for "~ ~ " is +\[(Th)Pe Agl, "~t}"  + lAg  (Ag)l. So, there are five cases tobe considered:(1) "~;~ "  is treated as the only verb, while "~\ [~"  anoun.
Score :~ 0.15/I = 0.15.
(2) "~t ~?"
is treated as a verb, while "~h~"  a noun.T -F--C_(Ag) CONJ AgFor "~\[ #~ ", Base= 3.
Note that although "~ ~ " is anNP, it cannot play as Ag for " ~(\[ ~ ".
It is because itdoesn't satisfy the constraint for playing as Ag: an Agmust has a feature "+animate",  according to Gruber'stheory that an agent nmst be an entity with intent ional i ty\[Gruber J. S. 19761.
The situation that a verb cannotfind a theta role is represented by the symbol "r--'l ".
So,RWR = 3/4 = 0.75, and Score-Per-Verb ={\[1"2+0\]/31"0.75 = 0.5.
Score -- 0.5/1 = 0.5.945(3) "~ ~ " and "~ ~t~" both are treated as verbs.
Seore= (0.134+0.67)/2 = 0.402.
(4) "~ ~"  and "N  ~; '  both are treated as verbs, with "~l}" being subordinate to "~ ~"T-J(Ag) CONJ| _.-VA9I !Pe-7PeFor "~r~" ,  Base=5.
RWR=4/4= 1.
Score-Per-Verb ={\[ l '2+0\] /5} = 0.4.
For " N ~h ~ ", Base=3.RWR=3/3= 1.
Score-Per-Verb = {\[1"2+01/3} = 0.67.Score = (0.4+0.67)/2 = 0.535.
(5) "~ 5\]~" and "N  ~"  both are treated as verbs, with "~ ~ " being subordinate to " ~ ~}' ".
Score ---(0.134+0)/2 = 0.067.From the above discussions, case(4) apparently gets thehighest score (0.535).
So, the parsed structure in case(4)is preferable to those in the other cases.
That is, in thissentence, "N  ~"  and "~ ~t\[}" both are treated as verbs,while " ~ ~ " is subordinate to " ~'~ J-\]~ ".
The clauseconstructed by "N ~"  is assigned the Pe role for "~ ~ ".Thus, this is a SVC sentence; moreover, this kind ofSVC is commonly called "sentential objects".3.4  St ructure  Se lec torStructure Selector plays a final arbitrator.
It collectsall feasible cases and their scores.
After scores of allcases are evaluated, the competition of all cases isarbitrated by Structure Selector.
Structure Selectorselects the case with the highest score as the mostprelbrred one.
The final result is retnrncd to the parser.4 Experimental Results4.1 Results of More Sample Sentencesin tablc 2, we show thc results of more sentences withSVC in the legal documents which are parsed by thisscheme in our TG-Chart parser.
The sample sentencesare shown in table 1 :Tahle 1.
Some sample sentences with SVCsSl :~,-~ -ff~g~ ~{~ ~ ~-{-~J~;~ ( t l~~thedefendant  tg!y 2 three hundred thousand ollars)The plaintiffpetitioncd the defendant to~ive him three hundred thousand dollars.$2:~,~-~ g~/~ ~-~ ~ t~J  ( ~ ' ~  the defendant re~L ~The plaintiffrequested he defendant torepay his debts.$3: ~0~-~ ~ ~lJ \]2~ -~:~ (Ihedefendant didnht arrive theeonrtThe defendant didn't arrive at the court o argue.$4: ~-~ ~ ~f~i~' ~l\]~g-~ ;~ (the defendant suddcnl~  left h ..... desert his famil~The defendant deserted his family suddenly and causelessly.$5: ~-~ :5~ ~_ _~ ~ J~,-~ \[Nit ~ (the defendant didn't retum l .
.
.
.
.
ith the21aintiffcohabit )The defendant didn't return home to cohabit with the plaintiff.$6: f'~,-~ ~.~ -~g~=~J -~)-, (the defendant  petition inten'o~ate the witness)The defendant petitioned tointerro\[~ate th  witness.$7: ~j~-~ ~J_~ /~,~-~ ~ -~,~ (the defendant ~ ~ c_anThe defendant hoped that he plaintiffcould ford, ire him.$8: N-~ I~g~ ~-~\]~\[\] ~T{~I~ (the defendant ~ attend the labor insurance)The defendant applied to attend the labor insurance.S9: 1~,-~ -~\[\]~ ,~ ,,k, ~1~ l\]lt'~ (theplaintiff ordinaril~ treat iLeo2~lc ~ ~ )Ordinarily, the plaintifftreats people fiiendly.SIO: ~,~'~ Z~ Z -- IN ~~1~ {1~ {~ (~f l "  hreak As E .
.
.
.
.
.
.
.
~ va\[nah\[~)The plaintiffbroke a vase thai was valuable.Tahle 2.
Results of S-function calculation for sample sentencesiiiiii::iiiiiiiiii~!~iiiiiiiii}iiljiiii vl: ~j~,v2:~'~-3  vl,v2 vl>v2 1.00?
;.Z.I Z .
I  .
; !
.
.Z .
ZZiiiiiiiii::)i::!i!::!S~::!ii::!i!i::!i!
::i::i vl: --=~5~,v2: i~f~ vl ,v2 vl>v2 1.00iiiiii;~!iiiiiiiiiii~!iii!i!i!iiiii!i!i vl:ii!iiiiiiii!iiiii!iiS~ilililiiii!iii!i!i!
vl:!!iii!iiiii!
!ilililig~iiiiiiiililiiii!iii vt: ::::::::::::::::::::::::iiii~i!iiii!iiiiiiilS~iiii~!~!i!iiiiiiii~iiiii!i!ililiiiiiiii~iliiiiiiii~i~i~i~i~iiiiiiiiiiiiiiiiiilggiiiiiiiiiiiiii!iiiii!iiiiiiiiiiiiiiiiiS~iiiiiiiiiiiiii!iiii~11, v2: -5~ vl,v2 vl=v2f~j~,v2: ~Z-~: vl,v2 vl=v2~_, v2: ~/=~ vl,v2 vl-v2vl: ~.~,v2: ~yt~ vl,v2 vl>v2vl: NN,v2: NN0.841.000.830.70vl,v2 vl>v2 0.84vl: ~ ,v2 :~\ ] j I3  vl,v2 vl>v2 0.75vl: "~, v2: :~1\]1~ vl,v2 vl<v2 1.00vl:-}'\]'ti~,v2: t11~ vl,v2 vl=v2 1.009464.2 Demonstrating How to ilandleThree-Verbs SVCsLet's consider the following three-verbs enlencc: ".~.~ "~ ~ - lh~ .
},t_ ~ ~_ 4~," (!t~cplaintiff returnhome remind his wife p)~ fees_) (The plaintiffrelurned home to remind his wife lo pay fees.).
There arethree verbs in this sentence: .~ (return), ~:L/~2 (remind),and ~ (pay).
At the first stage, Combination Generatorgenerates 29 possible combination; and then,Combination Filler filters out 26 of them, and only threecases remained to be considered: "~ = -1~ ~2 = ,~" , "~ =\[ ,b~/$~ >.~ l", and "1 ~ = ,t,~{ fi'~l > ~ ".
Thus, ScoreEvaluator only needs to calculate the scores lot thesethree remained cases.
At the final slage, StructureSelector accepts the evahmted scores for these cases andselects the one with the highest score.
In this example,the structure "=>" gels the highesl score: (/.94', it is lhecorrect structure l'or this sentence.Consider another interesting example, ",fC vx~ k .q~'~)1 ~ qg ~ ~, 6.0" (12q think l mock he i s ~,rong)\[Pun 1991\].
This sentence is ambiguou.v to nativespeakers, since there arc two possible readings: (1) "l~gvX~ ;1.~ ':~)1 ~ 4'gl ~ $~@" (His thinking lhal 1 mockedhim is wrong.
), and (2) "~G vX J..~ \[4~, t~)l ~ ~ ~'~ $~ 6"~J\] ''(He thinks that 1 mocked him for being wrong.).
In S-model, bath these two readings get the highest score: 1.0,and thus both are selected by Slruclure Selector as thefinal onlpnl.
S-model doesn't altempt 1o select a"uniquely-correct" structure, bul just selects what arepr~'.rred.
It matches humans' behavior since even ahuman may not be able to tell which of these two isbetter,5 Conc lus ionIn this paper, we propose a systematic method foranalyzing SVCs.
The method is based on theinformation offered by theta grids.
Many possiblecorrelation relations may exist between verbs, we use anumerical scoring fimetion to determine the mostpreferred one.
To utilize the S-fimction defined, wcdesign a S-model, which consists of four modules: acombination generator, a combination filter, a scoreevaluator, and a slruclure selcclor, to realize il.
For theexamples we have lestcd so far, taken from the legaldocuments \[Taiwang0al rFaiwang0b\], our mechanismalways produces the correct reading.Li and Thompson 119811 classified SVCs into fourtypes: (1) two or more separate vents (2) a VP or aclause plays the subject or dirccl object of another verb (3)pivotal construction (4) descriptive clauses.
We usuallysplit lype (2) into two sub-types: (2)-1 scntential subjects,and (2)-2 scntcntial objects.
Most work for handlingSVCs are based on this classification.
In our desigi~ of S-function, information about this classification is not used.However, in our testing sentences, it lnrlls otlt 1hal thesefive lypes are actually covered by the S-model whichselects a preferred slructure based on only scoringfunctions.
For example, $5 in table 1 belongs to type (1),$9, type (2)-1, $6, type (2)-2, $2, type (3), and SI0, type(4).
The rcason why S-model may cover theclassification is due to the rich information cacoded inthela grids.
As an example, consider the sentence "~$ ~-~ ~ I','\] ;~v .& ,,.
(The dcfcndant pclitioncd tointerrogate the witness.)
By Li and Thompson'sclassification, it belongs to the "scntential objecls" type.If we can classil~?
the senlence into the correct ype, thestructure " A~:f~petitioeO >Jtg I:/\] (interrogfge)" will bedetermined.
This is the idea used in most previous work.However, in S-model, we achieve the same result withoutrelying on the classification.
In S-model, sincc "~ a~"needs a "Pe" which implies that it expects an "event",i.e., a "sentential object" to play the thela role, altercalculating S-flmclion, the stntcture where " ~,E I':1 " issubordinate to "~: 2~" naturally gets the highest scorealld lhlls becomes II1c "winner".
As the previous cxalnplein section 4.2, lbr the ambiguous entence S-model alsoyields more than one highesl score.
We can concludethai S-model could be a very general and soundmechanism 1o handle SVC sentences.AcknowledgmentThis research is supported in part by National ScienceCouncil of R.O.C.
under the grant NSC83-0408-E-007-OO8.RefCl'ellces\[Chan~ and Krulec 19911 Chao-Huang Chang andGilbert K. Krulee, Prediction Ambi?,ui(v in Chinese andIts Resolution.
Proc.
of ICCPCOL 1991, Pl).
10%114.\[Chert and lluang 1990\] Keh-jiann Chert and Chu-Rcn11uang, Information-based Case Grammar.
In Proc.
ofCOLING-90.\[Fass and Wilks 1983\] Dan Fass and Yorick Wilks,Prefi, rence Semantic's, IIl-libtwtednes.v, and \]vIetaphor.American Journal of Computational Linguistics, Vol.
9(3-4), July-December 1983, pp.
178-187.\[Gruber J. S. 19761 Gmber J. S., Lexical Structures Dt,~vntax and Semantics, North-Ilolland PublishingCompany.
1976.\[llirst 1981\] In Graemc ifirst, Lecture Notes mComputer Science, Anaphora in Natural LanguageUnderstanding, A Nt#'vey.
Springer-Vcrlag BcrlinHeidelberg 1981.\[Kay 198111 Martin Kay.
Algorithm Schemata nd DataStructures in ?iyntactic Processin,q.
It) Prec.
of the NobelSymposmm on Text Processing, Gothenburg, 1980.lt, i and Thompson 19811 C. N. I.i and S. Thompson,Mandarin Chinese: a Functional Re/krence Grammar,University of California Press, Berkeley.
1981.\[Lin and Soo 1993\] Koong 1t.C.
Lin and Von-Wnn Soo,Toward l)iscoutwe-guided Chart Parsing jor MandarinChinese--A Preliminat T Report.
ROCLING VI, 1993.\[Liu and Soo 1993\] P, cy-Long l,iu and Von-Wun Soo,An \]Onpirical ,%'tully of Thematic KnowledL, e AcquisitionBased on ?Zyntactic ('lues and f\[euristicx.
In Proceedingsof ACl, 1993.947\[Pun 1991\] K. H. Pun, Analysis of Serial VerbConstructions in Chinese.
ICCPCOL 1991, pp.170-175.1991.\[Taiwan 1990a\] Taiwan Kaohsiung district court,Summary of Kaohsiung District Court Criminal VerdictDocuments, Vol.
1, 1990.\[Taiwan 1990b\] Taiwan Kaohsiung district court,Summary of Kaohsiung District Court Civil VerdictDocuments, Vol.
1, 1990.\[Tang 1992\] Ting-Chi Tang, Syntax Theory andMachine Translation: Principle and Parameter Theory.In Proc.
of ROCLING V, pp.53-83.
1992.\[Yang 1987\] Yiming Yang, Combining Prediction,Syntactic Analysis and Semantic Analysis in ChineseSentence Analysis.
IJCAI 1987, pp.679-681.\[Yell and Lee 1992\] Ching-Long Yeh and Hsi-Jian Lee,A Lexicon-Driven Analysis of Chinese Serial VerbConstructions.
In Proc.
of ROCLING V, pp.195-214.1992.\[Wilks 1975\] Yorick Wilks, An h~telligentAnalyzer andUnderstander of English.
tn B. J. Grosz, K. S. Jones, andB.
L. Webber, "Reading in Natural LanguageProcessing", 1975.948
