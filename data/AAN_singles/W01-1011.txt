GIST-IT: Summarizing Email Using Linguistic Knowledge and MachineLearningEvelyne TzoukermannBell Labs, LucentTechnologies700 Mountain AvenueMurray Hill, NJ, 07974, USAevelyne@lucent.comSmaranda MuresanColumbia University500 W 120th StreetNew York, NY, 10027, USAsmara@cs.columbia.eduJudith L. KlavansColumbia UniversityCenter for Research onInformation Access535 W 114th StreetNew York, NY, 10027, USAklavans@cs.columbia.eduAbstractWe present a system for the automaticextraction of salient information fromemail messages, thus providing the gist oftheir meaning.
Dealing with email raisesseveral challenges that we address in thispaper:  heterogeneous data in terms oflength and topic.
Our method combinesshallow linguistic processing withmachine learning to extract phrasal unitsthat are representative of email content.The GIST-IT application is fullyimplemented and embedded in an activemailbox platform.
Evaluation wasperformed over three machine learningparadigms.IntroductionThe volume of email messages is huge andgrowing.
A qualitative and quantitative study ofemail overload [Whittaker and Sidner (1996)]shows that people receive a large number ofemail messages each day (~ 49) and that 21% oftheir   inboxes (about 334 messages) are longmessages (over 10 Kbytes).
Thereforesummarization techniques adequate for real-world applications are of great interest and need[Berger and Mittal (2000), McKeown and Radev(1995), Kupiec et al(1995), McKeown et al(1999), Hovy (2000)].In this paper we present GIST-IT, anautomatic email message summarizer that willconvey to the user the gist of the documentthrough topic phrase extraction, by combininglinguistic and machine learning techniques.Email messages and web documents raiseseveral challenges to automatic textprocessing, and the summarization taskaddresses most of them: they are free-styletext, not always syntactically orgrammatically well-formed, domain andgenre independent, of variable length and onmultiple topics.
Furthermore, due to the lackof well-formed syntactic and grammaticalstructures, the granularity of documentextracts presents another level of complexity.In our work, we address the extractionproblem at phrase-level [Ueda et al(2000),Wacholder et al(2000)], identifying salientinformation that is spread across multiplesentences and paragraphs.Our novel approach first extracts simplenoun phrases as candidate units forrepresenting document meaning and thenuses machine learning algorithms to selectthe most prominent ones.
This combinedmethod allows us to generate an informative,generic, ?at-a-glance?
summary.In this paper, we show: (a) the efficiencyof the linguistic approach for phraseextraction in comparing results with andwithout filtering techniques,  (b) theusefulness of vector representation indetermining proper features to identifycontentful information, (c) the benefit ofusing a new measure of TF*IDF for the nounphrase and its constituents, (d) the power ofmachine learning systems in evaluatingseveral classifiers in order to select the oneperforming the best for this task.1 Related workTraditionally a document summary is seen as asmall, coherent prose that renders to the user theimportant meaning of the text.
In this frameworkmost of the research has focused on extractivesummaries at sentence level.
However, asdiscussed in [Boguraev and Kennedy (1999)],the meaning of ?summary?
should be adjusteddepending on the information management taskfor which it is used.
Key phrases, for example,can be seen as semantic metadata thatsummarize and characterize documents [Wittenet al(1999), Turney (1999)].
These approachesselect a set of candidate phrases (sequence ofone, two or three consecutive stemmed, non-stopwords) and then apply machine learningtechniques to classify them as key phrases ornot.
But dealing only with n-grams does notalways provide good output in terms of asummary (see discussion in Section 5.4).Wacholder (1998) proposes a linguistically-motivated method for the representation of thedocument aboutness: ?head clustering?.
A list ofsimple noun phrases is first extracted, clusteredby head and then ranked by the frequency of thehead.
Klavans et al(2000) report on theevaluation of ?usefulness?
of head clustering inthe context of browsing applications, in terms ofquality and coverage.Other researchers have used noun-phrasesquite successfully for information retrieval task[Strzalkowski et al(1999), Sparck-Jones(1999)].
Strzalkowski et al(1999) uses head +modifier pairs as part of a larger systemwhich constitutes the ?stream model?
that isused for information retrieval.
They treat thehead-modifier relationship as an ?orderedrelation between otherwise equal elements?,emphasizing that for some tasks, the syntactichead of the NP is not necessarily a semantichead, and the modifier is not eithernecessarily a semantic modifier and that theopposite is often true.
Using a machinelearning approach, we proved this hypothesisfor the task of gisting.Berger and Mittal (2000) present asummarization system named OCELOT,based on probabilistic models, whichprovides the gist of web documents.
Likeemail messages, web documents are also veryheterogeneous and their unstructured naturepose equal difficulties.In this paper, we propose a noveltechnique for summarization that combinesthe linguistic approach of extracting simplenoun phrases as possible candidates fordocument extracts, and the use of machinelearning algorithms to automatically selectthe most salient ones.2 System architectureThe input to GIST-IT is a single emailmessage.
The architecture, presented inFigure 1 consists of four distinct functionalcomponents.
The first module is an emailpreprocessor developed for Text-To-SpeechHPDLOPHVVDJH(  0DLO 3UHS7RNHQL]DWLRQ6LPSOH 13([WUDFWLRQ13 ILOWHULQJ13 ([WUDFWLRQ DQG )LOWHULQJ 8QLW)HDWXUHVHOHFWLRQ)HDWXUHVHOHFWLRQ&ODVVLILFDWLRQ0RGHO13FODVVLILFDWLRQJLVW RI HPDLOPHVVDJHSUHVHQWDWLRQ0/ 8QLWFigure 1 System Architectureapplications.
The second component is a shallowtext processing unit, which is actually a pipelineof modules for extraction and filtering of simpleNP candidates.
The third functional componentis a machine learning unit, which consists of afeature selection module and a text classifier.This module uses a training set and a testing setthat were devided from our email corpus.
Inorder to test the performance of GIST-IT on thetask of summarization, we use a heterogeneouscollection of email messages in genre, length,and topic.
We represent each email as a set ofNP feature vectors.
We used 2,500 NPsextracted from 51 email messages as a trainingset and 324 NPs from 8 messages for testing.Each NP was manually tagged for saliency byone of the authors and we are planning to addmore judges in the future.
The final moduledeals with presentation of the gisted emailmessage.2.1 The Email PreprocessorThis module uses finite-state transducertechnology in order to identify message content.Information at the top of the message related to?From/To/Date'' as well as the signature blockare separated from the message content.2.2 Candidate Simple Noun Phrase Extraction andFiltering UnitThis module performs shallow text processingfor extraction and filtering of simple NPcandidates, consisting of a pipeline of threemodules: text tokenization, NP extraction, andNP filtering.
Since the tool was created topreprocess email for speech output, some of thetext tokenization suitable for speech is notaccurate for text processing and somemodifications needed to be implemented (e.g.email preprocessor splits acronyms like DLI2into DLI 2).
The noun phrase extraction moduleuses Brill's POS tagger [Brill (1992)]and a baseNP chunker [Ramshaw and Marcus (1995)].After analyzing some of these errors, weaugmented the tagger lexicon from our trainingdata and we added lexical and contextual rulesto deal mainly with incorrect tagging of gerundendings.
In order to improve the accuracy ofclassifiers we perform linguistic filtering, asdiscussed in detail in Section 3.1.2.2.3 Machine Learning UnitThe first component of the ML unit is thefeature selection module to compute NPvectors.
In the training phase, a model foridentifying salient simple NPs is created.The training data consist of a list of featurevectors already classified as salient/non-salient by the user.
Thus we rely on user-relevance judgments to train the ML unit.
Inthe extraction phase this unit will classifyrelevant NPs using the model generatedduring training.
We applied three machinelearning paradigms (decision trees, ruleinduction algorithms, and decision forest)evaluating three different classifiers.2.4 PresentationThe presentation of the message gist is acomplex user interface issue with itsindependent set of problems.
Depending onthe application and its use, one can think ofdifferent presentation techniques.
The gist ofthe message could be the set of NPs or the setof sentences in which these NPs occur so thatthe added context would make it moreunderstandable to the user.
We do not addressin this work the disfluency that could occur inlisting a set of extracted sentences, since theaim is to deliver to the user the very contentof the message even in a raw fashion.
GIST-IT is to be used in an application where theoutput is synthesized speech.
The focus ofthis paper is on extracting content with GIST-IT, although presentation is a topic for futureresearch.3 Combining Linguistic Knowledge andMachine Learning for Email GistingWe combine symbolic machine learning andlinguistic processing in order to extract thesalient phrases of a document.
Out of thelarge syntactic constituents of a sentence, e.g.noun phrases, verb phrases, and prepositionalphrases, we assume that noun phrases (NPs)carry the most contentful information aboutthe document, even if sometimes the verbsare important too, as reported in the work by[Klavans and Kan (1998)].
The problem isthat no matter the size of a document, thenumber of informative noun phrases is verysmall comparing with the number of all nounphrases, making selection a necessity.
Indeed, inthe context of gisting, generating and presentingthe list of all noun phrases, even with adequatelinguistic filtering, may be overwhelming.
Thus,we define the extraction of important nounphrases as a classification task, applyingmachine learning techniques to determine whichfeatures associated with the candidate NPsclassify them as salient vs. non-salient.
Werepresent the document -- in this case an emailmessage -- as a set of candidate NPs, each ofthem associated with a feature vector used in theclassification model.
We use a number oflinguistic methods both in the extraction and inthe filtering of candidate noun phrases, and inthe selection of the features.3.1 Candidate NPsNoun phrases were extracted using Ramshawand Marcus's base NP chunker [Ramshaw andMarcus (1995)].
The base NP is either a simpleNP as defined by Wacholder (1998) or aconjunction of two simple NPs.
Since thefeature vectors used in the classifier scheme aresimple NPs we used different heuristics toautomatically split the conjoined NPs (CNP)into simple ones (SNP), properly assigning thepremodifiers.
Table 1 presents such an example:CNP: physics/NN and/CC biology/NN skilled/JJresearchers/NNSSNP1:  physics/NN skilled/JJ researchers/NNSSNP2: biology/NN skilled/JJ researchers/NNSTable 1 Splitting Complex NPs into Simple NPs3.1.2 Filtering simple NPsSince not all simple noun phrases are equallyimportant to reflect the document meaning, weuse well-defined linguistic properties to extractonly those NPs (or parts of NPs) that have agreater chance to render the salient information.By introducing this level of linguistic filteringbefore applying the learning scheme, weimprove the accuracy of the classifiers, thusobtaining better results (see discussion insections 4.1.3 and 5.3).
We performed fourfiltering steps:1.
Inflectional morphological processing.English nouns have only two kinds of inflection:an affix that marks plural and an affix thatmarks possessive.2.
Removing unimportant modifiers.
In thissecond step we remove the determiners thataccompany the nouns and also the auxiliarywords most and more that form theperiphrastic forms of comparative andsuperlative adjectives modifying the nouns.3.
Remove common words.
We used a list of571 common words used in IR systems inorder to further filter the list of candidateNPs.
Thus, words like even, following, every,are eliminated from the noun phrasestructure.
(i.e.
?even more detailedinformation?
and ?detailed information?
willalso be grouped together).4.
Remove ?empty?
nouns.
Words like lot,group, set, bunch are considered ?empty?nouns in the sense that they have nocontribution to the noun phrase meaning.
Forexample the meaning of the noun phrases like?group of students?,  ?lots of students?
or?bunch of students?
is given by the noun?students?.
In order not to bias the extractionof empty nouns we used three different datacollections: Brown corpus, Wall StreetJournal, and a set of 4000 email messages(most of which were collected during aconference organization).
Our algorithm wasa simple one: we extracted all the nouns thatappear in front of the preposition ?of?
andthen sorted them by frequency of appearancein all three corpora and used a threshold toselect the final list.
We generated a set of 141empty nouns that we used in this forth step offiltering process.3.2 Feature SelectionWe select a set of nine features that fall intothree categories: linguistic, statistical(frequency-based) and positional.
Thesefeatures capture information about therelative importance of NPs to the documentmeaning.Several studies rely on linguistic intuitionthat the head of the noun phrase makes agreater contribution to the semantics of thenominal group than the modifiers.
For someNLP tasks, the head is not necessarily themost important item of the noun phrase.
Inanalyzing email messages from theperspective of finding salient NPs, we claimthat the constituents of the NP have often asmuch semantic content as the head.
Thisopinion is also supported in the work of[Strzalkowski et al(1999)].
In many cases, themeaning of the NP is given equally bymodifier(s) -- usually nominal modifiers(s) --and head.
Consider the following list of simpleNPs selected as candidates:(1) ?conference workshop announcement?
(2) ?international conference?
(3) ?workshop description?
(4) ?conference deadline?In the case of noun phrase (1) the importance ofthe noun phrase is found in the two nounmodifiers: conference and   workshop as muchas in the head announcement.
We test thisempirical observation by introducing as aseparate feature in the feature vector, a newTF*IDF measure that counts for both themodifiers and the head of the noun phrase, thusseeing the NP as a sequence of equally weightedelements.
For the example above the newfeature will be:TF*IDFconference + TF*IDFworkshop + TF*IDFannouncementWe divided the set of features into threegroups: one associated with the head of the nounphrase, one associated with the whole NP andone that represents the new TF*IDF measurediscussed above.
Since we want to use thistechnique on other types of documents, allfeatures are independent of the text type orgenre.
For example, in the initial selection ofour attributes we introduced as separate featuresthe presence or the absence of NPs in the subjectline of the email and in the headline of the body.Kilander (1996) pointed out that users estimatethat ?subject lines can be useful, but alsodevastating if their importance is overlyemphasized?.
Based on this study and also onour goal to provide a method that is domain andgenre independent we decided not to considerthe subject line and the headlines as separatefeatures, but rather as weights included in theTF*IDF measures as presented below.
Anothermotivation for this decision is that in emailprocessing the correct identification of headlinesis not always clear.3.2.1 Features associated with the HeadWe choose two features to characterize the headof the noun phrases:head_tfidf ?
the TF*IDF measure of thehead of the candidate NP.head_focc - The first occurrence of the headin text (the numbers of words that precede thehead divided by the total number of words inthe document).3.2.2 Features associated with the wholeNPWe select six features that we considerrelevant in association with the whole NP:np_tfidf ?
the TF*IDF measure associatedwith the whole NP.np_focc - The first occurrence of the nounphrase in the document.np_length_words - Noun phrase lengthmeasured in number of words, normalized bydividing it with the total numbers of words inthe candidate NPs list.np_length_chars - Noun phrase lengthmeasured in number of characters,normalized by dividing it with the totalnumbers of characters in the candidate NPslist.sent_pos - Position of the noun phrase insentence: the number of words that precedethe noun phrase, divided by the sentencelength.
For noun phrases in the subject lineand headlines (which are usually short andwill be affected by this measure), we considerthe maximum length of sentence in documentas the normalization factor.par_pos - Position of noun phrase inparagraph, same as sent_pos, but at theparagraph level.3.2.3 Feature that considers all constituentsof the NP equally weightedm_htfidf - the new TF*IDF measure thattake into consideration the importance of themodifiers.In computing the TF*IDF measures(head_tfidf, np_tfidf, m_tfidf), weights wi,were assigned to account for the presence inthe subject line and/or headline.wi1 ?
if the head appears both in the subjectline and headline;wi2 ?
if the head appears only in the subjectline;wi3 ?
if the head appears only in headlineswhere wi1 > wi2 > wi3.These weights were manually chosen aftera set of experiments, but we plan to use eithera regression method or explore with geneticalgorithms to automatically learn them.3.3 Three Paradigms of Supervised MachineLearningSymbolic machine learning is used inconjunction with many NLP applications(syntactic and semantic parsing, POS tagging,text categorization, word sense disambiguation).In this paper we compare three symboliclearning techniques applied to the task of salientNP extraction: decision tree, rule inductionlearning and decision forests.We tested the performance of an axis-paralleldecision tree, C4.5 [Quinlan (1993)]; a rulelearning system RIPPER [Cohen (1995)] and adecision forest classifier (DFC) [Ho (1998)].RIPPER allows the user to specify the loss ratio,which indicates the ratio of the cost of a falsepositive to the cost of a false negative, thusallowing the trade off between precision andrecall.
This is crucial for our analysis since wedeal with sparse data set (in a document thenumber of salient NPs is much smaller than thenumber of irrelevant NPs).
Finally we tried toprove that a combination of classifiers mightimprove accuracy, increasing both precision andrecall.
The Decision Forest Classifier (DFC)uses an algorithm for systematicallyconstructing decision trees by pseudo-randomlyselecting subsets of components of featurevectors.
It implements different splittingfunctions.
In the setting of our evaluation wetested the information gain ratio (similar to theone used by Quinlan in C4.5).
An augmentedfeature vector (pairwise sums, differences, andproducts of features) was used for this classifier.4 Evaluation and Experimental ResultsSince there are many different summaries foreach document, evaluating summaries is adifficult problem.
Extracting the salient nounphrases is the first key step in the summarizationmethod that we adopt in this paper.
Thus, wefocus on evaluating the performance of GIST-ITon this task, using three classification schemesand two different feature settings.4.1 Evaluation SchemeThere are several questions that we address inthis paper:4.1.1 What features or combination offeatures are important in determining thedegree of salience of an NP?Following our assumption that eachconstituent of the noun phrase is equallymeaningful, we evaluate the impact of addingm_htfidf(see section 3.2.3), as an additionalfeature in the feature vector.
This is shown inTable 2 in the different feature vectors fv1and fv2.fv1-  head_focc  head_tfidf np_focc np_tfidfnp_length_words  np_length_chars par_pos sent_posfv2 - head_focc  head_tfidf  m_htfidf  np_focc np_tfidfnp_length_words np_length_chars par_pos sent_posTable 2 Two feature settings to evaluate theimpact of m_htfidf4.1.2 What classification scheme is moreadequate to our task?We evaluate the performance of threedifferent classifiers in the task of extractingsalient noun phrases.
As measures ofperformance we use precision (p) and recall(r).
The evaluation was performed accordingto what degree the output of the classifierscorresponds to the user judgments.C4.5 Ripper     DFC  Featurevectors p  r p r p rfv1 73.3 78.6 83.6 71.4 80.3 83.5fv2 70 88.9 85.7 78.8 85.7 87.9Table 3 Evaluation of two feature vectors usingthree classifiersTable 3 shows our results that answerthese two questions.
The table rows representthe two feature vectors we are comparing,and the columns correspond to the threeclassifiers chosen for the evaluation.4.1.3 Is linguistic filtering an important stepin extracting salient NPs?In the third evaluation we analyse the impactof linguistic filtering on the classifier?sperformance.
It turns out that results showmajor improvements, from 69.2% to 85.7%for precision of fv2, and from 56.25% to87.9% for recall of fv2.
For detailed results,see [Muresan et al (2001)].4.1.4 After the filtering and classification, arenoun phrases good candidates for representingthe gist of an email message?In order to answer this question, we comparethe output of GIST-IT on one email with theresults of KEA system [Witten et al(1999)] thatuses a 'bag-of-words' approach to key phraseextraction (see Table 4).modulesort of batchWordNet dataaccessesthe WordNetlots of WordNetWordNet perlQueryDatawnperl moduleextractinguse this moduleextracting lotsWordNet systemwww.cogsci.princeton.eduPerl module wordneinterface'wn' command line programsimple easy perl interfaceincluded man pagewordnetwordnet.pm modulewordnet systemwordnet packagequery perl modulecommand linewordnet relationwordnet datafree softwarequerydataTable 4 KEA (left)  vs GIST-IT output (right)5  Discussion of resultsThe results shown indicate that best systemperformance reached 87.9% recall and 85.7%precision.
Although these results are very high,judging NP relevance is a complex and highlyvariable task.
In the future, we will extend thegold standard with more judges, more data, andthus a more precise standard for measurement.5.1 The right selection of featuresFeature selection has a decisive impact onoverall performance.
As seen in Table 2, fv2 hasm_htfidfas an additional feature, and itsperformance shown in Table 3 is superior to fv1;the DFC classifier shows an increase both inprecision and recall.
These results support theoriginal hypothesis that in the context of gisting,the syntactic head of the noun phrase is notalways the semantic head, and modifiers canalso have an important role.5.2 Different classification modelsThe effectiveness of different classificationschemes in the context of our task is discussedhere.
As shown in Table 3, C4.5 performs wellespecially in terms of recall.
RIPPER, asdiscussed in [Cohen (1995)], is more appropriatefor noisy and sparse data collection thanC4.5, showing an improvement in precision.Finally, DFC which is a combination ofclassifiers, shows  improved performance.The classifier was run with an augumentedfeature vector that included pairwise sums,differences and products of the features.5.3 Impact of linguistic knowledgeAs shown in previous section, DFCperformed best in our task, so we chose onlythis classifier to present the impact oflinguistic knowledge.
Linguistic filteringimproved precision and recall, having animportant role especially on fv2, where thenew feature m_tfidf was used.
This isexplained by the fact that the filteringpresented in section 3.1.2 removed the noiseintroduced by unimportant modifiers,common and empty nouns, thus giving thisnew feature a larger impact.5.4 Noun phrases are better than n-gramsPresenting the gist of an email message byphrase extraction addresses one obviousquestion: can any phrasal extract representthe content of a document, or must a welldefined linguistic phrasal structure be used?To answer this question we compare theresults of our system that extractlinguistically principled phrasal units, withKEA output, that extracts bigrams andtrigrams as key phrases [Witten et al(1999)].Table 4 shows the results of the KEA system.Due to the n-gram approach, KEA outputcontains phrases like sort of batch, extractinglots, wn, and even urls that are unlikely torepresent the gist of a document.Conclusion and future workIn this paper we presented a novel techniquefor document gisting suitable for domain andgenre independent collections such as emailmessages.
The method extracts simple nounphrases using linguistic techniques and thenuse machine learning to classify them assalient for the document content.
Weevaluated the system in differentexperimental settings using threeclassification models.
In analyzing thestructure of NPs, we demonstrated that themodifiers of a noun phrase can besemantically as important as the head for thetask of gisting.
GIST-IT is fully implemented,evaluated, and embedded in an application,which allows user to access a set of informationincluding email, finances, etc.We plan to extend our work by takingadvantage of structured email, by classifyingmessages into folders, and then by applyinginformation extraction techniques.
Since NPsand machine learning techniques are domain andgenre independent, we plan to test GIST-IT ondifferent data collections (e.g.
web pages), andfor other knowledge management tasks, such asdocument indexing or query refinement.Additionally, we plan to test the significance ofthe output for the user, i.e.
whether the systemprovide informative content and adequate gist ofthe message.ReferencesBerger, A.L and Mittal, V.O (2000).
OCELOT:A system forsummarizing web pages.
In Proceedings of the 23rdAnnual International ACM SIGIR, Athens, Greece, pp144-151.Brill, E. (1992).
A Simple Rule-based Part of SpeechTagger.
In Proceedings of the Third Conference onANLP.
Trento, Italy; 1992Boguraev, B. and Kennedy, C. (1999).
Salience-basedcontent characterisation of text documents.
In I. Maniand T. Maybury, M., editors, Advances in AutomaticText Summarization, pp 99-111.
The MIT Press.Cohen, W. (1995).
Fast Effective Rule Induction.
Machine-Learning: Proceedings of the Twelfth InternationalConference.Ho, T.K (1998).
The random subspace method forconstructing decision forests.
IEEE Transactions onPattern Analysis and Machine Intelligence, 20(8).Hovy, E.H (2000).
Automated Text Summarization.
In R.Mitkov, editor,  Oxford University Handbook ofComputational Linguistics.
Oxford Univ.
Press.Kilander, F. (1996).
Properties of electronic texts forclassification purposes as suggested by users.Klavans, J.L., Wacholder, N. and Evans, D.K.
(2000)Evaluation of computational linguistic techniques foridentifying significant topics for browsing applications.In Proceedings (LREC-2000), Athens.
Greece.Klavans, J.L.
and Kan, M-Y.
(1998).Role of verbs indocument analysis.
In proceedings of COLING/ACL  98.Kupiec, J., Pedersen, J. and Chen, F. (1995).
A trainabledocument summarizer.
In Proceedings of the 18thAnnual International ACM SIGIR Conference onResearch and Development in Information Retrieval, pp68-73, Seattle, WA.McKeown, K.R,  Klavans, J.L, Hatzivassiloglou, V.,Barzilay, R. and Eskin, E. (1999).
Towardsmultidocument summarization by reformulation:Progress and prospects.
In Proceedings of AAAI'99.McKeown, K.R and Radev, D.R (1995).
Generatingsummaries of multiple news articles.
In Proceedingsof the 18th Annual International ACM SIGIRConference on Research and Development inInformation Retrieval, pp 74-82, Seattle, WA.Muresan, S., Tzoukermann, E. and Klavans, J.L.(2001).
Email Summarization Using Linguistic andMachine Learning Techniques.
In Proceedings ofCoNLL 2001 ACL Workshop, Toulouse, France.Murthy, S.K., Kasif, S., Salzberg, S. and Beigel, R.(1993).
OC1: Randomized Induction of ObliqueDecision Trees.
Proceedings of the Eleventh NationalConference on Artificial Intelligence, pp.
322--327,Washington, D.C.Quinlan, J.R (1993).
C4.5: Program for MachineLearning.
Morgan Kaufmann.Ramshaw, L.A. and Marcus, M.P.
(1995).
TextChunking Using Transformation-Based Learning.
InProceedings of Third ACL Workshop on Very LargeCorpora, MIT.Sparck-Jones, K. (1999).
What Is The Role of NLP inText Retrieval.
In T. Strzalkowski, editor, NaturalLanguage Information Retrieval.
Kluwer, Boston,MA.Strzalkowski, T., Lin, F., Wang, J., and Perez-Carballo,J.
(1999).
Evaluating natural language  processingtechniques for information retrieval.
In T.Strzalkowski, editor, Natural Language InformationRetrieval.
Kluwer, Boston, MA.Turney, P.D.
(2000).
Learning algorithms forkeyphrase exraction.
Information Retrieval, 2(4): pp303-336.Ueda, Y., Oka M., Koyama T. and Miyauchi T (2000).Toward the "at-a-glance" summary: Phrase-representation summarization method.
InProceedings of COLING 2000.Wacholder, N. (1998).
Simplex NPS sorted by head: amethod for identifying significant topics within adocument, In Proceedings of the COLING-ACLWorkshop on the Computational Treatment ofNominals.Whittaker, S. and Sidner, C. Email overload: Exploringpersonal information management of email.
InProceedings of CHI?96.
p. 276-283.
NY:ACM PressWitten, I.H, Paynter, G.W., Frank E., Gutwin C. andNevill-Manning, C.G (1999).
KEA: Practicalautomatic keyphrase extraction.
In Proceedings ofDL'99, pp 254-256.
