A Multilingual Multimedia Indian Sign Language Dictionary ToolTirthankarDasguptaIIT, Kharagpurtirtha@iitkgp.ernet.inSambitShuklaNIT, Rourkelasks.at.nitr@gmail.comSandeepKumarNIT, Allahabad.mnnit.sandeep@gmail.comSynny DiwakarNIT, Suratkalsunny.diwakarnitk@gmail.comAnupam BasuIIT, KharagpurAnupam-bas@gmail.comAbstractThis paper presents a cross platform multi-lingual multimedia Indian Sign Language(ISL) dictionary building tool.
ISL is a lin-guistically under-investigated languagewith no source of well documented elec-tronic data.
Research on ISL linguisticsalso gets hindered due to a lack of ISLknowledge and the unavailability of anyeducational tools.
Our system can be usedto associate signs corresponding to a giventext.
The current system also facilitates thephonological annotation of Indian signs inthe form of HamNoSys structure.
The gen-erated HamNoSys string can be given asinput to an avatar module to produce ananimated sign representation.1 IntroductionA sign language is a visual-gesture language thatuses hand, arm, body, and face to convey thoughtsand meanings.
It is a language that is commonlydeveloped in deaf communities, which includesdeaf people, their friends and families as well aspeople who are hard of hearing.
Despite commonmisconceptions, sign languages are complete natu-ral languages, with their own syntax and grammar.However, sign languages are not universal.
As isthe case in spoken language, every country has gotits own sign language with high degree of gram-matical variations.The sign language used in India is com-monly known as Indian Sign Language (hence-forth called ISL).
However, it has been argued thatpossibly the same SL is used in Nepal, Sri Lanka,Bangladesh, and border regions of Pakistan(Zeshan et al, 2004).
Different dialects of ISLwith broad lexical variation are found in differentparts of the Indian subcontinent.
However, thegrammatical structure is same for all dialects(Zeshan, 2003).The All India Federation of the Deaf estimatesaround 4 million deaf people and more than 10million hard of hearing people in India (Zeshan etal, 2004).
Studies revealed that, one out of everyfive deaf people in the world are from India.
Morethan 1 million deaf adults and around 0.5 milliondeaf children uses Indian Sign Language as amode of communication (Zeshan et al 2004).However, an UNESCO report (1980) found thatonly 5% of the deaf get any education in India.The reason behind such a low literacy rate can bedue to the following reasons: a) Till the early 20thcentury, deafness in India, is considered as a pun-ishment for sins and signing is strictly discouraged(Zeshan et.
al, 2004).
b) Until the late 1970?s, ithas been believed that, there were no such lan-guage called ISL.
c) Lack of research in ISL lin-guistics.
d) Unavailability of well documented andannotated ISL lexicon.
e) Unavailability of anyISL learning tool.
f) Difficulties in getting signlanguage interpreters.Linguistic studies on ISL were startedaround 1978 and it has been found that ISL is acomplete natural language, instigated in India,having its own morphology, phonology, syntax,and grammar (Vasishta et.
al, 1978; Zeshan et.al,2004).
The research on ISL linguistics and phono-logical studies get hindered due to lack of linguis-tically annotated and well documented ISL data.
Adictionary of around 1000 signs in four differentregional varieties was released (Vasishta et.al,The 6th Workshop on Asian Languae Resources, 2008571978).
However, these signs are based on graphi-cal icons which are not only difficult to understandbut also lack phonological features like move-ments and non-manual expressions.As it has been specified above,  ISL is not onlyused by the deaf people but also by the hearingparents of the deaf children, the hearing childrenof deaf  adults and hearing deaf educators (Zeshanet al 2004).
Therefore the need to build a systemthat can associate signs to the words of spokenlanguage, and which can further be used to learnISL, is significant.
Further associating signs ofdifferent SL (like ASL1 , BSL2 and ISL) to a wordwill help the user to learn foreign SLs simultane-ously.Several works have been done on buildingmultimedia-based foreign SL dictionaries as dis-cussed in (Buttussi et.
al., 2007).
However no suchsystem is currently available for ISL.
moreover,most of the current systems suffer from the follow-ing limitations:?
Most of the systems are native language specificand hence, cannot be used for ISL.?
Most of the systems provide a word-sign searchbut very few systems provide a sign-word orsign-sign search.?
Very few systems are cross platform.?
Systems lack sophisticated phonological infor-mation like hand-shape, orientations, move-ments, and non-manual signs.In order to overcome the above mentioned crisis,and based on the limitations of the current sys-tems, our objective is to:?
Build a cross platform multilingual multimediaSL-Dictionary tool which can be used to create alarge SL lexicon.?
This tool can be used to associate signs to thewords, phrases, or sentences of a spoken lan-guage text.?
The sign associated with each word is composedof its related part-of-speech and semantic senses.?
The input text (word, phrase, or a sentence) maybe in any language (like English or Hindi) andthe associated sign can be in any standard signlanguage (ASL or ISL).?
This tool can also be used to associate complexSL phonological features like hand shape, palm1 ASL: American Sign Language.2 BSL: British Sign Language.orientation, locations, movements, and non-manual expressions.?
The phonological features are expressed in termsof HamNoSys (Prillwitz et.
al, 1989).?
Facilitate search options like word-sign andsearch by HamNoSys.?
The generated lexicon is exported in XML fileformat and the sign is stored in the form of digi-tal videos.?
The video segments are captured using webcamsconnected with the system.
It is possible to at-tach multiple webcams to the system to capturevideo segments from multiple angles.
This fea-ture enables a user to better understand some ofthe complex sign language attributes.The organization of the paper is as follows: Sec-tion 2 gives a brief introduction to ISL phonology.Section 3 presents related works on ISL Diction-ary.
Section 4 presents the overall system architec-ture of the SL-dictionary tool.
Section 5 and 6 pre-sents a brief discussion related HamNoSys repre-sentation, and the HamNoSys editor.
Section 7presents conclusion and future work.2 ISL PhonologyIndian Sign Language (ISL) is a visual-spatial lan-guage which provides linguistic information usinghands, arms, face, and head/body postures.
Thesigner often uses the 3D space around his body todescribe an event (Zeshan, 2003).
Unlike spokenlanguages where the communication medium isdependent on sound, in sign language, the com-munication medium depends upon the visualchannel.
In spoken language, a word is composedof phonemes.
Two words can be distinguished byat least one phoneme.
In SL, a sign is composed ofcheremes3 and similarly two signs can differ by atleast one chereme (Stokoe, 1978).
A sign is a se-quential or parallel construction of its manual andnon-manual cheremes.
A manual chereme can bedefined by several parameters like:?
Hand shape.?
Hand location?
Orientation.?
Movements (straight, circular or curved)3 The term chereme (originally proposed by WilliamStokoe (Stokoe, 1978)) in Greek means ?hand?.
It isequivalent to the phonemes of spoken languages.The 6th Workshop on Asian Languae Resources, 200858Non-manual cheremes are defined by:?
Facial expressions.?
Eye gaze and Head/body posture (Zeshan,2003).However, there exist some signs which may con-tain only manual or non-manual components.
Forexample the sign ?Yes?
is signed by vertical headnod and it has no manual component.ISL signs can be generally classified into threeclasses: One handed, two handed, and non-manualsigns.
Fig.
1 shows the overall Indian sign hierar-chy.Fig.
1: ISL Type HierarchyOne handed signs: the one handed signs are repre-sented by a single dominating hand.
One handedsigns can be either static or movement related.Each of the static and movement signs is furtherclassified into manual and non-manual signs.
Fig.2 shows examples of one handed static signs withnon-manual and manual components.Fig.
2: One Handed static manual sign (Ear) andnon-manual sign (Headache).Two hand signs: As in the case of one hand signs,similar classification can be applied to two handedsigns.
However, two handed signs with move-ments can be further distinguished as:Type0: Signs where both hands are active (see Fig3).Type1: Signs where one hand (dominant) is moreactive compared to the other hand (non-dominant)as shown in Fig 3.FlagLongFig.3 : Two handed sign "long"(both the hands aremoving) and ?Flag?
(only the dominant right handis moving)3 Related works on ISL dictionaryLinguistic studies on ISL are in their infancy ascompared to other natural languages like English,Hindi, or Bengali and also to other SLs.
Linguisticwork on ISL began during late 1970?s.
Before that,the existence of ISL was not acknowledged.
In1977 a survey was conducted (see Vasistha et.
al.,1998 for documentation) and it was revealed thatISL is a complete natural language instigated atthe Indian subcontinent.
Vasistha collected signsfrom four major states of India (Delhi, Mumbai,Kolkata, and Bangalore) and released four diction-aries of ISL regional varieties.
The RamkrishnaMission vidyalaya, Coimbatore has published an-other ISL dictionary in 2001.
However, all thesedictionaries are based on iconic representations ofsigns.
As a result some of the important phono-logical information like, movements and non-manual expression gets lost.
No other work of itskind has so far been reported (Zeshan, 2004).Several works have been done in buildingASL and BSL dictionary tools.
Some of the sys-tems are briefly discussed below:Headache Ear?
(Wilcox et.
al, 1994) developed a multimediaASL dictionary tool, which prerecorded digitalvideo frames.?
(Geitz et.al, 1996) developed a VRML basedASL finger spelled system, which ran on inter-net.?
Sign Smith (VCOM3D, 2004) is a 3D illustrateddictionary of ASL.
It is also used as educationalsoftware as well as an authoring tool to createASL content.?
(Buttussi et.
al, 2007) proposes an Italian SignLanguage dictionary tool.
This tool uses H-animator to generate signing avatar.
This toolprovides multiple search functionality like word-sign, sign-word, and sign-sign search.
This toolalso facilitates association of one or more SL fora given input word.The 6th Workshop on Asian Languae Resources, 2008594 SL-DictionaryThe primary objective of the SL-dictionary tool isto provide an easy to use GUI to create a multilin-gual multimedia SL dictionary by which a user canassociate signs as well as the parameters defining asign, corresponding to a given text.
The overallarchitecture of the system is shown in Fig.
4.
Thesystem has been divided into two modules: a) Ex-pert module and b) User Module.The expert module has got three mainunits: a) Input Text Processing Unit b) Visual DataCapture Unit (VDCU) c) Sign Storage Unit and d)HamNoSys Editor.Input Text Processing Unit: In this unit a SL ex-pert chooses the input spoken language (like, Eng-lish, or Hindi) and the target sign language (like,ISL, or ASL) and then enters a text.
The input tothe system may be word, phrase, or sentences.
Ifthe text is a word the system generates all possiblemeanings, with the help of WordNet4, along withthe part of speech (POS)5 of that particular word.In order to get the exact part-of-speech of a word,the SL expert has to enter an example sentencecorresponding to that word.
This sentence is givenas an input to the POS-tagger to get the correctPOS of the word.
A word may have multiplesenses as returned by WordNet.
The user can se-lect one or more senses from the list.Visual Data Capture Unit: Sign corresponding to aword sense is signed by the user which is capturedby the Visual Data Capture Unit (VDCU).
TheVDCU is connected through multiple webcams,placed at different angular positions with respectto the signer.
As a result different articulationpoints of a signs are getting stored with in the da-tabase.
This will enable the SL learner to under-stand a particular sign easily.
Fig.5 shows how asign from multiple angles is getting captured.Storage Unit: The input text along with its anno-tated information, the digital video sign, and thephonological parameters defining the sign arestored with in a database which is further exportedinto an XML formatted file (see Fig.
6).
The pho-nological parameters are expressed in the form ofHamNoSys (discussed in section 5).4 wordnet.princeton.edu/5 We have used the Stanford Part-of-Speech tagger(nlp.stanford.edu/software/tagger.shtml)Fig.
4: System Architecture of ISL-DictionaryFig.5: capturing video signs from multiple angleFig.6: The ISL-dictionary XML FormatSearching: The search engine of the current sys-tem takes a spoken language text as input parsesthe XML formatted dictionary and sequentiallysearches the dictionary.
If a match is found, thenThe 6th Workshop on Asian Languae Resources, 200860the sign corresponding to the lexical entry is beingdisplayed.5 Sign language notation systemsAs it has been mentioned above, Sign languagedoes not have any written form.
Hence, In order todefine a sign we need some notation system.
Thereare a number of phonological notation systems forthe representation of SL as discussed in (Smithet.al, 2003).
One of the popular among them isStokoe notation (Stokoe, 2003; Smith et.al, 2003).Stokoe defines a sign by three parameters: a)Hand-shape or designator (dez) b) location orplace of articulation with respect to the body (tab)and c) movements or signation (sig).HamNoSys (Prillwitz et.
al, 1989) is aphonetic transcription system, based on Stokoenotation, used to transcribe signing gestures.
It is asyntactic representation of a sign to facilitate com-puter processing.
HamNoSys extends the tradi-tional Stokoe based notation system by furtherexpanding sign representation by some more pa-rameters.
These parameters can be defined as:?
Dominant hand?s shape.?
Location of the dominant and the non-dominanthand with respect to the body.?
Extended finger orientation of both dominantand non-dominant hand.?
Palm orientation of both hands.?
Movements (straight, circular, or curved)?
Non-manual signs.Fig.
7 shows examples of different HamNoSyssymbols and their descriptions.Fig.
8 shows an example where HamNoSys repre-sentation of the word ?WOMAN?
is explained.Here, the parameters like movement and non-manual signs are not present, as the sign?WOMAN?
in ISL does not have these expres-sions.
Fig.9 shows the ISL representation of?WOMAN?.Fig.
8: HamNoSys representation of ?WOMAN?6 HamNoSys EditorTranscribing a sign by HamNoSys is not a trivialtask.
A user who is transcribing a sign should bean expert in both HamNoSys as well as ISL.Moreover he has to remember all the HamNoSyssymbols and their corresponding meanings in or-der to define a sign.
In India it is very difficult tofind such a person.
Hence our main goal behindbuilding a HamNoSys editor is that, it can be usedby an ISL expert with little or no knowledge inHamNoSys.
The tool should provide an easy touse GUI that can be used to transcribephonological information of a sign.The HamNoSys editor provides a set ofgraphical images (most of the images are collectedfrom www.sign-lang.uni-amburg.de/Projekte/HamNoSys) for most of the phonological parame-ters of a sign, like, Hand-shape, orientation, loca-tion and movements.
Based on the parameters, anISL expert can choose a set of images and the sys-tem will automatically generate the correspondingHamNoSys of the sign.
This HamNoSys string canbe given as an input to a signing avatar module togenerate animated sign representation.A signing avatar is a virtual human char-acter that performs sign language.
However, thischaracter needs a set of instructions which willguide its movement.
These instructions can beprovided in the form of HamNoSys (Marshall andS?f?r, 2001).Fig.7: HamNoSys symbols and there descriptionsPalmExtended Finger orientation??
\  ???
H   f  v?
?HandshapeLocationFig.9: Sign of ?WOMAN?The 6th Workshop on Asian Languae Resources, 200861Fig, 11: Twelve basic hand-shape classesFig.10: HamNoSys ParametersFig.12: GUI to express finger and palm orientationsFig.13: GUI to choose various hand locationsnear the human faceThe 6th Workshop on Asian Languae Resources, 200862Fig 14: GUI showing various straight movement parametersFig.10 shows the five basic parameters of Ham-NoSys.
For each of these parameters there existinterfaces through which a SL expert can choosethe desired parameters to define a sign.
For exam-ple, the right hand side of Fig.11 shows the twelvebasic hand-shape classes.
Each of these base hand-shapes may contain several derived hand-shapes asdefined in HamNoSys (version 4.0).
If a particularhand-shape is selected, then the HamNoSys sym-bol corresponding to the hand-shape gets stored inthe XML database (see Fig.6).
Similarly, separateinterfaces have been provided to identify palmorientation (see Fig,12), hand location (seeFig.13), movements (see Fig.14), and non-manualsigns.Due to its symbolic structure, HamNoSysis fairly easy to write, and understand.
However,there are some drawbacks on this notation systemthat make it difficult to be used universally for allsign languages (Smith and Edmondson, 2004).
Forexample, HamNoSys uses some fixed set of sym-bols to define a sign however it is possible that aparticular sign in any sign language may not bedefined by 'the fixed set of symbols.
For exampleHamNoSys does not have well defined symbolsfor non-manual expressions.
Consider the sign?BITTER?, in ISL the representation is shown inFig.15.
It can be observed that it is very difficult torepresent the facial expressions like eyebrow byHamNoSys.
Currently we have a collection ofaround 979 sign icons (published by Vasistha et.
al1998), which we are trying to transcribe in Ham-NoSys.
Out of these, 16% of the signs containnon-manual features which we are unable to repre-sent in HamNoSys.Fig.15: ISL representation of"BITTER"7 Conclusion and Future worksThe paper presents an approach towards building amultimedia SL dictionary tool.
This tool can beused to prepare a well documented ISL dictionary.The system is intended to take any Indian lan-guage text as input and can store signs in any SL.Currently the system takes English, Hindi andBengali texts as input and can store signs in ISLonly.
The system also provides an easy to use GUIThe 6th Workshop on Asian Languae Resources, 200863to include phonological information of a sign inthe form of HamNoSys string.
The generatedHamNoSys string can then be used as an input tothe signing avatar module to produce animatedsign output.In the next phase of our work we will im-prove the system so that it can associate signs inany other SL (like, ASL and BSL).
Further,WordNet as well as POS Tagger corresponding toHindi and Bengali languages should also be inte-grated with the system.
Also, support has to bebuilt so that system can perform sign-to-word andsign to sign search.
We will also perform properevaluation of the HamNoSys editor in order tounderstand its utility to the SL user.ReferencesButtussi F., Chittaro L., Coppo M. 2007.
Using Web3Dtechnologies for visualization and search of signs inan international sign language dictionary.
Proceed-ings of the twelfth international conference on 3Dweb technology.
Perugia, Italy Pages: 61 ?
70 Yearof Publication: 2007 ISBN:978-1-59593-652-3Geitz, S., Hanson, T., Maher, S. 1996.
Computer gener-ated 3-dimensional models of manual alphabet hand-shapes for the World Wide Web.
In Assets ?96:Proceedings of the second annual ACM confer-ence on Assistive technologies, ACM Press, NewYork, NY, USA, 27?31.Marshall I. and S?f?r ?.
2001.Extraction of semanticrepresentations from syntactic SMU link grammarlinkages..
In G. Angelova, editor, Proceedings ofRecent Advances in Natural Lanugage Processing,pp: 154-159, Tzigov Chark, Bulgaria, September.Prillwitz P., Regina Leven, Heiko Zienert, ThomasHamke, and Jan Henning.
1989.
HamNoSys Version2.0: Hamburg Notation System for Sign Languages:An Introductory Guide, volume 5 of InternationalStudies on Sign Language and Communication ofthe Deaf.
Signum Press, Hamburg, Germany,Smith G., Angus.
1999.
English to American Sign Lan-guage machine translation of weather reports.
Pro-ceedings of the Second High Desert Student Confer-ence in Linguistics.Smith,K.C., Edmondson, W. 2004.
The Developmentof a Computational Notation for Synthesis of Signand Gesture, GW03(312-323).Speers, A.
1995.
SL-Corpus: A computer tool for signlanguage corpora., Georgetown University.Stokoe W. C., 1960.
Sign language structure: an out-line of the visual communication systems of theAmerican deaf.
2nd edition, 1978.
Silver Spring,MD: Linstok Press.VCOM3D,2004.
Sign smith products.http://www.vcom3d.com.Wilcox, S., Scheibman, J., Wood, D., Cokely, D., andstokoe, w. c. 1994.
Multimedia dictionary of Ameri-can Sign Language.
In Assets ?94: Proceedings ofthe first annual ACM conference on Assistive tech-nologies, ACM Press, New York, NY, USA, 9?16.Vasishta M., Woodward J., DeSantis S. 1998, ?An In-troduction to Indian Sign Language?, All India Fed-eration of the Deaf (Third Edition).Zeshan U., 2003,?Indo-Pakistani Sign LanguageGrammar: A Typological Outline?, Sign LanguageStudies - Volume 3, Number 2, , pp.
157-212Zeshan U., Madan M. Vasishta, Sethna M. 2004, ?im-plementation of indian sign language in educationalsettings?- Volume 15, Number 2, Asia Pacific Dis-ability Rehabilitation Journal, , pp.
15-35The 6th Workshop on Asian Languae Resources, 200864
