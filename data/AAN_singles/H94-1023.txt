SESS ION 4: MACHINE TRANSLAT IONEduard HovyUSC Information Sciences InstituteMarina de1 Rey, CA 90292About 2~ years ago, ARPA initiated a new program inMachine Translation (MT).
Three projects were funded:CANI)II)E, built by IBM in New York; I,INGSTA'I~, built byDragon Systems in Boston; and PAN(;I,()SS, a collabora-tion of the Computing Research Laboratory at New Mex-ico State University, the Center for Machine Translation atCarnegie Mellon University, and the Information SciencesInstitute of the University of Southern California.
All butone of the papers in this section is directly related to thesesystems.
In one way or another, each paper addresses one ofthe following two major dimensions of variation: basic ap.proach (i.e., operation and data collection by statistical vs.symbolic means) and depth of analysis (i.e., direct replace-ment, transfer, or interlingual).
This overview first explainsthese terms and then describes the import of the papers.Basic ApproachOver the past six years, the CANI)nn)I,: group at IBM hasgained some impressive results, and considerable notori-ety, by performing MT employing only statistical, non-linguistic, methods.
Using cross-language correspondencescollected statistically from 3m sentences of the CanadianParliamentary records, which are bilingual French andEnglish, c:Asnm)n,~ operates by replacing portions of eachFrench input sentence with the statistically most appro-priate English equivalent, aking the whole sentence intoaccount, and then ~smoothing ~ the resulting words andphrases into the most probable grammatical English sen-tence.In contrast, the PAN(iI,OSS system takes a more tradi-tional symbolic approach, involving linguistic and semanticknowledge resources such as grammars of Spanish and En-glish, a library of ~semantic ~ symbols that can be composedto represent the ~meaning = of each sentence, and a varietyof process modules, such as sentence parsers, analyzers, andgenerators, that employ these resources to convert informa-tion from one form (say, a Spanish sentence) to another(say, a syntactic parse tree of that sentence).The i,zN(;s'n'^'l' system, as its name suggests, is a hybrid,involving linguistic-symbolic information for some subtasksand statistical information for others.Depth of  AnalysisThe basic theoretical underpinnings of MT involve theamount of analysis performed on the input (source lan-guage) sentence during the process of converting it to theoutput (target language) sentence (since almost all MT sys-tems work on a sentence by sentence basis, multisentencecomplexities are ignored here).
In the simplest possibletranslation method, asystem simply pattern-matches (por-tions of) each input sentence against a bilingual replace-ment dictionary and replaces each portion with its targetlanguage quivalent.
The result is usually massaged in vari-ous ways in order to achieve some degree of grammaticality.A major problem with this approach is the immensity ofthe replacement dictionary required: since no generaliza-tions are represented, the dictionary needs distinct entriesfor each form of each word (see, sees, saw, seen, or book,books, etc.).
Even a rudimentary generalization (e.g., stor-ing in the replacement dictionary only the root forms ofwords) can have a large effect.
However, this move comesat the cost of creating two new programs: one program onthe input side that recognizes each source language inflectedword and replaces it by its root form plus a pseudo-wordthat carries the additional (number, tense, etc.)
informa-tion, and another program on the output side that appro-priately inflects the replacement root form according to theinformation in the pseudo-word.Once you have embarked on this route of analysis, thenext step is to notice that languages exhibit syntactic reg-ularities that map regularly.
For example, in English theractive" verb appears in what one can call "second posi-tion', while in Japanese it appears at the end of the sen-tence.
Without knowing which word is the verb, a directreplacement system has no way in general of reposition-ing it correctly during translation.
However, at the costof writing two more programs, a syntactic parser (input)and a generator (output), and creating rules that specifyhow the syntactic wordclasses (verb, noun, etc.)
map overfrom one language to another, you can greatly improve thequality of the translation, since now you get grammaticalsentences.
This move involves ome effort: though by nowbasic parsing and generation technology is fairly well un-derstood, writing adequately large grammars of languagesis a daunting task; no complete grammar has so far beenwritten of any natural anguage.It is clear on a moment's reflection, however, that trans-lation on purely syntactic grounds is bound to fail in manyinstances; think of simple lexical ambiguity by which "thechair called for order" is translated as ~the stool called forcommand', still grammatically correct.
Adequate transla-tion obviously requires ome sensitivity to the meaning ofthe source text.
That is, to improve the quality of transla-tion ever further, you have to write semantic analyzer andgenerator programs and develop an internal meaning rep-resentation notation, upon which you can unleash inferencerules about how word meanings combine (disallowing ~call"to take inanimate agents, for example).
Here the central is-sue is constructing an adequately large and expressive setof meaning representation symbols.
Ideally, these symbolswould be independent of any human language; they wouldconstitute the symbols of what is called in MT the Interlin-133~Ua.One advantage of Interlingual systems is the fact thatthey c~m be significantly cheaper to extend to handle newlanguages.
MT systems that use transfer rules to specifyhow the intermediate representations map from one lan-guage to another require order n 2 sets of mapping rulesfor n l~mguages (one set of rules between each pair of lan-guages).
Interlingual systems, on the other hand, need onlyorder ~; rules, just between each language and the Interlin-gua.
When the number of transfer ules between any twolanguages exceeds 1,000, the cost of developing an interlin-gua starts looking attractive.The  PapersThe first paper in this session, by White and O'Connell, isthe one that ties everything together.
White and O'Connellhave been retained by ARPA to administer the frequent(on average, every 8 months) evaluations of the MT sys-tems.
These evaluations have grown from relatively small(the first involved the three ARPA contractors and threeor four additional systems) to fairly large (the most recent,of January-February 1994, involved 19 systems).
In theirpaper, White and O'Connell describe the three major eval-uation criteria and then provide the systems' scores for theevaluation of May-August 1993.PAN(~,,OSS is a symbolic system at heart, although someof its newer components, and many of its knowledge acqui-sition efforts, are of a more statistical or semi-automatedflavor.
The paper by Okumura and Hovy addresses the coreproblem of linking a large wordiist used by the JtJMAN mod-ule to separate words in the input Japanese text to the sys-tem's Ontology (its interlingua lexicon).
Since the wordlistcontains over 100,000 items and the Ontology over 70,000,this linkage cannot be done manually.
The algorithms out-lined employ a bilingual Japanese-English dictionary as aabridge".
PAN(;,.OSS has undergone other changes as well.It was originally designed as a pure interlingual system, butnow includes (as is described in the paper by Nirenburg andFrederking) several MT engines, one of which (lexical trans-fer) is essentially direct replacement technology.
With sucha multi-engine system, a central problem is reconciling thevarious engines' outputs; this paper describes how the besttranslation is selected by a chart-walk algorithm using dy-namic programming techniques to find an optimal cover.The paper by Smadja and McKeown describes work notat present used in an MT system, though its result is clearlyintended to be.
The issue is how automatically to constructbilingual phrase (i.e., multi-word collocation) dictionariesfrom & bilingual aligned text corpus.
Like the CANI)II)Esystem, Smadja and McKeown use the Canadian Parlia-mentary records for their statisticaJly based identificationfirst of the longest multi-word sequence that appears withhigh enough frequency to be a true phrase, in one of thelanguages, and then find its trahslational equivalence(s) inthe other.
They argue that the Dice coefficient is the mostsuitable for their purpose.The third ARPA-funded system, ,,NC;S'O'A'O', is an interac-tive machine-aided translation system that helps the usercompose a high-quality translation from Japanese to En-gUsh.
Architecturally designed along more symbolic lines,the system contains a tokenizer/de-inflector, a syntacticparser, and a word-order re-arranger.
As such, it is a classictransfer system.
Each of these modules, however, employsknowledge collected and used in the statistics paradigm.The bulk of the paper describes the automated construc-tion of a lexically based word sequence grammar.The final paper, by Berger et al, describes IBM's CAN-,),,~: system.
In its simplest original form, (:AN,~mI,~ wasa pure direct replacement system, for which various kindsof French-Engiish equivalencies had been collected statisti-cally and captured in a so-called Translation Model.
Overthe past two years, it has become an increasingly sophisti-cated transfer system, as its developers build more morpho-logical, \]exical, and syntactic knowledge into more complexmodels: equivalent words, fertility (the number of Englishwords corresponding to a French one), word and word-classalignment correspondences, etc.
Thus while CANI)II)E re-mains a statistical system at heart, some of the rules orknowledge it uses, especially during early processing, aresymboIic/linguistic in nature.134
