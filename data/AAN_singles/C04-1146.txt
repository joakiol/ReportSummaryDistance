Characterising Measures of Lexical Distributional SimilarityJulie Weeds, David Weir and Diana McCarthyDepartment of InformaticsUniversity of SussexBrighton, BN1 9QH, UK{juliewe, davidw,dianam}@sussex.ac.ukAbstractThis work investigates the variation in a word?s dis-tributionally nearest neighbours with respect to thesimilarity measure used.
We identify one type ofvariation as being the relative frequency of the neigh-bour words with respect to the frequency of the tar-get word.
We then demonstrate a three-way connec-tion between relative frequency of similar words, aconcept of distributional gnerality and the seman-tic relation of hyponymy.
Finally, we consider theimpact that this has on one application of distribu-tional similarity methods (judging the composition-ality of collocations).1 IntroductionOver recent years, many Natural Language Pro-cessing (NLP) techniques have been developedthat might benefit from knowledge of distribu-tionally similar words, i.e., words that occur insimilar contexts.
For example, the sparse dataproblem can make it difficult to construct lan-guage models which predict combinations of lex-ical events.
Similarity-based smoothing (Brownet al, 1992; Dagan et al, 1999) is an intuitivelyappealing approach to this problem where prob-abilities of unseen co-occurrences are estimatedfrom probabilities of seen co-occurrences of dis-tributionally similar events.Other potential applications apply the hy-pothesised relationship (Harris, 1968) betweendistributional similarity and semantic similar-ity; i.e., similarity in the meaning of words canbe predicted from their distributional similarity.One advantage of automatically generated the-sauruses (Grefenstette, 1994; Lin, 1998; Curranand Moens, 2002) over large-scale manually cre-ated thesauruses such as WordNet (Fellbaum,1998) is that they might be tailored to a partic-ular genre or domain.However, due to the lack of a tight defini-tion for the concept of distributional similarityand the broad range of potential applications, alarge number of measures of distributional sim-ilarity have been proposed or adopted (see Sec-tion 2).
Previous work on the evaluation of dis-tributional similarity methods tends to eithercompare sets of distributionally similar wordsto a manually created semantic resource (Lin,1998; Curran and Moens, 2002) or be orientedtowards a particular task such as language mod-elling (Dagan et al, 1999; Lee, 1999).
The firstapproach is not ideal since it assumes that thegoal of distributional similarity methods is topredict semantic similarity and that the seman-tic resource used is a valid gold standard.
Fur-ther, the second approach is clearly advanta-geous when one wishes to apply distributionalsimilarity methods in a particular applicationarea.
However, it is not at all obvious that oneuniversally best measure exists for all applica-tions (Weeds and Weir, 2003).
Thus, applying adistributional similarity technique to a new ap-plication necessitates evaluating a large numberof distributional similarity measures in additionto evaluating the new model or algorithm.We propose a shift in focus from attemptingto discover the overall best distributional sim-ilarity measure to analysing the statistical andlinguistic properties of sets of distributionallysimilar words returned by different measures.This will make it possible to predict in advanceof any experimental evaluation which distribu-tional similarity measures might be most appro-priate for a particular application.Further, we explore a problem faced bythe automatic thesaurus generation community,which is that distributional similarity methodsdo not seem to offer any obvious way to dis-tinguish between the semantic relations of syn-onymy, antonymy and hyponymy.
Previouswork on this problem (Caraballo, 1999; Lin etal., 2003) involves identifying specific phrasalpatterns within text e.g., ?Xs and other Ys?
isused as evidence that X is a hyponym of Y. Ourwork explores the connection between relativefrequency, distributional generality and seman-tic generality with promising results.The rest of this paper is organised as follows.In Section 2, we present ten distributional simi-larity measures that have been proposed for usein NLP.
In Section 3, we analyse the variation inneighbour sets returned by these measures.
InSection 4, we take one fundamental statisticalproperty (word frequency) and analyse correla-tion between this and the nearest neighbour setsgenerated.
In Section 5, we relate relative fre-quency to a concept of distributional generalityand the semantic relation of hyponymy.
In Sec-tion 6, we consider the effects that this has on apotential application of distributional similaritytechniques, which is judging compositionality ofcollocations.2 Distributional similarity measuresIn this section, we introduce some basic con-cepts and then discuss the ten distributionalsimilarity measures used in this study.The co-occurrence types of a target word arethe contexts, c, in which it occurs and thesehave associated frequencies which may be usedto form probability estimates.
In our work, theco-occurrence types are always grammatical de-pendency relations.
For example, in Sections 3to 5, similarity between nouns is derived fromtheir co-occurrences with verbs in the direct-object position.
In Section 6, similarity betweenverbs is derived from their subjects and objects.The k nearest neighbours of a target word ware the k words for which similarity with w isgreatest.
Our use of the term similarity measureencompasses measures which should strictly bereferred to as distance, divergence or dissimilar-ity measures.
An increase in distance correlateswith a decrease in similarity.
However, eithertype of measure can be used to find the k near-est neighbours of a target word.Table 1 lists ten distributional similarity mea-sures.
The cosine measure (Salton and McGill,1983) returns the cosine of the angle betweentwo vectors.The Jensen-Shannon (JS) divergence measure(Rao, 1983) and the ?-skew divergence measure(Lee, 1999) are based on the Kullback-Leibler(KL) divergence measure.
The KL divergence,or relative entropy, D(p||q), between two prob-ability distribution functions p and q is defined(Cover and Thomas, 1991) as the ?inefficiencyof assuming that the distribution is q when thetrue distribution is p?
: D(p||q) =?c p logpq .However, D(p||q) = ?
if there are any con-texts c for which p(c) > 0 and q(c) = 0.
Thus,this measure cannot be used directly on maxi-mum likelihood estimate (MLE) probabilities.One possible solution is to use the JS diver-gence measure, which measures the cost of usingthe average distribution in place of each individ-ual distribution.
Another is the ?-skew diver-gence measure, which uses the p distribution tosmooth the q distribution.
The value of the pa-rameter ?
controls the extent to which the KLdivergence is approximated.
We use ?
= 0.99since this provides a close approximation to theKL divergence and has been shown to providegood results in previous research (Lee, 2001).The confusion probability (Sugawara et al,1985) is an estimate of the probability that oneword can be substituted for another.
Wordsw1 and w2 are completely confusable if we areequally as likely to see w2 in a given context aswe are to see w1 in that context.Jaccard?s coefficient (Salton and McGill,1983) calculates the proportion of features be-longing to either word that are shared by bothwords.
In the simplest case, the features of aword are defined as the contexts in which it hasbeen seen to occur.
simja+mi is a variant (Lin,1998) in which the features of a word are thosecontexts for which the pointwise mutual infor-mation (MI) between the word and the contextis positive, where MI can be calculated usingI(c, w) = log P (c|w)P (c) .
The related Dice Coeffi-cient (Frakes and Baeza-Yates, 1992) is omittedhere since it has been shown (van Rijsbergen,1979) that Dice and Jaccard?s Coefficients aremonotonic in each other.Lin?s Measure (Lin, 1998) is based on hisinformation-theoretic similarity theorem, whichstates, ?the similarity between A and B is mea-sured by the ratio between the amount of in-formation needed to state the commonality ofA and B and the information needed to fullydescribe what A and B are.
?The final three measures are settings inthe additive MI-based Co-occurrence RetrievalModel (AMCRM) (Weeds and Weir, 2003;Weeds, 2003).
We can measure the precisionand the recall of a potential neighbour?s re-trieval of the co-occurrences of the target word,where the sets of required and retrieved co-occurrences (F (w1) and F (w2) respectively) arethose co-occurrences for which MI is positive.Neighbours with both high precision and highrecall retrieval can be obtained by computingMeasure Functioncosine simcm(w2, w1) =?cP (c|w1).P (c|w2)?
?cP (c|w1)2?cP (c|w2)2Jens.-Shan.
distjs(w2, w1) = 12(D(p||p+q2)+D(q||p+q2))where p = P (c|w1) and q = P (c|w2)?-skew dist?
(w2, w1) = D (p||(?.q + (1?
?
).p)) where p = P (c|w1) and q = P (c|w2)conf.
prob.
simcp(w2|w1) =?cP (w1|c).P (w2|c).P (c)P (w1)Jaccard?s simja(w2, w1) =|F (w1)?F (w2)||F (w1)?F (w2)|where F (w) = {c : P (c|v) > 0}Jacc.+MI simja+mi(w2,W1) =|F (w1)?F (w2)||F (w1)?F (w2)|where F (w) = {c : I(c, w) > 0}Lin?s simlin(w2, w1) =?F (w1)?F (w2)(I(c,w1)+I(c,w2))?F (w1)I(c,w1)+?F (w2)I(c,w2)where F (w) = {c : I(c, w) > 0}precision simP(w2, w1) =?F (w1)?F (w2)I(c,w2)?F (w2)I(c,w2)where F (w) = {c : I(c, w) > 0}recall simR(w2, w1) =?F (w1)?F (w2)I(c,w1)?F (w1)I(c,w1)where F (w) = {c : I(c, w) > 0}harm.
mean simhm(w2, w1) =2.simP (w2,w1).simR(w2,w1)simP (w2,w1)+simR(w2,w1)where F (w) = {c : I(c, w) > 0}Table 1: Ten distributional similarity measurestheir harmonic mean (or F-score).3 Overlap of neighbour setsWe have described a number of ways of calcu-lating distributional similarity.
We now con-sider whether there is substantial variation ina word?s distributionally nearest neighbours ac-cording to the chosen measure.
We do this bycalculating the overlap between neighbour setsfor 2000 nouns generated using different mea-sures from direct-object data extracted from theBritish National Corpus (BNC).3.1 Experimental set-upThe data from which sets of nearest neighboursare derived is direct-object data for 2000 nounsextracted from the BNC using a robust accuratestatistical parser (RASP) (Briscoe and Carroll,2002).
For reasons of computational efficiency,we limit ourselves to 2000 nouns and direct-object relation data.
Given the goal of compar-ing neighbour sets generated by different mea-sures, we would not expect these restrictions toaffect our findings.
The complete set of 2000nouns (WScomp) is the union of two sets WShighand WSlow for which nouns were selected on thebasis of frequency: WShigh contains the 1000most frequently occurring nouns (frequency >500), and WSlow contains the nouns ranked3001-4000 (frequency ?
100).
By excludingmid-frequency nouns, we obtain a clear sepa-ration between high and low frequency nouns.The complete data-set consists of 1,596,798 co-occurrence tokens distributed over 331,079 co-occurrence types.
From this data, we computedthe similarity between every pair of nouns ac-cording to each distributional similarity mea-sure.
We then generated ranked sets of nearestneighbours (of size k = 200 and where a wordis excluded from being a neighbour of itself) foreach word and each measure.For a given word, we compute the overlap be-tween neighbour sets using a comparison tech-nique adapted from Lin (1998).
Given a wordw, each word w?
in WScomp is assigned a rankscore of k ?
rank if it is one of the k near-est neighbours of w using measure m and zerootherwise.
If NS(w,m) is the vector of suchscores for word w and measure m, then theoverlap, C(NS(w,m1),NS(w,m2)), of two neigh-bour sets is the cosine between the two vectors:C(NS(w,m1),NS(w,m2)) =?w?
rm1(w?, w)?
rm2(w?, w)?ki=1 i2The overlap score indicates the extent to whichsets share members and the extent to whichthey are in the same order.
To achieve an over-lap score of 1, the sets must contain exactlythe same items in exactly the same order.
Anoverlap score of 0 is obtained if the sets do notcontain any common items.
If two sets shareroughly half their items and these shared itemsare dispersed throughout the sets in a roughlysimilar order, we would expect the overlap be-tween sets to be around 0.5.cm js ?
cp ja ja+mi lincm 1.0(0.0) 0.69(0.12) 0.53(0.15) 0.33(0.09) 0.26(0.12) 0.28(0.15) 0.32(0.15)js 0.69(0.12) 1.0(0.0) 0.81(0.10) 0.46(0.31) 0.48(0.18) 0.49(0.20) 0.55(0.16)?
0.53(0.15) 0.81(0.10) 1.0(0.0) 0.61(0.08) 0.4(0.27) 0.39(0.25) 0.48(0.19)cp 0.33(0.09) 0.46(0.31) 0.61(0.08) 1.0(0.0) 0.24(0.24) 0.20(0.18) 0.29(0.15)ja 0.26(0.12) 0.48(0.18) 0.4(0.27) 0.24(0.24) 1.0(0.0) 0.81(0.08) 0.69(0.09)ja+mi 0.28(0.15) 0.49(0.20) 0.39(0.25) 0.20(0.18) 0.81(0.08) 1.0(0.0) 0.81(0.10)lin 0.32(0.15) 0.55(0.16) 0.48(0.19) 0.29(0.15) 0.69(0.09) 0.81(0.10) 1.0(0.0)Table 2: Cross-comparison of first seven similarity measures in terms of mean overlap of neighboursets and corresponding standard deviations.P R hmcm 0.18(0.10) 0.31(0.13) 0.30(0.14)js 0.19(0.12) 0.55(0.18) 0.51(0.18)?
0.08(0.08) 0.74(0.14) 0.41(0.23)cp 0.03(0.04) 0.57(0.10) 0.25(0.18)ja 0.36(0.30) 0.38(0.30) 0.74(0.14)ja+mi 0.42(0.30) 0.40(0.31) 0.86(0.07)lin 0.46(0.25) 0.52(0.22) 0.95(0.039)Table 3: Mean overlap scores for seven simi-larity measures with precision, recall and theharmonic mean in the AMCRM.3.2 ResultsTable 2 shows the mean overlap score betweenevery pair of the first seven measures in Table 1calculated over WScomp.
Table 3 shows the meanoverlap score between each of these measuresand precision, recall and the harmonic mean inthe AMCRM.
In both tables, standard devia-tions are given in brackets and boldface denotesthe highest levels of overlap for each measure.For compactness, each measure is denoted byits subscript from Table 1.Although overlap between most pairs ofmeasures is greater than expected if sets of200 neighbours were generated randomly fromWScomp (in this case, average overlap would be0.08 and only the overlap between the pairs(?,P) and (cp,P) is not significantly greaterthan this at the 1% level), there are substan-tial differences between the neighbour sets gen-erated by different measures.
For example, formany pairs, neighbour sets do not appear tohave even half their members in common.4 Frequency analysisWe have seen that there is a large variation inneighbours selected by different similarity mea-sures.
In this section, we analyse how neighboursets vary with respect to one fundamental statis-tical property ?
word frequency.
To do this, wemeasure the bias in neighbour sets towards highfrequency nouns and consider how this variesdepending on whether the target noun is itselfa high frequency noun or low frequency noun.4.1 Measuring biasIf a measure is biased towards selecting high fre-quency words as neighbours, then we would ex-pect that neighbour sets for this measure wouldbe made up mainly of words from WShigh.
Fur-ther, the more biased the measure is, the morehighly ranked these high frequency words willtend to be.
In other words, there will be highoverlap between neighbour sets generated con-sidering all 2000 nouns as potential neighboursand neighbour sets generated considering justthe nouns in WShigh as potential neighbours.
Inthe extreme case, where all of a noun?s k nearestneighbours are high frequency nouns, the over-lap with the high frequency noun neighbour setwill be 1 and the overlap with the low frequencynoun neighbour set will be 0.
The inverse is, ofcourse, true if a measure is biased towards se-lecting low frequency words as neighbours.If NSwordset is the vector of neighbours (andassociated rank scores) for a given word, w, andsimilarity measure, m, and generated consider-ing just the words in wordset as potential neigh-bours, then the overlap between two neighboursets can be computed using a cosine (as be-fore).
If Chigh = C(NScomp,NShigh) and Clow =C(NScomp,NSlow), then we compute the bias to-wards high frequency neighbours for word w us-ing measure m as: biashighm(w) =ChighChigh+ClowThe value of this normalised score lies in therange [0,1] where 1 indicates a neighbour setcompletely made up of high frequency words, 0indicates a neighbour set completely made up oflow frequency words and 0.5 indicates a neigh-bour set with no biases towards high or low fre-quency words.
This score is more informativethan simply calculating the proportion of highhigh freq.
low freq.target nouns target nounscm 0.90 0.87js 0.94 0.70?
0.98 0.90cp 1.00 0.99ja 0.99 0.21ja+mi 0.95 0.14lin 0.85 0.38P 0.12 0.04R 0.99 0.98hm 0.92 0.28Table 4: Mean value of biashigh according tomeasure and frequency of target noun.and low frequency words in each neighbour setbecause it weights the importance of neighboursby their rank in the set.
Thus, a large numberof high frequency words in the positions clos-est to the target word is considered more biasedthan a large number of high frequency wordsdistributed throughout the neighbour set.4.2 ResultsTable 4 shows the mean value of the biashighscore for every measure calculated over the setof high frequency nouns and over the set of lowfrequency nouns.
The standard deviations (notshown) all lie in the range [0,0.2].
Any deviationfrom 0.5 of greater than 0.0234 is significant atthe 1% level.For all measures and both sets of targetnouns, there appear to be strong tendencies toselect neighbours of particular frequencies.
Fur-ther, there appears to be three classes of mea-sures: those that select high frequency nounsas neighbours regardless of the frequency of thetarget noun (cm, js, ?, cp andR); those that se-lect low frequency nouns as neighbours regard-less of the frequency of the target noun (P); andthose that select nouns of a similar frequency tothe target noun (ja, ja+mi, lin and hm).This can also be considered in terms of distri-butional generality.
By definition, recall preferswords that have occurred in more of the con-texts that the target noun has, regardless ofwhether it occurs in other contexts as well i.e.,it prefers distributionally more general words.The probability of this being the case increasesas the frequency of the potential neighbour in-creases and so, recall tends to select high fre-quency words.
In contrast, precision preferswords that have occurred in very few contextsthat the target word has not i.e., it prefers dis-tributionally more specific words.
The prob-ability of this being the case increases as thefrequency of the potential neighbour decreasesand so, precision tends to select low frequencywords.
The harmonic mean of precision and re-call prefers words that have both high precisionand high recall.
The probability of this beingthe case is highest when the words are of sim-ilar frequency and so, the harmonic mean willtend to select words of a similar frequency.5 Relative frequency and hyponymyIn this section, we consider the observed fre-quency effects from a semantic perspective.The concept of distributional generality in-troduced in the previous section has parallelswith the linguistic relation of hyponymy, wherea hypernym is a semantically more general termand a hyponym is a semantically more specificterm.
For example, animal is an (indirect1) hy-pernym of dog and conversely dog is an (indi-rect) hyponym of animal.
Although one canobviously think of counter-examples, we wouldgenerally expect that the more specific term dogcan only be used in contexts where animal canbe used and that the more general term animalmight be used in all of the contexts where dogis used and possibly others.
Thus, we might ex-pect that distributional generality is correlatedwith semantic generality ?
a word has highrecall/low precision retrieval of its hyponyms?co-occurrences and high precision/low recall re-trieval of its hypernyms?
co-occurrences.Thus, if n1 and n2 are related and P(n2, n1) >R(n2, n1), we might expect that n2 is a hy-ponym of n1 and vice versa.
However, havingdiscussed a connection between frequency anddistributional generality, we might also expectto find that the frequency of the hypernymicterm is greater than that of the hyponymicterm.
In order to test these hypotheses, we ex-tracted all of the possible hyponym-hypernympairs (20, 415 pairs in total) from our list of 2000nouns (using WordNet 1.6).
We then calculatedthe proportion for which the direction of the hy-ponymy relation could be accurately predictedby the relative values of precision and recall andthe proportion for which the direction of the hy-ponymy relation could be accurately predictedby relative frequency.
We found that the direc-tion of the hyponymy relation is correlated inthe predicted direction with the precision-recall1There may be other concepts in the hypernym chainbetween dog and animal e.g.
carnivore and mammal.values in 71% of cases and correlated in the pre-dicted direction with relative frequency in 70%of cases.
This supports the idea of a three-waylinking between distributional generality, rela-tive frequency and semantic generality.
We nowconsider the impact that this has on a potentialapplication of distributional similarity methods.6 Compositionality of collocationsIn its most general sense, a collocation is a ha-bitual or lexicalised word combination.
How-ever, some collocations such as strong tea arecompositional, i.e., their meaning can be de-termined from their constituents, whereas oth-ers such as hot dog are not.
Both types areimportant in language generation since a sys-tem must choose between alternatives but onlynon-compositional ones are of interest in lan-guage understanding since only these colloca-tions need to be listed in the dictionary.Baldwin et al (2003) explore empiricalmodels of compositionality for noun-noun com-pounds and verb-particle constructions.
Basedon the observation (Haspelmath, 2002) thatcompositional collocations tend to be hyponymsof their head constituent, they propose a modelwhich considers the semantic similarity betweena collocation and its constituent words.McCarthy et al (2003) also investigate sev-eral tests for compositionality including one(simplexscore) based on the observation thatcompositional collocations tend to be similar inmeaning to their constituent parts.
They ex-tract co-occurrence data for 111 phrasal verbs(e.g.
rip off ) and their simplex constituents(e.g.
rip) from the BNC using RASP and cal-culate the value of simlin between each phrasalverb and its simplex constituent.
The testsimplexscore is used to rank the phrasal verbsaccording to their similarity with their simplexconstituent.
This ranking is correlated with hu-man judgements of the compositionality of thephrasal verbs using Spearman?s rank correlationcoefficient.
The value obtained (0.0525) is dis-appointing since it is not statistically significant(the probability of this value under the null hy-pothesis of ?no correlation?
is 0.3).2However, Haspelmath (2002) notes that acompositional collocation is not just similar toone of its constituents ?
it can be considered tobe a hyponym of its head constituent.
For ex-ample, ?strong tea?
is a type of ?tea?
and ?to2Other tests for compositionality investigated by Mc-Carthy et al (2003) do much better.Measure rs P (rs) under H0simlin 0.0525 0.2946precision -0.160 0.0475recall 0.219 0.0110harmonic mean 0.011 0.4562Table 5: Correlation with compositionality fordifferent similarity measuresrip up?
is a way of ?ripping?.Thus, we hypothesised that a distributionalmeasure which tends to select more generalterms as neighbours of the phrasal verb (e.g.
re-call) would do better than measures that tendto select more specific terms (e.g.
precision) ormeasures that tend to select terms of a similarspecificity (e.g simlin or the harmonic mean ofprecision and recall).Table 5 shows the results of using differentsimilarity measures with the simplexscore testand data of McCarthy et al (2003).
We now seesignificant correlation between compositionalityjudgements and distributional similarity of thephrasal verb and its head constituent.
The cor-relation using the recall measure is significantat the 5% level; thus we can conclude that ifthe simplex verb has high recall retrieval of thephrasal verb?s co-occurrences, then the phrasalis likely to be compositional.
The correlationscore using the precision measure is negativesince we would not expect the simplex verb tobe a hyponym of the phrasal verb and thus, ifthe simplex verb does have high precision re-trieval of the phrasal verb?s co-occurrences, it isless likely to be compositional.Finally, we obtained a very similar result(0.217) by ranking phrasals according to theirinverse relative frequency with their simplexconstituent (i.e., freq(simplex)freq(phrasal) ).
Thus, it wouldseem that the three-way connection betweendistributional generality, hyponymy and rela-tive frequency exists for verbs as well as nouns.7 Conclusions and further workWe have presented an analysis of a set of dis-tributional similarity measures.
We have seenthat there is a large amount of variation in theneighbours selected by different measures andtherefore the choice of measure in a given appli-cation is likely to be important.We also identified one of the major axes ofvariation in neighbour sets as being the fre-quency of the neighbours selected relative to thefrequency of the target word.
There are threemajor classes of distributional similarity mea-sures which can be characterised as 1) higherfrequency selecting or high recall measures; 2)lower frequency selecting or high precision mea-sures; and 3) similar frequency selecting or highprecision and recall measures.A word tends to have high recall similaritywith its hyponyms and high precision similaritywith its hypernyms.
Further, in the majority ofcases, it tends to be more frequent than its hy-ponyms and less frequent than its hypernyms.Thus, there would seem to a three way corre-lation between word frequency, distributionalgenerality and semantic generality.We have considered the impact of these ob-servations on a technique which uses a distribu-tional similarity measure to determine composi-tionality of collocations.
We saw that in this ap-plication we achieve significantly better resultsusing a measure that tends to select higher fre-quency words as neighbours rather than a mea-sure that tends to select neighbours of a similarfrequency to the target word.There are a variety of ways in which this workmight be extended.
First, we could use the ob-servations about distributional generality andrelative frequency to aid the process of organ-ising distributionally similar words into hierar-chies.
Second, we could consider the impact offrequency characteristics in other applications.Third, for the general application of distribu-tional similarity measures, it would be usefulto find other characteristics by which distribu-tional similarity measures might be classified.AcknowledgementsThis work was funded by a UK EPSRC stu-dentship to the first author, UK EPSRC projectGR/S26408/01 (NatHab) and UK EPSRCproject GR/N36494/01 (RASP).
We would liketo thank Adam Kilgarriff and Bill Keller for use-ful discussions.ReferencesTimothy Baldwin, Colin Bannard, Takaaki Tanaka,and Dominic Widdows.
2003.
An empirical modelof multiword expression decomposability.
In Pro-ceedings of the ACL-2003 Workshop on MultiwordExpressions, pages 89?96, Sapporo, Japan.Edward Briscoe and John Carroll.
2002.
Robust ac-curate statistical annotation of general text.
InProceedings of LREC-2002, pages 1499?1504.P.F.
Brown, V.J.
DellaPietra, P.V deSouza, J.C. Lai,and R.L.
Mercer.
1992.
Class-based n-gram mod-els of natural language.
Computational Linguis-tics, 18(4):467?479.Sharon Caraballo.
1999.
Automatic construction ofa hypernym-labelled noun hierarchy from text.
InProceedings of ACL-99, pages 120?126.T.M.
Cover and J.A.
Thomas.
1991.
Elements ofInformation Theory.
Wiley, New York.James R. Curran and Marc Moens.
2002.
Im-provements in automatic thesaurus extraction.
InACL-SIGLEX Workshop on Unsupervised LexicalAcquisition, Philadelphia.Ido Dagan, Lillian Lee, and Fernando Pereira.
1999.Similarity-based models of word cooccurrenceprobabilities.
Machine Learning Journal, 34.Christiane Fellbaum, editor.
1998.
WordNet: AnElectronic Lexical Database.
MIT Press.W.B.
Frakes and R. Baeza-Yates, editors.
1992.
In-formation Retrieval, Data Structures and Algo-rithms.
Prentice Hall.Gregory Grefenstette.
1994.
Corpus-derived first-,second- and third-order word affinities.
In Pro-ceedings of Euralex, pages 279?290, Amsterdam.Zelig S. Harris.
1968.
Mathematical Structures ofLanguage.
Wiley, New York.Martin Haspelmath.
2002.
Understanding Morphol-ogy.
Arnold Publishers.Lillian Lee.
1999.
Measures of distributional simi-larity.
In Proceedings of ACL-1999, pages 23?32.Lillian Lee.
2001.
On the effectiveness of the skewdivergence for statistical language analysis.
Arti-ficial Intelligence and Statistics, pages 65?72.Dekang Lin, Shaojun Zhao, Lijuan Qin, and MingZhou.
2003.
Identifying synonyms among dis-tributionally similar words.
In Proceedings ofIJCAI-03, pages 1492?1493.Dekang Lin.
1998.
Automatic retrieval and cluster-ing of similar words.
In Proceedings of COLING-ACL ?98, pages 768?774, Montreal.Diana McCarthy, Bill Keller, and John Carroll.2003.
Detecting a continuum of compositionalityin phrasal verbs.
In Proceedings of the ACL-2003Workshop on Multiword Expressions, pages 73?80, Sapporo, Japan.C.
Radhakrishna Rao.
1983.
Diversity: Its measure-ment, decomposition, apportionment and analy-sis.
Sankyha: The Indian Journal of Statistics,44(A):1?22.G.
Salton and M.J. McGill.
1983.
Introduction toModern Information Retrieval.
McGraw-Hill.K.M.
Sugawara, K. Nishimura, K. Toshioka,M.
Okachi, and T. Kaneko.
1985.
Isolated wordrecognition using hidden markov models.
In Pro-ceedings of the ICASSP-1985, pages 1?4.C.J.
van Rijsbergen.
1979.
Information Retrieval.Butterworths, second edition.Julie Weeds and David Weir.
2003.
A general frame-work for distributional similarity.
In Proceedingsof EMNLP-2003, pages 81?88, Sapporo, Japan.Julie Weeds.
2003.
Measures and Applications ofLexical Distributional Similarity.
Ph.D. thesis,Department of Informatics, University of Sussex.
