EBERHARD PAUSEA CLASS OF TRANSFOKMATIONALRECOGNIT ION GRAMMARS1.
PETmCK considers transformational grammars (T-grammars) ofa special* form which essentially have the properties described by N.CHOMSKY (1965).a) The base grammar is context-free.
One recursive element Sis distinguished.
The base trees in general have the formssor in linear notationConsequently each base tree consists of  a finite set of  subtrees or ker-nel trees each of the form S(@ $1(...)@) where x is a str ing Overi I shall assume the reader somewhat familiar with the theory of generative trans-formational grammar.
: -:46 EBERHARD PAUSEV -{@}.~ A string in which maximally n kernel trees stand one abovethe other has the depth (of embedding) n.b) Transformational rules (T-rules) are singulary or binary.
Thesingulary ones operate on a subtree, called constituent tree, whoseinitial node has the label St and whose terminal string contains nosentence boundary symbol @.
The binary T-rules work on a constit-uent tree and the kernel tree (called the matrix tree) which dominatesit directly.c) The transformational rules are linearly ordered and are ap-plied cyclically in this order from bottom to top.
That is, a cycle iscompleted after the singulary and binary rules have been applied toa constituent tree.
(In the process the sentence boundary symbols ofthis subtree are removed).Now Petrick defines a class of T-grammars generating recursive lan-guages by first stating the condition of the "recoverability of dele-tions ".
That is, only ?
terminal node or a subtree which is identicalwith another subtree that remains in the resulting tree after the appli-cation of the T-rule can be deleted.
He states further conditions o thatthere is an upper bound for the depth of embedding of a base treeunderlying a sentence of the grammar.
In his case that means, thata base tree that underlies a sentence of length n can have maximallydepth n.A recognition grammar for a T-grammar of this class is constructedby Petrick roughly in the following way: Transformational derivationsare generated, and starting with the trees that constitute these deri-vations he determines context-free rules, so-called "auxiliary rules ",reflecting the structure of the derived trees.
By means of these auxiliaryrules a given string can be attributed as much structure as is necessaryfor applying the "inverse " T-rules.
If the string is a sentence of thegiven grammar one can obtain the underlying base tree(s) by thisprocedure.2.
The following problems arise in connection with the class oftransformational grammars defined by Petrick:a) To my knowledge there is no finite procedure to determinewhether a given T-grammar has the defining properties of the classor not, which represents a solution to the problem whether there existsV means the entire vocabulary, Y~ the terminal, ~ the nonterminal vocabulary ofthe base.A CLASS OF TRANSFORMATIONAL RECOGNITION GRAMMARS 47in principle some recognition procedure for the grammar.
There alsoremains the question of whether this problem is recursively solvableat all.b) In general there is no finite number of auxiliary rules impliedby the derivations of a T-grammar of this form.
For that reason Pe-trick can only construct auxiliary rules for finitely many derivations.These rules can then be used only for the analysis of sentences whoseunderlying base trees have maximally depth n (for a given n)whoselength is therefore smaller than or equal to n. For sentences contain-ing more than n words a new recognition grammar has to be construc-ted.
There may also be sentences of length smaller than or equal ton which cannot even be analysed because the depth of their under-lying base trees exceeds the specified boundary.c) The set of trees accepted by the auxiliary rules is larger thanthe one generated by the original grammar.
As a consequence spurioustrees result at the end of the analysis process and these mustbe discard-ed by an additional synthesis phase.These problems uggest hat it might be reasonable to look at thefollowing requirements when using a grammar for the recognition ofsentences.
It should belong to a (nontrivial) class of grammar havingthe following properties:a) All generated languages are recursive.b) It is decidable whether a given grammar belongs to the classor  not .c) There should be a general procedure which costructs for eachgrammar of this type a practicable recognition grammar.
That is,analysis with such a grammar should be as efficient as possible.I do not wish to claim that these requirements have all been met forthe type of grammar that I worked with.
8 But I want to show nowwhat results I obtained with a different approach to the matter andwhat difficulties one obviously faces when dealing with transform-ational recognition.3.
In what follows I will first of all illustrate a general method bywhich the set of base trees, given by some arbitrary context-free gram-mar can be decomposed into a finite set of kernel trees.
This construc-tion serves (in section 4) as a basis for the definition of a class of T-grammars that generate recursive languages.
A hierarchy of types of3 For details ee my dissertation (E. PAUSE, 1972).48 EBERHARD PAUSEgrammar will be characterized, included in this class, such that for eachtype membership of a given grammar is decidable.
Section 5 dealswith recognition grammars.The whole matter is discussed with respect o T-grammars of ageneralized form:a) Every context-free grammar can serve as base grammar.b) Transformational rules are unordered.
There is no distinctionbetween singulary and binary rules.
4We may assume that a context-free grammar P-~ (V, Y,, R, S)where V-lg = ~, the sentence symbol S in ~, is reduced and has astandard form.
s That is, R contains only rules of the form(I) S ~ ~,(II) A ~ D1 ... D,, n _> 2, A in ~, D~ in l ~ - {S},otherwise,if S ~ ~.is in R e(III) A ~ a, a in \]g.There is no loss of generality on considering only context-freegrammars of this form since for every context-free grammar an equiv-alent standard form grammar could effectively be given.A recursion sequence (of length k) of a standard form context-freegrammar P is defined as a sequence of rules from RAo ~ uxAxvxA1 ~ u~A2v~Ak.1 -~ u,Akv,where A~ is in ~.
u,, v, in V*, v Ao = A,  and A~ :~ A i (for i ?
: j) other-wise.
Each symbol A i occuring in the sequence is a recursive lementin P. Since there are only finitely many elements in ?
every recursion4 In E. PAUSE (1972) I also investigate T-grammars that c?ntain generalized transfor-mations of roughly the same form as discussed by N. CHOMSK'Y (1957).
Concerning theform of the T-rules I refer the reader to the sample grammar in section 4.For details ee for instance S. GrNSBURG (1966).e ~.
denotes the empty string.V* denotes the free semigroup (generated by V).Itf~A CLASS OF TRANSFORMATIONAL RECOGNITION GRAMMARS ~ 49/sequence of P can maximally have length m ~-/O/s and since!
R isa finite set, the number of recursion sequences of P is finite.
:Two recursion sequences are equivalent if they could be ideni~ifiedby cyclical permutation of the rules.
This leads to the concept o~: theequivalence class or recursion cycle of a recursion sequence.
Exactlyk recursion sequence of length k which could be transformed into oneanother: constitute a recursion cycle.
Therefore each recursion cycle isuniquely determined by specifying one recursion sequence belongingto it.Now all recursion cycles of a standard form context-free grammarP = (V, ~g, R, S), where t =/0 / ,  could be enumerated in the followingway: Let us consider all sequences of rules from R of the forms= Ao u,AI,,ri~ : A1 -> u2A~v~r~,: Ak~l --> ukX, v,where r~, is in R, A s in ?
and Aj ~ A,~ (for-j ~ m), then after maxi-mally k _~ t steps eithera) X, is in ~g orb) X, is equal to Aj for some j smaller than k.In case (b) the sequence of rules rii ..... ri,, noted as above, obviouslyrepresents some recursion sequence of P. Clearly, there are only finite-ly many sequences as given above in P and it is easy to see that in allthese sequences (which correspond in some sense to all derivations inP of length smaller than or equal to t) there is to be found at least onerepresentative of each recursion cycle of P.Now equivalent recursion sequences are identified until there re--mains exacdy one representative for each cycle.
Furthermore, onearbitrary recursive lement of each recursion cycle is chosen.
Let {C1,.... Cs} be the set of these symbols each of which is called a base symbolof P together with the sentence symbol S. Then consider all occurencesof base symbols on the right hand side of the rules of P as terminalelements which could not further be expanded by some rule.
Constructs /~/denotes  the cardinality of ~.,tk50 t EBERI-IARD PAUSE }taeriv~tion trees by taking the set Z = {G .....  C,} u {S) as start sym-bols: you will obtain a finite set of trees B with terminal string eitherin ~,~" or in {Ig u Z}* having the following properties:a) every base tree corresponding to some sentence derivationin :P can be uniquely decomposed into elements of B (in the obviousman.ner).b) If elements of B are embedded into one another by identifyingeach time some initial node with some terminal node having as labelthe same base symbol the resulting tree is always a subtree of a treeass?,ciated with some sentence derivation in P.Hence the elements of B are kernel trees in almost he same senseas are those occuring in base trees considered by Petrick.
I will notgive here a proof of my main statements but will illustrate them byan example.Let P = (V, Z, R, S) where Ig ~- ( a, d, f, i, j, n, v, x, y },=(C ,  D, E, F, F', H, L J, K, M, N, Q}, andR ={S~CF 'E I ,  F '~XY,  C~MJ ,  M~KI - t ,K~DF,  H~QH, Q-~- AF, H~ NF, A ~ a ,D~ d, F ~ f,  E ~v, I~  i , J~ j ,  N~ n, X~ x, Y~ y}.Taken P as base grammar the base trees in general have the formsc ~M - -  ~u iY\ ?\ &Y \  \ \!
i \ [d f a f .
.
.
a f ,, f .I x \]' v iNow all rule sequences of length smaller than or equal to 12 = \[~\[,(of the form (~_)), starting with the sentence symbol S areA CLASS OF TRANSFORMATIONAL RECOGNITION GRAMMARS 51(1) S :-.
CF 'E I  (2) S --+ CF 'E I  (3) S ---'.
CF 'E IC -+MJ  C -+MJ  C -+MJM ~ KH M ~ KH " M ~ KHK ~ DF  H --> QH H ~ NFD ~ d(or F -+f )  N ~ n(or F ~ f(4) S --> CF 'E I  (5) S -+ CF 'E I  (6) S -+ CF 'E IC ~ MJ  F ' -+ XY  E ~ v(or I ~ i)J ~ j  X~x(or  Y~y)It can be immediately observed that there is only one recursion sequence;namely the rule H ~ QH in (2) which represents imultaneously theonly recursion cycle of P. Now { H, S } is taken as the set of base sym-bols of P. Further following the given construction finally the kerneltrees (a), (b), (c) result:(a) S(C(M(K(D(d)F ( f ) )H) J ( j ) )F ' (X (x )Y (y ) )E (v ) I ( i ) )(b) H(Q(A(a)F ( f ) )H)  "(c) H(N(n)F ( f ) )It is easy to see that for instance taking the embedding sequenceH/q .
.
.
"A F Q Ht t /Xa )A  Fi I,, fthere is a tree associated with some sentence generation in P such thatthe sequence is a subtree of it.
From the construction equally followsthat each base tree can be decomposed into elements of B in the oppo-site manner as contructing trees using the members of B.Since there are three kernel trees in ~ embedded into one anotherwe speak in exactly the same sense as above of the depth of a tree.Thus 0~ has depth 3.
In the following we will also call every tree builtup only of kernel trees a complex.52 ~B~ vAus~4.
In this section, I will first deal with some relevant implicationsof the foregoing construction and introduce the required terminology.Suppose, some T-rule ,r of a T-grammar G is applied to a base tree 0~:Let ~ be the resulting tree.
Then ~ can also be decomposed intokernel trees, taking as cutting-points again those nodes labeled withbase symbols.
Some of the resulting kernel trees will perhaps have beendeleted or will have been modified by the application of'r.
In the lat-ter case we get derived kernel trees.
In any case, each tree that couldbe generated in G can be decomposed into (base or derived) kerneltrees.
I will call the set of all those kernel trees, thus obtained of alltrees occuring in the derivations of G, the decomposition set B* of G.Suppose further that there are k terms in the structural descriptionof-: which have been related to k nodes of 0~.
Now the sequence of alland only those kernel trees (from left to right) in which these nodeslie will be called the characteristic domain of'r.The complex which is the smallest subtree of 0c such that it containsexactly the nodes, characterized by % (see the dashed line)is said tobe a minimal complex of-~ (rel:/tive to 0t).Obviously only the minimal complex of a T-rule (relative to sometree) is relevant for the observation of the structural change producedby the rule, because all structure beyond it (above and below in thetree) is not directly concerned.
To examine certain properties of trans-formational derivations, it could therefore be sufficient to constructderivations consisting of such complexes rather than of the whole trees.This can be done nearly in the following way:a) Relative to all T-rules of G, at first all possible minimal com-plexes of depth 1 are built up of the elements of B.
The set of kerneltrees, obtained after the decomposition of the complexes resulting fromA CLASS OF TRANSFORMATIONAL RECOGNITION GRAMMARS 53the application of the rules, yields together with set B set B1,1.
Thisprocedure can be repeated for minimal complexes over B of depth2, 3, ... which gives the sets Bz,1, B3,,, ...b) Now continuations of the foregoing derivations (of length1) could be constructed taking as basis each time the correspondingset Bi,z, Bi, z .
.
.
.
According to the resulting derivations of length 2,3, ... the sets B1,2, B1,3, ..., B~,z, B~,3 .... of kernel trees will be obtained.By this procedure, which I cannot describe in detail here, the de-composition set B* of G can be enumerated as the union set of thesets Bp, q (p, q > 1).For our purposes, it is relevant o consider what happens with somekernel tree y or some node of a tree in the course of a derivation: per-forming some transformation, y is either deleted or there are somederived kernel trees (at least one) in the resulting tree which are theimages of y, either identical or modified by the rule.
Again the asso-ciated images of these in the following derived tree (which are alsoimages of y) could be identified, and so on.
This procedure could becarried out along the whole derivation starting with an element ofB, called the origin, in the base tree.
The same is valid for a node in atree.
It is either deleted or copied or only transferred by applying aT-rule, where in the latter cases it has some images (at least one) inthe resulting tree 13 called the occurrences of the node in 13.Now let us consider some derivation in G. It starts with a basetree ~, and we are looking at some kernel tree y that is a subtree of 0c,and some derived tree 13 occurring in the derivation:a) All occurrences of terminal nodes of y in 13, labeled withterminal elements, Or occurrences of nodes in 13, inserted in y or animage of it by T-rules introducing new terminals (or morphemes),are called the rest-nodes of y in ~.b) Each terminal node of y labeled with a base symbol is calleda base-node, and all occurrences of such nodes of y in 13 are said to bebase-nodes of y in 13.After these remarks we are ready to outline the class of structurallybounded T-grammars.
For a grammar G to be structurally bounded inparticular the following conditions must hold:a) The condition of recoverability of deletions.b) If a rest-node of some kernel tree.~ in the characteristic do-main of a T-rule $ relative to a tree 13 is deleted, the number of rest-no-des of 0~ in 13 must be greater than 1.c) If a subtree y is deleted by performing "~, then each base-node$4 EBERHARD PAUSEoccurring in % and lying in some kernel tree of ~, may be an occur-rence or a base-node of the origin of y.d) Let the number of terminal nodes of the origin of a kerneltree occurring in the characteristic domain of ": be m. Then this sub-tree, following its changes under the rules up to ~ by considering its"trace" along its images in the given derivation, may not have occur-red more than m-1 times in the characteristic domain of-r.For this class of grammars, say G1, the following theorem can beproved:(A) If G is structurally bounded, then the length of each sentencederived from some base tree ~ of depth n cannot be shorter than n,nthe member of kernel trees contained in 0~ could maximally be ~; k ~-1i=l(where k is a constant depending on G).Suppose G is structurally bounded, and m is the maximum of sub-trees which could be deleted on account of their identity by one T-rule of G. Lei.j be the number ofT-rules of G, and r the length of thelongest erminal string of members in the set B of G, then let j.m.r = k.n ~--- 1: If0~ is a base tree of depth 1, then every tree ~ that could bederived from 0c may contain a rest-node of e. Thus the length of theterminal string of ~ is greater than or equal to n = 1, and the numberof kernel trees in ~ is 1 = ~k ~-~.Now suppose (A) is true for all trees of depth h smaller than n (hgreater than 1).Let ~ be a base tree of depth n. Without loss of generality, we mayassume that 0~ has the form,where ~ is some kernel~tree, Y1, ..-, ~'~ subtrees maximally of depthn-l, and let us further assume that s does not exceed k. Then k-1 of thesesubtrees could be deleted maximally.
Some rest node of ~ in a tree\[~ derived from 0~ must also survive.
From this and by induction itA CLASS OF TRANSFORMATIONAL RECOGNITION GRAMMARS 55follows that the length of the terminal string of \[3 must be greater orequal to n-1 + 1 = n. Hence the number of kernel trees in ~ has asmaximum value k. (~ k iq) + 1 = 2f k iq.i=1 i= lObviously a decision procedure for the language generated by somegrammar of G1 could be given.
However, it can be proved that thereis no recursive solution to the problem whether in general a given gram-mar belongs to G1 or not.In the sequel I shall go on to sketch some properties of grammarsin G1 for which this problem is decidable.In considering the construc.tion of the decomposition set B* of agiven T-grammar G and of the corresponding derivations of complexes(see page 52 and 53), there might exist some point where the followingrequirements are fulfilled:Suppose that all derivations tarting with complexes up to acertain depth p have been constructed, that the length of these deriva-tions has as yet reached some q, and that they are "structurally bound-ed ".
Suppose further that by continuing the construction for some p'greater than p no new derivation (beginning with complexes over/3)could be started.
Then G is structurally bounded and is said to be inclass Gp,~, if the given derivations become periodical.
That is, if theyhave the same continuations in the q + 1-th step as in the q -  n + 1-thstep (for some n), in the q + 2-th step as in the q -n  + 2-th step, ...,in step q + n as in step q, and so on.
This in particular means, that atthose points in the derivations always the same minimal complexesappear periodically, and that therefore the decomposition set B* ofG is finite.
9Since there are grammars for which these properties hold forarbitrary _p and q, there exists an infinite hierarchy G2 of types ofgrammars Gp, q (p, q >1) in G1.
For each p and q obviously membershipof a given grammar in Gp,q could be determined in a finite numberof "steps.The following example should help in understanding these briefremarks:Let G be a T-grammar with base given by the ab0ve-mention-ed context-free grammar P, and let G contain the following oblig-atory T-rules:There is great evidence in the assumption that every <~ kernel sentence * of a sen-tence of a natural anguage can undergo only a finite number of transformations.V56 EBILRHAI~D PAUSEr l :  (~, y, v, i) 1, 2, 3 -+ 3, 2, 01?
"r2: (~, j, x, i, v) 1, 2, 3, 4 -+ 0,1, 3, 4%: (K,H,F',v) 1,2,3,4-+ l+3,2 ,0 ,4"r4: (d,f, F', ~e)1, 2, 3 , -+ 1 ,3 ,3 ,"rs: (~, F', F', n,f, ~)1,  2, 3, 4, -+ l, 0, 3, 2"re: (M,F',F', Q, H, ~)  1, 2, 3, 4, ~ 1 ,3 ,3 ,"rT: (M, a,f, F ' ,~)  1, 2, 3 -+ 1,3 ,3Now the following derivations could be constructed:~) o~ = S(C(M(K(D(d)F(f))H)J(j))F',(X(x)Y(y))E(v)I(i))~ S(C(M(K(D(d)F(f))H)J(j))F (X(x)Y(O)E(v)) S(C(M(K(D(d)V(f!
)n))F (X(j)Y(i))E(v))(~  o~,o~5 S(C(M(K(D(d)F (X(f)Y(i))H)))E(v))_~ = S(C(M(K(D(d)F(F'(X(j)Y(i))))F'(X(j)Y(i))H)E(V))y~___>t ?
:: -~ S(C(M(yIF'(X(j)Y(i))H(N(n)F(f))))E(v))== S(C(M(y~H(N(n)F(F' (X(j)Y(i))))))E(v))I~ t ~s = S(C(M(y~F' (X(j)Y(i))H(Q(A(a)F(I))H)))E(v))(~  = S(C(M(y~H(Q(A(a)F(f))F (X(j)Y(i))H)))E(v))--t ~) ~o = S(C(M(y~H(Q(A(a)F(F'(X(j)Y(i))))F(X(j)Y(i))H)))E(v))Y~--~l ~1~ = H(y2F'(X(j)Y(i))H(N(n)F(f)))?
~ = H(y~H(N(n)F'(X(j)Y(i)))))I ~3 = H(y2F'(X(j)Y(i))H(Q(A(a)F(f))H))(~)o~4 = H(y~H(Q(A(a)F(f))F'(X~j)Y(i))H))Q) o~S-- H(y~H(Q(A(a)F(F'(X~)Y(i))))F'(X(j)Y(i))H))There is no difficulty in verifying that the continuations which couldfollow always start with the minimal complexes ~u and ~18.
G is ob-viously structurally bounded and lies in G2,6.
The following graphrepresenting the order in the possible applications of the T-rules ofG makes perhaps the periodicity of the derivations more transparent:10 The symbol Af means almost the same as variables like X in the usual notation ofT-rules.n (~) means that he T-rule i is applied to the foregoing tree.
The arrow \['-~ denotessome continuation f the derivation where it leads out.A CLASS OF TRANSFORMATIONAL RECOGNITION GRAMMARS 5751------~ 2----> 3 "--"~ 4 /  5~ '~6- - - - .
.
-~  7.J__~ ~ /56 - " - -~  7 - ~  65.
As indicated above, there is a recognition grammar for eachgrammar G of the class G m, namely G itself, using the general deci-sion procedure for the language generated by G. This is, however,obviously not an efficient procedure but represents some general wayof analysis by synthesis.I will now sketch a way of constructing recognition grammars forthe class of grammars considered here which in most cases are morepracticable.
This will mainly be done by examining our sample grammar.I will finish with the discussion of some problems involved in thedescribed procedure.Let us consider the T-grammar G given above: Analysis shouldstart with some given string over V, say "d  j i n j i v ".
Now by re-versing the generation process, the last transformation that has beenapplied in generating this sentence, "rs: (~, F', F', n, f ~) 1, 2, 3, 4 --+ 1,0, 3, 2, has now to be performed first.
The inverse transformation":5 -1 (which can mechanically be constructed from ~5) would have thestructural description (M, F', n, F', ~,1).
However, there are no rulesto attribute some structure to the given string such that there werenodes labeled with F which could be related to the corresponding termsin this inverse structural description.
Base rules cannot do this workbecause the base structure has been modified by the applicafon ofT-rules.Now by inspecting the derivations of complexes a term A of astructural description, could be ' expanded' in this way: the sequenceof labels of the nodes which are dominated by a node related to A,such that the string of these labels is accepted by the inverse base rules, 1~is substituted for A in ..
This will be done, if possible (see below) andnecessary, for each term and each T-rule relative to the different reesto which it has been applied in all derivations.
In general, for each T-rule more than one 'expanded' rule results.,s For each base rule of the form A-+ x, the rule x-~ A is the inverse.58 ~B~.m~D I'AUS~.Since there are only finitely many different derived (minimal)complexes in the derivations of a grammar G of Gp,q, one obtains agrammar G' (called reversible) containing a finite set of expandedT-rules.
G' is by construction equivalent to G. A recognition grammarG is obtained from G' by computing the corresponding inverse T-rules.
Then analysis will be performed by 'intermixed parsing ', thatis, by alternating the application of base rules and T-rules.
~3In order to prevent he expanded T-rules being applicable at somepoint in a derivation, where the original rules could not have beenapplied, auxiliary symbols are inserted in the rules to control theircorrect application.To illustrate these remarks, let us look at the expanded inverseT-rules of our sample grammar G:?
i1: (~, i, v) 1, 2-+y, 2+1.r~: (~, j  d3,~, i, ~)) 1, 2, 3, 4-+1, x, 3, 4.r~: (K,j,d,,~,i,H,v) l,...,6-+ l, 0, O,O, 5 ,2+d3,x+4+6"r\]~: (d,j, dsi, i,j, d52, i, ~) t -~" (d, j ,d~,i , j ,c\[6~,i ,~) t 1 ..... 7~ 1,0, O,f, 5, d4x, 7~742 ?
, ,-~: (~, j ,  i, n, j ,  i, ~) 1, 2, 3, 4, 5~1,  d5,1+2, 4+ d5,2++5+3,  o,f"ra~: (~, j , i ,Q , j ,  dT,~,i,H,~)l .... ,7 ~ 1, de.1 + 2, 4 + d6,~ ++6+3,0 ,0 ,0 ,7-~.
(?~,a,j, ds,x,i,j, ds,2, i ,~) l "rT"~i (?~,a,j, d6,~,i,j, de,~,i,?~) 1, ..., 7---~1, O,O,f, 5, d~x, 7~'72  ?The construction should be clear in considering the original rules andthe derivations given above.
The symbols d~,,~ denote auxiliary symbols.For the rules % and "rv two expanded rules have been constructed be--cause "r4 and "r7 precede the application of either the rule "r6 or xe.The recognition procedure will be illustrated by the analysis ofthe sample sentence " d j in j iv ".
Let t~ ~i, tt R denote the appliCationof the rule -r i or of the inverse base rules respectively.
Notice that theinverse T-rules are not true inverse rules, since they apply to sequencesof trees, so~alled "terminal rest-trees"x3 It can be shown that the set of context-semitive languages i properly included inthe set of languages generated by grammars of G,.
Furthermore, for each context-sensi-tive grammar a reversible T-grammar can effectively be given.A CLASS OF TRANSFORMATIONAL RECOGNITION GRAMMARSdj  i n j  i vd j ds,1 i j d~,2 i n f vdf j  d4,~ i n fvD FI Id f j d,,~HN FI Ii n fvK H (Y(",:d f , ,  .
f jg~.~ivD FN FI I I  Id f n f j x iv/ \  / \d f n .
/ ' j xvv iS/ \  / \  ~ / \  K I D F N F l X ' Y I \[D I I I I. I I I Id.
f n f j x y v i5960 EBERHARD PAUSEIn addition the following condition is important: the final derivedtree of the input string (with respect o the generation process) couldbe reconstructed in the course of the analysis process.
It must then bechecked if some obligatory T-rule of G' is applicable to this tree.
Ifthis is not the case, the input string is a sentence of the grammar.The problems which arise out of the foregoing construction arethe following:a) There are cases in which no reversible grammar G' for a givengrammar G could be constructed, because, for instance, some auxiliarysymbol could not be removed in the course of a sentence derivation.b) Another source of not obtaining a reversible grammar is,that there could occur subtrees of arbitrary depth which have to beconsidered for the exp=msion of some .term in a structural description.In this case a partially reversible grammar could be constructed.
Therecognition grammar then works with base rules, T-rules, and so-called"predictions " associated to the T-rules.
14 Analysis with these grammarswill without doubt be much less efficient.The advantage in using reversible grammars appears to bea) that there is no additional synthesis phase necessary when theanalysis tep has been carried out,b) that the different possible paths which must be pursued inparsing a sentence could be reduced to a minimum, in using auxiliarysymbols whenever it is possible,c) and that the recognition grammar could effectively be given'for the whole set of generated sentences.
1514 See my dissertation (E. PAusE, 1972).15 At page 54, Theorem (A), the number k must correctly be taken as themaximum number of base symbols occurring in a kernel tree of the set B.REFERENCESN.
CHOMSKY, Syntactic Structures, TheHague, 1957.N.
CHOMSKY, Aspects of the Theory ofSyntax, Cambridge (Mass.
), 1965.S.
GINsBuaC, The mathematical Theoryof Context-Free Languages, New York,1966.S.
GINSBt~G, B. P.~a~TEE, A mathematicalmodel of transformational grammars, in<~ Information and Control ,, XV(1969), pp.
297-334.A.
KRATZER, E. PAUSE, A. g. STECHOW,Einfiihrung in Theorie und Anwendungder generativen Syntax, Frankfurt a.M., 1973.G.
H. MATTHEWS, Analysis by Synthesisin the Light of recent developments in thetheory of grammar, in <~ Kybemefica ~,I (1965), pp.
271-280.E.
PAUSE, Transformationssyntaxen, gen-erative Kraft-Entscheidbarkeit-Analyse,Diss., Konstanz, 1972.ST.
R.. PETRICK, A Recognition Procedurefor Transformational Grammars, Ph.D.Thesis, M.I.T., 1965.
