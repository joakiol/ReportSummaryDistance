MIMIC: An Adaptive Mixed Initiative Spoken Dialogue System forInformation QueriesJennifer Chu-CarrollLucent Technologies Bell Laboratories600 Mountain AvenueMurray Hill, NJ 07974, U.S.A.jencc @research.bell-labs.cornAbstractThis paper describes MIMIC, an adaptive mixed initia-tive spoken dialogue system that provides movie show-time information.
MIMIC improves upon previousdialogue systems in two respects.
First, it employsinitiative-oriented strategy adaptation to automaticallyadapt response generation strategies based on the cumu-lative effect of information dynamically extracted fromuser utterances during the dialogue.
Second, MIMIC'sdialogue management architecture decouples its initia-tive module from the goal and response strategy selec-tion processes, providing ageneral framework for devel-oping spoken dialogue systems with different adaptationbehavior.1 IntroductionIn recent years, speech and natural anguage technolo-gies have matured enough to enable the development ofspoken dialogue systems in limited domains.
Most ex-isting systems employ dialogue strategies pre-specifiedduring the design phase of the dialogue manager with-out taking into account characteristics of actual dialogueinteractions.
More specifically, mixed initiative systemstypically employ rules that specify conditions (generallybased on local dialogue context) under which initiativemay shift from one agent o the other.
Previous research,on the other hand, has shown that changes in initiativestrategies inhuman-human dialogues can be dynamicallymodeled in terms of characteristics of the user and ofthe on-going dialogue (Chu-Carroll and Brown, 1998)and that adaptability of initiative strategies in dialoguesystems leads to better system performance (Litman andPan, 1999).
However, no previous dialogue system takesinto account these dialogue characteristics or allows forinitiative-oriented adaptation of dialogue strategies.In this paper, we describe MIMIC, a voice-enabledtelephone-based dialogue system that provides movieshowtime information, emphasizing its dialogue man-agement aspects.
MIMIC improves upon previous ys-tems along two dimensions.
First, MIMIC automat-ically adapts dialogue strategies based on participantroles, characteristics of the current utterance, and dia-logue history.
This automatic adaptation allows appro-priate dialogue strategies to be employed based on bothlocal dialogue context and dialogue history, and has beenshown to result in significantly better performance thannon-adaptive systems.
Second, MIMIC employs an ini-tiative module that is decoupled from the goal selectionprocess in the dialogue manager, while allowing the out-come of both components ojointly determine the strate-gies chosen for response generation.
As a result, MIMICcan exhibit drastically different dialogue behavior withvery minor adjustments o parameters in the initiativemodule, allowing for rapid development and comparisonof experimental prototypes and resulting in general andportable dialogue systems.2 Adaptive Mixed Initiative DialogueManagement2.1 MotivationIn naturally occurring human-human dialogues, peakersoften adopt different dialogue strategies based on hearercharacteristics, dialogue history, etc.
For instance, thespeaker may provide more guidance if the hearer is hav-ing difficulty making progress toward task completion,while taking a more passive approach when the heareris an expert in the domain.
Our main goal is to enablea spoken dialogue system to simulate such human be-havior by dynamically adapting dialogue strategies dur-ing an interaction based on information that can be au-tomatically detected from the dialogue.
Figure 1 showsan excerpt from a dialogue between MIMIC and an ac-tual user where the user is attempting to find the timesat which the movie Analyze This playing at theaters inMontclair.
S and U indicate system and user utterances,respectively, and the italicized utterances are the outputof our automatic speech recognizer.
In addition, eachsystem turn is annotated with its task and dialogue ini-tiative holders, where task initiative tracks the lead in theprocess toward achieving the dialogue participants' do-main goal, while dialogue initiative models the lead indetermining the current discourse focus (Chu-Carroll andBrown, 1998).
In our information query application do-main, the system has task (and thus dialogue) initiative ifits utterances provide helpful guidance toward achievingthe user's domain goal, as in utterances (6) and (7) whereMIMIC provided valid response choices to its query in-tending to solicit a theater name, while the system has97dialogue but not task initiative if its utterances only spec-ify the current discourse goal, as in utterance (4).
iThis dialogue illustrates everal features of our adap-tive mixed initiative dialogue manager.
First, MIMIC au-tomatically adapted the initiative distribution based oninformation extracted from user utterances and dialoguehistory.
More specifically, MIMIC took over task initia-tive in utterance (6), after failing to obtain a valid an-swer to its query soliciting a missing theater name in (4).It retained task initiative until utterance (12), after theuser implicitly indicated her intention to take over taskinitiative by providing a fully-specified query (utterance(11)) to a limited prompt (utterance (10)).
Second, ini-tiative distribution may affect the strategies MIMIC se-lects to achieve its goals.
For instance, in the contextof soliciting missing information, when MIMIC did nothave task initiative, a simple information-seeking querywas generated (utterance (4)).
On the other hand, whenMIMIC had task initiative, additional guidance was pro-vided (in the form of valid response choices in utterance(6)), which helped the user successfully respond to thesystem's query.
In the context of prompting the user fora new query, when MIMIC had task initiative, a lim-ited prompt was selected to better constrain the user'sresponse (utterance (10)), while an open-ended promptwas generated to allow the user to take control of theproblem-solving process otherwise (utterances (1) and(13)).In the next section, we briefly review a framework fordynamic initiative modeling.
In Section 3, we discusshow this framework was incorporated into the dialoguemanagement component of a spoken dialogue system toallow for automatic adaptation of dialogue strategies.
Fi-nally, we outline experiments evaluating the resultingsystem and show that MIMIC's automatic adaptation ca-pabilities resulted in better system performance.2.2 An Evidential Framework for ModelingInitiativeIn previous work, we proposed a framework for mod-eling initiative during dialogue interaction (Chu-Carrolland Brown, 1998).
This framework predicts task and dia-logue initiative holders on a turn-by-turn basis in human-human dialogues based on participant roles (such as eachdialogue agent's level of expertise and the role that sheplays in the application domain), cues observed in thecurrent dialogue turn, and dialogue history.
More specif-ically, we utilize the Dempster-Shafer theory (Shafer,1976; Gordon and Shortliffe, 1984), and represent thecurrent initiative distribution as two basic probability as-signments (bpas) which indicate the amount of supportfor each dialogue participant having the task and dia-logue initiatives.
For instance, the bpa mt-cur({S}) =l Although the dialogues we collected in our experiments (Sec-tion 5) include cases in which MIMIC has neither initiative, such casesare rare in this application domain, and will not be discussed further inthis paper.0.3, mt-c~,r({U}) = 0.7 indicates that, with all evidencetaken into account, there is more support (to the degree0.7) for the user having task initiative in the current urnthan for the system.
At the end of each turn, the bpasare updated based on the effects that cues observed ur-ing that turn have on changing them, and the new bpasare used to predict he next task and dialogue initiativeholders.In this framework, cues that affect initiative distribu-tion include NoNewlnfo, triggered when the speaker sim-ply repeats or rephrases an earlier utterance, implicitlysuggesting that the speaker may want to give up initia-tive, AmbiguousActions, triggered when the speaker pro-poses an action that is ambiguous in the application do-main, potentially prompting the hearer to take over ini-tiative to resolve the detected ambiguity, etc.
The ef-fects that each cue has on changing the current bpasare also represented asbpas, which were determined byan iterative training procedure using a corpus of tran-scribed ialogues where each turn was annotated with thetask/dialogue initiative holders and the observed cues.The bpas for the next turn are computed by combiningthe bpas representing the current initiative distributionand the bpas representing the effects of cues observedduring the current urn, using Dempster's combinationrule (Gordon and Shortliffe, 1984).
The task and dia-logue initiative holders are then predicted based on thenew bpas.
This framework was evaluated using anno-tated dialogues from four task-oriented domains, achiev-ing, on average, a correct prediction rate of 97% and 88%for task and dialogue initiative holders, respectively.
InSection 3.2, we discuss how this predictive model is con-verted into a generative model by enabling the system toautomatically detect cues that were previously labelledmanually.
We further discuss how the model is usedby the dialogue manager for dynamic dialogue strategyadaptation.3 MIMIC :  M ixed  Init iative Mov ieIn fo rmat ion  Consu l tantMIMIC is a telephone-based dialogue system that pro-vides movie showtime information.
It consists of the fol-lowing main components, implemented on a distributed,client-server a chitecture (Zhou et al, 1997):1..Telephony server: this component detects ringsand hang-ups, and enables treaming of audio dataon channels of a telephony board.Speech recognizer: the recognizer receives audiodata from the telephony server and generates theword string hypothesis that best matches the audioinput.
We used the Lucent Automatic Speech Rec-ognizer (Reichl and Chou, 1998; Ortmanns et al,1999), configured to use class-based probabilistic n-gram language models to allow for rapid updates ofmovie/theater/town names._ql:l98Utterance(1) S: Hello, this is MIMIC, the movie information system.
(2) How can I help you?
(3) U: What time is Analyze This playing in Montclair?\[what time is analyze this playing in montclair\](4) S: What theater would you like?
User(5) U: Montclair.\[montclair\](6) S: Choices for theater are Wellmont Theater and Clearviews Screening Zone.
System(7) What theater would you like?
(8) U: Clearviews Screening Zone.\[urn movie screening zone\](9) S: Analyze This is playing at Clearviews Screening Zone in Montclair at l:15pm, 4:10pm, Systemand 6:30pm.
(10) Please say the name of the movie or theater or town you would like information about.
(11) U: What time is Analyze This playing at the Welimont Theater?\[what time is analyze this playing at the wellmont theater\](12) S: Analyze This is playing at Wellmont Theater in Montclair at 3:15pm, 5:45pm, 8:20pm, Userand lO:lOpm.
(13) Can I help you with anything else?TaskInitiativeUserDialogueInitiativeSystemSystemSystemSystemSystemFigure 1: Excerpt of an Adaptive Mixed Initiative Dialogue3.
NLP/Dialogue component: this main application-dependent component receives a user utterance hy-pothesis from the speech recognizer, and generatessystem utterance(s) in response.
Three major tasksare carried out by this component: 1) semantic in-terpretation, which constructs frame-based seman-tic representations from user utterances, 2)dialoguemanagement, where response strategies are selectedbased on the semantic representation f the user'sutterance, system's domain knowledge, and initia-tive distribution, and 3) utterance generation, whereutterance templates are chosen and instantiated torealize the selected response strategies.
These threetasks will be discussed in further detail in the rest ofthis section.4.
Text-to-speech engine: the TTS system receivesthe word string comprising the system's responsefrom the dialogue component and converts the textinto speech for output over the telephone.
We usedthe Bell Labs TTS system (Sproat, 1998), whichin addition to converting plain text into speech, ac-cepts text strings annotated to override default pitchheight, accent placement, speaking rate, etc.
23.1 Semantic InterpretationMIMIC utilizes a non-recursive frame-based semanticrepresentation commonly used in spoken dialogue sys-tems (e.g.
(Seneff et al, 1991; Lamel, 1998)), whichrepresents an utterance as a set of attribute-value pairs.Figure 2(a) shows the frame-based semantic representa-tion for the utterance "What time is Analyze This playing2 See (Nakatani and Chu-Carroll, 2000) for how MIMIC's dialogue-level knowledge is used to override default prosodic assignments forconcept-to-speech generation.Question-Type: WhenMovie: Analyze ThisTheater: nullTown: Montclair(a) Semantic RepresentationQuestion-Type: WhenMovie: mandatoryTheater: mandatoryTown: optional(b) Task SpecificationFigure 2: Semantic Representation a d Task Specifica-tionin Montclair?
"MIMIC's semantic representation is constructed byfirst extracting, for each attribute, a set of keywords fromthe user utterance.
Using a vector-based topic identifi-cation process (Salton, 1971; Chu-Carroll and Carpen-ter, 1999), these keywords are used to determine a setof likely values (including null) for that attribute.
Next,the utterance is interpreted with respect o the dialoguehistory and the system's domain knowledge.
This al-lows MIMIC to handle elliptical sentences and anaphoricreferences, as well as automatically infer missing valuesand detect inconsistencies in the current representation.This semantic representation allows for decouplingof domain-dependent task specifications and domain-99independent dialogue management s rategies.
Eachquery type is specified by a template indicating, for eachattribute, whether a value must, must not, or can option-ally be provided in order for a query to be consideredwell-formed.
Figure 2(b) shows that to solicit movieshowtime information (question type when), a moviename and a theater name must be provided, whereas atown may optionally be provided.
These specificationsare determined based on domain semantics, and must bereconstructed when porting the system to a new domain.3.2 Dialogue ManagementGiven a semantic representation, the dialogue history andthe system's domain knowledge, the dialogue managerselects a set of strategies that guides MIMIC's responsegeneration process.
This task is carried out by threesubprocesses: 1) initiative modeling, which determinesthe initiative distribution for the system's dialogue turn,2) goal selection, which identifies a goal that MIMIC'sresponse attempts to achieve, and 3) strategy selection,which chooses, based on the initiative distribution, a setof dialogue acts that MIMIC will adopt in its attempt torealize the selected goal.3.2.1 Initiative ModelingMIMIC's initiative module determines the task and di-alogue initiative holders for each system turn in orderto enable dynamic strategy adaptation.
It automaticallydetects cues triggered uring the current user turn, andcombines the effects of these cues with the current ini-tiative distribution to determine the initiative holders forthe system's turn.Cue Detection The cues and the bpas representingtheir effects are largely based on a subset of those de-scribed in (Chu-Carroll and Brown, 1998), 3 as shownin Figures 3(a) and 3(b).
Figure 3(a) shows that obser-vation of TakeOverTask supports a task initiative shiftto the speaker to the degree .35.
The remaining sup-port is assigned to O, the set of all possible conclusions(i.e., {speaker,hearer}), indicating that to the degree .65,observation of this cue does not commit to identifyingwhich dialogue participant should have task initiative inthe next dialogue turn.The cues used in MIMIC are classified into two cate-gories, discourse cues and analytical cues, based on thetypes of knowledge needed to detect hem:I. Discourse cues, which can be detected by consider-ing the semantic representation f the current utter-ance and dialogue history:?
TakeOverTask, an implicit indication that theuser wants to take control of the problem-solving process, triggered when the user pro-vides more information than the discourse x-pectation.3We selected only those cues that can be automatically detected ina spoken dialogue system with speech recognition errors and limitedsemantic interpretation capabilities.?
NoNewlnfo, an indication that the user is un-able to make progress toward task completion,triggered when the semantic representations oftwo consecutive user turns are identical (a re-sult of the user not knowing what to say or thespeech recognizer failing to recognize the userutterances).2.
Analytical cues, which can only be detected by tak-ing into account MIMIC's domain knowledge:?
lnvalidAction, an indication that the user madean invalid assumption about the domain, trig-gered when the system database lookup basedon the user's query returns null.?
lnvalidActionResolved, triggered when theprevious invalid assumption is corrected.?
AmbiguousAction, an indication that the userquery is not well-formed, triggered when amandatory attribute is unspecified or whenmore than one value is specified for an at-tribute.?
AmbiguousActionResolved, triggered when theattribute in question is uniquely instantiated.Computing Initiative Distribution To determine theinitiative distribution, the bpas representing the effectsof cues detected in the current user utterance are instan-tiated (i.e., speaker~hearer in Figure 3 are instantiated assystem~user accordingly).
These effects are then inter-preted with respect o the current initiative distributionby applying Dempster's combination rule (Gordon andShortliffe, 1984) to the bpas representing the current ini-tiative distribution and the instantiated bpas.
This resultsin two new bpas representing the task and dialogue initia-tive distributions for the system's turn.
The dialogue par-ticipant with the greater degree of support for having thetask/dialogue initiative in these bpas is the task/dialogueinitiative holder for the system's turn 4 (see Section 4 foran example).3.2.2 Goal SelectionThe goal selection module selects a goal that MIMIC at-tempts to achieve in its response by utilizing informa-tion from analytical cue detection as shown in Figure 4.MIMIC's goals focus on two aspects of cooperative di-alogue interaction: 1) initiating subdialogues to resolveanomalies that occur during the dialogue by attemptingto instantiate an unspecified attribute, constraining an at-tribute for which multiple values have been specified, orcorrecting an invalid assumption i  the case of invalid41n practice, this is the preferred initiative holder since practicalreasons may prevent the dialogue participant from actually holding theinitiative.
For instance, if having task initiative dictates inclusion ofadditional helpful information, this can only be realized if M1M1C'sknowledge base provides uch information.
"INN 100Cue ClassDiscourseAnalyticalCueTakeOverTaskNoNewlnfoInvalidActionlnvalidActionResolvedAmbiguousActionAmbiguousActionResolvedBPAmt-tot({speaker}) = 0.35; mr-tot(O) = 0.65mt-,~ni({hearer}) = 0.35; mt-nn~(O) = 0.65mt-i~({hearer}) = 0.35; mt- ia(O) = 0.65mt-iar({hearer}) = 0.35; mt- iar(O)  = 0.65mt-aa({hearer}) = 0.35; mt-a~(O) = 0.65mt .
.
.
.
({speaker}) = 0.35; mt .
.
.
.
(O) = 0.65(a)Task InitiativeCue ClassDiscourseAnalyticalCueTakeOverTaskNoNewlnfolnvalidActionInvalidActionResolvedAmbiguousActionAmbiguousActionResolvedBPAmd-tot({speaker}) = 0.35; ma-tot(O) = 0.65md-nni({hearer}) = 0.35; md-nni(O) -~- 0.65md-ia ({hearer}) = 0.7; md-ia (O) = 0.3ma-iar({hearer}) = 0.7; ma-iar(O) = 0.3ma-aa({hearer}) = 0.7; md_a~(O) = 0.3ma .
.
.
.
({speaker}) = 0.7; md .
.
.
.
(O) = 0.3(b)Dialogue InitiativeFigure 3: Cues and BPAs for Modeling Initiative in MIMICSeleet-Goal(SemRep):(1) IfAmbiguousAction detected(2) ambiguous-attr +--get-ambiguous(SemRep)/* get name of ambiguous attribute */(3) If (number-values(ambiguous-attr) == 0)/* attribute unspecified *,1(4) Instantiate(ambiguous-attr)(5) Else/* more than one value specified */(6) Constrain(ambiguous-attr)(7) Else if lnvalidAction detected(8) ProvideNegativeAnswer(SemRep)(9) Else/* well-formed query */(10) answer +-- database-query(SemRep)(11 ) ProvideAnswer(answer)Figure 4: Goal Selection Algorithmuser queries (steps 1-8) 5 (van Beeket  al., 1993; Raskuttiand Zukerman, 1993; Qu and Beale, 1999), and 2) pro-viding answers to well-formed queries (steps 9-11).3.2.3 Strategy SelectionPrevious work has argued that initiative affects the de-gree of control an agent has in the dialogue interaction(Whittaker and Stenton, 1988; Walker and Whittaker,1990; Chu-Carroll and Brown, 1998).
Thus, a cooper-ative system may adopt different strategies to achieve thesame goal depending on the initiative distribution.
Sincetask initiative models contribution to domain/problem-solving goals, while dialogue initiative affects the cur-5An alternative strategy to step (4) is to perform adatabase lookupbased on the ambiguous query and summarize the results (Litman etal., 1998), which we leave for future work.rent discourse goal, we developed alternative strategiesfor achieving the goals in Figure 4 based on initiativedistribution, as shown in Table 1.The strategies employed when MIMIC has only dia-logue initiative are similar to the mixed initiative dia-logue strategies employed by many existing spoken di-alogue systems (e.g., (Bennacef et al, 1996; Stent etal., 1999)).
To instantiate an attribute, MIMIC adoptsthe lnfoSeek dialogue act to solicit the missing informa-tion.
In contrast, when MIMIC has both initiatives, itplays a more active role by presenting the user with addi-tional information comprising valid instantiations of theattribute (GiveOptions).
Given an invalid query, MIMICnotifies the user of the failed query and provides an open-ended prompt when it only has dialogue initiative.
WhenMIMIC has both initiatives, however, in addition to No-tifyFailure, it suggests an alternative close to the user'soriginal query and provides a limited prompt.
Finally,when MIMIC has neither initiative, it simply adopts No-tifyFailure, allowing the user to determine the next dis-course goal.3.3 Utterance Generat ionMIMIC employs a simple template-driven utterance gen-eration approach.
Templates are associated with dialogueacts as shown in Table 2.6 The generation component re-ceives from the dialogue manager the selected ialogueacts and the parameters needed to instantiate the tem-plates.
It then generates the system response, which issent to the TTS module for spoken output synthesis.6In most cases, there is a one-to-one-mapping between dialogueacts and templates.
The exceptions are Answer, NotifyFailure, andSuggestAlternative, whose templates vary based on the question type.101Task + Dialogue Dialogue NoneConstrain Clarify Clarify AcknowledgeInstantiate GiveOptions lnfoSeek AcknowledgeInfoSeekProvideAnswer Answer Answer AnswerLimitedPrompt OpenPromptProvideNegativeAnswer NotifyFailure NotifyFailure NotifyFailureSuggestAltemative OpenPromptLimitedPromptTable 1: Strategy Selection Based on Goal and Initiative DistributionDialogue ActClarifyAcknowledgeGiveOptionsInfoSeekAnswerOpenPromptLimitedPromptNotifyFailureSuggestAltemativeTemplate"Did you say < valuel > .... or < valuen >.9""Uh-huh.
""Choices for < attribute > are < valuex > ... < value, >7"What < attribute > would you like?
"E.g., "< movie > is playing at < theater > at < time1 > ... < time,, >""Can I help you with anything elseT'"Please say the name of the movie or theater or town you would like information about.
"E.g., "< movie > is not playing at < theater >.E.g., "< movie > is playing at < alternativetheater > at < timex > ... < timen >"Table 2: Mappings Between Dialogue Acts and Utterance Templates4 ExamplesTo illustrate MIMIC's adaptation capabilities, we returnto the dialogue in Figure 1, which is repeated in Figure 5and annotated with the cues detected in each user turn(in boldfaced italics) and the dialogue acts employed forresponse generation i each system turn (in boldface).The bpas representing the initiative distribution for ut-terance (3) are the initial bpas, which, based on MIMIC'srole as an information provider, aremt-(3)({S}) = 0.3, mt-(3)({U}) = 0.7;= 0.6, md- (3 ) ({V})  = 0.4.The cue AmbiguousAction is detected in utterance (3)because the mandatory attribute theater was not specifiedand cannot be inferred (since the town of Montclair hasmultiple theaters).
The bpas representing its effect areinstantiated as follows (Figure 3):mt-,,({S}) = 0.35, mt_ , , (O)  = 0.65;md-aa({S}) = 0.7, md-aa(O) = 0.3.Combining the current bpas with the effects of the ob-served cue, we obtain the following new bpas:mt-(4)({S}) = 0.4, mt_(a)({U}) = 0.6;md_(4)({S}) = 0.83, md_(4)({U}) = 0.17.The updated bpas indicate that MIMIC should have dia-logue but not task initiative when attempting to resolvethe detected ambiguity in utterance (4).MIMIC selects Instantiate as its goal to be achieved(Figure 4), which, based on the initiative distribution,leads it to select he InfoSeek action (Table I) and gener-ate the query "What heater would you like?
"The user's response in (5) again triggers Ambiguous-Action, as well as NoNewlnfo since the semantic repre-sentations of (3) and (5) are identical, given the dialoguecontext.
When the effects of these cues are taken intoaccount, we have the following initiative distribution forutterance (6):mt-(6)({S}) = 0.62, mt_(6)({U}) = 0.38;md-(6)({S}) = 0.96, rnd_(6)({V}) = 0.04.Although Instaatiate is again selected as the goal,MIMIC now has both task and dialogue initiatives; thusit selects both GiveOptions and lnfoSeek to achieve thisgoal and generates utterances (6) and (7).
The addi-tional information, in the form of valid theater choices,helps the user provide the missing value in (8), allow-ing MIMIC to answer the query in (9) and prompt forthe next query.
However, despite the limited prompt,the user provides a well-formed query in (11), trigger-ing TakeOverTask.
Thus, MIMIC answers the query andswitches to an open-ended prompt in (13), relinquishingtask initiative to the user.In addition to its automatic adaptation capabilities, an-other advantage of MIMIC is the ease of modifying itsadaptation behavior, enabled by the decoupling of theinitiative module from the goal and strategy selectionprocesses.
For instance, a system-initiative rsion ofMIMIC can be achieved by setting the initial bpas as fol-lows:mt-initial({S}) = 1;md--initial({S}) -~1.102(1) S: Hello, this is MIMIC, the movie information system.
(2) How can I help you?
(3) U: What time is Analyze This playing in Montclair?\[what time is analyze this playing in montclair\](4) S: What theater would you like?
(5) U: Montclair.\[montclair\](6) S: Choices for theater are Wellmont heater and Clearviews Screening Zone(7) What theater would you like?
(8) U: Clearviews Screening Zone.\[um movie screening zone\](9) S: Analyze This is playing at Clearviews Screening Zone in Montclair at 1:15pm,4:10pm, and 6:30pm.
(10) Please say the name of the movie or theater or town you would like informationabout.
(11) U: What time is Analyze This playing at the Wellmont heater?\[what time is analyze this playing at the wellmont theater\](12) S: Analyze this is playing at Wellmont heater in Montclair at 3:15pm, 5:45pm,8:20pm, and 10:10pm.
(13) Can I help you with anything else?\[AmbiguousAction\]\[lnfoSeek\]\[AmbiguousAction, NoNewlnfo\]\[GiveOptions\]\[InfoSeek\]\[AmbiguousActionResolved\]\[Answer\]\[LimitedPrompt\]\[TakeOverTask\]\[Answer\]\[OpenPrompt\]Figure 5: Annotated Dialogue Shown in Figure 1This is because in the Dempster-Shafer theory, if theinitial bpas or the bpas for a cue provide definite evi-dence for drawing a certain conclusion, then no subse-quent cue has any effect on changing that conclusion.Thus, MIMIC will retain both initiatives throughout thedialogue.
Alternatively, versions of MIMIC with differ-ent adaptation behavior can be achieved by tailoring theinitial bpas and/or the bpas for each cue based on the ap-plication.
For instance, for an electronic sales agent, theeffect oflnvalidAction can be increased so that when theuser orders an out-of-stock item, the system will alwaystake over task initiative and suggest an alternative item.5 System EvaluationWe conducted two experiments oevaluate MIMIC's au-tomatic adaptation capabilities.
We compared MIMICwith two control systems: MIMIC-SI, a system-initiativeversion of MIMIC in which the system retains both ini-tiatives throughout the dialogue, and MIMIC-MI, a non-adaptive mixed-initiative version of MIMIC that resem-bles the behavior of many existing dialogue systems.
Inthis section we summarize these experiments and theirresults.
A companion paper describes the evaluation pro-cess and results in further detail (Chu-Carroll and Nick-erson, 2000).Each experiment involved eight users interacting withMIMIC and MIMIC-SI or MIMIC-MI to perform aset oftasks, each requiring the user to obtain specific movie in-formation.
User satisfaction was assessed by asking thesubjects to fill out a questionnaire after interacting witheach version of the system.
Furthermore, a number ofperformance f atures, largely based on the PARADISEdialogue valuation scheme (Walker et al, 1997), wereautomatically logged, derived, or manually annotated.
Inaddition, we logged the cues automatically detected ineach user utterance, as well as the initiative distributionfor each turn and the dialogue acts selected to generateeach system response.The features gathered from the dialogue interactionswere analyzed along three dimensions: system perfor-mance, discourse features (in terms of characteristicsof the resulting dialogues, such as the cues detected inuser utterances), and initiative distribution.
Our resultsshow that MIMIC's adaptation capabilities 1) led to bet-ter system performance in terms of user satisfaction, dia-logue efficiency (shorter dialogues), and dialogue quality(fewer ASR timeouts), and 2) better matched user expec-tations (by giving up task initiative when the user intendsto have control of the dialogue interaction) and more effi-ciently resolved ialogue anomalies (by taking over taskinitiative to provide guidance when no progress is madein the dialogue, or to constrain user utterances when ASRperformance is poor).6 ConclusionsIn this paper, we discussed MIMIC, an adaptive mixed-initiative spoken dialogue system.
MIMIC's automaticadaptation capabilities allow it to employ appropriatestrategies based on the cumulative ffect of informationdynamically extracted from user utterances during dia-logue interactions, enabling MIMIC to provide more co-operative and satisfactory responses than existing non-adaptive systems.
Furthermore, MIMIC was imple-mented as a general framework for information querysystems by decoupling its initiative module from thegoal selection process, while allowing the outcome ofboth processes to jointly determine the response strate-gies employed.
This feature nables easy modification toMIMIC's adaptation behavior, thus allowing the frame-work to be used for rapid development and comparisons103of experimental prototypes of spoken dialogue systems.AcknowledgmentsThe author would like to thank Egbert Ammicht, An-toine Saad, Qiru Zhou, Wolfgang Reichl, and StefanOrtmanns for their help on system integration and onASR/telephony server development, Jill Nickerson forconducting the evaluation experiments, and Bob Carpen-ter, Diane Litman, Christine Nakatani, and Jill Nickersonfor their comments on an earlier draft of this paper.ReferencesS.
Bennacef, L. Devillers, S. Rosset, and L. Lamel.1996.
Dialog in the RAILTEL telephone-based sys-tem.
In Proceedings of the 4th International Confer-ence on Spoken Language Processing.Jennifer Chu-Carroll and Michael K. Brown.
1998.
Anevidential model for tracking initiative in collabora-tive dialogue interactions.
User Modeling and User-Adapted Interaction, 8(3-4):215-253.Jennifer Chu-Carroll and Bob Carpenter.
1999.
Vector-based natural anguage call routing.
ComputationalLinguistics, 25(3):361-388.Jennifer Chu-Carroll and Jill S. Nickerson.
2000.
Evalu-ating automatic dialogue strategy adaptation for a spo-ken dialogue system.
In Proceedings of the 1st Con-ference of the North American Chapter of the Associ-ation for Computational Linguistics.
To appear.Jean Gordon and Edward H. Shortliffe.
1984.
TheDempster-Shafer theory of evidence.
In BruceBuchanan and Edward Shortliffe, editors, Rule-BasedExpert Systems: The MYCIN Experiments of theStanford Heuristic Programming Project, chapter 13,pages 272-292.
Addison-Wesley.Lori Lamel.
1998.
Spoken language dialog system de-velopment and evaluation at LIMSI.
In Proceedingsof the International Symposium on Spoken Dialogue,pages 9-17.Diane J. Litman and Shimei Pan.
1999.
Empiricallyevaluating an adaptable spoken dialogue system.
InProceedings of the 7th International Conference onUser Modeling, pages 55-64.Diane J. Litman, Shimei Pan, and Marilyn A. Walker.1998.
Evaluating response strategies in a web-basedspoken dialogue agent.
In Proceedings of the 36thAnnual Meeting of the Association for ComputationalLinguistics, pages 780-786.Christine H. Nakatani and Jennifer Chu-Carroll.
2000.Using dialogue representations forconcept-to-speechgeneration.
In Proceedings of the ANLP-NAACLWorkshop on Conversational Systems.Stefan Ortmanns, Wolfgang Reichl, and Wu Chou.
1999.An efficient decoding method for real time speechrecognition.
In Proceedings of the 5th European Con-ference on Speech Communication a d Technology.Yan Qu and Steve Beale.
1999.
A constraint-basedmodel for cooperative r sponse generation i informa-tion dialogues.
In Proceedings of the Sixteenth Na-tional Conference on Artificial Intelligence.Bhavani Raskutti and Ingrid Zukerman.
1993.
Elicit-ing additional information during cooperative consul-tations.
In Proceedings of the 15th Annual Meeting ofthe Cognitive Science Society.Wolfgang Reichl and Wu' Chou.
1998.
Decision treestate tying based on segmental c ustering for acousticmodeling.
In Proceedings of the International Confer-ence on Acoustics, Speech, and Signal Processing.Gerald Salton.
1971.
The SMART Retrieval System.Prentice Hall, Inc.Stephanie Seneff, James Glass, David Goddeau, DavidGoodine, Lynette Hirschman, Hong Leung, MichaelPhillips, Joseph Polifroni, and Victor Zue.
1991.
De-velopment and preliminary evaluation of the MITATIS system.
In Proceedings of the DARPA Speechand Natural Language Workshop, ages 88-93.Glenn Shafer.
1976.
A Mathematical Theory of Evi-dence.
Princeton University Press.Richard Sproat, editor.
1998.
Multilingual Text-to-Speech Synthesis: The Bell Labs Approach.
Kluwer,Boston, MA.Amanda Stent, John Dowding, Jean Mark Gawron, Eliz-abeth Owen Bratt, and Robert Moore.
1999.
TheCommandTalk spoken dialogue system.
In Proceed-ings of the 37th Annual Meeting of the Association forComputational Linguistics, pages 183-190.Peter van Beek, Robin Cohen, and Ken Schmidt.
1993.From plan critiquing to clarification dialogue for co-operative response generation.
Computational Intelli-gence, 9(2):132-154.Marilyn Walker and Steve Whittaker.
1990.
Mixed ini-tiative in dialogue: An investigation i to discoursesegmentation.
In Proceedings of the 28th AnnualMeeting of the Association for Computational Lin-guistics, pages 70-78.Marilyn A. Walker, Diane J. Litman, Candance A.Kamm, and Alicia Abella.
1997.
PARADISE: Aframework for evaluating spoken dialogue agents.
InProceedings of the 35th Annual Meeting of the Associ-ation for Computational Linguistics, pages 271-280.Steve Whittaker and Phil Stenton.
1988.
Cues and con-trol in expert-client dialogues.
In Proceedings of the26th Annual Meeting of the Association for Computa-tional Linguistics, pages 123-130.Qiru Zhou, Chin-Hui Lee, Wu Chou, and Andrew Pargel-lis.
1997.
Speech technology integration and researchplatform: A system study.
In Proceedings of the 5thEuropean Conference on Speech Communication andTechnology.104
