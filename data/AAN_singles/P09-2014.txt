Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 53?56,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPComparing the Accuracy of CCG and Penn Treebank ParsersStephen ClarkUniversity of CambridgeComputer Laboratory15 JJ Thomson Avenue, Cambridge, UKstephen.clark@cl.cam.ac.ukJames R. CurranSchool of Information TechnologiesUniversity of SydneyNSW 2006, Australiajames@it.usyd.edu.auAbstractWe compare the CCG parser of Clark andCurran (2007) with a state-of-the-art PennTreebank (PTB) parser.
An accuracy com-parison is performed by converting theCCG derivations into PTB trees.
We showthat the conversion is extremely difficult toperform, but are able to fairly compare theparsers on a representative subset of thePTB test section, obtaining results for theCCG parser that are statistically no differ-ent to those for the Berkeley parser.1 IntroductionThere are a number of approaches emerging in sta-tistical parsing.
The first approach, which began inthe mid-90s and now has an extensive literature, isbased on the Penn Treebank (PTB) parsing task:inferring skeletal phrase-structure trees for unseensentences of the WSJ, and evaluating accuracy ac-cording to the Parseval metrics.
Collins (1999) is aseminal example.
The second approach is to applystatistical methods to parsers based on linguisticformalisms, such as HPSG, LFG, TAG, and CCG,with the grammar being defined manually or ex-tracted from a formalism-specific treebank.
Evalu-ation is typically performed by comparing againstpredicate-argument structures extracted from thetreebank, or against a test set of manually anno-tated grammatical relations (GRs).
Examples ofthis approach include Riezler et al (2002), Miyaoand Tsujii (2005), Briscoe and Carroll (2006), andClark and Curran (2007).1Despite the many examples from both ap-proaches, there has been little comparison acrossthe two groups, which we refer to as PTB parsingand formalism-based parsing, respectively.
The1A third approach is dependency parsing, but we restrictthe comparison in this paper to phrase-structure parsers.PTB parser we use for comparison is the pub-licly available Berkeley parser (Petrov and Klein,2007).
The formalism-based parser we use is theCCG parser of Clark and Curran (2007), whichis based on CCGbank (Hockenmaier and Steed-man, 2007), a CCG version of the Penn Treebank.We compare this parser with a PTB parser becauseboth are derived from the same original source,and both produce phrase-structure in some formor another; the interesting question is whether any-thing is gained by converting the PTB into CCG.2The comparison focuses on accuracy and is per-formed by converting CCG derivations into PTBphrase-structure trees.
A contribution of this paperis to demonstrate the difficulty of mapping from agrammatical resource based on the PTB back to thePTB, and we also comment on the (non-)suitabilityof the PTB as a general formalism-independentevaluation resource.
A second contribution is toprovide the first accuracy comparison of the CCGparser with a PTB parser, obtaining competitivescores for the CCG parser on a representative sub-set of the PTB test sections.
It is important to notethat the purpose of this evaluation is comparisonwith a PTB parser, rather than evaluation of theCCG parser per se.
The CCG parser has been ex-tensively evaluated elsewhere (Clark and Curran,2007), and arguably GRs or predicate-argumentstructures provide a more suitable test set for theCCG parser than PTB phrase-structure trees.2 The CCG to PTB ConversionThere has been much recent work in attempt-ing to convert native parser output into alterna-tive representations for evaluation purposes, e.g.
(Clark and Curran, 2007; Matsuzaki and Tsujii,2008).
The conclusion is that such conversionsare surprisingly difficult.
Clark and Curran (2007)2Since this short paper reports a small, focused researchcontribution, we refer readers to Clark and Curran (2007) andPetrov and Klein (2007) for details of the two parsers.53shows that converting gold-standard CCG deriva-tions into the GRs in DepBank resulted in an F-score of only 85%; hence the upper bound on theperformance of the CCG parser, using this evalua-tion scheme, was only 85%.
Given that the currentbest scores for the PTB parsing task are over 90%,any loss from the conversion process needs to beconsidered carefully if a fair comparison with PTBparsers is to be achieved.CCGbank was derived from the PTB, and soit might be considered that converting back tothe PTB would be a relatively easy task, by es-sentially reversing the mapping Hockenmaier andSteedman (2007) used to create CCGbank.
How-ever, there are a number of differences betweenthe two treebanks which make the conversion backfar from trivial.
First, the corresponding deriva-tions in the treebanks are not isomorphic: a CCGderivation is not simply a relabelling of the nodesin the PTB tree; there are many constructions, suchas coordination and control structures, where thetrees are a different shape, as well as having differ-ent labels.
It is important to realise that Hocken-maier and Steedman (2007) invested a significantamount of time and effort in creating the mapping.Second, some of the labels in the PTB do not ap-pear in CCGbank, for example the QP label, andthese must be added back in; however, developingrules to insert these labels in the right places is afar from trivial task.There were two approaches we considered forthe conversion.
One possibility is to associate PTBtree structures with CCG lexical categories, andcombine the trees together in step with the cate-gory combinations in a CCG derivation ?
in muchthe same way that an LTAG has elementary treesin the lexicon which are combined using the sub-stitution and adjunction rules of TAG.
The secondapproach is to associate conversion rules with eachlocal tree ?
i.e.
a parent and one or two child nodes?
which appears in the CCGbank data.3In this pa-per we took the second approach.2.1 Conversion SchemasThere are three types of conversion schema:schemas which introduce nodes for lexical items;schemas which insert or elide PTB nodes for unary3Another possible approach has been taken by Matsuzakiand Tsujii (2008), who convert HPSG analyses from a gram-mar automatically extracted from the PTB back into the PTB.They treat the problem as one of translation, learning a syn-chronous grammar to perform the mapping.TYPE RULE SCHEMAlexical NP NPlexical NP [nb]/N ?lexical (S [dcl ]\NP)/NP VPunary S [dcl ]?
NP\NP (SBAR l)type- PP ?
lraising (S\NP)\((S\NP)/PP)binary NP [nb]/N N ?
NP [nb] >binary NP S [dcl ]\NP ?
S [dcl ] (S l r)binary NP/(S [dcl ]\NP) (SBARS [dcl ]\NP ?
NP l (S r))Table 1: Example conversion schemasrules and type-raising; and schemas which canperform arbitrary manipulation of generated PTBsubtrees for binary CCG rule instances.
Examplesof these schemas are shown in Table 1.
The pri-mary operations in the binary schema are insertingand attaching.
Inserting a new node, for exampleusing the schema (S l r), creates a new S nodedominating both the left and right children of a bi-nary rule.
The attaching schema can attach the leftnode under the right node (>); or the right nodeunder the left node (<).The lexical categories NP and(S [dcl ]\NP)/NP (shown in Table 1) intro-duce the PTB nodes NP and VP, respectively,while other lexical categories such as NP [nb]/Nintroduce no extra nodes.
Some unary rulesintroduce nodes, such as SBAR for the reducedrelative case, whilst others, such as the type-raisedPP , do not.
Finally, binary schemas may createno new nodes (e.g.
when a determiner is attachedto an existing NP), or one or more nodes (e.g.
anextra S node is created when a verb phrase findsits subject).A PTB tree is built from a CCG derivation byrunning over the derivation in a bottom-up fashionand applying these schemas to the local trees inthe derivation.2.2 Schema developmentThe schemas were developed by manual inspec-tion using section 00 of CCGbank and the PTB asa development set, following the oracle method-ology of Clark and Curran (2007), in which gold-standard derivations from CCGbank are convertedto the new representation and compared with thegold standard for that representation.
As well asgiving an idea of the difficulty, and success, of theconversion, the resulting numbers provide an up-54SECTION P R F COMP00 (all) 93.37 95.15 94.25 39.6800 (len ?
40) 94.11 95.65 94.88 42.1123 (all) 93.68 95.13 94.40 39.9323 (len ?
40) 93.75 95.23 94.48 42.15Table 2: Oracle conversion evaluationper bound on the performance of the CCG parser.The test set, section 23, was not inspected at anystage in the development of the schemas.In total, we annotated 32 unary and 776 binaryrule instances (of the possible 2853 instances) withconversion schemas, and 162 of the 425 lexicalcategories.
We also implemented a small num-ber of default catch-all cases for the general CCGcombinatory rules and for the rules dealing withpunctuation, which allowed most of the 2853 ruleinstances to be covered.
Considerable time and ef-fort was invested in the creation of these schemas.The oracle conversion results from the goldstandard CCGbank to the PTB for section 00 and23 are shown in Table 2.
The numbers are brack-eting precision, recall, F-score and complete sen-tence matches, using the EVALB evaluation script.Note that these figures provide an upper bound onthe performance of the CCG parser using EVALB,given the current conversion process.The importance of this upper bound should notbe underestimated, when the evaluation frame-work is such that incremental improvements of afew tenths of a percent are routinely presented asimproving the state-of-the-art, as is the case withthe Parseval metrics.
The fact that the upper boundhere is less than 95% shows that it is not possi-ble to fairly evaluate the CCG parser on the com-plete test set.
Even an upper bound of around 98%,which is achieved by Matsuzaki and Tsujii (2008),is not sufficient, since this guarantees a loss of atleast 2%.43 EvaluationThe Berkeley parser (Petrov and Klein, 2007) pro-vides performance close to the state-of-the-art forthe PTB parsing task, with reported F-scores ofaround 90%.
Since the oracle score for CCGbankis less than 95%, it would not be a fair comparison4The higher upper bound achieved by Matsuzaki and Tsu-jii (2008) could be due to the fact that their extracted HPSGgrammars are closer to the PTB than CCGbank, or due to theirconversion method.
We leave the application of their methodto the CCG parser for future work.to use the complete test set.
However, there are anumber of sentences which are correct, or almostcorrect, according to EVALB after the conversion,and we are able to use those for a fair comparison.Table 3 gives the EVALB results for the CCGparser on various subsets of section 00 of thePTB.
The first row shows the results on onlythose sentences which the conversion process canconvert sucessfully (as measured by convertinggold-standard CCGbank derivations and compar-ing with PTB trees; although, to be clear, the scoresare for the CCG parser on those sentences).
As canbe seen from the scores, these sentences form aslightly easier subset than the full section 00, butthis is a subset which can be used for a fair com-parison against the Berkeley parser, since the con-version process is not lossy for this subset.The second row shows the scores on those sen-tences for which the conversion process was some-what lossy, but when the gold-standard CCGbankderivations are converted, the oracle F-measure isgreater than 95%.
The third row is similar, but forsentences for which the oracle F-score is geaterthan 92%.
The final row is for the whole of sec-tion 00.
The UB column gives the upper bound onthe accuracy of the CCG parser.
Results are calcu-lated using both gold standard and automaticallyassigned POS tags; # is the number of sentencesin the sample, and the % column gives the samplesize as a percentage of the whole section.We compare the CCG parser to the Berkeleyparser using the accurate mode of the Berke-ley parser, together with the model supplied withthe publicly available version.
Table 3 gives theresults for Section 23, comparing the CCG andBerkeley parsers.
The projected columns givethe projected scores for the CCG parser, if it per-formed at the same accuracy level for those sen-tences which could not be converted successfully.The purpose of this column is to obtain an ap-proximation of the CCG parser score for a perfectconversion process.5The results in bold are thosewhich we consider to be a fair comparison againstthe Berkeley parser.
The difference in scores isnot statistically significant at p=0.05 (using DanBikel?s stratified shuffling test).One possible objection to this comparison isthat the subset for which we have a fair compar-5This is likely to be an upper bound on the performanceof the CCG parser, since the larger test sets contain sentenceswhich were harder to convert, and hence are likely to be moredifficult to parse.55SAMPLE # % UB actual F projected Fgold auto gold auto00 (F=100) 759 39.7 100.00 94.19 93.41 ?
?00 (F?95) 1164 60.8 98.49 91.08 89.93 92.46 91.2900 (F?92) 1430 74.6 97.41 89.73 88.47 92.05 90.7600 (all) 1913 100.0 94.25 87.00 85.60 92.00 90.52Table 3: Results on the development set (CCG parser only)SAMPLE # % UB Berkeley F actual F projected Fgold auto gold auto gold auto23 (F=100) 961 39.9 100.0 93.38 93.37 93.83 92.86 ?
?23 (F?95) 1401 58.2 98.61 91.66 91.63 90.82 89.84 92.08 91.0923 (F?92) 1733 72.0 97.44 91.01 90.88 89.53 88.54 91.82 90.8123 (all) 2407 100.0 94.40 89.67 89.47 86.36 85.50 91.20 90.29Table 4: Results on the test set (CCG parser and Berkeley)ison is likely to be an easy subset consisting ofshorter sentences, and so the most that can besaid is that the CCG parser performs as well asthe Berkeley parser on short sentences.
In fact,the subset for which we perform a perfect conver-sion contains sentences with an average length of18.1 words, compared to 21.4 for sentences with40 words or less (a standard test set for reportingParseval figures).
Hence we do consider the com-parison to be highly informative.4 ConclusionOne question that is often asked of the CCGparsing work is ?Why not convert back into thePTB representation and perform a Parseval eval-uation??
By showing how difficult the conver-sion is, we believe that we have finally answeredthis question, as well as demonstrating compara-ble performance with the Berkeley parser.
In addi-tion, we have thrown further doubt on the possibleuse of the PTB for cross-framework parser evalua-tion, as recently suggested by Matsuzaki and Tsu-jii (2008).
Even the smallest loss due to mappingacross representations is significant when a fewtenths of a percentage point matter.
Whether PTBparsers could be competitive on alternative parserevaluations, such as those using GR schemes, forwhich the CCG parser performs very well, is anopen question.AcknowledgementsJames Curran was funded under Australian Re-search Council Discovery grant DP0665973.Stephen Clark was funded under EPSRC grantEP/E035698/1.ReferencesTed Briscoe and John Carroll.
2006.
Evaluating the accu-racy of an unlexicalized statistical parser on the PARCDepBank.
In Proceedings of the Poster Session ofCOLING/ACL-06, Sydney, Austrailia.Stephen Clark and James R. Curran.
2007.
Wide-coverageefficient statistical parsing with CCG and log-linear mod-els.
Computational Linguistics, 33(4):493?552.Michael Collins.
1999.
Head-Driven Statistical Models forNatural Language Parsing.
Ph.D. thesis, University ofPennsylvania.Julia Hockenmaier and Mark Steedman.
2007.
CCGbank:a corpus of CCG derivations and dependency structuresextracted from the Penn Treebank.
Computational Lin-guistics, 33(3):355?396.Takuya Matsuzaki and Jun?ichi Tsujii.
2008.
Comparativeparser performance analysis across grammar frameworksthrough automatic tree conversion using synchronousgrammars.
In Proceedings of COLING-08, pages 545?552, Manchester, UK.Yusuke Miyao and Jun?ichi Tsujii.
2005.
Probabilistic dis-ambiguation models for wide-coverage HPSG parsing.
InProceedings of the 43rd meeting of the ACL, pages 83?90,University of Michigan, Ann Arbor.Slav Petrov and Dan Klein.
2007.
Improved inference forunlexicalized parsing.
In Proceedings of the HLT/NAACLconference, Rochester, NY.Stefan Riezler, Tracy H. King, Ronald M. Kaplan, RichardCrouch, John T. Maxwell III, and Mark Johnson.
2002.Parsing the Wall Street Journal using a Lexical-FunctionalGrammar and discriminative estimation techniques.
InProceedings of the 40th Meeting of the ACL, pages 271?278, Philadelphia, PA.56
