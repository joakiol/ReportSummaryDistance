Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 113?116,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsKernels on Linguistic Structures for Answer ExtractionAlessandro Moschitti and Silvia QuarteroniDISI, University of TrentoVia Sommarive 1438100 POVO (TN) - Italy{moschitti,silviaq}@disi.unitn.itAbstractNatural Language Processing (NLP) for Infor-mation Retrieval has always been an interest-ing and challenging research area.
Despite thehigh expectations, most of the results indicatethat successfully using NLP is very complex.In this paper, we show how Support VectorMachines along with kernel functions can ef-fectively represent syntax and semantics.
Ourexperiments on question/answer classificationshow that the above models highly improve onbag-of-words on a TREC dataset.1 IntroductionQuestion Answering (QA) is an IR task where themajor complexity resides in question processingand answer extraction (Chen et al, 2006; Collins-Thompson et al, 2004) rather than document re-trieval (a step usually carried out by off-the shelf IRengines).
In question processing, useful informationis gathered from the question and a query is created.This is submitted to an IR module, which providesa ranked list of relevant documents.
From these, theQA system extracts one or more candidate answers,which can then be re-ranked following various crite-ria.
Although typical methods are based exclusivelyon word similarity between query and answer, recentwork, e.g.
(Shen and Lapata, 2007) has shown thatshallow semantic information in the form of predi-cate argument structures (PASs) improves the auto-matic detection of correct answers to a target ques-tion.
In (Moschitti et al, 2007), we proposed theShallow Semantic Tree Kernel (SSTK) designed toencode PASs1 in SVMs.1in PropBank format, (www.cis.upenn.edu/?ace).In this paper, similarly to our previous approach,we design an SVM-based answer extractor, that se-lects the correct answers from those provided by abasic QA system by applying tree kernel technol-ogy.
However, we also provide: (i) a new kernelto process PASs based on the partial tree kernel al-gorithm (PAS-PTK), which is highly more efficientand more accurate than the SSTK and (ii) a new ker-nel called Part of Speech sequence kernel (POSSK),which proves very accurate to represent shallow syn-tactic information in the learning algorithm.To experiment with our models, we built twodifferent corpora, WEB-QA and TREC-QA by us-ing the description questions from TREC 2001(Voorhees, 2001) and annotating the answers re-trieved from Web resp.
TREC data (available atdisi.unitn.it/?silviaq).
Comparative exper-iments with re-ranking models of increasing com-plexity show that: (a) PAS-PTK is far more efficientand effective than SSTK, (b) POSSK provides a re-markable further improvement on previous models.Finally, our experiments on the TREC-QA dataset,un-biased by the presence of typical Web phrasings,show that BOW is inadequate to learn relations be-tween questions and answers.
This is the reasonwhy our kernels on linguistic structures improve itby 63%, which is a remarkable result for an IR task(Allan, 2000).2 Kernels for Q/A ClassificationThe design of an answer extractor basically dependson the design of a classifier that decides if an an-swer correctly responds to the target question.
Wedesign a classifier based on SVMs and different ker-nels applied to several forms of question and answer113PASA1autismrelcharacterizeA0spectrumPASA0behaviorR-A0thatrelcharacterizeA1inattention(a)PASA1disorderrelcharacterizeA0anxiety(b)PASrelcharacterizePASA1 rel A0PASA1 relcharacterizePASrelcharacterizeA0relcharacterize(c)Figure 1: Compact PAS-PTK structures of s1 (a) and s2 (b) and some fragments they have in common as produced bythe PTK (c).
Arguments are replaced with their most important word (or semantic head) to reduce data sparseness.representations:(1) linear kernels on the bag-of-words (BOW) orbag-of-POS-tags (POS) features,(2) the String Kernel (SK) (Shawe-Taylor and Cris-tianini, 2004) on word sequences (WSK) and POS-tag sequences (POSSK),(3) the Syntactic Tree Kernel (STK) (Collins andDuffy, 2002) on syntactic parse trees (PTs),(4) the Shallow Semantic Tree Kernel (SSTK) (Mos-chitti et al, 2007) and the Partial Tree Kernel (PTK)(Moschitti, 2006) on PASs.In particular, POS-tag sequences and PAS treesused with SK and PTK yield to two innovative ker-nels, i.e.
POSSK and PAS-PTK2.
In the next sec-tions, we describe in more detail the data structureson which we applied the above kernels.2.1 Syntactic StructuresThe POSSK is obtained by applying the String Ker-nel on the sequence of POS-tags of a question ora answer.
For example, given sentence s0: Whatis autism?, the associated POS sequence is WPAUX NN ?
and some of the substrings extracted byPOSSK are WP NN or WP AUX.
A more completestructure is the full parse tree (PT) of the sentence,that constitutes the input of the STK.
For instance,the STK accepts the syntactic parse: (SBARQ (WHNP(WP What))(SQ (VP (AUX is)(NP (NN autism))))(.
?
)).2.2 Semantic StructuresThe intuition behind our semantic representation isthe idea that when we ignore the answer to a def-inition question we check whether such answer isformulated as a ?typical?
definition and whether an-swers defining similar concepts are expressed in a2For example, let PTK(t1, t2) = ?
(t1) ?
?
(t2), where t1and t2 are two syntactic parse trees.
If we map t1 and t2into two new shallow semantic trees s1 and s2 with a map-ping ?M (?
), we obtain: PTK(s1, s2) = ?
(s1) ?
?
(s2) =?
(?M (t1)) ?
?
(?M (t2)) = ??
(t1) ?
??
(t2)=PAS-PTK(t1, t2),which is a noticeably different kernel induced by the mapping??
= ?
?
?M .similar way.To take advantage of semantic representations, wework with two types of semantic structures; first,the Word Sequence Kernel applied to both ques-tion and answer; given s0, sample substrings are:What is autism, What is, What autism, is autism,etc.
Then, two PAS-based trees: Shallow Seman-tic Trees for SSTK and Shallow Semantic Trees forPTK, both based on PropBank structures (Kings-bury and Palmer, 2002) are automatically generatedby our SRL system (Moschitti et al, 2005).
As anexample, let us consider an automatically annotatedsentence from our TREC-QA corpus:s1: [A1 Autism] is [rel characterized] [A0 by a broadspectrum of behavior] [R?A0 that] [relincludes] [A1 ex-treme inattention to surroundings and hypersensitivity tosound and other stimuli].Such annotation can be used to design a shallow se-mantic representation that can be matched againstother semantically similar sentences, e.g.s2: [A1 Panic disorder] is [rel characterized] [A0 by un-realistic or excessive anxiety].It can be observed here that, although autism is adifferent disease from panic disorder, the structureof both definitions and the latent semantics they con-tain (inherent to behavior, disorder, anxiety) are sim-ilar.
So for instance, s2 appears as a definition evento someone who only knows what the definition ofautism looks like.The above annotation can be compactly repre-sented by predicate argument structure trees (PASs)such as those in Figure 1.
Here, we can notice thatthe semantic similarity between sentences is explic-itly visible in terms of common fragments extractedby the PTK from their respective PASs.
Instead,the similar PAS-SSTK representation in (Moschittiet al, 2007) does not take argument order into ac-count, thus it fails to capture the linguistic ratio-nale expressed above.
Moreover, it is much heavier,causing large memory occupancy and, as shown byour experiments, much longer processing time.1143 ExperimentsIn our experiments we show that (a) the PAS-PTKshallow semantic tree kernel is more efficient and ef-fective than the SSTK proposed in (Moschitti et al,2007), and (b) our POSSK jointly used with PAS-PTK and STK greatly improves on BOW.3.1 Experimental SetupIn our experiments, we implemented the BOW andPOS kernels, WSK, POSSK, STK (on syntacticPTs derived automatically with Charniak?s parser),SSTK and PTK (on PASs derived automatically withour SRL system) as well as their combinations inSVM-light-TK3.
Since answers often contain morethan one PAS (see Figure 1), we sum PTK (or SSTK)applied to all pairs P1?P2, P1 and P2 being the setsof PASs of the first two answers.The experimental datasets were created by sub-mitting the 138 TREC 2001 test questions labeled as?description?
in (Li and Roth, 2002) to our basic QAsystem, YourQA (Quarteroni and Manandhar, 2008)and by gathering the top 20 answer paragraphs.YourQA was run on two sources: Web docu-ments by exploiting Google (code.google.com/apis/) and the AQUAINT data used for TREC?07(trec.nist.gov/data/qa) by exploiting Lucene(lucene.apache.org), yielding two different cor-pora: WEB-QA and TREC-QA.
Each sentence ofthe returned paragraphs was manually evaluatedbased on whether it contained a correct answer tothe corresponding question.
To simplify our task,we isolated for each paragraph the sentence with themaximal judgment (such as s1 and s2 in Sec.
2.2)and labeled it as positive if it answered the questioneither concisely or with noise, negative otherwise.The resulting WEB-QA corpus contains 1309 sen-tences, 416 of which positive; the TREC-QA corpuscontains 2256 sentences, 261 of which positive.3.2 ResultsIn a first experiment, we compared the learning andclassification efficiency of SVMs on PASs by apply-ing either solely PAS-SSTK or solely PAS-PTK onthe WEB-QA and TREC-QA sets.
We divided thetraining data in 9 bins of increasing size (with a step3Toolkit available at dit.unitn.it/moschitti/, basedon SVM-light (Joachims, 1999)020406080100120140160180200220240200 400 600 800 1000 1200 1400 1600 1800Training Set SizeTimeinSecondsPTK (training) PTK (test)SSTK (test) SSTK (training)Figure 2: Efficiency of PTK and SSTK606162636465666768691.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0cost-factorF1-measurePT+WSK+PAS(PTK) PTPT+BOW PT+POSPT+WSK WSKBOW PT+WSK+PAS(SSTK)Figure 3: Impact of different kernels on WEB-QA20222426283032343638404 6 8 10 12 14 16 18 20cost-factorF1-measurePT POS+PTPOSSK+PT POSSK+PT+PAS-PTKBOW+PT BOW+POS+PTBOW POSSK+PT+PAS-SSTKFigure 4: Impact of different kernels on TREC-QAof 200) and measured the training and test time4 foreach bin.
Figure 2 shows that in both the test andtraining phases, PTK is much faster than SSTK.
Intraining, PTK is 40 times faster, enabling the exper-imentation of SVMs with large datasets.
This differ-ence is due to the combination of our lighter seman-tic structures and the PTK?s ability to extract fromthese at least the same information that SSTK de-rives from much larger structures.Further interesting experiments regard the accu-4Processing time in seconds of a Mac-Book Pro 2.4 Ghz.115racy tests of different kernels and some of their mostpromising combinations.
As a kernel operator, weapplied the sum between kernels5 that yields thejoint feature space of the individual kernels (Shawe-Taylor and Cristianini, 2004).Figure 3 shows the F1-plots of several kernels ac-cording to different cost-factor values (i.e.
differentPrecision/Recall rates).
Each F1 value is the averageof 5 fold cross-validation.
We note that (a) BOWachieves very high accuracy, comparable to the oneproduced by PT; (b) the BOW+PT combination im-proves on both single models; (c) WSK improves onBOW and it is enhanced by WSK+PT, demonstrat-ing that word sequences and PTs are very relevantfor this task; (d) both PAS-SSTK and PAS-PTK im-prove on previous models yielding the highest result.The high accuracy of BOW is surprising as sup-port vectors are compared with test examples whichare in general different (there are no questionsshared between training and test set).
The explana-tion resides in the fact that WEB-QA contains com-mon BOW patterns due to typical Web phrasings,e.g.
Learn more about X, that facilitate the de-tection of incorrect answers.Hence, to have un-biased results, we experi-mented with the TREC corpus which is cleaner froma linguistic viewpoint and also more complex froma QA perspective.
A comparative analysis of Fig-ure 4 suggests that: (a) the F1 of all models is muchlower than for the WEB-QA dataset; (b) BOW de-notes the lowest accuracy; (c) POS combined withPT improves on PT; (d) POSSK+PT improves onPOS+PT; (f) finally, PAS adds further informationas the best model is POSSK+PT+PAS-PTK (or PAS-SSTK).4 ConclusionsWith respect to our previous findings, experimentingwith TREC-QA allowed us to show that BOW is notrelevant to learn re-ranking functions from exam-ples; indeed, while it is useful to establish an initialranking by measuring the similarity between ques-tion and answer, BOW is almost irrelevant to grasptypical rules that suggest if a description is valid ornot.
Moreover, using the new POSSK and PAS-PTK5All adding kernels are normalized to have a similarity scorebetween 0 and 1, i.e.
K?
(X1,X2) = K(X1,X2)?K(X1,X1)?K(X2,X2) .kernels provides an improvement of 5 absolute per-cent points wrt our previous work.Finally, error analysis revealed that PAS-PTK canprovide patterns like A1(X) R-A1(that) rel(result)A1(Y) and A1(X) rel(characterize) A0(Y), where Xand Y need not necessarily be matched.AcknowledgmentsThis work was partly supported by the FP6 IST LUNAproject (contract No.
33549) and by the EuropeanCommission Marie Curie Excellence Grant for theADAMACH project (contract No.
022593).ReferencesJ.
Allan.
2000.
Natural language processing for informa-tion retrieval.
In Proceedings of NAACL/ANLP (tuto-rial notes).Y.
Chen, M. Zhou, and S. Wang.
2006.
Reranking an-swers from definitional QA using language models.
InACL?06.M.
Collins and N. Duffy.
2002.
New ranking algorithmsfor parsing and tagging: Kernels over discrete struc-tures, and the voted perceptron.
In ACL?02.K.
Collins-Thompson, J. Callan, E. Terra, and C. L.A.Clarke.
2004.
The effect of document retrieval qualityon factoid QA performance.
In SIGIR?04.T.
Joachims.
1999.
Making large-scale SVM learningpractical.
In B. Scho?lkopf, C. Burges, and A. Smola,editors, Advances in Kernel Methods - Support VectorLearning.P.
Kingsbury and M. Palmer.
2002.
From Treebank toPropBank.
In LREC?02.X.
Li and D. Roth.
2002.
Learning question classifiers.In ACL?02.A.
Moschitti, B. Coppola, A. Giuglea, and R. Basili.2005.
Hierarchical semantic role labeling.
In CoNLL2005 shared task.A.
Moschitti, S. Quarteroni, R. Basili, and S. Manand-har.
2007.
Exploiting syntactic and shallow semantickernels for question/answer classification.
In ACL?07.A.
Moschitti.
2006.
Efficient convolution kernelsfor dependency and constituent syntactic trees.
InECML?06.S.
Quarteroni and S. Manandhar.
2008.
Designing aninteractive open domain question answering system.Journ.
of Nat.
Lang.
Eng.
(in press).J.
Shawe-Taylor and N. Cristianini.
2004.
Kernel Meth-ods for Pattern Analysis.
Cambridge University Press.D.
Shen and M. Lapata.
2007.
Using semantic roles toimprove question answering.
In EMNLP-CoNLL.E.
M. Voorhees.
2001.
Overview of the TREC 2001Question Answering Track.
In TREC?01.116
