Proceedings of the 6th EACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 55?64,Avignon, France, 24 April 2012. c?2012 Association for Computational LinguisticsLinguistically-Adapted Structural Query Annotation for Digital Li-braries in the Social SciencesCarol ine Brun Vassilina Nikoulina Nikolaos LagosXerox Research Centre Europe6, chemin de Maupertuis38240, Meylan France{firstname.lastname}@xrce.xerox.comAbstrac tQuery processing is an essential part of arange of applications in the social sciencesand cultural heritage domain.
However, out-of-the-box natural language processing toolsoriginally developed for full phrase analysisare inappropriate for query analysis.
In thispaper, we propose an approach to solvingthis problem by adapting a complete and in-tegrated chain of NLP tools, to make it  suit-able for queries analysis.
Using as a casestudy the automatic translation of queriesposed to the Europeana library, we demon-strate that adapted linguistic processing canlead to improvements in translation quality.1 IntroductionQuery processing tools are essential componentsof digital libraries and content aggregators.
Theiroperation varies from simple stop word removaland stemming to advanced parsing, that treatsqueries as a collection of phrases rather than sin-gle terms (Mothe and Tanguy, 2007).
They areused in a range of applications, from informationretrieval (via search engines that provide accessto the digital collections) to query analysis.Current query processing solutions tend touse out-of-the-box Natural Language Processing(NLP) tools that were originally developed forfull phrase analysis, being inappropriate forquery analysis.Correct query annotation and interpretation iseven more important in the cultural heritage orsocial sciences domain, as a lot of the contentcan be in multimedia form and only metadata(most of the times in the form of tags) is exploit-able by traditional text-oriented information re-trieval and analysis techniques.Furthermore, as recent studies of user query-ing behavior mention, queries in these domainsare not only very short but are also quite specificin terms of content: they refer to artist names,titles, dates, and objects (Koolen and Kamps,2010; Ireson and Oomen, 2007).
Take the exam-ple of a query like ?coupe apollon?
(?bowl apol-lon?).
While in standard analysis ?coupe?
wouldbe identified as a verb (?couper?, i.e.
?to cut?
), inthe context of a query it should be actuallytagged as a noun, which refers to an object.
Sucha difference may lead to different preprocessingand worse retrieval.In this paper, we propose an approach to solv-ing this problem by adapting a complete and in-tegrated chain of NLP tools, based on the XeroxIncremental Parser (XIP), to make it suitable forqueries?
analysis.
The adaptation includes recapi-talization, adapted Part of Speech (PoS) tagging,adapted chunking and Named Entities (NE) rec-ognition.
We claim that several heuristics espe-cially important for queries?
analysis, such asfavoring nominal interpretations, result in im-proved linguistic structures, which can have animpact in a wide range of further applications(e.g.
information retrieval, query translation, in-formation extraction, query reformulation etc.
).2 Prior artThe problem of adapted query processing, oftenreferred to as structural query annotation, in-cludes capitalization, NEs detection, PoS taggingand query segmentation.
Most of the existingworks treat each of these steps independently andaddress only one of the above issues.Many works address the problem of querysegmentation.
According to Tan and Peng(2008), query segmentation is a problem which isclose to the chunking problem, but the chunkingproblem is directly linked to the PoS tagging re-sults, which are often noisy for the queries.
Thus,most of the works on query segmentation arebased on the statistical interaction between a pairof query words to identify the border between thesegments in the query (Jones et al, 2006; Guo et55al., 2008).
Tan and Peng (2008) propose a gen-erative language model enriched with Wikipediato identify ?concepts?
rather than simply ?fre-quency-based?
patterns.
The segmentation pro-posed by Bergsma and Wang (2007) is closer tothe notion of NP chunking.
They propose a ma-chine-learned query segmentation system trainedon manually annotated set of 500 AOL queries.However, in this work PoS tagging is used as oneof the features in query segmentation and is donewith a generic PoS tagger, non adapted for que-ries.PoS tagging is an important part of queryprocessing and used in many information ana-lytics tasks (query reformulation, query segmen-tation, etc.).
However very few works addressquery-oriented PoS tagging.
Allan and Raghavan(2002) consider that PoS tagging might be am-biguous for short queries and propose to interactwith the user for disambiguation.
Barr et al(2008) produce a set of manually annotated que-ries, and then train a Brill tagger on this set inorder to create an adapted PoS tagger for searchqueries.A notable work is the one by Bendersky et al(2010), which addresses the capitalization, PoStagging and query segmentation in the same pa-per.
However, this approach proposes for each ofthe above steps a probabilistic model that relieson the document corpus rather on the query it-self.
Such an approach is not applicable for mostdigital content providers who would reluctantlygive access to their document collection.
More-over, the query expansion, which is the centralidea of the described approach, is not possible formost of digital libraries that are organized in adatabase.
Secondly, Bendersky et al (2010) pro-poses adapting each processing step independ-ently.
Although this is not mentioned in thepaper, these three steps can be applied in a se-quence, where PoS tagging can profit from therecapitalization, and chunking from the PoS tag-ging step.
However, once the recapitalization isdone, it can not be changed in the followingsteps.
This work doesn?t address the adaptationof the NE recognition component, as we do, andwhich might change the final chunking and PoStagging in certain cases.In our approach, part of the recapitalization isdone during the PoS tagging, in interaction withthe NE recognition, which allows us to considerthese two steps as interleaved.
Moreover, thelinguistic processing we propose is generic: cor-pus-independent (at least most of its parts exceptfor NE recognition) and doesn?t require access tothe document collection.3 DataThis work is based on search logs from Euro-peana 14 Motivation.
These are real users?
queries, whereNamed Entities are often lowercased and thestructures are very different from normal phrasestructure.
Thus, this data is well adapted to dem-onstrate the impact of adapted linguistic process-ing.We show the importance of the adapted linguisticquery processing using as example the task ofquery translation, a real need for today?s digitalcontent providers operating in a multilingual en-vironment.
We took a sample of Europeana que-ries and translated them with different MTsystems: in-house (purely statistical) or availableonline (rule-based).
Some examples of problem-atic translations are shown in the Table 1.Input query AutomaticTranslationHumantranslationFrench-English1journal pano-rama parisnewspaperpanorama betsnewspaperpanoramaparis2 saint jean deluzsaint jean ofluzsaint jeande luz3 vie et mortde l?imagelife and died ofthe imagelife anddeath ofimage4 langue etr?alit?and the realityof languagelanguageand realityEnglish-French5 maps europe trace l?Europe cartes del?Europe6 17th centurysawDu 17?mesi?cle a vuscie du17?mesi?cle7 chopingeorge sandgeorge sablechopin soitchopingeorgesandTable 1: Examples of the problematic querytranslations1 A portal that acts as an interface to millions of digitizedrecords, allowing users to explore Europe?s cultural heri-tage.
For more information please visithttp://www.europeana.eu/portal/56Although in general, the errors done by statis-tical and rule-based models are pretty different,there are some common errors done in the caseof the query translation.
Both models, being de-signed for full-sentence translation, find thequery structure very unnatural and tend to repro-duce the full sentence in the output (ex.
1, 3, 4, 5,6).
The errors may come either from a wrongPoS tagging (for rule-based systems), or from thewrong word order (statistical-based systems), orfrom the choice of the wrong translation (bothtypes of systems).One might think that the word order problemis not crucial for queries, because most of the IRmodels use the bag of words models, which ig-nore the order of words.
However, it might mat-ter in some cases: for example, if and/or areinterpreted as a logical operator, it is important toplace them correctly in the sentence (examples3,4).Errors also may happen when translating NEs(ex.1, 2, 7).
The case information, which is oftenmissing in the real-life queries, helps to deal withthe NEs translation.The examples mentioned above illustrate thatadapted query processing is important for a tasksuch as query translation, both in the case ofrule-based and empirical models.
Although theempirical models can be adapted if an appropri-ately sized corpus exists, such a corpus is notalways available.Thus we propose adapting the linguistic proc-essing prior to query translation (which is furtherintegrated in the SMT model).
We demonstratethe feasibility and impact of our approach basedon the difference in translation quality but theadaptations can be useful in a number of othertasks involving query processing (e.g.
questionanswering, query logs analysis, etc.
).5 Linguistic Processing AdaptationAs said before, queries have specific linguisticproperties that make their analysis difficult forstandard NLP tools.
This section describes theapproach we have designed to improve querychunking.
Following a study of the corpus ofquery logs, we rely on the specific linguisticproperties of the queries to adapt different stepsof linguistic analysis, from preprocessing tochunking.These adaptations consist in the followingvery general processes, for both English andFrench:Recapitalization: we recapitalize, in a preproc-essing step, some uncapitalized words in queriesthat can be proper nouns when they start with acapital letter.Part of Speech disambiguation?
the part of speech tagging favors nominalinterpretation (whereas standard part ofspeech taggers are designed to find a verb inthe input, as PoS tagging generally applieson complete sentences);:?
the recapitalization information transmittedfrom the previous step is used to change thePoS interpretation in some contexts.Chunking?
considering that a full NE is a chunk, whichis not the case in standard text processing,where a NE can perfectly be just a part of achunk;:  the chunking is improved by:?
grouping coordinated NEs of the same type;?
performing PP and AP attachment with theclosest antecedent that is morphologicallycompatibleThese processes are very general and may ap-ply to queries in different application domains,with maybe some domain-dependent adaptations(for example, NEs may change across domains).These adaptations have been implementedwithin the XIP engine, for the French and Eng-lish grammars.
The XIP framework allows inte-grating the adaptations of different steps of queryprocessing into a unified framework, where thechanges from one step can influence the result ofthe next step: the information performed at agiven step is transmitted to the next step by XIPthrough linguistic features.5.1 PreprocessingQueries are often written with misspelling errors,in particular for accents and capital letters ofNEs.
See the following query examples extractedfrom our query log corpus:lafont Robert (French query)henry de forge et jean maucl?re(French query)muse prado madrid (French query)carpaccio queen cornaro (Englishquery)man ray (English query)This might be quite a problem for linguistictreatments, like PoS tagging and of course NE57recognition, which often use capital letter infor-mation as a triggering feature.Recapitalizing these words at the preprocess-ing step of a linguistic analysis, i.e.
during themorphological analysis, is technically relativelyeasy, however it would be an important generatorof spurious ambiguities in the context of full sen-tence parsing (standard context of linguistic pars-ing).
Indeed, considering that all lower casewords that can be proper nouns with a capitalletter should also have capitalized interpretation,such as price, jean, read, us, bush, lay, etc., inEnglish or pierre, m?decin, ?
in French) wouldbe problematic for a PoS tagger as well as for aNE recognizer.
That?s why it is not performed ina standard analysis context, considering also thatmisspelling errors are not frequent in ?standard?texts.
In the case of queries however, they arefrequent, and since queries are far shorter in av-erage than full sentences the tagging can beadapted to this context (see next section), we canafford to perform recapitalization using the fol-lowing methodology, combining lexical informa-tion and contextual rules:1.
The preprocessing lexicon integrates allwords starting with a lower case letterwhich can be first name (henry, jean,isaac ?
), family and celebrity name(chirac, picasso...) and  place names(paris, saint p?tersbourg, ?)
when capi-talized.2.
When an unknown word starting with alower case letter is preceded by a firstname and eventually by a particle (de,van, von ?
), it is analyzed as a lastname, in order to be able to trigger stan-dard NE recognition.
This is one exam-ple of interleaving of the processes: herepart-of-speech interpretation is condi-tioned by the recapitalization steps whichtransmits information about recapitaliza-tion (via features within XIP) that trig-gers query-specific pos disambiguationrules.The recapitalization (1) has been imple-mented within the preprocessing components ofXIP within finite state transducers (see (Kart-tunen, 2000)).
The second point (2) is done di-rectly within XIP in the part-of-speech taggingprocess, with a contextual rule.
For example, theanalysis of the input query ?jean maucl?re?
getsthe following structure and dependency outputwith the standard French grammar.Query: jean maucl?reNMOD(jean, maucl?re)0>GROUP[NP[jean] AP[maucl?re]]Because jean is a common noun and maucl?reis an unknown word which has been guessed asan adjective by the lexical guesser.It gets the following analysis with the pre-processing adaptations described above:NMOD(jean,maucl?re)PERSON_HUM(jean maucl?re)FIRSTNAME(jean,jean maucl?re)LASTNAME(maucl?re,jean maucl?re)0>GROUP[NP[NOUN[jean maucl?re]]]Because jean has been recognized as a firstname and consequently the unknown word afterhas been inferred has a proper noun (last name)by the pos tagging contextual rule; the recapitali-zation process and part-of-speech interpretationare therefore interleaved.5.2 Part of speech disambiguationIn the context of query analysis, part-of-speechtagging has to be adapted also, since standardpart-of-speech disambiguation strategies aimgenerally at disambiguating in the context of fullsentences.
But queries are very different fromfull sentences: they are mostly nominal withsometimes infinitive, past participial, or gerun-dive insertions, e.g.
:statuettes hommes jouant avec unchien (French query)coupe apollon (French query)architecture musique (Frenchquery)statue haut relief grecque du 5siecle (French query)david playing harp fpr saul (Eng-lish query)stained glass angel (Englishquery)Standard techniques for part-of-speech tag-ging include rule based methods and statisticalmethods, mainly based on hidden Markov mod-els (see for example (Chanod and Tapanainen,1995)).
In this case, it would be possible to re-compute the probabilities on a corpus of queriesmanually annotated.
However, the correction ofpart-of-speech tags in the context of queries iseasy to develop with a small set of rules.
We fo-cus on English and French, and in queries, themain problems come from the ambiguity be-58tween noun and verbs, which has to be solveddifferently than in the context of a standard sen-tence.The approach we adopt to correct the taggingwith the main following contextual rules:?
If there is a noun/verb ambiguity:?
If the ambiguity is on the first word ofthe query (e.g.
?coupe apollon?, ?oil?
If the ambiguity is on the second word ofthe query, prefer the noun interpretationif the query starts with an adjective or anoun (e.g.
in ?youngflask?
), select the noun interpretation;people?
Select noun interpretation if there is noperson agreement with one of the previ-ous nouns (e.g.
?les fr?ressocial com-petences?, select the noun interpretationfor people, instead of verb)bissons?
For a verb which is neither at the pastparticiple form nor the infinitive form,select the noun interpretation if it is notfollowed by a determiner (e.g.
?tremble-ment?,fr?res belongs to the 3rd person but bis-sons to the 1st one of the verb ?bisser?)terre?
Choose the noun interpretation if theword is followed by a conjunction and anoun or preceded by a noun and a con-junction (e.g.
in ?gauguinlisbonne?, terre is disambigu-ated as a noun?
))moon andearth?, choose the noun interpretationfor moon, instead of verb2?
In case of ambiguity between adjective andpast participle verb, select the adjective in-terpretation if the word is followed by anoun (e.g.
?stained glass angel?, stained isdisambiguated as an adjective instead of apast participle verb)).5.3 ChunkingThe goal of chunking is to assign a partialstructure to a sentence and focuses on easy toparse pieces in order to avoid ambiguity and re-cursion.
In the very specific context of queryanalysis, and once again since queries have spe-cific linguistic properties (they are not sentencesbut mostly nominal sequences), chunking can beimproved along several heuristics.
We proposehere some adaptations to improve query chunk-2To moon abouting to deal with AP and PP attachment, and co-ordination, using also NE information to guidethe chunking strategy.AP and PP attachmentIn standard cases of chunking, AP and PP at-tachment is not considered, because of attach-ment ambiguity problems that cannot be solvedat this stage of linguistic analysis.Considering the shortness of queries and thefact that they are mostly nominal, some of theseattachments can be solved however in this con-text.For the adjectival attachment in French, weattach the post modifier adjectival phrases to thefirst previous noun with which there is agreementin number and gender.
For example, the chunk-ing structure for the query ?Biblioth?que eu-ropeenne numerique?
is:NP[ [Biblioth?que AP[europeenne]AP[numerique] ]while it isNP[Biblioth?que] AP[europeenne]AP[numerique]with our standard French grammar.For PP attachment, we simply consider thatthe PP attaches systematically to the previousnoun.
For example, the chunking structure for?The history of the University of Oxford?
is:NP[the history PP[of the UniversityPP[of Oxford] ] ]instead of:NP[The history] PP[of the Univer-sity] PP[of  Oxford ]CoordinationSome cases of coordination, usually very com-plex, can be solved in the query context, in par-ticular when NEs are involved.
For both Englishand French, we attach coordinates when theybelong to the same entity type (person conj per-son, date conj date, place conj place, etc.
), forexample, ?vase achilles et priam?
:NP[vase] NP[Achille et Priam]instead of:NP[vase] NP[Achille] et NP[Priam]59We also attach coordinates when the secondis introduced by a reflexive pronoun, such as in:?
[Le laboureur et ses enfants] La Fontaine?
andattach coordinates within a PP when they are in-troduced by the preposition ?entre?
in Frenchand ?between?
in English.Use of NE information to guide the chunkingstrategyWe also use information about NEs present inthe queries to guide the query chunking strategy.In standard analysis, NEs are generally part oflarger chunking units.
In queries, however, be-cause of their strong semantic, they can be iso-lated as separate chunking units.
We haveadapted our chunking strategy using this infor-mation: when the parser detects a NE (includinga date), it chunks it as a separate NP.
The follow-ing examples show the chunking results for thisadapted strategy versus the analysis of standardgrammar:?
?Anglo Saxon 11th century?
(English)Adapted chunking:NP[Anglo Saxon] NP[ 11th century]Standard chunking:NP[Anglo Saxon 11th century ]?
?Alexandre le Grand Persepolis?
(French)Adapted chunking:NP[Alexandre le Grand] NP[Perspolis]Standard chunking:NP[Alexandre le Grand Perspolis]The whole process is illustrated in Figure 1.When applying the full chain on an examplequery like ?gauguin moon and earth?, we havethe following steps and result:Preprocessing: gauguin is recognized as Gauguin(proper noun of celebrity);Part of speech tagging:  moon is disambiguatedas a noun instead of a verb);Chunking:So we get the following structure:moon and earth are grouped togetherin a coordination chunk, gauguin is a NEchunked separately.NP[Gauguin] NP[moon and earth]and gauguin is recognized as a person name,instead ofSC 3 [NP[gauguin] FV 4Input queryQueryPreprocessingQuery POSDisambiguationQueryChunkingAdapted lexicalResources combinedwith contextual rulesImproved query structureAdapted strategy forPOS tagging(Contextual rules)Adapted Chunkingstrategy: contextualrules + named entities[moon]] andNP[earth],gauguin remaining unknown,  with the standardEnglish grammar.Fig 1: Linguistic processing adaptation for que-ries5.4 Examples of query structuresThe following table shows the differences ofquery structures obtained with the standard lin-guistic processing and with the adapted linguisticprocessing.1.
Albert Camus la pesteStandard LP: NP {albert}  AP {camus}NP {la peste}Adapted LP: NP {albert camus}  NP {lapeste}2. dieux ou h?ros grecStandard LP: NP {dieux}  COORD {ou}NP {h?ros}  AP {grec}3 SC: chunk tag for sentential clause4 FV: finite verb chunk60Adapted LP: NP {dieux}  COORD {ou}NP {h?ros grec}3. pierre berg?Standard LP: NP {pierre}  VERB {berg?
}Adapted LP: NP {pierre berg?
}Table 2:  Some examples of query structure producedby standard and adapted linguistic processing.The evaluation of this customization is doneindirectly through query translation, and is de-scribed in the next section6 Experiments6.1 Experimental settingsIn our experiments we tried to enrich our base-line SMT system with an adapted linguistic proc-essing in order to improve the query translation.These experiments have double goal.
First, toshow that the adapted linguistic processing al-lows to improve query translation compared to astandard linguistic processing, and second, toshow that enriching an SMT model with a lin-guistic processing (adapted) is helpful for thetranslation.We use an open source toolkit Moses (trainedon Europarl) as a baseline model for query trans-lations.
Based on the examples from the section5, we choose to integrate the chunking and NEinformation in the translation.
We integrate thisknowledge in the following way:?
Chunking: We check whether the querymatches one of the following patterns: ?NP1and NP2?, ?NP1 or NP2?, ?NP1 NP2?,?NP1, NP2?, etc.
If it is the case, the NPs aretranslated independently.
Thus, we makesure that the output query will preserve thelogical structure, if ?and/or?
are treated aslogical operators.
Also, translating NPs inde-pendently might result at different (hopefullybetter) lexical choices.?
Named entities: We introduce XML tags forperson names where we propose a possibletranslation.
During the translation process theproposed translation competes with the pos-sible translations from a bi-phrase library.The translation maximizing internal transla-tion score is chosen.
In these experiments wepropose not to translate an NE at all, how-ever in more general case we could imaginehaving an adapted NE dictionary.6.2 EvaluationWe have translated the totality of availableEuropeana French logs to English (8870 distinctqueries), with the following translation models:?
Moses trained on Europarl (BaselineMT)?
Baseline MT model enriched with lin-guistic processing (as defined in 6.1)based on basic grammar (Baseline MT +basic grammar)?
Baseline MT enriched with linguisticprocessing based on adapted grammar(Baseline MT + adapted grammar)Our approach brings two new aspects com-pared to simple SMT system.
First, an SMT sys-tem is enriched with linguistic processing asopposed to system without linguistic processing(baseline system), second: usage of an adaptedlinguistic processing as opposed to standard lin-guistic processing.
Thus, we evaluate:1.
The impact of linguistic processing onthe final query translations;2.
The impact of grammar adaptation(adapted linguistic processing) in thecontext of query translation.First, we measure the overall impact of eachof the two aspects mentioned above.
Table 3 re-flects the general impact of linguistic enrichmentand grammar adaptation on query structure andtranslation.First, we note that the linguistic processing asdefined in 6.1 won?t be applied to all queries.Thus, we count an amount of queries out of ourtest set to which this processing can actually beapplied.
This corresponds to the first line of theTable 3 (26% of all queries).Second, we compare the queries translationwith and without linguistic processing.
This isshown in the second line of the Table 3: theamount of queries for which the linguistic proc-essing lead to different translation (25% of que-ries for which the linguistic processing wasapplied).The second part of the table shows the differ-ence between the standard linguistic processingand an adapted linguistic processing.
First, wecheck how many queries get different structureafter grammar adaptation (Section 5) (~42%) andsecond, we check how many of these queries61actually get different translation (~16% querieswith new structure obtained after adaptation getdifferent translations).These numbers show that the linguisticknowledge that we integrated into the SMTframework may impact a limited portion of que-ries?
translations.
However, we believe that thisis due, to some extent, to the way the linguisticknowledge was integrated in SMT, which ex-plores only a small portion of the actual linguis-tic information that is available.
We carried outthese experiments as a proof of concept for theadapted linguistic processing, but we believe thata deeper integration of the linguistic knowledgeinto the SMT framework will lead to more sig-nificant results.
For example, integrating such anadapted linguistic processing in a rule-based MTsystem will be straightforward and beneficial,since the linguistic information is explored di-rectly by a translation model (e.g.
in the example6 in Table 1 tagging "saw" as a noun will defi-nitely lead to a better translation).Next, we define 2 evaluation tasks, where thegoal of each task is to compare 2 translationmodels.
We compare:1.
Baseline MT versus linguistically en-riched translation model (Baseline MT+adaptedadapted linguistic processing).
This task evalu-ates the impact of linguistic enrichment in thequery translation task with SMT.2.
Translation model using standard lin-guistic processing versus translation model usingadapted linguistic processing.
This task evalu-ates the impact of the adapted linguistic process-ing in the query translation task.For each evaluation task we have randomlyselected a sample of 200 translations (excludingpreviously the identical translations for the 2models compared) and we perform a pairwiseevaluation for each evaluation task.
Thus, for thefirst evaluation task, a baseline translation (per-formed by standard Moses without linguisticprocessing) is compared to the translation doneby Moses + adapted linguistic processing.
In thesecond evaluation task, the translation performedby Moses + standard linguistic processing iscompared to the translation performed by Moses+ adapted linguistic processing.The evaluation has been performed by 3evaluators.
However, no overlapping evaluationshave been performed to calculate intra-evaluatorsagreement.
We could observe, however, the simi-lar tendency for improvement in each on theevaluated sample (similar to the one shown in theTable 2).We evaluate the overall translation perform-ance, independently of the task in which thetranslations are going to be used afterwards (textTable 3: Impact of linguistic processing andgrammar adaptation for query translationunderstanding, text analytics, cross-lingual in-formation retrieval etc.
)The difference between slight improvementsand important improvements as in the examplesbelow has been done during the evaluation.src1: max webert1:max mr webert2:max weber (slight improvement)src2: albert camus la pestet1:albert camus fevert2:albert camus the plague (impor-tant improvement)Thus, each pair of translations (t1, t2) re-ceives a score from the scale [-2, 2] which canbe:?
2, if t2 is much better than t1,?
1, if t2 is better than t1,?
0, if t2 is equivalent to t1,?
-1, if t1 is better than t2,?
-2, if t1 is much better than t2,Linguistic enrichmentNb of  queries to which the adaptedlinguistic processing was appliedbefore translation.2311(26% of8870)Nb of translations which differbetween baseline Moses and Moseswith adapted linguistic processing.582(25% of2311)Grammar adaptationNb of queries which get differentstructures between standard linguisticprocessing and adapted linguisticprocessing.3756(42% of8870)Nb of translations which differbetween Moses+standard linguisticprocessing and Moses+adaptedlinguistic processing638(16 %  of3756)62Table 4 presents the results of translationevaluation.Note, that a part of slight decreases can becorrected by introducing an adapted named enti-ties dictionary to the translation system.
For ex-ample, for the source query ?romeo et juliette?,keeping NEs untranslated results at the followingtranslation: ?romeo and juliette?, which is con-sidered as a slight decrease in comparison to abaseline translation: ?romeo and juliet?.
Creatingan adapted NEs dictionary, either by crawlingWikipedia, or other parallel resources, might behelpful for such cases.Often, the cases of significantly better transla-tions could potentially lead to the better retrieval.For example, a better lexical choice (don juanmoliere vs. donation juan moliere, the plague vs.fever) often judged as significant improvementmay lead to a better retrieval.Based on this observation one may hope thatthe adapted linguistic processing can indeed beuseful in the query translation task in CLIR con-text, but also in general query analysis context.7 ConclusionQueries posed to digital library search engines inthe cultural heritage and social sciences domaintend to be very short, referring mostly to artistnames, objects, titles, and dates.
As we have il-lustrated with several examples, taken from thelogs of the Europeana portal, standard NLPanalysis is not well adapted to treat that domain.In this work we have proposed adapting a com-plete chain of linguistic processing tools forquery processing, instead of using out-of-the-boxtools designed to analyze full sentences.Focusing on the cultural heritage domain, wetranslated queries from the Europeana portal us-ing a state-of-the-art machine translation systemand evaluated translation quality before and afterapplying the adaptations.
The impact of the lin-guistic adaptations is quite significant, as in 42%of the queries the resulting structure changes.Subsequently, 16% of the query translations arealso different.
The positive impact of the adaptedlinguistic processing on the translation quality isevident, as for 99 queries the translation (out of200 sample evaluated) is improved when com-pared to having no linguistic processing.
We ob-serve also that 78 queries are better translatedafter adapting the linguistic processing compo-nents.Our results show that customizing the linguis-tic processing of queries can lead to importantimprovements in translation (and eventually tomultilingual information retrieval and data min-ing).
A lot of the differences are related to theability of properly identifying and treating do-main-specific named entities.
We plan to furtherresearch this aspect in future works.Acknowledge mentsThis research was supported by the EuropeanUnion?s ICT Policy Support Programme as partof the Competitiveness and Innovation Frame-work Programme, CIP ICT-PSP under grantagreement nr 250430 (Project GALATEAS).ReferencesBin Tan and Fuchun Peng.
2008.
Unsupervised querysegmentation using generative language modelsand wikipedia.
In Proceedings of the 17th interna-tional conference on World Wide Web (WWW'08).
ACM, New York, NY, USA, 347-356.Cory Barr, Rosie Jones, Moira Regelson.
2008.
TheLinguistic Structure of EnglishWeb-Search Que-ries, Proceedings of ENMLP'08, pp 1021?1030,Octobre 2008, Honolulu.James Allan and Hema Raghavan.
2002.
Using part-of-speech patterns to reduce query ambiguity.
InProceedings of the 25th annual international ACMSIGIR conference on Research and development ininformat ion retrieval (SIGIR '02).
ACM, NewYork, NY, USA, 307-314.Jeann-Pierre Chanod, Pasi Tapanainen.
1995.
Tag-ging French - comparing a statistical and a con-straint-based method.
Proc.
From Texts To Tags:Important++Totalnb+Important- -Totalnb -OverallimpactMoses<Moses+adapted35 87 4 19 99Moses+basic<Moses+adapted28 66 2 12 80Table 4: Translation evaluation.
Total nb+ (-): totalnumber of improvements (decreases), not distinguish-ing whether it is slight or important; important ++ (--):the number of important improvements (decreases).Overall impact = (Total nb+) + (Importan++ ) ?
(Totalnb-) ?
(Important --)63Issues In Multilingual Language Analysis, EACLSIGDAT workshop.
Dublin, 1995.Jiafeng Guo, Gu Xu, Hang Li, Xueqi Cheng.
2008.
AUnified and Discriminative Model for Query Re-finement.
Proc.
SIGIR?08, July 20?24, 2008, Sin-gapore.Josiane Mothe and Ludovic Tanguy.
2007.
LinguisticAnalysis of Users' Queries: towards an adaptive In-formation Retrieval System.
International Confer-ence on Signal-Image Technology & Internet?Based Systems, Shangai, China, 2007.http://halshs.archives-ouvertes.fr/halshs-00287776/fr/ [Last accessed March 3, 2011]Lauri Karttunen.
2000.
Applications of Finite-StateTransducers in Natural Language Processing.
Pro-ceedings of CIAA-2000.
Lecture Notes in Com-puter Science.
Springer Verlag.Marijn Koolen and Jaap Kamps.
2010.
Searching cul-tural heritage data: does structure help expertsearchers?.
In Adaptivity, Personalizat ion and Fu-sion of Heterogeneous Information (RIAO '10).
Lecentre des hautes etudes internationalsd?informat ique documentaire, Paris, France, 152-155.Michael Bendersky, W. Bruce Croft and David A.Smith.
2010.
Structural Annotation of Search Que-ries Using Pseudo-Relevance Feedback.
Proceed-ings of CIKM'10, October 26-29, 2010, Toronto,Ontario, CanadaNeil Ireson and Johan Oomen.
2007.
Capturing e-Culture: Metadata in MultiMatch., J.
In Proc.DELOS-MultiMatch workshop, February 2007,Tirrenia, Italy.Rosie Jones, Ben jamin Rey, Omid Madani, and WileyGreiner.
2006.
Generating query substitutions.
InProceedings of the 15th international conference onWorld Wide Web (WWW '06).
ACM, New York,NY, USA, 387-396.Shane Bergsma and Qin Iris Wang.
2007.
LearningNoun Phrase Query Segmentation, Proceedings ofthe 2007 Jo int Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pp.
819?826, Prague,June 2007.64
