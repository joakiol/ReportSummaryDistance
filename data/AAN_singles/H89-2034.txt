Speaker Adaptation Using Multiple Reference SpeakersFrancis  Kubala,  R ichard Schwartz ,  Chris Bar ryBBN Systems and Technolog ies  Corporat ionCambr idge,  MA 02138ABSTRACTWe introduce a new technique for using the speech ofmultiple reference speakers as a basis for speaker adap-tation in large vocabulary continuous peech recogni-tion.
In contrast o other methods that use a pooledreference model, this technique normalizes the trainingspeech from multiple reference speakers to a single com-mon feature space before pooling it.
The normalized andpooled speech can then be treated as if it came from asingle reference speaker for training the reference hiddenMarkov model (HMM).
Our usual prohabilistic spectrumtransformation can be applied to the reference HMM tomodel a new (target) speaker.
In this paper, we de-scribe our baseline (single reference speaker) speaker-adaptation system and give current performance r sultsfrom a recent formal evaluation of the system.
We alsodescribe our proposal for adapting from multiple refer-ence speakers and report on recent preliminary experi-mental results in support of the proposed technique.1 INTRODUCTIONWe have, in the past, reported our work in speaker adap-tation for large vocabulary continuous peech recog-nition using a probabilistic spectral mapping \[5\].
Inthat work we transformed well-trained phonetic hiddenMarkov models of a single reference speaker so thatthey were appropriate for a new (target) speaker.
Thismethod reduced the recognition error rate by about afactor of five relative to a cross-speaker model (trainedon one speaker, tested on another).
However, the result-ing error rate was still 2 to 3 times that obtained with aspeaker-dependent model for the target speakers.In recent years several researchers have demonstratedspeaker-independent recognition using essentially thesame recognition algorithms used for speaker-dependentrecognition, but with a model derived by simply pool-ing the training speech of over 100 speakers as if itall were produced by one speaker.
For these systems,the error rate is again 2 to 3 times that of speaker-dependent models.
This shows that there is value insimple pooling of data from many speakers.
The logi-cal extension of these two results would be to use thepooled speaker-independent model as a reference modelfor speaker adaptation.
However, we know that pooledtraining yields a model that has very broad (less dis-"criminating) distributions compared to those produced byspeaker-dependent training.
Since the adaptation proce-dures that we have investigated also smooth the originalmodel, we expect hat a straightforward application ofthem to a pooled speaker-independent model will fail toyield improvements due to excessive smoothing.The approach we propose here consists of three steps:1) To reduce the smearing of the model distributions,we estimate and apply a deterministic spectral transfor-mation to each reference speaker so that their speechparameters lie in a single common space.2) We then treat all the transformed speech as if it camefrom one speaker for training the reference HMM.3) Finally, we estimate and apply our usual probabilisticspectrum transformation to the pooled reference HMMto model a new target speaker.In the next section, we describe our basic speaker-adaptation system in terms of its two primary speaker-transformation strategies; peech normalization and PDFmapping.
Section 3 contains experimental results whichestablish our current performance for a single referencespeaker system and introduce preliminary evidence insupport of our proposal for using multiple referencespeakers.2 BASEL INE SYSTEM DESCRIPT IONOur current baseline speaker-adaptation system consistsof two distinct components, both of which estimate trans-formations between the reference and target speaker,with the goal of making one of them 'look' like the256other.
The first component estimates a deterministictransformation which is applied to the speech featuresof the reference (targe0 speaker.
After transformationwithin this speech normalization component, he speechfeatures of the reference (targe0 speaker are superim-posed upon the feature space of the target (reference).The second component estimates a probabilistic trans-formation which is applied to the HMM parameters ofthe reference speaker.
After Ixansformation by this PDFmapping component, he modified reference model canbe used as an approximation toa well-trained HMM forthe target speaker.
These two primary components ofthe system are described in more detail below.2.1 Speech NormalizationSpeech normalization is accomplished by aligning thespeech features of the reference and target speakers froma small training set of utterances of known (supervised)and pair-wise identical (script-dependen0 transcription.Dynamic time warping (DTW) is used to derive thealignment of a given pair of utterences.
The align-ments can then be used to estimate a deterministic non-parametric transformation to describe differences in thefeature spaces of the two speakers.
Any unsupervisedfeature conditioning which can be applied prior to theDTW is also performed by the speech normalizationcomponent.The normalization procedure has been described in \[2\]and is briefly summarized here:1.
Make a VQ codebook for one of the speakers.2.
Partition the feature space of one speaker by quantiz-ing that speaker's training speech.3.
Map the partitioning to the other speaker through theDTW alignment.4.
Compute the means of each sub-population definedby the VQ and the mapped-VQ.5.
Shift the features of one speaker by the difference inthe means of the corresponding sub-populations.6.
Go to (3) if the alignment MSE has not converged.The speech normalization procedure is typically appliediteratively since each application of steps (3) and (5)above reduce (or leave unchanged) the MSE of the align-ment.
Note that, in this procedure, the codebook is usedonly to partition the space of one speaker into compactregions to define the degrees of freedom in the non-parametric mapping between the speakers.
The align-ment of the paired utterances is computed on the original(unquantized) speech features.2.2 PDF MappingPDF mapping is accomplished by aligning the (normal-ized) speech features of the reference and target speaker,again using DTW.
This final alignment serves to definea pair-wise correspondence b tween the VQ spectra ofthe reference and target speakers which can be used toestimate a probabilistic mapping between them.
The VQspectra re determined by independent codebooks madefor each of the speakers.
The codebook for the targetspeaker is made from the limited training material avail-able for adaptation.
The computed mapping is then usedto modify the discrete HMM observation density param-eters of the reference model.The mapping procedure has been described in \[1\] andis summarized here:1.
Make VQ codebooks for both speakers.2.
Quantize the target and reference training speech.3.
Use DTW to define a set of co-occurring VQ pairs..4.
Accumulate frequency counts of the VQ co-occurrences into a count matrix.5.
Normalize the count matrix yielding a transformationmatrix.6.
Apply the transformation matrix to the referenceHMM (discrete) observation densities.The resulting Uamformed model is then used directly inrecognition as if it were a model derived from the targetspeaker.The transformation described above can be made moredetailed by defining a set of class-dependent matricesand labeling the states of the reference HMM with theirclass membership.
One easily implemented set of equiv-alence classes for a phoneme-based system such as BY-BLOS is the set of phoneme-dependent transformationsdefined by the phonemes in the lexicon.
Since the ref-erence speaker has provided enough speech to train ahigh-performance speaker-dependent HMM, the modelcan be used to automatically abel the reference speechprior to computing the spectral mapping.3 EXPERIMENTAL RESULTSSpeaker-adaptation encompasses a wide variety of prac-tical scenarios.
Our current speaker-adaptation algo-257fithms are suited to a batch-style, limited-training sce-nario appropriate for bringing a new speaker up to an ac-ceptable initial recognition performance l vel.
We haveconcentrated onthe new speaker start-up seenario, usingsupervised techniques on a small set of known trainingutterances, in the belief that supervised techniques aremost likely to succeed in the short term.In most of our development work, and in the ex-periments described below, we have used the speaker-dependent data from the 1000-word DARPA ResourceManagement continuous speech database \[4\].
All resultsreported here used 2 minutes (40 utterances) of adapta-tion material (limited-training) from the target speaker.The standard word-pair grammar, defined as part of thedatabase for evaluation purposes, was used in all casesexcept where specified otherwise.
The number of testspeakers and the identity of the test set vary across theexperiments described below, and are noted where im-portant.
Unless otherwise noted, the performance num-bers given for all experiments are:% Word Error = 100 x \[(substitutions + deletions+ insertions) / total number of  word tokens\]3.1 Single Reference SpeakersWe performed a series of experiments on the baseline(single reference speaker) system to examine several is-sues related to our proposal for using multiple referencespeakers.
The experiments described below investigatethe importance of feature conditioning for DTW, de-termine the effect of reference speaker identity on theestimation of the between-speaker transformations, andestablish a baseline performance l vel for the single ref-erence speaker system.3.1.1 Feature ConditioningThe raw speech parameters that we use (Mel-warpedcePstra, cepstral differences, normalized and differenceenergy) have widely varying dynamic ranges.
This ne-cessitates some form of feature pre-conditioning to avoiddegenerate alignments from the DTW.In the past, we have found that normalizing each fea-ture independently to unit-variance (computed over theadaptation utterances) provided a satisfactory and con-venient solution to the dynamic range problem.
Aftersuch a normalization, each feature contributes equallyon average to the alignment score computed by DTW.This simple approach performed marginally better thanweighting the original feature vectors to equalize thecontribution of each feature set to the DTW score.Condition Norm Only + PDF Mapping1) Unit Variance 52.1 6.92) + Zero-Mean 45.1 7.63) + Weighting 34.2 5.7Table 1.
Improvements in speech normalization fromfeature conditioning.The results shown in Table 1 compare three cases offeature conditioning, tested on six speakers.
The resultsgiven in the column labeled, Norm Only, were achievedby computing the feature transformation from the tar-get adaptation speech and applying it to the target's testspeech.
The transformed target speech was then quan-tized by the reference codebook and recognized usingthe reference (cross-speaker) HMM.
The results givenin the column labeled, + PDF Mapping, were achievedafter applying the PDF spectrum tranformation to thereference HMM.
For this condition, the target speech isquantized by a speaker-dependent codebook made fromthe target's adaptation speech.
The PDF mapping istherefore computed between two independent codebooksas in our standard baseline system.The unit variance condition (1) establishes a baselineperformance for the system.
This condition is similar"to the system configuration used for the results fromFeb.
'89 reported in \[3\].
For condition (2) in the table,the sample mean is removed from the speech featuresof both reference and target speakers after normalizingthe features to unit variance.
This yields a small im-provement for the Norm Only case but doesn't improvewhen the PDF transformation is used.
Condition (3) ap-plies a fixed, non-unit weighting to the features of bothspeakers after unit variance scaling and mean removal.This yields an additional 25% reduction in error for thenormalization alone and marginally improves the perfor-mance of the PDF mapping.
For this condition the cep-stral features (unit-variance normalized) of both speakerswere scaled by the square root of the cepstral index ofthe feature.
The normalized energy feature was scaledby x/~, while the difference nergy was left unchangedat unit variance.These results indicate that the DTW is sensitive tofeature conditioning when computing alignments for thepurpose of estimating a between-speaker normalization.258This indicates that further work is needed in feature con-ditioning and suggests that improvements to the iterativenormalization procedure itself may also be important.
Itis also evident hat the performance of the PDF mappingis largely independent of the quality of the normaliza-tion.
This result is important since we must rely moreheavily upon the feature normalization procedure whenusing multiple reference speakers as we propose.3.1.2 Current Baseline ResultsWe tested our baseline, single reference, speaker-adaptation system on new test data for the Oct. '89DARPA speech recognition evaluation.
We used the fea-ture conditioning enhancements described above.
In ad-dition the models for our standard reference speaker wereretrained using cross-word-boundary context-dependenttriphones.The reference model was trained from 30 minutes ofspeech (600 utterances).
Two minutes of speech (40utterances) from the target speaker was used to computethe transformations.
All development was done on thedesignated, May88 test set, consisting of 25 utterancesper speaker.The twelve speaker average word error rate for theOct.
'89 test set was 7.4% for the word-pair gram-mar and 28.7% for the no-grammar condition.
Theseaverage results are competitive with the best speaker-independent results being reported today (elsewhere inthese proceedings) on different, but comparable, testdata.
While the speaker-independent scenario requiresno adaptation speech from the target speaker, it does re-quire a large training data collection effort o provide ad-equate training for the (pooled) reference model.
Specifi-cally, speaker-independent training for the DARPA eval-uations utilizes about 3.5 hours (4000 utterances) of ref-erence speech from over 100 speakers.
In contrast, ourbaseline speaker-adaptation system uses only 30 min-utes (600 utterances) of reference speech from a singlespeaker to achieve the same performance.
This suggeststhat speaker-adaptation may offer a more economical p-proach for those applications which require rapid con-figuration on new task domains.Detailed Oct. '89 evaluation results for the word-pairgrammar are shown in Table 2 in order of increasingword error rate.
The results in the last column of thetable are:% Word Correct = 100 x \[1 - (substitutions +deletions) / total number of word tokens\].WordSpeaker ErrorHXS (F) 2.0DMS (F) 3.0JWS 3.3DAS (F) 3.7DTD (F) 4.8TAB 4.9PGH 5.0DTB 8.2CMR (F) 9.9BEF 13.3RK_M 13.8ERS 17.2AVG i 7.4Wo~Correct98.397.596.797.395.295.895.093.692.187.287.785.393.5Table 2.
Baseline speaker-adaptation system resultsfor Oct. '89 evaluation test with word-pair grammar.Curiously, the female target speakers tend to achievehigher recognition results despite the fact that the ref-erence speaker is male.
Also, these results show awide variance across speakers that is not consistent withspeaker-dependent results (elsewhere in these proceed-ings) obtained from these same speakers on the sametest material.In order to prove useful, speaker-adaptation must per-form reliably for most speakers, and must be consid-erably more powerful than can be demonstrated today.Below, we discuss everal possible strategies for improv-ing our speaker-adaptation performance.3.1.3 Alternate Reference SpeakersIn all of our previous work in speaker adaptation, oneparticular speaker has been used as the reference.
Herewe investigated the effect of the reference speaker'sidentity on recognition performance.
Our standardspeaker (male) was recorded at BBN in a normal officeenvironment and spoke in a clear deliberate style.
Thedevelopment training and test data, on the other hand,was collected at another site in a sound isolating booth,and the subjects (both male and female) often spoke incasual undirected styles.We tested the effect of reference speaker identity byselecting four additional speakers from the database tobe used as reference speakers.
The speakers were chosenwith the sole criterion that their speaker-dependent mod-259els performed better than the average of the 12 speakersin the database.Reference Word ErrRS 11.8TAB 10.7PGH 11.7DMS (F) 12.2DTD (F) 14.9Average 12.3Table 3.
Comparison of alternate reference speakersused for speaker-adaptation.In Table 3, we show results, averaged over five testspeakers, for each of five reference speakers.
Speaker,RS, is our standard reference speaker.
The results showthat selection of an adequate reference speaker is not adifficult task since three of the four new speakers cho-sen do as well as our standard speaker.
Furthermore,the recording and speaking style differences between ourstandard reference speaker and the test speakers are ap-parently not important ones, since reference speakers e-lected from the homogeneous database material did nobetter than our standard speaker.
The 20- confidenceinterval for this experiment is ,.~ :t: 2.2%.The alternate reference speaker results were also usedto determine whether the individual pairings of referenceand target speaker were important.
Since each targetspeaker had been adapted to each of the 5 referencespeakers, we could pick the best matching reference foreach target based on overall recognition performance.TargetBEF TABCMR DMSDTB TABJWS DTD or RSRKM TABBest Reference Word Err9.812.83.59.014.5Average 9.9Table 4.
Post-hoe selection of best reference speakerfor a given target speaker.The resulting average word error ate for (unfair) post-hoe reference selection was 9.9% as show in Table 4.This is 20% less than the average across all target-reference combinations shown in Table 3.
This resultrepresents an upper bound on the improvement that couldbe expected from automatic reference speaker selectionat the test set level, making such a strategy relativelyunattractive.Since we need a larger improvement than seems likelyfrom any single reference speaker, we are attempting tofind effective methods of combining multiple referencespeakers.3.2 Multiple Reference SpeakersWe have performed two preliminary experiments o ex-plore the feasibility of combining multiple referencespeakers for speaker-adaptation.3.2.1 Averaged Reference ModelsOne approach for combining multiple reference speak-ers into a single reference model is to adapt each refer-ence speaker independently o the target speaker, and usethe adapted models jointly in the recognition stage.
Astraight-forward method of combining the adapted mod-els is to average the HMM (discrete) densities.We created such a combined reference model from thelast 4 of the reference speakers hown in Table 3.
Theresulting recognition word error rate for the averagedmodel was 9.3%, compared to 12.4% for the average ofthe same 4 speakers used as single reference speakers.While this result is encouraging, the gain must be mea-sured against he added expense of the scenario.
Alsothis approach produces a more smoothed adapted modelthan the single reference baseline system, so that it maynot extend to combinations of large numbers of referencespeakers.In order to reduce the smoothing inherent in averagingHMM parameters, we have tried combining the referencespeakers before the final adapted model is trained.3.2.2 Pooled Normalized Reference SpeechThe feature normalization component of our system is"designed to superimpose the speech features of onespeaker onto another's for the purpose of improving theDTW alignment used for estimating the PDF mapping.This same component can be used to transform the fea-tures of many reference speakers to a single, commonspeaker (a prototypical reference speaker).
The trans-formed speech can then be pooled and trained as if it260came from a single reference speaker.
The resultingmodel parameters should be less smoothed (more dis-criminating) than a model made from similarly pooled,but unnormalized speech.A target speaker can be similarly normalized to theprototypicai reference before adapting with the PDFmapping component of the system, exactly as is donein our standard single-reference speaker-adaptation sys-tem.X-Spkr NormCondition Onlyi Ref 99 52.112 Ref ?
10.4PDF Map Norm +Only PDF Map9 6.9?
7.3Table 5.
Comparison of single and multiple referencesystems, with speech normalization and PDF mapping.Preliminary results from an experiment designed totest this proposal are shown in Table 5.
The table com-pares performance for a single reference speaker againsta 12 speaker reference model across four conditions:1) cross-speaker ecognition (train on referencespeaker(s), test on target speaker)2) speech normalization before cross-speaker recognition3) PDF transformation f cross-speaker model to adaptedtarget model4) speech normalization before PDF transformation ofcross-speaker model.All conditions in Table 5 are based on the resultsfrom 6 target speakers on the designated May88 test set.Two minutes of speech (40 utterances) from the targetspeaker were used to estimate the speaker transforma-tions.
The single reference condition used 600 utterancesfrom our standard reference speaker, RS, to train the ref-erence model.
For the 12 speaker eference condition,11 speakers were normalized (the intended target speakerwas held-out) to the prototypical reference speaker, RS.This resulted in a pool of 7200 normalized training ut-terances for each target speaker.
A single codebook wasmade for the entire experiment from 100 utterances fromeach of the 13 speakers.
The normalization used in thisexperiment did not include the feature conditioning im-provements described earlier.
The baseline unit-variancefeature scaling was used here.
Note that condition (1)shown in Table 1 is identical to the single reference con-dition, with normalization only, shown here in Table 5.The single reference results show that normaliza-tion alone halves the error rate relative to cross-speakerrecognition, while PDF mapping alone yields a ten-foldreduction in error rate.
When combined, however, theadditional gain is small.
In the past, this effect has led usto regard the normalization as a way to make small im-provements o the DTW-based alignment used for com-.puting the PDF transformation.The 12 speaker esults, however, show that the nor-malization alone can be made as powerful as the PDFmapping by utilizing speech from multiple referencespeakers.
A five-fold reduction in error rate is real-ized for normalizing 12 reference speakers instead ofone.
Since the 12 speaker unnormalized control condi-tion (pooled cross-speaker) has not been completed atthis writing, we cannot say what proportion of the im-provement is due to the normalization procedure, theadditional training speech, and the additional referencespeakers.
As was the case for the single reference con-difion, combining the two transformations yields only asmall additional improvement.While these absolute performance numbers are unim-pressive, pooling the normalized speech of only 12speakers has realized a dramatic reduction in error rateover the single reference normalization.
At this point, itmakes sense to ask: How much better would this condi-tion be if done on 100 reference speakers?
The speaker-independent portion of the DARPA Resource Manage-ment database will permit us to answer this question.4 SummaryWe have described our speaker-adaptation system interms of the two speaker-transformations used to makeone speaker look like another; speech normalization a dPDF mapping.
Experimental results indicate that thespeech normalization can be improved by feature condi-tioning, whereas the PDF mapping is relatively insensi-five to improvements in the normalization.
Also we haveshown that the choice of any single reference speaker isnot an important issue, indicating that improvements tothe reference model are likely to be gained only by usingmultiple reference speakers.We have reported baseline system (single referencespeaker) test results of 7.4% word error rate for the word-pair grammar and 28.7% for no grammar on the desig-nated Oct. '89 DARPA evaluation test set.
This per-formance is comparable to the best speaker-independentresults being reported today, but with considerably ess ~261effort required to collect he reference training material(1 speaker vs. 100, 600 utterances vs. 4000).We have proposed a new method of utilizing speechfrom multiple reference speakers by transforming themto a single common feature space before pooling.
Pre-liminary experiments have shown a five-fold reductionin error rate for using the proposed normalization on a12 speaker pooled model compared to a single speakermodel.
We propose to test our approach on the speaker-independent portion of the DARPA Resource Manage-ment database in the near future.AcknowledgementThis work was supported by the Defense AdvancedResearch Projects Agency and monitored by the Officeof Naval Research under Contract No.
N00014-85-C-0279.References[1] Feng, M., F. Kubala, R. Schwartz, J. Makhoul(1988) "Improved Speaker Adaptation Using TextDependent Spectral Mappings," IEEE ICASSP-88,paper $3.9.
[2] Feng, M., R. Schwartz, F. Kubala, J Makhoul(1989) "Iterative Normalization for Speaker-Adaptive Training in Continuous Speech Recog-nition," IEEE ICASSP-89, paper S 12.4.
[3] Kubala, F., M. Feng, J. Makhoul, R. Schwartz(1989) "Speaker Adaptation from Limited Train-ing in the BBN BYBLOS Speech Recognition Sys-tem," Proceedings of the DARPA Speech and Nat-ural Language Workshop, Morgan Kaufmann Pub-lishers, Inc., pp.
100-105, Feb.
1989.
[4] Price, P., W. Fisher, J. Bernstein, and D. Pallett(1988) "The DARPA 1000-Word Resource Man-agement Database for Continuous Speech Recog-nition," IEEE ICASSP-88, paper S13.21.
[5] Schwartz, R., Y. Chow, F. Kubala (1987) "RapidSpeaker Adaptation using a Probabilistic SpectralMapping," IEEE ICASSP-87, paper 15.3.1.262
