Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 254?259,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsOptimal and Syntactically-Informed Decoding for MonolingualPhrase-Based AlignmentKapil Thadani and Kathleen McKeownDepartment of Computer ScienceColumbia UniversityNew York, NY 10027, USA{kapil,kathy}@cs.columbia.eduAbstractThe task of aligning corresponding phrasesacross two related sentences is an importantcomponent of approaches for natural languageproblems such as textual inference, paraphrasedetection and text-to-text generation.
In thiswork, we examine a state-of-the-art struc-tured prediction model for the alignment taskwhich uses a phrase-based representation andis forced to decode alignments using an ap-proximate search approach.
We propose in-stead a straightforward exact decoding tech-nique based on integer linear programmingthat yields order-of-magnitude improvementsin decoding speed.
This ILP-based decodingstrategy permits us to consider syntactically-informed constraints on alignments which sig-nificantly increase the precision of the model.1 IntroductionNatural language processing problems frequently in-volve scenarios in which a pair or group of relatedsentences need to be aligned to each other, establish-ing links between their common words or phrases.For instance, most approaches for natural languageinference (NLI) rely on alignment techniques to es-tablish the overlap between the given premise and ahypothesis before determining if the former entailsthe latter.
Such monolingual alignment techniquesare also frequently employed in systems for para-phrase generation, multi-document summarization,sentence fusion and question answering.Previous work (MacCartney et al, 2008) has pre-sented a phrase-based monolingual aligner for NLI(MANLI) that has been shown to significantly out-perform a token-based NLI aligner (Chambers etal., 2007) as well as popular alignment techniquesborrowed from machine translation (Och and Ney,2003; Liang et al, 2006).
However, MANLI?s useof a phrase-based alignment representation appearsto pose a challenge to the decoding task, i.e.
thetask of recovering the highest-scoring alignment un-der some parameters.
Consequently, MacCartney etal.
(2008) employ a stochastic search algorithm todecode alignments approximately while remainingconsistent with regard to phrase segmentation.In this paper, we propose an exact decoding tech-nique for MANLI that retrieves the globally opti-mal alignment for a sentence pair given some pa-rameters.
Our approach is based on integer lin-ear programming (ILP) and can leverage optimizedgeneral-purpose LP solvers to recover exact solu-tions.
This strategy boosts decoding speed by anorder of magnitude over stochastic search in our ex-periments.
Additionally, we introduce hard syntac-tic constraints on alignments produced by the model,yielding better precision and a large increase in thenumber of perfect alignments produced over ourevaluation corpus.2 Related WorkAlignment is an integral part of statistical MT (Vo-gel et al, 1996; Och and Ney, 2003; Liang et al,2006) but the task is often substantively differentfrom monolingual alignment, which poses uniquechallenges depending on the application (MacCart-ney et al, 2008).
Outside of NLI, prior research hasalso explored the task of monolingual word align-254ment using extensions of statistical MT (Quirk et al,2004) and multi-sequence alignment (Barzilay andLee, 2002).ILP has been used extensively for applicationsranging from text-to-text generation (Clarke and La-pata, 2008; Filippova and Strube, 2008; Wood-send et al, 2010) to dependency parsing (Martinset al, 2009).
It has also been recently employed forfinding phrase-based MT alignments (DeNero andKlein, 2008) in a manner similar to this work; how-ever, we further build upon this model through syn-tactic constraints on the words participating in align-ments.3 The MANLI AlignerOur alignment system is structured identically toMANLI (MacCartney et al, 2008) and uses the samephrase-based alignment representation.
An align-ment E between two fragments of text T1 and T2is represented by a set of edits {e1, e2, .
.
.
}, each be-longing to one of the following types:?
INS and DEL edits covering unaligned words inT1 and T2 respectively?
SUB and EQ edits connecting a phrase in T1 toa phrase in T2.
EQ edits are a specific case ofSUB edits that denote a word/lemma match; werefer to both types as SUB edits in this paper.Every token in T1 and T2 participates in exactly oneedit.
While alignments are one-to-one at the phraselevel, a phrase-based representation effectively per-mits many-to-many alignments at the token level.This enables the aligner to properly link paraphrasessuch as death penalty and capital punishment by ex-ploiting lexical resources.3.1 DatasetMANLI was trained and evaluated on a corpus ofhuman-generated alignment annotations producedby Microsoft Research (Brockett, 2007) for infer-ence problems from the second Recognizing Tex-tual Entailment (RTE2) challenge (Bar-Haim et al,2006).
The corpus consists of a development setand test set that both feature 800 inference prob-lems, each of which consists of a premise, a hy-pothesis and three independently-annotated humanalignments.
In our experiments, we merge the an-notations using majority rule in the same manner asMacCartney et al (2008).3.2 FeaturesA MANLI alignment is scored as a sum of weightedfeature values over the edits that it contains.
Fea-tures encode the type of edit, the size of the phrasesinvolved in SUB edits, whether the phrases are con-stituents and their similarity (determined by lever-aging various lexical resources).
Additionally, con-textual features note the similarity of neighboringwords and the relative positions of phrases whilea positional distortion feature accounts for the dif-ference between the relative positions of SUB editphrases in their respective sentences.Our implementation uses the same set of fea-tures as MacCartney et al (2008) with some mi-nor changes: we use a shallow parser (Daume?
andMarcu, 2005) for detecting constituents and employonly string similarity and WordNet for determiningsemantic relatedness, forgoing NomBank and thedistributional similarity resources used in the orig-inal MANLI implementation.3.3 Parameter InferenceFeature weights are learned using the averagedstructured perceptron algorithm (Collins, 2002), anintuitive structured prediction technique.
We deviatefrom MacCartney et al (2008) and do not introduceL2 normalization of weights during learning as thiscould have an unpredictable effect on the averagedparameters.
For efficiency reasons, we parallelizethe training procedure using iterative parameter mix-ing (McDonald et al, 2010) in our experiments.3.4 DecodingThe decoding problem is that of finding the highest-scoring alignment under some parameter values forthe model.
MANLI?s phrase-based representationmakes decoding more complex because the segmen-tation of T1 and T2 into phrases is not known before-hand.
Every pair of phrases considered for inclusionin an alignment must adhere to some consistent seg-mentation so that overlapping edits and uncoveredwords are avoided.Consequently, the decoding problem cannot befactored into a number of independent decisionsand MANLI searches for a good alignment usinga stochastic simulated annealing strategy.
Whileseemingly quite effective at avoiding local maxima,255System Data P% R% F1% E%MANLI dev 83.4 85.5 84.4 21.7(reported 2008) test 85.4 85.3 85.3 21.3MANLI dev 85.7 84.8 85.0 23.8(reimplemented) test 87.2 86.3 86.7 24.5MANLI-Exact dev 85.7 84.7 85.2 24.6(this work) test 87.8 86.1 86.8 24.8Table 1: Performance of aligners in terms of precision, re-call, F-measure and number of perfect alignments (E%).this iterative search strategy is computationally ex-pensive and moreover is not guaranteed to return thehighest-scoring alignment under the parameters.4 Exact Decoding via ILPInstead of resorting to approximate solutions, wecan simply reformulate the decoding problem as theoptimization of a linear objective function with lin-ear constraints, which can be solved by well-studiedalgorithms using off-the-shelf solvers1.
We first de-fine boolean indicator variables xe for every possibleedit e between T1 and T2 that indicate whether e ispresent in the alignment or not.
The linear objectivethat maximizes the score of edits for a given param-eter vector w is expressed as follows:f(w) = max?exe ?
scorew(e)= max?exe ?w ?
?
(e) (1)where ?
(e) is the feature vector over an edit.
Thisexpresses the score of an alignment as the sum ofscores of edits that are present in it, i.e., edits e thathave xe = 1.In order to address the phrase segmentation issuediscussed in ?3.4, we merely need to add linear con-straints ensuring that every token participates in ex-actly one edit.
Introducing the notation e ?
t to in-dicate that edit e covers token t in one of its phrases,this constraint can be encoded as:?e: e?txe = 1 ?t ?
Ti, i = {1, 2}On solving this integer program, the values of thevariables xe indicate which edits are present in the1We use LPsolve: http://lpsolve.sourceforge.net/Corpus Size Approximate ExactSearch ILPRTE2 dev 800 2.58 0.11test 800 1.67 0.08McKeown et al(2010)297 61.96 2.45Table 2: Approximate running time per decoding task inseconds for the search-based approximate decoder andthe ILP-based exact decoder on various corpora (see textfor details).highest-scoring alignment under w. A similar ap-proach is employed by DeNero and Klein (2008) forfinding optimal phrase-based alignments for MT.4.1 Alignment experimentsFor evaluation purposes, we compare the perfor-mance of approximate search decoding against ex-act ILP-based decoding on a reimplementation ofMANLI as described in ?3.
All models are trainedon the development section of the Microsoft Re-search RTE2 alignment corpus (cf.
?3.1) usingthe training parameters specified in MacCartneyet al (2008).
Aligner performance is determinedby counting aligned token pairs per problem andmacro-averaging over all problems.
The results areshown in Table 1.We first observe that our reimplemented versionof MANLI improves over the results reported inMacCartney et al (2008), gaining 2% in precision,1% in recall and 2-3% in the fraction of alignmentsthat exactly matched human annotations.
We at-tribute at least some part of this gain to our modifiedparameter inference (cf.
?3.3) which avoids normal-izing the structured perceptron weights and insteadadheres closely to the algorithm of Collins (2002).Although exact decoding improves alignment per-formance over the approximate search approach, thegain is marginal and not significant.
This seems toindicate that the simulated annealing search strategyis fairly effective at avoiding local maxima and find-ing the highest-scoring alignments.4.2 Runtime experimentsTable 2 contains the results from timing alignmenttasks over various corpora on the same machine us-ing the models trained as per ?4.1.
We observe a256twenty-fold improvement in performance with ILP-based decoding.
It is important to note that the spe-cific implementations being compared2 may be re-sponsible for the relative speed of decoding.The short hypotheses featured in the RTE2 cor-pus (averaging 11 words) dampen the effect of thequadratic growth in number of edits with sentencelength.
For this reason, we also run the aligners ona corpus of 297 related sentence pairs which don?thave a particular disparity in sentence lengths (McK-eown et al, 2010).
The large difference in decodingtime illustrates the scaling limitations of the search-based decoder.5 Syntactically-Informed ConstraintsThe use of an integer program for decoding pro-vides us with a convenient mechanism to preventcommon alignment errors by introducting additionalconstraints on edits.
For example, function wordssuch as determiners and prepositions are often mis-aligned just because they occur frequently in manydifferent contexts.
Although MANLI makes useof contextual features which consider the similar-ity of neighboring words around phrase pairs, out-of-context alignments of function words often ap-pear in the output.
We address this issue by addingconstraints to the integer program from ?4 that lookat the syntactic structure of T1 and T2 and preventmatching function words from appearing in an align-ment unless they are syntactically linked with otherwords that are aligned.To enforce token-based constraints, we defineboolean indicator variables yt for each token t intext snippets T1 and T2 that indicate whether t is in-volved in a SUB edit or not.
The following constraintensures that yt = 1 if and only if it is covered by aSUB edit that is present in the alignment.yt ?
?e: e?t,e is SUBxe = 0 ?t ?
Ti, i = {1, 2}We refer to tokens t with yt = 1 as being active inthe alignment.
Constraints can now be applied overany token with specific part-of-speech (POS) tag in2Our Python reimplementation closely follows the originalJava implementation of MANLI and was optimized for perfor-mance.
MacCartney et al (2008) report a decoding time ofabout 2 seconds per problem.System Data P% R% F1% E%MANLI-Exact with dev 86.8 84.5 85.6 25.3M constraints test 88.8 85.7 87.2 29.9MANLI-Exact with dev 86.1 84.6 85.3 24.5L constraints test 88.2 86.4 87.3 27.6MANLI-Exact with dev 87.1 84.4 85.8 25.4M + L constraints test 89.5 86.2 87.8 33.0Table 3: Performance of MANLI-Exact featuring addi-tional modifier (M) and lineage (L) constraints.
Figuresin boldface are statistically significant over the uncon-strained MANLI reimplementation (p ?
0.05).order to ensure that it can only be active if a differ-ent token related to it in a dependency parse of thesentence is also active.
We consider the followingclasses of constraints:Modifier constraints: Tokens t that represent con-junctions, determiners, modals and cardinals canonly be active if their parent tokens pi(t) are active.yt ?
ypi(t) <= 0if POS(t) ?
{CC, CD, MD, DT, PDT, WDT}Lineage constraints: Tokens t that represent prepo-sitions and particles (which are often confused byparsers) can only be active if one of their ancestors?
(t) or descendants ?
(t) is active.
These constraintsare less restrictive than the modifier constraints inorder to account for attachment errors.yt ??a??
(t)ya ??d??
(t)yd <= 0if POS(t) ?
{IN, TO, RP}5.1 Alignment experimentsA TAG-based probabilistic dependency parser (Ban-galore et al, 2009) is used to formulate the aboveconstraints in our experiments.
The results areshown in Table 3 and indicate a notable increase inalignment precision, which is to be expected as theconstraints specifically seek to exclude poor edits.Despite the simple and overly general restrictionsbeing applied, recall is almost unaffected.
Mostcompellingly, the number of perfect alignments pro-duced by the system increases significantly when257compared to the unconstrained models from Table 1(a relative increase of 35% on the test corpus).6 DiscussionThe results of our evaluation indicate that exact de-coding via ILP is a robust and efficient technique forsolving alignment problems.
Furthermore, the in-corporation of simple constraints over a dependencyparse can help to shape more accurate alignments.An examination of the alignments produced by oursystem reveals that many remaining errors can betackled by the use of named-entity recognition andbetter paraphrase corpora; this was also noted byMacCartney et al (2008) with regard to the originalMANLI system.
In addition, stricter constraints thatenforce the alignment of syntactically-related tokens(rather than just their inclusion in the solution) mayalso yield performance gains.Although MANLI?s structured prediction ap-proach to the alignment problem allows us to encodepreferences as features and learn their weights viathe structured perceptron, the decoding constraintsused here can be used to establish dynamic links be-tween alignment edits which cannot be determineda priori.
The interaction between the selection ofsoft features for structured prediction and hard con-straints for decoding is an interesting avenue for fur-ther research on this task.
Initial experiments witha feature that considers the similarity of dependencyheads of tokens in an edit (similar to MANLI?s con-textual features that look at preceding and followingwords) yielded some improvement over the base-line models; however, this did not perform as wellas the simple constraints described above.
Specificfeatures that approximate soft variants of these con-straints could also be devised but this was not ex-plored here.In addition to the NLI applications considered inthis work, we have also employed the MANLI align-ment technique to tackle alignment problems thatare not inherently asymmetric such as the sentencefusion problems from McKeown et al (2010).
Al-though the absence of asymmetric alignment fea-tures affects performance marginally over the RTE2dataset, all the performance gains exhibited by exactdecoding with constraints appear to be preserved insymmetric settings.7 ConclusionWe present a simple exact decoding technique as analternative to approximate search-based decoding inMANLI that exhibits a twenty-fold improvement inruntime performance in our experiments.
In addi-tion, we propose novel syntactically-informed con-straints to increase precision.
Our final system im-proves over the results reported in MacCartney et al(2008) by about 4.5% in precision and 1% in recall,with a large gain in the number of perfect alignmentsover the test corpus.
Finally, we analyze the align-ments produced and suggest that further improve-ments are possible through careful feature/constraintdesign, as well as the use of named-entity recogni-tion and additional resources.AcknowledgmentsThe authors are grateful to Bill MacCartney for pro-viding a reference MANLI implementation and theanonymous reviewers for their useful feedback.
Thismaterial is based on research supported in part bythe U.S. National Science Foundation (NSF) underIIS-05-34871.
Any opinions, findings and conclu-sions or recommendations expressed in this materialare those of the authors and do not necessarily reflectthe views of the NSF.ReferencesSrinivas Bangalore, Pierre Boullier, Alexis Nasr, OwenRambow, and Beno?
?t Sagot.
2009.
MICA: a prob-abilistic dependency parser based on tree insertiongrammars.
In Proceedings of HLT-NAACL, pages185?188.Roy Bar-Haim, Ido Dagan, Bill Dolan, Lisa Ferro, DaniloGiampiccolo, Bernardo Magnini, and Idan Szpektor.2006.
The second PASCAL Recognising Textual En-tailment challenge.
In Proceedings of the SecondPASCAL Challenges Workshop on Recognising Tex-tual Entailment.Regina Barzilay and Lilian Lee.
2002.
Bootstrappinglexical choice via multiple-sequence alignment.
InProceedings of EMNLP.Chris Brockett.
2007.
Aligning the 2006 RTE cor-pus.
Technical Report MSR-TR-2007-77, MicrosoftResearch.Nathanael Chambers, Daniel Cer, Trond Grenager,David Hall, Chloe Kiddon, Bill MacCartney, Marie-Catherine de Marneffe, Daniel Ramage, Eric Yeh, and258Christopher D. Manning.
2007.
Learning alignmentsand leveraging natural logic.
In Proceedings of theACL-PASCAL Workshop on Textual Entailment andParaphrasing, pages 165?170.James Clarke and Mirella Lapata.
2008.
Global infer-ence for sentence compression: an integer linear pro-gramming approach.
Journal of Artifical IntelligenceResearch, 31:399?429, March.Michael Collins.
2002.
Discriminative training meth-ods for hidden Markov models.
In Proceedings ofEMNLP, pages 1?8.Hal Daume?, III and Daniel Marcu.
2005.
Learning assearch optimization: approximate large margin meth-ods for structured prediction.
In Proceedings of ICML,pages 169?176.John DeNero and Dan Klein.
2008.
The complexity ofphrase alignment problems.
In Proceedings of ACL-HLT, pages 25?28.Katja Filippova and Michael Strube.
2008.
Sentence fu-sion via dependency graph compression.
In Proceed-ings of EMNLP, pages 177?185.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of HLT-NAACL,pages 104?111.Bill MacCartney, Michel Galley, and Christopher D.Manning.
2008.
A phrase-based alignment modelfor natural language inference.
In Proceedings ofEMNLP, pages 802?811.Andre?
F. T. Martins, Noah A. Smith, and Eric P. Xing.2009.
Concise integer linear programming formula-tions for dependency parsing.
In Proceedings of ACL-IJCNLP, pages 342?350.Ryan McDonald, Keith Hall, and Gideon Mann.
2010.Distributed training strategies for the structured per-ceptron.
In Proceedings of HLT-NAACL, pages 456?464.Kathleen McKeown, Sara Rosenthal, Kapil Thadani, andColeman Moore.
2010.
Time-efficient creation of anaccurate sentence fusion corpus.
In Proceedings ofHLT-NAACL, pages 317?320.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29:19?51, March.Chris Quirk, Chris Brockett, and William Dolan.
2004.Monolingual machine translation for paraphrase gen-eration.
In In Proceedings of EMNLP, pages 142?149,July.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
Hmm-based word alignment in statistical trans-lation.
In Proceedings of COLING, pages 836?841.Kristian Woodsend, Yansong Feng, and Mirella Lapata.2010.
Title generation with quasi-synchronous gram-mar.
In Proceedings of EMNLP, pages 513?523.259
