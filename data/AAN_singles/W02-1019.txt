Minimum Bayes-Risk Word Alignments of Bilingual TextsShankar Kumar and William ByrneCenter for Language and Speech Processing, Johns Hopkins University,3400 North Charles Street, Baltimore, MD, 21218, USAskumar,byrne @jhu.eduAbstractWe present Minimum Bayes-Risk wordalignment for machine translation.
Thisstatistical, model-based approach attemptsto minimize the expected risk of align-ment errors under loss functions that mea-sure alignment quality.
We describe var-ious loss functions, including some thatincorporate linguistic analysis as can beobtained from parse trees, and show thatthese approaches can improve alignmentsof the English-French Hansards.1 IntroductionThe automatic determination of word alignments inbilingual corpora would be useful for Natural Lan-guage Processing tasks such as statistical machinetranslation, automatic dictionary construction, andmultilingual document retrieval.
The developmentof techniques in all these areas would be facili-tated by automatic performance metrics, and align-ment and translation quality metrics have been pro-posed (Och and Ney, 2000b; Papineni et al, 2002).However, given the difficulty of judging translationquality, it is unlikely that a single, global metric willbe found for any of these tasks.
It is more likelythat specialized metrics will be developed to mea-sure specific aspects of system performance.
This iseven desirable, as these specialized metrics could beused in tuning systems for particular applications.We have applied Minimum Bayes-Risk (MBR)procedures developed for automatic speech recog-nition (Goel and Byrne, 2000) to word alignment ofbitexts.
This is a modeling approach that can be usedwith statistical models of speech and language to de-velop algorithms that are optimized for specific lossfunctions.
We will discuss loss functions that canbe used for word alignment and show how the over-all alignment process can be improved by the useof loss functions that incorporate linguistic features,such as parses and part-of-speech tags.2 Word-to-Word Bitext AlignmentWe will study the problem of aligning an Englishsentence to a French sentence and we will use theword alignment of the IBM statistical translationmodels (Brown et al, 1993).Let and denote a pair of translatedEnglish and French sentences.
An English word isdefined as an ordered pair, where the index refers to the posi-tion of the word in the English sentence; is thevocabulary of English; and the word at position isthe NULL word to which ?spurious?
French wordsmay be aligned.
Similarly, a French word is writtenas .An alignment between and is defined to bea sequence where.
Under the alignment, the French word is connected to the Englishword .
For every alignment , we define a linkset defined as whose ele-ments are given by the alignment links.3 Alignment Loss FunctionsIn this section we introduce loss functions to mea-sure the quality of automatically produced align-ments.
Suppose we wish to compare an automat-ically produced alignment to a reference align-ment , which we assume was produced by a com-petent translator.
We will define various loss func-tions that measure the quality of relativeto through their link sets and .The desirable qualities in translation are fluencyAssociation for Computational Linguistics.Language Processing (EMNLP), Philadelphia, July 2002, pp.
140-147.Proceedings of the Conference on Empirical Methods in Naturaland adequacy.
We assume here that both word se-quences are fluent and adequate translations but thatthe word and phrase correspondences are unknown.It is these correspondences that we wish to deter-mine and evaluate automatically.We now present two general classes of loss func-tions that measure alignment quality.
In subsequentsections, we will give specific examples of these andshow how to construct decoders that are optimizedfor each loss function.3.1 Alignment ErrorThe Alignment Error Rate (AER) introduced byOch and Ney (2000b) measures the fraction of linksby which the automatic alignment differs from thereference alignment.
Links to the NULL word areignored.
This is done by defining modified link setsfor the reference alignmentand the automatic alignment.The reference annotation procedure allowed thehuman transcribers to identify which links in theyjudged to be unambiguous.
In addition to the ref-erence alignment, this gives a set of sure links (S)which is a subset of .AER is defined as (Och and Ney, 2000b)(1)Since our modeling techniques require loss func-tions rather than error rates, we introduce the Align-ment Error loss function(2)We consider error rates to be ?normalized?
lossfunctions.
We also note that, unlike AER, doesnot distinguish between ambiguous and unambigu-ous links.
However, if a decoder generates an align-ment for which is zero, the AER isalso zero.
Therefore if AER is the metric of inter-est, we will design alignment procedures to mini-mize .3.2 Generalized Alignment ErrorWe are interested in extending the Alignment Er-ror loss function to incorporate various linguisticfeatures into the measurement of alignment quality.The Generalized Alignment Error loss is defined as(3)where and(4)Here we have introduced the word-to-word distancemeasure which compares thelinks and as a function of the words inthe translation.
refers to all loss functions thathave the form of Equation 3.
Specific loss functionsare determined through the choice of .
To see thevalue in this, suppose is a verb in the French sen-tence and that it is aligned in the reference alignmentto , the verb in the English sentence.
If our goal isto ensure verb alignment, then can be constructedto penalize any link in the automatic align-ment in which is not a verb.
We will later give ex-amples of distances in which is based on Part-of-Speech (POS) tags, parse tree distances, and au-tomatically determined word clusters.
We note thatthe can almost be reduced to , except forthe treatment of NULL in the English sentence.4 Minimum Bayes-Risk Decoding ForAutomatic Word AlignmentWe present the Minimum Bayes-Risk alignment for-mulation and derive MBR alignment procedures un-der the loss functions of Section 3.Given a translated pair of English-French sen-tences , the decoder produces an align-ment .
Relative to a reference align-ment , the decoder performance is measured as.
Our goal is to find the decoder thathas the best performance over all translated sen-tences.
This is measured through the Bayes Risk.
The ex-pectation is taken with respect to the true distribu-tion that describes ?human quality?
align-ments of translations as they are found in bitext.Given a loss function and a probability distribu-tion, it is well known that the decision rule whichminimizes the Bayes Risk is given by the follow-ing expression (Bickel and Doksum, 1977; Goel andByrne, 2000).
(5)Several modeling assumptions have been made toobtain this form of the decoder.
We do not have ac-cess to the true distribution over translations.
Wetherefore use statistical MT models to approximate.
We furthermore assume that the space ofalignment alternatives can be restricted to an align-ment lattice , which is a compact representation ofthe most likely word alignments of the sentence pairunder the baseline models.It is clear from Equation 5 that the MBR de-coder is determined by the loss function.
The Sen-tence Alignment Error refers to the loss functionthat gives a penalty of 1 for any errorful alignment:, where is the indi-cator function of the set .
The MBR decoder un-der this loss can easily be seen to be the MaximumLikelihood (ML) alignment under the MT models:.
This illustrates why weare interested in MBR decoders based on other lossfunctions: the ML decoder is optimal with respect toa loss function that is overly harsh.
It does not dis-tinguish between different types of alignment errorsand good alignments receive the same penalty aspoor alignments.
Moreover, such a harsh penalty isparticularly inappropriate when unambiguous word-to-word alignments cannot be provided in all caseseven by human translators who produce the refer-ence alignments.
The AER makes an explicit dis-tinction between ambiguous and unambiguous wordalignments.
Ideally, the decoder should be able to doso as well.
Motivated by this, the MBR hypothesiscan be thought of as the consensus hypothesis un-der a particular loss function: Equation 5 selects thehypothesis that is, in an average sense, close to theother likely hypotheses.
In this way, ambiguity canbe reduced by selecting the hypothesis that is ?mostsimilar?
to the collection of most likely competinghypotheses.We now describe the alignment lattice (Sec-tion 4.1) and introduce the lattice based probabilitiesrequired for the MBR alignment (Section 4.2).
Thederivation of the MBR alignment under the AE andGAE loss functions is presented in Sections 4.3 and4.4.4.1 Alignment LatticeThe lattice is represented as a Weighted FiniteState Transducer (WFST) (Mohri et al, 2000)with a finite set of states , a set oftransition labels , an initial state , the set of fi-nal states , and a finite set of transitions .
Atransition in this WFST is given bywhere is the starting state, is the ending state,is the alignment link and is the weight.
Foran English sentence of length and a French sen-tence of length , we define as.A complete path through the WFST is a sequenceof transitions given bysuch that and .
Each completepath defines an alignment link set .When we write , we mean that is derivedfrom a complete path through .
This allows us touse alignment models in which the probability of analignment can be written as a sum over alignmentlink weights, i.e.
.4.2 Alignment Link Posterior ProbabilityWe first introduce the lattice transition posteriorprobability of each transition in thelattice(6)where is if and otherwise.
Thelattice transition posterior probability is the sum ofthe posterior probabilities of all lattice paths pass-ing through the transition .
This can be com-puted very efficiently with a forward-backward al-gorithm on the alignment lattice (Wessel et al,1998).
is the posterior probability of analignment link set which can be written as(7)We now define the alignment link posterior prob-ability for a link(8)where .
This is the probabilitythat any two words are aligned given all thealignments in the lattice .4.3 MBR Alignment UnderIn this section we derive MBR alignment under theAlignment Error loss function (Equation 2).
The op-timal decoder has the form (Equation 5)(9)The summation is equal toIf is the subset of transitions ( )that do not contain links with the NULL word, wecan simplify the bracketed term asFor an alignment link we note that.
Therefore, theMBR alignment (Equation 9) can be found in termsof the modified link weight for each alignment link(10)We can rewrite the above equation as(11)4.4 MBR Alignment UnderWe now derive MBR alignment under the Gener-alized Alignment Error loss function (Equation 3).The optimal decoder has the form (Equation 5)(12)The summation can be rewritten aswhere and .We can simplify the bracketed term aswhere and .The MBR alignment (Equation 12) can be foundin terms of the modified link weight for each align-ment link(13)4.5 MBR Alignment Using WFST TechniquesThe MBR alignment procedures under the andloss functions begin with a WFST that con-tains the alignment probabilities as de-scribed in Section 4.1.
To build the MBR decoderfor each loss function the weights on the transitions( ) of the WFST are modified ac-cording to either Equation 11 ( ) or Equa-tion 13 ( ).
Once the weights are modified,the search procedure for the MBR alignment is thesame in each case.
The search is carried out using ashortest-path algorithm (Mohri et al, 2000).5 Word Alignment ExperimentsWe present here examples of Generalized Align-ment Error loss functions based on three types oflinguistic features and show how they can be incor-porated into a statistical MT system to obtain auto-matic alignments.5.1 Syntactic Distances From Parse-TreesSuppose a parser is available that generates a parse-tree for the English sentence.
Our goal is to con-struct an alignment loss function that incorporatesfeatures from the parse.
One way to do this is todefine a graph distance(14)Here and are the parse-tree leaf nodes cor-responding to the English words and .
Thisquantity is computed as the sum of the distancesfrom each node to their closest common ancestor.It gives a syntactic distance between any pair ofEnglish words based on the parse-tree.
This dis-tance has been used to measure word association forinformation retrieval (Mittendorfer and Winiwarter,2001).
It reflects how strongly the words andare bound together by the syntactic structure of theEnglish sentence as determined by the parser.
Fig-ure 1 shows the parse tree for an English sentencein the test data with the pairwise syntactic distancesbetween the English words corresponding to the leafnodes.TOPSNPPRP iVPVBP think SBARSNPDT thatVPVBZ is ADJPJJ good .
.Pairwise Distancesg("i","think") = 4g("i", "that") = 7g("i","is") = 7g("i" , "good") = 8g("i" , ".")
= 8Figure 1: Parse tree for a English sentence with thepairwise syntactic distances between words.To obtain these distances, Ratnaparkhi?s part-of-speech (POS) tagger (Ratnaparkhi, 1996) andCollins?
parser (Collins, 1999) were used to obtainparse trees for the English side of the test corpus.With defined as in Equation 14, the GeneralizedAlignment Error loss function (Equation 3) is calledthe Parse-Tree Syntactic Distance ( ).5.2 Distances Derived From Part-of-SpeechLabelsSuppose a Part-of-Speech(POS) tagger is availableto tag each word in the English sentence.
If POSdenotes the POS of the English word , we can de-fine the word-to-word distance measure (Equa-tion 4) asPOS POS (15)Ratnaparkhi?s POS tagger (Ratnaparkhi, 1996)was used to obtain POS tags for each word inthe English sentence.
With specified by Equa-tion 15, the Generalized Alignment Error loss func-tion (Equation 3) is called the Part-Of-Speech Dis-tance ( ).5.3 Automatic Word Cluster DistancesSuppose we are working in a language for whichparsers and POS taggers are not available.
In thissituation we might wish to construct the loss func-tions based on word classes determined by auto-matic clustering procedures.
If specifies theword cluster for the English word , then we definethe distance(16)In our experiments we obtained word clustersfor English words using a statistical learning proce-dure (Kneser and Ney, 1991) where the total numberof word classes is restricted to be 100.
With asdefined in Equation 16, the Generalized AlignmentError loss function (Equation 3) is called the Auto-matic Word Class Distance ( ).5.4 IBM-3 Word Alignment ModelsSince the true distribution over alignments is notknown, we used the IBM-3 statistical transla-tion model (Brown et al, 1993) to approximate.
This model is specified through fourcomponents: Fertility probabilities for words; Fer-tility probabilities for NULL; Word Translationprobabilities; and Distortion probabilities.
Weused a modified version of the IBM-3 distortionmodel (Knight and Al-Onaizan, 1998) in whicheach of the possible permutations of the Frenchsentence is equally likely.
The IBM-3 modelswere trained on a subset of the Canadian HansardsFrench-English data which consisted of 50,000 par-allel sentences (Och and Ney, 2000b).
The vocab-ulary size was 18,499 for English and 24,198 forFrench.
The GIZA++ toolkit (Och and Ney, 2000a)was used for training the IBM-3 models (as in (Ochand Ney, 2000b)).5.5 Word Alignment Lattice GenerationWe obtained word alignments under themodified IBM-3 models using the finitestate translation framework introduced byKnight and Al-Onaizan (1998).
The finite stateoperations were carried out using the AT&T FiniteState Machine Toolkit (Mohri et al, 2001; Mohri etal., 2000).The WFST framework involves building a trans-ducer for each constituent of the IBM-3 AlignmentModels: the word fertility model ; the NULL fer-tility model ; and the word translation model(Section 5.4).
For each sentence pair we also built afinite state acceptor that accepts the English sen-tence and another acceptor which accepts all legalpermutations of the French sentence.
The alignmentlattice for the sentence pair was then obtainedby the following weighted finite state composition.
In practice, the WFST ob-tained by the composition was pruned to a maximumof 10,000 states using a likelihood based pruning op-eration.
In terms of AT&T Finite State Toolkit shellcommands, these operations are given as:fsmcompose E M fsmcompose - Nfsmcompose - T fsmcompose - Ffsmprune -n 10000The finite state composition and pruning were per-formed using lazy implementations of algorithmsprovided in AT&T Finite State libraries (Mohri etal., 2000).
This made the computation efficient be-cause even though five WFSTs are composed intoa potentially huge transducer, only a small portionof it is actually searched during the pruning used togenerate the final lattice.A heavily pruned alignment lattice for asentence-pair from the test data is shown in Fig-ure 2.
For clarity of presentation, each alignmentlink in the lattice is shown as an orderedpair where and arethe English and French words on the link.
For eachsentence, we also computed the lattice path with thehighest probability .
This gives the MLalignment under the statistical MT models that willgive our baseline performance under the various lossfunctions.5.6 Performance Under The Alignment ErrorRatesOur unseen test data consisted of 207 French-English sentence pairs from the Hansards cor-pus (Och and Ney, 2000b).
These sentence pairs hadat most 16 words in the French sentence; this restric-tion on the sentence length was necessary to controlthe memory requirements of the composition.5.6.1 MBR Consensus AlignmentsIn the previous sections we introduced a totalof four loss functions: , , and.
Using either Equation 11 or 13, an MBRdecoder can be constructed for each.
These decodersare called MBR-AE, MBR-PTSD, MBR-POSD, andMBR-AWCD, respectively.5.6.2 Evaluation MetricsThe performance of the four decoders was mea-sured with respect to the alignments provided by hu-man experts (Och and Ney, 2000b).
The first eval-uation metric used was the Alignment Error Rate(Equation 1).
We also evaluated each decoder un-der the Generalized Alignment Error Rates (GAER).These are defined as:(17)There are six variants of GAER.
These arisewhen is specified by ,or .
There are two versions of eachof these: one version is sensitive only to sure(S) links.
The other version considers all (A)links in the reference alignment.
We there-fore have the following six Generalized AlignmentError Rates: PTSD-S, POSD-S, AWCD-S, andPTSD-A, POSD-A, AWCD-A.
We say we have amatched condition when the same loss function isused in both the error rate and the decoder design.01NULL_0:a_4/5.3483it_1:ce_1/2.3442it_1:ce_1/1.9274NULL_0:a_4/5.3486is_2:est_2/1.3495is_2:est_2/1.3499quite_3:tout_3/4.1328quite_3:fait_5/4.405is_2:est_2/0.9337NULL_0:a_4/5.34810quite_3:fait_5/2.195quite_3:tout_3/1.921quite_3:tout_3/3.715quite_3:fait_5/3.98911understandable_4:comprehensible_6/2.161 12/0._5:._7/0.432Figure 2: A heavily pruned alignment lattice for the English-French sentence paire=?it is quite understandable .?
f=?ce est tout a fait comprehensible .
?.5.6.3 Decoder PerformanceThe performance of the decoders under variousloss functions is given in Table 1.
We observe thatin none of these experiments was the ML decoderfound to be optimal.
In all instances, the MBRdecoder tuned for each loss function was the bestperforming decoder under the corresponding errorrate.
In particular, we note that alignment perfor-mance as measured under the AER metric can beimproved by using MBR instead of ML alignment.This demonstrates the value of finding decoding pro-cedures matched to the performance criterion of in-terest.We observe some affinity among the loss func-tions.
In particular, the ML decoder performs betterunder the AER than any of the MBR-GAE decoders.This is because the loss, for which the ML de-coder is optimal, is closer to the loss than anyof the loss functions.
The NULL symbol istreated quite differently under and , andthis leads to a large mismatch between the MBR-GAE decoders and the AER metric.
Similarly, theperformance of the MBR-POS decoder degradessignificantly under the AWCD-S and AWCD-A met-rics.
Since there are more word clusters (100) thanPOS tags (55), the MBR-POS decoder is thereforeincapable of producing hypotheses that can matchthe word clusters used in the AWCD metrics.6 Discussion And ConclusionsWe have presented a Minimum Bayes-Risk decod-ing strategy for obtaining word alignments of bilin-gual texts.
MBR decoding is a general formulationthat allows the construction of specialized decodersfrom general purpose models.
The strategy aims atdirect minimization of the expected risk of align-ment errors under a given alignment loss function.We have introduced several alignment loss func-tions to measure the alignment quality.
These in-corporate information from varied analyses, suchas parse trees, POS tags, and automatically derivedword clusters.
We have derived and implementedlattice based MBR consensus decoders under theseloss functions.
These decoders rescore the latticesproduced by maximum likelihood decoding to pro-duce the optimal MBR alignments.We have chosen to present MBR decoding usingthe IBM-3 statistical MT models implemented viaWFSTs.
However MBR decoding is not restrictedto this framework.
It can be applied more broadlyusing other MT model architectures that might beselected for reasons of modeling fidelity or compu-tational efficiency.We have presented these alignment loss functionsto explore how linguistic knowledge might be in-corporated into machine translation systems withoutbuilding detailed statistical models of these linguis-tic features.
However we stress that the MBR decod-ing procedures described here do not preclude theconstruction of complex MT models that incorporatelinguistic features.
The application of such mod-els, which could be trained using conventional max-imum likelihood estimation techniques, should stillbenefit by the application of MBR decoding tech-niques.In future work we will investigate loss functionsthat incorporate French and English parse-tree infor-mation into the alignment decoding process.
Our ul-timate goal, towards which this work is the first step,is to construct loss functions that take advantage oflinguistic structures such as syntactic dependenciesfound through monolingual analysis of the sentencesto be aligned.
Recent work (Hwa et al, 2002) sug-gests that translational corresponence of linguisticstructures can indeed be useful in projecting parsesacross languages.
Our ideal would be to constructMBR decoders based on loss functions that are sen-sitive both to word alignment as well as to agreementin higher level structures such as parse trees.
In thisway ambiguity present in word-to-word alignmentswill be resolved by the alignment of linguistic struc-tures.Generalized Alignment Error RatesDecoder AER PTSD-S POSD-S AWCD-S PTSD-A POSD-A AWCD-AML 18.13 3.13 4.35 4.69 29.39 51.36 54.58MBR-AE 14.87 1.34 1.89 1.94 19.81 36.42 38.58MBR-PTSD 23.26 0.62 0.69 0.82 14.45 26.76 28.42MBR-POSD 28.60 2.43 0.69 3.23 15.70 26.28 29.48MBR-AWCD 24.71 1.00 0.95 0.86 14.92 26.83 28.39Table 1: Performance (%) of the MBR decoders under the Alignment Error and Generalized AlignmentError Rates.
For each metric the error rate of the matched decoder is in bold.MBR alignment is a promising modeling frame-work for the detailed linguistic annotation of bilin-gual texts.
It is a simple model rescoring formalismthat improves well trained statistical models by tun-ing them for particular performance criteria.
Ideally,it will be used to produce decoders optimized forthe loss functions that actually measure the qualitiesthat we wish to see in newly developed automaticsystems.AcknowledgmentsWe would like to thank F. J. Och of RWTH, Aachenfor providing us the GIZA++ SMT toolkit, the mk-cls toolkit to train word classes, the Hansards 50Ktraining and test data, and the reference word align-ments and AER metric software.
We would also liketo thank P. Resnik, R. Hwa and O. Kolak of the Univ.of Maryland for useful discussions and help with theGIZA++ setup.
We thank AT&T Labs - Research foruse of the FSM Toolkit.
This work was supported byan ONR MURI grant N00014-01-1-0685.ReferencesP.
J. Bickel and K. A. Doksum.
1977.
MathematicalStatistics: Basic Ideas and Selected topics.
Holden-Day Inc., Oakland, CA, USA.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: Parameter estimation.
Computa-tional Linguistics, 19(2):263?311.M.
Collins.
1999.
Head-Driven Statistical Models forNatural Language Parsing.
Ph.D. thesis, Universityof Pennsylvania, Philadelphia, PA, USA.V.
Goel and W. Byrne.
2000.
Minimum Bayes-risk auto-matic speech recognition.
Computer Speech and Lan-guage, 14(2):115?135.R.
Hwa, P. Resnik, A. Weinberg, and O. Kolak.
2002.Evaluating translational correspondence using annota-tion projection.
In Proceedings of ACL-2002.
To ap-pear.R.
Kneser and H. Ney.
1991.
Forming word classes bystatistical clustering for statistical language modelling.In The 1st Quantititative Linguistics Conference, Trier,Germany.K.
Knight and Y. Al-Onaizan.
1998.
Translation withfinite-state devices.
In Proceedings of the AMTA Con-ference, pages 421?437, Langhorne, PA, USA.M.
Mittendorfer and W. Winiwarter.
2001.
Experimentswith the use of syntactic analysis in information re-trieval.
In Proceedings of the 6th International Work-shop on Applications of Natural Language and Infor-mation Systems, Bonn, Germany.M.
Mohri, F. C. N. Pereira, and M. Riley.
2000.
Thedesign principles of a weighted finite-state transducerlibrary.
Theoretical Computer Science, 231(1):17?32.M.
Mohri, F. Pereira, and M. Riley, 2001.
ATTGeneral-purpose finite-state machine software tools.http://www.research.att.com/sw/tools/fsm/.F.
Och and H. Ney.
2000a.
A comparison of alignmentmodels for statistical machine translation.
In Proceed-ings Of 18th Conference On Computational Linguis-tics, pages 1086?1090, Saarbrucken, Germany.F.
Och and H. Ney.
2000b.
Improved statistical align-ment models.
In Proceedings of ACL-2000, pages440?447, Hong Kong, China.K.
Papineni, S. Roukos, T. Ward, J. Henderson, andF.
Reeder.
2002.
Corpus-based comprehensive and di-agnostic mt evaluation: Initial arabic, chinese, french,and spanish results.
In Proceedings of HLT 2002.A.
Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 133?142, Philadelphia, PA, USA.F.
Wessel, K. Macherey, and R. Schlueter.
1998.
Us-ing word probabilities as confidence measures.
In Pro-ceedings of ICASSP-98, pages 225?228, Seattle, WA,USA.
