Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 434?438,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsReordering Constraint Based on Document-Level ContextTakashi Onishi and Masao Utiyama and Eiichiro SumitaMultilingual Translation Laboratory, MASTAR ProjectNational Institute of Information and Communications Technology3-5 Hikaridai, Keihanna Science City, Kyoto, JAPAN{takashi.onishi,mutiyama,eiichiro.sumita}@nict.go.jpAbstractOne problem with phrase-based statistical ma-chine translation is the problem of long-distance reordering when translating betweenlanguages with different word orders, such asJapanese-English.
In this paper, we propose amethod of imposing reordering constraints us-ing document-level context.
As the document-level context, we use noun phrases which sig-nificantly occur in context documents contain-ing source sentences.
Given a source sen-tence, zones which cover the noun phrases areused as reordering constraints.
Then, in de-coding, reorderings which violate the zonesare restricted.
Experiment results for patenttranslation tasks show a significant improve-ment of 1.20% BLEU points in Japanese-English translation and 1.41% BLEU points inEnglish-Japanese translation.1 IntroductionPhrase-based statistical machine translation is use-ful for translating between languages with similarword orders.
However, it has problems with long-distance reordering when translating between lan-guages with different word orders, such as Japanese-English.
These problems are especially crucial whentranslating long sentences, such as patent sentences,because many combinations of word orders causehigh computational costs and low translation qual-ity.In order to address these problems, various meth-ods which use syntactic information have been pro-posed.
These include methods where source sen-tences are divided into syntactic chunks or clausesand the translations are merged later (Koehn andKnight, 2003; Sudoh et al, 2010), methods wheresyntactic constraints or penalties for reordering areadded to a decoder (Yamamoto et al, 2008; Cherry,2008; Marton and Resnik, 2008; Xiong et al, 2010),and methods where source sentences are reorderedinto a similar word order as the target language inadvance (Katz-Brown and Collins, 2008; Isozakiet al, 2010).
However, these methods did notuse document-level context to constrain reorderings.Document-level context is often available in real-lifesituations.
We think it is a promising clue to improv-ing translation quality.In this paper, we propose a method where re-ordering constraints are added to a decoder usingdocument-level context.
As the document-level con-text, we use noun phrases which significantly oc-cur in context documents containing source sen-tences.
Given a source sentence, zones which coverthe noun phrases are used as reordering constraints.Then, in decoding, reorderings which violate thezones are restricted.
By using document-level con-text, contextually-appropriate reordering constraintsare preferentially considered.
As a result, the trans-lation quality and speed can be improved.
Ex-periment results for the NTCIR-8 patent transla-tion tasks show a significant improvement of 1.20%BLEU points in Japanese-English translation and1.41%BLEU points in English-Japanese translation.2 Patent TranslationPatent translation is difficult because of the amountof new phrases and long sentences.
Since a patentdocument explains a newly-invented apparatus ormethod, it contains many new phrases.
Learningphrase translations for these new phrases from the434Source ???????????????????????????????????????????????
?Reference the pad electrode 11 is formed on the top surface of the semiconductor substrate 10 through aninterlayer insulation film 12 that is a first insulation film .Baseline output an interlayer insulating film 12 is formed on the surface of a semiconductor substrate 10 , apad electrode 11 via a first insulating film .Source + Zone ?????????
<zone>???
<zone>???
</zone>?????
<zone>???
</zone>??
</zone>??????????????????????
?Proposed output pad electrode 11 is formed on the surface of the semiconductor substrate 10 through the inter-layer insulating film 12 of the first insulating film .Table 1: An example of patent translation.training corpora is difficult because these phrasesoccur only in that patent specification.
Therefore,when translating such phrases, a decoder has to com-bine multiple smaller phrase translations.
More-over, sentences in patent documents tend to be long.This results in a large number of combinations ofphrasal reorderings and a degradation of the transla-tion quality and speed.Table 1 shows how a failure in phrasal reorder-ing can spoil the whole translation.
In the baselineoutput, the translation of ????????????
??
?
?
??
(an interlayer insulation film12 that is a first insulation film) is divided into twoblocks, ?an interlayer insulating film 12?
and ?a firstinsulating film?.
In this case, a reordering constraintto translate ??????????????????
as a single block can reduce incorrect reorder-ings and improve the translation quality.
However,it is difficult to predict what should be translated asa single block.Therefore, how to specify ranges for reorderingconstraints is a very important problem.
We proposea solution for this problem that uses the very natureof patent documents themselves.3 Proposed MethodIn order to address the aforementioned problem, wepropose a method for specifying phrases in a sourcesentence which are assumed to be translated as sin-gle blocks using document-level context.
We callthese phrases ?coherent phrases?.
When translat-ing a document, for example a patent specification,we first extract coherent phrase candidates from thedocument.
Then, when translating each sentence inthe document, we set zones which cover the coher-ent phrase candidates and restrict reorderings whichviolate the zones.3.1 Coherent phrases in patent documentsAs mentioned in the previous section, specifyingcoherent phrases is difficult when using only onesource sentence.
However, we have observed thatdocument-level context can be a clue for specify-ing coherent phrases.
In a patent specification, forexample, noun phrases which indicate parts of theinvention are very important noun phrases.
In pre-vious example, ??
?
?
??
?
?
??
??
??
?
?
??
is a part of the invention.
Since thisis not language dependent, in other words, this nounphrase is always a part of the invention in any otherlanguage, this noun phrase should be translated as asingle block in every language.
In this way, impor-tant phrases in patent documents are assumed to becoherent phrases.We therefore treat the problem of specifying co-herent phrases as a problem of specifying importantphrases, and we use these phrases as constraints onreorderings.
The details of the proposed method aredescribed below.3.2 Finding coherent phrasesWe propose the following method for finding co-herent phrases in patent sentences.
First, we ex-tract coherent phrase candidates from a patent docu-ment.
Next, the candidates are ranked by a criterionwhich reflects the document-level context.
Then,we specify coherent phrases using the rankings.
Inthis method, using document-level context is criti-cally important because we cannot rank the candi-dates without it.4353.2.1 Extracting coherent phrase candidatesCoherent phrase candidates are extracted from acontext document, a document that contains a sourcesentence.
We extract all noun phrases as co-herent phrase candidates since most noun phrasescan be translated as single blocks in other lan-guages (Koehn and Knight, 2003).
These nounphrases include nested noun phrases.3.2.2 Ranking with C-valueThe candidates which have been extracted are nestedand have different lengths.
A naive method can-not rank these candidates properly.
For example,ranking by frequency cannot pick up an importantphrase which has a long length, yet, ranking bylength may give a long but unimportant phrase ahigh rank.
In order to select the appropriate coher-ent phrases, measurements which give high rank tophrases with high termhood are needed.
As one suchmeasurement, we use C-value (Frantzi and Anani-adou, 1996).C-value is a measurement of automatic termrecognition and is suitable for extracting importantphrases from nested candidates.
The C-value of aphrase p is expressed in the following equation:C-value(p)={(l(p)?1)n(p) (c(p)=0)(l(p)?1)(n(p)?
t(p)c(p))(c(p)>0)wherel(p) is the length of a phrase p,n(p) is the frequency of p in a document,t(p) is the total frequency of phrases which containp as a subphrase,c(p) is the number of those phrases.Since phrases which have a large C-value fre-quently occur in a context document, these phrasesare considered to be a significant unit, i.e., a part ofthe invention, and to be coherent phrases.3.2.3 Specifying coherent phrasesGiven a source sentence, we find coherent phrasecandidates in the sentence in order to set zones forreordering constraints.
If a coherent phrase candi-date is found in the source sentence, the phrase is re-garded a coherent phrase and annotated with a zonetag, which will be mentioned in the next section.We check the coherent phrase candidates in the sen-tence in descending C-value order, and stop whenthe C-value goes below a certain threshold.
Nestedzones are allowed, unless their zones conflict withpre-existing zones.
We then give the zone-taggedsentence, an example is shown in Table 1, as a de-coder input.3.3 Decoding with reordering constraintsIn decoding, reorderings which violate zones, suchas the baseline output in Table 1, are restricted andwe get a more appropriate translation, such as theproposed output in Table 1.We use the Moses decoder (Koehn et al, 2007;Koehn and Haddow, 2009), which can specify re-ordering constraints using <zone> and </zone> tags.Moses restricts reorderings which violate zones andtranslates zones as single blocks.4 ExperimentsIn order to evaluate the performance of the proposedmethod, we conducted Japanese-English (J-E) andEnglish-Japanese (E-J) translation experiments us-ing the NTCIR-8 patent translation task dataset (Fu-jii et al, 2010).
This dataset contains a training set of3 million sentence pairs, a development set of 2,000sentence pairs, and a test set of 1,251 (J-E) and 1,119(E-J) sentence pairs.
Moreover, this dataset containsthe patent specifications from which sentence pairsare extracted.
We used these patent specifications ascontext documents.4.1 BaselineWe usedMoses as a baseline system, with all the set-tings except distortion limit (dl) at the default.
Thedistortion limit is a maximum distance of reorder-ing.
It is known that an appropriate distortion-limitcan improve translation quality and decoding speed.Therefore, we examined the effect of a distortion-limit.
In experiments, we compared dl = 6, 10, 20,30, 40, and ?1 (unlimited).
The feature weightswere optimized to maximize BLEU score by MERT(Och, 2003) using the development set.4.2 Compared methodsWe compared two methods, the method of specify-ing reordering constraints with a context document436w/o Context in ( this case ) , ( the leading end ) 15f of ( the segment operating body ) ( ( 15 swings ) in( a direction opposite ) ) to ( the a arrow direction ) .w/ Context in ( this case ) , ( ( the leading end ) 15f ) of ( ( ( the segment ) operating body ) 15 )swings in a direction opposite to ( the a arrow direction ) .Table 3: An example of the zone-tagged source sentence.
<zone> and </zone> are replaced by ?(?
and ?
)?.J?E E?JSystem dl BLEU Time BLEU TimeBaseline6 27.83 4.8 35.39 3.510 30.15 6.9 38.14 4.920 30.65 11.9 38.39 8.530 30.72 16.0 38.32 11.540 29.96 19.6 38.42 13.9?1 30.35 28.7 37.80 18.4w/o Context ?1 30.01 8.7 38.96 5.9w/ Context ?1 31.55 12.0 39.21 8.0Table 2: BLEU score (%) and average decoding time(sec/sentence) in J-E/E-J translation.
(w/ Context) and the method of specifying reorder-ing constraints without a context document (w/oContext).
In both methods, the feature weights usedin decoding are the same value as those for the base-line (dl = ?1).4.2.1 Proposed method (w/ Context)In the proposed method, reordering constraints weredefined with a context document.
For J-E transla-tion, we used the CaboCha parser (Kudo and Mat-sumoto, 2002) to analyze the context document.
Ascoherent phrase candidates, we extracted all sub-trees whose heads are noun.
For E-J translation, weused the Charniak parser (Charniak, 2000) and ex-tracted all noun phrases, labeled ?NP?, as coherentphrase candidates.
The parsers are used only whenextracting coherent phrase candidates.
When speci-fying zones for each source sentence, strings whichmatch the coherent phrase candidates are defined tobe zones.
Therefore, the proposed method is robustagainst parsing errors.
We tried various thresholdsof the C-value and selected the value that yieldedthe highest BLEU score for the development set.4.2.2 w/o ContextIn this method, reordering constraints were definedwithout a context document.
For J-E translation,we converted the dependency trees of source sen-tences processed by the CaboCha parser into brack-eted trees and used these as reordering constraints.For E-J translation, we used all of the noun phrasesdetected by the Charniak parser as reordering con-straints.4.3 Results and DiscussionsThe experiment results are shown in Table 2.
Forevaluation, we used the case-insensitive BLEU met-ric (Papineni et al, 2002) with a single reference.In both directions, our proposed method yieldedthe highest BLEU scores.
The absolute improve-ment over the baseline (dl = ?1) was 1.20% in J-Etranslation and 1.41% in E-J translation.
Accord-ing to the bootstrap resampling test (Koehn, 2004),the improvement over the baseline was statisticallysignificant (p<0.01) in both directions.
When com-pared to the method without context, the absoluteimprovement was 1.54% in J-E and 0.25% in E-J.The improvement over the baseline was statisticallysignificant (p < 0.01) in J-E and almost significant(p < 0.1) in E-J.
These results show that the pro-posed method using document-level context is effec-tive in specifying reordering constraints.Moreover, as shown in Table 3, although zonesetting without context is failed if source sen-tences have parsing errors, the proposed method canset zones appropriately using document-level con-text.
The Charniak parser tends to make errors onnoun phrases with ID numbers.
This shows thatdocument-level context can possibly improve pars-ing quality.As for the distortion limit, while an appropriatedistortion-limit, 30 for J-E and 40 for E-J, improvedthe translation quality, the gains from the proposedmethod were significantly better than the gains fromthe distortion limit.
In general, imposing strongconstraints causes fast decoding but low translationquality.
However, the proposed method improvesthe translation quality and speed by imposing appro-priate constraints.4375 ConclusionIn this paper, we proposed a method for imposingreordering constraints using document-level context.In the proposed method, coherent phrase candidatesare extracted from a context document in advance.Given a source sentence, zones which cover the co-herent phrase candidates are defined.
Then, in de-coding, reorderings which violate the zones are re-stricted.
Since reordering constraints reduce incor-rect reorderings, the translation quality and speedcan be improved.
The experiment results for theNTCIR-8 patent translation tasks show a significantimprovement of 1.20% BLEU points for J-E trans-lation and 1.41% BLEU points for E-J translation.We think that the proposed method is indepen-dent of language pair and domains.
In the future,we want to apply our proposed method to other lan-guage pairs and domains.ReferencesEugene Charniak.
2000.
A Maximum-Entropy-InspiredParser.
In Proceedings of the 1st North Americanchapter of the Association for Computational Linguis-tics conference, pages 132?139.Colin Cherry.
2008.
Cohesive Phrase-Based Decodingfor Statistical Machine Translation.
In Proceedings ofACL-08: HLT, pages 72?80.Katerina T. Frantzi and Sophia Ananiadou.
1996.
Ex-tracting Nested Collocations.
In Proceedings of COL-ING 1996, pages 41?46.Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, Take-hito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, andSayori Shimohata.
2010.
Overview of the PatentTranslation Task at the NTCIR-8 Workshop.
In Pro-ceedings of NTCIR-8 Workshop Meeting, pages 371?376.Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, andKevin Duh.
2010.
Head Finalization: A Simple Re-ordering Rule for SOV Languages.
In Proceedings ofthe Joint Fifth Workshop on Statistical Machine Trans-lation and MetricsMATR, pages 244?251.Jason Katz-Brown and Michael Collins.
2008.
Syntac-tic Reordering in Preprocessing for Japanese?EnglishTranslation: MIT System Description for NTCIR-7Patent Translation Task.
In Proceedings of NTCIR-7Workshop Meeting, pages 409?414.Philipp Koehn and Barry Haddow.
2009.
Edinburgh?sSubmission to all Tracks of the WMT 2009 SharedTask with Reordering and Speed Improvements toMoses.
In Proceedings of the Fourth Workshop on Sta-tistical Machine Translation, pages 160?164.Philipp Koehn and Kevin Knight.
2003.
Feature-RichStatistical Translation of Noun Phrases.
In Proceed-ings of the 41st Annual Meeting of the Association forComputational Linguistics, pages 311?318.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
In Pro-ceedings of the 45th Annual Meeting of the Associ-ation for Computational Linguistics Companion Vol-ume Proceedings of the Demo and Poster Sessions,pages 177?180.Philipp Koehn.
2004.
Statistical Significance Tests forMachine Translation Evaluation.
In Proceedings ofEMNLP 2004, pages 388?395.Taku Kudo and Yuji Matsumoto.
2002.
Japanese De-pendency Analysis using Cascaded Chunking.
In Pro-ceedings of CoNLL-2002, pages 63?69.Yuval Marton and Philip Resnik.
2008.
Soft Syntac-tic Constraints for Hierarchical Phrased-Based Trans-lation.
In Proceedings of ACL-08: HLT, pages 1003?1011.Franz Josef Och.
2003.
Minimum Error Rate Training inStatistical Machine Translation.
In Proceedings of the41st Annual Meeting of the Association for Computa-tional Linguistics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a Method for Automatic Eval-uation of Machine Translation.
In Proceedings of 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 311?318.Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, TsutomuHirao, and Masaaki Nagata.
2010.
Divide and Trans-late: Improving Long Distance Reordering in Statisti-cal Machine Translation.
In Proceedings of the JointFifth Workshop on Statistical Machine Translation andMetricsMATR, pages 418?427.Deyi Xiong, Min Zhang, and Haizhou Li.
2010.
Learn-ing Translation Boundaries for Phrase-Based Decod-ing.
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages136?144.Hirofumi Yamamoto, Hideo Okuma, and EiichiroSumita.
2008.
Imposing Constraints from the SourceTree on ITG Constraints for SMT.
In Proceedingsof the ACL-08: HLT Second Workshop on Syntax andStructure in Statistical Translation (SSST-2), pages 1?9.438
