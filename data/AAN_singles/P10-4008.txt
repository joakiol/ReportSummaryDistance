Proceedings of the ACL 2010 System Demonstrations, pages 42?47,Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational LinguisticsAn Open-Source Package for Recognizing Textual EntailmentMilen Kouylekov and Matteo NegriFBK - Fondazione Bruno KesslerVia Sommarive 18, 38100 Povo (TN), Italy[kouylekov,negri]@fbk.euAbstractThis paper presents a general-purposeopen source package for recognizing Tex-tual Entailment.
The system implements acollection of algorithms, providing a con-figurable framework to quickly set up aworking environment to experiment withthe RTE task.
Fast prototyping of newsolutions is also allowed by the possibil-ity to extend its modular architecture.
Wepresent the tool as a useful resource to ap-proach the Textual Entailment problem, asan instrument for didactic purposes, and asan opportunity to create a collaborative en-vironment to promote research in the field.1 IntroductionTextual Entailment (TE) has been proposed asa unifying generic framework for modeling lan-guage variability and semantic inference in dif-ferent Natural Language Processing (NLP) tasks.The Recognizing Textual Entailment (RTE) task(Dagan and Glickman, 2007) consists in deciding,given two text fragments (respectively called Text- T, and Hypothesis - H), whether the meaning ofH can be inferred from the meaning of T, as in:T: ?Yahoo acquired Overture?H: ?Yahoo owns Overture?The RTE problem is relevant for many differentareas of text processing research, since it repre-sents the core of the semantic-oriented inferencesinvolved in a variety of practical NLP applicationsincluding Question Answering, Information Re-trieval, Information Extraction, Document Sum-marization, and Machine Translation.
However, inspite of the great potential of integrating RTE intocomplex NLP architectures, little has been doneto actually move from the controlled scenario pro-posed by the RTE evaluation campaigns1 to morepractical applications.
On one side, current RTEtechnology might not be mature enough to providereliable components for such integration.
Due tothe intrinsic complexity of the problem, in fact,state of the art results still show large room for im-provement.
On the other side, the lack of availabletools makes experimentation with the task, and thefast prototyping of new solutions, particularly dif-ficult.
To the best of our knowledge, the broadliterature describing RTE systems is not accompa-nied with a corresponding effort on making thesesystems open-source, or at least freely available.We believe that RTE research would significantlybenefit from such availability, since it would allowto quickly set up a working environment for ex-periments, encourage participation of newcomers,and eventually promote state of the art advances.The main contribution of this paper is to presentthe latest release of EDITS (Edit Distance TextualEntailment Suite), a freely available, open sourcesoftware package for recognizing Textual Entail-ment.
The system has been designed followingthree basic requirements:Modularity.
System architecture is such that theoverall processing task is broken up into majormodules.
Modules can be composed through aconfiguration file, and extended as plug-ins ac-cording to individual requirements.
System?sworkflow, the behavior of the basic components,and their IO formats are described in a compre-hensive documentation available upon download.Flexibility.
The system is general-purpose, andsuited for any TE corpus provided in a simpleXML format.
In addition, both language depen-dent and language independent configurations areallowed by algorithms that manipulate differentrepresentations of the input data.1TAC RTE Challenge: http://www.nist.gov/tacEVALITA TE task: http://evalita.itc.it42Figure 1: Entailment Engine, main componentsand workflowAdaptability.
Modules can be tuned over train-ing data to optimize performance along several di-mensions (e.g.
overall Accuracy, Precision/Recalltrade-off on YES and NO entailment judgements).In addition, an optimization component based ongenetic algorithms is available to automatically setparameters starting from a basic configuration.EDITS is open source, and available underGNU Lesser General Public Licence (LGPL).
Thetool is implemented in Java, it runs on Unix-basedOperating Systems, and has been tested on MACOSX, Linux, and Sun Solaris.
The latest releaseof the package can be downloaded from http://edits.fbk.eu.2 System OverviewThe EDITS package allows to:?
Create an Entailment Engine (Figure 1) bydefining its basic components (i.e.
algo-rithms, cost schemes, rules, and optimizers);?
Train such Entailment Engine over an anno-tated RTE corpus (containing T-H pairs anno-tated in terms of entailment) to learn aModel;?
Use the Entailment Engine and the Model toassign an entailment judgement and a confi-dence score to each pair of an un-annotatedtest corpus.EDITS implements a distance-based frameworkwhich assumes that the probability of an entail-ment relation between a given T-H pair is inverselyproportional to the distance between T and H (i.e.the higher the distance, the lower is the probabilityof entailment).
Within this framework the systemimplements and harmonizes different approachesto distance computation, providing both edit dis-tance algorithms, and similarity algorithms (seeSection 3.1).
Each algorithm returns a normalizeddistance score (a number between 0 and 1).
At atraining stage, distance scores calculated over an-notated T-H pairs are used to estimate a thresholdthat best separates positive from negative exam-ples.
The threshold, which is stored in a Model, isused at a test stage to assign an entailment judge-ment and a confidence score to each test pair.In the creation of a distance Entailment Engine,algorithms are combined with cost schemes (seeSection 3.2) that can be optimized to determinetheir behaviour (see Section 3.3), and optional ex-ternal knowledge represented as rules (see Section3.4).
Besides the definition of a single EntailmentEngine, a unique feature of EDITS is that it al-lows for the combination of multiple EntailmentEngines in different ways (see Section 4.4).Pre-defined basic components are already pro-vided with EDITS, allowing to create a variety ofentailment engines.
Fast prototyping of new solu-tions is also allowed by the possibility to extendthe modular architecture of the system with newalgorithms, cost schemes, rules, or plug-ins to newlanguage processing components.3 Basic ComponentsThis section overviews the main components ofa distance Entailment Engine, namely: i) algo-rithms, iii) cost schemes, iii) the cost optimizer,and iv) entailment/contradiction rules.3.1 AlgorithmsAlgorithms are used to compute a distance scorebetween T-H pairs.EDITS provides a set of predefined algorithms,including edit distance algorithms, and similar-ity algorithms adapted to the proposed distanceframework.
The choice of the available algorithmsis motivated by their large use documented in RTEliterature2.Edit distance algorithms cast the RTE task asthe problem of mapping the whole content of Hinto the content of T. Mappings are performedas sequences of editing operations (i.e.
insertion,deletion, substitution of text portions) needed totransform T into H, where each edit operation hasa cost associated with it.
The distance algorithmsavailable in the current release of the system are:2Detailed descriptions of all the systems participating inthe TAC RTE Challenge are available at http://www.nist.gov/tac/publications43?
Token Edit Distance: a token-based versionof the Levenshtein distance algorithm, withedit operations defined over sequences of to-kens of T and H;?
Tree Edit Distance: an implementation of thealgorithm described in (Zhang and Shasha,1990), with edit operations defined over sin-gle nodes of a syntactic representation of Tand H.Similarity algorithms are adapted to the ED-ITS distance framework by transforming measuresof the lexical/semantic similarity between T and Hinto distance measures.
These algorithms are alsoadapted to use the three edit operations to supportoverlap calculation, and define term weights.
Forinstance, substitutable terms in T and H can betreated as equal, and non-overlapping terms can beweighted proportionally to their insertion/deletioncosts.
Five similarity algorithms are available,namely:?
Word Overlap: computes an overall (dis-tance) score as the proportion of commonwords in T and H;?
Jaro-Winkler distance: a similarity algorithmbetween strings, adapted to similarity onwords;?
Cosine Similarity: a common vector-basedsimilarity measure;?
Longest Common Subsequence: searches thelongest possible sequence of words appearingboth in T and H in the same order, normaliz-ing its length by the length of H;?
Jaccard Coefficient: confronts the intersec-tion of words in T and H to their union.3.2 Cost SchemesCost schemes are used to define the cost of eachedit operation.Cost schemes are defined as XML files that ex-plicitly associate a cost (a positive real number) toeach edit operation applied to elements of T andH.
Elements, referred to as A and B, can be of dif-ferent types, depending on the algorithm used.
Forinstance, Tree Edit Distance will manipulate nodesin a dependency tree representation, whereas To-ken Edit Distance and similarity algorithms willmanipulate words.
Figure 2 shows an example of<scheme><insertion><cost>10</cost></insertion><deletion><cost>10</cost></deletion><substitution><condition>(equals A B)</condition><cost>0</cost></substitution><substitution><condition>(not (equals A B))</condition><cost>20</cost></substitution></scheme>Figure 2: Example of XML Cost Schemecost scheme, where edit operation costs are de-fined as follows:Insertion(B)=10 - inserting an element B from Hto T, no matter what B is, always costs 10;Deletion(A)=10 - deleting an element A from T,no matter what A is, always costs 10;substitution(A,B)=0 if A=B - substituting A withB costs 0 if A and B are equal;substitution(A,B)=20 if A !=B - substituting Awith B costs 20 if A and B are different.In the distance-based framework adopted byEDITS, the interaction between algorithms andcost schemes plays a central role.
Given a T-Hpair, in fact, the distance score returned by an al-gorithm directly depends on the cost of the opera-tions applied to transform T into H (edit distancealgorithms), or on the cost of mapping words inH with words in T (similarity algorithms).
Suchinteraction determines the overall behaviour of anEntailment Engine, since distance scores returnedby the same algorithm with different cost schemescan be considerably different.
This allows users todefine (and optimize, as explained in Section 3.3)the cost schemes that best suit the RTE data theywant to model3.EDITS provides two predefined cost schemes:?
Simple Cost Scheme - the one shown in Fig-ure 2, setting fixed costs for each edit opera-tion.?
IDF Cost Scheme - insertion and deletioncosts for a word w are set to the inverse doc-ument frequency of w (IDF(w)).
The sub-stitution cost is set to 0 if a word w1 fromT and a word w2 from H are the same, andIDF(w1)+IDF(w2) otherwise.3For instance, when dealing with T-H pairs composed bytexts that are much longer than the hypotheses (as in the RTE5Campaign), setting low deletion costs avoids penalization toshort Hs fully contained in the Ts.44In the creation of new cost schemes, users canexpress edit operation costs, and conditions overthe A and B elements, using a meta-languagebased on a lisp-like syntax (e.g.
(+ (IDF A) (IDFB)), (not (equals A B))).
The system also providesfunctions to access data stored in hash files.
Forexample, the IDF Cost Scheme accesses the IDFvalues of the most frequent 100K English words(calculated on the Brown Corpus) stored in a filedistributed with the system.
Users can create newhash files to collect statistics about words in otherlanguages, or other information to be used insidethe cost scheme.3.3 Cost OptimizerA cost optimizer is used to adapt cost schemes (ei-ther those provided with the system, or new onesdefined by the user) to specific datasets.The optimizer is based on cost adaptationthrough genetic algorithms, as proposed in(Mehdad, 2009).
To this aim, cost schemes canbe parametrized by externalizing as parameters theedit operations costs.
The optimizer iterates overtraining data using different values of these param-eters until on optimal set is found (i.e.
the one thatbest performs on the training set).3.4 RulesRules are used to provide the Entailment Enginewith knowledge (e.g.
lexical, syntactic, semantic)about the probability of entailment or contradic-tion between elements of T and H. Rules are in-voked by cost schemes to influence the cost of sub-stitutions between elements of T and H. Typically,the cost of the substitution between two elementsA and B is inversely proportional to the probabilitythat A entails B.Rules are stored in XML files called RuleRepositories, with the format shown in Figure 3.Each rule consists of three parts: i) a left-handside, ii) a right-hand side, iii) a probability thatthe left-hand side entails (or contradicts) the right-hand side.EDITS provides three predefined sets of lexicalentailment rules acquired from lexical resourceswidely used in RTE: WordNet4, Lin?s word sim-ilarity dictionaries5, and VerbOcean6.4http://wordnet.princeton.edu5http://webdocs.cs.ualberta.ca/ lindek/downloads.htm6http://demo.patrickpantel.com/Content/verbocean<rule entailment="ENTAILMENT"><t>acquire</t><h>own</h><probability>0.95</probability></rule><rule entailment="CONTRADICTION"><t>beautiful</t><h>ugly</h><probability>0.88</probability></rule>Figure 3: Example of XML Rule Repository4 Using the SystemThis section provides basic information about theuse of EDITS, which can be run with commandsin a Unix Shell.
A complete guide to all the pa-rameters of the main script is available as HTMLdocumentation downloadable with the package.4.1 InputThe input of the system is an entailment corpusrepresented in the EDITS Text Annotation Format(ETAF), a simple XML internal annotation for-mat.
ETAF is used to represent both the input T-Hpairs, and the entailment and contradiction rules.ETAF allows to represent texts at two differentlevels: i) as sequences of tokens with their asso-ciated morpho-syntactic properties, or ii) as syn-tactic trees with structural relations among nodes.Plug-ins for several widely used annotationtools (including TreeTagger, Stanford Parser, andOpenNLP) can be downloaded from the system?swebsite.
Users can also extend EDITS by imple-menting plug-ins to convert the output of other an-notation tools in ETAF.Publicly available RTE corpora (RTE 1-3, andEVALITA 2009), annotated in ETAF at both theannotation levels, are delivered together with thesystem to be used as first experimental datasets.4.2 ConfigurationThe creation of an Entailment Engine is done bydefining its basic components (algorithms, costschemes, optimizer, and rules) through an XMLconfiguration file.
The configuration file is dividedin modules, each having a set of options.
The fol-lowing XML fragment represents a simple exam-ple of configuration file:<module alias="distance"><module alias="tree"/><module alias="xml"><option name="scheme-file"45value="IDF_Scheme.xml"/></module><module alias="pso"/></module>This configuration defines a distance EntailmentEngine that combines Tree Edit Distance as a coredistance algorithm, and the predefined IDF CostScheme that will be optimized on training datawith the Particle Swarm Optimization algorithm(?pso?)
as in (Mehdad, 2009).
Adding externalknowledge to an entailment engine can be done byextending the configuration file with a reference toa rules file (e.g.
?rules.xml?)
as follows:<module alias="rules"><option name="rules-file"value="rules.xml"/></module>4.3 Training and TestGiven a configuration file and an RTE corpus an-notated in ETAF, the user can run the trainingprocedure to learn a model.
At this stage, ED-ITS allows to tune performance along several di-mensions (e.g.
overall Accuracy, Precision/Recalltrade-off on YES and/or NO entailment judge-ments).
By default the system maximizes the over-all accuracy (distinction between YES and NOpairs).
The output of the training phase is a model:a zip file that contains the learned threshold, theconfiguration file, the cost scheme, and the en-tailment/contradiction rules used to calculate thethreshold.
The explicit availability of all this in-formation in the model allows users to share, repli-cate and modify experiments7.Given a model and an un-annotated RTE corpusas input, the test procedure produces a file con-taining for each pair: i) the decision of the system(YES, NO), ii) the confidence of the decision, iii)the entailment score, iv) the sequence of edit oper-ations made to calculate the entailment score.4.4 Combining EnginesA relevant feature of EDITS is the possibility tocombine multiple Entailment Engines into a sin-gle one.
This can be done by grouping their def-initions as sub-modules in the configuration file.EDITS allows users to define customized combi-nation strategies, or to use two predefined com-bination modalities provided with the package,7Our policy is to publish online the models we use for par-ticipation in the RTE Challenges.
We encourage other usersof EDITS to do the same, thus creating a collaborative envi-ronment, allow new users to quickly modify working config-urations, and replicate results.Figure 4: Combined Entailment Enginesnamely: i) Linear Combination, and ii) Classi-fier Combination.
The two modalities combine indifferent ways the entailment scores produced bymultiple independent engines, and return a finaldecision for each T-H pair.Linear Combination returns an overall entail-ment score as the weighted sum of the entailmentscores returned by each engine:scorecombination =n?i=0scorei ?
weighti (1)In this formula, weighti is an ad-hoc weightparameter for each entailment engine.
Optimalweight parameters can be determined using thesame optimization strategy used to optimize thecost schemes, as described in Section 3.3.Classifier Combination is similar to the ap-proach proposed in (Malakasiotis and Androut-sopoulos, 2007), and is based on using the entail-ment scores returned by each engine as features totrain a classifier (see Figure 4).
To this aim, ED-ITS provides a plug-in that uses the Weka8 ma-chine learning workbench as a core.
By defaultthe plug-in uses an SVM classifier, but other Wekaalgorithms can be specified as options in the con-figuration file.The following configuration file describes acombination of two engines (i.e.
one based onTree Edit Distance, the other based on CosineSimilarity), used to train a classifier with Weka9.<module alias="weka"><module alias="distance"><module alias="tree"/><module alias="xml"><option name="scheme-file"value="IDF_Scheme.xml"/></module></module>8http://www.cs.waikato.ac.nz/ml/weka9A linear combination can be easily obtained by changingthe alias of the highest-level module (?weka?)
into ?linear?.46<module alias="distance"><module alias="cosine"/><module alias="IDF_Scheme.xml"/></module></module>5 Experiments with EDITSTo give an idea of the potentialities of the ED-ITS package in terms of flexibility and adaptabil-ity, this section reports some results achieved inRTE-related tasks by previous versions of the tool.The system has been tested in different scenarios,ranging from the evaluation of standalone systemswithin task-specific RTE Challenges, to their inte-gration in more complex architectures.As regards the RTE Challenges, in the lastyears EDITS has been used to participate both inthe PASCAL/TAC RTE Campaigns for the En-glish language (Mehdad et al, 2009), and in theEVALITA RTE task for Italian (Cabrio et al,2009).
In the last RTE-5 Campaign the resultachieved in the traditional ?2-way Main task?
(60.17% Accuracy) roughly corresponds to theperformance of the average participating systems(60.36%).
In the ?Search?
task (which consists infinding all the sentences that entail a given H ina given set of documents about a topic) the sameconfiguration achieved an F1 of 33.44%, rank-ing 3rd out of eight participants (average score29.17% F1).
In the EVALITA 2009 RTE task,EDITS ranked first with an overall 71.0% Accu-racy.
To promote the use of EDITS and ease ex-perimentation, the complete models used to pro-duce each submitted run can be downloaded withthe system.
An improved model obtained with thecurrent release of EDITS, and trained over RTE-5data (61.83% Accuracy on the ?2-way Main task?test set), is also available upon download.As regards application-oriented integrations,EDITS has been successfully used as a core com-ponent in a Restricted-Domain Question Answer-ing system within the EU-Funded QALL-MEProject10.
Within this project, an entailment-basedapproach to Relation Extraction has been definedas the task of checking for the existence of en-tailment relations between an input question (thetext in RTE parlance), and a set of textual realiza-tions of domain-specific binary relations (the hy-potheses in RTE parlance).
In recognizing 14 re-lations relevant in the CINEMA domain present ina collection of spoken English requests, the system10http://qallme.fbk.euachieved an F1 of 72.9%, allowing to return cor-rect answers to 83% of 400 test questions (Negriand Kouylekov, 2009).6 ConclusionWe have presented the first open source packagefor recognizing Textual Entailment.
The systemoffers a modular, flexible, and adaptable workingenvironment to experiment with the task.
In addi-tion, the availability of pre-defined system config-urations, tested in the past Evaluation Campaigns,represents a first contribution to set up a collabo-rative environment, and promote advances in RTEresearch.
Current activities are focusing on the de-velopment of a Graphical User Interface, to furthersimplify the use of the system.AcknowledgmentsThe research leading to these results has receivedfunding from the European Community?s Sev-enth Framework Programme (FP7/2007-2013) un-der Grant Agreement n. 248531 (CoSyne project).ReferencesProdromos Malakasiotis and Ion Androutsopoulos2007.
Learning Textual Entailment using SVMs andString Similarity Measures.
Proc.
of the ACL ?07Workshop on Textual Entailment and Paraphrasing.Ido Dagan and 0ren Glickman 2004.
ProbabilisticTextual Entailment: Generic Applied Modeling ofLanguage Variability.
Proc.
of the PASCAL Work-shop on Learning Methods for Text Understandingand Mining.Kaizhong Zhang and Dennis Shasha 1990.
Fast Al-gorithm for the Unit Cost Editing Distance BetweenTrees.
Journal of Algorithms.
vol.11.Yashar Mehdad 2009.
Automatic Cost Estimation forTree Edit Distance Using Particle Swarm Optimiza-tion.
Proc.
of ACL-IJCNLP 2009.Matteo Negri and Milen Kouylekov 2009.
QuestionAnswering over Structured Data: an Entailment-Based Approach to Question Analysis.
Proc.
ofRANLP-2009.Elena Cabrio, Yashar Mehdad, Matteo Negri, MilenKouylekov, and Bernardo Magnini 2009.
Rec-ognizing Textual Entailment for Italian EDITS @EVALITA 2009 Proc.
of EVALITA 2009.Yashar Mehdad, Matteo Negri, Elena Cabrio, MilenKouylekov, and Bernardo Magnini 2009.
Recogniz-ing Textual Entailment for English EDITS @ TAC2009 To appear in Proceedings of TAC 2009.47
