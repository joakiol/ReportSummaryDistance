Proceedings of the 6th EACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 107?111,Avignon, France, 24 April 2012. c?2012 Association for Computational LinguisticsNatural Language Inspired Approach for Handwritten Text LineDetection in Legacy Documents?Vicente Bosch CamposInst.
Tec.
de Informa?ticaUniv.
Polite?cnica ValenciaValencia - Spainvbosch@iti.upv.esAlejandro He?ctor ToselliInst.
Tec.
de Informa?ticaUniv.
Polite?cnica ValenciaValencia - Spainahector@iti.upv.esEnrique VidalInst.
Tec.
de Informa?ticaUniv.
Polite?cnica ValenciaValencia - Spainevidal@iti.upv.esAbstractDocument layout analysis is an importanttask needed for handwritten text recogni-tion among other applications.
Text lay-out commonly found in handwritten legacydocuments is in the form of one or moreparagraphs composed of parallel text lines.An approach for handwritten text line de-tection is presented which uses machine-learning techniques and methods widelyused in natural language processing.
It isshown that text line detection can be accu-rately solved using a formal methodology,as opposed to most of the proposed heuris-tic approaches found in the literature.
Ex-perimental results show the impact of us-ing increasingly constrained ?vertical lay-out language models?
in text line detectionaccuracy.1 IntroductionHandwritten text transcription is becoming an in-creasingly important task, in order to provide his-torians and other researchers new ways of index-ing, consulting and querying the huge amounts ofhistoric handwritten documents which are beingpublished in on-line digital libraries.Transcriptions of such documents are currentlyobtained with solutions that range from the use ofsystems that aim at fully automatic handwrittentext recognition (Bazzi et al, 1999)(HTR), to computer assisted transcription(CATTI), were the users participate interactivelyin the proper transcription process (Toselli et al,2009).
?Work supported under the MIPRCV ?ConsoliderIngenio 2010?
program (CSD2007-00018), MITTRAL(TIN2009-14633-C03-01) and also Univ.
Polite?cnica Valen-cia (PAID-05-11)The basic input to these systems consists of textline images.
Hence, text line detection and ex-traction from a given document page image be-comes a necessary preprocessing step in any kindof transcription systems.
Furthermore the qualityof line segmentation directly influences the finalaccuracy achieved by such systems.Detection of handwritten text lines in an im-age entails a greater difficulty, in comparison withprinted text lines, due to the inherent properties ofhandwritten text: variable inter-line spacing, over-lapping and touching strokes of adjacent hand-written lines, etc.The difficulty is further increased in the caseof ancient documents, due to common problemsappearing in them: presence of smear, significantbackground variations and uneven illumination,spots due to the humidity, and marks resultingfrom the ink that goes through the paper (gener-ally called ?bleed-through?
).Among the most popular state-of-the art meth-ods involved in handwritten text line detectionwe find four main families: based on (ver-tical) projection profiles (Likforman-Sulem etal., 2007), on the Hough transform (Likforman-Sulem et al, 1995), the repulsive-attractive net-work approach (O?ztop et al, 1999) and finallythe so-called stochastic methods (Vinciarelli et al,2004), which combine probabilistic models suchas Hidden Markov Models (HMMs) along withdynamic programming techniques (e.g.
Viterbialgorithm) to derive optimal paths between over-lapping text lines.It is worth noting that, most of the mentionedapproaches somewhat involve heuristic adjust-ments of their parameters, which have to be prop-erly tuned according to the characteristics of each107task in order to obtain adequate results.In this work, the text line detection problem inlegacy handwritten documents is approached byusing machine-learning techniques and methodswhich are widely used in natural language pro-cessing (NLP).It is shown that the text line detection problemcan be solved by using a formal methodology, asopposed to most of the currently proposed heuris-tic based approaches found in the literature.2 Statistical Framework for Text LineDetectionFor the work presented in this paper, we assumethat the input image (of a page or selected region)contains one or more paragraphs of single-columnparallel text with no images or diagram figures.Additionally, we assume that the input image hasbeen properly preprocessed so as to ensure thattheir text lines are roughly horizontal.
These as-sumptions are reasonable enough for most legacyhandwritten documents.Similarly to how the statistic framework ofautomatic speech recognition (ASR) is estab-lished, the handwritten text line detection prob-lem can be also formulated as the problem offinding the most likely text lines sequence, h?
=?h1, h2, .
.
.
, hn?, for a given handwritten pageimage represented by a sequence of observations1o = ?o1, o2, .
.
.
, om?, that is:h?
= argmaxhP (h | o) (1)Using the Bayes?
rule we can decompose theprobability P (h | o) into two terms:h?
= argmaxhP (o | h) ?
P (h) (2)In the jargon of NLP these probabilities rep-resent the morphological and syntactic knowl-edge levels, respectively.
As it happens in ASR,P (o | h) is typically approximated by HMMs,which model vertical page regions, while P (h)by a ?language model?
(LM), which restricts howthose regions are composed in order to form anactual page.
In what follows, a detailed descrip-tion of this modelling scheme is given.1Henceforward, in the context of this formal framework,each time it is mentioned image of page or selected text, weare implicitly referring to the input feature vector sequence?o?
describing it.2.1 ModellingIn our line detection approach four different kindsof vertical regions are defined:Blank Line-region (BL): Large rectangular re-gion of blank space usually found at the startand the end of a page (top and bottom mar-gins).Normal text Line-region (NL): Region oc-cupied by the main body of a normalhandwritten text line.Inter Line-region (IL): Defined as the regionfound within two consecutive normal textlines, characterized by being crossed by theascenders and descenders belonging to theadjacent text lines.Non-text Line-region (NT): Stands for every-thing which does not belong to any of theother regions.Figure 1: Examples of the different kind of line-regions.We model each of these regions by an HMMwhich is trained with instances of such regions.Basically, each line-region HMM is a stochasticfinite-state device that models the succession offeature vectors extracted from instances of thisline-region image.
In turn, each HMM stategenerates feature vectors following an adequateparametric probabilistic law; typically, a mixtureof Gaussian densities.
The adequate number ofstates and Gaussians per state may be conditionedby the available amount of training data.Once an HMM ?topology?
(number of statesand structure) has been adopted, the model pa-rameters can be easily trained from instances (se-quences of features vectors) of full images con-taining a sequence of line-regions (without any108kind of segmentation) accompanied by the refer-ence labels of these images into the correspond-ing sequence of line-region classes.
This trainingprocess is carried out using a well known instanceof the EM algorithm called forward-backward orBaum-Welch re-estimation (Jelinek, 1998).The syntactic modelling level is responsible forthe way that the different line regions are com-posed in order to produce a valid page structure.For example we can force that NL and NT lineregions must always be followed by IL inter-lineregions: NL+IL and NT+IL.
We can also usethe LM to impose restrictions about the mini-mum or maximum number of line-regions to bedetected.
The LM for our text line detection ap-proach, consists in a stochastic finite state gram-mar (SFSG) which recognizes valid sequences ofelements (line regions): NL+IL, NT+IL and BL.Both modelling levels, morphological and syn-tactical, which are represented by finite-state au-tomaton, can be integrated into a single globalmodel on which Eq.
(2) is easily solved; that is,given an input sequence of raw feature vectors,an output string of recognized sequence of line-region labels is obtained.
In addition the verticalposition of each detected line and and line-regionis obtained as a by-product.3 System ArchitecturePage layoutcorpusLM ModelOff-line  lineHMMsHMM Training LM TrainingPreprocessingFeature ExtractionDecodingTrainingPage ImagesCleaned PageImagesFeature VectorsType label and Region positioncoordinatesFigure 2: Global scheme of the handwritten text linedetection process.The flow diagram of Fig.
2 displays the overallprocess of the proposed handwritten text line de-tection approach.
It is composed of four differentphases: image preprocessing, feature extraction,HMMs and LM training and decoding.
Next wewill overview the first two phases, preprocessingand feature extraction, since the rest has alreadybeen covered in the preceding section.3.1 Preprocessing PhaseInitially performing background removal andnoise reduction is carried out by applying a bi-dimensional median filter on them.
The resultingimage skew is corrected by applying vertical pro-jection profile and RLSA (Wong and Wahl, 1982),along with standard techniques to calculate theskew angle.3.2 Feature Extraction PhaseAs our text line detection approach is based onHMMs, each preprocessed image must be rep-resented as a sequence of feature vectors.This isdone by dividing the already preprocessed image(from left-to-right) into D non-overlapping rect-angular regions with height equal to the image-height (see Fig.
3).In each of these rectangular regions we calcu-late the vertical grey level histogram.
RLSA isapplied to obtain a more emphasized vertical pro-jection profile.
Finally, to eliminate local maximaon the obtained vertical projection profiles, theyare smoothed with a rolling median filter (Man-matha and Srimal, 1999) (see Fig.
3) .
In this way,Figure 4: Review of the impact of the RLSA androlling media filter on the histogram calculation of asample line.a D-dimensional feature vector is constructed foreach page/block image pixels row, by stacking theD projection profile values corresponding to thatrow.
Hence, at the end of this process, a sequenceof L D-dimensional feature vectors is obtained,where L is the image height.4 Experimental Setup and ResultsIn order to study the efficacy of the line detectionapproach proposed in this paper, different experi-ments were carried out.
We are mainly interestedin assessing the impact upon final text line detec-1091 2 3 4 5Figure 3: Partial page image visualization of 5 (D = 5) rectangular regions across over 3 handwritten text lines.For each region, its vertical projection profile is also plotted.tion accuracy of employing increasingly restric-tive LMs.4.1 Corpus DescriptionExperiments are carried out with corpus compiledfrom a XIX century Spanish manuscript identifiedas ?Cristo-Salvador?
(CS), which was kindly pro-vided by the Biblioteca Valenciana Digital (Bi-VaLDi)2.
This is a rather small document com-posed of 53 colour images of text pages, scannedat 300 dpi and written by a single writer.
Somepage images examples are shown in Fig.
5.Figure 5: Examples of pages images from CS corpus.In this work we employ the so-called bookpartition, which has been defined for this data-set (Romero et al, 2007).
Its test set containsthe last 20 page images were as the training setis composed of the 33 remaining pages.
Table 1summarizes the relevant information of this parti-tion.Table 1: Basic statistics of the Cristo-Salvador corpuspartition.Number of: Training Test TotalPages 33 20 53Normal-text lines (NL) 685 497 1 182Blank Lines (BL) 73 70 143Non-text Lines (NT) 16 8 24Inter Lines (IL) 701 505 1 206Each page was annotated with a succession ofreference labels (NL, NT, BL and IL) indicating2http://bv2.gva.es.the kind of line-regions that composed it.
Suchreferences were generated by executing standardmethods for text line detection based on verticalprojection profiles, which were afterwards manu-ally labelled, verified, adjusted and/or rectified bya human operator to ensure correctness.4.2 Evaluation MeasuresWe measure the quality of the text line detec-tion by means of the ?line error rate?
(LER)which is performed by comparing the sequencesof automatically obtained region labels with thecorresponding reference label sequences.
TheLER is computed in the same way as the wellknown WER, with equal costs assigned to dele-tions, insertions and substitutions (McCowan etal., 2004).4.3 Experiments and ResultsA series of experiments were performed on the CScorpus using a simple hold-out validation as perthe CS ?book?
partition.
Initially some param-eters were set up: feature extraction dimensionD, HMM topology (number of states and Gaus-sians),number of Baum-Welch iterations, and de-coding grammar scale factor (GSF) and word in-sertion penalty (WIP).
After some informal exper-imentation, adequate values were found for sev-eral of them: feature vectors dimension of 2, left-to-right HMMs with 4 states topology, 32 Gaus-sian mixtures per state trained by running 3 cyclesof Baum-Welch re-estimation algorithm.
The re-maining parameters, all related with the decodingprocess itself, were tuned to obtain the best figuresfor each of the two following language models:the prior and conditional represented by topolog-ically different SFSGs.
The prior model transi-tion probabilities are estimated from the trainingset as the fraction of the number of appearancesof each vertical region label over the whole countof labels.
The conditional model also considersthe previous label in order to perform the estima-tion.
These estimates resemble the uni-gram and110bi-gram LMs calculations, except no smoothingstrategy is implemented here.Additionally, it is defined for each test page aline-number constrained LM which uses the con-ditional probabilities to populate the model butenforces a total number of possible line-regions todetect as per the number of reference line-regionlabels of that test page.
Table 2 reports the ob-tained LER results for each of these LMs.Table 2: Best detection LER(%) obtained for eachkind of language model: Prior, Conditional and Line-Number Constrained.LM WIP GSF LER(%)Prior -32 8 0.86Conditional -8 16 0.70LN-Constrained -128 1 0.34As can be seen, the more restrictive the LMis, the better accuracy is achieved.
Concerningthe line-number constrained, they are really con-ceived for its utilization in (parts of) documentsor document collections with homogeneous num-bers of lines per page.5 ConclusionsWe have presented a new approach for text linedetection by using a statistical framework similarto that already employed in many topics of NLP.It avoids the traditional heuristics approaches usu-ally adopted for this task.The accuracy of this approach is similar to orbetter than that of current state of the art solutionsfound in the literature.
We find that the detectedbaselines provided by our approach are of betterquality (visually closer to the actual line) than cur-rent heuristic methods as can be seen in 6.Figure 6: Image shows the difference between our pro-posed method (upper side of each coloured region )and the histogram projection method (lower side)In the future we will extend this approach notonly to detect, but also to classify line-regiontypes in order to determine for example titles,short lines, beginning and and end of paragraphs,etc.
Furthermore, it is envisioned that the pro-posed stochastic framework serves as a corner-stone to implementing interactive approaches toline detection similar to those used for handwrit-ten text transcription used in (Toselli et al, 2009).ReferencesIssam Bazzi, Richard Schwartz, and John Makhoul.1999.
An omnifont open-vocabulary OCR systemfor English and Arabic.
IEEE Transactions on Pat-tern Analysis and Machine Intelligence, 21(6):495?504.Frederick Jelinek.
1998.
Statistical methods forspeech recognition.
MIT Press.Laurence Likforman-Sulem, Anahid Hanimyan, andClaudie Faure.
1995.
A hough based algorithmfor extracting text lines in handwritten documents.Document Analysis and Recognition, InternationalConference on, 2:774.Laurence Likforman-Sulem, Abderrazak Zahour, andBruno Taconet.
2007.
Text line segmentation ofhistorical documents: a survey.
International Jour-nal on Document Analysis and Recognition, 9:123?138, April.Raghavan Manmatha and Nitin Srimal.
1999.
Scalespace technique for word segmentation in handwrit-ten documents.
In Proceedings of the Second In-ternational Conference on Scale-Space Theories inComputer Vision, SCALE-SPACE ?99, pages 22?33, London, UK.
Springer-Verlag.Iain A. McCowan, Darren Moore, John Dines, DanielGatica-Perez, Mike Flynn, Pierre Wellner, andHerve?
Bourlard.
2004.
On the use of informa-tion retrieval measures for speech recognition eval-uation.
Idiap-RR Idiap-RR-73-2004, IDIAP, Mar-tigny, Switzerland, 0.Vero?nica Romero, Alejandro He?ctor Toselli, LuisRodr?
?guez, and Enrique Vidal.
2007.
Com-puter Assisted Transcription for Ancient Text Im-ages.
In International Conference on Image Anal-ysis and Recognition (ICIAR 2007), volume 4633of LNCS, pages 1182?1193.
Springer-Verlag, Mon-treal (Canada), August.Alejandro He?ctor Toselli, Vero?nica Romero, Moise?sPastor, and Enrique Vidal.
2009.
Multimodal inter-active transcription of text images.
Pattern Recog-nition, 43(5):1824?1825.Alessandro Vinciarelli, Samy Bengio, and HorstBunke.
2004.
Off-line recognition of uncon-strained handwritten texts using hmms and statisti-cal language models.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 26(6):709?720,june.Kwan Y. Wong and Friedrich M. Wahl.
1982.
Doc-ument analysis system.
IBM Journal of Researchand Development, 26:647?656.Erhan O?ztop, Adem Y. Mu?layim, Volkan Atalay, andFatos Yarman-Vural.
1999.
Repulsive attractivenetwork for baseline extraction on document im-ages.
Signal Processing, 75(1):1 ?
10.111
