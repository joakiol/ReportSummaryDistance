Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 697?705,Berlin, Germany, August 7-12, 2016. c?2016 Association for Computational LinguisticsAraSenTi: Large-Scale Twitter-Specific Arabic Sentiment LexiconsNora Al-Twairesh1,2, Hend Al-Khalifa2, AbdulMalik Al-Salman1Computer Science Department1, Information Technology Department2College of Computer and Information SciencesKing Saud University{twairesh,hendk,salman@ksu.edu.sa}AbstractSentiment Analysis (SA) is an active researcharea nowadays due to the tremendous interestin aggregating and evaluating opinions beingdisseminated by users on the Web.
SA ofEnglish has been thoroughly researched;however research on SA of Arabic has justflourished.
Twitter is considered a powerfultool for disseminating information and a richresource for opinionated text containingviews on many different topics.
In this paperwe attempt to bridge a gap in Arabic SA ofTwitter which is the lack of sentiment lexi-cons that are tailored for the informal lan-guage of Twitter.
We generate two lexiconsextracted from a large dataset of tweets usingtwo approaches and evaluate their use in asimple lexicon based method.
The evaluationis performed on internal and external da-tasets.
The performance of these automatical-ly generated lexicons was very promising, al-beit the simple method used for classification.The best F-score obtained was 89.58% on theinternal dataset and 63.1-64.7% on the exter-nal datasets.1 IntroductionThe past decade has witnessed the proliferationof social media websites which has led to theproduction of vast amounts of unstructured texton the Web.
This text can be characterized asobjective, i.e.
containing facts, or subjective i.e.containing opinions and sentiments about enti-ties.
Sentiment Analysis (SA) is the researchfield that is concerned with identifying opinionsin text and classifying them as positive, negativeor neutral.
SA of English has been thoroughlyresearched; however research on SA of Arabichas just flourished.Arabic is ranked fourth among languages onthe web although it is the fastest growing lan-guage on the web among other languages (Inter-net World Stats, 2015).
Arabic is a morphologi-cally rich language where one lemma can havehundreds of surface forms; this complicates thetasks of SA.
Moreover, the Arabic language hasmany variants.
The formal language is calledModern Standard Arabic (MSA) and the spokenlanguage differs in different Arabic countriesproducing numerous Arabic dialects sometimescalled informal Arabic or colloquial Arabic.
Thelanguage used in social media is known to behighly dialectal (Darwish and Magdy, 2014).Dialects differ from MSA phonologically, mor-phologically and syntactically and they do nothave standard orthographies (Habash, 2010).Consequently, resources built for MSA cannot beadapted to dialects very well.The informal language used in social mediaand in Twitter in particular makes the SA oftweets a challenging task.
The language on socialmedia is known to contain slang, nonstandardspellings and evolves by time.
As such sentimentlexicons that are built from standard dictionariescannot adequately capture the informal languagein social media text.
Therefore, in this paper wepropose to generate Arabic sentiment lexiconsthat are tweet-specific i.e.
generated from tweets.We present two approaches to generating Arabicsentiment lexicons from a large dataset of 2.2million tweets.
The lexicons are evaluated onthree datasets, one internal dataset extracted fromthe larger dataset of tweets and two external da-tasets from the literature on Arabic SA.
Moreo-ver, the lexicons are compared to an external Ar-abic lexicon generated also from tweets.
A sim-ple lexicon-based method is used to evaluate thelexicons.This paper is organized as follows: Section 2reviews the related work on sentiment lexicongeneration.
Section 3 describes the details of thedatasets used to generate the lexicons and howthey were collected.
Section 4 presents the ap-proaches used to generate the lexicons.
Section 5details the experimental setup while Section 6presents and analyzes the results.
Finally, we697conclude the paper and present potential futurework in Section 7.2 Related WorkWords that convey positive or negative sentimentare fundamental for sentiment analysis.
Compil-ing a list of these words is what is referred to assentiment lexicon generation.
There are threeapproaches to generate a sentiment lexicon (Liu,2012): manual approach, dictionary-based ap-proach, and corpus-based approach.
The manu-al approach is usually not done alone since it istime consuming and labor intensive.
It is usedhowever, in conjunction with automated ap-proaches to check the correction of the resultinglexicons from these approaches.
In this sectionwe review popular English and Arabic sentimentlexicons in the literature.2.1 English Sentiment LexiconsIn the dictionary based approach as thename implies a dictionary is used by utilizing thesynonym and antonym lists that are associatedwith dictionary words.
The technique starts witha small set of sentiment words as seeds withknown positive or negative orientations.
Theseed words are looked up in the dictionary thentheir synonyms and antonyms are added to theseed set and a new iteration starts.
The processends when no new words are found.
A manualinspection is usually done after the process endsto correct errors.
A majority of studies under thisapproach used the WordNet with different ap-proaches for expanding the list such as distance-based measures (Kamps, 2004; Williams andAnand, 2009) and graph-based methods (Blair-Goldensohn et al, 2008; Rao and Ravichandran,2009).
Pioneering work in this approach is theconstruction of SentiWordNet by (Esuli and Se-bastiani, 2005).
Initially, they started with a setof positive seeds and a set of negative seeds thenexpanded the sets using the synonym and anto-nym relations in WordNet.
This formed a train-ing set which they used in a supervised learningclassifier and applied it to all the glosses inWordNet, the process is run iteratively.
Then in afollowing attempt (Esuli and Sebastiani, 2006), acommittee of classifiers based on the previousmethod were used to build SentiWordNet whichcontains terms that are associated with threescores for objectivity, positivity and negativity,where the sum of the scores is 1.
The latest ver-sion is SentiWordNet 3.0 (Baccianella et al,2010).As for corpus-based approaches, the wordsof the lexicon are extracted from the corpus us-ing a seed list of known sentiment words anddifferent approaches to find words of similar oropposite polarity.
One of the earliest work in thisapproach was that of (Hatzivassiloglou andMcKeown, 1997), where they utilized connec-tives e.g.
and, but, etc.
between adjectives in acorpus to learn new sentiment words not in theseed list.
Turney, (2002); Turney and Littman,(2002) used the once popular AltaVista searchengine to find the sentiment of a certain wordthrough calculating the association strength be-tween the word and a set of positive words minusthe association strength between the word and aset of negative words.
The association strengthwas measured using Pointwise-Mutual Infor-mation (PMI).
The result is the sentiment scoreof the word, if it is positive this means the wordis strongly associated with positive polarity andas such its polarity will be positive and if it isnegative the word?s polarity will be negative.The magnitude indicates the sentiment intensityof the word.
We used PMI to generate one of thelexicons in this paper.After the emergence of sentiment analysis asan evolving research field, several lexicons wereconstructed according to the approaches men-tioned above.
In the Bing Liu?s lexicon (Hu andLiu, 2004), which falls under the dictionary-based method, the WordNet was exploited toinfer the semantic orientation of adjectives ex-tracted from customer reviews.
The lexicon onlyprovides the prior polarity of words: positive ornegative, the sentiment intensity of the wordswas not calculated.
Another popular sentimentlexicon is the MPQA subjectivity lexicon (Wil-son et al, 2005) which was constructed by man-ually annotating the subjective expressions in theMPQA corpus.
The words were annotated withfour tags: positive, negative, both and neutralthen further classified as strong or weak to de-note intensity.
We use these two lexicons in thegeneration of the other lexicon in this paper.With the proliferation of social media web-sites, the need for lexicons that can capture thepeculiarities of social medial language emerges.As such, many solutions for sentiment analysisof social media and Twitter in particular initiateby developing sentiment lexicons that are ex-tracted from Twitter (Tang et al, 2014; Ki-ritchenko et al, 2014).2.2 Arabic Sentiment Lexicons01 102 203 304 405 506 607 708 809 910 011 112 213 314 415 516 617 718 819 920 021 022 023 024 025 026 027 028 029 030 031 032 033 034 035 036 037 038 039 040 041 042 043 044 045 046 047 048 049 050 051 052 053 054 055 0698Generating sentiment lexicons for Arabic hasgained the interest of the research communitylately.
Consequently, we found several efforts forgenerating these lexicons.
A recent effort to builda large scale multi-genre multi dialect Arabicsentiment lexicon was proposed by (Abdul-Mageed and Diab, 2014).
However, it coversonly two dialects: Egyptian and Levantine and isnot yet fully applied to SSA tasks.
Badaro et al,(2014) constructed ArSenL, a large scale Arabicsentiment lexicon.
They relied on four resourcesto create ArSenL: English WordNet (EWN), Ar-abic WordNet (AWN), English SentiWordNet(ESWN), and SAMA (Standard Arabic Morpho-logical Analyzer).
Two approaches were fol-lowed producing two different lexicons: the firstapproach used AWN, by mapping AWN entriesinto ESWN using existing offsets thus producingArSenL-AWN.
The second approach utilizesSAMA?s English glosses by finding the highestoverlapping synsets between these glosses andESWN thus producing ArSenL-Eng.
Hence Ar-SenL is the union of these two lexicons.
Alt-hough this lexicon can be considered as the larg-est Arabic sentiment lexicon developed to date, itis unfortunate that it only has MSA entries andno dialect words and is not developed from asocial media context which could affect the accu-racy when applied on social media text.Following the example of ArSenL, the lexiconSLSA (Sentiment Lexicon for Standard Arabic)(Eskander and Rambow, 2015) was constructedby linking the lexicon of an Arabic morphologi-cal analyzer Aramorph with SentiWordNet.
Alt-hough the approach is very similar to ArSenL,since both use SentiWordNet to obtain the scoresof words, the linking algorithm used to link theglosses in Aramorph with those in SentiWordNetis different.
SLSA starts by linking every entry inAramorph with SentiWordNet if the one-glossword and POS match.
Intrinsic and extrinsicevaluations were performed by comparing SLSAand ArSenL which demonstrated the superiorityof SLSA.
Nevertheless, SLSA like ArSenL doesnot include dialect words and cannot accuratelyanalyze social media text.Mohammad et al, (2015), generated three Ar-abic lexicons from Twitter.
Three datasets werecollected from Twitter: the first was tweets thatcontained the emoticons:?:)?
and ?
:(?, the secondwas tweets that contained a seed list of positiveand negative Arabic words as hashtags and thethird was also from tweets that contained Arabicpositive and negative words as hashtags but thesewere dialectal words.
Then using PMI three lexi-cons were generated from these datasets: ArabicEmoticon Lexicon, Arabic Hashtag Lexicon andDialectal Arabic Hashtag Lexicon.
Our approachin generating one of the lexicons is very similarand thus we use one of their lexicons in the ex-periments to compare with our lexicons.
The bestperforming lexicon was the Dialectal ArabicHashtag Lexicon therefore we use it in this paperto compare and evaluate our lexicons.3 Dataset CollectionWe followed the approaches in previous work onSA of English Twitter to collect the datasets.
Asin (Go et al, 2009; Pak and Paroubek, 2010) weutilized emoticons as noisy labels to constructthe first dataset EMO-TWEET.
Tweets contain-ing the emoticons: ?:)?
and ?:(?
and the rule?lang:ar?
(to retrieve Arabic tweets only) werecollected during November and December 2015.The total number of Tweets collected is shown inTable 1.Davidov et al, (2010) and Kiritchenko et al,(2014) used hashtags of sentiment words such as#good and #bad to create corpora of positive andnegative tweets, we adopted a similar method totheirs.
Initially, we tried collecting tweets thatcontain Arabic sentiment words with hashtagsbut the search results were too low.
We designat-ed this result to a cultural difference in usinghashtags between the western and eastern socie-ties.
Arabs do not use hashtags in this way.
Ac-cordingly we opted to use the sentiment words askeywords without the hashtag sign and the num-ber of search results was substantial.
Tweets con-taining 10 Arabic words having positive polarityand 10 Arabic words having negative polaritywere collected during January 2016.
The key-words are in Table 2 and the number of tweetscollected in Table1.
These results constitute oursecond dataset KEY-TWEET.Retweets, tweets containing URLs or mediaand tweets containing non-Arabic words were allexcluded from the dataset.
The reason for ex-cluding tweets with URLs and media is that wefound that most of the tweets that contain URLSand media were spam.
We also noticed that alt-hough we had specified in the search query thatthe fetched tweets should be in Arabic ?lang:ar?some of the tweets were in English and otherlanguages.
So we had to add a filter to eliminatetweets with non-Arabic characters.In total, the number of collected tweets wasaround 6.3 million Arabic tweets in a time spanof three months.
After filtration and cleaning of699the tweets, the remaining were 2.2 milliontweets.EMO-TWEET KEY-TWEETPositiveEmoticon:)NegativeEmoticon:(PositivekeywordsNegativekeywordsTotalnumber oftweetscollected2,245,054 1,272,352 1,823,517 1,000,212Aftercleaningand filter-ing1,033,393 407,828 447,170 337,535Number ofTokens12,739,308 5,082,070 9,058,412 7,135,331Table 1: Number of collected tweets, number oftweets in datasets after cleaning and filtering andnumber of tokens in each dataset.PositiveKeywordsEnglishTranslationNegativeKeywordsEnglishTranslation????
?sEAdpHappiness ????mHznSad??
?xyrGood ????m&sfRegrettable????
?tfA&lOptimism ????ll>sfUnfortunately?????
?>EjbnyI like it ???
?fA$lFailing, un-successful???
?njAHSuccess ?????t$A&mPessimism??
?frHJoy ???sy'Bad?????
?<yjAbyPositive ????slbyNegative??
?jydGood ?????<hmAlNegligence????
?mmtAzExcellent ???xT>Wrong???
?rA}EFabulous  ???
?m&lmPainfulTable 2: Positive and negative keywords used tocollect tweets.4 Lexicon GenerationTwo sentiment lexicons were extracted from thedatasets of tweets using two different approach-es.
We call the first AraSenTi-Trans and thesecond AraSenTi-PMI.
The approaches are pre-sented in the following subsections.4.1 AraSenTi-TransThe datasets of tweets were processed using theMADAMIRA tool (Pasha et al, 2014).
MAD-AMIRA is a recent effort by Pasha et al (2014)that combines some of the best aspects of twoprevious systems used for Arabic NLP: MADA-Morphological Analysis and Disambiguation ofArabic (Habash and Rambow, 2005; Roth et al,2008; Habash et al, 2009; Habash et al, 2013)and AMIRA (Diab et al, 2007).
MADAMIRA,on the other hand, improves on these two sys-tems with a solution that is more robust, portable,extensible, and faster.The MADAMIRA tool identifies words intothree types: ARABIC, NO_ANALYSIS andNON_ARABIC.
This feature was used to elimi-nate tweets containing non-Arabic words and todistinguish MSA words from dialect words asNO_ANALYSIS words can be identified as dia-lect words or misspelled words or new wordsmade up by tweepers (twitter users).
Accordingto the POS tags provided by MADAMIRA, weextracted only nouns, adjectives, adverbs, verbsand negation particles in an effort to eliminateunwanted stop words.Then we utilized two popular English senti-ment lexicons that were used in previous workon English and Arabic sentiment analysis: theLiu lexicon (Hu and Liu, 2004) and the MPQAlexicon (Wilson et al, 2005).Most previous papers on Arabic SA that usedthese lexicons just translated them into Arabic,yet we tried a different approach.
MADAMIRAprovides an English gloss for each word identi-fied as ARABIC, the gloss could be one, two orthree words.
We used this gloss to compare withthe Liu lexicon and MPQA lexicon using thefollowing heuristics:?
If all the word?s glosses are positive inboth lexicons or found in one lexicon aspositive and do not exist in the other lex-icon: classify as positive.?
If all the word?s glosses are negative inboth lexicons or found in one lexicon asnegative and do not exist in the other:classify as negative.?
If the word?s glosses have different po-larities in the lexicons or are (both) inMPQA: add to both list.?
Else: all remaining words are classifiedas neutral.Although this approach could contain some er-rors, a manual check can be performed to cleanup.
The manual cleanup is time consuming but itis a one-time effort that requires only a few days(Liu, 2012).
Accordingly we gave the automati-700cally generated lists of positive, negative, both,and neutral words to two Arabic native speakersto review and correct the errors.
We found that5% of the neutral words were incorrectly mis-classified as neutral while they were sentimentbearing words.
Also 10% of the positive wordswere misclassified as negative, and 15% of thenegative words were misclassified as positive.The lists were corrected accordingly.
We canconclude that using translated English lexiconsdoes not always give us accurate classification ofpolarity.
This result could be due to mistransla-tions or cultural differences in classifying senti-ment as demonstrated by  (Mohammad et al,2015; Mobarz et al, 2014; Duwairi, 2015).
Ac-cordingly, we propose a different approach togenerating another lexicon in the following sec-tion.4.2 AraSenti-PMIThe second lexicon was also generated from thedataset of tweets but through calculating thepointwise mutual information (PMI) measure forall words in the positive and negative datasets oftweets.
The PMI is a measure of the strength ofassociation between two words in a corpus, i.e.the probability of the two words to co-occur inthe corpus (Church and Hanks, 1990).
It has beenadapted in sentiment analysis as a measure of thefrequency of a word occurring in positive text tothe frequency of the same word occurring innegative text.
Turney, (2002); Turney andLittman, (2002) was the first work that proposedto use this measure in sentiment analysis.
Theyused the once popular AltaVista search engine tofind the sentiment of a certain word through cal-culating the PMI between the word and a set ofpositive words minus the PMI between the wordand a set of negative words.
Other works thatused PMI to generate sentiment lexicons can befound in (Kiritchenko et al, 2014; Mohammad etal., 2015).The frequencies of the words in the positiveand negative datasets of tweets were calculatedrespectively then the PMI was calculated foreach as follows:???
(?, ???)
= log2????(?,???)??????(?)?????(???
)(1)where freq(w,pos) is the frequency of the word win the positive tweets, freq(w) is the frequency ofthe word w in the dataset, freq(pos) is the totalnumber of tokens in the positive tweets and N isthe total number of tokens in the dataset.
ThePMI of the word associated with negative tweetsis calculated in the same way PMI(w,neg).
Thesentiment score for word w will be:Sentiment Score(w)=PMI(w,pos)-PMI(w,neg) (2)This was calculated for all words that occurredin the dataset five times or more, the reason forthis is that the PMI is a poor estimator of low-frequency words (Kiritchenko et al, 2014), sowords occurring less than 5 times were excluded.Also for words that are found in the set of posi-tive tweets but not in the set of negative tweets orvice versa, Equation 2 would give us a sentimentscore of ?, which would highly affect the calcu-lation of the sentiment of the whole tweet.
Sincethe absence of a word from the negative datasetdoes not require that the word?s sentiment is pos-itive or vice versa; as such we calculated the sen-timent score of such words as in Equation 1,PMI(w,pos) for words occurring only in the posi-tive tweets and PMI(w,neg) for words occurringonly in the negative tweets.4.3 Lexicons CoverageThe number of positive and negative entries ineach of the lexicons is shown in Table 3.
Thedetails of the lexicon of (Mohammad et al,2015) are also shown since this lexicon will beused in the experiments in the following sectionfor evaluation and comparison purposes.
Mo-hammad et al, (2015) generated three lexicons,however they demonstrated that the DialectalArabic Hashtag Lexicon (DAHL) gave the bestresults and accordingly we use this lexicon in theexperiments in this paper.
From Table 3, we cansee the high coverage of the generated lexiconsAraSenti-Trans and AraSenti-PMI when com-pared to DAHL.
In addition we manually exam-ined the three lexicons of (Mohammad et al,2015) and found that they were not cleaned.They contained non-Arabic words and hashtagsthat do not convey sentiment.
This put a questionmark on the validity of the lexicons and thenumber of entries reported.
Our datasets werecleaned from non-Arabic words and punctuation,so the generated lexicons all contain valid Arabicwords.Lexicon Positive Negative TotalAraSenti-Trans 59,52571,817 131,342AraSenti-PMI 56,938 37,023 93,961DAHL 11,947 8,179 20,126Table 3: Details of the generated lexicons and thelexicon they will be compared to.56 157 258 359 460 561 662 763 864 965 066 167 268 369 470 571 672 773 874 975 076 077 078 079 080 081 082 083 084 085 086 087 088 089 090 091 092 093 094 095 096 097 098 099 0100 0101 0102 0103 0104 0105 0106 0107 0108 0109 0110 07015 EvaluationTo evaluate the performance of the tweet-specific lexicons, we performed a set of experi-ments using a simple lexicon-based approach,hence no training and/or tuning is required.
Weperformed a two-way classification on the da-tasets (positive or negative).
We leave the prob-lem of three and four way classification (posi-tive, negative, neutral, mixed) for future work.We evaluated the generated lexicons on a datasetof 10,133 tweets extracted from the larger da-tasets of tweets EMO-TWEET and KEY-TWEET.
The tweets were manually annotated bythree annotators that are Arabic native speakers.The conflict between annotators was resolved bymajority voting.
We will call this datasetAraSenTi-Tweet.
We also evaluated the generat-ed lexicons on two external datasets of tweets:ASTD by (Nabil et al, 2015) and RR by (Refaeeand Rieser, 2014).
We extracted only the tweetsthat were labeled as positive or negative fromthese datasets.
The details of all the datasets usedin the experiments are illustrated in Table 4.
Weplan to release the dataset and the generated lexi-cons for the public.Dataset Positive Negative TotalAraSenti-Tweet 4329 5804 10133ASTD 797 1682 2479RR 876 1941 2817Table 4: Datasets used in the evaluation of thegenerated lexicons.Negation significantly affects the sentiment ofits scope and consequently affects the evaluationof the lexicons.
Accordingly, we propose toevaluate the generated lexicons in two settings:with and without negation handling.
We alsocompare the performance of the generated lexi-cons with a lexicon that was generated in a verysimilar approach to one of the lexicons.Since the datasets are unbalanced, we will re-port the performance measures of the macro-averaged F-score (Favg), precision (P) and recall(R) of the positive and negative classes as fol-lows:P= TP/(TP+FP)    (3)R=TP/(TP+FN)    (4)F=2*PR/P+R    (5)where in the case of the positive class: TP is thenumber of positive tweets classified correctly aspositive (true positive), FP is the number of neg-ative tweets falsely classified as positive (falsepositive), and FN is the number of positivetweets falsely classified as negative (false nega-tives).
The same holds for the negative class.Then the F-score is calculated as:????
=????+???
?2(6)5.1 Setup A: No Negation HandlingFor the AraSenTi-Trans lexicon, we use thesimple method of counting the number of posi-tive and negative words in the tweet and which-ever is the greatest denotes the sentiment of thetweet.
The results of applying this method on thedifferent datasets are illustrated in Table 5.As for the AraSenTi-PMI lexicon, the senti-ment score of all words in the tweet weresummed up.
The natural threshold to classify thedata into positive or negative would be zero,since positive scores denote positive sentimentand negative scores denote negative sentiment.However, according to (Kiritchenko et al, 2014)other thresholds could give better results.
Conse-quently, we experimented with the value of thisthreshold.
We set it to 0, 0.5,and 1 and found thatthe best results were obtained when setting thethreshold to 1.
As such if the sum of the senti-ment scores of the words in a tweet is greaterthan one, then the tweet is classified as positive,otherwise the tweet is classified as negative.5.2 Setup B:Negation HandlingWe also experimented with handling negation inthe tweet, by compiling a list of negation parti-cles found in the tweets and checking if the tweetcontains a negation particle or not.For the AraSenTi-Trans lexicon, if the tweetcontains a negation particle and a positive word,we do not increment the positive word counter.However, for tweets containing negative wordsand negation particles we found that not incre-menting the negative word counter degraded theaccuracy, so we opted to increment the negativeword counter even if a negation particle is foundin the tweet.Moreover, we experimented with adjusting thescore of negation particles in the AraSenTi-PMIlexicon.
After several experiments, we found thatadjusting the score of the negation particles to -1was the setting that gave the best performance.111 1112 2113 3114 4115 5116 6117 7118 8119 9120 0121 1122 2123 3124 4125 5126 6127 7128 8129 9130 0131 0132 0133 0134 0135 0136 0137 0138 0139 0140 0141 0142 0143 0144 0145 0146 0147 0148 0149 0150 0151 0152 0153 0154 0155 0156 0157 0158 0159 0160 0161 0162 0163 0164 0165 07026 Discussion and ResultsThe results of the first experimental setup for thetwo generated lexicons AraSenti-Trans andAraSenti-PMI are presented in Table 5.
For theRR dataset and AraSenti-Tweet dataset, the su-periority of the AraSenti-PMI lexicon is evident.The Favg of applying the AraSenti-PMI lexiconon the RR dataset is 63.6% while the Favg of ap-plying the AraSenti-PMI lexicon on the AraSen-ti-Tweet dataset is 88.92%.
As for the ASTDdataset, applying the AraSenti-Trans lexicongave better results with an Favg of 59.8%.In Table 6, the results of the lexicon-based meth-od with negation handling are presented.
Theresults of using the DAHL lexicon on the samedatasets are also reported for comparison.First of all, the effect of negation handling onperformance is significant, with increases of (1-4%) on all datasets.
Although the two lexiconsAraSenti-Trans and AraSenti-PMI handled nega-tion differently but the increase for every datasetwas almost the same: the ASTD dataset +4%, theRR dataset +1% and the AraSenti-Tweet dataset+2% and +1% respectively.When comparing the performance of the gen-erated lexicons AraSenti-Trans and AraSenti-PMI with the DAHL lexicon, we find that ourlexicons presented better classification results onall datasets.Finally, although the two lexicons were ex-tracted from the same dataset, we find that theirperformance varied on the different datasets.
Thebest performance for the ASTD dataset waswhen the AraSenti-Trans lexicon was used.However, the best performance for the RR andAraSenti-Tweet datasets was when the AraSenti-PMI lexicon was used.
Moreover, albeit the sim-ple lexicon-based method used in the evaluation,we find that the performance is encouraging.Several enhancements could be made such asincorporating Arabic valence shifters and certainlinguistic rules to handle them.LexiconDataSet AraSenti-Trans AraSenti-PMIPositve NegativeFavgPositve NegativeFavg   P R P R P R P RASTD 43.92 90.21 90.74 45.42 59.80 37.24 77.79 78.26 37.87 50.70RR 40.66 89.95 89.99 40.75 56.05 46.01 73.74 83.72 60.95 63.60AraSenti-Tweet 63.14 95.43 94.48 58.44 74.11 85.73 89.37 91.81 88.9 88.92Table 5: Results of the first experimental setup without negation handling on the generated lexiconsAraSenti-Trans and AraSenti-PMI.LexiconDataSet AraSenti-Trans AraSenti-PMI DAHLPositve  NegativeFavgPositve NegativeFavgPositve NegativeFavg   P R P R P R P R P R P RASTD 46.24 86.32 89 52.44 63.10 38.06 56.59 73.26 56.36 54.61 36.4 43.16 70.47 64.27 53.36RR 41.31 86.3 87.84 44.67 57.55 52.03 49.77 77.77 79.29 64.70 38.06 38.58 72.11 71.66 55.10AraSenti-Tweet66.27 90.76 90.49 65.54 76.31 91.16 84.57 89.08 93.88 89.58 76.35 62.88 75.53 85.48 74.58Table 6: Results of the second experimental setup with negation handling on the generated lexiconsAraSenti-Trans and AraSenti-PMI and on the external lexicon DAHL7 ConclusionIn this paper, two large-scale Arabic sentimentlexicons were generated from a large dataset ofArabic tweets.
The significance of these lexiconslies in their ability to capture the idiosyncraticnature of social media text.
Moreover, their highcoverage suggests the possibility of using themin different genres such as product reviews.
Thisis a possible future research direction.The performance of the lexicons on externaldatasets also suggests their ability to be used inclassifying new datasets.
However, there is muchroom for improvement given the simple method703used in evaluation.
This simple lexicon-basedmethod could be further enhanced by incorporat-ing Arabic valence shifters and certain linguisticrules to handle them.
We also plan to make theclassification multi-way: positive, negative, neu-tral and mixed.AcknowledgmentsThis Project was funded by the National Plan forScience, Technology and Innovation(MAARIFAH), King Abdulaziz City for Scienceand Technology, Kingdom of Saudi Arabia,Award Number (GSP-36-332).ReferencesMuhammad Abdul-Mageed and Mona Diab.
2014.SANA: A Large Scale Multi-Genre, Multi-DialectLexicon for Arabic Subjectivity and Sentiment Anal-ysis.
In In Proceedings of the Language Resourcesand Evaluation Conference (LREC), Reykjavik, Ice-land.Stefano Baccianella, Andrea Esuli, and Fabrizio Se-bastiani.
2010.
SentiWordNet 3.0: An Enhanced Lex-ical Resource for Sentiment Analysis and OpinionMining.
In LREC, volume 10, pages 2200?2204.Gilbert Badaro, Ramy Baly, Hazem Hajj, Nizar Ha-bash, and Wassim El-Hajj.
2014.
A large scale Arabicsentiment lexicon for Arabic opinion mining.
ANLP2014:165.Sasha Blair-Goldensohn, Kerry Hannan, RyanMcDonald, Tyler Neylon, George A Reis, and JeffReynar.
2008.
Building a sentiment summarizer forlocal service reviews.
In WWW Workshop on NLP inthe Information Explosion Era, volume 14, pages339?348.Kenneth Ward Church and Patrick Hanks.
1990.Word association norms, mutual information, andlexicography.
Computational linguistics, 16(1):22?29.Kareem Darwish and Walid Magdy.
2014.
ArabicInformation Retrieval.
Foundations and Trends inInformation Retrieval, 7(4):239?342.Dmitry Davidov, Oren Tsur, and Ari Rappoport.2010.
Enhanced sentiment learning using twitterhashtags and smileys.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics:Posters, pages 241?249.
Association for Computa-tional Linguistics.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.2007.
Automated methods for processing arabic text:from tokenization to base phrase chunking.
ArabicComputational Morphology: Knowledge-based andEmpirical Methods.
Kluwer/Springer.Rehab M Duwairi.
2015.
Sentiment analysis for dia-lectical Arabic.
In 6th International Conference onInformation and Communication Systems (ICICS),2015, pages 166?170.
IEEE.Ramy Eskander and Owen Rambow.
2015.
SLSA: ASentiment Lexicon for Standard Arabic.
In Proceed-ings of the 2015 Conference on Empirical Methods inNatural Language Processing, pages 2545?2550,Lisbon,Purtogal, September.
ACL.Andrea Esuli and Fabrizio Sebastiani.
2005.
Deter-mining the semantic orientation of terms throughgloss classification.
In Proceedings of the 14th ACMinternational conference on Information andknowledge management, pages 617?624.
ACM.Andrea Esuli and Fabrizio Sebastiani.
2006.
Senti-wordnet: A publicly available lexical resource foropinion mining.
In In Proceedings of the 5th Confer-ence on Language Resources and Evaluation(LREC?06), volume 6, pages 417?422.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.CS224N Project Report, Stanford:1?12.Nizar Habash and Owen Rambow.
2005.
Arabic to-kenization, part-of-speech tagging and morphologicaldisambiguation in one fell swoop.
In Proceedings ofthe 43rd Annual Meeting on Association for Compu-tational Linguistics, pages 573?580.
Association forComputational Linguistics.Nizar Habash, Owen Rambow, and Ryan Roth.
2009.Mada+ tokan: A toolkit for arabic tokenization, dia-critization, morphological disambiguation, pos tag-ging, stemming and lemmatization.
In Proceedings ofthe 2nd International Conference on Arabic Lan-guage Resources and Tools (MEDAR), Cairo, Egypt,pages 102?109.Nizar Habash, Ryan Roth, Owen Rambow, RamyEskander, and Nadi Tomeh.
2013.
MorphologicalAnalysis and Disambiguation for Dialectal Arabic.
InHLT-NAACL, pages 426?432.
Citeseer.Nizar Y Habash.
2010.
Introduction to Arabic naturallanguage processing.
Synthesis Lectures on HumanLanguage Technologies, 3(1):1?187.Vasileios Hatzivassiloglou and Kathleen R McKe-own.
1997.
Predicting the semantic orientation of ad-jectives.
In Proceedings of the 35th annual meeting ofthe association for computational linguistics andeighth conference of the european chapter of the as-704sociation for computational linguistics, pages 174?181.
Association for Computational Linguistics.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference onKnowledge discovery and data mining, pages 168?177.
ACM.Internet World Stats.
2015.
Internet World Stats.
No-vember.Jaap Kamps.
2004.
Using wordnet to measure seman-tic orientations of adjectives.
In Proceedings of the4th International Conference on Language Resourcesand Evaluation (LREC 2004).Svetlana Kiritchenko, Xiaodan Zhu, and Saif M Mo-hammad.
2014.
Sentiment analysis of short informaltexts.
Journal of Artificial Intelligence Research,50:723?762.Bing Liu.
2012.
Sentiment analysis and opinion min-ing.
Synthesis Lectures on Human Language Tech-nologies, 5(1):1?167.Hanaa Mobarz, Mohsen Rashown, and Ibrahim Farag.2014.
Using Automated Lexical Resources in ArabicSentence Subjectivity.
International Journal of Artifi-cial Intelligence & Applications, 5(6):1.Saif M Mohammad, Mohammad Salameh, and Svet-lana Kiritchenko.
2015.
How Translation Alters Sen-timent.
Journal of Artificial Intelligence Research,54:1?20.Mahmoud Nabil, Mohamed Aly, and Amir F Atiya.2015.
ASTD: Arabic Sentiment Tweets Dataset.
InProceedings of the 2015 Conference on EmpiricalMethods in Natural Language Processing, pages2515?2519.Alexander Pak and Patrick Paroubek.
2010.
Twitter asa Corpus for Sentiment Analysis and Opinion Mining.In Proceedings of the Sixth International Conferenceon Language Resources and Evaluation (LREC2010), Valleta,Malta.
European Language ResourcesAssociation (ELRA).Arfath Pasha, Mohamed Al-Badrashiny, Ahmed ElKholy, Ramy Eskander, Mona Diab, Nizar Habash,Manoj Pooleery, Owen Rambow, and Ryan Roth.2014.
Madamira: A fast, comprehensive tool for mor-phological analysis and disambiguation of arabic.
InIn Proceedings of the 9th International Conference onLanguage Resources and Evaluation, LREC 2014,Reykjavik, Iceland.
European Language ResourcesAssociation (ELRA).Delip Rao and Deepak Ravichandran.
2009.
Semi-supervised polarity lexicon induction.
In Proceedingsof the 12th Conference of the European Chapter ofthe Association for Computational Linguistics, pages675?682.
Association for Computational Linguistics.Eshrag Refaee and Verena Rieser.
2014.
An ArabicTwitter Corpus for Subjectivity and Sentiment Analy-sis.
In In Proceedings of the 9th International Confer-ence on Language Resources and Evaluation, LREC2014, Reykjavik, Iceland.
European Language Re-sources Association (ELRA).Ryan Roth, Owen Rambow, Nizar Habash, MonaDiab, and Cynthia Rudin.
2008.
Arabic morphologicaltagging, diacritization, and lemmatization using lex-eme models and feature ranking.
In Proceedings ofthe 46th Annual Meeting of the Association for Com-putational Linguistics on Human Language Technol-ogies: Short Papers, pages 117?120.
Association forComputational Linguistics.Duyu Tang, Furu Wei, Bing Qin, Ming Zhou, andTing Liu.
2014.
Building Large-Scale Twitter-Specific Sentiment Lexicon: A Representation Learn-ing Approach.
In COLING, pages 172?182.Peter D Turney.
2002.
Thumbs up or thumbs down?
:semantic orientation applied to unsupervised classifi-cation of reviews.
In Proceedings of the 40th annualmeeting on association for computational linguistics,pages 417?424.
Association for Computational Lin-guistics.Peter Turney and Michael L Littman.
2002.
Unsuper-vised learning of semantic orientation from a hun-dred-billion-word corpus.
Technical report, NationalResearch Council Canada, NRC Institute for Infor-mation Technology; National Research Council Can-ada.Gbolahan K Williams and Sarabjot Singh Anand.2009.
Predicting the Polarity Strength of AdjectivesUsing WordNet.
In Third International AAAI Confer-ence on Weblogs and Social Media.Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.2005.
Recognizing contextual polarity in phrase-levelsentiment analysis.
In Proceedings of the conferenceon human language technology and empirical meth-ods in natural language processing, pages 347?354.Association for Computational Linguistics.705
