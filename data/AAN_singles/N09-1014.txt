Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 119?127,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsGraph-based Learning for Statistical Machine TranslationAndrei AlexandrescuDept.
of Comp.
Sci.
Eng.University of WashingtonSeattle, WA 98195, USAandrei@cs.washington.eduKatrin KirchhoffDept.
of Electrical Eng.University of WashingtonSeattle, WA 98195, USAkatrin@ee.washington.eduAbstractCurrent phrase-based statistical machinetranslation systems process each test sentencein isolation and do not enforce global consis-tency constraints, even though the test datais often internally consistent with respect totopic or style.
We propose a new consistencymodel for machine translation in the formof a graph-based semi-supervised learningalgorithm that exploits similarities betweentraining and test data and also similaritiesbetween different test sentences.
The algo-rithm learns a regression function jointly overtraining and test data and uses the resultingscores to rerank translation hypotheses.
Eval-uation on two travel expression translationtasks demonstrates improvements of up to 2.6BLEU points absolute and 2.8% in PER.1 IntroductionCurrent phrase-based statistical machine translation(SMT) systems commonly operate at the sentencelevel?each sentence is translated in isolation, evenwhen the test data consists of internally coherentparagraphs or stories, such as news articles.
Foreach sentence, SMT systems choose the translationhypothesis that maximizes a combined log-linearmodel score, which is computed independently ofall other sentences, using globally optimized com-bination weights.
Thus, similar input strings maybe translated in very different ways, depending onwhich component model happens to dominate thecombined score for that sentence.
This is illustratedby the following example (from the IWSLT 2007Arabic-English translation task):Source 1: Asf lA ymknk *lk hnAk klfp HwAly vmAnyndwlAr lAlsAEp AlwAHdpRef: sorry you can?t there is a cost the charge is eightydollars per hour1-best: i?m sorry you can?t there in the cost about eightydollars for a one o?clockSource 2: E*rA lA ymknk t$gyl AltlfAz HtY tqlEAlTA}rpRef: sorry you cannot turn the tv on until the plane hastaken off1-best: excuse me i you turn tv until the plane departsThe phrase lA ymknk (you may not/you cannot)is translated differently (and wrongly in the sec-ond case) due to different segmentations and phrasetranslations chosen by the decoder.
Though differ-ent choices may be sometimes appropriate, the lackof constraints enforcing translation consistency of-ten leads to suboptimal translation performance.
Itwould be desirable to counter this effect by encour-aging similar outputs for similar inputs (under a suit-ably defined notion of similarity, which may includee.g.
a context specification for the phrase/sentence).In machine learning, the idea of forcing the out-puts of a statistical learner to vary smoothly with theunderlying structure of the inputs has been formal-ized in the graph-based learning (GBL) framework.In GBL, both labeled (train) and unlabeled (test)data samples are jointly represented as vertices in agraph whose edges encode pairwise similarities be-tween samples.
Various learning algorithms can beapplied to assign labels to the test samples while en-suring that the classification output varies smoothly119along the manifold defined by the graph.
GBL hasbeen successfully applied to a range of problems incomputer vision, computational biology, and natu-ral language processing.
However, in most cases,the learning tasks consisted of unstructured classi-fication, where the input was represented by fixed-length feature vectors and the output was one of afinite set of discrete labels.
In machine translation,by contrast, both inputs and outputs consist of wordstrings of variable length, and the number of possi-ble outputs is not fixed and practically unlimited.In this paper we propose a new graph-based learn-ing algorithm with structured inputs and outputs toimprove consistency in phrase-based statistical ma-chine translation.
We define a joint similarity graphover training and test data and use an iterative labelpropagation procedure to regress a scoring functionover the graph.
The resulting scores for unlabeledsamples (translation hypotheses) are then combinedwith standard model scores in a log-linear transla-tion model for the purpose of reranking.
Our con-tributions are twofold.
First, from a machine trans-lation perspective, we design and evaluate a globalconsistency model enforcing that similar inputs re-ceive similar translations.
Second, from a machinelearning perspective, we apply graph-based learningto a task with structured inputs and outputs, whichis a novel contribution in itself since previous ap-plications of GBL have focused on predicting cat-egorical labels.
We evaluate our approach on twomachine translation tasks, the IWSLT 2007 Italian-to-English and Arabic-to-English tasks, and demon-strate significant improvements over the baseline.2 Graph-Based LearningGBL algorithms rely on a similarity graph consistingof a set of nodes representing data samples xi (wherei ranges over 1, .
.
.
, l labeled points and l+1, .
.
.
, nunlabeled points), and a set of weighted edges en-coding pairwise similarities between samples.
Thegraph is characterized by a weight matrix W whoseelements Wij ?
0 are the similarity values for edgesbetween vertices xi and xj , and by its label vectorY = (y1, .
.
.
yl), yi ?
{1, .
.
.
, C} that defines la-bels for the first l points.
If there is no edge linkingnodes xi and xj , then Wij = 0.
There is consider-able freedom in choosing the weights.
The similar-ity measure used to compute the edge weights de-termines the graph structure and is the most impor-tant factor in successfully applying GBL.
In mostapplications of GBL, data samples are representedby fixed-length feature vectors, and cosine similar-ity or Euclidean distance-based measures are usedfor edge weights.Learning algorithms on similarity graphs includee.g.
min-cut (Blum and Chawla, 2001), spectralgraph transducer (Joachims, 2003), random walk-based approaches (Szummer and Jaakkola, 2001),and label propagation (Zhu and Ghahramani, 2002).The algorithm proposed herein is based on the latter.2.1 Label PropagationGiven a graph defined by a weight matrix W anda label set Y , the basic label propagation algorithmproceeds as follows:1.
Initialize the matrix P as Pij = Wij?WiiPj Wij?Wii2.
Initialize a n?
C matrix f with binary vectorsencoding the known labels for the first l rows:fi = ?C(yi) ?i ?
{1, 2, .
.
.
, l}, where ?C(yi) isthe Kronecker vector of length C with 1 in po-sition yi and 0 elsewhere.
The remaining rowsof f can be zero.3.
f ?
?
P ?
f4.
Clamp already-labeled data rows: f ?i = ?C(yi)?i ?
{1, 2, .
.
.
, l}5.
If f ?
?= f , stop.6.
f ?
f ?7.
Repeat from step 3.After convergence, f contains the solution in rowsl + 1 to n in the form of unnormalized label proba-bility distributions.
Hard labels can be obtained byy?i = argmaxj?
{1,...,C}fij ?i ?
{l + 1, .
.
.
, n} (1)The algorithm minimizes the following cost func-tion (Zhu, 2005):S =C?k=1?i>l ?
j>lWij(fik ?
fjk)2 (2)S measures the smoothness of the learned function,i.e., the extent to which the labeling allows large-weight edges to link nodes of different labels.
Byminimizing S , label propagation finds a labeling120that, to the extent possible, assigns similar soft labels(identical hard labels) to nodes linked by edges withlarge weights (i.e., highly similar samples).
Thelabeling decision takes into account not only sim-ilarities between labeled and unlabeled nodes (asin nearest-neighbor approaches) but also similaritiesamong unlabeled nodes.
Label propagation has beenused successfully for various classification tasks,e.g.
image classification and handwriting recogni-tion (Zhu, 2005).
In natural language processing, la-bel propagation has been used for document classifi-cation (Zhu, 2005), word sense disambiguation (Niuet al, 2005; Alexandrescu and Kirchhoff, 2007), andsentiment categorization (Goldberg and Zhu, 2006).3 Graph-Based Learning for MachineTranslationOur goal is to exploit graph-based learning for im-proving consistency in statistical phrase-based ma-chine translation.
Intuitively, a set of similar sourcesentences should receive similar target-languagetranslations.
This means that similarities betweentraining and test sentences should be taken into ac-count, but also similarities between different testsentences, which is a source of information currentlynot exploited by standard SMT systems.
To thisend we define a graph over the training and test setswith edges between test and training sentences aswell as between different test sentences.
In caseswhere a test sentence does not have any connectionsto training sentences but is connected to other testsentences, helpful information about preferred trans-lations can be propagated via these edges.As mentioned above, the problem of machinetranslation does not neatly fit into the standardGBL framework.
Given that our samples consistof variable-length word strings instead of featurevectors, the standard cosine or Euclidean-distancebased similarity measures cannot be used mean-ingfully, and the number of possible ?labels?
?correct translations?is unbounded and practicallyvery large.
We thus need to modify both the graphconstruction and the label propagation algorithms.First, we handle the problem of unlimited out-puts by applying GBL to rescoring only.
In mostSMT systems, an N -best list (generated by a first de-coding pass) approximates the search space of goodhypotheses reasonably well, provided N is largeenough.
For all hypotheses of all sentences in thetest set (set we denote with H), the system learns aranking function r : H ?
[0, 1].
Larger values of rindicate better hypotheses.
The corresponding lossfunctional isL(r) =?i,jWij [r(xi)?
r(xj)]2 (3)L(r) measures the smoothness of r over the graphby penalizing highly similar clusters of nodes thathave a high variance of r (in other words, simi-lar input sentences that have very different transla-tions).
The smaller L(r), the ?smoother?
r is overthe graph.
Thus, instead of directly learning a clas-sification function, we learn a regression function?similar to (Goldberg and Zhu, 2006)?that is thenused for ranking the hypotheses.3.1 Graph ConstructionEach graph node represents a sentence pair (consist-ing of source and target strings), and edge weightsrepresent the combined similarity scores computedfrom comparing both the source sides and targetsides of a pair of nodes.
Given a training setwith l source and target language sentence pairs(s1, t1), .
.
.
, (sl, tl) and a test set with l + 1, ..., nsource sentences, sl+1, .
.
.
, sn, the construction ofthe similarity graph proceeds as follows:1.
For each test sentence si, i = l + 1, .
.
.
, n,find a set Straini of similar training sourcesentences and a set Stesti of similar test sen-tences (excluding si and sentences identical toit) by applying a string similarity function ?
tothe source sides only and retaining sentenceswhose similarity exceeds a threshold ?.
Dif-ferent ?
?s can be used for training vs. test sen-tences; we use the same ?
for both sets.2.
For each hypothesis hsi generated for si by abaseline system, compute its similarity to thetarget sides of all sentences in Straini .
Theoverall similarity is then defined by the com-bined score?ij = ?
(?
(si, sj), ?
(hsi , tj)) (4)where i = l + 1, .
.
.
n, j = 1, .
.
.
, |Straini | and?
: R+ ?
R+ ?
R+ is an averaging function.121If ?ij > 0, establish graph nodes for hsi and tjand link them with an edge of weight ?ij .3.
For each hypothesis hsi and each hypothe-sis generated for each of the sentences sk ?
?testi , compute similarity on the target side anduse the combined similarity score as the edgeweight between nodes for hsi and hsk .4.
Finally,for each node xt representing a train-ing sentence, assign r(xt) = 1 and also de-fine its synthetic counterpart: a vertex x?t withr(x?t) = 0.
For each edge incident to xt ofweight Wth, define a corresponding edge ofweight 1?Wt?h.The synthetic nodes and edges need to be addedto prevent the label propagation algorithm from con-verging to the trivial solution that assigns r = 1 toall points in the graph.
This choice is theoreticallymotivated?a similarity graph for regression shouldhave not only ?sources?
(good nodes with high valueof r) but also ?sinks?
(counterparts for the sources).Figure 1 illustrates the connections of a test node.Similarity Measure The similarity measure usedfor comparing source and target sides is of primeimportance, as it determines the structure of thegraph.
This has consequences for both computa-tional efficiency (denser graphs require more com-putation and memory) and the accuracy of the out-come.
A low similarity threshold results in a richgraph with a large number of edges but possibly in-troduces noise.
A higher threshold leads to a smallgraph emphasizing highly similar samples but withtoo many disconnected components.
The similaritymeasure is also the means by which domain knowl-edge can be incorporated into the graph construc-tion process.
Similarity may be defined at the levelof surface word strings, but may also include lin-guistic information such as morphological features,part-of-speech tags, or syntactic structures.
Here,we compare two similarity measures: the famil-iar BLEU score (Papineni et al, 2002) and a scorebased on string kernels.
In using BLEU we treateach sentence as a complete document.
BLEU is notsymmetric?when comparing two sentences, differ-ent results are obtained depending on which one isconsidered the reference and which one is the hy-pothesis.
For computing similarities between trainand test translations, we use the train translation asthe reference.
For computing similarity between twotest hypotheses, we compute BLEU in both direc-tions and take the average.
We note that more ap-propriate distance measures are certainly possible.Many previous studies, such as (Callison-Burch etal., 2006), have pointed out drawbacks of BLEU,and any other similarity measure could be utilizedinstead.
In particular, similarity measures that modelaspects of sentences that are ill handled by standardphrase-based decoders (such as syntactic structureor semantic information) could be useful here.A more general way of computing similarity be-tween strings is provided by string kernels (Lodhi etal., 2002; Rousu and Shawe-Taylor, 2005), whichhave been extensively used in bioinformatics andemail spam detection.
String kernels map stringsinto a feature space defined by all possible sub-strings of the string up a fixed length k, and com-puting the dot product between the resulting featurevectors.
Several variants of basic string kernels ex-ist, notably those allowing gaps or mismatches, andefficient implementations have been devised evenfor large scale applications.
Formally, we define asentence s as a concatenation of symbols from a fi-nite alphabet ?
(the vocabulary of the language) andan embedding function from strings to feature vec-tors, ?
: ??
?
H. A kernel function K(s, t) com-putes the distance between the resulting vectors fortwo sentences s and t. In our case, the embeddingfunction is defined as?ku(s) :=?i:u=s(i)?|i| u ?
?k (5)where k is the maximum length of substrings, |i| isthe length of i, and ?
is a penalty parameter for eachgap encountered in the substring.
K is defined asK(s, t) =?u?
?u(s), ?u(t)?wu (6)where w is a weight dependent on the length of thesubstring u.
Finally, the kernel score is normalizedby?K(s, s) ?
K(t, t) to discourage long sentencesfrom being favored.
Thus, our similarity measure isa gapped, normalized string kernel, which is a moregeneral measure than BLEU in that is considers non-contiguous substrings.
We use a dynamic program-ming implementation of string kernels (Rousu andShawe-Taylor, 2005).122For the combination of source-side and target-side similarity scores (the function we denoted as ?
)we test two simple schemes, using either the ge-ometric or the arithmetic mean of the individualscores.
In the first case, large edge weights only re-sult when both source and target are close to eachother; the latter may produce high edge weightswhen only one of them (typically the source score)is high.
More sophisticated combination schemes,using e.g.
weighted combination, could be used butwere not investigated in this study.Scalability Poor scalability is often mentioned asa drawback of graph-based learning.
Straightfor-ward implementations of GBL algorithms often rep-resent the joint training and test data in workingmemory and therefore do not scale well to largedata sets.
However, we have developed several tech-niques to improve scalability without impeding ac-curacy.
First, we construct separate graphs for eachtest sentence without losing global connectivity in-formation.
The graph for a test sentence is com-puted as the transitive closure of the edge set E overthe nodes containing all hypotheses for that test sen-tence.
This smaller graph does not affect the out-come of the learning process for the chosen sentencebecause in label propagation the learned value r(xi)can be influenced by that of another node xj if andonly if xj is reachable from xi.
In the worst the-oretical case, the transitive closure could compre-hend the entire graph, but in practice the edge set isnever that dense and can be easily pruned based onthe heuristic that faraway nodes connected throughlow-weight edges have less influence on the result.We use a simple embodiment of this heuristic in awork-list approach: starting from the nodes of inter-est (hypotheses for the focal sentence), we expandthe closure starting with the direct neighbors, whichhave the largest influence; then add their neighbors,which have less influence, and so forth.
A thresh-old on the number of added vertices limits undueexpansion while capturing either the entire closureor a good approximation of it.
Another practicalcomputational advantage of portioning work is thatgraphs for different hypothesis sets can be triviallycreated and used in parallel, whereas distributinglarge matrix-vector multiplication is much more dif-ficult (Choi, 1998).
The disadvantage is that overall1 01 0. .
.
.
.
.W2hW1h 1?W1h1?W2hFigure 1: Connections for hypothesis node xh.
Similar-ity edges with weights Wth link the node with train sen-tences xt, for which r(xt) = 1.
For each of these edgeswe define a dissimilarity edge of weight 1?Wth, linkingthe node with node x?t for which r(x?t) = 0.
The vertex isalso connected to other test vertices (the dotted edges).redundant computations are being made: incompleteestimates of r are computed for the ancillary nodesin the transitive closure and then discarded.Second, we obtain a reduction in graph size of or-ders of magnitude by collapsing all training verticesof the same r that are connected to the same testvertex into one and sum the edge weights.
This isequivalent to the full graph for learning purposes.3.2 PropagationLabel propagation proceeds as follows:1.
Compute the transitive closure over the edgesstarting from all hypothesis nodes of a givensentence.2.
On the resulting graph, collapse all test-trainsimilarities for each test node by summing edgeweights.
Obtain accumulated similarities inrow and column 1 of the similarity matrix W .3.
Normalize test-to-train weights such that?j W1j =?j Wj1 = 1.4.
Initialize the matrix P as Pij = Wij1?Wi1+Pj Wij .
(The quantity 1?W1i in the denominator is theweight of the dissimilarity edge.)5.
Initialize a column vector f of height n withf1 = 1 (corresponding to node x1) and 0 in theremaining positions.6.
f ?
?
P ?
f7.
Clamp f ?1: f ?1 = 18.
If f ?
?= f , continue with step 11.9. f ?
f ?10.
Repeat from step 6.11.
The result r is in the slots of f that correspondto the hypotheses of interest.
Normalize persentence if needed, and rank in decreasing or-der of r.123Convergence Our algorithm?s convergence proofis similar to that for standard label propagation (Zhu,2005, p. 6).
We split P as follows:P =[ 0 PLUPUL PUU](7)where PUL is a column vector holding global simi-larities of test hypotheses with train sentences, PLUis a horizontal vector holding the same similarities(though PLU 6= P TUL due to normalization), andPUU holds the normalized similarities between pairsof test hypotheses.
We also separate f :f =[ 1fU](8)where we distinguish the first entry because it repre-sents the training part of the data.
With these nota-tions, the iteration formula becomes:f ?U = PUUfU + PUL (9)Unrolling the iteration yields:fU = limn??
[(PUU )nf0U +( n?i=1(PUU )i?1)PUL]It can be easily shown that the first term convergesto zero because of normalization in step 4 (Zhu,2005).
The sum in the second term converges to(I ?
PUU )?1, so the unique fixed point is:fU = (I ?
PUU )?1PUL (10)Our system uses the iterative form.
On the data setsused, convergence took 61.07 steps on average.At the end of the label propagation algorithm, nor-malized scores are obtained for each N-best list (sen-tences without any connections whatsoever are as-signed zero scores).
These are then used togetherwith the other component models in log-linear com-bination.
Combination weights are optimized on aheld-out data set.4 Data and SystemWe evaluate our approach on the IWSLT 2007Italian-to-English (IE) and Arabic-to-English (AE)travel tasks.
The first is a challenge task, where thetraining set consists of read sentences but the de-velopment and test data consist of spontaneous di-alogues.
The second is a standard travel expres-sion translation task consisting entirely of read in-put.
For our experiments we chose the text input(correct transcription) condition only.
The data setsizes are shown in Table 1.
We split the IE develop-ment set into two subsets of 500 and 496 sentenceseach.
The first set (dev-1) is used to train the systemparameters of the baseline system and as a trainingset for GBL.
The second is used to tune the GBL pa-rameters.
For each language pair, the baseline sys-tem was trained with additional out-of-domain textdata: the Italian-English Europarl corpus (Koehn,2005) in the case of the IE system, and 5.5M wordsof newswire data (LDC Arabic Newswire, Multiple-Translation Corpus and ISI automatically extractedparallel data) in the case of the AE system.Set # sent pairs # words # refsIE train 26.5K 160K 1IE dev-1 500 4308 1IE dev-2 496 4204 1IE eval 724 6481 4AE train 23K 160K 1AE dev4 489 5392 7AE dev5 500 5981 7AE eval 489 2893 6Table 1: Data set sizes and reference translations count.Our baseline is a standard phrase-based SMTsystem based on a log-linear model with the fol-lowing feature functions: two phrase-based trans-lation scores, two lexical translation scores, wordcount and phrase count penalty, distortion score,and language model score.
We use the Moses de-coder (Koehn et al, 2007) with a reordering limit of4 for both languages, which generates N -best listsof up to 2000 hypotheses per sentence in a first pass.The second pass uses a part-of-speech (POS) basedtrigram model, trained on POS sequences generatedby a MaxEnt tagger (Ratnaparkhi, 1996).
The lan-guage models are trained on the English side usingSRILM (Stolcke, 2002) and modified Kneser-Neydiscounting for the first-pass models and Witten-Bell discounting for the POS models.
The baselinesystem yields state-of-the-art performance.124Weighting dev-2 evalnone (baseline) 22.3/53.3 29.6/45.5(a) 23.4/51.5 30.7/44.1(b) 23.5/51.6 30.6/44.3(c) 23.2/51.8 30.0/44.6Table 2: GBL results (%BLEU/PER) on IE taskfor different weightings of labeled-labeled vs. labeled-unlabeled graph edges (BLEU-based similarity measure).5 Experiments and ResultsWe started with the IE system and initially inves-tigated the effect of only including edges betweenlabeled and unlabeled samples in the graph.
Thisis equivalent to using a weighted k-nearest neighborreranker that, for each hypothesis, computes averagesimilarity with its neighborhood of labeled points,and uses the resulting score for reranking.Starting with the IE task and the BLEU-basedsimilarity metric, we ran optimization experimentsthat varied the similarity threshold and comparedsum vs. product combination of source and targetsimilarity scores, settling for ?
= 0.7 and prod-uct combination.
We experimented with three dif-ferent ways of weighting the contributions fromlabeled-unlabeled vs. unlabeled-unlabeled edges:(a) no weighting, (b) labeled-to-unlabeled edgeswere weighted 4 times stronger than unlabeled-unlabeled ones; and (c) labeled-to-unlabeled edgeswere weighted 2 times stronger.
The weightingschemes do not lead to significantly different results.The best result obtained shows a gain of 1.2 BLEUpoints on the dev set and 1 point on the eval set, re-flecting PER gains of 2% and 1.2%, respectively.We next tested the string kernel based similaritymeasure.
The parameter values were 0.5 for the gappenalty, a maximum substring length of k = 4, andweights of 0, 0.1, 0.2, 0.7.
These values were chosenheuristically and were not tuned extensively due totime constraints.
Results (Table 3) show significantimprovements in PER and BLEU.In the context of the BTEC challenge task it isinteresting to compare this approach to adding thedevelopment set directly to the training set.
Part ofthe improvements may be due to utilizing kNN in-formation from a data set that is matched to the testSystem dev-2 evalBaseline 22.3/53.3 29.6/45.5GBL 24.3/51.0 32.2/42.7Table 3: GBL results (%BLEU/PER) on IE tasks withstring-kernel based similarity measure.set in terms of style.
If this data were also used fortraining the initial phrase table, the improvementsmight disappear.
We first optimized the log-linearmodel combination weights on the entire dev07 set(dev-1 and dev-2 in Table 1) before retraining thephrase table using the combined train and dev07data.
The new baseline performance (shown in Ta-ble 4) is much better than before, due to the im-proved training data.
We then added GBL to thissystem by keeping the model combination weightstrained for the previous system, using the N-bestlists generated by the new system, and using thecombined train+dev07 set as a train set for select-ing similar sentences.
We used the GBL parametersthat yielded the best performance in the experimentsdescribed above.
As can be seen from Table 4, GBLagain yields an improvement of up to 1.2% absolutein both BLEU and PER.System BLEU (%) PERBaseline 37.9 38.4GBL 39.2 37.2Table 4: Effect of GBL on IE system trained withmatched data (eval set).For the AE task we used ?
= 0.5; however, thisthreshold was not tuned extensively.
Results usingBLEU similarity are shown in Table 5.
The bestresult on the eval set yields an improvement of 1.2BLEU points though only 0.2% reduction in PER.Overall, results seem to vary with parameter settingsand nature of the test set (e.g.
on dev5, used as a testset, not for optimization, a surprisingly larger im-provement in BLEU of 2.7 points is obtained!
).Overall, sentence similarities were observed to belower for this task.
One reason may be that the AEsystem includes statistical tokenization of the sourceside, which is itself error-prone in that it can split thesame word in different ways depending on the con-125Method dev4 dev5 evalBaseline 30.2/43.5 21.9/48.4 37.8/41.8GBL 30.3/42.5 24.6/48.1 39.0/41.6Table 5: AE results (%BLEU/PER, ?
= 0.5)text.
Since our similarity measure is word-based,this may cause similar sentences to fall below thethreshold.
The string kernel does not yield any im-provement over the BLEU-based similarity measureon this task.
One possible improvement would be touse an extended string kernel that can take morpho-logical similarity into account.Example Below we give an actual example of atranslation improvement, showing the source sen-tence, the 1-best hypotheses of the baseline systemand GBL system, respectively, the references, andthe translations of similar sentences in the graphneighborhood of the current sentence.Source: Al+ mE*rp Aymknk {ltqAT Swrp lnABaseline: i?m sorry could picture for usGBL: excuse me could you take a picture of the usRefs:excuse me can you take a picture of usexcuse me could you take a photo of uspardon would you mind taking a photo of uspardon me could you take our picturepardon me would you take a picture of usexcuse me could you take a picture of uSimilar sentences:could you get two tickets for usplease take a picture for mecould you please take a picture of us6 Related WorkGBL is an instance of semi-supervised learning,specifically transductive learning.
A different formof semi-supervised learning (self-training) has beenapplied to MT by (Ueffing et al, 2007).
Ours isthe first study to explore a graph-based learning ap-proach.
In the machine learning community, workon applying GBL to structured outputs is beginningto emerge.
Transductive graph-based regularizationhas been applied to large-margin learning on struc-tured data (Altun et al, 2005).
However, scalabilityquickly becomes a problem with these approaches;we solve that issue by working on transitive closuresas opposed to entire graphs.
String kernel represen-tations have been used in MT (Szedmak, 2007) ina kernel regression based framework, which, how-ever, was an entirely supervised framework.
Finally,our approach can be likened to a probabilistic imple-mentation of translation memories (Maruyana andWatanabe, 1992; Veale and Way, 1997).
Translationmemories are (usually commercial) databases ofsegment translations extracted from a large databaseof translation examples.
They are typically used byhuman translators to retrieve translation candidatesfor subsequences of a new input text.
Matches canbe exact or fuzzy; the latter is similar to the iden-tification of graph neighborhoods in our approach.However, our GBL scheme propagates similarityscores not just from known to unknown sentencesbut also indirectly, via connections through other un-known sentences.
The combination of a translationmemory and statistical translation was reported in(Marcu, 2001); however, this is a combination ofword-based and phrase-based translation predatingthe current phrase-based approach to SMT.7 ConclusionWe have presented a graph-based learning schemeto implement a consistency model for SMT thatencourages similar inputs to receive similar out-puts.
Evaluation on two small-scale translation tasksshowed significant improvements of up to 2.6 pointsin BLEU and 2.8% PER.
Future work will includetesting different graph construction schemes, in par-ticular better parameter optimization approaches andbetter string similarity measures.
More gains canbe expected when using better domain knowledgein constructing the string kernels.
This may includee.g.
similarity measures that accommodate POS tagsor morphological features, or comparisons of thesyntax trees of parsed sentence.
The latter could bequite easily incorporated into a string kernel or therelated tree kernel similarity measure.
Additionally,we will investigate the effectiveness of this approachon larger translation tasks.Acknowledgments This work was funded byNSF grant IIS-032676 and DARPA under ContractNo.
HR0011-06-C-0023.
Any opinions, findingsand conclusions or recommendations expressed inthis material are those of the author(s) and do notnecessarily reflect the views of these agencies.126ReferencesA.
Alexandrescu and K. Kirchhoff.
2007.
Data-DrivenGraph Construction for Semi-Supervised Graph-Based Learning in NLP.
In HLT.Y.
Altun, D. McAllester, and M. Belkin.
2005.
Max-imum margin semi-supervised learning for structuredvariables.
In Proceedings of NIPS 18.A.
Blum and S. Chawla.
2001.
Learning from labeledand unlabeled data using graph mincuts.
Proc.
18thInternational Conf.
on Machine Learning, pages 19?26.C.
Callison-Burch, M. Osborne, and P. Koehn.
2006.
Re-evaluating the role of BLEU in machine translation re-search.
In Proceedings of EACL.Jaeyoung Choi.
1998.
A new parallel matrix multi-plication algorithm on distributed-memory concurrentcomputers.
Concurrency: Practice and Experience,10(8):655?670.A.
Goldberg and J. Zhu.
2006.
Seeing stars whenthere aren?t many stars: Graph-based semi-supervisedlearning for sentiment categorization.
In HLT-NAACLWorkshop on Graph-based Algorithms for NaturalLanguage Processing.T.
Joachims.
2003.
Transductive learning via spectralgraph partitioning.
In Proceedings of ICML.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In ACL.P.
Koehn.
2005.
Europarl: A parallel corpus for sta-tistical machine translation.
In Machine TranslationSummit X, pages 79?86, Phuket, Thailand.H.
Lodhi, J. Shawe-taylor, and N. Cristianini.
2002.
Textclassification using string kernels.
In Proceedings ofNIPS.D.
Marcu.
2001.
Towards a unified approach to memory-and statistical-based machine translation.
In Proceed-ings of ACL.H.
Maruyana and H. Watanabe.
1992.
Tree cover searchalgorithm for example-based translation.
In Proceed-ings of TMI, pages 173?184.Zheng-Yu Niu, Dong-Hong Ji, and Chew Lim Tan.
2005.Word sense disambiguation using label propagationbased semi-supervised learning method.
In Proceed-ings of ACL, pages 395?402.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2002.Bleu: a method for automatic evaluation of machinetranslation.
In Proceedings of ACL.A.
Ratnaparkhi.
1996.
A maximum entropy part-of-speech tagger.
In Proc.of (EMNLP).J.
Rousu and J. Shawe-Taylor.
2005.
Efficient computa-tion of gap-weighted string kernels on large alphabets.Journal of Machine Learning Research, 6:1323?1344.A.
Stolcke.
2002.
SRILM?an extensible language mod-eling toolkit.
In ICSLP, pages 901?904.Zhuoran Wang;John Shawe-Taylor;Sandor Szedmak.2007.
Kernel regression based machine translation.
InProceedings of NAACL/HLT, pages 185?188.
Associ-ation for Computational Linguistics.Martin Szummer and Tommi Jaakkola.
2001.
Partiallylabeled classification with markov random walks.
InAdvances in Neural Information Processing Systems,volume 14. http://ai.mit.edu/people/szummer/.N.
Ueffing, G. Haffari, and A. Sarkar.
2007.
Trans-ductive learning for statistical machine translation.
InProceedings of the ACL Workshop on Statistical Ma-chine Translation.T.
Veale and A.
Way.
1997.
Gaijin: a template-based bootstrapping approach to example-based ma-chine translation.
In Proceedings of News Methods inNatural Language Processing.X.
Zhu and Z. Ghahramani.
2002.
Learning from labeledand unlabeled data with label propagation.
Technicalreport, CMU-CALD-02.Xiaojin Zhu.
2005.
Semi-Supervised Learning withGraphs.
Ph.D. thesis, Carnegie Mellon University.CMU-LTI-05-192.127
