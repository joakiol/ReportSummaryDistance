T IED MIXTURES IN  THE L INCOLN ROBUST CSR 1Douglas B. PaulLincoln Laboratory, MITLexington, MA 02173ABSTRACTHMM recognizers using either a single Gaussian or a Gaussian mixture per state have been shownto work fairly well for 1000-word vocabulary continuous peech recognition.
However, the largenumber of Gaussians required to cover the entire English language makes these systems unwieldyfor large vocabulary tasks.
Tied mixtures offer a more compact way of representing the observationpdf's.
We have converted our independent mixture systems to tied mixtures and have obtainedmixed results: a 13% improvement in speaker-dependent recognition without cross-word triphonemodels, but no improvement in our speaker-dependent system with cross-word boundary triphonemodels or in our speaker-independent system.
There is also a reduction in CPU requirementsduring recognition--but this is counter-balanced by an increase during training.
This paper alsoincludes a comment on the validity of the DARPA program's evaluation test system comparisons.INTRODUCTIONSingle Gaussian per state speaker-dependent (SD) HMM recognizers and low-order Gaussian mix-ture per state speaker-independent (SI) HMM recognizers have been shown to work fairly well for1000-word vocabulary, continuous speech recognition \[10,11\].
However, a SD system would requireabout 30,000 Gaussians to cover the word-internal triphones of English and a SI system wouldrequire at least 100,000.
The strategy of one or more individual Gaussians per state is appropriatefor small vocabulary systems, but becomes unwieldy for large vocabulary systems.
Interpolation isoften required to cluster models, smooth models, or to predict models which are not observed intraining--but there is no clean strategy for interpolating independent Gaussian mixtures--eitherthe mean(s) are changed or the mixture order increases each time another model is included intoan interpolated model.Tied mixtures \[3,2,4\] offer a solution for these problems while retaining a basic continuous observa-tion HMM system.
(Gaussian tied mixtures are mixtures which share a common pool of Gaussians.
)They are mixtures, and thus avoid the unimodal distribution limitation of single Gaussians.
Un-like independent mixtures, they interpolate well by interpolating the weights of the correspondingGaussians.
And since the pool of Gaussians is of a given size, a mixture order cannot exceed thissize.
In effect, they form a middle ground between the histograms of discrete observation systemsand non-tied-mixture systems.
Tied mixtures can also be viewed as a discrete observation systemmodified to allow a simultaneous match to many templates with the degree of template matchincluded.
In contrast o the discrete observation system, there is no quantization error and the"templates"(Gaussians) canbe jointly optimized with the rest of the HMM.1This work was sponsored by the Defense Advanced Research Projects Agency.293T IED MIXTURESA tied mixture HMM system simply substitutes a mixture with shared Gaussians for the observationpdf in a continuous observation HMM:hi(o) = w sij(o) (i)E wij = 1 (2)where i is the state (or arc), b is the observation pdf, o is an observation vector, w is the weight,and Nj is the set of shared Gaussians.
The forward-backward e-estimation procedure is identicalto the procedure for independent mixtures except the Gaussians are tied.
(The equations can bederived trivially from the well known independent mixture case.
They are presented in \[3,2,4\] andare not repeated here.)
In general, all Gaussians are used by all states, but in practice most of theweights are set to zero by the training procedure.
However, the average mixture order can be veryhigh during the early phases of training.T IED MIXTURE SYSTEMS AT OTHER S ITESSeveral other sites have experimented with tied mixture HMM recognizers \[3,13,2,4\].
However, theinitial parameters for training these systems have been derived from existing discrete observationHMM systems.
The initial Gaussian means and covariances were derived from the templates ofthe vector quantizer, and the mixture weights were initialized from the observation probabilityhistograms.
All of these sites reported moderate performance improvements over their discreteobservation systems.
The work reported here does not bootstrap from any discrete observationsystem.
This provides ome additional freedom in training which may influence the final recognitionperformance.THE TESTSAll system tests reported here were performed on the DARPA Resource Management (RM) database\[12\].
The SD system was trained on the designated 600 training sentences per speaker, and the SIsystem was trained on either 72 designated training speakers x 40 sentences per speaker = 2880sentences (SI-72) or the SI-72 + 37 development test speakers ?
30 sentences per speaker = 3990sentences (SI-109).
0nly 72 of the 80 SI training and 37 of the 40 SI development test speakerscould be used because the other speakers are contained in the test set.
Except for the evaluationtests, the test set in all cases was all 100 development test sentences per speaker for the 12 SDspeakers.
These 1200 sentences contain 10242 words.
The word error rate is:(substitutions + insertions + deletions)correct nr of words (3)The recognition development test results quoted in the text and in Table 1 are percent word errorrate with the perplexity 60 word-pair grammar.294THE T IED MIXTURE SYSTEMS AND EXPERIMENTSThe systems reported at the February 1989 DARPA meeting (the "Feb89" systems) \[10,11\] werea single Gaussian per state HMM with word (boundary) context-dependent (WCD) triphones forSD, and a variable order Gaussian mixture per state HMM with word (boundary) context-free(WCF) triphone models.
All Gaussians used a single-tied (grand) diagonal covariance matrix.The observation vector is a 10 ms mel-cepstrum augmented with a temporal difference ("delta")mel-cepstrum.
The development test performances are shown in Table 1.The tied-mixture systems were initialized by a modification of our monophone bootstrapping pro-cedure \[10\].
As in the Feb89 systems, single Gaussian monophone (context independent phone)models were trained from a "fiat" start (all phones identical) and used to initialize single Ganssiantriphone models.
This produced about 7200 (one per state) Gaussians with a tied (grand) variance.The means of these Gaussians were treated as observations and clustered own to 256 clusters by abinary-splitting k-means algorithm.
(The tied variance was used but not altered during clustering.
)The mixture weights were initialized by computing the Gaussian probability of the cluster meangiven the state and then normalizing according to Eq.
2.
All parameters (transition probabilities,distribution weights, Gaussian means, and tied variance) were trained.
(Each stage of training usedthe forward-backward algorithm.)
If a mixture weight became less than a threshold, the componentwas removed from the mixture.
Thus the mixtures were automatically pruned in response to thetraining data to reduce the computation.
Average mixture orders were initially very high, but werereduced significantly by the end of training.The first tied mixture system used only mel-cepstral observations, WCF triphone models, and256 Gaussians.
(Unless otherwise noted, all of the following systems use WCF triphone models.
)Results for SD (5.5% word errors) were very similar to the corresponding Feb89 system (5.2%),but the SI-72 performance was significantly degraded: 26.2% word errors vs. 12.9% for the Feb89system.
The reduced performance without the delta mel-cepstral parameters was not unexpected.However, the number of Gaussians was reduced from 24,000 for SI-72 and 7200 for SD to 256.Delta mel-cepstral parameters were then returned to the system by augmenting the observationvector.
The performance on the SD task decreased to 6.1% word errors, but the SI-72 task im-proved to 17.2% word error rate.
Including the delta parameters changed the relation between themel-cepstral nd delta mel-cepstraJ observations for the SD system.
In the single Gaussian case,the diagonal covariance matrix treated the mel-cepstral nd the delta mel-cepstral observationsas statistically independent.
However, the mixture weights induced a relation between the twoparameter sets.
(They were already related in the SI system due to the independent mixtures.
)Increasing the number of Ganssians to 512 to increase the system's ability to model the correlationbetween the mel-cepstral nd delta mel-cepstral parameters improved the SD performance to 5.0%word errors but had no effect on SI-72: 17.1% word errors.
It appears that there was insufficientdata to train the correlations or still an insufficient number of Gaussians to model the correlationsin the SI task.A number of other sites \[14,5,6\], for example, have improved performance with limited trainingdata by separating different parameters into separate observation streams and multiplying theirrespective observation probabilities to force the HMM to treat them as if they were statisticallyindependent.
Therefore, the mel-cepstra and the delta mel-cepstra were split into separate obser-vation streams:295b (oo, od) = bc,i(oc) ?
(4)where c denotes mel-cepstrum and d denotes the delta mel-cepstrum.
This maintained the perfor-mance on the SD task (5.0% word errors) and further improved the performance on the SI-72 taskto 14.7% word errors.Next, the training procedure was modified by, instead of clustering the means of the Gaussians,clustering a subset of the training data, again using a binary-splitting k-means algorithm.
It washoped that this would provide an initialization with better representation f outliers which mighthave been suppressed by the single Ganssians.
This change resulted in improvements in both tasks:the SD error rate went down to 4.7% and the SI-72 error rate went down to 13.7%A variation in the training procedure of the "kt" systems was tested.
It was feared that thehigh-frequency triphones were dominating the Ganssian means in the early iterations of trainingcausing damage to the modeling of low-frequency triphones.
Therefore, the Ganssian means werenot trained until the weights had settled.
This was intended to protect he Gaussian means untilthe phone models had become very specific.
No improvement was found.To fully test for outliers, the system was initialized wilth a set of Ganssians formed by binary-splitting k-means clustering a subset of the training data using the perceptually-motivated w ighting\[8,9\] (which was again not altered during clustering).
The system was started with flat start tiedmixture monophones (maximum order mixtures with all weights equal).
These monophone modelswere used to bootstrap the triphone models, again using the forward-backward algorithm at eachstage.
These "ks" systems provided the best performance for the SD task (4.5% word errors), butfailed to improve on the SI-72 task (15.3% word errors), probably due to the slight smoothinginduced by the old initialization.
This SD performance is better than the corresponding Feb89system with WCF triphone models (5.2%).None of the above systems used word context (boundary) modeling.
The "kt" system was testedon the SD task using word context-dependent models.
The performance (4.0% word errors) wasbetter than the WCF system (4.7% word errors), but was not better than the Feb89 SD systemswith WCD models (3.0% word errors).
The tied mixture system appears to require more trainingdata than does a single Gaussian per state system.The above systems do not have any smoothing on the mixture weights.
A preliminary attempt ouse deleted interpolation across phonetic ontexts \[1,5\] caused a slight increase in the error rate ofan SI-72 system.D ISCUSSIONThe changeover to tied mixtures has achieved better performance than the WCF SD system.
Theimprovement due to adding the delta mel-cepstral observations was quite small (5.5 to 5.0% worderror rate) compared the improvement on the SI-72 task (26.7 to 14.7% word error rate).
The SDimprovement found here is similar to that achieved in a similar test with a single Gaussian perstate WCF SD system.
In contrast, BBN \[14\] achieved a dramatic improvement by adding deltaobservations to their SD system.
It is not obvious why the effect of delta observations should beso variable.296The net improvement in the WCF SD system but not the WCD SD system and the SI systemsin the context of the changeover to tied mixtures uggests the need for smoothing of the weights.
(The WCF systems have about 2400 triphones and the SD WCD has about 6000 triphones.)
Themixture weights in the tied mixture systems give more degrees of freedom in spectral matching thansingle Gaussians or low-order independent mixtures and, therefore, require more training data orsmoothing to be effective.
The "kt" system was SI-109 trained which, as expected, improved theresults (13.7 to 11.2% word error).
However, it still did not outperform the independent mixturesystem (10.1% word errors).
The attempt o use deleted interpolation to smooth the weights of anSI-72 system failed for reasons that are as yet unknown.
(It might be a defect in the details of ourtechnique or just a bug in our program.)
Smoothing will require re-examination.Tied mixture systems are very compute-intensive.
Some of the other tied mixture systems haveattempted to reduce computation by limiting the number of "active" Gaussians to a few with thehighest probability \[3,4,13\].
The systems used here dynamically reduced the mixture order byremoving components if their weights fell below a threshold.
This resulted in long iteration timesearly in the training when the mixtures were still of a high order, but the later iterations proceededat a reasonable pace.
The recognizer, of course, saw only the lowest order mixtures from the finaliteration of training.
The net effect is an approximate doubling of the training time over the Feb89systems and a halving of the recognition times.
Since most experiments require both training andrecognition, the total experiment time was significantly increased.
A changeover to limiting thenumber of active Gaussians may reduce the training time.Our work with tied mixtures has shown promise of improved performance.
There are still a numberof issues to be examined or re-examined, and we will continue working on tied mixture HMMrecognition systems.COMMENT ON COMPARATIVE  EVALUATION TEST INGThe standard deviations in Table 1 are computed, assuming a binomial distribution.
This stan-dard deviation is very optimistic--it assumes that al___l conditions are equal and that all errors areindependent.
If it has any validity, it is valid only for comparisons of very similar (preferably min-imal pair) systems tested on exactly this data.
A standard eviation computed across speakers ismuch higher--see Table 2 for some comparative values.
This standard eviation gives an idea ofthe confidence one would have in predicting the recognition performance of a new speaker.
Thehigh across-speaker standard eviation also suggests that comparisons between systems are highlydependent upon the speaker set used for the comparison tests.Using the SD February 89 evaluation test data, we compared the best six (of twelve) speaker listsfrom both the Lincoln and BBN systems, and found only three (50%) speakers common to bothlists.
This was true with and without the word-pair grammar.
A similar comparison on the bestfive (of ten) speakers yields a list intersection averaged over all site pairs with grammar and allsite pairs without grammar of 63% for the SI-72 task (Lincoln, MIT, and SRI systems) and 73%for the SI-109 task (CMU, Lincoln, and SRI systems).
In general, since the SI training only usesa moderate number of speakers, a higher correlation between the best lists is expected for SI thanfor SD because the SI test speakers may be more or less similar to the training speakers; whereas,no such systematic variation exists for the SD tests.This analysis is ad-hoc, but the high across-speaker standard eviation and the poor agreement in297the best speaker lists suggest a weakness in our current inter-site system comparison procedures.Strengthening our inter-site comparisons cannot be achieved just by more powerful tests for com-paring two sets of results for the same speaker--much larger test speaker sets and tests which takeinto account the inter-speaker variation are required.
SRI has made a comparison based uponsumming the per-speaker comparisons between two systems and reached a similar conclusion \[7\].In practice, we may not be able to collect adequate data from, for example, 100 speakers for SDtraining and testing, but 100 test speakers for SI testing is quite practical.EVALUATION TESTS RESULTSImmediately after the February 89 meeting, a bug was found in the recognition etwork generationsoftware for the WCD models.
(This bug only affected our SD WCD system.)
The fix was not achange in concept, only a correction of the implementation.
The development test results are shownin Table 1 as "'Feb89 WCD with bug" and "Feb89 WCD".
The comparisons in this paper havebeen made with the "Feb89 WCD" system because it is (barring other bugs) the implementationof the system described in the talk and paper \[10\].
These tests were rerun and filed with NIST.A summary of the February 89 SD evaluation test results with and without the bug are shown inTable 3.Since our tied mixture systems have not shown better performance than our (fixed) SD "Feb89WCD" single Ganssian per-state system and our "Feb 89" independent mixture SI systems, theFeb89 systems are being used for the evaluation tests.
A summary of the results is shown in Table4.There appears to be a bias in the SD test data relative to other test data-- the SD tests showsignificantly fewer insertions than deletions.
The effect is very strong for the with grammar testwhere 10 of the 12 speakers howed no insertion errors.
In contrast, only one speaker showed nodeletion errors.
The February 89 tests of the same SD system show a balance between the two formsof errors (Table 3).
(There is a similar, but weaker, bias in the no grammar SD case.
This weakerbias would not be noteworthy if the with grammar case did not call attention to it.)
The insertionpenalty, which controls this trade-off, was set for minimum word error rate on the developmenttest data.
Usually, this minimum occurs when the insertion and deletion error rates are similar.The skew observed here is large enough that the SD word error rate would probably be reduced ifthe insertion penalty were adjusted to match this test data.
(The excess of deletion errors in thecurrent SI tests also occurred in the February 89 tests and is, therefore, not noteworthy.
)Re ferences\[1\] L. R. Bahl, F. Jelinek, and R. L. Mercer, "A Maximum Likelihood Approach to ContinuousSpeech Recognition," PAMI-5, No.
2, March 1983.\[2\] J. R. Bellegarda nd D. Nahamoo, "Tied Mixture Continuous Parameter Models for LargeVocabulary Isolated Speech Recognition," ICASSP 89, Glasgow, May 1989.\[3\] X. D. Huang and M. A. Jack, "Semi-continuous Hidden Markov Models for Speech Recogni-tion," Computer Speech and Language, Vol.
3, 1989.298\[4\]\[5\]\[6\]\[7\]\[8\]\[9\]\[10\]X. D. Huang, H. W. Hon, and K. F. Lee, "Large Vocabulary Speaker-Independent ContinuousSpeech Recognition with Semi-Continuous Hidden Markov Models," Eurospeech 89, Paris,September 1989.K.
F. Lee, "Automatic Speech Recognition: The Development of the SPHINX System," KluwerAcademic Publishers, Boston, 1989.II.
Murveit and M. Weintraub, "1000-Word Speaker-Independent Continuous-Speech Recog-nition Using Hidden Markov Models," ICASSP 88, New York, April 1988.H.
Murveit, M. Cohen, P. Price, G. Baldwin, M. Weintraub, and J. Bernstein, "SRI's DECI-PHER System," Proceedings DARPA Speech and Natural Language Workshop, Philadelphia,February 1989.D.
B. Paul, "A Speaker-Stress Resistant Isolated Word Recognizer," ICASSP 89, Dallas, Texas,April 1987.D.
B. Paul, "Speaker Stress-Resistant Continuous Speech Recognition," ICASSP 88, NewYork, April 1988.D.
B. Paul, "The Lincoln Continuous Speech Recognition System: Recent Developments andResults," Proceedings DARPA Speech and Natural Language Workshop, Philadelphia, Febru-ary 1989.\[11\] D. B. Paul, "The Lincoln Robust Continuous Speech Recognizer," ICASSP 89, Glasgow, May1989.\[12\]\[13\]\[14\]P. Price, W. M. Fisher, J. Bernstein, and D. S. Pallett, "The DARPA 1000-Word ResourceManagement Database for Continuous Speech Recognition," ICASSP 88, New York, April1988.R.
Schwartz, personal communication, September 1989.R.
Schwartz, C. Barry, Y. L. Chow, A. Derr, M. W. Feng, O. Kimball, F. Kubala, J. Makhoul,and J. Vendegrift, "The BBN BYBLOS Continuous Speech Recognition System," ProceedingsDARPA Speech and Natural Language Workshop, Philadelphia, February 1989.299TABLE 1DEVELOPMENT TEST RESULTS WITH p=60 WORD-PAIR GRAMMAR% Word Errors (% std dev)Training Conditionk-meansSystem on SD SI-72 S1-109Feb89 WCF - 5.2 (.2) 12.9 (.3)* 10.1 (.3)*single observation streamcep tri 5.5 (.2) 26.2 (.4)cep+delta tri 6.1 (.2) 17.2 (.4)cep+delta, 512 Gaussians tri 5.0 (.2) 17.1 (.4)multiple observation streamscep+delta tri 5.0 (.2) 14.7 (.4)cep+delta: "kt" obs 4.7 (.2) 13.7 (.3)cep+delta: "ks" start 4.5 (.2) 15.3 (.4)11.2 (.3)word boundary context-dependentFeb89 WCD with bug - 3.4 (.2)*Feb89 WCD - 3.0 (.2)**cep+delta: WCD "kt" obs 4.0 (.2)All tests use the SD Development Test set: 12 SD speakers, 100 sentences per speaker, 10242 total words.The std dev assumes a binomial distribution.
The "k-means on" column gives the data used by the k-means algorithm to create the set of Gaussians used by the tied mixtures.
All tied mixture systems use 256Gaussians unless otherwise noted.
* Feb89 official test systems** fixed Feb89 SD test systemk-means codes (see text for complete description):start = k-means of data, tied mixtures at all stages of trainingtri = single Gaussian bootstrap, k-means of triphone meansobs = single Gaussian bootstrap, k-means of observation data- = not a tied mixture system300TABLE 2COMPARATIVE DEVELOPMENT TEST STANDARD DEVIATIONSStandard DeviationsSystem Word Errors Binomial Across SpeakerSD Feb89 WCD 3.0% .17% 1.03%SD Feb89 WCF 5.2% .22% 1.16%SI-72 Feb89 12.9% .33% 4.97%SI-109 Feb89 10.1% .30% 4.68%TABLE 3SUMMARY OF FEBRUARY 89 EVALUATIONS TEST RESULTSWITH WCD MODEL RECOGNIZER BUG FIXEDSystem% Word Error RatesWord-Palr Grammar (p=60) No Grammar (p=991)*sub ins del word (sd) sent  sub ins del word (sd) sentFeb89 SD WCD, bug 2.7 1.0 .5 4.2 (.4) 28.0 8.4 2.9 2.0 13.2 (.7) 60.3Feb89 SD WCD 2.5 .6 .6 3.6 (.4) 25.7 8.6 2.5 2.1 13.1 (.7) 60.0* Homonyms equivalentBinomial standard eviations301TABLE 4SUMMARY OF OCTOBER 89 EVALUATION TEST RESULTSSystem% Word Error RatesWord-Pair Grammar (p=60) No Grammar (p=991)*sub ins del word (sd) sent sub ins del word (sd) sentOctober 89 test setFeb89 SD WCDFeb89 SI-72Feb89 SI-1092.5 .1 1.0 3.6 (.4) 24.07.2 1.6 3.2 12.0 (.6) 52.76.1 1.9 2.8 10.8 (.6) 44.79.9 1.5 2.6 14.0(.7)21.9 4.4 8.2 34.5(.9)18.9 3.1 7.8 29.8(.9)63.791.088.3"Retest" test setFeb89 SD WCDFeb89 SI-1098.9 2.5 1.7 13.1(1.0)17.9 3.1 6.0 26.9(1.2)60.078.7* Homonyms equivalentBinomial standard eviations302
