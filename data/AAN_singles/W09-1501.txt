Proceedings of the NAACL HLT Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 1?4,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsBuilding Test Suites for UIMA ComponentsPhilip V. Ogren Steven J. BethardCenter for Computational Pharmacology Department of Computer ScienceUniversity of Colorado Denver Stanford UniversityDenver, CO 80217, USA Stanford, CA 94305, USAphilip@ogren.info bethard@stanford.eduAbstractWe summarize our experiences building acomprehensive suite of tests for a statisticalnatural language processing toolkit, ClearTK.We describe some of the challenges we en-countered, introduce a software project thatemerged from these efforts, summarize our re-sulting test suite, and discuss some of the les-sons learned.1 IntroductionWe are actively developing a software toolkit forstatistical natural processing called ClearTK (Og-ren et al, 2008) 1, which is built on top of the Un-structured Information Management Architecture(UIMA) (Ferrucci and Lally, 2004).
From the be-ginning of the project, we have built and main-tained a comprehensive test suite for the ClearTKcomponents.
This test suite has proved to be inva-luable as our APIs and implementations haveevolved and matured.
As is common with early-stage software projects, our code has undergonenumber of significant refactoring changes and suchchanges invariably break code that was previouslyworking.
We have found that our test suite hasmade it much easier to identify problems intro-duced by refactoring in addition to preemptivelydiscovering bugs that are present in new code.
Wehave also observed anecdotally that code that is1 http://cleartk.googlecode.commore thoroughly tested as measured by code cov-erage has proven to be more reliable and easier tomaintain.While this test suite has been an indispensableresource for our project, we have found creatingtests for our UIMA components to be challengingfor a number of reasons.
In a typical UIMAprocessing pipeline, components created by devel-opers are instantiated by a UIMA container calledthe Collection Processing Manager (CPM) whichdecides at runtime how to instantiate componentsand what order they should run via configurationinformation provided in descriptor files.
This pat-tern is typical of programming frameworks: thedeveloper creates components that satisfy someAPI specification and then these components aremanaged by the framework.
This means that thedeveloper rarely directly instantiates the compo-nents that are developed and simple programs con-sisting of e.g.
a main method are uncommon andcan be awkward to create.
This is indeed consistentwith our experiences with UIMA.
While this isgenerally a favorable approach for system devel-opment and deployment, it presents challenges tothe developer that wants to isolate specific compo-nents (or classes that support them) for unit orfunctional testing purposes.2 Testing UIMA ComponentsUIMA coordinates data generated and consumedby different components using a data structurecalled the Common Analysis Structure (CAS).
The1CAS represents the current state of analysis thathas been performed on the data being analyzed.
Asa simple example, a UIMA component that per-forms tokenization on text would add token anno-tations to the CAS.
A subsequent component suchas a part-of-speech tagger would read the tokenannotations from the CAS and update them withpart-of-speech labels.
We have found that many ofour tests involve making assertions on the contentsof the CAS after a component or series of compo-nents has been executed for a given set of configu-ration parameters and input data.
As such, the testmust obtain an instance of a CAS after it has beenpassed through the components relevant to thetests.For very simple scenarios a single descriptor filecan be written which specifies all the configurationparameters necessary to instantiate a UIMA com-ponent, create a CAS instance, and process theCAS with the component.
Creating and processinga CAS from such a descriptor file takes 5-10 linesof Java code, plus 30-50 lines of XML for the de-scriptor file.
This is not a large overhead if there isa single test per component, however, testing avariety of parameter settings for each componentresults in a proliferation of descriptor files.
Thesedescriptor files can be difficult to maintain in anevolving codebase because they are tightly coupledwith the Java components they describe, yet mostcode refactoring tools fail to update the XML de-scriptor when they modify the Java code.
As a re-sult, the test suite can become unreliable unlesssubstantial manual effort is applied to maintain thedescriptor files.Thus, for ease of refactoring and to minimize thenumber of additional files required, it made senseto put most of the testing code in Java instead ofXML.
But the UIMA framework does not make iteasy to instantiate components or create CAS ob-jects without an XML descriptor, so even for rela-tively simple scenarios we found ourselves writingdozens of lines of setup code before we could evenstart to make assertions about the expected con-tents of a CAS.
Fortunately, much of this code wassimilar across test cases, so as the ClearTK testsuite grew, we consolidated the common testingcode.
The end result was a number of utilityclasses which allow UIMA components to be in-stantiated and run over CAS objects in just 5-10lines of Java code.
We decided that these utilitiescould also ease testing for projects other thanClearTK, so we created the UUTUC project, whichprovides our UIMA unit test utility code.3 UUTUCUUTUC2 provides a number of convenienceclasses for instantiating, running, and testingUIMA components without the overhead of thetypical UIMA processing pipeline and without theneed to provide XML descriptor files.Note that UUTUC cannot isolate componentsentirely from UIMA ?
it is still necessary, for ex-ample, to create AnalysisEngine objects, JCas ob-jects, Annotation objects, etc.
Even if it werepossible to isolate components entirely fromUIMA, this would generally be undesirable as itwould result in testing components in a differentenvironment from that of their expected runtime.Instead, UUTUC makes it easier to create UIMAobjects entirely in Java code, without having tocreate the various XML descriptor files that areusually required by UIMA.Figure 1 provides a complete code listing for atest of a UIMA component we wrote that providesa simple wrapper around the widely used Snowballstemmer3.
A complete understanding of this codewould require detailed UIMA background that isoutside the scope this paper.
In short, however, thecode creates a UIMA component from the Snow-ballStemmer class, fills a CAS with text and to-kens, processes this CAS with the stemmer, andchecks that the tokens were stemmed as expected.Here are some of the highlights of how UUTUCmade this easier:Line 3 uses TypeSystemDescriptionFactoryto create a TypeSystemDescription from theuser-defined annotation classes Token and Sen-tence.
Without this factory, a 10 line XML de-scriptor would have been required.Line 5 uses AnalysisEngineFactory to createan AnalysisEngine component from the user-defined annotator class SnowballStemmer andthe type system description, setting the stemmername parameter to "English".
Without thisfactory, a 40-50 line XML descriptor wouldhave been required (and near duplicate descrip-2 http://uutuc.googlecode.com ?
provided under BSD license3 http://snowball.tartarus.org2tor files would have been required for each ad-ditional parameter setting tested).Line 11 uses TokenFactory to set the text ofthe CAS object and to populate it with Tokenand Sentence annotations.
Creating these anno-tations and adding them to the CAS manuallywould have taken about 20 lines of Java code,including many character offsets that wouldhave to be manually adjusted any time the testcase was changed.While a Python programmer might not be im-pressed with the brevity of this code, anyone whohas written Java test code for UIMA componentswill appreciate the simplicity of this test over anapproach that does not make use of the UUTUCutility classes.4 ResultsThe test suite we created for ClearTK was builtusing UUTUC and JUnit version 44 and consists of92 class definitions (i.e.
files that end in .java) con-taining 258 tests (i.e.
methods with the markedwith the annotation @Test).
These tests contain atotal of 1,943 individual assertions.
To measurecode coverage of our unit tests we use EclEmma5,a lightweight analysis tool available for the Eclipsedevelopment environment, which counts the num-ber of lines that are executed (or not) when a suiteof unit tests are executed.
While this approach pro-4 http://junit.org5 http://www.eclemma.orgvides only a rough approximation of how well theunit tests ?cover?
the source code, we have foundanecdotally that code with higher coverage re-ported by EclEmma proves to be more reliable andeasier to maintain.
Overall, our test suite provides74.3% code coverage of ClearTK (5,391 lines cov-ered out of 7,252) after factoring out automaticallygenerated code created by JCasGen.
Much of theuncovered code corresponds to the blocks catchingrare exceptions.
While it is important to test thatcode throws exceptions when it is expected to,forcing test code to throw all exceptions that areexplicitly caught can be tedious and sometimestechnically quite difficult.5 DiscussionWe learned several lessons while building our testsuite.
We started writing tests using Groovy, a dy-namic language for the Java Virtual Machine.
Thehope was to simplify testing by using a less ver-bose language than Java.
While Groovy provides agreat syntax for creating tests that are much lessverbose, we found that creating and maintainingthese unit tests was cumbersome using the Eclipseplug-in that was available at the time (Summer2007).
In particular, refactoring tasks such aschanging class names or method names would suc-ceed in the Java code, but the Groovy test codewould not be updated, a similar problem to that ofUIMA?s XML descriptor files.
We also found thatEclipse became less responsive because user ac-tions would often wait for the Groovy compiler to1 @Test2 public void testSimple() throws UIMAException {3     TypeSystemDescription typeSystemDescription = TypeSystemDescriptionFactory4         .createTypeSystemDescription(Token.class, Sentence.class);5     AnalysisEngine engine = AnalysisEngineFactory.createAnalysisEngine(6         SnowballStemmer.class, typeSystemDescription,7         SnowballStemmer.PARAM_STEMMER_NAME, "English");8     JCas jCas = engine.newJCas();9     String text =   "The brown foxes jumped quickly over the lazy dog.
";10     String tokens = "The brown foxes jumped quickly over the lazy dog .
";11     TokenFactory.createTokens(jCas, text, Token.class, Sentence.class, tokens);12     engine.process(jCas);13     List<String> actual = new ArrayList<String>();14     for (Token token: AnnotationRetrieval.getAnnotations(jCas, Token.class)) {15         actual.add(token.getStem());16     }17     String expected = "the brown fox jump quick over the lazi dog .
";18     Assert.assertEquals(Arrays.asList(expected.split(" ")), actual);19 }Figure 1: A complete test case using UUTUC.3complete.
Additionally, Groovy tests involvingJava?s Generics would sometimes work on oneplatform (Windows) and fail on another (Linux orMac).
For these reasons we abandoned usingGroovy and converted our tests to Java.
It shouldbe noted that the authors are novice users ofGroovy and that Groovy (and the Eclipse Groovyplug-in) may have matured significantly in the in-tervening two years.Another challenge we confronted while buildingour test suite was the use of licensed data.
For ex-ample, ClearTK contains a component for readingand parsing PennTreebank formatted data.
One ofour tests reads in and parses the entire PennTree-bank corpus, but since we do not have the rights toredistribute the PennTreeBank, we could not in-clude this test as part of the test suite distributedwith ClearTK.
So as not to lose this valuable test,we created a sibling project of ClearTK which isnot publicly available, but from which we couldrun tests on ClearTK.
This sibling project nowcontains all of our unit tests which use data wecannot distribute.
We are considering making thisproject available separately for those who haveaccess to the relevant data sets.We have begun to compile a growing list of bestpractices for our test suite.
These include:Reuse JCas objects.
In UIMA, creating a JCasobject is expensive.
Instead of creating a newJCas object for each test, a single JCas objectshould be reused for many tests where possible.Refer to descriptors by name, not location.UIMA allows descriptors to be located by either?location?
(a file system path) or ?name?
(a Ja-va-style dotted package name).
Descriptors re-ferred to by ?name?
can be found in a .jar file,while descriptors referred to by ?location?
can-not.
This applies to imports of both type systemdescriptions (e.g.
in component descriptors) andto imports of CAS processors (e.g.
in collectionprocessing engine descriptors).Test loading of descriptor files.
As discussed,XML descriptor files can become stale in anevolving codebase.
Simply loading each de-scriptor in UIMA and verifying that the para-meters are as expected is often enough to keepthe descriptor files working if the actual com-ponent code is being properly checked throughother tests.Test copyright and license statements.
Wefound it useful to add unit tests that searchthrough our source files (both Java code anddescriptor files) and verify that appropriatecopyright and license statements are present.Such statements were a requirement of thetechnology transfer office we were workingwith, and were often accidentally omitted whennew source files were added to ClearTK.
Add-ing a unit test to check for this meant that wecaught such omissions much earlier.As ClearTK has grown in size and complexity itstest suite has proven many times over to be a vitalinstrument in detecting bugs introduced by extend-ing or refactoring existing code.
We have foundthat the code in UUTUC has greatly decreased theburden of maintaining and extending this test suite,and so we have made it available for others to use.ReferencesPhilip V. Ogren, Philipp G. Wetzler, and Steven Be-thard.
2008.
ClearTK: a UIMA toolkit for statisticalnatural language processing.
In UIMA for NLPworkshop at LREC.David Ferrucci and Adam Lally.
2004.
UIMA: an archi-tectural approach to unstructured informationprocessing in the corporate research environment.Natural Language Engineering, 10(3-4):327?348.4
