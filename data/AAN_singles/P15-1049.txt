Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 504?513,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsS-MART: Novel Tree-based Structured Learning AlgorithmsApplied to Tweet Entity LinkingYi YangSchool of Interactive ComputingGeorgia Institute of Technologyyiyang@gatech.eduMing-Wei ChangMicrosoft Researchminchang@microsoft.comAbstractNon-linear models recently receive a lotof attention as people are starting to dis-cover the power of statistical and em-bedding features.
However, tree-basedmodels are seldom studied in the con-text of structured learning despite their re-cent success on various classification andranking tasks.
In this paper, we proposeS-MART, a tree-based structured learningframework based on multiple additive re-gression trees.
S-MART is especially suit-able for handling tasks with dense fea-tures, and can be used to learn many dif-ferent structures under various loss func-tions.We apply S-MART to the task of tweetentity linking ?
a core component oftweet information extraction, which aimsto identify and link name mentions to en-tities in a knowledge base.
A novel infer-ence algorithm is proposed to handle thespecial structure of the task.
The exper-imental results show that S-MART signif-icantly outperforms state-of-the-art tweetentity linking systems.1 IntroductionMany natural language processing (NLP) prob-lems can be formalized as structured predictiontasks.
Standard algorithms for structured learninginclude Conditional Random Field (CRF) (Laf-ferty et al, 2001) and Structured Supported Vec-tor Machine (SSVM) (Tsochantaridis et al, 2004).These algorithms, usually equipped with a linearmodel and sparse lexical features, achieve state-of-the-art performances in many NLP applica-tions such as part-of-speech tagging, named entityrecognition and dependency parsing.This classical combination of linear models andsparse features is challenged by the recent emerg-ing usage of dense features such as statistical andembedding features.
Tasks with these low dimen-sional dense features require models to be moresophisticated to capture the relationships betweenfeatures.
Therefore, non-linear models start to re-ceive more attention as they are often more expres-sive than linear models.Tree-based models such as boosted trees (Fried-man, 2001) are flexible non-linear models.
Theycan handle categorical features and count data bet-ter than other non-linear models like Neural Net-works.
Unfortunately, to the best of our knowl-edge, little work has utilized tree-based methodsfor structured prediction, with the exception ofTreeCRF (Dietterich et al, 2004).In this paper, we propose a novel structuredlearning framework called S-MART (StructuredMultiple Additive Regression Trees).
UnlikeTreeCRF, S-MART is very versatile, as it can beapplied to tasks beyond sequence tagging and canbe trained under various objective functions.
S-MART is also powerful, as the high order relation-ships between features can be captured by non-linear regression trees.We further demonstrate how S-MART can beapplied to tweet entity linking, an important andchallenging task underlying many applications in-cluding product feedback (Asur and Huberman,2010) and topic detection and tracking (Math-ioudakis and Koudas, 2010).
We apply S-MART toentity linking using a simple logistic function asthe loss function and propose a novel inference al-gorithm to prevent overlaps between entities.Our contributions are summarized as follows:?
We propose a novel structured learningframework called S-MART.
S-MART com-bines non-linearity and efficiency of tree-based models with structured prediction,leading to a family of new algorithms.
(Sec-tion 2)504?
We apply S-MART to tweet entity link-ing.
Building on top of S-MART, we pro-pose a novel inference algorithm for non-overlapping structure with the goal of pre-venting conflicting entity assignments.
(Sec-tion 3)?
We provide a systematic study of evaluationcriteria in tweet entity linking by conduct-ing extensive experiments over major datasets.
The results show that S-MART sig-nificantly outperforms state-of-the-art entitylinking systems, including the system that isused to win the NEEL 2014 challenge (Canoand others, 2014).
(Section 4)2 Structured Multiple AdditiveRegression TreesThe goal of a structured learning algorithm is tolearn a joint scoring function S between an inputx and an output structure y, S : (x,y) ?
R. Thestructured output y often contains many interde-pendent variables, and the number of the possiblestructures can be exponentially large with respectto the size of x.
At test time, the prediction y forx is obtained byarg maxy?Gen(x)S(x,y),whereGen(x) represents the set of all valid outputstructures for x.Standard learning algorithms often directly op-timize the model parameters.
For example, as-sume that the joint scoring function S is param-eterized by ?.
Then, gradient descent algorithmscan be used to optimize the model parameters ?iteratively.
More specifically,?m= ?m?1?
?m?L(y?, S(x,y; ?))?
?m?1, (1)where y?is the gold structure, L(y?, S(x,y; ?
))is a loss function and ?mis the learning rate of them-th iteration.In this paper, we propose a framework calledStructured Multiple Additive Regression Trees(S-MART), which generalizes Multiple AdditiveRegression Trees (MART) for structured learn-ing problems.
Different from Equation (1), S-MART does not directly optimize the model pa-rameters; instead, it approximates the optimalscoring function that minimize the loss by adding(weighted) regression tree models iteratively.Due to the fact that there are exponentiallymany input-output pairs in the training data,S-MART assumes that the joint scoring functioncan be decomposed asS(x,y) =?k??
(x)F (x,yk),where ?
(x) contains the set of the all factors forinput x and ykis the sub-structure of y that cor-responds to the k-th factor in ?(x).
For instance,in the task of word alignment, each factor can bedefined as a pair of words from source and targetlanguages respectively.
Note that we can recovery from the union of {yk}K1.The factor scoring function F (x,yk) can beoptimized by performing gradient descent in thefunction space in the following manner:Fm(x,yk) = Fm?1(x,yk)?
?mgm(x,yk) (2)where function gm(x,yk) is the functional gradi-ent.Note that gmis a function rather than a vector.Therefore, modeling gmtheoretically requires aninfinite number of data points.
We can address thisdifficulty by approximating gmwith a finite num-ber of point-wise functional gradientsgm(x,yk= uk) = (3)[?L(y?, S(x,yk= uk))?F (x,yk= uk)]F (x,yk)=Fm?1(x,yk)where ukindex a valid sub-structure for the k-thfactor of x.The key point of S-MART is that it approximates?gmby modeling the point-wise negative func-tional gradients using a regression tree hm.
Thenthe factor scoring function can be obtained byF (x,yk) =M?m=1?mhm(x,yk),where hm(x,yk) is also called a basis functionand ?mcan be simply set to 1 (Murphy, 2012).The detailed S-MART algorithm is presented inAlgorithm 1.
The factor scoring functionF (x,yk)is simply initialized to zero at first (line 1).
Afterthis, we iteratively update the function by addingregression trees.
Note that the scoring function isshared by all the factors.
Specifically, given thecurrent decision function Fm?1, we can considerline 3 to line 9 a process of generating the pseudo505Algorithm 1 S-MART: A family of structuredlearning algorithms with multiple additive regres-sion trees1: F0(x,yk) = 02: for m = 1 to M do: .
going over all trees3: D ?
?4: for all examples do: .
going over all examples5: for yk?
?
(x) do: .
going over all factors6: For all uk, obtain gkuby Equation (3)7: D ?
D ?
{(?
(x,yk= uk),?gku)}8: end for9: end for10: hm(x,yk)?
TrainRegressionTree(D)11: Fm(x,yk) = Fm?1(x,yk) + hm(x,yk)12: end fortraining data D for modeling the regression tree.For each training example, S-MART first computesthe point-wise functional gradients according toEquation (3) (line 6).
Here we use gkuas the ab-breviation for gm(x,yk= uk).
In line 7, for eachsub-structure uk, we create a new training exam-ple for the regression problem by the feature vec-tor ?
(x,yk= uk) and the negative gradient?gku.In line 10, a regression tree is constructed by min-imizing differences between the prediction valuesand the point-wise negative gradients.
Then a newbasis function (modeled by a regression tree) willbe added into the overall F (line 11).It is crucial to note that S-MART is a fam-ily of algorithms rather than a single algorithm.S-MART is flexible in the choice of the lossfunctions.
For example, we can use either lo-gistic loss or hinge loss, which means that S-MART can train probabilistic models as well asnon-probabilistic ones.
Depending on the choiceof factors, S-MART can handle various structuressuch as linear chains, trees, and even the semi-Markov chain (Sarawagi and Cohen, 2004).S-MART versus MART There are two keydifferences between S-MART and MART.
First,S-MART decomposes the joint scoring functionS(x,y) into factors to address the problem of theexploding number of input-output pairs for struc-tured learning problems.
Second, S-MART mod-els a single scoring function F (x,yk) over inputsand output variables directly rather than O differ-ent functions Fo(x), each of which corresponds toa label class.S-MART versus TreeCRF TreeCRF can beviewed as a special case of S-MART, and thereare two points where S-MART improves uponTreeCRF.
First, the model designed in (Dietterichet al, 2004) is tailored for sequence tagging prob-lems.
Similar to MART, for a tagging task with Otags, they choose to model O functions Fo(x, o?
)instead of directly modeling the joint score of thefactor.
This imposes limitations on the featurefunctions, and TreeCRF is consequently unsuit-able for many tasks such as entity linking.1Second,S-MART is more general in terms of the objectivefunctions and applicable structures.
In the nextsection, we will see how S-MART can be applied toa non-linear-chain structure and various loss func-tions.3 S-MART for Tweet Entity LinkingWe first formally define the task of tweet entitylinking.
As input, we are given a tweet, an entitydatabase (e.g., Wikipedia where each article is anentity), and a lexicon2which maps a surface forminto a set of entity candidates.
For each incomingtweet, all n-grams of this tweet will be used to findmatches in the lexicon, and each match will form amention candidate.
As output, we map every men-tion candidate (e.g., ?new york giants?)
in the mes-sage to an entity (e.g., NEW YORK GIANTS) or toNil (i.e., a non-entity).
A mention candidate canoften potentially link to multiple entities, whichwe call possible entity assignments.This task is a structured learning problem, as thefinal entity assignments of a tweet should not over-lap with each other.3We decompose this learn-ing problem as follows: we make each mentioncandidate a factor, and the score of the entity as-signments of a tweet is the sum of the score ofeach entity and mention candidate pair.
Althoughall mention candidates are decomposed, the non-overlapping constraint requires the system to per-form global inference.Consider the example tweet in Figure 1, wherewe show the tweet with the mention candidatesin brackets.
To link the mention candidate ?newyork giants?
to a non-Nil entity, the system has tolink previous overlapping mention candidates toNil.
It is important to note that this is not a lin-ear chain problem because of the non-overlappingconstraint, and the inference algorithm needs to be1For example, entity linking systems need to model thesimilarity between an entity and the document.
The TreeCRFformulation does not support such features.2We use the standard techniques to construct the lexiconfrom anchor texts, redirect pages and other information re-sources.3We follow the common practice and do not allow embed-ded entities.506Figure 1: Example tweet and its mention candidates.
Each mention candidate is marked as a pair of brackets in the originaltweet and forms a column in the graph.
The graph demonstrates the non-overlapping constraint.
To link the mention candidate?new york giants?
to a non-Nil entity, the system has to link previous four overlapping mention candidates to Nil.
The mentioncandidate ?eli manning?
is not affected by ?new york giants?.
Note that this is not a standard linear chain problem.carefully designed.3.1 Applying S-MARTWe derive specific model for tweet entity linkingtask with S-MART and use logistic loss as our run-ning example.
The hinge loss version of the modelcan be derived in a similar way.Note that the tweet and the mention candidatesare given.
Let x be the tweet, ukbe the entity as-signment of the k-th mention candidate.
We usefunction F (x, yk= uk) to model the score of thek-th mention candidate choosing entity uk.4Theoverall scoring function can be decomposed as fol-lows:S(x,y = {uk}Kk=1) =K?k=1F (x, yk= uk)S-MART utilizes regression trees to model thescoring function F (x, yk= uk), which requirespoint-wise functional gradient for each entity ofevery mention candidate.
Let?s first write downthe logistic loss function asL(y?, S(x,y)) =?
logP (y?|x)= logZ(x)?
S(x,y?
)where Z(x) =?yexp(S(x,y)) is the potentialfunction.
Then the point-wise gradients can becomputed asgku=?L?F (x, yk= uk)= P (yk= uk|x)?
1[y?k= uk],where 1[?]
represents an indicator function.
Theconditional probabilityP (yk= uk|x) can be com-puted by a variant of the forward-backward algo-rithm, which we will detail in the next subsection.4Note that each mention candidate has different own en-tity sets.3.2 InferenceThe non-overlapping structure is distinct from lin-ear chain and semi-Markov chain (Sarawagi andCohen, 2004) structures.
Hence, we propose acarefully designed forward-backward algorithm tocalculate P (yk= uk|x) based on current scor-ing function F (x, yk= uk) given by the re-gression trees.
The non-overlapping constraintdistinguishes our inference algorithm from otherforward-backward variants.To compute the forward probability, we sort5the mention candidates by their end indices anddefine forward recursion by?
(u1, 1) = exp(F (x, y1= u1))?
(uk, k) = exp(F (x, yk= uk))?P?1?p=1exp(F (x, yk?p= Nil))??uk?P?
(uk?P, k ?
P ) (4)where k ?
P is the index of the previous non-overlapping mention candidate.
Intuitively, forthe k-th mention candidate, we need to identifyits nearest non-overlapping fellow and recursivelycompute the probability.
The overlapping mentioncandidates can only take the Nil entity.Similarly, we can sort the mention candidatesby their start indices and define backward recur-5Sorting helps the algorithms find non-overlapping candi-dates.507sion by?
(uK,K) =1?
(uk, k) =?uk+Qexp(F (x, yk+Q= uk+Q))?Q?1?q=1exp(F (x, yk+q= Nil))?
?
(uk+Q, k +Q) (5)where k + Q is the index of the next non-overlapping mention candidate.
Note that the thirdterms of equation (4) or (5) will vanish if there areno corresponding non-overlapping mention candi-dates.Given the potential function can be computedby Z(x) =?uk?
(uk, k)?
(uk, k), for entitiesthat are not Nil,P (yk= uk|x) =exp(F (x, yk= uk)) ?
?
(uk, k)Z(x)?P?1?p=1exp(F (x, yk?p= Nil))??uk?P?
(uk?P, k ?
P ) (6)The probability for the special token Nil can beobtained byP (yk= Nil|x) = 1?
?uk6=NilP (yk= uk|x) (7)In the worst case, the total cost of the forward-backward algorithm is O(max{TK,K2}), whereT is the number of entities of a mention candi-date.6Finally, at test time, the decoding problemarg maxyS(x,y) can be solved by a variant ofthe Viterbi algorithm.3.3 Beyond S-MART: Modeling entity-entityrelationshipsIt is important for entity linking systems to takeadvantage of the entity-to-entity information whilemaking local decisions.
For instance, the identi-fication of entity ?eli manning?
leads to a strongclue for linking ?new york giants?
to the NFLteam.Instead of defining a more complicated struc-ture and learning everything jointly, we employ a6The cost is O(K2) only if every mention candidate ofthe tweet overlaps other mention candidates.
In practice, thealgorithm is nearly linear w.r.t K.two-stage approach as the solution for modelingentity-entity relationships after we found that S-MART achieves high precision and reasonable re-call.
Specifically, in the first stage, the systemidentifies all possible entities with basic features,which enables the extraction of entity-entity fea-tures.
In the second stage, we re-train S-MART ona union of basic features and entity-entity features.We define entity-entity features based on the Jac-card distance introduced by Guo et al (2013).Let ?
(ei) denotes the set of Wikipedia pagesthat contain a hyperlink to an entity eiand ?
(t?i)denotes the set of pages that contain a hyperlinkto any identified entity ejof the tweet t in the firststage excluding ei.
The Jaccard distance betweeneiand t isJac(ei, t) =|?
(ei) ?
?(t?i)||?
(ei) ?
?
(t?i)|.In addition to the Jaccard distance, we add one ad-ditional binary feature to indicate if the current en-tity has the highest Jaccard distance among all en-tities for this mention candidate.4 ExperimentsOur experiments are designed to answer the fol-lowing three research questions in the context oftweet entity linking:?
Do non-linear learning algorithms performbetter than linear learning algorithms??
Do structured entity linking models performbetter than non-structured ones??
How can we best capture the relationships be-tween entities?4.1 Evaluation Methodology and DataWe evaluate each entity linking system using twoevaluation policies: Information Extraction (IE)driven evaluation and Information Retrieval (IR)driven evaluation.
For both evaluation settings,precision, recall and F1 scores are reported.
Ourdata is constructed from two publicly availablesources: Named Entity Extraction & Linking(NEEL) Challenge (Cano et al, 2014) datasets,and the datasets released by Fang and Chang(2014).
Note that we gather two datasets fromFang and Chang (2014) and they are used in twodifferent evaluation settings.
We refer to these twodatasets as TACL-IE and TACL-IR, respectively.We perform some data cleaning and unification on508these sets.7The statistics of the datasets are pre-sented in Table 1.IE-driven evaluation The IE-driven evaluationis the standard evaluation for an end-to-end entitylinking system.
We follow Carmel et al (2014)and relax the definition of the correct mentionboundaries, as they are often ambiguous.
A men-tion boundary is considered to be correct if it over-laps (instead of being the same) with the gold men-tion boundary.
Please see (Carmel et al, 2014) formore details on the procedure of calculating theprecision, recall and F1 score.The NEEL and TACL-IE datasets have differ-ent annotation guidelines and different choices ofknowledge bases, so we perform the followingprocedure to clean the data and unify the annota-tions.
We first filter out the annotations that link toentities excluded by our knowledge base.
We usethe same knowledge base as the ERD 2014 com-petition (Carmel et al, 2014), which includes theunion of entities in Wikipedia and Freebase.
Sec-ond, we follow NEEL annotation guideline andre-annotate TACL-IE dataset.
For instance, in or-der to be consistent with NEEL, all the user tags(e.g.
@BarackObama) are re-labeled as entities inTACL-IE.We train all the models with NEEL Traindataset and evaluate different systems on NEELTest and TACL-IE datasets.
In addition, we sam-ple 800 tweets from NEEL Train dataset as ourdevelopment set to perform parameter tuning.IR-driven evaluation The IR-driven evaluationis proposed by Fang and Chang (2014).
It ismotivated by a key application of entity linking?
retrieval of relevant tweets for target entities,which is crucial for downstream applications suchas product research and sentiment analysis.
Inparticular, given a query entity we can search fortweets based on the match with some potential sur-face forms of the query entity.
Then, an entitylinking system is evaluated by its ability to cor-rectly identify the presence or absence of the queryentity in every tweet.
Our IR-driven evaluationis based on the TACL-IR set, which includes 980tweets sampled for ten query entities of five entitytypes (roughly 100 tweets per entity).
About 37%of the sampled tweets did not mention the queryentity due to the anchor ambiguity.7We plan to release the cleaned data and evaluation codeif license permitted.Data #Tweet #Entity DateNEEL Train 2340 2202 Jul.
?Aug.
11NEEL Test 1164 687 Jul.
?Aug.
11TACL-IE 500 300 Dec. 12TACL-IR 980 NA Dec. 12Table 1: Statistics of data sets.4.2 Experimental SettingsFeatures We employ a total number of 37 densefeatures as our basic feature set.
Most of the fea-tures are adopted from (Guo et al, 2013)8, includ-ing various statistical features such as the proba-bility of the surface to be used as anchor text inWikipedia.
We also add additional Entity Typefeatures correspond to the following entity types:Character, Event, Product and Brand.
Finally,we include several NER features to indicate eachmention candidate belongs to one the followingNER types: Twitter user, Twitter hashtag, Person,Location, Organization, Product, Event and Date.Algorithms Table 2 summarizes all the algo-rithms that are compared in our experiments.
First,we consider two linear structured learning algo-rithms: Structured Perceptron (Collins, 2002) andLinear Structured SVM (SSVM) (Tsochantaridiset al, 2004).For non-linear models, we consider polynomialSSVM, which employs polynomial kernel insidethe structured SVM algorithm.
We also includeLambdaRank (Quoc and Le, 2007), a neural-based learning to rank algorithm, which is widelyused in the information retrieval literature.
Wefurther compare with MART, which is designedfor performing multiclass classification using logloss without considering the structured informa-tion.
Finally, we have our proposed log-loss S-MART algorithm, as described in Section 3.9Note that our baseline systems are quite strong.Linear SSVM has been used in one of the state-of-the-art tweet entity linking systems (Guo et al,2013), and the system based on MART is the win-ning system of the 2014 NEEL Challenge (Canoand others, 2014)10.Table 2 summarizes several properties of the al-gorithms.
For example, most algorithms are struc-8We consider features of Base, Capitalization Rate, Pop-ularity, Context Capitalization and Entity Type categories.9Our pilot experiments show that the log-loss S-MART consistently outperforms the hinge-loss S-MART.10Note that the numbers we reported here are differentfrom the results in NEEL challenge due to the fact thatwe have cleaned the datasets and the evaluation metrics areslightly different in this paper.509Model Structured Non-linear Tree-basedStructured Perceptron XLinear SSVM XPolynomial SSVM X XLambdaRank XMART X XS-MART X X XTable 2: Included algorithms and their properties.tured (e.g.
they perform dynamic programmingat test time) except for MART and LambdaRank,which treat mention candidates independently.Parameter tuning All the hyper-parameters aretuned on the development set.
Then, we re-trainour models on full training data (including thedev set) with the best parameters.
We choose thesoft margin parameter C from {0.5, 1, 5, 10} fortwo structured SVM methods.
After a prelimi-nary parameter search, we fixed the number oftrees to 300 and the minimum number of docu-ments in a leaf to 30 for all tree-based models.For LambdaRank, we use a two layer feed for-ward network.
We select the number of hiddenunits from {10, 20, 30, 40} and learning rate from{0.1, 0.01, 0.001}.It is widely known that F1 score can be affectedby the trade-off between precision and recall.
Inorder to make the comparisons between all algo-rithms fairer in terms of F1 score, we include apost-processing step to balance precision and re-call for all the systems.
Note the tuning is onlyconducted for the purpose of robust evaluation.
Inparticular, we adopt a simple tuning strategy thatworks well for all the algorithms, in which we adda bias term b to the scoring function value of Nil:F (x, yk= Nil)?
F (x, yk= Nil) + b.We choose the bias term b from values between?3.0 to 3.0 on the dev set and apply the same biasterm at test time.4.3 ResultsTable 3 presents the empirical findings for S-MART and competitive methods on tweet entitylinking task in both IE and IR settings.
In the fol-lowing, we analyze the empirical results in details.Linear models vs. non-linear models Table 3clearly shows that linear models perform worsethan non-linear models when they are restrictedto the IE setting of the tweet entity linking task.The story is similar in IR-driven evaluation, with?2 ?1 0 1 250607080BiasF1scoreSPLinear SSVMPoly.
SSVMMARTNNS-MARTFigure 2: Balance precisions and recalls.
X-axis correspondsto values of the bias terms for the special token Nil.
Note thatS-MART is still the overall winning system without tuning thethreshold.the exception of LambdaRank.
Among the lin-ear models, linear SSVM demonstrates its supe-riority over Structured Perceptron on all datasets,which aligns with the results of (Tsochantaridis etal., 2005) on the named entity recognition task.We have many interesting observations on thenon-linear models side.
First, by adopting apolynomial kernel, the non-linear SSVM furtherimproves the entity linking performances on theNEEL datasets and TACL-IR dataset.
Second,LambdaRank, a neural network based model,achieves better results than linear models in IE-driven evaluation, but the results in IR-driven eval-uation are worse than all the other methods.
Webelieve the reason for this dismal performance isthat the neural-based method tends to overfit theIR setting given the small number of training ex-amples.
Third, both MART and S-MART signifi-cantly outperform alternative linear and non-linearmethods in IE-driven evaluation and performs bet-ter or similar to other methods in IR-driven eval-uation.
This suggests that tree-based non-linearmodels are suitable for tweet entity linking task.Finally, S-MART outperforms previous state-of-the-art method Structured SVM by a surprisinglylarge margin.
In the NEEL Test dataset, the dif-ference is more than 10% F1.
Overall, the resultsshow that the shallow linear models are not ex-pressive enough to capture the complex patternsin the data, which are represented by a few densefeatures.Structured learning models To showcasestructured learning technique is crucial for entitylinking with non-linear models, we compareS-MART against MART directly.
As shown in510ModelNEEL Dev NEEL Test TACL-IE TACL-IRP R F1 P R F1 P R F1 P R F1Structured Perceptron 75.8 62.8 68.7 79.1 64.3 70.9 74.4 63.0 68.2 86.2 43.8 58.0Linear SSVM 78.0 66.1 71.5 80.5 67.1 73.2 78.2 64.7 70.8 86.7 48.5 62.2Polynomial SSVM 77.7 70.7 74.0 81.3 69.0 74.6 76.8 64.0 69.8 91.1 48.8 63.6LambdaRank 75.0 69.0 71.9 80.3 71.2 75.5 77.8 66.7 71.8 85.8 42.4 56.8MART 76.2 74.3 75.2 76.8 78.0 77.4 73.4 71.0 72.2 98.1 46.4 63.0S-MART 79.1 75.8 77.4 83.2 79.2 81.1 76.8 73.0 74.9 95.1 52.2 67.4+ entity-entity 79.2 75.8 77.5 81.5 76.4 78.9 77.3 73.7 75.4 95.5 56.7 71.1Table 3: IE-driven and IR-driven evaluation results for different models.
The best results with basic features are in bold.
Theresults are underlined if adding entity-entity features gives the overall best results.Table 3, S-MART can achieve higher precision andrecall points compared to MART on all datasetsin terms of IE-driven evaluation, and can improveF1 by 4 points on NEEL Test and TACL-IRdatasets.
The task of entity linking is to producenon-overlapping entity assignments that match thegold mentions.
By adopting structured learningtechnique, S-MART is able to automaticallytake into account the non-overlapping constraintduring learning and inference, and produce globaloptimal entity assignments for mention candidatesof a tweet.
One effect is that S-MART can easilyeliminate some common errors caused by popularentities (e.g.
new york in Figure 1).Modeling entity-entity relationships Entity-entity relationships provide strong clues for entitydisambiguation.
In this paper, we use the sim-ple two-stage approach described in Section 3.3to capture the relationships between entities.
Asshown in Table 3, the significant improvement inIR-driven evaluation indicates the importance ofincorporating entity-entity information.Interestingly, while IR-driven results are signif-icantly improved, IE-driven results are similar oreven worse given entity-entity features.
We be-lieve the reason is that IE-driven and IR-drivenevaluations focus on different aspects of tweet en-tity linking task.
As Guo et al (2013) showsthat most mentions in tweets should be linked tothe most popular entities, IE setting actually paysmore attention on mention detection sub-problem.In contrast to IE setting, IR setting focuses on en-tity disambiguation, since we only need to decidewhether the tweet is relevant to the query entity.Therefore, we believe that both evaluation policiesare needed for tweet entity linking.Balance Precision and Recall Figure 2 showsthe results of tuning the bias term for balancingprecision and recall on the dev set.
The resultsshow that S-MART outperforms competitive ap-proaches without any tuning, with similar marginsto the results after tuning.
Balancing precisionand recall improves F1 scores for all the systems,which suggests that the simple tuning method per-forms quite well.
Finally, we have an interest-ing observation that different methods have vari-ous scales of model scores.5 Related WorkLinear structured learning methods have been pro-posed and widely used in the literature.
Popu-lar models include Structured Perceptron (Collins,2002), Conditional Random Field (Lafferty et al,2001) and Structured SVM (Taskar et al, 2004;Tsochantaridis et al, 2005).
Recently, many struc-tured learning models based on neural networkshave been proposed and are widely used in lan-guage modeling (Bengio et al, 2006; Mikolovet al, 2010), sentiment classification (Socher etal., 2013), as well as parsing (Socher et al,2011).
Cortes et al (2014) recently proposed aboosting framework which treats different struc-tured learning algorithms as base learners to en-semble structured prediction results.Tree-based models have been shown to pro-vide more robust and accurate performances thanneural networks in some tasks of computer vi-sion (Roe et al, 2005; Babenko et al, 2011)and information retrieval (Li et al, 2007; Wu etal., 2010), suggesting that it is worth to investi-gate tree-based non-linear models for structuredlearning problems.
To the best of our knowl-edge, TreeCRF (Dietterich et al, 2004) is the onlywork that explores tree-based methods for struc-tured learning problems.
The relationships be-tween TreeCRF and our work have been discussedin Section 2.511Early research on entity linking has focusedon well written documents (Bunescu and Pasca,2006; Cucerzan, 2007; Milne and Witten, 2008).Due to the raise of social media, many techniqueshave been proposed or tailored to short texts in-cluding tweets, for the problem of entity linking(Ferragina and Scaiella, 2010; Meij et al, 2012;Guo et al, 2013) as well as the related problemof named entity recognition (NER) (Ritter et al,2011).
Recently, non-textual information such asspatial and temporal signals have also been used toimprove entity linking systems (Fang and Chang,2014).
The task of entity linking has attracted alot of attention, and many shared tasks have beenhosted to promote entity linking research (Ji et al,2010; Ji and Grishman, 2011; Cano and others,2014; Carmel et al, 2014).Building an end-to-end entity linking system in-volves in solving two interrelated sub-problems:mention detection and entity disambiguation.
Ear-lier research on entity linking has been largely fo-cused on the entity disambiguation problem, in-cluding most work on entity linking for well-written documents such as news and encyclope-dia articles (Cucerzan, 2007) and also few fortweets (Liu et al, 2013).
Recently, people havefocused on building systems that consider mentiondetection and entity disambiguation jointly.
Forexample, Cucerzan (2012) delays the mention de-tection decision and consider the mention detec-tion and entity linking problem jointly.
Similarly,Sil and Yates (2013) proposed to use a rerankingapproach to obtain overall better results on men-tion detection and entity disambiguation.6 Conclusion and Future WorkIn this paper, we propose S-MART, a family ofstructured learning algorithms which is flexible onthe choices of the loss functions and structures.We demonstrate the power of S-MART by applyingit to tweet entity linking, and it significantly out-performs the current state-of-the-art entity linkingsystems.
In the future, we would like to investigatethe advantages and disadvantages between tree-based models and other non-linear models suchas deep neural networks or recurrent neural net-works.Acknowledgments We thank the reviewers fortheir insightful feedback.
We also thank Yin Liand Ana Smith for their valuable comments onearlier version of this paper.ReferencesS.
Asur and B.A.
Huberman.
2010.
Predict-ing the future with social media.
arXiv preprintarXiv:1003.5699.Boris Babenko, Ming-Hsuan Yang, and Serge Be-longie.
2011.
Robust object tracking with onlinemultiple instance learning.
Pattern Analysis andMachine Intelligence, IEEE Transactions on, pages1619?1632.Yoshua Bengio, Holger Schwenk, Jean-S?ebastienSen?ecal, Fr?ederic Morin, and Jean-Luc Gauvain.2006.
Neural probabilistic language models.
In In-novations in Machine Learning, pages 137?186.R.
C Bunescu and M. Pasca.
2006.
Using encyclo-pedic knowledge for named entity disambiguation.In Proceedings of the European Chapter of the ACL(EACL), pages 9?16.AE Cano et al 2014.
Microposts2014 neel challenge.In Microposts2014 NEEL Challenge.Amparo E Cano, Giuseppe Rizzo, Andrea Varga,Matthew Rowe, Milan Stankovic, and Aba-SahDadzie.
2014.
Making sense of microposts (#microposts2014) named entity extraction & linkingchallenge.
Making Sense of Microposts (# Microp-osts2014).David Carmel, Ming-Wei Chang, Evgeniy Gabrilovich,Bo-June Paul Hsu, and Kuansan Wang.
2014.Erd?14: entity recognition and disambiguation chal-lenge.
In ACM SIGIR Forum, pages 63?77.Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and exper-iments with perceptron algorithms.
In Proceedingsof the conference on Empirical methods in naturallanguage processing (EMNLP), pages 1?8.Corinna Cortes, Vitaly Kuznetsov, and Mehryar Mohri.2014.
Learning ensembles of structured predictionrules.
In Proceedings of ACL.Silviu Cucerzan.
2007.
Large-scale named entity dis-ambiguation based on wikipedia data.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), pages 708?716.Silviu Cucerzan.
2012.
The msr system for entity link-ing at tac 2012.
In Text Analysis Conference.Thomas G Dietterich, Adam Ashenfelter, and YaroslavBulatov.
2004.
Training conditional random fieldsvia gradient tree boosting.
In Proceedings of thetwenty-first international conference on Machinelearning (ICML), pages 28?35.Yuan Fang and Ming-Wei Chang.
2014.
Entity link-ing on microblogs with spatial and temporal signals.Transactions of the Association for ComputationalLinguistics (ACL), pages 259?272.512P.
Ferragina and U. Scaiella.
2010.
TAGME: on-the-fly annotation of short text fragments (by Wikipediaentities).
In Proceedings of ACM Conference onInformation and Knowledge Management (CIKM),pages 1625?1628.Jerome H Friedman.
2001.
Greedy function approx-imation: a gradient boosting machine.
Annals ofStatistics, pages 1189?1232.Stephen Guo, Ming-Wei Chang, and Emre Kiciman.2013.
To link or not to link?
a study on end-to-endtweet entity linking.
In Proceedings of the NorthAmerican Chapter of the Association for Computa-tional Linguistics (NAACL), pages 1020?1030.Heng Ji and Ralph Grishman.
2011.
Knowledge basepopulation: Successful approaches and challenges.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics, pages1148?1158.Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-fitt, and Joe Ellis.
2010.
Overview of the tac 2010knowledge base population track.
In Third TextAnalysis Conference (TAC).John Lafferty, Andrew McCallum, and Fernando CNPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of the 18th inter-national conference on Machine learning (ICML),pages 282?289.Ping Li, Qiang Wu, and Christopher J Burges.
2007.Mcrank: Learning to rank using multiple classifica-tion and gradient boosting.
In Advances in neuralinformation processing systems (NIPS), pages 897?904.Xiaohua Liu, Yitong Li, Haocheng Wu, Ming Zhou,Furu Wei, and Yi Lu.
2013.
Entity linking fortweets.
In Proceedings of the Association for Com-putational Linguistics (ACL), pages 1304?1311.Michael Mathioudakis and Nick Koudas.
2010.
Twit-termonitor: trend detection over the twitter stream.In Proceedings of the 2010 ACM SIGMOD Inter-national Conference on Management of data (SIG-MOD), pages 1155?1158.E.
Meij, W. Weerkamp, and M. de Rijke.
2012.Adding semantics to microblog posts.
In Proceed-ings of International Conference on Web Search andWeb Data Mining (WSDM), pages 563?572.Tomas Mikolov, Martin Karafi?at, Lukas Burget, JanCernock`y, and Sanjeev Khudanpur.
2010.
Recur-rent neural network based language model.
In IN-TERSPEECH, pages 1045?1048.D.
Milne and I. H. Witten.
2008.
Learning to link withWikipedia.
In Proceedings of ACM Conference onInformation and Knowledge Management (CIKM),pages 509?518.Kevin P Murphy.
2012.
Machine learning: a proba-bilistic perspective.
MIT press.C Quoc and Viet Le.
2007.
Learning to rank withnonsmooth cost functions.
pages 193?200.A.
Ritter, S. Clark, Mausam, and O. Etzioni.
2011.Named entity recognition in tweets: an experimen-tal study.
In Proceedings of the Conference on Em-pirical Methods for Natural Language Processing(EMNLP), pages 1524?1534.Byron P Roe, Hai-Jun Yang, Ji Zhu, Yong Liu, IonStancu, and Gordon McGregor.
2005.
Boosted de-cision trees as an alternative to artificial neural net-works for particle identification.
Nuclear Instru-ments and Methods in Physics Research Section A:Accelerators, Spectrometers, Detectors and Associ-ated Equipment, pages 577?584.Sunita Sarawagi and William W Cohen.
2004.
Semi-markov conditional random fields for informationextraction.
In Advances in Neural Information Pro-cessing Systems (NIPS), pages 1185?1192.Avirup Sil and Alexander Yates.
2013.
Re-rankingfor joint named-entity recognition and linking.
InProceedings of ACM Conference on Informationand Knowledge Management (CIKM), pages 2369?2374.Richard Socher, Cliff C Lin, Chris Manning, and An-drew Y Ng.
2011.
Parsing natural scenes and nat-ural language with recursive neural networks.
InProceedings of the 28th International Conference onMachine Learning (ICML), pages 129?136.Richard Socher, Alex Perelygin, Jean Y Wu, JasonChuang, Christopher D Manning, Andrew Y Ng,and Christopher Potts.
2013.
Recursive deep mod-els for semantic compositionality over a sentimenttreebank.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing(EMNLP), pages 1631?1642.Ben Taskar, Carlos Guestrin, and Daphne Roller.
2004.Max-margin markov networks.
Advances in neuralinformation processing systems, 16:25.Ioannis Tsochantaridis, Thomas Hofmann, ThorstenJoachims, and Yasemin Altun.
2004.
Support vec-tor machine learning for interdependent and struc-tured output spaces.
In Proceedings of the twenty-first international conference on Machine learning(ICML), page 104.Ioannis Tsochantaridis, Thorsten Joachims, ThomasHofmann, and Yasemin Altun.
2005.
Large mar-gin methods for structured and interdependent out-put variables.
In Journal of Machine Learning Re-search, pages 1453?1484.Qiang Wu, Christopher JC Burges, Krysta M Svore,and Jianfeng Gao.
2010.
Adapting boosting forinformation retrieval measures.
Information Re-trieval, pages 254?270.513
