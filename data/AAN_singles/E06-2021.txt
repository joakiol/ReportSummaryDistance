Automatic Acronym RecognitionDana Danne?llsComputational Linguistics, Department of Linguistics andDepartment of Swedish LanguageGo?teborg UniversityGo?teborg, Swedencl2ddoyt@cling.gu.seAbstractThis paper deals with the problemof recognizing and extracting acronym-definition pairs in Swedish medical texts.This project applies a rule-based methodto solve the acronym recognition task andcompares and evaluates the results of dif-ferent machine learning algorithms on thesame task.
The method proposed is basedon the approach that acronym-definitionpairs follow a set of patterns and otherregularities that can be usefully appliedfor the acronym identification task.
Su-pervised machine learning was applied tomonitor the performance of the rule-basedmethod, using Memory Based Learning(MBL).
The rule-based algorithm wasevaluated on a hand tagged acronym cor-pus and performance was measured usingstandard measures recall, precision and f-score.
The results show that performancecould further improve by increasing thetraining set and modifying the input set-tings for the machine learning algorithms.An analysis of the errors produced indi-cates that further improvement of the rule-based method requires the use of syntacticinformation and textual pre-processing.1 IntroductionThere are many on-line documents which containimportant information that we want to understand,thus the need to extract glossaries of domain-specific names and terms increases, especially intechnical fields such as biomedicine where the vo-cabulary is quickly expanding.
One known phe-nomenon in biomedical literature is the growth ofnew acronyms.Acronyms are a subset of abbreviations andare generally formed with capital letters from theoriginal word or phrase, however many acronymsare realized in different surface forms i.e.
useof Arabic-numbers, mixed alpha-numeric forms,low-case acronyms etc.Several approaches have been proposed for au-tomatic acronym extraction, with the most com-mon tools including pattern-matching techniquesand machine learning algorithms.
Considering thelarge variety in the Swedish acronym-definitionpairs it is practical to use pattern-matching tech-niques.
These will enable to extract relevant in-formation of which a suitable set of schema willgive a representation valid to present the differentacronym pairs.This project presents a rule-based algorithm toprocess and automatically detect different forms ofacronym-definition pairs.
Since machine learningtechniques are generally more robust, can easilybe retrained for a new data and successfully clas-sify unknown examples, different algorithms weretested.
The acronym pair candidates recognizedby the rule-based algorithm were presented as fea-ture vectors and were used as the training data forthe supervised machine learning system.This approach has the advantage of using ma-chine learning techniques without the need formanual tagging of the training data.
Several ma-chine learning algorithms were tested and their re-sults were compared on the task.2 Related workThe task of automatically extracting acronym-definition pairs from biomedical literature hasbeen studied, almost exclusively for English, overthe past few decades using technologies from Nat-ural Language Processing (NLP).
This section167presents a few approaches and techniques thatwere applied to the acronym identification task.Taghva and Gilbreth (1999) present theAcronyms Finding Program (AFP), based onpattern matching.
Their program seeks foracronym candidates which appear as upper casewords.
They calculate a heuristic score for eachcompeting definition by classifying words into:(1) stop words (?the?, ?of?, ?and?
), (2) hyphen-ated words (3) normal words (words that don?tfall into any of the above categories) and (4) theacronyms themselves (since an acronym cansometimes be a part of the definition).
The AFPutilizes the Longest Common Subsequence (LCS)algorithm (Hunt and Szymanski, 1977) to find allpossible alignments of the acronym to the text,followed by simple scoring rules which are basedon matches.
The performance reported from theirexperiment are: recall of 86% at precision of 98%.An alternative approach to the AFP was pre-sented by Yeates (1999).
In his program, ThreeLetters Acronyms (TLA), he uses more complexmethods and general heuristics to match charac-ters of the acronym candidate with letters in thedefinition string, Yeates reported f-score of 77.8%.Another approach recognizes that the align-ment between an acronym and its definition of-ten follows a set of patterns (Park and Byrd,2001), (Larkey et al, 2000).
Pattern-based meth-ods use strong constraints to limit the number ofacronyms respectively definitions recognized andensure reasonable precision.Nadeau and Turney (2005) present a machinelearning approach that uses weak constraints to re-duce the search space of the acronym candidatesand the definition candidates, they reached recallof 89% at precision of 88%.Schwartz and Hearst (2003) present a simple al-gorithm for extracting abbreviations from biomed-ical text.
The algorithm extracts acronym candi-dates, assuming that either the acronym or the def-inition occurs between parentheses and by givingsome restrictions for the definition candidate suchas length and capital letter initialization.
When anacronym candidate is found the algorithm scansthe words in the right and left side of the foundacronym and tries to match the shortest definitionthat matches the letters in the acronym.
Their ap-proach is based on previous work (Pustejovsky etal., 2001), they achieved recall of 82% at precisionof 96%.It should be emphasized that the common char-acteristic of previous approaches in the surveyedliterature is the use of parentheses as indication forthe acronym pairs, see Nadeau and Turney (2005)table 1.
This limitation has many drawbackssince it excludes the acronym-definition candi-dates which don?t occur within parentheses andthereby don?t provide a complete coverage for allthe acronyms formation.3 Methods and implementationThe method presented in this section is based ona similar algorithm described by Schwartz andHearst (2003).
However it has the advantage ofrecognizing acronym-definition pairs which arenot indicated by parentheses.3.1 Finding Acronym-Definition CandidatesA valid acronym candidate is a string of alpha-betic, numeric and special characters such as ?-?and ?/?.
It is found if the string satisfies the condi-tions (i) and (ii) and either (iii) or (iv):(i) The string contains at least two charac-ters.
(ii) The string is not in the list of rejectedwords1.
(iii) The string contains at least one capi-tal letter.
(iv) The strings?
first or last character islower case letter or numeric.When an acronym is found, the algorithmsearches the words surrounding the acronym for adefinition candidate string that satisfies the follow-ing conditions (all are necessary in conjunction):(i) At least one letter of the words in the stringmatches the letter in the acronym.
(ii) The stringdoesn?t contain a colon, semi-colon, questionmark or exclamation mark.
(iii) The maximumlength of the string is min(|A|+5,|A|*2), where|A| is the acronym length (Park and Byrd, 2001).
(iv) The string doesn?t contain only upper case let-ters.3.2 Matching Acronyms with DefinitionsThe process of extracting acronym-definition pairsfrom a raw text, according to the constraints de-scribed in Section 3.1 is divided into two steps:1.
Parentheses matching.
In practice, most ofthe acronym-definition pairs come inside paren-theses (Schwartz and Hearst, 2003) and can cor-respond to two different patterns: (i) defini-tion (acronym) (ii) acronym (definition).
The1The rejected word list contains frequent acronyms whichappear in the corpus without their definition, e.g.
?USA?,?UK?, ?EU?.168algorithm extracts acronym-definition candidateswhich correspond to one of these two patterns.2.
Non parentheses matching.
The algorithmseeks for acronym candidates that follow the con-straints, described in Section 3.1 and are not en-closed in parentheses.
Once an acronym candidateis found it scans the previous and following con-text, where the acronymwas found, for a definitioncandidate.
The search space for the definition can-didate string is limited to four words multiplied bythe number of letters in the acronym candidate.The next step is to choose the correct substringof the definition candidate for the acronym can-didate.
This is done by reducing the definitioncandidate string as follows: the algorithm searchesfor identical characters between the acronym andthe definition starting from the end of both stringsand succeeds in finding a correct substring forthe acronym candidate if it satisfies the follow-ing conditions: (i) at least one character in theacronym string matches with a character in thesubstring of the definition; (ii) the first characterin the acronym string matches the first characterof the leftmost word in the definition substring, ig-noring upper/lower case letters.3.3 Machine Learning ApproachTo test and compare different supervised learn-ing algorithms, Tilburg Memory-Based Learner(TiMBL)2 was used.
In memory-based learningthe training set is stored as examples for later eval-uation.
Features vectors were calculated to de-scribe the acronym-definition pairs.
The ten fol-lowing (numeric) features were chosen: (1) theacronym or the definition is between parenthe-ses (0-false, 1-true), (2) the definition appears be-fore the acronym (0-false, 1-true), (3) the dis-tance in words between the acronym and thedefinition, (4) the number of characters in theacronym, (5) the number of characters in the def-inition, (6) the number of lower case letters in theacronym, (7) the number of lower case letters inthe definition, (8) the number of upper case let-ters in the acronym, (9) the number of upper caseletters in the definition and (10) the number ofwords in the definition.
The 11th feature is theclass to predict: true candidate (+), false candi-date (-).
An example of the acronym-definitionpair ?
?vCJD?, ?variant CJD??
represented asa feature vector is: 0,1,1,4,11,1,7,3,3,2,+.2http://ilk.uvt.nl4 Evaluation and Results4.1 Evaluation CorpusThe data set used in this experiment consists of861 acronym-definition pairs.
The set was ex-tracted from Swedish medical texts, the MEDLEXcorpus (Kokkinakis, 2006) and was manually an-notated using XML tags.
For the majority of thecases there exist one acronym-definition pair persentence, but there are cases where two or morepairs can be found.4.2 Experiment and ResultsThe rule-based algorithm was evaluated on the un-tagged MEDLEX corpus samples.
Recall, pre-cision and F-score were used to calculate theacronym-expansion matching.
The algorithm rec-ognized 671 acronym-definition pairs of which 47were incorrectly identified.
The results obtainedwere 93% precision and 72.5% recall, yielding F-score of 81.5%.A closer look at the 47 incorrect acronym pairsthat were found showed that the algorithm failedto make a correct match when: (1) words thatappear in the definition string don?t have a corre-sponding letter in the acronym string, (2) lettersin the acronym string don?t have a correspondingword in the definition string, such as ?PGA?
from?glycol alginate lo?sning?, (3) letters in the defini-tion string don?t match the letters in the acronymstring.The error analysis showed that the reasons formissing 190 acronym-definition pairs are: (1) let-ters in the definition string don?t appear in theacronym string, due to a mixture of a Swedishdefinition with an acronym written in English,(2) mixture of Arabic and Roman numerals, suchas ?USH3?
from ?Usher typ III?, (3) position ofnumbers/letters, (4) acronyms of three characterswhich appear in lower case letters.4.3 Machine Learning ExperimentThe acronym-definition pairs recognized by therule-based algorithm were used as the training ma-terial in this experiment.
The 671 pairs were pre-sented as feature vectors according to the featuresdescribed in Section 3.3.
The material was di-vided into two data files: (1) 80% training data;(2) 20% test data.
Four different algorithms wereused to create models.
These algorithms are: IB1,IGTREE, TRIBL and TRIBL2.
The results ob-tained are given in Table 1.169Algorithm Precision Recall F-scoreIB1 90.6 % 97.1 % 93.7 %IGTREE 95.4 % 97.2 % 96.3 %TRIBL 92.0 % 96.3 % 94.1 %TRIBL2 92.8 % 96.3 % 94.5 %Table 1: Memory-Based algorithm results.5 ConclusionsThe approach presented in this paper relies onalready existing acronym pairs which are seenin different Swedish texts.
The rule-based algo-rithm utilizes predefined strong constraints to findand extract acronym-definition pairs with differ-ent patterns, it has the advantage of recognizingacronyms and definitions which are not indicatedby parentheses.
The recognized pairs were usedto test and compare several machine learning al-gorithms.
This approach does not requires manualtagging of the training data.The results given by the rule-based algorithmare as good as reported from earlier experimentsthat have dealt with the same task for the Englishlanguage.
The algorithm uses backward search al-gorithm and to increase recall it is necessary tocombine it with forward search algorithm.The variety of the Swedish acronym pairs islarge and includes structures which are hard to de-tect, for example: ?
?V F?, ?kammarflimmer?
?and ?
?CT?, ?datortomografi?
?, the acronymis in English while the extension is written inSwedish.
These structures require a dictio-nary/database lookup3, especially because thereare also counter examples in the Swedish textwhere both the acronym and the definition are inEnglish.
Another problematic structure is threeletter acronyms which consist of only lowercaseletters since there are many prepositions, verbs anddeterminates that correspond to this structure.
Tosolve this problem it may be suitable to combinetextual pre-processing such as part-of-speech an-notation or/and parsing with the exiting code.The machine learning experiment shows thatthe best results were given by the IGTREE algo-rithm4.
Performance can further improve by mod-ifying the input settings e.g test different featureweighting schemes, such as Shared Variance and3Due to short time available and the lack of resources thisfeature was not used in the experiment.4The IGTREE algorithm uses information gain in a com-pressed decision tree structure.Gain Ratio and combine different values of k forthe k-nearest neighbour classifier5.On-going work aim to improve the rule-basedmethod and combine it with a supervised machinelearning algorithm.
The model produced will laterbe used for making prediction on a new data.AcknowledgementsProject funded in part by the SematicMining EUFP6 NoE 507505.
This research has been car-ried out thanks to Lars Borin and Dimitrios Kokki-nakis.
I thank Torbjo?rn Lager for his guidanceand encouragement.
I would like to thank WalterDaelemans, Ko van der Sloot Antal van den Boschand Robert Andersson for their help and support.ReferencesAriel S. Schwartz and Marti A. Hearst.
2003.
A simplealgorithm for identifying abbreviation definitions inbiomedical texts.
Proc.
of the Pacific Symposium onBiocomputing.
University of California, Berkeley.David Nadeau and Peter Turney.
2005.
A SupervisedLearning Approach to Acronym Identification.
In-formation Technology National Research Council,Ottawa, Ontario, Canada.Dimitrios Kokkinakis.
2006.
Collection, Encodingand Linguistic Processing of a Swedish MedicalCorpus: The MEDLEX Experience.
Proc.
of the 5thLREC.
Genoa, Italy.James W. Hunt and Thomas G. Szymanski.
1977.
Afast algorithm for computing longest common sub-sequences.
Commun.
of the ACM, 20(5):350-353.James Pustejovsky, Jose?
Castan?o, Brent Cochran, Ma-ciej Kotecki and Michael Morrella.
2001.
Au-tomation Extraction of Acronym-MeaningPairs fromMedline Databases.
In Proceedings of Medinfo.Kazen Taghva and Jeff Gilbreth.
1999.
Technical Re-port.
Recognizing Acronyms and their Definitions.University of Nevada, Las Vegas.Leah S. Larkey, Paul Ogilvie, Andrew M. Price andBrenden Tamilio.
2000.
Acrophile: An AutomatedAcronym Extractor and Server.
University of Mas-sachusetts, Dallas TX.Stuart Yeates.
1999.
Automatic extraction of acronymsfrom text.
Proc.
of the Third New Zealand ComputerScience Research Students?
Conference.
Universityof Waikato, New Zealand.Youngja Park and Roy J. Byrd.
2001.
Hybrid Text Min-ing for Finding Abbreviations and Their Definitions.IMB Thomas J. Watson Research Center, NY, USA.5In the machine learning experiment default value is used,k=1.170
