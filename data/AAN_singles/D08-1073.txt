Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 698?706,Honolulu, October 2008. c?2008 Association for Computational LinguisticsJointly Combining Implicit Constraints Improves Temporal OrderingNathanael Chambers and Dan JurafskyDepartment of Computer ScienceStanford UniversityStanford, CA 94305{natec,jurafsky}@stanford.eduAbstractPrevious work on ordering events in text hastypically focused on local pairwise decisions,ignoring globally inconsistent labels.
How-ever, temporal ordering is the type of domainin which global constraints should be rela-tively easy to represent and reason over.
Thispaper presents a framework that informs lo-cal decisions with two types of implicit globalconstraints: transitivity (A before B and B be-fore C implies A before C) and time expressionnormalization (e.g.
last month is before yes-terday).
We show how these constraints canbe used to create a more densely-connectednetwork of events, and how global consis-tency can be enforced by incorporating theseconstraints into an integer linear programmingframework.
We present results on two eventordering tasks, showing a 3.6% absolute in-crease in the accuracy of before/after classifi-cation over a pairwise model.1 IntroductionBeing able to temporally order events is a neces-sary component for complete document understand-ing.
Interest in machine learning approaches for thistask has recently been encouraged through the cre-ation of the Timebank Corpus (Pustejovsky et al,2003).
However, most work on event-event order-ing has focused on improving classifiers for pair-wise decisions, ignoring obvious contradictions inthe global space of events when misclassificationsoccur.
A global framework to repair these event or-dering mistakes has not yet been explored.This paper addresses three main factors involvedin a global framework: the global optimization al-gorithm, the constraints that are relevant to the task,and the level of connectedness across pairwise de-cisions.
We employ Integer Linear Programming toaddress the first factor, drawing from related workin paragraph ordering (Bramsen et al, 2006).
Afterfinding minimal gain with the initial model, we ex-plore reasons for and solutions to the remaining twofactors through temporal reasoning and transitivityrule expansion.We analyze the connectivity of the Timebank Cor-pus and show how textual events can be indirectlyconnected through a time normalization algorithmthat automatically creates new relations betweentime expressions.
We show how this increased con-nectivity is essential for a global model to improveperformance.We present three progressive evaluations of ourglobal model on the Timebank Corpus, showing a3.6% gain in accuracy over its original set of re-lations, and an 81% increase in training data sizefrom previous work.
In addition, we present the firstresults on Timebank that include an unknown rela-tion, establishing a benchmark for performance onthe full task of document ordering.2 Previous WorkRecent work on classifying temporal relationswithin the Timebank Corpus built 6-way relationclassifiers over 6 of the corpus?
13 relations (Mani etal., 2006; Mani et al, 2007; Chambers et al, 2007).A wide range of features are used, ranging from sur-face indicators to semantic classes.
Classifiers make698local pairwise decisions and do not consider globalimplications between the relations.The TempEval-07 (Verhagen et al, 2007) contestrecently used two relations, before and after, in asemi-complete textual classification task with a newthird relation to distinguish relations that can be la-beled with high confidence from those that are un-certain, called vague.
The task was a simplified clas-sification task from Timebank in that only one verb,the main verb, of each sentence was used.
Thus, thetask can be viewed as ordering the main events inpairwise sentences rather than the entire document.This paper uses the core relations of TempEval(before,after,vague) and applies them to a full docu-ment ordering task that includes every labeled eventin Timebank.
In addition, we extend the previouswork by including a temporal reasoning componentand embedding it within a global constraint model.3 The Timebank CorpusThe Timebank Corpus (Pustejovsky et al, 2003) isa corpus of 186 newswire articles that are taggedfor events, time expressions, and relations betweenthe events and times.
The individual events are fur-ther tagged for temporal information such as tense,modality and grammatical aspect.
Time expressionsuse the TimeML (Ingria and Pustejovsky, 2002)markup language.
There are 6 main relations andtheir inverses in Timebank: before, ibefore, includes,begins, ends and simultaneous.This paper describes work that classifies the re-lations between events, making use of relations be-tween events and times, and between the timesthemselves to help inform the decisions.4 The Global ModelOur initial model has two components: (1) a pair-wise classifier between events, and (2) a global con-straint satisfaction layer that maximizes the confi-dence scores from the classifier.
The first is basedon previous work (Mani et al, 2006; Chambers etal., 2007) and the second is a novel contribution toevent-event classification.4.1 Pairwise ClassificationClassifying the relation between two events is thebasis of our model.
A soft classification with confi-dence scores is important for the global maximiza-tion step that is described in the next section.
Asin Chambers et al (2007), we build support vec-tor machine (SVM) classifiers and use the probabili-ties from pairwise SVM decisions as our confidencescores.
These scores are then used to choose an op-timal global ordering.Following our previous work, we use the set offeatures summarized in figure 1.
They vary fromPOS tags and lexical features surrounding the event,to syntactic dominance, to whether or not the eventsshare the same tense, grammatical aspect, or aspec-tual class.
These features are the highest performingset on the basic 6-way classification of Timebank.Feature DescriptionWord* The text of the eventLemma* The lemmatized head wordSynset* The WordNet synset of head wordPOS* 4 POS tags, 3 before, and 1 eventPOS bigram* The POS bigram of the event and itspreceding tagPrep* Preposition lexeme, if in a preposi-tional phraseTense* The event?s tenseAspect* The event?s grammatical aspectModal* The modality of the eventPolarity* Positive or negativeClass* The aspecual class of the eventTense Pair The two concatenated tensesAspect Pair The two concatenated aspectsClass Pair The two concatenated classesPOS Pair The two concatenated POS tagsTense Match true if the events have the same tenseAspect Match true if the events have the same as-pectClass Match true if the events have the same classDominates true if the first event syntacticallydominates the secondText Order true if the first event occurs first inthe documentEntity Match true if they share an entity as an ar-gumentSame Sent true if both events are in the samesentenceFigure 1: The features to learn temporal relations be-tween two events.
Asterisks (*) indicate features that areduplicated, one for each of the two events.We use Timebank?s hand tagged attributes in thefeature values for the purposes of this comparative699before after unknownA r1 B .5 .3 .2B r2 C .4 .3 .3A r3 C .4 .5 .1total 1.3 1.1 .6A r1 B .5 .3 .2B r2 C .4 .3 .3A r3 C .2 .7 .1total 1.1 1.3 .6Figure 2: Two sets of confidence scores.
The first setchooses before for all three labels, and the second choosesafter.
Other lower-scoring valid relation sets also exist,such as before, unknown, and before.study of global constraints, described next.4.2 Global ConstraintsPairwise classifiers can make contradictory classifi-cations due to their inability to consider other deci-sions.
For instance, the following three decisions arein conflict:A before BB before CA after CTransitivity is not taken into account.
In fact, thereare several ways to resolve the conflict in this exam-ple.
Given confidence scores (or probabilities) foreach possible relation between the three pairs, wecan compute an optimal label assignment.
Differ-ent scores can lead to different conflict resolutions.Figure 2 shows two resolutions given different setsof scores.
The first chooses before for all three rela-tions, while the second chooses after.Bramsen et al (2006) presented a variety of ap-proaches to using transitivity constraints to help in-form pairwise decisions.
They found that IntegerLinear Programming (ILP) performed the best on aparagraph ordering task, consistent with its propertyof being able to find the optimal solution for a setof constraints.
Other approaches are variations ona greedy strategy of adding pairs of events one at atime, ordered by their confidence.
These can lead tosuboptimal configurations, although they are guar-anteed to find a solution.
Mani et al (2007) sub-sequently proposed one of these greedy strategies aswell, but published results are not available.
We alsoimplemented a greedy best-first strategy, but foundILP outperformed it.Our Integer Linear Programming framework usesthe following objective function:max?i?jpijxij (1)with added constraints:?i?j xij ?
{0, 1} (2)?i xi1 + xi2 + ... + xim = 1 (3)where xij represents the ith pair of events classifiedas the jth relation of m relations.
Thus, each pairof events generates m variables.
Given n pairs ofevents, there are n ?
m variables.
pij is the proba-bility of classifying pair i with relation j. Equation2 (the first constraint) simply says that each variablemust be 0 or 1.
Equation 3 contains m variables fora single pair of events i representing its m possiblerelations.
It states that one relation must be set to 1and the rest to 0.
In other words, a pair of eventscannot have two relations at the same time.
Finally,a transitivity constraint is added for all connectedpairs i, j, k, for each transitivity condition that infersrelation c given a and b:xia + xjb ?
xkc <= 1 (4)We generated the set of constraints for each doc-ument and used lpsolve1 to solve the ILP constraintproblem.The transitivity constraints are only effective ifthe available pairwise decisions constitute a con-nected graph.
If pairs of events are disconnected,then transitivity makes little to no contribution be-cause these constraints are only applicable to con-nected chains of events.4.3 Transitive ClosureIn order to connect the event graph, we draw onwork from (Mani et al, 2006) and apply transitiveclosure to our documents.
Transitive closure wasfirst proposed not to address the problem of con-nected event graphs, but rather to expand the sizeof training data for relations such as before.
Time-bank is a relatively small corpus with few examples1http://sourceforge.net/projects/lpsolve700Total Event-Event Relations After Closurebefore afterTimebank 592 656+ closure 3919 3405Figure 3: The number of event-event relations after tran-sitive closure.of each relation.
One way of expand the trainingset is through transitive rules.
A few rules are givenhere:A simultaneous B ?A before C ?
B before CA includes B ?A ibefore C ?
B before CA before B ?A ends C ?
B after CWhile the original motivation was to expand thetraining size of tagged relations, this approach alsocreates new connections in the graph, replacing pre-viously unlabeled event pairs with their true rela-tions.
We adopted this approach and closed the orig-inal set of 12 relations to help connect the globalconstraint model.4.4 Initial ExperimentThe first evaluation of our global temporal modelis on the Timebank Corpus over the labeled rela-tions before and after.
We merged ibefore and iafterinto these two relations as well, ignoring all oth-ers.
We use this task as a reduced evaluation tostudy the specific contribution of global constraints.We also chose this strict ordering task because it iswell defined from a human understanding perspec-tive.
Snow et al (2008) shows that average inter-net users can make before/after decisions with veryhigh confidence, although the distinction with an un-known relation is not as clear.
An evaluation includ-ing unknown (or vague as in TempEval) is presentedlater.We expanded the corpus (prior to selecting the be-fore/after relations) using transitive closure over all12 relations as described above.
Figure 3 shows theincrease in data size.
The number of before and afterrelations increase by a factor of six.We trained and tested the system with 10-foldcross validation and micro-averaged accuracies.
Thefolds were randomly generated to separate the 186files into 10 folds (18 or 19 files per fold).
The same10-way split is used for all the evaluations.
We usedComparative ResultsTraining Set AccuracyTimebank Pairwise 66.8%Global Model 66.8%Figure 4: Using the base Timebank annotated tags fortesting, accuracy on before/after tags in the two models.libsvm2 to implement our SVM classifiers.Figure 4 shows the results from our ILP modelwith transitivity constraints.
The first row is thebaseline pairwise classification trained and tested onthe original Timebank relations.
The second rowgives performance with ILP.
The model shows noimprovement.
The global ILP constraints did affectlocal decisions, changing 175 of them (out of 7324),but the changes cancelled out and had no affect onoverall accuracy.4.5 Loosely Connected GraphWhy didn?t a global model help?
The problem liesin the graph structure of Timebank?s annotated rela-tions.
The Timebank annotators were not requiredto annotate relations between any particular pair ofevents.
Instead, they were instructed to annotatewhat seemed appropriate due to the almost insur-mountable task of annotating all pairs of events.
Amodest-sized document of 30 events, for example,would contain(302)= 435 possible pairs.
Anno-tators thus marked relations where they deemed fit,most likely between obvious and critical relations tothe understanding of the article.
The vast majority ofpossible relations are untagged, thus leaving a largeset of unlabeled (and disconnected) unknown rela-tions.Figure 5 graphically shows all relations that areannotated between events and time expressions inone of the shorter Timebank documents.
Nodes rep-resent events and times (event nodes start with theletter ?e?, times with ?t?
), and edges represent tempo-ral relations.
Solid lines indicate hand annotations,and dotted lines indicate new rules from transitiveclosure (only one, from event e4 to time t14).
Ascan be seen, the graph is largely disconnected anda global model contributes little information sincetransitivity constraints cannot apply.2http://www.csie.ntu.edu.tw/?
cjlin/libsvm701Timebank Annotation of wsj 0551Figure 5: Annotated relations in document wsj 0551.The large amount of unlabeled relations in thecorpus presents several problems.
First, building aclassifier for these unknown relations is easily over-whelmed by the huge training set.
Second, many ofthe untagged pairs have non-unknown ordering rela-tions between them, but were missed by the annota-tors.
This point is critical because one cannot filterthis noise when training an unknown classifier.
Thenoise problem will appear later and will be discussedin our final experiment.
Finally, the space of an-notated events is very loosely connected and globalconstraints cannot assist local decisions if the graphis not connected.
The results of this first experimentillustrate this latter problem.Bethard et al (2007) strengthen the claim thatmany of Timebank?s untagged relations should notbe left unlabeled.
They performed an independentannotation of 129 of Timebank?s 186 documents,tagging all events in verb-clause relationships.
Theyfound over 600 valid before/after relations that areuntagged in Timebank, on average three per docu-ment.
One must assume that if these nearby verb-clause event pairs were missed by the annotators,the much larger number of pairs that cross sentenceboundaries were also missed.The next model thus attempts to fill in some of thegaps and further connect the event graph by usingtwo types of knowledge.
The first is by integratingBethard?s data, and the second is to perform tempo-ral reasoning over the document?s time expressions(e.g.
yesterday or january 1999).5 A Global Model With TimeOur initial model contained two components: (1) apairwise classifier between events, and (2) a globalconstraint satisfaction layer.
However, due to thesparseness in the event graph, we now introducea third component addressing connectivity: (3) atemporal reasoning component to inter-connect theglobal graph and assist in training data expansion.One important aspect of transitive closure in-cludes the event-time and time-time relations duringclosure, not just the event-event links.
Starting with5,947 different types of relations, transitive rules in-crease the dataset to approximately 12,000.
How-ever, this increase wasn?t enough to be effective inglobal reasoning.
To illustrate the sparsity that stillremains, if each document was a fully connectedgraph of events, Timebank would contain close to160,000 relations3, more than a 13-fold increase.More data is needed to enrich the Timebank eventgraph.
Two types of information can help: (1) moreevent-event relations, and (2) a separate type of in-formation to indirectly connect the events: event-X-event.
We incorporate the new annotations fromBethard et al (2007) to address (1) and introducea new temporal reasoning procedure to address (2).The following section describes this novel approachto adding time expression information to furtherconnect the graph.5.1 Time-Time InformationAs described above, we use event-time relations toproduce the transitive closure, as well as annotatedtime-time relations.
It is unclear if Mani et al (2006)used these latter relations in their work.However, we also add new time-time links thatare deduced from the logical time intervals that theydescribe.
Time expressions can be resolved to timeintervals with some accuracy through simple rules.New time-time relations can then be added to ourspace of events through time stamp comparisons.Take this newswire example:The Financial Times 100-share index shed 47.3 points toclose at 2082.1, down 4.5% from the previous Friday,and 6.8% from Oct. 13, when Wall Street?s plunge helpedspark the current weakness in London.3Sum over the # of events nd in each document d,(nd2)702The first two expressions (?previous Friday?and ?Oct.
13?)
are in a clear before relation-ship that Timebank annotators captured.
The?current?
expression, is correctly tagged with thePRESENT REF attribute to refer to the document?stimestamp.
Both ?previous Friday?
and ?Oct.
13?should thus be tagged as being before this expres-sion.
However, the annotators did not tag eitherof these two before relations, and so our timestampresolution procedure fills in these gaps.
This is acommon example of two expressions that were nottagged by the annotators, yet are in a clear temporalrelationship.We use Timebank?s gold standard TimeML an-notations to extract the dates and times from thetime expressions.
In addition, those marked asPRESENT REF are resolved to the document times-tamp.
Time intervals that are strictly before or aftereach other are thus labeled and added to our spaceof events.
We create new before relations based onthe following procedure:if event1.year < event2.yearreturn trueif event1.year == event2.yearif event1.month < event2.monthreturn trueif event1.month == event2.monthif event1.day < event2.dayreturn trueendendreturn falseAll other time-time orderings not including thebefore relation are ignored (i.e.
includes is not cre-ated, although could be with minor changes).This new time-time knowledge is used in two sep-arate stages of our model.
The first is just prior totransitive closure, enabling a larger expansion of ourtagged relations set and reduce the noise in the un-known set.
The second is in the constraint satisfac-tion stage where we add our automatically computedtime-time relations (with the gold event-time rela-tions) to the global graph to help correct local event-event mistakes.Total Event-Event Relations After Closurebefore afterTimebank 3919 3405+ time-time 5604 5118+ time/bethard 7111 6170Figure 6: The number of event-event before and after re-lations after transitive closure on each dataset.Comparative Results with ClosureTraining Set AccuracyTimebank Pairwise 66.8%Global Model 66.8%Global + time/bethard 70.4%Figure 7: Using the base Timebank annotated tags fortesting, the increase in accuracy on before/after tags.5.2 Temporal Reasoning ExperimentOur second evaluation continues the use of the two-way classification task with before and after to ex-plore the contribution of closure, time normaliza-tion, and global constraints.We augmented the corpus with the labeled rela-tions from Bethard et al (2007) and added the au-tomatically created time-time relations as describedin section 5.1.
We then expanded the corpus usingtransitive closure.
Figure 6 shows the progressivedata size increase as we incrementally add each tothe closure algorithm.The time-time generation component automati-cally added 2459 new before and after time-time re-lations into the 186 Timebank documents.
This isin comparison to only 157 relations that the humanannotators tagged, less than 1 per document on av-erage.
The second row of figure 6 shows the dras-tic effect that these time-time relations have on thenumber of available event-event relations for train-ing and testing.
Adding both Bethard?s data andthe time-time data increases our training set by 81%over closure without it.We again performed 10-fold cross validation withmicro-averaged accuracies, but each fold tested onlyon the transitively closed Timebank data (the firstrow of figure 6).
The training set used all availabledata (the third row of figure 6) including the Betharddata as well as our new time-time links.703Figure 7 shows the results from the new model.The first row is the baseline pairwise classificationtrained and tested on the original relations only.
Ourmodel improves by 3.6% absolute.
This improve-ment is statistically significant (p < 0.000001, Mc-Nemar?s test, 2-tailed).5.3 DiscussionTo further illustrate why our model now improveslocal decisions, we continue our previous graph ex-ample.
The actual text for the graph in figure 5 isshown here:docstamp: 10/30/89 (t14)Trustcorp Inc. will become(e1) Society Bank & Trustwhen its merger(e3) is completed(e4) with Society Corp.of Cleveland, the bank said(e5).
Society Corp., which isalso a bank, agreed(e6) in June(t15) to buy(e8) Trustcorpfor 12.4 million shares of stock with a market value ofabout $450 million.
The transaction(e9) is expected(e10)to close(e2) around year end(t17).The automatic time normalizer computes and addsthree new time-time relations, two connecting t15and t17 with the document timestamp, and one con-necting t15 and t17 together.
These are not other-wise tagged in the corpus.Time-Time + ClosureFigure 8: Before and after time-time links with closure.Figure 8 shows the augmented document.
Thedouble-line arrows indicate the three new time-timerelations and the dotted edges are the new relationsadded by our transitive closure procedure.
Most crit-ical to this paper, three of the new edges are event-event relations that help to expand our training data.If this document was used in testing (rather thantraining), these new edges would help inform ourtransitive rules during classification.Even with this added information, disconnectedsegments of the graph are still apparent.
However,the 3.6% performance gain encourages us to moveto the final full task.6 Final Experiment with UnknownsOur final evaluation expands the set of relations toinclude unlabeled relations and tests on the entiredataset available to us.
The following is now a clas-sification task between the three relations: before,after, and unknown.We duplicated the previous evaluation by addingthe labeled relations from Bethard et al (2007) andour automatically created time-time relations.
Wethen expanded this dataset using transitive closure.Unlike the previous evaluation, we also use this en-tire dataset for testing, not just for training.
Thus, allevent-event relations in Bethard as well as Timebankare used to expand the dataset with transitive closureand are used in training and testing.
We wanted tofully evaluate document performance on every pos-sible event-event relation that logically follows fromthe data.As before, we converted IBefore and IAfter intobefore and after respectively, while all other rela-tions are reduced to unknown.
This relation set co-incides with TempEval-07?s core three relations (al-though they use vague instead of unknown).Rather than include all unlabeled pairs in our un-known set, we only include the unlabeled pairs thatspan at most one sentence boundary.
In other words,events in adjacent sentences are included in the un-known set if they were not tagged by the Timebankannotators.
The intuition is that annotators are morelikely to label nearby events, and so events in adja-cent sentences are more likely to be actual unknownrelations if they are unlabeled.
It is more likely thatdistant events in the text were overlooked by con-venience, not because they truly constituted an un-known relationship.The set of possible sentence-adjacent unknown re-lations is very large (approximately 50000 unknowncompared to 7000 before), and so we randomly se-lect a percentage of these relations for each evalu-704Classification Accuracy% unk base global global+time0 72.0% 72.2% 74.0%1 69.4% 69.5% 71.3%3 65.5% 65.6% 67.1%5 63.7% 63.8% 65.3%7 61.2% 61.6% 62.8%9 59.3% 59.5% 60.6%11 58.1% 58.4% 59.4%13 57.1% 57.1% 58.1%Figure 9: Overall accuracy when training with differentpercentages of unknown relations included.
13% of un-knowns is about equal to the number of befores.ation.
We used the same SVM approach with thefeatures described in section 4.1.6.1 ResultsResults are presented in figure 9.
The rows in thetable are different training/testing runs on varyingsizes of unknown training data.
There are threecolumns with accuracy results of increasing com-plexity.
The first, base, are results from pairwiseclassification decisions over Timebank and Bethardwith no global model.
The second, global, are re-sults from the Integer Linear Programming globalconstraints, using the pairwise confidence scoresfrom the base evaluation.
Finally, the global+timecolumn shows the ILP results when all event-time,time-time, and automatically induced time-time re-lations are included in the global graph.The ILP approach does not alone improve perfor-mance on the event-event tagging task, but addingthe time expression relations greatly increases theglobal constraint results.
This is consistent with theresults from out first two experiments.
The evalua-tion with 1% of the unknown tags shows an almost2% improvement in accuracy.
The gain becomessmaller as the unknown set increases in size (1.0%gain with 13% unknown).
Unknown relations willtend to be chosen as more weight is given to un-knowns.
When there is a constraint conflict in theglobal model, unknown tends to be chosen becauseit has no transitive implications.
All improvementsfrom base to global+time are statistically significant(p < 0.000001, McNemar?s test, 2-tailed).Base Pairwise Classificationprecision recall f1-scorebefore 61.4 55.4 58.2after 57.6 53.1 55.3unk 53.0 62.8 57.5Global+Time Classificationprecision recall f1-scorebefore 63.7 (+2.3) 57.1 (+2.2) 60.2 (+2.0)after 60.3 (+2.7) 54.3 (+2.9) 57.1 (+1.8)unk 52.0 (-1.0) 62.9 (+0.1) 56.9 (-0.6)Figure 10: Precision and Recall for the base pairwise de-cisions and the global constraints with integrated time in-formation.The first row of figure 9 corresponds to the re-sults in our second experiment in figure 7, but showshigher accuracy.
The reason is due to our differenttest sets.
This final experiment includes Bethard?sevent-event relations in testing.
The improved per-formance suggests that the clausal event-event rela-tions are easier to classify, agreeing with the higheraccuracies originally found by Bethard et al (2007).Figure 10 shows the precision, recall, and f-scorefor the evaluation with 13% unknowns.
This set waschosen for comparison because it has a similar num-ber of unknown labels as before labels.
We see anincrease in precision in both the before and after de-cisions by up to 2.7%, an increase in recall up to2.9%, and an fscore by as much as 2.0%.
The un-known relation shows mixed results, possibly due toits noisy behavior as discussed throughout this pa-per.6.2 DiscussionOur results on the two-way (before/after) task showthat adding additional implicit temporal constraintsand then performing global reasoning results insignificant improvements in temporal ordering ofevents (3.6% absolute over simple pairwise deci-sions).Both before and after also showed increases inprecision and recall in the three-way evaluation.However, unknown did not parallel this improve-ment, nor are the increases as dramatic as in the two-way evaluation.
We believe this is consistent withthe noise that exists in the Timebank corpus for un-labeled relations.
Evidence from Bethard?s indepen-705dent annotations directly point to missing relations,but the dramatic increase in the size of our closuredata (81%) from adding a small amount of time-timerelations suggests that the problem is widespread.This noise in the unknown relation may be damp-ening the gains that the two way task illustrates.This work is also related to the task of event-timeclassification.
While not directly addressed in thispaper, the global methods described within clearlyapply to pairwise models of event-time ordering aswell.Further progress in improving global constraintswill require new methods to more accurately iden-tify unknown events, as well as new approaches tocreate implicit constraints over the ordering.
We ex-pect such an improved ordering classifier to be usedto improve the performance of tasks such as summa-rization and question answering about the temporalnature of events.AcknowledgmentsThis work is funded in part by DARPA through IBMand by the DTO Phase III Program for AQUAINT.We also thank our anonymous reviewers for manyhelpful suggestions.ReferencesSteven Bethard, James H. Martin, and Sara Klingenstein.2007.
Timelines from text: Identification of syntac-tic temporal relations.
In International Conference onSemantic Computing.Philip Bramsen, Pawan Deshpande, Yoong Keok Lee,and Regina Barzilay.
2006.
Inducing temporal graphs.In Proceedings of EMNLP-06.Nathanael Chambers, Shan Wang, and Dan Jurafsky.2007.
Classifying temporal relations between events.In Proceedings of ACL-07, Prague, Czech Republic.R Ingria and James Pustejovsky.
2002.
TimeML specifi-cation 1.0.
In http://www.time2002.org.Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong MinLee, and James Pustejovsky.
2006.
Machine learningof temporal relations.
In Proceedings of ACL-06, July.Inderjeet Mani, Ben Wellner, Marc Verhagen, and JamesPustejovsky.
2007.
Three approaches to learningtlinks in timeml.
Technical Report CS-07-268, Bran-deis University.James Pustejovsky, Patrick Hanks, Roser Sauri, AndrewSee, David Day, Lisa Ferro, Robert Gaizauskas, Mar-cia Lazo, Andrea Setzer, and Beth Sundheim.
2003.The timebank corpus.
Corpus Linguistics, pages 647?656.Rion Snow, Brendan O?Connor, Dan Jurafsky, and An-drew Ng.
2008.
Cheap and fast - but is it good?evaluating non-expert annotations for natural languagetasks.
In Proceedings of EMNLP-08, Waikiki, Hawaii,USA.Marc Verhagen, Robert Gaizauskas, Frank Schilder,Mark Hepple, Graham Katz, and James Pustejovsky.2007.
Semeval-2007 task 15: Tempeval temporal re-lation identification.
In Workshop on Semantic Evalu-ations.706
