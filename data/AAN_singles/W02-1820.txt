A Knowledge-based Approach to Text ClassificationZhu Jingbo Yao TianshunInstitute of Computer Software & Theory Institute of Computer Software & TheoryNortheastern University, Shenyang Liaoning,P.R.China 110006Northeastern University, Shenyang Liaoning,P.R.China 110006zhujingbo@yahoo.com tsyao@china.comAbstractThe paper presents a simple and effectiveknowledge-based approach for the task of textclassification.
The approach uses topicidentification algorithm named FIFA to textclassification.
In this paper the basic process oftext classification task and FIFA algorithm aredescribed in detail.
At last some results ofexperiment and evaluations are discussed.Keywords: FIFA algorithm, topic identification,text classification, natural language processingIntroductionThe text automatic classification method is basedon the content analysis automatically to allocatethe text into pre-determined catalogue.
Themethods of text automatic classification mainlyuse information retrieval techniques.
Traditionalinformation retrieval mainly retrieves relevantdocuments by using keyword-based orstatistic-based techniques (Salton.G1989).Generally, three famous models are used: vectorspace model, Boolean model and probabilitymodel, based on the three models, someresearchers brought forward extended models suchas John M.Picrrc(2001), Thomas Bayer, IngridRenz,Michael Stein(1996), Antal van den Bosch,Walter Daelemans, Ton Weijters(1996), Manuel deBuenaga Rodriguez, Jose Maria Gomez-llidalgo,Belen Diaz-agudo(1997), Ellen Riloff and WendyLehnert(1994).One central step in automatic text classificationis to identify the major topics of the texts.
Wepresent a simple and effective knowledge-basedapproach to text automatic classification.
Theapproach uses topic identification algorithmnamed FIFA to text classification.
In this paper thebasic process of text classification task and FIFAalgorithm are described in detail.
At last someresults of experiment and evaluations arediscussed.1 Knowledge-based text classificationThe principal process for the Knowledge -basedtext classification is illustrated as following:Text setNULL?
EndSelect a text for analysisTopic identificationOutput topic tagging of the textFigure 1 The principal process for the knowledge-based text classificationFrom the figure 1 we can know that the crucialtechnique of the text classification is the topicidentification parser.
The topic tagging of the textis identified as its catalogue.DictionaryRule baseTopic feature aggregationformula libraryNY2 Automatic Topic Identification2.1 Feature DictionaryThe feature dictionary is mainly used to storesome terms that can illustrate the topic featureconcept, and we call these terms as ?featureterms?.
The data structure of the featuredictionary is consist of word, POS, semantic,location and field attribute.
Some examples offeature dictionary are described as following:Feature terms Attributes??
?HuiTong CountyS(),,?,(???),,??(?)??(*+)(??),Z?(?
)S(),,LOCATION,LOCATION(HuitongCounty),,COUNTRY(China)PROVINCE (HuNan)CITY(HuaiHua),FIELD(geography)?
?Bank of ChinaN(),,?
,X(??
),,??(?),Z?(?
)Z?(?a)N(),,BANK,ORGANIZATION(bank),,COUNTRY(China),FIELD(bank)FIELD(finance)0?
?y?battle informationcenterN(),,?y?,X(0??y?),,,Z?(?y)Z?
(o_)N(),,INFORMATION-CENTER,ORGANIZATION(battle informationceter),,,FIELD(information)FIELD(military)???
?Sanxia ProjectN(),,??,??(????),,??(?),Z?(?
)N(),,PROJECT,PROJECT(Sanxia Project),,COUNTRY(China), FIELD(irrigation)Table 1: Some examples in the feature dictionarySince 1996 we employed a semi-automaticmethod to acquire feature terms from pre-categorized corpus, and developed a featuredictionary including about 300,000 feature terms.There are about 1,500 kinds of semantic features,and about 1,000 kinds of field attributes to tagfeature terms in this dictionary.2.2 Topic Feature Distribution ComputingFormulaAccording to the field attributes, frequenciesand positions of feature terms, we could computetopic feature distribution.
The computing stepsare described as following:1) According to the frequency and position of afeature term fti, we could compute the weight ofthe term fti.
The computing formula is describedas following:Where p(fti) is the weight of the feature term fti.freq(fti) is frequency of the feature term fti.
Ntitleis times of the feature term fti occurring in thetitle.
Nbegin is times of the feature term ftioccurring in the first sentence of a paragraph.Nend is times of the feature term fti occurring inthe end sentence of a paragraph.
freq(fti) istotal frequency of the all feature terms in the text.In the experiment we discovered that thefeature terms in different position of a text havethe different influence abilities on the topicfeatures.
So we take into account of this factorand use different experience coefficient in theweight computing formula of feature terms.
Inthe formula (1), the coefficient of Ntitle is 1.0, thecoefficient of Nbegin is 0.5, and the coefficient ofNend is 0.5.2) From the attribute of a feature term in thedictionary we could acquire its field attribute, infact this field attribute is the topic featureillustrated by the feature term.
The weight of atopic feature could be gotten by adding allweights of feature terms that illustrate the sametopic feature.
The more the feature termsillustrates the same topic feature, the higher theweight of the topic feature.
The weight of a topicfeature expresses its abilities illustrating the topicof the text.
The weight p(fi) computing formulaof a topic feature fi  is described as following:Where p(fi) is the weight of the topic feature fi.p(ftj) is the weight of the feature term ftj.
ftjfishows feature term set illustrating the same topicfeature fi.?
?+?++= )(5.05.0)()(iendbegintitleii ftfreqNNNftfreqftp (1)?
?=ij fftji ftpfp )()( (2)2.3 Topic Feature Aggregation FormulaThe topic feature aggregation formula isdescribed as following:Where ?
(ti) is the weight of the topic ti.
fj is thetopic feature illustrating the topic ti.
p(fj) is theweight of the topic feature fj.?
(fj) is thecoefficient of the topic feature fj.In the application system, we used automaticconstruction technique to construct a library,which called topic feature aggregation formulalibrary that includes 105 topic feature aggregationformulas.2.4 FIFA algorithmMost of automatic text processing techniquesuses topic identification as part of a specific task.The approaches to topic identification taken inthese techniques can be summarized in threegroup: statistical, knowledge-based, and hybrid.The statistical approach (H.P.Luhn 1957 ?H.P.Edmundson 1969?Gerard Salton, JamesAllan, Chris Buckley, and Amit Singhal 1994)infers topics of texts from term frequency, termlocation, term co-occurrence, etc, without usingexternal knowledge bases such as machinereadable dictionaries.
The knowledge-basedapproach (Wendy Lehnert and C. Loiselle 1989,Lin Hongfei 2000) relies on a syntactic orsemantic parser, knowledge bases such as scriptsor machine readable dictionaries, etc., withoutusing any corpus statistics.
The hybrid approach(Elizabeth D. Liddy and Sung H. Myaeng 1992,Marti A. Hearst 1994) combines the statisticaland knowledge-based approaches to takeadvantage of the strengths of both approachesand thereby to improve the overall systemperformance.This paper presents a simple and effectiveapproach named FIFA (feature identification andfeature aggregation) to text automatic topicidentification.
The core of algorithm FIFA isbased on the equation:Topic Identification = Topic FeatureIdentification + Topic Feature Aggregation.Topic identification (TI) can be divided intotwo phases: topic feature identification (FI) andtopic feature aggregation (FA).1) Topic Feature Identification (FI): We usethe term ?topic feature?
to name the sub-topic in atext.
In this phase algorithm FIFA identifiesfeature terms1 in a text by dictionary-based andrule-based methods.
The distribution of a topicfeature is computed by attributes, frequencies andpositions of topic feature terms.2) Topic Feature Aggregation (FA):According to distribution of topic features, in thisphase we use topic feature aggregation formulasto compute the weights of topics of a text, thenthe topic of a text could be determined by theweights computed.
Topic feature aggregationformula will be introduced detailedly in thefollowing chapters.
Using machine-learningmethod, the topic feature aggregation formulascould be acquired automatically frompre-classified training corpus.The topic identification algorithm FIFA couldbe described as following:Step1: Text segmentation and POS taggingInput: a raw text1.
Preprocessing phase: One major function isto recognize sentence boundaries, paragraphbreaks, abbreviations, numbers, and otherspecial tokens.2.
Segmentation phase: Employing maximalmatching algorithm to segment a sentencesinto some words, and setting a word?s POSset in machine readable dictionary as itsPOS tagging.3.
Disambiguation phase: Employing atechnology based on ambiguoussegmentation dictionary 2  to resolve theproblem of word ambiguous segmentation,and base on rules to recognize the unknownwords, such as name, location, company,organization noun etc.4.
POS tagging phase: Employing tri-grambased technology to POS tagging.Output: a text with formats, segmentationand POS taggingStep2: Topic feature identificationInput: a text with formats, segmentation andPOS tagging1.
Feature-dictionary-based feature termsidentification and taggingThe core of the method is to use featuredictionary to realize the feature termsidentification and tagging.
If a term in thetext is found in the dictionary, then we callthis term as a feature term of the text and its1Perhaps is a word, phrase, string, etc.
According toneed of the application system to determine the type ofthe feature term.2Is a machine readable man-made dictionary whichincludes examples of ambiguous segmentation and itscorrect segmentation?=?=njjjii ffpt1)()()(: ??
?field attribute in the dictionary is tagged asthe topic attribute of the feature term.2.
Rule-based feature terms identification andtaggingBecause of the limitation of the featuredictionary, we could not identify all featureterms by feature-dictionary-based technique.To resolve the problem of the unknownfeature terms, we use the technique ofrule-based feature terms identification andtagging.
There are two steps for theidentification and tagging:1) We employ statistics-based approach toacquire some high-frequency terms from thetext as analysis objects which length iscomposed of two or more words, and thefrequency in the text should exceed twotimes.2) We employ rule-based technique toanalyze the grammatical structure of thehigh frequency terms, and according to thegrammatical structure of the terms and theattribute of the central word to estimate thefield attribute of the term, which is tagged asthe topic feature attribute of the term.3.
According to attributes, frequencies andpositions of the feature terms to calculate thedistribution of the topic feature of the text.Output: topic feature set ?
?={(fi,?i)}?of thetext.
Where fi is the ith text topic feature; ?i is  theweight of the ith text topic feature fi subjected to?i(0,1).Step3: Topic feature aggregationInput: The topic feature set?
of the text.1.
Reading a formula ?i from the topic featureaggregation formula library, where theformula ?i is the aggregation formula ofthe topic ti.2.
According to parameters in the topic featureset ?, the weight of the topic ti could becomputed by the formula?i.3.
If there are some other aggregation formulasin the library, then go to Step1, otherwise goto the next step.4.
Supposing the topic feature fi in the set?
?={(fi,?i)}?as a topic, and ?i is the weightof the topic fi.
We sort the topic ti and fi byweight.Output: Selecting the topic with maximalweight as topic tagging of the text.Algorithm1: Topic identification algorithm FIFA3.
ExperimentTo test the efficiency of the FIFA-based textautomatic classification, and according to thepre-determined 10 topics we constructed a testcorpus, which includes 1000 articles downloadedfrom the Internet.
The composing of the testcorpus is described as following:Topic (abbreviation) Number of articlesSex (SEX) 100Sex Healthy (SHE) 100Fa Lun Gong (FLG) 100Critical of Fa Lun Gong (CFLG) 100Physical (PHY) 100Military affairs (MIA) 100Finance and economics (FAE) 100Education (EDU) 100Entertainment (ENT) 100Computer (COM) 100Total 1000Table 2 The composing of the test corpusExperiment 1: By classifying the test corpus, wecould value the effect of the FIFA-based textautomatic classification.
The following figure 2shows the results of text classification.
Line ?represents precision percent while line ?represents recall percent.SUHFLVLRQ         UHFDOO         6(; 6+( )/* &)/* 3+< 0,$ )$( ('8 (17 &20Figure 2 The results of FIFA-based text classification4.
ConclusionThis paper presented a simple and effectiveapproach to topic automatic identification.
Weuse the topic identification approach for the taskof text classification.
The results of experimentshow that a good precise and recall percent areachieved.
In fact the topic identification approachcalled FIFA could be used not only as astand-alone topic identification unit, but also inother text processing tasks such as textsummarization, information retrieval, informationrouting etc.ReferencesSalton.G(1989), Automatic Text Processing : TheTransformation : Analysis and Retrieval ofInformation by Computer, Addison-Wesley,Reading, MassJohn M.Picrrc(2001), On the automatedclassification of web sites, Linkoping ElectronicArticles in Computer and Information Science,Vol.6, 2001, Sweden,Thomas Bayer, Ingrid Renz,Michael Stein, UlrichKressel(1996), Domain and languageindependent feature extraction for statistical textcategorization, proceedings of workshop onlanguage engineering for document analysis andrecognition - ed.
by L. Evett and T. Rose, part ofthe AISB 1996 Workshop Series, April 96,Sussex University, England, 21-32 (ISBN 0 905488628)Antal van den Bosch, Walter Daelemans, TonWeijters(1996), Morphological analysis asclassification: an inductive-learning approach,Proceedings of NEMLAP-2, 2, July, 1996Manuel de Buenaga Rodriguez, Jose MariaGomez-llidalgo, Belen Diaz-agudo(1997), UsingWORDNET to complement training informationin text categorization, Second InternationalConference on Recent Advances in NaturalLanguage Processing, 1997Ellen Riloff and Wendy Lehnert(1994),Information Extraction as Basis forHigh-precision Text Classification, ACMTransactions on Information System, Vol12, No.3,July 1994H.P.Luhn(1957).
A statistical approach tomechanized encoding and searching of literaryinformation.
IBM Journal, p309-17, October1957H.P.Edmundson(1969).
New methods inautomatic extracting.
Journal of the ACM,16(2):264-85,1969Gerard Salton, James Allan, Chris Buckley, andAmit Singhal(1994).
Automatic analysis, themegeneration, and summarization ofmachine-readable texts.
Science, 264:1421-26,June 1994Wendy Lehnert and C. Loiselle(1989).
Anintroduction to plot unit.
In David Waltz, editor,Semantic Structures-Advances in NaturalLanguage Processing, p88-111, LawrenceErlbaum Associates, Hillsdale, New Jersey, 1989Lin Hongfei(2000), Logic Model for Chinese TextFiltering, Ph.D dissertation, NortheasternUniversity, 2000.3Elizabeth D. Liddy and Sung H. Myaeng(1992).DR-LINK?s linguistic- conceptual approach todocument detection.
In Proceedings of the FirstText Retrieval Conferece (TREC-1), p113-29,1992Marti A. Hearst(1994).
Context and Structure inAutomated Full-Text Information Access.
PhDthesis, Computer Science Division, University ofCalifornia at Berkeley, California, April 1994
