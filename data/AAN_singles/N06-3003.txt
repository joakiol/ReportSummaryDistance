Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 219?222,New York, June 2006. c?2006 Association for Computational LinguisticsCan the Internet help improve Machine Translation?Ariadna Font Llitj?sLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA, 15213.
USAaria@cs.cmu.eduAbstractThis paper summarizes a largely automatedmethod that uses online post-editing feed-back to automatically improve translationrules.
As a starting point, bilingual speak-ers?
local fixes are collected through anonline Translation Correction Tool.
Next,the Rule Refinement Module attacks theproblem at its core and uses the local fixesto detect incorrect rules that need to be re-fined.
Once the grammar and lexicon havebeen refined, the Machine Translation sys-tem not only produces the correct transla-tion as fixed by the bilingual speaker, but isalso able to generalize and correctly trans-lates similar sentences.
Thus, this workconstitutes a novel approach to improvingtranslation quality.
Enhanced by the reach-ing power of the Internet, our approach be-comes even more relevant to address theproblem of how to automatically improvethe quality of Machine Translation output.1 IntroductionAchieving high translation quality remains the big-gest challenge Machine Translation (MT) systemscurrently face.
Researchers have explored a varietyof methods to include user feedback in the MTloop.
Similar to our approach, Phaholphinyo andcolleagues (2005) proposed adding post-editingrules to their English-Thai MT system with the useof a post-editing tool.
However, they use contextsensitive pattern-matching rules, which make itimpossible to fix errors involving missing words.Unlike our approach, in their system, the rules arecreated by experienced linguists and their approachrequires a large corpus.
They mention an experi-ment with 6,000 bilingual sentences but report noresults due to data sparseness.In general, most MT systems have failed to in-corporate post-editing efforts beyond the additionof corrected translations to the parallel trainingdata for SMT and EBMT or to a translation mem-ory database.1 Therefore, a largely automatedmethod that uses online post-editing information toautomatically improve translation rules constitutesa great advance in the field.If an MT-produced translation is incorrect, a bi-lingual speaker can diagnose the presence of anerror reliably using the online Translation Correc-tion Tool (Font Llitj?s and Carbonell, 2004).
Anexample of an English-Spanish sentence pair gen-erated by our MT system is ?Gaud?
was a greatartist - Gaud?
era un artista grande?.
Using theonline tool, bilingual speakers modified the incor-rect translation to obtain a correct one: ?Gaud?
eraun gran artista?.Bilingual speakers, however, cannot be expectedto diagnose which complex translation rules pro-duced the error, and even less, determine how toimprove those rules.
One of the main goals of thisresearch is to automate the Rule Refinement proc-ess based on just error-locus and possibly someerror-type information from the bilingual speaker,relying on rule blame assignment and on regres-sion testing to evaluate and measure the conse-quent improvement in MT accuracy.
In this case,our Automatic Rule Refinement system can addthe missing sense to the lexicon (great?gran) as1 For a more detailed discussion, see Font Llitj?s and colleagues (2005a)219well as the special case rule for Spanish pre-nominal adjectives to the grammar.With this system in place, we envision a modi-fied version of the Translation Correction Tool as agame with a purpose, available online through amajor web portal.
This would allow bilingualspeakers to correct MT input and get rewards formaking good corrections, and compare their scoresand speed with other users.
For the MT communitythis means having a free and easy way to get MToutput feedback and potentially improve their sys-tems based on such feedback.
Furthermore, a fullyinteractive system would be a great opportunity toshow users that their corrections have a visible im-pact on technology, since they would see the ef-fects their corrections have on other sentences.Last but not least, this new method is also expectedto be particularly useful in resource-poor scenarios,such as the ones the Avenue project is devoted to(Font Llitj?s et al, 2005b), where statistical sys-tems are not an option and where there might be noexperts with knowledge of the resource-poor lan-guage (Figure 1).Figure 1.
Simplified Avenue Architecture2 Online Elicitation of MT ErrorsThe main challenge of the error elicitation part ofthis work is how to elicit minimal post-editing in-formation from non-expert bilingual speakers.
TheTranslation Correction Tool (TCTool) is a user-friendly online tool that allows users to add, deleteand modify words and alignments, as well as todrag words around to change word order.
A set ofuser studies was conducted to discover the rightamount of error information that bilingual speakerscan detect reliably when using the TCTool.
Thesestudies showed that simple error information canbe elicited much more reliably (F1 0.89) than errortype information (F1 0.72) (Font Llitj?s and Car-bonell, 2004).
Most importantly, it became appar-ent that for our Rule Refinement purposes, the listof correction action(s) with information about errorand correction words is sufficient.Building on the example introduced above, Fig-ure 2 shows the initial state of the TCTool, oncethe user has decided that the translation producedby the MT system is not correct.Figure 2.
TCTool snapshot with initial translation pairIn this case, the bilingual speaker changed?grande?
to ?gran?
and dragged ?gran(de)?
in frontof ?artista?, effectively flipping the order of thesetwo words.
Figure 3 shows the state of the TCToolafter the user corrections.Figure 3.
TCTool snapshot after user has corrected thetranslation3 Extracting Error InformationUser correction actions are registered into a logfile.
The Automatic Rule Refinement (RR) moduleextracts all the relevant information from theLearningModuleLearnedTr.
RulesLexicalResourcesTransferSystemDecoderOnlineTranslationCorrectionToolWord-AlignedParallelCorpusElicitationRuleLearningRun-TimeSystemRule RefinementRuleRefinementModuleElicitationToolElicitationCorpusManualRulesINPUTOUTPUT220TCTool log files and stores it into a CorrectionInstance.
See Figure 4 for an example.SL: Gaud?
was a great artistTL: Gaud?
era un artista grandeAL: ((1,1),(2,2),(3,3),(4,5),(5,4))Action 1: edit (grande?
gran)Temp CTL: Gaudi era un artista granAction 2: change word order(gran artista)CTL: Gaud?
era un gran artistaAL: ((1,1),(2,2),(3,3),(4,4),(5,5))Figure 4.
A Correction Instance stores the source lan-guage sentence (SL), the target language sentence (TL)and the initial alignments (AL), as well as all the correc-tion actions done by the user.
It also provides the cor-rected translation (CTL) and final alignments.The Rule Refinement (RR) module processesone action at a time.
So in this approach, the orderin which users correct a sentence does have an im-pact on the order in which refinements apply.4 Lexical RefinementsAfter having stored all the relevant informationfrom the log file, the Rule Refinement modulestarts processing the Correction Instance.
In theexample above, it first goes into the lexicon and,after double checking that there is no lexical entryfor [great?gran], it proceeds to add one by dupli-cating the lexical entry for [great?grande].
Sincethese two lexical entries are identical at the featurelevel, the RR module postulates a new binary fea-ture, say feat12, which serves the purpose of distin-guishing between two words that are otherwiseidentical (according to our lexicon):2 A more mnemonic name for feat1 would be pre-nominal.5 Rule RefinementsNow the RR module moves on to process the nextaction in the Correction Instance and the first stepis to look at the parse trace output by the MT sys-tem, so that the grammar rule responsible for theerror can be identified:At this point, the system extracts the relevantrule (NP,8) from the grammar, and has two op-tions, either to make the required changes directlyonto the original rule (REFINE) or to make a copyof the original rule and modify the copy (BIFUR-CATE).
If the system has correctly applied the rulein the past (perhaps because users have evaluatedthe translation pair ?She saw a dangerous man ?Ella vio un hombre peligroso?
as correct), then theRR module opts for the BIFURCATE operation.
Inthis case, the RR module makes a copy of theoriginal rule (NP,8) and then modifies the copy(NP,8?)
by flipping the order of the noun and ad-jective constituents, as indicated by the user.
Thisrule needs to unify with ?gran?
but not with?grande?, and so the RR module proceeds to addthe constraint that the Spanish adjective (now y2)needs to have the feat1 with value +:These two refinements result in the MT systemgenerating the desired translation, namely ?Gaud?era un gran artista?
and not the previous incorrecttranslation.
But can the system also eliminate otherincorrect translations automatically?
In addition togenerating the correct translation, we would alsolike the RR module to produce a refined grammarthat is as tight as possible, given the data that isavailable.
Since the system already has the infor-mation that ?un artista gran?
is not a correct se-221quence in Spanish, the grammar can be further re-fined to also rule out this incorrect translation.
Thiscan be done by restricting the application of thegeneral rule (NP,8) to just post-nominal adjectives,like ?grande?, which in this example are marked inthe lexicon with (feat1 = ?
).6 Generalization powerThe difference between this approach and merepost-editing is that the resulting refinements affectnot only to the translation instance corrected by theuser, but also to other similar sentences where thesame error would manifest.
After the refinementshave been applied to the grammar in our examplesentence, a sentence like ?Irina is a great friend?will now correctly be translated as ?Irina es unagran amiga?, instead of ?Irina es una amigagrande?.7 EvaluationWe plan to evaluate the RR module on its ability toimprove coverage and overall translation quality.This requires identifying sensible evaluation met-rics.
Initial experiments have shown that bothBLEU [Papineni et al, 2001] and METEOR [La-vie et al, 2004] can automatically distinguish be-tween raw MT output and corrected MT output,even for a small set of sentences.
In addition to thepresence of the corrected translation in the latticeproduced by the refined system, our evaluationmetrics will also need to take into account whetherthe incorrect translation is now prevented frombeing generated and whether the lattice of alterna-tive translations increased or decreased.
A decreaseof lattice size would mean that the refinement alsomade the grammar tighter, which is the desiredeffect.8 Technical Challenges and Future WorkThe Rule Refinement process is not invariable.
Itdepends on the order in which refinement opera-tions are applied.
In batch mode, the RR modulecan rank Correction Instances (CI) in such a wayas to maximize translation accuracy.
Suppose thatthe first CI (CI1) triggers a bifurcation of a gram-mar rule, like the one we see in the example de-scribed in Section 5.
After that, any CI that affectsthe same rule that got bifurcated, will only modifythe original rule (NP,8) and not the copy (NP,8?
).If the constraint that enforces determiner-nounagreement were missing from the original rule,say, the copy (NP,8?)
would not have that con-straint added to it, and so another example with thepre-nominal adjective exhibiting that agreementerror would be required (CI2: *Irina es un granamiga), before the system added the relevant con-straint to NP,8?.
However, if we can detect suchrule dependencies before the refinement process,then we can try to find an optimal ranking, giventhe current set of CIs, which should result in highertranslation accuracy, as measured on a test set.Another interesting future direction is enhancingthe Rule Refinement system to allow for furtheruser interaction.
In an interactive mode, the systemcan use Active Learning to produce minimal pairsto further investigate which refinement operationsare more robust, treating the bilingual speaker asan oracle.
We hope to explore the space betweenbatch mode and a fully interactive system to dis-cover the optimal setting which allows the systemto only ask the user for further interaction when itcannot determine the appropriate refinement opera-tion or when it would be impossible to correctlyrefine the grammar and the lexicon automatically.ReferencesAlon Lavie, Kenji Sagae and Shyamsundar Jayaraman.2004.
The Significance of Recall in Automatic Met-rics for MT Evaluation.
AMTA, Washington, DC.Ariadna Font Llitj?s, Jaime Carbonell and Alon Lavie.2005a.
A Framework for Interactive and AutomaticRefinement of Transfer-based Machine Translation.EAMT, Budapest, Hungary.Ariadna Font Llitj?s, Roberto Aranovich and Lori Levin2005b.
Building Machine translation systems for in-digenous languages.
Second Conference on the In-digenous Languages of Latin America (CILLA II),Texas, USA.Ariadna Font Llitj?s and Jaime Carbonell.
2004.
TheTranslation Correction Tool: English-Spanish userstudies.
LREC 04, Lisbon, Portugal.Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu.
2001.
BLEU: A Method for AutomaticEvaluation of Machine Translation.
IBM ResearchReport RC22176 (W0109-022).Sitthaa Phaholphinyo, Teerapong Modhiran, NattapolKritsuthikul and Thepchai Supnithi.
2005.
A Practi-cal of Memory-based Approach for Improving Accu-racy of MT.
MT Summit X. Phuket Island, Thailand.222
