BBN's PLUM Probabilistic Language Understanding SystemThe PLUM System Group*BBN Systems and Technologies70 Fawcett  StreetCambridge, MA 02138weischedel @bbn.com1.
APPROACHTraditional approaches to the problem of extracting datafrom texts have emphasized hand-crafted linguisticknowledge.
In contrast, BBN's PLUM system(Probabilistic Language Understanding Model) wasdeveloped as part of an ARPA-funded research effort onintegrating probabilistic language models with moretraditional inguistic techniques.
Our research anddevelopment goals are:?
Achieving high performance in objective valuations,such as the Tipster evaluations.?
Reducing human effort in porting the naturallanguage algorithms to new domains and to newlanguages.?
Providing technology that is scalable to realisticapplications.We began this research agenda pproximately three yearsago.
During the past two years, we have ported our dataextraction system (PLUM) to a new language (Japanese)and to two new domains.2.
KEY SYSTEM FEATURESThree key design features distinguish PLUM from otherapproaches: statistical anguage modeling, learningalgorithms and partial understanding.
The first key featureis the use of statistical modeling to guide processing.
Forthe version of PLUM used in MUC-5, part of speechinformation was determined by using well-known Markovmodeling techniques embodied in BBN's part-of-speechtagger POST \[5\].
We also used a correction model, AMED\[3\], for improving Japanese segmentation and part-of-speech tags assigned by JUMAN.
For the microelectronicsdomain, we used a probabilistic model to help identify therole of a company in a capability (whether it is a developer,user, etc.).
Statistical modeling in PLUM contributes toportability, robustness, and trainability.algorithms.
We feel the key to portability of a dataextraction system is automating the acquisition of theknowledge bases that need to change for a particularlanguage or application.
For the MUC-5 applications weused learning algorithms to train POST, AMED, and thetemplate-filler model mentioned above.
We also used astatistical learning algorithm to learn case frames for verbsfrom examples (the algorithm and empirical results are in\[4\]).A third key feature is partial understanding, by which wemean that all components ofPLUM are designed to operateon partially interpretable input, taking advantage ofinformation when available, and not failing wheninformation is unavailable.
Neither a completegrammatical nalysis nor complete semantic interpretationis required.
The system finds the parts of the text it canunderstand and pieces together a model of the whole fromthose parts and their context.3.
PLUM SYSTEM DESCRIPTIONThe PLUM architecture is presented in Figure 3-1.
Ovalsrepresent declarative knowledge bases; rectangles representprocessing modules.
The arrows connecting the processingmodules indicate a roughly sequential processing of thesentences ofan input document through the modules.
Afterthe message reader processes the whole document, eachsentence is processed through the morphological nalyzer,concept-based pattern marcher, parser, semantic interpreter,and the anaphora resolution portion of the discourseprocessor.
After all the sentences are processed in thisfashion, final document-level discourse processing andtemplate-generation ake place.A more detailed description of the system components,their individual outputs, and their knowledge bases ispresented in Ayuso et al, \[1\].
The processing modules arebriefly described below.The second key feature is our use of learning algorithmsboth to obtain the knowledge bases used by PLUM'sprocessing modules and to train the probabilistic*Ralph Weischedel (Principal Investigator), DamarisAyuso, Sean Boisen, Heidi Fox, Tomoyoshi Matsukawa,Constantine Papageorgiou (BBN), Dawn MacLaughlin,Masaichiro Kitawa, Tsutomu Sakai (Boston University),June Abe, Hiroto Hosihi, Yoichi Miyamoto (University ofConnecticut), and Scott Miller (Northeastern U iversity)3.1 Message ReaderThis module is like the "text zoner" of Hobbs' descriptionof generic data extraction systems.
PLUM's specificationof the input format is a declarative component of themessage reader, allowing the system to be easily adapted tohandle different formats.
The input to the PLUM system isa file containing one or more messages.
The messagereader module determines message boundaries, identifiesthe message header information, and determines paragraph195and sentence boundaries.
To date, we have designedformat specifications for about half a dozen domains.3.2 Morphological AnalyzerThe first phase of sentence processing is assignment ofpart-of-speech information to the words, e.g., proper noun,verb, adjective, tc.
In BBN's part-of-speech tagger POST\[5\], a bi-gram probability model, frequency models forknown words (derived from large corpora), andprobabilities based on word endings for unknown words areemployed to assign part of speech to the highly ambiguousknown and unknown words of the corpus.
POST tags eachword with one of 47 possible tags with 97% accuracy forknown words.
For the Japanese domains, JUMAN is usedto propose word segmentation and part-of-speechassignments, which are then corrected by AMED \[3\] beforebeing handed to POST for final disambiguation.
Below arethe part-of-speech tags produced by POST for the firstsentence of the EJV walkthrough article 0592:"BRIDGESTONE SPORTS CO. SAID FRIDAY IT HASSET UP A JOINT VENTURE IN TAIWAN WITH ALOCAL CONCERN AND A JAPANESE TRADINGHOUSE TO PRODUCE GOLF CLUBS TO BE SHIPPEDTO JAPAN.
"(BRIDGESTONE NP) (SPORTS NPS) (CO. NP)(SAID VBD) (FRIDAY NP) (IT PP) (HAS VBZ)(SET UP VBN) (A DT) (JOINT VENTURE NN) (IN IN)MessageMessage ReaderI Morphological AnalyzerConcept-basedFast PalSemanticDis~\[ Template G neratorOutputFigure 3-1.
PLUM System Architecture:Rectangles represent domain-independent, language-independent algorithms; ovals represent knowledgebases.
(TAIWAN NP)(WITH IN)(A DT)(LOCAL JJ)(CONCERN NN)(AND CC)(A DT)(JAPANESE JJ)(TRADING HOUSE NN)(TO TO)(PRODUCE VB)(GOLF NN)(CLUBS NNS)(TO TO)(BE VB)(SHIPPED VBN) (TO TO) (JAPAN NP) (..)3.3 Concept-Based Pattern MarcherThe concept-based pattern matcher was developed afterMUC-4 to deal with certain grammatical forms, such ascorporation ames.
In particular, word groups that areimportant to the domain and that may be detectable withonly local lexical information can be treated here.
Theconcept-based pattern matcher applies finite-state patternsto the output of POST, which consists of word tokens withpart-of-speech information.
The patterns in addition haveaccess to lexical semantic information, which includes asemantic type (or concept) and other semantic information.When a pattern is matched, a semantic form is assigned bythe action component of the pattern to the word sequence.This assignment has two effects: the word sequence istemporarily defined in PLUM's lexicon, and the input is re-tokenized to treat he word sequence as a single unit forfurther processing.
Lexical items added by the patternactions remain active for the duration of the document'sprocessing.
In this way, subsequent sentences mayrecognize, for example, aliases of corporations identified inprevious entences.The patterns used by the concept-based pattern-matchermay be grouped by "phases", indicating multiple pattern-matching passes.
Phases following the first phase operateon the input as modified by the previous phase.
We haveused at most wo phases in our applications o far.
In bothjoint ventures and microelectronics, patterns were used togroup proper nouns into company names, organizationnames, and person names.
Continuing with the examplesentence discussed above, a pattern recognized thesequence (BRIDGESTONE NP) (SPORTS NPS) (CO. NP)as a company; the pattern's action substituted the singletoken (BRIDGESTONE SPORTS CO. CORP), withsemantics of corporation.3.4 Fast Partial Parser (FPP)The FPP is a near-deterministic parser which generates oneor more non-overlapping parse fragments panning theinput sentence, deferring any difficult decisions onattachment ambiguities.
When cases of permanent,predictable ambiguity arise, the parser finishes the analysisof the current phrase, and begins the analysis of a newphrase.
Therefore, the entities mentioned and somerelations between them are processed in every sentence,whether syntactically ill-formed, complex, novel, orstraightforward.
Furthermore, this parsing is done usingessentially domain-independent sy tactic information.FPP averages about 6 fragments for sentences as complexas in the EJV corpus; this number is inflated sincepunctuation usually results in an isolated fragment.Continuing with the same example sentence, Figure 3-2196shows nine parse fragments as generated by FPP.
TheJapanese grammar produces maller fragments by design.3.5 Semantic InterpreterThe semantic interpreter contains two sub-components: arule-based fragment interpreter and a pattern-basedsentence interpreter.
The first was used in MUC-3 andMUC-4.
The second subcomponent was added beforeMUC-5.3.5.1 Rule-based Fragment InterpreterThe rule-based fragment interpreter applies emantic rulesto each fragment produced by FPP in a bottom-up,compositional fashion.
Semantic rules are matched basedon general syntactic patterns, using wildcards and similarmechanisms to provide robustness.
A semantic rulecreates a semantic representation f the phrase as anannotation on the syntactic parse.
A semantic form includesa variable (e.g., ?13), its type, and a collection of predicatespertaining to that variable.
There are three basic types ofsemantic forms: entities in the domain, events, and states ofaffairs.
Each of these can be further categorized as known,unknown, and referential.
Entities correspond to the people,places, things, and time intervals of the domain.
These arerelated in various ways, such as through events (who didwhat to whom) and states of affairs (properties of theentities).
Entity descriptions typically arise from nounphrases; events and states of affairs are often described inclauses.The rule-based fragment interpreter ncodes defaults o thatmissing semantic information does not produce rrors, butsimply marks elements or relationships as unknown.Partial understanding is critical to text processing systems;missing data is normal.
For example, the generic predicatePP-MODIFIER is used to indicate that two entities areconnected via a certain preposition when no more specificinformation is known.
In this way, the system has a"placeholder" for the information that a certain structuralrelation holds, even though it does not know what theactual semantic relation is.
Sometimes understanding therelation more fully is of no consequence, since theinformation does not contribute to the template-filling task.The information is maintained, however, so that laterexpectation-driven processing can use it if necessary.In Figure 3-3 we show the semantic representation that isbuilt by the rule-based semantic interpreter for the phrase"THE JOINT VENTURE, BRIDGESTONE SPORTSTAIWAN CO., CAPITALIZED AT 20 MILLION NEWTAIWAN DOLLARS" in EJV walkthrough article 0592(this phrase is parsed within a single fragment by FPP).Notice that the JOINT-VENTURE is linked to theOWNERSHIP information via an unknown role, becausethe interpreter was unable to determine a specificrelationship between the NP "THE JOINT VENTURE,BRIDGESTONE SPORTS TAIWAN CO.," and theparticipial modifier "CAPITALIZED AT ..." The discoursecomponent will further efine the relationship betweenthese two semantic objects to the JV-OWNERSHIP-OFrelation.FI: "BRIDGESTONE SPORTS CO. SAID FRIDAY ITHAS SET UP A JOINT VENTURE"(S (NP (N (NAME "BRIDGESTONE SPORTS CO.")))(VP (AUX)(VP (V "SAID")(NP (MONTH "FRIDAY"))(s(S (NP (PRO-DET-SPEC "IT"))(VP (AUX (V "HAS"))(VP (V "SET UP")(NP (DETERMINER "A")(N "JOINT VENTURE")))))))))F2: "IN TAIWAN"(PP (PREP "IN")(NP (N (NAME "TAIWAN"))))F3: "WITH A LOCAL CONCERN"(PP (PREP "WITH")(NP (DETERMINER "A")(ADJP (ADJ "LOCAL"))(N "CONCERN")))F4: "AND"(CONJ "AND")F5: "A JAPANESE TRADING HOUSE"(NP (DETERMINER "A")(ADJP (ADJ "JAPANESE"))(N "TRADING HOUSE"))F6: "TO PRODUCE GOLF CLUBS"(VP (AUX (TO "TO"))(VP (V "PRODUCE")(NP (N "GOLF") (N "CLUBS"))))F7: "TO"(PREP "TO")F8: "BE SHIPPED TO JAPAN"(VP (AUX (V "BE"))(VP (V "SHIPPED")(PP (PREP "TO")(NP (N (NAME "JAPAN"))))))F9: ".
"(PUNCT ".
")Figure 3-2.
Parser Output: Partial parse found for theexample sentence.197An important consequence of the fragmentation producedby FPP is that top-level constituents are typically moreshallow and less varied than full sentence parses.
As aresult, a fairly high level of semantics coverage can beobtained quite quickly when the system is moved to a newdomain.
This would not be possible if the semantic ruleswere required to cover a wider variety of syntacticstructures before it could achieve reasonable performance.In this way, semantic overage can be added gradually,while the rest of the system is progressing in parallel.3.5.2 Pattern-based Sentence InterpreterThe second sub-component of the semantic interpretermodule is a pattern-based sentence interpreter whichapplies semantic pattern-action rules to the semantics ofeach fragment of the sentence.
This replaced the fragmentcombining component used in MUC-4.
The semanticpattern-matching component employs the same core engineas the concept-based pattern matcher.
These semantic rulescan add additional long-distance r lations between semanticentities in different fragments within a sentence.
Thepatterns used by the sentence-level interpreter may be interms of individual words, semantic structures, and/orsyntactic structures.
Unlike the fragment-combinationmodule used in MUC-4, the rules used in this module neednot be tailored to expected fragmentation by the parser.The rules may simply look for parsed phrases with certainsemantic haracteristics, ignoring whether such a phrase isalone in a fragment or is a part of a larger fragment.
Forexample, in the English joint-venture domain, we havedefined a rule which looks for possibly multiple instancesof \[<PERCENTAGE> "by" <ENTITY>\].
This rule'saction creates an OWNERSHIP semantic form, where<ENTITY> is related via the OWNERSHIP-ENTITY roleand <PERCENTAGE> via the OWNERSHIP-% role.
Inthe walkthrough, this rule matches in the sentence "THENEW COMPANY .
.
.
.
.
IS OWNED 75 PCT BYBRIDGESTONE SPORTS, 15 PCT BY UNIONPRECISION ...".and has much less coverage.
Lexical semantic entriesindicate the word's semantic type (a domain modelconcept), as well as predicates pertaining to it.
For example,here is the lexical semantics for the noun collocation "jointventure".
(defnoun "joint venture"(JOINT-VENTURE(:CASE(("with" "between") ENTITY PARENT-OF)("for" ACTIVITY ACTIVITY-OF))))This entry indicates that the semantic type is JOINT-VENTURE, and that a "with" or "between" PP argumentwhose type is ENTITY should be given the role PARENT-OF, and a "for" PP argument of type ACTIVITY should begiven the role ACTIVITY-OF.We used an automatic ase frame induction procedure toconstruct an initial version of the lexicon \[4\].
Word sensesin the semantic lexicon have probability assignments.
ForMUC-5 probabilities were (automatically) assigned so thateach word sense is more probable than the next sense, asentered in the lexicon.3.6 Discourse ProcessingPLUM's discourse component \[2\] performs the operationsnecessary to create a meaning for the whole message fromthe meaning of each sentence.
The message levelrepresentation is a list of discourse domain objects (DDOs)for the events of interest in the message (e.g., JOINT-VENTURE events in the joint-venture domain,CAPABILITY events in the microelectronics domain orENTITIES in both domains).
The semantic representationof a sentence only includes information contained within it;in creating a DDO, the discourse module must infer otherlong-distance or indirect relations not explicitly found bythe semantic interpreter, and resolve any references in thetext.3.5.3 Lexical SemanticsThe semantic lexicon is separate from the parser's lexiconEvent: JOINT-VENTUREJOINT-VENTURE-CO-OF:Unknown-role:The discourse component creates and maintains twoprimary structures: a discourse predicate database and theDDOs.
The database is a propositional database supportingEntity: CORPORATIONNAME-OF: "Bddgestone Sports Taiwan Co."Entity: OWNERSHIP ~'~kOWNERSHIP-CAPITAI~IZATION:Entity: MONETARY-AMOUNTUNIT: "TWD"SCALAR: 20000000Figure 3-3.
Semantic Structure: The semantic representation for the first fragment inFigure 3-2.198unification, and contains all the predicates mentioned in thesemantic representation f the message.
When referencesare resolved, corresponding semantic variables are unified.Other inferences may also be added to the database.For each sentence, the discourse component processes eachsemantic form produced by the interpreter, adding itsinformation to the predicate database and performingreference resolution for pronouns and anaphoric definiteNPs.
Set- and member-type r ferences may be treated.When a semantic form for an event of interest isencountered, an initial DDO is generated, and any slotsalready found by the interpreter are filled in.
The discourseprocessor then tries to merge the new DDO with a previousDDO, in order to account for the possibility that the newDDO might be a repeated reference to an earlier one.This merging of discourse domain objects is itself a form ofreference resolution.
To check compatibility of objectsbefore allowing merging to take place, this procedure usesthe same tests used for reference resolution.
In addition,other parameters are also used which may, for example,limit the distance allowed between objects considered formerging.Once all the sentences have been processed through DDOcreation and merging, heuristic rules are applied to fill anyempty DDO slots by looking at the text surrounding theforms that triggered a given DDO.
Each slot filler found inthe text is assigned a confidence score based on distancefrom its trigger.
Fillers found nearby are of highconfidence, while those farther away receive worse scores.Low numbers represent high confidence; high numbers lowconfidence; thus 0 is the "highest" confidence score, usedmainly for fillers obtained from predicates asserted in thesemantic representation.Following is the DDO for the first JOINT-VENTURE inEJV walkthrough article 0592:DDO: JOINT-VENTURETrigger fragments:"BRIDGESTONE SPORTS CO. SAID FRIDAY IT HASSET UP A JOINT VENTURE""THE JOINT VENTURE; BRIDGESTONE SPORTSTAIWAN CO., CAPITALIZED AT 20 MILLION NEWTAIWAN DOLLARS, WILL START PRODUCTION INJANUARY 1990""THE NEW COMPANY, BASED IN KAOHSIUNG,SOUTHERN TAIWAN, IS OWNED" "CASTING CO. OFTAIWAN"JOINT-VENTURE-CO-OF:"BRIDGESTONE SPORTS TAIWAN CO." (score = 0)JV-PARENT-OF:"BRIDGESTONE SPORTS CO." (score = 0)"A LOCAL CONCERN" (score = 2)"A JAPANESE TFtADING HOUSE" (score = 2)"GOLF CLUBS" (score = 2)"TAGA CO" (score = 2)JV-ACTIVITY-OF:"START PRODUCTION" (score = 1)"PRODUCE GOLF CLUBS" (score = 2)"BE SHIPPED TO JAPAN" (score = 2)"WITH PRODUCTION OF 20,000 IRON'' (score = 2)JV-OWNERSHIP-OF:"CAPITALIZED AT 20 MILLION NEW TAIWANDOLLARS" (score =0)Each trigger fragment contains one or more semanticcomponents which triggered this DDO.
Whefi a DDO hasmultiple trigger fragments it indicates coreference ormerging took place.
In this example, a "joint venture" inthe first fragment co-refers with "the joint venture" in thesecond fragment.
A score of 0 indicates the filler wasfound directly by the semantics; 1that it was found in thesame fragment as a trigger form; and 2 in the samesentence.3.7 Template GenerationThe template generator takes the DDOs produced bydiscourse processing and fills out the application-specifictemplates.
Clearly, much of this process is governed by thespecific requirements of the application, considerationswhich have little to do with linguistic processing.
Thetemplate generator must address any arbitrary constraints,as well as deal with the basic details of formatting.The template generator uses a combination of data-drivenand expectation-driven strategies.
First the DDOs found bythe discourse module are used to produce template objects.Next, the slots in those objects are filled using informationin the DDO, the discourse predicate database, or othersources of information such as the message header (e.g.,document number, document source, and date information),statistical models of slot filling (e.g., as in themicroelectronics domain to choose among the slots:purchaser/user, developer, distributor, and manufacturer),or from heuristics (e.g., the status of an equipment object ismost likely to be IN_USE, or the status of a joint ventureobject is most likely to be EXISTING).3.8 Parameters in PLUMMany aspects of PLUM's behavior can be controlled bysimply varying the values of system parameters.
Forexample, PLUM has parameters to control aspects oftagging, parsing, pattern matching, event merging and slotfilling by discourse, and template filling.
An important goalhas been to make our system as "parameterizable" aspossible, so that the same software can meet differentdemands for recall, precision, and overgeneration.3.9 Hardware/Software requirementsThe PLUM system is implemented in CommonLisp.
Wehave been developing the system on Sun Spare stations aswell as on SGI machines.
By running the PLUM system onthe TIPSTER 24-month data set on a SunSparcl0 with199128M memory, we gathered the following timinginformation.Minutes/ Bytes/Application message minuteEJV 0.49 3,766EME 0.72 3,416JJV 2.35 420JME 2.43 564Table 3-1.
Runtime Performance: Current speed on adesktop workstation isgiven here; considerable speedup isfeasible, since little optimization has been pelformed todate.4.
ORIG INAL  PROJECT/SYSTEM GOALSOur original goal was to apply a new, unproven approach tothe text understanding problem.
Our new approach was toemploy probabilistic models and learning algorithms withtraditional sources of linguistic knowledge (e.g., part ofspeech for words, grammars, semantic preferences, anddiscourse constraints) to data extraction from text.
Wepostulated that that would result in?
Achieving high performance in objective valuations,such as the Tipster evaluations.?
Reducing human effort in porting the naturallanguage algorithms to new domains and to newlanguages.?
Providing technology that is scalable to realisticapplications.We believe that our results, as summarized in Sections 6and 7, represent achieving a significant milestone towardthese goals, and that further esearch and development willprovide further advances in the state of the art.5.
EVOLUTION OF  SYSTEM OVER 2YEARSWe began our research agenda pproximately three yearsago.
During the past two years, we have focused much ofour effort on techniques to facilitate porting our dataextraction system (PLUM) to new languages (Japanese)and to two new domains (joint ventures andmicroelectronics).
We have also concentrated oninfrastructure development, including the addition of thetwo pattern matching components as well as an object-oriented template generator.First, consider the evolution in the runtime version ofPLUM, as illustrated in Figure 3-1 can be summarized asfollows:Message reader -- Prior to this contract, the messagereader was code that had to be modified for eachapplication domain.
The change was to make thecode domain independent and language independent,driven by a declarative knowledge base which ismodifiable for the peculiarities of a given class oftext.?
Concept-based pattern matcher -- This is a newmodule, which processes finite state grammars ofexpressions that can be reliably recognized upfront.
Itcovers organization ames, person names, and otheritems which could be defined in the context-freegrammar, but which are so simple in structure that afinite state grammar is sufficient.?
Semantic interpreter -- Coverage of the semanticinterpreter was extended in two ways- The number of domain-independent rules wasincreased greatly, particularly for English- A phrase-based pattern matcher replaced a"fragment combining" component to robustly capturethe semantics of phrases that are not parsed in a singlefragment.?
Discourse - Discourse processing was improved andgeneralized to more accurately determine whethertwo text descriptions actually discussed the samething or same event.?
Template generator -- A new template generationcomponent was written to separate domain-independent code from domain-dependent details, tosupport output of object-oriented data.Several new algorithms were added to automate the portingprocess, rather than being part of the runtime version ofPLUM.
These included:?
A component to automatically earn to classify text(paragraphs) asrelevant or irrelevant, given examplesof both types of text.?
A simple technique for rapidly defining jargon words.?
A technique for hypothesizing semantically relatedwords from relatively small volumes of text, e.g.,from as few as 1,000 articles.6.
ACCOMPL ISHMENTS6.1 Dealing With Mult iple Languages AndMultiple DomainsAny system that participated in more than one domain inMUC-5 and/or in more than one language has demonstrateddomain independence and language independence.
InPLUM, the text zoner, morphological processing, parsing,and semantic interpretation employ language-independentand domain-independent algorithms driven by data(knowledge) bases.
Similarly, the discourse algorithms andtemplate generation algorithms are domain- and language-independent, and are driven by knowledge that ispredominantly declarative.The issue (or the goal)that all systems must addressfurther is greater automation of the porting process.Our approach as been to rely on probabilistic learning200algorithms.
Here we focus on some surprises in dealingwith multiple languages and multiple domains.6.1.1 Dealing With Multiple DomainsPorting PLUM to a new domain, even in multiplelanguages, takes much less effort as a result of the last twoyears of work.
Table 1 shows the labor expended in portingPLUM to the microelectronics domain.
In 52 person-days,PLUM was processing microelectronics articles in bothEnglish and Japanese, obtaining reasonable performance.Had we run PLUM at that time on the TIPS3 test sets,scores would already have been impressive in English (anERR of 74).
For Japanese, performance was 73 on test setTIPS2.
(We quote the score for TIPS2, because it coveredonly the capabilities for which there was data at the time ofthe TIPS2 version of PLUM.
)When the proposal for this effort was submitted, we made aconservative assumption that all probability models wouldneed to be re-estimated for each domain.
During this effort,it became clear that, though one could re-estimateprobabilities for each domain, that it was not necessary.Performance of the overall data extraction system could beadequate without domain-specific training.
In fact, inmoving to microelectronics, no domain-specific linguistictraining was used; however, the performance inmicroelectronics was quite close to that in joint ventures,where domain-specific training was used.
See Figure 7-1Tasks Person-DavsLanguage-independent 14English 19Japanese 1.__9TOTAL 52Table 6-1: Effort to Port to MicroelectronicsPorting the PLUM system to a new domain involvesdeveloping the domain-dependent knowledge bases,primarily the domain model, event rules, and applicationconstraints of Figure 1.
To the degree that jargon is used inthe domain, the lexicon and patterns will be updated.
Wehave generally proceeded by first building a text-to-response system with small domain coverage.
In ourexperience, this base system can be built in about a week.Once this base system exists, development of knowledgebases can proceed in parallel.In order to build the basic text-to-response ystem, thefollowing tasks must be performed (not necessarilysequentially).?
The format description for the input texts must bespecified; this enables the system to digest the textthat is to be processed.?
The domain model (concepts and roles) is defined.The domain model can be defined based on the outputtemplate specification.?
An initial lexicon of important words is created.
Here,we utilize a tool that assists the domain developer inclassifying words (collected from a text corpus andsorted by frequency) into a small number of semanticclasses.
This tool allows the domain developer toquickly create a lexicon with semantic typeinformation.
The lexicon is subsequently reviewed byhand, and case frame information is added.?
An initial set of event rules is defined.?
The output emplate objects are defined.Optionally, the POST part-of-speech tagger may beretrained on the new corpus.
Note that we did not retrainPOST in porting to the microelectronics domain, as wefound the frequency models that were derived fromdomain-independent training were adequate.It is also helpful to identify a key set of example sentencesthat the system should cover.
These sentences can be usedto drive initial development, aswell as to track progress.Once these tasks have been completed, it should be possibleto process a text in the new domain and get some limitedamount of output.
The key to this achievement is thedefault reasoning that is part of the PLUM system.
Forexample, default semantic, discourse, and template fillingrules will be utilized where no domain-specific informationis available.After the initial system is created, the knowledge bases canbe refined in parallel to achieve greater coverage.
Analysistools, such as a scoring program, can be used to identifyand focus on areas in need of development.6.1.2 Porting to Multiple LanguagesAnnotating data for PLUM's probabilistic model of a newlanguage, even with little language-specific resources,proved easier than anticipated.
The only resource availableto us at the start was the JUMAN system from KyotoUniversity, which hypothesizes word segmentation a d partof speech for Japanese text.
Our Japanese speakers wereable to annotate part of speech and word boundaries atabout 1,000 words per hour, and were able to annotatesyntactic structure at about 750 words per hour.
Initialannotation and testing were performed using only 16,000words plus the JUMAN lexicon; therefore, the initial portto Japanese required only about a person-week ofannotation effort.One algorithm change was made in the port to Japanese.The change was not required; the algorithms are languageindependent; however, by introducing an existing Japanesealgorithm much labor was saved in processing Japanesetext, where neither spaces nor any other delimiters mark thebeginning and end of words.
We had at our disposal thefollowing:- A rule-based Japanese morphological processor(JUMAN) from Kyoto University.201A context-free grammar of Japanese based on part ofspeech labels distinct from those produced by JUMAN.- A probabilistic part-of-speech tagger (POST) \[Meteer,et al, 1991\] which assumed asingle sequence of words asinput.- Limited human resources for creating training data.The architecture in Figure 6-1 was chosen to minimizelabor and to maximize use of existing software.
It employsJUMAN first to provide initial word segmentation of thetext, an annotation-based algorithm second to correct bothsegmentation errors and part of speech errors in JUMANoutput, and POST third both to select among ambiguousalternative segmentations/part-of-speech assignments andalso to predict he part of speech of unknown words.JapaneseTextiAI JUMAN \[\] AM~ED I~ Segment CorrectionModelPOST I ~ Part-of-speechI ModelWord segmentswith Part ofSpeechFigure 6-1.
Japanese Morphological Processing:Though POST could be used to find word boundaries inJapanese, an existing component (JUMAN) was used tosave effort.Building lexical resources for a new language or a newdomain took only a few person days using heuristics.
InJapanese, a three step process for hypothesizing propernames reduced the labor involved.
First, we ran JUMAN +POST over the training corpus to find the sequence ofwords and their most likely part of speech in context.Then, a finite-state process with a handful of language-specific patterns was run on the result to hypothesize(previously unknown) proper nouns in the corpus.
Thepatterns were designed for high recall of names, at theexpense of low precision; we measured the effectiveness ofthe technique as 90% recall at 20% precision.
Lastly, aperson ran through the hypothesized proper names usingKWIC as a resource to quickly eliminate bad hypotheses.The resulting list of names was made available to all theparticipants in JJV.A simple manual technique also enabled fast semanticcategorization of the nouns and verbs of each domain inboth languages.
Using a KWIC index and the frequency ofeach noun and each verb in the corpus, we could defineabout 125 words per hour, placing each word intocategories uch as HUMAN, CORPORATION, OFFICER,GOVERNMENT-ORGANIZATION, etc.
The process couldgo so quickly by organizing the categories into small menusof at most 12 items, so that a person need only make simplediscriminations in any pass through a list of words.6.2 Demonstration PrototypeSince data extraction from text is a new capability, thevalue of demonstration prototypes became clear, not onlyas a medium to communicate what the capability offerspotential users and also as a trigger to ignite thoughts ofhow the technology could become a usable aid to users.We developed a single, MOTIF-based, graphical userinterface to both domains (joint ventures andmicroelectronics) and both languages, (English andJapanese), for a total of 4 applications English jointventures, Japanese joint ventures, English microelectronics,and Japanese microelectronics.
The demonstrationemphasized the perspective of a potential user of the dataextraction technology.
A message was selected andprocessed by the PLUM system, and the output wasdisplayed in the form of a table summarizing theinformation extracted by the system.
In the amount of timethat it would take a user to quickly read through an article,the PLUM system can process it and present its results.
Theuser can then browse through the specific template objectsand make any changes or corrections that are necessary.The system also serves as an aide for the analyst'scorrection task.
PLUM graphically displays its confidencein particular pieces of information in the output so theanalyst can choose to focus on verifying information thatPLUM is not highly confident in.
Furthermore, by clickingon a piece of information in the template, the analyst cansee where in the text the information came from.
Figure 6-2 shows the contents of the screen after the user has clickedon the slot fill "a company in Japan": the fragmentcontaining the phrase which gave rise to the filler, "theJapanese group", is highlighted in the text.When editing template fill values, the analyst can mark andcopy text in the article.
The system automatically"normalizes" the new value.
For example, the analystmight add or correct a company's location by highlighting astring in the text.
The system then normalizes the text intothe gazetteer-style format required by the domain.
Thesystem also displays alternate values that it had consideredbut rejected for some reason.
Figure 6-3 shows the pop-upwindow which presents the user with the entities that were202considered for a slot.
The boxes to the left of each entitydescription are used as "push-buttons": a raised buttonindicates the entity is not selected for the slot (as in the firstentry, "A company in Japan", which the user hadcorrected).
By providing this type of support, the analystcan concentrate more on what information should be in thetemplate, not what the particular format of the template fillsneeds to be.6.3 Results  in Probabi l is t ic /LearningAlgor i thms6.3.1 MorphologyOur POST part-of-speech tagger (Meteer, Schwartz, andWeischedel 1991) uses a stochastic bi-gram model to assignsyntactic ategories to words in unrestricted text, even ifthey are unknown.
BBN was the first to successfully useseveral new techniques inpart-of-speech analysis:In addition to its use in several PLUM applications, POSThas now been distributed to over ten research anddevelopment si es.In the last two years, it was modified to deal withambiguous cases of word boundaries.
Also, a more optimalversion was written, achieving speedup by a factor of 80.6.3.2 Acquiring Word Association InformationBBN has recently developed a technique for semi-automatically earning word and word group associations\[Matsukawa, 1993\].
Unlike some other approaches basedon mutual information between words, this techniqueestimates the likely association between groups of words, akind of conceptual c ustering.
These word groups can eitherbe automatically generated by a hill-climbing algorithm, orproduced by manual classification (in the case of nouns, asimple and rapid classification at the rate of 500 words perhour proved to be adequate).
By using words grouped intoconcept classes, even low-frequency data can beconsidered.6.3.3 Automatic Error CorrectionThe traditional approach to word segmentation a d part-of-speech labelling in Japanese is the use of rule-basedmorphological nalyzers employing a hand-crafted lexiconand a hand-crafted connectivity matrix.
BBN's AMEDmodule \[Matsukawa, Miller, and Weischedel, 1993\] is anexample-based correction technique for segmentation a dpart-of-speech labelling, which uses annotated text assupervised training.
AMED is able to cover cases thatoccur infrequently by generalizing during training.
UsingAMED together with POST improved the accuracy of part-of-speech labelling without requiring revision to theexisting morphological nalyzer (JUMAN).6.3.4 First Application of Statistical Text Classifier toData Extraction from TextFor MUC-4, we demonstrated the first technique forsignificantly varying the trade-off between recall andprecision (Weischedel et al 1992).
This used anautomatically-trained t xt classifier that predicted whetherparagraphs of text were relevant to the data extraction task,based on a probabilistic model using words as features.This gives the user the capability of tuning systemperformance to favor either ecall or precision, by varyingthe threshold on the classifier.203Select Message !Analyze\[\[Find Entities \[Options \[QuitJPertamina would make a decision on the matter possibly in early November.The contract, if given ~.EI, Jb.Ei~.E\]Z,F.I~..I,:,IL.~,Lfz,EI~ would be the largest everJapanese plant export deal with Indonesia.The consortium consists of Jgc Corp., C. Itoh And Co., Nissho Iwai Corp. andblTemplate-I IOetails\] ~ l  ~ ~ ~li .
.
.
.
i i  .TIE-UP STATUS .
.
.
.
.
.
.
.
.
.
~ J' EXISTINGJOINT VENTURE COCCORP~LC: I~rgH AN DcO~\[NISS.HO.IW_ AI CORP~\[ FAR EAST OIL TRADING_ 1t,IIFigure 6-2.
PLUM highlights the source of the information in the text: A user can see justification of the outputinformation before editing.Name:\[Tie Up between JGC CORP, C. ITOH AND CO, NISSHO IWAI CORP, and F,e ObjectSlot Name: I ENTITYCh~ Confidence\] [Change Offsets\] \[ New Object \]~ \[A Company In JAPAN\ [ \ ]  r \[~\]~\]:g:E~Zjj\]j\[\] = \[c:aTO\ [ \]  \[\] \[NISSHO IWAI CORPJ CloseFigure 6-3.
The entities that have been considered for a slot rdl are presented to the user: A newfiUer can bequickly selected from this list, or a new one pasted in from the text.2047.
EVALUATION SUMMARYThe official scores achieved by the PLUM system in eachof the four application domains are summarized in the tablebelow.EME EJV JME JJVERR 66 68 70 72minERR 0.7485 0.7971 0.8671 0.7990maxERR 0.7822 0.8191 0.9114 0.8196UND 46 54 53 63OVG 33 28 41 27SUB 19 18 15 14REC 43 38 40 32PRE 54 59 50 63F 48.09 45.95 44.61 42.49Table 7-1.
Summary of PLUM scores on TIPS3 data.Figure %1 graphically illustrates that the PLUM systemshowed remarkable consistency on the official measureERR across both languages and both domains.
Of course,this is meaningless unless one factors in the human effortinvolved.
Figure 7-2 shows the labor invested in the fourlanguage-domain pairs: EVJ, JJV, EME, and JME.
Theeffort in each language was largely balanced.Person-Month~English Joint Venture 4-5Japanese Joint Venture 2English Microelectronics 3Japanese Microelectronics 3.5\[11 English JointVenturem Japanese JointVentureEnglishMicroeleetronics?
JapaneseMieroeleetronicsFigure 7-2.
Distribution of Effort across Domains:Effort across languages was about equal.The previous evaluation was held eighteen months into thecontract and was reported in February, 1993.
Much of theeffort in this last quarter focused on improving PLUM'sperformance in extracting data in the microelectronicsdomain.
Figures 7-3 and 7-4 graph our progress in Englishand in Japanese respectively.EJV JJV EME JMEFigure 7-1.
Performance Based on ERR: Acrosslanguage-domain pairs, there was remarkable consistencyin PLUM's performance.6050403020100Recall Precision[ \[\]18 month \] ?
24 monthFigure 7-3.
Progress in English Microelectronics:Improvement i  the English microelectronics domain fromFebruary, 1993 to August, 1993.In English, PLUM is extracting about 25% more data thansix months ago, and its overall accuracy has improvedabout 15-20%.
Performance in Japanese shows a threefoldimprovement in the amount of data extracted with about a10% improvement in accuracy.
The improvement inJapanese took that form since our focus was on coveringthe additional two microelectronics capabilities that had notbeen attempted in the February evaluation.20560 5oI4321|\[\] 18 month \]I ?
24 monthRecall PrecisionFigure 7-4.
Progress in Japanese Microelectronics:Substantial improvement in the quantity of data extracted(recall) and the quality of data extracted (precision) wasachieved from the evaluation at 18 months to 24 months.7.1 Discussion of Japanese PerformanceTraining new staff to use PLUM effectively proved easierthan anticipated.
Our team faced training new staff twomonths before the MUC-5 test, as our single Japaneseprogrammer needed to reduce his involvementsubstantially.
Starting at the beginning of June, twoJapanese computer science majors, who had just completedtheir junior year at college came to BBN.
They had notraining in computational linguistics, but had one course inartificial intelligence and one in LISP.
In June, theylearned about data extraction, the joint venture andmicroelectronics tasks, and how to use PLUM.
Since theJapanese articles on packaging and lithography had arrivedmuch later than the other data, and since we had nottouched that data, they focussed on those two capabilitiesstarting July 1.
Initially, of course, PLUM had near 100 asan ERR on sets composed primarily of thosemicroelectronics capabilities.As evident in Figure 7-5, the progress was rapid anddramatic, as the error rate dropped by 25% in all cases andby almost 50% in some cases.One consequence in the change of personnel was thatperformance in both Japanese domains had not peaked.Also, very little effort was devoted to Japanese jointventures.
Many slotw received no effort, accounting for therelatively low recall in JJV.7.2 Discussion of MetricsIn the last few months before the final evaluation, wenoticed an anomaly in the official measure ERR.
Wenoticed that some changes to the runtime version of PLUMcould reduce ERR ("error ate") by 2 points (e.g., by 5%),even though the actual number of errors made by thesystem increased.The anomaly arises because ERR is computed as# missed ata + # incorrect answers + # spurious answers# system answersTherefore, it is theoretically possible to generate morequestionable output, producing just enough correct outputto reduce ERR, even though more than 50% of theadditional output is spurious.100757065605550July July July July July July July.2 9 14 16 19 23 28Figure 7-5.
Progress in JME: For development messages involving packaging and lithography,staff with minimal training was rapid and dramatic.~rogress of new206As a consequence of the fact that the denominator f ERRis system-dependent, ERR is not ideal for cross-systemcomparisons.
Rather, min-err/max-err are better for cross-system comparison, since they normalize the number oferrors by a system-independent measure, the number ofanswers in the answer key.
Min-err/max-err a e defined as# missed ata + # incorrect answers + # spurious answers# answers in answer keySince some answers are optional, min-err and max-errdiffer in whether the optional answers are counted in thedenominator.If one uses this unofficial, system-independent measure,systems perform quite differently in at least some cases.Since we tuned PLUM, trying to jointly optimize both ERRand min-err, PLUM's performance for both Englishdomains was outstanding on both measures.8.
CONCLUSIONSSome of the lessons we learned during our work inTIPSTER include the following:?
Automatic training and acquisition of knowledgebases can yield relatively good performance atreduced labor, as evidenced, for example, by a quickport to the microelectronics domain (in 2 languages)in 2 person-months (after which further efinementswere made).
For the TIPS3 test, our total effort spenton each of the 4 domains (in person-months) was asfollows: FEJV 4.5, EME 3, JJV 2, JME 3.?
Domains dominated by jargon (sub-language) may beeasier than domains of normal vocabulary becausethere is less ambiguity and more predictability.
ForTIPSTER this means that the microelectronicsdomain was easier than joint ventures.?
Japanese was easier to process than English becauseof strong clues provided by case-markers, and a lessvaried linguistic structure in the articles.?
Availability of a large text corpus was invaluable forquick knowledge acquisition.
Less filled templatesshould still be adequate.?
Our algorithms are already largely language- anddomain-independent; an important goal remains tofurther automate the porting process.?
Finite-state pattern matching is a useful complementto linguistic processing, offering a good fall-backstrategy for addressing language constructions thatare hard to treat via general linguistically-basedapproaches.?
Continued work on discourse processing is importantto improving performance.
Reliably determiningwhen different descriptions of events or objects infact refer to the same thing remains one of the hardestproblems in data extraction.?
Improving syntactic overage is a priority.
Increasedcoverage normally leads to greater perceivedambiguity in the system; we hope to counter thisthrough the use of probabilistic models.We plan to continue our research agenda emphasizing theuse of probabilistic modeling and learning algorithms fordata extraction in order to continue improving robustnessand portability.ACKNOWLEDGMENTSThe work reported here was supported in part by theDefense Advanced Research Projects Agency and wasmonitored by the Rome Air Development Center underContract No.
F30602-91-C-0051.
The views andconclusions contained in this document are those of theauthors and should not be interpreted as necessarilyrepresenting, the official policies, either expressed orimplied, of the Defense Advanced Research ProjectsAgency or the United States Government.REFERENCES\[1\] Ayuso, D.M., Boisen, S., Fox, H., Ingria, R., andWeischedel, R. "BBN: Description of the PLUM Systemas Used for MUC-4", MUC-4 Proceedings, 1992.\[2\] Iwanska, et.al., "Computational Aspects of Discourse inthe Context of MUC-3", Proceedings ofthe Third MessageUnderstanding Conference (MUC-3), 1991.\[3\] Matsukawa, T., Miller, S., and Weischedel, R."Example-Based Correction of Word Segmentation andPart of Speech Labelling", to appear in Proceedings of theARPA Workshop on Human Language Technology, 1993.\[4\] Weischedel, R., Ayuso, D.M., Bobrow, R., Boisen, S.,Ingfia, R., and Palmucci, J., "Partial Parsing, A Report onWork in Progress", Proceedings of the Fourth ARPAWorkshop on Speech and Natural Language, 1991.\[5\] Weischedel, R., Meteer, M., Schwartz, R., Ramshaw,L., and Palmucci, J.
"Coping with Ambiguity and UnknownWords through Probabilistic Models", ComputationalLinguistics (Special Issue on Using Large Corpora: 11) 19,359-382, 1993.\[6\] Matsukawa, T., Hypothesizing Word Association fromUntagged Text", to appear in Proceedings ofthe ARPAWorkshop on Human Lnaguage Technology, 1993.207
