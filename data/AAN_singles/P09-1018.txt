Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 154?162,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPRevisiting Pivot Language Approach for Machine TranslationHua Wu and Haifeng WangToshiba (China) Research and Development Center5/F., Tower W2, Oriental Plaza, Beijing, 100738, China{wuhua, wanghaifeng}@rdc.toshiba.com.cnAbstractThis paper revisits the pivot language ap-proach for machine translation.
First,we investigate three different methodsfor pivot translation.
Then we employa hybrid method combining RBMT andSMT systems to fill up the data gapfor pivot translation, where the source-pivot and pivot-target corpora are inde-pendent.
Experimental results on spo-ken language translation show that thishybrid method significantly improves thetranslation quality, which outperforms themethod using a source-target corpus ofthe same size.
In addition, we pro-pose a system combination approach toselect better translations from those pro-duced by various pivot translation meth-ods.
This method regards system com-bination as a translation evaluation prob-lem and formalizes it with a regressionlearning model.
Experimental results in-dicate that our method achieves consistentand significant improvement over individ-ual translation outputs.1 IntroductionCurrent statistical machine translation (SMT) sys-tems rely on large parallel and monolingual train-ing corpora to produce translations of relativelyhigher quality.
Unfortunately, large quantities ofparallel data are not readily available for some lan-guages pairs, therefore limiting the potential useof current SMT systems.
In particular, for speechtranslation, the translation task often focuses on aspecific domain such as the travel domain.
It is es-pecially difficult to obtain such a domain-specificcorpus for some language pairs such as Chinese toSpanish translation.To circumvent the data bottleneck, some re-searchers have investigated to use a pivot languageapproach (Cohn and Lapata, 2007; Utiyama andIsahara, 2007; Wu and Wang 2007; Bertoldi et al,2008).
This approach introduces a third language,named the pivot language, for which there existlarge source-pivot and pivot-target bilingual cor-pora.
A pivot task was also designed for spokenlanguage translation in the evaluation campaign ofIWSLT 2008 (Paul, 2008), where English is usedas a pivot language for Chinese to Spanish trans-lation.Three different pivot strategies have been in-vestigated in the literature.
The first is basedon phrase table multiplication (Cohn and Lap-ata 2007; Wu and Wang, 2007).
It multiplescorresponding translation probabilities and lexicalweights in source-pivot and pivot-target transla-tion models to induce a new source-target phrasetable.
We name it the triangulation method.
Thesecond is the sentence translation strategy, whichfirst translates the source sentence to the pivot sen-tence, and then to the target sentence (Utiyama andIsahara, 2007; Khalilov et al, 2008).
We name itthe transfer method.
The third is to use existingmodels to build a synthetic source-target corpus,from which a source-target model can be trained(Bertoldi et al, 2008).
For example, we can ob-tain a source-pivot corpus by translating the pivotsentence in the source-pivot corpus into the targetlanguage with pivot-target translation models.
Wename it the synthetic method.The working condition with the pivot languageapproach is that the source-pivot and pivot-targetparallel corpora are independent, in the sense thatthey are not derived from the same set of sen-tences, namely independently sourced corpora.Thus, some linguistic phenomena in the source-pivot corpus will lost if they do not exist in thepivot-target corpus, and vice versa.
In order to fillup this data gap, we make use of rule-based ma-chine translation (RBMT) systems to translate thepivot sentences in the source-pivot or pivot-target154corpus into target or source sentences.
As a re-sult, we can build a synthetic multilingual corpus,which can be used to improve the translation qual-ity.
The idea of using RBMT systems to improvethe translation quality of SMT sysems has beenexplored in Hu et al (2007).
Here, we re-examinethe hybrid method to fill up the data gap for pivottranslation.Although previous studies proposed severalpivot translation methods, there are no studies tocombine different pivot methods for translationquality improvement.
In this paper, we first com-pare the individual pivot methods and then in-vestigate to improve pivot translation quality bycombining the outputs produced by different sys-tems.
We propose to regard system combinationas a translation evaluation problem.
For transla-tions from one of the systems, this method uses theoutputs from other translation systems as pseudoreferences.
A regression learning method is usedto infer a function that maps a feature vector(which measures the similarity of a translation tothe pseudo references) to a score that indicates thequality of the translation.
Scores are first gener-ated independently for each translation, then thetranslations are ranked by their respective scores.The candidate with the highest score is selectedas the final translation.
This is achieved by opti-mizing the regression learning model?s output tocorrelate against a set of training examples, wherethe source sentences are provided with several ref-erence translations, instead of manually labelingthe translations produced by various systems withquantitative assessments as described in (Albrechtand Hwa, 2007; Duh, 2008).
The advantage ofour method is that we do not need to manually la-bel the translations produced by each translationsystem, therefore enabling our method suitable fortranslation selection among any systems withoutadditional manual work.We conducted experiments for spoken languagetranslation on the pivot task in the IWSLT 2008evaluation campaign, where Chinese sentences intravel domain need to be translated into Spanish,with English as the pivot language.
Experimen-tal results show that (1) the performances of thethree pivot methods are comparable when onlySMT systems are used.
However, the triangulationmethod and the transfer method significantly out-perform the synthetic method when RBMT sys-tems are used to improve the translation qual-ity; (2) The hybrid method combining SMT andRBMT system for pivot translation greatly im-proves the translation quality.
And this translationquality is higher than that of those produced by thesystem trained with a real Chinese-Spanish cor-pus; (3) Our sentence-level translation selectionmethod consistently and significantly improvesthe translation quality over individual translationoutputs in all of our experiments.Section 2 briefly introduces the three pivottranslation methods.
Section 3 presents the hy-brid method combining SMT and RBMT sys-tems.
Section 4 describes the translation selec-tion method.
Experimental results are presentedin Section 5, followed by a discussion in Section6.
The last section draws conclusions.2 Pivot Methods for Phrase-based SMT2.1 Triangulation MethodFollowing the method described in Wu and Wang(2007), we train the source-pivot and pivot-targettranslation models using the source-pivot andpivot-target corpora, respectively.
Based on thesetwo models, we induce a source-target translationmodel, in which two important elements need tobe induced: phrase translation probability and lex-ical weight.Phrase Translation Probability We induce thephrase translation probability by assuming the in-dependence between the source and target phraseswhen given the pivot phrase.?(s?|t?)
=?p??(s?|p?)?(p?|t?)
(1)Where s?, p?
and t?
represent the phrases in the lan-guages Ls, Lp and Lt, respectively.Lexical Weight According to the method de-scribed in Koehn et al (2003), there are two im-portant elements in the lexical weight: word align-ment information a in a phrase pair (s?, t?)
and lex-ical translation probability w(s|t).Let a1 and a2 represent the word alignment in-formation inside the phrase pairs (s?, p?)
and (p?, t?
)respectively, then the alignment information inside(s?, t?)
can be obtained as shown in Eq.
(2).a = {(s, t)|?p : (s, p) ?
a1 & (p, t) ?
a2} (2)Based on the the induced word alignment in-formation, we estimate the co-occurring frequen-cies of word pairs directly from the induced phrase155pairs.
Then we estimate the lexical translationprobability as shown in Eq.
(3).w(s|t) = count(s, t)?s?
count(s?, t)(3)Where count(s, t) represents the co-occurring fre-quency of the word pair (s, t).2.2 Transfer MethodThe transfer method first translates from thesource language to the pivot language using asource-pivot model, and then from the pivot lan-guage to the target language using a pivot-targetmodel.
Given a source sentence s, we can trans-late it into n pivot sentences p1, p2, ..., pn using asource-pivot translation system.
Each pi can betranslated into m target sentences ti1, ti2, ..., tim.We rescore all the n ?
m candidates using boththe source-pivot and pivot-target translation scoresfollowing the method described in Utiyama andIsahara (2007).
If we use hfp and hpt to denote thefeatures in the source-pivot and pivot-target sys-tems, respectively, we get the optimal target trans-lation according to the following formula.t?
= argmaxtL?k=1(?spk hspk (s, p)+?ptk hptk (p, t)) (4)Where L is the number of features used in SMTsystems.
?sp and ?pt are feature weights set byperforming minimum error rate training as de-scribed in Och (2003).2.3 Synthetic MethodThere are two possible methods to obtain a source-target corpus using the source-pivot and pivot-target corpora.
One is to obtain target transla-tions for the source sentences in the source-pivotcorpus.
This can be achieved by translating thepivot sentences in source-pivot corpus to targetsentences with the pivot-target SMT system.
Theother is to obtain source translations for the tar-get sentences in the pivot-target corpus using thepivot-source SMT system.
And we can combinethese two source-target corpora to produced a fi-nal synthetic corpus.Given a pivot sentence, we can translate it inton source or target sentences.
These n translationstogether with their source or target sentences areused to create a synthetic bilingual corpus.
Thenwe build a source-target translation model usingthis corpus.3 Using RBMT Systems for PivotTranslationSince the source-pivot and pivot-target parallelcorpora are independent, the pivot sentences in thetwo corpora are distinct from each other.
Thus,some linguistic phenomena in the source-pivotcorpus will lost if they do not exist in the pivot-target corpus, and vice versa.
Here we use RBMTsystems to fill up this data gap.
For many source-target language pairs, the commercial pivot-sourceand/or pivot-target RBMT systems are availableon markets.
For example, for Chinese to Span-ish translation, English to Chinese and English toSpanish RBMT systems are available.With the RBMT systems, we can create a syn-thetic multilingual source-pivot-target corpus bytranslating the pivot sentences in the pivot-sourceor pivot-target corpus.
The source-target pairs ex-tracted from this synthetic multilingual corpus canbe used to build a source-target translation model.Another way to use the synthetic multilingual cor-pus is to add the source-pivot or pivot-target sen-tence pairs in this corpus to the training data to re-build the source-pivot or pivot-target SMT model.The rebuilt models can be applied to the triangula-tion method and the transfer method as describedin Section 2.Moreover, the RBMT systems can also be usedto enlarge the size of bilingual training data.
Sinceit is easy to obtain monolingual corpora than bilin-gual corpora, we use RBMT systems to translatethe available monolingual corpora to obtain syn-thetic bilingual corpus, which are added to thetraining data to improve the performance of SMTsystems.
Even if no monolingual corpus is avail-able, we can also use RBMT systems to translatethe sentences in the bilingual corpus to obtain al-ternative translations.
For example, we can usesource-pivot RBMT systems to provide alternativetranslations for the source sentences in the source-pivot corpus.In addition to translating training data, thesource-pivot RBMT system can be used to trans-late the test set into the pivot language, whichcan be further translated into the target languagewith the pivot-target RBMT system.
The trans-lated test set can be added to the training data tofurther improve translation quality.
The advantageof this method is that the RBMT system can pro-vide translations for sentences in the test set andcover some out-of-vocabulary words in the test set156that are uncovered by the training data.
It can alsochange the distribution of some phrase pairs andreinforce some phrase pairs relative to the test set.4 Translation SelectionWe propose a method to select the optimal trans-lation from those produced by various translationsystems.
We regard sentence-level translation se-lection as a machine translation (MT) evaluationproblem and formalize this problem with a regres-sion learning model.
For each translation, thismethod uses the outputs from other translationsystems as pseudo references.
The regression ob-jective is to infer a function that maps a featurevector (which measures the similarity of a trans-lation from one system to the pseudo references)to a score that indicates the quality of the transla-tion.
Scores are first generated independently foreach translation, then the translations are rankedby their respective scores.
The candidate with thehighest score is selected.The similar ideas have been explored in previ-ous studies.
Albrecht and Hwa (2007) proposeda method to evaluate MT outputs with pseudoreferences using support vector regression as thelearner to evaluate translations.
Duh (2008) pro-posed a ranking method to compare the transla-tions proposed by several systems.
These twomethods require quantitative quality assessmentsby human judges for the translations produced byvarious systems in the training set.
When we applysuch methods to translation selection, the relativevalues of the scores assigned by the subject sys-tems are important.
In different data conditions,the relative values of the scores assigned by thesubject systems may change.
In order to train a re-liable learner, we need to prepare a balanced train-ing set, where the translations produced by differ-ent systems under different conditions are requiredto be manually evaluated.
In extreme cases, weneed to relabel the training data to obtain betterperformance.
In this paper, we modify the methodin Albrecht and Hwa (2007) to only prepare hu-man reference translations for the training exam-ples, and then evaluate the translations producedby the subject systems against the references us-ing BLEU score (Papineni et al, 2002).
We usesmoothed sentence-level BLEU score to replacethe human assessments, where we use additivesmoothing to avoid zero BLEU scores when wecalculate the n-gram precisions.
In this case, weID Description1-4 n-gram precisions against pseudo refer-ences (1 ?
n ?
4)5-6 PER and WER7-8 precision, recall, fragmentation fromMETEOR (Lavie and Agarwal, 2007)9-12 precisions and recalls of non-consecutive bigrams with a gapsize of m (1 ?
m ?
2)13-14 longest common subsequences15-19 n-gram precision against a target cor-pus (1 ?
n ?
5)Table 1: Feature sets for regression learningcan easily retrain the learner under different con-ditions, therefore enabling our method to be ap-plied to sentence-level translation selection fromany sets of translation systems without any addi-tional human work.In regression learning, we infer a functionf that maps a multi-dimensional input vec-tor x to a continuous real value y, such thatthe error over a set of m training examples,(x1, y1), (x2, y2), ..., (xm, ym), is minimized ac-cording to a loss function.
In the context of trans-lation selection, y is assigned as the smoothedBLEU score.
The function f represents a math-ematic model of the automatic evaluation metrics.The input sentence is represented as a feature vec-tor x, which are extracted from the input sen-tence and the comparisons against the pseudo ref-erences.
We use the features as shown in Table 1.5 Experiments5.1 DataWe performed experiments on spoken languagetranslation for the pivot task of IWSLT 2008.
Thistask translates Chinese to Spanish using Englishas the pivot language.
Table 2 describes the dataused for model training in this paper, including theBTEC (Basic Travel Expression Corpus) Chinese-English (CE) corpus and the BTEC English-Spanish (ES) corpus provided by IWSLT 2008 or-ganizers, the HIT olympic CE corpus (2004-863-008)1 and the Europarl ES corpus2.
There aretwo kinds of BTEC CE corpus: BTEC CE1 and1http://www.chineseldc.org/EN/purchasing.htm2http://www.statmt.org/europarl/157Corpus Size SW TWBTEC CE1 20,000 164K 182KBTEC CE2 18,972 177K 182KHIT CE 51,791 490K 502KBTEC ES 19,972 182K 185KEuroparl ES 400,000 8,485K 8,219KTable 2: Training data.
SW and TW representsource words and target words, respectively.BTEC CE2.
BTEC CE1 was distributed for thepivot task in IWSLT 2008 while BTEC CE2 wasfor the BTEC CE task, which is parallel to theBTEC ES corpus.
For Chinese-English transla-tion, we mainly used BTEC CE1 corpus.
We usedthe BTEC CE2 corpus and the HIT Olympic cor-pus for comparison experiments only.
We used theEnglish parts of the BTEC CE1 corpus, the BTECES corpus, and the HIT Olympic corpus (if in-volved) to train a 5-gram English language model(LM) with interpolated Kneser-Ney smoothing.For English-Spanish translation, we selected 400ksentence pairs from the Europarl corpus that areclose to the English parts of both the BTEC CEcorpus and the BTEC ES corpus.
Then we builta Spanish LM by interpolating an out-of-domainLM trained on the Spanish part of this selectedcorpus with the in-domain LM trained with theBTEC corpus.For Chinese-English-Spanish translation, weused the development set (devset3) released forthe pivot task as the test set, which contains 506source sentences, with 7 reference translations inEnglish and Spanish.
To be capable of tuning pa-rameters on our systems, we created a develop-ment set of 1,000 sentences taken from the trainingsets, with 3 reference translations in both Englishand Spanish.
This development set is also used totrain the regression learning model.5.2 Systems and Evaluation MethodWe used two commercial RBMT systems in ourexperiments: System A for Chinese-English bidi-rectional translation and System B for English-Chinese and English-Spanish translation.
Forphrase-based SMT translation, we used the Mosesdecoder (Koehn et al, 2007) and its support train-ing scripts.
We ran the decoder with its defaultsettings and then used Moses?
implementation ofminimum error rate training (Och, 2003) to tunethe feature weights on the development set.To select translation among outputs producedby different pivot translation systems, we usedSVM-light (Joachins, 1999) to perform supportvector regression with the linear kernel.Translation quality was evaluated using both theBLEU score proposed by Papineni et al (2002)and also the modified BLEU (BLEU-Fix) score3used in the IWSLT 2008 evaluation campaign,where the brevity calculation is modified to useclosest reference length instead of shortest refer-ence length.5.3 Results by Using SMT SystemsWe conducted the pivot translation experimentsusing the BTEC CE1 and BTEC ES describedin Section 5.1.
We used the three methods de-scribed in Section 2 for pivot translation.
For thetransfer method, we selected the optimal transla-tions among 10?
10 candidates.
For the syntheticmethod, we used the ES translation model to trans-late the English part of the CE corpus to Spanish toconstruct a synthetic corpus.
And we also used theBTEC CE1 corpus to build a EC translation modelto translate the English part of ES corpus into Chi-nese.
Then we combined these two synthetic cor-pora to build a Chinese-Spanish translation model.In our experiments, only 1-best Chinese or Span-ish translation was used since using n-best resultsdid not greatly improve the translation quality.
Weused the method described in Section 4 to selecttranslations from the translations produced by thethree systems.
For each system, we used threedifferent alignment heuristics (grow, grow-diag,grow-diag-final4) to obtain the final alignment re-sults, and then constructed three different phrasetables.
Thus, for each system, we can get threedifferent translations for each input.
These differ-ent translations can serve as pseudo references forthe outputs of other systems.
In our case, for eachsentence, we have 6 pseudo reference translations.In addition, we found out that the grow heuristicperformed the best for all the systems.
Thus, foran individual system, we used the translation re-sults produced using the grow alignment heuristic.The translation results are shown in Table 3.ASR and CRR represent different input condi-tions, namely the result of automatic speech recog-3https://www.slc.atr.jp/Corpus/IWSLT08/eval/IWSLT08auto eval.tgz4A description of the alignment heuristics can be found athttp://www.statmt.org/jhuws/?n=FactoredTraining.TrainingParameters158Method BLEU BLEU-FixTriangulation 33.70/27.46 31.59/25.02Transfer 33.52/28.34 31.36/26.20Synthetic 34.35/27.21 32.00/26.07Combination 38.14/29.32 34.76/27.39Table 3: CRR/ASR translation results by usingSMT systemsnition and correct recognition result, respectively.Here, we used the 1-best ASR result.
From thetranslation results, it can be seen that three meth-ods achieved comparable translation quality onboth ASR and CRR inputs, with the translation re-sults on CRR inputs are much better than those onASR inputs because of the errors in the ASR in-puts.
The results also show that our translation se-lection method is very effective, which achievedabsolute improvements of about 4 and 1 BLEUscores on CRR and ASR inputs, respectively.5.4 Results by Using both RBMT and SMTSystemsIn order to fill up the data gap as discussed in Sec-tion 3, we used the RBMT System A to translatethe English sentences in the ES corpus into Chi-nese.
As described in Section 3, this corpus canbe used by the three pivot translation methods.First, the synthetic Chinese-Spanish corpus can becombined with those produced by the EC and ESSMT systems, which were used in the syntheticmethod.
Second, the synthetic Chinese-Englishcorpus can be added into the BTEC CE1 corpus tobuild the CE translation model.
In this way, the in-tersected English phrases in the CE corpus and EScorpus becomes more, which enables the Chinese-Spanish translation model induced using the trian-gulation method to cover more phrase pairs.
Forthe transfer method, the CE translation quality canbe also improved, which would result in the im-provement of the Spanish translation quality.The translation results are shown in the columnsunder ?EC RBMT?
in Table 4.
As compared withthose in Table 3, the translation quality was greatlyimproved, with absolute improvements of at least5.1 and 3.9 BLEU scores on CRR and ASR inputsfor system combination results.
The above resultsindicate that RBMT systems indeed can be used tofill up the data gap for pivot translation.In our experiments, we also used a CE RBMTsystem to enlarge the size of training data by pro-00.10.20.30.40.50.60.70.80.91234567Phrase lengthCoverageSMT (Triangulation)+EC RBMT+EC RBMT+CE RBMT+EC RBMT+CE RBMT+Test SetFigure 1: Coverage on test source phrasesviding alternative English translations for the Chi-nese part of the CE corpus.
The translation resultsare shown in the columns under ?+CE RBMT?
inTable 4.
From the translation results, it can beseen that, enlarging the size of training data withRBMT systems can further improve the translationquality.In addition to translating the training data, theCE RBMT system can be also used to translate thetest set into English, which can be further trans-lated into Spanish with the ES RBMT system B.56The translated test set can be further added to thetraining data to improve translation quality.
Thecolumns under ?+Test Set?
in Table 4 describesthe translation results.
The results show that trans-lating the test set using RBMT systems greatly im-proved the translation result, with further improve-ments of about 2 and 1.5 BLEU scores on CRRand ASR inputs, respectively.The results also indicate that both the triangula-tion method and the transfer method greatly out-performed the synthetic method when we com-bined both RBMT and SMT systems in our exper-iments.
Further analysis shows that the syntheticmethod contributed little to system combination.The selection results are almost the same as thoseselected from the translations produced by the tri-angulation and transfer methods.In order to further analyze the translation re-sults, we evaluated the above systems by examin-ing the coverage of the phrase tables over the testphrases.
We took the triangulation method as acase study, the results of which are shown in Fig-5Although using the ES RBMT system B to translate thetraining data did not improve the translation quality, it im-proved the translation quality by translating the test set.6The RBMT systems achieved a BLEU score of 24.36 onthe test set.159EC RBMT + CE RBMT + Test SetMethod BLEU BLEU-Fix BLEU BLEU-Fix BLEU BLEU-FixTriangulation 40.69/31.02 37.99/29.15 41.59/31.43 39.39/29.95 44.71/32.60 42.37/31.14Transfer 42.06/31.72 39.73/29.35 43.40/33.05 40.73/30.06 45.91/34.52 42.86/31.92Synthetic 39.10/29.73 37.26/28.45 39.90/30.00 37.90/28.66 41.16/31.30 37.99/29.36Combination 43.21/33.23 40.58/31.17 45.09/34.10 42.88/31.73 47.06/35.62 44.94/32.99Table 4: CRR/ASR translation results by using RBMT and SMT systemsMethod BLEU BLEU-FixTriangulation 45.64/33.15 42.11/31.11Transfer 47.18/34.56 43.61/32.17Combination 48.42/36.42 45.42/33.52Table 5: CRR/ASR translation results by using ad-ditional monolingual corporaure 1.
It can be seen that using RBMT systemsto translate the training and/or test data can covermore source phrases in the test set, which resultsin translation quality improvement.5.5 Results by Using Monolingual CorpusIn addition to translating the limited bilingual cor-pus, we also translated additional monolingualcorpus to further enlarge the size of the trainingdata.
We assume that it is easier to obtain a mono-lingual pivot corpus than to obtain a monolingualsource or target corpus.
Thus, we translated theEnglish part of the HIT Olympic corpus into Chi-nese and Spanish using EC and ES RBMT sys-tems.
The generated synthetic corpus was added tothe training data to train EC and ES SMT systems.Here, we used the synthetic CE Olympic corpusto train a model, which was interpolated with theCE model trained with both the BTEC CE1 cor-pus and the synthetic BTEC corpus to obtain aninterpolated CE translation model.
Similarly, weobtained an interpolated ES translation model.
Ta-ble 5 describes the translation results.7 The resultsindicate that translating monolingual corpus usingthe RBMT system further improved the translationquality as compared with those in Table 4.6 Discussion6.1 Effects of Different RBMT SystemsIn this section, we compare the effects of twocommercial RBMT systems with different transla-7Here we excluded the synthetic method since it greatlyfalls behind the other two methods.Method Sys.
A Sys.
B Sys.
A+BTriangulation 40.69 39.28 41.01Transfer 42.06 39.57 43.03Synthetic 39.10 38.24 39.26Combination 43.21 40.59 44.27Table 6: CRR translation results (BLEU scores)by using different RBMT systemstion accuracy on spoken language translation.
Thegoals are (1) to investigate whether a RBMT sys-tem can improve pivot translation quality even ifits translation accuracy is not high, and (2) to com-pare the effects of RBMT system with differenttranslation accuracy on pivot translation.
Besidesthe EC RBMT system A used in the above section,we also used the EC RBMT system B for this ex-periment.We used the two systems to translate the test setfrom English to Chinese, and then evaluated thetranslation quality against Chinese references ob-tained from the IWSLT 2008 evaluation campaign.The BLEU scores are 43.90 and 29.77 for SystemA and System B, respectively.
This shows thatthe translation quality of System B on spoken lan-guage corpus is much lower than that of System A.Then we applied these two different RBMT sys-tems to translate the English part of the BTEC EScorpus into Chinese as described in Section 5.4.The translation results on CRR inputs are shownin Table 6.8 We replicated some of the results inTable 4 for the convenience of comparison.
Theresults indicate that the higher the translation ac-curacy of the RBMT system is, the better the pivottranslation is.
If we compare the results with thoseonly using SMT systems as described in Table 3,the translation quality was greatly improved by atleast 3 BLEU scores, even if the translation ac-8We omitted the ASR translation results since the trendsare the same as those for CRR inputs.
And we only showedBLEU scores since the trend for BLEU-Fix scores is similar.160Method Multilingual + BTEC CE1Triangulation 41.86/39.55 42.41/39.55Transfer 42.46/39.09 43.84/40.34Standard 42.21/40.23 42.21/40.23Combination 43.75/40.34 44.68/41.14Table 7: CRR translation results by using multilin-gual corpus.
?/?
separates the BLEU and BLEU-fix scores.curacy of System B is not so high.
Combiningtwo RBMT systems further improved the transla-tion quality, which indicates that the two systemscomplement each other.6.2 Results by Using Multilingual CorpusIn this section, we compare the translation resultsby using a multilingual corpus with those by us-ing independently sourced corpora.
BTEC CE2and BTEC ES are from the same source sentences,which can be taken as a multilingual corpus.
Thetwo corpora were employed to build CE and ESSMT models, which were used in the triangula-tion method and the transfer method.
We also ex-tracted the Chinese-Spanish (CS) corpus to build astandard CS translation system, which is denotedas Standard.
The comparison results are shownin Table 7.
The translation quality produced bythe systems using a multilingual corpus is muchhigher than that produced by using independentlysourced corpora as described in Table 3, with anabsolute improvement of about 5.6 BLEU scores.If we used the EC RBMT system, the translationquality of those in Table 4 is comparable to that byusing the multilingual corpus, which indicates thatour method using RBMT systems to fill up the datagap is effective.
The results also indicate that ourtranslation selection method for pivot translationoutperforms the method using only a real source-target corpus.For comparison purpose, we added BTEC CE1into the training data.
The translation quality wasimproved by only 1 BLEU score.
This againproves that our method to fill up the data gap ismore effective than that to increase the size of theindependently sourced corpus.6.3 Comparison with Related WorkIn IWSLT 2008, the best result for the pivot taskis achieved by Wang et al (2008).
In order tocompare the results, we added the bilingual HITOurs Wang TSALBLEU 49.57 - 48.25BLEU-Fix 46.74 45.10 45.27Table 8: Comparison with related workOlympic corpus into the CE training data.9 Wealso compared our translation selection methodwith that proposed in (Wang et al, 2008) thatis based on the target sentence average length(TSAL).
The translation results are shown in Ta-ble 8.
?Wang?
represents the results in Wang et al(2008).
?TSAL?
represents the translation selec-tion method proposed in Wang et al (2008), whichis applied to our experiment.
From the results, itcan be seen that our method outperforms the bestsystem in IWSLT 2008 and that our translation se-lection method outperforms the method based ontarget sentence average length.7 ConclusionIn this paper, we have compared three differ-ent pivot translation methods for spoken languagetranslation.
Experimental results indicated that thetriangulation method and the transfer method gen-erally outperform the synthetic method.
Then weshowed that the hybrid method combining RBMTand SMT systems can be used to fill up the datagap between the source-pivot and pivot-target cor-pora.
By translating the pivot sentences in inde-pendent corpora, the hybrid method can producetranslations whose quality is higher than those pro-duced by the method using a source-target corpusof the same size.
We also showed that even if thetranslation quality of the RBMT system is low, itstill greatly improved the translation quality.In addition, we proposed a system combinationmethod to select better translations from outputsproduced by different pivot methods.
This methodis developed through regression learning, whereonly a small size of training examples with ref-erence translations are required.
Experimental re-sults indicate that this method can consistently andsignificantly improve translation quality over indi-vidual translation outputs.
And our system out-performs the best system for the pivot task in theIWSLT 2008 evaluation campaign.9We used about 70k sentence pairs for CE model training,while Wang et al (2008) used about 100k sentence pairs, aCE translation dictionary and more monolingual corpora formodel training.161ReferencesJoshua S. Albrecht and Rebecca Hwa.
2007.
Regres-sion for Sentence-Level MT Evaluation with PseudoReferences.
In Proceedings of the 45th AnnualMeeting of the Accosiation of Computational Lin-guistics, pages 296?303.Nicola Bertoldi, Madalina Barbaiani, Marcello Fed-erico, and Roldano Cattoni.
2008.
Phrase-BasedStatistical Machine Translation with Pivot Lan-guages.
In Proceedings of the International Work-shop on Spoken Language Translation, pages 143-149.Tevor Cohn and Mirella Lapata.
2007.
Machine Trans-lation by Triangulation: Making Effective Use ofMulti-Parallel Corpora.
In Proceedings of the 45thAnnual Meeting of the Association for Computa-tional Linguistics, pages 348?355.Kevin Duh.
2008.
Ranking vs. Regression in MachineTranslation Evaluation.
In Proceedings of the ThirdWorkshop on Statistical Machine Translation, pages191?194.Xiaoguang Hu, Haifeng Wang, and Hua Wu.
2007.Using RBMT Systems to Produce Bilingual Corpusfor SMT.
In Proceedings of the 2007 Joint Con-ference on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning, pages 287?295.Thorsten Joachims.
1999.
Making Large-ScaleSVM Learning Practical.
In Bernhard Scho?elkopf,Christopher Burges, and Alexander Smola, edi-tors, Advances in Kernel Methods - Support VectorLearning.
MIT Press.Maxim Khalilov, Marta R. Costa-Jussa`, Carlos A.Henr?
?quez, Jose?
A.R.
Fonollosa, Adolfo Herna?ndez,Jose?
B. Marin?o, Rafael E. Banchs, Chen Boxing,Min Zhang, Aiti Aw, and Haizhou Li.
2008.
TheTALP & I2R SMT Systems for IWSLT 2008.
InProceedings of the International Workshop on Spo-ken Language Translation, pages 116?123.Philipp Koehn, Franz J. Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In HLT-NAACL: Human Language Technology Conferenceof the North American Chapter of the Associationfor Computational Linguistics, pages 127?133.Philipp Koehn, Hieu Hoang, Alexanda Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: OpenSource Toolkit for Statistical Machine Translation.In Proceedings of the 45th Annual Meeting of theAssocia-tion for Computational Linguistics, demon-stration session, pages 177?180.Alon Lavie and Abhaya Agarwal.
2007.
METEOR:An Automatic Metric for MT Evaluation with HighLevels of Correlation with Human Judgments.
InProceedings of Workshop on Statistical MachineTranslation at the 45th Annual Meeting of the As-sociation of Computational Linguistics, pages 228?231.Franz J. Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proceedingsof the 41st Annual Meeting of the Association forComputational Linguistics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
In Proceedingsof the 40th annual meeting of the Association forComputational Linguistics, pages 311?318.Michael Paul.
2008.
Overview of the IWSLT 2008Evaluation Campaign.
In Proceedings of the In-ternational Workshop on Spoken Language Trans-lation, pages 1?17.Masao Utiyama and Hitoshi Isahara.
2007.
A Com-parison of Pivot Methods for Phrase-Based Statisti-cal Machine Translation.
In Proceedings of humanlanguage technology: the Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 484?491.Haifeng Wang, Hua Wu, Xiaoguang Hu, Zhanyi Liu,Jianfeng Li, Dengjun Ren, and Zhengyu Niu.
2008.The TCH Machine Translation System for IWSLT2008.
In Proceedings of the International Workshopon Spoken Language Translation, pages 124?131.Hua Wu and Haifeng Wang.
2007.
Pivot Lan-guage Approach for Phrase-Based Statistical Ma-chine Translation.
In Proceedings of 45th AnnualMeeting of the Association for Computational Lin-guistics, pages 856?863.162
