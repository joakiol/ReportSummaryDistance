Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 953?960,Sydney, July 2006. c?2006 Association for Computational LinguisticsAccurate Collocation Extraction Using a Multilingual ParserVioleta SeretanLanguage Technology LaboratoryUniversity of Geneva2, rue de Candolle, 1211 GenevaVioleta.Seretan@latl.unige.chEric WehrliLanguage Technology LaboratoryUniversity of Geneva2, rue de Candolle, 1211 GenevaEric.Wehrli@latl.unige.chAbstractThis paper focuses on the use of advancedtechniques of text analysis as support forcollocation extraction.
A hybrid system ispresented that combines statistical meth-ods and multilingual parsing for detectingaccurate collocational information fromEnglish, French, Spanish and Italian cor-pora.
The advantage of relying on fullparsing over using a traditional windowmethod (which ignores the syntactic in-formation) is first theoretically motivated,then empirically validated by a compara-tive evaluation experiment.1 IntroductionRecent computational linguistics research fully ac-knowledged the stringent need for a systematicand appropriate treatment of phraseological unitsin natural language processing applications (Saget al, 2002).
Syntagmatic relations between words?
also called multi-word expressions, or ?id-iosyncratic interpretations that cross word bound-aries?
(Sag et al, 2002, 2) ?
constitute an im-portant part of the lexicon of a language: accord-ing to Jackendoff (1997), they are at least as nu-merous as the single words, while according toMel?c?uk (1998) they outnumber single words tento one.Phraseological units include a wide range ofphenomena, among which we mention compoundnouns (dead end), phrasal verbs (ask out), idioms(lend somebody a hand), and collocations (fiercebattle, daunting task, schedule a meeting).
Theypose important problems for NLP applications,both text analysis and text production perspectivesbeing concerned.In particular, collocations1 are highly problem-atic, for at least two reasons: first, because theirlinguistic status and properties are unclear (aspointed out by McKeown and Radev (2000), theirdefinition is rather vague, and the distinction fromother types of expressions is not clearly drawn);second, because they are prevalent in language.Mel?c?uk (1998, 24) claims that ?collocations makeup the lions share of the phraseme inventory?, anda recent study referred in (Pearce, 2001) showedthat each sentence is likely to contain at least onecollocation.Collocational information is not only useful, butalso indispensable in many applications.
In ma-chine translation, for instance, it is considered ?thekey to producing more acceptable output?
(Orliacand Dillinger, 2003, 292).This article presents a system that extracts ac-curate collocational information from corpora byusing a syntactic parser that supports several lan-guages.
After describing the underlying method-ology (section 2), we report several extraction re-sults for English, French, Spanish and Italian (sec-tion 3).
Then we present in sections 4 and 5 a com-parative evaluation experiment proving that a hy-brid approach leads to more accurate results than aclassical approach in which syntactic informationis not taken into account.2 Hybrid Collocation ExtractionWe consider that syntactic analysis of source cor-pora is an inescapable precondition for colloca-tion extraction, and that the syntactic structure ofsource text has to be taken into account in order toensure the quality and interpretability of results.1To put it simply, collocations are non-idiomatical, butrestricted, conventional lexical combinations.953As a matter of fact, some of the existing colloca-tion extraction systems already employ (but onlyto a limited extent) linguistic tools in order to sup-port the collocation identification in text corpora.For instance, lemmatizers are often used for recog-nizing all the inflected forms of a lexical item, andPOS taggers are used for ruling out certain cate-gories of words, e.g., in (Justeson and Katz, 1995).Syntactic analysis has long since been recog-nized as a prerequisite for collocation extraction(for instance, by Smadja2), but the traditional sys-tems simply ignored it because of the lack, at thattime, of efficient and robust parsers required forprocessing large corpora.
Oddly enough, this situ-ation is nowadays perpetuated, in spite of the dra-matic advances in parsing technology.
Only a fewexceptions exists, e.g., (Lin, 1998; Krenn and Ev-ert, 2001).One possible reason for this might be the waythat collocations are generally understood, as apurely statistical phenomenon.
Some of the best-known definitions are the following: ?Colloca-tions of a given word are statements of the ha-bitual and customary places of that word?
(Firth,1957, 181); ?arbitrary and recurrent word combi-nation?
(Benson, 1990); or ?sequences of lexicalitems that habitually co-occur?
(Cruse, 1986, 40).Most of the authors make no claims with respect tothe grammatical status of the collocation, althoughthis can indirectly inferred from the examples theyprovide.On the contrary, other definitions state explic-itly that a collocation is an expression of language:?co-occurrence of two or more lexical items asrealizations of structural elements within a givensyntactic pattern?
(Cowie, 1978); ?a sequence oftwo or more consecutive words, that has character-istics of a syntactic and semantic unit?
(Choueka,1988).
Our approach is committed to these laterdefinitions, hence the importance we lend to us-ing appropriate extraction methodologies, basedon syntactic analysis.The hybrid method we developed relies on theparser Fips (Wehrli, 2004), that implements theGovernment and Binding formalism and supportsseveral languages (besides the ones mentioned in2?Ideally, in order to identify lexical relations in a corpusone would need to first parse it to verify that the words areused in a single phrase structure.
However, in practice, free-style texts contain a great deal of nonstandard features overwhich automatic parsers would fail.
This fact is being seri-ously challenged by current research (...), and might not betrue in the near future?
(Smadja, 1993, 151).the abstract, a few other are also partly dealt with).We will not present details about the parser here;what is relevant for this paper is the type of syn-tactic structures it uses.
Each constituent is rep-resented by a simplified X-bar structure (withoutintermediate level), in which to the lexical head isattached a list of left constituents (its specifiers)and right constituents (its complements), and eachof these are in turn represented by the same typeof structure, recursively.Generally speaking, a collocation extraction canbe seen as a two-stage process:I. in stage one, collocation candidates are iden-tified from the text corpora, based on criteriawhich are specific to each system;II.
in stage two, the candidates are scored andranked using specific association measures(a review can be found in (Manning andSchu?tze, 1999; Evert, 2004; Pecina, 2005)).According to this description, in our approachthe parser is used in the first stage of extraction,for identifying the collocation candidates.
A pairof lexical items is selected as a candidate only ifthere is a syntactic relation holding between thetwo items (one being the head of the current parsestructure, and the other the lexical head of its spec-ifier/complement).
Therefore, the criterion we em-ploy for candidate selection is the syntactic prox-imity, as opposed to the linear proximity used bytraditional, window-based methods.As the parsing goes on, the syntactic word pairsare extracted from the parse structures created,from each head-specifier or head-complement re-lation.
The pairs obtained are then partitionedaccording to their syntactic configuration (e.g.,noun + adjectival or nominal specifier, noun +argument, noun + adjective in predications, verb+ adverbial specifier, verb + argument (subject,object), verb + adjunt, etc).
Finally, the log-likelihood ratios test (henceforth LLR) (Dunning,1993) is applied on each set of pairs.
We callthis method hybrid, since it combines syntacticand statistical information (about word and co-occurrence frequency).The following examples ?
which, like all theexamples in this paper, are actual extraction re-sults ?
demonstrate the potential of our systemto detect collocation candidates, even if subject tocomplex syntactic transformations.9541.a) raise question: The question ofpolitical leadership has been raisedseveral times by previous speakers.1.b) play role: What role can Canada?simmigration program play in help-ing developing nations... ?1.c) make mistake: We could look backand probably see a lot of mistakesthat all parties including Canadaperhaps may have made.3 Multilingual Extraction ResultsIn this section, we present several extraction re-sults obtained with the system presented in sec-tion 2.
The experiments were performed on datain the four languages, and involved the followingcorpora: for English and French, a subpart or theHansard Corpus of proceedings from the CanadianParliament; for Italian, documents from the SwissParliament; and for Spanish, a news corpus dis-tributed by the Linguistic Data Consortium.Some statistics on these corpora, some process-ing details and quantitative results are provided inTable 1.
The first row lists the corpora size (intokens); the next three rows show some parsingstatistics3, and the last rows display the number ofcollocation candidates extracted and of candidatesfor which the LLR score could be computed4.Statistics English French Spanish Italiantokens 3509704 1649914 1023249 287804sentences 197401 70342 67502 12008compl.
parse 139498 50458 13245 4511avg.
length 17.78 23.46 15.16 23.97pairs 725025 370932 162802 58258(extracted) 276670 147293 56717 37914pairs 633345 308410 128679 47771(scored) 251046 131384 49495 30586Table 1: Extraction statisticsIn Table 2 we list the top collocations (of lengthtwo) extracted for each language.
We do notspecifically discuss here multilingual issues in col-location extraction; these are dealt with in a sepa-rate paper (Seretan and Wehrli, 2006).3The low rate of completely parsed sentences for Spanishand Italian are due to the relatively reduced coverage of theparsers of these two languages (under development).
How-ever, even if a sentence is not assigned a complete parse tree,some syntactic pairs can still be collected from the partialparses.4The log-likelihood ratios score is undefined for thosepairs having a cell of the contingency table equal to 0.Language Key1 Key2 LLR scoreEnglish federal government 7229.69reform party 6530.69house common 6006.84minister finance 5829.05acting speaker 5551.09red book 5292.63create job 4131.55right Hon 4117.52official opposition 3640.00deputy speaker 3549.09French premier ministre 4317.57bloc que?be?cois 3946.08discours tro?ne 3894.04ve?rificateur ge?ne?ral 3796.68parti re?formiste 3615.04gouvernement fe?de?ral 3461.88missile croisie`re 3147.42Chambre commune 3083.02livre rouge 2536.94secre?taire parlementaire 2524.68Spanish banco central 4210.48millo?n do?lar 3312.68millo?n peso 2335.00libre comercio 2169.02nuevo peso 1322.06tasa intere?s 1179.62deuda externo 1119.91ca?mara representante 1015.07asamblea ordinario 992.85papel comercial 963.95Italian consiglio federale 3513.19scrivere consiglio 594.54unione europeo 479.73servizio pubblico 452.92milione franco 447.63formazione continuo 388.80iniziativa popolare 383.68testo interpellanza 377.46punto vista 373.24scrivere risposta 348.77Table 2: Top ten collocations extracted for eachlanguageThe collocation pairs obtained were further pro-cessed with a procedure of long collocations ex-traction described elsewhere (Seretan et al, 2003).Some examples of collocations of length 3, 4and 5 obtained are: minister of Canadian her-itage, house proceed to statement by, secretary toleader of gouvernment in house of common (En),question adresser a` ministre, programme de aidea` re?novation re?sidentielle, agent employer forcesusceptible causer (Fr), bolsa de comercio local,peso en cuota de fondo de inversio?n, permitir usode papel de deuda esterno (Sp), consiglio federaledisporre, creazione di nuovo posto di lavoro, cos-tituire fattore penalizzante per regione (It)5.5Note that the output of the procedure contains lemmasrather than inflected forms.9554 Comparative Evaluation Hypotheses4.1 Does Parsing Really Help?Extracting collocations from raw text, without pre-processing the source corpora, offers some clearadvantages over linguistically-informed methodssuch as ours, which is based on the syntactic anal-ysis: speed (in contrast, parsing large corpora oftexts is expected to be much more time consum-ing), robustness (symbolic parsers are often notrobust enough for processing large quantities ofdata), portability (no need to a priori define syn-tactic configurations for collocations candidates).On the other hand, these basic systems sufferfrom the combinatorial explosion if the candidatepairs are chosen from a large search space.
Tocope with this problem, a candidate pair is usu-ally chosen so that both words are inside a context(?collocational?)
window of a small length.
A 5-word window is the norm, while longer windowsprove impractical (Dias, 2003).It has been argued that a window size of 5 isactually sufficient for capturing most of the col-locational relations from texts in English.
Butthere is no evidence sustaining that the same holdsfor other languages, like German or the Romanceones that exhibit freer word order.
Therefore, aswindow-based systems miss the ?long-distance?pairs, their recall is presumably lower than that ofparse-based systems.
However, the parser couldalso miss relevant pairs due to inherent analysiserrors.As for precision, the window systems are sus-ceptible to return more noise, produced by thegrammatically unrelated pairs inside the colloca-tional window.
By dividing the number of gram-matical pairs by the total number of candidatesconsidered, we obtain the overall precision withrespect to grammaticality; this result is expected tobe considerably worse in the case of basic methodthan for the parse-based methods, just by virtueof the parsing task.
As for the overall precisionwith respect to collocability, we expect the propor-tional figures to be preserved.
This is because theparser-based methods return less, but better pairs(i.e., only the pairs identified as grammatical), andbecause collocations are a subset of the grammat-ical pairs.Summing up, the evaluation hypothesis that canbe stated here is the following: parse-based meth-ods outperform basic methods thanks to a drasticreduction of noise.
While unquestionable underthe assumption of perfect parsing, this hypothesishas to be empirically validated in an actual setting.4.2 Is More Data Better Than Better Data?The hypothesis above refers to the overall preci-sion and recall, that is, relative to the entire list ofselected candidates.
One might argue that thesenumbers are less relevant for practice than theyare from a theoretical (evaluation) perspective, andthat the exact composition of the list of candi-dates identified is unimportant if only the top re-sults (i.e., those pairs situated above a threshold)are looked at by a lexicographer or an application.Considering a threshold for the n-best candi-dates works very much in the favor of basic meth-ods.
As the amount of data increases, there isa reduction of the noise among the best-scoredpairs, which tend to be more grammatical becausethe likelihood of encountering many similar noisypairs is lower.
However, as the following exampleshows, noisy pairs may still appear in top, if theyoccur often in a longer collocation:2.a) les essais du missile de croisie`re2.b) essai - croisie`reThe pair essai - croisie`re is marked by the basicsystems as a collocation because of the recurrentassociation of the two words in text as part or thelonger collocation essai du missile de croisie`re.
Itis an grammatically unrelated pair, while the cor-rect pairs reflecting the right syntactic attachmentare essai missile and missile (de) croisie`re.We mentioned that parsing helps detecting the?long-distance?
pairs that are outside the limitsof the collocational window.
Retrieving all suchcomplex instances (including all the extrapositioncases) certainly augment the recall of extractionsystems, but this goal might seem unjustified, be-cause the risk of not having a collocation repre-sented at all diminishes as more and more datais processed.
One might think that systematicallymissing long-distance pairs might be very simplycompensated by supplying the system with moredata, and thus that larger data is a valid alternativeto performing complex processing.While we agree that the inclusion of more datacompensates for the ?difficult?
cases, we do con-sider this truly helpful in deriving collocationalinformation, for the following reasons: (1) moredata means more noise for the basic methods; (2)some collocations might systematically appear in956a complex grammatical environment (such as pas-sive constructions or with additional material in-serted between the two items); (3) more impor-tantly, the complex cases not taken into accountalter the frequency profile of the pairs concerned.These observations entitle us to believe that,even when more data is added, the n-best precisionmight remain lower for the basic methods with re-spect to the parse-based ones.4.3 How Real the Counts Are?Syntactic analysis (including shallower levels oflinguistic analysis traditionally used in collocationextraction, such as lemmatization, POS tagging, orchunking) has two main functions.On the one hand, it guides the extraction systemin the candidate selection process, in order to bet-ter pinpoint the pairs that might form collocationsand to exclude the ones considered as inappropri-ate (e.g., the pairs combining function words, suchas a preposition followed by a determiner).On the other, parsing supports the associationmeasures that will be applied on the selected can-didates, by providing more exact frequency infor-mation on words ?
the inflected forms count asinstances of the same lexical item ?
and on theirco-occurrence frequency ?
certain pairs mightcount as instance of the same pair, others do not.In the following example, the pair loi modifieris an instance of a subject-verb collocation in 3.a),and of a verb-object collocation type in 3.b).
Basicmethods are unable to distinguish between the twotypes, and therefore count them as equivalent.3.a) Loi modifiant la Loi sur la respons-abilite?
civile3.b) la loi devrait e?tre modifie?eParsing helps to create a more realistic fre-quency profile for the candidate pairs, not only be-cause of the grammaticality constraint it applieson the pairs (wrong pairs are excluded), but alsobecause it can detect the long-distance pairs thatare outside the collocational window.Given that the association measures rely heav-ily on the frequency information, the erroneouscounts have a direct influence on the ranking ofcandidates and, consequently, on the top candi-dates returned.
We believe that in order to achievea good performance, extraction systems should beas close as possible to the real frequency countsand, of course, to the real syntactic interpretationprovided in the source texts6.Since parser-based methods rely on more accu-rate frequency information for words and their co-occurrence than window methods, it follows thatthe n-best list obtained with the first methods willprobably show an increase in quality over the sec-ond.To conclude this section, we enumerate the hy-potheses that have been formulated so far: (1)Parse methods provide a noise-freer list of collo-cation candidates, in comparison with the windowmethods; (2) Local precision (of best-scored re-sults) with respect to grammaticality is higher forparse methods, since in basic methods some noisestill persists, even if more data is included; (3) Lo-cal precision with respect to collocability is higherfor parse methods, because they use a more realis-tic image of word co-occurrence frequency.5 Comparative EvaluationWe compare our hybrid method (based on syntac-tic processing of texts) against the window methodclassically used in collocation extraction, from thepoint of view of their precision with respect togrammaticality and collocability.5.1 The MethodThe n-best extraction results, for a given n (in ourexperiment, n varies from 50 to 500 at intervalsof 50) are checked in each case for grammaticalwell-formedness and for lexicalization.
By lexi-calization we mean the quality of a pair to con-stitute (part of) a multi-word expression ?
be itcompound, collocation, idiom or another type ofsyntagmatic lexical combination.
We avoid givingcollocability judgments since the classification ofmulti-word expressions cannot be made preciselyand with objective criteria (McKeown and Radev,2000).
We rather distinguish between lexicaliz-able and trivial combinations (completely regularproductions, such as big house, buy bread, thatdo not deserve a place in the lexicon).
As in(Choueka, 1988) and (Evert, 2004), we considerthat a dominant feature of collocations is that theyare unpredictable for speakers and therefore haveto be stored into a lexicon.6To exemplify this point: the pair de?veloppement hu-main (which has been detected as a collocation by the basicmethod) looks like a valid expression, but the source text con-sistently offers a different interpretation: de?veloppement desressources humaines.957Each collocation from the n-best list at thedifferent levels considered is therefore annotatedwith one of the three flags: 1. ungrammatical;2. trivial combination; 3. multi-word expression(MWE).On the one side, we evaluate the results of ourhybrid, parse-based method; on the other, we sim-ulate a window method, by performing the fol-lowing steps: POS-tag the source texts; filter thelexical items and retain only the open-class POS;consider all their combinations within a colloca-tional window of length 5; and, finally, apply thelog-likelihood ratios test on the pairs of each con-figuration type.In accordance with (Evert and Kermes, 2003),we consider that the comparative evaluation ofcollocation extraction systems should not be doneat the end of the extraction process, but separatelyfor each stage: after the candidate selection stage,for evaluating the quality (in terms of grammati-cality) of candidates proposed; and after the ap-plication of collocability measures, for evaluatingthe measures applied.
In each of these cases, dif-ferent evaluation methodologies and resources arerequired.
In our case, since we used the same mea-sure for the second stage (the log-likelihood ratiostest), we could still compare the final output of ba-sic and parse-based methods, as given by the com-bination of the first stage with the same collocabil-ity measure.Again, similarly to Krenn and Evert (2001), webelieve that the homogeneity of data is importantfor the collocability measures.
We therefore ap-plied the LLR test on our data after first partition-ing it into separate sets, according to the syntacti-cal relation holding in each candidate pair.
As thedata used in the basic method contains no syntac-tic information, the partitioning was done based onPOS-combination type.5.2 The DataThe evaluation experiment was performed on thewhole French corpus used in the extraction exper-iment (section 2), that is, a subpart of the Hansardcorpus of Canadian Parliament proceedings.
Itcontains 112 text files totalling 8.43 MB, withan average of 628.1 sentences/file and 23.46 to-kens/sentence (as detected by the parser).
The to-tal number of tokens is 1, 649, 914.On the one hand, the texts were parsed and370, 932 candidate pairs were extracted using thehybrid method we presented.
Among the pairs ex-tracted, 11.86% (44, 002 pairs) were multi-wordexpressions identified at parse-time, since presentin the parser?s lexicon.
The log-likelihood ratiostest was applied on the rest of pairs.
A scorecould be associated to 308, 410 of these pairs (cor-responding to 131, 384 types); for the others, thescore was undefined.On the other hand, the texts were POS-taggedusing the same parser as in the first case.
If in thefirst case the candidate pairs were extracted dur-ing the parsing, in the second they were generatedafter the open-class filtering.
From 673, 789 POS-filtered tokens, a number of 1, 024, 888 combina-tions (560, 073 types) were created using the 5-length window criterion, while taking care not tocross a punctuation mark.
A score could be asso-ciated to 1, 018, 773 token pairs (554, 202 types),which means that the candidate list is considerablylarger than in the first case.
The processing timewas more than twice longer than in the first case,because of the large amount of data to handle.5.3 ResultsThe 500 best-scored collocations retrieved withthe two methods were manually checked by threehuman judges and annotated, as explained in 5.1,as either ungrammatical, trivial or MWE.
Theagreement statistics on the annotations for eachmethod are shown in Table 3.Method Agr.
1,2,3 1,2 1,3 2,3parse observed 285 365 362 340k-score 55.4% 62.6% 69% 64%window observed 226 339 327 269k-score 43.1% 63.8% 61.1% 48%Table 3: Inter-annotator agreementFor reporting n-best precision results, we usedas reference set the annotated pairs on which atleast two of the three annotators agreed.
Thatis, from the 500 initial pairs retrieved with eachmethod, 497 pairs were retained in the first case(parse method), and 483 pairs in the second (win-dow method).Table 4 shows the comparative evaluation re-sults for precision at different levels in the listof best-scored pairs, both with respect to gram-maticality and to collocability (or, more exactly,the potential of a pair to constitute a MWE).
Thenumbers show that a drastic reduction of noise isachieved by parsing the texts.
The error rate with958Precision (gram.)
Precision (MWE)n window parse window parse50 94.0 96.0 80.0 72.0100 91.0 98.0 75.0 74.0150 87.3 98.7 72.7 73.3200 85.5 98.5 70.5 74.0250 82.8 98.8 67.6 69.6300 82.3 98.7 65.0 69.3350 80.3 98.9 63.7 67.4400 80.0 99.0 62.5 67.0450 79.6 99.1 61.1 66.0500 78.3 99.0 60.1 66.0Table 4: Comparative evaluation resultsrespect to grammaticality is, on average, 15.9%for the window method; with parsing, it drops to1.5% (i.e., 10.6 times smaller).This result confirms our hypothesis regardingthe local precision which was stated in section 4.2.Despite the inherent parsing errors, the noise re-duction is substantial.
It is also worth noting thatwe compared our method against a rather highbaseline, as we made a series of choices suscep-tible to alleviate the candidates identification withthe window-based method: we filtered out func-tion words, we used a parser for POS-tagging (thateliminated POS-ambiguity), and we filtered outcross-punctuation pairs.As for the MWE precision, the window methodperforms better for the first 100 pairs7); on the re-maining part, the parsing-based method is on aver-age 3.7% better.
The precision curve for the win-dow method shows a more rapid degradation thanit does for the other.
Therefore we can concludethat parsing is especially advantageous if one in-vestigates more that the first hundred results (asit seems reasonable for large extraction experi-ments).In spite of the rough classification we used inannotation, we believe that the comparison per-formed is nonetheless meaningful since resultsshould be first checked for grammaticality and?triviality?
before defining more difficult taskssuch as collocability.6 ConclusionIn this paper, we provided both theoretical and em-pirical arguments in the favor of performing syn-tactic analysis of texts prior to the extraction ofcollocations with statistical methods.7A closer look at the data revealed that this might be ex-plained by some inconsistencies between annotations.Part of the extraction work that, like ours, re-lies on parsing was cited in section 2.
Most of-ten, it concerns chunking rather than completeparsing; specific syntactic configurations (such asadjective-noun, preposition-noun-verb); and lan-guages other than the ones we deal with (usually,English and German).
Parsing has been also usedafter extraction (Smadja, 1993) for filtering out in-valid results.
We believe that this is not enoughand that parsing is required prior to the applica-tion of statistical tests, for computing a realisticfrequency profile for the pairs tested.As for evaluation, unlike most of the existingwork, we are not concerned here with compar-ing the performance of association measures (cf.
(Evert, 2004; Pecina, 2005) for comprehensivereferences), but with a contrastive evaluation ofsyntactic-based and standard extraction methods,combined with the same statistical computation.Our study finally clear the doubts on the use-fulness of parsing for collocation extraction.
Pre-vious work that quantified the influence of parsingon the quality of results suggested the performancefor tagged and parsed texts is similar (Evert andKermes, 2003).
This result applies to a quite rigidsyntactic pattern, namely adjective-noun in Ger-man.
But a preceding study on noun-verb pairs(Breidt, 1993) came to the conclusion that goodprecision can only be achieved for German withparsing.
Its author had to simulate parsing becauseof the lack, at the time, of parsing tools for Ger-man.
Our report, that concerns an actual systemand a large data set, validates Breidt?s finding fora new language (French).Our experimental results confirm the hypothe-ses put forth in section 4, and show that parsing(even if imperfect) benefits to extraction, notablyby a drastic reduction of the noise in the top ofthe significance list.
In future work, we considerinvestigating other levels of the significance list,extending the evaluation to other languages, com-paring against shallow-parsing methods instead ofthe window method, and performing recall-basedevaluation as well.AcknowledgementsWe would like to thank Jorge Antonio Leoni deLeon, Mar Ndiaye, Vincenzo Pallotta and YvesScherrer for participating to the annotation task.We are also grateful to Gabrielle Musillo and tothe anonymous reviewers of an earlier version of959this paper for useful comments and suggestions.ReferencesMorton Benson.
1990.
Collocations and general-purpose dictionaries.
International Journal of Lexi-cography, 3(1):23?35.Elisabeth Breidt.
1993.
Extraction of V-N-collocationsfrom text corpora: A feasibility study for Ger-man.
In Proceedings of the Workshop on VeryLarge Corpora: Academic and Industrial Perspec-tives, Columbus, U.S.A.Yaacov Choueka.
1988.
Looking for needles in ahaystack, or locating interesting collocational ex-pressions in large textual databases expressions inlarge textual databases.
In Proceedings of the In-ternational Conference on User-Oriented Content-Based Text and Image Handling, pages 609?623,Cambridge, MA.Anthony P. Cowie.
1978.
The place of illustrative ma-terial and collocations in the design of a learner?sdictionary.
In P. Strevens, editor, In Honour of A.S.Hornby, pages 127?139.
Oxford: Oxford UniversityPress.D.
Alan Cruse.
1986.
Lexical Semantics.
CambridgeUniversity Press, Cambridge.Gae?l Dias.
2003.
Multiword unit hybrid extraction.In Proceedings of the ACL Workshop on MultiwordExpressions, pages 41?48, Sapporo, Japan.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
ComputationalLinguistics, 19(1):61?74.Stefan Evert and Hannah Kermes.
2003.
Experi-ments on candidate data for collocation extraction.In Companion Volume to the Proceedings of the 10thConference of The European Chapter of the Associ-ation for Computational Linguistics, pages 83?86,Budapest, Hungary.Stefan Evert.
2004.
The Statistics of Word Cooccur-rences: Word Pairs and Collocations Word Pairs andCollocations.
Ph.D. thesis, University of Stuttgart.John Rupert Firth.
1957.
Papers in Linguistics 1934-1951.
Oxford Univ.
Press, Oxford.Ray Jackendoff.
1997.
The Architecture of the Lan-guage Faculty.
MIT Press, Cambridge, MA.John S. Justeson and Slava M. Katz.
1995.
Technicalterminology: Some linguistis properties and an al-gorithm for identification in text.
Natural LanguageEngineering, 1:9?27.Brigitte Krenn and Stefan Evert.
2001.
Can we dobetter than frequency?
A case study on extractingPP-verb collocations.
In Proceedings of the ACLWorkshop on Collocations, pages 39?46, Toulouse,France.Dekang Lin.
1998.
Extracting collocations from textcorpora.
In First Workshop on Computational Ter-minology, pages 57?63, Montreal.Christopher Manning and Heinrich Schu?tze.
1999.Foundations of Statistical Natural Language Pro-cessing.
MIT Press, Cambridge, Mass.Kathleen R. McKeown and Dragomir R. Radev.
2000.Collocations.
In Robert Dale, Hermann Moisl,and Harold Somers, editors, A Handbook of Nat-ural Language Processing, pages 507?523.
MarcelDekker, New York, U.S.A.Igor Mel?c?uk.
1998.
Collocations and lexical func-tions.
In Anthony P. Cowie, editor, Phraseology.Theory, Analysis, and Applications, pages 23?53.Claredon Press, Oxford.Brigitte Orliac and Mike Dillinger.
2003.
Collocationextraction for machine translation.
In Proceedingsof Machine Translation Summit IX, pages 292?298,New Orleans, Lousiana, U.S.A.Darren Pearce.
2001.
Synonymy in collocation extrac-tion.
In WordNet and Other Lexical Resources: Ap-plications, Extensions and Customizations (NAACL2001 Workshop), pages 41?46, Carnegie MellonUniversity, Pittsburgh.Pavel Pecina.
2005.
An extensive empirical study ofcollocation extraction methods.
In Proceedings ofthe ACL Student Research Workshop, pages 13?18,Ann Arbor, Michigan, June.
Association for Com-putational Linguistics.Ivan A.
Sag, Timothy Baldwin, Francis Bond, AnnCopestake, and Dan Flickinger.
2002.
Multiwordexpressions: A pain in the neck for NLP.
In Pro-ceedings of the Third International Conference onIntelligent Text Processing and Computational Lin-guistics (CICLING 2002), pages 1?15, Mexico City.Violeta Seretan and Eric Wehrli.
2006.
Multilingualcollocation extraction: Issues and solutions solu-tions.
In Proceedings or COLING/ACL Workshopon Multilingual Language Resources and Interoper-ability, Sydney, Australia, July.
To appear.Violeta Seretan, Luka Nerima, and Eric Wehrli.
2003.Extraction of multi-word collocations using syn-tactic bigram composition.
In Proceedings ofthe Fourth International Conference on Recent Ad-vances in NLP (RANLP-2003), pages 424?431,Borovets, Bulgaria.Frank Smadja.
1993.
Retrieving collocations formtext: Xtract.
Computational Linguistics, 19(1):143?177.Eric Wehrli.
2004.
Un mode`le multilingue d?analysesyntaxique.
In A. Auchlin et al, editor, Structureset discours - Me?langes offerts a` Eddy Roulet, pages311?329.
E?ditions Nota bene, Que?bec.960
