Coling 2010: Poster Volume, pages 869?875,Beijing, August 2010Support or Oppose?Classifying Positions in Online Debatesfrom Reply Activities and Opinion ExpressionsAkiko Murakami1,2 Rudy Raymond11 IBM Research - Tokyo2 Graduate School of Interdisciplinary Information Studies, The University of Tokyo{akikom,raymond}@jp.ibm.comAbstractWe propose a method for the task of iden-tifying the general positions of users inonline debates, i.e., support or oppose themain topic of an online debate, by ex-ploiting local information in their remarkswithin the debate.
An online debate isa forum where each user post an opin-ion on a particular topic while other usersstate their positions by posting their re-marks within the debate.
The supportingor opposing remarks are made by directlyreplying to the opinion, or indirectly toother remarks (to express local agreementor disagreement), which makes the task ofidentifying users?
general positions diffi-cult.
A prior study has shown that a link-based method, which completely ignoresthe content of the remarks, can achievehigher accuracy for the identification taskthan methods based solely on the contentsof the remarks.
In this paper, we showthat utilizing the textual content of theremarks into the link-based method canyield higher accuracy in the identificationtask.1 IntroductionSocial computing tools, such as a SNS (So-cial Network Service) or an online discussionboard have become very powerful communicationtools for discussing topics with people around theworld.
Many companies use these kinds of socialcomputing tools to understand their customers?
re-quirements and their marketing activities.
Socialcomputing tools are very useful not only for ag-gregating customers?
opinions outside the com-panies, but also for aggregating their employees?ideas.
For example, IBM has held Jam1 sessions,which are short-term online discussions to aggre-gate ideas from employees and customers.
The re-sults of Jam sessions help management decisions,for instance the technology areas to invest.Not just enterprises, but some nations are try-ing to aggregate their citizens?
ideas in the Internetand provide systems for discussions at the people-to-people levels as part of the movement for opengovernment.
The United States government hasthe Idea Factory2 website for collecting ideas toenhance activities of Department of HomelandSecurity (DHS) and the Open For Questions3 tocollect requests for the US government.The motivation for creating these kinds of on-line discussions is not limited to collecting ideasbut also to help understand the trends of opinionsabout the ideas or topics.
This means that gettinga quick overview of opinions about ideas is a keypoint for the success of online discussions.In this paper we propose a method to showquick overview of participants?
positions, ?Sup-port?
or ?Oppose?
for the main idea or topic inonline debates.
It is difficult to identify each per-son?s position for a topic directly, since most ofopinionative expressions are made not for maintopic but for adjacent remarks.
This causes a dif-ficulty in building answer sets for classifier.
Thefollowing example shows opinion expressions fora main topic focused on an adjacent remark in a1https://www.collaborationjam.com2http://www.whitehouse.gov/open/innovations/IdeaFactory3http://www.whitehouse.gov/OpenForQuestions/869Figure 1: Identifying users?
positions from their opinions about previous remarksdebate.
In this example, The main topic is ?Traveland F2F (face-to-face) meeting is fundamental tobusiness?.Remark A Travel isn?t necessary be-cause besides the high cost of trav-els around the world, today wehave a lot of communication tools,for instance web conference, videochat that can easily contribute tojoin leaders around the world in acheaper way.Remark B I disagree.
Without traveland F2F meetings global integra-tion does not work as well or asquickly.
It doesn?t mean that ev-erybody has to travel all the time,but at least some meetings are keyto success.The author of Remark A mentions that travel isnot necessary to business.
This opinion opposedto the main topic, so that the position for the maintopic is ?Oppose?.
In contrast, the opinion expres-sion in Remark B is not an opinion about the maintopic, but relates to the previous opinion in Re-mark A.
This opinion expression indicates that theauthor of Remark B disagrees with the opinion ofRemark A, and indirectly implies agreement withthe main topic.
Thus, although it is hard to inferthe global position of Remark B from only the sur-face expressions, it is straightforward to infer thatan opinion in Remark B about Remark A is nega-tive (i.e., Remark B expresses disagreement withRemark A).In this paper, positions with regards to the maintopic (global positions) are classified into twoclasses: support and oppose, while opinions aboutthe previous remarks (local positions) are classi-fied into three: agree, disagree, and neutral.
Forexample, let us consider the case in Fig.
1, whereRemark ?a?
is the main topic, and Remark ?b?
isthe reply to Remark ?a?
and Remark ?c?
is thereply to Remark ?b?.
Here, let b(a) be the localposition, that is, opinion (agree/disagree/neutral)in Remark ?b?
on the topic in Remark ?a?.
Forexample, if b(a) and c(b) are disagree, one can de-termine that the authors of the corresponding re-marks are in the opposition.
That is, the author ofRemark ?c?
agrees with Author A (the author ofRemark ?a?
), that is, the main topic, while AuthorB is against the others.
On the contrary, if b(a) isdisagree and c(b) is agree, then Author C agreeswith Author B and therefore it implies that AuthorC is against Author A.
In this case, only Author Asupports the main topic while Author B and Au-thor C oppose to the main topic.To infer supporting or opposing positions withregards to the main topic, two steps are used.
First,the degree of disagreement between any two usersis computed from the link structure and the text of870each pair of their adjacent replies.
This is used asthe link weight between nodes (which correspondto users in a debate) in the network.
Second, thebipartition of the users in the weighted network iscomputed by finding a bipartition that induces themaximum cut of the network, a partition of nodesinto two disjoint sets that maximizes the sum ofthe weights of the links connecting nodes in dif-ferent sets.
Since the weight of the links is higher(more positive) when the degree of disagreementis higher, the bipartition is expected to express twogroups of opposing positions.In order to evaluate the performance of ourmethod, we conducted some experiments to iden-tify the supporting and opposing positions of par-ticipants in online debates.
The experimental re-sults indicate that our method leads to higher pre-cision than the baseline method, which is de-scribed in (Agrawal et al, 2003).The rest of this paper is organized as follows.First we describe related work in Section 2, andin Section 3 we propose our method for identify-ing participants?
positions from their reply activi-ties and text contents.
In Section 4 we explain thedata sets used for the evaluations and show the ex-perimental results of an opinion classifier for ad-jacent remarks and a support/oppose classifier forthe participants in online debates.
We concludethis paper and describe future work in Section 5.2 Related WorkThere are some research papers published on anal-ysis of online discussions.
Some researches re-ported on how to analyze and navigate IBM Jamsessions.
Millen et al pointed out the importanceof supporting the participants in discussions anddemonstrated the effectiveness of their methodsin one of these jams (Millen and Fontaine, 2003).Dave et al described ways for jam participants tonavigate using visualization techniques (Dave etal., 2004).
One of the authors previously also pro-posed a method to mine discussion records usingXML annotations (Murakami et al, 2001) and amethod to find important remarks in a discussionthread based on the reply-to structure and partici-pants?
opinions (Murakami et al, 2007).Classifying agree/disagree opinions in conver-sational debates using Bayesian networks waspresented in (Galley et al, 2004).
Agrawal et aldescribed an observation that reply activities showdisagreement with previous authors, and showed amethod to classify the supporting/opposing posi-tion of users based on this observation in (Agrawalet al, 2003).
Thomas et al (Thomas et al, 2006)introduced some constraints that a single speakerretains the same position for the classificationof participants?
positions from floor-debate tran-scripts.3 Proposed Method3.1 Calculating the Reaction Coefficientbetween participantsWe call the degree of divergence in the opinionsbetween participants a reaction coefficient.
Thisreaction coefficient is defined as a function of theparticipants i, j, represented as r(i, j).
To calcu-late reaction coefficients, we extracted pairs of aremark and its reply remark, and assigned ?localposition flags?
to the pairs.
There are three lo-cal position flags, ?agree?, ?disagree?, and ?neu-tral?.
The reaction coefficient r(i, j) between par-ticipants i and j is defined as:r(i, j) = ?Ndisagree(i, j)+?Nneutral(i, j)+?Nagree(i, j),(1)where Nopinion(i, j) is the number of remark pairswith opinion as the corresponding local positionflag between participants i and j.Typically we assign a positive value to ?, aslightly positive value to ?, and a negative valueto ?.
This means that r(i, j) is positive when thereare only neutral remarks between user i and j.This is based on the hypothesis in (Agrawal et al,2003) that replies usually indicate disagreementwith previous remarks.
There is no directionalityin reaction coefficients so that r(i, j) = r(j, i).3.2 Classification of Participants?
Positionsbased on the Max Cut ProblemLet the graph corresponding to the activity net-work of the participants in an online debate beG(V,E), where V is the set of nodes that corre-sponds to participants and E is the set of edgeseach of which links participants that exchangedremarks.
For any i, j ?
V , let r(i, j) be the weightof the link between i and j.
A partition of the871Table 1: Ideas and Number of Comments and Participants for the IdeasIdea ID Title # ofComments# ofParticipant# of Remarksper Participant1 Making ?IT?
Education as a CompulsorySubject in Schools 75 45 1.72 Making Personal-Computer Makers toSupplying Service Parts 130 21 6.23 Adoption of ?Basic Income?
118 57 2.14 Votes in elections using Closed Networks 108 40 2.75 Computerized Books in Libraries 50 12 4.2participants into supporting and opposing parties,Ssup and Sopp respectively, is computed by solv-ing the max cut problem on G(V,E) defined asfollows.
[Max cut problem] Given G(V,E) as above,find a bipartition of V into Ssup and Sopp =V \ Ssup so that?i?Ssup,j?Sopp r(i, j) is max-imized.The max cut problem is known to be NP-hard,and thus in general is difficult to solve.
How-ever, good approximation algorithms based onLinear Programming and Semidefinite Program-ming have been developed recently, and combinedwith branch-and-bound techniques a good exactmax-cut solver called BiqMac exists (Rendl et al,2010).
We used BiqMac for solving the max cutproblem exactly on the activity network.
Althougha faster approximate max cut solver is used in(Agrawal et al, 2003), it is based on the limitingassumption that the size of Sopp is approximatelythe same as Sopp.
This cannot be assumed for thenetworks in this paper.4 Experiments4.1 CorpusThe Ministry of Economy, Trade and Industryin Japan (METI) was accepting public opinionson e-government programs via the ?e-METI IdeaBox4?
from February 23 to March 15 2010.
Par-ticipants could show their positions for the ideassince the site accepted comments on the main ideaand other comments, so this discussion can be re-garded as a kind of debate.
We used this data4http://www.meti.go.jp/policy/it policy/open-meti/to evaluate our proposed method.
The ideas andcomments were written in Japanese and the datais available at the METI website.For the 936 ideas that were posted to the IdeaBox, we examined 17 ideas with more than 40comments.
Finally we selected five ideas for theevaluation.
The numbers of remarks (a main ideaand comments), participants, and remarks per par-ticipants are shown in Table 1.We extracted the reply-to structure informationin textual contents.
The Idea Box system had acapability to adding a comment to a main topicor the other comment, and the system insertedan identifier in comment?s text.
Each identifierstarted with ?#?
and the IDs of the previous com-ments followed the identifier, such as ?#003?
(with #001 referring to the main topic in thethread).
An idea or comments may have severalcomments as replies, so this reply-to structure in adebate is a tree structure whose root node is themain topic.
A typical reply-to tree structure isshown in Fig 2.4.2 Agree/Disagree ClassificationTo calculate the reaction coefficients, we need toextract the reply-to pairs and classify these pairsinto the agree/disagree/neutral classes.
To classifythese remark pairs we use opinionative and senti-ment expressions.
If a reply remark contains anexpression of ?I agree with you?
then it should beclassified into the agree class.
Another exampleof expressions of the agree class would be ?That?sa good idea!
?.To extract expressions of opinion, we cre-ated a simple pattern dictionaries that contains872Figure 2: Reply-to Structure of a Debateagree/disagree expressions.
For instance, ?I dis-agree with your idea?
and ?I don?t agree with you?are in the disagree pattern dictionary.
At the sametime we use a sentiment analysis tool to extractsentiment expressions.
The tool we used for sen-timent expression extractions is the same as de-scribed in (Kanayama et al, 2004), which use ma-chine translation techniques to identify sentimentexpressions in text.
The tool returns sentiment ex-pressions with a sentiment label, favorable or un-favorable.After identifying opinionative and sentimentexpressions in the remarks, scores for the opin-ion classification are calculated.
The score of eachreply-to pair is the number of agreeing and favor-able expressions minus the number of disagreeingand unfavorable expressions in the reply remark.When the score is positive, the opinion of the pairis identified as agree, and if the score is negativethen the opinion of the pair identified as disagree.If the score equals zero, then the opinion is iden-tified as neutral.To evaluate this opinion classifier, we did anexperiment with the METI data, which was man-ually assigned agree/disagree/neutral flags.
Theanswers for these evaluation were created by usfor three of the idea threads (Idea IDs #1,#2 and#3).
Since most remarks do not have agree or dis-agree expressions, most reply-to pairs are classi-fied into the neutral class.
This means that cal-culating precision and recall for the neutral classare not important.
For the evaluation of the clas-Table 2: Accuracy of opinion classification forreply-to pairsIdea ID Precision Recall1 0.63 0.252 0.62 0.143 0.44 0.38Ave.
0.56 0.26sifier we calculated precisions and recalls only foragree and disagree classes.
The results are shownin Table 2.4.3 Support/Oppose ClassificationUsing the numbers of agree/disagree/neutralreply-to pairs, we can calculate the reaction co-efficients for each pair of participants.
After cal-culating the reaction coefficients for all of the par-ticipants?
pairs, we can classify each participantinto support or oppose sets using the max cut tech-nique.
In this subsection, we explain how to eval-uate our proposed method and show experimentalresults.4.3.1 Answer Sets for Global PositionClassificationTo evaluate our method we created answer setsfor a global position classifier, consisting of par-ticipant sets with the position labels Support orOppose.
We identified the positions of the par-ticipants?
remarks with contexts, but we assignedthe ?Unclear?
label for some participants sincetheir remarks did not contain enough informationto classify their global positions.
For showing thevalidity of the answer sets, two annotators anno-tated three ideas and calculated a ?
value.
The ?value is 0.69 so that this answer set is appropri-ate as an evaluation set.
The use of the answer setannotated by a single annotator for the evaluationof support/oppose classification is justified sincethe agreement rate (the ?
value) is enough for theevaluation.4.3.2 Evaluation Index for PositionClassificationFor evaluation we defined the estimation indexaccuracy since the number of participants in theSupport position is not always the same as the873number of participants in the Oppose position.If the answers are grossly one-sided, the generalaccuracy does not work well, since the systemcan lead to a high score when it classifies all ofthe participants into the larger side.
To minimizethis potential bias, we defined an estimation in-dex accuracy using the average of the accuraciesfor the Support/Oppose sets.
The estimation indexaccuracy is defined as:accuracy = 12( |Asup ?
Ssup||Asup|+ |Aopp ?
Sopp||Aopp|), (2)where Asup and Aopp are the Support and Op-pose participant sets in the answer set and Ssupand Sopp are the Support and Oppose participantsets generated by the system, respectively.
Foraccuracy, we ignore ?Unclear?
users since thesystem is a two-class classifier.4.3.3 Experimental ResultsIn the experiments we use the reaction coeffi-cients r(i, j) calculated based on the results of theagree/disagree/neutral Classifier, and classify par-ticipants into Support/Oppose position sets usingBiqMac.
Since we assumed that the main topic ofthe debate is the first remark of the debate thread,we assume that the set which includes the authorof the first remark as the ?Support?
set and theother set as the ?Oppose?
set5.We conducted experiments for (?, ?, ?)
=(1, 0, 0), (1, 0.5, 0), (1, 0.5,?1) in Eq.
(1) to ex-amine the dependency of the accuracy on the co-efficients r(i, j).
We also conducted an experi-ment for (1, 1, 1), which is regarded as a baselinemethod described in (Agrawal et al, 2003), sinceall of the reply actions represent ?disagree?
opin-ions for the previous remarks with these parame-ter.
The experimental results are shown in Table3.The ideas other than ID 1 show better accu-racy than the baseline and their accuracies tendto increase in the order of (1, 0, 0), (1, 0.5, 0),(1, 0.5,?1).
This result shows that the effec-tiveness of distinguishing between ?disagree?
and?agree?
replies.
This distinction makes it possibleto introduce the constraint in which the user pairs5For this reason, the values of the accuracies can be lowerthan 0.5.Table 3: Accuracy of Support/Oppose positionclassificationID Baseline (1,0,0) (1,0.5,0) (1,0.5,-1)1 47.86 66.67 54.52 54.052 66.43 76.43 76.43 89.293 46.47 48.88 42.63 55.454 53.19 51.52 55.36 77.605 66.67 58.33 66.67 75.00with ?disagree?
and ?neutral?
should be classi-fied into opposing positions and user pairs with?agree?
should be classified into same position inthe Support/Oppose user sets.At the same time, ID 1 shows lower accuracyfor (1, 0.5, 0), (1, 0.5,?1) even though the accu-racy of agree/disagree classifier is good.
In ideaID 1, the number of remarks per participant is thelowest in data sets, so the errors of the Agree-ment/Disagreement classifier strongly affect theresults of the Support/Oppose classifier.5 Conclusion and Future WorkWe have shown how to classify users in an onlinedebate based on their general positions with re-gards to the main topic by the textual contents oftheir remarks and the link structure of their replies.The previous work used the assumption that thereplies are usually disagreements and based onthis assumption used a link-based method to clas-sify the participants.
However, in an online debatethe replies are also used for clarifying previousremarks and quite often for supporting the previ-ous ones.
Our proposed method uses not only thelink structure of the replies, but also the textualcontents of the local agreement/disagreement po-sitions between the remarks to boost the accuracyof the task of classifying users into the supportingand opposing parties.The proposed method is based on the observa-tion that it is easier to use the textual contents forclassifying the local positions of a user?s replieswith regards to the previous remarks, than to usethem (e.g., by aggregating them) for classifyinghis/her global position with regards to the maintopic of the debate.
In our experiments, we useda rule-based classifier to classify the replies into874agree, disagree, and neutral (with regards to theprevious replies) and used these classifier?s resultto determine the weight of the corresponding linksin the link structure of the reply network.
Themax cut algorithm is then applied to the network,which results in a classification of the users intosupporting or opposing parties (with regards to themain topic of the debate).
The experiments indi-cate that the accuracies of the link-based methodof (Agrawal et al, 2003) can be significantly in-creased by considering the textual contents of thereplies.There are several directions to extend ourmethod.
When an expression of opinion appearsin a reply, we have to locate the target of the opin-ion.
In the current method the target is deter-mined by the ID of the remark pointed by the re-ply.
When the ID is not available, we assume thatthe reply is with regards to the main topic.
How-ever, we also observed that even though a replywas directed to a particular remark, it often alsocontained opinions about the main topic.
Identi-fying such replies can be used to yield higher ac-curacy in the classification task.Much work remains for ultimate understandingof the participants?
opinions in debate corpus.
Un-derstanding the reasons for the position for themain topic is one of the ways to understand theiropinions and it may help to decide the next stepsfor companies or governments which held the de-bate sessions.
An integrated system that includesa discussion system and an analysis system show-ing the ratio of positions and the reasons wouldsupport such purposes.AcknowledgmentsThe authors would like to acknowledge Kenji Hi-ramoto and Manabu Morita, who are responsiblefor the IdeaBox, for their helpful comments andconversation.ReferencesAgrawal, Rakesh, Sridhar Rajagopalan, Ramakrish-nan Srikant, and Yirong Xu.
2003.
Mining news-groups using networks arising from social behav-ior.
In WWW ?03: Proceedings of the 12th interna-tional conference on World Wide Web, pages 529?535, New York, NY, USA.
ACM.Dave, Kushal, Martin Wattenberg, and Michael Muller.2004.
Flash forums and forumreader: navigating anew kind of large-scale online discussion.
In CSCW?04: Proceedings of the 2004 ACM conference onComputer supported cooperative work, pages 232?241, New York, NY, USA.
ACM.Galley, Michel, Kathleen McKeown, Julia Hirschberg,and Elizabeth Shriberg.
2004.
Identifying agree-ment and disagreement in conversational speech:use of bayesian networks to model pragmatic de-pendencies.
In ACL ?04: Proceedings of the 42ndAnnual Meeting on Association for ComputationalLinguistics, pages 669?676, Morristown, NJ, USA.Association for Computational Linguistics.Kanayama, Hiroshi, Tetsuya Nasukawa, and HideoWatanabe.
2004.
Deeper sentiment analysis usingmachine translation technology.
In COLING ?04:Proceedings of the 20th international conference onComputational Linguistics, page 494, Morristown,NJ, USA.
Association for Computational Linguis-tics.Millen, David R. and Michael A. Fontaine.
2003.Multi-team facilitation of very large-scale dis-tributed meetings.
In ECSCW?03: Proceedings ofthe eighth conference on European Conference onComputer Supported Cooperative Work, pages 259?275, Norwell, MA, USA.
Kluwer Academic Pub-lishers.Murakami, Akiko, Katashi Nagao, and Koichi Takeda.2001.
Discussion Mining: Knowledge discoveryfrom online discussion records.
In NLPRS Work-shop XML and NLP, 2001.Murakami, Akiko, Tetsuya Nasukawa, Fusashi Naka-mura, Hironori Takeuchi, Risa Nishiyama, PninaVeisberg, and Hideo Watanabe.
2007.
Innovation-Jam: Analysis of online discussion records usingtext mining technology.
In International Workshopon Intercultual Collaboration 2007 (IWIC2007).Rendl, Franz, Giovanni Rinaldi, and AngelikaWiegele.
2010.
Solving Max-Cut to optimalityby intersecting semidefinite and polyhedral relax-ations.
Math.
Programming, 121(2):307.Thomas, Matt, Bo Pang, and Lillian Lee.
2006.Get out the vote: Determining support or opposi-tion from congressional floor-debate transcripts.
InProceedings of the 2006 Conference on EmpiricalMethods in Natural Language Processing, pages327?335, Sydney, Australia, July.
Association forComputational Linguistics.875
