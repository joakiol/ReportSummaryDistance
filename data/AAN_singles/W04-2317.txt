Towards automatic addressee identification in multi-party dialoguesNatasa JovanovicDepartment of Computer ScienceUniversity of TwentePO Box 217 Enschede, the Netherlandsnatasa@cs.utwente.nlRieks op den AkkerDepartment of Computer ScienceUniversity of TwentePO Box 217 Enschede, the Netherlandsinfrieks@cs.utwente.nlAbstractThe paper is about the issue of addressing inmulti-party dialogues.
Analysis of addressingbehavior in face to face meetings results inthe identification of several addressing mech-anisms.
From these we extract several utter-ance features and features of non-verbal com-municative behavior of a speaker, like gazeand gesturing, that are relevant for observers toidentify the participants the speaker is talkingto.
A method for the automatic prediction ofthe addressee of speech acts is discussed.1 IntroductionCommunication, between humans or between humansand conversational computer agents, involves address-ing.
Addressing has received attention in the traditionof conversation analysis (Clark and Carlson, 1992; Clarkand Schaefer, 1992), but not that much in the commu-nity of computational dialogue systems.
One exception is(Traum, 2003).
An explanation for this lack of attentionmay be that most research in computational dialogue sys-tems concerns systems that were designed for interactionbetween one human user and one conversational agent.In dialogues in which only two participants take part ad-dressing goes without saying.
Addressing becomes a realissue in multi-party conversations and that is the subjectof this paper.There are a number of application areas that could ben-efit from studying addressing behavior in human humaninteractions.
It can provide valuable data for learningmore about human interaction and the way humans in-teract with intelligent environments.
The result can beused by those who develop communicative agents in in-teractive intelligent environments, meeting managers andpresentation assistants.
If we could induce from recordedmeetings the ?who said what, when and to whom?
wecan use this information for making summarizations ofmeetings, and for real-time tracking.Research on small group discussions (Carletta et al,2002) has shown that there is a noticeable difference inthe interaction patterns between large and small groups(up to seven participants).
A small group discussionlooks like two-way conversations but conversations oc-cur between all pairs of members and every member caninitiate conversation.
A large group discussion is morelike a series of conversations between a group leader andvarious individuals with the rest participants present butsilent.
We will focus our research on small group discus-sions in meetings.In this paper we propose research that aims at the au-tomatic determination of the addressee of a speaker insmall meetings.
Analysis of the mechanisms that peopleuse in identifying their addressees leads to a model of aconversation that describes the features that play a rolein these mechanisms.
These features can be of severaltypes: verbal, non-verbal, and features of the situation.Our research is partly based on analysis of the IDIAPmulti-modal meeting data corpus made available throughthe Media File Server 1.2 Addressee detection - problem overviewOne of the question of interest concerning a meeting is:?Who talked to whom and about what during the meet-ing??.
This question refers to three very important as-pects of a conversational event: source of the message(speaker identification), topic of the message (topic de-tection) and addressee of the message (addressee identi-fication).Speaker and addressee roles are the basic conversa-tional roles.
There are different ways to categorize theaudience of a speech act.
We use a taxonomy of con-versational roles proposed in (Clark and Carlson, 1992).People around an action are divided in those who re-1http://mmm.idiap.chally participate in the action (active participants) andthose who do not (non-participants).
The active partic-ipants in a conversation include speaker and addressee aswell as other participants taking part in conversation butcurrently not being addressed.
Clark called them side-participants.
All other listeners who have no rights totake part in conversation are called overhearers.
Over-hearers are divided in two groups: bystanders and eaves-droppers.
Bystanders are overhearers who are present andthe speaker is aware of their presence.
Eavesdroppers arethose who are listening without the speakers awareness.In determining the conversational roles in a meeting situ-ation we will focus on the active participants.
The prob-lem of addressee identification amounts to the problem ofdistinguishing the addressee from the side participants ina conversation.According to dialogue act theory (Bunt, 2000) an ut-terance can consist of several segments which carry dif-ferent dialogue acts.
Each of these dialogue acts can haveit?s own addressee.
The following example is an exampleof multi-addressee utterances.A: We could use Java as a standard?
[suggestion] addressee B,CB: yes?
but what about C++ ?
[agreement]addressee A?
[suggestion]addressee A,CC: Both is OK for me[accept] addressee A,B3 Observation analysis - addresseedetection in meetingsThree main questions considering addressee detectionsare: 1.
What are the relevant sources of information forthe addressee detection in face-to-face meetings?
2.
Howdoes the speaker express who is the addressee of his ut-terance?
3.
How can we combine all this information inorder to determine the addressee of the speaker utterance?In order to find answers on these questions we ob-served meetings recorded at the IDIAP and annotatedseveral of them.
For annotation we used the NITE Work-bench for Windows (NWB3) annotation tool 2.
We de-fined our annotation scheme based on the initial assump-tions about the information sources that can be used forthe addressee identification.
These assumptions are theresult of our meeting observations.3.1 Sources of informationWhen two or more people are engaged in interactionthey communicate using verbal and/or non-verbal ele-ments.
The most natural and powerful human commu-nication is in combined use of words, gaze, facial andgestural movements, posture, bodily contact, etc.2http://nite.nis.sdu.dk/download/.
NWB The NITE Work-bench is a general-purpose natural interactivity coding tool3.1.1 SpeechSpeech is the main communication channel used in themeeting conversation.
Therefore, it is the main sourcefor addressee detection.
The most common heuristics thatmay guide the addressee recognition process is the searchfor linguistic markers in the utterance.
Table 1 containslinguistic markers that can be used as cues for addresseedetection.
For instance, you is the personal pronoun thatrefers to the meeting participants excluding the speaker ofthe utterance.
Usage of quantifying determiners, numer-als and indefinite pronouns may help in distinguish youas a particular person from you as a group.
If an utter-ance contains noun phrases like some of you, few of you,most of you, etc., then it is addressed to all meeting par-ticipants.
The speaker doesn?t know who he is actuallyaddressing (He saw some of you yesterday).Name detection is a powerful method for addresseedetermination.
The name in vocative form is used for di-rect addressing the person with that name (What aboutyou, John?).
Using the name of the participant thespeaker can claim something about the participant ad-dressing the utterance to the other addressee (John wasnot present et the last meeting).Dialogue acts.
There is a relation between addresseesof an utterances and the type of the dialogue act thespeaker performed.
Sometimes the description of a di-alogue act includes the possible addressees of the act.Therefore, knowledge about the dialog act is used as a cuefor addressee detection.
For dialogue act annotation weuse the Meeting Recorder Dialogue Acts (MRDA) tag set(Dhillon et al, 2003).
The MRDA is a tag set for labelingmultiparty face-to-face meetings.
The tags in the MRDAset are organized into thirteen groups according to syn-tactic, semantic, pragmatic and functional characteristicof the utterance they mark.
For addressee detection pur-poses we used a large subset of the MRDA tag set but weorganized them at two levels: forward looking function(FLF) and backward looking function (BLF).
FLF rep-resents the effect that an utterance has on the subsequentinteraction.
BLF indicates how an utterance relates to theprevious discourse.
If an utterance has both functions thecorresponding addressee is the addressee of the BLF.When an utterance is marked with a BLF it is relatedto one of the previous utterances in the conversation.
Theaddressee of the associated dialogue act in most cases isthe speaker of the related utterance.
However, it is pos-sible that the speaker of the related utterance is the sameas the current speaker.
For instance, a speaker can repeator correct himself.
The addressees of these utterances areaddressees of the related utterances.
Most of the BLFs arerelated to the previous utterances of the other speaker (ac-ceptance tags, answer tags, etc.).
In the multiparty casethere is a number of interesting interaction patterns withrespect to addressee identification.Word classes Example ExamplePersonal pronouns PP I/me, you, she/her, he/him, we/us What do you think about that?Quantifying determiners+PP all of you, some of you, few of you He saw some of you yesterday.Numerals+PP two of you, three of you, last of you Three of you should prepare a presentation.Indefinite pronouns+PP anyone of you, someone of you Did anyone of you finish the job?Possessive pronouns mine, yours, hers, his, ours, theirs Is this yours?Personal adjectives my, your, his, her, our, their I like your style.Indefinite pronouns everybody, somebody, anyone Does anyone have any question?Table 1: Linguistic markers1.A: We could use Java as a standard [suggestion]B: I agree [accept]C: No [reject]D: For me, it is OK [accept]2.A: I think that we should use Java [suggestion]B: I propose C++ [suggestion]C: I don?t agree with you [reject]In the first conversation all responses are related to A?sproposal.
Therefore, A is the addressee of the utterancesexpressed by B, C and D. It means the addressee doesn?thave to be the previous speaker.
In the second example itis not clear whether C rejects A?s or B?s proposal or bothproposals.
Additional information obtained from visualchannels can help in resolving the addressee ambiguity.Unlike BLFs, FLFs do not provide much informationabout the addressee of a speaker?s utterance.
Yet, someassumptions about the utterance?s addressee are possible,especially if we take in consideration the linguistic mark-ers mentioned above.
For instance, the speaker of an ut-terance marked with some of the question tags directlyaddresses the addressee to provide information.
In com-bination with the use of the personal pronoun we thesequestions are addressed to a subgroup of participants or toall participants rather than to a single person.
Very oftenquestions in meeting discussions are open-ended ques-tions.
An open-ended question is a question that doesnot seek a specific answer.
Rather, it is asked in a broadsense.
An open-ended question is more likely addressedto all meeting participants.
If an open ended questioncontains ?you?
than a single person is the most probableaddressee (What about C?
questions?
What about you?
).Linguistic markers and dialogue acts described aboveprovide us with starting assumptions about the mostlikely addressee.
These assumptions are mostly relatedto a size of the target group i.e.
whether the addressee isa single participant, a group of participant or all partic-ipants.
Therefore, some other communication channelsare used in combination with speech for addressing theutterance.
In the following sections we will describe therole of non-verbal communication channels in addresseedetection.3.1.2 Gaze directionGaze is an important aspect of social interaction (Ar-gyle, 1973).
One of the functions of gaze is channel-control.
Mutual gaze is important when people want toestablish relationship.
Unless the utterance is very shortthe speaker very soon breaks the mutual gaze.
When fin-ishing the utterance, the speaker gazes back to a listener.If the speaker decided to continue to talk at turn transitionpoints, or even before, he usually gazes away.
Need forfeedback effects the speaker?s gaze direction.
Gaze direc-tion shows a participant?s focus of attention.
In the meet-ing scenario where all participants are around the tablethe focus of attention of the current speaker are mostly theother meeting participants.
Since it is almost impossibleto record eye gazing of participants, gaze information isobtained and induced from head movements.
In (Stiefel-hagen and Zhu, 2002) it is shown that we can predict aparticipant focus of attention based on head orientationwith a reliability of 88,7 %.The contribution of gaze information to addressee de-tection is dependent on the current meeting action (dis-cussion, presentation, note-taking, etc.
), the participants?location and the utterance length.
During a presentation aspeaker most probably addresses utterances to all meetingparticipants.
Therefore, information about gaze directionis less relevant for a presentation than for a discussionmeeting action.
When the utterance is short a speakerusually gazes only at one participant or at no one, ad-dressing the utterance at a group of people or at the wholeaudience.
Moreover, information about the visible areasof the participants and hence the relative positions theyhave in the meeting is relevant for interpreting the gazebehavior in terms of focus of attention and it?s contribu-tion to addressing.
During a turn a speaker mostly looksat the participant who are in his visible area.
On the otherhand if he wants to address someone outside his visualarea he will often move his body towards the addressee.The result of automatic or manual gaze annotation isa list of gazed participants or objects, together with timestamps.
For the BLFs the first participant in the list isof interest.
If the participant is not in the speaker?s vis-ible area then the gazed participant is the most likelyaddressee of the speaker utterance.
If the participant isin the speaker?s visible area and he is a candidate fromthe speech analysis then the likelihood that he is the ad-dressee of the speaker utterance is greater.
For the FLFsutterance length and structure of the gaze list play a veryimportant role.
For BLFs the last participant in the gazedlist is of interest.3.1.3 GesturePointing at a person is a way to address a speech actto a person.
It is usually accompanied with gazing at theperson.
Still the addressee of a speaker?s utterance is notnecessarily the same as a person that the speaker pointsat.
When X talks to Y and points at Z, at the same timeX usually verbally refers to Z using a proper noun (nameof people, group name, etc.
), a pronoun (he/she/they,him/her/them, his/her/their, etc.)
or using the role of par-ticipant (boss, chairman, etc.).
This means that X talksto Y about Z.
(Yesterday I met him on the street.
)3.1.4 ContextThe categories of the context that contribute to ad-dressee detection are: interaction history, meeting actionhistory, user context and spatial context.
Interaction his-tory is related to the conversation history and to the non-verbal interaction history.
Conversation history containsthe temporal sequence of speakers, performed dialogueacts and their addressees.
Meeting action history is a se-quence of previous meeting actions including the currentmeeting action.
For instance, if a presentation is fol-lowed by a discussion, the presenter is the more proba-ble addressee of the other participants?
utterances, espe-cially those that are marked as questions.
Spatial con-text includes participants?
location, locations of the en-vironmental objects, distance between participants, par-ticipants?
visible area.
User context includes participantsnames, gender, social roles (status roles and closeness),institutional roles etc.3.2 Towards an automatic addressee detectionAlthough participants or outsiders are most of the timequite sure about the intended addressee of a speaker thisknowledge is essentially error-prone.
Using observa-tional features obtained from different available sourcesthey can only predict the most probable addressee of anutterance.
Methods for addressee detection will either berule based or follow a statistical approach.A rule-based algorithm used for computing addresseein the MRE (Mission Rehearsal Exercise) project isshown in (Traum, 2003).
The rule-based method we in-tend to apply for addressee identification first processesinformation obtained from the utterance.
This returns alist of possible addressees with corresponding probabil-ities.
The probabilities are estimations from annotatedmeeting data.
The idea is first to eliminate cases wherethe addressee is completely determined (names in voca-tive forms, quantifiers and numerals in combination with?you?, etc.).
According to analysis of the relation betweendialogue acts and addressee, different sets of rules are ap-plied for FLFs and BLFs.
For instance, if an utteranceis marked with a BLF that is related to an utterance of aprevious speaker, the addressee is the speaker of the re-lated utterance with probability P .
The following stepsare related to the processing of information from addi-tional sources (gaze and gesture) adding the additionalprobability values to the possible addressee.
Contextualfeatures are used at each level of processing.Given all available multi-modal information E abouta conversational situation a statistical addressee identifi-cation method should classify the addressee for each dia-logue act in the conversation.
As a computational modelwe will use Bayesian networks (BN).
The nodes in theBayesian network will include all observable features asinput variable and one unobservable output variable thatrepresent the addressee.
From some preliminary models,we concluded that Bayesian network used for addresseeclassification of FLFs is more complicated than for BLFs.We therefore consider using separate models for BLFsand FLFs.4 Conclusions and future directionsAddressing is an interesting aspect of communicationand the automatic identification of conversational roles inmulti-party dialogues is an open research problem.
Weexpect that statistical approaches can be applied at thisdomain.
Our future work will be based primarily on ob-taining a huge set of data for training and testing the mod-els.
We will also define new scenario?s for new types ofmeetings that will show more interesting phenomena re-lated to addressing behavior.ReferencesMichael Argyle.
1973.
Social Interaction.
TavistockPublications.H.
Bunt.
2000.
Dialogue pragmatics and context specifi-cation.
In Abduction, Belief and Context in Dialogue;studies in computational pragmatics.
John Benjamins,Amsterdam.Jean Carletta, Anne H. Anderson, and S. Garrod.
2002.Seeing eye to eye: an account of grounding and un-derstanding in work groups.
Bulletin of the Japanesecognitive sciences, 9(1):1?20.Herbert H. Clark and Thomas B. Carlson.
1992.
Hear-ers and speech acts.
In Arenas of Language Use(H.H.Clark ed.).
University of Chicago Press andCSLI.Herbert H. Clark and Edward F. Schaefer.
1992.
Deal-ing with overhearers.
In Arenas of Language Use(H.H.Clark ed.).
University of Chicago Press andCSLI.R.
Dhillon, S Bhagat, H Carvey, and E. Shriberg.
2003.Meeting recorder project:dialogue act labeling guide,version 3.
Technical report, ICSI.Rainer Stiefelhagen and Jie Zhu.
2002.
Head orienta-tion and gaze direction in meetings.
In Conference onHuman Factors in Computing Systems (CHI2002).David Traum.
2003.
Issues in multi-party dialogues.
InAdvances in Agent Communication (F. Dignum, ed.
).Springer-Verlag LNCS.
