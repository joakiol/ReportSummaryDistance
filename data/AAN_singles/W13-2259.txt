Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 464?471,Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational LinguisticsA Dependency-Constrained Hierarchical Model with MosesYvette Graham??
?Department of Computing and Information Systems, The University of Melbourne?Centre for Next Generation Localisation, Dublin City Universityygraham@unimelb.edu.auAbstractThis paper presents a dependency-constrained hierarchical machine transla-tion model that uses Moses open-sourcetoolkit for rule extraction and decoding.Experiments are carried out for theGerman-English language pair in both di-rections for projective and non-projectivedependencies.
We examine effects onSCFG size and automatic evaluationresults when constraints are applied withrespect to projective or non-projectivedependency structures and on the sourceor target language side.1 IntroductionA fundamental element of natural language syntaxis the dependency structure encoding the binaryasymmetric head-dependent relations captured independency grammar theory.
A main criteria fordetermining the dependency structure of a givensentence is the following: The linear position ofdependent, D, is specified with reference to itshead, H (Ku?bler et al 2009).
This runs in parallelwith that which hierarchical machine translationSCFG rules encode: The linear position of a trans-lated phrase, Xi, is specified with reference to thelexicalised words in the rule.
Figure 1 shows de-She lives in a white house .Ella vive en una casa blanca .Figure 1: Projective Dependency Structurespendency structures for She lives in a white houseand its Spanish translation, with example SCFG(1) X ?< white house , casa blanca >(2) X ?< white , blanca >(3) X ?< house , casa >(4) X ?< X0 house , casa X0 >(5) X ?< white X0 , X0 blanca >Figure 2: Initial rules (1), (2) and (3), with hierar-chical rules (4) and (5)rules shown in Figure 2.
Given the existence ofinitial rules (1), (2) and (3), hierarchical rules (4)and (5) can be created.
Rule (4) specifies the lin-ear position of the translation of the English phrasethat precedes house with reference to lexicalisedcasa.For hierarchical machine translation models(Chiang, 2005), there is no requirement for a syn-tactic relationship to exist between the lexicalisedwords of a rule and the words replaced by non-terminals, the only requirement being that substi-tuted words form an SMT phrase (Koehn et al2003).
The dependency structure of either thesource or target (or indeed both) can, however, beused to constrain rule extraction as to only allowhierarchical rules in which the linear position ofdependents are specified with reference to the po-sition of their lexicalised heads.
For example, inthe case of the hierarchical rules in Figure 2, rule(4) satisfies such a constraint according to both thesource and target language dependency structures(since white is the dependent of house and blancais the dependent of casa, and it is both white andblanca that are replaced by non-terminals whilethe heads remain lexicalised) and results in a syn-chronous grammar rule that positions a dependentrelative to the position of its lexicalised head.
Rule(5), on the other hand, does not satisfy such a con-straint for either language dependency structure.In this work, we examine a dependency-constrained model in which hierarchical rules are464only permitted in which lexicalised heads spec-ify the linear position of missing dependents, andexamine the effects of applying such constraintsacross a variety of settings for German to Englishand English to German translation.2 Related WorkThe increased computational complexity intro-duced by hierarchical machine translation mod-els (Chiang, 2005), has motivated techniques ofconstraining model size as well as decoder search.Among such include the work of Zollmann et al(2008) and Huang and Xiang (2010), in which ruletable size is vastly reduced by means of filteringlow frequency rules, while Tomeh et al(2009),Johnson et al(2007) and Yang and Zheng (2009)take the approach of applying statistical signifi-cance tests to rule filtering, with Lee et al(2012)defining filtering methods that estimate transla-tional effectiveness of rules.Dependency-based constraints have also beenapplied in a variety of settings to combat complex-ity challenges.
Xie et al(2011) use source sidedependency constraints for translation from Chi-nese to English, while Shen et al(2010) applytarget-side dependency constraints for the samelanguage pair and direction in addition to Ara-bic to English, Peter et al(2011) also apply de-pendency constraints on the target side, but rathersoft constraints that can be relaxed in the case thatan ill-formed structure does in fact yield a bet-ter translation.
Gao et al(2011) similarly ap-ply soft dependency constraints but to the sourceside for Chinese to English translation, and Galleyand Manning (2009) show several advantages tousing maximum spanning tree non-projective de-pendency parsing decoding for Chinese to Englishtranslation.
Li et al(2012), although not con-straining with dependency structure, instead cre-ate non-terminals with part-of-speech tag combi-nations for Chinese words identified as heads fortranslation into English.In this paper, we apply the same dependencyconstraint to SCFG rule extraction in a varietyof configurations to investigate effects of apply-ing constraints on the source or target side, to thelanguage with most or least free word order, aswell as constraining with non-projective depen-dency structures.Non-Projective DependenciesGerman 38%English 11%Table 1: WMT Parallel Training Data3 Non-Projective DependenciesA non-projectivity structure is defined as follows:A non-projective dependency structure is a depen-dency structure in which at least one dependencyrelation exists between a head, H , and its depen-dent, D, in which the directed path from H toD does not include at least one word positionedlinearly in the surface form between H and D.Figure 3 shows an example non-projective depen-dency structure arising from English Wh-fronting.Non-projective dependencies occur frequentlyWhen did  the crisis begin ?Figure 3: Non-projective Dependency Structurefor many languages, increasingly so for languageswith high levels of free words order.
An exami-nation of Chinese treebanks, for example, reportsthat Chinese displays nine different kinds of non-projective phenomena (Yuelong, 2012) with re-ports of as many as one in four sentences in treebanks having non-projective dependency struc-tures (Nivre, 2007).
Even for a language withrelatively rigid word order such as English non-projectivity is still common, due to Wh-fronting,topicalisation, scrambling and extraposition.
Ta-ble 1 shows the frequency of non-projective de-pendency structures in WMT parallel data sets forGerman and English when parsed with a state-of-the-art non-projective dependency parser (Bohnet,2010).4 Constrained ModelWe define the dependency constraint as follows: tocreate a hierarchical rule by replacing a word orphrase with a non-terminal, all the words of thatphrase must belong to a single complete depen-dency tree and its head must remain lexicalisedin the rule.
In this way, the hierarchical rules ofthe SCFG position missing dependents relative tothe position of lexicalised heads.
Before extract-465ing SCFG rules for the dependency-constrainedmodels, we transform non-projective structuresinto projective ones, in order to allow the sub-stitution of non-projective dependency trees by asingle non-terminal.
Although the transformationsimplifies the dependency structure, it will intro-duce some dis-fluency to the training data, and wetherefore include experiments to examine such ef-fects.Figure 4 shows a German-English translationconstrained by means of the German dependencystructure and Figure 5 shows the full set ofdependency-constrained hierarchical SCFG rules,where dependents are specified with reference tolexicalised heads.5 Implementation with MosesFor rule extraction we use Moses (Williams andKoehn, 2012) implementation of GHKM (Galleyet al 2004; Galley et al 2006), which although isconventionally used to extract syntax-augmentedSCFGs from phrase-structure parses (Zollmannand Venugopal, 2006), we apply the same rule ex-traction tool to dependency parses.
Rule extrac-tion is implemented in such a way as not to be re-stricted to any particular set of node labels.
Theconventional input format is for example:<tree label="NP"><tree label="DET"> the </tree><tree label="NN"> cat </tree></tree>The dependency-constrained ruleset can be ex-tracted with this implementation by arranging de-pendency structures into tree structures as fol-lows:1<tree label="X"><tree label="X"><tree label="X"> the </tree><tree label="X"> black </tree>cat</tree>ate<tree label="X"><tree label="X"> the </tree>rat</tree></tree>Since XML format requires nesting of substruc-tures, only projective dependency structures canbe input to the tool in the way we use it, as non-projectivity breaks nesting.1Note that is is possible to replace X with dependencylabels.6 Non-Projectivity TransformWe therefore transform non-projective depen-dency structures into projective ones by relocat-ing the dislocated dependent to a position closerto its head so that it no longer violates projectivity.We do this in such a way as not to break any ofthe existing dependency relations between pairs ofwords.
Figure 6 shows an example non-projectivestructure (a) before and (b) after the transforma-tion, where the transformation results in the con-stituent comprised of words when and begin form-ing a continuous string, making possible the sub-stitution of this constituent with a non-terminal.The fact that one side of the training data fromwhich hierarchical rules are extracted, however, isno longer guaranteed to be fluent, raises the ques-tion as to what effect this disfluency might havewhen the constraint is applied on the target side.We therefore include in our evaluation for bothlanguage directions (and for the case where theconstraints are applied to the source) the effectsof word reorder cause by the transformation.
TheFigure 6: Non-Projectivity Transformationalgorithm for converting non-projective structuresis an inorder traversal of the dependency struc-ture as follows, where words are indexed accord-ing to their position in the original string prior tothe transformation:Algorithm 6.1: DEP IN ORD(root)for each d ?
D and d.index < root.indexdo dep in ord(d)PRINT(root)for each d ?
D and d.index > root.indexdo dep in ord(d)466Figure 4: German English translation with German dependency structure, words surrounded by a dashedbox form a complete dependency tree.Rules spanning source words 0-6: ich mo?chte nur wenige anmerkungen machen .X0 mo?chte nur wenige anmerkungen machen .
X0 should like to make just a few comments .ich mo?chte X0 .
i should like to X0 .ich mo?chte X0 machen .
i should like to make X0 .ich mo?chte X0 anmerkungen machen .
i should like to make X0 comments .ich mo?chte X0 wenige anmerkungen machen .
i should like to make X0 a few comments .ich mo?chte nur wenige anmerkungen machen X0 i should like to make just a few comments X0non-proj X0 mo?chte X1 .
X0 should like to X1 .X0 mo?chte X1 machen .
X0 should like to make X1 .X0 mo?chte X1 anmerkungen machen .
X0 should like to make X1 comments .X0 mo?chte X1 wenige anmerkungen machen .
X0 should like to make X1 a few comments .X0 mo?chte nur wenige anmerkungen machen X1 X0 should like to make just a few comments X1ich mo?chte X0 X1 i should like to X0 X1ich mo?chte X0 machen X1 i should like to make X0 X1ich mo?chte X0 anmerkungen machen X1 i should like to make X0 comments X1ich mo?chte X0 wenige anmerkungen machen X1 i should like to make X0 a few comments X1X0 mo?chte X1 X2 X0 should like to X1 X2X0 mo?chte X1 machen X2 X0 should like to make X1 X2X0 mo?chte X1 anmerkungen machen X2 X0 should like to make X1 comments X2X0 mo?chte X1 wenige anmerkungen machen X2 X0 should like to make X1 a few comments X2Rules spanning source words 2-5: nur wenige anmerkungen machenX0 machen make X0X0 anmerkungen machen make X0 commentsX0 wenige anmerkungen machen X0 a few commentsRules spanning source words 2-4: nur wenige anmerkungenX0 anmerkungen X0 commentsX0 wenige anmerkungen X0 a few commentsRules spanning source words 2-3: nur wenigeX0 wenige X0 a fewFigure 5: Complete set of dependency-constrained hierarchical SCFG rules for Figure 44677 ExperimentsWMT training data sets were used for both paral-lel (1.49 million German/English sentence pairs)and monolingual training (11.51 million English& 4.74 million German sentences).
Mate non-projective dependency parser (Bohnet, 2010) wasused for parsing both the German and Englishparallel data with standard pre-trained models,the same parser was used for projective parsingwith non-projectivity turned off.2 Parallel train-ing data lines containing multiple sentences weremerged into a single pseudo-dependency structureby adding an artificial root and head-dependent re-lation between the head of the initial sentence andany subsequent sentences.
Non-projective depen-dencies were converted into projective structuresusing Algorithm 6.1.Giza++ (Och et al 1999) was employed forautomatic word alignment, and Moses GHKMrule extraction (Williams and Koehn, 2012) wasused for hierarchical rule extraction for thedependency-constrained models.
Default settingswere used for rule extraction for all models withthe exception on non-fractional counting beingused, as well as Good-turing discounting.
Boththe dependency-constrained and standard mod-els use the same set of initial rules.
For de-coding, since only a single non-terminal, X , ispresent for all models, Moses hierarchical decoder(Koehn et al 2007) was used with default set-tings with the exception of rule span limit being re-moved for all models.
SRILM (Stolke, 2002) wasused for 5-gram language modeling and Kneser-Ney smoothing (Kneser and Ney, 1995) for bothGerman-to-English and English-to-German trans-lation.
MERT (Och, 2003) was carried out onWMT newstest2009 development set optimizingfor BLEU, and final results are reported for held-out test sets, newstest2010 and newstest2011, withBLEU (Papineni et al 2001) and LR-score (Birchand Osborne, 2010) for evaluation.7.1 ResultsTable 2 shows automatic evaluation results forboth the dependency-constrained and standardhierarchical models for both language direc-tions.
Compared to the standard hierarchicalmodel (orig), the best performing dependency-constrained models, sl npr (de-en) and tl npr (en-2OpenNLP (Feinerer, 2012) sentence splitter is recom-mended with the parser we and was used for preprocessing.de), show significant decreases in mean BLEUscore, -0.44 for German to English and -0.13for English to German.
However, there is atrade-off, as the dependency-constrained modelsachieve vast reductions in model size, approx.93% for German to English and 89% for Englishto German in numbers of SCFG hierarchical rules.This results in decreased decoding times, with thebest performing dependency-constrained modelsachieving a decrease of 26% for German to En-glish and 34% for English to German in mean de-coding times.The decrease in BLEU scores is not likely to beattributed to less accurate long-distance reorderingfor German to English translation, as the KendallTau LR-scores for this language direction show anincrease over the standard hierarchical models of+0.25 mean LR.
Although this is not the case forEnglish to German, as mean LR scores show aslight decrease (-0.11 LR).The number of hierarchical rules (not includingglue rules) employed during decoding provides auseful indication of to what degree each model ac-tually uses hierarchical rules to construct transla-tions, i.e.
not simply concatenating phrases withglue rules.
For English to German translation,while the number of hierarchical rules present inthe SCFG is vastly reduced, the number of hier-archical rules used during decoding actually in-creases, with double the number of hierarchicalrules used to translate test segments compared tothe standard hierarchical model, from an averageof only 0.58 hierarchical rules per segment for thestandard model to 1.19 per segment.
This indi-cates that the set of hierarchical rules is refined bythe dependency constraint.When the more linguistically valid non-projective dependency structure, as opposed tothe projective dependency structure, is used toconstrain rule extraction significant increases inBLEU scores are achieved for all configurations.The most significant gains in this respect occurwhen constraints are applied on the source side,+0.58 mean BLEU for German to English and+0.50 mean BLEU for English to German.In general, when constraints are applied to themore free word order language, German, regard-less of whether or not translation is into or out ofGerman, marginally higher BLEU scores result,with an increase of +0.03 mean BLEU for Germanto English translation and similarly an increase of468SCFG mean hier.
mean segmenthier.
rules newstest 2010 newstest 2011 mean rules decode time(millions) BLEU LR-K BLEU LR-K BLEU decoder (seconds)de-enhpborig 35.25 22.30 71.86 20.47 70.55 21.39 2.51 6.76tl re 34.77 22.31 71.43 20.49 70.27 21.40 2.63 6.39tl are 34.77 22.41 71.16 20.36 69.89 21.39 2.68 6.14sl are 33.87 22.40 70.78 20.27 69.78 21.34 2.71 6.02sl re 33.87 22.06 71.38 20.15 70.25 21.11 2.41 6.17dcsl npr 2.49 21.57 71.87 20.09 71.04 20.95 1.15 4.99tl npr 1.45 21.88 72.20 19.95 71.36 20.92 2.85 4.62tl pr 1.12 21.43 71.82 19.75 70.90 20.59 1.40 3.62sl pr 0.34 21.05 72.20 19.69 71.36 20.37 1.10 1.98en-dehpborig 36.30 16.14 70.24 15.05 69.91 15.60 0.58 7.25tl re 35.20 16.13 69.81 14.94 69.45 15.54 1.03 5.16tl are 35.20 16.15 69.06 14.57 68.66 15.36 1.89 4.82sl are 35.68 15.72 69.25 14.44 69.06 15.08 1.88 5.23sl re 35.68 15.72 70.21 14.38 69.84 15.05 1.16 5.16dctl npr 4.00 16.03 70.12 14.91 69.81 15.47 1.19 4.79sl npr 1.09 15.94 70.07 14.85 69.69 15.40 1.78 3.46tl pr 0.92 15.88 70.46 14.78 69.90 15.33 1.23 4.05sl pr 0.88 15.58 70.18 14.22 69.80 14.90 1.19 2.90Table 2: Effects of dependency constraints and dependency-based reordering on translation quality forGerman-to-English (de-en) and English to German (en-de), hpb=hierarchical phrase-based, orig=no re-ordering, ?re=dependency-based word reordering where only hierarchical rules are extracted from re-ordered training data, ?are=dependency-based word reordering where all SCFG rules extracted from re-ordered training data, dc=dependency-constrained, ?pr=projective parse used for dependency constraint,?npr=non-projective parse used for dependency constraint, sl?=constraints or reordering for source lan-guage, tl?=constraints or reordering for target language, numbers of hierarchical rules reported do notinclude glue rules.+0.07 mean BLEU for English to German, withthe increase being statistically significant for Ger-man to English for the newstest2010 test set, butnot statistically significant for newstest2011 testset or English to German (Koehn, 2004).Overall the best performing dependency-constrained models are those that retain the high-est numbers of hierarchical rules in the SCFG.This indicates that although the dependency-constrained models produce a refined ruleset,they nevertheless discard some SCFG rules thatwould be useful to translate the unseen test data.One possible reason is that although the non-projective dependency structures are significantlybetter, these high-quality linguistic structures maystill not be optimal for translation.
Another pos-sibility is that a the GHKM rule extraction con-straints combined with the dependency constraintis causing a small set of very useful rules to bediscarded.7.2 Dependency-based ReorderingWe examine the effects of the non-projectivetransformation in isolation of any dependency-constraints by training a standard hierarchicalmodel on the reordered corpus with no depen-dency constraints applied.
We do this in two set-ups.
First, we extract hierarchical rules from thereordered training corpus and initial rules from theoriginal unaltered corpus (?
re in Table 2), as thisis the set-up for the dependency-constrained mod-els.
Simply for interest sake, we repeat this exper-iment but extract all rules (hierarchical and initialrules) from the reordered corpus (?
are in Table 2).Surprisingly, when non-projective reordering iscarried out on the target side no significant de-crease in BLEU scores occurs for both languagedirections.
In fact, a minor increase in meanBLEU (+0.01) is observed for German to Englishtranslation, but this small increase is not statisti-cally significant.
For the English to German direc-tion, a minor decrease of -0.06 mean BLEU occurs(not statistically significant).Similarly for German to English, when reorder-ing is applied to the source side, only a minordecrease (-0.05) results.
Non-projective reorder-ing causes the most significant reduction in per-formance for English to German when the Englishsource is reordered, with a decrease of -0.52 meanBLEU.469ConclusionsThis paper examines non-projectivity and lan-guage application for dependency-constrainedhierarchical models using Moses open-sourcetoolkit.
Experiments show that when appliedto English to German translation, vastly reducedmodel size and subsequently decreased decodingtimes result with only a minor decrease in BLEU.In addition, higher numbers of (non-glue) hierar-chical rules are used to translate test segments.
ForGerman to English translation, similar decreasesin model size and decoding times occur, but at theexpense of a more significant decrease in BLEU.In general, results for the dependency-constrained models show that applying constraintson the source or target side does not have a majorimpact on BLEU scores.
Rather the use of highquality linguistic structures is more important, assignificant improvements are made for all con-figurations when the non-projective dependencystructure is used to constrain rule extraction.AcknowledgmentsMany thanks to the Moses developers, especiallyHieu Hoang and Alexandra Birch.
Thanks also toTsuyoshi Okita and anonymous reviewers.
Thisresearch was supported by the Australian Re-search Council, as well as Science Foundation Ire-land as part of the Centre for Next Generation Lo-calisation.ReferencesAlexandra Birch and Miles Osborne.
2010.
Lrscore forevaluating lexical and reordering quality in mt.
InProceedings of the Joint Fifth Workshop on Statisti-cal Machine Translation and MetricsMATR, pages327?332, Uppsala, Sweden, July.
Association forComputational Linguistics.Bernd Bohnet.
2010.
Very high accuracy and fast de-pendency parsing is not a contradiction.
In Proceed-ings of the 23rd International Conference on Com-putational Linguistics, pages 89?97.
Association forComputational Linguistics.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the 43rd Annual Meeting on Associationfor Computational Linguistics, pages 263?270.
As-sociation for Computational Linguistics.Ingo Feinerer.
2012. tm: Text mining package.
Rpackage version 0.5-7.1.Michel Galley and Christopher D Manning.
2009.Quadratic-time dependency parsing for machinetranslation.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 2-Volume2, pages 773?781.
Association for ComputationalLinguistics.Michel Galley, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a translation rule?In HLT-NAACL, pages 273?280.Michel Galley, Jonathan Graehl, Kevin Knight, DanielMarcu, Steve DeNeefe, Wei Wang, and IgnacioThayer.
2006.
Scalable inference and trainingof context-rich syntactic translation models.
InProceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, pages 961?968.
Association for Computa-tional Linguistics.Yang Gao, Philipp Koehn, and Alexandra Birch.
2011.Soft dependency constraints for reordering in hier-archical phrase-based translation.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 857?868.
Associationfor Computational Linguistics.Fei Huang and Bing Xiang.
2010.
Feature-rich dis-criminative phrase rescoring for smt.
In Proceed-ings of the 23rd International Conference on Com-putational Linguistics, pages 492?500.
Associationfor Computational Linguistics.Howard Johnson, Joel Martin, George Foster, andRoland Kuhn.
2007.
Improving translation qual-ity by discarding most of the phrasetable.
In Pro-ceedings of the 2007 Joint Conference on EmpiricalMethods in Natural Language Processing and Com-putational Natural Language Learning (EMNLP-CoNLL), pages 967?975.Reinhard Kneser and Hermann Ney.
1995.
Improvedbacking-off for m-gram language modeling.
InProceedings of the IEEE International Conferenceon Accoustics, Speech and Signal Processing, vol-ume 1.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase based translation.
In Pro-ceedings of the Joint Conference on Human Lan-guage Technologies and the Annual Meeting of theNorth American Chapter of the Association of Com-putational Linguistics (HLT-NAACL).Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Christopher J. Dyer, Ondr?ej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open source toolkit for statistical machinetranslation.
In Proceedings of the 45th Annual Meet-ing of the Association for Computational Linguis-tics Companion Volume Proceedings of the Demo470and Poster Sessions, pages 177?180, Prague, CzechRepublic, June.
Association for Computational Lin-guistics.Philipp Koehn.
2004.
Statistical significance tests formachine translation evaluation.
In Dekang Lin andDekai Wu, editors, Proceedings of EMNLP 2004,pages 388?395, Barcelona, Spain, July.
Associationfor Computational Linguistics.Sandra Ku?bler, Ryna McDonald, and Joakim Nivre.2009.
Dependency Parsing.
Synthesis Lectures onHuman Language Technologies.
Morgan & Clay-pool.Seung-Wook Lee, Dongdong Zhang, Mu Li, MingZhou, and Hae-Chang Rim.
2012.
Translationmodel size reduction for hierarchical phrase-basedstatistical machine translation.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics (Volume 2: Short Papers), pages291?295, Jeju Island, Korea, July.
Association forComputational Linguistics.Junhui Li, Zhaopeng Tu, Guodong Zhou, and Josefvan Genabith.
2012.
Using syntactic head infor-mation in hierarchical phrase-based translation.
InProceedings of the Seventh Workshop on Statisti-cal Machine Translation, pages 232?242, Montre?al,Canada, June.
Association for Computational Lin-guistics.Joakim Nivre.
2007.
Incremental non-projectivedependency parsing.
In Proceedings of HumanLanguage Technologies: The Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics (NAACL-HLT), pages396?403, Rochester, NY.Franz Josef Och, Christoph Tillmann, and HermannNey.
1999.
Improved alignment models for sta-tistical machine translation.
In Proceedings of theJoint Conference of Empirical Methods in Natu-ral Language Processing and Very Large Corpora(EMNLP-VLC), pages 20?28.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Erhard Hinrichsand Dan Roth, editors, Proceedings of the 41st An-nual Meeting of the Association for ComputationalLinguistics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
BLEU: a method for automaticevaluation of machine translation.
Technical Re-port RC22176(W0109-022), IBM Research Report,September 17.Jan-Thorsten Peter, Matthias Huck, Hermann Ney, andDaniel Stein.
2011.
Soft string-to-dependency hi-erarchical machine translation.
In Marcello Fed-erico, Mei-Yuh Hwang, Margit Ro?dder, and Sebas-tian Stu?ker, editors, Proceedings of the seventh In-ternational Workshop on Spoken Language Transla-tion (IWSLT), pages 246?253.Libin Shen, Jinxi Xu, and Ralph Weischedel.
2010.String-to-dependency statistical machine transla-tion.
Computational Linguistics, 36(4):649?671.Andreas Stolke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
In Proceedings of the Inter-national Conference on Spoken Language Process-ing, pages 577?585.Nadi Tomeh, Nicola Cancedda, and Marc Dymetman.2009.
Complexity-based phrase-table filtering forstatistical machine translation.
In Proceedings of theTwelfth Machine Translation Summit (MT SummitXII).
International Association for Machine Trans-lation.Philip Williams and Philipp Koehn.
2012.
GHKMrule extraction and scope-3 parsing in moses.
InProceedings of the Seventh Workshop on Statisti-cal Machine Translation, pages 434?440, Montreal,Canada, June.
Association for Computational Lin-guistics.Jun Xie, Haitao Mi, and Qun Liu.
2011.
A noveldependency-to-string model for statistical machinetranslation.
In Proceedings of the 2011 Conferenceon Empirical Methods in Natural Language Pro-cessing, pages 216?226, Edinburgh, Scotland, UK.,July.
Association for Computational Linguistics.Mei Yang and Jing Zheng.
2009.
Toward smaller,faster, and better hierarchical phrase-based smt.
InProceedings of the ACL-IJCNLP 2009 ConferenceShort Papers, pages 237?240, Suntec, Singapore,August.
Association for Computational Linguistics.Wang Yuelong.
2012.
Edge-crossing Non-projectivePhenomena in Chinese Language.
Ph.D. thesis, Na-tional University of Singapore.Andreas Zollmann and Ashish Venugopal.
2006.
Syn-tax augmented machine translation via chart parsing.In Proceedings on the Workshop on Statistical Ma-chine Translation, pages 138?141, New York City,June.
Association for Computational Linguistics.Andreas Zollmann, Ashish Venugopal, Franz JosefOch, and Jay Ponte.
2008.
A systematic comparisonof phrase-based, hierarchical and syntax-augmentedstatistical MT.
In Proceedings of the 22nd Inter-national Conference on Computational Linguistics(Coling 2008), pages 1145?1152, Manchester, UK,August.
Coling 2008 Organizing Committee.471
