Using WordNet-based Context Vectorsto Estimate the Semantic Relatedness of ConceptsSiddharth PatwardhanSchool of ComputingUniversity of UtahSalt Lake City, UT, 84112, USAsidd@cs.utah.eduTed PedersenDepartment of Computer ScienceUniversity of Minnesota, DuluthDuluth, MN, 55812, USAtpederse@d.umn.eduAbstractIn this paper, we introduce a WordNet-based measure of semantic relatednessby combining the structure and contentof WordNet with co?occurrence informa-tion derived from raw text.
We use theco?occurrence information along with theWordNet definitions to build gloss vectorscorresponding to each concept in Word-Net.
Numeric scores of relatedness are as-signed to a pair of concepts by measuringthe cosine of the angle between their re-spective gloss vectors.
We show that thismeasure compares favorably to other mea-sures with respect to human judgmentsof semantic relatedness, and that it per-forms well when used in a word sense dis-ambiguation algorithm that relies on se-mantic relatedness.
This measure is flex-ible in that it can make comparisons be-tween any two concepts without regard totheir part of speech.
In addition, it canbe adapted to different domains, since anyplain text corpus can be used to derive theco?occurrence information.1 IntroductionHumans are able to quickly judge the relative se-mantic relatedness of pairs of concepts.
For exam-ple, most would agree that feather is more relatedto bird than it is to tree.This ability to assess the semantic relatednessamong concepts is important for Natural Lan-guage Understanding.
Consider the following sen-tence: He swung the bat, hitting the ball into thestands.
A reader likely uses domain knowledge ofsports along with the realization that the baseballsenses of hitting, bat, ball and stands are all se-mantically related, in order to determine that theevent being described is a baseball game.Consequently, a number of techniques havebeen proposed over the years, that attempt to au-tomatically compute the semantic relatedness ofconcepts to correspond closely with human judg-ments (Resnik, 1995; Jiang and Conrath, 1997;Lin, 1998; Leacock and Chodorow, 1998).
It hasalso been shown that these techniques prove use-ful for tasks such as word sense disambiguation(Patwardhan et al, 2003), real-word spelling cor-rection (Budanitsky and Hirst, 2001) and informa-tion extraction (Stevenson and Greenwood, 2005),among others.In this paper we introduce a WordNet-basedmeasure of semantic relatedness inspired by Har-ris?
Distributional Hypothesis (Harris, 1985).
Thedistributional hypothesis suggests that words thatare similar in meaning tend to occur in similar lin-guistic contexts.
Additionally, numerous studies(Carnine et al, 1984; Miller and Charles, 1991;McDonald and Ramscar, 2001) have shown thatcontext plays a vital role in defining the mean-ings of words.
(Landauer and Dumais, 1997) de-scribe a context vector-based method that simu-lates learning of word meanings from raw text.
(Schu?tze, 1998) has also shown that vectors builtfrom the contexts of words are useful representa-tions of word meanings.Our Gloss Vector measure of semantic related-ness is based on second order co?occurrence vec-tors (Schu?tze, 1998) in combination with the struc-ture and content of WordNet (Fellbaum, 1998), asemantic network of concepts.
This measure cap-tures semantic information for concepts from con-textual information drawn from corpora of text.We show that this measure compares favorably1to other measures with respect to human judg-ments of semantic relatedness, and that it performswell when used in a word sense disambiguation al-gorithm that relies on semantic relatedness.
Thismeasure is flexible in that it can make comparisonsbetween any two concepts without regard to theirpart of speech.
In addition, it is adaptable sinceany corpora can be used to derive the word vec-tors.This paper is organized as follows.
We startwith a description of second order context vectorsin general, and then define the Gloss Vector mea-sure in particular.
We present an extensive evalua-tion of the measure, both with respect to human re-latedness judgments and also relative to its perfor-mance when used in a word sense disambiguationalgorithm based on semantic relatedness.
The pa-per concludes with an analysis of our results, andsome discussion of related and future work.2 Second Order Context VectorsContext vectors are widely used in InformationRetrieval and Natural Language Processing.
Mostoften they represent first order co?occurrences,which are simply words that occur near each otherin a corpus of text.
For example, police and car arelikely first order co?occurrences since they com-monly occur together.
A first order context vectorfor a given word would simply indicate all the firstorder co?occurrences of that word as found in acorpus.However, our Gloss Vector measure is based onsecond order co?occurrences (Schu?tze, 1998).
Forexample, if car and mechanic are first order co?occurrences, then mechanic and police would besecond order co?occurrences since they are bothfirst order co?occurrences of car.Schu?tze?s method starts by creating a WordSpace, which is a co?occurrence matrix whereeach row can be viewed as a first order contextvector.
Each cell in this matrix represents the fre-quency with which two words occur near one an-other in a corpus of text.
The Word Space is usu-ally quite large and sparse, since there are manywords in the corpus and most of them don?t occurnear each other.
In order to reduce the dimension-ality and the amount of noise, non?content stopwords such as the, for, a, etc.
are excluded frombeing rows or columns in the Word Space.Given a Word Space, a context can then be rep-resented by second order co?occurrences (contextvector).
This is done by finding the resultant of thefirst order context vectors corresponding to eachof the words in that context.
If a word in a contextdoes not have a first order context vector createdfor it, or if it is a stop word, then it is excludedfrom the resultant.For example, suppose we have the followingcontext:The paintings were displayed in the artgallery.The second order context vector would be theresultant of the first order context vectors forpainting, display, art, and gallery.
The wordswere, in, and the are excluded from the resultantsince we consider them as stop words in this ex-ample.
Figure 1 shows how the second order con-text vector might be visualized in a 2-dimensionalspace.dim1dim2ContextVectorgallerydisplayartpaintingFigure 1: Creating a context vector from word vec-torsIntuitively, the orientation of each second ordercontext vector is an indicator of the domains ortopics (such as biology or baseball) that the con-text is associated with.
Two context vectors that lieclose together indicate a considerable contextualoverlap, which suggests that they are pertaining tothe same meaning of the target word.3 Gloss Vectors in Semantic RelatednessIn this research, we create a Gloss Vector for eachconcept (or word sense) represented in a dictio-nary.
While we use WordNet as our dictionary,the method can apply to other lexical resources.3.1 Creating Vectors from WordNet GlossesA Gloss Vector is a second order context vectorformed by treating the dictionary definition of a2concept as a context, and finding the resultant ofthe first order context vectors of the words in thedefinition.In particular, we define a Word Space by cre-ating first order context vectors for every word wthat is not a stop word and that occurs above a min-imum frequency in our corpus.
The specific stepsare as follows:1.
Initialize the first order context vector to azero vector?w.2.
Find every occurrence of w in the given cor-pus.3.
For each occurrence of w, increment those di-mensions of ?w that correspond to the wordsfrom the Word Space and are present withina given number of positions around w in thecorpus.The first order context vector ?w, therefore, en-codes the co?occurrence information of word w.For example, consider the gloss of lamp ?
an ar-tificial source of visible illumination.
The GlossVector for lamp would be formed by adding thefirst order context vectors of artificial, source, vis-ible and illumination.In these experiments, we use WordNet as thecorpus of text for deriving first order context vec-tors.
We take the glosses for all of the conceptsin WordNet and view that as a large corpus oftext.
This corpus consists of approximately 1.4million words, and results in a Word Space ofapproximately 20,000 dimensions, once low fre-quency and stop words are removed.
We chose theWordNet glosses as a corpus because we felt theglosses were likely to contain content rich termsthat would distinguish between the various con-cepts more distinctly than would text drawn froma more generic corpus.
However, in our futurework we will experiment with other corpora as thesource of first order context vectors, and other dic-tionaries as the source of glosses.The first order context vectors as well as theGloss Vectors usually have a very large numberof dimensions (usually tens of thousands) and it isnot easy to visualize this space.
Figure 2 attemptsto illustrate these vectors in two dimensions.
Thewords tennis and food are the dimensions of this 2-dimensional space.
We see that the first order con-text vector for serve is approximately halfway be-tween tennis and food, since the word serve couldNormalizedgloss vectorfor "fork"FoodTennisEatServe= Word Vector= Gloss VectorCutleryFigure 2: First Order Context Vectors and a GlossVectormean to ?serve the ball?
in the context of tennis orcould mean ?to serve food?
in another context.The first order context vectors for eat and cut-lery are very close to food, since they do not havea sense that is related to tennis.
The gloss for theword fork, ?cutlery used to serve and eat food?,contains the words cutlery, serve, eat and food.The Gloss Vector for fork is formed by adding thefirst order context vectors of cutlery, serve, eat andfood.
Thus, fork has a Gloss Vector which is heav-ily weighted towards food.
The concept of food,therefore, is in the same semantic space as and isrelated to the concept of fork.Similarly, we expect that in a high dimensionalspace, the Gloss Vector of fork would be heavilyweighted towards all concepts that are semanti-cally related to the concept of fork.
Additionally,the previous demonstration involved a small glossfor representing fork.
Using augmented glosses,described in section 3.2, we achieve better repre-sentations of concepts to build Gloss Vectors upon.3.2 Augmenting Glosses Using WordNetRelationsThe formulation of the Gloss Vector measure de-scribed above is independent of the dictionaryused and is independent of the corpus used.
How-ever, dictionary glosses tend to be rather short, andit is possible that even closely related concepts willbe defined using different sets of words.
Our be-lief is that two synonyms that are used in differentglosses will tend to have similar Word Vectors (be-cause their co?occurrence behavior should be sim-ilar).
However, the brevity of dictionary glossesmay still make it difficult to create Gloss Vectorsthat are truly representative of the concept.3(Banerjee and Pedersen, 2003) encounter a sim-ilar issue when measuring semantic relatedness bycounting the number of matching words betweenthe glosses of two different concepts.
They ex-pand the glosses of concepts in WordNet with theglosses of concepts that are directly linked by aWordNet relation.
We adopt the same techniquehere, and use the relations in WordNet to augmentglosses for the Gloss Vector measure.
We take thegloss of a given concept, and concatenate to it theglosses of all the concepts to which it is directlyrelated according to WordNet.
The Gloss Vectorfor that concept is then created from this big con-catenated gloss.4 Other Measures of RelatednessBelow we briefly describe five alternative mea-sures of semantic relatedness, and then go on toinclude them as points of comparison in our exper-imental evaluation of the Gloss Vector measure.All of these measures depend in some way uponWordNet.
Four of them limit their measurementsto nouns located in the WordNet is-a hierarchy.Each of these measures takes two WordNet con-cepts (i.e., word senses or synsets) c1 and c2 as in-put and return a numeric score that quantifies theirdegree of relatedness.
(Leacock and Chodorow, 1998) finds the pathlength between c1 and c2 in the is-a hierarchy ofWordNet.
The path length is then scaled by thedepth of the hierarchy (D) in which they reside toobtain the relatedness of the two concepts.
(Resnik, 1995) introduced a measure that isbased on information content, which are numericquantities that indicate the specificity of concepts.These values are derived from corpora, and areused to augment the concepts in WordNet?s is-a hi-erarchy.
The measure of relatedness between twoconcepts is the information content of the mostspecific concept that both concepts have in com-mon (i.e., their lowest common subsumer in theis-a hierarchy).
(Jiang and Conrath, 1997) extends Resnik?smeasure to combine the information contents ofc1, c2 and their lowest common subsumer.
(Lin, 1998) also extends Resnik?s measure, bytaking the ratio of the shared information contentto that of the individual concepts.
(Banerjee and Pedersen, 2003) introduce Ex-tended Gloss Overlaps, which is a measure that de-termines the relatedness of concepts proportionalto the extent of overlap of their WordNet glosses.This simple definition is extended to take advan-tage of the complex network of relations in Word-Net, and allows the glosses of concepts to includethe glosses of synsets to which they are directlyrelated in WordNet.5 EvaluationAs was done by (Budanitsky and Hirst, 2001), weevaluated the measures of relatedness in two ways.First, they were compared against human judg-ments of relatedness.
Second, they were used in anapplication that would benefit from the measures.The effectiveness of the particular application wasan indirect indicator of the accuracy of the related-ness measure used.5.1 Comparison with Human JudgmentOne obvious metric for evaluating a measure of se-mantic relatedness is its correspondence with thehuman perception of relatedness.
Since semanticrelatedness is subjective, and depends on the hu-man view of the world, comparison with humanjudgments is a self-evident metric for evaluation.This was done by (Budanitsky and Hirst, 2001) intheir comparison of five measures of semantic re-latedness.
We follow a similar approach in evalu-ating the Gloss Vector measure.We use a set of 30 word pairs from a studycarried out by (Miller and Charles, 1991).
Theseword pairs are a subset of 65 word pairs used by(Rubenstein and Goodenough, 1965), in a similarstudy almost 25 years earlier.
In this study, humansubjects assigned relatedness scores to the selectedword pairs.
The word pairs selected for this studyranged from highly related pairs to unrelated pairs.We use these human judgments for our evaluation.Each of the word pairs have been scored by hu-mans on a scale of 0 to 5, where 5 is the most re-lated.
The mean of the scores of each pair from allsubjects is considered as the ?human relatednessscore?
for that pair.
The pairs are then ranked withrespect to their scores.
The most related pair is thefirst on the list and the least related pair is at theend of the list.
We then have each of the measuresof relatedness score the word pairs and a anotherranking of the word pairs is created correspondingto each of the measures.4Table 1: Correlation to human perceptionRelatedness Measures M & C R & GGloss Vector 0.91 0.90Extended Gloss Overlaps 0.81 0.83Jiang & Conrath 0.73 0.75Resnik 0.72 0.72Lin 0.70 0.72Leacock & Chodorow 0.74 0.77Spearman?s Correlation Coefficient (Spearman,1904) is used to assess the equivalence of tworankings.
If the two rankings are exactly thesame, the Spearman?s correlation coefficient be-tween these two rankings is 1.
A completely re-versed ranking gets a value of ?1.
The value is 0when there is no relation between the rankings.We determine the correlation coefficient of theranking of each measure with that of the humanrelatedness.
We use the relatedness scores fromboth the human studies ?
the Miller and Charlesstudy as well as the Rubenstein and Goodenoughresearch.
Table 1 summarizes the results of ourexperiment.
We observe that the Gloss Vector hasthe highest correlation with humans in both cases.Note that in our experiments with the GlossVector measure, we have used not only the glossof the concept but augmented that with the glossof all the concepts directly related to it accord-ing to WordNet.
We observed a significant dropin performance when we used just the glosses ofthe concept alone, showing that the expansion isnecessary.
In addition, the frequency cutoffs usedto construct the Word Space played a critical role.The best setting of the frequency cutoffs removedboth low and high frequency words, which elimi-nates two different sources of noise.
Very low fre-quency words do not occur enough to draw dis-tinctions among different glosses, whereas highfrequency words occur in many glosses, and againdo not provide useful information to distinguishamong glosses.5.2 Application-based EvaluationAn application-oriented comparison of five mea-sures of semantic relatedness was presented in(Budanitsky and Hirst, 2001).
In that study theyevaluate five WordNet-based measures of seman-tic relatedness with respect to their performance incontext sensitive spelling correction.We present the results of an application-orientedTable 2: WSD on SENSEVAL-2 (nouns)Measure NounsJiang & Conrath 0.45Extended Gloss Overlaps 0.44Gloss Vector 0.41Lin 0.36Resnik 0.30Leacock & Chodorow 0.30evaluation of the measures of semantic related-ness.
Each of the seven measures of semantic re-latedness was used in a word sense disambigua-tion algorithm described by (Banerjee and Peder-sen, 2003).Word sense disambiguation is the task of deter-mining the meaning (from multiple possibilities)of a word in its given context.
For example, in thesentence The ex-cons broke into the bank on Elmstreet, the word bank has the ?financial institution?sense as opposed to the ?edge of a river?
sense.Banerjee and Pedersen attempt to perform thistask by measuring the relatedness of the senses ofthe target word to those of the words in its context.The sense of the target word that is most related toits context is selected as the intended sense of thetarget word.The experimental data used for this evaluationis the SENSEVAL-2 test data.
It consists of 4,328instances (or contexts) that each includes a singleambiguous target word.
Each instance consists ofapproximately 2-3 sentences and one occurrenceof a target word.
1,754 of the instances includenouns as target words, while 1,806 are verbs and768 are adjectives.
We use the noun data to com-pare all six of the measures, since four of the mea-sures are limited to nouns as input.
The accuracyof disambiguation when performed using each ofthe measures for nouns is shown in Table 2.6 Gloss Vector TuningAs discussed in earlier sections, the Gloss Vectormeasure builds a word space consisting of first or-der context vectors corresponding to every word ina corpus.
Gloss vectors are the resultant of a num-ber of first order context vectors.
All of these vec-tors encode semantic information about the con-cepts or the glosses that the vectors represent.We note that the quality of the words used as thedimensions of these vectors plays a pivotal role in5getting accurate relatedness scores.
We find thatwords corresponding to very specific concepts andare highly indicative of a few topics, make gooddimensions.
Words that are very general in natureand that appear all over the place add noise to thevectors.In an earlier section we discussed using stopwords and frequency cutoffs to keep only the high?information content?
words.
In addition to those,we also experimented with a term frequency ?
in-verse document frequency cutoff.Term frequency and inverse document frequencyare commonly used metrics in information re-trieval.
For a given word, term frequency (tf ) isthe number of times a word appears in the corpus.The document frequency is number of documentsin which the word occurs.
Inverse document fre-quency (idf ) is then computed asidf = logNumber of DocumentsDocument Frequency (1)The tf ?
idf value is an indicator of the speci-ficity of a word.
The higher the tf ?
idf value, thelower the specificity.Figure 3 shows a plot of tf ?
idf cutoff on thex-axis against the correlation of the Gloss Vectormeasure with human judgments on the y-axis.0.60.650.70.750.80.850.90  500  1000  1500  2000  2500  3000  3500  4000  4500Correlationtf.idf cutoffM&CR&GFigure 3: Plot of tf ?
idf cutoff vs. correlationThe tf ?
idf values ranged from 0 to about 4200.Note that we get lower correlation as the cutoff israised.7 AnalysisWe observe from the experimental results that theGloss Vector measure corresponds the most withhuman judgment of relatedness (with a correlationof almost 0.9).
We believe this is probably be-cause the Gloss Vector measure most closely im-itates the representation of concepts in the humanmind.
(Miller and Charles, 1991) suggest that thecognitive representation of a word is an abstrac-tion derived from its contexts (encountered by theperson).
Their study also suggested the semanticsimilarity of two words depends on the overlap be-tween their contextual representations.
The GlossVector measure uses the contexts of the words andcreates a vector representation of these.
The over-lap between these vector representations is used tocompute the semantic similarity of concepts.
(Landauer and Dumais, 1997) additionally per-form singular value decomposition (SVD) on theircontext vector representation of words and theyshow that reducing the number of dimensions ofthe vectors using SVD more accurately simulateslearning in humans.
We plan to try SVD on theGloss Vector measure in future work.In the application-oriented evaluation, the GlossVector measure performed relatively well (about41% accuracy).
However, unlike the human study,it did not outperform all the other measures.
Wethink there are two possible explanations for this.First, the word pairs used in the human relatednessstudy are all nouns, and it is possible that the GlossVector measure performs better on nouns than onother parts of speech.
In the application-orientedevaluation the measure had to make judgments forall parts of speech.
Second, the application itselfaffects the performance of the measure.
The WordSense Disambiguation algorithm starts by select-ing a context of 5 words from around the targetword.
These context words contain words from allparts of speech.
Since the Jiang-Conrath measureassigns relatedness scores only to noun concepts,its behavior would differ from that of the Vectormeasure which would accept all words and wouldbe affected by the noise introduced from unrelatedconcepts.
Thus the context selection factors intothe accuracy obtained.
However, for evaluatingthe measure as being suitable for use in real ap-plications, the Gloss Vector measure proves rela-tively accurate.The Gloss Vector measure can draw conclu-sions about any two concepts, irrespective of part-of-speech.
The only other measure that can makethis same claim is the Extended Gloss Overlapsmeasure.
We would argue that Gloss Vectorspresent certain advantages over it.
The Extended6Gloss Overlap measure looks for exact string over-laps to measure relatedness.
This ?exactness?works against the measure, in that it misses po-tential matches that intuitively would contribute tothe score (For example, silverware with spoon).The Gloss Vector measure is more robust than theExtended Gloss Overlap measure, in that exactmatches are not required to identify relatedness.The Gloss Vector measure attempts to overcomethis ?exactness?
by using vectors that capture thecontextual representation of all words.
So eventhough silverware and spoon do not overlap, theircontextual representations would overlap to someextent.8 Related Work(Wilks et al, 1990) describe a word sense disam-biguation algorithm that also uses vectors to de-termine the intended sense of an ambiguous word.In their approach, they use dictionary definitionsfrom LDOCE (Procter, 1978).
The words in thesedefinitions are used to build a co?occurrence ma-trix, which is very similar to our technique ofusing the WordNet glosses for our Word Space.They augment their dictionary definitions withsimilar words, which are determined using the co?occurrence matrix.
Each concept in LDOCE isthen represented by an aggregate vector created byadding the co?occurrence counts for each of thewords in the augmented definition of the concept.The next step in their algorithm is to form a con-text vector.
The context of the ambiguous wordis first augmented using the co?occurrence ma-trix, just like the definitions.
The context vectoris formed by taking the aggregate of the word vec-tors of the words in the augmented context.
Todisambiguate the target word, the context vectoris compared to the vectors corresponding to eachmeaning of the target word in LDOCE, and thatmeaning is selected whose vector is mathemati-cally closest to that of the context.Our approach differs from theirs in two primaryrespects.
First, rather than creating an aggregatevector for the context we compare the vector ofeach meaning of the ambiguous word with the vec-tors of each of the meanings of the words in thecontext.
This adds another level of indirection inthe comparison and attempts to use only the rele-vant meanings of the context words.
Secondly, weuse the structure of WordNet to augment the shortglosses with other related glosses.
(Niwa and Nitta, 1994) compare dictionarybased vectors with co?occurrence based vectors,where the vector of a word is the probability thatan origin word occurs in the context of the word.These two representations are evaluated by apply-ing them to real world applications and quantify-ing the results.
Both measures are first applied toword sense disambiguation and then to the learn-ing of positives or negatives, where it is requiredto determine whether a word has a positive or neg-ative connotation.
It was observed that the co?occurrence based idea works better for the wordsense disambiguation and the dictionary based ap-proach gives better results for the learning of pos-itives or negatives.
From this, the conclusion isthat the dictionary based vectors contain some dif-ferent semantic information about the words andwarrants further investigation.
It is also observedthat for the dictionary based vectors, the networkof words is almost independent of the dictionarythat is used, i.e.
any dictionary should give us al-most the same network.
(Inkpen and Hirst, 2003) also use gloss?basedcontext vectors in their work on the disambigua-tion of near?synonyms ?
words whose sensesare almost indistinguishable.
They disambiguatenear?synonyms in text using various indicators,one of which is context-vector-based.
ContextVectors are created for the context of the targetword and also for the glosses of each sense of thetarget word.
Each gloss is considered as a bagof words, where each word has a correspondingWord Vector.
These vectors for the words in agloss are averaged to get a Context Vector corre-sponding to the gloss.
The distance between thevector corresponding to the text and that corre-sponding to the gloss is measured (as the cosineof the angle between the vectors).
The nearnessof the vectors is used as an indicator to pick thecorrect sense of the target word.9 ConclusionWe introduced a new measure of semantic relat-edness based on the idea of creating a Gloss Vec-tor that combines dictionary content with corpusbased data.
We find that this measure correlatesextremely well with the results of these humanstudies, and this is indeed encouraging.
We be-lieve that this is due to the fact that the context vec-tor may be closer to the semantic representationof concepts in humans.
This measure can be tai-7lored to particular domains depending on the cor-pus used to derive the co?occurrence matrices, andmakes no restrictions on the parts of speech of theconcept pairs to be compared.We also demonstrated that the Vector measureperforms relatively well in an application-orientedsetup and can be conveniently deployed in a realworld application.
It can be easily tweaked andmodified to work in a restricted domain, such asbio-informatics or medicine, by selecting a spe-cialized corpus to build the vectors.10 AcknowledgmentsThis research was partially supported by a Na-tional Science Foundation Faculty Early CAREERDevelopment Award (#0092784).All of the experiments in this paper werecarried out with the WordNet::Similarity pack-age, which is freely available for download fromhttp://search.cpan.org/dist/WordNet-Similarity.ReferencesS.
Banerjee and T. Pedersen.
2003.
Extended glossoverlaps as a measure of semantic relatedness.
InProceedings of the Eighteenth International Confer-ence on Artificial Intelligence (IJCAI-03), Acapulco,Mexico, August.A.
Budanitsky and G. Hirst.
2001.
Semantic distancein WordNet: An experimental, application-orientedevaluation of five measures.
In Workshop on Word-Net and Other Lexical Resources, Second meeting ofthe North American Chapter of the Association forComputational Linguistics, Pittsburgh, June.D.
Carnine, E. J. Kameenui, and G. Coyle.
1984.
Uti-lization of contextual information in determining themeaning of unfamiliar words.
Reading ResearchQuarterly, 19:188?204.C.
Fellbaum, editor.
1998.
WordNet: An electroniclexical database.
MIT Press.Z.
Harris.
1985.
Distributional structure.
In J. J. Katz,editor, The Philosophy of Linguistics, pages 26?47.Oxford University Press, New York.D.
Inkpen and G. Hirst.
2003.
Automatic sense disam-biguation of the near-synonyms in a dictionary en-try.
In Proceedings of the 4th Conference on Intel-ligent Text Processing and Computational Linguis-tics (CICLing-2003), pages 258?267, Mexico City,February.J.
Jiang and D. Conrath.
1997.
Semantic similar-ity based on corpus statistics and lexical taxonomy.In Proceedings on International Conference on Re-search in Computational Linguistics, Taiwan.T.
K. Landauer and S. T. Dumais.
1997.
A solutionto plato?s problem: The latent semantic analysis the-ory of acquisition, induction and representation ofknowledge.
Psychological Review, 104:211?240.C.
Leacock and M. Chodorow.
1998.
Combining localcontext and WordNet similarity for word sense iden-tification.
In C. Fellbaum, editor, WordNet: An elec-tronic lexical database, pages 265?283.
MIT Press.D.
Lin.
1998.
An information-theoretic definition ofsimilarity.
In Proceedings of International Confer-ence on Machine Learning, Madison, Wisconsin,August.S.
McDonald and M. Ramscar.
2001.
Testing the dis-tributional hypothesis: The influence of context onjudgements of semantic similarity.
In Proceedingsof the 23rd Annual Conference of the Cognitive Sci-ence Society, Edinburgh, Scotland.G.A.
Miller and W.G.
Charles.
1991.
Contextual cor-relates of semantic similarity.
Language and Cogni-tive Processes, 6(1):1?28.Y.
Niwa and Y. Nitta.
1994.
Co-occurrence vec-tors from corpora versus distance vectors from dic-tionaries.
In Proceedings of the Fifteenth Inter-national Conference on Computational Linguistics,pages 304?309, Kyoto, Japan.S.
Patwardhan, S. Banerjee, and T. Pedersen.
2003.Using measures of semantic relatedness for wordsense disambiguation.
In Proceedings of the FourthInternational Conference on Intelligent Text Pro-cessing and Computational Linguistics (CICLING-03), Mexico City, Mexico, February.P.
Procter, editor.
1978.
Longman Dictionary of Con-temporary English.
Longman Group Ltd., Essex,UK.P.
Resnik.
1995.
Using information content to evalu-ate semantic similarity in a taxonomy.
In Proceed-ings of the 14th International Joint Conference onArtificial Intelligence, Montreal, August.H.
Rubenstein and J.B. Goodenough.
1965.
Contex-tual correlates of synonymy.
Communications of theACM, 8:627?633, October.H.
Schu?tze.
1998.
Automatic word sense discrimina-tion.
Computational Linguistics, 24(1):97?123.C.
Spearman.
1904.
Proof and measurement of as-sociation between two things.
American Journal ofPsychology, 15:72?101.M.
Stevenson and M. Greenwood.
2005.
A seman-tic approach to ie pattern induction.
In Proceedingsof the 43rd Annual Meeting of the Association forComputational Linguistics, pages 379?386, Ann Ar-bor, Michigan, June.Y.
Wilks, D. Fass, C. Guo, J. McDonald, T. Plate, andB.
Slator.
1990.
Providing machine tractable dictio-nary tools.
Machine Translation, 5:99?154.8
