Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 964?969,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsSo similar and yet incompatible:Toward automated identification of semantically compatible wordsGerm?an Kruszewski and Marco BaroniCenter for Mind/Brain Sciences (University of Trento, Italy)(german.kruszewski|marco.baroni)@unitn.itAbstractWe introduce the challenge of detecting se-mantically compatible words, that is, wordsthat can potentially refer to the same thing (catand hindrance are compatible, cat and dog arenot), arguing for its central role in many se-mantic tasks.
We present a publicly availabledata-set of human compatibility ratings, and aneural-network model that takes distributionalembeddings of words as input and learns alter-native embeddings that perform the compati-bility detection task quite well.1 IntroductionVectors encoding distributional information ex-tracted from large text corpora provide very effectiveestimates of semantic similarity or, more generally,relatedness between words (Clark, 2015; Erk, 2012;Turney and Pantel, 2010).
Semantic relatedness isundoubtedly a core property of word understand-ing, and indeed current vector-based distributionalsemantic models (DSMs) provide an impressive ap-proximation to human judgments in many tasks (Ba-roni et al, 2014).
However, relatedness alone istoo general a notion to truly capture the nuances ofhuman conceptual knowledge.
The terms animal,puppy, and cat are all closely related to dog, but thenature of their relation is very different, each afford-ing different inferences: If you tell me that Fido isa dog, I will also conclude that he?s an animal, thathe is not a cat, and that he might or might not be apuppy.The previous examples hint at a fundamental se-mantic property that is only partially linked to relat-edness, namely compatibility, that we define, for ourcurrent purposes, as follows: Linguistic expressionsw1and w2are compatible iff, in a reasonably nor-mal state of affairs, they can both truthfully refer tothe same thing.
If they cannot, then they are incom-patible.
We realize that the notion of a ?reasonablynormal sate of affairs?
is dangerously vague, but wewant to exclude science-fiction scenarios in whichdogs mutate into cats.
And we use thing as a catch-all term for anything words (or other linguistic ex-pressions) can refer to (entities, events, collections,etc.
).The notions of compatibility and incompatibilityhave been introduced in theoretical semantics before(Cruse, 1986; Murphy, 2010).
The definition thatwe give here for compatibility is related, but differ-ent from the one by Cruse.
For example, subsumingpairs are out of the scope of compatibility under hisdefinition, whereas we include them.
Murphy de-fines incompatibility similarly to us, but she does notdefine compatibility.
We are not aware, on the otherhand, of any earlier systematic attempt to study thephenomenon empirically, nor to model it computa-tionally.In general, compatible terms will be semanticallyrelated (dog and animal).
However, relatedness doesnot suffice: many semantically related, even verysimilar terms are not compatible (dog and cat).
Re-latedness is not even a necessary condition: A hus-band can be a hindrance in an all-too-normal state ofaffairs, but the concepts of husband and hindranceare not semantically close.
Moreover, compatibil-ity does not reduce to (a set of) more commonlystudied semantic relations.
While it relates to hy-964pernymy, synonymy and co-hyponymy, there arecases, such as husband/hindrance, that do not nat-urally map to any of these relations.
Also, althoughmany incompatibles among closely related pairs areco-hyponyms, this is not necessarily the case: Youcannot be both a dog and a cat, but you can be aviolinist and a drummer.We argue that, since knowing what?s compatibleplays a central role in human semantic reasoning, al-gorithms that determine compatibility automaticallywill help in many domains that require human-likesemantic knowledge.
Most obviously, compatibil-ity is a necessary (although not sufficient) prerequi-site for coreference.
Dog and puppy could belongto the same coreference chain, whereas dog and catdo not.
We conjecture that the relatively disappoint-ing performance of DSMs in support of coreferenceresolution (Poesio et al, 2010) is at least partiallydue to the inability of standard DSMs to distinguishcompatible and incompatible terms.
Compatibilityis also central to recognizing entailment (and contra-diction): Standard DSMs are of relatively little usein recognizing entailment as they treat antonymous,contradictory words such as dead and alive as highlyrelated (Adel and Sch?utze, 2014; Mohammad et al,2013), with catastrophic results for the inferencesthat can be drawn (antonyms are just the tip of the in-compatibility iceberg: dog and cat are not antonyms,but one still contradicts the other).
Knowing what?scompatible might also help in tasks that require rec-ognizing (distant) paraphrases, such as question an-swering, document summarization or even machinetranslation (the violinist also played the drum mightcorefer with the drummer also played the violin,whereas the dog was killed and the cat was killedmust refer to different events).
Other applicationscould include modeling semantic plausibility of anominal phrase (Vecchi et al, 2011; Lynott andConnell, 2009), where the goal is to accept expres-sions like coastal mosquito, but reject parlamentarytomato.
Finally, the notion of incompatibility relatesto (certain kinds of) negation.
Negation is notori-ously difficult to model with DSMs (Hermann et al,2013), and compatibility might offer a new angleinto it.In this paper, we introduce a new, large bench-mark to evaluate computational models on com-patibility detection.
We then present a supervisedneural-network based model that takes distributionalsemantic vectors as input and embeds them into aspace that is optimized for compatibility detection.The model performs significantly better than directDSM relatedness, and achieves high scores in abso-lute terms.2 The compatibility benchmarkWe started the benchmark construction by manuallyassembling a list of 299 words including mostly con-crete, basic-level concepts picked from categorieswhere taxonomically close terms tend to be incom-patible (e.g., biological classes such as animals andvegetables), as well as from categories that are morecompatibility-prone (kinship terms, professions), orsomewhere in the middle (tools, places).
The listalso included category names at different levels ofabstraction (creature, animal, carnivore.
.
.
), as wellas some terms that were expected to be of highgeneral compatibility (hindrance, expert, compan-ion.
.
.
).
By randomly coupling words from this list,we generated pairs that should reflect a wide rangeof compatibility patterns (compatible and incompat-ible coordinate terms, words in an entailment rela-tion, dissimilar but compatible, dissimilar and in-compatible, etc.
).1We generated about 18K suchrandom pairs.We used a subset of about 3K pairs in a pilot studyon the CrowdFlower2crowd-sourcing platforms, inwhich we asked participants to annotate them forcompatibility either as a yes/no judgment accompa-nied by a confidence rating, or on a 7-point scale.Correlation between mean binary and ordinal ratingswas extremely high (>0.95), so we decided to adoptthe potentially more precise, albeit more noisy, 7-point scale.
Confidence judgments (median: 6.6/7),participant agreement and sanity checks on obviouscases confirmed that the raters understood the taskwell and produced the expected judgments consis-tently.We thus launched a larger CrowdFlower survey,1We realize that the resulting pairs might not resemble thenatural distribution of compatibility decisions that an averageperson might encounter in daily life.
However, the fact that(as we show below) subjects were highly consistent in judgingthe items proves that the data reflect genuine shared semanticknowledge a computational model should be able to capture.2http://www.crowdflower.com965asking participants to rate pairs on a 7-point scaleby answering the following question: ?How muchdo you agree with the statement that <word1> and<word2> can refer to the same thing, animal or per-son??
We asked the judges to consider real-life sce-narios and fairly ordinary circumstances; in case ofambiguity, they were asked to choose the sense thatwould make the pair compatible, as long as it wassufficiently common.
20 control items with obviouschoices (e.g.
drummer/ant - writer/father) were in-serted to exclude raters that did not perform the taskseriously.
We paid close attention to contributors?feedback, correcting dubious controls.
For exam-ple, we removed bucket/chair, since one contribu-tor pointed out that you could turn a bucket upsidedown and use it as a chair.3In this way, we obtainedusable annotation for 17973 pairs, each rated by 10participants4.
The average standard deviation was asas low as 0.70, compared to the standard deviationof a uniformly distributed multinomial distribution,which amounts to 1.8.
As expected, ratings werehighly skewed as most random pairs are incompati-ble: the median is 1.10 (with a standard deviation of1.81).
Yet, the overall distribution is bimodal, peak-ing at the two ends of the scale.In order to be able to phrase (in)compatibility de-tection not only in continuous terms, but also asdichotomous tasks, we further produced a list ofunambiguously (in)compatible pairs from the endsof the rating scale.
Specifically, we manually in-spected a subset of the list (before any computa-tional simulation was run), and picked a mean 3.7rating (exclusive) as minimum value for compatiblepairs, and 1.6 (inclusive) as maximum score for in-compatible ones.
The number of problematic casesabove/below these thresholds was absolutely negli-gible.
We thus coded the data set by classifying the2,933 pairs above the first threshold as compatible(e.g., expert/criminal, hill/obstacle, snake/vermin),the 12,669 pairs below the second as incompatible(e.g., bottle/plate, cheetah/queen), and the remain-3We also were surprised to learn that drummer ants actuallyexist.
Yet, in that case we decided to keep the control item since,under the most common sense of drummer, and in ordinary cir-cumstances, ants cannot be drummers.4The guidlienes provided to the participants and the col-lected data set are available at: http://clic.cimec.unitn.it/composes/(a) 2L direct (b) 2L interaction (c) 2L interactiondirect(d) 1L direct (e) 1L interaction (f) 1L interactiondirectFigure 1: Schematic representation of the modelsder as neither.3 ModelsWe take DSM vectors as input, since they provideus with semantically rich word representations, andseek to induce a compatibility measure by learningthe parameters of a model in a supervised manner.In particular, we used the word vectors publiclyavailable at http://clic.cimec.unitn.it/composes/semantic-vectors.html.These vectors, extracted with the word2vec toolkit(Mikolov et al, 2013) from a 3B token corpus,were shown by Baroni et al (2014) to producenear-state-of-the-art performance on a variety ofsemantic tasks.We hypothesized that the interaction between asimple set of features (induced from the distribu-tional ones) should account for a large portion ofcompatibility patterns.
For example, human roleswould typically be compatible (classmate/friend),whereas two animals would probably be incompat-ible (iguana/zebra).
The model should thus be ableto learn features associated to such classes, and com-patibility rules associated to their interaction (e.g.,if both w1and w2have large values for a humanfeature, compatibility is more likely).
We incorpo-rated this insight into the 2L interaction neural net-work illustrated in Figure 1b.
This network takes thedistributional representations of the words in a pair,transforms them into new feature vectors by meansof a mapping that is shared by both inputs, con-structs the vector of pairwise interactions betweenthe induced features, and finally uses the weightedcombination of the latter to produce a real-number966score.We considered then some variations of the 2Linteraction model, to investigate the importance ofeach of its components.
In 2L direct (Figure 1a),we removed the interaction layer, making the modelscore a weighted combination of the mapped vec-tors.
The 2L interaction direct model (Figure 1c)computes the final score through a weighted combi-nation of both the mapped representations and theirinteraction vector.
The 1L models (Figures 1d, 1eand 1f) are analogous to the corresponding 2L mod-els, but removing the feature mapping layer, thus op-erating directly on the distributional vectors.4 ExperimentsSince compatibility is a symmetric relation, we firstduplicated each pair in the benchmark by swappingthe two words.
We then split it into training, test-ing and development sections.
To make the taskmore challenging, we enforced disjoint vocabulariesin each of them.
For example, drummer only occursin the training set, while ant, only in the test set.We use about 1/10th of the vocabulary (29 words)on the development set and the rest was split equallybetween train and test (135 words each).
The result-ing partitions contain 7,228 (train), 7,336 (test) and312 (development) pairs, respectively.To train the models, we used the scores they gen-erate in three sub-tasks: approximation of averageratings, classification of compatibles and classifica-tion of incompatibles.
We used mean square error ascost function for the first sub-task, cross-entropy forthe latter two.We implemented the models in Torch7 (Col-lobert et al, 2011).5We trained them for 120epochs with adagrad, with a batch size of 150 itemsand adopting an emphasizing scheme (LeCun etal., 2012), where compatibles, incompatibles andmiddle-ground items appear in equal proportions.We fixed hidden-layer size to 100 dimensions, whilewe tuned a coefficient for a L2-norm regularizationterm on the development data.We evaluated the models ability to predict humancompatibility ratings as well as to detect compatibleand incompatible items.5We make the code available at https://github.com/germank/compatibility-naacl2015corr.
comp.
incomp.Model r P R F1 P R F11L direct 50 59 55 57 80 83 721L interaction 51 50 61 55 80 77 791L int.
direct 49 52 57 54 80 79 802L direct 49 51 58 54 81 79 802L interaction 72 76 58 66 84 90 872L int.
direct 67 71 58 64 82 85 841L mono 35 31 57 41 79 77 782L mono 35 32 64 43 80 72 76Cosine 36 29 58 38 78 71 74Table 1: Experimental results.
Correlationwith human ratings measured by Pearson r.(In)compatibility detection scored by the F1 mea-sure.We compared the supervised measures to the co-sine of pairs directly represented by their DSM vec-tors (with thresholds tuned on the training set).
Weexpected this baseline to fare relatively well on in-compatibility detection, since many of our randomlygenerated pairs were both incompatible and dissim-ilar (e.g., bag/bus).Also, we controlled for the portion of the data thatcan be accounted just by looking at one of the wordsof the relation (for example, the presence of a wordmight indicate that the relation is incompatible).
Tothis end, we included two models that look at onlyone of the words in the pair.
1L mono is a logis-tic regression model that only looks at the first wordof the pair while 2L mono is an analogous neuralnetwork with one hidden layer.Results are reported in Table 1.
As it can be seen,all the supervised models from Figure 1 stronglyoutperform the cosine (that, as expected, is never-theless quite good at detecting incompatibles).
Also,they outperform the mono models (with the only ex-ception of 1L direct on incompatibility), showingthat the data they account for cannot be reduced toproperties of individual lexical items.
Importantly,the 2L interaction model is way ahead of all othermodels, confirming our expectations.To gain some insight into the features learned bythe best model, we labeled the words of our inputvocabulary with one of the following general cat-egory tags: animal, artefact, general-function, hu-man, organic-and-food and place.
The distribution967(a) Inputvectors(b) Mappedvectors(c) CategoriesFigure 2: Heatmap visualization of original DSMfeatures and features learned by the mapping func-tion of the 2L interaction model.of the vocabulary across the labels is shown in Fig-ure 2c.
If we plot the input distributional vectors sothat words tagged with the same category are adja-cent to each other, and categories arranged as in Fig-ure 2c, we obtain the heatmap in Figure 2a, where noobvious pattern emerges.
If instead we plot the out-put vectors of 2L interaction mapping in the sameway, we obtain the heatmap in Figure 2b.
It is evi-dent that the mapping produces vectors that are sim-ilar within most categories, and very different acrossthem.
Thus, the 2L interaction model clearly learnedthe relevance of general categories in capturing com-patibility judgments.
The fact that this model pro-duced the best results hints at the importance of ex-ploiting this source of information, confirming theintuition we used in designing it, that compatibilitycan be characterized by a combination of general re-latedness and category-specific cues.Finally, we explored to what extent the data canbe accounted by co-hyponymy, an idea briefly in-troduced in the introductory discussion of Section1.
For simplicity purposes, we take the same cate-gory tags we just introduced as a word?s hypernym.Classifying co-hyponyms as incompatibles and non-cohyponyms as compatibles performs very poorly (7and 18 F1-scores for compatibility and incompati-bility, respectively).
On the other hand, the oppo-site strategy ?
co-hyponyms as compatibles and non-cohyponyms as incompatibles ?
works much better(62 and 84 F1), even outperforming many super-vised models.
Yet, this strategy does not suffice.
Forexample, all animal pairs would be treated as com-patibles, whereas 54% of them are actually incom-patible.
By contrast the L2 interaction model gets78% of these incompatible pairs right.5 ConclusionWe have introduced the challenge of modeling com-patibility to the computational linguistics commu-nity.
To this end, we collected a data set, and pro-duced a model that satisfactorily captures a largeportion of the data, that cannot be accounted for bysimple semantic relatedness.
Finally, we have ex-plored the features learned by the model, confirmingthat high-order category information is relevant forproducing compatibility judgements.Computational models of compatibility couldhelp in many semantic tasks, such as coreferenceresolution, question answering, modeling plausibil-ity and negation.
Future lines of research will ex-plore the contributions that accounting for compati-bility can make to these tasks.AcknowledgmentsWe thank Denis Paperno for the interesting dis-cussions that motivated this paper and the threeanonymous reviewers for useful comments.
Weacknowledge ERC 2011 Starting Independent Re-search Grant n. 283554 (COMPOSES).ReferencesHeike Adel and Hinrich Sch?utze.
2014.
Using minedcoreference chains as a resource for a semantic task.In Proceedings of EMNLP, pages 1447?1452, Doha,Qatar.Marco Baroni, Georgiana Dinu, and Germ?an Kruszewski.2014.
Don?t count, predict!
a systematic compari-son of context-counting vs. context-predicting seman-tic vectors.
In Proceedings of ACL, pages 238?247,Baltimore, MD.Stephen Clark.
2015.
Vector space models oflexical meaning.
In Shalom Lappin and ChrisFox, editors, Handbook of Contemporary Seman-tics, 2nd ed.
Blackwell, Malden, MA.
Inpress; http://www.cl.cam.ac.uk/?sc609/pubs/sem_handbook.pdf.Ronan Collobert, Koray Kavukcuoglu, and Cl?ementFarabet.
2011.
Torch7: A matlab-like environmentfor machine learning.
In BigLearn, NIPS Workshop.D.
Alan Cruse.
1986.
Lexical Semantics.
CambridgeUniversity Press, Cambridge, UK.968Katrin Erk.
2012.
Vector space models of word meaningand phrase meaning: A survey.
Language and Lin-guistics Compass, 6(10):635?653.Karl Moritz Hermann, Edward Grefenstette, and PhilBlunsom.
2013.
?Not not bad?
is not ?bad?
: A distri-butional account of negation.
In Proceedings of ACLWorkshop on Continuous Vector Space Models andtheir Compositionality, pages 74?82, Sofia, Bulgaria.Yann A LeCun, L?eon Bottou, Genevieve B Orr, andKlaus-Robert M?uller.
2012.
Efficient backprop.
InNeural networks: Tricks of the trade, pages 9?48.Springer, Berlin.Dermot Lynott and Louise Connell.
2009.
Embod-ied conceptual combination.
Frontiers in Psychology,1:212.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013.
Efficient estimation of word representa-tions in vector space.
http://arxiv.org/abs/1301.3781/.Saif Mohammad, Bonnie Dorr, Graeme Hirst, and PeterTurney.
2013.
Computing lexical contrast.
Computa-tional Linguistics, 39(3):555?590.M.
Lynne Murphy.
2010.
Antonymy and incompatibil-ity.
In Keith Allan, editor, Concise Encyclopedia ofSemantics.
Elsevier, Amsterdam.Massimo Poesio, Simone Ponzetto, and Yannick Vers-ley.
2010.
Computational models of anaphora reso-lution: A survey.
http://clic.cimec.unitn.it/massimo/Publications/lilt.pdf.Peter Turney and Patrick Pantel.
2010.
From frequencyto meaning: Vector space models of semantics.
Jour-nal of Artificial Intelligence Research, 37:141?188.Eva Maria Vecchi, Marco Baroni, and Roberto Zampar-elli.
2011.
(Linear) maps of the impossible: Cap-turing semantic anomalies in distributional space.
InProceedings of the ACL Workshop on DistributionalSemantics and Compositionality, pages 1?9, Portland,OR.969
