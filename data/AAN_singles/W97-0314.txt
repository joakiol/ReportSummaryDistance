Inducing Terminology for Lexical AcquisitionRober to  Bas i l i ,  G ian luca  De  Ross i ,  Mar ia  Teresa  Paz ienzaDepartment of Computer Science, Systems and ProductionUniversity of Roma, Tor Vergata{basi l i  ,derossi ,pazienza}@info .utovrm.
i tAbst rac tFew attention has been paid to terminol-ogy extraction for what concerns the pos-sibilities it offers to corpus linguistics andlexical acquisition.
The problem of detect-ing terms in textual corpora has been ap-proached in a complex framework.
Termi-nology is seen as the acquisition of domainspecific knowledge (i.e.
semantic features,selectional restrictions) for complex termsand /or unknown words.
This has usefulimplications on more complex text process-ing tasks (e.g.
information extraction).
Anhybrid symbolic and probabilistic approachto terminology extraction has been defined.The proposed inductive method puts a spe-cific attention to the linguistic descriptionof what terms are as well as to the statis-tical characterization f terms as complexunits of information typical of domain sub-.languages.
Experimental evidence of theproposed method are discussed.1 In t roduct ionNowadays corpus processing techniques are widelyadopted to approach the well-known lexical bot-tleneck problems in language ngineering.
Lexicalacquisition methods rely on collocational analysis(pure statistics), robust parsing (syntax-driven ac-quisition) or semantic annotations as they are foundin large thesaura or on-line dictionaries.
The lexicalinformation that trigger induction varies from simpleword/tokens to syntactically annotated or semanti-cally typed collocations (e.g.
powerful  vs. strong tea(Smadj a, 1989)), syntactic disambiguation rules (e.g.
(Hindle and Rooths,1993), (Brill and Resnik,1994))or sense disalnbiguation rules are usually derived.Such information is lexical as it, encodes constraints(of different ypes) at the word level, to be thus in-herited by morphologic variants of a given lemma.This strongly lexicalized knowledge, as it is ex-tracted from corpus data, requires lexical entries tobe known in advance in some morphologic database.POS taggers or temmatizers are generally used tosuitably map tokens to lemmas.
It should be notedthat lemmas in a corpus depends on the underly-ing sublanguage and their nature and shape is notas general as it is usually encoded in a morphologicdictionary.
As an example, let studio (i.e.
study asa noun) be an entry in an italian morphologic dic-tionary.
Typical information in such a database isthe following:studio pos=noun gen=mas aura=singTlle only legal morphologic variant of ,studio is studi(studies, with nura=plur).
When searching for studioin a corpus of environment related texts 1, we foundthis kind of occurrences (e.g.
short contexts):... studi di base .... (basic studies)... studi di impatto ambientale ....(*studies on the environmental impact)... studi di fattibi l itd .... (feasibility studies),... studi di riferimento .... (reference studies)It is very common in a corpus (not balanced, thusfocused to a limited domain) to find a set of specifi-cations of nouns that have some specific properties:?
they are not always compositional (e.g.
studiodi base);* tlmy describe complex concepts (e.g.
studi difa t t ib i l i td )  in the underlying technical domain,so they are relevant for text understanding andclassification/extractionAlthough our approach isin principle language inde-pendent, we systematically will describe rules and exam-ples in italian as they have been derived from text.
cor-pora in \[talian.
Tile environmental corpus, called ENEA,is a collection of short scientific abstracts or newspaperarticles dealing with pollution.125they select specific and independent senses ofthe related term: studi di base refers to the ab-stract notion of study as an on-going reasearch,while studi di fattibilita' is not a reaseareh buta specific engineering task ;the related nominal compounds how indepen-dent lexical properties.
For example, all the ex-amples are potential object of verbs like carryout, do .... but only feasibility studies or studieson the environmental impact can be modelledby some techniques or policies.
Furthermore,studies on the environmental impact have spe-cific social and political implications that are nolonger valid for the general notion of study.In the same environmental corpus the typical shortcontexts of the lemma attivit6 (activity) include no-tions like:attivitti umana (human activity),attivit6 entropica (hentropic activity),attivit6 di costruzione (building activity).These very common instances how that lexical ac-quisition for attivit6 or studio cannot be fully ac-complished without discriminating the lexieal prop-erties of such pure collocations from those relatedto their complex nominals.
The results of lexicalacquisition should thus be different for entries likeattivittl and attivitd entropica.The underlying hypothesis is that complex conceptsrelated to a lemma do not support all the general-izations related to the source lemma.
In fact, when-ever a concepts is built it acquires an autonomousrole within a language so it behaves in an almostindependent fashion.
In order to capture the essen-tial differences we need to select the proper set ofterms in a given sublanguages, formalize them intoindependent lexicalizations and carry out a separatelexical acquisition for each of them.A further aspects that is worth to be mentionedis that terms are generally understood as single lex-ical units during syntactic recognition.
They aresentence fragments already parsed.
Robust meth-ods widely empl3yed in computational linguistics arethus sensible to a precise recognition of terms, asmuch of the ambiguity embedded within the termstructures simply disappear after ercognition hasbeen accomplished.
Let for example be attivit~ dicostruzione or articoli da spiaggia (beach articles)two terms.
Sentence fragments like.
.
.
l'inizio della attivitd di costruzione ...the start of the building activityor.
.
.
lrasportavano articoli da spiaggia .
.
.they transported beach articles,although inherently ambiguous (l 'iniziodella costruzione and trasportavano da spiaggia aresentence readings that also obey to selectional con-straints (e.g.
to transport/bring from a place)) canbe correctly parsed when the two terms are employedbefore syntactic analysis is triggered.
Applying syn-tactic driven lexical acquisition (e.g.
(Grishman andSterling,1994) or (Basili et a1.,1996)) after corpusspecific term recognition and extraction highly im-prove the precision and complexity of the parsingactivity.
Experimental evidence will be discussed inlater sections.In synthesis corpus driven terminology definitionand recognition has positive implications on LA:* Terms rather than words are the atomic unitsof information on which LA applies: more se-lective induction thus results in a more preciseacquisition?
Terminologic variants of a given term are hintsfor domain specific word sense disambiguation?
Terms are sentence fragments that have beenalready parsed: the lower ambiguity resultingfrom term recognition has a beneficial effect onthe later syntagmatic analysis of the corpus2 Termino logy  and  Lex ica lAcqu is i t ion .In this framework, a term is more than a token orword (to be searched for) as it stands in a more sub-tle relation with a piece of information in a specificknowledge domain.
It is a concept, as it requires alarger number of constraints on the information tobe searched for in texts.
Furthermore a term con-veys a well assessed (usually complex) meaning aslong as a user community agrees on its content.
Aslong as we are interested in automatic terminologyderivation, we can look at terms as surface canonicalforms of (possibly structured) expressions indicatingthose contents.A term is thus characterized by a general com-mitment about it and this has some effects on itsusage.
Distributional properties of complex terms(nominals) differ significantly on those of their ba-sic elements.
Deviance from usual distributional be-havior of single components can be used both asmarker of non compositionality and specific hints ofdomain relevance.
The detection of complex terms126assumes a crucial role in improving robust parsingand POS tagging for lexical acquisition, thus sup-porting a more precise induction of lexical proper-ties (e.g.
PP disambiguation rules).
This specificview extends and generalizes the classical notion ofterminology as used in Information Science.Most of the domain specific terms we are inter-ested to are nouns or noun phrases that generallydenote concepts in a knowledge domain.
In orderto approach the problem of terminological inductionwe thus need:1. to extract surface forms that are possible can-didates as concept markers;2. to decide which of those candidates are actu-ally concepts within a given knowledge domain,identified by the set of analyzed texts.Linguistic principles characterize classes of surfaceforms as potential terms (step 1).
Note that thenotion of terminological legal expression here is notequivalent to that of legal noun phrases.
Conceptsare lexicalized in surface forms via a set of opera-tions that imply semantic specifications.
The waysyntax operates uch specification may be very com-plex and independent on the notion of grammaticalwell formedness.The decision in step (2) is again sensible to aprincipled way a language xpresses concept spec-ifications but needs also to be specific to the givenknowledge domain, i.e.
to the underlying sublan-guage.
Given the body of texts, the selective x-traction should be sensitive to the different observedinformation.
In this phase statistics is crucial to con-trol the relevance of linguistically plausible forms ofall the guessed terms.3 In tegrat ing  l ingu is t i c  ands ta t i s t i ca l  in fo rmat ion  fo r  te rmd iscoveryThe principled definitions of legal grammaticalstructures by which terms are expressed and the de-scription of their distributional properties in a sub-language are crucial for the automatic onstructionof a domain terminological dictionary.
A number ofmethods for language driven terminological extrac-tion and complex nominals parsing and recognitionhave been proposed to support NLP and lexical ac-quisition tasks.
They mainly differ in the empha-sis they give to syntactic and statistical control ofthe induction process.
In (Church,1988) a well-knowpurely statistical method for POS tagging is appliedto the derivation of simple noun phrases that arerelevant in the underlying corpus.
On the contrarymore language oriented methods are those wherespecialized grammar are used.
LEXTER (Bouri-gault,1992) extracts maximal ength noun phrases(mlnp) from a corpus, and then applies a specialpurpose noun phrase parsing to ~hem in order to fo-cus on significant complex nominals.
Although thereported recall of the mlnp extraction is very high(95%) tile precision of the method is not reported.Voutilanen (1993) describes a noun phrase extrac-tion tool (NPtool) based upon a lemmatizer forEnglish (ENGTWOL) and on a Constraint Gram-mar parser.
The set of potential well-formed nounphrases are selected according to two parsers work-ing with different NP-hood heuristics.
A very highperformance of NP recognition is reported (98.5%recall, and 95% precision).A more statistically oriented approach is undertakenin (Daille et a1,1994) where a methodology for syn-tactic recognition of complex nominals is described.Linguistic filters of morphological nature are also ap-plied.
Corpus driven analysis is mainly based on mu-tual information statistics and the resulting systemhas been successfully applied to technical documen-tation, e.g.
telecommunication.All these methods deal with the problem of NPrecognition.
As we are essentially interested to NPthat are actual terms in a domain, we will need todecide which NPs are actual terms.
We will define:1. well formedness principia for term denotationsand a description of the different grammaticalphenomena related to terms of a language2.
distributional properties that distinguish termsfrom other (accidental) forms (e.g.
non termi-nological complex nominals).3.1 Grammat ica l  descr ipt ions  of  te rms inItalianIt is generally assumed that a terminologic dictio-nary is composed of a (possibly structured) list ofnouns, or complex nominals.
Nominal forms are infact lexicalization of domain concepts: proper nouns,acronyms as well as technical concepts are mostlyrepresented as nominal phrases of different lengthand complexity.
For this reason, we concentratedonly on noun phrases analysis, as the main sourceof terminologic nformation 2.
A term is obtained byapplying several mechanisms that add to a sourceword (generally a noun) a set of further specifica-tions (as additional constraints of semantic nature).2In lexical acquisition the role of other syntactic at-egories (e.g.
verbs, adjectives, ...) is also very importantbut the set of phenomena related to them is very differ-ent, ms also outlined by (Basili et al,1996b)127A detailed analysis of the role of syntactic modi-tiers and specifiers (De Rossi,1996) revealed that le-gal structures for modifiers and specifiers in Italianare mainly of two types:1. restrictive (or denotative) modifiers (postnom-inal participial, adjectival or prepositionalphrases)2. appositive (or connotative) modifiers (prenomi-nal modifiers, i.e.
adjectival phrases)Restrictive modifiers are generally used to constraint,the semantic information related to the correspond-ing noun, via a further specification of a giventypefor that noun as in scambi commerciali (*ex-changes commercial): the referent noun is forced tobelong to a restricted set of exchanges (that are infact of commercial nature).
On the contrary, apposi-tive modifiers are used by the speaker/writer to addadditional details: his own point of view or prag-matic information, as in la bianca cornice (the whiteframe) or la perduta genre (the lost people).
Appos-itive modifiers do not correspond to any (shared)classification, but rather to the subjective speaker'spoint of view.
Furthermore prenominal modifica-tions are rather unfrequent in Italian.
We thusdecided to focus only on restrictive modifiers, thebest candidates to bring terminological (i.e.
assessedclassificatory) information.
The set of syntactic phe-nomena that have been studied as good candidatesfor restrictive forms are:1. adjectival specification (via postnominal adjec-tives, as in inquinamento idrologico (*pollutionhydrological)2. nominal specification (postnominal ppositions,as in vagone letto (wagon-lit), or Fiat Auto(Fiat Cars))3. locative phenomena (postnominal proper nounsindicating locations, as in IBM Italia4.
verbal specification (via postnominal past par-ticiple, as in siti inquinati (*sites polluted))5. prepositional specification (via a particular setof postnominal prepositional structures, as inIstituto di Matematica (Institute of Mathemat-ics), or barca a vela (sailin9-boat)).
aGiven the above linguistic principles, a specialpurpose grammar for potential terminological struc-tures can be sketched.
With a simple languageof regular expressions the grammar of adjectival,3The set of prepositions that have been selected to in-troduce typical restrictive descriptions are: di,a,per, da.Only postnominal prepositional phrases introduced byone of these prepositions have been allowed for termexpressions.prepositional and participial restrictions can be ex-pressed as:Term 6- noun A_P"Term.
6- noun A_P (Con9 A_P) ?Term 6- noun"Term.
6- noun ( -  noun)*Term 6- noun , Term,A_P 6- adjective I past_participleCong 6- ' - '  \[ ePrepositional postmodifiers are modeled accordingto the following rules:Term 6- noun P.P"P_P 6- Prep nounPrep 6- di I a Ida I perNote that the allowed structures are post nominaldue to the typical role of specifications in Italian.3.2 D is t r ibut iona l  p roper t ies  and  te rmext rac t ionThe recursive nature of some rules require an itera-live analysis of the corpus.
The following algorithmis used:1.
Select singleton nouns whose distributionalproperties are those for terms and insert themin the terminologic dictionary (TD)2.
Use the valid terms in TD to trigger the gram-mar and build complex nominals cn3.
Select those cn whose distributional propertiesare those for terms and insert them in TD.4.
Iterate steps 2 and 3 to build longer cn 4Note that newly found complex terms, added to TDin step 3, force a re-estimation of term probabilitiesobtained by a further corpus scanning, so that theirheads are not counted twice.The validation of a limited set of potential surfaceforms as actual terms is crucial for lowering the com-plexity of tile above algorithm.
Given the grammar,we need criteria to decide which surface forms, that,reflect the typical structure of a potential terms, areactual exicalizations of relevant concepts of the cor-pus.
The kind of observations that are available fromthe corpus are: (i) the set of lemmas met in thetexts, (ii) the set of their well formed restrictions(i.e.
complex nominals) and (iii) the distributionalproperties of entries in (i) and (ii).
We firstly estab-lish when a singleton lemma is a relevant conceptby using distributional properties of nouns.
Thenwe characterize which restrictions of those terms arevalid lexicalizations of more specific concepts.
Weproceed as follows:4 As terminological units longer than 5 words are veryinfrequent in any sublanguage, we decided to stop afterthe second iteration1281.
Select the set of lemmas that by themselvesare markers of relevant concepts in the cor-pus.
Lemmas are detected according to theirfrequency in the observed language sample aswell as to their selectivity, i.e.
how they parti-tion the set of documents.
This phase producesan early TD dictionary of simple terminologicalelements.2.
Extend TD also with those (well-formed) re-strictions, cn(l), of any l E TD according tothe mutual information they exchange with I.,Select and Extend depend on distributional prop-erties of simple lemmas and complex nominals, re-spectively.The distributional property needed for the Selectstep is the term specificity.
Specific nouns are thosefrequently occurring in a corpus, but whose selectiv-ity in sets of documents is very high, that is: theyare very frequent in a (possibly small) set of docu-ments and very rare in the rest.
In order to capturesuch behavior we use two scores: the frequency tij ofa term i in a document j and the inverse documentfrequency of a term (Salton,1989).
Given a term i,its inverse document frequency is defined as follows:idfi = log s ~Nwhere dfi is the number of documents of the corpusthat include term i, while N is the total number ofdocuments in the collection.
The following criteriais defined to capture singleton terms: if exists atleast one document where a noun i is required asindex (because it is relevant for that document andselective with respect o other documents) then sucha noun denotes a relevant domain term (i.e.
specificconcept).
In order to decide we rely on idfi and tijas follows.DEF: (Singleton term).
A noun i is a term if at leastone document j exists for which:Nwij = tij log2 ~// _> r (1)wi.i captures exactly the notion of specificity re-quired in the Select step of our algorithm.
Potentialheads of terminological entries are selected accord-ing to their selective power in the corpus?
Even veryrare words of the corpus can be captured by (1).In the Extend step of the a.lgorithm we need toevaluate the mutual information values of phrasestructures like:head Modlhead Modl Mod2head Modi Mod2 ...  Mod,~Mutual Information between two words x and yis defined as (Fano,1961):l (x ,y)  = log vrob(~,y) prob(x)prob(y)and it can be estimated by a maximum likelihoodmethod as in (Dagan,1993):\](x, y) = log s N.Jreq(x,y) \]req(x)freq(y)where: freq(x, y) is the frequency of the joint eventof (x,y), freq(x), freq(y) and N are the frequencyof x, y and the corpus size respectively.
In order toapply the standard efinition of mutual informationwe need to extend it to capture the specific nature ofthe joint event head-modifier (H M1).
Note thatM1 denotes post nominal adjectives or past partici-ple but also prepositional phrase like dello Stato interritorio deilo Stato.
We decided to estimate theMutual Information of such structures in a left toright fashion.
The rightmost modifier (i.e.
M1 in (HM1) structures, or M,  in (H M1 .. .
M,,)) is consid-ered as the right event y and every left incoming sub-structure (i.e.
H or H .. .
Mn-t)  is represented as asingle event x.
The generalized evaluation of Mutualinformation for cn = ( ( H , M1, M2 .
. "
Mn-  \] ), M ,  ) isthus:N ?
freq(H, M i , ' " ,  Mn-1, Mn)\](en) = log 2 freq(H, M1, ' " ,  Mn-1) f req(M, )(2)As an example a term like debito pubblico (publicdebt) receive a mutual information score accordingto the following figure:N.Ireq(debito,publieo)\](x, y) = log 2 freq(debito)freq(publico)while debito publico estero (foreign public debt) pro-duces to the following ratio:N'~recl(debito,publico,estero )\](x, y) = log 2 freq(debito,publico)freq(estero)DEF.
(Complex Terms) A Complex nominal cn =( ( U, M1, U2 .
.
.
Mn-1), Mn) is selected as term (andthus included in TD) if the following conditionholds:\](cn) > 6(H) (3)The threshold if(H) depends on noun H as it is eval-uated according to the statistical distribution of ev-ery complex nominals headed by H 5.
The set ofsingleton terms is exactly the same set that a clas-sical indexing model (Salton,1989) obtains from thedocument collection (i.e.
the corpus).
The Extend~ In the experimental tests best values for g have beenobtained a.s a fimction of mean and variance of the \[distribution over the set of cn headed by H129phase allows to capture all the relevant specificationsof the singleton terms, cornpile a more appropriatedictionary (for the corpus) and structure it in hier-archically organized entries.4 Imp lementat ion  I ssuesThe model described in the previous ection has beenused to implement a system for terminology deriva-tion from a corpus.
The system relies upon thePOS tagging activity as it is carried out within aLA framework (e.g.
the ARIOSTO system (Basiliet a1.,1996)) and extracts a fifil terminologic dictio-nary TD of:1. simple terms (i.e.
nouns) as seeds of a termino-logical structured ictionary (selected accordingto (1)2. complex nominal forms of some of those seeds,generated by the grammar and filtered accord-ing to (3).Terminology extraction is triggered after POS tag-ging.
Morphologic analysis is rerun according to thecompiled TD.
This feedback allows the system toexploit complex term extraction before activatingsyntactic recognition, in order to prune out signif-icant components of grammatical ambiguity.
Thisimproves the overall ability of the linguistic proces-sor and supports term oriented rather than lemmaoriented lexical acquisition.A dedicated subsystem has been developed to sup-port manual validation of single terms.
In Figure 1a screen dump of the graphical interface that sup-ports the interactive validation (or removal)of termsin TD is shown.
TD is hierarchically organizedin separate sections where singleton terms domi-nate all their specified subconcepts.
A section isthe set of terms that share the same term head.
Aterm like smaltimento dei rifiuti (garbage collection),has the noun "smaltimento" (garbage) as its termhead.
A specific section includes terms like smalti-mento dei rifiuti, smaltimento di materiale tossico,smaitimento di gas di scarieo .
.
.
.
).
In Figure 1 thehead noun debito (debt)) is reported: the section re-lated to debito includes all its validated specifications(e.g.debito pubblico (public debt), debito pubblico es-tero (.foreign public debt) ... ).5 Exper imenta l  Set -UpIn this section we describe the experimental set-upused to evaluate and assess the described model ofterminological derivation.The method has been tested over two corpora ofitalian documents.
The first corpus (ENEA) is aSb'ucture Name : debRoComponent fist :< ,  debito {POSS,AB$\]_ / 2x__  __totale p ubblico oubbli?o estero netto f inanziario cornMFigure 1: User Interface for Terminology ValidationTable 1: Distribution of indexes headed by attivit5l,dex I 1to20 I 2~to40 I 41toS0 I SltoS0 I S,tol0S IMethod RI: I I \[ I I \[at t iv i t f i  3 2 5 1 4Method Thot t iv i thent rop icadl cost ruz ioneprodut t ivaumanacollection of scientific abstracts on the environment,made of about 350.000 words.
The second corpus(Sole24Oore) is an excerpt of financial news from theSole 24 Ore economic newspaper, of about 1.300.000words.
The terminology extraction have been runover both tile corpora.
From the ENEA corpus wederived a dictionary of about 2828 words.
From theSole24Ore corpus 5639 terms have been extracted.In order to carry out the experiments we used asubset of tile ENEA corpus in order to measure per-formance over manually validated documents.
Thespecific nature of our tests required the definitionof particular performance valuation measures.
Infact, together with the classical notion of recall andprecisions, we used also data compression, as thepercentage of incorrect syntactic data that are nolonger produced when specific terminology is used.A further index is the average ambiguity defined ac-cording to the notion of collision set (Basili et al,1994).
Ill order to accomplish the task further ref-erence information has been used: two standard do-main specific thesaura have been used for comparingthe result of the terminology extraction in the envi-ronmental domain (ENEA corpus).5.1 L inguist ic  ana lys is  o f  corpus  dataIn Table 1 the section headed by attivitd, as it hasbeen derived from the ENEA corpus, is shown.
The130specific nature of the corpus is well reproduced bythe data.
Here two specific senses of the lemmaattivit6 are captured: natural and biological activityas in attivitd entropies and human activities (likeattivitd produttiva (productive activity) or attivitddi costruzione (building activity).
These latter havespecific implications (for what concerns artificial pol-lution) in the environment.Table 1 reports also the distribution of the termin a set of 106 documents.
In method RI termshave been selected by classical inverse document fre-quency (Salton,1989) applied to singleton lemmas(i.e.attivit6).
In Method TI we run inverse docu-ment frequency after a terminology driven lemma-tization of documents (i.e.
using complex terms assource lemmas).
The two sections of the table showthat no index has been lost by the TI method (all ofthe 15 indexes have been found).
This result is moregeneral: TI method produces more indexes.
Overthe 106 documents MI extracts 476 simple indexeswhile TI extracts 732 (terminological) indexes.Again in Table 1, 5 of the fifteen indexes found bythe TI method are complex nominals.
In the set ofdocuments from 1 to 20 (lto20 column) these al-low to discriminate between attivit6 and attivitdantropica.Such an higher discriminating power is requirednot only for document classification/retrieval but,first of all for lexical acquisition: in this techni-cal domain in fact it seems necessary to rely onthe information that attivit6 is typically carriedout by humans while attivit6 antropica is not.
Weare convinced that these are the typical selectionalconstraints to be captured by corpus driven lexi-cal acquisition methods.
Finer lexicalizations (likeattivit6 antropica) are the only way to provide abetter input to the target acquisition tasks.5.2 Exper iment  1: Ef fect iveness of  thete rmlno logy  extractionThe aim of this experiment was to test the abilityof the method to capture relevant concepts in thesublanguage.
We run this test on the environmentaldomain (ENEA corpus).
The reference term dic-tionary was manually compiled by a team of threedomain experts, culturally heterogeneous.
We got acomplete list of terms (simple nouns as well as com-plex nominals) to be used as a test-set (RT).
Thereference document set was a collection of 106 doc-uments.
The experts compiled a set of 482 termsorganized in 155 sections (i.e.
relevant head nouns).Each section thus includes 3.12 terms.
For sakeof completeness we selected two large hand-codedthesaura for the environment: the CNR dictionaryTable 2: Smaltimento in different dictionariesRT CNR AIB TDsmaltimento dei fanghi _ Xsmaltimento dei rifiuti X X Xsmaltimento delle scorie XTable 3: Global Performance ofdifferent dictionariesDictionary CNRD AIB TD# of Relevant Terms 41 45 331# of Terms 880 180 472Recall 8,87% 9,74% 71,56%Precision 4,66% 23,94% 70,13%(CNR,1995)(that includes 9613 terms) and the AIBdictionary (AIB,1995).
Both these dictionaries aswell as the automatically generated ictionary TDhave been compared with the reference RT.
Thecomparison has been carried out throughout the dif-ferent aligned sections.
The alignment of the sectionrelated to the head smaltimento is reported in Table2 ("X" means the presence of the term in the corre-sponding dictionary, while "."
denotes its absence):Any dictionary D can thus be evaluated by mea-suring precision~ i.e.precision = RTterrnsoDterrn8Dter rnsand recall, i.e.recall = RTterrnsf'lDterrnsRTter rnsFor example within the section related to the headsmalt imento, we have 3 RT terms, of which 1 is inCNR and AIB respectively and 3 are in TD.
Whenapplying the recall and precision definition to everysections of the RT dictionary we obtained tile aver-age performance scores reported in Table 3 over thethree dictionaries.5.3 Experiment 2: Shallow parsing withtermino log ica l  knowledgeConsulting a terminologic dictionary before acti-vating a shallow syntactic analyzer is helpful tosolve several morphological nd syntactic ambigui-ties.
For exa~nple, given the sentence 6L 'ufficiale della Guardia di Finanza v i s i t  I'aereoporto di Fiumicino(The officer of Finance Guard visited the Fiumicino airport)a typical shallow syntactic analyzer (SSA) (Basiliet al, 1992) produces the following elementary syn-tactic links (esl), due the syntactic ambiguity ofprepositional phrases (PP), e.g.
( (di linanza), (diFiumicino )) :N-P-N ufficiale della guardiaN_P-N ufficiale di f inanz~N_P-N guardia di fin~nz~6This sentence has been extracted from the Sole24Orecorpus131N-V ufficiale visit6V-N visit6 aeropor toN-P-N aereoporto di fiumicinoV_P_N visit6 dl tiumicinoAs each sentence reading cannot assign more thana single referent o each PP, we can partition theset of esl into several collision sets (i.e.
sets of esithat cannot belong to the same sentence reading ac-cording to (Basili et al 1994)).
The sample sentencegives rise to the following collision sets:{ (ufliiciale di flna, nza) (guardia di f inanza) }{ (uiilciale visit6 ) }{(aereoporto di fiumicino) (visit6 di fiumicino) }{ (ufficiMe della guardia) }{ (visit6 aeroporto) }When terminology is available many complex nomi-nals are retained as single tokens and several am-biguity disappear.
In the Sole24Ore corpus ourmethod produced both the terms guardia di finanzaand aeroporto di Fium, icino so that the final list ofesl reduces toN-P-N ufficiale della gua.rdia-di-finanz&N_V ufl~ciMe visit6N_V guardia-di- f inanza visit6V_N visit6 aeroporto_di_fiumicinoand no ambiguous (i.e.
not singleton) collision setremains.
We have two positive effects on the parsingactivity.
The first is data compression.
In fact theovergeneration typically due to the shallow gram-matical approach is significantly limited.
In our ex-ample the early 7 elementary syntactic groups ob-tained in absence of terminology reduced to 4 withan overall data compression of ((7-4)/7) 42.8%.
Anextended experimentation has been carried out ona subset of 500 sentences of the corpus.
The use ofterminology reduces the number of elementary syn-tactic links from 500 to 403 with a corresponding20% of overall data compression.
Furthermore, thedetection of a term carried out over single tokensthat are morphologically ambiguous improves alsothe morphological recognition.
In fact the detectionof a chain of tokens that are part of the same termimplies a specific choice on the grammatical cate-gory of each token, thus augmenting the selectivityof POS tagging.
Over the same subset of the corpuswe measured a decrement of 4% in the number ofmorphological derivations produced with terminol-ogy against he recognition carried out in absence ofany terminological knowledge.A second positive aspect of having an availableTable 4: Performance evaluation of terminology drivenparsingParser Ambiguity #Collisions Recall PrecisionSP 0.60 3.2 0.65 0.67TP 0.55 2.9 0.68 0.71domain specific terminology is the reduction of theunderlying syntactic ambiguity and increase of theparser precision.
As shown in the example many PPambiguity disappears as soon as a set complex nom-inals is detected.
This has a strong implication onshallow (or robust ms widely accepted in literature)parsing.
We conducted a systematic analysis of cor-rect parsing results by contrasting a parser with andwithout access to domain terminology.
The analy-sis of the results has been performed by comparingcollision sets obtained by the two runs over a set of100 sentences.
Four performance scores have beenevaluated: the degree of ambiguity (i.e.the ratio be-tween the number of ambiguous esl's over the to-tal number of derived esl's); the average ambiguity(expressed by the average eardinality of the colli-sion sets (i.e.
the number of reciprocally ambiguousesl%); finally, precision and recall have been mea-sured according to a hand validation of the derivedsyntactic material 7.
The analysis has been carriedout specifically for prepositional esl% (i.e.
noun-preposition-noun, verb-preposition-noun, adjective-preposition-noun links).
Results are reported in Ta-ble 4 where separate columns express the scores forthe different runs: a simple parser (SP), and a ter-minology driven parser (TP).
As a result the simpleparser obtains several complex nominals but onlyas syntactic structures o that it fails in detectinghigher order syntactic links (i.e.
syntactic relationsbetween complex nominals and other sentence seg-ments).
In these cases we penalized also the recall ofthe SP method, so that the difference between thetwo methods relies not only in amount of persist-ing ambiguity (i.e.
precision), but also in coverage(better captured by recall).6 Conc lus ionsIn this paper a method for the automatic extractionof terminological (possibly complex) units of infor-mation from corpora is presented.
The proposedmethod combines principle of grammatical correct-ness with statistical constraints on the distributional7 Precision is the number of detected correct esl's overthe total number of detected esl's, while recall is thenumber of detected correct esl's over the number of cor-rect esl~s132properties of the detected domain terms.
In an in-cremental fashion NPs are first selected as possiblecandidates for term denotation and then inserted inan incremental terminological dictionary accordingto their mutual information value.
The experimen-tal test has been difficult as a precise notion of whatis a relevant erm in a domain is very vague and sub-jective.
Tests against a domain specific user orienteddictionary have been carried out, in comparison withlarge scale thesaura in the domain.
The significantimprovement against this standard sources is verysuccessful.
The method has been widely applied todifferent corpora and it demonstrated to be easilyportable without any heavy customization.
As it re-lies upon simple POS tagging, it is widely portableto other languages, as soon as NP grammars areavailable.
Feedback of the terminological extractionprocess to the morphologic analysis has been alsodesigned.
A measure of the improvement that ter-minological NP recognition implies over the activityof a shallow parser for LA has been carried out.
Theresult is an overall improvement: data compressionis around 5% while syntactic ambiguity eliminationis about 10%.
Recall and Precision of the syntacticanalysis is consequently higher.The main result of this method is to support finerlexicalization, in form of complex nominals, for lex-ical acquisition.
Lexical acquisition based on col-locations between terms (and not simple lemmas)provides more granular information on lexical sensesas well as (syntactic or semantic) selectional con-straints.
The success of this method allow to designautomatic methods for taxonomic (thesaurus-like)knowledge generation.
Distributional, as well syn-tactic, knowledge is a crucial source of informationfor large scale similarity estimation among detectedterms.ReferencesA1B, 1995, Ensoli A., Marconi G., Sistema di Classifi-cazione dei Documenti di Interesse Ambientale, RapportiAIB-7, ISSN 1121-1482Basili 1992, R.Basili, M.T.Pazienza, P.Velardi A Shal-low Syntactic Analyzer to extract word association fromcorpora, Literary and Linguistic Computing, 1992, vol.7,n.2, 114-124Basili, R., A. Marziali, M.T.
Pazienza, Modelling syn-tactic uncertainty in lexical acquisition from texts, Jour-nal of Quantitative Linguistics, vol.1, n.1, 1994.Basili et al1996a.
Basili R., M.T.
Pazienza, P. Ve-lardi.
An Empirical Symbolic Approach to Natural Lan-guage Processing.
Artificial Intelligence, Vol.85, August1996.Basili et al,1996b.
Basili, R., M.T.
Pazienza,P.Velardi, Integrating General Purpose and Corpus-based Verb Classifications, Computational Linguistics,1996.Bourigault, D., 1992, Surface Grammatical Analysisfor the Extraction of Terminological Noun Phrases, Proc.of COLING 1992, Nantes, France, pp.977-981.Brill E., Resnik P.,1994, A rule-based approach toprepositional phrase attachment disambiguation, i  Proc.of COLING 94, 1198-1204Church, K., 1988, A Stochastic Parts Program andNoun Phrase Parser for Unrestricted Text, Proc.
of 2ndConf.
on Applied Natural Language Processing, Austin,pp.
136-143CNR, 1995.
Thesaurus ltalimm Generale peri'Ambiente, Consiglio Nazionale delle Ricerche (CNR),Rapporto Scientifico 10/95, Ed.
Bruno Felluga, Edizione31/07/1995, Roma.Dagan 1993, l.Dagan, K.Church Identifying andTraslating Technical Terminology, \[JCAI 1993Daille et al 1994, Daille B., Gaussier E., Lange',J.M., Towards Automatic Extraction of Monolingualand Bilingual Terminology, COLING-94, August, Ky-oto, Japan, 1994.De Rossi, 1996, Eiaborazioni Satistiche di CorporaTestuali mirate all'Acquisizione di Conoscenza per laCostruzione di Thesaura, Faculty of Engineering, Uni-versity of Roma, Tor Vergata, 1996.R.
Fano, Transmission of Information, Cambridge,Mass., MIT Press, 1961Hindle D. and Rooth M., 1993, StructuralAmbiguityand Lexical Relations, Computational Linguistics, 19(1):103-120.Salton G., Automatic Text Processing: the Transfor-mation, Analysis and Retrieval of Information by Com-puter, Addison-Wesley Puhl., 1989.7 Appendix 1: Excerpt ofTerminological Dictionaries fromtwo domainsNounFonte(Source)Rischio(Risk)ENEA terms\[fonte,di,inquin amento\]\[fonte,principale\]\[fonte,dei,rifiuti\]\[fonte,di,energia\]\[fonte,di,in quinamento\]\[fonte,di,materia,prima\]\[fonte,energetica\]\[fonte,eoli?~\]\[fonte,idrica\]\[fonte,informativa\]\[fonte,nucleare\]\[fonte,primaria,di,energi~\]\[fonte,principMe,dei,rifi uti\]\[rischio,ambientMe\]\[rischio,cancerogeno\]\[ri8chio,chimico\]\[rise hio,clim atico\]\[rischio,di,are~\]\[rischio,di,crisi\]\[rischio,di,inquin amento\]\[rischio,erosivo\]\[rise hio,indu st riale\]\[ri~chio,reale,connesso l\[rischio,relativo\]\[rischio,sanitario l\[rischio,sismico\]\[rischio,tec nologico\]\[rise hio,tossicologico\]Sole 24 Terms\[fonte,energetic~,prim aria\]\[fonte,norrn~tiva\]\[fonte,normatiw,citata\]\[fonte,princip~le\]\[rischio,aziendMe\]\[rischio,stand~rd\]133
