2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 70?79,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsMulti Event Extraction Guided by Global ConstraintsRoi Reichart Regina BarzilayComputer Science and Artificial Intelligence LaboratoryMassachusetts Institute of Technology{roiri, regina}@csail.mit.eduAbstractThis paper addresses the extraction of eventrecords from documents that describe multi-ple events.
Specifically, we aim to identifythe fields of information contained in a docu-ment and aggregate together those fields thatdescribe the same event.
To exploit the in-herent connections between field extractionand event identification, we propose to modelthem jointly.
Our model is novel in that itintegrates information from separate sequen-tial models, using global potentials that en-courage the extracted event records to havedesired properties.
While the model con-tains high-order potentials, efficient approxi-mate inference can be performed with dual-decomposition.
We experiment with two datasets that consist of newspaper articles de-scribing multiple terrorism events, and showthat our model substantially outperforms tra-ditional pipeline models.1 IntroductionToday, most efforts in information extraction havefocused on the field extraction task, commonly for-mulated as a sequence tagging problem.
When adocument describes a single event, the list of ex-tracted fields provides a useful abstraction of the in-put document.
In practice, however, a typical news-paper document describes multiple events, and a flatlist of field values may not contain the sufficientstructure required for many NLP applications.
Ourgoal is therefore to extract event templates which ag-gregate field values for individual events.Consider, for instance, the New York Times arti-cle excerpt in Figure 1 that describes three relatedterrorist events.
As this example illustrates, in orderto populate the corresponding event templates, themodel needs to identify segments that describe indi-vidual events.
Such segmentation is challenging, asevent boundaries are not explicitly demarcated in thetext.
Moreover, descriptions of different events areoften intermingled, as in the above example, furthercomplicating boundary recovery.In this paper, we consider a model that jointlyperforms event segmentation and field extraction.This model capitalizes on the inherent connectionbetween the two tasks in order to reduce the ambi-guity of template-based extraction.
For example, thedistribution of field values in the text provides strongclues about event segmentation, such as the presenceof multiple new fields strongly signaling a segmentboundary.
Likewise, knowledge of the boundariesenables the model to rule out mutually inconsistentpredictions, such as extracting two distinct locationsfor the same event.We formulate our approach as a joint model thatmarks each word with field and event labels si-multaneously.
At the sentence level, segmentationand field extraction taggers are implemented usingseparate sequence models operating over local fea-tures.
At the document level, the model encouragesglobal consistency via potentials that link the ex-tracted event records and their fields.
Some of thesepotentials are limited to fields of an individual eventsuch as the ?single city per event?
constraint.
Othersencode discourse-level properties of the whole doc-ument and thus involve records of multiple events,70A powerful car bomb exploded today in Baghdad inside the holiest Shiite shrine .
As many as 95 people were killedin the event, according to sources in Washington.
The blast came only two days after another car bomb exploded in a crowdedstreet in Mosul in the northern part of Iraq, killing 13 pedestrians, in an attack carried out by Al Qaeda.
Together with theprevious attack by Al Qaeda, the shooting in Najaf three weeks ago that killed 15 American soldiers, violence seemedto spike to its highest level.
The bombing today, happened around 9am, when the roads are crowded with people.
...Organization Tactic Target Weapon Fatalities City CountryEvent 1 ?
bombing Shiite shrine car bomb 95 people Baghdad ?Event 2 Al Qaeda bombing ?
car bomb 13 pedestrians Mosul IraqEvent 3 Al Qaeda shooting ?- ?
15 American Soldiers Najaf ?Figure 1: A New York times article describing three terrorist events and a table demonstrating the corresponding event records.such as the tendency in newspaper reporting to fea-ture the main event at the beginning and repeatedlythroughout the document.While these high-order potentials encode impor-tant linguistic properties of valid assignments, theygreatly complicate learning and inference.
There-fore, our method estimates the parameters of the lo-cal sequence models and the global potentials sep-arately.
Then, at inference time, it finds variableassignments that are most consistent with both thelocal models and the global potentials.
Inferenceis implemented via dual-decomposition, an efficientalgorithm shown to be effective for complex jointinference problems.We evaluate our approach for event extraction ontwo data sets, one is a new collection of long news-paper articles and the other is a subset of the MUC-4 documents.
Both data sets consist of articles thatdescribe multiple terrorist events (40.3 and 12.4 sen-tences and 4.4 and 3.1 events per article for each dataset on average).
We demonstrate the benefits of thejoint model for event extraction; it outperforms a tra-ditional pipeline model by a significant margin.
Forinstance, it yields an absolute gain of 8.5% for ournew corpus when measured using document-level F-score.
Our results show the effectiveness of globalconstraints in the context of template extraction andmotivate their exploration in other IE tasks.2 Previous WorkEvent-Template Extraction Event template extrac-tion has been previously explored in the MUC-4scenario template task.
Work on this task has fo-cused on pipeline models which decouple the taskinto the sub-tasks of field extraction and event-basedtext segmentation.
For example, rule-based meth-ods (Rau et al, 1992; Chinchor et al, 1993) identifygeneralizations both for single field fillers and for re-lations between fields and use them to fill event tem-plates.
Likewise, classifier-based algorithms (Chieuet al, 2003; Xiao et al, 2004; Maslennikov andChua, 2007; Patwardhan and Riloff, 2009) gener-ally train individual classifiers for each type of fieldand aggregate candidate fillers based on a senten-tial event classifier.
Finally, unsupervised techniques(Chambers and Jurafsky, 2011) have combined clus-tering, semantic roles, and syntactic relations in or-der to both construct and fill event templates.In our work, we also address the sub-tasks offield extraction and event segmentation individu-ally; however, we link them through soft global con-straints and encourage consistency through joint in-ference.
To facilitate the joint inference, we use alinear-chain CRF for each sub-task.Global Constraints Previous work demonstratedthe benefits of applying declarative constraints in in-formation extraction (Finkel et al, 2005; Roth andtau Yih, 2004; Chang et al, 2007; Druck and Mc-Callum, 2010).
Constraints have been explored bothat sentence and document level.
For example, Finkelet al (2005) employ document-level constraints toencourage global consistency of named entity as-signments.
Likewise, Chang et al (2007) use con-straints at multiple levels, such as sentence-levelconstraints to specify field boundaries and globalconstraints to ensure relation-level consistency.
Inour work we focus on document-level constraints.We utilize both discourse and record-coherence con-straints to encourage consistency between local se-quence models.There has also been unsupervised work thatdemonstrates the benefit of domain-specific con-straints (Chen et al, 2011).
In our work we showthat domain-specific constraints based on the com-mon structure of newspaper articles are also usefulto guide a supervised model.713 ModelProblem Formulation Given a document, our goalis to extract field values and aggregate them intoevent records.
The training data consists of event an-notations where each word in the document is taggedwith a field and with an event id.
If a word is not afiller for a field, it is annotated with a default NULLfield value.
At test time, the number of events is notgiven and has to be inferred from the data.Model Structure Our model is built around theconnection between local extraction decisions andglobal constraints on event structure.
Based onlocal cues, the model can identify candidate fieldfillers.
However, connecting them to events requiresa broader document context.
To effectively capturethis context, the model needs to group together por-tions of the document that describe the same event.Global constraints are instrumental in this process,as they drive the aggregation of contiguous segmentscomputed by a local segmentation model.
In ad-dition, global constraints coordinate local decisionsand thereby enable us to express important discoursedependencies between various assignments.To implement these ideas in a computationalframework, we define an undirected graphical modelwith a vertex set V = X ?
Y ?
Z .
X is a set of ob-served nodes; xi represents the ithe word in a docu-ment.
Y and Z are sets of unobserved nodes corre-sponding to the field and event assignments respec-tively of the ith word.
The number of input words ina document is denoted by n.We define three types of potentials:?
Field-labeling Potentials associate words in adocument with field labels based on their localsentential context.?
Event-labeling Potentials associate words in adocument with event boundaries based on thelocal surroundings of a candidate boundary.?
Global Consistency Potentials link the ex-tracted event records and their fields to encour-age global consistency.
These potentials are de-fined over the entire set of variables related to adocument.The resulting maximum aposteriori problem is:MAP (?)
=?f?F?f (rf )where ?f are the potential functions and {rf |f ?
{1, .
.
.
, n}, f ?
F} is the set of their variables.3.1 Modeling Local DependenciesField Labeling The first step of the model is taggingthe words in the input document with fields.
Fol-lowing traditional approaches, we employ a linear-chain CRF (Lafferty et al, 2001) that operatesover standard lexical, POS-based and syntactic fea-tures (Finkel et al, 2005; Finkel and Manning, 2009;Bellare and McCallum, 2009; Yao et al, 2010).Event Segmentation At the local level, event analy-sis involves identification of event boundaries whichwe model as linear segmentation.
To this end, weemploy a binary CRF that predicts whether a givenword starts a description of a new event or continuesthe description of the current event, based on lex-ical and POS-based features.
In addition, we addfeatures obtained from the output of the field extrac-tion CRF.
These features capture the intuition thatboundary sentences often contain multiple fields.The potential functions of these components aregiven by the likelihoods of the corresponding CRFs.3.2 Modeling Global DependenciesThe main function of the global constraints is tolink extracted fields to the corresponding events.In addition, the model can use global constraintsto resolve potentially inconsistent decisions of thelocal models by encouraging them to agree withglobal, document-level properties.
We consider twotypes of global consistency potentials: discourse po-tentials that involve interactions between multiplerecords, and record coherence potentials that cap-ture patterns at the level of individual records.The general form of a global potential p is:?f (xf?p, yf?p, zf?p) ={?p if potential-property holds0 otherwiseWhere f ?
p is the index set of variables overwhich the potential is defined.
Table 1 gives a formaldescription of all the potentials.
Below we describethe linguistic intuition behind these potentials.Discourse Potentials To populate event recordswith extracted information, the model needs to72DiscourseMAIN EVENT Two consecutive sentences without fields indicate a transitionto the main event:(?Si, Si+1 s.t.
(?k ?
Si, yk = NULL) ?
(?k ?
Si+1, yk = NULL)) ?
(?l ?
i s.t.
(?u, u ?
i, u < l, 1fME(Su)=1), ?p ?
Sl, zp = CENTRAL)SEGMENT BOUNDARY Event changes should take place in multi-field sentences:?i, j ?
I, ((i = j + 1) ?
(zi!
= zj)) ?
(?i1 .
.
.
it ?
I s.t.
1[fs?SB(i,i1,...it)=1] ?
1[ff?SB(i1,...it)=1])EVENT REDUNDANCY Events should not significantly overlap:?i, j ?
{1, .
.
.
, |Z|}, ?k, l ?
I s.t.
((yk = yl) ?
(yk!
= NULL) ?
(zk = i) ?
(zl = j) ?
(xk!
= xl))Record CoherenceFIELD SPARSITY Some fields take a single unique value per record:?K,L ?
I, C ?
?, ((YK = C) ?
(YL = C) ?
(ZK = ZL)) ?
(XK = XL)RECORD DENSITY Words associated with a field should fill the field if it is otherwise empty:?i ?
?, C ?
?, (?k ?
I s.t.
(1[Cind(xk)=1]) ?
(zk = i)) ?
(?l ?
I s.t.
(yl = C) ?
(zl = i))Table 1: Logical formulations of the properties encouraged by the global potentials.
Si is the set of indexes corre-sponding the the ith sentence.
fME(Su) = 1 iff there is no event change in sentence Su.
fs?SB(i1, .
.
.
, it) = 1 iff thecorresponding words appear in the same sentence.
ff?SB(i1, .
.
.
, it) = 1 iff the corresponding words have different,non-NULL, field values.
Cind(xk) = 1 iff xk is assigned to C in a training event record.
CENTRAL is the centralevent of the document, defined to be its first event.
I = {1, .
.
.
, n}, ?
= {1, .
.
.
|Y |}, ?
= {1, .
.
.
, |Z|}.group together sentences that describe the sameevent.
The local boundary model can only predictcontiguous blocks of event descriptions, but it can-not link together blocks that appear in different partsof the document.
Our approach towards this taskis informed by regularity in the discourse organiza-tion of news articles.
A typical news story is de-voted to a single event, mixed with short descrip-tions of other events.
Therefore, we prefer event as-signments where long segments with no field values?
e.g., background descriptions ?
are associated withthe main event.
This intuition is formalized in theMain Event Potential shown in Table 1.The second discourse constraint concerns detec-tion of event boundaries.
We prefer assignments inwhich the boundary sentence contains a large num-ber of fields.
This preference is expressed in the Seg-ment Boundary Potential shown in Table 1.The final discourse constraint favors assignmentsthat reduce redundancy in generated records.
It isunlikely that a document describes several eventswith significant factual overlap.
This constraintis implemented in the Event Redundancy Potentialshown in Table 1.Record Coherence Potentials These potentialscapture properties of valid field assignments in thecontext of a given event record.
The first potentialin this group ?
Field Sparsity Potential ?
is ap-plied to fields, such as City, that tend to take a singleunique value per event record.1 This potential dis-courages assignments that link this field with multi-ple values within the same event.
Similar constraintshave been effectively used in information extractionin the past (Finkel et al, 2005).
In our work, we ap-ply this constraint at the event level, rather than atthe document level, thereby enabling multiple vari-able values for multi-event documents.The second record coherence potential ?
RecordDensity Potential ?
aims to reduce empty fields inthe event record.
This potential turns on when a lo-cal extractor fails to identify a filler for a field whenprocessing a given event segment.
If this segmentcontains words that are labeled as potential fillers inthe context of other events in the training data, weprefer assignments that associate them with the fieldthat otherwise would have been empty.
This poten-tial is inspired by the one sense per discourse con-straint (Gale et al, 1992) that associates all the oc-currences of the word in a document with the samesemantic meaning.1The potential is defined for the following fields: TerroristOrganization, Weapon, City, and Country.734 InferenceDual Decomposition The global potentials encodeimportant document level information that links to-gether the extracted event records and their fields.Introducing these potentials, however, greatly com-plicates inference.
Consider the MAP equation ofSection 3.
If the intersection between each pair ofsubsets, fi, fj ?
F , had been empty, we could havefound the MAP assignment by solving each poten-tial separately.
However, since many subset pairs dooverlap, we must enforce agreement among the as-signments which results in an NP-hard problem.In order to avoid this computational bottleneck weturn to dual-decomposition (Rush et al, 2010; Kooet al, 2010), an inference technique that enables ef-ficient computation of a tight upper bound on theMAP objective, while preserving the original depen-dencies of the model.
Dual decomposition has beenrecently applied to a joint model for biomedical en-tity and event extraction by Riedel and McCallum(2011).
In their work, however, events are defined inthe sentence level.
Here we show how this techniquecan be applied to a model which involves document-level potentials.We first re-write the MAP equation, such that itcontains a local potential for each of the unobservedvariables, as required by the inference algorithm:MAP (?)
= maxy,z?j?J?j(rj) +?f?F?f (rf )where we denote the set of indexes of all unob-served variables with J and refer to each of themwith rj .
We then define the dual problem:min?L(?
), L(?)
=?j?Jmaxrj[?j(rj) +?f :j?f?fj(rj)]+?f?Fmaxrf[?f (rf )?
?j?f?fj(rj)]where for every f ?
F and j ?
f , ?fj is a vector ofLagrange multipliers with an entry for each possi-ble assignment of rj .
We add the notation ?f for thematrix of Lagrange multipliers for all the variablesin f , and for an assignment M of the variables in fwe define ?f (M) to be the corresponding vector ofLagrange multipliers.
The multipliers can be viewedas messages transferred between the potentials to en-courage agreement between their assignments.The dual objective, L(?
), forms an upper boundon the MAP objective.
Our inference algorithmSet g0fj ?
0 for all j ?
J, f ?
Ffor k = 1 to K dofor j ?
J dorlkj = argmaxrj[?j(rj) +?f :j?f?fj(rj)]end?
TRUEfor f ?
F dorpkf = argmaxrf[?f (rf )?
?j?f?fj(rj)]for j ?
f doif rlkj 6= rpkfj thengkfj(rlkj ) + = 1gkfj(rpkfj) ?
= 1end?
FALSE?k+1fj = ?kfj ?
?k ?
gkfjif end thenreturn Rk?k ?
1/kreturn (RK )(a)rlkj : Sort [?j(rj) +?f :j?f?fj(rj)].
Return the minimizing rj .rpkf :MMAkf ?
: Minimum-Message assignmentPRAkf ?
: Property-Respecting assignmentif (?p ?
sum(?f (PRA)) > (?1) ?
sum(?f (MMA)) thenrpkf = PRAkfelserpkf = MMAkf(b)Figure 2: The inference algorithm.
(a): The dual-decomposition algorithm.
(b): Algorithms for theargmax operations of the dual-decomposition algorithm.therefore searches for its minimum, i.e.
the tightestupper bound of the original MAP objective.
L(?)
isconvex and non-differentiable and can therefore beminimized by the subgradient descent algorithm inFigure 2 (a).Individual Potentials Maximization The inferencealgorithm requires efficient solvers for its argmaxproblems.
For the field labeling and event segmen-tation potentials, the messages are encoded into thefeature space of the CRF, and exact maximization isachieved through standard CRF decoding.
For thelocal potentials, (rlkj ), the maximizing assignmentsare computed by sorting the messages for each un-observed variable (Figure 2 (b)).The global potentials are more challenging.
Ide-ally, we could find the optimal assignment, rp?f , thatagrees with the assignments of the other potentials( rp?f = argmin?j?f ?fj(rpj)) and at the sametime respects the property encouraged by its own po-74tential (?p(rp?f ) > 0).
In practice, however, theremay be no such assignment, in which case the as-signment conflict needs to be resolved.We first compute the minimum-message assign-ment (MMA), the assignment that minimizes themessage sum.
If this assignment respects the poten-tial property then it is the optimal assignment.
Oth-erwise, we compute the property-respecting assign-ment (PRA), the assignment with the (approximate)lowest message sum under the condition that the po-tential property holds.
From these two assignmentswe select the one with the higher score.Finding the MMA is simple, as it is the minimum-message assignment of each unobserved variableseparately.
However, finding the global optimalPRA is computationally demanding, as it requiressearching over a very large assignment space.
Wetherefore trade accuracy for efficiency and restricteach potential to modify the MMA assignment foronly one type of variables: Y (fields) or Z (events).The discourse potentials and the FIELD SPARSITYpotential are restricted to changes of the event vari-ables, while the RECORD DENSITY potential is re-stricted to changes of the field variables.For the MAIN EVENT potential, consecutive sen-tences with no fields trigger a return to the mainevent.
For the SEGMENT BOUNDARY potential,event changes that take place in sentences with asmall number of fields are removed.
For our work,this threshold is set to three.
For the EVENT RE-DUNDANCY potential, redundant events are inte-grated with the largest event in which they are con-tained.
For the RECORD DENSITY potential, wordsseen in both training records and event text are usedto fill empty fields.
For each empty field in eachevent, words labeled with event are scanned for can-didate fillers, and those with the minimal impact onthe message sum are assigned to that field.Finally, for the FIELD SPARSITY potential, if afield contains more than one word or phrase perevent, the event assignments of these words orphrases are recomputed.
This computation is imple-mented as a minimum matching problem in a bipar-tite graph.
One side of the graph consists of a vertexfor every word or phrase assigned to the addressedfield, and the other side consists of one vertex foreach event in the document.
If the number of phrasesassigned to the field is larger than the number ofevents in the document, some of the event verticeswill be assigned to new events.
The edge weightsare the sum of message changes corresponding torelabeling the word or phrase with the new event.We solve this problem efficiently (O(n3)) using theKuhn-Munkres algorithm (Kuhn, 1955).5 ExperimentsData This work focuses on multi-event extraction.While some of the articles in the MUC test corpusdo have multiple events, the majority contain onlyone (77.5%) or two (12%).
We therefore created twocorpora for our experiments.
The first is a new cor-pus of 70 articles from New York Times (NYT) LDCcorpus, each describing one or more terrorist eventsfrom various parts of the world.
The second, also of70 articles, consists of a subset of the MUC articlesthat describe more than one event.
We stripped thiscorpus from the MUC annotation and annotated itaccording to our scheme.Annotations were provided by two annotatorswith graduate school educations.
Every word wastagged with a field and an event id.
The 8 fieldswe use are: Terrorist Organization, Target, Tactic,Weapon, Fatalities, Injuries, Country and City.We compared the agreement between annotatorson 10 articles by computing the percentage of wordsfor which the annotators gave the same labeling.The inter-annotator agreement was 90.9% (kappa =0.9) when fields and events are evaluated together(i.e., the annotators are considered to agree onlywhen they assign the same field and event id to theword), 97.8% (kappa = 0.97) for events only, and92% (kappa = 0.91) for fields only.The two corpora differ from each other with re-spect to several important properties.
The New-YorkTimes articles are longer (40.3 compared to 12.4sentences per article) and describe a larger numberof events (4.4 compared to 3.1 events per article onaverage).
In addition, while our hypothesis aboutthe predominance of the main (first) event cover-age holds for both corpora, it better characterizes theNew-York Times corpus, as is demonstrated by thefollowing two statistics.First, in the NYT corpus the average number ofsentences containing field fillers for the main eventis 14.7, while for any other event the average number75is 3.2.
In the MUC corpus the corresponding num-bers are 5.3 and 2.0.
Second, in the NYT corpusthe number of times an article goes back to a pre-viously described event is 182 (average of 2.6 timesper article), of which 154 (84.6%) are transitions tothe main event.
In the MUC corpus the number oftimes an article goes back to a previously describedevent is only 38 (average of 0.54 times per article),but, similarly to the NYT, in as much as 32 (84.2%)of these cases the transitions are to the main event.Experimental Setup For both corpora, we used 30articles for training (1218 sentences in NYT, 423 inMUC), 7 articles for development (358 sentences inNYT, 79 in MUC) and 33 articles for test (1244 sen-tences in NYT, 367 in MUC).
The sentences werePOS tagged with the MXPOST tagger (Ratnaparkhi,1996) and parsed with the Charniak parser (Char-niak and Johnson, 2005).We trained our model with a two steps procedure.First, the local CRFs were separately trained on thetraining articles.
Then, we trained the parameters ofthe global potentials using the structured perceptronalgorithm (Collins, 2002) on the development data.We perform joint inference over the local CRFsas well as the global potentials with dual decompo-sition.
This algorithm is guaranteed to give the MAPassignment if it converges to a solution in which allthe potentials agree on the label assignment for thevariables in their scope.
To deal with disagreements,we ran the algorithm for 200 iterations past the pointof fluctuations around the dual minimum.
The finallabel assignment is determined by a majority votebetween the potentials in the 10 iterations with thehighest total inter potential agreement (Sontag et al,2010).Baselines We compare our algorithm to two base-line models.
The first baseline is related to previoustechniques that decompose the task into field extrac-tion and event segmentation sub-tasks (Jean-Louiset al, 2011; Patwardhan and Riloff, 2007; Patward-han and Riloff, 2009).
For this PIPELINE baseline,we run the CRF models described in Section 3.1,first the field CRF and then the event CRF.
The field-based features of the event CRF are extracted fromthe output of the field CRF.Our model incorporates global dependencies intoa document level model.
An alternative approach isto encode this information as local features that re-flect global dependencies (Liang et al, 2008).
Wetherefore constructed a second baseline, the bidirec-tional pipeline model (BI-PIPELINE), that considersglobal features which encode similar properties tothose encouraged by our global potentials.
We im-plement this by incorporating event-based featuresinto the feature set of the field labeling CRF, whilekipping the event segmentation CRF fixed.
2 As inthe pipeline model, each CRF is trained separatelyon the training data.
The BI-PIPELINE model, how-ever, emulates our joint inference procedure by it-eratively running a field labeling and an event seg-mentation CRFs.
The number of iterations for thismodel was estimated on development data.Evaluation Measures We follow the MUC-4scoring guidelines (Chinchor, 1992).
To comparebetween a learned and a gold standard event, wecompute the word-level F-score between each oftheir fields and average the results.
If a field is emptyin both event records, it is not counted in the mutualevent score, while if it is empty in only one of theevent records, its F-score is 0.Ideally, the measure should be able to captureparaphrases.
For example, if the Tactic field ina gold event record contains the words ?bombing?and ?blast?, the measure is expected to give a per-fect score to a learned record that contains one ofthese words.
Therefore, as in the MUC-4 guidelines,we count pre-specified synonyms and morphologi-cal derivations of the same word only once.For every document, we then map the learnedevents to the gold events in a greedy 1-1 mannerusing the Kuhn-Munkres algorithm (Kuhn, 1955).Once we have an event mapping, we can reportan average recall, precision and F-score across thetest set for all fields, events and documents (wherethe document F-score is the average F-score of itsevents).
We use the sign test to measure the statis-tical significance for our results.
Since the numberof events described in a document is not given to themodels as input, we also report the average ratio be-tween the number of induced and gold events.2Example additional features are: (1) whether a word withthe same most frequent field (MFF) as the encoded word previ-ously appeared in its event; (2) whether a new event is startedin the sentence of the encoded word; and (3) whether the eventof the encoded word contains at least one word annotated withthe MFF of the encoded word.76NYT Documents Events Fields Event NumberR P F R P F R P F RatioJoint Model 38.7 42.4 38.5 36.2 40.8 36.4 43.6 49.1 43.8 0.95Bi-pipeline Model 33.3 30.8 30.2 31.9 30.1 29.4 38.8 36.6 35.7 1.14Pipeline Model 28.3 27.0 26.2 27.1 26.8 25.5 35.4 34.8 33.2 1.5MUC Documents Events Fields Event NumberR P F R P F R P F RatioJoint Model 49.8 43.2 43.5 48.7 43.0 42.7 53.6 45.9 46.2 0.88Bi-pipeline Model 38.1 38.6 36.3 34.3 33.9 32.2 41.5 40.5 38.6 0.92Pipeline Model 30.8 32.8 29.7 29.9 32.0 28.9 37.9 40.1 36.6 0.89Table 2: Performance of the joint model and the pipeline models on the event record extraction task.
Top table is forthe New-York Times data.
Bottom table is for the MUC data.
All results are statistically significant with p < 0.05.NYT TO TAR TAC WEAP INJ FAT CO CITYJoint Model 21.9 23.4 49.0 39.6 40.8 49.1 43.1 46.6Bi-pipeline Model 8.4 19.7 47.5 20.9 25.9 18.3 38.8 38.1Pipeline Model 7.1 18.1 41.9 36.9 19.1 16.5 38.0 46.1MUC TO TAR TAC WEAP INJ FAT CO CITYJoint Model 49.0 25.2 63.6 62.0 43.3 21.1 19.7 38.3Bi-pipeline Model 28.0 24.7 38.2 55.8 42.7 25.6 37.5 37.2Pipeline Model 34.9 23.4 50.3 56.5 10.4 12.4 30.0 32.0Table 3: Comparison between the joint model and the pipeline models for the different fields.
When the joint model issuperior results are statistically significance with p < 0.05.
(a)NYT Fields EventsR P F GF LFJoint model 47.3 51.3 49.2 54.8 61.3Bi-Pipeline 31.0 43.8 36.3 48.8 56.2Pipeline Model 39.2 55.4 45.9 51.3 52.9(b)MUC Fields EventsR P F GF LFJoint model 47.3 51.3 49.2 62.8 70.0Bi-Pipeline 49.5 36.1 41.8 62.2 62.0Pipeline Model 31.0 43.8 36.3 65.5 70.3Table 4: Performance of the joint and the pipeline models on the labeling tasks of assigning words to fields (left) andto events (right).
Field values are computed for words tagged with the non-NULL field.
Events values are computedfor words that are assigned to a non-NULL field by the gold standard (GF) or by the model (LF).
When the joint modelis superior, results for fields are statistically significant with p < 0.01 and for events with p < 0.05.6 ResultsEvent-Records Results for event record extraction,the main task addressed in this paper, are presentedin Table 2.
For all measures, the model outperformsthe pipeline baselines, with an F-score difference ofup to 13.8%.The rightmost column of the table demonstratesthe tendency of our model to under-segment.
Forboth corpora our model extracts a smaller numberof events than the gold standard on average (5% forNYT, 12% for MUC).
The pipeline baselines extractmore events than our model on average.
For NYTthey over-segment (14% for bi-pipeline, 53% for thepipeline) while for MUC they under-segment (8%and 11% respectively).
These differences are ex-pected as the baselines cannot combine different textsegments that describe the same event.Table 3 presents per-field F-score performance.The joint model outperforms the pipeline baselinesfor 7 out of the 8 fields in the NYT experiments, andfor 6 out of 8 fields in the MUC experiments.Model Components Table 6 presents the perfor-mance of variants of the joint model created by ex-cluding each potential type.
The results demonstratethe significance of both discourse and record co-herence potentials for the performance of the fullmodel.Sub-tasks Performance A model for our task77(a)Gold Fields Gold EventsNYT Doc.
Events Fields Ratio Doc.
Events FieldsJointModel69.1 62.5 64.4 1.05 45.7 46.5 50.0Bi-Pipeline?
?
?
?
41.7 40.8 46.1Pipeline 47.9 43.9 51.3 1.56 40.8 40.4 43.9(b)Gold Fields Gold EventsMUC Doc.
Events Fields Ratio Doc.
Events FieldsJointmodel78.5 75.0 74.5 0.76 50.8 47.9 51.4Bi-Pipeline?
?
?
?- 37.0 34.3 39.9Pipeline 76.1 71.1 72.0 0.78 32.6 31.2 36.0Table 5: Performance of the joint model and the pipeline models when the gold standard for one of the labeling tasksis given at test time.
Results are statistically significant with p < 0.05.NYTExcluded Component Documents Events Fields EventRat.Record Coherence 32.1 31.0 37.7 1.04Discourse 26.7 26.3 34.3 1.5MUCRecord Coherence 37.4 33.6 39.6 0.88Discourse 37.7 36.6 42.7 0.89Table 6: The effect of the record coherence potentials andof the discourse potentials on the performance of the jointmodel.
Results are presented for F-scores, each line is forthe full model when potentials of one type are excluded.should determine both when a word is a good fieldfiller and to which event the field belongs.
Sinceour main evaluation collapses the effect of these de-cisions together, we performed two additional setsof experiments to analyze the model?s accuracy oneach sub-task separately.Figure 4 presents the performance of the differentmodels on the labeling tasks of assigning words tofields and to events.
The number of words associatedwith a field differs between the gold standard andthe models?
output.
For fields, we therefore reportword level recall, precision and F-score between theset of words assigned a non-NULL field by a modeland the corresponding gold standard set.
For events,we compute the fraction of words assigned the cor-rect event among the words assigned to a non-NULLfield in either the gold standard or the output of themodel.Figure 5 presents the document F-score when thegold-standard fields (left) or events (right) of the testset are known at test time.
Note that when the goldstandard fields are known, the BI-PIPELINE modelis not applicable anymore since it is designed toimprove field assignment using event-informed fea-tures.
The results demonstrate that encoding fieldinformation to the models is more valuable than en-coding information about events.
This provides uswith an important direction for future improvementof our model.Accuracy and Efficiency When we ran our algo-rithm on the joint task of the NYT data-set it con-verged after 89 iterations.
For the MUC joint taskand the ablation analysis experiments we ran the al-gorithm for 200 iterations past the point of fluctua-tions around the dual minimum.On a 2GHz CPU, 2GB RAM machine, it tookour dual-decomposition algorithm 15 minutes and10 seconds to complete its run on the entire NYT testset.
For the MUC joint task experiment, in the 10iterations considered for the majority vote, there isfull agreement between the potentials for 97.77% ofthe unobserved variables.
That is, the voting schemeaffects the assignment of only 2.23% of the unob-served variables.7 ConclusionsIn this paper we presented a joint model for identify-ing fields of information and aggregating them intoevent records.
We experimented with two data setsof newspaper articles containing multiple event de-scriptions.
Our results demonstrate the importanceand effectiveness of global constraints for eventrecord extraction.AcknowledgementsThe authors gratefully acknowledge the support ofthe DARPA Machine Reading Program under AFRLprime contract no.
FA8750-09-C0172.
Any opin-ions, findings and conclusions expressed in the ma-terial are those of the author(s) and do not neces-sarily reflect the views of DARPA, AFRL or the USgovernment.
Thanks also to the members of the MITNLP group and to Amir Globerson for their sugges-tions and comments.78ReferencesKedar Bellare and Andrew McCallum.
2009.
General-ized expectation criteria for bootstrapping extractorsusing record-text alignment.
In EMNLP.Nathanael Chambers and Dan Jurafsky.
2011.
Template-based information extraction without the templates.
InACL.Ming-Wei Chang, Lev Ratinov, and Dan Roth.
2007.Guiding semi-supervision with constraint driven learn-ing.
In ACL.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In ACL.Harr Chen, Edward Benson, Tahira Naseem, and ReginaBarzilay.
2011.
In-domain relation discovery withmeta-constraints via posterior regularization.
In ACL.Hai Leong Chieu, Hwee Tou Ng, and Yoong Keok Lee.2003.
Closing the gap: Learning-based informationextraction rivaling knowledge-engineering methods.In ACL.Nancy Chinchor, David Lewis, and Lynette Hirschman.1993.
Evaluating message understanding systems: ananalysis of the third message understanding confer-ence.
Computational Linguistics, 19(3):409?449.Nancy Chinchor.
1992.
Muc-4 evaluation metrics.
InFourth Message Understanding Conference (MUC-4).Michael Collins.
2002.
Discriminative training methodsfor hidden markov models: Theory and experimentswith perceptron algorithms.
In EMNLP.Gregory Druck and Andrew McCallum.
2010.
High-performance semi-supervised learning using discrimi-natively constrained generative models.
In ICML.Jenny Rose Finkel and Christopher D. Manning.
2009.Joint parsing and named entity recognition.
InNAACL.Jenny Rose Finkel, Trond Grenager, and Christopher D.Manning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In ACL.William Gale, Kenneth Church, and David Yarowsky.1992.
One sense per discourse.
In Proceedings of the4th DARPA Speech and Natural Language Workshop.Ludovic Jean-Louis, Romaric Besancon, and Olivier Fer-ret.
2011.
Text segmentation and graph-based meth-ods for template filling in information extraction.
InIJCNLP.Terry Koo, Alexander M. Rush, Michael Collins, TommiJaakkola, and David Sontag.
2010.
Dual decomposi-tion for parsing with non-projective head automata.
InEMNLP.Harold W. Kuhn.
1955.
The hungarian method for theassignment problem.
Naval Research Logistics Quar-terly, 2:83?97.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In ICML.Percy Liang, Hal Daume, and Dan Klein.
2008.
Struc-ture compilation: trading structure for features.
InICML.Mstislav Maslennikov and Tat-Seng Chua.
2007.
Amulti-resolution framework for information extractionfrom free text.
In ACL.Siddharth Patwardhan and Ellen Riloff.
2007.
Effectiveie with semantic affinity patterns and relevant regions.In EMNLP.Siddharth Patwardhan and Ellen Riloff.
2009.
A unifiedmodel of phrasal and sentential evidence for informa-tion extraction.
In EMNLP.Adwait Ratnaparkhi.
1996.
A maximum entropy part-of-speech tagger.
In WVLC.Lisa Rau, George Krupka, Paul Jacobs, Ira Sider, andLois Childs.
1992.
Muc-4 test results and analysis.In Fourth Message Understanding Conference (MUC-4).Sebastian Riedel and Andrew McCallum.
2011.
Fast androbust joint models for biomedical event extraction.
InEMNLP.Dan Roth and Wen tau Yih.
2004.
A linear programmingformulation for global inference in natural languagetasks.
In CoNLL.Alexander M. Rush, David Sontag, Michael Collins, andTommi Jaakkola.
2010.
On dual decomposition andlinear programming relaxations for natural languageprocessing.
In EMNLP.David Sontag, Amir Globerson, and Tommi Jaakkola.2010.
Introduction to dual decomposition for infer-ence.
In Optimization for Machine Learning, editorsS.
Sra, S. Nowozin, and S. J. Wright: MIT Press.Jing Xiao, Tat-Seng Chua, and Hang Cui.
2004.
Cas-cading use of soft and hard matching pattern rules forweakly supervised information extraction.
In COL-ING.Limin Yao, Sebastian Riedel, and Andrew McCallum.2010.
Collective cross-document relation extraction-without labelled data.
In EMNLP.79
