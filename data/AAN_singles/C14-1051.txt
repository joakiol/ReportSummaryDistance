Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 530?540, Dublin, Ireland, August 23-29 2014.Jointly or Separately: Which is Better forParsing Heterogeneous Dependencies?Meishan Zhang?, Wanxiang Che?, Yanqiu Shao?, Ting Liu??
?Research Center for Social Computing and Information RetrievalHarbin Institute of Technology, China{mszhang, car, tliu}@ir.hit.edu.cn?Beijing Language and Culture Universityyqshao163@163.comAbstractFor languages such as English, several constituent-to-dependency conversion schemes are pro-posed to construct corpora for dependency parsing.
It is hard to determine which scheme isbetter because they reflect different views of dependency analysis.
We usually obtain dependen-cy parsers of different schemes by training with the specific corpus separately.
It neglects thecorrelations between these schemes, which can potentially benefit the parsers.
In this paper, westudy how these correlations influence final dependency parsing performances, by proposing ajoint model which can make full use of the correlations between heterogeneous dependencies,and finally we can answer the following question: parsing heterogeneous dependencies jointlyor separately, which is better?
We conduct experiments with two different schemes on the PennTreebank and the Chinese Penn Treebank respectively, arriving at the same conclusion that joint-ly parsing heterogeneous dependencies can give improved performances for both schemes overthe individual models.1 IntroductionDependency parsing has been intensively studied in recent years (McDonald et al., 2005; Nivre, 2008;Zhang and Clark, 2008; Huang et al., 2009; Koo and Collins, 2010; Zhang and Nivre, 2011; Sartorio etal., 2013; Choi and McCallum, 2013; Martins et al., 2013).
Widely-used corpus for training a dependen-cy parser is usually constructed according to a specific constituent-to-dependency conversion scheme.Several conversion schemes for certain languages have been available.
For example, the English lan-guage has at least four schemes based on the Penn Treebank (PTB), including the Yamada scheme (Ya-mada and Matsumoto, 2003), the CoNLL 2007 scheme (Nilsson et al., 2007), the Stanford scheme(de Marneffe and Manning, 2008) and the LTH scheme (Johansson and Nugues, 2007).
There are dif-ferent conversion schemes for the Chinese Penn Treebank (CTB) as well, including the Zhang scheme(Zhang and Clark, 2008) and the Stanford scheme (de Marneffe and Manning, 2008).
It is hard tojudge which scheme is more superior, because each scheme reflects a specific view of dependency analy-sis, and also there is another fact that different natural language processing (NLP) applications can preferdifferent conversion schemes (Elming et al., 2013).Traditionally, we get dependency parsers of different schemes by training with the specific corpusseparately.
The method neglects the correlations between these schemes, which can potentially helpdifferent dependency parsers.
On the one hand, there are many consistent dependencies across heteroge-neous dependency trees.
Some dependency structures remain constant in different conversion schemes.Taking the Yamada and the Stanford schemes as an example, overall 70.27% of the dependencies areidentical (ignoring the dependency labels), according to our experimental analysis.
We show a concreteexample for the two heterogeneous dependency trees in Figure 1, where six of the twelve dependenciesare consistent in the two dependency trees (shown by the solid arcs).On the other hand, differences between heterogeneous dependencies can possibly boost the ev-idences of the consistent dependencies.
For example in Figure 1, the dependencies ?doVCxthink?
?Corresponding author.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/530We do n?t think at this point anything need to be saidSUBROOTVMODVCVMOD NMODPMODSUBVMODVMODVMODVCnsubjauxnegrootprep detpobjnsubjccompauxauxpassxcompFigure 1: An example to show the differences and similarities of two dependency schemes.
The abovedependency tree is based on the Yamada scheme, while the below dependency tree is based on theStanford scheme.
The solid arcs show the consistent dependencies between the two dependencytrees, while the dashed arcs show the differences between the two trees.and ?Wensubjx think?
from the two trees can both be potential evidences to support the dependency?thinkyat?.
Another example, the label ?PMOD?
from the Yamada scheme and the label ?pobj?
fromthe Stanford scheme on a same dependency ?atypoint?
can make it more reliable than one alone.In this paper, we investigate the influences of the correlations between different dependency schemeson parsing performances.
We propose a joint model to parse heterogeneous dependencies from twoschemes simultaneously, so that the correlations can be fully used by their interactions in a single model.Joint models have been widely studied to enhance multiple tasks in NLP community, including jointword segmentation and POS-tagging (Jiang et al., 2008; Kruengkrai et al., 2009; Zhang and Clark,2010), joint POS-tagging and dependency parsing (Li et al., 2011; Hatori et al., 2011), and the joint wordsegmentation, POS-tagging and dependency parsing (Hatori et al., 2012).
These models are proposedover pipelined tasks.
We apply the joint model into parallel tasks, and parse heterogeneous dependenciestogether.
To our knowledge, we are the first work to investigate joint models on parallel tasks.We exploit a transition-based framework with global learning and beam-search decoding to imple-ment the joint model (Zhang and Clark, 2011).
The joint model is extended from a state-of-the-arttransition-based dependency parsing model.
We conduct experiments on PTB with the Yamada and theStanford schemes, and also on CTB 5.1 with the Zhang and the Stanford schemes.
The resultsshow that our joint model gives improved performances over the individual baseline models for bothschemes on both English and Chinese languages, demonstrating positive effects of the correlations be-tween the two schemes.
We make the source code freely available at http://sourceforge.net/projects/zpar/,version0.7.2 BaselineTraditionally, the dependency parsers of different schemes are trained with their corpus separately, usinga state-of-the-art dependency parsing algorithm (Zhang and Clark, 2008; Huang et al., 2009; Koo andCollins, 2010; Zhang and McDonald, 2012; Choi and McCallum, 2013).
In this work, we exploit atransition-based arc-standard dependency parsing model combined with global learning and beam-searchdecoding as the baseline.
which is initially proposed by Huang et al.
(2009).
In the following, we give adetailed description of the model.In a typical transition-based system for dependency parsing, we define a transition state, which consistsof a stack to save partial-parsed trees and a queue to save unprocessed words.
The parsing is performedincrementally via a set of transition actions.
The transition actions are used to change contents of thestack and the queue in a transition state.
Initially, a start state has an empty stack and all words of asentence in its queue.
Then transition actions are applied to the start state, and change states step by step.Finally, we arrive at an end state with only one parsed tree on the stack and no words in the queue.
Wescore each state by its features generated from the historical actions.531S1?
?
??
?
?S0?
?
?SAR(l)AL(l)PRQ0Q1?
?
?QSH(a) Arc-standard dependency parsing model for a single dependency treeSa1?
?
??
?
?Sa0?
?
?SaARa(l)ALa(l)PRaQa0Qa1?
?
?QaSHaSb1?
?
??
?
?Sb0?
?
?SbARb(l)ALb(l)PRbQb0Qb1?
?
?QbSHbGuidedaGuidedb(b) The joint model based on arc-standard dependency parsing for two dependency treesFigure 2: Illustrations for the baseline dependency parsing model and our proposed joint model.In the baseline arc-standard transition system, we define four kinds of actions, as shown in Figure 2(a).They are shift (SH), arc-left with dependency label l (AL(l)), arc-right with dependency label l (AR(l))and pop-root (PR), respectively.
The shift action shifts the first element Q0of the queue onto the stack;the action arc-left with dependency label l builds a left arc between the top element S0and the secondtop element S1on the stack, with the dependency label being specified by l; the action arc-right withdependency label l builds a right arc between the top element S0and the second top element S1on thestack, with the dependency label being specified by l; and the pop-root action defines the root node of adependency tree when there is only one element on the stack and no element in the queue.During decoding, each state may have several actions.
We employ a fixed beam to reduce the searchspace.
The low-score states are pruned from the beam when it is full.
The feature templates in ourbaseline are shown by Table 1, referring to baseline feature templates.
We learn the feature weights bythe averaged percepron algorithm with early-update (Collins and Roark, 2004; Zhang and Clark, 2011).3 The Proposed Joint ModelThe aforementioned baseline model can only handle a single dependency tree.
In order to parse multipledependency trees for a sentence, we usually use individual dependency parsers.
This method is notable to exploit the correlations across different dependency schemes.
The joint model to parse multipledependency trees with a single model is an elegant way to exploit these correlations fully.
Inspired bythis, we make a novel extension to the baseline arc-standard transition system, arriving at a joint modelto parse two heterogeneous dependency trees for a sentence simultaneously.In the new transition system, we double the original transition state of one stack and one queue intotwo stacks and two queues, as shown by Figure 2(b).
We use stacks Saand Sband queues Qaand Qbto save partial-parsed dependency trees and unprocessed words for two schemes a and b, respectively.Similarly, the transition actions are doubled as well.
We have eight transition actions, where four of themare aimed for scheme a, and the other four are aimed for scheme b.
The concrete action definitions aresimilar to the original actions, except an additional constraint that actions should be operated over thecorresponding stack and queue of scheme a or b.We assume that the actions to build a specific tree of scheme a are Aa1Aa2?
?
?Aan, and the actions to532Baseline feature templatesUnigram featuresS0w S0t S0wt S1w S1t S1wt N0w N0t N0wt N1w N1t N1wtBigram featuresS0w?S1w S0w?S1t S0t?S1w S0t?S1t S0w?N0w S0w?N0t S0t?N0w S0t?N0tSecond-order featuresS0lw S0rw S0lt S0rt S0ll S0rl S1lw S1rw S1lt S1rt S1ll S1rlS0l2w S0r2w S0l2t S0r2t S0l2l2 S0r2l2 S1l2w S1r2w S1l2t S1r2t S1l2l2 S1r2l2Third-order featuresS0t?S0lt?S0l2t S0t?S0rt?S0r2t S1t?S1lt?S1l2t S1t?S1rt?S1r2tS0t?S1t?S0lt S0t?S1t?S0l2t S0t?S1t?S0rt S0t?S1t?S0r2tS0t?S1t?S1lt S0t?S1t?S1l2t S0t?S1t?S1rt S0t?S1t?S1r2tValancy featuresS0wvlS0tvlS0wvrS0tvrS1wvlS1tvlS1wvrS1tvrLabel set featuresS0wsrS0tsrS0wslS0tslS1wslS1tslProposed new feature templates for the joint modelGuided head featuresS0w?hguideS0t?hguideS0wt?hguideS1w?hguideS1t?hguidehguideGuided label featuresS0w?S0lguideS0t?S0lguideS0wt?S0lguideS1w?S0lguideS1t?S0lguideS0lguideS0w?S1lguideS0t?S1lguideS0wt?S1lguideS1w?S1lguideS1t?S1lguideS1lguideTable 1: Feature templates for the baseline and joint models, where w denotes the word; t denotes thePOS tag; vland vrdenote the left and right valencies; l denotes the dependency label; sland srdenotesthe label sets of the left and right children; the subscripts l and r denote the left-most and the right-mostchildren, respectively; the subscripts l2 and r2 denote the second left-most and the second right-mostchildren, respectively; hguidedenotes the head direction of the top two elements on the processing stackin the other tree; lguidedenotes the label of the same word in the other tree.build a specific tree of scheme b for the same sentence are Ab1Ab2?
?
?Abn.
We use STa0STa1?
?
?
STanandSTb0STb1?
?
?
STbnto denote the historical states for the two action sequences, respectively.
A sequence ofactions should consist of Aa1Aa2?
?
?Aanand Ab1Ab2?
?
?Abnin a joint model.
However, one question thatneeds to be answered is that, for a joint state (STai,STbj), which action should be chosen as the next stepto merge the two action sequences into one sequence, Aai+1or Abj+1?
To resolve the problem, we employa parameter t to limit the next action in the joint model.
When t is above zero, an action for scheme bcan be applied only if the last action of scheme a is t steps in advance.
For example, the action sequenceis Aa1Ab1Aa2Ab2?
?
?AanAbnwhen t = 1. t can be negative as well, denoting the reverse constraints.In the joint model, we extract features separately for the two dependency schemes.
When the nextaction is aimed for scheme a, we will extract features from Saand Qa, according to baseline featuretemplates in Table 1.
In order to make use of the correlations between the two dependency parsing trees,we introduce several new feature templates, shown in Table 1 referring to proposed new feature templatesfor the joint model.
The new features are based on two kinds of atomic features: the guided head hguideand the guided dependency label lguide.
Assuming that the currently processing scheme is a, when thetop two elements (Sa0and Sa1) have both found their heads in Guidedb(the partial-parsed trees of schemeb), we can fire the atomic feature hguide, which denotes the arc direction between S0and S1in Guideb(Sx0S1, Sy0S1or other).
When Sa0or Sa1has its dependency label in Guidedb, we can fire the atomicfeature lguide, which denotes the dependency label of Sa0or Sa1in Guidedb.
Similarly we can extract thehguideand lguidefrom Guideawhen we are processing scheme b.
When t is infinite, we always have533the two atomic features, because the other tree is already parsed.
Thus the proposed new features can bethe most effective when t = ?
and t = ??.
In other conditions, the other tree may not be ready forthe new feature extracting.
Similar to the baseline model, we use the beam-search decoding strategy toreduce the search space, and use the averaged perceptron with early-update to learn the feature weights.We are especially interested in two cases of the joint models when t is infinite (t =?
and t = ??
),where the tree of one specified scheme is always processed after the other tree is finished, because thenew features can be most effectively exploited according to the above analysis.
We assume that the firstand second processing schemes are s1and s2respectively, to facilitate the below descriptions.
We can seethat the joint model behaves similarly to a pipeline reranking model, in optimizing scheme s1?s parsingperformances.
First we get K-best (K equals the beam size of the joint model) candidates for scheme s1,and then employ additional evidences from scheme s2?s result, to rerank the K-best candidates, obtaininga better result.
The joint model also behaves similarly to a pipeline feature-based stacking model (Li etal., 2012), in optimizing scheme s2?s parsing performances.
After acquiring the best result of schemes1, we can use it to generate guided features to parse dependencies of scheme s2.
Thus additionalinformation from scheme s1can be imported into the parsing model of scheme s2.
Different with thepipeline reranking and the feature-based stacking models, we employ a single model to achieve the twogoals, making the interactions between the two schemes be better performed.4 Experiments4.1 Experimental SettingsIn order to evaluate the baseline and joint models, we conduct experiments on English and Chinese da-ta.
For English, we obtain heterogeneous dependencies by the Yamada and the Stanford schemes,respectively.
We transform the bracket constituent trees of English sentences into the Yamada dependen-cies with the Penn2Malt tool,1and into the Stanford dependencies with the Stanford parser version3.3.1.2Following the standard splitting of PTB, we use sections 2-21 as the training data set, section 22 asthe development data set, and section 23 as the final test data set.
For Chinese, we obtain heterogeneousdependencies by the Zhang and the Stanford schemes, respectively.
The Zhang dependencies areobtained by the Penn2Malt tool using the head rules from Zhang and Clark (2008), while the Stanforddependencies are obtained by the Stanford parser version 3.3.1 similar to English.We use predicted POS tags in all the experiments.
We utilize a linear-CRF POS tagger to obtainautomatic POS tags for English and Chinese datasets.3We use a beam size of 64 to train dependencyparsing models.
We train the joint models with the Yamada or Zhang dependencies being handledon stack Saand queue Qa, and the Stanford dependencies being handled on stack Sband queue Qb,referring to Section 3.
We follow the standard measures of dependency parsing to evaluate the baselineand joint models, including unlabeled attachment score (UAS), labeled attachment score (LAS) andcomplete match (CM).
We ignore the punctuation words for all these measures.4.2 Development Results4.2.1 BaselineTable 2 at the subtable ?Baseline?
shows the baseline results on the development data set.
The perfor-mances of the Yamada scheme are better than those of the Stanford scheme.
The UAS and LAS ofthe Yamada scheme are 92.83 and 91.73 respectively, while they are 92.85 and 90.49 for the Stanfordscheme respectively.
The results demonstrate that parsing the Stanford dependencies is more difficultthan parsing the Yamada dependencies because of the lower performances of the Stanford scheme.1http://stp.lingfil.uu.se/?nivre/research/Penn2Malt.html.2The tool is available on http://nlp.stanford.edu/software/lex-parser.shtml.
We use three options toperform the conversion: ?-basic?
and ?-keepPunct?, respectively.3The tagging accuracies are 97.30% on the English test dataset and 93.68% on the Chinese test dataset.
We thank HaoZhang for sharing the data used in Martins et al.
(2013) and Zhang et al.
(2013a).534ModelYamada StanfordUAS LAS CM UAS LAS CMBaseline 92.83 91.73 47.35 92.85 90.49 50.06The joint models,where the Yamada dependencies are processed with priorityt = 1 92.65 91.55 46.35 93.11 90.75 50.24t = 2 92.65 91.57 46.71 93.15 90.77 50.59t = 3 92.82 91.74 47.12 93.19 90.82 50.76t = 4 92.89 91.78 47.35 93.27 90.93 51.29t =?
93.04 92.01 48.65 93.52 91.15 52.59The joint models,where the Stanford dependencies are processed with priorityt = ?1 92.62 91.54 46.71 93.10 90.70 50.76t = ?2 92.50 91.41 46.18 93.06 90.74 51.12t = ?3 92.57 91.42 47.00 93.10 90.68 51.35t = ?4 92.74 91.60 47.41 93.15 90.72 51.29t = ??
93.04 91.95 47.88 93.19 90.91 50.71Table 2: The main results on the development data set of the baseline and proposed joint models.4.2.2 Parameter TuningThe proposed joint model has one parameter t to adjust.
The parameter t is used to control the decoding ina joint model, determining which kind of dependencies should be processed at the next step.
In our jointmodel, if t is larger than zero, scheme a (the Yamada scheme) should be handled t steps in advance,while when t is smaller than zero, scheme b (the Stanford scheme) should be handled in advance.When the value of t is infinite, the dependency tree of one scheme is handled until the dependency treeof the other scheme is finished for a sentence.As shown by Table 2, we have two major findings.
First, the joint models are slightly better when t isabove zero, by decoding with the Yamada scheme in advance.
The phenomenon demonstrates that thedecoding sequence is important in the joint parsing models.
Second, no matter when t is above or belowzero, the performances arrive at the peak when t is infinite.
One benefit of the joint models is that wecan use the correlations between different dependency trees, through the new features proposed by us.The new features can be the most effective when t is infinite according to the analysis Section 3.
Thusthis finding indicates that the new features are crucial in the joint models, since the ineffective utilizationwould decrease the model performances a lot.
Actually, when the absolute value of t is small, the featurescan sometimes be fired and in some other times are not able to be fired, making the training insufficientand also inconsistent for certain word-pair dependencies when their distances can differ (when t = 1 forexample, the joint model can fire the new features only if the dependency distance equals 1).
This wouldmake the final model deficient, and can even hurt performances of the Yamada scheme.According to the results on the development data set, we use the t = ?
for the final joint model,which first finishes the Yamada tree and then the Stanford tree for each sentence.
Our final modelachieves increases of 0.21 on UAS and 0.28 on LAS for the Yamada scheme, and increases 0.67 onUAS and 0.66 on LAS for the Stanford scheme.4.2.3 Feature AblationIn order to test the effectiveness of the proposed new features, we conduct a feature ablation experiment.Table 3 shows the results, where the mark ?/wo?
denotes the model without the new features proposedby us.
For the Yamada scheme, losses of 0.15 on UAS and 0.21 on LAS are shown without the newfeatures.
While for Stanford scheme, larger decreases are shown by 0.57 on UAS and 0.58 on LAS,respectively.
The results demonstrate the new features are effective in the joint model.535ModelYamada StanfordUAS LAS CM UAS LAS CMOur joint model 93.04 92.01 48.65 93.52 91.15 52.59Our joint model/wo 92.89 91.80 48.25 92.95 90.57 50.62?
-0.15 -0.21 -0.40 -0.57 -0.58 -1.97Table 3: Feature ablation results.ModelYamada StanfordUAS LAS CM UAS LAS CMBaseline 92.71 91.67 47.48 92.72 90.61 47.76Our joint model 92.89 91.86 48.39 93.30?91.19?50.37Zhang and Nivre (2011) 92.9 91.8 48.0 ?
?
?Rush and Petrov (2012) ?
?
?
92.7??
?Martins et al.
(2013) 93.07 ?
?
92.82??
?Zhang et al.
(2013a) 93.50 92.41 ?
93.64?91.28?
?Zhang and McDonald (2014) 93.57 92.48 ?
93.71?/93.01??91.37?/90.64??
?Kong and Smith (2014) ?
?
?
92.20??89.67??
?Table 4: The final results on the test data set, where the results with mark?demonstrates that the p-valueis below 10?3using t-test.
Our Stanford dependencies are slightly different with previous works, wherethe results with mark?show the numbers for the Stanford dependencies from Stanford parser version2.0.5 and the results with mark?
?show the numbers for the Stanford dependencies from Stanford parserversion 3.3.0.4.3 Final ResultsTable 4 shows our final results on the English test dataset.
The final joint model achieves better per-formances than the baseline models for both the Yamada and the Stanford schemes, by increasesof 0.18 on UAS and 0.19 on LAS for the Yamada scheme, and increases of 0.58 on UAS and 0.58on LAS for the Stanford scheme.
The results demonstrate that the interactions between the two de-pendency schemes are useful, and the joint model is superior to separately trained models in handlingheterogeneous dependencies.We compare our results with some representative previous work of dependency parsing as well.
Zhangand Nivre (2011) is a feature-rich transition-based dependency parser using the arc-eager transition sys-tem.
Rush and Petrov (2012), Zhang et al.
(2013a) and Zhang and McDonald (2014) are state-of-the-artgraph-based dependency parsers.
Martins et al.
(2013) and Kong and Smith (2014) report their resultswith the full TurboParser.
TurboParser is also a graph-based dependency parser but its decoding algo-rithm has major differences with the general MST-style decoding.4.4 AnalysisTo better understand the joint model, we conduct analysis work on the Chinese development dataset.First, we make a comparison to see whether the consistent dependencies give larger increases by thejoint model.
As mentioned before, the consistent dependencies can be supported by different evidencesfrom heterogeneous dependencies.
We compute the proportion of the consistent dependencies (ignoringthe dependency labels) between the Yamada and the Stanford dependencies, finding that 70.27% ofthe overall dependencies are consistent.
Table 5 shows the comparison results.
The joint model showsimprovements for the consistent dependencies.
However, it does not always show positive effectivenessfor the inconsistent dependencies.
The results support our initial motivation that consistent dependenciescan benefit much in joint models .We also make a comparison between the baseline and joint models with respect to dependency dis-tance.
We use the F-measure value to evaluate the performances.
The dependency distances are normal-536Yamada StanfordConsistent Inconsistent Consistent InconsistentUAS LAS UAS LAS UAS LAS UAS LASBaseline 93.43 92.39 91.44 90.17 93.74 91.35 90.75 88.47Our joint model 93.81 92.85 91.21 90.02 94.58 92.15 91.01 88.78?
+0.38 +0.46 -0.23 -0.15 +0.84 +0.80 +0.36 +0.31Table 5: Performances of the baseline and joint models by whether the dependencies are consistentacross the Yamada and the Stanford schemes, where the bold numbers denote the larger increases bycomparisons of consistent and inconsistent dependencies for each scheme.1 2 3 4 5 6 77580859095F-measure(%)Baseline Joint(a) Yamada1 2 3 4 5 6 765758595F-measure(%)Baseline Joint(b) StanfordFigure 3: F-measures of the two heterogeneous dependencies with respect to dependency distance.ized to a max value of 7.
Figure 3 shows the comparison results.
We find that the joint model can achieveconsistent better performances for the dependencies of different dependency distance, demonstrating therobustness of the joint model in improving parsing performances.
The joint model performs slightlybetter for long-distance dependencies, which is more obvious for the Stanford scheme.4.5 Parsing Heterogeneous Chinese DependenciesTable 6 shows our final results on the Chinese test data set.
For Chinese, the joint model achieves betterperformances with Stanford dependencies being parsed first.
The final joint model achieves betterperformances than the baseline models for both the Zhang and the Stanford schemes, by increasesof 1.13 on UAS and 0.99 on LAS for the Zhang scheme, and increases of 0.30 on UAS and 0.36 onLAS for the Stanford scheme.
The results also demonstrate similar conclusions with the experimentson English dataset.5 Related WorkOur work is mainly inspired by the work of joint models.
There are a number of successful studieson joint modeling pipelined tasks where one task is a prerequisite step of another task, for example,the joint model of word segmentation and POS-tagging (Jiang et al., 2008; Kruengkrai et al., 2009;Zhang and Clark, 2010), the joint model of POS-tagging and parsing (Li et al., 2011; Hatori et al., 2011;Bohnet and Nivre, 2012), the joint model of word segmentation, POS-tagging and parsing (Hatori etModelZhang StanfordUAS LAS CM UAS LAS CMBaseline 79.07 76.08 27.96 80.33 75.29 31.14Our joint model 80.20?77.07?30.10 80.63 75.65 31.20Table 6: The final results on the test data set, where the results with mark?demonstrates that the p-valueis below 10?3using t-test.537al., 2012; Zhang et al., 2013b; Zhang et al., 2014), and the joint model of morphological and syntacticanalysis tasks (Bohnet et al., 2013).
In our work, we propose a joint model on parallel tasks, to parse twoheterogeneous dependency trees simultaneously.There has been a line of work on exploiting multiple treebanks with heterogeneous dependencies toenhance dependency parsing.
Li et al.
(2012) proposed a feature-based stacking model to enhance aspecific target dependency parser with the help of another treebank.
Zhou and Zhao (2013) presenteda joint inference framework to combine the parsing results based on two different treebanks.
All thesework are case studies of annotation adaptation from different sources, which have been done for Chineseword segmentation and POS-tagging as well (Jiang et al., 2009; Sun and Wan, 2012).
In contrast to theirwork, we study the heterogeneous annotations derived from the same source.
We use a unified model toparsing heterogeneous dependencies together.Our joint parsing model exploits a transition-based framework with global learning and beam-searchdecoding (Zhang and Clark, 2011), extended from a arc-standard transition-based parsing model (Huanget al., 2009).
The transition-based framework is easily adapted to a number of joint models, includingjoint word segmentation and POS-tagging (Zhang and Clark, 2010), the joint POS-tagging and parsing(Hatori et al., 2012; Bohnet and Nivre, 2012), and also joint word segmentation, POS-tagging and parsing(Hatori et al., 2012; Zhang et al., 2013b; Zhang et al., 2014).6 ConclusionsWe studied the effectiveness of the correlations between different constituent-to-dependency schemesfor dependency parsing, by exploiting these information with a joint model to parse two heterogeneousdependency trees simultaneously.
We make a novel extension to a transition-based arc-standard depen-dency parsing algorithm for the joint model.
We evaluate our baseline and joint models on both Englishand Chinese datasets, based on the Yamada/Zhang and the Stanford dependency schemes.
Finalresults demonstrate that the joint model which handles two heterogeneous dependencies can give im-proved performances for dependencies of both schemes.
The source code for the joint model is publiclyavailable at http://sourceforge.net/projects/zpar/,version0.7.AcknowledgmentsWe thank Yue Zhang and the anonymous reviewers for their constructive comments, and grateful-ly acknowledge the support of the National Basic Research Program (973 Program) of China viaGrant 2014CB340503, the National Natural Science Foundation of China (NSFC) via Grant 61133012,61170144 and 61370164.ReferencesBernd Bohnet and Joakim Nivre.
2012.
A transition-based system for joint part-of-speech tagging and labelednon-projective dependency parsing.
In Proceedings of the EMNLP-CONLL, pages 1455?1465, Jeju Island,Korea, July.Bernd Bohnet, Joakim Nivre, Igor Boguslavsky, Rich?ard Farkas Filip Ginter, and Jan Hajic.
2013.
Joint morpho-logical and syntactic analysis for richly inflected languages.
TACL, 1.Jinho D. Choi and Andrew McCallum.
2013.
Transition-based dependency parsing with selectional branching.
InProceedings of ACL, pages 1052?1062, August.Michael Collins and Brian Roark.
2004.
Incremental parsing with the perceptron algorithm.
In Proceedings of theACL, pages 111?118, Barcelona, Spain, July.Marie-Catherine de Marneffe and Christopher D. Manning.
2008.
The Stanford typed dependencies representa-tion.
In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,pages 1?8, Manchester, UK, August.Jakob Elming, Anders Johannsen, Sigrid Klerke, Emanuele Lapponi, Hector Martinez Alonso, and AndersS?gaard.
2013.
Down-stream effects of tree-to-dependency conversions.
In Proceedings of the NAACL, pages617?626, Atlanta, Georgia, June.538Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii.
2011.
Incremental joint POS tagging anddependency parsing in Chinese.
In Proceedings of 5th IJCNLP, pages 1216?1224, Chiang Mai, Thailand,November.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun?ichi Tsujii.
2012.
Incremental joint approach to wordsegmentation, POS tagging, and dependency parsing in Chinese.
In Proceedings of the 50th ACL, pages 1045?1053, Jeju Island, Korea, July.Liang Huang, Wenbin Jiang, and Qun Liu.
2009.
Bilingually-constrained (monolingual) shift-reduce parsing.
InProceedings of the EMNLP, pages 1222?1231.Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan L?u.
2008.
A cascaded linear model for joint Chinese wordsegmentation and part-of-speech tagging.
In Proceedings of ACL-08, pages 897?904, Columbus, Ohio, June.Wenbin Jiang, Liang Huang, and Qun Liu.
2009.
Automatic adaptation of annotation standards: Chinese wordsegmentation and POS tagging: a case study.
In Proceedings of the ACL-IJCNLP, pages 522?530.Richard Johansson and Pierre Nugues.
2007.
Extended constituent-to-dependency conversion for english.
InProceedings of NODALIDA 2007, Tartu, Estonia.Lingpeng Kong and Noah A Smith.
2014.
An empirical comparison of parsing methods for stanford dependencies.arXiv preprint arXiv:1404.4314.Terry Koo and Michael Collins.
2010.
Efficient third-order dependency parsers.
In Proceedings of the 48th AnnualMeeting of the ACL, pages 1?11.Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichi Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi Isahara.2009.
An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging.
InProceedings of the ACL-IJCNLP, pages 513?521, Suntec, Singapore, August.Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wenliang Chen, and Haizhou Li.
2011.
Joint models forChinese POS tagging and dependency parsing.
In Proceedings of the EMNLP, pages 1180?1191, Edinburgh,Scotland, UK., July.Zhenghua Li, Ting Liu, and Wanxiang Che.
2012.
Exploiting multiple treebanks for parsing with quasi-synchronous grammars.
In Proceedings of the 50th ACL, pages 675?684, Jeju Island, Korea, July.Andre Martins, Miguel Almeida, and Noah A. Smith.
2013.
Turning on the turbo: Fast third-order non-projectiveturbo parsers.
In Proceedings of the 51st ACL, pages 617?622, Sofia, Bulgaria, August.
Association for Com-putational Linguistics.Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005.
Online large-margin training of dependencyparsers.
In Proceedings of ACL, number June, pages 91?98, Morristown, NJ, USA.Jens Nilsson, Sebastian Riedel, and Deniz Yuret.
2007.
The CoNLL 2007 shared task on dependency parsing.
InProceedings of the CoNLL Shared Task Session of EMNLP-CoNLL, pages 915?932.Joakim Nivre.
2008.
Algorithms for deterministic incremental dependency parsing.
Computational Linguistics,34(4):513?553.Alexander M Rush and Slav Petrov.
2012.
Vine pruning for efficient multi-pass dependency parsing.
In Proceed-ings of the NAACL, pages 498?507.Francesco Sartorio, Giorgio Satta, and Joakim Nivre.
2013.
A transition-based dependency parser using a dynamicparsing strategy.
In Proceedings of the 51st ACL, pages 135?144, Sofia, Bulgaria, August.Weiwei Sun and Xiaojun Wan.
2012.
Reducing approximation and estimation errors for Chinese lexical processingwith heterogeneous annotations.
In Proceedings of the 50th ACL, pages 232?241, Jeju Island, Korea, July.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statistical dependency analysis with support vector machines.
InProceedings of IWPT, volume 3.Yue Zhang and Stephen Clark.
2008.
A tale of two parsers: Investigating and combining graph-based andtransition-based dependency parsing.
In Proceedings of EMNLP, pages 562?571, Honolulu, Hawaii, October.Yue Zhang and Stephen Clark.
2010.
A fast decoder for joint word segmentation and POS-tagging using a singlediscriminative model.
In Proceedings of the EMNLP, pages 843?852, Cambridge, MA, October.539Yue Zhang and Stephen Clark.
2011.
Syntactic processing using the generalized perceptron and beam search.Computational Linguistics, 37(1):105?151.Hao Zhang and Ryan McDonald.
2012.
Generalized higher-order dependency parsing with cube pruning.
InProceedings of the EMNLP, pages 320?331.Hao Zhang and Ryan McDonald.
2014.
Enforcing structural diversity in cube-pruned dependency parsing.
InProceedings of ACL.
Association for Computational Linguistics.Yue Zhang and Joakim Nivre.
2011.
Transition-based dependency parsing with rich non-local features.
In Pro-ceedings of the 49th ACL, pages 188?193, Portland, Oregon, USA, June.Hao Zhang, Liang Huang, Kai Zhao, and Ryan McDonald.
2013a.
Online learning for inexact hypergraph search.In Proceedings of the EMNLP, pages 908?913, Seattle, Washington, USA, October.
Association for Computa-tional Linguistics.Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu.
2013b.
Chinese parsing exploiting characters.
InProceedings of the 51st ACL, pages 125?134, Sofia, Bulgaria, August.Meishan Zhang, Yue Zhang, Wanxiang Che, and Ting Liu.
2014.
Character-level Chinese Dependency Parsing.In Proceedings of the 52st ACL.Guangyou Zhou and Jun Zhao.
2013.
Joint inference for heterogeneous dependency parsing.
In Proceedings ofthe 51st ACL, pages 104?109, Sofia, Bulgaria, August.540
