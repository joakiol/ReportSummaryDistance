Situated Reference in a Hybrid Human-Robot Interaction SystemManuel Giuliani1 and Mary Ellen Foster2 and Amy Isard3Colin Matheson3 and Jon Oberlander3 and Alois Knoll11Informatik VI: Robotics and Embedded Systems, Technische Universita?t Mu?nchen2School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh3Institute for Communicating and Collaborative Systems, School of Informatics, University of EdinburghAbstractWe present the situated reference genera-tion module of a hybrid human-robot in-teraction system that collaborates with ahuman user in assembling target objectsfrom a wooden toy construction set.
Thesystem contains a sub-symbolic goal in-ference system which is able to detect thegoals and errors of humans by analysingtheir verbal and non-verbal behaviour.
Thedialogue manager and reference genera-tion components then use situated refer-ences to explain the errors to the humanusers and provide solution strategies.
Wedescribe a user study comparing the resultsfrom subjects who heard constant refer-ences to those who heard references gener-ated by an adaptive process.
There was nodifference in the objective results acrossthe two groups, but the subjects in theadaptive condition gave higher subjectiveratings to the robot?s abilities as a conver-sational partner.
An analysis of the objec-tive and subjective results found that themain predictors of subjective user satisfac-tion were the user?s performance at the as-sembly task and the number of times theyhad to ask for instructions to be repeated.1 IntroductionWhen two humans jointly carry out a mutual taskfor which both know the plan?for example, as-sembling a new shelf?it frequently happens thatone makes an error, and the other has to assistand to explain what the error was and how it canbe solved.
Humans are skilled at spotting errorscommitted by another, as well as errors whichthey made themselves.
Recent neurological stud-ies have shown that error monitoring?i.e., ob-serving the errors made by oneself or by others?plays an important role in joint activity.
For ex-ample, Bekkering et al (2009) have demonstratedthat humans show the same brain activation pat-terns when they make an error themselves andwhen they observe someone else making an error.In this paper, we describe a human-robot inter-action (HRI) system that is able both to analysethe actions and the utterances of a human part-ner to determine if the human made an error inthe assembly plan, and to explain to the humanwhat went wrong and what to do to solve the prob-lem.
This robot combines approaches from sub-symbolic processing and symbolic reasoning in ahybrid architecture based on that described in Fos-ter et al (2008b).During the construction process, it is frequentlynecessary to refer to an object which is being usedto assemble the finished product, choosing an un-ambigious reference to distinguish the object fromthe others available.
The classic reference gen-eration algorithm, on which most subsequent im-plementations are based, is the incremental algo-rithm of Dale and Reiter (1995), which selectsa set of attributes of a target object to single itout from a set of distractor objects.
In real-worldtasks, the speaker and hearer often have more con-text in common than just the knowledge of objectattributes, and several extensions have been pro-posed, dealing with visual and discourse salience(Kelleher and Kruijff, 2006) and the ability to pro-duce multimodal references including actions suchas pointing (van der Sluis, 2005; Kranstedt andWachsmuth, 2005).Foster et al (2008a) noted another type of mul-timodal reference which is particularly useful inembodied, task-based contexts: haptic-ostensivereference, in which an object is referred to as itis being manipulated by the speaker.
Manipulat-ing an object, which must be done in any case aspart of the task, also makes an object more salientand therefore affords linguistic references that in-Figure 1: The dialogue robotdicate the increased accessibility of the referent.This type of reference is similar to the placing-foractions noted by Clark (1996).An initial approach for generating referring ex-pressions that make use of haptic-ostensive refer-ence was described in (Foster et al, 2009a).
Withthis system, a study was conducted comparing thenew reference strategy to the basic Dale and Reiterincremental algorithm.
Na?
?ve users reported that itwas significantly easier to understand the instruc-tions given by the robot when it used referencesgenerated by the more sophisticated algorithm.
Inthis paper, we perform a similar experiment, butmaking use of a more capable human-robot in-teraction system and a more complete process forgenerating situated references.2 Hybrid Human-Robot DialogueSystemThe experiment described in this paper makes useof a hybrid human-robot dialogue system whichsupports multimodal human-robot collaborationon a joint construction task.
The robot (Figure 1)has a pair of manipulator arms with grippers,mounted in a position to resemble human arms,and an animatronic talking head (van Breemen,2005) capable of producing facial expressions,rigid head motion, and lip-synchronised synthe-sised speech.
The subject and the robot work to-gether to assemble wooden construction toys ona common workspace, coordinating their actionsthrough speech (English or German), gestures, andfacial expressions.The robot can pick up and move objects in theworkspace and perform simple assembly tasks.
Inthe scenario considered here, both of the partici-pants know the assembly plan and jointly executeit.
The robot assists the human, explains necessaryassembly steps in case the human makes an error,and offers pieces as required.
The workspace is di-vided into two areas?one belonging to the robotand one to the human?to make joint action nec-essary for task success.The system has components which use bothsub-symbolic and symbolic processing.
It in-cludes a goal inference module based on dynamicneural fields (Erlhagen and Bicho, 2006; Bichoet al, 2009), which selects the robot?s next actionsbased on the human user?s actions and utterances.Given a particular assembly plan and the knowl-edge of which objects the user has picked up, thismodule can determine when the user has madean error.
The system also incorporates a dialoguemanager based on the TrindiKit dialogue manage-ment toolkit (Larsson and Traum, 2000), whichimplements the information-state based approachto dialogue management.
This unique combina-tion of abilities means that when the robot detectsthat its human partner has made an error?for ex-ample, picking up or requesting an assembly piecethat is not needed in the current step of the buildingplan?it can explain to the human what the errorwas and what can be done to correct the mistake?for example by picking up or indicating the correctassembly piece.Messages from all of the system?s input chan-nels (speech, object recognition, and gesturerecognition) are processed and combined by amultimodal fusion component based on (Giulianiand Knoll, 2008), which is the link between thesymbolic and the sub-symbolic parts of the sys-tem.
The fusion component then communicateswith the goal inference module, which calculatesthe next action instructions for the robot and alsodetermines if the user made an error.
From there,fusion combines the information from goal infer-ence with the input data and sends unified hy-potheses to the dialogue manager.When it receives the fusion hypotheses, the dia-logue manager uses the dialogue history and thephysical and task context to choose a response.It then sends a high-level specification of the de-1.
System First we will build a windmill.2.
User Okay.3.
User {picks up a yellow cube, unnecessary piece for awindmill}4.
System You don?t need a yellow cube to build a windmill.5.
System To build a windmill, you first need to build atower.6.
System [picking up and holding out red cube] To buildthe tower, insert the green bolt through the end of thisred cube and screw it into the blue cube.7.
User [takes cube, performs action] Okay.Figure 2: Sample human-robot dialogue, showingadaptively-generated situated referencessired response to the output planner, which in turnsends commands to each output channel: linguis-tic content (including multimodal referring ex-pressions), facial expressions and gaze behavioursof the talking head, and actions of the robot ma-nipulators.
The linguistic outputs are realised us-ing the OpenCCG surface realiser (White, 2006).3 Reference GenerationIn this system, two strategies were implementedfor generating references to objects in the world:a constant version that uses only the basic incre-mental algorithm (Dale and Reiter, 1995) to se-lect properties, and an adaptive version that usesmore of the physical, dialogue and task contextto help select the references.
The constant sys-tem can produce a definite or indefinite reference,and the most appropriate combination of attributesaccording to the incremental algorithm.
The adap-tive system also generates pronominal and deicticreferences, and introduces the concept of multipletypes of distractor sets depending on context.Figure 2 shows a fragment of a sample interac-tion in which the user picks up an incorrect piece:the robot detects the error and describes the correctassembly procedure.
The underlined referencesshow the range of output produced by the adap-tive reference generation module; for the constantsystem, the references would all have been ?thered cube?.
The algorithms used by the adaptivereference generation module are described below.3.1 Reference AlgorithmThe module stores a history of the referring ex-pressions spoken by both the system and the user,and uses these together with distractor sets to se-lect referring expressions.
In this domain there aretwo types of objects which we need to refer to:concrete objects in the world (everything which ison the table, or in the robot?s or user?s hand), andobjects which do not yet exist, but are in the pro-cess of being created.
For non-existent objects wedo not build a distractor set, but simply use thename of the object.
In all other cases, we use oneof three types of distractor set:?
all the pieces needed to build a target object;?
all the objects referred to since the last men-tion of this object; or?
all the concrete objects in the world.The first type of set is used if the object underconsideration (OUC) is a negative reference to apiece in context of the creation of a target object.In all other cases, the second type is used if theOUC has been mentioned before and the third typeif it has not.When choosing a referring expression, we firstprocess the distractor set, comparing the proper-ties of the OUC with the properties of all distrac-tors.
If a distractor has a different type from theOUC, it is removed from the distractor set.
Withall other properties, if the distractor has a differentvalue from the OUC, it is removed from the dis-tractor set, and the OUC?s property value is addedto the list of properties to use.We then choose the type of referring expression.We first look for a previous reference (PR) to theOUC, and if one exists, determine whether it wasin focus.
Depending on the case, we use one of thefollowing reference strategies.No PR If the OUC does not yet exist or we aremaking a negative reference, we use an indef-inite article.
If the robot is holding the OUC,we use a deictic reference.
If the OUC doesexist and there are no distractors, we use adefinite; if there are distractors we use an in-definite.PR was focal If the PR was within the same turn,we choose a pronoun for our next reference.If it was in focus but in a previous turn, ifthe robot is holding the OUC we use a deicticreference, and if the robot is not holding it,we use a pronoun.PR was not focal If the robot is holding theOUC, we make a deictic reference.
Other-wise, if the PR was a pronoun, definite, or de-ictic, we use a definite article.
If the PR wasindefinite and there are no distractors, we usea definite article, if there are distractors, weuse an indefinite article.If there are any properties in the list, and thereference chosen is not a pronoun, we add them.3.2 Examples of the Reference AlgorithmWe will illustrate the reference-selection strategywith two cases from the dialogue in Figure 2.Utterance 4 ?a yellow cube?This object is going to be referred to in a negativecontext as part of a windmill under construction,so the distractor set is the set of objects needed tomake a windmill: {red cube, blue cube, small slat,small slat, green bolt, red bolt}.We select the properties to use in describing theobject under consideration, processing the distrac-tor set.
We first remove all objects which do notshare the same type as our object under considera-tion, which leaves {red cube, blue cube}.
We thencompare the other attributes of our new object withthe remaining distractors - in this case ?colour?.Since neither cube shares the colour ?yellow?
withthe target object, both are removed from the dis-tractor set, and ?yellow?
is added to the list ofproperties to use.There is no previous reference to this object,and since we are making a negative reference,we automatically choose an indefinite article.
Wetherefore select the reference ?a yellow cube?.Utterance 6 ?it?
(a green bolt)This object has been referred to before, earlier inthe same utterance, so the distractor set is all thereferences between the earlier one and this one?
{red cube}.
Since this object has a different typefrom the bolt we want to describe, the distractorset is now empty, and nothing is added to the listof properties to use.There is a previous definite reference to the ob-ject in the same utterance: ?the green bolt?.
Thisreference was focal, so we are free to use a pro-noun if appropriate.
Since the previous referencewas definite, and the object being referred to doesexist, we choose to use a pronoun.
We thereforeselect the reference ?it?.4 Experiment DesignIn the context of the HRI system, a constant refer-ence strategy is sufficient in that it makes it possi-ble for the robot?s partner to know which item isneeded.
On the other hand, while the varied formsproduced by the more complex mechanism can in-crease the naturalness of the system output, theymay actually be insufficient if they are not usedin appropriate current circumstances?for exam-ple, ?this cube?
is not a particularly helpful refer-ence if a user has no way to tell which ?this?
is.As a consequence, the system for generating suchreferences must be sensitive to the current stateof joint actions and?in effect?of joint attention.The difference between the two systems is a test ofthe adaptive version?s ability to adjust expressionsto pertinent circumstances.
It is known that peo-ple respond well to reduced expressions like ?thiscube?
or ?it?
when another person uses them ap-propriately (Bard et al, 2008); we need to see ifthe robot system can also achieve the benefits thatsituated reference could provide.To address this question, the human-robot di-alogue system was evaluated through a user studyin which subjects interacted with the complete sys-tem.
Using a between-subjects design, this studycompared the two reference strategies, measuringthe users?
subjective reactions to the system alongwith their overall performance in the interaction.Based on the findings from the user evaluation de-scribed in (Foster et al, 2009a)?in which the pri-mary effect of varying the reference strategy wason the users?
subjective opinion of the robot?themain prediction for this study was as follows:?
Subjects who interact with a system usingadaptive references will rate the quality ofthe robot?s conversation more highly than thesubjects who hear constant references.We made no specific prediction regarding theeffect of reference strategy on any of the objec-tive measures: based on the results of the userevaluation mentioned above, there is no reason toexpect an effect either way.
Note that?as men-tioned above?if the adaptive version makes in-correct choices, that may have a negative impacton users?
ability to understand the system?s gener-ated references.
For this reason, even a finding of(a) Windmill (b) Railway signalFigure 3: Target objects for the experimentno objective difference would demonstrate that theadaptive references did not harm the users?
abilityto interact with the system, as long as it was ac-companied by the predicted improvement in sub-jective judgements.4.1 Subjects41 subjects (33 male) took part in this experiment.The mean age of the subjects was 24.5, with a min-imum of 19 and a maximum of 42.
Of the subjectswho indicated an area of study, the two most com-mon areas were Mathematics (14 subjects) and In-formatics (also 14 subjects).
On a scale of 1 to 5,subjects gave a mean assessment of their knowl-edge of computers at 4.1, of speech-recognitionsystems at 2.0, and of human-robot systems at 1.7.Subjects were compensated for their participationin the experiment.4.2 ScenarioThis study used a between-subjects design withone independent variable: each subject interactedeither with a system that used a constant strategyto generate referring expressions (19 subjects), orelse with a system that used an adaptive strategy(22 subjects).1Each subject built two objects in collaborationwith the system, always in the same order.
Thefirst target object was the windmill (Figure 3a);after the windmill was completed, the robot andhuman then built a railway signal (Figure 3b).
Forboth target objects, the user was given a buildingplan (on paper).
To induce an error, both of theplans given to the subjects instructed them to usean incorrect piece: a yellow cube instead of a redcube for the windmill, and a long (seven-hole) slatinstead of a medium (five-hole) slat for the rail-1The results of an additional three subjects in the constant-reference condition could not be analysed due to technicaldifficulties.way signal.
The subjects were told that the plancontained an error and that the robot would cor-rect them when necessary, but did not know thenature of the error.When the human picked up or requested an in-correct piece during the interaction, the system de-tected the error and explained to the human whatto do in order to assemble the target object cor-rectly.
When the robot explained the error andwhen it handed over the pieces, it used referringexpressions that were generated using the constantstrategy for half of the subjects, and the adaptivestrategy for the other half of the subjects.4.3 Experimental Set-up and ProcedureThe participants stood in front of the table facingthe robot, equipped with a headset microphone forspeech recognition.
The pieces required for thetarget object?plus a set of additional pieces in or-der to make the reference task more complex?were placed on the table, using the same layoutfor every participant.
The layout was chosen toensure that there would be points in the interactionwhere the subjects had to ask the robot for build-ing pieces from the robot?s workspace, as well assituations in which the robot automatically handedover the pieces.
Along with the building plan men-tioned above, the subjects were given a table withthe names of the pieces they could build the ob-jects with.4.4 Data AcquisitionAt the end of a trial, the subject responded toa usability questionnaire consisting of 39 items,which fell into four main categories: Intelligenceof the robot (13 items), Task ease and task suc-cess (12 items), Feelings of the user (8 items),and Conversation quality (6 items).
The items onthe questionnaire were based on those used in theuser evaluation described in (Foster et al, 2009b),but were adapted for the scenario and researchquestions of the current study.
The questionnairewas presented using software that let the subjectschoose values between 1 and 100 with a slider.
Inaddition to the questionnaire, the trials were alsovideo-taped, and the system log files from all tri-als were kept for further analysis.5 ResultsWe analysed the data resulting from this study inthree different ways.
First, the subjects?
responsesTable 1: Overall usability resultsConstant Adaptive M-WIntell.
79.0 (15.6) 74.9 (12.7) p = 0.19, n.s.Task 72.7 (10.4) 71.1 (8.3) p = 0.69, n.s.Feeling 66.9 (15.9) 66.8 (14.2) p = 0.51, n.s.Conv.
66.1 (13.6) 75.2 (10.7) p = 0.036, sig.Overall 72.1 (11.2) 71.8 (9.1) p = 0.68, n.s.to the questionnaire items were compared to de-termine if there was a difference between the re-sponses given by the two groups.
A range of sum-mary objective measures were also gathered fromthe log files and videos?these included the dura-tion of the interaction measured both in secondsand in system turns, the subjects?
success at build-ing each of the target objects, the number of timesthat the robot had to explain the construction planto the user, and the number of times that the usersasked the system to repeat its instructions.
Finally,we compared the results on the subjective and ob-jective measures to determine which of the objec-tive factors had the largest influence on subjectiveuser satisfaction.5.1 Subjective MeasuresThe subjects in this study gave a generally positiveassessment of their interactions with the system onthe questionnaire?with a mean overall satisfac-tion score of 72.0 out of 100?and rated the per-ceived intelligence of the robot particularly highly(overall mean of 76.8).
Table 1 shows the meanresults from the two groups of subjects for eachcategory on the user-satisfaction questionnaire, inall cases on a scale from 0?100 (with the scoresfor negatively-posed questions inverted).To test the effect of reference strategy on theusability-questionnaire responses, we performed aMann-Whitney test comparing the distribution ofresponses from the two groups of subjects on theoverall results, as well as on each sub-category ofquestions.
For most categories, there was no sig-nificant difference between the responses of thetwo groups, with p values ranging from 0.19 to0.69 (as shown in Table 1).
The only categorywhere a significant difference was found was onthe questionnaire items that asked the subjects toassess the robot?s quality as a conversational part-ner; for those items, the mean score from sub-jects who heard the adaptive references was sig-nificantly higher (p < 0.05) than the mean scorefrom the subjects who heard references generatedby the constant reference module.
Of the six ques-Table 2: Objective results (all differences n.s.
)Measure Constant Adaptive M-WDuration (s.) 404.3 (62.8) 410.5 (94.6) p = 0.90Duration (turns) 29.8 (5.02) 31.2 (5.57) p = 0.44Rep requests 0.26 (0.45) 0.32 (0.78) p = 0.68Explanations 2.21 (0.63) 2.41 (0.80) p = 0.44Successful trials 1.58 (0.61) 1.55 (0.74) p = 0.93tions that were related to the conversation quality,the most significant impact was on the two ques-tions which assessed the subjects?
understandingof what they were able to do at various points dur-ing the interaction.5.2 Objective MeasuresBased on the log files and video recordings, wecomputed a range of objective measures.
Thesemeasures were divided into three classes, basedon those used in the PARADISE dialogue-systemevaluation framework (Walker et al, 2000):?
Two dialogue efficiency measures: the meanduration of the interaction as measured bothin seconds and in system turns;?
Two dialogue quality measures: the numberof times that the robot gave explanations, andthe number of times that the user asked forinstructions to be repeated; and?
One task success measure: how many of the(two) target objects were constructed as in-tended (i.e., as shown in Figure 3).For each of these measures, we tested whether thedifference in reference strategy had a significanteffect, again via a Mann-Whitney test.
Table 2 il-lustrates the results on these objective measures,divided by the reference strategy.The results from the two groups of subjectswere very similar on all of these measures: onaverage, the experiment took 404 seconds (nearlyseven minutes) to complete with the constant strat-egy and 410 seconds with the adaptive, the meannumber of system turns was close to 30 in bothcases, just over one-quarter of all subjects askedfor instructions to be repeated, the robot gave justover two explanations per trial, and about three-quarters of all target objects (i.e.
1.5 out of 2)were correctly built.
The Mann-Whitney test con-firms that none of the differences between the twogroups even came close to significance on any ofthe objective measures.5.3 Comparing Objective and SubjectiveMeasuresIn the preceding sections, we presented results ona number of objective and subjective measures.While the subjects generally rated their experi-ence of using the system positively, there wassome degree of variation, most of which could notbe attributed to the difference in reference strat-egy.
Also, the results on the objective measuresvaried widely across the subjects, but again werenot generally affected by the reference strategy.In this section, we examine the relationship be-tween these two classes of measures in order todetermine which of the objective measures had thelargest effect on users?
subjective reactions to theHRI system.Being able to predict subjective user satisfac-tion from more easily-measured objective proper-ties can be very useful for developers of interac-tive systems: in addition to making it possible toevaluate systems based on automatically availabledata without the need for extensive experimentswith users, such a performance function can alsobe used in an online, incremental manner to adaptsystem behaviour to avoid entering a state that islikely to reduce user satisfaction (Litman and Pan,2002), or can be used as a reward function in areinforcement-learning scenario (Walker, 2000).We employed the procedure used in the PAR-ADISE evaluation framework (Walker et al,2000) to explore the relationship between the sub-jective and objective factors.
The PARADISEmodel uses stepwise multiple linear regression topredict subjective user satisfaction based on mea-sures representing the performance dimensions oftask success, dialogue quality, and dialogue effi-ciency, resulting in a predictor function of the fol-lowing form:Satisfaction =n?i=1wi ?N (mi)The mi terms represent the value of each measure,while the N function transforms each measureinto a normal distribution using z-score normali-sation.
Stepwise linear regression produces coef-ficients (wi) describing the relative contribution ofeach predictor to the user satisfaction.
If a predic-tor does not contribute significantly, its wi value iszero after the stepwise process.Table 3 shows the predictor functions that werederived for each of the classes of subjective mea-sures in this study, using all of the objective mea-sures from Table 2 as initial factors.
The R2 col-umn indicates the percentage of the variance in thetarget measure that is explained by the predictorfunction, while the Significance column gives sig-nificance values for each term in the function.In general, the two factors with the biggest in-fluence on user satisfaction were the number ofrepetition requests (which had a uniformly neg-ative effect on user satisfaction), and the num-ber of target objects correctly built by the user(which generally had a positive effect).
Asidefrom the questions on user feelings, the R2 valuesare generally in line with those found in previousPARADISE evaluations of other dialogue systems(Walker et al, 2000; Litman and Pan, 2002), andin fact are much higher than those found in a pre-vious similar study (Foster et al, 2009b).6 DiscussionThe subjective responses on the relevant itemsfrom the usability questionnaire suggest thatthe subjects perceived the robot to be a bet-ter conversational partner if it used contextuallyvaried, situationally-appropriate referring expres-sions than if it always used a baseline, constantstrategy; this supports the main prediction for thisstudy.
The result also agrees with the findings ofa previous study (Foster et al, 2009a)?this sys-tem did not incorporate goal inference and had aless-sophisticated reference strategy, but the maineffect of changing reference strategy was also onthe users?
subjective opinions of the robot?s inter-active ability.
These studies together support thecurrent effort in the natural-language generationcommunity to devise more sophisticated referencegeneration algorithms.On the other hand, there was no significant dif-ference between the two groups on any of theobjective measures: the dialogue efficiency, dia-logue quality, and task success were nearly iden-tical across the two groups of subjects.
A de-tailed analysis of the subjects?
gaze and object-manipulation behaviour immediately after variousforms of generated references from the robot alsofailed to find any significant differences betweenthe various reference types.
These overall resultsare not particularly surprising: studies of human-human dialogue in a similar joint construction task(Bard et al, In prep.)
have demonstrated that thecollaborators preserve quality of construction inTable 3: PARADISE predictor functions for each category on the usability questionnaireMeasure Function R2 SignificanceIntelligence 76.8+7.00?N (Correct)?5.51?N (Repeats) 0.39 Correct: p < 0.001,Repeats: p < 0.005Task 72.4+3.54?N (Correct)?3.45?N (Repeats)?2.17?N (Explain) 0.43 Correct: p < 0.005,Repeats: p < 0.01,Explain: p?
0.10Feeling 66.9?6.54?N (Repeats)+4.28?N (Seconds) 0.09 Repeats: p < 0.05,Seconds: p?
0.12Conversation 71.0+5.28?N (Correct)?3.08?N (Repeats) 0.20 Correct: p < 0.01,Repeats: p?
0.10Overall 72.0+4.80?N (Correct)?4.27?N (Repeats) 0.40 Correct: p < 0.001,Repeats: p < 0.005all cases, though circumstances may dictate whatstrategies they use to do this.
Combined with thesubjective findings, this lack of an objective effectsuggests that the references generated by the adap-tive strategy were both sufficient and more naturalthan those generated by the constant strategy.The analysis of the relationship between thesubjective and objective measures analysis hasalso confirmed and extended the findings from asimilar analysis (Foster et al, 2009b).
In thatstudy, the main contributors to user satisfactionwere user repetition requests (negative), task suc-cess, and dialogue length (both positive).
In thecurrent study, the primary factors were similar,although dialogue length was less prominent asa factor and task success was more prominent.These findings are generally intuitive: subjectswho are able to complete the joint constructiontask are clearly having more successful interac-tions than those who are not able to complete thetask, while subjects who need to ask for instruc-tions to be repeated are equally clearly not hav-ing successful interactions.
The findings add ev-idence that, in this sort of task-based, embodieddialogue system, users enjoy the experience morewhen they are able to complete the task success-fully and are able to understand the spoken contri-butions of their partner, and also suggest that de-signers should concentrate on these aspects of theinteraction when designing the system.7 ConclusionsWe have presented the reference generation mod-ule of a hybrid human-robot interaction systemthat combines a goal-inference component basedon sub-symbolic dynamic neural fields with anatural-language interface based on more tradi-tional symbolic techniques.
This combination ofapproaches results in a system that is able to worktogether with a human partner on a mutual con-struction task, interpreting its partner?s verbal andnon-verbal behaviour and responding appropri-ately to unexpected actions (errors) of the partner.We have then described a user evaluation of thissystem, concentrating on the impact of differenttechniques for generating situated references inthe context of the robot?s corrective feedback.
Theresults of this study indicate that using an adaptivestrategy to generate the references significantly in-creases the users?
opinion of the robot as a con-versational partner, without having any effect onany of the other measures.
This result agrees withthe findings of the system evaluation described in(Foster et al, 2009a), and adds evidence that so-phisticated generation techniques are able to im-prove users?
experiences with interactive systems.An analysis of the relationship between the ob-jective and subjective measures found that themain contributors to user satisfaction were theusers?
task performance (which had a positive ef-fect on most measures of satisfaction), and thenumber of times the users had to ask for instruc-tions to be repeated (which had a generally neg-ative effect).
Again, these results agree with thefindings of a previous study (Foster et al, 2009b),and also suggest priorities for designers of thistype of task-based interactive system.AcknowledgementsThis research was supported by the Euro-pean Commission through the JAST2 (IST-FP6-003747-IP) and INDIGO3 (IST-FP6-045388)projects.
Thanks to Pawel Dacka and Levent Kentfor help in running the experiment and analysingthe data.2http://www.jast-project.eu/3http://www.ics.forth.gr/indigo/ReferencesE.
G. Bard, R. Hill, and M. E. Foster.
2008.
Whattunes accessibility of referring expressions intask-related dialogue?
In Proceedings of the30th Annual Meeting of the Cognitive ScienceSociety (CogSci 2008).
Chicago.E.
G. Bard, R. L. Hill, M. E. Foster, and M. Arai.In prep.
How do we tune accessibility in jointtasks: Roles and regulations.H.
Bekkering, E.R.A.
de Bruijn, R.H. Cuijpers,R.
Newman-Norlund, H.T.
van Schie, andR.
Meulenbroek.
2009.
Joint action: Neurocog-nitive mechanisms supporting human interac-tion.
Topics in Cognitive Science, 1(2):340?352.E.
Bicho, L. Louro, N. Hipolito, and W. Erlhagen.2009.
A dynamic field approach to goal infer-ence and error monitoring for human-robot in-teraction.
In Proceedings of the Symposium on?New Frontiers in Human-Robot Interaction?,AISB 2009 Convention.
Heriot-Watt UniversityEdinburgh.H.
H. Clark.
1996.
Using Language.
CambridgeUniversity Press.R.
Dale and E. Reiter.
1995.
Computational inter-pretations of the Gricean maxims in the genera-tion of referring expressions.
Cognitive Science,19(2):233?263.W.
Erlhagen and E. Bicho.
2006.
The dynamicneural field approach to cognitive robotics.Journal of Neural Engineering, 3(3):R36?R54.M.
E. Foster, E. G. Bard, R. L. Hill, M. Guhe,J.
Oberlander, and A. Knoll.
2008a.
The rolesof haptic-ostensive referring expressions in co-operative, task-based human-robot dialogue.
InProceedings of HRI 2008.M.
E. Foster, M. Giuliani, A. Isard, C. Matheson,J.
Oberlander, and A. Knoll.
2009a.
Evaluatingdescription and reference strategies in a coop-erative human-robot dialogue system.
In Pro-ceedings of IJCAI-09.M.
E. Foster, M. Giuliani, and A. Knoll.
2009b.Comparing objective and subjective measuresof usability in a human-robot dialogue system.In Proceedings of ACL-IJCNLP 2009.M.
E. Foster, M. Giuliani, T. Mu?ller, M. Rickert,A.
Knoll, W. Erlhagen, E. Bicho, N. Hipo?lito,and L. Louro.
2008b.
Combining goal inferenceand natural-language dialogue for human-robotjoint action.
In Proceedings of the 1st Interna-tional Workshop on Combinations of IntelligentMethods and Applications at ECAI 2008.M.
Giuliani and A. Knoll.
2008.
MultiML:A general-purpose representation language formultimodal human utterances.
In Proceedingsof ICMI 2008.J.
D. Kelleher and G.-J.
M. Kruijff.
2006.
Incre-mental generation of spatial referring expres-sions in situated dialog.
In Proceedings ofCOLING-ACL 2006.A.
Kranstedt and I. Wachsmuth.
2005.
Incremen-tal generation of multimodal deixis referring toobjects.
In Proceedings of ENLG 2005.S.
Larsson and D. Traum.
2000.
Information stateand dialogue management in the TRINDI dia-logue move engine toolkit.
Natural LanguageEngineering, 6(3&4):323?340.D.
J. Litman and S. Pan.
2002.
Designing andevaluating an adaptive spoken dialogue system.User Modeling and User-Adapted Interaction,12(2?3):111?137.A.
J. N. van Breemen.
2005. iCat: Experimentingwith animabotics.
In Proceedings of AISB 2005Creative Robotics Symposium.I.
F. van der Sluis.
2005.
Multimodal Reference:Studies in Automatic Generation of MultimodalReferring Expressions.
Ph.D. thesis, Universityof Tilburg.M.
Walker, C. Kamm, and D. Litman.
2000.
To-wards developing general models of usabilitywith PARADISE.
Natural Language Engineer-ing, 6(3?4):363?377.M.
A. Walker.
2000.
An application of reinforce-ment learning to dialogue strategy selection ina spoken dialogue system for email.
Journal ofArtificial Intelligence Research, 12:387?416.M.
White.
2006.
Efficient realization of co-ordinate structures in Combinatory CategorialGrammar.
Research on Language and Compu-tation, 4(1):39?75.
