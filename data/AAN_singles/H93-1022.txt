IMPROVED KEYWORD-SPOTTING USING SRI'S DECIPHER TM LARGE-VOCABUARLYSPEECH-RECOGNITION SYSTEMMitchel WeintraubSRI InternationalSpeech Research and Technology ProgramMenlo Park, CA,  94025ABSTRACTThe word-spotting task is analogous to text-based infor-marion retrieval tasks and message-understanding tasks in that anexhaustive accounting of the input is not required: only a usefulsubset of the full information eed be extracted in the task.
Tradi-tional approaches have focussed on the keywords involved.
Wehave shown that accounting for more of the data, by using alarge-vocabulary recognizer for the wordspotting task, can leadto dramatic improvements relative to traditional approaches.This result may well be generalizable tothe analogous text-basedtasks.The approach described makes several novel contribu-tions, including: (1) a method for dramatic improvement in theFOM (figure of merit) for word-spotting results compared tomore traditional approaches; (2) a demonstration f the benefit oflanguage modeling in keyword spotting systems; and (3) amethod that provides rapid porting of to new keyword vocabular-ies.1.
INTRODUCTIONAlthough both continuous peech recognition and key-word-spotting tasks use the very similar underlying technology,there are typically significant differences in the way in which thetechnology is developed and used for the two applications (e.g.acoustic model training, model topology and language modeling,filler models, search, and scoring).
A number of HMM-basedsystems have previously been developed for keyword-spotting\[1-5\].
One of the most significant differences between these key-word-spotting systems and a CSR system is the type of non-key-word model that is used.
It is generally thought that very simplenon-keyword models (such as a single 10-state model \[2\], or theset of monophone models \[1\]) can perform as well as more com-plicated non-keyword models which include words or triphones.We describe how we have applied CSR techniques to thekeyword-spotting task by using a speech recognition system togenerate a transcription of the incoming spontaneous speechwhich is searched for the keywords.
For this task we have usedSR.I's DECIPI-IER TM system, a state-of-the-art large-vocabularyspeaker-independent continuous-speech recognition system \[6-10\].
The method is evaluated on two domains: (1) the Air TravelInformation System (ATIS) domain \[13\], and (2) the "credit cardtopic" subset of the Switchboard Corpus \[11\], a telephone speechcorpus consisting of spontaneous conversation on a number ofdifferent opics.In the ATIS domain, for 78 keywords in a vocabulary of1200, we show that the CSR approach significantly outperformsthe traditional wordspotting approach for all false alarm rates perhour per word: the figure of merit (FOM) for the CSR recognizeris 75.9 compared to only 48.8 for the spotting recognizer.
In theCredit Card task, the sporing of 20 keywords and their 58 vari-ants on a subset of the Switchboard corpus, the system's perfor-mance levels off at a 66% detection rate, limited by the system'sability to increase the false alarm rate.
Additional experimentsshow that varying the vocabulary size from medium- to large-vocabulary recognition systems (700 to 7000) does not affect heFOM performance.A set of experiments compares two topologies: (1) atopology for a fixed vocabulary for the keywords and the N mostcommon words in that task (N varies from Zero to VocabularySize), forcing the recognition hypothesis to choose among theallowable words (traditional CSR), and (2) a second topology inwhich a background word model is added to the word list,thereby allowing the recognition system to transcribe parts of theincoming speech signal as background.
While including thebackground word model does increase the overall ikelihood ofthe recognized transcription, the probability of using the back-ground model is highly likely (due to the language model proba-bilities of out of vocabulary words) and tended to replace anumber of keywords that had poor acoustic matches.Finally, we introduce an algorithm for smoothing lan-guage model probabilities.
This algorithm combines mall task-specific language model training data with large task-indepen-dent language training data, and provided a 14% reduction in testset perplexity.2.
TRA IN ING .2.1.
Acoust ic  Mode l ingDECIPHER TM uses a hierarchy of phonetic context-dependent models, including word-specific, triphone, general-ized-triphone, biphone, generalized-biphone, and context inde-pendent models.
Six spectral features are used to model thespeech signal: the eepstral vector (C1-CN) and its first and sec-ond derivatives, and cepstral energy (CO) and its first and secondderivatives.
These features are computed from an FFT filterbankand subsequent high-pass RASTA filtering of the filterbank log114energies, and are modeled either with VQ and scalar codebooksor with tied-mixture Gaussian models.
The acoustic models usedfor the Switchboard task use no cross word acoustic onstraints.2.2.
Language ModelingThe DECIPI-IER m system uses a probabilistie finite stategrammar (PFSG) to constrain allowable word sequences.
In theATIS, WSL and Credit Card tasks, we use a word-based bigramgrammar, with the language model probabilities timated usingKatz's back-off bigrarn algorithm \[12\].
All words that are not inthe specified vocabulary that are in the language model trainingdata are mapped to the background word model.
The backgroundword model is treated like all the other words in the recognizer,with bigram language model probabilities on the grammar t ansi- Ttions between words.Two topologies are used for the experiments described inthis paper.
One topology is to use a fixed vocabulary with thekeywords and the N most common words in that task (N variesfrom Zero to VocabSize), forcing the reeoguition hypothesis toehoose among the allowable words.
A second topology is to addthe background word model to the above word list, therebyallowing the recoguition system to transcribe parts of the incom-ing speech signal as background.
A sample background wordwith 60 context-independent phones is shown below in Figure 1.Grammar ( ~  GrammarTransition Transition60 Context-Independent PhonesFigure 1: A sample topology for the background word model.The minimum duration is 2 phones and the self loop allows foran infinite duration.2.3.
Task-Specific Language Model EstimationThe Switchboard Corpus \[11\] is a telephone databaseconsisting of spontaneous conversation  a number of differenttopics.
The Credit Card task is to spot 20 keywords and theirvariants where both the keywords and the test set focus on a sub-set of the Switchboard conversations pertaining to credit cards.To estimate the language model for this task, we could (1) use asmall amount of task-specific training data that focuses only onthe credit card topic, (2) use a large amount of task-independenttraining data, or (3) combine the task-specific training with thetask-indepondent training data.For combining a small amount of task-specific (TS)training with a very large amount of task-independent (TI) train-ing data, we modified the Katz back-off bigram estimation algo-rithm \[12\].
A weight was added to reduce the effective size of thetask-independent training database as shown in Equation 1:C(w2, wl) - Crs(w2, wl) +Y*CTt(W2, wl)where C (w2, wl)  is the counts of the nurnher of occurrencesof word wl followed by w2, CTS (w2, wl) are the counts fromthe task-specific database and Crt (w2, wl) are the countsfrom the task-independent da abase.
The weight 3, reduces theeffective size of the task-independent database so that thesecounts don't overwhelm the counts of the task-specific database.Table 1 shows both the training set and test set perplexityfor the credit card task as a function of T. The task-specific train-ing consisted of 18 credit card conversations (59 K words) whilethe task-independent training consisted of 1123 general conver-satious (17 M words).Table 1: Perplexity of Credit Card Task as a Function of TaskIndependent-Specific Smoothing1.00.50.20.10.050.020.010.0050.0020.001Effective Task Training Test SetIndep.
Training SetSize Perplexity Perplexity17,611,159 174.7 380.08,805,579 154.5 358.33,352,223 131.0 332.01,761,116 117.5 321.8880,558 109.7 328.8352,223 102.6 360.4176,111 98.8 396.988,055 96.2 443.435,222 94.5 521.517,611 94.0 592.33.
SEARCHThe DECIPHER a~ system uses a time-synchronousbeam search.
A partial Viterbi baektrace \[6\] is used to locate themost-likely Viterbi path in a continuous running utterance.
TheViterbi backtrace contains both language model information(grammar t ansition probabilities into and out of the keyword),acoustic log likelihood probabilities for the keyword, and theduration of the keyword hypothesis.A duration-normalized likelihood score for each key-word is computed using the following Equation 2:AP + GP + ConstantKeyScore = Durationwhere AP is the acoustic log-likelihood score for the keyword,and GP is the log probability of the grammar transition into thekeyword, and Constant is a constant added to the score to penal-ize keyword hypotheses that have a short duration.
None of theearlier HMM keyword systems used a bigram language in eitherthe decoding or the scoring.
Many previous systems did useweights on the keywords to adjust he operating location on theROC curve.115A hypothesized keyword is scored as correct if its mid-point falls within the endpoints of the correct keyword.
The key-word scores are used to sort the occurrences ofeach keyword forcomputing the probability of detection at different false-alarmlevels.
The overall figure-of-merit is computed as the averagedetection rate over all words and over all false alarm rates up toten false alarms per word per hour.4.
EXPERIMENTS4.1.
ATIS TaskThe ATIS task \[13\] was chosen for keyword-spottingexperiments because (1) the template-based system that inter-prets the queries of the airline database focuses on certain key-words that convey the meaning of the query, and ignores many ofthe other filler words (e.g.
"I would like...", "Can you please ...'),(2) the task uses spontaneous speech, and (3) we have workedextensively on this recognition task over the last two years.Sixty-six keywords and their variants were selected as keywordsbased on the importance of each of the words to the SRI tem-plate-mateher which interprets he queries.SRI applied two different recognition systems to theATIS keyword spotting task.
The first system was SRI's large-vocabulary speaker-independent speech recognition system thatwe have used for the ATIS speech-recognition task \[3\].
Thevocabulary used in this system is about 1200 words, and a back-off bigram language model was trained using the ATIS MAD-COW training data \[13\].
Many of the words in the vocabularyuse word-specific or triphone acoustic models, with biphone andcontext-independent models used for those words that occurinfrequently.The second system is a more traditional word-spottingsystem.
There are 66 keywords plus 12 variants of those key-words for a total of 78 keyword models.
There is a backgroundmodel (see Figure 1) that tries to account for the rest of theobserved acoustics, making a total of 79 words in this secondsystem.
This second system also uses a back-off bigram gram-mar, but all non-keywords are replaced with the backgroundword when computing language model probabilities.The acoustic models for the keywords and their variantswere identical in the two systems.
The only difference betweenthe two systems is that the first system uses ~1100 additionalwords for the background model, while the second system usesone background model with 60 context-independent phones.
Theresulting FOM and ROC curves are show in Figure 2 for the twosystems.Table 2: ATIS Keyword Spotting ResultsNumber ofSystem Description Filler ModelsATIS Recognizer 11001 Spotting RecognizerFOM75.948.8Probability of Detection1 00 ............................ ~ ..... ....................... i .. .......... ATI8 models!
.___.i?--- .
.
.
.
.
.
.080 ... ... i ..............o .4 o-......,,-.:.
::::L-.i ........................... i ...............o.zo ...... i .... i ..............o.oo I I False Alarms/Hr/Wd5.00 10.00Figure 2: Probability of detection as a function of the false alarmrate for the above two CSR systems on the ATIS Task.There are two possible xplanations for the experimentalresults in Figure 2 and Table 2.
The first explanation is that theATIS recognizer has a much larger vocabulary, and this largervocabulary is potentially better able at matching the non-key-word acoustics than the simple background model The secondexplanation is that for the larger vocabulary ATIS system, theback-off bigram grammar can provide more interword con-straints to eliminate false alarms than the back-off bigram gram-mar that maps aU non-keywords to the filler model Additionalexperiments are planned to determine the extent of these ffects.4.2.
Credit Card TaskThe Credit Card task is to spot 20 keywords and their 58variants on a subset of the Switchboard database.
The keywordswere selected to be content words relevant to the credit card topicand based on adequate frequency of occurrence of each keywordfor training and testing.Acoustic models were trained on an 11,290 hand-tran-scribed utterances subset of the Switchboard atabase.
A back-off bigram language model was trained as described in Section2.3, using the text transcriptions from 1123 non-credit-card con-versations and 35 credit card conversations.
The most common5,000 words in the non-credit-card conversations were combinedwith the words in the credit card conversations, the keywords,and their variants to bring the recognition vocabulary size to6914 words (including the background word model).The resulting CSR system was tested on 10 credit-cardconversations from the Switchboard database.
Each conversationconsisted of two stereo recordings (each talker was recorded sep-arately) and was approximately 5 minutes long.
Each of the twochannels is processed independently.
The resulting ROC curve isshown in Figure 3.
The ROC curve levels out at 66% because theCSR system hypothesized 431 keywords out of a total of 498true keyword locations.
Our current CSR approach, which usesthe Viterbi backtracee, does not allow us to increase the keywordfalse alarm rate.116Probability of Detection70.00 .
|  ............................................. ...................................... .........e000  t ........... ....000r/ ................................. i .................................
!
'000r l  ..................................... i .. .. .. .. ........................... i................................... V - - - - i  ...................................................... i ........................................................................................ i ................................. i .........0.00 i : FAIHr/Wd0.00 5.00 10.00Figure 3: Probability of detection as a function fo the false alarmrate for the 6914 word CSR system on the Credit Card Task.The effect of using different scoring formulas is shownin Table 3.
If only the duration-normalized acoustic log-likeli-hoods are used, an average probability of detection (FOM) of54% is achieved.
When the grammar transition log-probabilityinto this keyword is added to the score (Eqn 2), the FOMihereases to 59.9%.
In addition, if a constant is added to thescore before normalization, the FOM increases for both cases.This has the effect of reducing the false-alarm rate for shorter-duration keyword hypotheses.
We have not had a chance toexperiment with the grammar t ansition leaving the keyword, norwith any weighting of grammar scores relative to acousticScoreS.Table 3: Credit Card FOM ScoringAcoustic Likelihood + AcousticGrammar Transition LikelihoodKeyword Score 59.9 54.0Optimized Score 60.5 57.1We then varied the recognition vocabulary size anddetermined its effect on the keyword-spotting performance.These experiments show that varying the vocabulary size frommedium- to large-vocabulary recognition systems (700 to 7000)does not affect he FOM performance.Table 4: Credit Card FOM as a Function of CSR Vocabulary SizeVoeabularySize FOM725 59.31423 59.56914 59.9Finally, we experimented with including or excluding thebackground word model in the CSR lexicon.
While including thebackground word model does increase the overall ikelihood ofthe recognized transcription, the probability of using the back-ground model is highly likely (due to the language model proba-bilities of OOV words) and tended to replace a number ofkeywords that had poor acoustic matches.
Table 5 shows that aslight improvement can be gained by eliminating this back-ground word model.Table 5: FOM With and Without Background Model for LargeVocabulary CSR SystemVocabulary Size FOM6914 59.96913 (No Background) 61.65.
SUMMARYThis paper describes how SRI has applied our speaker-independent large-vocabulary CSR system (DECIPHER TM) tothe keyword-spotting task.
A transcription is generated for theincoming spontaneous speech by using a CSR system, and anykeywords that occur in the transcription are hypothesized.
Weshow that the use of improved models of non-keyword speechwith a CSR system can yield significantly improved keywordspotting performance.The algorithm for computing the score of a keywordcombine information from acoustic, language, and duration.
Onekey limitation of this approach is that keywords are only hypoth-esized if they are included in the Viterbi baektrace.
This does notallow the system builder to operate ffectively at high false alarmlevels if desired.
We are eousidering other algorithms for hypoth-esizing "good score" keywords that are on high scoring paths.We introduced an algorithm for smoothing languagemodel probabilities.
This algorithm combines mall task-specificlanguage model training data with large task-independent lan-guage training data, and provided a 14% reduction in test set per-plexity.The use of a large-vocabulary continuous-speech recog-nition system allows the system designer agreat dealof lexibil-ity in choosing the keywords that hey would like to select for theparticular application.
If the desired keyword is already in thelexicon, then searching for the keyword can be achieved by look-ing for the word in the transcription generated by the recognizer.If the word is not in the lexicon, the word can be easily added tothe system since triphone models have already been trained.The ability to transerihe spontaneous speech and searchfor relevant keywords will play an important role in the futuredevelopment of simple spoken language applications.
Such sys-tems will be easily portable to new domains.
Since the operatingpoint for our speech recognizer is typically one which has a lowinsertion rate, there is little chance for a keyword false alarm.Future experimentation will determine the effectiveness of suchunderstanding systems for human-computer interaction.117REFERENCES1.
R. Rose and D. Paul, "A Hidden Markov Model Based Key-word Recognition System," 1990 IEEE ICASSP, pp.
129-132.2.
J.G.
Wilpon, L.R.
Rabiner, C.H.
Lee, and E.R.
Goldman,"Automatic Recognition of Keywords in UnconstrainedSpeech Using Hidden Markov Models," 1990 IEEE Trans.ASSP, Vo138.
No.
11, pp.
1870-1878.3.
LG.
Wilpon, L.G.
Miller, and P. Modi, "Improvements andApplications for Key Word Recognition Using HiddenMarkov Modeling Techniques," 1991 IEEE ICASSP, pp.309-312.R.
Rohlicek, W. Russell, S. Roukos, H. Gish, "ContinuousHidden Markov Modeling for Speaker-Independent WordSpotting," 1989 IEEE ICASSP, pp.
627-630.L.D.
Wilcox, and M.A.
Bush, "Training and Search Algo-rithms for an Interactive Wordsptting System," 1992 IEEEICASSP, pp.
H-97-lI-100.H.
Murveit, J. Butzberger, and M. Weintraub, "Performanceof SRI's DECIPHER Speech Recognition System on DAR-PA's CSR Task," 1992 DARPA Speech and Natural Lan-guage Workshop Proceedings, pp 410-414Murveit, H., J. Butzberger, and M. Weintraub, "ReducedChannel Dependence for Speech Recognition," 1992DARPA Speech and Natural Language Workshop Proceed-ings, pp.
280-284.8.
Butzberger, J. H. Murveit, E. Shriberg, and P. Price, "Spon-taneous Speech Effects in Large Vocabulary Speech Recog-nition Applications," 1992 DARPA Speech and NaturalLanguage Workshop Proceedings, pp.
339-343.9.
H. Murveit, J. Butzberger, and M. Weintraub, "Speech Rec-ognition in SRI's Resource Management and ATIS Sys-tems," 1991 DARAP Speech and Natural LanguageWorkshop, pp.
94-100.10.
Cohen, M., H. Murveit, J. Bemstein, P. Price, and M. Wein-traub, "The DECIPHER TM Speech Recognition System,"1990 IEEE ICASSP, pp.
77-80.11.
J.J. Godfrey, E.C.
Holliman, and J.MeDaniel, "SWITCH-BOARD: Telephone Speech Corpus for Research and Devel-opment," 1992 IEEE ICASSP, pp.
1-517-I-520.12.
S.M.
Katz, "Estimation of Probabilities from Sparse Data forthe Language Model Component of a Speech Recognizer,"1987 IEEEASSP, Vol.
35, No.
3. pp.400-401.13.
MADCOW, "Multi-Site Data CoUeetion for a Spoken Lan-guage Corpus," 1992 DARPA Speech and Natural LanguageWorkshop Proceedings, pp.
7-14.4.5.6.7.118
