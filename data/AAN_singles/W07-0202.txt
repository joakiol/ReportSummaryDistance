TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 9?16,Rochester, April 2007 c?2007 Association for Computational LinguisticsMulti-level Association Graphs ?A New Graph-Based Model for Information RetrievalHans Friedrich WitschelNLP departmentUniversity of Leipzig04009 Leipzig, P.O.
Box 100920witschel@informatik.uni-leipzig.deAbstractThis paper introduces multi-level associa-tion graphs (MLAGs), a new graph-basedframework for information retrieval (IR).The goal of that framework is twofold:First, it is meant to be a meta model ofIR, i.e.
it subsumes various IR modelsunder one common representation.
Sec-ond, it allows to model different forms ofsearch, such as feedback, associative re-trieval and browsing at the same time.
Itis shown how the new integrated modelgives insights and stimulates new ideas forIR algorithms.
One of these new ideas ispresented and evaluated, yielding promis-ing experimental results.1 IntroductionDeveloping formal models for information retrievalhas a long history.
A model of information retrieval?predicts and explains what a user will find relevantgiven the user query?
(Hiemstra, 2001).
Most IRmodels are firmly grounded in mathematics and thusprovide a formalisation of ideas that facilitates dis-cussion and makes sure that the ideas can be imple-mented.
More specifically, most IR models providea so-called retrieval function f(q, d) , which returns?
for given representations of a document d and of auser information need q ?
a so-called retrieval statusvalue by which documents can be ranked accordingto their presumed relevance w.r.t.
to the query q.In order to understand the commonalities and dif-ferences among IR models, this paper introduces thenotion of meta modeling.
Since the word ?metamodel?
is perhaps not standard terminology in IR,it should be explained what is meant by it: a metamodel is a model or framework that subsumes otherIR models, such that they are derived by specifyingcertain parameters of the meta model.In terms of IR theory, such a framework conveyswhat is common to all IR models by subsumingthem.
At the same time, the differences betweenmodels are highlighted in a conceptually simpleway by the different values of parameters that haveto be set in order to arrive at this subsumption.
Itwill be shown that a graph-based representation ofIR data is very well suited to this problem.IR models concentrate on the matching process,i.e.
on measuring the degree of overlap between aquery q and a document representation d. On theother hand, there are the problems of finding suit-able representations for documents (indexing) andfor users?
information needs (query formulation).Since users are often not able to adequately statetheir information need, some interactive and asso-ciative procedures have been developed by IR re-searchers that help to overcome this problem:?
Associative retrieval, i.e.
retrieving informa-tion which is associated to objects known orsuspected to be relevant to the user ?
e.g.
queryterms or documents that have been retrieved al-ready.?
Feedback, another method for boosting recall,either relies on relevance information givenby the user (relevance feedback) or assumes9top-ranked documents to be relevant (pseudofeedback) and learns better query formulationsfrom this information.?
Browsing, i.e.
exploring a document collec-tion interactively by following links betweenobjects such as documents, terms or concepts.Again, it will be shown that ?
using a graph-basedrepresentation ?
these forms of search can be sub-sumed easily.2 Related work2.1 Meta modelingIn the literal sense of the definition above, there isa rather limited number of meta models for IR, themost important of which will be described here veryshortly.Most research about how to subsume various IRmodels in a common framework has been done inthe context of Bayesian networks and probabilisticinference (Turtle and Croft, 1990).
In this approach,models are subsumed by specifying certain proba-bility distributions.
In (Wong and Yao, 1995), theauthors elaborately show how all major IR modelsknown at that time can be subsumed using proba-bilistic inference.
Language modeling, which wasnot known then was later added to the list by (Met-zler and Croft, 2004).Another graph-based meta modeling approachuses the paradigm of spreading activation (SA) as asimple unifying framework.
Given semantic knowl-edge in the form of a (directed) graph, the idea ofspreading activation is that a measure of relevance?
w.r.t.
a current focus of attention ?
is spread overthe graph?s edges in the form of activation energy,yielding for each vertex in the graph a degree of re-latedness with that focus (cf.
(Anderson and Pirolli,1984)).
It is easy to see how this relates to IR: us-ing a graph that contains vertices for both terms anddocuments and appropriate links between the two,we can interpret a query as a focus of attention andspread that over the network in order to rank docu-ments by their degree of relatedness to that focus.A very general introduction of spreading activa-tion as a meta model is given in the early work by(Preece, 1981) All later models are hence specialcases of Preece?s work, including the multi-level as-sociation graphs introduced in section 3.
Preece?smodel subsumes the Boolean retrieval model, coor-dination level matching and vector space processing.Finally, an interesting meta model is described by(van Rijsbergen, 2004) who uses a Hilbert space asan information space and connects the geometry ofthat space to probability and logics.
In particular,he manages to give the familiar dot product betweenquery and document vector a probabilistic interpre-tation.2.2 Graph-based models for associativeretrieval and browsingThe spreading activation paradigm is also often usedfor associative retrieval.
The idea is to reach verticesin the graph that are not necessarily directly linked toquery nodes, but are reachable from query nodes viaa large number of short paths along highly weightededges.Besides (Preece, 1981), much more work on SAwas done, a good survey of which can be found in(Crestani, 1997).
A renewed interest in SA was latertriggered with the advent of theWWWwhere hyper-links form a directed graph.
In particular, variants ofthe PageRank (Brin and Page, 1998) algorithm thatbias a random searcher towards some starting nodes(e.g.
an initial result set of documents) bear close re-semblance to SA (Richardson and Domingos, 2002;White and Smyth, 2003).Turning to browsing, we can distinguish threetypes of browsing w.r.t.
to the vertices of the graph:index term browsing, which supports the user in for-mulating his query by picking related terms (Doyle,1961; Beaulieu, 1997), document browsing whichserves to expand result sets by allowing access tosimilar documents or by supporting web browsing(Smucker and Allan, 2006; Olston and Chi, 2003)and combined approaches where both index termsand documents are used simultaneously for brows-ing.In this last category, many different possibilitiesarise for designing interfaces.
A common guidingprinciple of many graph-based browsing approahcesis that of interactive spreading activation (Oddy,1977; Croft and Thompson, 1987).
Another ap-proach, which is very closely related to MLAGs,is a multi-level hypertext (MLHT), as proposed in10(Agosti and Crestani, 1993) ?
a data structure con-sisting of three levels, for documents, index termsand concepts.
Each level contains objects and linksamong them.
There are also connections betweenobjects of two adjacent levels.
An MLHT is meantto be used for interactive query formulation, brows-ing and search, although (Agosti and Crestani, 1993)give no precise specification of the processing pro-cedures.2.3 Contribution of this workCompared to Preece?s work, the MLAG frameworkmakes two sorts of modifications in order to reachthe goals formulated in the introduction: in order tosubsume more IR models, the flexibility and powerof Preece?s model is increased by adding real-valuededge weights.
On the other hand, a clearer distinc-tion is made between local and global informationthrough the explicit introduction of ?level graphs?.With the introduction of levels, the MLAG datastructure becomes very closely related to the MLHTparadigm of (Agosti and Crestani, 1993), MLAGs,however, generalise MLHTs by allowing arbitrarytypes of levels, not only the three types proposed in(Agosti and Crestani, 1993).
Additionally, links inMLAGs are weighted and the spreading activationprocessing defined in the next section makes exten-sive use of these weights.All in all, the new model combines the data struc-ture of multi-level hypertexts (Agosti and Crestani,1993) with the processing paradigm of spreading ac-tivation as proposed by Preece (Preece, 1981), re-fining both with an adequate edge weighting.
Theframework is an attempt to be as general as neces-sary for subsuming all models and allowing for dif-ferent forms of search, while at the same time beingas specific as possible about the things that are reallycommon to all IR models.3 The MLAG model3.1 Data structureFormally, the basis of a multi-level associationgraph (MLAG) is a union of n level graphsL1, ..., Ln.
Each of these n directed graphs Li =G(V Li, ELi,WLi) consists of a set of verticesV Li, a set ELi ?
V Li ?
V Li of edges and a func-tion WLi : ELi ?
R returning edge weights.In order to connect the levels, there are n ?1 connecting bipartite graphs (or inverted lists)I1,2, ..., In?1,n where each inverted list Ij,j+1 con-sists of vertices V Ij,j+1 = V Lj ?
V Lj+1, edgesEIj,j+1 ?
(V Lj ?
V Lj+1) ?
(V Lj+1 ?
V Lj) andweights WIj,j+1 : EIj,j+1 ?
R. Figure 1 depictsa simple example multi-level association graph withtwo levels Ld and Lt for documents and terms.                    Term levelDocument levelInverted listt1`t2`t3` t4`t5`t6`t7`t8`t9`aaa((%@EEEd5`d1`d3` d9`d8`d6`d4`d7`d2`aaa@ BBBBBBBBBTTTTTTFigure 1: A simple example MLAGAssuming that the vertices on a given level cor-respond to objects of the same type and verticesin different levels to objects of different types, thisdata structure has the following general interpreta-tion: Each level represents associations between ob-jects of a given type, e.g.
term-term or document-document similarities.
The inverted lists, on theother hand, represent associations between differenttypes of objects, e.g.
occurrences of terms in docu-ments.3.2 Examples3.2.1 Standard retrievalThe simplest version of a multi-level associationgraph consists of just two levels ?
a term levelLt anda document level Ld.
This is the variant depicted infigure 1.The graph Itd that connects Lt and Ld is an in-verted list in the traditional sense of the word, i.e.
aterm is connected to all documents that it occurs inand the weight WI(t, d) of an edge (t, d) connect-ing term t and document d conveys the degree towhich t is representative of d?s content, or to whichd is about t.11The level graphs Lt and Ld can be computed invarious ways.
As for documents, a straight-forwardway would be to calculate document similarities,e.g.
based on the number of terms shared by twodocuments.
However, other forms of edges are pos-sible, such as hyperlinks or citations ?
if available.Term associations, on the other hand, can be com-puted using co-occurrence information.
An alterna-tive would be to use relations from manually createdthesauri or ontologies.3.2.2 More levelsIn order to (partly) take document structure intoaccount, it can be useful to introduce a level for doc-ument parts (e.g.
headlines and/or passages) in be-tween the term and the document level.
This canbe combined with text summarisation methods (cf.e.g.
(Brandow et al, 1995)) in order to give higherweights to more important passages in the invertedlist connecting passages to documents.In distributed or peer-to-peer environments,databases or peers may be modeled in a separatelayer above the document level, inverted lists in-dicating where documents are held.
Additionally,a peer?s neighbours in an overlay network may bemodeled by directed edges in the peer level graph.More extensions are possible and the flexibility ofthe MLAG framework allows for the insertion of ar-bitrary layers.3.3 Processing paradigmThe operating mode of an MLAG is based on thespreading activation principle.
However, the spreadof activation between nodes of two different levelsis not iterated.
Rather, it is carefully controlled, yetallowing non-linear modifications at some points.In order to model spreading activation in anMLAG, we introduce an activation function Ai :V Li ?
R which returns the so-called activation en-ergies of vertices on a given level Li.
The defaultvalue of the activation function is Ai(v) = 0 for allvertices v ?
V Li.In the following, it is assumed that the MLAGprocessing is invoked by activating a set of verticesA on a given levelLi of theMLAG bymodifying theactivation function of that level so that Ai(v) = wvfor each v ?
A.A common example of such activation is a querybeing issued by a user.
The initial activation is theresult of the query formulation process, which se-lects some vertices v ?
A and weights them accord-ing to their presumed importance wv.
This weight isthen the initial activation energy of the vertex.Once we have an initial set of activated vertices,the following general procedure is executed untilsome stopping criterion is met:1.
Collect activation values on current level Li,i.e.
determine Ai(u) for all u ?
V Li.2.
(Optionally) apply a transformation to the acti-vation energies of Li-nodes, i.e.
alter Ai(u) byusing a ?
possibly non-linear ?
transformationfunction or procedure.3.
Spread activation to the next level Li+1 alongthe links connecting the two levels:Ai+1(v) =?
(u,v)?Ii,i+1Ai(u) ?WI(u, v) (1)4.
Set Ai(u) = 0 for all u ?
V Li, i.e.
?forget?about the old activation energies5.
(Optionally) apply a transformation to the acti-vation energies of Li+1-nodes (see step 2).6.
Go to 1, increment i (or decrement, depend-ing on its value and the configuration of theMLAG)If we take a vector space view of this process-ing mode and if we identify level Li with terms andlevel Li+1 with documents, we can interpret the ac-tivation energies Ai(u) as a query vector and theedge weights WI(u, v) of edges arriving at vertexv ?
V Li+1 as a document vector for document v.This shows that the basic retrieval function re-alised by steps 1, 3 and 4 of this process is a simpledot product.
We will later see that retrieval functionsof most IR models can actually be written in thatform, provided that the initial activation of queryterms and the edge weights of Ii,i+1 are chosen cor-rectly (section 4).For some models, however, we additionally needthe possibility to perform nonlinear transformationson result sets in order to subsume them.
Steps 2 and5 of the algorithm allow for arbitrary modifications12of the activation values based on whatever evidencemay be available on the current level or globally ?but not in the inverted list.
This will later also allowto include feedback and associative retrieval tech-niques.4 The MLAG as a meta modelIn this section, examples will be shown that demon-strate how existing IR models of ranked retrieval 1can be subsumed using the simple MLAG of figure1 and the processing paradigm from the last section.This is done by specifying the following parametersof that paradigm:1.
How nodes are activated in the very first step2.
How edges of the inverted list are weighted3.
Which transformation is used in 2 and 5.For each model, the corresponding retrieval func-tion will be given and the parameter specificationwill be discussed shortly.
The specification of theabove parameters will be given in the form of triplets?activationinit, edge weights, transform?.4.1 Vector space modelIn the case of the vector space model (Salton et al,1975), the retrieval function to be mimicked is asfollows:f(q, d) =?t?q?dwtqwtd (2)where wtq and wtd are a term?s weight in the queryq and the current document d, respectively.
Thiscan be achieved by specifying the parameter triplet?wtq, wtd, none?.
This simple representation reflectsthe closeness of the MLAG paradigm to the vectorspace model that has been hinted at above.4.2 Probabilistic modelFor the probabilistic relevance model (Robertsonand Sparck-Jones, 1976), the MLAG has to realisethe following retrieval functionf(q, d) =?idi logpi(1 ?
ri)ri(1 ?
pi)(3)1This excludes the Boolean model, which can, however, alsobe subsumed as shown in section 5.5 of (Preece, 1981)where di ?
{0, 1} indicates whether term i is con-tained in document d, pi is the probability that a rele-vant document will contain term i and ri is the prob-ability that an irrelevant document will contain it.This retrieval function is realised by the parametertriplet ?log pi(1?ri)ri(1?pi) , di, none?.Now there is still the question of how the esti-mates of pi and ri are derived.
This task involves theuse of relevance information which can be gainedvia feedback, described in section 6.1.4.3 Language modelsThe general language modeling retrieval function(cf.
e.g.
(Zhai and Lafferty, 2001)) is ?
admittedly ?not in the linear form of equation 1.
But using log-arithms, products can be turned into sums withoutchanging the ranking ?
the logarithm being a mono-tonic function (note that this is what also happenedin the case of the probabilistic relevance models).In particular, we will use the approach of com-paring query and document language models byKullback-Leibler divergence (KLD) (Lafferty andZhai, 2001) which results in the equationKLD(Mq||Md) =?t?qP (t|Mq) logP (t|Mq)P (t|Md)?
?
?t?qP (t|Mq) logP (t|Md)where P (t|Mq) and P (t|Md) refer to the probabil-ity that term t will be generated by the unigram lan-guage model of query q or document d, respectively.Note that we have simplified the equation by drop-ping a term?t P (t|Mq) logP (t|Mq), which de-pends only on the query, not on the documents tobe ranked.Now, the triplet ?P (t|Mq),?
logP (t|Md), t?can be used to realise this retrieval func-tion where t stands for a procedure that adds?P (t|Mq) logP (t|Md) to the document node?sactivation level for terms t not occurring in d andsorts documents by increasing activation valuesafterwards.5 Combining IR modelsAs can be seen from the last equation above, the lan-guage model retrieval function sums over all termsin the query.
Each term ?
regardless of whether it13appears in the document d or not ?
contributes some-thing that may be interpreted as a ?penalty?
for thedocument.
The magnitude of this penalty dependson the smoothing method used (cf.
(Zhai and Laf-ferty, 2001)).
A popular smoothing method usesso-called Dirichlet priors to estimate document lan-guage models:P (t|Md) =tf + ?p(t|C)?
+ |d|(4)where tf is t?s frequency in d, p(t|C) is the term?srelative frequency in the whole collection and ?
isa free parameter.
This indicates that if a rare termis missing from a document, the penalty will belarge, P (t|Md) being very small because tf = 0and p(t|C) small.Conceptually, it is unproblematic to model theretrieval function by making Itd a complete bipar-tite graph, i.e.
specifying a (non-zero) value forP (t|Md), even if t does not occur in d. In a practicalimplementation, this is not feasible, which is whywe add the contribution of terms not contained ina document, i.e.
?P (t|Mq) logP (t|Md), for termsthat do not occur in d. 2This transformation indicates an important differ-ence between language modeling and all other IRmodels: language models penalise documents forthe absence of rare (i.e.
informative) terms whereasthe other models reward them for the presence ofthese terms.These considerations suggest a combination ofboth approaches: starting with an arbitrary ?pres-ence rewarding?
model ?
e.g.
the vector space model?
we may integrate the ?absence penalising?
philos-ophy by subtracting from a document?s score, foreach missing term, the contribution that one occur-rence of that term would have earned (cf.
(Witschel,2006)).For the vector space model, this yields the follow-ing retrieval function:f(q, d) =?t?q?dwtqwtd?
?|q|?t?q\dwtd(tf = 1)wtq2In order to do this, we only need to know |d| and the relativefrequency of t in the collection p(t|C), i.e.
information that isavailable outside the inverted list.where ?
is a free parameter regulating the relativeinfluence of penalties, comparable to the ?
parame-ter of language models above.5.1 Experimental resultsTable 2 shows retrieval results for combining twoweighting schemes, BM25 (Robertson et al, 1992)and Lnu.ltn (Singhal et al, 1996), with penalties.Both of them belong to the family of tf.idf weight-ing schemes and can hence be regarded as represent-ing the vector space model, although BM25 was de-veloped out of the probabilistic model.Combining them with the idea of ?absence penal-ties?
works as indicated above, i.e.
weights are ac-cumulated for each document using the tf.idf -likeretrieval functions.
Then, from each score, the con-tributions that one occurrence of each missing termwould have earned is subtracted.
More precisely,what is subtracted consists of the usual tf.idf weightfor the missing term, where tf = 1 is substituted inthe tf part of the formula.Experiments were run with queries from TREC-7and TREC-8.
In order to study the effect of querylength, very short queries (using only the title fieldof TREC queries), medium ones (using title and de-scription fields) and long ones (using all fields) wereused.
Table 1 shows an example TREC query.< top>< num> Number: 441< title> Lyme disease< desc> Description:How do you prevent and treat Lyme disease?< narr> Narrative:Documents that discuss current prevention andtreatment techniques for Lyme disease are relevant [...]< /top>Table 1: A sample TREC queryTable 2 shows that both weighting schemes canbe significantly improved by using penalties, espe-cially for short queries, reaching and sometimes sur-passing the performance of retrieval with languagemodels.
This holds even when the parameter ?
isnot tuned and confirms that interesting insights aregained from a common representation of IR modelsin a graph-based environment.
33Note that these figures were obtained without any refine-ments such as query expansion and are hence substantially14TREC-7 TREC-8Weighting very short medium long very short medium longBM25 0.1770 0.2120 0.2141 0.2268 0.2514 0.2332+ P (?
= 1) 0.1867* 0.2194* 0.2178* 0.2380* 0.2593* 0.2335+ P (best ?)
0.1896* 0.2220* 0.2185* 0.2411* 0.2625* 0.2337best ?
value 2 2 1.5 2 2 0.25Lnu.ltn 0.1521 0.1837 0.1920 0.1984 0.2226 0.2013+ P (?
= 1) 0.1714* 0.1972* 0.1946* 0.2176* 0.2305* 0.2040+ P (best ?)
0.1873* 0.2106* 0.1977 0.2394* 0.2396* 0.2064*best ?
value 5 5 3 5 4 1.5LM 0.1856 0.2163 0.2016 0.2505 0.2578 0.2307Table 2: Mean average precision of BM25 and Lnu.ltn and their corresponding penalty schemes (+ P) forTREC-7 and TREC-8.
Asterisks indicate statistically significant deviations (using a paired Wilcoxon teston a 95% confidence level) from each baseline, whereas the best run for each query length is marked withbold font.
Performance of language models (LM) is given for reference, where the value of the smoothingparameter ?
was set to the average document length.6 Different forms of search with MLAGsIn order to complete the goals stated in the intro-duction of this paper, this section will briefly ex-plain how feedback, associative retrieval and brows-ing can be modeled within the MLAG framework.6.1 FeedbackUsing the simple term-document MLAG of figure1, feedback can be implemented by the followingprocedure:1.
Perform steps 1 ?
4 of the basic processing.2.
Apply a transformation to the activation valuesof Ld-nodes, e.g.
let the user pick relevant doc-uments and set their activation to some positiveconstant ?.3.
Perform step 3 of the basic processing withLi = Ld and Li+1 = Lt, i.e.
let activationflow back to term level.4.
Forget about activation levels of documents.5.
Apply transformation on the term level Lt, e.g.apply thresholding to obtain a fixed number ofexpansion terms.6.
Spread activation back to the document level toobtain the final retrieval status values of docu-ments.lower than MAP scores achieved by systems actually partici-pating in TREC.In order to instantiate a particular feedback algo-rithm, there are three parameters to be specified:?
The transformation to be applied in step 2?
The weighting of document-term edges (if dif-ferent from term-document edges) and?
The transformation applied in step 5.Unfortunately, due to space constraints, it is out ofthe scope of this paper to show how different spec-ifications lead to well-known feedback algorithmssuch as Rocchio (Rocchio, 1971) or the probabilisticmodel above.6.2 Associative retrievalAssociative retrieval in MLAGs exploits the infor-mation encoded in level graphs: expanding querieswith related terms can be realised by using the termlevel graph Lt of a simple MLAG (cf.
figure 1) instep 2 of the basic processing, whereas the expan-sion of document result sets takes place in step 5 onthe document level Ld.
In order to exploit the rela-tions encoded in the level graphs, one may again usespreading activation, but also simpler mechanisms.Since relations are used directly, dimensionality re-duction techniques such as LSI cannot and need notbe modeled.6.3 BrowsingSince the MLAG framework is graph-based, it iseasy to grasp and to be visualised, which makes it15a suitable data structure for browsing.
The levelgraphs can be used as a flat graphical representa-tion of the data, which can be exploited directlyfor browsing.
Depending on their information need,users can choose to browse either on the term levelLt or on the document level Ld and they can switchbetween both types of levels at any time using theinverted list Itd.
This applies, of course, also to pas-sage or any other type of levels if they exist.7 ConclusionsIn this paper, a new graph-based framework for in-formation retrieval has been introduced that allowsto subsume a wide range of IR models and algo-rithms.
It has been shown how this common rep-resentation can be an inspiration and lead to newinsights and algorithms that outperform the origi-nal ones.
Future work will aim at finding similarforms of synergies for the different forms of search,e.g.
new combinations of feedback and associativeretrieval algorithms.ReferencesM.
Agosti and F. Crestani.
1993.
A methodology for the au-tomatic construction of a hypertext for information retrieval.In Proceedings of SAC 1993, pages 745?753.J.
R. Anderson and P. L. Pirolli.
1984.
Spread of activa-tion.
Journal of Experimental Psychology: Learning, Mem-ory and Cognition, 10:791?799.M.
Beaulieu.
1997.
Experiments of interfaces to support queryexpansion.
Journal of Documentation, 1(53):8?19.R.
Brandow, K. Mitze, and L. F. Rau.
1995.
Automatic con-densation of electronic publications by sentence selection.Information Processing and Management, 31(5):675?685.S.
Brin and L. Page.
1998.
The anatomy of a large-scale hyper-textual Web search engine.
In Proceedings of WWW7, pages107?117.F.
Crestani.
1997.
Application of spreading activation tech-niques in information retrieval.
Artificial Intelligence Re-view, 11(6):453?482.W.
B. Croft and R. H. Thompson.
1987.
I3R : a new approachto the design of document retrieval systems.
Journal of theamerican society for information science, 38(6):389?404.L.
B. Doyle.
1961.
Semantic Road Maps for LiteratureSearchers.
Journal of the ACM, 8(4):553?578.D.
Hiemstra.
2001.
Using language models for informationretrieval.
Ph.D. thesis, University of Twente.J.
Lafferty and C. Zhai.
2001.
Document language mod-els, query models, and risk minimization for information re-trieval.
In Proceedings of SIGIR 2001, pages 111?119.D.
Metzler and W. B. Croft.
2004.
Combining the languagemodel and inference network approaches to retrieval.
Infor-mation Processing and Management, 40(5):735?750.R.
N. Oddy.
1977.
Information retrieval through man-machinedialogue.
Journal of Documentation, 33(1):1?14.C.
Olston and E. H. Chi.
2003.
ScentTrails: Integratingbrowsing and searching on the Web.
ACM Transactions onComputer-Human Interaction, 10(3):177?197.S.
E. Preece.
1981.
A spreading activation network model forinformation retrieval.
Ph.D. thesis, Universtiy of Illinois atUrbana-Champaign.M.
Richardson and P. Domingos.
2002.
The intelligent surfer:Probabilistic combination of link and content information inpagerank.
In Proceedings of Advances in Neural Informa-tion Processing Systems.S.
E. Robertson and K. Sparck-Jones.
1976.
Relevance Weight-ing of Search Terms.
JASIS, 27(3):129?146.S.
E. Robertson, S. Walker, M. Hancock-Beaulieu, A. Gull, andM.
Lau.
1992.
Okapi at TREC-3.
In Proceedings of TREC,pages 21?30.J.J.
Rocchio.
1971.
Relevance feedback in information re-trieval.
In G. Salton, editor, The SMART Retrieval System: Experiments in Automatic Document Processing.
PrenticeHall Inc., Englewood Cliffs, New Jersey.G.
Salton, A. Wong, and C. S. Yang.
1975.
A vector spacemodel for automatic indexing.
Communications of the ACM,18(11):613?620.A.
Singhal, C. Buckley, and M. Mitra.
1996.
Pivoted documentlength normalization.
In Proceedings of SIGIR 1996, pages21?29.M.
D. Smucker and J. Allan.
2006.
Find-similar: similaritybrowsing as a search tool.
In Proceedings of SIGIR 2006,pages 461?468.H.
Turtle and W. B. Croft.
1990.
Inference networks for docu-ment retrieval.
In Proceedings of SIGIR 1990, pages 1?24.C.
J. van Rijsbergen.
2004.
The Geometry of Information Re-trieval.
Cambridge University Press.Scott White and Padhraic Smyth.
2003.
Algorithms for esti-mating relative importance in networks.
In Proceedings ofKDD 2003, pages 266?275.H.
F. Witschel.
2006.
Carrot and stick: combining informationretrieval models.
In Proceedings of DocEng 2006, page 32.S.
K. M. Wong and Y. Y. Yao.
1995.
On modeling informationretrieval with probabilistic inference.
ACM Transactions onInformation Systems, 13(1):38?68.C.
Zhai and J. Lafferty.
2001.
A study of smoothing methodsfor language models applied to Ad Hoc information retrieval.In Proceedings of SIGIR 2001, pages 334?342.16
