Proceedings of the COLING/ACL 2006 Interactive Presentation Sessions, pages 21?24,Sydney, July 2006. c?2006 Association for Computational LinguisticsMIMA Search: A Structuring Knowledge Systemtowards Innovation for Engineering EducationHideki MimaSchool of EngineeringUniversity of TokyoHongo 7-3-1, Bunkyo-ku, Tokyo 113-0033, Japanmima@t-adm.t.u-tokyo.ac.jpAbstractThe main aim of the MIMA (Mining In-formation for Management and Acquisi-tion) Search System is to achieve ?struc-turing knowledge?
to accelerate knowl-edge exploitation in the domains of sci-ence and technology.
This system inte-grates natural language processing includ-ing ontology development, informationretrieval, visualization, and database tech-nology.
The ?structuring knowledge?
thatwe define indicates 1) knowledge storage,2) (hierarchical) classification of knowl-edge, 3) analysis of knowledge, 4) visu-alization of knowledge.
We aim at inte-grating different types of databases (pa-pers and patents, technologies and innova-tions) and knowledge domains, and simul-taneously retrieving different types ofknowledge.
Applications for the severaltargets such as syllabus structuring willalso be mentioned.1 IntroductionThe growing number of electronically availableknowledge sources (KSs) emphasizes the impor-tance of developing flexible and efficient tools forautomatic knowledge acquisition and structuringin terms of knowledge integration.
Different textand literature mining techniques have been de-veloped recently in order to facilitate efficientdiscovery of knowledge contained in large textualcollections.
The main goal of literature mining isto retrieve knowledge that is ?buried?
in a textand to present the distilled knowledge to users ina concise form.
Its advantage, compared to ?man-ual?
knowledge discovery, is based on the as-sumption that automatic methods are able toprocess an enormous amount of text.
It is doubt-ful that any researcher could process such a hugeamount of information, especially if the knowl-edge spans across domains.
For these reasons,literature mining aims at helping scientists in col-lecting, maintaining, interpreting and curatinginformation.In this paper, we introduce a knowledge struc-turing system (KSS) we designed, in which ter-minology-driven knowledge acquisition (KA),knowledge retrieval (KR) and knowledge visuali-zation (KV) are combined using automatic termrecognition, automatic term clustering and termi-nology-based similarity calculation is explained.The system incorporates our proposed automaticterm recognition / clustering and a visualizationof retrieved knowledge based on the terminology,which allow users to access KSs visually thoughsophisticated GUIs.2 Overview of the systemThe main purpose of the knowledge structuringsystem is 1) accumulating knowledge in order todevelop huge knowledge bases, 2) exploiting theaccumulated knowledge efficiently.
Our approachto structuring knowledge is based on:?
automatic term recognition (ATR)?
automatic term clustering (ATC) as an ontol-ogy1 development?
ontology-based similarity calculation?
visualization of relationships among docu-ments (KSs)One of our definitions to structuring knowledge isdiscovery of relevance between documents (KSs)and its visualization.
In order to achieve real timeprocessing for structuring knowledge, we adoptterminology / ontology-based similarity calcula-tion, because knowledge  can also be representedas textual documents or passages (e.g.
sentences,subsections) which are efficiently characterizedby sets of specialized (technical) terms.
Furtherdetails of our visualization scheme will be men-tioned in Section 4.1  Although, definition of ontology is domain-specific, our definition of ontology is the collectionand classification of (technical) terms to recognizetheir semantic relevance.21The system architecture is modular, and it inte-grates the following components (Figure 1):- Ontology Development Engine(s) (ODE) ?components that carry out the automatic ontol-ogy development which includes recognitionand structuring of domain terminology;- Knowledge Data Manager (KDM) ?
stores in-dex of KSs and ontology in a ontology informa-tion database (OID) and provides the corre-sponding interface;- Knowledge Retriever (KR) ?
retrieves KSs fromTID and calculates similarities between key-words and KSs.
Currently, we adopt tf*idfbased similarity calculation;- Similarity Calculation Engine(s) (SCE) ?
calcu-late similarities between KSs provided from KRcomponent using ontology developed by ODEin order to show semantic similarities betweeneach KSs.
We adopt Vector Space Model(VSM) based similarity calculation and useterms as features of VSM.
Semantic clusters ofKSs are also provided.- Graph Visualizer ?
visualizes knowledge struc-tures based on graph expression in which rele-vance links between provided keywords andKSs, and relevance links between the KSsthemselves can be shown.3 Terminological processing as an ontol-ogy developmentThe lack of clear naming standards in a domain(e.g.
biomedicine) makes ATR a non-trivial prob-lem (Fukuda et al, 1998).
Also, it typically givesrise to many-to-many relationships between termsand concepts.
In practice, two problems stemfrom this fact: 1) there are terms that have multi-ple meanings (term ambiguity), and, conversely,2) there are terms that refer to the same concept(term variation).
Generally, term ambiguity hasnegative effects on IE precision, while term varia-tion decreases IE recall.
These problems show thedifficulty of using simple keyword-based IEtechniques.
Obviously, more sophisticated tech-niques, identifying groups of differentterms referring to the same (or similar)concept(s), and, therefore, could benefitfrom relying on efficient and consistentATR/ATC and term variation manage-ment methods are required.
These meth-ods are also important for organising do-main specific knowledge, as terms shouldnot be treated isolated from other terms.They should rather be related to one an-other so that the relations existing betweenthe corresponding concepts are at leastpartly reflected in a terminology.3.1 Term recognitionThe ATR method used in the system is based onthe C / NC-value methods (Mima et al, 2001;Mima and Ananiadou, 2001).
The C-valuemethod recognizes terms by combining linguisticknowledge and statistical analysis.
The methodextracts multi-word terms2 and is not limited to aspecific class of concepts.
It is implemented as atwo-step procedure.
In the first step, term candi-dates are extracted by using a set of linguistic fil-ters which describe general term formation pat-terns.
In the second step, the term candidates areassigned termhood scores (referred to as C-values) according to a statistical measure.
Themeasure amalgamates four numerical corpus-based characteristics of a candidate term, namelythe frequency of occurrence, the frequency ofoccurrence as a substring of other candidate terms,the number of candidate terms containing thegiven candidate term as a substring, and the num-ber of words contained in the candidate term.The NC-value method further improves the C-value results by taking into account the context ofcandidate terms.
The relevant context words areextracted and assigned weights based on how fre-quently they appear with top-ranked term candi-dates extracted by the C-value method.
Subse-quently, context factors are assigned to candidateterms according to their co-occurrence with top-ranked context words.
Finally, new termhood es-timations, referred to as NC-values, are calculatedas a linear combination of the C-values and con-text factors for the respective terms.
Evaluation ofthe C/NC-methods (Mima and Ananiadou, 2001)has shown that contextual information improvesterm distribution in the extracted list by placingreal terms closer to the top of the list.2 More than 85% of domain-specific terms are multi-wordterms (Mima and Ananiadou, 2001).Figure 1: The system architectureBrowserGUIKSsPDF, Word, HTML,XML, CSVData ReaderDocumentViewerOntology DataManagerKnowledgeRetrieverSimilarityManager????????
?SimilarityCalculationEngineSimilarityGraphVisualizerOntologyDevelopmentEngineSummarizerBrowserInterfaceKnowledge DataManagerOntology InformationDatabase DatabaseSimilarity Processing Ontology Development223.2 Term variation managementTerm variation and ambiguity are causing prob-lems not only for ATR but for human experts aswell.
Several methods for term variation man-agement have been developed.
For example, theBLAST system Krauthammer et al, 2000) usedapproximate text string matching techniques anddictionaries to recognize spelling variations ingene and protein names.
FASTR (Jacquemin,2001) handles morphological and syntactic varia-tions by means of meta-rules used to describeterm normalization, while semantic variants arehandled via WordNet.The basic C-value method has been enhancedby term variation management (Mima andAnaniadou, 2001).
We consider a variety ofsources from which term variation problemsoriginate.
In particular, we deal with orthographi-cal, morphological, syntactic, lexico-semantic andpragmatic phenomena.
Our approach to termvariation management is based on term normali-zation as an integral part of the ATR process.Term variants  (i.e.
synonymous terms) are dealtwith in the initial phase of ATR when term can-didates are singled out, as opposed to other ap-proaches (e.g.
FASTR handles variants subse-quently by applying transformation rules to ex-tracted terms).
Each term variant is normalized(see table 1 as an example) and term variants hav-ing the same normalized form are then groupedinto classes in order to link each term candidate toall of its variants.
This way, a list of normalizedterm candidate classes, rather than a list of singleterms is statistically processed.
The termhood isthen calculated for a whole class of term variants,not for each term variant separately.Table 1: Automatic term normalizationTerm variants  Normalised termhuman cancerscancer in humanshuman?s cancerhuman carcinoma}?
human cancer3.3 Term clusteringBeside term recognition, term clustering is anindispensable component of the literature miningprocess.
Since terminological opacity andpolysemy are very common in molecular biologyand biomedicine, term clustering is essential forthe semantic integration of terms, the constructionof domain ontologies and semantic tagging.ATC in our system is performed using a hierar-chical clustering method in which clusters aremerged based on average mutual informationmeasuring how strongly terms are related to oneanother (Ushioda, 1996).
Terms automaticallyrecognized by the NC-value method and their co-occurrences are used as input, and a dendrogramof terms is produced as output.
Parallel symmet-ric processing is used for high-speed clustering.The calculated term cluster information is en-coded and used for calculating semantic similari-ties in SCE component.
More precisely, the simi-larity between two individual terms is determinedaccording to their position in a dendrogram.
Alsoa commonality measure is defined as the numberof shared ancestors between two terms in thedendrogram, and a positional measure as a sum oftheir distances from the root.
Similarity betweentwo terms corresponds to a ratio between com-monality and positional measure.Further details of the methods and their evalua-tions can be referred in (Mima et al, 2001; Mimaand Ananiadou, 2001).4 Structuring knowledgeStructuring knowledge can be regarded as abroader approach to IE/KA.
IE and KA in oursystem are implemented through the integrationof ATR, ATC, and ontology-based semantic simi-larity calculation.
Graph-based visualization forglobally structuring knowledge is also providedto facilitate KR and KA from documents.
Addi-tionally, the system supports combining differentdatabases (papers and patents, technologies andinnovations) and retrieves different types ofknowledge simultaneously and crossly.
This fea-ture can accelerate knowledge discovery by com-bining existing knowledge.
For example, discov-ering new knowledge on industrial innovation bystructuring knowledge of trendy scientific paperdatabase and past industrial innovation report da-tabase can be expected.
Figure 3 shows an exam-ple of visualization of knowledge structures in theP O S  ta g g e rA c r o n y m r e c o g n i t io nC - v a lu e  A T RO r th o g r a p h i c  v a r ia n t sM o r p h o l o g i c a l  v a r i a n t sS y n ta c t i c  v a r ia n t sN C - v a lu e  A T RT e r m  c lu s t e r in gX M L  d o c u m e n t s  in c l u d in gt e r m  t a g s  a n d  t e r mv a r ia t io n / c l a s s  in fo r m a t io nIn p u t  d o c u m e n t sR e c o g n i t io no f  t e r m sS t r u c t u r i n go f  t e r m sFigure 2: Ontology development23domain of engineering.
In order to structureknowledge, the system draws a graph in whichnodes indicate relevant KSs to keywords givenand each links between KSs indicates semanticsimilarities dynamically calculated using ontol-ogy information developed by our ATR / ATCcomponents.Figure 3: Visualization5 ConclusionIn this paper, we presented a system for structur-ing knowledge over large KSs.
The system is aterminology-based integrated KA system, inwhich we have integrated ATR, ATC, IR, simi-larity calculation, and visualization for structuringknowledge.
It allows users to search and combineinformation from various sources.
KA within thesystem is terminology-driven, with terminologyinformation provided automatically.
Similaritybased knowledge retrieval is implementedthrough various semantic similarity calculations,which, in combination with hierarchical, ontol-ogy- based matching, offers powerful means forKA through visualization-based literature mining.We have applied the system to syllabus re-trieval for The University of Tokyo`s OpenCourse Ware (UT-OCW)3 site and syllabus struc-turing (SS) site4 for school / department of engi-neering at University of Tokyo, and they are bothavailable in public over the Internet.
The UT-OCW?s MIMA Search system is designed tosearch the syllabuses of courses posted on theUT-OCW site and the Massachusetts Institute ofTechnology's OCW site (MIT-OCW).
Also, theSS site?s MIMA Search is designed to search thesyllabuses of lectures from more than 1,600 lec-tures in school / department of engineering atUniversity of Tokyo.
Both systems show searchresults in terms of relations among the syllabusesas a structural graphic (figure 3).
Based on theautomatically extracted terms from the syllabusesand similarities calculated using those terms,MIMA Search displays the search results in anetwork format, using dots and lines.
Namely,3 http://ocw.u-tokyo.ac.jp/.4 http://ciee.t.u-tokyo.ac.jp/.MIMA Search extracts the contents from thelisted syllabuses, rearrange these syllabuses ac-cording to semantic relations of the contents anddisplay the results graphically, whereas conven-tional search engines simply list the syllabusesthat are related to the keywords.
Thanks to thisprocess, we believe users are able to search forkey information and obtain results in minimaltime.
In graphic displays, as already mentioned,the searched syllabuses are shown in a structuralgraphic with dots and lines.
The stronger the se-mantic relations of the syllabuses, the closer theyare placed on the graphic.
This structure will helpusers find a group of courses / lectures that areclosely related in contents, or take courses / lec-tures in a logical order, for example, beginningwith fundamental mathematics and going on toapplied mathematics.
Furthermore, because of thestructural graphic display, users will be able toinstinctively find the relations among syllabusesof other universities.Currently, we obtain more than 2,000 hits perday in average from all over the world, and haveprovided more then 50,000 page views during lastthree months.
On the other hand, we are in aprocess of system evaluation using more than 40students to evaluate usability as a next generationinformation retrieval.The other experiments we conducted also showthat the system?s knowledge structuring schemeis an efficient methodology to facilitate KA andnew knowledge discovery in the field of genomeand nano-technology (Mima et al, 2001).ReferencesK.
Fukuda, T. Tsunoda, A. Tamura, T. Takagi, 1998.Toward information extraction: identifying proteinnames from biological papers, Proc.
of PSB-98,Hawaii, pp.
3:705-716.H.
Mima, S. Ananiadou, G. Nenadic, 2001.
ATRACTworkbench: an automatic term recognition and clus-tering of terms, in: V. Matou?ek, P. Mautner, R.Mou?ek, K. Tau?er (Eds.)
Text, Speech and Dia-logue, LNAI 2166, Springer Verlag, pp.
126-133.H.
Mima, S. Ananiadou, 2001.
An application andevaluation of the C/NC-value approach for theautomatic term recognition of multi-word units inJapanese, Int.
J. on Terminology 6/2, pp.
175-194.M.
Krauthammer, A. Rzhetsky, P. Morozov, C.Friedman, 2000.
Using BLAST for identifying geneand protein names in journal articles, in: Gene 259,pp.
245-252.C.
Jacquemin, 2001.
Spotting and discovering termsthrough NLP, MIT Press, Cambridge MA, p. 378.A.
Ushioda, 1996.
Hierarchical clustering of words,Proc.
of COLING ?96, Copenhagen, Denmark, pp.1159-1162.24
