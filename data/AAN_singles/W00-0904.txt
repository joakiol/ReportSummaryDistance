Comparison between Tagged Corpora for the Named EntityTaskChi~sh i  NOBATA N ige l  COLL IER  and Jun ' i ch i  TSUJ I IKansa i  Advanced Research Center  Depar tment  of  In format ion  ScienceCommunicat ions  Research Laboratory  Graduate  School of  Science588-2 Iwaoka, Iwaoka-cho, Nishi-ku University of  Tokyo, Hongo 7-3-1Kobe,  Hyogo, 65\].-2492 JAPAN Bunkyo-ku,  Tokyo,  113-0033 JAPANnova@crl, go.
j p {nigel, tsuj ii}@is, s. u-tokyo, ac.
jpAbst rac tWe present two measures for compar-ing corpora based on infbrmation the-ory statistics uch as gain ratio as wellas simple term-class ~equency counts.We tested the predictions made by thesemeasures about corpus difficulty in twodomains - -  news and molecular biol-ogy - -  using the result of two well-usedparadigms for NE, decision trees andHMMs and found that gain ratio was themore reliable predictor.made by these measures against actual systemperformance.Recently IE systems based on supervised learn-ing paradigms uch as hidden Markov models(Bikel et al, 1997), maximum entropy (Borth-wick et al, 1998) and decision trees (Sekine etal., 1998) have emerged that should be easier toadapt to new domains than the dictionary-basedsystems of the past.
Much of this work has takenadvantage of smoothing techniques to overcomeproblems associated with data sparseness (Chenand Goodman, 1996).The two corpora we use in our NE experimentsrepresent the following domains:1 In t roduct ionWith the advent of the information society andincreasing availability of large mounts  of infor-mation in electronic form, new technologies suchas information extraction are emerging to meetuser's information access needs.
Recent evalu-ation conferences such as TREC (Voorhees andHarman, 2000) showed the feasibility of this taskand highlighted the need to combine informationret r ied  (m) and extraction (IE) to go beyondsimply offering the user a long ranked list of in-teresting documents to providing facts for user'squestions.The problem of domain dependence r mains aserious one and in fact there has been very littlework so far to compare the difllculty of IE tasks fordifferent domaln~ and their corpora.
Such knowl-edge is useful for developing IE systems that areportable between domains.
This paper begins toaddress this issue, in particular the lowest level ofIE task, defined in the TIPSTER sponsored MUC-6 conference (MUC, 1995) as named entity (NE).This is emerging as a key technology in severalother IF-related tasks such as question answer-ing.
We seek here to show theoretically motivatedmeasures for comparing the ditficulty of corporafor the NE task in two domains, newswire andmolecular-biology.
We then test the predictions?
Newswire: acquisition of names of people, or-ganizations and monetary units etc., from theMUC-6 data set.?
Molecular-biology: acquisition of proteins,DNAs, RNAs etc.
from a subset of the MED-LINE database (MEDLINE, 1999).Information extraction in the molecular-biologydomain (Seldmlzu et al, 1998) (Craven and Kum-lien, 1999) (Rindflesch et al, 2000) has recentlybecome a topic of interest o the NLP community.This is a result of the need to formalise the hugenumber of research results that appear in free-textform in online collections of journal abstracts andpapers such as MEDLINE for databases such asSwissprot (Ban:och and Apwefler, 1997) and alsoto search such collections for facts in an intelligentway.The purpose of our study is not to show a highlevel of absolute system performance.
In fact sincewe use only the MUC-6 executive succession dataset of 60 articles and a new MEDLINE data setof 100 articles we cannot hope to achieve perfor-mance limits.
What we aim to do is to comparemodel performance against he predictions of cor-pus difficulty made by two different methods.
Inthe rest of this paper we firstly introduce the NEmodels used for evaluation, the two corpora we20examined and then the difficulty comparison met-rics.
Predictive scores from the metrics are ex-amined against he actual performance of the NEmodels.2 Mode lsRecent studies into the use of supervised learning-based modeels for the NE task in the molecular-biology domain have shown that models based onhidden Markov models (HMMs) (Collier et al,2000) and decision trees (Nobata et al, 1999) arenot only adaptable to this highly technical do-main, but are also much more generalizable to newclasses of words than systems based on traditionalhand-built heuristic rules such as (Fukuda et al,1998).
We now describe two models used in ourexperiments based on the decision trees packageC4.5 (Quiuian, 1993) and HMMs (Rabiner andJuang, 1986).2.1 Decision tree named entityrecogniser:NE-DTA decision tree is a type of classifier whichhas "leaf nodes" indicating classes and "decisionnodes" that specify some test to be carried out,with one branch or subtree for each possible out-come of the test.
A decision tree can be usedto classify an object by starting at the root ofthe tree and moving through it until a leaf is en-countered.
When we can define suitable featuresfor the decision tree, the system can achieve goodperformance with only a small amount of trainingdata.The system we used is based on one that wasoriginally created for Japanese documents (Seineet al, 1998).
It has two phases, one for creatingthe decision tree from training data and the otherfor generating the class-tagged text based on thedecision tree.
When generating decision trees, tri-grams of words were used.
For this system, wordsare considered to be quadruple features.
The fol-lowing features are used to generate conditions inthe decision tree:Par t -o f -speech in format ion:  There are 45part-of-speech categories, whose definitionsare based on Pennsylvania Treebank's cat-egories.
We use a tagger based on AdwaitRatnaparkhi's method (Ratnaparkhi, 1996).Character type in format ion:  Orthographicinformation is considered such as upper case,lower case, capitalization, numerical expres-sions, symbols.
These character featuresare the same as those used by NEHMMdescribed in the next section and shown inTable 1.Word  l ists specif ic to  the  domain :  Wordlists are made from the training corpus.Only the 200 highest fxequency words areused.2.2 H idden Markov  mode l  named ent i tyreco~.
i ser :  NEHMMHMMs are a widely u~d class of learning algo-rithms and can be considered to be stochastic fi-nite state machines.
In the following model, sum-marized here from the full description given in(Collier et al, 2000), we consider words to be or-dered pairs consisting of a surface word, W, anda word feature, F ,  given as < W, F >.
The wordfeatures themselves are discussed below.
As iscommon practice, we need to calculate the prob-abilities for a word sequence for the first word'sname class and every other word differently sincewe have no initial name-class to make a transitionfrom.
Accordingly we use the following equationto calculate the initial name class probability,Pr(NC~\[ < Wf~,t , Flli,,~ >)=aof(NC$,,s,\[ < Wf,,,,,Ffi,,t >)+o~f(gcs~,,,I < -,Ff~,,, >) +a~f(NCfi,.,,) (i)and for all other words and their name classesas follows:Fr(NCT~ I < Wt,Ft >,< W~-,,Ft-, >,NC~-i) =Aof(NGtl < W~,F~ >,< Wt-,,Ft-1 >,NG~-,) +Alf(NCtI < .,F~ >,< W~-I,F~-i >,NC~- i )+A2f(NC~I < W,,F~ >, < .. F,-, >,NCt-x) +AsI(NG, I < .,Ft >,< _, F~-, >,NG,- ,)+A4f(NC, INC,-,) +Asf(NC,) (2)where f(I) is calculated with maximum-likelihood estimates from counts on training data.In our current system we set the constants Aiand al by hand and let ~ ai = 1.0, ~ Ai = 1.0,ao _> al  > ~,  ~o >_ A , .
.
.
>_ As.
The cur-rent name-class NCt is conditioned on the cur-rent word and feature, the previous name-class,NCt-1, and previous word and feature.Equations 1 and 2 implement a linear-interpolating HMM that incorporates a number ofsub-models designed to reduce the effects of datasparseness.Table 1: Word features v~ith examplesWord Feature ExampleTwoDig i tN~ 25FourDigitNumber 2000DigitNumber 15012SingleCap MGreekLetter alphaCapsAndDigits 12TwoCaps RalGDSLettersAnd.Digits p52In i tCap InterleukinLowCaps kappaBLowercase kinasesHyphonBackslash /Feature Ex.CloseSquare \]ColonSemiColon ;Percent %OpenParen (CloseParen )CommaFullStop .Determiner theConjunction andOther *+~Once the state transition probabilities havebeen calculated according to Equations 1 and 2,the Viterbi algorithm (Viterbi, 1967) is used tosearch the state space of possible name class as-signments in linear time to find the highest prob-ability path, i.e.
to maximise Pr(W, NC).
The fi-nal stage of our algorithm that is used after narae-class tagging is complete is to use a clean-up mod-ule called Unity.
This creates a frequency listof words and name-classes and then re-tags thetext using the most frequently used name classassigned by the HMM.
We have generally foundthat this improves F-score performance by be-tween 2 and 4%, both for re-tagging spuriouslytagged words and for finding untagged words inunknown contexts that had been correctly taggedelsewhere in the text.Table 1 shows the char~ter  features that weused in both NEHMM and NE-DT.
Our intuitionis that such features will help the model to findsimilarities between known words that were foundin the training set and unknown words and soovercome the unknown word problem.3 CorporaWe used two corpora in our experiments repre-senting two popular domains in IE, molecular-biology (from MEDLINE) and newswire texts(from MUC-6).
These are now described.3.1 MUC-6The corpus for MUC-6 (MUC, 1995) contains 60articles, from the test corpus for the dry and for-malruns.
An example canbe seenin Figure 1.
Wecan see several interesting features of the domainsuch as the focus of NF.,s on people and organiza-tion profiles.
Moreover we see that there are manypre-name clue words such as "Ms." or "Rep." indi-cating that a Republican politician's name shouldfollow.3.2 BiologyIn our tests in the domain of molecular-biologywe are using abstracts available from PubMed'sMEDLIhrE.
The MEDLINE database is an onlinecollection of abstracts for published journal arti-cles in biology and medicine and contains morethan nine million articles.
Currently we have ex-tracted a subset of MEDLINE based on a searchusing the keywords human AND blood cell ANDtranscription .factor yielding about 3650 abstracts.Of these 100 docmnents were NE tagged for ourexperiments using a human domain expert.
Anexample of the annotated abstracts is shown inFigure 2.
In contrast o MUC-6 each article isquite short and there are few pre-class clue wordsmaking the task much more like terminology iden-tification and classification than pure name find-ing.4 A f i r s t  a t tempt  a t  corpuscompar i son  based  on  s impletoken  f requencyA simple and intuitive approach to NE task dif-ficulty comparison used in some previous tudiessuch as (palmer and Day, 1997) who studied cor-pora in six different languages, compares class toterm-token ratios on the assumption that rarerclasses are more difficult to acquire.
The relativefrequency counts from these ratios also give an in-direct measure of the granularity of a class, i.e.how wide it is.
While this is appealing, we showthat this approach does not necessarily give thebest metric for comparison.Tables 2 and 3 show the ratio of the number ofdifferent words used in NEs to the total numberof words in the NE  class vocabulary.
The num-ber of different tokens is influenced by the corpussize and is not a suitable index that can uniformlyshow the difficulty for different NE tasks, there-fore it should be normalized.
Here we use wordsas tokens.
A value close to zero indicates littlevariation within the class and should imply thatthe class is easier to acquire.
We see that the NEsin the biology domain seem overall to be easierto acquire than those in the MUC-6 domain givenhxical variation.The figures in the second columns of Tables 2and 3 are normalized so that all numerals are re-placed by a single token.
It still seems thoughthat MUC-6 is a considerably more eheJlengingdomain than biology.
This is despite the fact thatthe ratios for ENAMEX expressions such as Date,22A graduate of <ENAMEX TYPE=" ORGANIZATION" >Harvard Law SChooI</ENAMEX>, Ms.<ENAMEX TYPE="PERSON'>Washington</ENAMEX> worked as a laywer for the corporate fi-nance division of the <ENAMEX TYPE='ORGANIZATION~>SEC</ENAMEX> in the late <TIMEXTYPE='DATE">1970s</TIMEX>.
She has been a congressional staffer since <TIMEX TYPE="DATE'>1979</TIMEX>.
Separately, <ENAMEX TYPE='PERSON'>Clintou</ENAMEX> transi-tion officials said that <ENAMEX TYPE='PERSON">Frank Newman</ENAMEX>, 50, vice chairmanand chief financial officer of <ENAMEX TYPE=" ORGANIZATION" >BankAmerica Corp.</ENAMEX>,is expected to be nominated as assistant <ENAMEX TYPE="ORGANIZATION~>Treasury</ENAMEX>secretary for domestic finance.Figure 1: Example sentences taken from the annotated MUC-6 NE text<PROTEIN>SOX-4</PROTEIN>, an <PROTEIN>Sty-like HMG box protein</PROTEIN>, isa transcriptional activator in <SOLrRCE.cell-type>lymphocytes</SOUl:tCE>.
Previous studies in<SOURCE.cell-type>lymphocytes</SOUB.CE> have described two DNA-binding <PROTEIN>HMGbax proteins</PROTEIN>, <PROTEIN>TCF-I</PROTEIN> and <PROTEIN>LEF-I</PROTEIN>,with affinity for the <DNA>A/TA/TCAAAG motif</DNA> found in several <SOURCE.cell-type>Tcell</SOUl~CE>-specific enhancers.
Evaluation of cotransfection experiments in <SOURCE.cell-type>non-T cells</SOURCE> and the observed inactivity of an <DNA>AACAAAG concatamer</DNA> in the<PROTEIN>TCF-1 </PROTEIN> / <PROTEIN>LEF-1 </PROTEIN>-expressing <SOURCE.cell-line>Tcell line BW5147</SOURCE>, led us to conclude that these two proteins did not mediate the observedenhancer effect.Figure 2: Example sentences taken from the annotated biology textTable 2: Frequency values for words in the MUC-6test corpusClassOrg.PersonLoc.DateTimeMoneyPercentAl lOriginal0.28(=507 / 1783)0.45(=381 / 838)0.38(=148 / 390)0.23(=123 / 542)1.00(= 3 / 3)0.33(=138 / 423)0.39(= 42 / 108)0.33(=1342/4087)Table 3: Frequency values for words in the biologycorpusNorm.
numerals Class Original0.28(=507 / 1783) DNA 0.21(=245 / 1140)0.45(=381 / 838) Protein 0.15(=631 / 4125)0.38(=148 / 390) RNA 0.43(= 30 / 70)0.11(= 60 / 542) Source 0.16(=248 / 1533)1.00(= 3 / 3) All 0.17(=1'154/6868)0.05(= 20 / 423)0.03(= 3 / 108)0.27(=1122/4087)Money and Percent all fall significantly.
Expres-sions in the Time class are so rare however that itis di~cult o make any sort of meaningftfl compar-ison.
In the biology corpus, the ratios are not sig-nificantly changed and the NE classes defined forbiology documents eem to have the same chuj--acteristics as non-numeric ENAMEX classes inMUCC-6 documents.Comparing between the biology documents andthe MUC-6 documents, we may say that identify-ing entities in biology docmnents is easier thanidentifying ENAMEX entities in MUC-6 docu-ments.5 Exper imentsWe evaluated the performance ofour two systemsusing a cross validation method.
For the MUC-6 corpus, 6-fold cross validation was performedon the 60 texts and 5-fold cross validation wasperformed for the 100 texts in the biology corpus.Norm.
numerals0.20(=228 / 1140)0.13(=540 / 4125)0.43(= 30 / 70)0.16(=242 / 1833).0.15(=I040/6868)We use "F-scores ~for evaluation of our experi-ments (Van Rijsbergen, 1979).
"F-score" is a mea-surement combining "Recall" and "Predsion" anddefined in Equation 3.
"Recall" is the percent-age of answers proposed by the system that corre-spond to those in the human-made key set.
"Pre-cision" is the percentage of correct answers amongthe answers proposed by the system.
The F-scorespresented here are automatically calculated usinga scoring program (Chinchor, 1995).2 x Precision x RecallF-score = Precision + Recall (3)In Table 4 we show the actual performanceof our term recognition systems, NE-DT andNEHMM.
We can see that corpus comparisonsbased only on class-token ratios are inadequate oexplain why both systems' performance was aboutthe same in both domains or why NEHMM didbetter in both test corpora than NE-DT.
The dif-ference in performance is despite there being moretraining examples in biology (3301 NEs) than inMUC-6 (2182 NEs).
Part of the reason for this is97Table 4: Performance of the NE systemsNEHMM with Unity 7&4 75.0NEHMM w/o Unity 74.2: 73.1NE-DT 68:~-" 69.4that the class-token ratios ignore individual sys-tem knowledge, i.e.
the types of features thatcan be captured and useful in the corpus domain.Among other considerations they also fail to con-sider the overlap of words and features betweenclasses in the same corpus domain.6 Corpus  compar i son  based  onin fo rmat ion  theoret i ca l  measuresIn this section we attempt o present measuresthat overcome some of the limitations of the class-token method.
We evaluate tbe contribution fromeach feature used in our NE recognition systemsby calculating its entropy.
There are thee  types offeature information used by our two systems: lexoical information, character type information, andpart-of-speech information.The entropy for NE classes H(C) is defined by= - E p(c) log 2 p(c) H(C)cECwhere:n(Op(c) = "Nn(c): the number of words in class cN: the total number of words in textWe can calculate the entropy for features in thesame way.When a feature F is given, the conditional en-tropy for NE classes H(CIF) is defined by- ~ ~ p(~, f) logs p(cll) H(C\]F)cEC fEFwhere:p(c, I) = .
(c, I)Nn(c, I) p(cll) = n(l)n(c, f):  the number of words in class cwith the feature value fn(/): the number of wordswith the feature value fUsing these entropies, we can calculate infor-mation gain (Breiman et al, 1984) and gain ra-tio (Quinlan, 1990).
Information gain for NEclasses and a feature I(C; F) is given as follows:I(C; F) = H(C) - H(CIF )The information gain I(C; F) shows how the fea-ture F is related with NE classes C. When F iscompletely independent ofC, the value of I(C; F)becomes the minimum value O.
The maximumvalue of I(C;_F) is equivalent to that of H(C),when the feature F gives sufficient information torecognize named entities.
Information gain canalso be calculated by:I(C; F) = H(C) + H(F) - H(C, F)We show the values of the above three entropiesin Table 5,6, and 7.
In these tables, F is replacedwith single letters which represent each of themodel's features, i.e.
character types (T), part-of-speech (P), and hxical information (W).Gain ratio is the normalized value of in.forma-tion gain.
The gain ratio GR(C; F) is defined byGR(C; F) = I(C; F)H(C)The range of the gain ratio GR(C; F) is 0 <GR(C; F) _~ 1 even when the class entropy isdifferent in various corpora, so we can comparethe values directly in the different NE recognitiontasks.6.1 Character typesCharacter type features are used to identifynamed entities in the MUCC-6 and biology corpus.However, the distribution of the character typesare quite different between these two types of doc-uments as we can see in Table 5.
We see throughthe gain-ratio score that character type informa-tion has a greater predictive power for classes inMUC~ than biology due to the higher entropyof character type and class sequences in the bi-ology corpus, i.e.
the greater disorder of this in-formation.
The result partially shows why iden-tification and classification is harder in biologicaldocuments than in newspaper articles such as theMUC-6  corpus.6.2  Part-of -speechTable 6 shows the entropy scores for part-of-speech (POS) sequences in the two corpora.
Wesee through the gain ratio scores that POS infor-mation is not so powerful for acquiring NEs in thebiology domain compared to the MUC-6 domain.24Table 5: Values of Entropy for character typeEntropy MUC-6 BiologyH(T) \[\[ 1.880 2.013H(C) II 0.890 1.264H(C,T) II 2.345 2.974I(C;T) \[I .0.425 0.302GR(C;T) H 0.478 0.239Table 6: Values of Entropy for POSsEntropy MUC-6 Biology"H(P) 4.287 4.037H(C) 0.890 1.264H(C,P) 4.750 5.029I(C;P) 0.426 0.272GR(C;P) 0.479 0.216In fact POS information for biology is far less use-ful than character information when we comparethe results in Tables 5 and 6, whereas POS hasabout the same predictive power as character in-formation in the MUC-6 domain.
One likely ex-planation for this is that the POS tagger we use inNE-DT is trained on a corpus based on newspaperarticles, therefore the assigned POS tags are oftenincorrect in biology documents.6.3 Lexical informationTable 7 shows the entropy statistics for the twodomains.
Although entropy for words in biologyis lower than MUC-6, the entropy for classes ishigher leading to a lower gain ratio in biology.
Wealso note that, as we would expect, in comparisonto the other two types of knowledge, surface wordforms are by far the most useful type of knowledgewith a gain ratio in MUC-6 of 0.897 compared to0.479 for POS and 0.478 for character types in thesame domain.
However, such knowledge is alsothe least generalizable and runs the risk of data-sparseness.
It therefore has to be complementedby more generalizable knowledge such as characterfeatures and POS.Table 7: Values of Entropy for words--Entropy MUC-6 BiologyH(W) 9.570 8.89OH(C) 0.890 1.264H(C,W) 9.662 9.232I(C;W) 0.798 0.921~R(C;W) 0.897 0.729Table 8: Values of Entropy for NEHMM featuresin the MUC-6 corpusGR0.9940.8980.9670.7980.3400.8060.4610.5580.2210.8060.5630.9710.633Cross Entropy5.38(4.08-9.68)7.69(6.97-9.32)7.73(7.07-9.30)4.38(4.12-.-4.82)1.62(1.32-1.90)7.65(7.11-8.65)2.64(2.41-2.97)7.91(7.25--8.99)2.94(2.70-3.25)7.65(7.11-6.65)7.92(7.26-9.03)5.42(4.10-9.70)4.18(3.91-4.60)Coverageo.44(o.34-o.78)O.
77(0.72-0.90)0.79(0.73-0.90)0.99(0.98-1.00)L00(1.00-L00)0.65(0.81-0.93)1.00(0.99-1.00)0.83(0.79-0.92)1.00(1.00-1.00)0.85(0.81,-0.93)0.83(0.79-0.92)0.44 (0.34-O.75)0.99(0.99--1.00)Features.for A0for Alfor A2for AsCt-1WtFtWt- IF~-xWt FzW~-l F=-iWt-l,~F~-LtTablein the biology corpusGR Cross Entropy0.977 5.83(5.66-6.14)0.793 7.93(7.77-8.08)0.929 7.79(7.65-7.85)0.643 5.07(4.95-5.21)0.315 2.26(2.24--2.28)0.694 7.64(7.52-7.78)0.257 3.12(3.06--3.19)0.423 7.99(7.62-8.08)0.093 3.33(3.27-3,43)0.694 7.64(7.52-7.78)0.424 7.98(7.82-8.04)0.904 5.96(5.78-6.24)0.339 4.66(4.53-4,78)9: Values of Entropy for NEHMM featuresCoverage0.49(0.48--0.52)o.6o(o.79-o.61)o.so(o.70-o.81)0.98(0.98-0.98)1.00(1.00-I.00)0.89(0.87-0.89)1.oo(1.OO-l.OO)0.87(0.86-0.88)1.00(1.00-1.00)0.89(0.87-0,89)o.87(0.85-0.86)0.50(0.49-0.52)0.99(0.98-0.99)Featuresfor ~tofor A1for ~t2for AsCt- IW=FeWt  FtWt-1 F,-zWz-l,tF~-l,t6.4 Compar i son  between thecomblnutlon of featuresIn this section we show a comparison of gain ra-tio for the features used by both systems in eachcorpus.
Values of gain ratio for each feature setare shown on the 'GR' column in Tables 8, 9, 10and 111.
The values of GR show that surfacewords have the best contribution in both corporafor both systems.
We can see that gain ratio forall features in NE-DT is actually lower than thetop level model for NEHMM in biology, reflectingthe actual system performance that we observed.We also see that in the biology corpus, the com-bination of all features in NE-DT has a lower con-tribution than in the MUC-6  corpus.
This indi-cates the limitation of the current feature set forthe biology corpus and shows that we need to uti-lize other types of features in this domain.Values for cross entropy between training andtest sets are shown in Tables 8, 9, 10 and 11 to-IOn the 'Features' col, mn~ "(Features) for A#"means the features used in each HMM sub-model which corresponds with the A# in Eclua-tion 2.
And also, 'ALL' in Tables 10 and 11means all the features used in decision tree, i.e.
{P~-l,~,,+l,F~-l,t,t+l,W,-1,~,~+l).Table 10: Values of Entropy for NE-DT featuresin the MUC-6 corpus0.G91~8 !
Cross Entropy1.59(1.38-1.77)0.402 5.22(5.09..-5.32)0.4681 2.66(2.51-2.87)0.844 7.36(7.19-7.57)0.670 7.89(7.81-7.97)0.6691 3.87(3.67-4.07)0.977 4.42(4.10-4.88)0.822 9.25(9.10-9.40)0.807 4.92(4.72-5.08)0.998 1.89(1.67-2.16)Coverage0.12(0.10-0.13)1.00(0.99-:t.00)L00(0.99-1.00)o.81(o.8o~.83)0.98(0.96--0.98)0.99(0.98-1.00)0.36(0.34--0.40)0.89(0.87~0.91)0.96(0.95--0.96)0.15(0.13-9.17)FeaturesALLPtFtWtPt-l,$Ft- l .
tWt--l,tPt-l ,t,t+lF?-1.
:.~+1W~-l.t.t+lTable 11: Values of Entropy for NE-DT featuresin the biology corpusGR Cross Entropy0.937 2.31(2.00-2.50)0.23"/ 5.31(5.21-5.38)0.262 3.27(3.14-3.41)0.416 7.63(7.50-7.79)0.370 7.78(7.69.-7.86)0.363 4.57(4.38-4.67)0.586 5.71(5.37-5.93)0.541 8.92(8.82-9.02)0.502 5.46(5.26-5.64)0.764 2.56(2.25-2.76)Coverage Features0.18(0.15-0.19) ALL1.00(0.99-1.00) P,1.00(1.00-1.00) Ft0.87(0.85--0.68) wt0.97(0.96-0.97) P~-a.=0.98(0.98-.0.99) F~-I,~0.48(0.45--0.50) Wt-  s,~0.88(0.87--0.89) Pt-x.~t.t +a0.96(0.94--0,96) Ft-l.t.~+a0.20(0.17--0.21) Wt_L?,t+tgether with error bounds in parentheses.
Thesevalues are calculated for pairs of an NE class andfeatures, and averaged for the n-fold experiments.In the MUC-6 corpus, 60 texts are separated into6 subsets, and one of them is used as the test setand the others are put together to form a train-ing set.
Similarly, 100 texts are separated into 5subsets in the biology corpus.
We also show thecoverage of the pairs on the 'Coverage' col,,mn.Coverage means that how many pairs which ap-peared in a test set alo appear in a trainlug set.In these columns, the greater the cross entropybetween features and a class, the more differenttheir occurrences between tr~iuing and test sets.On the other hand, as the coverage for class-features pairs increases, so does the part of thetest set that is covered with the given feature set.The results in both corpora for both systemsshow a drawback of surface words, since their cov-erage for a test set is lower than that of featureslike POSs and character types in both corporaAlso, the coverage of surface words in the biol-ogy corpus is higher than in the MUC6 corpusas opposed to other features.
The result matchesour intuition that vocabulary inthe biology corpusis relatively restricted but has a variety of typesother than normal English words.7 Conc lus ionThe need for soundly-motivated metrics to com-pare the usefulness of corpora for specific tasksand systems is dearly necessary for the develop-ment of robust and portable information extrac-tion systems.In this paper we have shown that measures forcomparing corpora based just on class-token ratioshave difficulty predicting system performance andcannot adequately explain the difficulty of the NEtask either generally or for specific systems.While we should be cautious in ma~ng sweep-ing conclusions due to the small size of corpora inour study, our results from gain ratio and crossentropy indicate that counts from the features ofboth systems will be more useful in the MUC6 cor-pus than in the biology corpus.
We can also seethat while the coverage is limited, surface wordsplay a leading role for both systems.
Gain ra-tio statistics for surface words in the two domainswere far closer than for any other type of feature,and given that this is also the dominant knowl-edge type this seems to be one likely reason thatthe performance of systems is about the same inboth domains.We have presented the results of applying twosupervised learning based models to the namedentity task in two widely different domains andexplained the performance through class-token ra-tios, entropy and gain ratio.
Measures such asentropy and gain ratio have been found to havethe best predictive power, although the featuresused to calculate gain ratio are not sufficient odescribe all the information that is necessary forthe named entity task.
In future work we intendto extend our study to new and larger NE corporain various domains and to try to reduce the errorfactor in our calculations that is a result of corpussize.Re ferencesA.
Bairoch and 1t.
Apweiler.
1997.
The SWISS-PROT protein sequence data bank and its newsupplement TrEMBL.
Nucleic Acids Research,25:31-36.D.
Bikel, S. Miller, R. Schwartz, and11.
Wesichedel.
1997.
Nymble: a high-performance learning name-finder.
In Pro-ceedings of the Fifth Con/ererenee on AppliedNatural Language Processing, pages 194--201.A.
Borthwiek, J.
Sterling, E. Agichtein, and11.
Grishman.
1998.
Exploiting diverse knowl-edge sources via maximum entropy in namedentity recognition.
In Proceedings of the Work-shop on Very Large Corpora (WYLC'98).L.
Breiman, It.
Friedman, A. Olshen, andC.
Stone.
1984.
Classification and regressiwa26trees.
Belmont CA: Wadsworth InternationalGroup.S.
Chen and J. Goodman.
1996.
An empiri-cal study of smoothing techniques for languagemodeling.
3gst Annual Meeting of the Associ-ation of Computational Linguistics, California,USA, 24-27 3tree.N.
Chinchor.
1995.
MUC-5 evaluation metrics.In In Proceedings of the Fifth Message Un-derstanding Conference (MUC-5), Baltimore,Maryland, USA., pages 69-78.N.
Collier, C. Nobata, and J. Tsujii.
2000.
Ex-tracting the names of genes and gene productswith a hidden Markov model.
In Proceedingsof the 18th International Conference on Com-putational Linguistics (COLING'2000), Saar-bruchen, Germany, July 31st-August 4th.M.
Craven and J. Kumlien.
1999.
Constructingbiological knowledge bases by extracting infor-mation from text sources.
In Proceedings ofthe7th International Conference on Intelligent Sys-temps for Molecular Biology (ISMB-99), Hei-delburg, Germany, August 6--10.K.
Fukuda, T. Tsunoda, A. Tamura, and T. Tak-ag i.
1998.
Toward information extraction:identifying protein names from biological pa-pers.
In Proceedings of the Pacific Symposiumon Biocomputin9'98 (PSB'98), January.MEDLINE.
1999.
The PubMeddatabase can be found at:.http://www.ncbi.nlm.nih.gov/PubMed/.DARPA.
1995.
Proceedings ofthe Sixth MessageUnderstanding Conference(MUC-6), Columbia,MD, USA, November.
Morgan Kaufmann.C.
Nobata, N. Collier, and I. Tsujii.
1999.
Au-tomatic term identification and classificationin biology texts.
In Proceedings of the Nat-ural Language Pacific Rim Symposium (NL-PRS'gO00), November.D.
Palmer and D. Day.
1997.
A statisticalprofile of the named entity task.
In Proceed-ings of the Fifth Conference on Applied NaturalLanguage Processing (ANLP'97), WashingtonD.C., USA., 31 March - 3 April.J.R.
Quinlan.
1990.
Introduction to DecisionTrees.
In J.W.
Shavlik and T.G.
Dietterich, ed-itors, Readings in Machine Learning.
MorganKauf:marm Publishers, Inc., San Mateo, Cali-fornia.J.R.
Quinlan.
1993. cJ.5 Programs for MachineLearning.
Morgan Kaufmann Publishers, Inc.,San Mateo, California.L.
Rabiner and B. Juang.
1986.
An introductionto bidden Markov models.
1EEE ASSP Maga-zine, pages 4-16, January.A.
Ratnaparkhi.
1996.
A maximum entropymodel for part-of-speech tagging.
In Uon\]er-ence on Empirical Methods in Natural LanguageProcessing, pages 133-142, University of Penn-sylvania, May.T.
Rindflesch, L. Tanabe, N. Weinstein, and L..Hunter.
2000.
EDGAR: Extraction of drugs,genes and relations from the biomedical litera-ture.
In Pacific Symposium on Bio-inforraaties(PSB '2000), Hawai 'i, USA, January.T.
Sekimizu, H. Park, and J. Tsujii.
1998.
Iden-tifying the interaction between genes and geneproducts based on frequently seen verbs in reed-line abstracts.
In Genome Informatics.
Univer-sal Academy Press, Inc.Satosbi Sekine, Ralph Grishman, and HiroyukiSbinnou.
1998.
A Decision Tree Method forFinding and Classifying Names in JapaneseTexts.
In Proceedings o\] the Sixth Workshopon Very Large Corpora, Montreal, Canada, Au-gust.C.
Van Rijsbergen.
1979.
Information Retrieval.Butterworths, London.A.
J. Viterbi.
1967.
Error bounds for convolutionscodes and an asymptotically optimum decodingalgorithm.
IEEE Transactions on InformationTheory, IT-13(2):260-269.E.M.
Voorhees and D.K.
Harman, editors.2000.
The Eighth Text REtrieval Confer-ence (TREC-8), Electronic version available athttp://trec.nist.gov/pubs.html.
