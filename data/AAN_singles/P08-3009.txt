Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 49?54,Columbus, June 2008. c?2008 Association for Computational LinguisticsAn Unsupervised Vector Approach to Biomedical Term Disambiguation:Integrating UMLS and MedlineBridget T. McInnesComputer Science DepartmentUniversity of Minnesota Twin CitiesMinneapolis, MN 55155, USAbthomson@cs.umn.eduAbstractThis paper introduces an unsupervised vectorapproach to disambiguate words in biomedi-cal text that can be applied to all-word dis-ambiguation.
We explore using contextualinformation from the Unified Medical Lan-guage System (UMLS) to describe the pos-sible senses of a word.
We experiment withautomatically creating individualized stopliststo help reduce the noise in our dataset.
Wecompare our results to SenseClusters andHumphrey et al (2006) using the NLM-WSDdataset and with SenseClusters using con-flated data from the 2005 Medline Baseline.1 IntroductionSome words have multiple senses.
For example, theword cold could refer to a viral infection or the tem-perature.
As humans, we find it easy to determinethe appropriate sense (concept) given the context inwhich the word is used.
For a computer, though, thisis a difficult problem which negatively impacts theaccuracy of biomedical applications such as medicalcoding and indexing.
The goal of our research is toexplore using information from biomedical knowl-edge sources such as the Unified Medical LanguageSystem (UMLS) and Medline to help distinguish be-tween different possible concepts of a word.In the UMLS, concepts associated with wordsand terms are enumerated via Concept Unique Iden-tifiers (CUIs).
For example, two possible sensesof cold are ?C0009264: Cold Temperature?
and?C0009443: Common Cold?
in the UMLS release2008AA.
The UMLS is also encoded with differ-ent semantic and syntactic structures.
Some suchinformation includes related concepts and semantictypes.
A semantic type (ST) is a broad subject cat-egorization assigned to a CUI.
For example, the STof ?C0009264: Cold Temperature?
is ?Idea or Con-cept?
while the ST for ?C0009443: Common Cold?is ?Disease or Syndrome?.
Currently, there existsapproximately 1.5 million CUIs and 135 STs in theUMLS.
Medline is an online database that contains11 million references biomedical articles.In this paper, we introduce an unsupervised vectorapproach to disambiguate words in biomedical textusing contextual information from the UMLS andMedline.
We compare our approach to Humphrey etal.
(2006) and SenseClusters.
The ability to makedisambiguation decisions for words that have thesame ST differentiates SenseClusters and our ap-proach from Humphrey et al?s (2006).
For exam-ple, the word weight in the UMLS has two possibleCUIs, ?C0005912: Body Weight?
and ?C0699807:Weight?, each having the ST ?Quantitative Con-cept?.
Humphrey et al?s (2006) approach relies onthe concepts having different STs therefore is unableto disambiguate between these two concepts.Currently, most word sense disambiguation ap-proaches focus on lexical sample disambiguationwhich only attempts to disambiguate a predefinedset of words.
This type of disambiguation is notpractical for large scale systems.
All-words dis-ambiguation approaches disambiguate all ambigu-ous words in a running text making them practi-cal for large scale systems.
Unlike SenseClusters,Humphrey, et al (2006) and our approach can be49used to perform all-words disambiguation.In the following sections, we first discuss relatedwork.
We then discuss our approach, experimentsand results.
Lastly, we discuss our conclusions andfuture work.2 Related WorkThere has been previous work on word sense dis-ambiguation in the biomedical domain.
Leroy andRindflesch (2005) introduce a supervised approachthat uses the UMLS STs and their semantic relationsof the words surrounding the target word as featuresinto a Naive Bayes classifier.
Joshi et al (2005) in-troduce a supervised approach that uses unigramsand bigrams surrounding the target word as featuresinto a Support Vector Machine.
A unigram is a sin-gle content word that occurs in a window of contextaround the target word.
A bigram is an ordered pairof content words that occur in a window of contextaround the target word.
McInnes et al (2007) in-troduce a supervised approach that uses CUIs of thewords surrounding the target word as features into aNaive Bayes classifier.Humphrey et al (2006) introduce an unsupervisedvector approach using Journal Descriptor (JD) In-dexing (JDI) which is a ranking algorithm that as-signs JDs to journal titles in MEDLINE.
The authorsapply the JDI algorithm to STs with the assumptionthat each possible concept has a distinct ST.
In thisapproach, an ST vector is created for each ST by ex-tracting associated words from the UMLS.
A targetword vector is created using the words surroundingthe target word.
The JDI algorithm is used to obtaina score for each word-JD and ST-JD pair using thetarget word and ST vectors.
These pairs are used tocreate a word-ST table using the cosine coefficientbetween the scores.
The cosine scores for the STs ofeach word surrounding the target word are averagedand the concept associated with the ST that has thehighest average is assigned to the target word.3 Vector ApproachesPatwardhan and Pedersen (2006) introduce a vectormeasure to determine the relatedness between pairsof concepts.
In this measure, a co-occurrence matrixof all words in a given corpus is created containinghow often they occur in the same window of con-text with each other.
A gloss vector is then createdfor each concept containing the word vector for eachword in the concepts definition (or gloss).
The co-sine between the two gloss vectors is computed todetermine the concepts relatedness.SenseClusters 1 is an unsupervised knowledge-lean word sense disambiguation package The pack-age uses clustering algorithms to group similar in-stances of target words and label them with the ap-propriate sense.
The clustering algorithms includeAgglomerative, Graph partitional-based, Partitionalbiased agglomerative and Direct k-way clustering.The clustering can be done in either vector spacewhere the vectors are clustered directly or similar-ity space where vectors are clustered by finding thepair-wise similarities among the contexts.
The fea-ture options available are first and second-order co-occurrence, unigram and bigram vectors.
First-ordervectors are highly frequent words, unigrams or bi-grams that co-occur in the same window of contextas the target word.
Second-order vectors are highlyfrequent words that occur with the words in their re-spective first order vector.We compare our approach to SenseClusters v0.95using direct k-way clustering with the I2 clusteringcriterion function and cluster in vector space.
We ex-periment with first-order unigrams and second-orderbigrams with a Log Likelihood Ratio greater than3.84 and the exact and gap cluster stopping param-eters (Purandare and Pedersen, 2004; Kulkarni andPedersen, 2005).4 Our ApproachOur approach has three stages: i) we create a thefeature vector for the target word (instance vector)and each of its possible concepts (concept vectors)using SenseClusters, ii) we calculate the cosine be-tween the instance vector and each of the conceptvectors, and iii) we assign the concept whose con-cept vector is the closest to the instance vector to thetarget word.To create the the instance vector, we use the wordsthat occur in the same abstract as the target word asfeatures.
To create the concept vector, we explorefour different context descriptions of a possible con-cept to use as features.
Since each possible concept1http://senseclusters.sourceforge.net/50has a corresponding CUI in the UMLS, we exploreusing: i) the words in the concept?s CUI definition,ii) the words in the definition of the concept?s STdefinition, iii) the words in both the CUI and STdefinitions, and iv) the words in the CUI definitionunless one does not exist then the words in its STdefinition.We explore using the same feature vector param-eters as in the SenseCluster experiments: i) first-order unigrams, and ii) second-order bigram.
Wealso explore using a more judicious approach to de-termine which words to include in the feature vec-tors.
One of the problems with an unsupervised vec-tor approach is its susceptibility to noise.
A wordfrequently seen in a majority of instances may notbe useful in distinguishing between different con-cepts.
To alleviate this problem, we create an in-dividualized stoplist for each target word using theinverse document frequency (IDF).
We calculate theIDF score for each word surrounding the target wordby taking the log of the number of documents in thetraining data divided by the number of documentsthe term has occurred in the dataset.
We then ex-tract those words that obtain an IDF score under thethreshold of one and add them to our basic stoplistto be used when determining the appropriate sensefor that specific target word.5 Data5.1 Training DataWe use the abstracts from the 2005 Medline Base-line as training data.
The data contains 14,792,864citations from the 2005 Medline repository.
Thebaseline contains 2,043,918 unique tokens and295,585 unique concepts.5.2 NLM-WSD Test DatasetWe use the National Library of Medicine?s WordSense Disambiguation (NLM-WSD) dataset devel-oped by (Weeber et al, 2001) as our test set.
Thisdataset contains 100 instances of 50 ambiguouswords from 1998 MEDLINE abstracts.
Each in-stance of a target word was manually disambiguatedby 11 human evaluators who assigned the word aCUI or ?None?
if none of the CUIs described theconcept.
(Humphrey et al, 2006) evaluate their ap-proach using a subset of 13 out of the 50 wordswhose majority sense is less than 65% and whosepossible concepts do not have the same ST. Instancestagged as ?None?
were removed from the dataset.We evaluate our approach using these same wordsand instances.5.3 Conflate Test DatasetTo test our algorithm on a larger biomedical dataset,we are creating our own dataset by conflating twoor more unambiguous words from the 2005 Med-line Baseline.
We determine which words to conflatebased on the following criteria: i) the words have asingle concept in the UMLS, ii) the words occur ap-proximately the same number of times in the corpus,and iii) the words do not co-occur together.We create our dataset using name-conflate 2 toextract instances containing the conflate words fromthe 2005 Medline Baseline.
Table 4 shows our cur-rent set of conflated words with their correspondingnumber of test (test) and training (train) instances.We refer to the conflated words as their pseudowordsthroughout the paper.6 Experimental ResultsIn this section, we report the results of our ex-periments.
First, we compare the results of usingthe IDF stoplist over a basic stoplist.
Second, wecompare the results of using the different contextdescriptions.
Third, we compare our approach toSenseClusters and Humphrey et al (2006) using theNLM-WSD dataset.
Lastly, we compare our ap-proach to SenseClusters using the conflated dataset.In the following tables, CUI refers to the CUI def-inition of the possible concept as context, ST refersto using the ST definition of the possible concept ascontext, CUI+ST refers to using both definitions ascontext, and CUI?ST refers to using the CUI defi-nition unless if one doesn?t exist then using ST def-inition.
Maj. refers to the ?majority sense?
baselinewhich is accuracy that would be achieved by assign-ing every instance of the target word with the mostfrequent sense as assigned by the human evaluators.6.1 Stoplist ResultsTable 2 shows the overall accuracy of our approachusing the basic stoplist and the IDF stoplist on the2http://www.d.umn.edu/ tpederse/namedata.html51target word Unigram BigramCUI ST CUI+ST CUI?ST CUI ST CUI+ST CUI?STadjustment 44.57 31.61 46.74 44.57 47.83 38.04 27.17 47.83blood pressure 39.39 34.34 41.41 38.38 43.43 27.27 47.47 38.38degree 3.13 70.31 70.31 70.31 3.13 48.44 48.44 48.44evaluation 50.51 50.51 53.54 51.52 50.51 54.55 52.53 51.52growth 63.64 51.52 42.42 63.64 63.64 51.52 48.48 63.64immunosuppression 50.51 46.46 50.51 50.51 43.43 57.58 48.48 43.43mosaic 0 33.33 27.08 37.50 0 28.13 22.92 22.92nutrition 28.41 34.09 35.23 25.00 38.64 39.77 36.36 37.50radiation 57.73 44.78 58.76 57.73 60.82 28.36 60.82 60.82repair 74.63 25.00 41.79 37.31 76.12 54.69 44.78 41.79scale 32.81 48.00 42.19 51.56 0 18.00 95.31 96.88sensitivity 6.00 50.56 48.00 48.00 8.00 44.94 18.00 18.00white 48.31 38.61 46.07 49.44 44.94 38.16 43.82 49.44average 38.43 43.01 46.46 48.11 36.96 40.73 45.74 47.74Table 1: Accuracy of Our Approach using Different Context DescriptionsNLM-WSD dataset using each of the different con-text descriptions described above.
The results showan approximately a 2% higher accuracy over usingthe basic stoplist.
The exception is when using theCUI context description; the accuracy decreased byapproximately 2% when using the unigram featureset and approximately 1% when using the bigramfeature set.context Basic stoplist IDF stoplistunigram bigram unigram bigramCUI 41.02 37.68 38.43 36.96ST 42.74 37.14 43.01 40.73CUI+ST 44.13 42.71 46.46 45.74CUI?ST 46.61 45.58 48.11 47.74Table 2: Accuracy of IDF stoplist on the NLM-WSDdataset6.1.1 Context ResultsTable 1 shows the results of our approach usingthe CUI and ST definitions as context for the possi-ble concepts on the NLM-WSD dataset and Table 4shows similar results using the conflate dataset.On the NLM-WSD dataset, the results show alarge difference in accuracy between the contexts ona word by word basis making it difficult to deter-mine which of the context description performs thebest.
The unigram results show that CUI?ST andCUI+ST obtain the highest accuracy for five words,and CUI and ST obtain the highest accuracy for oneword.
The bigram results show that CUI?ST andCUI obtains the highest accuracy for two words,ST obtains the highest accuracy for four words, andCUI+ST obtains the highest accuracy for one word.The overall results show that using unigrams withthe context description CUI?ST obtains the high-est overall accuracy.On the conflated dataset, the pseudowords a a,a o, d d and e e have a corresponding CUI defini-tion for each of their possible concepts therefore theaccuracy for CUI and CUI?
would be the same forthese datasets and is not reported.
The pseudowordsa a i, x p p and d a m e do not have a CUI defini-tions for each of their possible concepts.
The resultsshow that CUI obtained the highest accuracy for sixout of the seven datasets and CUI?ST obtained thehighest accuracy for one.
These experiments wererun using the unigram feature.6.2 NLM-WSD ResultsTable 3 shows the accuracy of the results obtainedby our unsupervised vector approach using theCUI?ST context description, SenseClusters, andthe results reported by Humphrey et al (2006).As seen with the context description results, thereexists a large difference in accuracy on a word byword basis between the approaches.
The resultsshow that Humphrey et al (2006) report a higheroverall accuracy compared to SenseClusters and ourapproach.
Although, Humphrey et al (2006) per-formed better for 5 out of the 13 words where asSenseClusters performed better for 9.
The unigramfeature set with gap cluster stopping returned thehighest overall accuracy for SenseClusters.
Thenumber of clusters for all of the gap cluster stoppingexperiments were two except for growth which re-turned one.
For our approach, the unigram featureset returned the highest overall accuracy.52target word senses Maj. Humphrey SenseClusters Our Approachet al 2006 exact cluster stopping gap cluster stopping CUI?STunigram bigram unigram bigram unigram bigramadjustment 3 66.67 76.67 49.46 38.71 55.91 45.16 44.57 47.83blood pressure 3 54.00 41.79 40.00 46.00 51.00 54.00 38.38 38.38degree 2 96.92 97.73 53.85 55.38 53.85 55.38 70.31 48.44evaluation 2 50.00 59.70 66.00 50.00 66.00 50.00 51.52 51.52growth 2 63.00 70.15 66.00 52.00 66.00 63.00 63.64 63.64immunosuppression 2 59.00 74.63 67.00 80.00 67.00 80.00 50.51 43.43mosaic 2 53.61 67.69 72.22 58.57 61.86 50.52 37.50 22.92nutrition 2 50.56 35.48 40.45 47.19 44.94 41.57 25.00 37.50radiation 2 62.24 78.79 69.39 56.12 69.39 56.12 57.73 60.82repair 2 76.47 86.36 86.76 73.53 86.76 73.53 37.31 41.79scale 2 100.0 60.47 100.0 100.0 100.0 100.0 51.56 96.88sensitivity 2 96.08 82.86 41.18 41.18 52.94 54.90 48.00 18.00white 2 54.44 55.00 80.00 53.33 80.00 53.33 49.44 49.44average 67.92 68.26 64.02 57.85 65.82 59.81 48.11 47.74Table 3: Accuracy of Approaches using the NLM-WSD Datasettarget word pseudo- test train Maj.
Sense Our Approachword Clusters CUI ST CUI+ST CUI?STactin-antigens a a 33193 298723 63.44 91.30 53.95 44.81 54.17angiotensin II-olgomycin a o 5256 47294 93.97 56.76 16.62 20.68 17.73dehydrogenase-diastolic d d 22606 203441 58.57 95.85 45.78 43.94 45.70endogenous-extracellular matrix e e 19820 178364 79.92 71.21 74.34 65.37 73.37allogenic-arginine-ischemic a a i 22915 206224 57.16 69.03 47.68 24.60 33.77 32.07X chromosome-peptide-plasmid x p p 46102 414904 74.61 66.21 20.04 31.60 42.89 42.98diacetate-apamin-meatus-enterocyte d a m e 1358 12212 25.95 74.23 28.87 24.08 26.07 22.68Table 4: Accuracy of Approaches using the Conflate Dataset6.3 Conflate ResultsTable 4 shows the accuracy of the results obtained byour approach and SenseClusters.
The results showthat SenseClusters returns a higher accuracy thanour approach except for the e e dataset.7 DiscussionWe report the results for four experiments in this pa-per: i) the results of using the IDF stoplist over a ba-sic stoplist, ii) the results of our approach using dif-ferent context descriptions of the possible conceptsof a target word, iii) the results of our approach com-pared to SenseClusters and Humphrey et al (2006)using the NLM-WSD dataset, and iv) the results ofour approach compared to SenseClusters using theconflated dataset.The results of using an individualized IDF stoplistfor each target word show an improvement over us-ing the basic stoplist.
The results of our approachusing different context descriptions show that for theNLM-WSD dataset the large differences in accuracymakes it unclear which of the context descriptionsperformed the best.
On the conflated dataset, addingthe ST definition to the context description improvedthe accuracy of only one pseudoword.
When com-paring our approach to Humphrey et al (2006) andSenseClusters, our approach did not return a higheraccuracy.When analyzing the data, we found that there doesnot exist a CUI definition for a large number of pos-sible concepts.
Table 5 shows the number of wordsin the CUI and ST definitions for each concept in theNLM-WSD dataset.
Only four target words have aCUI definition for each possible concept.
We alsofound the concept definitions vary widely in length.The CUI definitions in the UMLS come from a va-riety of sources and there may exist more than onedefinition per source.
Unlike CUI definitions, theredoes exist an ST definition for each possible con-cept.
The ST definitions come from the same sourceand are approximately the same length but they area broad categorization.
We believe this makes themtoo coarse grained to provide descriptive enough in-formation about their associated concepts.This can also be seen when analyzing the con-flate datasets.
The conflate dataset d a m e is miss-ing two definition which is a contributing factor toits low accuracy for CUI.
Adding the ST definition53target word CUI Definition ST Definitionc1 c2 c3 c1 c2 c3adjustment 41 9 48 31 19 10blood pressure 26 18 0 20 31 22degree 0 0 15 23evaluation 54 0 33 17growth 91 91 20 19immunosuppression 130 41 30 20mosaic 0 38 0 10 10 23nutrition 152 152 0 10 31 30radiation 71 207 14 30repair 0 51 30 20scale 0 10 144 47 23 8sensitivity 0 0 0 25 50 22white 0 60 15 28Table 5: Number of words in CUI and ST Definitions ofPossible the Concepts in the NLM-WSD Datasetthough did not provide enough distinctive informa-tion to distinguish between the possible concepts.8 Conclusions and Future WorkThis paper introduces an unsupervised vector ap-proach to disambiguate words in biomedical text us-ing contextual information from the UMLS.
Our ap-proach makes disambiguation decisions for wordsthat have the same ST unlike Humphrey et al(2006).
We believe that our approach shows promiseand leads us to our goal of exploring the use ofbiomedical knowledge sources.In the future, we would also like to increase thesize of our conflated dataset and possibly create abiomedical all-words disambiguation test set to testour approach.
Unlike SenseClusters, our approachcan be used to perform all-words disambiguation.For example, given the sentence: His weight hasfluctuated during the past month.
We first createa instance vector containing fluctuated, past andmonths for the word weight and a concept vectorfor each of its possible concepts, ?C0005912: BodyWeight?
and ?C0699807: Quantitative Concept?
us-ing their context descriptions.
We then calculate thecosine between the instance vector and each of thetwo concept vectors.
The concept whose vector hasthe smallest cosine score is assigned to weight.
Wethen repeat this process for fluctuated, past andmonths.We also plan to explore using different contex-tual information to improve the accuracy of ourapproach.
We are currently exploring using co-occurrence and relational information about the pos-sible CUIs in the UMLS.
Our IDF stoplist exper-iments show promise, we are planning to exploreother measures to determine which words to includein the stoplist as well as a way to automatically de-termine the threshold.AcknowledgmentsThe author thanks Ted Pedersen, John Carlis andSiddharth Patwardhan for their comments.Our experiments were conducted usingCuiTools v0.15, which is freely available fromhttp://cuitools.sourceforge.net.ReferencesS.M.
Humphrey, W.J.
Rogers, H. Kilicoglu, D. Demner-Fushman, and T.C.
Rindflesch.
2006.
Word sense dis-ambiguation by selecting the best semantic type basedon journal descriptor indexing: Preliminary experi-ment.
Journal of the American Society for InformationScience and Technolology, 57(1):96?113.M.
Joshi, T. Pedersen, and R. Maclin.
2005.
A compar-ative study of support vectors machines applied to thesupervised word sense disambiguation problem in themedical domain.
In Proceedings of 2nd Indian Inter-national Conference on AI, pages 3449?3468, Dec.A.
Kulkarni and T. Pedersen.
2005.
SenseClusters: un-supervised clustering and labeling of similar contexts.In Proceedings of the ACL 2005 on Interactive posterand demonstration sessions, pages 105?108, June.G.
Leroy and T.C.
Rindflesch.
2005.
Effects of in-formation and machine learning algorithms on wordsense disambiguation with small datasets.
Interna-tional Journal of Medical Info., 74(7-8):573?85.B.
McInnes, T. Pedersen, and J. Carlis.
2007.
Using umlsconcept unique identifiers (cuis) for word sense disam-biguation in the biomedical domain.
In Proceedings ofthe Annual Symposium of the American Medical Infor-matics Association, pages 533?37, Chicago, IL, Nov.S.
Patwardhan and T. Pedersen.
2006.
Using WordNet-based Context Vectors to Estimate the Semantic Relat-edness of Concepts.
In Proceedings of the EACL 2006Workshop Making Sense of Sense - Bringing Computa-tional Linguistics and Psycholinguistics Together, vol-ume 1501, pages 1?8, Trento, Italy, April.A.
Purandare and T. Pedersen.
2004.
Word sense dis-crimination by clustering contexts in vector and sim-ilarity spaces.
In Proceedings of the Conference onCoNLL, pages 41?48.M.
Weeber, J.G.
Mork, and A.R.
Aronson.
2001.
Devel-oping a test collection for biomedical word sense dis-ambiguation.
In Proceedings of the American MedicalInformatics Association Symposium, pages 746?750.54
