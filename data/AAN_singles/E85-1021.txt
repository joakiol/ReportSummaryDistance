DESIGN AND IMPLEMENTATION OF A LLXICAL DATA BASEEric WehrliDepartment of LinguisticsU.C.L.A.405 Hilgard Ave, Los Angeles, CA 90024ABSTRACTThis paper is concerned with thespecifications and the implementation of aparticular concept of word-based lexicon to beused for large natural language processing systemssuch as machine translation systems, and comparesit with the morpheme-based conception of thelexicon traditionally assumed in computationallinguistics.It will be argued that, although lessconcise, a relational word-based lexicon issuperior to a morpheme-based lexicon from atheoretical, computational and also practicalviewpoint.INTRODUCTIONIt has been traditionally assumed bycomputational linguists and particularly bydesigners of large natural language processingsystems such as machine translation systems thatthe lexicon should be limited to lexicalinformation that cannot be derived by rules.According to this view, a lexicon consists of alist of basic morphemes along with irregular orunpredictable words.In this paper, I would like to reexamine thistraditional view of the lexicon and point out someof the problems it faces which seriously questionthe general adequacy of this model for naturallanguage processing.As a trade-off between the often conflictinglinguistic, computational and also practicalconsiderations, an alternative conception of thelexicon will be discussed, largely based onJackendoff's (1975) proposal.
According to thisview, lexical entries are fully-specified butrelated to one another.
First developed for aFrench parser (cf.
Wehrli, 1984), this model hasbeen adopted for an English parser in development,as well as for the prototype of a French-Englishtranslation system.This paper is organized as follows: the firstsection addresses the general issue of whatconstitutes a lexical entry as well as thequestion of the relation between lexicon andmorphology from the point of view of boththeoretical linguistics and computationallinguistics.
Section 2 discusses the relationalword-based model of the lexicon and the rolemorphology is assigned in this model.
Finally, itspells out some of the details of theimplementation of this model.OVERVIEW OF THE PROBLSMOne of the well-known characteristic featuresof natural languages is the size and thecomplexity of their lexicons.
This is in sharpconstrast with artificial languages, whichtypically have small lexicons, in most cases madeup of simple, unambiguous lexical items.
Not onlydo natural languages have a huge number of lexicalelements -- no matter what precise definition ofthis latter term one chooses -- but these lexicalelements can furthermore (i) be ambiguous inseveral ways (ii) have a non-trivial internalstructure, or (iii) be part of compounds oridiomatic expressions, as illustrated in (1)-(A):(I) ambiguous words:can, fly, bank, pen, race, etc.
(2) internal structure:use-ful-ness, mis-understand-ing, lake-s,tri-ed(3) compounds:milkman, moonlight, etc.
(4) idiomatic expressions:to kick the bucket, by and large,to pull someone's leg, etc.In fact, the notion of word, itself, is notall that clear, as numerous linguists --theoreticians and/or computational linguists --have acknowledged.
Thus, to take an example fromthe computational linguistics literature, Kay(1977) notes:"In common usage, the term word referssometimes to sequences of letters thatcan be bounded by spaces or punctuationmarks in a text.
According to this view,run, runs, runnin~ and ran aredifferent words.
But common usage alsoallows these to count as instances ofthe same word because they belong to the146same paradigm in English accidence andare listed in the same entry in thedictionary.
"Some of these problems, as well as thegeneral question of what constitutes a lexicalentry, whether or not lexical items should berelated to one another, etc.
have been muchdebated over the last I0 or 15 years within theframework of generative grammar.
Considered as arelatively minor appendix of the phrase-structurerule component in the early days of generativegrammar, the lexicon became little by little anautonomous component of the grammar with its ownspecific formalism -- lexical entries as matricesof features, as advocated by Chomsky (1965).Finally, it also acquired specific types of rules,the so-called word formation rules (cf.
Halle,1973; Aronoff, 1976; Lieber, 1980; Selkirk, 1983,and others), and lexical redundancy rules (cf.Jackendoff, 1975; Bresnan, 1977).By and large, there seems to be widespreadagreement among linguists that the lexicon shouldbe viewed as the repository of all theidiosyncratic properties of the lexical items of alanguage (phonological, morphological, syntactic,semantic, etc.).
This agreement quicklydisappears, however, when it comes to definingwhat constitutes a lexical item, or, to put itslightly differently, what the lexicon is a listof, and how should it be organized.Among the many proposals discussed in thelinguistic literature, I will consider tworadically opposed views that I shall call themorpheme-bayed and the word-based conceptions ofthe lexicon .The morpheme-based lexicon corresponds to thetraditional derivational view of the lexicon,shared by the structuralist school, many of thegenerative linguists and virtually all thecomputational linguists.
According to this option,only non-derived morphemes are actually listed inthe lexicon, complex words being derived by meansof morphological rules.
In contrast, in aword-based lexicon a la Jackendoff, all the words(simple and complex) are listed as independentlexical entries, derivational as well asinflectional relgt~ons being expressed by means ofredundancy rules-'-.The crucial distinction between these twoviews of the lexicon has to do with the role ofmorphology.
The morpheme-based conception of thelexicon advocates a dynamic view of morphology,i.e.
a conception according to which "words aregenerated each time anew" (Hoekstra et al 1980).This view contrasts with the static conception ofmorphology assumed in Jackendoff's word-basedtheory of the lexicon.Interestingly enough, with the exception ofsome (usually very small) systems with nomorphology at all, all the lexicons incomputational linguistic projects seem to assume adynamic conception of morphology.The no-morphology option, which can be viewedas an extreme version of the word-based lexiconmentioned above modulo the redundancy rules, hasbeen adopted mostly for convenience by researchersworking on parsers for languages fairlyuninteresting from the point of view ofmorphology, e.g.
English.
It has the non-trivialmerit of reducing the lexical analysis to a simpledictionary look-up.
Since all flectional forms ofa given word are listed independently, all theorthographic words must be present in the lexicon.Thus, this option presents the double advantage ofbeing simple and efficient.
The price to pay isfairly high, though, in the sense that theresulting lexicon displays an enormous amount ofredundancy: lexical information relevant for awhole class of morphologically related words hasto be duplicated for every member of the class.This duplication of information, in turn, makesthe task of updating and/or deleting lexicalentries much more complex than it should be.This option is more seriously flawed thanjust being redundant and space-greedy, though.
Byignoring the obvious fact that words in naturallanguages do have some internal structure, maybelong to declension or conjugation classes, butabove all that different orthographical words mayin fact realize the same grammatical word indifferent syntactic environments it fails to bedescriptively adequate.
Interestingly enough, thisinadequacy turns out to have serious consequences.Consider, for example, the case of a translationsystem.
Because a lexicon of this exhaustive listtype has no way of representing a notion such as"lexeme", it lacks the proper level for lexicaltransfer.
Thus, if been, was, were, a._m.m and be aretreated as independant words, what should be theirtranslation, say in French, especially if weassume that the French lexicon is organized on thesame model?
The point is straightforward: there isno way one can give translation equivalents fororthographic words.
Lexical transfer can only bemade at the more abstract level of lexeme.
Thechoice of a particular orthographic word torealize this lexeme is strictly languagedependent.
In the previous example, assuming that,say, were is to be translated as a form of theverbe etre, the choice of the correct flectionalform will be governed by various factors andproperties of the French sentence.
In other words,a transfer lexicon must state the fact that theverb to be is translated in French by etre, ratherthan the lower level fact that under somecircumstances were is translated by etaient.The problems caused by the size and thecomplexity of natural language lexicons, as wellas the basic inadequacy of the "no morphology"option just described, have been long acknowledgedby computational linguists, in particular by thoseinvolved in the development of large-scaleapplication programs such as machine translation.It is thus hardly surprising that some version ofthe morpheme-based lexicon has been the optioncommon to all large natural language systems.There is no doubt that restricting the lexicon tobasic morphemes and deriving all complex words aswell as all the inflected forms by morphologicalrules, reduces substantially the size of thelexicon.
This was indeed a crucial issue not solong ago, when computer memory was scarce andexpensive.There are, however, numerous problems --linguistic, computational as well as practical --with the morpheme-based conception of the lexicon.Its inadequacy from a theoretical linguistic pointof view has been discussed abundantly in the"lexicalist" literature.
See in particular Chomsky(1970), Halle (1973) and Jackendoff (1975).
Someof the linguistic problems are summarized below,along with some mentions of computational as wellas practical problems inherent to this approach.First of all, from a conceptual point ofview, the adoption of a derivational model ofmorphology suggests that the derivation of a wordis very similar, as a process, to the derivationof a sentence.
Such a view, however, fails torecognize some fundamental distinctions betweenthe syntax of words and the syntax of sentences,for instance regarding creativity.
Whereas thevast majority of the words we use are fixedexpressions that we have heard before, exactly theopposite is true of sentences: most sentences wehear are likely to be novel to us.Also, given a morpheme-based lexicon, themorphological analysis creates readings of wordsthat do not exist, such as strawberry understoodas a compund of the morphemes @traw and berrz.This is far from being an isolate case, exampleslike the following are not hard to find:(5)a. comput-erb.
trans-missionc.
under-standd.
re-plye.
hard-lyThe problem with these words is that they aremorphologically composed of two or more morphemes,but their meaning is not derivable from themeaning of these morphemes.
Notice that listingthese words as such in the lexicon is notsufficient.
The morphological analysis will stillapply, creating an additional reading on the basisof the meaning of its parts.
To block this processrequires an ad hoc feature, i.e.
a specificfeature saying that this word should not beanalysed any further.Generally speaking, the morpheme-basedlexicon along with its word formation rules, Joe.the rules that govern the combination of morphemesis bound to generate far more words (or readingsof words) than what really exists in a particularlanguage.
It is clearly the case that only astrict subset of the possible combination ofmorphemes are actually realized.
To put itdifferently, it confuses the notion of potentialword 4 for a language with the notion of actualword .This point was already noticed in Halle(1973), who suggested that in addition to the listof morphemes and the word formation rules whichcharacterize the set of possible words, there mustexist a list of actual words which functions as afilter on the output of word formation rules.
Thisfilter, in other words, accounts for thedifference between potential words and actualwords.The idiosyncratic behaviour of lexical itemshas been further stressed in "Remarks onNominalization" where Chomsky convincingly arguesthat the meaning of derived nominals, such asthose in (6), cannot be derived by rules f rom themeaning of its constitutive morphemes.
Given thefact that derivational morphology is semanticallyirregular it should not be handled in the syntax.Chomsky concludes that derived nominals must belisted as such in the lexicon, the relationbetween verb and nominals beeing captured bylexical redundancy rules.(6)a.
revolve revolutionbo marry marriageCo do deedd.
act actionIt should be noticed that the somewhaterratic and unpredictable morphological relationsare not restricted to the domain of what istraditionally called derivation.
As Halle pointsout (p. 6), the whole range of exceptionalbehaviour observed with derivation can be foundwith inflection.
Halle gives examples ofaccidental gaps such as defective paradigms,phonological irregularity (accentuation of Russiannouns) and idiosyncratic meaning.From a computational point of view,' amorpheme-based lexicon has few merits beyond thefact that it is comparatively small in size.
Inthe generation process as well as in the analysisprocess the lack of clear distinction betweenpossible and actual words makes it unreliable --i.e.
one can never be sure that its output iscorrect.
Also, since a large number ofmorphological rules must systematically be appliedto every single word to make sure that allpossible readings of each word is taken intoconsideration, lexical analysis based on suchconceptions of the lexicon are bound to be fairlyinefficient.
Over the years, increasinglysophisticated morphological parsers have beendesigned, the best examples being Kay's (1977),Karttunen (1983) and Koskeniemmi (1983a,b), butnot surprisingly, the efficiency of such systemsremain well below the simple dictionary lookup 9.Also, this model has the dubious propertythat the retrieval of an irregular formnecessitates less computation than the retrievalof a regular form.
This is so because unlikeregular forms that have to be created/analyzedeach time they are used, irregular forms arelisted as such in the lexicon.
Hence, they cansimply be looked up.148This rapid and necessarily incompleteoverview of the organization of the lexicon andthe role of morphology in theoretical andcomputational linguistics has emphasized two basictypes of requirements: the linguistic requirementswhich have to do with descriptive adequacy of themodel, and the computational requirements whichhas to do with the efficiency of the process oflexical analysis or generation.
In particular, weargued that a lexicon consisting of the list ofall the inflected forms without any morphologyfails to  meet the first requirement, i.e.linguistic adequacy.
It was also pointed out thatsuch a model lacks the abstract lexical levelwhich is relevant, for instance, for lexicaltransfer in translation systems.
Although clearlysuperior to what we called the "no morphology"system, the traditional morpheme-based model runsinto numerous problems with respect to bothlinguistic and computational requirements.A third type of considerations which areoften overlooked in academical discussions, butturns out to be of primary importance for any"real life" system involving a large lexical database is what I would call "practical requirements"and has to do with the complexity of the task ofcreating a lexical entry.
It can roughly be viewedas a measure of the time it takes to create a newlexical entry, and of the amount of linguisticknowledge that is required to achieve this task.The relevance of these practical requirementsbecomes more and more evident as large naturallanguage processing systems are being developed.For instance, a translation system -- or any othertype of natural language processing program thatmust be able to handle very large amounts of text-- necessitates dictionaries of substantial size,of the order of at least tens of thousands ofentries, perhaps even more than I00,000 lexicalentries.
Needless to say the task of creating aswell as the one of updating such huge databasesrepresents an astronomical investment in terms ofhuman resources which cannot be overestimated.Whether it takes an average of, say 3 minutes, toenter a new lexical entry or 30 minutes may not beall that important as long as we are consideringlexicons of a few hundred words.
It may be thedifference between feasible a~d not feasible whenit comes to very big databases .Another important practical issue is thelevel of linguistic knowledge that is requiredfrom the user.
Systems which require littletechnical knowledge are to be preferred to thoserequiring an extensive amount of linguisticbackground, everything else being equal.
It shouldbe clear, in this respect, that morpheme-basedlexicons tend to require more linguistic knowledgefrom the user than a word-based lexicon, since theuser has to specify (i) what the morphologicalstructure of the word is (ii) to what extent themeaning of the word is or is not derived from themeaning of its parts, (iii) whatmorphophonological rules apply in the derivationof this word.A RELATIONAL WORD-BASED LEXICONThe traditional view in computationallinguistics is to assume some version of themorpheme-based lexicon, coupled with amorphological analyzer/generator.
Thus it isassumed that a dynamic morphological process takesplace both in the analysis and in the generationof words (i.e.
orthographical words).
Each time aword is read or heard, it is decomposed into itsatomic constituents and each time it is producedit has t~ be re-created from its atomicconstituents .As I pointed out earlier, I don't see anycompelling evidence supporting this view otherthan the simplicity argument.
Crucial for thisargument, then, is the assumption that thecomplexity measure is just a measure of the lengthof the lexicon, i.e.
the sum of the symbolscontained in the lexicon.One cannot exclude, though, moresophisticated ways to mesure the complexity of thelexicon.
Jackendoff (1975:640) suggests analternative complexity measure based on"independent information content".
Intuitively,the idea is that redundant information that ispredictable by the existence ~f a redundancy ruledoes not count as independent .Assumimg a strict lexicalist framework a laJackendoff, we developed a word-based lexicaldatabase dubbed relational word-based lexicon(RWL).
Essentially, the RWL model is a list-typelexicon with cross references.
All the words ofthe language are listed in such a lexicon and haveindependent lexical entries.
The morphologicalrelations between two or more lexical entries arecaptured by a complex network of relations.
Thebasic idea underlying this organization is tofactor out properties shared by several lexicalentries.To take a simple example, all themorphological forms of the English verb run have alexical entry.
Hence, run, runs, ra._~n and runnin~are listed independently in the lexicon.
At thesame time, however, these four lexical entries areto be related in some way to express the fact thatthey are morphologically related, i.e.
they belongto the same paradigm.
In turns, this has thefurther advantage of providing a clear definitionof the "lexeme", the abstract lexical unit whichis relevant, for instance, for lexical transfer,as will be pointed out below.In contrast with the common use incomputational linguistics, 9in this modelmorphology is essentially static .
By interpretingmorphology as relations within the lexicaldatabase rather than as a process, we shift somecomplexity from the parsing algorithm to thelexical data structures.
Whether or not this shiftis justified from a linguistic point of view is anopen question, and I have nothing co say about ithere.
From a computational point of view, though,this shift has rather interesting consequences.149First of all, it drastically simplifies thetask of lexical analysis (or generation), makingit a deterministic process N as opposed to anecessarily non-deterministic morphologicalparser.
In fact, it makes lexical analysis rathertrivial, equating it with a fairly simple databasequery.
It follows that the process of retrievingan irregular word is identical to the process ofretrieving a regular word.
The distinction betweenregular morphological forms and exceptional oneshas no effect on the lexical analysis, i.e.
onprocessing.
Rather, it affects the complexitymeasure of the lexicon.Also, in sharp contrast to what happens witha derivational conception of morphology, in ourmodel, the morphological complexity of a languagehas very little effect on the efficiency oflexical analysis, which seems essentially correct:speakers of morphologically complex languages donot seem to require significantly more time toparse individual words than speakers of, say,English.A partial implementation of this relationalword-based model of the lexicon has been realizedfor the parser for French described in Wehrli(1984).
This section describes some of thefeatures of this implementation.
Only inflectionhas been implemented, so far.
Some aspects ofderivational morphology should be added in thenear future.In this implementation, lexical entries arecomposed of three distinct kinds of objectsreferred to as words, morpho-syntactic elementsand lexemes, cf.
figure I .
A word is simply astr ing of characters, or what is sometimes calledan orthographic word.
It is linked to a set ofmorpho-syntactic elements, each one of themspecifying a particular grammatical reading of theword.
A morpho-syntactic element is a just aparticular set of grammatical features such ascategory, gender, number, person, case, etc.
Alexeme contains all the information shared by allthe flectional forms of a given lexical item.
Thelexeme is defined as a set of syntactic andsemantic features shared by one or severalmorpho-syntactic elements.
Roughly speaking, itcontains the kind of information one expect tofind in a standard dictionary entry.Words Morpho-syntactic elements Lexemes?stIIest-ce quetest-ce qu'~tei  tresommessuisN, sg.
\]\ .
V, 3rd sg.
pres.i ,~ Adv, inter, prtc.I j ~t Adv, inter, prt \]\\\\V, paat part.
~ " ~ "  ,\\\N, sg.
"~ V, inf.
4- V. I.st pl.
pres.///j ~  - V. 1st sg.
pres.
/V, t-2 sg.
pres .
:eaat ' \]lu"aummer~tre'being'~.tre;to be 'T&re (aux.
)'to be '.
~ somme: c l rno~nt  'suivre"to fo l low 'Figure i: Structure of the lexicon150In relational ~erms, fully-specified lexicalentries are broken into three different relations.The full set of information belonging to a lexicalentry can be obtained by intersecting the threerelations.The following example illustrates thestructure of the lexical data base and therespective roles of words, morpho-syntacticelements and lexemes.
In French, suis isambiguous.
It is the first person singular presenttense of the verb etre ('to be'), which, as inEnglish, is both a verb and an auxiliary.
But suisis also the first and second person singularpresent tense of the verb suivre ('to follow').This information is represented as follows: thelexicon has a word (in the technical sense, i.e.
as~ring of characters) suis associated with twomorpho-syntactic elements.
The firstmorpho-syntactic element which bears the features\[+V, Ist, sg, present\] is linked to a list of twolexemes.
One of them contains all the generalproperties of the verb etre, the other one theinformation corresponding to the auxiliary readingof etre.
As for the second morpho-syntacticelement, it bears the features \[+V, Ist-2nd, sg,present\] and it is related to the lexemecontaining the syntactic and semantic featurescharacterizing the verb suivre.Such an organization allows for a substantialreduction of redundancy.
All the differentmorphological forms of etre, i.e.
over 25different words are ultimately linked to 2 lexemes(verbal and auxiliary readings).
Thus, informationabout subcategorization, selectional restrictions,etc.
is specified only once rather than 25 timesor more.
Naturally, this concentration of theinformation also simplifies the updatingprocedure.
Also, as we pointed out above, thisstructure provides a clear definition of "lexeme",the abstract lexical representation, which is thelevel of representation relevant for transfer intranslation systems.Figure i, above, illustrates the structure ofthe lexical database.
Boxes stand for thedifferent items (words, morphosyntactic elements,lexemes) and arrows represent the relationsbetween these items.
Notice that not allmorphosyntactic elements are associated with somelexemes.
In fact, there is a lexeme level only forthose categories which display morphologicalvariation, i.e.
nouns, adjectives, verbs anddeterminers.The arrow between the words est and est-ceque expresses the fact that the string est occursat the initial of the compound est-ce que.
This isthe way compounds are dealt with in this lexicon.The compound clair de lune ('moonlight') is listedas an independent word M along with itsassociated morphosyntactic elements and lexemes --related to the word clair.
The function of thisrelation is to signal to the analyzer that theword clair is also the first segment of acompound.Consider the vertical arrow between thelexeme corresponding to the verbal reading of etre('to be') and the lexeme corresponding to theauxiliary reading of etre.
It expresses the factthat a given morphosyntactic element may haveseveral distinct readings (in this case the verbalreading and the auxiliary reading).
Thus,morphosyntactic elements can be related not justto one lexeme, but to a list of lexemes.The role of morphology in Jackendoff's systemis double.
First, the redundancy rules have astatic role, which is to describe morphologicalpatterns in the language, and thus to account forword-structure.
In addition to this primary role,morphology also assumes a secondary role, in thesense that it can be used to produce new words orto analyze words that are not present in thelexicon.
In this respect, Jackendoff (1975:668)notes, "lexical redundacy rules are learned formgeneralizations observed in already known lexicalitems.
Once learned, they make it easier to learnnew lexical items".
In other words, redundancyrules can also function as word ~rmat ion rulesand, hence, have a dynamic functionIn our implementation of the relationalword-based lexicon, morphology has also a doublefunction.
On the one hand, morphological relationsare embedded in the structure of the databaseitself and, roughly, correspond to Jackendoff'sredundancy rules in their static role.
On theother hand, morphological rules are considered as"learning rules", i.e.
as devices which facilitatethe acquisition of the paradigm of the inflectedforms of a new lexeme.
As such, morphologicalrules apply when a new word is entered in thelexicon.
Their role is to help and assist the userin his/her task of entering new lexical entries.For example, if the infinitival form of a verb isentered, the morphological rules are used tocreate all the inflected forms, in an interactivesession.
So, for instance, the system firstconsiders the verb to be morphologically regular.If so, that is if the user confirms thishypothesis, the system generates all the inflectedforms without further assistance.
If the answer isno, the system will try another hypothesis,looking for subregularities.Our relational word-based lexicon was firstimplemented on a relational database system on aVAX-780.
However, for efficiency reasons, it wastransfered to a more conventional system usin Bindexed sequential and direct access files.
In itspresent implementation, on a VAX-750, words andmorphosyntactic elements are stored in indexedsequential files, lexemes in direct access files.In other words, the lexicon is entirely stored inexternal files, which can be expanded, practicallywithout affecting the efficiency of the system.
Aset of menu-oriented procedures allow the user tointeract with the lexical data base, to eitherinsert, delete, update or just visualize words andtheir lexical specifications.151CONCLbSIONSeveral important issues have been discussedin this paper, regarding the structure and thefunction of the lexicon, as well as the role ofmorphology.
We first pointed out the importantrole of morphology and showed that it cannot bedispensed with, even in processing systems with noparticular psychological claim.
Hence, anexhaustive list of all the orthographic forms ofEnglish words cannot stand for an adequate lexiconof English.Turning then to what appears to be thetraditional conception of morphology incomputational linguistics, we showed that amorpheme-based lexicon, along with a derivationalmorphological component faces a variety of seriousproblems, including its inability to distinguishactual words from potential words, its inabilityto express partial morphological or semanticrelations, as well as its inherent inefficiencyand often lack of reliability.The success of this traditional conception ofthe lexicon in computational linguistics mustprobably be attributed to its relativeconciseness.
However, alternative ways to evaluatethe complexity of lexical entries, i.e.Jackendoff's independent information content, aswell as the emergence of cheap and abundant memoryhave drastically modify this state of affair, andopen new perspectives more in line with currentresearch in theoretical linguistics.To the traditional view, we opposed arelational word-based lexicon, along the lines ofJackendoff's (1975) proposal, where morphology canbe viewed, in part, as relations among lexicalentries.
Simple words, complex words, compounds,etc., are all listed in our lexicon.
But lexicalentries which belong to a same paradigm arerelated to the same lexeme.
Rather than derivingor analyzing words each time they are used,morphological rules only serve when a new wordoccurs.FOOTNOTESI.
One might think of compromises between thesetwo options, such as, for instance, thestem-based lexicon argued for in Anderson(1982), where lexical entries consists of stemsrather than morphemes, and an independentmorphological component is responsible for thederivation of inflectional forms.Aronoff's (1976) proposal can also be viewed asa compromise solution.
See footnote 2.2.
It should be pointed out that other word-basedtheories have been proposed.
For instance,Aronoff (1976) argues for a word-based lexiconwhere only words which are atomic or exceptionalin one way or another are entered in thelexicon.3.
In this paper, I will simply considerinflectional morphology as the adunc=ion towords of affixes which only modify features suchas tense, person, number, gender, case, etc.
asin read-?, read-inR, book-s. Derivationalmorphology, on the other hand, deals with theaddition of affixes which can modify the meaningof the word, and very often its categorialstatus, e.g.
use-ful, use-ful-ness, hard-lv.4.
Potential words are words that are well-formedwith respect to word formation rules, whereasthe actual words are the those potential wordsthat are realized in this language.
To give anexample, both arrival and arrivation arepotential English words, but only the secondhappens to be an actual English word.5.
For instance, Koskeniemmi (1983b) mentions anaverage of I00 milliseconds per words on aDEC-20.6.
This figure is indeed very conservative.
Slocum(1982:8) reports that the cost of writing adictionary entry for the TAUM-Aviation projectwas estimated at 3.75 man-hours...7.
This concepcion is yet another example of the"historicist approach" typical of classicaltransformational generative grammar, whichassumes that synchronic processes recapitulatesmany of the diachronic developments.8.
The following is an approximation of howindependent information can be measu red:"(Information measure)Given a fully specified leixcal entry W to beintroduced into the lexicon, the independentinformation it adds to the lexicon is(a) the information that W exists in thelexicon, i.e.
that W is a word of thelanguage; plus(b) all the information in W which cannot bepredicted by the existence of someredundancy rule R which permits W to bepartially described in terms of informationalready in the lexicon: plus(c) the cost of referring to the redundancyrule R.9.
It will be argued below that morphology has asecondary role, which is to facilitate theacquisition of new words.i0.
In the conclusion of his "Prolegomena" Hallealso mentions the possibility th at wordformation rules be used when the speaker hearsan unfamiliar word or when he uses a word freelyinvented.II.
From a psychological point of view, it couldalso be argued that morphology facilitatesmemorization.152REFERENCESAnderson, S. R. (1982).
"Where is morphology?
",LinKuistic Inquiry.Aronoff, M. (1976).
Word Fromation in GenerativeGrammar, Linguistic Inquiry Monograph One,MIT Press.Bresnan, J.
(1977).
"A realistic transformationalgrammar", in Halle, M., J. Bresnan and G.A.Miller (eds.)
Linguistic Theory andPsychological Reality, MIT Press.Chomsky, N. (1957).
Syntactic Structures, Mouton.Chomsky, N. (1965).
Aspects of the Theory ofSyntax, MIT Press.Chomsky, N. (1970).
"Remarks on nominalization",Studies on Semantics in Generative Grammar,Mouton.Halle, M. (1973).
"Prolegomena to a theory of wordformation", Linguistic Inquiry, 4.1. pp.3-16.Hoekstra, T., H. van der Hulst and M. Moortgat(1983).
Lexical Grammar, Foris.Jackendoff, R. (1975).
'~orphological and semanticregularities in the lexicon", Language 51.3,pp.
639-671.Karttunen, L. (1983).
"KIMMO: A generalmorphological processor".
Texas LinguisticForum, No.
22, pp.
165-228.Kay, M. (1977).
"Morphological and syntacticanalysis", in A. Zampoli (ed.)
LinKuisticStructures Processing, North-Holland.Koskenniemi, K. (1983a).
Two-Level Morphology: AGeneral Computational Model For Word-FormRecognition And Production, Publications Noii, Umiversity of Helsinki.Koskenniemi, K. (1983b).
"Two-Level Model forMorphological Analysis", Proceedin@s of theEighth International Joint Conference onArtificial Intelligence, pp.
683-685, WilliamKaufmann, Inc.Lieber, R. (1980).
On the OrRanization of theLexicon, Ph.D. Dissertation, MIT.Selkirk, E. (1982).
The Syntax of Words.Linguistic Inquiry Monograph Seven, MITPress.Slocum, J.
(1981).
"Machine translation: itshistory, current status and futureprospects", mimeo, University of Texas.Wehrli, E..(1984).
"A Government-Binding parserfor French", working paper no 48,ISSCO-Geneva University.153
