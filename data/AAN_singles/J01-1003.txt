Bootstrapping Morphological Analyzersby Combining Human Elicitation andMachine LearningKemal Oflazer*Sabancl UniversityMarjorie McShane*New Mexico State UniversitySergei Nirenburg*New Mexico State UniversityThis paper presents a semiautomatic technique for developing broad-coverage finite-state mor-phological analyzers for use in natural language processing applications.
It consists of threecomponents--elicitation f linguistic information from humans, a machine learning bootstrap-ping scheme, and a testing environment.
The three components are applied iteratively until athreshold of output quality is attained.
The initial application of this technique is for the mor-phology of low-density languages in the context of the Expedition project at NMS U ComputingResearch Laboratory.
This elicit-build-test technique compiles lexical and inflectional informationelicited from a human into a finite-state transducer lexicon and combines this with a sequenceof morphographemic rewrite rules that is induced using transformation-based l arning fromthe elicited examples.
The resulting morphological nalyzer is then tested against a test set,and any corrections are fed back into the learning procedure, which then builds an improvedanalyzer.1.
IntroductionThe Expedition project at NMSU Computing Research Laboratory is devoted to thefast "ramp-up" of machine translation systems from less studied, so-called low-densitylanguages, into English.
One of the components hat must be acquired and built dur-ing this process is a morphological nalyzer for the source language.
Since languageinformants are not expected or required to be well-versed in computational linguisticsin general, or in recent approaches tobuilding morphological nalyzers (e.g., Kosken-niemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) andthe operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen andBeesley 1992; Karttunen et al 1996; Mohri, Pereira, and Riley 1998; van Noord 1999;van Noord and Gerdemann 1999) in particular, the generation of the morphologicalanalyzer component has to be accomplished semiautomatically.
The informant willbe guided through a knowledge licitation procedure using the elicitation componentof Expedition, the Boas system.
As this task is not easy, we expect hat the develop-ment of the morphological nalyzer will be an iterative process, whereby the humaninformant will revise and/or refine the information previously elicited based on thefeedback from test runs of the nascent analyzer.
* Faculty of Engineering and Natural Sciences, Orhanh, 81474 Tuzla, Istanbul, TURKEYt Computing Research Laboratory, Las Cruces, NM 88003Computational Linguistics Volume 27, Number 1The work reported in this paper describes the process of building and refining mor-phological analyzers using data elicited from human informants and machine learning.The main use of machine learning in our current approach is in the automatic learningof formal rewrite or replace rules for morphographemic changes derived from the ex-amples provided by the informant.
The subtask of accounting for morphographemicchanges is perhaps one of the more complicated aspects of building an analyzer; byautomating it, we expect o improve productivity.After a review of related work, we very briefly describe the Boas project, of whichthe current work is a part.
Subsequent sections describe the details of the approach,the architecture of the morphological analyzer, the elicited descriptive data, and thecomputational processes performed on this data, including segmentation and the in-duction of morphographemic rules.
We then provide a detailed example of applyingthis approach to developing a morphological nalyzer for Polish.
Finally, we providesome conclusions and ideas for future work.2.
Related WorkMachine learning techniques are widely employed in many aspects of language pro-cessing.
The availability of large, annotated corpora has fueled a significant amount ofwork in the application of machine learning techniques to language processing prob-lems, such as part-of-speech tagging, grammar induction, and sense disambiguation,as witnessed by recent workshops and journal issues dedicated to this topic.
1 The cur-rent work attempts to contribute to this literature by describing a human-supervisedmachine learning approach to the induction of morphological analyzers--a problemthat, surprisingly, has received little attention.There have been a number of studies on inducing morphographemic rules from alist of inflected words and a root word list.
Johnson (1984) presents a scheme for in-ducing phonological rules from surface data, mainly in the context of studying certainaspects of language acquisition.
The premise is that languages have a finite number ofalternations to be handled by morphographemic rules and a fixed number of contextsin which they appear; so if there is enough data, phonological rewrite rules can begenerated to account for the data.
Rules are ordered by some notion of "surfaciness",and at each stage the most surfacy rule--the rule with the most transparent context--is selected.
Golding and Thompson (1985) describe an approach for inducing rules ofEnglish word formation from a corpus of root forms and the corresponding inflectedforms.
The procedure described there generates a sequence of transformation rules, 2each specifying how to perform a particular inflection.More recently, Theron and Cloete (1997) have presented a scheme for obtainingtwo-level morphology rules from a set of aligned segmented and surface pairs.
Theyuse the notion of string edit sequences, assuming that only insertions and deletionsare applied to a root form to get the inflected form.
They determine the root formassociated with an inflected form (and consequently the suffixes and prefixes) by ex-haustively matching the inflected form against all root words.
The motivation is that"real" suffixes will appear frequently in the corpus of inflected forms.
Once commonsuffixes and prefixes are identified, the segmentation for an inflected word can bedetermined by choosing the segmentation with the most frequently occurring affixsegments; the remainder is then considered the root.
While this procedure seems to1 For instance, the CoNLL (Computational Natural Language Learning) Workshops, recent special issuesof Machine Learning Journal (Vol.
34 Issue 1/3, Feb. 1999) and AIMagazine (Vol.
18, No.
4, 1997).2 Not in the sense in which it is used in transformation-based learning (Brill 1995).60Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzersbe reasonable for a small root word list, the potential for "noisy" or incorrect align-ments is quite high when the corpus of inflected forms is large and the procedureis not given any prior knowledge of possible segmentations.
As a result, automati-cally selecting the "correct" segmentation becomes nontrivial.
An additional compli-cation is that allomorphs how up as distinct affixes and their counts in segmentationsare not accumulated, which might lead to actual segmentations being missed due tofragmentation.
The rules are not induced via a learning scheme: aligned pairs arecompressed into a special data structure and traversals over this data structure gener-ate morphographemic rules.
Theron and Cloete have experimented with pluralizationin Afrikaans, and the resulting system has shown about 94% accuracy on unseenwords.Goldsmith (1998) has used an unsupervised learning method based on the mini-mum description length principle to learn the "morphology" of a number of languages.What is learned is a set of root words and affixes, and common inflectional-patternclasses.
The system requires just a corpus of words in a language.
In the absence ofany root word list to use as a scaffolding, the shortest forms that appear frequentlyare assumed to be roots, and observed surface forms are then either generated by theconcatenative affixation of suffixes or by rewrite rules.
3 Since the system has no notionof what the roots and their part-of-speech values really are, and what morphologicalinformation is encoded by the affixes, this information eeds to be retrofitted manuallyby a human, who has to weed through a large number of noisy rules.
We feel that thisapproach, while quite novel, can be used to build real-world morphological nalyzersonly after substantial modifications are made.3.
The BOAS ProjectBoas (Nirenburg 1998; Nirenburg and Raskin 1998) is a semiautomatic knowledgeelicitation system that guides a team of two people (a language informant and aprogrammer) through the process of developing the static knowledge sources requiredto produce a moderate-quality, broad-coverage MT system from any "low-density"language into English.
Boas contains knowledge about human language phenomenaand various realizations of these phenomena in a number of specific languages, aswell as extensive pedagogical support, making the system a kind of "linguist in abox," intended to help nonprofessional users with the task.
In the spirit of the goal-driven, "demand-side" approach to computational pplications of language processing(Nirenburg and Raskin 1999), the process of acquiring this knowledge has been splitinto two steps: (i) acquiring the descriptive, declarative knowledge about a languageand (ii) deriving operational knowledge (content for the processing engines) from thisdescriptive knowledge.An important goal that we strive to achieve regarding these descriptive and op-erational pieces of information, be they elicited from human informants or acquiredvia machine learning, is that they be transparent, human-readable, and, where neces-sary, human-maintainable and human-extendable, contrary to the opaque and unin-terpretable representations acquired by various statistical learning paradigms.Before proceeding any further, we would also like to make explicit the aims andlimitations of our approach.
Our main goal is to significantly expedite the develop-ment of a morphological nalyzer.
It is clear that for inflectional languages where each3 Some of these rules may not make sense, but they are necessary to account for the data: for instance, arule like insert a word f inal y after the root " eas " is used to generate easy.61Computational Linguistics Volume 27, Number 1root word can be associated with a finite number of word forms, one can, with a lot ofwork, generate a list of word forms with associated morphological features encoded,then use this as a lookup table to analyze word forms in input texts.
Since this pro-cess is time consuming, expensive, and error-prone, it is something we would like toavoid.
We prefer to capture general morphophonological and morphographemic phe-nomena using sample paradigms as the basis of lexical abstractions.
This reduces theacquisition process to assigning citation forms to one of the established paradigms;the automatic generation process described below does the rest of the work.
4 Thisprocess is still imperfect, as we expect human informants to err in making theirparadigm abstractions and to overlook details and exceptions.
So, the whole pro-cess is an iterative one, with convergence to a wide-coverage analyzer coming slowlyat the beginning (where morphological phenomena nd lexicon abstractions are be-ing defined and tested), but significantly speeding up once wholesale lexical acqui-sition starts.
Since the generation of the operational content (data files to be usedby the morphological analyzer engine) from the elicited descriptions i  expected totake only a few minutes, feedback on operational performance can be provided veryquickly.Human languages have many diverse morphological phenomena nd it is notour intent at this point to have a universal architecture that can accommodate anyand all phenomena.
Rather, we propose an extensible approach that can accommo-date additional functionality in future incarnations of Boas.
We also intend to limitmorphological processing to single tokens and to deal with multitoken phenomena,such as partial or full word reduplications, with additional machinery that we do notdiscuss here.4.
The Elicit-Build-Test LoopIn this paper we concentrate on operational content in the context of building a mor-phological analyzer.
To determine this content, we integrate the information providedby the informant with automatically derived information.
The whole process is aniterative one, as illustrated in Figure 1: the elicited information is transformed intothe operational data required by the generic morphological analyzer engine and theresulting analyzer is then tested on a test corpus, s'6 Any discrepancies between theoutput of the analyzer and the test corpus are then analyzed and potential sourcesof errors are given as feedback to the elicitation process.
Currently, this feedback islimited to identifying problems in handling morphographemic processes (such as forinstance the change of word-final -y to -i when the suffix -est is added).The box in Figure 1 labeled Morphological Analyzer Generation is the main com-ponent, which takes in the elicited information and generates a series of regular ex-pressions for describing the morphological lexicon and morphographemic rules.
Themorphographemic rules describing changes in spelling as a result of affixation opera-tions are induced from the examples provided by using transformation-based l arning(Brill 1995; Satta and Henderson 1997).
The result is an ordered set of contextual re-place or rewrite rules, much like those used in phonology.4 We use the term citation form to refer to the word form that is used to look up a given inflected formin a dictionary.
It may  be the root or stem form that affixation is applied to, or it may  have additionalmorphological markers to indicate its citation form status.5 We currently use XRCE finite-state tools as our target environment (Karttunen et al 1996).6 The test corpus is either elicited from the human informant or compiled from on-line resources for thelanguage in question.62Oflazer, Nirenburg, and McShane Bootstrapping Morphological AnalyzersCorpus  1~ompilatiol~StartI Human Elicitation 1~ProcessI Description f Morphology(paradigms~ examples~ exceptions~ etc.
)i Test I Err?rs, I Corpus OmissionsFigure 1I Morphological Analyzer 1Generation\[ Content for Morphological Analyzer Engine \](lexicons~ morphographemic rules)\[" Comparison ~ ~l~'| with Test Corpus \[\[,(MA Engine, Test Engine)J "\[The elicit-build-test paradigm for bootstrapping a morphological nalyzer.4.1 Morphological Analyzer ArchitectureWe adopt the general approach advocated by Karttunen (1994) and build the morpho-logical analyzer as the combination of several finite-state transducers, ome of whichare constructed irectly from the elicited information, and others of which are con-structed from the output of the machine learning stage.
Since the combination of thetransducers i computed at compile-time, there are no run-time overheads.
The ba-sic architecture of the morphological analyzer is depicted in Figure 2.
The analyzerconsists of the union of transducers, each of which implements the morphologicalanalysis process for one paradigm.
Each transducer is the composition of a number ofcomponents.
These components (from bottom to top) are described below:..The bottom component is an ordered sequence of morphographemicrules that are learned via transformation-based l arning from the sampleinflectional paradigms provided by the human informant.
These rules arethen composed into one finite-state transducer (Kaplan and Kay 1994).The citation form and affix lexicon contains the citation forms and theaffixes.
We currently assume that all affixation is concatenative and thatthe lexicon is described by a regular expression of the sort\[ Pref ixes  \]* \[ Citat ionForms \] \[ Suf f ixes \].77 We currently assume that we have at most one prefix and at most one suffix, but this is not afundamental limitation.
The elicitation of morphotactics foran agglutinating language like Turkish orFinnish requires a significantly more sophisticated licitation machinery.63Computational Linguistics Volume 27, Number 1Lemma+Morphological Features (e.g., happy+Adj+Super).
- - - ~ ZZ-_Z,Z,Z-,--22-7.--7.2--ZZZZZZZZZ--Z'2~ .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
7~2-=2=2-=2- :22: :2=:=:==-==:==:=:2=:=: :~- - .i J Feature Constraints Feature Constraints o ',I Surfacy-to-FeatureMapping 1OI Lexical & Surfacy Constraints IU 000 UOSurfacy-to-FeatureMapping ),, 0?
1' Lexical & Surfacy ConstraintsOI Morpheme-to-Surf icy-Feature 1 r Morpheme-to-Surfacy-FeatureMapping J Mapping JO onl 1 Citation Form and Affix Lexico itation Form and Affix LexiconO O\[,I Morphographemic Rules lJ !\[ Morphographemic Rules 11Paradigm 1 Paradigm n" ' '4  .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
I " *Surface Form (e.g., happiest)Figure 2General architecture of the morphological nalyzer....The morpheme to surfacy feature mapping essentially mapsmorphemes to feature names but retains some encoding of the surfacemorpheme.
Thus, al lomorphs that encode the same feature would bemapped to different surfacy features.The lexical and surfacy constraints pecify any conditions to constrainthe possibly overgenerating morphotactics of the citation form andmorpheme lexicons.
These constraints can be encoded using the citationforms and the surfacy features generated by the previous mapping.
Theuse of surfacy features also enables reference to zero morphemes, whichotherwise could not be used.
For instance, if in some paradigm a certainprefix does not co-occur with a certain suffix, or always occurs withsome other suffix, or if a certain citation form in that paradigm hasexceptional behavior with respect o one or more of the affixes, or if theaffixal aUomorph that goes with a certain citation form depends on theproperties of the citation form, these are encoded at this level asfinite-state constraints.The surfacy feature to feature mapping module maps the surfacyrepresentation f the affixes to symbolic feature names; as a result, nosurface information remains except for the citation form.
Thus, forinstance, al lomorphs that encode the same feature and map to differentsurfacy features now map to the same feature symbol.64Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers.
The feature constraints specify constraints among the symbolic features.They are different means of constraining morphotactics than the oneprovided by lexical and surfacy constraints.
At this level, one refers toand constrains symbolic morphosyntactic features as opposed to surfacyfeatures.
This may provide a more natural or convenient abstraction,especially for languages with long-distance morphotactic constraints.These six finite-state transducers are composed to yield a transducer for the paradigm.The union of the transducers for all paradigms produces one (possibly large) trans-ducer for morphological nalysis, where surface strings applied at the lower end pro-duce all possible analyses at the upper end.4.2 Information Elicited from Human InformantsThe Boas environment guides the language informant through a series of questionsleading up to paradigm delineation.
The informant indicates the parameters for whicha given part of speech inflects (e.g., Case, Number), the relevant values for those pa-rameters (e.g., Nominative, Accusative; Singular, Plural), and the licit combinationsof parameter values (e.g., Nominative Singular, Nominative Plural).
The informantthen posits any number of paradigms, whose members are expected to show sim-ilar patterns of inflection.
It is assumed that all citation forms that belong to thesame paradigm take essentially the same set of inflectional affixes (perhaps ubjectto morphophonological v riations).
It is expected that the citation forms and/or theaffixes may undergo systematic or idiosyncratic morphographemic changes.
It is alsoassumed that certain citation forms in a given paradigm may behave in some excep-tional way (for instance, contrary to all other citation forms, a given citation formmay not have one of the inflected forms.)
A paradigm description provides the fullinflectional pattern for one characteristic or distinguished citation form and additionalexamples for any other citation forms whose inflectional forms undergo nonstandardmorphographemic changes.
If necessary, any lexical and feature constraints can beencoded.
Currently the provisions we have for such constraints are limited to writingregular expressions (albeit at a much higher level than standard regular expressions);however, capturing such constraints using a more natural language (e.g., Ranta 1998)can be incorporated into future versions.4.3 Elicited Descriptive DataFigure 3 presents the encoding of the information elicited for one paradigm of a Polishmorphological nalyzer, which will be covered in detail ater, sThe data elicited using the user interface component of Boas is converted intoa description text file with various components delineated by SGML-like tags.
Thecomponents in the description are as follows:?
The <LANGUAGE-DESCRIPTION... >component lists information about helanguage and specifies its vowels and consonants, and other orthographicsymbols that do not fall into those two groups.?
A paradigm description starts with the tag <PARADIGM NAME=... >, whichlists the name of the paradigm, its part-of-speech ategory, and any8 Our actual system works using unicode character representation.
But unicode input and output are notyet supported in the XRCE xfst tool, hence we employ an ASCII external representation f r the unicodecharacters during off-line testing.
Inthe following examples, however, we have opted to represent theactual characters a they should appear on screen.65Computational Linguistics Volume 27, Number 1<LANGUAGE-DESCRIPTION TYPE = "morphology"NAME = "Polish"ALPHABET = "a~bcdde~fghijklhnnfio6pqrs~tuvwxyz~z"VOWELS = "age@io6uy"CONSONANTS= "bcddfghjkl~mnfipqrs~tvwxz~z"OTHER = ""><PARADIGM NAME="MasclnUStart"  POS = "Noun" FEATURES="Mascul ine"><PRIMARY-EXAMPLE><INF-GROUP><PRIMARY-CIT-FORM FORM = "telefon"><INF-FORM FORM = "telefon" FEATURE = "Nom.
Sg.
"><INF-FORM FORM = "tslefon" FEATURE ="Acc .
Sg.
"><INF-FORM FORM = "telefonach" FEATURE = "Loc.Pl .
"><INF-FORM FORM = "telefonami" FEATURE = "Instr .P l .
"></ INF-GROUP></PRIMARY-EXAMPLE ><EXAMPLE><INF-GROUP></INF-GROUP></EXAMPLE><LEXICON></LEXICON></PARADIGM><CIT-FORM FORM = "akcent"><INF-FORM FORM = "akcent" FEATURE = "Nom.
Sg.
"><INF-FORM FORM = "akcencie" FEATURE = "Loc.Sg.
"><CIT-FORM FORM = "stron"><CIT-FORM FORM = "klub"><CIT-FORM FORM = "sklep"></LANGUAGE-DESCRIPTION>Figure 3Sample paradigm description generated by Boas elicitation.additional morphosyntactic features that are common to all citationforms in this paradigm.
In the example in Figure 3, the paradigm is formasculine nouns.
Everything up to the </PARADIGM> tag is part of thedescriptive data for the paradigm.
This descriptive data consists of aprimary example, a series of zero or more additional examples, and thelexicon.The primary example is given between the <PRIMARY-EXAMPLE> and</PRIMARY-EXAMPLE> tags.
The description is given as a sequence of oneor more inflection groups between <INF-GROUP> and </INF-GROUP> tags.In some instances, a given lexical item can use different citation forms indifferent inflectional forms.
For example, one citation form might beused in the present tense and another in the past tense; or one might be66Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzersused with multisyllable affixes and another with single-syllable affixes.Thus, a given lexical item can have multiple citation forms, each ofwhich gets associated with a mutually exclusive subset of inflectionalforms.
All the citation forms for a given lexical item, plus all itsinflectional forms, are represented in an inflection group.
If theassociation of citation forms with inflectional forms is predictable (asindicated by the language informant), the subsets of inflectional formsare processed separately; if not, we assume that all citation forms can beused in all inflectional forms and hence overgenerate.
Manual constraintscan later be added, if necessary, to constrain this overgeneration.Additional examples are provided between <EXAMPLE> and </EXAMPLE>tags.
Examples contain ew citation forms plus any inflectional formsthat are not predictable based on the primary example.
Each example isconsidered an inflectional group and is enclosed within thecorresponding tags.The citation forms given in the primary example and any additionalexamples are considered to be a part of the citation form lexicon of theparadigm definition.
Any additional citation forms in this paradigm arelisted between the <LEXICON> and </LEXICON> tags.5.
Generating the Morphological AnalyzerThe morphological nalyzer is a finite-state transducer that is actually the union ofthe transducers for each paradigm definition in the description provided.
Thus, theelicited data is processed one paradigm at a time.
For each paradigm we proceed asfollows:...The elicited primary citation form and associated inflected forms areprocessed to find the "best" segmentation f the forms into stem andaffixes.
9Although we allow for inflectional forms to have both a prefixand a suffix (one of each), we expect only suffixation to be employed bythe inflecting languages with which we are dealing (Sproat 1992).Once the affixes are determined, we segment the inflected forms for theprimary example and any additional examples provided, and pair themwith the corresponding surface forms.
The segmented forms are nowbased on the citation form plus the affixes (not the stem).
The reason isthat we expect he morphological nalyzer to generate the citation formfor further access to lexical databases to be used in the applications.
Theresulting segmented form-surface form pairs make up the example baseof the paradigm.The citation forms given in the primary example, in additional examples,and explicitly in the lexicon definition of the elicited data, along with themapping from suffix strings to the corresponding morphosyntacticfeatures, are compiled (by our morphological nalyzer generatingsystem) into suitable regular expressions (expressed using the regular9 The stern is considered to be that part of the citation form onto which affixes are attached, and in ourcontext i has no function except for determining the affix strings.67Computational Linguistics Volume 27, Number 1..expression language of the XRCE finite-state tools \[Karttunen tal.1996\]).
l?The example base of the paradigm generated in step 2 is then used by alearning algorithm to generate a sequence of morphographemic rules(Kaplan and Kay 1994) that handle the morphographemic phenomena.The regular expressions for the lexicon in step 3 and the regularexpressions for the morphographemic rules induced in step 4 are thencompiled into finite-state transducers and combined by composition togenerate the finite-state morphological nalyzer for the paradigm.The resulting finite-state transducers for each paradigm are then unioned to givethe transducer for the complete set of paradigms.5.1 Determining Segmentation and AffixesThe suffixes and prefixes in a paradigm are determined by segmenting the inflectedforms provided for the primary example.
This process is complicated by the fact thatthe citation form may not correspond to the stem--it may contain a morphological in-dication that it is the citation form.
Furthermore, since the language informant providesonly a small number of examples, tatistically motivated approaches like the one sug-gested by Theron and Cleoete (1997) are not applicable.
We have experimented with anumber of approaches and have found that the following approach works quite well.Using the notion of description length (Rissanen 1989), we try to find a stem anda set of affixes that account for all the inflected forms of the primary example.
LetC = (cl, c2 .
.
.
.
.
ccl be the character string for the citation form in the primary example(ci are symbols in the alphabet of the language).
Let Sk = (cl, c2 .
.
.
.
.
Ckl, 1 < k <_ cbe a (string) prefix of C length k. We assume that the stem onto which morphologicalaffixes are attached is Sk for some k. 11 The set of inflectional forms given in the primaryJ J ,fill (f//are alphabet example are {F1, F2,..., El}, with each Fj = ~f~,f~ .
.
.
.
symbols in theof the language and lj is the length of the jth form).
The function ed(v,w) (ed foredit distance), where v and w are strings, measures the minimum number of symbolinsertions and deletions (but not substitutions) that can be applied to v to obtain w(Damerau 1964).
12 We definej=fd(Sk) = k + ~_~ ed(Sk, Fj)j=las a measure of the information eeded to account for all the inflected forms.
The firstterm above, k, is the length of the stem.
The second term, the summation, measureshow many symbols must be inserted and deleted to obtain the inflected form.
TheSk with the minimum d(Sk) is then chosen as the stem S. Creating segmentationsbased on stem S proceeds as follows: To determine the affixes in each inflected formFj = ~f~,f~ .
.
.
.
.
f/i/, we compute the projection of the stem Pj = ~f~ .
.
.
.
,f/el in Fj, as that10 Note that other finite state tools could also be used (e.g., Mohri, Pereira and Riley 1998; van Noord1999).11 The stem can also be an arbitrary substring of C, not just some initial prefix.
Our approach cancertainly extend to that.12 The function ed(...) assumes that vowels only align with other vowels or are elided, and consonantsonly align with consonants or are elided.68Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzerssubstring of Fj whose alignment with S provides the minimum edit distance, that is,P j = argmin ed ( S, ~f~ .
.
.
.
.
.
/d,>)(f~ ..... ,fd,>,l<_b'<e'<ljThen we select he substring ~f~ .
.
.
.
.
f~-l> of Fj (if it exists) as the prefix and ... ,J~} q~+l"(if it exists) as the suffix.
If there are multiple substrings of Fj that give the same(minimum) edit distance when aligned with S, we prefer the longer substring.
Wethen createf~_l + C + 9<~+1 .
.
.
.
.
.
.
.
.
.as an aligned segmented form-surface form pair and add it to the example base thatwe will use in the learning stage.
Note that we now use the citation form C, and notthe stem S, as a part of the segmented form.Thus, at the end of the process we generate pairs of inflected forms and theircorresponding segmented forms to be used in the derivation of the morphographemicrules.
These pairs come from both the inflected forms given in the primary exampleand from any additional examples given.For example, suppose we have the following primary example:<PRIMARY-EXAMPLE><INF-GROUP><PRIMARY-C IT -FORM FORM = "strona"><INF-FORM FORM = "strona" FEATURE = "Nom.
Sg.
"><INF-FORM FORM = "strong" FEATURE = "Acc.
Sg.
"><INF-FORM FORM = "strony" FEATURE = "Gen.
Sg.
"><INF-FORM FORM = "stronie" FEATURE = "Dat .Sg.
"><INF-FORM FORM = "stronie" FEATURE ="Loc .
Sg.
"><INF-FORM FORM = "strong" FEATURE =" Ins t r .
Sg.
"><INF-FORM FORM = "strony" FEATURE = "Nom.
P l .
"><INF-FORM FORM = "strony" FEATURE = "Acc .P I .
"><INF-FORM FORM = "stron" FEATURE = "Gen. P l .
"><INF-FORM FORM = "stronom" FEATURE = "Dat.
P l .
"><INF-FORM FORM = "stronach" FEATURE = "Loc.P l .
"><INF-FORM FORM = "stronami"  FEATURE = " Inst r .P l .
"></ INF-GROUP></PR IMARY-EXAMPLE>For this example, stems Sk: s, st, str, stro, stron, strona, are considered.
Table 1tabulates d(Sk) considering all the unique inflected forms above.
It can be seen thatthe value of d(Ss) is minimum for $5 = S = stron.
We then determine suffixes basedon this stem selection.
The suffixes are given in this table under k = 5, where the stemS = stron perfectly aligns with the initial substring stron in each inflected form Fj, with0 edit distance.The segmented form-surface form pairs in Table 2 are then generated from thealignment of the stem with each surface form.5.2 Learning Segmentation and Morphographemic RulesThe citation form and the affix information elicited and extracted by the process de-scribed above are used to construct regular expressions for the lexicon component69Computational Linguistics Volume 27, Number 1Table 1Stems Sk and the corresponding d(Sk).k=l  k=2Stems Considered, Skk=3 k=4 k=5 k=6Form Fj s st str stro stronstrona 5 4 3 2 1stron~ 5 4 3 2 1strony 5 4 3 2 1stronie 6 5 4 3 2stron G 5 4 3 2 1stron 4 3 2 1 0stronom 6 5 4 3 2stronach 7 6 5 4 3stronami 7 6 5 4 3Suffix-a-?-y-ie-om-ach-amistrona022321322d(Sk) 51 43 35 27 19Table 2The segmented and surface pair examples obtained.Segmented Surfacestrona+a stronastrona+~ stron~strona+y stronystrona+ie stroniestrona+ G stron Gstrona+ stronstrona+om stronomstrona+ach stronachstrona+ami stronamiof each paradigm.
13The example segmentations are fed into the learning module toinduce morphographemic rules.5.2.1 Generat ing Candidate Rules f rom Examples.
The preprocessing stage yieldsa list of pairs of segmented lexical forms and surface forms.
The segmented formscontain the citation forms and affixes; the affix boundaries are marked by the + symbol.This list is then processed by a transformation-based l arning paradigm (Brill 1995;Satta and Henderson 1997), as illustrated in Figure 4.
The basic idea is that we considerthe list of segmented words as our input and find transformation rules (expressed ascontextual rewrite rules) to incrementally transform this list into the list of surfaceforms.
The transformation we choose at every iteration is the one that makes the listof segmented forms closest o the list of surface forms.The first step in the learning process is an initial alignment of pairs using a stan-dard dynamic programming scheme.
The only constraints in the alignment are: (i) a +in the segmented lexical form is always aligned with an empty string on the surfaceside, notated by 0; (ii) a consonant on one side is always aligned with a consonant or0 on the other side, and likewise for vowels; (iii) the alignment must correspond to13 The result of this process i a script for the XRCE finite-state ool xfst.
Large-scale l xicons can be moreefficiently compiled by the XRCE tool lexc.
We currently do not generate l xc scripts, but it is trivial todo so.70Oflazer, Nirenburg, and McShane Bootstrapping Morphological AnalyzersSegmentedFormsIFigure 4l(incrementally)transformedsegmentedformsLearnerSurface forms(Truth)Transformation-based learning of morphographemic rules.the minimum edit distance between the original lexical and surface forms.
14 From thispoint on, we will use a simple example from English to clarify our points.Assume that we have the pairs (un+happy+est, unhappiest)  and (shop+ed,shopped) in our example base.
We align these and determine the total number of"errors" in the segmented forms that we have to fix to make all segmented formsmatch the corresponding surface forms.
The initial alignment produces the alignedpairs:un + happy + est shopO+ edun 0 happi 0 est shopp 0 edwith a total of five errors.
From each segmented pair we generate rewrite rules of thesort isu -> i \[\] Le f tContext ,  RightContext ;where u(pper) is a symbol in the segmented form, l(ower) is a symbol in the surfaceform.
Rules are generated only from those aligned symbol pairs that are different.Lef tContext  and RightContext are simple regular expressions describing contextsin the segmented side (up to some small length), also taking into account he wordboundaries.
For instance, from the first aligned-pair example, this procedure wouldgenerate rules such as the following (depending on the amount of left and right contextallowed):y -> iy -> iy -> i+ -> 0+ -> 0+ -> 0+ -> 0p_  y->ip_+es  y -> ip_  + e s t # y -> i# U ne s test# .
.est# Ppy  -+ -> 0p_+ep_+estp p_+e#un _ hap14 We arbitrarily choose one if there are multiple legitimate alignments.15 We use the XRCE finite-state ools regular expression syntax (Karttunen et al 1996).
For the sake ofreadability, we will ignore the escape symbol (%) that should precede any special characters (e.g., ?
)used in these rules.71Computational Linguistics Volume 27, Number 1The # symbol denotes a word boundary and is intended to capture any word-initialand word-final phenomena.
The segmentation rules (+ -> 0) require at least someminimal eft or right context (usually longer than the minimal context for other rulesin order to produce more accurate segmentation decisions).
We disallow contexts thatconsist only of a morpheme boundary, as such contexts are usually not informative.It should be noted that these rules transform a segmented form into a surface form(contrary to what may be expected for analysis).
This lets us capture situations wheremultiple segmented forms map to the same surface form, which occurs when thelanguage has morphological mbiguity.
Thus, in a reverse lookup, a given surfaceform may be interpreted in multiple ways, if applicable.Since we have many examples of aligned pairs in our example base, it is likely thata given rule will be generated from many pairs.
For instance, if the pairs (stop+ed,stopped) and (tr ip+ed, tr ipped) were also in the list, the gemination rule 0 -> pI I p - + e d (along with certain others) will also be generated from these examples.We count how many times a rule is generated and associate this number with the ruleas its promise, meaning that it promises to fix this many "errors" if it is selected toapply to the current list of segmented forms.5.2.2 Genera l i z ing  Ru les .
The candidate rules generated by the processes describedabove refer to specific strings of symbols as left and right contexts.
It is, however,possible to obtain more generalized rules by classifying the symbols in the alphabetinto phonologically relevant groups, like vowels and consonants.
The benefit of thisapproach is that the number of rules thus induced is typically smaller, and moreunseen cases can be covered.For instance, in addition to a rule like 0 -> p I I p - + e,  the rules0 -> p0 -> pCONSONANTS _p _ + VOWELS+ e0 -> p CONSONANTS _ + VOWELScan be generated, where symbols such as CONSONANTS and VOWELS stand for regu-lar expressions denoting the union of relevant symbols in the alphabet.
The promisescores of the generalized rules are found by adding the promise scores of the origi-nal rules generating them.
Generalization substantially increases the number of can-didate rules to be considered during each iteration, but this is not a very seriousissue, as the number of examples per paradigm is expected to be quite small.
Therules thus learned would be the most general set of rules that do not conflict withthe evidence in the examples.
It is possible to use a more refined set of classes thatcorrespond to subclasses of vowels (e.g., high vowels) and consonants (e.g., frica-tives) but these will substantially increase the number of candidate rules at everyiteration and will have an impact on the iteration time unless examples are chosencarefully.5.2.3 Selecting Rules.
At each iteration, all the rules along with their promise scoresare generated from the current state of the example pairs.
The rules generated are thenranked based on their promise scores, with the top rule having the highest promise.Among rules with the same promise score, we rank more general rules higher, withgenerality being based on context subsumption (i.e., preference goes to rules usingshorter contexts and/or referring to classes of symbols, like vowels or consonants).All segmentation rules go to the bottom of the list, though within this group, rulesare still ranked based on decreasing promise and context generality.
The reasoning72Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzersfor treating the segmentation rules separately and later in the process is that affixa-tion boundaries constitute contexts for all morphographemic  changes; therefore theyshould not be eliminated if there are any (more) morphographemic  phenomena toprocess.Starting with the top-ranked rule, we test each rule on the segmented compo-nent of the pairs.
A finite-state ngine emulates the replace rules to see how muchthe segmented forms are "fixed."
The first rule that fixes as many "errors" as itpromises to fix, and does not generate an interim example base with generationambiguity, is selected.
16 The issue of generation ambiguity refers to cases where thesame segmented forms are paired with distinct surface forms.
17 In such cases, find-ing a rule that fixes both pairs is not possible, so in choosing rules, we avoid anyrules whose tentative application generates an interim example base with such am-biguities.
In this way, we can account for all the discrepancies between the sur-face and segmented forms without falling into a local minima.
Although we do nothave formal proof that this simple heuristic avoids such local minima situations, inour experimentation with a large number  of cases we have never seen such an in-stance.The complete procedure for rule learning can now be given as follows:- Align surface and segmented forms in the example base;- Compute total Error;- while(Error > O) {-Generate all possible rewrite rules subject to context size limits;-Rank Rules ;-whi le  ( there  are more ru les  and a ru le  has not yet  been se lec ted)  {- Tentatively apply the next rule to all the segmented forms;- Re-align the resulting segmented forms with thecorresponding surface forms to see how many''errors'' have been fixed;- If the number of errors fixed is equal to what the rulepromised to fix AND the result does not have generationambiguity, select this rule;}-Commit the changes performed by the rule on the segmented formsto the example base;-Reduce Error by the promise score of the selected rule;This procedure ventually generates an ordered sequence of two ordered groupsof rewrite rules.
The first group of rules is for any morphographemic  phenomenain the given set of examples, and the second group of rules handles segmentation.All these rules are composed in the order in which they are generated to constructthe Morphographemic Rules transducer at the bottom of each parad igm (see Fig-ure 2).16 Note that a rule may actually introduce unintended errors in other pairs, since context checking isdone only on the segmented form side; therefore what a rule delivers may be different than what itpromises, as promise scores also depend on the surface side.17 Consider a state of the example base where some segmented lexical form L is paired with differentsurface forms $1 and $2, that is, we have pairs (L, $1) and (L, $2) in our example base.
Any rule thatwill bring L closer to $1 will also change L of the second pair and potentially make it impossible tobring it closer to $2.73Computational Linguistics Volume 27, Number 15.3 Identifying Errors and Providing FeedbackOnce the Morphographemic Rules transducers are compiled and composed with thelexicon transducer that is generated automatically from the elicited information, weobtain an analyzer for the paradigm.
The analyzer for the paradigm can be tested byusing the xfst environment of the XRCE finite-state tools.
This environment providesmachinery for testing the output of the analyzer by generating all forms involvinga specific citation form, a specific morphosyntactic feature, or the like.
This kind oftesting has proved quite sufficient for our purposes.When the full analyzer is generated by unioning all the analyzers for each para-digm, one can do a more comprehensive t st against a test corpus to see what surfaceforms in the test corpus are not recognized by the generated analyzer.
Apart fromrevealing obvious deficiencies in coverage (e.g., missing citation forms in the lexicon),such testing provides feedback about minor human errors--the failure to cover cer-tain morphographemic phenomena, or the incorrect assignment of citation forms toparadigms, for example.Our approach is as follows: we use the resulting morphological analyzer with anerror-tolerant finite-state recognizer engine (Oflazer 1996).
Using this engine, we try tofind words recognized by the analyzer that are (very) close to a rejected (correct) wordin the test corpus, essentially performing a reverse spelling correction.
If the rejectionis due to a small number of errors (1 or 2), the erroneous words recognized by therecognizer are aligned with the corresponding correct words from the test corpus.These aligned pairs can then be analyzed to see what the problems may be.5.4 Applicability to Infixing, Circumfixing, and Agglutinating LanguagesThe machine learning procedure for inducing rewrite rules is not language dependent.It is applicable to any language whose lexical representation is a concatenation offree and bound morphemes (or portions thereof).
All this stage requires is a set ofpairs of lexical and surface representations of the examples compiled for the examplebase.We have tested the rule learning component above on several other languages in-cluding Turkish, an agglutinating language, using an example base with lexical formsproduced by a variant of the two-level morphology-based finite-state morphologicalanalyzer described in Oflazer (1994).
The lexical representation for Turkish also in-volved meta symbols (such as H for high vowels, D for dentals, etc.
), which wouldbe resolved with the appropriate surface symbol by the rules learned.
For instance,vowel harmony rules would learn to resolve H as one of ~, i ,  u, ii in the appropriatecontext.Furthermore, the version of the rule learning (sub)system used for Turkish alsomade use of context-bound morphophonological distinctions that are not elicited inBoas, such as high vowels, low unrounded vowels, dentals, etc.
The rules generatedwere the most general set of rules that did not conflict with the example base.
Therewere many examples in the example base that involved multiple suffixes, not justone, as in the inflecting languages we address in this paper.
It was quite satisfyingto observe that the system could learn rules for dealing with vowel harmony, de-voicing, and so on.
A caveat is that if there were too many examples and too manymorphophonological classes, the number of candidate rules to be tried increased ex-ponentially.
This could be alleviated to a certain extent by a careful selection of theexample base.Thus, the rule-learning component is applicable to agglutinative, and also to in-fixing and circumfixing languages, provided there is a proper representation of thelexical and surface forms.
However, for infixing languages it could be very problem-74Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzersatic to have a linear representation f the infixation, with the lexical root being splitin two and the morphotactics picking up the first part, the infix, and the second part.To prevent overgeneration, the infix lexicon might have to be replicated for each root,to enforce the fact that the two parts of the stem go together.
18The case for circumfix-ation is simpler since the number of such morphemes i  assumed to be much smallerthan the number of stems, so the circumfixing morphemes can be split up into twolexicons and treated as a prefix-suffix combination.
The co-occurrence r strictions forthe respective pairs can then be manually enforced with finite-state constraints thatcan be added to the lexical and surfacy constraints section of the analyzer (see Fig-ure 2).Thus, in all three cases, learning the rules is not a problem provided the examplebase is in the requisite linear representation.
On the other hand, this approach as suchis inapplicable to languages like Arabic, which have radically different word formationprocesses (for which a number of other finite-state approaches have been proposed;(see, for example, Beesley \[1996\] and Kiraz \[2000\]).On the other hand, in contrast o acquiring the rewrite rules, eliciting the mor-photactics and the affix lexicons for an agglutinating language (semi)automaticallyis a very different process and is yet to be addressed.
There are three parts to thisproblem:.2.3.Determining the boundaries of free and bound morphemes, accountingfor any morphographemic variations;Determining the order of morphemes;Determining the "semantics" of the morphemes, that is, the features theyencode.These are complicated by a number of additional issues uch as zero morphemes, localand long-distance o-occurrence r strictions (e.g., for allomorph selection), exceptions,productive derivations, circular derivations, and morphemes with the same surfaceforms but a totally different morphotactic position and function.
Also, in languagesthat have a phenomenon like vowel harmony, such as Turkish, even if all harmonicallomorphs of a certain suffix are somehow automatically grouped into a lexicon with-out any further abstraction, severe overgeneration would result, unless the all root andsuffix lexicons were split or replicated along vowel lines.
In such cases, a human in-formant (who possesses a certain familiarity with morphographemics and issues ofovergeneration) may have to resort o manual abstraction of the morpheme represen-tations.
Then the process of acquiring the features for inflectional and derivationalmorphemes could proceed.6.
Bootstrapping a Polish AnalyzerThis section presents a quite extensive xample of bootstrapping a morphological n-alyzer for Polish by iteratively providing examples and testing the morphological n-alyzer systematically.
The idea of this exercise was to have a relatively limited numberof paradigms that bunched words showing slight inflectional variations.
19For reasons18 This is much like what one encounters when dealing with reduplication in the FS framework.
Alsonote that his is a lexicon issue and not a rule issue.19 Nonexpert language informants u ing Boas will be encouraged to split, rather than bunch, paradigms,for the sake of simplicity.75Computational Linguistics Volume 27, Number 1of space, the exposition is limited to developing four paradigms, of which one will becovered in detail.
The paradigms here cover only a subset of masculine norms, anddo not treat feminine or neuter nouns at all; however, they cover all the problems thatwould be found in words of those genders.For purposes of testing the learner off-line (i.e., outside the Boas environment), wetried to keep to a minimum the number of inflected forms given for each additionalcitation form.
This was a learner-oriented task and intended to determine how robustthe learner could become with a minimum of input.
When using the Boas interface, thelanguage informant will not have the option of selectively providing inflected forms.The interface works as follows: the informant gives all forms of the primary exampleand lists other citation forms that he or she thinks belong to the given paradigm.
Hav-ing learned rules from the primary example, the learner generates all the inflectionalforms for each citation form provided.
The informant hen corrects all mistakes andthe learner elearns the rules.
So, the informant never has the opportunity to say "Well,I know the learner can't predict the locative singular for this word, so I will supplyit overtly from the outset."
The informant will just have to wait for the learner to getthe given forms wrong and then correct hem.
Any other approach would make fora complex interface and would require a sophisticated language informant--not whatwe are expecting.Polish is a highly inflectional West Slavic language that is written using extendedLatin characters (six consonants and three vowels have diacritics).
Certain phonemesare written using combinations of letters: e.g., sz, cz, and szcz represent phonetic ~,G and ~,  respectively.
R?
Polish nominals inflect for seven cases: Nominative (Nom.
),Accusative (Acc.
), Genitive (Gen.), Dative (Dat.
), Locative (Loc.
), Instrumental (Instr.
),and Vocative (Voc.
); and two numbers: Singular (Sg.)
and Plural (P1.).
21 The complex-ity of Polish declension derives from four sources: (i) certain stem-final consonantsmutate during inflection; these are called "alternating" consonants, and are contrastedwith so-called "nonalternating" consonants (alternating/nonalternating is a crucialdiagnostic for paradigm delineation in Polish); (ii) certain letters are spelled differ-ently depending on whether they are word-final or word-internal (e.g., word-final-d is written -si when followed by a vocalic ending); (iii) final-syllable vowels areadded/deleted in some (not entirely predictable) words; and (iv) declension is notentirely phonologically driven--semantics and idiosyncrasy affect inflectional end-ings.The following practical simplifications have been made for testing purposes:Words that are normally capitalized (like names) are not capitalized here.Some inflectional form(s) that might not be semantically valid (e.g.,plurals for collectives) were disregarded.
Thus a bit of overgenerationstill remains but can be removed with some additional effort.6.1 Paradigm 1The process starts with the description of Paradigm 1, which describes alternatinginanimate masculine nouns with genitive singular in -u and no vowel shifts.
The20 We actually treat hese as single symbols during learning.
Such symbols are indicated in thedescription file in a special section that we have omitted in Figure 3.21 The Vocative case was not included in these tests because it is not expected tooccur widely in thejournalistic prose for which the system is being built.76Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzersfollowing pr imary example for theCaseNom.Acc.Gen.Dat.Loc.Instr.citation form telefon is given in full:NumberSingular Pluraltelefon telefonytelefon telefonytelefonu telefon6wtelefonowi telefonomtelefonie telefonachtelefonem telefonamiAll inflectional forms in this paradigm are trivial except:?
The Loc.Sg.
depends on the final consonant and induces orthographicalternations for some alternating consonants: 22Final Consonant(s)b, p, f, w, m, n, s, zt, d, st, zmLr, stg, k, chLoc.Sg.
Ending-ie- ie-e-uConsonant Alternationst-,c, d--,dz, st--+gc, zm--*;~mf~l, r--*rz, sl--*gl?
Instr.Sg.
and Nom.P1.
depend on the final consonant; two velars have anidiosyncratic ending:Final Consonant(s)b, p, f, w, m, n, s, zt, d, st zm, L r, st, chg,kInstr.Sg.Ending-em- iemNom.P1.Ending-y-iThe following examples were provided in addition to the inflectional forms of thepr imary example in order to show Loc.Sg.
endings and accompanying consonant al-ternations that could not be predicted based on the pr imary example:1. t~c: akcent (Nom.Sg.
), akcencie (Loc.Sg.)2.
d --* dz: wyktad (Nom.Sg.
), wyktadzie (Loc.Sg.)3.
st ---~dc: most (Nom.Sg.
), modcie (Loc.Sg.)4.
zm---~m: komunizm (Nom.Sg.
), komuni~mie (Loc.Sg.)5.
t-*l: artykut (Nom.Sg.
), artykule (Loc.Sg.)6.
r--*rz: teatr (Nom.Sg.
), teatrze (Loc.Sg.)7.
st~sl: pomyst (Nom.Sg.
), pomydle (Loc.Sg.
)The following additional examples were provided to show velar pecularities:8. g: pociqg (Nom.Sg.
), pociqgu (Loc.Sg.
), pociqgiem (Instr.Sg.
), pociqgi (Nom.Pl.
)22 Strictly speaking, the consonants b,p,f, w, m, n, s, and z alternate as well in the Loc.Sg., sincealternating/nonalternating is a phonological distinction, ot a graphotactic one.
The softening of theseconsonants i  indicated by the -i that precedes the canonical Loc.Sg.
ending -e. However, for ourpurposes it is more straightforward toconsider the Loc.Sg.
ending for these consonants -ie with noaccompanying graphotactic alternation.77Computational Linguistics Volume 27, Number 1Table 3Summary of runs for Paradigm 1.Citation Additional Run 1 Additional Run 2 Additional Run 3Key Forms Examples Results Examples Results Examples Results0 telefon, stron, x/paragraf,~piew, sklep,ttum, adres,obraz1 akcent, bilet Nom.Sg.
mutates all Nom.P1.
mutates Instr.Sg.
x/Loc.Sg.
oblique forms lnstr.Sg.2 wyklad, sad Nom.Sg.
mutates all Nom.P1.
mutates Instr.Sg.
x/Loc.Sg.
oblique forms Instr.Sg.3 most, list Nom.Sg.
mutates all Nom.P1.
mutates Instr.Sg.
V'Loc.Sg.
oblique forms Instr.Sg.4 komunizm, Nom.Sg.
mutates all Nom.P1.
mutates Instr.Sg.
~/socjalizm Loc.Sg.
oblique forms Instr.Sg.5 artykut, Nom.Sg.
mutates all Nora.P1.
mutates Instr.Sg.
x/kawat Loc.Sg.
oblique forms Instr.Sg.6 teatr, numer Nom.Sg.
mutates all Nom.P1.
mutates Instr.Sg.
x/Loc.Sg.
oblique forms Instr.Sg.7 pomysl, Nom.Sg.
mutates all Nom.P1.
mutates Instr.Sg.
x/zmyst Loc.Sg.
oblique forms Instr.Sg.8 poci~g, brzeg Nom.Sg.
x/Loc.Sg.Instr.Sg.Nora.P1.9 bank, krok Nom.Sg.
missed velar- Loc.Sg.
of v /krok;Loc.Sg.
specific Loc.Sg.
; Add btysk toInstr.Sg.
gave *krokie lexicon forNom.P1.
not kroku testing10 dach, wirch Nom.Sg.
missed velar- Loc.Sg.
of wrong add v /wirch;specific Loc.Sg.
; Add ~miech Instr.Sg.
Instr.Sg.gave *wirchie to lexicon for wirch, ofnot wirchu for testing ~miech wirchLoc.Sg..10.k: bank (Nom.Sg.
), banku (Loc.Sg.
), bankiem (Instr.Sg.
), banki (Nom.Pl.
)ch: dach (Nom.Sg.
), dachu (Loc.Sg.
)Table 3 summarizes the first three runs for this paradigm, which were sufficient ocreate a relatively robust set of morphological rules that required only slight amend-ment and further testing in two additional runs.
For this and subsequent such tableswe use the following conventions: Key 0 shows the primary citation form and addi-tional citation forms whose inflectional patterns hould be fully covered by the rulesgenerated for the primary example.
The other key numbers correspond to the addi-tional examples given above.
Boldface citation forms under the lexicon column arethose for which some additional inflectional examples were given.
The citation formsgiven in plain text are for testing purposes.
Oblique cases refer to the Genitive, Dative,Locative, and Instrumental cases.The original assumption for Paradigm 1 was that it would be sufficient o pro-vide one unmutated form (the Nom.Sg.)
plus the mutated form (the Loc.Sg.)
for wordsending in mutating consonants.
This led to overgeneralization of the alternation; there-78Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzersfore, another unmutated form had to be added as a "control."
Adding the Nom.P1.forms fixed most oblique forms for all the words, but it left the Instr.Sg.
mutated.This appears to be because the inflectional ending for the Loc.Sg.
(which mutates) andthe Instr.Sg.
(which does not) both begin in -e for the words in question.
Adding theInstr.Sg.
overtly counters overgeneralization of the alternation.
The source of the velarerrors is not immediately evident.Supplementary testing was carried out after the above-mentioned words were allcorrect.
Correct forms were produced for all new words showing consonant mutationsand velar peculiarities: amolot, przyklad, pretekst, podziaL kolor, dtug, lek, gmach.
One errorfor a nonmutating word (in Key 0) occurred.
This word, herb, ends in a differentconsonant than the primary example and produced the wrong Loc.Sg.
form.
This waslater added overtly and more words with other nonmutating consonants (postcp, puf,gniew, film, opis, raz) were tested; all were covered correctly.6.2 Paradigm 2The paradigm implemented next was Paradigm 2: alternating inanimate masculinenouns with genitive singular in -u and vowel shifts.
The following primary examplefor the citation form gr6b was given in full:CaseNom.Acc.Gen.Dat.Loc.Instr.NumberSingular Pluralgr6b grobygr6b grobygrobu grob6wgrobowi grobomgrobie grobachgrobem grobamiThis paradigm is just like Paradigm 1, except hat there are vowel shifts that arenot entirely graphotactically predictable; therefore, words showing these shifts must beclassed separately.
The vowel shifts occur in all inflectional forms except he Nom.Sg.and the Acc.Sg., which are identical.
The following vowel shifts occurred in the caseswe considered (~b indicates vowel deletion).Vowel in Vowel inNom.Sg./Acc.Sg.
Other Forms6 oeie ~ba e ~This shift only occurs in Loc.Sg.The following consonant alternations are also observed in this paradigm:Consonant inMost FormsddztrConsonant inLoc.Sg.dz~dz1r zBased on the experience of Paradigm 1, the Instr.Sg.
forms for all words withconsonant alternation were provided as examples at the outset o avoid the overgen-eralization of the alternation.
The velar pecularities are still in effect and must be dealtwith explicitly.79Computational Linguistics Volume 27, Number 1The following examples were given to exemplify vowel shifts with an unmutatingconsonant:1. e --* q~ shift with n: sen(Nom.Sg.
), snie (Loc.Sg.
)The following examples were employed to show vowel shifts in combination withvarious consonant alternations in the Loc.Sg.
forms:..,5.6.d ~ o and d --* dz: samoch6d (Nom.Sg.
), samochodzie (Loc.Sg.
), samochodem(Instr.Sg.
)a --~ e and zd ~ ~dz: dojazd (Nom.Sg.
), doje~dzie (Loc.Sg.
), dojazdem(Instr.Sg.
)d --+ o and t --* h st6t (Nom.Sg.
), stole (Loc.Sg.
), stotem (Instr.Sg.
)e -* ~ and r --~ rz: puder (Nom.Sg.
), pudrze (Loc.Sg.
), pudrem (Instr.Sg.
)ie --~ ~ and r ~ rz: cukier (Nom.Sg.
), cukrze (Loc.Sg.
), cukrem (Instr.Sg.
)Finally, the following examples were given to show velar peculiarities:..e --, ~ with k: budynek (Nom.Sg.
), budynku (Loc.Sg.
), budynkiem (Instr.Sg.
),budynki (Nom.P1.
)d --* 0 with g: r6g (Nom.Sg.
), rogu (Loc.Sg.
), rogiem (Instr.Sg.
), rogi(Nom.P1.
)At the end of first run for this paradigm only one of the eight groups abovewas covered completely.
All vowel shifts for all groups came out right.
However, theNom.P1.
and Acc.P1.
endings were incorrectly generalized as -i instead of -y, probablybecause two "exceptional" velar examples (in -i) were provided in contrast o one"regular" nonvelar example (in -y).
Adding the Nom.P1.
forms of three nonvelar wordsfixed this error.
The results for velars were perfect except for the loss of z in 10 of 12forms of obowiqzek.
Adding the Nom.P1.
form obowi~zki f xed this.
For st6t and d6t, theconsonant alternation was incorrectly extended to Gen.Sg.
Adding the Gen.Sg.
formof st6t fixed this error for both words.
At the end of the second run, all groups werecorrectly learned.Supplementary testing after the above-mentioned words were correct included thewords naw6z, doch6d, poz6r, rozbi6r, gr6d, rozch6d, nar6d, wtorek, kierunek; all forms werecorrect.6.3 Parad igm 3Paradigm 3 contains alternating "man" nouns--that is, masculine nouns referring tohuman men.
The following primary example for the citation form pasierb was givenin full:CaseNom.acc.Gen.Dat.Loc.InstENumberSingularpasierbpasierbapasierbapasierbowipasierbiepasierbemPluralpasierbowiepasierbipasierb6wpasierb6wpasierbompasierbachpasierbami80Oflazer, Nirenburg, and McShane Bootstrapping Morphological AnalyzersIn this paradigm, all of the consonant alternations encountered above are still ineffect and some word-final consonants undergo additional alternations in the Nom.P1.The velar peculiarities remain in effect.
One additional complication i this paradigmis that there may be multiple Nom.P1.
forms for a given citation form (e.g., pasierbowieand pasierbi are both acceptable Nora.P1.
forms for pasierb).
Furthermore, -i/-y are allo-morphs in complementary distribution (i.e., the second Nom.P1.
form in this paradigmis realized with -y for certain word-final consonants).Stem-FinalConsonantb, f, w, m, n, z, tp, chd,tr,k,gNom.P1.Ending-owie or -i or both-i only-owie only-owie or -y or bothSince the analyzer needs only to analyze (and not generate) forms, there is no needto split this paradigm into five different ones to account for each Nom.P1.
possibility:-owie,-owie/-i,-i, -owie/-y, -y.
We simply permit overgeneration, allowing each word tohave two Nom.P1.
forms: the correct one of the -i/-y allomorphs and -owie.
Further,since the analyzer has no way to predict which of the -i/-y allomorphs i used with agiven word-final consonant, explicit examples of each word-final consonant must beprovided.These considerations lead to splitting the citation forms for this paradigm into14 groups, which represent the primary example plus 13 inflectional groups addedas supplementary examples.
The Nom.Sg., Loc.Sg., and both (or applicable) Nom.P1.forms were provided for all groups apart from the primary example.
After the firstrun, 13 of 14 groups were correctly covered.
The remaining roup was handled cor-rectly in two additional runs: two more inflectional forms of the example in word-finalr had to be provided to counter overgeneralization of the r --* rz alternation.Supplementary testing after the above-mentioned words were correct includedthe citation forms drab, piastun, kasztelan, faraon, w6jt, mnich, biedak, norweg, wtoch.
Thefollowing errors were encountered:norweg got the Acc.Sg./Gen.Sg.
form *norweda instead of norwega.Adding the correct Acc.Sg.
form fixed this problem.wtoch got the Nom.P1.
form *wtoci instead of wtosi.
This form was addedovertly.mnich got the Nom.P1.
form *mnici instead of mnisi.
This form was addedovertly.After these final additions, wtoch and mnich ended up with the Acc.Sg./Gen.Sg.forms *wtosa and *mnisa instead of wtocha and mnicha (i.e., the alternation was overgen-eralized again).
Overtly adding the correct Acc.Sg.
form wtocha solved this problemfor both words and all forms were now correct.6.4 Paradigm 4Paradigm 4 was for nonalternating inanimate masculine nouns with genitive singularin -a and no vowel shifts.
The following declension for bicz was provided as the81Computational Linguistics Volume 27, Number 1primary example:CaseNom.Acc.Gen.Dat.Loc.Instr.NumberSingular Pluralbicz biczebicz biczebicza biczybiczowi biczombiczu biczachbiczem biczamiA spelling rule of Polish comes into play in this paradigm: letters that take adiacritic word-finally or when followed by a consonant are spelled with no diacriticplus an -i when followed by a vowel.
For instance: ~+u --* niu, ~+owi --* niowi, d+u --*ciu, d+owi --+ ciowi.
Some, but not all, word-final letters in this paradigm have diacritics.In addition, in this paradigm, Gen.Sg.
endings depend on the final consonant: theycan be -6w (for j, ch, szcz), -i (for L ~, ~) or -y (for cz, sz, rz, ~).
In many instances, morethan one form is possible, but this test covers only the most common form for eachstem-final consonant.The citation forms in this paradigm broke down into 10 groups based on the finalconsonant.
The Nom.Sg., Gen.Pl., and Instr.P1.
forms were provided for the 9 groups(the tenth is the primary example, for which all forms were provided).
Eight of the10 groups were handled correctly after the first run.
The spelling-rule related to -irequired some extra forms to be learned correctly.
Otherwise, everything came out aspredicted.
Supplementary testing included the citation forms klawisz, b~bel, strumie~,tach, cyrkularz; all inflectional forms were produced correctly.7.
Performance IssuesGenerating a morphological nalyzer once the descriptive data is given can be carriedout very fast.
Each paradigm can be processed within tens of seconds on a fast work-station, including the few tens of iterations of rule learning from the examples.
A newversion of the analyzer can be generated within minutes and tested rapidly on any testdata.
Thus, none of the processes described in this paper constitutes a bottleneck in theelicitation process.
Figure 5 provides ome relevant information from the runs of thefirst paradigm in Polish described above.
The top graph shows, for different runs, thenumber of distinct rules generated from the aligned segmented form--surface-formpairs generated from the examples provided, using a rule format with at most fivesymbols in each of the left and right contexts.
The bottom graph shows, for differ-ent runs, the total number of rules generated and generalized--again, with the samecontext size as above.There are a few interesting things about these graphs.
As expected, when moreexamples are added, the number of rules and the number of iterations needed forconvergence usually increases.
All curves have a steeper initial segment and a steeperfinal segment.
The steep initial segments result from the initial selection of rules thatfix the largest number of "errors" between the segmented and surface forms.
Oncethose rules are found, the curves flatten as a number of morphographemic rules areselected, each dealing with a very small number of errors.
Finally, when all the mor-phographemic changes are accounted for, the segmentation rules kick in and each suchrule fixes a large number of segmentation "errors," so that a few general rules dealwith all such cases.82Oflazer, Nirenburg, and McShane Bootstrapping Morphological AnalyzersRules generated in each i te ra t ion  o f  the learner i n  sequent ia l  runs- - - ?
- - -Run  1- - - I I - - -Run  2& Run 31000 ?900  ?800  ?700600500 ?=-5400  ?300  ?2001000\?
\?
, L" ' ?
,  " I L" ?
- - .
?
,  l i -  ~ ~ll- ~.
iB.
i .~-- -e* - .~?
.
.
?  "
i t -  ~ ~il-- ~ .
i .
~ .
i -;'.-,, .1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  23Learning i terationRules general ized in each i te ra t ion  o f  the learner i n  sequent ia l  runs- - -e - - -Run  1- - -m- - -Run  2A Run 320000,18000,16000,14000,~ 12000,mlO000,8000,6000,4000,2000,0~ #1-.
- +an- :--+HI- --+l+.,..
- ~ _ .
.
0~ -i-.
~ -il~,.~, L" '~- - - t - .
~-ap ."
' t - .
.e .
~'i l- ~ L1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  21 22 23Learning IterationFigure 5Rule statistics for processing Paradigm 1.8.
Summary  and Conc lus ionsWe have presented the highlights of our approach for automatically generating finite-state morphological nalyzers from information elicited from human informants.
Ourapproach uses transformation-based learning to induce morphographemic rules fromexamples and combines these rules with the lexicon information elicited to compilethe morphological nalyzer.
There are other opportunities for using machine learningin this process.
For instance, one of the important issues in wholesale acquisition of83Computational Linguistics Volume 27, Number 1open-class items is that of determining which paradigm a given citation form belongsto.
From the examples given during the acquisition phase, it is possible to induce aclassifier that can perform this selection to aid the language informant.We believe that we have presented a viable approach to the automatic generationof a natural language processor.
Since this approach involves a human informantworking in an elicit-generate-test loop, the noise and opaqueness of other inductionschemes can be avoided.We also feel that the task of analyzing a set of incorrectly generated forms andautomatically offering a diagnosis of what may have gone wrong and what additionalexamples can be supplied as remedies is, in itself, an important aspect of this work.Although we have only scratched the surface of this topic here, we consider it a fruitfulextension of the work described in this paper.AcknowledgmentsThis research was supported in part byContract MDA904-97-C-3976 from the U.S.Department of Defense.
We also thankXRCE for providing the finite-state tools.Most of this work was done while the firstauthor was visiting NMSU ComputingResearch Laboratory during the 1998-1999academic year, on leave from BilkentUniversity, Ankara, Turkey.ReferencesAntworth, Evan L. 1990.
PC-KIMMO: Atwo-level processor for Morphological Analysis.Occasional Publications in AcademicComputing, Number 16.
SummerInstitute of Linguistics, Dallas, TX.Beesley, Kenneth R. 1996.
Arabic finite-statemorphological nalysis and generation.
InProceedings ofthe 16th InternationalConference on Computational Linguistics(COLING'96), pages 89-94, Copenhagen,Denmark.Brill, Eric.
1995.
Transformation-basederror-driven learning and naturallanguage processing: A case study inpart-of-speech tagging.
ComputationalLinguistics, 21(4):543-566, December.Damerau, F. J.
1964.
A technique forcomputer detection and correction ofspelling errors.
Communications of theAssociation for Computing Machinery,7(3):171-176.Golding, Andrew and Henry S. Thompson.1985.
A morphology component forlanguage programs.
Linguistics,23:263-284.Goldsmith, John.
1998.
Unsupervisedlearning of the morphology of a naturallanguage.
Unpublished manuscript,available at http:/ /humanit ies.uchicago, edu/f aculty/goldsmith/index, html.Johnson, Mark.
1984.
A discovery procedurefor certain phonological rules.
InProceedings ofl Oth International Conferenceon Computational Linguistics (COLING'84),pages 344-347, Stanford, CA, USA.Kaplan, Ronald M. and Martin Kay.
1994.Regular models of phonological rulesystems.
Computational Linguistics,20(3):331-378, September.Karttunen, Lauri.
1993.
Finite-state l xiconcompiler.
Technical Report, XEROX, PaloAlto Research Center, April.Karttunen, Lauri.
1994.
Constructing lexicaltransducers.
In Proceedings ofthe 15thInternational Conference on ComputationalLinguistics (COLING '94), volume 1,pages 406-411, Kyoto, Japan.Karttunen, Lauri and Kenneth R. Beesley.1992.
Two-level rule compiler.
TechnicalReport, XEROX Palo Alto ResearchCenter.Karttunen, Lauri, Jean-Pierre Chanod,Gregory Grefenstette, and Anne Schiller.1996.
Regular expressions for languageengineering.
Natural Language Engineering,2(4):305-328.Karttunen, Lauri, Ronald M. Kaplan, andAnnie Zaenen.
1992.
Two-levelmorphology with composition.
InProceedings ofthe 14th InternationalConference on Computational Linguistics,volume 1, pages 141-148, Nantes, France.Kiraz, George Anton.
2000.
Multitierednonlinear morphology using multitapefinite automata: A case study on Syriacand Arabic.
Computational Linguistics,26(1):77-105.Koskenniemi, Kimmo.
1983.
Two-levelmorphology: A general computationalmodel for word form recognition andproduction.
Publication No.
11,Department of General Linguistics,University of Helsinki.Mohri, Mehryar, Fernando Pereira, andMichael Riley.
1998.
A rational design fora weighted finite-state transducer library.84Oflazer, Nirenburg, and McShane Bootstrapping Morphological AnalyzersIn Lecture Notes in Computer Science, 1436.Springer Verlag.Nirenburg, Sergei.
1998.
Universal grammarand lexis for quick ramp-up of MTsystems.
In Proceedings ofthe FirstInternational Conference on LanguageResources and Evaluation, pages 739-746,Spain.Nirenburg, Sergei and Victor Raskin.
1998.Project Boas: "A Linguist in a Box" as amulti-purpose language resource.
InCOLING-ACL "98: 36th Annual Meeting ofthe Association for Computational Linguisticsand 17th International Conference onComputational Linguistics, pages 975-979,Montreal, Quebec Canada.Nirenburg, Sergei and Victor Raskin.
1999.Supply-side and demand-side l xicalsemantics.
In Evelyne Viegas, editor,Depth and Breadth of Semantic Lexicons.
Text,Speech, and Language Technology Series.Kluwer, Dordrecht and Boston.Oflazer, Kemal.
1994.
Two-level descriptionof Turkish morphology.
Literary andLinguistic Computing, 9(2):137-148.Oflazer, Kemal.
1996.
Error-tolerantfinite-state recognition with applicationsto morphological nalysis and spellingcorrection.
Computational Linguistics,22(1):73-90, March.Ranta, Aarne.
1998.
A multilingual naturallanguage interface to regular expressions.In Lauri Karttunen and Kemal Oflazer,editors, Proceedings ofthe InternationalWorkshop on Finite State Methods in NaturalLanguage Processing, FSMNLP'98,pages 79-90.Rissanen, Jorma.
1989.
Stochastic Complexityin Statistical Inquiry.
World ScientificPublishing.Satta, Giorgio and John C. Henderson.
1997.String transformation learning.
InProceedings ofACL/EACL'97.Sproat, Richard.
1992.
Morphology andComputation.
M1T Press.Theron, Pieter and Ian Cloete.
1997.Automatic acquisition of two-levelmorphological rules.
In Proceedings ofthe5th Conference on Applied Natural LanguageProcessing.van Noord, Gertjan.
1999.
FSA6: Finite stateautomata utilities (version 6) manual.Available at http://odur.let.rug.nl/van-noord/Fsa/Manual/.van Noord, Gertjan and Dale Gerdemann.1999.
An extendible regular expressioncompiler for finite-state approaches innatural anguage processing.
InProceedings ofWIA 99.85
