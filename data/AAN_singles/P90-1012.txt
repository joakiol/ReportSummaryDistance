NORMAL STATE IMPL ICATURENancy L. GreenDepartment of Computer and Information SciencesUniversity of DelawareNewark, Delaware 19716, USAAbstractIn the right situation, a speaker can use an unqual-ified indefinite description without being misun-derstood.
This use of language, normal slate im-plicature, is a kind of conversational implicature,i.e.
a non-truth-functional context-dependent i -ference based upon language users' awareness ofprinciples of cooperative conversation.
I presenta convention for identifying normal state implica-tures which is based upon mutual beliefs of thespeaker and hearer about certain properties of thespeaker's plan.
A key property is the preconditionthat an entity playing a role in the plan must bein a normal state with respect o the plan.1 In t roduct ionIn the right situation, a speaker can usean unqualified indefinite description without beingmisunderstood.
For example, a typical customerin a typical pet shop who said (la) in response tothe clerk's question in (1) would expect o be un-derstood as meaning (lb).
The goal of this paperis to formally describe such uses of language.
11A similar use of language is noted in \[McC87\].
Mc-Carthy (pp.
29-30) discusses the problem of b r id~ng thegap between a "rather direct \[translation\] into first orderlogic" of a s tatement  of the Missionaries and  Cannibals puz-zle, and a representat ion suitable for devising a solution tothe puzzle.
For example, if the puzzle s ta tement  mentionsthat  '% rowboat that  seats two is available" and  doesn't  saythat  anyth ing is wrong with the boat,  the problem-solvermay assume that the boat doesn't leak, has oars, etc.
Mc-Carthy proposes a general-purpose method for formalizingcommon sense reasoning, "circumscription", to solve theproblem.Also, a similar use of language is described in \[GriT5\] (p.51): "A is standing by an obviously immobilized car and isapproached by B; the following exchange takes place:A: I am out of petrol.B: There is a garage round the corner.... \[B\] implicates that the garage is, or at least may beopen, \[has petrol to sell\], etc."
That tiffs use of language891.
(Clerk A:) May I help you?a.
(Customer B:) I'd like to see a parrot.b.
I \[the speaker\] would like to see a live parrot.c.
3 p:PARROT REQUEST(B,A,SIIOW(A,B,p))d. 3 q:\[A p:PARROT LIVE(p)\] REQUEST(B,A,SHOW(A,B,q)One problem is that (la) (i.e.
its putativerepresentation in (lc)) does not entail (lb) (i.e.
itsputative representation in (ld)).
2Another problemis the context-dependence, both spatio-temporaland linguistic, of the relationship of (lb) to (la).In a different spatic~temporal context, such as ina china shop, a speaker might use (la) to convey(2) rather than (lb).2.
I \[the speaker\] would like to see a porcelainparrot.In a different linguistic context, such as if the cus-tomer had said (3a) following (la), she would notinvolves the use of language I have i l lustrated in (1) canbe seen by considering a s i tuat ion identical to the aboveexcept that  the dialogue consists of just  A 's  saying "I needa garage."
In other words, Grice's example is of a situationwhere B has ant ic ipated a request from A which is the samekind of request as (la).2The customer's use of (la) is an indirect speech act,namely, a request to be shown a parrot; other possible re-alizations of this request include "Show me a parrot" and"Can you show me a parrot?".
(The derivation of represen-tations of indirect speech acts has been treated elsewhere\[PAS0\] and is not a concern of this paper.)
(Ic) is intendedto represent that request by means of a first order languageextended with hlgher-order operators such as REQUEST.Also, indefinite descriptions are represented as in \[Web83\].The status of the existence of the parrot in the real worldor discourse context (and the related question as to theproper scope of the existential quantifier), is not relevazltto the concerns of this paper.
My  point is that the usualtreatments employing a one-to-one translation from surfacestructure to logical form without consideration of other in-formation will not he able to explain the relationship of( lb) to (1@normally expect he clerk to think she had meant(lb).
A related question is why it would be ap-propriate (non-redundant) for the customer to say(3b) following (la) if the customer believed thatthe clerk might mistakenly believe that the cus-tomer wanted to see a dead parrot.2 Scalar Impl icaturetIirschberg proposes the following set of sixnecessary and sufficient conditions for identifyingconversational implicatures (p. 38).
3 A speakerS conversationally implicates Q to a hearer tI bysaying U (where U is a realization of a propositionP) in a context C iff:3.a .
.
.
.
a dead oneb .
.
.
.
a l ive  oneA third problem is that in order to derive(lb) from (la) it is necessary to consider the beliefsof speaker (S) and hearer (H): e.g.
S's and H'sbeliefs about why each said what they did, andabout the appropriate state of the parrot.Grice \[Gri75\] described conversational im-plicature, a kind of non-truth-functional context-dependent inference based upon a speaker's andhearer's awareness ofprinciples of cooperative con-versation.
In this paper, I claim that a speaker'suse of (la) may conversationally implicate (lb).In order to formally describe this kind of conver-sational implicature, which I have termed 'nor-mal state implicature', I adopt the methodologyused by Hirschberg \[Hir85\] for the identification ofanother kind of conversational implicature, scalarimplicature.In section 2, I present a brief descriptionof scalar implicatures and Hirschberg's methodol-ogy for identifying them.
In section 3, I presenta convention for identifying normal state implica-tures.
Informally speaking, the convention is thatif speaker S makes a request hat hearer H per-form an action A on an entity E, and if S and ttmutually believe that S has a plan whose successdepends on the E being in a certain state N (whichis the normal state for an E with respect o thatplan) and that S's request is a step of that plan,then S is implicating a request for S to do A on anE in state N.In section 4, I clarify the notion of nor-mal state with respect to a plan by distinguish-ing it from the notions of stereotype and plan-independent normal state.
Next, in section 5, Ishow how states can be represented in the lexicon.In section 6, I compare scalar and normal state im-plicature; in section 7, survey related work; and,in section 8, present my conclusions.1.
S intends to convey Q to H via U; and2.
S believes that S and H mutually believe thatS is being cooperative; and....S and H mutually believe that S's saying U inC, given S's cooperativity, licenses Q; andQ is cancelable; i.e., it is possible to deny Qwithout denying P; andQ is nondetachable; i.e., the choice of a real-ization U of P does not affect S's implicatingQ (except in certain situations where Q is li-censed via Grice's Maxim of Manner); andQ is reinforceable; i.e., it is possible to affirmQ without seeming redundant.Instead of using these conditions to identifyparticular scalar implicatures, Hirschberg arguesthat it is sufficient o provide a means of iden-tifying instances of a class of conversational im-plicature, such as scalar implicatures.
Then, sheprovides a convention for identifying instances ofscalar implicat ure.Informally speaking, scalar implicature isbased on the convention that (pp.
1 - 2)"cooper-ative speakers will say as much as they truthfullycan that is relevant o a conversational exchange";and distinguished from other conversational impli-catures by "being dependent upon the identifica-tion of some salient relation that orders a conceptreferred to in an utterance with other concepts";e.g.
by saying (4a), B has scalar implicated (4b).
4(4) A: How was the party last night?a.
B: Some people left early.b.
Not all people left early.90The convention for identifying scalar impli-cature proposed by Hirschberg is of the form: if3Her condit ions are ~ revision of Grice's.
Also, I havechanged the names  of her variables to be consistent withusage in the rest of my paper.4 (4) is example (1) in \[Hir85\].there exists a partial order O such that S and Hmutually believe that O is salient in context C,and utterance U realizes the proposition that S af-firms/denies/is gnorant of some value in O, thenby saying U to H in C, S licenses the scalar im-plicature that S has a particular belief regardingsome other value of O.In the next section, I will ap-ply Hirschberg's methodology to the problem ofidentifying normal state implicatures.3 Normal  S tate  Imp l i ca tureIn this section, I will argue that (lb) is aconversational implicature and propose a conven-tion for identifying instances of that class of impli-cature, which I will call 'normal state implicature'.First, I claim that a speaker S conversa-tionally implicates (lb) to a hearer H by saying(la) in the context described above; i.e.
that (lb)is a conversational implicature according to thesix conditions described in section 2.
Condition 1is met since S intends to cause H to believe (lb)by saying (la); condition 2 since S believes thatit is a mutual belief of S and H that S is beingcooperative; condition 3 will be satisfied by pro-viding a convention for normal state implicaturebelow.
The previous discussion about (3a) and(3b) provides evidence for cancelability (condition4) and reinforceability (condition 6), respectively;and, (lb) is nondetachable (condition 5) since al-ternate ways of saying (la), in the same context,would convey (lb).Next, in order "to motivate the generalconvention ((6) below) for identifying normalstate implicatures, I'll present the instance ofthe convention that accounts for the implicaturein (1).
Let S, H, U, and C be constants de-noting speaker, hearer, utterance, and context,respectively.
Let b0, bl, and g be first or-der variables over parrots (PARROT), live par-rots (the lambda expression), and plans (PLAN),respectively.
5 HAS-PLAN(Agent,Plan,Entity) is5The model of plans used here is that of STRIPS \[FN71\]with minor extensions.
A plan includes preconditionswhich must hold in order for the plan to succeed, and asequence ofactions to be carried out to achieve some goal.One extension to this model is to add a llst of entities play-ing a role in the plan either as instruments (e.g.
a boatwhich is to be used to cross a river) or as the goal itself(e.g.
a parrot o be acquired for a pet).
The second exten-true if Agent has a plan in which Entityplays a role; PRECOND(Plan,Proposition) istrue if Plan has Proposition as a precondition;STEP(Plan,Action) is true if Action is a stepof Plan.
Also, BMB(A,B,Proposition) is trueif A believes that A and B mutually believethat Proposition; REALIZE(Utterance, Propo-sition) is true if Utterance expresses Proposi-tion; REQUEST(S,H,Action) is true if S re-quests H to perform Action; and SAY(S,H,U,C)is true if S says U to H in C. 6 SHOW(A,B,C) istrue if A shows C to B.
IN-STATE(Entity,State)is true if Entity is in the given State; andNORMAL-STATE(State,Plan,Entity) is true ifState is the normal state of Entity with re-spect to Plan.
7 Finally, NORMAL-STATE-IMP (Speaker, Hearer ,Utterance ,Prop osition ,Context )is true if by use of Utterance in Context, Speakerconveys Proposition to Hearer.Now, to paraphrase (5) below, if S and Hmutually believe that S has a plan in which a par-rot plays a role and that a precondition of S's planis that the parrot should be alive, which is its nor-mal state with respect to the plan, and that S'ssaying U is a step of that plan; and, if U is a re-quest to be shown a parrot, then S normal stateimplicates a request o be shown a l ive parrot.5.
Vb0:PARROTVbl : \[Ab2: PARROT LIVE(b2)\]?g:PLANBMB(S, H, ~HAS-PLAN(S, g, b0) APRECOND(g, IN-STATE(b0, LIVE)) ANORMAL-STATE(LIVE, g, b0) ASTEP(g, SAY(S, H, U, C))) AREALIZE(U, REQUEST(S, H, SHOW(H, S, b0)))NORMAL-STATE-IMP(S, H, U, REQUEST(S, H,SHOW(H, S, bl)),C)It is possible to generalize (5) as follows.Let K, N, and A be higher order variables overclassifications (CLASSIF), states (STATE), andactions that may be performed as a step in a plansloE, suggested in \[Car88\], is to distinguish preconditionswhich can be achieved as subgoais from those which areunreasonable for the agent o try to bring about ("applica-bility conditions" ).
In (5) and (6), preconditions are meantin the sense of applicability conditions.eBMB, REALIZE, REQUEST, and SAY are from\[Hir85\].7I will discuss what is meant by state and normal statein section 4.91(ACT), respectively.
Then, (6) is the general con-vention for identifying normal state implicature.6.
V K:CLASSIF V N:STATE V A:ACTVb0:KVbl: \[~b2:K N(b~)\]V g:PLANBMB(S, H, HAS-PLAN(S, g, b0) APRECOND(g, IN-STATE(b0, N)) ANORMAL-STATE(N, g, b0) ASTEP(g, SAY(S, It, U, C))) AREALIZE(U, REQUEST(S, H, A(b0))) ?~NORMAL-STATE-IMP(S, H, U,REQUEST(S, I-I, A(bl)),C)Unfortunately, if (6) is to be of maximumuse, there are two problems to be solved.
First,there is the problem of representing all precon-ditions of a plan, s and, second, is the problem ofplan inference, i.e., how does H come to know whatS's plan is (including the problem of recognizingthat the saying of U is a step in S's plan)?
9 Bothproblems are outside the scope of this paper.4 States and Normal  StatesFirst, what I mean by a state of an entityE is, adopted from \[Lan87\], a history of relatedevents involving E. In Lansky's ontology, eventsmay be causally or temporally related.
Tem-poral precedence is transitive.
Causality is nottransitive and does not necessitate occurrence butdoes imply temporal precedence.
A strong pre-requisite constraint (--,) can be defined such that"each event of type E~ can be caused by ex-actly one event of type El,  and each event oftype E1 can cause at most one event of type E2"(\[Lan87\],p. 142).Many classifications expressed as nouns de-note a class of entity whose state varies over theperiod of existence during which it is aptly char-acterized by the classification.
For example, Fig-ure 1 and Figure 2 depict causal event chains l?
ofparrots and vases, respectively.
(Nodes represent events and directed arcsrepresent causality.)
The state of being dead orSE.g., see \[McC87\].9E.g., see \[Car88\].1?I don't mean 'causal chain' in the sense that philoso-phers have recently used it \[Sch77\], nor in the sense of\[SA77\], nor do I mean 'chain' in the mathematical senseof a total order.broken can be defined in terms of the occurrenceof an event type of dying or breaking, respectively.Live is the state of an entity who has been bornbut has not yet died; ready-to-use is the state ofan artifact between its creation or repair and itsdestruction.
11 Note that, paradoxically, languageusers would agree that a dead parrot or a vase witha crack in it is still aptly characterized as a parrotor vase, respectively.
12Next, what I mean by a normal state of Eis a state that E is expected to be in.
For example,in the absence of information to the contrary, liveor ready-to-use is expected by language users tobe a state of parrots or vases, respectively.
Note,however, that NORMAL-STATE in (6) representsa normal state of an entity with respect o someplan.
That is, I am not claiming that, in the ab-sence of information about S's plan, S's use of ( la)conversationally implicates (lb).The reason for stipulating that NORMAL-STATE be relative to S's plan is that use of ( la) inthe context of a different plan could change whatS and H consider to be normal.
For example, in ataxidermist's plan, dead could be the normal stateof a parrot.
Also, consider 'coffee': a speaker's useof (7) in the context of a coffee farm could be usedto request coffee beans; in a grocery store, a ja r  ofinstant; and in a restaurant, a hot beverage.7.
I'd like some coffee.92Note that more than one precondition ofS's plan may be relevant o interpreting S's use ofan expression.
For example, a typical restaurantcustomer uttering (7) expects to be understood asnot only requesting coffee in its hot-beverage state,but also in its safe-to-drink state.
Also, more thanone of S's plans may be relevant, Returning to thepet shop example, suppose that S and H mutuallybelieve that S has plans to acquire a parrot as a petand also to study its vocalizations; then it wouldbe inappropriate for H to show S a parrot that Hbelieved to be incapable of making vocalizations.Normal states differ from stereotypes.
Astereotype is a generalization about prototypes ofa category, 13 e.g.
(8).
1411Examples of how state predicates can be defined inLansky's formal anguage will be given later.12The cracked vase example is from \[Her87\].laThe prototype-stereotype distinction is describedin\[HH83\].14Note that stereotypes may be relative to a state of the8.
Unripe bananas are green.Qualifying an expression in a way whichcontradicts a stereotype may have a different ef-fect on H than doing so in a way which specifies anon-normal state.
For instance, if S says (9) aftersaying (la) in the above pet shop scenario, H maydoubt S's sincerity or S's knowledge about parrots;while S's use of (3a) after saying (la) may causetI to have doubts about S's sincerity or It's knowl-edge of S's plan, but not S's knowledge about par-rots.9 .
.
.
.
a 100 pound oneAnother difference between stereotypes andnormal states is that stereotypes are not affectedby S's and H's mutual beliefs about S's plan,whereas I have just demonstrated that what isconsidered normal may change in the context ofS's plan.
Finally, another eason for making thedistinction is that I am not claiming that, in theabove pet shop scenario, S's use of (la) licenses(10); i.e., S does not intend to convey (10).
1510.
I \[the speaker\] would like to see a large,green, talking bird.5 The Role of Events in cer-tain Lexical Representa-tionsNow I will show how the notion of statepresented in the previous section can be repre-sented in the lexicon via state predicates basedon causal event chains.
The purpose of this is toclarify what counts as a state and hence, what isprototype; e.g.
contrast (8) with "Ripe bananas  are yel-low".
A statement of a stereotype in which the state of theprototypes is unspecif ied may describe prototypes in theplan- independent ormal  state for the category; e.g.
con-sider "Bananas  are yellow".
Also, note that  stereotypicalproperties may be used to convey the state; e.g.
consider"I want a green banana" used to convey "I want an unripebanana" .15I recognize that  it is possible for a speaker to exploitmutua l  beliefs about  stereotypes or p lan- independent or-real states to convey conversational implicatures.
E.g., con-sider the conversation: A says, "Is your neighbor ich?"
Breplies, "He's a doctor."
However, this k ind of impl icaturedoes not occur under  the same condit ions as those givenfor normal  state implicature, and is outside of the scope oftiffs paper.93to be identified by the convention for normal stateimplicature.
This way of representing states hasbenefits in other areas.
First, entaihnent relation-ships between states of an entity are thereby rep-resented.
Second, certain scalar implicatures maybe based on the event ordering of a causal eventchain.For example, Figure 3 contains pictorialand formal representations of a causal event chainfor the ripening of fruit.
Definitions of states aregiven as state predicates; e.g.
the expression 'un-ripe' is used to denote a state such that no eventof ripening (R) has occurred (yet).
Note that, as(11) shows, 'ripe' may be used to scalar implicatebut not to entail 'not overripe'; the event order-ing of the causal event chain serves as the salientorder for the scalar implicature.
The expected en-tailments follow from the constraints representedin Figure 3.l l .a.
It's ripe.
In fact, it's just right for eating.b.
It's ripe.
In fact, it's overripe/too ripe.6 Comparison of Scalar andNormal State ImplicatureThese two classes of conversational impli-cature have some interesting similarities and dif-ferences.First, licensing a scalar implicature requiresthe mention of some specific value in an ordering,while licensing a normal state implicature requiresthe absence of the mention of any state.
For ex-ample, consider a situation where S is a restaurantcustomer; H is a waiter; S and H have mutual be-lief of the salience of an ordering such that warmprecedes boiling hot; and, S and H have mutualbelief of S's plan to make tea by steeping a teabag in boiling hot water.14.a.
I'd like a pot of water.b.
I'd like a pot of warm water.c.
I'd like a pot of boiling hot water.d.
I'd like a pot of warm but not boilinghot water.In this situation, use of (14a) would licensethe normal state implicature (14c) but no scalarimplicature.
IIowever, use of (14b) would licensethe scalar implicature (14d) but not the normalstate implicature (14c).
(In fact, use of 'warm' in(14b) would cancel (14c), as well as be confusingto H due to its inconsistency with H's belief aboutS's intention to make tea.)
Thus, at least in thisexample, scalar and normal state implicature aremutually exclusive.Second, saliency and order relations play arole in both.
Scalar implicature is based on thesalience of a partially ordered set (from any do-main).
Normal state implicature is based on thesalience of a plan; one of a plan's preconditionsmay involve a normal state, which can be definedin terms of a causal event chain.normal state implicature, while the presence of aqualification (the marked case), blocks it (therebyallowing the scalar implicature to be conveyed).Finally, Herskovits \[Her87\] addresses theproblem that the meaning of a locative expressionvaries with the context of its use.
Her approachis to specify "a set of characteristic constraints -constraints that must hold for the expression to beused truly and appropriately under normal condi-tions. "
(p. 20) Her constraints appear to includestereotypes and plan-independent ormal states;normal is distinguished from prototypical; and theconstraints may include speaker purpose.7 Re la ted  WorkThis work is related to work in several dif-ferent areas.First, one of the goals of research on non-monotonic reasoning 16 has been the use of defaultinformation.
The classic example, that if some-thing is a bird then it can fly, appears to in-volve all three notions that I have distinguishedhere; namely, stereotype, plan-independent or-mal state, and normal state with respect o a plan.
(It is a stereotype that birds are genetically suitedfor flight; a plan-independent normal state that abird is alive or uninjured; and a normal state withrespect o a plan to send a message via carrier pi-geon that the bird be able to fly.)
Also, I haveshown that the calculation of normal state impli-cature is based only on the third notion, i:e., thatcertain "defaults" are context-dependent.In another area, work has been done onusing knowledge of a speaker's plans to fill inmissing information to interpret incomplete utter-ances, e.g.
sentence fragments \[AP80\] and ellipsis\[car89\].As for related work on conversational im-plicature, both \[iior84\] and \[ALS1\] describe prag-matic inferences where what is conveyed by anutterance is more precise than its literal mean-ing.
They claim that such inferences are basedon a principle of speaker economy and exploit thespeaker's and hearer's hared beliefs about stereo-types.
Also, Horn points out that an unmarked ex-pression tends to be associated with the stereotypeof an extension and its marked counterpart withthe non-stereotype.
Roughly, this corresponds tomy observation regarding (14), that the absenceof a qualification (the unmarked case) licenses alOFor a survey, see \[GinS7\].
948 Conc lus ionsThis paper has provided a convention foridentifying normal state implicatures.
Normalstate implicature permits a speaker to omit certaininformation from an indefinite description in cer-tain situations without being misunderstood.
Theconvention is that if S makes a request hat tt per-form an action A on an E, and if S and H mutuallybelieve that S has a plan whose success dependsupon the E being in the normal state N with re-spect to that plan, and that S's request is a stepof that plan, then S is implicating a request for Sto do A on an E in state N.In order to specify the convention for nor-mal state implicature, I distinguished the notionsof stereotype, plan-independent normal state, andnormal state with respect o a plan.
This distinc-tion may prove useful in solving other problems inthe description of how language is used.
Also, arepresentation for states, in terms of causal eventchains, was proposed.The convention I have provided is impor-tant both in natural language generation and in-terpretation.
In generation, a system needs toconsider what normal state implicatures would belicensed by its use of an indefinite description.These implicatures determine what qualificationsmay be omitted (namely, those which would be im-plicated) and what ones are required (those whichare needed to block implicatures that the systemdoes not wish to convey), lr In interpretation, asystem may need to understand what a user has17This latter behavior is an example of Joshi's revisedMaxim of Quality: "If you, the speaker, plan to say any-thing which may imply for the hearer something you believeto be false, then provide further information to block it.
"\[JosS2\]implicated in order to provide a cooperative re-sponse.
For instance, if during a dialogue a sys-tem has inferred that a user has a plan to make animmediate delivery, and then the user says (15a),then if the system knows that the only truck interminal A is out of service, it would be uncoop-erative for the system to reply with (15b) alone;(15c) should be added for a more cooperative r -sponse.15.a.
User: Is there a truck in terminal A?b.
System: Yes, there is onec.
but it's out of service.This work may be extended in at least twoways.
First, it would be interesting to investigatewhat plan inference algorithms are necessary in or-der to recognize normal state implicatures in ac-tual dialogue.
Another question is whether thenotion of normal state implicature can be gener-alized to account for other uses of language.9 AcknowledgmentsAn earlier version of this work was doneat the University of Pennsylvania, partially sup-ported by DARPA grant N00014-85-K0018.
Mythanks to the people there, particularly BonnieWebber and Ellen Prince.
Thanks to my col-leagues at SAS Institute Inc., Cary, N. C., for theirmoral support while much of this paper was beingwritten.
The final draft was prepared at the Uni-versity of Delaware; thanks to the people there,especially Sandra Carberry and K. Vijayashanker.References\[AL81\] Jay David Atlas and Stephen C. Levin-son.
It-clefts, informativeness, and log-ical form: radical pragmatics (revisedstandard version).
In Peter Cole, editor,Radical Pragmatics, pages 1-62, Aca-demic Press, N. Y., 1981.lAP80\] James F. Allen and C. Raymond Per-rault.
Analyzing intention in utterances.Artificial Intelligence, 15:143-178, 1980.\[c~881 Sandra Carberry.
Modeling the user'splans and goals.
Computational Linguis-tics, 14(3):23-37, 1988.
95\[Car80\]\[FN71\]\[Gin87\]\[Gri75\]\[Her87\]\[HH831\[Hir85\]\[Hot84\]\[JosS2\]\[Lan87\]\[McC87\]Sandra Carberry.
A pragmatics-basedapproach to ellipsis resolution.
Compu-tational Linguistics, 15(2):75-96, 1989.R.
E. Fikes and N. J. Nilsson.
Strips: anew approach to the application of the-orem proving to problem solving.
Artifi-cial Intelligence, 2:189-208, 1971.Matthew L. Ginsberg.
Readings in Non-monotonic Reasoning.
Morgan Kauf-mann, Los Altos, California, 1987.H.
Paul Grice.
Logic and conversation.In P. Cole and J. L. Morgan, editors,Syntax and Semantics III: Speech Acts,pages 41-58, Academic Press, N.Y.,1975.Annette Herskovits.
Language and Spa-tial Cognition.
Cambridge UniversityPress, Cambridge, England, 1987.J.
Hurford and B. Heasley.
Semantics:A Coursebook.
Cambridge UniversityPress, Cambridge, England, 1983.Julia Bell Hirschberg.
A Theoryof Scalar Implicature.
Technical Re-port MS-CIS-85-56, Department ofComputer and Information Science, Uni-versity of Pennsylvania, 1985.Larry Horn.
Toward a new taxonomyfor pragmatic inference: q-based and r-based implicature.
In D. Schiffrin, ed-itor, GURT '84.
Meaning, Form andUse in Context: Linguistic Applica-tions, pages 11--42, Georgetown Univer-sity Press, Washington, D. C., 1984.Aravind K. Joshi.
Mutual beliefs inquestion-answer systems.
In N. Smith,editor, Mutual Beliefs, pages 181-197,Academic Press, New York, 1982.Amy Lansky.
A representation of par-allel activity based on events, struc-ture, and causality.
In M. P. Georgeffand A. Lansky, editors, Reasoning aboutActions and Plans: Proceedings of the1986 Workshop, pages 123-160, MorganKaufmann, 1987.John McCarthy.
Circumscription - aform of non-monotonic reasoning.
InMatthew L. Ginsberg, editor, Readingsin Nonmonotonic Reasoning, pages 145-152, Morgan Kaufmann, 1987.\[PASO\]\[SA77\]\[Sch77\]\[Web83\]R. Perrault and J. Allen.
A plan-basedanalysis of indirect speech acts.
Amer-ican Journal of Computational Linguis-tics, 6(3-4):167-182, 1980.Roger C. Schank and Robert P. Abel-son.
Scripts, Plans, Goals and Under-standing.
Lawrence Erlbaum Associates,Hinsdale, New Jersey, 1977.Stephen P. Schwartz.
Introduction.
InStephen P. Schwartz, editor, Naming,Necessity, and Natural Kinds, pages 13-41, Cornell University Press, 1977.Bonnie L. Webber.
So what can we talkabout now?
In Jones K. S. Grosz, B. andB.
L. Webber, editors, Readings in Nat-ural Language Processing, Morgan Kauf-mann, Los Altos, California, 1983.unborn ,~  live ,~  deadFigure 1: Causal event chain for parrotunfinished~ready-to-use~Figure 2: Causal event chain for vase\ YY ripeFruit-for-eating = element ypeeventsR \[Ripen\]0 \[Become Overripe\]constraints1.
R--.
Oend element ypeunripe(x) = --, (3 r:x.R) occurred(r)just-ripe(x) =- (3 r:x.a) occurred(r) A-~((5o:x.O) occurred(o) A r --* o)overripe(x) -- (3 o:x.O) occurred(o)ripe(x) _ (3 r:x.R) occurred(r)Figure 3: Causal event chain for fruit ripening96
