Automatic Identification of Chinese Event DescriptiveClauseLiou ChenDepartment of Computer Scienceand technologyTsinghua Universitychouou@foxmail.comQiang ZhouNational Laboratory for Informa-tion Science and Technology,Tsinghua Universityzq-lxd@mail.tsinghua.edu.cnAbstractThis paper gives a new definition of Chi-nese clause called ?Event DescriptiveClause?
and proposes an automatic me-thod to identify these clauses in Chinesesentence.
By analyzing the characteristicsof the clause, the recognition task is formu-lated as a classification of Chinese punctua-tions.
The maximum entropy classifier istrained and two kinds of useful features andtheir combinations are explored in the task.Meanwhile, a simple rule-based postprocessing phase is also proposed to im-prove the recognition performance.
Ulti-mately, we obtain 81.32% F-score on thetest set.1 IntroductionAn important task in natural languageprocessing (NLP) is to identify the completestructure of a sentence.
However, the ambigui-ties of the natural language make full parsingdifficult to become a practical and effective toolfor NLP applications.
In order to solve thisproblem, ?partial parsing?
is proposed to dividecomplex sentences into simple units, and thenthe complex full-parsing task can be simplifiedto be the analysis of single units and relationsamong them.
Ejerhed(1998) once found that aparser can benefit from automatically identifiedclause boundaries in discourse, and he showedthe partial parsing method called ?clause identi-fication?
is useful for full parsing.For example, given a Chinese sentence as fol-lows:?
????????????????????????????????????????????????????
Along the way, we see the trees havebeen cut down for regeneration, and thetrees needed to be cut for building.
All ofthem are useful building material.
We al-so see several freight trucks and tractorsgoing south and north.The illustrative sentence is a long one that isdifficult to parse with a one-step full parsingand will suffer from the error propagation fromthe previous wrong parsing results.However, if the sentence is segmented intoseveral independent clauses which can beparsed separately, the shortening of sentencelength will make each sub-parsing much easierand the independent of each clause can alsoprevent the error-propagation.
For example, theabove sentence can be divided into four partswhich are labeled with dashed borders shown inFigure 1.
Each segment can be parsed solely asa sub tree and the whole parse tree can be easilybuilt through analyzing the event relationshipsamong them.
Moreover, the parse errors occur-ring in each sub tree have little effect on thewhole tree as they are parsed independently ineach segment region.The key issue is how to select a suitable seg-mentation unit.
It is not a trivial question be-cause it must be based on the characteristics oflanguage itself.
In English, a clause is a closelyrelated group of words that include both a sub-ject and a verb.
The independent sentence isusually ended by punctuation and the dependentone is often introduced by either a subordinatingconjunction or a relative pronoun.
The structuraltrait of English language is the basic to defineEnglish clause and clause recognition task, likeCoNLL-2001 (Erik F et al, 2001).However in Chinese, there is no obvious con-junction between two clauses, especially thedependent clauses.
The separators used oftenare just punctuations, like commas and periods.Therefore the characteristics of Chinese sen-tence call for a new clause identification schemeto spit a sentence into clause segments.To meet this need, we define a new clauseunit called ?Event Descriptive Clause (EDC)?
inthe Chinese sentence.
It mainly considers thepunctuation separators so as to skip the difficul-ty in identifying different subordination clauseswithout any obvious separating tags.Figure 1.
Parsing result of the example sen-tence.According to the definition, we proposed anEDC recognition method based on punctuationclassification.
Experimental results show thatthe new definition of Chinese clause identifica-tion task is reasonable and our feature set is ef-fective to build a feasible EDC recognition sys-tem.2 EDC Recognition Task2.1 Definition of Chinese ClauseAs we discussed before, ?clause identification?is a useful step in language processing as it candivide a long complex sentence into severalshort meaningful and independent segments.Therefore the definition of a clause shouldsatisfy two basic requirements: ?meaningful?and ?independent?.
The previous restrictionrequires each clause to make sense and expressa full meaning, and the latter one insures thateach clause can be parsed alone.We firstly give the definition of ?Event?.
Anevent is expressed by several functional chunks(Zhou and Li, 2009) which are controlled by acertain predicate.
The functional chunks are de-fined as the subject, predicate, object and ad-verbial parts of a clause.
According to differentevent level, the complex components of a highlevel event may contain some low level events.Let us take the second part of Figure 1 as anexample.
The high level event dominated by theverbal predicate ???/see?
is : ?
[S ?
?/ We][P ?
?/ see] [C ??????????????????
?/ the trees have been cut downfor regeneration, and the trees needed to be cutfor building]?.
The event is composed of threehigh level functional chunks.The complement of above event also containstwo nested events controlled by the predicate??
?/cut down?.
Which are ?
[D ????
(forregeneration)] [P ??
(cut down)] ?
[H ??(trees)]?
and ?[D????
(for building)] [P??
(cut down)]?[H??(trees)]?.
The chunks inthese two events are low level ones.Next, we consider the characteristics of Chi-nese sentences.
Because the punctuations, likecommas, semicolons, question marks, etc.
arecommonly-used obvious independent event se-parators.
We can use them to segment a wordsequence as a possible clause in a sentence.
[D ??
(along the way) ]?[S??
(we)][P??
(see)][C[H[D???
(for regeneration)][P ??
(cut down)]?
(-)[H ??
(trees)]]?[H[D???
(for building)][P??
(cut down)]?
(-)[H??
(trees)]]]?[D?
(all)][P?
(are)][O????
(useful)]?[S[P????
(freight)]?
(-)[H??\???
(trucks and tractors)]?][P????
(going south and north)]?Then based on the overall consideration ofthe definition of ?Event?
and the characteristicsof Chinese sentence, we define the Event De-scriptive Clause (EDC) as a word sequence se-parated by punctuations, the sequence shouldcontain either a simple high level event or acomplex main event with its nested low levelevents.Taking some special conditions into consid-eration, the adverbials to describe common time orspace situations of several events, and the indepen-dent components to describe sentence-level paren-thesis, can also be regarded as special EDCs thoughsometimes they do not contain any predicates.In the Chinese language, many events can sharesubject and object with the adjacent events so thatthe subject or object can be omitted.
We differen-tiated them with different tags in our EDC defini-tion schemes.In summary, three types of EDCs are consi-dered as follows:(1) E1: an EDC that includes at least one sub-ject in the event it contains.
(2) E2: an EDC that has no subject.
(3) D/T: an EDC acted as sentence-level ad-verbial or independent composition.Then the above example sentence can be di-vided into following four EDCs:?
[D?? ]
?
[E1 ?????????????????????
]?
[E2 ?????? ]
?
[E1 ????????????????]
??
[D Along the way], [E1 we see the treeshave been cut down for regeneration, andthe trees needed to be cut for building].
[E2 All of them is useful building materi-al].
[E1 We also see several freight trucksand tractors going south and north].2.2 Task AnalysesAccording to the EDC definition, we define theChinese clause identification as a task that re-cognizing all types of EDCs in an input sen-tence after word segmentation and POS tagging.Like the example in section 2.1, each EDC isrecognized and enclosed between brackets.
Thetask consists of two subtasks.
One is to recog-nize suitable EDC boundaries in a sentence.
Theother is to assign suitable tags for each recog-nized EDCs.
We only focus on the first subtaskin the paper.
Comparing with CoNLL-2010 task,our task only recognizes the EDCs that containthe highest level events without identifying itsinternal nested structures.Since EDC is defined as a word sequence se-parated by certain punctuations.
The identifica-tion problem can be regarded as a classificationtask to classify the punctuations as one of twoclasses: boundary of an EDC (Free Symbol), ornot an EDC boundary (Non-Free Symbol).
Thenthe words sequence between two Free Symbolsis an EDC.By analysis, we found only several types ofpunctuations could be used as EDC separatorcommonly, including period, question mark,exclamatory mark, ellipsis, comma, semicolon ,colon and brackets.
The previous four types ofpunctuations always appear at the end of a sen-tence so we simply name them as ?End Symbol?.The following four types are called ?Non-EndSymbol?
accordingly.
The Free-Symbols arerecognized from these special punctuations.3 EDC Recognition System3.1 Recognition ProcessStatistical data from the EDC-annotated corpusprovided by CIPS-ParsEval-2009 task (Zhouand Li, 2009) show that 99.87% End Symbolsact as the boundaries of EDCs.
So we can simp-ly assume them as Free Symbol.
But for Non-End Symbols, the linguistic phenomena arecomplex.
If we present a baseline system thatregards every Non-End Symbol as a Free Sym-bol rough, only 61% symbols can be correctlyrecognized and the remaining 39% are wronglytreated.To solve this problem, we implement a clas-sifier for Non-End Symbol specially.
First of all,we propose several features that might be usefulto determine whether a Non-End Symbol is free ornot.
Then, the performance of each feature istested on a maximum entropy classifier to find themost effective features and form the final featureset.
We will discuss them detailed in the follow-ing sections.3.2 FeaturesFeatures are very important in implementing aclassifier.
We consider two types of features:As EDC is a word sequence, the word andpart of speech (POS) features are the most intui-tional information for clause boundary recogni-tion.
We call the word level features ?basic fea-tures?
as Table 1 shows.However, the structural characteristics of asentence cannot be completely reflected bywords it contains.
As the events in an EDC areexpressed by functional chunks as section 2.1presents, the functional chunk (FC) might beeffective in recognition.
They can provide moresyntactic structure features than the word se-quences.
We consider four types of FC-relatedfeatures as in Table 2.Those two major types of features are testedand the final feature set will be selected throughexperimentsFeatureCurrent POSWordn/POSnAdjacent Non-EndSymbolsdistancecurrent wordadjacent wordLeft verbLeft prepositionAdjacent bracketsdistanceadjacent POSTable 1.
Basic FeaturesFeature DescriptionLocationif current punctuation is in afunctional chunk, the featureis 1, else is 0Chunknfunctional tags in differentpositions of local contextwindowsChunksequencefunctional tags betweencurrent punctuation andfirst left Non-End SymbolPredicatenumberthe number of predicatesbetween current punctuationand first left Non-End Sym-bolTable 2.
Extended Features3.3 Feature Selection StrategyThe features listed in Table 1 and Table 2 areconsidered to be useful but whether there areactually effective are unknown.
Therefore weshould select the most useful ones through ex-periments using certain strategy.In the paper, we try a greedy strategy.
Firstly,each feature is used alone to get its ?contribu-tion?
to the classification system.
Then after allfeatures are tested, they are sorted by their con-tributions.
At last, features are added one by oneinto classifier according to their contributionranks and then pick out the features that canimprove the performance and take out thosefeatures that have no effect on performance oreven lead to the degradation.
Eventually, we geta proper feature set.As shown in Table 1 and Table 2,Wordn/POSn and Chunkn tags are used and theirpositions (n) are important.
In this paper, we letthe position window change from [0, 0] to [-5, 5]to select the proper position area.4 Experimental resultsAll data we use in this paper are provided byCIPS-ParsEval-2009 task (Zhou and Li, 2009).They are automatically extracted from TsinghuaChinese Treebank/TCT (Zhou et al, 1997), in-cluding 14,248 Chinese sentences as trainingmaterial and 3,751 sentences as test data.
Weused the sentences annotated with Gold-standard word segmentation and POS tags asthe input data for EDC recognition.4.1 Feature SelectionWe use the 14,248 training sentences to judgethe contribution of each feature and get finalfeature set.
The training corpus is divided intotwo parts with the ratio of 80% and 20%.
80%data is used to train classifiers and the remain-ing 20% for feature selection.The maximum entropy toolbox1 is chosen forclassification due to its training efficiency andbetter performance.
A functional chunk parser(Yu, 2007) trained on the same CIPS-ParsEval-2009 FC bank (Zhou and Li, 2009) are used toprovide extended features.
Its F-score is 85%.The parser could only provide the lowest levelfunctional chunks.
For example, given the inputsentence ????????????????
?/ the freight trucks and tractors going south1http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.htmland north?, the output functional chunk se-quence are : ?[P????
(freight)] ?
[H??????
(trucks and tractors)]?
[P ????
(going south and north)]?.The evaluation measure is defined as follows:Accuracy =Correctly  classified  SymbolsTotal  Non?End  Symbols(a)The performance of each feature is evaluatedand ranked as Table 3 shows.When selecting the proper position area ofChunkn and Wordsn/POSn, the areas changefrom [0, 0] to [-5, 5] and the performancecurves are shown in Figure 2 and Figure 3.Then the feature in Table 3 is added one byone into classifier and the feature will be movedwhen it causes performance degradation.
Table4 presents the accuracy changes on 20% devel-opment data set.Form above experimental figures and tableswe can get several conclusions:Figure 2 and Figure 3 display the perfor-mance changes under different window sizes(from [0, 0] to [-5, 5]).
Then the abscissas oftheir highest points are chosen as best windowsizes.
We can find that when the window size islarge enough, the performance change will beinconspicuous, which means the information faraway from current punctuation has less help injudging whether it is free or not.Table 3 gives the contribution of each singlefeature in identifying Non-End Symbols.
Com-paring with the baseline system proposed in sec-tion 3.1, each feature could achieve obviousincrease.
Therefore our attempt that building aclassifier to identify Free Symbols from Non-End Symbols is feasible.The results in Table 4 show that with featuresadded into classifier the performance raises ex-cept for the fifth one (Left preposition).
There-fore our final feature set will include nine fea-tures without the ?Left preposition?.At the same time, the top four features are allextended ones and they can achieve 81.83%accuracy while the basic features could onlyincrease the performance less than 1% (0.95%g).
This phenomenon indicates that the syntacticinformation can reflect the structural characte-ristics of Chinese clauses much better.
There-fore we hypothesize that we can use extendedfeatures only to build the classifier.Feature AccuracyChunkn (n?
[-4, 4]) 80.07Chunk sequence 76.51Predicate number 75.40Location 69.57Left preposition 69.40Wordsn/POSn (n?
[-4, 3]) 68.77Left verb 68.77Current POS 66.81Adjacent Non-End Symbols 66.33Adjacent brackets 66.19Table 3.
Accuracy and rank of each featureFigure 2.
Performance of Wordsn/POSnFigure 3.
Performance of Chunkn feature un-der different context windowsFeature AccuracyChunkn (n?
[-4, 4]) 80.07(+)Chunk sequence 80.43(+)Predicates number 80.87(+)Location 81.83(+)Left preposition 81.67(+)Wordsn/POSn (n?
[-4, 3]) 81.93(+)Left verb 82.04(+)Current POS 82.12(+)Adjacent Non-End Symbols 82.43(+)Adjacent bracket 82.78Table 4.
Accuracy with adding features ondevelopment data set.68.775055606570[0 ,1] [-1,1] [-2,1] [-2,3] [-3,3] [-4,3] [-4,5] [-5,5]80.0765707580[0,1] [-1,1] [-2,1] [-2,3] [-3,3] [-4,3] [-4,5] [-5,5]4.2 Evaluating System PerformanceWith the feature set selected in section 4.1, theEDC identification system can be built.
Thetotal 14,248 sentences are included to train theclassifier for classifying the Non-End Symboland all test material is used for evaluating theperformance of clause recognition.We consider different modes to evaluate theclause recognition system.
One is only using theextended features provided by automatic syntac-tic parser to validate our guess that the syntacticfeatures are so effective that they will achievesatisfying result without other accessional fea-tures (mode_1).
The second mode is adding ba-sic word features along with syntactic ones toget the best performance that our current systemcan obtain (mode_2).
Since the chunk featuresused in this classifier are from the automaticanalyses.
To clear the influence caused by au-tomatic parsing, we use the lowest level correctchunks to provide syntactic features in the thirdmethod.
The entirely correct chunks are pro-vided by CIPS-ParsEval-2009 FC bank (Zhouand Li, 2009).
As EDC is defined as the de-scription of a high level event, we guess that thehighest level chunks might provide more effec-tive information.
For example, for the same in-put sentence ????????????????
?/ the freight trucks and tractors goingsouth and north?,  its high level chunk sequencewill be ?
[S ???????????
(freighttrucks and tractors)]?[P????
(going southand north)]?.Then model_4 will use the golden-standard high level chunk features extractedfrom relevant TCT (Zhou et al, 1997) to clearthe upper bound of system performance.The evaluation measure is defined as follows,and we only use the F-score.Recall =Correctly  recognized  clausesTotal  correct  clauses(b)Precision =Correctly  recognized  clausesTotal  recognized  clauses(c)F?
score =2?Precision ?RecallPrecision +Recall(d)Recognition performances of the four modesare shown in Table 5.In order to deal with some special conditionsthat our classifier cannot treat well to improvethe performance of whole system, a simple rule-based post processing phase is designed which aimsat rectifying wrong recognized sentence-leveladverbial and independent composition, that is:When there are only two EDCs are recog-nized in a sentence and one of which is an ad-verbial or independent composition, we simplyassume that these two EDCs should be mergedinto a single big EDC.To estimate the benefit of post-processing,we compare the performances before/after add-ing post-processing.
The contrasts are shown inTable 6.mode1 mode2 mode3 mode4ClassifierAccuracy79.64 80.60 83.46 93.34SystemF-score77.71 78.77 81.29 89.57ModelSize181KB2.2MB/ /TrainingTime3.7s 12.6s / /Table 5.
Performances on four modelsmode1 mode2 mode3 mode4F-score(Before)77.71 78.77 81.29 89.57F-score(After)79.43?
1.7281.32?2.5584.04?2.7590.65?1.08Table 6.
The Performance changes caused bypost-processingThe first line of Table 5 is the accuracy ofNon-End Symbol classifier and the second oneshows the F-score of whole EDC recognitionsystem.
From the two lines we can get this con-clusion that the performance of whole systemwill increase along with the advancement ofclassifier.
We also find that the system perfor-mance under automatic lowest level chunk fea-ture does not drop too much comparing with theone under gold-standard chunks (less than 3%),which means existing syntactic parser is goodenough to provide the low level chunk features.However, the recognition F-score will increaseto nearly 91% when standard high level chunkfeatures are used, which proves that the rela-tionship between high level functional chunksand our defined EDCs are much closer that theyare more efficient in recognition.
Therefore wecan try to build a good high level chunk parserin future.
Results of  mode_1 and mode_2 showthat comparing with the classifier that uses allfeatures, using only syntactic features can savenearly three times of training time and occupyonly 1/10 storage space without losing too muchreorganization performance.
It tells us that whentime and storage space is limited we can just usesyntactic features.Table 6 presents the impact of our post-processing.
We can find that the processing iseffective though it is simple.
This result alsoreflects that current classifier has difficulties todistinguish whether an adverbial or independentcomposition is at sentence-level or clause-level.5 Discussions5.1 EDC Error TypesBecause different EDC recognition errors(too long or too short) might cause differentproblems, we define three error types accordingto the boundary differences between the recog-nized EDCs and the gold-standard ones.
(1) ?1: N?
error: The boundary of a recog-nized EDC is wider than the gold-standard one.
(2) ?N: 1?
error: The boundary of a gold-standard EDC is wider than the recognized one.
(3) ?N: M?
error: Several recognized EDCsand the gold-standard ones are crossed on theirboundaries.We do some statistical analysis on all 1584wrongly recognized EDCs and Table 7 displaysthe distributional ratios of each error type.Error type 1:N N:1 N:MRatio (%) 59.2 38.9 1.9Table 7.
Distribution of different EDC recog-nition errors5.2 Error Analysis(1) 1:N ErrorWhen this error happens, it will have no ter-rible effect on the final whole parse tree if therelations between this wrong recognized EDCand other EDCs remain the same.
Like the ex-ample sentence in Figure 1, if the second andthe third EDCs are wrong recognized as a singleone, it will become a little troublesome to parsethis EDC as its length is longer than it should bebut the tree it builds with other two EDCs willnot change.
However, if the wrong EDC causesrelationship changes, the parse errors mighthappen on the complete tree.
In our system 1: Nerrors are mainly the following three types:I.
Several sentence-level adverbials are com-bined.II.
Adjacent EDCs are recognized as a subjector object that they are regarded as a single EDC.III.
Several adverbials at different levels aremerged to be one adverbial incorrectly.For the following sentence:?
[D ??????]?
[D ??????????]?
[E1 ?????????????]
[E2 ?????????]?
[E1 ??????????]??
[D For 4.6 billion years], [D in theprocess of the formation of the earth'ssurface], [E1 the climate change regularlyon land], [E2 the phenomenon presentsclearly in the mid-latitude regions], [E1organisms develop from ocean to land].If the first two adverbials are recognized as asingle one, error I happens.
Then error II occurswhen E1 and E2 are merged into one EDC.
Ifthe adverbial ?????
/on land?
of E1 iswrongly recognized as sentence-level and  ismerged to its adjacent adverbial ??????????
?/in the process of the formation ofthe earth?s surface?, the third error appears.The previous two error conditions may notaffect the final parser tree and could be regardedas ?tolerable?
error.
The third situation willchange the relationships within EDCs that mightaffect following parser.
(2) N:1 ErrorN: 1 error mainly includes three sub-types.I.
Complex coordinate structure/adverbialclause/attributive clause is wrong separated.II.
Complex subject/object clause is divided.Conditions II is the reflections of sub-type IIin 1: N error.
Therefore it is ?tolerable?
error.The first errors are caused by complex sentence-like component, like in Figure 1, when thecomma in the second EDC is classified as End-Symbol, the error occurs.
To solve this problem,one proper method is to consider some featuresof the relationship between two adjacent possi-ble EDCs.
Another way is trying to implementhigh level chunk parser that can provide sen-tence-level features instead of current bottomfunctional chunks.
(3) N:M ErrorThe proportion of this error is less than 2%that we will not pay much attention to it now.6 Related worksThere have already been some systems forclause identification.
Abney (1990) used aclause filter in his CASS parser.
The filter couldrecognize basic clauses and repair difficult cases.Leffa (1998) implemented an algorithm for findingclauses in English and Portuguese texts.
He wrote aset of clause identification rules and applied them toa small corpus and achieved a good performancewith recall rates above 90%.
Orasan (1990) used ahybrid method for clause splitting in the Susannecorpus and obtained F-score of about 85% for thisparticular task.
In the CoNLL-2001 shared task(Erik F et al, 2001), six systems had participatedto identify English clauses.
They used various ma-chine learning techniques and connectionist me-thods.
On all three parts of the shared task, theboosted decision tree system of Carreras and Mar-quez (2001) performed best.
It obtained an F-scoreof 78.63.However, as English and Chinese clauseshave different characteristics, the researches onEnglish sometimes ignore punctuation, especial-ly the comma, or they just use a comma as onefeature to detect the segmentation without fullyusing the information of punctuations.In Chinese, Jin (2004) gave an analysis forthe complete usages of the comma.
Li (2005)tried to use punctuations to divide long sentenceinto suitable units to reduce the time consump-tion in parsing long Chinese sentences.
Theirprocessing based on simply rules.
Yu (2007)proved that using clause recognition to divide asentence into independent parts and parse themseparately could achieve extremely significantincrease on dependency accuracy comparedwith the deterministic parser which parsed asentence in sequence.
The CIPS-ParsEval-2009(Zhou and Li, 2009) put forward a task to iden-tify the Chinese EDC and six systems partici-pated.
Based on the idea of ?HNC?
(1998), Wei(2009) used a semantic knowledge corpus toidentify EDCs and achieved the performance ofF-score 80.84 (open track).
Zhou (2009) formu-lated the task as a sequence labeling problemand applied the structured SVMs model.
Theirperformance was 78.15.
Wang (2009) also re-garded the task as a sequence labeling problemand considered the CRFs to resolve this prob-lem and got an F-score of 69.08.
Chen and Zhou(2009) presented a classification method thatidentified the boundaries of EDCs using maxi-mum entropy classifier, and the system obtainedan F-score of 79.98.Based on our previous work, some new fea-tures are introduced and the performance ofeach feature is evaluated, our identification sys-tem achieved an F-score of 81.32.
At the sametime, the comparison between two differentchunk levels show that high level chunk fea-tures are much more powerful that we can de-vote ourselves to building a good high levelparser in future to increase the performancefarther.7 ConclusionsIn this paper, we compare the different characte-ristics between Chinese language and English,and define a new Chinese clause called ?EventDescriptive Clause (EDC)?.
Then on the basisof this definition, we propose an effective me-thod for Chinese EDC identification.Our work focus on the commas which areusually useful in Chinese clause recognition butalways ignored by researchers, and tries differ-ent types of features through experiments toclear their different effects in identifying EDCboundaries from commas.
At the same time, ourstatistical model is combined with useful rulesto deal with the recognition task better.
Finallyour automatic EDC recognition system achieved81.32 of F-score, which is higher than other sys-tems based on the same data set.Meanwhile, error analyses show that the cur-rent identification system has some problems.Therefore we propose several possible methods,expecting to solve these problems and improvethe recognition ability of EDC recognition sys-tem in future.AcknowledgementsThis work was supported by National NaturalScience Foundation of China (No.
60573185,60873173), National High Technology Re-search and Development Projects 863 (No.2007AA01Z173) and Tsinghua-Intel Joint Re-search Project.ReferencesAbney Steven, ?Rapid Incremental Parsing with Re-pair?.
In "Proceedings of the 8th New OED Con-ference: Electronic Text Research", University ofWaterloo, Ontario, 1990.Carreras, X. and Marquez, L. ?Boosting Trees forClause Splitting?.
In ?Proceedings of CoNLL-2001?, Toulouse, France, pp 73-75, 2001.Chen Liou, Zhou Qiang.
?Recognition of Event De-scriptive Clause?.
In ?Proceedings of the 1stCIPS-ParsEval?, Tsinghua University, Beijing,pp.65-72.
2009.Ejerhed Eva I., ?Finding Clauses in UnrestrictedText by Finitary and Stochastic Methods,?
In?Proceedings of ANLP ?88?, pp.219-227, 1998.Erik F. Tjong Lim Sang and D?jean H. ?Introductionto the CoNLL-2001 Shared Task: Clause Identifi-cation [A]?.
In Proc.
of CoNLL-2001 [C], Toul-ouse, France, p53-57, 2001.Huang Zengyang.
?Theory of Hierarchical Networkof Concepts?.
Tsinghua University Press, Beijing,1998.Jin Meixun, Mi-Yong Kim, Dongil Kim and Jong-Hyeok Lee.
?Segmentation of Chinese Long Sen-tences Using Commas?.
Proc.
SIGHAN, Barcelo-na, Spain, pp.
1-8, 2004.Leffa, Vilson J.
?Clause processing in complex sen-tences, In ?Proceedings of LREC'98?, Granada,Espanha, 1998.Li Xing and Chengqing Zong.
?A Hierarchical Pars-ing Approach with Punctuation Processing forLong Complex Chinese Sentences.?
In Compa-nion Volume to the Proceedings of Conferenceincluding Posters/Demos and Tutorial Abstracts,IJCNLP2005, Jeju Island, Korea, pp.9-14, 2005.Orasan Constantin.
?A hybrid method for clausesplitting in unrestricted English texts?.
In ?Pro-ceedings of ACIDCA'2000?, Monastir, Tunisia,2000.Wei Xiangfeng, ?Labeling Functional Chunk andEvent Sentence Based on the Analysis of Sen-tence Category?.
In ?Proceedings of the 1st CIPS-ParsEval?, Tsinghua University, Beijing, pp.57-64,2009.Wang Xi, Wang Jinyong, Liu Chunyang, Wang Qi,and Fu Chunyuan.
?CRF-based Chinese Chunkingand Event Recognition?.
In ?Proceedings of the1st CIPS-ParsEval?, Tsinghua University, Beijing,pp.53-56.
2009.Yu Hang.
?Automatic Analysis of Chinese Chunks?,Graduation thesis of computer science, TsinghuaUniversity?2007.Yu Kun, Sadao Kurohashi and Hao Liu.
?A Three-Step Deterministic Parser for Chinese Dependen-cy Parsing?.
In ?Proceedings of the Human Lan-guage Technologies 2007 (HLT2007-NAACL2007)?, Rochester, pp.201-204, 2007.Zhou Junsheng, Yabing Zhang, Xinyu Dai, JiajunChen.
?Chinese Event Descriptive Clause Split-ting with Structured SVMs?.
In ?Proceedings ofthe 1st CIPS-ParsEval?, Tsinghua University, Bei-jing, pp.73-80, 2009.Zhou Qiang, Yumei Li.
?The Testing Report ofCIPS-ParsEval-2009 Workshop?.
In ?Proceedingsof the 1st CIPS-ParsEval?, Tsinghua University,Beijing, 2009.Zhou Qiang.
?Annotation Scheme for Chinese Tree-bank?.
Journal of Chinese Information Processing,pp 18-21, 2004.Zhou Qiang, Yume Li.
?The Design of ChineseChunk Parsing Task??
The Tenth Chinese Na-tional Conference on Computational Linguistics(CNCCL-2009)?Tsinghua University Press, Bei-jing,  pp.130-135, 2009Zhou Qiang, Wei Zhang, Shiwen Yu, ?ChineseTreebank Construction?, Journal of Chinese In-formation Processing, pp42-51, 1997.
