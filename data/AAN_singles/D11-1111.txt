Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1202?1212,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsComputing Logical Form on Regulatory Texts?Nikhil DineshArtificial Intelligence CenterSRI InternationalMenlo Park, CA - 94025dinesh@ai.sri.comAravind Joshi and Insup LeeDepartment of Computer ScienceUniversity of PennsylvaniaPhiladelphia, PA - 19104{joshi,lee}@seas.upenn.eduAbstractThe computation of logical form has been pro-posed as an intermediate step in the translationof sentences to logic.
Logical form encodesthe resolution of scope ambiguities.
In thispaper, we describe experiments on a modest-sized corpus of regulation annotated with anovel variant of logical form, called abstractsyntax trees (ASTs).
The main step in com-puting ASTs is to order scope-taking opera-tors.
A learning model for ranking is adaptedfor this ordering.
We design features by study-ing the problem of comparing the scope of oneoperator to another.
The scope comparisonsare used to compute ASTs, with an F-score of90.6% on the set of ordering decisons.1 IntroductionMay (1985) argued for a level of logical form as aprelude to translating sentences to logic.
Just as aparse tree determines the constituent structure of asentence, a logical form of a sentence represents oneway of resolving scope ambiguities.
The level oflogical form is an appealing layer of modularity; itallows us to take a step beyond parsing in studyingscope phenomenon, and yet, avoid the open problemof fully translating sentences to logic.Data-driven analyses of scope have been of in-terest in psycholinguistics (Kurtzman and MacDon-ald, 1993) and more recently in NLP (Srinivasanand Yates, 2009).
The focus has typically been?This research was supported in part by ONR MURIN00014-07-1-0907, NSF CNS-1035715, NSF IIS 07-05671,and SRI International.on predicting the preferred scopal ordering of sen-tences with two quantifying determiners, for exam-ple, in the sentence ?every kid climbed a tree?.
Inthe related problem of translating database queriesto logic, Zettlemoyer and Collins (2009) and Wongand Mooney (2007) consider the scope of adjectivesin addition to determiners, for example the scope of?cheapest?
in the noun phrase ?the cheapest flightsfrom Boston to New York?.
To our knowledge, em-pirical studies of scope have been restricted to phe-nomenon between and within noun phrases.In this paper, we describe experiments on a novelannotation of scope phenomenon in regulatory texts?
Section 610 of the Food and Drug Administra-tion?s Code of Federal Regulations1 (FDA CFR).Determiners, modals, negation, and verb phrasemodifiers are the main scope-taking operators.
Wehave annotated 195 sentences with a variant of log-ical form, called abstract syntax trees (ASTs).
Ourfocus is on the problem of computing the AST, givena (variant of a) parse tree of a sentence.The long term goal of this work is to assist in thetranslation of regulation to logic, for the applicationof conformance checking.
The problem is to for-mally determine whether an organization conformsto regulation, by checking the organization?s recordsusing the logical translation of regulation.
Confor-mance checking has been of interest in a variety ofregulatory contexts, and examples include privacypolicy (Barth et al, 2006; Jones and Sergot, 1992;Anderson, 1996) and business contracts (Governa-tori et al, 2006; Grosof et al, 1999).We now discuss some problems that arise in defin-1http://www.gpoaccess.gov/cfr/index.html1202ing logical form and the assumptions that we maketo circumvent these problems.1.1 Problems and AssumptionsA key assumption of logical form is that the trans-lation from language to logic is syntax-based.
Asa result, the logic needs to be expressive enough toaccomodate a syntactic translation.
There is no con-sensus logic for constructs, such as, plurals, purposeclauses, and certain modals.
This leads to the fol-lowing problem in defining logical form.How do we define the logical form of a sentence,without defining the logic?
We adopt a specific for-malism that accomodates a subset of the constructsfound in regulation.
We generalize from the formal-ized constructs to other constructs.
Some of thesegeneralizations may need revision in the future.We assume that sentences in regulation are trans-lated to statements in logic of the form:(id) ?
(x1, ..., xn) 7?
?
(x1, ..., xn)where, ?id?
is an identifier, ?
is the precondition,?
is the postcondition, and x1, ..., xn are free vari-ables.
The distinction between pre and postcondi-tions has been adopted by most logics for regula-tion, to accomodate exceptions to laws (Sergot et al,1986; Makinson and van der Torre, 2000; Governa-tori et al, 2006).
The pre and postconditions areexpressed in a modal logic that we designed in priorwork (Dinesh et al, 2011).
In describing the logi-cal form, we will sketch how the logical form canbe mapped to logic.
But, we do not assume that thereader has a detailed understanding of the logic.Given the assumptions about the logic, our goalis to transform a regulatory sentence into a structurethat lets us determine: (I) the constituents of a sen-tence that contribute to the pre/postcondition, and(II) the scope of operators in the pre/postcondition.The structures that we use are called abstract syn-tax trees (ASTs), which can be understood as a re-stricted kind of logical form for regulatory texts.1.2 Contributions and OutlineIn this paper, we focus on the problem of computingthe AST given a (kind of) parse tree for a sentence.The main step is is to order or rank scope-takingoperators.
A learning model for ranking is adaptedfor this ordering.
We design features by studying theproblem of comparing the scope of one operator toanother.
The pairwise scope comparisons are thenused to compute ASTs, with an F-score of 90.6% onthe set of ordering decisons.The rest of this paper is organized as follows.
Wedefine ASTs using an example in Section 2, andsetup the learning problem in Section 3.
We then de-scribe the corpus using statistics about operators inSection 4.
In Section 5, we describe experiments oncomparing the scope of an operator to another.
Weuse the pairwise scope comparisons, in Section 6 tocomput the AST.
We discuss related work in Sec-tion 7 and conclude in Section 8.2 Abstract Syntax TreesWe describe abstract syntax trees (ASTs) using anexample from CFR Section 610.11:(1) A general safety test for the detection of extra-neous toxic contaminants shall be performed onbiological products intended for administrationto humans.We discuss the translation in logic and the ASTfor the fragment of (1) that appears in black.
In or-der to keep figures to a manageable size, we restrictattention to fragments of sentences, by graying outportions.
The term AST is borrowed from compil-ers (Aho et al, 1986), where it is used as an interme-diate step in the semantic interpretation of programs.Translation in Logic: The sentence (1) is formallyexpressed as:(1) bio prod(x) 7?
Om(x)(?y : test(y) ?
?
(x, y))where, ?
(x, y) = gensaf(y)?ag(y,m(x))?ob(y, x)The predicates and function symbols are read asfollows.
bio prod(x) - ?x is a biological product?.m(x) denotes the manufacturer of x.
The modal op-erator O stands for ?obligation?.
test(y) - ?y is atest (event)?.
gensaf(y) - ?y is a general safety pro-cedure?.
ag(y,m(x)) - ?the agent of y ism(x)?, andob(y, x) - ?the object of the event y is x?.
The for-malized version of the law is read as follows: ?If xis a biological product, then the manufacturer m(x)is required/obligated to perform a general safety testy which has x as its object?.
We refer the readerto (Dinesh et al, 2011) for details on the logic.1203The distinction between pre and postconditionsis a non-trivial assumption.
As with all logic-programming formalisms, only free variables are?shared?
between pre and postconditons.
This im-plies that all existential quantification, modals, andnegation appear within the pre or postcondition.
Inthe example above, the existential quantifier (?y)and the modal (O) appear within the postcondition.Abstract Syntax Tree: The AST for (1) is shown inFigure 1.
The main nodes of interest are the inter-nal nodes labeled ?
.
An internal node with n + 1children corresponds to an n-ary operator.
The firstchild of the internal node is the operator.
Opera-tors are labeled with a part-of-speech tag, for exam-ple, ?D?
for determiner, ?M?
for modal, and ?O?
forother.
The remaining n children are its arguments.We use the term nuclear scope to refer to the last(nth) argument of the operator, and the term restric-tor to refer to any other argument.
We borrow theseterms from the literature on quantifier scope for de-terminers (Heim and Kratzer, 1998, Chapter 7).For example, the phrase ?general safety test?
is inthe restrictor of the operator A, and the variable yis in its nuclear scope.
The modal shall is a unaryoperator, and doesn?t have a restrictor.
Non-unaryoperators bind the variable displayed on the internalnode.
The variable y is bound by the operator A.Implicit operators are inserted when there is noovert word or phrase.
In Figure 1, the implicit oper-ators are underlined.
The generic noun phrase ?bi-ological products?
is associated with the implicit de-terminer all.
Similarly, we use the implicit operatorPost to mark the position of the postcondition.?xDallRbio.
prod.?OPost?Mshall?Mbe?yDARgen.
saf.
test.y performed on xFigure 1: Example of an abstract syntax tree (AST).We conclude this section with some notation fordescribing ASTs.
Given an AST for a sentences, wesay that an operator oi scopes over oj, denoted oioj, if oj appears in the nuclear scope of oi.
For ex-ample, in Figure 1, we have all  Post, all  shall,all  A, Post  A, and shall  A.
In addition, wesay that the restrictor of oi scopes over oj, denotedR(oi)  oj, if oj appears in the restrictor of oi.
Suchconfigurations occur with PP-modification of NPs,and we discuss examples in later sections.3 Computing ASTs ?
OverviewIn this section, we give an overview of our approachto computing ASTs.
We will assume as given a Pro-cessed Parse Tree (PPT) of a sentence, with the op-erators and their restrictors identified.
An exampleis discussed in Section 3.1.
Given such a PPT, theAST is computed in two steps: (1) finding the preter-minal at which an operator takes scope, and (2) or-dering the operators associated with a preterminal.We describe the second step in Section 3.2, and thenbriefly outline the first step in Section 3.3.
The stepsare described in reverse order, because in most cases,the operators associated with a preterminal are deter-mined directly by syntactic attachment.3.1 Processed Parse TreesWe compute ASTs from processed parse trees(PPTs) of sentences.
Figure 2 gives the PPT cor-responding to the AST in Figure 1..?PPost?yDARgen.
saf.
test?Mshall?Mbe.performed on?xDIMPRbio.
prod.Figure 2: Processed parse tree (PPT) for (1).A PPT provides the set of operators in a sen-tence, associated with their restrictors.
For exam-ple, the determiner ?a?
has the restrictor generalsafety test.
The phrase biological products has noexplicit determiner associated with it, and the cor-responding operator in the PPT is labeled ?IMP?for implicit.
In addition, the postcondition marker?Post?
is also identified.
Except for the postcon-1204dition marker, annotator-specified implicit operatorsare not given in the PPT.There are two main types of nodes in the PPT ?operators and preterminals.
The nodes labeled withthe symbol ?, e.g., ?
and ?x , correspond to op-erators.
The root of the PPT and the restrictors ofthe operators, are the preterminals.
Based on thisexample, it may seem that a sentence just has a listof operators.
While this is true of example (1), em-bedded operators arise, for example, in the contextof PP-modification of NPs and relative clauses.
Wewill discuss an example in Section 3.3.In this work, the PPTs are obtained by removingall scope decisions from the AST.
To a first approxi-mation, we start by removing all operators from theAST, and then, replace the corresponding variablesby the operators.
Implicit unary operators (such asthe postcondition marker) are placed at the start ofthe preterminal.It is worthwhile to consider whether it is rea-sonable to assume PPTs as given.
We believe thatthis assumption is (slightly) stronger than assumingperfect parse trees.
Although the PPT leaves cer-tain chunks of the sentence unprocessed, in mostcases, the unprocessed chunks correspond to baseNPs.
The main additional piece of information is theexistence of a postcondition marker for each mainclause of a sentence.
We believe that computationof PPTs is better seen as a problem of syntax ratherthan scope, and we set it aside to future work.
Ourfocus here is on converting a PPT to an AST.3.2 Ordering OperatorsThe problem of learning to order a set of items isnot new.
Cohen et al (1998) give a learning theo-retic perspective, and Liu (2009) surveys informa-tion retrieval applications.
The approach that we usecan be seen as a probabilistic version of the boostingapproach developed by Cohen et al (1998).
We ex-plain the step of ordering operators, by revisiting theexample of the general safety test, from Section 2.Given the PPT in Figure 2, we compute the ASTin Figure 1 by ordering or ranking the operators.
Forexample, we need to determine that the implicit de-terminer associated with biological products is uni-versal, and hence, we have IMP  Post.
However,the determiner ?A?
associated with general safetytest is existential, and hence, we have Post  A.We now develop some notation to describe thescopal ordering of operators.
A PPT ?
is viewedas a set of preterminal nodes, and we will write ?
(a) p ?
?
to denote that p occurs in ?
, and (b)|?
| to denote the number of preterminals in ?
.
Apreterminal p is viewed as an ordered set of oper-ators p = (o1, ..., o|p|).
For example, in Figure 2,the root preterminal p has |p| = 5, and the operatorso1 = Post, o2 = A, o3 = shall, and so on.An AST ?
contains a ranking of operators asso-ciated with each preterminal, denoted r?(p).
Theranks of operators are denoted by subscripts.
Letp = (o1, ..., o5) be the root preterminal of the PPTin Figure 2.
The ranking associated with the AST inFigure 1 is given by r?
(p) = (o12, o25, o33, o44, o51).
Forexample, o25 = A denotes that the determiner ?A?
ap-pears second in the surface order (Figure 2) and fifthor lowest in the scope order (Figure 1).
Similarly,o51 = IMP denotes that the implicit determiner ap-pears fifth or last in the surface order (Figure 2) andfirst or highest in the scope order (Figure 1).
Notethat the subscript suffices to identify the position ofan operator in the AST.Model: We now describe the learning model for or-dering operators.
Given a PPT ?
, let A(?)
be the setof all possible ASTs.
Our goal is to find the ASTwhich has the highest probability given the PPT:??
= arg max??A(?
)P (?|?
)The conditional probability of an AST is defined as:P (?|?)
=?p?
?P (r?(p)|?
)P (r?(p)|?)
=|p|?1?i=1|p|?j=i+1P (oi  oj|?
)In other words, P (?|?)
is modeled as the productof the probabilities of the ranking of each pretermi-nal, which is in turn expressed as the product of theprobabilities of the pairwise ordering decisions.
Themodel falls under the class of pairwise ranking ap-proaches (Liu, 2009).
We will consider the problemof estimating the probabilities in Section 5, and theproblem of searching for the best AST in Section 6.1205.?PPost?x3DIMPRsamp.
of?x1DanyR.lot of?x2DaRlic.
prod.
?Mmay?Mbe....Figure 3: PPT for (2)?x1DanyR?x2DaRlic.
prod..lot of x2?PPost?Mmay?Mbe?x3DsomeRsamp.
of x1....Figure 4: AST for (2)3.3 Finding the Scope PreterminalIn the example that we discussed in the previous sec-tion, there were no embedded operators, i.e., an op-erator or its variable located in the restrictor of an-other.
An embedded operator can either ?
(a) takescope within the restrictor of the embedding oper-ator, or (b) outscope the embedding operator.
Toaccount for the second case, we need to determinewhether it is appropriate to lift an embedded opera-tor to a higher preterminal than the one to which itis associated syntactically.We discuss an example of inverse linking (Larson,1985) to illustrate the problem.
Consider the follow-ing sentence:(2) Samples of any lot of a licensed product, exceptfor radioactive biological products, together withthe protocols showing results of applicable tests,may at any time be required to be sent to the Di-rector, Center for Biologics Evaluation and Re-search.The PPT and AST for (2) are shown in Figures 3and 4 respectively.
Consider the noun phrase ?IMPsamples of any lot of a licensed product?
in the.
?PPost?x1DanyR.lot of?x2DaRlic.
prod.?x3DIMPRsamp.
of x1?Mmay?Mbe....Figure 5: Second PPT for (2), obtained from the PPT inFigure 3, by raising any to the root preterminal.PPT.
The implicit determiner IMP in the PPT is in-terpreted as the existential determiner some in theAST.
The three operators are related as follows inthe AST: any  some and R(any)  a, i.e., anyoutscopes the implicit determiner, and a appears inthe restrictor of any.
Observe that the variables x1and x2 , which are associated with any and a, ap-pear in the restrictors of some and any respectively.As a result, in the PPT, in Figure 3, any and a appearin the restrictor of IMP and any.
The PPT providesa standard parse of PP-modification of NPs.The important feature of this example is thatthe determiner ?any?
is syntactically embedded inthe restrictor of IMP in the PPT (Figure 4), but itoutscopes the implicit determiner in the AST (Fig-ure 3).
As a result, the PPT in Figure 3 cannot beconverted to the AST in Figure 4 simply by rankingsibling operators (as we did in the previous section).To handle such cases, we convert the PPT in Fig-ure 3 to a second PPT (shown in Figure 5).
The onlyallowed operation during this conversion is to raisean embedded operator to a higher preterminal.
ThePPT in Figure 5 is obtained by raising any to theroot preterminal, making it a sibling of the implicitdeterminer IMP in the PPT in Figure 5.
This secondPPT can be converted to the AST by reordering sib-ling operators.
The learning model used for this stepis similar to the one used to order operators, and inthe interests of space, we omit the details.4 Brief Overview of the CorpusWe have annotated 195 sentences from the FDACFR Section 610 with ASTs.
The operators are di-vided into the following types ?
determiners (e.g.,1206every, a, at least), modal auxiliaries (e.g., must,be), VP modifiers (e.g., if, for, after), negation andcoordinating conjunctions (e.g., and, but, or).
Themajority of the corpus was annotated by a single an-notator.
However, to estimate inter-annotator agree-ment, a set of 32 sentences was annotated by asecond annotator.
In this section, we restrict our-selves to presenting statistics that highlight part ofthe guidelines and motivate the features that we useto order operators.
An example-based justificationof guidelines, and a discussion of inter-annotatoragreement can be found in (Dinesh, 2010).De Re vs De Dicto: We narrow our focus to one partof the annotation, the de re vs de dicto distinction.Informally, operators with de re scope occur in theprecondition of the logical translation of a sentence,while those with de dicto scope occur in the post-condition.
This distinction is of key importance inthe application of conformance checking, as it helpsdetermine the facts that need to be provided by anorganization (de re), and the actions that an organi-zation is required to take (de dicto).For simplicity, we further restrict attention to op-erators that are siblings of the postcondition in theAST, and ignore the operators embedded in preposi-tional phrases and clauses, for example.
A (mainclause) operator o is said to have de re scope iffit outscopes the postcondition marker (o  Post).Otherwise, the operator is said to have de dicto scope(Post  o).
In the example of the general safety testfrom Section 2, the implicit determiner associatedwith ?biological products?
has de re scope, while allother operators in the sentence have de dicto scope.Operator Number of De Re ScopeType Instances PercentageDeterminer 277 59.9%Modal Aux 268 0%VP Modifier 132 68.2%CC 36 22.2%Neg 33 0%Other 74 17.6%Table 1: De Re scope distribution.
An operator has de rescope iff it outscopes the postcondition marker.Table 1 shows the percentage of each type of op-erator that has de re scope.
Modal auxiliaries andnegation are umambigous to this distinction, and al-ways have de dicto scope.
Note that a type of opera-tor with 50% occuring de re is ambiguous, while 0%or 100% are unambiguous.
Thus, from Table 1, wecan conclude that determiners, and VP modifiers arethe most ambiguous types.
And, more features areneeded to disambiguate them.Determiner Number of De Re ScopeType Instances PercentageUniversal 74 100%Existential 12 0%Ambiguous 50 28%Deictic 127 53.5%Other 14 35.7%Table 2: De Re scope distribution for determiners.Determiners: We divide the determiners into thefollowing subtypes: universal/generic (e.g., every,all), existential (some), ambiguous (e.g., a, an), de-ictic (e.g., the, those), and other (e.g., at least, atmost).
The guidelines for annotation were as fol-lows ?
(a) universal determiners have de re scope,(b) existential determiners have de dicto scope, and(c) for other determiners, the annotator needs to de-cide whether a particular use is interpreted existen-tially or universally.
Table 2 shows de re scope dis-tribution for each of these subtypes.
As expected,universal and existential determiners are unambigu-ous, while ambiguous and deictic determiners showmore variety.
For example, the deictic determinerthe can refer to a specific entity (?the FDA?)
or havea universal interpretation (?the products?
).Thus, to disambiguate between de re and de dictointerpretations for determiners, we need two types offeatures ?
(1) Features to predict whether ambiguousand deictic determiners are universal or not, and (2)Features to determine the type of implicit determin-ers.
In Table 2, we assume that the type of implicitdeterminers are given.
This assumption is unreal-istic.
Rather, we need to predict the type of suchdeterminers, during the computation of the AST.VP Modifier Number of De Re ScopeType Instances PercentageTemporal and Conditional 73 100%Purpose 8 0%References to Laws 33 0.9%Other 29 65.5%Table 3: De Re scope distribution for VP modifiers.1207VP Modifiers: We divide the VP modifiers into thefollowing subtypes: temporal and conditional (e.g.,after, if), purpose (for), references to laws (whichare a special type of modifier in the legal domain,e.g., ?as specified in paragraph (c)?
), and other (e.g.,regardless, notwithstanding).
Table 3 shows thepercentage of each subtype of modifier that has dere scope.
Following the guidelines for annotation,the temporal and conditional modifiers are always dere, the purpose modifiers and modifiers conveyingreferences to laws are always de dicto.5 Comparing the Scope of OperatorsWe now consider a subproblem in computing theAST ?
comparing the scope of pairs of operators.In Section 6, we will use the classifiers that performcomparisons, to compute the AST.
All experimentsin this section use the MAXENT implentation fromthe MALLET toolkit (McCallum, 2002).
We beginby revisiting de re-de dicto distinction from Sec-tion 4.
Then, we generalize to other comparisons.De Re vs De Dicto: The (binary) classificationproblem is as follows.
Our observations are triplesx = (o, o?, ?)
are such that there is a preterminalp ?
?
, {o, o?}
?
p, and o?
= Post.
In other words,we are considering operators (o) that are siblings ofthe postcondition marker (o?).
An observation hasthe label 1 if o  o?
(de re scope), and a label of 0otherwise (de dicto scope).Features: We use the following (classes of) fea-tures for an observation x = (o, o?, ?):?
TYPE - The type and subtype of the operator.We use the subtypes from Section 4 only forexplicit operators.?
PRE-VERB - Tracks whether o and o?
appearbefore or after the main verb of the sentence.?
PRE-VERB + PERF - Conjunction of the previ-ous feature with whether the main verb is per-form.
The verb perform is frequent in the CFR,and its subject is typically given de dicto scope,as it is the main predicate of the sentence.?
POS - The part-of-speech of the head word.
Forexample, for the noun phrase biological prod-ucts, the head word is products, and the POS isNNS (plural common noun).
And, this POS tagmay indicate a generic/universal interpretation.Count MAJORITY TYPE ALLAll 823 66.2% 84.1% 89.2%No MD 522 53.2% 74.9% 83.7%DT 277 59.9% 62.9% 81.2%Imp.
DT 100 69% 76%Table 4: De Re vs De Dicto classification.
Average accu-racies over 10-fold cross-validation.
The rows describethe subset of observations considered, and the columnsdescribe the subset of features used.Experiments: We evaluate the features by perform-ing 10-fold cross-validation.
The results are summa-rized in Table 4.
The rows describe the subset of ob-servations used.
?All?
includes all observations, ?NoMD?
excludes the modal auxiliaries, ?DT?
includesonly the determiners, and ?Imp.
DT?
includes onlyimplicit determiners.
The columns describe the fea-tures used.
MAJORITY is the majority baseline, i.e.,the accuracy obtained by predicting the most fre-quent class or the majority class.
The majority classis de dicto when all operators are considered (thefirst row), and de re in all other rows.
The TYPEcolumn gives the accuracy when only the type andsubtypes are used as features.
This column does notapply to implicit determiners, as the subtype infor-mation is unavailable.
And, finally, the ALL columngives the accuracy when all features are used.From Table 4, we can conclude that the TYPE fea-ture is useful in making the de re-de dicto distinc-tion, and further gains are obtained by using ALLfeatures.
The most dramatic improvement is for de-terminers, and indeed, our features were designedfor this case.
However, the performance gains arenot very high for implicit determiners, and furtherinvestigation is needed.Next, we apply the features to more general oper-ator comparisons.
The first row of Table 5 considersobservations x = (o, o?, ?
), where o and o?
are sib-lings, and predicts whether o  o?.
The second rowconsiders observations where o?
is embedded syn-tactically within o, and predicts whether R(o)  o?.In other words, the problem is to determine whethera syntactically embedded operator remains scopallyembedded, or whether it has inverse scope (see Sec-tion 3.3).1208Count MAJORITY TYPE ALLSiblings 2793 76.1% 83.3% 87.5%Embedded 5081 95% 95.3% 96.4%Table 5: Ordering siblings and embedded operators.Average accuracies over 10-fold cross-validation.
Thecolumns describe the subset of features used.6 From Operator Comparisons to ASTsWe now consider the problem of computing theAST given the classifiers for comparing operators.Section 6.1 describes the algorithms used.
In Sec-tion 6.2, we develop metrics to evaluate the com-putation of ASTs.
We conclude, in Section 6.3, byevaluating different algorithms using the metrics.6.1 AlgorithmsWe begin by discussing the intractability of the prob-lem of ranking or ordering operators.
Then, wesketch the search heuristics used.Intractability: The decision version of the rank-ing problem is NP-complete.
A similar result is es-tablished by Cohen et al (1998) in the context of aboosting approach to ranking.Theorem 1.
The following problem is NP-complete:Input: A PPT ?
, a preterminal p ?
?
, probabilitiesP (oi  oj|?
), and c ?
[0, 1]Output: Yes, if there is an ordering r such thatP (r(p)|?)
?
cThe proof is by reduction from ACYCLIC SUB-GRAPH (Karp, 1972) ?
finding a subgraph which isacyclic and has at least k edges.Heuristics: To order operators, we use a beamsearch procedure.
Each search state consists preter-minal, in which the first i ranks have been assignedto operators.
We then search over next states by as-signing the rank i+1 to one of the remaining opera-tors.
We used a beam size of 104 in our experiments.In most cases, the number of operators per preter-minal is less than 7.
As a result, the total numberof possible orderings is typically less than 7!, and abeam size of 104 is sufficient to compute an exact or-dering.
In other words, due to the size restrictions, inmost cases, beam search is equivalent to exact (ex-haustive) search.To handle embedded operators, we use a simplegreedy heuristic.
We enumerate the operators in theinitial PPT, corresponding to an in-order traversal.For each operator, we attach it to the most likely an-cestor, given the attachment decisions for the previ-ous operators.
This heuristic is optimal for the casewhere the depth of embedding is at most 1, which isthe common case.6.2 MetricsIn this section, we describe metrics used to evaluatethe computation of ASTs.
Let ?
be the initial PPT,?
the correct AST, and ??
the computed AST.
Wedefine accuracy at various levels.The simplest metric is to define accuracy at thelevel of ASTs, i.e., by computing the fraction of casesfor which ?
= ??.
However, this metric is harsh,in the sense that it does not give algorithms partialcredit for getting a portion of the AST correct.The next possible metric is to define accuracy atthe level of preterminals.
Let p be a preterminal.Note that ?
, ?
and ??
share the same set of preter-minals, but may associate different operators withthem.
We say that p is correct in ?
?, if it is asso-ciated with the same set of operators as in ?, andfor all {o, o?}
?
p, we have o  o?
w.r.t.
??
iffo  o?
w.r.t.
?.
In other words, the preterminalsare identical, both in terms of the set of operatorsand the ordering between pairs of operators.
Whilepreterminal-level accuracy gives partial credit, it isstill a little harsh, in the sense that an algorithmwhich makes one ordering mistake at a preterminalis penalized the same as an algorithm which makesmultiple mistakes.Finally, we consider metrics to define accuracy atthe level of pairs of operators.
Let p be a preter-minal.
The set Pairs(p, ?)
consists of pairs of op-erators (o, o?)
such that o and o?
are both associ-ated with p in ?, and o = o?
or o  o?.
The setPairs(p, ??)
is defined similarly using ??
instead of?.
Given the sets Pairs(p, ?)
and Pairs(p, ??
), pre-cision, recall, and f-score are defined in the usualway.
We leave the details to the reader.6.3 ResultsWe evaluate the following algorithms:1.
No Embedding ?
The AST is computed purelyby reordering operators within a preterminal inthe PPT.1209(a) SURFACE ?
No reordering is performed,i.e., the order of operators in the AST re-spects the surface order(b) TYPE ?
Using only type and subtype in-formation for the operators(c) ALL ?
Using all the features described inSection 52.
ALL+ ?
The initial PPT is transformed into asecond PPT before reordering (as described inSection 3.3).
All features are used.Prec.
Rec.
F p ?SURF.
86.9% 82.7% 84.6% 81% 4.2%TYPE 90.4% 86% 88.1% 83.6% 24.7%ALL 92% 87.6% 89.8% 85.1% 33.5%ALL+ 91.9% 89.4% 90.6% 85.9% 36.2%Table 6: Performance of the algorithms in computing theASTs.
Averaged over 10-fold cross-validation.
195 ASTsin total, an average of 8.6 preterminals per AST, and 1.8operators per preterminal.Table 6 summarizes the performance of the al-gorithms, under the various metrics.
The accura-cies are averaged over 10-fold cross-validation.
Atotal of 195 ASTs are used.
The average numberof preterminals per AST is 8.6, with an average of1.8 operators per preterminal.
The best number un-der each metric is shown in bold-face.
By addingfeatures, we improve the precision from 86.9% to90.4% to 92% in moving from SURFACE to TYPEto ALL.
By handling embedded operators, we im-prove the recall from 87.6% to 89.4% in movingfrom ALL to ALL+.
As we saw in Section 5, in 95%of the cases, the embedded operators respects syn-tactic scope, and as a result, we obtain only modestgains from handling embedded operators.The reader may feel that the F-score of 90.6% isquite high given the size of our training data.
Thisscore is inflated by inclusion of reflexive pairs, ofthe form (o, o).
Such pairs are included for thefollowing (technical) reasons.
The algorithm thathandles embedded operators (ALL+) usually raisesthem from a single operator node (as in Figure 3) toa multi-operator node (as in Figure 5).
If it makesan incorrect decision to raise an operator it takes aprecision hit, at the multi-operator node (becauseit has some false positives).
By contrast, an algo-rithm loses precision for failing to correctly raise,only when we encounter the single operator node.For these reasons, it is better to consider the rela-tive improvement in F-score over the baseline.
Therelative improvement of ALL+ over SURFACE interms of F-score is 36.6%.
We believe that thepreterminal-level accuracy is more indicative in anabsolute sense.
Furthermore, when we restrict atten-tion to those preterminals with two or more opera-tors in the PPT, the accuracy of ALL+ is 69.4%.7 Related WorkASTs can be seen as a middle ground between twolines of research in translating sentences to logic.At one end of the spectrum, we have methodsthat achieve good accuracy on restricted texts.
Thetwo main corpora that have been considered are theGEOQUERY corpus (Thompson et al, 1997) andthe ATIS-3 corpus (Dahl et al, 1994).
The GEO-QUERY corpus consists of queries to a geographicaldatabase.
The queries were collected from studentsparticipating in a study and the average sentencelength is 8 words.
The ATIS corpus is collectedfrom subjects?
interaction with a database of flightinformation, using spoken natural language.
The ut-terances have be transcribed, and the average sen-tence length is 10 words (Berant et al, 2007).
Algo-rithms, which achieve good accuracy, have been de-veloped to compute the logical translation for thesequeries (Zettlemoyer and Collins, 2005; Wong andMooney, 2007; Zettlemoyer and Collins, 2009).
Theannotated sentences in the FDA CFR Section 610.40are longer (about 30 words on average), and containmodalities which are not present in these corpora.At the other end of the spectrum, Bos et al (Bos etal., 2004) have developed a broad-coverage parser totranslate sentences to a logic based on discourse rep-resentation theory.
Here, there is no direct method toevaluate the correctness of the translation.
However,indirect evaluations are possible, for example, bystudying improvement in textual entailment tasks.To summarize, there are techniques that eitherproduce an accurate translation for sentences in alimited domain, or produce some translation for sen-tences in a broader range of texts.
ASTs offer a mid-dle ground in two ways.
First, we focus on regula-1210tory texts which are less restricted than the databasequeries in the GEOQUERY and ATIS corpora, but donot exhibit anaphoric phenomenon found in genres,such as, newspaper text.
In (Dinesh et al, 2007), wediscuss lexical statistics that show significant differ-ences in the distribution of anaphoric items in theCFR and Wall Street Journal (WSJ) corpora.
For ex-ample, the frequency of pronouns and anaphoric dis-course connectives is significantly lower in the CFRthan in the WSJ.
Instead, the CFR has an idiosyn-cratic mechanism for referring to sentences, usingphrases such as ?except as specified in paragraph(c) and (d)?.
A question of interest is whether theGEOQUERY and ATIS corpora show similar pecu-liarities in terms of anaphora.
The second differencebetween our approach and others is that we do notattempt to translate all the way to logic.
The level oflogical form lets us obtain a direct evaluation, whileleaving open the design of parts of the logic.8 ConclusionsWe described experiments on a modest-sized cor-pus of regulatory sentences, annotated with a novelvariant of logical form, called abstract syntax trees(ASTs).
An example from the corpus was presentedin Section 2 and some statistics, describing the cor-pus, were discussed in Section 4.
In Sections 3, 5,and 6, we developed and tested algorithms to con-vert a processed parse tree (PPT) to an AST.
Themain step in this conversion was to rank or order theoperators at a preterminal.
We presented a proba-bilistic model for ranking, investigated the design offeatures, and developed search heuristics.
The bestalgorithm, which uses all features and handles em-bedded operators, achieves an F-score of 90.6%.An important direction for further inquiry is in thedesign of better features.
Various types of featureshave been proposed for the scopal ordering of deter-miners.
Examples include syntactic features (Ioup,1975; Reinhart, 1983), such as position and voice,semantic features (Grimshaw, 1990; Jackendoff,1972), such as thematic roles.
More recently, Srini-vasan and Yates (2009) showed how pragmatic in-formation, for example ?there are more people thancities?, can be leveraged for scope disambiguation.We experimented with lexico-syntactic features inthis work, and leave an investigation of semantic andpragmatic features to future work.AcknowledgementsWe thank Claire Cardie, Steve Kimbrough, AnnieLouis, Fernando Pereira, Emily Pitler, Oleg Sokol-sky, and the anonymous reviewers for helpful com-ments on earlier versions of this paper.ReferencesA.
Aho, R. Sethi, and J. Ullman.
1986.
Compilers: Prin-ciples, Techniques, and Tools.
Addison-Wessley.R.
J. Anderson.
1996.
A security policy model for clin-cial information systems.
In Proceedings of the IEEESymposium on Security and Privacy.A.
Barth, A. Dutta, J. C. Mitchell, and H. Nissenbaum.2006.
Privacy and contextual integrity: Frameworkand applications.
In Proceedings IEEE Symposium onSecurity and Privacy.J.
Berant, Y.
Gross, M. Mussel, B. Sandbank, E. Ruppin,and S. Edelman.
2007.
Boosting unsupervised gram-mar induction by splitting complex sentences on func-tion words.
In Proceedings of the Boston UniversityConference on Language Development.J.
Bos, S. Clark, M. Steedman, J. R. Curran, and J. Hock-enmaier.
2004.
Wide-coverage semantic representa-tions from a CCG parser.
In Proceedings of COLING.W.
W. Cohen, R. E. Schapire, and Y.
Singer.
1998.Learning to order things.
Journal of Artificial Intel-ligence Research, 10:243?270.D.
Dahl, M. Bates, M. Brown, W. Fisher, K. Hunicke-Smith, D. Pallett, C. Pao, A. Rudnicky, andE.
Shriberg.
1994.
Expanding the scope of the ATIStask: the ATIS-3 corpus.
In Proceedings of the ARPAHLT Workshop.N.
Dinesh, A. Joshi, I. Lee, and O. Sokolsky.
2007.Logic-based regulatory conformance checking.
InProceedings of the 14th Monterey Workshop.N.
Dinesh, A. Joshi, I. Lee, and O. Sokolsky.
2011.
Per-mission to speak: A logic for access control and con-formance.
Journal of Logic and Algebraic Program-ming, 80(1):50?74.N.
Dinesh.
2010.
Regulatory Conformance Checking:Logic and Logical Form.
Ph.D. thesis, University ofPennsylvania.G.
Governatori, Z. Milosevic, and S. Sadiq.
2006.
Com-pliance checking between business processes and busi-ness contracts.
In 10th International Enterprise Dis-tributed Object Computing Conference (EDOC).J.
Grimshaw.
1990.
Argument Structure.
MIT Press.1211B.
Grosof, Y. Labrou, and H. Y. Chan.
1999.
A declar-ative approache to business rules in contracts: Cour-teous logic programs in xml.
In ACM Conference onElectronic Commerce.Irene Heim and Angelika Kratzer.
1998.
Semantics inGenerative Grammar.
Blackwell.G.
Ioup.
1975.
Some universals for quantifier scope.Syntax and Semantics, 4:37?58.R.
Jackendoff.
1972.
Semantic Interpretation in Genera-tive Grammar.
MIT Press.A.
J. I. Jones and M. J. Sergot.
1992.
Formal spec-ification of security requirements using the theoryof normative positions.
In European Symposium onReasearch in Computer Security (ESORICS).R.
M. Karp.
1972.
Reducibility among combinatorialproblems.
In R. E. Miller and J. W. Thatcher, editors,Complexity of Computer Computations, pages 85?103.Plenum Press.H.
S. Kurtzman and M. C. MacDonald.
1993.
Resolutionof quantifier scope ambiguities.
Cognition, 48:243?279.R.
K. Larson.
1985.
Quantifying to np.
Manuscript,MIT.T.
Liu.
2009.
Learning to rank for information retrieval.Foundations and Trends in Information Retrieval, 3(3).D.
Makinson and L. van der Torre.
2000.
Input/outputlogics.
Journal of Philosophical Logic, 29:383?408.R.
May.
1985.
Logical Form: Its structure and deriva-tion.
MIT Press.A.
McCallum.
2002.
MALLET: A machine learning forlanguage toolkit.
http://mallet.cs.umass.edu.T.
Reinhart.
1983.
Anaphora and Semantic Interpreta-tion.
Croom Helm.M.J.
Sergot, F.Sadri, R.A. Kowalski, F.Kriwaczek,P.Hammond, and H.T.
Cory.
1986.
The british na-tionality act as a logic program.
Communications ofthe ACM, 29(5):370?86.P.
Srinivasan and A. Yates.
2009.
Quantifier scopedisambiguation using extracted pragmatic knowledge:Preliminary results.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP).C.
A. Thompson, R. J. Mooney, and L. R. Tang.
1997.Learning to parse natural language database queriesinto logical form.
In Proceedings of the Workshop onAutomata Induction, Grammatical Inference and Lan-guage Acquisition.Y.
W. Wong and R. J. Mooney.
2007.
Learning syn-chronous grammars for semantic parsing with lambdacalculus.
In Proceedings of the Annual Meeting of theAssociation for Computational Linguistics (ACL).L.
S. Zettlemoyer and M. Collins.
2005.
Learning tomap sentences to logical form: Structured classifica-tion with probabilistic categorial grammars.
In Pro-ceedings of UAI.L.
S. Zettlemoyer and M. Collins.
2009.
Learningcontext-dependent mappings from sentences to logi-cal form.
In Proceedings of the Annual Meeting of theAssociation for Computational Linguistics (ACL).1212
