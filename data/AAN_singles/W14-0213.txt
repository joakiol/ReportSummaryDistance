Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 73?77,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsHuman pause and resume behaviours forunobtrusive humanlike in-car spoken dialogue systemsJens EdlundKTH Speech, Music and HearingStockholmSwedenedlund@speech.kth.seFredrik EdelstamKTH Speech, Music and HearingStockholmSwedenfreede41@kth.seJoakim GustafsonKTH Speech, Music and HearingStockholmSwedenjocke@speech.kth.seAbstractThis paper presents a first, largely qualitativeanalysis of a set of human-human dialoguesrecorded specifically to provide insights in howhumans handle pauses and resumptions insituations where the speakers cannot see eachother, but have to rely on the acoustic signal alone.The work presented is part of a larger effort to findunobtrusive human dialogue behaviours that can bemimicked and implemented  in-car spokendialogue systems within in the EU project GetHome Safe, a collaboration between KTH, DFKI,Nuance, IBM and Daimler aiming to find ways ofdriver interaction that minimizes safety issues,.
Theanalysis reveals several human temporal,semantic/pragmatic, and structural behaviours thatare good candidates for inclusion in spokendialogue systems.1 IntroductionIn-car spoken dialogue systems face specificchallenges that are of little or no relevance forsystems designed for other environments.
Thetwo most striking of these are (1) the very strongfocus on safety in the driving situation and (2)the fact that the person who speaks to the system?
its user, in other words the driver in themajority of cases ?
does so in an environmentthat may change quite drastically from thebeginning of an interaction to its completion.
Themost straightforward source for this change is thefact that the car (and the user) moves through theenvironment while the dialogue progresses.
Thedynamic and mobile nature of the surroundingtraffic adds to the complexity.
Generallyspeaking, safety is the key concern whendesigning spoken dialogue systems for in-car use.While poor performance in spoken dialoguesystems can clearly be a nuisance to a driver, thepromise of using properly designed spokendialogue instead of other interfaces is increasedsafety.
This promise is based in the nature ofspeech: it does not require the driver to divert theuse hands and eyes from the driving, and it is amode of communication that most are quite usedto and comfortable with, so should not inducegreat amounts of cognitive load.We present a corpus consisting of a set ofhuman-human dialogues recorded specifically toprovide insights in how humans handleinterruptions - how they pause and resumespeaking - in situations where the speakerscannot see each other, but have to rely on theacoustic signal alone, and a preliminary analysisof these which reveals several candidates forinclusion in in-car spoken dialogue systems.Finally, we discuss how these can beimplemented and how a selection of them areincluded in the Get Home Safe experimentimplementation.2 Background and related workIn a government-commissioned survey from2011, the Swedish National Road and TransportResearch Institute reviews several hundredresearch publications on traffic safety and the useof mobile phones and other communicationdevices [Kircher et al., 2011].
Amongst the moststriking findings: although there is a broadconsensus that visual-manual interactions (e.g.using social media or texting) withcommunication devices impair drivingperformance, bans have not had any measurableeffects in terms of lowered accident rates orinsurance claims.
Ban compliance statistics show73that bans have an effect on driver behaviour thefirst year, after which drivers return to theirformer habits.
With bans being virtuallyineffective, solutions must be sought elsewhere.Allowing drivers to manage more tasks usingspeech, which does not occupy hands and eyes,would decrease the time spent in visual-manualinteraction while driving, provided that thedrivers can be persuaded to use the systems.Clearly, the systems must work well - a largeproportion of errors may well put the driver atrisk (e.g.
Kun et al., 2007).
It is also unlikely thatdrivers can be persuaded to use systems that donot work well.
But using hand-free and eyes-freecontrols may not suffice.
Kircher et al.
(2011)notes that there is virtually no evidence thathands-free telephony is less risky than hand-helduse, suggesting that the conversations inthemselves may be a risk factor.
Speaking to aperson who is present in the car and who sharesthe driver?s situation, however, is much safer(Peissner et al., 2011), suggesting that a systemthat is perceived as and behaves like a co-presenthuman is a sensible aim.
In the EU project GetHome Safe, of which this research is a part, wecall such systems humanlike proactive systems.Where a traditional spoken dialogue systembases its decisions largely on (1) whether it hassomething to say, (2) what the user has just said,and (3) whether the user is speaking or is silent, ahumanlike proactive system will also consider (4)the (traffic) situation, (5) the user?s (driver's)estimated attention, and (6) the urgency of thetask at hand, much like a passenger might.This paper focusses on two broad types ofproactive humanlike behaviours: user controlledpacing, referring to the ability to pause at thewhim of the user in the middle of a conversation,or even an utterance, and then resume theconversation; and situation sensitive speech, theability to allow the situation to affect the mannerin which the system speaks.
We are searching forbehaviours that people use when interrupted,either by their interlocutor or by some event intheir environment, and when they resume theoriginal dialogue again.
We are specificallyinterested in behaviours that can be implementedin the Get Home Safe architecture without majorchanges to existing applications.
The architectureallows a central manager to instruct applicationsto stop where they are and maintain their innerstate until instructed to either exit or continuewhere they were.The task has been approached by others, albeitin different manners.
Villing (2010) presents ananalysis of interruptions and resumptions inhuman-human in-vehicle dialogues, as well asimplications for future in-car dialogue systems,and Yang et al.
(2011) used human-human multi-tasking dialogues that involved a poker game asthe main task, and a picture game as aninterrupting real-time task.3 MethodOur goal is to collect and analyse data that willprovide an insight to how a human speaker dealswith interruptions in in-car dialogue (our targetsetting) and to find relevant behaviours that canbe successfully mimicked in an in-car human-computer environment.
The question can besubdivided: How does a human speaker stopspeaking when faced with an (possible)interruption?
How does a human speaker resumespeaking after such an event?
Which of thesebehaviours are plausible candidates for inclusionin a spoken dialogue system?3.1 Data CollectionSetting.
Collecting data from a real drivingsituation is time consuming, not to say dangerouswhen adding a secondary task.
We have insteadopted to simulate the key elements of interest inour dialogue recording studio ?
a safe recordingenvironment consisting of several physicallydistinct locations that are interconnected withlow and constant latency audio and video.
Theinterlocutors were placed in different rooms, andcommunicated through pairs of wireless close-range microphones and loudspeakers.Subjects.
The purpose of this data collection isnot for example training a recognizer, but thegeneration of a consistent set of candidate74behaviours for implementation in a spokendialogue system ?
one that contains behavioursthat could all plausibly be used by the samespeaker.
To achieve this, we consistently use thesame single male speaker in the role as thesystem (?speaker?, hereafter) for all recordings.For the user role (?listener?, hereafter), abalanced variety of speakers were used: two setsof 8 listeners, both balanced for gender, wereused.
None of the listeners had any previousknowledge of this research.
All listeners wererewarded with one cinema ticket.
They were toldthat those who performed the task best wouldearn a second ticket, and the top performers fromeach setup received a second ticket after therecordings were completed.Task.
The data collection was designed as a dualtask experiment.
The main task for the speakerwas to read three short informative texts abouteach of three cities (Paris, Stockholm, andTokyo), arranged so that the first is quite general,the second more specific, and the third deals witha quite narrow detail with some connection to thecity.
This task is equivalent to what one mightexpect from a tourist information system.
For thelistener, the main task is to listen to the cityinformation.
The listener is motivated by theknowledge that the reading of each segment -that is each of the nine informative texts - isfollowed by three questions on the content of thetext.
Their performance in answering thesequestions and in completing the secondary taskcounted towards the extra movie ticket.
Thesecondary task was designed as follows.
Atirregular, random intervals, a clearly visiblecoloured circle would appear, either in front ofthe speaker or the listener.
When this happened,the speaker was under obligation to stop thenarration and instead read a sequence of eightdigits from a list.
The listener must then to repeatthe digit sequence back to the speaker, afterwhich the speaker could resume the narration.Conditions.
We considered two characteristicsof in-car interruptions that we assumed wouldhave an effect on how humans react to theinterruption and to how they resume speakingafter it: the source of an interruption can beeither internal or external in an in-car dialogue(our target setting); and the duration and contentof an interruption varies, they can be brief oreven the result of a mistake, or they can be longand contentful.
The condition mapping to thefirst of these characteristics was designed suchthat the coloured circle signalling an interruptionwas presented randomly to either the speaker,mapping to en external event visible to thesystem but not the driver, or to the listener,mapping to an interruption from the driver to thesystem (the listener had to speak up to inform thespeaker that the circle was present).
The secondcondition was designed such that in one set ofeight dialogues, the coloured circle would startout yellow, and as soon as the speaker becamesilent, it would randomly either disappear(causing only a short interruption with light or nocontent, corresponding to e.g.
a false alarm) orturn red, in which case the sequence of digitswould be read and repeated (a contentfulinterruption).
In the other set of eight recordings,the circle always went straight to red, and alwayscaused digits to be read and repeated.3.2 AnalysisEach channel of each recording was segmentedinto silence delimited speech segmentsautomatically, and these were transcribed usingNuance Dragon Dictate.
The transcriptions werethen corrected by a human annotator, andlabelled for interruptions and resumptions.
In thisinitial analysis, we looked at temporal statistics(e.g.
the durations between interruption from thelistener and silence from the speaker),semantics/pragmatics (e.g.
lexical choices,insertions, repetitions) and syntax (e.g.
where inan utterance resumption begins).4 ResultsA categorical difference was found in thedistribution of speaker response times (from theonset of a listener interruption to the offset ofspeaker speech) depending on whether theinterruption occurred in the middle of a phrase orclose to the end of the phrase.
In the first case,the vast majority of the response times are75distributed between 300 and 700 ms, with a clearmode around 400 ms. Only a fraction of responsetimes are slower than 700 ms, and none exceptone is faster than 300 ms.
Phrase finalinterruptions show an almost flat response timedistribution, with only a very weak mode around500 ms, and a large proportion with responsetimes longer than 700 ms.For lexical/pragmatic choices, we find acategorical variation for the insertion ofvocalizations we somewhat lazily term filledpauses (e.g.
"eh", "em") and what we equallylazily term lexical cue phrases (e.g.
"right", "ok")before resumption.
The existence of suchinsertions, as well as the choice of vocalization,is straightforwardly dependant on thecontentfulness of the interruption.
For shortinterruptions of light content, filled pauses arenearly never inserted before resumption.
Lexicalcue phrases are inserted, but rarely.
In the typicalcase, the speaker goes straight back to theinformational text.
For long, contentfulinterruptions, resumption is initiated by aninsertion in an overwhelming majority of cases.If the insertion consists of one vocalization only,this is nearly always a filled pause.
If more thanone vocalization is present, then lexical cuephrases occur frequently, but overall, lexical cuephrases are no more common here than in thecase of the short interruptions.In the case of structural comparisons, the oneclear distinction we found has to do with what, ifany, material is repeated at resumption, acharacteristic that varies strongly with the type ofinterruption.
For long interruptions, in everyinstance but a handful, the speaker either repeatsthe entire utterance in which the interruptionoccurs, or - in the few cases where aninterruption occurred just as an utterance came toan end - with the next utterance.
For shortinterruptions, resumptions also start mostregularly from either the start of the currentutterance or from the start of the next one.However, starts from the beginning or end of thecurrent phrase, word, or even part of word arealso frequent.5 DiscussionWe think that the three main findings presentedin the results are all good candidates forimplementation.
The different distributions ofresponse times suggest that if an interruptionoccurs centrally, in the midst of a production, thespeaker stops as fast as possible - the distributionis largely consistent with reaction timedistributions.
Towards the end of phrases, thedistribution is flat and quite different to what onewould expect if reaction time was the maingoverning factor.
The larger proportion of longresponse times suggests that when the speaker isclose to the end of a phrase, finishing the phrasefirst might be preferable to stopping as soon asreaction permits.
From an implementationperspective, this is quite encouraging.
In order tocreate a behaviour consistent with this, we needto halt system speech with a reaction time ofaround 3-500ms.
If possible (i.e.
if the systemknows how much time remains of its production),we may instead complete the utterance if lessthan, say, 700ms remains.Seemingly, short light content interruptionsneed no specific signalling of resumption.
If suchsignalling is made, it is in the form of a lexicalcue phrase, such as "ok" or "right".
Resumptionsfollowing longer, contentful interruptions areroutinely initiated by a filled pause.
This may besolely due to the speaker's need to find thecorrect place in the script to start over, but it isnoteworthy that instead of doing this in silence,the speaker opts to vocalize.
For implementation,resumptions following contentful subdialoguesshould start with a filled pause and perhaps alexical cue phrase.The straightforward interpretation of the thirdfinding is that in the case of short interruptions,both speaker and listener have the point ofinterruption in fresh memory, and need noreminder, while long interruptions require thespeaker to help the listener out by recapitulatingwhat was last said.
In the latter case, the systemcan simply start over with its last utterance(provided that it produces its synthesis on agranularity of at least utterance level).76AcknowledgmentsThis work was funded by the GetHomeSafe  (EU7th Framework STREP project  288667).ReferencesKircher, K., Patten, C., & Ahlstr?m, C. (2011).Mobile telephones and other communication devicesand their impact on traffic safety: a review of theliterature.
Technical Report VTI 729A, Stockholm.Kun, A., Paek, T., & Medenica, Z.
(2007).
The effectof speech interface accuracy on driving performance.In Proc.
of Interspeech 2007.
Antwerp, Belgium.Peissner, M., Doebler, V., & Metze, F. (2011).
Canvoice interaction help reducing the level of distractionand prevent accidents?
Meta-Study on DriverDistraction and Voice Interaction.
Technical Report,Fraunhofer, Germany and CMU, USA, Aachen,Germany.Villing, J.
(2010).
Now, where was I?
Resumptionstrategies for an in-vehicle dialogue system.
In The48th Annual Meeting of the Association forComputational Linguistics (pp.
798-805).
Sweden.Yang, F., Heeman, P. A., & Kun, A. L. (2011).
Aninvestigation of interruptions and resumptions inmulti-tasking dialogues.
Computational inguistics,27(1), 75-104.77
