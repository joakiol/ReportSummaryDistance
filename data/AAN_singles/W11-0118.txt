Formalising and specifying underquantificationAurelie HerbelotUniversity of Cambridgeah433@cam.ac.ukAnn CopestakeUniversity of Cambridgeaac@cl.cam.ac.ukAbstractThis paper argues that all subject noun phrases can be given a quantified formalisation in termsof the intersection between their denotation set and the denotation set of their verbal predicate.
Themajority of subject noun phrases, however, are only implicitely quantified and the task of retrievingthe most plausible quantifier for a given NP is non-trivial.
We propose a formalisation which capturesthe underspecification of the quantifier in subject NPs and we show that this formalisation is widelyapplicable, including in statements involving kinds.
We then present a baseline for a quantificationresolution system using syntactic features as basis for classification.
Although the syntactic baselineprovides a respectable 78% precision, our error analysis shows that obtaining true performance onthe task requires information beyond syntax.1 Quantification resolutionMost subject noun phrases in English are not explicitly quantified.
Still, humans are able to give themquantificational interpretations in context:1.
Cats are mammals = All cats...2.
Cats have four legs = Most cats...3.
Cats were sleeping by the fire = Some cats...4.
The beans spilt out of the bag = Most/All of the beans...5.
Water was dripping through the ceiling = Some water...We refer to this process as quantification resolution, that is, the process of giving an implicitely quan-tified NP a formalisation which expresses a unique set relation appropriate to the semantics of the utter-ance.
For instance, the most plausible resolution of 1 can be expressed as:6.
All cats are mammals.|?
?
?| = |?| where ?
is the set of all cats and ?
the set of all mammals.Resolving the quantification value of NPs is important for many NLP tasks, in particular for infer-ence.
We would like to be able to automatically perform the type of interpretations shown in 1 to 5.It will allow us to draw conclusions such as If (all) cats are mammals and Tom is a cat, then Tom is amammal and If (some) cats are in my garden, then (some) animals are in my garden.1The task of quantification resolution involves finding a semantic representation that goes beyond whatis directly obtainable from a sentence?s syntactic composition.
We can write the(x, cat?
(x), sleep?
(x))as we would write some(x, cat?
(x), sleep?
(x))2, but while the quantification semantics of some can be1The type of entailment relying on word substitution is dependent on quantification: (All) cats are mammals doesn?t implythat (All) animals are mammals.2We use here a generalised quantifier notation were the first argument of the quantifier is the bound variable.165fully defined (given a singular NP, we are talking of one entity only), that of the cannot: in a singu-lar NP introduced by the, the referent can either be a single entity or a plurality with various possiblequantificational interpretations (cf The cat is sleeping vs The cat is a mammal).This paper is an attempt to provide a formal semantics for implicitely quantified NPs which a) sup-ports the type of inferences required by NLP, b) has good empirical coverage (beyond ?standard?
lin-guistic examples), c) lends itself to evaluation by human annotation and d) can be derived automatically.We draw on work in formal linguistics, but by formulating the problem as quantification resolution,we obtain an account which is more tractable from an NLP perspective.
We also present preliminaryexperiments that automate quantification resolution using a syntax-driven classifier.2 Under(specified) quantificationThe phenomenon of ambiguous quantification overlaps with genericity.
Generic NPs have tradition-ally been described as referring to kinds (Krifka et al, 1995) and one of their most frequent syntacticexpressions is the bare plural, although they occur in definite and indefinite singulars too, as well asbare singulars.
There are many views on the semantics of generics (e.g.
Carlson, 1995; Pelletier andAsher, 1997; Heyer, 1990; Leslie, 2008) but one of them is that they quantify (Cohen, 1996), although,puzzlingly enough, not always with the same quantifier:7.
Dogs are in my garden = Some dogs...8.
Frenchmen eat horsemeat = Some/Relatively-many Frenchmen... (For the relatively many reading,see Cohen, 2001.)9.
Cars have four wheels = Most cars...This behaviour has so far prevented linguists from agreeing on a single formalisation for all generics.Note that relegating the various readings to a matter of pragmatics, formalising all bare plurals using anexistential, is no solution as we are then unable to explain the semantic difference between, for instance,Mosquitoes carry malaria and Some mosquitoes carry malaria.
The only accepted assumption is thatan operator GEN exists, which acts as a silent quantifier over the restrictor (subject) and matrix (verbalpredicate) of the generic statement.In this paper, we take an approach which sidesteps some of the intractable problems associated withthe literature on generics and which also extends to definite plurals, as discussed below.
Instead oftalking of ambiguous quantification, we will talk of underspecified quantification, or underquantifi-cation.
By this, we mean that the bare plural, rather than exhibiting a silent, GEN quantifier, simplyfeatures a placeholder in the logical form which must be filled with the appropriate quantifier (e.g.,uq(x, cat?
(x), sleep?
(x)), where uq is the placeholder quantifier).
This account caters for the facts thatso-called generics can so easily be quantified via traditional quantifiers, that GEN is silent in all knownlanguages, and it explains also why it is the bare form which has the highest productivity, and can denotea range of quantified entities, from existentials to universals.
Using the underquantification hypothesis,we can paraphrase any generic of the form ?X does Y?
as ?there is a set of things X, a certain number ofwhich do Y?
(note the partitive construction).We now turn to definite plurals which have traditionally been thought to be outside of the genericityphenomenon and associated with universals (e.g., Lyons, 1999).
Definite plurals do exhibit a range ofquantificational behaviour and thus we argue that they should be studied as underquantified forms too.Consider the following, from Dowty (1987):10.
At the end of the press conference, the reporters asked the president questions.Dowty remarks that it is not necessary that all reporters ask questions for the sentence to be true.
In fact,it is only necessary that some of them did.
Dowty says: ?The question of how many members of thegroup referent of a definite NP must have the distributive property is in part lexically determined and inpart determined by the context, and only rarely is every member required to have these properties.
?Following the existential reading, we can write:16611. some(x, reporter?
(x), askQuestion?
(x))The problem is that for Dowty, the NP refers to a ?group?, i.e., to the reporters as a whole, and not tospecific reporters.
We don?t want to say ?there is a small set of reporters, each of which asked a question?
;we want to say ?there is a large set of reporters ?
all those present at the press conference ?
and someof them asked a question?, i.e., we want to use a partitive construction.
We follow Brogaard?s (2007)account of definite plurals as partitive constructions, where she examines the following:12.
The students asked questions.Brogaard argues that, given X , the denotation of the students, a subset Y of X is selected via the quan-tifier some and that the verbal predicate applies (distributively) to Y .
A similar account can be givenof (10): there is a set of reporters, and a certain number of elements in that set (some reporters) askedquestions ?
which is our desired reading.
Note that all definite plurals can have this interpretation (e.g.,possessives and demonstratives also).We will next argue that the partitive construct observed in definite plurals can be generally applied tosubject NPs and we will propose a single formalisation for all underquantified statements.3 Formalisation3.1 Link?s notation (1983)In what follows, we briefly define each item of notation used in this work, as taken from Link (1983).We illustrate the main points via examples over a closed worldW containing three cats (Kitty, Sylvesterand Bagpuss).The background assumption for our formalisation is that, following Link, plurals can be representedas lattices.
The star sign ?
generates all individual sums of members of the extension of predicate P .
Soif P is cat?, the extension of ?P is a join-semilattice representing all possible sums of cats in the worldunder consideration.
The join-semilattice of cats in worldW is shown in Fig 1.Figure 1: Join-semilattice of all cats in worldWThe sign ?
is the sum operator.
?xPx represents the sum, or supremum, of all objects that are ?P .?
?xPx represents the proper sum of Ps, that is, the supremum of all objects that are proper pluralpredicates of P .
The sum includes (non-plural) individuals such asK or S while the proper sum doesn?t.In worlds where there is more than one object in the extension of ?P , ?xPx = ?
?xPx: e.g., in Fig 1,the sum of all cats is the same as the proper sum of all cats, i.e., the set {K,S,B}.
(Compare this with aworld where there is only one cat, say Kitty: then ?xPx = {K} while ?
?xPx = ?
).The product sign?expresses an individual-part relation.
The ?
sign in combination with ?
indi-cates atomic part.
Following Chierchia (1998), we assume the same underlying lattice for both massterms and count nouns, so we use the?and ?
operators for formalising quantification over mass entities.3.2 Collective and distributive predicatesSome predicates are collective: they refer to a group as a whole and not to its instances (13).
Otherpredicates are always distributive (14):16713.
Antelopes gather near water holes (*Andy the antelope gathers near water holes.)14.
Three soldiers were asleep (Tom was asleep, Bill was asleep, Cornelia was asleep.
)Most verbal phrases, though, are ?mixed predicates?
that accept both readings:15.
Three soldiers stole wine from the canteen.
(Tom, Bill and Cornelia went together to the canteen to steal wine or Tom, Bill and Cornelia eachstole wine from the canteen.
)Collective predicates can be a source of confusion when trying to directly apply quantification to anambiguously quantified NP:16.
(*Some/Most/All) Americans elect a new president every five years.Quantifying 16 seems initially impossible in shallow form: we cannot write all(x,american?(x),electPres?
(x))as it seems to imply distributivity.
However, we refer to the reporter example (10) and the latent partitiveconstruct that we suggested existed in that (distributive) sentence.
By similarity, we can say that thereis a set X of Americans able to vote, and a subset Y of those ?
which in this case is selected by thequantifier all and is therefore equal to X ?
collectively elects the president.3.3 Formalising the partitive constructFollowing Link (1998) for the formalisation of collective and distributive predicates, we can write, for10 and 16:17.
X = ?
?x reporterAtPressConference?
(x) ?
?Y [Y ?X ?
?z[z ?
?Y ?askques?(z)]]18.
X = ??xvotingAmerican?
(x) ?
?Y [Y ?X?electPresident?
(Y )]3For the collective case, we just apply the verbal predicate collectively.We can then add the quantifier resolution.
We assume a three-fold partitioning of the quantificationalspace, corresponding to the natural language quantifiers some, most and all (in addition to one, for thedescription of singular, unique entities).
The corresponding set relations are:19. if some(?, ?)
then 0 < |?
?
?|20.
ifmost(?, ?)
then |??
?| ?
|?
?
?|21.
if all(?, ?)
then |??
?| = 0These set relations can be expressed in terms of the sets involved in the partitive construction: in 16,ifX is the set of all Americans able to vote, Y the subset ofX selected by the quantifier, and Z the set ofall things that elect the president, then Y actually represents the intersection X ?
Z.
We can thus write:22.
X = ?
?x reporterAtPressConference?(x)?
?Y [Y ?X ?
?z[z ?
?Y ?askques?(z)]?
(0 < |Y |)]23.
X = ?
?x votingAmerican?
(x) ?
?Y [Y ?X?electPresident?
(Y ) ?
(|X ?
Y | = 0)]The same principle applies to mass nouns.
We show below a distributive example.24.
Water was dripping through the ceiling.X = ?
?x water?
(x) ?
?Y [Y ?X ?
?z[z ?
?Y ?dripThroughCeiling?
(z)] ?
(0 < |Y |)]We thus write the underspecified quantifier as:25.
X = ?
?x P ?
(x) ?
?Y [Y ?X ?Q(Y )] ?
quantConstraint(X,Y )]where the quantConstraint ensures the correct cardinality of Y for various quantifiers and the predicateQapplies distributively or collectively depending on the semantics of the sentence.
X and Y respectivelydenote the Nbar and NP referents in the quantified paraphrase of the statement.3Note that in the two examples, we have restricted X to the relevant set of entities.
We will not investigate here how thisparticular reference resolution takes place.1684 KindsIn order to argue that our formalisation is applicable to all subject noun phrases, we must briefly comeback to the case of generics which, in some linguistic accounts, are not seen as quantified (Carlson,1977).4 According to those accounts, the subject NP in sentences such as The cat is a mammal (thekind) can be regarded as an entity similar to proper nouns.
The generic reading of the sentence thentakes a straightforward subject/predicate formalisation of the type mammal?(cat?).
The main argumentin favour of such a representation is the existence of sentences where the verbal predicate seems to onlybe applicable to a species rather than to its instances:26.
The dodo is extinct.Such cases, we claim, do not preclude quantification.
We use the accounts of Chierchia (1998) andKrifka (2004), where a kind is defined as a function that returns the greatest element of the extension ofthe property relevant to that kind: Kind(X) = ?
?x X ?(x).
This gives us the following for 26:27.
X = ?
?x dodo?
(x) ?
?Y [Y ?X ?
extinct?
(Y ) ?
(|Y ?X| = 0)]We stress however that we do not deny the validity of representations that involve a simple sub-ject/predicate structure.
It should be clear that the sentence The cat is a mammal has an interpretationwhere the species ?cat?
is attributed the property of being a mammal.
What we argue is simply that themeaning of the sentence also includes a quantificational aspect.
We want, after all, to be able to makenatural inferences about individual cats: if the cat is a mammal then Tom the cat is a mammal.
We believethat both quantification and a subject/predicate formalisation are necessary to fully render the semanticsof such sentences.
We will also argue in Section 7 that for the purposes of computational linguistics, itis actually desirable to formalise the quantificational aspect separately, as part of the full semantics.We should also note that the genericity phenomenon is usually seen as encompassing habitual con-structions (Krifka et al, 1995).
Our quantificational account of kinds will not necessarily be applicableto quantification of events and we do not wish to make any claims with regard to habituality in this paper.For completeness, we will however point out that, following Chierchia (1995) on indefinites, we seequantification adverbs as able to bind, and therefore quantify over individuals: according to this view,the most felicitous reading of Mosquitoes sometimes carry malaria is Some mosquitoes carry malaria,formalisable with 25.5 Automatic quantification: first attemptsTo our knowledge, no attempt at the automatic specification of quantification has been made before.
Inconsequence, we start our investigation with the simplest possible type of machine learning algorithm,using as determining features the direct syntactic context of the statement to be quantified.
The generalidea of such a system is that grammatical information such as the number of a subject noun phrase andthe tense of its verbal predicate may be statistically related to its classification.5.1 Gold standardWe built a gold standard by re-using and expanding the quantification annotations we produced in Herbe-lot and Copestake (2010).
This small corpus, which contains randomly extracted Wikipedia5 sentences,provides 300 instances of triply annotated subject noun phrases.
The categories used for annotation arethe natural language quantifiers ONE, SOME, MOST, ALL and the label QUANT (for noun phrases of thetype some cats, most turtles or more than 37 unicorns which, being explicitly quantified, do not enter ourunderquantification account and must be marked with a separate label).
In order to convert the multiple4A more comprehensive discussion can be found in Herbelot (2010).5http://www.wikipedia.org/169annotations to a gold standard, we used majority opinion when it was available and negotiation in casesof complete disagreement.
There were only 14 cases where a majority opinion cannot be obtained.The main issue with the resulting gold standard is its relatively small size.
The 300 data points itprovides are clearly insufficient for machine learning, but the annotation process is time-consuming andwe do not have the resources to set up a large-scale annotation effort.
As a trade-off, the first authorof this paper annotated a further 300 noun phrases, thus doubling the size of the gold standard.
As aprecaution, we ran the classifier presented later in this section over the original gold standard and overthe new annotations; no substantial difference in performance between the two runs was found.Table 1 shows the class distribution of our five quantification labels over the 600 instances of theextended gold standard.Class Number of instances Percentage of corpusONE 367 61%SOME 53 9%MOST 34 6%ALL 102 17%QUANT 44 7%Table 1: Class distribution over 600 instancesWe note, first, that the number of explicitly quantified noun phrases amounts to only 7% of the an-notation set.
This shows that the resolution of underquantification has potentially high value for NLPsystems.
Next, we remark that 61% of all instances simply denote a single entity, leaving 32% to under-quantified plurals ?
189 instances.
This imbalance is problematic for the machine learning task that weset out to achieve.
First, it means that the training data available for SOME, MOST and ALL annotationsis comparably sparse.
Secondly, it implies that the baseline for our future classifier is relatively high:assuming a most frequent class baseline, we must beat 61% precision.5.2 Quantifying with syntaxMost of the remarks that can be found in the literature on the relation between syntax and quantificationhave been written with respect to the generic versus non-generic distinction.
Although we have movedaway from the terminology on genericity, the two following examples show the potential promises ?and hurdles ?
of using syntax to induce quantification annotations.?
Noun phrases which act as subjects of simple past tense verbs are usually non-generic: A cow says?moo?
/ A cow said ?moo?
(Gelman, 2004).
However, the so-called ?historic past?
is an exceptionto this rule: The woolly mammoth roamed the earth many years ago.?
The combination of a bare plural and present tense is a prototypical indication of genericity: Tigersare massive (Cimpian and Markman, 2008).
But news headlines behave differently: Cambridgestudents steal cow.We informally investigate the distribution of various grammatical constructions with respect to quan-tification, as obtained from our gold standard.
Although some constructions give a clear majority to oneor another label, that majority is not always overwhelming.
For instance, consistently annotating bareplurals followed by a past tense as SOME would result in a precision of only 54%.
It is therefore unclearhow accurate a classifier based only on syntax can be.
(Note that the quantification phenomenon is un-derstood to be semantically complex and that syntax is only one of many features used in the annotationguidelines produced in Herbelot and Copestake, 2010.
)1705.3 FeaturesWe give the system article and number information for the noun phrase to be quantified, as well as thetense of the verbal predicate following it.
In order to cater for proper nouns, we also indicate whether thehead of the noun phrase is capitalised or not.
Article, number and capitalisation information is similarlyprovided for the object of the verb.
All features are automatically extracted from the Robust MinimalRecursion Semantics (RMRS, Copestake, 2004) representation of the sentence in which the noun phraseappears (obtained via a RASP parse, Briscoe et al, 2006).
The following shows an example of a featureline for a particular noun phrase (the sentence in which the noun phrase appears is also given):ORIGINAL: [His early blues influences] included artists such as RobertJohnson, Bukka White, Skip James and Sleepy John Estes.FEATURES: past,possessive,plural,nocap,bare,plural,nocapNote that articles belonging to the same class are labelled according to that class: all possessivearticles, for instance, are simply marked as ?possessive?.
This is the same for demonstrative articles.5.4 Experiments and resultsThe aim of this work is not only to produce an automatic quantification system, but also, if possible,to learn about the linguistic phenomena surrounding the underspecification of quantification.
Becauseof this, we choose a tree-based classifier which has the advantage of letting us see the rules that arecreated by the system and thereby may allow us to make some linguistic observations with regard to thecooccurrence of certain quantification classes with certain grammatical constructions.
We use an off-the-shelf implementation of the C4.5 classifier (Quinlan, 1993) included in the Weka data mining software.6We perform a 6-fold cross-validation on the gold standard and report class precision, recall and F-score.Class Precision Recall F-scoreONE 86% (362/422) 99% (362/367) 92%SOME 60% (25/42) 47% (25/53) 53%MOST 33% (2/6) 6% (2/34) 10%ALL 53% (57/108) 56% (57/102) 54%QUANT 100% (22/22) 50% (22/44) 67%Table 2: Class precision and recall for the quantification taskThe C4.5 classifier gives 78% overall precision to the quantification task.
Tables 2 shows per classresults for the three tasks.
The figures in brackets indicate the number of true positives for a particularclass, followed by the total number of instances annotated by the system as instances of that class.
Theclassifier performs extremely well with the ONE class, reaching 92% F-score.
Already quantified nounphrases yield perfect precision and mediocre recall, as might be expected since we do not provide thesystem with a list of quantifiers.
The system performs less well with the labels SOME, MOST and ALL.In order to understand the distribution of errors, we perform a detailed analysis on the first fold ofour data.
Out of 100 instances, the classifier assigns 25 to an incorrect class.
The majority of thoseerrors (44%) are due to the fact that the classifier labels all singulars as ONE, missing out on genericinterpretations and in particular on the plural reading of mass terms: out of 11 errors, 5 are linked toa bare singular).
The next most frequent type of error, covering another 16% of incorrectly classifiedinstances, comes from already quantified noun phrases being labelled as another class.
These errorsaffect the recall of the QUANT class and the precision of the SOME, MOST and ALL labels in particular(most of those errors occur in plural noun phrases).
The coarseness of the rules is again to blame forthe remaining errors: looking at the decision tree produced by the classifier, we observe that all bare6http://www.cs.waikato.ac.nz/ml/weka/171plurals followed by a present tense, as well as all definite plurals, are labelled as universals, while allbare plurals followed by a past tense are labelled as SOME.
This accounts for a further 7 errors.
The lastthree incorrect assignments are due to a dubious capitalisation rule.5.5 Correspondence with linguisticsWe observe that most definite plurals (including demonstratives and possessives) are classified as eitherMOST or ALL.
This fits the linguistic notion of a definite as being essentially universal (Lyons, 1999) butalso misses out on the correct quantification of statements such as 10.We note also that non-capitalised bare plurals followed by a present tense are similarly classed asALL.
This echoes the observation that the combination of bare plural and present is a typical manifes-tation of genericity (if one understands genericity as a quantification phenomenon close to universality).When followed by past or perfect tenses, an existential quantification with SOME is however preferred.One of the puzzles opened by the classifier?s decision trees is the use of the direct object feature todistinguish between MOST and ALL in the case of some definite plurals.
Given Sentences 28 and 29, ourclassifier would label the first one as ALL and the second one as MOST.28.
My cats like the armchair.
ALL29.
My cats like the armchairs.
MOSTAt first glance, the rule seems to be a mere statistical effect of our data.
We will however remarkthat statements like 29 are reserved a special section in Link (1998), where they are introduced as ?rela-tional plural sentences?.
One of Link?s claims is that those sentences warrant four collective/distributivecombinations ?
as opposed to two only in the case where the object is an individual.
So we can say inSentence 29 that a collective of cats likes a collective of armchairs, or that this collective of cats likeseach armchair individually, etc.
This proliferation of interpretations makes uncertainties more likely withregard to who likes what, and to the quantification of the subject and object.For now, we will simply conclude that, although a simple syntax-based classifier is able to classifycertain constructs with high precision, other constructs are beyond its capabilities.
Further, it is difficultto see how improvements can be made to the current classification without venturing outside of thegrammatical context.
For instance, it seems practically impossible to improve on the high-precision rulespecifying that every singular noun phrase should be classified as ONE.
Due to space constraints, wewill not report any further experiments in this paper.
However, preliminary investigations into the use oflexical similarity to resolve quantification ambiguity can be found in Herbelot (2010).6 Previous workThe general framework of this proposal is an underspecification account close to that described in Pinkal(1996) or Egg (2010).
Computational approaches to underspecified quantification have so far focusedon the genericity phenomenon.
Leaving aside the question of annotation, which is treated in Herbelotand Copestake (2010), research on genericity can be classified within two strands: theoretical researchon defeasible reasoning and extraction of common sense knowledge.
Attempts to model defeasiblereasoning were made in the 1980s with, for instance, the developments of default logic (Reiter, 1980)and non-monotonic logic (McDermott and Doyle, 1982).
With information extraction as aim, Suh et al(2006) attempt to retrieve ?common sense?
statements from Wikipedia.
They posit that common senseis contained in generic sentences.
Their system, however, makes simplifying assumptions with regard tosyntax: in particular, all bare plurals (and bare plurals only) are considered generic.
In general, commonsense extraction systems tend to restrict the data they mine to avoid the problem of identifying genericity(e.g., Voelker et al, 2007).1727 Conclusion, with some remarks on semanticsWe have shown in this paper that subject noun phrases that are not explicitly quantified could be rep-resented in an underspecified form.
We have also argued that this formalisation is applicable to allconstructs, including so-called generics.
We have introduced a syntax-based classifier for quantificationresolution and discussed the limits of an approach relying on compositional information only.We acknowledge that our quantificational account of noun phrases, and especially of generics, doesnot satisfy the common requirement that a formalisation be a full description of the semantic particu-larities of a linguistic phenomenon.
We think, however, that this requirement has led to over-restrictiveapproaches.
One of the debates surrounding generics, for instance, relates to whether they should begiven a ?rules and regulations?
or an inductivist truth condition (Carlson, 1995).
Our view is that it wouldbe a mistake to exclude either interpretation.
Burton-Roberts?
(1977) A gentleman opens doors for ladiesclearly has normative force and without doubt, also allows the hearer to make their own conclusions withregard to the intersection between the set of all gentlemen and the set of people opening doors for ladies.Our view of semantics is that it is a layered system and that specifying the quantification semanticsof a noun phrase does not mean providing the full semantics of that noun phrase.
It may be argued thatthe ideal semantics of generics should be unified and integrate all possible aspects of meaning.
But sucha theory is yet to be developed for genericity and, from a computational point of view, may not evenbe desirable: a modular representation of meaning allows us to only formalise the aspects that we areinterested in for a particular task, leaving the rest out.The approach presented here can be said to implement the idea of ?slacker?
semantics (Copestake,2009) in that a) our experiments try to derive a specification from compositional information only andb) we only attempt to specify one aspect of the meaning of noun phrases (quantification), leaving otheraspects unspecified.
In the future, we would like to take away some of the slack in a) by using lexicalsemantics in the specification of quantification.
In order to do this, a much larger corpus should becreated for the training and testing of the system, and this will be our next task.ReferencesBriscoe, T., J. Carroll, and R. Watson (2006).
The second release of the RASP system.
In Proceedingsof the COLING/ACL on Interactive presentation sessions, Morristown, NJ, USA, pp.
77?80.Brogaard, B.
(2007).
The But Not All: A Partitive Account of Plural Definite Descriptions.
Mind &Language 22(4), 402?426.Burton-Roberts, N. (1977).
Generic sentences and analyticity.
Studies in Language 1, 155?196.Carlson, G. N. (1977).
Reference to Kinds in English.
Ph.
D. thesis, University of Massachusetts atAmherst.Carlson, G. N. (1995).
Truth-Conditions of Generic Sentences: Two Contrasting Views.
In G. N. Carlsonand F. J. Pelletier (Eds.
), The Generic Book, pp.
224?237.
Chicago: University of Chicago Press.Chierchia, G. (1995).
Individual-level predicates as inherent generics.
In G. N. Carlson and F. J.
Pelletier(Eds.
), The Generic Book, pp.
176?223.
Chicago: University of Chicago Press.Chierchia, G. (1998).
Reference to kinds across languages.
Natural Language Semantics 6, 339?405.Cimpian, A. and E. M. Markman (2008).
Preschool children?s use of cues to generic meaning.
Cogni-tion 107(1), 19?53.Cohen, A.
(1996).
Think Generic: The Meaning and Use of Generic Sentences.
Ph.
D. thesis, Carnegie-Mellon University at Pittsburgh.173Copestake, A.
(2004).
Robust Minimal Recursion Semantics.
http://www.cl.cam.ac.uk/?aac10/papers/rmrsdraft.pdf.Copestake, A.
(2009).
Slacker semantics : why superficiality , dependency and avoidance of commitmentcan be the right way to go.
In Proceedings of the 12th Conference of the European Chapter of theAssociation for Computational Linguistics, Athens, Greece, pp.
1?9.Dowty, D. (1987).
Collective predicates, distributive predicates and all.
In F. Marshall, A. Miller, andZ.-s. Zhang (Eds.
), The Third Eastern States Conference on Linguistics, Columbus, pp.
97?115.
TheOhio State University, Department of Linguistics.Egg, M. (2010).
Semantic Underspecification.
Language and Linguistics Compass 4(3), 166?181.Gelman, S. A.
(2004).
Learning words for kinds: Generic noun phrases in acquisition.
In D. Hall andS.
Waxman (Eds.
), Weaving a lexicon.
Cambridge, MA: MIT Press.Herbelot, A.
(2010).
Underspecified quantification.
Ph.
D. thesis, University of Cambridge.Herbelot, A. and A. Copestake (2010).
Annotating underquantification.
In Proceedings of the FourthLinguistic Annotation Workshop, Uppsala, Sweden, pp.
73?81.Heyer, G. (1990).
Semantics and Knowledge Representation in the Analysis of Generic Descriptions.Journal of Semantics 7(1), 93?110.Krifka, M. (2004).
Bare NPs: Kind-referring, Indefinites, Both, or Neither?
In O. Bonami and P. CabredoHofherr (Eds.
), Empirical Issues in Formal Syntax and Semantics, pp.
111?132.Krifka, M., F. J. Pelletier, G. N. Carlson, A. ter Meulen, G. Chierchia, and G. Link (1995).
Genericity:An Introduction.
In G. N. Carlson and F. J. Pelletier (Eds.
), The Generic Book, pp.
1?125.
Chicago:Chicago University Press.Leslie, S.-J.
(2008).
Generics: Cognition and Acquisition.
Philosophical Review 117(1), 1?47.Link, G. (1983).
The Logical Analysis of Plurals and Mass Terms: a Lattice-Theoretical Approach.
InR.
Bauerle, C. Schwarze, and A. von Stechow (Eds.
), Meaning, Use, and Interpretation of Language,pp.
302?323.
Berlin: de Gruyter.Link, G. (1998).
Plural.
In Algebraic Semantics in Language and Philosophy.
Stanford: CSLI Publica-tions.Lyons, C. (1999).
Definiteness.
Cambridge: Cambridge University Press.McDermott, D. and J. Doyle (1982).
Non-monotonic Logic I.
Artificial Intelligence 13, 41?72.Pelletier, F. J. and N. Asher (1997).
Generics and Defaults.
In J. van Bethem and A. ter Meulen (Eds.
),Handbook of Logic and Language, pp.
1125?1177.
Amsterdam: Elsevier.Pinkal, M. (1996).
Radical Underspecification.
In P. Dekker and M. Stokhof (Eds.
), Proceedings of the10th Amsterdam Colloquium, Amsterdam, pp.
479?498.
de Gruyter.Quinlan, J.
(1993).
Programs for Machine Learning.
San Francisco, CA: Morgan Kaufmann.Reiter, R. (1980).
A logic for default reasoning.
Artificial Intelligence 13(1-2), 81?132.Suh, S., H. Halpin, and E. Klein (2006).
Extracting Common Sense Knowledge from Wikipedia.
InProceedings of the International Semantic Web Conference (ISWC-06).
Workshop on Web ContentMining with Human Language Technology, Athens, GA.Voelker, J., P. Hitzler, and P. Cimiano (2007).
Acquisition of OWL DL Axioms from Lexical Resources.In Proceedings of the Fourth European conference on The Semantic Web: Research and Applications,Innsbruck, Austria, pp.
670?685.
Springer Verlag.174
