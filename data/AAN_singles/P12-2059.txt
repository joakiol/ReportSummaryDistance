Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 301?305,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsCombining Word-Level and Character-Level Modelsfor Machine Translation Between Closely-Related LanguagesPreslav NakovQatar Computing Research InstituteQatar Foundation, P.O.
box 5825Doha, Qatarpnakov@qf.org.qaJo?rg TiedemannDepartment of Linguistics and PhilologyUppsala UniversityUppsala, Swedenjorg.tiedemann@lingfil.uu.seAbstractWe propose several techniques for improv-ing statistical machine translation betweenclosely-related languages with scarce re-sources.
We use character-level translationtrained on n-gram-character-aligned bitextsand tuned using word-level BLEU, which wefurther augment with character-based translit-eration at the word level and combine witha word-level translation model.
The evalua-tion on Macedonian-Bulgarian movie subtitlesshows an improvement of 2.84 BLEU pointsover a phrase-based word-level baseline.1 IntroductionStatistical machine translation (SMT) systems, re-quire parallel corpora of sentences and their transla-tions, called bitexts, which are often not sufficientlylarge.
However, for many closely-related languages,SMT can be carried out even with small bitexts byexploring relations below the word level.Closely-related languages such as Macedonianand Bulgarian exhibit a large overlap in their vo-cabulary and strong syntactic and lexical similari-ties.
Spelling conventions in such related languagescan still be different, and they may diverge moresubstantially at the level of morphology.
However,the differences often constitute consistent regulari-ties that can be generalized when translating.The language similarities and the regularities inmorphological variation and spelling motivate theuse of character-level translation models, whichwere applied to translation (Vilar et al, 2007; Tiede-mann, 2009a) and transliteration (Matthews, 2007).Macedonian Bulgariana v m e a h m ea v m e d a a h m e d av e r u v a m v  r v a md e k a t o j , q e t o $iTable 1: Examples from a character-level phrase table(without scores): mappings can cover words and phrases.Certainly, translation cannot be adequately mod-eled as simple transliteration, even for closely-related languages.
However, the strength of phrase-based SMT (Koehn et al, 2003) is that it can supportrather large sequences (phrases) that capture transla-tions of entire chunks.
This makes it possible to in-clude mappings that go far beyond the edit-distance-based string operations usually modeled in translit-eration.
Table 1 shows how character-level phrasetables can cover mappings spanning over multi-wordunits.
Thus, character-level phrase-based SMT mod-els combine the generality of character-by-charactertransliteration and lexical mappings of larger unitsthat could possibly refer to morphemes, words orphrases, as well as to various combinations thereof.2 Training Character-level SMT ModelsWe treat sentences as sequences of characters in-stead of words, as shown in Figure 1.
Due to thereduced vocabulary, we can use higher-order mod-els, which is necessary in order to avoid the genera-tion of non-word sequences.
In our case, we optedfor a 10-character language model and a maximumphrase length of 10 (based on initial experiments).However, word alignment models are not fit forcharacter-level SMT, where the vocabulary shrinks.301original:MK: navistina ?BG: naistina ?characters:MK: n a v i s t i n a ?BG: n a i s t i n a ?character bigrams:MK: na av vi is st ti in na a ?
?BG: na ai is st ti in na a ?
?Figure 1: Preparing the training corpus for alignment.Statistical word alignment models heavily rely oncontext-independent lexical translation parametersand, therefore, are unable to properly distinguishcharacter mapping differences in various contexts.The alignment models used in the transliteration lit-erature have the same problem as they are usuallybased on edit distance operations and finite-state au-tomata without contextual history (Jiampojamarn etal., 2007; Damper et al, 2005; Ristad and Yiani-los, 1998).
We, thus, transformed the input to se-quences of character n-grams as suggested by Tiede-mann (2012); examples are shown in Figure 1.
Thisartificially increases the vocabulary as shown in Ta-ble 2, making standard alignment models and theirlexical translation parameters more expressive.Macedonian Bulgariansingle characters 99 101character bigrams 1,851 1,893character trigrams 13,794 14,305words 41,816 30,927Table 2: Vocabulary size of character-level alignmentmodels and the corresponding word-level model.It turns out that bigrams constitute a good com-promise between generality and contextual speci-ficity, which yields useful character alignments withgood performance in terms of phrase-based transla-tion.
In our experiments, we used GIZA++ (Ochand Ney, 2003) with standard settings and the grow-diagonal-final-and heuristics to symmetrize the fi-nal IBM-model-4-based Viterbi alignments (Brownet al, 1993).
The phrases were extracted and scoredusing the Moses training tools (Koehn et al, 2007).1We tuned the parameters of the log-linear SMTmodel using minimum error rate training (Och,2003), optimizing BLEU (Papineni et al, 2002).1Note that the extracted phrase table does not include se-quences of character n-grams.
We map character n-gram align-ments to links between single characters before extraction.Since BLEU over matching character sequencesdoes not make much sense, especially if the k-gramsize is limited to small values of k (usually, 4 orless), we post-processed n-best lists in each tuningstep to calculate the usual word-based BLEU score.3 TransliterationWe also built a character-level SMT system forword-level transliteration, which we trained on a listof automatically extracted pairs of likely cognates.3.1 Cognate ExtractionClassic NLP approaches to cognate extraction lookfor words with similar spelling that co-occur in par-allel sentences (Kondrak et al, 2003).
Since ourMacedonian-Bulgarian bitext (MK?BG) was small,we further used a MK?EN and an EN?BG bitext.First, we induced IBM-model-4 word alignmentsfor MK?EN and EN?BG, from which we extractedfour conditional lexical translation probabilities:Pr(m|e) and Pr(e|m) for MK?EN, and Pr(b|e) andPr(e|b) for EN?BG, where m, e, and b stand for aMacedonian, an English, and a Bulgarian word.Then, following (Callison-Burch et al, 2006; Wuand Wang, 2007; Utiyama and Isahara, 2007), weinduced conditional lexical translation probabilitiesas Pr(m|b) =?e Pr(m|e) Pr(e|b), where Pr(m|e)and Pr(e|b) are estimated using maximum likeli-hood from MK?EN and EN?BG word alignments.Then, we induced translation probability estima-tions for the reverse direction Pr(b|m) and we cal-culated the quantity Piv(m, b) = Pr(m|b) Pr(b|m).We calculated a similar quantity Dir(m, b), wherethe probabilities Pr(m|b) and Pr(b|m) are estimatedusing maximum likelihood from the MK?BG bitextdirectly.
Finally, we calculated the similarity scoreS(m, b) = Piv(m, b)+Dir(m, b)+2?LCSR(m, b),where LCSR is the longest common subsequence oftwo strings, divided by the length of the longer one.The score S(m, b) is high for words that are likelyto be cognates, i.e., that (i) have high probability ofbeing mutual translations, which is expressed by thefirst two terms in the summation, and (ii) have sim-ilar spelling, as expressed by the last term.
Here wegive equal weight to Dir(m, b) and Piv(m, b); wealso give equal weights to the translational similar-ity (the sum of the first two terms) and to the spellingsimilarity (twice LCSR).302We excluded all words of length less than three, aswell as all Macedonian-Bulgarian word pairs (m, b)for which Piv(m, b) + Dir(m, b) < 0.01, and thosefor which LCSR(m, b) was below 0.58, a valuefound by Kondrak et al (2003) to work well for anumber of European language pairs.Finally, using S(m, b), we induced a weighted bi-partite graph, and we performed a greedy approxi-mation to the maximum weighted bipartite matchingin that graph using competitive linking (Melamed,2000), to produce the final list of cognate pairs.Note that the above-described cognate extractionalgorithm has three important components: (1) or-thographic, based on LCSR, (2) semantic, basedon word alignments and pivoting over English, and(3) competitive linking.
The orthographic compo-nent is essential when looking for cognates sincethey must have similar spelling by definition, whilethe semantic component prevents the extraction offalse friends like vreden, which means ?valuable?in Macedonian but ?harmful?
in Bulgarian.
Finally,competitive linking helps prevent issues related toword inflection that cannot be handled using the se-mantic component alone.3.2 Transliteration TrainingFor each pair in the list of cognate pairs, we addedspaces between any two adjacent letters for bothwords, and we further appended special start andend characters.
We split the resulting list intotraining, development and testing parts and wetrained and tuned a character-level Macedonian-Bulgarian phrase-based monotone SMT system sim-ilar to that in (Finch and Sumita, 2008; Tiedemannand Nabende, 2009; Nakov and Ng, 2009; Nakovand Ng, 2012).
The system used a character-levelBulgarian language model trained on words.
We setthe maximum phrase length and the language modelorder to 10, and we tuned the system using MERT.3.3 Transliteration Lattice GenerationGiven a Macedonian sentence, we generated a lat-tice where each input Macedonian word of lengththree or longer was augmented with Bulgarian al-ternatives: n-best transliterations generated by theabove character-level Macedonian-Bulgarian SMTsystem (after the characters were concatenated toform a word and the special symbols were removed).In the lattice, we assigned the original Macedo-nian word the weight of 1; for the alternatives, weassigned scores between 0 and 1 that were the sumof the translation model probabilities of generatingeach alternative (the sum was needed since some op-tions appeared multiple times in the n-best list).4 Experiments and EvaluationFor our experiments, we used translated movie sub-titles from the OPUS corpus (Tiedemann, 2009b).For Macedonian-Bulgarian there were only about102,000 aligned sentences containing approximately1.3 million tokens altogether.
There was substan-tially more monolingual data available for Bulgar-ian: about 16 million sentences containing ca.
136million tokens.However, this data was noisy.
Thus, we realignedthe corpus using hunalign and we removed someBulgarian files that were misclassified as Macedo-nian and vice versa, using a BLEU-filter.
Fur-thermore, we also removed sentence pairs contain-ing language-specific characters on the wrong side.From the remaining data we selected 10,000 sen-tence pairs (roughly 128,000 words) for develop-ment and another 10,000 (ca.
125,000 words) fortesting; we used the rest for training.The evaluation results are summarized in Table 3.MK?BG BLEU % NIST TER METEORTransliterationno translit.
10.74 3.33 67.92 60.30t1 letter-based 12.07 3.61 66.42 61.87t2 cogn.+lattice 22.74 5.51 55.99 66.42Word-level SMTw0 Apertium 21.28 5.27 56.92 66.35w1 SMT baseline 31.10 6.56 50.72 70.53w2 w1 + t1-lattice 32.19(+1.19) 6.76 49.68 71.18Character-level SMTc1 char-aligned 32.28(+1.18) 6.70 49.70 71.35c2 bigram-aligned 32.71(+1.61) 6.77 49.23 71.65trigram-aligned 32.07(+0.97) 6.68 49.82 71.21System combinationw2 + c2 32.92(+1.82) 6.90 48.73 71.71w1 + c2 33.31(+2.21) 6.91 48.60 71.81Merged phrase tablesm1 w1 + c2 33.33(+2.13) 6.86 48.86 71.73m2 w2 + c2 33.94(+2.84) 6.89 48.99 71.76Table 3: Macedonian-Bulgarian translation andtransliteration.
Superscripts show the absolute improve-ment in BLEU compared to the word-level baseline (w1).303Transliteration.
The top rows of Table 3 showthe results for Macedonian-Bulgarian transliteration.First, we can see that the BLEU score for the originalMacedonian testset evaluated against the Bulgarianreference is 10.74, which is quite high and reflectsthe similarity between the two languages.
The nextline (t1) shows that many differences between Mace-donian and Bulgarian stem from mere differences inorthography: we mapped the six letters in the Mace-donian alphabet that do not exist in the Bulgarian al-phabet to corresponding Bulgarian letters and lettersequences, gaining over 1.3 BLEU points.
The fol-lowing line (t2) shows the results using the sophis-ticated transliteration described in Section 3, whichtakes two kinds of context into account: (1) word-internal letter context, and (2) sentence-level wordcontext.
We generated a lattice for each Macedoniantest sentence, which included the original Mace-donian words and the 1-best2 Bulgarian transliter-ation option from the character-level transliterationmodel.
We then decoded the lattice using a Bulgar-ian language model; this increased BLEU to 22.74.Word-level translation.
Naturally, lattice-basedtransliteration cannot really compete against stan-dard word-level translation (w1), which is betterby 8 BLEU points.
Still, as line (w2) shows,using the 1-best transliteration lattice as an inputto (w1) yields3 consistent improvement over (w1)for four evaluation metrics: BLEU (Papineni etal., 2002), NIST v. 13, TER (Snover et al, 2006)v. 0.7.25, and METEOR (Lavie and Denkowski,2009) v. 1.3.
The baseline system is also signifi-cantly better than the on-line version of Apertium(http://www.apertium.org/), a shallow transfer-rule-based MT system that is optimized for closely-related languages (accessed on 2012/05/02).
Here,Apertium suffers badly from a large number of un-known words in our testset (ca.
15%).Character-level translation.
Moving down tothe next group of experiments in Table 3, we cansee that standard character-level SMT (c1), i.e.,simply treating characters as separate words, per-forms significantly better than word-level SMT.
Us-ing bigram-based character alignments yields fur-ther improvement of +0.43 BLEU.2Using 3/5/10/100-best made very little difference.3The decoder can choose between (a) translating a Macedo-nian word and (b) using its 1-best Bulgarian transliteration.System combination.
Since word-level andcharacter-level models have different strengths andweaknesses, we further tried to combine them.We used MEMT, a state-of-the-art Multi-EngineMachine Translation system (Heafield and Lavie,2010), to combine the outputs of (c3) with the out-put of (w1) and of (w2).
Both combinations im-proved over the individual systems, but (w1)+(c2)performed better, by +0.6 BLEU points over (c2).Combining word-level and phrase-level SMT.Finally, we also combined (w1) with (c3) in a moredirect way: by merging their phrase tables.
First,we split the phrases in the word-level phrase tablesof (w1) to characters as in character-level models.Then, we generated four versions of each phrasepair: with/without ?
?
at the beginning/end of thephrase.
Finally, we merged these phrase pairs withthose in the phrase table of (c3), adding two ex-tra features indicating each phrase pair?s origin: thefirst/second feature is 1 if the pair came from thefirst/second table, and 0.5 otherwise.
This combina-tion outperformed MEMT, probably because it ex-pands the search space of the SMT system more di-rectly.
We further tried scoring with two languagemodels in the process of translation, character-basedand word-based, but we did not get consistent im-provements.
Finally, we experimented with a 1-bestcharacter-level lattice input that encodes the sameoptions and weights as for (w2).
This yielded ourbest overall BLEU score of 33.94, which is +2.84BLEU points of absolute improvement over the (w1)baseline, and +1.23 BLEU points over (c2).45 Conclusion and Future WorkWe have explored several combinations of character-and word-level translation models for translatingbetween closely-related languages with scarce re-sources.
In future work, we want to use such a modelfor pivot-based translations from the resource-poorlanguage (Macedonian) to other languages (such asEnglish) via the related language (Bulgarian).AcknowledgmentsThe research is partially supported by the EU ICTPSP project LetsMT!, grant number 250456.4All improvements over (w1) in Table 3 that are greater orequal to 0.97 BLEU points are statistically significant accordingto Collins?
sign test (Collins et al, 2005).304ReferencesPeter Brown, Vincent Della Pietra, Stephen Della Pietra,and Robert Mercer.
1993.
The mathematics of statis-tical machine translation: parameter estimation.
Com-putational Linguistics, 19(2):263?311.Chris Callison-Burch, Philipp Koehn, and Miles Os-borne.
2006.
Improved statistical machine translationusing paraphrases.
In Proceedings of HLT-NAACL?06, pages 17?24, New York, NY.Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of ACL ?05, pages 531?540, Ann Arbor, MI.Robert Damper, Yannick Marchand, John-DavidMarsters, and Alex Bazin.
2005.
Aligning text andphonemes for speech technology applications using anEM-like algorithm.
International Journal of SpeechTechnology, 8(2):149?162.Andrew Finch and Eiichiro Sumita.
2008.
Phrase-basedmachine transliteration.
In Proceedings of the Work-shop on Technologies and Corpora for Asia-PacificSpeech Translation, pages 13?18, Hyderabad, India.Kenneth Heafield and Alon Lavie.
2010.
Combin-ing machine translation output with open source:The Carnegie Mellon multi-engine machine transla-tion scheme.
The Prague Bulletin of MathematicalLinguistics, 93(1):27?36.Sittichai Jiampojamarn, Grzegorz Kondrak, and TarekSherif.
2007.
Applying many-to-many alignmentsand hidden Markov models to letter-to-phoneme con-version.
In Proceedings of NAACL-HLT ?07, pages372?379, Rochester, New York.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of NAACL ?03, pages 48?54, Edmonton, Canada.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of ACL ?07, pages 177?180, Prague, Czech Re-public.Grzegorz Kondrak, Daniel Marcu, and Kevin Knight.2003.
Cognates can improve statistical translationmodels.
In Proceedings of NAACL ?03, pages 46?48,Edmonton, Canada.Alon Lavie and Michael Denkowski.
2009.
The Meteormetric for automatic evaluation of machine translation.Machine Translation, 23:105?115.David Matthews.
2007.
Machine transliteration ofproper names.
Master?s thesis, School of Informatics,University of Edinburgh, Edinburgh, UK.Dan Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.Preslav Nakov and Hwee Tou Ng.
2009.
Improved statis-tical machine translation for resource-poor languagesusing related resource-rich languages.
In Proceedingsof EMNLP ?09, pages 1358?1367, Singapore.Preslav Nakov and Hwee Tou Ng.
2012.
Improvingstatistical machine translation for a resource-poor lan-guage using related resource-rich languages.
Journalof cial Intelligence Research, 44.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of ACL?03, pages 160?167, Sapporo, Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proceedings of ACL?02, pages 311?318, Philadelphia, PA.Eric Ristad and Peter Yianilos.
1998.
Learning stringedit distance.
IEEE Transactions on Pattern Recogni-tion and Machine Intelligence, 20(5):522?532.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings of AMTA ?06, pages 223?231.Jo?rg Tiedemann and Peter Nabende.
2009.
Translatingtransliterations.
International Journal of Computingand ICT Research, 3(1):33?41.Jo?rg Tiedemann.
2009a.
Character-based PSMT forclosely related languages.
In Proceedings of EAMT?09, pages 12?19, Barcelona, Spain.Jo?rg Tiedemann.
2009b.
News from OPUS - A collectionof multilingual parallel corpora with tools and inter-faces.
In Recent Advances in Natural Language Pro-cessing, volume V, pages 237?248.
John Benjamins.Jo?rg Tiedemann.
2012.
Character-based pivot transla-tion for under-resourced languages and domains.
InProceedings of EACL ?12, pages 141?151, Avignon,France.Masao Utiyama and Hitoshi Isahara.
2007.
A compar-ison of pivot methods for phrase-based statistical ma-chine translation.
In Proceedings of NAACL-HLT ?07,pages 484?491, Rochester, NY.David Vilar, Jan-Thorsten Peter, and Hermann Ney.2007.
Can we translate letters?
In Proceedings ofWMT ?07, pages 33?39, Prague, Czech Republic.Hua Wu and Haifeng Wang.
2007.
Pivot languageapproach for phrase-based statistical machine transla-tion.
Machine Translation, 21(3):165?181.305
