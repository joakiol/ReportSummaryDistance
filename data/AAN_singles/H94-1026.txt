Toward Multi-Engine Machine TranslationSergei Nirenburg and Robert FrederlcingCenter for Machine TranslationCarnegie Mellon UniversityPittsburgh, PA 15213ABSTRACTCurrent MT systems, whatever translation method they at presentemploy, do not reach an optimum output on free text.
Our hy-pothesis for the experiment reported in this paper is that if an MTenvironment can use the best results from a variety of MT systemsworking simultaneously onthe same text, the overallquality will im-prove.
Using this novel approach to MT in the latest version of thePangloss MT project, we submit an input text to a battery of machinetranslation systems (engines), coLlect heir (possibly, incomplete) re-sults in a joint chaR-like data structure and select the overall besttranslation using a set of simple heuristics.
This paper describes thesimple mechanism we use for combining the findings of the varioustranslation engines.1.
INTRODUCTIONA number of proposals have come up in recent years for hybridiza-tion of MT.
Current MT projects - -  both "pure" and hybrid, bothpredominantly technology-oriented an  research-oriented aresingle-engine projects, capable of one particular type of source text analysis,one particular method of finding target language correspondences forsource language lements and one prescribed method of generatingthe target language text.It is common knowledge that MT systems, whatever translationmethod they at present employ, do not reach an optimum outputon free text.
In part, this is due to the inherent problems of aparticular method - for instance, the inability of statistics-basedMT to take into account long-distance dependencies or the relianceof most transfer-oriented MT systems on similarities in syntacticstructures of the source and the target languages.
Another crucialsource of deficiencies i the size and quality of the static knowledgesources underlying the various MT systems - pmlicular grammars,lexicons and world models.
Thus, in knowledge-based MT the sizeof the underlying world model is typically smaller than necessary forsecure coverage of free text.Our hypothesis for the experiment reported in this paper is that ifan MT environment can use the best results from a variety of MTsystems working simultaneously on the same text, the overall qualitywill improve.
Using this novel approach to MT in the latest versionof the Pangloss MT project, we submit an input text to a batteryof machine translation systems (engines), collect their (possibly,incomplete) results in a joint chart-like data structure and select heoverall best translation using a set of simple heuristics.2.
INTEGRATING MULTI-ENGINEOUTPUTThe MT configuration i our experiment used three MT engines:?
a knowledge-based MT (K.B MT) system, the mainline Panglossengine\[l\];?
an example-based MT (EBMT) system (see \[2, 3\]; the originalidea is due to Nagao\[4\]); and?
a lexical transfer system, fortified with morphological nalysisand synthesis modules and relying on a number of databases- a machine-readable dictionary (the Collins Spanish/English),the lexicons used by the KBMT modules, a large set of user-generated bilingual glossaries as well as a gazetteer and a Listof proper and organization names.The results (target language words and phrases) were recorded ina chart whose initial edges corresponded to words in the sourcelanguage input.
As a result of the operation of each of the MTengines, new edges were added to the chart, each labeled with thetranslation of a segment of the input string and indexed by thissegment's beginning and end positions.
The KBMT and EBMTengines also carried a quality score for each output element.
Figure 1presents a general view of the operation of our multi-engine MTsystem.UserTranslator'sWorkStat ionKnowledge-Based MTChart~mpl~Based  MT Mana~,erLexical transfer b i tFigure I: Structure of a multi-engine MT systemIn what follows we illustrate the behavior of the system using theexample Spanish sentence: AI momento de su venta a lberia, VIASAcontaba con ocho aviones, que tentan en promedio 13 afios de vuelowhich can be translated into English as At the moment of its sale tolberia, VIASA had eight airplanes, which had on average thirteenyears offlight (time).
This is a sentence from one of the 1993 ARPAMT evaluation texts.147The initial collecfion of candidate partial translations placed in thechart for this sentence by each individual engine are shown in Fig-ures 2, 3, 4, 5, and 6.
The chart manager selects the overall bestcover" from this collection of candidate partial translations by pro-viding each edge with a normalized positive quality score (largerbeing better), and then selecting the best combination fedges withthe help of the chart-walk algorithm.Position Input OutputLeft Right (Spanish) (English)0 1 A1 momento "A moment"2 4 de su venta "sale.
"5 6 a Iberia iberia8 8 VIASA Viasa11 12 ocho aviones eight airplane15 15 tertian do.16 21 en promedio 13 afios de vuelo "thirteen in"Figure 2: Knowledge-Based MT (KBMT) candidatesPosition Input OutputLeft Right (Spanish) (English)0 0 A1 AI0 1 AI momento "In a minute" At once"3 3 su his her its one's your their4 4 venta inn sale selling marketing6 6 Iberia Iberia7 7 NIL9 9 contaba "was count" count9 10 contaba con "was rely on" "rely on""was count on" "count on" "wasdepending on" "depended on"13 13 NIL15 15 tenfan "were have" have "were hold"hold "were thinking" thought"were considering" considered"were deeming" deemed"were coming" came17 17 promedio average mean middle midpoint19 19 afios year21 21 vuelo flightPosition Input OutputLeft Right (Spanish) (English)19 21 afios de vuelo "flight activities" "of years"19 21 afios de vuelo "years of experience withspace flight"Figure 3: Example-Based MT (EBMT) candidatesPosition Input OutputLeft Right (Spanish) (English)1 1 momento time moment hour momentum3 3 su his her your their its4 4 venta sale6 6 Iberia Iberia9 10 contaba con "count on" have12 12 aviones airplane18 18 13 13Figure 4: Transfer-Based MT (lexicon candidates)2.1.
Scoring the outputs of MT enginesThe scores in the chart are normalized to reflect the empiricallyderived expectation f the relative quality of output produced by aparticular engine.
In the case of K.BMT and EBMT, the pre-existingscores are modified, while edges from other engines receive scoresdetermined by a constant for each engine.These modifications can include any calculation which can be madewith information available from the edge.
For example, currently theK.BMT scores are reduced by a constant, except for known erroneousoutput, which has its score set to zero.
The EBMT scores initiallyrange from 0 being perfect o 10,000 being totally bad; but thequality is nonlinear.
So a region selected by two cutoff constants iconverted by a simple linear equation i to scores ranging from zeroFigure 5: Transfer-Based MT (glossary candidates)to a normalized maximum EBMT score.
Lexical transfer results arescored based on the reliability of individual glossaries.In every case, the base score produced by the scoring functions imultiplied by the length of the candidate inwords, on the assumptionthat longer items are better.
This may be producing too large aneffect on the chart-walk.
We intend to test functions other thanmultiplication i  order to find the right level of influence for length.The scoring functions represent all of the chart manager's knowledgeabout relative quality of edges.
Once the edges are scored, thecover is produced using a simple dynamic programming algorithm,described below.2.2.
The chart-walk algorithmFigure 7 presents the chart-walk algorithm used to produce a sin-gle, best, non-overlapping, contiguous combination f the availablecomponent translations.
The algorithm uses dynamic programmingto find the optimal cover (a cover with the best cumulative score), as-suming correct component quality scores.
The code is organized asa recursive divide-and-conquer procedure: for each position withina segment, the sentence is split into two parts, the best possible coverfor each part is recursively found, and the two scores are combinedto give a score for the chart-walk containing the two best subwalks.This primitive step is repeated for each possible top-level split of theinput sentence, compared with each other and with any simple dges(from the chart) spanning the segment, and the overall best result isused.Without dynamic programming, this would have a combinatorialtime complexity.
Dynamic programming utilizes a large array tostore partial results, so that he best cover of any given subsequenceis only computed once; the second time that a recursive call wouldcompute the same result, it is retrieved from the array instead.
Thisreduces the time complexity opolynomial, and in practice ituses an148Position Input OutputLeft Right (Spanish) (English)0 0 AI1 1 momento2 2 de3 3 su4 4 venta5 5 a6 6 Iberia7 78 8 VIASA9 9 contaba10 10 con11 11 echo12 12 aviones13 13 ,14 14 que15 15 tenian16 16 en17 17 promedio18 18 1319 19 aries20 20 de21 21 vuelo22 22"To the ..... Fo it" "To him" "To you"moment instant ime "just amoment!
.
.
.
.
in due time" "in duecourse" when the time isright" momentumconsequence importanceof from about for byits his her one's your theirsale selling marketing countzyinn small shop stall boothto ao fNILVIASA"was count" count "number off""was include" include "count in""was reckon" reckon"was consider" considerwith by although in towardeight eighthaeroplanes planes aircraftsairplanes martins hopscoteheswho that whom which"were have" have "have got""were possess" possess "werehold" hold "hold on to""hold up" "were grasp"in on onto at byaverage middle mid-pointNILyearsof from about for byflight "to dash off" "to clear off""to leave the parental nest""spread one's wings" "tooverhear sth in passing" to catchon immediately" "get it at once""to be pretty smart" 'flight feathers"Figure 6: Transfer-Based MT (MRD candidates)insignificant part of total processing time.The combined score for a sequence of edges is the weighted averageof their individual scores.
Weighting by length is necessary so thatthe same edges, when combined in a different order, produce thesame combined scores.
In other words, whether edges a, b, and c arecombined as ((a b) c) or (a (b c)), the combined edge must have thesame score, or the algorithm can produce inconsistent results.The chart-walk algorithm can also be visualized as a task of filling atwo-dimensional array.
The array for our example sentence is shownin Figure 8.
Element ( id)  of the array is the best score for any set ofedges covering the input from word i to word j.
(The associated listof edges is not shown, for readability.)
For any position, the score isTo find best walk on a segment:if there is a stored result for this segmentthen return itelsebeginget al primitive edges for this segmentfor each position p within this segmentbeginsplit segment into two parts at pfind best walk for first partfind best walk for second partcombine into an edgeendfind maximum score over all primitiveand combined edgesstore and return itendFigure 7: Chart-walk algorithmcalculated as a weighted average of the scores in the row to its left,in the column below it and the previous contents of the array cell forits position.
So to calculate lement (1,4), we compare the combinedscores of the best walks over (1,1) and (2,4), (1,2) and (3,4), and(1,3) and (4,4) with the scores of any chart edges going from 1 to4, and take the maximum.
When the score in the top-right comer isproduced, the algorithm is finished, and the associated set of edgesis the final chart-walk result.It may seem that the scores should increase towards the top-rightcomer.
In our experiment, howevel~ this has not generally beenthe case.
Indeed, the system suggested a number of high-scoringshort edges, but many low-scoring edges had to be included to spanthe entire input.
Since the score is a weighted average ,  these low-scoring edges pull it down.
A clear example can be seen at position(18,18), which has a score of 15.
The scores above and to its righteach average this 15 with a 5, for total values of 10.0, and the scorecontinues to decrease with distance from this point as one movestowards the final score, which does include (18,18) in the cover.2 .3 .
Reorder ing  componentsThe chart-oriented integration of MT engines does not easily sup-port deviations from the linear order of the source text elements, aswhen discontinuous constituents ranslate contiguous trings or inthe case of cross-segmental substring order differences.
Following avenerable tradition in MT, we used a target language-dependent setof postprocessing rules to alleviate this problem (e.g., by switchingthe order of adjectives and nouns in a noun phrase if it was producedby the word-for-word engine).3 .
TRANSLAT ION DEL IVERY SYSTEMResults of multi-engine MT were fed in our experiment into a trans-lator's workstation (TWS)\[5\], through which a translator either ap-proved the system's output or modified it.
The main option for hu-man interaction i  TWS currently is the Component Machine-AidedTranslation (CMAT) editor\[6\].
A view of this editor is presentedin Figure 9.
(The user can see the original source language text inanother editor window.)
The user can use menus, function keys andmouse clicks to change the system's initially chosen candidate trans-1490i23456789tO111213141516171819202122051I02.52 3 4 57.3 6.75 6.4 5.62.25 3.16 3.62 3.32 3.5 4.0 3.55 5.0 4.05 3.526 7 8 9 I0 ii 12 13 14 15 16 17 18 19 20 21 225.57 5.5 5.1 5.1 6.0 5.663.58 3.78 3.56 3.72 4.85 4.593.8 4.0 3.71 3.87 5.11  4.84.25 4.4 4.0 4.14 5.5 5.114.0 4.25 3.8 4.0 5.57 5.133.5 4.0 3.5 3.8 5.66 5.145 5.0 4.0 4.25 6.4 5.665 3.5 4.0 6.75 5.82 3.5 7.33 6.05 10 7.33 6.12  5.9 5.25 5.21 42 2.0 2.16 2.87 2.7 3.08 22 2.25 3.16 2.87 3.3 32.5 3.75 3.16 3.62 35 3.5 4.0 32 3.5 35 325.42 5.39 5.16 5.15 4.97 4.97 5.5 5.47 5.31 5.96 5.784.42 4.46 4.29 4.33 4.19 4.24 4.83 4.84 4.7 5.41 5.254.59 4.63 4.42 4.46 4.3 4.34 4.97 4.97 4.82 5.55 5.384.85 4.86 4.63 4.65 4.46 4.5 5.16 5.15 4.97 5.74 5.554.83 4.85 4.59 4.63 4.42 4.46 5.16 5.16 4.97 5.78 5.584.81 4.83 4.55 4.59 4.38 4.42 5.18 5.16 4.97 5.83 5.615.21 5.18 4.83 4.85 4.59 4.62 5.42 5.39 5.16 6.06 5.825.25 5.21 4.81 4.83 4.55 4.59 5.45 5.42 5.17 6.13 5.875.3 5.25 4.78 4.81 4.5 4.55 5.5 5.45 5.19 6.21 5.93?
81 4.83 5.85 5.77 5.45 6.54 6.21?
92 3.18 4.5 4.55 4.31 5.58 5.31?
08 3.35 4.81 4.83 4.55 5.91 5.58?
3 3.58 5.21 5.18 4.83 6.30 5.91?
5 3.8 5.66 5.57 5.12 6.72 6.25?
0 3.5 5.8 5.66 5.14 6.94 6.39.5 4.0 6.75 6.4 5.66 7.64 6.943.5 7.33 6.75 5.8 8.09 7.225 10.0 8.33 6.75 9.30 8.0915 10.0 7.33 10.3 8.705 3.5 8.84 7.132 3.5 3.05 3.52Figure 8: Triangular array produced by chart-walklation string, as well as perform both regular and enhanced editingactions.The phrases marked by double angle brackets are "components",each of which is the first translation from a candidate chosen by thechart-walk.
In the typical editing action shown, the user has clickedon a component to get the main CMAT menu.
This menu shows thecorresponding source text, and provides everal functions (such asmoving or deleting the whole constituent) and altsrnate translations,followed by the original source text as an option.
If the user selectsan alternate translation, it instantly replaces the component in the_ editor window, which becomes the first alternative in this menu ffit is used again.
The alternate translations are the other translationsfrom the chosen edge 1.Figure IO presents the sets of candidates in the best chart-walk thatare presented as choices to the human user through the CMAT editorin our example.
It also shows their individual engine-level qualityScoreS.4.
TESTING AND EVALUATINGMULTI-ENGINE PERFORMANCEAs a development tool, it is useful to have an automatic testing proce-dure that would assess the utility of the multi-engine system relativeto the engines taken separately.
The best method we could comeup with was counting the number of keystrokes, in an advanced textprocessor, such as the TWS, necessary to convert he outputs of in-dividual engines and the multi-engine configuration toa"canonical"human translation.
A sample test on a passage of 2060 charactersfrom the June 1993 evaluation of Pangloss is shown in figure 11.The difference in keystrokes was calculated as follows: onekeystroke for deleting a character, two keystrokes for inserting acharacter, three keystrokes for deleting a word (in an editor with1 The CMAT editor may also include translations from other candidates,lower in the menu, if they have the same boundaries as the chosen candidateand the menu is not too long.m - 1<<Realty Refund Trust>> <<buy>> <<thepropert ies of two unions>><<Realty Refund Trust>> <<in>> <<one effort>><<by>> <<to elaborate on>> <<his>> <<investmentportfolio>> <<and>> <<increase>> <<its>><<return>> <<to decidestate unions>> <<of<<of>> <<New York>> <<i:<<valued at>> <<dollami l l ion dollars>><<the acquis i t ion oIncome Fund Lp>> <<aCorporate Income Fpurchase>> <<~n i oh>><<twenty-two>> <<prop<<the first acquisireal estate>> <<of>><<t~rpical>> <<a>> <<re<<real estate>> <<ref<<existing generat i<<such as>> <<commerc<<industrial>> <<and>><<unity>> <<multiple>>'amt .argraml\]zlzt~s; Fi~.shto m.~nsnt~:ov 1.argermmzntm:<<t~ rea lliability>>a Iing s>>~dred fourZorporate~epercq<<onestltute>><<commercialfund Trust>>trust>> <<in>>property>>,> <<interest>>state>>iary>> <<of>>L~m4;: ZNSLZII~\[; IJe44: ')~UI~; no4.~,~LedbFigure 9: The TWS CMAT editor (main menu)mouse action); three keystrokes plus the number of characters in theword being inserted for inserting a word.
It is clear fi'om the abovetable that the multi-engine configuration works bet~r than any ofour available individual engines, though it still does not reach thequality of a Level 2 ~anslator.
It is clear that using keysUokes as ameasure is not completely satisfactory under the given conditions.It would be much better to make the comparison ot against asingle150Position Input Output Engine ScoreLeft Right (Sp~aish) (English)0 1 A!
"In a minute" GLOSS 10momento "At once"~A moment"2 2 de of from about for by MRD 23 3 su his her its GLOSS 5one's your their4 4 venta inn sale selling GLOSS 5marketing "countryinn" =small shop"stall booth5 5 a toaof MRD 26 6 Ibena lberia GLOSS 57 7 GLOSS 58 8 ~/IASA ~/IASA MRD 29 10 contaba "was rely on" GLOSS 10con =rely on" "wascount on" "count on"~was depending on"=depended on" have11 11 ocho eight eighth MRD 212 12 av iones  airplane ~ 2.5aeroplanesplanesaircraftsairplanesmartinshopscotches13 13 GLOSS 514 14 que who that MRD 2whom which15 15 tenian "were have" have" GLOSS 5"were hold" hold=were thinking"thought "wereconsidering"considered "weredeeming" deemed"were coming" came16 16 en in on onto MRD 2atby17 17 promedio average mean GLOSS 5middle midpointmid-point18 18 13 13 MTLEX 1519 21 afios de =years of experience EBMT 8.85vuelo with space flight""flight activities"~of years"22 22 MRD 2Figure 10: Chart-walk results"canonical" translation but against a set of equivalent paraphrastictranslations, the reason being that, as all translators know, there aremany "correct" ways of translating a given input, so that a moreappropriate t st would be counting the number of keystrokes ofdif-ference between the system output and the closest member of the setof correct ranslation paraphrases.
However, this is predicated onthe availability of a "'paraphraser" system, developing which is nota trivial task.Type of translation Number of keystrokes toconvert to canonicalUranslationhuman tester (US Government 1542Level 2 translator)word-for-word lookup in MRDs 1829lookup in phrasal glossaries 1973K.BMT 1883Example-Based MT 1876Multi-engine configuration 1716Figure 11: Results of keystroke test5.
FUTURE WORKUltimately, a multi-engine system depends on the basic quality ofeach particular engine.
We expect he performance of some of theindividual engines (especially, KBMT and EBMT) to grow.
Conse-quently, the multi-engine environment will improve, as larger staticknowledge sources are added and the scoring mechanism is furtheradjusted.
We expect to gain insight into how to improve the scoringmechanism: we plan a battery of tests to help adjust he coefficientson the function which combines the individual scores in the finalscore.
We plan to use a standard regression mechanism tomodifythese scores based on feedback from having humans elect he bestcovers for test exts.
We expect such calibration further to optimizethe system to produce the best possible output from the set of avail-able candidate translations produced by the multiple ngines.
Wealso intend to develop a method of how to empirically assess theexpected output quality of each translation engine based on its avail-able resources, uch as dictionaries, glossaries, grammars, paragelcorpora, etc.References1.
Frederking, R., A. Cohen, P. Cousseau, D. Grannes and S.Nirenburg.
"The Pangloss Mark I MAT System."
Proceedingsof EACL-93, Utrecht, The Netherlands, 1993.2.
Nirenburg, S. C. Domashnev and D.J.
Grannes.
"Two Ap-proaches to Matching in Example-Based Machine Transla-tion."
Proceedings ofTMI-93, Kyoto, 1993.3.
Nirenburg, S., S. Beale, C. Domaslmev and P.
Sheridan.
"Example-Based Machine Translation of Running Text."
Inpreparation.4.
Nagao, M. "A framework of a mechanical translation betweenJapanese and English by analogy principle."
In: A. Elithornand R. B anerji (eds.)
Artificial and Human Intelligence.
NATOPublications, 1984.5.
Cohen, A., Cousseau, P., Frederking, R., Grannes, D., Khanna,S., McNeiUy, C., Nirenburg, S., Shell, P., Waeltermann, D.Translator's WorkStation User Document, Center for MachineTranslation, Carnegie Mellon University, 1993.6.
Frederking, R., Grannes, D., Cousseau, P., and Nirenburg, S."An MAT Tool and Its Effectiveness."
In Proceedings of theDARPA Human Language Technology Workshop, Princeton,NJ, 1993.151
