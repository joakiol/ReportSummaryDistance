Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL),pages 169?172, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsSemantic Role Labelling withTree Conditional Random FieldsTrevor Cohn and Philip BlunsomUniversity of Melbourne, Australiatacohn@csse.unimelb.edu.au and pcbl@csse.unimelb.ed.auAbstractIn this paper we apply conditionalrandom fields (CRFs) to the semanticrole labelling task.
We define a randomfield over the structure of each sentence?ssyntactic parse tree.
For each nodeof the tree, the model must predict asemantic role label, which is interpretedas the labelling for the correspondingsyntactic constituent.
We show howmodelling the task as a tree labellingproblem allows for the use of efficientCRF inference algorithms, while alsoincreasing generalisation performancewhen compared to the equivalentmaximum entropy classifier.
We haveparticipated in the CoNLL-2005 sharedtask closed challenge with full syntacticinformation.1 IntroductionThe semantic role labelling task (SRL) involvesidentifying which groups of words act as argumentsto a given predicate.
These arguments mustbe labelled with their role with respect to thepredicate, indicating how the proposition should besemantically interpreted.We apply conditional random fields (CRFs) tothe task of SRL proposed by the CoNLL sharedtask 2005 (Carreras and Ma`rquez, 2005).
CRFs areundirected graphical models which define a condi-tional distribution over labellings given an obser-vation (Lafferty et al, 2001).
These models allowfor the use of very large sets of arbitrary, over-lapping and non-independent features.
CRFs havebeen applied with impressive empirical results to thetasks of named entity recognition (McCallum andLi, 2003; Cohn et al, 2005), part-of-speech (PoS)tagging (Lafferty et al, 2001), noun phrase chunk-ing (Sha and Pereira, 2003) and extraction of tabledata (Pinto et al, 2003), among other tasks.While CRFs have not been used to date for SRL,their close cousin, the maximum entropy model hasbeen, with strong generalisation performance (Xueand Palmer, 2004; Lim et al, 2004).
Most CRFimplementations have been specialised to work withchain structures, where the labels and observationsform a linear sequence.
Framing SRL as a lineartagging task is awkward, as there is no easy modelof adjacency between the candidate constituentphrases.Our approach simultaneously performs both con-stituent selection and labelling, by defining an undi-rected random field over the parse tree.
This allowsthe modelling of interactions between parent andchild constituents, and the prediction of an optimalargument labelling for all constituents in one pass.The parse tree forms an acyclic graph, meaning thatefficient exact inference in a CRF is possible usingbelief propagation.2 DataThe data used for this task was taken from thePropbank corpus, which supplements the PennTreebank with semantic role annotation.
Full detailsof the data set are provided in Carreras and Ma`rquez(2005).2.1 Data RepresentationFrom each training instance we derived a tree, usingthe parse structure from the Collins parser.
The169nodes in the trees were relabelled with a semanticrole label indicating how their corresponding syn-tactic constituent relates to each predicate, as shownin Figure 1.
The role labels are shown as subscriptsin the figure, and both the syntactic categories andthe words at the leaves are shown for clarity only?
these were not included in the tree.
Addition-ally, the dashed lines show those edges which werepruned, following Xue and Palmer (2004) ?
onlynodes which are siblings to a node on the path fromthe verb to the root are included in the tree.
Childnodes of included prepositional phrase nodes arealso included.
This reduces the size of the resultanttree whilst only very occasionally excluding nodeswhich should be labelled as an argument.The tree nodes were labelled such that only argu-ment constituents received the argument label whileall argument children were labelled as outside, O.Where there were parse errors, such that no con-stituent exactly covered the token span of an argu-ment, the smaller subsumed constituents were allgiven the argument label.We experimented with two alternative labellingstrategies: labelling a constituent?s children with anew ?inside?
label, and labelling the children withthe parent?s argument label.
In the figure, the IN andNP children of the PP would be affected by thesechanges, both receiving either the inside I label orAM-LOC label under the respective strategies.
Theinside strategy performed nearly identically to thestandard (outside) strategy, indicating that either themodel cannot reliably predict the inside argument,or that knowing that the children of a given node areinside an argument is not particularly useful in pre-dicting its label.
The second (duplication) strategyperformed extremely poorly.
While this allowed theinternal argument nodes to influence their ancestortowards a particular labelling, it also dramaticallyincreased the number of nodes given an argumentlabel.
This lead to spurious over-prediction of argu-ments.The model is used for decoding by predicting themaximum probability argument label assignment toeach of the unlabelled trees.
When these predic-tions were inconsistent, and one argument subsumedanother, the node closest to the root of the tree wasdeemed to take precedence over its descendants.3 ModelWe define a CRF over the labelling y given theobservation tree x as:p(y|x) =1Z(x)exp?c?C?k?kfk(c,yc,x)where C is the set of cliques in the observation tree,?k are the model?s parameters and fk(?)
is the fea-ture function which maps a clique labelling to a vec-tor of scalar values.
The function Z(?)
is the nor-malising function, which ensures that p is a validprobability distribution.
This can be restated as:p(y|x) =1Z(x)exp???
?v?C1?k?kgk(v,yv,x)+?u,v?C2?j?jhj(u, v,yu,yv,x)??
?where C1 are the vertices in the graph and C2 arethe maximal cliques in the graph, consisting of all(parent, child) pairs.
The feature function has beensplit into g and h, each dealing with one and twonode cliques respectively.Preliminary experimentation without anypair-wise features (h), was used to mimic asimple maximum entropy classifier.
This modelperformed considerably worse than the modelwith the pair-wise features, indicating that theadded complexity of modelling the parent-childinteractions provides for more accurate modellingof the data.The log-likelihood of the training sample wasoptimised using limited memory variable metric(LMVM), a gradient based technique.
This requiredthe repeated calculation of the log-likelihood andits derivative, which in turn required the use ofdynamic programming to calculate the marginalprobability of each possible labelling of every cliqueusing the sum-product algorithm (Pearl, 1988).4 FeaturesAs the conditional random field is conditioned onthe observation, it allows feature functions to bedefined over any part of the observation.
The treestructure requires that features incorporate either anode labelling or the labelling of a parent and its170SNP NP VPDT NN NN NNJJ NN V NP PPCD NNS NPDT NNPINThe luxury auto maker last year sold 1,214 cars in the USOA0A1 AM-LOCVAM-TMP OO OFigure 1: Syntax tree labelled for semantic roles with respect to the predicate sell.
The subscripts show therole labels, and the dotted and dashed edges are those which are pruned from the tree.child.
We have defined node and pairwise clique fea-tures using data local to the corresponding syntacticnode(s), as well as some features on the predicateitself.Each feature type has been made into binary fea-ture functions g and h by combining (feature type,value) pairs with a label, or label pair, where thiscombination was seen at least once in the trainingdata.
The following feature types were employed,most of which were inspired by previous works:Basic features: {Head word, head PoS, phrasesyntactic category, phrase path, position rel-ative to the predicate, surface distance to thepredicate, predicate lemma, predicate token,predicate voice, predicate sub-categorisation,syntactic frame}.
These features are commonto many SRL systems and are described in Xueand Palmer (2004).Context features {Head word of first NP in prepo-sition phrase, left and right sibling head wordsand syntactic categories, first and last wordin phrase yield and their PoS, parent syntacticcategory and head word}.
These features aredescribed in Pradhan et al (2005).Common ancestor of the verb The syntactic cate-gory of the deepest shared ancestor of both theverb and node.Feature conjunctions The following features wereconjoined: { predicate lemma + syntactic cate-gory, predicate lemma + relative position, syn-tactic category + first word of the phrase}.Default feature This feature is always on, whichallows the classifier to model the prior prob-ability distribution over the possible argumentlabels.Joint features These features were only definedover pair-wise cliques: {whether the parentand child head words do not match, parent syn-tactic category + and child syntactic category,parent relative position + child relative posi-tion, parent relative position + child relativeposition + predicate PoS + predicate lemma}.5 Experimental ResultsThe model was trained on the full training setafter removing unparsable sentences, yielding90,388 predicates and 1,971,985 binary features.
AGaussian prior was used to regularise the model,with variance ?2 = 1.
Training was performed ona 20 node PowerPC cluster, consuming a total of62Gb of RAM and taking approximately 15 hours.Decoding required only 3Gb of RAM and about 5minutes for the 3,228 predicates in the developmentset.
Results are shown in Table 1.171Precision Recall F?=1Development 73.51% 68.98% 71.17Test WSJ 75.81% 70.58% 73.10Test Brown 67.63% 60.08% 63.63Test WSJ+Brown 74.76% 69.17% 71.86Test WSJ Precision Recall F?=1Overall 75.81% 70.58% 73.10A0 82.21% 79.48% 80.82A1 74.56% 71.26% 72.87A2 63.93% 56.85% 60.18A3 63.95% 54.34% 58.75A4 68.69% 66.67% 67.66A5 0.00% 0.00% 0.00AM-ADV 54.73% 48.02% 51.16AM-CAU 75.61% 42.47% 54.39AM-DIR 54.17% 30.59% 39.10AM-DIS 77.74% 73.12% 75.36AM-EXT 65.00% 40.62% 50.00AM-LOC 60.67% 54.82% 57.60AM-MNR 54.66% 49.42% 51.91AM-MOD 98.34% 96.55% 97.44AM-NEG 99.10% 96.09% 97.57AM-PNC 49.47% 40.87% 44.76AM-PRD 0.00% 0.00% 0.00AM-REC 0.00% 0.00% 0.00AM-TMP 77.20% 68.54% 72.61R-A0 87.78% 86.61% 87.19R-A1 82.39% 75.00% 78.52R-A2 0.00% 0.00% 0.00R-A3 0.00% 0.00% 0.00R-A4 0.00% 0.00% 0.00R-AM-ADV 0.00% 0.00% 0.00R-AM-CAU 0.00% 0.00% 0.00R-AM-EXT 0.00% 0.00% 0.00R-AM-LOC 0.00% 0.00% 0.00R-AM-MNR 0.00% 0.00% 0.00R-AM-TMP 71.05% 51.92% 60.00V 98.73% 98.63% 98.68Table 1: Overall results (top) and detailed results onthe WSJ test (bottom).6 ConclusionConditional random fields proved useful in mod-elling the semantic structure of text when providedwith a parse tree.
Our novel use of a tree structurederived from the syntactic parse, allowed for parent-child interactions to be accurately modelled, whichprovided an improvement over a standard maximumentropy classifier.
In addition, the parse constituentstructure proved quite appropriate to the task, moreso than modelling the data as a sequence of words orchunks, as has been done in previous approaches.AcknowledgementsWe would both like to thank our research super-visor Steven Bird for his comments and feedbackon this work.
The research undertaken for thispaper was supported by an Australian PostgraduateAward scholarship, a Melbourne Research Scholar-ship and a Melbourne University Postgraduate Over-seas Research Experience Scholarship.ReferencesXavier Carreras and Llu?
?s Ma`rquez.
2005.
Introduction tothe CoNLL-2005 Shared Task: Semantic Role Labeling.
InProceedings of the CoNLL-2005.Trevor Cohn, Andrew Smith, and Miles Osborne.
2005.
Scal-ing conditional random fields using error correcting codes.In Proceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics.
To appear.John Lafferty, Andrew McCallum, and Fernando Pereira.
2001.Conditional random fields: Probabilistic models for seg-menting and labelling sequence data.
In Proceedings of the18th International Conference on Machine Learning, pages282?289.Joon-Ho Lim, Young-Sook Hwang, So-Young Park, and Hae-Chang Rim.
2004.
Semantic role labeling using maximumentropy model.
In Proceedings of the CoNLL-2004 SharedTask.Andrew McCallum and Wei Li.
2003.
Early results for namedentity recognition with conditional random fields, featureinduction and web-enhanced lexicons.
In Proceedings ofthe 7th Conference on Natural Language Learning, pages188?191.Judea Pearl.
1988.
Probabilistic Reasoning in Intelligent Sys-tems: Networks of Plausible Inference.
Morgan Kaufmann.David Pinto, Andrew McCallum, Xing Wei, and Bruce Croft.2003.
Table extraction using conditional random fields.In Proceedings of the Annual International ACM SIGIRConference on Research and Development in InformationRetrieval, pages 235?242.Sameer Pradhan, Kadri Hacioglu, Valerie Krugler, WayneWard, James Martin, and Daniel Jurafsky.
2005.
Sup-port vector learning for semantic argument classification.
InTo appear in Machine Learning journal, Special issue onSpeech and Natural Language Processing.Fei Sha and Fernando Pereira.
2003.
Shallow parsing with con-ditional random fields.
In Proceedings of the Human Lan-guage Technology Conference and North American Chap-ter of the Association for Computational Linguistics, pages213?220.Nianwen Xue and Martha Palmer.
2004.
Calibrating featuresfor semantic role labeling.
In Proceedings of EMNLP.172
