Proceedings of EACL '99Full Text Parsing using Cascades of Rules:an Information Extraction PerspectiveFab io  Ci ravegna and  A lber to  Lave l l iITC-irst Centro per la Ricerca Scientifica e Tecnologicavia Sommarive, 1838050 Povo (TN)ITALY{cirave\[lavelli} Qirst.itc.itAbst rac tThis paper proposes an approach to fullparsing suitable for Information Extrac-tion from texts.
Sequences of cascades ofrules deterministically analyze the text,building unambiguous structures.
Ini-tially basic chunks are analyzed; then ar-gumental relations are recognized; finallymodifier attachment is performed andthe global parse tree is built.
The ap-proach was proven to work for three lan-guages and different domains.
It was im-plemented in the IE module of FACILE,a EU project for multilingual text classi-fication and !E.1 I n t roduct ionMost successful approaches in IE (Appelt et al,1993; Grishman, 1995; Aone et al, 1998) make avery poor use of syntactic information.
They aregenerally based on shallow parsing for the anal-ysis of (non recursive) NPs and Verba~ Groups(VGs).
After such step regular patterns are ap-plied in order to trigger primitive actions that filltemplate(s); meta-rules are applied to patterns tocope with different syntactic lausal forms (e.g.,passive forms).
If we consider the most com-plex MUC-7 task (i.e., the Scenario Template task(MUC7, 1998)), the current echnology is not ableto provide results near an operational level (ex-pected F(1)=75%; the best system scored about50% (Aone et al, 1998)).
One of the limita-tions of the current technology is the inabilityto extract (and to represent) syntactic relationsamong elements in the sentence, i.e.
grammati-cal functions and thematic roles.
Scenario Tem-plate recognition eeds the correct treatment ofsyntactic relations at both sentence and text level(Aone et al, 1998).
Full parsing systems are gen-erally able to correctly model syntactic relations,but they tend to be slow (because of huge searchspaces) and brittle (because of gaps in the gram-mar).
The use of big grammars partially solves theproblem of gaps but worsens the problem of hugesearch spaces and makes grammar modificationsdifficult (Grishman, 1995).
Grammar modifica-tions are always to be taken into account.
Manydomain-specific texts present idiosyncratic phe-nomena that require non-standard ules.
Oftensuch phenomena are limited to some cases only(e.g., some types of coordinations are applied topeople only and not to organizations).
Insertinggeneric rules for such structures introduces (use-less) extra complexity into the search space and- when applied indiscriminately (e.g., on classesother than people) - can worsen the system re-sults.
It is not clear how semantic restrictions canbe introduced into (big) generic grammars.In this paper we propose an approach to fullparsing for IE based on cascades of rules.
Theapproach is inspired by the use of finite-state cas-cades for parsing (e.g., (Abney, 1996) uses themin a project for inducing lexical dependencies fromcorpora).
Our work is interesting in an IE per-spective because it proposes:?
a method for efficiently and effectively per-forming full parsing on texts;?
a way of organizing eneric grammars thatsimplifies changes, insertion of new rulesand especially integration of domain-orientedrules.The approach proposed in this paper for parsinghas been extended to the whole architecture ofanIE system.
Also lexical (lexical normalization andpreparsing), semantic (default reasoning and tem-plate filling) and discourse modules are based onthe same approach.
The system has been devel-oped as part of FACILE (Ciravegna et al, 1999),a successfully completed project funded by theEuropean Union.
FACILE deals with text clas-sification and information extraction from text in102Proceedings of EACL '99the financial domain.
The proposed approach asbeen tested mainly for Italian, but proved to workalso for English and, as of the time of this writing,partially for Russian.
Applications and demon-strators have been built in four different domains.In this paper we first introduce the adopted for-malism and then go into details on grammar orga-nization and on the different steps through whichparsing is accomplished.
Finally we present someexperimental results.2 Representation and RulesEvery lexical element a in the input sentence wis abstractly represented by means of elementaryobjects, called tokens.
A token T is associatedwith three structures:?
\[T\]dep is a dependency tree for a, i.e.
a treerepresenting syntactic dependencies betweena and other lexical elements (its dependees)in w.?
\[T\]leat is a feature structure representing syn-tactic and semantic information needed tocombine a with other elements in the input.?
\[T\]zy is a Quasi Logical Form (QLF) providinga semantic interpretation for the combinationof a with its dependees.Rules operate on tokens, therefore they can accessall the three structures above.
Rules incremen-tally build and update the above structures.
Lex-ical, syntactic and semantic onstraints can thenbe used in rules at any level.
The whole IE ap-proach can be based on the same formalism andrule types, as both lexical, syntactic and semanticinformation can be processed uniformly.The general form of a ru le  is a triple(Ta~, FT, FA>,where?
7c~d is a non-empty string of tokens, calledthe rule pat tern ;  cr is called the rule coreand is non-empty, 7, fi are called the rule con-text  and may be empty;?
FT is a set of boolean predicates, called ruletest,  defined over tokens in the rule pattern;?
FA is a set of elementary operations, calledrule act ion,  defined over tokens in the solerule core.The postfix, unary operators "," (Kleene star)and "?"
(optionality operator) can be used in therule patterns.A basic data structure, called token  chart ,  isprocessed and dynamically maintained.
This isa directed graph whose vertices are tokens andwhose arcs represent binary relations from some(finite) basic set.
Initially, the token chart is achain-like graph with tokens ordered as the corre-sponding lexical elements in w, i.e.
arcs initiallyrepresent lexical adjacency between tokens.
Dur-ing the processing, arcs might be rewritten so thatthe token chart becomes a more general kind ofgraph.For a rule to apply, a path cr must be foundin the token chart that, when viewed as a stringof tokens, satisfies the two following conditions:(i) ~ is matched by 7a~; and (ii) all the booleanpredicates in FT hold when evaluated on c~.When a rule applies, the elementary operationsin FA are executed on the tokens of ?
matchingthe core of the rule.
The effect of action executionis that \[T\]dep, IT\]lear and \[Tit/are updated for theappropriate matching tokens.Rules are grouped into cascades that are fi-nite, ordered sequences of rules.
Cascades rep-resent elementary logical units, in the sense thatall rules in a cascade deal with some specific con-struction (e.g., subcategorization f verbs).
Froma functional point of view, a cascade is composedof three segments:?
s l  contains rules that deal with idiosyncraticcases for the construction at hand;?
s2 contains rules dealing with the regularcases;?
s3 contains default rules that fire only whenno other rule can be successfully applied.3 ParsingThe parsing model is strongly influenced by IEneeds.
Its aim is to build the sufficient IE ap-proximation (SIEA) of the correct parse tree foreach sentence, i.e.
a complete parse tree whereall the relations relevant for template filling arerepresented, while other relations are left implicit.The parser assumes that there is one and only onepossible correct parse tree for each sentence andtherefore also only one SIEA.Parsing is based on the application of a fixedsequence of cascades of rules.
It is performed inthree steps using different grammars:* chunking (analysis of NPs, VGs and PPs);.
subcategorization frame analysis (for verbs,nominalizations, etc.);?
modifier attachment.103Proceedings of EACL '99\[ACME\] npA CME\[iniziare\] vgstart\[in raodo da\]comptso to\[ha deciso\]vg,has decided,\[1' emis s lone\] npthe issue\[divers if icare\] vgdiversify\[informa\] vgtells\[di obbligazioni\] ppof bonds\[il proprio impegno\]npits obligation\[una nora\] np, \[di\]  eompta press release, to\[per 12 milioni di Euro\]ppfor 1~ million (o\]) Euro\[nel mercato\]pp.in the market.Figure 1: The Italian sentence used as an example.The first two steps are syntax driven and based ongeneric grammars.
Most rules in such grammarsare general syntactic rules, even if they stronglyrely on the semantic information provided by aforeground lexicon (see also Section 3.2).
Dur-ing modifier attachment, mainly semantic pat-terns are used.
At the end of these three stepsthe SIEA is available.We use deterministic dependency parsing 1 op-erating on a specific linear path within the to-ken chart (the parsing path); at the beginning theparsing path is equal to the initial token chart.When a rule is successfully applied, the parsingpath is modified so that only the head token isvisible for the application of the following rules;this means that the other involved elements areno longer available to the parser.3.1 ChunkingChunking is accomplished in a standard way.In Figure I an example of chunk recognition isshown.
23.2 A-structure AnalysisA-structure analysis is concerned with therecognition of argumental dependencies betweenchunks.
All kinds of modifier dependencies (e.g.,PP  attachment) are disregarded during this step.More precisely: let w be the input sentence.A dependency  tree for w is a tree represent-ing all predicate-argument and predicate-modifiersyntactic relations between the lexical elements inw.
The A-structure for w is a tree forest ob-tained from the dependency tree by unattachingall nodes that represent modifiers.
A-structuresare associated with the token that represents thesemantic head of w (Tsent in the following).
A-structure analysis associates to Ts~nt:?
\[Tsent\]dep: the A-structure spanning thewhole sentence;t Even if we use dependency parsing, in this paperwe will make reference to constituency based struc-tures (e.g., PPs) because most readers are more ac-quainted with them than with dependency structures.2In this paper we use literal English translations ofItalian examples.
* \[Ts~.t\]f~,t: i s feature structure;?
\[Tsent\]tf: its QLF.A-structure analysis is performed without recur-sion by the successive application of three se-quences of rule cascades: 3.
The first sequence of cascades performs anal-ysis of basic (i.e., non-recursive) sentences.It does so using the subcategorization framesof available chunks.
Three cascades of rulesare involved: one for the subcategorizationframes of NP and PPs, one for those of VGs,and one for combining complementizers withtheir clausal arguments.?
The second sequence of cascades performsanalysis of dependencies between basic sen-tences.
This sequence processes all sententialarguments and all incidentals by employingonly two cascades of rules, without any needfor recursion.
This sequence is applied twice,i.e.
it recognizes structures with a maximumof two nested sentences.
* The third sequence of cascades performs re-covery analysis.
During this step all tree frag-ments not yet connected together are merged.Tokens not recognized as arguments at the end ofA-structure analysis are marked as modifiers andleft unattached in the resulting A-structure.
Theywill be attached in the parse tree during modifierattachment (see Section 3.3).We adopt a highly lexicalized approach.
Ina pure IE perspective the information for A-structure analysis is provided by a foreground lex-icon (Kilgarriff, 1997).
Foreground lexica pro-vide detailed information about words relevantfor the domain (e.g., subcategorization frame, re-lation with the ontology); for words outside theforeground lexicon a large background lexicon pro-vides generic information.
The term subcatego-rization frame is used here in restricted sense: i t3The order of the cascades in the sequences de-pends on the intrasentential structure of the specificlanguage coped with.104Proceedings of EACL '99PATTERN TEST ACTION Matched InputT1T2*T3\[T1\]yeat.cat=NP\[T2\]/eat.cat=ld j unct\[T3\]yeat.cat=PP\[T3\]\]eat=\[T1\]\]e~t.subcat.int-argDepend ant (IT1\] aep, \[T3\] aep)\[T1\]yeat.subcat.int-arg=\[T3\]yeat\[T1\]t/.patient =\[7"3\]ty.head"the issue""of  bonds"Figure 2: The rule that recognizes \[the i ssue of bonds\]np.generally includes ubject, object and - possibly -one indirect complement.
The information in theforeground lexicon allows to classify known tokensas arguments of other known tokens with high re-liability.
Let's go back to our example.
The firstsequence of cascades recognizes:* \[the issue of bonds\]np: the rule in Figure2 recognizes \[of bonds\]pp as internal argu-ment of \ [the issue\]np; the rule uses the in-formation associated with issue in the fore-ground lexicon, i.e.
that it is the nominal-ization of "to issue".
The subcategorizationframe of such verb specifies its argumentsand their semantic restrictions.
The syntacticrule adds the condition that - being a nomi-nalization - the internal argument is realizedas a PP marked by of;- \[ACME has decided\]ip: \[ACME\]np is the ex-ternal argument of \[has decided\]vg;?
\[tells a press release\]ip: \[a pressrelease\]np is the external argument of\[tells\]vg;?
\[start the issue of bonds for 12million Euro\]ip: \[issue\]np is the internalargument of \[start\]v9; \[for 12 millionEuro\]pp is a modifier (as it is not subcatego-rized by other tokens) and is unattached inthe A-structure;- \[diversify its obligation in themarket\]ip: \[its obligation\]np is theinternal argument of \[diversify\]v9; \[inthe market\]pp is a modifier;?
\[to start the issue of bonds for 12mi l l ion Euro\]ep: \[tO\]compl gets its argu-ment \[start ...lip;?
\[so to divers i fy its obl igat ion inthe market\]cp: \[so tO\]compl gets itsargument \[diversify .
.
.
\]ip.The result after the application of the first se-quence is:\[ACME has decided\]ip\[tells a press release\]ip\[to start the issue of bonds for 12million Euro\] cp\[so to diversify its obligation in themarket\] cpThe second sequence recognizes that \[ACME hasdecided\]@ still needs a sentential argument, i.e.a subordinate clause introduced by to  (such infor-mation comes from the foreground lexicon).
Suchargument is found after the incidental \ [ te l l sa press re lease \ ] :  it is the CY headed by \[tos tar t \ ] .
The result of the second phase is:\[ACME has decided, tel ls a press release,to start the issue of bonds for 12million Euro\] sentence\[so to diversify its obligation in themarket\] epFinally, the recovery sequence collapses the twoconstituents above into a single sentence struc-ture; the CP is considered a clausal modifier (asit was not subcategorized by anything) and is leftunattached in the A-structure.At the end of the A-structure recognition Tsentis the token associated with \[has decided'\].\[Tsent\]dep is integrated with the search space foreach unattached modifier (see Section 3.3).The way A-structures are produced is interest-ing for a number of reasons.First of all generic grammars are used to copewith generic linguistic phenomena t sentencelevel.
Secondly we represent syntactic relationsin the sentence (i.e., grammatical functions andthematic roles); such relations allow a bettertreatment of linguistic phenomena than possi-ble in shallow approaches (Aone et ah, 1998;105Proceedings of EACL '99Kameyama, 1997).The initial generic grammar is designed to coverthe most frequent phenomena in a restrictivesense.
Additional rules can be added to the gram-mar (when necessary) for coping with the un-covered phenomena, especially domain-specific id-iosyncratic forms.
The limited size of the gram-mar makes modifications simple (the A-structuregrammar for Italian contains 66 rules).The deterministic approach combined with theuse of sequences, cascades and segments makesgrammar modifications simple, as changes in acascade (e.g., rule addition/modification) i flu-ence only the following part of the cascade or thefollowing cascades.
This makes the writing anddebugging of grammars easier than in recursiveapproaches (e.g., context-free grammars), wherechanges to a rule can influence the application ofany rule in the grammar.The grammar organization i cascades and seg-ments allows a clean definition of the grammarparts.
Each cascade copes with a specific phe-nomenon (modularity of the grammar).
All therules for the specific phenomenon are grouped to-gether and are easy to check.The segment/cascade structure is suitable forcoping with the idiosyncratic phenomena of re-stricted corpora.
As a matter of fact domain-oriented corpora can differ from the standard useof language (such as those found in generic cor-pora) in two ways:?
in the frequency of the constructions for aspecific phenomenon;?
in presenting different (idiosyncratic) con-structions.Coping with different frequency distributions isconceptually easy by using deterministic parsingand cascades of rules, as it is just necessary tochange the rule order within the cascade copingwith the specific phenomenon, so that more fre-quently applied rules are first in the cascade.
Cop-ing with idiosyncratic constructions requires theaddition of new rules.
Adding new rules in highlymodularized small grammars i not complex.Finally from the point of view of grammar or-ganization, defining segments is more than justhaving ordered cascades.
Generic rules ~in s2) areseparated from domain specific ones (in sl); rulescovering standard situations (in s2) are separatedfrom recovery rules (in s3).
In s2, rules are genericand deal with unmarked cases.
In principle s2and s3 are units portable across the applicationswithout changes.
Domain-dependent rules aregrouped together in sl and are the resources theapplication developer works on for adapting thegrammar to the specific corpus needs (e.g., cop-ing with idiosyncratic cases).
Such rules generallyuse contexts and/or introduce domain-dependent(semantic) constraints in order to limit their ap-plication to well defined cases.
S1 rules are ap-plied before the standard rules and then idiosyn-cratic constructions have precedence with respectto standard forms.Segments also help in parsing robustly.
$3 dealswith unexpected situations, i.e.
cases that couldprevent he parser from continuing.
For examplethe presence of unknown words is coped with afterchunking by a cascade trying to guess the word'slexical class.
If every strategy fails, a recoveryrule includes the unknown word in the immedi-ately preceding chunk so to let the parser con-tinue.
Recovery rules are applied only when rulesin sl and s2 do not fire.3.3 Modi f ier  a t tachmentThe aim of modifier attachment is to find the cor-rect position for attaching relevant modifiers inthe parse tree and to add the proper semanticrelations between each modifier and its modifieein \[Tsent\]ty.
\[Tsent\]dep and \[Tsent\]t$ are used todetermine the correct attachments and are alsomodified during this step.
Modifier attachmentis performed in two steps: first all the possibleattachments are computed for each modifier (itssearch space, SP).
Here mainly generic syntac-tic rules are used.
Then the correct attachment inthe search space is determined for each modifier,applying domain-specific rules.
The rules alwaysmodify both \[Tsent\]dep and \[Tsent\]ty.
Only modi-fiers relevant for the IE task are attached in theproper position.
Other modifiers are attached ina default position in \[T~ent\] d~p.Initially modifiers are attached in the lowest po-sition in \[Tsent\]dep.
No semantic relation is hy-pothesized between each modifier and the rest ofthe sentence in \[Ts~nt\]t/.
Given:?
T~: a modifier token derived from chunk n,?
Tn-l: the token, derived from chunk n - 1,immediately preceding n in the sentence,in right branching languages (such as Italian) thelowest possible attachment for T,~ is in the positionof modifier of Tn-x.Afterwards, the possible SP for each modifier iscomputed.
The SP for a modifier Tn is a path inthe token chart connecting T,~ with other elementsin \[Zsent\]dep that - from a syntactic point of view- can be modified by Tn.
The initial SP for Tnis given by the path in \[T~nt\]d~p connecting Ta-1106Proceedings of EACL '99PATTERNTIT2*T3T4*T5TEST\[T1\] t/.head=TO-INCREASE\[T2\]/eat.cat =Adjunct\[T3\]i/.head=PROFIT\[T3\]/oor.cat=VV\[Ta\]/~,~t.marked=' ' o f "\[T4\]Ieat.Cat :Ad junct\[Tb\] I/.head:PERCENTAGE\[Tb\]/eat.cat=PP\[Ts\]feat.marked: " of /by ' 'ACTIONDependant (\[T1\] dev, \[Tb\] dev)\[ T1\] l\] .increased-by=\[Ta\]t/.headMatched Input"an  increase""o f  prof i ts""o f /by  20%"Figure 3: An example of modifier attachment rule.with Tsent.
Then rules are applied to filter outelements in SPs according to syntactic onstraints(e.g., NPs or PPs can be modified by a relativeclause, but VGs can not).After SPs have been computed, modifiers areattached using a sequence of cascades of rules.A first cascade, mainly composed by genericsyntactic rules, attaches ubordinates (e.g., rela-tive clauses).
Many of these rules are somehowsimilar to A-structure recognition rules.
They aretruly syntactic rules recognizing part of the sub-categorization frame of subordinated verbs, usingsemantic information provided by the foregroundlexicon.
Note however that they are applied ontoSPs not on the parsing path (as A-structure rulesare).Other cascades are used to attach differenttypes of modifiers, such as PPs.
Such rulesmainly involve semantic onstraints.
For exam-ple, the rule shown in F igure 3 can recognizeuna crescita dei profitti del 20Y, (lit.
anincrease of profits of/by 20%).44Generally rules involve two elements (i.e.
themodifier and the modifiee), taking into account in-tervening elements (such as other adjuncts) that donot have further associated conditions.
The exampleabove, instead, is more complex as it introduces con-straints also on one of the intervening adjuncts (i.e., onT3).
Such domain-oriented rule solves a recurring am-biguity in the domain of company financial results.
Asa matter of fact of/by 20% could modify both nounsfrom a syntactic and semantic point of view.
The ruleRules for modifier attachment are easy to write.The SP allows to reduce complex cases to simpleones.
For exampl ethe rule in Figure 3 also appliesto:?
an increase in 1997 of profits of/by20Z?
an increase, news report, of profitsof/by 20Z?
an increase, considering theinflation rate, of profits (bothgross and net) of/by 20~Patterns are usually developed having in mindthe simplest case, i.e.
a sequence of contiguouschunks in the sentence (such as in \[an increase\ ]\[of p ro f i t s \ ]  \ [o f /by  20%\]) that can be inter-leaved by other non relevant chunks.Conceptually this step is very similar to thatused by shallow parsing approaches uch as in(Grishman, 1997).
Note however that rules arenot applied on a list of contiguous chunks, buton the search space (where the parse tree and re-lated syntactic relations are available).
Parse-treebased modifier attachment is less error prone thanattachment performed on fiat chunk structures (asused in shallow parsing).
For example it is possi-ble to avoid cases of attachments violating syntac-tic constraints, as it would be the case in attachingallows to solve the ambiguity attaching of /by 20% toincrease.107Proceedings of EACL '99NP~ p p  "..,,,an increase, considering the inflation rate, of profits (both gross and net) of/by 20%Figure 4: Violation of syntactic onstraints(in the third example above) profit to i nc reaseand 20% to in f la t ion  ra te  (see Figure 4).At the end of modifier attachment the finalparse tree is available in \[T~ent\] aep, together with\[Tse,~t\]feat and \[Tsent\]g. The syntactic informa-tion in \[Tse,,t\]aep and \[Tsent\].feat is useful in thesteps following parsing because, for example, theavailability of syntactic relations increases the ac-curacy in determining discourse relations.
As amatter of fact at discourse level it is possible toadopt strategies to compute salience for corefer-ence resolution that take into account both thesyntactic relations among constituents and the ar-gumental structure of the sentence.
Shallower ap-proaches do not produce anything similar either to\[Tse,~t\]aep or to \[Tse,~t\]yeat.
They generally adoptheuristics uch as linear ordering and recency ofbasic chunks: such heuristics have been shown notas effective as those based on full syntactic rela-tions, even if for some languages they represent anacceptable approximation (Kameyama, 1997).The obtained final parse tree is very close tothe SIEA mentioned at the beginning of Section3.
In this tree all the A-structures are correctlybuilt and all the modifiers are attached.
Modi-fiers relevant for the IE application are attachedin the correct position in the tree and a valid se-mantic relation is established with the modifieein \[Tsent\]g. Irrelevant modifiers are attached ina default position in the tree (the lowest possi-ble attachment) and a null semantic relation isestablished with the modif iee.
The only differ-ence between the produced tree and the SIEAis in the A-structure, where all the relations arecaptured (and not only those relevant for the do-main).
Modeling also the argumental structuresof irrelevant constituents can be useful in order tocorrectly assign salience at discourse level.
For ex-ample when interesting relations involve elementsthat are dependees of irrelevant verbs.4 Remarks and ConclusionsThe approach to parsing proposed in this paperwas implemented in the IE module of FACILE(Ciravegna et al, 1999), a EU project for multi-lingual text classification and IE.
It was tested onfour domains and in three languages.
In particularfor Italian one application (about bond issues) hasbeen fully developed and two others have reachedthe level of demonstration (management succes-sion and company financial results).
For Englisha demonstrator for the field of economic indica-tors was developed.
A Russian demonstrator forbond issues was developed till the level of modi-fier attachment.
The approach to rule writing andorganization adopted for parsing '(i.e., the type ofrules, cascades, egments, and available primitivesand rule interpreter) was extended to the wholearchitecture of the IE module.
Also lexical (lexi-cal normalization and preparsing), semantic (de-fault reasoning and template filling) and discourselevels are organized in the same way.Provided that the approach to parsing proposedin this paper is strongly influenced by IE needs,it is difficult to evaluate it by means of the stan-dard tools used in the parsing community.
Ap-proximate indications can be provided by the ef-fectiveness in recognizing A-structures and by themeasures on the overall IE tasks.Effectiveness in recognizing A-structures wasexperimentally verified for Italian on a corpus of95 texts in the domain of bond issue: 33 textswere used for training, 62 for test.
Results were:P=97, R=83 on the training corpus, P=95, R=71on the test corpus.
In our opinion the high preci-sion demonstrates the applicability of the method.The lower recall shows difficulties of building com-plete foreground lexica, a well known fact in IE.Concerning the effectiveness of the IE process,in the Italian application on bond issues the sys-tem reached P=80, R--72, F(1)=76 on the 95108Proceedings of EACL '99texts used for development (33 ANSA agencynews, 20 "II Sole 24 ore" newspaper articles, 42Radiocor agency news; 10,472 words in all).
Ta-ble 4 shows the kind of template used for this ap-plication.
Effectiveness was automatically calcu-lated by comparing the system results against auser-defined tagged corpus via the MUC scorer(Douthat, 1998).
The development cycle of thetemplate application was organised as follows: re-sources (grammars, lexicon and knowledge base)were developed by carefully inspecting the first 33texts of the corpus.
Then the system was com-pared against he whole corpus (95 texts) withthe following results: Recall=51, Precision=74,F(1)=60.
Note that the corpus used for train-ing was composed only by ANSA news, while thetest corpus included 20 "I1 Sole 24 ore" newspa-per articles and 42 Radiocor agency news (i.e.,texts quite different from ANSA's in both termi-nology and length).
Finally resources were tunedon the whole corpus mainly by focusing on thetexts that did not reach sufficient results in termsof R&P.
The system analyzed 1,125 word/minuteon a Sparc Ultra 5, 128M RAM (whole IE pro-cess).issuerkind of bondamountcurrencyannouncement dateplacement dateinterest datematurityaverage durationglobal ratefirst ratea template lementa labela monetary amounta string from the texta temporal expressiona temporal expressiona temporal expressiona temporal expressiona temporal expressiona string from the texta string from the textTable 1: The template to be filled for bond issues.AcknowledgmentsGiorgio Satta has contributed to the whole workon parsing for IE via cascades of rules.
The au-thors would like to thank him for the constant helpand the fruitful discussions in the last two years.He also provided useful comments to this pa-per.
The FACILE project (LE 2440) was partiallyfunded by the European Union in the frameworkof the Language Engineering Sector.
The En-glish demonstrator was developed by Bill Black,Fabio Rinaldi and David Mowatt (Umist, Manch-ester) as part of the FACILE project.
The Russiandemonstrator was developed by Nikolai Grigoriev(Russian Academy of Sciences, Moscow).Re ferencesSteven Abney.
1996.
Partial parsing via finite-state cascades.
In Proceedings of the ESSLI '96Robust Parsing Workshop.Chinatsu Aone, Lauren Halverson, Tom Hamp-ton, and Mila Ramos-Santacruz.
1998.SRA: description of the IE 2 system usedfor MUC-7.
In Proceedings of the SeventhMessage Understanding Conference (MUC-7),http://www.muc.saic.com/.Douglas E. Appelt, Jerry R. Hobbs, John Bear,David Israel, and Mabry Tyson.
1993.
FAS-TUS: A finite-state processor for informationextraction from real-world text.
In Proceed-ings of the Thirteenth International Joint Con-ference on Artificial Intelligence, Chambery,France.Fabio Ciravegna, Alberto Lavelli, Nadia Mann,Luca Gilardoni, Silvia Mazza, Massimo Ferraro,Johannes Matiasek, William J.
Black, Fabio Ri-natdi, and David Mowatt.
1999.
FACILE: Clas-sifying texts integrating pattern matching andinformation extraction.
In Proceedings of theSixteenth International Joint Conference on Ar-tificial Intelligence, Stockholm, Sweden.Aaron Douthat.
1998.
The message un-derstanding conference scoring software user'smanual.
In Proceedings of the SeventhMessage Understanding Conference (MUC- 7},http://www.muc.saic.com/.Ralph Grishman.
1995.
The NYU system forMUC-6 or where's syntax?
In Sixth mes-sage understanding conference MUC-6.
MorganKaufmann Publishers.Ralph Grishman.
1997.
Information extraction:Techniques and challenges.
In M. T. Pazienza,editor, Information Extraction: a multidisci-plinary approach to an emerging technology.Springer Verlag.Megumi Kameyama.
1997.
Recognizing referen-tial links: An information extraction perspec-tive.
In Mitkov and Boguraev, editors, Proceed-ings of ACL/EACL Workshop on OperationalFactors in Practical, Robust Anaphora Resolu-tion for Unrestricted Texts, Madrid, Spain.Adam Kilgarriff.
1997.
Foreground and back-ground lexicons and word sense disambiguationfor information extraction.
In InternationalWorkshop on Lexically Driven Information Ex-traction, Frascati, Italy.MUC7.
1998.
Proceedings of the Seventh MessageUnderstanding Conference (MUC-7}.
SAIC,http://www.muc.saic.com/.109
