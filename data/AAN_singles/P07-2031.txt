Proceedings of the ACL 2007 Demo and Poster Sessions, pages 121?124,Prague, June 2007. c?2007 Association for Computational LinguisticsPredicting Evidence of Understanding by Monitoring User?s TaskManipulation in Multimodal ConversationsYukiko I. Nakano?Yoshiko Arimoto??
?Tokyo University of Agri-culture and Technology2-24-16 Nakacho, Koganei-shi, Tokyo 184-8588, Japan{nakano, kmurata, meno-moto}@cc.tuat.ac.jpKazuyoshi Murata?Yasuhiro Asa????
?Tokyo University ofTechnology1404-1 Katakura, Hachioji,Tokyo 192-0981, Japanar@mf.teu.ac.jpMika Enomoto?Hirohiko Sagawa?????
?Central Research Laboratory,Hitachi, Ltd.1-280, Higashi-koigakubo Kokub-unji-shi, Tokyo 185-8601, Japan{yasuhiro.asa.mk, hiro-hiko.sagawa.cu}@hitachi.comAbstractThe aim of this paper is to develop ani-mated agents that can control multimodalinstruction dialogues by monitoring user?sbehaviors.
First, this paper reports on ourWizard-of-Oz experiments, and then, usingthe collected corpus, proposes a probabilis-tic model of fine-grained timing dependen-cies among multimodal communicationbehaviors: speech, gestures, and mousemanipulations.
A preliminary evaluationrevealed that our model can predict a in-structor?s grounding judgment and a lis-tener?s successful mouse manipulationquite accurately, suggesting that the modelis useful in estimating the user?s under-standing, and can be applied to determiningthe agent?s next action.1 IntroductionIn face-to-face conversation, speakers adjust theirutterances in progress according to the listener?sfeedback expressed in multimodal manners, suchas speech, facial expression, and eye-gaze.
In task-manipulation situations where the listener manipu-lates objects by following the speaker?s instruc-tions, correct task manipulation by the listenerserves as more direct evidence of understanding(Brennan 2000, Clark and Krych 2004), and affectsthe speaker?s dialogue control strategies.Figure 1 shows an example of a software in-struction dialogue in a video-mediated situation(originally in Japanese).
While the learner saysnothing, the instructor gives the instruction insmall pieces, simultaneously modifying her ges-tures and utterances according to the learner?smouse movements.To accomplish such interaction between humanusers and animated help agents, and to assist theuser through natural conversational interaction, thispaper proposes a probabilistic model that computestiming dependencies among different types of be-haviors in different modalities: speech, gestures,and mouse events.
The model predicts (a) whetherthe instructor?s current utterance will be success-fully understood by the learner and grounded(Clark and Schaefer 1989), and (b) whether thelearner will successfully manipulate the object inthe near future.
These predictions can be used asconstraints in determining agent actions.
For ex-ample, if the current utterance will not be grounded,then the help agent must add more information.In the following sections, first, we collect hu-man-agent conversations by employing a Wizard-of-Oz method, and annotate verbal and nonverbalbehaviors.
The annotated corpus is used to build aBayesian network model for the multimodal in-struction dialogues.
Finally, we will evaluate how?That?
(204ms pause)Pointing gesture <preparation><stroke>Mouse moveInstructor:Learner:?at the most?
(395ms pause)?left-hand side?Instructor:Learner:Instructor:Mouse moveFigure 1: Example of task manipulation dialogue121accurately the model can predict the events in (a)and (b) mentioned above.2 Related workIn their psychological study, Clark and Krych(2004) showed that speakers alter their utterancesmidcourse while monitoring not only the listener?svocal signals, but also the listener?s gestural sig-nals as well as through other mutually visibleevents.
Such a bilateral process functions as a jointactivity to ground the presented information, andtask manipulation as a mutually visible event con-tributes to the grounding process (Brennan 2000,Whittaker 2003).
Dillenbourg, Traum, et al (1996)also discussed cross-modality in grounding: ver-bally presented information is grounded by an ac-tion in the task environment.Studies on interface agents have presented com-putational models of multimodal interaction(Cassell, Bickmore, et al 2000).
Paek and Horvitz(1999) focused on uncertainty in speech-based in-teraction, and employed a Bayesian network tounderstand the user?s speech input.
For user moni-toring, Nakano, Reinstein, et al (2003) used a headtracker to build a conversational agent which canmonitor the user?s eye-gaze and head nods as non-verbal signals in grounding.These previous studies provide psychologicalevidence about the speaker?s monitoring behaviorsas well as conversation modeling techniques incomputational linguistics.
However, little has beenstudied about how systems (agents) should monitorthe user?s task manipulation, which gives directevidence of understanding to estimate the user?sunderstanding, and exploits the predicted evidenceas constraints in selecting the agent?s next action.Based on these previous attempts, this study pro-poses a multimodal interaction model by focusingon task manipulation, and predicts conversationstates using probabilistic reasoning.3 Data collectionA data collection experiment was conducted usinga Wizard-of-Oz agent assisting a user in learning aPCTV application, a system for watching and re-cording TV programs on a PC.The output of the PC operated by the user wasdisplayed on a 23-inch monitor in front of the user,and also projected on a 120-inch big screen, infront of which a human instructor was standing(Figure 2 (a)).
Therefore, the participants sharedvisual events output from the PC (Figure 2 (b))while sitting in different rooms.
In addition, a rab-bit-like animated agent was controlled through theinstructor?s motion data captured by motion sen-sors.
The instructor?s voice was changed through avoice transformation system to make it sound likea rabbit agent.4 CorpusWe collected 20 conversations from 10 pairs, andannotated 11 conversations of 6 pairs using theAnvil video annotating tool (Kipp 2004).Agent?s verbal behaviors: The agent?s (actually,instructor?s) speech data was split by pauses longerthan 200ms.
For each inter pausal unit (IPU), utter-ance content type defined as follows was assigned.?
Identification (id): identification of a targetobject for the next operation?
Operation (op): request to execute a mouseclick or a similar primitive action on the target?
Identification + operation (idop): referring toidentification and operation in one IPUIn addition to these main categories, we alsoused:  State (referring to a state before/after an op-eration), Function (explaining a function of thesystem), Goal (referring to a task goal to be ac-complished), and Acknowledgment.
The inter-coder agreement for this coding scheme is veryhigh K=0.89 (Cohen?s Kappa), suggesting that theassigned tags are reliable.Agent?s nonverbal behaviors: As the most salientinstructor?s nonverbal behaviors in the collecteddata, we annotated agent pointing gestures:?
Agent movement: agent?s position  movement?
Agent touching target (att): agent?s touchingthe target object as a stroke of a pointing ges-ture(a) Instructor                          (b) PC outputFigure 2: Wizard-of-Oz agent controlled by instructor122User?s nonverbal behaviors: We annotated threetypes of mouse manipulation for the user?s taskmanipulation as follows:?
Mouse movement: movement of the mousecursor?
Mouse-on-target: the mouse cursor is on thetarget object?
Click target: click on the target object4.1 Example of collected dataAn example of an annotated corpus is shown inFigure 3.
The upper two tracks illustrate theagent?s verbal and nonverbal behaviors, and theother two illustrate the user?s behaviors.
The agentwas pointing at the target (att) and giving a se-quence of identification descriptions [a1-3].
Sincethe user?s mouse did not move at all, the agentadded another identification IPU [a4] accompaniedby another pointing gesture.
Immediately after that,the user?s mouse cursor started moving towards thetarget object.
After finishing the next IPU, theagent finally requested the user to click the objectin [a6].
Note that the collected Wizard-of-Oz con-versations are very similar to the human-humaninstruction dialogues shown in Figure 1.
Whilecarefully monitoring the user?s mouse actions, theWizard-of-Oz agent provided information in smallpieces.
If it was uncertain that the user was follow-ing the instruction, the agent added more explana-tion without continuing.5 Probabilistic model of user-agent mul-timodal interaction5.1 Building a Bayesian network modelTo consider multiple factors for verbal and non-verbal behaviors in probabilistic reasoning, weemployed a Bayesian network technique, whichcan infer the likelihood of the occurrence of a tar-get event based on the dependencies among multi-ple kinds of evidence.
We extracted the conversa-tional data from the beginning of an instructor'sidentification utterance for a new target object tothe point that the user clicks on the object.
EachIPU was split at 500ms intervals, and 1395 inter-vals were obtained.
As shown in Figure 4, the net-work consists of 9 properties concerning verbaland nonverbal behaviors for past, current, and fu-ture interval(s).5.2 Predicting evidence of understandingAs a preliminary evaluation, we tested how ac-curately our Bayesian network model can predictan instructor?s grounding judgment, and the user?smouse click.
The following five kinds of evidencewere given to the network to predict future states.As evidence for the previous three intervals (1.5sec), we used (1) the percentage of time the agenttouched the target (att), (2) the number of theuser?s mouse movements.
Evidence for the currentinterval is (3) current IPU?s content type, (4)whether the end of the current interval will be theend of the IPU (i.e.
whether a pause will followafter the current interval), and (5) whether themouse is on the target object.Well,Yes Viewthe TV right ofYesBeside the DVD There is a buttonstarts with ?V?Ah, yes Er, yesPress itThisUserAgentSpeechGestureMouser actionsid id id id id+opMouse moveclickatt att attMouse ontarget[a2] [a3] [a4] [a5] [a6][a1]ack ack ack ackSpeechOffOnFigure 3: Example dialogue between Wizard-of-Oz agent and userFigure 4: Bayesian network model123(a) Predicting grounding judgment: We testedhow accurately the model can predict whether theinstructor will go on to the next leg of the instruc-tion or will give additional explanations using thesame utterance content type (the current messagewill not be grounded).The results of 5-fold cross-validation are shownin Table 1.
Since 83% of the data are ?same con-tent?
cases, prediction for ?same content?
is veryaccurate (F-measure is 0.90).
However, it is notvery easy to find ?content change?
case because ofits less frequency (F-measure is 0.68).
It would bebetter to test the model using more balanced data.
(b) Predicting user?s mouse click: As a measureof the smoothness of task manipulation, the net-work predicted whether the user?s mouse clickwould be successfully performed within the next 5intervals (2.5sec).
If a mouse click is predicted, theagent should just wait without annoying the userby unnecessary explanation.
Since randomizeddata is not appropriate to test mouse click predic-tion, we used 299 sequences of utterances that w-ere not used for training.
Our model predicted 84%of the user?s mouse clicks: 80% of them were pre-dicted 3-5 intervals before the actual occurrence ofthe mouse click, and 20% were predicted 1 intervalbefore.
However, the model frequently generateswrong predictions.
Improving precision rate isnecessary.6 Discussion and Future WorkWe employed a Bayesian network technique to ourgoal of developing conversational agents that cangenerate fine-grained multimodal instruction dia-logues, and we proposed a probabilistic model forpredicting grounding judgment and user?s success-ful mouse click.
The results of preliminary evalua-tion suggest that separate models of each modalityfor each conversational participant cannot properlydescribe the complex process of on-going multi-modal interaction, but modeling the interaction asdyadic activities with multiple tracks of modalitiesis a promising approach.The advantage of employing the Bayesian net-work technique is that, by considering the cost ofmisclassification and the benefit of correct classifi-cation, the model can be easily adjusted accordingto the purpose of the system or the user?s skill level.For example, we can make the model more cau-tious or incautious.
Thus, our next step is to im-plement the proposed model into a conversationalagent, and evaluate our model not only in its accu-racy, but also in its effectiveness by testing themodel with various utility values.ReferencesBrennan, S. 2000.
Processes that shape conversation andtheir implications for computational linguistics.
InProceedings of 38th Annual Meeting of the ACL.Cassell, J., Bickmore, T., Campbell, L., Vilhjalmsson, H.and Yan, H. (2000).
Human Conversation as a Sys-tem Framework: Designing Embodied Conversa-tional Agents.
Embodied Conversational Agents.
J.Cassell, J. Sullivan, S. Prevost and E. Churchill.Cambridge, MA, MIT Press: 29-63.Clark, H. H. and Schaefer, E. F. 1989.
Contributing todiscourse.
Cognitive Science 13: 259-294.Clark, H. H. and Krych, M. A.
2004.
Speaking whilemonitoring addressees for understanding.
Journal ofMemory and Language 50(1): 62-81.Dillenbourg, P., Traum, D. R. and Schneider, D. 1996.Grounding in Multi-modal Task Oriented Collabora-tion.
In Proceedings of EuroAI&Education Confer-ence: 415-425.Kipp, M. 2004.
Gesture Generation by Imitation - FromHuman Behavior to Computer Character Animation,Boca Raton, Florida: Dissertation.com.Nakano, Y. I., Reinstein, G., Stocky, T. and Cassell, J.2003.
Towards a Model of Face-to-Face Grounding.In Proceedings of the 41st Annual Meeting of the As-sociation for Computational Linguistics: 553-561.Paek, T. and Horvitz, E. (1999).
Uncertainty, Utility,and Misunderstanding: A Decision-Theoretic Per-spective on Grounding in Conversational Systems.Working Papers of the AAAI Fall Symposium onPsychological Models of Communication in Collabo-rative Systems.
S. E. Brennan, A. Giboin and D.Traum: 85-92.Whittaker, S. (2003).
Theories and Methods in Medi-ated Communication.
The Handbook of DiscourseProcesses.
A. Graesser, MIT Press.Table 1: Preliminary evaluation resultsPrecision Recall F-measureContentchange  0.53 0.99 0.68Samecontent 1.00 0.81 0.90124
