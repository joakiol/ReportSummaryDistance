Coping Wi th  Derivation in a Morphological Component  *Harald TrostAustrian Research Institute for Artificial IntelligenceSchottengasse 3, A-1010 WienAustriaemail: harald@ai.univie.ac.atAbstractIn this paper a morphological componentwith a limited capability to automaticallyinterpret (and generate) derived words ispresented.
The system combines an ex-tended two-level morphology \[Trost, 1991a;Trost, 1991b\] with a feature-based wordgrammar building on a hierarchical lexicon.Polymorphemic stems not explicitly storedin the lexicon are given a compositional in-terpretation.
That way the system allowsto minimize redundancy in the lexicon be-cause derived words that are transparentneed not to be stored explicitly.
Also, wordsformed ad-hoc can be recognized correctly.The system is implemented in CommonLispand has been tested on examples from Ger-man derivation.1 IntroductionThis paper is about words.
Since word is a ratherfuzzy term we will first try to make clear what wordmeans in the context of this paper.
Following \[di Sci-ullo and Williams, 1989\] we discriminate two senses.One is the morphological word which is built frommorphs according to the rules of morphology.
Theother is the syntactic word which is the atomic entityfrom which sentences are built according to the rulesof syntax.
*Work on this project was partially sponsored bythe Austrian Federal Ministry for Science and Researchand the "Fonds zur FSrderung der wissenschaftlichenForschung" grant no.P7986-PHY.
I would also like tothank John Nerbonne, Klaus Netter and Wolfgang Heinzfor comments on earlier versions of this paper.These two views support wo different sets of infor-mation which are to be kept separate but which arenot disjunctive.
The syntactical word carries infor-mation about category, valency and semantics, infor-mation that is important for the interpretation of aword in the context of the sentence.
It also carries in-formation like case, number, gender and person.
Theformer information is basically the same for all dif-ferent surface forms of the syntactic word 1 the latteris conveyed by the different surface forms producedby the inflectional paradigm and is therefore sharedwith the morphological word.Besides this shared information the morphologi-cal word carries information about the inflectionalparadigm, the stem, and the way it is internallystructured.
In our view the lexicon should be a me-diator between these two views of word.Traditionally, the lexicon in natural anguage pro-cessing (NLP) systems is viewed as a finite collectionof syntactic words.
Words have stored with themtheir syntactic and semantic information.
In themost simple case the lexicon contains an entry forevery different word form.
For highly inflecting (oragglutinating) languages this approach is not feasiblefor realistic vocabulary sizes.
Instead, morphologicalcomponents are used to map between the differentsurface forms of a word and its canonical form storedin the lexicon.
We will call this canonical form andthe information associated with it lezeme.There are problems with such a static view of thelexicon.
In the open word classes our vocabulary ispotentially infinite.
Making use of derivation andcompounding speakers (or writers) can and do al-ways create new words.
A majority of these wordsIFor some forms like the passive PPP some authorsassume different syntactic features.
Nevertheless they arederived regularly, e.g., by lexical rules.368are invented on the spot and may never be usedagain.
Skimming through real texts one will alwaysfind such ad-hoc formed words not to be found inany lexicon that are nevertheless readily understoodby any competent reader.
A realistic NLP systemshould therefore have means to cope with ad-hocword formation.Efficiency considerations also support the idea ofextending morphological components o treat deriva-tion.
Because of the regularities found in derivationa lexicon purely based on words will be highly re-dundant and wasting space.
On the other hand alarge percentage of lexicalized derived words (andcompounds) is no longer transparent syntacticallyand/or semantically and has to be treated like amonomorphemic lexeme.
What we do need then isa system that is flexible enough to allow for both acompositional nd an idiosyncratic reading of poly-morphemic stems.The system described in this paper is a combi-nation of a feature-based hierarchical lexicon andword grammar with an extended two-level morphol-ogy.
Before desribing the system in more detail wewill shortly discuss these two strands of research.2 Inheritance LexicaResearch directed at reducing redundancy in the lexi-con has come up with the idea of organizing the infor-mation hierarchically making use of inheritance (see,e.g.
\[Daelemans et al, 1992; Russell et al, 1992\]).Various formalisms upporting inheritance havebeen proposed that can be classified into two majorapproaches.
One uses defaults, i.e., inherited datamay be overwritten by more specific ones.
The de-fault mechanism handles exceptions which are an in-herent phenomenon of the lexicon.
A well-knownformalism following this approach is DATR \[Evansand Gazdar, 1989\].The major advantage of defaults is the rather nat-ural hierarchy formation it supports where classescan be organized in a tree instead of a multiple-inheritance hierarchy.
Drawbacks are that defaultsare computationally costly and one needs an inter-face to the sentence grammar which is usually writ-ten in default-free feature descriptions.Although the term default is taken from knowledgerepresentation e should be aware of the quite dif-ferent usage.
In knowledge representation defaultsare used to describe uncertain facts which may ormay not become xplicitly known later on.
2 Excep-tions in the lexicon are of a different nature becausethey form an a priori known set.
For any word it is2An example for the use of defaults in knowledge rep-resentation is an inference rule like Birds typically can fly.In the absence of more detailed knowledge this allows meto conclude that Tweety which I only know to be a birdcan fly.
Should I later on get the additional informationthat Tweety is a penguin I must revoke that conclusion.known whether it is regular or an exception.
3 Theonly motivation to use defaults in the lexicon is thatthey allow for a more concise and natural represen-tation.The alternative approach organizes classes ina multiple-inheritance hierarchy without defaults.This means that lexical items can be described asstandard feature terms organized in a type hierarchy(see, e.g., \[Smolka, 1988; Carpenter el al., 1991\]).The advantages are clear.
There is no need for aninterface to the grammar and computational com-plexity is lower.At the moment it is an open question which of thetwo anppproaches i  the more appropriate.
In oursystem we decided against introducing a new for-malism.
Most current natural anguage systems arebased on feature formalisms and we see no obviousreason why the lexicon should not be feature-based(see also \[Nerbonne, 1992\]).While inheritance lexica--concerned with the syn-tactic word--have mainly been used to express gen-eralizations over classes of words the idea can alsobe used for the explicit representation of deriva-tion.
In \[Nerbonne, 1992\] we find such a proposal.What the proposal shares with most of the otherschemes is that not much consideration is given tomorphophonology.
The problem is acknowledged bysome authors by using a function morphologically ap-pend instead of pure concatenation of morphs but itremains unclear how this function should be imple-mented.The approach presented here follows this line of re-search in complementing anextended two-level mor-phology with a hierarchical lexicon that contains asentries not only words but also morphs.
This waymorphophonology can be treated in a principled waywhile retaining the advantages of hierarchical lexica.3 Two-Level MorphologyFor dealing with a compositional syntax and seman-tics of derivatives one needs a component that iscapable of constructing arbitrary words from a fi-nite set of morphs according to morphotactic rules.Very successful in the domain of morphological nal-ysis/generation are finite-state approaches, notablytwo-level morphology \[Koskenniemi, 1984\].
Two-level morphology deals with two aspects of word for-mation:Morphotact i cs :  The combination rules that gov-ern which morphs may be combined in what or-der to produce morphologically correct words.Morphophono logy :  Phonological alterations oc-curing in the process of combination.Morphotactics i dealt with by a so-called continua-tion lexicon.
In expressiveness that is equivalent toa finite state automaton consuming morphs.aWe do not consider language acquisition here.369Morphophonology is treated by assuming two dis-tinct levels, namely a lexical and a surface level.
Thelexical evel consists of a sequence of morphs as foundin the lexicon; the surface level is the form foundin the actual text/utterance.
The mapping betweenthese two levels is constrained by so-called two-levelrules describing the contexts for certain phonologicalalterations.An example for a morphophonolocical alterationin German is the insertion of e between a stem end-ing in a t or d, and a suffix starting with s or t, e.g.,3rd person singular of the verb arbeiten (to work) isarbeitest.
In two-level morphology that means thatthe lexical form arbei~+st has to be mapped to sur-face arbeitest.
The following rule will enforce justthat mapping:(1) +:e gO {d, t} _ {s, t};A detailed escription of two-level morphology canbe found in \[Sproat, 1992, chapter 3\].In its basic form two-level morphology is not wellsuited for our task because all the morphosyntacticinformation is encoded in the lexical form.
Whenconnected to a syntactic/semantic component oneneeds an interface to mediate between the morpho-logical and the syntactic word.
We will show in inchapter 5 how our version of two-level-morphology isextended to provide such an interface.4 Der ivat ion  in  GermanUsually, in German derived words are morphologi-cally regular.
4 Morphophonological lterations arethe same as for inflection only the occurrence of um-laut is less regular.
Syntax and semantics on theother hand are very often irregular with respect tocompositional rules for derivation.As an example we will look at the German deriva-tional prefix be-.
This prefix is both very productiveand considered to be rather regular.
The prefix be-produces transitive verbs mostly from (intransitive)verbs but also from other word categories.
We willrestrict ourselves here to all those cases where thenew verb is formed from a verb.
In the new verbthe direct object role is filled by a modifier role ofthe original verb while the original meaning is ba-sically preserved.
One regularly formed example isbearbeiten derived from the intransitive verb arbeiten(to work).
(2) \[Maria\]svBj arbeitet \[an dem Papier\]eoBj.Mary works on the paper.
(3) \[Maria\]svBJ bearbeitet \[das Papier\]oBj.Skimming through \[Wahrig, 1978\] we find 238 en-4Most exceptions are regularly inflecting compoundverbs derived from an irregular verb, e.g., handhaben (tomanipulate) a regular verb derived from the irregularverb haben (to have).tries starting with prefix be-.
91 of these can beexcluded because they cannot be explained as be-ing derived from verbs.
Of the remaining 147 wordsabout 60 have no meaning that can be interpretedcompositionally.
5 The remaining ones do have atleast one compositional meaning.Even with those the situation is difficult.
In somecases the derived word takes just one of the meaningsof the original word as its semantic basis, e.g., befol-gen (to obey) is derived from folgen in the meaningto obey, but not to follow or to ensue:(4) Der Soldat folgt \[dem Befehl \]~onJ.The soldier obeys the order.
(5) Der Soldat befolgt \[den Befehl \]oBJ.
(6) Bet Soldat folgt \[dem 017izier \]IonJ.The soldier follows the officer.
(7) *Der Soldat befolgt \[den Offizier \]oBJ.In other cases we have a compositional as well asa non-compositional reading, e.g., besetzen derivedfrom setzen (to set) may either mean to set or tooccupy.What is needed is a flexible system where regu-larities can be expressed to reduce redundancy whileirregularities can still easily be handled.5 The  Morpho log ica l  ComponentX2MORFX2MORF \[Trost, 1991a; Trost, 1991b\] that forms thebasis of our system is a morphological componentbased on two-level morphology.
X2MORF extendsthe standard model in two way which are crucial forour task.
A feature-based word grammer replaces thecontinuation class approach thus providing a naturalinterface to the syntax/semantics component.
Two-level rules are provided with a morphological filterrestricting their application to certain morphologicalclasses.5.1 Feature -Based  Grammar  and  Lex iconIn X2MORF morphotactics are described by afeature-based grammar.
As a result, the represen-tation of a word form is a feature description.
Theword grammar employs a functor argument structurewith binary branching.Let us look at a specific example.
The (simplified)entry for the noun stem Hand (hand) is given in fig.1.To form a legal word that stem must combine withan inflectional ending.
Fig.2 shows the (simplified)entry for the plural ending.
Note that plural for-mation also involves umlaut, i.e., the correct surface5About half of them are actually derived from wordsfrom other classes like belehlen (to order) which is clearlyderived from the noun Belehl (order) and not the verbfehlen (to miss).370r \[CAT: N \]MORPH: /PARAD: e-plura q\[.UMLAUT: binary JPHON: handSTEM: (han~Figure 1: Lexical entry for Hand (preliminary)form is ttSnde.
As we will see later on this is whatthe feature UMLAUT is needed for.CAT: N \]~IORPH: L:c UM: plASE: { nora yen acc }PHON: +eSTEM: \[~\]MORPH: IPARAD: ARG: L UMLAUT: e~pluraSTEM: \[~\]Figure 2: Lexical entry for suffix e (preliminary)Combining the above two lexical entries in theappropriate way leads to the feature structure de-scribed in fig.3.MORPH:PHON:STEM:ARG:!AT: N \]UM: piASE: { nor.
ge.
ace }+e\ [~  hand~CAT:~IORPH: \[\]FARAD:LUML AUT:PHON: hand.STEM: \[~\]~ pluraFigure 3: Resulting feature structure for H~nde5.2 Extending Two-level Rules withMorphological ContextsX2MORF employs an extended version of two-levelrules.
Besides the standard phonological contextthey also have a morphological context in form ofa feature structure.
This morphological context isunified with the feature structure of the morph towhich the character pair belongs.
This morphologi-cal context serves two purposes.
One is to restrict theapplication of morphophonological rules to suitablemorphological contexts.
The other is to enable thetransmission of information from the phonological tothe morphological level.We can now show how umlaut is treated inX2MORF.
A two-level rule constrains the mappingof A to ~ to the appropriate contexts, namely wherethe inflection suff?x requires umlaut:(8) A:~ ?~_ ; \[MORPH: \[HEAD: \[UMLAUT: +\] \]\]The occurrence of the umlaut ~ in the surface formis now coupled to the feature UMLAUT taking thevalue +.
As we can see in fig.3 the plural ending hasforced the feature to take that value already whichmeans that the morphological context of the rule isvalid.Reinhard \[Reinhard, 1991\] argues that a purelyfeature-based approach is not well suited for thetreatment of umlaut in derivation because of its id-iosyncrasy.
One example are different derivationsfrom Hand (hand) which takes umlaut for plural(ll~nde) and some derivations (h~ndisch) but not forothers (handlich) There are also words like Tag (day)where the plural takes no umlaut (Tage) but deriva-tions do (tSglich).
Reinhard maintains that a defaultmechanism like DATR is more appropriate to dealwith umlaut.We disagree since the facts can be described inX2MORF in a fairly natural manner.
Once theequivalence classes with respect o umlaut are knownwe can describe the data using a complex featureUMLAUT 6 instead of the simple binary one.
Thiscomplex feature UMLAUT consists of a feature foreach class, which takes as value + or - and one fea-ture value for the recording of actual occurrence ofumlaut:LrMLAUT:"VALUE: binary\]PL-UML: binary\]LICH-UML: binary IISCH-UML: binaryJThe value of the feature UMLAUT\[VALUE is set bythe morphological fi ter of the two-level rule trigger-ing umlaut, i.e., if an umlaut is found it is set to +otherwise to -.
The entries of those affixes requiringumlaut set the value of their equivalence class to +.Therefore the relevant parts of the entries for -iichand -isch look like \[UMLAUT: \[UOH-U~,: +\] \ ]  and\[UMLAUT: \[ISCH-UML: + \]\] because both these end-ings normally require umlaut.As we have seen above the noun Hand comes withumlaut in the plural (llSnde) and the derived adjec-tive hSndisch (manually)but (irregularly) withoutumlaut in the adjective handlich (handy).
In fig.4we show the relevant part of the entry for Hand thatproduces the correct results.
The regular cases are6In our simplified example we assume just 3 classes(for plural, derivation with -lich and -isch).
In reality thenumber of classes is larger but still fairly small.371single.stemCAT: i,VlORPH: UMLAUT:PHON: hAndSTEM: (ha.~SYNSEM: synsemIVALUE: \ [~PL-UML: V~\]ISCH-UML: \[~\]lLICH-UML:- JPL-UML: \[~ISCH-UML: \ [ \ ]blCH-UML: +Figure 4: Lexical entry for Hand (final version)taken care of by the first disjunct while the excep-tions are captured by the second.The first disjunct in this feature structure takescare of all cases but the derivation with .lich.
Theentries for plural (see fig.5) and -isch come with thevalue + forcing the VALUE feature also to have a +value.
The entry for -lich also comes with a + valueand therefore fails to unify with the first disjunct.Suffixes that do not trigger umlaut come with theVALUE feature set to -.The second isjunct captures the exception for the-lich derivation of Hand.
Because of requiring a -value it fails to unify with the entries for plural and-isch.
The + value for -lich succeeds forcing at thesame time the VALUE feature to be -.rCAT: NMORPH: \[lCUM: plASE: {PHON: +eSTEM: \[~\]SYNSEM: \[~\]MORPH:ARG:nor.
gen aec }\]CAT: N \] \]PARAD : e-pluralUMLAUT: \[PL-UMLAUT: +\]STEM: \ [ \ ].SYNSEM: ~\]Figure 5: Lexical entry for suffix e (final version)This mechanism allows us to describe the umlautphenomenon in a very general way while at the sametime being able to deal with exceptions to the rulein a simple and straightforward manner.5.3 Using X2MORF directly for derivationRegarding morphotactics and morphophonologythere is basically no difference between inflection andderivation.
So one could use X2MORF as it is tocope with derivation.
Derivation particles are word-forming heads \[di Sciullo and Williams, 1989\] thathave to be complemented with the appropriate (sim-ple or complex) stems.
Words that cannot be inter-preted compositionally anymore have to be regardedas monomorphemic and must be stored in the morphlexicon.Such an approach is possible but it poses someproblems:* The morphological structure of words is no moreavailable to succeeding processing stages.
Forsome phenomena just this structural informa-tion is necessary though.
Take as an examplethe partial deletion of words in phrases with con-junction (gin- und Vcrkan\]).?
The compositional reading of a derived wordcannot be suppressed r, even worse, it is indis-tinguishable from the correct reading (remem-ber the befehlen example).?
Partial regularities cannot be used anymore toreduce redundancy.Therefore we have chosen instead to augmentX2MORF with a lexeme lexicon and an explicit in-terface between morphological nd syntactic word.6 System ArchitectureLogically, the system uses two different lexica.A morph lexicon contains MI the morphs, i.e.,monomorphemic stems, inflectional and derivationalaffixes.
This lexicon is used by X2MORF.
A iezemelexicon contains the lexemes, i.e.
stem morphs andderivational endings (because of their word-formingcapacity).
The lexical entries contain the lexeme-specific syntactic and semantic information underthe feature SYNSEM.These two lexica can be merged into a single typehierarchy (see fig.6) where the morph lexicon en-tries are of type morph and lexeme lexicon entriesof type lezeme.
Single-stems and deriv-morphs sharethe properties of both lexica.ZOne could argue that the idea of preemption is incor-rect anyway and that only syntactic or semantic restric-tions block derivation.
While this may be true in theoryat least for practical considerations we will need to beable to block derivation in the lexicon.37?lez.entrymoth lezemem f l e ~single-stem complex-stemFigure 6: Part of the type lattice of the lexiconSince we have organized our lexica in a type hier-archy we have already succeeded in establishing aninheritance hierarchy.
We can now impose any of thestructures proposed in the literature (e.g., \[Kriegerand Nerbonne, 1991; Russell et al, 1992\]) for hierar-chical lexica on it, as long as they observe the samefunctor argument structure of words crucial to ourmorphotactics.Why are we now in a better situation thanby using X2MORF directly?
Because complexstems are no morphs and therefore inaccessible toX2MORF.
They are only used in a second process-ing stage where complex words can be given a non-compositional reading.
To make this possible the as-signing of compositional readings must also be post-poned to this second stage.
This is attained by givingderivation morphs in the lexicon no feature SYNSEMbut stating the information under FUNCTOR\]SYNSEMinstead.In the first stage X2MORF processes the morpho-tactic information including the word-form-specificmorphosyntactic information making use of themorph lexicon.
The result is a feature-descriptioncontaining the morphotactic structure and the mor-phosyntactic information ofthe processed word form.What has also been constructed is a value for theSTEM feature that is used as an index to the lexemelexicon in the second processing stage, sIn the second stage we have to discriminate be-tween the following cases:?
The stem is found in the lexeme lexicon.
In caseof a monomorphemic stem processing is com-pleted because the relevant syntactic/semanticinformation has already been constructed ur-ing the first stage.
In case of a polymorphemicstem the retrieved lexical entry is unified withthe result of the first stage, delivering the lexi-calized interpretation.SInflectional endings do not contribute to the stem.Also, allomorphs like irregular verb forms share a com-mon stem.The stem is not found in the lexeme lexicon.
Inthat case a compositional interpretation is re-quired.
This is achieved by unifying the resultof stage one with the feature structure shownin fig.7 This activates the SYNSEM informationof the functor-which must be either an inflec-tion or a derivation morph.
In case of an in-flection morph nothing really happens.
But forderivation morphs the syntactic/semantic infor-mation which has already been constructed isbound to the feature SYNSEM.
Then the processmust recursively be applied to the argument ofthe structure.
Since all monomorphemic stemsand all derivational ffixes are stored in the lex-eme lexicon this search is bound to terminate.
"FUNCTOR: \[SYNSEIVI: \[~\]complex.stem SYNSEM: \[ '~Figure 7: Default entry in the lexeme lexiconHow does this procedure account for the flexibilitydemanded insection 4.
By keeping the compositionalsynyactic/semantic interpretation local to the rune-tot during morphological interpretation the decisionis postponed to the second stage.
In case there isno explicit entry found this compositional interpre-tation is just made available.In case of an explicit entry in the lexeme lexiconthere is a number of different possibilities, amongthem:?
There are just lexicalized interpretations.?
There is a compositional swell as a lexiealizedinterpretation.?
The compositional interpretation is restricted toa subset of the possible semantics of the root.The entries in the lexeme lexicon can easily betailor-made to fit any of these possibilities.373deriv.morpA"PHON:MORP H:STEM:FUNCTOR:ARQ:be+ \[:i:\] \[HE,D: \[O,T" q\](aPPend ~7 \[~\])?MORPH: \[HEAD: \[-~STEM: \[~3(be)SYNSEM: CAT: \[SUBCAT: (appendNP\[OBJ\]\[~_\], \[~ )tOO.T: ,o.tod"H  .
:STEM: q \]\]tOONT:NFigure 8: Lexical entry for the derivational prefix be-7 A Detailed ExampleWe will now illustrate the workings of the systemusing a few examples from section 4.
The first ex-ample describes the purely compositional case.
Theverb betreten (to enter) can be regularly derived fromtreten (to enter) and the suffix be-.
The sentences(9) Die Frau tritt \[in das Zimmer\]POBd.The woman enters the room.
(10) Die Frau betritt \[das Zimmer\]oBJ.are semantically equivalent.
The prepositional ob-ject of the intransitive verb treten is transformed intoa direct object making betreten a transitive verb.
Anumber of verbs derived by using the particle be-follows this general pattern.
Figure 8 shows-a sim-plified version of-the lexical entry for be-.The SYNSEM feature of the functor contains themodified syntactic/semantic description.
Note thatthe lexical entry itself contains no SYNSEM feature.When analyzing a surface form of the word betretenthis functor is combined with the feature structurefor treten (shown in fig.9) as argument.At that stage the FUNCTORISYNSEM feature of be-is unified with the SYNSEM feature of treten.
Butthere is still no value set for the SYNSEM feature.This is intended because it allows to disregard thecomposition i favour of a direct interpretation f thederived word.
In our example we will find no entryfor the stem betreten though.
We therefore have totake the default approach which means unifying theresult with the structure shown in fig.7.Up to now our example was overly simplified be-cause it did not take into account hat treten hasa second reading, namely to kick.
The final lexicalentry for treten is shown in fig.10.But this second reading of treten cannot be usedfor deriving a second meaning of betreten:(11) Die Frau 1tilt \[den Huna~oss.The woman kicks the dog.
(12) *Die Frau betritt \[den Hnna~oB.~.We therefore need to block the second compositionalinterpretation.
This is achieved by an explicit entryfor betreten in the lexeme lexicon which is shown infig.ll.single-ster~Figure 9:'PHON: trEt \[O T" V\]\]STEM: tret)' \[HEAD: verbCAT: \[sunoAT: (NP\[SVBJ\] ,SYNSEM: \[REL: fret 'CONT: IAGENT: \[~persorLTO: ~to-locLexical entry for verb treten (preliminary version)374single.stem"PHON: trEtMoRPR- \[READ: \[OAT: q\]STEM: ( tret)"HEAD: verb \]CAT: SUBCAT: (NPtSUBJ\]F\], P I~)"REL: tret 'AGENT: \[l~rsor I \[CONT:.TO: ~\]to-locSYNSEM: I \]HEAD: verb \]\]CAT: \[SUBCAT: (NP\[SUB.I\]\[~\], NP\[OBJ\]~\])\[REL: t t" \]\[THEME: ~\]animateJFigure 10: Lexical entry for treten (final version)FUNCTOR:STEM:?
.
ISYNSEM: complez-s~eml.\[S EM" \[\] \](be tret)IT\]\[?ONT: \[REL" t~t'\]\]Figure 11: Entry for betreten in the lexeme lexiconWe now get the desired results.
While both read-ings of treten produce a syntactic/semantic interpre-tation in the first stage the incorrect one is filteredout by applying the lexeme lexicon entry for betretenin the second stage.8 ConclusionIn this paper we have presented a morphological na-lyzer/generator that combines an extended two-levelmorphology with a feature-based word grammar thatdeals with inflection as well as derivation.
The gram-mar works on a lexicon containing both morphs andlexemes.The system combines the main advantage of two-level morphology, namely the adequate treatment ofmorphophonology with the advantages of feature-based inheritance l xica.
The system is able to auto-matically deduce a compositional interpretation forderived words not explicitly contained in the sys-tem's lexicon.
Lexicalized compounds may be en-tered explicitly while retaining the information abouttheir morphological structure.
That way one can im-plement blocking (suppressing compositional read-ings) but is not forced to do so.Re ferences\[Backofen et al, 1991\] Rolf Backofen, Harald Trost,and Hans Uszkoreit.
Linking Typed Fea-ture Formalisms and Terminological Knowl-edge Representation Languages in Natural Lan-guage Front-Ends.
In W. Bauer, editor.
Pro-ceedings GI Kongress Wissensbasierte Systeme199I, Springer, Berlin, 1991.\[Carpenter tal., 1991\] Bob Carpenter, Carl Pol-lard, and Alex Franz.
The Specification andImplementation of Constraint-Based Unifica-tion Grammars.
In Proceedings of the Sec-ond International Workshop on Parsing Tech-nology,pages 143-153, Cancun, Mexico, 1991.\[Daelemans et al, 1992\] Walter Daelemans, Koen-raad De Smetd, and Gerald Gazdar.
Inheritancein Natural Language Processing.
ComputationalLinguistics 18(2):205-218, June 1992.\[Evans and Gazdar, 1989\] Roger Evans and GeraldGazdar.
Inference in DATR.
In Proceedings ofthe ~th Conference of the European Chapter ofthe ACL, pages 66-71, Manchester, April 1989.Association for Computational Linguistics.\[Heinz and Matiasek, 1993\] Wolfgang Heinz and Jo-hannes Matiasek.
Argument Structure and CaseAssignment in German.
In J. Nerbonne, K. Net-ter, and C. Pollard, editors.
HPSG for German,CSLI Publications, Stanford, California, (to ap-pear), 1993.\[Koskenniemi, 1984\] Kimmo Koskenniemi.
A Gen-eral Computational Model for Word-FormRecognition and Production.
In Proceed-ings of the lOth International Conference onComputational Linguistics, Stanford, Califor-nia, 1984. International Committee on Com-putational Linguistics.\[Krieger and Nerbonne, 1991\] Hans-Ulrich Kriegerand John Nerbonne.
Feature-Based InheritanceNetworks for Computational Lexicons.
DFKI375Research Report RR-91-31, German ResearchCenter for Artificial Intelligence, Saarbriicken,1991.\[Nerbonne, 1992\] John Nerbonne.
Feature-BasedLexicons: An Example and a Comparison toDATR.
DFKI Research Report RR-92-04, Ger-man Research Center for Artificial Intelligence,Saarbriicken, 1992.\[Reinhard, 1991\] Sabine Rein-hard.
Ad~quatheitsprobleme automatenbasierterMorphologiemodelle am Beispiel der deulschenUmlautung.
Magisterarbeit, Universit~it Trier,Germany, 1990.\[Russell et al, 1992\] Graham Russell, Afzal Ballim,John Carroll, and Susan Warwick-Armstrong.
APractical Approach to Multiple Default Inheri-tance for Unification-Based Lexicons.
Compu-tational Linguistics, 18(3):311-338, September1992.\[di Sciullo and Williams, 1989\] Anna-Maria di Sci-ullo and Edwin Williams.
On the Definition ofWord.
MIT Press, Cambridge, Massachusetts,1987.\[Sproat, 1992\] Richard Sproat.
Morphology andComputation.
MIT Press, Cambridge, Mas-sachusetts, 1992.\[Smolka, 1988\] Gerd Smolka.
A Feature Logic withSubsorts.
LILOG-Report 33, IBM-Germany,Stuttgart, 1988.\[Trost, 1991a\] Harald Trost.
Recognition and Gen-eration of Word Forms for Natural LanguageUnderstanding Systems: Integrating Two-LevelMorphology and Feature Unification.
AppliedArtificial Intelligence, 5(4):411-458, 1991.\[Trost, 1991b\] Harald Trost.
X2MORF: A Morpho-logical Component Based on Two-Level Mor-phology.
In Proceedings of the 12th Inter-national Joint Conference on Artificial Intel-ligence, pages 1024-1030, Sydney, Australia,1991.
International Joint Committee on Arti-ficial Intelligence.\[Wahrig, 1978\] Gerhard Wahrig, editor, dryW6rterbuch der deutschen Sprache.
DeutscherTaschenbuch Verlag, Munich, Germany, 1978.376
