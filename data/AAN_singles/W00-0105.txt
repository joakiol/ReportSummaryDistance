Dependency of context-based Word Sense Disambiguation fromrepresentation and domain complexityPaola VelardiDipartimento di Scienze dell' InformazioneUniversity "La Sapienza"RomaVelardi@dsi.uniromal.itAlessandro CucchiarelliIstituto di InformaticaUniversity of AnconaAnconaalex@inform.unian.itAbstractWord Sense Disambiguation (WSD) is acentral task in the area of NaturalLanguage Processing.
In the past few yearsseveral context-based probabilistic andmachine learning methods for WSD havebeen presented in literature.
However, animportant area of research that has notbeen given the attention it deserves is aformal analysis of the parameters affectingthe performance of the learning task facedby these systems.
Usually performance isestimated by measuring precision andrecall of a specific algorithm for specifictest sets and environmental conditions.Therefore, a comparison among differentlearning systems and an objectiveestimation of the difficulty of the learningtask is extremely difficult.In this paper we propose, in the frameworkof Computational Learning theory, aformal analysis of the relations betweenaccuracy of a context-based WSD system,the complexity of the contextrepresentation scheme, and theenvironmental conditions (e.g.
thecomplexity of language domain andconcept inventory ) .1 IntroductionIn the literature (see Computational Linguistics(1998) for some recent results), there is a rathervast repertoire of supervised and unsupervisedlearning algorithms for WSD, most of whichare based on a formal characterization f thesurrounding context of a word or linguisticconcept 1, and a function f to compute themembership of a word to a category, given itscontext in running texts.Despite the rich literature, none of thesealgorithms exhibit an "acceptable"performance with reference to the needs ofreal-world computational task (e.g.Information Retrieval, Information Extraction,Machine Translation etc.
), except forparticularly straightforward cases.A very interesting WSD experiment isSenseval (1998), a large:-scale exercise inevaluating WSD programs.
One of theobjectives of this experiment was to identifycorrelations between performance of thevarious systems and the parameters of theWSD task.
Though the scoring of systemsappears ensitive to certain factors, such as thedegree of polysemy and the entropy of sensedistributions, these correlations could not beconsistently observed.
There are words withfewer senses (e.g.
bet, consume, generous)causing troubles to most systems, while thereare words with a very high polysemy andentropy (e.g.
shake) on which all systemsobtain good performance.
The justification thatthe Senseval coordinator Adam Kilgariffprovides for shake is very interesting in thelight of what we will discuss later in this paper:"The items (means contexts) for shake involvemulti-word expressions, uch as shake one'shead.
(...) Over 50% of the items for shakeinvolve some multi-word expression or other.
"In other words, the contexts for shake are very1 The inventory of linguistic concepts is usuallyextracted from on-line resources like WordNet, theLongman dictionary (LDOCE), or HECTOR.28repetitive in the training set, therefore allsystems could easily learn a sensediscrimination model.Furthermore, in Senseval (but also in otherreported evaluations experiments) it appearsthat performances for individualwords/concepts are extremely uneven withinthe same system.
This scarce homogeneity ofresults suggests that performance is not solelyrelated with the "cleverness" of a givenlearning algorithm.Clearly, the performances of WSD systems arerelated to a variety of parameters, but theformal nature of these dependencies is not fullyunderstood.The Senseval experiment highlighted thenecessity of a more accurate analysis of thecorrelations between performance of WSDsystems and the parameters that may affect histask.
In absence, a comparison of the variousWSD algorithms and an estimation of theirperformance under different environmentalconditions is extremely difficult.In the next sections we briefly present acomputational model of learning, called PACtheory (Anthony and Biggs (1997), Kearns andVazirani (1994), Valiant (1984)), and we thenshow that this theory may be used to determinethe formal relations between performance ofcontext-based WSD models and environmentalconditions, such as the complexity of thecontext representation scheme, and the thecomplexity of language domain and conceptinventory.2 A relation between sample size andcomplexity of learning taskFormally, the problem of example-basedlearning of WSD models can be stated asfollows:1 Given a class C of concepts Cl (where Cis either a hierarchy or a "flat" conceptinventory),2 Given a context-based representadonclass H for a concept class C, where H:~*--~C and ~ is a finite alphabet ofsymbols (e.g.
words or word tags),3 Given an input space X~*  ofencodings of instances in the learner'sworld, e.g.
feature vectors representingcontexts around words wj, where wj is amember of Ct,Given a training sample S of length m:S=((xl,bl)...(xm,bm)) xi eX, ~ e{O,l}where bl=l if xi is a positive example of Cl,characterize formally a function h (C~)e H thatassigns a word w to a concept Cl, given thesentence context x of w. The hypothesis mayhave the form of a Hidden Markov Model withestimated transition probabilities, a decisionlist, a cluster of points in a representationspace, a logic formula, etc.The complexity of this learning task is relatedto several aspects, such as selecting anappropriate representation space H, anappropriate grain for the concept inventory C,and finally, a sufficiently representativetraining sample S.As first, H must be a "reasonable"representation space for C. Quite intuitively, ifwe represent a linguistic concept as the set ofpossible morphologic tags pairs in a ?1window, we will not be able to predict much,simply because surrounding morphologic tagsare not sufficient to determine the semanticcategory of a word.On the opposite, if we select an overlycomplex representation model, includingirrelevant features, we run through the socalled overfitdng problem.Thirdly, some of the features used in arepresentation may be dependent from otherfeatures, and again the model would resultunnecessarily complex.The problem of noise and overfitting are wellknown in the area of Machine Learning(Russell and Norvig (1999)), therefore we willnot discuss the matter in detail here.
Ananalysis of this issue as applied to probabilisticWSD learners may be found in Bruce andWiebe (1999).For the purpose of this paper, we assume thatthe representation space H is optimized withrespect to the choice of the relevant modelparameters.
Our objective will be to determinethe size of S, given H and C, and given certainperformance objectives.As we said, the aim of a WSD learningprocess, when instructed with a sequence S ofexamples in X, is to produce an hypothesis hwhich, in some sense, "corresponds" to the29concept under consideration.
Because S is afinite sequence, only concepts with a finitenumber of positive examples can be learnedwith total success, i.e.
the learner can output anhypothesis h= C~ .
In general, and this is thecase for linguistic oncepts, we can only hopethat h is a good approximation of Ci..
In ourproblem at hand, it is worth noticing that evenhumans may provide only approximatedefinitions of linguistic oncepts !The theory of Probably Approximately Correct(PAC) learning, a relatively recent field at theborderline between Artificial Intelligence andInformation Theory, states the conditionsunder which h reaches this objective, i.e.
theconditions under which a computer derivedhypothesis h 'probably' represents Ct'approximately'.Definition 1 (PAC learning).
Let C be aconcept class over X.
Let D be a fixedprobability distribution over the instance spaceX, and EX(Ci,D) be a procedure reflecting theprobability distribution of the population wewhish to learn about.
We say that C is PAClearnable if there exists an algorithm L withthe following property: For every Ci~C, forevery distribution D on X, and for all 0<e<l/2and 0<8<1/2, if L is given access to EX(C~,D)and inputs e and 8, then with probability atleast (1-8), L outputs a hypothesis h forconcept Cl, satisfying error(h)<e.
Theparameters e and 5 have the followingmeaning: e is the probability that the learnerproduces a generalization of the sample thatdoes not coincide with the target concept,while 5 is the probability, given D, that aparticularly unrepresentative (or noisy) trainingsample is drawn.
The objective of PAC theoryis to predict the performance of learningsystems by deriving a lower bound for m, as afunction of the performance parameters e and6.Figure 1 (from Russell and Norvig (1999))illustrates the "intuitive" meaning of PACdefinition.
After seeing m examples, theprobability that Hbad includes consistenthypotheses is:P(Hbad~Hco.s)-<\[ Hbad \[(l-l~)m-<lH\[(l-~) mHHbad @Figure I : e-sphere around the "true"function CiAnd we want this to be:IHl(1-e)m_<6we hence obtain a lower bound for the numberof examples we need to submit o the learner inorder to obtain the required accuracy:(1) m_>~(ln~ +1 ~ I~The inequality (1) establishes a sort of worst-case general bound, relating the size of thelearning set with the complexity of therepresentation space \[HI.
Unfortunately thisbound turns out to have limited utility inpractical applications.For example, if the hypothesis pace for alinguistic concept Ci is the classic "bag ofwords", i.e.
a set of at least k "typical" contextwords selected by a probabilistic learner, afterobserving m samples of the ?n words aroundwords we Cl(e.g.
x = (W.n,W.n+l,.. W .. .
.
Wn-l,Wn) )then H is any choice of _<k_<lV\[ words over IVIelements, where \[V\[ (--10 s) is the size of thevocabulary.
We then have:the above expression, used in inequality (1),produces an overly high bound for m, that canbe hardly pursued especially in case thelearning algorithm is supervised!In PAC literature, the bound for m is oftenderived "ad hoc" for specific algorithms, inorder to exploit knowledge on the preciselearning conditions.It is also worth noticing that PAC literature hasmostly a theoretical emphasis, and mostapplications concentrated onthe field of neuralnetworks and natural learning systems(Hanson, Petsche, Kearns, Rivest (1994)).
Tothe knowledge of the authors, the utility of thistheory in the area of computer learning ofnatural language has not been explored.30In the following, we will derive a probabilisticexpression for m in the track of (1), for thecase of a context-based WSD probabflisticlearner, a learning method that includes arather wide class of algorithms in the area ofWSD.
We believe that adapting our analysis toother example-based WSD systems will notrequire a significant effort.
This relation allowsit to establish, upon an a-priori analysis of thechosen conceptual model and of the languagedomain, a more precise relation betweenperformance, complexity of the learningalgorithm, and environmental conditions (e.g.complexity of the language domain).Our objective is to show that an a-priorianalysis of the learning model and languagedomain may help to tune precisely a WSDexperiment and allows a more uniformcomparison between different WSD systems.3.
A formal estimate of accuracy forcontext-based probability WSD modelsA probabilistic context-based WSD learnermay be described as follows:Let X be a space of feature vectors:fk=( f(all=vl,a21=v2 .... ani=Vn)e ~n, bik)),b\[ =1 if fk is a positive example of Ct under H.Each vector describes the context in which aword we Cl is found, with variable degree ofcomplexity.
For examples, arguments may beany combination of plain words and theirmorphologic, syntactic and semantic tags.We assume that arguments are not statisticallyindependent (in case they are, therepresentation f a concept is more simple, seeBruce and Wiebe, (1999)).An example (Cucchiarelli, Luzi and Velardi(1998)) is the case in which fk represents asyntactic relation between we C~ and anotherword in its context.
For example, given thecompound istrict banks the following featureis generated as an example of the categoryorganization:((N_N district bank), organization(bank))We further assume that observations ofcontexts are noisy, and the noise may beoriginated by several factors, such as tagsambiguity, and semantic ambiguity of the wordwhose context is observed.In the above feature vector, the syntactic tag(first argument) could be wrong because ofsyntactic ambiguity and limited coverage ofavailable parsers, and the ambiguous wordbank could not be, in a specific context, aninstance of the category organization, though itis in the example above.Probabilistic learners usually associate touncertain information a measure of theconfidence the system has in that information.Therefore, we assume that each feature fk isassociated to a concept Cl with a confidenceqb(i,k).The confidence may be calculated in severalways, depending upon the type of selectedfeatures for fk.
For example, the MutualInformation measures the strength of acorrelation between co-occurring arguments,and the Plausibility (Cucchiarelli, Luzi andVelardi (1998)) assigns a weight to a featurevector, depending upon the degree ofambiguity of its arguments and the frequencyof its observations in a corpus.
We assume herethat ~ is adjusted to be a probability, i.e.~l~(i,k)=l.
The factor ~(i,k) represents hencean estimate of the probability that fk.
is indeeda context of Ci.Under these hypotheses, a representation he Hfor a concept Ct is the following:h(Cl):{fll..flm,}(2) fk-~h(Cl ) iff qb(i,k) > yA concept is hence represented by a set offeatures with associated probabilities 2.
Policy(2) establishes that only features with aprobability higher than a threshold y areassigned to a category model.Given an unknown word w' occurring in acontext represented by f'k, the WSD algorithmassigns w' to the category in C that maximizesthe similarity between f'k and one of itsmembers.
Again, see Cucchiarelli, Luzi andVelardi (1998) and Bruce and Wiebe, (1999)for examples of similarity functions.2 Note that in case of statistical independenceamong the features in a vector, a model for aconcept would be a set of features, rather thanfeature vectors, but most of  what we discuss in thissection would still apply with simple changes.31Given the above, the probabilistic WSD modelfor a category Ct may fail because:1 Cl includes falsepos#Jves (fp), e.g.
featurevectors erroneously assigned to Cl2 There are false negatives (fn), i.e.
featurevectors erroneously discarded because of alow value qb(i,k)3 The context f'k of the word w' has neverbeen observed around members of Ct, norit is similar (in the precise sense ofsimilarity established by a givenalgorithm) to any of the vectors in thecontextual models.We then have3:(3) P(w' is misclassified on the basis off'k)=P(f'kE fp in C0+P(f'kE fn outside C0+P(f'kisunseen in C OLet:m be the total number of feature vectorsextracted from a corpusm k the total number of occurrences of a featurefkk the number of times the context fk occurred m iwith a word w' member of ClNotice that ~irnik~m k, since, because ofiambiguity, a context may be assigned to morethan one concept (or to none).We can then estimate the three probabilities inexpression (3) as follows:L(3.1) ~ (fp in Ct)= E -~-(l-dp(i, k)~( i, k~?m.
k(3.2) ~ (fn outside C~)= X 1 0(i,k)?
(i, k~y m(3.3) ~ (unseen in CO=(1 ~mk).
(~ Emik ).
(~(i)) =~m Emik,(i, km Vm =l k kThe third probability is computed as theproduct of three estimated factors: theprobability ~ of unseen contexts 4 in the3 In the expression 3) the three events are clearlymutually exclusive.4 We here assume for simplicity that the similarityfunction is an identity.
A multtnomial or a morecorpus, the probability of extracting contextsaround members of Cl, and the averageconfidence of a feature vector in Cl.Classic methods uch as Chernoff bounds maybe applied to obtain good approximations forthe three probabilities above.
Notice howeverthat in order to obtain a given accuracy ofestimate, Chernoff bounds (and other methods)again impose a bound on the number ofobserved examples (Kearns and Vazirani(1994))Since in (3.1) (1-~(i,k))<y, in (3.2) ~(i,k))>y,and in (3.3) ~(i,k))_<l, we obtain the bound:P(w' is misclassified on the basis of f'k)=<_ Mi m -Ni (l-y)+_~ty +l~m ~mThe expression (3) establishes interestingdependencies between the accuracy of acontext-based probabilistic WSD model andcertain environmental conditions.3.1 Dependency upon the corpus andlinguistic conceptsIn a complex language domain (e.g.
newspaperarticles) linguistic phenomena re far lessrepetitive than in a restricted language (e.g.airline reservations).
However, even in arelatively unrestricted domain certaincategories are used in a more narrow sense.Let us consider the probabilistic ontext-basedalgorithm in Cucchiarelli, Luzi and Velardi(1998), where a feature is defined by:fk: (syntactic_relation, wl, wi) (e.g.
(N_Ndistrict bank))fk ~C~ if w i reaches the hyperonym C~ in theWordNet on-line taxonomy, and ~(i,k) > yUsing the 1 million word Wall Street Journalcorpus, we estimated the followingprobabilities (3.3) of unseen feature vectors (min this experiment is O(105)):P(unseen in artifact)=0,7692P(unseen in person)= 0,7161P(unseen in psychological feature)=0.8598complex function must be used in case contexts areconsidered similar if, for example, co-occurringwords have some common hyperonym.
SeeCucchiarelli, Luzi and Velardi (1998) forexamples.32The linguistic concepts artifact, person andpsychological feature are three hyperonyms ofthe on-line WordNet taxonomy.
The abovefigures show that the more "vague" conceptpsychological feature occurs in more variablecontexts, though the distribution of words inthe three categories i approximately even.3.2 Dependency on the representat ionmodelThe representation model H also affects theestimates of erroneous classifications.
Forexample, if we modify the contextual model byremoving the information on wi (that is to say,the feature vectors in the contextual model nowonly includes the syntactic relation type andthe co-occurring word wl), we obtain thefollowing values for the probabilies (3.3):P (unseen in artifact) =0,1778P (unseen in person) = 0,1714P(unseen in psychological feature)=O,2139The probability of "unseens" in this simplermodel is considerably lower (we removed anattribute, wi, that assumes values over V), butclearly, the probability of false positives andfalse negatives increases.The motivation is that we now assume that acontext for a word belonging (also to) Ct is avalid context for any word in that category.Regardless of the specific adopted formula forO(i,k), the confidence ~b(i,k) in such ageneralization depends on the number ofdifferent words w~ in occurring in a givencontext fk.
If this number is low, or is just 1,then the value of dp(i,k) must be low,accordingly.
The selected threshold y thendetermines the different contribution of falsepositives and false negatives to the total modelaccuracy.A preliminary experiment is illustrated inFigure 2.
The figure computes (1-P(fp in C1)for the category artifact, as a function of m and~(i,k), evaluated on a test set of 78 words.The figure shows that when y is >_0,5 thenumber of false positives is rather low, afterobserving sufficient examples.On the other side, P(fn outside Ci) (not shownhere for sake of space) has a specularbehavour.
For 7=0,9, the probability of falsenegative is as low as 0,6.4.
ConclusionBy no means the work presented in this paperneeds more investigation, especially on theexperimental side.
However, we believe thatlearnability analysis of WSD models hasstrong practical implications.The quantitative and (preliminary)experimental results of Section 2 put inevidence that :?
In order to acquire statistically stablecontextual models of linguistic concepts,the dimension of the analyzed corporamust be considerably high.
Paradoxically,untrained probabilistic systems are inbetter shape in this regard.
Very largerepositories of language samples can benow obtained from the WWW.?
The experimental setting (i.e.
size of thetraining set) must be tuned for eachcategory and language domain, because thevariability of contextual behavior may besignificantly different, depending ondomain complexity, e.g.
the type and grainof the selected category, and the more orless restricted language domain?
it is possible and indeed advisable, for agiven WSD algorithm, to determine in aformal way the relation between expectedaccuracy of the WSD model and thedomain and representation complexity.This would allow a better comparisonamong systems, and an a-priori tuning ofthe parameters of the disambiguationmodel.ReferencesAnthony M. and Biggs, N. (1997) ComputationalLearning Theory Cambridge University Press,1997Bruce R. and Wiebe J., (1999) DecomposableModeling in Natural Language Processing,Computational Linguistics vol.
25, N. 2.
199Computational Linguistics (1998) Special Issue onWord Sense Disamblguatlon, Vol.
24 (1) March198833Cucchiarelli A. Luzi D. and Velardi P. (1998)Automatic Semantic Tagging of Unknown ProperNames Proc.
of joint 36 ?
ACL-17 ?
COLING,Montreal, August 1998Hanson S.J., Petsche T., Kearns M., Rivest R.L.
(1994) Computational Learning Theory andNatural Learning Systems, Vol.
II, MIT Press,1994Kearns M.J. and Vazirani U.V.
(1994) AnIntroduction to Computational Learning TheoryMIT Press, 1994Russell S.J and Norvig P (1999).
Chapter 18:Learning from Observations in: ArtificialIntelligence: a modern approach Prentice-hall1999Senseval (1998) homepage: http://www.itri.brtghton.ac.uk/events/senseval\]Valiant L. (1984) A Theory of LearnableCommunications of the ACM, 27(11), 1984Figure 2: (1 -P( fp) )  VS. Corpus Dim.
For the category Ar t i fact100 ?9590  .l'!I~.
8580 ~7024943 4988S 74827 99770 124712 149654Corpus Dim.34
