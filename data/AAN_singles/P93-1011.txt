ASSIGNING A SEMANTIC SCOPE TO OPERATORSMassimo PoesioUniversity of Rochester, Department ofComputer ScienceRochester, NY 14627-0226, USApoesio@cs, rochester, eduAbstractI propose that he characteristics of the scope disamhiguationprocess observed in the literature can be explained in termsof the way in which the model of the situation describedby a sentence is built.
The model construction procedure Ipresent builds an event structure by identifying the situationsassociated with the operators in the sentence and their mu-tual dependency relations, as well as the relations betweenthese situations and other situations in the context.
The pro-cedure takes into account lexical semantics and the result ofvarious discourse interpretation procedures such as definitedescription i terpretation, and does not require a completedisambiguation to take place.THE PROBLEMBecause new ways of obtaining semantically distinct inter-pretations for sentences are continuously discovered, com-ing to grips with ambiguity is becoming more and moreof a necessity for developers of natural anguage process-ing systems, linguists and psychologists alike \[9, 31, 7, 2\].In this paper, I am concerned with the scopal ambiguity ofoperators I \[31, 33\].The attention of both psycholinguists and computationallinguists interested in ambiguity has concentrated on theproblem of combinatorial explosion.
If the number of read-ings of an utterance were to actually grow with the factorialof the number of operators, even a simple sentence like (1),with 4 operators (the modal 'should', tense, an indefinite anda definite), would have 4I = 24 scopally different readings.Two distinct questions thus must be answered: how can lis-teners (and how should machines) deal with the combinato-rial explosion of readings?
Do we really use the brute-forcestrategy of considering all of the available readings, and thenchoose among them?
And, if we do choose among severalreadings, how is that done?
(1) We should hook up an engine to the boxcar.To my knowledge, three positions on the problem of com-binatorial explosion have been taken in the literature.
Somehave argued that there is no problem: our brains contain1I use here the term operator as it is used by Heim \[13\], i.e., tomean either quantifier or modal/tense operator.78more than enough machinery to process in parallel 4I in-terpretations.
It's unclear, however, whether this strategyis feasible when larger numbers of readings are concerned.A classical demonstration f the number of readings onemay have to consider is (2), which has 1 l I interpretationsif the standard treatment of quantification and modality isassumed.
(2) You can fool most people on most of the issues mostof the time, but you can't fool everybody on every singleissue all of the time.
\[15\]Another position is that sentences like (1) are not semanti-cally ambiguous, but vague.
Consider for example (3):(3) Every kid climbed a tree.Here, one of the readings (the one in which the indefinitetakes narrow scope) is entailed by the other (in which theindefinite takes wide scope).
The claim is that (3) is inter-preted in the vaguest possible way, and the strongest reading,if at all, is derived by pragmatic 'strengthening' \[25\].
A dif-ficulty with this approach is that a vaguest reading doesn'talways exist.
The two readings of (4), for example, are dis-tinct.
(4) Few people speak many languages.
\[27\]Finally, it has been proposed that the reason why listenersdo not seem to have problems in processing utterances like(1) is because they do not disambiguate.
They build a non-disambiguated representation f the sentence and leave theinterpretation pen.
This strategy might be advantageousfor some kinds of applications 2 and it has been argued thata complete disambiguation never takes place \[7\].No matter what processing strategy is chosen, the ques-tion of how listeners choose one particular interpretationcannot be ignored.
All experimental work done on the sub-ject of scopal ambiguity \[20, 35, 26\] indicates that subjectsdo have preferred interpretations when confronted with taskswhich require understanding.
In addition, sentences like (1),(5) and (6) clearly have preferred interpretations.
However,the only answers to to this question that I have seen are basedon heuristics)2E.g., machine translation \[2\].3See \[17\] for an example of state-of-the-art techniques(5) A girl took every chemistry course.
\[20\](6) Each daughter of an admiral married a captain.I present in this paper an hypothesis about interpretation thataccounts for facts about scope disambiguation that were pre-viously explained in the literature by stipulating a number ofunmotivated principles.
The proposal developed here is be-ing applied to develop the module of the TRAINS-93 system\[1\] that handles cope disambiguation a d reference inter-pretation.
The goal of the TRAINS project is to develop aconversationally proficient planning assistant.
More detailsabout he project and the work presented here can be foundin \[29\].SCOPE D ISAMBIGUATION FACTORSMost proposals on scope disambiguation were developed toaccount for the general preference of the leftmost quantifiedphrase from taking wide scope in simple active sentenceslike (7):(7) Every kid climbed a tree.Lakoff \[27\] proposed that this preference is due to the factthat sentences are parsed from left to right; "every kid" takesscope over "a tree" because it is processed first.
(Kurtzmanand MacDonald called this the Left to Right principle.
)Ioup \[20\] argued instead that "...in natural language, or-der has little to do with the determination of quantifierscope."
(\[20\], p.37).
The preferred reading of (8), for ex-ample, is the one in which the NP "each child" takes widescope.
(8) I saw a picture of each child.
\[20\]According to Ioup, the relative scope of quantifiers i deter-mined by the interaction of two factors.
First of all, quan-tifiers such as "each" or "the" have the inherent property oftaking wide scope over indefinites, which, in turn are lexi-cally marked to take scope over plural quantifiers like "all.
"This hypothesis motivated by contrasts uch as those in(9), and accounts for cases such as (8).
4(9) a. I saw a picture of each child.b.
I saw a picture of all the children.Secondly, Ioup proposed that a hierarchy exists amonggrammatical functions, such that listeners tend to attributeto NPs in subject position wide scope over NPs in indirectobject position, which in turn tend to take wide scope overNPs in object position.
The hierarchy between grammaticalfunctions accounts for the preferred reading of (7).Ioup also observed that NPs in topic position tend to takewide scope, This is especially obvious in languages thathave a specific grammatical category for topic, like Japaneseor Korean.
The Japanese sentence (10b) is ambiguous, butthe reading in which the NP in subject position, "most stu-dents" takes scope over the NP in object position, "everylanguage," is preferred.
This preference is maintained if the')Van Lehn \[35\] and Hendrix \[14\] also studied the effect oflexical preferences, or'strengths' as they are also called.79NP in object position is scrambled in sentence-initial posi-tion, as in (10c) (another counterexample to Lakoff's left-to-right principle).
If, however, the NP is marked with thetopic-marking suffix "wa," as in (10d), suddenly the pre-ferred reading of the sentence becomes the one in which"every language" takes wide scope.
5(I0) a.
Most students speak every language.b.
Hotondo-no gakusei-ga subete-no gengo-o hanasumost-gen student-nora every language-ace speakc.
Subete-no gengo-o hotondo-no gakusei-ga hanasuevery language-ace most-gen student-nora speakd.
Subete-no gengo-wa hotondo-no gakusei-ga hanasuevery language-TOP most-gen student-nora speakSeveral proposals attribute an important role to structuralfactors in assigning a scope to operators.
Jackendoff \[21\]and Reinhart (\[32\], ch.
3 and 9) propose to account for thepreferred reading of (7) by means ofa C-commandprincipleaccording to which a quantified expression is allowed to takescope over another quantified expression only if the latter isc-commanded bythe former at surface structure.Structural explanations (in the form of constraints on syn-tactic movement) have also been proposed to explain theconstraint that prevents a quantifier to take scope outsidethe clause in which it appears, first observed by May \[28\]and called Scope Constraint by Heim \[13\].
This constraintis exemplified by the contrast in (11): whereas (lla) hasa reading in which "every department" is allowed to takewide scope over "a student," this reading is not available for(llb).
(11) a.
A student from every department was at the party.b.
A student who was from every department was at theparty.Lexical semantics and commonsense knowledge also playan important role in detemaining the scope of operators.
Thecontrast between the preferred readings of (12a) and (12b)can only be explained in terms of lexical semantics:(12) a.
A workstation serves many users.b.
A workstation can be found in many offices.Kurtzman and MacDonald \[26\] set out to verify the empiri-cal validity of several of these principles.
The most crucialresult is that none of the principles they set to verify canaccount for all the observed effects, and actually counterex-amples to all of thenv--including the quantifier hierarchy--can be found.
No evidence for a Left-to-Right processingprinciple was found.
Kurtzman and MacDonald hypothesizethat "...processes that are not strictly dedicated to the inter-pretation of scope relations may nonetheless influence theinterpretation f quantifier scope ambiguities."
(\[26\], p.22).They conclude that "...the results leave open the questionof whether the building and selection of representations ofscope are mandatory processes" (\[26\], p.45).
65Arguably, the closest thing to an explicit opic marker in En-glish are certain uses of definite descriptions and the topicalizationconstruction; i  both cases, the topically marked NP tends to takewide scope.6Their experiments are discussed inmore detail in \[29\].OVERVIEW OF THE PROPOSALScope Disambiguation as Construction of an EventStructureIt is commonly assumed in the psycholinguistic literatureon sentence interpretation that hearers interpret sentencesby constructing a model of the situation described by thesentence \[10, 22\].
I propose that the scope assigned to theoperators contained in a sentence is determined by the char-acteristics of the model construction procedure.
The modelbeing constructed, which I call event structure, consists of aset of situation descriptions, one for each operator, togetherwith dependency relations between them.
The task of themodel construction procedure is to identify these situationsand to establish dependency relations.
The scope assignedby a hearer to an operator depends on the position of thesituation associated with that operator in the event structure.For example, I propose that the scope assigned to quanti-tiers depends on how their resource situation \[3, 8\] is iden-tiffed.
It is well-known that a sentence like (13):(13) Everybody is asleep.is not interpreted as meaning that every single human be-ing is asleep, but only that a certain contextually relevantsubset is.
The process of identifying the set of individualsover which an operator quantifies is usually called domainrestriction.
In the case of, say, (7) whether "every kid" or"atree" takes wide scope depends on how the listener builds amodel of the sentence.
If she starts by first identifying a situ-ation containing the group of kids that"every" is quantifyingover, and then proceeds to 'build' for each of these kids asituation which contains atree the kid is climbing, then "ev-ery kid" will take wide scope.
In other words, I propose thata listener has a preferred reading for a sentence if she's ableto identify the resource situation of one or more of the oper-ators in that sentence ('to picture some objects in her mind'),and to hypothesize dependency relations between these sit-uations.
If this process cannot ake place, the sentence isperceived as 'ambiguous' or 'hard to understand.
'The less context is available, the more the establishmentof dependency relations between situations depends on theorder in which the model is built, i.e., on the order in whichthe situations associated with the different operators andevents are identified.
This order depends in part on whichNPs are perceived to be 'in topic,' and in part on gen-eral principles for building the conceptual representation fevents (see below).
In addition, some operators (e.g., defi-nite descriptions) impose constraints on their resource situ-ation.A Model  Construct ion Procedure: The DRTAlgor i thmIn order to make the intuition more concrete we need thedetails of the model construction procedure.
Ideally, onewould want to adopt an existing procedure and show thatthe desired results fall out automatically.
Unfortunately, themodel construction procedures presented in the psycholin-guistic literature are not very detailed; often it's not evenclear what these researchers intend as a model.
There is,80however, adiscourse interpretation procedure that is speci-fied in detail and has some oftbe characteristics of the modelconstruction procedure I have in mind; I 'm thinking of theDRS construction algorithm \[23, 24\].The DRS construction algorithm consists of a set of rulesthat map discourses belonging to the language into certain"interpretive structures".
The output structures are called"Discourse Representation Structures" or "DRSs."
A DRSis a pair consisting of a set of discourse referents and a setof conditions (= predicates on the discourse referents).
Theconstruction algorithm works by first adding the syntacticstructure of the sentence to the 'root' DRS representing thediscourse up to that point, then applying the rules to the syn-tactic structure, thus adding discourse referents and condi-tions to the DRS.
Consider how the algorithm is applied toobtain an interpretation for (7):(14) Every kid climbed the tree.The initial interpretation f (14) is the tree shown in (15).
(15) SNP VPDet N' V NPDetA Every kid climbed a treeThe DRS construction role for definites and universal quan-tification are as follows:(Definite Descriptions)When a syntactic configurationcontaining a definite NP is met in a DRS K,1.
Add a new discourse referent x to the root DRS,2.
Add a new condition to the root DRS representing therestriction on the indefinite NP,3.
Replace the NP with x in the syntactic onfiguration.
(Universal Quantification) When a syntactic configura-tion containing an NP with determiner "every" is met in aDRS K,1.
Add a complex condition KI ~ 1(2 to K,2.
Add a new discourse referent x to K~,3.
Add a new condition to K1 representing the restrictionon the indefinite NP,4.
Replace the NP with the discourse referent in the syn-tactic configuration,5.
Move the syntactic configuration i sider K2.Both the rule for definites and the rule for universal quantifi-cation are triggered by (15).
Two hypotheses are obtained;that obtained by applying first the rule for definite descrip-tions is shown in (16).
Both of these hypothesis contain op-erators whose DRS construction roles haven't been appliedyet: this algorittun comes with a built-in notion of partialhypothesis--a paltial hypothesis a DRS some of whoseoperators till have to 'interpreted' in the sense just men-tioned.
(16)xTREE(X)SNP VPDet N' V xEvery kid climbedThe two partial hypotheses are made into complete hypothe-ses by applying the remaining rules; the complete hypothesiswith the definite taking wide scope is shown in (17).
(17)xTREE(X)YID(y) \[ ever~y>CLIMBED(y, X)Modifying the DRS Construct ion Algor i thmBecause the DRS construction rules depend on syntactic pat-terns, the role of structural factors in disambiguatiou can betaken into account--and a lot of data about disambiguationpreferences can be explained without any further machin-ery.
The Scope Constraint, for example, is embedded inthe very semantics of DRT; and one can 'build in' the con-struction rules principles uch as the c-command principle.
(Kamp and Reyle do just that in \[24\].)
The limitations ofthis approach are shown by examples in which the choiceof an interpretation does not depend on the structure, like(12).
Also, the rule for definites as just formulated is too re-strictive: in cases like (18), for example, predicts the correctreading for the definite NP''the meeting," but the wrong onefor "the principal," that, intuitively, takes narrow scope withrespect to "every school:"(18) Every school sent the principal to the meeting.I propose that the role of lexical semantics, as well as thedata accounted for in the literature by introducing principlessuch as the grammatical function hierarchy, the topic prin-ciple, and the quantifier hierarchy, can be accounted for bymaking the activation of the DRS construction rules dependon factors other than the syntactic structure of the sentence.The factors I propose to incorporate are (i) the semantics oflexical items, (ii) the results of the interpretation f opera-tors in context, and (iii) the way the representation f eventsis built in memory.In order to achieve this goal, I propose two main modi-fications to the standard DRS construction algorithm.
Firstof all, I propose that the input to the algorithm is a logi-calform--a structure isomorphic to the s-structure, that car-ties however information about he semantic interpretationof lexical items.
In this way, the role of semantic factorsin interpretation can be taken into account; in addition, asemantic value can be assigned to a representation contain-ing unresolved conditions or partial hypotheses.
Secondly,I propose to make the application of the DRS constructionrules depend on the identification fcertain contextually de-pendent elements of the interpretation.
The ingredients ofthe account thus include: a proposal about he input to themodel construction procedure; a notion of what an eventstructure is; and an account of discourse interpretation.
Idiscuss these issues in turn in the next sections.THE LOGICAL  FORMAs said above, the first difference between the interpretationprocedure proposed here and the DRS construction algorithmillustrated above is that he rules I propose rely on semanticaland contextual factors.
I propose to do this by adding tostandard DRT a new class of conditions, that I call 'logicalforms.'
Logical forms include semantic information aboutthe lexical items occurring in the sentence.
The logical formrepresentation is the interface between the parser and themodel construction algorithm, and can be compositionallyobtained by a GPSG parser \[11, 18\] that couples a context-free grammar with rules of semantic interpretation.
I firstdescribe the language used to characterize the semantics oflexical items, SEL (for Simple Episodic Logic), then thesyntax and interpretation f logical forms.81Lexical Semantics in Simple Episodic LogicI introduce SEL by presenting the truth conditions I proposeto assign to (18), repeated here for convenience:(18) Every school sent he principal to the meeting.The truth conditions usually assigned to (18) in a languagewith restricted quantification, and ignoring tense, are shownin (19); I propose instead to assign to (18) the interpretationspecified by (20).
(19) (the m MEETING(m)(V S SCHOOL(S)(the p PRINCIPAL(p,s)\]sE~rr(s,pan))))(20) (the m \[s'l ~= MEL~NG(m)\] ^sHARl~(spkr,hearerW0(V S \[S'2 ~ SCHOOL(s)\](too p IS3 ~ pP.n~cw~(p,s)\]^ SHARED(spkr,hearer ,.
?3)SENT(s,p,m))))(20) reads: there xists a unique m that is a meeting in a con-textually specified resource situation s'l, and for all s's thatare schools in a contextually specified resource situation ~2the unique p such that p is the principal of s participates tom.The intent of the expression used for the quantifier restric-tions in (20) is to make it explicit hat the situations fromwhich the quantified ements are 'picked up' need not bethe complete set of objects and relations at which the truth of(20) is evaluated.
This is accomplished by introducing intothe language an explicit relation ~ ('supports') torepresent'truth at a situation' \[8\].
A statement of the formIs1 MEWrING(X)\]evaluates to true in a situation s if the object--say, m- -assigned to the variable x is a meeting in the situation s1.A situation is a set of objects and facts about hese objects\[8, 18\].
I assume a language which allows us to make state-ments about situations, and an ontology in which situationsare objects in the universe.
Episodic Logic provides uch alanguage and such an ontology \[19, 18\]; where not otherwisenoted, the reader should assume that an expression of SELhas the semantics of the identical expression in EpisodicLogic.The restriction of the existential quantifier in (20) con-tains a parameter ~.
Parameters are used in SEL to trans-late anaphoric expressions of English.
A parameter behavessemantically as an open variable, a value for which has tobe provided by context.
7I have assumed the following translations for the lexicalitems "every," meeting," and "sent" (I have again ignoredtense):"every" -,-+ )~ P 3.
Q (V x \[s'i ~ P(x)\] Q(x))"meeting" -,-+ MEETING"sent" --~ SENTThe semantics assigned to definite descriptions needs a bitof an explanation.
According to the location theory \[12,4\] the major uses of definite NP's, as well as the contrastbetween definites, indefinites, and demonstratives, can beaccounted for by stipulating that a speaker, when using adefinite article,1.
instructs the hearer to locate the referent in some sharedset of objects, and2.
refers to the totality of the objects/mass within this set thatsatisfy the restriction.I formalize this idea in \[301 by associating to definite de-scriptions the translation below.
A situation is 'shared' be-tween x and y if every fact ?
supported by that situation ismutually believed by x and y (see \[301 for details).
"the meeting" -,~ )~ P (the x: (\[S ~ MEETING(X)\] ASHARED (spkr,hearer,S)) P(x))Syntax and Interpretat ion  o f  the Logical FormThe translations een above, together with the obviouscontext-free roles, result in the following LF for (18) (I have7See \[29\] for details.
The idea is to add to the parameters ofevaluation an anchoring function a that provides the values forparameters, thus plays the role of 'context' inHelm's proposal.
Thereader should be aware that while the notation and terminology Ihave adopted isborrowed from Situation Theory, parameters havea different semantic interpretation there \[8\].82used here, and elsewhere in the paper, a linear notation tosave space):(21) \[CP\[IP \[NP '~, Q (V s \[s'2 ~ SCHOOL(s)\] Q(s))\]\[vP \[vP \[v' SENT\[NP 'Z Q (the p \[s'3 ~ PRINCIPAI~,~)\]^ SHARED(spkr,hearer $3)Q(P))\]\]\]\[pp 'TO\[NP 'Z Q (the m \[s'l ~ MEmOs(m)\]^ SHARED(spkr,hearer ,,q 0Q(m))llll\]I propose that expressions like (21) can appear as conditionsof DRSs.
The syntax of LFs is as follows.
Each internalnode of (21) is labeled with a phrase category; the leavesare labeled with expressions of the form 'a, where a is anexpression of SEL (and has therefore a 'standard' model the-oretic denotation).
I use the phrase structure system largelyadopted in the Government and Binding literature, accord-ing to which the sentence isthe maximal projection of an Inflnode and is therefore labeled IP \[34\].
I also assume the exis-tence of a maximal projection of complementizer CP aboveIP.
Because I don't discuss relatives here, I use the followingsimplified notation for NPs with determiners, such as "everyschool":\[NP '~- Q (V x \[Sl ~ SCHOOL(x)\] Q(x))\]LFs like (21) are usually treated in the natural anguageprocessing literature as uninterpreted data structures fromwhich to 'extract' the readings \[16, 17\].
However, it hasbeen recently proposed \[31, 2, 33\] that it is possible (andindeed desirable) to assign a denotation to expressions like(21).
The reason is that in this way one can define a no-tion of sound inference --that is, one can specify what canand cannot properly be inferred from an expression like (21)prior to disambiguation; and therefore, a notion of 'mono-tone disambiguation.'
I do not assume disambiguation towork monotonically, but I want to be able to treat expres-sions like (21) as full-fledged conditions o that a DRS con-taining a condition of this kind can be interpreted, and I needto be able to characterize a disambiguation step as compati-ble in the sense that it does not introduce any new readings.To do this I need LFs to have an interpretation.Were it not for the problem that more than one interpre-tation can be associated to a single LF, one could easily de-fine a recursive mapping EXT from logical forms to truth-theoretical denotations (functions from situations to lluthvalues) in temxs of the usual \[\[ \[\[ function, as follows:= I la l lEXT(\[ v,  a\]) = EXT(a)EXT(\[vp a\]) = EXT(a)EXT(\[ N, a\]) = EXT(a)EXT(tNP a 131) = EXT(a)(EXT(~))EXT(tIP a \]~l) = EXT(a)(EXT(~))if TYPE(EXT(a)) = (t~,t~)and TYPE(EXT(fl)) = tl;EXT(/~)(EXT(a)) otherwise.Once this is done, one can reformulate the semantics ofDRS in terms of situations and situations extensions insteadof embeddings and embedding extensions, and interpret alconditions as functions from situations to truth values.
(See\[29\] for details.
)Matters get more complicated when expressions withmore than one reading like (21) are considered.
Differentways for assigning a denotation to expressions with morethan one interpretation have been proposed \[2, 31\]; my pro-posal derives from \[31\].
I use a Cooper storage mechanism\[5\] to define EXT in such a way as to allow for an LF to havemore than one 'indirect interpretation.'
Briefly, Cooper'sidea is to have a syntactic tree denote a set of sequences,each sequence representing a distinct 'order of application'in computing the interpretation f the sentence.
For exam-ple, because in interpreting (22) one can either apply thetranslation of tense immediately or walt, EXT maps (22) ina set of two sequences, hown in (23).
(22) \[V" 'P \[NP '~.
Q (det x R(x)) Q(x)\] \]EXT((22)) = {(~ x (det x R(x))P(x) ),(23) (P,)~ Q (det x R(x)) Q(x) )}I omit here the definition of the EXT function implement-ing Cooper storage, that is rather complex.
For the currentpurposes, it is enough to understand that EXT associates to(21) a set of functions from situations to truth values, as in(24).
(24) EXT((21)) ={the function denoted byII (the m \[s'~ p ~L~tNG(m)\] ^ SnARED(spkr,hearer,g0(V S \[~"2 \[= SCHOOL(s)\](the p \[g3 ~ PRINCIPAL(p,s)\]^ SHARED(spkr,hearer ,g3)s~,rr(s,p,x)))) II,the funct ion denoted byII (v s \[~2 h scnooL~s)\](the m \[~?x ~MEElqNG(m)\] ^SI/ARED(spkr,hearer,~l)(the p \[~3 P PRn~Cn'AL(p,s)\]^ SrlARED(spkr,hearer ,g3)s~cr(s,p,x)))) II, et~ }Having done this, we can say that a DRS condition like (21)is verifies the current situation s if one of the functions de-noted by (21) maps s into 1.BUILDING EVENT STRUCTURESNot all assertions in a narrative or conversation are goingto be about he same situation.
In the conversations withthe TRAINS system, for example, the participants can dis-cuss both the state of the world and the state of the planbeing developed.
Maintaining this separation is crucial forthe proper interpretation f definite descriptions, for exam-ple.
The separation between the situations that are the topicof different sentences is achieved by translating sentences asituation descriptions.
A situation description is a conditionof the form:\[-""--'3s : l~ \[ (25)i -- I83whose intuitive interpretation is that ?
provides a partialcharacterization f the situation s. The semantics of situa-tion descriptions i defined as follows, using a semantics ofDRSs in terms of situation extensions, as discussed in theprevious ection, and interpreting discourse markers as con-stituents of situations:The condition s:K is satisfied wrt the situation s' i f fKis satisfied wrt the value assigned to s in s '.I also propose the following constraint on the model con-struction rules:Constraint on Interpretation : with the exception of thediscourse markers interpreted over situations and of thesituation descriptions, every discourse marker and condi-tion has to be part of a situation descriptions.Situation descriptions are added to the model by rules trig-gered by an LF whose root is a CP node.
The rules (nowshown for lack of space) delete the complementizer and itswhole projection, and introduce a situation structure.
Theresult is shown in (26).S(26) s: /~The conslraint on discourse interpretation proposed above isimplemented by forcing the rules that build situation struc-tures to be triggered before any other rule; this is done byhaving every other ule being triggered by LFs whose rootnode is an IP.
The result of this constraint is that a discoursemodel consists of a set of situation descriptions:(27) s :~-~The DRSs produced by the standard DRT algorithm are se-mantically equivalent to the special case of a set of situationdescriptions all describing the same situation s.Models like the one in (27) enable the formalization ofprocesses of resource situation identification like that de-scribed in \[30\].
I illustrate how my rules for interpretingoperators differ from those of standard DRT, and how the in-teraction between model construction rules and discourse in-terpretation works, by means of the model construction rulefor definites.
The rule MCR-DD is triggered by the config-uration in (28), and results in the configuration i (29).
Thenotation used for the pattern indicates that this mle appliesto a definite NP in any position within a syntactic tree whosemaximal projection is an IP node, without any interveningIP node.
(28IPXX '~.
Q (the y \[3 I= P(y)\] Q(y)) YYANCHOR(% S')(29) s:!ys': P(y)IPXX y YYANCHOR(% S')The key observation is that the application of this rule, aswell as of any other NP rule, depends on the hearer's pre-vious identification of a resource situation for the definitedescription.
The statement ANCHOR('~, s ' )  constraining theinterpretation f & is added to the situation structure by theprocesses that identify the referent of the definite descrip-tion; I describe these processes in detail in \[30\].
8Finally, I propose that, when context is missing, a defaultmodel construction procedure operates.
It has been sug-gested \[6\] that the conceptualization f events follows anorder eflected in the thematic hierarchy AGENT < LOCA-TION, SOURCE, GOAL < THEME proposed to account forphenomena like passivization \[21\].
Briefly, the idea is that'the normal procedure for building an event description' isto follow the order in the hierarchy: first identify the agent,then the location, then the theme.
This proposal can be for-malized in the current framework by having rules that oper-ate in case no other ule has, and that modify the model byintroducing a resource situation for an operator and estab-lishing anchoring connections.
These rules depend both onthe semantics of the verb and on the syntactic configuration.The rule that identifies the AGENT, for example, istriggeredby the configuration i (30), and results in the configurationin (31), that allows for the rule for the NP to operate in thatthe resource situation of the operator has been anchored:8A more conventional situation-theoretic framework is usedthere, but the analysis carries over to the framework in this paper.84(30)IPNP VPwv YP'3.
P (det x \[~ ~ (2\] "3. x3.
y v(x)(y)P(x)) ^ AGENT(x)(31IPNP VPV YPA'X P (det x \[t ~ Q\] '3.
x3.
y P(x)(y)P(x)) ^ AGENT(x)ANCHOR(%~, S')These roles can of course originate conflicts with the re-suits of other discourse interpretation processes.
I assumethe following conflict resolution rule: when two rules pro-duce conflicting hypothesis, assume the result of the morespecific rule.
In general, the discourse interpretation rulesare more specific than the default rules for constructingevents representations, so they will be preferred.Although lack of space prevents me from giving exam-pies, rules relating the construction of the model to lexicalsemantics, uch as those accounting for data like (12), canalso be formulated.AN EXAMPLEWe can now discuss in more detail the process of disam-biguation of (18).
I have presented the logical form for (18)above, as (21).
(18) Every school sent the principal to the meeting.After identifying the situation descriptions, various interpre-tation processes take place, like those performing definitedescription i terpretation described in \[30\].
These processesgenerate hypotheses about he anchoring of resource situa-tions.
Without entering into details, I assume that the con-text for (18) is provided by (32), that introduces into themodel the situation description i  (33), containing a groupof schools and a meeting.
(32) There was a meeting of the schools in the district.sx S(33) MEETING(X)S: SCHOOL* (S)PARTICIPATE(S, X)Given this context, the discourse interpretation processesidentify sas the resource situation for the NPs "every school"and "the meeting."
However, no unique principal can beidentified in s. The activation of the model constructionrules for universal quantification and definite descriptionsresults in the partial model in (34), in which ~1 and s'2 havebeen identified:(34)$ $1$1:i: ~_emaNG(,v)ANCHOR(y, X)$2s2: ~:z E Ss2 _C THIS_SITUATIONS3IPNP VPs3: VP PP'SENT "the principal" 'TO yS 2 E S 3Th, model construction role applied to the universal "ev-ery school" introduces a complex condition K1 ---> I(2 asusual, but both the restriction and the nuclear scope includesituation descriptions.
The situation description in the re-striction, s2, is a subsituation of the situation at which therestriction is evaluated (denoted by the indexical constantTHIS_SITUATION).
The situation description in the nu-clear scope, s3, is an extension of s2.85Now that a situation description for the resource situationof the universal and a discourse marker for the school havebeen introduced (s2 and z, respectively), the roles for resolv-ing the parametric component Jc of the interpretation f"theprincipal" can apply.
The result is that z is chosen as an-tecedent of ?, and s2 is chosen as the resource situation for"the principal."
The model construction role updates 3 ac-cordingly; the resulting event structure is equivalent to theinterpretation f (21) specified by (20).ACCOUNTING FOR THED ISAMBIGUATION DATAI briefly retum here the disambiguation principles, to showhow the proposal just presented accounts for them.
First ofall, I'll note that, under simple assumptions about he map-ping between grammatical functions and theta-roles, thereis a striking resemblance between the grammatical functionhierarchy proposed by Ioup and the thematic hierarchy pro-posed by Jackendoff to account for facts about passives andreflexives.
The facts accounted for by the grammatical func-tion hierarchy principle can also be explained if we assurmthat the description of an event is constructed by identify-ing the filler of each thematic role in the order specified byJackendoff's thematic hierarchy.Consider now the case of the other disambiguation fac-tor proposed by Ioup, the lexically encoded preference forcertain operators to take wide scope.
Definite descriptionsare the paradigmatic case of an operator that tends to takewide scope.
This preference can be explained in terms ofthe model construction hypothesis as follows.
The choiceof a resource situation for definite descriptions i restrictedby the constraint that this resource situation be either sharedamong the conversational participants, or related to sharedknowledge by shared relations \[12, 4\].
In our dialogues, forexample, definite descriptions are usually interpreted withrespect to the 'situation' corresponding to the current visualscene, which is independent from other situations.
It followsthat a definite description will be assigned narrow scope rel-ative to another operator only if (i) the resource situationof the definite is perceived to depend on this other esourcesituation, and (ii) this dependency relation is known to beshared.As for the tendency for NPs in topic to take wide scope,an element of a sentence is said to be in topic if it is consid-ered to be part of the background information on which thenew information i  the sentence depends.
As the interpre-tation of the 'new' infonnation in the sentence depends onthe background information, it is plausible to assume that,in constructing a model for the sentence, the listener beginsby applying the model construction roles for the operatorsperceived to be in topic (or explicitly marked as being intopic, in the case of Japanese).
The interpretation f theoperators not in topic, when determined at all, will dependon the interpretation f the operators in topic, resulting inthe dependency relations between the related situations thatI have assumed to be the way scope is represented.Finally, I'll note that, in the absence of contextual c ues,whether acompletely disambiguated vent structure is actu-ally constructed depends on how strong the model construc-tion roles are supposed to be; it's perfectly possible that theactivation of these rules is controlled by additional factors,such as the specific needs of a task to be performed.ACKNOWLEDGMENTSI wish to thank my advisor Len Schubert and James Allen,Howard Kurtzman, Peter Lasersohn, and Uwe Reyle for sev-eral suggestions, technical help, and constructive criticism.This work was supported by the US Air Force - Rome Lab-oratory Research Contract no.
F30602-91-C-0010.References\[1\] J.F.
Allen andL.K.
Schubert.
The TRAINS project.
TRAINSTechnical Note 91-1, University of Rochester, Department ofComputer Science, 1991.\[2\] H. Alshawi and R. Crouch.
Monotonic semantic interpre-tation.
In Proc.
30th.
ACL, pages 32-39, University ofDelaware, 1992.\[3\] J. Barwise and J. Perry.
Situations and Attitudes.
The M1TPress, 1983.\[4\] H. H. Clark and C. R. Marshall.
Definite reference and mu-tual knowledge.
In Elements of Discourse Understanding.Cambridge University Press, 1981.\[5\] Robin Cooper.
Quantification a d Syntactic Theory.
D. Rei-del, 1983.\[6\] W. Croft.
Syntactic Categories and Grammatical Relations:The cognitive organization of information.
University ofChicago Press, 1991.\[7\] Kees van Deemter.
On the Composition of Meaning.
PhDthesis, University of Amsterdam, 1991.\[8\] K. Devlin.
Logic and Information.
Cambridge UniversityPress, 1991.\[9\] J.E.
Fenstad, P.K.
Halvorsen, T. Langholm, and J. van Ben-them.
Situations, Language andLogic.
D.Reidel, 1987.\[10\] A. Garnham.
On-line construction of representations of thecontent of texts.
Reproduced by Indiana University Linguis-tics Club, 1982.\[11\] G. Gazdar, E. Klein, G. Pullum, and I.
Sag.
GeneralizedPhrase Structure Grammar.
Blackwell, 1985.\[12\] J.A.
Hawkins.
Definiteness and lndefiniteness.
Croom Helm,1978.\[13\] I. Heim.
The Semantics of Definite and Indefinite NounPhrases.
PhD thesis, University of Massachusetts at Amherst,1982.\[14\] G.G.
Hendrix.
Semantic aspects of translation.
In D. Walker,editor, Understanding Spoken Language, pages 193-226.
El-sevier, 1978.\[15\] J. Hobbs.
An improper t eatment ofquantification i  ordinaryEnglish.
In Proc.
ACL-83, pages 57-63, Cambridge, MA,June 1983.\[16\] J. R. Hobbs and S. M. Shieber.
An algorithm for generatingquantifier scopings.
ComputationaILinguistics, 13(1-2):47-63, January-June 1987.\[17\] Sven Hurum.
Handling scope ambiguities using domain-independent heuristics.
Technical Report TR 88-12, Univer-sity of Alberta, June 1988.86\[18\] C. H. Hwang.
A Logical Approach to Narrative Understand-ing.
PhD thesis, University of Alberta, 1992.\[19\] C. H. Hwang and L. K. Schubert.
Episodic logic: A situ-ational ogic for natural anguage processing.
In P. Aezel,D.
Israel, Y. Katagiri, and S. Peters, editors, Situation Theoryand its Applications, v.3.
CSLI, 1993.
To appear.\[20\] Georgette Ioup.
Some universals for quantifier scope.
InJ.
Kimball, editor, SyntaxandSemantics4, pages 37-58.
Aca-demic Press, New York, 1975.\[21\] R. Jaekendoff.
Semantic Interpretation i  Generative Gram-mar.
MIT Press, 1972.\[22\] E Johnson-Laird.
Mental Models.
Harvard University Press,1983.\[23\] H. Kamp.
A theory of truth and semantic representation.In J. Groenendijk, T. Janssen, and M. Stokhof, editors, For-mal Methods in the Study of Language.
Mathematical Centre,Amsterdam, 1981.\[24\] H. Kamp and U. Reyle.
From discourse to logic.
To appear.,1993.\[25\] R. Kempson and A. Cormack.
Ambiguity and quantification.Linguistics and Philosophy, 4(2):259-310, 1981.\[26\] H. S. Kurtzman and M. C. MacDonald.
Resolution of quan-tifier scope ambiguities.
To appear., April 1992.\[27\] G. Lakoff.
Semantic interpretation in generative grammar.
InD.
A. Steinberg and L. A. Jakobovits, editors, Semantics: Aninterdisciplinary reader in philosophy, linguistics, anthropol-ogy, and psychology.
Cambridge University Press, 1971.\[28\] R. May.
The Grammar of Quantification.
PhD thesis, M1T,1977.\[29\] M. Poesio.
Assigning a Scope to Operators in Dialogues.PhD thesis, University of Rochester, Department of Com-puter Science, 1993.\[30\] M. Poesio.
A situation-theoretic formalization of definitedescription interpretation i plan elaboration dialogues.
InE Aezel, D. Israel, Y. Katagiri, and S. Peters, editors, Situ-ations Theory and its Applications, voL3, chapter 12, pages343-378.
CSLI, 1993.
To appear.\[31\] Massimo Poesio.
Relational semantics and scope ambigu-ity.
In J. Barwise, J. M. Gawron, G. Plotkin, and S. Tutiya,editors, Situation Semantics and its Applications, voL2, chap-ter 20, pages 469-497.
CSLI, 1991.\[32\] T. Reinhart.
Anaphora nd semantic interpretation.
CroomHelm, 1983.\[33\] U. Reyle.
Dealing with ambiguities by underspecification:Construction, representation a d deduction.
Journal of Se-mantics, 3, 1993.\[34\] T. Stowell.
Origins of Phrase Structure.
PhD thesis, M1T,1981.\[35\] Kurt A. VanLehn.
Determining the scope of English quan-tifiers.
Technical Report AI-TR-483, Artificial IntelligenceLaboratory, MIT, Cambridge, MA, 1978.
