Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 407?412,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsDomain Adaptation for Machine Translation by Mining Unseen WordsHal Daume?
IIIUniversity of MarylandCollge Park, USAhal@umiacs.umd.eduJagadeesh JagarlamudiUniversity of MarylandCollege Park, USAjags@umiacs.umd.eduAbstractWe show that unseen words account for alarge part of the translation error when mov-ing to new domains.
Using an extension ofa recent approach to mining translations fromcomparable corpora (Haghighi et al, 2008),we are able to find translations for otherwiseOOV terms.
We show several approachesto integrating such translations into a phrase-based translation system, yielding consistentimprovements in translations quality (between0.5 and 1.5 Bleu points) on four domains andtwo language pairs.1 IntroductionLarge amounts of data are currently available totrain statistical machine translation systems.
Un-fortunately, these training data are often qualita-tively different from the target task of the transla-tion system.
In this paper, we consider one specificaspect of domain divergence (Jiang, 2008; Blitzerand Daume?
III, 2010): the out-of-vocabulary prob-lem.
By considering four different target domains(news, medical, movie subtitles, technical documen-tation) in two source languages (German, French),we: (1) Ascertain the degree to which domain di-vergence causes increases in unseen words, and thedegree to which this degrades translation perfor-mance.
(For instance, if all unknown words arenames, then copying them verbatim may be suffi-cient.)
(2) Extend known methods for mining dic-tionaries from comparable corpora to the domainadaptation setting, by ?bootstrapping?
them basedon known translations from the source domain.
(3)Develop methods for integrating these mined dictio-naries into a phrase-based translation system (Koehnet al, 2007).As we shall see, for most target domains, out ofvocabulary terms are the source of approximatelyhalf of the additional errors made.
The only excep-tion is the news domain, which is sufficiently sim-ilar to parliament proceedings (Europarl) that thereare essentially no new, frequent words in news.
Bymining a dictionary and naively incorporating it intoa translation system, one can only do slightly bet-ter than baseline.
However, with a more clever inte-gration, we can close about half of the gap betweenbaseline (unadapted) performance and an oracle ex-periment.
In most cases this amounts to an improve-ment of about 1.5 Bleu points (Papineni et al, 2002)and 1.5 Meteor points (Banerjee and Lavie, 2005).The specific setting we consider is the one inwhich we have plentiful parallel (?labeled?)
data in asource domain (eg., parliament) and plentiful com-parable (?unlabeled?)
data in a target domain (eg.,medical).
We can use the unlabeled data in the tar-get domain to build a good language model.
Finally,we assume access to a very small amount of parallel(?labeled?)
target data, but only enough to evaluateon, or run weight tuning (Och, 2003).
All knowl-edge about unseen words must come from the com-parable data.2 Background and ChallengesDomain adaptation is a well-studied field, both in theNLP community as well as the machine learning andstatistics communities.
Unlike in machine learning,in the case of translation, it is not enough to simply407adjust the weights of a learned translation model todo well on a new domain.
As expected, we shallsee that unseen words pose a major challenge foradapting translation systems to distant domains.
Nomachine learning approach to adaptation could hopeto attenuate this problem.There have been a few attempts to measure or per-form domain adaptation in machine translation.
Oneof the first approaches essentially performs test-setrelativization (choosing training samples that lookmost like the test data) to improve translation per-formance, but applies the approach only to verysmall data sets (Hildebrand et al, 2005).
Laterapproaches are mostly based on a data set madeavailable in the 2007 StatMT workshop (Koehn andSchroeder, 2007), and have attempted to use mono-lingual (Civera and Juan, 2007; Bertoldi and Fed-erico, 2009) or comparable (Snover et al, 2008) cor-pus resources.
These papers all show small, but sig-nificant, gains in performance when moving fromParliament domain to News domain.3 DataOur source domain is European Parliamentproceedings (http://www.statmt.org/europarl/).
We use three target domains: theNews Commentary corpus (News) used in the MTShared task at ACL 2007, European MedicinesAgency text (Emea), the Open Subtitles data(Subs) and the PHP technical document data,provided as part of the OPUS corpus http://urd.let.rug.nl/tiedeman/OPUS/).We extracted development and test sets from eachof these corpora, except for news (and the sourcedomain) where we preserved the published dev andtest data.
The ?source?
domain of Europarl has 996ksentences and 2130k words.)
We count the numberof words and sentences in the English side of theparallel data, which is the same for both languagepairs (i.e.
both French-English and German-Englishhave the same English).
The statistics are:Comparable Tune Testsents words sents sentsNews 35k 753k 1057 2007Emea 307k 4220k 1388 4145Subs 30k 237k 1545 2493PHP 6k 81k 1007 2000Dom Most frequent OOV WordsNews(17%)behavior, favor, neighbors, fueled, neigh-boring, abe, wwii, favored, nicolas, fa-vorable, zhao, ahmedinejad, bernanke,favorite, phelps, ccp, skeptical, neighbor,skeptics, skepticismEmea(49%)renal, hepatic, subcutaneous, irbesartan,ribavirin, olanzapine, serum, patienten,dl, eine, sie, pharmacokinetics, riton-avir, hydrochlorothiazide, erythropoietin,efavirenz, hypoglycaemia, epoetin, blis-ter, pharmacokineticSubs(68%)gonna, yeah, f...ing, s..., f..., gotta, uh,wanna, mom, lf, ls, em, b....h, daddy, sia,goddamn, sammy, tyler, bye, bigweldPHP(44%)php, apache, sql, integer, socket, html,filename, postgresql, unix, mysql, color,constants, syntax, sesam, cookie, cgi, nu-meric, pdf, ldap, byteTable 1: For each domain, the percentage of target do-main word tokens that are unseen in the source domain,together with the most frequent English words in the tar-get domains that do not appear in the source domain.
(Inthe actual data the subtitles words do not appear cen-sored.
)All of these data sets actually come with paralleltarget domain data.
To obtain comparable data, weapplied to standard trick of taking the first 50% ofthe English text as English and the last 50% of theGerman text as German.
While such data is moreparallel than, say, Wikipedia, it is far from parallel.To get a better sense of the differences betweenthese domains, we give some simple statistics aboutout of vocabulary words and examples in Table 1.Here, for each domain, we show the percentage ofwords (types) in the target domain that are unseen inthe Parliament data.
As we can see, it is markedlyhigher in Emea, Subs and PHP than in News.4 Dictionary MiningOur dictionary mining approach is based on Canon-ical Correlation Analysis, as used previously by(Haghighi et al, 2008).
Briefly, given a multi-viewdata set, Canonical Correlation Analysis is a tech-nique to find the projection directions in each viewso that the objects when projected along these di-408rections are maximally aligned (Hotelling, 1936).Given any new pair of points, the similarity betweenthe them can be computed by first projecting ontothe lower dimensions space and computing the co-sine similarity between their projections.
In general,using all the eigenvectors is sub optimal and thusretaining top eigenvectors leads to an improved gen-eralizability.Here we describe the use of CCA to find the trans-lations for the OOV German words (Haghighi et al,2008).
From the target domain corpus we extract themost frequent words (approximately 5000) for boththe languages.
Of these, words that have translationin the bilingual dictionary (learnt from Europarl) areused as training data.
We use these words to learnthe CCA projections and then mine the translationsfor the remaining frequent words.
The dictionarymining involves multiple stages.
In the first stage,we extract feature vectors for all the words.
Weuse context and orthographic features.
In the sec-ond stage, using the dictionary probabilities of seenwords, we identify pairs of words whose feature vec-tors are used to learn the CCA projection directions.In the final stage, we project all the words into thesub-space identified by CCA and mine translationsfor the OOV words.
We will describe each of thesesteps in detail in this section.For each of the frequent words we extract the con-text vectors using a window of length five.
To over-come data sparsity issue, we truncate each contextword to its first seven characters.
We discard all thecontext features which co-occur with less than fivewords.
Among the remaining features, we consideronly the most frequent 2000 features in each lan-guage.
We convert the frequency vectors into TFIDFvectors, center the data and then binarize the vec-tors depending on if the feature value is positive ofnot.
We convert this data into word similarities us-ing linear dot product kernel.
We also represent eachword using the orthographic features, with n-gramsof length 1-3 and convert them into TFIDF form andsubsequently turn them into word similarities (againusing the linear kernel).
Since we convert the datainto word similarities, the orthographic features arerelevant even though the script of source and tar-get languages differ.
Where as using the featuresdirectly rending them useless for languages whosescript is completely different like Arabic and En-waste blutdruckabfall 0.274233bleeding blutdruckabfall 0.206440stroke blutdruckabfall 0.190345dysphagia dysphagie 0.233743encephalopathy dysphagie 0.215684lethargy dysphagie 0.203176ribavirin ribavirin 0.314273viraferonpeg ribavirin 0.206194bioavailability verfgbarkeit 0.409260xeristar xeristar 0.325458cymbalta xeristar 0.284616Table 2: Random unseen Emea words in German andtheir mined translations.glish.
For each language we linearly combine thekernel matrices obtained using the context vectorsand the orthographic features.
We use incomletecholesky decomposition to reduce the dimension-ality of the kernel matrices.
We do the same pre-processng for all words, the training words and theOOV words.
And the resulting feature vectors foreach word are used for learning the CCA projectionsSince a word can have multiple translations, andthat CCA uses only one translation, we form a bipar-tite graph with the training words in each languageas nodes and the edge weight being the translationprobability of the word pair.
We then run Hungar-ian algorithm to extract maximum weighted bipar-tite matching (Jonker and Volgenant, 1987).
Wethen run CCA on the resulting pairs of the bipartitematching to get the projection directions in each lan-guage.
We retain only the top 35% of the eigenvec-tors.
In other relevant experiments, we have foundthat this setting of CCA outperforms the baseline ap-proach.We project all the frequent words, including thetraining words, in both the languages into the lowerdimensional spaces and for each of the OOV wordreturn the closest five points from the other languageas potential new translations.
The dictionary min-ing, viewed subjectively and intrinsically, performsquite well.
In Table 2, we show four randomly se-lected unseen German words from Emea (that do notoccur in the Parliament data), together with the topthree translations and associated scores (which arenot normalized).
Based on a cursory evaluation of5 randomly selected words in French and German409by native speakers (not the authors!
), we found that8/10 had correct mined translations.5 Integration into MT SystemThe output of the dicionary mining approach is a listof pairs (f, e) of foreign words and predicted En-glish translations.
Each of these comes with an as-sociated score.
There are two obvious ways to in-tegrate such a dictionary into a phrase-based trans-lation system: (1) Provide the dictionary entries as(weighted) ?sentence?
pairs in the parallel corpus.These ?sentences?
would each contain exactly oneword.
The weighting can be derived from the trans-lation probability from the dictionary mining.
(2)Append the phrase table of a baseline phrase-basedtranslation model trained only on source domaindata with the word pairs.
Use the mining probabilityas the phrase translation probabilities.It turned out in preliminary experiments (on Ger-man/Emea) that neither of these approaches workedparticularly well.
The first approach did not workat all, even with fairly extensive hand-tuning of thesentence weights.
It often hurt translation perfor-mance.
The second approach did not hurt transla-tion performance, but did not help much either.
Itled to an average improvement of only about 0.5Bleu points, on development data.
This is likely be-cause weight tuning tuned a single weight to accountfor the import of the phrase probabilities across both?true?
phrases as well as these ?mined?
phrases.We therefore came up with a slightly more com-plex, but still simple, method for adding the dic-tionary entries to the phrase table.
We add fournew features to the model, and set the plain phrase-translation probabilities for the dictionary entries tozero.
These new features are:1.
The dictionary mining translation probability.
(Zero for original phrase pairs.)2.
An indicator feature that says whether all Ger-man words in this phrase pair were seen inthe source data.
(This will always be true forsource phrases and always be false for dictio-nary entries.)3.
An indicator that says whether all Germanwords in this phrase pair were seen in targetdata.
(This is not the negation of the previousfeature, because there are plenty of words in thetarget data that had also been seen.
This featuremight mean something like ?trust this phrasepair a lot.?)4.
The conjunction of the previous two features.Interestingly, only adding the first feature wasnot helpful (performance remained about 0.5 Bleupoints above baseline).
Adding only the last threefeatures (the indicator features) alone did not help atall (performance was roughly on par with baseline).Only when all four features were included did per-formance improve significantly.
In the results dis-cussed in Section 6.2, we report results on test datausing the combination of these four features.6 ExperimentsIn all of our experiments, we use two trigram lan-guage models.
The first is trained on the Gigawordcorpus.
The second is trained on the English side ofthe target domain corpus.
The two language modelsare traded-off against each other during weight tun-ing.
In all cases we perform parameter tuning withMERT (Och, 2003), and results are averaged overthree runs with different random initializations.6.1 Baselines and OraclesOur first set of experiments is designed to establishbaseline performance for the domains.
In these ex-periments, we built a translation model based onlyon the Parliament proceedings.
We then tune it us-ing the small amount of target-domain tuning dataand test on the corresponding test data.
This is rowBASELINE in Table 3.
Next, we build an oracle,based on using the parallel target domain data.
Thissystem, OR in Table 3 is constructed by traininga system on a mix of Parliament data and target-domain data.
The last line in this table shows thepercent improvement when moving to this oraclesystem.
As we can see, the gains range from tiny(4% relative Bleu points, or 1.2 absolute Bleu pointsfor news, which may just be because we have moredata) to quite significant (73% for medical texts).Finally, we consider how much of this gain wecould possible hope to realize by our dictionary min-ing technique.
In order to estimate this, we takethe OR system, and remove any phrases that con-tain source-language words that appear in neither410BLEU MeteorNews Emea Subs PHP News Emea Subs PHPBASELINE 23.00 26.62 10.26 38.67 34.58 27.69 15.96 24.66German ORACLE-OOV 23.77 33.37 11.20 39.77 34.83 30.99 17.03 25.82ORACLE 24.62 42.77 11.45 41.01 35.46 36.40 17.80 25.85BASELINE 27.30 40.46 16.91 28.12 37.31 35.62 20.61 20.47French ORACLE-OOV 27.92 50.03 19.17 29.48 37.57 39.55 21.79 20.91ORACLE 28.55 59.49 19.81 30.15 38.12 45.55 23.52 21.77ORACLE-OOV CHANGE +2% +24% +11% +5% +0% +12% +6% +7%ORACLE CHANGE +4% +73% +15% +2% +2% +29% +13% +6%Table 3: Baseline and oracle scores.
The last two rows are the change between the baseline and the two types oforacles, averaged over the two languages.German FrenchBLEU Meteor BLEU MeteorNews 23.80 35.53 27.66 37.41+0.80 +0.95 +0.36 +0.10Emea 28.06 29.18 46.17 37.38+1.44 +1.49 +1.51 +1.76Subs 10.39 16.27 17.52 21.11+0.13 +0.31 +0.61 +0.50PHP 38.95 25.53 28.80 20.82+0.28 +0.88 +0.68 +0.35Table 4: Dictionary-mining system results.
The italicizednumber beneath each score is the improvement over theBASELINE approach from Table 3.the Parliament proceedings nor our list of high fre-quency OOV terms.
In other words, if our dictio-nary mining system found as-good translations forthe words in its list as the (cheating) oracle system,this is how well it would do.
This is referred toas OR-OOV in Table 3.
As we can see, the upperbound on performance based only on mining unseenwords is about halfway (absolute) between the base-line and the full Oracle.
Except in news, when itis essentially useless (because the vocabulary differ-ences between news and Parliament proceedings arenegligible).
(Results using Meteor are analogous,but omitted for space.
)6.2 Mining ResultsThe results of the dictionary mining experiment, interms of its effect on translation performance, areshown in Table 4.
As we can see, there is a mod-est improvement in Subtitles and PHP, a markedlylarge improvement in Emea, and a modest improve-ment in News.
Given how tight the ORACLE resultswere to the BASELINE results in Subs and PHP, it isquite impressive that we were able to improve per-formance as much as we did.
In general, acrossall the data sets and both languages, we roughlysplit the difference (in absolute terms) between theBASELINE and ORACLE-OOV systems.7 DiscussionIn this paper we have shown that dictionary miningtechniques can be applied to mine unseen words ina domain adaptation task.
We have seen positive,consistent results across two languages and four do-mains.
The proposed approach is generic enough tobe integrated into a wide variety of translation sys-tems other than simple phrase-based translation.Of course, unseen words are not the only causeof translation divergence between two domains.
Wehave not addressed other issues, such as better es-timation of translation probabilities or words thatchange word sense across domains.
The former isprecisely the area to which one might apply do-main adaptation techniques from the machine learn-ing community.
The latter requires significant ad-ditional work, since it is quite a bit more difficultto spot foreign language words that are used in newsenses, rather that just never seen before.
An alter-native area of work is to extend these results beyondsimply the top-most-frequent words in the target do-main.411ReferencesSatanjeev Banerjee and Alon Lavie.
2005.
Meteor: Anautomatic metric for MT evaluation with improvedcorrelation with human judgments.
In In Proceed-ings of Workshop on Intrinsic and Extrinsic EvaluationMeasures for MT and/or Summarization at ACL.Nicola Bertoldi and Marcello Federico.
2009.
Do-main adaptation for statistical machine translation withmonolingual resources.
In StatMT ?09: Proceedingsof the Fourth Workshop on Statistical Machine Trans-lation.John Blitzer and Hal Daume?
III.
2010.
Do-main adaptation.
Tutorial at the InternationalConference on Machine Learning, http://adaptationtutorial.blitzer.com/.Jorge Civera and Alfons Juan.
2007.
Domain adap-tation in statistical machine translation with mixturemodelling.
In StatMT ?07: Proceedings of the SecondWorkshop on Statistical Machine Translation.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of the Con-ference of the Association for Computational Linguis-tics (ACL).Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,and Alex Waibel.
2005.
Adaptation of the translationmodel for statistical machine translation based on in-formation retrieval.
In European Association for Ma-chine Translation.H.
Hotelling.
1936.
Relation between two sets of vari-ables.
Biometrica, 28:322?377.J.
Jiang.
2008.
A literature survey on domainadaptation of statistical classifiers.
Available athttp://sifaka.cs.uiuc.edu/jiang4/domain_adaptation/survey.R.
Jonker and A. Volgenant.
1987.
A shortest augment-ing path algorithm for dense and sparse linear assign-ment problems.
Computing, 38(4):325?340.Philipp Koehn and Josh Schroeder.
2007.
Experiments indomain adaptation for statistical machine translation.In StatMT ?07: Proceedings of the Second Workshopon Statistical Machine Translation.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Proceed-ings of the Conference of the Association for Compu-tational Linguistics (ACL).Franz Josef Och.
2003.
Minimum error rate training forstatistical machine translation.
In Proceedings of theConference of the Association for Computational Lin-guistics (ACL), Sapporo, Japan, July.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In Proceedings of theConference of the Association for Computational Lin-guistics (ACL), pages 311?318.Matthew Snover, Bonnie Dorr, and Richard Schwartz.2008.
Language and translation model adaptation us-ing comparable corpora.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing (EMNLP).412
